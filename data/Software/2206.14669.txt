Towards a Data-Driven Requirements Engineering Approach:
Automatic Analysis of User Reviews

Jialiang Wei∗, Anne-Lise Courbis∗, Thomas Lambolais∗, Binbin Xu∗,
Pierre Louis Bernard∗∗ and G´erard Dray∗

∗: EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Ales, France
∗∗: EuroMov Digital Health in Motion, Univ Montpellier, IMT Mines Ales, Montpellier, France
jialiang.wei@mines-ales.fr

2
2
0
2

n
u
J

9
2

]
L
C
.
s
c
[

1
v
9
6
6
4
1
.
6
0
2
2
:
v
i
X
r
a

This is the translated English version, the origi-
nal work was written in French, attached in this
PDF: Go to page 5

Abstract
We are concerned by Data Driven Requirements Engi-
neering, and in particular the consideration of user’s
reviews. These online reviews are a rich source of in-
formation for extracting new needs and improvement
requests. In this work, we provide an automated anal-
ysis using CamemBERT, which is a state-of-the-art
language model in French. We created a multi-label
classiﬁcation dataset of 6000 user reviews from three
applications in the Health & Fitness ﬁeld1. The results
are encouraging and suggest that it’s possible to iden-
tify automatically the reviews concerning requests for
new features.

Keywords
Requirements Engineering, Data Driven Requirements
Engineering, Deep Learning, NLP, CamemBERT

1

Introduction

Requirements Engineering (RE) aims to ensure that
systems meet the needs of their stakeholders including
users, sponsors, and customers. Placed in the prelim-
inary and upstream stage of Software Engineering cy-
cle, it plays a vital role in ensuring the software quality
[1]. RE includes requirements elicitation, requirements
modeling & analysis, requirements veriﬁcation and re-
quirements management. Requirements elicitation is
the ﬁrst step of requirements engineering, which aims
to discover the real needs of stakeholders [2]. Conven-
tional approaches aimed at establishing explicit mod-
els of requirements based on interviews, brainstorm-
ing, observations, etc. are now enriched by new ones
which directly exploit the user feedback posted on app
markets or social networks. Thus, the RE community
proposes to take up new challenges [3] consisting in

developing a Data Driven Requirements Engineering
allowing to process a large volume of user feedback.
The app markets, like Google Play and App Store, pro-
vide a valuable channel for users and app developers to
communicate, through which users express their com-
ments on apps – including praise and criticism of the
application, user experience, bug report and feature
requests [4]. Many of these feedback are helpful and
can serve for requirements elicitation. For example,
Facebook app receives more than 4000 user reviews
per day, of which 30% can be used for requirements
elicitation [4]. While manually sifting through these
feedback is laborious. To ﬁlter out the most useful user
feedback, we employ Bidirectional Encoder Represen-
tations from Transformers (BERT) [5], a deep learning
model based on Transformer architecture. The pre-
trained BERT model can be ﬁne-tuned for diﬀerent
downstream tasks, including text classiﬁcation, ques-
tion answering, natural language inference, etc. Mod-
els based on BERT have achieved the state-of-the-
art metric on almost all natural language processing
(NLP) tasks. The original BERT is pre-trained with
English corpus, while CamenBERT [6] is a language
model for French which is pre-trained on the French
sub-corpus of the OSCAR.
For BERT model ﬁne-tuning, new applications should
be trained/retrained with labelled data from down-
stream tasks. There exists several user reviews dataset
for classiﬁcation task [7, 8, 9, 10, 11, 12, 13]. They are
all in English, two of them are multilingual [8, 13], but
none of them contains enough reviews in French. To ﬁll
this gap, we created a French user reviews dataset in-
cluding 6000 reviews for multi-label classiﬁcation task,
it contains four labels: rating, bug report, feature re-
quest and user experience. As the main theme of our
project is data driven development applied in system
monitoring on the elderly for

2 Method

1Dataset

is available at:

https://github.com/Jl-wei/

APIA2022-French-user-reviews-classification-dataset

27`eme Conf´erence Nationale sur les Applications Pratiques

de l’Intelligence Artiﬁcielle

2.1 Dataset
NLP tasks based on CamemBERT model require large
number of labelled user reviews on apps in French. To

1

 
 
 
 
 
 
the best of our knowledge, such dataset does not ex-
ist yet. This drives us to create French user reviews
dataset and to share it with the community. Firstly,
we collected the French user reviews on three appli-
cations from Google Play: Garmin Connect, Huawei
Health and Samsung Health. The number of reviews
collected and the sampled size to constitute the dataset
during the learning phase are presented in Table 1.
Then we manually labelled all the sampled user re-
views. As proposed in the work of [12], we selected
four labels: rating, bug report, feature request and user
experience. Ratings are simple text which express the
overall evaluation to that app, including praise, crit-
icism, or dissuasion. Bug reports show the problems
that users have met while using the app, like data loss,
app crash, connection error, etc. Feature requests cate-
gory reﬂects the demand of users on new functionality,
In user experience,
new content, new interface, etc.
users describe their practical experience in relation to
the functionality of the app, how certain functions are
helpful. As we can observe from Table 3, it shows ex-
amples of labelled user reviews, each review can belong
to one or more categories resulting a multi-label clas-
siﬁcation problem.

App
Garmin Connect
Huawei Health
Samsung Health

#Reviews
22880
10304
18400

Sample
2000
2000
2000

Table 1: Applications and collected reviews for the
pre-training phase

App
Garmin Connect
Huawei Health
Samsung Health

Total
2000
2000
2000

(R)
1260
1068
1324

(B)
757
819
491

(F)
170
384
486

(U)
493
289
349

Table 2: Manual classiﬁcation of reviews into 4 fami-
lies: (R)ating, (B)ug report, (F)eatures request, (U)ser
experience

The user reviews are annotated by four authors of this
paper and then reviewed by Jialiang Wei. The number
of reviews classiﬁed in each of the categories for each
of the applications is given in Table 2. The sum of
classiﬁed reviews does not equal the total of reviews
because some reviews have been assigned to more than
one class.
2.2 Model
The user reviews classiﬁcation is a common text clas-
siﬁcation problem in NLP, which aims to assign labels
to textual units [14]. Due to the large amount of text
data, manual classiﬁcation is unpractical, automatic
classiﬁcation is becoming more and more important or
necessary in real applications. In recent years, user re-
views classiﬁcation problem has been addressed with

many machine learning (ML) or deep learning (DL)
approaches. Maalej et al.
[12] used Na¨ıve Bayes, De-
cision Tree and Maximum Entropy to classify user re-
views into bug reports, feature requests, user experi-
[15]
ences, and text ratings. Restrepo Henao et al.
applied BERT to classify user reviews in three cate-
gories(problem report, feature request and irrelevant),
and they compared the performance of conventional
ML, CNN-based DL model, BERT model and found
that BERT allows obtaining the highest precision and
recall. Mekala et al.
[16] compared the performance
of crowdsourcing, SVM, Na¨ıve Bayes, FastText-based
classiﬁer, ELMo and BERT on classifying useless and
helpful app reviews. Among all these methods, BERT
performed the best overall. As BERT archived the best
result on classiﬁcation of user feedback, we decided to
utilize BERT for the classiﬁcation task in this work.
And we use CamemBERT [6], model trained with a
large French corpus, for classifying our French user re-
views dataset.

Figure 1: CamemBERT for multi-label classiﬁcation

CamemBERT cannot use raw text as input, each user
review is at ﬁrst tokenized into subword units [17], and
’<s>’ and ’</s>’ is added at the start and end of
the review. The tokenized review is then padded to
a length of 512 with a special ‘<PAD>’ token, and
attention masks is added for each of ‘<PAD>’ token.
Finally, each subword token is mapped to a numeric
ID. To convert the CamemBERT representation to the
classiﬁcation task, we have also adapted the architec-
ture of CamemBERT by adding a linear layer with 4
outputs on the its top, as shown in ﬁgure 1

3 Experiment

For our experiments, we used pre-trained Camem-
BERT model from HuggingFace platform. Each ex-
perience was trained for 3 epochs, with a batch size of
1 and used the AdamW optimizer with a learning rate
2e−5 on a machine with 48 GB RAM, an Intel i7 pro-
cessor and NVIDIA Quadro M2200 GPU with 4 GB
VRAM. To evaluate the performance of CamemBERT
on user feedback classiﬁcation, we designed two types
of experiments.
In the ﬁrst experiments, we trained
and tested the model with the user reviews of the three
apps. While in the second type, we trained the model

CTNT1<s>Tok1</s>CamemBERTTextTokN......TokenizationRBFUTr`es bien

User review

tr`es bon application qui aide `a faire plus activit´es

C’est une tr`es bonne application.
rester toujours actif.

Elle nous aide beaucoup `a

Labels

Rating

Rating, User Experience

Rating, User Experience

Cette appli prends bien en compte les trajets et son syst`eme de
d´efi permet de bien se motiver `a marcher.

User Experience

j’aimais bien cette appli mais elle ne fonctionne plus:
d’erreur t´el´ephone root´e !!

faux et j’ai v´erifi´e.

message

Rating, Bug Report

Hello. It is possible to add the STOP SMOKING function in your
Thank you
application with a Widget for the S3 Frontier watch.

Feature Request

Table 3: Examples of labelled user reviews

with the user reviews of two apps and compared the
performance of the model on the user reviews of these
two apps and on the user reviews of the third app.

3.1 Train and test on user reviews from

same apps

In this experiment, we split 60% of the 6000 user re-
views as training set, 20% as validation set and 20%
as test set in a stratiﬁed manner. For the purpose of
cross validation, each model is trained 10 times with
random split (stratiﬁed sampling) of training and test
sets. As for the evaluation metric, we use precision,
recall and F1 score. The mean performance of 10 runs
is shown in Table 4.

Rating
Bug Report
Feature Request
User Experience
Weighted Average

Precision Recall
0.93
0.93
0.83
0.73
0.89

0.88
0.92
0.85
0.81
0.88

F1
0.91
0.93
0.84
0.77
0.89

Table 4: Classiﬁcation accuracy on user reviews of
three apps

As shown in Table 5, the retrained model archives good
results overall, with a weighted average F1 0.89. While
the performance on user experience is relatively lower
than the other three categories. According to our label-
ing experiences, there would be two reasons. Firstly,
the user experience are more diverse than three other
categories, the model may need a larger training set
to learn the features of that type. The second reason
could probably lie in the fact that four authors par-
ticipated in the annotation of the reviews and their
interpretation of the user experience criterion can in-
ﬂuence the performance of the model, even though the
same deﬁnition / rule is applied.

3.2 Train and test on user reviews from

separate apps

In this experiment, we used the same stratiﬁed sam-
pling strategy: 60% of the reviews of two apps as
training set, 20% as validation. The tests apply to
the remaining 20% and also to all reviews of the third
application. For example, one of these combinations
consisted in running the training / validation on 1600
reviews of Garmin Connect and 1600 of Huawei Health
and the test on the 800 reviews of these applications
and the 2000 reviews of Samsung Health. There are
three combination of apps, for each combination, we
ran 10 times. The mean results of the 30 runs (3 × 10)
is shown in Table 5 and Table 6.

Rating
Bug Report
Feature Request
User Experience
Weighted Average

Precision Recall
0.93
0.93
0.81
0.72
0.88

0.88
0.91
0.85
0.79
0.87

F1
0.90
0.92
0.83
0.76
0.88

Table 5: Classiﬁcation accuracy on 20% rest user re-
views of two apps

Rating
Bug Report
Feature Request
User Experience
Weighted Average

Precision Recall
0.92
0.92
0.74
0.69
0.86

0.88
0.85
0.80
0.77
0.86

F1
0.90
0.88
0.75
0.73
0.85

Table 6: Classiﬁcation accuracy on all user reviews of
third apps

Performances in Table 5 are slightly lower to those in
Table 4, which means that we can get good accuracy
with even smaller training set. As shown in Table 6,
the average precision and recall on unseen apps’ re-
views is just 0.01 − 0.02 (1% to 2%) lower than on the
apps which we have trained on.

International Requirements Engineering Conference
(RE), 2017, pp. 1–10.

[8] S. Scalabrino, G. Bavota, B. Russo, M. D. Penta, and
R. Oliveto, “Listening to the crowd for the release
planning of mobile apps,” IEEE Transactions on Soft-
ware Engineering, vol. 45, no. 1, pp. 68–86, 2019.

[9] E. Guzman, M. El-Haliby, and B. Bruegge, “Ensemble
methods for app review classiﬁcation: An approach for
software evolution,” in 2015 30th IEEE/ACM Interna-
tional Conference on Automated Software Engineering
(ASE), 2015, pp. 771–776.

[10] F. Palomba, M. Linares-V´asquez, and G. e. a. Bavota,
“Crowdsourcing user reviews to support the evolution
of mobile apps,” Journal of Systems and Software,
vol. 137, pp. 143–162, 2018.

[11] A. Ciurumelea, A. Schaufelb¨uhl, S. Panichella, and
H. C. Gall, “Analyzing reviews and code of mobile
apps for better release planning,” in 2017 IEEE 24th
International Conference on Software Analysis, Evo-
lution and Reengineering (SANER), 2017, pp. 91–102.

[12] W. Maalej, Z. Kurtanovi´c, H. Nabil, and C. Stanik,
“On the automatic classiﬁcation of app reviews,”
Requirements Engineering, vol. 21, no. 3, pp. 311–331,
2016.

[13] C. Stanik, M. Haering, and W. Maalej, “Classifying
multilingual user feedback using traditional machine
learning and deep learning,” in 2019 IEEE 27th Inter-
national Requirements Engineering Conference Work-
shops (REW), 2019, pp. 220–226.

[14] S. Minaee, N. Kalchbrenner, E. Cambria, N. Nikzad,
M. Chenaghlu, and J. Gao, “Deep learning–based
text classiﬁcation: A comprehensive review,” ACM
Comput. Surv., vol. 54, no. 3, Apr. 2021.

[15] P. R. Henao, J. Fischbach, D. Spies, J. Frattini, and
A. Vogelsang, “Transfer learning for mining feature re-
quests and bug reports from tweets and app store re-
views,” in 2021 IEEE 29th International Requirements
Engineering Conference Workshops (REW), 2021, pp.
80–86.

[16] R. R. Mekala, A. Irfan, E. C. Groen, A. Porter, and
M. Lindvall, “Classifying user requirements from on-
line feedback in small dataset environments using deep
learning,” in 2021 IEEE 29th International Require-
ments Engineering Conference (RE), 2021, pp. 139–
149.

[17] R. Sennrich, B. Haddow, and A. Birch, “Neural
machine translation of rare words with subword
units,” in Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics (Volume
1: Long Papers). Berlin, Germany: Association for
Computational Linguistics, Aug. 2016, pp. 1715–1725.

4 Discussion & Future Work

In this work, we created a dataset for the multi-label
classiﬁcation of reviews written in French by users of
physical activity monitoring applications. We used the
CamemBERT model to classify these reviews and the
results showed good performance which conﬁrmed the
experience in other works. The training and test ex-
periments on diﬀerent applications showed the feasi-
bility of generalizing the model on applications from
the same App category. These results encourage us to
continue our work on Data Driven Requirements Engi-
neering for the development of diﬀerent versions of an
application for preventing the adverse aging eﬀects by
monitoring the physical activity of seniors in a context
of healthy aging. We plan to reﬁne the classiﬁcation
of requests for new functionalities by making it pos-
sible to identify, through an unsupervised approach,
the concepts of the domain with respect to the target
application, such as walking speeds and times, imbal-
ances, sleep monitoring, etc. This classiﬁcation could
provide a visual scheme of the functionalities requested
by the users for App designer.
The overall objectives of the project will be to (i)
group the requests and proposals by category of re-
quirements, (ii) match the identiﬁed requirements with
the models present in App speciﬁcations, in order to
be able to take them all into account during the design
phase with a more relevant and optimised manner.

References

[1] A. van Lamsweerde, Requirements Engineering: From
System Goals to UML Models to Software Speciﬁca-
tions. Wiley, Jan. 2009.

[2] A. Bennaceur, T. Than Tun, Y. Yu, and B. Nuseibeh,
“Requirements engineering,” in Handbook of Software
Engineering. Springer Verlag, 2019, pp. 1–44.

[3] X. Franch, “Data-driven requirements engineering: A
guided tour,” in Communications in Computer and
Information Science, vol. 1375.
Springer, 2021, pp.
83–105.

[4] D. Pagano and W. Maalej, “User feedback in the app-
store: An empirical study,” in 2013 21st IEEE Inter-
national Requirements Engineering Conference (RE),
2013, pp. 125–134.

[5] J. Devlin, M. W. Chang, K. Lee, and K. Toutanova,
“Bert: Pre-training of deep bidirectional transformers
for language understanding,” in NAACL HLT 2019
— 2019 Conference of the North American Chapter
of
the Association for Computational Linguistics:
Human Language Technologies — Proceedings of the
Conference, vol. 1, Oct. 2019, pp. 4171–4186.

[6] L. Martin, B. Muller, and P. J. e. a. Ortiz Su´arez,
“Camembert: a tasty french language model,” in 58th
Annual Meeting of the Association for Computational
Linguistics, Seattle, United States, Jul. 2020.

[7] G. Williams and A. Mahmoud, “Mining twitter feeds
for software user requirements,” in 2017 IEEE 25th

Versuneingénieriedesexigencesdirigéeparlesdonnées:analyseautomatiqued’avisd’utilisateursJialiangWei∗,Anne-LiseCourbis∗,ThomasLambolais∗,BinbinXu∗,PierreLouisBernard∗∗andGérardDray∗∗:EuroMovDigitalHealthinMotion,UnivMontpellier,IMTMinesAles,Ales,France∗∗:EuroMovDigitalHealthinMotion,UnivMontpellier,IMTMinesAles,Montpellier,France∗:firstname.lastname@mines-ales.fr∗∗:firstname.lastname@umontpellier.frRésuméCestravauxs’inscriventdanslecadredel’ingénieriedesexigencesdirigéeparlesdonnéesetnotammentlesavisd’utilisation.Lescommentairesenligned’utilisateursd’applicationssontunesourceimportanted’informationspourenaméliorerleurfonctionnementetenextrairedenouveauxbesoins.Nousproposonsuneanalyseautomati-séeenutilisantCamemBERT,unmodèledelangueenfran-çaisquifaitaujourd’huiétatdel’art.Afind’affinercemo-dèle,nousavonscrééunjeudedonnéesdeclassificationmulti-labelsde6000commentairesissusdetroisapplica-tionsdudomainedel’activitéphysiqueetlasanté1.Lesrésultatssontencourageantsetpermettentd’identifierlesavisconcernantdesdemandesdenouvellesfonctionnalités.Mots-clésIngéniériedesexigences,Ingénierieguidéeparlesdon-nées,TALN,CamemBERT,ApprentissageprofondAbstractWeareconcernedbyDataDrivenRequirementsEnginee-ring,andinparticulartheconsiderationofuser’sreviews.Theseonlinereviewsareanimportantsourceofinforma-tionforextractingnewneedsandimprovementrequests.Inthispaper,weprovideanautomatedanalysisusingCa-memBERT,whichisastate-of-the-artlanguagemodelinFrench.Inordertofinetunethemodel,wecreatedamulti-labelclassificationdatasetof6000userreviewsfromthreeapplicationsintheHealth&Fitnessfield.Theresultsareencouragingandmakeitpossibletoidentifyautomaticallythereviewsconcerningrequestsfornewfeatures.KeywordsRequirementsEngineering,DataDrivenRequirementsEn-gineering,NLP,CamemBERT,DeepLearning1.Donnéesdisponibleenligne:https://github.com/Jl-wei/APIA2022-French-user-reviews-classification-dataset1IntroductionL’ingénieriedesexigences(IE)estl’unedesphasesducyclededéveloppementdessystèmes,visantàélaboreruncahierdeschargesaussiclairetcompletquepossible,àpar-tirdesinterviewsdedifférentespartiesprenantes(clients,utilisateurs,donneursd’ordre).Ils’agitd’unedesphaseslespluscritiques[1],jouantunrôlefondamentalpourobtenirunlogicieldequalité.Lesactivitésprincipalesdel’IEsont:laconduitedesinterviews,l’élicitation,lamodélisationdudomaineetl’analysedefaisabilité.L’étaped’élicitationapourobjectifdemettreenexerguelesbesoinsréelsdespartiesprenantes[2].Lesapprochestraditionnellesvisantàétablirdesmodèlesexplicitesd’exigencesàpartird’inter-views,brainstorming,observations,etc.sontenrichiespardenouvellesapproches,visantàexploiterlesretoursdesutilisateursmisenlignesurlesstoresd’applicationsoulesréseauxsociaux.Ainsi,lacommunautéd’IEproposedere-leverdenouveauxdéfis[3]consistantàdévelopperunein-génieriedesexigencesdirigéeparlesdonnéespermettantdetraiterunvolumeimportantd’avisd’utilisateurs.Lesstoresd’applications,commeGooglePlay®etAppStore®,sontdevenusdesplate-formesdecommunicationentreutilisateursetdéveloppeursassurantlacollected’avissurchacunedesapplicationsentéléchargement.Cesavissontricheseninformationcarilscontiennentdescritiquesetdespréférences,desretoursd’expérience,desrapportsd’erreuretdesdemandesdenouvellesfonctionnalités.Parexemple,l’applicationFacebookreçoitplusde4000com-mentairesjournaliersdont30%peuventêtreconsidéréscommeunesourcepouridentifierdenouveauxbesoins[4].Exploitermanuellementdetellessourcesseraitlaborieux.Nousproposonsd’effectuerunTraitementAutomatiqueduLangageNaturel(TALN)pourfiltrerlesavisetciblerlespluspertinentsenvued’identifierdenouvellesexi-gences.Plusprécisément,nousnoussommesintéressésàBERT(BidirectionalEncoderRepresentationsfromTrans-formers)[5],quiestunmodèled’apprentissageprofondbasésurunearchitecturedetypeTransformer.BERTpeutêtreaffinépoureffectuerdifférentestâchestellesquelaclassificationdetextes,laréponseauxquestions,l’infé-renceenlangagenaturel,etc.CesontlesmodèlesbasésJ.Wei,A.-L.Courbis,T.Lambolais,B.Xu,P.-L.Bernard,G.Dray119APIA@PFIA2022surBERTquiontobtenulesmeilleuresrésultatssurlaplu-partdestâchesdelacommunautéTALN.BERTétanten-traînéenanglais,nousnoussommestournésversCamem-BERT[6],unmodèledetypeBERTquiaétéentraînésurlecorpusOSCARenfrançaisafind’avoirdemeilleuresper-formancessurlescommentairesécritsenfrançais.PouraffinerlemodèleBERT,ilestnécessairedel’entraî-neravecunensemblededonnéesannoté.Ilexisteplusieursjeuxdedonnéesdecommentairesannotéspoureffectuerlaclassification[7–13].Laplupartdecesjeuxdedonnéessontenanglais.Certainssontmulti-langues[8,13].Maisaucund’euxn’intègresuffisammentdecommentairesrédigésenfrançais.Nousproposonsdoncdecréerunjeudedonnéesenfrançaisetd’explorerlesrésultatsobtenus.Notresujetd’étudeétantàtermeledéveloppementselonuneapprochedirigéeparlesdonnéesd’applicationsdesuivideséniorspour«bienvieillirensanté»,nousnoussommesintéres-sésauxcommentairesdetroisapplicationsdelacatégorie«Health&Fitness»deGooglePlay.Danslapartiesuivantenousprésentonslejeudedonnéesconstituéainsiquelaméthodemiseenœuvrepourconduirenotreexpérimentation.Lesrésultatsdeclassificationobte-nussontdiscutésdanslatroisièmepartie.Enfin,dansladernièrepartie,nousexposonslesperspectivesenvisagéessurcestravaux.2Méthodemiseenœuvrepourl’ap-prentissage2.1JeudedonnéesetsonannotationL’usagedeCamemBERTpourclassifierlesavisd’utilisa-teursécritsenfrançaisnécessiteunjeudedonnéesannoté.Enl’étatactueldenosconnaissances,iln’enexistepas.Nousenavonsdonccrééun.Nousavonstoutd’abordcol-lectésurlaplateformeGooglePlaydesavisrédigésenfran-çaisconcernantlesapplicationsGarminConnect,HuaweiHealthetSamsungHealth.Lenombredecommentairescollectésetlataillechoisiepourconstituerlejeudedon-néespourlaphased’apprentissagesontprésentésdansleTableau1.Nousavonsensuiteassociémanuellementdeslabelsauxavis.Nousavonschoisid’utiliserquatrelabels,commecelaestproposédans[12]:Évaluation,Rapportd’erreur,DemandedenouvellesfonctionnalitésetExpé-rienceutilisateur.L’évaluationestgénéralementuntextesimplequiexprimelesentimentgénéraldel’utilisateursousformed’éloge,decritiqueoudedissuasion.Lerapportd’erreurestrelatifauxproblèmesrencontréslorsdel’uti-lisationdel’application:pertededonnées,arrêtbrutaldel’application,problèmedeconnexion,etc.Lademandedenouvellesfonctionnalitésconcernedenouveauxservices,denouveauxcontenusouencoredenouvellesinterfaces.Enfin,lesavisdetypeexpérienceutilisateursontdesex-périencesrelatéesparlesutilisateursquisontdécritesparexemplecommedesconseilsd’utilisation,desfonctionsoudesusagesperçuscommetrèsutilesoufacilesd’utilisation.Ilestpossibled’associerplusieurslabelsàunmêmeavis.Parexemple,l’avis:“c’estunetrèsbonneapplication.ElleApp#AvisÉchantillonGarminConnect228802000HuaweiHealth103042000SamsungHealth184002000TABLEAU1–Applicationsetaviscollectéspourlaphased’entraînementnousaidebeaucoupàrestertoujoursactif.”seraannotédanslescatégoriesÉvaluationetExpérienceUtilisateur.L’avis“j’aimaisbiencetteapplicationmaisellenefonc-tionneplus:messaged’erreurtéléphonerooté!!fauxetj’aivérifié.”seraannotédanslescatégoriesÉvaluationetRapportd’erreur.Lesavissontannotésparquatreauteursdel’article,etrévisésparJialiangWei.LeTableau2in-diquelenombred’avisclassésdanschacunedescatégoriespourlestroisapplicationscibles.Lasommedesavisclassésn’estpaségaleautotaldesavispuisquecertainsavisontétéaffectésàplusieursclasses.AppTotal(Ev)(R)(D)(Exp)GarminConnect20001260757170493HuaweiHealth20001068819384289SamsungHealth20001324491486349TABLEAU2–Classificationmanuelledesavisenquatrefamilles:(Ev)aluation,(R)apportd’erreur,(D)emandedefonctions,(Exp)érienceutilisateurCTNT1<s>Tok1</s>CamemBERTTextTokN......TokenizationEvRDExpFIGURE1–Vued’ensembledumodèleCamemBERTpourlaclassificationmultilabels2.2ModèledeclassificationLaclassificationdesavisd’utilisateursestunproblèmedeclassificationdetypeTALN[14].Cesdernièresannées,denombreusesméthodesd’apprentissagestatistiqueontétéappliquéesàlaclassificationd’avis.Maalejetal.[12]uti-lisedesréseauxbayésiens,desarbresdedécisionetrégres-sionlogistiquemultinomialepoureffectuerlaclassificationdesavisdanscesmêmesquatrecatégories:évaluation,rap-portd’erreur,demandedefonctionnalitésetexpérienceuti-lisateur.RestrepoHenaoetal.[15]appliqueBERTpourfairelaclassificationdesavisdanslescatégories:rapportdeproblèmes,demandedefonctionnalités,etavisnonper-tinent;ilscomparentlesperformancesdesmodèlesd’ap-prentissageBERTetd’unréseaudeneuronesconvolutifàapprentissageprofondetconcluentqueBERTobtientlesVersuneingénieriedesexigencesdirigéeparlesdonnées:analyseautomatiqued’avisd’utilisateursAPIA@PFIA2022120meilleurestauxdeprécisionetderappel.Mekalaetal.[16]comparentlaperformancedansledomaineducrowdsour-cing(productionparticipative)deBERTavecdesmodèlesdeMachinesàVecteursdeSupport,desclassifieursdetypeFastTextetELMosurdesavisd’utilisateursclassésendeuxcatégories:inutileetutile.BERTobtientégalementlesmeilleursrésultats.LesbonnesperformancesdeBERTontguidénotrechoixsursaversionfrançaiseCamemBERT.CamemBERTnepeututiliserdutextebrutenentrée.Unephasedepré-traitementestnécessaire:chaqueavisestdé-coupéenunensembledetermes,oujetons[17].Lesbalises<s>et</s>sontajoutéespourmarquerrespectivementledébutetlafindel’avis.Lesavissontensuiteformatésàlalongueur512encomplétantceuxquisontdetailleinfé-rieureaveclabalise<PAD>.Ceuxquisontdetaillesupé-rieuresonttronqués.Unmasqueestalorsassociéàchaqueavisafinderepérerlessymboles<PAD>(valeur0)etlestermes(valeur1).Puis,onattribueàchaquetermeuniden-tifiantnumérique.Enfin,pouradapterCamemBERTàlatâchedeclassificationsouhaitée,nousmodifionssonarchi-tectureenajoutantàsondernierniveauunecouchelinéaireàquatresorties,commelemontrelaFigure1.3ExpérimentationsetrésultatsNousavonsutilisélabibliothèquePyTorchpourlamiseenœuvreCamemBERT.Lemodèleaétéentraînéavectroisepochs,leparamètrebatch_sizeetl’optimiseurAdamWavecuntauxd’apprentissagefixéà2e−5.Lemo-dèleaétéentraînésurunordinateurde48GodemémoireRAM,munid’unprocesseurInteli7-7820HQetd’unecartegraphiqueNVIDIAQuadroM2200de4GodeVRAM.L’évaluationdelaperformancedeCamemBERTsurlaclas-sificationdesaviss’estfaitesurdeuxexpérimentations.Danslapremière,lesmodèlessontentraînéssurunepar-tiedesavisdestroisapplicationsettestéssurl’autrepartie.Danslasecondeexpérimentation,lesmodèlessontentraî-néssurlesavisdedeuxapplicationsetévaluéssurcesap-plicationsetsurlatroisièmeapplication.3.1Apprentissageàpartirdestroisapplica-tionsPourcetteexpérimentation,nousavonssélectionné60%desavisdestroisapplicationscommeensembled’appren-tissage,20%commeensembledevalidationet20%commeensembledetestenutilisantunéchantillonnagestratifié.Cetteopérationaétérépétée10fois.Lescritèresd’éva-luationdeperformancedesmodèlessont:laprécision,lerappeletlaF1-Mesure.Lesrésultatsmoyensobtenussurles10apprentissagessontprésentésdansleTableau3.CommelemontreleTableau3,lesrésultatsobtenussontcorrectsdansl’ensemble:lamoyennedelaF1-Mesureestde0,89.LesrésultatsconcernantlecritèreExpérienceUtilisateursontinférieursauxtroisautres.Cecis’expliquededeuxfaçons.Toutd’abordlesavisconcernantcecritèresontplusvariés,denaturemoinshomogènequelesautrescritères,cequirendplusdifficilel’apprentissagedescarac-téristiques.Aussi,ilseraitnécessairedefaireunapprentis-PrécisionRappelF1Évaluation0,880,930,91Rapportd’erreur0,920,930,93Demandedefonctions0,850,830,84Expérienceutilisateur0,810,730,77Moyennepondérée0,880,890,89TABLEAU3–Résultatsdelaclassificationdesavisdestroisapplicationssagesurunensembleplusimportantd’avispouraméliorerlesrésultats.Laseconderaisonrésidevraisemblablementdanslefaitquequatrepersonnesontparticipéàl’anno-tationdesavisetleurinterprétationducritèreExpérienceUtilisateurpeutinfluencerlesperformancesdumodèle.3.2Apprentissageàpartirdedeuxapplica-tionsDanscetteexpérimentation,nousavonsutilisélamêmestratégied’échantillonagestratifié:60%desavisdedeuxapplicationscommebased’apprentissage,20%commeva-lidation.Lestestss’appliquentsurles20%restantsetéga-lementsurtouslesavisdelatroisièmeapplication.Nousavonsfaitcecipourlestroiscombinaisonspossiblesd’ap-plicationssélectionnéespourl’apprentissageversusletest.Parexemple,unedecescombinaisonsaconsistéàréali-serl’apprentissage/validationsur1600avisdeGarminConnectet1600deHuaweiHealthetletestsur800avisdecesapplicationsetles2000avisdeSamsungHealth.Pourchaquecombinaison,10expériencesontétéréalisées.Lesrésultatsmoyensdes30apprentissages(3×10)sontpré-sentésdanslesTableaux4et5.PrécisionRappelF1Évaluation0,880,930,90Rapportd’erreur0,910,930,92Demandedefonctions0,850,810,83Expérienceutilisateur0,790,720,76Moyennepondérée0,870,880,88TABLEAU4–Résultatsdeclassificationdesavispourles20%restantsdedeuxapplicationsPrécisionRappelF1Évaluation0,880,920,90Rapportd’erreur0,850,920,88Demandedefonctions0,800,740,75Expérienceutilisateur0,770,690,73Moyennepondérée0,860,860,85TABLEAU5–Résultatsdeclassificationdesavis:appren-tissagesurdeuxapplicationsettestsurlatroisièmeappli-cationLesrésultatsprésentésdansleTableau4sontlégèrementinférieursàceuxduTableau3.Ilsmontrentquel’onpeutobtenirdebonnesperformancesdeclassificationavecunjeudedonnéesrestreint.DansleTableau5,onpeutobser-J.Wei,A.-L.Courbis,T.Lambolais,B.Xu,P.-L.Bernard,G.Dray121APIA@PFIA2022verquelamoyennedelaprécisionetdurappelpourles-quelslesmodèlesn’ontpasétéentraînéssontinférieursde1-2%parrapportauxmodèlesayantservipourl’entraîne-ment.Cetteexpérimentationmontrequelesrésultatsrestentdetrèsbonnequalitéenentraînantlemodèlesurunsous-ensembled’applications.4DiscussionettravauxfutursDanscetravail,nousavonscrééunjeudedonnéespourlaclassificationmulti-labelsd’avisrédigésenfrançaisd’uti-lisateursd’applicationsdesuivid’activitéphysique.NousavonsutilisélemodèleCamemBERTpourclassifiercesavisetlesrésultatsobtenusmontrentdebonnesperfor-mances.Lesexpérimentationsd’entraînementetdetestsurdesapplicationsdistinctesmontrentqu’ilestpossibledegé-néraliserlemodèlesurdesapplicationsdemêmechampapplicatif.Cesrésultatsnousencouragentàpoursuivrenostravauxrelatifsàl’ingénieriedesexigencesdirigéeparlesdonnéespourledéveloppementdedifférentesversionsd’uneapplicationdepréventiondeseffetsduvieillissementparlesuividel’activitéphysiquedesseniorspourbienvieillirensanté.Nousenvisageonsd’affinerlaclassificationdesdemandesdenouvellesfonctionnalitésenpermettantd’identifier,paruneapprochenonsupervisée,lesconceptsdudomainedel’applicationcible,commeparexemple,lesvitessesettempsdemarche,lesdéséquilibresoulesuividusommeil.Cetteclassificationpourraitêtreprésentéevisuel-lementpourindiquerauconcepteurquellessontlesfonc-tionnalitésprincipalementdemandéesparlesutilisateurs.L’objectifglobalserade(i)regrouperlesdemandesetpro-positionsparcatégoriedebesoins,(ii)mettreencorrespon-dancecesbesoinsaveclesmodèlesprésentsdanslecahierdescharges,afindepouvoirlesprendreencompteplusfa-cilementdanslaconception.Références[1]A.vanLamsweerde,RequirementsEngineering:FromSys-temGoalstoUMLModelstoSoftwareSpecifications.Wi-ley,January2009.[2]A.Bennaceur,T.ThanTun,Y.Yu,andB.Nuseibeh,“RequirementsEngineering,”inHandbookofSoftwareEngineering.SpringerVerlag,2019,pp.1–44.[3]X.Franch,“Data-DrivenRequirementsEngineering:AGui-dedTour,”inCommunicationsinComputerandInformationScience,vol.1375.Springer,2021,pp.83–105.[4]D.PaganoandW.Maalej,“Userfeedbackintheappstore:Anempiricalstudy,”in201321stIEEEInternationalRequi-rementsEngineeringConference(RE),2013,pp.125–134.[5]J.Devlin,M.W.Chang,K.Lee,andK.Toutanova,“BERT:Pre-trainingofdeepbidirectionaltransformersforlanguageunderstanding,”inNAACLHLT2019—2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies—ProceedingsoftheConference,vol.1,October2019,pp.4171–4186.[6]L.Martin,B.Muller,andP.J.e.a.OrtizSuárez,“CamemBERT:aTastyFrenchLanguageModel,”in58thAnnualMeetingoftheAssociationforComputationalLinguistics,Seattle,UnitedStates,July2020.[7]G.WilliamsandA.Mahmoud,“MiningTwitterFeedsforSoftwareUserRequirements,”in2017IEEE25thInterna-tionalRequirementsEngineeringConference(RE),2017,pp.1–10.[8]S.Scalabrino,G.Bavota,B.Russo,M.D.Penta,andR.Oli-veto,“ListeningtotheCrowdfortheReleasePlanningofMobileApps,”IEEETransactionsonSoftwareEngineering,vol.45,no.1,pp.68–86,2019.[9]E.Guzman,M.El-Haliby,andB.Bruegge,“EnsembleMe-thodsforAppReviewClassification:AnApproachforSoftwareEvolution,”in201530thIEEE/ACMInternatio-nalConferenceonAutomatedSoftwareEngineering(ASE),2015,pp.771–776.[10]F.Palomba,M.Linares-Vásquez,andG.e.a.Bavota,“Crowdsourcinguserreviewstosupporttheevolutionofmobileapps,”JournalofSystemsandSoftware,vol.137,pp.143–162,2018.[11]A.Ciurumelea,A.Schaufelbühl,S.Panichella,andH.C.Gall,“Analyzingreviewsandcodeofmobileappsforbetterreleaseplanning,”in2017IEEE24thInternationalConfe-renceonSoftwareAnalysis,EvolutionandReengineering(SANER),2017,pp.91–102.[12]W.Maalej,Z.Kurtanovi´c,H.Nabil,andC.Stanik,“Ontheautomaticclassificationofappreviews,”RequirementsEngineering,vol.21,no.3,pp.311–331,2016.[13]C.Stanik,M.Haering,andW.Maalej,“ClassifyingMulti-lingualUserFeedbackusingTraditionalMachineLearningandDeepLearning,”in2019IEEE27thInternationalRequi-rementsEngineeringConferenceWorkshops(REW),2019,pp.220–226.[14]S.Minaee,N.Kalchbrenner,E.Cambria,N.Nikzad,M.Chenaghlu,andJ.Gao,“DeepLearning–BasedTextClassification:AComprehensiveReview,”ACMComput.Surv.,vol.54,no.3,April2021.[15]P.R.Henao,J.Fischbach,D.Spies,J.Frattini,andA.Vogel-sang,“TransferLearningforMiningFeatureRequestsandBugReportsfromTweetsandAppStoreReviews,”in2021IEEE29thInternationalRequirementsEngineeringConfe-renceWorkshops(REW),2021,pp.80–86.[16]R.R.Mekala,A.Irfan,E.C.Groen,A.Porter,andM.Lind-vall,“ClassifyingUserRequirementsfromOnlineFeed-backinSmallDatasetEnvironmentsusingDeepLearning,”in2021IEEE29thInternationalRequirementsEngineeringConference(RE),2021,pp.139–149.[17]R.Sennrich,B.Haddow,andA.Birch,“Neuralmachinetranslationofrarewordswithsubwordunits,”inProcee-dingsofthe54thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).Ber-lin,Germany:AssociationforComputationalLinguistics,August2016,pp.1715–1725.Versuneingénieriedesexigencesdirigéeparlesdonnées:analyseautomatiqued’avisd’utilisateursAPIA@PFIA2022122