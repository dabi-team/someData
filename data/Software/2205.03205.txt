2
2
0
2

y
a
M
6

]

R
C
.
s
c
[

1
v
5
0
2
3
0
.
5
0
2
2
:
v
i
X
r
a

Unlimited Lives: Secure In-Process Rollback with Isolated
Domains

Merve Turhan
Ericsson Security Research
Kista, Sweden
imec-Distrinet, KU Leuven
Leuven, Belgium
merve.turhan@ericsson.com

Thomas Nyman
Ericsson Product Security
Jorvas, Finland
thomas.nyman@ericsson.com

Christoph Bauman
Ericsson Security Research
Kista, Sweden
christoph.bauman@ericsson.com

Jan Tobias Mühlberg
imec-Distrinet, KU Leuven
Leuven, Belgium
jan.muehlberg@kuleuven.be

ABSTRACT
The use of unsafe programming languages still remains one of the
major root causes of software vulnerabilities. Although well-known
defenses that detect and mitigate memory-safety related issues exist,
they don’t address the challenge of software resilience, i.e., whether
a system under attack can continue to carry out its function when
subjected to malicious input. We propose secure rollback of iso-
lated domains as an efficient and secure method of improving the
resilience of software targeted by run-time attacks. We show the
practicability of our methodology by realizing a software library for
Secure Domain Rollback (SDRoB) and demonstrate how SDRoB
can be applied to real-world software.

INTRODUCTION

1
Software written in unsafe programming languages can suffer from
various memory-related vulnerabilities [35] that allow run-time at-
tacks, such as control-flow attack and non-control-data attacks [13],
to compromise program behavior. Attackers and malicious software
use such run-time attacks to gain access to vulnerable software and
systems. According to the Google Project Zero "0day In the Wild"
dataset over 70% of the zero-day vulnerabilities between July 2014
and March 2022 can be attributed to memory-safety issues [115].
Security research into run-time attacks has, during the past 30 years,
yielded an ongoing arms race between increasingly sophisticated
attacks and run-time defenses to mitigate such attacks [96]. Today,
major operating systems provide such mitigations by default. The
mitigations include non-executable stack and heap areas, address-
space-layout randomization (ASLR) [65], toolchain hardening op-
tions such as stack canaries [105], and hardware-enforced control-
flow integrity (CFI) [28]. However, virtually all currently known
defenses mitigate detected attacks by terminating the victim ap-
plication [2, 6–12, 16–18, 24, 25, 27, 30–34, 36, 38, 39, 41, 45,
49, 53, 57–59, 61–63, 67, 69, 74, 76, 78, 79, 82, 83, 85, 88, 90–
92, 94, 96, 98, 99, 102, 106, 108, 111, 113, 116]. This means that
even though applications have been hardened against run-time at-
tacks, the response can still be leveraged by attackers to create
temporary denial-of-service conditions while the application (or sys-
tem) is restarted, or to bypass security controls by resetting volatile
system state, e.g., counts of failed login attempts.

Service-oriented applications are at particular risk as even a tem-
porary failure in a critical component can affect a large number of
clients. An example for such an application is Memcached, a general-
purpose distributed memory-caching system, which is commonly
used to speed up database-driven applications by caching database
content.

1

This Paper. To address the limitation of current defenses and
improve the resilience of software that is being targeted by run-
time attacks we propose secure rollback of isolated domains. Secure
rollback allows the state of a victim application under attack to
be restored to a prior state, known to be unaffected by an ongoing
run-time attacks. This is possible by leveraging hardware-assisted
software fault isolation (SFI) to compartmentalize the application
into distinct domains that limit the effects of run-time attacks to
isolated memory compartments. An application can be instrumented
to isolate, e.g., "high-risk" code that operates with untrusted input
in a secure in-process sandbox and rollback the application state
if an attack is detected against sandboxed code. Domains can be
nested to allow for efficient and secure rollback in different software
architectures and use cases.

We show the practicability of our methodology by realizing a soft-
ware library for secure domain rollback (SDRoB) for commodity 64-
bit x86 processors with protection keys for userspace (PKU) [3, 48]
and demonstrate how SDRoB can be applied to real world software
in a case study on Memcached, a popular distributed memory-cache
system. In summary, the contributions of this paper are:

∙ We introduce secure rollback of isolated domains, a novel scheme
to improve software resilience against run-time attacks by rolling
back the state of a victim application.

∙ We explore different design patterns for compartmentalization
and rollback and discuss their applicability for retrofitting secure
rollback to existing software.

∙ We provide SDRoB, a realization of secure rollback for commod-

ity 64-bit x86 processor with PKU.

∙ We apply SDRoB to Memcached as a case study and show that
SDRoB can be used with minor changes to application code
and with a reasonable performance overhead (3.0% – 7.3%) and
negligible memory overhead (0.4%).

Roadmap. Section 2 summarizes the memory vulnerabilities and
the relevant countermeasures, checkpointing and restoring, and PKU.
Section 3 gives an overview of the SDRoB design. Section 4 presents
a detailed overview of the software implementation. Section 5 pro-
vides information on the evaluation of SDRoB’s performance, Sec-
tion 7 on its security, and Section 7 on its applicability. Section 8
discusses the related work, and Section 9 concludes.

2 BACKGROUND
2.1 Vulnerabilities and Countermeasures
Prominent vulnerabilities caused by memory-safety issues include
buffer overflows, use-after-free, and format string vulnerabilities [96].

 
 
 
 
 
 
Today, countermeasures such as W⊕X [88], ASLR [59], stack ca-
naries [24] and CFI [2] aimed at mitigating memory vulnerabilities
are widely deployed by all major operating systems.

However, the current state-of-practice in runtime defenses focuses
on detecting attacks and terminating the offending processes. This
is effective in preventing adversaries from leveraging memory vul-
nerabilities as a stepping stone for privilege escalation, remote code
execution, or exfiltration of sensitive information, but disregards
availability concerns in favor of disrupting the attack’s kill chain.
This approach may be acceptable to protect end users from security
threats, e.g., restarting a browser is a minor inconvenience for the
user. However, in high-availability applications any measure which
may cause service disruption necessitates overall system resilience
to be provided through redundancy and load balancing.

It may also be desirable to collect diagnostics data from the ap-
plication when an attack is detected to aid in root-cause analysis.
Instant termination of an application hinders the collection of diag-
nostics data, except perhaps for a core dump, but collecting data from
a process which is under the attacker’s control poses yet another
challenge.

2.2 Checkpoint & Restore
Application checkpoint & restore [43] is a technique for increasing
system resilience against failure. It involves saving the state of a
running process periodically or before a critical operation, so that a
failed process can later be restarted from the checkpoint. The cost
of this depends on the amount of data that is needed to capture the
system’s state and the checkpointing interval.

Several studies have focused on optimizing checkpointing [64,
114, 117]. Checkpoints can be created at system level or application
level. At system level, checkpointing needs to capture a complete
reproduction of the application’s memory as well as other attributes,
such as sockets, open files, and pipes. At application level, check-
pointing requires additional functionality inserted into the applica-
tion itself to facilitate checkpoint & restore.

Secure checkpointing schemes [75] generally leverage cryptogra-
phy to protect the integrity and confidentiality of checkpoint data at
rest. However they generally do not consider attacks that may tamper
with checkpointing code at the application level. Furthermore, the
cost of bulk encryption of checkpoint data is too high for latency-
sensitive applications, e.g., network traffic processing or distributed
caches unless the system provides load balancing and redundancy.
In this work, we avoid the pitfalls of checkpoints that reproduce
process memory by leveraging hardware-assisted fault isolation to
partition an application process intro distinct, isolated domains. This
compartmentalization facilitates secure rollback of application state
by isolating the effects of memory errors. This enables rollback to
application states that precede the point of failure in the application’s
call graph and are unaffected by a caught and contained error.

2.3 Memory Protection Keys
Memory protection keys (MPK) provide an access control mecha-
nism that augments page-based memory permissions. MPK allows
memory access permissions to be controlled without the overhead of
kernel-level modification of page table entries (PTEs). On 64-bit x86
processors, protection keys for userspace code (PKU) are supported

Figure 1: Overview of 64-bit x86 PKU components.

since Intel’s Skylake [48] and AMD’s Zen 3 [3] microarchitectures.
Future Intel processors will add support for memory protection keys
for supervisor mode (PKS) [48]. Similar hardware mechanisms are
also available in ARMv8-A [4], IBM Power [46], HP PA-RISC [44]
and Itanium [47] processor architectures.

Figure 1 illustrates the component of PKU on 64-bit x86 proces-
sors. Each memory page is associated with a 4-bit protection key
stored in the page’s PTE ❶. The access rights to memory associated
with each protection key are kept in a protection key rights regis-
ter (PKRU) ❷. The PKRU allows write-disable (WD) and access-
disable (AD) policies to be configured for protection keys. These
policies are enforced by hardware on each memory access.

Unlike MPK mechanisms for architectures such as ARMv8-A
and IBM Power, which limit access to the PKRU to privileged code,
the PKRU in 64-bit x86 is configurable from userspace. This allows
domain transitions to occur efficiently without involving the OS ker-
nel. However, it also means that PKU on its own cannot effectively
enforce secure in-process isolation, but has to be combined with
mechanisms such as W⊕X and CFI that can limit PKRU access to
code which is trusted to manage isolation. Existing work has shown
that compiler-based code rewriting [56] or binary inspection [100]
when combined with system call filtering [104], or non-invasive hard-
ware extensions [87], provide sufficient security for PKRU access to
preclude bypassing PKU policies.

3 SECURE DOMAIN ROLLBACK
We propose secure rollback of isolated domains, a novel approach
for improving the resilience of userspace software against run-time
attacks that augments existing, widely deployed run-time defenses.
First, we present our threat model and system requirements (Sec-
tion 3.1). Then we introduce a motivating example (Section 3.2) and
use it to explain the high-level idea behind the solution (Section 3.3).
Sections 3.4 to 3.6 delve deeper into specific aspects of the design.

3.1 Threat Model and Requirements

Assumptions. In this work, we assume that the attacker has arbi-
trary access to process memory, but is restricted by the following
assumptions about the system:

A1 A W⊕X policy restricts the adversary from modifying code

pages and performing code-injection.

A2 The application is hardened against run-time attacks and can
detect when the attack is in progress, but not necessarily prevent
the attacker from corrupting process memory. For the purposes
of the security analysis in Section 6 we assume that general
Linux protections outlined in Section 2.1 are in place.

2

1 int get_number () {
2

3

char buf [ BUFSIZE ]; // BUFSIZE = 8
gets ( buf ); ➀
return atoi ( buf );

4
5 }
6
7 void main ( void ) {
int sum = 0;
8
for (;;) {

9

// read input to buf
// returns number as integer
// if conversion is possible ,
// otherwise zero

// sum of all inputs

sum += get_number ();
printf (" The sum so far : %d\n", sum );

10

11

}

12
13 }

Listing 1: A vulnerable C application.

./a.out
AAAAAAAAA
*** stack smashing detected ***: terminated
Aborted (core dumped)

Listing 2: A stack overflow is detected at run-time.

// to hold return value

1 int ret ;
2 for (;;) {
3

// The return value of get_number is written
// to ret on normal domain exit
if( enter_domain (& get_number , & ret ) == OK) { ❶

sum += ret ;
printf (" The sum so far : %d\n", sum );

// normal domain exit

} else {

// abnormal domain exit ❸

❷

printf (" ERROR ! Bad Input ");

4

5

6

7

8

9

We limit the scope of A2 to software-level attacks. Transient
execution [112] and hardware-level attacks, e.g., fault injection [93],
rowhammer [73] etc., which are generally mitigated at hardware,
firmware, or kernel level, are therefore out of scope.

Requirements. Our goal is to improve the resilience of a protected
application against active run-time attack that may compromise the
integrity of the application’s memory by introducing a mechanism
for secure rollback. We define the following requirements:

R1 The mechanism must allow the application to continue operation

after system defenses (A2) detect an attack.

R2 The mechanism must ensure that the integrity of memory after

recovering from the detected attack is maintained.

To facilitate R1 and R2 the application is compartmentalized into

isolated domains with the following requirements:

R3 Run-time attacks that affect one domain must not affect the

integrity of memory in other domains

R4 The attacker must not be able to tamper with components re-
sponsible for maintaining isolation between domains, transitions
between domains, or data used as part of the rollback process.

3.2 A Vulnerable C Program
Latent memory vulnerabilities may exist undiscovered within ap-
plications until they are set off by input that triggers the software
defect. When a defect is triggered, it is highly likely that it causes the
application’s memory to become corrupt in unexpected ways. As a
motivating example, consider the program in Listing 1 that contains
a "classic" buffer overflow vulnerability. The memory vulnerabil-
ity ➀ is triggered by input that exceeds the size of the input buffer
buf. As the input overflows the buffer it will corrupt the surrounding
stack frame, and eventually overflow into the main function’s stack
frame where it will corrupt the local variable sum.

Modern C compilers guard against this particular vulnerability
in two ways: 1) by deprecating the gets() function in favor of
fgets() with explicit array bounds checks, 2) by emitting stack ca-
naries at stack frame boundaries which indicate if a buffer overflow
corrupts a function’s stack frame. Listing 2 shows how the hardened
application is terminated at run-time when the overflow is detected.
However, by the time the overflow is detected the application’s mem-
ory has already been corrupted, rendering the application process
unrecoverable.

}

10
11 }

Listing 3: The loop from Listing 1 equipped for rollback.

3.3 High-level Idea
The objective of the secure rollback mechanism is to recover the
application’s execution state after a memory defect has triggered to
a prior state before the application’s memory has been corrupted
(R2). Thus, the application can resume its execution and continue
to provide its services without interruption (R1). To facilitate this,
the application is compartmentalized into separate, isolated domains
that each execute in distinct memory compartments allocated from
the process’s memory space. Should the execution of code inside
a domain fail due to a memory defect, the memory that belongs
to the domain may be corrupt. However, since the effects of the
memory defect are isolated to the memory belonging to the failing
domain (R3, R4) the application’s execution can now be recovered
by: 1) discarding any affected memory compartments, 2) unwinding
the application’s stack to a state prior before the offending domain
began its execution, and 3) performing an application-specific error
handling procedure that avoids triggering the same defect again, e.g.,
by discarding the potentially malicious input that caused it.

Listing 3 shows how the program from Listing 1 is modified to
benefit from secure rollback. The call to get_number() has been
wrapped by a call to the enter_domain() function ❶. This wrapper
function is part of secure rollback instrumentation, here shown with
simplified arguments. It performs the following actions:
∙ Save information about the calling environment such as register
values, including the stack and instruction pointers, and signal
mask (in a manner similar to C setjmp() [80]) for later use by
the rollback mechanism

∙ Reserve a portion of the application’s memory for a new domain.
This memory area contains the domain’s stack and heap and per-
sists for the duration the domain remains active (see Section 3.4).
∙ Update the memory access policy enforced by hardware, granting
access to memory areas assigned to new domain, and preventing
access to all other memory areas. Global data is set to read-only.

∙ Finally, invoke the function inside the domain.

The newly spawned domain can end its execution in one of two
ways: 1) normal domain exit, and 2) abnormal domain exit A nor-
mal domain exit ❷ occurs when the application’s execution flow
returns naturally from the code invoked inside the domain to the call
site. This means that the isolated code has completed successful and
application execution is resumed outside the domain. An abnormal

3

domain exit occurs ❸ if the isolated code tries to access memory past
the confines of the domain’s memory area, or a possible run-time
attack is detected. In an abnormal domain exit, the execution of the
domain is halted, the domain’s memory is discarded, and the appli-
cation execution is resumed by restoring the calling environment
from the information stored prior to invoking the offending domain,
effectively rolling back application state to the point before the do-
main started executing. In Listing 3, the effects of a buffer overflow
inside get_number() are limited to the newly created domain; the
main function’s stack is unaffected by the overflow, and the rollback
mechanism can thus transfer control back to main().

The caller learns a domain’s exit status from enter_domain()’s
return value. On abnormal domain exit the application is expected
to take some alternate action to avoid the conditions that lead to the
previous abnormal domain exit before retrying the operation. For
example, a service-oriented application can close the connection to
a potentially malicious client. The rollback of application state is
limited to the state of the application’s memory. Operations that have
side-effects on the application’s environment, e.g., reading from a
socket, are still visible to the application after rollback.

In the following we explain design patterns for secure rollback
that apply to different software architectures. We discuss considera-
tions regarding the applicability of our approach in Section 7.

3.4 Domain Life Cycle
As part of process initialization, all application memory, including
stack, heap, and global data, are assigned to the root domain which
forms the initial isolated domain where an application executes. Ap-
plication subroutines are compartmentalized into nested domains
to create multiple recovery points from which rollbacks can be per-
formed at any point during the application’s execution. As the names
suggests, domains can be nested in the sense that several domains
can be entered subsequently starting from the root domain, each
with a dedicated rollback procedure (cf. Section 3.5). We envision
two flavors of isolation with rollback for application subroutines:
∙ Protecting the application from a subroutine: Code that may
have undetected memory vulnerabilities, e.g., third-party software
libraries, can be executed in a nested domain by instrumenting
calls to the functionality so that they execute in their own domain
and may be rolled back in case memory safety violations are
detected, as shown in the previous section.

∙ Protecting a subroutine from its caller: parts of the application
that operate on persistent sensitive application data such as cryp-
tographic keys can be isolated from vulnerabilities in its callers,
preventing the leak and loss of such data. For example, functions
for encryption, decryption, or key derivation from the OpenSSL
library can be isolated in their own nested domain to protect the
application’s cryptographic keys if a fault occurs in a calling
nested domain. Listing 6 in Section 4.1 shows a concrete example
of isolating OpenSSL.

When the application’s execution flow enters any isolated sub-
routine, a nested domain is created and assigned a substack and
subheap area. To support the two application scenarios described
above, we identify two design patterns for nested domains. The type
of a domain determines how it continues its life cycle, in particular
what happens upon domain exit.

4

Persistent Domains. A persistent domain retains all assigned
memory areas even after the application’s execution flow returns
from the persistent nested domain to the parent domain. Another
code path may enter the persistent domain again, at which point
access is granted to memory areas that belong to the persistent do-
main. Modules that maintain state information across invocations
should be isolated in a persistent domain so that their state is not lost
after a normal domain exit. For instance, some software libraries
may encapsulate such state by creating a "context" object that de-
couples domain-specific data from business logic. One strategy for
compartmentalizing such libraries is to ensure each distinct context
is allocated in different persistent domains. A good example of this
pattern is OpenSSL which can be instantiated multiple times within
an application using different contexts. Assigning one persistent
domain per context therefore ensures cryptographic keys associated
in memory with one context remain isolated from other domains.

On abnormal exits from any domain, the rollback mechanism is
triggered and all state of the domain is discarded. Note that for persis-
tent domains this may have serious repercussions for an application,
if the program state depends on the persistent state of the isolated
library. When, for example, the abnormal exit leads to the loss of
session keys for a TLS connection, the application may need to
recover by re-initializing the affected context and close connections
that were handled in the lost context.

Depending on the application, the parent domain may or may
not be given access to a persistent nested domain’s memory. For
instance, in the case of cryptographic libraries, access to the persis-
tent domain’s memory from any other domain should be blocked
to protect sensitive data stored by the library. In such cases data
cannot be directly passed between the caller and callee in distinct
domains and shared data, e.g., call arguments and results need to
be copied between the nested domain and its caller via a designated
shared memory area. This is similar to how data is passed between
different protection domains in hardware-enforced trusted execution
environment, e.g., Intel SGX enclaves [50].

Transient Domains. Memory areas assigned to transient nested
domains persist until the application’s execution flow returns from
such a domain to the parent domain at which point the stack as
well as unused heap memory areas assigned to the transient nested
domain are discarded. For this the rollback mechanism needs to
keep track of memory allocations in a nested domain. Any allocated
memory in a transient nested domain’s heap area can be merged
back to the parent domain’s heap area or discarded upon a normal
domain exit, depending on the specific application scenario.

In the example in Listing 4, execution enters a nested domain ❶
where get_name() ❷ dynamically allocates a buffer in heap mem-
ory ❸ and returns it as a result to main(). In a normal domain exit
❹, the active allocation of the transient domain is merged to the root
domain where main() lives. This means that control of the buffer
allocated in the transient domain and pointed to by ret is transferred.
The developer can free this memory later ❺. Unused heap area of
the nested domain and the stack are discarded automatically by the
secure rollback mechanism. On an abnormal domain exit ❻ substack
area and subheap area assigned to the transient nested domain are
discarded by the rollback mechanism already and no further clean-up
by the developer is necessary.

1 void get_name () { ❷
2

void * buf ;
buf = malloc ( BUFSIZE ); ❸ // BUFSIZE = 8
gets ( buf );
return buf ;

5
6 }
7 void main ( void ) {
8

void * ret ; // holds the return value
for (;;) {

if( enter_domain (& get_name , ret ) == OK){ ❶

printf ("%s", ret ); // normal domain exit ❹
free ( ret ); ❺

} else {

// abnormal domain exit ❻

printf (" ERROR ! Bad Input ");

3

4

9

10

11

12

13

14

}

15
16 }

Listing 4: Domain Merging Area Example

While read-only access from any nested domain to data in the
parent domain is allowed, writable access must never be allowed in
order to contain any memory safety violations to the nested domain.
The overall life cycle of a nested domain in the transient style
is depicted in Figure 2, highlighting the different steps the rollback
mechanism has to perform to isolate execution in a nested domain
from a parent domain. As an example, we consider a call to a func-
tion or library F that takes one in-memory argument and returns a
is wrapped by enter_domain(), which creates a
value. The call
new domain , allocates separate stack and heap memory , saves
, and copies the input argument onto the new
the caller context
heap . The domain transition step
performs mainly two actions:
1) reconfiguring the memory protection mechanism to restrict or
grant memory access policies for the entered domain, 2) switch be-
tween the stacks of the two domains. If a fault is caught in the nested
domain , the abnormal domain exit is triggered (
), discarding
the contents of the faulty domain, and executing the custom error
) stores the result and
handling code
deletes the domain including freeing its memory. In the “Handle Re-
sult” step , control is transferred to the developer-provided handler
code for normal exits. In both exit cases, after the handler code is
executed, regular program execution resumes in the parent domain.

. The normal domain exit (

-

-

3.5 Domain Nesting and Rollback
Domain nesting means creating new isolated domains within an
application. Each nested domain has exactly one parent domain,
which is responsible for creating the nested domain. All domains
may have zero or more nested child domains, i.e., additional nested
domains may be created by already nested domains.

Transient and persistent-style domains can be nested with each
other. One example of a domain nesting configuration is illustrated
in Figure 3. Here, the first level of nesting domain is transient and
its subsequent nested domain can be persistent. Such a setup can
allow the developer to effectively "hide" errors in the more deeply
nested persistent domain by specifying that rollback always occur to
the recovery point established for the outer domain. At the event of
an abnormal domain exit, the rollback can occur from any nesting
level to a lower nesting level according to application requirement,
i.e., the rollback can be configured to occur from “Nesting level 2”
to “Nesting level 1”, or from “Nesting level 2” to “Nesting level 0”
as seen in Figure 3. The rollback mechanisms can achieve rollback
from any nested domain, but not from the root domain.

5

Table 1: SDRoB API. udi: user domain index

API Name
➀ sdrob_init()
➁ sdrob_malloc()
➂ sdrob_free()
➃ sdrob_dprotect()

Arguments
udi, options
udi, size
udi, adr
udi, tddi, PROT

➄ sdrob_enter()
➅ sdrob_exit()
➆ sdrob_destroy()
➇ sdrob_deinit()
➈ sdrob_call()

udi
—
udi, options
udi
udi, fun, arg,
size, ret

Description
Initialize Domain udi
Allocate size memory in domain udi
Free memory at adr in domain udi
Set domain udi’s access permissions
to PROT on target data domain tddi
Enter Domain udi
Exit Domain udi
Destroy Domain udi
Delete return context of Domain udi
Convenience wrapper for single
function calls with one argument

3.6 Multithreading
The secure rollback mechanism supports POSIX threads. In most
cases, threads need to communicate with each other using shared
memory, hence they need to access root domain memory. Conse-
quently, it would not be possible to isolate two threads completely
from each other or from the main process.

Nevertheless, it is still possible to isolate partial code paths within
the thread to separate domains, i.e., each thread can still create
nested domains with stacks and heaps that are isolated from the
root domain and other nested domains. Hence, each thread may
recover via rollback from errors in such nested domains. If one
of the threads suffers an abnormal exit from the root domain, the
rollback mechanism cannot recover other threads and the application
must be terminated.

Threads have shared access to global and root domain heap mem-
ory, to per-thread stack areas and thread-local storage. It is possible
to strengthen the isolation by configuring exclusive memory access
to each thread’s stack. However, the security benefits are arguably
marginal when heap access is still shared. A shared root domain
allows a higher number of parallel threads to be supported, if the
available domains provided by the underlying memory protection
mechanism is limited, as only threads that instantiate nested domains
consume domain slots. However, one could allow the developer to
configure stricter, non-uniform access privileges to other threads.

4 PROTOTYPE IMPLEMENTATION
We implement the concept of secure domain rollback as SDRoB – a
C-language Linux library for the 64-bit x86 architecture using PKU
as the underlying isolation primitive. The library provides an API to
control the life cycle of domains.

4.1 SDRoB API
Developers can use the SDRoB API calls shown in Table 1 to en-
hance their application with a secure rollback mechanism in a flexi-
ble way, accounting for the different design patterns described above.
Domains are initialized by sdrob_init() ➀ where the devel-
oper chooses a unique index by which the domain is referenced in
future API calls. Execution and data domains may be created, where
the latter may hold shareable data but cannot execute code. For ex-
ecution domains we further distinguish isolated and non-isolated
domains, and whether an abnormal exit from the domain should
be handled in the current domain or its parent domain. A domain
can only be initialized once per thread (unless it is deinitialized or
destroyed before by the programmer) and the point of initialization
for execution domains marks the execution context to which control
flow returns in case of an abnormal domain exit.

Figure 2: Domain life cycle for calling an internal or library function F in a nested domain from a parent domain. Dotted arrows
initialize the domain. An argument arg of size size is copied into the nested
represent execution of user space instructions. Steps
domain in step
reverses the initialization
and frees all of the nested domain’s memory. Code for steps

and the result is returned in variable ret in step . Deleting the domain in steps

is provided by the programmer.

and

and

to

1 int err = sdrob_init ( udi_F , EXECUTION_DOMAIN |
2
3 if ( err == OK ){
4

NONISOLATED | RETURN_HERE );

// prepare passing return value and argument
register int r asm (" r12 ");
register void * adr asm (" r13 ");
adr = sdrob_malloc ( udi_F , size );
if (! adr && size >0) { return MALLOC_FAILED ; }
if (size >0) { memcpy (adr , arg , size ); }
sdrob_enter ( udi_F );
// invoke F on copy of argument and save return value
r = F( adr );
sdrob_exit ();
if ( ret ) { * ret = r; }
sdrob_free ( adr );
sdrob_destroy ( udi_F , NO_HEAP_MERGE );

5

6

7

8

9

10

11

12

13

14

15

16
17 }
18 return err ;

Listing 5: Pseudocode showing a possible implementation of
sdrob_call(udi_F,F,arg,size,ret) using other API calls (orange).

To support the transient domain design pattern, child domains
can be deleted using sdrob_destroy() ➆ with the option to either
discard the domain’s heap memory or to merge it to the current
domain. The latter is forbidden for isolated domains. The persistent
domain pattern can then be implemented by simply not destroying
the domain after exiting it, so that it can be entered again.

An important requirement is that a nested execution domain needs
to be destroyed before the function that initialized that domain re-
turns. Otherwise, the stored execution context to which to return
to would become invalid as it would point to a stack frame that
no longer exists. To provide more flexibility, sdrob_deinit() ➇
allows to just discard a child domain’s execution context but leave
its memory intact. Before entering the domain again, it needs to be
re-initialized, setting a new return context for abnormal exits.

Finally, we provide sdrob_call() ➈ which implements the
domain life cycle of enter_domain() shown in Figure 2 for a
function F that receives a pointer to an object in memory as input
and returns an integer-sized value. To illustrate the API, Listing 5
shows how sdrob_call() can be implemented.

In the example, we first initialize a new non-isolated execution
domain for function F. If an abnormal exit occurs in that domain,

entering domain,

Figure 3: Example of deeply nested domains. Arrows indicate:
abnor-
mal domain exit. Normal domain exits ➁, ➀ match the path of
entered domains in reverse order. Abnormal domain exits may
deviate from this path, e.g., the persistent domain at ➂ has the
root domain as rollback target, same as the transient domain ➃.

normal domain exit,

The API call’s return value fulfills two roles. When the domain
is first initialized, it returns OK on success or an error message,
e.g., if the domain was already initialized in the current thread. On
abnormal domain exit, control flow returns another time from the init
function and the return value signifies the index of the nested domain
that failed and was configured to return to this point. This means
that error handling for abnormal domain exits needs to be defined in
a case split on the return value of the sdrob_init() function.

After initialization, memory in an execution or data domain can
be managed using sdrob_malloc() ➁ and sdrob_free() ➂, e.g.,
to be able to pass arguments into the domain. Note that this is
only allowed for child domains of the current domain that are non-
isolated. For isolated domains, a shared data domain needs to be used
to exchange data. Using sdrob_dprotect() ➃ access permissions
to a data domain can be configured for child domains.

An execution domain initialized in the current domain can be
entered and exited using sdrob_enter() ➄ and sdrob_exit() ➅.
This switches the stack and heap to the selected domain and back,
and changes the memory access permissions accordingly. Currently,
the SDRoB prototype does not copy local variables on such domain
transitions. Such variables need to be passed via registers or heap.

6

RootDomainTransientDomainPersistentDomainNestingLevel:012①②③④control returns here, so we save the error code in err. If initialization
succeeded, we allocate a local variable r in a register to retrieve the
return value later. We also allocate memory for the input argument
at adr in the new domain. Since that domain is non-isolated, we can
copy the argument directly from the parent domain. Afterwards, we
enter the nested domain and invoke F on the copy of the argument,
saving the return value. After exiting, we are back in the parent
domain and can copy the return value to the desired location (which
is inaccessible to the nested domain). We free all temporary memory
and destroy the nested domain, freeing its remaining memory.1
Finally, we return OK in case of normal domain exit, or the error
code otherwise. Users of sdrob_call() can then define their own
error handling depending on this return value as shown earlier.

Listing 6 shows a EVP_EncryptUpdate() wrapper for OpenSSL
that implements the persistent domain pattern introduced in Sec-
tion 3.4. Here, OpenSSL allocates it’s data, such as its context (ctx)
❶ from a domain which is strongly isolated from its parent. While
the caller can hold a pointer to ctx, the object itself is unaccessible
to the parent domain. Functions that enter the domain through such
wrappers must receive their input and write their output via an inter-
mediate shared data domain. ❷ and ❸ show how data is allocated
and copied in, and ❹ how it is copied out from the intermediate data
domain. This persistent domain can be combined with a transient
domain as shown in Figure 3 to 1) encapsulate the pointer to ctx
within an outer domain, and 2) to protect the root domain from errors
in the caller, such as an out buffer of insufficient size. Listing 7 in
Appendix B shows another example usage of the wrapper.

Implementation Overview

4.2
In a nutshell, SDRoB is implemented using four components: 1) a
hardware mechanism for enforcing in-process memory protection,
2) an isolated monitor data domain that houses control data for
managing execution and data domains, 3) initialization code that is
run at the beginning of each application that is linked to the SDRoB
library, setting up the monitor domain and memory protection, as
well as 4) trusted reference monitor code that realizes the SDRoB
API calls, having exclusive access to the monitor data domain. Below
we provide more details about these components.

Memory Protection. SDRoB uses PKU protection keys (cf. Sec-
tion 2.3) as a hardware-assisted SFI mechanism to create different
isolated domains within an application governed by different mem-
ory access policies. When a domain is created, a unique protection
key is assigned for it. At each domain transition, PKRU is updated
to grant access to memory areas as permitted for the newly entered
domain, and to prevent access to other memory areas.

Our evaluation platform supports Intel PKU, hence it allows us to
manage up to 15 isolated domains at a time for each process. Soft-
ware abstractions for MPK, like libmpk [82], increase the number
of available domains.

SDRoB Control Data. SDRoB stores global control data in the
monitor data domain for keeping track of, e.g., the registered domain
identifiers and the protection key usage. It also stores per-thread
information for domains such as stack size, heap size, parent domain,

1Technically, the sdrob_free() call is redundant here because sdrob_destroy()
would free this memory as well with the NO_HEAP_MERGE option.

7

and memory access permissions. To support abnormal domain exits,
the currently executing domain and the saved execution contexts are
stored here as well.

Initialization. An application is compiled with the SDRoB library
to use the rollback mechanism. The library provides a constructor
function that is executed before main() to assign all application
memory to the initial isolated domain as a root domain associated
with one of the PKU protection keys. It then initializes SDRoB global
control data where the default stack and heap size for domains is
configurable through environment variables. Furthermore, it sets the
root domain as active domain, to be updated at domain transitions
by the reference monitor, and finally initializes a signal handler.

For the multithreading scenario, SDRoB has a thread constructor
function as well, that is executed before the thread start routine
function to assign a thread memory area to a domain and associate it
with one of the protection keys.

Reference Monitor. The reference monitor is responsible for book-
keeping of domain information in SDRoB control data. It performs
domain initialization, domain memory management, and secure
domain transitions, including updating the memory access policy,
and saving and restoring the execution state of the calling domain.
Only the reference monitor has access to the monitor data domain
by updating the PKRU register accordingly. The monitor code is
executed using the stack of the nested domain that invoked it.

Rollback. The secure rollback from a domain is achieved by
the reference monitor saving the execution context of the parent
domain into SDRoB control data when that domain is initialized.
SDRoB uses a setjmp()-like functionality to store the stack pointer,
the instruction pointer, the values of other registers, and the signal
mask for the context to which the call to sdrob_init() returns.
Note that we cannot simply call setjmp() within sdrob_init()
because that execution context would become invalid as soon as the
initialization routine returns. On an abnormal domain exit, the saved
parent execution state can be used by the recovery process to restore
the application’s state to the initialization point prior to entering
the nested domain by using longjmp(). This rollback allows the
application to continue from that last secure point of execution that
is now redirected to the developer-specified error handling code. To
simplify programming under these non-local goto semantics [80],
we only allow to set the return point once per domain and thread.
Moreover, the convention that a domain needs to be destroyed or
deinitialized before the function that initialized it returns, ensures
that the saved execution context is always valid.

4.3 Memory Management and Isolation
The secure rollback mechanism is achieved by creating different
domains within an application and its security objective is that a
memory defect within a domain must only affect that domain’s mem-
ory, not the memory of others. Using the underlying SFI mechanism
based on PKU, each domain is isolated from other domains.

Global Variables. We modify the linker script to ensure that
global variables are allocated in a page-aligned memory region
that can be protected by PKU. At application initialization, all global
variables are assigned to the root domain; consequently they are

1 int __wrap_EVP_EncryptUpdate ( EVP_CIPHER_CTX * ctx ❶ , unsigned char *out , int *outl , const unsigned char *in , int inl ) {

register evp_encrypt_update_args_t * args asm (" r12 ");2
. . .
args = sdrob_malloc ( OPENSSL_DATA_UDI , sizeof ( evp_encrypt_update_args_t )); ❷
args -> ctx = ctx ; ❸
args -> inl = inl ; ❸

// copy ctx from current domain to shared data domain
// copy inl from current domain to shared data domain

// holds copied function arguments and return value

if ( out != NULL && inl >= 0) {

// inl + cipher_block_size is upper bound for yet unknown output size

args . out = sdrob_malloc ( OPENSSL_DATA_UDI , inl + cipher_block_size3); ❷

} else { args . out = NULL ; }

if (in != NULL && inl >= 0) {

args ->in = sdrob_malloc ( OPENSSL_DATA_UDI , ( size_t ) inl ); ❷
memcpy (args ->in , in , inl ); ❸

// copy in from current domain to shared data domain

} else { args .in = NULL ; }

sdrob_enter ( OPENSSL_UDI );
args -> ret = __real_EVP_EncryptUpdate (args ->ctx , args ->out , &( args -> outl ), args ->in , args -> inl );
sdrob_exit ();

// execute real EVP_EncryptUpdate in isolated domain

* outl = args -> outl ; ❹
if ( out != NULL ) {

// copy out outl value from shared data domain
// copy out encrypted data from shared data domain

memcpy (out , args ->out , ( size_t )* outl ); ❹

}
sdrob_free ( OPENSSL_DATA_UDI , args -> out );
sdrob_free ( OPENSSL_DATA_UDI , args ->in);
sdrob_free ( OPENSSL_DATA_UDI , args );
. . .

// data domain persists past the lifetime of wrapper function so
// allocated memory must be freed to avoid memory leak

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28
29 }

Listing 6: excerpt from wrapper function for EVP_EncryptUpdate() that executes OpenSSL in a persistent nested domain. Data is passed between
the parent and nested domain via a distinct shared data domain (OPENSSL_DATA_UDI). Error handling is omitted in excerpt for brevity.

not accessible to nested domains. As a pragmatic solution to the
problem, we make the root domain by default read-only for all
nested domains. Write access to global data may then be achieved
by allocating it on the heap of a shared data domain, referenced by
a global pointer. Note that this approach breaks the confidentiality
of the root domain towards nested domains. As our main goal is
integrity, and confidential data can still be stored and processed in
separate domains, we find it a reasonable trade-off for our prototype.

Stack Management. SDRoB creates a disjoint stack for each exe-
cution domain to ensure that the code running in a nested domain
cannot affect the stacks of other domains. The stack area is allocated
when first initializing a domain and protected using the protection
key assigned to that domain. As an optimization, we never unmap
the stack area, even when the domain is destroyed, but keep it for
reuse, i.e., when a new domain is initialized. At each domain entry,
we change the stack pointer to the nested domain stack pointer and
push the return address of the sdrob_enter() call, so that the API
call returns to the call site using the new stack. Then we update the
PKRU register according to memory access policy for that domain.
A similar maneuver is performed when switching back to the parent
domain’s stack via the sdrob_exit() API call.

Heap Management. In order to manage a domain’s heap allo-
cations as described in Section 3.4 the underlying allocator must
have the ability to differentiate between allocations that occur in
different domains and ensure that the underlying memory is chosen
from an address range in a particular domain’s reserved heap area.

2The args pointer is kept in a callee-saved register (r12) to ensure it remains accessible
to the nested domain after sdrob_enter() (line 17) changes the domain stack
3The args.out buffer requires room to store inl + cipher_block_size bytes of
data. The cipher_block_size is known from ctx. [5]

8

Traditionally the heap is set up to be one large continuous memory
area. Modern malloc() implementations, including the GNU Al-
locator in glibc [66] have the ability to maintain multiple disjoint
heap areas, typically for the purpose of optimizing memory access
patterns in multi-threaded applications. For example, the GNU Allo-
cator internally maintains one or more memory areas, referred to as
arenas, that are reserved via mmap() to provide the backing memory
for the application’s initial heap and subsequently allocated thread
heaps. Concurrent allocations require threads to obtain a lock on
the arena structure that malloc() operates on. Consequently, by
assigning different arenas to different threads the GNU Allocator en-
ables memory allocations in different threads to occur concurrently
without interfering with each other. Unfortunately the GNU Alloca-
tor’s design does not guarantee thread-isolation between arenas: if
a thread fails to allocate memory from the arena attached to it, the
malloc() implementation continues the search for a suitable large
block of memory to satisfy the allocation from the application’s
other arenas [40].

Because heap isolation in SDRoB requires memory management
with strict guarantees that allocations within a domain are satisfied
only from memory reserved for that domain, we opted to use an
allocator that natively supports fully disjoint heap areas instead of
the default glibc GNU Allocator. For our proof-of-concept imple-
mentation, we chose the Two-Level Segregated Fit (TLSF) [70]
allocator [20]. TLSF is a "good-fit", constant-time allocator that
allocates memory blocks from one or more pools of memory. Each
free block in a pool is linked in two different doubly linked lists:
1) a free list of blocks belonging to the same size class, and 2) a list
ordered by physical address. The TLSF control structure contains a
free list bitmap that describes the availability of free memory blocks
in different size ranges. TLSF uses processor bit instructions and the

bitmap to locate a corresponding linked list of suitable-sized free
blocks.

Each SDRoB domain is an assigned its own TLSF control struc-
ture and memory pool that correspond to the domain’s subheap. The
size of the initial pool assigned to domains is configurable via an
environmental variable. Each individual TLSF pool is limited to
4GB in size [70]. Beyond that, a domain’s memory is increased by
reserving additional pools for the domain’s TLSF allocator.

Lazy Heap Initialization. In order to reduce the memory footprint
when domains don’t make heap allocations, the control structure and
initial memory pool are not initialized when the domain is created.
Instead, the reference monitor initializes the domain’s TLSF instance
the first time the domain allocates heap memory with the malloc()
family of functions. We interpose such functions with wrappers by
placing the SDRoB library before libc in the library load order. Upon
initialization the associated memory pool is protected by associating
it with the domain’s protection key.

Subheap Merging. Recall from Section 4.1 that a domain’s sub-
heap is either discarded or merged with the parent domain’s sub-
heap when sdrob_destroy() is called, depending on the option
parameter provided. To enable subheap merging we extended the
TLSF implementation to associate a partially consumed pool to a
pre-existing TLSF control structure. When a subheap is merged, its
associated protection key is updated to match the parent domain’s
protection key. The parent’s TLSF control structure is then updated
as follows: 1) detect used and unused blocks in the memory pool
being merged, 2) link all these blocks to the pre-existing block lists
in the parent domain, 3) update the parent domain’s TLSF free list
bitmap for unused blocks, and 4) delete the child domain’s TLSF
control structure. If the heap is not be merged when the domain
is destroyed any allocations are freed and the underlying memory
pools can be reused by new domains.

Error Detection. Memory access violations are generally reported
to userspace software either via 1) a SEGFAULT signal, e.g. when a
domain tries to access memory past the confines of the domain’s
memory area, and 2) calls to runtime functions inserted by instru-
mentation, e.g., GCC’s stack protector calls __stack_chk_fail()
if a stack guard check fails. The __stack_chk_fail() function is
typically provided by glibc and terminates the application if called.
During process initialization SDRoB sets up its own signal handler
for the SEGFAULT signal that attributes the segmentation fault to its
cause using the signal code (si_code) available via a siginfo_t
structure [81] provided by the runtime to the signal handler. For in-
stance, violations of PKU access rules are reported by SEGV_PKUERR
signal code. In Linux the SEGFAULT signal is always delivered to
the thread that generated it. If the SDRoB signal handler detects
that a violation occurs in a nested domain it can trigger an abnormal
domain exit. If a segmentation fault occurs in a root domain, or the
fault is attributed to a cause the SDRoB signal handler is not pre-
pared to handle the process is still terminated. SDRoB also provides
its own implementation of __stack_chk_fail() that replaces the
default glibc implementation to respond to stack guard violations.

SDRoB can be extended to incorporate other pre-existing run-time
error detection mechanisms, such as Clang CFI [1] or heap-based

9

overflow protections (e.g., heap red zones [90]), improving the re-
covery capabilities. Probabilistic and passive protections such as
ASLR hinder the exploitation of memory safety violations, but can-
not detect them. Nevertheless, our rollback mechanism is compatible
with ASLR, as domains are created at run-time.

5 CASE STUDY: MEMCACHED
Memcached [72] is a general-purpose distributed memory caching
system, which is commonly used to speed up database-driven ap-
plications by caching database content. To do so efficiently, Mem-
cached stores its state in non-persistent memory; after termination
and restart, clients must start over and resend a large amount of
requests to return to the situation prior to the restart. Even in real-
world deployments with built-in redundancy and automatic remedi-
ation even small outages can take up to a few minutes to re-route
requests to an unaffected cluster [77]. To address this issue, sev-
eral studies propose to use low latency persistent storage for Mem-
cached [68, 118], but their solutions come with a non-negligible
performance overhead. As availability and resilience of Memcached
to unforeseen failures is of high importance, it is a worthwhile target
for hardening with secure domain rollback.

In order to understand how to apply SDRoB to Memcached, we
first give a short overview of its design. The main thread in Mem-
cached accepts connections and dispatches them among worker
threads to handle related requests. Memcached uses a hash table to
map keys to an index and slab allocation to manage the database’s
memory. Memcached has an event-driven architecture, so it handles
each client request as an event. The clients can send get, set, and
update commands with key and value arguments. To handle a re-
quest, command parser subroutines in Memcached classify the client
request, then the key-value pairs are fetched from, inserted in, or
updated in the database, according to the client’s command.

If a client event contains a malicious request leading to memory
corruption, the database and hash table, as well as the complete
application memory area lose their integrity, and Memcached should
be restarted. As a result, one malicious request affects all other
clients’ requests and the availability of the database service.

5.1 Memcached with SDRoB
We propose that each client event should be handled in a nested
domain. In case of memory corruption, the abnormal domain exit
occurs in the nested domain, we discard the related nested domain
contents and come back to the root domain securely. Memcached
closes the related connection, and it can continue its execution,
handling another client request without restarting.

Figure 4 shows a sequence diagram of Memcached with SDRoB.
We configure SDRoB with a partially isolated multithreading config-
uration (see in Section 3.6), because the main thread needs to com-
municate with the worker threads. Each event is handled using the
drive_machine() function with a corresponding connection buffer.
We isolate this function using the SDRoB API, along the lines of List-
ing 5. Recall from Section 3.4 that nested domains by default only
have read access to data that belongs to the parent domain. Neverthe-
less, certain subroutines, such as drive_machine(), need to update
shared state residing in a parent domain, e.g., the connection buffer.

the database. However, due to the atomic nature of the Memcached
requests, consistency is not affected.

Memcached uses a shared mutex for synchronization of worker
threads. In this case our copying mechanism for shared data does
not work, because it would hide concurrent accesses to the mutex
and break the synchronization. We opted to create a separate data
domain for the mutex that every worker can access. See Section 7
for a security discussion of this scheme.

5.2 Performance Evaluation
Two aspects of the secure rollback scheme’s performance are evalu-
ated: 1) rollback latency on an abnormal exit, 2) performance impact
of the isolation mechanism. We run our experiments on Dell Pow-
erEdge R540 machines with 24-core MPK-enabled Intel(R) Xeon(R)
Silver 4116 CPU (2.10GHz) having 128 GB RAM and using Ubuntu
18.04, Linux Kernel 4.15.0.

Rollback Latency. We reproduced CVE-2011-4971 [26] to verify
the SDRoB rollback mechanism and compiled Memcached v1.4.5
with SDRoB. This CVE causes denial of service by crashing Mem-
cached via a large body length value in a packet. Simply put, it
creates a heap overflow but SDRoB ensures that this overflow is
limited to current execution domain, hence it triggers the domain
violation and an abnormal domain exit occurs. We measured the
latency of abnormal domain exit starting with catching SEGFAULT
until after we close the corresponding connection. The mean latency
is 3.5µs (σ=0.9µs).

For comparison, in our experiments the restart and loading time
for 10GiB of data into Memcached was about 2 minutes. Thus, an
attacker that successfully launches repeated attacks could completely
hobble the Memcached service without secure rollback. While this
is clearly dominated by the loading time, even applications without
such volatile state, but ultra-reliable low-latency requirements, can
profit from rollback. For reference, we measured the mean latency
to restart the Memcached container automatically at about 0.4s
(400000µs, σ=19000µs).

Performance Impact. We used the Yahoo! Cloud Service Bench-
mark (YCSB) [21] to test the impact of SDRoB on Memcached
performance. YCSB has two phases: a loading phase that popu-
lates the database with key-value pairs, and a running phase which
perform read and update operations on this data. We used work-
loads with sizes of 1KiB, with a read/write distributions of 95/5. For
our measurements, we stored 1 × 107 key-value pairs (1KiB each)
and performed 1 × 108 operations on those pairs. Operations were
performed with a Zipfian distribution over the keys.

We compiled Memcached v1.6.13 with -O2 optimizations, -pie
(for ASLR), -fstack-protector-strong, and -fcf-protection
and evaluated the performance of Memcached with the TLSF allo-
cator and Memcached with equipped with SDRoB as described in
Section 5.1. We compare the results against YCSB on unmodified
Memcached. Figure 5 shows the load and running phase throughput
(operations/second) of the three versions for 1, 2, 4, and 8 work-
ers threads over 10 benchmark runs each. Each thread was pinned
to separate CPU cores. We used 32 YCSB clients with 16 threads
pinned to separate cores for each test. We fully saturated Memcached

Figure 4: Sequence diagram of Memcached with SDRoB

As a solution, the event handler that calls drive_machine() initial-
izes a non-isolated, nested domain D (3) and makes a deep copy of
the connection buffer that is made available to drive_machine()
(4). It then enters D (5) and calls drive_machine() (6) to handle
the client request, working on a copy of the connection buffer. After
successfully handling the request, it exits from D (7), the original
connection buffer in the parent domain is updated with any changes
present in the shared copy (8). On abnormal domain exit, the copied
connection buffer is discarded. Since the event handler returns after
handling the request, we need to invalidate the saved execution con-
text of D. As drive_machine() does not allocate any persistent
state in D, we could use the transient domain pattern and destroy D.
However, as an optimization, we retain the copy of the connection
buffer used by the domain, hence sdrob_deinit() (10) is used.

The drive_machine() function also needs both read and write
access to the hash table and database to perform look-ups, insertions,
and updates. To protect database and hash table integrity, we store
them in separate data domains and grant read-only access to the
workers. Since domain heaps grow dynamically, we do not need
preallocation as other PKU-based Memcached adaptations [55, 82].
In order to allow inserts and updates, we wrap the slabs_alloc()
function, that normally returns a pointer to a memory area in the
database, to return a copy of the memory area to insert the key-value
pair. Similarly, we wrap the store_item() function which stores
new data and updates the hash table. Each event handler first per-
forms its operation on a copy of the corresponding item. On a normal
exit from the nested domain, we insert the key-value pair to the data-
base, and update the hash table (9). On an abnormal domain exit
(11-12), the corrupt key-value pair is discarded along with all other
memory of the domain. Note that this solution delays updates to

10

W⊕X and binary inspection [100]. For programs that do not rely on
dynamic code generation, this policy can be implemented with very
low run-time overhead. Alternative proposals of hardware designs
for PKU-like security features restrict access to userspace configura-
tion registers [87]. (2) Since the SDRoB library necessarily contains
WRPKRU instructions, we must employ a CFI mechanism to protect
the API implementation of our Reference Monitor and statically
ensure that the Reference Monitor API does not contain abusable
WRPKRU or XRSTOR gadgets. (3) An alternative way to modify PKRU
is by utilizing sigreturn is described in [19]: An untrusted do-
main may exploit sigreturn gadgets and a fabricated sigframe
crafted on the stack to make the kernel write an arbitrary value to the
PKRU. This can happen without using a WRPKRU or XRSTOR gadget
in userspace. sigreturn attacks are mitigated by ASLR [22] but
precluding them requires kernel-level authentication of sigframe
data [62]. (4) As highlighted in [19, 86], existing PKU sandboxes
do not sufficiently safeguard the syscall interface. Attackers can use
a number of unsafe system calls that do not honor PKRU to erase
or manipulate protected memory pages. Previous work [86, 104]
proposes efficient syscall filtering mechanisms to prevent untrusted
domains from invoking unsafe syscalls. With the above security
mechanisms in place, SDRoB satisfies our fourth requirement:

R4 The attacker must not be able to tamper with components re-
sponsible for maintaining isolation between domains, transitions
between domains, or data used as part of the rollback process.

It is possible to implement secure rollback of isolated domains
on top of other isolation mechanisms e.g., within Intel SGX to equip
enclaves with rollback or by using capability-based enforcement
of isolation, e.g., CHERI or ARM Morello. Such uses will incur
different low-level security requirements and exhibit different perfor-
mance characteristics. Furthermore, SDRoB is not limited to rely on
SEGFAULT handling but could employ different attack oracles that,
e.g., trigger when a domain invokes an unexpected system call.

7 DISCUSSION

Applicability. As we highlighted earlier, secure rollback of iso-
lated domains is particularly suited for service-oriented applications
that require strong availability guarantees and may hold volatile state
such as client sessions, TLS connections or object caches. Redun-
dancy and load balancing can be used minimize the impact of denial
of service attacks, but loss of volatile state can still degrade service
quality for clients, which can be mitigated by our approach.

Of course, different applications will benefit from secure rollback
in different ways. A prime target for this mechanism are subroutines
and libraries that handle sequences of external, untrusted data, e.g.,
functions that perform input validation, JavaScript engines in web
browsers, database front-ends, or video, image, and document ren-
derers. Such components exhibit a heightened degree of exposure
towards potential attacks since they operate directly on unsanitized
input. Thus, an application should isolate them in their own domain
so that any memory corruption is contained and execution can con-
tinue on a different path after recovery via the rollback mechanism.
In practice, the specific setup of domains and protections will
depend highly on the architecture of individual applications. We ex-
pect retrofitting existing applications written in unsafe programming
languages in-lieu of a complete re-write in a memory-safe language,

Figure 5: Throughput of different Memcached instrumentation
for different numbers of threads.

cores for 1, 2, and 4 threads but were unable to reach full satura-
tion for 8 threads. We concluded that TLSF has negligible impact
on throughput in all our tests (<1%). For Memcached augmented
with SDRoB the load and running phase overhead is 3.0% / 3.7%
respectively for 4 threads, and 4.4% / 4.9% for 2 threads. SDRoB
introduced a worst-case overhead of 6.6% / 7.3% for a single thread.
We measured a performance degradation of < 1.7% for 8 threads but
lack confidence in the soundness of that result as the CPU was not
fully saturated (cf. Table 4 in Appendix A for all figures).

We measured the memory overhead of SDRoB from the maxi-
mum resident set size (RSS) after the YCSB load phase and compar-
ing the RSS of Memcached with SDRoB to the baseline. The mean
RSS increase is 0.4% (σ=171kb).

6 SECURITY EVALUATION
The primary security requirement for our work is defined with

R1 The mechanism must allow the application to continue operation

after system defenses (A2) detect an attack.

Our proposal satisfies this requirements by compartmentalizing ap-
plications into isolated domains where an attack against a child do-
main can be detected, which leads to the termination of that domain,
while the parent domain is informed and can continue operation.
With respect to attack detection, we assume that an attack or fault
will exhibit an illegal memory access that triggers a SEGFAULT sig-
nal. We then use signal handlers to detect and handle the failure,
leading to a termination of the crashed child domain and a rollback
of the parent domain to a well-defined state. Compartmentalization
is achieved by implementing the following two requirements:

R2 The mechanism must ensure that the integrity of memory after

recovering from the detected attack is maintained.

R3 Run-time attacks that affect one domain must not affect the

integrity of memory in other domains.

In our implementation of SDRoB, we use PKU as a mechanism
to enforce in-process isolation while facilitating efficient domain
switches. The security of this mechanism critically relies on protect-
ing potential gadgets in the SDRoB implementation that allow an
attacker to manipulate the PKRU register.

To guarantee the security of SDRoB, the following orthogonal
defenses need to be in place: (1) PKU crucially relies on untrusted
domains to not contain unsafe WRPKRU or XRSTOR instructions that
manipulate the PKRU register [19]. This can be guaranteed through

11

to be a compelling use case. As such, the design of secure rollback
incorporates different options to compartmentalization.

Furthermore, rollbacks that occur in long-running services may
serve as early warning signals of an attack campaign. The incident
may be reported to a Security Information and Event Management
(SIEM) system and appropriate action, such as blocking malicious
clients in firewall rules can be taken to shield the overall system
from repeated attacks, minimizing the impact on legitimate clients.

Limitations. It is clear that not all applications can be easily com-
partmentalized and refactored to make use of SDRoB. For example,
applications that rely on global mutexes might suffer from avail-
ability issues when a child domain that holds a lock crashes and
the lock is not released prior to continuation of the parent domain.
Options for resolving this are, e.g., to provide an SDRoB-aware
locking mechanism as part of our SDRoB library, or to rely on local
locks in data structures that can be copied into the child domain.

Another potential issue comes with complex data structures used
by target applications. Similar to other strong isolation mechanisms
such as Intel SGX, data needs to be copied into the address space
of the protection domain [23], which is done by entry wrappers.
Both, manual as well as automated generation of these wrappers can
be error prone and may hamper security [101]. Generally, domain
transitions and domain termination bear subtle risks. Currently, con-
fidentiality of child domain data is not guaranteed after destroying it
and we leave it to the developer to realize such requirements, e.g.,
scrub sensitive allocations from memory before leaving the domain.
The use of SDRoB as a mechanism that increases the availabil-
ity of long-running services may open up new side-channel attack
surface. As observing errors might give an attacker insights into an
application’s execution, the observable effects of a rollback (e.g.,
delayed execution) might also give such insights. Coupled with the
absence of re-randomization of the application’s memory layout, an
attacker could potentially use this to break probabilistic defenses
such as ASLR. A potential protection against such attacks could be
achieved by making the rollback behavior of SDRoB configurable
and force an application restart after a certain number of rollbacks,
similarly to probabilistic defenses for pre-forking applications [63].
Ultimately the security of SDRoB depends on the correctness of
our library implementation and further exploration of the attack sur-
face and potentially formal verification of our code are envisaged to
harden our approach. Additionally, we further envision the following
possible extensions to SDRoB:

Global variables. Currently, global variables are stored in the root
domain that is read-only by default to allow access to all nested do-
mains. A more comprehensive solution would place these variables
in their own dedicated data domain(s) with a reserved identifier.

Accessing local variables. As discussed in Section 4.1, having
dedicated stacks per domain precludes accessing local variables
across domain transitions. Beyond the use of registers for passing
arguments and heap memory in shared domains for passing data,
SDRoB could also incorporate existing compiler support for disjoint
stacks present in GCC [110] to facilitate accesses to objects across
stack boundaries, e.g., arguments passed on the stack.

Access control. At the moment, a very simple policy governs
access to domains: in principle only parent domains can perform

12

API calls targeting a nested domain. Still, more flexible policies
may be desirable, i.e., inheriting access to data domains from a
parent. However, such features need to be designed carefully, not to
over-complicate the programming model, or to compromise security.

Strongly Isolated Multithreading Design. SDRoB currently em-
ploys the partially isolated multithreading design discussed in Sec-
tion 3.6. However, if an application employs threads that do not
need to synchronize on shared data, e.g., worker threads processing
local data, then each thread can have a separate isolated root domain
containing each thread’s stack and heap area. This strongly isolated
setup prevents that a compromised thread can access any data owned
by other threads. Furthermore, in case of abnormal domain exit from
a thread root domain, the rollback mechanism can be configured to
discard all the compromised thread’s domains and recreate the thread
from scratch without aborting the application. It would be possible
to allow the setup and initialization of thread root domains to the
configurable by the programmer, to allow for hybrid configurations
where a subset of threads may fail without affecting the main process.
To this end we would add thread creation to the SDRoB API to let
the programmer specify thread root domain identifiers, instead of
wrapping pthread_create() as is done now. This would allow
allocating threads to the same root domains explicitly and also to
share data domains with otherwise strongly isolated threads.

Thread safety. Different threads can initialize the same domain
individually. However, our current implementation of domains is
not thread-safe apart from shared root domains, i.e., it is undefined
what happens if two threads enter a given nested domain at the same
time. The programmer needs to ensure that entry to shared nested
domains (e.g., an isolated crypto library) is synchronized. While our
internal data structures can support concurrent domain entry, more
work is needed to manage abnormal domain exits. If such an exit is
triggered by one thread, it should be propagated automatically to all
other threads that might be running in that domain.

8 RELATED WORK

Compartmentalization via MPK. The idea of using MPK for com-
partmentalizing applications is not new; especially PKU in 64-bit
x86 has been used to augment software fault isolation (SFI) ap-
proaches that generally suffer from high enforcement overheads [89,
106]. Work on PKU-based SFI enforcement falls in two broad cat-
egories: 1) in-process isolation [14, 42, 51, 54, 56, 84, 87, 100,
104, 107], and 2) isolation for unikernels and library operating sys-
tems [60, 71, 95]. PKU, when used a building-block for in-process
isolation has been scrutinized for the lack of discrete controls on
PKRU access which may leave PKU-based schemes vulnerable to
attacks that bypass established isolation domains [19, 86, 104]. A
number of different countermeasures have been proposed against
such attacks, including code rewriting [56], binary inspection [100],
system call filtering [86, 104] and variations on the PKU hardware
design [29, 37, 87]. Secure multi-threading has also been consid-
ered [15, 54, 97]. However, in-process SFI, similar to the defenses
discussed in Section 2.1, generally does not consider how to recover
from attacks that corrupt memory within compartments regardless
of whether enforced via software or hardware. This work addresses

this gap in literature by improving software resilience through the
incorporation of capabilities for secure rollback.

Checkpoint & restore. Existing approaches to checkpoint & re-
store, such as CRIU [52] provide support for process snapshots
that can enable rollback-like functionality. However, checkpoint &
restore generally suffers from high overheads due to relying on re-
producing process memory and do not consider in-memory attacks
in their threat models [64, 75, 109, 114, 117]. SDRoB avoids these
drawbacks by combining in-process isolation to limit the scope of
attacks and to ensure the integrity of memory after rollback.

N-variant Execution. N-variant Execution (NVX) [103] provides
resilience against invasive attacks by introducing redundancy through
running multiple, artificially diversified variants of the same applica-
tion in tandem and monitor each distinct copy for divergent behavior.
If any inconsistencies between the instances are detected NVX termi-
nates the offending instances’ execution while unaffected instances
can continue. While SDRoB shares the goal of improving software
resilience with NVX we consider use cases for which the high cost
of replicating compute instances and I/O across each instance is im-
practical. Safety-critical applications for which the high deployment
cost of NVX may be justified are outside the scope of this work.

9 CONCLUSION & FUTURE WORK
We presented the novel concept of secure rollback of isolated do-
mains which complements protection mechanisms against memory
safety vulnerabilities by providing a hardening mechanism to recover
from detected violations. The concept can be applied to a variety of
software application, improving their availability and resilience to
attacks that exploit such vulnerabilities. At its core, secure rollback
uses hardware-assisted in-process memory isolation to isolate ex-
posed functionality in separate domains, so that a compromise in one
domain cannot spread to other parts of a program’s memory. As soon
as a compromise is detected by the selected defense mechanism, a
rollback to a previously defined consistent state of the application
occurs, enabling error handling and resuming the application.

We explored various design patterns for domains and presented
SDRoB, our prototype library implementation of secure rollback.
We demonstrated its applicability to real software by adding it to the
multi-threaded Memcached system.

Besides alleviating current limitations discussed above, we aim to
improve usability for the programmer, e.g., by providing a domain
specific language and compiler support for the definition of domains
and the exchange of data between them, similar to the edger8r tool
used for Intel SGX enclaves. Providing an amenable, secure, and
efficient implementation of the secure rollback mechanism will fill
an important gap in the current software security architecture.

ACKNOWLEDGMENTS
We thank Ilhan Gurel, Michael Liljestam, Eddy Truyen, Sini Ruo-
homaa and Sava Nedeljkovic for their feedback, which helped im-
prove the paper. We further thank Stijn Volckaert and his team at KU
Leuven – Ghent for providing the infrastructure to run our experi-
ments, and for his feedback on our work. This research is partially
funded by the Research Fund KU Leuven, by the Flemish Research

Programme Cybersecurity. This research has received funding un-
der EU H2020 MSCA-ITN action 5GhOSTS, grant agreement no.
814035.

REFERENCES
[1] Clang 15.0.0git documentation. 2022. Control Flow Integrity.

(February
Retrieved April 23, 2022 from https://clang.llvm.org/docs/

2022).
ControlFlowIntegrity.html.

[2] Martín Abadi, Mihai Budiu, Úlfar Erlingsson, and Jay Ligatti. 2009. Control-flow
Integrity Principles, Implementations, and Applications. ACM Trans. Inf. Syst.
Secur. 13, 1, Article 4 (Nov. 2009), 40 pages. https://doi.org/10.1145/
1609956.1609960

[3] AMD 2021. AMD64 Architecture Programmer’s Manual Volume 2: System
Programming. Revision 3.38. AMD. Publication No. 24593 https://www.amd.
com/system/files/TechDocs/24593.pdf.

[4] Arm Ltd. 2019. ARMv8-A Architecture Reference Manual, Version E.a. Arm
Ltd. https://static.docs.arm.com/ddi0487/ea/DDI0487E_a_armv8_
arm.pdf.

[5] The OpenSSL Project Authors. 2021. OpenSSL 3.0 manpages.

(September
2021). Retrieved April 22, 2022 from https://www.openssl.org/docs/
man3.0/man3/EVP_EncryptUpdate.html.

[6] Sandeep Bhatkar and R. Sekar. 2008. Data Space Randomization. In Detection of
Intrusions and Malware, and Vulnerability Assessment (Lecture notes in Computer
Science), Vol. 5137. Springer-Verlag, Berlin, Heidelberg, Germany, 1–22. https:
//doi.org/10.1007/978-3-540-70542-0_1

[7] Nicholas Brown. 2017. Control-flow Integrity for Real-time Embedded Systems.

Master’s thesis. Worcester Polytechnic Institute, Worcester, MA, USA.

[8] Nathan Burow, Scott A. Carr, Joseph Nash, Per Larsen, Michael Franz, Stefan
Brunthaler, and Mathias Payer. 2017. Control-Flow Integrity: Precision, Security,
and Performance. ACM Comput. Surv. 50, 1, Article 16 (April 2017), 33 pages.
https://doi.org/10.1145/3054924

[9] Nathan Burow, Xingping Zhang, and Mathias Payer. 2019. SoK: Shining Light
on Shadow Stacks. In Proceedings of the 2019 IEEE Symposium on Security and
Privacy (SP ’19). IEEE, Washington, DC, USA, 985–999. https://doi.org/
10.1109/SP.2019.76

[10] Cristian Cadar, Periklis Akritidis, Manuel Costa, Jean-Philippe Martin, and
Miguel Castro. 2008. Data Randomization. Technical Report MSR-TR-2008-
120. Microsoft Research. 14 pages. https://www.microsoft.com/en-us/
research/publication/data-randomization/

[11] Miguel Castro, Manuel Costa, and Tim Harris. 2006. Securing Software by En-
forcing Data-flow Integrity. In Proceedings of the 7th Symposium on Operating
Systems Design and Implementation (OSDI ’06). USENIX Association, Berke-
ley, CA, USA, 147–160. http://dl.acm.org/citation.cfm?id=1298455.
1298470

[12] Miguel Castro, Manuel Costa, Jean-Philippe Martin, Marcus Peinado, Periklis
Akritidis, Austin Donnelly, Paul Barham, and Richard Black. 2009. Fast Byte-
granularity Software Fault Isolation. In Proceedings of the ACM SIGOPS 22nd
Symposium on Operating Systems Principles (SOSP ’09). ACM, New York, NY,
USA, 45–58. https://doi.org/10.1145/1629575.1629581

[13] Shuo Chen, Jun Xu, and Emre C. Sezer. 2005.

Attacks Are Realistic Threats.
(USENIX Security 05). USENIX Association, Baltimore, MD.
//www.usenix.org/conference/14th-usenix-security-symposium/
non-control-data-attacks-are-realistic-threats

Non-Control-Data
In 14th USENIX Security Symposium
https:

[14] Yuan Chen, Jiaqi Li, Guorui Xu, Yajin Zhou, Zhi Wang, Cong Wang, and Kui Ren.
2022. SGXLock: Towards Efficiently Establishing Mutual Distrust Between Host
Application and Enclave for SGX. In 31st USENIX Security Symposium (USENIX
Security 22). USENIX Association, Boston, MA. https://www.usenix.org/
conference/usenixsecurity22/presentation/chen-yuan

[15] Yaohui Chen, Sebassujeen Reymondjohnson, Zhichuang Sun, and Long Lu. 2016.
Shreds: Fine-Grained Execution Units with Private Memory. In 2016 IEEE Sym-
posium on Security and Privacy (SP). 56–71. https://doi.org/10.1109/SP.
2016.12

[16] Long Cheng, Hans Liljestrand, Md Salman Ahmed, Thomas Nyman, Dan-
feng Yao, Trent Yaeger, and N. Asokan. 2019. Exploitation Techniques
and Defenses for Data-Oriented Attacks. In Proceedings of IEEE Secure
Development Conference 2019 (SecDev ’19). IEEE, Washington, DC, USA,
https://conferences.computer.org/secdevwp/2019/pdfs/
114–128.
SecDev2019-1rjjdWR0xr5TteaniOqo87/6KAs9q0R8P5JJ6f5o1Mk6x/
7MG44mi8avOr4kkcynEmUK.pdf

[17] Long Cheng, Ke Tian, and Danfeng (Daphne) Yao. 2017. Orpheus: Enforcing
Cyber-Physical Execution Semantics to Defend Against Data-Oriented Attacks.
In Proceedings of the 33rd Annual Computer Security Applications Conference
(ACSAC 2017). ACM, New York, NY, USA, 315–326. https://doi.org/10.
1145/3134600.3134640

13

[18] Tzi-Cker Chiueh and Fu-Hau Hsu. 2001. RAD: A Compile-Time Solution to
Buffer Overflow Attacks. In Proceedings of the The 21st International Conference
on Distributed Computing Systems (ICDCS ’01). IEEE, Washington, DC, USA,
409–417. https://doi.org/10.1109/ICDSC.2001.918971

[19] R. Joseph Connor, Tyler McDaniel, Jared M. Smith, and Max Schuchard.
2020. PKU Pitfalls: Attacks on PKU-based Memory Isolation Systems. In
29th USENIX Security Symposium (USENIX Security 20). USENIX Association,
1409–1426. https://www.usenix.org/conference/usenixsecurity20/
presentation/connor

[20] Matthew Conte. 2016. Github - mattconte/tlsf: Two-Level Segregated Fit memory
allocator implementation. (April 2016). Retrieved April 22, 2022 from https:
//github.com/mattconte/tlsf.

[21] Brian F. Cooper, Adam Silberstein, Erwin Tam, Raghu Ramakrishnan, and Russell
Sears. 2010. Benchmarking Cloud Serving Systems with YCSB. In Proceedings
of the 1st ACM Symposium on Cloud Computing (SoCC ’10). Association for
Computing Machinery, New York, NY, USA, 143–154. https://doi.org/10.
1145/1807128.1807152

[22] Jonathan Corbet. 2016. Sigreturn-oriented programming and its mitigation. (Feb-
ruary 2016). Retrieved April 27, 2022 from https://lwn.net/Articles/
676803/.

[23] Victor Costan and Srinivas Devadas. 2016. Intel SGX explained. Cryptology

ePrint Archive (2016).

[24] Crispin Cowan, Calton Pu, Dave Maier, Heather Hintony, Jonathan Walpole,
Peat Bakke, Steve Beattie, Aaron Grier, Perry Wagle, and Qian Zhang. 1998.
StackGuard: Automatic Adaptive Detection and Prevention of Buffer-overflow
Attacks. In Proceedings of the 7th USENIX Security Symposium (USENIX Security
’98). USENIX Association, Berkeley, CA, USA, 5–5. http://dl.acm.org/
citation.cfm?id=1267549.1267554

[26] CVE-2011-4971. 2021.

[25] Stephen Crane, Christopher Liebchen, Andrei Homescu, Lucas Davi, Per Larsen
Larsen, Ahmad-Reza Sadeghi, Stefan Brunthaler, and Michael Franz. 2015.
Readactor: Practical Code Randomization Resilient to Memory Disclosure. In
Proceedings of the 2015 IEEE Symposium on Security and Privacy (SP ’15). IEEE,
Washington, DC, USA, 763–780. https://doi.org/10.1109/SP.2015.52
(December 2021). Retrieved April 26, 2022 from
https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2011-4971.
[27] Thurston H.Y. Dang, Petros Maniatis, and David Wagner. 2015. The Performance
Cost of Shadow Stacks and Stack Canaries. In Proceedings of the 10th ACM
ASIA Conference on Information, Computer and Communications Security (ASIA
CCS ’15). ACM, New York, NY, USA, 555–566. https://doi.org/10.1145/
2714576.2714635

[28] Ruan de Clercq and Ingrid Verbauwhede. 2017. A survey of Hardware-based

Control Flow Integrity (CFI). (2017). arXiv:cs.CR/1706.07257

[29] Leila Delshadtehrani, Sadullah Canakci, Manuel Egele, and Ajay Joshi. 2021.
SealPK: Sealable Protection Keys for RISC-V. In 2021 Design, Automation Test
in Europe Conference Exhibition (DATE). 1278–1281. https://doi.org/10.
23919/DATE51398.2021.9473932

[30] Joe Devietti, Colin Blundell, Milo M. K. Martin, and Steve Zdancewic. 2008.
Hardbound: Architectural Support for Spatial Safety of the C Programming
Language. In Proceedings of the 13th International Conference on Architectural
Support for Programming Languages and Operating Systems (ASPLOS ’08).
ACM, New York, NY, USA, 103–114. https://doi.org/10.1145/1346281.
1346295

[31] Ren Ding, Chenxiong Qian, Chengyu Song, William Harris, Taesoo Kim, and
Wenke Lee. 2017. Efficient Protection of Path-Sensitive Control Security. In
Proceedings of the 26th USENIX Security Symposium (USENIX Security ’17).
USENIX Association, Berkeley, CA, USA, 131–148.

[32] Gregory J Duck, Roland HC Yap, and Lorenzo Cavallaro. 2017. Stack Bounds
Protection with Low Fat Pointers. In Proceedings of the 24th Annual Network and
Distributed System Security Symposium (NDSS ’17). The Internet Society, Reston,
VA, USA. https://doi.org/10.14722/ndss.2017.23287

[33] Gregory J. Duck and Roland H. C. Yap. 2016. Heap Bounds Protection with Low
Fat Pointers. In Proceedings of the 25th International Conference on Compiler
Construction (CC 2016). ACM, New York, NY, USA, 132–142. https://doi.
org/10.1145/2892208.2892212

[34] Úlfar Erlingsson, Martín Abadi, Michael Vrable, Mihai Budiu, and George C.
Necula. 2006. XFI: Software Guards for System Address Spaces. In Proceedings
of the 7th Symposium on Operating Systems Design and Implementation (OSDI
’06). USENIX Association, Berkeley, CA, USA, 75–88. http://dl.acm.org/
citation.cfm?id=1298455.1298463

[35] Úlfar Erlingsson, Yves Younan, and Frank Piessens. 2010. Low-level software
security by example. In Handbook of Information and Communication Security.
Springer, 633–658.

[36] Lang Feng, Jeff Huang, Jiang Hu, and Abhijith Reddy. 2019. FastCFI: Real-
Time Control Flow Integrity Using FPGA Without Code Instrumentation. In
Runtime Verification (Lecture Notes in Computer Science), Vol. 11757. Springer
International Publishing, Cham, Switzerland, 221–238.

[37] Tommaso Frassetto, Patrick Jauernig, Christopher Liebchen, and Ahmad-Reza
Sadeghi. 2018. IMIX: In-Process Memory Isolation EXtension. In 27th USENIX
Security Symposium (USENIX Security 18). USENIX Association, Baltimore,
MD, 83–97. https://www.usenix.org/conference/usenixsecurity18/
presentation/frassetto

[38] Jonathon T. Giffin, Somesh Jha, and Barton P. Miller. 2002. Detecting Manipulated
Remote Call Streams. In Proceedings of the 11th USENIX Security Symposium
(USENIX Security ’02). USENIX Association, Berkeley, CA, USA, 61–79. http:
//dl.acm.org/citation.cfm?id=647253.720282

[39] Jonathon T. Giffin, Somesh Jha, and Barton P. Miller. 2004. Efficient context-
sensitive intrusion detection. In Proceedings of the 11th Network and Distributed
System Security Symposium (NDSS ’04). The Internet Society, Reston, VA, USA.
[40] glibc wiki. 2019. Overview of Malloc. (May 2019). Retrieved April 26, 2022

from https://sourceware.org/glibc/wiki/MallocInternals.

[41] Javid Habibi, Ajay Panicker, Aditi Gupta, and Elisa Bertino. 2015. Dis-
ARM: Mitigating Buffer Overflow Attacks on Embedded Devices. Springer
https://doi.org/10.1007/
International Publishing, Cham, 112–129.
978-3-319-25645-0_8

[42] Mohammad Hedayati, Spyridoula Gravani, Ethan Johnson, John Criswell,
Michael L. Scott, Kai Shen, and Mike Marty. 2019. Hodor: Intra-Process
Isolation for High-Throughput Data Plane Libraries. In 2019 USENIX Annual
Technical Conference (USENIX ATC 19). USENIX Association, Renton, WA,
489–504. https://www.usenix.org/conference/atc19/presentation/
hedayati-hodor

[47]

[46]

[43] Thomas Herault and Yves Robert. 2015. Fault-Tolerance Techniques for High-
Performance Computing (1st ed.). Springer Publishing Company, Incorporated.
[44] Hewlett Packard 1994. PA-RISC 1.1 Architecture and Instruction Set Reference
mMnual, Third Edition. Hewlett Packard. HP Part Number: 09740-90039 https:
//parisc.wiki.kernel.org/images-parisc/6/68/Pa11_acd.pdf.
[45] Hong Hu, Chenxiong Qian, Carter Yagemann, Simon Pak Ho Chung, William R.
Harris, Taesoo Kim, and Wenke Lee. 2018. Enforcing Unique Code Target
Property for Control-Flow Integrity. In Proceedings of the 2018 ACM SIGSAC
Conference on Computer and Communications Security (CCS ’18). ACM, New
York, NY, USA, 1470–1486. https://doi.org/10.1145/3243734.3243797
IBM 2022. Programming for AIX 7.3: Storage Protect Keys. IBM. https://www.
ibm.com/docs/en/aix/7.3?topic=concepts-storage-protect-keys.
Intel IA-64 Architecture Software Developer’s Man-
Intel Corporation 2000.
ual Volume 1: IA-64 Application Architecture. Revision 1.1.
Intel Corpora-
tion. Document Number: 245317-002 http://refspecs.linux-foundation.
org/IA64-softdevman-vol1.pdf.
Intel 64 and IA-32 Architectures Software Devel-
Intel Corporation 2007.
oper’s Manual Volume 3A: System Programming Guide.
Intel Corporation.
Order Number: 325462-076US https://www.intel.com/content/www/us/
en/developer/articles/technical/intel-sdm.html.
Intel Corporation 2016. Control-flow Enforcement Technology Preview. Intel
https://software.intel.com/sites/default/files/
Corporation.
managed/4d/2a/control-flow-enforcement-technology-preview.
pdf.
Intel Corporation 2016. Intel Software Guard Extensions SDK for Linux OS. Intel
https://01.org/sites/default/files/documentation/
Corporation.
intel_sgx_sdk_developer_reference_for_linux_os_pdf.pdf.

[48]

[49]

[50]

[51] X. Jin, X. Xiao, S. Jia, W. Gao, H. Zhang, D. Gu, S. Ma, Z. Qian, and J.
Li. 2022. Annotating, Tracking, and Protecting Cryptographic Secrets with
CryptoMPK. In 2022 2022 IEEE Symposium on Security and Privacy (SP)
(SP). IEEE Computer Society, Los Alamitos, CA, USA, 473–488. https:
//doi.org/10.1109/SP46214.2022.00028

[52] Sanidhya Kashyap, Changwoo Min, Byoungyoung Lee, Taesoo Kim, and Pavel
Emelyanov. 2016. Instant OS Updates via Userspace Checkpoint-and-Restart.
In 2016 USENIX Annual Technical Conference (USENIX ATC 16). USENIX
Association, Denver, CO, 605–619. https://www.usenix.org/conference/
atc16/technical-sessions/presentation/kashyap

[53] Gaurav S. Kc, Angelos D. Keromytis, and Vassilis Prevelakis. 2003. Countering
Code-Injection Attacks with Instruction-Set Randomization. In Proceedings of
the 10th ACM Conference on Computer and Communications Security (CCS ’03).
ACM, New York, NY, USA, 272–280. https://doi.org/10.1145/948109.
948146

[54] Paul Kirth, Mitchel Dickerson, Stephen Crane, Per Larsen, Adrian Dabrowski,
David Gens, Yeoul Na, Stijn Volckaert, and Michael Franz. 2022. PKRU-Safe:
Automatically Locking down the Heap between Safe and Unsafe Languages.
In Proceedings of the Seventeenth European Conference on Computer Systems
(EuroSys ’22). Association for Computing Machinery, New York, NY, USA,
132–148. https://doi.org/10.1145/3492321.3519582

[55] Chris Kjellqvist, Mohammad Hedayati, and Michael L. Scott. 2020. Safe, Fast
Sharing of Memcached as a Protected Library. In 49th International Conference
on Parallel Processing - ICPP (ICPP ’20). Association for Computing Machin-
ery, New York, NY, USA, Article 6, 8 pages. https://doi.org/10.1145/
3404397.3404443

14

[56] Koen Koning, Xi Chen, Herbert Bos, Cristiano Giuffrida, and Elias Athanasopou-
los. 2017. No Need to Hide: Protecting Safe Regions on Commodity Hardware.
In Proceedings of the Twelfth European Conference on Computer Systems (Eu-
roSys ’17). Association for Computing Machinery, New York, NY, USA, 437–452.
https://doi.org/10.1145/3064176.3064217

[57] Volodymyr Kuznetsov, László Szekeres, Mathias Payer, George Candea, R.
Sekar, and Dawn Song. 2014. Code-Pointer Integrity. In Proceedings of the
11th USENIX Conference on Operating Systems Design and Implementation
(OSDI’14). USENIX Association, Berkeley, CA, USA, 147–163.

[58] Albert Kwon, Udit Dhawan, Jonathan M. Smith, Thomas F. Knight, Jr., and
Andre DeHon. 2013. Low-fat Pointers: Compact Encoding and Efficient Gate-
level Implementation of Fat Pointers for Spatial Safety and Capability-based
Security. In Proceedings of the 2013 ACM SIGSAC Conference on Computer
and Communications Security (CCS ’13). ACM, New York, NY, USA, 721–732.
https://doi.org/10.1145/2508859.2516713

[59] Per Larsen, Andrei Homescu, Stefan Brunthaler, and Michael Franz. 2014. SoK:
Automated Software Diversity. In Proceedings of the 2014 IEEE Symposium on
Security and Privacy (SP ’14). IEEE, Washington, DC, USA, 276–291. https:
//doi.org/10.1109/SP.2014.25

[60] Hugo Lefeuvre, Vlad-Andrei B˘adoiu, ¸Stefan Teodorescu, Pierre Olivier, Tiberiu
Mosnoi, R˘azvan Deaconescu, Felipe Huici, and Costin Raiciu. 2021. FlexOS:
Making OS Isolation Flexible. In Proceedings of the Workshop on Hot Topics
in Operating Systems (HotOS ’21). Association for Computing Machinery, New
York, NY, USA, 79–87. https://doi.org/10.1145/3458336.3465292
[61] Hans Liljestrand, Zaheer Gauhar, Thomas Nyman, Jan-Erik Ekberg, and N.
Asokan. 2019. Protecting the Stack with PACed Canaries. In Proceedings of
the 4th Workshop on System Software for Trusted Execution (SysTEX ’19). As-
sociation for Computing Machinery, New York, NY, USA, Article 4, 6 pages.
https://doi.org/10.1145/3342559.3365336

[62] Hans Liljestrand, Thomas Nyman, Lachlan J. Gunn, Jan-Erik Ekberg, and
In 30th
N. Asokan. 2021.
USENIX Security Symposium (USENIX Security 21). USENIX Association,
https://www.usenix.org/conference/
Berkeley, CA, USA, 357–374.
usenixsecurity21/presentation/liljestrand

PACStack: an Authenticated Call Stack.

[63] Hans Liljestrand, Thomas Nyman, Kui Wang, Carlos Chinea Perez, Jan-
Erik Ekberg, and N. Asokan. 2019.
PAC it up: Towards Pointer In-
tegrity using ARM Pointer Authentication. In 28th USENIX Security Sym-
posium (USENIX Security ’19). USENIX Association, Berkeley, CA, USA,
https://www.usenix.org/conference/usenixsecurity19/
177–194.
presentation/liljestrand

[64] Yudan Liu, Raja Nassar, Chokchai Leangsuksun, Nichamon Naksinehaboon,
Mihaela Paun, and Stephen L. Scott. 2008. An optimal checkpoint/restart model
for a large scale high performance computing system. In 2008 IEEE International
Symposium on Parallel and Distributed Processing. 1–9. https://doi.org/
10.1109/IPDPS.2008.4536279

[65] Kangjie Lu, Chengyu Song, Byoungyoung Lee, Simon P. Chung, Taesoo Kim, and
Wenke Lee. 2015. ASLR-Guard: Stopping Address Space Leakage for Code Reuse
Attacks. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and
Communications Security (CCS ’15). Association for Computing Machinery, New
York, NY, USA, 280–291. https://doi.org/10.1145/2810103.2813694

[66] Libc Manual. 2022. The GNU Allocator.

Retrieved
April 26, 2022 from https://www.gnu.org/software/libc/manual/html_
node/The-GNU-Allocator.html.

(January 2022).

[67] Yandong Mao, Haogang Chen, Dong Zhou, Xi Wang, Nickolai Zeldovich, and
M. Frans Kaashoek. 2011. Software Fault Isolation with API Integrity and
Multi-principal Modules. In Proceedings of the Twenty-Third ACM Symposium on
Operating Systems Principles (SOSP ’11). ACM, New York, NY, USA, 115–128.
https://doi.org/10.1145/2043556.2043568

[68] Virendra J. Marathe, Margo Seltzer, Steve Byan, and Tim Harris. 2017. Persistent
Memcached: Bringing Legacy Code to Byte-Addressable Persistent Memory.
In 9th USENIX Workshop on Hot Topics in Storage and File Systems (HotStor-
age 17). USENIX Association, Santa Clara, CA. https://www.usenix.org/
conference/hotstorage17/program/presentation/marathe

[69] Ali Jose Mashtizadeh, Andrea Bittau, Dan Boneh, and David Mazières. 2015.
CCFI: Cryptographically Enforced Control Flow Integrity. In Proceedings of
the 22nd ACM SIGSAC Conference on Computer and Communications Security
(CCS ’15). ACM, New York, NY, USA, 941–951. https://doi.org/10.1145/
2810103.2813676

[70] M. Masmano, I. Ripoll, A. Crespo, and J. Real. 2004. TLSF: a new dy-
namic memory allocator for real-time systems. In Proceedings. 16th Euromi-
cro Conference on Real-Time Systems, 2004. ECRTS 2004. 79–88. https:
//doi.org/10.1109/EMRTS.2004.1311009

[71] Marcela S. Melara, Michael J. Freedman, and Mic Bowman. 2019. Enclave-
Dom: Privilege Separation for Large-TCB Applications in Trusted Execution
Environments. arXiv:1907.13245 [cs.CR]. (2019). http://arxiv.org/
abs/1907.13245

[72] Memcached. 2022.

(March 2022). Retrieved April 26, 2022 from https:

//memcached.org/.

[73] Onur Mutlu and Jeremie S. Kim. 2020. RowHammer: A Retrospective. Trans.
Comp.-Aided Des. Integ. Cir. Sys. 39, 8 (aug 2020), 1555–1571. https://doi.
org/10.1109/TCAD.2019.2915318

[74] Santosh Nagarakatte, Jianzhou Zhao, M.K. Martin, Milo, and Steve Zdancewic.
2009. SoftBound: Highly Compatible and Complete Spatial Memory Safety
for C. In Proceedings of the 30th ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI ’09). ACM, New York, NY, USA,
245–258. https://doi.org/10.1145/1542476.1542504

[75] Hyochang Nam, Jong Kim, Sung Je Hong, and Sunggu Lee. 2003. Secure
checkpointing. Journal of Systems Architecture 48, 8 (2003), 237–254. https:
//doi.org/10.1016/S1383-7621(02)00137-6

[76] Danny Nebenzahl, Mooly Sagiv, and Avishai Wool. 2006. Install-Time Vacci-
nation of Windows Executables to Defend Against Stack Smashing Attacks.
IEEE Trans. Dependable Secur. Comput. 3, 1 (Jan. 2006), 78–90. https:
//doi.org/10.1109/TDSC.2006.14

[77] Rajesh Nishtala, Hans Fugal, Steven Grimm, Marc Kwiatkowski, Herman Lee,
Harry C. Li, Ryan McElroy, Mike Paleczny, Daniel Peek, Paul Saab, David
Stafford, Tony Tung, and Venkateshwaran Venkataramani. 2013. Scaling Mem-
cache at Facebook. In Proceedings of the 10th USENIX Conference on Net-
worked Systems Design and Implementation (nsdi’13). USENIX Association,
USA, 385–398.

[78] Ben Niu and Gang Tan. 2014. RockJIT: Securing Just-In-Time Compilation
Using Modular Control-Flow Integrity. In Proceedings of the 2014 ACM SIGSAC
Conference on Computer and Communications Security (CCS ’14). ACM, New
York, NY, USA, 1317–1328. https://doi.org/10.1145/2660267.2660281
[79] Ben Niu and Gang Tan. 2015. Per-Input Control-Flow Integrity. In Proceedings of
the 22Nd ACM SIGSAC Conference on Computer and Communications Security
(CCS ’15). ACM, New York, NY, USA, 914–926. https://doi.org/10.1145/
2810103.2813644

[80] Linux Manual Page. 2021. setjmp(3). (August 2021). Retrieved April 23, 2022
from https://man7.org/linux/man-pages/man3/setjmp.3.html.
[81] Linux Manual Page. 2021. sigaction(2). (August 2021). Retrieved April 23, 2022

from https://man7.org/linux/man-pages/man2/sigaction.2.html.
[82] Soyeon Park, Sangho Lee, Wen Xu, Hyungon Moon, and Taesoo Kim. 2019.
Libmpk: Software Abstraction for Intel Memory Protection Keys (Intel MPK).
In Proceedings of the 2019 USENIX Conference on Usenix Annual Technical
Conference (ATC ’19). USENIX Association, Berkeley, CA, USA, 241–254.
[83] Manish Prasad and Tzi-cker Chiueh. 2003. A Binary Rewriting Defense against
Stack Based Overflow attacks. In Proceedings of the 2003 USENIX Annual
Technical Conference (ATC ’03). USENIX Association, Berkeley, CA, USA,
211–224.

[84] Elijah E. Rivera. 2016. Preserving Memory Safety in Safe Rust during Interactions
with Unsafe Languages. Master’s thesis. Department of Electrical Engineering
and Computer Science.

[85] C. Schlesinger, K. Pattabiraman, N. Swamy, D. Walker, and B. Zorn. 2011. Mod-
ular Protections against Non-control Data Attacks. In 2011 IEEE 24th Com-
puter Security Foundations Symposium. IEEE, Washington, DC, USA, 131–145.
https://doi.org/10.1109/CSF.2011.16

[86] David Schrammel, Samuel Weiser, Richard Sadek, and Stefan Mangard. 2022.
Jenny: Securing Syscalls for PKU-based Memory Isolation Systems. In 31st
USENIX Security Symposium (USENIX Security 22). USENIX Association,
Boston, MA. https://www.usenix.org/conference/usenixsecurity22/
presentation/schrammel

[87] David Schrammel, Samuel Weiser, Stefan Steinegger, Martin Schwarzl, Michael
Schwarz, Stefan Mangard, and Daniel Gruss. 2020. Donky: Domain Keys –
Efficient In-Process Isolation for RISC-V and x86. In 29th USENIX Security Sym-
posium (USENIX Security 20). USENIX Association, 1677–1694. https://www.
usenix.org/conference/usenixsecurity20/presentation/schrammel
[88] Edward J. Schwartz, Thanassis Avgerinos, and David Brumley. 2011. Q: Exploit
Hardening Made Easy. In Proceedings of the 20th USENIX Security Symposium
(USENIX Security ’11). USENIX Association, Berkeley, CA, USA, 25–25. http:
//dl.acm.org/citation.cfm?id=2028067.2028092

[89] David Sehr, Robert Muth, Cliff Biffle, Victor Khimenko, Egor Pasko,
Karl Schimpf, Bennet Yee, and Brad Chen. 2010. Adapting Software
In 19th USENIX
Fault
Security Symposium (USENIX Security 10). USENIX Association, Washing-
https://www.usenix.org/conference/usenixsecurity10/
ton, DC.
adapting-software-fault-isolation-contemporary-cpu-architectures

Isolation to Contemporary CPU Architectures.

[90] Kostya Serebryany. 2019. ARM Memory Tagging Extension and How It Improves
C/C++ Memory Safety. ;login: The USENIX Magazine 48, 2 (2019), 12–16.
[91] Konstantin Serebryany, Derek Bruening, Alexander Potapenko, and Dmitriy
Vyukov. 2012. AddressSanitizer: A Fast Address Sanity Checker. In Proceedings
of the 2012 USENIX Annual Technical Conference (ATC ’12). USENIX Associa-
tion, Berkeley, CA, USA, 309–318. https://www.usenix.org/conference/
atc12/technical-sessions/presentation/serebryany

15

Symposium on Security and Privacy. IEEE, Washington, DC, USA, 20–37.
https://doi.org/10.1109/SP.2015.9

[109] Ashton Webster, Ryan Eckenrod, and James Purtilo. 2018. Fast and Service-
preserving Recovery from Malware Infections Using CRIU. In 27th USENIX
Security Symposium (USENIX Security 18). USENIX Association, Baltimore, MD,
1199–1211. https://www.usenix.org/conference/usenixsecurity18/
presentation/webster

[110] GCC Wiki. 2011. Split Stacks in GCC. (February 2011). Retrieved April 26,

2022 from https://gcc.gnu.org/wiki/SplitStacks.

[111] Jonathan Woodruff, Robert N.M. Watson, David Chisnall, Simon W. Moore,
Jonathan Anderson, Brooks Davis, Ben Laurie, Peter G. Neumann, Robert Norton,
and Michael Roe. 2014. The CHERI Capability Model: Revisiting RISC in
an Age of Risk. In Proceeding of the 41st Annual International Symposium
on Computer Architecture (ISCA ’14). IEEE, Washington, DC, USA, 457–468.
http://dl.acm.org/citation.cfm?id=2665671.2665740

[112] Wenjie Xiong and Jakub Szefer. 2021. Survey of Transient Execution Attacks
and Their Mitigations. ACM Comput. Surv. 54, 3, Article 54 (may 2021), 36 pages.
https://doi.org/10.1145/3442479

[113] Jun Xu, Zbigniew Kalbarczyk, Sanjay Patel, and Ravishankar K. Iyer. 2002.
Architecture Support for Defending Against Buffer Overflow Attacks. Technical
Report UILU-ENG-02-2205 (CRHC-02-05). University of Illinois at Urbana-
Champaign. 18 pages. https://www.ideals.illinois.edu/bitstream/
handle/2142/74493/B53-CRHC_02_05.pdf

[114] John W. Young. 1974. A first order approximation to the optimum checkpoint

interval. Commun. ACM 17 (1974), 530–531.

[115] Google Project Zero. 2022. 0day "In the Wild" dataset. (February 2022). Re-
trieved April 26, 2022 from https://googleprojectzero.blogspot.com/
p/0day.html.

[116] Chao Zhang, Mehrdad Niknami, Kevin Zhijie Chen, Chengyu Song, Zhaofeng
Chen, and Dawn Song. 2015. JITScope: Protecting web users from control-flow
hijacking attacks. In Proceedings of the 2015 IEEE Conference on Computer
Communications (INFOCOM ’15). IEEE, Washington, DC, USA, 567–575.

[117]

Irene Zhang, Tyler Denniston, Yury Baskakov, and Alex Garthwaite. 2013. Opti-
mizing VM Checkpointing for Restore Performance in VMware ESXi. In 2013
USENIX Annual Technical Conference (USENIX ATC 13). USENIX Associa-
tion, San Jose, CA, 1–12. https://www.usenix.org/conference/atc13/
technical-sessions/presentation/zhang

[118] Yiying Zhang and Steven Swanson. 2015. A study of application performance
with non-volatile main memory. In 2015 31st Symposium on Mass Storage Systems
and Technologies (MSST). 1–10. https://doi.org/10.1109/MSST.2015.
7208275

[92] Arvind Seshadri, Mark Luk, Elaine Shi, Adrian Perrig, Leendert van Doorn,
and Pradeep Khosla. 2005. Pioneer: Verifying Code Integrity and Enforcing
Untampered Code Execution on Legacy Systems. In Proceedings of the 20th ACM
Symposium on Operating Systems Principles (SOSP ’05). ACM, New York, NY,
USA, 1–16. https://doi.org/10.1145/1095810.1095812

[93] Carlton Shepherd, Konstantinos Markantonakis, Nico van Heijningen, Driss
Aboulkassimi, Clément Gaine, Thibaut Heckmann, and David Naccache. 2021.
Physical fault injection and side-channel attacks on mobile devices: A com-
prehensive analysis. Computers & Security 111 (2021), 102471. https:
//doi.org/10.1016/j.cose.2021.102471

[94] Chengyu Song, Hyungon Moon, Monjur Alam, Insu Yun, Byoungyoung Lee,
Taesoo Kim, Wenke Lee, and Yunheung Paek. 2016. HDFI: Hardware-Assisted
Data-Flow Isolation. In Proceedings of the 2016 IEEE Symposium on Security
and Privacy (SP ’16). IEEE, Washington, DC, USA, 1–17. https://doi.org/
10.1109/SP.2016.9

[95] Mincheol Sung, Pierre Olivier, Stefan Lankes, and Binoy Ravindran. 2020. Intra-
Unikernel Isolation with Intel Memory Protection Keys. In Proceedings of the
16th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution
Environments (VEE ’20). Association for Computing Machinery, New York, NY,
USA, 143–156. https://doi.org/10.1145/3381052.3381326

[96] Laszlo Szekeres, Mathias Payer, Tao Wei, and Dawn Song. 2013. SoK: Eternal
War in Memory. In Proceedings of the 2013 IEEE Symposium on Security and
Privacy (SP ’13). IEEE, Washington, DC, USA, 48–62. https://doi.org/10.
1109/SP.2013.13

[97] Zahra Tarkhani and Anil Madhavapeddy. 2020. µTiles: Efficient Intra-Process

Privilege Enforcement of Memory Regions. (2020). arXiv:cs.OS/2004.04846

[98] Caroline Tice, Tom Roeder, Peter Collingbourne, Stephen Checkoway, Úlfar
Erlingsson, Luis Lozano, and Geoff Pike. 2014. Enforcing Forward-edge Control-
flow Integrity in GCC & LLVM. In Proceedings of the 23rd USENIX Security
Symposium (USENIX Security ’14). USENIX Association, Berkeley, CA, USA,
941–955. http://dl.acm.org/citation.cfm?id=2671225.2671285
[99] Stylianos Tsampas, Akram El-Korashy, Marco Patrignani, Dominique Devriese,
Deepak Garg, and Frank Piessens. 2017. Towards automatic compartmental-
ization of C programs on capability machines. Presented at the 2017 Work-
shop on Foundations of Computer Security, FCS ’17. (2017), 14 pages.
https://lirias.kuleuven.be/handle/123456789/593124.

[100] Anjo Vahldiek-Oberwagner, Eslam Elnikety, Nuno O. Duarte, Michael Samm-
ler, Peter Druschel, and Deepak Garg. 2019. ERIM: Secure, Efficient In-
process Isolation with Protection Keys (MPK). In 28th USENIX Security
Symposium (USENIX Security 19). USENIX Association, Santa Clara, CA,
1221–1238. https://www.usenix.org/conference/usenixsecurity19/
presentation/vahldiek-oberwagner

[101] Jo Van Bulck, David Oswald, Eduard Marin, Abdulla Aldoseri, Flavio D Garcia,
and Frank Piessens. 2019. A tale of two worlds: Assessing the vulnerability of
enclave shielding runtimes. In Proceedings of the 2019 ACM SIGSAC Conference
on Computer and Communications Security. 1741–1758.

[102] Victor van der Veen, Dennis Andriesse, Enes Gökta¸s, Ben Gras, Lionel Sambuc,
Asia Slowinska, Herbert Bos, and Cristiano Giuffrida. 2015. Practical Context-
Sensitive CFI. In Proceedings of the 22nd ACM SIGSAC Conference on Computer
and Communications Security (CCS ’15). ACM, New York, NY, USA, 927–940.
https://doi.org/10.1145/2810103.2813673

[103] Alexios Voulimeneas, Dokyung Song, Fabian Parzefall, Yeoul Na, Per Larsen,
Michael Franz, and Stijn Volckaert. 2020. Distributed Heterogeneous N-Variant
Execution. In Detection of Intrusions and Malware, and Vulnerability Assessment,
Clémentine Maurice, Leyla Bilge, Gianluca Stringhini, and Nuno Neves (Eds.).
Springer International Publishing, Cham, 217–237.

[104] Alexios Voulimeneas, Jonas Vinck, Ruben Mechelinck, and Stijn Volckaert.
2022. You Shall Not (by)Pass! Practical, Secure, and Fast PKU-Based Sandboxing.
In Proceedings of the Seventeenth European Conference on Computer Systems
(EuroSys ’22). Association for Computing Machinery, New York, NY, USA,
266–282. https://doi.org/10.1145/3492321.3519560

[105] Perry Wagle and Crispin Cowan. 2003. StackGuard: Simple Stack Smash

Protection for GCC. (01 2003).

[106] Robert Wahbe, Steven Lucco, Thomas E. Anderson, and Susan L. Graham. 1993.
Efficient Software-based Fault Isolation. In Proceedings of the Fourteenth ACM
Symposium on Operating Systems Principles (SOSP ’93). ACM, New York, NY,
USA, 203–216. https://doi.org/10.1145/168619.168635

[107] Xiaoguang Wang, SengMing Yeoh, Pierre Olivier, and Binoy Ravindran. 2020.
Secure and Efficient In-Process Monitor (and Library) Protection with Intel MPK.
In Proceedings of the 13th European Workshop on Systems Security (EuroSec
’20). Association for Computing Machinery, New York, NY, USA, 7–12. https:
//doi.org/10.1145/3380786.3391398

[108] Robert N. M. Watson, Jonathan Woodruff, Peter G. Neumann, Simon W. Moore,
Jonathan Anderson, David Chisnall, Nirav Dave, Brooks Davis, Khilan Gudka,
Ben Laurie, Steven J. Murdoch, Robert Norton, Michael Roe, Stacey Son, and
Munraj Vadera. 2015. CHERI: A Hybrid Capability-System Architecture for
Scalable Software Compartmentalization. In Proceedings of the 2015 IEEE

16

Table 2: Detailed table of rollback latency measurements

Zeroing of domain data

No (default)
Yes

Rollback latency (µs)
σ
SDRoB
±0.9µs
3.46
228376.99 (0.2s) ±2500µs

Table 3: Detailed table of memory consumption measurements

#Thr

Maximum resident set size (kb)

Baseline

σ

SDRoB

σ

4

14535444.8 ±1.19% 14598972.8 ±1.18%

A SUPPLEMENTARY MEASUREMENTS
Table 2 shows the detailed results for our rollback latency measure-
ments for Memcached. The Rollback latency column gives the mean
latency in µs over 1000 rollback iterations and the σ column the
standard deviation. We measured both the rollback that destroys
the offending domain but leaves the contents of its memory intact
and a version of the rollback that "scrubs" (zeroes) the full contents
of domain memory before it can be re-allocated, as indicated in
the Zeroing of domain data column. The latter estimates the upper
bound for maintaining confidentiality guarantees for nested domains
using a 4GB heap pool and 4MB domain stack thats store sensitive
information as discussed in Section 7. As rollbacks are exceptional
events, we deem the 0.2s latency reasonable for use cases with
confidentiality requirements. The latency could be be reduced by
tracking and scrubbing only allocations that contain sensitive data,
or reducing the reserved memory confidential domains.

Table 3 shows the detailed results of our memory consumption
measurements. The Maximum resident set size column reports the
mean maximum resident size (RSS) reported by the Bash shell
builtin time command over five iterations of the YCSB benchmark
loading phase for the unmodified baseline (Baseline) and Mem-
cached equipped with SDRoB (SDRoB). The columns marked σ
give the relative standard deviation of the RSS. We used used four
worker threads for this experiment as indicated in the #Thr column.
Table 4 shows the detailed result of our throughput measurements
of the YCSB benchmark for Memcached using different numbers of
threads (#Thr) that were summarized in Section 5.2. The Through-
put column gives the throughput in operations / seconds of three
versions of Memcached: 1) The unmodified baseline (Baseline),
2) Memcached using the TLSF allocator (TLSF), and 3) Memcached
equipped with SDRoB (SDRoB). The columns marked σ give the
relative standard deviation of the throughput over ten benchmark
runs as percentage for the aforementioned versions. The Throughput
degradation column gives the degradation of throughput in percent-
age of (a) Memcached using the TLSF allocator compared to the
baseline (TLSF/Baseline), (b) Memcached equipped with SDRoB
compared to Memcached using the TLSF allocator (SDRoB/TLSF),
and (c) Memcached equipped with SDRoB compared to baseline
(SDRoB/Baseline).

Table 4: Detailed table of throughput measurements

#Thr

1
2
4
8

1
2
4
8

Throughput (ops/sec)

Baseline

σ

TLSF

σ

SDRoB

σ

Loading Phase
78670 ±0.65%
84223 ±0.38% 84093 ±0.62%
117062 ±0.53% 116802 ±0.29% 111898 ±0.24%
158243 ±0.33% 157716 ±1.11% 153488 ±0.51%
162210 ±0.61% 161221 ±1.09% 160378 ±0.79%
Running Phase
93328 ±0.46%
100719 ±0.42% 100332 ±0.31%
156458 ±0.45% 156256 ±0.50% 148779 ±0.28%
226251 ±0.38% 224673 ±1.01% 217911 ±0.48%
237928 ±0.50% 237426 ±0.46% 233896 ±0.40%

Throughput degradation (%)
TLSF/Baseline SDRoB/TLSF SDRoB/Baseline

-0.15%
-0.22%
-0.33%
-0.60%

-0.38%
-0.12%
-0.69%
-0.21%

-6.44%
-4.19%
-2.68%
-0.52%

-6.98%
-4.78%
-3.00%
-1.48%

-6.59%
-4.41%
-3.00%
-1.12%

-7.33%
-4.90%
-3.68%
-1.69%

17

B OPENSSL EXAMPLE

1 int gcm_encrypt (...)
2 {
3

EVP_CIPHER_CTX * ctx ;
int len ;
int ciphertext_len ;

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60

61

62
63 }

/* Creating a persistent domain for OpenSSL */
if( sdrob_init ( OPENSSL_UDI , SDROB_EXECUTION_DOMAIN | SDROB_ISOLATED_DOMAIN | SDROB_RETURN_TO_CURRENT ) !=
SDROB_SUCCESSFUL_RETURNED )

handleErrors (); /* On an abnormal domain exit of OpenSSL domain , alternative action can be taken ,

/* Creating a data domain shared between current domain and
if( sdrob_init ( OPENSSL_DATA_UDI , SDROB_DATA_DOMAIN ) != SDROB_SUCCESSFUL_RETURNED ){

OpenSSL domain */

* i.e return the caller */

sdrob_destroy ( OPENSSL_UDI , SDROB_NO_HEAP_MERGE ) /* If the shared domain initialization fails , don 't continue ,

* OpenSSL domain is destroyed */

handleErrors ();

}
/* Grant access of data domain to domain OpenSSL */
if( sdrob_dprotect ( OPENSSL_UDI , OPENSSL_DATA_UDI , WRITE_ENABLE | READ_ENABLE ) != SDROB_SUCCESSFUL_RETURNED ){

sdrob_destroy ( OPENSSL_UDI , SDROB_NO_HEAP_MERGE ); /* If granting shared domain access to OpenSSL fails , don 't

continue ,

* OpenSSL domain and shared data domain is destroyed */

sdrob_destroy ( OPENSSL_DATA_UDI , SDROB_NO_HEAP_MERGE )

}

/* Create and initialize the context */
if (!( ctx = EVP_CIPHER_CTX_new ()))

handleErrors ();

/* Initialize the encryption operation . */
if (1 != EVP_EncryptInit_ex (ctx , EVP_aes_256_gcm () , NULL , NULL , NULL ))

handleErrors ();

/* Set IV length if default 12 bytes (96 bits ) is not appropriate */
if (1 != EVP_CIPHER_CTX_ctrl (ctx , EVP_CTRL_GCM_SET_IVLEN , iv_len , NULL ))

handleErrors ();

/* Initialize key and IV */
if (1 != EVP_EncryptInit_ex (ctx , NULL , NULL , key , iv))

handleErrors ();

/* Provide any AAD data . This can be called zero or more times as required */
if (1 != EVP_EncryptUpdate (ctx , NULL , &len , aad , aad_len ))

handleErrors ();

/* Provide the message to be encrypted , and obtain the encrypted output .

* EVP_EncryptUpdate can be called multiple times if necessary */

if (1 != EVP_EncryptUpdate (ctx , ciphertext , &len , plaintext , plaintext_len ))

handleErrors ();

ciphertext_len = len ;

/* Finalize the encryption . Normally ciphertext bytes may be written at

* this stage , but this does not occur in GCM mode */

if (1 != EVP_EncryptFinal_ex (ctx , ciphertext + len , & len ))

handleErrors ();
ciphertext_len += len ;

/* Get the tag */
if (1 != EVP_CIPHER_CTX_ctrl (ctx , EVP_CTRL_GCM_GET_TAG , 16 , tag ))

handleErrors ();

/* Clean up */
EVP_CIPHER_CTX_free ( ctx );
return ciphertext_len ;

Listing 7: gcm_encrypt() is an example of an OpenSSL caller function taken from https://wiki.openssl.org/index.php/EVP_Authenticated_Encryption_and_
Decryption. Lines 7–22 have been added to initialize the rollback functionality. The call to the EVP functions have been wrapped to execute in domain
OPENSSL_UDI.

18

