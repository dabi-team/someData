2
2
0
2

y
a
M
7

]
E
S
.
s
c
[

1
v
8
2
6
3
0
.
5
0
2
2
:
v
i
X
r
a

PRESTO: Predicting System-level Disruptions through
Parametric Model Checking

Xinwei Fang
Department of Computer Science
University of York, York, UK
xinwei.fang@york.ac.uk

Colin Paterson
Department of Computer Science
University of York, York, UK
colin.paterson@york.ac.uk

Radu Calinescu
Department of Computer Science
University of York, York, UK
radu.calinescu@york.ac.uk

Julie Wilson
Department of Mathematics
University of York, York, UK
julie.wilson@york.ac.uk

ABSTRACT
Self-adaptive systems are expected to mitigate disruptions by con-
tinually adjusting their configuration and behaviour. This mitiga-
tion is often reactive. Typically, environmental or internal changes
trigger a system response only after a violation of the system re-
quirements. Despite a broad agreement that prevention is better
than cure in self-adaptation, proactive adaptation methods are
underrepresented within the repertoire of solutions available to
the developers of self-adaptive systems. To address this gap, we
present a work-in-progress approach for the prediction of system-
level disruptions (PRESTO) through parametric model checking.
Intended for use in the analysis step of the MAPE-K (Monitor-
Analyse-Plan-Execute over a shared Knowledge) feedback control
loop of self-adaptive systems, PRESTO comprises two stages. First,
time-series analysis is applied to monitoring data in order to iden-
tify trends in the values of individual system and/or environment
parameters. Next, future non-functional requirement violations are
predicted by using parametric model checking, in order to establish
the potential impact of these trends on the reliability and perfor-
mance of the system. We illustrate the application of PRESTO in a
case study from the autonomous farming domain.

KEYWORDS
self-adaptive system, proactive adaptation, parametric model check-
ing, non-functional requirements, system verification

1 INTRODUCTION
Self-adaptive systems are expected to mitigate disruptions in com-
plex and uncertain environments by continually analysing, evalu-
ating and adjusting their configurations. To achieve this, their be-
haviours and operating environments need to be modelled and anal-
ysed, often using stochastic models such as queueing networks [19],
Markov models [20, 31] and stochastic Petri nets [5]. These models
are continually updated to reflect changes observed through mon-
itoring, and used to re-verify compliance with the requirements
when needed. In this work, we focus on the use of discrete-time
Markov chains (DTMCs) for such purpose and consider disruptions
as violations of system-level requirements.

Proactive adaptations that make decisions before disruptions
occur have a number of advantages over traditional reactive adap-
tations, especially when associated with cost [32] or latency [29].

However, many proactive adaptations are triggered by the changes
of system parameters rather than the anticipated violation of system-
level properties [1, 25]. Due to the complexity and non-linearity of
system processes, the impact at system-level caused by these low-
level changes may not be obvious. For example, large changes in
system parameters not necessarily lead to the violation of require-
ments but small ones may [18]. Therefore, adaptation decisions
triggered by changes in system parameters may result in over or
under adaptations.

Fortunately, recent advances in the analysis of parametric discrete-
time Markov chains allow the efficient verification of system-level
requirements using runtime observations of system parameters [9,
15, 22]. Additionally, a growing collection of methods for online
learning the parameters of these models ensures that underlying
changes or trends in these parameters can be successfully cap-
tured [10, 17, 38]. Finally, advances in data analysis allow the confi-
dent prediction of observed parameters [1, 26, 27]. Combining these
methods can enable self-adaptive systems to predict and prevent
disruptions before they happen.

Our paper introduces a work-in-progress approach for the predic-
tion of system-level disruptions (PRESTO) through parametric
model checking. PRESTO is intended for use in the analysis step of
the MAPE-K (Monitor-Analyse-Plan-Execute over a shared Knowl-
edge) feedback control loop [3, 8] of self-adaptive systems. PRESTO
allows adaptation decisions to be made based on predicted system-
level requirement violations due to degradation in system and/or
environmental parameters—a common phenomenon in real-world
applications [34, 35] that is underexplored by current research into
self-adaptive systems. PRESTO can work in conjunction with meth-
ods that mitigate other types of disruptions in self-adaptive systems,
e.g., sudden requirement violations due to step changes in system
and/or environment parameter values [16, 38].

The rest of paper is structured as follows. In Section 2, we pro-
vide a formal definition for Markov models and how to define and
evaluate system-level properties. Section 3 gives a running example
that will be used throughout this paper. We present PRESTO and
its preliminary evaluation in Section 4 and 5, respectively, followed
by related work on proactive adaptation in Section 6. Lastly, we
conclude the paper with a brief summary in Section 7.

 
 
 
 
 
 
SEAMS 2022, May 21–29, 2022, Pittsburgh, PA, USA

Xinwei Fang, Radu Calinescu, Colin Paterson, and Julie Wilson

2 PRELIMINARIES
Discrete-time Markov chains (DTMCs) are finite state-transition
systems comprising states associated with relevant configurations
of a system under analysis, and probabilistic state transitions that
model the stochastic behaviour of that system.

Definition 2.1. A discrete-time Markov chain over a set of atomic

propositions AP is a tuple

𝐷 = (𝑆, 𝑠𝑖𝑛𝑖𝑡 , 𝑀, 𝐿),
(1)
where 𝑆 ≠ ∅ is a finite set of states; 𝑠𝑖𝑛𝑖𝑡 ∈ 𝑆 is the initial state;
𝑀 : 𝑆 × 𝑆 → [0, 1] is a transition probability matrix such that, for
any pair of states 𝑠, 𝑠 ′ ∈ 𝑆, 𝑀 (𝑠, 𝑠 ′) provides a value indicating the
probability of transitioning from 𝑠 to 𝑠 ′, and (cid:205)𝑠′ ∈𝑆 𝑀 (𝑠, 𝑠 ′) = 1 for
any 𝑠 ∈ 𝑆; 𝐿 : 𝑆 → 2AP is a labelling function that maps every state
𝑠 ∈ 𝑆 to the atomic propositions from AP that hold in that state.

A reward can be assigned to states to extend the range of non-
functional properties that can be analysed.

Definition 2.2. A reward structure over a discrete-time Markov

chain (1) is a function

rwd : 𝑆 → R≥0

(2)

that associates non-negative values with the DTMC states.

Parametric discrete-time Markov chains (pDTMCs) can be utilised
for the analysis of reward-augmented DTMCs with unknown prob-
abilities and/or rewards.

Definition 2.3. A parametric discrete-time Markov chain (pDTMC)
is a discrete-time Markov chain (1), with or without a set of reward
functions (2), that includes transition probabilities 𝑃 (𝑠, 𝑠 ′) and/or
rewards specified as rational functions over a set of real-valued
parameters.

Probabilistic computation tree logic (PCTL) [2, 7, 21] is a prob-
abilistic variant of temporal logic used to specify the properties of
DTMCs.

Definition 2.4. A PCTL state formula Φ, path formula Ψ, and
reward state formula ΦR over an atomic proposition set AP are
defined by:

(3)

(4)

Φ ::= 𝑡𝑟𝑢𝑒 | 𝑎 | ¬Φ | Φ ∧ Φ | P=? [Ψ]
Ψ ::= XΦ | Φ U≤𝑘 Φ| Φ U Φ
[I=𝑘 ] | Rrwd
=?

[C≤𝑘 ] | Rrwd
=?

R := Rrwd
Φ:
=?

(5)
where 𝑎 ∈ 𝐴𝑃 is an atomic proposition, 𝑘 ∈ N>0 is a timestep
bound, and rwd is a reward structure.

[F Φ] | Rrwd
=?

[S]

The PCTL semantics is defined using a satisfaction relation |=
𝐷 (𝑠) of a DTMC. Thus, 𝑠 |=
over the states 𝑠 ∈ 𝑆 and paths 𝜋 ∈ Paths
Φ means “Φ holds in state 𝑠”, 𝜋 |= Ψ means “Ψ holds for path 𝜋”, and
we have: 𝑠 |= 𝑡𝑟𝑢𝑒 for all states 𝑠 ∈ 𝑆; 𝑠 |= 𝑎 iff 𝑎 ∈ 𝐿(𝑠);𝑠 |= ¬Φ iff
¬(𝑠 |= Φ); 𝑠 |= Φ1 ∧ Φ2 iff 𝑠 |= Φ1 and 𝑠 |= Φ2. The quantitative state
𝐷(𝑠)
formula P=? [Ψ] specifies the probability that paths from Paths
satisfy the path property Ψ. Reachability properties P=? [true U Φ]
are equivalently written as P=? [F Φ] or P=? [F 𝑅], where 𝑅 ⊆ 𝑆 is the
set of states in which Φ holds. The next formula 𝑋 Φ holds if Φ is
satisfied in the next state of the analysed path 𝜋. The time-bounded

Figure 1: pDTMC model of autonomous fruit-picking pro-
cess

until formula Φ1 U≤𝑘 Φ2 holds for a path 𝜋 iff 𝜋 (𝑖) |= Φ2 for some
𝑖 ≤ 𝑘 and 𝜋 ( 𝑗) |= Φ1 for all 𝑗 = 1, 2, . . . , 𝑖 − 1. The unbounded until
formula Φ1 U Φ2 removes the bound 𝑘 from the time-bounded until
formula. Finally, the reward state formulae specify the expected
[I=𝑘 ]); the
values for: the instantaneous reward at timestep 𝑘 (Rrwd
=?
[C≤𝑘 ]); the reachability
cumulative reward up to timestep 𝑘 (Rrwd
=?
reward cumulated until reaching a state that satisfies a property
Φ (Rrwd
[F Φ]); The steady-state reward in the long run (Rrwd
[S]).
=?
=?
For detailed descriptions of the PCTL semantics, see [2, 7, 21].

Parametric model checking (PMC) [13] is a mathematically
based technique for the verification of PCTL-encoded pDTMC prop-
erties. Supported by probabilistic model checkers such as PRISM [23]
and Storm [14], the technique yields rational functions (i.e., a quo-
tients between two polynomials with respect to the parameters) for
the analysed PCTL property. These functions, which we term PMC
expressions in the remainder of the paper, can be efficiently evalu-
ated by a self-adaptive system at runtime, when the value of the
pDTMC parameters are observed through the MAPE-K monitoring.

3 MOTIVATING EXAMPLE
We motivate PRESTO and demonstrate its effectiveness for a fruit-
picking robot from the autonomous farming domain. Our example,
inspired by recent development in this domain [36, 37], assumes
that the robot needs to perform three operations autonomously:
(1) position itself in the right location for the fruit picking; (2) use
its arm to pick up the fruit; and (3) when operation 2 is unsuccessful,
decide whether to retry the fruit picking from operation 1 or to
give up. Fig. 1 shows the pDTMC model of this process. The robot
begins with positioning itself next to a piece of fruit (state 𝑠0). The
positioning operation may succeed, in which case the robot moves
to state 𝑠1, where it attempts picking, or may fail, in which case
the picking will be abandoned (𝑠3) and the process finishes (𝑠5).
The process also finishes when the picking is successful (𝑠4). If the
picking is unsuccessful, the robot enters the decision state (𝑠2) from
where it needs to decide whether to re-position itself and retry the
entire process, or to abandon picking this fruit (𝑠3) and end the
process (𝑠5).

positioningpickingpicking abandonedpickingsuccessdonedecisiont1e1t0e0t2e2PRESTO: Predicting System-level Disruptions through Parametric Model Checking

SEAMS 2022, May 21–29, 2022, Pittsburgh, PA, USA

Table 1: System-level requirements, related properties, and the result of parametric model checking for the properties

R1

R2

R3

Informal description

The robot shall complete the fruit picking successfully
with probability of at least 0.8

Property to check (PCTL)
P=? [F “picking success”] ≥ 0.8

PMC expressions†
(𝛼 ∗𝑝1∗𝛽 ∗𝑝2+ (−1) ∗𝛼 ∗𝑝1)/(𝛼 ∗𝑝1∗𝛽 ∗𝑝2∗𝑝3+ (−1))

The expected time to complete the picking process
shall not exceed 30 seconds.

R“time”
=?

[F]“done" ] ≤ 30𝑠

(−1 ∗ (𝛼 ∗ 𝑝1 ∗ 𝛽 ∗ 𝑝2 ∗ 𝑡 3 + 𝑡 1 + 𝛼 ∗ 𝑝1 ∗ 𝑡 2))/(𝛼 ∗
𝑝1 ∗ 𝛽 ∗ 𝑝2 ∗ 𝑝3 + (−1))

The expected energy consumption to complete the
picking process shall not exceed 10 joules.

R“energy”
=?

[F]“done" ] ≤ 10𝐽

(−1 ∗ (𝛼 ∗ 𝑝1 ∗ 𝛽 ∗ 𝑝2 ∗ 𝑒3 + 𝑒1 + 𝛼 ∗ 𝑝1 ∗ 𝑒2))/(𝛼 ∗
𝑝1 ∗ 𝛽 ∗ 𝑝2 ∗ 𝑝3 + (−1))

†

PMC expressions were returned from the model checker Storm [14] by providing the pDTMC and the property specified in PRISM language [23] and PCTL respectively.

As shown in Fig. 1, the outgoing transition probabilities from
states 𝑠0, 𝑠1 and 𝑠2 are defined in terms of several system parame-
ters. Out of these parameters, we assume that 𝑝1, 𝑝2 and 𝑝3 have
predefined, domain-specific values. For instance, 𝑝1 is the probabil-
ity of successful positioning when the robot is in perfect working
condition. In contrast, 𝛼, 𝛽 ∈ (0, 1] represent coefficients that re-
flect the robot degradation from its perfect working condition, e.g.
due to wear and tear. We assume that 𝛼 and 𝛽 are unknown, and
their values need to be obtained through monitoring [24] or via
self-testing [30].

Additionally, the pDTMC is annotated with two reward functions
(depicted in rectangular boxes linked to states 𝑠0, 𝑠1 and 𝑠2 from
Fig. 1). First, a “time” reward function associates mean operation
execution times 𝑡0, 𝑡1 and 𝑡2 with the three operations performed by
the robot. Similarly, an “energy” reward function associates mean
energy consumptions 𝑒0, 𝑒1 and 𝑒2 with the same operations. We
assume that the values of 𝑡𝑖 and 𝑒𝑖 , 0 ≤ 𝑖 ≤ 2, are unknown and
need to be obtained through monitoring.

Finally, we assume that the autonomous robot has to satisfy the

three system-level requirements shown in Table 1.

4 PRESTO APPROACH
The PRESTO analysis process, depicted in Fig. 2, takes as input
a pDTMC model of the self-adaptive system’s behaviour, a set of
PCTL-encoded system requirements, a prediction horizon ℎ > 0, and

runtime observations of the unknown system and/or environment
parameters that appear in the pDTMC. The first three inputs are
provided, at design time, by system engineers and domain experts,
whereas the runtime observations are obtained from the monitoring
component of the MAPE-K control loop.

Given these inputs, PRESTO predicts violation of the system-
level requirements within the prediction horizon ℎ. To that end, our
approach first uses a parametric verification engine to obtain PMC
expressions for the PCTL properties associated with the system re-
quirements. Typically, this is a one-off step executed at design time;
however, PRESTO also allows the run-time execution of this step,
if needed because the model structure and/or the system require-
ments change in operation. The PMC expressions are then used at
runtime, to continually assess the impact of predicted parameter
changes on the system-level requirements. In this step, PRESTO
uses recent observations of the parameter values to predict the
parameter future values within the prediction horizon. These pre-
dicted parameter values are then “propagated” through the PMC
expressions (i.e., they are used to evaluate the PMC expressions)
in order to predict the future values of the nonfunctional prop-
erties from the system requirements, and thus to predict future
requirement violations.

Figure 2: PRESTO analysis process and architecture

design time or runtimeruntimeInputPRESTO MAPE-K analysisOutputParametricMarkov chainPCTLrequirementsPredictionhorizonVerification  manager Parametricverification engine [Storm] 1. obtain PMC expressionTime-seriesprediction engine[ARIMA] 2. predict parametersObservations ofparametersKnowledge in  MAPE-K  (from engineers  and  domain experts)Monitoring in MAPE-K  (from sensors) Predictedrequirementviolation'Now'SEAMS 2022, May 21–29, 2022, Pittsburgh, PA, USA

Xinwei Fang, Radu Calinescu, Colin Paterson, and Julie Wilson

5 EVALUATION
A prototype of PRESTO was implemented to aid evaluation and
answer the following research questions:

RQ1 Can PRESTO predict the violation of system-level disrup-
tions and how does it perform in terms of prediction errors?
RQ2 How does the noise level in model parameters affect PRESTO’s

prediction performance?

RQ3 How can we utilise PRESTO for proactive adaptation?

The prototype and a simple simulator of the autonomous robot
from our motivating example were implemented in Java, using a
modular design as shown in Fig. 2. The modular design enables: 1)
technologies used in this version of PRESTO to be replaced with
alternatives if deemed more suitable for a given application and 2)
additional technologies can be integrated to extend the functionality
or to improve efficiency. This early version of PRESTO uses the
following technologies:

• The parametric verification engine uses Storm [14], one of the
leading parametric model checkers, in the background. As an
alternative, fPMC [15] is worth exploring, especially when the
system under analysis is complex and with many parameters.
• The time-series prediction engine uses ARIMA (Autoregressive
Integrated Moving Average), one of the most widely used meth-
ods for time-series prediction, also invoked in the background.
Numerous alternative prediction methods could be substituted
for this module depending on requirements.

In our evaluation, we assigned values 𝑝1 = 0.95, 𝑝2 = 0.2 and
𝑝3 = 0.95, and gave ranges and trends for the other parameters
as shown in Table 3. The range and value of model parameters
were selected to ensure that the system-level properties would
vary around the requirement, but can be based on prior knowledge
in practice. Calculations were performed on a Macbook Pro with
2.3GHz Quad-core i7 CPU and 32 GB of RAM and all “monitored”
parameters were updated every minute with a prediction horizon
set for 240 minutes.
RQ1: To answer this research question, we predicted the viola-
tion of a system-level requirement by propagating the predicted

parameters within the prediction horizon via the PMC expressions
presented in Table 1. We first present one experiment in detail for
illustration of the prediction results, and then we analyse the result
from a large set of experiments. The detailed results are shown
in Fig. 3 where the x-axis shows the time in hours and the y-axis
indicates the system-level property, for example, in Fig. 3a, the
probability of completing the process with picking being successful.
The bound from the requirement is shown as an orange dashed
line. The ground truth for the system-level property is plotted as a
solid blue line with predicted values as a dotted red line. The predic-
tion horizon is highlighted in green with zero hours indicating the
start. It can be seen that PRESTO is able to predict the violation of
system-level requirements if there is any (R1 and R2), and predict
the trend of the system level property if no violation is occurred
within the prediction horizon (R3). The deterministic values of each
monitored parameter at different time point are presented in Table 2
to show the tends. We evaluate the performance of PRESTO further
by repeating the above experiment for 3000 times with randomly
generated trends according to the specifications shown in Table 3.
For each experiment, we randomly chose two values that within the
specified range for each parameter, and generated a set of values(600
value points for each parameters) that vary randomly between the
two values. The unique trends of each parameter was created by
sorting the value set in a descending or ascending order according
to the specification in Table 3. The first 360 values were used for
parameter analysis and the last 240 values were used as the ground
truth of prediction horizon. This evaluation can synthesise a large
number of scenarios, including the violation of requirements before
the prediction (1761 cases for R1, 1600 cases for R2, and 2209 cases
for R3 out of 3000), violation of requirement within the prediction
horizon (488 for R1, 715 for R2,and 501 for R3), and no violation
of requirements during the period of analysis (751 for R1, 685 for
R2, and 290 for R3), to minimise the impact of stochasticity in the
experiments. The overall time span for a single run including pre-
diction of time-series and evaluating the result is under one second,
and the violation requirements can be observed uniformly across
the prediction horizon. It is worth noting that during the 3000 runs
of evaluating all three requirements, we did not observe any false

(a) 𝑅1

(b) 𝑅2

(c) 𝑅3

Figure 3: Prediction of system-level properties and potential disruptions for the properties listed in Table 1, the actual dis-
ruptions happen at 89-min (R1) and 105-min(R2) in contrast to the predicted disruptions are at 97-min(R1) and 115-min(R2),
respectively

01h2h3h4hTime in hours0.750.80.850.90.95System-level propertyActualPredictedRequirementTime "NOW"PredictionHorizon01h2h3h4hTime in hours10152025303540System-level propertyActualPredictedRequirementTime "NOW"PredictionHorizon01h2h3h4hTime in hours4681012System-level propertyActualPredictedRequirementTime "NOW"PredictionHorizonPRESTO: Predicting System-level Disruptions through Parametric Model Checking

SEAMS 2022, May 21–29, 2022, Pittsburgh, PA, USA

(a) 𝑅1

(b) 𝑅2

(c) 𝑅3

Figure 4: Errors of predicting violation of requirements collected from experiments that have violation of requirements within
the prediction horizon

(a) 𝑅1

(b) 𝑅2

(c) 𝑅3

Figure 5: Changes of error distributions as the results of noise level in parameters

(a) 𝑅1

(b) 𝑅2

(c) 𝑅3

Figure 6: Percentage of undesired cases as a function of 𝜏 (out of 488 cases for R1, 715 for R2, and 501 for R3)

positives (i.e., the prediction of a violation when one does not occur
within the prediction horizon) or false negatives (i.e., a violation
within the prediction horizon that was not predicted), which can
be due to the combination effect of parameter trends, prediction
horizon, and model structure. The violation of requirements before
the prediction can be addressed by a reactive adaption method [10]
which is not in the scope of this work. We evaluated prediction
errors, calculated as the difference in time between the predicted
and actual violation of the requirement, for those experiments that
have violation of requirement within the prediction horizon. The
histograms together with fitted distributions are shown in Fig. 4.
Our preliminary results show the prediction errors are normally
distributed with mean values between -0.6 and 0.47 minutes (for R2
and R3 respectively), showing no real bias. The standard deviations

Table 2: Deterministic parameter values at three time points

𝛼

𝛽

0.98

0.88

0.80

0.01

0.12

0.19

𝑡0

1.04

11.6

19.8

𝑡1

𝑡2

10.01

8.90

14.6

17.9

11.6

13.9

𝑒0

3.30

4.03

4.49

𝑒1

2.40

2.77

2.99

𝑒2

0.30

2.84

4.49

now-360

now

now+240

of between 7.91 (for R3) and 11.4 (for R1) suggest that PRESTO is
likely to predict system-level disruptions accurately.

RQ2: To evaluate the impact of noise on the prediction of disrup-
tions, we added different levels of noise to the generated parameter
trends using normal distributions with zero mean but different
standard deviations as shown in Table 4. The maximum value of
𝛼 and 𝛽 are capped to one, and the minimum values for 𝑡1, 𝑡2𝑎𝑛𝑑𝑡3

Mean = -0.082Std = 11.40-2002040errors in minute10203040506070number of countMean = -0.60Std = 10.24-40-2002040errors in minute050100150number of countMean = 0.47Std = 7.91-20-100102030errors in minute020406080100120number of count-1000100200300erros in minutes00.0050.010.0150.020.025probabilitylevel 0level 2level 4level 6level 8level 10-1000100200300erros in minutes00.010.020.030.040.05probabilitylevel 0level 2level 4level 6level 8level 10-1000100200300erros in minutes00.010.020.03probabilitylevel 0level 2level 4level 6level 8level 10050100150200= (minutes)0%50%100%Percentage050100150200= (minutes)0%50%100%Percentage050100150200= (minutes)0%50%100%PercentageSEAMS 2022, May 21–29, 2022, Pittsburgh, PA, USA

Xinwei Fang, Radu Calinescu, Colin Paterson, and Julie Wilson

Table 3: Ranges and trends for the model parameters

𝛼

𝛽

𝑡0, 𝑡1, 𝑡2

𝑒0, 𝑒1, 𝑒2

range

[0.7,0.99]

[0.01, 0.2]

[1s, 30s]

[0.3J, 4.5J]

trend

constant or mono-
tonically increasing

constant or monotonically decreasing

Table 4: Standard deviations of noise levels from RQ3

level 0

level 2

level 4

level 6

level 8

level 10

𝛼, 𝛽
𝑡0, 𝑡1, 𝑡2
𝑒0, 𝑒1, 𝑒2

0

0

0

0.02

0.04

0.06

0.08

2

0.6

4

1.2

6

1.8

8

2.4

0.1

10

3

and 𝑒1, 𝑒2, 𝑎𝑛𝑑𝑒3 are set to be 1s and 0.3J, respectively. The experi-
ment was repeated 1000 times for each noise level to obtain their
distributions as shown in Fig. 5. The distribution with zero mean
(in blue), observed in all three cases, is obtained using trends with
no added noise (level 0) and provides a baseline. As noise is added,
the mean error shifts to the right due to noise spikes violating the
requirement before the predicted value, which only considers viola-
tions caused by the underlying trend, here increasing or decreasing
monotonically. The noise level also impacts the error variance, be-
coming larger as the noise level increases. These early stage results
suggest PRESTO may be sensitive to noise, and that the integration
of a de-noising module could be worthwhile.
RQ3: While our preliminary evaluation does not cover the end-
to-end use of PRESTO within the MAPE-K loop of self-adaptive
systems, we suggest how PRESTO predictions can be exploited by
the planning step of the MAPE-K loop. It is clear that adaptation
decisions need to be triggered at an appropriate time. In our ex-
ample, the robot can trigger the decision any time between now
and predicted violation of requirements. We use a user specified
variable, 𝜏, to determine the time to trigger the adaptation decision
as max(now,(𝑡𝑝 − 𝜏)), where 𝑡𝑝 is the predicted time that the viola-
tion will occur. If 𝜏 is too large, the value (𝑡𝑝 − 𝜏) could represent
a time point in the past, in which case, the robot would need to
make a reactive adaptation at now, possibly generating additional
adaptation cost. In addition, a large value of 𝜏 could lead to frequent
unnecessary adaptations that affect the performance of the robot.
On the other hand, if 𝜏 is too small, particularly when smaller than
the prediction errors, the violation is more likely to happen before
being predicted, resulting in high cost from recovery. To facilitate
the selection of 𝜏, we illustrate the impact of this parameter in terms
of the percentage of undesired cases out of 488 for R1, 715 for R2 and
501 for R3 that could occur using the same experimental data used
for RQ1 (Fig. 6). Here (𝑡𝑝 − 𝜏) ≤ 60𝑚𝑖𝑛 is considered too large and
𝜏 < 𝑎𝑏𝑠 (𝑡𝑝 − 𝑡𝑟𝑒 𝑓 ) is considered too small, where 𝑡𝑟𝑒 𝑓 is the time
of the actual violation of the requirement. The three plots in Fig. 6
show a consistent trend in that the number of undesirable cases is
extremely high (up to 100%) when 𝜏 is either close to zero or close
to its maximum value. Our results show that 𝜏 has a sweet spot
around 30-min as the percentage of undesired cases goes down as
low as 50%. However, if the violation of requirements is associated
with a significant cost, a slightly larger 𝜏 is preferred.

6 RELATED WORK
Self-adaptive systems can proactively or reactively adapt to changes [6].
While both adaptation techniques have shown good results in han-
dling changes and uncertainties [4], proactive adaptation is par-
ticularly important when restoring compliance with requirements
after they were violated incurs high costs [32] or latency [29].

Proactive adaptation relies on the prediction of current execu-
tion and environmental parameters to identify potential violations
and to apply adaptations before these violations occur. While some
research in this area concentrated on the improvement of predic-
tion accuracy [12, 27, 28], others investigated possible limitations,
such as the trade-off between early prediction and accuracy [26],
the impact of adaptation latency [11] and the impact of limited
computational resources [33].

Related to PRESTO, the research from [29] integrates probabilis-
tic model checking within a latency-aware proactive adaptation
method to determine the best adaptation strategy. The resulting
method allows optimal adaptation decisions to be made over the
prediction horizon with consideration of the stochastic behaviour of
the environment. While this method can be applied at runtime, the
entire model needs to be updated when the changes are observed.
In contrast, our approach utilises parametric model checking, in
which the same PMC expression can be re-used, with only its re-
evaluation for new parameter values is required at runtime.

7 CONCLUSION
We have presented a new approach for the prediction of system-
level disruptions (PRESTO) which is intended both for use in the
analysis step and to support the planning step in the MAPE-K loop.
PRESTO uses parametric model checking to establish functional re-
lationships between system and/or environmental parameters and
the system-level property. Time-series analysis is used to identify
trends in the parameters from which values can be predicted and
then propagated via the PMC expressions to assess their impact
on system-level properties and to identify potential disruptions.
Our preliminary evaluation suggests that PRESTO can accurately
predict the system-level disruptions with no false positives or false
negatives observed in our experiments.

The benefit of a modular architecture means that the techniques
used in PRESTO can be substituted with alternatives according to
needs and new technologies can be added to extend functionality.
We plan to integrate a de-noising module in future work as eval-
uation showed noise to have significant impact on the prediction
results. Furthermore, more detailed evaluations need to be carried
out with different pDTMCs and parameter trends to identify the
limitations of PRESTO.

ACKNOWLEDGEMENT
This project funded by the UKRI project EP/V026747/1 ‘Trustworthy
Autonomous Systems Node in Resilience’.

PRESTO: Predicting System-level Disruptions through Parametric Model Checking

SEAMS 2022, May 21–29, 2022, Pittsburgh, PA, USA

(QEST), pages 404–420, 2014.

[23] M. Kwiatkowska, G. Norman, and D. Parker. PRISM 4.0: Verification of proba-
bilistic real-time systems. In 23rd International Conference on Computer Aided
Verification (CAV), pages 585–591, 2011.

[24] Guozhi Li, Fuhai Zhang, Yili Fu, and Shuguo Wang. Joint stiffness identification
and deformation compensation of serial robots based on dual quaternion algebra.
Applied Sciences, 9(1):65, 2019.

[25] Andreas Metzger, Rod Franklin, and Yagil Engel. Predictive monitoring of het-
erogeneous service-oriented business networks: The transport and logistics case.
In 2012 Annual SRII Global Conference, pages 313–322. IEEE, 2012.

[26] Andreas Metzger, Tristan Kley, and Alexander Palm. Triggering proactive busi-
In International

ness process adaptations via online reinforcement learning.
Conference on Business Process Management, pages 273–290. Springer, 2020.
[27] Andreas Metzger, Adrian Neubauer, Philipp Bohn, and Klaus Pohl. Proactive
process adaptation using deep learning ensembles. In International Conference
on Advanced Information Systems Engineering, pages 547–562. Springer, 2019.

[28] Andreas Metzger, Christian Reinartz, and Klaus Pohl. Incremental verification
of complex event processing applications for system monitoring. In 2018 44th
Euromicro Conference on Software Engineering and Advanced Applications (SEAA),
pages 293–297. IEEE, 2018.

[29] Gabriel A Moreno, Javier Cámara, David Garlan, and Bradley Schmerl. Proactive
self-adaptation under uncertainty: a probabilistic model checking approach. In
Proceedings of the 2015 10th joint meeting on foundations of software engineering,
pages 1–12, 2015.

[30] Antonis Paschalis and Dimitris Gizopoulos. Effective software-based self-test
strategies for on-line periodic testing of embedded processors. IEEE Transactions
on Computer-aided design of integrated circuits and systems, 24(1):88–99, 2004.

[31] Colin Paterson and Radu Calinescu. Observation-enhanced QoS analysis of
component-based systems. IEEE Transactions on Software Engineering, 46(5):526–
548, 2018.

[32] Vahe Poladian, David Garlan, Mary Shaw, Mahadev Satyanarayanan, Bradley
Schmerl, and Joao Sousa. Leveraging resource prediction for anticipatory dy-
namic configuration. In First International Conference on Self-Adaptive and Self-
Organizing Systems (SASO 2007), pages 214–223. IEEE, 2007.

[33] Federico Quin, Danny Weyns, Thomas Bamelis, Sarpreet Singh Buttar, and Sam
Michiels. Efficient analysis of large adaptation spaces in self-adaptive systems
using machine learning. In 2019 IEEE/ACM 14th International Symposium on
Software Engineering for Adaptive and Self-Managing Systems (SEAMS), pages
1–12. IEEE, 2019.

[34] Matthew B Russell, Evan M King, Chadwick A Parrish, and Peng Wang. Sto-
chastic modeling for tracking and prediction of gradual and transient battery
performance degradation. Journal of Manufacturing Systems, 59:663–674, 2021.
[35] Chaitanya Sankavaram, Bharath Pattipati, Anuradha Kodali, Krishna Pattipati,
Mohammad Azam, Sachin Kumar, and Michael Pecht. Model-based and data-
driven prognosis of automotive and electronic systems. In 2009 IEEE International
Conference on Automation Science and Engineering, pages 96–101. IEEE, 2009.

[36] Nikolaus Wagner, Raymond Kirk, Marc Hanheide, Grzegorz Cielniak, et al. Effi-
cient and robust orientation estimation of strawberries for fruit picking applica-
tions. 2021.

[37] Ya Xiong, Yuanyue Ge, and Pål Johan From. An improved obstacle separation
method using deep learning for object detection and tracking in a hybrid visual
control loop for fruit picking in clusters. Computers and Electronics in Agriculture,
191:106508, 2021.

[38] Xingyu Zhao, Radu Calinescu, Simos Gerasimou, Valentin Robu, and David Flynn.
Interval change-point detection for runtime probabilistic model checking. In
2020 35th IEEE/ACM International Conference on Automated Software Engineering
(ASE), pages 163–174. IEEE, 2020.

REFERENCES
[1] Ayman Amin, Lars Grunske, and Alan Colman. An automated approach to
forecasting qos attributes based on linear and non-linear time series modeling.
In 2012 Proceedings of the 27th IEEE/ACM International Conference on Automated
Software Engineering, pages 130–139. IEEE, 2012.

[2] Suzana Andova, Holger Hermanns, and Joost-Pieter Katoen. Discrete-time re-
wards model-checked. In International Conference on Formal Modeling and Anal-
ysis of Timed Systems, pages 88–104. Springer, 2003.

[3] Paolo Arcaini, Elvinia Riccobene, and Patrizia Scandurra. Modeling and analyzing
mape-k feedback loops for self-adaptation. In 2015 IEEE/ACM 10th International
Symposium on Software Engineering for Adaptive and Self-Managing Systems,
pages 13–23. IEEE, 2015.

[4] Davide Arcelli. Exploiting queuing networks to model and assess the performance
of self-adaptive software systems: a survey. Procedia Computer Science, 170:498–
505, 2020.

[5] Simonetta Balsamo, Peter G Harrison, and Andrea Marin. Methodological con-
struction of product-form stochastic petri nets for performance evaluation. Jour-
nal of Systems and Software, 85(7):1520–1539, 2012.

[6] Matthias Becker, Markus Luckey, and Steffen Becker. Model-driven performance
engineering of self-adaptive systems: a survey. In Proceedings of the 8th inter-
national ACM SIGSOFT conference on Quality of Software Architectures, pages
117–122, 2012.

[7] Andrea Bianco and Luca de Alfaro. Model checking of probabilistic and nondeter-
ministic systems. In P. S. Thiagarajan, editor, Foundations of Software Technology
and Theoretical Computer Science, volume 1026 of LNCS, pages 499–513. Springer
Berlin Heidelberg, 1995.

[8] Yuriy Brun, Giovanna Di Marzo Serugendo, Cristina Gacek, Holger Giese, Holger
Kienle, Marin Litoiu, Hausi Müller, Mauro Pezzè, and Mary Shaw. Engineering
self-adaptive systems through feedback loops. In Software engineering for self-
adaptive systems, pages 48–70. Springer, 2009.

[9] R. Calinescu, C. A. Paterson, and K. Johnson. Efficient parametric model checking
using domain knowledge. IEEE Transactions on Software Engineering, PP:1–1,
2019.

[10] Radu Calinescu, Yasmin Rafiq, Kenneth Johnson, and Mehmet Emin Bakır. Adap-
tive model learning for continual verification of non-functional properties. In
Proceedings of the 5th ACM/SPEC international conference on Performance engi-
neering, pages 87–98, 2014.

[11] Javier Cámara, Gabriel A Moreno, and David Garlan. Stochastic game analysis
and latency awareness for proactive self-adaptation. In Proceedings of the 9th
International Symposium on Software Engineering for Adaptive and Self-Managing
Systems, pages 155–164, 2014.

[12] Javier Cámara, Henry Muccini, and Karthik Vaidhyanathan. Quantitative
verification-aided machine learning: A tandem approach for architecting self-
adaptive iot systems. In 2020 IEEE International Conference on Software Architec-
ture (ICSA), pages 11–22. IEEE, 2020.

[13] Conrado Daws. Symbolic and parametric model checking of discrete-time markov
chains. In International Colloquium on Theoretical Aspects of Computing, pages
280–294. Springer, 2004.

[14] Christian Dehnert, Sebastian Junges, Joost-Pieter Katoen, and Matthias Volk. A
storm is coming: A modern probabilistic model checker. In Rupak Majumdar
and Viktor Kunčak, editors, Computer Aided Verification, pages 592–600, Cham,
2017. Springer International Publishing.

[15] Xinwei Fang, Radu Calinescu, Simos Gerasimou, and Faisal Alhwikem. Fast
parametric model checking through model fragmentation. In Proceedings of the
43rd International Conference on Software Engineering (To appear ), 2021.
[16] Antonio Filieri, Carlo Ghezzi, and Giordano Tamburrelli. A formal approach to
adaptive software: continuous assurance of non-functional requirements. Formal
Aspects of Computing, 24(2):163–186, 2012.

[17] Antonio Filieri, Lars Grunske, and Alberto Leva. Lightweight adaptive filtering
for efficient learning and updating of probabilistic models. In 2015 IEEE/ACM 37th
IEEE International Conference on Software Engineering, volume 1, pages 200–211.
IEEE, 2015.

[18] Kathi Fisler, Shriram Krishnamurthi, Leo A Meyerovich, and Michael Carl
Tschantz. Verification and change-impact analysis of access-control policies.
In Proceedings of the 27th international conference on Software engineering, pages
196–205, 2005.

[19] G. Franks, T. Al-Omari, M. Woodside, O. Das, and S. Derisavi. Enhanced model-
ing and solution of layered queueing networks. IEEE Transactions on Software
Engineering, 35(2):148–161, 2009.

[20] Simos Gerasimou, Radu Calinescu, and Giordano Tamburrelli. Synthesis of
probabilistic models for quality-of-service software engineering. Automated
Software Engineering, 25(4):785–831, 2018.

[21] Hans Hansson and Bengt Jonsson. A logic for reasoning about time and reliability.

Formal Aspects of Computing, 6(5):512–535, September 1994.

[22] Nils Jansen, Florian Corzilius, Matthias Volk, Ralf Wimmer, Erika Ábrahám,
Joost-Pieter Katoen, and Bernd Becker. Accelerating parametric probabilistic
verification. In 11th International Conference on Quantitative Evaluation of Systems

