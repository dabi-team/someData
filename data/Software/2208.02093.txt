Layered Binary Templating: Efﬁcient Detection of
Compiler- and Linker-introduced Leakage

2
2
0
2

g
u
A
4

]

R
C
.
s
c
[

2
v
3
9
0
2
0
.
8
0
2
2
:
v
i
X
r
a

Martin Schwarzl
Graz University of Technology

Erik Kraft
Graz University of Technology

Daniel Gruss
Graz University of Technology

Abstract—Cache template attacks demonstrated automated
leakage of user input in shared libraries. However, for large
binaries, the runtime is prohibitively high. Other automated
approaches focused on cryptographic implementations and media
software but are not directly applicable to user input. Hence,
discovering and eliminating all user input side-channel leakage on
a cache-line granularity within huge code bases are impractical.

In this paper, we present a new generic cache template attack
technique, LBTA, layered binary templating attacks. LBTA uses
layers as an extension
multiple coarser-grained side channel
to cache-line granularity templating to speed up the runtime
of cache templating attacks. We describe LBTA with a vari-
able number of layers with concrete side channels of different
granularity, ranging from 64 B to 2 MB in practice and in
theory beyond. In particular the software-level page cache side
channel in combination with the hardware-level L3 cache side
channel, already reduces the templating runtime by three orders
of magnitude. We apply LBTAs to different software projects and
thereby discover data deduplication and dead-stripping during
compilation and linking as novel security issues. We show that
these mechanisms introduce large spatial distances in binaries
for data accessed during a keystroke, enabling reliable leakage
of keystrokes. Using LBTA on Chromium-based applications,
we can build a full unprivileged cache-based keylogger1. Our
ﬁndings show that all user input to Chromium-based apps is
affected and we demonstrate this on a selection of popular apps
including Signal, Threema, Discord, and password manager apps
like passky. As this is not a ﬂaw of individual apps but the
framework, we conclude that all apps that use the framework
will also be affected, i.e., hundreds of apps.

I.

INTRODUCTION

Side-channel attacks are a powerful

technique to leak
information from side effects of computations [56]. Especially
caches, buffering memory recently accessed, are a popular
attack target, with generic attack techniques like Flush+Reload
enabling attacks with a high spatial and temporal resolution
and high accuracy. The ﬁrst cache attacks were focused on
cryptographic algorithms [73], [99], [7], [75], [71], [58],
[41], [47], [43], [42], [48]. In the last decade,
the focus
has been extended to non-cryptographic applications that still
operate on secret data, e.g., breaking address-space layout
randomization [46], [36], [6], [27], [57], [54], attacking secure
enclaves [35], [10], [65], [86], [25], spying on websites and
user input [61], [89], [107], and covert channels [114], [115],
[61], [62], [85]. In particular, user input, especially keystrokes,
has become a popular attack target for inter-keystroke timing
attacks [95], [81], [61], [67], [89], [107], [72]. Gruss et al. [40]

1In the demo provided, the user ﬁrst announces via Signal messenger to
send money to a friend, then switches to Google Chrome to visit a banking
website and enters the credentials there. All keystrokes are correctly leaked.
https://streamable.com/dgnuwk.

demonstrated that some libraries might leak more information
than just inter-keystroke timings, being able to distinguish
groups of keys, e.g., number and alphabetic keys.

Compilers can also introduce side-channel leakage, which
is invisible on the source level, by applying various optimiza-
tions with respect to the program’s runtime, memory footprint,
and binary size. Moreover, link-time optimizations [50] can
further optimize binaries in the linking stage. Page [74] showed
that dynamic compilation could lead to side-channel leakage
in a cryptographic library with constant-time implementation.
Simon et al. [94] demonstrated that different optimization
levels in common C compilers can break constant-time imple-
mentation of cryptographic primitives by introducing timing
side channels. Brennan et al. [11] discovered that timing side
channels can be introduced by exploiting JIT compilation.
Hence, side channels introduced in the development process
due to the complex interaction between software components
and compilers that are not obvious on the software layer may
remain undetected and pose a risk for all computer users.

As a consequence, numerous works explored the automatic
identiﬁcation of cache side-channel leakage. Most of these
works focus on cryptographic implementations and aim for the
goal of making the code constant-time [19], [79], [63], [13].
More recently, Yuan et al. [116] showed that manifold learning
can be used for automated side-channel analysis of media
software. For common applications processing sensitive input,
e.g., browsers, the situation is less clear, as it is not feasible to
linearize and unify the entire instruction stream for different
user inputs that
trigger vastly different program behavior.
Cryptographic implementations must be resistant to repeatable
attack attempts, while other form of input, such as user input,
is unpredictable and non-repeatable [89]. Such attacks often
suffer from a noisy channel, e.g., affected by co-location with
other data on the same cache line or prefetching effects due
to spatial proximity. Therefore, the state-of-the-art is not to
analyze the leakage based on models and theoretical leakage
assumptions but to actively use side channels to template (i.e.,
to proﬁle) the leakage that can be observed [40], [107]. In
a cache-template attack the attacker maps binaries as shared
memory into the address space of the templating process and
proﬁles which memory locations show side-channel activity
upon speciﬁc events. In the attack phase, the attacker also
maps binaries as shared memory, as this requires no privileges
beyond read access. Thus, the two attack phases operate on
binary offsets and are entirely unaffected by mechanisms such
as ASLR (address-space layout randomization). To achieve
the templating (i.e., proﬁling)
a high level of conﬁdence,
must be performed on an attacker-controlled system that is
identical or very similar to the target system and using the side

 
 
 
 
 
 
channel that will also be used for exploitation subsequently.
Unfortunately, this comes at a high cost, namely the runtime of
the templating. For instance, templating the binary with cache
template attacks [40], shared libraries, and memory-mapped
ﬁles used by the Chrome browser (about 210 MB), would take
113.17 days with the published cache template attack tool [40]
on our test system. This leads to an unsatisfying situation,
where cache leakage analysis is not part of secure development
workﬂows.

In this paper, we present LBTA, Layered Binary Templating
Attack. LBTA uses multiple different
layers with different
spatial granularities as an extension to cache-line granularity
templating. While a smaller spatial granularity is beneﬁcial in
the attack phase, it comes at a substantial slowdown in the
templating phase. LBTA solves this problem by introducing
a previously unexplored dimension into software-based tem-
plating attacks. LBTA combines the information of multiple
side channels that provide information, e.g., at different spatial
granularity, to optimize and accelerate the search for secret-
dependent activity. Our templating starts with the channel with
the most coarse spatial granularity and based on the activity
uses more ﬁne-grained spatial granularity to detect the exact
location (cache-line granularity 64 B).

Our evaluation of LBTA on state-of-the-art systems shows
that a variety of hardware and software channels with different
granularity are available. We focus in particular on a com-
bination of a software channel, the page-cache side channel,
with 4 kB granularity, and the cache side channel, with 64 B
granularity. Page cache attacks are hardware-agnostic [38],
i.e., our templater
resulting in cross-platform applicability,
supports both Windows and Linux with the 4 kB page-cache
side channel. We show that this two-layered approach already
speeds up cache templating [40] by three orders of magnitude
(i.e., 1848x).

We evaluate LBTA on different large software projects,
including Chrome, Firefox, and LibreOfﬁce Writer. The most
signiﬁcant ﬁnding is a novel security issue introduced by
compiler and linker optimizations such as data deduplica-
tion during compilation and linking and dead-stripping.
Linker optimizations introduce a spatial distance of multiple
4 kB pages between key-dependent data accessed during a
keystroke. Using LBTA [96], we ﬁnd distinct
leakage for
all alphanumeric keys, allowing us to build a full unprivi-
leged cache-based keylogger using Flush+Reload that leaks
all keystrokes from Chromium-based applications involving
password input ﬁelds, e.g., Google Chrome on banking web-
sites, popular messengers including Signal, Threema, Discord,
and password manager apps like passky. Based on our ﬁnd-
ings, we conclude that multiple hundreds of apps using the
Chromium framework are affected [30]. Using Flush+Reload
we can mount powerful keyloggers with high accuracy for
Chromium-based applications. In addition, we demonstrate
keystroke-correlated cache activity on Firefox and LibreOfﬁce
Writer. While the cache activity does not reveal the actual
keystoke, inter-keystroke timing attacks might be mounted on
these targets [95], [81], [117], [26], [40]. We conﬁrm that
on Linux, the preadv2 syscall can be used instead of the
meanwhile mitigated mincore syscall [38], to perform page
cache attacks [51]. However, accurate keylogging using with

preadv2 and the page cache attacks are infeasible, as stable
results require a delay of 2 seconds between cache activity.

Since existing system hardening techniques, e.g., ASLR
(address-space layout randomization), have no effect on our
attack, we provide a systematic discussion of the possible
mitigation vectors.

Contributions. The main contributions of this work are:

1) We introduce a new dimension, side-channel granularity,
into cache template attacks and exploit it to speed up the
templating runtime by three orders of magnitude.

2) We show that the leakage discovered by LBTA can be ex-
ploited both in hardware (i.e., Flush+Reload) and software
cache attacks (i.e., page cache attacks).

3) With LBTA, we discover optimizations in LLVM/clang
that introduce side-channel leakage invisible on the source
level, namely data deduplication and dead-stripping.

4) Our end-to-end keylogger attack can be applied to
Chromium-based software, including Google Chrome, se-
cure messengers like Signal, and password managers.

Responsible Disclosure. We responsibly disclosed our ﬁnd-
ings to the Chromium project. The underlying issue was rated
as ‘medium’ severity and a CVE will be assigned at
the
beginning of August 2022. We are working with the Chromium
team on resolving the vulnerability and informing all affected
parties. In alignment with them, our experiments and tools will
be open-sourced after the vulnerability is patched. The patch
is already implemented and will be included in the Chromium
release M104 in the beginning of August 2022. 2

Outline.
In Section II, we provide the background. In Sec-
tion III, we explain the building blocks of LBTA. In Section IV,
we describe the effects during compilation and linking that
facilitate or even introduce side-channel leakage, i.e., data
deduplication and dead-stripping. In Section V, we evaluate
LBTA on different attack targets and show a full end-to-end
keylogger attack on the Chrome browser and Electron apps.
In Section VI, we provide a systematic analysis of mitigation
vectors. In Section VII, we discuss its implications before we
conclude in Section VIII.

II. BACKGROUND

In this section, we explain the necessary preliminaries on
hard- and software cache attacks, automated discovery of side
channel attacks, and side channels introduced by compiler
optimizations.

A. Shared Memory

Operating systems apply various optimizations to reduce
the systems general memory footprint. One such optimization
is shared memory, where the operating system actively tries to
remove duplicate data mappings. An example would be shared
libraries, such as the glibc, which is used in many programs,
and thus, can be shared between processes. Moreover, with the
mmap respectively LoadLibrary functions, a user program
can request shared memory from the operating system by
mapping the library as read-only memory. Another opti-
mization to reduce the memory footprint commonly used for

2We will provide a link via the chairs as soon as patches are ready.

2

virtual machines is memory deduplication on a pagewise level.
The operating system deduplicates pages with identical content
and maps the deduplicated page in a copy-on-write semantic.

B. Deduplication

The concept of deduplication is very generic and can
be applied in the context of various memory systems to
save memory. For storage systems, one example is cloud
storage systems that deduplicate ﬁles to minimize the amount
of storage required [45], [53]. For main memory, there are
multiple mechanisms that lead to deduplicated memory. One
is copy-on-write, which avoids duplicating memory in the ﬁrst
place during process creation. A similar effect can be achieved
via the operating system’s page cache [38], i.e., ﬁle-based
page deduplication. Modern operating systems also deduplicate
the zero page, i.e., many processes can map the same zero
page as copy-on-write instead of having their own copies
of zeroed memory. However, the most prominent example
is data-based page deduplication [98]. With data-based page
deduplication, the operating system or hypervisor scans the
main memory page-wise and identiﬁes identical pages, e.g.,
using hashes or byte-wise data comparison. The identical
pages are then deduplicated and marked as copy-on-write.
In all cases of deduplication, when a user tries to modify
the deduplicated memory, it is copied (duplicated) again. All
above types of deduplication are known to introduce side-
channel leakage, e.g., ﬁle deduplication [45], [4], and also page
deduplication [98] also from JavaScript [37], [23] and even
remotely [92]. Deduplication has also been a building block for
other attacks such as KASLR breaks [112], and Rowhammer
attacks [9], [78].

While all above types of deduplication target memory, there
is also deduplication in other contexts. In this paper, we focus
on a different type of deduplication that has little to do with
the above or memory systems in general. We instead focus
on deduplication during compilation and linking. The goal of
deduplication here is similar, i.e., reducing memory usage.
However, the security implications of deduplication during
compilation and linking have not been studied so far.

C. Cache Attacks

Caches are fast and reliable hardware buffers used to speed
up the memory access times. There is a signiﬁcant timing
difference between cached and uncached data, which leads to
a powerful cache side channel. Kocher [56] demonstrated that
timing attacks on cryptographic primitives are possible i.e.,
via caches or non constant-time arithmetic operations. Cache
attacks were used to attack cryptographic primitives [56], [73],
[99], [7], [75], [71], [58], [41], [47], [43], [42], [48], to break
the integrity of secure enclaves [35], [10], [65], [86], [25],
monitor user interaction and keystrokes [61], [89], [107], and
build stealthy and fast covert channels [114], [61], [62], [85].
Two main techniques on cache attacks evolved with Prime+
Probe [71] and Flush+Reload [115]. Osvik et al. [71] devel-
oped Prime+Probe, where the attacker occupies cache lines and
observes cache usage based on the cache eviction of the victim
application. Flush+Reload requires a shared memory between
attacker and victim, such as shared libraries [115]. However, as
Flush+Reload works on the attacker’s own addresses pointing
to the same physical shared memory, i.e., the attacker does

not need to know the victim’s address space layout or ASLR
offsets, as binary offsets are used instead.

Further cache attacks were developed in JavaScript to spy
on keystrokes, break memory randomization, and leak arbitrary
memory in combination with transient-execution attacks [70],
[61], [36], [55], [103], [82], [97], [1], [90]. Most of these
i.e., a 64 B cache line
attacks focus on hardware caches,
granularity when attacking data and instruction caches. For
attacks on TLB caches, the spatial granularity can be 4 kB,
2 MB, 1 GB, or 512 GB [39], [57], [102], [60].

In particular, for SGX, so-called controlled channels have
been demonstrated as powerful attack primitives [113], [100],
[65] with high spatial and temporal resolution, as well as a very
high accuracy. Controlled channels are side channels running
with elevated privileges, e.g., kernel privileges, with a typical
attack target being secure enclaves, that are protected against
regular kernel access.

D. Software caches

On the software level, there are also caches that buffer data
from slower memory components in faster memory compo-
nents. Software caches are used to cache frequent data like web
requests in web servers [68], [80], in-memory databases [64],
or keep frequently used database records [66]. These caches are
limited in their size and follow similar replacement strategies
to replace old data, such as LRU eviction [64]. Caches like
Nginx’s request pool and Memcached [64] were exploited in
memory-deduplication attacks [9], [78], [92].

Operating systems use a software-level page cache to
speed up accesses on disk-backed data by keeping the data
buffered in main memory (DRAM) [34], [38]. If the page
cache is full, a page-replacement algorithm is used to replace
pages and swap them out
to disk [14], [49]. Linux and
Windows offer functions to verify whether a speciﬁc virtual
in memory or not, namely mincore
address is resident
and QueryWorkingSetEx,Shared,ShareCount re-
spectively. Gruss et al. [38] showed that cache attacks can
be applied to the page cache by using either these functions
or by measuring timing differences. Consequently, the Linux
kernel developers hardened the mincore implementation to
only return page cache status information if the calling user
can write to the underlying ﬁle, mitigating cache attacks
using the mincore syscall. The Windows kernel developers
further restricted lower privileged processes to directly obtain
information about
the working set form higher privileged
processes [38].

On Linux, however, the system call preadv2 can still be
used to mount cache attacks [51] in the same way as with the
mincore syscall: Using the RWF_NOWAIT ﬂag, an attacker
can observe whether a page is resident in the page cache or
not, yielding the same side-channel information as mincore.
The results of the preadv2 templating attacks can be found
in Section V.

E. Automated Discovery of Side Channel Attacks

Templating attacks have been ﬁrst shown and mentioned
on cryptographic primitives running on physical devices [19],
[79], [63]. Brumley and Haka [13] ﬁrst described templating

3

attacks on caches. Doychev et al. [29] presented a static ana-
lyzer that detects cache side-channel leakage in applications.
Gruss et al. [40] showed that the usage of certain cache lines
can be observed to mount powerful non-cryptographic attacks,
namely on keystrokes. Lipp et al. [61] showed cache attacks
and cache template attacks on ARM. Van Cleemput et al.
[101] proposed using information gathered in the templat-
ing phase to detect and mitigate side channels. Wang used
symbolic execution and constraint solvers to speed up cache
templating of cryptographic software
[108]. Schwarz et al.
[87] demonstrated template attacks on JavaScript to enable
host ﬁngerprinting in browsers. Weiser et al. [110] and Wichel-
mann et al. [111] showed that Intel PIN tools can be used
to automatically detect secret-dependent behavior in applica-
tions, especially in a cryptographic context. Wang et al. [107]
presented a similar automated approach to detect keystrokes
in graphics libraries. Carre et al. [15] mounted an automated
approach for cache attacks driven by machine learning. With
that approach, they were able to attack the secp256k11
OpenSSL ECDSA implementation and extract 256 bits of
the secret key. Brotzmann et al. [12] presented a symbolic
execution framework to detect secret-dependent operations in
cryptographic algorithms and database queries. Li et al. [59]
demonstrated a neural network to perform power analysis
attacks automatically. Yuan et al. [116] demonstrated that
manifold learning can be used to detect and locate side-channel
leakage in media software.

F. Compiler-introduced Side Channels

While developers typically focus on the source code level
and care is taken to not introduce side channels there, the
compiler translates the source code to a binary, essentially a
different language. However, this step can introduce program
behavior that is not visible on the source level and introduces
or ampliﬁes side-channel
leakage. Page [74] demonstrated
that dynamic compilation in Java leads to power side-channel
leakage in a side-channel-secured library. Simon et al. [94]
showed that mainstream C compilers optimizations can break
cryptographically secure code by introducing timing side chan-
nels. Brennan et al. [11] showed that timing side channels can
be introduced by exploiting JIT compilation.

Due to this signiﬁcant inﬂuence of compilers on side-
channel leakage in binaries, they are also frequently used for
new mitigation proposals against side-channel leakage [22],
[77], [76], [17], [33], [16], [8].

III. Layered Binary Templating Attack

For

applications,

non-cryptographic
[61],

templating
approaches [40],
[107] can be used to ﬁnd real-
world exploitable leakage. However, for large binaries like
the Chrome browser with multiple shared libraries (220 MB),
templating with ﬁne granularity, e.g., a cache line, becomes
impractical. Therefore, we present LBTA, a layered approach
taking advantage of the coarser granularity of some side
channels, which is typically considered a disadvantage for the
attacker. In this section, we present the high-level view on
LBTA and show how LBTA reduces the templating runtime
by three orders of magnitude (i.e., 1848x). We discuss
implementation details and design decisions for our proof of
concept implementation.

Attacker

User

1(cid:13) Proﬁle

<input type="password"/>

2(cid:13) Type

Victim

handleKeystroke();

3(cid:13) Access cache

2(cid:13) Monitor

SW/HW Cache

Fig. 1: Overview of the LBTA

A. Threat Model

Our threat model follows the standard template attack
threat model [40], that distinguishes between the templating
and the exploitation phase.

Threat Model in the Templating Phase. For the templating,
also known as the proﬁling phase, we assume the attacker
was able to obtain a reasonably similar system, i.e., with the
same side channels as the victim system, such as the page
cache and CPU cache. The attacker has full control over
this system and can template the same binary version, e.g.,
obtained from package repositories or the vendor website,
that also runs on the victim system. The attacker can create
templates for different binary versions and applications to have
a suitable template in the exploitation phase subsequently.
In this phase, the attacker can also use any privileged or
unprivileged mechanisms for the templating or improve its
detection accuracy.

Threat Model in the Exploitation Phase. In the exploitation
phase, the attacker runs an unprivileged attack program on the
victim’s system, possibly under a separate user account. Hence,
we assume the victim application is started independently by
the victim user, and cannot be started, stopped, or debugged
by the attacker. This also excludes “preloading”, which, e.g.,
on Wayland (the default Ubuntu display server), would allow
monitoring all inputs to the application [5]. For non-Wayland
systems, we assume that the attacker cannot use other keylog-
ging techniques (e.g., on X11 [3]), or Windows (e.g., using the
getasynckeystate API call [106]), e.g., due to system
hardening or enforced security policies. For our keylogging
scenario, we assume that the victim user performs keystrokes
manually and does not use scripted input generation, e.g., auto-
ﬁllers or password managers.

B. High-Level Attack Overview

Figure 1 illustrates the steps of LBTA. First, the attacker
templates the library and creates templates for the cache usage
of different keystrokes (step 1). After the templating phase,

4

the attacker starts monitoring the software or hardware cache
usage. Depending on the cache activity, the attacker can infer
if input was given or, in the optimal case, distinguish the
keystrokes.

C. Exploiting Different Spatial Granularity

One novel aspect of LBTA is to use the different spatial
granularity of different side channels to our advantage. The
main focus here is on the templating phase, i.e., the threat
model for the templating phase applies. In the following,
we discuss how we extend cache templating from cache-line
granularity, as used in previous work [40], over 4 kB page
granularity [38] and 2 MB page granularity, to a practical and
generic multi-layered approach. Our technique also extends to
dimensions of 1 GB steps and beyond but we are not aware
of real-world victim binaries of such large size.

64B Granularity. Previous cache template attacks [40] used
cache-line granularity (64 B). One disadvantage of this ap-
proach is the runtime of the templating phase. When tem-
plating a single cache line with Flush+Reload, we observe an
average runtime of 490 cycles (n = 1000000, σx = 20.35%).
On a 4.0 GHz CPU, this would take 122.5 ns. The Google
Chrome binary has a ﬁle size of about 210 MB leading to
2 949 120 addresses to template with Flush+Reload. This leads
to a runtime of 0.36 s for templating every cache line once.
However, Gruss et al. [40] describe that multiple rounds
of Flush+Reload are required to get reliable cache templat-
ing results. Running an Intel 6700k CPU at 4.0 GHz with
a Ubuntu 20.04, templating 1 MB of the Chrome browser
(version 100.0.4896.60) with the provided implementation of
Gruss et al. [40], we observe a runtime of 817.652 s for 1 MB
and a total runtime of 1.98 days for the full binary, including
shared libraries, of 210 MB. Moreover, this templating tool
only reports whether a certain address was cached or not and
does not match the cache hits with the entered keystrokes. To
template, for instance, the 57 different common keys sequen-
tially with the method by Gruss et al. [40], we would need
an impractical total runtime of 113.17 days to obtain useful
templates. We conclude that such an approach is not feasible
for browser developers as the code base changes frequently,
and releases sometimes occur on a monthly basis [20].

4kB Granularity. Page cache attacks exploit the operating
system page cache, which works at a coarser granularity of
4 kB [38]. Page cache attacks have the advantage of working
independent of the underlying hardware. To identify the exact
memory locations causing leakage, they also resorted to tem-
plating. However, they did not combine this information with
timing differences from hardware caches.

Our intuitive idea here is to combine the 4 kB-granularity
side channel with the more ﬁne-grained side channel into a
two-layered approach. Hence, we do not template all cache
lines on a 64 B granularity but
instead pre-ﬁlter memory
locations on a 4 kB granularity. Instead of 2 949 120 memory
locations, we then only need to monitor 46 080 memory lo-
cations for the Chrome example, i.e., a templating runtime
speedup of at least 64. In addition, the templating phase on the
4 kB granularity level implicitly identiﬁes locations exploitable
via the page cache.

In the templating phase, the attacker is not restricted as the
code runs on the attackers own machine (cf. Section III-A).
Similarly to previous work, we can use the page cache
side channel or privileged channels, e.g., controlled-channel
attacks [113] via page-table bits [100]. We used the idle bit
as page tracker for Google Chrome (cf. Section III-E) to be
particularly useful as we have only a runtime of 1.47 hours for
all 57 key strokes.

2MB Granularity. While the two-layered approach already
brings a signiﬁcant runtime speedup, our approach is more
generic and extends to further layers. Again, in the templating
phase, the threat model (cf. Section III-A) permits the use
of privileged channels, e.g., controlled-channel attacks, but
this time on the page directory layer. Each page-table layer
provides referenced bits that are set by the hardware when
a location in this region is accessed. This 2 MB-granularity
side channel is also exposed via various side channels [39],
[57], [102], [60]. However, the activity on 2 MB pages can
be observed via the Page Middle Directory paging structure
and the referenced bit. We use the tool PTEditor [88] to
clear the referenced bit in the PMD. Checking and clearing
the referenced bit of the PMD, i.e., a 2 MB page, leads to a
runtime of 661.965 ns (n = 1000000, σx = 0.049%). Similar to
the templating with 4 kB granularity, we assume that multiple
repetitions are required to observe stable results and remove
false positives. Hence, to template the 57 different common
keys in Chrome with 20 repetitions per key, we estimate the
total templating to be about 0.15 seconds.

D. Beyond Huge Pages

The concept of LBTA extends to arbitrarily coarser granu-

larities as long as a channel exists.

For the 1 GB granularity level, we
1 GB Granularity.
experimentally validated that we can again use controlled-
channel attacks [113], [100], albeit this time on the page-
directory-pointer-table level. On this level, one entry (and thus
one referenced bit) covers a 1 GB region. Following a
similar approach as for the previous levels, we use PTEditor
to template and clear the referenced bit, for the single offset
in a 1 GB range. The runtime for checking and clearing
the referenced bit in the PUD is the same as for the PMD
(661.965 ns (n = 1000000, σx = 0.049%)). Note that this layer
of LBTA may become relevant in the future with constantly
growing binaries and libraries.3
512 GB and 256 TB Granularity. The intuitive extension
of our approach also uses the referenced bits on higher
page-table layers, i.e., the page-map level 4 to template in
512 GB steps, and the page-map level 5 (if available) to tem-
plate in 256 TB steps. We veriﬁed that we can indeed observe
activity in this range via controlled-channel attacks [113],
[100], i.e., via the referenced bits, showing that LBTA
can be extended to a 5-layer templating phase. The runtime
for checking and clearing the referenced bit in the PML4 is
the same as for the PUD (661.965 ns (n = 1000000, σx =
0.049%)).

We emphasize that scanning layers that exceed the binary
size, e.g., the 1 GB layer for a 180 MB binary, provides no

3The Google Chrome binary had 100 MB in 2017 and 180 MB in 2022,

showing an increase of 80 %.

5

additional information and does not reduce the search space,
as the search will always proceed to the next smaller layer for
the entire memory range then. Therefore, in the evaluation, we
skip all layers that exceed the binary size.

E. Templating Phase Implementation

The high-level idea is that the templater tracks the usage
of pages and then actively ﬁlters out pages that are not related
to keystrokes to reduce the search space of pages to template
and, as a result, reduce the overall runtime of the templating.
We implement our templater in Python, and provide it as open
source in our Github repository [2]. The templater takes as
input the set of different keys, the PID or process names that
should be monitored, and the number of samples per key.

Algorithm 1 summarizes the steps of the templating. First,
the templater runs a warmup phase, where all keystrokes to
template are entered once to load all related memory loca-
tions into RAM. Then the templater collects all the memory
mapping information from all ﬁles from the target processes
where activity has been found. These memory mappings
include all shared libraries. The templater generates random
key sequences based on the set of keys to template. For each
key in the sequence, the templater iterates over all the memory
locations on the current granularity level, and resets the access
information, i.e., resets the referenced or idle bit, or
ﬂushes the cache line depending on the side channel used.
Based on the number of samples performed, the templater
computes the hit ratio for each location. Subsequently, the
templater repeats this step for all memory locations above a
speciﬁc hit ratio with the next lower spatial granularity. With
this search strategy, the templater continues down to the lowest
level, where only regions are templated that showed activity on
coarser granularities. On the lowest level, the templater then
obtains a hit ratio for each single cache line.

Algorithm 1: LBTA Templating Algorithm

Input: Set of keys K, target PIDs Pn, number of samples N
Output: hit ratio matrix of all memory mappings H

1: Enter all keys in K once // Warmup
2: Collect all valid memory mappings of Pn

(possibly from previous layer)

3: for i = 0; i < N ; i + + do
for each k ∈ K do
4:
5:

6:
7:

Reset memory mappings (reset referenced/idle bits
or ﬂush)
Enter key k
Check state for all present memory mappings (via
interface or timing)
Compute hit ratios for k and update Hk

end for

8:
9:
10: end for
11: return H, and repeat algorithm for next layer

Linux. On the upper layers, we start by obtaining the memory
mappings for the target process. On Linux, we read these
mappings from procfs (with root privileges in line with the
threat model). We group the memory locations then according
to the most coarse granularity we use in our templating.
By using the referenced-bit side channel according to

6

Algorithm 1, we narrow down the set of memory locations
for the next layer.

Windows. On Windows, we can also obtain a list of memory
mappings using the EnumProcessModules PSAPI call,
which lists all loaded libraries and executable programs. To
retrieve the actual sizes of the libraries and executables,
the GetModuleInformation PSAPI call is used. Subse-
quently, we follow the same process using the referenced-
bit side channel as on Linux to narrow down the set of memory
locations using Algorithm 1. Subsequently, we continue with
the next layer.

1) 4 kB Page Granularity: While for the upper layers, we
used PTEditor [88] to read the referenced bits, we implemented
a more optimized approach for the page granularity.

a

bit

the

and

over

page

page

reads

usage

physical

corresponding

active mappings,

implement
all

We
iterates
for

Linux.
tracker
the
which
from
idle
/sys/kernel/mm/page_idle/bitmap
checks
if the page was accessed. We start by resetting the bit so
that the page usage tracker is ready. We use the Python3
keyboard library to inject keystrokes into an input ﬁeld.
After the templater performs the sequence of keystrokes, we
check all pages that are still in the candidate list for activity.
If we now observe a 1 at the page offset in the bitmap,
the page was not accessed. Conversely, if we observe a 0
at the page offset, we reset the page offset, and add it to
the set of correlated pages to track on the next layer. Note
that this approach is fully hardware-agnostic as this feature
is implemented in software in the Linux kernel. After each
iteration, we reset the state again by marking the pages as
idle again and repeat the measurements.

In case of a sequential read access pattern,

the Linux
kernel speculatively prefetches further pages of the same ﬁle
after a new page was added to page cache. This optimization
is called readahead [44]. On Ubuntu 20.04 (kernel 5.4.0),
the default read-ahead size is 128 kB and can be found in the
sysfs (/sys/block/
<block_device>/bdi/read_ahead_kb).
ﬁle-
mappings
the kernel performs a different optimization
called read-around.4 There, the kernel prefetches pages
surrounded by the page causing the pagefault e.g., 16 pages
before the page causing the pagefault and 15 pages after. To
reduce triggering read-ahead prefetching for sequential reads,
we use the madvise system call with the MADV_RANDOM ﬂag
to indicate a random read order.

For

Overlapping event (i.e., keystroke) groups for the current
candidate page and pages that might trigger the readahead of
the current candidate page could cause false positives in the
Linux case. In addition, if the number of readahead suppress
pages is too small, false positives can occur. Our classiﬁer tries
to reduce the number of false positives by checking out the
read-ahead/read-around windows and systematically rule out
other keystrokes. Based on the results of the templater, the clas-
siﬁer actively accesses surrounding pages from the target page
to suppress the read-ahead/read-around optimization. Note that
the read-ahead and read-around windows might overlap for

4https://elixir.bootlin.com/linux/v5.4/source/mm/ﬁlemap.c#L2437

some keys. If the keys to template are not on the same 4 kB-
page, we can still distinguish two keys by checking the ﬁrst and
last surrounded pages being accessed. The templater actively
creates warnings in the templating phase in case the keys are
still indistinguishable.

Windows uses

a different page

Windows.
replace-
ment strategy with global and local working sets [84].
To build the page usage tracker on Windows, we use
the PSAPI call QueryWorkingSetEx and monitor the
Shared,ShareCount and Valid ﬂags. If the page is
marked as valid and shared and the share count is larger
than 1, we mark the page as used. To perform the reset, the
EmptyWorkingSet PSAPI call is used to remove the pages
from all workings sets. This PSAPI call is only available for
unprotected processes, which is no issue during the templating
phase (cf. Section III-A).

On Windows, we observed no prefetching optimization
within working sets. Therefore, read-ahead is no problem for
measuring the hit ratio and detecting the exact offset on this
level. Alternatively, the templating could also be performed via
controlled side channels [113], [32], [93], tracing tools such
as Intel PIN, machine learning [107], [15] or architecturally
monitoring the accesses of pages using PTEditor [88].

Classiﬁer. We further try to restrict the search space further
on the 4 kB level. On the 4 kB level, we collect the page-hit
ratios for all events (i.e., keys) and pages, showing the link
between event and observable page hit. The templater also
templates a dummy idle event that sleeps for 30 seconds to
measure which hit ratios are above the system’s noise ﬂoor.
This idle event will not be linked to any page hit but rather
should represent unrelated noise that the templater might have
missed during the sampling of the other events. Our classiﬁer
links events or groups of events with single page hits to keep
the number of observed pages as low as possible. This is a
trade-off between search time and completeness of the search
that can be chosen differently for any LBTA on any target
application. Furthermore, a more sophisticated attack could
increase detection accuracy from monitoring multiple pages
or cache lines for each event. However, we decided to use the
search-time-optimized path, as side-channel attacks typically
cannot observe an arbitrary amount of memory addresses
anyway, i.e., we focus on a more practical set of leaking
addresses.

The algorithm to ﬁnd a suitable page hit describing an event

e works as follows:

1) We take the vector of all page-hit ratios related to event
e and subtract the sum of the page-hit-ratio vectors of all
other events (noise) from it. The resulting vector describes
how strongly accesses to a certain page (index in the
vector) are correlated with an event e.

2) We select the page with the highest score as a candidate.
a) Should the resulting candidate fail to fulﬁll our min-
imum score requirements (i.e., not above the location-
speciﬁc noise ﬂoor), our algorithm merges events to ﬁnd
a suitable page to recognize this group of events.

b) We treat the target event and the M −1 remaining events
(exluding the idle event) with the highest page-hit ratios
per page as one group. The difference is that we now
have an event group E = {e1, ..., eM } instead of a single

event. The group’s score is the minimum score of its
events. After merging, we use the same classiﬁcation
scheme as in step 1.

c) Should we still fail to ﬁnd a suitable page, we return to
step 2.1, i.e., we merge further events until we succeed,
or we end the classiﬁcation for the event.

3) While running, the classiﬁer also collects information on
potential read-around prefetching pages to ﬁlter them out.

After a successful classiﬁcation, the attacker has a mapping of
pages to events (i.e., key) and groups of events (i.e., groups of
keys). Subsequently, we can use this information and the trace
from the side-channel attack to build our keylogger.

IV. COMPILER- AND LINKER-INTRODUCED SPATIAL
DISTANCE IN BINARIES

Before we evaluate LBTA, we present one signiﬁcant
leakage-facilitating effect that we discovered while applying
LBTA on a variety of targets. This effect is particularly critical
as it originates in compiler optimizations in LLVM/clang that
are enabled by default and cannot be disabled via compiler
ﬂags. Compiler optimizations aim for a minimal program run-
time, small memory footprint, and small binary size. Moreover,
linker optimizations try to further optimize the binary in the
linking stage. This is especially useful for large software
projects such as browsers. We primarily found two effects
to facilitate cache side-channel leakage: One is data dedu-
plication during compilation and linking, the other is the
ﬁrst-come-ﬁrst-serve data placement introduced by the dead-
stripping mechanism. While memory deduplication at runtime
has been explored as a security risk already (cf. Section II-B),
data deduplication (e.g., of strings) during compilation is
not widely known and its security implications are entirely
unexplored. The security of constant-time implementations
has been analyzed for side channels being introduced by
compilers [74], [101], [94], [11]. In this section, we ﬁrst
show that dead-stripping (cf. Section IV-A) can facilitate and
amplify side channels on read-only strings used in C/C++
programs. We then show that deduplication during compilation
(cf. Section IV-B) and linking (cf. Section IV-C) can amplify
this effect by increasing the chance that secret-dependently
accessed victim data is placed in an attacker-facilitating way.
In addition to compiler optimizations, deduplication can als be
performed at the linking stage. The spatial distance between
secret-dependent accesses can be introduce by both compiler
and linker optimizations. We present two scenarios that we
also found in widely used real-world applications, where the
placement of read-only data, especially strings, ampliﬁes side-
channel leakage dramatically.

7

Compiler

Binary

DataA
DataD
DataH

P
l
a
c
e

d
a
t
a

Data

DataA
DataB
DataC
DataD
DataE
DataF
DataG
DataH
DataI
DataJ

used
unused
unused
used
unused
unused
unused
used
unused
unused

Data

KeyA
KeyB
KeyC
KeyD

KeyA
KeyB
KeyC
KeyD

Compiler

D
e
d
u
p
l
i
c
a
t
e

s
t
r
i
n
g
s

Binary

KeyA

KeyB

KeyC

KeyD

0x21000

0x22000

0x23000

0x24000

Fig. 2: Dead stripping in combination with ﬁrst-come-ﬁrst-
serve population of the .rodata section in the binary.

Fig. 3: String deduplication in the compiler causing spatial
distance in .rodata section of the binary.

A. Dead-Stripping

1 struct MapEntry {
2

const char* key;
const char* value;

3
4 };
5 #define LANGUAGE_CODE(key,value) \
6
7 #define MAP_DECL constexpr MapEntry mappings[]
8 =
9

{ key, value }

MAP_DECL {

LANGUAGE_CODE("KeyA","DataA"),
LANGUAGE_CODE("KeyB","DataB")

10

};

11
12 #undef MAP_DECL
13 void string_func(vector<string>& vec) {
14

//Key A
MapEntry k1 = mappings[0];
vec.push_back(k1.value);
// Padding string
string padding = "<64-byte-string>";
vec.push_back(padding);
//Key B
MapEntry k3 = mappings[1];
vec.push_back(k3.value);

15

16

17

18

19

20

21

22
23 }

Listing 1: Compiler populates .rodata based on accesses in
code

Lookup tables are frequently used in applications to speed-
up memory accesses and store constant data like locality
strings. For the developer, it is not transparent how constants
are stored in the compiled binary. Thus, even if the code
seems to hide a cache-side channel on 64 B granularity, the
compiler might reorder strings and add more spatial granularity
between items of the same lookup table. One optimization
to reduce the binary size is to only populate the read-only
data section if the compiler observes that only certain indices
of a lookup table are accessed. Figure 2 illustrates how data
can be re-ordered in the use case of dead-stripping. If the
developer uses a macro to dynamically populate a lookup
table, e.g., with key mappings or similar, compilers do not
insert all elements into the read-only section of the binary
to reduce the binary size. Listing 1 lists an example of code
that seems to have co-located strings mappings array in the
.rodata section. However, as the compiler is free to populate
the readonly section in the binary,
the
compiler introduces leakage here that is not visible on the
source level. While without
this optimization, an attacker
could not distinguish whether KeyA or KeyB was accessed
with Flush+Reload in the original code snippet. The compiler
creates a spatial distance exposing this secret information to the

is possible that

it

attacker. We evaluate our test program on Clang 10 and GCC
9.4.0 with the optimization levels O0-O3,Os. For Clang, we
observe that on every optimization level and also without
optimizations, the padding string is between the DataA and
DataB strings, i.e., DataA.<64-byte-string>.DataB..
The . indicates a NULL-byte in the memory layout for
C strings. Clang compiler traverses all functions and pop-
ulates the .rodata depending on the ﬁxed indices for the
array lookup. GCC with the O0/O1 ﬂags populates the
.rodata directly with all strings from the mappings array,
i.e., DataA.DataB.<64-byte-string>. Therefore, an
attacker would not be able to observe which cache line was
accessed. For the other optimization levels in that concrete
example, the small strings DataA,DataB would be directly
stored as immediate in the binary, e.g., "mov DWORD PTR
[rsp+0x50], 0x756c6156" and then the full string on
the heap is allocated.

B. Data Deduplication during Compilation

Another optimization facilitating cache attacks, also in
combination with the dead-stripping we just discussed,
is
data deduplication during compilation. Deduplicating strings
can reduce the binary size signiﬁcantly but also the memory
resident size when running the program, as strings do not have
to be kept in memory multiple times. Figure 3 demonstrates
how string deduplication can introduce spatial distance in
sections of the binary, for instance, the .rodata section. C/C++
compilers deduplicate strings that occur more than once in
the source code. Listing 2 illustrates a situation where the
string deduplication optimization can be used. Both the lookup
table mappings and the function string_funcA contain
the string DataA. Since the compiler again traverses over the
functions and DataB is ﬁrst inserted into the .rodata section.
Again a constant padding string could cause DataA and
DataB to be located in different cache lines. Before the com-
piler inserts DataB (mappings[1] in string_funcB),
the compiler checks for duplicates and only points to the
existing occurence of DataB in the .rodata for all future
usages. Again we evaluate this code constellation for GCC and
Clang. For Clang, we observe again for all optimizations levels
the ordering DataA.<64-byte-string>.DataB in the
.rodata section. For GCC, we observe the same result that
for optimization levels O0/O1, both values are populated next
to each other in the .rodata (DataA.DataB). Again for the
higher optimization levels, the small strings are encoded as
immediates.

8

1 struct MapEntry {
2

const char* key;
const char* value;

3
4 };
5 #define LANGUAGE_CODE(key,value) \
6
7 #define MAP_DECL constexpr MapEntry mappings[]
8 = MAP_DECL {
9

{ key, value }

LANGUAGE_CODE("KeyA","DataA"),
LANGUAGE_CODE("KeyB","DataB")

10
11 };
12 #undef MAP_DECL
13 void string_funcA(vector<string>& vec) {
string local_ro_string = "DataB";
14
vec.push_back(local_ro_string);
string padding_string = "<64-byte-string>";
vec.push_back(padding_string);

17
18 }
19 void string_funcB(vector<string>& vec) {
20

15

16

//KeyA
MapEntry k1 = mappings[0];
vec.push_back(k1.value);
//KeyB
MapEntry k2 = mappings[1];
vec.push_back(k1.value);

21

22

23

24

25
26 }

Listing 2: Strings are deduplicated in the binary and could
lead to spatial distance between readonly-strings in the
same array.

C. Deduplication in the linking step.

As we showed, string deduplication can cause spatial
distance between strings and enable side-channel attacks in
the compile step. For large software projects such as the
Chromium project, it is important also to save time while
linking together a large amount of object ﬁles. However, for
the runtime of the linker is
such large software projects,
crucial. Linkers are also merging strings as an optimization
in the linking time. To perform fast lookups of strings in
the linking step, hash tables are used [83]. Since 2017, lld
uses multiple hash tables instead of one large one to enable
concurrency. Concurrency in the linking step brings a speedup
in the linking time. However, as there are multiple tables,
inserting merged strings can cause a different layout for strings
in the .rodata section than in the ﬁnal linked binary. Figure 4
illustrates how the concurrent merging can lead spatial distance
in the ﬁnal binary. In the highest optimizations of lld linker,
i.e., -O2[69], the linker merges duplicate substrings contained
in larger strings. The smaller substring will be removed,
and the tail of the larger string used to index the substring.
The security implications of string deduplication need to be
considered in software projects since large spatial distance
between secret dependent values such as different key inputs
can lead to leakage of all user input, as we show in Section V.

V. EVALUATION

In this section, we evaluate our templater on large binaries
such as browsers that have not been targeted with templating
attacks so far. We also focus on widespread Chromium-
based products and demonstrate that they are susceptible to
LBTA. We analyze the root cause for the leakage and show
that it is caused by a compiler optimization. Table I lists
all the evaluated applications, including the Chromium-based
browsers and applications, Firefox and LibreOfﬁce Writer.

9

Data

KeyA
KeyB
KeyC
KeyD

KeyA
KeyB
KeyC
KeyD

Write

Hash-Tables

HT 1

HT 2

HT 3

HT 3

Binary

KeyA

KeyB

KeyC

KeyD

0x21000

0x22000

0x23000

0x24000

Fig. 4: String deduplication in the linker causing spatial
distance in .rodata section of the binary.

Templating of HTML form input ﬁelds Google Chrome.
We ﬁrst run our templating tool while generating keystrokes.
We run our templater on an Intel
i7-6700K with a ﬁxed
frequency of 4 GHz running Ubuntu 20.04 (kernel 5.4.0-40) on
Google Chrome version 100.0.4896.60. To get more accurate
results during the templating phase, we recommend drop-
ping the active caches before the execution of the templater
via procfs (/proc/sys/vm/drop_caches). Moreover, we
blacklist ﬁle mappings from the /usr/share/fonts/ as
they lead to unstable results during the evaluation phase. Our
templater traces 57 different key codes of a common US_EN
keyboard in HTML password ﬁelds. For each key code, we
sample 20 times. On average, we observe a runtime of 1.47
hours (n = 10, σx = 0.33%) for 57 key codes, including the
time for key classiﬁcation. For a single character, the runtime is
92 seconds. We use the ldd to ﬁnd all shared libraries used in
Google Chrome to determine the overall ﬁle size of libraries to
template. Including the main binary, the total size of memory
mappings to scan is 209.81 MB. We estimate the runtime of
the public implementation for cache template attacks [40] to
113.17 days. Our templater brings a speedup in the templating
runtime of factor 1484. Using the proposed optimizations of
Gruss et al. [40] leveraging parallelism in the templating phase,
we can achieve a runtime of 17 s per megabyte. Thus, the
templating time could be improved to 2.35 days. However,
this approach appears to be noisier and was not merged in the
public implementation of cache templating attacks [40].

Leakage Source in Chrome. As we discovered the page
offsets related to the different keystrokes, we want to ﬁnd the
exact cache line causing the cache leakage. We extend our
monitor with Flush+Reload to determine the cache line within
the page. To speed up the templating time and reduce the noise
for cache lines, we disable most of the Intel prefetchers by
writing the value 0xf to MSR 0x1a4 [105]. We map the
Chrome binary as shared memory and perform Flush+Reload
on all mapped cache lines to determine the corresponding
cache lines for each key.

We analyze the Chrome binary and lookup the offsets
causing the leakage for a speciﬁc key stroke. Each cache line
causing the leakage of a certain character contains a string
for the key event, e.g., “KeyA”. By reading Chrome’s ELF
header, we observe that all offsets lie in the read-only data
(.rodata section of the binary. The leakage source are key-
dependent accesses to the key code strings in the dom code

User

Type C

.rodata

KeyA

KeyB

KeyC

KeyD

Page / Cache Line accessed

Fig. 5: Illustration of strings in the .rodata section for key
codes that cause the cache input leakage.

table,5 e.g., DOM_CODE(0x070004, 0x001e, 0x0026,
0x001e, 0x0000, "KeyA", US_A);. As these strings
appear multiple times at different locations in the code, the
location in the .rodata depends on the compiler. Figure 5
illustrates the leakage source for a user typing in a certain
character and the corresponding DOM CODE for the UI event.

To verify if the leakage is related to string deduplication,
we download the Chromium source, disable the string dedu-
plication -fno-merge-all-constants and rebuild the
Chromium browser. We still observe, that the single keystrokes
are spread over multiple pages in the .rodata section.

As a next step, we analyze the compiled object ﬁles after
the build process. We observe that
the created object ﬁle
keycode_converter.o still contains all the key event
strings adjacent to each other in the binary. This indicates that
the linker introduces the spatial distance between key event
strings.

We perform a binary search on older Chrome binaries from
a public Github repository containing archived Chrome Debian
packages [109] to see when the spatial distance for key event
strings was introduced. As a result, we observe that between
version 63 and 64 of Chrome (year 2017), the single key
event string was placed in the .rodata at different 4 kB
pages. According to [83], the linker optimizations have been
constanly improved since 2017. As discussed in Section IV,
the parallelism in string deduplication can also cause spatial
distance between key events. Disabling the string merging opti-
mization of the linker with -Wl,-O0 for a current Chromium
version removes the spatial distance between the key event
strings. Re-enabling the string merging optimization of the
linker, i.e., -Wl,-O1, the spatial distance reappears as strings
are again deduplicated. This conﬁrms that one of the effects
we exploit is introduced by the linker.

In comparison to state-of-the-art keyloggers on Linux like
xkbcat [3], our keylogger does not rely on running as the same
user within the same X-session. We verify this by running
our keylogger as a different user and can still recover the
keys from the Chrome browser. Note that more sophisticated
cache attacks like Prime+Probe can be performed to enable
JavaScript-based attacks [71], [104], [1].

Keylogging in Google Chrome with Flush+Reload. We
run our monitor in three experiments for 180 seconds with all

5https://source.chromium.org/chromium/chromium/src/+/main:

ui/events/keycodes/dom/dom code data.inc

0
0
0
0
0
0
0
0
0
0
0

0x1521203

115

0x151b9bd

0x1513d05

0x1510118

0x150d59a

0x150b526

0x1509a35

0x1508991

0x1506eb8

0x1505e5b

5

0

2

0

0

0

0

0

0

1
1
1
1
1
1
1
1
1
1
1

0

185

0

0

0

0

0

0

0

0

2
2
2
2
2
2
2
2
2
2
2

0

0

165

0

0

0

0

0

0

0

3
3
3
3
3
3
3
3
3
3
3

0

0

0

178

0

0

0

0

0

0

4
4
4
4
4
4
4
4
4
4
4

0

0

0

0

171

0

0

0

0

0

5
5
5
5
5
5
5
5
5
5
5

0

0

0

0

0

173

0

0

0

0

6
6
6
6
6
6
6
6
6
6
6

1

0

0

0

0

0

156

0

0

0

7
7
7
7
7
7
7
7
7
7
7

0

0

0

0

0

0

0

169

0

0

8
8
8
8
8
8
8
8
8
8
8

0

0

0

0

0

0

0

0

9
9
9
9
9
9
9
9
9
9
9

43

47

53

45

49

56

51

58

165

52

0

140

Fig. 6: Cache-hit ratio using Flush+Reload for all digits letters
in Chrome.

lowercase alphanumeric characters and observe cache activity
for every single keystroke. The ﬁrst experiment runs with fast
user input with 1 ms between each keystroke. We count cache
hits following a keystroke as true positives if they occur on
the cache line that is correct according to our template, and
as false positive otherwise. To obtain the number of false
positives, we run the monitor in a second experiment without
performing any keystrokes in the input ﬁeld, i.e., idling. To
complete our data on false negatives and true positives, we run
the monitor in a third experiment while performing user input
with 1 s between each keystroke. Over the total 540 second
measurement
time frame, we observed no false negatives.
Figure 9 (Appendix) shows the cache-hit ratio for the cache
lines detecting lowercase letters in Chrome. Figure 6 shows
the cache-hit ratio for the cache lines detecting numeric digits
in Chrome. As shown from Figure 6, the different digits can
be highly-accurately classiﬁed. As can be seen, digit 9 causes
constant noise for all the different keys as in that version of
Google Chrome. The cache-line is constantly accessed also in
an idle state. The F-Score is the harmonic mean of precision
and recall. Figure 7 illustrates the F-Score for all alphanumeric
characters. From all the 36 alphanumeric keys, this is the
only character causing constant noise on Google Chrome.
Moreover, we observe that a single keystroke causes up to
three cache hits. These cache hits could be related to the
window events key_up,key_pressed and key_down. To
avoid printing the same character multiple times, a cache miss
counter between the keystrokes can be used [40]. Note that
multiple cache lines can be considered to further increase the
accuracy of the keylogger [61], [107], [15].

Keylogging with the page cache. To demonstrate that the
Chrome leakage is not speciﬁc to a certain CPU, we run our
keylogger on Chrome version 99.0.4844.84. Our test device
runs Ubuntu 20.04 (kernel 5.18.0-051800-generic), equipped
with an AMD Ryzen 5 2600X CPU, 16 GB of RAM, and
a Samsung 970 EVO NVME SSD. We circumvent the read-

10

1

0.5

e
r
o
c
S
-
1
F

a b c d e f g h i j k l mn o p q r s t u vwx y z 0 1 2 3 4 5 6 7 8 9

Key Event

Fig. 7: F-Score per key using Flush+Reload for all alphanu-
meric characters in Chrome.

1

0.9

0.8

e
r
o
c
S
-
1
F

a b c d e f g h i j k l mn o p q r s t u vwx y z 0 1 2 3 4 5 6 7 8 9

Key Event

Fig. 8: F-Score per key event using page cache attacks for all
alphanumeric characters in Chrome.

around and read-ahead optimization as explained in Sec-
tion III-E. The keylogger uses the keystroke template for the
main Chrome binary and monitors the page cache utilization
for the corresponding pages using the preadv2 syscall. It
then reports the detected activity as keystrokes and subse-
quently evicts the page cache. While the page cache attack
using the mincore syscall was able to observe keystrokes on
a ﬁne temporal granularity, we observe that using preadv2
comes with practical
limitations. In particular, with large
eviction set sizes, guessed by the attacker, we conclude that
only very slow keyboard interaction with gaps of 2 s and more
can be observed. However, our evaluation of the page-cache
side channel is generic and would also apply to scenario where
the mincore syscall is available, which allowed fast and non-
destructive continuous probing.

Based on the page cache accesses, we compute the page-
hit ratio for Google Chrome over the page cache. Figure 9
(Appendix) shows the page-hit ratio for the page cache detect-
ing alphanumeric letters in Chrome. For the Chrome version,
we observe that the characters b,m,9,h,y,x are grouped
and cannot be uniquely distinguished. We again perform the
experiment in three phases to determine true positive, false
positive, and false negative rate, by simulating fast, slow,
and no user input. Figure 8 shows the F-Score for all al-
phanumeric characters running the page cache attack. While
most characters have very high F-Scores, the character group
b,m,9,h,y,x has a lower F-Score due to false positives
when other keys are pressed. Also, same as in the Flush+
Reload attack, the character 9 suffers from a high number of
false positives, negatively impacting the F-Score.

Electron. As we observed the leakage of keystrokes within
the Chrome binary, we further analyze Chromium-based ap-
plications like the Electron framework. As Chromium-based

11

applications use the same handling for keystrokes for all
applications, we can directly scan the .rodata section for
the keystroke mappings to ﬁnd the offsets. We evaluate the
templates on Chromium, Threema, Passky, VS-Code, Matter-
most, Discord and observe similar leakage rates to Google
Chrome with F-Score of over 85 %. Table I contains the high
F-Scores for the different applications. We run our monitor
on the lowercase alphanumeric keys and observe a similar
leakage rate with Flush+Reload. Based on these very clear
results, we deduce that in principle all Electron applications
are susceptible to LBTA and full key recovery attacks.

Chromium Embedded Framework. The Chromium Embed-
ded Framework (CEF) is widely used and another interesting
target for LBTA. While Electron directly uses the Chromium
API, CEF tries to hide the details of the Chromium API [31].
CEF is actively run on more than 100 million devices [18].
We target Spotify, and the Brackets editor application, which
are both based on CEF. To attack a CEF application, an
attacker needs to read out the .rodata section from the
shared library libcef.so. We run our monitor again with
Flush+Reload and observe an F-Score of 0.96 % over the
lowercase alphanumeric characters. For Brackets (1.5.0) we
observe, that the libcef.so was built with an older linker
version as the different key-event related strings for the lower-
case alphanumeric characters are co-located in three different
cache lines. Therefore, we consider all CEF applications to
be susceptible to cache templating in principle. We observe
an F-Score of 94 % for detecting key events. However, we
also observe that hardware prefetching practically thwarts the
distinction of different blocks in this scenario more than in
the other attack scenarios, leaving only inter-keystroke timing
attacks as an option for the attack phase.

Firefox. We also templated the Firefox binary with LBTA
and identiﬁed locations with cache activity upon keystrokes.
While we observe cache activity for each keystroke in the
shared library libxul.so (offset: 0x332d000), we did not
ﬁnd leakage to distinguish keys reliably. Firefox uses a com-
pletely different build system, i.e., optimizations such as data
deduplication and dead-stripping may still be applied but will
not behave exactly the same as with LLVM/clang. However,
using the found binary offset, an attacker can determine
whether a user is typing and perform an inter-keystroke timing
attack [95], [81], [117], [26], [40] to recover the keystrokes.
We run the monitor again and probe the address that has the
most hits within the page on different keystrokes. The accuracy
we observed for such an attack is 96 %.

LibreOfﬁce Writer. We proﬁle the LibrefOfﬁce Writer
version 6.4.2 on our Linux setup. Our proﬁler shows that
the library libQt5XcbQpa.so.5.12.8 (offset: 0x51000)
offset reveals cache activity on all letters but no digits. The
library libswlo.so (offset: 0x53e000) shows cache activity
on keystrokes reliably, with an F-Score of 1. Again, inter-
keystroke timing attacks can be performed.

Chrome on Windows. On Windows, we tested Chrome
versions 103.0.5060.53 and 103.0.5060.114. Our evaluation
runs on a notebook equipped with an Intel i5-4300U run-
ning Windows 10 (1803, Build 17134.1726). We use the
LoadLibrary function to load libraries and create a shared
mapping between the attacker and victim applications. Using
the key event strings, we directly ﬁnd the offsets in the DLL

ﬁle. We observe that in the chrome.dll (offset: 0xa4ee000)
the different key bytes are co-located instead of having a
spatial distance of multiple 4 kB pages. The Chrome build on
Windows uses a different compiler and linker, and, thus, the
string merging optimization might behave differently or is even
turned off. Running our cache monitor using Flush+Reload
we do not observe any cache leakage on the DLL ﬁle. The
grouped keys there are KeyA-KeyF,KeyG-KeyS,KeyT-Digit4
and Digit5-Digit9. Again, the prefetchers on the evaluated CPU
practically thwart the distinction between the different groups
of keys. Running a similar experiment as on Linux, we observe
a F-Score of 0.99 %.

In addition, we use our proﬁler to observe cache activity
on other locations. The DLLs msctf.dll (offset:0x45000))
and imm32.dll (offset:0x3000) also correlate to user input
in Chrome on Windows. These two libraries are mainly used
for user input methods and the text management. Therefore,
using Flush+Reload inter-keystroke timing attacks are possible
on Chrome on Windows.

Search bar. Templating user queries in the browser would
tremendously reduce the privacy of browsers. Running the
templater on the search bar of Google Chrome 103.0.5060.53
revealed that the search bar uses a different method to load
the keys and there is only a single page (offset: 0x91d4000) in
Google Chrome with cache activity upon keystrokes. Based on
our results, we conclude that the search bar does not use the
same internal structures for key events as HTML input data.
Still, the leakage we discovered enables inter-keystroke timing
attacks on keystrokes. Running the proﬁling experiment with
all alphanumeric, we achieve a F-Score of 0.99 % for detecting
key presses.

VI. MITIGATION

In this section, we discuss different mitigation vectors that
could prevent the leakage. Nevertheless, we want to emphasize
that preventing leakage on such a broad scale as user input
in various contexts comes at a signiﬁcant performance and
usability cost. Furthermore, system-hardening techniques such
as ASLR have no effect on the attack as the attacker just maps
(which is an unprivileged operation) the victim binary into its
own address space. In principle we identiﬁed four conditions
for an attack to succeed:

it

is still possible to detect

1) Disable Compiler and Linker Optimizations: For the
concrete leakage of Chromium-based applications, dis-
abling the linker optimizations would mitigate accurate
the
keylogging. However,
activity of key groups as the keys are co-located in 4 differ-
ent cache lines. Inter-keystroke timing attacks would also
enable accurate keylogging as the cache activity can also
be used for timing measurements between cache hits [95],
[81], [61], [67], [89], [107], [72]. Moreover, removing
these optimizations would bring back again overhead in
the linking time [83].

2) Golden device availability: All templating attacks require
that the attacker is able to run the templating phase on
a setup that is similar enough to the victim system [19],
[79], [13], [40]. This is in principle not difﬁcult to achieve
as most desktop and laptop processors today are similar
enough with respect to the cache side channel (i.e., 64-
byte cache lines and the availability of a ﬂush instruction),

12

that it is sufﬁcient to have essentially any desktop or laptop
processor available for the templating. It is slightly more
challenging to obtain precisely the same software version
and binary that is running on the target system. While
software diversity [24] could be an avenue to break this
link, it has not really found its way into practice yet. In
practice, the vast majority of users runs binaries obtained
from the ofﬁcial repositories or websites.
While the idea of templating is decades old already [19],
few works have looked at templating in the context of
non-cryptographic leakage from software binaries, e.g., via
caches [40], [107]. Since our layered approach, LBTA,
makes the templating much faster, software diversity could
be a possible mitigation to break this condition. Without
a binary identical to the one the victim runs, i.e., due
the attacker could not determine
to software diversity,
templates that work on the victim’s system.

3) Secret-dependent execution: The side-channel leakage,
e.g., which key was pressed, originates in differences in
code and data accesses depending on the speciﬁc key value.
The state-of-the-art approach to secure cryptographic code
is the linearization to a so-called constant-time implemen-
tation. Here, code and data accesses are always identical,
regardless of the secret processed. For cryptographic algo-
rithms this already comes at a non-negligible performance
cost [21]. On an abstract level, the idea is to always run
all the code and access all the data, e.g., in a square-and-
always-multiply implementation [52]. However, for non-
cryptographic algorithms, always running all the code and
accessing all the data is entirely infeasible. Domas [28]
presented a compiler that linearizes the entire control ﬂow
to a sequence of mov instructions, effectively eliminat-
ing all secret-dependent branches, but with an enormous
runtime overhead. Schwarzl et al. [91] further optimized
this approach but still observe runtime overheads of factor
1000 and more, even for comparably simple applications.
Borrello et al. [8] focused more on the protection of
cryptographic implementations and still observe a runtime
overhead of factor 3.17 to 5.07 on these relatively small
examples. Hence, the problem of secret dependency on user
input in large applications remains an open problem.
4) Side-channel observability: A practical limitation to the
exploitation of secret-dependent execution is the side-
channel observability. While tools like CacheAudit [29]
or CaSym [12], follow the cryptography-focused notion
of constant time to consider an application leakage free,
the practice for user input is more nuanced. For instance,
distinguishing keys may be infeasible for an unprivileged
attacker in practice when secret key-value-dependent exe-
cution exists but does not cross e.g., page or cache-line
boundaries. In particlular, within a page,
the hardware
prefetcher will pose a substantial obstacle that introduces
spurious cache activity on the target cache lines, foiling
exploitation in practice [40].
The compiler could use this effect by grouping potentially
secret-dependent accesses closer together or placing these
strings in between frequently used code or data. We ob-
served this effect in gcc where short strings are directly
encoded into the instruction stream, or placed in physical
proximity with other strings that are accessed based on a
secret value. While speciﬁc patches can reduce the leakage
in the cases we discovered, compilers could in general

TABLE I: Evaluated applications. Page cache (PC) and cache-line (CL) indicate whether precise keystroke attacks are possible
on that granularity. Inter-Keystroke Timing indicates that key events can be detected on the application via Flush+Reload or the
page cache.

Name
Chrome (99.0.4844.84)
Signal-Desktop (5.46.0)
Threema (2.4.1)
Passky (7.0.0)
VS-Code (1.69.1)
Chromium Browser (103.0.5060.114)
Mattermost-Desktop (5.1.1)
Discord (0.0.18)
Spotify (1.1.84.716)
Brackets (1.2.1)
Chrome 103.0.5060.134(Windows)
Chrome 103.0.5060.53 (Search Bar)
libxul.so (Firefox 102)
LibreOfﬁce Writer (6.4.2)

Category
Browser
Private Messenger
Private Messenger
Password Manager
Editor
Browser
Collaboration Platform
Text and Voice Chat
Audio Streaming
Editor
Browser
Browser
Browser
Ofﬁce Software

CL (all key events)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:55)
(cid:55)
(cid:55)
(cid:55)
(cid:55)

PC (all key events)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:55)
(cid:55)
(cid:55)
(cid:55)
(cid:55)

Inter-Keystroke Timing on Blocks
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)

Avg. F-Score (Flush+Reload)
0.94 %
0.98 %
0.84 %
0.99 %
0.85 %
0.99 %
0.94 %
0.98 %
0.96 %
0.94 %
0.99 %
0.99 %
0.99 %
0.99 %

take side channels into account and employ side-channel-
adverse data placement, i.e., minimizing the number of
cache lines a data structure is spread across.

5) Noise-resilience: Since user input cannot be arbitrarily
triggered and repeated by the attacker millions of times,
noise-resilience of the side channel is one condition for
an attack on user input to succeed [89]. Hence, inducing
noise, which is usually not recognized as a viable strategy
for cryptographic operations, can provide strong practical
security guarantees for user input which occurs at a low
frequency and is not arbitrarily repeatable. In particular
for modern systems, a low number of additional memory
accesses for potentially secret dependent operations would
come at a negligible performance cost while practically
mitigating these attacks on user input. Furthermore, user
annotations of potentially secret data may help minimizing
the performance costs for this approach.

VII. DISCUSSION

LBTA is an effective technique to identify leakage in large
binaries. As such, it cannot only used by attackers but is
more interesting as a defensive technique revealing leakage
already during the development process. While constant-time
implementations have been analyzed for side channels being
introduced by compilers [74], [101], [94], [11], developers
should be aware that compiler and linker optimizations can
lead to spatial distances in binaries enabling side-channel
attacks on both hardware and software caches. We want
to emphasize that string deduplication is not only related
to native programs. Many languages like JavaScript, Java,
PHP and Python perform string deduplication (under the
term ‘string interning’) to reduce memory utilization. For
instance, Java also offers the possibility of string deduplica-
tion (-XX:+UseStringDeduplication) during garbage
collection which could lead to similar side effects.

We demonstrated that keystrokes in form input ﬁelds
in Google Chrome can be detected using cache attacks on
hardware and software caches. While Google Chrome is a
valuable target, the dependency of many frameworks on the
Chromium project, such as CEF and Electron, leads to a sig-
niﬁcantly higher impact as hundreds of browser-based desktop
applications [30] are susceptible to accurate keylogging with
our attack.

The templating phase runs in native code on an attacker-
controlled system. While we also demonstrate the exploitation
phase only in native code, we want to emphasize that browser-
based attacks based on the same leakage are also possible. Us-
ing more advanced techniques like Prime+Probe in JavaScript
and WebAssembly in the browser [104], [1], an attacker may
then infer keystrokes from a browser tab, spying on another
tab or an Electron app running on the victim’s machine. The
crucial challenge of such an attack would be to map the ﬁle
offsets in the precomputed template to cache sets. However,
LBTA is a generic technique that can be instantiated with
various side channels, e.g., Prime+Probe that does not require
any shared memory. Moreover, with techniques by Lipp et al.
[61] and Gruss et al. [38], LBTA could be applied to Android
as well.

VIII. CONCLUSION

We discovered that data deduplication and dead-stripping
during compilation and linking facilitate side-channel leakage
in compiled binaries. We show that this effect can even induce
side-channel leakage in previously secure binaries, i.e., no
secret-dependent accesses crossing a 64-byte boundary on the
source level but on the binary level. The foundation to discover
this attack was our extension to cache template attacks, called
Layered Binary Templating Attacks, LBTA. LBTA is a scalable
approach to templating that combines spatial information from
multiple side channels. Using LBTA we scan binaries compiled
with LLVM/clang, which applies deduplication and dead-
stripping by default. Our end-to-end attack is an unprivileged
cache-based keylogger for all Chrome-based / Electron-based
applications, including hundreds of security-critical apps, e.g.,
the popular Signal messenger app. While mitigation strategies
exist, they come at a cost, and further research is necessary
to overcome the open problem of side-channel attacks on user
input.

ACKNOWLEDGMENTS

This work was supported by generous funding and gifts
to thank Hanna M¨uller, Claudio
from Red Hat. We want
Canella, Michael Schwarz and Moritz Lipp for valueable
feedback on an early draft of this work.

13

REFERENCES

[1] Ayush Agarwal, Sioli O’Connell, Jason Kim, Shaked Yehezkel, Daniel
Genkin, Eyal Ronen, and Yuval Yarom. Spook.js: Attacking Chrome
Strict Site Isolation via Speculative Execution. In S&P, 2022.

[2] Anonymous. Blinded for Peer Review, 2022.
[3] Antti Korpi. xkbcat, 2021. URL: https://github.com/anko/xkbcat.
[4] Andrei Bacs, Saidgani Musaev, Kaveh Razavi, Cristiano Giuffrida,
and Herbert Bos. DUPEFS: Leaking Data Over the Network With
Filesystem Deduplication Side Channels. In FAST, 2022.

[5] Maarten Baert. wayland-keylogger, 2022. URL: https://github.com/

Aishou/wayland-keylogger.

[6] Antonio Barresi, Kaveh Razavi, Mathias Payer, and Thomas R. Gross.
CAIN: silently breaking ASLR in the cloud. In WOOT, 2015.
[7] Daniel J. Bernstein. Cache-Timing Attacks on AES, 2005. URL:

http://cr.yp.to/antiforgery/cachetiming-20050414.pdf.

[8] Pietro Borrello, Daniele Cono D’Elia, Leonardo Querzoni, and Cris-
tiano Giuffrida. Constantine: Automatic Side-Channel Resistance
Using Efﬁcient Control and Data Flow Linearization. In CCS, 2021.
[9] Erik Bosman, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida.
Dedup Est Machina: Memory Deduplication as an Advanced Exploita-
tion Vector. In S&P, 2016.

[10] Ferdinand Brasser, Urs M¨uller, Alexandra Dmitrienko, Kari Kosti-
ainen, Srdjan Capkun, and Ahmad-Reza Sadeghi. Software Grand
Exposure: SGX Cache Attacks Are Practical. In WOOT, 2017.

[11] Tegan Brennan, Nicol´as Rosner, and Tevﬁk Bultan.

inducing timing side channels through just-in-time compilation.
S&P, 2020.

JIT Leaks:
In

[12] Robert Brotzman, Shen Liu, Danfeng Zhang, Gang Tan, and Mahmut
Kandemir. CaSym: Cache aware symbolic execution for side channel
detection and mitigation. In S&P, 2019.

[13] Billy Brumley and Risto Hakala. Cache-Timing Template Attacks. In

AsiaCrypt, 2009.

[14] Luigi Bruno. What page replacement algorithms does the windows 7
OS uses?, February 2013. URL: https://social.technet.microsoft.com/
Forums/ie/en-US/e61aef24-38fd-4e7e-a4c1-a50aa226818c.

[15] Sebastien Carre, Victor Dyseryn, Adrien Facon, Sylvain Guilley, and
Thomas Perianin. End-to-end automated cache-timing attack driven
by Machine Learning. Journal of Cryptology, 2019.

[16] Sunjay Cauligi, Craig Disselkoen, Klaus v Gleissenthall, Deian Stefan,
Tamara Rezk, and Gilles Barthe. Towards Constant-Time Foundations
for the New Spectre Era. In PLDI, 2020.

[17] Sunjay Cauligi, Gary Soeller, Fraser Brown, Brian Johannesmeyer,
Yunlu Huang, Ranjit Jhala, and Deian Stefan. FaCT: A ﬂexible,
constant-time programming language. In SecDev, 2017.

[18] CEF. Chrome Embedded Framework, 2022. URL: https://github.com/

chromiumembedded/cef.

[19] Suresh Chari, Josyula R Rao, and Pankaj Rohatgi. Template attacks.

In CHES, 2002.

[20] Chromium. Speeding up Chrome’s release cycle, 2022. URL: https:
//blog.chromium.org/2021/03/speeding-up-release-cycle.html.
[21] Szu-Chi Chung, Jen-Wei Lee, Hsie-Chia Chang, and Chen-Yi Lee. A
high-performance elliptic curve cryptographic processor over GF(p)
In International Symposium on Circuits and
with SPA resistance.
Systems (ISCAS), 2012.

[22] Bart Coppens, Ingrid Verbauwhede, Koen De Bosschere, and Bjorn
De Sutter. Practical mitigations for timing-based side-channel attacks
on modern x86 processors. In S&P, 2009.

[23] Andreas Costi, Brian Johannesmeyer, Erik Bosman, Cristiano Giuf-
frida, and Herbert Bos. On the effectiveness of same-domain memory
deduplication. In European Workshop on Systems Security, pages 29–
35, 2022.

[24] Stephen Crane, Andrei Homescu, Stefan Brunthaler, Per Larsen, and
Michael Franz. Thwarting Cache Side-Channel Attacks Through
Dynamic Software Diversity. In NDSS, 2015.

[25] Fergus Dall, Gabrielle De Micheli, Thomas Eisenbarth, Daniel Genkin,
Nadia Heninger, Ahmad Moghimi, and Yuval Yarom. Cachequote:
Efﬁciently recovering long-term secrets of SGX EPID via cache
attacks. In CHES, 2018.

14

[26] Wenrui Diao, Xiangyu Liu, Zhou Li, and Kehuan Zhang. No Pardon
for the Interruption: New Inference Attacks on Android Through
Interrupt Timing Analysis. In S&P, 2016.

[27] Lizzie Dixon. Breaking KASLR with perf, 2017. URL: https://blog.

lizzie.io/kaslr-and-perf.html.

[28] Christopher Domas. M/o/Vfuscator, 2015. URL: https://github.com/

xoreaxeaxeax/movfuscator.

[29] Goran Doychev, Dominik Feld, Boris Kopf, Laurent Mauborgne, and
Jan Reineke. CacheAudit: A Tool for the Static Analysis of Cache
Side Channels. In USENIX Security Symposium, 2013.

[30] Electron. Electron Apps, 2022. URL: https://www.electronjs.org/apps.

[31] Electron JS.

Electron Internals: Building Chromium as a Li-
brary, 2022. URL: https://www.electronjs.org/blog/electron-internals-
building-chromium-as-a-library.

[32] Yangchun Fu, Erick Bauman, Raul Quinonez, and Zhiqiang Lin.
SGX-LAPD: Thwarting Controlled Side Channel Attacks via Enclave
Veriﬁable Page Faults. In RAID, 2017.

[33] Cesar Pereida Garc´ıa and Billy Bob Brumley. Constant-Time Callees

with Variable-Time Callers. In USENIX Security Symposium, 2017.

[34] Mel Gorman. Understanding the Linux Virtual Memory Manager.

Prentice Hall Upper Saddle River, 2004.

[35]

Johannes G¨otzfried, Moritz Eckert, Sebastian Schinzel, and Tilo
M¨uller. Cache Attacks on Intel SGX. In EuroSec, 2017.

[36] Ben Gras, Kaveh Razavi, Erik Bosman, Herbert Bos, and Cristiano
Giuffrida. ASLR on the Line: Practical Cache Attacks on the MMU.
In NDSS, 2017.

[37] Daniel Gruss, David Bidner, and Stefan Mangard. Practical Memory
Deduplication Attacks in Sandboxed JavaScript. In ESORICS, 2015.
[38] Daniel Gruss, Erik Kraft, Trishita Tiwari, Michael Schwarz, Ari
Trachtenberg, Jason Hennessey, Alex Ionescu, and Anders Fogh. Page
Cache Attacks. In CCS, 2019.

[39] Daniel Gruss, Cl´ementine Maurice, Anders Fogh, Moritz Lipp, and
Stefan Mangard. Prefetch Side-Channel Attacks: Bypassing SMAP
and Kernel ASLR. In CCS, 2016.

[40] Daniel Gruss, Raphael Spreitzer, and Stefan Mangard. Cache Template
Attacks: Automating Attacks on Inclusive Last-Level Caches.
In
USENIX Security Symposium, 2015.

[41] David Gullasch, Endre Bangerter, and Stephan Krenn. Cache Games
– Bringing Access-Based Cache Attacks on AES to Practice. In S&P,
2011.

[42] Berk Gulmezoglu, Mehmet Sinan Inci, Gorka Irazoqui, Thomas Eisen-
IEEE
barth, and Berk Sunar. Cross-VM cache attacks on AES.
Transactions on Multi-Scale Computing Systems, 2(3):211–222, 2016.
[43] Berk G¨ulmezo˘glu, Mehmet Sinan Inci, Thomas Eisenbarth, and Berk
Sunar. A Faster and More Realistic Flush+Reload Attack on AES. In
COSADE, 2015.
halolinux. Page Cache Readahead, 2022. URL: https://www.halolinux.
us/kernel-architecture/page-cache-readahead.html.

[44]

[45] Danny Harnik, Benny Pinkas, and Alexandra Shulman-Peleg. Side
channels in cloud services, the case of deduplication in cloud storage.
IEEE Security & Privacy, (6), 2010.

[46] Ralf Hund, Carsten Willems, and Thorsten Holz. Practical Timing

Side Channel Attacks against Kernel Space ASLR. In S&P, 2013.

[47] Mehmet Sinan Inci, Berk Gulmezoglu, Gorka Irazoqui, Thomas Eisen-
barth, and Berk Sunar. Seriously, get off my cloud! Cross-VM RSA
Key Recovery in a Public Cloud. Cryptology ePrint Archive, Report
2015/898, 2015.

[48] Mehmet Sinan Inci, Berk Gulmezoglu, Gorka Irazoqui, Thomas Eisen-
barth, and Berk Sunar. Cache Attacks Enable Bulk Key Recovery on
the Cloud. In CHES, 2016.

[49] Song Jiang, Feng Chen, and Xiaodong Zhang. CLOCK-Pro: An
Effective Improvement of the CLOCK Replacement. In USENIX ATC,
2005.

[50]

[51]

John Richard Moser. Optimizing Linker Load Times, 2006. URL:
https://lwn.net/Articles/192624/.

Jonathan Corbet. Fixing page-cache side channels, second attempt,
2019. URL: https://lwn.net/Articles/778437/.

[52] Marc Joye and Sung-Ming Yen. The Montgomery powering ladder.

In CHES, 2002.

[53] Sriram Keelveedhi, Mihir Bellare, and Thomas Ristenpart. DupLESS:
In USENIX

Server-Aided Encryption for Deduplicated Storage.
Security Symposium, 2013.

[54] Taehun Kim, Taehyun Kim, and Youngjoo Shin. Breaking KASLR Us-
ing Memory Deduplication in Virtualized Environments. Electronics,
10(17), 2021.

[55] Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss,
Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas
Prescher, Michael Schwarz, and Yuval Yarom.
Spectre Attacks:
Exploiting Speculative Execution. In S&P, 2019.

[56] Paul C. Kocher. Timing Attacks on Implementations of Diffe-Hellman,

[57]

RSA, DSS, and Other Systems. In CRYPTO, 1996.
Jakob Koschel, Cristiano Giuffrida, Herbert Bos, and Kaveh Razavi.
TagBleed: Breaking KASLR on the Isolated Kernel Address Space
Using Tagged TLBs. In EuroS&P, 2020.

[58] Nate Lawson. Side channel attacks on cryptographic software. IEEE

Security & Privacy, 7(6):65–68, 2009.

[59] Guanlin Li, Chang Liu, Han Yu, Yanhong Fan, Libang Zhang, Zongyue
Wang, and Meiqin Wang. SCNet: A Neural Network for Automated
Side-Channel Attack. arXiv:2008.00476, 2020.

[60] Moritz Lipp, Daniel Gruss, and Michael Schwarz. AMD Prefetch
In USENIX Security Symposium,

Attacks through Power and Time.
2022.

[61] Moritz Lipp, Daniel Gruss, Raphael Spreitzer, Cl´ementine Maurice,
and Stefan Mangard. ARMageddon: Cache Attacks on Mobile
Devices. In USENIX Security Symposium, 2016.

[62] Cl´ementine Maurice, Manuel Weber, Michael Schwarz, Lukas Giner,
Daniel Gruss, Carlo Alberto Boano, Stefan Mangard, and Kay R¨omer.
Hello from the Other Side: SSH over Robust Cache Covert Channels
in the Cloud. In NDSS, 2017.

[63] Marcel Medwed and Elisabeth Oswald. Template attacks on ECDSA.

In WISA. Springer, 2008.

[64] Memcached. memcached - a distributed memory object caching

system, 2020. URL: https://memcached.org/.

[65] Ahmad Moghimi, Gorka

and Thomas Eisenbarth.
Irazoqui,
CacheZoom: How SGX ampliﬁes the power of cache attacks.
In CHES, 2017.

[66] MySQL.

URL:
structure.html.

The Physical Structure of an InnoDB Index, 2020.
https://dev.mysql.com/doc/refman/8.0/en/innodb-physical-

[67] Hoda Naghibijouybari, Ajaya Neupane, Zhiyun Qian, and Nael Abu-
Ghazaleh. Rendered Insecure: GPU Side Channel Attacks are Practi-
cal. In CCS, 2018.

[68] nginx. Advanced Load Balancer, Web Server, & Reverse Proxy -

[69]

NGINX, 2021. URL: https://www.nginx.com/.
nxmnpg.lemoda. Manual Pages - LD.LLD, 2022. URL: https:
//nxmnpg.lemoda.net/1/ld.lld.

[70] Yossef Oren, Vasileios P Kemerlis, Simha Sethumadhavan, and Ange-
los D Keromytis. The Spy in the Sandbox: Practical Cache Attacks
in JavaScript and their Implications. In CCS, 2015.

[71] Dag Arne Osvik, Adi Shamir, and Eran Tromer. Cache Attacks and

Countermeasures: the Case of AES. In CT-RSA, 2006.

[72] Riccardo Paccagnella, Licheng Luo, and Christopher W Fletcher. Lord
of the Ring(s): Side Channel Attacks on the CPU On-Chip Ring
Interconnect Are Practical. In USENIX Security Symposium, 2021.

[73] Dan Page. Theoretical Use of Cache Memory as a Cryptanalytic Side-
Channel. Cryptology ePrint Archive, Report 2002/169, 2002.
[74] Dan Page. A note on side-channels resulting from dynamic compila-

tion. Cryptology ePrint archive, Report 2006/349, 2006.

[75] Colin Percival. Cache Missing for Fun and Proﬁt. In BSDCan, 2005.
[76] Cesar Pereida Garc´ıa, Billy Bob Brumley, and Yuval Yarom. Make
Sure DSA Signing Exponentiations Really Are Constant-Time.
In
CCS, 2016.

[77] Ashay Rane, Calvin Lin, and Mohit Tiwari. Raccoon: Closing Digital
In USENIX Security

Side-Channels through Obfuscated Execution.
Symposium, 2015.

15

[78] Kaveh Razavi, Ben Gras, Erik Bosman, Bart Preneel, Cristiano Giuf-
frida, and Herbert Bos. Flip Feng Shui: Hammering a Needle in the
Software Stack. In USENIX Security Symposium, 2016.

[79] Christian Rechberger and Elisabeth Oswald. Practical template attacks.

In WISA, 2004.

[80] Redis.

memtier benchmark: A High-Throughput Bench-
URL:

for Redis & Memcached,

marking Tool
https://redis.com/blog/memtier benchmark-a-high-throughput-
benchmarking-tool-for-redis-memcached.

2013.

[81] Thomas Ristenpart, Eran Tromer, Hovav Shacham, and Stefan Savage.
Hey, You, Get Off of My Cloud: Exploring Information Leakage in
Third-Party Compute Clouds. In CCS, 2009.

[82] Stephen R¨ottger.

Escaping the Chrome Sandbox with RIDL,
2020. URL: https://googleprojectzero.blogspot.com/2020/02/escaping-
chrome-sandbox-with-ridl.html.

[83] Rui Ueyama.

lld: A Fast, Simple and Portable Linker, 2017. URL:

https://llvm.org/devmtg/2017-10/slides/Ueyama-lld.pdf.

[84] Mark E Russinovich, David A Solomon, and Alex Ionescu. Windows

internals. Pearson Education, 2012.

[85] Gururaj Saileshwar, Christopher W Fletcher, and Moinuddin Qureshi.
Streamline: a fast, ﬂushless cache covert-channel attack by enabling
asynchronous collusion. In ASPLOS, 2021.

[86] Michael Schwarz, Daniel Gruss, Samuel Weiser, Cl´ementine Maurice,
and Stefan Mangard. Malware Guard Extension: Using SGX to
Conceal Cache Attacks. In DIMVA, 2017.

[87] Michael Schwarz, Florian Lackner, and Daniel Gruss. JavaScript Tem-
plate Attacks: Automatically Inferring Host Information for Targeted
Exploits. In NDSS, 2019.

[88] Michael

Lipp,
Canella.
Schwarz, Moritz
misc0110/PTEditor: A small
library to modify all page-table
levels of all processes from user space for x86 64 and ARMv8, 2018.
URL: https://github.com/misc0110/PTEditor.

Claudio

and

[89] Michael Schwarz, Moritz Lipp, Daniel Gruss, Samuel Weiser,
Cl´ementine Maurice, Raphael Spreitzer,
and Stefan Mangard.
KeyDrown: Eliminating Software-Based Keystroke Timing Side-
Channel Attacks. In NDSS, 2018.

[90] Martin Schwarzl, Pietro Borrello, Andreas Kogler, Kenton Varda,
Thomas Schuster, Daniel Gruss, and Michael Schwarz. Dynamic
process isolation. arXiv preprint arXiv:2110.04751, 2021.

[91] Martin Schwarzl, Claudio Canella, Daniel Gruss, and Michael
Schwarz. Specfuscator: Evaluating Branch Removal as a Spectre
Mitigation. In FC, 2021.

[92] Martin Schwarzl, Erik Kraft, Moritz Lipp, and Daniel Gruss. Remote

Page Deduplication Attacks. In NDSS, 2022.

[93] Ming-Wei Shih, Sangho Lee, Taesoo Kim, and Marcus Peinado. T-
SGX: Eradicating controlled-channel attacks against enclave programs.
In NDSS, 2017.

[94] Laurent Simon, David Chisnall, and Ross Anderson. What you get is
what you C: Controlling side effects in mainstream C compilers. In
EuroS&P, 2018.

[95] Dawn Xiaodong Song, David Wagner, and Xuqing Tian. Timing
In USENIX

Analysis of Keystrokes and Timing Attacks on SSH.
Security Symposium, 2001.

[96]

statcounter Global Stats. Browser Market Share Worldwide, 2022.
URL: https://gs.statcounter.com/.

[97] Stephen R¨ottger and Artur Janc. A Spectre proof-of-concept for a
Spectre-proof web, 2021. URL: https://security.googleblog.com/2021/
03/a-spectre-proof-of-concept-for-spectre.html.

[98] Kuniyasu Suzaki, Kengo Iijima, Toshiki Yagi, and Cyrille Artho.
In EuroSys,

Memory Deduplication as a Threat to the Guest OS.
2011.

[99] Yukiyasu Tsunoo, Teruo Saito, and Tomoyasu Suzaki. Cryptanalysis
of DES implemented on computers with cache. In CHES, 2003.

[100]

Jo Van Bulck, Nico Weichbrodt, R¨udiger Kapitza, Frank Piessens, and
Raoul Strackx. Telling Your Secrets Without Page Faults: Stealthy
Page Table-Based Attacks on Enclaved Execution. In USENIX Security
Symposium, 2017.

[101]

Jeroen Van Cleemput, Bjorn De Sutter, and Koen De Bosschere.
Adaptive compiler strategies for mitigating timing side channel attacks.
TDSC, 2017.

[102] Stephan Van Schaik, Cristiano Giuffrida, Herbert Bos, and Kaveh
Razavi. Malicious Management Unit: Why Stopping Cache Attacks in
Software is Harder Than You Think. In USENIX Security Symposium,
2018.

[103] Stephan van Schaik, Alyssa Milburn, Sebastian ¨osterlund, Pietro
Frigo, Giorgi Maisuradze, Kaveh Razavi, Herbert Bos, and Cristiano
Giuffrida. RIDL: Rogue In-ﬂight Data Load. In S&P, 2019.
[104] Pepe Vila, Boris K¨opf, and Jose Morales. Theory and Practice of

Finding Eviction Sets. In S&P, 2019.

[105] Vish Viswanathan. Disclosure of Hardware Prefetcher Control on
Some Intel Processors, 2014. URL: https://web.archive.org/web/
20160304031330/https://software.intel.com/en-us/articles/disclosure-
of-hw-prefetcher-control-on-some-intel-processors.

[106] Ahsan Wajahat, Azhar Imran, Jahanzaib Latif, Ahsan Nazir, and Anas
In

Bilal. A Novel Approach of Unprivileged Keylogger Detection.
iCoMET, 2019.

[107] Daimeng Wang, Ajaya Neupane, Zhiyun Qian, Nael Abu-Ghazaleh,
Srikanth V Krishnamurthy, Edward JM Colbert, and Paul Yu. Unveil-
ing your keystrokes: A Cache-based Side-channel Attack on Graphics
Libraries. In NDSS, 2019.

[108] Shuai Wang, Pei Wang, Xiao Liu, Danfeng Zhang, and Dinghao Wu.
{CacheD}: Identifying {Cache-Based} timing channels in production
software. In USENIX, 2017.

[109] Webnicer Ltd. chrome-downloads, 2022. URL: https://github.com/

webnicer/chrome-downloads/.

[111]

[110] Samuel Weiser, Raphael Spreitzer, and Lukas Bodner. Single Trace
Attack Against RSA Key Generation in Intel SGX SSL. In AsiaCCS,
2018.
Jan Wichelmann, Ahmad Moghimi, Thomas Eisenbarth, and Berk
Sunar. MicroWalk: A Framework for Finding Side Channels in
Binaries. In ACSAC, 2018.
Jidong Xiao, Zhang Xu, Hai Huang, and Haining Wang. Security
implications of memory deduplication in a virtualized environment.
In International Conference on Dependable Systems and Networks
(DSN), 2013.

[112]

[113] Yuanzhong Xu, Weidong Cui, and Marcus Peinado. Controlled-
Channel Attacks: Deterministic Side Channels for Untrusted Operating
Systems. In S&P, 2015.

[114] Yunjing Xu, Michael Bailey, Farnam Jahanian, Kaustubh Joshi, Matti
Hiltunen, and Richard Schlichting. An exploration of L2 cache covert
channels in virtualized environments. In CCSW, 2011.

[115] Yuval Yarom and Katrina Falkner. Flush+Reload: a High Resolution,
In USENIX Security

Low Noise, L3 Cache Side-Channel Attack.
Symposium, 2014.

[116] Yuanyuan Yuan, Qi Pang, and Shuai Wang. Automated side channel
analysis of media software with manifold learning. arXiv preprint
arXiv:2112.04947, 2021.

[117] Kehuan Zhang and XiaoFeng Wang. Peeping Tom in the Neighbor-
hood: Keystroke Eavesdropping on Multi-User Systems. In USENIX
Security Symposium, 2009.

APPENDIX

The cache hit ratio for all lowercase characters with Flush+
Reload can be seen with Figure 10 and all alphanumeric
characters for the page cache attack Figure 9.

16

a

98

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

c

0

0

95

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

d

0

0

0

99

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

e

0

0

0

0

98

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

f

0

0

0

0

0

97

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

g

0

0

0

0

0

0

98

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

i

0

0

0

0

0

0

0

0

99

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

j

0

0

0

0

0

0

1

0

0

100

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

k

0

0

0

0

0

0

0

0

0

0

98

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

l

0

0

0

0

0

0

0

0

0

0

0

91

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

n

0

0

0

0

0

0

0

0

0

0

0

0

0

97

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

o

0

0

0

0

0

0

0

0

0

0

0

0

0

0

94

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

p

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

99

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

q

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

100

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

r

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

97

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

s

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

97

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

t

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

96

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

u

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

98

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

v

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

93

0

0

0

0

0

0

0

0

0

0

0

0

0

0

w

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

99

0

0

0

0

0

0

0

0

0

0

0

0

0

z

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

98

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

98

0

0

0

0

0

0

0

0

0

1

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

99

0

0

0

0

0

0

0

0

2

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

97

0

0

0

0

0

0

0

3

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

98

0

0

0

0

0

0

4

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

97

0

0

0

0

0

5

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

97

0

0

0

0

6

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

98

0

0

0

7

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

97

0

0

8 bm9hyx

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

100

2

100

0

0

1

0

1

100

0

0

2

6

100

2

1

1

0

1

1

2

1

1

1

100

100

1

1

1

3

1

1

2

0

0

0

0

100

0x14e7000

0x14e2000

0x14df000

0x14d2000

0x14c1000

0x14c0000

0x14be000

0x14bc000

0x14bb000

0x14ba000

0x14b9000

0x14b3000

0x14af000

0x14ab000

0x14aa000

0x14a9000

0x14a8000

0x14a2000

0x149b000

0x1494000

0x1492000

0x148f000

0x148e000

0x148c000

0x148b000

0x148a000

0x1521000

0x151b000

0x1513000

0x1510000

0x150d000

0x150b000

0x1509000

0x1508000

0x1506000

0x1505000

Fig. 9: Cache-hit ratio using a page cache attack for alphanumeric characters in Google Chrome.

17

0x14e7e5b

0x14e24a8

0x14df043

0x14d2ab9

0x14c1a5e

0x14c0a76

0x14be05f

0x14bc5ad

0x14bb06c

0x14bae3b

0x14b981f

0x14b3350

0x14af573

0x14ab755

0x14aa938

0x14a9172

0x14a8e1c

0x14a2f87

0x149b36d

0x149411c

0x1492c1d

0x148f151

0x148e546

0x148cb27

0x148b08b

0x148ac19

a

99

2

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

b

1

178

0

0

1

0

0

0

0

0

1

0

1

0

0

0

0

1

0

0

1

0

0

0

0

0

c

0

0

151

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

d

0

0

0

173

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

e

0

0

0

0

101

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

f

0

0

0

0

0

100

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

g

0

0

0

0

0

0

96

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

h

1

0

0

0

0

0

0

169

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

i

0

0

0

0

0

0

0

0

114

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

j

0

0

0

0

0

0

0

0

0

156

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

k

0

0

0

0

0

0

0

0

0

0

171

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

l

0

0

0

0

0

0

0

0

0

0

0

146

0

0

0

0

0

0

0

0

0

0

0

0

0

0

m

0

0

0

0

0

0

0

0

0

0

0

0

125

0

0

0

0

0

0

0

0

0

0

0

0

0

n

0

0

0

0

0

0

0

0

0

0

0

0

0

148

0

0

0

0

0

0

0

0

0

0

0

0

o

0

0

0

0

0

0

0

0

0

0

0

0

0

0

165

0

0

0

0

0

0

0

0

0

0

0

p

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

87

q

2

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

15

156

r

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

141

0

0

0

0

0

0

0

0

s

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

108

0

0

0

0

0

0

0

t

2

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

157

0

0

0

0

0

0

u

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

135

0

0

0

0

0

v

0

0

0

0

0

0

1

0

0

0

0

0

0

1

0

0

0

0

0

0

0

107

0

0

0

0

w

8

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

124

0

0

0

x

7

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

138

0

0

Fig. 10: Cache-hit ratio using Flush+Reload for lowercase letters in Google Chrome.

y

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

137

z

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

141

18

