Autonomous Intelligent Software Development

Mark Alan Matties
The Johns Hopkins Applied Physics Lab
11100 Johns Hopkins Rd.
Laurel, MD 20723
mark.matties@jhuapl.edu

2
2
0
2

g
u
A
2
1

]
I

A
.
s
c
[

1
v
3
9
3
6
0
.
8
0
2
2
:
v
i
X
r
a

Abstract

We present an overview of the design and ﬁrst proof-of-
concept implementation for AIDA, an autonomous intelligent
developer agent that develops software from scratch. AIDA
takes a software requirements speciﬁcation and uses reason-
ing over a semantic knowledge graph to interpret the re-
quirements, then designs and writes software to satisfy them.
AIDA uses both declarative and procedural knowledge in the
core domains of data, algorithms, and code, plus some gen-
eral knowledge. The reasoning codebase uses this knowledge
to identify needed components, then designs and builds the
necessary information structures around them that become
the software. These structures, the motivating requirements,
and the resulting source code itself are all new knowledge
that are added to the knowledge graph, becoming available
for future reasoning. In this way, AIDA also learns as she
writes code and becomes more efﬁcient when writing subse-
quent code.

Introduction
Software development as practiced today is still a largely
manual activity that is time consuming, costly, and error
prone, depending on the skill of the human software devel-
opers (“developers”). All good, competent software devel-
opment requires a high level of skill, but much of the “day
to day”, routine programming is not necessarily creative. It
is done by employing well used patterns across a range of
detail levels, from the very high-level of overall program de-
sign to very low-level of writing syntactically correct state-
ments. Oftentimes, the only meaningful variation from one
program to the next is some context, such as the variable
names chosen based on the type of data they hold. If these
patterns can be encoded and the contextual variations dis-
cerned and addressed, we claim that much of routine soft-
ware development can be fully automated, taking the human
completely out of the writing code loop.

These characteristics make software development ripe for
intelligent automation. Limited progress has already been
made in the forms of (1) code templating, (2) “intelligent”
completion, and (3) some early forays into machine learning
(ML) systems that write code. Code templating is usually
targeted, and even wide-scale code reuse remains a largely

© 2023 The Johns Hopkins University Applied Physics Laboratory
LLC.

unfulﬁlled promise. Intelligent completion systems like Kite
(Kite) and Copilot (GitHub Copilot) use ML models to re-
duce the amount of typing a developer must do by guess-
ing what she intended to type and ﬁlling it in, reducing the
amount of typing she must actually do. However, neither re-
moves her from the loop. Rather, they seem to turn her into
a real-time reviewer/debugger of the “completer’s” code. A
“Frequently asked questions” section of the Copilot website
states that “In a recent evaluation, we found that users ac-
cepted on average 26% of all completions shown by GitHub
Copilot.” (GitHub Copilot FAQ) So, in practice, the beneﬁt
is questionable.

Platforms that use ML models to write code, such as Ope-
nAI Codex (OpenAI Codex), are still bound by the inherent
limitations of ML. They include the requirement of a very
large training data set of (existing) code samples, some of
which may be of questionable quality, and that ML meth-
ods are generally much better at interpolating than extrap-
olating. In this context, interpolating translates to copying
“known” (ie, learned through training) code structures with
limited variation rather than creating new code structures,
which would translate to extrapolating. Importantly, they do
not easily permit the introduction of new program structures
or programming patterns, and certainly without a large li-
brary of existing samples and retraining of the model.

The ﬁrst two approaches (templating and completion) still
require a great deal of typing by developers to customize
parts of what automatically gets ﬁlled in. Picking variable
names or stringing together function calls of the imple-
mented algorithms are not exercises in creativity, as they also
follow patterns that draw from general knowledge. The third
approach is still early in its exploration, but has some under-
lying limitations.

These constraints and deﬁciencies provide the motivation
for AIDA, the autonomous intelligent developer agent. The
overarching goal of AIDA (“aye-ee-duh”) is to produce
software at the level of an expert human developer, given
only a problem statement or set of requirements. AIDA rea-
sons over encoded knowledge to build information struc-
tures, which in turn become part of her available knowledge.
Much of the knowledge is speciﬁc and deals in patterns of
various kinds across multiple scales of detail. Some of it
is simply general and allows AIDA to ﬁnd and use needed
components or add customized stylistic qualities.

 
 
 
 
 
 
AIDA writes code from scratch using semantic reasoning
in a top-down approach. She reasons from general to more
speciﬁc terms about how to develop software, rather than
blindly following patterns gleaned from a multitude of code
samples. This approach enables AIDA to not only write cor-
rect, high-quality code, but also to easily incorporate style
elements using general knowledge. Ultimately, AIDA’s pur-
pose is to empower anyone who needs software but is not a
programmer to create high quality software very quickly and
at a very low cost simply by providing proper requirements.
In this paper, we present an overview of the design and
ﬁrst working version of AIDA. This version is intended to
explore whether our approach is at all feasible, and so the
knowledge currently encoded, especially the programming
patterns, are necessarily limited. We believe that our ap-
proach is generalizable and extendable to fuller, much richer
representations that will lead to creating substantial analytic
software that is useful for real world applications.

Background

Semantic Reasoning
In this paper, we view semantic reasoning broadly as the
processing of linguistically meaningful information using
methods drawn from the ﬁeld of logic. We are especially
interested in the now popular knowledge graph (Singhal
2012; Ehrlinger and W¨oß 2016) approach, which views in-
formation in terms of entities and the relationships between
them. Two entities linked by a relationship forms a state-
ment to which one can assign a truth value. By virtue of be-
ing in the knowledge graph, the statement has a truth value
of “True”. This view naturally lends itself to a graphical
representation, where the entities are nodes and their rela-
tionships are edges, hence the knowledge graph paradigm.
Currently, there are a few different forms that a knowledge
graph can take in practice. We use the one where a knowl-
edge graph is built up from OWL2 (W3C 2012) description
logic (Kr¨otzsch, Simancik, and Horrocks 2012) ontologies,
which, in this work, we construct from expert human knowl-
edge.

We import

the ontologies into the knowledge graph,
where they serve as a sort of schema. The knowledge graph
is progressively built out through the addition of of knowl-
edge (“instance” data) according to the structure deﬁned in
the ontologies. In addition to the graph itself, a semantic
reasoning platform requires a reasoning codebase, which
reads information from the knowledge graph, performs the
logic operations, eg, inference, and (possibly) inserts new
information back into the knowledge graph. For AIDA, the
knowledge graph and speciﬁc reasoning codebase are inex-
tricably interwoven.

Encoding Knowledge for Semantic Reasoning
As currently practiced, knowledge graphs encode only
declarative knowledge (“knowing-that”), which one can
view as “simple facts”. For example, we can create two log-
ical statements (in subject predicate object format)
Detroit
Michigan

Walter_Pitts
Detroit

born-in
city-in

and assign the value true to each of them. In practice, any
information encoded in such a knowledge graph is taken to
be true by virtue of its inclusion and does not change unless
it is later shown, in fact, to be false. Hopefully, such cases
are rare. Then, a knowledge graph is mostly static unless
new facts are added to it.

In addition to declarative knowledge, epistemology en-
tails the study of procedural knowledge (“knowing-how”)
(Pavese 2022). Encoding procedural knowledge is challeng-
ing because, as we learn from introductory logic courses,
we may assign a truth value only to declarative statements,
and so use them in logical reasoning. We normally think of
procedural knowledge in terms of imperative statements, eg,
“drive three miles, make a right turn, drive two more miles,
look to your left”. Unfortunately, imperative statements can-
not have a truth value and so cannot be used in logic, at
least in that form. However, “knowledge” about “how to do
things” is implicitly encoded in the reasoning codebase that
works with the knowledge graph proper. If we can recast
procedural knowledge, as least in part, into declarative state-
ments, we can move that part of it into the knowledge graph.
Through this addition of procedural knowledge to seman-
tic reasoning, AIDA can build information structures, not
just infer and report back simple facts. As far as we know,
this approach to explicitly encode some part of procedural
knowledge in the ontologies is novel.

Design and Architecture

Design Considerations
First and foremost, AIDA must write code that is both tech-
nically and contextually correct. By technically correct, we
mean that the resulting code must run without error and pro-
duce correct results as stated in the requirements. It must be
veriﬁable by current conventional means. We expect that un-
til AIDA gains some level of trust from users, any software
she writes would be subjected to code reviews by people.
So, it must be readable by people without undue cognitive
strain.

By contextually correct, we mean that stylistic elements
should conform to accepted standards and/or stated pref-
erences, such as would be found in a style guide. For ex-
ample, labels such as variable names should be chosen
that are meaningful in context while also conforming to
programming language constraints, such as a maximum
character length. A variable in a Python program hold-
ing the value of a temperature reading should be named
“current temperature” not “T”. Other contextual el-
ements include (1) customizable ordering, such as the order
of listing imported code libraries (eg, alphabetical by library
name), (2) use of name aliases, and (3) even preferred pat-
terns or structures, eg, using list comprehension in Python.

Finally, the code must be easy to maintain, so documen-
tation is a key element. Any documentation must be an inte-
grated part of the software AIDA develops. Using the knowl-
edge graph, the documentation can be co-located with the re-
quirements, any and all built structures, and the source code
itself. Documentation then need not be slapped together as
an afterthought, but can be built and modiﬁed in real time

requires that knowledge as well. We only brieﬂy describe
knowledge about algorithms here, deferring the details to a
future manuscript. We can include the more detailed knowl-
edge in the future, when it becomes useful. Then, she should
be able to mix and match individual operations and develop
variations on algorithms, if not entirely new ones.

Of course, AIDA must know about code – not only about
low-level, detailed programming language structures and
when to use them, but also about high-level, programming
language agnostic information, such as gross program struc-
ture. In fact, all programming language structures are im-
plementations of abstracted ones that are language agnostic.
AIDA exploits this relationship and deals in both.

As shown in Figure 1, AIDA takes in a problem state-
ment and analyzes it to determine what program to write.
The problem statement must specify some minimal infor-
mation about the desired program, especially what output is
needed from it. A user might also state what input data or al-
gorithms to use in either speciﬁc or general terms. For exam-
ple, “use the data set with name my input.txt and cal-
culate the average value of the data with an error estimate”.
The ”data set” part of the speciﬁcation is quite speciﬁc. The
”calculate” part of it actually states both the desired output
and (indirectly) the type of algorithm to use. It is somewhat
more general and descriptive of the kind of algorithm to use
(such as average value), rather than naming a speciﬁc one
(such as arithmetic mean or geometric mean). Likewise, the
user may state desired aspects of the desired software itself.
Usually, the user should at least specify the programming
paradigm, such as imperative/procedural, and one or more
programming languages into which AIDA should render the
program, such as Python or Python-3.8.10. The user might
also specify a preference for a certain external code library,
such as NumPy. These are just a few simple examples of
many possible variations.

If AIDA ﬁnds multiple matches for any of these speciﬁ-
cations, she must have some criteria to choose among them.
The criteria could also be speciﬁed by the user, or AIDA
could know about default selection criteria. While we try to
keep code details separated from data and algorithms, some
dependency is inevitable for highest efﬁciency. For example,
selection criteria might be to choose the data whose source
is compatible with, ie, can be read by, a given code func-
tion. Or, the user might specify that the least expensive data
source be used, if monetary cost of the data were an attribute
known to AIDA. For algorithms, a common criterion is the
time complexity of the algorithm, though other efﬁciency
metrics are possible.

Architecture of Information Structures
All programming languages (PLs) provide a means to render
a set of abstract information structures into runnable code.
Which structures to use and how to arrange them is driven by
both hard and soft constraints. Oftentimes, a given PL is de-
signed for a certain programming paradigm, such as proce-
dural or object oriented. The choice of a particular paradigm
drives much of the overall structure of the software and, ul-
timately, the PL choice. Regardless, the PL will implement
all abstract structures necessary to render source code in that

Figure 1: A high-level view of the AIDA architecture.

as the software is built. As natural language generation im-
proves and matures, we expect that AIDA can even interface
with it to write user guides by providing context-aware in-
formation to it.

Architecture Considerations

Since AIDA must build software from knowledge about how
to build software, we took a semantic reasoning design ap-
proach that has been extended to use both declarative and
procedural knowledge, as shown in Figure 1. Both core and
general knowledge are explicitly encoded in a set of ontolo-
gies that are imported into and form the basis of the knowl-
edge graph. How and when to use that knowledge is implic-
itly encoded in the reasoning codebase. It consists of a set of
SPARQL queries to read from and write to the knowledge
graph, as well as the code to perform these actions and ma-
nipulate the results. Both components - the knowledge graph
and the reasoning codebase - form the extended semantic
reasoning platform that is AIDA.

The three “pillars” of AIDA’s core knowledge are data,
algorithms, and code. Her core knowledge is in those do-
mains that are speciﬁcally tied to writing software. In our
view, nearly all software exists to take some input, apply
one or more algorithms to it, and transform the input to some
output. In the current version of AIDA, the input comes from
some external data source, such as a data ﬁle. Before starting
to write code, AIDA must have detailed, speciﬁc knowledge
about the needed data - what it describes, how and where
to get it, its format, the nature of it content, etc. Likewise,
she must have speciﬁc information about algorithms - what
kind of transformation they perform, what are their input and
output types, what are their time and/or space complexities,
etc. Note that AIDA does not store any raw data, as shown in
Figure 1. Doing so would quickly overwhelm her knowledge
base, making it unusable. Rather, she holds all the detailed
metadata that one would need to use the data when writing
software and the data resides wherever it resides external to
her, including a description of (ie, pointer to) that location.
For algorithms, AIDA currently encodes knowledge
about how and when to use them, not any detail about their
constituent operations. This knowledge includes the type of
algorithm across several different aspects, the purpose of it,
ie, “type of calculation” it performs, the required inputs, and
the output it produces. Other knowledge, such as algorith-
mic complexity, is included as well. Again, all the meta-
data a developer would need to choose an algorithm, AIDA

an ontology, especially its object properties, is driven by its
intended application. It seems to us that the intended appli-
cation of many published ontologies is to demonstrate that
their authors are experts in the hierarchy of some ﬁeld, as
they are too often little more than taxonomies. We believe
the real power of an ontology comes from its “cross-branch”
relationships (expressed as object and datatype properties),
not its taxonomic hierarchy.

The criteria of which attributes of which entities should be
matched for which purposes is currently held in the logic of
the reasoning codebase. As described above, AIDA’s proce-
dural knowledge is currently spread across both the KG and
the RC. The part of the procedural knowledge that is about
the structures of the processes, such as the names of their
constituent steps and, especially, their order of execution are
held in the knowledge graph. The statements that execute
the constituent steps are still encoded in the reasoning code-
base. We are actively working on how to cast all procedural
knowledge so that it can be encoded to the greatest degree
possible in the KG.

To encode the necessary knowledge, we took the design
goals described above and created a set of OWL2 ontolo-
gies covering the domains of data, algorithms, and code,
as well as some supporting ontologies containing general
knowledge. For our manageability, we break the ontologies
up into smaller units (ie, ﬁles) that are cross-linked through
inclusion of others’ entities and relationships. All ontology
ﬁles are imported into AIDA’s graph database to form her
initial knowledge graph. Figure 2 shows the core ontologies
we created for the ﬁrst prototype implementation. (There
are several other supporting ontologies that provide general
knowledge about what is a quantity, a value, units of mea-
sure, and more.) The Data ontologies cover the range of
knowledge needed to ﬁnd and use speciﬁc data in practice.
At the highest level, the data source ontology holds knowl-
edge about all possible classes of data sources, especially
the content of data held and container in which they are
held. Here, there is only one speciﬁc data source. It is de-
scribed in the ontology myinput. It describes an ASCII en-
coded ﬁle of six ﬂoating point numbers arranged in CSV
format with zero header rows and six rows of data with the
ﬁlename my input.txt.

The ontologies under Algorithms are also few in number.
In this ﬁrst implementation, the algorithm ontology pri-
marily encodes high-level information, such as that an algo-
rithm requires some inputs (number and types), that it pro-
duces output (number and types), a description of what kind
of transformation it performs, and what its “big-O” time
complexity is. For example, the two algorithms used in the
ﬁrst implementation are the arithmetic mean and the stan-
dard deviation. In order to choose these algorithms, AIDA
must know at a minimum that they require input that is nu-
merical, consists of at least two values, and that all values
must of the same quantity type. That is, it makes no sense to
calculate the arithmetic mean of a temperature value, a hu-
midity value, and a pressure value, which are different types
of quantities. The algorithm produces an output that is a sin-
gle value that is of the same quantity type as the input, and is
an average value of the input values. At this stage, the label

Figure 2: A high-level view of the AIDA ontologies.

particular paradigm (and if it cannot, AIDA can have that
knowledge as well).

We designed AIDA to have knowledge about both ab-
stract structures and programming language implementa-
tions of them. For maximum ﬂexibility, AIDA builds soft-
ware in two stages. After parsing the requirements, she ﬁrst
builds a representation using abstract structures that depends
on the programming paradigm, but is programming lan-
guage agnostic (the PLA version). From the PLA version,
she builds a programming language rendered (PLR) version
in the chosen programming language. Using this two stage
approach, AIDA is designed to correctly render the same
PLA version into multiple programming languages with-
out the problems of “translating” between different PLs (eg,
Java / C++) or even versions of the same PL (eg, Python
2.x / Python 3.x). In our approach, the abstract structures
in the PLA version of the software are faithfully mapped
to any supported PL, so that it can be rendered “naturally”
in that language. Any quirks or special requirements of a
PL can be part of AIDA’s knowledge. Both the PLA version
and any PLR version that AIDA constructs become part of
her knowledge and can be used in future projects. Finally,
AIDA “walks” the PLR version to write the source code out
to a ﬁle.

Authoring software requires knowledge about much more
than software structures and programming language syntax.
Distilled to its essence, software is created to take informa-
tion you “have but don’t really need” and transform it into
information “you really need but don’t have”. For example,
software that predicts the closing price of some stock takes
historical price data over the course of the day (information
you have really but don’t need) and transforms it into a clos-
ing price for the day (information you really need but don’t
have). It performs this transformation using algorithms that
have been implemented in code.

Implementation
In practice, most of what AIDA does is (1) ﬁnd and match
attributes of different kinds of entities through relationships,
and (2) create and modify patterns of structures. Knowledge
about the entities and their relationships is encoded in the
knowledge graph via OWL2 ontologies. We developed all
ontologies from scratch using Protege (Musen 2015). While
there are many ontologies published across a wide range of
knowledge domains, we have not found any that could sub-
stantially be used for AIDA. In our opinion, the content of

“average value” is just that, a label. AIDA does not really
“know” what it means except that it is a kind of output value
of an algorithm and also a string found in the parsed prob-
lem statement, and that they match in this context. However,
as AIDA gains more instances of using the “average value”
label (ie, matches that label in different contexts), she bet-
ter “understands” its scope, which means she can use that
knowledge across a wider range of logical arguments.

In the discussion above, we stated our goal of AIDA
reasoning over both declarative and procedural knowledge.
While not commonly viewed in this way, declarative knowl-
edge is normally explicitly encoded in the knowledge graph
and procedural knowledge, such as it is, is implicitly en-
coded in the associated reasoning codebase. It is not nor-
mally viewed in this way because, as in the case of publicly
available general knowledge graphs, the reasoning codebase
is left up to the consumer of the knowledge graph.

There is not usually such a tight integration and interde-
pendence of the knowledge graph and the reasoning code-
base. In this version of AIDA, the procedural knowledge
is not yet completely located within the knowledge graph.
It is split across the knowledge graph and the reasoning
codebase. The “structural“ part of the procedural knowl-
edge consisting of certain structures and their elements and,
especially, their dependencies and ordering, are recast as
declarative knowledge and encoded in the knowledge graph
(through ontologies). The actual “doing” is still implicit in
the reasoning codebase, along with some knowledge about
the when to do the “doing”.

We illustrate the division of knowledge with a simple ex-
ample – building the Python statement import sys. We
begin at the point where AIDA has already identiﬁed that
she used the sys package elsewhere in the program and now
needs to build the statement to import it. In order to build
the statement, AIDA needs to know (1) which variation of
the statement she should use, (2) what are the elements of
the one she selects, and (3) what is the order of the ele-
ments in the statement. AIDA uses this knowledge to build
the statement and insert it into the correct part of the PLR
representation of the program. All the information in (1) –
(3) is encoded in the knowledge graph (KG). The knowledge
that the order is a given is implicit in the reasoning codebase
(RC), because the information is queried in that order in the
RC.

While we defer the full details to a later paper, the pro-
cess AIDA follows is to execute the correct query to get the
information in (1) – (3), where the details of the next query
is dependent on the results of the previous one. Once AIDA
retrieves all this information, it becomes input to the part of
the RC that builds the statement. She then executes a query
to ﬁnd the correct place in the PLR structure and executes a
ﬁnal query (for this process) to insert the new information in
the KG.

This high-level example illustrates the tight connection
between AIDA’s KG and RC. It suggests where we can con-
tinue to move procedural knowledge from the RC to the KG.
For one, we can encode the order of (1) – (3) above, even en-
coding the entire query for each step in the KG. As we have
more examples of what AIDA must do, ie, what procedural

Figure 3: The annotated target program decomposed into
program sections. The section names appear in red to the
left and are the components of the program structure type
Input Calculate Output.

data_sources_names = ['my_input.txt']
requested_calculations = \

['average value',

'average value variation']

program_requirements = \

['read input data',

'calculate quantity',
'report result']

programming_language = 'Python-3.8'
program_basename = 'hello_analytic'

Figure 4: The ﬁrst target program for AIDA to compose.

knowledge she uses to what ends, we can encode those pat-
terns into the KG in more detail. Then, AIDA could build her
queries dynamically as needed and retain the ones she uses
most often in the KG for efﬁciency. We are actively working
on creating this capability.

First Exemplar Problem and Results
Obviously, the problem area we are attacking is very wide
ranging and a ﬁrst implementation of it using the approach
we outline above can become very large, complicated, and
overwhelming very quickly. For the ﬁrst implementation of
AIDA, we created a very simple exemplar problem with a
target program, show in in Figure 3, that AIDA should write
given the problem statement in Figure 4. This program con-
tains what we consider to be a set of bare minimum elements
constituting analytic software.

The core elements are that it must (1) read some data, (2)
apply an algorithmic transformation, and (3) produce some
report of the results. The ancillary, but still necessary, el-
ements are that it must import external code libraries and
explicitly exit the program. It should also exhibit some min-
imal examples of customization. We used the target program
as a general guide in scoping our ontologies. in developing
the content of the ontologies, we took an approach of “re-
verse engineering” the target program with a wide view. Es-
sentially, we decomposed the actions across all levels one
would take to conceive of and write the target program into
general patterns, as one might ﬁnd in a textbook on program-
ming.

The target program performs the minimal functions re-
quired as described. It has additional stylistic and contextual
components, such as ordering import statements alphabet-

ically by “ofﬁcial” package name (ie, not alias), use of a
package name alias (np for numpy), and use of meaningful
variables names. We emphasize that the variable names are
not “hard coded”. They come from general patterns encoded
in AIDA’s knowledge graph about how to pick variable
names. In this ﬁrst simple example, there are three patterns.
The ﬁrst is that a literal is assigned to a variable and that lit-
eral is the name of a data source ﬁle, then the name should
be a combination of its types. In this case, those types are
“input data” and “ﬁlename” for input data filename.
The second is that if a “data source ﬁlename” variable is
used as an argument to a function that reads its data, the
variable name should be just the type of data. Here, it is
“input data”. Lastly, if the return value of a function
is assigned to a variable, the name of the variable should
be the same as the name of the function, such as “mean”
and “std”. Since the program is an example of a pro-
totypical analytic and is written in Python, we named it
hello analytic.py. Note that AIDA knows the fact
that a Python program should have the extension “.py” and
appends it to the base program name when she writes out the
source code to a ﬁle. Importing the ontologies and building
the starting knowledge graph takes about 75 seconds, since
this knowledge graph is small.

to

(in

the

and

give

use
of

calculations

source
the

In the problem statement, we identify a speciﬁc
data source names),
to
data
perform (in
name
type
requested calculations),
pro-
gram requirements, ie, what the program should do (in
program requirements). We also specify the pro-
(in programming language).
gramming language
Note that the problem statement is quite simple. Each of the
strings in the problem statement appear in the knowledge
graph as labels to some entity (with the exception of
program basename) in order to prove out the simplest
matching. While certainly not unimportant, the richness of
the problem statement is not a focus at this stage of our
work. It will grow as AIDA’s capabilities grow.

From this statement, AIDA should ﬁnd that myinput
holds the detailed metadata of a speciﬁc data source (as op-
posed to a type of data) with the name “my input.txt”.
AIDA gathers all
this data source.
the metadata about
Likewise, AIDA should (and does) ﬁnd that each of the
two requested calculations are descriptions of the
types of calculations and that they map to the speciﬁc algo-
rithms arithmetic mean and standard deviation
(the only such algorithms that she knows). AIDA checks
that the requirements on the inputs to these algorithms
(such as that there are two or more values and that all
the values have the same quantity type) match the data
source she found. In fact, they match (by design). Fi-
nally, AIDA will ﬁnd from the ‘report result‘ part of
program requirements that she should “print out” the
results.

Having found entities for

the data source and al-
gorithms, AIDA reasons over her knowledge to build
to low level.
the code structures
the program structure that
At
the highest
is
satisﬁes

the stated program requirements.

from high level

level

is

It

import numpy as np
import sys
input_data_filename = 'my_input.txt'
input_data = np.loadtxt(input_data_filename)
mean = np.mean(input_data)
std = np.std(input_data)
print('mean = ',mean)
print('std = ',std)
sys.exit(0)

Figure 5: The literal, unaltered source code written out by
AIDA to a ﬁle named hello analytic.py.

Input Calculate Output, which is a subclass of Pro-
gramStructure. At the intermediate level are the code func-
tions that can read the data source and implement the iden-
tiﬁed algorithms. Respectively, they are loadtxt, mean,
and std, all from the numpy Python package. At the low-
est, most detailed level is building the needed lines of code
(ie, statements) with the correct structure and and writing
them out in the correct order. All of these entities have de-
tailed metadata encoded in AIDA’s constituent ontologies,
such as would be needed for a developer to use them.

Note that in the KG, we can specify different ordering
for different purposes. The sections of the chosen program
structure are Preamble, Input, Calculate, Output,
and CleanUp. When AIDA writes out the source code to
a ﬁle, it must have this order. The program must import
packages before using them, etc. However, when compos-
ing the program, it is better to do so in the order, Input,
Calculate, Output, CleanUp, Preamble. Then, de-
pendencies from one section can ﬂow naturally into the next.
For example, the Input section names the variable that
holds the data (input data) that is needed in the Calculate
section. However, all sections after Preamble might have
functions from external code libraries. While those sections
are composed, AIDA makes note of the external code li-
braries that are referenced and then creates the import
statements when all the other sections are complete.
In this ﬁrst simple step for AIDA, each of

these
calculations has only one matching algorithm, namely
arithmetic mean
and
standard deviation
“average value
variation”. In the future ,when more knowledge is
encoded in the knowledge graph, AIDA will need methods
to make choices, not only on algorithms, but also on data
sources, code functions and other structures. Such methods
are essentially algorithms themselves and so could be
encoded in the knowledge graph.

“average value”
for

for

The actual source code that AIDA writes to satisfy this
problem statement is given in Figure 5. It is not reformat-
ted in any way. It matches the target program almost ex-
actly, except for very minor stylistic elements, such as an
empty new line between program sections and a space be-
tween the comma and the variable name in the print state-
ments. (These elements can also be included, they just have
not been yet.) This source code is correct and gives the cor-
rect output when run (with the correct Python interpreter).
We give some statistics on the AIDA v0.1 implementation

References
Ehrlinger, L.; and W¨oß, W. 2016. Towards a Deﬁnition of
Knowledge Graphs. In SEMANTiCS (Posters, Demos, SuC-
CESS).
GitHub Copilot. 2022. GitHub Copilot. https://github.com/
features/copilot. Accessed: 2022-06-30.
GitHub Copilot FAQ. 2022. GitHub Copilot “Frequently
asked questions” under the question “Does GitHub Copi-
lot write perfect code?”. https://github.com/features/copilot.
Accessed: 2022-06-30.
Kite. 2022. Kite. https://www.kite.com. Accessed: 2022-
06-30.
Kr¨otzsch, M.; Simancik, F.; and Horrocks, I. 2012. A De-
scription Logic Primer. CoRR, abs/1201.4089.
Musen, M. A. 2015. The prot´eg´e project: a look back and a
look forward. AI Matters, 1(4): 4–12.
OpenAI Codex. 2022. OpenAI Codex. https://openai.com/
blog/openai-codex. Accessed: 2022-06-30.
In Zalta, E. N., ed.,
Pavese, C. 2022. Knowledge How.
The Stanford Encyclopedia of Philosophy. Metaphysics Re-
search Lab, Stanford University, Fall 2022 edition.
Singhal, A. 2012. Introducing the Knowledge Graph: things,
not strings. 2020-11-13.
W3C. 2012. OWL 2 Web Ontology Language Proﬁles (Sec-
ond Edition). Http://www.w3.org/TR/owl2-proﬁles/.

Acknowledgments
The author thanks Dr. Amanda Hicks of JHU APL for many
valuable discussions and Mr. Mark LoPresto, Mr. Andrew
Adams, Dr. Scott Laprise, and Dr. Andrew Newman, all of
JHU APL, for their valuable feedback in review of this work.

Ontologies { 20 ontologies
Knowledge Graph

Total \core" size > 22,500 triples
Named graph size = 1458 triples
PLA version = 677 triples
PLR version = 546 triples

Reasoning Codebase

Lines of Python code > 4300
Lines of SPARQL queries > 1900
Number of SPARQL queries = 129
Number of SPARQL query calls = 107
Total time to run ˜ 5 minutes on laptop

Figure 6: Statistics on the AIDA v0.1 implementation.

in Figure 6. The core graph is built from 20 ontologies and
its core size, ie, before AIDA builds any code, is more than
22,500 triples. The two versions of the program (PLA and
PLR) combined add up to almost 1500 triples in the graph,
split more or less evenly. They are stored in a named graph
subgraph for easy reference and access. On a modest laptop,
AIDA takes about 5 minutes to build the knowledge graph
from scratch, build the PLA and PLR versions of the pro-
gram, and write out the source code to a ﬁle.

Thus, we have successfully demonstrated our concept for
and implementation of an extended semantic reasoning plat-
form to develop software from scratch for a minimal exem-
plar program.

Future Work

We have already extended AIDA’s capability to compose a
composite algorithm from several simple ones (manuscript
in preparation). Currently, we are working to give AIDA the
ability to use other basic software structures of loops and
conditionals. The challenge is not in the building of these
structures. We have demonstrated here and in ongoing work
that procedural knowledge encoded across both the knowl-
edge graph and reasoning codebase is a viable approach to
building information structures. The real challenge lies in
how we give AIDA the ability to recognize when to use
such structures and what elements should be involved. We
are working on this question now.

A second important question that we are actively pursu-
ing is how we can cast procedural knowledge into only a
set of declarative statements, if it is possible at all. Doing
so would allow AIDA to have all knowledge about not only
how to write software, but how to write her own software,
including her reasoning codebase, from scratch upon startup
using only a very simple bootstrap program. In principle,
SPARQL queries, which are the heart of the logic in the rea-
soning codebase, have structure and purpose very much like
software generally. Thus, they should be amenable to reduc-
tion to a representation that can be encoded into a knowl-
edge graph. Writing her own knowledge graph queries from
scratch as needed itself would be another signiﬁcant accom-
plishment for AIDA.

