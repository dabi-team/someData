©2016 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including

reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any
copyrighted component of this work in other works

2
2
0
2

r
p
A
1
2

]

V

I
.
s
s
e
e
[

1
v
1
5
1
0
1
.
4
0
2
2
:
v
i
X
r
a

A Bitstream Feature Based Model for Video
Decoding Energy Estimation

Christian Herglotz, Yongjun Wen, Bowen Dai, Matthias Kr¨anzler, Andr´e Kaup
Chair of Multimedia Communications and Signal Processing
Friedrich-Alexander University Erlangen-N¨urnberg (FAU)
Cauerstr. 7, Erlangen, Germany
{ christian.herglotz@, yongjun.wen@studium., bowen.dai@studium, matthias.kraenzler@, andre.kaup@ } FAU.de

Abstract—In this paper we show that a small amount of
bit stream features can be used to accurately estimate the
energy consumption of state-of-the-art software and hardware
accelerated decoder implementations for four different video
codecs. By testing the estimation performance on HEVC, H.264,
H.263, and VP9 we show that the proposed model can be used
for any hybrid video codec. We test our approach on a high
amount of different test sequences to prove the general validity.
We show that less than 20 features are sufﬁcient to obtain mean
estimation errors that are smaller than 8%. Finally, an example
will show the performance trade-offs in terms of rate, distortion,
and decoding energy for all tested codecs.

I. INTRODUCTION

Recent studies showed that the global demand for video
streaming applications is growing rapidly [1]. Video data
already constitutes more than 50% of the total internet trafﬁc,
where a major part of this trafﬁc is used for mobile streaming
applications on portable devices like smartphones or tablet
PCs. Unfortunately, these devices are battery driven such that
the available processing power is limited. Hence, research
aiming at reducing the energy consumption of the video
streaming process is a worthwhile task.

To this end, researchers developed different methods to
reduce the energy consumption of video decoders. The most
popular method is to create dedicated decoding hardware.
E.g., Engelhardt et al. developed an HEVC-decoder for FPGA
[2]. In other works, dedicated hardware modules for major
decoder functions such as the deblocking ﬁlter [3] or the
integer transform [4] are presented. In a different direction,
the processing energy is reduced using dynamic voltage and
frequency scaling to reduce the power consumption of the CPU
[5]. Finally, research has been performed on the complexity of
the decoding process where the encoder adopts the estimated
decoding complexity into the rate-distortion optimization for-
mula [6]. Similarly, a dedicated model for estimating the
energy consumption of an HEVC decoder [7] was developed
and successfully applied in the encoder to produce bit streams
that require less decoding energy at the same objective visual
quality [8].

In this paper, we generalize the model for estimating the
HEVC decoding energy presented in [7] to be applicable to
other codecs and decoder implementations. The model is based
on bit stream features that describe the main processing steps
that are executed repeatedly during the decoding process. For

a given input bit stream, the decoding energy is estimated by

ˆE =

F

Xf =1

nf · ef ,

(1)

where f is the feature index, F the magnitude of the feature
set that depends on the used codec, nf the feature number
that describes how often feature f occurs, and ef the feature’s
speciﬁc energy that represents the mean processing energy
consumed upon each occurence of the corresponding feature.
By generalizing this model to other codecs, in this paper we
will

• show the general applicability of the model,
• provide a new method to compare the energetic properties

of different video codecs,

• construct models that can be further used for decoding

energy optimization.

Particularly, we will adapt this model to the H.263 [9], the
H.264 [10], and the VP9 codec [11] and, by comparing to
the baseline HEVC model, show that the proposed feature
based model can be used to accurately estimate the decoder’s
energy consumption independent from the used codec and its
implementation.

The paper is organized as follows: Section II gives more
details on the general concept of a bit stream feature and
introduces the different feature categories that are used. Then,
Section III presents the explicit feature sets used for the
codecs and explains the corresponding feature analyzers used
to determine the feature numbers nf . Afterwards, Section IV
introduces our evaluation setup and gives a thorough analysis
on the test results. Section V concludes the paper.

II. BIT STREAM FEATURES

Generally, a bit stream feature describes the execution of a
standardized process when decoding a given bit stream. As an
example, one feature corresponds to the execution of a DCT-
transform of a certain block size (feature trans). This transform
is executed repeatedly during the decoding process and, due
to the predeﬁned processing ﬂow, requires roughly the same
amount of processing energy upon each execution. Hence,
counting the number of executed transforms and determining
the mean processing energy we can estimate the complete
decoding energy related to transformation.

 
 
 
 
 
 
Likewise, further features are deﬁned where the feature
numbers can be determined for any given, standard compliant
bit stream. As all considered codecs use a block-based hybrid
approach, we ﬁnd that a general categorization of features can
be deﬁned:

• Offset features (OFFSET): In this category, two features
are deﬁned that comprise processes during encoding that
cannot be skipped. The ﬁrst feature (f = E0) corresponds
to the offset energy required for starting and ending the
decoding process. Hence, for each bit stream, the corre-
sponding feature number is ﬁxed to one. Secondly, the
number of frames is counted to represent the processing
energy used to initialize a frame (f = frame).

• Intraframe prediction features (INTRA): These fea-
tures correspond to all processes performed for intraframe
prediction of a block (intra). Our studies showed that
processing larger blocks requires less energy than using
small blocks, hence we consider the different intraframe-
prediction block sizes that the codec allows.

• Interframe prediction features (INTER): Similar to the
intraframe case, these features describe the interframe
prediction process of a certain block size (inter). To
represent the motion compensation process, we count
the number of pels that need to be predicted (pel), that
are counted twice in biprediction. As additionally all
codecs allow fractional pel motion vectors for more
accurate motion compensation, the number of fractional
pel ﬁlterings is counted (frac), too.

• Residual transformation features (TRANS): For these
features we count the number of inverse transforms per-
formed for reconstruction (trans). Just like for prediction,
we consider the transformation block size.

• Residual coding features (COEFF): To represent the
parsing process of the residual coefﬁcients we count the
number of non-zero coefﬁcients (coeff) and consider their
value (val).

Naturally, decoding consists of many more processes like
loop ﬁltering, de-quantization, motion vector coding and so
forth. These processes can either be assigned to one of the
above-mentioned features (like de-quantization to coefﬁcient
decoding as de-quantization must be performed for each non-
zero coefﬁcient), or they only consume a marginal amount of
energy such that their consideration would not increase the
estimation accuracy signiﬁcantly. The explicit feature sets for
the codecs are deﬁned in the next section.

III. FEATURE SETS

In this section, the properties of the feature sets for each
codec are discussed in detail. The most important difference
results from the block sizes that are allowed. For intraframe
prediction, all considered codecs only allow square blocks.
H.263 provides a single block size (16 × 16), H.264 addition-
ally uses 4 × 4-blocks (we do not consider the high proﬁle),
and HEVC as well as VP9 allow four different sizes (32 × 32
to 4 × 4). Note that in our work, we count the block size that
is actually processed. E.g., in the HEVC standard a prediction

TABLE I
CATEGORIZED FEATURE SETS FOR EACH CODEC. THE NUMBERS INDICATE
HOW MANY BLOCK SIZES ARE CONSIDERED, IF APPLICABLE. THE
MAGNITUDE OF THE FEATURE SETS IS WRITTEN IN THE LAST ROW.

Category

Feature f

H.263

H.264

HEVC

VP9

OFFSET

INTRA

INTER

TRANS
COEFF

SAO

E0
frame
intra
inter
OBMC
pel
frac
trans
coeff
val
SAO

1
1
1
2
1
1
1
1
1
1

-

1
1
2
3

-
1
1
1
2
2

-

1
1
4
4

-
1
1
4
1
1
1

1
1
4
5

-
1
1
4
1
1

-

magn(F )

11

14

19

19

block is allowed to be of size 64 × 64, nevertheless processing
is performed on four 32 × 32 blocks corresponding to the
residual transformation process [12].

For interframe prediction, even more block sizes are al-
lowed. Including rectangular splits, e.g., VP9 includes 13
different block sizes to choose from. To prune the resulting
high amount of features, we propose merging some of the
block sizes having a similar amount of pixels. As a result, we
deﬁne two block sizes for H.263 (16 × 16 and 8 × 8) and three
for H.264 (16 × 16 to 4 × 4), where the rectangular sizes are
added with a half-weight to the next bigger square block. E.g.,
a block of size 8 × 16 is counted as a half 16 × 16 block. For
HEVC, four block sizes are counted (64 × 64 to 8 × 8) and for
VP9, we additionally count 4 × 4-blocks. Note that we deﬁne
a special block for the H.263 standard that corresponds to
overlapped block motion compensation (OBMC), cf. [9], as the
corresponding process is more complex than standard motion
compensation.

For transformations, H.263 only provides a single block size
(8 × 8). In H.264, only 4 × 4 transformations are counted as
we do not consider the high proﬁle. For HEVC and VP9, the
four transform sizes 32 × 32 to 4 × 4 are taken into account.
In order to consider the value of the residual coefﬁcients (val),
two different methods are applied. For HEVC, we sum up the
logarithms to the basis 2 of each non-zero residual coefﬁcient
(cf. [8]). For the other codecs, the number of coded bits for
each coefﬁcient is used.

Finally, we would like to mention two special cases. The
ﬁrst case holds for H.264 where two different arithmetic cod-
ing methods (CAVLC and CABAC) are allowed. Therefore,
the two residual coding features coeff and val are deﬁned twice,
once for CAVLC and once for CABAC. For the second case,
we take the sample adaptive offset ﬁlter (SAO) [13] into
account that was newly introduced for the HEVC standard. As
SAO introduces a signiﬁcant amount of additional complexity
into the decoder, we count the number of 64 × 64-sized luma
blocks that are ﬁltered by this new algorithm.

Summarizing, all the above mentioned feature sets including
their categorization are listed in Table I. We can see that

the recent codecs have a larger feature set which is caused
by a higher amount of coding modes. The feature analyzers
used to count
the feature numbers are implemented into
readily available, existing decoder solutions which are the
TMN-2.0 [14], JM-18.4 [15], HM-11.0 [16], and libvpx [17]
software decoders. In the next section we will show that these
feature sets sufﬁce to accurately estimate the decoding energy
consumption.

IV. EVALUATION

In this section we thoroughly explain our evaluation method.
First, the setup for measuring the decoding energy is intro-
duced followed by a discussion on the evaluation sequences.
Afterwards, the training and validation method is described
and the ﬁnal results are given.

A. Measurement Setup

To measure the true decoding energies, the test setup pre-
sented in [8] is used. As a power meter, we employ ZES Zim-
mer’s LMG95 to obtain the energies Edec required to decode
all tested bit streams. We measure the energy consumption of
the FFmpeg software decoder [18] which is readily capable
of decoding all considered codecs. We consider FFmpeg to
show a realistic processing ﬂow as it is optimized for real-
time, practical applications. The decoding device (DEC) is a
Pandaboard [19] which features a smartphone like architecture
using an ARM processor.

To show that our model is not restricted to a single software
solution, we evaluate the estimation accuracy on alterna-
tive decoders, namely the TMN-2.0 decoder for H.263 and
libde265 [20] for HEVC. For H.264, a hardware accelerated
decoder was tested on the Pandaboard which is included on the
OMAP4430 system-on-chip (SoC) [21]. It includes an image
and video acceleration unit (IVA) that is capable of decoding
H.264-coded videos with a resolution up to 1080p.

B. Evaluation Sequence Set

The input sequences for H.264, HEVC, and VP9 are taken
from all classes of the standard HEVC test set [22] and are
listed in Table II. Furthermore, as H.263 only allows speciﬁc
resolutions, further sequences are coded for all four codecs in
CIF and QCIF resolution (Table III).

To take different visual qualities into account, for each codec
a set of QPs was chosen that spans the range of PSNRs from
around 25dB to 55dB. For encoding, the reference software
encoders were chosen using different standard encoder conﬁg-
urations. Note that class A sequences were not tested for the
H.264 hardware accelerated decoder as the resolution is too
high. Detailed information about the coded sequences for all
codecs is summarized in Table IV.

C. Validation Method

Our method for testing the estimation performance of the
proposed model is depicted in Figure 1. For each codec we
perform a 10-fold cross-validation as proposed in [23]. In this
method, we randomly divide the complete set of bit streams
into 10 approximately equally sized subsets. Then, we perform

TABLE II
EVALUATION SEQUENCES TAKEN FROM THE HEVC TEST SET. EXCEPT
FOR CLASS A (8 FRAMES), ALL SEQUENCES WERE CODED USING 40
FRAMES.

Class A (2560 × 1600 pixels)
PeopleOnStreet
Trafﬁc

Class C (832 × 480 pixels)
BasketballDrill
BQMall
PartyScene
RaceHorses
Class E (1280 × 720 pixels)
FourPeople
Johnny
KristenAndSara
vidyo1,3,4

Class B (1920 × 1080 pixels)
BasketballDrive
BQTerrace
Cactus
Kimono
ParkScene
Class D (416 × 240 pixels)
BasketballPass
BlowingBubbles
BQSquare

Class F (variable resolution)
SlideEditing
SlideShow
ChinaSpeed
BaketballDrillText

TABLE III
EVALUATION SEQUENCES COMPATIBLE WITH H.263.
CIF (352 × 288 pixels)
QCIF (176 × 144 pixels)
Foreman (30 frames)
Akiyo (30 frames)
Crew (50 frames)
Tennis (30 frames)
Car Phone (50 frames)
Miss America (50 frames)
Coastguard (50 frames)
Bus (50 frames)
Suzie (30 frames)
News (30 frames)

10 iterations where in each iteration, one subset is deﬁned as
the validation subset. The remaining 9 subsets are used to
train the parameters (which are the speciﬁc energies ef in
our case) using the measured decoding energies Edec. As a
training method we use the trust-region approach [24] which
aims at minimizing the squared error. The resulting speciﬁc
energies ef are then used for validating the validation subset.

As a criterion to express the estimation performance we use

the mean relative estimation error calculated by

¯ε =

1
M

ˆEm − Em,dec
Em,dec

,

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

Xm

(2)

where m is the bit stream index, M the magnitude of the bit
stream sets, and ˆEm and Em,dec the estimated and measured
decoding energy of the m-th bit stream, respectively. A mean
relative error of ¯ε = 0 would indicate that we have a perfect
estimator.

To further prove the superior estimation performance of the
proposed feature based model, we compare the results to the
estimation error of two models from the literature. The ﬁrst
(HL1) is proposed in [26] and estimates the decoding energy
based on high-level properties of a coded bit stream which are
resolution S, number of frames N , and bit stream ﬁle size B.
In this model, the energy is estimated by

ˆEHL1 = C + S · N ·

α + β ·

(cid:20)

γ

B
S · N (cid:19)

,

(cid:21)

(cid:18)

(3)

TABLE IV
SOFTWARE AND CONFIGURATIONS FOR ENCODING THE EVALUATION BIT
STREAMS. THE LAST ROW IN EACH COLUMN DENOTES THE TOTAL
NUMBER OF TESTED BIT STREAMS. TO OBTAIN A SUFFICIENTLY LARGE
TEST SET FOR H.263, DIFFERENT PARTS OF THE INPUT SEQUENCES WERE
CODED.

TABLE V
MEAN RELATIVE ESTIMATION ERRORS ¯ε FOR THE FOUR CONSIDERED
CODECS. THE FIRST ROW GIVES THE RESULTS FOR THE PROPOSED
MODEL. THE SECOND ROW VALIDATES THE ESTIMATION ERRORS ON
OTHER DECODER IMPLEMENTATIONS. THE LAST TWO ROWS SHOW THE
ESTIMATION ERRORS OF THE REFERENCE MODELS.

Encoder
Conﬁgurations

H.263
TMN-2.0 [14]
Frames 1 to N

VP9
libvpx [17]
One-pass coding
Frames N + 1 to 2N Two-pass coding

QPs
# Bit streams

1, 3, 7, 12, 23, 30
120

Encoder
Conﬁgurations

H.264
JM-18.4 [15]
baseline
main
extended

QPs
# Bit streams

12, 22, 32, 42
408

5, 20, 44, 59
272

HEVC
HM-16.4 [16]
intra
lowdelay
lowdelay P
randomaccess
10, 20, 30, 40
544

Coded evaluation sequences (Tables II, III)

Bit stream analysis

Measurement

PSfrag replacements

Bit stream speciﬁc variables nf

Decoding energies Edec

Training

Model
parameters ef

Validation

10-fold cross-validation

Estimation error ε

Evaluation ﬂow. The evaluation sequences are analyzed for their
Fig. 1.
corresponding feature numbers nf . Furthermore,
the decoding energy of
these sequences is measured for each codec using the setup shown in [25].
Afterwards, we feed the bit stream speciﬁc variables and the decoding energies
into a 10-fold cross-validation loop to train the model parameters and validate
the estimation accuracy. As an output, we obtain the mean absolute estimation
error ε.

where the parameter C can be interpreted as a constant offset
energy, α as the offset energy needed to decode a pixel, and
β and γ represent a pixel-wise additive term that depends on
the mean amount of bits that are used for coding a pixel.

The second model (HL2) was introduced in [27] and further

reﬁned in [25] and reads

ˆEHL2 =

c1 · pI ·

(cid:18)

B
S · N

+ c2 · pI + c3 ·

B
S · N

+ c4

· N · S.

(cid:19)

(4)
In addition to bitrate B, number of frames N , and resolution S
the rate of intra frames pI (which is the number of intra frames
divided by the complete number of frames) is considered. The
parameters c1 to c4 are the codec and implementation speciﬁc

Model
Feature based
Feature based
HL1
HL2

Software
FFmpeg
Alt.
FFmpeg
FFmpeg

VP9
H.264
HEVC
5.11%
6.41%
5.27%
3.18%
7.50%
-
13.04% 15.22%
30.55%
20.86% 26.23% 30.38% 33.34%

H.263
2.51%
0.77%
2.67%

parameters. Similar to the evaluation of the feature based
model, the parameters of these two models are determined
using the 10-fold cross-validation approach.

D. Results

The resulting estimation errors are summarized in Table
V. Considering the ﬁrst row we can see that the proposed
model reaches errors that are smaller than 7% for all codecs.
The lowest error is obtained for the H.263 codec (2.51%)
which is not surprising as it is the oldest one providing least
complexity. Furthermore, estimation errors are signiﬁcantly
lower than errors returned by the high-level models (rows three
and four) which can be explained by the increased number of
parameters. Note that for HL2, under certain circumstances
estimation errors of around 20% can be reached. For H.264,
the estimation error is smaller than 20% when the bit streams
are solely coded with the main encoder conﬁguration and
for H.263, the error is smaller than 8% when only a single
resolution is considered. Furthermore, the estimation errors of
HL1 and HL2 for VP9 are relatively high (> 30%) which can
be explained by the following two reasons:

• Compound prediction: VP9 offers the possibility to code
frames that are only used for prediction and not displayed.
These additionally coded frames are not considered in the
reference model.

• In [26] it is stated that screen content videos are badly
estimated by a high-level model. Removing them from
the evaluation test set we could achieve estimation errors
smaller than 22% for both HL1 and HL2.

In contrast, note that the estimations for the H.263 decoder
given by HL1 are very sound (2.64%) which can again be
explained by the low complexity of this codec.

The second row shows the estimation errors for the alterna-
tive software decoders. We can see that the values for H.263
and HEVC are even smaller (3.18% and 0.77%, respectively)
which indicates that the general purpose FFmpeg solution
is more difﬁcult
to model. As additionally the hardware
accelerated decoder shows a relatively low estimation error
(7.5%), we can say that the proposed model can be used
independent from the decoder implementation.

To visualize how the results of our investigations can be
interpreted we plot measured and estimated energies for a
showcase sequence in Figure 2. We chose the QPs such that
the bit streams are coded at an approximately constant PSNR
in all codecs. Details are given in Table VI.

PSfrag replacements

REFERENCES

HEVC

H.264

H.263

VP9

Edec
ˆE

Edec
ˆE

Edec
ˆE

Edec
ˆE

Edec
OFFSET
INTRA
INTER
TRANS
COEFF
SAO

0

0.2

0.4
Energy [J]

0.6

0.8

Fig. 2. Measured and estimated decoding energies (FFmpeg) for sequence
Foreman coded at a nearly constant objective quality (PSNR ≈ 34.3dB). The
upper bars correspond to the measured energy Edec, the lower, stacked bars
to the estimated energy ˆE. Each segment of the stacked bars represents the
accumulated energies of the categories presented in Section II.

TABLE VI
OBJECTIVE VISUAL QUALITY, BIT STREAM FILE SIZE, AND QP OF THE
FOREMAN SEQUENCE CODED USING THE DIFFERENT CODECS.

Codec
YUV-PSNR
File size
QP

HEVC
34.304dB
20.3kB
33

H.264
34.250dB
31.3kB
32

H.263
34.272dB
103kB
8

VP9
34.283dB
28.7kB
42

In Figure 2, the dark blue bars correspond to the measured
energy Edec. Below, the stacked bars represent the estimated
energy ˆE where we can see that for each codec, it is very
close to the measured energy. Each element of the stacked bar
corresponds to a feature category as deﬁned in Table I where
we can see that most energy is used for inter prediction.

Furthermore, we can see that H.263-decoding, due to a
very low complexity, consumes least energy. In contrast, the
decoding energy of VP9 is relatively high which was not
expected. Analyzing the distribution of the estimated energy
on the features indicates that the fractional pel ﬁltering process
(feature frac) consumes a relatively large amount of energy in
comparison to the other codecs.

V. CONCLUSIONS

In this paper we have shown that a feature based approach
to model the energy consumption of state-of-the-art video
decoders is highly suitable to accurately estimate the decoding
energy. Estimation errors are found to be lower than 8% for all
tested decoder implementations. In future work, the proposed
models can be used to encode decoding energy saving bit
streams.

ACKNOWLEDGEMENT

This work was ﬁnancially supported by the Research Train-
ing Group 1773 “Heterogeneous Image Systems”, funded by
the German Research Foundation (DFG).

[1] Cisco.

Feb)
data

(2016,
networking
update,
Global mobile
http://www.cisco.com/c/en/us/solutions/collateral/service-
provider/visual-networking-index-vni/mobile-white-paper-c11-
520862.pdf.

visual
forecast

Cisco
trafﬁc

index:
2015-2020.

[2] D. Engelhardt, J. Hahlbeck, J. M¨oller, and B. Stabernack, “FPGA
implementation of a full HD real-time HEVC main proﬁle decoder,”
IEEE Transactions on Consumer Electronics, vol. 60, no. 3, pp. 476–
484, August 2014.

[3] Y. Adibelli, M. Parlak, and I. Hamzaoglu, “Energy reduction techniques
for H.264 deblocking ﬁlter hardware,” IEEE Transactions on Consumer
Electronics, vol. 57, no. 3, pp. 1399–1407, August 2011.

[4] T. T. T. Do, Y. H. Tan, and C. Yeo, “High-throughput and low-
cost hardware-oriented integer transforms for HEVC,” in Proc. IEEE
International Conference on Image Processing (ICIP), 2014.

[5] E. Akyol and M. van der Schaar, “Complexity model based proactive
dynamic voltage scaling for video decoding systems,” IEEE Transactions
on Multimedia, vol. 9, no. 7, pp. 1475 –1492, Nov 2007.

[6] S.-W. Lee and C.-C. Kuo, “Motion compensation complexity model for
decoder-friendly H.264 system design,” in Proc. IEEE 9th Workshop on
Multimedia Signal Processing, Chania, Oct 2007, pp. 119 –122.

[7] C. Herglotz, D. Springer, and A. Kaup, “Modeling the energy con-
sumption of HEVC P- and B-frame decoding,” in Proc. International
Conference on Image Processing (ICIP), Oct 2014, pp. 3661 – 3665.

[8] C. Herglotz and A. Kaup, “Joint optimization of rate, distortion, and
decoding energy for HEVC intraframe coding,” in Proc. International
Conference on Image Processing (ICIP), Phoenix, USA, Sep 2016, pp.
544 – 548.

[9] ITU-T, Video Coding for Low Bit Rate Communication.

ITU-T Rec.

H.263, Nov 1995.

[10] Advanced Video Coding for Generic Audio-Visual Services.

ITU-T Rec.
H.264 and ISO/IEC 14496-10 (AVC), ITU-T and ISO/IEC JTC 1, May
2003.

[11] D. Mukherjee, J. Bankoski, A. Grange, J. Han, J. Koleszar, P. Wilkins,
Y. Xu, and R. Bultje, “The latest open-source video codec VP9 -
an overview and preliminary results,” in Proceedings Picture Coding
Symposium (PCS), Dec 2013, pp. 390–393.

[12] G. Sullivan, J. Ohm, W.-J. Han, and T. Wiegand, “Overview of the
high efﬁciency video coding (HEVC) standard,” IEEE Transactions on
Circuits and Systems for Video Technology, vol. 22, no. 12, pp. 1649
–1668, Dec. 2012.

[13] C.-M. Fu, E. Alshina, A. Alshin, Y.-W. Huang, C.-Y. Chen, C.-Y. Tsai,
C.-W. Hsu, S.-M. Lei, J.-H. Park, and W.-J. Han, “Sample adaptive offset
in the HEVC standard,” IEEE Transactions on Circuits and Systems for
Video Technology, vol. 22, no. 12, pp. 1755–1764, Dec. 2012.

[14] T. Research. TMN (H.263) encoder/decoder, version 2.0. Not available

online anymore.

[15] JVT. (2016) H.264/AVC Reference Software (JM). [Online]. Available:

http://iphome.hhi.de/suehring/tml/

[16] Joint collaborative team on video coding reference software, HM.

[Online]. Available: https://hevc.hhi.fraunhofer.de/

[17] (2016) WebM libvpx. http://www.webmproject.org/. Accessed 2016-06.
[18] (2015) FFmpeg. http://ffmpeg.org/. Accessed 2016-06.
[19] (2015) pandaboard.org. http://pandaboard.org/. Accessed 2016-06.
[20] (2015) libde265 HEVC. http://www.libde265.org/. Accessed 2016-06.
[21] Texas Instruments. (2014) OMAP4430 multimedia device silicon re-
vision 2.x [public] - technical reference manual. [Online.] Available:
http://www.ti.com/product/omap4430. Texas Instruments.

[22] F. Bossen, “Common test conditions and software reference conﬁgu-
rations,” document JCTVC-L1100, ITU-T VCEG and ISO/IEC MPEG
(JCT-VC), Geneva, Switzerland, Jan 2013.

[23] M. Zaki and W. Meira, Data mining and analysis, 1st ed. Cambridge

Univ. Press, 2014.

[24] T. F. Coleman and Y. Li, “An interior trust region approach for nonlinear
minimization subject to bounds,” SIAM Journal on optimization, vol. 6,
no. 2, pp. 418–445, 1996.

[25] C. Herglotz, D. Springer, M. Reichenbach, B. Stabernack, and A. Kaup,
“Modeling the energy consumption of the HEVC decoding process,”
accepted for IEEE Transactions on Circuits and Systems for Video
Technology, Aug 2016. DOI: 10.1109/TCSVT.2016.2598705.

[26] C. Herglotz and A. Kaup, “Estimating the HEVC decoding energy using
high-level video features,” in Proc. 23rd European Signal Processing
Conference (EUSIPCO), Nice, France, Aug 2015, pp. 1591–1595.
[27] P. Raouﬁ and J. Peters, “Energy-efﬁcient wireless video streaming with
H.264 coding,” in Proc. IEEE International Conference on Multimedia
and Expo Workshops (ICMEW), Jul 2013, pp. 1–6.

 
 
