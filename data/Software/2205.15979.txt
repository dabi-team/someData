2
2
0
2

y
a
M
1
3

]

O
R
.
s
c
[

1
v
9
7
9
5
1
.
5
0
2
2
:
v
i
X
r
a

TUM Autonomous Motorsport:
An Autonomous Racing Software
for the Indy Autonomous Challenge

Johannes Betz1, Tobias Betz1, Felix Fent1, Maximilian Geisslinger1, Alexander Heilmeier1,

Leonhard Hermansdorfer1, Thomas Herrmann1, Sebastian Huch1, Phillip Karle1∗,

Markus Lienkamp1, Boris Lohmann2, Felix Nobis1, Levent ¨Ogretmen2, Matthias Rowold2,

Florian Sauerbeck1, Tim Stahl1, Rainer Trauth1, Frederik Werner1,

Alexander Wischnewski2

TU Munich
Garching, Germany

Abstract

For decades, motorsport has been an incubator for innovations in the automotive sector and
brought forth systems like disk brakes or rearview mirrors. Autonomous racing series such
as Roborace, F1Tenth, or the Indy Autonomous Challenge (IAC) are envisioned as playing
a similar role within the autonomous vehicle sector, serving as a proving ground for new
technology at the limits of the autonomous systems capabilities. This paper outlines the
software stack and approach of the TUM Autonomous Motorsport team for their partici-
pation in the Indy Autonomous Challenge, which holds two competitions: A single-vehicle
competition on the Indianapolis Motor Speedway and a passing competition at the Las Ve-
gas Motor Speedway. Nine university teams used an identical vehicle platform: A modiﬁed
Indy Lights chassis equipped with sensors, a computing platform, and actuators. All the
teams developed diﬀerent algorithms for object detection, localization, planning, predic-
tion, and control of the race cars. The team from TUM placed ﬁrst in Indianapolis and
secured second place in Las Vegas. During the ﬁnal of the passing competition, the TUM
team reached speeds and accelerations close to the limit of the vehicle, peaking at around
270 km h−1 and 28 m s−2. This paper will present details of the vehicle hardware platform,
the developed algorithms, and the workﬂow to test and enhance the software applied during
the two-year project. We derive deep insights into the autonomous vehicle’s behavior at
high speed and high acceleration by providing a detailed competition analysis. Based on
this, we deduce a list of lessons learned and provide insights on promising areas of future
work based on the real-world evaluation of the displayed concepts.

∗Correspondence: phillip.karle@tum.de
1Authors are with the Institute of Automotive Technology (FTM), TU Munich
2Authors are with the Chair of Automatic Control (RT), TU Munich

 
 
 
 
 
 
1

Introduction

1.1 Motivation

Racing has been a platform for innovation since its very beginning. Safety mechanisms, powertrain, and
suspension technology as well as tires have been improved during the past decades in several competition
formats. Recently, autonomous racing became a proving ground for autonomous vehicle technology at the
limits of its current capabilities. The most prominent examples include the F1Tenth racing series, Formula
Student Driverless (FSD), Roborace, and the Indy Autonomous Challenge. While each of those series has
a slightly diﬀerent scope and focus, all of them target the improvement of the used sensors, actuators,
and compute platforms as well as the development of the required algorithms, middleware, and operating
systems. The race track provides a safe proving ground for high-speed testing and challenges autonomous
vehicles frequently with complex scenarios.

A research team from the Technical University of Munich (TUM) decided to participate in the Indy Au-
tonomous Challenge (IAC, Figure 1a) and the follow-up event, the Autonomous Challenge at CES in Las
Vegas (AC@CES, Figure 1b), in October 2021 and January 2022. Nine teams from international universities
took part in the real-world events and competed in two diﬀerent formats: Firstly, the target in Indianapolis
was a combination of setting the fastest lap on the Indianapolis Motor Speedway (IMS) and demonstrating
dynamic obstacle evasion capability. Secondly, the event in Las Vegas was based on a head-to-head passing
competition with alternating overtaking attempts of two participants with increasing speeds for each round.
The TUM team ﬁnished ﬁrst at the inaugural event at the IMS and second at the AC@CES.

The competition focused solely on the development of the required autonomous racing software stack. There-
fore, all the vehicles were based on the same chassis as well as the same sensors, actuators, and compute
platform. It started initially with 31 teams and a series of hackathons built around simulated racing chal-
lenges with increasing complexity, leading up to multiple eight vehicle simulation race in May 2021. Finally,
nine teams were asked to deploy their software on the vehicles starting in July 2021 and practiced on a small
oval race track, Lucas Oil Raceway, before moving to the larger Indianapolis Motor Speedway and the Las
Vegas Motor Speedway.

This paper introduces the approach of the TUM Autonomous Motorsport team to tackle the competition,
including the software architecture, simulation technology and development workﬂow applied. The aim of
the paper is to explain the relations and challenges behind certain design choices within the software stack
and the respective outcomes during real-world testing.

(a) Dallara AV-21 at Indianapolis Motor Speedway

(b) Dallara AV-21 at Las Vegas Motor Speedway

Figure 1: The TUM Autonomous Motorsport racing software driving the AV-21 on diﬀerent race tracks
(Indy Autonomous Challenge, 2021).

1.2 Vehicle Platform

The oﬃcial race vehicle of the IAC is the Dallara AV-21. It is based on the Dallara IL-15, which is used
in the Indy Lights Series. It is equipped with a drive train consisting of a 2.0 l single-turbocharged engine
and a 6-speed sequential semi-automatic gearbox. The retroﬁtting of the cars was mainly focused on the
autonomous driving capabilities. Therefore, the basic parts of the drive train and the aerodynamic setup
only received minor changes for the IAC, resulting in a similar behavior compared to the Indy Lights Series.
It should be mentioned that the hardware platform comprising the conventional and the automated driving
parts are equal for all teams. As a result, the performance of each vehicle in the competition solely relies on
the implemented functional autonomy software of the teams. The autonomous driving parts are mounted
in the driver’s cockpit. The perception sensors and the computing platform replace the driver’s seat, the
actuation system is positioned in the footwell of the cockpit. The installed components are listed in Table 1
and are brieﬂy described in the following.

Table 1: Overview of the automated driving parts for the AV-21.

Component

Manufacturer

Model

DBW System
DBW Interface
ECU
Power Management
Computing Plattform
Network Switch
GNSS Receiver
LiDAR
Camera
Side RADAR
Front RADAR

Schaeﬄer Paravan
New Eagle
Motec
Cosworth
ADLink
Cisco
Novatel
Luminar
Allied Vision
Aptiv
Aptiv

SpaceDrive II
GCM 196 Raptor
M142
IPS-32
AVA-3501
IE500
Pwrpak 7d Receiver
H3
Mako G319C
MRR
ESR 2.5

The throttle, brake, and steering actuation is realized by a full Drive-by-Wire-system (DBW) by Schaeﬄer
Paravan called SpaceDrive II. This embedded system consists of an electronic control unit and servo motors to
receive braking and steering signals from the software and to execute them fulﬁlling real-time constraints. The
overlying interface is realized by a New Eagle GCM 196 Raptor unit, which also handles the communication
to the control unit of the combustion engine and the low-voltage power management. The communication
on the actuation side is realized via the serial bus system CAN.

The core part of the automated driving hardware is a x64-based computing platform. It is an ADLink AVA-
3501, a modiﬁed version of the DLAP-8000. It comes with the 8-core Intel Xeon E-2278GE CPU with 64 GB
RAM and the Nvidia Quadro RTX8000 GPU with 48 GB memory. Alongside the computing platform, a
network switch establishes the connection to the sensors for perception and localization via Ethernet. The
GNSS system is realized by two dual-antenna setups using Novatel Pwrpak 7d receivers. The perception
sensor system consists of camera, RADAR, and LiDAR sensors. In total there are six cameras installed,
which are positioned to enable a full surround view. Similarly, the three LiDAR sensors are orientated in
120° such that LiDAR setup also
alignment to the vehicle heading and rotated around a vertical axis to
covers in total 360°-ﬁeld-of-view. The RADAR sensors are placed at the front and on both sides at

90°.

±

±

1.3 Related Work

Teams with autonomous vehicles have already competed against each other in the past. The DARPA Grand
Challenge (2004 and 2005) (Buehler et al., 2007) was the ﬁrst-long distance competition for autonomous
vehicles. Participating university teams needed to build their own vehicle and write respective software
capable of driving the car autonomously. The goal was to drive a predeﬁned route of over 200 km fully

autonomously without human interaction, and therefore, the vehicles needed to localize themselves, detect
objects and plan their path entirely on their own. As a successor, in 2007 the DARPA Urban Challenge
(Buehler et al., 2009) presented a similar competition setup but now in an urban scenario. Furthermore, the
cars needed to obey traﬃc rules, negotiate with other traﬃc participants to merge correctly e.g., into lanes
and ﬁnish the race within 6 h.

Since these events, autonomous driving has become more and more relevant to the industry. New companies
like Waymo, Zoox, and Cruise were established to develop a fully self-driving vehicle that operates the car
in our transportation systems. At the same time, researchers began to use high-performance sports and race
cars for their research purposes. This is because driving autonomously on the race track creates a variety
of challenges for the autonomous software: localization and object detection at high speeds, trajectory and
behavior planning in an adversarial environment, and control of the car at the dynamic limits of handling
(Betz et al., 2018). The research in this ﬁeld is mainly divided into soft- and hardware eﬀorts.

Software
A race track typically consists of a single lane as a driveable area with inner and outer bounds that are
deﬁned by curbs and none-driveable areas like grass and gravel. In addition, walls consisting of tires or stone
surround the track to keep the car inside the race track in case of an accident. In the ﬁeld of perception,
researchers use the unique environment of the race track to demonstrate large-scale mapping with fewer
features (Nobis et al., 2019) as well as localization at high speeds (Renzler et al., 2020; Schratter et al.,
2021). Since the Formula Student Driverless (FSD) competition requires the teams to drive and localize at
the same time, the teams present Graph-SLAM (Andresen et al., 2020; Large et al., 2021) and Recurrent
Neural Network-based methods (Srinivasan et al., 2020) for localization and state estimation of the FSD
vehicle. In addition, the FSD competition provides yellow and blue cones as the race track and the teams
need to detect those cones at high vehicle speeds. As a result, particular applications of YOLO-based
methods are used to detect the cones (Dhall et al., 2019; Strobel et al., 2020).

In the ﬁeld of path planning, authors focus on global, local, and behavioral planning. The global planning
algorithms provide an optimal racing line for the whole race track. This racing line is the fastest trajectory
for the vehicle that needs to be followed when there are no opponents around the car. Under speciﬁc
optimization objectives like minimum curvature (Braghin et al., 2008; Heilmeier et al., 2019), minimum time
(Christ et al., 2019; Pagot et al., 2020) and minimum energy (Herrmann et al., 2019) there are a variety of
solutions to this problem. Local planning aims to achieve a high planning horizon for recursive feasibility
while avoiding opponent vehicles with evasive maneuvers at high speeds. There are three main approaches
for planning a local trajectory on the race track. Firstly, the global plan can be adjusted and modiﬁed via an
additional optimization (Subosits and Gerdes, 2019; Kapania et al., 2016). Secondly, multiple dynamically
feasible trajectories are sampled. Based on racing speciﬁc cost functions, the best trajectory that avoids
obstacles is selected (Liniger et al., 2014; O'Kelly et al., 2020). Thirdly, sampling-based methods provide an
eﬃcient but non-optimal technique to randomly sample the free space around obstacles and ﬁnd a possible
trajectory (Arslan et al., 2017; Feraco et al., 2020). Finally, the work in the ﬁeld of behavioral planning
covers the task of planning the behavior of the car under high uncertainty and deﬁning interactions with
non-cooperative agents. This type of behavioral planning for race cars is done either by designing multiple
cost functions with weighting and then selecting the trajectory with the lowest overall cost (Sinha et al.,
2020; Liniger and Lygeros, 2015) or by combining the local planner with game-theory methods (Notomista
et al., 2020; Wang et al., 2021). Especially the ladder one showed the possibility of advanced cutting and
blocking maneuvers (Liniger and Lygeros, 2020) which is crucial for the race car to succeed on the race track.

Finally, in the ﬁeld of control, the goal is to handle the vehicle at the limits and track a reference trajectory
as accurately as possible: low lateral tracking errors, low heading tracking errors, and low velocity tracking
errors. Another goal is to achieve high control frequencies with the available computation hardware for
real-time high-speed driving. Research in this ﬁeld uses an enhancement of classical control approaches to
maximize the lateral and longitudinal tire forces (Fu et al., 2018; Kapania and Gerdes, 2015). A big part
of the research applies Model Predictive Control (MPC) methods in some variations (Verschueren et al.,
2016; Gandhi et al., 2021). The MPC solves a ﬁnite-time optimal control problem and computes an optimal

sequence of vehicle state and control inputs (steering, acceleration) based on a speciﬁc vehicle dynamics
model (kinematic, linear single-track, and nonlinear single-track model). Lastly, since the autonomous race
car is driving repeatably around the track for multiple laps, it is suitable for the application of Iterative
Learning Control (ILC) methods. With these data-driven approaches, algorithms are displayed that learn
the control gap over time and apply afterward e.g., corrective steering input, to achieve a faster lap time
(Rosolia et al., 2017; Hewing et al., 2018).

Furthermore, in addition to this classical perception-planning-control work, many researchers are focusing on
full or partial end-to-end approaches that leverage the usage of deep neural networks (DNN) or reinforcement
learning (RL) methods. The racing task provides a clear objective function (fastest lap time) for the algorithm
training and the race track provides with its clear driveable area and one class of objects a perfect proving
ground. Researchers in this ﬁeld displayed partial end-to-end approaches (Weiss and Behl, 2020; Lee et al.,
2019) that combine DNNs with MPC methods to create and follow dynamic trajectories.
In addition,
by using algorithms from the ﬁeld of RL (e.g., Soft-Actor-Critic, Q-Learning), researchers were able to
demonstrate how to train an agent to drive fast (Jaritz et al., 2018; de Bruin et al., 2018), how to train an
agent to overtake other agents on the race track (Song et al., 2021) and how to bridge the sim-to-real gap
with model-based RL approaches (Brunnbauer et al., 2021).

Hardware
Besides pure software development eﬀorts, in the last years, various hardware platforms for the purpose of
autonomous racing have been displayed. Firstly, small-scale vehicles based on remote-controlled (RC) cars
are used to test newly developed algorithms quickly. Those vehicles are equipped with sensors (Camera,
LiDAR, IMU) and computation hardware to run the autonomous driving software. Researchers display
hardware in a 1:43 scale (Liniger et al., 2014), 1:10 scale (O’Kelly et al., 2020; Balaji et al., 2020) and 1:5
scale (Goldfain et al., 2019). The FSD competition covers a large part of the ﬁeld of autonomous small-scale
racing. Here university teams build their own 1:1.5 racing vehicles (Zeillinger et al., 2017) that need to drive
autonomously around the race track in various competitions. The teams use these vehicles afterwards for
additional research and display both full autonomous driving stacks (Kabzan et al., 2020; Nekkah et al.,
2020; Tian et al., 2018) as well as individual algorithm developments (Andresen et al., 2020; Large et al.,
2021).
Full-scale vehicles are also used for autonomous racing research, apart from these small-scale race cars.
In particular, these vehicles are high-performance sports cars that are used for autonomous handling at
the limits (Theodosis and Gerdes, 2012; Funke et al., 2012) or autonomous drifting with high side-slip angle
(Hindiyeh and Gerdes, 2014; Goh et al., 2019). In 2017, the company Roborace designed a special autonomous
race car based on a LeMans-Prototype (LMP) chassis. This vehicle was equipped with sensors, actuation,
and computation hardware to drive autonomously around the race track. Roborace gave interested student
teams the opportunity to use this race car which displayed research in the ﬁeld of localization (Massa et al.,
2020; Zubaca et al., 2020), high dynamic path planning (Caporale et al., 2018; Stahl et al., 2019b) software
development (Betz et al., 2019; Hermansdorfer et al., 2020) and control (Buyval et al., 2017; Wischnewski
et al., 2019a). In addition, Roborace organized diﬀerent competitions called Season Alpha and Season Beta
that consisted of single- and multi-vehicle events on various race tracks. Finally, the IAC vehicle is the latest
autonomous race car that was designed for research and competition purposes and is further explained in
section 1.2.

In summary, we can say that autonomous racing is an emerging topic in the ﬁeld of robotics and intelligent
vehicles (Betz et al., 2022). With the rising number of active researchers in this area providing both software
and hardware developments, the community is constantly growing. With the setup of the IAC we see the
ﬁrst-time vehicles competing against each other at high speeds and high accelerations - entirely autonomously.

1.4 Contributions and Outline of the Paper

In this paper, we present the eﬀorts in the software development of the TUM Autonomous Motorsport team
for participating in the Indy Autonomous Challenge. This work builds upon (Wischnewski et al., 2022) and
has four main contributions:

1. We provide a holistic view of the software architecture and design decisions made during the devel-
opment of the TUM Autonomous Motorsport software stack for high speed autonomous racing.

2. We elaborate on the development and testing workﬂow and their impact on the achievements made

during the both IAC competitions.

3. We provide an evaluation of all developed software modules in a full software stack. The results
obtained in this full stack evaluation include implications that might be hard to ﬁnd in isolated
studies and research projects.

4. Finally, we share experimental results of single-vehicle as well as two-vehicle racing scenarios with

speeds of up to 270 km h−1 and accelerations up to 28 m s−2.

The paper is structured as follows: Section 2 introduces the software architecture and gives insights into the
applied algorithms and concepts. Section 4 describes the event formats as well as the results and ﬁndings
during these experiments. Finally, section 5 summarizes the learnings and conclusions from this project.
It outlines streams of future work and potential areas of technology transfer from the race track to series
production vehicles.

2 TUM Autonomous Motorsport Software

This section deals with the software that the TUM Autonomous Motorsport team developed for participation
in the IAC. After the introduction of the overall software architecture in section 2.1 the speciﬁc software
modules are presented in the order of application in the overall stack. Additionally, related topics such as
middleware and software latency as well as our development infrastructure consisting of Software-in-the-Loop
(SIL) and Hardware-in-the-Loop (HIL) simulation are displayed.

2.1 Architecture

The software architecture (Figure 2) employs a classical separation into three main areas: Perception, plan-
ning, and control. The perception module leverages RADAR, camera, and LiDAR to detect opponent
vehicles. The LiDAR detection is done with two diﬀerent strategies to increase the reliability: First, a
deep learning-based approach is utilized to classify race vehicles in the point-cloud data. This algorithm is
speciﬁcally trained on race vehicles and shows high detection performance. At the same time, it is prone
to overﬁtting and will not detect other classes of objects which might appear on the track due to unfore-
seen circumstances. The second approach aims to overcome these deﬁciencies with a geometric clustering
approach. Even though it takes into account basic geometric information about the considered objects, it is
capable of detecting arbitrary classes of objects. These two main pipelines are accompanied by a pipeline
for camera-based detection. It uses a bounding box approach in conjunction with a known-height assump-
tion for distance estimation. While this enables large detection distances, the transformation errors resulting
from track banking and diﬀerent vehicle orientations lead to greater positional uncertainties than the LiDAR
pipelines. Finally, RADAR detection completes the set of detection algorithms. Its main strength is the
ability to measure the velocity diﬀerence between an object and the ego vehicle. This improves the transient
performance of opponent velocity estimation, which is key for reliable driving performance in highly dynamic
scenarios with limited sensor range.

Figure 2: Software architecture of the TUM Autonomous Motorsport team.

The detected objects are fed into an object tracking algorithm, which serves two purposes: The matching of
already tracked objects and incoming measurements as well as the temporal fusion of the detections. The
ﬁrst task is executed by an algorithm based on the Hungarian assignment method (Kuhn, 1955). The second
task is achieved via a Kalman-Filter based-approach with a constant velocity and turn rate dynamic model.
This ﬁlter creates a position history of the fused observations for each identiﬁed vehicle on the track. This
history serves as a basis for the prediction of future behavior, which has been implemented in two diﬀerent
ways: Firstly, a physics- and track-informed prediction; secondly a data-driven approach. The resulting
predictions are the most likely outcomes for the behavior of the opponent vehicles and are handed over to
the trajectory planning module.

The trajectory planning module is based on a combination of a sampling and a graph-search strategy. This
makes it possible to resolve the combinatorial nature of the multi-vehicle planning problem eﬃciently. The
planned trajectory is approximately 5 s long and has to be updated frequently to take into account new
information about the behavior of other race participants. The target path and target velocity proﬁle are
handed over to the motion control module which utilizes an MPC algorithm to attenuate disturbances and
optimize the coarse output of the trajectory planning to generate smooth vehicle behavior. This is enabled
via the introduction of a safe driving tube which is assumed to be collision-free for approximately two times
the vehicle width. Finally, the state estimation provides a consistent estimate of the vehicle position and
motion state to all software modules. It leverages multiple localization sources (two GPS and one LiDAR
localization) as well as two IMUs to achieve reliable operation and fault tolerance.

2.2 Localization

High precision and low latency localization is a key challenge of autonomous racing (Lingemann et al., 2005).
The sensors used for this application are two Novatel GNSS receivers with integrated IMU and two antennas
each. One has the two antennas at the left and right sidebox and the other has them at the nose and on top
of the main roll hoop.

LiDARDeepLearningLiDARClusteringCameraDeepLearningRadarDetectionLocalizationObjectTrackingBehaviorPredictionTrajectoryPlanningMotionControlStateEstimationSensorsActuatorsIn (Sauerbeck et al., 2022), we introduced a localization algorithm that uses camera images and LiDAR point
clouds for ego pose estimation. However, real-world testing showed no beneﬁt over a redundant diﬀerential
GNSS setup at open-sky race tracks. The ﬁnal localization and state estimation were mainly based on a
fusion of the two GNSS signals and their IMU units. Therefore, an enhanced version of the Kalman Filter
approach presented in (Wischnewski et al., 2019b) is used. This approach is based on a two-dimensional
point mass model to represent the vehicle dynamics. Since detailed data of the vehicle setup and the
used tires were not available, this approach can outperform approaches with a more detailed vehicle model
(Wischnewski et al., 2019b). The measurement quality of the two GNSS receivers was determined empirically
and the weighting of the sensors was speciﬁed accordingly. Since the diﬀerential heading calculated from the
GNSS receiver by antenna positions does not exhibit reliable behavior, we use a heading estimation based
on the derivation of velocity, which provides small errors when the vehicle turns. To account for the track
banking (up to 9° in Indianapolis and 20° in Las Vegas), additional banking information is used. The used
map consists of two-dimensional track boundaries and a one-dimensional banking map along the race track.
Lateral diﬀerences in banking can be disregarded because measurements proved them to be small enough.
Moreover, this avoids numerous exploitation runs. The banking information allows the compensation of the
banking in the measured accelerations and calculate the Kalman Filter as on a plane. As shown in Equations
1 and 2, only the lateral acceleration is compensated. a(cid:48)
y denote the accelerations used for the state
estimation. ax,meas and ay,meas are the measured accelerations received from the IMU. θ(s) is the banking
angle at the corresponding longitudinal track coordinate s, and g is the gravitational constant.

x and a(cid:48)

a(cid:48)
x = ax,meas
a(cid:48)
y = ay,meas ·

[cos(θ(s)) + tan(θ(s))

sin(θ(s))] + g

tan(θ(s))

·

·

(1)

(2)

The two-dimensional track boundaries were generated with laser scans and known ego-position. To obtain
the one-dimensional banking map, the residuals from the state estimation Kalman Filter were utilized. The
Kalman Filter for localization and state estimation is implemented in Matlab Simulink and deployed to the
car via C-code generation. It is executed in the same process as the vehicle controller at a frequency of
100 Hz.

2.3 LiDAR Preprocessing

The ﬁrst step in the LiDAR object detection pipeline is the preprocessing to reduce the number of points
captured by the three LiDAR sensors. Each unit sends raw point cloud to the LiDAR sensor driver, where
the point clouds are directly fused and transformed into the vehicle’s coordinate system. The output of the
driver is a raw point cloud covering a horizontal ﬁeld of view (FoV) of 360° and a vertical FoV of 17.5° and
20° for the sections of the front and left/right LiDAR sensors, respectively. The front LiDAR vertical FoV
is lower compared to the left/right LiDAR sensors’ vertical FoV to achieve a higher resolution, which can
be beneﬁcial with distant objects. With a sensing frequency of 20 Hz, the LiDAR sensors have 32 vertical
layers. The distribution of these layers can be changed at runtime. We use this feature to dynamically adapt
the high-density layer region to the region of interest (ROI). Due to the track’s banking, the vertical ROI
has diﬀerent positions based on the location of the vehicle on the track. On the track’s straights, the ROI
is centered in front of the vehicle, whereas in the banked turns, the ROI is shifted to the top.

The point cloud serves as input for both LiDAR detection algorithms. Their main task is the detection of
objects on the track. These objects usually consist of only a few points in the point cloud, and the number of
points decreases signiﬁcantly with increasing distance between the vehicle and the object. As a result, only a
few points are relevant for the driving task and the rest of the points within a point cloud should be ﬁltered
before it is passed to the object detection algorithms. This not only increases the algorithm’s performance,
but also reduces the computational load, the data transfer times and lowers the overall latency. Hence,
the vehicle can react faster to the opponent’s changes in position and orientation. However, this comes
at the cost of additional computational load and calculation time for the preprocessing itself. Therefore it
is necessary to employ lightweight and eﬃcient preprocessing algorithms. Since the number of points per

object is low, especially at distances beyond 50 m, the preprocessing algorithms should not reduce the point
density of the relevant objects.

Given these initial constraints, we develop a point cloud preprocessing pipeline consisting of three sequential
algorithms: conditional removal, voxel downsampling, and ground ﬁlter (Figure 3). Each algorithm is
described brieﬂy in the following. The order of the three algorithms is based on the algorithm’s ability to
handle large point clouds with low computational load and time. The ground ﬁlter beneﬁts from a lower
input point number as opposed to conditional removal, which can handle an arbitrary number of points
without additional computation time.

Conditional Removal is a method to extract the relevant region of interest from a point cloud. The
goal is to remove any points which are outside of the race track, such as reﬂections from buildings or the
stands, based on geometric ﬁltering. Points that meet certain criteria are labeled as not relevant and are
therefore removed from the point cloud. Conditional removal is performed in local vehicle coordinates and no
information on the vehicle’s global position is used. Hence, conditional removal is based on the assumption
that the vehicle’s heading is roughly parallel to the direction of the racing line.

Voxel Downsampling is a method to compress the information about multiple points within a certain area
into a single point. The entire point cloud is divided into a grid with a ﬁxed voxel size by using an algorithm
from the Point Cloud Library (Rusu and Cousins, 2011). We use cuboid voxels of diﬀerent sizes for each
cuboid side. The selection of the length, height, and width of the voxels is based on the expected point
cloud shape of the relevant objects, which are mainly race vehicles. A voxel size of 0.15 m/0.1 m/0.05 m for
x/y/z reduces the number of points in close range but keeps the point cloud structure for objects at higher
distances. Beyond a threshold of 150 m, the points are not voxelized. For each voxel, the average in each
x/y/z of all points within the voxel generates a new output point representing this voxel. In case no points
are found within the voxel, an output point is not created for this voxel. The resulting output point cloud
resembles the input point cloud with fewer points.

The Ground Filter uses a ground segmentation algorithm to detect points belonging to the ground and
ﬁlters these out of the point cloud. The usage of a neural network trained in a supervised fashion for this
task is not an option due to the lack of a data set. Data from a race track including banking with point-wise
labels are not available and are not feasible to create due to limited testing time. Therefore, we employ a
ray-ground ﬁlter, based on the implementation of Autoware.Auto (The Autoware Foundation, 2021), which
follows the ideas of (Cho et al., 2014).

Figure 3: Overview of the object detection pipelines

LiDARPreprocessingLiDARDriverLiDARSensorLiDARSensorLiDARSensorConditionalRemovalVoxelDownsamplingGroundFilterPointRCNNClusteringStage1Stage2CameraDriverFrontCameraCameraDeepLearningYOLOv5Lifting2Dto3DRadarDriverFrontRadarRadarProcessingFilterTransformBuﬀerWe test a point cloud distortion correction algorithm based on point-wise time stamps to remove the dis-
tortion originating from the diﬀerence in capture time for all points within a single point cloud. The eﬀect
of distortion can be seen especially at higher speeds. For example, at a vehicle speed of 60 m s−1 and a
LiDAR refresh rate of 20 Hz, the vehicle moves 3 m between the ﬁrst and last captured point in a single
point cloud. Since the relevant objects travel with roughly the same speed as the ego vehicle and the relative
speed diﬀerence — and therefore the distortion of these objects — is low, the eﬀect can be neglected. Hence,
we don’t actively use distortion correction during the race.

The performance of the individual LiDAR preprocessing algorithms is depicted in Figure 4. Outliers with a
lower number of points, especially at the raw input point clouds, emerge when only one or two of the three
LiDAR sensors send data, which occurs occasionally for single time steps. Overall, the preprocessing pipeline
reduces the point cloud size by more than 80 % with a total calculation time of around 22 ms, including data
transfer between the algorithms. Figure 5 illustrates the output of the three preprocessing algorithms on
an exemplary point cloud. Although the visual diﬀerence between 5b and 5c is hard to identify, the voxel
downsampling step halves the number of points. The reduced point clouds retain the relevant information
of each raw point cloud and serve as input for the following object detection algorithms.

Figure 4: Breakdown of the point reduction for each LiDAR preprocessing algorithm, based on 32,568 point
clouds captured during the ﬁnal run of the Autonomous Challenge at CES on the 7th of January 2022.

2.4 Object Detection - LiDAR Deep Learning

For the detection of opponent race vehicles, we employ a neural network that uses preprocessed point clouds
(Section 2.3) as input. Speciﬁcally, we select the two-stage PointRCNN (Shi et al., 2019), which ranked
at the top of the KITTI Benchmark at the time of selection (Geiger et al., 2012). To ﬁt our needs for
detecting race vehicles, we modify this network as described in the following. First, we adapt the network
conﬁguration to enable a 360° horizontal FoV. Additionally, we move the reference system of the detections
from the front camera (default KITTI Benchmark) to the vehicle rear axle. Since there is only one type of
race vehicle to detect, the network only has to predict one class. Finally, we manually ﬁne-tune parameters,
such as detection thresholds, for best performance in our use case.

The network is trained in a supervised fashion. Labeled point cloud data sets with race vehicles were
not available until our ﬁrst tests on the race track. Therefore, we use initial training data generated in our
simulator (Section 3.2). Additionally, we manually label data recorded from the ﬁrst real-world multi-vehicle
test sessions. Once the network’s performance reaches a satisfactory state, i.e., it detects the race car in
every other point cloud, we use it to auto-label the recorded data and supervise the results. Both training
and inference are conducted on a GPU to leverage the beneﬁts of parallel processing. Deployed on the race
vehicle, the network runs at a frequency of around 12 Hz.

Raw InputAfter Conditional RemovalAfter Voxel DownsamplingAfter Ground Filter0100002000030000400005000060000700008000090000Number of Points per Point Cloud(a) Raw input
74,302 points

(b) After Conditional Removal
66,585 points

(c) After Voxel Downsampling
29,502 points

(d) After Ground Filter
11,995 points

Figure 5: Visualization of the three LiDAR preprocessing steps on an exemplary point cloud.

2.5 Object Detection - LiDAR Clustering

The LiDAR object detection neural network can detect only objects it has encountered during training.
Since we generate a data set containing race vehicles only, other unstructured objects like debris cannot be
detected by the neural network. Therefore, we employ a second object detection algorithm that can detect
any kind of object on the race track. Furthermore, this competitive pipeline complements detections from
the neural network. This increases redundancy in case either of the algorithms misses an object. In case
both algorithms detect the same object, even with diﬀerent extends, the output is fused in the object fusion
and tracking algorithm (Section 2.8). The pipeline is based on a classical machine learning algorithm. In
detail, we employ a grid-based euclidean-cluster-extraction algorithm, which operates in two stages.

The ﬁrst clustering stage is specialized to detect small clusters within the preprocessed point cloud. Small
clusters usually include parts of a race vehicle, such as the front wing or wheels. Clusters larger than the
dimensions of a race vehicle are disregarded.
In the second clustering stage, the remaining clusters are
combined into larger clusters, ideally returning one cluster per race vehicle or object. This stage is also
followed by a threshold step, in which clusters larger than race vehicles are not considered. This threshold
step works only as long as there is only one opponent at a time on the race track, which was always the
case during testing and the events. 3D bounding boxes are calculated based on the minimum and maximum
extends in x/y/z of the points in each cluster. These boxes are oriented in the same direction as the ego
race vehicle. The clustering algorithm runs with a frequency of 20 Hz on one core of the CPU.

2.6 Object Detection - Camera Deep Learning

Object detection using cameras provides additional redundancy. However, the projection of the 3D world
onto 2D images entails a loss of information and direct detection in 3D space is not possible. Our approach
to solving this challenge is the detection in the 2D space and subsequent recovery of the 3D information
based on a priori knowledge. In detail, we use YOLOv5 (Jocher et al., 2021) for object detection on 2D
images. The input is the image recorded by the front camera and the output are 2D bounding boxes of all
detected objects on the input image. The recovery of the object’s 3D information, i.e. the relative x and
y distance to the ego vehicle, is based on a pinhole model of the camera. Using the intercept theorem, the
distance dobj of the object to the camera is a function of the camera focal length f , the 2D bounding box
height pixel count n (assuming a known pixel size), and the real race vehicle height h

dobj =

f h
n

.

(3)

We calculate the rotation of the object around its vertical axis using the ratio of the bounding box width and
height and compare this to the known width-to-height ratio of the real race vehicle. The resulting rotation
angle estimate is not unique, i.e. the object can be rotated to the left or right with the same angle. Based on
the position of the oval track, one of the two solutions is more likely. We also experimented with predicting
the rotation angle directly using YOLOv5 with an additional output per predicted bounding box, but the
results were inferior to the rotation estimation from the width and height ratio.

2.7 Object Detection - RADAR

The RADAR detection pipeline (Figure 3) extends the set of perception algorithms with an additional and
independent object detection method to further increase the functional safety of the vehicle. The main
beneﬁt of this pipeline is the utilization of the RADAR sensor’s ability to directly measure the relative
velocity of the opponent vehicle via the Doppler eﬀect. In addition, the RADAR sensor represents the sensor
with the highest detection range on the straights and therefore enables early object tracking with an accurate
speed estimation. However, the RADAR sensor is limited to a maximum of 64 detections per cycle and is
subject to a high number of false positives. Therefore, a dedicated RADAR processing pipeline had to be
developed to deal with these challenges.

The main purpose of the RADAR processing pipeline is the ﬁltering of the input data to extract the objects
of interest from the surroundings. The applied ﬁlter separates the incoming objects, based on their absolute
velocity, to isolate the dynamic objects from the static environment. To achieve this, a threshold-based ﬁlter
is used and tuned for a racing application. Finally, the ﬁltered objects are transformed to the vehicle frame
and stored within an object buﬀer to supply the downstream modules with a ﬁxed frequency of 20 Hz.

2.8 Object Fusion & Tracking

The following section outlines the software module of object fusion and tracking. For more detailed infor-
mation about the fusion and tracking task, the reader is referred to (Wang et al., 2020). The object fusion
handles multiple object lists that originate from diﬀerent perception pipelines. Ultimately, this algorithm
combines the given information to output a uniﬁed object list. As Figure 2 reveals, the perception pipelines
work independently from each other and output individual object lists. This late fusion approach allows
us to incorporate a variable number of perception pipelines without any dependencies. This is especially
beneﬁcial to conduct real-world tests with basic perception pipelines in the absence of rich data to train
and develop more comprehensive algorithms. The object tracking addresses the estimation of the detected
objects’ dynamic states, which is realized by the Extended Kalman Filter (EKF) (Jazwinski, 1970) based
on a Constant Turn Rate and Velocity (CTRV)-model. An important feature to realize this is the matching
between previously estimated objects and new objects provided by one of the perception pipelines. Figure
6 outlines the module sequence, which is described in the following.

Figure 6: Overview of object fusion and tracking.

Input to the module are both the dynamic vehicle ego state and the perception input. The latter one consists
of an object list
Li and a sensor time stamp Ti per perception pipeline. Our implementation is parametrized
with m = 4 perception pipelines but is capable to scale up to an arbitrary number of pipelines. Depending
on the applied algorithm and sensor the object states in the object list contain distinct variables. Due to
the fact that the modules are not synchronized and the individual perception pipelines have diﬀerent cycle
times, the number of received objects lists varies. The perception input is processed sequentially, starting
with the object list having the oldest sensor time stamp. The object list has to be transformed from the
local vehicle coordinates to a global coordinate system, which is used for tracking, prediction, and trajectory
planning. In this step, a yaw estimation based on the orientation of the track’s center line is added in case
the heading is not given by the respective perception pipeline. By this, the state estimation can be enhanced.
The coarse assumption is handled by a high measurement uncertainty in the EKF update step.

Next, plausibility checks are conducted in two stages.
In the ﬁrst stage, multiple detections of a single
object are merged which prevents multiple tracks of the same object. This is realized by kd-tree clustering
(Maneewongvatana and Mount, 1999) and a ﬁxed distance threshold for the cluster distance. In the second
stage, we reduce the number of false positives with a map-based ﬁlter. This removes all objects which are
outside the global track boundaries and is necessary due to the reﬂectivity of the pit and track wall.

The ﬁltered object list is input to the object matching, which is based on the Hungarian Method (Kuhn,
1955). This combinatorial optimization algorithm solves the data association problem of the given old object
list from the previous time step and the new object list. The applied cost function is the pairwise distance
between n old and m new objects, which are assigned in a n
m-matrix. With the constraint of a maximal
valid matching distance, the solution of the assignment problem can result in the following cases:

×

• New Unmatched Object

There are more new objects than old objects (n < m) or matches are classiﬁed as invalid and the
new object remains unmatched if the matching distance is above the threshold. The new unmatched
object is assigned with an unique ID and a status counter is set up. Additionally, the CTRV-model
in the state estimation module and object storage are initialized.

• Old Matched Object

There is a valid match between an old and a new object. In this case, the ID of the old object is
assigned to the new one. The status counter is increased, an update step of the EKF is conducted
and the resulting state correction is added to the object storage.

• Old Unmatched Object

There are more old objects than new objects (n > m) or matches are classiﬁed as invalid and the
old object remains unmatched if the matching distance is above the threshold. The old unmatched
object’s status counter is decreased and the object storage is updated with the estimated state as
no measurement update step is possible.

PerceptionInput(L1,T1),..,(Lm,Tm)Transformationloc→globPlausbilityCheckObjectMergeOut-of-Track-FilterObjectMatchingDataAssociationStatusCounterStateEstimationEKFCTRV-ModelObjectStorage3s/3Hzdeque[x,y,Ψ,v,˙Ψ]EgoStateDelayCompensationThe idea of the status counter is to deﬁne the number of perception inputs without detecting a tracked
object before it is discarded. A status counter is initialized with a positive integer for each new unmatched
object. In case the object is matched by the next perception input (old matched object), the counter is
increased by Xup,i. Otherwise, if the object is not matched (old unmatched object) the counter is decreased
by Xlow,i. If the status counter reaches 0, the object is removed from the storage and is not tracked anymore.
The values for Xup,i and Xlow,i are positive integers and depend on the perception pipeline i. The value
of the status counter is limited by a maximal value Xmax. By this, it is ensured that an object, which
was successfully matched multiple times, is still removed quickly after it has not been detected anymore.
The parameterization of the counter values depends on the sensitivity and speciﬁcity of the perception
pipelines and the trade-oﬀ between recognizing objects preferably early when they enter the sensor range
and discarding them if they are not detectable anymore.

The state estimation runs with a ﬁlter step size of 10 ms, which means that during each cyclic call of
the module the forward integration of the EKF estimation step is executed multiple times. By this, the
linearization error of the EKF remains within the tolerance. All estimation steps are stored in the object
storage to ensure an equidistant sampling rate. However, the respective entries are replaced by the corrected
position after a successful match and related EKF update. The CTRV-model is an appropriate choice for
our use case of autonomous racing. On the one hand, the yaw rate is essential to accurately estimate the
objects’ motion in turns at high speed. On the other hand, the estimation of the acceleration is prone to
oscillations. So we attempt to reﬂect this trade-oﬀ in the complexity of the model. The states of the tracked
objects are stored in the object storage, which is a deque of 3 s with 100 Hz resolution. Each state comprises
the 2D-position (x and y), the orientation in the global coordinate system (heading Ψ), the speed v, and the
yaw rate ˙Ψ.

For reliable object tracking at high speeds the consideration of delays resulting from the sensors and the
perception algorithms is essential. The implemented delay compensation handles this task with a backward-
forward iteration within the object storage during the object matching and the update step of the EKF.
The backward iteration occurs before the object matching takes place. Based on the received sensor time
stamp, the existence of objects in the object storage at the given time is checked. These historic object states
including the ego state are applied for the transformation and matching procedure. In case of a successful
match, the state estimation is corrected at the given sensor time stamp and the corrected state is iteratively
predicted up to the ego time stamp. New unmatched objects, which are initialized at the outdated perception
time stamp are also iteratively predicted up to the ego time stamp. With this concept, the implemented
delay compensation enables the synchronization of the tracked object states with the ego time stamp while
still considering delayed perception inputs up to 200 ms and is one of the core features to enable high-speed
multi-object racing.

2.9 Prediction

There are some key aspects in which prediction in autonomous racing diﬀers from that on public roads: First,
the vehicles are in direct competition with each other. While all participants want to avoid a collision, they
are not necessarily cooperative, but competitive. Second, there are no intersections, lanes, or traﬃc rules.
While the absence of intersections or forks initially simpliﬁes the prediction task, this task is complicated by
the absence of traﬃc rules and lanes. This ultimately leads to situations where the lateral uncertainties of
predictions take up the entire width of the race track because a wide variety of driving and behavior patterns
are possible with the same initial situation. Third, multiple laps are run on the race track. So similar
situations appear several times during a race and can be used as valuable information for future predictions.
In the following, we will brieﬂy present our approach to the trajectory prediction of adversarial vehicles,
returning to these particular aspects. Current approaches in vehicle trajectory prediction are classiﬁed
into three diﬀerent categories (Karle et al., 2022): physics-based, pattern-based, and planning-based. Our
approach incorporates components from all three of these categories.

The prediction model is based on the following input data: a tracked object list (Section 2.8), an ego-state
tracked over time (Section 2.12), and map information (Section 2.2). As output, a most likely trajectory for
each vehicle on the track is sent to the planning module (Section 2.11) in the form of time-dependent x
y
positions over a time horizon of 5 s with a sampling rate of 5 Hz. We also incorporate uncertainties with a
bivariate Gaussian distribution for every local point.

−

We build our approach on an LSTM-based encoder-decoder architecture. This network encodes the states
of the predicted vehicle, as well as the track boundaries with LSTM layers. Unlike common approaches
for road traﬃc (Messaoud et al., 2020), we avoid using an image-based map representation due to the
simple track geometry, and instead make use of a much more eﬃcient way by processing the left and right
boundary similar to the ego state history in a vector representation. The diﬀerent input streams are fused
by concatenation in the latent space.
In contrast to previous work (Deo and Trivedi, 2018), we do not
use LSTM decoders that generate corresponding time-dependent points as trajectories. The use of LSTM
decoders has the deﬁnite disadvantage that the predicted trajectories are often physically infeasible and leave
the track, for example. Hence, we extend this purely data-based approach to include physical knowledge:
We identify basic trajectories that completely cover the output space of predictions by linear combination.
Consequently, the neural network directly learns not the time-dependent positions, but weighting factors for
the base trajectories; We call this mixture of data-based and physical approaches MixNet, which is discussed
in further detail in (T¨or¨ok et al., 2022). Furthermore, to make use of observations from past laps in similar
situations we investigated an additional online-learning approach (Geisslinger et al., 2022), which adopts the
weights in a neural network according to an observation loss. However, due to a lack of robustness (and the
inability to recognize speciﬁc objects), eventually, we did not incorporate this online learning in the ﬁnal
software stack.

We also want to account for interactions on the race track in the sense that each vehicle’s behavior does not
depend only on its past states and the track boundaries, but also on the other vehicles around. This can be
solved by learning interactions from a data set in the neural network, but the solution requires vast amounts
of data from interactive scenarios. To account for the interaction of diﬀerent vehicles (including the ego
vehicle) in our prediction network, we modify the predictions with a subsequent planning-based approach.
For this purpose, we ﬁrst predict each vehicle, including the ego vehicle, independently. The predictions
are checked for collisions and only if a predicted collision occurs are the trajectories modiﬁed. Based on
the racing rules, which are similar to those of Formula 1, we make the simplifying assumption that the rear
vehicle must react to the leading vehicle and adjust the prediction of the rear vehicle accordingly. To do
this, we utilize fuzzy logic to decide whether an overtaking event will occur and whether it will occur on the
left or right side.

We also use a priori quality measures of our MixNet predictions, which are described in (T¨or¨ok et al., 2022).
Once a quality measure exceeds a certain threshold we fall back to a simpliﬁed, naive prediction. In this naive
prediction, we use a constant velocity proﬁle originating from the object tracking (Section 2.8) and assume
that the vehicle will hold its line in terms of lateral positioning between the left and right boundaries. This
simple, but eﬀective approach proved to be suﬃcient for the passing competition at the AC@CES (Section
4.2).

2.10 Global Planning

The global planning module builds upon the work of Christ et al. (Christ et al., 2019). Their work describes
an optimal control problem (OCP) to solve a minimum lap time problem for an autonomous race car, which
is transcribed into a nonlinear program (NLP) via direct orthogonal collocation. The OCP is formulated
using the CasADi modeling language (Andersson et al., 2019), and subsequently solved using the Interior
Point OPTimizer (IPOPT) (W¨achter and Biegler, 2006).

The optimization problem to be solved minimizes the achievable lap time tl,

min tl =

(cid:90) SΣ

0

dt
ds

ds =

(cid:90) SΣ

0

1

nκ

−
v cos (ξ + β)

ds,

(4)

while simultaneously adhering to the constraints stemming from the driving dynamics of the vehicle, which
we describe as a nonlinear double-track model. With this, we can ensure that the realistic vehicle dynamic
behavior is captured - especially the nonlinear behavior of the tires. The traveled distance s along the
reference line is used as the independent variable. The race track geometry is described by the curvature
proﬁle κ, v denotes the velocity on the racing line, n the lateral distance to the reference line, β the side slip
angle, and ξ the relative angle of the vehicle to the tangent on the reference line. For further details on the
formulation of the OCP and the constraints we refer the reader to our previous work in (Christ et al., 2019).

2.11 Local Planning

The main task of the local planning module is to generate a trajectory that guides the vehicle through the
local dynamic environment. Since the racing scenario requires the car to adapt quickly to new circumstances,
the local planner should provide an updated trajectory every 150 ms. The trajectory should follow the
global racing line from Section 2.10 whenever possible and be collision-free in multi-vehicle scenarios. The
inputs for the trajectory generation are the map of the race track, the global racing line, the current state
estimation, and the predicted behavior of the surrounding race cars. After generation, the trajectory is
sent to the subsequent control module. Since the MPC-based controller re-optimizes the trajectory, the
planning module also provides a collision-free corridor around the planned path serving as a constraint for
the re-optimization. The state estimation is not directly used as a starting point for the planning step but
is projected onto the trajectory planned in the previous step. The starting point is calculated from this
projected state by interpolating along the last planned trajectory to the average calculation time. This
interpolation step avoids jumping trajectories across multiple planning steps and ensures consistent motion
planning.

Our trajectory planning approach is a combination of a sampling and a graph-based method. The spatio-
temporal graph used is structured in layers perpendicular to a reference line using the curvilinear Fren´et
coordinates s, the longitudinal progress along the reference line, and d, the lateral displacement (Figure 7b).
The spatial part of the graph is constructed according to (Stahl et al., 2019a) and consists of spatial nodes
(black points) distributed on the layers and spatial edges (gray lines) connecting the nodes. Since a search
in the spatial graph alone cannot solve the combinatorial planning problem, the spatial nodes are extended
by the time and velocity dimensions.
Instead of using discrete values, we cover the reachable times and
velocity with continuous intervals as in (McNaughton et al., 2011), resulting in spatio-temporal nodes (cells
of the grids). The spatio-temporal edges (red, green, and black lines) are trajectory sections connecting these
spatio-temporal nodes within the layers. After generation, each spatio-temporal edge is associated with a
cost.

The planning step consists of two parts depicted in Figure 7: The short-term planning step (STPS) and
the long-term planning step (LTPS). While the STPS creates connecting edges from the start state (blue
point) to the next graph layer, the LTPS performs a subsequent graph-search within the successive layers.
Due to the update frequency of the local planning module a trajectory is not driven completely, so that the
part generated by the STPS is mostly the part driven. Therefore, the main task of the STPS is to generate
multiple ﬁnely planned spatio-temporal edges close to the driving limits. In contrast, the LTPS fulﬁlls the
requirement for a suﬃcient planning horizon by performing a coarse graph search. This enables the planning
module to react earlier to curves and other race cars. With a long planning horizon, the LTPS thus leads
the STPS with a shorter horizon to ensure recursive feasibility.

Within the STPS, a set of spatio-temporal edges from the start state to the next layer is created using a
polynomial approach and sampling various end conditions in Fren´et coordinates. Similar to the planning
concept for traﬃc scenarios in (Werling et al., 2012), we use quartic polynomials in both lateral and lon-

t

t

v

v

t

v

s

t

v

t

v

t

v

t

v

t

v

d

(a) Short-term planning step (STPS)

(b) Long-term planning step (LTPS)

Figure 7: Overview of the short-term and long-term planning steps for the local trajectory planning.

gitudinal motion, as this allows for fast computation of variable and ﬁnely planned trajectories for a short
horizon. However, in contrast to the mentioned approach for traﬃc scenarios, it is necessary to embed the
polynomials in the graph structure. For the edge to reach the next layer with the individual heading angle
of the spatial node, the longitudinal end position and both end velocities must be speciﬁed accordingly.
Besides these adaptions, the edges must also comply with the more demanding race scenario in terms of
performance. Since an additional sampling of the end acceleration would increase the computation time too
much, we use an iterative process to determine only one acceleration end condition for each spatial node and
end velocity combination.

Beginning at the spatio-temporal nodes connected to the start state by the edges of the STPS as exemplarily
shown for one node in Figure 7b, the LTPS performs a search in the spatio-temporal graph. It generates
edges connecting spatio-temporal nodes of the following layers until the desired planning horizon is reached.
In general, a spatio-temporal node can be reached with multiple paths through the spatio-temporal graph,
ending in the time and velocity intervals of the node (blue squares). Each path has a total cost which is the
sum of the edge costs along the path beginning at the start state. Instead of expanding all reached states
with edges to the next layer, only the end state of the cheapest path ending within the intervals is used
as an initial state for further expansion from the considered node. This procedure follows the principle of
dynamic programming and not only reduces the number of nodes by the use of intervals, but also prevents
the exponential growth of the number of edges to be generated with an increasing planning horizon. As in
(McNaughton et al., 2011) we sample constant accelerations along the spatial edges to create the spatio-
temporal edges. This is shown in Figure 7b, simpliﬁed with one acceleration (green) and one deceleration
(orange) proﬁle applied per spatial edge. Instead of an exhaustive search that proceeds from layer to layer,
we perform a search based on Dijkstra’s algorithm (Dijkstra, 1959) which is suited for graphs that are built
during the search and often referred to as uniform-cost search. This algorithm makes it possible to go back
in layers and expands only the node with the cheapest path to reach it. While the uniform-cost search
retains optimality in terms of our cost function, it requires signiﬁcantly fewer edges to be generated in our
application, reducing the computation time by a factor of three compared to an exhaustive search. Another
major advantage is that the search can be interrupted if it approaches an upper calculation time limit. In
this case, we select the – at this stage – cheapest available path through the graph that satisﬁes the planning

horizon and still obtain a suboptimal solution.

The costs of the edges determine the vehicle’s behavior and must be carefully chosen to achieve safe driving
on the one hand and competitive racing on the other hand. Our cost function consists of four terms, each
serving a diﬀerent behavior. The ﬁrst term penalizes the deviation from the global racing line to reach fast
laps in single-vehicle scenarios. A second term penalizes the deviation from the target speed provided by
the racing line or by rules. For multi-vehicle racing, a prediction cost term ensures that certain lateral and
longitudinal distances to other vehicles are kept and that overtaking maneuvers are initiated in time. Ellipses
cover proximity regions to the predicted opponents to be avoided and provide a fast calculation for a distance
measure. Finally, the fourth term penalizes the curvature for avoiding abrupt steering at high speeds. The
curvature term especially comes into play in multi-vehicle scenarios and smoothes out overtaking maneuvers.

Besides high costs preventing spatio-temporal edges from being further considered in the search, edges can
be sorted out completely. First, the edges from both the STPS and the LTPS have to be feasible in terms of
maximum curvature, engine power limits, and velocity-dependent combined acceleration limits on the vehicle
level so that the subsequent controller can ﬁnd a re-optimized solution. Edges that exceed the limits – stored
and accessed with lookup tables – are sorted out. Second, edges have to be collision-free. To determine a
collision, we follow a hierarchical approach starting with oriented bounding boxes of the underlying spatial
edge and ending with the exact geometry of the vehicle. Since the prediction becomes more uncertain with an
increasing planning horizon, we introduce a collision checking horizon for which the prediction is conﬁdent.
Only edges that collide within this horizon are sorted out. A suﬃcient distance to the predictions for the rest
of the trajectory, and thus recursive feasibility, is ensured by the prediction cost term. Since the edges from
the STPS are mainly aﬀected by the hard collision checks and not many behavioral options are available at
this stage, there is a risk that no collision-free solution is available. In this case, we perform soft collision
checks and allow colliding edges with an additional distance cost term to lead the vehicle out of the proximity
region as quickly as possible.

Additionally, the local trajectory planner generates an emergency trajectory for safety reasons. Both local
and emergency trajectories are sent to the control module in every planning step. The emergency trajectory
decelerates on the path of the actual trajectory to eventually reach a safe state at standstill. It utilizes the
full potential of the tires in terms of combined acceleration.

2.12 Motion Control

The motion control module is responsible for the determination of appropriate throttle, steering, and brake
commands based on the planned trajectory. This includes feed-forward as well as feedback actions. The
controller is structured as a three-layer concept (Figure 8a), with the highest layer utilizing a Tube-MPC with
a limited friction point-mass model, an extension of a previous work (Wischnewski et al., 2021). This layer
handles deviations in the position and velocity. The middle layer consists of independent PI-like controllers
for the lateral and longitudinal accelerations. They serve the task of matching the vehicle dynamics with the
assumptions in the Tube-MPC as well as handling model inaccuracies in the utilized feed-forward control
laws. The third layer adds a low-level feedback loop for the steering actuator to ensure tracking with zero
steady-state error and prevent negative impacts of this subsystem on the higher-level control loops.

The second task of the motion control module is the re-optimization of the planned trajectories. Instead
of applying a classical tracking control scheme, the cost function of the Tube-MPC is designed so that
the lateral motion is mainly inﬂuenced by the driving tube constraints (Figure 8b) and not via a tracking
target. This enables smooth driving behavior at the limits of handling, even though the graph-based local
trajectory planner uses a rather coarse discretization to ensure frequent updates to the local target trajectory.
However, this requires some changes to the classical MPC concept: A nominal MPC would exploit the limits
aggressively, which might lead to constraint violation in the presence of disturbances or uncertainties. The
proposed Tube-MPC replaces the prediction of the nominal model behavior with a set of predictions of
potential uncertain outcomes (bold orange lines in Figure 8b). This leads to a closed-loop behavior that

applies caution towards the end of the prediction horizon, as the optimizer requires that all constraints are
fulﬁlled for the uncertain predictions rather than for the nominal prediction only.

(a) Internal motion control structure

(b) Driving and uncertainty tubes

Figure 8: Overview of the motion control algorithm based on Tube-MPC.

The motion control software was developed using Simulink and a custom C-code integration of the numerical
solver OSQP (Stellato et al., 2020). The deployment was done via code generation from Simulink and the
addition of Robot Operating System 2 (ROS2) interfaces via a custom wrapper node. The software runs the
main cycle of the module with a frequency of 100 Hz and handles incoming data via asynchronous callbacks.
As the AV-21 does not have a dedicated real-time control ECU, we utilized real-time scheduling priorities
and CPU isolation (to ensure that only speciﬁc processes or threads are scheduled on certain CPU cores) to
achieve reliable execution times on the Ubuntu-based x64 computer.

2.13 Middleware & Latency

Our entire software stack is based on the middleware ROS2 Galactic. For Data Distribution Service (DDS)
implementation we rely on the open-source Eclipse Cyclone DDS version. For the development and de-
ployment of the software stack, the principle of virtualization using Docker is applied. Here, every module
corresponds to a Docker image that is launched via Docker Compose either on the vehicle or in the simulation
environment. The usage of a docker container is advantageous for deployment and versioning. The isolation
especially ensures that software dependencies and requirements are not in conﬂict with other modules. Each
container is based on an OS base image, in our case we use Ubuntu 20.04. The running containers share
a kernel with the OS of the vehicle computer. A CPU isolation was set up to ensure the computation of
time-critical modules on speciﬁc cores. Using Docker Compose as an orchestrator each module or service
can be allocated to a certain percentage of core usage.

The communication between the software stacks’ modules is designed asynchronous. The default option in
ROS2 for the data history is set to 10. As we work asynchronously, we do not make use of historical data
and only use the most recent message. Therefore, the queue length of the message buﬀer is set to 1. The
reliability of the quality of the service proﬁle is set as follows: For sensor data, recent data are used at
the expense of losing some, to achieve as fast as possible processing. Thus, all communication interfaces to
sensors are set to best eﬀort. Furthermore, it is necessary to ensure that the communication between modules
is set to reliable, meaning that the whole data package is delivered. Due to the asynchronous character of
the software, small delays in communication can occur. These delays result from communication between
modules with diﬀerent cycle times. Nevertheless, this feature provides a beneﬁt. It enables ﬂexibility within
the development process of the modules, which is of importance for the overall project progress.

The software stack has no real-time behavior as the speciﬁc modules have no ﬁxed runtime deadlines. Many
modules are developed using Python, whereas time-critical algorithms are based on compiled C/C++ code.
Table 2 provides an overview of the cycle time of the respective modules. The average end-to-end latency

TrajectoryplanningTube-MPCLong.andlateralaccelerationcontrollersSteeringcontrollerVehicledynamicsStateestimationThrottlebrakefrom sensor output to the controller output results in 304.20 ms with a standard deviation of 38.01 ms for
the clustering pipeline. For the RADAR pipeline an average end-to-end latency of 179.22 ms with a standard
deviation of 21.53 ms occur. Additionally, an actuator latency of 60 ms on average needs to be added to the
software runtime, which can be approximated from the controller’s target and actual values. All previously
mentioned settings are based on the ﬁnal race at the AC@CES.

Table 2: Statistical overview about the module cycle times display in ms.

module
Clustering
RADAR
Prediction
Planning
Control

mean
79.94
50.01
50.00
107.55
10.00

std
26.31
35.17
3.53
14.33
0.41

min
12.37
1.67
5.62
74.15
7.63

25 %
50.81
14.43
48.12
97.75
9.90

50 %
88.30
50.00
50.00
106.93
9.99

75 %
98.42
85.58
51.88
111.75
10.10

max
259.06
136.74
98.78
239.40
12.48

3 Software Development

3.1 Parameter Optimization & Software-in-the-loop Testing

Important tasks in the development of autonomous race cars at the handling limits are the validation and
testing of the software stack. To ensure robust vehicle behavior before testing the software on the real vehicle,
two test phases are introduced: Software-in-the-Loop (SiL) and Hardware-in-the-Loop (HiL) testing. The
Software-in-the-Loop simulation environment is a fast way to test and validate the software stack. The
test environment can be run on the developers’ workstations. Some limitations arise in this environment
from the fact that the perception and localization module cannot be tested. Their reliability and robustness
are examined by the HiL simulator or by recordings on the real vehicle. SiL is ideally suited for software
stability analysis and the investigation of predictive and planning behavior. Especially when testing vehicle
behavior for rule consistency, the SiL has shown signiﬁcant advantages in reducing the time investment of
the developer and in increasing software reliability. Errors in the setting of race rules can be identiﬁed and
corrected. The overall testing workﬂow concept can be seen in Figure 9.

In total, there are nine diﬀerent stages in the test procedure. Usually, modiﬁed software is reviewed by
the developer. As a further veriﬁcation step, the collaboratively developed software is tested automatically
through our own Continuous Integration/Continuous Development (CI/CD) pipeline. This pipeline checks
the module for general errors in the code. In addition, a detailed test run of the entire software is performed
every night. This creates a time-based performance history of the software based on deﬁned Key Performance

Figure 9: Overall testing workﬂow.

Development Process209.02.2022 | Testing & Parameter OptimizationSoftware DevelopmentAutomaticGitlab CI/CD TestingSoftware Testing by DeveloperDaily Automatic Full Software-Stack Test HIL TestingSoftware Release TagAutomatic Parameter OptimizationTesting New Parameters on HILReal World Testing1in the computing time of the modules, can be detected quickly so that
Indicators (KPI). Diﬀerences, e.g.
they can be addressed in the development process in a short time. Lap time and success rate are generally
the most important objectives. Predeﬁned scenarios are tested in the pipeline. Each scenario is evaluated
in terms of successful completion. The further the vehicle gets, the better the score of the optimization run.
In the event of failure, the scenario provides information about possible weaknesses in the software.

Testing Environment
The scenarios correspond most closely to real driving situations when opposing vehicles are on the track.
Therefore, we use an additional module in the SIL to generate opponent vehicles. The generated dummy
objects can follow a deﬁned trajectory. For a more realistic simulation of the objects, it is possible to add
noise to the object’s perceived trajectory. A scenario catalog is deﬁned to test the software under a variety of
circumstances automatically. In addition to the performance tests, the software is also tested for emergency
scenarios. For this purpose, a tool was developed that triggers an automatic error within a module in
random situations. To simulate this, a single software module is disabled via Docker so that there is no
further communication between that module and the rest of the software. The software must be able to
bring the vehicle to a safe stop while complying with deﬁned safety criteria.

Automatic Parameter Optimization
When the software is working correctly, it needs to be optimized to meet the requirements of the racing
scenarios. For this reason, we have developed an optimization tool that automatically searches for suitable
module parameters. We use Nevergrad for gradient-free optimization of the parameters (Rapin and Teytaud,
2018). The tool has proven to be particularly helpful in optimizing the parameters of the planning module.
Suitable cost terms of the graph planner can be determined quickly. The optimization process can be seen
in Figure 10.

The optimization is executed on the LRZ Compute Cloud (Leibnitz Rechenzentrum, 2022). Diﬀerent simu-
lations can be executed simultaneously. A test-based population size adaptation (TBPSA) method proved
to be a suitable optimization algorithm since we simulate in a non-deterministic, noisy environment (Hellwig
and Beyer, 2016; Liu and Teytaud, 2019). After a few hundred iterations, good results can be obtained.

Figure 10: Optimization workﬂow.

OptimizationengineComputing power allocationControlPlannerPredictionPerceptionROS_ID=1docker-composeControlPlannerPredictionPerceptionROS_ID=2docker-composeControlPlannerPredictionPerceptionROS_ID=3docker-composeLRZ ComputeCloudScenariosParameter set1nm…………m*nPerformance evaluationThe gradient-free optimization leads to fast results, but due to the noisy non-deterministic environment, no
global minimum can be guaranteed. The target value of the optimization is the average lap time. The mis-
behavior of the vehicle, such as exceeding acceleration limits, is incorporated into the lap time. If the vehicle
leaves the track or causes a crash, the run is considered to have failed. In this case, the maximum distance
traveled within the scenario can be used to evaluate the performance. In the next step, the parameters can
be conﬁrmed on the (HiL) simulator and the race car.

3.2 Hardware-in-the-loop Testing

To allow a quick and agile software development, testing, and integration workﬂow, a sophisticated simulation
environment was developed. It enables testing of deployment-ready software independent of the vehicles and
external factors. The use of such simulation environment is a crucial element for successful participation in the
challenge. Beyond the SiL simulation introduced in Section 3.1, we developed a Hardware-in-the-Loop (HIL)
simulation fulﬁlling the needs of autonomous racing. The setup is shown in Figure 11. This environment
allows simulating one full-stack AV-21 including perception and sensors and up to nine competitors with the
whole software besides perception (prediction, planning, control). The ego vehicle computer is a consumer
desktop PC with speciﬁcations similar to those of the computer in the real Dallara AV-21. The other vehicles
are represented by computers with a comparable CPU and no GPU. A Speedgoat Performance machine is
responsible for calculating the vehicle dynamics of all vehicles in real-time. Therefore, a double-track model
was developed and implemented in Matlab Simulink. The three-dimensional scene with all vehicles and the
track model is calculated and rendered on a GPU server. With the Unity engine, sensor models for LiDARs
and cameras are realized to enable full-stack closed-loop simulation. All generated data (rosbags and internal
software logs) are automatically saved on a cloud storage. A visualization and operation PC allows easy
access to all components of the HIL setup and quick analysis of the runs.

To make the transition and changes from the HIL to the real car as smooth as possible, the whole ROS2
interfaces and the state machines of the AV-21 are integrated into the simulation. During switching from
the real car to the HIL, the only code change that has to be made is using custom drivers for cameras and
LiDARs. This also allows the integration of the race control and base station interfaces as on the actual
cars.

Basic GNSS and RADAR models are integrated into the vehicle dynamics simulation and sent to the vehicle
computers via UDP. The sensor drivers convert the UDP streams to ROS2 messages and publish those. For
cameras and LiDARs, more detailed models were developed in the Unity environment. The virtual cameras
are based on a pinhole camera model to render the environment and other cars from the same perspective as

Figure 11: Overview of the TUM HIL architecture.

All vehicle states (V2V)All Vehicle States Actuator signalsActuator signalsDataStorageActuator signalsCamera and LiDAR UDP streamRosbags, Software logsOpponent Vehicle 9Prediction, planning, controlOpponent Vehicle 1Prediction, planning, controlEgo VehicleFull-stacksoftwareReal-timevehicledynamicssimulationSpeedgoatPerformanceEnvironmentand sensorsimulationGPUServerOperationandvisualizationDesktopComputer& MonitorSSH / RDP(a) Real point cloud from the AV-21

(b) Synthetic point cloud from the TUM HIL

Figure 12: Comparison of real and synthetic point cloud.

the real cameras. The LiDAR model is based on raycasting. Resolution and scanning patterns are adjusted
to the Luminar LiDARs, deployed on the real vehicle, and can easily be adapted to any other LiDAR. The
model incorporates noise, can handle transparent structures, and calculates intensity based on the surface
color when material information is missing. The implementation of the scanning pattern also results in
motion blur, which is especially important at higher speeds. Figure 12 shows a real and a synthetic point
cloud from our simulator.

4 Event Analysis

4.1

Indianapolis - Indy Autonomous Challenge

The IAC on the Indianapolis Motor Speedway on the 23th of October 2021 set out to be the ﬁrst race
showcasing fully autonomous race cars. In the lead up to the race were multiple simulation challenges during
the year of 2021 where multi-vehicle racing between the software stacks of the diﬀerent teams could be shown.

The race format was as follows (Energy Systems Network, 2021): Each team can show up to two runs.
Whether a second run can be performed depends on the performance in the ﬁrst run. The ﬁrst run is
divided into a high-speed part and an obstacle avoidance part. In the high-speed part, the teams were given
an out lap, two warm-up laps and two high-speed laps. The track layout is displayed in Figure 13. Following
the fast laps, two obstacles blocking opposite sides of the track must be avoided. The obstacles were placed at
a random position on the start/ﬁnish straight at a longitudinal distance of 100 m. If the vehicles avoid these
obstacles at a speed of 28 m s−1, the run is considered successful. The average lap time over the two high
speed laps determined the ranking position after the ﬁrst run. The three teams with the fastest averaged lap
times and a successful pass of the obstacles advanced to the second and ﬁnal run. In the ﬁnal run, a total of
four warm-up and two high-speed laps were given. The starting order was determined by the ranking of the
ﬁrst run. The team with the fastest averaged lap time over the two high-speed runs wins the competition.

Pushing into new speed ranges for autonomous vehicles brings both diﬃculties and learnings. When the
speeds were noticeably increased during test sessions it could be observed that an important assumption of
the used vehicle dynamics simulation could not be met. In the speed range up to 60 m s−1 it proved to be
diﬃcult to get the tires up to their nominal operating temperature. Warm-up rates < 8 °C/lap and maximum
tire core temperatures of 50 °C showed that it would be diﬃcult to reach the optimal tire temperature range
of 80 °C-100 °C. This proved to be challenging since the tire data for ﬁtting the tire model of the simulation

Figure 14: Comparison of the racing lines. A classic racing line in blue, replaced by a curvature change
minimized racing line in light blue. Due to smaller cuvature gradients, the necessary rates of change for
lateral acceleration and yaw rate to run the latter trajectory could thus be reduced by 38 %.

is naturally recorded in warm conditions. The simulation as a means to estimate the vehicle performance
limit is therefore subject to an unknown uncertainty in tire data. Therefore, to further increase the speed, an
exploratory approach with small speed increases on the track was chosen. This example illustrates advantages
of a robust design of the algorithms to deliver a good performance even under uncertainty or disturbances.
It should also be noted that despite the focus on the software side in this challenge, conventional vehicle
performance aspects should not be overlooked.

With increasing speed, it could additionally be observed that at the exit and en-
trance of the 90° turns, there were increasing challenges in the tracking of the lateral
dynamics. The lateral accelerations required by the trajectory could no longer be
built up and reduced at the desired rate. Analysis showed that this happend due
to latencies at the steering actuator itself and on the signal path to the steering
actuator, a shortcoming which was partly compensated for the Vegas event with the
steering controller proposed in Section 2.12. Additionally the tire was increasingly
operating in the nonlinear range, and the factors of tire run-in length and the yaw
inertia of the vehicle became more relevant. To remedy this, the global trajectory
of the vehicle was modiﬁed and optimized towards reduced curvature change rates.
With this new global trajectory, the vehicle no longer arrives at the corner entry on
the outer side of the track, but moves to the center. The vehicle then pulls outward
in a swerve and ﬁnally moves towards the apex in a manner comparable to a classic
racing line as shown in Figure 14. This behavior is mirrored at the exit of the turn.
This is similar to a racing line often chosen by human IndyCar drivers, because is
decreases the necessary yaw accelerations and therefore maximizes the combined
usable tire grip for lateral acceleration.

The test period was essentially completed without the occurrence of collisions or loss
of control. Internal errors could mostly be detected by the internal self-monitoring
and safety stops were initiated. Once a loss of control could not be prevented by
the software and an incident occurred during an attempt to increase the top speed
driven up to that point. At a corner entry speed of 61 m s−1, the car spun 360 ° at
the exit of Turn 1 and came to a stop just before leaving the track boundary on
the short chute between Turns 1 and 2. The analysis found multiple root causes:

Figure 13: Map of
the Indianapolis Mo-
tor Speedway. The
track length is 4023 m
with a banking of 9°
throughout the turns.

100150200250300350400450distance in m-2024curvature in 1/m10-3baselinecurvature change minimized• At the beginning of this testing day, the parameterization of the turbocharger was changed for
all the cars to achieve the nominal engine performance for the event, which noticeably increased
the available boost pressure. The response time of the turbocharger resulted in the throttle control
starting to oscillate up against the turbocharger inertia. At low speeds, this is not noticeable because
of the lower torque requests, but at speeds around 60 m s−1, it became apparent that the throttle
requests oscillated between 40-60 %, resulting in ECU internal boost requests changes from 0-100 %.
This was strongly aﬀecting vehicle dynamics and resulted in longitudinal acceleration oscillations of
+/- 2 m s−2 with a frequency of 0.5 Hz.

• Just before the spin, the input of the state estimation did not receive an update of the GPS position
for several cycles. Due to cumulative integration errors of the estimation by acceleration sensor data
only, a stepwise correction of the lateral error occurred when the GPS signal was received again.

The cause of the spin can be explained by the combination of the two reasons. On the one hand, the vehicle is
generally closer to a vehicle-dynamically unstable state in the phases in which the drive torque is decreasing.
On the other hand, the abrupt correction of the lateral error caused an additional excitation of the controller,
which increased the steering angle. This led to a situation with lift-oﬀ oversteer which was favored by the
increasing steering request. Since the software is conceptually not capable of counteracting oversteer but
has the sole goal of fulﬁlling lateral deviation constraints, the described situation could no longer be solved
adequately and resulted in a 360° spin. For future work, this highlighted the importance of a control module
with the ability to stabilize unstable driving situations if the vehicle dynamic limit range is to be further
exploited.

Another similar spin occurred on the vehicle of the contending team of PoliMOVE. As a consequence and
in consultation with the organizer, some setup adjustments were made to all cars. The aerodynamic and
mechanical balance was shifted by adjustments to wing angles and anti-roll bar conﬁguration in favor of
improved grip for the rear axle to provide a greater stability reserve in comparable situations. In addition,
the turbocharger parameterization was changed to ensure a linear torque delivery across the engine speed
range. On the vehicle software side, the P-gain of the lower-level longitudinal acceleration controller was
reduced to decrease the oscillation tendency of the accelerator pedal request.

On race day, the potential of the car could be shown. At a temperature of 12 °C and cloudy conditions both
runs could be ﬁnished successfully. In the ﬁrst run, an average lap time of 69.7 s and an average speed of
58.4 m s−1 could be reached. This was enough for the provisional second place and thus for a place in the
ﬁnal. In the second run, an average lap time of 66,2 s was achieved with an average speed of 61.5 m s−1. The
speed and lateral acceleration diagrams of the two runs can be seen in Figure 15a.

The challenge in the trade-oﬀ between speed and risk was, on the one hand, the unknown tire performance
at tire temperatures below optimum. On the other hand, a limiting factor was the level of development
from a hardware and software perspective achieved up to that point. This becomes particularly evident in
the plot of the lateral deviation. Especially at the entry and exit of turns, lateral deviations of up to 1 m
were reached. This reaches the constraints of the lateral deviation in the optimization problem of the MPC.
If the lateral deviation increases to more than 1 m, the aggressiveness of the controller behavior increases
signiﬁcantly due to the controller design as proposed in (Wischnewski et al., 2021). A lateral deviation of
> 1 m is still manageable, but the risk increases disproportionately above this. In Figure 15b it is shown
that the maximum lateral deviation during the second run was > 1.03 m.

With additional testing data, higher speeds would have been possible at the expense of higher lateral devia-
tion. Due to the limited testing time and the unknown velocity regime, it was decided to go for a balanced
compromise between velocity and risk according to the motto ”To ﬁnish ﬁrst, ﬁrst you have to ﬁnish”. In
the end this secured the ﬁrst oﬃcial win of the inaugural edition of the IAC which came with a Grand Prize
of one Million USD.

(a) Speed and lateral acceleration: In the second run, the speed was set to 67 m s−1 on the straights and 61 m s−1
during the turns.

(b) Lateral path deviation: Even though the speed in the second run was faster the lateral devation did not increase.
The reason for this were higher gains of the low level acceleration controller which got retuned inbetween the runs.

Figure 15: Analysis of vehicle dynamics and controller performance at the IAC.

4.2 Las Vegas - Autonomous Challenge at CES

±

The Autonomous Challenge at the CES 2022 (AC@CES), the second
major event, took place on the 7th of January 2022 at the Las Vegas
Motor Speedway (Figure 16). The event’s focus was autonomous over-
taking of two competing vehicles, i.e. a dual-vehicle competition. The
race rules were deﬁned as follows: The leading vehicle was the defender
and was obligated to maintain a ﬁxed speed with a tolerance of
5%.
Besides that, the defender had to stay on the inner side of the race track
to prevent arbitrary blocking maneuvers. The trailing vehicle, the at-
tacker had the task to conduct a successful overtaking maneuver against
the defender within a given overtaking sector. To ensure that the at-
tacker had a fair chance to overtake, some prerequisites must be fulﬁlled
before the overtaking sector is entered. These were the target speed of
the defender and the maximum distance threshold between attacker and
defender at the start of the overtaking sector. During the overtaking
the cars had to respect a exclusion zone around the vehicles, deﬁned in
a lateral and longitudinal direction. A match between two opponents
followed predeﬁned target speeds starting from 28 m s−1 with degressive
steps. The roles of attacker and defender switched after every successful
overtaking maneuver. The target speed was increased to the next step as
long as both vehicles were able to overtake. Hence, the team that failed
ﬁrst to overtake lost the match. The ﬁnal event of the AC@CES was scheduled with single performance
runs to evaluate the seeding based on the fastest single lap time and the main competition consisting of the
described dual-vehicle challenge with two semi-ﬁnals and one ﬁnal run. From the technical point of view,
the following aspects were our focus in preparation for the race:

Figure 16: Map of the Las Ve-
gas Motor Speedway. The track
length is 2410 m with a banking
of 20° in the turns.

0500100015002000250030003500400055606570 v in m s-105001000150020002500300035004000Distance in m01020 ay in  m s-2Run 1Run 205001000150020002500300035004000Distance in m-1-0.500.51Lateral deviation in mRun 1Run 2Figure 17: The cascaded steering controller in real world operation. “target” marks the steering angle that
is requested by the controller. “request” denotes the signal calculated by the steering controller that is sent
to the actuator. “actual” shows the sensor signal that is reported back by the actuator. It can be seen
that through the implementation of the steering controller the steady state steering angle deviations can be
compensated in order that “actual” matches “target”.

• Adaption of the global map to the new race track with the challenge of a higher banking angle.

• Improved adaptation of the controller to the vehicle hardware to enable higher speeds and acceler-

ations.

• Adjustment and ﬁne-tuning of the perception pipeline for banking areas and fusion of multiple

modalities.

• Optimization of the cost function in the local planning module for safe but aggressive overtaking

behavior.

The global map and the resulting racing line had to be adjusted to the race track geometry, which provided
a higher banking angle. We could beneﬁt from the experience we made in Indianapolis and by this could
release a ﬁrst valid draft of the map and racing line before the ﬁrst test week. However, we faced again
challenges in the ego state estimation due to our 2D representation on a 3D track. By projecting the acting
forces into the plane it was possible to handle this issue. To implement this transformation, knowledge of
the location-dependent road banking angle is required. Due to the signiﬁcantly higher banking compared
to Indianapolis, it turned out that a precise banking map is required to enable accurate localization. Since
it was not possible to measure road banking directly, such a banking map could only be obtained by an
iterative improvement. The residuals of the state estimation served as metrics for the evaluation. In the
future, a 4+ degrees of freedom (DOF) state estimation should be used instead of a 3 DOF one to realize a
more robust estimation.

To mitigate the problems described in Section 4.1 at the entry and exit of turns, the performance of the
steering actuator was identiﬁed as the main cause after examining the data. In particular, a remaining control
deviation in the steering angle and slow dynamics in the steering angle rates were noticed. The reasons for
this were a missing steering servo which increases the load on the actuator and that the current controller of
the actuator only uses a P-controller. This led to the implementation of a cascaded steering angle controller
described in Section 2.12 to mitigate the mentioned problems. The performance of the steering controller is
presented in Figure 17.

The tuning of the perception pipeline together with object fusion and tracking was another major task in
the preparation for the dual-vehicle competition. Especially to realize a reliable detection range along the
whole race track with varying banking angles was challenging as the vertical ﬁeld-of-view (FOV) of LiDAR
and RADAR are quite narrow. In the case of the LiDAR we could solve this issue on the hardware side
by adjusting the vertical high-density FOV along the s-coordinate on the track (section 2.3). The setup is
optimized for high sensor ranges on the straights with a tight opening angle and a comprehensive FOV with a
bigger opening angle at the entrance and inside the turns to be able to detect vehicles on parallel lanes. Due

10001100120013001400150016001700180019002000Distance in m01020Steering angle in rad10-3targetrequestactualto the high inﬂuence of the positioning before the overtaking maneuver, the ability to measure an object’s
velocity and a high sensor range of the RADAR comes into play. Due to the fact of a ﬁxed opening angle,
we optimized the RADAR perception on the software side. To cope with the high number of false positives
we adjusted the ﬁlter algorithm to process the RADAR data as described in section 2.7. Additionally, the
status counter in the fusion and tracking module (Section 2.8) was adjusted to count individually per sensor
depending on the ego-object-distance. By this, we could track objects with higher distances more stable
due to the weighted priority of the RADAR. If the object comes closer and is detectable by the LiDAR,
the weighted counting is changed in the way that the eﬀective sensitivity of the RADAR is decreased. In
combination, the speed measurement and initialization of an object could be realized at high distances, but
the robustness against false positives within the short range is not deteriorated.

An overview of the three event runs of the qualiﬁcation, semi-ﬁnal and ﬁnal is given in Figure 18. After the
qualiﬁcation run and a win in the semi-ﬁnal due to a crash of the competing vehicle, the ﬁnal event was held
with the pairing of PoliMOVE and TUM Autonomous Motorsport. In the ﬁnal event, we achieved a top
speed of 74 m s−1 during an overtake maneuver. However, at the next target speed step as a defender, our
software triggered an emergency brake because the vehicle got unstable and oversteered on the straight at
the moment when the attacker passed us. The reason for the unstable behavior was a false positive detection
that led to an object predicted to cross our trajectory and a respective maneuver by the local trajectory
planner. The whole combination of events will be discussed in the following.

The perception input was stable during the initialization of the overtaking maneuver, i.e. when the vehicle
was behind and near us, it was properly tracked over 5 s in total. Some false positives occurred, but none
of them were tracked more than the single step they occurred. As the attacker advanced on the outer line
60° in relation to the ego-heading a high delay of 200 ms occurred in the LiDAR
at an angular position of
perception pipeline due to a high amount of reﬂections. Considering that the matching is distance-based it
gets worse with high speed and high delay, which was the case in this step. The estimated position based on
the CTRV-model had a signiﬁcant yaw rate and by this, the position of the vehicle was forward integrated to
the inside of the track such that the maximal matching distances did not hold anymore. As a consequence,

−

Figure 18: Speed and lateral acceleration of the fastest laps and the following half lap at the AC@CES. Run
1 marks the single-vehicle qualiﬁcation run with a constant speed of 70 m s−1. After crossing the start/ﬁnish
line at 2444 m the vehicle backs of. The second run was held with TII EuroRacing as a competitor. Around
500 m it can be seen that the vehicle is closing the gap to set itself up for the overtake. The overtake started
in Turn 4 around 1850 m as the vehicle increased the speed. Due to a crash of the vehicle of TII EuroRacing
at the end of the overtake, no further speed increase was achieved. The maximum lateral acceleration during
the overtake is 28 m s−2. Run 3 represents the ﬁnal run against PoliMOVE. The vehicle closes the gap at a
later stage and the process takes longer because of the higher aerodynamic resistance at higher speeds. The
maximum speed achieved during this overtake is 74 m s−1.

406080 v in m s-1Run 1Run 2Run 30500100015002000250030003500Distance in m0102030 ay in  m s-2a new object was initialized on the outer line. However, the old object was still kept in the object storage
and its position was further estimated because its status counter was at the maximum value. The estimated
position drifted towards the inner racing line of the ego vehicle up to the point that the object was directly
at the ego position. The resulting prediction caused high costs due to object collision for the inner lines
of the graph. Hence, an evasion maneuver was planned to the right, i.e. to the outer side of the track.
At this point, another factor came into play. The acceleration limits did not consider the varying banking
angle along the track and especially did not consider the dependency of right and left turn. So the evasion
trajectory was calculated based on the maximal positive banking angle in the turns but was indeed executed
with a negative banking angle (right turn) on the straight. In combination with a slight deceleration, the
tire limits at the rear axle were violated and it got unstable, which led to a spin. To sum it up, the major
factors for the emergency brake were:

1. The perception delay caused by a high amount of reﬂection in the LiDAR pipeline.

2. The ﬁx maximal matching distance and the ﬁx status counter based on number of (non-)detections,
which did not reﬂect the actual uncertainty depending on the object’s speed and perception delay.

3. The missing spatial dependency of the acceleration limits in the trajectory planning to evaluate the

driveability of trajectories more precisely.

4. The missing consideration of the curvature-rate (correlation with lateral jerk) in the cost function

of the trajectory planning to prevent high curvature changes.

All the factors were known before but were approved to resolve trade-oﬀs with other performance indicators.
It becomes obvious that the sum of small weak spots can result in such a situation if the car is close to its
handling limits. However, the collected data of sensors and ego vehicle’s interactive behavior are of high
value to further improve the software as the insights serve as speciﬁc starting points for future development
steps.

5 Discussion

5.1 Evolutionary Software Stack Development

The interdisciplinary research group TUM Autonomous Motorsport started their participation in autonomous
racing events in early 2018 with a demonstration of high-speed single-vehicle behavior on the Berlin Formula-
E circuit in conjunction with Roborace. Afterward, the software stack and simulation capabilities were
extended to multi-vehicle scenarios and close-to-human lap-time performance on the same vehicle platform
in 2019. Based on these developments and achievements, the software stack displayed in this paper for
participation in the IAC competitions was created. The evolutionary development of the software stack
provided the chance to reuse modules and rethink some software components that needed to be developed
from scratch again. Furthermore, the evolutionary development provided the change to replace old software
modules with more powerful ones. For example, while in the Roborace competition, classical control ap-
proaches for path- and velocity tracking were chosen, in the IAC, the more advanced technology of Tube
MPC was used. Building upon the previous knowledge allows the comparison between methods, evaluation
of their performance, the integration of more aggressive algorithms that can handle the car at the dynamical
limits and ultimately leading to the software stack displayed in this paper.

5.2 Lessons Learned

5.2.1 Autonomous Software Design Guidelines

This software stack was designed to handle multi-vehicle racing scenarios with various opponent vehicles and
is scalable depending on the available computational resources. The primary design guidelines were: Firstly,
a modular and comprehensive software architecture that can handle racing and other autonomous driving
challenges. Secondly, early and extensive full-stack testing in simulation to determine the inﬂuence and
sensitivity of particular algorithms on the overall software level and fast iteration through a solid continuous
integration and testing framework. Thirdly, robust real-world performance via the proactive consideration
of uncertainties and failures in each algorithm. In addition to achieving those goals, we benchmarked the
proposed architecture and the developed algorithms under realistic conditions, which led to several important
insights shaping our current and future research strategy. The holistic approach to these research challenges
allowed us to generate further insights and learnings.

5.2.2 Autonomous Racing as an ODD

An important design decision for many developers is the speciﬁcation of an operational design domain (ODD).
While it allows focusing on speciﬁc aspects of the problem, this strategy often leads to a crucial pitfall: Many
algorithms are prone to complete failure if the assumptions made within the ODD are slightly violated.
Examples of this are hard constraints in motion planning or model-predictive-control algorithms. While this
does not lead to severe issues in isolated applications and benchmarks, the inherent uncertainties (either
caused by sensor input noise, inaccurate model assumptions, or numerical issues) propagating through the
software stack will almost certainly lead to frequent issues with algorithms crashing or becoming infeasible.
Therefore, it is of paramount importance to understand the behavior of the algorithms when the ODD is
violated to a certain extent and ensure that the response remains reasonable, e.g., via the introduction of
soft constraints. The violation of predeﬁned domain assumptions must also be considered during the concept
phase by choosing generic and robust algorithms. Even though a lower module performance in contrast to
more speciﬁc and overﬁtted algorithms might occur, at ﬁrst sight, the robustness pays oﬀ in the long run
when it comes to real-world applications with the mentioned uncertainties and overall software integration.
Additionally, a valid safety concept to handle module failures is essential to ensure safety on the one hand
and on the other hand to enable the integration of new features while still having a fallback option in case
of ODD violations.

5.2.3 Model Fidelity vs. Software Performance

There exists a counterintuitive relation between increasing model ﬁdelity and the increase in overall software
performance. The low complexity of the algorithms leads to a software stack that has diﬃculties adjusting
to the behavior of other vehicles on track or other deviations from the internal assumptions. There are two
ways to counteract this issue: The ﬁrst, probably the more common, is the introduction of more complex
models of reality. However, this almost certainly leads to an increase in computational costs and, therefore,
a decrease in update rate. This might lead to worse overall performance, even though the utilized model
improves accuracy as the higher latency strongly inﬂuences the opportunity to react adequately in dynamic
situations. The second strategy is to keep the complexity and related computational costs of particular models
low and optimize the overall software latency. Upgrades to more complex models are strictly prioritized by
the model’s inﬂuence on the overall software performance, i.e., bottlenecks must be identiﬁed a priori. This
strategy has proven promising during our development; however, it is much harder to measure or evaluate as
it strongly depends on the test cases and performance indicators. This ﬁnding emphasizes the importance
of overall software stack performance rather than measuring KPIs of individual algorithms. Consequently,
early integration and standardized testing are of high relevance to ensure the compatibility of new features
and to track the progress of the overall software performance.

5.2.4 Data-driven Algorithms

Data-driven algorithms are prone to a chicken-and-egg problem. Their use relies on the availability of data,
which is hard to acquire in an autonomous vehicle when the acquisition requires the desired capability to
be available. While this issue is often circumvented via human test drivers, drones, or other data collection
equipment, this will challenge especially research groups, and smaller companies as their access to realistic
data is limited. A potential way of tackling this issue is the gradual introduction of data-driven strategies
with increasing capabilities of the software stack. When the software stack initially uses classical algorithms,
the utilization of data-driven algorithms can increase and improve the software stack with increasing maturity
and data availability. For this, the design of a modular architecture is required to continuously integrate new
features but still be able to run the complete software for testing and data collecting purposes. In addition,
synthetic data generation in a versatile simulation framework of sensor and vehicle dynamics simulation is
If these techniques are used, training of deep-learning models and parameter tuning of complex
crucial.
algorithms can take place a priori to real-world operation and can continue to be conducted during the
development phase.

6 Conclusion and Future Work

This paper presented the autonomous racing software stack developed by TUM Autonomous Motorsport.
We displayed the content of the individual software modules capable of multi-vehicle racing at high speeds
and high accelerations. It was demonstrated that the software drives close to the Dallara AV-21s limit by
peaking at around 270 km h−1 and 28 m s−2. Furthermore, by developing a dedicated testing and development
pipeline, we created a robust and advantageous software that is tested in various simulations and real-world
racing competitions. The experiences and learnings during the application of this software stack at the IAC
allowed us to identify crucial further research directions to enable safe autonomy within the future:

Firstly and foremost, the transfer of algorithms and knowledge among diﬀerent domains of autonomy has
to be improved. While autonomous racing with one or two vehicles is a reasonable proving ground, we see
a strong need to increase the complexity of these challenges to align with the problems faced in urban and
highway scenarios. An essential part of this is racing more than two vehicles simultaneously to prove the
algorithms’ interaction awareness and scalability. As this strategy increases the risk of vehicle damage, we
identify a strong need for improved open and freely accessible resources for virtual development. Open-source
projects like CARLA are promising but have not been adopted on a wide scale in these large competitive
projects.

Secondly, the thorough handling of uncertainties (and their multi-modal nature) through the whole software
stack will be an essential part of increasing the safety of autonomous vehicles. While promising approaches
for independent algorithms such as object detection, prediction, and planning are available, these parts must
be combined and evaluated as a full software stack. This will be especially challenging from a computational
complexity point of view. It seems necessary that these holistic approaches employ signiﬁcant parallelization
of their workload, either via an increased number of CPU cores or the employment of GPU-based calculations.

Thirdly, the development workﬂow has to be considered as an active research direction rather than an
industrialization challenge. The safe and eﬃcient deployment of autonomous vehicles in various applications
will depend heavily on the ability of companies to iterate quickly to generate learnings on their approach while
having safety requirements complying with all guidelines and highest standards. This especially includes the
software development workﬂow, requirements speciﬁcation, testing scenario design, and holistic tracking of
algorithm performance from a virtual, single algorithm level up to the full software stack.

Lastly, it remains to keep working towards a free racing format and increase the complexity of the race
situations. The era of autonomous racing is relatively new, but we already see the beneﬁt of gaining new
insights for research and development, which are transferable to further autonomous applications. The goal

is to enable multi-vehicle races on road courses and oval tracks. The required rules should be minimized such
that they ensure the basics of safety and fairness but should support a dynamic, interactive, and free racing
style. Both the rule format and the track selection led to the development of generic and robust software
stacks highly correlated to software for autonomous driving on public roads.

Acknowledgments

We want to thank the Indy Autonomous Challenge organizers, Juncos Hollinger Racing, and all other
participating teams for the countless eﬀorts to make the Indy Autonomous Challenge and all of those
experiments with multiple full-scale autonomous racing vehicles possible. Furthermore, this project was
made possible with the generous support and contributions of the basic research funds of the Technical
University of Munich and several private donors and sponsors.

References

Andersson, J. A. E., Gillis, J., Horn, G., Rawlings, J. B., and Diehl, M. (2019). CasADi – A software
framework for nonlinear optimization and optimal control. Mathematical Programming Computation,
11(1):1–36.

Andresen, L., Brandemuehl, A., Honger, A., Kuan, B., Vodisch, N., Blum, H., Reijgwart, V., Bernreiter,
L., Schaupp, L., Chung, J. J., Burki, M., Oswald, M. R., Siegwart, R., and Gawel, A. (2020). Accu-
rate mapping and planning for autonomous racing. In 2020 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS). IEEE.

Arslan, O., Berntorp, K., and Tsiotras, P. (2017). Sampling-based algorithms for optimal motion planning
In 2017 IEEE International Conference on Robotics and Automation

using closed-loop prediction.
(ICRA). IEEE.

Balaji, B., Mallya, S., Genc, S., Gupta, S., Dirac, L., Khare, V., Roy, G., Sun, T., Tao, Y., Townsend, B.,
Calleja, E., Muralidhara, S., and Karuppasamy, D. (2020). DeepRacer: Autonomous racing platform
for experimentation with sim2real reinforcement learning. In 2020 IEEE International Conference on
Robotics and Automation (ICRA). IEEE.

Betz, J., Wischnewski, A., Heilmeier, A., Nobis, F., Hermansdorfer, L., Stahl, T., Herrmann, T., and
Lienkamp, M. (2019). A software architecture for the dynamic path planning of an autonomous racecar
In 2019 IEEE International Conference on Connected Vehicles and Expo
at the limits of handling.
(ICCVE). IEEE.

Betz, J., Wischnewski, A., Heilmeier, A., Nobis, F., Stahl, T., Hermansdorfer, L., Lohmann, B., and
Lienkamp, M. (2018). What can we learn from autonomous level-5 motorsport? In Proceedings, pages
123–146. Springer Fachmedien Wiesbaden.

Betz, J., Zheng, H., Liniger, A., Rosolia, U., Karle, P., Behl, M., Krovi, V., and Mangharam, R. (2022).

Autonomous vehicles on the edge: A survey on autonomous vehicle racing.

Braghin, F., Cheli, F., Melzi, S., and Sabbioni, E. (2008). Race driver model. Computers & Structures,

86(13-14):1503–1516.

Brunnbauer, A., Berducci, L., Brandst¨atter, A., Lechner, M., Hasani, R., Rus, D., and Grosu, R. (2021).

Model-based versus model-free deep reinforcement learning for autonomous racing cars.

Buehler, M., Iagnemma, K., and Singh, S., editors (2007). The 2005 DARPA grand challenge. Springer

Tracts in Advanced Robotics. Springer, Berlin, Germany, 2007 edition.

Buehler, M., Iagnemma, K., and Singh, S., editors (2009). The DARPA urban challenge. Springer Tracts in

Advanced Robotics. Springer, Berlin, Germany, 2010 edition.

Buyval, A., Gabdulin, A., Mustaﬁn, R., and Shimchik, I. (2017). Deriving overtaking strategy from nonlinear
In 2017 IEEE/RSJ International Conference on Intelligent

model predictive control for a race car.
Robots and Systems (IROS). IEEE.

Caporale, D., Venturini, L., Fagiolini, A., Pallottino, L., Settimi, A., Biondo, A., Amerotti, F., Massa, F.,
Caro, S. D., and Corti, A. (2018). A planning and control system for self-driving racing vehicles. In 2018
IEEE 4th International Forum on Research and Technology for Society and Industry (RTSI). IEEE.

Cho, S., Kim, J., Ikram, W., Cho, K., Jeong, Y.-S., Um, K., and Sim, S. (2014). Sloped terrain segmentation

for autonomous drive using sparse 3d point cloud. The Scientiﬁc World Journal, 2014:582753.

Christ, F., Wischnewski, A., Heilmeier, A., and Lohmann, B. (2019). Time-optimal trajectory planning for
a race car considering variable tyre-road friction coeﬃcients. Vehicle System Dynamics, 59(4):588–612.

de Bruin, T., Kober, J., Tuyls, K., and Babuska, R. (2018). Integrating state representation learning into

deep reinforcement learning. IEEE Robotics and Automation Letters, 3(3):1394–1401.

Deo, N. and Trivedi, M. M. (2018). Convolutional social pooling for vehicle trajectory prediction. IEEE Com-
puter Society Conference on Computer Vision and Pattern Recognition Workshops, 2018-June:1549–
1557.

Dhall, A., Dai, D., and Gool, L. V. (2019). Real-time 3d traﬃc cone detection for autonomous driving. In

2019 IEEE Intelligent Vehicles Symposium (IV). IEEE.

Dijkstra, E. W. (1959). A note on two problems in connexion with graphs. Numerische Mathematik, 1:269–

271.

Energy Systems Network (2021). Indy autonomous challenge powered by cisco ﬁnal competition rule set.

Feraco, S., Luciani, S., Bonﬁtto, A., Amati, N., and Tonoli, A. (2020). A local trajectory planning and
In 2020 AEIT International

control method for autonomous vehicles based on the RRT algorithm.
Conference of Electrical and Electronic Technologies for Automotive (AEIT AUTOMOTIVE). IEEE.

Fu, M., Ni, J., Li, X., and Hu, J. (2018). Path tracking for autonomous race car based on g-g diagram.

International Journal of Automotive Technology, 19(4):659–668.

Funke, J., Theodosis, P., Hindiyeh, R., Stanek, G., Kritatakirana, K., Gerdes, C., Langer, D., Hernandez,
M., Muller-Bessler, B., and Huhnke, B. (2012). Up to the limits: Autonomous audi TTS. In 2012 IEEE
Intelligent Vehicles Symposium. IEEE.

Gandhi, M. S., Vlahov, B., Gibson, J., Williams, G., and Theodorou, E. A. (2021). Robust model predictive
path integral control: Analysis and performance guarantees. IEEE Robotics and Automation Letters,
6(2):1423–1430.

Geiger, A., Lenz, P., and Urtasun, R. (2012). Are we ready for autonomous driving? the kitti vision

benchmark suite. In Conference on Computer Vision and Pattern Recognition (CVPR).

Geisslinger, M., Karle, P., Betz, J., and Lienkamp, M. (2022). Watch-and-Learn-Net: Self-supervised On-
line Learning for Probabilistic Vehicle Trajectory Prediction. 2021 IEEE International Conference on
Systems, Man, and Cybernetics (SMC), pages 869–875.

Goh, J., Goel, T., and Gerdes, J. C. (2019). Toward automated vehicle control beyond the stability limits:
Drifting along a general path. Journal of Dynamic Systems, Measurement, and Control, 142(2).

Goldfain, B., Drews, P., You, C., Barulic, M., Velev, O., Tsiotras, P., and Rehg, J. M. (2019). AutoRally:

An open platform for aggressive autonomous driving. IEEE Control Systems, 39(1):26–55.

Heilmeier, A., Wischnewski, A., Hermansdorfer, L., Betz, J., Lienkamp, M., and Lohmann, B. (2019). Mini-
mum curvature trajectory planning and control for an autonomous race car. Vehicle System Dynamics,
58(10):1497–1527.

Hellwig, M. and Beyer, H.-G. (2016). Evolution under strong noise: A self-adaptive evolution strategy can
reach the lower performance bound - the pcCMSA-ES. In Parallel Problem Solving from Nature – PPSN
XIV, pages 26–36. Springer International Publishing.

Hermansdorfer, L., Betz, J., and Lienkamp, M. (2020). Benchmarking of a software stack for autonomous
racing against a professional human race driver. In 2020 Fifteenth International Conference on Ecological
Vehicles and Renewable Energies (EVER). IEEE.

Herrmann, T., Christ, F., Betz, J., and Lienkamp, M. (2019). Energy management strategy for an au-
In 2019 IEEE Intelligent Transportation Systems

tonomous electric racecar using optimal control.
Conference (ITSC). IEEE.

Hewing, L., Liniger, A., and Zeilinger, M. N. (2018). Cautious NMPC with gaussian process dynamics for

autonomous miniature race cars. In 2018 European Control Conference (ECC). IEEE.

Hindiyeh, R. Y. and Gerdes, J. C. (2014). A controller framework for autonomous drifting: Design, stability,

and experimental validation. Journal of Dynamic Systems, Measurement, and Control, 136(5).

Indy Autonomous Challenge (2021). https://www.indyautonomouschallenge.com.

Jaritz, M., de Charette, R., Toromanoﬀ, M., Perot, E., and Nashashibi, F. (2018). End-to-end race driving
with deep reinforcement learning. In 2018 IEEE International Conference on Robotics and Automation
(ICRA). IEEE.

Jazwinski, A. H. (1970). Stochastic processes and ﬁltering theory, volume 64 of Mathematics in science and

engineering. Acad. Press, San Diego, 1 edition.

Jocher, G., Stoken, A., Ayush Chaurasia, Borovec, J., NanoCode012, TaoXie, Yonghye Kwon, Kalen Michael,
Changyu, L., Jiacong Fang, Abhiram V, Laughing, Tkianai, YxNONG, Skalski, P., Hogan, A., Jebastin
Nadar, Imyhxy, Mammana, L., AlexWang1900, Fati, C., Montes, D., Hajek, J., Diaconu, L., Minh,
M. T., , Marc, Albinxavi, , Fatih, , Oleg, and Wanghaoyang0106 (2021). ultralytics/yolov5: v6.0 -
yolov5n ’nano’ models, roboﬂow integration, tensorﬂow export, opencv dnn support.

Kabzan, J., Valls, M. I., Reijgwart, V. J. F., Hendrikx, H. F. C., Ehmke, C., Prajapat, M., B¨uhler, A.,
Gosala, N., Gupta, M., Sivanesan, R., Dhall, A., Chisari, E., Karnchanachari, N., Brits, S., Dangel,
M., Sa, I., Dub´e, R., Gawel, A., Pfeiﬀer, M., Liniger, A., Lygeros, J., and Siegwart, R. (2020). AMZ
driverless: The full autonomous racing system. Journal of Field Robotics.

Kapania, N. R. and Gerdes, J. C. (2015). Design of a feedback-feedforward steering controller for accurate
path tracking and stability at the limits of handling. Vehicle System Dynamics, 53(12):1687–1704.

Kapania, N. R., Subosits, J., and Gerdes, J. C. (2016). A sequential two-step algorithm for fast generation

of vehicle racing trajectories. Journal of Dynamic Systems, Measurement, and Control, 138(9).

Karle, P., Geisslinger, M., Betz, J., and Lienkamp, M. (2022). Scenario Understanding and Motion Prediction
for Autonomous Vehicles – Review and Comparison. Transactions on Intelligent Transportation Systems.

Kuhn, H. W. (1955). The hungarian method for the assignment problem. Naval Research Logistics Quarterly,

2(1-2):83–97.

Large, N. L., Bieder, F., and Lauer, M. (2021). Comparison of diﬀerent SLAM approaches for a driverless

race car. tm - Technisches Messen, 88(4):227–236.

Lee, K., An, G. N., Zakharov, V., and Theodorou, E. A. (2019). Perceptual attention-based predictive

control.

Leibnitz Rechenzentrum (2022). Lrz compute cloud.

Lingemann, K., N¨uchter, A., Hertzberg, J., and Surmann, H. (2005). High-speed laser localization for mobile

robots. Robotics and autonomous systems, 51(4):275–296.

Liniger, A., Domahidi, A., and Morari, M. (2014). Optimization-based autonomous racing of 1:43 scale RC

cars. Optimal Control Applications and Methods, 36(5):628–647.

Liniger, A. and Lygeros, J. (2015). A viability approach for fast recursive feasible ﬁnite horizon path
planning of autonomous RC cars. In Proceedings of the 18th International Conference on Hybrid Systems:
Computation and Control. ACM.

Liniger, A. and Lygeros, J. (2020). A noncooperative game approach to autonomous racing. IEEE Trans-

actions on Control Systems Technology, 28(3):884–897.

Liu, J. and Teytaud, O. (2019). A simple yet eﬀective resampling rule in noisy evolutionary optimization.

In 2019 IEEE Symposium Series on Computational Intelligence (SSCI). IEEE.

Maneewongvatana, S. and Mount, D. M. (1999). Analysis of approximate nearest neighbor searching with

clustered point sets. CoRR, cs.CG/9901013.

Massa, F., Bonamini, L., Settimi, A., Pallottino, L., and Caporale, D. (2020). LiDAR-based GNSS denied

localization for autonomous racing cars. Sensors, 20(14):3992.

McNaughton, M., Urmson, C., Dolan, J. M., and Lee, J. W. (2011). Motion planning for autonomous driving
with a conformal spatiotemporal lattice. Proceedings - IEEE International Conference on Robotics and
Automation, pages 4889–4895.

Messaoud, K., Deo, N., Trivedi, M. M., and Nashashibi, F. (2020). Trajectory Prediction for Autonomous

Driving based on Multi-Head Attention with Joint Agent-Map Representation.

Nekkah, S., Janus, J., Boxheimer, M., Ohnemus, L., Hirsch, S., Schmidt, B., Liu, Y., Borb´ely, D., Keck, F.,

Bachmann, K., and Bleszynski, L. (2020). The autonomous racing software stack of the kit19d.

Nobis, F., Betz, J., Hermansdorfer, L., and Lienkamp, M. (2019). Autonomous racing: A comparison of slam
algorithms for large scale outdoor environment. In Proceedings of the 2019 3rd International Conference
on Virtual and Augmented Reality Simulations. ACM.

Notomista, G., Wang, M., Schwager, M., and Egerstedt, M. (2020). Enhancing game-theoretic autonomous
In 2020 IEEE International Conference on Robotics and

car racing using control barrier functions.
Automation (ICRA). IEEE.

O'Kelly, M., Zheng, H., Jain, A., Auckley, J., Luong, K., and Mangharam, R. (2020). TUNERCAR: A
superoptimization toolchain for autonomous racing. In 2020 IEEE International Conference on Robotics
and Automation (ICRA). IEEE.

O’Kelly, M., Zheng, H., Karthik, D., and Mangharam, R. (2020). F1tenth: An open-source evaluation envi-
ronment for continuous control and reinforcement learning. In Escalante, H. J. and Hadsell, R., editors,
Proceedings of the NeurIPS 2019 Competition and Demonstration Track, volume 123 of Proceedings of
Machine Learning Research, pages 77–89. PMLR.

Pagot, E., Piccinini, M., and Biral, F. (2020). Real-time optimal control of an autonomous RC car with
minimum-time maneuvers and a novel kineto-dynamical model. In 2020 IEEE/RSJ International Con-
ference on Intelligent Robots and Systems (IROS). IEEE.

Rapin, J. and Teytaud, O. (2018). Nevergrad - a gradient-free optimization platform.

Renzler, T., Stolz, M., Schratter, M., and Watzenig, D. (2020). Increased accuracy for fast moving LiDARS:
Correction of distorted point clouds. In 2020 IEEE International Instrumentation and Measurement
Technology Conference (I2MTC). IEEE.

Rosolia, U., Carvalho, A., and Borrelli, F. (2017). Autonomous racing using learning model predictive

control. In 2017 American Control Conference (ACC). IEEE.

Rusu, R. B. and Cousins, S. (2011). 3D is here: Point Cloud Library (PCL).
Conference on Robotics and Automation (ICRA), Shanghai, China. IEEE.

In IEEE International

Sauerbeck, F., Baierlein, L., Betz, J., and Lienkamp, M. (2022). A combined lidar-camera localization for
autonomous race cars. SAE International Journal of Connected and Automated Vehicles, 5(12-05-01-
0006).

Schratter, M., Zubaca, J., Mautner-Lassnig, K., Renzler, T., Kirchengast, M., Loigge, S., Stolz, M., and
Watzenig, D. (2021). Lidar-based mapping and localization for autonomous racing. In 2021 International
Conference on Robotics and Automation (ICRA 2021) - Workshop Opportunities and Challenges With
Autonomous Racing. IEEE.

Shi, S., Wang, X., and Li, H. (2019). Pointrcnn: 3d object proposal generation and detection from point

cloud.

Sinha, A., O’Kelly, M., Zheng, H., Mangharam, R., Duchi, J., and Tedrake, R. (2020). FormulaZero:
Distributionally robust online adaptation via oﬄine population synthesis.
In III, H. D. and Singh,
A., editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of
Proceedings of Machine Learning Research, pages 8992–9004. PMLR.

Song, Y., Lin, H., Kaufmann, E., Duerr, P., and Scaramuzza, D. (2021). Autonomous overtaking in gran

turismo sport using curriculum reinforcement learning.

Srinivasan, S., Sa, I., Zyner, A., Reijgwart, V., Valls, M. I., and Siegwart, R. (2020). End-to-end velocity

estimation for autonomous racing. IEEE Robotics and Automation Letters, 5(4):6869–6875.

Stahl, T., Wischnewski, A., Betz, J., and Lienkamp, M. (2019a). Multilayer graph-based trajectory planning
for race vehicles in dynamic scenarios. In 2019 IEEE Intelligent Transportation Systems Conference
(ITSC). IEEE.

Stahl, T., Wischnewski, A., Betz, J., and Lienkamp, M. (2019b). ROS-based localization of a race vehicle

at high-speed using LIDAR. E3S Web of Conferences, 95:04002.

Stellato, B., Banjac, G., Goulart, P., Bemporad, A., and Boyd, S. (2020). OSQP: an operator splitting solver

for quadratic programs. Mathematical Programming Computation, 12(4):637–672.

Strobel, K., Zhu, S., Chang, R., and Koppula, S. (2020). Accurate, low-latency visual perception for
autonomous racing: Challenges, mechanisms, and practical solutions. In 2020 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS). IEEE.

Subosits, J. K. and Gerdes, J. C. (2019). From the racetrack to the road: Real-time trajectory replanning

for autonomous driving. IEEE Transactions on Intelligent Vehicles, 4(2):309–320.

The Autoware Foundation (2021). AutowareAuto. https://gitlab.com/autowarefoundation/autoware.

auto/AutowareAuto.

Theodosis, P. A. and Gerdes, J. C. (2012). Nonlinear optimization of a racing line for an autonomous race-
car using professional driving techniques. In Volume 1: Adaptive Control; Advanced Vehicle Propulsion
Systems; Aerospace Systems; Autonomous Systems; Battery Modeling; Biochemical Systems; Control
Over Networks; Control Systems Design; Cooperative and Decentralized Control; Dynamic System Mod-
eling; Dynamical Modeling and Diagnostics in Biomedical Systems; Dynamics and Control in Medicine
and Biology; Estimation and Fault Detection; Estimation and Fault Detection for Vehicle Applications;
Fluid Power Systems; Human Assistive Systems and Wearable Robots; Human-in-the-Loop Systems;
Intelligent Transportation Systems; Learning Control. ASME.

Tian, H., Ni, J., and Hu, J. (2018). Autonomous driving system design for formula student driverless racecar.

In 2018 IEEE Intelligent Vehicles Symposium (IV). IEEE.

T¨or¨ok, F., Karle, P., and Geisslinger, M. (2022). Structured Deep Neural Motion Prediction of Opposing

Vehicles for Autonomous Racing.

Verschueren, R., Zanon, M., Quirynen, R., and Diehl, M. (2016). Time-optimal race car driving using an
online exact hessian based nonlinear MPC algorithm. In 2016 European Control Conference (ECC).
IEEE.

W¨achter, A. and Biegler, L. (2006). On the implementation of an interior-point ﬁlter line-search algorithm

for large-scale nonlinear programming. Mathematical Programming, 106(1):25–57.

Wang, M., Wang, Z., Talbot, J., Gerdes, J. C., and Schwager, M. (2021). Game-theoretic planning for
self-driving cars in multivehicle competitive scenarios. IEEE Transactions on Robotics, pages 1–13.

Wang, Z., Wu, Y., and Niu, Q. (2020). Multi-sensor fusion in automated driving: A survey. IEEE Access,

8:2847–2868.

Weiss, T. and Behl, M. (2020). DeepRacing: A framework for autonomous racing. In 2020 Design, Automa-

tion & Test in Europe Conference & Exhibition (DATE). IEEE.

Werling, M., Kammel, S., Ziegler, J., and Gr¨oll, L. (2012). Optimal trajectories for time-critical street
scenarios using discretized terminal manifolds. International Journal of Robotics Research, 31(3):346–
359.

Wischnewski, A., Betz, J., and Lohmann, B. (2019a). A model-free algorithm to safely approach the handling
limit of an autonomous racecar. In 2019 IEEE International Conference on Connected Vehicles and
Expo (ICCVE). IEEE.

Wischnewski, A., Euler, M., G¨um¨us, S., and Lohmann, B. (2021). Tube model predictive control for an

autonomous race car. Vehicle System Dynamics, pages 1–23.

Wischnewski, A., Geisslinger, M., Betz, J., Betz, T., Fent, F., Heilmeier, A., Hermansdorfer, L., Herrmann,
T., Huch, S., Karle, P., Nobis, F., ¨Ogretmen, L., Rowold, M., Sauerbeck, F., Stahl, T., Trauth, R.,
Lienkamp, M., and Lohmann, B. (2022). Indy Autonomous Challenge - Autonomous Race Cars at the
Handling Limits. pages 1–16.

Wischnewski, A., Stahl, T., Betz, J., and Lohmann, B. (2019b). Vehicle dynamics state estimation and

localization for high performance race cars. IFAC-PapersOnLine, 52(8):154–161.

Zeillinger, M., Hauk, R., Bader, M., and Hofmann, A. (2017). Design of an autonomous race car for the

formula student driverless (fsd).

Zubaca, J., Stolz, M., and Watzenig, D. (2020). Extended h

for advanced ego-vehicle motion estimation.
Symposium (CAVS). IEEE.

ﬁlter adaptation based on innovation sequence
In 2020 IEEE 3rd Connected and Automated Vehicles

∞

