2
2
0
2

y
a
M
6

]

V
C
.
s
c
[

1
v
5
9
2
4
0
.
5
0
2
2
:
v
i
X
r
a

A modular software framework for the
design and implementation of
ptychography algorithms

Francesco Guzzi1, 2, George Kourousias1, Fulvio Bill `e1, Roberto
Pugliese1, Alessandra Gianoncelli1, and Sergio Carrato2

1Elettra Sincrotrone Trieste, Basovizza, Italy
2University of Trieste, Trieste, Italy

Corresponding author:
Francesco Guzzi1,2

Email address: francesco.guzzi@elettra.eu

ABSTRACT

Computational methods are driving high impact microscopy techniques such as ptychography. However,
the design and implementation of new algorithms is often a laborious process, as many parts of the
code are written in close-to-the-hardware programming constructs to speed up the reconstruction. In this
paper, we present SciComPty, a new ptychography software framework aiming at simulating ptychography
datasets and testing state-of-the-art and new reconstruction algorithms. Despite its simplicity, the software
leverages GPU accelerated processing through the PyTorch CUDA interface. This is essential to design
new methods that can readily be employed. As an example, we present an improved position reﬁnement
method based on Adam and a new version of the rPIE algorithm, adapted for partial coherence setups.
Results are shown on both synthetic and real datasets. The software is released as open-source.

INTRODUCTION

Today, modern microscopy fully relies on cutting edge computing. The contemporary presence of a large
Field Of View (FOV), high resolution and quantitative phase information is the distinctive characteristic
of the ptychography diffraction imaging technique (Rodenburg and Faulkner, 2004; Pfeiffer, 2018).
This phase retrieval scheme is commonly solved through a computationally intensive procedure - a
reconstruction - which requires algorithms written in a low-level language or following complex HPC
paradigms. Writing such programs is typically done by an expert software engineer, and this step may
discourage the prototyping or the study of new methods. Ptychography algorithms are complex not only
in their implementation, but also per se: simple computational systems suffers from setup inconsistencies,
which usually takes the form of bad parameter modelling of positions (Zhang et al., 2013), distances
(Guzzi et al., 2021b), illumination conditions (Thibault and Menzel, 2013), just to enumerate a few. Such
problems produce very noticeable artefacts. To improve the quality of the reconstructions, parameter
tweaking becomes essential (Reinhardt and Schroer, 2018), especially for common setups; powerful
but even more advanced and complex algorithms (Enders and Thibault, 2016; Mandula et al., 2016;
Marchesini et al., 2016a) are thus employed.

State of the art
Iterative algorithms such as ePIE (Maiden and Rodenburg, 2009) or DM (Thibault et al., 2008) are
typically employed for the reconstructions. Recently, the rPIE algorithm (Maiden et al., 2017) has been
proposed and studied: while being reasonably simple, it provides a fast convergence to a good object
estimate (Maiden et al., 2017). Compared to ePIE, we noticed that the rPIE algorithm, at least in our
implementation, also provides a large computational FOV, which is comparable to the one seen in more
advanced, but also computational eager, optimisation algorithms (Guizar-Sicairos and Fienup, 2008;
Thibault and Guizar-Sicairos, 2012; Guzzi et al., 2021b). Indeed, these latter methods are used to reﬁne a
previous reconstruction, as they are more prone to stagnation (Thibault and Guizar-Sicairos, 2012). Being

 
 
 
 
 
 
new, the rPIE algorithm is currently lacking of: i) a public implementation; ii) a model decomposition
approach; iii) a tested position reﬁnement routine. As a whole, a recipe is missing for this kind of
algorithm.

Proposed framework - SciComPty
In this paper we describe how these three elements can be combined within the SciComPty GPU
framework, a new software released as open-source (Guzzi et al., 2021a), entirely written in the PyTorch
(Paszke et al., 2019) Python dialect. Our reconstruction recipe is tested against other solutions and then
the results are reported. We designed a fast position reﬁnement technique exploiting Adam (Kingma
and Ba, 2015) as a feedback controller. To do so, a fast subpixel registration algorithm (Guizar-Sicairos
et al., 2008) has also been implemented via a PyTorch GPU code. This latter element has many uses, for
example in CT alignment (Guzzi et al., 2021c), or super-resolution imaging (Guarnieri et al., 2021; Guzzi
et al., 2018).The details are described in the ”method section”. The software and algorithms capabilities
are illustrated (”Results section”) with reconstructions from simulated and real soft-X-ray data acquired
at TwinMic (Elettra) (Gianoncelli et al., 2016, 2021). Within the ”Discussion section”, we will elaborate
more on the features of the reconstructed images. The datasets and the code can be accessed at (Guzzi
et al., 2021a; Kourousias et al., 2022).

Background
Ptychography aims at recovering the 2D specimen transmission function O(x, y) ∈ C starting solely from
a set of diffraction patterns (Williams et al., 2006; Pfeiffer, 2018). In a transmission setup (Fig. 1), a
coherent and monochromatic waveﬁeld P(x, y) ∈ C is shined onto the specimen (z = zO), placed between
the source and the detector (z = zd). In the thin sample approximation (Paganin, 2006), the exit-wave
ψexw(x, y) transmitted by the object becomes:

ψexw(x, y) = ψ(x, y, zo) = P(x, y) · |O(x, y)| · e j·φO(x,y)

(1)

Figure 1. Panel (a): P(x, y) is shined onto an object O(x, y), producing ψexw(x, y). At the detector we
observe |ψd(x, y)|2. Panel (b): ptychography uses overlapped illumination (e.g. 4x oversampling) to solve
the phasing. The model in Eq. 1 is repeated for each illuminated region.

During the path from the sample to the detector, free-space propagation occurs (Paganin, 2006), modelled
by the Dz operator (Schmidt, 2010):

ψd(x, y) = ψ(x, y, zd) = Dzd −zo{ψexw(x, y)} = Dzd −zo{P(x, y, zo) · O(x, y)}

(2)

Finally, a 2D photon detector is used to reveal the intensity (magnitude squared) of the incident radiation,
producing a real, discrete, and quantised image I(x, y), which is the diffraction pattern.

I(x, y) = ψd(x, y) · ψ ∗

d (x, y)

(3)

Ptychography employs translation diversity to over-condition the problem; a large illumination (probe)
is indeed scanned across the sample, by imposing a large overlap on each illuminated region (Fig. 1,

2/12

panel b); as a result, the object is highly oversampled. A ptychography dataset (real or simulated) is
thus composed of multiple diffraction patterns, paired with their corresponding translation coordinates.
Geometry and illumination metadata complete the description of a particular instance of the computational
forward model.
During the reconstruction process, the model described by Eq. 3 must be inverted to gather back the object
transmission function O(x, y). Since this inversion cannot, in general, be done analytically, an iterative
procedure is employed. Modern versions of the ptychography reconstruction algorithms (Thibault et al.,
2008; Maiden and Rodenburg, 2009) automatically perform the factorisation of the P(x, y) and O(x, y)
functions. In a typical imaging-oriented ptychography experiment like ours, the recovery of P(x, y) is just
a by-product, though mandatory for the O-P factorisation.

METHODS

Virtual experiment
Reconstructions apart, SciComPty offers a simple method to perform virtual experiments. To simulate a
ptychography dataset, one can implement the general transmission model of Eq. 3, and assign particular
values to its setup parameters. In the case of a far-ﬁeld setup (Schmidt, 2010), by ﬁxing the detector
pixel size δD, the corresponding pixel size at the sample plane δs can be readily calculated (Eq. 1 in
the supplementary material). The recurring parameters in both simulations and reconstructions are W
(detector size in pixels), Sd (detector lateral dimension) and zdo (sample-detector distance). In a simulation,
δs normally deﬁnes the basis for the scanning movements, that in the simplest case follows a grid pattern.
Random jitter is added to the (x, y) coordinates, to prevent the raster scanning pathology (Thibault et al.,
2008; Dierolf et al., 2010; Edo et al., 2013). The overlap factor is deﬁned instead by the maximum step
movement. The object function O(x, y) and the illumination function P(x, y) are assembled in magnitude
and phase providing two images each. Deﬁning such virtual experiment parameters follows what is
actually done during a real experiment (see Listing 1 in the Simulation section of supplementary material).

M-rPIE algorithm
In order to describe partial coherece beams (Chen et al., 2012) the waveﬁeld is decomposed into a set of
mutually incoherent probe modes (Thibault and Menzel, 2013; Odstrcil et al., 2016; Li et al., 2016). For
each sample position (x j, y j), the jth diffraction pattern I j(x, y) can be modeled by:

I j(x, y) =

M
∑
p=1

|Dz{Pp(x, y) · O(x, y, x j, y j)}|2 =

M
∑
p=1

|Dz{Pp(x, y) · o j(x, y)|2

(4)

where Pp with p ∈ {1, ..., M} is a particular probe mode; ooo jjj = o j(x, y) = O(x, y, x j, y j) is the cropped
region of the object, corresponding to the jth illuminated area in the scan sequence. To reconstruct an
object with the model in Eq. 4, we solve for O(x, y) and a set of M mutually incoherent probe functions
PPPppp = Pp(x, y). A public implementation of rPIE is currently missing and its multiprobe variant has not
been reported yet. We implemented it in SciComPty, calling it M-rPIE. The procedure to design the
method follows what has been done for one of the multimode-ePIE (M-ePIE) versions (Thibault and
Menzel, 2013), producing the following new update steps (2D arrays depending on x, y are in bold):

PPP(cid:48)(cid:48)(cid:48)

ppp = PPPppp + αP

(ψψψ (cid:48)(cid:48)(cid:48)
β (cid:12)

(cid:12)ooo jjj

− PPPppp · ooo jjj) · ooo∗
exwp, j
jjj
2 ;
(cid:12)
max + (1 − β ) (cid:12)
(cid:12)
2
(cid:12)ooo jjj
(cid:12)
(cid:12)

ooo(cid:48)(cid:48)(cid:48)

jjj = ooo jjj + αO

p=1(ψψψ (cid:48)(cid:48)(cid:48)

∑M
exwp, j
p=1 |PPPppp|2)max + (1 − γ) ∑M

− PPPppp · ooo jjj) · PPP∗
ppp
p=1 |PPPppp|2

γ(∑M

(5)

(6)

As usual, ooo(cid:48)(cid:48)(cid:48)
object box and the current probe, while:

j(x, y) and PPP(cid:48)(cid:48)(cid:48)

ppp = P(cid:48)

jjj = o(cid:48)

p(x, y) represent the updated quantities respectively for the current

ψψψ (cid:48)(cid:48)(cid:48)

exwp, j

= D−z{(cid:112)III jjj

(cid:113)

ψψψ exwp, j
(cid:12)
∑N
(cid:12)ψψψ ppp

n=1

(cid:12)
2
(cid:12)

}

(7)

3/12

is the magnitude-corrected scattering wave produced by the pth illumination mode; αp and αo represent
the update rates of the probe and object estimates and are typically set to [0.5, 1]. The role of each
denominator is to weight the update where the exit wave is not bright (Rodenburg and Faulkner, 2004;
Maiden et al., 2017), reducing thus the noise ampliﬁcation. β and γ are regularisation parameters: when
set to 1, M-rPIE simpliﬁes to M-ePIE (Thibault and Menzel, 2013; Maiden et al., 2017). The net effect of
the modiﬁcations, weighted by β and γ, is to slow down the update, by introducing a loss cost given by
o j(x, y) and Pp(x, y). Increasing the number of modes increases the iteration time by the same factor: that
is why it is extremely important the fact that SciComPty is actually working on GPUs.

Adam-based position reﬁnement
As the resolution increases, the effects of backlash and limited mechanical precision become more and
more noticeable. The positions vector is indeed populated by the open-loop commands given to the
stage. A correction method must then be introduced a posteriori, increasing the reconstruction time. In
(Guizar-Sicairos and Fienup, 2008; Guzzi et al., 2021b) positions are corrected through an optimisation
method, within the gradient-based reconstruction; in (Mandula et al., 2016), instead, the authors propose
to use a gradient-less method based on (Powell, 1964) to guide the position reﬁnement procedure.
In this work, we consider a fast and reliable way to correct translations. Similarly to (Zhang et al., 2013;
Tripathi et al., 2014; Loetgering et al., 2015; Dwivedi et al., 2018), it employs a 2D cross correlation
signal, calculated at some points in the reconstruction chain. The same principle is used also for CT
alignment in (G¨ursoy et al., 2017; Guzzi et al., 2021c), as the synthesised projection o j(x, y) are inevitably
centred; when confronted with reﬁned estimates (o(cid:48)
j(x, y), XCORRA), or measured data (I(x, y), XCORRB),
geometrical shifts can then be measured. Figure 2 shows how such position reﬁnement scheme can be
introduced in the canvas of a PIE reconstruction algorithm: 2D weighted phase correlation (Guizar-
Sicairos et al., 2008) here is used to determine the shift between two different estimates ooo jjj and ooo(cid:48)(cid:48)(cid:48)
jjj (switch
in position XCORRA in Fig. 2, more details later) belonging to the same crop-box (x j, y j).

Figure 2. Position reﬁnement routine integrated into a PIE algorithm; the position error signal (argmax
of 2D cross-correlation) can be calculated meaningfully in two points, XCORRA or XCORRB (purple
boxes). The estimated positions (x, j) are then updated to (x j, y j)(cid:48) iteration by iteration.

In this class of position reﬁnement methods, the error signal (the 2D argmax of the 2D cross-correlation)
is extremely small and provides a correction factor that is cumulated at each iteration. A gain factor η j
is indeed used to provide a correction. Here we propose to use a spatially variant and adaptive gain
factor, that can change iteration after iteration and is probes-dependent. Our subpixel shift detection is
based on the work (Guizar-Sicairos et al., 2008) and its implementation in SciPy (Jones et al., 01 ). We
adapted the same algorithm in PyTorch, allowing for fast GPU computation and avoiding costly move
operation between the two memory systems, as the core of the reconstruction (M-rPIE) is already working

4/12

on the GPU. To speed up the procedure for subpixel scales, the matrix multiplication version of the 2D
DFT is employed. An upsampled version of the cross-correlation can then be computed within just a
neighbourhood of the coarse peak estimate, without the need for zero-padding. Each probe position is
updated at each iteration by the following expression:

x(cid:48)
j = x j + ηx, j · argmax

x

{XCORRi∈[A,B]},

y(cid:48)
j = y j + ηy, j · argmax

{XCORRi∈[A,B]},

y

(8)

(9)

where ηx, j and ηy, j are the gain factors (>> 1). The variable gain is calculated by using the Adam
optimization algorithm (Kingma and Ba, 2015): Adam is an extension to stochastic gradient descent, and
is nowadays widely used in deep learning (Zhang, 2018). While in Stochastic Gradient Descent (SGD)
the same learning rate is kept constant for all the variables, Adam provides a per-parameter factor that is
separately adapted as learning unfolds. This is achieved by considering the evolution of each parameter. In
our method, the argmax of the 2D cross-correlation takes the place of the gradient in the Adam algorithm,
because its value will maximise the position error gradient. The resulting algorithm is then reported in
Alg. 1:

Data: The cropped object oj and its reﬁned estimate o(cid:48)
j
Result: Gain parameters ηx, j and ηy, j for the jth crop-box (the jth position vector (x, y) j)
Initialization as in Alg. 1 of (Kingma and Ba, 2015);
while reconstruction iteration > 0 do

t = t+1;
gt = argmax{XCORRi∈[A,B]} ;
proceed as from row 3 of Alg. 1 of (Kingma and Ba, 2015);
[...]

end

Algorithm 1: The modiﬁed Adam algorithm uses the argmax of the 2D phase correlation as the
gradient of the error, then the exponentially damped moving averages are updated as in (Kingma and
Ba, 2015).

RESULTS

Experiments on simulated and real data were performed. We compared the proposed reconstruction
recipe in SciComPty with other state of the art algorithms, also implemented in the advanced PyNx
software (Mandula et al., 2016; Favre-Nicolin et al., 2020). Simulated data experiments are reported
in the supplementary material and conﬁrm that XCORRA (see Fig. 2) is the best point to estimate the
position error. From those results we deﬁned our strategy for the analysis of real datasets.

Synchrotron soft-X-ray experiments
Real data have been acquired at the TwinMic beamline of the Elettra Synchrotron facility. We used a
1020 eV (Fig. 3 and S1 in supplementary material) and 1495 eV (Fig. 4) soft-X-ray beam obtained from a
secondary source of 15 µm. The zone plate has a diameter of 600 µm with a smallest ring width of 50 nm.
At those energies the focus length is respectively of 36 and 24 mm. The sample was placed at 370µm
from the virtual point source, providing a probe size of roughly 9 µm. The sample-detector distance is set
at roughly 75 cm. The Princeton camera is based on a peltier-cooled CCD sensor with a resolution of
1300x1340 pixels, with a pixel size of 20 µm.
Figure 3 shows a series of phase reconstructions of a group of chemically ﬁxed Mesenchymal-Epithelial
Transition (MET) cells, grown in silicon nitride windows and exposed to asbestos ﬁbres (Cammisuli et al.,
2018). The reconstruction in panel (a) has been produced by the DM algorithm, while the one in panel (b)
is the output of the ML algorithm (Thibault and Guizar-Sicairos, 2012). In both, the position reﬁnement
method (Mandula et al., 2016) is enabled. In the same conﬁguration, similar results can be obtained by
the AP method (Marchesini et al., 2016b), that can be seen as a parallelised version of the ePIE algorithm,
implemented in PyNx. The reconstruction programs for these images are listed in the supplementary
material. Even if stunning, images in panel (a) and (b) appear blurry and full of artefacts. As expected,
the ML algorithm provides a better reconstruction than DM; a larger FOV can also be observed. In both,

5/12

Figure 3. Reconstruction of a MET cells sample. Panel (a) and (b) show respectively the output of DM
and ML, paired with the position correction algorithm Mandula et al. (2016). Panel (c) and (d) show the
reconstruction with the proposed recipe, using M-ePIE (c) and M-rPIE (d). The insets show how the latter
gives fewer ringing artefacts.

6/12

AP was essential to create a meaningful P(x, y), that allowed the object to appear as ”reconstructed”. At
the end of these reconstructions, it was also required to remove a phase modulation; many details about
this post-processing can be found in the supplementary material.
Conversely, panel (c) and (d) show the reconstructions obtained with SciComPty, for the same set of
parameters and pre-processed data; in both the two cases, the proposed Adam-based position reﬁnement
method is used. Even the simple M-ePIE (panel b) is able to provide a high quality reconstruction, if
paired with the proposed position reﬁnement method. Reconstruction quality can be even increased if the
proposed M-rPIE method is engaged (panel d): the proposed recipe allows to resolve a large FOV, that
becomes not only comparable to the one in panel (b), but in some cases (e.g. in the top left corner) is even
larger: the bottom left ﬁbre can be now observed in its entire length, as well as other cell organelles. No
post-processing is required at the end of these reconstructions. The reconstruction for a different region of
the MET sample can be found in Figure S1 of the supplementary material.

Figure 4. Reconstruction of a siemens star (magnitude) with different position reﬁnement methods; (a):
(Zhang et al., 2013); (b): (Mandula et al., 2016); (c) no correction at all; (d): proposed method.

7/12

Figure 4 shows the effects of different position correction methods applied on another real dataset,
acquired at 1495 eV. Diffraction patterns are acquired following a regular raster grid. Panel (a) shows the
reconstruction with the position reﬁnement algorithm in (Zhang et al., 2013); in panel (b) the algorithm in
(Mandula et al., 2016) is applied; panel (c) is the reconstruction output with no position correction applied
at all, while in panel (d) the proposed Adam-based position correction is applied. As can be seen, even if
with simple features, this dataset is quite challenging to correct. While in (a) a form of correction can be
seen, the reconstruction in panel (b) is even worse than the one with no correction at all (panel c). The
proposed method (d) estimates the best correction, while being fast. Note that in panel (d) the raster grid
pathology is quite absent (actual positions are not regularly spaced).
A large FOV is the most visible feature in any reconstruction employing M-rPIE (Fig. 3, Fig. 5 and Fig.
S4). To better analyse this effect, and to disentangle it from the position correction, a sparser dataset
has been synthesised from the one of Fig. 4, producing Fig. 5: panel (a) and (d) are respectively the
reconstructions with M-ePIE with the full and a sparse dataset (half of the probes); the canvas map
(Kourousias et al., 2016) in panel (c) and (f) shows the two different densities. Panel (b) and (e) show
instead the reconstruction with the M-rPIE algorithm: for the same amount of sparsity, the reconstruction
is way more resolved in panel (e) than in panel (d).

Figure 5. Reconstruction (phase), obtained using the full dataset (a,b) or a synthetic sparser version
(d,e). M-ePIE is used in (a,d), M-rPIE in (b,e). Panel (c) and (f) show the canvas map for each dataset.
The white bar represents 10 µm.

Implementation details
SciComPty software framework leverage GPU-based computing for the entire process. The test con-
ﬁguration is reported in the supplementary material. The performance gain obtained by carrying the
reconstruction algorithm from the CPU to the GPU is about 10x (0.1 s vs 1.3 s). The reason for such
a large gain is the high number of GPU cores which allow to parallelize array calculations. With no
position correction, the performance in terms of speed are comparable to other CUDA based solvers
implemented in PyNx, which is currently the fastest alternative. Regarding the position correction, at the
best of our knowledge, no implementation of (Guizar-Sicairos et al., 2008) is readily available for GPU
computing; consequently, we implemented it in PyTorch GPU. Having part of the algorithm on the GPU

8/12

(reconstruction) and part on the CPU (registration) would have been detrimental, due to the overhead
given by the data transfer. It is indeed extremely important that all the required arrays reside in the same
domain, minimising copy operations. Figure 6 shows the computation time measured for the registration
algorithm implemented on the two devices: the performance gain is of about an order of magnitude. The
acceleration is signiﬁcant, as during the reconstruction the same operation has to be performed for any
position in the dataset.

Figure 6. Benchmark for the position reﬁnement procedure implemented on CPU (Jones et al., 01 ) or
on GPU (proposed method). The performance gain in terms of speed is about 10x.

DISCUSSION

A larger FOV is the most noticeable effect in the reconstructions obtained with M-rPIE (see Fig. 3d
and Fig. S4). A well-designed regularisation is considered to be the main candidate for a successful
phase-retrieval, that is shown to work better for under-sampled areas (Fig. 5). This effects automatically
translates in a better reconstruction in the case of sparser scanning, as the higher resolving power can
effectively cope with the missing information between different subsequent measures. Sparse scanning
means reduced acquisition and reconstruction times, as well as lower radiation dose, and that is why the
implementation of the rPIE algorithm in both its single and multi-probe versions is essential for a modern
beamline. The fact that these algorithms are implemented on GPU, in a simple way and using open-source
tools, effectively allows to use these algorithms.
The positioning error induced naturally by the sample stage mitigates the raster grid pathology (see Fig.
4), as the actual movements performed by the motors differs from the position commands sent by the
control software. Indeed, as backlash, irregular friction and limited mechanical precision introduce a
small irregular jitter, it is not required to add it during a scan. Raster grid artefacts, howewer, are not an
effect due to position error; the pathology exists and is a consequence of sampling, as they appears also for
perfectly ideal simulations with regular grids (see supplementary material). A position reﬁnement method
applied a posteriori may greatly reduce the artefact, if the actual positions are not regular. That is why a
fast implementation of a position reﬁnement algorithm (as deployed by this work) is essential. The Powell
method in (Mandula et al., 2016) tends to fail, as the loss function may be incorrectly estimated by the
optimiser. Two are the supposed main characteristics which describe the performances of the Adam-based
method: i) being based on the evolution of the error through many iterations, the gain estimation is more
robust than a simple look-back at the previous iteration; ii) different regions of the sample may require
different gains, that have to be adjusted separately.
In CT alignment, the position error estimation is carried out at position XCORRB (see Fig. 2). In
supplementary material we brieﬂy analysed the dynamics of this kind of error signal, concluding that this
conﬁguration performs poorly in a ptychograpy environment, compared to the proposed XCORRA: the
use of complex quantities provides a more robust estimate than its real-only counterpart; in addiction,
images at the object plane tend to be way more intercorrelated than the one at the detector plane, reducing
the noise in the cross-correlation.

9/12

CONCLUSION

In this paper, we presented solutions for three major ﬂaws in ptychography: complex software architec-
tures, partial coherence and position errors. By combining together the proposed solutions, we provide
a recipe that is giving good results in many ptychography experiments performed at synchrotron and
FEL laboratories (Elettra Sincrotrone Trieste). The development of a multi-mode variant for rPIE is
essential to reduce the overlap condition, allowing for sparser measurements and thus providing shorter
acquisition and reconstruction time. This is critical for dynamics experiments (e.g. with many energies
and pump-probe delays). Reducing the lag between measurements and reconstruction is a critical research
path, which has a signiﬁcant impact on all the ﬁelds that use this kind of microscopy. We designed
these solutions by employing our new GPU-accelerated ptychography software framework, SciComPty,
which can be used to easily study and develop both state-of-the-art and new reconstruction algorithms.
Throughout the text, we presented several reconstruction examples from real and synthetic datasets,
comparing them to other state-of-the art solutions. The position reﬁnement procedure relies on a fast
subpixel registration algorithm that also runs on GPU. The entire software is provided to the research
community as open source and can be downloaded from (Kourousias et al., 2022; Guzzi et al., 2021a).

ACKNOWLEDGEMENTS

We are grateful to Roberto Borghes for his fundamental work on the TwinMic microscope control system
and to Iztok Gregori for his work on the HPC solution.

AUTHOR CONTRIBUTIONS STATEMENT

GK, FB, RP, AG, SC started the project, GK, AG, FG, SC, FB conceived the experiments, FG, GK, SC,
FB designed the method, AG, GK supervised the experiments. All authors participated in the experiments
and contributed to the manuscript.

ADDITIONAL INFORMATION

The authors declare no conﬂict of interest.

REFERENCES

Cammisuli, F., Giordani, S., Gianoncelli, A., Rizzardi, C., Radillo, L., et al. (2018). Iron-related toxicity
of single-walled carbon nanotubes and crocidolite ﬁbres in human mesothelial cells investigated by
synchrotron xrf microscopy. Scientiﬁc Reports, 8(1):706.

Chen, B., Abbey, B., Dilanian, R., Balaur, E., van Riessen, G., et al. (2012). Diffraction imaging: The

limits of partial coherence. Phys. Rev. B, 86:235401.

Dierolf, M., Thibault, P., Menzel, A., Kewish, C. M., Jeﬁmovs, K., et al. (2010). Ptychographic coherent

diffractive imaging of weakly scattering specimens. New Journal of Physics, 12(3):035017.

Dwivedi, P., Konijnenberg, A., Pereira, S., and Urbach, H. (2018). Lateral position correction in

ptychography using the gradient of intensity patterns. Ultramicroscopy, 192:29–36.

Edo, T. B., Batey, D. J., Maiden, A. M., Rau, C., Wagner, U., et al. (2013). Sampling in x-ray ptychography.

Phys. Rev. A, 87:053850.

Enders, B. and Thibault, P. (2016). A computational framework for ptychographic reconstruc-
tions. Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences,
472(2196):20160640.

Favre-Nicolin, V., Girard, G., Leake, S., Carnis, J., Chushkin, Y., Kieffer, J., Paleo, P., and Richard, M.-I.
(2020). PyNX: high-performance computing toolkit for coherent X-ray imaging based on operators.
Journal of Applied Crystallography, 53(5):1404–1413.

Gianoncelli, A., Bonanni, V., Gariani, G., Guzzi, F., Pascolo, L., et al. (2021). Soft x-ray microscopy

techniques for medical and biological imaging at twinmic–elettra. Applied Sciences, 11(16).

Gianoncelli, A., Kourousias, G., Merolle, L., Altissimo, M., and Bianco, A. (2016). Current status of the
twinmic beamline at elettra: a soft x-ray transmission and emission microscopy station. Journal of
Synchrotron Radiation, 23(6):1526–1537.

10/12

Guarnieri, G., Fontani, M., Guzzi, F., Carrato, S., and Jerian, M. (2021). Perspective registration and
multi-frame super-resolution of license plates in surveillance videos. Forensic Science International:
Digital Investigation, 36:301087.

Guizar-Sicairos, M. and Fienup, J. R. (2008). Phase retrieval with transverse translation diversity: a

nonlinear optimization approach. Opt. Express, 16(10):7264–7278.

Guizar-Sicairos, M., Thurman, S. T., and Fienup, J. R. (2008). Efﬁcient subpixel image registration

algorithms. Opt. Lett., 33(2):156–158.

G¨ursoy, D., Hong, Y. P., He, K., Hujsak, K., Yoo, S., et al. (2017). Rapid alignment of nanotomography

data using joint iterative reconstruction and reprojection. Scientiﬁc Reports, 7(1):11818.

Guzzi, F., Kourousias, G., Bill`e, F., Pugliese, R., and Gianoncelli, A.

(2021a). Mate-
rial concerning a manuscript about two algorithms implemented in the scicompty framework.
https://doi.org/10.5281/zenodo.6524326. [Online; accessed 15-February-2021].

Guzzi, F., Kourousias, G., Bill`e, F., Pugliese, R., Reis, C., et al. (2018). Reﬁning scan positions in
ptychography through error minimisation and potential application of machine learning. Journal of
Instrumentation, 13(06):C06002–C06002.

Guzzi, F., Kourousias, G., Gianoncelli, A., Bill`e, F., and Carrato, S. (2021b). A parameter reﬁnement

method for ptychography based on deep learning concepts. Condensed Matter, 6(4).

Guzzi, F., Kourousias, G., Gianoncelli, A., Pascolo, L., Sorrentino, A., et al. (2021c). Improving a rapid

alignment method of tomography projections by a parallel approach. Applied Sciences, 11(16).
Jones, E., Oliphant, T., Peterson, P., et al. (2001–). SciPy: Open source scientiﬁc tools for Python.
Kingma, D. P. and Ba, J. (2015). Adam: A method for stochastic optimization. In Bengio, Y. and LeCun,
Y., editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA,
USA, May 7-9, 2015, Conference Track Proceedings.

Kourousias, G., Bozzini, B., Gianoncelli, A., Jones, M. W., Junker, M., et al. (2016). Shedding light on
electrodeposition dynamics tracked in situ via soft x-ray coherent diffraction imaging. Nano Research,
9(7):2046–2056.

Kourousias, G., Guzzi, F., Bill`e, F., Pugliese, R., and Gianoncelli, A. (2022).

Datasets.

http://dx.doi.org/10.34965/i10053. [Online; accessed 29-April-2022].

Li, P., Edo, T., Batey, D., Rodenburg, J., and Maiden, A. (2016). Breaking ambiguities in mixed state

ptychography. Opt. Express, 24(8):9038–9052.

Loetgering, L., Hammoud, R., Juschkin, L., and Wilhein, T. (2015). A phase retrieval algorithm based on

three-dimensionally translated diffraction patterns. EPL (Europhysics Letters), 111(6):64002.

Maiden, A., Johnson, D., and Li, P. (2017). Further improvements to the ptychographical iterative engine.

Optica, 4(7):736–745.

Maiden, A. M. and Rodenburg, J. M. (2009). An improved ptychographical phase retrieval algorithm for

diffractive imaging. Ultramicroscopy, 109(10):1256–1262.

Mandula, O., Elzo Aizarna, M., Eymery, J., Burghammer, M., and Favre-Nicolin, V. (2016). PyNX.Ptycho:
a computing library for X-ray coherent diffraction imaging of nanostructures. Journal of Applied
Crystallography, 49(5):1842–1848.

Marchesini, S., Krishnan, H., Daurer, B. J., Shapiro, D. A., Perciano, T., et al. (2016a). SHARP: a
distributed GPU-based ptychographic solver. Journal of Applied Crystallography, 49(4):1245–1252.
Marchesini, S., Tu, Y.-C., and Wu, H.-T. (2016b). Alternating projection, ptychographic imaging and

phase synchronization. Applied and Computational Harmonic Analysis, 41(3):815–851.

Odstrcil, M., Baksh, P., Boden, S. A., Card, R., Chad, J. E., et al. (2016). Ptychographic coherent

diffractive imaging with orthogonal probe relaxation. Opt. Express, 24(8):8360–8369.

Paganin, D. (2006). Coherent X-ray Optics. Oxford University Press, Oxford.
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., et al. (2019). Pytorch: An imperative style,
high-performance deep learning library. In Wallach, H. M., Larochelle, H., Beygelzimer, A., d’Alch´e-
Buc, F., Fox, E. B., and Garnett, R., editors, Advances in Neural Information Processing Systems 32:
NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 8024–8035.

Pfeiffer, F. (2018). X-ray ptychography. Nature Photonics, 12(1):9–17.
Powell, M. J. D. (1964). An efﬁcient method for ﬁnding the minimum of a function of several variables

without calculating derivatives. The Computer Journal, 7(2):155–162.

Reinhardt, J. and Schroer, C. (2018). Quantitative ptychographic reconstruction by applying a probe

constraint. Journal of Instrumentation, 13(04):C04016–C04016.

11/12

Rodenburg, J. M. and Faulkner, H. M. L. (2004). A phase retrieval algorithm for shifting illumination.

Applied Physics Letters, 85(20):4795–4797.

Schmidt, J. D. (2010). Numerical simulation of optical wave propagation with examples in MATLAB.

SPIE, Bellingham, Washington.

Thibault, P., Dierolf, M., Menzel, A., Bunk, O., David, C., et al. (2008). High-resolution scanning x-ray

diffraction microscopy. Science, 321(5887):379–382.

Thibault, P. and Guizar-Sicairos, M. (2012). Maximum-likelihood reﬁnement for coherent diffractive

imaging. New Journal of Physics, 14(6):063004.

Thibault, P. and Menzel, A. (2013). Reconstructing state mixtures from diffraction measurements. Nat.,

494(7435):68–71.

Tripathi, A., McNulty, I., and Shpyrko, O. G. (2014). Ptychographic overlap constraint errors and the limits
of their numerical recovery using conjugate gradient descent methods. Opt. Express, 22(2):1452–1466.
Williams, G. J., Quiney, H. M., Dhal, B. B., Tran, C. Q., Nugent, K. A., et al. (2006). Fresnel coherent

diffractive imaging. Phys. Rev. Lett., 97:025506.

Zhang, F., Peterson, I., Vila-Comamala, J., Diaz, A., Berenguer, F., et al. (2013). Translation position
determination in ptychographic coherent diffraction imaging. Opt. Express, 21(11):13592–13606.

Zhang, Z. (2018).

Improved adam optimizer for deep neural networks.

In 2018 IEEE/ACM 26th

International Symposium on Quality of Service (IWQoS), pages 1–2.

12/12

