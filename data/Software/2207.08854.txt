2
2
0
2

l
u
J

8
1

]
E
S
.
s
c
[

1
v
4
5
8
8
0
.
7
0
2
2
:
v
i
X
r
a

A Pattern-based deadlock-freedom analysis
strategy for concurrent systems∗

Pedro Antonino

Augusto Sampaio

Centro de Inform´atica, Universidade Federal de Pernambuco, Recife, PE, Brazil

{prga2@cin.ufpe.br, acas@cin.ufpe.br}

Jim Woodcock
Department of Computer Science, University of York, York, UK

jim.woodcock@york.ac.uk

January 31, 2019

Abstract

Local analysis has long been recognised as an eﬀective tool to combat
the state-space explosion problem.
In this work, we propose a method
that systematises the use of local analysis in the veriﬁcation of deadlock
freedom for concurrent and distributed systems. It combines a strategy for
system decomposition with the veriﬁcation of the decomposed subsystems
via adherence to behavioural patterns. At the core of our work, we have a
number of CSP reﬁnement expressions that allows the user of our method
to automatically verify all the behavioural restrictions that we impose.
We also propose a prototype tool to support our method. Finally, we
demonstrate the practical impact our method can have by analysing how
it fares when applied to some examples.

Keywords— CSP; model checking; reﬁnement; local analysis; behavioural

patterns; system decomposition; deadlock freedom

1

Introduction

A deadlock is a long-standing, common pathology of concurrent systems [1, 2].
It occurs when the system reaches a state where all its components are stuck.
The importance of deadlock analysis is attested by the fact that deadlock free-
dom is often considered to be the ﬁrst step towards correctness for distributed

∗The EU Framework 7 Integrated Project COMPASS (Grant Agreement 287829) ﬁ-
nanced most of the work presented here. This work is partially funded by INES, grants
CNPq/465614/2014-0 and FACEPE/APQ/0388-1.03/14. No new primary data was created
as part of the study reported here.

1

 
 
 
 
 
 
and concurrent systems. Moreover, safety properties can be reduced to dead-
lock checking [3]. As with many properties of concurrent systems, deadlock
veriﬁcation can be severely aﬀected by the state space explosion problem [4].

One common way to cope with the state space explosion problem is to use
local analysis [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]. Instead of
checking the entire state space of the concurrent system, the analysis of small
combinations of components is carried out to determine whether a system is
deadlock free. In fact, for some complex systems, a method using local anal-
ysis might be the only practicable option. Local analysis methods are usually
incomplete in the sense that they either guarantee deadlock freedom or are in-
conclusive. The latter means they can neither show that the system deadlocks
nor prove deadlock freedom. Traditional local analysis techniques consist of
either fully automatic a posteriori veriﬁcation methods, or guidelines to the de-
sign of a system that, if followed, guarantee deadlock freedom by construction.
The former techniques do not provide any guidance on how system designers
can avoid deadlocks, whereas the latter ones do not provide automatic ways of
checking that the guidelines were correctly followed.

We propose a method that provides both guidelines to construct deadlock-
free systems and a procedure for automatically checking that the guidelines have
been correctly followed. This method embodies a notion of decomposition that
can be used to prove deadlock freedom for systems with an acyclic communi-
cation topology. Moreover, it relies on three behavioural patterns to deal with
cyclic-topology systems. These behavioural patterns restrict both the behaviour
of components and the structure of the system. Both the decomposition and be-
havioural patterns rely on local behavioural analysis. The decomposition relies
on the analysis of pairs of components of the system, whereas the behavioural
patterns constrain the behaviour of individual components. So, this method is
not hindered by the state space explosion problem. Nevertheless, its eﬃciency
comes at the price of incompleteness: deadlock freedom can only be proved for
systems that fall into our decomposition/pattern-adherence method.

This proposed method is based on prior works that explored local analysis
for the veriﬁcation of deadlock freedom for concurrent and distributed systems.
In fact, both the decomposition strategy and two out of the three patterns
presented have been proposed decades ago [5, 7]. Nevertheless, we introduce a
CSP formalisation based on reﬁnement expressions that can be automatically
checked by a reﬁnement checker. In prior works, the decompositions and pattern
adherence are characterised in terms of semantic properties that a system must
have [5, 7]. This characterisation forces the user of such methods to understand
not only the formalism but also the subtleties of its semantic models. On the
other hand, our characterisation based on reﬁnement expressions, together with
design guidelines and tool support, gives a more practical support for the system
designer. More importantly, prior works do not suggest an automatic way to
test whether a system has a given semantic property, whereas our reﬁnement
expressions can be automatically checked by a reﬁnement checker like FDR [21].
Finally, we conduct some experiments to measure the eﬃciency gains on the
analysis of some practical examples.

2

This work is a signiﬁcant extension of two previous works [11, 12]. The new

contributions of this paper are as follows.

• We present formal proofs that our adherence to communication patterns

guarantees deadlock freedom.

• We propose a method that systematises the application of system decom-
position and pattern-adherence checking strategy to ensure deadlock free-
dom for a system. This systematisation should guide the user in applying
our method in practice.

• We analyse the computational complexity of the proposed method, illus-
trate its application to three systems, and compare the method with three
other approaches to deadlock analysis.

• We implemented a prototype tool that supports the proposed systemati-
sation, saving a lot of manual eﬀort that would otherwise be required in
applying our method.

This paper is organised as follows. Section 2 introduces the CSP notation,
some of its semantic models and a theory of networks of processes, based on
CSP, that we use to represent and reason about concurrent systems. In Sec-
tion 3, we present our decomposition strategy and how it can ensure deadlock
freedom for acyclic-topology systems. Section 4 presents the formalisation of
three behavioural patterns that prevent deadlocks. In Section 5, we present our
method and a tool to support it. This section also presents the results of some
experiments we conduct to assess the eﬃciency of our method when compared
to traditional a posteriori veriﬁcation techniques. Section 6 introduces a series
of related works and how they relate to ours. Finally, in Section 7, we present
our concluding remarks.

2 Background

We present a brief introduction to CSP, including the main operators and se-
mantic models used in this work. Then we introduce a notion of live-network
model, which is basically a sequence of components that obey some relevant
properties. Two CSP models, used as running examples, are also presented.

2.1 CSP

Communicating Sequential Processes (CSP) [22, 23, 24] is a notation used to
model concurrent systems where processes interact by exchanging messages. In
this notation, sequential processes can be combined using high-level parallel
operators to create complex concurrent processes. The CSP notation used here
is the machine-readable version called CSPM , which is the standard version for
encoding CSP processes by the FDR tool [21]. In the following, we informally
introduce some operators of this language using two CSP systems that serve

3

as running examples throughout this paper. Our ﬁrst example introduces a
ring-buﬀer system.

Running Example 1. A ring buﬀer with NCELLS storage cells is a system
that stores data in a ﬁrst-in-ﬁrst-out fashion and where its storage cells are
written to in a cyclic way. Cells are organised as if they were part of a ring,
and once some piece of data is written to a cell, the next piece of data will be
written to the next cell on this ring, provided the next cell is available. Our
system can store up to N = NCELLS + 1 pieces of data because it has an extra
cache storage space. N CELLS (and N ) is a global constant that serves as a pa-
rameter for our model; by changing N CELLS, we can create an arbitrary-sized
system with N CELLS > 0 many cells. We use a central controller (described
by process Controller(cache,size,top,bot) whose parameters are initially
0) to manage input and output requests to the buﬀer. This process has four
parameters: cache holds the next element to be output, size keeps track of
how many cells are full, top and bot keep track of which cell is the top (i.e., be-
ginning) and the bottom (i.e., end) of the buﬀer, respectively. The parameters
of a process represent its internal state.

Controller(cache,size,top,bot) =

size < N & Input(cache,size,top,bot)
[]
size > 0 & Output(cache,size,top,bot)

The process c & P behaves like P if the condition c is true and like STOP if
c evaluates to false, where STOP is the atomic process that does nothing and
deadlocks. The process P [] Q represents the external choice of P and Q, that
is, the behaviours of P and Q are initially oﬀered and then either P or Q is chosen.
We point out that an external choice between P and STOP behaves just as P, i.e.,
P [] STOP = P. So, process Controller oﬀers the choice of behaving as Input
if size < N and as Output if size > 0.

If the buﬀer is not full (i.e., size < N ), the controller can receive and store

some data as described by process Input.

Input(cache,size,top,bot) =

input?x ->

(size == 0 & Controller(x,1,top,bot)
[]
size > 0 & write.top!x ->

Controller(cache,size+1,(top+1)%NCELLS,bot))

The preﬁxed process a -> P initially oﬀers the event a and after this event is
performed it behaves as P. CSPM also proposes the notion of a channel that
transmits data. A channel ch is associated to the type of data, say values in
the set datatype, they transmit. So, a channel gives rise to a number of events
each of which denotes the transmission of a diﬀerent piece of data, that is, event
ch.x where x ∈ datatype denotes the transmission of value x. A channel ch
can output ch!x and input ch?x values. Outputting ch!x simply creates event

4

ch.x based on the value x, whereas the input operation ch?x binds the values
of ch’s datatype to x (intuitively, this means that ch can receive/input any
value associated with this channel). So, ch!x -> P behaves as a simple preﬁx,
whereas ch?x -> P behaves like an external choice: each possible value v for
x gives rise to a new branch for which x = v. Note that channels and their
operations are just syntactic sugar over events. For instance, process Input
initially inputs some value v on channel input, and then it proceeds execution
with x = v. The expression (top+1)%NCELLS stands for the increment of top
modulo NCELLS.

If the buﬀer is not empty, the controller can output and update its state as

described by process Output.

Output(cache,size,top,bot) =

output!cache ->

(size > 1 & (read.bot?x ->

Controller(x,size-1,top,(bot+1)%NCELLS))

[]
size == 1 & Controller(cache,0,top,bot))

The process Cell(id,0) describes the individual cells that build up the
buﬀer’s storage space. It holds some value which can be read (using channel
read.id) and updated (using channel write.id).

Cell(id,val) =

read.id!val -> Cell(id,val)
[]
write.id?x -> Cell(id,x)

Our ﬁnal system, given by process RingBufferBehaviour, runs our con-
troller process in parallel with N CELLS storage cell processes using the indexed
version of CSP’s alphabetised-parallel operator.

RingBufferBehaviour = || i : {0..NCELL} @ A(i) [P(i)]

where

• P(0) = Controller(0,0,0,0)

• A(0) = {|read, write, input, output|},

• P(i) = Cell(i,0) for i ∈ {1 . . . N CELL}

• A(i) = {|read.i, write.i|} for i ∈ {1 . . . N CELL}

– In CSPM , the extension operator {|e1, . . . , en|} gives the events that
extend the elements ei. For instance,
in this example, we have
{|read|} gives {read.i.v | i ∈ {0 . . . N − 1} ∧ v ∈ {0, 1}|}, assuming
cells store binary values v.

5

The parallel process P [X||Y] Q allows P and Q to freely perform events
not in the set of events X ∩ Y , but to perform an event in X ∩ Y , P and Q
must synchronise on it. Additionally, P (Q) is only allowed to perform events
in X (Y ). X is called the alphabet of P . This parallel operator also has
an indexed version || e : S @ [A(e)] P(e), where A(e) gives an alphabet
and P(e) gives a CSP process. For this indexed version, all processes are put
in parallel using their corresponding alphabet. Similar to the binary version
of this operator, shared events require synchronisation by all processes having
the event on their alphabet and the non-shared events can be performed freely
by a process. RingBufferBehaviour ensures that components synchronise on
shared events, namely, read and write events only occur when the controller and
the cells cooperate. We formally deﬁne the parallel composition for this system
(cid:4)
when we later introduce our network model.

The second running example that we use describes the well-known asym-

metric solution to the dining philosophers problem.

Running Example 2. In the dining philosophers setting, N philosophers are
trying to eat on a shared round table; N is a constant that also serves as a
parameter for our example/model. To do so, each of them must acquire a pair of
forks: one on its left-hand side and another on its right-hand side. Philosophers
share their right-hand fork with their right neighbour and their left-hand one
with the left neighbour. If all philosophers acquire their forks in the same order,
they might run into the following deadlock. Say that all philosophers acquire
ﬁrst their left-hand fork and then their right-hand one, then they might reach
a state where all of them have acquired their left-hand fork and are waiting for
their right-hand one to be released. A well-known solution to avoid this deadlock
is to have an asymmetric philosopher that acquires forks in the opposite order.
We describe the behaviour of philosophers that acquire and release ﬁrst their
left-hand fork and then their right-hand one by process Phil(id). On the other
hand, asymmetric philosophers are described by APhil(id). Event pickup.i.j
(putdown.i.j) is used by philosopher i to acquire (release) fork j. Functions
next(i) and prev(i) yield (i + 1)%N and (i − 1)%N , respectively.

Phil(id) =

sit.id -> pickup.id.id -> pickup.id!next(id) -> eat.id ->

putdown.id.id -> putdown.id!next(id) -> getup.id ->

Phil(id)

APhil(id) =

sit.id -> pickup.id!next(id) -> pickup.id.id ->

eat.id -> putdown.id!next(id) -> putdown.id.id ->

getup.id -> APhil(id)

A fork can be acquired by a philosopher which later releases it as described

by process Fork(id).

Fork(id) =

[] i : {id,prev(id)} @ pickup.i.id -> putdown.i.id -> Fork(id)

6

The process [] x : S @ P(x) is the indexed version of the external choice
operator. For S = {v1, . . . , v|S|} where |S| gives the size of set S, this process is
P(v1) [] ... [] P(v|S|).

The system implementing the asymmetric solution, given by APhilsBehaviour,

runs in parallel N forks, N − 1 philosophers and an asymmetric philosopher. It
relies on the indexed version of CSP’s alphabetised-parallel operator to ensure
processes synchronise on shared events.

APhilsBehaviour = || i : {0..2N-1} @ A(i) [P(i)]

where

• P(i) = Phil(i) for i ∈ {0, . . . , N − 2}

• A(i) = AlphaP hil(i) for i ∈ {0, . . . , N − 2}

– AlphaP hil(i) = {sit.i, pickup.i.i, pickup.i.next(i), eat.i,
putdown.i.i, putdown.i.next(i), getup.i}

• P(N-1) = APhil(N-1)

• A(N-1) = AlphaP hil(N − 1)

• P(i) = Fork(i) for i ∈ {N, . . . , 2N − 1}

• A(i) = ({pickup.i.i, pickup.prev(i).i,

putdown.i.i, putdown.prev(i).i}, Fork(i))

(cid:4)

2.2 Denotational semantics

In order to reason about processes, CSP embodies a collection of mathematical
models. In this work, we use the stable failures model, and the less conventional
stable revivals model.

In the stable-failures model, a process is represented by a pair (F, T ) con-
taining its stable failures and its ﬁnite traces, respectively. The traces of a
process are represented by a set of all the ﬁnite sequences of visible events that
this process can perform; this set is given by traces(P ). The stable failures of
a process are represented by a set of pairs (s, X), where s is a trace and X is
a set of events that the process can refuse to do after performing the trace s.
At the state where the process can refuse events in X, the process must not be
able to perform an internal action, otherwise this state would be unstable and
would not be taken into account in this model. The function failures(P ) gives
the set of stable failures of process P . Hence, the representation of process P
in this model is given by the pair (failures(P ), traces(P )).

Before introducing how to systematically calculate the traces and failures of a
process, we introduce a few more constructs of the CSPM notation. Similarly to
STOP, SKIP is the atomic process that does nothing and terminates successfully.

7

Another useful atomic process, mainly from a theoretical perspective, is div,
which is the diverging process. Σ is the universal set of visible events; the
invisible event τ and the termination signal (cid:88) are not members of this set. The
internal (non-deterministic) choice process P |~| Q oﬀers either P or Q non-
deterministically. The process P ; Q behaves initially as process P and, once P
successfully terminates, it behaves as process Q.

The renaming process P [[R]], where R is a set of pairs a <- b, oﬀers a de-
terministic choice of events in S whenever P oﬀers a, where S = {b | (a <- b) ∈
R}. The hidden process P \ S oﬀers the events not in S whenever P oﬀers them.
On the other hand, P \ S can perform a τ , the silent event, whenever P can
perform an event in S. The interrupt process P /\ Q behaves like P and at any
point it can be interrupted in which case it behaves as Q.

The CSPM notation does not provide an explicit operator for recursion, but
it allows one to use the name of the process in its deﬁnition. For instance, P
= a -> P performs a, and then recurses, behaving as P. Even though a formal
construct is not available for recursion, we can deﬁne it as an equation where the
right-hand side is a process context depending on the deﬁnition of the process
itself, e.g. X = F (X). For the process P given above, we can deﬁne it as P
= F(P), where F (X) = a -> X. For the purpose of giving the semantics of a
recursive process, we use this style of deﬁnition.

The functions traces(P ) and failures(P ) are calculated inductively based on
the constructs of the CSP language. The clauses for calculating the traces are
presented in Table 1, whereas the clauses for calculating the failures are depicted
in Table 2. The semantics of a recursive process can be calculated, using the
presented clauses, thanks to the following equivalence. For a recursive process
P = F (P ), P ≡ (cid:117){F n(div) | n ∈ N}, where (cid:117) S is the distributed application
of the operator |~| to the processes in S. This equivalence also holds for the
stable revivals model, presented later.

We illustrate the calculation of these behaviours using our ring-buﬀer system.

Running Example 1. We illustrate the traces and stable-failures for the pro-
cesses Controller(0,0,0,0) and Cell(0,0). For the following failures sets,
(tr, S) is a shorthand for all pairs (tr, X) such that X ⊆ S; this makes our
examples more compact.

• traces(Controller(0,0,0,0)) =

{(cid:104)(cid:105), (cid:104)input.0(cid:105), (cid:104)input.1(cid:105), (cid:104)input.2(cid:105), (cid:104)input.0, input.0(cid:105), (cid:104)input.0, input.1(cid:105),
(cid:104)input.0, input.2(cid:105), (cid:104)input.0, output.0(cid:105), (cid:104)input.1, output.1(cid:105), . . .}

• failures(Controller(0,0,0,0)) =

{((cid:104)(cid:105), Σ − {input.0, input.1, input.2}),
((cid:104)input.0(cid:105), Σ − {input.0, input.1, input.2, output.0}),
((cid:104)input.1(cid:105), Σ − {input.0, input.1, input.2, output.1}),
((cid:104)input.2(cid:105), Σ − {input.0, input.1, input.2, output.2})), . . .}

• traces(Cell(0,0)) =

{(cid:104)(cid:105), (cid:104)read.0(cid:105), (cid:104)write.0(cid:105), (cid:104)write.1(cid:105), (cid:104)write.2(cid:105), (cid:104)read.0, write.0(cid:105),
(cid:104)read.0, write.1(cid:105), (cid:104)read.0, write.2(cid:105), (cid:104)read.0, write.0, read.0(cid:105), . . .}

8

• failures(Cell(0,0)) =

{((cid:104)(cid:105), Σ − {read.0, write.0, write.1, write.2}),
((cid:104)read.0(cid:105), Σ − {read.0, write.0, write.1, write.2}),
((cid:104)write.0(cid:105), Σ − {read.0, write.0, write.1, write.2}),
((cid:104)write.1(cid:105), Σ − {read.1, write.0, write.1, write.2})),
((cid:104)write.2(cid:105), Σ − {read.2, write.0, write.1, write.2}), . . .}

(cid:4)

In this model, the failures for a given trace are subset closed:

if (s, X) ∈
failures(P ) then so is (s, Y ) provided Y ⊆ X. So, for some properties, we will
be interested only in the maximal failures, considering the subset order, for each
trace s. failures(P ) denotes the set of such maximal failures for process P .

Stable Revivals Model

In the stable revivals model, a process is described by a triple (T, D, R) contain-
ing its traces, its deadlocks and its stable revivals, respectively. The deadlocks

traces(STOP)

traces(SKIP)

traces(div)

traces(a -> P )

traces(P ; Q)

traces(P [] Q)

= {(cid:104)(cid:105)}
= {(cid:104)(cid:105), (cid:104)(cid:88)(cid:105)}
= {(cid:104)(cid:105)}

= {(cid:104)(cid:105)} ∪ {(cid:104)a(cid:105) ˆ s | s ∈ traces(P )}
= (traces(P ) ∩ Σ∗) ∪ {s ˆt | sˆ (cid:104)(cid:88)(cid:105) ∈ traces(P ) ∧ t ∈ traces(Q)}
= traces(P ) ∪ traces(Q)

traces(P |~| Q)
traces(P [|X|] Q) = (cid:83){s (cid:107)
X

= traces(P ) ∪ traces(Q)

t | s ∈ traces(P ) ∧ t ∈ traces(Q)}

traces(P \ X)

traces(P [[R]])

traces(P /\ Q)

= {s \ X | s ∈ traces(P )}
= {t | ∃ s ∈ traces(P ) • s R∗ t}
= traces(P ) ∪ {s ˆt | s ∈ traces(P ) ∩ Σ∗ ∧ t ∈ traces(Q)}

where

• sˆ t represents the concatenation of sequences s and t.

• s (cid:107)
X

t gives all the traces w that are interleaving of s and t such that

w `| X = s `| X = t `| X.

• s `| X gives the trace resulting from removing events not in X from s.

• s \ X gives the trace resulting from removing events in X from s.

• (cid:104)s0, . . . , sn(cid:105)R∗(cid:104)t0, . . . , tm(cid:105) holds iﬀ n = m and ∀ i ∈ {0 . . . n} • siRti.

Table 1: Semantic clauses for the traces model

9

failures(STOP)

failures(SKIP)

failures(div)

= {((cid:104)(cid:105), X) | X ⊆ Σ ∪ {(cid:88)}}
= {((cid:104)(cid:105), X) | X ⊆ Σ} ∪ {((cid:104)(cid:88)(cid:105), X) | X ⊆ Σ ∪ {(cid:88)}}
= ∅

failures(a -> P )

failures(P ; Q)

= {((cid:104)(cid:105), X) | a /∈ X} ∪ {((cid:104)a(cid:105) ˆs, X) | (s, X) ∈ failures(P )}
= {(s, X) | s ∈ Σ∗ ∧ (s, X ∪ {(cid:88)}) ∈ failures(P )}∪

{(sˆ t, X) | s ˆ(cid:104)(cid:88)(cid:105) ∈ traces(P ) ∧ (t, X) ∈ failures(Q)}

failures(P [] Q)

= {((cid:104)(cid:105), X) | ((cid:104)(cid:105), X) ∈ failures(P ) ∩ failures(Q)}∪

{(t, X) | (t, X) ∈ failures(P ) ∪ failures(Q) ∧ t (cid:54)= (cid:104)(cid:105)}∪
{((cid:104)(cid:105), X) | X ⊆ Σ ∧ (cid:104)(cid:88)(cid:105) ∈ traces(P ) ∪ traces(Q)}

failures(P |~| Q)
failures(P [|X|] Q) = (cid:83){(s (cid:107)
X

= failures(P ) ∪ failures(Q)

t, Y ∪ Z) | Y (cid:56)(X ∪ {(cid:88)}) = Z(cid:56)(X ∪ {(cid:88)}) ∧

(s, Y ) ∈ failures(P ) ∧ (t, Z) ∈ failures(Q)}

failures(P \ X)

failures(P [[R]])

failures(P /\ Q)

= {(t \ X, Y ) | (t, Y ∪ X) ∈ f ailures(P )}
= {(t, X) | (∃ t(cid:48) | (t(cid:48), t) ∈ R∗ ∧ (t(cid:48), R−1(X)) ∈ failures(P )}
= {(s, X) | (s, X) ∈ failures(P ) ∧ s ∈ Σ∗ ∧ ((cid:104)(cid:105), X) ∈ failures(Q)}

∪ {(s, X) | sˆ (cid:104)(cid:88)(cid:105) ∈ traces(P ) ∧ (cid:88) /∈ X}
∪ {(s ˆ(cid:104)(cid:88)(cid:105), X) | sˆ (cid:104)(cid:88)(cid:105) ∈ traces(P )}
∪ {(s ˆt, X) | s ∈ traces(P ) ∩ Σ∗ ∧ (t, X) ∈ failures(Q)}

Table 2: Semantic clauses for the failures model

of a process are given by the set of traces after which the process refuses all the
events in its alphabet; this set is given by deadlocks(P ). The stable revivals set
is composed of triples (s, X, a) containing a trace, a refusal set, and a revival
event, respectively. The refusal set X, similarly to the one described in the sta-
ble failures model, describes the set of events that can be refused by the process
after the trace s. The revival event a represents an event that the process can of-
fer after performing s and refusing X. At the state where the revival is recorded,
the process must not be able to perform an internal action, otherwise this state
is unstable, not being taken into account. The function revivals(P ) gives the
set of stable revivals of process P . Thus, the representation of a process P in
this model is given by (traces(P ), deadlocks(P ), revivals(P )). The necessity of
this model comes from the fact that some properties that we intend to capture
cannot be naturally captured using the notion of reﬁnement over the failures
model. Conﬂict freedom is a concrete example of such properties. Generally,
requiring that diﬀerent refusal behaviours R1 and R2, where R1 ⊂ R2, from a
process based on whether a particular event is oﬀered cannot be naturally cap-
tured using failures reﬁnement; the subset-closed structure of refusal sets gets
in the way of specifying such a property.

The functions traces(P ), deadlocks(P ) and revivals(P ) are calculated induc-
tively based on the constructs of the CSP language. The clauses for calculating
the traces are presented in Table 1. In the same way, the clauses for calculating
deadlocks and revivals are depicted in Table 3 and Table 4, respectively.

10

deadlocks(STOP)

deadlocks(SKIP)

deadlocks(div)

= {(cid:104)(cid:105)}

= ∅

= ∅

deadlocks(a -> P )

deadlocks(P ; Q)

deadlocks(P [] Q)

= {(cid:104)a(cid:105) ˆ s | s ∈ deadlocks(P )}
= {s | s ∈ deadlocks(P )} ∪ {sˆ t | sˆ (cid:104)(cid:88)(cid:105) ∈ traces(P ) ∧ t ∈ deadlocks(Q)}
= ((deadlocks(P ) ∪ deadlocks(Q))∩

{s | s (cid:54)= (cid:104)(cid:105)}) ∪ (deadlocks(P ) ∩ deadlocks(Q))

deadlocks(P |~| Q)

= deadlocks(P ) ∪ deadlocks(Q)

deadlocks(P [|X|] Q) = {u | ∃(s, Y ) : failures(P ) ; (t, Z) : failures(Q) •

Y \ (X ∪ {(cid:88)}) = Z \ (X ∪ {(cid:88)}) ∧ u ∈ (s (cid:107)
X

t) ∩ Σ∗ ∧ Σ(cid:88) = Y ∪ Z}

deadlocks(P \ X)

deadlocks(P [[R]])

= {s \ X | s ∈ deadlocks(P )}
= {s(cid:48) | ∃ s • sRs(cid:48) ∧ s ∈ deadlocks(P )}

where:

failures(P )

= {(s, X) | X ⊆ Σ(cid:88) ∧ s ∈ Dead} ∪ {(s, X), (s, X ∪ {(cid:88)}) | (s, X, a) ∈ Rev}

∪{(s, X) | sˆ (cid:104)(cid:88)(cid:105) ∈ T r ∧ X ⊆ Σ} ∪ {(s ˆ(cid:104)(cid:88)(cid:105), X) | s ˆ(cid:104)(cid:88)(cid:105) ∈ T r ∧ X ⊆ Σ(cid:88)}

Table 3: Deadlocks semantic clauses

We illustrate the calculation of deadlocks and revivals using our ring-buﬀer

system.

Running Example 1. We illustrate the revivals for the processes Cell(0,0)
and Controller(0,0,0,0). Since these two processes do not deadlock, they
have empty deadlocks sets. For the following revivals sets, to make our pre-
sentation more compact, we use (tr, S, S(cid:48)) as a shorthand denoting all pairs
(tr, X, a) such that X ⊆ S and a ∈ S(cid:48).

• revivals(Controller(0,0,0,0)) =

{((cid:104)(cid:105), Σ − {input.0, input.1, input.2}, {input.0, input.1, input.2}),
((cid:104)input.0(cid:105), Σ − {input.0, input.1, input.2, output.0},

{input.0, input.1, input.2, output.0}),

((cid:104)input.1(cid:105), Σ − {input.0, input.1, input.2, output.1},

{input.0, input.1, input.2, output.1}),

((cid:104)input.2(cid:105), Σ − {input.0, input.1, input.2, output.2},

{input.0, input.1, input.2, output.2}), . . .}

• revivals(Cell(0,0)) =

{((cid:104)(cid:105), Σ − {read.0, write.0, write.1, write.2},
{read.0, write.0, write.1, write.2}),

((cid:104)read.0(cid:105), Σ − {read.0, write.0, write.1, write.2},

{read.0, write.0, write.1, write.2}),

((cid:104)write.0(cid:105), Σ − {read.0, write.0, write.1, write.2},

{read.0, write.0, write.1, write.2}),

((cid:104)write.1(cid:105), Σ − {read.1, write.0, write.1, write.2},

{read.1, write.0, write.1, write.2}),

((cid:104)write.2(cid:105), Σ − {read.2, write.0, write.1, write.2},

{read.2, write.0, write.1, write.2}), . . .}

11

revivals(STOP)

revivals(SKIP)

revivals(div)

= ∅

= ∅

= ∅

revivals(a -> P )

= {((cid:104)(cid:105), X, a) | a /∈ X} ∪ {((cid:104)a(cid:105) ˆs, X, b) | (s, X, b) ∈ revivals(P )}

revivals(P ; Q)

= {(s, X, a) | ∧ (s, X, a) ∈ revivals(P )}

∪ {(sˆ t, X, a) | sˆ (cid:104)(cid:88)(cid:105) ∈ traces(P ) ∧ (t, X, a) ∈ revivals(Q)}

revivals(P [] Q)

= {((cid:104)(cid:105), X, a) | ((cid:104)(cid:105), X) ∈ failures b(P ) ∩ failures b(Q)
∧ ((cid:104)(cid:105), X, a) ∈ revivals(P ) ∪ revivals(Q)}

∪ {(s, X, a) | (s, X, a) ∈ revivals(P ) ∪ revivals(Q) ∧ s (cid:54)= (cid:104)(cid:105)}

revivals(P |~| Q)
revivals(P [|X|] Q) = {(u, Y ∪ Z, a) | ∃ s, t • (s, Y ) ∈ failures b(P ) ∧ (t, Z) ∈ failures b(Q)
t ∧ Y \ X = Z \ X

= revivals(P ) ∪ revivals(Q)

∧ u ∈ s (cid:107)
X

∧ ((a ∈ X ∧ (s, Y, a) ∈ revivals(P ) ∧ (t, Z, a) ∈ revivals(Q))

∨ (a /∈ X ∧ ((s, Y, a) ∈ revivals(P ) ∨ (t, Z, a) ∈ revivals(Q))))}
∪ {(u, Y ∪ Z, a) | ∃ s, t • (s, Y, a) ∈ revivals(P ) ∧ t ˆ (cid:104)(cid:88)(cid:105) ∈ traces(Q)
∧ Z ⊆ X ∧ a /∈ X ∧ u ∈ s (cid:107)
X

t}

∪ {(u, Y ∪ Z, a) | ∃ s, t • (t, Z, a) ∈ revivals(Q) ∧ sˆ (cid:104)(cid:88)(cid:105) ∈ traces(P )
∧ Y ⊆ X ∧ a /∈ X ∧ u ∈ s (cid:107)
X

t}

revivals(P \ X)

revivals(P [[R]])

= {(s \ X, Y, a) | (s, Y ∪ X, a) ∈ revivals(P )}
= {(s(cid:48), X, a(cid:48)) | ∃ s, a • sRs(cid:48) ∧ aRa(cid:48) ∧ (s, R−1(X), a) ∈ revivals(P )}

where:

failures b(P )

= {(s, X) | X ⊆ Σ ∧ s ∈ Dead} ∪ {(s, X) | (s, X, a) ∈ Rev}

Table 4: Revivals semantic clauses

(cid:4)

The CSP framework oﬀers, for each semantic model, a reﬁnement relation
between processes. [F= is the reﬁnement relation for the stable failures model. P
[F= Q holds if and only if traces(Q) ⊆ traces(P ) and failures(Q) ⊆ failures(P )
hold. This order relation can be seen as depicting that Q is more deterministic
than P. [V= is the reﬁnement relation for the stable revivals model. P [V= Q
holds if and only if traces(Q) ⊆ traces(P ), revivals(Q) ⊆ revivals(P ) and
deadlocks(Q) ⊆ deadlocks(P ) hold. This relation can be seen as depicting a
ﬁner more-deterministic order. While P [F= Q establishes that Q is more deter-
ministic than P after each trace, P [V= Q establishes that Q is more deterministic
than P for each event oﬀered after each trace (namely, Q must refuse fewer events
than P for each oﬀer of an event a after the trace s).

2.3 Network model

The concepts presented in this section are essentially a slight reformulation of
concepts presented in [6, 5]. A network provides a model for a concurrent system

12

in terms of its components.

Deﬁnition 1. A network is a sequence of components (cid:104)C1, . . . , Cn(cid:105), where
Ci = (Ai, Pi), Ai ⊆ Σ and Pi is a CSP process.

In this work, we consider only live networks. A network is live if and only
if it is busy, non-terminating and triple disjoint. A network is busy if and
only if every component is deadlock free, non-terminating if and only if every
component does not terminate, and triple disjoint if and only if an event is
shared by at most two components.

The communication topology (or topology for short) of a network can be
analysed through its communication graph. It shows how components are con-
nected, where a connection (i.e. edge) between two components represent that
they (might) communicate/interact. This graph only depicts the (static) con-
nections between components.

Deﬁnition 2. The communication graph of a network is an undirected graph
where nodes denote components and there is an (undirected) edge between two
nodes if and only if the corresponding components share some event.

For example, Figure 2 depicts the communication graph for the system imple-
menting the (deadlocking) symmetric version of the dining philosophers problem
with 3 philosophers and 3 forks, Figure 4 depicts the communication graph for an
instance of our ring-buﬀer network with 3 storage cells, and Figure 6 depicts the
communication graph for our (asymmetric) dining-philosophers network with 3
philosophers and 3 forks.

Note that this graph can be constructed based on a static analysis of com-
ponents and their alphabets. The communication topology of a network plays
an important role in deadlock analysis as we present later.

The behaviour of a network is given by a composition of the components’

behaviours as follows.

Deﬁnition 3. Let V = (cid:104)C1, . . . , Cn(cid:105), where Ci = (Ai, Pi), be a network. The
behaviour of V is given by the CSP expression: || i : {1 . . . n} @ [Ai] Pi

We (re-)deﬁne the systems in our running examples using the network model.
Note how the behaviour of the following networks coincide with the processes
that we have earlier introduced to capture the behaviour of the systems in our
running examples. We deﬁne our ring buﬀer system as follows.

Running Example 1. Our ring-buﬀer system is deﬁned by the RingBuffer
network. Its behaviour requires processes to synchronise on shared events.

RingBuffer = (cid:104)Controller, Cell(0), . . . , Cell(N − 1)(cid:105)

• Controller = ({|read, write, input, output|}, Controller(0,0,0,0))

• Cell(i) = ({|read.i, write.i|}, Cell(i,0))

13

– In CSPM , the extension operator {|e1, . . . , en|} gives the events that
extend the elements ei. For instance,
in this example, we have
{|read|} gives {read.i.v | i ∈ {0 . . . N − 1} ∧ v ∈ {0, 1}|}, assuming
cells store binary values v.

(cid:4)

The asymmetric solution to the dining philosophers problem is deﬁned as

follows.

Running Example 2. We deﬁne our asymmetric solution system using net-
work APhils. Note that philosopher N − 1 behaves asymmetrically. Also, we
point out that this network’s behaviour requires processes to synchronise on
shared events.

APhils = (cid:104)P hil(0), . . . , P hil(N − 2), AP hil(N − 1), F ork(0), . . . , F ork(N − 1)(cid:105)

• P hil(i) = (AlphaP hil(i), Phil(i))

– AlphaP hil(i) = {sit.i, pickup.i.i, pickup.i.next(i), eat.i,
putdown.i.i, putdown.i.next(i), getup.i}

• AP hil(i) = (AlphaP hil(i), APhil(i))

• F ork(i) = ({pickup.i.i, pickup.prev(i).i,

putdown.i.i, putdown.prev(i).i}, Fork(i))

(cid:4)

To reason about the behaviour of a network, we deﬁne the notion of a state.
A state presents an instant picture of the behaviour of the network in terms of
its components’ behaviours.

Deﬁnition 4. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi). A state
of the network is a pair (s, R), where R = (R1, . . . , Rn), such that:

• s ∈ Σ∗

• For all i ∈ {1 . . . n}, (s `| Ai, Ri) ∈ failures(Pi).

A network deadlocks if and only if it can reach a state in which no further

action can be taken.

Deﬁnition 5. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and
σ = (s, R), where R = (R1, . . . , Rn), one of V ’s states.

Deadlocked(σ) (cid:98)= Ref usals(σ) = Σ

where Ref usals(σ) (cid:98)= (cid:83){Ai ∩ Ri | i ∈ {1 . . . n}}

14

For live networks, ungranted requests are considered to be the building blocks
of deadlocks. An ungranted request denotes a wait-for dependency from a com-
ponent to another component in a given state. It arises, in a system state, when
one component is oﬀering an event which is being refused by its communication
partner, so they cannot synchronise on this event. As components in a live
network do not deadlock, a deadlock must be formed of a situation in which
there exists a mutual wait between components.

Deﬁnition 6. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and
σ = (s, R), where R = (R1, . . . , Rn), one of V ’s states. There is an ungranted
request between i and j in state σ if the following predicate holds.

ungranted request(σ, i, j) (cid:98)=

request(σ, i, j) ∧ ungrantedness(σ, i, j) ∧ in vocabulary(σ, i, j)

where:

• request(σ, i, j) (cid:98)= (Ai − Ri) ∩ Aj (cid:54)= ∅
• ungrantedness(σ, i, j) (cid:98)= (Ai − Ri) ∩ (Aj − Rj) = ∅
• in vocabulary(σ, i, j) (cid:98)= (Ai − Ri) ∪ (Aj − Rj) ⊆ Voc

– Voc = (cid:83)

i,j∈{1...n}∧i(cid:54)=j(Ai ∩ Aj) gives the vocabulary of the network,

namely, the events requiring components to synchronise.

Given a ﬁxed state σ, we use i →• j to denote that there exists an ungranted
request from i to j in σ. For a given ﬁxed state, one can calculate all ungranted
requests between components and create what we call a snapshot graph.

Deﬁnition 7. A snapshot graph for system state σ is a directed graph where
components are nodes and there is an edge from component i to component j
if and only if there is an ungranted request in σ from i to j.

Unlike communication graphs that depict a static view of the (ﬁxed) topol-
ogy of the network, these snapshot graphs give instantaneous pictures of the
dynamic behaviour of the system. Instead of attempting to capture the overall
complexity of components’ interactions, a snapshot graph depicts dependencies
(i.e., ungranted requests) between components, which are the building blocks
for our study of deadlock.

As mentioned, a network deadlocks when all components are blocked in a
given state. For a live network, in such a state, all components must be waiting
for some other component to advance. This situation implies that there must
exist a cycle of ungranted requests between components. To be more concrete,
the snapshot graph constructed for a deadlocked system state must exhibit a
cycle (of dependencies). The following theorem, asserting these two facts, is our
main tool in proving the soundness of our framework. These facts and their
proofs can be found in [5, 7, 23]

Theorem 1. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network. In a deadlock state σ:

15

1. Each Ci must be blocked.

• A process Ci is blocked in σ if Ai ⊆ Ref usals(σ).

2. There must be a cycle of ungranted requests among components.

• Given a state σ, a cycle of ungranted requests is a sequence c ∈
{1 . . . n}∗ such that for all i in {1 . . . |c|}, ci →• ci⊕1 holds, where ⊕
denotes addition modulo |c| and |c| is the length of sequence/cycle c.

In this paper, we will mainly prove that a system is deadlock free by showing
that a cycle of ungranted requests cannot arise in any conceivable state of the
system. Since such a cycle is a necessary condition for a deadlock, deadlock
freedom can be proved this way. We ﬁnish this section by illustrating a few of
the concepts we have presented.

Example 3. We discuss the concepts of communication and snapshot graph
using the example of the symmetric (deadlocking) dining philosophers. This
system is very similar to the asymmetric version that we have deﬁned in Running
Example 2 but instead of having one right-handed philosopher (as captured in
component AP hil), all philosophers are left-handed (as in component P hil).
We discuss an instance of this system with 3 (left-handed) philosophers and 3
forks. Since all philosophers are left-handed, they ﬁrst acquire their left-hand-
side fork in order to eat. If all of them acquire their left-hand-side fork at the
same time, let us call this system state σ, then all forks have been acquired and
none of them can acquire their right-hand-side one; a deadlock occurs.

Figure 2 depicts the communication graph of this system (left-hand side)
and the snapshot graph for system state σ (right-hand side). On the snapshot
graph, a dependency from F orkx to P hily arises because the philosopher y
has acquired fork x but has not released it yet. So, the fork is oﬀering event
putdown.x.y which is being refused by the philosopher, who is trying to acquire
its right-hand-side fork. A dependency from P hilx to F orky occurs because the
philosopher x is trying to acquire the fork y, which has already been acquired
by the philosopher who is next in the cycle of dependencies (P hilx⊕1, where ⊕
is addition modulo 3). The cycle of ungranted requests in the snapshot graph
is an evidence of the deadlock system state σ represents. Note that ungranted
requests can only arise (in a snapshot graph) between components that are
connected by an edge in the communication graph; if two components do not
(cid:4)
share an event, there cannot be an ungranted request between them.

3 Conﬂict freedom, acyclic networks and decom-

position

Conﬂict freedom can be a very helpful property in proving deadlock freedom
for a system.
It can be used to decompose a proof of deadlock freedom for
a system or, even, to prove that an acyclic network is deadlock free. In this

16

P hil2

F ork0

F ork2

P hil0

P hil1

F ork1

Figure 1: Communication
graph for symmetric dining
philosophers.

P hil2

F ork0

F ork2

P hil0

P hil1

F ork1

Figure 2: Communication graph and snapshot graph for symmetric dining
philosophers.

section, we present a reﬁnement expression that captures conﬂict freedom for
a pair of components. An important advantage of this formalisation is that it
can be automatically checked by a reﬁnement checker. We also discuss how this
property, and our reﬁnement expression, can be used to break down a deadlock-
freedom proof and to show an acyclic network deadlock free.

Deﬁnition 8. A conﬂict is a cycle of ungranted requests of size two, i.e. a
cycle between a pair of components in a network. In a system state σ, a conﬂict
between components i and j arises if and only if i →• j and j →• i. In such a
state, both components are willing to interact with one another, but they cannot
agree on the event they need to synchronise on. Then, a pair of components i
and j is conﬂict free if and only if in there is no system state in which a conﬂict
between i and j occurs.

Conﬂict freedom can be more naturally captured by a reﬁnement expression
if the pair of components being veriﬁed is placed in a particular behavioural
context. This context abstracts the behaviour of both components by using the
process Abs. It abstracts away the events that components can perform individ-
ually as they do not play a part in making a system deadlock. This abstraction
plays a fundamental role in our work; instead of their original behaviour, our
behavioural analyses examine the abstract behaviour of components.

Deﬁnition 9. For a given network V = (cid:104)C1, . . . , Cn(cid:105), where Ci = (Ai, Pi), we
have that Abs(i) = Pi \ (Σ − Voc).

17

Our context is also designed so it oﬀers the special event req whenever these
abstract components can both oﬀer an event from Ai ∩Aj. This context is given
by the process Context.

Deﬁnition 10. Let Ci and Cj be two components of network V .

Context(i,j) = Ext(i,j)[union(A(i),req)||union(A(j),req)] Ext(j,i)

where Ext(i,j) = Abs(i) [[ x <- x, x <- req | x <- inter(A(i),A(j))]]

When in this context, if both components are making requests to each other
(i.e. they are both oﬀering events in Ai ∩ Aj) but they do not agree on this
event (i.e. they oﬀer diﬀerent events), then they both can oﬀer req so they can
synchronise on req but they cannot synchronise on any event on Ai ∩ Aj. So,
a conﬂict arises when the req event is oﬀered and Ai ∩ Aj is refused. Hence,
a conﬂict free pair of processes does not have some revival of the form (s, Ai ∩
Aj, req). So, the characteristic process ConflictFreeSpec capturing conﬂict
freedom must have all possible revivals but these ones.

Deﬁnition 11. Let Ci and Cj be two components in network V .

ConflictFreeSpec(i,j) =

let U_A = union(A(i),A(j))
I_A = inter(A(i),A(j))
CF = ((|~| ev : I_A @ ev -> CF)

[] req -> CHAOS(union(U_A,{req})))

|~|
(|~| ev : U_A @ ev -> CF)

within CF

where: CHAOS(A) = SKIP |~| STOP |~| (|~| ev : A @ ev -> CHAOS(A))

The following theorem depicts the reﬁnement expression we propose to check
conﬂict freedom. Note that we use the stable revivals model, as this property
can be more intuitively captured in this model. The reason is the nature of
conﬂict freedom. A pair of processes are conﬂict free if they are not at all
willing to engage or if they are willing and able to engage. This implies that in
the stable failures model, we would need a process that could refuse all shared
events as well as oﬀer some events to engage, but this intuitively violates the
property that refusals should be subset closed.

Theorem 2. ConflictFreeSpec(i,j) [V= Context(i,j) ⇒ the pair of com-
ponents (Ci, Cj) is conﬂict free.

Proof. In a conﬂict free state, the Context process must not have a revival of
the form (s, X, req) where Ai ∩ Aj ⊆ X. After calculation of the revivals of the
ConflictFreeSpec, its revivals are given by the following set comprehension
expression {(s, X, a)|s ∈ (Ai ∪ Aj ∪ {req})∗ ∧ a ∈ (Ai ∪ Aj ∪ {req}) ∧ a (cid:54)∈
X ∧ (a = req ⇒ (Ai ∩ Aj) (cid:54)⊆ X)}; this speciﬁcation has all the possible

18

revivals but the ones generated by a conﬂict. If the reﬁnement expression holds,
then revivals(ConflictFreeSpec(i,j)) ⊇ revivals(Context(i,j)). Hence, in
this case Context has only conﬂict free revivals. For the other components of
this model, deadlocks and traces, the restrictions are evident. Traces are not
restricted at all, traces(ConflictFreeSpec(i,j)) = (Ai ∪ Aj ∪ {req})∗, also as
deadlock can only arise if there is a conﬂict, we restrict the set of deadlocks to
be empty, deadlocks(ConflictFreeSpec(i,j)) = ∅.

Conﬂict freedom can be used to break down the veriﬁcation of deadlock for
a network to the analysis of some of its subnetworks. In the communication
graph of a network, the disconnecting edges are the edges whose removal would
increase the number of connected components in this graph – these are bridges in
graph-theoretic terms. We call essential subnetworks the connected components
resulting after removing some of these edges.

Theorem 3 (Theorem 4 in [6]). A network V is deadlock free if the essen-
tial subnetworks resulting from the removal of conﬂict-free disconnecting edges
are deadlock free. A disconnecting edge is conﬂict free if and only if the two
components participating on it are conﬂict free.

We give an example to illustrate the concepts linked to decomposition.

Example 4. Let V = (cid:104)C0, C1, C2, C3, C4, C5(cid:105) be a live network for which com-
munication graph is given in Figure 3. This network has two rings (C0, C1, C2
and C3, C4, C5) which are interconnected via components C0 and C3. Also, let
σ1, σ2, and σ3 be states of this network for which snapshot graphs are also
depicted in Figure 3.

This network has a single disconnecting edge (C0, C3). Note that by re-
moving this edge, we end up with two essential subnetworks (i.e. connected
components in graph-theoretic terms) (cid:104)C0, C1, C2(cid:105) and (cid:104)C3, C4, C5(cid:105). If, instead,
we decided to remove any other edge, we would end up with a single connected
component. Hence, all other edges are not disconnecting.

In a live network, a component is either blocked because it is in a path of
ungranted requests leading to a blocked subnetwork or because it is in a cycle of
ungranted requests; such a cycle is sort of a fundamental blocked subnetwork.
Considering our network, a deadlocked state could arise because there is a con-
ﬂict between our two rings, i.e. a conﬂict between C0 and C3, as for instance in
state σ1. Note that in this state, all other components depend on this pair of
components to progress. If we remove the C0, C3 edge (from the communication
graph) and analyse the two rings independently, these two separate subnetworks
could even be deadlock free and still admit exactly the paths of ungranted re-
quests leading to the conﬂict shown in σ1 when put together. Note that these
paths on their own are not blocking either ring (hence, deadlock free could admit
these paths), the conﬂict is the root cause of the deadlock. Therefore, inadver-
tently removing disconnecting edges and might lead to unknowingly removing
the root cause of a deadlock from our analysis. Disconnecting edges can only
be removed if they are conﬂict free.

19

C1

C2

C1

C2

C4

C1

C0

C3

C0

C3

C5

C2

C4

C1

C0

C3

C0

C3

C5

C2

C4

C5

C4

C5

Figure 3: Communication graph and snapshot graphs for states σ1, σ2, and σ3,
respectively (left to right, top to bottom), for our examples.

Let us assume now that the edge C0, C3 is conﬂict free (so state σ1 is un-
reachable). For a deadlock to arise, it must be that one of the rings is blocked
and the components in the other ring are in ungranted-request paths leading to
it. This happens, for instance, in state σ2 where we have that the subnetwork
(cid:104)C3, C4, C5(cid:105) is blocked by a cycle of dependencies and the other ring (involving
C0, C1, C2) depends on this subnetwork, so we have a deadlock. As our discon-
necting edge is conﬂict free, we could analyse our rings independently. This state
shows, however, that it only takes one blocked (essential) subnetwork to make a
system deadlock. Note here that the path in σ2 around ring C0, C1, C2 is a valid
conﬁguration of a deadlock free (sub)network. The cycle of ungranted requests
around the ring C3, C4, C5, however, means that this subnetwork deadlocks.

If the edge C0, C3 is conﬂict free and the two rings are independently dead-
lock free, it is impossible for one ring to be blocked by the other. State σ3 shows
(cid:4)
a state where ring C0, C1, C2 depends on a progressing ring C3, C4, C5.

Thus, our reﬁnement expression can be used to show that a disconnecting
edge is conﬂict free, enabling one to decompose the network into smaller essential
subnetworks. Also, note that the identiﬁcation of disconnecting edges can be
carried out statically, i.e., by examining the communication graph, so generally
this should be considerably simpler than showing conﬂict freedom for them.
Note that a given network has a unique set of conﬂict-freedom disconnecting
edges that can be removed to decompose the network.

20

In addition to that, from this theorem, we can deduce the following corollary:

Corollary. A (live) conﬂict-free acyclic (topology) network must be deadlock
free.

A network is conﬂict free if and only if all its edges are conﬂict free. Note
that for an acyclic network, all edges are disconnecting ones. So, provided
that all edges are conﬂict free, we can remove them and, as a result, we would
have essential subnetworks with a single component. Thus, as components are
deadlock-free, by the busyness requirement, this acyclic network must be dead-
lock free.

So, using our reﬁnement expression, one can systematically decompose a
network or even prove deadlock freedom for conﬂict-free acyclic networks. Both
these applications can substantially reduce the complexity of deadlock-freedom
analysis at a fairly low price; our conﬂict analysis only involves the examina-
tion of pairs of components as opposed to the system’s overall behaviour. For
instance, a conﬂict-free acyclic network can be simply ensured deadlock free by
this sort of pairwise (local) analysis; we illustrate this with an example.

Running Example 1. Our ring-buﬀer network can be checked deadlock free
by using decomposition alone. In this example, we analyse a network with one
controller and three storage cells. In Figure 4, we depict the communication
graph of our example system and which sort of conﬂicts could potentially hap-
pen (they do not actually happen as we discuss next). Contr represents the
controller component, whereas Celli depicts a Cell(i) component. This system
has an acyclic communication graph (i.e.
topology) so every edge is discon-
necting. Moreover, every edge (i.e. pair of components connected by an edge)
is conﬂict free: whenever the controller wants to read from or write to a cell,
it can do so. So, none of the possible conﬂicts depicted in Figure 4 can arise
in any given system state. As all disconnecting edges are conﬂict free, we can
decompose this network by removing all edges. This process results in 4 essen-
tial networks all of which have a single component. Since all components are
deadlock free by virtue of our network being live, these essential subnetworks
are deadlock free. Finally, by Theorem 3, this network must be deadlock free.
(cid:4)

4 Behavioural patterns

Despite being useful, conﬂict-freedom testing has its limitation. For instance,
it is unable to show deadlock freedom for cyclic-topology systems or even to
decompose systems with no disconnecting edges. For these cases, we propose
pattern adherence as an alternative eﬀective veriﬁcation technique that relies
on local (compositional) analysis to ensure deadlock freedom. Once again, we
give up completeness in exchange for eﬃciency. We can only ensure deadlock
freedom for systems that adhere to one of the communication/behavioural pat-
terns that we propose but adherence to these patterns can be eﬃciently tested
in a local/compositional way.

21

Cell1

Cell1

Contr

Cell2

Contr

Cell2

Cell3

Cell3

Figure 4: Communication graph for RingBuﬀer network with 3 storage cells and
example of conﬂicts that could arise, respectively.

In this section, we present a characterisation of behavioural patterns using
reﬁnement expressions that can prove deadlock freedom for some networks with
an arbitrary communication topology. We introduce our formalisation and a
proof of their soundness. We formalise requirements on the behaviour of com-
ponents as reﬁnement assertions. This formalisation permits automatic checking
of behavioural constraints using reﬁnement checkers, providing their model sizes
are tractable.

4.1 Resource allocation

The resource allocation pattern can be applied to systems that, in order to
perform an action, have to acquire some shared resources. In this pattern, the
components of a network are divided into users and resources. A user represents
a component of the system that needs to acquire some resources in order to fulﬁl
its ﬁnal purpose. A resource is at the disposal of the users of the system.

As with design patterns for object-oriented programming languages, our
behavioural patterns are speciﬁed in terms of some distinguished elements. For
instance, when designing a resource allocation network, some components are
meant to be users, whilst others are meant to be resources. These pattern
elements are identiﬁed through a pattern descriptor.

A resource-allocation descriptor for a network V , with n components and Σ
as alphabet, is a tuple M = (C, acquire, release) containing a set C ⊆ {1 . . . n}×
{1 . . . n} and two functions acquire and release. Each pair (i, j) ∈ C represents
the existence of a connection in V between the user component i and the resource
component j. The function application acquire(i, j) (release(i, j)) gives the
event used by i to acquire (release) j. These functions must be deﬁned to all
pairs in C. As conventions, users (cid:98)= {i | ∃ j : {1 . . . n} • (i, j) ∈ C}, resources (cid:98)=
{j | ∃ i : {1 . . . n} • (i, j) ∈ C}, resources(i) (cid:98)= {j | (i, j) ∈ C}, users(j) (cid:98)= {i |
(i, j) ∈ C}.

22

A network and a resource allocation descriptor are compliant with the re-
source allocation pattern if they fulﬁl some structural and behavioural condi-
tions. The structural constraint restricts the static elements of the network. For
instance, it may restrict which connections can be made between components or
which events are shared amongst components. On the other hand, behavioural
constraints restrict the behaviour of the components of the network.

The structural constraint for this pattern requires the identiﬁcation of ele-
ments as either resources or users. Additionally, it restricts which events are
shared. In this case, only events for acquisition and release of resources can be
shared. This constraint, which appears recurrently in our patterns, singles out
which events are used for interaction between components. Therefore, we can
restrict the behaviour of components on these events to avoid deadlocks.

Deﬁnition 12. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and
M a resource allocation pattern descriptor for V . The network V and the
descriptor M are structurally compliant if and only if the following predicates
hold.

• partitioned (cid:98)= {1 . . . n} = users ∪ resources ∧ users ∩ resources = ∅
• mutually disjoint events (cid:98)=

¬ ∃ i : users ; j : resources • acquire(i, j) = release(i, j)

• controlled alpha users (cid:98)=

∀ i : users • Ai ∩ Voc = {acquire(i, j), release(i, j) | j ∈ resources(i)}

• controlled alpha resources (cid:98)=

∀ i : resources • Ai ∩ Voc = {acquire(j, i), release(j, i) | j ∈ users(i)}

On the behavioural side, we present two CSP processes that deﬁne the ex-
pected behaviour of a user component and of a resource component. The re-
source component should oﬀer the events of acquisition to all users able to
acquire this resource and, once acquired, it oﬀers the release event to the user
that has acquired it.

Deﬁnition 13. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network, and M a resource allo-
cation descriptor for V . ResourceSpec(i) deﬁnes the expected behaviour of a
resource component.

ResourceSpec(i) = [] j : users(i) @ acquire(j,i) ->

release(j,i) -> Resource

A user component should ﬁrst acquire all the necessary resources, and then
release them. Both acquiring and releasing must be performed using the order
denoted by the order(i) sequence.

Deﬁnition 14. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network, M a resource allocation
descriptor for V , and order(i) a function giving the sequence in which resources
are acquired by component i. U serSpec(i) deﬁnes the expected behaviour of a
user component.

23

UserSpec(i) =

let Acquire(s) =

if s != <> then acquire(i,head(s)) -> Acquire(tail(s))
else SKIP

Release(s) =

if s != <> then release(i,head(s)) -> Release(tail(s))
else SKIP

User(s) = Acquire(s);Release(s);User(s)

within User(order(i))

To ensure that a component meets its speciﬁcation, the behavioural con-
straint requires the stable failure reﬁnement relation to hold between the spec-
iﬁcation and the behaviour of a component.

Deﬁnition 15. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), M
a resource allocation pattern descriptor for V , order(i) a function giving the
sequence in which resources are acquired by component i, and >RA a strict
total order on resources. V and M are behaviourally compliant if and only if
the following hold.

• ∀ i : users • UserSpec(i) [F= Abs(i)

• ∀ i : resources • ResourceSpec(i) [F= Abs(i)

• ∀ i : users • order(i) must respect >RA

A sequence (cid:104)s1, . . . , sn(cid:105) respects an order > if the elements in the sequence are
ordered respecting >, namely, for all i ∈ {1 . . . n} we have that si > si+1.

Note that we require an abstract version of a component’s behaviour to
comply with its speciﬁcation. The reason is that, to guarantee deadlock freedom,
we only need to regulate the behaviour related to events used in the interaction
between components. The behaviour of a component on non-shared events is not
relevant in deadlock analysis, as the component can perform them individually.
So, in the analysis of deadlock freedom, we can study the network composed of
the abstract behaviours of components, rather than the fully detailed network.
This result is presented in the following lemma.

Lemma 1. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and
V (cid:48) = (cid:104)C (cid:48)
i = (Ai, Abs(i)); Abs(i) as per
Deﬁnition 9. If V (cid:48) is deadlock free then so is V .

n(cid:105) another network where C (cid:48)

1, . . . , C (cid:48)

Proof. We prove this claim by contradiction. Assuming that V (cid:48) is deadlock free
and V is not, we reach a contradiction. Let us assume that σ = (s, (R1, . . . , Rn))
is a deadlock state of V , thus Ref usal(σ) = Σ. In σ, none of the components
of V must be willing to perform an event that is not in the vocabulary, that
is, Voc ⊆ Ri for all i ∈ {1 . . . n}.
If that was not the case, then σ would
not be a deadlocked state. Hence, from the deﬁnition of a network state and
from the clause calculating the failures for the hiding operator, we can deduce

24

that the state σ(cid:48) = (s `| Voc, (R1, . . . , Rn)) is a valid state for V (cid:48). So, since
Ref usal(σ) = Ref usal(σ(cid:48)) and both networks have the same alphabet, then σ(cid:48)
represents a deadlock for V (cid:48), thus a contradiction.

As the main result of this section, we show that compliance to the resource-
allocation pattern guarantees deadlock freedom. It ensures that resources in a
path of ungranted requests respect our strict order >RA, namely, if there is a
path from r1 to rn then r1 >RA rn. Hence, a cycle of ungranted requests would
lead to a contradiction in the form of r >RA r. Therefore, such cycles cannot
arise and that, in turn, guarantees deadlock freedom. This sort of coincidence
between paths of ungranted requests and a strict order is a core common idea
shared by our patterns which makes them sound. Note that the idea of ordering
resources and their acquisition to prevent deadlocks, which inspired ours and
many other works, reaches back decades [1, 25].

Theorem 4. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), M
a resource allocation pattern descriptor for V , order(i) a function giving the
sequence in which resources are acquired by component i, and >RA a strict total
order on resources. If V and M are resource allocation compliant then V is
deadlock free.

Proof. We prove this theorem by showing that the network V (cid:48) = (cid:104)C (cid:48)
where C (cid:48)

i = (Ai, Abs(i)), is deadlock free and by using Lemma 1.

1, . . . , C (cid:48)

n(cid:105),

To prove that V (cid:48) is deadlock free, we rely on the second condition of Theorem
1. So, we show that there cannot be a cycle of ungranted requests between
components of this network.

First, given that partitioned holds, we know that a component must be
either a resource or a user. Moreover, thanks to mutually disjoint events,
we know that events cannot be used for both acquiring and releasing a re-
source. Conditions controlled alpha users, controlled alpha resources and
triple-disjointness implies that no two resources, nor two users, can share an
event. As no two resources, nor two users, can share an event, the predicate
request cannot be met and, as a consequence, there cannot be an ungranted
request between such two elements. Thus, a cycle of ungranted requests in this
network must be composed of alternating users and resources. So, we move on
to analyse the interaction between a user and a resource.

Let Cr be a resource component and Cu a user one. From the required be-
haviour compliance, we know that the Abs(i) has to behave exactly as User(u)
or Resource(r) for i = u or i = r, respectively. So, we can analyse the be-
haviour of Abs(i) in terms of the behaviour of these two processes.

Based on the behaviour of User(u) and Resource(r), we know that an un-
granted request can only arise from u to r in a state σ if and only if u is ready
to acquire r, but r has already been acquired by another user.
In all other
cases, u and r can successfully interact preventing the ungranted request. Note,
then, that a cycle of ungranted requests can only involve resources that have
already been acquired. Thus, we only discuss paths and cycles of ungranted re-
quest where all resources have been acquired. Additionally, based on User(u)’s

25

r1

u1

r2

...

rn−1

un−1

rn

implies r1 >RA rn

u1

r1

r2

un

...

rn

implies r1 >RA r1
(contradiction)

Figure 5: Chain of ungranted requests and cycle of ungranted requests coinci-
dence with >RA.

behaviour, we know that (i) u is trying to acquire a resource that is higher,
considering >RA, than any of its acquired resources.

Two kind of ungranted requests can happen from a resource r to one of its
users u. An ungranted request from r to u might arise if either r has not been
acquired yet or r has been acquired by u but u is not yet ready to release it.
We are only interested in the later since the former case cannot be part of a
cycle of ungranted requests; note that a free resource cannot be the target of
an ungranted request, as the user issuing the request to acquire this resource
would just be able to do so (i.e. the request would be “granted”).

So, we have that cycles of ungranted requests can only be formed by chains
of the form r →• u →• r(cid:48) where r has been acquired by u and u is trying
to acquire r(cid:48). Such a chain implies that r >RA r(cid:48) by (i). So, for any pair of
resources r1 and rn in a path of ungranted requests r1 →• u1 →• r2 →• . . . →•
rn−1 →• un−1 →• rn, it must hold that r1 >RA rn.

Note, then, that the existence of a cycle of ungranted requests would lead
to a contradiction. Such a cycle is a resource-user chain of ungranted requests
that begins and ends in the same resource. That would imply that a reﬂexive
pair (r, r) belongs to >RA, contradicting the fact that >RA is a strict order
on resources.
In Figure 5, we illustrate the coinciding of the order in which
resources appear in paths of ungranted requests with the order >RA, and the
contradiction it leads to in the context of cycles of ungranted requests.

We use our asymmetric dining philosophers example to illustrate how pat-

terns can be applied to ensure deadlock freedom.

26

AP hil2

AP hil2

F ork0

F ork2

F ork0

F ork2

P hil0

P hil1

P hil0

P hil1

F ork1

F ork1

Figure 6: Communication graph and snapshot graph for asymmetric dining
philosophers.

Running Example 2. Our asymmetric-dining-philosophers network does not
have an acyclic topology.
It is in fact a large ring of alternating fork and
philosopher components. Hence, decomposition is not an option as all edges are
not disconnecting. Note that by removing any edge the number of connected
(graph-theoretic) components/essential subnetworks does not increase; we al-
ways have a single subnetwork.
In this example, we analyse a network with
3 forks and 3 philosophers. Figure 6 depicts the communication graph of our
example system and an example of a system state σ which we discuss next.
P hili represents component P hil(i), F orki component F ork(i), and AP hili
component AP hil(i).

As decomposition is not an option, we apply a pattern to the entire network:
the resource allocation pattern. Philosophers are users and forks are resources,
and philosophers have to acquire forks according to the expected order on their
indexes; this is the >RA order. As this network adheres to this pattern, in a
cycle of ungranted requests the resources present in this cycle must have been
acquired and the way in which they are ordered must respect their natural
index order. For instance, assume that σ is a network state exhibiting a cycle
of ungranted requests such as the one in Figure 6, we explain how the network
cannot reach such a state. Note that there is an ungranted request from F ork2
to AP hil2 and from AP hil2 to F ork0. Such a conﬁguration can only happen
if the F ork2 has not been acquired by AP hil2, according to the behavioural
requirements over users and resources enforced by our pattern. Hence, P hil1
cannot have an ungranted request to F ork1 as it is free to be acquired. If all
the resources were acquired, an ungranted-request path from r1 to r2 would
coincide with our >RA order. Therefore, a cycle of ungranted requests could
(cid:4)
not arise as it would violate the irreﬂexiveness of >RA.

27

4.2 Client/Server

The client/server pattern applies to some networks implementing a client/server
interaction architecture. In such a network, a component might behave as both
a server and a client. As a server, it waits for a request from a client. As
a client, it contacts a server component in the search for some service. The
distinction between behaving as a server or as a client is based on the oﬀer
of events by a component. In a server state it must be oﬀering all its server
events, whereas in a client state it must be willing to request some service. The
distinction between such events, as well as the identiﬁcation of other elements
of this pattern, is made via a pattern descriptor.

A client/server descriptor for a network V , with n components and Σ as
alphabet, is a tuple M = (C, request, responses) containing a set C ⊆ {1 . . . n}×
{1 . . . n} and functions requests and responses. Each pair (i, j) ∈ C represents
the existence of a connection in V between components i and j such that i acts
as a client and j as a server. The function application requests(i, j) yields a set
of events for which the client i requests some service of the server j. For the
request event k, the expected responses are given by the events in responses(k).
As conventions, we have that:

• client request(i) (cid:98)= (cid:83){requests(i, j) | (i, j) ∈ C};
• server request(i) (cid:98)= (cid:83){requests(j, i) | (j, i) ∈ C};
• client response(i) (cid:98)= (cid:83){responses(k) | k ∈ client request(i)};
• server response(i) (cid:98)= (cid:83){responses(k) | k ∈ server request(i)}.
A network V and a client/server descriptor are structurally compliant if they
fulﬁl some conditions. Roughly speaking, these conditions ensure that there
can only be interaction between components through the use of the controlled
events, that is, request and response events. Furthermore, we impose that the
client/server relation between components C should respect a strict order on
component identiﬁers.

Deﬁnition 16. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and
M a client/server pattern descriptor for V , and >CS a strict total order on
component identiﬁers. V and M are structurally compliant if and only if the
following predicates hold.

• disjoint events (cid:98)= requests ∩ responses = ∅
– requests (cid:98)= (cid:83){requests(i, j) | (i, j) ∈ C}
– responses (cid:98)= (cid:83){responses(k) | k ∈ requests}

• controlled alpha (cid:98)=

∀ i : {1 . . . n} • Ai ∩ Voc = server request(i) ∪ client request(i)

∪ server response(i) ∪ client response(i)

28

• ordered holds if and only if the relation C respects >CS.

We propose two expected behaviours for a component in a client/server
network. The ﬁrst one concerns how it behaves as a server. When a component
is behaving as a server, namely, oﬀering some server request event, it must oﬀer
all its server request events. This is to say, as a server, a component cannot
choose which requests it is able to do, but it should rather oﬀer all its services
for its clients.

Deﬁnition 17. Let V = (cid:104)C1, . . . , Cn(cid:105), and M a client/server pattern descriptor
for V . The server request speciﬁcation for component i ∈ {1 . . . n} is given by
the following process.

ServerRequestsSpec(i) =

let sEvts = server_requests(i)

otherEvts = diff(A(i),sEvts)
Server =

((|~| ev : otherEvts @ ev -> SKIP)
|~|
([] ev : sEvts @ ev -> SKIP)) ; Server

within if not empty(otherEvts) then Server else RUN(sEvts)

where RUN(evts) = [] ev : etvs @ ev -> RUN(evts)

In the deﬁnition of the process ServerRequestsSpec, we check whether the
set of non server request events is empty, since the replicated internal choice
operator is not deﬁned for an empty set of elements.

The second behavioural imposition restricts the request-response behaviour
of components. A process, conforming to the client/server pattern, must recur-
sively oﬀer its request events and then the appropriate responses for the selected
request event. The speciﬁcation of this behaviour is given by the following pro-
cess, which also has to deal with the replicated internal choice undeﬁnedness for
the empty set.

Deﬁnition 18. Let V = (cid:104)C1, . . . , Cn(cid:105), and M a client/server pattern descriptor
for V . The request-response speciﬁcation for component i ∈ {1 . . . n} is given
by the following process.

RequestsResponsesSpec(i) =

let cEvts = client_requests(i)
sEvts = server_requests(i)
ClientRequestsResponsesSpec =
|~| ev : cEvts @ ev ->

(if empty(responses(ev)) then SKIP
else ([] res : responses(ev) @ res -> SKIP))

ServerRequestsResponsesSpec =
|~| ev : sEvts @ ev ->

(if empty(responses(ev)) then SKIP
else (|~| res : responses(ev) @ res -> SKIP))

29

C = ClientRequestsResponsesSpec; C
S = ServerRequestsResponsesSpec; S
CS = (ClientRequestsResponsesSpec

|~| ServerRequestsResponsesSpec); CS

within

if empty(cEvts) and empty(sEvts) then STOP
else

if empty(cEvts) then S
else

if empty(sEvts) then C
else CS

We use the revivals’ reﬁnement relation to check conformance of a com-
ponent’s behaviour to the process ServerRequestsSpec. The reason is that
the speciﬁcation that “either all server-requests are oﬀered or none of them is”
cannot be intuitively represented by a characteristic process in the stable fail-
ures model. Note that, intuitively, such a characteristic process would require
failures that are not preﬁx closed. On the other hand, this process can be sim-
ply captured, in the stable revivals model, by the aforementioned characteristic
process. The other speciﬁcation does not suﬀer from this problem and can be
simply captured in the stable failures model.

Deﬁnition 19. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and M
a client/server pattern descriptor for V . V and M are behaviourally compliant
if and only if the following predicates hold.

• ∀ i : {1 . . . n} • ServerRequestsSpec(i) [V= Abs(i)

• ∀ i : {1 . . . n} • RequestResponsesSpec(i) [F= Abs(i)

As with the previous pattern, we beneﬁt from the order imposed on the
client-server relation to show that a cycle of ungranted requests cannot arise
and, as a result, a network compliant to this pattern is deadlock free.

Theorem 5. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and M
a client/server pattern descriptor for V , and >CS a strict order on component
identiﬁers. If V and M are structural and behaviourally compliant then V is
deadlock free.

Proof. We prove this theorem by showing that the network V (cid:48) = (cid:104)C (cid:48)
where C (cid:48)

i = (Ai, Abs(i)), is deadlock free and by using Lemma 1.

1, . . . , C (cid:48)

n(cid:105),

To prove the former claim, we rely on the second condition of Theorem 1. So,
we show that there cannot be a cycle of ungranted requests between components
of this network. From the validity of mutually disjoint events, we know that
events cannot be used for both requesting and responding.

From the behavioural compliance of the network to the client/server pattern,
we know that a component might be in one of three cases: ready to request as
a client, waiting for a request as a server, and ready to respond.

30

C1

C2

C3

...

Cn

implies 1 >CS n

C2

C1

C3

Cn

...

Cn−1

implies 1 >CS 1
(contradiction)

Figure 7: Chain of ungranted requests and cycle of ungranted requests coinci-
dence with >CS.

In the case a component is responding, due to behavioural compliance, it can
only be willing to communicate with its peer, namely, the component that has
shared a request event with it. In this case, both must be willing to engage in a
shared event. The component behaving as server has to oﬀer at least a response,
whereas the client component must be waiting for any response event. Hence,
in such a state, a component and its peer cannot be part of a cycle of ungranted
requests, as the ungrantedness predicate does not hold for them. So, a cycle
of ungranted requests can only be formed by a combination of client-requesting
and server-waiting-for-request components.

Given two components i and j, there cannot be an ungranted request i →• j
in a state where i is a client-requesting and j a server-waiting. The reason is
that j would be willing to engage on the request oﬀered by i. So, this fact
implies that a cycle of ungranted requests can only exists if all components are
behaving either as a server-waiting or as a client-requesting.

So, let us ﬁrst assume that a cycle involving only client-requesting compo-
nents exists. This means that for each pair of adjacent elements i and j in the
cycle, (i, j) ∈ C and consequently (by ordered) i >CS j must hold. Thus, we
reach a contradiction as >CS is a strict order and, based on the cycle, we can
establish that a reﬂexive pair exists. In the case of all server-waiting compo-
nents, one can use the same argument, but using the order dual to >CS, to
reach a contradiction. Figure 7 illustrates the coincidence of order >CS and
components in a path of ungranted requests, and the contradiction that a cycle
would lead to.

4.3 Async Dynamic

This pattern can be applied to construct networks in which participants interact
via a transport layer. For instance, this pattern seems to be suited for building

31

name-server and address-resolution systems [26, 27]. Participants are elements
that embed the functional behaviour of the network, whereas the transport layer
is a mere communication infrastructure. In such a network, a ﬁxed number of
participants, which are also known in advance, might join and leave the network.
Aside from transporting messages, the transport layer also detects participants
leaving and entering the network. The transport layer is composed of transport
entities. These are components responsible for providing one-direction commu-
nication between two participants and detecting whether its sending participant
is present or not in the network.

An async-dynamic descriptor for a network V , with n components and Σ
as alphabet, is a tuple M = (C, link, send, receive, on, of f, timeout) containing
a set C ⊆ {1 . . . n} × {1 . . . n}, and functions link(i, j), send(i, j), receive(i, j),
on(i, j), of f (i, j), timeout(i, j). A pair (i, j) ∈ C denotes the connection from
i to j. The function link(i, j) yields the transport-entity component that relay
messages from i to j. This function must be deﬁned for all pairs in C; send(i, j)
and receive(i, j) denote the set of events used to pass data from i to j; and
on(i, j), of f (i, j) and timeout(i, j) denote control events that are explained
later. We deﬁne participants (cid:98)= {i | ∃ j : {1 . . . n} • (i, j) ∈ C ∨ (j, i) ∈ C},
transport entities (cid:98)= {link(i, j) | ∃ i, j : {1 . . . n} • (i, j) ∈ C}. We require a
given transport entity to link a unique pair of participants, so we use source(k) =
i and target(k) = j if link(i, j) = k.

Structural compliance is achieved if the network’s components are parti-
tioned into transport entities and participants. In addition to that, we require
the traditional shared events to be the ones controlled by the pattern.

Deﬁnition 20. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and
M an async-dynamic pattern descriptor for V , and S(i) a function that gives
the sequence in which participant i interacts with its peer participants. V and
M are structurally compliant if and only if the following predicates hold.

• partitioned (cid:98)= participants ∩ transport entities = ∅

∧ participants ∪ transport entities = {1 . . . n}

• mutually disjoint events holds if and only if the events used for sending,
receiving, turning on, turning oﬀ and timing out are all mutually disjoint.
For any two sets X and Y , representing all the events used for two of these
activities, X ∩ Y = ∅ must hold;

• controlled alpha participant (cid:98)=
∀ i : participants • Ai ∩ Voc =

(cid:91)

{send(i, j) | (i, j) ∈ C}
(cid:91)

{receive(j, i) | (j, i) ∈ C}

∪

∪ {on(i, j), of f (i, j), timeout(i, j) | (i, j) ∈ C}

32

• controlled alpha transport entity (cid:98)=

∀ link(i, j) : transport entities • Alink(i,j) ∩ Voc =

send(i, j) ∪ receive(i, j) ∪ {on(i, j), of f (i, j)} ∪ {timeout(i, j)}

On the behavioural side, we restrict the behaviours of participants and trans-
port entities in diﬀerent ways. A transport entity is expected to behave as a
one-place buﬀer that can be overwritten with new data, providing one-direction
communication as illustrated in Figure 8. In addition to that, it must be able
to detect whether its sender is present or not in the network. The information
about the presence of a participant is conveyed by the events on and oﬀ.
If
the participant is oﬀ, it means that it is no longer part of the network, it is on
otherwise.

Deﬁnition 21. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and
M an async-dynamic pattern descriptor for V . The expected behaviour of the
transport entity component k is given by the following process.

TransportSpec(k) =

let i = source(k)
j = target(k)
On = off(i,j) -> Off

[] send(i,j)?data -> OnF(data)

OnF(d) = off(i,j) -> Off

[] send(i,j)?data -> OnF(data)
[] receive(i,j)!d -> On

Off = on(i,j) -> On

[] timeout(i,j) -> Off

within Off

As mentioned, participants are the elements of the network carrying its
business logic. For the purpose of deadlock analysis, we are only interested
in the pattern of interaction of the participants, rather than in the business
logic that they carry out. So, a participant should cyclically interact with its
peer participants, ﬁrst sending a message for each of its peer and then receiving
messages from all of them. It might receive a timeout instead of some data, if
a peer participant has left the network. At any time, a participant should be
able to turn oﬀ, namely, leave the network. After leaving, the participant might
re-join the network.

Deﬁnition 22. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and
M an async-dynamic pattern descriptor for V , and S(i) a function that gives

Sender participant

send

Transport entity

receive

Receiver participant

Figure 8: Illustration of the communication role performed by a transport entity.

33

an order in which participant i interact with its peer participants. The expected
behaviour of participant i is given by the following process.

ParticipantSpec(i) =
let s = S(i)

SendReceive(i,s) =

Send(i,s); Receive(i,s); SendReceive(i,s)

within OnDetect(i,s);(SendReceive(i,s) /\ (SKIP |~| STOP));

OffDetect(i,s); ParticipantSpec(i,s)

The OnDetect (OffDetect) process sends a signal to inform that it is on
(oﬀ) to each of the transport entity to which it acts as a sender; this mechanism
abstracts the ability of the transport layer to detect participant status. In the
same way, The s parameter gives the sequence in which the participant interacts
with its transport entities. The Send process sends messages to all transport
entities that have this participant as sender, following the order of sequence
s. The Receive process interacts with the transport entities that have it as
a receiver, also following how participants are ordered in s. This receiving
interaction consists of either accepting incoming data or a timeout, in the case
that the sender associated with the transport entity in question is oﬀ.

Note that we use the process (SKIP |~| STOP) on the right-hand side of the
interruption operator instead of, for instance, SKIP. The reason is that the latter
construction would trivially imply deadlock freedom as a participant would be
always able to turn oﬀ. On the other hand, the internal-choice construction
implies that the process might not have the ability of turning oﬀ (if STOP is
chosen), and as a consequence, one can guarantee that deadlock freedom is
achieved because they are well behaved processes rather than because they can
always turn oﬀ.

For a network and an async-dynamic descriptor to be behaviour compliant,
participant and transport entities must meet their respective speciﬁcations. In
addition to that, the sequence in which participants interact with its peers, given
by S(i), must not have the same component twice.

Deﬁnition 23. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and
M an async-dynamic pattern descriptor for V , and S(i) a function that gives
the sequence in which participant i interact with its peer participants. V and
M are behaviourally compliant if and only if the following conditions hold.

• ∀ i : transport entities • TransportSpec [F= Abs(i)

• ∀ i : participants • ParticipantSpec [F= Abs(i)

• ∀ i : participants • ∀ j, k : {1 . . . |S(i)|} | j (cid:54)= k • S(i)j (cid:54)= S(i)k

Finally, given the introduced pattern, we present the main theorem of this

section. It shows that compliance to the pattern implies deadlock freedom.

Theorem 6. Let V = (cid:104)C1, . . . , Cn(cid:105) be a network where Ci = (Ai, Pi), and M
an async-dynamic pattern descriptor for V , and S(i) a function that gives the

34

sequence in which participant i interact with its peer participants. If V and M
are behavioural and structurally compliant to the async-dynamic pattern, then
V is deadlock free.

Proof. From the analysis of structural restrictions, a process must be either a
transport entity or a participant. This fact together with triple disjointness
and the controlled-alphabet restriction imply that there can only be ungranted
requests between a transport entity and a participant. To be more speciﬁc,
there can only be an ungranted request between a participant and one of its
sender or receiver transport entities, for a participant only shares events with
these transport entities.

Next, we show that there cannot be a cycle of ungranted requests in a state

where all transport entities have not an on event as their last event.

First, we examine the behaviour of a participant i when interacting with its
transport entity k. We analyse two cases: when i is a sender to k and when i is
a receiver from k. When i is a sender, no ungranted requests can from i to k.
Whenever i is willing to communicate with k, k is accepting a communication
from i, be it a send, on or off event. When i is a receiver, however, an ungranted
request arises from i to k if k is on and empty.

In order to be on and empty, a transport entity k, linking i to j, must have
just turned on (i.e., on(i, j) was its last event performed), or it must have been
ﬁlled and then emptied (i.e., receive(i, j) was its last event performed). In the
ﬁrst case, the participant j has to be turning on or broadcasting data. In both
cases, j has to be in a state in which it can eﬀectively communicate a send or
an on event to a transport entity that has j as a sender. Therefore, the network
V (cid:48) cannot be blocked. So, we only have to establish that a cycle involving
participants willing to receive messages and ﬁlled-and-then-emptied transport
entities cannot arise.

Let us assume that such a cycle of participants willing to receive messages
and ﬁlled-and-then-emptied transport entities exist. We analyse the behaviour
of a transport entity k, which links i to j, and of participants j and i.

In such a cycle, k must have receive(i, j) as its last performed event, and
based on the behaviour of a transport entity, it must have performed a send(i, j)
immediately before receive(i, j). So, it has to have executed a trace like:

(cid:104). . . , send(i, j), receive(i, j)(cid:105)

Participant j must be willing to receive some data from k. So, it has to be
oﬀering the event receive(i, j). As j synchronises with k in receive(i, j), the last
occurrence of this event for j and k must have happened at the same time. Note
that, as receive(i, j) is being oﬀered by j, j must have broadcast between the
last occurrence of receive(i, j) and its current state. So, j must have performed
its last broadcast after the last occurrence of receive(i, j).

Participant i, as j, must be willing to receive some data from a transport
entity. So, it must be in its receiving phase, and that means that its last
broadcast has been completed. As i synchronises with k in send(i, j), the last
occurrence of this event for i and k must have happened at the same time.

35

P1

T E1

P2

T E2

...

Pn

implies 1 >AD n

T E1

P1

P2

T En

...

Pn

implies 1 >AD 1
(contradiction)

Figure 9: Chain of ungranted requests and cycle of ungranted requests coinci-
dence with >AD.

Thus, considering the behaviour of these components together, we know
that j’s last broadcast must have started more recently than the start of i’s
last broadcast. j’s last broadcast must have started after the last receive(i, j)
occurred.
i’s last broadcast must have started before the last occurrence of
receive(i, j), as the last occurrence of send(i, j), which is part of i’s last broad-
cast, happened before receive(i, j).

Hence, in such a cycle, we have the following strict order being induced
between participants. If j, k and i are a path in this cycle then j must have
had its last broadcast more recently than i’s last one. Let us call this order
>AD. This strict order implies that a cycle cannot happen as this would lead to
a contradiction: one could deduce that a participant’s last broadcast happened
more recently than its last broadcast. Thus, this network is sdeadlock free. In
Figure 9, we illustrate the coinciding of these paths of ungranted requests and
the order >AD, and the contradiction that a cycle of ungranted request would
lead to.

Note that the patterns presented impose restrictions that can be eﬃciently
checked. These are either restrictions that can be statically checked, or be-
havioural restrictions that can be checked by the examination of individual or
pairs of processes. So, in the case of proving deadlock freedom for large systems,
pattern adherence is an eﬃcient choice and it might, in fact, be the only viable
option. For example, in Section 5.3, we present a leadership-election system,
modelled after a commercial protocol, for which monolithic analysis and even
compression techniques are not viable options for checking deadlock freedom.

36

5 A systematic and scalable method for ensur-

ing deadlock freedom

In this section, we propose a systematic approach that combines network decom-
position and the application of our behavioural patterns to construct and verify
some deadlock-free systems. In addition to the method itself, we propose the
DFA (Deadlock-Freedom Analysis) tool to support our method’s application.
It is a plugin to the well-known Eclipse IDE, oﬀering an Eclipse-like look-and-
feel. It fully automates most of the application steps of our method. The only
step that is not fully automated is checking pattern adherence. It involves the
user selecting a pattern and providing the information needed to construct its
descriptor. In Subsection 5.1 we give an overview of the DFA tool. The de-
composition and patten adherence method is presented in Section 5.2, and its
application, using the tool, in Subsection 5.3 (the decomposition strategy) and
in Subsection 5.4 (pattern adherence). Finally, Subsection 5.5 is dedicated to
the evaluation of our method, comparing the eﬃciency of the deadlock analysis
of the systems developed using our approach with three other approaches.

5.1 Deadlock Freedom Analysis tool overview

Through this section, we use our tool to discuss and illustrate our method
application. We begin by brieﬂy describing DFA’s interface and how it can be
used to model a network, and then we propose our method and explain how
DFA supports its application.

DFA’s graphical interface is divided into four areas as depicted in Figure 10.
We number the areas in this ﬁgure to facilitate referencing them. Area 1 pro-
vides the projects or networks that have been created in a given workspace. In
this example, we created the networks RingBuﬀer and DiningPhilosophers. To
create a project, we provide a project creation wizard in Eclipse’s New menu.
Area 2 provides a view of the communication graph of the network under anal-
ysis. In this case, we selected the RingBuﬀer project.

Area 3 provides three panels that enables one to have an overview of the
elements that have been created to construct the network, such as components,
channels, etc. Area 4 has several panels that give details of the elements that
have been created, and allows the user to edit them. For instance, for a selected
component, it shows its alphabet, behaviour and name. In the following, we
present in more detail Areas 3 and 4, their panels and the features that they
oﬀer.

Area 3 oﬀers three diﬀerent panels: the description-list panel, the network-
list panel and the essential-components-list panel. The description-list panel
lists the elements that have been declared and are, as a consequence, available
for the construction of the network. These elements are: atom, channel, variable,
and datatype declarations. Also, in the top part of it, it has four buttons that
allows the user to create new elements. An atom (or component schema) is a
parametrised component, i.e. its alphabet and behaviour are parametrised. So,

37

Figure 10: DFA’s interface.

it becomes a component once the parameters are deﬁned. A channel declaration
is a declaration of a set of events, and the last two elements are self-explanatory.
The network-list panel provides instantiations of atoms that deﬁne the network.
The purpose of having these two separate notions for an atom and its instanti-
ation (a component) is to facilitate the creation of networks composed of many
similar components. We discuss the essential-components-list panel later.

For instance, Figure 11 depicts the declarations and instantiations used to
create our RingBuﬀer network. We can see that this network is composed of
a single controller atom that has been instantiated with the value 0 and three
ring cell atoms that have been instantiated with values 0, 1 and 2. Thus, we
use a set notation to denote the parameter values (and number of components)
that are to be instantiated for each atom.

Area 4 oﬀers 6 panels: atom-info, channel-info, datatype-info, variable-info,
network-element-info and essential-component-info panels. Upon selection of
an atom in the descriptions-list panel, the atom-info panel presents its details.
It shows its name, parametrised behaviour and parametrised alphabet. Atoms
are parametrised by the implicit variable id. This variable is what needs to be
instantiated to turn an atom into a component. At the bottom of the panel, the
update button allows the user to edit the details of an atom. Panels channel-
info, datatype-info, and variable-info provide similar informative and editing
functionalities for the other declared elements. For instance, in Figure 12, we

38

Figure 11: Descriptions-list and network-elements-list panels, respectively.

illustrate the declaration of the RingCell component schema for the RingBuﬀer
network. Note the behaviour and alphabet are described using CSPM and have
the implicit variable id. Upon selection of a network element in the network-
list panel, the network-element-info provides the user with detailed information
about this element and an update functionality, just like for the atom-info panel.
We discuss the essential-component-info panel later.

5.2 The Decomposition and Pattern Adherence method

After presenting how our tool can be used to model a network, we move on
to propose and discuss our veriﬁcation method. The DPA (Decomposition and
Pattern Adherence) method essentially relies on two main phases: ﬁrstly, it de-
composes the network, then it proves that the essential subnetworks are deadlock
free. In the following, we detail all smaller steps that are necessary to carry out
both of DPA’s two main phases. We discuss how the steps can be implemented

Figure 12: Atom-info panel.

39

and estimate the complexity of this method.

The steps of the DPA method are as follows.

1. Decompose network (identify essential subnetworks):

(a) Construct communication graph;

(b) Identify disconnecting edges (bridges) in this undirected graph;

(c) Remove conﬂict-free disconnecting edges; and

(d) Identify resulting essential subnetworks.

2. Show pattern adherence for essential subnetworks with more than one

component:

(a) Describe pattern descriptor for each of these subnetworks; and

(b) Check pattern adherence.

5.2.1 Method application: decomposition strategy

The ﬁrst part of our method attempts to decompose the network under analysis.
As our decomposition strategy is based on the network’s topology, in Step 1(a),
it constructs the network’s communication graph. The creation of the com-
munication graph can be carried out in time O(n2|A|) where n is the number
of components in the network and |A| over-approximates the size of individual
component alphabets (say, it is the size of the largest alphabet). This approxi-
mates the time taken to create the edges of the graph. There are O(n2) potential
edges (pairs of components) in this graph and, for each pair of component, we
can check whether their alphabets intersect, thereby giving rise to an edge in
the communication graph, in O(|A|) steps.

In the next step, our decomposition strategy identiﬁes disconnecting edges.
There is a linear time algorithm – taking time O(|V | + |E|) where |V | and |E|
are the sizes of the sets of nodes and edges, respectively, of the input graph –
that identiﬁes all the bridges of an undirected graph [28]. This algorithm can
be readily applied to ﬁnd disconnecting edges in a communication graph. So, it
takes time O(n2) to ﬁnd all disconnecting edges in such a graph, given that the
communication graph has O(n) nodes and O(n2) edges.

Step 1(c) involves ﬁnding which disconnecting edges are conﬂict free and
removing them. So, for each pair of components corresponding to a discon-
necting edge, we test them for conﬂict freedom using the reﬁnement assertion
in Deﬁnition 2. A graph with |V | nodes has at most |V | − 1 bridges. So, our
communication graph has O(n) bridges to be tested. For the purposes of esti-
mating DPA’s complexity, we assume that components are described by labelled
transition systems instead of CSP processes. This is a reasonable assumption
since CSP has an operational semantics that enables this translation and most
checkers internally represent components and systems in this way. We assume
that |B| is number of states/nodes for the largest component (i.e., transition
system) of the input network. Reﬁnement checkers work by examining the

40

product space of speciﬁcation and implementation. Our speciﬁcations, used to
constrain the behaviour of network components, are small and simple processes,
which should be simply normalised. So, in our complexity analysis, we factor
speciﬁcations out and use the size of the implementation’s state space as an
estimate for the work required to check some reﬁnement expression. Thus, if
the implementation is a network with n components, its has O(|B|n) states and
the reﬁnement checking has to examine this many states. Note the state-space
explosion is represented by the exponent n in this bound. Our conﬂict-freedom
reﬁnement expression, however, analyses only a pair of components (placed in
the Context process) at a time. So, checking each of our conﬂict-freedom re-
ﬁnement expressions takes O(|B|2) steps1. Moreover, given that there are O(n)
bridges, Step 1(c) can be carried out in O(n|B|2) steps.

The last step of our decomposition strategy consists of calculating the re-
sulting essential subnetworks. This step consists of ﬁnding the graph-theoretic
connected components of the graph resulting from the removal of conﬂict-free
disconnecting edges. These connected components can be found in linear time in
the size of the input communication graph using depth-ﬁrst search. Therefore,
similarly to Step 1(b), this step can be carried out in time O(n2).

We use our RingBuﬀer network in Example 1 to illustrate the proposed
decomposition strategy.
In Step 1(a), our strategy constructs this system’s
acyclic communication graph depicted in Area 2 of Figure 10; it has a controller
and three memory cells. Given its acyclic topology, Step 1(b) ﬁnds that all
its edges are disconnecting. Step 1(c) analyses each of these edges using our
conﬂict-freedom assertion to ﬁnd out that all of them are conﬂict free. So,
they are all removed leading to the communication graph depicted in Figure 13.
Finally, Step 1(d) ﬁnds that each individual component is a singular essential
subnetwork, i.e., an essential subnetwork with a single component.

This strategy could be manually carried out.

It would, however, involve
many tedious and error-prone tasks such as manually constructing and analysing
a graph and manually crafting our conﬂict-freedom reﬁnement assertions. In-
stead, it is much more productive to carry it out in a fully automatic way by
using our tool, via the Decompose option in DFA’s menu depicted in Figure 13.
It fully automates the strategy’s steps using the algorithms we discuss and the
FDR2 tool [29], in background, to check the conﬂict-freedom reﬁnement expres-
sions.

We make a few relevant remarks about our decomposition strategy. Firstly,
this strategy alone can prove conﬂict-free acyclic systems deadlock free. If after
decomposition all essential subnetworks are singular then the network under
analysis must be deadlock free. This is exactly the case for our RingBuﬀer
example. The buﬀer in this example has only three cells but our strategy
can, in fact, show deadlock freedom for similar buﬀers with any ﬁxed num-
ber of cells. Thirdly, based on the analysis of its complexity, this decomposition
strategy seems much less computationally costly than carrying our deadlock-

1In fact, we should say that the state space of the Context process, which is the actual

implementation, is proportional to |B|2.

41

Figure 13: DFA’s menu and RingBuﬀer’s decomposed communication graph.

freedom checking for the entire network. While traditional exact deadlock-
freedom checking explores the network’s entire state space (taking O(|B|n)
steps), our strategy can be carried out in polynomial time, taking O(n2|A||B|2)
steps. Therefore, it is much more scalable in proving deadlock freedom for
conﬂict-free acyclic systems when compared to traditional exact methods.

5.2.2 Method application: pattern adherence

The second part of DPA consists of proving that the essential subnetworks found
by our decomposition strategy are deadlock free. As singular essential subnet-
works are deadlock free by our busyness requirement, this second part is only
really concerned with showing deadlock freedom for non-singular essential sub-
networks and we do so via pattern adherence. Our method requires showing
that each of these non-singular essential subnetworks adhere to one of our pat-
terns. So, for each of these networks, the user of our method has to choose which
pattern it adheres to and provide the appropriate pattern descriptor. Given a
pattern descriptor, one can simply test adherence by validating the structural
and behavioural constraints. The behavioural constraints can be validated us-
ing the reﬁnement expressions we propose, whereas structural restrictions can
be tackled by simple iterative algorithms. In the following, we discuss and il-
lustrate this part of our method and the tool support we provide using the
DiningPhilosopher network in Example 2 and the resource-allocation pattern.
Given its ring-like topology, as depicted in Figure 14, the DiningPhisolophers
network has no disconnecting edges. So, the application of the decomposition
strategy to it results in the original network being the single essential subnetwork
found. In our tool, the decomposition strategy updates the essential-components
panel (located in Area 3 of Figure 10) to show the non-singular essential sub-
networks found. In our example, Figure 14 shows that DFA ﬁnds this single
essential subnetwork and names it EC0.

By our method’s deﬁnition, we are then left with proving this essential sub-
network, i.e., the entire original network, adheres to some pattern; we show it
adheres to the resource-allocation pattern. Firstly, we identify the resource allo-
cation descriptor for this network. Instead of describing the descriptor in terms
of the structure C as per Section 4, we directly describe sets users and resources,
and functions users, resources, acquire and release. Also, we represent our >RA

42

Figure 14: DiningPhilosophers’ communication graph and essential-components
panel.

order by a sequence of resources (cid:104)r1, . . . , rn(cid:105), where ri >RA rj if and only if
i > j. This alternative description is the one used by our tool. We believe that,
although less concise, this alternative description is more user-friendly and more
suited to users that are not formal methods enthusiasts.

Deﬁnition 24. Resource allocation descriptor for DiningPhilosophers. We use
Phil.i to identify a philosopher component, Fork.i a fork one, and N = 3
respresents the number of philosophers/forks in the network.

• User = {Phil.i | i <- {0..N-1}}

• Resources = {Fork.i | i <- {0..N-1}}

• users(id) = {Phil.id,Phil.((id-1)%N)}

• resources(id) = if id == N-1 then <Fork.0,Fork.id>

else <Fork.id,Fork.((id+1)%N)>

• acquire(idU, idR) = pickup.idU.idR

• release(idU, idR) = putdown.idU.idR

• >RA= <Fork.i | i <- <0..N>>

We can test whether the provided descriptor satisﬁes the pattern’s struc-
tural restrictions using simple iterative algorithms. For instance, the condition
partitioned can be checked in time O(n) by a simple algorithm that carries out
the required operations and comparisons on the two sets: users and resources.
Similarly, we can check controlled alpha users in time O(n2|A|2) since Voc’s
size is bound by O(n|A|); we can iterate over Voc at most |A| times to ﬁnd the
intersection set Voc ∩ A, and there are n such calculations to be carried out.

43

This descriptor also gives the information that we need to craft the appro-
priate reﬁnement expressions to test whether the behavioural constraints the
pattern enforces are met. In the case of our DiningPhilosopher network, it leads
to N assertions for philosophers and N for forks. Since each assertion checks a
component individually they can be carried in time O(|B|), and checking all of
them takes time O(n|B|).

Figure 15: Essential-component-info panel for ECO subnetwork.

Our tool supports this step as follows. By selecting an essential subnetwork
in the essential-components panel, the essential-component-info panel (located
in Area 4 of Figure 10) is updated to show the components in this essential
subnetwork. For instance, Figure 15 presents the information for our example’s
EC0 subnetwork. This panel also allows the user to apply the resource allocation
by clicking on the “Apply resource allocation” button. Then, the user has to
input the pattern descriptor via a dialog box as depicted in Figure 16. The
boxes should be ﬁlled as per Deﬁnition 242. At the moment, our prototype only
supports the application of the resource allocation pattern. Other patterns can
be similarly implemented using the same core idea. Given this descriptor, our
tool can show that this subnetwork adheres to the resource allocation pattern,
and so the network is deadlock free. This network has only 3 philosophers and
forks but our method can, similarly, tackle this example for any ﬁxed number
of philosophers and forks.

We point out that in terms of eﬃciency, pattern adherence checking should
be substantially faster than monolithically checking deadlock freedom for the
corresponding network. For the cases when the state space of a system in-
creases exponentially with the number of components, our approach will very
much outperform monolithic approaches. While monolithic deadlock checking
has to explore an exponentially large state space in general, pattern-adherence
veriﬁcation only examines one component at a time, for behavioural conditions,
and the structural conditions can be polynomially checked in the size of the
structure of the process (i.e., size of alphabets and number of nodes), which
tends to be much smaller than the behavioural part. On the other hand, there
are concurrent systems for which state space only grows polynomially. They
are not common but they exist. So, in general, as the state-explosion prob-

2Our tool requires the two sets users and resources to be written without the variable N so
intervals are 0..2 instead of 0..N-1. Also, we adopt the convention that <RA is the natural
order on Fork’s identiﬁers.

44

lem aﬀects most (interesting, worth-verifying) concurrent systems, our approach
should normally outperform monolithic ones.

5.3 Method evaluation

In this section, we empirically evaluate our method. Our evaluation only takes
into account the veriﬁcation of behavioural constraints. So, the veriﬁcation
times that we present for DPA disregard the examination of structural restric-
tions. Checking the behavioural aspect of our method should be much more
demanding than checking its structural counterpart, given the static nature of a
network’s structure and the simplicity of structural conditions. Thus, the time
to verify our method’s behavioural conditions should approximate the time that
would take checking structural restrictions.

We compare DPA against three other approaches that can prove deadlock
freedom: the SDD framework implemented in the Deadlock Checker tool [30],
FDR2’s built-in deadlock-freedom assertion (FDR2) and its combination with
compression techniques (FDR2c)3. SDD is an incomplete framework that works
by constructing the system’s dependency digraph and checking it for cycles. A
live system/network that does not exhibit such a cycle must be deadlock free [7].
FDR2 and FDR2c are complete methods that explicitly explore the system’s
state space. While FDR2 simply explore this space, FDR2c relies on some user-
provided hierarchical compression strategy to attempt to reduce the size of the
system’s original state space. We point out that while incomplete methods can
only show deadlock freedom for some deadlock-free systems, complete ones do
so for them all. This incompleteness is the price paid to achieve eﬃciency.

We use our two running examples in this comparison, i.e., the ring buﬀer and
the asymmetric dining philosophers examples, and we also check the transport
layer of the leadership-election system presented in [11]. This last example

3FDR is currently in its fourth version (FDR4). Version 3 was a complete rewrite of FDR2
which largely improved it. This version (and subsequent ones), however, does not implement
the stable-revivals model, which is an essential part of our method’s conﬂict-freedom analysis.

Figure 16: Resource-allocation descriptor dialog box.

45

Ring buﬀer

Dining philosophers

Leadership Election

n
3
5
10
20
30
5
10
50
100
200
3
5
10
20
30

DPA
0.01
0.32
1.54
11.65
53.43
0.03
0.11
3.82
28.02
214.13
0.30
0.89
7.76
71.54
383.30

SDD
0.25
0.28
1.83
48.28
-
0.18
0.18
0.18
0.23
0.38
-
-
-
-
-

FDR2
0.03
0.27
371.94
-
-
0.06
448.41
-
-
-
2039.40
-
-
-
-

FDR2c
0.06
0.03
0.11
0.42
0.92
0.03
0.06
0.82
7.28
-
+
+
+
+
+

Table 5: Results of evaluation. n is a parameter used to conﬁgure the size of
the systems tested. We measure in seconds the time taken to check deadlock
freedom for each system. - means that the method could not prove deadlock
freedom for the system: either the (incomplete) method is unable to prove so, or
it took longer than 1 hour, or an error, such as running out of memory, occurred.
+ means that no eﬃcient compression technique could be found.

models a protocol used by B&O’s4 Audio and Video (AV) systems to elect a
In this system,
leader that coordinates the interaction between components.
nodes exchange messages containing their priority value, which represents their
eagerness to become the leader, so they coordinate and agree on which node
becomes the leader. The transport layer is composed of the nodes themselves
and bus cells implementing the asynchronous means of communication through
which they exchange messages. This pattern adheres to the async-dynamic
pattern where nodes are participants and bus cells are transport entities. A
detailed description of this system and its adherence to this pattern can be
found in the aforementioned work. Our evaluation was conducted on a dedicated
machine with Intel i7-7500U CPU @ 2.70GHz, 16GB of RAM, and running
Fedora 25, and the scripts used can be found in [31].

The results of our evaluation are presented in Table 5. For DPA, we show
the results of showing conﬂict freedom for the disconnecting edges of examples
RB, behavioural adherence of examples DP to the resource allocation pattern,
and behaviour adherence of examples LE to the async-dynamic pattern.

Unsurprisingly, these results suggest that incomplete methods are fairly scal-
able; both DPA and SDD can handle these examples quite eﬃciently, albeit SDD
cannot tackle the leadership-election examples we analyse. FDR2’s built-in as-
sertion quickly becomes unable to handle systems with the growth of n. This

4http://www.bang-olufsen.com/

46

Its combination with
demonstrates the state-explosion problem in practice.
compression techniques, however, is fairly eﬀective in handling the ring buﬀer
and dining philosophers examples. We point out that the user has to ﬁnd a good
compression strategy to make this approach eﬀective and ﬁnd such a strategy is
not usually a simple task. For instance, for the leadership-election system, we
were unable to ﬁnd a good compression strategy. These results also suggest that
our method can tackle systems that cannot be handled by traditional incom-
plete methods such as SDD and that the sort of local analysis that our method
employs might be the only alternative in handling complex systems such as the
ones modelled in the leadership-election examples.

We reinforce that unlike the other approaches, DPA provides not only a
method to check that a system is deadlock free but a guideline to construct
deadlock-free systems. In fact, our formal analysis of B&O’s protocol identiﬁed
several issues that were addressed by modiﬁcations to the real C++ implemen-
tation, which were guided by our async-dynamic pattern. This attests the real
and practical impact that our method can make.

5.4 Final considerations

The main driving force behind our method’s eﬃciency is local analysis. Instead
of explicitly examining the global behaviour of the system as traditional ap-
proaches do, we only analyse small parts of the network at a time. Our method
analyses the behaviour of pairs of components when we analyse disconnecting
edges for conﬂict freedom and of individual components when checking for pat-
tern adherence. Our method can be seen as a systematisation of local reasoning
to ensure deadlock freedom. As we show later, for some complex networks, lo-
cal reasoning might be the only practical alternative for guaranteeing deadlock
freedom.

Our work was inspired by [5] and [7]. They proposed the ideas behind decom-
position and pattern adherence, and we reﬁned, combined and extended them
into a practical framework. The soundness of our method follows straightfor-
wardly from Theorems 3, 2, 4, 5 and 6. Our method can show deadlock freedom
for acyclic systems that are conﬂict free and for cyclic systems for which essential
subnetworks adhere to one of our pattern. Unlike traditional techniques that
propose a posteriori veriﬁcation, our method proposes an approach that can
be used as a guide to design deadlock-free systems. One can create a deadlock
free acyclic network by composing components in a way that they are conﬂict
free; conﬂict free captures the natural idea that for an eﬀective communication
protocols must be conjugate/symmetric, if a component requests some action
its communication partner must provide it. Also, one can design cyclic networks
by ensuring that they conform to one of our patterns. Note that this perspective
also leads to a way to combine diﬀerent patterns into a single complex system.
If we have (sub)networks that adhere to diﬀerent patterns, we can link them
with conﬂict-free disconnecting edges and the resulting network is also deadlock
free. So, our method also allows for this sort of combination of patterns.

47

6 Related Work

In this section, we discuss some alternative incomplete approaches to ensure
deadlock freedom. Broadly speaking, we can split such approaches into non-
constructive and constructive ones. Constructive approaches explicitly provide
guidelines on how to construct deadlock-free networks, whereas non-constructive
approaches do not. So, while non-constructive approaches normally propose
some a posteriori veriﬁcation technique, constructive ones provide some sys-
tematic technique to avoid deadlocks. We begin by analysing constructive ap-
proaches, and then discuss non-constructive ones.

6.1 Constructive approaches

Roscoe and Brookes developed a theory, which is used in this work, for analysing
deadlock freedom for networks of CSP processes [6]. They identiﬁed a cycle of
ungranted requests as a necessary condition for a deadlock. Roscoe and Dathi
contributed by developing a (local) proof method for deadlock freedom [5]. They
have built a method to prove deadlock freedom based on variants, similar to the
ones used to prove loop termination.
In their work, they also analyse some
patterns that arise in deadlock free systems. They use the proposed proof rule
to establish deadlock freedom for some classes of networks.

Following these initial works, Martin deﬁned and formalised some design
rules to guarantee deadlock freedom by avoiding cycles of ungranted requests [7].
These design rules are similar to our patterns in the sense that they describe
some constraints to be followed while designing a network so as to avoid dead-
locks. Nevertheless, they describe behavioural constraints as semantic proper-
ties that processes in the network must have, and no automatic way of checking
design rule adherence is suggested.

In [32], the authors propose an encoding of the network model and of a
proof rule from [5] in a theorem prover. Even though this encoding provides
mechanical support for deadlock analysis and allows one to reason locally, it
does not resolve the problems that motivated this work, which is to insulate
the user as much as possible from the details of the formalisation. For instance,
in order to carry out the proof using this approach one has to understand the
stable-failures semantic model, has to directly interact with the theorem prover,
and has to provide some mathematical structures that are not evident, such as
a partial order that breaks possible cycles of ungranted requests. On the other
hand, our work could beneﬁt from this encoding to mechanise the formalisation
of our patterns using a theorem prover.

In [33], a method that proves deadlock freedom for message-passing component-

based systems is proposed. This method only deals with live networks that
respect some topological restrictions.
It presents a necessary condition for a
deadlock based on the analysis of wait-for dependencies for pairs of compo-
nents. So, this condition can be checked in polynomial time, which also implies
that this method is immune to the state space explosion problem. No auto-
mated strategy, however, is proposed to verify that a given network respects

48

these restrictions.

BRICK [34, 10] is an alternative approach for designing asynchronous deadlock-

free systems. This approach represents systems as contracts and proposes rules
for composition of systems that ensure deadlock freedom. BRICK is systematic
and rely on reﬁnement expressions to discharge the side conditions imposed by
composition rules. A BRICK user can create basic contracts from scratch, and
then design design deadlock-free systems, in a step-by-step fashion, guided by
the proposed rules. This approach, however, is not fully compositional. One
of its composition rules, the ref lexive rule, imposes a restriction on the over-
all behaviour of the resulting composition, rather than on its components, like
the other rules require. As this composition is a parallel combination of com-
ponents, this veriﬁcation can quickly become unfeasible. This issue is rather
signiﬁcant given that cyclic-topology networks can only be created using this
rule. In [13], we adapted our pattern based approach to BRICK to make this
rule compositional. Recently, a tool to support the original BRICK framework
without pattern adherence has been proposed [35].

In [36], the author studies networks that conform to the resource-allocation
pattern. The author acknowledges that to make such a network deadlock-free,
one has to impose a strict order on the way resources are acquired. She goes,
then, into studying how to choose a good ordering of resources in the sense that
it minimises the time users need to wait to acquire resources. She proposes a
few “good” orderings, an algorithm to implement this well-behaved acquisition
of resources, and analysis of a few networks using diﬀerent orderings. The
problem studied in that paper is much narrower than the one we tackle here.
There, to some extent, the author is reﬁning the ordering of resources used in
the resource-allocation pattern (>RA) and ﬁnding orderings and algorithms that
will maximise the work of users, by minimising the time they wait to acquire
resources. So, one could potentially create a reﬁned version of our pattern that
would require component to conform to these “good” orderings instead of a
general ordering.

As for these approaches, our method is also constructive and provide a clear
and systematic guideline on how to design deadlock-free systems. Unlike these
approaches, however, we do provide fully automatic procedures that can be
readily implemented and used to show that a system was constructed respecting
our method. Our method can be seen as a lightweight and synchronous version
of BRICK that is fully local/compositional and automated. We are not aware
of any other approach that automates communication pattern adherence, as we
do in the DPA method and in the DFA tool.

6.2 Non-constructive approaches

In addition to design rules, Martin developed three frameworks (SDD, CSDD,
and FSDD) and a tool with the speciﬁc purpose of deadlock veriﬁcation, the
Deadlock checker [30, 37]. Broadly speaking, this tool reduces the problem of
deadlock checking to the quest of cycles of ungranted requests in live networks.
So, it can verify deadlock freedom for some networks in a very eﬃcient way. In

49

fact, this method constructs a digraph, in polynomial time in the size of the
input system, using local analyses of the network. Furthermore, cycle ﬁnding
can be conducted in polynomial time in the size of this digraph. We point out
that our method and Martin’s have incomparable accuracy: some networks that
can be proved deadlock free by the Deadlock Checker do not obey any of the
patterns, and some networks that obey the Async-dynamic pattern cannot be
proved deadlock free by the Deadlock Checker. For instance, the leadership-
election system we evaluated have cycles of dependencies between participants
and transport entities, rendering SDD, FSDD and CSDD unable to prove it
deadlock free.

Similarly to Martin’s approaches, the techniques in [8, 38, 20] rely on a graph-
like structure that depicts wait-for dependencies between component states.
These works prove deadlock freedom by showing that a necessary condition
for the existence of this graph-like structure is not met by the system under
analysis. While [8] uses this framework to analyse shared-memory concurrent
programs, [38, 20] extend this approach to a more general setting. In the context
of shared-memory concurrent programs, this condition is shown to be checked
by the analysis of pairs of components, while in the setting of [38, 20] it is
unclear the complexity for establishing this condition.

In [39, 40], the authors propose a compositional veriﬁcation strategy to-
gether with a tool, which checks deadlock freedom, based on component and
global invariants; these global invariants, which are called interaction invari-
ants, express global synchronisation requirements between atomic components.
The D-Finder tool iteratively tries to ﬁnd a system invariant, combining com-
ponent and interaction invariants, that can ensure deadlock freedom. Although
powerful, these strategies can suﬀer from combinatorial explosion in calculating
interaction invariants.

In [15, 16, 17, 18], the ﬁrst author has proposed a number of techniques
that ﬁnd sophisticated invariants and use them to prove deadlock freedom. It
uses local analysis to ﬁnd local and global invariants that are combined to over-
approximate the state space of a system. Although these approaches can be hin-
dered by combinatorial explosion, they tend to generally be much more eﬃcient
than complete methods. These frameworks, however, cannot prove deadlock
freedom for some systems that our method can. For instance, our leadership-
election example cannot be proved deadlock free by these techniques; the in-
variants captured by these methods are not strong enough to show deadlock
freedom for this system.

These non-constructive approaches and our method should come close in
terms of scalability. They diﬀer, however, in terms of the methodology em-
ployed. While these approaches try to establish deadlock freedom for a con-
structed system, our method provides a design guideline to help the user build
a deadlock-free network. We point out that while these other approaches are
fully automatic, our method is only semi-automatic in the sense that the user
might be required to provide a pattern descriptor so pattern adherence can be
checked. Nevertheless, one should note that such information should be trivially
known to the user if they use our method, and in particular our patterns, to

50

design the network under analysis.

7 Conclusion

In this work, we propose a method that combines both a decomposition strat-
egy and behavioural-pattern adherence to prove deadlock freedom. This method
can be a very useful design tool as it provides both a systematic guideline to
construct deadlock-free systems and procedures to ensure that the guideline has
been correctly followed. Our use of reﬁnement expressions to impose behavioural
constraints improves previous pattern formalisations in two ways. Firstly, the
reﬁnement expressions give a practical representation of the behavioural re-
strictions imposed by a given pattern. That means that, instead of describing
semantic properties of the process, we have a CSP process describing what is
expected from the behaviour of a component. Secondly, it allows automatic
checking of these constraints by the use of a reﬁnement checker.

Our method can be seen as a systematisation of local analysis to prove dead-
lock freedom. Local analysis is a core factor in making our method eﬃcient.
Many frameworks using local analysis have been proposed. Some of them pro-
pose a posteriori veriﬁcation and give no indication of how to avoid deadlocks,
whereas others provide guidelines to avoid deadlock but no automatic veriﬁca-
tion to ensure that the guidelines were correctly followed. Our method provides
both a guideline and veriﬁcation procedures to ensure it was properly followed.
Its use in the design of a practical protocol for B&O also demonstrates our
method’s practical relevance and impact. Moreover, we also provide a tool that
support and automates the application of our method. Finally, our evaluation
suggests that, for some examples, our method might be the only practical and
capable option to prove deadlock freedom. So, it can tackle a class of systems
that cannot be handled by available incomplete approaches.

In order to improve this framework, our pattern catalogue could be aug-
mented. Some patterns described in prior works have not been formalised in
our framework yet. To make our framework more general, we plan to add those
patterns to it. Moreover, the tool developed is a proof of concept that, so far,
has only a single pattern available. So, a natural extension would be to add
the two missing patterns to it. Finally, we plan to promote this framework to a
general modelling language level, such as SysML. This involves deﬁning a suit-
able component model for SysML, and adapting the proposed DPA method. It
is also required a front-end tool to translate from SysML to CSP, running FDR
in background, and supporting traceability between the SysML and the CSP
models. This should hide the formal methods part of our method, making it
more accessible for industry partners.

51

References

References

[1] E. G. Coﬀman, M. Elphick, A. Shoshani, System deadlocks, ACM Comput.

Surv. 3 (2) (1971) 67–78.

[2] E. W. Dijkstra, The origin of concurrent programming, Springer-Verlag
New York, Inc., New York, NY, USA, 2002, Ch. Cooperating Sequential
Processes, pp. 65–138.

[3] P. Godefroid, P. Wolper, Using partial orders for the eﬃcient veriﬁcation of
deadlock freedom and safety properties, Formal Methods in System Design
2 (2) (1993) 149–164.

[4] C. Baier, J.-P. Katoen, Principles of Model Checking (Representation and

Mind Series), The MIT Press, 2008.

[5] A. W. Roscoe, N. Dathi, The pursuit of deadlock freedom, Inf. Comput.

75 (3) (1987) 289–327.

[6] S. D. Brookes, A. W. Roscoe, Deadlock analysis in networks of communi-

cating processes, Distributed Computing 4 (1991) 209–230.

[7] J. M. R. Martin, The design and construction of deadlock-free concurrent

systems, Ph.D. thesis, University of Buckingham (1996).

[8] P. C. Attie, H. Chockler, Eﬃciently veriﬁable conditions for deadlock-
freedom of large concurrent programs, in: Veriﬁcation, Model Checking,
and Abstract Interpretation, Springer, 2005, pp. 465–481.

[9] S. Gruner, T. J. Steyn, Deadlock-freeness of hexagonal systolic arrays, Inf.

Process. Lett. 110 (14-15) (2010) 539–543.

[10] R. T. Ramos, Systematic development of trustworthy component-based
systems, Ph.D. thesis, Universidade Federal de Pernambuco (2011).

[11] P. R. G. Antonino, M. V. M. Oliveira, A. C. A. Sampaio, K. E. Kristensen,
J. W. Bryans, Leadership election: an industrial SoS application of com-
positional deadlock veriﬁcation, in: NFM 2014, 2014, pp. 31–45.

[12] P. Antonino, A. Sampaio, J. Woodcock, A reﬁnement based strategy for
local deadlock analysis of networks of csp processes, in: FM 2014, Springer,
2014, pp. 62–77.

[13] M. V. M. Oliveira, P. Antonino, R. Ramos, A. Sampaio, A. Mota, A. W.
Roscoe, Rigorous development of component-based systems using compo-
nent metadata and patterns, Formal Aspects of Computing (2016) 1–68.

[14] M. S. C. Filho, M. V. M. Oliveira, A. Sampaio, A. Cavalcanti, Local livelock
analysis of component-based models, in: ICFEM, 2016, pp. 279–295.

52

[15] P. Antonino, T. Gibson-Robinson, A. Roscoe, Eﬃcient deadlock-freedom
checking using local analysis and SAT solving, in: IFM, no. 9681 in LNCS,
Springer, 2016, pp. 345–360.

[16] P. Antonino, T. Gibson-Robinson, A. Roscoe, Tighter reachability criteria
for deadlock freedom analysis, in: FM, no. 9995 in LNCS, Springer, 2016.

[17] P. Antonino, T. Gibson-Robinson, A. W. Roscoe, The automatic detection
of token structures and invariants using SAT checking, in: TACAS, no.
10206 in LNCS, Springer, 2017, pp. 249–265.

[18] P. Antonino, T. Gibson-Robinson, A. W. Roscoe, Checking static proper-
ties using conservative SAT approximations for reachability, LNCS, 2017.

[19] R. Otoni, A. Cavalcanti, A. Sampaio, Local analysis of determinism for

CSP, in: SBMF 2017, 2017, pp. 107–124.

[20] P. C. Attie, S. Bensalem, M. Bozga, M. Jaber, J. Sifakis, F. A. Zaraket,
Global and local deadlock freedom in BIP, ACM Trans. Softw. Eng.
Methodol. 26 (3) (2018) 9:1–9:48.

[21] T. Gibson-Robinson, P. Armstrong, A. Boulgakov, A. Roscoe, FDR3 —
A Modern Reﬁnement Checker for CSP, in: TACAS, Vol. 8413 of LNCS,
2014, pp. 187–201.

[22] C. A. R. Hoare, Communicating Sequential Processes, Prentice-Hall, 1985.

[23] A. W. Roscoe, The theory and practice of concurrency, Prentice Hall, 1998.

[24] A. Roscoe, Understanding Concurrent Systems, Springer, 2010.

[25] E. W. Dijkstra, Hierarchical ordering of sequential processes, Acta Infor-

matica 1 (2) (1971) 115–138.

[26] D. Plummer, et al., An ethernet address resolution protocol (rfc 826), Net-

work Working Group.

[27] P. Mockapetris, Rfc 1035—domain names—implementation and speciﬁca-

tion, november 1987, URL http://www. ietf. org/rfc/rfc1035. txt.

[28] R. Tarjan, A note on ﬁnding the bridges of a graph, Information Processing

Letters 2 (6) (1974) 160 – 161.

[29] University of Oxford, FDR: User Manual, version 2.94, http://www.cs.

ox.ac.uk/projects/concurrency-tools/ (2012).

[30] J. Martin, Deadlock checker repository, http://wotug.org/parallel/

theory/formal/csp/Deadlock/ (2012).

[31] P. Antonino, A. Sampaio, J. Woodcock, Tool and experiments package,
http://www.cs.ox.ac.uk/people/pedro.antonino/dpapkg.zip (2018).

53

[32] Y. Isobe, M. Roggenbach, S. Gruner, Extending CSP-Prover by deadlock-
in: FOSE 2005,

analysis: Towards the veriﬁcation of systolic arrays,
Japanese Lecture Notes Series 31, Kindai-kagaku-sha, 2005.

[33] C. Lambertz, M. Majster-Cederbaum, Eﬃcient deadlock analysis of
component-based software architectures, Vol. 78, 2013, pp. 2488–2510.

[34] R. Ramos, A. Sampaio, A. Mota, Systematic development of trustworthy

component systems, in: FM, 2009, pp. 140–156.

[35] D. I. de Almeida Pereira, M. V. M. Oliveira, M. S. C. Filho, S. R. D. R.
Silva, BTS: A tool for formal component-based development, in: IFM 2017,
2017, pp. 211–226.

[36] N. A. Lynch, Upper bounds for static resource allocation in a distributed
system, Journal of Computer and System Sciences 23 (2) (1981) 254 – 278.

[37] J. M. R. Martin, P. H. Welch, A Design Strategy for Deadlock-Free Con-
current Systems, Transputer Communications 3 (4) (1997) 215–232.

[38] P. C. Attie, S. Bensalem, M. Bozga, M. Jaber, J. Sifakis, F. A. Zaraket,
An Abstract Framework for Deadlock Prevention in BIP, in: Formal Tech-
niques for Distributed Systems, no. 7892 in Lecture Notes in Computer
Science, Springer Berlin Heidelberg, 2013, pp. 161–177.

[39] S. Bensalem, A. Griesmayer, A. Legay, T.-H. Nguyen, J. Sifakis, R. Yan,
D-ﬁnder 2: Towards eﬃcient correctness of incremental design, in: NASA
Formal Methods, 2011, pp. 453–458.

[40] S. Bensalem, M. Bozga, A. Legay, T. Nguyen, J. Sifakis, R. Yan,
Component-based veriﬁcation using incremental design and invariants,
Software and System Modeling 15 (2) (2016) 427–451.

54

