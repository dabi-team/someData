2
2
0
2

p
e
S
1

]
E
S
.
s
c
[

1
v
7
3
4
0
0
.
9
0
2
2
:
v
i
X
r
a

Agile Eﬀort Estimation: Have We Solved the Problem Yet?
Insights From A Second Replication Study

(GPT2SP Replication Report)

Vali Tawosi, Rebecca Moussa, Federica Sarro
{vali.tawosi, rebecca.moussa.18, f.sarro}@ucl.ac.uk

Fu and Tantithamthavorn [1] have recently proposed GPT2SP, a Transformer-based deep learning
model for SP estimation of user stories.

They empirically evaluated the performance of GPT2SP on a dataset shared by Choetkiertikul
et al. [2] including 16 projects with a total of 23,313 issues. They benchmarked GPT2SP against
two baselines (namely the naive Mean and Median estimators) and the method previously proposed
by Choetkiertikul et al. [2] (which we will refer to as DL2SP from now on) for both within- and
cross-project estimation scenarios, and evaluated the extent to which each components of GPT2SP
contribute towards the accuracy of the SP estimates.

Their results show that GPT2SP outperforms DL2SP with a 6%-47% improvement over MAE

for the within-project scenario and a 3%-46% improvement for the cross-project scenarios.

However, when we attempted to use the GPT2SP source code made available by Fu and Tan-
tithamthavorn [1] to reproduce their experiments, we found a bug in the computation of the Mean
Absolute Error (MAE), which may have inﬂated the GPT2SP’s accuracy reported in their work.
Therefore, we had issued a pull request to ﬁx such a bug, which has been accepted and merged into
their repository at https://github.com/awsm-research/gpt2sp/pull/2.

In this report, we describe the results we achieved by using the ﬁxed version of GPT2SP to
replicate the experiments conducted in the original paper for RQ1 and RQ2. Following the original
study, we analyse the results considering the Medan Absolute Error (MAE) of the estimation
methods over all issues in each project, but we also report the Median Absolute Error (MdAE) and
the Standard accuracy (SA) for completeness.

For completeness, we also report the results of three other approaches used as a benchmark to
assess and compare GPT2SP’s performance, namely DL2SP, Mean, and Median estimators. These
results are taken from our previous replication study of DL2SP [3].

RQ1. Does GPT2SP outperform DL2SP and the baselines for the within-project

scenario?

Table 1 shows the the results we obtained by running GPT2SP, DL2SP, and the Mean and
Median baselines on the dataset used and shared publicly by Choetkiertikul et al. [2] (which is also
the dataset used by Fu and Tantithamthavorn in their study [1]).

These results reveal that, for the within-project scenario, GPT2SP outperforms the median
baseline and DL2SP in only six cases out of 16. Whereas the results of Wicoxon Ranked-Sum test

1

 
 
 
 
 
 
(α = 0.05) on the distribution absolute errors (see Table 2) reveal that the improvement is statis-
tically signiﬁcant in only three cases against median (two with negligible and one with small eﬀect
size), and two cases against DL2SP (both with negligible eﬀect size). If we also consider Bonferroni
correction (by setting α = 0.016 for K = 3 hypothesis) the number of statistically signiﬁcant cases
goes down to two and one for the median baseline and DL2SP, respectively. Compared to the mean
baseline, GPT2SP achieves a lower MAE in 14 cases, whereas it slightly underperforms in one case
(Mule) and performs as good in one case (Usergrid). However, the diﬀerence between the absolute
errors produced by the two methods is statistically signiﬁcant in 12 cases even when considering
Bonferroni correction.

Over all 16 cases and among all four estimation methods, the median baseline achieves the
lowest MAE in 8 (50%) cases, GPT2SP in 5 (31%) cases, and DL2SP in remaining 3 (19%) cases.
Therefore, our replication disproves the results previously obtained by Fu and Tantithamthavorn [1],
that is GPT2SP outperforms DL2SP or the median baseline statistically signiﬁcantly in all cases
for the within project scenario.

RQ2. Does GPT2SP outperform DL2SP and the baselines for the cross-project

scenario?

Similar to Choetkiertikul et al. [2] and Tawosi et al. [3], Fu and Tantithamthavorn also inves-
tigated two cross-project estimation scenarios, namely the within-repository and cross-repository
scenarios.

Table 3a shows the results we achieved for GPT2SP, DL2SP and the mean and median baselines
for the within-repository scenario. The results of the Wilcoxon test on the distribution of the
absolute errors produced by GPT2SP against each of the other methods is provided in the last
column of this table.

We can observe that GPT2SP outperforms DL2SP in only two out of eight cases (with marginal
statistical signiﬁcance and a negligible eﬀect size in only one of the two cases), whereas DL2SP
outperforms GPT2SP in six cases.

GPT2SP outperforms the Median baseline in only two cases out of eight, with statistical sig-
niﬁcance but negligible eﬀect size in both cases. GPT2SP achieves a lower MAE than that of the
Mean baseline in ﬁve cases, a higher one in two, and equal one in the remaining one case out of
eight cases, where the diﬀerence is signiﬁcant for three cases but always with a negligible eﬀect size.
When considering the results of cross-repository scenario in Table 3b, we can observe that
GPT2SP outperforms DL2SP in six cases out of eight with statistically signiﬁcant diﬀerence in
ﬁve of them out of which one show a medium eﬀect size, one a small one, and three a negligible
one. GPT2SP achieves a lower MAE than that obtained by Median in three cases only, among
which one case shows a small eﬀect size and two other cases show a negligible eﬀect size. GPT2SP
outperforms the Mean baseline in seven cases with statistically signiﬁcant diﬀerence in six with a
large eﬀect size in three, medium one in two and small in one.

Overall, considering both cross-project scenarios, GPT2SP performs better than DL2SP in the
cross-repository scenario (the same conclusion achieved by the original study). However, GPT2SP
performs poorly when compared against the na¨ıve Median baseline, that is, it achieves statistically
signiﬁcantly better results in less than a third of the cases in both scenarios combined (i.e., ﬁve out
of 16 cases). Therefore, the replication results does not support the conclusion made in the original
study stating that GPT2SP outperforms the baselines statistically signiﬁcantly.

2

References

[1] M. Fu and C. Tantithamthavorn, “GPT2SP: A transformer-based agile story point estimation

approach,” IEEE Transactions on Software Engineering, 2022.

[2] M. Choetkiertikul, H. K. Dam, T. Tran, T. Pham, A. Ghose, and T. Menzies, “A deep learning

model for estimating story points,” IEEE TSE, vol. 45, no. 7, pp. 637–656, 2019.

[3] V. Tawosi, R. Moussa, and F. Sarro, “Deep learning for agile eﬀort estimation have we solved

the problem yet?” arXiv preprint arXiv:2201.05401, 2022.

3

Table 1: RQ1. Results obtained by GPT2SP, DL2SP, and the two baselines (Mean and Median)
for the Within-Project SP scenario. Best results (among all approaches per project) are highlighted
in bold.

Method MAE MdAE

SA Project

Method MAE MdAE

SA

Project

Mesos

Usergrid

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

Appcelerator Studio GPT2SP

Aptana Studio

Titanium

Bamboo

Clover

Jira Software

DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

1.21
1.12
1.41
1.22

1.19
1.18
1.19
1.15

1.53
1.42
1.91
1.30

3.52
4.14
3.59
3.61

2.35
2.09
3.02
2.04

0.77
0.81
1.22
0.75

3.76
3.39
4.57
3.71

1.57
1.70
2.40
2.31

0.98
0.73
1.78
2.00

1.02
0.80
1.23
1.00

0.71
0.58
1.52
1.00

3.10
2.52
3.46
4.00

1.45
1.34
1.97
2.00

0.69
0.61
1.31
1.00

0.97
0.80
3.06
2.00

0.81
1.09
2.15
2.00

42.56 Duracloud
46.72
33.18
42.30

22.56 Data Management
23.25
22.43
24.97

49.88 Moodle
53.49
37.52
57.41

37.75 Mule
26.74
36.53
36.18

48.78 Mulesoft
54.49
34.29
55.71

Spring XD

54.30
51.78
27.99
55.34

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

32.89 Talend Data Quality GPT2SP
39.41
18.46
33.77

DL2SP
Mean
Median

54.09 Talend ESB
50.08
29.61
32.40

GPT2SP
DL2SP
Mean
Median

0.80
0.82
1.00
0.82

5.39
5.86
8.66
6.19

8.38
7.89
12.63
6.59

2.61
2.59
2.60
2.47

3.70
3.67
3.74
3.66

1.78
1.70
2.05
1.71

3.65
3.61
4.56
3.31

0.86
0.90
1.04
0.92

0.50
0.53
1.14
1.00

2.00
2.22
4.55
3.00

8.53
4.93
12.11
6.00

2.23
1.96
2.22
2.00

2.62
2.26
2.80
3.00

1.54
1.31
2.53
2.00

3.44
2.92
5.08
4.00

0.55
0.59
0.91
1.00

47.97
46.97
35.17
46.78

54.82
50.87
27.35
48.09

45.76
48.92
18.21
57.32

28.55
29.14
28.72
32.29

23.55
24.12
22.65
24.32

37.09
39.96
27.59
39.55

29.41
30.07
11.69
35.85

38.81
36.19
26.47
34.86

4

Table 2: RQ1. Results of the Wilcoxon test (with Vargha-Delaney ˆA12 eﬀect size in parentheses)
comparing the absolute errors of GPT2SP to that of DL2SP and the two baselines (i.e., Mean and
Median).

Project

GPT2SP vs

Mean

Median

DL2SP

0.127 (0.55)
Mesos
<0.001 (0.70)
Usergrid
Appcelerator Studio <0.001 (0.64)
0.713 (0.48)
Aptana Studio
<0.001 (0.70)
Titanium
<0.001 (0.70)
Bamboo
<0.001 (0.76)
Clover
<0.001 (0.62)
Jira Software
<0.001 (0.58)
Duracloud
<0.001 (0.79)
Data Management
0.323 (0.51)
Moodle
0.497 (0.50)
Mule
<0.001 (0.59)
Mulesoft
<0.001 (0.66)
Spring XD
Talend Data Quality <0.001 (0.61)
Talend ESB

0.955 (0.43)
1.000 (0.43)
1.000 (0.37)
0.679 (0.49)
0.583 (0.49)
0.021 (0.59)
0.004 (0.54)
0.988 (0.42)
0.663 (0.49)
1.000 (0.31)
0.678 (0.49)
0.751 (0.48)
0.962 (0.47)
0.977 (0.45)
0.130 (0.53)
<0.001 (0.68) <0.001 (0.65)

0.248 (0.53)
0.999 (0.44)
1.000 (0.43)
0.044 (0.55)
0.516 (0.50)
0.412 (0.51)
0.001 (0.54)
0.478 (0.50)
0.972 (0.46)
1.000 (0.40)
0.294 (0.52)
0.722 (0.48)
0.843 (0.48)
0.433 (0.50)
0.325 (0.51)
0.217 (0.54)

Table 3: RQ2. Comparing GPT2SP cross-project SP estimation replication results to DL2SP [2],
and to the baselines. The results of the Wilcoxon test ( ˆA12 eﬀect size in parentheses) for GPT2SP
vs. DL2SP and baselines are shown in the last column. Best results (among all approaches per
project) are highlighted in bold.

(a) Within-Repository Training

(b) Cross-Repository Training

Target

Method MAE MdAE

SA

GPT2SP vs.

Source

Target

Method MAE MdAE

SA

GPT2SP vs.

Source

MESOS
(ME)

USERGRID
(UG)

USERGRID
(UG)

MESOS
(ME)

TISTUD
(AS)

APSTUD
(AP)

TISTUD
(AS)

TIMOB
(TI)

APSTUD
(AP)

TISTUD
(AS)

APSTUD
(AP)

TIMOB
(TI)

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

MULE
(MU)

MULESTUDIO GPT2SP
(MS)

DL2SP
Mean
Median

MULESTUDIO MULE
(MS)

(MU)

GPT2SP
DL2SP
Mean
Median

1.11
1.16
1.02
0.89

1.52
1.51
1.52
1.50

4.62
4.37
4.27
4.38

3.28
3.38
3.45
3.17

2.86
2.70
3.38
3.17

4.09
3.51
4.36
4.19

3.48
3.64
3.34
3.26

3.03
2.77
3.05
2.60

0.84
0.96
0.19
0.00

0.92
1.01
0.80
1.00

3.37
2.98
2.18
3.00

2.47
2.39
2.82
2.00

2.45
2.07
3.24
3.00

3.52
2.53
4.24
4.00

2.29
2.04
2.71
3.00

2.65
2.47
1.77
3.00

42.49
39.84
46.99
54.10

15.64
16.18
15.57
16.27

7.99
12.99
15.05
12.73

0.049 (0.53)
0.998 (0.45)
1.000 (0.37)

0.662 (0.50)
0.325 (0.50)
0.692 (0.50)

1.000 (0.45)
0.992 (0.47)
1.000 (0.43)

22.60
20.31
0.253 (0.51)
18.69 <0.001 (0.56)
25.24
1.000 (0.44)

45.15
48.25
1.000 (0.47)
35.20 <0.001 (0.58)
39.30 <0.001 (0.55)

30.38
40.34
1.000 (0.39)
25.78 <0.001 (0.56)
0.004 (0.52)
28.67

21.32
17.61
24.42
26.26

30.27
36.28
29.83
40.24

0.206 (0.51)
0.943 (0.48)
0.999 (0.45)

0.985 (0.47)
0.078 (0.52)
1.000 (0.43)

TISTUD
(AS)

USERGRID
(UG)

TISTUD
(AS)

MESOS
(ME)

MDL
(MD)

MDL
(MD)

MDL
(MD)

DM

APSTUD
(AP)

TIMOB
(TI)

TISTUD
(AS)

TIMOB
(TI)

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

GPT2SP
DL2SP
Mean
Median

USERGRID MULESTUDIO GPT2SP
(UG)

(MS)

DL2SP
Mean
Median

MESOS
(ME)

MULE
(MU)

GPT2SP
DL2SP
Mean
Median

5

2.18
3.47
3.08
2.30

2.65
3.18
3.28
2.58

4.37
5.03
9.84
3.97

3.60
3.34
11.19
4.19

2.16
2.64
11.45
3.17

3.58
3.81
5.61
3.46

4.02
3.95
4.04
3.91

3.13
3.20
2.89
2.92

2.03
3.50
2.82
2.00

2.75
3.20
2.82
3.00

3.07
3.77
8.95
3.00

2.53
1.96
11.95
4.00

1.96
1.66
11.95
3.00

2.31
2.65
5.03
1.00

2.16
2.11
2.20
2.00

2.24
2.31
1.81
2.00

37.67

0.98 <0.001 (0.76)
12.02 <0.001 (0.73)
34.40 <0.001 (0.56)

28.83
14.70 <0.001 (0.60)
11.95 <0.001 (0.64)
30.85
0.994 (0.47)

68.12
63.29 <0.001 (0.55)
28.21 <0.001 (0.86)
71.05
0.989 (0.47)

73.90
75.82
1.000 (0.45)
18.91 <0.001 (0.91)
69.63 <0.001 (0.60)

83.92
80.35 <0.001 (0.57)
14.90 <0.001 (0.98)
76.44 <0.001 (0.61)

61.99
59.52 <0.001 (0.53)
40.35 <0.001 (0.75)
63.22
0.999 (0.47)

4.57
6.18
4.00
7.16

9.57
7.37
16.56
15.65

0.865 (0.48)
0.145 (0.52)
0.996 (0.46)

0.347 (0.51)
0.999 (0.46)
0.999 (0.46)

