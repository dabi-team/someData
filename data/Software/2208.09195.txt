2
2
0
2

g
u
A
9
1

]

V
C
.
s
c
[

1
v
5
9
1
9
0
.
8
0
2
2
:
v
i
X
r
a

1

Real-Time Robust Video Object Detection
System Against Physical-World
Adversarial Attacks

Husheng Han,Xing Hu IEEE, Kaidi Xu,Pucheng Dang,Ying Wang, Yongwei Zhao,Zidong Du IEEE,
Qi Guo IEEE, Yanzhi Yang,Tianshi Chen

Abstract—DNN-based video object detection (VOD) powers autonomous driving and video surveillance industries with rising importance
and promising opportunities. However, adversarial patch attack yields huge concern in live vision tasks because of its practicality,
feasibility, and powerful attack effectiveness. This work proposes Themis, a software/hardware system to defend against adversarial
patches for real-time robust video object detection. We observe that adversarial patches exhibit extremely localized superﬁcial feature
importance in a small region with non-robust predictions, and thus propose the adversarial region detection algorithm for adversarial
effect elimination. Themis also proposes a systematic design to efﬁciently support the algorithm by eliminating redundant computations
and memory trafﬁcs. Experimental results show that the proposed methodology can effectively recover the system from the adversarial
attack with negligible hardware overhead.

Index Terms—Deep learning security;Real-time and embedded systems;Adversarial patch attack;Video object detection.

(cid:70)

1 INTRODUCTION

P OWERED by deep neural network (DNN) techniques, video

recognition achieves tremendous success and starts to boost
existing industries, such as autonomous driving, surveillance
systems, drones, and robots. For example, autonomous driving
based on video recognition, whose market is predicted to leap to
$77 billion (25% of the whole automotive market) by 2035 [1], has
attracted the attention of giants including Tesla and Waymo [2],
[3].

Despite the promising opportunities and rising importance
of DNN-powered video recognition, the vulnerability of DNNs
emerges as an important problem to video recognition tasks,
especially in life-critical scenarios. DNN techniques have shown
to be vulnerable to adversarial attacks. For example, wearing the

The preliminary version is published in NeurIPS 2021.

• Husheng Han, Pucheng Dang and Yongwei Zhao are with the SKL of
Processors, Institute of Computing Technology, CAS, Beijing 100190, China,
the University of Chinese Academy of Sciences, Beijing, 100049, China,
and also with Cambricon Technologies, Beijing, China.
E-mail:{hanhusheng20z,dangpucheng20g,zhaoyongwei}@ict.ac.cn
Xing Hu and Qi Guo are with the SKL of Processors, Institute of Computing
Technology, CAS, Beijing, 100190, China.
E-mail:{huxing,guoqi}@ict.ac.cn

•

• Kaidi Xu is with Department of Computer Science, College of Computing

•

•

•

•

& Informatics, Drexel University. Philadelphia, 19104, USA.
E-mail:kx46@drexel.edu
Zidong Du is with the SKL of Processors, Institute of Computing Technology,
CAS, Beijing, 100190, China, and also with Cambricon Technologies,
Beijing, China. E-mail:duzidong@ict.ac.cn
Tianshi Chen is with Cambricon Technologies, Beijing, China.
E-mail:chentianshi@ict.ac.cn
Ying Wang is with SKL of Computer Architecture, Institute of Computing
Technology, CAS, Beijing 100190, China. Email:wangying2009@ict.ac.cn
Yanzhi Yang is with Department of Electrical and Computer Engineering,
Northeastern University, Boston, 02115, USA
Email:yanz.wang@northeastern.edu

(Corresponding author: Xing Hu.)

T-shirt with adversarial patch printing on it, which effectively fools
DNN-based person detectors in physical environments even under
diverse scenarios like people walking, sitting, and running [4],
[5]. Such attacks are malicious in the surveillance and autonomous
vehicle application scenarios, which evade the video detectors in the
physical world and incur life-or-death problems. Therefore, robust
video recognition that defends against such adversarial attacks and
eliminates the adversarial effects is urgent and important.

For live vision scenarios, the defensive methodology should
meet the following two requirements: 1) Effectively recover (more
than detection only) the system from the adversarial attacks
considering video recognition is usually adopted in real-time
decision-making scenarios. 2) The proposed defensive methodology
should introduce lightweight performance overhead to achieve the
goal of real-time object detection. Effectively recovering the VOD
system from adversarial attack in real-time is a highly challenging
task. Existing pioneering studies for robust image classiﬁcation fail
to meet these two requirements: They either detect abnormal inputs
only without recovery [6], [7], [8], [9],

or introduce too much overhead that cannot be born in real-time

VOD systems

[10], [11]. MRD introduces extremely large overhead (costs
about 1446s for one ImageNet-class image), which is not feasible
in real-time scenario [10]. Patchguard++ relies on analyzing deep
feature of every single image and cannot utilize the temporal and
spatial redundancy of adjacent frames in video data [12].

To this end, focusing on the important live vision scenario that
is widely adopted in autonomous driving and surveillance systems,
this work proposes the real-time robust video object detection
system, Themis, to defend the adversarial patch attacks that
practically introduce damaging consequences in video recognition
tasks. We propose localized important superﬁcial feature (LISF)
based defensive methodology, which not only effectively identiﬁes
the adversarial regions but is also able to leverage temporal

 
 
 
 
 
 
and spatial redundancy of video data for efﬁcient robust object
detection.

Themis Algorithm1: We draw the key observation that adver-
sarial inputs induce VOD to be overshadowed by the localized but
inductive superﬁcial features, and the effect of adversarial patches
can be eliminated facilely without aggravating the prediction
accuracy of benign images when moving out LISFs. Hence, we
propose LISF-based detection and recovery method based on
prediction stabability testing by moving out LISFs. Results show
that Themis algorithm effectively locates the adversarial regions
and eliminate adversarial effects.

Themis Architecture: Although Themis algorithm is effective at
detecting the adversarial regions in input data, it also introduces
challenges due to the additional multiple rounds of inference during
the prediction stability testing by occluding LISFs. To reduce
performance overhead to support real-time robust video object
detection, we propose the Themis architecture to eliminate both the
inter-frame and intra-frame redundant computations. 1) Inter-frame:
Themis leverages the spatial and temporal redundancy of video
data to eliminate unnecessary computations in non-key frames.
Speciﬁcally, for key frames of video data, the complete defensive
algorithm is performed to locate adversarial region or features. For
non-key frames, by leveraging the temporal and spatial locality
in video data, Themis approximately predicts the adversarial
region location or features in non-key frames by estimating the
motion movement of adversarial regions and features (i.e. optical
ﬂow in this work). 2) Intra-frame: In observing the redundant
computations of benign features during LISF-based detection and
recovery, we propose the efﬁcient hardware design for benign
feature computation reuse and eliminate redundant unnecessary
computation and memory trafﬁc. Themis architecture can be easily
integrated with existing DNN accelerators to friendly support
state-of-the-art performance-oriented or accuracy-oriented video
recognition methodologies In summary, this work has the following
contributions:

• We propose the LISF-based methodology to accurately
identify the adversarial region locations in input data. The
detection methodology can effectively work under adaptive
attack when an adversary has white-box knowledge of
defensive approaches.

• We propose the defensive framework that signiﬁcantly re-
duces defending overhead in non-key frames by leveraging
temporal and spatial locality in video data, which can be
friendly integrated with the state-of-the-art video object
detection frameworks.

• We propose lightweight hardware customization to efﬁ-
ciently support the defensive framework and fully exploit
the computation reuse of benign features, which can be
easily adapted to existing deep learning accelerators.
• We make an extensive experimental evaluation and the re-
sults show that Themis system can effectively and efﬁciently
defend adversarial attacks in real-time. Compared to the
system without defensive mechanisms, Themis improves
the average mAP of real-time object detection from 0.03 to
0.66, with 1.08% of hardware overhead.

1. Themis, (Greek: “Order”) in Greek religion, personiﬁcation of justice, a

blindfolded goddess holding a pair of scales.

2

2 BACKGROUND

2.1 Video Object Detection Preliminary

Video object detection, recognizing instances of visual objects
(e.g, humans, cars, animals) and their locations in digital videos,
is a fundamental important computer vision task. It forms the
basis of many other computer vision tasks, such as instance
segmentation [13], object tracking [14], and image captioning [15],
etc.
Object Detection in a Single Image: Image object detection
is the foundation of detecting objects in videos. Image object
detector solves the following two subtasks: 1) Predicting how
many objects are in the images. 2) Classifying these objects and
estimating their locations with bounding boxes. The most important
evaluation metric for object detector prediction accuracy is mAP
(mean Average Precision) which considers both precision and recall
rate. Recently, video object detection capability has been largely
boosted by deep learning techniques with milestones of CNN-
based image detectors, such as RCNN, YOLO [16], SSD [17],
RetinaNet [18], etc.
Object Detection in Video Data: Video data consists of many
time-sequential images. Hence, video object detection can be
achieved by performing image object detection in every image
(referred to as accuracy-oriented (AO) schema). For better com-
puting efﬁciency, prior video object detection methodologies are
proposed to leverage temporal redundancy across frames in time-
sensitive applications [19], [20], [21] (referred to as performance-
oriented (PO) schema). The key design concept of PO schema
is to undergo the precise computation of key frames, while
approximately computing non-key frames based on key frame
features and the motion, trajectory, or optic ﬂow information.
Optical Flow: Optical ﬂow is widely used to utilize the tem-
poral redundancy in video data and to approximate the non-key
frames.Optical ﬂow describes the apparent motion of image objects
in consecutive frames caused by the movement of objects or the
camera. Speciﬁcally, as shown in Fig. 1, optical ﬂow(c) is a 2D
vector ﬁeld where each vector is a displacement (dx, dy), showing
the movement of pixels from ﬁrst frame (a) to second (b). Once
we obtain the optical ﬂow, the pixels or feature map of non-key
frames can be estimated by warping the pixels or feature map of
their predecessor key frame with optical ﬂow:

V (x + dx, y + dy, k + 1) (cid:44) V (x, y, k)

where V can be the pixel values or feature activation and (cid:44) can
be implemented with different interpolation methods. The optical
ﬂow should be resized to warp the feature maps with different size.
Optical ﬂow can be calculated based on pixel matching [22] or
CNN [23], with the assumption that objects maintain the same
intensity (brightness) between consecutive frames.
AO and PO Video Object Detection Details: Fig. 2 illustrates
accuracy-oriented (AO) and performance-oriented (PO) video
object detection frameworks. For AO framework, the image pixels
of every frame are input to the full video object detector for precise
computation. For PO framework, the DNN-based video object
detector is divided into two parts: DNN-preﬁx for more generic
feature extraction with much heavier computation and DNN-sufﬁx
for ﬁnal prediction with low computation overhead [21], [24]. PO
framework ﬁrst calculates the optic ﬂow between non-key frames
and the key frame. Then, warps the key-frame features with
the resized and scaled optic ﬂow information to approximately
compute the non-key-frame features. The predicted non-key-frame

3

recovered. Hence, autonomously identifying the adversarial region
in the video data is the key foundation of robust object detection.
Patch Attacks vs. Example Attacks. Compared to adversarial
example attacks [25] that have been largely studied in image classiﬁ-
cation tasks, patch attacks have the following advantages: 1) Better
universality, because the adversarial patch is independent of input
images. Such a scene-independent feature enables physical-world
attack without prior knowledge of the scene. Adversarial example
attacks, on the other hand, generate perturbation noises highly
dependent on the input images, which hinders their deployment in
the physical world. 2) Better robustness to environmental noises
and geometric distortion. For example, human being wearing the T-
shirt printed with the adversarial patch can be ignored in the object
detection systems in different environments and body gestures [4].
It is not only effective in a static ﬁgure input, but also in complex
scenarios like walking, sitting, and running [4]. More studies prove
that adversarial patches are robust to not only environmental noises
but also geometric distortion.

Adversarial example attacks, however, are scene-dependent
and transfer poorly in different inputs. In real cases, the adversary
neither can obtain the attack scene in advance nor compute the
adversarial examples for every frame in real-time. Therefore,
adversarial example attack is not a practical attack model in
physical environments for video recognition tasks. In this following,
we do not consider the adversarial example attacks.

Limitation of Existing Defenses. Although some prior re-
searches propose the adversarial example detection methodol-
ogy [26], [27], the differences between adversarial patch and the
adversarial example noises hinder these countermeasures’ appli-
cability in the patch attacks. Additionally, these countermeasures
can only recognize whether the input is a benign image or not,
but cannot recover the DNN system from the attack effect. In this
study, we aim to rescue the video recognition tasks by not only
detecting the malicious input but also eliminating the adversarial
effect by moving out the malicious patches. More adversarial
defense comparisons are introduced in Section 7.

Fig. 1. Optical ﬂow (2D vector ﬁeld) describes the motion of objects in
two frames.

Fig. 2. Video recognition framework: (a) Accuracy-oriented (AO) frame-
work precisely computes every frame; (b) Performance-oriented (PO)
framework precisely computes key frames, while approximately computes
non-key frame based on optical ﬂow.

feature map is input to the DNN-sufﬁx for the non-key frame result
computation. Due to the large gap between the computation of
DNN-preﬁx and DNN-sufﬁx, the computation overhead of non-
key frames is signiﬁcantly reduced. These two VOD frameworks
(image-based and feature-based) are adopted in different scenarios
that are optimized for accuracy or performance. It is important to
support effective and efﬁcient defensive mechanisms in both these
two cases. We propose Themis framework to achieve this goal.

2.2 Adversarial Attacks in Video Recognition

Attack Formalization. Adversarial patch attack can largely dam-
age video recognition tasks by evading video object detectors. It
manipulates the victim model to output malicious results by adding
the patch perturbation in the object of video data. Formally, the
goal of adversarial patch attack is to generate the adversarial patch,
ˆP, to maximize the expectation of possibility for classiﬁer h to
output targeted malicious label yp with all adversarial inputs xp
derived from data set X.

ADVERSARIAL VIDEO PATCH CHARACTERIZA-

3
TION

Intuitively, patched images rely on the extremely localized im-
portant neurons in the adversarial regions to deceive and induce
the object detector to output the incorrect results, while benign
images perform stable object detection without relying on ex-
tremely localized important neurons. Hence, we perform the LISF
characterization and have the following observations:

1) LISFs are good candidates for detecting adversarial regions

ˆP = arg max

p

EX [logPr(h(xp) = yp|xp)]

(1)

in single frame.

Patched image xp is generated by applying patch p to x in the

input dataset X, which can be formalized as:

xp = A(p, x), x ∈ X

(2)

where p is the adversarial patch, x is the clean image, and A
is the transformation function applying the adversarial patch on
the clean image (environmental noises, resizing, rotations, and
deformations).

The adversarial patch determines the prediction results with
a very small region of pixels (adversarial region) for a relatively
broad range of input images. By moving out the adversarial region,
the adversarial effects are eliminated and the prediction results are

LISF Distribution: The important neurons in feature maps
of superﬁcial layers exhibit a localized pattern in patched images
while scattered in benign images. The superﬁcial important features
refer to the neurons that contribute signiﬁcantly to the feature map
value in the superﬁcial layers (in this paper, we use the ﬁrst layer).
Speciﬁcally, we take the superﬁcial important neurons as the Top-K
ones having the biggest value in the output feature map of the ﬁrst
layer. We visualize these important neurons of a patched image
example in Fig. 3(a). Intuitively, the patched image exhibits an
extremely localized region of important neurons. Further, we make
statistical counting about the distribution of Top-200 neurons of
12K images randomly selected from FLIC dataset [28] based on
two metrics: cluster distance and cluster number. We compare the

(b) Frame k+1(c) Optical flow(a) Frame kFeatureExtraction(NN-prefix)Optic Flow/Motion Estimation/Decoder InfoTask Network(NN-suffix)Task Network(NN-suffix)Key frameNon-key frameHeavy computationLight computationExactfeature mapPredictedfeature mapLight computationKey frame resultNon-key frame resultLight computationT=kT=k+1Video Object DetectorEvery frameResults(a)(b)4

Fig. 3. Distribution of important neurons. (a) A showcase of the important
neuron distribution and temporal association of LISFs along consecutive
frames. (b) The distance deviation of the important neurons in 12K
images. (c) The average important neuron cluster number distribution in
12K images.

standard deviation of the distance between the highlighted nodes to
the central node in benign images and patched images. The patched
images’ distance deviation is much smaller than benign images,
as shown in Fig. 3(b). We also cluster the Top-k nodes with the
classic MeanShift clustering algorithm. As shown in Fig. 3(c), for
patched images, about 86% of cases have only one cluster and 97%
of cases have no more than two clusters. While for benign images,
about 80% of the cases have more than three clusters. Both of these
two metrics show the localized distribution of superﬁcial important
neurons in patched images.

Prediction Stability by moving out LISFs: When occluding
the localized superﬁcial important features, patched images can
be recovered mostly without affecting the prediction accuracy of
benign images. As shown in Fig. 4, we compare the detection rate
of benign objects and patched objects before and after moving
out the localized important features. The detection rate of benign
objects decreases to 97.4% slightly, while the detection rate of
patched data increases from 17.9% to 72.8% signiﬁcantly, which
means that the prediction results of benign objects are much more
stable than patched objects. For benign objects, the detection rate
is not sensitive to the localized features. For the patched objects,
patch effect would been effectively eliminated after moving the
localized important superﬁcial features.

2) LISFs exhibit temporal association in video data, which
enables us to leverage temporal redundancy to eliminate the
recovery overhead in non-key frames. Superﬁcial feature computing
is very closed to the input, hence the important superﬁcial features
exhibit the similar temporal association as the image frames in
video data. The bottom two subﬁgures in Fig. 3 (a) show the LISFs
marked within the solid red boxes in two consecutive frames. The
LISF in the following frames can be predicted by warping the
optical ﬂow with the LISF in the previous key frame (predicted
LISF marked in green box).

In summary, LISF-based methodology not only effectively
detects adversarial region and recovers the object detection in key
frames, but is also able to leverage temporal redundancy in videos
and eliminate defensive overhead in non-key frames. Based on
these two observations, we then propose the LISF-based robust
video objector detection system.

Fig. 4. Prediction stability of occluding LISFs: benign inputs vs. patched
inputs.

4 THEMIS SYSTEM ARCHITECTURE
4.1 Overview

The overall Themis system is shown in Fig. 5 with algorithm,
framework, and hardware designs.

Algorithms: LISF-based methodology effectively targets the
adversarial regions in input images and recovers the prediction
results by moving out those regions.

Framework: Although the Themis algorithm already reduces the
adversarial region searching space with LISF-based methodology,
multiple inferences are introduced in the occluding testing stage
and incur large overhead. To achieve the goal of real-time robust
object detection, Themis proposes systematic design to efﬁciently
remove redundant computations for better computing efﬁciency.

To further reduce the detection overhead, Themis proposes
the inter-frame and intra-frame optimizations to reduce redun-
dant computations. 1) Inter-frame optimization: By leveraging
the spatial and temporal locality between frames, Themis only
performs complete adversarial detection in key frames. For non-
key frames, Themis framework either predicts the adversarial region
locations based on regions detected in key frames (image-based
warping) or reuse the clean features in key frames after eliminating
the adversarial effects (feature-based warping). These two warp
strategies can be easily integrated with existing AO and PO video
object detection frameworks. 2) Intra-frame optimization: The
algorithm introduces a large volume of redundant calculations
of benign features during occluding prediction stage for the
key frames. Hence, Themis scheduler reduces the computing
overhead with computation reuse of benign features (Section 4.2).
Additionally, Themis provides the interfaces of setting the following
conﬁgurations for better feasibility: key frame proportion, the video
object detector model segmentation strategy, and the conﬁgurable
parameters in adversarial patch detection algorithms.

Hardware: Although Themis algorithm can be implemented in
pure software, it is inefﬁcient because of the following reasons: 1)
Searching the heat-map of the input activation for the adversarial
candidates is inefﬁcient in the DNN accelerator due to the lack
of the computing parallelism between the searching process and
typical inference process; 2) During the voting stage, multiple
patch candidate regions will be occluded to calculate the inference
results. In this process, a signiﬁcant volume of benign features
is computed repeatedly and introducing large unnecessary perfor-
mance overhead. To address these issues, we propose the T hemis
hardware architecture for efﬁcient defense. The top-level block
diagram of hardware architecture is shown in Fig. 5 (c). Apart from
the typical DNN accelerators with PE array, scalar function unit
(SFU), global buffer, and control logic, Themis is augmented with

(b)6543210.5%8.8%30.2%40.3%18.5%1.7%0.0%0.0%0.4%2.4%10.4%86.7%Benign ImagesPatched Images(c)(a)0.000.200.400.600.801.00FLICLSPMS COCODetection rate BenignBenign ISF MaskedPatchedPatched ISF Masked+0.63+0.61+0.41-0.02-0.09-0.045

to the derivation brought by the inaccurate optical ﬂow information
(more validation in Section 6.1).

2) Feature-based Warping in PO Frameworks: For PO frame-
work, we directly warp the clean features in key-frames with the
resized and scaled optical ﬂow to compute the non-key-frames
features. Then, the predicted feature map is forwarded to the DNN-
sufﬁx for the ﬁnal object detection results. Under both AO and PO
cases, the defensive overhead of non-key frames is minimized.
Intra-frame optimization for Benign Feature Computation
Reuse. With the obtained coordinates of the patch candidates,
Themis then makes the prediction decisions by masking them from
the original image individually. During this process, multiple infer-
ence rounds of inputs with different mask locations are introduced,
which incurs a large execution overhead. Hence, we propose the
scheduling methodology with computation reuse to alleviate the
execution overhead and eliminate redundant computations. As
shown in Fig. 7, the masked images and the original image share
the most same pixels, with only the differences of masked regions.
Thus, we compute the masked regions separately and splice the
masked region back to the complete feature map for the ﬁnal
prediction results, to eliminate the most redundant computations.
The detailed mask region computing is as follows: Given an image
(224×224 pixels) with the masked regions (50×50 pixels). The
pixels in the masked region are set as 0 to occlude their effect on
the results. However, the features of the masked region through
neural network layers are not simply set to 0, because the the
existence of weight bias and the kernels that larger than 1. So we
need to take the padding number into consideration to compute
the features of the masked region. For example, when computing
the C1 layer in Fig. 7 for masked images, the complete region
(masked region + padded region) for recomputation is 53×53, with
an additional purple part. The detailed computing process and
dataﬂow optimization are in Section 4.4.
Reconﬁgurable Design Knobs. Themis framework provides the
interfaces to conﬁgure the following design knobs that affect overall
performance efﬁciency: the key frame proportion, the strategy of
dividing the object detector to feature extraction DNN preﬁx and
classiﬁcation DNN sufﬁx, the candidate numbers during adversarial
patch detection.

Key frame: We set the key frame rate as 10% with ﬁxed length.
Themis framework can support the adaptive key frame strategies
proposed by prior video object detection studies [21]. However,
how to choose the key frame is out of the scope of this work.

PO framework splitting: Designing DNN preﬁx and sufﬁx in
PO frameworks is the trade-off between performance and detection
accuracy. When the preﬁx is close to the classiﬁcation layers,
the feature map is too small and may introduce larger accuracy
degradation during optical ﬂow estimation. We test extensive
datasets and set the splitting spot when the feature map size is
smaller than 56×56.

Adversarial region detection parameters: In the adversarial
patch detection stage, the more adversarial candidates, the more
rounds of the additional inferences and larger performance overhead
are. The number of the patch candidates is determined by the heat
spot selected threshold (β and θ ). We set β = 0.75 and θ = 0.85.

4.3 Adversarial Detection and Recovery

In observing that important superﬁcial features exhibit different
spatial distribution characteristics and exert distinct inﬂuence on the

Fig. 5. Themis Architecture Overview. Themis reduce the defending
overhead in non-key frames for both AO framework (a) and PO framework
(b); Hardware optimization for benign feature computation reuse (c).

the LISF searching logic to search the candidate regions according
to the heat map of the ﬁrst superﬁcial layer feature map, Masked
Neuron Buffer to optimize the data and computation reuse of
benign features, and the voting logic to decide the ﬁnal prediction
results.

4.2 Framework

Inter-frame Optimization based on Tempo-Spatial Redun-
dancy. The overview of T hemis framework is shown in Fig. 5(a)
and Fig. 5(b) with support for AO and PO video object detection
frameworks. Under both AO and PO scenarios, the defensive
mechanisms for key frames are the same: T hemis algorithm detects
the adversarial region of frames and masks them to eliminate
the adversarial effect. For non-key frames, T hemis proposes
two warp strategies with optical ﬂow information which are
friendly integrated in existing AO and PO video object detection
frameworks, as shown in Fig. 5(a) and Fig. 5(b).

1) Image-based Warping in AO Frameworks: For AO frame-
work, we approximately estimate the patch location in non-key
frames by warping the patch location in key-frame images with
the optical ﬂow. Speciﬁcally, every frame will be forwarded to the
object detector for a complete inference. T hemis only performs
the adversarial patch detection in key frames and obtains the
adversarial region location. Then warps the detected adversarial
region in key-frames with the optical ﬂow information to estimate
the adversarial region in non-key frames. The corresponding area
of non-key frames is masked and the masked non-key frames are
forwarded to the object detector for inference. The rationality is
that the adversarial regions in the input data also exhibit temporal
and spatial redundancy in live vision. Moreover, compared to the
object to be segmented, the adversarial region is much less sensitive

Key frameNon-key frameAdv region detection and removalOptic FlowVideo Object DetectormaskedT=kWarpAdv region locationRecovered prediction resultsKey frameNon-key frameT=kT=k+1Adv region detection and removalOptic FlowFeature Extraction(NN-prefix)WarpTask Network(NN-suffix)(a)(b)HardwareGlobal BufferAdv Candidate Searching LogicControllerMemoryMaskedNeuron BufferVotingPE ArraySFU(a)(b) Frameworks(c) Hardware DesignClean imageClean featuresprediction results in benign and adversarial input data, we propose
the LISF-based patch candidate searching methodology and then
detect and eliminate the adversarial effect by occluding testing.

LISF-based Patch Candidate Searching. We perform the
LISF searching in the output feature map of the ﬁrst layer. The size
of the searching window is the upper limit of the patch sizes and the
searching stride is 1. When the number of important neurons in one
searching window is larger than the threshold (θ ), it is recognized
as an important window and marked as the patch candidate. When
several important windows are overlapped, the central important
window will be retained as patch candidate with all the other
deleted. The detailed searching logic implementation is described
in Section 4.4.

Occluding Testing and Recovery. We recover the prediction

results with the following two steps:

1) Masked image execution. After obtaining the candidate
locations of adversarial patches, we generate masked images by
occluding the patch candidate locations individually from the
original images. These masked images are taken into the victim
model to produce the prediction decisions.

2) Monopolist-occluded voting. Themis performs the prediction
decision analysis to detect patched images by examining whether
there is a monopolist patch candidate that determines the prediction
results. It is true that such a methodology will introduce the true-
negatives. However, the results show that such cases are rare and
Themis can achieve good detection effectiveness. The detailed
patch candidate searching and voting mechanisms are introduced
as follows. There are k candidates: P1, P2, ..., Pk. The prediction
result of the original image is L0, and the corresponding prediction
results of masked images: L1, L2, ..., Lk. We ﬁrst detect the patch
by checking whether there is a Li distinct from others, while all
the other labels are the same: If positive, the Pi is the monopolist
that dominates the prediction results, which is the adversarial patch.
Only when tearing it off the image, the classiﬁer predicts the robust
and benign label Li.

If there is only one candidate, i.e. k = 1, we compare L1 and
L0 to determine whether there is an adversarial patch. If they are
different, P1 is the adversarial patch and L1 would be recovered
label.

If there is no such particular label (either all the labels are the
same, or several labels are different), no monopolist is detected.
Then the image is recognized as a benign image. Themis then
performs the majority voting to obtain the predicted label.

4.4 Hardware Design

The Themis architecture can be integrated into the typical DNN
hardware accelerator to support real-time detection with small
overhead.

LISF searching logic. The LISF searching logic outputs
the coordinates of clustered important neurons, which infers the
possible candidate locations in the input image. LISF searching
consists of the following three steps:

1) Obtain the binary important (output) feature map of the
ﬁrst layer. Computing Top-K neurons in the feature map is time-
consuming and introduces large hardware overhead. Therefore, we
make the estimation about the adaptive threshold according to the
maximum value of the feature map. All neurons with activation
values larger than the threshold (β ∗ f eaturemax) are selected as
important neurons. The important neurons map is stored in the
buffer of LISF searching logic.

6

Fig. 6. Searching&Voting logic.

Fig. 7. Computing ﬂow for original images and the masked images.

Fig. 8. Data reuse ﬂow

2) Identify the important windows. We slide the ﬁxed-size
window to make statistic counting about the important neuron
numbers in one window. When the important neuron numbers
occupy more than the threshold (θ ) of the total neurons, we
mark this window as an important neuron window, which will
be highlighted as the patch candidates. To reduce the hardware
overhead, we make the incremental accumulation of the important
neurons in one window. As shown in Fig. 6(a), with the number
of important neurons in Window[i,j,i+s,j+s], to compute the
Window[i,j+1,i+s,j+1+s], we simply subtract the important neurons
in column j+1 and add the important neurons in column j+1+s
between row i and row i+s.

3) Delete the overlapped important windows. When two sliding
important windows have more than 30% of the area overlapped,
we take them as one single patch candidate.

Noted, the LISF searching is not on the critical path of DNN
inference, which is parallelized with the processing of the original
images.

Masked Neuron Buffer (MNB). To support efﬁcient computa-
tion reuse of benign features and optimize the data accesses of the
adversarial features, the masked neuron buffer is proposed to buffer
the padded bounding area for feature computation of candidate
adversarial regions.

The data reuse ﬂow of computing candidate adversarial regions

Window[i,j,i+s, j+s]Window[i,j+1,i+s,j+1+s]Incremental computing(Binarized Feature Map)RegRegReg0000110110+1-1+Reg(a)(b)RegcounterCMPCMPcounterL0, L1,…, LkCMPC1:feature maps32@112x112P2:f.maps32@56x56C3:f.maps64@28x28P4:f.maps64@14x14FC5:10Masked Region:50x50M. + Padded Region:53x53。。。。……………………M.Region:26x26MP.Region:28x28M.Region:14x14MP.Region:17x17M.Region:8x8MP.Region:10x10M.Region:5x5MP.Region:14x14FC5:10INPUT:224x224MaskedComputation ReusePadded(a)(b)MNBPE ArrayGB① During complete inference, store the padded adversarial region to MNB② Masked image inference:Read candidate adversarial features from MNB and GB③ Masked image inference：Write back candidate adversarial featuresMNBPE ArrayGB① During complete inference, store the padded adversarial region to MNB② Masked image inference:Read candidate adversarial features from MNB and GB③ Masked image inference：Write back candidate adversarial featuresis as follows (Fig. 8): With the coordinates of potential adversarial
region candidates, the padded bounding areas through all the neural
network layers in Fig. 7(a) are determined. Through the typical
inference, all the activation values of the padded bounding areas
are stored in Masked Neuron Buffer. Then, during the inferences of
masked images, all the masked regions are batched for computation.
For every layer, the PE array reads the candidate adversarial features
from global buffers and the padded bounding areas from masked
neuron buffers, as the red box and purple box shown in Fig. 8 2(cid:13).
The PE array combines these neurons by padding the red box
with the purple box, takes it as input, and computes the candidate
adversarial feature of next layer. After completing the computation
of this layer, the adversarial features are stored back to global
buffers. Because the padded bounding area is very small compared
to the full activation map, we conﬁgure the mask neuron buffer
with a size of 8KB for every PE array.

Voting Logic. The basic voting logic is as shown in Fig. 6(b).
We use a compactor array to perform the pairwise comparison
between the prediction labels of masked images (L0, L1, ..., Lk). If
there is an orphan label Li, this image is identiﬁed as a patched
image and the recovered label is Li. Otherwise, it is a benign image
and Themis performs the majority voting to obtain the recovered
label.

Computing Flow. The overall computing ﬂow is as follows:
taking in a new input image, the DNN accelerator ﬁrst performs
the normal inference procedure on the image. Meanwhile, the
searching logic obtains the candidate masked regions in the input
based on the localized superﬁcial important features. During the
inference procedure of the original images, the feature data of
corresponding padded bounding box are stored in the masked
neuron buffer. After the completion of the original image inference,
masked image inference rounds start to get their prediction results.
After that, taking in those prediction results, voting logic detects
the adversarial patches and output the recovered results.

For one input image, searching and voting operations are only
performed once, while the inference rounds are determined by the
searching candidates.Among these stages, multiple inferences in-
troduce the most performance cost. Voting is simple and performed
within several cycles. Although the searching algorithm is time-
consuming when ofﬂoaded to the CPU platform, its customized
hardware largely boosts the performance and the overhead is less
than 0.5% of the multiple inferences. The detailed experimental
evaluation is illustrated in Fig. 15.

5 EXPERIMENTAL METHODOLOGY
In the following sections, we will evaluate the defensive effective-
ness and architecture efﬁciency of Themis, which is complementary
to enable the robust and real-time video object detection.

5.1 Validation on Algorithm Accuracy

We test the attack success rate and the defensive effectiveness
in both single-frame object detection tasks and the video object
recognition tasks. For the previous scenario, we focus on exploring
and validating the adversarial patch detection capability of Themis
algorithm on static images. In the latter scenario, we focus on
exploring the defensive effectiveness on the non-key frames when
Themis framework leverages the temporal and spatial information
in video data.

Attack Methodologies: For single-frame testing scenario, we
adopt the digital-synthesized attack methodology that randomly

7

TABLE 1
Hardware Platform Conﬁgurations

Mem

Comp

Global Buffer/Array
64KB
# of Arrays
2×2

RegisterFile/PE
256B
# of PEs/Array
24×24

Bandwidth MNB/Array

26GB/s
DataType
INT8

8KB

MNB denotes Masked Neuron Buffer.

attaches the digital adversarial patches onto the bounding box
regions of the objects in MS COCO, FLIC, LSP datasets and
random locations of images in ImageNet dataset with random
rotated angles. The patch size is scaled with the area of bounding
boxes ranging from 33x33 to 130x130 pixels. Since we focus on
the defensive effectiveness of Themis, we only perform attacks
on the objects or images that can be correctly identiﬁed by the
detector. For video data testing scenario, we adopt physical attack
videos released in the state-of-the-art attack methodology [4] (Adv
T-shirt), which signiﬁcantly damages the functionality of YOLOv2
object detector. The patch size is variable and the adversarial patch
has been signiﬁcantly deformed during the human movement.

Optical Flow Methodologies: Themis framework is compat-
ible with different optical ﬂow methodologies. We use both the
CV-based and DNN-based optic ﬂow methodologies: DIS [22] and
SpyNet [23], to validate the defensive effectiveness and architecture
efﬁciency. The SpyNet is customized with scaled input image sizes
and reduced pyramid levels.

Evaluation Metrics: We adopt the commonly-used metrics,
the detection rate and the standard mean average precision (mAP)
score, to measure the accuracy of video object detection. In terms
of performance efﬁciency, the frame per second (fps) is used to
indicate how fast the framework process the video data.

5.2 Validation on Architecture Efﬁciency

NN Accelerator Hardware Implementation. Our methodology
can be generalized adopted in diverse neural network accelerators.
In this work, we evaluate our methodology based on the classic Ey-
eriss accelerator. Speciﬁcally, we augment the Eyeriss accelerator
with the patch detector consisting of the LISF searching, masked
neuron buffer, and voting logic. To prove the generality and its
low overhead, we test both the server and edge accelerators with
different conﬁgurations, as shown in Table 1.

We implement the Themis hardware design in Verilog RTL. To
obtain the area and power, we synthesis and place&route the RTL
code with Synopsys toolchains under TSMC 28nm technology.
We use CACTI 7 and DESTINY to model the DRAM memory
and on-chip SRAM buffers. Due to the unbearable long duration
of silicon simulation, we also tailor an open-sourced simulator,
nn-dataﬂow to support Themis for the total execution latency
simulation. The simulator also reports the exact memory traces and
module activities, which are then used to calculate dynamic energy
consumption.

Besides, we deploy Themis system on an off-the-shelf FPGA,
Zynq UltraScale+ MPSoC ZCU104 board, to show the real
performance. Speciﬁcally, we implement the proposed architecture
components like Adv Candidate Search Logic and integrate them
with a DPU (a soft IP for NN inference) using Vitis-ai framework.

6 EXPERIMENTAL RESULTS
We ﬁrst show the defensive effectiveness of T hemis in terms of
single frame and video scenarios (Section 6.1). Then we show the

8

strong adaptive attack [33] that the adversary gets known the
full knowledge of the defensive strategies. To steer clear of the
detection of T hemis, the adversary trains the adversarial patch with
Equation(3) that a penalty loss for the superﬁcial activation value
of patch is considered compared to Equation(1). In this way, the
adversary aims to build the adversarial patch with good poisoning
effects, but also trying to escape from the adversary candidate
searching. α is the parameter to control the scale of the penalty
loss in superﬁcial activation value.

loss = −logPr(h(xp) = yp) + α ∗∑(w1 ∗ patch)

(3)

We perform the adaptive attacks on ImageNet dataset and
the results are shown in Fig. 10. Adversary detection rate refers
to the rate that Themis correctly identiﬁes the adversarial region
in the adversarial inputs or the benign input with no adversarial
region. Recovery object detection rate refers to the rate that Themis
correctly identiﬁes the object in the image. The results show that,
it is indeed that both the adversary detection rate and the recovery
object detection rate decrease to 82.1% and 82.0% respectively,
when α increases from 0 to 0.01. However, compared to the gentle
slope of adversary detection rate and the recovery object detection
rate, the attack success rate decreases much more drastically. When
α is set to 0.01, the adversarial attack success rate is dropped
to 7.9%. As a comparison, after adding total variation loss, the
detection rate of LGS drops signﬁcantly from 59.1% to 19.8%
while attack success rate maintains high. These results indicate
that the adversary cannot maintain the two goals of high attack
success rate and good stealthiness simultaneously. Themis can work
effectively even under adaptive attack.

6.1.2 Video Frame Defensive Effectiveness
For the video frames, we adopt the adversarial video benchmarks
in the state-of-the-art adversarial attack study [4], where the
people wearing the adversarial T-shirt moving in indoor and
outdoor scenarios and perform the practical attacks in the physical
environment. The video object detector is based on YOLOv2. We
evaluate the object detection rate and mAP under the following
scenarios:

• AO-ND: AO framework with no defensive mechanisms.
• AO-Full: Defensive AO framework that examines every

frames.

• AO-Dis: Defensive AO framework that completely exam-
ines key frames, but CV-based methodology to predict the
adversarial patch locations in non-key frame.
AO-Spynet: Defensive AO framework that completely exam-
ines key frames, but DNN-based optical ﬂow information
to predict the adversarial patch locations in non-key frame.

•

• PO-ND: PO framework with no defensive mechanisms.
• PO-Spynet: Defensive PO framework with DNN-based

optical ﬂow (spynet) .

Detection Rate: Fig. 11 shows the object detection rate under
different scenarios. With adversarial attacks, both AO and PO
object detectors have signiﬁcant low object detection rates of 4.4%
and 4.8%, which indicates that adversarial attacks can essentially
damage the integrity and functionality of object detectors even in
the physical environments. With Themis defensive algorithm, the
detection rate is signiﬁcantly improved above 93.8% for different
defensive strategies. Compared to AO-Full that examines every
frame, other approximate defensive methods achieve relatively
good object detection rates within a gap of less than 5%.

Fig. 9. Detection Effectiveness.

Fig. 10. Defensive Effectiveness under Adaptive Attack.The x-axis refers
to the penalty coefﬁcient α.

performance and energy efﬁciency of T hemis (Section 6.2), which
introduces negligible overhead to real-time video object detection.
Finally, we show that T hemis adds negligible area overhead to the
baseline DNN accelerator(Section 6.2.4).

6.1 Defensive Effectiveness Evaluation

We validate the defensive effectiveness of Themis under the
following two scenarios: single-frame data and the video data with
sequential frames.

6.1.1 Single-frame Defensive Effectiveness
For single-frame testing, we use FLIC [28], LSP [29], MS
COCO [30] and ImageNet [31] datasets that are commonly used
in object detection domain. We ﬁrst evaluate the adversarial
patch detection accuracy based on the metric of overlapped area
proportion in Fig. 9(a). The predicted patch area and the actual
patch area have an average of 72%, 81%, 50% and 88% overlapped
region compared to the actual patch area size. The results show
that LISF-based searching methodology can accurately identify
the location of adversarial patches. We then show the object
detection rate before and after Themis defense in Fig. 9(b) compared
with Local Gradient Smoothing (LGS) [32] method. LGS locates
the patch using local gradient of image pixels with the basic
assumption that patch pixels are not smoothing. The detailed attack
methodology is as follows: the adversary randomly attaches the
adversarial patch in the person bounding box of the images in
the datasets, so that the object detectors are evaded to ignore the
persons. With the adversarial patch attack, the object detection rate
is 11.9%, 6.8%, 22.8%, 14.0% for FLIC, LSP, MS COCO and
ImageNet. Compared to LGS that improves the detection rates to
71.9%, 23.3%, 70.8%, 59.1%. , our Themis defensive mechanisms
works better and improves them to 96.2%, 91.3% , 91.4% and
85.8%. The results show that Themis can eliminate the adversarial
patch effect effectively.

Defensive Effectiveness Against Adaptive Attacks. In the
further step, we evaluate the defensive effectiveness under the

(a)(b)0.719 0.812 0.504 0.884 0.0 0.2 0.4 0.6 0.8 1.0 FLICLSPCOCOImageNetPredicted Patch Acc0.119 0.068 0.288 0.140 0.7190.2330.7080.5910.962 0.913 0.914 0.858 0.00.20.40.60.81.0FLICLSPCOCOImageNetDetection RateAdversarial AttackLGSThemis0.856 0.856 0.765 0.079 0.998 0.887 0.886 0.821 0.944 0.866 0.815 0.820 0.0000.2000.4000.6000.8001.00000.00010.0010.01Detection RateAttack Succ RateAdv Detection RateRecovery Obj Detection RateLGS Recovery Detection Rate9

Fig. 11. Detection rate in video-frames.

Fig. 12. Defensive effectiveness in video-frames .

Detection rate is only a coarse-grained metric that intuitively
indicates the detection recall rate of object detectors. In the further
step, we evaluate the mAP that considers both the prediction
accuracy, recall rate, and the predicted bounding box accuracy in
the following.

mAP: Fig. 12 shows the mAP results under IoU = 0.5
(mAP@0.5), IoU = 0.75 (mAP@0.75), and average mAP value
where IoU ranges from 0.5 to 0.95 with the step of 0.05. IoU
(Intersections over Union) is the metric to determine whether it is
an accurate prediction of the bounding box, which is calculated as
the rate of dividing the area of overlap by area of union. A larger
IoU indicates a more strict criterion of mAP prediction accuracy.
From the plot, speciﬁcally, we have the following observations:

1) Consistently, it is observed that adversarial attacks can
effectively fool the object detector to ignore the human being with
mAP as low as 0.03, 0.05 of AO-ND and PO-ND. With the guard
of Themis, the functionality of object detector is recovered and
the average mAP is improved to the range of (0.53, 0.68) under
different defensive mechanisms.

2) When IoU is low (IoU=0.5), the mAP of defensive PO
frameworks is equally good to the defensive approaches that
examine every frame (AO-Full). When IoU is high, PO series may
introduce the reduction of mAP due to the shift and deviation of the
optical ﬂow information. Speciﬁcally, the gap between mAP@0.75
and the average mAP of PO-Spynet and AO-Full is 0.09 and 0.15.
3) Adversarial patch location prediction is less sensitive to
the deviation of optical ﬂow. Although optical ﬂow information
also introduces the deviation between the predicted and actual
adversarial regions, such deviation does not markedly hurt the
defensive effectiveness of Themis (less than 0.03), because of the
prediction instability of adversarial regions, as analysis in Section 3.

6.2 Architecture Efﬁciency Evaluation

6.2.1 Overall Performance and Energy Comparison
We also evaluate the performance and energy of AO and PO
frameworks with different defensive strategies. Fig. 13(a) shows
the object detection throughput for four commonly-used video

Fig. 13. Performance and Energy comparison among different defensive
strategies.

detectors: YOLOv2, YOLOv3, RetinaNet, and FasterRCNN. From
the plot, we have the following conclusions:

1) PO frameworks signiﬁcantly boost the performance when
their model architectures can be divided into heavy NN-preﬁx and
light NN-sufﬁx.

2) Performing adversarial detection in every frame incurs heavy
overhead. Compared to AO-ND, AO-Full incurs 3.3x execution
latency, which remarkably reduces the fps in all four object
detectors.

3) Eliminating the unnecessary recomputing for the adversarial
region locations in non-key frames improves the performance and
reduces the performance gap between defensive approaches with
original approaches, while maintains the defensive effectiveness.
Speciﬁcally, AO-SpyNet introduce 25.0%, 17.7%, 15.5%, 22.9%
overhead compared to AO-ND. PO-SpyNet introduces 28.6%,
20.4%, 14.6%, and 26.4% overhead compared to PO-SpyNet-ND.
In summary, Themis can effectively defend against adversarial
attacks in video tasks, while still maintain the throughput of about
36 fps and 59 fps for real-time object detection in AO and PO
frameworks.

6.2.2 Scheduling Optimization

We ﬁrst evaluate the effectiveness of scheduling optimization for
computing masked images in four typical datasets: MS COCO,
FLIC, LSP and T-shirt [4]. Fig. 14 shows the latency reduction ratio
with benign feature computation reuse for different object detection
models. Patches on MS COCO, FLIC, LSP, and T-shirt account for
2.81%, 1.47%, 3.60%, and 2.01% of the whole image pixels on
average, respectively. We have the following observations:

1) Overall, Themis reduces the latency for masked images
effectively with scheduling optimization. The average latency
reduction ratio for MS COCO, FLIC, LSP, and T-shirt are 51.93%

0.044 0.981 0.951 0.951 0.048 0.938 0.941 0.000.200.400.600.801.00AO-NDAO-FullAO-DisAO-SpynetPO-NDPO-DisPO-SpynetDetection Rate0.98 0.95 0.68 0.95 0.92 0.66 0.95 0.92 0.66 0.93 0.86 0.53 0.94 0.86 0.53 0.000.200.400.600.801.00mAP@0.5mAP@0.75mAP@[0.5,0.95]mAPAO-FullAO-DisAO-SpynetPO-DisPO-SpynetAO-NDPO-ND49.8318.8812.8710.2713.956.424.742.5736.1015.3010.767.8637.3815.5310.877.9283.5026.9913.8813.2359.6621.4611.859.740102030405060708090YOLOv2YOLOv3RetinaNetFasterRCNNThroughput(fps)AO-NDAO-FullAO-DisAO-SpynetPO-Spynet-NDPO-Spynet1.001.001.001.003.572.942.714.001.351.231.191.281.271.201.171.280.700.730.860.970.940.911.021.24012345YOLOv2YOLOv3RetinaNetFasterRCNNNormalized  EnergyAO-NDAO-FullAO-DisAO-SpynetPO-Spynet-NDPO-Spynet(a) Performance comparison(b) Energy comparison10

6.2.4 Hardware Area Overhead
The baseline Eyeriss-like DNN accelerator has an area of 12.60
mm2. On top of the basic DNN accelerator design, Themis only
introduces a total area overhead of 0.136 mm2, which incurs only
1.08% of hardware overhead. Speciﬁcally, the LFI searching logic
occupies 0.0746% of the hardware overhead, the masked neuron
buffer occupies 1.005%, and the rest is attributed to the voting
logic.

6.2.5 Implementation on FPGA
The experimental FPGA device (Xilinx ZCU104 evaluation
board) consists two ARM processor cores and 16nm FinFET+
programmable logic. The ARM processors are used to run Linux
system and control the operation ﬂow, while the programmable
logic is reconﬁgured to accelerate the user applications. We use the
Vitis-ai framework to deploy Themis with a customized DPU IP.
Compared to the ofﬁcially provided Yolov2 demo that runs at 24
FPS, Themis achieves 22 FPS at AO defense mode and 35 FPS at
PO defense mode.

7 RELATED WORK
7.1 Real-time Video Object Detection

Video object detection is the fundamental important computer
vision task and grows rapidly with the increasing demands in
autonomous driving and video surveillance [34]. Extended from
image to video domain, DNN techniques largely boost video
recognition capability. YOLO series [16], SSD [17], RCNN
series [35], are proposed in rapid succession. Compared to single
image object detection, video object detection has new attributes of
existing both spatial and temporal correlations within consecutive
frames. Previous studies leverage such attributes to improve the
performance of video recognition tasks [19], [20], [21]. In addition
to the optimized video recognition frameworks that make use of
temporal-spatial information for computing efﬁciency, some recent
studies enhance feature maps with tempo-spatial information to
improve detection accuracy that originally degraded by motion
blur, rare poses, video defocus, etc [34], [36]. Besides, LSTM-
based [37],attention-based [38],tracking-based [39]video object
detectors are also proposed. Themis algorithm can support such
video recognition frameworks well, because it is able to directly
identify the adversarial region of input and supports feature
aggregation or propagation operations during leveraging the tempo-
spatial video information.

7.2 Defense Against Adversarial Attack

Adversarial patch attack is one of the most practical DNN attack
models that can effectively damage object detectors even in
physical environments [4]. Envisioning its importance, prior studies
contribute to the defense techniques against the adversarial patch
attack by 1) building certiﬁed robust neural networks that resist
the attack effect, such as IBP, de-randomized smoothing, etc [12],
[40], [41]; However, all of these certiﬁed studies achieve distinctly
low certiﬁed accuracy for large scale datasets such as ImageNet. A
certiﬁed accuracy of 20.5%-36.3% from these methods can hardly
be applied in the real world systems. 2) adversarial training to
obtain robust model again patch attack [42], in which online re-
training process introduces unacceptable cost. 3) performing patch
detection based on empirical observations to eliminate the attack
effect, such as digital watermarking (DW) [43], local gradient

Fig. 14. Latency reduction with benign feature computation reuse.

Fig. 15. Performance and Energy comparison with different architectures.

˜53.77%, which indicates that the scheduling optimization in
Themis is applicable to various scenarios.

2) The scheduling optimization strategy in Themis is more
efﬁcient in object detectors with a shallower depth. The average
latency reduction ratio in FasterRCNN is 73.75%, which is
signiﬁcantly higher than 29.13% in RetinaNet. The intrinsic reason
is that the computation reuse ratios in the ﬁrst several layers are
higher than the latter. Speciﬁcally, for the ﬁrst layer in YOLOv3,
the computation reuse ratio reaches 98.38%.

Themis can efﬁciently reduce latency of the detection process
for masked images with scheduling optimization. With an average
latency reduction of 53.31%, which signiﬁcantly reduces the
overhead incurred by the defense scheme.

6.2.3 Comparison with different Architectures
We compare the performance and energy of Themis with CPU
(Intel(R) Core(TM) i7-4770K at 3.50GHz) and GPU (NVIDIA
TITAN V) platforms. Fig. 15 shows the normalized latency and
energy for CPU, GPU and Themis architectures running four video
detectors: YOLOv2, YOLOv3, RetinaNet, and FasterRCNN with
MS COCO dataset. T hemis hardware components can be integrated
with any DNN architectures and we choose Eyeriss-like architecture
as the basic DNN accelerator. Speciﬁcally, ‘Themis’ refers to the
cases of adopting candidate searching hardware components and
‘Themis-Opt’ refers to the T hemis architecture with computation
reuse optimization. For each case, we break down the system into
inference procedure and searching procedure (CPU data bars are
too large in this ﬁgure and are rescaled with the value marking on
it). We draw the following conclusions: 1) T hemis is much more
efﬁcient compared to CPU and GPU platforms. Compared with
CPU, T hemis achieves speedup from 16.3x to 60.3x. Compared
with Titan V, T hemis reduces energy from 9.47x to 29.7x. 2)
Candidate searching consumes non-negligible overhead in GPU
platform. The customized searching logic achieves 745.7x speedup.
3) With the computation reuse optimization, Themis-Opt achieves
speedup from 1.20x to 1.75x.

44.09%66.44%28.77%73.07%45.47%66.69%30.17%75.41%41.44%66.27%28.24%71.79%44.37%66.64%29.34%74.74%0%10%20%30%40%50%60%70%80%YOLOv2YOLOv3RetinaNetFasterRCNNLatency Reduction RatioMS COCOFLICLSPT-shirt23.264.701.351.00 4.883.54 2.176.205.204.32 9.616.51 3.730246810CPUGPUTHEMISOpt-THEMISCPUGPUTHEMISOpt-THEMISCPUGPUTHEMISOpt-THEMISCPUGPUTHEMISOpt-THEMISNormalized LatencyInferenceSearchingYOLOv2YOLOv3RetinaNetFasterRCNN123.27682.14762.96154.8374.5929.721.351.0047.052.731.6763.304.443.6928.5916.36020406080100CPUGPUTHEMISOpt-THEMISCPUGPUTHEMISOpt-THEMISCPUGPUTHEMISOpt-THEMISCPUGPUTHEMISOpt-THEMISNormalized EnergyInferenceSearchingYOLOv2YOLOv3RetinaNetFasterRCNN35.37197.47224.96(a) Performance(b) Energysmoothing (LGS) [32]. However, these defenses proved to be
invalidated when confronting with the strong adaptive attacker
that has the white-box knowledge of the defense [40]. Note that
since locality is the intrinsic property of patch attack, our LISF-
based detection algorithm prevents the adversary from maintaining
both strong attack effect and stealthiness, which promises the
effectiveness of Themis even under the adaptive attack.

The most related recovery methodology are MRD [10] and
ObjectSeeker [11]. MRD [10] requires a large amount of iterative
inference passes to obtain the prediction map by masking every
small region sliding across the entire original input images. It is
extremely time-consuming and costs 1446s for detection of one
single image with sizes of 224×224 on an Eyeriss-scale accelerator.
Similarly, ObjectSeeker [11] proposes patch-agnostic masking for
certiﬁed objection detection that needs more than 100 inferences
for different bands of the input image. Therefore, both MRD and
ObjectSeeker are unacceptable for real-time detection due to their
additional large cost.

In summary, existing countermeasures are unable to perform
online defense for video recognition tasks. This work proposes
a high-efﬁcient and effective detection and recovery system to
defend the adversarial attacks that practically introduce damaging
consequences in video scenarios.

7.3 Feature Importance Analysis

Neuron importance has been widely used for abnormal input
the metric
detection [44], [45]in previous studies. However,
(superﬁcial feature importance) in our methodology is distinct
from previous work. Previous studies focus more on the neurons
that contribute signiﬁcantly to the inference output (deep feature
importance). We envision that deep feature importance is not a
good candidate from the following two aspects: 1) both the benign
images and the adversarial images have the deep feature importance.
Its discrimination in the benign images and adversarial images is
not straightforward, so that it requires more complex computation to
identify the benign and adversarial images. 2) calculating such deep
feature importance is time-consuming, which demands the gradient
information and the complete backward propagation process. We
propose the superﬁcial input feature importance as the metric
for discrimination analysis based on the intuition that in order to
efﬁciently manage the output prediction results with a very small
region of the input data, the adversarial patch must incur large
activation from the ﬁrst place instead of the accumulation of the
deep feature extraction.

8 CONCLUSION

Themis efﬁciently and accurately recovers the DNN systems from
the adversarial attacks with both algorithmic framework and the
architectural support. At the algorithmic level, Themis prevents the
classiﬁer from being overshadowed by the trivial but extremely
biased parts by tearing the patch off the original images. At the
architectural level, Themis not only proposes efﬁcient searching
and voting logic, but also proposes the scheduling methodology
to accelerate the masked image execution by eliminating the
redundant computations and memory trafﬁcs. The results show
that the proposed methodology can effectively recover the VOD
system from the adversarial effect in real-time.

11

REFERENCES

[1] Global Management Consulting. Autonomous vehicle adoption study,

2016.

[2] Electrek. Elon musk clariﬁes tesla’s plan for level 5 fully autonomous

driving: 2 years away from sleeping in the car, 2017.

[3] Waymo. Introducing waymo’s suite of custom-build, self-driving hard-

ware, 2017.

[4] Kaidi Xu, Gaoyuan Zhang, Sijia Liu, Quanfu Fan, Mengshu Sun, Hongge
Chen, Pin-Yu Chen, Yanzhi Wang, and Xue Lin. Adversarial t-shirt!
evading person detectors in a physical world. In ECCV, pages 665–681,
2020.

[5] Zuxuan Wu, Ser-Nam Lim, Larry S Davis, and Tom Goldstein. Making
an invisibility cloak: Real world adversarial attacks on object detectors. In
European Conference on Computer Vision, pages 1–17. Springer, 2020.
[6] Chong Xiang and Prateek Mittal. Patchguard++: Efﬁcient provable attack
detection against adversarial patches. arXiv preprint arXiv:2104.12609,
2021.

[7] Ahmed Abusnaina, Yuhang Wu, Sunpreet Arora, Yizhen Wang, Fei Wang,
Hao Yang, and David Mohaisen. Adversarial example detection using
latent neighborhood graph. In Proceedings of the IEEE/CVF International
Conference on Computer Vision, pages 7687–7696, 2021.
Jinyu Tian, Jiantao Zhou, Yuanman Li, and Jia Duan. Detecting adversarial
examples from sensitivity inconsistency of spatial-transform domain.
arXiv preprint arXiv:2103.04302, 2021.

[8]

[9] Ning Wang, Yimin Chen, Yang Xiao, Yang Hu, Wenjing Lou, and
Thomas Hou. Manda: On adversarial example detection for network
intrusion detection system. IEEE Transactions on Dependable and Secure
Computing, 2022.

[10] Michael McCoyd, Won Park, Steven Chen, Neil Shah, Ryan Roggenkem-
per, Minjune Hwang, Jason Xinyu Liu, and David Wagner. Minority
reports defense: Defending against adversarial patches. In International
Conference on Applied Cryptography and Network Security, pages 564–
582. Springer, 2020.

[11] Chong Xiang, Alexander Valtchanov, Saeed Mahloujifar, and Prateek Mit-
tal. Objectseeker: Certiﬁably robust object detection against patch hiding
attacks via patch-agnostic masking. arXiv preprint arXiv:2202.01811,
2022.

[12] Chong Xiang, Arjun Nitin Bhagoji, Vikash Sehwag, and Prateek Mittal.
Patchguard: A provably robust defense against adversarial patches via
small receptive ﬁelds and masking. 2021.

[13] Pedro O Pinheiro, Tsung-Yi Lin, Ronan Collobert, and Piotr Doll´ar.
Learning to reﬁne object segments. In European conference on computer
vision, pages 75–91. Springer, 2016.

[14] Wongun Choi and Silvio Savarese. A uniﬁed framework for multi-target
tracking and collective activity recognition. In European Conference on
Computer Vision, pages 215–230. Springer, 2012.

[15] Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. Neural baby talk.
In Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 7219–7228, 2018.

[16] Joseph Redmon and Ali Farhadi. Yolo9000: better, faster, stronger. In
Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 7263–7271, 2017.

[17] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott
Reed, Cheng-Yang Fu, and Alexander C Berg. Ssd: Single shot multibox
In European conference on computer vision, pages 21–37.
detector.
Springer, 2016.

[18] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll´ar.
In Proceedings of the IEEE

Focal loss for dense object detection.
international conference on computer vision, pages 2980–2988, 2017.

[19] Xizhou Zhu, Yuwen Xiong, Jifeng Dai, Lu Yuan, and Yichen Wei. Deep
feature ﬂow for video recognition. In Proceedings of the IEEE conference
on computer vision and pattern recognition, pages 2349–2358, 2017.
[20] Zhuoran Song, Feiyang Wu, Xueyuan Liu, Jing Ke, Naifeng Jing, and
Xiaoyao Liang. Vr-dann: Real-time video recognition via decoder-
assisted neural network acceleration. In 2020 53rd Annual IEEE/ACM
International Symposium on Microarchitecture (MICRO), pages 698–710.
IEEE, 2020.

[21] Mark Buckler, Philip Bedoukian, Suren Jayasuriya, and Adrian Sampson.
Eva2: Exploiting temporal redundancy in live computer vision.
In
2018 ACM/IEEE 45th Annual International Symposium on Computer
Architecture (ISCA), pages 533–546. IEEE, 2018.

[22] Till Kroeger, Radu Timofte, Dengxin Dai, and Luc Van Gool. Fast optical
ﬂow using dense inverse search. In European Conference on Computer
Vision, pages 471–488. Springer, 2016.

[23] Anurag Ranjan and Michael J Black. Optical ﬂow estimation using a
In Proceedings of the IEEE conference on

spatial pyramid network.
computer vision and pattern recognition, pages 4161–4170, 2017.

[24] Yu Feng, Paul Whatmough, and Yuhao Zhu. Asv: Accelerated stereo vi-
sion system. In Proceedings of the 52nd Annual IEEE/ACM International
Symposium on Microarchitecture, pages 643–656, 2019.

[25] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining

and harnessing adversarial examples. ICLR, 2015.

[26] Bita Darvish Rouhani, Mohammad Samragh, Mojan Javaheripi, Tara
Javidi, and Farinaz Koushanfar. Deepfense: Online accelerated defense
In 2018 IEEE/ACM International
against adversarial deep learning.
Conference on Computer-Aided Design (ICCAD), pages 1–8. IEEE, 2018.
[27] Xingbin Wang, Rui Hou, Boyan Zhao, Fengkai Yuan, Jun Zhang, Dan
Meng, and Xuehai Qian. Dnnguard: An elastic heterogeneous dnn
accelerator architecture against adversarial attacks. In Proceedings of
the Twenty-Fifth International Conference on Architectural Support for
Programming Languages and Operating Systems, pages 19–34, 2020.

[28] Ben Sapp and Ben Taskar. Modec: Multimodal decomposable models
for human pose estimation. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pages 3674–3681, 2013.
[29] Sam Johnson and Mark Everingham. Clustered pose and nonlinear
appearance models for human pose estimation. In Proceedings of the
British Machine Vision Conference, 2010. doi:10.5244/C.24.12.

[30] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona,
Deva Ramanan, Piotr Doll´ar, and C Lawrence Zitnick. Microsoft coco:
Common objects in context. In European conference on computer vision,
pages 740–755. Springer, 2014.

[31] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei
In 2009
Li.
ImageNet: A large-scale hierarchical image database.
IEEE Computer Society Conference on Computer Vision and Pattern
Recognition (CVPR), pages 248–255, 2009.

[32] Muzammal Naseer, Salman Khan, and Fatih Porikli. Local gradients
smoothing: Defense against localized adversarial attacks. In IEEE Winter
Conference on Applications of Computer Vision (WACV), pages 1300–
1307, 2019.

[33] Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry.
On adaptive attacks to adversarial example defenses. In H. Larochelle,
M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in
Neural Information Processing Systems, volume 33, pages 1633–1645.
Curran Associates, Inc., 2020.

[34] Haidi Zhu, Haoran Wei, Baoqing Li, Xiaobing Yuan, and Nasser
Kehtarnavaz. A review of video object detection: Datasets, metrics
and methods. Applied Sciences, 10(21):7834, 2020.

[35] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn:
towards real-time object detection with region proposal networks. IEEE
transactions on pattern analysis and machine intelligence, 39(6):1137–
1149, 2016.

[36] Xizhou Zhu, Yujie Wang, Jifeng Dai, Lu Yuan, and Yichen Wei. Flow-
guided feature aggregation for video object detection. In Proceedings of
the IEEE International Conference on Computer Vision, pages 408–417,
2017.

[37] Mason Liu, Menglong Zhu, Marie White, Yinxiao Li, and Dmitry
Kalenichenko. Looking fast and slow: Memory-guided mobile video
object detection. arXiv preprint arXiv:1903.10172, 2019.

[38] Yihong Chen, Yue Cao, Han Hu, and Liwei Wang. Memory enhanced
global-local aggregation for video object detection. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
pages 10337–10346, 2020.

[39] Wenfei Yang, Bin Liu, Weihai Li, and Nenghai Yu. Tracking assisted
faster video object detection. In 2019 IEEE International Conference on
Multimedia and Expo (ICME), pages 1750–1755. IEEE, 2019.

[40] Ping-Yeh Chiang, Renkun Ni, Ahmed Abdelkader, Chen Zhu, Christoph
Studor, and Tom Goldstein. Certiﬁed defenses for adversarial patches. In
8th International Conference on Learning Representations (ICLR), 2020.
(De)randomized smoothing for
In Conference on Neural

[41] Alexander Levine and Soheil Feizi.

certiﬁable defense against patch attacks.
Information Processing Systems, (NeurIPS), 2020.

[42] Sukrut Rao, David Stutz, and Bernt Schiele. Adversarial training against
In European Conference on

location-optimized adversarial patches.
Computer Vision, pages 429–448. Springer, 2020.

[43] Jamie Hayes. On visible adversarial perturbations & digital watermarking.
In 2018 IEEE Conference on Computer Vision and Pattern Recognition
Workshops (CVPR Workshops), pages 1597–1604, 2018.

[44] Yiming Gan, Yuxian Qiu, Jingwen Leng, Minyi Guo, and Yuhao Zhu.
In 2020
Ptolemy: Architecture support for robust deep learning.
53rd Annual IEEE/ACM International Symposium on Microarchitecture
(MICRO), pages 241–255. IEEE, 2020.

[45] Zirui Xu, Fuxun Yu, and Xiang Chen. Lance: A comprehensive and
lightweight cnn defense methodology against physical adversarial attacks
In 2020 25th Asia and South
on embedded multimedia applications.

Paciﬁc Design Automation Conference (ASP-DAC), pages 470–475. IEEE,
2020.

12

Husheng Han received the B.S degree from
Tsinghua University, Beijing, China in 2020. Cur-
rently he is working toward the PhD degree in
the Institute of Computing Technology, Chinese
Academy of Sciences, Beijing, China, and the
University of Chinese Academy of Science, Bei-
jing, China. His current research interests include
machine learning security and domain-speciﬁc
hardware architectures.

Xing Hu received the B.S. degree from
Huazhong University of Science and Technology,
Wuhan, China, and Ph.D. degree from University
of Chinese Academy of Sciences, Beijing, China,
in 2009 and 2014, respectively. She is currently
an associate professor of State Key Laboratory
of Processors, Institute of Computing Technology
(ICT), Chinese Academy of Sciences (CAS), Bei-
jing, China. Her current research interests include
domain-speciﬁc hardware architectures and deep
learning system.

Kaidi Xu received the B.S. and M.S. degrees
from Sichuan University in 2015 and the Depart-
ment of Computer Science at University of Florida
in 2017 respectively and Ph.D. degree at North-
eastern University in 2021. He is currently an
Assistant Professor in Department of Computer
Science at Drexel University, Philadelphia, USA.
His primary research interest is the robustness
of machine learning, including physical adversar-
ial attacks, rigorous robustness veriﬁcation and
certiﬁed defenses.

Pucheng Dang received the B.S degree from
Harbin Institute Of Technology, Harbin, China
in 2019. Currently he is working toward the
PhD degree in the Institute of Computing Tech-
nology, Chinese Academy of Sciences, Beijing,
China, and the University of Chinese Academy
of Science, Beijing, China. His current research
interests include machine learning security and
Computer Vision.

Ying Wang received the B.S and M.S. degree
from School of Astronautics, Harbin Institute of
Technology, Heilongjiang, China in 2007 and
2009 respectively and the PhD degree from
the Institute of Computing Technology, Chinese
Academy of Sciences, Beijing, China in 2014. He
is currently an Associate Professor in State Key
Laboratory of Computer Architecture at Institute
of Computing Technology, Chinese Academy of
Sciences. His research interests primarily focus
on the area of reliable computer architecture and
VLSI design, with an emphasis on memory systems, energy-efﬁcient
accelerators, and approximate/error-tolerant computing.

13

Yanzhi Wang received his B.S. Degree in Elec-
tronic Engineering from Tsinghua University, Bei-
jing, China, in 2009 and the Ph.D. Degree in Com-
puter Engineering from University of Southern
California (USC) in 2014, under the supervision
of Prof. Massoud Pedram. He is currently an
Associate Professor and Faculty Fellow in the De-
partment of Electrical and Computer Engineering,
and Khoury College of Computer Science (Afﬁl-
iated) at Northeastern University. His research
interests include real-time and energy-efﬁcient
deep learning and artiﬁcial intelligence systems, model compression of
deep neural networks (DNNs), neuromorphic computing and non-von
Neumann computing paradigms.

Tianshi Chen received the bachelor’s degree in
mathematics from the Special Class for the Gifted
Yong, University of Science and Technology of
China (USTC), Hefei, China, in 2005, and the
PhD degree in computer science from the Depart-
ment of Computer Science and Technology, Uni-
versity of Science and Technology of China, Hefei,
China, in 2010. He received the China Computer
Federation Distinguished Doctoral Dissertation
Award, in 2011 and the Chinese Academy of Sci-
ences Distinguished Doctoral Dissertation Award,
in 2011 for his PhD work on computational complexity analysis of
evolutionary algorithms. He is currently a professor with the Institute
of Computing Technology, Chinese Academy of Sciences, Beijing, China.
He is also serving as the CEO of a startup called Cambricon Technologies
Corporation Limited, whose commercial processor products are named
“Cambricon”.

Yongwei Zhao recieved the bachelor’s degree
in computer science and technology from the
Huazhong University of Science and Technology,
Wuhan, China, in 2015 and the PhD degree from
the institute of Computing Technology, Chinese
Academy of Sciences, Beijing, China, in 2020.
He is currently an assistant professor at the
Institute of Computing Technology (ICT), Chinese
Academy of Sciences (CAS), Beijing, China. His
research interests primarily focus on the area of
accelerator architecture.

Zidong Du (Member, IEEE) received his B.E. de-
gree from the Department of Electronic Engineer-
ing, Tsinghua University, Beijing, China, in 2011,
and the Ph.D. degree from the Institute of Com-
puting Technology (ICT), Chinese Academy of
Sciences (CAS), Beijing, in 2016. He is currently
an associate professor at Intelligent Processor
Research Center, Institute of Computing Technol-
ogy (ICT), Chinese Academy of Sciences (CAS).
His research interests mainly focus on novel ar-
chitecture for artiﬁcial intelligence, including deep
learning processors, inexact/approximate computing, neural network
architecture, neuromorphic architecture. He has published over 20 top-
tier computer architecture research papers, including ASPLOS, MICRO,
ISCA, TC, TOCS, TCAD. For his innovative works on deep learning
processors, he won the best paper award of ASPLOS’14, Distinguished
Doctoral Dissertation Award of CAS (40/10000), Distinguished Doctoral
Dissertation Award of China Computer Federation (10 per year).

Qi Guo (Member, IEEE) received the B.E. de-
gree in computer science from Tongji University,
Shanghai, China, in 2007, and the Ph.D. de-
gree from the Institute of Computing Technology,
Chinese Academy of Sciences, Beijing, China,
in 2012.,From 2012 to 2014, he was a Staff
Researcher at IBM Research, Beijing. From 2014
to 2015, he was a Postdoctoral Researcher with
Carnegie Mellon University, Pittsburgh, PA, USA.
He is currently a Professor with the Institute
of Computing Technology, Chinese Academy of
Sciences. His research interests include computer architecture, program-
ming models, and machine learning.

