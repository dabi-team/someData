2
2
0
2

r
a

M
2
2

]

M

I
.
h
p
-
o
r
t
s
a
[

1
v
5
4
9
1
1
.
3
0
2
2
:
v
i
X
r
a

sympy2c: from symbolic expressions to fast C/C++
functions and ODE solvers in Python

Uwe Schmitta,b, Beatrice Moserb, Christiane S. Lorenzb, Alexandre
Refregierb

aScientiﬁc IT Services, ETH Zurich, Binzmühlestrasse
120, Zurich, CH-8092, Switzerland
bInstitute for Particle Physics and Astrophysics, ETH Zurich, Wolfgang-Pauli-Strasse
27, Zurich, CH-8093, Switzerland

Abstract

Computer algebra systems play an important role in science as they fa-
cilitate the development of new theoretical models. The resulting symbolic
equations are often implemented in a compiled programming language in
order to provide fast and portable codes for practical applications. We de-
scribe sympy2c, a new Python package designed to bridge the gap between
the symbolic development and the numerical implementation of a theoretical
model. sympy2c translates symbolic equations implemented in the SymPy
Python package to C/C++ code that is optimized using symbolic transfor-
mations. The resulting functions can be conveniently used as an extension
module in Python. sympy2c is used within the PyCosmo Python package to
solve the Einstein-Boltzmann equations, a large system of ODEs describing
the evolution of linear perturbations in the Universe. After reviewing the
functionalities and usage of sympy2c, we describe its implementation and
optimization strategies. This includes, in particular, a novel approach to gen-
erate optimized ODE solvers making use of the sparsity of the symbolic Jaco-
bian matrix. We demonstrate its performance using the Einstein-Boltzmann
equations as a test case. sympy2c is widely applicable and may prove useful
for various areas of computational physics. sympy2c is publicly available at
https://cosmology.ethz.ch/research/software-lab/sympy2c.html .

Email address: uwe.schmitt@id.ethz.ch (Uwe Schmitt)

Preprint submitted to Astronomy and Computing

March 24, 2022

 
 
 
 
 
 
1. Introduction

Computer Algebra Systems (CAS), such as Mathematica [1] and
SymPy [2], play an important role in scientiﬁc disciplines such as mathematics
and theoretical physics, as they facilitate the development of new or modiﬁed
theories. Most often, the resulting equations are implemented in a compiled
programming language in order to provide fast, robust and portable codes
for practical applications.

In this paper, we describe sympy2c, a new Python package designed to
bridge the gap between the symbolic development and the numerical imple-
mentation of a theoretical model. For this purpose, sympy2c translates sym-
bolic equations implemented within the Python CAS SymPy to fast C/C++
code that can then be used from Python as an extension module.

The development of sympy2c started in the ﬁeld of computational cos-
mology as part of the Python package PyCosmo1 [3, 4, 5]. The concept of the
just-in-time compiler HOPE [6] preceded the development of sympy2c. Among
other features, PyCosmo oﬀers a fast solver for Einstein-Boltzmann equations,
a large system of ODEs which describes the evolution of linear perturbations
in the Universe [7, 8]. To improve the code structure of PyCosmo and to make
the code generator available to a wider audience, we separated the code cre-
ation part from the other functionalities of PyCosmo and thus created the
separate Python package sympy2c.

for example by supporting special
interpolation and numerical

sympy2c extends the basic C/C++ code generation functionalities
of SymPy,
in-
solution of ODEs. We par-
tegration,
ticularly optimised the sympy2c code generator for high dimensional
stiﬀ ODEs with a sparse Jacobian matrix. A direct solver for gen-
eral sparse linear systems
the ODE solver and
sympy2c is publicly available at
will be described below in detail.
https://cosmology.ethz.ch/research/software-lab/sympy2c.html.

functions, numerical

is at the heart of

This paper is organised as follows. In Section 2, we introduce the role of
Python in scientiﬁc programming, performance related aspects and the role
of sympy2c within this context. In Section 3, we give an overview of func-
tionalities oﬀered by sympy2c and how to use the library. We list resources
to access the sympy2c package, its source code and documentation in Sec-
tion 4. In Section 5, we discuss the implementation and optimization details

1https://cosmology.ethz.ch/research/software-lab/PyCosmo.html

2

of sympy2c. In Section 6, we demonstrate the performance of sympy2c. In
Section 7, we summarise our conclusions.

2. Fast Scientiﬁc Computation with Python

Python is an interpreted, high-level, general-purpose programming lan-
guage with a focus on readability and eﬃcient programming. Nowadays, it
plays an important role in many scientiﬁc disciplines. Factors for its suc-
cess in science are its permissive open source license, its extendability using
C/C++, and the availability of high-quality and easy-to-use scientiﬁc pack-
ages.

Fundamental packages such as numpy and scipy are featured in multi-
disciplinary scientiﬁc journals [9, 10]. Python libraries for machine learning,
such as TensorFlow [11], PyTorch [12] and scikit-learn [13] are widely
used [14].

Another important package is SymPy, an open source computer algebra
system (CAS) written in Python. SymPy can be used directly as a Python
library, and does not implement its own programming language. This allows
extending SymPy in Python and using SymPy with other Python libraries,
without the diﬃculties caused by crossing language barriers.

Python is, in particular, widely used in astrophysics. Examples include
astropy [15, 16], a Python package for astronomy that counts more than
5800 citations at Web of Science 2 as of March 2022, and the data processing
pipelines of the Event Horizon Telescope [17], the LIGO observatory [18]
and the Legacy Survey of Space and Time (LSST) [19]. We refer the reader
also to the article [20] which provides an overview of the role of Python in
astronomy and science.

Since Python is an interpreted and dynamically typed programming lan-
guage, it oﬀers great ﬂexibility and supports an agile development process.
This, however, also implies reduced speed and higher memory consumption
during run-time, features that have an impact in many scientiﬁc applications.
To circumvent this, solutions to increase execution speed have been de-

veloped and can be classiﬁed as follows:

• Implementation of parts of the code in a lower level language, such as
C/C++ or Rust, or binding Python to existing C/C++ code. For ex-

2https://clarivate.com/products/web-of-science/

3

ample, large parts of numpy [9] and scipy [10] consist of a thin Python
layer on top of BLAS [21] and other established numerical libraries.
Notable tools to simplify bindings between Python and lower level lan-
guages include Cython [22], swig [23], pybind11 [24], f2py [25] or PyO3.

• Using just-in-time compilation as provided by HOPE [6], numba [26] or

PyPy [27].

• Automatic translation of Python code to C/C++, as supported by

Pythran [28].

The sympy2c package ﬁts in the third category but, in contrast to the
mentioned tools, creates C/C++ code from SymPy expressions rather than
from existing Python functions. The package pyodesys [29] follows a similar
approach to generate C/C++ code for evaluating the right hand side of an
ODE and its Jacobian matrix. pyodesys delegates these functions to exist-
ing ODE solvers, such as pygslodeiv2 [30], which do not take sparsity into
account. The function autowrap of SymPy allows compilation of expressions
to diﬀerent back-ends such as C or FORTRAN. However, autowrap does not
generate code for integrals or ODEs without an explicit symbolic solution
and was thus not suﬃcient to be used within PyCosmo [3, 4, 5]. sympy2c
diﬀers from the mentioned tools by oﬀering a very fast ODE solver by con-
sidering sparsity in the Jacobian and by implementing routines for numerical
integration and spline interpolation.

3. Functionalities

In this section, we describe and demonstrate the main function-
For a detailed documentation of the sympy2c
alities of sympy2c.
to the sympy2c online documentation,
API we
available at
https://cosmo-docs.phys.ethz.ch/sympy2c/. More details about the in-
ner workings of sympy2c follow in Section 5.

refer

3.1. Functions

The steps to create and use a function are as follows:

1. We declare a function by providing the symbolic expression which the

function should evaluate and the arguments the function takes.

2. We declare an extension module and add this function to the module.

4

3. We trigger the code generation process and the compilation of the cre-

ated code.

4. We import the compiled Python extension module.
5. We can now call the declared C-Function as a function within this

module from Python.

We demonstrate the usage pattern of sympy2c in Listing 1 where we create
and use a Python extension module with a function to compute the volume
of a cylinder V = hπr2 given its height h and radius r:

1 from sympy2c import symbols, Function, Module
2 import numpy as np
3
4 r, h = symbols("r h")
5
6 module_decl = Module()
7 f = Function("volume_cylinder", h * np.pi * r ** 2, r, h)
8 module_decl.add(f)
9

10 imported_module = module_decl.compile_and_load()
11 print(
12
13
14 )

"the volume of a cylinder of radius 1 and height 2 is",
imported_module.volume_cylinder(1.0, 2.0))

Listing 1: Example of function declaration in sympy2c.

• Line 4: Contrary to Mathematica, symbols are not ﬁrst-class citizens

in Python, thus we have to declare r and h.

• Line 6: This declares an extension module.

• Line 7: We declare a function named "volume_cylinder" which com-
putes the value of h * pi * r ** 2 and takes the arguments r and
h.

• Line 8: We add this function to the extension module

• Line 10: Here we trigger code generation and compilation of the
generated code. We also import the generated extension module as
imported_module.

5

• Line 12: Now the function named volume_cylinder is available as part

of the imported_module module.

3.2. Integrals

An important feature of sympy2c is the creation of C/C++ code for
the numerical computation of integrals. sympy2c oﬀers a function Integral
which takes an expression, the integration variable and expressions for the
lower and upper integration limits. When used, for example within a sympy2c
Function, sympy2c creates C/C++ code to compute a numerical approxi-
mation.

This is especially useful when a closed form of the anti-derivative is
unknown or not computable by SymPy.
Internally, sympy2c calls well-
established QUADPACK [31] routines available in the GNU Scientiﬁc Library
(gsl)[32]. These routines also support computation of indeﬁnite integrals.

The function Integral from sympy2c returns a symbolic function which
can be used as any other expression but will later be translated to a routine
for the numerical approximation of the integral.

0

Listing 2 shows an example of how to compute the gaussian integral
−∞ e−t2
R

dt with sympy2c:

1 from sympy2c import symbols, Function, Integral, Module
2 import numpy as np
3
4 t = symbols("t")
5
6 integral = Integral(exp(-(t ** 2)), t, -oo, oo)
7 module_decl.add(Function("gauss", integral))
8
9 imported_module = module_decl.compile_and_load()

10 gauss_integral = imported_module.gauss()
11 print(
12
13
14 )

"the numerical error is",
abs(gauss_integral - np.sqrt(np.pi)

Listing 2: Numerical computation of an indeﬁnite integral.

6

• Line 6: This deﬁnes the symbolic integral

dt. t is the integra-

tion variable and the symbol oo is used by SymPy to represent ∞.

∞

−∞ e−t2
R

• Line 7: We add the function gauss which computes the given integral

and takes no arguments.

• Line 10: We call the function gauss from Python, this will now execute

the numerical integration.

3.3. Cubic Spline Interpolation

Interpolation functions can be helpful to speed up numerical computa-
tions. sympy2c oﬀers a function InterpolationFunction1D which will cre-
ate C/C++ code to call spline interpolation from gsl. Such interpolation
functions can also be used within the integrand or in the limits for numerical
integration as presented previously in Section 3.2 or as a term in the right
hand side of the symbolic representation of an ODE as introduced later in
Section 3.4.

Listing 3 showcases how this is supported within sympy2c:

InterpolationFunction1D, Module)

1 from sympy2c import (symbols, Function,
2
3 import numpy as np
4
5 t = symbols("t")
6 cos_approx = InterpolationFunction1D("cos_approx")
7 module_decl.add(Function("f", cos_approx(t ** 2), t))
8
9 imported_module = module_decl.compile_and_load()

10
11 xi = np.linspace(0, 1.0, 11)
12 imported_module.set_cos_approx_values(xi, np.cos(xi))
13 print(
14
15
16 )

"interpolation error at x=0.5 is",
abs(imported_module.f(0.5) - np.cos(0.5 ** 2))

Listing 3: Using interpolation functions.

7

• Line 6: This declares an interpolation function with the given name. It
can be used as any other symbolic function, e.g. sympy.sin. Right now
this serves as a "place holder function" and the user must provide ap-
propriate values for the actual interpolation of the compiled extension
module (see Line 12).

• Line 7: We add the function f which uses the interpolation function

and computes cos_approx(t ** 2).

• Line 12: After compilation and import, the module contains a function
set_cos_approx_values (this name is derived from the name we spec-
iﬁed in Line 6) to setup the interpolation. Here we provide the values
for the xi values 0.0, 0.1, . . . , 1.0.

• Line 15: We check the impact of the interpolation on the actual result.

3.4. Ordinary diﬀerential equations

sympy2c also generates eﬃcient code for the numerical solution of stiﬀ
and non-stiﬀ ordinary diﬀerential equations using the LSODA3 algorithm [33].
LSODA automatically switches between the Adams-Bashford method [34] for
non-stiﬀ and the BDF4 method [35] for stiﬀ time domains.

We used this method to replace the existing hand-crafted BDF solver
from PyCosmo to beneﬁt from the robust and eﬃcient step-size control as
well as from the detection of stiﬀness and automatic adaption of the order of
the two LSODA integrators.

To demonstrate this feature, we consider the Robertson problem [36, 37], a
common example of a stiﬀ equation describing the kinetics of an autocatalytic
chemical reaction of three reactants with concentrations y1, y2 and y3. This
problem is often used as a test problem to compare solvers for stiﬀ ODEs.
The equations for the Robertson problem are as follows:

˙y1 = −k1y1 + k3y2y3
˙y2 = k1y1 − k2y2 − k3y2y3
˙y3 = k2y2
2,

3LSODA is a variant of LSODE (Livermore Solver for Ordinary Diﬀerential Equations)

with Automatic method switching

4Backward Diﬀerentiation Formula

8

where values for the reaction coeﬃcients are given by k1 = 0.04, k2 = 3 · 107
and k3 = 104.

Listing 4 shows how to implement this ODE using sympy2c:

1 import numpy as np
2 from sympy_to_c import Module, OdeFast, symbols
3
4 y1, y2, y3, t = symbols("y1 y2 y3 t")
5 k1, k2, k3 = 1e-4, 3e7, 1e4
6 y1dot = -k1 * y1 + k3 * y2 * y3
7 y2dot = k1 * y1 - k2 * y2 - k3 * y2 * y3
8 y3dot = k2 * y2 ** 2
9

10 module_decl = Module()
11 lhs = [y1, y2, y3]
12 rhs = [y1dot, y2dot, y3dot]
13 module_decl.add(OdeFast("robertson", t, lhs, rhs))
14 imported_module = module_decl.compile_and_load()
15
16 y_start = np.array([1.0, 0.0, 0.0])
17 tvec = 0.4 * 10 ** np.arange(0, 6)
18 rtol = 1e-6
19 atol = np.array([1e-8, 1e-8, 1e-10])
20
21 result, diagnostics = imported_module.solve_fast_robertson(
22
23 )
24 print(result)

y_start, tvec, rtol=rtol, atol=atol

[[1.00000000e+00 0.00000000e+00 0.00000000e+00]
[9.99640065e-01 3.33213355e-12 1.20024984e-15]
[9.96047827e-01 3.32015942e-12 1.31485884e-14]
[9.60826498e-01 3.20275499e-12 1.28035090e-13]
[6.70346206e-01 2.23448735e-12 9.17743119e-13]
[1.83165556e-02 6.10551854e-14 1.66613769e-12]]

Listing 4: Numerical solution of the Robertson ODE using sympy2c.

9

• Lines 6–8: These are the Robertson ODE equations.

• Line 13: Declaration to compile the ODE solver with sympy2c. We
provide a name for the ODE, the time variable, a list of state variables
(here named lhs) and the list or right-hand-side expressions of the
ODE.

• Lines 17–19: Declaration of initial values, time grid for evaluation and

tolerance settings.

• Lines 21–24: Finally solve the ODE and print the results.

4. Usage

The sympy2c package is hosted on https://pypi.org/project/sympy2c

and hence can be installed using pip install sympy2c.

The

source

code

for

sympy2c

is

publicly

hosted

https://cosmo-gitlab.phys.ethz.ch/cosmo_public/sympy2c
licensed under GPLv3.

at
and

To reduce the package size and to avoid potential

license conﬂicts,
sympy2c will download and compile external C code, such as the GNU
The documenta-
Scientiﬁc Library [32], during the ﬁrst invocation.
tion is available at https://cosmo-docs.phys.ethz.ch/sympy2c/ and
https://cosmology.ethz.ch/research/software-lab/sympy2c.html

5. Implementation

In this section, we describe the main features of the implementation of
sympy2c. Since the fast ODE solver is at the heart of sympy2c and was
one of the major drivers when implementing the package, we present its
optimization strategy in more detail.

5.1. Python Extension Modules

As mentioned in Section 2, Python can be extended using extension mod-
ules [38]. The purpose of this method is either to improve performance of
critical parts of a program, or alternatively to use existing external C/C++
code.

Instead of implementing extension modules directly, programmers can
use Cython [22] which is a super-set of the Python language adding support

10

for optional type declarations for variables, function arguments and return
values. The Cython project oﬀers tools to translate Cython source code into
C/C++, including the code required to interact with the Python interpreter.
Furthermore, using Cython to implement extension modules helps to avoid
errors due to reference counting of Python objects and the created code com-
piles on all major operating systems and plays well with all Python versions
≥ 2.6 without the need to adapt the original Cython source code.

sympy2c uses Cython and its tools internally to make the generated
C/C++ code accessible from Python and to create code which is indepen-
dent of changes between diﬀerent Python versions or operating systems and
compilers.

5.2. The fast ODE solver

Implicit solvers for stiﬀ ODEs require to solve a linear equation involv-
ing the Jacobian matrix of the right hand side of the ODE at each time
step. These systems are often sparse with a structure that depends on the
interactions of the components of the ODE.

A commonly used tool to solve dense linear systems is the LUP decom-
position [39] which factors a matrix A as A = LUP where L is a lower
triangular matrix, U is an upper triangular matrix and P is a permutation
matrix. This decomposition takes O(n3) operations for a matrix of size n×n.
Since P −1 = P T for permutation matrices, solving Ax = b can be performed
eﬃciently by ﬁrst solving Lz = P T b and then Ux = z. Since both L and U
are lower (respectively upper) triangular matrices, both steps involve forward
(respectively backward) substitutions only.

To solve such systems, LSODA uses LAPACK’s [40] routines dgetrf to
compute the LUP decomposition of general matrices, and dgbtrf for banded
matrices. LSODA does not support other sparse matrix structures. Due to
the run-time complexity of O(n3), the LUP decomposition dominates the
overall run-time of LSODA for larger systems with a non-banded Jacobian.
sympy2c is able to gain major speed improvements by replacing the
dgetrf routine with a specialised and fast implementation which considers
the a-priori known sparsity structure derived from the symbolic representa-
tion of the ODE.

5.2.1. Loop unrolling in the linear solver

As an introduction into the code generator, we ignore the permutations

in the LUP decomposition, and ﬁrst focus on an LU decomposition.

11

sympy2c unrolls loops appearing in the computation of the LU decompo-
sition. To illustrate the idea, we assume an identity matrix P and n = 4 for
a matrix



M =



(1)

1 x 0 0
1 2 3 4
y 0 1 1
0 0 x y









The ﬁrst step of the LU decomposition of M consists then of the following
nested loops:

for (k = 0; k < n - 1; k ++)

for (int i= k + 1; i < n; i++) {

m[i][k] /= m[k][k];
for (int j= k + 1; j < n; j++)

m[i][j] -= m[i][k] * m[k][j]

}

Using dedicated variables for the matrix entries instead of arrays, and un-
rolling the loops during code generation, the previous code can be trans-
formed to

double m_0_0 = 1.0;
double m_0_1 = x;
...
m_1_0 /= m_0_0;
m_1_1 -= m_1_0 * m_0_1;
m_1_2 -= m_1_0 * m_0_2;
m_1_3 -= m_1_0 * m_0_3;
m_2_0 /= m_0_0;
...
m_3_2 -= m_3_1 * m_1_2;
m_3_3 -= m_3_1 * m_1_3;

Since m0,2 = m0,3 = m2,1 = m3,0 = m3,1 = 0, sympy2c reduces the number
of computations by generating

m_1_0 /= m_0_0;
m_1_1 -= m_1_0 * m_0_1;
m_2_0 /= m_0_0;
m_2_1 -= m_2_0 * m_0_1;

12

m_2_1 /= m_1_1;
m_2_2 -= m_2_1 * m_1_2;
m_2_3 -= m_2_1 * m_1_3;

The ﬁrst implementation using for loops and arrays required 14 integer ad-
ditions, 14 integer comparisons and 31 ﬂoating point operations, whereas the
last specialized implementation requires 11 ﬂoating point operations only and
no integer additions or comparisons.

5.2.2. Permutation handling

In the above example, we ignored the P matrix for permuting rows for
In practice however, permuting rows to implement
the sake of simplicity.
partial pivoting is necessary to control numerical errors [39] and cannot be
ignored. To check if we need to swap rows, the LUP solver checks for every
row if the corresponding element on the diagonal has a higher magnitude
than the elements in the same column below the diagonal. If this is not the
case, rows are swapped.

The mathematical formulation to detect swapping is

∃k > i |mki| > |mii|.

(2)

This challenges our approach, since the values of mij are updated during the
LUP decomposition and cannot be eﬃciently computed in advance.

We use sympy2c within PyCosmo to solve the same system with varying
parameters over and over again. Therefore, we implemented the following
adaptive strategy to mitigate this problem:

1. Try to solve the linear system Ax = b with the optimized solver without
pivoting. The specialised solver implements the necessary checks if
permutations are required and falls back to a general LUP solver if
required. In this case we record required permutations.

2. Afterwards, we generate and compile more optimized solvers for AP T

i =

bP T
i

for recorded permutations Pi.

3. In the next run, the solver switches between the existing specialized
solvers if feasible. In case changes in the parameters of the ODE require
a previously not appearing permutation, we fall back to the general
solver as in step 1 and record permutations.

4. Continue with step 2.

13

Our experiments to solve the Einstein-Boltzmann equations with varying
parameters have shown that only very few of the described iterations are
required to capture the involved permutations. This is also the case for
physically very unlikely parameter combinations which potentially can arise
in MCMC sampling [41].

To reduce the number of permutations required, we relaxed the check

above with a conﬁgurable security factor C > 1 to

∃k > i |mki| > C |mii|.

(3)

The motivation behind this change is that we assumed that numerical
issues most likely arise if the aﬀected matrix entries diﬀer on diﬀerent orders
of magnitude. We used C = 5 or C = 10 in our experiments, and observed
a reduction of row swaps without signiﬁcant diﬀerences between computed
ODE solutions.

To further speed up the fallback LUP solver, we implemented a variant
which considers an a-priori known banded structure in the symbolic represen-
tation of the linear system. This avoids looping over known zero entries but
at the cost of tracking band limits during matrix updates in the LUP algo-
rithm. This functionality is useful in our applications, but can be switched
oﬀ since it increases run-time in case the given system is not banded.

5.2.3. Splitting

Large systems can create C/C++ functions of several millions lines of
code for the unrolled LUP solvers. This can challenge the optimizer of the
compiler resulting in long compilation times and high memory consumption.
Our approach to mitigate these issues is to split a linear system Mx = b into
uncoupled separate systems using Schur-complements:

1. We split the matrix M into blocks A, B, C, D with square matrices A
and D (which may have diﬀerent sizes) and also split x and b accord-
ingly:

A B
C D(cid:19) (cid:18)
2. Using block-wise Gaussian elimination, we can solve this system in two

x1
x2(cid:19)

b1
b2(cid:19)

Mx =

(4)

=

(cid:18)

(cid:18)

steps:

(A − BD−1C) x1 = b1 − BD−1b2

D x2 = b2 − Cx1

(5)
(6)

14

The code generator can compute the involved matrices symbolically and ﬁ-
nally create two smaller C/C++ functions instead of one larger function.
sympy2c can apply this idea recursively to create more and smaller functions
in the generated code.

Another beneﬁt is that the fallback general LUP solver now operates on
smaller systems. The solution time can thus be signiﬁcantly less aﬀected in
case arising permutations are not considered already:
instead of solving a
system of size n having run-time O(n3), splitting the system of size n into
two uncoupled systems of size n

2 reduces the run-time by a factor of 4.

The drawback of this approach is reduced pivoting: in the extreme case
of splitting a matrix M of size n×n into n uncoupled solvers, sympy2c would
not consider pivoting at all. We did not experience precision issues in our
experiments for reasonable block sizes.

5.3. Code generation optimizations

Since SymPy is implemented in Python, extensive symbolic manipulations
performed by sympy2c can slow down the code generation process. This
especially applies for larger ODE systems. Another factor aﬀecting the run-
time of code involving sympy2c is the involved compilation of the generated
C/C++ code. To improve run-time in both cases, sympy2c extensively uses
disk-based caches to avoid repetitive computations such that speed is sig-
niﬁcantly improved for following executions and for smaller modiﬁcations of
symbolic expressions.

To improve the performance of symbolic inversion of matrices needed in
the splitting approach, we replaced the inv function from SymPy by recursive
application of the following equation for M of size n × n and quadratic
matrices A of size ⌊ n

2 ⌋ and D of size ⌈ n
2 ⌉

M =

A B
C D(cid:19)

(cid:18)

−1

=

R =

A−1 + A−1BRCA−1 −A−1BR

−RCA−1
−1

(cid:18)
D − CA−1B

R

(cid:19)

.

(7)

(8)

(cid:0)

(cid:1)

6. Performance

6.1. Setup

To test the performance of sympy2c, we consider the numerical solution of
the Einstein-Boltzmann equations [7, 8] implemented in PyCosmo [4, 3]. This

15

is a system of ﬁrst-order linear homogeneous diﬀerential equations describing
the evolution of linear perturbations in the Universe. The overall structure
of the equation system is of the form

y′(t) = J(t)y(t)

(9)

where y is a vector of perturbation ﬁelds, prime denotes derivative with
respect to a time variable t, and J is a time dependent Jacobian matrix.
Generally y also depends on the wave number k, so this equation needs to
be solved for a vector of k values.

These equations are crucial for accurate cosmological model predictions.
The radiation ﬁelds, photons’ temperature and polarization and (massless)
neutrinos’ temperature, need to be described as an inﬁnite hierarchy of mul-
tipoles, which are truncated to ﬁnite sums of length l + 1 to allow numerical
solutions. Thus, the size of the ODE system depends on a parameter l_max
which leads to a system of size 5 + 3 × (l_max + 1). In practical cases, the
resulting dimension of pertubation ﬁelds y can be several hundreds. This
large dimensionality in addition to the stiﬀ nature of the equations make
their fast numerical solution challenging. For a theoretical analysis of this
system of equations we refer to [42].

We published time measurements for diﬀerent variations of the Einstein-
Boltzmann equations in [3]. Below, we focus on demonstrating and compar-
ing the eﬀects of the discussed optimizations. The presented time measure-
ments were performed on the high performance computing cluster Euler at
ETH Zurich. We allocated a full node equipped with an EPYC 7742 processor
from AMD. Further, we measured timings ﬁve times for every conﬁguration
and always report the fastest of these runs.

As noted above, the system depends on the wave number k. Higher values
of k increase oscillations in the solution, which enforce smaller step-sizes in
LSODA, and thus lead to longer computation times.

We compare run-times of diﬀerent k ∈ {10−5, 0.1, 1, 10} hMpc

l_max ∈ {10, 50, 100} resulting in equations
{38, 158, 308}.

systems of

−1

and
size n ∈

6.2. Time Measurements

Tables 1, 2 and 3 show the execution time measurements for k = 0.1, 1.0

and 10.0 hMpc−1. The presented columns are:

• n is the size of the system.

16

• mode:

– full indicates that we disabled all optimizations and LSODA al-

ways uses the fallback general LUP solver.

– banded indicates that we disabled all optimizations and LSODA
uses the fallback LUP solver with the optimizations for the banded
structure of the Jacobian matrix as described before.

– optimized refers to using the optimized linear solver using unrolled

loops and avoiding computations involving known zeros.

• TLUP is the total time spent in the full LUP linear solver. This solver is
used when the optimized solver is disabled (modes full and banded ), or
when the optimized solver encounters an unknown row permutations
and switches to the fallback LUP solver (mode optimized ). Reporting
the value 0.00 in optimized mode indicates that the fallback solver was
not required during solving the ODE system.

• Toptim is the total time spent in the optimized linear solver.

• Ttotal is the overall time required to solve the diﬀerential equation.
In addition to the time spent in solving linear equations measured as
TLUP resp. Toptim, this also includes time spent in the actual LSODA
algorithm.

• S is the achieved speedup to solve the ODE. This factor describes the

reduction in run time compared to the baseline mode full.

Tables 1, 2 and 3 show that the optimized solver spends no measurable
time in the fallback LUP solver, indicating that no row permutations were
required to ensure numerical precision. The speed-up we achieved is almost
independent of k but signiﬁcantly inﬂuenced by the size n of the system.

We did not ﬁnd any numerical diﬀerence in the computed solutions for
the diﬀerent linear solvers. This is not surprising since the diﬀerent solvers
just reduce the number of computations involving zeros and else run the same
algebraic operations in the same order.

17

Table 1: Timings for k = 0.1 hMpc

−1

n mode
full
38
banded
optimized

TLUP[s]

4.53 · 10−2
1.86 · 10−2
0.00

158

308

full
banded
optimized

full
banded
optimized

3.28
1.82
0.00

2.65 · 101
1.29 · 101
0.00

Toptim[s]

2.16 · 10−3

7.30 · 10−3

1.71 · 10−2

Ttotal[s]

5.01 · 10−2
2.32 · 10−2
6.76 · 10−3

S
1.00
2.15
7.41

3.29
1.83
1.80 · 10−2

1.00
1.80
183.36

2.66 · 101
1.30 · 101
3.71 · 10−2

1.00
2.05
716.66

Table 2: Timings for k = 1.0 hMpc

−1

n mode
full
38
banded
optimized

TLUP[s]

4.23 · 10−1
1.68 · 10−1
0.00

158

308

full
banded
optimized

full
banded
optimized

2.57 · 101
1.44 · 101
0.00

2.07 · 102
1.05 · 102
0.00

Toptim[s]

1.70 · 10−2

6.83 · 10−2

1.38 · 10−1

Ttotal[s]

4.65 · 10−1
2.08 · 10−1
5.14 · 10−2

2.58 · 101
1.46 · 101
1.65 · 10−1

2.07 · 102
1.06 · 102
2.97 · 10−1

S

1.00
2.24
9.04

1.00
1.77
156.50

1.00
1.96
697.21

18

Table 3: Timings for k = 10 hMpc

−1

n mode
full
38
banded
optimized

58

full
banded
optimized

158

full
banded
optimized

TLUP[s]

Toptim[s]

3.97
1.63
0.00

2.38 · 102
1.43 · 102
0.00

1.99 · 103
1.01 · 103
0.00

1.71 · 10−1

5.82 · 10−1

1.37

Ttotal[s]
4.35
2.00
5.00 · 10−1

2.39 · 102
1.44 · 102
1.37

1.99 · 103
1.01 · 103
2.88

S
1.00
2.18
8.70

1.00
1.66
175.39

1.00
1.97
691.24

6.3. Impact of the Fallback LUP solver

To trigger the use of the fall-back solver we had to choose k =
10−5 hMpc−1. As shown in table 4, in this case the values in the column
TLUP are non-zero in the optimized mode. The speed-up of the optimized
solver is reduced signiﬁcantly in this situation.

Table 4: Timings for k = 10−5 hMpc

−1

, using the LUP fallback solver

n mode
full
38
banded
optimized

58

full
banded
optimized

TLUP[s]

5.22 · 10−3
3.50 · 10−3
1.65 · 10−3

3.47 · 10−1
1.93 · 10−1
1.44 · 10−1

158

full
banded
optimized

3.18
1.15
0.82

Toptim[s]

6.24 · 10−5

8.71 · 10−4

1.16 · 10−3

Ttotal[s]

5.78 · 10−3
4.40 · 10−3
2.29 · 10−3

3.49 · 10−1
1.95 · 10−1
1.47 · 10−1

3.18
1.16
8.26 · 10−1

S
1.00
1.31
2.53

1.00
1.79
2.37

1.00
2.75
3.85

19

Table 5 shows the execution time after updating and recompiling the
generated C/C++ code based on the recorded row-permutations from the
previous run. We can see that the optimized solver now achieves reduction
in execution time similar to the measurements we presented before.

Table 5: Improved timings for k = 10−5 hMpc

−1

after recompilation

n mode
full
38
banded
optimized

58

full
banded
optimized

TLUP[s]

5.22 · 10−3
3.50 · 10−3
0.00

3.47 · 10−1
1.93 · 10−1
0.00

158

full
banded
optimized

3.18
1.15
0.00

Toptim[s]

2.87 · 10−4

1.18 · 10−3

1.96 · 10−3

Ttotal[s]

5.78 · 10−3
4.40 · 10−3
7.35 · 10−4

S
1.00
1.31
7.53

3.49 · 10−1
1.95 · 10−1
2.17 · 10−3

1.00
1.79
189.31

3.18
1.16
3.58 · 10−3

1.00
2.75
881.80

6.4. Runtime scaling

We investigated the run-time scaling of the LSODA solver for diﬀerent
linear solvers as a function of the number of equations n. Figure 5 shows
how the run-time of both variants of the LUP solver (full and banded ) grows
similarly with n, whereas the dependence on n is ﬂatter for the optimized
solver.

We performed polynomial ﬁts of diﬀerent orders and compared them using
the AIC and BIC model selection criteria [43] using the Python package
statsmodels [44]. We ﬁnd that

• the run-times for solving systems of n equations in the full and banded

modes follow

Tmode,k(n) ≈ αmode,k + βmode,k n3
with ﬁtted parameters αmode,k and βmode,k. The goodness of ﬁt resulted
in adjusted r2
adj values ≥ 0.99 for all k values considered.

(10)

20

k

= 0.1

full

banded

optimized

50

75

100

125

150

175

200

225

n

k

= 1.0

1

10

0

10

]
s
[
e
m

i
t

−1

10

−2

10

2

10

full

banded

1

10

optimized

0

10

]
s
[
e
m

i
t

−1

10

3

10

50

75

100

125

150

175

200

225

n

k

= 10.0

full

banded

2

10

optimized

]
s
[
e
m

i
t

10

1

0

10

50

75

100

125

150

175

200

225

n

Figure 5: Run-time comparisons of the diﬀerent optimization levels for diﬀerent values of
the wave number k (in hMpc
). n is the size of the ODE system and the measured time
is the total execution time to compute the ODE solution

−1

21

• the run-time for solving a system of n equations in the optimized mode

grows linearly in n:

Tk(n) ≈ αk + βk n

(11)

with ﬁtted parameters αk and βk. Fits achieved adjusted r2
adj values
≥ 0.98 for k = 1.0, 10.0 hMpc−1 and r2
adj ≥ 0.87 for k = 0.1 hMpc−1.
Residuals for all k appeared randomly distributed. This also indicates
that the lower r2
is caused by measurement
noise and that there is no remaining term growing faster than n which
our ﬁt may have missed.

adj value for k = 0.1 hMpc

−1

Users of sympy2c thus beneﬁt most from our optimized solver for large
systems, but at the cost of upfront code generation and compilation times.

7. Conclusions

We presented the new sympy2c Python package for generating fast
C/C++ code from symbolic expressions. sympy2c supports the creation
of functions and solvers for stiﬀ and non-stiﬀ ordinary diﬀerential equations.
It also implements functions to support numerical interpolation and integra-
tion. sympy2c is general and widely applicable and may thus prove useful
for various areas of computational physics.

Our run-time measurements show that the optimization of the linear
solver yield a signiﬁcant improvement on the overall runtime performance
of the ODE solver, in particular for larger systems. The overhead of code
generation and compilation time limits application scope of the ODE solver
to situations where the same ODE has to be solved many times with vary-
ing coeﬃcients or initial conditions. To mitigate this, we plan to reduce
the compilation times in future versions of sympy2c by creating more and
smaller ﬁles to support the optimization step of the underlying compiler and
to enable parallel compilation of diﬀerent source code ﬁles.

8. Acknowledgements

The authors thank Joel Mayor for useful discussions on extensions of
PyCosmo. This work was supported in part by grant No 200021_192243 from
the Swiss National Science Foundation. sympy2c depends on the Python
packages Cython [22] and sympy [2]. Further sympy2c makes use of the
GNU Scientiﬁc Library (gsl)[32] and the LSODA source code [33]. Many

22

ideas in sympy2c are inﬂuenced by the Python package HOPE [6] and previous
developments in PyCosmo [4, 5].

Benchmarks were run on the Euler computing cluster at ETH Zurich5

provided by the HPC team from Scientiﬁc IT Services of ETH 6.

5https://scicomp.ethz.ch
6https://sis.id.eth.ch

23

References

[1] W. R. Inc., Mathematica, Version 12.3, champaign, IL (2021).

URL https://www.wolfram.com/mathematica

C.

[2] A. Meurer,

al.,
Sympy: symbolic computing in python, PeerJ Computer Science 3
(2017) e103. doi:10.7717/peerj-cs.103.
URL https://doi.org/10.7717/peerj-cs.103

Paprocki,

Smith,

M.

P.

et

[3] B. Moser, C. S. Lorenz, U. Schmitt, et al., Symbolic Implemen-
tation of Extensions of the PyCosmo Boltzmann Solver (12 2021).
arXiv:2112.08395.

[4] A. Refregier, L. Gamper, A. Amara, L. Heisenberg, Pycosmo: An inte-
grated cosmological boltzmann solver (2017). arXiv:1708.05177.

[5] F. Tarsitano, U. Schmitt, A. Refregier, et al., Predicting cosmological

observables with pycosmo (2020). arXiv:2005.00543.

[6] J. Akeret, L. Gamper, A. Amara, A. Refregier, Hope: A python just-in-
time compiler for astrophysical computations, Astronomy and Comput-
ing 10 (2015) 1–8.

[7] C.-P. Ma, E. Bertschinger, Cosmological perturbation theory in the syn-
chronous and conformal Newtonian gauges, Astrophys. J. 455 (1995)
7–25. arXiv:astro-ph/9506072, doi:10.1086/176550.

[8] S. Dodelson, Modern Cosmology, Academic Press, Amsterdam, 2003.

[9] C. R. Harris, K. J. Millman, S. J. van der Walt, et al., Array program-

ming with numpy, Nature 585 (7825) (2020) 357–362.

[10] P. Virtanen, R. Gommers, T. E. Oliphant, et al., Scipy 1.0: fundamental
algorithms for scientiﬁc computing in python, Nature methods 17 (3)
(2020) 261–272.

[11] T.

Developers,

Tensorﬂow,

TensorFlow

can be
this
ps://github.com/tensorﬂow/tensorﬂow/graphs/contr

found in the "Versions"
list
the

page.<br>See

on the
authors <a

full

right

Speciﬁc
list
of

versions
of
side
href="htt
ibutors">on

24

GitHub</a>. (Jan. 2022). doi:10.5281/zenodo.5898685.
URL https://doi.org/10.5281/zenodo.5898685

[12] A.

Paszke,

S.

Gross,

F.

Massa,

et

al.,

Pytorch: An imperative style, high-performance deep learning library,
in: H. Wallach, H. Larochelle, A. Beygelzimer, et al. (Eds.), Advances
in Neural Information Processing Systems 32, Curran Associates, Inc.,
2019, pp. 8024–8035.
URL http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf

[13] F. Pedregosa, G. Varoquaux, A. Gramfort, et al., Scikit-learn: Machine
learning in python, Journal of machine learning research 12 (Oct) (2011)
2825–2830.

[14] S.

Raschka,

J.

Patterson,

C.

Nolet,

Machine learning in python: Main developments and technology trends in data science, machine learning, and artiﬁcial intelligence,
Information 11 (4) (2020). doi:10.3390/info11040193.
URL https://www.mdpi.com/2078-2489/11/4/193

[15] The Astropy Collaboration, Robitaille, Thomas P., Tollerud, Erik J.,
et al., Astropy: A community python package for astronomy, A&A 558
(2013) A33. doi:10.1051/0004-6361/201322068.
URL https://doi.org/10.1051/0004-6361/201322068

[16] A. M. Price-Whelan, B. M. Sipőcz, H. M. Günther,

et al.,

The astropy project: Building an open-science project and status of the v2.0 core package,
Journal
The
doi:10.3847/1538-3881/aabc4f.
URL http://dx.doi.org/10.3847/1538-3881/aabc4f

Astronomical

(2018)

123.

156

(3)

[17] K. Akiyama, A. Alberdi, W. Alef, et al., First m87 event horizon tele-
scope results. iii. data processing and calibration, The Astrophysical
Journal Letters 875 (1) (2019) L3.

[18] B.

P. Abbott,

R. Abbott,

T. D. Abbott,

et

al.,

Gw150914: First results from the search for binary black hole coalescence with advanced ligo,
Phys. Rev. D 93 (2016) 122003. doi:10.1103/PhysRevD.93.122003.
URL https://link.aps.org/doi/10.1103/PhysRevD.93.122003

[19] M. Jurić, J. Kantor, K.-T. Lim, et al., The lsst data management system

(2015). arXiv:1512.07914.

25

[20] D. Faes, Use of python programming language in astronomy and science,
Interdisciplinary Sciences 3 (3) (2012).

Journal of Computational
doi:10.6062/jcis.2012.03.03.0063.
URL http://dx.doi.org/10.6062/jcis.2012.03.03.0063

[21] L. S. Blackford, A. Petitet, R. Pozo, et al., An updated set of basic
linear algebra subprograms (blas), ACM Transactions on Mathematical
Software 28 (2) (2002) 135–151.

[22] S. Behnel, R. Bradshaw, C. Citro, et al., Cython: The best of both
worlds, Computing in Science & Engineering 13 (2) (2011) 31–39.

[23] D. M. Beazley, Swig: An easy to use tool for integrating scripting
languages with c and c++, in: Proceedings of the 4th Conference on
USENIX Tcl/Tk Workshop, 1996 - Volume 4, TCLTK’96, USENIX As-
sociation, USA, 1996, p. 15.

[24] W. Jakob, J. Rhinelander, D. Moldovan, pybind11 – seamless operabil-
ity between c++11 and python, https://github.com/pybind/pybind11
(2017).

[25] P. Peterson, F2py: a tool for connecting fortran and python programs,
Sci-
296–305.

International
ence
(4)
and
arXiv:https://www.inderscienceonline.com/doi/pdf/10.1504/IJCSE.2009.029165,
doi:10.1504/IJCSE.2009.029165.
URL https://www.inderscienceonline.com/doi/abs/10.1504/IJCSE.2009.029165

Journal
Engineering

Computational

(2009)

of
4

[26] S. K. Lam, A. Pitrou, S. Seibert, Numba: A llvm-based python jit com-
piler, in: Proceedings of the Second Workshop on the LLVM Compiler
Infrastructure in HPC, 2015, pp. 1–6.

[27] A. Rigo, S. Pedroni, Pypy’s approach to virtual machine construction,
in: Companion to the 21st ACM SIGPLAN Symposium on Object-
Oriented Programming Systems, Languages, and Applications, OOP-
SLA ’06, Association for Computing Machinery, New York, NY, USA,
2006, p. 944–953. doi:10.1145/1176617.1176753.
URL https://doi.org/10.1145/1176617.1176753

26

[28] S.

Guelton,

Pythran:
Science

Crossing
Engineering

the

python

20

(2)

(2018)

frontier,
83–89.

Computing
doi:10.1109/MCSE.2018.021651342.

in

[29] B. Dahlgren, pyodesys: Straightforward numerical integration of ode systems from python,

of Open

Journal
doi:10.21105/joss.00490.
URL https://doi.org/10.21105/joss.00490

Software

Source

3

(21)

(2018)

490.

[30] Bjorn,

bjodah/pygslodeiv2:

pygslodeiv2-0.9.4

(Apr

2020).

doi:10.5281/zenodo.3760754.

[31] R. Piessens, E. de Doncker-Kapenga, C. W. Überhuber, D. K. Kahaner,
QUADPACK: A subroutine package for automatic integration, Vol. 1,
Springer Science & Business Media, 2012.

[32] M. Galassi, GNU Scientiﬁc Library : reference manual for GSL version 1.12,

Network Theory, 2009.
URL http://www.worldcat.org/isbn/9780954612078

[33] L. Petzold, Automatic selection of methods for solving stiﬀ and nonstiﬀ
systems of ordinary diﬀerential equations, SIAM journal on scientiﬁc
and statistical computing 4 (1) (1983) 136–148.

[34] F. Bashforth, J. C. Adams, An attempt to test the theories of capillary
action by comparing the theoretical and measured forms of drops of
ﬂuid, University Press, 1883.

[35] C. F. Curtiss, J. O. Hirschfelder, Integration of stiﬀ equations, Proceed-
ings of the National Academy of Sciences of the United States of America
38 (3) (1952) 235.

[36] H. Robertson, The solution of a set of reaction rate equations, Numerical

analysis: an introduction 178182 (1966).

[37] E. Hairer, G. Wanner, Solving ordinary diﬀerential equations. ii, volume

14 of (1996).

[38] Extending

Python

with

C

or

C++,

https://docs.python.org/3/extending/extending.html.

27

[39] H. Gene, C. F. Golub, Van loan. matrix computations third edition,

Johns Hopikins Univ Pr (1996).

[40] E. Anderson, Z. Bai, C. Bischof, et al., LAPACK Users’ Guide, 3rd
Edition, Society for Industrial and Applied Mathematics, Philadelphia,
PA, 1999.

[41] D. Foreman-Mackey, D. W. Hogg, D. Lang,

J. Goodman,
emcee: The mcmc hammer, Publications of the Astronomical Society
of the Paciﬁc 125 (925) (2013) 306–312. doi:10.1086/670067.
URL http://dx.doi.org/10.1086/670067

[42] S. Nadkarni-Ghosh, A. Refregier, The einstein–boltzmann equations revisited,
Monthly Notices of the Royal Astronomical Society 471 (2) (2017)
2391–2430. doi:10.1093/mnras/stx1662.
URL http://dx.doi.org/10.1093/mnras/stx1662

[43] K. Burnham, et al., dr anderson. 2002. model selection and multi-model
inference: a practical information–theoretic approach, Ecological Mod-
elling. Springer Science & Business Media, New York, New York, USA.

[44] S. Seabold, J. Perktold, statsmodels: Econometric and statistical mod-

eling with python, in: 9th Python in Science Conference, 2010.

28

