2
2
0
2

y
a
M
8
1

]

M

I
.
h
p
-
o
r
t
s
a
[

1
v
4
0
2
9
0
.
5
0
2
2
:
v
i
X
r
a

Simulating Transient Noise Bursts in LIGO with
gengli

M. L´opez, S. Schmidt and S. Caudill
Nikhef, Science Park 105, 1098 XG,
Amsterdam, The Netherlands
Institute for Gravitational and Subatomic Physics
(GRASP), Utrecht University, Princetonplein 1,
3584 CC Utrecht, The Netherlands
Email: m.lopez@uu.nl
Email: s.schmidt@uu.nl
Email: s.e.caudill@uu.nl

V. Boudart
STAR Institute, Bˆatiment B5,
Universit´e de Li`ege, Sart Tilman B4000
Li`ege, Belgium
Email: vboudart@uliege.be

Abstract—In the ﬁeld of gravitational-wave (GW) interferom-
eters, the most severe limitation to the detection of GW signals
from astrophysical sources comes from random noise, which
reduces the instrument sensitivity and impacts the data quality.
For transient searches, the most problematic are transient noise
−1.
artifacts, known as glitches, happening at a rate around 1min
As they can mimic GW signals, there is a need for better modeling
and inclusion of glitches in large-scale studies, such as stress
testing the searches pipelines and increasing conﬁdence of a detec-
tion. In this work, we employ Generative Adversarial Networks
(GAN) to learn the underlying distribution of blip glitches and
to generate artiﬁcial populations. Taking inspiration from the
ﬁeld of image processing, we implement Wasserstein GAN with
consistency term penalty for the generation of glitches in time
domain. Furthermore, we share the trained weights through the
gengli, a user-friendly open-source software package for fast
glitch generation and provide practical examples about its usage.

Index terms—Generative adversarial networks, gravitational

waves, synthetic data, machine learning.

I. INTRODUCTION

The existence of gravitational-wave (GW) signal from bi-
nary black hole (BBH) coalescence was successfully proven
by Advanced Laser Interferometer Gravitational-Wave Obser-
vatory (LIGO) during the ﬁrst observing run (O1) [1]. After an
upgrade of the detectors to increase their sensitivity, Advanced
LIGO [2] started in November 2016 the second observing
run (O2), which Advanced Virgo [3] joined in August 2017
[4], [5]. Following signiﬁcant upgrades, in April 2019, the
third observing run (O3) was initiated by Advanced LIGO,
and Advanced Virgo [6], [7], [8]. In the coming years, the
improvement of the second generation of interferometers and
the construction of the third generation of detectors, such as
Cosmic Explorer, LISA, and Einstein Telescope, will increase
signiﬁcantly the detection sensitivity [9], [10], [11].

Despite the signiﬁcant improvements acquired in the past
years to isolate the components of the interferometers from
non-cosmic disturbances, LIGO detectors are still susceptible
to transient bursts of non-Gaussian noise, known as “glitches”.
Glitches come in a wide variety of time-frequency-amplitude
morphologies produced by instrumental or environmental

Fig. 1. (Left) Q-transform of a blip glitch retrieved from Gravity Spy. (Right)
Q-transform of a intermediate binary blach hole chirp.

causes. They reduce the amount of analyzable data, biasing
astrophysical detection and parameter estimation, and even
mimic GW signals (see Fig. 1 for an example) [12], [13]. Thus,
it is fundamental to develop robust techniques to identify and
characterize these sources of noise for their elimination.

Due to the overwhelming amount of glitches present in the
LIGO data1, this task goes beyond human ability. An exciting
way around this problem is to construct machine learning
(ML) algorithms to classify their different morphologies. The
main difﬁculty of this approach, besides network design, lies
in the need of having a pre-labeled, fairly regular, data set. In
a pionieering work, Zevin et al. [14] have pursued this goal
building a method to identify transient noise, called Gravity
Spy. It combines the strengths of both humans and computers
to analyze and characterize LIGO glitches and to improve the
effectiveness of GW searches. In this way, volunteers provide
large labeled data sets to train the ML algorithms through
Zooniverse platform, while ML algorithms learn to classify
the rest of the glitches correctly and guide how information is
provided back to participants. In practice, a time series of the
glitch that we wish to classify is fed to the ML classiﬁer that
generates the Q-transform of its input (see [14] for details).
Then, Gravity Spy assigns a class and a conﬁdence value cGS
to the Q-transform of the glitch, where cGS represents how
conﬁdent the algorithm is about its classiﬁcation.

The identiﬁcation of glitches is the ﬁrst step towards a robust

1The rate of glitches can be as large as ≈ 1 min

−1 (see [8] for details).

 
 
 
 
 
 
mitigation of these transient noise. In this investigation we
intend to move further and generate the known classes of
glitches. Our goal is to understand their features by modelling
a population of glitches with Generative Adversarial Networks
(GAN). This does not only allow us to enhance our under-
standing of the morphologies of glitches, but also clears the
way to new various applications in GW data analysis such as:
• Improving glitch classiﬁcation: modelling glitches with
GAN allows us to provide feedback to glitch classiﬁers,
like Gravity Spy, about their classiﬁcation conﬁdence.
• New glitch detection: related to the previous point, we
can detect anomalous glitches from a certain class, that
could imply detecting new classes of glitches.

• Glitch population statistics: by learning the morphologies
of glitches we are able to distinguish them and perform
statistical tests about their population.

• Mock data challenges: we can inject generated glitches

to stress-test state-of-the-art pipelines.

• Improving signiﬁcance of a GW detection: a better under-
standing of glitches allows to increase the conﬁdence of
the probabilistic model we use to identify GW candidates.
This work accompanies the main publication [15], adding
more details on the network architecture and describing the
released code. Moreover, we present our ﬂexible and user-
friendly tool gengli2 for glitch generation. Currently, we aim
to generate blip glitches, but we will extend it to other classes
in future works. The interested reader can ﬁnd more details
about applications and network validation in the other work
of this investigation. A thorough description of blip glitches
is also presented in Section II B of [15].

II. DATA
To train our ML model, we select blips 3 from Livingston
(L1) and Hanford (H1) that have a conﬁdence c1
GS ≥ 0.9,
during the second observing run (O2). However, since the
glitch is surrounded non-stationary and uncorrelated noise,
there is little structure that our ML method can retrieve.
Therefore, we need to extract glitches from the input strain.
For this aim, we employ BayesLine [16] to whiten the glitches
locally and BayesWave [17] to ﬁt and reconstruct the input
signal with wavelet decomposition. The whitening operation
is deﬁned on the frequency domain glitch ˜g as,

˜gW =

˜g
Sn(f )

,

(1)

where Sn(f ) is the power spectral density (PSD) of a
given stretch of data. The number of wavelets employed by
BayesWave and their parameters are data-driven, since this
algorithm employs Reversible Jump Markov Chain Monte
Carlo [18] for this choice to acquire a trade-off between
complexity of the model and quality of the ﬁt.

2The code is released as a Git repository https://git.ligo.org/melissa.lopez/

genglimelissa.lopez/gengli.

3Data retrieved from: https://www.gw-openscience.org/data/

TABLE I
SIZE OF THE BLIP SET FOR EACH DETECTOR IN THE DIFFERENT PHASES OF
THE PRE-PROCESSING: SELECTION, RECONSTRUCTION AND EVALUATION.

Num. blips
c1
GS = 1.0
BW output
Num. blips
c2
GS ≥ 0.9
Num. blips
GS , c3
c2

GS ≥ 0.9

Livingston

Hanford

5540

5461

3654

3291

6768

5612

3407

2587

The input provided to BayesWave is a time series of 2.0 s
long containing the blip centered in the time series. After pre-
processing the time series with BayesWave we crop the output
to obtain the reconstructed blip, removing irrelevant data: each
element of the ﬁnal training set has 938 data points sampled
at 4096 Hz. To evaluate the quality of the reconstruction, we
inject them in real whitened noise and evaluate it with Gravity
Spy classiﬁer, selecting blip glitches with a c2

GS ≥ 0.9.

The reconstruction of BayesWaves is not perfect since, as
we can see in Fig. 2 (top left), there is still some noise
contribution at high frequencies (light blue) that will hinder the
learning of our ML algorithm. To minimize this contribution
we employ regularized Rudin-Osher-Fatemi (rROF) proposed
in [19], that solves the denoising problem, y = g + n, as
a variational problem. n is a noise realization and g is the
smooth reconstruction of a blip, whose solution is

gλ = arg min{R(g) + λ
2

F(g)}

(2)

In this formula, R(g) is the regularization term that con-
strains the data, which refers to the quality of the smooth
reconstruction g, while F(g) is the ﬁdelity term, which mea-
sures the L2-distance between the g glitch and the observed
signal s. λ regularises and controls the relative weight of
both terms in the equation. It is important to note that this
parameter needs to be tuned manually to achieve the desired
level of denoising. We found λ = 0.5 to be a trade-off
between preserving the structure of the glitch and removing the
non-smooth high-frequency contribution. In Fig.2 (top right),
we plot the BayesWaves reconstruction denoised with rROF
(dashed orange), and the denoised characteristic blip (green).
In Fig.2 (bottom), we show the amplitude spectral density
(ASD) of the BayesWaves reconstruction with and without
denoising (grey and dashed orange), as well as the charac-
teristic peak with and without denoising (blue and green)
and the original high-frequency contribution (light blue). We
can observe that we are able to maintain the structure of
the characteristic peak by damping the power of the high-
frequency contribution.

III. METHODOLOGY

A. Generative Adversarial Networks

GANs, ﬁrst introduced by Ian Goodfellow in 2014 [20],
are a class of generative algorithm in which two networks
compete against each other
to achieve realistic image
generation. One network is responsible for the generation

getting better, the JS divergence saturates, leading to vanishing
gradients. This change of paradigm led Arjovsky et al. [23] to
reformulate the optimization problem as:

θopt = arg min

θ

W1(Px∥P˜x)

(3)

where W1 is the Wasserstein distance evaluated between
the true data distribution Px and the fake data distribution P˜x.
This expression can be written as [23]:

θopt = arg min

θ

max
φ∶∣∣D(x,φ)∣∣L≤1

L(φ, θ) with,

L(φ, θ) = −Ex∼Px [D(x, φ)] + E˜x∼P˜x [D(˜x, φ)]

(4)

(5)

where D and G stand for the discriminator and the generator
with their respective parameters φ and θ. Ex∼Px indicates that
the expression has been averaged over a batch of real images.
The same averaging holds over a batch of generated images
in E˜x∼P˜x , where ˜x = G(z, θ), with z being the latent space
vector. The new condition over φ in expression 4 imposes
a new constraint on the form of the discriminator, which
must be 1-Lipschitz continuous [23]. The Lipschitz constraint
is a fundamental aspect of Wasserstein-GANs that must be
satisﬁed in order to properly evaluate the Wasserstein distance.

Unlike the ﬁrst attempt to solve this with clipping gradients
[23], to solve this we implement the idea by Gulrajani et
al. [24]. It consists in adding a regularization term to the
discriminator loss (5), known as gradient penalty (GP):

Ltot = L(φ, θ) + λ GP (φ) with,

GP (φ) = Eˆx∼P˜x [(∣∣ (cid:95)x D(ˆx, φ)∣∣2 − 1)

2

]

(6)

(7)

where λ is known as the regularization parameter, ∣∣ ⋅ ∣∣2

stands to the L2-norm and ˆx is evaluated following:

ˆx = ˜x t + x (1 − t)

(8)

where x is a real image and ˜x is a fake image, with t
uniformly taken between 0 and 1. However, unlike weight
clipping, the gradient penalty term proposed by Gulrajani et
al. [24] cannot penalize everywhere the Wasserstein distance.
Indeed, the penalization takes effect upon the sampled points
ˆx, lying in the straight line between the real samples x and
the fake ones ˜x. In particular, in the very beginning of the
training, the generated samples being quite far from the true
data manifold, so the Lipschitz condition is not enforced until
the generator becomes sufﬁciently good [25].

To overcome this obstacle, Wei et al. [25] have proposed
a second penalization term to add to the loss from Eq. 5.
They suggest to directly penalise the points near any observed
real data point x. Therefore, when the gradient penalty fails
to enforce the Lipschitz continuity in a close vicinity of x,
the new term will constrain the latter. To penalize the real
data manifold, Wei et al. applied their new constraint
to
two perturbed versions of the real samples x. For this, they

Fig. 2. Blip glitch reconstructed with BayesWave and denoised with rROF
algorithm. The regularisation parameter is λ = 0.5.

of new images from random noise, while the other tries to
discriminate the generated images from the real training data.
The generator progressively learns which features of the real
images should be mimicked to foul the discriminator and
stores them into a feature space called the latent space. At
the end of the training, new images are drawn by randomly
taking a latent space vector and passing it to the generator,
which has learned to translate this vector into a realistic
image. This early approach has been shown to work well
under some hyperparameter conﬁgurations [21].

However,

this early GAN paradigm from [20] suffers
from two major problems known as vanishing gradients and
meaningless loss function [22]. Vanishing gradients happen
when the discriminator has a high performance and can
perfectly differentiate between generated and real samples. In
such a case, the gradients from the discriminator become close
to zero, preventing the generator to get valuable feedbacks to
improve the data generation. In [20], the loss is somewhat
proportional to the Jensen-Shannon (JS) divergence (Eq. 5
and 6 from [20]) that is used to measure the distance between
the real and fake data distributions. However, this distance
saturates when the two distributions do not overlap, so it is
difﬁcult to assess the quality of the generated data.

Wasserstein GANs have been developed [23] to address
those issues by making use of another distance estimator
known as the Earth’s mover distance or Wasserstein-1 distance
(W1). Here,
the Wasserstein distance is evaluated through
the discriminator, also known as critic, and increases mono-
tonically while never saturating, providing a meaningful loss
metric even for two disjoint distributions. This distance then
allows to keep track of the quality of the samples as the train-
ing progresses. The Earth’s mover distance being continuous
and differentiable, yields reliable gradients and allows to train
the discriminator optimally. Conversely, as the discriminator is

introduced dropout layers into the discriminator architecture.
The features kept by the dropout layer being random, which
ultimately lead to two different estimates noted D(x
) and
′′
). The penalty, called consistency term, is then applied
D(x
to these two estimates following:

′

CT (φ) = Ex∼Px [max(0, d(D(x
′′
, φ), D (x

+ 0.1 d(D (x

′

, φ), D(x
, φ)) − M

, φ))
′

)]

′

′′

(9)

where d(.,.) is the L2 metric, D stands for the second-
to-last layer output of the discriminator and M
is a constant
value. Wei et al. found that controlling the second-to-last layer
output helps improving the performance of the WGAN. The
ﬁnal discriminator loss implemented in this work is then [25]:
LD = L(φ, θ) + λ1 GP (φ) + λ2 CT (φ)

(10)

′

with λ2 being the consistency parameter, that is used to
tune the weight of the consistency term with respect to the
gradient penalty. That last expression summarizes the recent
improvements brought on the discriminator loss to improve the
performance of WGANs. As for the expression 10 that helps
updating the weights of the discriminator, we need a loss to
train the weights of the generator. For Wasserstein nets, that
loss has not been modiﬁed since its ﬁrst introduction in [23]:
LG = −E˜x∼P˜x [D(˜x, φ)]

(11)

B. Architecture of the networks

The architecture of the networks has been inspired by
[21], which suggests to build a CNN, which has proven
successfully in dealing with images. In the generator structure,
we make use of nearest-neighbour upsampling layers instead
of transposed convolutions to avoid possible artefacts. The
convolution parameters were chosen to be ﬁxed through the
generator layers with a kernel size of 5, no padding and a
stride of 1. We also decide to increase the dilation parameters
across the layers to enlarge the receptive ﬁeld at ﬁxed kernel
size [26]. Batch normalization is also applied after each
convolution layer except the penultimate one [27]. Finally,
LeakyReLU (⋅, α = 0.2) activation function is preferred over
ReLU (⋅) for being differentiable, while the output layer is a
T anh(⋅) layer, constraining the values in the range [−1, 1].

is

structure

composed of

The discriminator

strided
convolutions on which spectral normalization is used, as
suggested in [24]. Dropout layers are triggered after each
convolution layer to regularise the discriminator, with the
exception of the ﬁrst and last layers. The kernel size is set to
5 for all layers, no padding is added to the time series and
LeakyReLU (⋅, α = 0.2) activation is placed after at the end
of each block. The architecture of CT-GAN is shown in [15].

C. Training procedure

During the training of

the CT-GAN algorithm, both
the generator and the discriminator need to be updated at
similar rates to acquire stability and guarantee convergence.

Fig. 3. Graph representing the discriminator loss (blue), generator loss (pink),
CT (green) and GP (orange) penalisation as a function of the epochs.

(Top row) Raw blips plotted as a function of time. (Bottom row) We
Fig. 4.
show the Q-transform representation of the generated raw glitches that have
been rescaled and injected in real noise.

However,
the task of the discriminator is more difﬁcult
since the generated samples that the discriminator intends to
classify are randomly sampled at every iteration [28]. Hence,
we update the discriminator 5 times per generator update.
We employ RMSProp optimizer [29] with a learning rate
−4 for both discriminator and generator, and we train the
= 10
CT-GAN for 500 epochs. Employing GPU TITAN V with
a memory of 96 Gb allowed us to train our model in ≈ 7.75 h.

To represent the behaviour of CT-GAN during training, we
show the generator and the discriminator loss as a function of
the epochs in Fig. 3 (top). We can observe that both networks
stabilize around epoch 100 and continue to oscillate around
values close to zero until the training is complete. This stability
can also be observed in the behaviour of the CT and GP
penalizations in Fig. 3, where both terms tend to zero as the
network stabilizes. The values employed for converge were
CT = 5 and GP = 5, with a dropout rate of 0.6.

IV. IMPLEMENTED FEATURES

Once the CT-GAN model is trained, it is straightforward to
use the generator network to produce random glitches starting
from random samples from its latent space. The output of the
generator, namely a raw glitch, is a whitened glitch evaluated
on a ﬁxed length time grid at a constant sampling rate 4096
Hz and an amplitude in the range [−1, 1]. We can generate a
raw glitch in ∼ 10 ms on a laptop. For visualization, in Fig. 4
(top) we show some examples of the output of the generator
from Handford (H1) population. To obtain them, the user can
run the following lines in Python.

import gengli

g = gengli.glitch_generator(’H1’)
g_whithened = g.get_raw_glitch()

The raw glitch generated by the GAN is often not suitable
for immediate application, so a number of post-processing
steps are required, which have been implemented in gengli:
they are described in ﬁrst subsection. In [15], it was shown
that the CT-GAN-generated glitches have the same statistical
properties as the input population. However, the training data
employed contains anomalous glitches that our model has also
learnt to generate (see Section IV of [15]). In this work we
propose a novel method to discard the anomalous glitches,
based on an “anomaly score”. This will be the aim of next
section.

A. Post-processing

The simplest post-processing step implemented in gengli
is resampling4 the raw glitch at a desired sampling rate. In
order to inject the raw glitch in the noise of the detector of
our choice, it is necessary to re-color the whithened glitch
generated by the GAN. Mathematically,

gC = F

−1

√
(

Sn(f )

′˜gW )

(12)

′

where gW and gC are the whitened and coloured glitches,
respectively, and Sn(f )
represents the PSD of the noise
−1 is the inverse Fourier transform.
to inject the glitch. F
Furthermore, it’s useful to scale the glitch to inject it at a
desired “loudness”, known as signal-to-noise ratio (SNR) ρ.

ρ2 = 4 ∫

fmin

fmax

∣F(g(f ))∣
Sn(f )

′ df

(13)

′ = ρtarget

The coloured glitch is scaled to achieve the given ρtarget
using: g
g In Fig. 5 we plot a raw glitch (blue)
that has been, and a scaled and coloured glitch (pink). Note
that all such functionalities are achieved by the function
g.get_glitch().

ρ

4When upsampling, we make the key assumption that there are no inter-

esting features at frequencies higher than 4096 Hz.

(Left) Raw generated glitch. (Right) Coloured generated glitch with

Fig. 5.
Einstein telescope design sensitivity PSD at ρtarget = 10.

B. Selecting generations

As for any random distributed quantity, any randomly
generated glitch comes with a different degree of “similarity”
with respect to the statistical distribution. We want to make
this notion mathematically precise and deﬁne an anomaly
percentile for each randomly generated glitch. Following our
previous work, we consider three distances between a pair of
glitches:

• Wasserstein distance dW : a standard measure of distance

between distributions, commonly employed in ML.

• Mis-match dmm: a measure of distance based on the

details of the ﬁltering, standard in the GW ﬁeld.

• Cross covariance dcc: we employ the quantity 1−k, where
k is the normalized cross-covariance as deﬁned in [15].
We then generate a benchmark set of Nb glitches from the
generator. For each of the Nb(Nb−1)
pairs of glitches in the
benchmark set, we compute the three distances above. In Fig.
6 we show the distribution for a population of Nb = 1000.

2

For each new glitch being generated, we compute the set
of average distances (dW , dmm, dcc) between the glitch and
the benchmark set and we measure the set of percentiles
(pW , pmm, dcc) of each of the distances with respect to the
benchmark distances. The triple (pW , pmm, dcc) is our novelty
measure for the glitch. This allow us to ﬁlter glitches based on
an anomaly score interval [pmin, pmax]. The code will output
only glitches for which all the three anomaly scores lie within
the given interval.

V. CONCLUSIONS

In this work, we develop a methodology to generate artiﬁcial
time-domain blip glitches data with GAN algorithm. Because
of the heavy pre-processing required to deal with real glitches
(i.e. denoising, reconstructing etc...), this is a valid way to
avoid using real data [15]. Due to the instability of GAN
algorithms, in this particular research, we trained a CT-GAN
[25], a state-of-the-art Wasserstein-GAN, that has shown better
performance in both training stability and accuracy.

The performance of the generated blips has been assessed in
the companion paper [15], where we employ several similarity
distances: Wasserstein distance (dW ), mis-match (dmm) and

[7] R. A. et al., “GWTC-2: Compact Binary Coalescences Observed by
LIGO and Virgo During the First Half of the Third Observing Run,”
Phys. Rev. X, vol. 11, p. 021053, 2021.

[8] R. Abbott et al., “GWTC-3: Compact Binary Coalescences Observed by
LIGO and Virgo During the Second Part of the Third Observing Run,”
11 2021.

[9] D. R. et al., “Cosmic Explorer: The U.S. Contribution to Gravitational-
Wave Astronomy beyond LIGO,” Bull. Am. Astron. Soc., vol. 51, p. 035,
7 2019.

[10] S. B. et al., “LISA Sensitivity and SNR Calculations,” 8 2021.
[11] S. Hild et al., “Sensitivity Studies for Third-Generation Gravitational

Wave Observatories,” Class. Quant. Grav., vol. 28, p. 094013, 2011.

[12] B. A. et al., “Characterization of transient noise in advanced ligo relevant
to gravitational wave signal gw150914,” Classical and Quantum Gravity,
vol. 33, p. 134001, 07 2016.

[13] J. A. et al., “Characterization of the ligo detectors during their sixth
science run,” Classical and Quantum Gravity, vol. 32, no. 11, p. 115012,
2015.

[14] M. Z. et al., “Gravity spy: integrating advanced ligo detector character-
ization, machine learning, and citizen science.” Classical and quantum
gravity, vol. 34 No 6, 2017.

[15] M. L. et al., “Simulating Transient Noise Bursts in LIGO with Genera-

tive Adversarial Networks,” 3 2022.

[16] T. B. L. et al., “Bayesian inference for spectral estimation of gravitational

wave detector noise,” Phys. Rev. D, vol. 91, no. 8, p. 084034, 2015.

[17] N. C. et al., “Bayeswave: Bayesian inference for gravitational wave
bursts and instrument glitches,” Classical and Quantum Gravity, vol. 32,
no. 13, p. 135012, 2015.

[18] J. Green, “Reversible jump Markov chain Monte Carlo computation and
Bayesian model determination,” Biometrika, vol. 82, no. 4, pp. 711–732,
12 1995. [Online]. Available: https://doi.org/10.1093/biomet/82.4.711

[19] A. T. et al., “Total-variation-based methods for gravitational wave
denoising,” Phys. Rev. D, vol. 90, p. 084029, Oct 2014. [Online].
Available: https://link.aps.org/doi/10.1103/PhysRevD.90.084029
[20] I. J. G. et al., “Generative adversarial nets,” in Proceedings of the 27th
International Conference on Neural Information Processing Systems -
Volume 2, ser. NIPS’14. Cambridge, MA, USA: MIT Press, 2014, p.
2672–2680.

[21] A. R. et al., “Unsupervised representation learning with deep
convolutional generative adversarial networks,” in 4th International
Conference on Learning Representations, ICLR 2016, San Juan, Puerto
Rico, May 2-4, 2016, Conference Track Proceedings, Y. Bengio and
Y. LeCun, Eds., 2016. [Online]. Available: http://arxiv.org/abs/1511.
06434

[22] L. Weng, “From gan to wgan,” ArXiv, vol. abs/1904.08994, 2019.
[23] M. A. et al., “Wasserstein generative adversarial networks,” in
Proceedings of
the 34th International Conference on Machine
Learning, ser. Proceedings of Machine Learning Research, D. Precup
and Y. W. Teh, Eds., vol. 70. PMLR, 06–11 Aug 2017, pp. 214–223.
[Online]. Available: http://proceedings.mlr.press/v70/arjovsky17a.html

[24] I. G. et al., “Improved training of wasserstein gans,” in Proceedings
of the 31st International Conference on Neural Information Processing
Systems, ser. NIPS’17. Red Hook, NY, USA: Curran Associates Inc.,
2017, p. 5769–5779.

[25] X. W. et al., “Improving the improved training of wasserstein
gans: A consistency term and its dual effect,” in International
Conference on Learning Representations, 2018. [Online]. Available:
https://openreview.net/forum?id=SJx9GQb0-

[26] A. V. D. O. et al., “Pixel recurrent neural networks,” p. 1747–1756,

2016.

[27] S. I. et al., “Batch normalization: Accelerating deep network training by

reducing internal covariate shift,” ArXiv, vol. abs/1502.03167, 2015.

[28] N. K. et al., “How to train your dragan,” ArXiv, vol. abs/1705.07215,

2017.

[29] T. T. et al., “Lecture 6.5-rmsprop: Divide the gradient by a running
average of its recent magnitude,” COURSERA: Neural networks for
machine learning, vol. 4, no. 2, pp. 26–31, 2012.

Fig. 6.
mark population of 103.

Probability distribution of distances (dW , dmm, dcc) for a bench-

cross-covariance (dcc). The results of these metrics indicate
that our model was able to learn the underlying distribution
of blip glitches despite the presence of anomalies due to
imperfections of the input data set.

In this follow-up work, we present our open-source package
gengli: it provides an easy-to-use interface to the trained
GAN output, and has some additional features such as building
a glitch population with or without anomalies, resampling, re-
coloring and scaling. The long-term goal of this investigation
is to learn other classes of glitches in time domain for various
applications as discussed in [15].

ACKNOWLEDGMENT

V.B.

is supported by the Gravitational Wave Science
(GWAS) grant funded by the French Community of Belgium,
and M.L., S.C and S.S. are supported by the research pro-
gram of the Netherlands Organisation for Scientiﬁc Research
(NWO). The authors are grateful for computational resources
provided by the LIGO Laboratory and supported by the Na-
tional Science Foundation Grants No. PHY-0757058 and No.
PHY-0823459. This material is based upon work supported by
NSF’s LIGO Laboratory which is a major facility fully funded
by the National Science Foundation.

REFERENCES

[1] B. P. A. et al., “Observation of gravitational waves from a binary black
hole merger,” Phys. Rev. Lett., vol. 116, p. 061102, Feb 2016. [Online].
Available: https://link.aps.org/doi/10.1103/PhysRevLett.116.061102
[2] J. A. et al., “Advanced LIGO,” Class. Quant. Grav., vol. 32, p. 074001,

2015.

[3] F. A. et al., “Advanced Virgo: a second-generation interferometric
gravitational wave detector,” Class. Quant. Grav., vol. 32, no. 2, p.
024001, 2015.

[4] B. P. A. et al., “Gw170814: A three-detector observation of
gravitational waves from a binary black hole coalescence,” Phys.
Rev. Lett., vol. 119, p. 141101, Oct 2017.
[Online]. Available:
https://link.aps.org/doi/10.1103/PhysRevLett.119.141101

[5] ——, “GWTC-1: A Gravitational-Wave Transient Catalog of Compact
Binary Mergers Observed by LIGO and Virgo during the First and
Second Observing Runs,” Phys. Rev. X, vol. 9, no. 3, p. 031040, 2019.
[6] B. P. Abbott et al., “GW190425: Observation of a Compact Binary
Coalescence with Total Mass ∼ 3.4M⊙,” Astrophys. J. Lett., vol. 892,
no. 1, p. L3, 2020.

