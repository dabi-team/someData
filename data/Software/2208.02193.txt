2
2
0
2

p
e
S
6
2

]
E
S
.
s
c
[

2
v
3
9
1
2
0
.
8
0
2
2
:
v
i
X
r
a

HIRFUZZ: Detecting High-Level Optimization
Bugs in DL Compilers via Computational Graph
Generation

Haoyang Ma , Qingchao Shen , Yongqiang Tian , Junjie Chen , Shing-Chi Cheung

1

Abstract—Deep Learning (DL) compilers are widely adopted to optimize advanced DL models for efﬁcient deployment at diverse
hardware. However, the optimization of high-level intermediate representation (IR) is found to be error-prone. Testing the
implementation of high-level optimization is challenging. First, high-level IRs are subject to integrity constraints. IRs that violate these
constraints are rejected by DL compilers before entering the optimization stage. Such IRs are not useful to reveal optimization bugs.
Since high-level optimization modules are so implemented to process possible computational graph structures, bug detection for these
modules can be facilitated by feeding DL compilers with diverse computational graphs, which can be readily converted to high-level
IRs. However, generating diverse computational graphs whose converted high-level IRs never violate the integrity constraints required
by high-level optimization is non-trivial. Second, deﬁning test oracles for optimization bugs in DL compilers is challenging.
To address the challenges, we propose HIRFUZZ, a fuzzing technique for bug detection at the optimization of high-level IR in DL
compilers. We propose coverages based on data types, tensor shapes and computation operators to guide diverse computational
graph generation, which is governed by the conformance of IR’s integrity constraints. We note that a primary implementation
requirement of IR optimization is to avoid crash and preserve the computation results after optimization. We, therefore, design effective
test oracles to detect crash and inconsistent computation. Leveraging the diverse computational graph generation and test oracles,
HIRFUZZ has successfully detected 21 new high-level optimization bugs that occur at TVM, with 17 bugs conﬁrmed and 12 ﬁxed.
Further, we construct three baselines using the state-of-the-art DL compiler fuzzers that can cover the high-level optimization stage.
Our experiment results show that HIRFUZZ outperforms these baselines in bug detection ability. Besides, our ablation study and case
study validate the the usefulness of the proposed coverage criteria and test oracles.

Index Terms—Deep Learning Compiler, Software Testing

(cid:70)

1 INTRODUCTION

Deep learning (DL) compilers, such as TVM [1], Glow [2],
XLA [3] and nGraph [4], have shown the effectiveness in
optimizing advanced DL models for efﬁcient model de-
ployment at diverse devices [5]. They take as input a DL
model, extract its computational graph, and re-represent
the DL model using intermediate representations (IRs) [5].
DL compilers consist of multiple compilation stages, which
include high-level and low-level optimizations. DL com-
pilers arrange these two optimizations in order with high-
level optimization ﬁrst and low-level optimization second.
The optimizations aim to compile deep learning models

Shing-Chi Cheung is the corresponding author.

• Haoyang Ma is with the Department of Computer Science and Engineer-
ing, The Hong Kong University of Science and Technology, Hong Kong,
China. Email: haoyang.ma@connect.ust.hk

• Qingchao Shen is with the College of Intelligence and Computing, Tianjin

University, China. Email: qingchao@tju.edu.cn

•

• Yongqiang Tian is with the Cheriton School of Computer Science, Univer-
sity of Waterloo and Department of Computer Science and Engineering,
Canada; and The Hong Kong University of Science and Technology, Hong
Kong, China. Email: yongqiang.tian@uwaterloo.ca
Junjie Chen is with the College of Intelligence and Computing, Tianjin
University, China. Email: junjiechen@tju.edu.cn
Shing-Chi Cheung is with the Department of Computer Science and
Engineering, The Hong Kong University of Science and Technology, Hong
Kong, China. Email: scc@cse.ust.hk

•

into binary executables that can run efﬁciently on target
hardware devices.

Like conventional compilers [6], [7], DL compilers are
prone to bugs. These bugs can cause undesired compiler
behaviors, such as crash, unexpected wrong behavior and
poor performance [8]. These undesired behaviors could re-
sult in catastrophic effects on the correctness and reliability
of mission-critical DL applications (e.g., autonomous driving
cars [9] and aircraft collision avoidance systems [10]).

Techniques have been recently proposed to detect bugs
in DL compilers, including TZER [11], TVMFuzz [12] and
MT-DLComp [13]. Despite preliminary reported success in
bug detection for TVM, they are weak in revealing the
bugs that occur in high-level optimization, which accounts
for 44.92% of the bugs found in DL compilers [8]. TZER
and TVMFuzz [11], [12] are proposed to detect low-level
optimization bugs in a DL compiler with generated low-
level IRs. Since these two techniques test DL compilers by
mutating low-level IR, and low-level IR cannot be used
by high-level optimization, they theoretically cannot detect
bugs in high-level optimization stage. MT-DLComp [13]
tests a DL compiler by constructing mutated DL models.
Since its mutation strategies only insert operators that yield
zero, the kinds of operators and the available places to insert
these operators are limited. Therefore, it cannot generate
models of diverse computational graphs to cover corner
high-level optimization cases. In test oracle design, MT-

 
 
 
 
 
 
DLComp does not take advantage of the language features
of high-level IR and high-level optimizations. As a result,
it cannot effectively detect bugs in high-level optimizations
(We will prove it in section 5).

To bridge the gap, we propose the ﬁrst DL compiler
fuzzing technique that focuses on high-level optimization:
HIRFUZZ. HIRFUZZ is designed to satisfy the following
three objectives: 1) the satisfaction of integrity constraints,
such as type match and tensor shape match, that govern
high-level IR to avoid early crash before invoking optimiza-
tion, 2) the exploration of diversity of computational graph,
and 3) the capability of detecting multiple types of optimiza-
tion bugs. To achieve the ﬁrst objective, HIRFUZZ performs
type checking and shape checking in each operator node in-
sertion by leveraging the information, including type, shape
and connection information, of the existing nodes. After
insertion, HIRFUZZ also updates the information of the new
node for future use. To meet the second objective, HIRFUZZ
incorporates a coverage-guided strategy to explore diverse
operator nodes, operator edges and the combination of
operator type and data type. To meet the third objective,
HIRFUZZ 1) explores functions call chains to test function-
related high-level optimization, and 2) incorporates three
test oracles, two of which are designed purposely for DL
compilers. An example of test oracles is that a model should
not make different prediction after optimization. Besides
functional correctness, HIRFUZZ can also test the robustness
of DL compilers. Speciﬁcally, HIRFUZZ provides an option
of generating invalid computational graphs that violate type
constraints and shape constraints [14]. The option aims to
test whether DL compilers can catch such invalid compu-
tational graphs and throw the expected exceptions. In this
way, HIRFUZZ can also detect bugs caused by incorrect
exception handling.

Following existing works on DL compiler testing, we
evaluate the performance of HIRFUZZ on TVM, which is
the most popular DL compiler. In baseline selection, we
choose 1) TVMfuzz (with lower-case f), preliminary proof-
of-concept application from a bug study [8]. The tool is
chosen because it is the only testing technique focusing
on detecting bugs arising from high-level optimizations in
DL compilers; 2) MT-DLComp [13], a metamorphic testing
framework that can cover high-level optimization stage; and
3) LEMON [15], a fuzzing technique for DL library (e.g.,
Tensorﬂow [16], PyTorch [17]) testing. Our experimental
results show that HIRFUZZ can detect eleven different bugs
in two-day’s execution, while the baselines can only ﬁnd
three in total, two of which are also detected by HIRFUZZ.
Besides this comparison experiment, we examine the useful-
ness of the coverage-guided strategy in generating diverse
computational graph by an ablation study.

In summary, we make three major contributions.
• This work introduces a new focus on testing the most
bug-prone stage, high-level optimization, of DL com-
pilers. We propose a computational graph generation
algorithm and three test oracles to detect bugs of di-
verse root causes in the implementation of high-level
optimization.

• We have implemented HIRFUZZ, a fuzzing technique
targeting at TVM. HIRFUZZ is implemented in 3K lines
of C++ code. It has detected 21 bugs, of which 17

2

have been conﬁrmed, 12 have been ﬁxed and 10 were
previously unknown. Among the 17 conﬁrmed bugs, 14
are highly related to high-level optimizations and three
are about low-level optimization and deployable code
generation. Furthermore, we have conducted an ex-
perimental study to compare HIRFUZZ with TVMfuzz,
MT-DLComp and LEMON, the state-of-the-art testing
techniques that can cover high-level optimization stage.
We have also discussed the utility of each component
of HIRFUZZ.

• We release HIRFUZZ, the details of detected bugs and

experiment data at
https://github.com/haoyang9804/HIRFuzz.

2 BACKGROUND

2.1 DL Compilers

Figure 1 gives an overview of DL compilers. DL compiler
takes as input DL models. These models can be constructed
with the help of DL frameworks, such as Tensorﬂow [16]
and PyTorch [17]. After interpreting the input model’s com-
putational graph (will be detailed in the next subsection),
the DL compiler converts it into high-level IR. Each node
in the computational graph is represented by one or several
IR expressions. For instance, the conv2d (two-dimensional
convolution) node in Figure 1 is represented by nn.conv2d
in the high-level IR of TVM. DL compilers then optimize
the computational graph at the high-level IR. For instance,
a static subgraph independent of inputs can be optimized
through constant folding at IR. After optimization, high-
level IR is translated into low-level IR for further optimiza-
tion. In this step, a high-level IR expression (nn.conv2d in
Figure 1) is expanded into a nested loop of low-level com-
putation instructions. Subsequently, low-level optimizations
are performed to improve efﬁciency. For instance, loop tiling
can be performed at low-level optimization to accelerate
the computation of conv2d on a speciﬁed hardware device.
Finally, low-level IR is translated into deployable code for
diverse hardware using traditional compilers and platforms.

2.2 Computational Graph and High-level IR

A computational graph is a directed graph that expresses
the data ﬂow in computation. High-level IR, also known
as graph-level IR, is an intermediate representation to ex-
press computational graph. In DL community, high-level
IR is widely used for describing computational graph
by DL compilers (e.g., TVM) and also frameworks (e.g.,
ONNX). Figure 2a illustrates the computational graph of
a 2-dimensional convolutional neural network, where vari-
able/constant nodes and operator nodes are colored in blue
and green, respectively. The end of a graph is denoted by
a black ellipse. Arrows in this graph represent data ﬂows.
Speciﬁcally, variable nodes and constant nodes are the start-
ing point of a data ﬂow, passing their data to the next nodes
while operator nodes work as a relay to extend the data ﬂow,
passing the results they calculate. Some DL compilers such
as TVM provide APIs to convert a computational graph
into a high-level IR. For instance, relay.nn.conv2d is the
API to represent the conv2d node with the corresponding
high-level IR expression nn.conv2d. Figure 2b illustrates

3

Fig. 1: Workﬂow of DL compiler

violated by the underlying high-level IRs of the generated
graphs.

3 APPROACH

This section presents the design and underlying methodol-
ogy of HIRFUZZ whose workﬂow is given in Figure 3. HIR-

(a) Computational Graph

(b) High-level IR

Fig. 2: Computational Graph and the Corresponding High-
level IR

TVM’s high-level IR, Relay IR, of the computational graph
in Figure 2a. These APIs simplify the generation of high-
level IR. HIRFUZZ also takes advantage of this convenience
and generates high-level IR by generating computational
graph and utilizing these APIs.

2.3 Type Constraints and Shape Constraints

Similar to speciﬁcations of common programming lan-
guages [18], [19], constraints in high-level IR is useful to
distinguish valid IR from the invalid one. Constraints in-
clude type constraints and shape constraints. Any break
of these constraints will cause an early crash before high-
level optimizations. Since high-level IR is used to describe
computational graph, any constraint breaking in the graph
will propagate to high-level IR and thus trigger an early
crash. Common constraints include 1) each operator has
acceptable data types on its operands 2) type-compatibility
and shape-compatibility across the multiple parameters of
each operator. In TVM, type system is so rigorous that
type-compatibility is implemented as type-equality. As for
shape-compatibility, take BroadcastRel as an example,
TVM allows broadcast in basic operators to make shape
inference more ﬂexible. This broadcast is similar to that in
Numpy [20], allowing small tensors to be operated with
big tensors. For instance, TVM supports addition between
a scalar (small tensor) with an array (big tensor). Therefore,
HIRFUZZ needs to consider type and shape constraints
in computational graph generation so that they are not

Fig. 3: Workﬂow of HIRFUZZ

FUZZ maintains a pool of 58 operators that can be expressed
by high-level IRs in popular high-level framework (e.g.
Relay [21], ONNX [22]). HIRFUZZ ﬁrst loads existing cov-
erage information, generates a computational graph based
on it, and updates coverage information from the newest
graph. Then, HIRFUZZ leverages an high-level framework
such as Relay or ONNX, to convert the graph into a high-
level IR and feeds it into the DL compiler. To capture the
defects in the target DL compiler more sufﬁciently, HIRFUZZ
constructs three test oracles from the spirits of differential
testing and metamorphic testing. Any test case that violates
the oracles is regarded as a witness to a bug of the compiler
and will be reported to developers. The remainder of this
section is divided into three parts. In Section 3.1, we will
elaborate the details of our computational graph generation
algorithm. Section 3.2 will present how to utilize the lan-
guage features of Relay IR and convert computational graph
into this IR. In Section 3.3, we will introduce the design of
our created test oracles.

3.1 Computational Graph Generation

3.1.1 Overview.

We consider the generation of computational graph as a
process of continuously inserting various operator nodes
into the initially empty graph CG = {} until the number
of operator nodes equals to the number required. Generally
speaking, HIRFUZZ selects one operator from the operator
pool, loads the operator into CG as a node nd, and con-
structs connection between nd and other existing nodes. In
these steps, HIRFUZZ maintain node information, including
data type, tensor shape and connection information, for
each node. To improve the diversity of the graph, HIRFUZZ
also involves three coverage criteria and try to improve the
coverage in each insertion of node.

With these prerequisites, HIRFUZZ provides two gen-
eration modes. To generate valid computational graphs,
HIRFUZZ utilizes the above-mentioned node information
for strict type checking and shape checking. In this way, each
insertion is valid and breaks no constraint. We call this mode
strict generation. On the other hand, strictly following the
constraints may miss the opportunity to test the exception
handling ability of DL compilers when constraints are vio-
lated. Therefore, HIRFUZZ also provides disruptive generation
to deliberately break type constraints and shape constraints.
We will ﬁrst elaborate strict generation and then disruptive
generation.

3.1.2 Node Information
Inserting a node into CG requires node information of
all existing nodes to perform type-checking and shape-
checking. Node information describes the typical features
of node, and such information is essential to promise the
correctness of each insertion. For instance, in the insertion
of an operator named add that sums two nodes, HIRFUZZ
ﬁrst checks all available nodes (including operator nodes,
variable nodes and constant nodes) and selects two nodes
na and nb from available nodes, such that na and nb have
the compatible tensor shapes and data types, and their data
types are acceptable by the operator add. Each type of node
has its own node information, as detailed in Table 1.

Node Type Node Information

variable
constant
operator

dataT ype, tensorShape
dataT ype, tensorShape, value
dataT ype, parentN odes, tensorShape = INFERENCE(parentN odes)

TABLE 1: Node Information

Speciﬁcally, HIRFUZZ considers three types of nodes,
namely, variable, constant and operator. The detailed intro-
duction of them is as follows.
1) Variable node. It involves data type dataT ype and tensor
shape tensorShape describing the details of the tensor
wrapped in this node. dataT ype corresponds to the data
type of all elements in this tensor, such as int64 and
f loat32. tensorShape is a vector of the scale of all
dimensions in the tensor.

2) Constant node. Besides the dataT ype and tensorShape,
constant node includes the value of tensor value as a part
of its information.

3) Operator node. Operators require parameter(s) and thus
they are all connected with other nodes in the graph. To

4

document this connection information for each operator
node, Besides dataT ype, HIRFUZZ records its parent
node(s) parentN odes to which this node connects and
records its tensor shape inferred from parent node(s).

3.1.3 Coverage Guidance.

To let HIRFUZZ intelligently generate diverse computational
graph with in-depth thoughts about selection of data type,
operator, etc, we design three coverage criteria.

1) Operator-datatype Coverage. Let opi be the ith opera-
tor in the operator pool. Let dtypej be the jth data type
in the collection of data types. Let Cov(opi, dtypej) be
1 when opi has once been inserted into the graph as a
node with data type dtypej. Otherwise, it is 0.

2) Operator-shape Coverage. Let opi be the ith operator in
the operator pool. Let shape be the shape of the output
tensor of this operator node after being inserted into the
graph. Let Cov(opi, shape) be 1 if opi has once been
inserted into the graph as a node with tensor shape
shape, and 0 otherwise.

3) Operator-edge Coverage. Let opi and opj be the ith and
jth operator in the operator pool. Let Cov(opi, opj) be 1
if there exists one edge from opi to opj, and 0 otherwise.
The design of the ﬁrst two coverage criteria are motivated
by the fact that type problem and shape problem are the two
major root causes of DL compiler bugs [8]. The design of the
third one tries to complicate the data ﬂow of the computa-
tional graph since the third coverage encourages HIRFUZZ
to interleave different operators in a computational graph.
Speciﬁcally, with operator-datatype coverage, HIRFUZZ is
encouraged to 1) involve different operators into the graph
and 2) utilize diverse data types since data type problem
is a big concern for DL compilers [8]. With operator-shape
coverage, HIRFUZZ is encouraged to try various calculation
with diverse tensor shapes and thus increase the probability
of encountering calculation problem, such as poor imple-
mentation of some operator in special shape or different
calculation results on different platform. With operator-edge
coverage, HIRFUZZ is guided to connect the new operator
node to the existing operator nodes instead of variable
nodes and constant nodes. In this way, the generated com-
putational graph contains more complex and deep data
ﬂow instead of parallel connection of several simple data
ﬂows. In implementation, we can easily extend operator-
edge coverage to operator-path coverage with 3 or more
operator nodes included. In this way, we can explore a more
diverse and complicated computational graph, but at the
cost of greater time costs. HIRFUZZ is encouraged to explore
the diversity of computational graph by increasing these
three coverages. Therefore, we name our computational
graph generation approach coverage-guided generation.

3.1.4 Strict Generation

Algorithm 1 presents how HIRFUZZ strictly generates com-
putational graph with type-checking and shape-checking by
two procedures. GENERATION is the main procedure. This
procedure takes as input the required number of operators
rOpN um contained in computational graph. It outputs a
computational graph of which the number of operators
equals to rOpN um. PREINSERT is the auxiliary procedure.

It details how HIRFUZZ embeds type-checking and shape-
checking in generation. GENERATION procedure includes
the following two main parts.

Algorithm 1 Computational Graph Generation

1: procedure GENERATION(rOpN um)
2:

CG ← {}
opnum ← 0
opP ool ← {add, subtract, multiply, divide, ...}
dataT ypeSet ← {int64, int32, int16, int8, uint64, uint32,

repeat

uint16, uint8, f loat64, f loat32, bool}

opN ode ← SELECT(opP ool)
dataT ype ← SELECT(dataT ypeSet)
connection, shape, CG ← PREINSERT(opN ode, dataT ype, CG)
coverage

← CALCULATECOVERAGE(opN ode,

dataT ype,

connection, shape)

if NEWCOVERAGE(coverage) then

opnum ← opnum + 1
UPDATECOVERAGE(coverage)
opN ode.inf o ← (connection, shape, dataT ype)
CG ← CG (cid:83){node}

end if

18:

until opnum = rOpN um
return CG
19:
20: end procedure
21: procedure PREINSERT(opN ode, dataT ype, CG)
22:

availableN odes ← TYPECHECK(CG, dataT ype)
nodeGroup1, nodeGroup2, ... ← SHAPECHECK(availableN odes)
paramN odes ← SELECT (nodeGroup1, nodeGroup2, ...)
if NODENOTENOUGH(paramN odes) then

node1, node2, ... ← CREATE(dataT ype, paramN odes)
CG ← CG (cid:83){node1, node2, ...}
paramN odes ← paramN odes (cid:83){node1, node2, ...}

end if
for node IN paramN odes do

connection ← (opN ode, node)

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

23:

24:

25:

26:

27:

28:

29:

30:

31:

32:

33:

end for
shape ← INFERENCE(connection)
return connection, shape, CG

34:
35: end procedure

Initialization. HIRFUZZ performs

initialization from
Line 2 to Line 6. Speciﬁcally, computational graph CG is
initialized as empty and the number of operators opnum in
CG is set to 0. Operator Pool and data type set are both
initialized for future use.

Generation Loop. In each iteration (Lines 7-18), HIRFUZZ
generates an operator node, updates its node information
and ﬁnally inserts it into CG if new coverage is explored.
Speciﬁcally, HIRFUZZ ﬁrst randomly selects an operator
and data type (Line 8, 9). Then it seeks for connection
from CG and infers the tensor shape of the operator node
opN ode built from the newly selected operator (Line 10).
Subsequently, HIRFUZZ calculates coverage and performs
update and insertion if new coverage is explored (Line 11-
17). The exploration of new coverage is detected by any
increment of the three coverages deﬁned in section 3.1.3.
During update, HIRFUZZ adds opnum by 1, updates cover-
age and node information of opN ode. The generation loop
stops when opnum equals rOpN um and HIRFUZZ returns
CG eventually.

Procedure PREINSERT shows the details of building con-
nection between opN ode and existing nodes of CG and
shape inference. With type-checking (Line 22) and shape-
checking (Line 23), HIRFUZZ sorts out several node groups
from CG. All nodes of each node groups are mutually
shape-compatible and nodes from these groups are all type-
compatible with opN ode. Then HIRFUZZ selects a node
group and dumps all its nodes into paramN odes (Line
24). The number of required parameter nodes is ﬁxed for

5

each kind of operator. In implementation, HIRFUZZ has a
certain probability of connecting one node to an operator
node for multiple times, such as connecting one variable
node to add node for twice, meaning add the node to
itself. But to complicate data ﬂow, HIRFUZZ discourages
this behavior in favor of connecting the required number of
different nodes. Therefore, if the number of parameter nodes
in paramN odes are insufﬁcient for opN ode, HIRFUZZ has
large probability in creating variable nodes or constant
nodes that are shape-compatible with all parameter nodes
and type-compatible with opN ode, inserts them into CG
and updates paramN ode (Line 25-29). Finally, HIRFUZZ
creates connection information (Line 30-32), infers tensor
shape of opN ode and returns them both plus the possibly
updated CG.

3.1.5 Disruptive Generation Algorithm.

Disruptive generation is similar to strict generation. It also
needs coverage to memorize what type constraints and
shape constraints have been broken. In addition, node in-
formation is also required. Since it contains data type and
tensor shape of each node, which is necessary for breaking
constraints. Speciﬁcally, during disruptive generation, HIR-
FUZZ purposely 1) connects operator node to other node(s)
with the data type(s) it can not accept in TVM (e.g., add
operator with bool data type), and 2) connects nodes that
are type-incompatible or shape-incompatible (e.g., add two
nodes of which the shapes are [3,4] and [2,3] respec-
tively).

3.2 High-level IR Generation

High-level IR generation is simple with the help of existing
high-level frameworks, such as Relay and ONNX. Taking
Relay as example, it provides ample APIs for receiving node
information of various types of nodes and diverse operator
nodes. For instance, relay.var takes as inputs its name,
data type and tensor shape, and relay.add takes as input
only its connection information. These APIs contain strict
type constraints and shape constraints and it is easy to
crash early before optimization if the computational graph
contains error.

Besides the plain conversion by loading each node into
its corresponding high-level expressions and assembling
them into a high-level IR, we can also utilize the primitive
features of these high-level frameworks. Take Relay for ex-
ample, to improve expressivity, it allows using a function to
wrap a subgraph and call the function in other ones. ONNX
also plans to support this feature by supporting Function
API1. To better utilize these features, we also consider
extracting a subgraph from the generated computational
graph and wrap it with a high-level function. In this way, we
can better test how DL compilers tackle the situation where
functions are included.

The overall algorithm of converting computational
graph into high-level IR is shown in Algorithm 2. CON-
VERSION procedure takes as input computational graph CG
and outputs its corresponding high-level IR. During initial-
ization, HIRFUZZ creates two empty sets, named F unctions

1. https://github.com/onnx/onnx/blob/main/docs/Operators.md

Algorithm 2 Conversion from Computational Graph to
High-level IR

1: procedure CONVERSION(CG)
F unctions ← {}
2:
Expressions ← {}
for node IN CG do

4:

3:

the generated computational graph under checking strictly
follows all constraints in TVM and the crash is largely due
to the poor implementation of TVM.

6

5:

6:

7:

8:

9:

10:

11:

12:

Expressions ← LOAD(node.inf o, F unctions, Expressions)
if ROLL() == f unc then

inputN odes, outputN odes ← ANALYZE(Expressions)
f unction ← COMPOSEFUNCTION (inputN odes, outputN odes)

F unctions ← F unctions (cid:83) f unction
Expressions ← {}

end if

end for
return Expressions (cid:83) F unctions

13:
14: end procedure
15: procedure LOAD(node.inf o, F unctions, Expressions)
expression ← CONSTRUCTEXPRESSION (node.inf o)
16:
if PARENTINFUNCTION(node.inf o) then
f unctions ← FIND(node.inf o)
callExprs ← CREATECALLEXPRESSION(f unctions)
Expressions ← Expressions (cid:83){callExprs}

17:

18:

19:

20:

21:

22:

end if
Expressions ← Expressions (cid:83){expression}
return Expressions

23:
24: end procedure

and Expressions respectively (Line 2, 3). They represent
the collection of functions and high-level expressions, re-
spectively. In the for loop (Line 4-12), HIRFUZZ traverses
all nodes in CG, loads each node into high-level expres-
sion and update Expressions (Line 5). Then it randomly
selects a set of high-level expressions and wraps them with
a function (Line 6-11). To compose a function, HIRFUZZ
ﬁrst analyzes the input nodes and output nodes of the
underlying subgraph of the expressions (Line 7). Then it
composes a function using these nodes (Line 8. Finally,
HIRFUZZ updates F unctions and Expressions (Line 9-10).
CONVERSION procedure returns the union of Expressions
and F unctions as High-level IR. LOAD procedure presents
the detail of loading a node into high-level expression. Dur-
ing loading, HIRFUZZ takes care of connection information
by inquiring whether the node connects to other nodes
wrapped in function(s) (Line 17), if it is the case, then a
call expression is created (Line 19). This procedure return
Expressions after update.

3.3 Test Oracles

Test oracle is an important mechanism to determine if a test
passes or fails. In this paper, we consider three test oracles in
total. Any failed test case determined by these oracles will
be reported.

3.3.1 Oracle1: Crash.
Crash is widely used in test oracle construction to decide
whether the testing fails [11]. Besides, according to the
statistics in a compiler bug study [8], the number of bugs
with crash symptom occupy 59.37% of all collected 603
bugs. This huge proportion shows a urgent need to take
crash seriously. As for crash bugs detected when type-
checking and shape-checking are turned off, we only report
the bug if the crash is a segmentation fault because other
crashes with detailed bug trace is largely due to explicit
violation of constraints in the computational graph. As
for other crash bugs, we report them all. This is because

Fig. 4: High-level IR Mutation

3.3.2 Oracle2: Result Inconsistency among original high-
level IR, optimized high-level IR and mutated high-level IR

It is intuitive that high-level optimization is only related
to performance boost such as calculation acceleration and
memory cost saving, but can not change results. In addition
to involving high-level optimization, we also design a mu-
tation strategy named function rewrite to generate mutated
high-level IRs who has the same output as the original
high-level IR given the same input. This mutation strategy
is inspired by Relay’s support for functional programming
features. By function rewriting, we can better utilize Relay’s
expressions and better test TVM with richer high-level IR.
All mutation examples are shown in Figure 4. Speciﬁcally,
this mutation strategy can rewrite function expressions in
high-level IR in the following ways.

• Turn a global function f into the local closure of an-
other newly created global function g. g has the same
parameters as f and its returned value is a call to f with
these parameters. After this tuning, this mutation also
substitute all calls to f with calls to g (Refer to Mutated
High-level IR-1).

• Wrap a function f with an empty function g which
returns f and also change all calls to f to calls to the
call to g (Refer to Mutated High-level IR-2).

• Call a function f and return the call in another function
g, then substitute all calls to f with calls to g (Refer to
Mutated High-level IR-3).

The mutated high-level IR only differs from the original
high-level IR in the function call chain. Therefore, it is
sound to expect the same calculation results among these
three high-level IRs given the same input. In addition to
different calculation results, if the original high-level IR
passes compilation and runtime but the optimized one or
mutated one fails in one of these two processes, we also
count it as result inconsistency.

3.3.3 Oracle3: Result Inconsistency across hardware de-
vices

To maintain the same predictive capability of a DL model on
different supported hardware devices, TVM should promise
to output the same results on diverse hardware given the
same input to a DL model. And similar to Oracle2, incon-
sistent execution status (e.g., crash on CPU but execute well
on GPU) is also counted as result inconsistency. Following
this common sense, we build Oracle3 with the spirit of
different testing. Given any high-level IR, after compiling
it with multiple provided compilation approaches, feeding
an input and executing it on CPU and GPU, it is reasonable
to expect the same calculation results.

4 EXPERIMENT SETUP
4.1 Research Questions

In this study, we aim to address the following research
questions:

• RQ1: How effective is HIRFUZZ in detecting bugs of

TVM?

• RQ2: Are all the test oracles effective in detecting bugs?
• RQ3: Are bugs found by HIRFUZZ highly related to

high-level optimization?

• RQ4: Is disruptive generation useful in ﬁnding excep-

tion handling bugs?

• RQ5: Can coverage-guided generation beneﬁt the di-

versity of graph?

4.2 HIRFUZZ Implementation

We implement HIRFUZZ in C++ with around 3K lines of
code. Our implementation involves 58 operators to generate
computational graph, 25 high-level optimizations for catch
optimization bugs and four compilation methods to conduct
testing.

4.2.1 Operators

In total, HIRFUZZ includes 58 operators supported by TVM,
including 23 binary operators and 35 unary operators. And
it is easy to extend HIRFUZZ with other operators. The
following lists are the two groups of operators involved by
HIRFUZZ.
• binary operators: Add, Subtract, Multiply, Divide,
Power, Mod, Floor Mod, Floor Divide, Logical
And,
Bitwise And,
Bitwise Or, Equal, Not Equal, Less, LessEqual,
Greater, GreaterEqual, Maximum, Minimum, Right
Shift, Left Shift.

Logical Xor,

Logical Or,

7

optimizations in TVM is our generated computational
graph can trigger them. Besides collecting these high-level
optimizations, we also utilize different compilation methods
provided by TVM. Different compilation methods deal with
different scenarios and include different optimization
sequences. Overall, we include relay.build(),
relay.build_module.create_executor(’debug’),
relay.build_module.create_executor(’graph’)
and
relay.build_module.create_executor(’vm’)
in
HIRFUZZ. Besides these high-level optimizations, it is easy
to extend HIRFUZZ with other optimizations.

4.3 Bug Report

For each bug we have found, we report it in one of the three
channels: 1) upload the bug-triggered script and experiment
environment on TVM Community3; 2) report the bug on
Github Issue4 with reproducible script, experimental envi-
ronment, and most importantly, our analysis on the reason
for triggering it; 3) create a pull request with the elaboration
of this bug and our code patch. We choose our reporting
channels primarily based on our expertise of the problem.
For the least familiar bug, we submit it on TVM Community
in the form of question to get rid of misdiagnosis. Then, we
wait for an ofﬁcial ﬁx or some comments from developers
on this problem. For the most familiar one, we directly ﬁx
it, and we succeed in creating two pull requests and ﬁxing
two bugs. For other situations, we choose the second way
and leave some comments on how to ﬁx the bug.

4.4 Baseline Selection

4.4.1 TVMfuzz

TVMfuzz is a preliminary proof-of-concept application for
fuzzing TVM [8]. It can learn TVM API call chains from
unit test scripts, then re-order and mutate them. By learning
from high-level IR and optimization related unit test scripts,
TVMfuzz can cover this stage.

4.4.2 MT-DLComp

MT-DLComp is an automated testing framework for DL
compilers [13]. It mutates existing DL models to generate
equivalent models and test DL compilers by three oracles.
Though this technique is not specially created for detecting
bugs in high-level optimization, it can cover this bug-prone
stage. Therefore, we also include it as a baseline.

4.4.3 LEMON

• unary operators: Log, Log2, Log10, Tan, Tanh, Cos,
Cosh, Sin, Sinh, Acos, Acosh, Asin, Asinh, Atan,
Atanh, Exp, Erf, Sqrt, Rsqrt, Sigmoid, Floor, Ceil,
Trunc, Round, Abs, Sign,
Negative, Logical not, Bitwise not, Zeros Like,
Ones Like, Copy, isNan, isFinite, isInf.

4.2.2 Optimization and Compilation Methods.

We select in total 25 high-level optimizations supported
by TVM2 The main reason for choosing these high-level

LEMON is a testing technique for deep learning frameworks
[23]. It generates Keras [24] models by mutating existing
models. By setting different backends of Keras, LEMON
detects prediction difference incurred by these backends.
Though LEMON is not for testing DL compiler, we can
retroﬁt it to barely achieve the goal. In short, we remain
the mutation part to generate new models and test DL com-
pilers by two test oracles: 1) crash, and 2) above-threshold
prediction difference between original Keras models and
compiled Keras models.

2. https://github.com/haoyang9804/HIRFuzz/blob/experiment/

optimizations

3. https://discuss.tvm.apache.org/
4. https://github.com/apache/tvm/issues

4.5 Metrics

To compare HIRFUZZ with these three baselines in the
ability of detecting bugs in high-level optimization stage, we
execute them all separately in two days. To be fair, we only
execute HIRFUZZ in strict generation mode, since all other
three techniques can only generate valid DL models and
APIs. As for bug counting, we utilize the informative stack
trace and bug text provided by TVM and manually check
bug duplication. Following existing works [25], failures with
same bug text and same bug trace are regarded as dupli-
cates. We also use this metric in the comparison between
coverage-guided generation and no-guide generation in the
answer to RQ5.

4.6 Experiment Environment

We conducted experiments on a server with Intel(R) Xeon(R)
CPU, NVIDIA GeForce GTX1080Ti GPU, and 128 RAM,
coordinated with 64-bit Ubuntu 16.04 OS.

5 EVALUATION

5.1 RQ1: Bug Detection Capability of HIRFUZZ

5.1.1 Summary of Detected Bugs by HIRFUZZ

Until now, HIRFUZZ has found 21 bugs, of which 17 have
been conﬁrmed, 12 have been ﬁxed in the main branch of
TVM and 10 are previously unknown to developers. Table 2
presents all details about all the conﬁrmed bugs discovered
by HIRFUZZ, including their symptoms, root causes, the
test oracles detecting them, the ﬁxing status and whether
they are previously unknown. Symptom includes crash
and inconsistency. The former means that TVM terminates
unexpectedly while the latter means that different results or
statuses are caught in testing. We also manually investigate
the root cause of each bug adopting the taxonomy of a recent
bug study [8]. Speciﬁcally, We carefully compare these bugs
with the collected historical bugs and assign each of them
with a root cause.

The root causes of these bugs are divided into the fol-

lowing classes:
• Type Problem. This category of bugs is triggered by data
type related problems, including incorrect type inference,
incomplete implementation of an operator on one data
type, etc.

• Incorrect Exception Handling. This category of bugs oc-
curs when TVM lacks rich and readable warning messages
or even has no handling of some extreme situations. This
kind of bugs are related to the robustness of TVM.

• Incorrect Numerical Computation. This root cause in-
volves incorrect numerical computations, values, or us-
ages.

• Internal API Incompatibility. This category of bugs is
triggered because TVM can not handle the combination
of some APIs correctly. For instance, unexpected refuse
of one combination of several high-level optimizations is
counted as this kind of bug.

• Memory Allocation Problem. This root cause refers to the

poor or incorrect memory allocation.

Check mark in Previously Unknown column in Table 2
means that the corresponding bug was unknown before we

8

reported it. Since we tested TVM v0.9 (commit id: 124813f)
at the beginning of our experiment and TVM was evolving
fast, we found some cases early in the experiment that
crashed on the version we tested but worked ﬁne on the
latest version. These bugs have been actually ﬁxed before
being reported and thus marked as previously known bugs.

5.1.2 Comparison with State-of-the-art Techniques

We conducted a comparison experiment among HIRFUZZ
and other three state-of-the-art DL compiler fuzzers, named
TVMfuzz, MT-DLComp and LEMON respectively, to com-
pare their bug detection ability. All tests are executed on
TVM v0.9 (commit id: 124813f). This version is the initial
TVM version we began our ﬁrst testing using HIRFUZZ. Af-
ter two-day execution, HIRFUZZ detected 11 non-duplicate
bugs, TVMfuzz detected three non-duplicate bugs, of which
only one bug has not been detected by HIRFUZZ, while MT-
DLComp and LEMON detected nothing. These bugs have
been released in HIRFUZZ repository.

5.2 RQ2: Effectiveness of Test Oracles

To demonstrate the effectiveness of our test oracles, we
conduct a case study of several representative conﬁrmed
bugs detected by each test oracle.

Oracle1: Crash. Oracle1 caught the most bugs among all
test oracles. In total, it ﬁnds eight bugs of three root causes,
including Incorrect Numerical Computation, Incorrect Exception
Handling, Memory Allocation Problem.

Fig. 5: The Computational Graph to Trigger Bug1

Incorrect Numerical Computation. Take Bug1 as an exam-
ple. The computational graph to trigger this bug is pre-
sented in Figure 5. In this graph, a divide operator ﬁrst
calculates the result of dividing a constant by a variable and
then passes the calculation result R to floor_mod as divi-
dend. All involved variable nodes and constant nodes are of
data type uint and this type ﬁnally ﬂows into floor_mod.
However, TVM pre-calculates the possible value range of R
and detects it could probably be 0. Therefore, TVM incor-
rectly throws an exception and terminates even before we
give values to var1 and var2, This bug only happens when
the data type is uint and is caused by incorrect value range
estimation. After developers conﬁrmed this bug and ﬁxed
const_int_bound analyzer, this numerical computation
related bug was ﬁxed.

Incorrect Exception Handling. Bug11, Bug12 and Bug13
are three bugs of Incorrect Exception Handling. They are
detected under disruptive generation. To trigger these bugs,
HIRFUZZ must generate computational graphs containing
obvious breaks of constraints. Take Bug11 for example,
its corresponding computational graph includes a constant
node of type int16, a tan operator node and the connection
between these two nodes. The constant node passes its int16

ID

Symptom

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

Crash
Inconsistency
Crash
Crash
Crash
Inconsistency
Inconsistency
Inconsistency
Inconsistency
Inconsistency
Crash
Crash
Crash
Crash
Inconsistency
Inconsistency
Inconsistency

TABLE 2: Conﬁrmed Bugs found by HIRFUZZ

Test
Oracle
Incorrect Numerical Computation Oracle1

Root Cause

Status

Fixed

Incorrect Exception Handling
Incorrect Exception Handling
Incorrect Exception Handling
Incorrect Exception Handling
Incorrect Exception Handling
Type Problem
Type Problem
Internal API Incompatibility
Incorrect Exception Handling
Incorrect Exception Handling
Incorrect Exception Handling
Incorrect Exception Handling
Memory Allocation Problem

Oracle2 Conﬁrmed
Oracle1
Oracle1
Oracle1
Oracle2
Oracle2
Oracle2
Oracle2
Oracle2
Oracle1
Oracle1
Oracle1
Oracle1 Conﬁrmed
Incorrect Numerical Computation Oracle3 Conﬁrmed
Incorrect Numerical Computation Oracle3 Conﬁrmed
Incorrect Numerical Computation Oracle3 Conﬁrmed

Fixed
Fixed
Fixed
Fixed
Fixed
Fixed
Fixed
Fixed
Fixed
Fixed
Fixed

9

Previously
Unknown
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)

data to the operator node. In this tiny subgraph, HIRFUZZ
purposely breaks the constraint that tan only accepts f loat
data type deﬁned in TVM and receives a segmentation fault
during compilation. This is because TVM does not have
exception handling for this operator and its unacceptable
data types.

Memory Allocation Problem. Bug14 is the only bug of
root cause, named Memory Allocation Problem. Speciﬁ-
cally, when HIRFUZZ leverages relay.shape_of to in-
fer to tensor shape of variable node with static ten-
sor shape (1, 2), an unexpected crash happens with
warning message Cannot allocate memory symbolic
tensor shape [?, ?].

Oracle2: Result Inconsistency among original high-level IR,
optimized high-level IR and mutated high-level IR. Oracle2
caught a total of six conﬁrmed bugs, and ﬁve of them have
been ﬁxed. These bugs are caused by three different root
causes, including Incorrect Exception Handling, Type Problem
and Internal API Incompatibility.

Incorrect Exception Handling. Take Bug10 as an exam-
ple HIRFUZZ catches this bug because it ﬁnds a high-
level IR passes compilation while its optimized version
fails. Speciﬁcally, HIRFUZZ places FirstOrderGradient
before FuseOps in a optimization sequence and detects
that TVM cannot successfully handle this optimization se-
quence. This is because exception handling is too strict.
Concretely, TVM performs a traversal on the high-level
IR after FirstOrderGradient for conducting FuseOps.
When visiting a constant node, TVM ﬁnds this node is
not scalar because FirstOrderGradient has rewritten
this attribute. Therefore, TVM throws an exception and the
compilation terminates. However, this check about scalar
attribute is too strict and does not consider data type. A ﬁx
for this bug completes this exception handling and makes
the optimized version successfully passes compilation.

Type Problem. Take Bug8 for instance. This bug is found
with function rewrite mutation. Speciﬁcally, after changing
a global function f into the local closure of another empty

global function g and return f in g, TVM can not infer the
type of g. This is because after successfully inferring the type
of f , this type information is lost when TVM begins to infer
the type of g.

Internal API Incompatibility. Take Bug9 for example. This

bug is detected because
relay.build_module.create_executor(’vm’) fails,
but compilation in other ways run smoothly. Speciﬁcally, af-
ter HIRFUZZ transforms high-level IR into a A Norm Form.
Compilation with virtual machine cannot ﬁgure out the
bound relation between x91 and a global function. However,
other compilation ways do not encounter this problem.

Oracle3: Result

Inconsistency across hardware devices.
Oracle3 caught a total of three conﬁrmed bugs, but none
of them has been ﬁxed. This is because difference among
computation results on CPU and GPU is caused by platform
speciﬁc differences. More speciﬁcally, LLVM and CUDA has
different implementations on the same operator, while TVM
lacks full speciﬁcation about this operator or lacks com-
plete warning message of using this operator. Developers
responded with a conﬁrmation of this deﬁciency but they
consider it unnecessary to remedy it without it violating the
effectiveness of TVM seriously.

Take Bug15 as an example. HIRFUZZ creates a simple
computational graph containing a right_shift opera-
tor node. This operator node takes as input two other
variable nodes. Subsequently, HIRFUZZ ﬁrst generates the
corresponding high-level IR, then compiles the IR with
relay.build to generate runtime model and ﬁnally cre-
ates the input and run runtime model on CPU and GPU
to get two computation results. When the second variable
is larger than the ﬁrst one, results are inconsistent. This is
because this situation incurs a poison value in LLVM and the
use of it in an operator is undeﬁned. Though this conﬁrmed
bug does not come from poor implementation of TVM but
from problems in external compiler, it is still confusing to
users when their DL model triggers this inconsistency. The
reﬁnement of the exception handling system could be a

compromise approach for this ill situation.

5.3 RQ3: Relation between our found bugs and high-
level Optimization.

As a DL compiler fuzzer focusing on high-level optimiza-
tion, HIRFUZZ is capable of detecting bugs in high-level
optimization or bugs highly related to this stage. In this
subsection, we manually study the code patch of each ﬁxed
bug detected by HIRFUZZ and analyze their relationship
with high-level optimization and how the detection of them
improve this stage.

Bug2, Bug8, Bug9, Bug10 are bugs detected in high-
level optimization. Bug-triggered pattern for these four
bugs are similar: after high-level optimizations, HIRFUZZ
detects a violation of Oracle2. These bugs show inability
to optimize the structure several high-level optimizations
should have optimized, and incompatibility among several
optimizations. For instance, Bug8 shows that after perform-
ing InferType on one function, the solved types cannot be
passed to the next function and thus triggers a type problem.
Bug10 shows FuseOp can not be well performed after per-
forming FirstOrderGradient. Fix of these bugs directly
improves performance of the optimization and facilitates the
possibility of multiple optimization combinations.

Besides, HIRFUZZ ﬁnds a total of eight bugs with crash
symptom and all of them trigger crash during compila-
tion. Except for Bug11, Bug12 and Bug13, all other bugs
are directly related to high-level optimization. To improve
efﬁciency, TVM calls OptimizeImpl during compilation
and invokes 11 high-level optimization implicitly. These op-
timizations work by one or several passes on the high-level
IR, which performs rewrite at any optimizable expression.
In each pass, all expressions in high-level IR are visited and
assertions embedded in TVM check each expression. Bugs
in this process may prevent high-level optimizations from
being well executed, or even result in a crash to stop the
optimization. Fix for these bugs are actually ﬁx for required
IR passes needed by high-level optimizations.

Although our approach is proposed for high-level op-
timization, the test cases generated by our approach can
also execute the low-level optimization and deployable code
generation. Thus, it has the side effect of testing the other
stages. And the results also conﬁrm it. Bug15, Bug16 and
Bug17 are all related to low-level part and backend of TVM.
They are detected due to inconsistent calculation results
on different backends (LLVM and CUDA) given the same
inputs. These bugs show the need to better couple TVM
with these backends.

5.4 RQ4: Contribution of Disruptive Generation

During experiments, we have generated 170 computational
graphs with different bug-triggering combinations of oper-
ator, data type and tensor shape. All these graphs can incur
crash of TVM with only “segmentation fault” information,
showing the deﬁciency of exception handling ability. In the
latest TVM version, all these bugs have been ﬁxed. All these
obvious breaks of constraints trigger crash with detailed bug
information now. By comparing the bug information of the
latest TVM, we found there are three bugs in total found by
these 170 graphs.

10

5.5 RQ5: Contribution of Coverage-guided generation
to The Diversity of Graph

To generate diverse computational graphs with various
data types, tensor shapes and operators, we design three
coverage criteria. In this section, we will present three exper-
iments to show the usefulness of these criteria in generating
diverse computational graph and ﬁnding more bugs. We
implement a simpliﬁed version of HIRFUZZ, saying HIR-
FUZZnoncov. HIRFUZZnoncov is identical to HIRFUZZ except
that HIRFUZZnoncov is not guided to generate computa-
tional graphs. We have conducted three experiments for
comparison between these two techniques.

Fig. 6: HIRFUZZ vs. HIRFUZZnoncov in Diversity Score

is about

The ﬁrst experiment

the diversity scores
achieved by HIRFUZZ and HIRFUZZnoncov. In short, diver-
sity score is a quantiﬁcation of the coverage achieved by
HIRFUZZ and HIRFUZZnoncov. In experiment setting, each
new piece of coverage increases diversity score by 1. In this
experiment, HIRFUZZ and HIRFUZZnoncov both generated
200 computational graphs, each of which contains 100 op-
erators. Figure 6 presents the experiment result. After all
generations, HIRFUZZ’s score is more than ﬁve times than
that of HIRFUZZnoncov. HIRFUZZ explores stable amount
of new coverage in each computational graph generation,
while HIRFUZZnoncov explores less and less with the in-
crease of the number of graphs.

The second experiment is about the bug detection ability
of HIRFUZZ and HIRFUZZnoncov under strict generation
mode. In this experiment, we executed these two techniques
for two days separately and collect all failing tests. HIRFUZZ
found 11 bugs out of 24 failing tests, while HIRFUZZnoncov
found 8 bugs out of 37 failing tests. This result shows
that 1) HIRFUZZ has better bug detection ability than
HIRFUZZnoncov, and 2) with coverage-guided generation,
HIRFUZZ can avoid triggering duplicate failure and focus
on ﬁnding new bugs.

The third experiment is similar to the second one. In
this experiment, we compare the bug detection ability of
HIRFUZZ and HIRFUZZnoncov under disruptive generation
mode. Since disruptive generation promises that each in-
sertion contains a violation of constraints and must trig-
ger failure, there is no need to generate multiple-operator
graph. Therefore, we utilize these two techniques to gener-
ate computational graphs that contain only one operator.
Figure 7 presents the experiment results. HIRFUZZ and
HIRFUZZnoncov both generated 170 bug-triggered compu-

11

6.2 Future Work

HIRFUZZ can be potentially extended in these three aspects.
First, the operators and high-level optimizations supported
by HIRFUZZ are extensible. We can easily add new opera-
tors and high-level optimizations to HIRFUZZ in the future.
Second, HIRFUZZ only focuses on TVM currently. In the
future, we can improve the support for ONNX and test
diverse DL compilers with the help of this framework.

Third, since the size of the generated computational
graphs could be large by manual setting, the reduction of
graph size may cost huge manual effort. Directly submitting
a large bug-triggered computational graph is not friendly to
developers and may leave the bug ignored. Besides, though
TVM provides bug stack trace and bug information, it is
also not easy to determine whether the bug is duplicate.
And the submission of duplicate bug is harmful for the
efﬁciency in software development. Therefore, we will work
on automatically reducing computational graph and even
ﬁltering out duplicate bugs of DL compilers in the future.

7 RELATED WORK

HIRFUZZ is a generation-based fuzzer for DL compiler
testing. In this subsection, we introduce two categories of
related work in this section, including generation-based
fuzzing and DL compiler testing.
Generation-based Fuzzing. Generation-based fuzzing is a
class of common fuzzing techniques [26], [27], [28], [29],
[30]. Different from mutation-based fuzzing that mutates
existing seed inputs to create new test inputs, generation-
based fuzzing constructs new inputs from scratch according
to some pre-deﬁned grammar models. Since generation-
based fuzzing does not rely on the seed inputs, it may cover
more diverse input space that is not covered by the seed
inputs and trigger more code logic of the program under
test [31], [32].

Generation-based fuzzing has been widely used in many
domains, such as C compilers [30] and so on [27], [28], [29],
[33]. However, these techniques cannot be directed adopted
to test DL compilers due to its characteristics. To our best
knowledge, TVMFuzz [12] is the ﬁrst generation-based tech-
nique to fuzzing low-level IR and low-level optimization of
TVM. However, this open-source fuzzer can not cover high-
level optimization and thus is incapable of detecting bugs
in this most bug-prone stage. Besides, authors of a DL Com-
piler bug study [8] propose a proof-of-concept prototype
also named TVMfuzz (with lowercase f) to test high-level
optimization. Speciﬁcally, TVMfuzz learns API call chains
and parameters needed by these APIs from unit tests of
TVM and attempts to generate test scripts by reordering
these API calls. It attempts to cover some under-tested paths
in this way. However, it is highly dependent on unit test
and can not explore complicated high-level IRs to test high-
level optimization systematically. Different from these two
techniques, HIRFUZZ is able to generate complicated and
valid computational graphs independently from scratch and
then their corresponding high-level IRs with thousands of
nodes and diverse data types and tensor shapes. In this way,
HIRFUZZ can effectively detect bugs related to high-level
optimization.

Fig. 7: HIRFUZZ vs. HIRFUZZnoncov under Disruptive Gen-
eration

tational graphs, each of which contains unique tuple of
(operator, tensor shape, data type). In this ﬁgure, HIRFUZZ
shows more exploratory nature in diversity of graph and
thus detects bugs faster. Besides, two techniques both found
3 bugs using these 170 graphs. And the timestamps of
bug detection are also marked in this ﬁgure, showing that
HIRFUZZ found bugs faster than HIRFUZZnoncov.

These three experiments show that coverage-guided
generation help HIRFUZZ become more exploratory in the
diversity of computational graphs. Therefore, HIRFUZZ can
detect more bugs and ﬁnd them in faster speed.

6 DISCUSSION

6.1 Threats to Validity

The internal threat validity mainly lies in the implementation
of HIRFUZZ. To reduce this threat, two authors of this paper
have carefully checked and tested the functionality of all
components of HIRFUZZ.

The external threat validity mainly lies in the DL compiler
we chose in our study. Until now, TVM is one of the most
popular and active open-source DL compilers, with 8K
stars in Github. Though HIRFUZZ now mainly supports
converting its generated computational graph into high-
level IR of TVM with Relay. The technical approach of it
is also useful for testing other DL compilers with the help
of ONNX [22]. And we also have one experimental version
to support ONNX. ONNX is an open format to represent
diverse DL models deﬁned by various DL frameworks and
is supported by currectly popular DL compilers. Similar
to Relay, we can use ONNX’s APIs to easily convert a
computational graph into high-level IR of ONNX. This IR
is transformable to high-level IRs of existing DL compilers.
And more support for ONNX to test more DL compilers is
also our future work.

The construct threat mainly lies in randomness. In com-
putational graph generation, though with coverage guid-
ance, the selection of operator and connection also involves
randomness. To alleviate the negative impact of construct
threat, we 1) conducted bug detection ability comparison
experiment for a sufﬁcient time, and 2) conducted the ﬁrst
and the third experiment in section 5.5 for 10 times to assure
the stability of the experimental results.

DL Compiler Testing. With the development of DL com-
piler, the importance of DL compiler testing has been no-
ticed by more and more researchers. To our best knowl-
edge, existing DL compiler testing technique can be divided
into two categories according to their testing focus. MT-
DLComp [13] aims at testing the whole workﬂow of four
DL compilers, including TVM, Glow, NNFusion and Ten-
sorﬂow XLA. This technique performs mutation on existing
DL models and involves three test oracles from the spirit
of metamorphic testing. During testing, it treats all tested
Compilers as a black box and test if DL compilers corrupt
the predictive capability of DL models. Different from MT-
DLComp, several other techniques [8], [11], [12] focus on
the testing of single stage but not the whole workﬂow. Be-
sides, they perform white-box testing to utilize knowledge
gained from codebase to achieve more efﬁcient and effective
testing results. For instance, TZER [11] collects low-level
IR passes and mutates them to focus on bug detection in
low-level optimizations, while the above-mentioned TVM-
fuzz focuses on high-level optimization with generation-
based approaches. Similar to these techniques, HIRFUZZ
also focuses on single stage: high-level optimization. This
stage is the most vulnerable to bugs and has not been
systematically studied by previous literature. HIRFUZZ is
therefore proposed to ﬁll this gap.

8 CONCLUSION

High-level optimization is the most bug-prone stage in the
workﬂow of DL compilers. However, there is no system-
atic study on testing this stage. To ﬁll this gap, we offer
HIRFUZZ, a generation-based fuzzer with effective compu-
tational graph generation approach and three test oracles.
Different from existing works, HIRFUZZ can explore more
complicated and valid high-level IR and thus detect deeper
bugs. Besides, three test oracles in HIRFUZZ also improve
its capability of detecting bugs of various root causes. In
total, HIRFUZZ has detected 21 bugs, of which 17 have been
conﬁrmed and 12 have been ﬁxed. Our effort has been rec-
ognized by TVM community and improved the robustness
and functional correctness of high-level optimization.

REFERENCES

[1] T. Chen, T. Moreau, Z. Jiang, L. Zheng, E. Yan, M. Cowan, H. Shen,
L. Wang, Y. Hu, L. Ceze, C. Guestrin, and A. Krishnamurthy,
“Tvm: An automated end-to-end optimizing compiler for deep
learning,” in 13th USENIX Symposium on Operating Systems Design
and Implementation (OSDI 18), ser. OSDI’18. USENIX Association,
2018.

[2] N. Rotem, J. Fix, S. Abdulrasool, G. Catron, S. Deng, R. Dzhabarov,
N. Gibson, J. Hegeman, M. Lele, R. Levenstein, J. Montgomery,
B. Maher, S. Nadathur, J. Olesen, J. Park, A. Rakhov, M. Smelyan-
skiy, and M. Wang, “Glow: Graph lowering compiler techniques
for neural networks,” 2018.

[3] Google, “Xla: Optimizing compiler for machine learning,” 2016.

[4]

[Online]. Available: https://www.tensorﬂow.org/xla
S. Cyphers, A. K. Bansal, A. Bhiwandiwalla,
J. Bobba,
M. Brookhart, A. Chakraborty, W. Constable, C. Convey, L. Cook,
O. Kanawi, R. Kimball, J. Knight, N. Korovaiko, V. Kumar, Y. Lao,
C. R. Lishka, J. Menon, J. Myers, S. A. Narayana, A. Procter,
and T. J. Webb, “Intel ngraph: An intermediate representation,
compiler, and executor for deep learning,” 2018.

[5] M. Li, Y. Liu, X. Liu, Q. Sun, X. You, H. Yang, Z. Luan, L. Gan,
G. Yang, and D. Qian, “The deep learning compiler: A compre-
hensive survey,” vol. 32, 2021.

12

[6] C. Sun, V. Le, Q. Zhang, and Z. Su, “Toward understanding com-
piler bugs in gcc and llvm,” in Proceedings of the 25th International
Symposium on Software Testing and Analysis, 2016, pp. 294–305.
[7] Z. Zhou, Z. Ren, G. Gao, and H. Jiang, “An empirical study of
optimization bugs in gcc and llvm,” Journal of Systems and Software,
vol. 174, p. 110884, 2021.

[8] Q. Shen, H. Ma, J. Chen, Y. Tian, S.-C. Cheung, and X. Chen,
“A comprehensive study of deep learning compiler bugs,” in
Proceedings of the 29th ACM Joint Meeting on European Software
Engineering Conference and Symposium on the Foundations of Software
Engineering, ser. ESEC/FSE 2021, 2021.

[9] C. Chen, A. Seff, A. Kornhauser, and J. Xiao, “Deepdriving: Learn-
ing affordance for direct perception in autonomous driving,” in
2015 IEEE International Conference on Computer Vision (ICCV), 2015.
[10] K. D. Julian, J. Lopez, J. S. Brush, M. P. Owen, and M. J. Kochender-
fer, “Policy compression for aircraft collision avoidance systems,”
in 2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC),
2016.

[11] J. Liu, Y. Wei, S. Yang, Y. Deng, and L. Zhang, “Coverage-guided
tensor compiler fuzzing with joint ir-pass mutation,” arXiv preprint
arXiv:2202.09947, 2022.

[12] D. Pankratz, “Tvmfuzz,” 2020.

[Online]. Available: https:

//github.com/dpankratz/TVMFuzz

[13] D. Xiao, Z. LIU, Y. Yuan, Q. Pang, and S. Wang, “Metamorphic
testing of deep learning compilers,” Proc. ACM Meas. Anal. Com-
put. Syst., 2022.

[14] D. Xie, Y. Li, M. Kim, H. V. Pham, L. Tan, X. Zhang, and M. W.
Godfrey, “DocTer: documentation-guided fuzzing for testing deep
learning API functions,” in Proceedings of the 31st ACM SIGSOFT
International Symposium on Software Testing and Analysis. ACM, jul
2022.

[15] Z. Wang, M. Yan, J. Chen, S. Liu, and D. Zhang, “Deep learning
library testing via effective model generation,” in ESEC/SIGSOFT
FSE. ACM, 2020, pp. 788–799.

[16] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro,
G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat,
I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz,
L. Kaiser, M. Kudlur,
J. Levenberg, D. Mané, R. Monga,
S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner,
I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan,
F. Viégas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke,
Y. Yu, and X. Zheng, “TensorFlow: Large-scale machine learning
software available from
on heterogeneous
tensorﬂow.org. [Online]. Available: https://www.tensorﬂow.org/
[17] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison,
A. Köpf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy,
B. Steiner, L. Fang, J. Bai, and S. Chintala, PyTorch: An Imperative
Style, High-Performance Deep Learning Library. Curran Associates
Inc., 2019.

systems,” 2015,

[18] B. Yu, L. Kong, Y. Zhang, and H. Zhu, “Testing java components
based on algebraic speciﬁcations,” in 2008 1st International Confer-
ence on Software Testing, Veriﬁcation, and Validation.
IEEE, 2008, pp.
190–199.

[19] J. W. Nimmer and M. D. Ernst, “Automatic generation of program
speciﬁcations,” ACM SIGSOFT Software Engineering Notes, vol. 27,
no. 4, pp. 229–239, 2002.

[20] C. R. Harris, K. J. Millman, S. J. van der Walt, R. Gommers,
P. Virtanen, D. Cournapeau, E. Wieser, J. Taylor, S. Berg, N. J.
Smith, R. Kern, M. Picus, S. Hoyer, M. H. van Kerkwijk,
M. Brett, A. Haldane, J. F. del Río, M. Wiebe, P. Peterson,
P. Gérard-Marchant, K. Sheppard, T. Reddy, W. Weckesser,
H. Abbasi, C. Gohlke, and T. E. Oliphant, “Array programming
with NumPy,” Nature, vol. 585, no. 7825, pp. 357–362, Sep. 2020.
[Online]. Available: https://doi.org/10.1038/s41586-020-2649-2

[21] J. Roesch, S. Lyubomirsky, L. Weber, J. Pollock, M. Kirisame,
T. Chen, and Z. Tatlock, “Relay: A new ir for machine learning
frameworks,” in Proceedings of the 2nd ACM SIGPLAN International
Workshop on Machine Learning and Programming Languages, ser.
MAPL 2018, 2018.

[22] “Onnx,” 2022. [Online]. Available: https://onnx.ai/
[23] Z. Wang, M. Yan, J. Chen, S. Liu, and D. Zhang, “Deep learning
library testing via effective model generation,” in ESEC/SIGSOFT
FSE. ACM, 2020, pp. 788–799.

[24] “Keras,” 2022. [Online]. Available: https://keras.io/
[25] W. Luo, D. Chai, X. Run, J. Wang, C. Fang, and Z. Chen, Graph-

13

Based Fuzz Testing for Deep Learning Inference Engines.
2021.

IEEE Press,

[26] X. Zhu, S. Wen, S. Camtepe, and Y. Xiang, “Fuzzing: A survey for

roadmap,” ACM Comput. Surv., 2022.

[27] H. Abdelnur, O. Festor, and R. State, “Kif: a stateful sip fuzzer,”

2007.

[28] K. Dewey, J. Roesch, and B. Hardekopf, “Fuzzing the rust type-
checker using clp,” in Proceedings of the 30th IEEE/ACM Interna-
tional Conference on Automated Software Engineering, ser. ASE ’15.
IEEE Press, 2015.

[29] K. Dewey, J. Roesch, and Hardekopf, “Language fuzzing us-
ing constraint logic programming,” in Proceedings of the 29th
ACM/IEEE International Conference on Automated Software Engineer-
ing, ser. ASE ’14. Association for Computing Machinery, 2014.

[30] X. Yang, Y. Chen, E. Eide, and J. Regehr, “Finding and understand-
ing bugs in c compilers,” in Proceedings of the 32nd ACM SIGPLAN
conference on Programming language design and implementation, 2011,
pp. 283–294.

[31] C. Miller, Z. N. Peterson et al., “Analysis of mutation and
generation-based fuzzing,” Independent Security Evaluators, Tech.
Rep, vol. 4, 2007.

[32] J. Li, B. Zhao, and C. Zhang, “Fuzzing: a survey,” Cybersecurity,

vol. 1, no. 1, pp. 1–13, 2018.

[33] P. Amini and A. Portnoy, “Sulley fuzzing framework,” 2010.

