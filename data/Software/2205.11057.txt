2
2
0
2

y
a
M
3
2

]
E
S
.
s
c
[

1
v
7
5
0
1
1
.
5
0
2
2
:
v
i
X
r
a

Falsiﬁcation of Multiple Requirements for
Cyber-Physical Systems Using Online Generative
Adversarial Networks and Multi-Armed Bandits

Jarkko Peltomäki and Ivan Porres
Faculty of Science and Engineering,
Åbo Akademi University
Turku, Finland
name.surname@abo.fi

Abstract—We consider the problem of falsifying safety require-
ments of Cyber-Physical Systems expressed in signal temporal
logic (STL). This problem can be turned into an optimization
problem via STL robustness functions. In this paper, our focus
is in falsifying systems with multiple requirements. We propose
to solve such conjunctive requirements using online generative
adversarial networks (GANs) as test generators. Our main contri-
bution is an algorithm which falsiﬁes a conjunctive requirement
ϕ1 ∧· · ·∧ϕn by using a GAN for each requirement ϕi separately.
Using ideas from multi-armed bandit algorithms, our algorithm
only trains a single GAN at every step, which saves resources.
Our experiments indicate that, in addition to saving resources,
this multi-armed bandit algorithm can falsify requirements with
fewer number of executions on the system under test when
compared to (i) an algorithm training a single GAN for the
complete conjunctive requirement and (ii) an algorithm always
training n GANs at each step.

I. INTRODUCTION

In this paper, we study the problem of black-box falsiﬁca-
tion of safety requirements of Cyber-Physical Systems (CPS).
This is a validation method to increase the conﬁdence that a
system works as expected before it is taken into production.
This is especially important with safety requirements of CPS,
where a fault can lead to severe damage or injuries.

We focus on Cyber-Physical Systems where inputs and
outputs are given as real-valued signals. We deﬁne the safety
requirements of such systems as properties expressed in signal
temporal logic (STL) [12]. An example of such requirement
is

((cid:3)[0,30]RPM < 3000) → ((cid:3)[0,4]SPEED < 35).

Informally, this states that if the RPM signal is below 3000
during the ﬁrst 30 units of time, then SPEED signal should
be below 35 for the ﬁrst 4 units of time. We test the system
against these requirements by generating concrete input signals
aiming to obtain an output signal that falsiﬁes the given STL
properties. By doing this, the input signals become a witness
the provided
that
requirements.

the system under study does not fulﬁll

Black-box falsiﬁcation methods only consider inputs and
observable outputs and do not require access to the internals

of the system under study nor to its design speciﬁcations or
source code. Black-box methods can be used at any point
of the development process and only require that we are
able to evaluate inputs and output pairs by simulation or
actual execution. An example of a simulation environment is
MATLAB. It is a popular design and simulation toolset for
Cyber-Physical Systems and it is widely used in academia
and industry. Therefore many falsiﬁcation tools, including the
implementations of the algorithms presented here, can use it
as a simulation environment.

The challenge in black-box safety validation of CPS lies in
how to achieve the falsiﬁcation of the proposed requirements
with a limited testing budget. Corso et al. have recently
published a survey of algorithms tackling this problem [3].
This survey presents four main strategies studied in the litera-
ture: optimization, path planning, reinforcement learning, and
importance sampling.

Optimization-based falsiﬁcation uses requirement robust-
ness functions [2] to drive the search of falsifying inputs.
Intuitively a robustness function indicates how close a given
input is falsifying a requirement. A robustness function returns
a value ≤ 0 for inputs that falsify the requirements, and
it should yield progressively lower values when its inputs
approach a falsiﬁcation region. Given this, minimizing a
robustness function will provide us with inputs that falsify
the requirements, if they exist.

Different authors have proposed the use of existing opti-
mization meta-heuristics such as genetic algorithms or simu-
lated annealing to drive the search for falsiﬁcation inputs [3]
and also new algorithms that combine model learning with
global and local search [8]. It is characteristic to these earlier
algorithms that they have no knowledge of how the robustness
functions are derived from requirements. More recently Zhang
et al. [19] and Mathesen et al. [13] have proposed falsiﬁcation
algorithms that use information about the structure of the
requirements to drive the falsiﬁcation search. The work by
Zhang et al. accepts requirements of the form (cid:3)I (ϕ1 ∧ ϕ2)
or (cid:3)I (ϕ1 ∨ ϕ2) while the more recent work of Mathesen can
deal with more general requirements of the form ϕ1 ∧ · · · ∧ ϕn
[13].

 
 
 
 
 
 
In this paper, we continue this line of research and propose
an algorithm for the robustness-based falsiﬁcation of CPS that
uses the online GAN framework to generate falsifying inputs.
We have used the online GAN framework in the past for the
problem of performance testing [15]. As the ﬁrst contribution
of this article, we show here how the online GAN framework
can also be applied for the falsiﬁcation of safety requirements
with a competitive performance.

The second contribution presented in this article is an exten-
sion of our base algorithm that uses speciﬁc knowledge on how
to falsify a conjunctive requirement ϕ1 ∧ · · · ∧ ϕn efﬁciently.
We ﬁrst show how to solve this problem by training a GAN for
each requirement ϕi separately as proposed in [13]. We offer
experimental evidence that such an algorithm outperforms an
algorithm training a single GAN for the complete conjunctive
requirement. The drawback of such an approach is that it
requires the simultaneous training of n different GANs. This
in [13] where the creation of n
problem is also present
different Gaussian process models is required at each step.

Inspired by the multi-armed bandit problem, we address this
issue by proposing a third algorithm which, after a warm up
period, trains a single GAN at a time which saves resources.
Our experiments indicate that, in addition to saving resources,
it is possible that this variant falsiﬁes requirements with fewer
number of executions on the system under test.

We proceed as follows. In Section II, we introduce the
problem of falsiﬁcation of requirements of CPS formally and
discuss related work in more detail. Section III presents our
initial algorithm for a single conjunctive requirement falsiﬁ-
cation based on the online GAN framework. This algorithm
is evaluated in Section IV using the Automatic Transmission
Controller model, a benchmark problem presented in [5]. We
continue in Section V by extending our original algorithm
to deal with conjunctive requirements more efﬁciently and
propose two new algorithms. The new algorithms are evaluated
in Section VI using a synthetic problem proposed in [13].
Finally we present our concluding remarks in the last section.

II. FALSIFICATION OF FORMAL REQUIREMENTS OF CPS

A. Problem Description

We assume that the safety requirements of the system under
test (SUT) can be expressed in signal temporal logic (STL)
[12] as formulas ϕ1, . . ., ϕn. Falsifying a formula ϕ means
exhibiting a test such that the behavior (signal or trajectory)
of the SUT while executing the test violates ϕ. In our case,
falsifying the safety requirements amounts to falsifying the
conjunctive requirement ϕ1 ∧ · · · ∧ ϕn.

More precisely, we represent the SUT as a model M which
takes as its input a test t and outputs a (possibly vector-valued)
signal M(t) for which the truth value of ϕ1 ∧ · · · ∧ ϕn can
be evaluated. In order to search for a falsifying test t, we
turn the problem into an optimization problem via robustness
functions. As described, e.g., in [2], an STL formula ϕ can be
effectively transformed into a real-valued robustness function
ρϕ such that ϕ evaluates to true for a signal s if and only
if ρϕ(s) ≥ 0. Moreover,
the robustness function has the

following stability property: small changes to a signal s with
robustness ρϕ(s) of high absolute value do not affect the truth
value of ϕ whereas small changes when |ρϕ(s)| is small could
change it. This property turns the problem of falsifying ϕ to
that of minimizing ρϕ. In other words, our task is to solve the
optimization problem

arg min
t

ρψ(M(t))

(1)

where ψ = ϕ1 ∧ · · · ∧ ϕn. The elementary properties of
robustness functions allows us to write (1) as

arg min
t

min
i=1,...,n

ρϕi(M(t)).

(2)

We remark that the success of this plan depends on how
complicated the formulas ϕi are. It is reasonable to assume, for
example, that the function predicates appearing in the formulas
refer to locally Lipschitz continuous functions. Observe also
that continuous signals need to be discretized appropriately.

As pointed out in [13], it is often the case that evaluating
M(t) is slow, but computing ρϕ(s) is fast. Therefore it
makes sense to assume that we have all values ρϕi (M(t)),
i = 1, . . . , n, available as soon as a test t has been executed
on the SUT. With this assumption, we gain knowledge as we
can use all values ρϕi(M(t)), i = 1, . . . , n, instead of just
observing their minimum. The assumption also helps with the
scale problem [13], [19]. Indeed, the value of ρϕi could have
wildly different scale than ρϕj , so ρϕi could effectively mask
any information in ρϕj if we only get to observe the minimum.
It is worth remarking that this problem can persist even after
appropriate scaling.

B. Previous Work

Solving (2) can be approached in different ways. Common
optimization methods,
like the cross-entropy method [17],
have been used; see the introduction of [13] for more ref-
erences to prior works.

We are interested in the recent paper [13] of Mathesen
et al. where Bayesian optimization is used. The main points
of their minBO algorithm are as follows. Let us write ρi(t)
for ρϕi(M(t)) for brevity. First sample tests randomly and
execute them on the SUT to obtain a training data

(tj, ρi(tj), . . . , ρn(tj)),

j = 1, . . . N,

and best test t∗ with

t∗ = arg min
tj ,j=1,...,N

min
i=1,...,n

ρi(tj).

Then a Gaussian Process [16] is ﬁtted for each ρi using
the above training data. This yields an approximate model
for each ρi. These models are used to ﬁgure out a test
tN +1 which is likely to give smaller robustness values than
t∗. The selection of tN +1 is done by maximizing expected
improvement as is common in Bayesian optimization [1].
More precisely: a candidate test t(cid:48)
i with highest expected
improvement EIi (with respect to t∗) is selected separately
for each ρi, and the ﬁnal candidate tN +1 is chosen to be t(cid:48)
k

with k = arg maxi=1,...,n EIi. The test tN +1 is executed on
the SUT and the results are added to the training data. The
best test t∗ is updated if needed, and the above is repeated
until the execution budget is exhausted.

In order to evaluate the minBO algorithm described above,
two experiments are proposed in [13]. The ﬁrst experiment is
artiﬁcial and concerns properties of predeﬁned but complicated
and nonlinear functions. The second experiment concerns
two industry benchmark models: the automatic transmission
(AT) model of [5] and the ground collision avoidance system
(GCAS) autopilot model for the F-16 ﬁghter jet [9]. The
ﬁndings of [13] are that the minBO algorithm performs always
at least as well as a similar Bayesian optimization approach
which has only access to the minimum mini ρi(t). The minBO
algorithm performs statistically signiﬁcantly better in cases
where the scale problem is present (both use cases in the
ﬁrst experiment and GCAS in the second experiment). The
minBO algorithm is proposed as a performant solution to the
scale problem.

III. THE ONLINE GAN ALGORITHM FOR
ROBUSTNESS-BASED FALSIFICATION

In this section, we present an algorithm which solves (1)
using online GANs. We falsify a single requirement meaning
we assume that we can only observe the minimum robustness
of multiple requirements.

A. Online GAN Training

At the heart of the algorithm is the idea of using a GAN for
optimization. The idea is the same as in [15] where an online
GAN is used for maximization. The idea is the following. Let
ϕ be an STL formula, and suppose that the test robustness
function t (cid:55)→ ρϕ(M(t)) takes values in [0, 1]. We deem ϕ to
be falsiﬁed if there exists a test t such that ρϕ(M(t)) = 0.

In addition to the SUT, we have two components: a gen-
erator G and a discriminator D. Both G and D are machine
learning models, and in this paper they are neural networks.
The generator G is a mapping from a latent space to the space
of tests, and the aim is to train G in such a way that when
the latent space is sampled uniformly, we obtain, via the map
G, tests t for which the robustness ρϕ(M(t)) is low. The
discriminator D simply learns the map t (cid:55)→ ρϕ(M(t)).

Initially a random search is performed to obtain training
data for D. Then we ﬁnd new tests and train G as follows. We
generate candidate tests with G and estimate their robustness
with D (this avoids executing tests on the SUT). Whenever a
test with high estimated robustness is found, we execute it on
the SUT, add the test and its robustness to the training data,
and train D using this updated training data. We then sample
randomly points x1, . . ., xN from the latent space and form
the artiﬁcial training data

(xi, 0),

i = 1, . . . , N.

Using this training data, we train the composite model D ◦ G
with the model parameters of D frozen. Since 0 is the smallest

value the robustness function can attain, this encourages the
parameters of G to change in such a way that it generates
tests which D estimates to have low robustness. As more and
more data is collected, D should become more accurate and
G should thus generate tests with low robustness. Ideally G
generates a test with robustness 0 provided that ϕ is falsiﬁable.
Notice that our approach does not follow the traditional
GAN training [6] where the discriminator is trained to distin-
guish between fake and real samples. The traditional approach
is not possible here as we need to ﬁnd the tests online.

Our online GAN approach can be seen as an instance of
the idea of studying a SUT via a surrogate model which is
reﬁned over time as more information is available. The minBO
algorithm of [13] ﬁts into the same framework: their surrogate
model is a Gaussian process instead of an online GAN.

B. Online-GAN Algorithm for a Single Conjunctive Require-
ment

Here we present an online GAN algorithm which attempts
to falsify a single STL formula ϕ with robustness function ρ
deﬁned by ρ(t) = ρϕ(M(t)). In our context of falsifying the
safety requirements of a SUT, the formula can be thought
to be ϕ1 ∧ · · · ∧ ϕn,
is, we can only observe the
minimum robustness. The algorithm is presented in detail in
Algorithm 1. We remark that ﬁnding the robustness function ρ
is straightforward and implementations can be found in [14],
[7].

that

Algorithm 1: Online GAN test generation algorithm
for a single requirement.

1 T := Latin hypercube sampling(initial sample size);
2 GAN := new model with generator GN and

discriminator DN;

3 repeat
4

train(GAN, T);
target := 0;
repeat

5

6

7

8

target := target + ∆;
t := generate(GN);

9

10

until predict(DN, t) ≤ target;
outcome := robustness(t);
T := T ∪ {(t, outcome)};
11
12 until outcome ≤ 0 ∨ |T| = budget;
13 result test suite T

in Subsection III-A. The ﬁrst

The algorithm simply does what is described on a higher
level
task is to perform a
random search using a small part of our testing budget. In this
algorithm we propose to use Latin hypercube sampling [10]
for this purpose. After that, the algorithm proceeds with the
search driven by the GAN. The generator is used to ﬁnd a test
with high estimated ﬁtness in the inner loop. Initially we set
the target estimated ﬁtness to be 0 (falsiﬁed) but, as it is not
necessarily possible to generate such a test (especially just
after the algorithm has started), we raise the target on each

Fig. 1. Overview of the MATLAB model for the Automatic Transmission
Controller (AT) problem. Model source: [5].

execution of the loop until a candidate test is found. As more
training data is available, we should be able to achieve lower
and lower targets.

IV. EXPERIMENT 1: AUTOMATIC TRANSMISSION (AT)
MODEL

Fig. 2. Experiment 1: Box plot for number of executions needed for
falsiﬁcation.

In this section, we evaluate Algorithm 1 on the automatic
transmission (AT) model which is standard benchmark model
proposed in [11]. The model performs automatic gear selection
for a car when two input signals throttle and brake are provided
to it. The model outputs two signals: engine speed (in RPM)
and vehicle speed (in mph).

We are interested falsifying the requirement ϕ1 ∧ ϕ2 ∧ ϕ3

where

ϕ1 = ((cid:3)[0,30]RPM < 3000) → ((cid:3)[0,4]SPEED < 35),
ϕ2 = ((cid:3)[0,30]RPM < 3000) → ((cid:3)[0,8]SPEED < 50),
ϕ3 = ((cid:3)[0,30]RPM < 3000) → ((cid:3)[0,20]SPEED < 65).

These requirements are given, e.g., in the ARCH workshop
2021 competition [4]. They require that during the ﬁrst 30
time units (which is the complete duration of the signals)
the initial vehicle speeds should take values 35, 50, and 65
provided that the engine speed is below 3000 RPM during the
whole execution. The same falsiﬁcation problem is considered
in [13].

As in [4], we assume that 0 ≤ THROTTLE ≤ 100 and 0 ≤
BRAKE ≤ 325 during the whole execution (both signals can
be positive simultaneously). Our input signals are piecewise
constant functions with 6 pieces meaning that each input is
constant for 5 time units at a time. We discretize the signals by
sampling every 0.2 time units. We represent our tests as vectors
in R12 whose components satisfy the preceding requirements.
A general way to ﬁnd a robustness function for STL
formulas described in [2]. However such a direct approach
is problematic as RPM and SPEED are measured on very

different scales. We use the following ad hoc robustness
function ρ1 for ϕ1:

(cid:40) 1

2 (35 − MSPEED)/35, if MRPM < 3000
MRPM/3000 − 1
2 ,

otherwise

,

ρ1(RPM, SPEED) =

where

MRPM = sup

RPM(t) and

t∈[0,30]

MSPEED = sup
t∈[0,4]

SPEED(t).

We deﬁne robustness functions ρ2 and ρ3 analogously for
ϕ2 and ϕ3. It
is readily checked that ϕi
is falsiﬁed if
and only if there exists a signal (RPM, SPEED) such that
ρi(RPM, SPEED) < 0.

We attempt to falsify the requirement ϕ1 ∧ ϕ2 ∧ ϕ3 using
Algorithm 1. Due to the stochastic nature of the algorithm, we
repeat the falsiﬁcation task 50 times. We allow 80 executions
on the SUT and use 25% of the execution budget for random
search (Latin hypercube sampling). We have implemented
Algorithm 1 in Python using TensorFlow for GAN implemen-
tation. The SUT is implemented in MATLAB as a Simulink
model available at the ARCH veriﬁcation competition reposi-
tory.1 The model is called via the MATLAB Python engine.
The box plot for the number of executions on the SUT
required for falsiﬁcation is found in Figure 2. Algorithm 1
succeeded in falsiﬁcation in each replication with mean 22.8
(SD 4.4) executions required for a successful falsiﬁcation.
Since 20 executions were allowed for random search, we

1https://gitlab.com/goranf/ARCH-COMP

A1 Single conjunctive requirement5101520253035Number of evaluations to falsifyconclude that
typically the random search was unable to
falsify the requirement but the GAN could with just a few
extra executions. This shows that Algorithm 1 is capable for
falsiﬁcation as intended.

Interestingly, the minBO algorithm of [13] needed on av-
erage 68.7 executions for falsiﬁcation. We explain the differ-
ence as follows. During research, we observed that the AT
requirements are easily falsiﬁed for constant input signals.
When the GAN is trained for the ﬁrst time, it is typical
that the components of its output are close to the middles
of the allowed ranges. The ﬁrst test proposed by the GAN is
thus approximately constant and has high chance succeeding
in falsiﬁcation. We take this as an indication that the tests
proposed by the minBO algorithm are not approximately
constant.

We should note that we have not reproduced the results
presented in [13] ourselves. Instead, we used the ﬁgures of
the article, and therefore we cannot be certain that all the
algorithms are evaluated under the same conditions.

V. ONLINE-GAN ALGORITHMS FOR MULTIPLE
REQUIREMENTS

In this section, we present two Algorithms 2 and 3 which
better take into account the information on multiple require-
ments.

A. Multiple Requirements

In Algorithm 2, we present an online GAN algorithm which
attempts to falsify multiple requirements ϕ1, . . ., ϕn with
corresponding robustness functions ρ1, . . ., ρn.

Algorithm 2: Online GAN test generation algorithm
for multiple requirements.

1 T := Latin hypercube sampling(initial sample size);
2 GAN := nproperties new models with generators GN

and discriminators DN;

3 repeat
4

5

6

7

8

9

10

11

12

13

14

15

16

17

for i ∈ [1..nproperties] do
train(GAN, i, T);

end
target := 0;
repeat

target := target + ∆;
for i ∈ [1..nproperties] do
t[i] := generate(GN[i]);
p[i] := predict(DN[i], t[i]);

end
best := argmin(p);
until p[best] ≤ target;
outcome := robustness(t[best]);
best = min(outcome);
T := T ∪ {(t, outcome)};

18
19 until best ≤ 0 ∨ |T| = budget;
20 result test suite T

The difference to Algorithm 1 is that we train n online
GANs, one for each requirement ϕi. When we search for a
candidate test, we consult the generators of each GAN and
select the test which the corresponding discriminator estimates
to have the lowest robustness. Again, we raise the target
robustness until a candidate test is found.

B. Multiple Requirements with Property Selection

Next we introduce a new idea which addresses an obvious
problem with Algorithm 2: the requirements ϕ1, . . ., ϕn are
not equal, so they should not be given the same amount of
consideration. Indeed, if there is a falsiﬁable requirement,
then there is a requirement that is easiest to falsify and we
should focus only on it. This saves both generation time
and executions on the SUT. The problem is, of course, that
we do not know which requirement (if any) is the easiest.
Moreover, we are studying the requirements indirectly via
the online GANs G1, . . ., Gn which act as surrogate models
for the requirements and change over time. Our problem is
thus similar to the nonstationary multi-armed bandit (MAB)
problem [18]: how to explore all the surrogate models Gi and
how to exploit the ones we deem to be the best?

We propose the following simple approach for solving the
problem. Whenever a candidate test is executed on the SUT,
we record which surrogate model Gi achieved the lowest
robustness. Using these records we keep track of success
frequencies p1, . . ., pn for each surrogate model. When a
new candidate test needs to be generated, we proceed as
follows: we pick a random surrogate model G according to the
frequencies p1, . . ., pn and use G to generate a new candidate
test. In an initial warm-up period, we consult all surrogate
models in order to obtain good initial estimates for the success
frequencies.

The described strategy clearly satisﬁes the requirements of
exploration and exploitation: the historically most successful
surrogate model is most likely being selected again, but there
is a chance that another is selected, which perhaps leads to
favoring an easily falsiﬁable requirement which initially looks
unpromising. The success of this approach obviously depends
on the nature of the requirements ϕ1, . . ., ϕn and the quality
of the initial random search. We leave it as an open problem
to develop a better strategy which would take into account the
available information better. Recall that the minBO algorithm
of [13] uses expected improvement to detect tests which likely
have low robustness.

The variant of Algorithm 2 with the above MAB-inspired
approach is described in detail in Algorithm 3. On line 3,
we pick a single GAN to be used for candidate generation
based on the success frequencies. On line 13, we record which
GAN achieved the lowest robustness when the selected test
was executed on the SUT. Notice that this GAN might be
different from the GAN used for candidate test generation.

VI. EXPERIMENT 2: MO3D

In this section, we evaluate the three algorithms on a
synthetic problem proposed in [13]. It concerns the nonlinear

Algorithm 3: Online GAN test generation algorithm
for multiple requirements with property selection.

1 Apply Algorithm 2 for N% of the total budget.
2 repeat
3

chosen := pick one from [1..nproperties] with
weights winner[1..nproperties] ;
train(GAN, chosen, T);
target := 0;
repeat

target := target + ∆;
t := generate(GN);
p := predict(DN, t);

until p ≤ target;
outcome := robustness(execute(t));
best, best_index = min(outcome), argmin(outcome);
winner[best_index] := winner[best_index] + 1;
T := T ∪ {(t, outcome)};

14
15 until best ≤ 0 ∨ |T| = budget;
16 result test suite T

4

5

6

7

8

9

10

11

12

13

Fig. 3. Experiment 2: Percentage of successful falsiﬁcations.

TABLE I
MAIN STATISTICS OF EXPERIMENT 2.

Falsiﬁcations after 50 repetitions
% of falsiﬁcations
Median observed minimum
Mean observed minimum
SD observed minimum

A3
A2
A1
46
39
16
32%
92%
78%
2.84 −1.36 −2.01
3.39 −1.00 −1.67
1.25
1.72
4.59

function mo3d : R3 → R3, mo3d(x) = (h1(x), h2(x), h3(x))
where

h1(x1, x2, x3) = 305 − 100

3
(cid:88)

i=1
3
(cid:88)

h2(x1, x2, x3) = 230 − 75

cos

h3(x1, x2, x3) =

i=1

(xi − 7)2 −

3
(cid:88)

i=1

(cid:16) xi
2.5

(cid:17)

+ 15

, and

3
(cid:88)

i=1

cos

(cid:18) xi − 7
2.75

(cid:19)

.

This function achieves its componentwise minimum value at
x∗ = (7, 7, 7) with f (x∗) = h3(x∗) = −3. The other two
components achieve their minimum value of 5 at the points
3π/2(1, 1, 1) and −37.5(1, 1, 1) respectively.

We are interested in requiring that all elements of f (x)
should be greater than 0 in the input domain [−15, 15]3. This
can be represented in STL as

((cid:3)h1(x) > 0) ∧ ((cid:3)h2(x) > 0) ∧ ((cid:3)h3(x) > 0).

We simply use the functions h1, h2, and h3 themselves as
robustness functions. We repeat the falsiﬁcation task 50 times
for each algorithm. We allow 80 executions on the SUT and
use 25% of the execution budget for random search.

The results written in Table I show that Algorithm 1
succeeds in falsifying the given requirement only in 16 of the

sin

(cid:17)

,

(cid:16) xi
3

Fig. 4. Experiment 2: Box plots for minimum mo3d component over 50
experiments.

50 repetitions while Algorithms 2 and 3 succeed 39 and 46
times respectively. These correspond to 32%, 78%, and 92% of
the repetitions. The success ratios are represented visually in
Figure 3. The two proportion Z-test reports that the differences
in falsiﬁcation success rates between Algorithms 2 and 3 are
statistically signiﬁcant albeit with an observed p-value of 0.05.
Figure 4 shows box plots for the minima found by each
algorithm after 80 executions on the SUT. It clearly shows
again that Algorithms 2 and 3 perform better than Algorithm 1.
While Algorithm 1 produces a median greater than 0, Al-
gorithms 2 and 3 exhibit a median smaller than 0. When
comparing Algorithms 2 and 3, the ﬁrst one yields a median
of −1.36 while the later yields a median of −2.01. The
Wilcoxon signed-rank test reports a p-value of 0.02 under the
null hypothesis that the median of differences is 0.

Finally, Figure 5 shows the evolution of the mean observed
minimum over the sequence of function evaluations. We
observe how the mean for the minimum reported by Algorithm
3 becomes smaller than 0 with less evaluations than the other

A1 Single conjunctive requirementA2 Always multiple requirementsA3 MAB selection0.00.10.20.30.40.50.60.70.80.91.0Percentage of falsifications after 50 repetitionsA1 Single conjunctive requirementA2 Always multiple requirementsA3 MAB selection2.50.02.55.07.510.012.5Min mo3d component after 80 executionsefﬁcient than Algorithm 2 both in achieving the falsiﬁcation
with less function evaluations and using less computational
resources.

We should note that the presented evaluation of the pro-
posed algorithms is based on a small number of numerical
experiments. Also the performance comparisons between the
algorithms presented here and the algorithm presented in [13]
are only indicative.

As a future work, we acknowledge that a more compre-
hensive evaluation with a larger set of problems is necessary
in order to establish the beneﬁts of the proposed algorithms.
the theoretical underpinnings of the online GAN
Finally,
framework should be studied in more detail
in order to
understand better its beneﬁts and limitations as an optimization
tool.

Fig. 5. Experiment 2: Evolution of minimum mo3d component over number
of function evaluations, mean of 50 experiments.

ACKNOWLEDGMENTS

two algorithms.

We have thus empirically conﬁrmed that observing the ro-
bustness of each requirement separately can lead to signiﬁcant
improvement in falsiﬁcation rate and the number of executions
needed for falsiﬁcation. Moreover the multi-armed bandit
approach of focusing only on the most promising requirement
can bring further improvements in falsiﬁcation in addition to
saving signiﬁcantly on computational resources.

VII. CONCLUSIONS

In this paper we present a series of algorithms for
robustness-based falsiﬁcation of cyber-physical systems based
on the online GAN framework.

The online GAN framework for requirement falsiﬁcation
is a novel concept that apparently has not been proposed
before in the research literature. Both our approach and the
Bayesian optimization approach of [3] combine surrogate
model creation and test generation in an iterative loop. One
difference is that Bayesian optimization methods use a Gaus-
sian process as a surrogate model while we use a neural
network. However we consider that the main difference is
that Bayesian optimization methods must query the Gaussian
process to determine the next input to evaluate while our
approach uses a generative neural network that serves as a
model of the space of falsifying inputs. The surrogate model
and the generator model are trained together as in a GAN. Our
early results indicate that Algorithm 1, based on the online
GAN framework, exhibits a competitive performance when
compared to the results published in [13].

We also present an extension of our basic algorithm to pro-
cess conjunctive requirements more efﬁciently. The approach
adopted in Algorithm 2 is based on the solution provided
in [13]. Algorithm 2 conﬁrms that the idea of unfolding a
single conjunctive requirement in multiples requirements can
also be used with the online GAN framework. Algorithm 2
is then extended with the addition of a multi-armed bandit to
produce Algorithm 3. In our experiment, Algorithm 3 is more

This research work has received funding from the ECSEL
Joint Undertaking (JU) under grant agreement No 101007350.
The JU receives support from the European Union’s Horizon
2021 research and innovation programme and Sweden, Aus-
tria, Czech Republic, Finland, France, Italy, Spain.

REFERENCES

[1] F. Archetti and A. Candelieri. Bayesian Optimization and Data Science.

SpringerBriefs in Optimization. Springer, 2019.

[2] A. Donzé and O. Maler. Robust satisfaction of temporal logic over real-
valued signals. In K. Chatterjee and T. A. Henzinger, editors, Formal
Modeling and Analysis of Timed Systems, pages 92–106. Springer Berlin
Heidelberg, 2010.

[3] A. Corso et al. A survey of algorithms for black-box safety validation.

CoRR, abs/2005.02979, 2020.

[4] G. Ernst et al. Arch-comp 2021 category report: Falsiﬁcation with vali-
dation of results. In G. Frehse and M. Althoff, editors, 8th International
Workshop on Applied Veriﬁcation of Continuous and Hybrid Systems
(ARCH21), volume 80 of EPiC Series in Computing, pages 133–152.
EasyChair, 2021.

[5] Gidon Ernst et al. Arch-comp 2020 category report: Falsiﬁcation.
In G. Frehse and M. Althoff, editors, 7th International Workshop on
Applied Veriﬁcation of Continuous and Hybrid Systems (ARCH20),
volume 74 of EPiC Series in Computing, pages 140–152. EasyChair,
2020.

[6] I. J. Goodfellow et al. Generative adversarial networks. CoRR,

abs/1406.2661, 2014.

[7] J. Cralley et al. TLTk: A toolbox for parallel robustness computation of
temporal logic speciﬁcations. In J. Deshmukh and D. Niˇckovi´c, editors,
Runtime Veriﬁcation, pages 404–416. Springer International Publishing,
2020.

[8] L. Mathesen et al. Falsiﬁcation of cyber-physical systems with ro-
bustness uncertainty quantiﬁcation through stochastic optimization with
adaptive restart. In 15th IEEE International Conference on Automation
Science and Engineering, CASE 2019, pages 991–997. IEEE, 2019.
[9] P. Heidlauf et al. Veriﬁcation challenges in F-16 ground collision
In G. Frehse, editor, 5th
avoidance and other automated maneuvers.
International Workshop on Applied Veriﬁcation of Continuous and
Hybrid Systems (ARCH18), volume 54 of EPiC Series in Computing,
pages 208–217. EasyChair, 2018.

[10] J. C. Helton and F. J. Davis. Latin hypercube sampling and the
propagation of uncertainty in analyses of complex systems. Reliab. Eng.
Syst. Saf., 81(1):23–69, 2003.

[11] B. Hoxha, H. Abbas, and G. Fainekos. Benchmarks for temporal logic
In G. Frehse and M. Althoff,
requirements for automotive systems.
editors, 1st and 2nd International Workshop on Applied Veriﬁcation
for Continuous and Hybrid Systems (ARCH14-15), volume 34 of EPiC
Series in Computing, pages 25–30. EasyChair, 2015.

20304050607080Evaluations performed5051015202530Mean min mo3d componentA1 Single conjunctive requirementA2 Always multiple requirementsA3 MAB selection[12] O. Maler and D. Nickovic. Monitoring temporal properties of continuous
signals. In Yassine Lakhnech and Sergio Yovine, editors, Formal Tech-
niques, Modelling and Analysis of Timed and Fault-Tolerant Systems,
pages 152–166. Springer Berlin Heidelberg, 2004.

[13] L. Mathesen, G. Pedrielli, and G. Fainekos. Efﬁcient optimization-based
falsiﬁcation of cyber-physical systems with multiple conjunctive require-
In 2021 IEEE 17th International Conference on Automation
ments.
Science and Engineering (CASE), pages 732–737, 2021.

[14] D. Niˇckovi´c and T. Yamaguchi. RTAMT: Online robustness monitors
In D. Van Hung and O. Sokolsky, editors, Automated
from STL.
Technology for Veriﬁcation and Analysis, pages 564–571. Springer
International Publishing, 2020.

[15] I. Porres, H. Rexha, and S. Lafond. Online GANs for automatic
In IEEE International Conference on Software
performance testing.
Testing, Veriﬁcation and Validation Workshops (ICSTW 2021), pages
95–100, 2021.

[16] C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine
Learning. Adaptive Computation and Machine Learning. MIT Press,
2006.

[17] S. Sankaranarayanan and G. Fainekos. Falsiﬁcation of temporal proper-
ties of hybrid systems using the cross-entropy method. In Proceedings of
the 15th ACM International Conference on Hybrid Systems: Computa-
tion and Control, page 125–134. Association for Computing Machinery,
2012.
[18] A. Slivkins.

Introduction to multi-armed bandits. Foundations and

Trends® in Machine Learning, 12(1–2):1–286, 2019.

[19] Z. Zhang, I. Hasuo, and P. Arcaini. Multi-armed bandits for boolean
connectives in hybrid system falsiﬁcation. In I. Dillig and S. Tasiran,
editors, Computer Aided Veriﬁcation, pages 401–420. Springer Interna-
tional Publishing, 2019.

