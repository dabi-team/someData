libACA, pyACA, and ACA-Code: Audio Content Analysis in 3 Languages

Alexander Lerch

Abstract

The three packages libACA, pyACA, and ACA-Code provide reference implementations for basic approaches
and algorithms for the analysis of musical audio signals in three diﬀerent languages: C++, Python, and Matlab.
All three packages cover the same algorithms, such as extraction of low level audio features, fundamental
frequency estimation, as well as simple approaches to chord recognition, musical key detection, and onset
detection. In addition, it implementations of more generic algorithms useful in audio content analysis such as
dynamic time warping and the Viterbi algorithm are provided. The three packages thus provide a practical
cross-language and cross-platform reference to students and engineers implementing audio analysis algorithms
and enable implementation-focused learning of algorithms for audio content analysis and music information
retrieval.

Keywords

Audio Content Analysis, Music Information Retrieval, C++, Python, Matlab

2
2
0
2

n
u
J

0
3

]

D
S
.
s
c
[

1
v
9
1
2
5
1
.
6
0
2
2
:
v
i
X
r
a

1

 
 
 
 
 
 
Code metadata

Nr. Code metadata description
C1
C2

link to code/repository

Current code version
Permanent
used for this code version
Permanent link to Reproducible Cap-
sule
Legal Code License
Code versioning system used
Software code languages, tools, and ser-
vices used
Compilation requirements, operating
environments & dependencies

C3

C4
C5
C6

C7

C8

C9

If available Link to developer documen-
tation/manual
Support email for questions

Please ﬁll in this column
v0.3.1
github.com/alexanderlerch/2022-ACA-SIMPAC

codeocean.com/capsule/b1eb9884-ac26-4292-b752-f7e02280f38c

MIT License
git
C++, Python, Matlab

C++: CMake with Gcc, Clang, or MSVC, C++11
Python: Python 3.x, Dependencies: numpy, scipy, matplotlib
Matlab: V2016x+, Dependencies: Signal Processing Toolbox
alexanderlerch.github.io/libACA
alexanderlerch.github.io/pyACA/
alexanderlerch.github.io/ACA-Code/

info@audiocontentanalysis.org

1. Introduction

The areas of audio content analysis and music information retrieval are growing ﬁelds with evolving demands
on software solutions available to researchers, teachers, software engineers, and system designers. There are,
therefore, diﬀerent objectives that a software can aim to address. Such objectives include, for example, to
eﬃciently solve a well-established problem, to design state-of-the art systems for potentially new tasks, to use
the software package in educational environments to demonstrate algorithmic properties, or to provide reference
implementations of established algorithms. Often, these objectives are not easily aligned, i.e., a software for
problem solving might not be useful for classroom teaching.

The software presented here implements many tasks related to audio analysis with a focus on educational
aspects. It provides reference implementations of multiple audio analysis algorithms such as feature extraction,
fundamental frequency detection, chord detection, etc.; what makes the software truly unique is that these
reference implementations are available in three diﬀerent programming languages: C++, Python, and Matlab.
Closely integrated with other educational materials such as lecture slides1 and based on the algorithmic intro-
ductions in the text book “An Introduction to Audio Content Analysis” [1], the three presented packages libACA
[2], pyACA [3], and ACA-Code [4] aim at giving students and engineers quick access to algorithmic implemen-
tations, fostering the understanding of practical implementation details that might otherwise be missed. Thus,
the presented three software packages are not in competition with popular existing open source frameworks for
audio content analysis such as libROSA [5] or Essentia [6] which target the easy utilization for audio analysis,
but complement these existing packages by providing easy access to algorithms through implementation in
three languages. This allows for a better separation of language-speciﬁc choices from algorithmic details. It
also provides an implementation focus that diﬀerentiates the ACA packages from classroom software such as
M¨uller and Zalkow’s FMP notebooks [7].

1

github.com/alexanderlerch/ACA-Slides/tree/2nd edition/, last accessed: Jun 28, 2022

2

2. Software description

2.1 Functionality

The functionality of all three packages, whether Matlab, Python, or C++, is identical. The software oﬀers
reference implementations for common low level spectral audio features such as Spectral Centroid, Crest Factor,
Flatness, MFCCs, Pitch Chroma, Rolloﬀ, and Skewness as well as time-domain features such as RMS and
Zero-Crossing-Rate. It also implements multiple fundamental frequency extraction algorithms based on auto
correlation, the harmonic product spectrum, and others. Example implementations of chord and key detection,
audio ﬁngerprint extraction, beat histogram computation, and onset detection, are complemented by reference
implementations of more general algorithms such as dynamic time warping, the Viterbi algorithm, a K nearest
neighbor classiﬁer, a Gaussian mixture model, K-means clustering, and principal component analysis. Sophis-
ticated machine learning methods are not utilized to avoid third-party dependencies (see below). One of the
core properties of the presented software is that all algorithms are implemented in three diﬀerent programming
languages C++, Python, and Matlab, each of which has speciﬁc advantages and drawbacks. Matlab/Octave has
been traditionally very prominent in the signal processing community and provides a monolithic environment
well-suited to quick prototyping and visualization. Python, probably the most widely used language in the ﬁeld
now, is appealing because it combines easy extensibility through modular packages, including easy availability
of powerful machine learning packages. C++ is, while not particularly suitable for algorithmic prototyping
and lacking easy extensibility, a language that is often used in production environments with high performance
requirements and is probably the most commonly used language in audio software. Having implementations in
all three languages increases versatility and accessibility and fosters better algorithmic understanding.

2.2 Design choices

The source code aims at demonstrating how to implement audio analysis solutions and at facilitating al-
gorithmic understanding. Thus, the design principles need to be somewhat diﬀerent from software to be used
in production environments. Most importantly, performance optimization is given a very low priority. High
priority is assigned to (i) readability, i.e., easily understandable and consistent variable, function, and ﬁle nam-
ing, (ii) implementing source code that can be executed on a variety of operating systems and environments
(C++ 11 compatibility, Python 3.x compatibility, Matlab 2016 compatibility), and (iii) reducing third-party
dependencies to avoid code/algorithm obfuscation, allow for easier maintainability, and ensure a code base with
consistent programming style. Note, however, that avoiding third-party dependencies tends to increase the
necessary number of lines of code — especially in the case of the C++ package — and shifts the focus towards
baseline approaches with low and medium level of sophistication. Deep learning approaches, for instance, are
generally avoided.

2.3 Future extensions

In the short-term, the packages will be extended with examples showcasing existing functionality in various
tasks. For instance, a simple music style classiﬁer can be built with the features, and one of the implemented
classiﬁers, and audio alignment can be implemented utilizing the dynamic time warping code. Simple extensions
of functionality can build, for example, on the non-negative matrix factorization to implement multi-pitch
detection or drum transcription systems. The highest priority for new implementations from scratch is the
currently missing task of beat tracking, a core task in music information retrieval.

3. Software impact

Audio content analysis includes a multitude of research areas, including: (i) speech analysis, e.g., automatic
speech recognition [8] or recognizing emotion in speech [9], (ii) urban sound analysis, e.g., noise pollution mon-
itoring [10] or the automatic detection of dangerous events [11], (iii) industrial sound analysis, e.g., monitoring
the state of mechanical devices like engines [12] or monitoring the health of livestock [13], and (iv) musical audio
analysis, targeting the understanding and extraction of musical parameters and properties from the audio signal
[14]. The presented software can be applied to all of these scenarios and can serve as an educational resource

3

as well as a foundation for research and commercial applications in these areas. It has been used in institutions
for higher education. Despite the focus on educational aspects, the software can be and has been used in a wide
variety of research scenarios, ranging from singing transcription [15] and crowd behavior estimation [16] over
EEG signal processing [17] to the analysis of sound imitation capacities of orca whales [18].

4. Conclusion

While implementations of most audio analysis algorithms can be found online, their usefulness for under-
standing algorithmic details is often hampered by diﬀerent coding styles, naming conventions, extended or
removed functionality, and the excessive use of third-party dependencies. The packages libACA, pyACA, and
ACA-Code address this problem by showcasing the implementation of a multitude of algorithms for audio con-
tent analysis in a consistent way with identical functionality in three diﬀerent languages: C++, Python, and
Matlab.

5. Acknowledgments

The author would like to thank Kaushal Sali (github: @kaushalsali) for his contributions to both pyACA

and ACA-Code.

6. References

[1] A. Lerch, An

Introduction

to Audio Content Analysis:

cessing
http://ieeexplore.ieee.org/xpl/bkabstractplus.jsp?bkn=6266785

and Music

Informatics.

Hoboken: Wiley-IEEE Press,

Applications
2012.

in

Signal Pro-
[Online]. Available:

[2] ——, “libACA: C++ Sources accompanying the Book ’An Introduction to Audio Content Analysis’,” Jun.

2022. [Online]. Available: https://github.com/alexanderlerch/libACA

[3] ——, “pyACA: Python Sources accompanying the Book ’An Introduction to Audio Content Analysis’,”

Feb. 2022. [Online]. Available: https://github.com/alexanderlerch/pyACA

[4] ——, “ACA-Code: Matlab Sources accompanying the Book ’An Introduction to Audio Content Analysis’,”

Apr. 2022. [Online]. Available: https://github.com/alexanderlerch/ACA-Code

[5] B. McFee, C. Raﬀel, D. Liang, D. Ellis, M. McVicar, E. Battenberg, and O. Nieto, “librosa: Audio and
Music Signal Analysis in Python,” in Proceedings of the Python in Science Conference, Austin, Texas,
2015, pp. 18–24. [Online]. Available: https://conference.scipy.org/proceedings/scipy2015/brian mcfee.html

[6] D. Bogdanov, N. Wack, E. G´omez, S. Gulati, P. Herrera, O. Mayor, G. Roma, J. Salamon,
J. Zapata, and X. Serra, “ESSENTIA: An Open-source Library for Sound and Music Analysis,” in
Proceedings of the ACM International Conference on Multimedia (ACMMM), ser. MM ’13. New
[Online]. Available:
York, NY, USA: Association for Computing Machinery, Oct. 2013, pp. 855–858.
https://doi.org/10.1145/2502081.2502229

[7] M. M¨uller and F. Zalkow, “libfmp: A Python Package for Fundamentals of Music Processing,”
[Online]. Available:

vol. 6, no. 63, p. 3326,

Jul. 2021.

Journal of Open Source Software,
https://joss.theoj.org/papers/10.21105/joss.03326

[8] X. Huang, J. Baker, and R. Reddy, “A Historical Perspective of Speech Recognition,” Communications of
the ACM, vol. 57, no. 1, pp. 94–103, Jan. 2014. [Online]. Available: https://doi.org/10.1145/2500887

4

[9] M. El Ayadi, M. S. Kamel, and F. Karray, “Survey on Speech Emotion Recognition: Features,
Classiﬁcation Schemes, and Databases,” Pattern Recognition, vol. 44, no. 3, pp. 572–587, Mar. 2011.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/S0031320310004619

[10] J. P. Bello, C. Mydlarz, and J. Salamon, “Sound Analysis in Smart Cities,” in Computational
[Online]. Available:

Springer, Cham, 2018, pp. 373–397.

Analysis of Sound Scenes and Events.
https://link.springer.com/chapter/10.1007/978-3-319-63450-0 13

[11] M. Crocco, M. Cristani, A. Trucco,

and V. Murino,

“Audio Surveillance:

Review,” ACM Computing Surveys, vol. 48, no. 4, pp. 52:1–52:46, Feb. 2016.
https://doi.org/10.1145/2871183

A Systematic
[Online]. Available:

[12] S. Grollmisch, J. Abeßer, J. Liebetrau, and H. Lukashevich, “Sounding Industry: Challenges and Datasets
for Industrial Sound Analysis,” in Proceedings of the European Signal Processing Conference (EUSIPCO),
A Coruna, Spain, Sep. 2019, pp. 1–5, iSSN: 2076-1465.

[13] D. Berckmans, M. Hemeryck, D. Berckmans, E. Vranken, and T. v. Waterschoot, “Animal Sound... Talks!
Real-time Sound Analysis for Health Monitoring in Livestock,” in Proceedings of the International Sympo-
sium on Animal Environment and Welfare (ISAEW), Chongqing, China, 2015.

[14] D. P. W. Ellis, “Extracting Information from Music Audio,” Communications of the ACM, vol. 49, no. 8,
pp. 32–37, Aug. 2006. [Online]. Available: http://portal.acm.org/citation.cfm?doid=1145287.1145310

[15] L.-X. Yang, “Singing Transcription Using Machine Learning with Feature Selection,” Master’s
[Online]. Available:

thesis, McGill University (Canada), Canada,
https://www.proquest.com/docview/2512806010/abstract/89DA62FCEAD74F0CPQ/1

iSBN: 9798597023083.

2015,

[16] B. A. Butler, K. Pedersen, M. R. Cook, S. G. Wadsworth, E. Todd, D. Stark, K. L. Gee, M. K.
Transtrum, and S. Warnick, “Classifying Crowd Behavior at Collegiate Basketball Games using Acoustic
Data,” Proceedings of Meetings on Acoustics, vol. 35, no. 1, p. 055006, Nov. 2018, publisher: Acoustical
Society of America. [Online]. Available: https://asa.scitation.org/doi/abs/10.1121/2.0001061

[17] A. Vinay, A. Lerch, and G. Leslie, “Mind the Beat: Detecting Audio Onsets from EEG Recordings
of Music Listening,” in Proceedings of the International Conference on Acoustics, Speech, and Signal
Institute of Electrical and Electronics Engineers
Processing (ICASSP). Toronto, Ontario, Canada:
(IEEE), 2021. [Online]. Available: https://arxiv.org/abs/2102.06393

[18] J. Z. Abramson, M. V. Hern´andez-Lloreda, L. Garc´ıa, F. Colmenares, F. Aboitiz, and J. Call, “Imitation
of Novel Conspeciﬁc and Human Speech Sounds in the Killer Whale (Orcinus orca),” Proceedings of the
Royal Society B: Biological Sciences, vol. 285, no. 1871, p. 20172171, Jan. 2018, publisher: Royal Society.
[Online]. Available: https://royalsocietypublishing.org/doi/10.1098/rspb.2017.2171

5

