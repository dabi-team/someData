2
2
0
2

l
u
J

1
2

]
P
A

.
t
a
t
s
[

1
v
6
0
4
0
1
.
7
0
2
2
:
v
i
X
r
a

Advice on describing Bayesian analysis of neutron and X-ray reﬂectometry∗

Andrew R. McCluskey,1, † Andrew J. Caruana,2 Christy J. Kinane,2 Alexander J. Armstrong,2
Tom Arnold,1 Joshaniel F. K. Cooper,2 David L. Cortie,3 Arwel V. Hughes,2 Jean-Fran¸cois
Moulin,4 Andrew R. J. Nelson,3 Wojciech Potrzebowski,1 and Vladimir Starostin5
(Open Reﬂectometry Standards Organisation)
1European Spallation Source ERIC, P.O. Box 176, SE-221 00, Lund, SE
2ISIS-Neutron and Muon Source, Rutherford Appleton Laboratory, Didcot, Oxon OX11 0QX, GB
3Australian Nuclear Science and Technology Organisation, Lucas Heights, New South Wales, AU
4German Engineering Material Science at Heinz Maier-Leibnitz Zentrum,
Helmholtz-Zentrum Hereon, Lichtenbergstraße 1, 85748 Garching, DE
5Institute of Applied Physics, University of T¨ubingen, Auf der Morgenstelle 10, 72076 T¨ubingen, DE

Driven by the availability of modern software and hardware, Bayesian analysis is becoming more
popular in neutron and X-ray reﬂectometry analysis. The understandability and replicability of
these analyses may be harmed by inconsistencies in how the probability distributions central to
Bayesian methods are represented in the literature. Herein, we provide advice on how to report the
results of Bayesian analysis as applied to neutron and X-ray reﬂectometry. This includes the clear
reporting of initial starting conditions, the prior probabilities, and results of any analysis, and the
posterior probabilities that are the Bayesian equivalent of the error bar, to enable replicability and
improve understanding. We believe that this advice, grounded in our experience working in the
ﬁeld, will enable greater analytical reproducibility among the reﬂectometry community, as well as
improve the quality and usability of results.

¥

I.

INTRODUCTION

Neutron and X-ray reﬂectometry are powerful tools to
probe the interfacial structure of materials [1]. However,
as a result of the “phase problem”, the analysis of these
techniques is ill-posed in nature, as there are multiple
possible solutions [2]. This has led to the use of Bayesian
analysis, where some prior understanding of the system
is used to aid our understanding of some reﬂectivity pro-
ﬁle [3–5]. Recently, developments in the availability of
computer software for reﬂectometry analysis that include
Bayesian functionality, such as Reﬂ1d, refnx, anaklasis,
and RasCAL [6–9], which implement sampling methods
from bumps, emcee, and dynesty [10–12], have led to an
increase in the utilisation of Bayesian methods by the
reﬂectometry community [13, 14].

This work will focus on the best practice for reporting
the results from Bayesian and sampling-based analysis
of neutron and X-ray reﬂectivity data. This work will
not introduce Bayesian or sampling methods for neutron
and X-ray reﬂectometry analysis. For those unfamiliar
with these techniques, we suggest the work of Sivia and
co-workers [5, 15] and more recent work focusing on re-
ﬂectometry analysis [7, 14, 16, 17]. We hope that this
work will inform best practices in data sharing from re-
ﬂectometry analysis and inspire software developers to
enable these to be accessed easily by the user.

∗ This work was developed as a part of the Open Reﬂectometry
Standards Organisation Workshop in 2022 with contributions
from all authors as part of a round-table discussion.

† andrew.mccluskey@ess.eu

Reﬂectometry analysis can be described, in the most
simplistic terms, as a comparison and reﬁnement of a
model based on some parameters, x, to reproduce some
reﬂectivity data set, D. This reﬁnement process involves
comparing the model to the data and calculating some
goodness-of-ﬁt value or likelihood, p(D|x), and modify-
ing the model to optimize the goodness-of-ﬁt or maximise
the likelihood. A commonly used goodness-of-ﬁt param-
eter is the χ2 parameter which is found as [7],

χ2 =

qmax
(cid:88)

q=qmin

(cid:20) (R(q) − R(q)m)
σR(q)

(cid:21)2

,

(1)

where, R(q) and R(q)m are the measured and mod-
elled reﬂectivity at a given q, the measured momen-
tum transfer vector, and σR(q) is the uncertainty as-
sociated with the measured reﬂectivity at each q point.
Under an assumption of normally distributed residuals
R(q) − R(q)m ∼ N (0, σR(q)), the likelihood is related to
the χ2 variable in the following way:

ln[p(D|x)] = −

(cid:18)

1
2

χ2 +

qmax
(cid:88)

(cid:19)
ln (cid:2)2πσR(q)2(cid:3)

.

(2)

q=qmin

The input for this reﬁnement process is the model and
some initial parameter values, which may be an absolute
value or some parameter range, depending on the reﬁne-
ment algorithm. While for some Bayesian sampling pro-
cess, the input is a probability distribution for each pa-
rameter, known as the prior. The output is a set of values
for x, potentially with associated error bars, where these
are present they typically describe a standard deviation
from the mean of a Gaussian probability distribution. A

 
 
 
 
 
 
Bayesian sampling process gives a probability distribu-
tion, the posterior, the deﬁnes the relative likelihood of
diﬀerent values of each parameter, from this we can re-
port statistical measures, e.g. mode/mean/median. This
process implicitly assumes that the data is completely
reduced, accounting for all experimental parameters, un-
certainties are accurately described and the model can
accurately describe the data.

The input required depends on a minimisation algo-
rithm being used, with some algorithms requiring a single
starting guess (such as traditional Newtonian methods)
and others taking a range of potential values (more com-
mon in stochastic approaches, like diﬀerential evolution).
The nature of these inputs deﬁnes the results of the anal-
ysis, therefore it is of the utmost importance that these
are shared as part of a publication describing the work.
Furthermore, the minimisation is often performed with
bounds in place, deﬁning that the parameter values will
lie within a given range. This range can be thought of
as having a prior probability distribution, p(x), where
values of x outside of this range have a probability of
0. Even when a non-Bayesian approach is used in the
analysis (i.e. Bayes theorem is not utilised), the result
where bounds are set would be analogous to a Bayesian
analysis with a uniform prior probability.

The optimised parameters from the minimisation algo-
rithm, which depend on the particular algorithm, often
include some statistical uncertainty. This uncertainty
comes from an assumption of normally distributed pa-
rameters [18], however, Bayesian sampling approaches
make no assumption of an underlying statistical distri-
bution. How these statistical uncertainties are found is
beyond the scope of this work, but it is important to ac-
knowledge that this uncertainty typically assumes that
the probability distribution of the parameter is Gaussian
in nature. This probability distribution is either the par-
tial likelihood or posterior, the latter when some prior is
included and Bayes theorem is applied. The posterior de-
scribes our understanding of the parameter values given
the data that was measured. When Bayesian modelling
is used and the prior is included, the posterior probability
is found as,

p(x|D) ∝ p(D|x)p(x).

(3)

Therefore, when Bayesian modelling is performed, the
priors and likelihood are of fundamental importance to
the results that are obtained (the posterior), and any
scientiﬁc conclusions that are drawn.

The use of Bayesian inference can be valuable in the
interpretation of reﬂectivity data, however, inconsistency
in the description of the process will result in analysis
that cannot be reproduced or easily understood. This
can range from not reporting the priors applied to each
parameter (e.g. the lower/upper limits for a uniform dis-
tribution that applies box bounds), to failing to share
the complete sampling chain of a Markov Chain Monte
Carlo sampling, or details of any autocorrelation analy-
sis (the last of which, the authors of this work admit to

2

TABLE I. An example of the presenting uniform priors in a
tabular format. Reproduced from [14], where each parameter
was either constrained to a given value or sampled within the
prior range.

Parameter Constrained Value Prior Range

3

dh/(cid:6)A
Vh/(cid:6)A
dt/(cid:6)A
φt
Vt/(cid:6)A
σ/(cid:6)A

3

10.0
339.5
21.0
1.0
850.4
2.9

[8.0, 16.0)
[300.0, 380.0)
[10.0, 26.0)
[0.5, 1.0]
[800.0, 1000.0)
[2.9, ∞)

being guilty of [13]). In this letter, we outline the best
practice for reporting the results of Bayesian analysis for
neutron and X-ray reﬂectometry, we hope that this work
will engage others to carefully consider how they report
this information. Furthermore, uptake of the approaches
discussed herein will lead to greater clarity about the
models and assumptions used in, and reproducibility of,
our analyses.

II. PRIOR

The most common probability distributions that are
used for a prior are uniform between a lower and upper
bound or a half-closed interval, where only a lower or up-
per bound is deﬁned. The use of a bounded parameter
along with some traditional χ2-minimisation method and
a parameter with a uniform prior and a Bayesian maxi-
mum a-posteriori approach will lead to the same result.
For priors that are uniform is it important that the upper
and lower bounds are reported, this can be achieved with
a simple table (see Table I for an example) to be included
in the article or supplementary information. Note, that
this table also gives information of “constrained” values,
where in some analysis parameters were not allowed to
vary, these constrained values can have a signiﬁcant im-
pact on the result of any analysis and therefore must also
be given.

Currently, the use of non-uniform, informative priors
is less common in reﬂectometry analysis. However, the
increasing popularity of Bayesian methods and interest
in using complementary methods for analysis means that
these are likely to become more popular in the coming
years. Here we will deﬁne two potential types of informa-
tive prior probabilities, those that can be described with
some mathematical function and those that cannot, for
example arising from the application of a sampling-based
analysis of a complementary technique.

When a prior probability can be described with a
mathematical function, this should be done by provid-
ing this function in the clearest possible language. For
example, if the prior is taken from a single complemen-
tary measurement that is deﬁned as a value with some
uncertainty, which represents a normal distribution with
a mean and standard deviation, this information should

3

FIG. 1. A prior probability distribution for Si3N4 with a
density of ρm = (2.9 ± 0.1) g cm−3.

¥

be provided. This is shown in Figure 1 for the density of
silicon nitride (Si3N4) produced by atomic layer deposi-
tion [19]) which is used to inform the value for a scatter-
ing length density for some layer of the material. Such a
prior probability distribution could be described graphi-
cally, Figure 1, or in prose as being “normally distributed
with a mean of 2.9 g cm−3 and a standard deviation of
0.1 g cm−3”, mathematically as,

p(ρm) =

1
√
2π

σ

(cid:34)

exp

−

(cid:18) ρm − µ
σ

1
2

(cid:19)2(cid:35)

(4)

where, µ = 2.9 g cm−3 and σ = 0.1 g cm−3, or more
concisely p(ρm) ∼ N (µ = 2.9 g cm−3, σ = 0.1 g cm−3).
The same descriptive approach could be taken for any
common statistical distribution, including log-normal or
truncated normal distributions.

It is possible that the prior distribution cannot be de-
scribed with a simple mathematical function, with multi-
modal priors being an example,
if it is a multimodal
model result from some other sampling method, then the
chain from the prior sampling should be given. The chain
is all of the samples investigated in the sampling and
should be shared, although in the case that this chain is
very large a subsampled object may be shared, in which
case, the autocorrelation analysis performed should be
described (see Section IV for a more complete discussion
of this). To use such a prior probability in Bayesian anal-
ysis, some functional description of the prior must be gen-
erated, most commonly this will be some kernel density
estimation, when this is used it is also necessary to state
the structure of the kernel being used. An example of this
is shown in Figure 2, where the prior probability for the
volume of a phospholipid tail could be found from molec-
ular dynamics simulation where there are three common
conformers that the lipid is likely to have.

III. LIKELIHOOD

Bayes theorem (given in Equation 3) consists of the
product of the prior and the likelihood. The former
describes our current understanding of the parameters

FIG. 2.
A hypothetical prior probability distribution for
a DPPC lipid that could arise from a molecular dynamics
simulation (orange histogram) and a Gaussian kernel density
estimation for the probability distribution using a bandwidth
factor of 0.05 (blue line).

¥

before we conduct some experiments, while the latter
describes how well the data is described by the model
parameters. Therefore, we must state how the likeli-
hood for a given model and data is calculated (giving
the analysis package used, version number, and if not
the default the likelihood option), in particular, because
although Equation 2 is a common approach, it assumes
a normally distributed uncertainty for a measured reﬂec-
tivity value. While a normally distributed uncertainty is
the most common, it may not be accurate in all circum-
stances, for example, when low numbers of counts are
present, a Poisson uncertainty may oﬀer a more accurate
description.

IV. POSTERIOR

Bayesian analysis methods typically involve using some
sampling process, such as Markov chain Monte Carlo, to
estimate the posterior probability distributions for each
of the parameters. Assuming there are m parameters un-
der investigation, the posterior will be an m-dimensional
probability distribution. The result of a Bayesian sam-
pling process is a “chain” consisting of n samples for
each parameter. Therefore, the full chain has a shape
(m, n). Typically these are histogrammed to show the
probability of diﬀerent values of the parameters. How-
ever, to identify independent (non-correlated) samples
in the chain, autocorrelation analysis [20] may be per-
formed and the chain “thinned”. We will not cover in
detail autocorrelation analysis other than to say that it
helps to identify the length of separation required for
samples to be independent and that thinning means that
we only included samples separated by this length in the
ﬁnal chain. Additionally, it is valuable to report the use
of convergence diagnostics, such as the Gelman-Rubin
statistic [21], which can assist in determining if a chain
appropriately describes a posterior.

Either the full posterior chain or the thinned chain

2.52.62.72.82.93.03.13.23.3ρm/gcm−301234p(ρm)/g−1cm38008258508759009259509751000Vt/Å30.000.010.020.03p(Vt)/Å−3Gaussian KDESampling result4

at the discretion of the user.
If the parameter distri-
bution passes a statistical test for a given distribution
type, this can be quoted in the work, with information
about the distribution type and the threshold value used,
and the distribution can be described based on ﬁtted pa-
rameters of the distribution as is discussed above for the
Gaussian distribution. For example, the three parame-
ters in Figure 3 pass this statistical tests, with p-values
of greater than 0.01 when 1000 random samples are
used, therefore we can quote the parameters as normal
distributions; ρmag = (1.366 ± 0.001) 10−6(cid:6)A
, ρm =
(8.390 ± 0.001) kgm−3, and d = (982.668 ± 0.121) (cid:6)A.

−2

If it is not possible to describe the m-dimensional dis-
tribution using some statistical test and a common dis-
tribution type, then conﬁdence intervals can be given.
Where these are used the percentage of the conﬁdence
interval must be deﬁned alongside it. Alongside these
conﬁdence intervals, it is typically most accurate to give
the maximum probability value for the parameter, rather
than the numerical mean which may sit in a region of
low probability. When reporting these quantiles of inter-
est, we should assess how much precision we prescribe to
them, which is typically achieved by deﬁning some Monte
Carlo standard error (MCSE) [27]. This is the variance
that would be observed should the sampling process be
repeated. Theres a range of approaches to compute the
MCSE, including the mcse method from the ArviZ pack-
age [28]. It is important to check that the MCSE is small
enough to report the level of precision desired for a given
parameter.

Regardless of how the chain is shared, as a component
of a fully reproducible analysis, the author should give
details of the software packages, scripts, and data used to
produce the analysis and any random number seeds that
were deﬁned. This means that if the chain is not avail-
able, the reader can rerun the sampling and replicate the
results. Included in this is information regarding speciﬁc
version numbers for diﬀerent software packages, as these
can create irreplicable results between version numbers.

V. CONCLUSION

The use of Bayesian analysis in neutron and X-ray re-
ﬂectometry is increasing, and alongside this, there is a
need for analytical clarity and reproducibility. We have
outlined the best practice, based on experience, for re-
porting information from Bayesian analysis. Speciﬁcally,
we have outlined how the prior probabilities used to in-
form our analyses should be stated, either as uniform
or more informed probability distributions that may or
maybe not be described mathematically. We mentioned
the importance of including the speciﬁc likelihood func-
tion used in an analysis. Additionally, we described how
best to present the results from our Bayesian analysis
in a clear and precise fashion, including the importance
of statistical tests and conﬁdence intervals in reporting.
We hope that this advice will be taken on by the reﬂec-

FIG. 3. An example of a graphical depiction of the unthinned
posterior as a corner plot (produced using the corner.py
package [23]), representing a three-dimensional probability
distribution showing the posterior distribution for the pa-
rameters of nickel magnetic scattering length density, nickel
mass density, and nickel layer thickness, from the analysis of
a nickel layer on a silicon block.

¥

should be shared along with details of any autocorre-
lation analysis to accompany any Bayesian or sampling
analysis. This will allow the best replication and veriﬁca-
tion of any results obtained from the data. Furthermore,
large output ﬁles such as these chains can be easily shared
using some versioned data repository, such as Zenodo [22]
or those available at speciﬁc institutions. Additionally,
to allow the reader to quickly interpret the sampled pos-
terior, a graphical description (such as that in Figure 3)
should be included, at a minimum, in the supplementary
information of the work. The importance of presenting
the full posterior graphically lies in the ability to easily
interpret correlations between parameters through this
medium. For example, in Figure 3, the ellipsoidal prob-
ability distribution (for the d/rho) parameters indicates
correlation.

To report values for parameters and some form of sta-
tistical uncertainty, two approaches can be taken from
the posterior chain. The ﬁrst is to use some known
statistical distribution that describes the samples well.
This is best deﬁned for a normal distribution, for which
there are statistical tests to check normality, such as the
D’Agostino and Pearson’s test [24, 25] (which is available
in the SciPy library as scipy.stats.normaltest [26]).
As with all statistical tests, this requires some thresh-
old value to be deﬁned to reject the null hypothesis, for
this value we recommend 0.001 but accept that this is

8.3858.3908.395ρ/kgm−31.3601.3651.370ρmag/10−6Å−2982.5983.0d/Å8.3858.3908.395ρ/kgm−3982.5983.0d/Åtometry community and in future, there will be greater
consistency and clarity in the reporting of results from
Bayesian methods. Furthermore, we hope that devel-
opers of analysis software will take this work as a call
to arms to include these best practices as easy-to-access
methods in their software. Finally, if the results of neu-
tron and X-ray Bayesian analysis are shared as outlined
in this work, then the analysis will be both reproducible
and comprehensible.

DATA AVAILABILITY

Electronic Supplementary Information (ESI) avail-
able: All analysis/plotting scripts and data ﬁles al-
lowing for a fully reproducible and automated analysis
workﬂow, using
[29, 30], for this work
is available at https://github.com/arm61/reporting_
sampling (DOI: 10.5281/zenodo.6874560) under an MIT

license, while the paper is shared under a CC BY-SA 4.0
license [31].

5

CReDiT AUTHOR STATEMENT

A.R.M: Conceptualization, Methodology, Resources,
Writing - original draft, Writing - review & editing, Visu-
alisation, Project administration. A.J.C & C.J.K.: Con-
ceptualization, Writing - review & editing. Other au-
thors: Writing - review & editing.

ACKNOWLEDGMENTS

All authors gratefully acknowledge the contribution of
Rev. T. Bayes (1701-1761) and D. S. Sivia, an early pio-
neer in using Bayesian methods in reﬂectometry analysis.

[1] Lovell, M. R. & Richardson, R. M. Analysis methods
in neutron and X-ray reﬂectometry. Curr. Opin. Colloid
Interface Sci. 4, 197–204 (1999).

[2] Majkrzak, C. F. & Berk, N. F. Exact determination of
the phase in neutron reﬂectometry. Phys. Rev. B 52,
10827–10830 (1995).

[3] Sivia, D., Hamilton, W. & Smith, G. Analysis of neutron
reﬂectivity data: maximum entropy, Bayesian spectral
analysis and speckle holography. Physica B: Condens.
Matter 173, 121–138 (1991).

[4] Geoghegan, M., Jones, R. A. L., Sivia, D. S., Penfold, J.
& Clough, A. S. Experimental study of surface segrega-
tion and wetting in ﬁlms of a partially miscible polymer
blend. Phys. Rev. E 53, 825–837 (1996).

[5] Sivia, D. & Webster, J. The Bayesian approach to reﬂec-
tivity data. Physica B: Condens. Matter 248, 327–337
(1998).

[6] Kienzle, P. A., Krycka, J., Patel, N. & Sahin, I. Reﬂ1d

0.8.15. https://refl1d.readthedocs.io/ (2021).

[7] Nelson, A. R. J. & Prescott, S. W. refnx : neutron and
X-ray reﬂectometry analysis in Python. J. Appl. Crys-
tallogr. 52, 193–200 (2019).

[8] Koutsioubas, A. anaklasis: a compact software package
for model-based analysis of specular neutron and X-ray
reﬂectometry data sets. J. Appl. Crystallogr. 54, 1857–
1866 (2021).

[9] Hughes, A. V. Rascal v1.1.0. https://github.com/

arwelHughes/RasCAL_2019 (2021).

[10] Kienzle, P. A., Krycka, J., Patel, N. & Sahin, I. Bumps

0.8.1. https://bumps.readthedocs.io/ (2021).

[11] Foreman-Mackey, D. et al. emcee v3: A Python ensem-
ble sampling toolkit for aﬃne-invariant MCMC. J. Open
Source Softw. 4, 1864 (2019).

[12] Speagle, J. S. dynesty: a dynamic nested sampling pack-
age for estimating Bayesian posteriors and evidences.
Mon. Notices Royal Astron. Soc. 493, 3132–3158 (2020).
[13] McCluskey, A. R. et al. Bayesian determination of the
eﬀect of a deep eutectic solvent on the structure of lipid
monolayers. Phys. Chem. Chem. Phys. 21, 6133–6141

(2019).

[14] McCluskey, A. R., Cooper, J. F. K., Arnold, T. & Snow,
T. A general approach to maximise information density
in neutron reﬂectometry analysis. Mach. Learn.: Sci.
Technol. 1, 035002 (2020).

[15] Sivia, D. S. & Skelling, J. Data Analysis : a Bayesian
tutorial (Oxford University Press, Oxford, GB, 2006).
[16] Hughes, A. V. et al. Physical Properties of Bacte-
rial Outer Membrane Models: Neutron Reﬂectometry
& Molecular Simulation. Biophys. J. 116, 1095–1104
(2019).

[17] Aboljadayel, R. O. M. et al. Determining the Proximity
Eﬀect Induced Magnetic Moment in Graphene by Polar-
ized Neutron Reﬂectivity and X-ray Magnetic Circular
Dichroism (2021). arXiv:2101.09946.

[18] Bevington, P. & Robinson, D. K. Data Reduction and
Error Analysis for the Physical Sciences (McGraw-Hill
Education, New York City, US, 2002), 3 edn.

[19] Knoops, H. C. M. et al. Atomic Layer Deposition of
Silicon Nitride from Bis(tert-butylamino)silane and N2
Plasma. ACS Appl. Mater. Interfaces 7, 19857–19862
(2015).

[20] Sokal, A. Monte Carlo Methods in Statistical Mechan-
ics: Foundations and New Algorithms.
In DeWitt-
Morette, C., Cartier, P. & Folacci, A. (eds.) Functional
Integration: Basics and Applications, chap. 6, 131–192
(Springer, New York City, US, 1997).

[21] Gelman, A. & Rubin, D. B.

Inference from Iterative
Simulation using Multiple Sequences. Stat. Sci. 7, 457–
472 (1992).

[22] European Organization For Nuclear Research & Ope-

nAIRE. Zenodo (2013).

[23] Foreman-Mackey, D. corner.py: Scatterplot matrices in

Python. J. Open Source Softw. 1, 24 (2016).

[24] D’Agstino, R. B. An omnibus test of normality for mod-
erate and large size samples. Biometrika 58, 341–348
(1971).

[25] D’Agostino, R. & Pearson, E. S. Tests for departure from

normality. Biometrika 60, 613–622 (1973).

showyourwork![26] Virtanen, P. et al. SciPy 1.0:

fundamental algorithms
for scientiﬁc computing in Python. Nat. Methods 17,
261–272 (2020).

[27] Vehtari, A., Gelman, A., Simpson, D., Carpenter, B. &
B¨u¨ukner, P.-C. Rank-Normalization, Folding, and Lo-
calization: An Improved (cid:98)R for Assessing Convergence of
MCMC (with Discussion). Bayesian Anal. 16, 667–718
(2021).

[28] Kumar, R., Carroll, C., Hartikainen, A. & Martin,
O. ArviZ a uniﬁed library for exploratory analysis of

Bayesian models in python. J. Open Source Softw. 4,
1143 (2019).

[29] Luger, R.

showyourwork.

https://github.com/

showyourwork/showyourwork (2022).

[30] Luger, R. et al. Mapping stellar surfaces III: An Eﬃ-
cient, Scalable, and Open-Source Doppler Imaging Model
(2021). arXiv:2110.06271.

[31] McCluskey, A. R. et al. ESI for “Advice on describing
Bayesian analysis of neutron and X-ray reﬂectometry”
(2022). URL https://github.com/arm61/reporting_
sampling.

6

