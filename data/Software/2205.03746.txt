2
2
0
2

y
a
M
8

]

R
C
.
s
c
[

1
v
6
4
7
3
0
.
5
0
2
2
:
v
i
X
r
a

Reasoning about inter-procedural security
requirements in IoT applications

Mattia Paccamiccio, Leonardo Mostarda

Abstract The importance of information security dramatically increased and will
further grow due to the shape and nature of the modern computing industry. Soft-
ware is published at a continuously increasing pace. The Internet of Things and
security protocols are two examples of domains that pose a great security challenge,
due to how diverse the needs for those software may be, and a generalisation of the
capabilities regarding the toolchain necessary for testing is becoming a necessity.
Oftentimes, these software are designed starting from a formal model, which can be
veriﬁed with appropriate model checkers. These models, though, do not represent
the actual implementation, which can deviate from the model and hence certain se-
curity properties might not be inherited from the model, or additional issues could
be introduced in the implementation. In this paper we describe a proposal for a novel
technique to assess software security properties from LLVM bitcode. We perform
various static analyses, such as points-to analysis, call graph and control-ﬂow graph,
with the aim of deriving from them an ’accurate enough’ formal model of the paths
taken by the program, which are then going to be examined via consolidated tech-
niques by matching them against a set of deﬁned rules. The proposed workﬂow then
requires further analysis with more precise methods if a rule is violated, in order
to assess the actual feasibility of such path(s). This step is required as the analyses
performed to derive the model to analyse are over-approximating the behaviour of
the software.

Mattia Paccamiccio
Universit`a di Camerino, Via Andrea d’Accorso 16, 62032 Camerino, e-mail: mattia.
paccamiccio@unicam.it

Leonardo Mostarda
Universit`a di Camerino, Via Andrea d’Accorso 16, 62032 Camerino, e-mail: leonardo.
mostarda@unicam.it

1

 
 
 
 
 
 
2

1 Introduction

Mattia Paccamiccio, Leonardo Mostarda

The veriﬁcation of software security properties is a critical step when implementing
software of any kind. More importantly, in a scenario where we want to assess the
logical implementation of a software, we would like to perform, at least in a ﬁrst
instance, the analysis statically because of the following reasons: i) covering all
possible environmental conditions can be unfeasible; ii) the code coverage achieved
through concrete execution might not be optimal and the poor scaling capabilities
of symbolic execution make it unfeasible for this kind of task. The assessment of
the logical part of a software is often left to model-checking without considering
the code. While the model and its validation can be correct, the implementation can
differ from the model, hence there might be the possibility for some properties of
the model to be invalidated.

Other problems arising with certain implementations can be the unavailability
of the source code, the toolchain employed to compile it into machine code and/or
execute it in a machine with suitable computing power. Dealing with multi-threaded
applications increases the complexity of such analyses, as race conditions might
happen spuriously if calling order and conditions are not properly enforced. Our
approach aims to tackle the detection of violations of inter-procedural requirements
in a scalable, fast and static manner.

Consider the following snippet of code:

Listing 1 Example of the usage of sockets in C languase.

int main(void) {

struct sockaddr_in servername;
int sock = socket(PF_INET, SOCK_STREAM, 0);
if (sock < 0) { exit (EXIT_FAILURE); }
init_sockaddr (&servername, SERVERHOST, PORT);
if (0 > connect(sock, (struct sockaddr *)&servername,
sizeof(servername))) { exit(EXIT_FAILURE); }

write_to_server(sock);
close(sock);
exit(EXIT_SUCCESS);

}

Our goal is to check that whenever there is a call to write to server(), the methods
init sockaddr(), connect() and close() are also being called, enforcing the order of
these calls. In this paper we refer to this type of requirements as rules.

These properties, which in the example above could cause a crash if the program
were not to be implemented correctly, could work as well to verify, for instance,
that there is no non-encrypted data being sent in certain phases of a hypothetical
protocol[1]. A higher degree of precision could be obtained by enforcing a speciﬁc
ﬂow. To further generalise we want to analyse if certain rules are always followed
in the implementation.

Reasoning about inter-procedural security requirements in IoT applications

3

1.1 Motivation

Consider the following scenario: the company XY has in its core business certain
services that are typically used via internet-enabled devices. These devices are of-
tentimes produced by third-parties, which we will call ABC, that take care of the
development of the apps that interface with such services via APIs. For the sake of
brevity we will assume the example device is a Smart Home Hub device. XY has the
need to validate whether or not the software in the Smart Hub Device is performing
the right operations when accessing the APIs. This to prevent having non-handled
exceptions visible from the front-end application, crashes or, worse, leakage of sen-
sitive data. XY has at its disposal the application executable but not its source ﬁles.
This paper aims to cover this speciﬁc use case.

1.2 Background: Call graph, Points-to, LLVM

A call graph is a type of control-ﬂow graph representing calling relationships be-
tween the subroutines of a software. The property of a statically computed call graph
is to be, typically, an over approximation of the real program’s behaviour [2]. It is
deﬁned as a may-analysis, which means that every calling relationship happening in
the program is represented in the graph and possibly some that do not. Notice that
computing the exact static call graph is an undecidable problem.

Points-to analysis is a static analysis technique that computes a model of the
memory that is used to retrieve what value or set of values a pointer variable will
have when de-referenced. Computing a precise call graph for languages that allow
for dynamic dispatching requires a precise points-to analysis and vice-versa. An-
other way to put it is points-to analysis precision is boosted by a precise call graph
computation and vice-versa, because they reduce the sets of possible call relation-
ships and points-to relationships by discarding the impossible ones.

The construction of both call-relationships and points-to relationships have vari-
ous degrees of sensitivity, which can be used to enhance the precision of the analysis.
It can be based on: context (call-site, object), ﬂow. [2].

LLVM [3] is a widely used compiler and tool-chain infrastructure. Its intermedi-
ate representation, called LLVM IR, acts as intermediate layer between high-level
programming languages and machine code, so that the compiler’s duty is to trans-
late the language to LLVM, which is then assembled into the targeted architecture
by LLVM itself. The purpose behind this is to simplify the source to binary transla-
tion process, by ofﬂoading architecture-speciﬁc logic from the compiler, task which
is instead performed by the LLVM assembler.

4

Mattia Paccamiccio, Leonardo Mostarda

2 Paper contribution

This paper presents a novel approach for the veriﬁcation of software security prop-
erties, speciﬁcally targeting IoT software but potentially extensible to other soft-
ware domains, such as security protocols. Our goal consists in obtaining a inter-
procedural control-ﬂow graph, apply transformations to it and using efﬁcient tech-
niques to performs analyses against a set of deﬁned rules. To reach this goal we need
to address the following basic questions: (i) would the approach taken be precise
enough for reconstructing the behaviour of the software?; (ii) will using this method
provide an advantage in terms of performance compared to other methods of analy-
sis?; (iii) what possible limitations can arise compared to other methodologies?; (iv)
how can those be addressed or mitigated?. In order to answer these questions we
reviewed the literature on the subject and performed several tests. Such experiments
targeted known edge-cases in the analyses we performed. More speciﬁcally we as-
sessed the precision for static call-graph generation and points-to and what could
be done, if anything, to improve the performance of the analysis. Our experiments
show that our set of approaches could allow for fast and sound analyses, appropriate
with the issue being tackled, as also conﬁrmed by the literature.

3 Related Work

In this section we review the state of the art in analyzing and reconstructing the
behaviour of a software and give a brief overview on the techniques used, their
strengths and weaknesses.

3.1 Concrete execution

Approaches based on concrete execution consist in executing the software in in-
strumented environments. The way they typically work is by the use of test cases,
aiming for maximum code coverage. As mentioned this approach is accurate when
it comes to vulnerability discovery and the reconstruction of a program’s behaviour
but is not best suited for our scope of analysis. It lacks in terms of performance when
computing call relationships and, most importantly, the coverage offered is limited
to the paths that are actually executed.

aﬂ++1 (american fuzzy lop) is a state of the art fuzzer for concrete executions. It
works like a traditional fuzzer: a binary is instrumented and random mutated inputs
are fed to the program to explore its states. It also supports LLVM bitcode fuzzing.

1 https://aﬂplus.plus , https://github.com/AFLplusplus/AFLplusplus

Reasoning about inter-procedural security requirements in IoT applications

5

3.2 Dynamic symbolic execution

Approaches based on symbolic execution consist in statically exploring a binary,
representing, ideally, all possible combination of paths it can take as states[4]. Its
scalability is poor due to the state-explosion problem which is an open research
problem. Methods to mitigate the issue have been proposed and implemented, by
selecting promising paths [5], by the means of executing the program backwards [6,
7], and merging paths on loops [8].

Valgrind [9] is an instrumentation framework for building dynamic analysis
tools. There are Valgrind tools that can automatically detect many memory man-
agement and threading bugs, and proﬁle programs in detail.

klee [10] is a symbolic execution tool capable of automatically generating tests
that achieve high coverage on a diverse set of complex and environmentally-
intensive programs. There are two main components: i) the symbolic virtual ma-
chine engine built on top of LLVM, ii) a POSIX/Linux emulation layer, which also
allows to make parts of the operating system environment symbolic.

3.3 Hybrid approaches

The capabilities of symbolic execution and dynamic execution can be combined in
order to mitigate each techniques’ limitations. Dynamic execution’s main weakness
is the lack of semantic insights inside the program’s reasoning and is prone to getting
stuck. This can be mitigated with symbolic execution, which ofﬂoads dynamic ex-
ecution by solving complex constraints, while the dynamic execution engine is fast
at exploring the ’trivial’ parts of a program and does not suffer from state explosion.
angr [11] is a programmable binary analysis toolkit that performs dynamic sym-
bolic execution and various static analyses on binaries. It allows for concolic ex-
ecution: a virtual machine emulates the architecture of the loaded binary and there
is a concrete execution driven by the symbolic exploration engine. This allows to re-
trieve concrete data from symbolic constraints, allowing for SMT solver ofﬂoading
and state thinning.

driller [5], based on angr, is a successful example of a symbolic execution engine

combined with the traditional fuzzer, aﬂ, with the beneﬁts mentioned above. ‘

3.4 Static Analysis

Approaches based on static analysis work by reasoning about the software without
executing it. Applications of the usage of static analysis techniques are: i) disassem-
blers, ii) linters, iii) data-ﬂow analyses, iv) model checking.

6

Mattia Paccamiccio, Leonardo Mostarda

Ddisasm [12] is a fast and accurate disassembler. It implements multiple static
analyses and heuristics in a combined Datalog implementation. Ddisasm is, at the
moment, the best-performing disassembler aimed at reassembling binaries.

cclyzer [13] is a tool for statically analyzing LLVM bitcode. It is built on Datalog
and works by querying a parsed version of the LLVM bitcode. It then performs
points-to analysis and call-graph construction on the facts generated. It is capable
of yielding highly precise analyses. It supports call-site sensitivity.

RetDec [14] is a retargetable decompiler based on LLVM. Its main feature is
the conversion of machine code to LLVM bitcode. It supports reconstruction of
functions, types, and high-level constructs. It is capable of generating call graphs
and control-ﬂow graphs.

McSema2 offers very similar functionalities and can be applied to the same scope
as RetDec. Its main difference from it is to use external software to deal with control-
ﬂow graph recovery (a step of paramount importance for disassembling).

4 Proposed approach

Our approach can be summarised by the diagram in ﬁgure 1 and will be further
explained in the following sections.

Fig. 1 Our approach.

4.1 Call relationships

We chose to base our workﬂow on LLVM, which allows to be quasi-agnostic to
binary, source or LLVM bitcode as a starting point, as source can be compiled to
LLVM and binary can be lifted to LLVM bitcode. The LLVM bitcode will then

2 https://github.com/lifting-bits/mcsema

Reasoning about inter-procedural security requirements in IoT applications

7

be used to perform points-to analysis with online call-graph construction, so to get
a accurate inter-procedural and infra-procedural view of the software. We would
obtain a model which would then be validated against our set of rules.

This could be formalised as follows:

∀ f , ∀c( f ) → ∃ϕ ∈ f( c( f ) ) ∪ f : ϕ ↑

(1)

The previous formula is read as follows: for each function f and c( f ) (c calls
function f ), there exists a set ϕ that is a subset of f(c( f )) (set of functions that
call functions calling f ) and f (that do not call f and c) so that ϕ is converging (up
arrow). The analysis, as introduced here, only reasons about call-relationships with
no considerations regarding ﬂow. We call this property converge. Our goal for the
scope of this paper has been to assess whether or not the model of tested software
can be tested against this rules and similar ones.

Consider the following example rule that encodes the fact that the call order is

connect, followed by write to server, followed by close:

rule { properties[] = ["converge","order"],

f[] = ["connect", "write_to_server", "close"]; }

What we want to verify is that for each of the functions speciﬁed in f[] the prop-
erty is ensured. The property converge is explained in the equation 1. The prop-
erty order means: the functions in f[] are executed in the speciﬁed order.

4.2 Program behaviour extraction

For complexity reasons we deem necessary to further simplify the model we anal-
yse, instead of working directly with control-ﬂow graphs. As mentioned in [15] we
can transform control-ﬂow graphs into context-free grammars. This allows for very
efﬁcient exploration and further simpliﬁcation of the model without compromising
soundness and accuracy for the intended scope.

4.3 Validation and reﬁnement

Once the behaviour has been extracted and matched against our set of rules, we ob-
tain the violations, if present. Since we are working in an over-approximated realm
we propose to apply selective symbolic execution to the paths that failed the vali-
dation in order to retrieve if: i) if such paths can exist; ii) test cases to replicate the
failure; iii) information to help debugging by locating the failure.

8

5 Experiments

Mattia Paccamiccio, Leonardo Mostarda

To evaluate if our methodology is feasible we tested our workﬂow on edge-cases
that make points-to analysis necessary to obtain an accurate call-graph. These tests
included: i) utilisation of pointers to data, ii) utilisation of calls and branched calls
to function pointers. The following snippets of code in C (compiled to LLVM) are
the examples we performed validations on:

Listing 2 ”branched funptr” snippet.

int main()
{

int in = 3;
void (*one)();
if (in > 5) {

one = &first;

} else {

one = &second;

}
(*one)();
return 0; }

Listing 3 ”branched funptr order” snippet.

int main()
{

int in = 3;
void (*one)(), void (*two)();
if (in > 5) {

one = &first;
two = &second;

} else {

one = &second;
two = &first;

}
(*one)();
(*two)();
return 0; }

Listing 4 Methods ”ﬁrst” and ”second”.

void first(){ puts("First"); } void second(){ puts("Second"); }

For the sake of brevity we included only the snippets involving branched function
pointers. At the time of writing we did not account for control-ﬂow in our experi-
ments but just on pure call relationships, as control-ﬂow recovery can be obtained
once the inter-procedural relationships are accurate. Additional analyses on GNU
binaries have been performed to test how fast the analysis would have been on more
sizeable software, considering performances only and not accuracy. The validation
of the rule formalised in 4.1 is left behind because the performance load is negligible
compared to the one given by computing the call-graph and points-to relationships.

Reasoning about inter-procedural security requirements in IoT applications

9

5.1 Experimental Results

We obtained positive results using Cclyzer[13] when performing points-to and call-
graph generation on LLVM bitcode. We also noted how the analysis becomes slower
when working with higher call-site sensitivities. We also tested RetDec[14] and Mc-
Sema3 as lifters, with the latter being the most accurate one. We did not perform
more detailed experiments on this aspect at the time of writing because we assumed
that we can have correct LLVM bitcode. Table 1 summarises the experimental re-
sults obtained with CClyzer. Such results show performance (time taken) only, based
on sensitivity and complexity (ﬁle size).

Target
fptr (snippets)
br fptr (snippets)
fptr order (snippets)
br fptr order (snippets)
dd (coreutils)
dd (coreutils)
ls (coreutils)
ls (coreutils)
cp (coreutils)
cp (coreutils)

Sensitivity
call-site-2
call-site-2
call-site-2
call-site-2
insensitive
call-site-2
insensitive
call-site-2
insensitive
call-site-2

Size (KB) Time (s)
2.5
2.8
2.6
2.8
273
273
612.3
612.3
733
733

6.39
6.12
6.33
6.24
14.27
16.23
22.57
27.38
28.50
31.49

Table 1 CClyzer performance tests for points-to analysis and call-graph construction. ”insensi-
tive” analyses do not take into account call-site, ”call-site-2” account for call-site up to depth 2.
Among the snippets the words: fptr, br, order mean respectively: call to function pointer, branched
and change of order, as shown in 5.

6 Conclusion and Future Work

The ﬁrst results of our methodology are positive and allow for basic validations
on our test samples. The test samples were designed to target applications where
points-to analysis is made necessary and met our expectations, both in precision
and performance.

6.1 Future developments

Future work includes adding parallel and ﬂow reasoning to the framework, thus ex-
tending the application to detection of call-order violations on both single and multi-
threaded application, enabling validation of operational order. This task is made

3 https://github.com/lifting-bits/mcsema

10

Mattia Paccamiccio, Leonardo Mostarda

easier by LLVM being a Single Static Assignment, hence having intrinsic ﬂow-
sensitivity [2]. To implement this step we propose to derive context-free grammars
from control-ﬂow graphs, as discussed in 4.2 and demonstrated in [15], allowing
for both call-order enforcement and veriﬁcation of atomicity properties in parallel
software. To narrow down unfeasible paths, we propose to use symbolic execution
to generate use-cases targeting the path(s) violating the rule(s) as it is more precise
than the previously performed analyses.

References

1. R. Sekaran, R. Patan, A. Raveendran, F. Al-Turjman, M. Ramachandran, L. Mostarda, Sur-
vival study on blockchain based 6g-enabled mobile edge computation for iot automation, IEEE
Access 8 (2020).

2. S. Yannis, B. George, Pointer analysis, Found. Trends Program. Lang. 2 (1) (2015) 1–69.
3. C. Lattner, LLVM: An Infrastructure for Multi-Stage Optimization, Master’s thesis, Computer

Science Dept., University of Illinois at Urbana-Champaign, Urbana, IL (Dec 2002).

4. C. Vannucchi, M. Diamanti, G. Mazzante, D. Cacciagrano, R. Culmone, N. Gorogiannis,
L. Mostarda, F. Raimondi, Symbolic veriﬁcation of event-condition-action rules in intelligent
environments, J. Reliab. Intell. Environ. 3 (2) (2017).

5. N. Stephens, J. Grosen, C. Salls, A. Dutcher, R. Wang, J. Corbetta, Y. Shoshitaishvili,
C. Kruegel, G. Vigna, Driller: Augmenting fuzzing through selective symbolic execution
(2016).

6. K. Ma, Y. P. Khoo, J. S. Foster, M. Hicks, Directed symbolic execution, in: E. Yahav (Ed.),
Static Analysis - 18th International Symposium, SAS 2011, 2011. Proceedings, Vol. 6887 of
Lecture Notes in Computer Science, Springer, 2011, pp. 95–111.

7. C. Basile, D. Canavese, J. d’Annoville, B. D. Sutter, F. Valenza, Automatic discovery of soft-
ware attacks via backward reasoning, in: P. Falcarin, B. Wyseur (Eds.), 1st IEEE/ACM Inter-
national Workshop on Software Protection, SPRO 2015, IEEE Computer Society, 2015, pp.
52–58.

8. T. Avgerinos, A. Rebert, S. K. Cha, D. Brumley, Enhancing symbolic execution with veritest-
ing, in: P. Jalote, L. C. Briand, A. van der Hoek (Eds.), 36th International Conference on
Software Engineering, ICSE ’14, 2014, ACM, 2014, pp. 1083–1094.

9. N. Nethercote, J. Seward, Valgrind: a framework for heavyweight dynamic binary instrumen-
tation, in: J. Ferrante, K. S. McKinley (Eds.), Proceedings of the ACM SIGPLAN 2007 Con-
ference on Programming Language Design and Implementation, 2007, ACM, 2007, pp. 89–
100.

10. C. Cadar, D. Dunbar, D. R. Engler, KLEE: unassisted and automatic generation of high-
coverage tests for complex systems programs, in: R. Draves, R. van Renesse (Eds.), 8th
USENIX Symposium on Operating Systems Design and Implementation, OSDI 2008,
USENIX Association, 2008, pp. 209–224.

11. Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino, A. Dutcher, J. Grosen, S. Feng,
C. Hauser, C. Kruegel, G. Vigna, Sok: (state of) the art of war: Offensive techniques in binary
analysis (2016).

12. A. Flores-Montoya, E. M. Schulte, Datalog disassembly, CoRR abs/1906.03969 (2019).
13. G. Balatsouras, Y. Smaragdakis, Structure-sensitive points-to analysis for C and C++, in:
X. Rival (Ed.), Static Analysis - 23rd International Symposium, SAS 2016, Proceedings, Vol.
9837 of Lecture Notes in Computer Science, Springer, 2016, pp. 84–104.

14. J. Kˇroustek, P. Matula, P. Zemek, Retdec: An open-source machine-code decompiler, [talk],

presented at Botconf 2017, Montpellier, FR (December 2017).

15. D. G. Sousa, R. J. Dias, C. Ferreira, J. Lourenc¸o, Preventing atomicity violations with con-

tracts, CoRR abs/1505.02951 (2015).

