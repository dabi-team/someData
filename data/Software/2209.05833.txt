White-Box and Black-Box Fuzzing for GraphQL APIs

Asma Belhadi, Man Zhang and Andrea Arcuri

Kristiania University College, Norway

2
2
0
2

p
e
S
3
1

]
E
S
.
s
c
[

1
v
3
3
8
5
0
.
9
0
2
2
:
v
i
X
r
a

Abstract

The Graph Query Language (GraphQL) is a powerful language for APIs manipulation in web services.
It has been recently introduced as an alternative solution for addressing the limitations of RESTful APIs.
This paper introduces an automated solution for GraphQL APIs testing. We present a full framework for
automated APIs testing, from the schema extraction to test case generation. In addition, we consider two
kinds of testing: white-box and black-box testing. The white-box testing is performed when the source code
of the GraphQL API is available. Our approach is based on evolutionary search. Test cases are evolved
to intelligently explore the solution space while maximizing code coverage and fault-finding criteria. The
black-box testing does not require access to the source code of the GraphQL API. It is therefore of more
general applicability, albeit it has worse performance. In this context, we use a random search to generate
GraphQL data. The proposed framework is implemented and integrated into the open-source EvoMaster
tool. With enabled white-box heuristics, i.e., white-box mode, experiments on 7 open-source GraphQL APIs
show statistically significant improvement of the evolutionary approach compared to the baseline random
search. In addition, experiments on 31 online GraphQL APIs reveal the ability of the black-box mode to
detect real faults.

Keywords: GraphQL, EvoMaster, Evolutionary Algorithms, Automated Testing, Random, SBST, SBSE,

fuzzing.

1 Introduction

Web services are very common in industry, especially in enterprise applications using microservice archi-
tectures [46]. They are also becoming more common with the appearing of smart city technologies, where
microservices are largely exploited in industrial internet-of-things settings [30, 29]. The investigation of automat-
ing techniques for generating test cases for web service APIs has become a research topic of importance for
practitioners [15].

Due to the high number of possible configurations for the test cases, evolutionary techniques have been
successfully used to address different software testing problems [11, 36]. Common examples are EvoSuite for
unit test generation for Java programs [33], Sapienz for mobile testing [43] and EvoMaster for REST API
testing [14].

The Graph Query Language (GraphQL) is a powerful language of web-based data access, created in 2012
and open sourced by Meta/Facebook in 2015 [6]. It addresses some of the RESTful API limitations, like the
possibility of specifying what to fetch on a graph of interconnected data with a single query [37, 47]. Different
companies have started to provide web APIs using GraphQL1, like for example Facebook, GitHub, Atlassian,
and Coursera.

To the best of our knowledge, only three recent approaches in the scientific literature exist which explore the
automated testing for GraphQL APIs, dealing with ‘‘deviation testing’’ [48], ‘‘property-based testing’’ [39] and
‘‘harvesting production queries’’ [51]. To deal with this gap in the scientific literature, this paper presents the
first white-box and black-box test generation approach for automating GraphQL APIs testing. We developed a
full framework for automate GraphQL APIs testing, from the schema extraction to the generation of the test
cases in executable test suite files (e.g., using JUnit and Jest). The proposed framework has been implemented
as an extension to the open-source EvoMaster tool [14, 22], and it is freely available online.

The main contributions of this research work are as follows:

1. We investigate two kinds of testing: white-box and black-box testing. The white-box testing is performed
when the source code of the GraphQL API is provided, whereas the black-box testing is employed when
the source code of the GraphQL APIs is either missing or when users do not have access to it (e.g., remote
services).

1https://graphql.org/users/

1

 
 
 
 
 
 
pets {
id
name
owner {
id
firstName
lastName
pets {
id
name

}

}
visits {

totalCount

}

}

1 {
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18 }
19

(a) Data graph

Figure 1: Example of GraphQL data graph and a query on it

(b) GraphQL query

2. We develop an evolutionary-based search for white-box testing. It intelligently explores the test case space
in GraphQL APIs. Different types of genes are created which allow the complete data representation of
the GraphQL schema. The genetic operators are used to explore the test case space while maximizing
metrics such as code coverage and the number of detected faults. We also adopt a random search for
black-box testing, where test cases are generated randomly from GraphQL schema without considering
information from the source code of the GraphQL APIs.

3. To validate the applicability of our presented framework, an empirical study has been carried out on 7
GraphQL APIs with source code, and 31 online GraphQL APIs. For white-box testing, the results show a
clear improvement of using the evolutionary algorithm compared with the random search baseline. Line
coverage is improved by 6% on average (up to +26.9% in one API), and more errors were automatically
found in the analyzed APIs (+77 new errors in total). For black-box testing, the results also reveal the
detection of up to 641 endpoints with errors over 825 endpoints.

This paper is an extension of a short poster [28]. In [28] we provided an initial implementation to support
a subset of GraphQL, with an empirical study of white-box testing on two artificial APIs. In this paper, we
significantly extended such support (e.g., how to deal with nested function calls), and provided a much larger
empirical study, including experiments on black-box testing as well.

The article is structured as follows. Section 2 provides background information on GraphQL APIs and
EvoMaster. Section 3 discusses related work. Section 4 gives a detailed explanation of the main components of
the proposed framework. The details of our empirical study are presented in Section 5, followed by a discussion
of the main findings of our research work in Section 6. Section 7 discusses the possible threats to validity.
Finally, Section 8 concludes the paper.

2 Background

This section provides important background information to better understand the rest of the paper, in particular
regarding GraphQL APIs (Section 2.1) and the EvoMaster tool (Section 2.2).

2.1 GraphQL

GraphQL is a query language and server-side runtime for application programming interfaces (APIs) [6]. Given
a set of data represented with a graph of connected nodes, GraphQL enables to query such graph, specifying
for each node which fields and connections to retrieve (and so recursively on each retrieved connected node).
Figure 1a shows a simplified/reduced example of graph for a pet clinic, whereas Figure 1b shows a GraphQL
query on it to retrieve the list of all pets with their owners and that have been registered in the clinic.

A GraphQL web service would be typically listening on a TCP socket, expecting GraphQL queries as part of
HTTP requests, on a given HTTP endpoint (typically /graphql). However, GraphQL is not tight to HTTP,
and queries could be technically sent via other communication mechanisms. One advantage here is that a user
can fetch all the data they need (and only that) in a single HTTP call.

A core concept in GraphQL is the schema, which is a collection of types and relationships between those
types. It describes which kind of types and fields on those types a client can request. GraphQL is a strongly
typed language and has its own language to write the schema.

2

Commonly used types definition in a GraphQL schema are as follows:

1. Object types. The most frequent elements of a GraphQL schema are object types. It indicates which

kind of object (e.g., a node in the graph) you can fetch and what fields it has.

2. Query type. A Query type is a special type in GraphQL that defines entry points (equivalent to remote
procedure calls) for fetching data from the graph. It is the same as an object type, but its name is always
Query. Each field of the Query type describes the name and return type of a different entry point. Note
that a GraphQL server has to define a query type.

3. Mutation type. A GraphQL operation can either be a read or a write operation. A Query type is used to
read data while the Mutation type is used to modify data. The Mutation type follows the same syntactical
structure as queries, however it defines entry points for writing operations. Note that a GraphQL server
may or may not have a mutation type.

4. Scalar types. Scalar types are primitive types that resolve to concrete data. GraphQL has five default
scalar types: Int, Float, String, Boolean and ID. Note that GraphQL allows creating custom scalar types
for more specific usage.

5. Input types. Input types are object types that allow passing complex objects as arguments to queries
and mutations. An input type’s definition is alike to an object type’s, but it starts with the keyword input
instead of type. Note that input types can only have basic field types (input types or scalar types) and
can not have field arguments.

6. Enum types. An Enum type is a special scalar type with a restricted set of allowed values specified in

the schema.

7. Interface types. An Interface type is an abstract type. An interface is composed of a set of fields held by
multiple object types. When an object type implements an interface, it has to include all of that interface’s
fields. Thereby, interfaces enable returning any object type that implements that interface. Note that, we
can query an interface schema type for any fields defined in the interface itself and we can also query it for
fields that are not in the interface but in the object types implementing the interface.

8. Union types. Like interface types, union type belong to the GraphQL abstract types. It allows to define
a schema type that belong to multiple types. In its definition, a union type will determine which object
types are included. In this case, the schema field can return any object type that is described by the union.
Note that, all union’s included types should be object types (e.g., not Input types).

9. Non-Nullable type. All types in GraphQL are nullable by default, i.e., the server can return a null
value for all the previous types. To override this default and specify that null is not a valid response,
an exclamation mark (!) following the type is added indicating that this field is required. The Non-Null
type can also be used in arguments. Note that, in queries a field is always optional, i.e., one can skip a
non-nullable field and the query would be still valid. However, if a field is required (declared as non-nullable)
the server must never return the null value if the query fetches such field. With regard to input arguments,
by default they are optional. However, if a type is declared as non-null, besides not taking the value null,
it also does not accept omission (i.e., the input argument must be present).

The following is a fragment of a GraphQL schema extracted from one of the SUTs used in our empirical
study in Section 5 (i.e., petclinic [8]). The schema describes the entry point pets that returns a list of all pets
that have been registered in the pet clinic. It is defined as a non-nullable object array type named Pet. The
object type Pet has as a field a non-nullable integer scalar type that represents the id of the pet. It also defines a
non-nullabe object type Owner which implements an interface named Person. The field VisitConnection is an
object type specifying all the visits to the pet clinic of this pet. It has an non-nullable integer field totalCount
that reports the total number of visits for this pet.

pets : [ Pet !]!

1 type Query {
2
3 }
4
5 type Pet {
6
7
8
9
10 }
11
12 type Owner i m p l e m e n t s Person {
13
14
15

id : Int !
name : String !
owner : Owner !
visits : V isi tConnection !

id : Int !
firstName : String !
lastName : String !

3

pets : [ Pet !]!

totalCount : Int !

16
17 }
18
19 type Vi si t Co nnection {
20
21 }
22
23 i n t e r f a c e Person {
id : Int !
24
firstName : String !
25
26
lastName : String !
27 }

As a response to a query, a GraphQL API will return a JSON object with two fields: data that contains the
result of the query, and errors if there was any error with the query (and in this case the data field would not
be present). Notice that GraphQL makes no distinction between user errors (e.g., a wrongly formatted query
or an input does not satisfy a business logic constraint) and server errors (e.g., internal crash in the business
logic of the API, like a null-pointer exception). However, it might support it in the future2. Furthermore, as
GraphQL is independent from HTTP, a query with errors could still have a HTTP response 200 (i.e., OK), and
this is a common behavior among GraphQL framework implementations.

Another limitation of GraphQL is that currently it has no standarized way to express constraints on the
fields of the graph (e.g., an integer within a specific numeric range, or a string that should satisfy a given regular
expression). Constraints could be added with ‘‘directives’’, which are decorators used to extend the semantics of
the schema. But those would be custom, and unique for each different implemented API.

2.2 EvoMaster

EvoMaster [14, 22] is an open-source tool that aims at system test generation, currently targeting REST
web services [16]. Internally it uses the evolutionary algorithm (i.e., Many Independent Objective algorithm
(MIO) [13]) enhanced with Adaptive Hypermutation [52], and can handle both black-box [17] and white-box
testing [21]. For white-box testing, it uses established heuristics like the branch distance [42, 13, 16], it employs
testability transformations to smooth the search landscape [21], and can also analyze all interactions with SQL
databases to improve the fitness function [20].

EvoMaster currently targets REST APIs running on the JVM and NodeJS [56](albeit for black-box testing
it can be applied on any kind of REST web service), and it outputs test suite files in the JUnit and Jest format.
Each generated test case is composed by one or more HTTP calls, and SQL data to initialize the database (if
any).

When targeting RESTful APIs, EvoMaster analyzes their schema, and create a chromosome representation
with a rich gene system to represent all possible needed types (from integers and strings to full JSON objects).
The resulting phenotype will represent complete HTTP requests, where each gene would represent the different
decisions that need to be made in these HTTP requests (e.g., query/path parameters in the URLs, and body
payloads in POST/PUT/PATCH requests). EvoMaster evolves test cases based on different metrics, like
statement and branch coverage, as well as coverage of the HTTP status codes for each endpoint in the API.
To detect potential faults, it considers the 500 HTTP status code (i.e., server error) and possible mismatches
between the schema and the concrete responses [44].

Internally, EvoMaster uses the MIO [13] algorithm to evolve test cases. It is a genetic based evolutionary
algorithm, designed specifically for handling system test case generation. Here, we briefly discuss how it works,
but for the full details of MIO we refer to [13]. MIO is a multi-population algorithm, with one population for
each testing target. MIO evolves individuals that are test cases, and outputs test suites. At the beginning of the
search, one single population is randomly initialized, based on the chromosome templates constructed from the
schema. For testing RESTful APIs, several kinds of testing targets are taken into account, like for example
statements coverage in the System Under Test (SUT), branch coverage and returned HTTP status codes. Next,
at each step, the MIO either samples a new test at random or selects one existing test from one population that
includes yet to covered targets, and mutate such a test. Different strategies are used to select which population
to sample from. Individuals are manipulated through only one operator, which is the mutation operator (i.e., no
crossover). Two types of mutation are applied: either a structure mutation or internal mutation. A test case is
composed by one or more ‘‘action’’ (i.e., an HTTP call in the case of testing of web services). In contrast to
the internal mutation, which affects only the values of the genes in the actions, for instance flipping the value
of a boolean gene from True to False, the structure mutation acts on the structure itself, such as adding and
removing actions (e.g., HTTP calls). Each time a new test is sampled/mutated, its fitness is calculated. If it
achieves any improvement on any target (regardless of the population it was sampled from), it will be saved
in the corresponding populations (and the worst individuals in such populations are deleted). In this context,
if a target is covered by a test, it is saved in an archive, the corresponding population is shrunk to one single
individual, and it will never expand again nor used for sampling. If new targets are reached (but not fully

2https://github.com/graphql/graphql-spec/issues/698

4

covered) during the evaluation of a test, a new population is created for each such newly discovered targets.
At the end of the search, MIO does output a test suite (i.e., a set of test cases) based on the best tests in the
archive for each testing target.

For black-box testing, EvoMaster employs a random test generation. The tool produces random inputs,

but still syntactically valid with respect to the OpenAPI/Swagger schema of the SUT.

Two different studies [40, 53] compared EvoMaster with other fuzzers for RESTful APIs, showing that
EvoMaster gives the best results. EvoMaster is open-source, hosted on GitHub [3], with each release
automatically published on Zenodo for long-term storage. The extension presented in this paper is available to
practitioners since EvoMaster version 1.5.0 [24].

3 Related Work

3.1 Testing of GraphQL APIs

Automated testing of GraphQL APIs is a topic that has been practically neglected in the research literature. To
the best of our knowledge, so far only three approaches have been investigated regarding the automated testing
of GraphQL APIs [48, 39, 51] (besides the poster version of this extended paper [28]).

Vargas et al. [48] proposed a technique called ‘‘Deviation Testing’’. It consists of three steps. In the first
step, an already existing test case is taken as input. This test constitutes a base to seed and compare the newly
generated tests. The second step is the test case variation, where variations of the initial seeded test case are
generated using deviation rules (where a deviation consists of a small modification). Four types of deviation
rules are defined: 1) field deviation consists of adding and deleting the selection of fields in the original query; 2)
not null deviation consists of replacing a declared non null argument with null; 3) type deviation consists of
changing an argument type by another type; 4) empty fields deviation consists of deleting all fields and sub
fields of the original query. The third step is the test case execution where the input test and its variations are
executed. The last step consists of comparing the results between the input test and its variation (e.g., wrong
inputs should lead to a response containing an error message).

Karlsson et al. [39] proposed a black-box property based testing method. The method consists of the following
steps. First, all specifications of the types and their relations are extracted from the schema. Data is generated
at random according to the schema, with customized ‘‘data generators’’ provided by the user. In addition, the
authors suggest two strategies to use as automated oracles: the first one aims to check the returned HTTP
status codes, and the second one verifies that the resulting data returned conform to the given schema.

Zetterlund et al. [51] presented a technique to capture the HTTP calls done by users in production (e.g.,
when interacting with web frontend), and generate test cases for the GraphQL API in the backend. These
generated tests can then be used for regression testing.

Our novel solution does not require any pre-existing test case (like in [48]), nor it requires the user to write
customized input generators (like in [39]), nor it requires users interacting with a frontend [51]. Our framework
benefits from the EvoMaster tool, which is able to do advance white-box testing (e.g., using testability
transformations [21] and SQL interaction analysis [20]), and also be able to perform black-box testing when
source code of the SUT is not available. In this paper, we provide a complete testing pipeline, and an intelligent
genetic-based exploration for the possible test case configurations.

3.2 Testing of REST APIs

In recent years, there has been an increasing interest in the research community about the automation of testing
web services, where RESTful APIs are the currently the most common type.

For example, Godefroid et al. [35] introduced the differential regression testing for avoiding breaking changes
in the REST APIs. They analyzed both types of regressions in APIs, regression in the contract rules between
the client and the server, and regression in the server itself, the different changes in the server versions. The
differential testing is performed to automatically identify abnormal behavior in both kinds of regressions. It
consists of comparing different versions of the server and also the different versions of the contracts with the
client.

Viglianisi et al. [49] proposed an approach for automatically generating black-box test cases for REST APIs.
It takes as input the Swagger/OpenAPI specification of the API and consists of three modules: It first analyzes
the schema and computes its corresponding operation dependency graph which is a graph that represents the
data dependencies. It then automatically generates test cases of the REST API by reading both the graph
created in the previous step and the schema in order to test the nominal scenarios. It finally applies mutation
operators to the nominal tests which violate data constraints for testing error scenarios. In order to decide
whether a test is successful or not, two oracles are established based on the returned status codes and on the
compliance with the schema.

5

Lopez et al. [45] presents a new formulation of the automated test APIs problem using CSP (Constraint
Satisfaction Problem). The IDL (Inter-parameter Dependency Language) is first introduced to formally describe
the different relations among input parameters of the REST API. Then, the CSP is used to automatically analyse
the IDL specification. Finally, a catalogue of analysis is constructed in order to extract helpful information such
as checking whether an API call is valid or not

So far, all approaches presented in the literature for testing RESTful APIs are black-box. EvoMaster
(Section 2.2) is currently the only tool that can do both white-box and black-box testing. It uses evolutionary
techniques for white-box testing, and random search for black-box testing. Furthermore, recent comparisons of
tools [41, 54] show that EvoMaster gives the best results on the selected APIs used in those tool comparisons.

4 GraphQL Test Generation

Figure 2: Framework for GraphQL test generation

This section presents our novel proposed framework for automated test case generation of GraphQL APIs,
built on top of the EvoMaster tool. As sketched in Figure 2, the proposed framework targets both white-box
and black-box testing. The white-box testing is performed when the information related to the schema is
provided and have access to source code of the GraphQL API. In case of only having the schema, black-box
testing is rather used.

Algorithm 1 GraphQL Test Generation Algorithm
1: Input: G = {N1, N2, . . . , Nn}: the set of n data in the GraphQL API.
2: Output: Tests: the set of generated tests.
3: Schema ← Extraction(G)
4: if code source in G then
5: Gene ← ChromosomeTemplateConstruction(Schema)
6:
7:
8: else
9:
10: end if
11: return Tests

TestCase ← Create(Gene)
Tests ← EvolutionaryAlgorithm(TestCase)

Tests ← Random(Schema)

Algorithm 1 presents the pseudo-code of the GraphQL test generation algorithm. The input data is the entry
point to the GraphQL API (e.g., a URL). In case of white-box testing, we also provide the source code as input.
The results will be a set of generated tests (e.g., in JUnit or Jest format). The process starts by extracting the
schema from the graph data in line 3. In case of having the source code of the GraphQL API, the white-box
solution is performed. It first determines the corresponding genes, creates the chromosome template, and applies
an evolutionary algorithm process to generate the tests (from line 4 to line 7). In case of missing the source code
of the GraphQL API, the black-box solution is established by generating random tests based on the schema,
illustrated in line 9. The algorithm returns the set of generated tests as shown in line 11. In the following, both
kinds of testing are explained in more details.

6

4.1 White-Box Testing

The process starts by extracting the schema from the GraphQL API. The chromosome template is then
constructed from the schema. Test cases are represented by a sequence of HTTP requests, instantiated from
the chromosome template. The test cases are evolved using MIO [13], where each test case will contain genes
representing how to build the GraphQL queries based on the given schema. The evolutionary search is performed
by applying two mutation operators to evolve the test cases (one to change the queries/mutations in each
HTTP calls, and the other to add/remove HTTP calls in a test case). This enables to efficiently explore the
solution space, with the aim of maximizing code coverage and fault finding. From the final evolved solution, a
self-contained test suite file (e.g., in JUnit format) is generated as output of the search.

In the following, we describe the main components of the white-box testing in more details:

1. Problem Representation In order to fetch the whole schema from a GraphQL API, an introspective
query is used. Given an entry point to the GraphQL API (e.g., typically a /graphql HTTP endpoint),
GraphQL enables a standard way to fetch a schema description of the API itself. The schema specifies
all the information about the available operation types, such as queries, mutations and all available data
types on each of them. As a result, the GraphQL schema is returned in JSON format. This latter is then
parsed in our EvoMaster extension and used to create a set of action templates, one for each query
and mutation operation. Each action will contain information on the fields related to input arguments (if
any is present) and return values. A chromosome template is defined for each action, which is composed
of non-mutable information (e.g., field’s names) and a set of mutable genes. In this context, each gene
characterizes either an argument or a return value in the GraphQL query/mutation. For objects as return
values, a query/mutation must specify which fields should be returned (at least one must be selected), and
so on recursively if any of the selected fields are objects as well. To represent the fact that a field is always
optional for queries, a return gene is modeled by an object gene where all its fields are optional. However,
we had to extend the mutation operator in EvoMaster with a post-processing phase, to guarantee that
at least one field gene is selected during the search. In other words, if after a mutation of a gene, which
represents a returned object value in the GraphQL query/mutation, all fields are de-selected, then the
post-processing will force the selection of one of them (and so on recursively if the selected field is an
object itself). On the other hand, if a return value is a primitive type, then there is no need to create
any gene for it, as there is no selection to make. Furthermore, similar to functions calls, fields in the
returned value can have input argument themselves. When a returned value for a parent field is executed,
both input arguments and returned value are recursively selected to generate a child field value until it
produces a scalar value whether in input arguments or in returned values. To model those function calls
we introduced a new special type of gene called Tuple, discussed next.
To fully represent what is available from the GraphQL specification, the following kinds of gene types
from EvoMaster have been re-used and adapted:

(a) String: It contains string variables which are defined by an array of characters. A minimum length
of the string is zero which represents the empty string. Each string gene cannot exceed a predefined
maximum number of characters (e.g., 100).

(b) Enum: This gene represents the enumeration type, where a set of possible values is defined, and only
one value is activated at a given time. The elements in the set can be in different formats (e.g.,
enumerations of numbers or enumerations of strings).

(c) Float/Integer/Boolean: genes representing variables with simple data types. Boolean genes
represent variables with true or false values. Integer and float genes represent integer and real-value
variables, respectively.

(d) Array: This gene represents a sequence of genes with the same type. This gene has variable length,
where elements can be added and removed throughout the search. In order to mitigate creating too
large test cases, for instance with millions of genes, the size of an array gene should not exceed a
given threshold.

(e) Object: This gene defines an object with a specific set of internal fields. Differently from the array
gene, where the elements should be with the same type, an object gene may contain elements with
different types. To do so, this gene is represented by a map, where each key in the map is determined
by the field name in each element in the object.

(f) Optional: A gene containing another gene, whose presence in the phenotype is controlled by a
boolean value. This is needed for example to represent nullable types in arguments and selection of
fields in returned objects.

(g) CycleObject: This special gene is used as a placeholder to avoid infinite cycles, when selecting object
fields that are objects themselves, which could be references back to the starting queried object. Once

7

a test case is sampled, its gene tree-structure is scanned, and all CycleObject genes are forced to be
excluded from the phenotype (e.g., if inside an Optional gene, that gets marked as non-selected, and
the mutation is prevented to select it; if the CycleObject is the type for an Array gene, such array
gets a fixed size of 0, and the mutation operator is prevented from adding new elements in it).
(h) LimitObject: GraphQL schemas are often very large and complex, and the levels of nesting fields
can be potentially huge. We use this special gene as a placeholder when a customized depth limit is
reached. The depth is the number of nesting levels of the object fields.

(i) Tuple: This gene is needed for example when representing the inputs of function calls. It is composed
of a list of elements of possible different types, where the last element can be treated specially. This
is for example the case of function calls when the return type is an object, on which we need to select
what to retrieve (and these selected elements could be function calls as well, and so on this is handled
recursively).

After defining the possible type of genes supported by the proposed framework, we consider the solution
space, where each solution is a set of test cases. A test case is composed of one or more HTTP request. In
order to represent an HTTP request, we typically need to deal with its components: HTTP verb, path
and query parameters, body payloads (if any) and headers.

A GraphQL request can be sent via HTTP GET (used only for queries) or HTTP POST methods with
a JSON body (used for queries and mutations). For simplicity, we only use the verb POST for both
queries and mutations. A GraphQL server uses a single URL endpoint (typically /graphql), where the
HTTP requests with the GraphQL queries/mutations will be sent. In the context of test generation for
a GraphQL API, the main decisions to make are on how to create JSON body payloads to send. The
genotype will contain genes (from the set defined above) to represent and evolve such JSON objects.

2. Search Operators and Fitness Function

Once a chromosome representation is defined based on the GraphQL schema, test cases are evolved and
evaluated in the same way as done for RESTful APIs in EvoMaster (recall Section 2.2), including
testability transformations [21] and SQL database handling [20].
Internally, the MIO algorithm is
implemented in a generic way, independently of the addressed problem (e.g., REST and GraphQL APIs),
and it is only a matter of defining an appropriate phenotype mapping function (e.g., how to create a valid
HTTP request for a GraphQL API based on the evolved chromosome genotype).

When evaluating the fitness of an evolved test, besides considering testing targets related to code coverage
and HTTP status coverage (for each different query/mutation operation), we also create new testing
targets based on the returned responses. As discussed in Section 2.1, each response could contain either a
data field or an errors field. For each query and mutation in the GraphQL schema, we consider two
additional testing targets for those two possible outcomes. Note that a trivial way to get a response with
errors is to send a syntactically invalid query. As such evolved test cases would be of little use, we
explicitly avoid generating such kind of test cases.

As a given query/mutation might fail for different reasons, we keep track of the last executed line in the
business logic of the SUT. We further create a separated testing target for each combination of errored
query/mutation and last executed line. Having explicit testing targets for those cases enables MIO to save
in its archive such evolved test cases, albeit the fitness function would have (currently) no gradient to lead
to generate such kind of test cases in the first place.

4.2 Black-Box Testing

We use the black-box testing when we do not have any knowledge about the source code of the GraphQL API,
or it is not available for instrumentation (e.g., to calculate the search-based heuristics like the branch distance).
It is not straightforward to get a high coverage value for such kind of tests, as little information from the SUT
can be exploited. However, in some cases (e.g., when testing remote services), a black-box approach might be
the only option available for automated testing. We use the random search algorithm developed in EvoMaster.
The main idea behind random search is performing a randomized process in generating the test cases, where no
fitness function is employed. The reason of not using search-based heuristics is due to the lack of the source
code of the GraphQL APIs.

Using the same process to sample new test cases for white-box testing, in the random search we sample a
series of test cases, which is saved in an archive. As no code information is available, test cases are added in the
archive only if they cover new targets based on the HTTP responses, based on each query/mutation operation
in the schema (in the same way as we do for white-box testing). In other words, for each query/mutation we
retain test cases that lead to different HTTP status codes, and at least one with a correct data response and at
least one with an errors response.

8

The main steps of the random search can be summarized as follows:

1. Test case generation: The test cases are generated in a random way, but they are still syntactically valid.
For instance, if we consider the example illustrated in Figure 1a, the test cases are generated by exploring
the fields of the pets node. For instance, if we consider the field ‘‘id’’ an integer represented in 32 bits.
The possible test cases for the field ‘‘id’’ is 232. We also explore different combinations of two or more
fields in each node. For instance, consider the same example illustrated in Figure 1a, the test cases might
be generated from both fields ‘‘id’’, and ‘‘name’’ of the node pets. If we consider the length of the string is
limited to 10, the possible tests cases for the field ‘‘name’’ is 2160 (assuming each character being 2-bytes).
Therefore, the number of possible test cases by only exploring the fields ‘‘id’’, and ‘‘name’’ is 232 × 2160,
which results an immense search space. Therefore, in our implementation, and in order to mitigate the
combinatorial explosion, we use threshold to limit the number of generated test cases (i.e., we limit the
number of test cases we sample during the random search).

2. Fault determination: After a test case is sampled, the test is evaluated by calling the GraphQL endpoint,

to detect possible faults (e.g., based on HTTP status codes and errors fields in the responses).

5 Empirical Study

5.1 Experimental Setup

In this section, several experiments have been carried out to validate the applicability of the proposed framework
for GraphQL test generation. This can be achieved by answering the three following research questions:

RQ1: For white-box testing of GraphQL APIs, how effective is MIO at maximizing code coverage and fault

detection compared to Random search?

RQ2: How does black-box testing fare on existing APIs on the Internet?

RQ3: What kinds of faults are found by our novel technique?

5.1.1 White-Box

GitHub [5], arguably the main repository for open-source projects, was used to find SUTs for experimentation.
JVM and NodeJS projects were scanned and filtered, while excluding trivial projects. For this study, seven
GraphQL web services are selected, which we could compile and run with no problems:

• The Spring petclinic [8] API (4 567 LOCs) is an animal clinic where a pet owner can register his pet for an
examination. The examination is carried out by a veterinarian who has one or more specialist areas.

• patio-api [7] (12 552 LOCs) is a web application that attempts to estimate the happiness of a given team

periodically by asking for a level of happiness.

• graphql-ncs(548 LOCs) and graphql-scs (577 LOCs) are based on artificial RESTfull APIs from an existing
benchmark [4]. For this study, we adapted these two APIs into GraphQL APIs. graphql-ncs and graphql-scs
are based on a code that was designed for studying unit testing approaches on solving numerical [18] and
string [12] problems.

• react-finland [9] (16 206 LOCs) is an API for a week long developer conference focused on React.js and

related technologies.

• timbuctoo [10] (85 365 LOCs) is an API that allows scientists to decide how data from different databases

is shared.

• e-commerce [2] (1 791 LOCs) an e-commerce API built on Phoenix and Elixir that can be utilized in order

to create interactive e-commerce web applications.

To the best of our knowledge, there is no other existing white-box fuzzer that can be used to test GraphQL
APIs. Therefore, in this paper we cannot compare with any existing technique, as none is available. White-box
fuzzing GraphQL APIs is a novel contribution of this paper. Still, it is important to verify whether a novel
sophisticated technique is really warranted, and no simpler technique would be already as effective [11]. When
nothing else is available, a common baseline in software testing research is Random Testing [23], in which
an application is tested with random inputs. Still, sending random bytes on the TCP connection the SUT is
listening on would be of little to no value, as the chances of generating a valid GraphQL query (or even simply a

9

Name
aniList

deutsche-bahn
barcelona-urban-mobility
buildkite
câmara-dos-deputados
catalysis-hub
contentful

countries
demotivational-quotes
digitransit

ehri
fauna
fake-graphQL-api
fruits
ghibli
gitLab
google-directions
music-brainz
pokémon

hivdb
jobs
melody
react-finland
rickandmortyapi

spacex
spotify
swapi
swop
travelgateX
universe
weather

Table 1: GraphQL APIs used for black-box experiments

Description
provides access to anime and manage entries, including character, staff, and
live airing data.
infrastructure Data, like realtime facility status and stations
combine information about the different urban mobility services of Barcelona city
a platform for continuous integration and deployments
an api to obtain the data from the brazilian deputies chamber
chemical surface reaction energies and structures
provides a content infrastructure for digital teams to power content in websites,
apps, and devices
information about countries, continents and languages
get random demotivational quote
journey planning solution combining several open source components into available
route planning service
holocaust-related archival materials held in institutions across Europe and beyond
serverless GraphQL database
mock user and to do data
provides information of fruit trees of the world
catalogs the people, places, and things found in the worlds of Ghibli
host-your-own Git repository hosting service
GraphQL wrapper over the google directions API
an open music encyclopedia that collects music metadata
query for all the Pokémon data including their abilities, moves, items, learnsets,
and type matchups
a curated database to represent, store and analyze HIV drug resistance data
GraphQL jobs directory
fast and reliable dependency manager for Go programming language
GraphQL API for conferences and meetings
based on the television show Rick and Morty. Provide the Rick and Morty
information (characters, episodes, locations)
a non official platform for SpaceX’s data
provides instant access to millions of songs, from old favorites to the latest hits
provides all the Star Wars data
GraphQL foreign exchange rate API
a global marketplace for the travel trade
check what your friends are doing and find unique events near you using our filter
retrieve the current weather for any given city

Source Code
Yes

Yes
Yes
No
Yes
Yes
Yes

Yes
Yes
No

No
No
No
Yes
Yes
No
Yes
Yes
Yes

No
No
No
Yes
Yes

No
Yes
Yes
No
No
No
Yes

valid HTTP request) would be virtually non-existent. Therefore, for doing random testing, we still sample and
send syntactically valid GraphQL queries based the schema of the SUT.

Our proposed framework is integrated in EvoMaster, where a comparison between MIO and the baseline
random search algorithm is carried out. For the experiments, we set 100 000 HTTP calls as search budget for
our white-box testing approach. To take into account the randomness of the algorithm, each experiment was
repeated 30 times [19]. We selected covered testing targets (#Targets), line coverage (%Lines), and the number
of detected faults (#Errors) as metrics for comparisons. The testing target (#Targets) is the default coverage
criterion in EvoMaster. It comprises and aggregates different metrics, such as code coverage (including branch
coverage), HTTP status code coverage and fault findings. The line coverage (%Lines) is collected as part of our
code instrumentation. Furthermore, we also reported (#Errors) by identifying potential faults, i.e., 500 HTTP
status codes and responses with errors entries (recall Section 4).

5.1.2 Black-Box

To evaluate the black-box testing, 31 online APIs with different domain applications, and different number of
endpoints have been selected from apis.guru [1], a curated public listing of available web services on Internet.
These APIs are written with different programming languages, such as JavaScript and Python. Some APIs
provide their implementation (e.g., open-source), whereas others do not (e.g., commercial services). When an API
required authentication, we created an account on these APIs, and added the right authentication information
the HTTP headers of EvoMaster (e.g., authentication header can be set with the command-line argument
--header). For our experiments, we considered all the GraphQL APIs listed on apis.guru, but excluded APIs
that are no longer available (but still listed on apis.guru), or that required payment to create an account. Table 1
gives short description of the 31 APIs used in our experiments.

We ran our extension of EvoMaster on all those APIs with black-box mode. The stopping criterion was set
to 1 000 HTTP calls per run. Each experiment was run only three times, since sending thousands and thousands
of HTTP calls to live services could be interpreted as Denial-of-Service attack. For the same reason, we put a
rate limiter of at most 10 HTTP requests per minute (i.e., EvoMaster would make HTTP calls only every 6
seconds).

As we do not have any control on these remote APIs, repeating the experiments more times would not add

much more information, as such runs would not be fully independent.

10

Table 2: Results for 100k HTTP call budget for white-box testing

SUT

ecommerce-server

graphql-ncs

graphql-scs

patio-api

petclinic

react-finland

timbuctoo

Average

RS

340.0

365.8

634.3

Targets #
ˆA12
WB
0.58

340.1

552.1

723.3

3538.4

3754.6

652.4

315.2

650.3

529.0

6787.2

7395.9

1804.8

1992.2

Line Coverage %

p-value

RS WB

0.218

8.2

8.0

1.00 < 0.001
1.00 < 0.001
1.00 < 0.001
0.328
0.43

1.00 < 0.001
1.00 < 0.001
0.86

51.4

78.3

68.1

75.7

39.0

43.9

60.0

59.7

1.0

1.8

27.3

29.3

36.4

42.4

p-value

ˆA12
0.08 < 0.001
1.00 < 0.001
1.00 < 0.001
0.97 < 0.001
0.011

0.40
1.00 < 0.001
0.99 < 0.001
0.78

RS WB

28.0

6.0

0.0

59.5

17.7

0.029

p-value

Errors #
ˆA12
0.37
1.00 < 0.001
0.79 < 0.001
1.00 < 0.001
0.001

27.6

8.2

0.8

85.2

17.3

0.28
1.00 < 0.001
0.99 < 0.001
0.77

24.5

30.5

43.9

87.4

25.7

36.7

5.2 Experiment Results

5.2.1 Results for RQ1

To compare MIO with Random, Table 2 reports their average #Targets, %Lines, #Errors and an analysis of the
pairwise comparisons using Mann-Whitney-Wilcoxon U-tests (p-value) and Vargha-Delaney effect sizes ( ˆA12),
for each of the case studies.

When looking at the achieved target coverage, there is a clear improvement of white-box evolutionary search
(i.e., MIO) compared to random search. On 5 out of 7 APIs, the effect-size is maximum, i.e., ˆA12 = 1. This
means that, in each of the 30 runs of MIO, the results were better than the best run of random search. In
absolute terms, the largest #Target improvement for MIO is on timbuctoo (i.e., +608.7 covered targets than
Random), which is the largest of the SUT used in our study. Relatively, it is a +8.9% improvement (from
6787.2 to 7395.9). However, the largest relative improvement is for react-finland, which is +67.8% (from 315.2
to 529.0). For ecommerce-server and petclinic there is no statistically significant difference (i.e., p-values are
greater than the α = 0.05 threshold).

When looking at only line coverage, we can see that MIO enables covering 78.3% of lines in graphql-ncs.
This is a large improvement compared to the 51.4% of Random (i.e., +26.9%). On average among the SUTs,
the improvement is +6% (i.e., from 36.4% to 42.4%). When looking at the absolute values for line coverage,
we need to point out an issue with collecting coverage for NodeJS applications (i.e., ecommerce-server and
react-finland), as coverage computation is not considering what achieved during boot-time of the API.

When looking at line coverage along, there is statistically worse results for petclinic and e-commerce. However,
the differences are minimal (i.e., at most -0.3%). For instance, petclinic is a simple API used for demonstration,
where large parts of its code is not executed (e.g., it has 3 different implementations of its data-layer, where only
one can be active at a time, and this has to be specified in a configuration file when the API is started). On
simple problems, random search can be already very good, whereas evolutionary search can have some small
side-effects (which would likely disappear when using a longer search budget). This is particularly the case if
the fitness function does not provide gradient to the search.

In Table 2, we also report the number of potential faults identified by both MIO and Random. The table
shows clear better results for MIO compared to Random, with an average high effect size of ˆA12 = 0.77. On
timbuctoo, MIO achieves the most, finding 87.4 errors on average compared to 43.9 for Random. This result is
achieved thanks to the evolutionary operators adopted in the proposed framework to handle GraphQL APIs.

On our employed hardware, 100k calls take for example roughly 1 hour for petclinic, and 2 hours for patio-api.
In this context, an automatically achieved coverage of 43.9% for a complex API like pation-api could be
considered a good, practical result, although more still need to be done (e.g., better search heuristics). Not only
many potential faults are found, but the generated tests can also be used for regression testing (i.e., they can
be added to the test suites of the SUTs, and run as part of Continuous Integration to check if any change is
breaking any current functionality).

The choice of using 100k HTTP calls as stopping criterion is technically arbitrary. It could had been more, or
less. Such choice was based on what practitioners could use in practice [55], although they would likely use ‘‘time’’
as stopping criterion (e.g., run the fuzzing for 10 minutes or 1 hour). Using the number of maximum HTTP
calls is done for scientific reasons, as it makes the experiments easier to replicate (e.g., they are not particularly
impacted by the used hardware). Nevertheless, the chosen search budget can impact the conclusions taken from
the comparisons of search algorithms. For this reason, in Figure 3 we report plot-lines for demonstrating the
performances of the two compared techniques for the number of covered targets throughout the search, collected
at each 5% intervals (i.e., at each 5 000 HTTP calls).

According to the reported results, MIO outperforms Random for all cases except for petclinic, where we

11

(a) patio-api

(b) petclinic

(c) ecommerce-server

(d) graphql-ncs

(e) react-finland

(f) timbuctoo

(g) graphql-scs

Figure 3: Covered targets throughout the search

observed a slight gain for Random. The improvements of MIO are visible throughout the entire search. In a few
cases, already with small budgets (e.g., 5 000 calls) MIO gets better results than Random at 100 000 calls. One
interesting case to discuss is ecommerce-server. For small budget, MIO is worse. Then, for most of the search,
it gives significantly better results than Random. However, by the end of the search, the performance of the two
algorithms converges. Given infinite time, even a trivial random search can achieve full coverage of the feasible
targets [23]. Therefore, based on the chosen search budget, one could reach very different conclusions. Using a
budget somehow representing how practitioners would use these fuzzers in practice is therefore essential.

RQ1: In terms of covered targets, MIO demonstrates a consistent and significant improvements (+6% line
coverage and +11 more faults found on average) compared with random testing. This shows the effectiveness
of MIO adapted for GraphQL testing for maximizing code coverage and fault detection.

5.2.2 Results for RQ2

Table 3 presents the results of the black-box testing on the 31 APIs described in Table 1. The results include
the number of endpoints (#Endpoints) representing the number of queries and mutations present in the schema,
the percentage of endpoints with generated tests without errors (%NoErrors), and the percentage of endpoints

12

350035503600365037003750Budget PercentageCovered Targets5102030405060708090100MIORAND590600610620630640650Budget PercentageCovered Targets5102030405060708090100MIORAND330335340Budget PercentageCovered Targets5102030405060708090100MIORAND400450500550Budget PercentageCovered Targets5102030405060708090100MIORAND300350400450500Budget PercentageCovered Targets5102030405060708090100MIORAND66006800700072007400Budget PercentageCovered Targets5102030405060708090100MIORAND620640660680700720Budget PercentageCovered Targets5102030405060708090100MIORANDTable 3: Results for black-box testing

SUT

#Endpoints %NoErrors %WithErrors

Anilist
Bahnql
barcelona-urban-mobility
Buildkite
Camara-deputados
Catalysis-hub
Contentful
Countries
Demotivation-quotes
Digitransit
Directions
Ehri
Fauna
Fruits
Ghibliql
Gitlab
Graphbrainz
Graphqlpokemon
Hivdb
Jobs
Melody
Mocki
React-finland
RickAndMortyapi
Spacex
Spotify
Swapi
Swop
Travelgatex
Universe
Weather

Total

56
7
10
70
33
11
23
8
2
33
6
19
13
7
10
270
6
13
9
15
2
4
13
9
43
11
13
6
11
90
2

825

1.8
100.0
50.0
7.6
23.2
100.0
11.6
87.5
100.0
26.3
33.3
73.7
10.3
85.7
100.0
1.9
0.0
53.8
44.4
13.3
16.7
100.0
35.9
63.0
93.8
0.0
46.2
16.7
100.0
10.4
100.0

48.6

98.2
100.0
100.0
99.0
100.0
100.0
100.0
12.5
0.0
93.9
83.3
100.0
100.0
28.6
30.0
95.2
100.0
76.9
77.8
86.7
100.0
0.0
100.0
66.7
68.2
100.0
100.0
100.0
0.0
94.4
100.0

77.8

with generated tests with errors (%WithErrors). Tests with errors and others without errors could be generated
for the same endpoint. However, the following formula would be satisfied:

with

and

%N oErrors
100

+

%W ithErrors
100

≤ 2

%N oErrors =

#N oErrors
#Endpoints

%W ithErrors =

#W ithErrors
#Endpoints

(1)

(2)

(3)

From Table 3, we remark that all endpoints were reached, and responses with either data or errors fields
are effectively derived. From the table we can see that we can generate tests which lead to responses with
errors fields for many endpoints (77.8%). However, there are also many queries/mutations for which we could
not get back any valid data (i.e., responses with data field and no errors were less than 50%). This is likely due
to input constraints which are unlikely to be satisfied with random data. Without code analysis (or constraints
expressed directly on schema), likely there is not much a black-box tool can do here (besides having the user
providing some sets of valid inputs to fuzz).

Similarly to the fuzzing of RESTful APIs, black-box testing can find faults in GraphQL APIs by just sending
random (but syntactically valid) inputs, as often APIs are not particularly robust when dealing with such kind
of random data [44]. However, without being able to analyze the source code, it can be hard to bypass their first
layer of input validation and generate successful API requests [17].

RQ2: The Black-box testing implemented in our novel approach enables the automated test generation that
can detect on average up to 641 endpoints with errors out of 825 endpoints (i.e., 77.8%).

5.2.3 Results for RQ3

As discussed in Section 2.1, currently GraphQL makes no distinction between user and server errors. So, without
an in-depth manual analysis of the generated tests, it is hard to tell which responses with errors messages are
due to actual software faults, and not a simple misuses of the API. Furthermore, without knowing the full details
of the expected business logic of the specific API under analysis, it might be hard for researchers (which are
not the developers of the API) to determine if a returned error is indeed due to a software fault. This problem
is further exacerbated for the external APIs used for black-box testing experiments, where the source code is

13

not available and cannot be used to validate if an error is indeed likely due to a fault. Still, when evaluating a
novel fuzzing technique like we do in this paper, it is important to check if it can find any actual faults. For this
reason, we did a manual analysis of hundreds of generated tests from our experiments. Here, we discuss some of
the most interesting cases.

Let us start from the following generated test case for petclinic.

given () . accept ( " application / json " )

1 @Test ( timeout = 60000)
2 public void test_4 () throws Exception {
3
4
5
6
7
8
9
10
11

. contentType ( " application / json " )
. body ( " { " +

" \" query \": \" mutation { removeSpecialty ( input :{ specialtyId :643}) { specialties { id }}}\" " +
" } " )

. post ( baseUrlOfSut + " / graphql " )
. then ()
. statusCode (200) // org / springframework / samples / petclinic / repository / springdatajpa /

S p r i n g D a t a S p e c i a l t y R e p o s i t o r y I m p l _ 3 8 _ d e l e t e

. assertThat ()
. contentType ( " application / json " )
. body ( " ’ data ’" , nullValue () )
. body ( " ’ errors ’. size () " , equalTo (1) )
. body ( " ’ errors ’[0]. ’ message ’" , contai nsString ( " Internal Server Error ( s ) while executing query " ) )
. body ( " ’ errors ’[0]. ’ path ’" , nullValue () )
. body ( " ’ errors ’[0]. ’ extensions ’" , nullValue () ) ;

12
13
14
15
16
17
18
19 }

Here, the message ‘‘Internal Server Error(s) while executing query’’ is a clear example of a fault, even if the
returned HTTP status code is 200. By debugging this test case, we found that the problem is due to a null
pointer exception: trying to remove a specialty with id equals to 643 that does not exist. Ideally, the API should
return an error message stating the requested resource does not exist. However, it looks like the implementation
of such API is ignoring the cases when a user asks for something not in the database, which leads to an internal
crash.

A similar case can be seen in the following test generated for react-finland.

given () . accept ( " application / json " )

. contentType ( " application / json " )
. body ( " { " +

1 @Test ( timeout = 60000)
2 public void test_0_with500 () throws Exception {
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22 }

" \" query \": \"{ theme ( conferenceId :\\\" coM_FEt0ANyU87 \\\") { id , fonts { primary }}} \" " +
" } " )
. post ( baseUrlOfSut )
. then ()
. statusCode (500)
. assertThat ()
. contentType ( " application / json " )
. body ( " ’ errors ’. size () " , equalTo (1) )
. body ( " ’ errors ’[0]. ’ message ’" , containsString ( " Conference id did not match series " ) )
. body ( " ’ errors ’[0]. ’ locations ’. size () " , equalTo (1) )
. body ( " ’ errors ’[0]. ’ locations ’[0]. ’ line ’" , numberMatches (1.0) )
. body ( " ’ errors ’[0]. ’ locations ’[0]. ’ column ’" , numberMatches (5.0) )
. body ( " ’ errors ’[0]. ’ path ’. size () " , equalTo (1) )
. body ( " ’ errors ’[0]. ’ path ’" , hasItems ( " theme " ) )
. body ( " ’ data ’" , nullValue () ) ;

Here, the API returns a meaningful error message stating ‘‘Conference id did not match series’’. This means
that the requested id ‘‘coM_FEt0ANyU87’’ is not matching any registered conference in the API. However, the
API is returning the HTTP status code 500, which in HTTP represents a server error, and not a user error
(where the most suited code for this case would likely be 404). Technically, this is a fault, although likely not a
serious one. Not properly handling the requests for missing data seems common as well in RESTful APIs [44].
However, there are a few cases of more serious faults, like when the returned responses are not matching the
constraints of the GraphQL schema of the API. For example, consider the following case of a HTTP call in a
generated test for Bahnql.

1 given () . accept ( " application / json " )
2
3
4

. contentType ( " application / json " )
. body ( " { " +

" \" query \": \"{ parkingSpace ( id : 842)

{ name , label , responsibility , spaceType , location { latitude

} , url , operator , distance , facilityType , openingHoursEn , isSpecialProductDb , isOutOfService , occupancy {
validData , timestamp , timeSegment } , clearanceHeight , outOfService , isMonthSeason , tariffDiscount ,
tariffPaymentCustomerCards , tariffFreeParkingTimeEn , tariffPaymentOptionsEn , slogan }

} \" " +

" } " )
. post ( baseUrlOfSut )
. then ()
. statusCode (200)
. assertThat ()
. contentType ( " application / json " )
. body ( " ’ errors ’. size () " , equalTo (2) )
. body ( " ’ errors ’[0]. ’ message ’" , containsString ( " Cannot return null for non - nullable field Location .

5
6
7
8
9
10
11
12

latitude . " ) )

14

13
14
15
16
17
18

. body ( " ’ errors ’[0]. ’ locations ’. size () " , equalTo (1) )
. body ( " ’ errors ’[0]. ’ locations ’[0]. ’ line ’" , numberMatches (1.0) )
. body ( " ’ errors ’[0]. ’ locations ’[0]. ’ column ’" , numberMatches (77.0) )
. body ( " ’ errors ’[0]. ’ path ’. size () " , equalTo (3) )
. body ( " ’ errors ’[0]. ’ path ’" , hasItems ( " parkingSpace " , " location " , " latitude " ) )
. body ( " ’ data ’. ’ parkingSpace ’" , nullValue () ) ;

Here a 200 status code is returned, which would imply a success from the point of view of HTTP. However,
the error message is ‘‘Cannot return null for non-nullable field Location.latitude.’’. This looks like a case of
internal server error, where a test case is asking for a non-nullable field named latitude, but the server tried
to return a null value. All types in GraphQL are nullable by default, and the null value is a valid response.
However, when looking into its schema definition, the field latitude is defined as a non-null scalar. This is a clear
example showing an actual fault in the SUT, where the API tries to return a response that violates the schema.

{

1 " kind " : " OBJECT " ,
2 " name " : " Location " ,
3 " fields " :[
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18

} ,

}

" name " : " latitude " ,
" args " : [] ,
" type " : {

" kind " : " NON_NULL " ,
" name " : null ,
" ofType " : {

" kind " : " SCALAR " ,
" name " : " Float " ,
" ofType " : null

} ,
" isDeprecated " : false ,
" d epr ecat ion Rea son " : null

Another interesting example of schema violation is the following test generated for the Catalysis-hub API.

1 @Test ( timeout = 60000)
2 public void test_11 () throws Exception {
3
4
5
6
7

. contentType ( " application / json " )
. body ( " { " +

given () . accept ( " application / json " )

" \" query \": \"{ information ( name :\\\" fyS8oO8Upt9ceuK \\\" , value : \\\" CblJF7FCM_kT_ \\\" ,

distinct : false , op : \\\"4 iyt \\\" , search : \\\" Uk4WPkx7y \\\" , jsonkey : \\\" dWws4 \\\" , order : \\\" pc
\\\" , before : \\\"\\\" , after : \\\" CU1SdJQYVHfnce \\\" , first : 298 , last : 303)
cursor } , totalCount }

{ edges { node { value , id } ,

} \" " +

8
9
10
11
12
13
14
15

16
17
18
19
20
21

1
2
3
4
5
6
7
8
9
10
11
12
13
14

" } " )
. post ( baseUrlOfSut )
. then ()
. statusCode (200)
. assertThat ()
. contentType ( " application / json " )
. body ( " ’ errors ’. size () " , equalTo (1) )
. body ( " ’ errors ’[0]. ’ message ’" , containsString ( " Can ’t find property named \" cursor \" on mapped

class Information - > information in this Query . " ) )

. body ( " ’ errors ’[0]. ’ locations ’. size () " , equalTo (1) )
. body ( " ’ errors ’[0]. ’ locations ’[0]. ’ line ’" , numberMatches (1.0) )
. body ( " ’ errors ’[0]. ’ locations ’[0]. ’ column ’" , numberMatches (5.0) )
. body ( " ’ errors ’[0]. ’ path ’. size () " , equalTo (1) )
. body ( " ’ errors ’[0]. ’ path ’" , hasItems ( " information " ) )
. body ( " ’ data ’. ’ information ’" , nullValue () ) ;

Here a 200 status code is returned, which would imply a success from the point of view of HTTP. However
in the body of the response the following error message appears: ‘‘Can’t find property named "cursor" on
mapped class Information->information in this Query’’. It states that there is no field named cursor belonging
to the root query information. We have extracted and analyzed the whole schema of the Catalysis-hub API
by sending an introspective query to its endpoint. The schema reveals that the field information is of type
InformationCountableConnection. The type InformationCountableConnection has the field named edges (that
we have asked for) of type InformationCountableEdge. This latter, as shown below, has two fields, namely node
and cursor, which shows a clear fault in the SUT. The internal implementation of the server does not respect
the defined GraphQL schema.

" kind " : " OBJECT " ,
" name " : " I n f o r m a t i o n C o u n t a b l e E d g e " ,
" fields " : [

{

} ,

" name " : " node " ,
" args " : [] ,
" type " : {

" kind " : " OBJECT " ,
" name " : " Information " ,
" ofType " : null

} ,
" isDeprecated " : false ,
" d epr ecat ion Rea son " : null

15

15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35

{

}

" name " : " cursor " ,
" args " : [] ,
" type " : {

" kind " : " NON_NULL " ,
" name " : null ,
" ofType " : {

" kind " : " SCALAR " ,
" name " : " String " ,
" ofType " : null

}

} ,
" isDeprecated " : false ,
" d epr ecat ion Rea son " : null

] ,
" inputFields " : null ,
" interfaces " : [] ,
" enumValues " : null ,
" possibleTypes " : null

} ,

Although schema violations might not be always easy to identify, there are other cases in which faults are

very clear. For instance, consider the following test generated for the Buildkite API.

1 given () . accept ( " application / json " )
2
3
4
5

. header ( " Authorization " , " Bearer 992 a e 7 a e 4 9 9 8 a 8 a 8 f a a 7 c 7 6 2 d 7 4 e 3 c 2 0 f 2 a b e 1 5 4 " )
. contentType ( " application / json " )
. body ( " { " +

" \" query \": \" mutation { j o b Ty p e B l o c k U nb l o c k ( input :{ clientMutationId :\\\" hVHw \\\" , id :\\\"

R2qgRAwGnOo \\\" , fields :\\\"6 nj19G \\\"}) { clientMutationId }}\" " +

" } " )
. post ( baseUrlOfSut )
. then ()
. statusCode (200)
. assertThat ()
. contentType ( " application / json " )
. body ( " ’ type ’" , containsString ( " unknown_error " ) )
. body ( " ’ errors ’. size () " , equalTo (1) )
. body ( " ’ errors ’[0]. ’ message ’" , containsString ( " An error occurred while executing your GraphQL query .

Please contact hello@buildkite . com for help and provide this query in the email . " ) ) ;

6
7
8
9
10
11
12
13
14

15

Here, the server returned the status code 200. However, an internal server error is detected by show-
ing this message in the body:
‘‘An error occurred while executing your GraphQL query. Please contact
hello@buildkite.com for help and provide this query in the email’’. Unfortunately, faults found by these black-box
experiments from the requested APIs cannot be further analyzed, as we do not have access to the source code of
this remote service. It seems like a case of crash due to requesting a resource that does not exist, but we cannot
be sure.

Another clear example of a major problem can be seen here in the following test generated for the Catalysis-
hub API. The test requests the resource called hasPreviousPage, but the actual call (done with the library
RestAssured) throws an exception.

1 try {
2
3
4
5

given () . accept ( " application / json " )

. contentType ( " application / json " )
. body ( " { " +

" \" query \": \"{ information ( name :\\\"8 qpQyCBnwDOgP2 \\\" , value :\\\" fU5gDkH6 \\\" , distinct :
false , op : \\\" J0ZA3ahBYJTLgMp \\\" , search : \\\"59 W \\\" , jsonkey : \\\" TMJOz \\\" , order : \\\" aHdTeItZ
\\\" , before : \\\" g7_U2sanJ_l0 \\\" , after : \\\" bEUm \\\" , first : 141 , last : 847) { pageInfo {
hasPreviousPage }}} \" " +

6
7
8 } catch ( Exception e ) {
9 }

" } " )

. post ( baseUrlOfSut ) ;

After a manual investigation, we found that the SUT is returning a failure in an HTML page instead of a

JSON object, meaning a significant crush in the SUT.

1 " <! DOCTYPE html >\ n \t < html >\ n \ t

< head >\ n \ t \t < meta name =\" viewport \" content =\" width = device - width , initial -

scale =1\" >\ n \ t \t < meta charset =\" utf -8\" >\ n \ t \t < title > Application Error </ title >\ n \ t \t < style media =\"
screen \" >\ n \ t \ t
t \ t \ theight : 100%;\ n \ t \ t \ toverflow : hidden ;\ n \ t \ t

html , body , iframe {\ n \ t \ t \ tmargin : 0;\ n \ t \ t \ tpadding : 0;\ n \ t \ t

}\ n \ t \ t

}\ n \ t \ t

html , body {\ n \
iframe {\ n \ t \ t \ twidth : 100%;\ n \ t \ t \ theight :
< body >\ n \ t \t < iframe src =\"// www .
</ body >\ n \t </ html > "

100%;\ n \ t \ t \ tborder : 0;\ n \ t \ t

</ head >\ n \ t
herokucdn . com / error - pages / application - error . html \" > </ iframe >\ n \ t

}\ n \ t \t </ style >\ n \ t

However, this might had been due to hardware issues, and not a software fault in the business logic of the
API. For example, it could had well been that, although we did successfully generate an introspective query on
this API, after a few hundreds HTTP calls the cloud provider Heroku (mentioned in that error page) temporarily
disabled the API due to bandwidth usage constraints.

The last error we are going to discuss is for the following test case for the ecommerce-server NodeJS API.
Note that, in contrast to the previous examples, the generated test here is in Jest (used for JavaScript/TypeScript
APIs) format instead of JUnit.

16

let token_foo = " Bearer " ;
await superagent

1 test ( " test_6 " , async () = > {
2
3
4
5
6
7
8

. post ( baseUrlOfSut + " / graphql " )
. set ( ’ Content - Type ’ , ’ application / json ’)
. send ( " { " +

" \" query \": \" mutation { login ( data :{ email :\\\" foo@foo . com \\\" , password :\\\" bar123 \\\"}) {

token }}\" " +

" } " )

. then ( res = > { token_foo += res . body . data . login . token ;} ,

error = > { console . log ( error . response . body ) ; throw Error ( " Auth failed . " ) }) ;;

const res_0 = await superagent

. post ( baseUrlOfSut + " / graphql " ) . set ( ’ Accept ’ , " application / json " )
. set ( " Authorization " , token_foo ) // foo - auth
. set ( ’ Content - Type ’ , ’ application / json ’)
. send ( " { " +

images } , employees { createdAt , username , email , bio , image } , createdAt , bio , rate , city , state , number , sales }

" \" query \": \"

{ findStoreById

( id : \\\" Z \\\")

{ id , products { categories { name } , brand ,

} \" " +

" } " )

. ok ( res = > res . status ) ;

expect ( res_0 . status ) . toBe (200) ; // build / src / store / store . service . js_39_40
expect ( res_0 . header [ " content - type " ]. startsWith ( " application / json " ) ) . toBe ( true ) ;
expect ( res_0 . body . errors . length ) . toBe (1) ;
expect ( res_0 . body . errors [0]. message ) . toBe ( " invalid input syntax for integer : \" Z \" " ) ;
expect ( res_0 . body . errors [0]. locations . length ) . toBe (1) ;
expect ( res_0 . body . errors [0]. locations [0]. line ) . toBe (1.0) ;
expect ( res_0 . body . errors [0]. locations [0]. column ) . toBe (5.0) ;
expect ( res_0 . body . errors [0]. path . length ) . toBe (1) ;
expect ( res_0 . body . errors [0]. path [0]) . toBe ( " findStoreById " ) ;
expect ( res_0 . body . errors [0]. extensions . code ) . toBe ( " I N T E R N A L _ S E R V E R _ E R R O R " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . query ) . toBe ( " SELECT \" Store \".\" id \" AS \" Store_id \" ,
\" Store \".\" created_at \" AS \" Store_created_at \" , \" Store \".\" updated_at \" AS \" S tor e_ up da te d_ at \" , \"
Store \".\" name \" AS \" Store_name \" , \" Store \".\" bio \" AS \" Store_bio \" , \" Store \".\" rate \" AS \"
Store_rate \" , \" Store \".\" slug \" AS \" Store_slug \" , \" Store \".\" street \" AS \" Store_street \" , \" Store
\".\" city \" AS \" Store_city \" , \" Store \".\" state \" AS \" Store_state \" , \" Store \".\" country \" AS \"
Store_country \" , \" Store \".\" neighborhood \" AS \" S to r e_ n ei gh b or h oo d \" , \" Store \".\" number \" AS \"
Store_number \" , \" Store \".\" zipCode \" AS \" Store_zipCode \" , \" Store \".\" sales \" AS \" Store_sales \" , \"
Store__employees \".\" id \" AS \" S t o r e __ e m p l o y e e s _ i d \" , \" Sto re_ _e mp lo ye es \".\" created_at \" AS \"
S t o r e _ _ e m p l o y e e s _ c r e a t e d _ a t \" , \" Store__em pl oy ee s \".\" updated_at \" AS \" S t o r e _ _ e m p l o y e e s _ u p d a t e d _ a t \" ,
\" Store__employees \".\" name \" AS \" S t o r e _ _ e m p l o y e e s _ n a m e \" , \" S to re __ em pl oy ee s \".\" username \" AS \"
S t o r e _ _ e m p l o y e e s _ u s e r n a m e \" , \" Store__employees \".\" email \" AS \" S t o r e _ _ e m p l o y e e s _ e m a i l \" , \"
Store__employees \".\" bio \" AS \" S t o r e _ _ e m p l o y e e s _ b i o \" , \" St or e_ _e mp lo ye es \".\" image \" AS \"
S t o r e _ _ e m p l o y e e s _ i m a g e \" , \" Store__employees \".\" role \" AS \" S t o r e _ _ e m p l o y e e s _ r o l e \" , \"
Store__employees \".\" status \" AS \" S t o r e _ _ e m p l o y e e s _ s t a t u s \" , \" S to re __ em pl oy ee s \".\" password \" AS \"
S t o r e _ _ e m p l o y e e s _ p a s s w o r d \" , \" Store__products \".\" id \" AS \" S to r e_ _ pr od u ct s_ i d \" , \" Store__products
\".\" created_at \" AS \" S t o r e _ _ p r o d u c t s _ c r e a t e d _ a t \" , \" Store__products \".\" updated_at \" AS \"
S t o r e _ _ p r o d u c t s _ u p d a t e d _ a t \" , \" Store__pro ducts \".\" title \" AS \" S t o r e _ _ p r o d u c t s _ t i t l e \" , \"
Store__products \".\" description \" AS \" S t o r e _ _ p r o d u c t s _ d e s c r i p t i o n \" , \" Store__products \".\" brand \" AS
\" S t o r e _ _ p r o d u c t s _ b r a n d \" , \" Store__products \".\" sku \" AS \" S t o r e _ _ p r o d u c t s _ s k u \" , \" Sto re__ pro duct s
\".\" price \" AS \" S t o r e _ _ p r o d u c t s _ p r i c e \" , \" Store__products \".\" thumbnail \" AS \"
S t o r e _ _ p r o d u c t s _ t h u m b n a i l \" , \" Store__products \".\" images \" AS \" S t o r e _ _ p r o d u c t s _ i m a g e s \" , \"
Store__products \".\" reviews \" AS \" S t o r e _ _ p r o d u c t s _ r e v i e w s \" , \" Store__products \".\" quantity \" AS \"
S t o r e _ _ p r o d u c t s _ q u a n t i t y \" , \" Store__products \".\" dimension \" AS \" S t o r e _ _ p r o d u c t s _ d i m e n s i o n \" , \"
Store__products \".\" storeId \" AS \" S t o r e _ _ p r o d u c t s _ s t o r e I d \" FROM \" store \" \" Store \" LEFT JOIN \"
s t o r e _ e m p l o y e e s _ u s e r s \" \" S t o r e _ S t o r e _ _ e m p l o y e e s \" ON \" S t o r e _ S t o r e _ _ e m p l o y e e s \".\" storeId \"=\" Store
\".\" id \" LEFT JOIN \" users \" \" Store__employees \" ON \" Store__employees \".\" id \"=\"
S t o r e _ S t o r e _ _ e m p l o y e e s \".\" usersId \"
\".\" storeId \"=\" Store \".\" id \" WHERE \" Store \".\" id \" IN ( $1 ) " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . parameters . length ) . toBe (1) ;
expect ( res_0 . body . errors [0]. extensions . exception . parameters [0]) . toBe ( " Z " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . driverError . length ) . toBe (90.0) ;
expect ( res_0 . body . errors [0]. extensions . exception . driverError . name ) . toBe ( " error " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . driverError . severity ) . toBe ( " ERROR " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . driverError . code ) . toBe ( " 22 P02 " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . driverError . file ) . toBe ( " numutils . c " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . driverError . line ) . toBe ( " 62 " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . driverError . routine ) . toBe ( " pg_atoi " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . length ) . toBe (90.0) ;
expect ( res_0 . body . errors [0]. extensions . exception . severity ) . toBe ( " ERROR " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . code ) . toBe ( " 22 P02 " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . file ) . toBe ( " numutils . c " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . line ) . toBe ( " 62 " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . routine ) . toBe ( " pg_atoi " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . stacktrace . length ) . toBe (9) ;
expect ( res_0 . body . errors [0]. extensions . exception . stacktrace [0]) . toBe ( " QueryFailedError : invalid input
syntax for integer : \" Z \" " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . stacktrace [1]) . toBe ( "
TypeORMError [ as constructor ] ( D :\\ WORK \\ EXPERIMENTS \\ graphql - journal \\ y100k_0_9 \\ ecommerce - server \\
node_modules \\ typeorm \\ error \\ TypeORMError . js :9:28) " ) ;
expect ( res_0 . body . errors [0]. extensions . exception . stacktrace [2]) . toBe ( "
WORK \\ EXPERIMENTS \\ graphql - journal \\ y100k_0_9 \\ ecommerce - server \\ node_modules \\ typeorm \\ error \\
Q u er y Fa i l e d Error . js :13:28) " ) ;
// Skipping assertions on the remaining 6 elements . This limit of 3 elements can be increased in the
confi gurations
expect ( res_0 . body . data . findStoreById ) . toBe ( null ) ;

LEFT JOIN \" product \" \" Store__products \" ON \" Store__product s

at QueryFailedError .

at new QueryFailedError ( D :\\

9
10
11
12
13
14
15
16
17
18
19

20
21
22
23
24
25
26
27
28
29
30
31
32
33

34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50

51

52

53

54
55 }) ;

17

The API here returns the error message invalid input syntax for integer: ‘‘Z’’. In the schema, the id input
for the query findStoreById is of type string (and so EvoMaster did send an input string like ‘‘Z’’), but the
API is expecting an integer. Technically, this could be considered as a schema-related fault. However, there
might be good reasons for sending a numeric value as a string in JSON, as JSON numbers are considered as
64-bit double-float values. This is an issue if one rather needs to deal with 64-bit integers (e.g., for numeric ids
in SQL databases). The major issue here, though, is ‘‘where’’ the check is done. The GraphQL specification
allows to provide extra information in the errors objects, under an optional field called extensions. What can
be present in this field depends on the different GraphQL framework implementations. In this particular case,
the full stack-trace of an internal thrown exception is added to the response.

First, this could be technically a security issue if the API was in production and not just run locally for
testing. Full stack-trace details are useful for debugging, but they expose internal details of the API that could
be exploited by external attackers. Second, the exception seems to happen in a SQL SELECT query, which is
malformed. The point here is that the id in the SQL database is of type numeric, and so a value like ‘‘Z’’ is
invalid. However, the API does not check for such integer constraints as a first layer of input validation when a
GraphQL query is executed, and rather fail afterwards. This can be a serious problem if there are modifications
to the internal state of API before the thrown exception, as the API might be left in a inconsistent state.

RQ3: Different kinds of faults were automatically detected with our novel techniques, including wrong
handling of requests for missing data, and generated responses that do not match the API schemas.

6 Discussion and Future Directions

This section discusses the main findings of the paper, followed by possible future work. The main findings of
using the EvoMaster for automated GraphQL APIs testing can be summarized as follows:

1. The first finding of this study consists on the difficulty of automatically identifying test cases of GraphQL
APIs compared to the RESTful APIs. Indeed, the graph representation of the actions is more complex
than the traditional representation of the RESTful APIs. This representation is rich and might be used in
different domain applications, however, this needs a careful care of the automated test generation process.
Furthermore, whereas a RESTful API can have clear relations between resources based on hierarchical
URIs, and that information can be successfully exploited by test generation tools [57], this does not seem
the case for GraphQL APIs (e.g., no easy heuristics to determine which resources on the graph each
mutation operation might manipulate).

2. The second finding of this study is that the EvoMaster tool proved its applicability in handling other kinds
of web service APIs, represented by GraphQL APIs. EvoMaster was implemented and architectured
from the start to be able to be extended and adapted to other system test generation domains besides
REST APIs [14]. The results obtained in this paper shows that EvoMaster is a generic enough framework
for evolutionary-based system test generation, at least for applications where the entry point is a TCP
connection. Being released as open-source [22], EvoMaster can be further extended and used in other
domains as well.

3. To obtain better code coverage, white-box heuristics based on search-based techniques can help significantly.
However, existing APIs can have many faults that can be easily detected by simply sending random inputs.
This makes even simple approaches like black-box testing potentially useful for practitioners.

In order to improve the effectiveness of the automated GraphQL API testing, several directions may be

investigated in the future:

1. Test oracle problem. Given a test case, whether the result of its execution is correct or not can be
determined with an automated oracle [27]. Without an automated oracle, the developer has to determine
manually whether the observed test results are as expected or not. But having to manually check
hundreds/thousands of generated test cases might not viable. As discussed in the paper, query responses
with errors fields might not be representing actual faults in the SUT, but rather just the user sending
wrong data. In order to mitigate the test oracle problem, an intelligent automated strategy is needed
to differentiate between the actual faults from the user errors for a given GraphQL API response. One
approach is to use machine learning, in particular supervised classification, to automatically label whether
a response with errors field should be treated as a potential fault that the developer should investigate.
When test suites are generated at the end of the search, the test cases could be ordered based on their
probability of representing actual faults.

2. Evolutionary Computation. Evolutionary computation is an intelligent mechanism of exploring large
and big solution spaces, inspired by the evolutionary process from nature. In this research work, we only

18

used the evolutionary algorithm MIO already present in EvoMaster, but others might be more fitting for
the case of GraphQL API testing. In order to further improve the code coverage of the automated testing in
this domain, further investigation should be carried out in this area. For example, other techniques such as
Particle Swarm Optimization [38] and Ant Colony Optimization [50] could be considered. Combining other
testing techniques (e.g., Symbolic Execution [26]) with evolutionary computation can also be considered a
good direction to further address this problem [34].

3. Knowledge Discovery. Data mining and knowledge discovery is the process of extracting hidden
patterns from a large data collection. Decomposition is a widely used technique in solving complex
problems [32, 31]. The aim is to create highly correlated clusters, where each cluster contains similar data.
In our context, the idea is to apply the decomposition method to the GraphQL schema in order to derive
sub-graphs of schema. Each sub-graph might contain highly connected actions. Good decomposition
methods allow to find independent sub-graphs as much as possible, in order to enable the same test case
generation while dealing with the sub-graphs as when dealing with the entire GraphQL schema.

4. Industrial Settings. Further investigations with more case studies will be essential to generalize the
effectiveness of our novel technique. Of particular importance it will be to apply our technique in industrial
settings, to see and evaluate how engineers would use tools like EvoMaster in practice on their APIs.

7 Threats To Validity

Threats to internal validity come from the fact that our experiments are derived from a software tool. Errors in
such a tool could negatively affect the validity of our empirical results. Although our EvoMaster extension was
carefully tested, we cannot provide any guarantee of not having software faults. However, as it is open-source,
anyone can review its source code. Another potential issue is that the implemented solution in this research
work is based on random algorithms. This happens in particular for population initialization of the evolutionary
algorithm, where different test cases may be generated. To deal with this issue, each experiment for white-box
testing was repeated 30 times [19], with different random seeds, and the appropriate statistical tests were used
to analyze the results. All the APIs used for the white-box experiments are collected in a GitHub repository
called EMB [4], which is stored on Zenodo as well [25]. Furthermore, all of our scripts used to carry out our
experiments are stored as part of the repository of EvoMaster. This is done to enable third-parties to replicate
and validate our experiments. However, experiments for black-box testing cannot be reliably replicated, as they
rely on live services on which we do not have any control on (e.g., they can be modified at any time by their
owners).

Threats to external validity are due to the fact that only 7 GraphQL APIs for white-box testing, and 31
GraphQL APIs for black-box testing, were used in our empirical analysis. The generalization of such results to
other APIs might not be possible at this stage. More APIs should be investigated in the future. However, as
this is the first work on white-box testing of GraphQL APIs, already achieving good coverage and finding real
faults on a complex GraphQL API provide a promising first step.

8 Conclusions

This paper introduced a new approach for automated testing for GraphQL APIs. It is a full complete solution,
starting from the schema extraction and ending by automatically generating test cases outputted in JUnit and
Jest format. Two testing modes are implemented and evaluated: white-box and black box testing.

In order to intelligently explore the test case space, evolutionary computation techniques are used in the
white-box testing. Two mutation operators (internal and structure mutation) are defined, where the goal is to
maximize code coverage and fault-finding. In addition, random testing is used for the black-box mode.

To validate the applicability of the proposed framework, it is integrated into the EvoMaster open-source
tool. Our empirical analysis was carried out on 7 GraphQL APIs for white-box testing, and 31 GraphQL APIs
for black-box testing. The results show the clear improvement of using the evolutionary computation compared
with the random search baseline for white-box testing. Regarding black-box testing, several real faults were
found by random testing in the analyzed APIs.

To learn more about EvoMaster, visit www.evomaster.org.

Acknowledgments

This work is funded by the European Research Council (ERC) under the European Union’s Horizon 2020
research and innovation programme (EAST project, grant agreement No. 864972).

19

References

[1] apis.guru. https://apis.guru/graphql-apis/.

[2] e-commerce. https://github.com/react-shop/react-ecommerce.

[3] EvoMaster. https://github.com/EMResearch/EvoMaster.

[4] Evomaster benchmark (emb). https://github.com/EMResearch/EMB.

[5] Github. https://github.com.

[6] Graphql foundation. https://graphql.org/foundation/.

[7] Patio-api. https://github.com/patio-team/patio-api.

[8] petclinic. https://github.com/spring-petclinic/spring-petclinic-graphql.

[9] react-finland. https://github.com/ReactFinland/graphql-api.

[10] timbuctoo. https://github.com/HuygensING/timbuctoo.

[11] Ali, S., Briand, L. C., Hemmati, H., and Panesar-Walawege, R. K. A systematic review of the
application and empirical investigation of search-based test case generation. IEEE Transactions on Software
Engineering 36, 6 (2009), 742--762.

[12] Alshraideh, M., and Bottaci, L. Search-based software test data generation for string data using
program-specific search operators. Software Testing, Verification, and Reliability 16, 3 (2006), 175--203.

[13] Arcuri, A. Many Independent Objective (MIO) Algorithm for Test Suite Generation. In International

Symposium on Search Based Software Engineering (SSBSE) (2017), pp. 3--17.

[14] Arcuri, A. EvoMaster: Evolutionary Multi-context Automated System Test Generation.

In IEEE

International Conference on Software Testing, Verification and Validation (ICST) (2018), IEEE.

[15] Arcuri, A. An experience report on applying software testing academic results in industry: we need usable

automated test generation. Empirical Software Engineering 23, 4 (2018), 1959--1981.

[16] Arcuri, A. Restful api automated test case generation with evomaster. ACM Transactions on Software

Engineering and Methodology (TOSEM) 28, 1 (2019), 3.

[17] Arcuri, A. Automated black-and white-box testing of restful apis with evomaster. IEEE Software 38, 3

(2020), 72--78.

[18] Arcuri, A., and Briand, L. Adaptive random testing: An illusion of effectiveness?

In ACM Int.

Symposium on Software Testing and Analysis (ISSTA) (2011), pp. 265--275.

[19] Arcuri, A., and Briand, L. A Hitchhiker’s Guide to Statistical Tests for Assessing Randomized
Algorithms in Software Engineering. Software Testing, Verification and Reliability (STVR) 24, 3 (2014),
219--250.

[20] Arcuri, A., and Galeotti, J. P. Handling sql databases in automated system test generation. ACM

Transactions on Software Engineering and Methodology (TOSEM) 29, 4 (2020), 1--31.

[21] Arcuri, A., and Galeotti, J. P. Testability transformations for existing apis. In 2020 IEEE 13th
International Conference on Software Testing, Validation and Verification (ICST) (2020), IEEE, pp. 153--
163.

[22] Arcuri, A., Galeotti, J. P., Marculescu, B., and Zhang, M. Evomaster: A search-based system

test generation tool. Journal of Open Source Software 6, 57 (2021), 2153.

[23] Arcuri, A., Iqbal, M. Z., and Briand, L. Random testing: Theoretical results and practical implications.

IEEE Transactions on Software Engineering (TSE) 38, 2 (2012), 258--277.

[24] Arcuri, A., ZhangMan, asmab89, Bogdan, Gol, A., Galeotti, J. P., Seran, López, A. M.,

Aldasoro, A., Panichella, A., and Niemeyer, K. Emresearch/evomaster:, June 2022.

[25] Arcuri, A., ZhangMan, Gol, A., and asmab89. Emresearch/emb:, Feb. 2022.

20

[26] Baldoni, R., Coppa, E., D’elia, D. C., Demetrescu, C., and Finocchi, I. A survey of symbolic

execution techniques. ACM Computing Surveys (CSUR) 51, 3 (2018), 1--39.

[27] Barr, E. T., Harman, M., McMinn, P., Shahbaz, M., and Yoo, S. The oracle problem in software

testing: A survey. IEEE Transactions on Software Engineering (TSE) 41, 5 (2015), 507--525.

[28] Belhadi, A., Zhang, M., and Arcuri, A. Evolutionary-based Automated Testing for GraphQL APIs.

In Genetic and Evolutionary Computation Conference (GECCO) (2022).

[29] Cabrera, E., Cárdenas, P., Cedillo, P., and Pesántez-Cabrera, P. Towards a methodology for
creating internet of things (iot) applications based on microservices. In 2020 IEEE International Conference
on Services Computing (SCC) (2020), IEEE, pp. 472--474.

[30] Cirillo, F., Gómez, D., Diez, L., Maestro, I. E., Gilbert, T. B. J., and Akhavan, R. Smart
city iot services creation through large-scale collaboration. IEEE Internet of Things Journal 7, 6 (2020),
5267--5275.

[31] Djenouri, Y., Belhadi, A., Fournier-Viger, P., and Lin, J. C.-W. Fast and effective cluster-based

information retrieval using frequent closed itemsets. Information Sciences 453 (2018), 154--167.

[32] Djenouri, Y., Lin, J. C.-W., Nørvåg, K., Ramampiaro, H., and Yu, P. S. Exploring decomposition
for solving pattern mining problems. ACM Transactions on Management Information Systems (TMIS) 12,
2 (2021), 1--36.

[33] Fraser, G., and Arcuri, A. EvoSuite: automatic test suite generation for object-oriented software. In

ACM Symposium on the Foundations of Software Engineering (FSE) (2011), pp. 416--419.

[34] Galeotti, J. P., Fraser, G., and Arcuri, A. Extending a search-based test generator with adaptive
dynamic symbolic execution. In ACM Int. Symposium on Software Testing and Analysis (ISSTA) (2014),
ACM, pp. 421--424.

[35] Godefroid, P., Lehmann, D., and Polishchuk, M. Differential regression testing for rest apis. In
Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis (2020),
pp. 312--323.

[36] Harman, M., Mansouri, S. A., and Zhang, Y. Search-based software engineering: Trends, techniques

and applications. ACM Computing Surveys (CSUR) 45, 1 (2012), 11.

[37] Hartig, O., and Pérez, J. Semantics and complexity of graphql. In Proceedings of the 2018 World

Wide Web Conference (2018), pp. 1155--1164.

[38] Hossain, M. S., Moniruzzaman, M., Muhammad, G., Ghoneim, A., and Alamri, A. Big data-driven
service composition using parallel clustered particle swarm optimization in mobile environment. IEEE
Transactions on Services Computing 9, 5 (2016), 806--817.

[39] Karlsson, S., Čaušević, A., and Sundmark, D. Automatic property-based testing of graphql apis.

arXiv preprint arXiv:2012.07380 (2020).

[40] Kim, M., Xin, Q., Sinha, S., and Orso, A. Automated test generation for rest apis: No time to rest

yet, 2022.

[41] Kim, M., Xin, Q., Sinha, S., and Orso, A. Automated test generation for rest apis: No time to rest yet.
In Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis
(New York, NY, USA, 2022), ISSTA 2022, Association for Computing Machinery, p. 289–301.

[42] Korel, B. Automated software test data generation. IEEE Transactions on software engineering 16, 8

(1990), 870--879.

[43] Mao, K., Harman, M., and Jia, Y. Sapienz: Multi-objective automated testing for android applications.

In ACM Int. Symposium on Software Testing and Analysis (ISSTA) (2016), ACM, pp. 94--105.

[44] Marculescu, B., Zhang, M., and Arcuri, A. On the faults found in rest apis by automated test
generation. ACM Transactions on Software Engineering and Methodology (TOSEM) 31, 3 (2022), 1--43.

[45] Martin-Lopez, A., Segura, S., Muller, C., and Ruiz-Cortés, A. Specification and automated
analysis of inter-parameter dependencies in web apis. IEEE Transactions on Services Computing (2021).

[46] Newman, S. Building Microservices. " O’Reilly Media, Inc.", 2015.

21

[47] Taelman, R., Vander Sande, M., and Verborgh, R. Graphql-ld: linked data querying with graphql.

In ISWC2018, the 17th International Semantic Web Conference (2018), pp. 1--4.

[48] Vargas, D. M., Blanco, A. F., Vidaurre, A. C., Alcocer, J. P. S., Torres, M. M., Bergel, A.,
and Ducasse, S. Deviation testing: A test case generation technique for graphql apis. In 11th International
Workshop on Smalltalk Technologies (IWST) (2018), pp. 1--9.

[49] Viglianisi, E., Dallago, M., and Ceccato, M. Resttestgen: Automated black-box testing of restful
apis. In IEEE International Conference on Software Testing, Verification and Validation (ICST) (2020),
IEEE.

[50] Wu, Q., and Zhu, Q. Transactional and qos-aware dynamic service composition based on ant colony

optimization. Future Generation Computer Systems 29, 5 (2013), 1112--1119.

[51] Zetterlund, L., Tiwari, D., Monperrus, M., and Baudry, B. Harvesting production graphql
queries to detect schema faults. In 2022 IEEE Conference on Software Testing, Verification and Validation
(ICST) (2022), IEEE, pp. 365--376.

[52] Zhang, M., and Arcuri, A. Adaptive hypermutation for search-based system test generation: A study
on rest apis with evomaster. ACM Transactions on Software Engineering and Methodology (TOSEM) 31, 1
(2021).

[53] Zhang, M., and Arcuri, A. Open problems in fuzzing restful apis: A comparison of tools, 2022.

[54] Zhang, M., and Arcuri, A. Open problems in fuzzing restful apis: A comparison of tools. arXiv preprint

arXiv:2205.05325 (2022).

[55] Zhang, M., Arcuri, A., Li, Y., Xue, K., Wang, Z., Huo, J., and Huang, W. Fuzzing microservices

in industry: Experience of applying evomaster at meituan, 2022.

[56] Zhang, M., Belhadi, A., and Arcuri, A. Javascript instrumentation for search-based software testing:
In IEEE International Conference on Software Testing, Verification and

A study with restful apis.
Validation (ICST) (2022), IEEE.

[57] Zhang, M., Marculescu, B., and Arcuri, A. Resource-based test case generation for restful web
services. In Proceedings of the Genetic and Evolutionary Computation Conference (2019), pp. 1426--1434.

22

