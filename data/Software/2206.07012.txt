Frequency Throttling Side-Channel Attack

Chen Liu†, Abhishek Chakraborty†, Nikhil Chawla†, Neer Roggel‡

† Intel Corporation, Hillsboro, OR, USA

‡ Intel Corporation, Rio Rancho, NM, USA

{chen1.liu,abhishek1.chakraborty,nikhil.chawla,neer.roggel}@intel.com

2
2
0
2

n
u
J

4
1

]

R
C
.
s
c
[

1
v
2
1
0
7
0
.
6
0
2
2
:
v
i
X
r
a

ABSTRACT
Modern processors dynamically control their operating frequency
to optimize resource utilization, maximize energy savings, and to
conform to system-defined constraints. If, during the execution
of a software workload, the running average of any electrical or
thermal parameter exceeds its corresponding predefined threshold
value, the power management architecture will reactively adjust
CPU frequency to ensure safe operating conditions. In this paper,
we demonstrate how such power management-based CPU throt-
tling activity forms a source of timing side-channel information
leakage, which can be exploited by an attacker to infer secret data
from a constant-cycle victim workload. We highlight the fact that a
constant-cycle implementation of code does not necessarily guar-
antee its constant execution on different data inputs with respect to
wall clock time. This is because existing throttling mechanisms per-
form data-dependent frequency adjustments, which in turn make
the running time of the code also data-dependent. The proposed
frequency throttling side-channel analysis attack can be launched
by kernel-space attackers and user-space attackers, thus compro-
mising security guarantees provided by isolation boundaries. We
validate our attack methodology across different systems by per-
forming experiments on a constant-cycle implementation of the
AES-128 algorithm. The results of our experimental evaluations
demonstrate how the attacker can successfully recover the targeted
AES key by correlating the collected timing side-channel traces
with the corresponding timing estimates for different key guesses,
under frequency throttling. Finally, we discuss different options
to mitigate the threat posed by frequency throttling side-channel
attacks, as well as their advantages and disadvantages.

KEYWORDS
Power Management, Frequency Throttling, Side-Channel Analysis

ACM Reference format:
Chen Liu†, Abhishek Chakraborty†, Nikhil Chawla†, Neer Roggel‡. 2022.
Frequency Throttling Side-Channel Attack. In Proceedings of , xxx, xxx (xxx),
14 pages.
https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 INTRODUCTION
Power management architectures of modern processor designs play
a central role in optimizing for and balancing between high per-
formance and low power consumption requirements, a product of
decades of academic and industry innovation [13, 22, 24, 31, 46, 51].
For example, a widely-used power management architectural mech-
anism known as Dynamic Voltage and Frequency Scaling (DVFS) is
available on Intel, AMD and ARM CPUs [36, 38]. DVFS dynamically
adjusts CPU frequency and voltage in order to reduce system power

consumption, yielding higher performance per Watt, or to quickly
alter CPU frequency during workload execution, in order to ensure
that different electrical and thermal parameters of the system re-
main below predefined safe limits [6, 9, 31]. Similar such throttling
has been recently identified as enabling covert channels [25], given
its reliance on shared infrastructure across security domains. In this
work, we investigate if such workload-dependent CPU frequency
adjustments yield exploitable side-channels.

Modern systems also provide multiple software-accessible teleme-
tries which allow users to characterize bottlenecks at scale [11],
monitor resource utilization, power and performance [15, 18, 47],
and gain insights into system reliability [26]. Recently, researchers
have demonstrated how a processor’s energy telemetry reporting
framework can be used maliciously to perform power side-channel
analysis attacks [40, 41]. These attacks allow a user-space attacker
(having Ring 3 privilege) to infer secret information from a targeted
victim workload running inside a TEE. In order to thwart such side-
channel attacks, CPU vendors (both Intel and AMD) have provided
security patches [5, 28] which remove Ring 3 software access to
the energy telemetry data via the Linux kernel module. In addi-
tion, Intel has also provided a filtering-based mitigation patch [29]
to safeguard the reported energy telemetry readings even from a
kernel-space attacker (having Ring 0 privilege).

In this paper, we study the potential threat posed by a new type of
side-channel information leakage source termed the frequency throt-
tling side-channel. Such a side-channel arises due to the dynamic
adjustment of CPU frequency when workload execution causes one
or more electrical or thermal system parameters to exceed prede-
fined limits. Typically, in such a scenario, the power management
architecture throttles CPU frequency to a lower value, for ensuring
safe operating conditions of the system. Then, depending on the
running average of the parameter(s) in question, CPU frequency is
again boosted to a higher value until any limit threshold is violated.
Therefore, increases and decreases in CPU frequency (hereinafter,
referred to as average throttling frequency) during workload exe-
cution are dependent on the instantaneous electrical and thermal
parameters being capped by system-defined limits. The average
throttled frequency in turn affects the overall execution time of the
workload, even if its implementation follows constant cycle coding
principles [27], or it is being executed inside a TEE. The objective
of a side-channel attacker is to deduce the targeted secret from a
victim workload by monitoring fluctuations in its execution time for
processing different inputs. Unlike software-accessible telemetries,
frequency throttling side-channel leakage cannot be thwarted by
enforcing access restriction or filtering-based mitigation patches.
This is because any presumed malicious Ring 3 software can pre-
cisely monitor the execution time of a targeted process by reading
timestamp counter values (e.g., using RDTSC [44]).

 
 
 
 
 
 
xxx, xxx, xxx

Chen Liu†, Abhishek Chakraborty†, Nikhil Chawla†, Neer Roggel‡

In this work, we mainly consider the running average power
limit (RAPL) controlled CPU frequency throttling activity, demon-
strating the feasibility of a throttling side-channel attack. Yet, a
similar attack methodology may be equally applicable in scenarios
where dynamic CPU frequency adjustments are performed due to
other electrical or thermal system constraints. In particular, we
focus on the data-correlated power consumption behavior of victim
code as considered previously in the Platypus attack[40]. While the
Platypus attack relies on power consumption information directly
exposed to privileged software through a telemetry interface, a
throttling side-channel converts the power differences to power
limit-induced execution time differences, which are easily acces-
sible by unprivileged software. It is to be further noted that the
Platypus attack and the proposed throttling side-channel attack
are two different attacks that exploit the same information leak-
age source, namely data-correlated power consumption resulting
from inherent CMOS circuit properties. Also, both attacks require
neither physical access to the target platform nor any additional
high-precision power measurement setup as required in traditional
side-channel attacks.

We demonstrate the applicability of the throttling side-channel
analysis attack to retrieve secret information from cryptographic
primitives by considering an AES-NI-based AES implementation
as a case study. The results of our experimental evaluations reveal
the effectiveness of such an attack in finding the secret AES key, by
performing statistical analysis on the collected timing side-channel
traces. In addition, we also discuss potential mitigation options
which can be incorporated by cryptographic implementations to
thwart throttling side-channel attacks.
The main contributions of this paper can be summarized as follows:
• Presentation of a new type of side-channel attack which exploits
the workload-dependent CPU frequency adjustments performed
by the power management architecture of modern processors
• Detailed experimental evaluation of the frequency throttling side-
channel analysis attack, showing extraction of cryptographic
secrets (e.g., AES key) across different systems

• Enumerating necessary conditions of a frequency throttling side-
channel attack and providing mitigation options thwarting each
of the necessary conditions

The rest of the paper is organized as follows: Section 2 presents
background information of power management algorithms and
related side-channel attacks. Section 3 presents details related to
the source of the throttling side-channel leakage and also, provides
an overview of how an attacker can exploit such leaked information.
Section 4 describes the threat model and showcases an attack using
the throttling side-channel against an AES-NI-based cryptographic
implementation. Section 5 discusses different options to mitigate
a frequency throttling side-channel. Section 6 discusses possible
directions for future work. Section 7 concludes the paper.

2 BACKGROUND
2.1 Power Telemetry Side-Channel Leakage

2.1.1 Related Work. Existing work in related literature has demon-

strated the vulnerability of software-accessible energy and power
telemetry information to side-channel analysis attacks. In [55], the
authors highlighted the use of software-accessible battery data of

an Android phone to extract sensitive information from multiple
applications. It has been shown in [19] that energy meter read-
ings can be used to infer control flow dependency as well as cache
hit/miss patterns for a program. [43] demonstrated the utilization
of energy meter readings to distinguish keys of different Hamming
weights for an RSA implementation.

In addition to the above, a couple of recent works have targeted
a processor’s energy consumption information (as exposed by Run-
ning Average Power Limit (RAPL) interfaces in both Intel and AMD
processors) to perform side-channel analysis attacks. In [40], the
authors demonstrate software-based power side-channel attacks
called Platypus to extract a key from a secure enclave, to break ker-
nel address space layout randomization (KASLR), and to establish
a timing-independent covert channel. In [41], the authors present
a methodology to perform side-channel risk assessment of differ-
ent software-accessible telemetries including RAPL energy, CPU
frequency, voltage, and temperature data.

2.1.2 Correlation Power Analysis (CPA). Power analysis attacks
exploit the fact that the dynamic power consumption 𝑃𝑑 𝑦𝑛 of a
digital CMOS-based circuit is data-dependent in nature [37], as
evident in the following equation:

𝑃𝑑𝑦𝑛 = 𝛼 · 𝐶 · 𝑉 2

𝐷𝐷 · 𝑓

(1)

where, 𝛼, 𝐶, 𝑉𝐷𝐷 , and 𝑓 represent switching activity factor, load
capacitance, supply voltage, and clock frequency, respectively. The
main objective of a power side-channel analysis attack is to re-
trieve a targeted secret by analyzing the data-dependent power
consumption of a cryptographic implementation during a selected
time window. Traditional physical side-channel analysis techniques
such as Correlation Power Analysis (CPA) perform statistical anal-
ysis on a large number of side-channel traces which are collected
by varying the input data [42]. In a typical CPA attack, the attacker
correlates the actual power consumption values 𝑃𝑎 from the col-
lected power traces with the corresponding hypothetical power
leakage values 𝑃ℎ (as calculated using standard Hamming weight
or Hamming distance power models). This is done for different key
guesses using the following measure:

𝜌𝑘 =

𝑐𝑜𝑣 (𝑃𝑎, 𝑃𝑘
ℎ )
𝜎𝑃𝑎 𝜎𝑃𝑘

ℎ

(2)

ℎ

, and 𝜎𝑃𝑘

where, 𝜌𝑘 , 𝜎𝑃𝑎
, represent the Pearson’s correlation coeffi-
cient for key guess 𝑘, the standard deviation of the actual power
values 𝑃𝑎, and the standard deviation of the hypothetical power
values 𝑃𝑘
ℎ

for key guess 𝑘, respectively.

The variation in power consumption values due to processing
of different data as measured by existing CPU telemetry interfaces
(low sampling rates) is much less pronounced when compared to the
variations as captured by traditional physical side-channel setups
(high sampling rates). In addition, measurement inaccuracy and
noise in the telemetry readings further reduce the signal-to-noise ra-
tio (SNR) of the collected side-channel traces. However, even in spite
of these challenges, it has been demonstrated in [40] that the CPA
attack is powerful enough to distinguish minute secret-dependent
biases in the telemetry readings and thus, can successfully recover
the underlying secret data. In this work, we also use a variation of

Frequency Throttling Side-Channel Attack

xxx, xxx, xxx

CPA attack (details in Section 3.1.2) to perform statistical analysis
of collected telemetry traces.

2.1.3 Existing Countermeasures. A number of possible counter-
measures to thwart power telemetry attacks were listed in [40].
These mitigation strategies include restricting user-space access
(Ring-3 privilege) to powercap driver in Linux and limiting the
measurement resolution of telemetry interfaces. In response to the
Platypus attack, CPU vendors (both Intel and AMD) have updated
the Linux powercap driver to restrict unprivileged access to RAPL
interface [5, 28]. In addition, Intel also issued a mitigation adding
white noise to reported RAPL interface readings, which is enforced
when Intel SGX is enabled and can be enabled by software via a
software switch [29]. These approaches effectively thwart the CPA
attack on software-accessible power telemetry data.

2.2 CPU Power Management
In this work, we demonstrate how an attacker can leverage the
fast dynamic changes in a processor’s power performance states,
triggered due to its power management-related limits (hereinafter,
referred to as power limits) to create a novel source of timing side-
channel leakage during workload execution. We show that the
attack is possible even with the abovementioned countermeasures
against power telemetry side-channels, which are not designed to
mitigate a frequency throttling side-channel. Here we introduce rel-
evant background information of modern CPU power management,
using Intel processors as an example.

2.2.1 Processor Performance States. Intel processors implement
performance states (referred to as 𝑃-𝑆𝑡𝑎𝑡𝑒𝑠, defined per ACPI [16]),
by realizing a DVFS mechanism for optimizing power consump-
tion. Such 𝑃-𝑆𝑡𝑎𝑡𝑒𝑠 correspond to different 𝑣𝑜𝑙𝑡𝑎𝑔𝑒-𝑓 𝑟𝑒𝑞𝑢𝑒𝑛𝑐𝑦 pairs,
which can be proactively controlled either by the operating system
(using SpeedStep [33]) or by the hardware (using Speed Shift [34]).
As per convention, the highest CPU 𝑃-𝑆𝑡𝑎𝑡𝑒 is referred to as P0 and
it corresponds to the highest achievable operating frequency, as
determined during manufacturing, enabling the processor to enter
the so called turbo mode.

During execution of a workload, if any system-specific limit (elec-
trical or thermal) is violated, the processor 𝑃-𝑆𝑡𝑎𝑡𝑒 is reactively
controlled by the power management algorithm. The remainder of
the paper focuses on reactive limits, which induce the frequency
throttling side-channel. Depending on the criticality of the limit
being hit, reactive control of 𝑃-𝑆𝑡𝑎𝑡𝑒𝑠 may be performed with vari-
ous response times (in the order of a few ms to tens of seconds) to
promptly bring the system back to safe operating conditions.

2.2.2 𝑃-𝑆𝑡𝑎𝑡𝑒 Control under Reactive Limits. The power man-
agement algorithm of a CPU periodically calculates different run-
ning averages of electrical parameters (e.g., power, current, etc.) of
windows of pre-specified lengths. The running averages are then
compared against respective reactive limit values to compute the
power budget, which is the difference between the reactive limit
and average consumed power, for example. Based on the power
budget, the power management algorithm 𝑃𝐿_𝐴𝐿𝐺 (·) computes
the new 𝑃-𝑆𝑡𝑎𝑡𝑒 limit 𝑓𝑚𝑎𝑥 , which is the maximum possible CPU

operating frequency that satisfies all the reactive limits of the sys-
tem. An overview of the new 𝑃-𝑆𝑡𝑎𝑡𝑒 upper bound selection process
by the controller is presented in Algorithm 1.

When none of the reactive limits are hit, all power budgets
remain positive and CPU operating frequency is not capped by 𝑓𝑚𝑎𝑥
(or in other words, 𝑓𝑚𝑎𝑥 is higher than maximum turbo frequency).
If any of these calculated running averages exceed a specific reactive
limit (e.g., power limit 𝑃𝐿), the power management algorithm will
trigger CPU throttling activity and reduce 𝑓𝑚𝑎𝑥 . In such cases, in
order to maximize performance while satisfying the reactive limits,
the processor may run at the frequency limit 𝑓𝑚𝑎𝑥 , as governed by
its feedback control mechanisms [10].

Algorithm 1 Determination of new 𝑃-𝑆𝑡𝑎𝑡𝑒 limit
Input:

1: (i) System reactive limit 𝑃𝐿𝑖 with running average time window

𝜏𝑖, 𝑖 ∈ [1, 𝑁 ]

2: (ii) Polling interval 𝑇
3: (iii) Current 𝑃-𝑆𝑡𝑎𝑡𝑒 limit 𝑓𝑚𝑎𝑥
4: (iv) Power management control algorithm 𝑃𝐿_𝐴𝐿𝐺 (·)

Output: New 𝑃-𝑆𝑡𝑎𝑡𝑒 limit 𝑓𝑚𝑎𝑥
5: for every 𝑇 time units do
6:

for 𝑖 from 1 to 𝑁 do

7:

8:

9:

10:

11:

12:

𝑃𝑖 ← Calculate avg. power over 𝜏𝑖
Δ ← 𝑃𝑖 − 𝑃𝐿𝑖 /*Available power budget*/
𝑓𝑚𝑎𝑥,𝑖 ← 𝑃𝐿_𝐴𝐿𝐺 (Δ)
if 𝑓𝑚𝑎𝑥 > 𝑓𝑚𝑎𝑥,𝑖 then

𝑓𝑚𝑎𝑥 = 𝑓𝑚𝑎𝑥,𝑖 /*Throttling activity*/

end if

end for

13:
14: end for

2.2.3 Common Reactive Limits. We describe a couple of the
reactive limits presented in several modern Intel processors [31].
Note that similar reactive limits are also present in the processors
of other vendors (e.g., AMD [6], ARM [9]).
• Running Average Power Limit (RAPL): RAPL is a feature
supported by Intel power management architecture to cap the
power consumption on the system. When the configured power
limit is exceeded, the CPU will be forced to run at a lower fre-
quency to maximize performance while meeting the power limit
requirement. Intel currently provides multiple power limit ca-
pabilities, such as package-level power limits (PL1, PL2, PL3)
and platform-level power limits (Psys). Ring 0 software can con-
figure the running average window 𝜏 and the power limit of
each capability through MSRs (e.g., MSR_PKG_POWER_LIMIT
for package-level power limits).

• Voltage Regulator Thermal Design Current Limit (VR TDC):
VR TDC is a power management feature supported by Intel
power management architecture. It is a current limit specified in
Amperes, that is maintained in order to satisfy the electrical con-
straints of the VR. Generally, the algorithm monitors the running
average current in Amperes by reading the VR current sensor
with the configured time window. If the limit is hit, the processor
will engage its frequency throttling to reduce its frequency, in
order to ensure current remains within the limit and budget.

xxx, xxx, xxx

Chen Liu†, Abhishek Chakraborty†, Nikhil Chawla†, Neer Roggel‡

2.3 Traditional Timing Side-Channel

Mitigations

In traditional timing side-channel analysis, an attacker exploits
differences in execution cycles of victim code to deduce the targeted
secret. Such timing differences can arise due to data-dependent
execution cycles of the victim process or due to mutual access of
shared system resources (e.g., cache lines, branch predictors, etc.)
by the victim and attacker processes.

Several countermeasures have been proposed in related litera-
ture, which use constant-cycle coding principles to address the issue
of traditional timing side-channel leakage [27]. A short summary
of such coding principles is as follows:

• Ensure code processes secret data consistently (i.e., requires same

number of clock cycles irrespective of secret data values).

• Ensure secret data values (or values derived from secret data)
do not affect the sequence of instructions executed due to a
conditional branch or an indirect branch target in the code.
• Ensure memory access patterns (or the data size of load/store

operations) are invariant with respect to secret data.

Existing work largely assumes that traditional timing side-channel
leakage can be mitigated by applying these principles to the secret
data-dependent portions of the code.

3 FREQUENCY THROTTLING

SIDE-CHANNEL

In this work, we demonstrate that mere application of constant-
cycle coding principles is insufficient to thwart timing side-channel
attacks, as system clock frequency may vary during the code exe-
cution phase and may be data-dependent and leak information.

3.1 Attack Primitives

3.1.1

Source of Throttling Side-Channel. In modern processors,
a major source of throttling side-channel information leakage is
related to the workload-dependent reactive control of 𝑃-𝑆𝑡𝑎𝑡𝑒𝑠 (line
11 of Algorithm 1). Let us consider the example presented in Fig. 1
to understand the underlying implementation details leading to
such throttling side-channel leakage. Suppose that the workload
under execution is a constant-cycle implementation of a function,
foo (arg data), with input argument data. As noted in section 2.3,
such a constant-cycle implementation has no traditional timing
side-channel leakage. However, as illustrated in Fig. 1(a), the power
consumption of the workload due to processing different data inputs
(𝑑𝑎𝑡𝑎1 and 𝑑𝑎𝑡𝑎2) might vary due to the differences in internal data-
dependent computations of the foo function. Without any loss of
generality, let us assume that the processing of 𝑑𝑎𝑡𝑎1 consumes
higher power (𝑃1) compared to that of 𝑑𝑎𝑡𝑎2 (𝑃2) (i.e., 𝑃1 > 𝑃2). If
both 𝑃1 and 𝑃2 are below all system-defined reactive limits, there
is no throttling activity and system frequency 𝑓𝑑𝑒 𝑓 𝑎𝑢𝑙𝑡 remains
the same irrespective of data consumed by foo. Therefore, in this
case, there is no data-dependent timing side-channel information
leakage, as the execution time of the workload is independent of
the inputs.

However, when power consumption reaches or crosses the sys-
tem’s electrical reactive limits (e.g., the limit is configured to a
lower value, or a power-hungry stressor code is executed in parallel

with function foo) as illustrated using Fig. 1(b), reactive limit in-
duced throttling activity will be triggered, resulting in a change to
𝑃-𝑆𝑡𝑎𝑡𝑒𝑠, as shown in Fig. 1(c). Since 𝑃1 > 𝑃2, the average throttling
frequency 𝑓1 for data input 𝑑𝑎𝑡𝑎1 will be lower than the average
throttling frequency 𝑓2 for data input 𝑑𝑎𝑡𝑎2 to satisfy the same
system-defined electrical or thermal limits. Both of these throttling
frequencies will be lower than the default system frequency prior to
throttling (i.e., 𝑓1 < 𝑓2 < 𝑓𝑑𝑒 𝑓 𝑎𝑢𝑙𝑡 ). Crucially, as shown in Fig. 1(c),
the execution time of foo with frequency 𝑓1 is higher compared to
its execution time with frequency 𝑓2. Therefore, even though foo
is a constant-cycle workload implementation, its execution time
becomes data-dependent due to such frequency throttling activ-
ity. This forms a new type of side-channel information leakage
source in modern processors, which we refer to as the frequency
throttling side-channel.

To visually appreciate the primitive, we design and run a proof-
of-concept (PoC) on an Intel Sky Lake system, plotted in Figure 2.
The function foo we use is composed of 2.8 billion IMUL instructions,
which is a cycle-constant instruction. Each IMUL instruction has
one operand fixed and the other operand set to either 𝑑𝑎𝑡𝑎1 = 0𝑥0
or 𝑑𝑎𝑡𝑎2 = 0𝑥𝐴𝐴..𝐴𝐴. In the first run, we configure reactive limits
to high values that will not be reached, to prevent throttling from
happening, and then execute foo with 𝑑𝑎𝑡𝑎1 and 𝑑𝑎𝑡𝑎2, measuring
aggregated package energy consumption1 and time elapsed for foo.
After repeating 100 times, we plot histograms of the average power
consumption (calculated from energy dividing by time) and the
time elapsed in Figure 2 (a), respectively. As can be observed, the
0𝑥𝐴𝐴 case consumes more power than the 0𝑥00 case and the time
it takes to execute foo for the two operands is identical. The second
run duplicates the first run, except for reducing Power Limit 1 (PL1)
to 8𝑊 and corresponding 𝑃𝐿1 𝜏 to 1𝑠. With this setting, PL1 is hit,
and frequency throttling is triggered. As can be seen from Figure 2
(b), power consumption distributions with different data become
indistinguishable and both are capped at 8𝑊 , which is the power
limit. Critically, foo now takes a longer time to execute with 0𝑥𝐴𝐴
compared to 0𝑥00, while both are slower than the case without
throttling. The results confirm that reactive limit induced throttling
converts a power side-channel to a timing side-channel.

3.1.2 Correlation Power Throttling Analysis (CPTA). An attacker
can apply a statistical measure similar to the one shown in equa-
tion (2) to exploit the data-dependent throttling behavior of the
system during the execution of a victim application. We dub this
Correlation Power Throttling Analysis, or CPTA. The attacker corre-
lates the actual 𝑃𝐿-induced execution times 𝑇𝛿 of the victim appli-
cation from the collected telemetry traces with the corresponding
hypothetical execution time values 𝑇ℎ for different key guesses
using the following measure:

𝛾𝑘 =

𝑐𝑜𝑣 (𝑇𝛿,𝑇 𝑘
ℎ )
𝜎𝑇 𝑘
𝜎𝑇𝛿

ℎ

(3)

1As a proof-of-concept to show power differences, this system did not apply Intel’s
Platypus mitigation.

Frequency Throttling Side-Channel Attack

xxx, xxx, xxx

Figure 1: Conversion of power side-channel to timing side-channel leakage by reactive limit-induced throttling.

(TEE), such as Intel SGX [17, 30] or AMD SEV [35, 45, 53]. Such
TEEs help protect secret information of the victim application
from being directly accessed by even privileged software. In or-
der to enable higher throttling activity during the execution of
code residing in a TEE, the attacker can set a lower value of
electrical or thermal limit(s) by configuring the corresponding
interfaces, such as model-specific registers (MSRs).

• Attack Scenario 2: The attacker is a user-space attacker with
Ring 3 privilege and the victim is another application or the
kernel. Unlike the previous scenario, the attacker does not have
the privilege to alter the values of the default reactive limits. A
Ring 3 attacker instead may execute a stressor code in parallel to
the victim code to boost the system power consumption beyond
the default limits, such that throttling activity is triggered.

In addition, we assume that the victim code under consideration is
implemented using the constant cycle coding principles highlighted
in section 2.3. In order to attack such a workload, an attacker utilizes
the reactive limit-induced throttling (see section 3.1.1) to make the
execution time of the code vary for different known data inputs.
The main objective of the attacker (for both of the above attack
scenarios) is to deduce the targeted secret information of victim
code by correlating the secret data-dependent computations with
the collected execution time of the code for different data inputs.
Note that, in case of a user-space attacker (Attack Scenario 2), the
additional noise introduced by the stressor code will degrade the
signal-to-noise ratio (SNR) of the collected timing side-channel
traces. However, if sufficiently large number of traces are collected
to perform statistical analysis (see section 3.1.2), then eventually
the Ring 3 attacker will succeed to retrieve the targeted secret of
the victim code.

3.2.2 Attack Methodology. Fig. 3 presents an overview of the
throttling side-channel attack against a constant-cycle implementa-
tion of victim workload. Such an attack consists of the following
three phases:
• Offline Phase: The attacker profiles a victim-like workload with
a known asset to either configure the related power management
settings (Ring 0 attacker) or identify a suitable stressor code (Ring

Figure 2: Average power consumption and time elapsed of
the same IMUL workload with different operands (a) when
throttling is not triggered, and (b) when there is reactive
limit induced throttling.

ℎ

, and 𝜎𝑇 𝑘

where, 𝛾𝑘 , 𝜎𝑇𝛿
, represent the Pearson’s correlation co-
efficient for key guess 𝑘, the standard deviation of the actual PL-
induced execution times 𝑇𝛿 , and the standard deviation of the hy-
pothetical execution time values 𝑇 𝑘
for key guess 𝑘, respectively.
ℎ
Note that such hypothetical execution time values can be modelled
similar to the hypothetical power models (see equation (2)) using
standard Hamming weight (HW) or Hamming distance (HD) mod-
els. This is because the execution time variations due to throttling
arises due to the proportional variations in the power consumption
values.

3.2 Overview of Frequency Throttling

Side-Channel Attack

3.2.1 Threat Model. We assume the following attack scenarios
for an adversary exploiting a frequency throttling side-channel
against a victim workload across security boundaries.
• Attack Scenario 1: The attacker is a privileged software at-
tacker such as kernel-space software or hypervisor. The victim
workload is executed inside a Trusted Execution Environment

xxx, xxx, xxx

Chen Liu†, Abhishek Chakraborty†, Nikhil Chawla†, Neer Roggel‡

baseline AES primitive is extended for encrypting large plaintext
blocks using different modes of operation such as ECB, CBC, CFB,
OFB, CTR, etc. Optimized implementations of such different AES
modes are available as part of Intel’s IPP Crypto library [32]. In
this work, we consider the AES-128 primitive to demonstrate its
vulnerability to a frequency throttling side-channel attack.

4.1.2 AES-NI-Based AES Implementation. AES-NI is an instruc-
tion set which improves the AES implementation by accelerat-
ing its complex performance-intensive steps using dedicated hard-
ware [23]. In addition to providing enhanced performance com-
pared to software-based AES code, AES-NI instructions also provide
improved security against side-channel attacks due to their con-
stant cycle implementations. AES-NI instructions are supported by
x86 processors of major vendors, including Intel and AMD.

The AESENC instruction within this set performs a single round of
encryption comprising of four operations – ShiftRows, SubBytes,
MixColumns and AddRoundKey. The AESENCLAST instruction per-
forms the last round of encryption which excludes the MixColumn
operation. Similar to encryption, the set also contains instructions
(AESDEC and AESDECLAST) to perform decryption in a constant cy-
cle manner. In this work, we demonstrate the applicability of our
proposed throttling side-channel attack against AES by considering
the encryption implementation as shown in Algorithm 2. As per the
implementation, register %xmm12 initially stores the plaintext while
registers %xmm0,%xmm1...%xmm10 store the individual round keys
𝑘0, 𝑘1, ..., 𝑘10 (after KeyExpansion). At the end of the encryption
(after AESENCLAST instruction), the ciphertext is stored in %xmm12.

Algorithm 2 AES-NI-based AES-128 Encryption (AT&T syntax)
pxor %xmm0, %xmm12 /*Initial AddRoundKey using 𝑘0*/
aesenc %xmm1, %xmm12
aesenc %xmm2, %xmm12
aesenc %xmm3, %xmm12
aesenc %xmm4, %xmm12
aesenc %xmm5, %xmm12
aesenc %xmm6, %xmm12
aesenc %xmm7, %xmm12
aesenc %xmm8, %xmm12
aesenc %xmm9, %xmm12
aesenclast %xmm10, %xmm12 /*Last Round using 𝑘10*/

4.2 Attack Methodology Details
As outlined in section 3.2.2, the throttling side-channel attack against
a victim workload comprises three distinct phases: the offline, the
online, and the analysis phases. Next, we present the details of each
of these phases as adopted in our case study, using power limit
RAPL as an example.

4.2.1 Offline phase. During the offline phase, the privileged
software attacker first profiles the AES-NI-based victim workload
(see Algorithm 2) to estimate 𝑃, which is the power consumption of
the victim workload. Then, in order to trigger throttling activity, the
attacker adjusts the system’s power limit value 𝑃𝐿 such that 𝑃 > 𝑃𝐿.
As per Algorithm 1, such an adjustment will lead to a change in
𝑃-𝑆𝑡𝑎𝑡𝑒 that satisfies the available power budget. In order to ensure

Figure 3: Exploitation of frequency throttling side-channel
information leakage from a victim code.

3 attacker) such that the victim workload execution will result
in triggering of the system’s reactive limits.

• Online Phase: The attacker provides different data inputs to
the victim code which in turn performs one or more secret asset-
dependent computations. The attacker also runs a monitor pro-
gram in parallel to collect the execution time of the victim code
for the various different data inputs. If the victim workload exe-
cution leads to system throttling activity, such execution time
values will exhibit notable variance.

• Analysis Phase: The attacker applies analysis methods (such as
the CPTA technique, see section 3.1.2) on the collected execution
time values, to deduce the targeted secret asset of the victim code.
In summary, the above methodology of performing throttling side-
channel leakage analysis not only allows an attacker to bypass the
security boundary against the victim code, but also enables the
attacker to violate the data-invariant execution time guarantees as
provided by constant-cycle coding principles.

4 CASE STUDY: ATTACK AGAINST AES

ENCRYPTION

In this section, we consider a victim workload comprising an AES-
NI-based implementation of AES-128 as a case study to illustrate
our proposed throttling side-channel attack. Also, we assume the
threat model of Attack Scenario 1 as described in section 3.2.1. In
order to assess the side-channel leakage due to throttling activity,
we use statistical analysis methods derived from Test Vector Leak-
age Assessment (TVLA) [21, 54] and correlation-based analysis (see
section 3.1.2).

4.1 Victim Workload

4.1.1 AES-128 Algorithm. AES is a block cipher established by
NIST in 2001 [48]. The algorithm encrypts a fixed size plaintext
block of 128-bit using key-size of 128, 192, or 256 bits. The en-
cryption is performed for 10, 12, and 14 rounds for 128, 192, or
256 bits key sizes respectively and the output is a 128-bit cipher-
text. The first step in the algorithm is to derive individual round
keys using the KeyExpansion procedure [23]. This is followed by
the Initial AddRoundKey operation, which computes the bitwise
XOR between the plaintext and the round key 𝑘0. Each subsequent
round (except the last round) is composed of four major opera-
tions being performed in succession on the intermediate states:
SubBytes, ShiftRows, MixColumns, and AddRoundKey. The final
round is composed of all the operations except MixColumns. The

Frequency Throttling Side-Channel Attack

xxx, xxx, xxx

that there is data-dependent frequency throttling activity, the value
of the reactive limit 𝑃𝐿 should be carefully adjusted : setting the 𝑃𝐿
value too high will not satisfy the requirement of 𝑃 > 𝑃𝐿 whereas
setting the 𝑃𝐿 value too low will cause the system to execute in a
constant low frequency which corresponds to the highest 𝑃-𝑆𝑡𝑎𝑡𝑒
configuration.

4.2.2 Online phase. During the online phase, the attacker inputs
plaintext to the victim workload (AES encryption) and obtains the
corresponding ciphertext as output. Note that due to PL-induced
throttling activity, different plaintexts will have different processing
times which correspond to the side-channel traces. During the 𝑖𝑡ℎ
trace collection, the attacker first records the starting time stamp
1 ) just before sending the 𝑖𝑡ℎ plaintext to the victim
counter value (𝑇 𝑖
workload and subsequently, also records the end time stamp counter
value (𝑇 𝑖
2 ) just after receiving the 𝑖𝑡ℎ ciphertext. Then, the attacker
calculates the corresponding execution time 𝑇 𝑖
by calculating the
𝛿
difference between the time stamp counter values, i.e., 𝑇 𝑖
2 −𝑇 𝑖
𝛿 = 𝑇 𝑖
1 .
On most of the modern CPUs, incrementing of the time stamp
counter is frequency-invariant so the 𝑇𝛿 captures wall clock time of
the victim’s execution time and will not be impacted by frequency
throttling [7, 31].
Techniques to reduce Minimum Time to Disclosure: We de-
fine 𝑀𝑖𝑛𝑖𝑚𝑢𝑚 𝑇 𝑖𝑚𝑒 𝑡𝑜 𝐷𝑖𝑠𝑐𝑙𝑜𝑠𝑢𝑟𝑒 (𝑀𝑇 𝐷) as the minimum time
spent to recover the secret information by collecting side-channel
traces. One approach to reduce MTD is increasing Signal-to-Noise
(SNR) per trace [42]. We define 𝑃𝑣 as the average power consump-
tion of the victim workload during 𝑇𝛿 , where 𝑇𝛿 is the execution
time of the victim within 𝜏. The average power consumption of
the rest of the system is defined as 𝑃𝑛. Then, the running average
power consumption during 𝜏 would be 𝑃 =
. We can
represent the percentage of difference between 𝑃 and 𝑃𝑣 as follows:

𝑃𝑣 × 𝑇𝛿 +𝑃𝑛 × 𝜏
𝜏

𝑃 − 𝑃𝑣
𝑃𝑣

=

𝑃𝑣 × 𝑇𝛿 +𝑃𝑛 × 𝜏
𝜏

− 𝑃𝑣

𝑃𝑣

𝑇𝛿 − 𝜏
𝜏

=

+

𝑃𝑛
𝑃𝑣

(4)

A better fitting of 𝑃𝑣 with 𝑃 reduces the above percentage difference
to about 0 and thus, diminishing the noise contributing factors (or in
other words, improving the SNR). In our experiments, we adopted
multiple techniques to achieve this:
• The first technique is to repeatedly execute the victim workload
when 𝑇𝛿 is shorter than 𝜏. In case of the AES-NI workload, the
attacker may send 𝑁 blocks of the same plaintext for encryption
and measure the aggregated execution time as 𝑇𝛿 = 𝑁 ∗ 𝑇𝑏 ,
where 𝑇𝑏 corresponds to the time taken to encrypt one plaintext
block. Note that 𝑇𝑏 is typically in the order of tens of 𝑛𝑠 which
is much shorter compared to the reactive limit time window 𝜏
(which ranges from a few 𝑚𝑠 to multiple 𝑠). However, by selecting
a sufficiently large value of 𝑁 , the attacker can ensure 𝑇𝛿 is
approximately equal to 𝜏.

• The second technique is to execute multiple instances of the
victim workload simultaneously across multiple cores, which
results in an increase of its average power consumption 𝑃𝑣, thus
reducing the factor 𝑃𝑛
in equation (4).
𝑃𝑣

Note that in order to further reduce the 𝑀𝑇 𝐷, the attacker could
select the system reactive limit having the lowest possible config-
urable value of 𝜏 to trigger throttling activity during execution of

the victim workload. This is because a shorter 𝜏 implies a smaller
value of 𝑁 is required to ensure 𝑇𝛿 is approximately equal to 𝜏.
This in turn implies faster trace collection in the online phase, thus
reducing the 𝑀𝑇 𝐷 for the attack.

4.2.3 Analysis phase. We utilize two statistical techniques to
analyze potential side-channel information leakage arising from
throttling side-channel activity: (i) First, in order to ascertain if
different data exhibit different PL-induced throttling behavior, we
apply TVLA to the corresponding timing traces. (ii) Second, de-
pending upon the positive outcome of the TVLA, we perform a
CPTA attack as described in this section, in order to determine if
the targeted AES encryption key can be recovered by analyzing the
collected timing side-channel traces. Next, we present the details
of these statistical techniques as adopted in our experiments.
TVLA: TVLA methodology utilizes t-scores generated from Welch’s
t-test to assess potential side-channel leakage in cryptographic im-
plementations [20]. In a Welch’s t-test, two datasets A and B defined
by a statistical measure.t-score is computed using 𝜇1 and 𝜇2 as their
sample mean and 𝑠2
2 as their sample variance, shown in equation
(5).

1, 𝑠2

𝑡-𝑠𝑐𝑜𝑟𝑒 =

𝜇1 − 𝜇2

√︂ 𝑠2
1
𝑁1

𝑠2
2
𝑁2

+

(5)

where, 𝑁1 and 𝑁2 are a number of samples in dataset A and B
respectively. The null hypothesis of t-test is that the samples from
these two sets are drawn from the same distribution, and therefore
not distinguishable. A |t-score| > 4.5 rejects the null hypothesis with
99.999% confidence, indicating the two datasets are statistically dis-
tinguishable [52]. In a general TVLA test, two sets of side-channel
traces are collected, during encryption of a “Fixed” and a “Random”
plaintext with the same key and a t-score is computed for these
two sets of traces [20].

In this work, we assess the throttling side-channel leakage of
a victim workload (AES-NI-based AES implementation) using the
above mentioned TVLA methodology. We applied the TVLA test
on the collected timing traces corresponding to encryption of three
different sets of plaintexts ( 𝐴𝑙𝑙_𝑜𝑛𝑒, 𝐴𝑙𝑙_𝑧𝑒𝑟𝑜 and 𝑅𝑎𝑛𝑑𝑜𝑚 ). The
configurations of different TVLA tests are as follows:
• TVLA Test 1: Dataset A (𝑇 𝐴𝑙𝑙_𝑧𝑒𝑟𝑜

) comprises of timing traces

𝛿
for encrypting all zero plaintext and dataset B (𝑇 𝐴𝑙𝑙_𝑜𝑛𝑒
prises of timing traces for encrypting all one plaintext.

) com-

𝛿

• TVLA Test 2: Dataset A (𝑇 𝐴𝑙𝑙_𝑧𝑒𝑟𝑜

𝛿
for encrypting all zero plaintext and dataset B (𝑇 𝑅𝑎𝑛𝑑𝑜𝑚
prises of timing traces for encrypting random plaintexts.

𝛿

) comprises of timing traces

) com-

• TVLA Test 3: Dataset A (𝑇 𝐴𝑙𝑙_𝑜𝑛𝑒

𝛿
encrypting all one plaintext and dataset B (𝑇 𝑅𝑎𝑛𝑑𝑜𝑚
of timing traces for encrypting random plaintexts.

𝛿

) comprises of timing traces for

) comprises

CPTA Attack: In order to perform a CPTA attack, the attacker
feeds randomly generated plaintexts to the victim workload and
collects PL-induced timing traces 𝑇𝛿 . The correlation measure 𝛾
(see equation (3)) detects if there is any dependency between 𝑇𝛿 and
the hypothetical execution time values 𝑇ℎ to deduce a secret key. In
a conventional CPA attack, measured power traces are correlated

xxx, xxx, xxx

Chen Liu†, Abhishek Chakraborty†, Nikhil Chawla†, Neer Roggel‡

with a hypothetical power model based on either HW or HD of tar-
geted intermediate values [14]. Since frequency throttling converts
data-dependent correlation in power to execution time, HW/HD
models are suitable for computing the hypothetical execution time
values.

Points of Attack: The attacker targets the following two opera-

tions of the victim workload implementation (see Algorithm 2).
• Initial AddRoundKey (PXOR) to find 𝑘0 using HW model.
• Last round (AESENCLAST) to find 𝑘10 using HW/HD models.
Once all the bytes of any round key are recovered, InvKeyExpansion
procedure can be used to derive the secret AES key [23]. Note that
the intermediate AES rounds are typically not considered as attack
points because in those cases the corresponding hypothetical exe-
cution time values become a function of multiple round keys, thus
substantially increasing attack complexity.

Algorithm 3 AESENCLAST Instruction Code Sequence

/* %xmm10 contains 𝑘10 */

1: aesenclast %xmm10 %xmm12
2: 𝑇𝑚𝑝 ← %𝑥𝑚𝑚12
3: 𝑅𝑜𝑢𝑛𝑑𝐾𝑒𝑦 ← %𝑥𝑚𝑚10
4: 𝑇𝑚𝑝 ← 𝑆ℎ𝑖 𝑓 𝑡𝑅𝑜𝑤𝑠 (𝑇𝑚𝑝)
5: 𝑇𝑚𝑝 ← 𝑆𝑢𝑏𝐵𝑦𝑡𝑒𝑠 (𝑇𝑚𝑝)
6: %𝑥𝑚𝑚12 ← 𝑇𝑚𝑝 ⊕ 𝑅𝑜𝑢𝑛𝑑𝐾𝑒𝑦

Execution Time Estimates: To recover 𝑘0, the hypothetical execu-
tion time values can be modeled using HW of the initial AddRoundKey
output as shown in the following equation.

𝑇 𝑘′
ℎ = 𝐻𝑊 (𝑝0 ⊕ 𝑘 ′

0,0)

(6)

where, 𝑇 𝑘′
ℎ
key guess 𝑘 ′
represents the first byte of the plaintext.

represents the hypothetical execution time values for
0,0 (corresponding to the first byte of key 𝑘0) and 𝑝0

In order to understand the execution time value estimates of 𝑘10,
let us first look into the details of the AESENCLAST instruction as
highlighted in Algorithm 3. Note that the input to the last round
(line 1) is stored in register %xmm12 and in the end the output (ci-
phertext 𝑐) is updated in the same register (line 6). Now, the attacker
can model the HW-based execution time estimates targeting 𝑘10 as
follows.

𝑇 𝑘′
ℎ = 𝐻𝑊 (𝑆ℎ𝑖 𝑓 𝑡𝑅𝑜𝑤 −1 (𝑆𝑢𝑏𝐵𝑦𝑡𝑒𝑠−1 (𝑐0 ⊕ 𝑘 ′
where, 𝑇 𝑘′
represents the hypothetical execution time values for
ℎ
key guess 𝑘 ′
10,0 and 𝑐0 represents the first byte of the ciphertext.
Similarly, the attacker can model the HD-based execution time
estimates targeting 𝑘10 as follows.

10,0)))

(7)

𝑇 𝑘′
ℎ = 𝐻𝐷 (𝑆ℎ𝑖 𝑓 𝑡𝑅𝑜𝑤 −1 (𝑆𝑢𝑏𝐵𝑦𝑡𝑒𝑠−1 (𝑐0 ⊕ 𝑘 ′

10,0)), 𝑐0)

(8)

Attack Outcome: The CPTA attack utilizes the above mentioned
execution time estimates 𝑇 𝑘′
along with the corresponding actual
ℎ
execution time 𝑇𝛿 measurements for several plaintexts to compute
the correlation measure 𝛾 as outlined in equation (3). Subsequently,
for each 𝑗𝑡ℎ byte of round key 𝑘𝑖 (denoted as 𝑘𝑖,𝑗 ), the ranks of all

possible key guesses 𝑟𝑎𝑛𝑘 (𝑘 ′
their correlation measures 𝛾𝑘′

𝑖,𝑗 ) are sorted in descending order of
𝑖,𝑗 as follows.

𝑟𝑎𝑛𝑘 (𝑘 ′

𝑖,𝑗 ) = 𝑎𝑟𝑔𝑠𝑜𝑟𝑡 (𝛾𝑘′
𝑖,𝑗 )

(9)

In this work, we define a new metric called Guessing Complexity
(𝐺𝐶) to evaluate the success of a CPTA attack. The metric 𝐺𝐶 is
a modified version of the standard Guessing Entropy metric [50].
For the 𝑖𝑡ℎ round key 𝑘𝑖 , 𝐺𝐶𝑖 sums the ranks (logarithmically) of
correct key byte guesses as shown in the following equation.

16
∑︁

𝐺𝐶𝑖 =

𝑙𝑜𝑔2 [𝑟𝑎𝑛𝑘 (𝑘𝑐𝑜𝑟𝑟𝑒𝑐𝑡 _𝑘𝑒𝑦
𝑖,𝑗

)]

(10)

𝑖,𝑗

𝑖,𝑗 = 𝑘𝑐𝑜𝑟𝑟𝑒𝑐𝑡 _𝑘𝑒𝑦

) is the rank corresponding to the correct

𝑗=1
where, 𝑟𝑎𝑛𝑘 (𝑘𝑐𝑜𝑟𝑟𝑒𝑐𝑡 _𝑘𝑒𝑦
key byte guess (𝑘 ′
), 𝑗 ∈ [16]. The convergence of
the CPTA attack is indicated by the reduction in 𝐺𝐶 values with
the increasing number of timing traces. A value of 𝐺𝐶 = 0 implies
all key bytes have been recovered. In practice, a successful CPTA
attack should result in a 𝐺𝐶 value lower than a pre-defined thresh-
old which allows the recovery of most key bytes with reasonable
computational complexity.

𝑖,𝑗

4.3 Evaluation
In this section, we first report the experimental outcomes of TVLA
tests to highlight potential side-channel information leakage arising
from frequency throttling activity. Then, we present the results of
a CPTA attack to demonstrate how an attacker can successfully
recover the secret key by collecting timing side-channel traces
of the AES-NI based AES-128 implementation. Our experiments
mainly focus on Intel systems, where we consider both power limit-
induced and current-limit induced frequency throttling activity
during trace collection. Additional experimental results on an AMD
processor are also provided in Appendix A.

4.3.1 Experimental Setup. We developed a Proof-of-Concept
(PoC) code to implement the AES encryption process outlined in
Algorithm 2. In our implementation, multiple instances of the en-
cryption (using the same plaintext and key) are executed in parallel
across cores for several number of iterations to boost the SNR of the
collected timing trace. The number of iterations were calibrated for
different systems such that every trace spans approximately 45𝑚𝑠.
In our trace dataset, a single trace corresponds to the aggregated
execution time of the victim workload (corresponding to the cali-
brated iteration count) measured using RDTSC. All the experiments
are performed in Ubuntu 20.04.

For experimental evaluations, we considered three Intel systems:
E3-1230V5 (Sky Lake), i7-1185G7 (Tiger Lake), and Xeon Gold 6326
(Ice Lake). Table 1 lists the details of different systems along with
their corresponding power limit (PL2) configurations as adjusted in
the offline phase to introduce frequency throttling activity during
workload execution. The reason behind selection of PL2 is related to
its lowest possible configuration of running average time window
of 𝜏=2ms among all the power limits available in an Intel system.
Note that the lower the 𝜏 value, the higher the granularity of fre-
quency throttling activity performed by the power management

Frequency Throttling Side-Channel Attack

xxx, xxx, xxx

Table 1: Information and configurations of the systems under test

Processor Number Code name
Sky Lake
Tiger Lake
Ice Lake

E3-1230V5
i7-1185G7
Xeon Gold 6326

# of physical cores Max Turbo frequency

4
2
8/socket

3.8 GHz
4.1 GHz
3.5 GHz

SMT
Disabled
Disabled
Disabled

PL2 configuration
10W
8W
50W

PL2 𝜏
2ms
2ms
2ms

Table 2: pairwise t-score (absolute value) among 𝐴𝑙𝑙_𝑧𝑒𝑟𝑜, 𝐴𝑙𝑙_𝑜𝑛𝑒, and 𝑅𝑎𝑛𝑑𝑜𝑚 traces, repeated on Sky Lake, Tiger Lake, and
Ice Lake. T-score greater than 4.5 are marked in red and indicates the set of data are statistically distinguishable.

Sky Lake

Tiger Lake
All_zero_2 All_one_2 Random_2 All_zero_2 All_one_2 Random_2 All_zero_2 All_one_2 Random_2
1.02
10.57
3.02
38.42
9.23
24.07

0.45
19.74
11.27

41.02
2.38
14.28

0.23
12.58
1.32

19.82
0.53
7.72

26.20
11.79
2.36

12.51
7.57
0.68

5.32
8.08
3.84

Ice Lake

All_zero_1
All_one_1
Random_1

Table 3: Converged Guessing Complexity (𝐺𝐶) with 8M
traces. Lower 𝐺𝐶 implies more key bytes are recovered.

Sky Lake Tiger Lake
17.5
Round0-HW
85.7
Round10-HW
0
Round10-HD
Round10-HW+HD 0

27.5
73.3
27.3
21.4

Ice Lake
2.6
86.0
81.2
72.7

4.3.2 T-test Results. For every system under test, following the
TVLA methodology described in 4.2.3, we collected 10, 000 timing
traces of the victim workload corresponding to the encryption of
each of the plaintext sets ( 𝐴𝑙𝑙_𝑜𝑛𝑒_1, 𝐴𝑙𝑙_𝑧𝑒𝑟𝑜_1 and 𝑅𝑎𝑛𝑑𝑜𝑚_1).
We repeated the trace collection process with the same plaintext sets
(𝐴𝑙𝑙_𝑜𝑛𝑒_2, 𝐴𝑙𝑙_𝑧𝑒𝑟𝑜_2 and 𝑅𝑎𝑛𝑑𝑜𝑚_2) in order to ascertain that
there are no false positives in the TVLA test outcomes due to issues
associated with data collection (e.g., inconsistent system behaviors
or settings). Subsequently, we first removed outlier traces followed
by calculation of Welch’s 𝑡-𝑠𝑐𝑜𝑟𝑒 measure using the remaining trace
sets which correspond to every possible pairs of plaintext sets. The
results of this experiment are presented in Table 2, where the 𝑡-
𝑠𝑐𝑜𝑟𝑒 values greater than 4.5 are marked in red to indicate that the
pairs of datasets are statistically distinguishable. It can be observed
that across all the three systems, 𝑡-𝑠𝑐𝑜𝑟𝑒 values between trace sets
corresponding to different plaintext sets are higher than 4.5 (the
only exception being the case 𝑅𝑎𝑛𝑑𝑜𝑚1 vs. 𝐴𝑙𝑙_𝑧𝑒𝑟𝑜_2 in Tiger Lake
system) while the 𝑡-𝑠𝑐𝑜𝑟𝑒 values between trace sets corresponding
to same plaintext sets are lower than 4.5. This signifies that due to
power limit-induced throttling activity, the CPU frequency changes
in a data-dependent manner, which leads even a constant-cycle
victim code implementation to exhibit data-dependent runtime
differences.

4.3.3 CPTA Attack Results with Power Limit. With the TVLA
tests exhibiting positive signs of potential side-channel information
leakage, we further investigated the applicability of a CPTA attack
on the power limit-induced timing traces, to recover the secret AES
key. On each of the systems, we collected 8 million timing traces of
the PoC code (with a fixed key) by providing randomly generated
plaintexts. The trace collection process took about 100 hours on
average across different systems. After the trace collection phase,

Figure 4: Guessing Complexity trend with different amount
of traces on (a) Sky Lake, (b) Tiger Lake, and (c) Ice Lake sys-
tems, with power limit-induced frequency throttling.

architecture (see Algorithm 1 for details). Also, note that since Xeon
Gold 6326 is a 2-socket server system with power limits being de-
fined per socket, we run victim workload on socket 0 by adjusting
only PL2 corresponding to socket 0.

xxx, xxx, xxx

Chen Liu†, Abhishek Chakraborty†, Nikhil Chawla†, Neer Roggel‡

we computed the median 𝜇 of the collected traces and discarded
the outliers from the dataset by removing the traces which do not
belong to the range of [0.95𝜇, 1.05𝜇]. Subsequently, we applied the
CPTA attack on the filtered trace dataset, targeting the AES rounds
keys 𝑘0 and 𝑘10. The execution time estimates of the AES-128 PoC
code as used in our analysis include the following:

• Round0-HW: HW of AddRoundKey output, see equation (6).
• Round10-HW:HW of the last round, see equation (7).
• Round10-HD: HD of the last round, see equation (8).
• Round10-HW+HD: Sum of equations (7) and (8).

Also, in our experiments we set 𝐺𝐶0=𝐺𝐶10=𝐺𝐶=80 as the pre-
defined threshold for both round keys 𝑘0 and 𝑘10 to determine
the success of the CPTA attack. Note that 𝐺𝐶=80 signifies that
the computational complexity of a brute force attack to find the
round key is reduced to 280. In Fig. 4, we present the GC trends
(corresponding to different execution time estimate models) ver-
sus the number of timing traces considered for the CPTA attack
across multiple systems. Based on the data, we make the following
observations:

• The general trend is that GC converges gradually when in-
creasing number of traces are used for analysis. This is because a
larger number of traces helps to reduce the effect of noise in the
collected traces. Such GC trends highlight the fact that all the
execution time estimate models considered correlate with the
actual execution times of the PoC code. Also, it can be observed
that in all cases, GC values start from somewhere around 112.
This is because the expected value of the initial rank of correct
key byte (without parsing any side-channel traces) is 128 among
the 256 possible key byte guesses. Therefore, the expected value
of initial GC value is 𝐸 (𝐺𝐶) = (cid:205)16

𝑖=1 𝑙𝑜𝑔2 (128) = 112.

• Round0-HW model appears to be effective on all the three
systems: GC converges to 17.5 on Sky Lake, 27.5 on Tiger Lake,
and 2.6 on Ice Lake. Especially, on Ice Lake, with this execution
time estimate model, we successfully recover 14 out of the 16
bytes of the correct key. The ranks of the remaining two key
bytes are 2 and 3.

• Round10-HW model converges the slowest among all the mod-
els tested. On both Sky Lake and Ice Lake systems, even after
analyzing with 8M traces the GC values remain above the con-
sidered threshold of 80, signifying that the CPTA attack was
unsuccessful in these cases. The lowest GC value obtained was
73.3 on Tiger Lake system.

• Round10-HD model shows distinctly different behaviors on
different systems. On Sky Lake system, for example, GC con-
verges to 0 (all key bytes recovered) with less than 2M traces.
Also, on Tiger Lake system, for this model GC converges to 27.3,
similar to Round0-HW model. But in case of Ice Lake system,
for this model GC value reduces to only 81.2 which is above the
considered threshold.

• Round10-HW+HD model results in consistently lower GC
values compared to the Round10-HW model across all the three
systems. However, compared to the Round10-HD model, for
this model the GC value converges slower on Sky Lake system
whereas the GC values converge faster on Tiger Lake and Ice
Lake systems.

Figure 5: Guessing Complexity trend with different amount
of traces on Tiger Lake, with current limit-induced fre-
quency throttling.

Note that for a given execution time estimate model, the differ-
ence in behavior of GC trends on different systems is likely due
to variations in the underlying hardware micro-architecture de-
signs and the fabrication technologies used. Table 3 summarizes the
outcomes of the CPTA attack corresponding to different execution
time estimate models across systems. These results demonstrate the
fact that power-limit induced frequency throttling activity can be
successfully leveraged by an attacker to extract secret information
from cryptographic workloads.

4.3.4 CPTA Attack Results with Current Limit. We also repeated
the CPTA test on the Tiger Lake system with VR-TDC limit set to 7
Amperes to trigger frequency throttling. All other configurations
were kept the same as used for the power-limit induced frequency
throttling experiments in the previous subsection. The GC trends
for different execution time estimate models are shown in Figure 5.
Similar to the power-limit experiments, the GC value corresponding
to the Round10-HW model converges the slowest amongst all the
models tested. The GC values for both Round0-HW and Round10-
HD models converge to around 20 after analyzing with 8M traces.
The GC value corresponding to Round10-HW+HD model converges
to the lowest value (around 10) for the CPTA attack with current
limit. These observations confirm the fact that VR-TDC limit can
also be leveraged by an attacker to mount the frequency throttling
side-channel attack.

5 MITIGATION
In this section, we discuss different countermeasures to safeguard
a victim workload from being susceptible to frequency throttling
side-channel attacks. Before going to the details of the mitigation
strategies, we first summarize the conditions that must be satisfied
to mount such an attack.

• Condition 1 (Secret Dependency): The victim code processes
a secret asset that is vulnerable to a power side-channel attack.
This requires (i) the victim software implementation to be vul-
nerable to traditional physical side-channel attacks and (ii) the
underlying hardware system to exhibit variation in power con-
sumption profiles for processing different data.

• Condition 2 (Controller Actuation): One of the reactive lim-
its of the system is being hit during victim code execution. This

Frequency Throttling Side-Channel Attack

xxx, xxx, xxx

will cause the power management architecture to trigger fre-
quency throttling activity based on the available power budget
(see Algorithm 1 for details).

• Condition 3 (Observability): The attacker can monitor the ex-
ecution time (wall clock time) of the victim code with sufficiently
high resolution, or else an equivalent quantity.

In order to thwart side-channel information leakage due to fre-
quency throttling activity, the designer should consider targeting
the above mentioned necessary conditions of the exploit. Next,
we present different potential countermeasures along with their
respective advantages and disadvantages.

5.1 Analysis of Secret Dependency

5.1.1 Necessary conditions of Secret Dependency. Since power
side-channel is the fundamental root cause of power management
throttling side-channel, the necessary conditions for the physical
power side-channel attack also need to be satisfied for throttling
side-channel (except for the physical access capability to measure
power). First, the victim application needs to process a secret asset
(e.g., cryptographic key) with a confidentiality requirement. Second,
power consumption of the underlying hardware processing the
secret is correlated with the asset. Third, the implementation of the
victim application is susceptible to side-channel attack. For example,
the victim application provides the capability for the adversary to
repeatedly initiate cryptographic operations with the same sensitive
key to collect enough data. Also, for block ciphers, the adversary
should have the ability to read input/output or inter-round state of
the block cipher primitives. Please note that the input/output is not
necessarily the plaintext or ciphertext. One example is the counter
(CTR) mode of operation for block ciphers, where the input to the
block cipher is the concatenation of the nonce and counter instead
of a plaintext.

5.1.2 Mitigations. Most of the existing countermeasures against
traditional power side-channel will be as effective against a fre-
quency throttling side-channel. For example, software-based mask-
ing [49] that splits a secret asset into multiple random shares will
randomize the power consumption of the hardware, and will be
useful against a frequency throttling side-channel. There are sev-
eral noteworthy exceptions. For example, shuffling-based counter-
measures that randomize instruction execution order, while being
effective in making trace alignment and identification of points of
interest harder for physical power side-channel attacks, are less
effective in mitigating a frequency throttling side-channel. This
is because reordering instructions at the cycle granularity is less
likely to impact average power consumption during the averaging
time window of milliseconds or longer. Also, since an adversary
does not need to physically access the hardware, any protection
that physically isolates the system will not be sufficient to prevent
a frequency throttling side-channel attack.

For cryptographic applications based on existing cryptographic
libraries, an example of a generic countermeasure against power
side-channel is key refresh. One of the necessary conditions for
power side-channel is amplification, or the ability to repeatedly kick
off cryptographic operations with the same sensitive key to collect
a sufficient amount of traces. If the secret key is refreshed before
enough traces can be collected, it will be harder for the attacker

to fully deduce the secret. One important design factor is the key
refresh frequency, which may be based on timing (e.g., refresh
per several hours) or data volume (e.g., the volume of data being
encrypted with the same key). If the implementer is uncertain of the
threshold to use, the lowest threshold that meets performance and
design requirements should be selected. Naturally, the practicality
of key refresh depends on the specific cryptographic use case (e.g.,
key refresh is typically not applicable to disk encryption).

From a hardware perspective, secret dependency is satisfied for
almost all modern CPUs since power consumption differences due
to circuit switching behavior are an inherent property of CMOS
circuits. Making the entire SoC power-constant would of course
address this condition, but is difficult to achieve. A more feasible
option is making specific security-sensitive hardware components
(e.g., hardware cryptography accelerator) power-constant.

5.2 Analysis of Controller Actuation
This condition allows conversion from power differences to timing
differences during an attack. As described in Algorithm 1, the new
frequency limit after throttling 𝑓𝑚𝑎𝑥 is a function of the power
budget, which is the difference between the power limit 𝑃𝐿 and
the measured average power consumption 𝑃. A mitigation may
target one of the components in this conversion process: the control
algorithm, 𝑃𝐿, or 𝑃.

5.2.1 Mitigations targeting the control algorithm. Since the pur-
pose of reactive limits is to restrict a system from consuming power
or current beyond the limit while maximizing system performance,
a control algorithm is typically designed to select the highest pos-
sible frequency limit that satisfies the reactive limits. A straight-
forward mitigation option to change the control algorithm is to
only allow the system to run at the lowest frequency when reactive
limits are hit. While it prevents data-dependent frequency change,
system performance is severely impacted. Another option is to
fully disable reactive limit based throttling, which is usually not
acceptable, since it is a critical power management feature widely
used. An option to trade-off between security and functionality is
to reduce sensitivity of the control algorithm so switching of the
frequency limit would be less correlated with the input.

5.2.2 Mitigations targeting reactive limits. Similarly, a firmware
or system software may take a straightforward approach to either
configure the limit to a value too high to hit, or keep it very low so
that the system always runs at the lowest frequency. However, these
changes have severe negative impact on performance or functional-
ity. One alternative solution is to randomly "fuzz” the reactive limit.
For example, instead of configuring a static reactive limit to 𝑃𝐿,
firmware or system software may define a range [𝑃𝐿𝐿𝑜𝑤, 𝑃𝐿𝐻𝑖𝑔ℎ],
and randomly select a value in the range, dynamically and rou-
tinely configuring the reactive limit. By doing so, randomness will
be introduced in the power budget, as well as CPU frequency.

As discussed, interfaces (e.g., MSRs) to configure reactive limits, if
accessible, could be utilized by an adversary to reduce the limits and
trigger the throttling side-channel attack. A cloud service provider
(CSP) or system software could prevent these interfaces from being
exposed to untrusted guest VMs or ring-3 software, and be aware
of the risk if the interfaces have to be exposed.

xxx, xxx, xxx

Chen Liu†, Abhishek Chakraborty†, Nikhil Chawla†, Neer Roggel‡

Table 4: Summary of mitigations against the frequency throttling side-channel

Secret Dependency

# Mitigation Target
1
2 Controller Actuation Keep the system at lowest frequency or disable reactive limits
3
4
5
6
7
8 Observability

Mitigation Description
Existing traditional power side-channel mitigations (e.g., masking, key refresh) User App/System SW/HW Vary
Fully
Partially
Partially
Partially
Fully
Partially
Partially

Reduce sensitivity of throttling control algorithm
Add randomness to the reactive limit
Avoiding exposing reactive limit configuration interfaces to untrusted entities
Use modelled power instead of actual power in throttling control algorithm
Add noise to power input of throttling control algorithm
Utilize inherent noise or inject artificial noise to cryptographic operations

System SW/HW
HW
System SW/HW
System SW
HW
HW
User App/System SW

Applicable Layer(s)

Mitigation Effectiveness

Perf./Func. Impact
Vary
High
Medium
Medium
Low
High
Medium
Medium

5.2.3 Mitigations targeting average power. The processor may
decouple the calculated average power consumption from the actual
power consumption. One approach is to utilize modelled power
consumption instead of the actual power reading in the algorithm. If
the model is selected to exclude information of instruction operands,
then the average power will be independent of any secret data
consumed by the victim application. Another approach is for the
processor to "fuzz” the average power consumption by adding noise
to the value before the control algorithm uses it to compute the
power budget. This is equivalent to the idea of fuzzing the reactive
limit, since power budget is the difference between reactive limits
and the average power. Please note that although fuzzing the power
reading will not directly change power consumption, it will alter
𝑓𝑚𝑎𝑥 and indirectly impact power consumption and performance.

5.3 Analysis of Observability
One of the common countermeasures against side-channel attacks
is to jam the channel with noise to prevent the attacker from deduc-
ing the secret. As the side-channel in this attack is frequency and
timing information, noise can be injected into the frequency tran-
sition or timing information. One method is to leverage inherent
noise during cryptographic application calls. As the cryptographic
library provider or cryptographic application provider, one may
restrict the maximal size allowed of processed data per API invoca-
tion, so that more invocations of the API are needed to process the
same amount of data, and larger intrinsic noise will be introduced.
Besides that, a cryptography implementer may proactively inject
random noise to cryptographic operations to increase timing vari-
ation. To implement this countermeasure, the developer may add
dummy instructions that introduce sufficient power or latency vari-
ation. The dummy instructions should be independent of the secret
data used in the cryptographic function. For example, timing varia-
tion can be introduced using a loop of instructions with random
iterations. In addition to that, any power variation induced by the
dummy instructions may also increase the entropy of the frequency
transition. To ensure randomness is introduced for every frequency
transition, it is recommended that some noise is injected during the
time window 𝜏 of the reactive limits that the attacker would target.
One possible way to trade-off security and performance impact
is to combine this scheme with a key refresh countermeasure, to
increase the time needed to perform a successful attack to a key
lifetime that is acceptable.

5.4 Summary of Mitigation Options
A summary of the mitigations is listed in Table 4, categorized based
on the condition to address, the layer(s) to apply, the security effec-
tiveness in mitigating the frequency throttling side-channel, and
the performance or functional impact. As can be seen, options that
fully resolve the security issue (e.g., #2 and #6) bring high perfor-
mance or functional impact, while options that partially reduce
the security risk have low to medium impact. Depending on the
layer in which the mitigation is applied, different options might be
selected. For example, the developer of a user-space cryptography
implementation may consider options #1 and #8, which are the
options available to ring-3 software.

6 FUTURE WORK
This work examines a new source of side-channel information
leakage from a victim workload arising due to the conversion of
data-dependent power consumption to data-dependent execution
time. Future work falls along the following non-orthogonal vectors:

• Other channels: Extending the analysis to other data-dependent
reactive limits, such as thermal limits, not covered by the present
case study. Such channels may yield differing SNR. As a general
rule, internally sampled telemetry tends to increase in fidelity
over time, suggesting future products require extra care.

• Other victims: Extending the analysis to other cryptographic
primitives (e.g., asymmetric primitives such as EcDSA [1]) and
cryptographic applications susceptible to power side channels.
• Using stressor code: This paper focused on reducing reactive
limits as a primary means to trigger frequency throttling. As
stated before, an alternative option is running a stressor work-
load, which should consume high but constant power, to boost
power or current consumption. Investigating this complemen-
tary option is part of future work.

• Improved data analysis methodologies: While TVLA is a
well recognized approach to detecting statistically significant
variation in power traces, other techniques have been proposed
that may serve to refine the work (e.g., NICV [12], HAC [2]). An
investigation of ML-based data analysis methods and comparison
with CPTA may prove fruitful.

• Improved mitigation strategies: The growing intersection be-
tween the fields of security and power management warrants
better trade-offs between security and system power, perfor-
mance and responsiveness—ideally, allowing all goals to be si-
multaneously met. We may consider designs with better power
infrastructure virtualization, isolation or control.

Frequency Throttling Side-Channel Attack

xxx, xxx, xxx

7 CONCLUSION
In this paper, we present a novel frequency throttling side-channel
analysis attack against constant-cycle software cryptographic im-
plementations. The root cause of such a side-channel is a power side-
channel, which is converted to a timing side-channel by the power
management architecture. We demonstrate the threat posed by fre-
quency throttling side-channel attacks by considering a constant-
cycle implementation of AES encryption as a case study. The out-
comes of our experimental evaluations highlight the effectiveness
of frequency throttling side-channel analysis to retrieve the secret
AES key, by applying the CPTA technique on the collected timing
traces. Finally, we present a set of options to thwart such throttling
side-channel analysis attacks, with analysis of pros and cons. These
mitigation options provide insights into the necessary conditions
for throttling side-channel information leakage and how to develop
effective countermeasures.

REFERENCES
[1] Monjur Alam, Baki Yilmaz, Frank Werner, Niels Samwel, Alenka Zajic, Daniel
Genkin, Yuval Yarom, and Milos Prvulovic. 2021. Nonce@Once: A Single-Trace
EM Side Channel Attack on Several Constant-Time Elliptic Curve Implemen-
tations in Mobile Platforms. In 2021 IEEE European Symposium on Security and
Privacy (EuroS P). 507–522. https://doi.org/10.1109/EuroSP51992.2021.00041
[2] Alric Althoff, Jeremy Blackstone, and Ryan Kastner. 2019. Holistic Power Side-
Channel Leakage Assessment: Towards a Robust Multidimensional Metric. In
2019 IEEE/ACM International Conference on Computer-Aided Design (ICCAD). 1–8.
https://doi.org/10.1109/ICCAD45719.2019.8942098

[3] AMD. 2014. Ryzen_Monitor. https://github.com/hattedsquirrel/ryzen_monitor.

(2014). Accessed: 2022-05-01.

[4] AMD. 2018. BIOS and Kernel Developer’s Guide (BKDG) for AMD Family
15h Models 70h-7Fh Processors. https://www.amd.com/system/files/TechDocs/
55072_AMD_Family_15h_Models_70h-7Fh_BKDG.pdf. (2018). Accessed: 2022-
05-01.
[5] AMD. 2022.

https://nvd.nist.gov/vuln/detail/

AMD CVE-2020-12912.

CVE-2020-12912. (2022). Accessed: 2022-04-12.

[6] AMD. 2022. AMD Ryzen Technology: Precision Boost 2 Performance Enhance-
ment. https://www.amd.com/en/support/kb/faq/cpu-pb2. (2022). Accessed:
2022-03-12.

[7] AMD. 2022. AMD uProf User Guide. https://developer.amd.com/wordpress/

media/2013/12/User_Guide.pdf. (2022). Accessed: 2022-4-21.

[8] AMD. 2022. Ryzen Master 2.9 - Reference Guide. https://www.amd.com/system/
files/documents/ryzen-master-quick-reference-guide.pdf. (2022). Accessed:
2022-05-01.

[9] ARM. 2022. ARMv8-A Power Management.

https://developer.arm.com/
documentation/100960/0100/ARMv8-A-Power-management?lang=en. (2022).
Accessed: 2022-04-10.

[10] Karl Johan Åström and Richard M Murray. 2010. Feedback systems. In Feedback

Systems. Princeton university press.

[11] Grant Ayers, Nayana Prasad Nagendra, David I. August, Hyoun Kyu Cho, Svilen
Kanev, Christos Kozyrakis, Trivikram Krishnamurthy, Heiner Litz, Tipp Moseley,
and Parthasarathy Ranganathan. 2019. AsmDB: Understanding and Mitigating
Front-End Stalls in Warehouse-Scale Computers. In International Symposium on
Computer Architecture (ISCA).

[12] Shivam Bhasin, Jean-Luc Danger, Sylvain Guilley, and Zakaria Najm. 2014. NICV:
Normalized inter-class variance for detection of side-channel leakage. In 2014
International Symposium on Electromagnetic Compatibility, Tokyo. 310–313.
[13] W Lloyd Bircher and Lizy K John. 2008. Analysis of dynamic power manage-
ment on multi-core processors. In Proceedings of the 22nd annual international
conference on Supercomputing. 327–338.

[14] Eric Brier, Christophe Clavier, and Francis Olivier. 2004. Correlation Power
Analysis with a Leakage Model. In Cryptographic Hardware and Embedded Sys-
tems - CHES 2004, Marc Joye and Jean-Jacques Quisquater (Eds.). Springer Berlin
Heidelberg, Berlin, Heidelberg, 16–29.

[15] Maxime Colmant, Pascal Felber, Romain Rouvoy, and Lionel Seinturier. 2017.
WattsKit: Software-Defined Power Monitoring of Distributed Systems. 2017
17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing
(CCGRID) (2017), 514–523.

[16] Compaq Computer Corporation and Revision B. 2000. Advanced Configuration

and Power Interface Specification. (2000). http://www.acpi.info/

[17] Victor Costan and Srinivas Devadas. 2016. Intel SGX explained. Cryptology

ePrint Archive (2016).

[18] Guillaume Fieni, Romain Rouvoy, and Lionel Seinturier. 2020. SmartWatts: Self-
Calibrating Software-Defined Power Meter for Containers. 2020 20th IEEE/ACM
International Symposium on Cluster, Cloud and Internet Computing (CCGRID)
(2020), 479–488.

[19] Matteo Maria Fusi. 2016. Information-Leakage Analysis based on Hardware Per-
formance Counters. Master’s thesis. The Polytechnic University of Milan.
[20] Benjamin Jun Gilbert Goodwill, Josh Jaffe, Pankaj Rohatgi, et al. 2011. A testing
methodology for side-channel resistance validation. In NIST non-invasive attack
testing workshop, Vol. 7.

[21] Gilbert Goodwill, Benjamin Jun, Josh Jaffe, and Pankaj Rohatgi. 2011. P.: A
testing methodology for side-channel resistance validation, NIAT. (2011).
[22] Corey Gough, Ian Steiner, and Winston Saunders. 2015. CPU power management.

In Energy Efficient Servers. Springer, 21–70.

[23] Shay Gueron. 2010. Intel® Advanced Encryption Standard (AES) New Instruc-

[24]

[28]

[27]

[25]

tions Set. (2010).
Jawad Haj-Yahya, Avi Mendelson, Yosi Ben-asher, and Anupam Chattopadhyay.
2018. Energy Efficient High Performance Processors Recent Approaches for Designing
Green High Performance Computing. https://doi.org/10.1007/978-981-10-8554-3
J. Haj-Yahya, L. Orosa, J. S. Kim, J. Gomez Luna, A. Yaglikci, M. Alser, I. Puddu,
and O. Mutlu. 2021. IChannels: Exploiting Current Management Mechanisms to
Create Covert Channels in Modern Processors. In 2021 ACM/IEEE 48th Annual In-
ternational Symposium on Computer Architecture (ISCA). IEEE Computer Society,
Los Alamitos, CA, USA, 985–998. https://doi.org/10.1109/ISCA52012.2021.00081
[26] Peter H. Hochschild, Paul Jack Turner, Jeffrey C. Mogul, Rama Krishna Govin-
daraju, Parthasarathy Ranganathan, David E Culler, and Amin Vahdat. 2021.
Cores that don’t count. In Proc. 18th Workshop on Hot Topics in Operating Systems
(HotOS 2021).
Intel. 2022. Guidelines for Mitigating Timing Side Channels Against Cryp-
tographic Implementations.
https://www.intel.com/content/www/us/en/
developer/articles/technical/software-security-guidance/secure-coding/
mitigate-timing-side-channel-crypto-implementation.html. (2022). Accessed:
2022-05-02.
Intel. 2022. Intel CVE-2020-8694. https://www.intel.com/content/www/us/en/
security-center/advisory/intel-sa-00389.html. (2022). Accessed: 2022-04-12.
Intel.
porting.
articles/technical/software-security-guidance/advisory-guidance/
running-average-power-limit-energy-reporting.html. (2022).
2022-04-12.
Intel. 2022. Intel SGX. https://software.intel.com/en-us/sgx. (2022). Accessed:
2022-05-02.
Intel. 2022.
Intel® 64 and IA-32 Architectures Software Developer Manu-
als. https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.
html. (2022). Accessed: 2022-05-02.
Intel. 2022.
//github.com/intel/ipp-crypto. (2022). Accessed: 2022-04-07.
Intel. 2022. Overview of Enhanced Intel SpeedStep® Technology for Intel® Pro-
cessors. https://www.intel.com/content/www/us/en/support/articles/000007073/
processors.html. (2022). Accessed: 2022-04-07.
Intel.
ogy.
software-development-platforms/client/platforms/alder-lake-desktop/
12th-generation-intel-core-processors-datasheet-volume-1-of-2/002/
intel-speed-shift-technology/. (2022). Accessed: 2022-04-07.

Intel Running Average Power Limit Energy Re-
https://www.intel.com/content/www/us/en/developer/

Technol-
Intel® Speed
Overview of
https://edc.intel.com/content/www/us/en/design/ipla/

Intel® Integrated Performance Primitives Cryptography. https:

Accessed:

2022.

2022.

Shift

[32]

[29]

[31]

[34]

[33]

[30]

[35] David Kaplan, Jeremy Powell, and Tom Woller. 2016. AMD memory encryption.

(2016).

[36] Wonyoung Kim, Meeta S Gupta, Gu-Yeon Wei, and David Brooks. 2008. System
level analysis of fast, per-core DVFS using on-chip switching regulators. In 2008
IEEE 14th International Symposium on High Performance Computer Architecture.
IEEE, 123–134.

[37] Paul Kocher, Joshua Jaffe, Benjamin Jun, and Pankaj Rohatgi. 2011. Introduction
to differential power analysis. Journal of Cryptographic Engineering 1, 1 (2011),
5–27.

[38] Andreas Kogler, Daniel Gruss, and Michael Schwarz. 2022. Minefield: A Software-
only Protection for SGX Enclaves against DVFS Attacks. In USENIX Security
Symposium.
[39]
leogx9r. 2022. Ryzen SMU. https://gitlab.com/leogx9r/ryzen_smu. (2022).
[40] Moritz Lipp, Andreas Kogler, David Oswald, Michael Schwarz, Catherine Easdon,
Claudio Canella, and Daniel Gruss. 2021. PLATYPUS: Software-based Power
Side-Channel Attacks on x86. In 2021 IEEE Symposium on Security and Privacy
(SP). 355–371.

[41] Chen Liu, Monodeep Kar, Xueyang Wang, Nikhil Chawla, Neer Roggel, Bilgiday
Yuce, and Jason M Fung. 2021. Methodology of Assessing Information Leakage
through Software-Accessible Telemetries. In 2021 IEEE International Symposium
on Hardware Oriented Security and Trust (HOST). IEEE, 259–269.

[42] Stefan Mangard, Elisabeth Oswald, and Thomas Popp. 2008. Power analysis
attacks: Revealing the secrets of smart cards. Vol. 31. Springer Science & Business

xxx, xxx, xxx

Media.

Chen Liu†, Abhishek Chakraborty†, Nikhil Chawla†, Neer Roggel‡

[43] Heiko Mantel, Johannes Schickel, Alexandra Weber, and Friedrich Weber. 2018.
How secure is green IT? The case of software-based energy side channels. In
ESORICS. Springer.

[44] Microsoft. 2022.

rdtsc instruction. https://docs.microsoft.com/en-us/cpp/

intrinsics/rdtsc?view=msvc-170. (2022). Accessed: 2022-04-11.

[45] Mathias Morbitzer, Sergej Proskurin, Martin Radev, Marko Dorfhuber, and Er-
ick Quintanar Salas. 2021. SEVerity: Code Injection Attacks against Encrypted
Virtual Machines. In 2021 IEEE Security and Privacy Workshops (SPW). 444–455.
https://doi.org/10.1109/SPW53761.2021.00063

[46] Rajeev Muralidhar, Renata Borovica-Gajic, and Rajkumar Buyya. 2022. En-
ergy Efficient Computing Systems: Architectures, Abstractions and Model-
ing to Techniques and Standards. ACM Comput. Surv. (jan 2022). https:
//doi.org/10.1145/3511094 Just Accepted.

[47] Adel Noureddine, Romain Rouvoy, and Lionel Seinturier. 2015. Monitoring
Energy Hotspots in Software. Automated Software Engg. 22, 3 (sep 2015), 291–332.
https://doi.org/10.1007/s10515-014-0171-1

[48] National Institute of Standards and Technology. 2001. ADVANCED ENCRYPTION
STANDARD (AES). Technical Report. U.S. Department of Commerce, Washington,
D.C.

[49] Emmanuel Prouff and Matthieu Rivain. 2013. Masking against Side-Channel
Attacks: A Formal Security Proof. In 2013 Annual International Conference on the
Theory and Applications of Cryptographic Techniques (EUROCRYPT ’13).
[50] Matthieu Rivain. 2009. Selected Areas in Cryptography: 15th International Work-
shop, SAC 2008, Sackville, New Brunswick, Canada, August 14-15, Revised Selected
Papers. Chapter On the Exact Success Rate of Side Channel Analysis in the
Gaussian Model, 165–183.

[51] Efraim Rotem, Alon Naveh, Avinash Ananthakrishnan, Eliezer Weissmann,
and Doron Rajwan. 2012. Power-Management Architecture of the Intel Mi-
croarchitecture Code-Named Sandy Bridge.
IEEE Micro 32, 2 (2012), 20–27.
https://doi.org/10.1109/MM.2012.12

[52] Tobias Schneider and Amir Moradi. 2015. Leakage Assessment Methodology.
In Cryptographic Hardware and Embedded Systems – CHES 2015, Tim Güneysu
and Helena Handschuh (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg,
495–513.

[53] Brijesh Singh. 2017. x86: Secure Encrypted Virtualization (AMD). (2017).
[54] François-Xavier Standaert. 2017. How (not) to Use Welch’s T-test in Side-Channel

Security Evaluations. In IACR Cryptol. ePrint Arch.

[55] Lin Yan, Yao Guo, Xiangqun Chen, and Hong Mei. 2015. A Study on Power Side
Channels on Mobile Devices. In Proceedings of the 7th Asia-Pacific Symposium on
Internetware. 30–38.

A APPENDIX
We examined the applicability of a frequency throttling side-channel
attack to an AMD processor. We consider the same AES-NI-based
implementation of an AES-128 victim workload and demonstrate
PoC results on a Ryzen 7 5600G processor (codename "Cezanne").

A.1 Reactive Limits on Ryzen 7
The reactive limits supported by the Ryzen processor include:

• Package Power Tracking (PPT): the total power capacity in Watts
at the processor socket, including memory controller power for
a CPU [8].

• Package Power Tracking (PPT) Fast: PPT limit with faster re-

sponse time.

• Thermal Design Current (TDC): the total current capacity in
Amperes at the thermal throttling limit of the processor [8].

The System Management Unit (SMU) is a sub-component of
the AMD processor that is responsible for a variety of system and
power management tasks during boot and runtime [4]. The afore-
mentioned reactive limits can be configured from system software
via an SMU mailbox interface with support from a kernel driver
[3, 39].

Figure 6: Guessing Complexity trend with different amounts
of traces on an AMD Ryzen 7 5600G processor, with PPT fast
limit induced frequency throttling

A.2 CPTA results with PPT Fast Limit
We followed the attack methodology comprising of offline, online
and analysis phases detailed in section 4.2, to mount a CPTA at-
tack. In the offline phase, the attacker sets PPT Fast Limit to 15W
to trigger frequency throttling. In the online phase, the attacker
inputs plaintexts to a victim workload and collects ciphertexts and
timing traces (𝑇𝛿 ). The victim workload is executed on 6 available
physical cores and each encryption with the same plaintext and
key is repeated, such that 𝑇𝛿 is around 50ms for every trace. We
collected 4.5M traces with trace collection time of 63 hours. In the
analysis phase, we considered the same points of attack, gener-
ated execution time estimates (𝑇 𝑘′
) and computed 𝐺𝐶 as described
ℎ
earlier in section 4.2.3.

Figure 6 shows the trend in GC against the number of traces
collected for CPTA analysis, for different execution time estimate
models. The GC converges much faster with Round0-HW model
as compared to other execution time estimate models. GC reduces
to near 0 with less than 1 million traces with Round-0 HW model,
indicating most bytes of the secret key are revealed in less than 16
hours. A similar trend in GC is observed with Round10-HW and
Round10-HW+HD models, with GC converging to 0 with approxi-
mately 3 million traces. GC converges slowest with Round10-HD
model (GC=40 with 4.5 million traces). In summary, this observa-
tion confirms the frequency throttling side-channel on an AMD
Ryzen processor.

