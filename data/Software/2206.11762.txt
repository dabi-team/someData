sparse-ir: optimal compression and sparse sampling of many-body propagators

Markus Wallerbergera, Samuel Badra, Shintaro Hoshinob, Fumiya Kakizawab, Takashi Koretsunec, Yuki Nagaik,l, Kosuke
Nogakid, Takuya Nomotog, Hitoshi Morih, Junya Otsukie, Soshun Ozakif, Rihito Sakuraib, Constanze Vogela, Niklas
Witti, Kazuyoshi Yoshimij, Hiroshi Shinaokab,m

aDepartment of Solid State Physics, TU Wien, 1040 Vienna, Austria
bDepartment of Physics, Saitama University, Saitama 338-8570, Japan
cDepartment of Physics, Toh¯oku University, Miyagi 980-8577, Japan
dDepartment of Physics, Kyoto University, Kyoto 606-8502, Japan
eInstitute for Interdisciplinary Science, Okayama University, Okayama 700-8530, Japan
fDepartment of Physics, University of Tokyo, Bunkyo, Tokyo 113-0033, Japan
gResearch Center for Advanced Science and Technology, University of Tokyo, 4-6-1 Meguro-ku, Tokyo, 153-8904, Japan
hRIKEN Center for Emergent Matter Science (RIKEN CEMS) 2-1 Hirosawa, Wako, Saitama 351-0198, Japan
iI. Institute of Theoretical Physics, University of Hamburg, 22607 Hamburg, Germany
jInstitute for Solid State Physics, University of Tokyo, Tokyo 113-8654, Japan
kCCSE, Japan Atomic Energy Agency, Kashiwa, Chiba 277-0871, Japan
lMathematical Science Team, RIKEN Center for Advanced Intelligence Project (AIP), Tokyo 103-0027, Japan
mJST, PRESTO, 4-1-8 Honcho, Kawaguchi, Saitama 332-0012, Japan

Abstract

We introduce sparse-ir, a collection of libraries to eﬃciently handle imaginary-time propagators, a central object in
ﬁnite-temperature quantum many-body calculations. We leverage two concepts: ﬁrstly, the intermediate representation
(IR), an optimal compression of the propagator with robust a-priori error estimates, and secondly, sparse sampling,
near-optimal grids in imaginary time and imaginary frequency from which the propagator can be reconstructed and on
which diagrammatic equations can be solved. IR and sparse sampling are packaged into stand-alone, easy-to-use Python,
Julia and Fortran libraries, which can readily be included into existing software. We also include an extensive set of
sample codes showcasing the library for typical many-body and ab initio methods.

Keywords:

Intermediate representation, Sparse sampling, Python, Julia, Fortran

Code metadata

1. Motivation and signiﬁcance

Nr. Code metadata descrip-

Please ﬁll in this column

C1
C2

C3

C4
C5
C6

C7
C8

tion
Current code version
link
Permanent
code/repository
for this code version

to
used

Code Ocean compute cap-
sule
Legal Code License
Code versioning system used
Software
languages,
code
tools, and services used
Dependencies
Link to developer documen-
tation/manual

C9

Support email for questions

1.0-beta1
github.com/SpM-
lab/sparse-ir;
github.com/SpM-
lab/SparseIR.jl;
github.com/SpM-
lab/sparse-ir-fortran
–

MIT
git
Python or Julia or Fortran

scipy (optional: xprec)
sparse-ir.readthedocs.io;
spm-lab.github.io/sparse-ir-
tutorial
github.com/SpM-
lab/sparse-ir/issues

Computational quantum many-body physics is a major
driver of advances in materials science, quantum comput-
ing, and high-energy physics. Yet, in pushing these ﬁelds
forward, we face a three-pronged challenge: ﬁrstly, the
requirement to model more complicated systems in an ef-
fort to understand advanced many-body eﬀects, secondly,
speeding up the calculations to allow large-scale automa-
tized system discovery, and thirdly, the need for reliable
error control to fortify predictive power of the results.

For diagrammatic methods working in imaginary (Eu-
clidean) time—widely used to solve quantum many-body
systems—these three prongs translate to the need to com-
pactly store, quickly manipulate, and reliably control the
error, respectively, of many-body propagators and the dia-
grammatic equations in which they appear. Previous eﬀorts
either focused on optimizing imaginary time grids [1, 2] or
modelling generic smooth functions [3, 4].

The intermediate representation (IR) [5, 6] instead lever-
ages the analytical structure of imaginary-time propagators
to construct a maximally compact, orthonormal basis: the
number of basis functions needed to represent a propaga-
tor scales logarithmically with the desired accuracy and

Preprint submitted to SoftwareX

June 24, 2022

2
2
0
2

n
u
J

3
2

]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[

1
v
2
6
7
1
1
.
6
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
logarithmically with Λ, the ultraviolet cutoﬀ in units of
temperature. (Related approaches either optimize for a
diﬀerent norm [7] or trade some compactness for simpler
algorithms [8, 9].) Sparse sampling [10] is a complementary
concept which connects the IR to sparse time and frequency
grids, which allows us to eﬃciently move between represen-
tations and restrict the solution of diagrammatic equations
to those grids. Uniquely, error control is baked into the
IR: each basis function comes with an a priori error level,
which also means changing accuracy is simply a matter of
changing the number of nonzero basis coeﬃcients. The IR
for the one-particle basis also serves as a building block for
compressing arbitrary n-point propagators [11, 12] and fast
solutions to the corresponding diagrammatic equations [13].
Precomputed IRs for diﬀerent cutoﬀs Λ have been re-
leased previously as the irbasis library [14]. Using this
library, IR and sparse sampling has been successfully em-
ployed in numerous physics and chemistry applications
[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28].

In the paper, we introduce sparse-ir, a major step for-
ward from the previous library: it computes the basis on
the ﬂy, usually within seconds. This not only removes
the need for precomputing and shipping databases, it also
allows tayloring the cutoﬀ Λ and even the type of kernel
to the speciﬁc application. We also simplify the use of
sparse sampling, which previously had to be implemented
on top of irbasis by the user. Finally, we improve the
infrastructure for two-particle calculations by adding the
possibility of augmented and vertex bases [11, 13]. We also
provide a set of small, self-contained Jupyter notebooks
showcasing the use of IR and sparse sampling for selected
physics and quantum chemistry applications, lower the
barrier of entry for new users. The library is available as
three standalone Python, Julia and Fortran ports, each
with minimal dependencies.

The remainder of this paper is organized as follows:
after an overview over IR and sparse sampling in Sec. 2,
we showcase the use of sparse-ir in a simple Feynman
diagrammatic method in Sec. 3. In Sec. 4, we then give
an overview of the anatonomy and function of the package.
We state our ﬁnal assessments in Sec. 5.

2. Software description

We are concerned with (retarded) many-body propaga-

tors and related functions in equilibrium:

GR(ω) =

i

−

∞

dt eiωt

t(cid:48)

(cid:90)

A(t)B(t(cid:48))
(cid:104)

∓

B(t(cid:48))A(t)

,
(cid:105)

(1)

·

βH

βH

e−

e−

/ Tr

= Tr

where both A, B are bosonic (

) or fermionic (+) operators,
−
is the expectation value, 1/β
(cid:104)·(cid:105)
is temperature and H is the Hamiltonian. At its core,
(cid:1)
sparse-ir seeks to (i) maximally compress the information
contained in these propagators and (ii) reliably reconstruct
this compressed form from sparse time and frequency grids
to allow its use in diagrammatic calculations.

(cid:0)

(cid:0)

(cid:1)

Figure 1: Singular value expansion (4) of the (a) analytic continuation
kernel K (3) for βωmax = 30 into (b) left-singular functions Ul on
the imaginary-time axis, (c) singular values Sl, and (d) right-singular
functions Vl on the real-frequency axis.

To achieve (i) compression, sparse-ir relies on the fact
that information is lost in transitioning from the (observ-
π Im GR(ω) on the real-
able) spectral function ρ(ω) =
frequency axis to the propagator G(τ ) on the imaginary-
time axis:

−

1

G(τ )

Tτ A(τ )B(0)
(cid:105)

≡ −(cid:104)

=

−

(cid:90)

dω K(τ, ω) ρ(ω),

(2)

where K is an integral kernel mediating the transition
(cf. Sec. 4):

K(τ, ω) =

exp(

τ ω)

exp(

−

−
βω)

1

±

Θ(ωmax

ω

),
|

− |

(3)

Tτ is the time-ordering operator, ωmax is a UV cutoﬀ (upper
bound to the bandwidth), and 0 < τ < β is imaginary time.
This information loss is epitomized by the singular value
expansion (SVE) [29] of the kernel K [30, 5]:

K(τ, ω) =

∞

(cid:88)l=0

Ul(τ ) Sl Vl(ω),

(4)

Ul}
{

are the left-singular functions, an orthonor-
where
mal system on the imaginary-time axis, and
are the
right-singular functions, an orthonormal system on the real-
frequency axis. The amount of information retained in the
transformation from Vl to Ul is encoded in the associated
(scaled) singular value Sl/S0. Crucially, Sl decays at least

Vl}
{

2

0.000.250.500.751.00τ/β−1.0−0.50.00.51.0ω/ωmax(a)Klog(τ,ω)−1012√ωmaxV‘(ω)(d)V0(ω)V1(ω)V2(ω)0510‘10−410−310−210−1100(βωmax/2)−1/2S‘(c)S‘−2−1012pβ/2U‘(τ)(b)U0(τ)U1(τ)U2(τ)10−310−210−1100exponentially quickly, log(Sl)
l/ log(βωmax). This in-
formation loss on the other hand allows the imaginary-time
propagator to be compressed by storing the expansion coef-
ﬁcients of the left-singular functions (“IR basis functions”)
Ul [6]:

∼ −

L

1

−

G(τ ) =

Ul(τ ) Gl + (cid:15)L(τ ),

(5a)

(cid:88)l=0

Sl

dω Vl(ω)ρ(ω) are the expansion coeﬃ-
where Gl =
−
cients and (cid:15)L is an error term which vanishes exponentially
quickly, (cid:15)L ∼

SL/S0. Its Fourier transform is given by

(cid:82)

ˆG(iω) =

β

0
(cid:90)

dτ eiωτ G(τ ) =

L

1

−

(cid:88)l=0

ˆUl(iω) Gl + ˆ(cid:15)L(iω), (5b)

where iω = iπ
β (2n+ζ) is a Matsubara frequency, ζ = 0/1 for
bosons/fermions, and ˆ
denotes the Fourier transform. The
·
singular value construction means that the IR basis is (a)
optimal in terms of compactness:1 for, e.g., βωmax < 108,
no more than 200 coeﬃcients must be stored to obtain full
double precision accuracy; (b) orthonormal; and (c) unique,
thereby providing a robust and compact storage format.

To achieve (ii) reconstruction, we note that the “poly-
nomial-like” properties of Ul [31, 13] guarantee that there
and
exists [32, 33] a sparse set of
frequencies
from which we can robustly infer
=
iωn}
{
the coeﬃcients [10]. sparse-ir solves the following ordinary
least-squares problems:

(L) times

τi}

W

O

=

T

{

1

L

−

Ul(τ ) Gl

2

,

G(τ )

−

ˆG(iω)

Gl = arg min
{

Gl

Gl = arg min
{

Gl

} (cid:88)τ
∈T (cid:12)
(cid:12)
(cid:12)

iω
} (cid:88)

∈W (cid:12)
(cid:12)
(cid:12)

(cid:88)l=0
L
−

1

−

(cid:88)l=0

(cid:12)
(cid:12)
(cid:12)

ˆUl(iω) Gl

2

.

(cid:12)
(cid:12)
(cid:12)

(6a)

(6b)

Given a sensible choice for the sampling points, Eqs. (5)
and (6) now allow us to move between sparse imaginary-
time and frequency grids and compressed representations
without any signiﬁcant loss of precision [10].

3. Example usage

As a simple example, let us perform self-consistent
second-order perturbation theory for the single impurity
Anderson model at ﬁnite temperature. Its Hamiltonian is
given by

µ(c†
↑

H =

−
+

c

c

+ c†
↓

) + U c†
↑

c†
↓

↓

↑
↓
Vpσf †pσcσ + V ∗pσc†σfpσ

c

c

↑
+

(cid:15)pf †pσfpσ,

(7)

pσ
(cid:88)

(cid:0)

pσ
(cid:88)

(cid:1)

where U is the electron interaction strength, µ is the chemi-
cal potential, cσ annihilates an electron on the impurity, fpσ

1The truncated IR expansion minimizes ||(cid:15)L|| in the L2-norm
sense if no additional information, i.e., a ﬂat prior, for ρ(ω) is used.

3

1 import sparse_ir as ir , numpy as np
2 basis = ir . F initeTempBas is ( ’F ’ , 10 , 8 , 1e -6)
3 U = 1.2
4 def rho0w ( w ) :
5
6 rho0l = basis . v . overlap ( rho0w )
7 G0l = - basis . s * rho0l
8 Gl_prev = 0
9 Gl = G0l

return np . sqrt (1 - w . clip ( -1 ,1) **2) * 2/ np . pi

10 stau = ir . TauSampling ( basis )
11 siw = ir . Ma t su bar aSa m pl i ng ( basis )
12 while np . linalg . norm ( Gl - Gl_prev ) > 1e -6:
13
14
15
16
17
18
19
20

Gl_prev = Gl
Gtau = stau . evaluate ( Gl )
Sigmatau = U **2 * Gtau **3
Sigmal = stau . fit ( Sigmatau )
Sigmaiw = siw . evaluate ( Sigmal )
G0iw = siw . evaluate ( G0l )
Giw = 1/(1/ G0iw - Sigmaiw )
Gl = siw . fit ( Giw )

Figure 2: Self-consistent second-order perturbation theory for a single-
impurity Anderson model (7) with a semi-elliptic density of states
and U = 1/2 at half ﬁlling and β = 10 using sparse-ir.

∈

denotes the Hermitian
annihilates an electron in the bath,
R is bath momentum, and σ
conjugate, p
is spin.
,
∈ {↑
The hybridization strength Vpσ and bath energies (cid:15)p are cho-
sen such that the non-interacting density of states is semi-
elliptic with a half-bandwidth of one, ρ0(ω) = 2
ω2,
π
−
U = 1.2, β = 10, and the system is half-ﬁlled, µ = U/2.

√1

↓}

†

We present the associated algorithm in Fig. 2. First,
we construct the IR basis for fermions and β = 10, in-
tuit that ωmax = 8 is larger than the interacting band-
6
width and content ourselves with an accuracy of (cid:15) = 10−
(line 2). We then compute the basis coeﬃcients as ρ0,l =
dω Vl(ω)ρ0(ω) (line 6). The non-interacting propagator
Slρ0,l (line 7) serves as initial guess for Gl (line 9).
G0,l =
(cid:82)
We then construct the grids and matrices for sparse sam-
pling (lines 10, 11), after which we enter the self-consistency
loop (line 12): At half ﬁlling, the second-order self-energy
is simply

−

Σ(τ ) = U 2G3(τ )

(8)

(line 15). We construct this object at the sampling points
by ﬁrst expanding Gl (line 14). The dynamical part of
τi}
{
the self-energy is propagator-like, so it can be modeled by
the IR basis (the Hartree and Fock term, if present, needs
to be handled separately). The Dyson equation

ˆG−

1(iω) = ˆG−

1
0 (iω)

ˆΣ(iω)

−

(9)

(line 19) is then solved by expanding both G0 and Σ on the
sparse set of frequencies (lines 17, 18). To complete the
loop, the IR coeﬃcients for G are then updated (line 20).
We converge if the deviation between subsequent iterations
(line 13) is consistent with the basis accuracy (line 12).

The resulting self-energy ˆΣ(iω) on the Matsubara axis
is presented in Fig. 3 (only the imaginary part is plotted,
since the real part is merely a constant U/2 at half ﬁlling).
Instead of a dense mesh (plusses), the Dyson equation has

4. Architecture and features

The main functions of the library are (a) construction
and handling of the kernel (3), (b) performing the singular
value expansion (4), (c) storage and evaluation of the IR
basis functions (5), and (d) construction of the sampling
points and solution of the ﬁtting problem (6). The sparse-ir
package was split along these lines into modules, see Fig. 4,
which we will brieﬂy describe in the following.

Kernel. Two kernels are packaged with sparse-ir:

(10a)

(10b)

K log

Λ (x, y) =

K RB

Λ (x, y) =

exp

Λ
2 (x + 1)y
−
Λy)
1 + exp(
(cid:1)
Λ
2 (x + 1)y
Λy)

−
exp(

(cid:0)
y exp
1

−

(cid:0)
−

Θ(1

),

y

|

− |

Θ(1

y

).
|

− |

(cid:1)

−

1, 1], where τ = β

−
Kernels are expressed in terms of dimensionless variables
x and y in the interval [
2 (x + 1) and
ω = ωmaxy. Instead of parametrization by both inverse
temperature β and UV cutoﬀ frequency ωmax, this allows
one to consider only a single scale parameter Λ = βωmax.
The logistic kernel (10a) is the default kernel used for
both fermionic and bosonic propagators for simplicity: even
though it is the analytic continuation kernel for fermions,
it can also be used to compactly model bosonic propaga-
tors [53, 26, 8]. The regularized bosonic kernel (10b) is
common in numerical analytic continuation of bosonic func-
tions [54, 55] and is used by the irbasis library for bosonic
propagators. Thermal contributions to the susceptibility,
χ(ω = 0), can be modelled by augmenting the basis [13].
User-deﬁned kernels may be added.

Each kernel K can be evaluated by supplying x, y, how-
1:
x to full precision to

ever care must be taken not to lose precision around x =
in addition to x we use x
avoid cancellation in the enumerators of Eqs. (10).

:= 1

±

±

±

Piecewise polynomials. To represent the IR basis functions
(4), we employ piecewise Legendre polynomials:

Pnq(x;

) :=

xm}
{

(cid:114)

where x0 < x1 <
1), ¯xn := 1
1
2 (xn −
xn
−
Legendre polynomial.

· · ·

1
∆xn

¯xn
x
−
∆xn (cid:19)

x

(cid:18)

Pq

Θ(∆xn − |

¯xn|
(11)
< xN are the segment edges, ∆xn :=
1), and Pq denotes the q-th
2 (xn + xn

−

),

−

Given suitable discretizations of the axes,

and
, as well as a Legendre order Q, the left and right IR

yn}
{
basis functions can then be expanded as follows:

xn}

{

ul(x)

vl(y)

≈

≈

N

Q

n=1
(cid:88)
N (cid:48)

q=0
(cid:88)
Q

ulnqPnq(x;

),
x0, . . . , xN }
{

(12a)

vln(cid:48)q(cid:48)Pn(cid:48)q(cid:48)(y;

y0, . . . , yN (cid:48)
{

),
}

(12b)

(cid:88)n(cid:48)=1

(cid:88)q(cid:48)=0

where ulnq and vln(cid:48)q(cid:48) are expansion coeﬃcients.

4

Figure 3: Imaginary part of the Matsubara self-energy ˆΣ(iω) for
the GF(2) calculation in Fig. 2. Black crosses mark the location
of sampling points W on which the Dyson equation (9) is solved
and from which the full signal is reconstructed. Inset: normalized
IR expansion coeﬃcients of G (plusses) and Σ − ΣHF (crosses) and
singular values (dots) for comparison. Lines are guides for the eye.

to be solved only on the sampling points (crosses). Since
the IR coeﬃcients for both the Green’s function and the
self-energy are guaranteed to decay quickly (see inset), this
is enough to reconstruct the functions everywhere with
6. We note that this
the given accuracy bound of (cid:15) = 10−
bound and the UV cutoﬀ ωmax are the only discretization
parameters we need to supply.

The code in Fig. 2 is short, simple—no explicit Fourier
transforms or models are required—yet guarantees the
given accuracy goal. Extending the approximation to
Σ = GW would require only the addition of a bosonic
basis, the construction of the RPA diagram, Π(τ ) = G2(τ ),
and solving the Bethe–Salpeter equation, ˆW (iω) = U +
U ˆΠ(iω) ˆW (iω), where again sparse grids and transforma-
tions can be used.

In addition to this example, sparse-ir ships a set of
tutorials [34], demonstrating the use of the Python, Julia,
and Fortran libraries in typical many-body calculations.
Each tutorial contains a short description of the underlying
many-body theory as well as sample code utilizing sparse-ir
and its expected output. Currently, we include tutorials
on: (a) the GF(2) and GW approximation [35, 36], (b)
ﬂuctuation exchange (FLEX) [37, 19, 23], (c) the two-
particle self-consistent (TPSC) approximation [38, 39], (d)
Eliashberg theory for the Holstein–Hubbard model [40, 41,
42, 43], (e) the Lichtenstein formula [44], (f) calculation of
the orbital magnetic susceptibility [45, 46, 47, 48, 49, 50,
51, 52], and (g) numerical analytic continuation based on
the SpM method [5].

0510152025ωn(Matsubarafrequency)−0.12−0.10−0.08−0.06−0.04−0.020.00ImˆΣ(iω)samplingpoints0481216‘(expansionorder)10−610−410−2100|Gl/G0||Σl/Σ0|Sl/S0Figure 4: Simpliﬁed UML class diagram of the core of sparse-ir. Classes with names in boldface are available from the top namespace.

Legendre polynomials have the advantage that their

Fourier transform is given analytically [3]:

ˆPnq(

ω;

±

xm}
{

) :=

xN

dx e±

iωxPnq(x;

x0

(cid:90)
= 2

∆xne±

iω ¯xn (

±

)
xm}
{
i)qjq(ω∆xn),

(13)

(cid:112)

≥

where ω
0 is a frequency and jq(x) is the q-th spherical
Bessel function. Thus, no numerical integration is necessary,
though exp(iωx) must be analytically mapped back to small
iωx to avoid cancellation.

Singular value expansion (SVE). Given the discretization
outlined above, we can relate the SVE (4) needed for con-
structing the IR basis to the singular value decomposition
(SVD) of the following (N Q)

(N (cid:48)Q) matrix [29, 6]:

×

Anq,n(cid:48)q(cid:48) =

(q + 1

2 )(q(cid:48) + 1
2 )

(cid:113)

(14)

×

(cid:90) (cid:90)

ym}
{

)K(x, y),

)Pn(cid:48)q(cid:48)(y,

dx dy Pnq(x,

xm}
{
where the singular values of A are equal to the singular
values sl of the kernel, and the left and right singular
vectors are the (scaled) expansion coeﬃcients of ul(x) and
vl(y), respectively (12). L is chosen such that sL < (cid:15)s0,
where (cid:15) is the desired accuracy of the basis. In practice,
we approximate the integral (14) by the associated Gauss–
Legendre rule and rewrite the problem as equation for
the Gauss nodes [32, 29, 8]. As the kernels (10) are all
y), the SVE problem
centrosymmetric, K(x, y) = K(
is block-diagonalized for a four-fold speedup [56].

x,

−

−

We empirically ﬁnd that choosing

close
ym}
1(x)
to the extrema of the highest-order basis functions, uL
1(y), respectively, to provide an excellent discretiza-
and vL
16. Since
tion, only necessitating Q = 16 for (cid:15) = 10−
computing the basis functions requires solving the SVE,

xm}
{

and

{

−

−

5

each kernel maintains approximations to
ym}
{
as hints. As only a fraction 1/Q of the singular values of
Eq. (14) are needed, we use a truncated SVD algorithm
(rank-revealing QR decomposition followed by two-sided
Jacobi rotations [57]) at the cost of

xm}
{

2N Q3).

and

(N (cid:48)

In order to guarantee an accuracy of (cid:15) for both singular
values and basis functions, one has to compute the SVE
with a machine precision of (cid:15)2 [57]. Thus we compute
8 and
the SVD in standard double precision for (cid:15)
quadruple precision otherwise. For the latter we have de-
veloped the xprec extension to numpy. Note that quadruple
precision is only needed in the SVE – the basis functions
are stored and evaluated in double precision.

10−

≥

O

−

−

−

{

±

τi}
{

iωn}

and frequencies

1(τi) and ˆUL

Sampling. The sampling times
iωn}
{
are chosen such that the highest-order basis functions,
1(iωn), respectively, are locally extremal.
UL
To optimize conditioning, τ1 and τL are moved from
1
±
to the midpoint of between the
1 and the closest root
of UL
1. Sampling in frequency is conditioned somewhat
worse due to the discrete nature of the frequency axis, which
are augmented by four additional frequencies.
is why
With the sampling points chosen, sparse sampling now
involves transitioning between IR basis coeﬃcients and the
value at the sampling points. For evaluation (5) at the
sampling points we multiply with precomputed matrices,
Fil := Ul(τi) and ˆFnl := ˆUl(iωn), respectively, at a cost of
(L2). For ﬁtting the IR coeﬃcients, we need to solve the
O
least-squares problems (6). However, multiplying with a
precomputed pseudoinverse can lead to loss of backward
stability [58], and we observe this in the case of basis
augmentation. Instead, we precompute and store the SVD
of F and ˆF and construct the pseudoinverse on the ﬂy,
again at a cost of

(L2).

O

IRBasisu : PiecewiseLegendrePolyuhat : PiecewiseLegendreFTs : float[ ]v : PiecewisePolykernel : KernelBaseAbstractSVEHintssegments_x : float[ ]segments_y : float[ ]ngauss : intnsvals : intAbstractKernel__call__(x, y) : floatsve_hints(eps) : AbstractSVEHintsget_symmetric(s) : AbstractKernelLogisticKernelRegularizedBoseKernelAbstractSVEK : AbstractKernelmatrices : float[ ][ ][ ]postprocess(u, s, v)SamplingSVECentrosymmSVEeven : SVEBaseodd : SVEBasePiecewiseLegendrePolydata : float[ ][ ][ ]knots : float[ ]« call »(x) : float[ ]roots( ) : float[ ]PiecewiseLegendreFTpoly : PiecewiseL...Poly« call »(wn) : complex[ ]extrema( ) : int[ ]AbstractSamplingbasis : IRBasissampling_points : number[ ]matrix : DecomposedMatrixevaluate(gl) : gsamplefit(gsample) : glTauSamplingMatsubaraSamplingDecomposedMatrixa : number[ ][ ]u : number[ ][ ]s : number[ ]vH : number[ ][ ]matmul(x) : number[ ]fit(x) : number[ ]FiniteTempBasisbeta : floatDimensionlessBasiskernelsvebasispolysamplingJulia and Fortran libraries. This software package includes
Julia [59] and Fortran [60] libraries. The Julia library im-
plements the full set of functionalities of the Python library
with a similar interface. The Fortran library implements
only their subset required for its use in ab initio programs:
The Fortran library uses the tabulated values of the IR ba-
sis functions computed by the Python library. The Fortran
interface is fully compatible with the Fortran95 standard
and has no additional external dependencies. More detailed
descriptions can be found in readme ﬁles of the repositories
and the tutorials described below.

research unit QUAST FOR5249 (project DFG WE 5342/8-
1). RS, FK and HS were supported by JST, PRESTO
Grant No. JPMJPR2012. HS was supported by JSPS
KAKENHI Grants No. 21H01041 and No. 21H01003. SH
was supported by No. JP21K03459. TK was supported by
JSPS KAKENHI Grants No. 21H01003, 21H04437, and
22K03447. SO was supported by JSPS KAKENHI Grants
No. 18H01162 and JSPS through the Program for Leading
Graduate Schools (MERIT). KN was supported by JSPS
KAKENHI Grants No. JP21J23007.

5. Impact and outlook

We expect that the library will be widely used in many-
body and ab initio calculations based on diagrammatic
theories such as GW and quantum embedding theories
such as the dynamical mean-ﬁeld theory and its extensions.
The computational complexity of diagrammatic calcula-
tions based on these technologies grows slower than any
power law with respect to the inverse temperature. This
makes these technologies particularly eﬃcient and useful in
studying systems with a large bandwidth at low tempera-
tures. The library will make new studies for understanding
the low-temperature properties of solids and molecules
feasible.

To facilitate its application to various ﬁelds, the library
supports languages popular in many diﬀerent areas (Python
and Julia for prototyping, Fortran, C, and C++ for existing
ab-initio codes.) The library is shipped with many self-
contained tutorials on speciﬁc topics in diﬀerent ﬁelds of
physics.

6. Conclusions

We present intermediate representation (IR) and sparse
sampling for eﬃcient many-body and ab initio calculations
based on imaginary-time propagators. These methods are
implemented in Python/Julia/Fortran libraries to allow
researchers in a large community of many-body physics
and ab initio calculations to use them.

Conﬂict of interest

We wish to conﬁrm that there are no known conﬂicts of
interest associated with this publication and there has been
no signiﬁcant ﬁnancial support for this work that could
have inﬂuenced its outcome.

Acknowledgements

MW was supported by the FWF through project P30997.
NW acknowledges funding by the Cluster of Excellence
‘CUI: Advanced Imaging of Matter’ of the DFG (EXC
2056 - project ID 390715994) and support by the DFG

References

[1] W. Ku, A. G. Eguiluz, Band-gap problem in semiconductors
revisited: Eﬀects of core states and many-body self-consistency,
Phys. Rev. Lett. 89 (2002) 126401. doi:10.1103/PhysRevLett.
89.126401.

[2] A. A. Kananenka, J. J. Phillips, D. Zgid, Eﬃcient temperature-
dependent Green’s functions methods for realistic systems: Com-
pact grids for orthogonal polynomial transforms, J. Chem. The-
ory Comput. 12 (2) (2016) 564–571. doi:10.1021/acs.jctc.
5b00884.

[3] L. Boehnke, H. Hafermann, M. Ferrero, F. Lechermann, O. Par-
collet, Orthogonal polynomial representation of imaginary-
time Green’s functions, Phys. Rev. B 84 (2011) 075145. doi:
10.1103/PhysRevB.84.075145.

[4] X. Dong, D. Zgid, E. Gull, H. U. R. Strand, Legendre-spectral
Dyson equation solver with super-exponential convergence, J.
Chem. Phys. 152 (13) (2020) 134107. doi:10.1063/5.0003145.
[5] J. Otsuki, M. Ohzeki, H. Shinaoka, K. Yoshimi, Sparse modeling
approach to analytical continuation of imaginary-time quantum
Monte Carlo data, Phys. Rev. E 95 (2017) 061302. doi:10.1103/
PhysRevE.95.061302.

[6] H. Shinaoka, J. Otsuki, M. Ohzeki, K. Yoshimi, Compress-
ing Green’s function using intermediate representation between
imaginary-time and real-frequency domains, Phys. Rev. B 96 (3)
(2017) 35147. doi:10.1103/PhysRevB.96.035147.

[7] M. Kaltak, G. Kresse, Minimax isometry method: A com-
pressive sensing approach for Matsubara summation in many-
body perturbation theory, Phys. Rev. B 101 (2020) 205145.
doi:10.1103/PhysRevB.101.205145.

[8] J. Kaye, K. Chen, O. Parcollet, Discrete Lehmann representation
of imaginary time Green’s functions, arXiv (2021). arXiv:2107.
13094.

[9] J. Kaye, K. Chen, H. U. R. Strand, libdlr: Eﬃcient imaginary
time calculations using the discrete Lehmann representation,
arXiv (2021). arXiv:2110.06765.

[10] J. Li, M. Wallerberger, N. Chikano, C.-N. Yeh, E. Gull, H. Shi-
naoka, Sparse sampling approach to eﬃcient ab initio calcula-
tions at ﬁnite temperature, Phys. Rev. B 101 (3) (2020) 035144.
doi:10.1103/physrevb.101.035144.

[11] H. Shinaoka, J. Otsuki, K. Haule, M. Wallerberger, E. Gull,
K. Yoshimi, M. Ohzeki, Overcomplete compact representation of
two-particle Green’s functions, Phys. Rev. B 97 (2018) 205111.
doi:10.1103/PhysRevB.97.205111.

[12] H. Shinaoka, D. Geﬀroy, M. Wallerberger, J. Otsuki, K. Yoshimi,
E. Gull, J. Kuneˇs, Sparse sampling and tensor network represen-
tation of two-particle Green’s functions, SciPost Phys. 8 (2020)
12. doi:10.21468/SciPostPhys.8.1.012.

[13] M. Wallerberger, H. Shinaoka, A. Kauch, Solving the Bethe–
Salpeter equation with exponential convergence, Phys. Rev.
Research 3 (2021) 033168. doi:10.1103/PhysRevResearch.3.
033168.

[14] N. Chikano, K. Yoshimi, J. Otsuki, H. Shinaoka, irbasis: Open-
source database and software for intermediate-representation
basis functions of imaginary-time Green’s function, Comput.
Phys. Commun. 240 (2019) 181–188. doi:10.1016/j.cpc.2019.
02.006.

6

[15] T. Nomoto, T. Koretsune, R. Arita, Local force method for the
ab initio tight-binding model: Eﬀect of spin-dependent hopping
on exchange interactions, Phys. Rev. B 102 (1) (2020) 014444.
doi:10.1103/physrevb.102.014444.

[16] T. Nomoto, T. Koretsune, R. Arita, Formation mechanism of
the helical Q structure in Gd-based skyrmion materials, Phys.
Rev. Lett. 125 (11) (2020) 117204. doi:10.1103/physrevlett.
125.117204.

[17] Y. Nomura, T. Nomoto, M. Hirayama, R. Arita, Magnetic ex-
change coupling in cuprate-analog d9 nickelates, Phys. Rev.
Research 2 (4) (2020) 043144. doi:10.1103/physrevresearch.
2.043144.

[18] S. Iskakov, C.-N. Yeh, E. Gull, D. Zgid, Ab initio self-energy
embedding for the photoemission spectra of NiO and MnO,
Phys. Rev. B 102 (8) (2020) 085105. doi:10.1103/physrevb.
102.085105.

[19] N. Witt, E. G. C. P. van Loon, T. Nomoto, R. Arita,
T. O. Wehling, Eﬃcient ﬂuctuation-exchange approach to low-
temperature spin ﬂuctuations and superconductivity: From the
Hubbard model to NaxCoO2 · yH2O, Phys. Rev. B 103 (2021)
205148. doi:10.1103/PhysRevB.103.205148.

[20] P. Pokhilko, S. Iskakov, C.-N. Yeh, D. Zgid, Evaluation of two-
particle properties within ﬁnite-temperature self-consistent one-
particle green’s function methods: Theory and application to
GW and GF2, J. Chem. Phys. 155 (2) (2021) 024119. doi:
10.1063/5.0054661.

[21] C.-N. Yeh, S. Iskakov, D. Zgid, E. Gull, Electron correlations in
the cubic paramagnetic perovskite Sr(V, Mn)O3: Results from
fully self-consistent self-energy embedding calculations, Phys.
Rev. B Condens. Matter 103 (19) (May 2021). doi:10.1103/
PhysRevB.103.195149.

[22] C.-N. Yeh, A. Shee, Q. Sun, E. Gull, D. Zgid, Relativistic
self-consistent GW : Exact two-component formalism with one-
electron approximation for solids, arXiv (2022). arXiv:2202.
02252.

[23] N. Witt, J. M. Pizarro, J. Berges, T. Nomoto, R. Arita, T. O.
Wehling, Doping ﬁngerprints of spin and lattice ﬂuctuations in
moir´e superlattice systems, Phys. Rev. B 105 (2022) L241109.
doi:10.1103/PhysRevB.105.L241109.

[24] Y. Nagai, H. Shinaoka,

Smooth self-energy in the
exact-diagonalization-based dynamical mean-ﬁeld theory:
Intermediate-representation ﬁltering approach, J. Phys. Soc.
Japan 88 (6) (2019) 064004. doi:10.7566/jpsj.88.064004.
[25] Y. Nagai, Intrinsic vortex pinning in superconducting quasicrys-

tals, arXiv (2021). arXiv:2111.13288.

[26] Y. N. Etsuko Itou, QCD viscosity by combining the gradient ﬂow
and sparse modeling methods, arXiv (2021). arXiv:2110.13417.
[27] R. Sakurai, W. Mizukami, H. Shinaoka, Hybrid quantum-
classical algorithm for computing imaginary-time correlation
functions, arXiv (2021). arXiv:2112.02764.

[28] Y. Nagai, H. Shinaoka, Sparse modeling approach for qua-
siclassical theory of superconductivity, arXiv (2022). arXiv:
2205.14800.

[29] P. C. Hansen, Discrete Inverse Problems: Insights and Algo-

rithms, SIAM, 2010. doi:10.1137/1.9780898718836.

[30] R. K. Bryan, Maximum entropy analysis of oversampled data
problems, Eur. Biophys. J. 18 (1990) 165–174. doi:10.1007/
BF02427376.

[31] S. Karlin, Total Positivity, Stanford University Press, 1968.
[32] V. Rokhlin, N. Yarvin, Generalized Gaussian quadratures and
singular value decompositions of integral operators, SIAM J. Sci.
Comput. 20 (1996) 44. doi:10.1137/S1064827596310779.
[33] H. Shinaoka, N. Chikano, E. Gull, J. Li, T. Nomoto, J. Ot-
suki, M. Wallerberger, T. Wang, K. Yoshimi, Eﬃcient ab initio
many-body calculations based on sparse modeling of Matsubara
Green’s function, arXiv (2021). arXiv:2106.12685.

[34] https://spm-lab.github.io/sparse-ir-tutorial (2022).
[35] L. Hedin, New method for calculating the one-particle Green’s
function with application to the electron-gas problem, Phys. Rev.
139 (1965) A796–A823. doi:10.1103/PhysRev.139.A796.
[36] F. Aryasetiawan, O. Gunnarsson, The GW method, Rep. Prog.

Phys. 61 (3) (1998) 237–312. doi:10.1088/0034-4885/61/3/002.
[37] N. E. Bickers, D. J. Scalapino, S. R. White, Conserving approxi-
mations for strongly correlated electron systems: Bethe–Salpeter
equation and dynamics for the two-dimensional Hubbard model,
Phys. Rev. Lett. 62 (1989) 961–964. doi:10.1103/PhysRevLett.
62.961.

[38] Y. M. Vilk, A.-M. S. Tremblay, Non-perturbative many-body
approach to the Hubbard model and single-particle pseudogap,
Journal de Physique I 7 (11) (1997) 1309–1368. doi:10.1051/
jp1:1997135.

[39] A.-M. S. Tremblay, Two-particle-self-consistent approach for
the Hubbard model, in: A. Avella, F. Mancini (Eds.), Strongly
Correlated Systems: Theoretical Methods, Springer Berlin Hei-
delberg, Berlin, Heidelberg, 2012, pp. 409–453. doi:10.1007/
978-3-642-21831-6_13.

[40] G. M. Eliashberg, Interactions between electrons and lattice
vibrations in a superconductor, Soviet Phys. JETP 11 (1960)
696.

[41] D. J. Scalapino, The electron-phonon interaction and strong-
coupling superconductors, in: R. D. Parks (Ed.), Superconduc-
tivity, 1st Edition, CRC Press, Boca Raton, FL, 1969, p. 112.
doi:10.1201/9780203737965.

[42] J. Zhong, H.-B. Sch¨uttler, Polaronic anharmonicity in the
Holstein–Hubbard model, Phys. Rev. Lett. 69 (1992) 1600–1603.
doi:10.1103/PhysRevLett.69.1600.

[43] Y. Kaga, P. Werner, S. Hoshino, Eliashberg theory of the
Jahn-Teller-Hubbard model, Phys. Rev. B 105 (2022) 214516.
doi:10.1103/PhysRevB.105.214516.
URL
214516

https://link.aps.org/doi/10.1103/PhysRevB.105.

[44] A. I. Lichtenstein, M. I. Katsnelson, V. A. Gubanov, Exchange
interactions and spin-wave stiﬀness in ferromagnetic metals, J.
Phys. F: Metal Phys. 14 (7) (1984) L125–L128. doi:10.1088/
0305-4608/14/7/007.

[45] H. Fukuyama, Theory of orbital magnetism of Bloch electrons:
Coulomb interactions, Progress of Theoretical Physics 45 (3)
(1971) 704–729. doi:10.1143/PTP.45.704.

[46] G. G´omez-Santos, T. Stauber, Measurable lattice eﬀects on the
charge and magnetic response in graphene, Phys. Rev. Lett. 106
(2011) 045504. doi:10.1103/PhysRevLett.106.045504.

[47] A. Raoux, F. Pi´echon, J.-N. Fuchs, G. Montambaux, Orbital
magnetism in coupled-bands models, Phys. Rev. B 91 (2015)
085120. doi:10.1103/PhysRevB.91.085120.

[48] F. Pi´echon, A. Raoux, J.-N. Fuchs, G. Montambaux, Geometric
orbital susceptibility: Quantum metric without Berry curva-
ture, Phys. Rev. B 94 (2016) 134423. doi:10.1103/PhysRevB.
94.134423.

[49] M. Ogata, H. Fukuyama, Orbital magnetism of Bloch electrons:
I. General formula, J. Phys. Soc. Japan 84 (12) (2015) 124708.
doi:10.7566/JPSJ.84.124708.

[50] H. Matsuura, M. Ogata, Theory of orbital susceptibility in the
tight-binding model: Corrections to the Peierls phase, J. Phys.
Soc. Japan 85 (7) (2016) 074709. doi:10.7566/JPSJ.85.074709.
[51] M. Ogata, Orbital magnetism of Bloch electrons: II. Applica-
tion to single-band models and corrections to landau–peierls
susceptibility, J. Phys. Soc. Japan 85 (6) (2016) 064709. doi:
10.7566/JPSJ.85.064709.

[52] M. Ogata, Orbital magnetism of Bloch electrons: III. Application
to graphene, J. Phys. Soc. Japan 85 (10) (2016) 104708. doi:
10.7566/JPSJ.85.104708.

[53] H. B. Meyer, Calculation of the shear viscosity in SU(3) gluody-
namics, Phys. Rev. D 76 (2007) 101701. doi:10.1103/PhysRevD.
76.101701.

[54] M. Jarrell, J. Gubernatis, Bayesian inference and the analytic
continuation of imaginary-time quantum Monte Carlo data,
Phys. Rep. 269 (3) (1996) 133–195. doi:10.1016/0370-1573(95)
00074-7.

[55] Y. Motoyama, K. Yoshimi, J. Otsuki, Robust analytic continua-
tion combining the advantages of the sparse modeling approach
and the Pad´e approximation, Phys. Rev. B 105 (2022) 035139.
doi:10.1103/PhysRevB.105.035139.

7

[56] N. Chikano, J. Otsuki, H. Shinaoka, Performance analysis of a
physically constructed orthogonal representation of imaginary-
time Green’s function, Phys. Rev. B 98 (3) (2018) 035104. doi:
10.1103/PhysRevB.98.035104.

[57] G. H. Golub, C. F. van Loan, Matrix Computations, 3rd Edition,

Johns Hopkins University Press, 1996.

[58] J. H. Wilkinson, Rounding Errors in Algebraic Processes,

Prentice–Hall, 1963.

[59] https://github.com/SpM-lab/SparseIR.jl (2022).
[60] https://github.com/SpM-lab/sparse-ir-fortran (2022).

8

