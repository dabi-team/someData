Environment Imitation: Data-Driven Environment Model Generation Using
Imitation Learning for Eﬃcient CPS Goal Veriﬁcation

Yong-Jun Shina, Donghwan Shinb,∗, Doo-Hwan Baea

aKorea Advanced Institute of Science and Technology
bUniversity of Luxembourg

2
2
0
2

r
p
A
4
1

]
E
S
.
s
c
[

1
v
9
9
7
6
0
.
4
0
2
2
:
v
i
X
r
a

Abstract

Cyber-Physical Systems (CPS) continuously interact with their physical environments through software controllers that
observe the environments and determine actions. Engineers can verify to what extent the CPS under analysis can achieve
given goals by analyzing its Field Operational Test (FOT) logs. However, it is challenging to repeat many FOTs to
obtain statistically signiﬁcant results due to its cost and risk in practice. To address this challenge, simulation-based
veriﬁcation can be a good alternative for eﬃcient CPS goal veriﬁcation, but it requires an accurate virtual environment
model that can replace the real environment that interacts with the CPS in a closed loop. This paper proposes a novel
data-driven approach that automatically generates the virtual environment model from a small amount of FOT logs.
We formally deﬁne the environment model generation problem and solve it using Imitation Learning (IL) algorithms.
In addition, we propose three speciﬁc use cases of our approach in the evolutionary CPS development. To validate our
approach, we conduct a case study using a simpliﬁed autonomous vehicle with a lane-keeping system. The case study
results show that our approach can generate accurate virtual environment models for CPS goal veriﬁcation at a low cost
through simulations.

Keywords: Cyber-Physical System (CPS), Environment model generation, Imitation Learning (IL)
2010 MSC: 00-01, 99-00

1. Introduction

Cyber-Physical Systems (CPS) utilize both physical
and software components deeply intertwined to continu-
ously collect, analyze, and control physical actuators at
runtime [1]. CPS has been increasingly studied for many
applications, such as autonomous vehicles [2, 3], robots [4,
5], smart factories [6, 7], and medical devices [8, 9].

One of the essential problems in CPS development is
to verify to what extent the CPS under development can
achieve its goals. To answer this, a developer could de-
ploy a CPS (e.g., an autonomous vehicle) into its opera-
tional environment (e.g., a highway road) and verify the
CPS’s goal achievement (e.g., lane-keeping) using the logs
collected from the Field Operational Tests (FOTs). How-
ever, conducting FOTs is expensive, time-consuming, and
even dangerous, especially when hundreds of repeats are
required to achieve a certain level of statistical signiﬁcance
in the veriﬁcation results. An alternative is a simulation-
based approach where the software controller of the CPS
is simulated with a virtual environment model. Though
it can reduce the cost and risk of the CPS goal veriﬁca-
tion compared to using FOTs, it requires a highly crafted

∗Corresponding author
Email addresses: yjshin@se.kaist.ac.kr (Yong-Jun Shin),
donghwan.shin@uni.lu (Donghwan Shin), bae@se.kaist.ac.kr
(Doo-Hwan Bae)

virtual environment model based on deep domain knowl-
edge. Furthermore, it may not be possible at all if a high-
ﬁdelity simulator for the problem domain does not exist. It
prevents the simulation-based approach from being better
used in practice.

To solve the diﬃculty of manually generating virtual
environment models, we propose an automated data-driven
environment model generation approach for CPS goal ver-
iﬁcation by recasting the problem of environment model
generation as the problem of imitation learning. We call
this novel approach ENVironment Imitation (ENVI ). In
machine learning, Imitation Learning (IL) has been widely
studied to mimic complex human behaviors in a given
task only from a limited amount of demonstrations [10].
Our approach leverages IL to mimic how the real envi-
ronment interacts with the CPS under analysis from a
small set of log data collected from FOTs. Since the log
data records how the CPS and the real environment inter-
acted, our approach can generate an environment model
that mimics a state transition mechanism of the real envi-
ronment according to the CPS action as closely as possible
to that recorded in the log data. The generated environ-
ment model is then used to simulate the CPS software
controller as many times as needed to statistically analyze
the CPS goal achievement.

We evaluate the feasibility of our novel approach while
comparing various imitation learning algorithms on a case

Preprint submitted to Journal of LATEX Templates

April 15, 2022

 
 
 
 
 
 
study of a lane-keeping system of an autonomous robot ve-
hicle. The evaluation results show that our approach can
automatically generate an environment model that mimics
the interaction mechanism between the lane-keeping sys-
tem and physical environment, even using minimal amounts
of FOT log data (e.g., less than 30 seconds execution log).
In summary, below are the contributions of this paper:

1) We shed light on the problem of environment model
generation for CPS goal veriﬁcation with a formal prob-
lem deﬁnition.

2) We propose ENVI, a novel data-driven approach for

environment model generation utilizing IL.

3) We assess the application of our approach through a
case study with a real CPS and various IL algorithms.

The remainder of this paper is organized as follows:
Section 2 illustrates a motivating example. Section 3 pro-
vides background on representative imitation learning al-
gorithms considered in our experiments. Section 4 formal-
izes the problem of the data-driven environment model
generation. Section 5 describes the steps of ENVI. Sec-
tion 6 reports on the evaluation of ENVI. Section 7 dis-
cusses implications and open issues. Section 8 introduces
related work. Section 9 concludes the paper.

2. Motivating Example

We present a simple example of CPS goal veriﬁcation

to demonstrate a use case of our approach.

Consider a software engineer developing a lane-keeping
system of an autonomous vehicle. The engineer aims to
develop and test the vehicle’s software controller (i.e., lane-
keeping system) that continuously monitors the distance
from the center of the lane and computes the steering angle
that determines how much to turn to keep the distance as
small as possible.

Once the software controller is developed, the engineer
must ensure that the vehicle equipped with the controller
continues to follow the center of the lane while driving.
To do this, the engineer deploys the vehicle on a safe road
and collect an FOT log, including the distance dt and the
steering angle at at time t = 1, . . . , T where T is a pre-
deﬁned FOT duration. Based on the collected data, the
engineer can quantitatively assess the quality of the lane-
keeping system by calculating the sum of the distances the
vehicle deviated from the center of the lane, i.e., ΣT
t=1|dt|.
The quantitative assessment is used to verify precisely a
goal of the system, i.e., whether ΣT
t=1|dt| < (cid:15) holds or not
for a small threshold (cid:15). Notice that, due to the uncertain-
ties in FOT, such as non-uniform friction between the tires
and the ground, the same FOT must be repeated multi-
ple times, and statistical analysis should be applied to the
results.

It takes a lot of time and resources to repeat the FOTs
enough to obtain statistically signiﬁcant results. To ad-
dress this issue, the engineer may decide to rely on sim-
ulations. However, using high-ﬁdelity and physics-based
simulators, such as Webots [11] or Gazebo [12], is very
challenging, especially for software engineers who do not
have enough expertise in physics. It is not easy to accu-
rately design the physical components of the system (e.g.,
the size of wheels and the wheelbase) and the road in the
simulator so that the simulation results are almost identi-
cal to the FOT results.

Our approach, ENVI, enables the CPS goal veriﬁcation
without using such a high-ﬁdelity simulator. The engi-
neer can simply provide ENVI with the software controller
(i.e., the lane-keeping system under analysis) and a small
amount of FOT logs collected from the beginning, which is
far less than the data required for statistically signiﬁcant
results using FOTs. Then ENVI automatically generates
a virtual environment model that imitates the behavior of
the real environment of the lane-keeping system; speciﬁ-
cally, the virtual environment model can simulate dt+1 for
given dt and at for t = 2, . . . , T such that ΣT
t=1|dt| calcu-
lated based on the virtual model is almost the same as the
value calculated based on the FOTs. Therefore, by quickly
re-running the simulation multiple times, the engineer can
have statistically signiﬁcant results about the quality of the
software controller at little cost. Furthermore, if multiple
software controller versions make diﬀerent CPS behaviors,
the virtual environment model generated by ENVI can be
reused to verify the CPS goal achievements of new con-
troller versions that have never been tested in the real
environment.

The challenge for ENVI is automatically generating
a virtual environment model that behaves as similar as
possible to the real environment using a limited amount
of data. To address this, we leverage imitation learning
detailed in Section 3.

3. Background: Imitation Learning

Imitation Learning (IL) is a learning method that al-
lows an agent to mimic expert behaviors for a speciﬁc task
by observing demonstrations of the expert [10]. For exam-
ple, an autonomous vehicle can learn to drive by observing
how a human driver controls a vehicle. IL assumes that
an expert decides an action depending on only the state
that the expert encounters. Based on this assumption, an
expert demonstration is a series of pairs of states and ac-
tions, and IL aims to extract the expert’s internal decision-
making function (i.e., a policy function that maps states
into actions) from the demonstration [10]. We introduce
two representative IL algorithms in the following subsec-
tions: Behavior Cloning (BC) and Generative Adversarial
Imitation Learning (GAIL).

2

3.1. Behavior Cloning

Behavior Cloning (BC) infers the policy function of the
expert using supervised learning [13, 14]. Training data
can be organized by pairing states and corresponding ac-
tions in the expert’s demonstration. Then existing super-
vised learning algorithms can train the policy function that
returns expert-like actions for given states. Due to the sim-
plicity of the BC algorithm, BC can create a good policy
function that mimics the expert quickly if there are suﬃ-
ciently much demonstration data. However, if the training
data (i.e., expert demonstration) does not fully cover the
input state space or is biased, the policy function may not
mimic the expert behavior correctly [14].

3.2. Generative Adversarial Imitation Learning

Generative Adversarial Imitation Learning (GAIL) [15]
utilizes the idea of Generative Adversarial Networks [16]
to evolve the policy function using iterative competitions
with a discriminator that evaluates the policy function.
Therefore, both the policy function and the discriminator
are trained in parallel.

The policy function gets states in the expert demon-
stration and produces simulated actions. The discrimina-
tor then gets the policy function’s input (i.e., states) and
output (i.e., simulated actions) and evaluates how the pol-
icy function behaves like the real expert, as shown in the
demonstration. The more similar the simulation is to the
expert demonstration, the more rewarded the policy func-
tion is by the discriminator. The policy function is trained
to maximize the reward from the discriminator.

On the other hand, the discriminator is trained using
both the demonstration data and the simulation trace of
the policy function. The state and action pairs, which is
the input and output of the policy function, in the demon-
stration data are labeled as real, but the pairs in the sim-
ulation trace are labeled as fake. A supervised learning
algorithm trains the discriminator to quantitatively eval-
uate whether a state and action pair is real (returning a
high reward) or fake (returning a low reward).

After numerous learning iterations of the policy func-
tion and the discriminator, the policy function ﬁnally mim-
ics the expert well to deceive the advanced discrimina-
tor. GAIL uses both the expert demonstration data and
the simulation trace data of the policy function generated
internally, so it works well even with small demonstra-
tion data [15]. However, because of the internal simula-
tion of the policy function, its learning speed is relatively
slow [17].

4. Problem Deﬁnition

This section introduces a mathematical framework for
modeling how the CPS under analysis interacts with its
environment to achieve its goals. Based on the formal
framework, we then deﬁne the environment model gener-
ation problem for CPS goal veriﬁcation.

Figure 1: Formal framework for CPS goal veriﬁcation

4.1. A Formal Framework for CPS Goal Veriﬁcation

A CPS achieves its goals by interacting with its physi-
cal environment. Speciﬁcally, starting from an initial state
of the environment, the CPS software controller observes
the state and decides an appropriate action to maximize
the likelihood of achieving the goals. Then, taking action
causes a change in the environment for the next step, which
the CPS will observe again to decide an action for the next
step. We assume the CPS and the environment interact
in a closed loop without interference by a third factor. To
formalize this process, we present a novel CPS-ENV in-
teraction model inspired by Markov Decision Process [18]
that models an agent’s sequential decision-making process
under observation over its environmental states.

Speciﬁcally, a CPS-ENV interaction model is a tuple
M = (S, A, π, δ, s0), where S is a set of observable states
of the environment under consideration, A is a set of pos-
sible CPS actions, π : S → A is a policy function that
captures the software controller of the CPS, δ : S × A → S
is a transition function that captures the transitions of en-
vironmental states over time as a result of CPS actions
and its previous states1, and s0 is an initial environmental
state. For example, starting from s0, the CPS makes an
action a0 = π(s0), leading to a next state s1 = δ(s0, a0).
By observing s1, the CPS again makes the next action
a1 = π(s1), and so on.

a2−→ ...

an−1−−−→ sn over n steps where st−1

For a CPS-ENV interaction model M = (S, A, π, δ, s0),
a1−→
a0−→ s1
we can think of a sequence of transitions s0
at−1−−−→ st denotes
s2
a transition from a state st−1 to another state st of the
environment by taking an action at−1 of the CPS. More
formally, we deﬁne a trajectory of M over T time ticks as
a sequence of tuples tr (M, T ) = (cid:104)(s0, a0), . . . , (sT , aT )(cid:105).

Since a trajectory of a CPS-ENV interaction model
concisely captures the sequential interaction between the
CPS under analysis and its environment, one can easily
verify whether CPS goals are achieved or not by analyz-
ing the trajectory. Figure 1 visualizes how a CPS-ENV
interaction model is used for simulation-based CPS goal

1Though we use deterministic policy and transition functions for
simplicity, they can be easily extended in terms of probability density,
i.e., π : S × A → [0, 1] and δ : S × A × S → [0, 1], to represent
stochastic behaviors if needed.

3

veriﬁcation. Speciﬁcally, let φ be a requirement that pre-
cisely speciﬁes a goal under veriﬁcation. The achievement
of φ is quantiﬁable. For a CPS-ENV interaction model M ,
the veriﬁcation result of φ for M , denoted by ψ(M, φ), is
computed by evaluating the achievement of φ on the tra-
jectory of M . Depending on the type of φ, the value of
ψ(M, φ) can be Boolean (expressing the success or failure
of a requirement with clear-cut criteria) or Float (express-
ing the measurement of an evaluation metric of φ). For
example, one of the evaluation metrics of the lane-keeping
requirement is the distance the vehicle is away from the
center of the lane. As a result of the veriﬁcation of the
lane-keeping goal, the average or maximum distance from
the center is computed.

4.2. Problem Statement

The problem of virtual environment model generation
for simulation-based CPS goal veriﬁcation is to ﬁnd an
accurate virtual environment model that can replace the
real environment of the CPS goal under veriﬁcation while
maintaining the same level of veriﬁcation accuracy. Specif-
ically, for the same CPS under analysis, let a CPS-ENV
interaction model Mr = (S, A, π, δr, s0) representing the
interaction between the CPS and its real environment (in
FOT) and another model Mv = (S, A, π, δv, s0) represent-
ing the interaction between the same CPS and its virtual
environment (in simulations). Notice that we have the
same S, A, π, and so for both Mr and Mv since they are
about the same CPS2, whereas δr and δv are diﬀerent since
they represent how the corresponding environments react
to the actions performed by the CPS. For a requirement φ,
we aim to have δv that minimizes the diﬀerence between
ψ(Mr, φ) and ψ(Mv, φ). Therefore, the problem of virtual
environment model generation for CPS goal veriﬁcation is
to ﬁnd δv such that |ψ(Mr, φ)−ψ(Mv, φ)| is the minimum.
The virtual environment model generation problem has
three major challenges. First, the number of possible states
and actions is often very large, making it infeasible to build
a virtual environment model (i.e., represented by a tran-
sition function δv : S × A → S) by exhaustively analyzing
individual states and actions. Second, since the virtual
environment model continuously interacts with the CPS
under analysis in a closed-loop, even a small diﬀerence be-
tween the virtual and real environments can signiﬁcantly
diﬀer in veriﬁcation results as it accumulates over time, the
so-called compounding error problem. This means that
simply having a transition function δv that mimics the be-
havior of δr in terms of individual input and output pairs,
without considering the accumulation of errors for sequen-
tial inputs, is not enough. Third, generating δv should not
be as expensive as using many FOTs; otherwise, there is
no point in using simulation-based CPS goal veriﬁcation.
Recall that manually crafting virtual environment mod-
els in a high-ﬁdelity simulator requires a lot of expertise,

2Note that S can be the same for Mr and Mv because it is a set
of observable states from the perspective of the CPS under analysis.

4

which takes longer than doing FOTs many times for hav-
ing statistically signiﬁcant veriﬁcation results. Therefore,
a practical approach should generate an accurate virtual
environment model eﬃciently and automatically.

To address the challenges mentioned above, we sug-
gest leveraging IL to automatically generate virtual envi-
ronment models from only a small amount of data. The
data is the partial trajectory of Mr, which can be collected
from a few FOTs for the CPS under test in its real appli-
cation environment. Since IL can eﬃciently extract how
experts make sequential actions for given states from a lim-
ited amount of demonstrations while minimizing the com-
pounding errors, it is expected to be an excellent match
to our problem. Therefore for our problem, IL will extract
δv, instead of π (which is the original goal of IL), that can
best reproduce given trajectories of Mr (i.e., FOT logs).
Generated δv may diﬀer depending on the amount of the
trajectory, so we analyze it in the experiment.

5. Environment Imitation

This section provides ENVI, a novel approach to the
problem of environment model generation for CPS goal
veriﬁcation, deﬁned in Section 4. We solve the problem
by using IL to automatically infer a virtual environment
state transition function from the log recorded during the
interaction between the CPS under test and its applica-
tion environment.
In this context, the real application
environment is considered an “expert,” and the FOT log
demonstrates the expert.

Figure 2 shows the overview of the environment model
generation and simulation-based CPS goal veriﬁcation pro-
cess using our approach.
It is composed of three main
stages: (1) FOT log collection for model generation, (2)
environment model generation using an IL algorithm, and
(3) CPS goal veriﬁcation using the generated environment
model. In the ﬁrst stage, engineers collect FOT logs of a
CPS controller under analysis π deployed in its real ap-
plication environment. The interaction between the CPS
and the real environment is abstracted as Mr, including
the unknown δr. The trajectory of Mr recorded in the
logs is then used by IL algorithms in the second stage to
generate a virtual environment model δv that imitates δr
automatically.
In the last stage, the simulation of π in
the virtual environment described by δv is performed to
generate simulation logs as many as needed for statistical
veriﬁcation. As a result, engineers can statistically verify
to what extent a requirement φ of the CPS is satisﬁed us-
ing only a few FOT logs. In the following subsections, we
explain each of the main steps in detail with the example
introduced in Section 2.

5.1. FOT Log Collection

The ﬁrst stage of ENVI is to collect the interaction
data between the CPS controller and its real environment,
which will be used as the “demonstrations” of imitation

Figure 2: Environment Imitation process and simulation-based CPS goal veriﬁcation

learning to generate the virtual environment later. For a
CPS-ENV interaction model Mr = (S, A, π, δr, s0) deﬁned
in Section 4, the interaction data collected over time T can
be represented as the trajectory of Mr over T steps, i.e.,
(cid:104)(s0, a0), (s1, a1), . . . , (sT , aT )(cid:105) where st+1 = δr(st, at) and
at = π(st) for t ∈ {0, 1, . . . , T − 1}. The trajectory can be
easily collected from an FOT, since it is common to record
the interaction between the CPS controller and its real
environment as an FOT log [19]. For example, the lane-
keeping system records time-series data of the distances
the vehicle deviated from the center of the lane dt and the
steering angles at over t = 0, 1, . . . , T during an FOT.

In practice, the trajectory of the same Mr is not nec-
essarily the same due to the uncertainty of the real envi-
ronment, such as the non-uniform surface friction. There-
fore, it is recommended to collect a few FOT logs for the
same Mr. Since the virtual environment model generated
by imitation learning will mimic the given trajectories as
much as possible, the uncertainty of the real environment
recorded in the trajectories will also be imitated. Section 6
will investigate to what extent virtual environment models
generated by ENVI can accurately mimic the real environ-
ment in terms of CPS goal veriﬁcation when the size of the
given FOT logs varies.

5.2. Environment Model Generation

The second stage of ENVI is to generate a virtual en-
vironment model from the collected FOT logs using an IL
algorithm.
It consists of two steps: (1) deﬁne the envi-
ronment model structure and (2) run an IL algorithm to
generate a trained model.

5.2.1. Deﬁning Environment Model Structure

We implement an environment model as a neural net-
work to leverage imitation learning. Before training the
environment model, users deﬁne the neural network struc-
ture.

The virtual environment model structure is based on
the environmental state transition function δ : S × A → S
deﬁned in Section 4. It assumes that the ideal (real) en-
vironment generates the next state st+1 ∈ S by taking
the current environment state st ∈ S and the current CPS

Figure 3: The environment model structure

action at ∈ A only, meaning that (st, at) is suﬃcient to de-
termine st+1 in the ideal environment at time t. However,
in practice, s may not include suﬃcient information since
it is observed by the sensors of the CPS under veriﬁcation
and the sensors have limited sensing capabilities. To solve
this issue, we extend δ for virtual environment models as
δv : (S × A)l → S where l is the length of the state-action
pairs required to predict the next state. This means that
δv uses (cid:104)(st−l+1, at−l+1), . . . , (st, at)(cid:105) to predict st+1. No-
tice that δv is equal to δ when l = 1. To account for the
extension of δ, we also extend the CPS-ENV interaction
model M = (S, A, π, δ, s0) to Mv = (S, A, π, δv, σ0) where
σ0 = (cid:104)(s0, a0), . . . , (sl−1, al−1)(cid:105) is a partial trajectory of
Mr over l steps starting from s0. Intuitively speaking, σ0
is the initial input for δv similar to s0 (and a0 = π(s0)) for
δ.

Based on the extended deﬁnition of δv, the structure
of δv is shown in Figure 3. The input and output of δv
are (cid:104)(st−l+1, at−l+1), . . . , (st, at)(cid:105) and st+1, respectively, as
deﬁned above. Recall that an environmental state s and
a CPS action a can be vectors in general; let |x| be the
length of a vector x. Then, the number of input neurons
of the neural network is l × (|s| + |a|), and the number of
output neurons is |s|.

Deﬁning the environment model structure involves two

5

manual tasks. The ﬁrst task is to choose a proper value
for the history length l. If the value of l increases, more
information can be captured in environmental states while
the cost of training and executing δv increases. Therefore,
it is important to balance the amount of information and
the cost of computation. For example, one can visualize
the FOT log and see if there are any cyclic patterns in the
sequence of environmental states. The second task is to
design the hidden layers of δv. The hidden layers specify
how the output variables are calculated from the input
variables, so-called forward propagation. The design of
hidden layers is speciﬁc to a domain, but general guidelines
of the neural network design exist for practitioners [20–22].

5.2.2. Environment Model Training using IL Algorithms
Once the structure of δv is determined, we can train
δv using an IL algorithm with a proper set of training
data D = {(X1, Y1), . . . , (Xn, Yn)}, where n is the number
of FOT logs, Xi is the sequence of inputs collected from
i-th FOT log and Yi is the corresponding sequence of out-
puts (i.e., the expected value of δv(xj) is yj for all j ∈
{1, . . . , |Xi|} and |Xi| = |Yi| for i ∈ {1, . . . , n}). Since x ∈
X is an l-length sequence of state-action pairs, we can gen-
erate D from an FOT log using a sliding window of length
l. Speciﬁcally, for an FOT log (cid:104)(s0, a0), . . . , (sT , aT )(cid:105), xj =
(cid:104)(sj, aj), . . . , (sl−j+1, al−j+1)(cid:105) for j ∈ {0, . . . , T − l + 1}.

In the following subsections, we explain how each of
the representative IL algorithms, i.e., BC, GAIL, and the
combination of BC and GAIL, can be used for training δv.

Using BC. As described in Section 3.1, BC trains an
environment model δv using supervised learning. Pairs of
the input and output of the real environment recorded in
FOT logs are given to δv as training data, and δv is trained
to learn the real environment state transition shown in the
training data.

Speciﬁcally, the BC algorithm (whose pseudocode is
shown in Algorithm 1) takes as input a randomly initial-
ized environment model δv and a training dataset D; it
returns an environment model δv trained using D.

Algorithm 1: ENVI BC algorithm

Input : ENV model (randomly initialized) δv,

Training data D = {(X1, Y1), . . . , (Xn, Yn)}

Output: ENV model (trained) δv
1 while not(stoping condition) do
foreach (X, Y ) ∈ D do
2

3

4

5

Sequence of model outputs Y (cid:48) ← δv(X)
Float loss BC ← getLoss(Y, Y (cid:48))
δv ← update(δv, loss BC )

end

6
7 end
8 return δv

(X, Y ) ∈ D, the algorithm repeats the following (lines 2–
6): (1) executing δv on X to predict a sequence of outputs
Y (cid:48) (line 3), (2) calculating the training loss lossBC based
on the diﬀerence between Y (cid:48) and Y (line 4), and (3) up-
dating δv to minimize lossBC (line 5). The algorithm ends
by returning δv (line 8).

Algorithm 1 is intuitive and easy to implement.
In
addition, the model’s loss converges fast because it is a
supervised learning approach. However, if the training
data does not fully cover the input space or is biased, the
model may not accurately imitate the real environment.

Using GAIL. As described in Section 3.2, GAIL itera-
tively trains not only δv but also the discriminator ζ that
evaluates δv in terms of the CPS controller π. Speciﬁcally,
for a state s, ζ evaluates δv with respect to δr (captured by
D) by comparing δv(s, π(s)) and δr(s, π(s)). To do this,
ζ is trained using D by supervised learning3, and δv is
trained using the evaluation results of ζ.

Algorithm 2 shows the pseudocode of GAIL. Similar
to Algorithm 1, it takes as input a randomly initialized
environment model δv and a training dataset D = (X, Y );
however, it additionally takes as input a randomly initial-
ized discriminator ζ and the CPS controller under analysis
π. It returns a trained virtual environment model δv.

Algorithm 2: ENVI GAIL algorithm

Input : ENV model (randomly initialized) δv,
Discriminator (randomly initialized) ζ,
Function of CPS decision-making logic π,
Training data D = {(X1, Y1), . . . , (Xn, Yn)}

Output: ENV model (trained) δv
1 while not(stoping condition) do
foreach (X, Y ) ∈ D do
2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

// Discriminator training
Sequence of model outputs Y (cid:48) ← δv(X)
Float loss d ← getDisLoss(ζ, X, Y, Y (cid:48))
ζ ← update(ζ, loss d)

// Environment model training
Sequence of model rewards R ← ∅
Model input x(cid:48) ← X[0]
for |X| − 1 do

Model output y(cid:48) ← δv(x(cid:48))
Reward r ← ζ(x(cid:48), y(cid:48))
R ← append (R, r)
CPS action a ← π(y(cid:48))
x(cid:48) ← updateInput(x(cid:48), y(cid:48), a)

end
Float loss GAIL ← aggregate(R)
δv ← update(δv, loss GAIL)

end

17
18 end
19 return δv

The algorithm iteratively trains δv using D until a stop-
ping condition (e.g., a ﬁxed number of iterations or con-
vergence of the model’s loss) is met (lines 1–7). For each

3The structure of ζ is similar to δv, but the input of ζ is

(s, δv(s, π(s)) and the output of ζ is a reward value r.

6

The algorithm iteratively trains both δv and ζ using
D and π until a stopping condition is met (lines 1–18).
To train ζ, for each (X, Y ) ∈ D (lines 2–17), the algo-
rithm executes δv on X to predict a sequence of outputs
Y (cid:48) (line 3), calculates the discriminator loss loss d indicat-
ing how well ζ can distinguish Y and Y (cid:48) for X (line 4),
and updates ζ using loss d (line 5). Once ζ is updated,
the algorithm trains δv using ζ and π (lines 6–16). Specif-
ically, the algorithm initializes a sequence of rewards R
(line 6) and a model input x(cid:48) (line 7), collects r ∈ R for
each x(cid:48) using δv, π, and ζ (lines 8–14), calculates the envi-
ronment model loss lossGAIL by aggregating R (line 15),
and updates δv using lossGAIL (line 16). To collect r ∈ R
for each x(cid:48) (lines 8–14), the algorithm executes δv on x(cid:48)
to predict an output y(cid:48) (line 9), executes ζ on x(cid:48) and
y(cid:48) to get a reward r (line 10), appends r at the end of
R (line 11), executes π on y(cid:48) to decide a CPS action a
(line 12), and updates x(cid:48) = (cid:104)(s1, a1), (s2, a2) . . . , (sl, al)(cid:105)
as x(cid:48) = (cid:104)(s2, a2) . . . , (sl, al), (y(cid:48), a)(cid:105) by removing (s1, a1)
and appending (y(cid:48), a) (line 13). The algorithm ends by
returning δv (line 19).

Notice that, to train δv, GAIL uses the input-output
pair (x(cid:48), y(cid:48)) simulated by π and ζ, in addition to the real
input-output pair (x, y) in D. This is why it is known to
work well even with a small amount of training data [15,
17]. However, the algorithm is more complex to implement
than BC, and the environment model converges slowly or
sometimes fails to converge depending on hyperparameter
values.

Using BC and GAIL together. Notice that BC trains
δv using the training data only, but GAIL trains δv using
the simulated data as well; BC and GAIL can be combined
to use both training and simulated data without algorith-
mic conﬂict. This idea is suggested by Ho and Ermon [15]
to improve learning performance, and Jena et al. [17] later
implemented the idea as an algorithm BCxGAIL.

The BCxGAIL algorithm is the same as GAIL in terms
of its input and output, and it also trains both δv and ζ
similar to GAIL. In particular, ζ is updated as the same as
in GAIL. However, δv is updated using both loss BC (line
4 in Algorithm 1) and loss GAIL (line 15 in Algorithm 2).
By doing so, BCxGAIL can converge fast (similar to BC)
with a small amount of training data (similar to GAIL).

5.3. Simulation-based CPS Goal Veriﬁcation

Using the virtual environment model δv generated from
the previous stage, an engineer can statistically verify if
the CPS controller π under analysis satisﬁes a goal φ (i.e.,
compute ψ(Mv, φ)) through many simulations of Mv =
(S, A, π, δv, σ0).

To simulate Mv, the initialization data σ0 should be
given. Since σ0 is the partial trajectory of Mr over l steps,
the engineer should conduct partial FOTs over l steps to
get σ0. Notice that acquiring σ0 is much cheaper than hav-
ing full FOTs for FOT-based CPS goal veriﬁcation since
l is much shorter than T (i.e., the full FOT duration).

The engineer then run Mv as many times as needed for
statistical veriﬁcation4. For example, to verify if a vehicle
equipped with a lane-keeping system under development is
not more than 1 m away from the center of the lane, engi-
neers simulate the lane-keeping system several times with
the generated environment model. The engineers then an-
alyze the distance farthest from the center of the lane in
each simulation and verify whether the requirement is sta-
tistically satisﬁed.

In practice, it is common to develop multiple versions of
the same CPS controller, for example, developed sequen-
tially during its evolutionary development [23–25]. Let
us consider a lane-keeping system controller implemented
with a conﬁguration parameter indicating the minimum
degree of steering for lane-keeping. Then, one can develop
a new version of the lane-keeping system by changing the
parameter value based on the CPS goal veriﬁcation results
of its previous versions. In such an evolutionary develop-
ment process, for the veriﬁcation of the new version, we
can consider diﬀerent use cases depending on which ver-
sion of the FOT logs is used to generate the environment
model. Speciﬁcally, we can consider three diﬀerent use
cases:

Case 1: One version is used for training, and veriﬁcation
is performed on the same version as training. This is the
basic use case, shown in Figure 4 (a). For example, for the
veriﬁcation of the ﬁrst version of the lane-keeping system
controller, some FOT logs of that version must be collected
since there are no previous versions (and their FOT logs).
Since Training involves One version and Veriﬁcation is for
the Known version, we refer to this case TOVK.

Case 2: Multiple versions are used for training, and veri-
ﬁcation is performed on one of the versions used for train-
ing. Multiple versions of the CPS controller can be used
for training, as shown in Figure 4 (b). For example, when
there are diﬀerent sets of FOT logs collected by previously
developed versions of the lane-keeping system in addition
to the FOT logs collected by the new version, all the logs
associated with diﬀerent parameter values can be used to-
gether to generate a single environment model. This al-
lows us to best utilize all FOT logs for virtual environ-
ment model generation. Since Training involves Multiple
versions and Veriﬁcation is for one of the Known versions,
we refer to this case TMVK.

Case 3: Multiple versions are used for training, and veri-
ﬁcation is performed on a new version that has never been
used for training. As shown in Figure 4 (c), this is sim-
ilar to the TMVK use case, but without using FOT logs
collected by the new version.
In other words, only the
previously collected FOT logs are used for the veriﬁcation
of the new version. This allows us to signiﬁcantly reduce

4This is because δv can be non-deterministic and the same σ0 can

lead to diﬀerent simulation results.

7

Figure 4: Use cases of simulation-based veriﬁcation using ENVI

the cost of new FOTs for the new version for CPS goal
veriﬁcation. Since Training involves Multiple versions and
Veriﬁcation is for an Unknown version, we refer to this
case TMVU.

6. Case Study

This section provides a case study to evaluate the ap-
plicability of our approach in various use cases introduced
in Section 5.3. Speciﬁcally, we ﬁrst investigate the accu-
racy of CPS goal veriﬁcation results when ENVI is used
for a single CPS controller version (i.e., the TOVK use
case). We then analyze if ENVI can eﬃciently generate
a single environment model that can be used for the CPS
goal veriﬁcation of multiple CPS controller versions (i.e.,
the TMVK use case). Last but not least, we also investi-
gate if the single environment model can be used for the
CPS goal veriﬁcation of a new CPS controller version that
has never been used for training (i.e., the TMVU use case).
To summarize, we answer the following research questions:

RQ1: Can ENVI generate a virtual environment model
that can replace the real environment in the CPS
goal veriﬁcation for a single CPS controller version?
(TOVK )

RQ2: Can ENVI generate a virtual environment model
that can replace the real environment in the CPS
goal veriﬁcation for multiple CPS controller ver-
sions? (TMVK )

RQ3: Can ENVI generate a virtual environment model
that can replace the real environment in the CPS
goal veriﬁcation for a new CPS controller version?
(TMVU )

6.1. Subject CPS

To answer the research questions in the context of a
real CPS development process, we implement a simpliﬁed
autonomous vehicle equipped with a lane-keeping system.

8

Figure 5: Case study subject CPS: a LEGO-lized autonomous vehicle

We utilize an open physical experimental environment [26]
that abstracts an autonomous vehicle as a programmable
LEGO robot and a road as a white and black paper lane,
as shown in Figure 5. The goal of the lane-keeping system
is to keep the center of the lane, indicated by the border
between white and black areas while driving, so we aim
to verify the goal achievement of the lane-keeping system
(e.g., how smoothly it drives following the lane center).
Similar to many other CPS, the LEGO-lized autonomous
vehicle comprises three parts: sensor, controller, and ac-
tuator. A sensor (e.g., a color sensor) gives data observing
the CPS environment to a controller. A controller (e.g.,
a Python program in a LEGO brick) controls actuators
(e.g., a motor of a wheel) that make CPS act.

As for the controller, we aim to consider multiple ver-
sions of the same lane-keeping system and compare them
using simulation-based CPS goal veriﬁcation to ﬁnd the
best one that allows the ego vehicle to drive the smoothest
along the center of the lane. To do this, we develop a
template of rule-based lane-keeping system logic and in-
stantiate it into multiple versions of the same lane-keeping
system with diﬀerent parameter values. Algorithm 3 shows
the template logic with a conﬁgurable parameter x indi-
cating the degree of rotation; the algorithm takes as input
a color c (range from 0 meaning the darkest to 100 mean-
ing the brightest) from the color sensor and returns an
angle a for the rotation motor. Positive/negative angle
means turning right/left, respectively. The algorithm sim-
ply turns right if the value of c is greater than 50 (i.e., the
color is darker than gray) and turns left if the value of c is
less than 50 (i.e., the color is lighter than gray); otherwise
(i.e., the color is exact gray), the algorithm goes straight.
The parameter value of x determines the degree of turning
right and left. We consider ﬁve diﬀerent parameter values
of x, i.e., from 10◦ to 50◦ in steps of 10◦ in our case study.
Although the algorithm simpliﬁes the logic of lane-
keeping systems with a conﬁguration parameter x, making
a parameterized controller and optimizing the controller’s
conﬁguration are common in practice [27, 28].
In addi-
tion, engineers experience that changing the conﬁguration
changes the CPS behavior in the real environment. Fig-
ure 6 shows the partial FOT logs of the lane-keeping sys-
tem with diﬀerent x values used in our case study; we can
see how the interaction between the lane-keeping system

Algorithm 3: Lane-keeping system controller logic
Conﬁg.: Positive ﬂoat of unit rotation degree x
Input : Float of lane color value c
Output: Float of rotation angle value a

1 Float gray ← 50
2 if c > gray then
a ← x
3
4 end
5 else if c < gray then
6
7 end
8 else
9

a ← −x

a ← 0

// Turn right

// Turn left

// Go straight

10 end
11 return a

Figure 7: Driving quality metrics in a lane-keeping system log

the vehicle stays in the lane center thresholds

2) total steady-state duration (cid:80)sc

i=1 sdi:

indicating how

long the vehicle stays in the lane center thresholds
3) number of overshooting oc: indicating how many times
the vehicle overshoots the upper threshold of the lane
center

4) sum of overshooting amplitudes (cid:80)oc
how much the vehicle overshoots
5) total overshooting duration (cid:80)oc
long the vehicle overshoots

i=1 odi:

i=1 oai:

indicating

indicating how

Figure 6: Diﬀerent interactions between the CPS and its real envi-
ronment depending on diﬀerent CPS controller versions

and the real environment varies depending on the value of
x.

Based on Algorithm 3, we implement ﬁve diﬀerent CPS
controllers to cover the three use cases (i.e., TOVK, TMVK,
and TMVU) described in Section 5.3. Speciﬁcally, we fol-
low an evolutionary development [24] scenario where (1)
a CPS controller with x = 30◦ is developed, and its goal
achievement is veriﬁed ﬁrst (i.e., TOVK), (2) two versions
with x = 10◦, and x = 50◦ are additionally developed,
and an environment model is generated using FOT logs of
x = 10◦, x = 30◦, and x = 50◦ together and is used to
verify each developed version (i.e., TMVK), and (3) two
more versions with x = 20◦ and x = 40◦ are additionally
developed, and their goal achievements are veriﬁed using
the previously generated virtual environment model with-
out using any FOT logs for x = 20◦ and x = 40◦ (i.e.,
TMVU).

To assess the goal achievement of the diﬀerent CPS
controllers (i.e., how smoothly the vehicle drives following
the lane), we deﬁne multiple driving performance metrics
by investigating driving traces collected during our prelim-
inary experiments [26, 29]. Speciﬁcally, given time length
T , eight driving quality metrics are deﬁned as follows (vi-
sualized in Figure 7):
1) number of steady-state sc: indicating how many times

6) number of undershooting uc: indicating how many times
the vehicle undershoots the lower threshold of the lane
center

7) sum of undershooting amplitudes (cid:80)uc
how much the vehicle undershoots
8) total undershooting duration (cid:80)uc
long the vehicle undershoots

i=1 uai: indicating

i=1 udi: indicating how

It is straightforward that the smaller the metrics about
the overshooting and undershooting (i.e., metric 3–8), the
better. In addition, if the vehicle does not deviate from
the lane center, the steady-state continues uninterrupted,
and its duration becomes T . Therefore, at the ideal case
(e.g., driving exactly on the lane center), the ﬁrst metric
sc = 1, the second metric (cid:80)sc
i=1 sdi = T , and the other
metrics are all 0.

6.2. ENVI Experimental Setup

As described in Section 5, the CPS goal veriﬁcation
using ENVI follows three main stages: (1) FOT log collec-
tion, (2) environment model generation, and (3) simulation-
based CPS goal veriﬁcation. In the following subsections,
we explain our experimental setup for each stage in detail.

6.2.1. FOT Log Collection

For each of the ﬁve CPS controller versions, we conduct
30 FOTs of the simpliﬁed autonomous vehicle and collect
30 logs to capture how the vehicle interacts with the real
environment. At each time t, the following information
is recorded in the logs: (1) a lane color value ct as an
environmental state observed by the vehicle’s color sensor
and (2) a steering angle at as a CPS action decided by the
vehicle’s controller. Therefore, an FOT log is a sequence of

9

       7 L P H                 / D Q H  F R O R Ux=10°x=20°x=30°x=40°x=50°Table 1: Hyperparameter values for IL algorithms

Table 3: Discriminator structure

Algorithm Hyperparameter

BC

Epoch
Learning rate

GAIL

Epoch
Model learning rate
PPO num. policy iteration
Discriminator learning rate
PPO num. discriminator iteration
PPO reward discount γ
PPO GAE parameter λ
PPO clipping (cid:15)

Value

300
0.00005

300
0.00005
10
0.01
10
0.99
0.95
0.2

Table 2: Environment model structure

# layer

# output units

input
fully connected layer
tanh
fully connected layer
tanh
fully connected layer
tanh

1
2
3
4
5
6

20
256
256
256
256
1
1

state-action pairs (cid:104)(c0, a0), (c1, a1), . . . , (cT , aT )(cid:105) where T
is the FOT duration. According to the vehicle’s hardware
spec, it records 25 state-action pairs per one second. Since
a sequence of 25 state-action pairs is enough to observe
the behavior of a CPS controller, we set T to 25 (i.e., one
FOT log is collected by one second).

6.2.2. Environment Model Generation

To investigate the impact of using diﬀerent IL algo-
rithms, we generate diﬀerent environment models using
BC, GAIL, and BCxGAIL. We implement the algorithms
in PyTorch [30]. BC uses the ADAM optimizer [31] to
update environment models. Since GAIL needs a pol-
icy gradient algorithm to update models [15], we use a
state-of-the-art Proximal Policy Optimization (PPO) al-
gorithm [32]. As for the hyperparameters of the IL algo-
rithms, we best use default values from the original pa-
pers [15, 32]. Table 1 shows the hyperparameter values
used in our evaluation.

As for the model structure, we set the length of history
l as 10, meaning that the input of a virtual environment
model is a 20-dimensional vector (i.e., a sequence of 10
state-action pairs). We use a simple design for hidden lay-
ers for both the virtual environment model and discrimi-
nator. Tables 2 and 3 summarize the structures of virtual
environment model and discriminator, respectively.

As for the model training, to better understand the
training data eﬃciency of each of the IL algorithms, we
vary the number of FOT logs to be used and compare
the resulting models. Speciﬁcally, among the 30 FOT logs
collected in Section 6.2.1, we randomly select n logs for
training a virtual environment model and vary n from 3
to 30 in steps of 3. For all models, normalized state and

10

# layer

# output units

input
fully connected layer
ReLU
fully connected layer
ReLU
fully connected layer
Sigmoid

1
2
3
4
5
6

21
256
256
256
256
1
1

action values (ranging between −1 and +1) recorded in
the FOT logs are used for training.

6.2.3. Simulation-based CPS Goal Veriﬁcation

To verify the CPS goal achievement, each of the ﬁve
CPS controller versions is simulated multiple times with
the environment models generated by ENVI, and the sim-
ulation logs are used to assess the degree of CPS goal
achievement in terms of the eight driving performance
metrics deﬁned in Section 6.1.

6.3. CPS Goal Veriﬁcation Accuracy

To evaluate how accurate the simulation-based veriﬁ-
cation using ENVI is with respect to the FOT-based veriﬁ-
cation using enough FOTs for a set of veriﬁcation require-
ments, we measure the similarity between the FOT-based
veriﬁcation and simulation-based veriﬁcation results. Specif-
ically, for a set of CPS goals (requirements) Φ, the CPS
goal veriﬁcation accuracy acc of a virtual environment
model δv for the CPS (controller) πx is deﬁned as

acc(δv, πx) = 1 −

Σφ∈Φ|ψ(Mx,r, φ) − ψ(Mx,v, φ)|
|Φ|

where Mx,r = (S, A, πx, δr, s0) represents the interaction
between the CPS under veriﬁcation (represented by πx)
and its real environment and Mx,v = (S, A, πx, δv, σ0) rep-
resents the interaction between the same CPS and δv. As
for the set of requirements Φ, we consider eight CPS goals
(requirements) φ1, φ2, . . . , φ8 based on the eight driving
performance metrics deﬁned Section 6.1. Since individual
requirements φ ∈ Φ have diﬀerent ranges, we normalize
ψ(·, φ) to a value between 0 and 1 using the possible min-
imum and maximum values. As a result, acc(δv) ranges
between 0 and 1; the higher its value, the more accurate
the virtual environment model.

To compute ψ(Mr, φ) for φ ∈ Φ, we perform 100 FOTs
using our autonomous robot vehicle and collect the FOT
logs. Note that these logs are for evaluating the simulation-
based veriﬁcation accuracy, and therefore diﬀerent from
the 30 FOT logs used for training virtual environment
models described in Section 6.2.

To compute ψ(Mv, φ) for φ ∈ Φ, we perform 100 sim-
ulations using a virtual environment model δv generated
by ENVI. To make the FOT-based veriﬁcation and the
simulation-based veriﬁcation compatible, the same initials

σ0 must be used. To achieve this, we provide δv with the
initial ten pairs of states and actions of each of the 100
FOT logs as σ0 for each simulation.

Notice that σ0 is the only real data given to δv to com-
pute ψ(Mv, φ). From δv’s point of view, the CPS under
veriﬁcation πx is black-box and the value of its conﬁgu-
ration parameter x is unknown to δv, meaning that δv
predicts how the real environment continuously interacts
with a black-box πx given σ0 only.

To account for the randomness in measuring ψ(Mr, φ)
and ψ(Mv, φ), we repeat the experiment 30 times and re-
port the average.

6.4. Comparison Baseline

It is ideal to compare ENVI with other existing envi-
ronment model generation approaches. However, to the
best of our knowledge, there is no such approach. There-
fore, we make a random environment model for an alterna-
tive comparison baseline. The random environment model
changes the environmental state randomly regardless of
CPS actions. As a result, in addition to the three IL al-
gorithms, we use four diﬀerent virtual environment model
generation approaches (BC, GAIL, BCxGAIL, and Ran-
dom) and compare them in terms of acc.

6.5. Experiment Results

6.5.1. RQ1: TOVK Use Case

RQ1 aims to evaluate whether ENVI can generate a
virtual environment model for the CPS goal veriﬁcation
of a single CPS controller version. To answer RQ1, we
generate a virtual environment model δv,30◦ using the FOT
logs of the controller version with x = 30◦ and measure
acc(δv,30◦ , π30◦ ) where π30◦ indicates the CPS controller
version with x = 30◦.

Before we investigate acc(δv,30◦ , π30◦ ) with diﬀerent
conﬁgurations (i.e., the diﬀerent model generation algo-
rithms and the diﬀerent numbers of FOT logs used for
training), we ﬁrst visualize the behaviors of the real and
virtual environments when interacting with the CPS. Fig-
ure 8 shows the behaviors of real (red) and virtual (blue)
environments in terms of the environmental states (y-axis)
generated by the continuous interaction with the lane-
keeping system over time (x-axis), when the number of
FOT logs used for training is 3 (Figure 8(a)), 15 (Fig-
ure 8(b)), and 30 (Figure 8(c)). When compared to ran-
dom, we can see that BC, GAIL, and BCxGAIL gener-
ate virtual environment models that can closely mimic the
real environment. Considering the fact that a slight diﬀer-
ence between the virtual and real lane colors at a moment
can be accumulated over time due to the closed-loop in-
teraction between the virtual environment model and the
lane-keeping system, the visualization shows that all the
IL algorithms can learn how the real environment inter-
acts with the lane-keeping system over time without sig-
niﬁcant errors. Moreover, for each of the IL algorithms,
the more FOT logs are used, the closer the virtual and real

11

Table 4: Veriﬁcation accuracy results for the TOVK use case. The
best accuracy for each number of FOT logs is highlighted in bold.

Algorithm Logs

acc(δv,30◦ , π30◦ )

Random

-

BCxGAIL

GAIL

BC

3
15
30

3
15
30

3
15
30

82.47%

98.69%
99.20%
99.30%

96.15%
97.62%
97.83%

97.53%
97.27%
97.49%

environment models’ behaviors are. Given the promising
visualization results, we continue to investigate the CPS
goal veriﬁcation accuracy below.

Figure 9 shows how the CPS goal veriﬁcation accuracy
varies depending on the number of FOT logs used for train-
ing the virtual environment model when diﬀerent model
generation algorithms are used. Table 4 additionally pro-
vides the accuracy values for representative cases (i.e.,
when the number of FOT logs is 3, 15, and 30). Overall,
due to the characteristics of the eight driving performance
metrics and their normalizations, the random approach’s
veriﬁcation accuracy is around 82.5%. Nevertheless, all
environment models generated by ENVI achieve higher
than 96% veriﬁcation accuracy, which is much higher than
that of the random approach. This means that the IL al-
gorithms used in ENVI are signiﬁcantly better than the
random baseline in terms of generating accurate virtual
environment models. Regarding the training data eﬃ-
ciency, the veriﬁcation accuracy only slightly increases as
the number of used FOT logs increases,
implying that
ENVI can generate an accurate environment model using
even a very small number of FOT logs (e.g., three). Com-
paring the IL algorithms, we can clearly see that BCxGAIL
outperforms the others regardless of the number of used
FOT logs. This is because the convergence speed and data
eﬃciency of the model training have been complemented
by using BC and GAIL algorithms together, as explained
in Section 5.2. This suggests that engineers can expect
the highest model accuracy in this use case through the
BCxGAIL algorithm.

The answer to RQ1 is that ENVI can generate an
accurate virtual environment model that can re-
place the real environment in FOTs using only a
small number of FOT logs. Among the three IL
algorithms used in ENVI, BCxGAIL outperforms
the others in terms of the CPS goal veriﬁcation ac-
curacy.

Figure 8: Comparison of real (i.e., FOT) and simulation log data

6.5.2. RQ2: TMVK Use Case

RQ2 aims to evaluate whether ENVI can generate a
virtual environment model for the CPS goal veriﬁcation
of multiple CPS controller versions. To answer RQ2, we
measure the veriﬁcation accuracy of the same virtual envi-
ronment model for diﬀerent lane-keeping system controller
versions. Speciﬁcally, we ﬁrst train δv,10◦|30◦|50◦ using the
FOT logs of three lane-keeping system controller versions
(i.e., x = 10◦, x = 30◦, and x = 50◦) and then assess
acc(δv,10◦|30◦|50◦ , πx) for each x ∈ {10◦, 30◦, 50◦}.

Figure 10 shows the veriﬁcation accuracy results de-
pending on the number of training FOT logs for the three
diﬀerent controller versions. Table 5 provides the accuracy
values when the number of FOT logs is 3, 15, and 30. In
the table, the best accuracy for each controller version and
the number of FOT logs is highlighted in bold. Overall,
the virtual environment models generated by ENVI using
the FOT logs of multiple controller versions achieve much
higher veriﬁcation accuracy (at least 95%) than the ran-
dom model, even when only a few FOT logs are used for
training them. Considering the diﬀerent interaction pat-
terns for diﬀerent CPS controller versions as shown in Fig-
ure 6, the high veriﬁcation accuracy indicates that, even
with small FOT logs, the IL algorithms can learn how the

12

Figure 9: Veriﬁcation accuracy of environment model generation ap-
proaches for TOVK use case

                  1 X P E H U  R I  ) 2 7  O R J V                                  9 H U L I L F D W L R Q  D F F X U D F \     ) 2 7 5 D Q G R P % &  [  * $ , / * $ , / % &Table 5: Veriﬁcation accuracy results for the TMVK use case. The
best accuracy for each number of FOT logs and for each controller
is highlighted in bold.

Algorithm Logs

acc(δv,10◦|30◦|50◦ , πx)
x = 30◦

x = 50◦

x = 10◦

Avg.

Random

BCxGAIL

GAIL

BC

-

3
15
30

3
15
30

3
15
30

69.63%

82.04%

80.96%

77.54%

97.38% 98.78% 98.54% 98.23%
96.95% 99.20% 99.24% 98.46%
97.47% 99.33% 99.34% 98.71%

96.16%
98.21%
98.52%

95.77%
96.14%
97.17%

96.64%
98.32%
98.59%

97.74%
97.91%
98.15%

97.25%
97.92%
98.80%

97.80%
97.85%
97.71%

96.68%
98.15%
98.63%

97.10%
97.30%
97.67%

real environment interacts with diﬀerent CPS controller
versions and generate a single virtual environment model
that covers all the diﬀerent interaction patterns. Com-
paring the IL algorithms, BCxGAIL generates the most
accurate environment models using the same number of
logs than the other algorithms in general, whereas GAIL
sometimes outperforms BCxGAIL when x = 10◦ and BC
never outperforms the others. This is because GAIL can
infer an accurate environment model with small training
data (e.g., less than 30) better than BC, as already demon-
strated by Ho and Ermon [15].

The answer to RQ2 is that ENVI can generate an
accurate virtual environment model that can be
shared in the CPS goal veriﬁcation of diﬀerent CPS
controller versions. Among the IL algorithms used
in ENVI, BCxGAIL generally outperforms the oth-
ers in terms of the CPS goal veriﬁcation accuracy.

6.5.3. RQ3: TMVU Use Case

RQ3 aims to evaluate whether ENVI can generate a
virtual environment model for the CPS goal veriﬁcation of
a new controller version that has never been used for train-
ing the model. To answer RQ3, we measure the veriﬁcation
accuracy of the virtual environment models generated by
multiple controller versions for a new controller version.
Speciﬁcally, we ﬁrst generate δv,10◦|30◦|50◦ as the same as
RQ2 and then assess acc(δv,10◦|30◦|50◦ , πx) for each new
x ∈ {20◦, 40◦}.

Similar to RQ2, Figure 11 and Table 6 show the veriﬁ-
cation accuracy results. In all cases, δv,10◦|30◦|50◦ achieves
more than 96% accuracy, which is much higher than ran-
dom. This means that the virtual environment model gen-
erated using the FOT logs of the previously developed CPS
controller versions (x = 10◦, x = 30◦, and x = 50◦) can
be used for the CPS goal veriﬁcation for newly developed
versions (x = 20◦ and x = 40◦) with high accuracy. This
implies that the virtual environment model can learn inter-
action patterns between the real environment and diﬀerent

(a) Controller under veriﬁcation x = 10◦

(b) Controller under veriﬁcation x = 30◦

(c) Controller under veriﬁcation x = 50◦

Figure 10: Veriﬁcation accuracy of environment model generation
approaches for TMVK use case

13

                  1 X P E H U  R I  ) 2 7  O R J V                9 H U L I L F D W L R Q  D F F X U D F \     ) 2 7 5 D Q G R P % &  [  * $ , / * $ , / % &                  1 X P E H U  R I  ) 2 7  O R J V                9 H U L I L F D W L R Q  D F F X U D F \     ) 2 7 5 D Q G R P % &  [  * $ , / * $ , / % &                  1 X P E H U  R I  ) 2 7  O R J V                9 H U L I L F D W L R Q  D F F X U D F \     ) 2 7 5 D Q G R P % &  [  * $ , / * $ , / % &Table 6: Veriﬁcation accuracy results for the TMVU use case. The
best accuracy for each number of FOT logs and for each controller
is highlighted in bold.

Algorithm Logs

Random

BCxGAIL

GAIL

BC

-

3
15
30

3
15
30

3
15
30

acc(δv,10◦|30◦|50◦ , πx)
x = 40◦
x = 20◦

avg.

79.63%

81.60%

80.61%

98.44%
97.47%
97.51%

97.03%
98.94%
99.21%

97.09%
96.62%
96.71%

98.76% 98.60%
98.40%
99.32%
98.52%
99.53%

96.85%
96.94%
98.18% 98.56%
98.73% 98.97%

97.79%
98.18%
98.03%

97.44%
97.40%
97.37%

The answer to RQ3 is that ENVI can generate
an accurate virtual environment model to verify
unknown controller versions that have never been
ﬁeld-tested for training. Regarding the IL algo-
rithms, BCxGAIL and GAIL outperform BC in all
cases.

6.6. Threats to Validity

In terms of external validity, our case study focused
on only a lane-keeping system in a simpliﬁed CPS im-
plemented as a LEGO-lized autonomous vehicle and used
only one parameter (i.e., the degree of rotations x) for
representing diﬀerent versions of software controllers. Al-
though the subject CPS of our case study may diﬀer from
the real CPS (e.g., autonomous vehicle), our simpliﬁed
CPS represents a CPS in practice in terms of continuous
interaction with the environment and distinction between
diﬀerent controller versions by multiple parameter values.
Applying ENVI to more complex CPS could show diﬀerent
results, but the applicability of ENVI for various use cases
(i.e., TOVK, TMVK, and TMVU) shown in this paper is
still valid for CPSs with such characteristics. However, ad-
ditional case studies with more complex CPS are required
to improve our results’ generalizability.

In terms of internal validity, the goal achievement mea-
sure deﬁned based on speciﬁc driving quality metrics could
be a potential threat since the evaluation of the lane-
keeping system’s goal could be biased to a speciﬁc aspect of
driving. To mitigate this threat, in our case study, we de-
ﬁned eight driving qualities from the FOT logs motivated
by Cherrett and Pitﬁeld [29] and aggregated the results on
the qualities to comprehensively understand whether the
lane-keeping system under analysis works well or not. Hy-
perparameter value settings for machine learning models
(e.g., number of iterations, learning rates, Etc.) could be
another potential threat to the internal validity since the
performance of machine learning models can largely de-
pend on hyperparameter values [33, 34]. We used the de-

14

(a) Controller under veriﬁcation x = 20◦

(b) Controller under veriﬁcation x = 40◦

Figure 11: Veriﬁcation accuracy of environment model generation
approaches for TMVU use case.

CPS controller versions and generalize the patterns to un-
known CPS controller versions. Therefore, only simulat-
ing the new CPS controller versions many times, without
much FOT, is required for the CPS goal veriﬁcation of
the new versions if an accurate virtual environment model
has been created in the TMVK use case. This can signiﬁ-
cantly reduce the cost of the CPS goal veriﬁcation in prac-
tice. Regarding the IL algorithms, GAIL and BCxGAIL
outperform BC as the same as in RQ2. This implies that
GAIL and BCxGAIL are recommended for the IL algo-
rithm when ENVI is used for the CPS goal veriﬁcation of
new CPS versions.

                  1 X P E H U  R I  ) 2 7  O R J V            9 H U L I L F D W L R Q  D F F X U D F \     ) 2 7 5 D Q G R P % &  [  * $ , / * $ , / % &                  1 X P E H U  R I  ) 2 7  O R J V            9 H U L I L F D W L R Q  D F F X U D F \     ) 2 7 5 D Q G R P % &  [  * $ , / * $ , / % &fault values provided in the original studies [15, 32]. Nev-
ertheless, hyperparameter tuning is an important research
ﬁeld, so it remains an interesting future work.
In addi-
tion, the veriﬁcation accuracy evaluation results could be
aﬀected by the simulation duration T because small errors
of the environment model can be accumulated and cause
signiﬁcant errors in a long simulation, as mentioned in Sec-
tion 4. However, in our case study, we could not see the
problem in all ENVI algorithms even when T is ten times
longer than the current setting in this paper. Nevertheless,
analyzing the performances on mitigating the compound-
ing error of various IL algorithms for ENVI in diﬀerent
systems remains an interesting future work.

7. Discussion

IL algorithm selection: In this paper, we considered
three representative IL algorithms (BC, GAIL, and BCx-
GAIL) for the environment model generation. In practice,
a speciﬁc IL algorithm should be selected when implement-
ing ENVI considering its characteristics, as described in
Section 3. Based on our case study results, we recommend
engineers use the BCxGAIL algorithm in practice since
the environment models generated by BCxGAIL were the
most accurate in terms of CPS goal veriﬁcation. However,
there are other factors for the IL algorithm selection, such
as learning speed or sensitivity to hyperparameters, and
therefore providing more empirical guidelines for selecting
a speciﬁc IL algorithm still remains an interesting future
work.

Knowledge-based approach vs. Data-driven ap-
proach: When there is a high-ﬁdelity simulation engine
based on well-known principles in the CPS domain, engi-
neers can manually create an accurate virtual environment
in the simulator for CPS goal veriﬁcation. In contrast to
such knowledge-based environment modeling, ENVI is a
data-driven approach where only a few FOT logs are re-
quired to automatically generate an accurate virtual en-
vironment model. This is a huge advantage when there
are no high-ﬁdelity simulators or well-deﬁned principles in
the CPS domain. Therefore, the data-driven approach can
complement the knowledge-based approach depending on
the application domain.

Open challenges: Though we successfully developed
and evaluated ENVI, there are three main open challenges
for data-driven environment model generation approaches.
First, sample eﬃciency is essential. This is because
conducting FOTs to collect logs is the most expensive task
in the data-driven approach. In our case study, BCxGAIL
that combines BC and GAIL to improve sample eﬃciency
indeed outperforms the other IL algorithms in most cases.
Using state-of-the-art techniques for increasing sample ef-
ﬁciency [17, 35, 36] could further help.

Second, it should be robust to noise in FOT logs. We
utilized IL techniques, and many IL studies assume the
correctness of the expert demonstration [37–39]. However,

the demonstrator for IL algorithms in the data-driven en-
vironment model generation is the real environment, and
therefore some level of noise can appear (e.g., due to sen-
sor noise. In our case study, though we used noisy data
collected by the real CPS, systematically investigating the
impact of noise was not in the scope of our work. Never-
theless, as many studies have already considered the noise
issue in machine learning [40–42], they could better guide
how to address noisy data.

Third, ﬁnding a proper level of abstraction for complex
environmental behaviors is important. We abstracted the
environment as a state-transition function in a closed-loop
simulation and recast the environment model generation
problem as the IL problem (see Section 4). This is a typical
level of abstraction when an environment is modeled [43–
45]. However, this simple representation may not be suf-
ﬁcient to model complex environmental behaviors, such
as structural changes in the environment during the FOT
or responses to factors other than the system. Therefore,
an extension of the CPS-ENV interaction model could be
needed for some domains. It is an interesting future work,
and we can also refer to some IL studies that imitate com-
plex expert behaviors (e.g., multi-task or concurrent be-
havior) [46–48].

8. Related work

Instead of conducting FOTs, assessing CPS on a sim-
ulation environment is widely used in CPS engineering.
Therefore, many studies have been presented in modeling
CPS environments.

Qin et al. [43] and Reichstaller and Knapp [44] mod-
eled the interaction between the CPS and environment as
a closed-loop similar to our CPS-ENV model. They gener-
ated environmental testing inputs to predict and evaluate
the CPS runtime behavior. Fredericks [49] also speciﬁed
uncertain situations the CPS may face at runtime, such
as inaccurate or delayed cognition of the environment,
to evaluate the CPS with adverse environmental inputs.
These approaches can generate the initial environmental
inputs that the CPS observes using sensors, but the state
transition of the environment during the simulation should
be manually modeled by domain experts or engineers in an
external simulator.

Some studies model the environment state transition
for CPS simulation similar to our approach. P¨uschel et al.
[50] modeled the change of the environment state as a pro-
cess model and reconﬁgured the environment based on the
model during CPS simulation. Yang et al. [51] explicitly
speciﬁed how the environmental state is changed after CPS
action on a state machine. C´amara et al. [52] and Moreno
et al. [53] also modeled the probabilistic environment state
transition in Markov Decision Process (MDP) and veriﬁed
the CPS goal achievement in the dynamic environment.
Though they modeled environmental state transition func-
tions, domain experts have to manually design these mod-
els, which require suﬃcient domain knowledge and eﬀorts.

15

There are studies utilizing environmental data to model
the environment. Ding et al. [54] modeled the continuous
environment state transition as a continuous place in an
extension of Petri nets, and the parameters in the model
were learned from data. Aizawa et al. [55] and Sykes et al.
[56] modeled the changing environment as a labeled transi-
tion system (LTS) and a logic program, respectively. The
initial environment models are revised by execution trace
data of the system so that the models represent the chang-
ing environment of reality as accurately as possible. How-
ever, in these studies, the revised environment model is
still highly dependent on the initial models made by ex-
perts because data update only the partial information in
the model.

Unlike the previous studies that modeled the environ-
ment of CPS, we abstract the complex state transition of
the environment into a black box function implemented as
a neural network. As a result, the environment model can
be automatically generated with execution trace samples
of CPS without prior knowledge of the environment.

Independently from CPS, model-based Reinforcement
Learning (RL) uses a notion of the environment model gen-
erally deﬁned as anything that informs how the RL agent’s
environment will respond to the agent’s actions [57]. Though
the concept is similar to our environment model that in-
teracts with the CPS under veriﬁcation, the purposes of
training (learning) the environment model are diﬀerent.
The primary objective of the environment model in model-
based RL is to better learn the agent’s policy function,
so an inaccurate environment model is acceptable as long
as it can promote the policy learning process. Naturally,
supervised learning is used for learning the environment
model [58] without considering possible accumulations of
errors over time. In contrast, the environment model in
ENVI is to replace the real FOT environment for CPS
goal veriﬁcation, and therefore making the environment
model the same as the real environment in a closed-loop
simulation is our primary objective, which is why we lever-
age Imitation Learning (IL) in our approach.

9. Conclusion

In this paper, we present ENVI, a novel data-driven
environment imitation approach that eﬃciently generates
accurate virtual environment models for CPS goal veriﬁca-
tion. Instead of conducting expensive FOTs many times,
ENVI requires only a few FOTs to collect some FOT logs
for training a virtual environment model. By leverag-
ing the representative IL algorithms (i.e., BC, GAIL, and
BCxGAIL), an accurate virtual environment model can
be generated automatically from the collected FOT logs.
Our case study using a LEGO-lized autonomous vehicle
equipped with a lane-keeping system shows that the CPS
goal veriﬁcation accuracy of the virtual environment mod-
els generated by our approach is very accurate, even when
only a few FOT logs are used for training the models. The

case study also shows that when the same CPS has multi-
ple versions from an evolutionary development process, an
ENVI -generated environment model can be used for the
CPS goal veriﬁcation of new versions whose FOT logs are
never collected before for the model training.

In future work, we plan to provide practical guidelines
for using ENVI with diﬀerent IL algorithms by further in-
vestigating the characteristics of individual IL algorithms
and conducting more case studies with complex CPS (e.g.,
an automated driving system composed of machine learn-
ing components). We further expect that ENVI is not
limited to the purpose of CPS controller veriﬁcation, so
we also plan to suggest new applications of ENVI, such
as an optimal CPS control predicting the environmental
reaction.

Acknowledgements

This research was supported by the MSIT (Ministry
of Science and ICT), Korea, under the ITRC (Informa-
tion Technology Research Center) support program (IITP-
2022-2020-0-01795) and (SW Star Lab) Software R&D for
Model-based Analysis and Veriﬁcation of Higher-order Large
Complex System (No. 2015-0-00250) supervised by the
IITP (Institute of Information & Communications Tech-
nology Planning & Evaluation). This research was also
partially supported by the Basic Science Research Pro-
gram through the National Research Foundation of Korea
(NRF) funded by the Ministry of Education (2019R1A6A-
3A03033444).

References

[1] R. Baheti, H. Gill, Cyber-physical systems, The impact of

control technology 12 (2011) 161–166.

[2] D. An, J. Liu, M. Zhang, X. Chen, M. Chen, H. Sun, Uncer-
tainty modeling and runtime veriﬁcation for autonomous vehi-
cles driving control: A machine learning-based approach, Jour-
nal of Systems and Software 167 (2020) 110617.

[3] G. E. Mullins, P. G. Stankiewicz, R. C. Hawthorne, S. K. Gupta,
Adaptive generation of challenging scenarios for testing and
evaluation of autonomous vehicles, Journal of Systems and Soft-
ware 137 (2018) 197–215.

[4] D. Bozhinoski, D. Di Ruscio, I. Malavolta, P. Pelliccione,
I. Crnkovic, Safety for mobile robotic systems: A systematic
mapping study from a software engineering perspective, Jour-
nal of Systems and Software 151 (2019) 150–179.

[5] A. Ahmad, M. A. Babar, Software architectures for robotic
systems: A systematic mapping study, Journal of Systems and
Software 122 (2016) 16–39.

[6] Y.-R. Shiue, K.-C. Lee, C.-T. Su, Real-time scheduling for a
smart factory using a reinforcement learning approach, Com-
puters & Industrial Engineering 125 (2018) 604–614.

[7] W. Wang, Y. Zhang, J. Gu, J. Wang, A proactive manufactur-
ing resources assignment method based on production perfor-
mance prediction for the smart factory, IEEE Transactions on
Industrial Informatics 18 (2022) 46–55.

[8] M. Zema, S. Rosati, V. Gioia, M. Knaﬂitz, G. Balestra, Devel-
oping medical device software in compliance with regulations,
in: 2015 37th Annual International Conference of the IEEE En-
gineering in Medicine and Biology Society (EMBC), 2015, pp.
1331–1334. doi:10.1109/EMBC.2015.7318614.

16

[9] K. Fu, Trustworthy medical device software, Public Health

doi:10.1007/978-3-642-28305-5_8.

Eﬀectiveness of the FDA 510 (2011) 102.

[10] A. Hussein, M. M. Gaber, E. Elyan, C. Jayne, Imitation learn-
ing: A survey of learning methods, ACM Comput. Surv. 50
(2017).

[11] O. Michel, Cyberbotics ltd. webots™: Professional mobile robot
simulation, International Journal of Advanced Robotic Systems
1 (2004) 5.

[12] N. Koenig, A. Howard, Design and use paradigms for gazebo, an
open-source multi-robot simulator,
in: 2004 IEEE/RSJ Inter-
national Conference on Intelligent Robots and Systems (IROS)
(IEEE Cat. No.04CH37566), volume 3, 2004, pp. 2149–2154
vol.3. doi:10.1109/IROS.2004.1389727.

Learning from demonstration,

[13] S. Schaal,
vances
pp.
1224-learning-from-demonstration.

Ad-
Information Processing Systems, 1996,
URL:
http://papers.nips.cc/paper/

in Neural
1040–1046.

in:

[14] B. D. Argall, S. Chernova, M. Veloso, B. Browning, A survey of
robot learning from demonstration, Robotics and Autonomous
Systems 57 (2009) 469–483.

[15] J. Ho, S. Ermon, Generative adversarial imitation learning,
in: Proceedings of the 30th International Conference on Neural
Information Processing Systems, NIPS’16, Curran Associates
Inc., Red Hook, NY, USA, 2016, p. 4572–4580.

[16] J. Ho, S. Ermon, Generative adversarial imitation learning,
in: Proceedings of the 30th International Conference on Neural
Information Processing Systems, NIPS’16, Curran Associates
Inc., Red Hook, NY, USA, 2016, p. 4572–4580.

[17] R. Jena, C. Liu, K. Sycara, Augmenting gail with bc for sample

eﬃcient imitation learning, arXiv (2020).

[18] R. S. Sutton, A. G. Barto, et al., Introduction to reinforcement

learning, volume 135, MIT press Cambridge, 1998.

[19] L. D. Xu, L. Duan, Big data for cyber physical systems in in-
dustry 4.0: a survey, Enterprise Information Systems 13 (2019)
148–169.

[20] M. T. Hagan, H. B. Demuth, M. Beale, Neural network design,

PWS Publishing Co., 1997.

[21] M. Raﬁq, G. Bugmann, D. Easterbrook, Neural network design
for engineering applications, Computers & Structures 79 (2001)
1541–1552.

[22] A. Schilling, C. Metzner, J. Rietsch, R. Gerum, H. Schulze,
P. Krauss, How deep is deep enough? – quantifying class sep-
arability in the hidden layers of deep neural networks, arXiv
(2019).

[23] A. Basden, I. Watson, P. Brandon, The evolutionary develop-
ment of expert systems, in: Research & Development In Expert
Systems Vlll, Cambridge University Press, 1991, pp. 67–81.
[24] R. Helps, F. N. Mensah, Comprehensive design of cyber physical
systems,
in: Proceedings of the 13th Annual Conference on
Information Technology Education, SIGITE ’12, Association for
Computing Machinery, New York, NY, USA, 2012, p. 233–238.
doi:10.1145/2380552.2380618.

[25] M. Sirjani, L. Provenzano, S. A. Asadollah, M. H. Moghadam,
M. Saadatmand, Towards a veriﬁcation-driven iterative devel-
opment of software for safety-critical cyber-physical systems,
Journal of Internet Services and Applications 12 (2021) 1–29.

[26] Y.-J. Shin, L. Liu, S. Hyun, D.-H. Bae, Platooning legos:
An open physical exemplar for engineering self-adaptive cyber-
physical systems-of-systems, in: 2021 International Symposium
on Software Engineering for Adaptive and Self-Managing Sys-
tems (SEAMS), 2021, pp. 231–237. doi:10.1109/SEAMS51251.
2021.00038.

[27] Y. Tao, Z. Bin, A novel self-tuning cps controller based on
in: 2008 IEEE Power and Energy Society
q-learning method,
General Meeting - Conversion and Delivery of Electrical En-
ergy in the 21st Century, 2008, pp. 1–6. doi:10.1109/PES.2008.
4596654.

[28] R.-C. David, R.-E. Precup, S. Preitl, J. K. Tar, J. Fodor,
Three evolutionary optimization algorithms in pi controller
tuning,
in: Applied Computational Intelligence in Engineer-
ing and Information Technology, Springer, 2012, pp. 95–106.

17

[29] T. Cherrett, D. Pitﬁeld, Extracting driving characteristics from
heavy goods vehicle tachograph charts, Transportation Plan-
ning and Technology 24 (2001) 349–363.

[30] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury,
G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Des-
maison, A. K¨opf, E. Yang, Z. DeVito, M. Raison, A. Tejani,
S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, S. Chintala, Py-
Torch: An Imperative Style, High-Performance Deep Learning
Library, Curran Associates Inc., Red Hook, NY, USA, 2019, pp.
8026–8037.

[31] D. P. Kingma, J. Ba, Adam: A method for stochastic optimiza-

tion, arXiv (2017).

[32] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, O. Klimov,

Proximal policy optimization algorithms, arXiv (2017).

[33] B. Wang, N. Z. Gong, Stealing hyperparameters in machine
in: 2018 IEEE Symposium on Security and Privacy

learning,
(SP), 2018, pp. 36–52. doi:10.1109/SP.2018.00038.

[34] P. Probst, A.-L. Boulesteix, B. Bischl, Tunability: Importance
of hyperparameters of machine learning algorithms, J. Mach.
Learn. Res. 20 (2019) 1934–1965.

[35] X. Zhang, Y. Li, Z. Zhang, Z.-L. Zhang,

f-gail: Learn-
ing f-divergence for generative adversarial imitation learning,
in: H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan,
H. Lin (Eds.), Advances in Neural Information Processing Sys-
tems, volume 33, Curran Associates, Inc., 2020, pp. 12805–
12815. URL: https://proceedings.neurips.cc/paper/2020/
file/967990de5b3eac7b87d49a13c6834978-Paper.pdf.

[36] Z. W. Robertson, M. R. Walter, Concurrent training improves
the performance of behavioral cloning from observation, arXiv
(2020).

[37] F. Codevilla, M. M¨uller, A. L´opez, V. Koltun, A. Dosovitskiy,
End-to-end driving via conditional imitation learning, in: 2018
IEEE International Conference on Robotics and Automation
(ICRA), 2018, pp. 4693–4700. doi:10.1109/ICRA.2018.8460487.
[38] M. Abdou, H. Kamal, S. El-Tantawy, A. Abdelkhalek, O. Adel,
imita-
K. Hamdy, M. Abaas, End-to-end deep conditional
tion learning for autonomous driving,
in: 2019 31st Interna-
tional Conference on Microelectronics (ICM), 2019, pp. 346–
350. doi:10.1109/ICM48031.2019.9021288.

[39] X. B. Peng, P. Abbeel, S. Levine, M. van de Panne, Deepmimic:
Example-guided deep reinforcement learning of physics-based
character skills, ACM Trans. Graph. 37 (2018).

[40] A. Atla, R. Tada, V. Sheng, N. Singireddy, Sensitivity of diﬀer-
ent machine learning algorithms to noise, J. Comput. Sci. Coll.
26 (2011) 96–103.

[41] S. Gupta, A. Gupta, Dealing with noise problem in machine
learning data-sets: A systematic review, Procedia Computer
Science 161 (2019) 466–474. The Fifth Information Systems In-
ternational Conference, 23-24 July 2019, Surabaya, Indonesia.
[42] Z. Zeng, Y. Liu, W. Tang, F. Chen, Noise is useful: Exploiting
data diversity for edge intelligence, IEEE Wireless Communi-
cations Letters 10 (2021) 957–961.

[43] Y. Qin, C. Xu, P. Yu, J. Lu, Sit: Sampling-based interactive
testing for self-adaptive apps, Journal of Systems and Software
120 (2016) 70–88.

[44] A. Reichstaller, A. Knapp, Risk-based testing of self-adaptive
systems using run-time predictions, in: 2018 IEEE 12th Interna-
tional Conference on Self-Adaptive and Self-Organizing Systems
(SASO), 2018, pp. 80–89. doi:10.1109/SASO.2018.00019.
[45] Y.-J. Shin, J.-Y. Bae, D.-H. Bae, Concepts and models of en-
vironment of self-adaptive systems: A systematic literature re-
view,
in: 2021 28th Asia-Paciﬁc Software Engineering Con-
ference (APSEC), 2021, pp. 296–305. doi:10.1109/APSEC53868.
2021.00037.

[46] S. Agrawal, M. van de Panne, Task-based locomotion, ACM

Trans. Graph. 35 (2016).

[47] J. Harmer, L. Gissl´en, J. del Val, H. Holst, J. Bergdahl,
Imitation learning with con-
T. Olsson, K. Sj¨o¨o, M. Nordin,
current actions in 3d games,
in: 2018 IEEE Conference on
Computational Intelligence and Games (CIG), 2018, pp. 1–8.

doi:10.1109/CIG.2018.8490398.

[48] A. Singh, E. Jang, A. Irpan, D. Kappler, M. Dalal, S. Levinev,
M. Khansari, C. Finn, Scalable multi-task imitation learning
with autonomous improvement,
in: 2020 IEEE International
Conference on Robotics and Automation (ICRA), 2020, pp.
2167–2173. doi:10.1109/ICRA40945.2020.9197020.

[49] E. M. Fredericks, Automatically hardening a self-adaptive
system against uncertainty,
in: 2016 IEEE/ACM 11th In-
ternational Symposium on Software Engineering for Adap-
tive and Self-Managing Systems (SEAMS), 2016, pp. 16–27.
doi:10.1109/SEAMS.2016.010.

[50] G. P¨uschel, C. Piechnick, S. G¨otz, C. Seidl, S. Richly,
T. Schlegel, U. Aßmann, A combined simulation and test case
generation strategy for self-adaptive systems, Journal On Ad-
vances in Software 7 (2014) 686–696.

[51] W. Yang, C. Xu, Y. Liu, C. Cao, X. Ma, J. Lu, Ver-
ifying self-adaptive applications suﬀering uncertainty,
in:
Proceedings of the 29th ACM/IEEE International Confer-
ence on Automated Software Engineering, ASE ’14, Associa-
tion for Computing Machinery, New York, NY, USA, 2014,
p. 199–210. URL: https://doi.org/10.1145/2642937.2642999.
doi:10.1145/2642937.2642999.

[52] J. C´amara, W. Peng, D. Garlan, B. Schmerl, Reasoning about
sensing uncertainty in decision-making for self-adaptation,
in:
A. Cerone, M. Roveri (Eds.), Software Engineering and Formal
Methods, Springer International Publishing, Cham, 2018, pp.
523–540.

[53] G. A. Moreno, J. C´amara, D. Garlan, B. Schmerl, Flexible
and eﬃcient decision-making for proactive latency-aware self-
adaptation, ACM Trans. Auton. Adapt. Syst. 13 (2018).
[54] Z. Ding, Y. Zhou, M. Zhou, Modeling self-adaptive software sys-
tems with learning petri nets, IEEE Transactions on Systems,
Man, and Cybernetics: Systems 46 (2016) 483–498.

[55] K. Aizawa, K. Tei, S. Honiden,

Identifying safety properties
guaranteed in changed environment at runtime, in: 2018 IEEE
International Conference on Agents (ICA), 2018, pp. 75–80.
doi:10.1109/AGENTS.2018.8460083.

[56] D. Sykes, D. Corapi, J. Magee, J. Kramer, A. Russo, K. In-
oue, Learning revised models for planning in adaptive systems,
in: 2013 35th International Conference on Software Engineering
(ICSE), 2013, pp. 63–71. doi:10.1109/ICSE.2013.6606552.
[57] R. S. Sutton, A. G. Barto, Reinforcement learning: An intro-

duction, MIT press, 2018.

[58] T. M. Moerland, J. Broekens, C. M. Jonker, Model-based rein-

forcement learning: A survey, arXiv (2021).

18

