IEEE JOURNAL, VOL. X, NO. Y, SEPTEMBER 2022

1

Mask-Mediator-Wrapper architecture as a Data
Mesh driver

Juraj Donˇcevi´c Member, IEEE, Kreˇsimir Fertalj Member, IEEE, Mario Brˇci´c Member, IEEE, Mihael Kovaˇc
Member, IEEE
This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice,
after which this version may no longer be accessible.

Abstract—The data mesh is a novel data management concept
that emphasises the importance of a domain before technology.
The concept is still in the early stages of development and many
efforts to implement and use it are expected to have negative
consequences for organizations due to a lack of technological
guidelines and best practices. To mitigate the risk of negative
outcomes this paper proposes the use of the mask-mediator-
wrapper architecture as a data mesh driver. The mask-mediator-
wrapper architecture provides a set of prefabricated conﬁgurable
components that provide basic functionalities which a data
mesh requires. This paper shows how the two concepts are
compatible in terms of functionality, data modelling, evolvability
and aligned capabilities. A mask-mediator-wrapper driven data
mesh facilitates: low-risk adoption trials, rapid prototyping,
standardization, and a guarantee of evolvability.

Index Terms—data mesh, software architecture, data manage-

ment, mediator-wrapper

I. INTRODUCTION

The landscape of data management is constantly changing.
In just the recent two decades, there has been a great pro-
cession of technologies, formats, tools and systems that have
shown promise in tackling data management. Data warehouses
serving as analytical data stores were the common starting
point. The situation became complicated with the introduc-
tion of NoSQL, as unstructured schemas, multitudes of data
formats, and data federation became commonplace.

In an understandable effort to stay ahead of the competition,
the industry more than adapted to these new ideas. The need
for velocitous, voluminous and various data was stamped into
the ”3 Vs” slogan. With the demand now up to 8 Vs, a decade
of data streaming, data lakes and data lakehouses is at a close,
with many promising ideas ahead.

2
2
0
2

p
e
S
0
1

]
E
S
.
s
c
[

1
v
1
6
6
4
0
.
9
0
2
2
:
v
i
X
r
a

is that

the target

These are all exciting ideas to explore, and very few can
really be considered obsolete. The problem with hitting the
mark in data management
is constantly
moving, making data management an ongoing struggle sus-
ceptible to rapid paradigm shifts. The most recent of these
leaving leading
is the introduction of the data mesh [1],
organizations [2, 3, 4, 5] in a race to extract every ounce
of beneﬁt available to them from this new paradigm. The
question is if all organizations can implement this shift quickly
and stably enough with a positive outcome, as some might
be forced to exhaustively restructure their entire data orga-
nization and provision. These organizations run the risk of
implementing a half-baked solution they don’t beneﬁt from,

J. Donˇcevi´c, K. Fertalj, M. Brˇci´c and M. Kovaˇc are with University of

Zagreb Faculty of Electrical Engineering and Computing, Zagreb, Croatia.

ultimately quitting mid-shift with an unmanageable product.
There is an implicit expectation that each organization will
develop its own custom components to drive a data mesh,
restricting inter-system composability, technologist migration
among projects, and challenging evolvability. The impact of
these problems is undeniable, with just 20 percent of analyses
bringing value [6], and the failure rate of data science projects
at 87 percent [7].

This papers shows that a data mesh can be driven by the
MMW architecture, and contributes with a MMW-driven data
mesh concept that enables:

• low-risk adoption trials for organizations that might not

have data exactly at scale

• rapid prototyping to reduce the time required for imple-

mentation

• standardization to reduce the cognitive load for technol-
ogists when switching projects and making the system
composable

• a guarantee of evolvability to alleviate technological

changeability

Sections II and III provide succinct overviews of the data
mesh and MMW architecture concepts. Section IV discusses
the compatibility of both concepts in terms of their function-
alities, modelling abilities, architectural evolvability and data
mesh capability coverage. This is demonstrated by construct-
ing a hypothetical data mesh using the MMW architecture in
Section IV. Section V discusses the beneﬁts that can be gained
by using the MMW architecture to drive a data mesh.

II. THE DATA MESH

The data mesh is an enterprise data platform architecture

that converges the ideas of [8]:

• distributed domain driven architecture
• self-serve platform design
• product thinking with data
It is an alternative to the centralized data platform approach,
where data is centrally managed and served through coupled
extract-transform-load (ETL) processes.

The key organizational feature of the data mesh is that it
arranges an organization’s data into bounded contexts. This
brings domain-driven design from operational systems into an-
alytical systems. With this conceptual data federation in place,
teams can more easily manage data in their domains, acquire
domain-speciﬁc knowledge faster and handle data and new
tasks with greater expertise. This means that responsibilities
are distributed among teams along the bounded contexts rather

 
 
 
 
 
 
IEEE JOURNAL, VOL. X, NO. Y, SEPTEMBER 2022

2

Fig. 1. Convergence of ideas in the data mesh [8]

Fig. 2. Centralized data management over planes (adapted from [8])

than along mechanical functions (e.g. ingestion, cleansing,
aggregation, serving) [8]. Echoing the statement of Richards
and Ford [9] that in engineering architectures everything is a
trade-off, the division by domains requires teams to be cross-
functional.

Each team creates a data pipeline to load domain data
from the data infrastructure platform (DIP). Ideally, domains
shouldn’t overlap [10], but this is inevitable. In this case, a
domain that uses data from another domain doesn’t create its
own separate data pipeline to the DIP, but correlates the data
from an existing domain. Since data is considered a product,
its quality is guaranteed by the other domain’s team - the
team owns the data. Verifying and maintaining data quality is
simpler since each team manages their domain.

The idea of the data mesh corresponds with the evolutionary
architectures concept, as presented by Ford et al. [11]. Each
domain can be considered an architectural quantum, which is
according to the deﬁnition of Ford et al. [11] an independently
deployable component with high functional cohesion, which
includes all the structural elements required for the system
to function properly. Since cases where architectural quanta
depend on each other are inevitable, this implies that the
interfaces between domains must be designed technologically
agnostic. Such interfacing is made easier since the data mesh
domains have to follow global interoperability principles pro-
scribed by federated computational governance. Dehghani [1]
even goes so far as specifying that data products (deﬁned by
domains) have input and output data ports as interface points.

It can be noticed that the data mesh relies heavily on the ports-
and-adapters pattern of the hexagonal architecture [12], which
gives promise that the data mesh is a sound solution. Even
Netﬂix, the proponents of the hexagonal architecture [13], have
been quick to admit that they ﬁnd the data mesh compelling
[2, 3].

Fig. 3. Data product’s placement in the domain and interaction (IDP - input
data port, ODP - output data port); adapted from [14]

In this domain-oriented architecture data is consumed by
users (reporting, visualization, dashboards of Fig. 2), opera-
tional systems and analytical systems (other data products).
The inter-connection possibilities are conceptually illustrated
in Fig. 4. It is important to note how some data products
might depend on analytical data from other data products; by
example of Fig. 4 the purple data product requires analytical
data from the green domain. On the other hand, data products

DataDistributed  Domain  Driven  ArchitectureSelf-Serve Platform DesignProduct ThinkingOperational Data PlaneAnalytical Data Plane Data Lake/Data Warehouse EEETTTLLLData pipelines Extract-Transform-LoadDashboards Reporting VisualizationETLLakeshore Data mart Data warehouseDomainData ProductOperationalSystem(microservice,legacyapplication...)IDPODPOperationaldataAnalyticaldataIEEE JOURNAL, VOL. X, NO. Y, SEPTEMBER 2022

3

• Data pipeline implementation and orchestration
• Data product discovery, catalog registration and publish-

ing

• Data governance and standardization
• Data product lineage
• Data product monitoring/alerting/log
• Data product quality metrics (collection and sharing)
• In memory data caching
• Federated identity management
• Compute and data locality

III. THE MASK-MEDIATOR-WRAPPER ARCHITECTURE

The mask-mediator-wrapper (MMW) architecture, proposed
by Donˇcevi´c et al. [17] is an extension of the already
known mediator-wrapper (MW) architecture (Fig. 6). The
MW architecture is shown to underperform in terms of data
representation, which is heavily leveraged in modern data man-
agement, so the MMW architecture proposes a new additional
component type - the mask. The work by Donˇcevi´c et al. [17]
presents ground rules for MMW components, a quantitative
ﬂexibility analysis comparing the MMW with the MW archi-
tecture, and a case where a legacy store-preserving system
could hypothetically be substituted by a MMW system. This
hypothetical case study shows how the MMW architecture
accommodates more than just data integration, but also other
data management purposes.

never depend on operational data from another domain; the
purple data product didn’t reach for the operational data from
the green domain.

Fig. 4. Multiple domains serving domain-oriented data (O - operational data;
D - analytical data) [14]

The DIP is seen as the primary data source location for the
data mesh, containing data warehouses, data lakes or opera-
tional data stores as as data platforms [15, 16]. On the other
hand, [1] mentions that there are other top-level data source
archetypes in the data mesh such as collaborating operational
systems or other data products. This raises a practical question
of whether some data should remain physically close to the
data product. In Fig. 5 we present a distilled view on this by
Dehghani [1], which proposes that a data product container
can keep data locally. This local data is the domain data being
served by the data product. The local data must be consumed
from the input data ports and transformed to a valuable
product. This all happens in the data product container.

Fig. 5. A data product container having a local domain data storage - data
prepared for serving (adapted from [1])

The data mesh as a data platform enables [8]:
• Scalable polyglot big data storage
• Encryption for data at rest and in motion
• Data product versioning
• Data product schema
• Data product de-identiﬁcation
• Uniﬁed data access control and logging

Fig. 6. The mediator-wrapper architecture pattern

The MMW architecture is comprised of three component
types: mask, mediator and wrapper. Each of these component
types deals with a speciﬁc set of tasks and responsibilities:

• The wrapper is used to encapsulate a data source and
provide a universal data source interface to the rest of the
system. The wrapper allows the data source to be queried
for both its data and metadata. The data sources can
be a variety of storage solutions: relational and NoSQL
databases, data lakes, or even web content.

• The mediator is used to transform and integrate data
and metadata from wrappers or lower-tier mediators.

DataProductOperational SystemOperational SystemIDPIDPODPDDataProductOperational SystemIDPIDPODPDDataProductOperational SystemIDPODPDOOOOData product containerTransformationsDomain dataTemporarystorageResultWrapperResultWrapperQueryQueryMediatorDatasourceDatasourceResultQueryQueryResultResultQueryIEEE JOURNAL, VOL. X, NO. Y, SEPTEMBER 2022

4

Mediators can be composed to work in multiple tiers,
each tier raising the level of abstraction or extracting a
piece of integrated data and metadata.

• The mask is used to represent the data and metadata
it acquires from a mediator in different formats. The
mask allows a MMW system to be both materializing and
virtualizing. A mask can provide a raw data acquisition
interface, or a graphical user interface for reporting, or
be used as a data warehouse loader.

Fig. 7. Mask-mediator-wrapper architecture example

The data and metadata that the components translate and
exchange are schemas, queries and data. Schemas represent
the organization of data, while queries over schemas are used
to select which data is currently of interest. Despite this
exchange, each component can be considered an architectural
quantum as, by deﬁnition of Ford et al. [11], each component
is independently deployable and cohesive. High cohesion is a
product of the reﬁned separation of concerns among compo-
nent types (set by the component type rules [17]). Independent
deployability is intrinsic to the componentization in the MMW
architecture; for example a wrapper doesn’t require other
components to function properly, neither do mediators and
masks (although they would present empty schemas and data
sets).

Our currently ongoing research of translation in mediators is
indicating that a loosely-relational data representation powered
by bidirectional transformations presents a practical solution.
Kleppmann [18] suggest
that relational models generalize
data very well, so they can be useful in a broad variety of
cases beyond their originally intended scope of business data
processing. The goal of the relational model was to hide
this implementation detail behind a cleaner interface [18].
This is ﬁtting, since mediators should be able to present a
schema merged from multiple heterogeneous sources. Bidi-
rectionalization, as proposed by Asano et al. [19], allows the

mediators to have set rules that describe transformations for
localization and globalization of schemas, queries and data.
Additionaly, Asano et al. [19] even go so far as presenting an
SQL-like language for declaring views (translated relations).
These declarations can then be followed through certain rules
to acquire bidirectional transformations of schemas, queries
and data going into and out of the mediator; this generally
comes down to query rewrites. In practice, this means that a
generalized set of transformations can be created by an SQL-
like declaration to manage schemas, queries and data in a
mediator.

IV. COMPATIBILITY OF CONCEPTS

Although at ﬁrst glance the data mesh and the MMW archi-
tecture seem to be concepts from different time periods and
paradigms, we consider them compatible. They cover similar
problem areas, use similar concepts and provide a similar
service. The MMW architecture is a much more primitive
idea, than the data mesh. Whereas the data mesh focuses
more on solving organizational problems (both human and
data-related), the MMW tries to solve functional granularity
problems and provide comprehensive reusable architectural
quanta for data management. However, Dehghani [1] and
Donˇcevi´c et al. [17] stress that their concepts are domain
and technology agnostic, giving their realizations the ability to
prove compatible. The data mesh and the MMW architecture
are orthogonal concepts, aiming to cover different problem
areas in data management. Together with the promise of
agnosticism, this provides the basis for the data mesh and
the MMW architecture to be complementary ideas that can
produce a greater effect when joined.

A. Consume-Transform-Serve

Fig. 8. Consume-transform-serve concept relating to the MMW architecture
(adapted from Donˇcevi´c et al. [17])

A data mesh’s data product is expected to autonomously
transform and serve data Dehghani [1]. This is
consume,
visible in Fig. 5, with the input ports used to consume data,

Maska (REST/JSON)Mask (JDBC/table)Mask (NoSQL/graph)Mask (CSV/flat)MiriteljMiriteljMiriteljWrapperWrapperWrapperWrapperMaska (REST/JSON)MiriteljMiriteljMiriteljWrapperWrapperMask (REST/JSON)MediatorMediatorMediatorWrapperWrapperAI modelsAnalystsDatawarehousesApplicationsRel. DBData lakeMicro-blogNoSQL DBMediatorsWrappersMasksSource dataPresentational dataConsumeTransformServeIEEE JOURNAL, VOL. X, NO. Y, SEPTEMBER 2022

5

transformations being done inside the container, and the data
served through the output ports. In the MMW architecture
(Fig. 8), data consumption is driven by the wrappers, trans-
formation is driven by mediators, and data serving is driven
by masks. By providing consume-transform-serve capabilities,
the components of a MMW architecture are capable of acting
as a data product.

B. Data models

Data models in domain-driven design are instinctively
thought of as constructs of classes or structs. This is because
domain-driven design is usually observed in operational sys-
tems. In analytical systems this could be a pitfall, because
the consumed data might be deﬁned by different metamodels
and it’s expected that the data is served in polyglot form.
Dehghani [14] also recognizes this stating: Depending on the
nature of the domain data and its consumption models, data
can be served as events, batch ﬁles, relational tables, graphs,
etc., while maintaining the same semantic. Rather, domain-
driven design should be considered at the most abstract level.
Kleppmann [18] have explained why relational systems have
stood the test of time: relational databases turned out to
generalize very well, beyond their original scope of business
data processing, to a broad variety of use cases[18]. The
relational model, with its generalization abilities and time-
enduring legacy in analytical systems, should be a good ﬁt
for the data mesh. Nothing prevents a domain from being
described in a relational model - this is done on a regular basis
in operational systems, especially when developing micro-
services.

A relational model could also be used in an MMW archi-
tecture. The use of a tabular relational-like model in mediators
has already been demonstrated by Asano et al. [19]. The
relational model’s generalization abilities [18] is a conﬁdent
sign that this should be the data model of choice. Support for
polyglot access would also be signiﬁcantly easier to research
and implement, as there are already numerous implementations
of relational mapping to other models. This is the focal point
of the MMW architectures capability to be domain-agnostic,
while enabling modeling, processing and sharing across the
organization, just as stipulated by Dehghani [1].

C. Evolutionary compatibility

Dehghani [1] declares that: ”it’s only appropriate to [...]
leave the speciﬁc implementation details and technology to be
reﬁned and built over time. [...] any speciﬁc implementation
design or tooling suggestion will be simply outdated by the
time you get to read this book”. Technology is considered
capricious in this research area, and it is now common sense
to avoid any technological dependency when discussing archi-
tectures and concepts in software engineering. Technological
changeability is one of the driving values of evolutionary
architectures [11], from which Dehghani [1] derives the sug-
gestions that are made about the data mesh’s hypothetical
implementation. Essentially, a data mesh should be evolvable,
and the MMW architecture should follow suit if it is to be
compatible.

The MMW architecture ﬁts the common dimensions of

evolvability as follows:

• Technical

The inner components of the mask, mediator and wrapper
component types are ﬁnely grained [17] and their core
functionalities can be separated by interfacing from tech-
nologically changeable inner components. This allows
the MMW components to be adapted to different tech-
nologies (e.g. in terms of communication protocols and
data formats). This decoupling also allows components
supporting newer or previously unsupported technologies
to be developed quickly.

• Data

Data shared across a MMW system is both metadata
and data, described in a generalized manner to begin
with. Changes to the core metamodels are expected to
be infrequent, but to minimize the effects of changes, the
deﬁnitions can be placed in a shared library.

• Security

Security related to authentication, authorization, conﬁ-
dentiality and data integrity for communication require-
ments can be interfaced along-side communication pro-
tocols and data formats. Security in terms of logical
operations (e.g. sharing conﬁdential system information
or sending unsafe data) can be assured through a common
library for each component type as well as deﬁning a
standard set of inter-component exchanges.

• Operational/System

Since each MMW system component is an architectural
quantum, mapping the components to an existing infras-
tructure is very ﬂexible.

to
The evolvability of the MMW architecture allows it
uphold the data mesh’s set of conventions that promote in-
teroperability between different technologies, which guarantee
its longevity alongside the data mesh concept.

D. Capability coverage

A set of capabilities the data mesh offers was mentioned in
Section II. The MMW can cover these ﬁfteen capabilities as
follows in Table I.

TABLE I. Data mesh capability coverage by the MMW architecture

Scalable
polyglot big
data storage
Encryption
for data at
rest and in
motion

Data product
versioning

The MMW architecture allows usage
of heterogeneous data source and
heterogeneous representation.
MMW components can be interface
their communication with encryption
protocols. Encryption of static data
comes down to the encryption of
local data storage.
Data products can be versioned over
a metamodel. As a hypothetical
example on a relational model, tables
are grouped in schemas, and schemas
represent speciﬁc versions of data
products.

IEEE JOURNAL, VOL. X, NO. Y, SEPTEMBER 2022

6

Data product
schema

Data product
de-
identiﬁcation

Uniﬁed data
access control
and logging

Data pipeline
implementa-
tion and
orchestration
Data product
discovery,
catalog
registration
and
publishing
Data
governance
and standard-
ization

Data product
lineage

Data product
monitor-
ing/alerting/log

Data product
quality
metrics
(collection
and sharing)
In-memory
data caching

Federated
identity
management

Compute and
data locality

A data product schema is provided
by default in each component,
because queries are declared over
schemata.
De-identiﬁcation can be done during
data transformation in mediators, or
via specialized instructions for
wrappers.
Data access can be controlled in all
MMW component types. Masks can
also provide access control via their
applications.
Data pipelines are implemented by
composing the mask, mediator and
wrapper components to consume,
transform and serve data.
Data product discovery is enabled by
examining schemata provided by
components. This process is
simpliﬁed, since all component types
have common interfaces.

Data is governance is federalized
because MMW components can work
in separate groups. Standardization is
provided by the MMW
compomnents’ standard interfaces.
Lineage can be overseen by looking
into mediator transformations, and
mask and wrapper translations.
Each MMW component can be
deployed along with a monitoring
application. Logging is expected to
be component-level in all
components types. Alerting interfaces
can also be put in place as part of
the core component or the
monitoring application.
Quality metrics can be shared as a
part of the schema metadata. This
allows quality metrics to be deﬁned
for each data product version
separately.
In-memory data caching can be
implemented for each component
type to optimize query response
times.
Identity management is a part of the
infrastructure capabilities, but the
MMW architecture doesn’t prohibit
or discourage such cases.
Data can be locally transformed in
mediators and placed in local storage
using materializing masks; then to be
consumed by a wrapper on request
and served (see Section IV-D1).

1) Constructing a data mesh platform:

A generic example of a MMW driven data mesh is shown in
Fig. 9 for some nondescript domains X, Y and Z. The example
is similar the one given in Fig. 4 to give the reader some
bearing. Each domain being covered by an operational system
and a data product serving analytical data. Data products
consume data from their domain’s operational system or the
DIP.

A DIP should solve the need for duplicating data pipelines,
storage and streaming infrastructure [1], making it the platform
for uniformed data access. This platform can be ﬁttingly driven
by multiple wrappers. Each wrapper can cover a single data
source, or there might be a case where multiple wrappers
cover a single data source (e.g. load balancing, or wrapper
specialization at runtime). This provides standardized access
to data sources and the DIP itself.

Data products access data from the DIP using their me-
diators, since the data and metadata are already consumed
and translated by wrappers. A data product may access data
consumed by multiple wrappers (like in the example of
Domain Z in Fig. 9). A data product accesses data from their
domain’s operational system using a wrapper. The operational
data is consumed through a wrapper either connecting to an
operational database or the operational system’s API. The
mediator combines and transforms the consumed data into
a data product. The data product is served through a mask.
Masks can also serve data to their domain’s operational sys-
tem. To reduce intermediate architectural steps, data products
can acquire data from other domains by connecting those data
products’ mediators directly. This is exempliﬁed for Domains
X and Y in Fig. 9, where the Domain X mediator in effect
requests data from the Domain Y mediator. Direct access to
these mediators from quanta that are not mediators in other
data products should be prohibited by policies of the federated
computational governance.

Fig. 9. MMW architecture used to drive a data mesh

Domain XData product XDomain ZData product ZDomain YData product YData infrastructure platformWrapperWrapperWrapperWrapperMaskMediatorMediatorMediatorMaskMaskOperationalsystemOperationalsystemDDDDOperationalsystemWrapperWrapperWrapperIEEE JOURNAL, VOL. X, NO. Y, SEPTEMBER 2022

7

2) Constructing a data product with localized storage:
Analogously to the product container presentation in Fig. 5,
Fig. 10 displays how it could be driven by MMW components
if a data product contained a local domain data storage. Data is
acquired either as a data product from another domain directly
by a mediator or by consumption of the domain operational
data via a wrapper. The (left-hand) mediator transforms the
data in preparation for it to be stored as a product in the
domain data storage. A mask then materializes the data in the
domain data storage. This persisted data can then be set into
motion by a wrapper’s consumption. The data is originally
requested by a (right-hand) mediator. Theoretically a mask
can connect directly to a wrapper [17], but not omitting
the mediator allows some manoeuvre space for additional
transformations before serving the data by a mask. The data
that is served to data products from other domains by the
mediator responsible for the ﬁnalizing transformations (in this
case the right-hand side one).

Fig. 10. MMW architecture used to emulate a data product with localized
domain data

The aforementioned cases presented in Fig. 9 and Fig. 10
demonstrate how the MMW architecture can drive the entire
data mesh boilerplate. The cases also demonstrate that custom-
built adapters are not required to ﬁt the data mesh’s function-
ality.

V. WHAT ARE THE GAINS?

A. Low-risk adoption trials

The data mesh promises getting value out of data at a scale.
Determining that scale currently remains a rule of thumb,
and it’s unlikely that a metric will be proposed until a larger
number of organizations try to adopt the data mesh - failing or
succeeding. The point remains that the data mesh is intended
for organizations that store various and voluminous data.
Would a small local convenience store or a local accountant’s
ofﬁce beneﬁt from a data mesh? Probably not. Would a
streaming service or an online market service beneﬁt from
a data mesh? Very likely.

Those organizations that are considered between the two
exempliﬁed groups are at most risk. Adopting a new analytical
system, in a novel architecture, and built from scratch is not
a simple operation. Many human and economic factors can
lead the adoption astray. The system might be too complex
to use in a simpler business environment, it might increase
latency without providing any tangible analytical ﬂexibility,

and it might not even be developed to product-level, leaving
the analytical capabilities of the organization in disarray. Even
worse, if engineers unwittingly use the elephant migration anti-
pattern, they might ﬁnd themselves with an unﬁnished data
mesh and a partially-dismantled legacy system. This is all
without mentioning the time, human and ﬁnancial resources
invested. These cases are expected to be common, as just 20
percent of analytic insights are expected to deliver business
outcomes through 2022 [6], and 87 percent of data science
projects never make it into production [7].

Organizations can greatly reduce the risk adopting a data
mesh by setting up a trial run by using the MMW architecture.
The risk is reduced by using the MMW architecture in the
following ways:

• Development failure

MMW components require development only if spe-
cialized components are required. This is an edge case
if wrappers and masks are not developed for certain
data source types or data representation. Components
are largely expected to just be acquired, deployed and
conﬁgured. There is no extensive coding required.

• Loss of large resource investment

Since there is no extensive coding required when using
the MMW architecture, a small technical or development
team could prepare a demonstrative data mesh in short
time. The ﬁnancial investment can boil down to the price
of additional infrastructure (if needed), and that could be
constrained to a cloud service so no additional hardware
acquisition is required.

• Deteriorated business usability

The MMW architecture doesn’t require the legacy analyt-
ical system to be dismantled, so a possible deterioration
of service is limited to the time frame of the adoption
trial run. If the data mesh is found unsuitable for the
organization, then it can be easily dismantled and the
analytical system reintroduced.

B. Rapid prototyping

The MMW architecture allows the data mesh to be rapidly
prototyped when initiating analytical capabilities in an organi-
zation. The entire setup of the system is realistic. The initial
step is to deploy and conﬁgure MMW components to drive a
prototypical data mesh. When requirements are fully distilled
over the prototype, the MMW-driven data products can then be
substituted piecemeal with permanently developed ones. The
DIP is migrated incrementally as permanent data products are
developed and deployed.

Rapid prototyping via the MMW architecture allows the
data mesh to be expeditiously deployed in an organization’s
environment, so beneﬁts can be reaped as soon as possible. It
enables early problem detection, business process and organi-
zational structure alignment, as well as bringing an increase
in business product value sooner.

C. Evolvability

It is expected that components driving the data mesh form
an evolvable architecture. In reality, the software development

Data product containerTransformationsMaskMediatorWrapperDomain dataWrapperMaskMediatorIEEE JOURNAL, VOL. X, NO. Y, SEPTEMBER 2022

8

industry is known to omit beneﬁcial architectural and design
system properties for the sake of reaching a minimum-viable-
product and creating proﬁt quickly. While the consideration
of evolvability is seen as obvious,
is questionable how
many software development projects will continue to follow
evolvability principles throughout their life-cycles. Another
problem is that senior developers, designers or architects tend
to stack technologies instead of components and quanta when
working on systems.

it

It was shown in Section IV-C that the MMW architecture is
evolvable. Evidently, a composition of evolvable architectural
quanta transiently makes their composition evolvable, hence
MMW components can be used as a set of building blocks
for a data mesh to guarantee evolvability.

D. Standardization

Since the data mesh concept proposes no explicit imple-
mentation or use of technology, it’s expected that organiza-
tions will implement data meshes as custom-built platforms.
According to Conway’s law [20], organizations will imple-
ment the data mesh according to their speciﬁc knowledge-
base; using speciﬁc design patterns and technologies used by
their technologists. Because of this, it is expected that each
data mesh implementation will be signiﬁcantly different from
another. The discrepancy will lead to a lack of standardization,
which can cause: a lack in composability of multiple data
meshes in case of mergers, increased learning curve for newer
technologists, a signiﬁcant
learning curve for experienced
technologists switching projects (this diminishes their existing
skill-set and making it largely unusable), or an implementation
of a data mesh far removed from the original concept with
detrimental effects on the organization.

Dehghani [1] stresses the importance of lowering the cog-
nitive load of developers by using experiences, languages and
APIs that are easy to learn as a starting point. With the MMW
architecture a step further can be taken, and a standardization
of architectural quanta created with which data meshes are
regularly developed. This further lowers the cognitive load,
allowing technologists to be calmly migrated among projects.
Standardization beneﬁts composability of systems, the com-
posing systems use the same interfaces to function. It can be
stated that standardization lowers degrees of implementation
freedom, but it brings the beneﬁcial effect of keeping projects
close to the original data mesh concept.

VI. CONCLUSION

Despite the data mesh being a promising concept, it is still
in its infancy and, as is with any such new concept, lacks
concerted best practices and standards. These will undoubtedly
arrive as real-world development experience is gathered by
early adopters. Potential data mesh adopters may come from
a multitude of business areas and come in different organiza-
tional sizes, so it would be beneﬁcial for them to run a trial
data mesh before committing to full adoption. Standardization
of a data mesh allows the system to be composable with
other data mesh implementations, and allows technologist to
be migrated from project to project with a minimal cognitive

load. The use of a MMW architecture to drive a data mesh
addresses all of those concerns.

The MMW architecture and data mesh are orthogonal
concepts - the data mesh concerns itself with the organization
of data management, while the MMW architecture solves func-
tional granularity problems for quanta in data management.
The concepts are compatible in terms of consume-transfer-
serve functionalities, data modelling, evolvability and coverage
of capabilities. The compatibility and orthogonality of the data
mesh and MMW architecture concepts means they can be used
side-by-side. The demonstrative examples have shown that a
MMW driven data mesh is feasible.

The beneﬁts of a MMW driven data mesh are: the ability
run low risk adoption trials, the ability to develop a data mesh
using rapid prototyping, guaranteed evolvability, and standard-
ization. Both early and late adopters can ﬁnd these beneﬁts
useful. Organizations at the edge of managing large scale data
can run trials to see if a data mesh suits them. Organizations
that require a data mesh to be developed quickly can use
the MMW architecture to rapidly prototype it. Organizations
concerned with standardization and evolvability can adopt the
MMW driven data mesh as a complete solution.

Looking to future research, the MMW architecture might
also be used to drive other data management architectures
(e.g. data hub, data fabric, data spoke). If these suspicions are
shown true, as in the case of the data mesh, further research
might also explore the ability for the MMW architecture to
drive migrations to other architectures. This includes state-of-
the-art architectures. The MMW architecture might prove to
be a long standing driver that enables technologists and their
organizations to execute generational migrations between data
management architectures. This could provide standardized
and low-risk adoption of state-of-the-art architectures, while
allowing the technological environment to evolve.

REFERENCES
[1] Z. Dehghani, Data Mesh: Delivering Data-Driven Value
Beijing Boston Farnham: O’Reilly

at Scale, 1st ed.
Media, Apr. 2022.

[2] Nguonly, Andrew, Magalh˜aes, Armando, Nwoke, Obi-
Ike, Afshar, Shervin, Das, Sreyashi, Liu, Tongliang,
Liu, Wei, and Zeng, Yucheng, “Data Movement
in
Netﬂix Studio via Data Mesh,” Jul. 2021. [Online].
https://netﬂixtechblog.com/data-movement-
Available:
in-netﬂix-studio-via-data-mesh-3fddcceb1059

[3] Lei, Bo, Pires, Guilherme, Shao, James, Chatterjee,
Kasturi, Jain, Sujay, and Sydoren, Vlad, “Data Mesh
— A Data Movement
and Processing Platform
[Online]. Available: https:
@ Netﬂix,” Aug. 2022.
//netﬂixtechblog.com/data-mesh-a-data-movement-and-
processing-platform-netﬂix-1288bcab2873

[4] D. Joshi, S. Pratik, and M. P. Rao, “Data Governance in
Data Mesh Infrastructures: The Saxo Bank Case Study,”
p. 7, 2021.

[5] Databricks, “Data Mesh in Practice: How Europe’s
Leading Online Platform for Fashion Goes Beyond
the Data Lake,” Jul. 2020. [Online]. Available: https:
//www.youtube.com/watch?v=eiUhV56uVUc

IEEE JOURNAL, VOL. X, NO. Y, SEPTEMBER 2022

9

Datamation magazine, F. D. Thompson Publications,
Inc., p. 4, 1968.

[6] A. White,
Predicts
for
able:
03/our-top-data-and-analytics-predicts-for-2019/

and
Analytics
[Online]. Avail-
https://blogs.gartner.com/andrew white/2019/01/

“Our
2019,”

Data
2019.

Top
Jan.

[7] VentureBeat, “What the heck does it even mean to “Do
AI”? | Business AI Integration | VB Transform 2019,”
Jul. 2019. [Online]. Available: https://www.youtube.com/
watch?v=EzmTZlho-EI

[8] Z. Dehghani, “How to Move Beyond a Monolithic
to a Distributed Data Mesh,” May
[Online]. Available: https://martinfowler.com/

Data Lake
2019.
articles/data-monolith-to-mesh.html

[9] M. Richards and N. Ford, Fundamentals of Software
Se-

Architecture: An Engineering Approach, 1st ed.
bastopol, CA: O’Reilly Media, Mar. 2020.

[10] E. Evans, Domain-Driven Design: Tackling Complexity
Boston: Addison-

in the Heart of Software, 1st ed.
Wesley Professional, Aug. 2003.

[11] N. Ford, R. Parsons, and P. Kua, Building Evolutionary
Architectures: Support Constant Change, 1st ed. Bei-
jing: O’Reilly Media, Nov. 2017.

and

“Ready

[13] D.

S. Makagon,

[12] A. Cockburn, “Hexagonal architecture,” 2005.

[On-
line]. Available: https://alistair.cockburn.us/hexagonal-
architecture/
Svrtan

for
changes with Hexagonal Architecture,” Mar. 2020.
[Online]. Available: https://netﬂixtechblog.com/ready-
for-changes-with-hexagonal-architecture-b315ec967749
[14] Z. Dehghani, “Data Mesh Principles and Logical
[Online]. Available: https:

Architecture,” Dec. 2020.
//martinfowler.com/articles/data-mesh-principles.html
[15] K. Waehner, “The Heart of the Data Mesh Beats Real-
Time with Apache Kafka,” Jul. 2022. [Online]. Available:
https://www.kai-waehner.de/blog/2022/07/28/the-heart-
of-the-data-mesh-beats-real-time-with-apache-kafka/

[16] Desai, Veeral, Fountaine, Tim,

value

and Rowshankish,
to unlock
Kayvaun, “Manage data like a product
| McKinsey,”
[Online].
full
2022.
https://www.mckinsey.com/business-
Available:
functions/quantumblack/our-insights/how-to-unlock-the-
full-value-of-data-manage-it-like-a-product

Jun.

[17] J. Donˇcevi´c, K. Fertalj, M. Brˇci´c, and A. Krajna,
“Mask-Mediator-Wrapper: A revised mediator-wrapper
architecture for heterogeneous data source integration,”
Aug. 2022, arXiv:2208.12319 [cs]. [Online]. Available:
http://arxiv.org/abs/2208.12319

[18] M. Kleppmann, Designing Data-Intensive Applications:
The Big Ideas Behind Reliable, Scalable, and Maintain-
able Systems, 1st ed.
Boston: O’Reilly Media, May
2017.

[19] Y. Asano, S. Hidaka, Z. Hu, Y. Ishihara, H. Kato,
H.-S. Ko, K. Nakano, M. Onizuka, Y. Sasaki,
T. Shimizu, K. Tsushima, and M. Yoshikawa, “A
View-based Programmable Architecture for Controlling
and Integrating Decentralized Data,” arXiv:1803.06674
[cs], Mar. 2018, arXiv: 1803.06674. [Online]. Available:
http://arxiv.org/abs/1803.06674

[20] M. E. Conway, “HOW DO COMMITTEES INVENT?”

