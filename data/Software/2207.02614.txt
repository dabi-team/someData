2
2
0
2

l
u
J

6

]

R
C
.
s
c
[

1
v
4
1
6
2
0
.
7
0
2
2
:
v
i
X
r
a

Securing Optimized Code Against Power Side
Channels

Rodothea Myrsini Tsoupidi
Royal Institute of Technology KTH
Stockholm, Sweden
tsoupidi@kth.se

Roberto Casta˜neda Lozano
Independent Researcher
Stockholm, Sweden
rcas@acm.org

Elena Troubitsyna
Royal Institute of Technology KTH
Stockholm, Sweden
elenatro@kth.se

Panagiotis Papadimitratos
Royal Institute of Technology KTH
Stockholm, Sweden
papadim@kth.se

Abstract—Side-channel attacks impose a serious threat to
cryptographic algorithms, including widely employed ones, such
as AES and RSA, taking advantage of the algorithm implemen-
tation in hardware or software to extract secret information
via timing and/or power side-channels. Software masking is a
software mitigation approach against power side-channel attacks,
aiming at hiding the secret-revealing dependencies from the
power footprint of a vulnerable implementation. However, this
type of software mitigation often depends on general-purpose
compilers, which do not preserve non-functional properties.
Moreover, microarchitectural features, such as the memory bus
and register reuse, may also reveal secret information. These
abstractions are not visible at the high-level implementation of the
program. Instead, they are decided at compile time. To remedy
these problems, security engineers often sacriﬁce code efﬁciency
by turning off compiler optimization and/or performing local,
post-compilation transformations. This paper proposes Secure
by Construction Code Generation (SecConCG), a constraint-
based compiler approach that generates optimized yet secure
code. SecConCG controls the quality of the mitigated program
by efﬁciently searching the best possible low-level implementation
according to a processor cost model. In our experiments with
ten masked implementations on MIPS32 and ARM Cortex M0,
SecConCG speeds up the generated code from 10% to 10x
compared to non-optimized secure code at a small overhead
of up to 7% compared to non-secure optimized code. For
security and compiler researchers, this paper proposes a formal
model to generate secure low-level code. For software engineers,
SecConCG provides a practical approach to optimize code that
preserves security properties.

Index Terms—compilation, power side-channel attacks, code

optimization, masking

I. INTRODUCTION

Cryptographic algorithms, symmetric/shared key or asym-
metric/private key ones, rely on safeguarding the shared secret
key or the private key, respectively. The exposure of these
keys to unintended users compromises the security of these
algorithms. Unfortunately,
the software implementation of
cryptographic algorithms may reveal information about their
secret/private keys [1]. In particular, the attacker may observe
what is termed side-channel information, notably observing the
execution time [1] or the power consumption [2, 3], during
the execution of the algorithm to extract information about

the secret keys. These attacks are attractive especially as they
usually do not require expensive equipment.

Software masking is a widely-used approach to mitigate
power side-channel attacks [4, 5], hiding secret information
by splitting a secret into n randomized shares. The attacker
has to retrieve all shares in order to acquire the secret value.
While software masking can be an effective mitigation, it can
be invalidated by compiler code generation. Moreover, some of
the leakage sources, such as register reuse or memory access,
are decided at compile time by low-level transformations [6,
7, 8].

To mitigate these compiler-induced side-channel leaks at the
binary level there are techniques based on compilation [7, 9,
10] and binary rewriting with hardware emulation [11, 12]. All
these approaches mitigate compiler-generated leakages using
local transformations [7, 11]. The methods that depend on
hardware emulation are typically accurate but introduce sig-
niﬁcant overhead [11]. In particular, Rosita [11], an emulation-
based approach, propose a mitigation that introduces an over-
head of 24% to 64%. Wang et al. [7] perform their mitigation
using a standard compiler with no optimizations (-O0). This is
a common practice for security research to ensure the absence
of compiler-induced mitigation invalidation [6, 13]. However,
unoptimized code is highly inefﬁcient. Moreover, unoptimized
code may introduce additional leaks due to the heavy use of
the program stack, as discussed in Section II.

There are also approaches for secure optimization of code
at a higher level [13, 14]. These approaches apply high-level
compiler optimizations by disallowing secure-code removal
and operand reordering (due to associativity of some opera-
tions). However, their high-level nature does not allow them to
handle low-level leaks related to register reuse and instruction
order.

The state-of-the-art approaches do not generate code that is
both efﬁcient and secure in the face of side-channel attacks.
this paper proposes Secure by
To address this challenge,
Construction Code Generation (SecConCG), an optimizing
compiler approach that provably preserves security proper-
the frontend, SecConCG handles code generated
ties. At

 
 
 
 
 
 
using register promotion as a high-level optimization. Then,
SecConCG uses a constraint-based method to generate code
that is secure. SecConCG controls the quality of the mitigated
program by efﬁciently searching the best possible low-level
implementation according to a processor cost model [15]. The
security model of SecConCG is hardware agnostic and can
be extended with additional architectural constraints. In our
experiments with ten masked implementations on MIPS32 and
ARM Cortex M0, SecConCG improves the execution time of
the generated code from 10% to a speedup of 10x compared
to non-optimized secure code at a small overhead of up to
7% compared to non-secure optimized code. In summary, this
paper makes the following contributions:

• a compiler approach to generate leak-free, low-overhead
assembly code for high-level software-masked programs;
• a constraint model for optimized, secure code generation;
• a proof that the constraint model guarantees the genera-
tion of secure code for a non-trivial leakage model; and
• experimental results on two architectures showing that
the overhead of our mitigation is low and its efﬁciency
beneﬁts are signiﬁcant compared to current approaches.

II. MOTIVATING EXAMPLE

We consider an example of a ﬁrst-order masked implemen-
tation to motive our approach. First-order masking splits a
secret value k into two shares, (m, mk), where m is a uniformly
distributed random variable sampled at every execution of
the algorithm; mk = m ⊕ k is also uniformly distributed (⊕
denotes the exclusive OR operation). Figure 1 shows a ﬁrst-
order masked C implementation of exclusive OR, where key
is a secret value, mask is a uniformly random variable, and
pub is a non-secret value. At line 2, the algorithm creates
the second share, mk, and at line 3, it performs the exclusive
OR operation with the secret-independent value, pub. At
a high-level, the code of Figure 1 is secure but a binary
implementation generated by a standard, security-unaware
compiler may leak information about key. For example,
hardware-register reuse and memory-bus access may reveal
secret information [7, 11, 6, 8]. These leaks are a result of
transitional effects, i.e., the power effect of bits switching
between one and zero.

Figure 3a shows the ARM Cortex M0 assembly code
generated by the standard compiler LLVM [16] for the C code
in Figure 1. The ﬁrst three str instructions store the function
arguments that reside in registers r0-r2 to the stack (lines
3-5). Line 6 loads (ldr) the value of rand from the stack
into register r1. Line 7 performs the ﬁrst exclusive OR (line
2 in Figure 1) and stores the result in register r1. Here, there
is a transition for register r1 from value mask to mk, which
leaks the secret key. Line 8 stores the content of r1 to the
stack and the value of the memory bus that contains the mask
at line 6 transitions to mk. This leads to another leak due to
the transitional effect in the memory bus. The rest of the code
performs the second exclusive OR (line 10) and stores the ﬁnal
result on the stack (line 11).

Figure 3b shows the mitigation produced by the security
backend of SecConCG that eliminates leakages that appear
in the LLVM unoptimized code. The mitigation is based on
instruction scheduling and register allocation transformations.
In particular, changing the order of operands at line 7 results
in a transition from sec to mk that leaks the value of mask,
which is not secret. Changing the order of the instructions
hides the memory-bus leakage. More speciﬁcally, because
there are no data dependencies between lines 3-6, the ldr
instruction that causes the leak in Figure 3a may be scheduled
earlier (line 4 in Figure 3b). Then, another memory instruction
that stores the secret value in memory (line 6 in Figure 3b)
is scheduled just before the store instruction at line 8. This
causes a transition from sec to mk in the memory bus
leaks the value of mask. These transformations are
that
global, considering possible available memory instructions and
register assignments to mitigate transitional leakages without
introducing any overhead.

However, unoptimized code leads to poor performance.
In general, compiler optimizations may invalidate high-level
software mitigations [13]. Fortunately, this is not the case
for register promotion (mem2reg in LLVM), a simple high-
level optimization that enables efﬁcient register allocation
by promoting program variables from memory to registers.
The register promotion optimization preserves the instruction
ordering and does not remove any redundant operations.
Equipped with improved high-level code,
the SecConCG
transformations and generates
backend optimizes low-level
optimized code. Figures 2a and 2b show the code of Fig-
ure 1 compiled with register promotion. Figure 2a leaks the
same secret information as Figure 3a due to register reuse,
namely the ﬁrst exclusive OR operation eors, but contains
no memory-bus secret leak. To mitigate the register-reuse leak
at line 2, SecConCG changes the order of the arguments and
the result is now stored in register r2.

As we see in Figure 3a, unoptimized code may introduce
additional leaks due to the heavy use of the program stack.
Instead, SecConCG uses register promotion to remove un-
necessary memory accesses that may cause additional leaks.
Then, SecConCG’s backend generates low-level optimized
information and does not
code that does not
introduce signiﬁcant overhead.

leak secret

III. THREAT MODEL AND MODELING BACKGROUND

This section describes the Hamming Distance (HD) model
(Section III-A),
the threat model (Section III-B), an HD-
based type-inference algorithm (Section III-C), a constraint-
based compiler backend model (Section III-D), and the run-
ning example for the constraint-based compiler backend (Sec-
tion III-E),

A. Hamming-Distance Model

The Hamming Weight (HW) model [17, 2, 18] corresponds
to the number of active bits in a data word. We assume the
following encoding of the binary data, d = (cid:80)N −1
i=0 2idi, where
is one if the ith bit of an N-bit word is set and zero
di

1 u32 Xor(u32 pub, u32 mask, u32 key) {
2
3
4
5 }

u32 mk = mask ˆ key;
u32 t = pub ˆ mk;
return t;

Fig. 1: Masked exclusive OR implementation in C

1 @ r0: pub, r1: rand, r2: key
2 ...
3 str
4 str
5 str
6 ldr
7 eors

r0, [sp, #16] @ mem: pub
r1, [sp, #12] @ mem: rand
r2, [sp, #8]
r1, [sp, #12] @ mem: rand
r1, r2

@ mem: key

@ proc: rand <- rand ˆ key

8 str
9 ldr
10 eors

r1, [sp, #4]
r0, [sp, #16] @ mem: pub
r0, r1

@ mem: rand ˆ key

@ proc: pub <- pub ˆ rand ˆ key

11 str

r0, [sp]
@ mem: pub ˆ rand ˆ key

12 ...

1 @ r0: public, r1: random, r2: secret
2
3
4

eors r2, r1
eors r0, r2
...

eors
eors
...

r1, r2
r0, r1

2
3
4

(a) Insecure (LLVM)

(b) Secure (SecConCG)

Fig. 2: Compilation of function Xor applying register
promotion

1 @ r0: pub, r1: rand, r2: key
2 ...
3 str
4 ldr
5 str
6 str
7 eors

r1, [sp, #12] @ mem: rand
r1, [sp, #12] @ mem: rand
r0, [sp, #16] @ mem: pub
r2, [sp, #8]
@ mem: key
r2, r1

@ proc: key <- sec ˆ rand

8 str
9 ldr
10 eors

r2, [sp, #4]
r0, [sp, #16] @ mem: pub
r0, r2

@ mem: key ˆ rand

@ proc: pub <- pub ˆ key ˆ rand

11 str

r0, [sp]
@ mem: pub ˆ rand ˆ key

12 ...

(a) Insecure (LLVM)

(b) Secure (SecConCG with no register promotion)

Fig. 3: Compilation of function Xor with no optimizations

otherwise. The HW of this data is the number of bits that are
set: HW (d) = (cid:80)N −1
i=0 di. The HD leakage model assumes
that the observed leakage when ﬂipping the bits of a memory
element from a value d1 to a value d2 is HW (d1 ⊕ d2),
where ⊕ denotes the exclusive OR operation. If one of the
values d1 is a uniform random variable, then d1 ⊕ d2 is also a
uniform random variable and HW (d1⊕d2) has the same mean
and variance as HW (d1) [18]. This means that by masking
(exclusive bitwise OR) a secret value k with a uniform random
variable m, the HD of the new variable has the same mean
and variance as m. In this way, masking hides the information
of k from the power consumption traces.

We assume a program P (IN) = i1; i2; ..., in that takes as
input a set of variables IN and consists of a sequence of n
instructions ij. We assume that the program has a leakage at
every execution step when there is bit ﬂipping in the hardware
registers or the memory bus. We represent the leakage as
a set of observations in the power trace. To calculate the
observed leakage L(P (IN )) for an instance IN of the input
variables, we use the HD leakage model. We write P = P (cid:48); in
to denote a program P = i1; i2; ...; in−1; in, with a preﬁx
P (cid:48) = i1; i2; ...; in−1 (IN is omitted for simplicity).

Equations 1-6 present the leakage model. In the formulas,
an expression e is e := r | bop(e1, e2) | uop(e1) | mem(ea, e),
where r is a register, bop is a binary operation, uop is
a unary operation, and mem(ea, e) is a memory load op-
eration accessing address ea with data e. An instruction is
i = r ← e | mem(e1, e2), where r ← e denotes that an
expression is assigned to register r, and mem(ea, e) is a store

memory operation. Equation 1 describes the leakage when
two instructions write the value of their result to the same
register and no other instruction between them writes to the
same register. Note that the ﬁrst equation deals also with
instructions in the form r ← bop(r, r(cid:48)), where bop is a
binary operation. These two-address instructions are common
in ARM Thumb and x86 architectures. Equation 2 describes
the leakage of a memory instruction that writes a value to the
memory, given that another memory instructions precedes this
memory instruction. Equation 3 describes the leakage when a
memory instruction loads a value from memory to a register.
Here, we have two leaked values, one from the memory bus
and one from the register reuse. Finally, Equations 4-6 describe
the leakage when no (known) preceding operations write to the
same register or use the memory bus.

B. Threat Model

We assume that the attacker has access to the software
implementation and the public data but not the secret data.
The goal of the attacker is to extract information about the
secret data, by measuring the power consumption of the
device that the code runs on. The attacker may accumulate
a number of traces and perform statistical analysis, such as
Differential Power Analysis (DPA) [2]. At every execution,
new random values are generated and the attacker has no
knowledge of the values of these variables. Our goal is to
eliminate any statistical dependencies between the secret data
and the measured power traces.

L(P (cid:48); r ← e2; P (cid:48)(cid:48); r ← e1)

=L(P (cid:48); r ← e2; P (cid:48)(cid:48)) ∪ {HW (e1 ⊕ e2)}, e1 (cid:54)= mem(ea, e3) ∧

L(P (cid:48); i1; P (cid:48)(cid:48); mem(eb, e2))

(cid:64)i ∈ P (cid:48)(cid:48). i = r ← e3

(1)
=L(P (cid:48); i1; P (cid:48)(cid:48)) ∪ {HW (e1 ⊕ e2)}, (i1 = mem(ea, e1) ∨ i1 = r ← mem(ea, e1)) ∧
(2)

(cid:64)i ∈ P (cid:48)(cid:48).( i = mem(ec, e3) ∨ i = r ← mem(ec, e3))

L(P (cid:48); i1; P (cid:48)(cid:48); i2; P (cid:48)(cid:48)(cid:48); r ← mem(ea, e1)) =L(P (cid:48); i1; P (cid:48)(cid:48); i2; P (cid:48)(cid:48)(cid:48)) ∪ {HW (mem(ea, e1) ⊕ e2), HW (e1 ⊕ e3)},

L(P (cid:48); r ← e)
L(P (cid:48); mem(ea, e1))
L(P (cid:48); r ← mem(ea, e))

∃j ∈ [1, 2].ij = r ← e2 ∧ (cid:64)i ∈ P (j). i = r ← e4 ∧

(i2−j = mem(eb, e3) ∨ i2−j = r(cid:48) ← mem(eb, e3)) ∧
(cid:64)i ∈ P (2−j). i = (mem(ec, e5) ∨ i = r(cid:48) ← mem(ec, e5)) ∧
P (2) = P (cid:48)(cid:48)(cid:48) ∧ P (1) = P (cid:48)(cid:48); i2; P (cid:48)(cid:48)(cid:48)

=L(P (cid:48)) ∪ {HW (e)}, e2 (cid:54)= mem(e21, e22) ∧ (cid:64)i ∈ P (cid:48). i = r ← e3
=L(P (cid:48)) ∪ {HW (e1)}, (cid:64)i ∈ P (cid:48). i = mem(eb, e3) ∨ i = r ← mem(eb, e3)
=L(P (cid:48)) ∪ {HW (mem(ea, e)), HW (e)},

(cid:64)i ∈ P (cid:48). i = r ← e3 ∨ i = mem(eb, e(cid:48)) ∨ i = r(cid:48) ← mem(eb, e(cid:48))

(3)

(4)

(5)

(6)

We assume that input variables are Secret, Public,
or Random. Secret variables contain sensitive values
(e.g. cryptographic keys), which the attacker wants to retrieve
information about. Public variables contain values that the
attacker knows or may learn without causing a leakage.
Finally, Random variables follow the uniform distribution in
the domain of the corresponding program variable. We deﬁne
the Leakage Equivalence security condition for the generated
programs as follows:

Deﬁnition 1 (Leakage Equivalence). Given a program P (IN)
that has a set of secret input variables, INsec ⊆ IN, a set
of random input variables, INrand ⊆ IN, and a set of public
input variables, INpub ⊆ IN. We assume two instances of the
input variables, IN and IN (cid:48). These two instances differ with
regards to the set of secret variables IN sec and IN (cid:48)
sec, i.e. for
all public variables, ∀v ∈ IN pub and ∀v(cid:48) ∈ IN (cid:48)
pub we have
v = v(cid:48). Let r ∈ IN rand and r(cid:48) ∈ IN (cid:48)
rand be sampled from a
uniform random distribution. Let Lp = L(P (IN )) and L(cid:48)
p =
L(P (IN (cid:48))). Then, we say that a program is leakage equivalent
if the distributions of the leakage of the two executions do not
differ, i.e.
(cid:88)

(cid:88)

(cid:88)

(cid:88)

Var (l) =

Var (l(cid:48)),

E[l] =

E[l(cid:48)] ∧

l∈Lp

l(cid:48)∈L(cid:48)
p

l∈Lp

l(cid:48)∈L(cid:48)
p

where E[l] and Var (l) are l’s expected value and variance.

C. HD-based Vulnerability Detection

In our approach, we need a technique to analyze whether
two values leak secret information or not. There are different
ways to identify whether there is a leak at some part of
the code. One approach is to use symbolic execution [6, 8].
Symbolic execution executes different paths of a program
symbolically and veriﬁes or invalidates speciﬁc properties
with the help of Satisﬁability Modulo Theory (SMT) solvers.
Symbolic execution is accurate but has scalability issues when

the number of problem variables or program paths increases.
On the other end, type-based approaches are typically efﬁcient
but at the price of accuracy. Wang et al. [7] propose a type-
inference algorithm to infer security types to the variables
of the program under analysis. In particular, they consider
a hierarchy of three types based on the properties of the
distribution they follow: uniformly random distribution, secret
independent distribution, or ﬁnally unknown distribution. We
call these, Random, Public, and Secret, respectively. The
type-inference algorithm assigns a type to each program vari-
able. To infer the program variable types, Wang et al. deﬁne a
logic model and solve it using an SMT solver. The complexity
of this approach is low compared to symbolic execution, at the
price of lower accuracy. However, the accuracy is sufﬁcient
for loop-free,
linearized programs, such as many masked
implementation [7]. Because of this, our approach uses type-
inference analysis, adapted with some accuracy improvements
(see Appendix, Section A).

D. Constraint-based Compiler Backend

A compiler backend performs three main low-level transfor-
mations to optimize and generate low-level code: instruction
selection, instruction scheduling, and register allocation. A
combinatorial compiler backend [15, 19, 20] uses combi-
natorial solving techniques to optimize software using the
aforementioned transformations. Different approaches may
implement one or more low-level transformations. This section
focuses on Constraint Programming (CP) [21] as a combina-
torial solving technique.

1) Constraint Model: The constraint-based compiler back-
end generates a constraint model that captures the program
semantics, the low-level compiler transformations, and the
hardware architecture. This paper focuses on two compiler
transformations, register allocation and instruction schedul-
that are crucial for our mitigation. The backend can
ing,

o1: in [t0 ← pub, t1 ← mask, t2 ← key]
o2: t3 ← [-, copy] t0
o3: t4 ← [-, copy] t1
o4: t5 ← [-, copy] t2
o5: t6 ← xor [t1,t4] [t2,t5]
o6: t7 ← [-, copy] t6
o7: t8 ← xor [t0,t3] [t6,t7]
o8: t9 ← [-, copy] t8
o9: out [t10 ← [t8,t9]]

Fig. 4: Simpliﬁed model of the function in Figure 1

be modeled as a Constraint Optimization Problem (COP),
P = (cid:104)V, U, C, O(cid:105), where V is the set of decision variables
of the problem, U is the domain of these variables, C is the
set of constraints among the variables, and O is the objective
function. A constraint-based backend aims at minimizing O,
which typically models the code’s execution time or size.

A program is modeled as a set of basic blocks B, pieces
of code with no branches apart from the their entry and
exit. Each block contains a number of optional operations,
o ∈ Operations, that may be active or not. The set of hardware
instructions that implement operation o is denoted by Ins o.
Each operation includes a number of operands p ∈ Operands,
each of which may be implemented by different, equally-
valued temporaries, t ∈ Temps. Temporaries are either not
live or assigned to a hardware register.

Figure 4 shows a simpliﬁed version of the constraint-based
compiler backend model for Figure 1. Temporaries t0, t1,
and t2 contain the input arguments pub, mask, and key,
respectively. Copy operations (o2, o3, o4, o6, o8) en-
able copying program values from one register to another and
are critical for providing ﬂexibility in register allocation. For
example, o2, allows the copy of the value pub from t0 to
t3. However, in the ﬁnal solution, a copy operation may not
be active (shown by the dash in the set of instructions). The
two xor operations (o5, o7) take two operands each, and
each of these operands can in its turn use different but equally-
valued temporary variables, e.g. t1 and t4.

Figure 5 shows a valid solution to the register allocation
of the previous example. All copy operations are deactivated
and t0, t1, and t2 are assigned to registers R0, R1, R2.
Temporary t6 is assigned to R1 and temporary t8 is assigned
to R0. This register assignment
is problematic because it
induces a transition in register R1 from the initial value that
holds the mask to the masked value mask ⊕ key, which
leads to a leakage L(R1 ← rand; R1 ← rand ⊕ sec) =
{HW (mask ⊕ (mask ⊕ key))} = {HW (key)} that leaks
information about key.

The model of instruction scheduling assigns issue cycles
to each operation. This assignment imposes an ordering of
the operation and is constrained by the program semantics.
For example, in Figure 4, scheduling o6 before o5 is not
allowed because o6 depends on o5 but scheduling o4 before
o3 is possible. In Figure 3b, the store instruction at line 6

o1: in [t0:R0, t1:R1, t2:R2]
o5: t6:R1 ← xor t1:R1 t2:R2
o7: t8:R0 ← xor t0:R0 t6:R1
o9: out [t10:R0]

Fig. 5: Solution of the model in Figure 4

(that corresponds to line 5 in Figure 3a) is scheduled after
the load instruction at line 4 (line 6 in Figure 3a). This is
allowed because there is no dependency between these two
instructions.

The decision variables of the constraint problem are:
• r(t) ∈ Regs t, t ∈ Temps denotes the hardware register

assigned to temporary t;

• a(o) ∈ [false, true], o ∈ Operations denotes

whether operation o is active or not;

• i(o) ∈ Ins o, o ∈ Operations is the instruction that

implements operation o;

• c(o) ∈ [0, maxc], o ∈ Operations is the cycle at which

an operation o is scheduled, bounded by maxc;

• y(p) ∈ Temps p, p ∈ Operands is the selected temporary

among all possible temporaries for operand p.

In addition to these, l(t) ∈ [false, true], t ∈ Temps
ls(t) ∈
represents whether a temporary is live or not,
[0, maxc], t ∈ Temps represents the cycle at which t becomes
live, and le(t) ∈ [0, maxc], t ∈ Temps represents the last
cycle at which t is live, with ls(t) > le(t), t ∈ Temps. An
important constraint of register allocation is that the register
live ranges of a speciﬁc hardware register ri do not overlap:

∀t1, t2 ∈ Temps . l(t1) ∧ l(t2) ∧ r(t1) = r(t2) =⇒

ls(t1) ≥ le(t2) ∨ ls(t2) ≥ le(t1).

(7)

Moreover, when a temporary is live, its last live cycle (le)

is strictly greater than its live start (ls):

∀t ∈ Temps . l(t) =⇒ ls(t) < le(t).

(8)

2) Objective Function: A typical objective function of a
constraint-based backend minimizes different metrics such as
code size and execution time. These can be captured in a
generic objective function that sums up the weighted cost of
each basic block:

weight(b) · cost(b).

(cid:88)

b∈B

The cost of each basic block consists of the cost of the speciﬁc
implementation and is a variable, whereas weight is a constant
value that represents the contribution of the speciﬁc basic
block to the total cost.

E. Example in a Constraint-based Compiler Backend

Low-level transformations, like register allocation and in-
struction scheduling, affect the security of programs. Figure 6a
shows the high-level masked implementation of exclusive OR
in C (same as Figure 1). The code takes three inputs: p (a

u32 Xor(u32 p, u32 m,

R0 R1 R2

u32 k) {

u32 mk = m ˆ k;
u32 rs = mk ˆ p;
return rs;

}

p

rs

m

k

mk

R0: p, R1: m,
R2: k

R1 = R1 ˆ R2
R0 = R0 ˆ R1

R0 R1 R2

p

rs

k

m

mk

R0: p, R1: m,
R2: k

R2 = R2 ˆ R1
R0 = R0 ˆ R2

(a) Exclusive OR in C.

(b) Vulnerable register assignment

(c) Secure register assignment

Fig. 6: The exclusive OR example, illustrating a HD vulnerability and alternative register assignments

Public value), k (a Secret value), and m (a Random
variable). The code computes ﬁrst the exclusive OR of m and
k and stores it in mk. Then, it computes the exclusive OR of
mk with p and stores it in rs, which the function returns.

Figure 6b shows a register allocation of function Xor that
leads to a HD vulnerability. Both m and mk are stored in the
same register, hence the content of mk replaces the previous
value m in register R1. According to the leakage model,
the attacker observes the exclusive OR between the initial
and updated value of a hardware register. Using the register
allocation of Figure 6b, the leakage reveals information about
the secret: HW(mk ⊕ m) = HW((m ⊕ k) ⊕ m) = HW(k). Value
k is a secret value, and thus, a leak occurs.

A constraint-based compiler backend is able to generate all
legal register allocations for a program. Figure 6c shows an
alternative register allocation for function Xor. Here, the result
of mk is written in hardware register R2, giving a HD leakage
HW(mk ⊕ k) = HW((m ⊕ k) ⊕ k) = HW(m). The leakage
here corresponds to the value of m, which is not a sensitive
value. In a similar way, instruction scheduling may be able to
remove leakages as seen in Figure 3. By changing the schedule
of the instructions, the model is often able to generate a secure
solution with no code quality overhead.

This example shows that low-level transformations can be
responsible for the introduction of HD vulnerabilities and have
thus to be taken into account to provide effective mitigations.

IV. SECCONCG

This section introduces SecConCG, an approach to opti-
mize code that does not expose secret information and is
secure against power side-channel attacks. Figure 7 shows
the high-level view of SecConCG. SecConCG is a constraint-
based optimizing secure compiler, i.e. it extends a constraint-
based compiler backend with security constraints. It takes two
inputs: 1) a C or C++ program, and 2) a security policy
denoting which variables are Secret, Random, or Public.
SecConCG enables register promotion at the compiler middle-
end because this optimization preserves the high-level proper-
ties of the program and, at the same time, creates substantial
the constraint-
opportunities for register allocation. Then,
based compiler backend, extended with security constraints,
takes as input the program in a machine-level Intermediate
Representation (IR) and the security policy. Next, SecConCG

performs a security analysis (see Section III-C). The results
are used to impose constraints that prevent HD vulnerabilities.
Given the secure model, the approach generates an optimized
solution.

Section IV-A presents the security analysis. Section IV-B
the

the secure constraint model

that extends

presents
constraint-based compiler backend.

A. Security Analysis

SecConCG performs a security analysis to extract
the
security types of each program variable and, subsequently,
generates constraints that prohibit insecure low-level imple-
mentations. The security analysis identiﬁes the security type
(Random, Public, or Secret) of each intermediate vari-
able. In the compiler constraint model, the program variables
are the input operands and the result of each operation.
Each operand can use a number of alternative temporary
values t ∈ Temps and each temporary value is assigned to
a register (see Section III-D). The type-inference rules do
not handle such program constructs. However, cryptographic
implementations that are free from power-side channels are
often linearizable [7].

The security analysis uses a type-inference algorithm based
on Wang et al. [7]. We extend this algorithm with additional
deﬁnitions that improve the accuracy of the type inference
(Section A). At the end of the analysis, all temporary variables
have an inferred type. Figure 8 shows the inferred security
types for each of the temporaries in our running example.
Temporaries t0 and t3 are Public, t2 and t5 are Secret,
and t1, t4 and t6-t10 are Random.

The type-inference algorithm is conservative. Function
type(t) : Temps → {R, S, P } returns the type assigned to
temporary variable t. This section abbreviates the types as
follows: type R corresponds to Random, S corresponds to
Secret, and P corresponds to Public.

In the following, we deﬁne the data that the security analysis
provides to the constraint model, which the latter requires to
impose security constraints. According to the leakage model,
when a hardware register changes from one value to another,
the exclusive OR of the two values is exposed. Rpairs is
the set of temporary variable pairs that when xor:ed together

SecConCG

source
code

Compiler
Frontend
(RegProm)

IR

Backend
Analysis

IR

Security
Analysis

secure
model

Optimizer

optimized
solution

Security Policy

Fig. 7: High-level view of SecConCG

o1: in [t0:Public, t1:Random, t2:Secret]
o2: t3:Public ← [-, copy] t0
o3: t4:Random ← [-, copy] t1
o4: t5:Secret ← [-, copy] t2
o5: t6:Random ← xor [t1,t4] [t2,t5]
o6: t7:Random ← [-, copy] t6
o7: t8:Random ← xor [t0,t3] [t6,t7]
o8: t9:Random ← [-, copy] t8
o9: out [t10:Random ← [t8,t9]]

Fig. 8: Typed intermediate representation

reveal secret information:

Rpairs = {(t1, t2) | t1 ∈ Temps ∧ t2 ∈ Temps ∧

(type(t1) ∈ {R, P }) ∧ (type(t2) ∈ {R, P }) ∧
(type(t1 ⊕ t2) = S)}.
(9)

In the running example (Figure 8), Rpairs = [(t1, t6),
(t1, t7), (t1, t8), (t1, t9), (t4, t6), (t4, t7), (t4, t8), (t4, t9),
(t6, t7), (t6, t8), (t6, t9), (t7, t8), (t7, t9), (t8, t9)]. For every
pair of temporaries in Rpairs, a constraint
is added to
prohibit their contiguous assignment to the same register (like
m and mk in Figure 6b).

Rpairs do not consider secret values. Instead, if the type
of a temporary variable t is Secret, we impose a different
constraint because the secret information will always result
in a leak. In this case, we impose the constraint that another
random variable should precede the deﬁnition of the secret
variable to mask the secret information. Spairs is a set of
pairs, each of which consists of a secret temporary variable t
and a set of random temporary variables ts that are able to
hide the secret information, i.e. ∀t(cid:48) ∈ ts . type(t(cid:48) ⊕ t) = R:

Spairs = {(t, ts) | t ∈ Temps ∧ type(t) = S ∧

ts = {t(cid:48) | t(cid:48) ∈ Temps ∧

type(t(cid:48)) = R ∧ type(t(cid:48) ⊕ t) = R}}.

(10)

Memory operations may also reveal secret

In the example (Figure 8), Spairs = [(t5, [t4, t6, t7, t8, t9])].
information.
We assume the same leakage model (HD model) for the
memory bus as for the register-reuse transitional effects. This
means that the leakage corresponds to the exclusive OR of
two subsequent memory operations. M mpairs includes the

memory operations that result
in memory-bus transitional
leakage, i.e. if the sequence of this pair of memory operations
when scheduled subsequently leads to a secret leakage.

M mpairs = {(o1, o2) | o1 ∈ MemOperations ∧

o2 ∈ MemOperations ∧
type(tm(o1)) = {R, P } ∧
type(tm(o1)) ∈ {R, P } ∧
type(tm(o1) ⊕ tm(o2) = S)}.

(11)

Here, tm(o) ∈ Temps is the temporary that corresponds to
the memory data of the operation. In the example (Figure 8),
M mpairs = [(o3, o6), (o3, o8), (o6, o8)], in case o3, o6, o8,
are memory spills. Note that Figure 8 does not include all
copies for memory spilling as we would need to duplicate the
copies for ﬁrst storing and then loading the variables.

The same leakage as in the case when a secret value was
written to a register applies here. If a memory operation
stores/loads a secret value to/from the memory, a random
memory operation that is able to hide the secret information
should precede this operation. M spairs is a set of pairs,
each of which consists of the memory operation that accesses
secret data, o, and a set of memory operations that access
random data and are able to hide the secret information, i.e.
type(tm(o(cid:48)) ⊕ tm(o)) = R:

M spairs = {(o, os) | o ∈ MemOperations ∧

type(tm(o)) = S ∧
os = {o(cid:48) | o(cid:48) ∈ MemOperations ∧
type(tm(o(cid:48))) = R ∧
type(tm(o(cid:48)) ⊕ tm(o)) = R}}.

(12)

In the example (Figure 8), M spairs = [(o4, [o3, o6, o8])], in
case o4, o3, o6, o8 is spilled in memory.

The security analysis provides Rpairs, Spairs, M mpairs,
and M spairs to the constraint model, which enables con-
straining code generation to generate secure implementations.

B. Constraint Model

The constraint model takes as input the four sets computed
by the security analysis (Rpairs, Spairs, M mpairs, and
M spairs) and uses them to generate appropriate constraints
that prohibit insecure solutions.

factorial.csecpol.txtfactorial.o101001010100111101100110001100100110100011100100010011o1: in [t0:R0, t1:R1, t2:R2]
o3: t4:R3 ← t1:R1
o4: t5:R3 ← t2:R2
o5: t6:R3 ← xor t1:R1 t5:R3
o7: t8:R0 ← xor t0:R0 t6:R3
o9: out [t10:R0]

Fig. 9: Solution of the model in Figure 4

Predicate samereg tells whether the two input temporaries
are active (l(t) = 1) and are assigned to the same register.

pred samereg(t1,t2):

l(t1) ∧ l(t2) ∧ (r(t1) = r(t2))

In Figure 5, constraint samereg(t0,t8) = true,
samereg(t1,t6) = false, and samereg(t1,t7) =
false (t7 is not live).

1) Rpairs Constraints: The following constraint ensures
that a pair of random (or public) temporaries in Rpairs
are either not assigned to the same register or they are not
subsequent (subseq constraint, deﬁned in Section IV-B5).

forall (t1,t2) in Rpairs:
samereg(t1, t2) =⇒

(¬subseq(t1,t2) ∧ ¬subseq(t2,t1))

In Figure 5, this constraint is not satisﬁed for t2 and t6.
2) Spairs Constraints: The following constraint ensures
that for each pair (ts, trs) ∈ Spairs, one of the random
temporaries tr ∈ trs precedes the secret temporary ts and
another random temporary succeeds ts, if ts is live.

forall (ts,trs) in Spairs:

exists tr in trs:

l(ts) =⇒ (l(tr) ∧ subseq(tr,ts))

∧
exists tr in trs:

l(ts) =⇒ (l(tr) ∧ subseq(ts,tr))

Figure 9 shows a solution to the model in Figure 4, where
both the Rpairs and the Spairs constraints are satisﬁed. t5
is active but is assigned to the same register as t4, which
precedes t5 and thus eliminates the leakage. Similarly, t6
follows the assignment of t5 and thus hides the secret value.
3) Mmpairs Constraints: The following constraint ensures
that a pair of non-secret memory operations in M mpairs,
are either not active or not subsequent memory operations
(msubseq constraint). Constraint msubseq (deﬁned in Sec-
tion IV-B5) is similar to subseq but considers consecutive
memory operations instead of temporaries.

forall (o1,o2) in M mpairs:

a(o1) ∧ a(o2) =⇒

(¬msubseq(o1,o2) ∧ ¬msubseq(o2,o1))

4) Mspairs Constraints: Finally, the following constraint
ensures that for each pair (os, ors) ∈ M spairs a random
memory operation or ∈ ors precedes the secret-dependent
memory operation os.

forall (os,ors) in M spairs:

exists or in ors:

a(os) =⇒ (a(or) ∧ msubseq(or,os))

∧
exists or in ors:

a(os) =⇒ (a(or) ∧ msubseq(or,os))

This constraint works similarly as the register equivalent,
where instead of register operations, we have memory oper-
ations. In particular, we need to have memory spilling, i.e.
store to the stack, and then load from the stack (only one of
the operations is shown in Figure 9).

5) Modeling subseq: To deﬁne the subseq constraint,
we ﬁrst deﬁne an auxiliary predicate is_before and a set of
auxiliary problem variables lk. Predicate is_before(t1,
t2) tells whether t1 is assigned to the same register as t2
and t1’s life range ends (le(t1)) before the beginning of
the life range of t2 (ls(t2)).

pred is_before(t1,t2): same_reg(t2, t1) ∧
(le(t2) ≤ ls(t1))

Variable lk(t) captures the end live cycle of the temporary
that occupied the same register as t (r(t)) right before t
was assigned. If t’ = lk(t), then the values of t and t’
result in a transitional effect that may reveal information to
the attacker.

forall t in Temps: lk(t) = max(

[ite(is_before(t(cid:48),t),le(t(cid:48)),-1)

| forall t(cid:48) in Temps])

Then, the deﬁnition of the subseq predicate is as follows:

pred subseq(t1,t2):

samereg(t1,t2) ∧ (lk(t2) = le(t1))

Theorem 1 (Subseq Constraint). The subseq constraint is
true only for pairs of temporary variables that are subse-
quently assigned to the same register:

subseq(t1,t2) ⇐⇒ P = P (cid:48); t1 ← e1; P (cid:48)(cid:48); t2 ← e2; P (cid:48)(cid:48)(cid:48) ∧

r(t1) = r(t2) ∧ ∀i ∈ P (cid:48)(cid:48) . i = t ← e =⇒ r(t) (cid:54)= r(t1).

Proof. (⇐) Assume P = P (cid:48); t1 ← e1; P (cid:48)(cid:48); t2 ← e2; P (cid:48)(cid:48)(cid:48) ∧
r(t1) = r(t2) ∧ ∀i ∈ P (cid:48)(cid:48)
. i = t = e ∧ r(t) (cid:54)= r(t1).
We consider all register assignments in P : P = ...; ti ←
ei; ...; t1 ← e2; ...; t2 ← e2; ...; tj ← ej...; all these assign-
ments are live because they appear in the ﬁnal program. For
all assignments tj following ti we have that le(tj) > ls(t2),
which implies that is_before(tj, ti) = false, and thus
all tj contribute with -1 to max in lk(t2). The same applies
for all registers that are assigned to a different register, they
contribute with -1 because is_before(tj, ti) = false.
Then, lk(t2) = max(le(t)|t ∈ {ti1 , ti2, .., t1}), where all
{ti1, ti2, .., t1} are assigned the same register, r(t2). Be-
cause these temporaries are assigned to the same register,
their live ranges do not overlap (Equation 7), i.e. ∀t, t(cid:48) ∈
{ti1, ti2 , .., t1} . ls(t) ≥ le(t(cid:48)) ∨ ls(t(cid:48)) ≥ le(t). Because
t1 ← e1 is scheduled last ∀t ∈ {ti1 , ti2, .., tin , t1} . ls(t1) ≥

le(t). Also, from Equation 8, le(t1) > ls(t1). This implies
that ∀t ∈ {ti1, ti2, .., tin } . le(t1) > le(t), so we have
lk(t2) = le(t1) and ∀t ∈ {ti1, ti2 , .., tin } . lk(t2) > le(t).
Therefore only for t1, subseq(t1, t2) = true.

perform structural induction on the program P to prove that
security constraints we introduce lead to secure programs. The
proof is available in the Appendix (Section B).

This

(⇒) Assume

subseq(t1, t2).
=

implies
that
samereg(t1, t2) ∧ lk(t2)
le(t1). Constraint
samereg(t1, t2) implies that r(t1) = r(t2) and l(t1) ∧ l(t2),
which means that they appear in the ﬁnal code, P , and are
assigned to the same register. Because lk(t2) = le(t1), t1 is
scheduled before t2 or P = P (cid:48); t1 ← e1; P (cid:48)(cid:48); t2 ← e2; P (cid:48)(cid:48)(cid:48).
Now, we only need to prove that there is no other assignment
of r(t1) in P (cid:48)(cid:48), i.e. ∀i ∈ P (cid:48)(cid:48)
. t ← e ∧ r(t) (cid:54)= r(t1).
If ∃i ∈ P (cid:48)(cid:48)
. t ← e ∧ r(t) = r(t1), then, because live
ranges do not overlap, le(t) > le(t1), which means that
lk(t2) = le(t), (cid:54)= le(t1), which is invalid.

For the deﬁnition of msubseq, we deﬁne an auxiliary
predicate is_before_mem and auxiliary problem variables
ok. Predicate is_before_mem(o1, o2) tells whether o1
is scheduled before o2.

pred is_before_mem(o1,o2):

a(o1) ∧ (c(o1) ≤ c(o2))

In Figure 9, is_before_mem(o4, o3) is true.

Variable ok(o) captures the issue cycle of memory oper-

ation o(cid:48) ∈ MemOperations that was issued before o.

forall o in MemOperations: ok(o) = max(
[ite(is_before_mem(o(cid:48), o), c(o(cid:48)), -1)

| forall o(cid:48) in MemOperations])

Similar to predicate subseq, msubseq is as follows:

pred msubseq(o1,o2):

a(o1) ∧ a(o2) ∧ ok(o2) = c(o1)

Theorem 2 (Msubsec Constraint). The msubseq con-
straint
is true only for two instructions that are subse-
quently accessing the memory: msubseq(o1,o2) ⇐⇒ P =
mem; P (cid:48)(cid:48); imem; P (cid:48)(cid:48)(cid:48) ∧ (cid:64)i ∈ P (cid:48)(cid:48) . i = mem(e(cid:48)(cid:48), e3) ∨ i =
P (cid:48); i(cid:48)
t ← mem(e(cid:48)(cid:48), e3), where imem and i(cid:48)
mem are memory op-
erations, imem = mem(e, e1) ∨ imem = mem(e, e1) and
mem = mem(e(cid:48), e2) ∨ i(cid:48)
i(cid:48)
Proof. Similar to Theorem 1.

mem = mem(e(cid:48), e2).

Theorem 3 shows that SecConCG generates secure code for

our threat model.

Theorem 3 (Secure Modeling). A program P, generated by
SecConCG, satisﬁes the leakage equivalence condition in
Deﬁnition 1. This means that given two input instances IN ,
IN (cid:48)
that differ only with regards to the secret variables,
IN sec ⊆ IN , IN (cid:48)
sec ⊆ IN (cid:48), the distributions of the leakages
do not differ.

Proof. We assume that the type-inference algorithm overap-
proximates the actual distribution of each variable. Then, we

V. EVALUATION

This section evaluates the quality of the generated code,

focusing on two axes:

Overhead What is the overhead in execution time for the
generated code using SecConCG? Here, we want
to
evaluate the introduced overhead of secure solutions
compared to optimized but
insecure solutions. To do
that, we compare the best known solution [15] with our
approach SecConCG.

Improvement What is the improvement in execution time of
the generated code over other techniques that use non-
optimized code? Here, we compare our results with the
work by Wang et al. [7].

A. Preliminaries

1) Implementation Details: SecConCG is implemented as
an extension of Unison [15], a constraint-based compiler
backend that uses CP to optimize software functions with
regards to code size and execution time. In particular, Unison
combines two low-level optimizations, instructions scheduling
and register allocation, and achieves optimizing medium-size
functions with improvement compared to LLVM. Register
allocation assigns machine registers to temporaries, whereas
instruction scheduling decides on the order of the operations.
The type-inference implementation is written in Haskell and
is based on Wang et al. [7] with precision improvements
described in the Appendix (Section A).

experiments

2) Experimental Setup: All

run on an
Intel®Core™i9-9920X processor at 3.50GHz with 64GB of
RAM running Debian GNU/Linux 10 (buster). We use LLVM-
3.8 as the frontend compiler for these experiments. To pre-
serve the high-level security properties of the compiled pro-
grams, we apply only one optimization, register promotion,
(-mem2reg in LLVM), which lifts program variables from
the stack to registers. We evaluate our method on two archi-
tectures: ARM Cortex M0, a highly predictable architecture
targeting small embedded devices; and MIPS32, a widely-used
embedded architecture.

We implemented the constraint model both as part of the
specialized Gecode [22] constraint model and the Miniz-
inc [23] model that Unison provides. The latter allows for
solving the problem using multiple solvers. In total, we
tried four solvers, Chuffed v0.10.3 [24], OR-Tools [25], Elsie
Geas1, and the specialized model written in Gecode v6.2. We
ran the former three solvers activating the free-search option.
Among all these solvers, Gecode and Chuffed performed best.
None of them was able to solve all the problems but together
they could solve all the problems.

1Elsie Geas: https://bitbucket.org/gkgange/geas/src/master/

3) Benchmarks: To evaluate our approach, we use a set of
small benchmark programs, up to 100 lines of C code, which
were made available by Wang et al. [7]. Table I provides a de-
scription of these benchmarks, including the number of lines of
code (LoC), and the program variables, i.e. the input variables
(IN ) and the number of secret (IN sec), public (IN pub), and
random (IN rand) input variables. These benchmark programs
constitute different masked implementations from previous
work and are linearized.

Progr.

Description

P0
P1
P2
P3
P4
P5
P6
P7
P8
P9

Xor (Listing 1)
AES Shift Rows [6]
Messerges Boolean [6]
Goubin Boolean [6]
SecMultOpt wires 1 [4]
SecMult wires 1 [4]
SecMultLinear wires 1 [4]
CPRR13-lut wires 1 [5]
CPRR13-OptLUT wires 1 [5]
CPRR13-1 wires 1 [5]

LoC

5
11
12
12
25
25
32
81
84
104

Input Variables (IN)
rand
sec
pub
1
1
1
2
2
0
2
1
0
2
1
0
3
1
1
3
1
1
3
1
1
7
1
1
7
1
1
7
1
1

TABLE I: Benchmark Description

B. Optimality Overhead

SecConCG builds on a constraint-based compiler back-
end to generate a program that satisﬁes security constraints
for software masking. This means that our approach might
compromise some of the code quality of the non-mitigated
code to mitigate the software masking leaks. To evaluate
the overhead of our method compared to non-secure opti-
mization, we compare the execution time of the optimized
solution (optimal or suboptimal solution) that Unison [15]
generates compared with SecConCG’s optimized and secure
code. The overhead is computed as (cycles(SecConCG) −
cycles(Unison))/cycles(Unison).

Table II shows the execution time for each of the benchmark
programs and architectures. In particular, for each of the archi-
tectures, we compare the execution time in number of cycles
of the solution that Unison produces against SecConCG’s
solution. The ﬁnal column shows the overhead of SecConCG
compared to Unison.

The results show zero overhead for MIPS32, and a max-
imum 7% overhead in ARM Cortex M0. More speciﬁcally,
ARM Cortex M0 has a non-zero overhead for programs P7-P9.
The observed overhead in ARM Cortex M0 depends partially
on the mitigation itself that may require redundant or non-
optimal operations. However, the main reason for the overhead
that appears in larger benchmarks is that the constraint model
becomes larger compared to the original model due to the
introduction of additional constraints and problem variables.
This leads to an increase in the search space and hinders the
constraint model to locate better solutions.

To summarize, SecConCG does not introduce signiﬁcant
overhead over the non-secure optimized solution that Unison
generates. This means that in most cases, there is space for
generating secure code without affecting the quality of the
generated code.

C. Execution-time Improvement

To evaluate the execution-time speedup of our approach, we
compare SecConCG with the work by Wang et al. [7]. Wang
et al. perform vulnerability identiﬁcation on non-optimized
code from LLVM 3.6. This is a common approach by different
security mitigations, because compilation passes might violate
the security properties of a program. However, non-optimized
code leads to high performance overhead.

We select the approach by Wang et al. [7] as the base-
line for the evaluation for three main reasons, 1) their tool
is available freely, 2) they propose an architecture-agnostic
approach that applies to both Mips and ARM, and 3) they
mitigate transitional effect caused by register reuse, a subset
of our mitigation. Table III compares the execution time in
number of cycles (based on a LLVM-derived cost model) of
the mitigated code by Wang et al. [7] and SecConCG, for
each of the programs and architectures. Speedup is computed
as cycles(SecConCG)/cycles(Baseline).

For ARM Cortex M0, the improvement ranges from 8% for
P8 to 83% for P1. We notice that for the smaller benchmarks,
SecConCG achieves increased improvement over the baseline,
whereas for the largest benchmarks P7-P9, the improvement
is smaller. These results are consistent with the results in
Section V-C, where the larger benchmarks, P7-P9, are not
able to reach the same quality level as in the absence of the
security constraints. The main reason for this, is the increased
size of the program under analysis that consists of one large
function. As future work, we plan to investigate decomposition
techniques for better scalability.

For MIPS32, the improvement ranges from 75% to 10x
speedup. The improvement is larger for smaller benchmarks
due to the large overhead of load and store instructions
that are present in the absence of optimizations in the baseline.
In contrast to the non-optimized code, the code generated by
SecConCG does not require memory spilling. In particular,
the generic cost model for MIPS32 that we use (derived
from LLVM) has a one cycle overhead compared to linear
instructions. For larger programs, P7-P9, the speedup is still
signiﬁcant (>2x).

This experiment shows a clear difference between the
two architectures with regards to the improvement over the
baseline, with SecConCG achieving a larger improvement for
MIPS32 than for ARM Cortex M0. There are two reasons for
this difference. First, the load and store instructions in the
timing model of ARM Cortex M0 do not introduce addition
overhead (the actual latency of memory instructions may be
higher depending on the speciﬁc hardware implementation). In
contrast, The MIPS32 timing model adds one cycle overhead
for every load instruction.

The second reason for this difference is the characteristics
of each architecture. ARM Cortex M0 has twelve general-
purpose registers, with only ﬁve of them non-callee-saved (the
function does not have to preserve their previous results).
MIPS32 has 32 general-purpose registers, from which more
than 15 are non-callee-saved. This allows the constraint model

Program

P0
P1
P2
P3
P4
P5
P6
P7
P8
P9

Unison [15]
4
5
8
11
25
25
27
157
156
183

ARM Cortex M0
SecConCG
4
5
8
11
25
25
27
168
164
195

Overhead (%)
0
0
0
0
0
0
0
7
5
6

Unison [15]
3
4
7
9
76
76
74
152
152
282

MIPS32
SecConCG
3
4
7
9
76
76
74
152
152
283

Overhead (%)
0
0
0
0
0
0
0
0
0
≈ 0

TABLE II: Optimal solution with and without security constraints in cycles

Program

P0
P1
P2
P3
P4
P5
P6
P7
P8
P9

ARM Cortex M0

Baseline [7]
13
29
27
32
61
58
78
182
187
218

SecConCG
4
5
8
11
25
25
27
164
168
195

Speedup
1.7
1.8
1.7
1.7
1.6
1.6
1.6
1.1
1.1
1.1

Baseline [7]
22
40
48
55
139
133
189
371
379
593

MIPS32
SecConCG
3
4
7
9
76
76
74
152
152
283

Speedup
7.3
10.0
6.9
6.1
1.8
1.7
2.5
2.4
2.5
2.1

TABLE III: Execution-time comparison between the non-optimized Baseline and SecConCG

to select among multiple registers to assign to a temporary,
avoiding non-secure register reuse. In addition to that, ARM
Cortex M0 implements the Thumb instruction set, which
contains many instructions, where one of the operands shares
the same register as the result. This increases the complexity
of the constraint model further.

To summarize, for both MIPS32 and ARM Cortex M0,
SecConCG improves the non-optimized but secure base-
line [7]. We notice a large improvement for MIPS32 ranging
from 75% to 10x speedup and a smaller but still signiﬁcant
improvement for ARM Cortex M0 ranging from 10% to 83%.
This observable difference in the improvement metric between
MIPS32 and ARM Cortex M0 depends on architectural char-
acteristics like the number of general-purpose registers, and
other register allocation constraints.

D. Threat to Validity

Our model considers the HD leakage model and generates
code that mitigates these leakages. However, it is not certain
that the removed vulnerabilities are observable by an attacker
on a real device and that the mitigated program does not lead
to further leakages in the actual hardware. For example, we
do not handle transitional effects through value interaction in
the pipeline stage registers. We leave further improvement of
the hardware model as a future work.

SecConCG is not a veriﬁed compiler approach like
CompCert [26]. Unison,
the constraint-based backend that
SecConCG depends on is based on a formal model that imple-
ments standard optimizations but the external solvers and the
tool implementation are not veriﬁed. Different approaches [27]
attempt to verify solver global constraints.

VI. RELATED WORK

This section discusses related work in binary-code hard-
ening against side-channel attacks, combinatorial compiler
backends, and optimized security compilation approaches.

Code Hardening Against Side-Channel Attacks: Wang
et al. [7] identify leaks in a masked implementation using
a type system and perform local register allocation and in-
struction selection transformations to mitigate these leaks in
LLVM. They identify transitional effects due to register reuse.
Their approach is efﬁcient because it allows the analysis
of large linearized functions and the mitigation introduces
small overhead. However, they depend on a non-optimized
compilation in order to preserve the security properties of the
high-level program, which leads to code generation of non-
optimized but secure code.

Rosita [11] is a recent approach to mitigate transitional
effects that may lead to power side-channel attacks using
an emulation-based technique. Rosita performs an iterative
process to identify power leakages in software implemen-
tations for ARM Cortex M0. Then, it identiﬁes transitional
effects due to register reuse, memory-bus access, and pipeline
stage-register reuse. Rosita uses a more accurate model but
introduces an overhead of 24% to 64%.

Other approaches perform mitigations at design time [28,
29, 30]. The availability of open hardware architectures and,
more speciﬁcally, RISC-V, has enabled approaches, such as
Coco, which apply software-hardware co-design techniques to
mitigate power side-channel attacks [29].

Veriﬁed software against side channels is an active research
topic. Zinzindohou´e et al. [31] present HACL*, a crypto-
graphic library in C that is veriﬁed for memory safety, mitiga-
tions against timing side-channels, and functional correctness

with regards to a high-level speciﬁcation. However, the output
code is in C and the compilation procedure cannot guarantee
the preservation of non-functional properties.

In summary, there are compiler-based and binary rewriting
approaches to mitigate power-side channel attacks and timing
attacks but none of these approaches is able to provide
optimization properties for the result.

Combinatorial Compiler Backend: Compiler backend op-
timizations, like instruction selection, instruction scheduling,
and register allocation are known to be hard combinatorial
problems. Hence, solving such problems completely does
not scale for large sizes. Therefore, popular compilers, like
GCC [32] and LLVM [16], use heuristics that throughout the
years have proved to improve program performance. However,
these heuristics do not guarantee ﬁnding the optimal solution
or the best solution to these backend optimizations.

For critical code and code aimed for compiler-demanding
architectures, combinatorial methods may be able to ﬁnd
an optimized version of the code that may lead to reduced
power consumption and/or high performance beneﬁts. Dif-
ferent works [15, 19, 20] aim to optimize critical code at
different levels, like loops [19], locally [20] or at function
level [15]. The optimization goals range from execution time,
code size, or estimated energy consumption [19, 15, 20]. The
main drawback of these approaches is scalability. However, a
recent work, Unison [15], allows the optimization of functions
with almost 1000 instructions.

To summarize, many combinatorial compiler backend tech-
niques allow low-level code optimization but, to our knowl-
edge, none of them considers the preservation of security
properties.

Optimized Secure Compilation: There is little work on
secure optimized compilation. A recent approach [13, 14]
deals with the problem that modern compilers do not guarantee
preservation of security properties and optimization passes
may invalidate security mitigations at
the software level.
Security developers have to either deactivate all optimizations
(-O0 in GCC and LLVM) or use special techniques, like the
use of volatile in C to forbid the compiler to optimize
out a speciﬁc variable. However, both approaches increase the
execution-time overhead of the security mitigations.

Vu et al. [13] build on LLVM and introduce the concept
of opaque observations that disallows the compiler to remove
security mitigations or rearrange operands in instructions, such
as masking instructions. In their later work [14], they improve
the performance of their optimizing compiler by reducing the
requirement for serialization. To achieve this, they require
source-code annotation that may be challenging for non-trivial
programs [14].

that

Our approach, SecConCG considers a more ﬁne-grained
leakage model
involving information leakage through
transitional effects. SecConCG does not restrict the compiler
backend optimizations and does not require serialization be-
cause the constraint-based model is able to identify which
instructions can be reordered to fulﬁll the security constraints.
In addition to that, our approach does not require extensive

source-level annotation but only the deﬁnition of security
policy (secret, public, or random) for each input variable. How-
ever, Vu et al. are able to perform high-level optimizations,
which is not in the scope of our approach.

To summarize, the work by Vu et al. deals with the same
problem as our approach but at a different level of abstraction
the
considering a weaker leakage model. We believe that
combination of these approaches could lead to more efﬁcient
secure code.

VII. DISCUSSION

This paper proposes an architecture-agnostic method to
generate high quality code against register-reuse and memory-
bus transitional effects. We aim speciﬁcally at small-size
embedded devices that have a predictable cost model and im-
plement single-issued, non-speculative architectures. However,
the current model does not protect against pipeline-register
transitional effects or hardware implementation speciﬁc leak-
ages. This is part of future work. In particular, we plan to
extend our ARM Cortex M0 model, with additional constraints
to enable a comparison with Rosita [11].

This paper proves that our model guarantees the absence
of leakage based on the leakage model (Equations 1-6) and
generates code that satisﬁes the leakage equivalence condition
(Deﬁnition 1). Currently, the veriﬁcation of our results with
different approaches is difﬁcult because some tools are not
available [6], while others [7] depend on the LLVM compiler
internals.

VIII. CONCLUSION AND FUTURE WORK

This paper proposes a constraint model to be embedded in
a constraint-based compiler backend that allows the automatic
generation of optimized code that is secure against power
side-channel attacks. We prove that the generated code is
secure according to a non-trivial leakage model, and show that
our approach achieves high code improvement against non-
optimized approaches ranging from 10% to a speedup of 10x
for two embedded architectures, MIPS32 and ARM Cortex
M0. At the same time, our approach introduces a maximum
overhead of 7% from the optimal solution.

There are several future directions for our work. First, by
improving the accuracy of the hardware model of SecConCG
to model precisely a speciﬁc device, we will be able to improve
the leakage model and compare our approach to approaches
like Rosita [11]. A second direction of future work is to
improve the scalability of SecConCG through decomposition.
The challenge here is to ﬁnd appropriate program points
to split
linearized code to different blocks. We also plan
to extend our approach to other mitigations such as timing
side channels of constant resource programs [9]. Finally, we
believe that combining our approach with optimizing high-
level approaches [13, 14] can also be beneﬁcial.

ACKNOWLEDGMENT

We would like to thank Jingbo Wang for providing support
for the FSE19 tool and Amir Mahmood Ahmadian for the

fruitful discussions and his signiﬁcant feedback on the paper.
Finally, we would like to thank Oscar Eriksson for proof
reading the paper.

REFERENCES

[1] P. C. Kocher, “Timing Attacks on Implementations of
Difﬁe-Hellman, RSA, DSS, and Other Systems,” in
Advances in Cryptology — CRYPTO ’96, ser. Lecture
Notes in Computer Science, N. Koblitz, Ed.
Berlin,
Heidelberg: Springer, 1996, pp. 104–113.

[2] P. Kocher, J. Jaffe, and B. Jun, “Differential Power
Analysis,” in Advances in Cryptology — CRYPTO’ 99,
ser. Lecture Notes in Computer Science, M. Wiener, Ed.
Berlin, Heidelberg: Springer, 1999, pp. 388–397.

[3] M. Joye, P. Paillier, and B. Schoenmakers, “On Second-
Order Differential Power Analysis,” in Cryptographic
Hardware and Embedded Systems – CHES 2005, ser.
Lecture Notes in Computer Science, J. R. Rao and
B. Sunar, Eds. Berlin, Heidelberg: Springer, 2005, pp.
293–308.

[4] M. Rivain and E. Prouff, “Provably Secure Higher-
Order Masking of AES,” in Cryptographic Hardware and
Embedded Systems, CHES 2010, ser. Lecture Notes in
Computer Science, S. Mangard and F.-X. Standaert, Eds.
Berlin, Heidelberg: Springer, 2010, pp. 413–427.

[5] J.-S. Coron, E. Prouff, M. Rivain, and T. Roche, “Higher-
Order Side Channel Security and Mask Refreshing,” in
Fast Software Encryption, ser. Lecture Notes in Com-
puter Science, S. Moriai, Ed.
Berlin, Heidelberg:
Springer, 2014, pp. 410–424.

[6] A. G. Bayrak, F. Regazzoni, D. Novo, and P. Ienne,
“Sleuth: Automated Veriﬁcation of Software Power Anal-
ysis Countermeasures,” in Cryptographic Hardware and
Embedded Systems - CHES 2013, ser. Lecture Notes
in Computer Science, G. Bertoni and J.-S. Coron, Eds.
Berlin, Heidelberg: Springer, 2013, pp. 293–310.

[7] J. Wang, C. Sung, and C. Wang, “Mitigating power
side channels during compilation,” in Proceedings
of
the 2019 27th ACM Joint Meeting on European
Software Engineering Conference and Symposium on the
Foundations of Software Engineering, ser. ESEC/FSE
2019. New York, NY, USA: Association for Computing
Machinery, Aug. 2019, pp. 590–601. [Online]. Available:
https://doi.org/10.1145/3338906.3338913

[8] H. Eldib, C. Wang, and P. Schaumont, “Formal
Veriﬁcation of Software Countermeasures against Side-
Channel Attacks,” ACM Transactions on Software
Engineering and Methodology, vol. 24, no. 2, pp.
[Online]. Available: https:
11:1–11:24, Dec. 2014.
//doi.org/10.1145/2685616

[9] G. Barthe, S. Blazy, R. Hutin, and D. Pichardie, “Secure
Compilation of Constant-Resource Programs,” in CSF
2021 - 34th IEEE Computer Security Foundations
Symposium. Dubrovnik, Croatia: IEEE, Jun. 2021, pp.
1–12. [Online]. Available: https://hal.archives-ouvertes.
fr/hal-03221440

[10] P. Borrello, D. C. D’Elia, L. Querzoni, and C. Giuffrida,
“Constantine: Automatic Side-Channel Resistance Using
and Data Flow Linearization,”
Efﬁcient Control
Proceedings of
the 2021 ACM SIGSAC Conference
on Computer and Communications Security, pp. 715–
733, Nov. 2021, arXiv: 2104.10749. [Online]. Available:
http://arxiv.org/abs/2104.10749

[11] M. A. Shelton, N. Samwel, L. Batina, F. Regazzoni,
M. Wagner, and Y. Yarom, “Rosita: Towards Automatic
Elimination of Power-Analysis Leakage in Ciphers,”
Proceedings 2021 Network and Distributed System
Security Symposium, 2021, appears in NDSS 2022.
[Online]. Available: http://arxiv.org/abs/1912.05183
[12] N. Veshchikov and S. Guilley, “Use of Simulators for
Side-Channel Analysis,” in 2017 IEEE European Sym-
posium on Security and Privacy Workshops (EuroS PW),
Apr. 2017, pp. 104–112.

[13] S. T. Vu, K. Heydemann, A. de Grandmaison, and
A. Cohen, “Secure delivery of program properties
through optimizing compilation,” in Proceedings of the
29th International Conference on Compiler Construction,
ser. CC 2020. New York, NY, USA: Association for
Computing Machinery, Feb. 2020, pp. 14–26. [Online].
Available: http://doi.org/10.1145/3377555.3377897
[14] S. T. Vu, A. Cohen, A. d. Grandmaison, C. Guillon,
and K. Heydemann, “Reconciling optimization with
secure compilation,” in Proceedings of
the ACM
on Programming Languages, vol. 5, Oct. 2021,
p. 1,
[Online]. Available: https:
//hal.sorbonne-universite.fr/hal-03399742

issue: OOPSLA.

[15] R. Casta˜neda Lozano, M. Carlsson, G. H. Blindell,
and C. Schulte, “Combinatorial Register Allocation and
Instruction Scheduling,” ACM Trans. Program. Lang.
Syst., vol. 41, no. 3, pp. 17:1–17:53, Jul. 2019. [Online].
Available: http://doi.acm.org/10.1145/3332373

[16] C. Lattner and V. Adve, “LLVM: a compilation frame-
work for lifelong program analysis amp; transformation,”
in International Symposium on Code Generation and
Optimization, 2004. CGO 2004., Mar. 2004, pp. 75–86.
[17] T. S. Messerges, E. A. Dabbish, and R. H. Sloan,
“Investigations of power analysis attacks on smartcards.”
Smartcard, vol. 99, pp. 151–161, 1999.

[18] E. Brier, C. Clavier, and F. Olivier, “Correlation Power
Analysis with a Leakage Model,” in Cryptographic Hard-
ware and Embedded Systems - CHES 2004, ser. Lecture
Notes in Computer Science, M. Joye and J.-J. Quisquater,
Eds. Berlin, Heidelberg: Springer, 2004, pp. 16–29.
and C. Kessler,

“Integrated Code
[19] M. Eriksson
on
Generation
Embedded Computing Systems, vol. 11S, no. 1,
pp.
[Online]. Available:
https://doi.org/10.1145/2180887.2180896

for Loops,” ACM Transactions

19:1–19:24,

2012.

Jun.

[20] C. Gebotys, “An efﬁcient model for DSP code gen-
eration: performance, code size, estimated energy,” in
Proceedings. Tenth International Symposium on System
Synthesis (Cat. No.97TB100114), Sep. 1997, pp. 41–47,

iSSN: 1080-1820.

[21] F. Rossi, P. Van Beek, and T. Walsh, Handbook of

constraint programming. Elsevier, 2006.

[22] Gecode Team, “Gecode: Generic constraint development
environment,” 2022. [Online]. Available: https://www.
gecode.org

[23] N. Nethercote, P. J. Stuckey, R. Becket, S. Brand, G. J.
Duck, and G. Tack, “MiniZinc: Towards a Standard
CP Modelling Language,” in Principles and Practice
of Constraint Programming – CP 2007, ser. Lecture
Notes in Computer Science, C. Bessi`ere, Ed. Berlin,
Heidelberg: Springer, 2007, pp. 529–543.

[24] G. G. Chu, “Improving combinatorial optimization,”
Ph.D. dissertation, The University of Melbourne, Aus-
tralia, 2011.

[25] Google Developers, “Google OR-Tools,” 2022. [Online].

Available: https://developers.google.com/optimization/

“A Formally Veriﬁed Compiler Back-
[26] X. Leroy,
Journal of Automated Reasoning, vol. 43,
end,”
no. 4, p. 363, Nov. 2009. [Online]. Available: https:
//doi.org/10.1007/s10817-009-9155-4

[27] S. Gocht, C. McCreesh, and J. Nordstr¨om, “An auditable
constraint programming solver,” 2022, to appear.

[28] D. Sijacic,

J. Balasch, B. Yang, S. Ghosh, and
I. Verbauwhede, “Towards Efﬁcient and Automated
Side Channel Evaluations at Design Time,” in Kalpa
Publications in Computing, vol. 7.
IEEE, Jan. 2018,
pp. 16–31. [Online]. Available: https://lirias.kuleuven.
be/2789453

[29] B. Gigerl, V. Hadzic, R. Primas, S. Mangard, and
R. Bloem, “Coco: {Co-Design} and {Co-Veriﬁcation}
of Masked Software Implementations on {CPUs},” 2021,
pp. 1469–1468. [Online]. Available: https://www.usenix.
org/conference/usenixsecurity21/presentation/gigerl
[30] I. Buhan, L. Batina, Y. Yarom, and P. Schaumont, “SoK:
Design Tools for Side-Channel-Aware Implementations,”
arXiv:2104.08593 [cs], Jun. 2021, arXiv: 2104.08593.
[Online]. Available: http://arxiv.org/abs/2104.08593

[31] J.-K. Zinzindohou´e, K. Bhargavan,

J. Protzenko,
and B. Beurdouche, “HACL*: A Veriﬁed Modern
the
Cryptographic Library,”
2017 ACM SIGSAC Conference on Computer and
Communications Security, ser. CCS ’17. New York,
NY, USA: Association for Computing Machinery,
[Online]. Available:
Oct.
https://doi.org/10.1145/3133956.3134043

in Proceedings

1789–1806.

2017,

pp.

of

[32] R. M. Stallman, Using the gnu compiler collection: a
gnu manual for gcc version 4.3. 3. CreateSpace, 2009.

APPENDIX A
TYPE INFERENCE RULES

The security analysis of SecConCG requires the type an-
notation of program variables and variables generated by the
transformations of the underline constraint-based compiler
backend. We have decided to implement the type inference

algorithm by Wang et al. [7] due to its scalability com-
pared with other approaches like symbolic execution [6]. This
section describes the type inference algorithm starting with
the deﬁnition of help functions. Although SecConCG uses
multiple equivalent temporary (copy) values for each operation
operand (see Figure 4), all deﬁnition use one temporary value
t. In reality, we unify these equivalent temporaries because
they are semantically equal because they are just copies of
the original program variables. In the following deﬁnition, the
parts in bold denote the extensions to the origin type-inference
algorithm [7].

The help function xor, returns true if an expression only
consists of exclusive OR operations. This function improves
the precision of the type inference algorithm, when multiple
exclusive OR operations remove the dependence on a secret
value. The recursive deﬁnition of xor is as follows:

xor(t0) =

true
xor(t1)
xor(t1) ∧ xor(t2)
false






if t0 ∈ IN
if t0 = uop(t1)
if t0 = ⊕(t1, t2)
if t0 = bop(t1, t2),

bop (cid:54)= ⊕

Help function supp [7] returns the support of each expres-
sion. That is, all the variables that are syntactically present
in the expression. We add two cases for supp, where some
of syntactically present values are removed in the case of
a simpliﬁcation. This improves the precision of the analysis,
because the type inference algorithm uses supp to decide on
the type of a temporary variable. The recursive deﬁnition of
supp is:

supp(t0) =





{t0}
supp(t1)
(supp(t1) ∪ supp(t2))\
(supp(t1) ∩ supp(t2))
supp(t2)
supp(t1) ∪ supp(t2)

if t0 ∈ IN
if t0 = uop(t1)
if t0 = ⊕(t1, t2)∧

xor(t0)
if t0 = ⊕(t1, ⊕(t1, t2))
if t0 = bop(t1, t2)

Help function unq [7] returns the random input variables
that appear only once in the expression. This means that if we
have a binary operator bop, with two operands t1 and t2 then,
if both operands are randomized with the same random value,
then this random value cannot randomize the expression t0.
The recursive deﬁnition of unq is:

unq(t0) =






{t0}
{}
unq(t1)
(unq(t1) ∪ unq(t2))\
(supp(t1) ∩ supp(t2)) if t0 = bop(t1, t2)

if t0 ∈ INrand
if t0 ∈ IN \INrand
if t0 = uop(t1)

dom(t) (cid:54)= ∅
Γ (cid:96) t : Rand

RAND

supp(t) ∩ INsec = ∅ dom(t) = ∅
Γ (cid:96) t : P ub

PUB1

Γ (cid:96) t0 : P ub Γ (cid:96) t1 : P ub
supp(t0) ∩ supp(t1) = ∅
Γ (cid:96) t = t0 (cid:126) t1 : P ub

PUB2

Γ (cid:96) t0 : Rand Γ (cid:96) t1 : Rand
(dom(t0)\supp(t1) (cid:54)= ∅ ∨
dom(t1)\supp(t0) (cid:54)= ∅)

Γ (cid:96) t0 ◦ t1 : P ub

PUB3

Γ (cid:96) t0 : Rand Γ (cid:96) t1 : Rand
(cid:54)= ∅ ∨
(dom(t0)\dom(t1)
(cid:54)= ∅)

dom(t1)\dom(t0)

Γ (cid:96) t0 (cid:12) t1 : P ub

PUB4

i ∈ {0, 1} j = 1 − i Γ (cid:96) ti : Rand
dom(ti)\supp(tj ) = ∅

dom(ti) = dom(tj )

supp(ti) = supp(tj )

Γ (cid:96) t0 (cid:126) t1 : P ub

PUB5

i ∈ {0, 1}

j = 1 − i
Γ (cid:96) ti : Rand Γ (cid:96) tj : P ub
(cid:54)= ∅

dom(ti)\supp(tj )

Γ (cid:96) t0 (cid:12) t1 : P ub

PUB6

i ∈ {0, 1}

j = 1 − i
Γ (cid:96) ti : P ub Γ (cid:96) tj : Rand
supp(ti) ∩ supp(tj ) = ∅

Γ (cid:96) t0 ◦ t1 : P ub

PUB7

(t0 = t1 (cid:12) t2 ∨ t1 = t0 (cid:12) t2)
Γ (cid:96) t2 : T2
Γ (cid:96) t0,1 : T1
(cid:54)= Sec
T1

(cid:54)= Sec ∧ T2

Γ (cid:96) t0 ⊕ t1 : P ub

PUB8

((t0 = t1 ⊕ t2) ∨ (t1 = t0 ⊕ t2))
Γ (cid:96) t2 : T
Γ (cid:96) t0 ⊕ t1 : T

NEST1

((t0 = t1 ∨ t2) ∨ (t1 = t0 ∨ t2))
Γ (cid:96) ¬t0,1 ∧ t2 : T
Γ (cid:96) t0 ⊕ t1 : T

NEST2

(t0 = t1 ∧ t2 ∧ t1 = t0 ∧ t2)
Γ (cid:96) t0,1 ∧ ¬t2 : T
Γ (cid:96) t0 ⊕ t1 : T

NEST3

Γ (cid:96) t0 (cid:12) (t1 ⊕ t2) : T
Γ (cid:96) (t0 (cid:12) t1) ⊕ (t0 (cid:12) t2) : T

DISTR0

Γ (cid:96) t0 (cid:12) (t1 ⊕ t2) : T
Γ (cid:96) (t0 (cid:12) t1) ⊕ (t2 (cid:12) t0) : T

DISTR1

Γ (cid:96) t1 (cid:12) (t0 ⊕ t2) : T
Γ (cid:96) (t0 (cid:12) t1) ⊕ (t1 (cid:12) t2) : T

DISTR2

Γ (cid:96) t1 (cid:12) (t0 ⊕ t2) : T
Γ (cid:96) (t0 (cid:12) t1) ⊕ (t2 (cid:12) t1) : T

DISTR3

Γ (cid:96) t0 : P ub Γ (cid:96) t1 : P ub
supp(t0) ∩ supp(t1) ∩ INrand = ∅
Γ (cid:96) t = t0 ⊕ t1 : P ub

PUB9

Fig. 10: Type inference for power side channels in SecConCG [7]; ⊕ denotes the exclusive OR operation, (cid:12) denotes the
multiplication in a ﬁnite ﬁeld, ◦ denotes any other operations apart from (cid:12) and ⊕, and ﬁnally, (cid:126) denotes any operation.

The last help function is dom [7]. For each temporary
variable dom returns the random input variables that are xor:ed
with that value. The recursive deﬁnition of dom is:

dom(t0) =


{t0}
{}
dom(t1)
(dom(t1) ∪ dom(t2))




if t0 ∈ INrand
if t0 ∈ IN \INrand
if t0 = uop(t1)

∩ unq(t0)

{}

if t0 = ⊕(t1, t2)
if t0 = bop(t1, t2) ∧ bop (cid:54)= ⊕

Finally, Figure 10 presents the type system. The ﬁrst nine
rules are described by Wang et al. [7] and the rest of the
rules are discussed in the same paper. Here, for space reasons,
we have abbreviated Random to Rand, Public to Pub, and
Secret to Sec. In particular, the ﬁrst two rules are the basic
rules, i.e. 1) if dom for an expression contains a value, then,
this temporary has type Rand, and 2) if the type is not Rand
and the expression does not depend on secret values, then the
expression has type Pub. The rest of the rules improve the
precision of the analysis.

APPENDIX B
SECURITY PROOF

We assume that the type-inference algorithm [7] is conser-
vative and sound. That is, if type(t) = Rand this implies that
t follows a uniform random distribution. If type(t) = P ub this
implies that t follows a secret-independent distribution (might
also be uniform random distribution). Finally, if type(t) = Sec
this implies that t may be secret dependent.

SecConCG generates a solution to the constraint model,
which we represent as an ordered sequence of instructions,
P = {i0, ..., in}. This means that instruction ij is executed
before instruction ik for j < k.

(Equation

To verify whether the generated program leaks secret in-
formation according to our leakage model (Equations 1-6),
we give a proof of Theorem 3 using structural induction on
a mitigated program, P . We start from the last instruction
because preceding instructions are able to hide the secret
values.
Case 1 Assume P = t ← e, e (cid:54)= mem(ea, e(cid:48)).
Case 1.a Assume type(e) ∈ {Rand, P ub}.
have
From the
leakage model
∈
L(P (IN ))
{Rand, P ub},
random
i.e. a constant value.
(uniformly distributed) or public,
This means that the distribution is not dependent on the
secret value. Thus, Deﬁnition 1 is satisﬁed.
Case 1.b Assume type(e) = Sec.
From the deﬁnition of Spairs (Equation 10), type(e) =
type(t) = Sec =⇒ ∃(ti, ts) ∈ Spairs. ti = t ∧ ts =
[t(cid:48)|t(cid:48) ∈ T emps ∧ type(t(cid:48)) = Rand ∧ type(t(cid:48) ⊕ t) =
Rand]. In this case we have a pair (t, ∅), and thus, con-
straint in Section IV-B2 is not satisﬁed, because (cid:64)ti ∈ ∅.
So, P is not a valid program.
Case 2 Assume P = mem(ea, e).

=
{HW (e)}. Because
the distribution of e is either

4), we

type(e)

Case 2.a Assume type(e) ∈ {Rand, P ub} From the leak-
age model (Equation 5), we have L(P (IN )) = {HW (e)}.
Because type(e) ∈ {Rand, P ub}, the distribution of e is
either random (uniformly distributed) or public, i.e. a con-
stant value. This means that the distribution is not dependent

=⇒

on the secret value. Thus, Deﬁnition 1 is satisﬁed.
Case 2.b Assume type(e) = Sec.
From the deﬁnition of Mspairs (Equation 12), type(e) =
Sec
tm(oi) =
e ∧ os = [o(cid:48)|o(cid:48) ∈ MemOperations ∧ type(tm(o(cid:48))) =
Rand ∧ type(tm(o(cid:48)) ⊕ tm(o)) = Rand]. In this case we
have a pair (o, ∅), and thus, the constraint in Section IV-B4
is not satisﬁed, because (cid:64)oi ∈ ∅. So, P is not a valid
program.

∃(oi, os) ∈ M spairs.

Case 3 Assume P = t ← mem(ea, e).

6), we

(Equation

leakage model

Case 3.a Assume type(mem(ea, e) ∈ {Rand, P ub} ∧ e ∈
{Rand, P ub}.
From the
have
L(P (IN )) = {HW (e), HW (mem(ea, e)}. Similar
with Case 1.a and Case 2.a, Deﬁnition 1 is satisﬁed.
Case 3.b Assume type(mem(ea, e) = Sec.
Analogous to Case 1.b
Case 3.c Assume e ∈ Sec.
Analogous to Case 2.b.
Case 4 Assume P = P (cid:48); t ← e, e (cid:54)= mem(ea, e(cid:48)).
Case 4.a Assume type(e) = Sec.
From the deﬁnition of Spairs (Equation 10), type(e) =
type(t) = Sec =⇒ ∃(ti, ts) ∈ Spairs. ti = t ∧ ts =
[t(cid:48)|t(cid:48) ∈ T emps ∧ type(t(cid:48)) = Rand ∧ type(t(cid:48) ⊕ t) =
Rand].
From the Spairs constraint in Section IV-B2, we have that
∃tr ∈ ts. l(t) =⇒ l(tr) ∧ subseq(tr, t). From
Theorem 1, we have subseq(tr, t) =⇒ P = P (cid:48)(cid:48); tr ←
er; P (cid:48)(cid:48)(cid:48); t ← e ∧ r(t) = r(tr) ∧ ∀i ← P (cid:48)(cid:48)(cid:48). i = t(cid:48) ←
e(cid:48) ∧ r(t(cid:48)) (cid:54)= r(t). According to the leakage model (Equa-
tions 1), L(P ) = L(P (cid:48)(cid:48); tr ← er; P (cid:48)(cid:48)(cid:48)) ∪ {HW (tr ⊕ t)}.
Because tr ∈ ts, we have that type(tr ⊕ t) = Rand.
This means that tr ⊕ t has a uniform random distribution,
and, thus, HW (tr ⊕ t) does not leak. From the induc-
tion hypothesis, (cid:80)
E[l] = (cid:80)
E[l]
and (cid:80)
l∈L(P (cid:48)(IN (cid:48))) var[l]. Thus,
(cid:80)
E[l] + HW (tr ⊕ t) =
(cid:80)
E[l].
l∈L(P (IN (cid:48)))

l∈L(P (cid:48)(IN )) var[l] = (cid:80)
E[l] = (cid:80)
E[l] + HW (tr ⊕ t) = (cid:80)

l∈L(P (cid:48)(IN (cid:48)))

l∈L(P (IN (cid:48)))

l∈L(P (cid:48)(IN ))

l∈L(P (IN ))

l∈L(P (IN ))

Same is true for var. Thus, Deﬁnition 1 is satisﬁed.
Case 4.b Assume type(e) ∈ {Rand, P ub}.
Case 4.b.i Assume ∃i ∈ P (cid:48). i = t(cid:48) ← e(cid:48) ∧ r(t) = r(t(cid:48)).
Of the temporaries assigned to the same register, we
select the temporary that is scheduled last before t, i.e.
P = P (cid:48)(cid:48); tr ← er; P (cid:48)(cid:48)(cid:48); t ← e ∧ ∀i ← P (cid:48)(cid:48)(cid:48). i = t(cid:48) ←
e(cid:48) ∧ r(t(cid:48)) (cid:54)= r(t)
Case 4.b.i.α Assume type(t ⊕ t(cid:48)) ∈ {R, P }.
In this case, the leakage model is L(P ) = L(P (cid:48)(cid:48); tr ←
er; P (cid:48)(cid:48)(cid:48)) ∪ {HW (t ⊕ t(cid:48))}. Due to the initial assump-
tion type(t ⊕ t(cid:48)) ∈ {R, P },
the distribution of the
leakage is either randomly distributed or public, i.e. it
does not reveal secret information. From the induction
hypothesis, (cid:80)
E[l]
and (cid:80)
l∈L(P (cid:48)(IN (cid:48))) var[l]. Thus,
(cid:80)
E[l] + HW (t ⊕ t(cid:48)) =

l∈L(P (cid:48)(IN )) var[l] = (cid:80)
E[l] = (cid:80)

E[l] = (cid:80)

l∈L(P (cid:48)(IN (cid:48)))

l∈L(P (cid:48)(IN ))

l∈L(P (IN ))

l∈L(P (IN ))

(cid:80)

E[l].

l∈L(P (IN (cid:48)))

l∈L(P (IN (cid:48)))

the ﬁrst

E[l] + HW (t ⊕ t(cid:48)) = (cid:80)
Same is true for var. Thus, Deﬁnition 1 is satisﬁed.
Case 4.b.i.β Assume type(t ⊕ t(cid:48)) = S.
Case 4.b.i.β.1 Assume type(t(cid:48)) ∈ {R, P }.
From the deﬁnition of Rpairs (Equation 9), (t, t(cid:48)) ∈
Rpairs. From the Rpairs constraint in Section IV-B,
that ¬subseq(t, t(cid:48)) ∧ ¬subseq(t(cid:48), t).
we have
From the deﬁnition of subseq,
term,
¬subseq(t, t(cid:48)),
t(cid:48)
is true because
in the program sequence. The second constraint
¬subseq(t(cid:48), t) contradicts with the hypothesis in Case
4.a.i (Theorem 1).
Case 4.b.i.β.2 Assume type(t(cid:48)) = S.
From the deﬁnition of Spairs (Equation 10) we have
that ∃(ti, ts) ∈ Spairs. ti = t(cid:48) with ∀ts ∈ ts. type(t(cid:48)⊕
ts) = Rand. From the Spairs constraint
in Sec-
tion IV-B, ∃tr ∈ ts. l(t(cid:48)) =⇒ l(tr) ∧ subseq(t(cid:48), tr).
However, because there is no other assignment
to
register r(t) in P (cid:48)(cid:48)(cid:48) (Case 4.b.i), we have that tr = t
and because tr ∈ ts, type(tr ⊕ t(cid:48)) = Rand. But
type(t ⊕ t(cid:48)) = Sec (Case 2.b.i), which is a contra-
diction.

follows

t

Case 4.b.ii Assume (cid:64)i ∈ P (cid:48). i = t(cid:48) ← e(cid:48) ∧ r(t) = r(t(cid:48)).
the leakage is L(P ) = L(P (cid:48)) ∪ {HW (e)}.
Then,
HW (e) follows either a random distribution or
is
independent. From the induction hypothesis,
secret
(cid:80)
(cid:80)
and
(cid:80)
l∈L(P (cid:48)(IN (cid:48))) var[l]. Thus,
(cid:80)
E[l] + HW (e) =
(cid:80)
E[l]. Same

E[l] = (cid:80)
E[l] + HW (e) = (cid:80)
l∈L(P (IN (cid:48)))
is true for var. Thus, Deﬁnition 1 is satisﬁed.

E[l]
l∈L(P (cid:48)(IN )) var[l] = (cid:80)

l∈L(P (cid:48)(IN (cid:48)))

l∈L(P (cid:48)(IN ))

l∈L(P (IN (cid:48)))

l∈L(P (IN ))

l∈L(P (IN ))

E[l]

=

Case 5 Assume P = P (cid:48); mem(e, ei).
Case 5.a Assume type(e) = Sec.
Analogous to Case 4.a.
Case 5.b Assume type(e) ∈ {Rand, P ub}.
Analogous to Case 4.b.
Case 6 Assume P = P (cid:48); t ← mem(e, ei).
Analogous to Case 4 and Case 5.

APPENDIX C
IMPLIED CONSTRAINTS

To improve the solver ability to ﬁnd solutions, we add
additional constraints that are logically implied by the imposed
constraints. Implied constraints often improve the solving
procedure by reducing the search space through propagation.
The following implied constraint is speciﬁcally relevant to
ARM Cortex M0 but also to architectures that use accumulator
for many operations, such as x86 architectures. In particular
this constraint implies that if a pair of temporaries in Rpairs
belong to the same operation o1 then the two operands (des-
tination and source) have to be assigned to different registers
or the operation operands should change. If the source and
destination operands have to be assigned to the same register
(accumulator) then, the operands have to be inverted. The
constraint is as follows:

forall (t1,t2) in Rpairs:

o = def_oper(t1)
if (o ∈ user_opers(t2)):

¬same_reg(t1, t2)

is

Another

implied constraint

related to preassigned
operands. Preassigned operands, are preassigned to a speciﬁc
register because of special hardware architecture properties or
calling conventions. For this, we add an additional implied
constraint that guides the solver to try to schedule a different
temporary if the two preassigned temporaries are not allowed
to be subsequent, i.e. they belong to Rpairs.

forall (t1,t2) in Rpairs:

if (t2 ∈ preassign ∧ t1 ∈ preassign):

samereg(t1, t2) =⇒ (

(exists t ∈ Temps: subseq(t1,t) ∨
subseq(t,t1)) ∧
(exists t ∈ Temps: subseq(t2,t) ∨
subseq(t,t2)))

