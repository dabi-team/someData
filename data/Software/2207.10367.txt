2
2
0
2

l
u
J

1
2

]
E
N
.
s
c
[

1
v
7
6
3
0
1
.
7
0
2
2
:
v
i
X
r
a

EC-KitY: Evolutionary Computation Tool Kit in
Python with Seamless Machine Learning Integration

Moshe Sipper, Tomer Halperin, Itai Tzruia, Achiya Elyasaf 1

Abstract

EC-KitY is a comprehensive Python library for doing evolutionary computa-
tion (EC), licenesed under GNU General Public License v3.0, and compatible
with scikit-learn. Designed with modern software engineering and ma-
chine learning integration in mind, EC-KitY can support all popular EC
paradigms, including genetic algorithms, genetic programming, coevolution,
evolutionary multi-objective optimization, and more. This paper provides an
overview of the package, including the ease of setting up an EC experiment,
the architecture, the main features, and a comparison with other libraries.

Keywords: Evolutionary Algorithms, Evolutionary Computation, Genetic
Programming, Machine Learning, scikit-learn

1. Introduction

In Evolutionary Computation (EC)—or Evolutionary Algorithms (EAs)—
core concepts from evolutionary biology—inheritance, random variation, and
selection—are harnessed in algorithms that are applied to complex computa-
tional problems. As discussed by [1], EAs present several important beneﬁts
less reliance on
over popular machine learning (ML) methods, including:
the existence of a known or discoverable gradient within the search space;
ability to handle design problems, where the objective is to design new enti-
ties from scratch; fewer required a priori assumptions about the problem at
hand; seamless integration of human expert knowledge; ability to solve prob-
lems where human expertise is very limited; support of interpretable solution
representations; support of multiple objectives.

1Ben-Gurion University, Beer-Sheva 8410501, Israel

Preprint submitted to arXiv

July 22, 2022

 
 
 
 
 
 
Importantly, these strengths often dovetail with weak points of ML algo-
rithms, which has resulted in an increasing number of works that fruitfully
combine the ﬁelds of EC and ML or deep learning (DL). For example, [2]
“converted” a selection method in EC to a random forest ensemble producer;
[3] used EC to evolve activation functions for DL-based image classiﬁers;
[4] utilized EC and DL to create accurate and interpretable context-aware
recommender systems. Major conferences in the ﬁeld of EC now regularly
address the combining of EC and ML, e.g., GECCO, arguably the major
EC event, devotes two entire tracks and three workshops to the blending of
evolution and learning. There are a number of good surveys on evolutionary
machine learning: [5], [6], and [7].

EC is thus a popular family of potent algorithms that complements ML
and DL to the beneﬁt of all ﬁelds concerned. Further, there is a large and
growing community of EC+ML practitioners. We have used several EC open-
source software packages over the years and have identiﬁed a large “hole” in
the software landscape—there is a lacuna in the form of an EC package that
is:

1. A comprehensive toolkit for running evolutionary algorithms.
2. Written in Python.
3. Can work with or without scikit-learn (aka sklearn), i.e., supports

both sklearn and non-sklearn modes.

4. Designed with modern software engineering in mind.
5. Designed to support all popular EC paradigms (GA, GP, ES, coevolu-

tion, multi-objective, etc’).

While there are several EC Python packages, none fulﬁll all ﬁve require-
ments. Some are not written in Python, some are badly documented, some
do not support multiple EC paradigms, and so forth. Importantly for the
ML community, most tools do not intermesh with extant ML tools. Indeed,
we have personally had experience with the hardships of combining EC tools
with scikit-learn when doing evolutionary machine learning. We hope that
by adhering to the above ﬁve pillars EC-KitY will be deemed useful by a
large community.

2. EC-KitY

2.1. Setting up an evolutionary experiment

As noted, EC-KitY can work both in general, non-sklearn mode and in

sklearn mode.

2

In non-sklearn mode, the user can run an EA with a mere 3 lines of code

(the problem being solved below is symbolic regression [8]):

algo = SimpleEvolution ( Subpopulation ( S y m b o l i c R e g r e s s i o n E v a l u a t o r () ) )
algo . evolve ()
print ( ' algo . execute ( x =2 , y =3 , z =4) : ' , algo . execute ( x =2 , y =3 , z =4) )

Running an EA in sklearn mode is just as simple (again, a symbolic-

regression problem):

X , y = make_regression ( n_samples =100 , n_features =3)
terminal_set = c re a t e _ t e r m in a l _ s e t ( X )
algo = SimpleEvolution ( Subpopulation ( creators = FullCreator ( terminal_set =

terminal_set ) ,

regressor = SKRegressor ( algo )
X_train , X_test , y_train , y_test = tra i n_t e st_ s pli t (X , y , test_size =0.2)
regressor . fit ( X_train , y_train )
print ( ' MAE on test set : ' , m e a n_ a b s o l u t e _e r r o r ( y_test , regressor . predict (

evaluator = R e g r e s s i o n E v a l u a t o r () ) )

X_test ) ) )

The user may wish to specify additional components of the EA rather
than rely on default values; this can be readily achieved through the relevant
constructor, e.g.:

algo = SimpleEvolution (

Subpopulation ( creators = R a m p e d H a l f A n d H a l f C r e a t o r ( init_depth =(2 , 4) ,

terminal_set ,

function_set ,

terminal_set =

function_set =

bloat_weight =0.0001)

,

)

populati on _s ize =200 ,
evaluator = S y m b o l i c R e g r e s s i o n E v a l u a t o r () ,
higher_ is_ bet ter = False ,
elitism_rate =0.05 ,
o pe ra t or s _s e q u e n c e =[

Sub tre eCr os sover ( probability =0.9 , arity =2) ,
SubtreeM ut ation ( probability =0.2 , arity =1) ,
ERCMutation ( probability =0.05 , arity =1)

] ,

) ,

breeder = SimpleBreeder () ,
max_workers =4 ,
max_generation =500 ,
statistics = B e s t A v e r a g e W o r s t S t a t i s t i c s ()

Detailed tutorials and several use cases are available at [9].

2.2. Architecture

As previously noted, we plan for EC-KitY to support all main EC paradigms,

including genetic algorithms (GAs), genetic programming (GP), evolution

3

Name Class

Name Abstract class

Name Class generalized by Operator

Composition

Association

Generalization

Statistics

Operator

GeneticOperator

TerminationChecker

Algorithm

Breeder

PopulationEvaluator

Population

SelectionMethod

IndividualEvaluator

Subpopulation

Creator

Individual

Fitness

ClassiﬁerMixin

RegressionMixin

SKLearnWrapper

SKRegressor

SKClassiﬁer

Algorithm

Figure 1: The general architecture of EC-KitY (left), and the added components for
sklearn mode (right).

strategies (ES), coevolution, and evolutionary multi-objective optimization.
To support this plethora of algorithms and genetic operators, we based our
design on ECJ, likely the most comprehensive EC package to date, which has
been in use and under development for over two decades [10]. We did, how-
ever, veer away from ECJ on a crucial point: Statistics can be drawn from
any operation using event hooks. Thus, evolution is distributed (as opposed
to ECJ), which improves the decoupling and the separation of concerns.

The architecture of EC-KitY is depicted in Figure 1. The Algorithm
class, which acts on the population using the Breeder class, serves as the
entry point to EC-KitY. Several classes extend the Operator class (these
are denoted by a small triangle); they emit events that can be intercepted
by Statistics. The same EC-KitY code can be used both in a standalone
mode (Figure 1, left) and in sklearn mode (Figure 1, right). The latter is
achieved by wrapping an Algorithm instance with an SKLearnWrapper.

EC-KitY is designed to be easily extended: it is heavily over-architected,
with many hooks that facilitate system modiﬁcation and enhancement. The
architecture supports the following features: execution in the cloud or in a
cluster, multiple statistics, multithreaded evaluation, replicability standards
(all of which have already been implemented), as well as checkpointing and
logging facilities (under active development).

4

Table 1: Feature comparison of EC-KitY with 8 other extant software packages. (cid:52): feature
exists, ((cid:52)): feature planned soon, (cid:55): feature completely lacking, ∃: feature mostly lacking.

Feature EC-KitY
Platypus
Language Python Python Python Python Python

gplearn

geatpy

DEAP

sklearn-compatible
SE Design
GA representations
GP representations
User-deﬁned operators
User-deﬁned representation
Coevolution
Multiobjective
Statistics
Documentation
API
Latest version

(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
((cid:52))
((cid:52))
(cid:52)
(cid:52)
(cid:52)
2022

(cid:52)
∃
(cid:52)
(cid:55)
(cid:55)
(cid:55)
(cid:55)
(cid:52)
(cid:52)
∃
∃
2022

(cid:52)
(cid:55)
(cid:55)
(cid:52)
(cid:55)
(cid:55)
(cid:55)
(cid:55)
(cid:52)
(cid:52)
(cid:52)
2019

(cid:55)
(cid:55)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
∃
(cid:52)
2019

(cid:55)
(cid:55)
(cid:52)
(cid:55)
(cid:52)
(cid:52)
(cid:55)
(cid:52)
∃
∃
(cid:55)
2020

ECJ
Java
(cid:55)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
2019

Jenetics
Java
(cid:55)
(cid:52)
(cid:52)
∃
(cid:52)
(cid:52)
(cid:55)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
2022

KEEL HeuristicLab
Java
(cid:55)
∃
(cid:52)
(cid:52)
(cid:55)
(cid:55)
(cid:52)
(cid:52)
(cid:52)
∃
(cid:55)
2015

C#
(cid:55)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
(cid:55)
(cid:52)
(cid:52)
(cid:52)
(cid:52)
2022

3. Comparison with Other Packages

Through considerable hands-on experience with EC open-source software
over many years, and through additional extensive research, we have iden-
tiﬁed the following 8 tools, whose major features are compared in Table 1,
along with EC-KitY [9]: gplearn [11], geatpy [12], DEAP [13], Platypus
[14], ECJ [10], Jenetics [15], KEEL [16], HeuristicLab [17].

Only two packages are written in Python and are also sklearn-compatible:
geatpy and gplearn. However, as shown in Table 1, they lack many im-
portant features that EC-KitY possesses.

4. Concluding Remarks

The EC-KitY library is under active development. Presently, we plan to
add a variety of evolutionary algorithms, individual types, genetic operators,
and tests. We are also working on extending and enhancing the documen-
tation. We wish to broaden both the user and developer communities by
implementing more sample use cases from diﬀerent domains, and by encour-
aging developers to contribute. Given the popularity and diverse applicability
of evolutionary algorithms, we hope that EC-KitY ﬁnds multitudinous and
beneﬁcial uses.

References

[1] M. Sipper, R. S. Olson, J. H. Moore, Evolutionary computation: the next major

transition of artiﬁcial intelligence?, BioData Mining 10 (1) (2017) 26.

5

[2] M. Sipper, J. H. Moore, Conservation machine learning: a case study of random

forests, Nature Scientiﬁc Reports 11 (1) (2021) 3629.

[3] R. Lapid, M. Sipper, Evolution of activation functions for deep learning-based image
classiﬁcation, in: GECCO ’22: Proceedings of the Genetic and Evolutionary Com-
putation Conference, Association for Computing Machinery, New York, NY, USA,
2022.

[4] A. Livne, E. S. Tov, A. Solomon, A. Elyasaf, B. Shapira, L. Rokach, Evolving context-
aware recommender systems with users in mind, Expert Systems with Applications
189 (2022) 116042.

[5] A. Telikani, A. Tahmassebi, W. Banzhaf, A. H. Gandomi, Evolutionary machine

learning: A survey, ACM Computing Surveys 54 (8) (2022).

[6] H. Al-Sahaf, Y. Bi, Q. Chen, A. Lensen, Y. Mei, Y. Sun, B. Tran, B. Xue, M. Zhang,
A survey on evolutionary machine learning, Journal of the Royal Society of New
Zealand 49 (2) (2019) 205–228.

[7] J. Zhang, Z.-h. Zhan, Y. Lin, N. Chen, Y.-j. Gong, J.-h. Zhong, H. S. Chung, Y. Li,
Y.-h. Shi, Evolutionary computation meets machine learning: A survey, IEEE Com-
putational Intelligence Magazine 6 (4) (2011) 68–75.

[8] M. Sipper, Binary and multinomial classiﬁcation through evolutionary symbolic re-
gression, in: GECCO ’22: Proceedings of the Genetic and Evolutionary Computation
Conference, Association for Computing Machinery, New York, NY, USA, 2022.

[9] M. Sipper, T. Halperin, I. Tzruia, A. Elyasaf, Evolutionary Computation Tool Kit in

Python, https://www.eckity.org/ (2022).

[10] E. O. Scott, S. Luke, ECJ at 20: Toward a general metaheuristics toolkit, in: Pro-
ceedings of the Genetic and Evolutionary Computation Conference Companion, 2019,
pp. 1391–1398.

[11] T. Stephens, Genetic Programming in Python, with a scikit-learn inspired API,

https://github.com/trevorstephens/gplearn (2019).

[12] geatpy, Evolutionary algorithm toolbox and framework with high performance for

Python, https://github.com/geatpy-dev/geatpy (2022).

[13] F.-A. Fortin, F.-M. De Rainville, M.-A. Gardner, M. Parizeau, C. Gagn´e, DEAP:
Evolutionary algorithms made easy, Journal of Machine Learning Research 13 (2012)
2171–2175.

[14] Platypus, A Free and Open Source Python Library for Multiobjective Optimization,
https://github.com/Project-Platypus/Platypus, accessed: 2022-4-29 (2020).
[15] F. Wilhelmst¨otter, Genetic Algorithm, Genetic Programming, Evolutionary
Algorithm, and Multi-objective Optimization, https://github.com/jenetics/
jenetics (2022).

[16] KEEL, Knowledge Extraction based on Evolutionary Learning, https://github.

com/SCI2SUGR/KEEL (2015).

[17] A. Elyasaf, M. Sipper, Software review: The HeuristicLab framework, Genetic Pro-

gramming and Evolvable Machines 15 (2) (2014) 215–218.

6

