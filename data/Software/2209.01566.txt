Towards Top-Down Deep Code Generation in Limited Scopes

Jian Gu
University of Zurich
Zurich, Switzerland
gu@ifi.uzh.ch

Harald C. Gall
University of Zurich
Zurich, Switzerland
gall@ifi.uzh.ch

2
2
0
2

p
e
S
4

]
E
S
.
s
c
[

1
v
6
6
5
1
0
.
9
0
2
2
:
v
i
X
r
a

ABSTRACT
Deep code generation is a topic of deep learning for software en-
gineering (DL4SE), which adopts neural models to generate code
for the intended functions. Since end-to-end neural methods lack
the awareness of domain knowledge and software hierarchy, the
results often require manual correction. To systematically explore
the potential improvements of code generation, we let it participate
in the whole top-down development from intentions to realizations,
which is possible in limited scopes. In the process, it benefits from
massive samples, features, and knowledge. As the foundation, we
suggest building a taxonomy on code data, namely code taxonomy,
leveraging the categorization of code information. Moreover, we
introduce a three-layer semantic pyramid (SP) to associate text data
and code data. It identifies the information of different abstraction
levels, and thus introduces the domain knowledge on development
and reveals the hierarchy of software. Furthermore, we propose a
semantic pyramid framework (SPF) as the approach, focusing on
softwares of high modularity and low complexity. SPF divides the
code generation process into stages and reserves spots for potential
interactions. Eventually, we conceived application scopes for SPF.

KEYWORDS
code generation, deep learning, frame semantics, knowledge graph,
requirement elicitation, program representation, software analytics

ACM Reference Format:
Jian Gu and Harald C. Gall. 2022. Towards Top-Down Deep Code Generation
in Limited Scopes. In Proceedings of ACM Conference (Conference’17). ACM,
New York, NY, USA, 5 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 INTRODUCTION
To promote the productivity of software development, using deep
learning to assist related activities is a lasting research trend [17, 33].
For example, neural models trained on massive code-related data
could assist programming through code generation [18]. However,
we identified a few restrictions of neural methods waiting to be
overcome. First, models lack the necessary domain knowledge on
software development. For example, models can merely learn the
idiomatic usage of the relevant API dependency but cannot ensure
validity or avoid possible misuse issues. Second, models require
accurate and complete functional descriptions, even related to the

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
Conference’17, July 2017, Washington, DC, USA
© 2022 Association for Computing Machinery.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

context and method call. The truth is that it is better to let mod-
els infer the requirement based on the software hierarchy. Third,
neural methods are weak in transparency and flexibility, thereby
tend to underperform in scenarios where potential interactions are
required, such as manual inspection or intervention. Based on the
above considerations, we propose adopting neural models in the
whole top-down development from intentions to realizations. In
this way, we explore performance improvements in various scenes,
by providing domain knowledge and software hierarchy to code
generation. Considering the difficulty, the research scope is limited
to softwares of high modularity and low complexity.

Figure 1: Diagram of modular WebUI development [6], where each
UI component in the webpage is supported by a separate depen-
dency, and meanwhile filled with specific resources or values.

The webpage in Fig. 1 is an illustrative example of top-down code
generation. Its implementation from intentions to realizations can
be a 3-step process: (1) everything starts with a prototype, which
clearly describes the webpage layout. For example, there should be
a navigation bar, an avatar and a search bar in the header, and a grid
view to display cards in the webpage body; and (2) a knowledge
engine that knows available libraries suggest API usages to fulfill
the requirements, such as recommending “featured-hotels@1.x” and
“hotel-card@2.x” for the grid view and cards, with the compatibility
consideration; and (3) a set of utility codes accessing algorithms
and data resources arrange and control UI components, including
personalizing the product list, loading the product detail.

To achieve the goal of adopting code generation in the top-down
development process, we start with taxonomy on code data, namely
code taxonomy, in the light of code information. On the basis of
code taxonomy, we designed the scheme of a three-layer seman-
tic pyramid (SP) to associate program realizations with human
intentions. In each SP layer, we take corresponding techniques to
organize data in the form of graphs. By taking SP as the mental
model, we plan to further construct a semantic pyramid framework
(SPF). SPF makes code data high-quality and well-organized, and
meanwhile, introduces program semantics and domain knowledge.

 
 
 
 
 
 
Conference’17, July 2017, Washington, DC, USA

Jian Gu and Harald C. Gall

Table 1: Categorization of code information

Table 2: Definitions of the datatype for code taxonomy

Group
Attributes Constraint

Type

Element
Knowledge

Description
restrictions on the applicable scope
discriminative implementation details
patterns or usages involved in development API dependencies, frameworks

Example
conditions, inputs, outputs
operators, numerics, strings

Semantics Concept
Function

entities referred to and their interrelations
logical functions to be actually executed

contexts, identifiers (objects, values)
calculations, operations, exceptions

Syntactics

Structure

about how other information is organized

sequence, syntax tree and derivatives

2 APPROACH
Code Taxonomy. We define the term “code taxonomy” as the prac-
tice of categorization of code data. It is straightforward to build a
taxonomy referring to software purposes or topics, however, that
manner seems insufficient in reflecting the capability of methods,
especially for code generation. Therefore, we describe the task from
another viewpoint: beyond the influence of software purpose or topic,
by what basis could we further build taxonomy on code data?

In our approach, we regard code data as a mixture of different
types of information and disentangle this information to build code
taxonomy. Considering the inherent properties of code data and
the semantic associations with related text data, we classify code
information into 3 groups and 6 types, as shown in Table 1. Based on
the categorization of code information, we suggest quantifying the
information abundance of data samples on each information type
for various usages. For example, when we evaluate code generation
respecting the difficulty of data samples, it is natural to assess the
results separately for cases like whether there are API dependencies.
Semantic Pyramid. We propose a semantic-aware framework as
the follow-up work of introducing code taxonomy for code gen-
eration. SPF guarantees the recognizability of code data via code
assetization and establishes the connectivity between intentions
and realizations via semantic bridging. Its mental model is visualized
as a three-layer semantic pyramid, shown in Fig. 2.

Datatype

Code Pattern
Code Template/Sketch
Code Instance
Property Graph

Semantic Entity
Semantic Pattern
Semantic Frame/Sketch

Attributes

Semantics

Syntactics

Constraint Element Knowledge Concept

Function

Structure

✗
✓
✓

✗
✗
✓

✓
✓
✓

✓

✓
✗
✓

✗
✓
✓

The involved information is intended to be organized in the form
of graphs even though it corresponds to different abstraction levels
in different layers. The reason is that graph-form expressions are
ideal as the medium to explicitly represent various information,
and performant to establish connections with each other. Consider-
ing the differences of the information itself and their roles in the
framework, we introduce suitable techniques to build graphs and
find ways to bridge different graphs, and thus associate intentions
to realizations crossing the concept hierarchy of software.
Semantic Pyramid Framework. To describe the mechanism of
our framework, we distinguish the involved datatypes based on
their information abundance following the code taxonomy. For
simplicity, we prefer the qualitative division but not the quantitative
one. As shown in Table 2, we use the check mark (✓) to indicate a
datatype is rich in some types of code information, and the cross
mark (✗) for the opposite case. If an information type is not that
important to a datatype, we leave blank the marked area.

Figure 2: Diagram of the three-layer semantic pyramid, where the
code information of each layer is specified. The higher the layer, the
closer to text data, and vice versa, the closer to code data.

Figure 3: Overview of the semantic pyramid framework, where
rectangles are databases of the corresponding datatype, trapezoids
are spots for human-machine interactions, and ellipses represent
data instances. The color is to distinguish datatypes and procedures.

The code information is divided into 3 abstraction layers. The
intention layer cares about semantic information, namely semantic
concepts and logic functions of code data. The specification layer
is about the outline of code implementations, such as constraints
and dependencies that cannot be ignored. The realization layer is
about the detail of code implementations, where concrete elements
or structures matter. Every node of any graph in the upper layer
points to the complete graph in the lower layer, and each graph in
the lower layer is pointed to by multiple nodes in the upper layer.

By characterizing the role of datatypes defined following code
taxonomy, we divide the mechanism of the framework into three
stages, as illustrated in Fig. 3. In the first stage named code assetiza-
tion, code data is first processed into subprograms as templates to
increase the sample richness. Then, we use a property graph as the
code representation for the higher recognizability of samples [38].
Eventually, we mine code patterns from property graphs to reduce
the effect of variants. In the second stage named semantic bridging,
leveraging the informative property graphs, we extract semantic

Towards Top-Down Deep Code Generation in Limited Scopes

Conference’17, July 2017, Washington, DC, USA

entities and patterns to collect involved concepts and functions.
Furthermore, we compose semantic frames based on concepts and
functions with external knowledge bases. In the third stage named
top-down pipeline, we introduce code generation to assist top-down
development, leveraging the databases on features, knowledge, and
samples from the former stages. The pipeline divides usual develop-
ment into stages and reserves spots for interactions, corresponding
to the abstraction layers in the semantic pyramid.

The specification layer emphasizes the semantics information of
code patterns, which is represented by its own description and the
relations with others. The description could come from related text
data, such as comments, API directives, and even identifiers. The
relations could be meaning representation of text data [36], or the
logic representation of code data [21]. Compared with the intention
layer, the specification layer differs in granularity, even though they
both revolve around semantic entities and interrelations.

2.1 Code Assetization
We define Code Assetization as organizing code data into samples,
following code taxonomy. It focuses on the realization layer.

In the process of code assetization, SPF decouples semantics,
syntactics, and attributes information from code samples. We need
to generate high-quality representations of code samples [35] to
support operations such as retrieval and clustering. As code data
could be parsed as ASTs, CFGs, and PDGs, it is a cheap but precise
practice to first convert code data into the graph form, as the joint
data structure of the above-mentioned parsed results [38].

We build a sample base of code templates and code patterns
through data processing. Except for the handling of the elements,
the code template is roughly equivalent to the code sample, since
both reserve the divergence of concrete implementations. In con-
trast, the code pattern represents a bunch of similar code samples
and has no tolerance for variants. Leveraging diff computation [7]
and subprogram division [1], code patterns are extracted from code
templates but shorter in length and fewer in amount. As the prop-
erty graph is preferred to represent code data, code patterns could
be seen as the idiomatic usage of a partial code template.

The realization layer is focused on the synergy of code patterns
with extra knowledge bases. Since the divergence in code samples
is mainly caused by contexts and dependencies, we thus define two
types of knowledge bases to complement the information missed
by code patterns. One knowledge base is on internal context, which
determines the constraints of code templates. The other one is on
external dependencies, which determines the API dependencies.

2.2 Semantic Bridging
We define Semantic Bridging as seeking features and knowledge to
express requirements. It is about intention and specification layers.
For semantic bridging, we propose to jointly utilize semantic
parsing and knowledge graph. On one side, semantic parsing con-
verts natural language utterances to machine instructions [23]. It
mines information from text data with techniques like named entity
recognition and relation extraction. On the other side, knowledge
graphs use graph structures to organize semantic entities and their
interrelations [14]. It provides further flexibility by linking together
with available commonsense or domain knowledge graphs.

The intention layer relies on a linguistic meaning theory called
frame semantics [8]. A semantic frame is a conceptual structure of
the involved participants and is used to describe events, scenes, etc.
It usually contains frame elements as semantic roles in the formal
definition and lexical units that evoke other frames. That makes it
very similar to a function module or class definition in programs.
This similarity inspires us to build a corpus oriented to program
intentions, for example, based on FrameNet lexical database [27].

2.3 Top-Down Pipeline
In the framework, the top-down pipeline associates text code with
code data through two transitions: the transition from intentions to
specifications, and from specifications to realizations. Their medium
data is respectively the semantic sketch and the code sketch [29].
In the transition from intentions to specifications, the semantic
sketch purely cares about concepts and functions. Both semantic
frame and semantic sketch take concepts as nodes and functions as
edges. However, compared with code sketches, their concepts could
be more abstract while functions could be more complex. Thereby,
the transition aims to adopt alignment methods to eliminate the
semantic gap between semantic sketch and code sketch, especially
the granularity inconsistency. Other concerns are the details in the
transition, such as issues on constraint and knowledge.

The transition medium from specifications to realizations is the
code sketch. The code sketch is different from the code template,
even though both are graphs taking code patterns as nodes. The
code sketch takes semantic dependencies between code patterns as
edges while the code template takes actual dependencies in samples
as edges. Therefore, assuming we have a code sketch from the
upstream, we could retrieve code templates for each code pattern in
the given code sketch, then composite or generate code templates
as candidates. Further, with manual inspection or intervention on
elements and structures, the optimal code instance is determined.

2.4 Scope of Application
Due to the complexity and diversity in actual development, it is
important to find suitable application scopes for the framework.
Thereby, we considered some as preliminary targets.

One conceived application is assistive top-down developments
for specific purposes or topics, including WebUI programming as
introduced. Similarly, mobile development centered on UI pages is
worth attention, since it usually follows a conventional standard.
For example, an app could be a transition graph of activities, where
each activity corresponds to a UI page and its functional code. The
implementation of each activity could be decoupled as layout code,
functional code, and method call hierarchy [4], and thus well fits
the requirements of SPF.

Meanwhile, to reveal the potentiality of SPF in associating in-
tentions with realizations, automated construction of new API de-
pendency for modular development could be an option. Assume
there are API dependencies available as the reference, leveraging
knowledge bases in the framework, we aim to spawn meaningful
semantic variants. We name the new task “API imitation”.

Eventually, code information of multiple layers in the semantic
pyramid corresponds to different abstraction levels and also reveals
the software hierarchy. Thereby, it could be regarded as multimodal

Conference’17, July 2017, Washington, DC, USA

Jian Gu and Harald C. Gall

representations of software [34]. In this direction, we consider using
code taxonomy and semantic pyramid for program representation.

3 RELATED WORK
For code taxonomy, we mainly refer to other practices on taxonomy
for deep learning. Meanwhile, for SP and SPF, we consider tasks
connecting code data and text data as related work. Besides, we are
aware of topics involved in implementing the framework, including
code features, and topics about actual applications.
Taxonomy for Deep Learning. When some tasks are hard to
learn or evaluate, it is a strategy to build a taxonomy. For example,
in software engineering, there is a taxonomy on build failures in
continuous integration [31], a taxonomy of faults in deep learning
systems [13]. In other areas, taxonomy for deep learning even plays
a considerable role. In natural language processing, FrameNet
motivated the study on automatic semantic role labeling [27]. In
computer vision, ImageNet [28] is an image database for visual
object recognition, it follows the WordNet [24] hierarchy, where
each node is depicted by massive samples.
Code Retrieval, Generation and Comprehension. Sometimes,
programmers want alternatives to current implementations, for
example, Aroma [22] recommends code snippets based on the sim-
ilarity of structural features. To search code snippets for the given
query, CODEnn aligns the semantics of code data and text data by
jointly modeling their representations in the same vector space [10].
CSRS [5] considers both relevance matching and semantic matching,
while Yogo [25] recognizes different but mathematically-equivalent
alternatives based on dataflow graphs and rewrite rules. Inspired
by machine translation, code generation translates descriptions
to implementations, such as the pseudocode-to-code one by Se-
manticScaffold [41]. TRANX introduced a transition system to
generate formal meaning representations for code generation [39].
Code comprehension uses proper natural utterance to describe
the given code data, which could help understand programs: Con-
text2Name [2] generates meaningful variable names based on
the usage contexts, AdaMo [9] assembles foundation models to
describe the functionality of code snippets, CodeQA [20] demon-
strates the value of generating textual answers for the pairs of code
snippet and various types of question.
Program Analysis and Transformation. By adopting changes
to code data, the critical features could be highlighted, such as
S4Eq [15], which proves the equivalence by computing a verifiable
sequence of rewrite rules, and Perses [30], which reduces programs
to smaller ones in a syntax-guided way, and further help localizes
bugs. Also, program analysis helps mine code features. For example,
Lupa [32] supports fine-grained analysis on the usage of program-
ming language, PyART [12] extracts features from the context of
the program point for API recommendation [11]. In addition, code
clone detection and code evolution promote code reuse [40].
Assisted Programming and Development. There have proposed
performant methods to assist programming, Codex [3] and Poly-
Coder [37] introduce large-scale language models to provide intel-
ligence programming suggestions, including code autocompletion.
In contrast, assisted development focuses on the solution itself but
not the programming process. For example, AlphaCode [19] ap-
plies sampling, filtering, clustering on program samples to generate

human-level submissions for competitive programming challenges.
Some work is oriented to other tasks in the development, for exam-
ple, TransCoder improves the application of back-translation for
program translation [16, 26].

4 FUTURE PLANS
To obtain experience in building the code taxonomy, and form an
effective methodology, we developed a three-step plan. First, we
start with neural methods that learn from both code properties and
data distributions, focusing on program representation and code
generation. Then, we build code taxonomies in limited application
scopes and evaluate their effectiveness and drawbacks. Eventually,
we seek decent models for a complete framework and increase the
scale of the engineering to explore its applicability to real-world
use. Some milestones to be achieved are as follows:

• We are currently conducting a mining study on open source
software distinguished by the purpose or topic. The object
data is coding patterns, complemented by the information
on context and API dependence.

• Further, we would seek solutions for semantic associations
between program sketches and functional descriptions or
API directives, but more focused on graph representations
of multiple granularity or modality.

• To bridge intentions and specifications in a formal way, we
plan on constructing a lexical database leveraging frame
semantics and knowledge graphs. Besides, we connect it to
available instances from relevant fields.

• To bridge specifications and realizations and promote code
reusability, we plan on building a code corpus, where the
data are templatized but composable subprograms, with the
compatibility support of code variants.

• Once the code taxonomy is constructed, we would design
retrieval-based neural models or inference engines to pair
with this knowledge base. The framework should apply to
other scenes where the semantic pyramid fits.

• Eventually, we would study the behavior and impact of the
framework on building programs with a certain complexity,
moreover, on building highly modular software or libraries
that fulfill actual development requirements.

5 CONCLUSIONS
To summarize, to overcome a few restrictions of neural methods, we
suggest building a code taxonomy in light of code information. And
then, we propose a semantic-aware framework, taking the semantic
pyramid as its mental model, for top-down code generation.

SPF promotes code reusability through solid recognizability of
code data and intense connectivity from intentions to realizations.
SPF indicates a novel framework of semantic awareness, especially
when centered on the graph-form expression of code-related data.
Its capability to support inspection or manipulation, requirement
elicitation, and multimodal representation is beneficial.

As an exploratory work, top-down code generation is novel but
faces challenges. For example, human-machine interactions could
be very heavy in some cases where requirements are hard to capture
or fulfill. Thus, we focus on realizing the proposed framework in
limited scopes and seek continuous evolutions thereafter.

Towards Top-Down Deep Code Generation in Limited Scopes

Conference’17, July 2017, Washington, DC, USA

[26] Baptiste Rozière, J Zhang, François Charton, Mark Harman, Gabriel Synnaeve,
and Guillaume Lample. 2021. Leveraging Automated Unit Tests for Unsupervised
Code Translation. ArXiv abs/2110.06773 (2021).

[27] Josef Ruppenhofer, Michael Ellsworth, Miriam R. L. Petruck, Christopher R.
Johnson, and Jan Scheffczyk. 2006. FrameNet II: Extended theory and practice.
[28] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean
Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael S. Bernstein,
Alexander C. Berg, and Li Fei-Fei. 2015. ImageNet Large Scale Visual Recognition
Challenge. International Journal of Computer Vision 115 (2015), 211–252.
[29] Armando Solar-Lezama, Liviu Tancau, Rastislav Bodík, Sanjit A. Seshia, and
Vijay A. Saraswat. 2006. Combinatorial sketching for finite programs. Proceedings
of the 12th international conference on Architectural support for programming
languages and operating systems - ASPLOS-XII (2006).

[30] Chengnian Sun, Yuanbo Li, Qirun Zhang, Tianxiao Gu, and Zhendong Su. 2018.
Perses: Syntax-Guided Program Reduction. 2018 IEEE/ACM 40th International
Conference on Software Engineering (ICSE) (2018), 361–371.

[31] Carmine Vassallo, Gerald Schermann, Fiorella Zampetti, Daniele Romano, Philipp
Leitner, Andy Zaidman, Massimiliano Di Penta, and Sebastiano Panichella. 2017.
A Tale of CI Build Failures: An Open Source and a Financial Organization Per-
spective. In ICSME.

[32] Anna Vlasova, Maria Tigina, Ilya Vlasov, Anastasiia Birillo, Yaroslav Golubev,
and Timofey Bryksin. 2022. Lupa: A Framework for Large Scale Analysis of the
Programming Language Usage.

[33] Cody Watson, Nathan Cooper, David Nader-Palacio, Kevin Moran, and Denys
Poshyvanyk. 2020. A Systematic Literature Review on the Use of Deep Learning
in Software Engineering Research. ArXiv abs/2009.06520 (2020).

[34] Martin Weyssow, Houari A. Sahraoui, and Bang Liu. 2022. Better Modeling
the Programming World with Code Concept Graphs-augmented Multi-modal
Learning.

[35] Steven Euijong Whang, Yuji Roh, Hwanjun Song, and Jae-Gil Lee. 2021. Data
Collection and Quality Challenges in Deep Learning: A Data-Centric AI Perspec-
tive.

[36] Wenkai Xie, Xin Peng, Mingwei Liu, Christoph Treude, Zhenchang Xing, Xiaoxin
Zhang, and Wenyun Zhao. 2020. API method recommendation via explicit
matching of functionality verb phrases. Proceedings of the 28th ACM Joint Meeting
on European Software Engineering Conference and Symposium on the Foundations
of Software Engineering (2020).

[37] Frank F. Xu, Uri Alon, Graham Neubig, and Vincent J. Hellendoorn. 2022. A
Systematic Evaluation of Large Language Models of Code. ArXiv abs/2202.13169
(2022).

[38] Fabian Yamaguchi, Nico Golde, Dan Arp, and Konrad Rieck. 2014. Modeling and
Discovering Vulnerabilities with Code Property Graphs. 2014 IEEE Symposium
on Security and Privacy (2014), 590–604.

[39] Pengcheng Yin and Graham Neubig. 2018. TRANX: A Transition-based Neural
Abstract Syntax Parser for Semantic Parsing and Code Generation. In EMNLP.
[40] Xunhui Zhang, Tao Wang, Yue Yu, Yanzhi Zhang, Yan Zhong, and Huaimin Wang.
2022. The Development and Prospect of Code Clone. ArXiv abs/2202.08497 (2022).
[41] Ruiqi Zhong, Mitchell Stern, and Dan Klein. 2020. Semantic Scaffolds for

Pseudocode-to-Code Generation. ArXiv abs/2005.05927 (2020).

REFERENCES
[1] Ferran Alet, Javier Lopez-Contreras, James Koppel, Maxwell Nye, Armando Solar-
Lezama, Tomas Lozano-Perez, Leslie Pack Kaelbling, and Joshua B. Tenenbaum.
2021. A large-scale benchmark for few-shot program induction and synthesis. In
ICML.

[2] Rohan Bavishi, Michael Pradel, and Koushik Sen. 2018. Context2Name: A Deep
Learning-Based Approach to Infer Natural Variable Names from Usage Contexts.
ArXiv abs/1809.05193 (2018).

[3] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared
Kaplan, Harri Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, et al. 2021.
Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374
(2021).

[4] Sen Chen, Lingling Fan, Chunyang Chen, Ting Su, Wenhe Li, Yang Liu, and
Lihua Xu. 2019. StoryDroid: Automated Generation of Storyboard for Android
Apps. 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)
(2019), 596–607.

[5] Yiran Cheng and Li Kuang. 2022. CSRS: Code Search with Relevance Matching

and Semantic Matching. ArXiv abs/2203.07736 (2022).

[6] Cocycles. 2022. Bit Cloud: How teams build composable software together.

Retrieved May 20, 2022 from https://bit.cloud/

[7] Jean-Rémy Falleri, Floréal Morandat, Xavier Blanc, Matias Martinez, and Monper-
rus Martin. 2014. Fine-grained and accurate source code differencing. Proceedings
of the 29th ACM/IEEE international conference on Automated software engineering
(2014).

[8] Charles J. Fillmore and Collin F. Baker. 2001. Frame semantics for text under-

standing.

[9] Jian Gu, Pasquale Salza, and Harald C. Gall. 2022. Assemble Foundation Models

for Automatic Code Summarization.

[10] Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018. Deep Code Search. 2018
IEEE/ACM 40th International Conference on Software Engineering (ICSE) (2018),
933–944.

[11] Xiaodong Gu, Hongyu Zhang, D. Zhang, and Sunghun Kim. 2016. Deep API
learning. Proceedings of the 2016 24th ACM SIGSOFT International Symposium on
Foundations of Software Engineering (2016).

[12] Xincheng He, Lei Xu, X. Zhang, Rui Hao, Yang Feng, and Baowen Xu. 2021.
PyART: Python API Recommendation in Real-Time. 2021 IEEE/ACM 43rd Inter-
national Conference on Software Engineering (ICSE) (2021), 1634–1645.

[13] Nargiz Humbatova, Gunel Jahangirova, Gabriele Bavota, Vincenzo Riccio, Andrea
Stocco, and Paolo Tonella. 2020. Taxonomy of Real Faults in Deep Learning
Systems. 2020 IEEE/ACM 42nd International Conference on Software Engineering
(ICSE) (2020), 1110–1121.

[14] Shaoxiong Ji, Shirui Pan, E. Cambria, Pekka Marttinen, and Philip S. Yu. 2021.
A Survey on Knowledge Graphs: Representation, Acquisition and Applications.
IEEE transactions on neural networks and learning systems PP (2021).

[15] Steven J Kommrusch, Monperrus Martin, and Louis-Noël Pouchet. 2021. Self-
Supervised Learning to Prove Equivalence Between Programs via Semantics-
Preserving Rewrite Rules. ArXiv abs/2109.10476 (2021).

[16] Marie-Anne Lachaux, Baptiste Rozière, Lowik Chanussot, and Guillaume Lam-
ple. 2020. Unsupervised Translation of Programming Languages. ArXiv
abs/2006.03511 (2020).

[17] Triet Huynh Minh Le, Hao Chen, and Muhammad Ali Babar. 2020. Deep Learning
for Source Code Modeling and Generation. ACM Computing Surveys (CSUR) 53
(2020), 1 – 38.

[18] Celine Lee, Justin Emile Gottschlich, Dan Roth Intel Labs, and University of
Pennsylvania. 2021. Toward Code Generation: A Survey and Lessons from
Semantic Parsing. ArXiv abs/2105.03317 (2021).

[19] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser,
Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al.
2022. Competition-Level Code Generation with AlphaCode. arXiv preprint
arXiv:2203.07814 (2022).

[20] Chenxiao Liu and Xiaojun Wan. 2021. CodeQA: A Question Answering Dataset

for Source Code Comprehension. ArXiv abs/2109.08365 (2021).

[21] Mingwei Liu, Xin Peng, Andrian Marcus, Christoph Treude, Xuefang Bai, Gang
Lyu, Jiazhan Xie, and Xiaoxin Zhang. 2021. Learning-based extraction of first-
order logic representations of API directives. Proceedings of the 29th ACM Joint
Meeting on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering (2021).

[22] Sifei Luan, Di Yang, Koushik Sen, and Satish Chandra. 2019. Aroma: code recom-
mendation via structural code search. Proceedings of the ACM on Programming
Languages 3 (2019), 1 – 28.

[23] Sungwon Lyu. 2019. Text Generation From Knowledge Graphs With Graph

Transformers. https://lyusungwon.github.io/studies/2019/09/19/graphwriter/
[24] George A. Miller. 1992. WordNet: A Lexical Database for English. Commun. ACM

38 (1992), 39–41.

[25] Varot Premtoon, James Koppel, and Armando Solar-Lezama. 2020. Semantic code
search via equational reasoning. Proceedings of the 41st ACM SIGPLAN Conference
on Programming Language Design and Implementation (2020).

