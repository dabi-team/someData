2
2
0
2

y
a
M
2
1

]

R
C
.
s
c
[

1
v
1
9
0
6
0
.
5
0
2
2
:
v
i
X
r
a

SYNERGÍA: Hardening High-Assurance Security Systems with
Conﬁdential and Trusted Computing

Wojciech Ozga
IBM Research – Zurich
TU Dresden

Rasha Faqeh
TU Dresden

Do Le Quoc
Huawei Research

Franz Gregor
Scontain

Silvio Dragone
IBM Research – Zurich

Christof Fetzer
TU Dresden

May 13, 2022

Abstract

High-assurance security systems require strong isolation
from the untrusted world to protect the security-sensitive
or privacy-sensitive data they process. Existing regula-
tions impose that such systems must execute in a trust-
worthy operating system (OS) to ensure they are not col-
located with untrusted software that might negatively im-
pact their availability or security. However, the existing
techniques to attest to the OS integrity fall short due to
the cuckoo attack.
In this paper, we ﬁrst show a novel
defense mechanism against the cuckoo attack, and we
formally prove it. Then, we implement it as part of an
integrity monitoring and enforcement framework that at-
tests to the trustworthiness of the OS from 3.7× to 8.5×
faster than the existing integrity monitoring systems. We
demonstrate its practicality by protecting the execution of
a real-world eHealth application, performing micro and
macro-benchmarks, and assessing the security risk.

1

Introduction

High-assurance security systems [27, 23, 48] leverage
trusted execution environments (TEEs) [18, 51, 4] because
TEEs offer strong integrity and conﬁdentiality guarantees
in the face of untrusted privileged software, i.e., ﬁrmware,
hypervisors, operating system (OS), and administrators.
However, applications executing in a TEE cannot exist
without the OS, which manages the computing resources
and controls applications’ life cycles. Thus, a trustwor-

thy OS is an essential element of each high-assurance se-
curity system because it guarantees its safety and secu-
rity. Otherwise, an untrustworthy OS might run malware
that halts the victim application or steals secrets from the
TEE via side-channel attacks [79, 87], as depicted in Fig-
ure 1. Germany introduced regulations requiring high-
assurance security systems in the eHealth domain [27] to
execute inside TEE on a trustworthy OS [26]. State-of-
the-art mechanisms to attest to the OS’s trustworthiness
rely on the trusted platform module (TPM) [76], a secure
element storing and certifying integrity measurements of
ﬁrmware and OS. Unfortunately, the TPM is vulnerable to
the cuckoo attack (a.k.a relay attack) [63, 21] that makes
the TPM attestation untrustworthy. We propose a novel
defense mechanism against the TPM cuckoo attack, and
we implement it as part of the framework responding to
the German eHealth systems regulations [26].

The integrity measurement architecture (IMA) [74] and
the dynamic root of trust for measurements (DRTM) [70]
are state-of-the-art mechanisms providing OS integrity
auditing and enforcement. The DRTM securely loads the
kernel to the memory, and IMA, which is part of that ker-
nel, ensures that the kernel loads only software whose in-
tegrity is certiﬁed with a digital signature. Both technolo-
gies, when used together, ensure the load-time integrity of
the kernel and software loaded to the memory during the
OS runtime. Speciﬁcally, the DRTM, a hardware technol-
ogy implemented in the CPU, stops all cores except one,
disables interrupts, measures the to-be-loaded kernel, and
executes the kernel with the IMA integrity enforcement

1

 
 
 
 
 
 
state ((cid:204)), not the state of the compromised computer ac-
cessed by the veriﬁer.

The existing defenses against the cuckoo attack have
limited application in real-world data centers (DCs). The
ﬁrst approach relies on the time side-channel [24, 69] in
which a remote TPM is unmasked by observing increased
communication latency. This approach requires calcula-
tion of hardware-speciﬁc statistics, is prone to false pos-
itives because the high TPM communication latency (in-
cluding signature generation) makes the distance bound-
ing infeasible [63, 46], and requires stable measurement
conditions in which extraneous OS services are suspended
during the TPM communication [24] — impractical as-
sumptions for real-world DCs. Flicker [57] adapts an-
other approach. It exploits DRTM to run an application
in isolation from the untrusted OS, allowing it to com-
municate with the TPM directly. Flicker is insufﬁcient
for the targeted systems like [27] because i) it does not
attest to the computer location, making the DRTM at-
testation untrustworthy because of simple hardware at-
tacks [83] and cold-boot attacks [32] and ii) while it per-
mits to split applications in multiple services that run iso-
lated, it does not support systems with moderate through-
put and latency requirements. In more detail, DRTM pro-
vides isolation in which the entire CPU executes only a
single service at a time and a single context-switching
takes 10-100s of milliseconds [57, 56].
It results in an
estimated program execution’s throughput of about 1-10
requests per computer per second when running multi-
ple eHealth services, like [26]. A practical solution re-
quires that hundreds of services are processed in paral-
lel per computer. We require an improvement of at least
one order of magnitude in throughput compared to Flicker.
Other approaches [19, 20] fall short in the context of the
TPM because i) the TPM is a passive device controlled
by software that could counterfeit its communication with
external devices and ii) they would require human inter-
action during each computer boot.

The limitations of the existing solutions motivate us
to propose a new automatic, practical at the data center-
scale defense mechanism that deterministically detects the
cuckoo attack and allows for the processing of parallel
requests. We demonstrate that despite the differences
in their threat models and designs, TEE and TPM-based
techniques complement each other, allowing for mitigat-
ing the cuckoo attack. Consequently, high-assurance se-

Figure 1: An adversary must run arbitrary software to
mount a software side-channel attack that can compro-
mise the conﬁdentiality guarantee of Intel SGX. Colors
are consistent across all ﬁgures.
mechanism. IMA restricts software loaded to the mem-
ory by reading the digital signature corresponding to the
given software from the ﬁle system and verifying that this
software’s integrity measurement (a cryptographic hash
over its binary) matches the original integrity measure-
ment signed by a trusted party (Figure 2). Thus, only
software certiﬁed by a trusted party can be loaded to the
memory by the kernel.

The TPM enables auditing of the kernel and software
integrity because DRTM and IMA store corresponding in-
tegrity measurements in the tamper-proof TPM memory.
The TPM then certiﬁes the stored measurements to a ver-
iﬁer accordingly with the TPM remote attestation proto-
col. However, the TPM remote attestation is prone to the
cuckoo attack, which is a security issue for TPM-based
systems [28, 46, 16]. In this attack, an adversary certi-
ﬁes the software integrity of the underlying computer us-
ing certiﬁed measurements of another computer (see Fig-
ure 3). A veriﬁer connects to the compromised computer
and communicates with the TPM to check the computer
software integrity ((cid:202)). The adversary prevents the veriﬁer
from accessing the local TPM by redirecting communica-
tion to a remote TPM ((cid:203)). Consequently, the veriﬁer reads
the remote TPM, which attests to an arbitrary, trustworthy

Figure 2: Integrity measurement architecture (IMA) is
part of the kernel. It approves software to execute and pro-
vides reporting capacity to verify what software has been
executed since the load of the kernel.

2

main memory Ωoperating system high-assurance security system εSGX enclaveuntrusteddata ﬂowadversarycovert  channelencrypted dataProblem addressed in this paper: side-channels, e.g., page faults, data access latencytrusted (SGX)dataCPU cachesεexecutablesψkey observation:  ε∈Ω∧ψ∈Ωεψ  malware ψtrusted (measured boot)data ﬂowcheck signature✓accept ε×store measurementadversaryIMA appraisalεexecutablesψmemory Ωεε∈Ω∧ψ∉ΩTPM certiﬁes:TPMtrust ?εexec εload εtrust ?ψexec ψcheck signaturereject ψkernelcurity systems executing inside TEE can attest to the OS
integrity. Our solution builds trust in a remote computer
starting from a piece of code executing inside the TEE,
and then systematically extend it to the entire OS. First,
we leverage TEE to settle a trusted piece of code on an
untrusted remote computer. We use it to verify that the
computer is in the correct DC and mitigate the cuckoo
attack. This allows us to extend trust to the TPM, then
to the loaded kernel and its integrity-enforcement mech-
anism and, ﬁnally, to software being executed during the
OS runtime.

We implement this approach in an integrity monitor-
ing and enforcement framework called SYNERGÍA, which
ensures that high-assurance security applications execute
on correctly initialized and integrity-enforced OS located
in the expected DC. The high-assurance security systems
conform to the TEE threat model, while they gain OS in-
tegrity guarantees under a less rigorous threat model typ-
ical for TPM-based systems. We perform security risk
analysis related to the use of these techniques in §6.
Altogether, we make the following contributions:

1. We designed and implemented an integrity monitor-
ing and enforcement framework called SYNERGÍA
that:

• attests to the OS trustworthiness (§1,§3),

• defends against the cuckoo attack (§5.1, §5.2),

• provides a reliable approach to estimate the ge-
olocation of physical servers beyond the simple
TPM geo-tagging (§4.3),

• provides local attestation, allowing decentral-
ization of the monitoring system (§4.1, §4.4),

• the service itself can be remotely attested

(§5.4),

• veriﬁes the compliance of provisioned re-

sources with a given policy (§4.2, §4.4).

2. We assessed the security risk of SYNERGÍA (§6).

3. We demonstrated SYNERGÍA protecting a real-world

application in the eHealth domain (§7.1).

4. We evaluated its security and performance (§7).

5. We provided the formal proof of the protocol detect-

ing the cuckoo attack (§7.4).

Figure 3: The cuckoo attack. The veriﬁer connects to the
compromised machine (left) and reads the TPM quote to
verify its integrity. The quote is, however, retrieved from
the remote TPM attached to a legitimate machine (right).
The veriﬁer cannot distinguish if the quote comes from
the TPM attached to the local or remote machine.
2 Threat Model

We adopt the threat model of organizations, such as gov-
ernments, banks, and health, legally bound to protect the
security-sensitive data they process.
In particular, we
assume they execute high-assurance security systems in
their own DCs or in the hybrid cloud in which security-
critical resources are provisioned on-premises. This im-
plies limited and well-controlled access to DCs, allowing
us to assume that an adversary, e.g., a rogue operator, can-
not perform physical or hardware attacks. To ensure that
a high-assurance security system executes inside the DC,
we only presume that dedicated computers, called trusted
beacons, are located inside that DC and cannot be physi-
cally moved outside (§4.3).

Initially, we only trust the CPU (including its hardware
features TEE and DRTM) and a small piece of code (the
agent). Using the TEE attestation protocol, we ensure that
the legitimate agent executes inside the TEE on a genuine
CPU on some computer. Then, we use the agent to verify
that the computer is located in the correct DC by measur-
ing the proximity to the trusted beacon via a round-trip
time distance-bounding protocol. Once we ensure that the
agent runs in the expected DC (no physical and hardware
attacks), we use it to establish trust with the local TPM
with the help of our protocol formally proved to be re-
sistant to the cuckoo attack (§7.4). At this point, we use
the TPM to extend the trust to the kernel and its built-in
integrity-enforcement mechanism, IMA. Eventually, we
use IMA to expand trust to the software loaded during the
OS runtime.

High-assurance security systems executing inside the
TEE follow the TEE threat model, i.e., operating sys-

3

computer controlled by adversarylegitimate computerveriﬁerveriﬁer requests the TPM quote of a local TPMmalicious driver  redirects request to a remote TPMthe remote TPM  certiﬁes a remote computer>_  malicious   TPM driver>_TPM123communication  over the networkcommunication  handled by the OS>_software/console providing  remote access to a TPMtrusted untrusted tem, ﬁrmware, other software, and system administra-
tor are untrusted. The additional guarantees of the op-
erating system integrity follow the threat model of TPM-
based systems, i.e., software whose integrity is enforced
at load-time behaves in a trustworthy way also during
its execution. The runtime integrity of the process can
be enforced using existing techniques, such as control-
ﬂow integrity enforcement [43], fuzzing [88], formal
proofs [89], memory-safe languages [54], or memory cor-
ruption mitigation techniques (position-independent exe-
cutables, stack-smashing protection, relocation read-only
techniques). Please note that many of these techniques are
applied nowadays by default during the software packag-
ing process, as in the case of Alpine Linux [2].

We assume a ﬁnancially or governmentally motivated
adversary who might gain root access to selected comput-
ers inside a DC by exploiting network or OS misconﬁgu-
rations, exploiting vulnerabilities in the OS, or using so-
cial engineering. Her goal is to extract security-sensitive
or privacy-sensitive data, e.g., personal data, credentials,
or cryptographic material. She can stop or halt individ-
ual computers or processes, but she cannot stop all central
monitoring service instances responsible for reporting se-
curity incidents. We consider an untrusted network where
an adversary can view, inject, drop, and alter messages.
She can call the API with any parameters and conﬁgure
the routing, forcing packages to choose faster or slower
routes. Our network model is consistent with the classic
Dolev-Yao adversary model [22]. We rely on the sound-
ness of the employed cryptographic primitives used within
software and hardware components.

3 Design Decisions

Our objective is to provide a design that: i) enforces that
only trusted software is executed on a computer; ii) mon-
itors the remote computer OS to verify compliance to in-
tegrity requirements; iii) allows high-assurance security
systems to get insights into the OSs integrity.

We start by introducing the existing integrity monitor-
ing systems architecture [36, 35, 37] and adjust it to meet
the security guarantees required by high-assurance secu-
rity systems. Figure 4 shows the integrity monitoring ar-
chitecture where a central server pulls integrity measure-
ments from computers by communicating with dedicated

software, the agent. The agent on each computer collects
data from the underlying security and auditing subsystems
that measure and enforce the OS integrity. Central servers
aggregate the data in databases, verify it against whitelists,
and notify the security ofﬁcer about integrity violations.
Such architecture relies on the TPM as a root of trust.

1. Enforce the load-time integrity with secure boot and
OS integrity enforcement.

Secure boot [82] is the state-of-the-art technology to
enforce that only trusted software bootstraps a computer.
It relies on the chain of trust where each component
measures the integrity (calculates a cryptographic hash)
of the next component and executes it only if the hash
matches a corresponding digital signature. The measured
boot [75, 77] complements it by storing hashes in the
TPM, thus enabling auditing.

The integrity measurement architecture (IMA) [66, 74]
extends the functionality of measured boot and secure
boot to the OS level. IMA is part of the kernel and veriﬁes
all ﬁles’ integrity (i.e., executables, conﬁguration ﬁles, dy-
namic libraries) before they are loaded to the memory.
In particular, IMA-appraisal [33] enforces that the kernel
loads ﬁles whose hashes are certiﬁed with digital signa-
tures stored in the ﬁle system (Figure 2). The application
execution is halted until a dynamic library is loaded, and
fails if the library fails the integrity check. IMA enables
auditing by maintaining an IMA log, a dedicated ﬁle stor-
ing hashes of all ﬁles loaded to the memory since the ker-
nel load. It adds each ﬁle to the IMA log and stores a hash
over it in the TPM before the ﬁle is loaded to the memory.
Any tampering of the IMA log is detectable because the
IMA log’s integrity hash must match the value stored in
the TPM.

2. Enable remote attestation to prove that secure boot
and integrity enforcement are enabled.

The TPM remote attestation protocol [78] delivers a
technical assurance of the computer’s integrity. The TPM
chip digitally signs a report (quote) certifying hashes
recorded since the computer boot. The hashes reﬂect
loaded ﬁrmware and kernel and prove that integrity en-
forcement mechanisms are enabled. The veriﬁer can
check that the quote has not been manipulated because the
TPM signs the quote with a signing key that is embedded
in the TPM and linked to the certiﬁcate authority (CA) of

4

hash(pcr[n]||value). We propose to extend the secret φ
on top of the existing measurements stored in the PCR to
achieve the following properties: i) an adversary cannot
extract the secret from the PCR value after the secret is
extended to the PCR because the hash function result is
not invertible; ii) an adversary cannot reproduce the PCR
value in another TPM without knowing the secret, or ﬁnd-
ing a collision in the hash function; iii) after extending
the TPM with the secret, the secret is no longer needed
to identify the TPM because the PCR value extended with
the secret is unique.

5. Leverage DRTM technology to provide a trusted and
measured environment to access the local TPM.

We must ensure that the secret is shared with the lo-
cal TPM securely. We do it in a trusted environment
established by hardware technologies available in mod-
ern CPUs because these technologies also permit veriﬁca-
tion of the established execution environment’s integrity.
Therefore, they allow detecting (post-factum) any secret
extraction attempt, including software side-channel at-
tacks, because such attacks require violating the kernel or
initramfs integrity.

We propose generating the secret and extending it to
PCRs inside the initramfs 1 because DRTM allows for
later veriﬁcation of the kernel and initramfs integrity.
Speciﬁcally, the DRTM [70], which is a hardware tech-
nology that establishes an isolated execution environment
to run code on a potentially untrusted computer, can be
used during the boot process (i.e., by tboot [38]) to pro-
vide a measured load of the Linux kernel and initramfs.

The integrity measurements performed by DRTM can-
not be forged because the TPM offers a dedicated range of
PCRs (dynamic PCRs) that can only be reset or extended
when the TPM is in a certain locality [40]; Only the code
executed by DRTM can enter such locality. Therefore,
the presence of measurements in dynamic PCRs conﬁrms
that the DRTM was executed, and the comparison of PCRs
with the golden values conﬁrms that the secret was shared
with the local TPM because the correct TPM driver was
used.

1The initramfs is a minimalistic root ﬁlesystem that provides a
user space to perform initialization tasks, like loading device drivers,
mounting network ﬁle systems, or decrypting a ﬁlesystem [64], before
the OS is loaded.

Figure 4: The architecture of existing integrity monitor-
ing systems. The security ofﬁcer uses a monitoring system
to verify that high-assurance security systems execute on
hosts running trusted software.
the TPM manufacturer. However, the monitoring system
cannot merely rely on the TPM attestation because it is
vulnerable to the cuckoo attack [63]. It is indistinguish-
able whether an untrusted OS proves its integrity present-
ing a quote from a local TPM or impersonates a trustwor-
thy OS presenting a quote from a remote TPM.

3. Detect the cuckoo attack by authenticating the TPM
with a secret random number.

The monitoring system must ensure that the quote orig-
inated from the local TPM, i.e., the TPM that collected in-
tegrity measurements from the software components that
booted the OS on the underlying computer. We propose to
extend the agent with the functionality of checking that it
communicates with the local TPM. The general idea con-
sists of sharing a randomly generated secret φ with the
local TPM to identify it uniquely and then use the secret
to authenticate the TPM (Figure 5). The main challenge
is generating a secret and sharing it with the local TPM
without revealing it to an adversary. The main challenge
is how to generate a secret and share it with the local TPM
without revealing it to the adversary. Otherwise, the ad-
versary can mount the cuckoo attack by sharing it with a
remote TPM.

4. Protect the secret in the TPM by relying on the one-
way cryptographic hash function.

The TPM contains dedicated memory registers, called
platform conﬁguration registers (PCRs), that have im-
portant properties; they cannot be written directly, but
they can only be extended with a new value using a
cryptographic one-way hash function. The operation
can be expressed as: PCR_extend(n,value): pcr[n] =

5

nodenotifyaggregator (e.g., a database)driverTPM. . . veriﬁcationpulltrustedinitially untrusted  (subject to attest.)security 
oﬃcerdata/communication ﬂowIMAagentεnodedriverTPMIMAagentnodedriverTPMIMAagentεsecurity-sensitive software’ε’’εFigure 5: Defense against the cuckoo attack. The agent
shares with the TPM a randomly generated secret φ,
which is used later to authenticate the TPM. PCR is the
TPM tamper-resistant memory.

6. Leverage Intel SGX to transfer the golden TPM PCR
value to the OS runtime securely.

Once the secret is shared with the TPM, we must expose
the unique local TPM’s identiﬁer (PCR value extended
with the secret) to the agent running in the OS. To do so,
we leverage Intel software guard extensions (SGX) [18], a
hardware CPU extension that provides conﬁdentiality and
integrity guarantees to the code executed in so-called en-
claves in the presence of an adversary with root access to
the computer. It offers a sealing [3] property that permits
storing a secret on an untrusted disk where only the same
enclave running on the same CPU can read it. The seal-
ing and its revert operation unsealing use a CPU- and an
enclave-speciﬁc key to encrypt and sign data in untrusted
storage. We propose to communicate with the TPM from
the inside of an enclave. First, the enclave executes in
the initramfs where it shares a secret with the local TPM
and seals the expected value of the TPM PCR to the disk.
Then, it executes in the untrusted OS, where it authen-
ticates the TPM using the PCR value unsealed from the
disk.

Figure 6: SYNERGÍA architecture. The agent provides
access to integrity measurements certiﬁed by the local
TPM after mitigating the cuckoo attack. High-assurance
security system ε and the monitoring controller query the
agent to verify the computer geolocation and operating
system integrity.
agents.

8. Formally prove the protocol of establishing trust be-
tween the agent and the TPM.

We use formal veriﬁcation techniques to prove that the
SYNERGÍA protocol is resilient against the cuckoo attack
because functional software testing cannot detect protocol
errors since they only appear in the presence of a mali-
cious adversary. We rely on automated security protocol
veriﬁcation approaches [47, 11, 5] because they can pro-
vide guarantees of the protocol’s correctness [6, 12, 52].
Speciﬁcally, we use SAPIC [47] tool to implement a for-
mal model of the SYNERGÍA protocol, verify its integrity,
and prove that it is resilient against the cuckoo attack
(§7.4).

4 SYNERGÍA architecture

7. Leverage the SGX local and remote attestation to ex-
pose integrity measurements to the veriﬁers.

4.1 High-level Overview

SGX offers local and remote attestation protocols [41].
While both protocols allow verifying that the expected
code runs on a genuine Intel CPU, the SGX local attes-
tation also permits two enclaves to learn that they execute
on the same CPU. We rely on this property to permit high-
assurance security systems to establish trust with the agent
running on the same computer. Like this, high-assurance
security systems gain access to integrity measurements of
the surrounding OS. Similarly, central monitoring services
leverage the SGX remote attestation to establish trust with

Figure 6 shows a high-level overview of the SYNERGÍA
architecture, which consists of ﬁve entities. A security of-
ﬁcer ((cid:202)) uses a controller ((cid:203)) to deﬁne security policies
describing correct (trusted) OS conﬁgurations. The con-
troller communicates with agents ((cid:204)) running on every
computer to check whether high-assurance security sys-
tems ((cid:205)) are executed in a trusted environment deﬁned in
security policies. Both the controller ((cid:203)) and the high-
assurance security system executing inside SGX ((cid:205)) sys-
tematically query the agent to check if the operating sys-
tem integrity conforms to the criteria deﬁned inside a se-

6

initramfsoperating systemﬁrmwarei-1ﬁrmwareiboot orderTPMtrusted  (DRTM)initially untrusted  (subject to attest.)secure bootPCRs=ℏ(ℏ(ℏ(ℏ(…)||σi)||σbl)||ϕ)σblagentSGXPCRs=ℏ(…∥ϕ)?ℏσtrusted (SGX)ϕ    agentSGXsecret ϕTPM driverbootloaderσiDRTM launchcommunication with a TPMTPM  driverhash functionσstore meas- urementoperating system      monitoring controller. . . high-assurance security system εSGX enclaveagentSGXdeploy policy & periodically check ittrusted (root of trust)trusted
(SGX)security 
oﬃcerdata ﬂowproximity veriﬁcation     trusted beacon125SGXIMATPMnotify4initially untrusted (subject of attest.)operating systemhigh-assurance security system ’εSGX enclaveagentSGXIMATPM334curity policy. Note that the integrity measurements are not
aggregated or veriﬁed centrally. Instead, agents aggregate
them and verify them locally on computers. Agents verify
their location using trusted beacons ((cid:206)), services running
in a known geographical location, i.e., speciﬁc DCs.

We distinguish between two types of veriﬁers commu-
nicating with agents, local and remote veriﬁers. A local
veriﬁer is a high-assurance security system that requires
strong conﬁdentiality guarantees ((cid:205)). An example of such
a service is a key management system [15, 48, 30] that ex-
ecutes inside an SGX enclave to protect integrity and con-
ﬁdentiality against privileged adversaries. The local veri-
ﬁer detects violations of the operating system integrity by
communicating with the agent running on the same host.
A remote veriﬁer, e.g., ((cid:203)), is an application running
on a different computer than the agent.
It aims to ver-
ify that the remote computer is located in the speciﬁc DC
and its OS is in the expected state. Typically, a remote
veriﬁer checks the integrity of the distributed system’s de-
ployment, i.e., various services distributed over machines,
data centers, and availability zones. The controller has
broader knowledge about the network load, machine fail-
ures, service migrations, software updates. It helps the se-
curity ofﬁcer to manage the deployment while relying on
individual services to react autonomously to integrity vio-
lations. The controller might be part of the security infor-
mation and event management (SIEM) system that corre-
lates system behavior to detect multi-faceted attacks [10].

4.2 Policy

The security ofﬁcer deﬁnes security policies (e.g., List-
ing 1) to declaratively state what software and dynamic
libraries are permitted to run on the computer and what
is the proper OS conﬁguration. He creates distinct secu-
rity policies for each high-assurance security system. For
example, a key management system has a different pol-
icy than a system processing medical data because they
use different dynamic libraries, software, and OS conﬁg-
urations. The monitoring controller reduces the burden of
creating policies by allowing deﬁning templates that can
be combined to build individual policies with overlapping
conﬁgurations. For example, services running on the same
type of OS share the same template that describes software
and conﬁguration speciﬁc to that OS.

The agent uses the security policy to verify the OS in-

Listing 1: Policy example

-----BEGIN CERTIFICATE-----
# TPM manufacturer certificates
-----END CERTIFICATE-----

1 chain: |-
2
3
4
5 whitelist:
-pcrs:
6
7 # secure boot / measured boot, PCRs 0-9
-{id: 0, sha256: ff0c...e3}
8
-{id: 3, sha256: e850...3e}
9
10 # trusted boot (DRTM) PCRs, 17-19
-{id: 18, sha256: f9d0...cb}
11
-{id: 19, sha256: a1e7...00}
12
13 runtime:
14
15
16

-----BEGIN CERTIFICATE-----
# IMA uses a certificate to verify

certificate: |-

↳ signatures

software:

whitelist:

-name: AppArmour

-name: agent-0.8.0

840f...72: /bin/agent

-----END CERTIFICATE-----

17
18
19
20
21
22
whitelist:
23
24 # hash of the executable
25
26 # hash of the configuration file
c39e...34: /etc/apparmour
27
28 location:
29
30
31
32
33

max_latency: 2 # in milliseconds
chain: |-

1e73...f6: /sbin/apparmour

-host: https://datacenter:10000/beacon

-----BEGIN CERTIFICATE-----
# TLS certificate chain of the trusted

↳ beacon

34

-----END CERTIFICATE-----

7

tains the asymmetric keypair with a certiﬁcate issued by
a trusted authority, e.g., a DC owner. These credentials,
known only to the trusted beacon, prove that the DC owner
placed the trusted beacon in the DC, and the trusted bea-
con executes in a trusted environment. The agent estab-
lishes trust with the trusted beacon by reading timestamps
signed by the trusted beacon. The agent then estimates
the network latency by calculating a trimmed mean from
the differences between timestamps obtained from pairs
of consecutive requests. A trimmed mean allows for tol-
erating network latency ﬂuctuations because it excludes
outliers.

Our design does not restrict what security mechanisms
must protect the trusted beacon. In particular, the trusted
beacon could be a network-accessible hardware security
module (HSM) [34] returning signed timestamps. HSM
is a crypto coprocessor offering the highest level of secu-
rity against software and hardware attacks. It is embedded
in a tamper responsive enclosure to actively detect physi-
cal and hardware attacks and protect against side-channel
attacks. A cheaper but less secure alternative might run a
TEE-based application implementing the abovementioned
protocol over TLS. Related work [21] demonstrated that
the network communication round-trip time between two
SGX enclaves located in the same network take in aver-
age 264 µs, a latency not achievable from the outside of
the data center.

4.4 Policy Veriﬁcation Protocol

We designed the agent to act as a facade between the ver-
iﬁer and the TPM to enable multiple veriﬁers to check the
OS integrity concurrently. Figure 8 shows how a veriﬁer
uses the policy veriﬁcation protocol to attest to the OS in-
tegrity. The agent regularly reads the list of new software
loaded by the OS, the quote, and persists it into the cache
that reduces the policy veriﬁcation latency for future re-
quests ((cid:202)). The local or remote veriﬁer perform the SGX
local or remote attestation [41] to verify the agent’s iden-
tity and integrity and the CPU genuineness. The local at-
testation also proves that the agent runs on the same CPU
((cid:203)). Once the veriﬁer deploys the policy ((cid:204)), the agent
checks that the computer complies with the policy, stores
the policy, and returns the corresponding policy_id ((cid:205)).
The veriﬁer uses the policy_id to re-evaluate the policy
during future health checks ((cid:206)).

Figure 7: Trusted beacons. Agents rely on the trusted
beacon to check that they are located in the expected data
center. Only machines located inside the same data cen-
ters can achieve very low network latency required to
prove their proximity.
tegrity. The OS is trusted if and only if the load-time in-
tegrity measurements of the kernel and the load-time in-
tegrity measurements of ﬁles loaded to the memory dur-
ing the OS runtime are declared on the whitelist or their
corresponding digital signatures are veriﬁable using the
certiﬁcate declared in the policy.

In more detail, the agent uses the TPM manufacturer’s
CA certiﬁcate chain to verify that the TPM chip attached
to the computer is legitimate (line 1). The integrity of
ﬁrmware and its conﬁguration is represented as a whitelist
of static PCRs (lines 8-9), while the integrity of the Linux
kernel and the initramfs is speciﬁed as a whitelist of dy-
namic PCRs (lines 11-12). Trusted conﬁguration ﬁles, ex-
ecutables, and dynamic libraries are deﬁned in the form
of hashes (lines 18-27) and a signing certiﬁcate (line 14).
Software updates are supported via complementary solu-
tions [62, 9] and require speciﬁcation of the certiﬁcate in
the policy (line 14).

4.3 Trusted Beacon

A policy might constrain the computers’ proximity to the
well-known trusted beacons deployed in DCs (lines 29-
34). A trusted beacon is a network service that responds
to agents’ requests with the current timestamp. The agent
can then estimate the physical machine’s proximity by
measuring the network communication’s round-trip times.
The adversary cannot accelerate network packets enough
to achieve a very short round-trip time achievable only be-
tween machines in the same local network.

Figure 7 shows a high-level view of the trusted beacon
proximity veriﬁcation protocol. The trusted beacon con-

8

computertrusted SGXuntrusted OSagentphysical isolationtrusted beaconΔcommunication latencycomputeragenttendΔ≤λinside data center
 latency≤λoutside data center latency>λnetwork communicationasymmetric keys and certiﬁcateΔ>λSGXΔ=tstart−tendSGXdelaytstart…tendtstart…t1t2t3t4t5t6trustedtablish a trusted environment. The tboot measures the in-
tegrity of the Linux kernel and initramfs, extends these
measurements to dynamic PCRs ((cid:204)), and executes them
((cid:205)).

The initramfs has two essential properties;

its in-
tegrity is reﬂected in dynamic PCRs, and failures during
initramfs execution prevent machine booting. We rely on
these properties to verify that the agent completed its exe-
cution. We refer to the agent execution inside initramfs as
agent initialization ((cid:206)).

During the agent initialization, the agent requests the
TPM to create a new attestation key (AIK), return the
TPM’s endorsement key (EK) certiﬁcate, and return
the quote certifying PCRs ((cid:207)). The agent performs
the activation of credential procedure ([8] p.
109-111) to verify that the AIK was created by the TPM,
which possesses the private key associated with the EK
certiﬁcate. The agent then obfuscates static PCRs by
extending them with a random number generated inside
the SGX enclave ((cid:208)). To ensure that the obfuscation
succeeded and the boot process to continue, the agent
reads PCRs again and compares them to the expected pre-
computed hashes. After all, the AIK, the EK certiﬁcate,
the TPM clock (includes computer reboot counter), and
PCRs (original and obfuscated) are persisted in the ﬁle
system in the SGX sealed conﬁguration ﬁle ((cid:209)). The
initramfs handles control to the OS ((cid:210)), after the agent
initialization ﬁnishes. The OS executes the agent together
with startup services. We refer to the agent execution after
the OS executes as agent runtime.

5.2 Establish Trust

During the agent runtime, the agent veriﬁes that there was
no cuckoo attack during agent initialization and agent run-
time by ensuring that the following conditions are ful-
ﬁlled:

Condition 1: the agent is able to unseal the conﬁgura-
tion ﬁle ((cid:211)). Relying on the properties of the SGX unseal,
we conclude that the conﬁguration ﬁle was created by the
agent enclave running the same binary, and both enclaves
were executed on the same SGX processor.

Condition 2: a successful match between dynamic
PCRs read from the TPM and the golden dynamic PCRs.
It proves that during agent initialization, the agent enclave
was executed in the trusted environment (Linux kernel,

Figure 8: SYNERGÍA policy veriﬁcation protocol. The
agent maintains a separate thread (agent’s cache) to con-
stantly read the platform’s fresh integrity measurements.
Veriﬁers query the agent in parallel to ensure the compli-
ance of the platform to the policy.
Implementation
5

We implemented SYNERGÍA on top of the Linux kernel.
We use existing integrity enforcement mechanisms built in
the Linux kernel, i.e., IMA-appraisal, kernel module sig-
nature veriﬁcation, and AppArmor. We rely on the support
for the secure boot built-in the underlying ﬁrmware. We
developed remote attestation components, i.e., the agent in
memory-safe language Rust [54] and the monitoring con-
troller in Python. We implemented the cuckoo attack de-
tection mechanism and the policy veriﬁcation protocol in-
side the agent. The monitoring controller allows deﬁning
policies, verifying the remote computer system’s integrity,
and alerting about integrity violations. We rely on the
SCONE framework [7] and the SCONE cross-compiler
to run SYNERGÍA inside the SGX enclave.

5.1 Computer bootstrap

Figure 9 illustrates the bootstrap of a computer where the
agent collects information required to detect the cuckoo
attack. Consecutive uniﬁed extensible ﬁrmware interface
(UEFI) components execute in the chain of trust; their
integrity measurements are extended in static PCRs ((cid:202)).
UEFI loads the bootloader, which starts the tboot ((cid:203)). The
tboot leverages Intel trusted execution technology (TXT)
[29, 39]–which implements DRTM on Intel CPUs–to es-

9

establish trust   agent  2SGX attestation34deploy policyverify  policyintegrity measurements1verify policyverify policy   agent's cacheread measurements5TPM + IMAintegrity measurementsintegrity measurementsintegrity measurements  veriﬁer (e.g., )εPOST /policyHTTP 200 ”ok”{policy_id}GET /policy/{policy_id}policypolicyread measurementstime linecommunication  ﬂowtrusted components (measured boot + IMA + DRTM)trusted components (SGX)SGXSGXSGXretrieves the quote and opens the IMA log ﬁle skipping B
bytes. It then reads a new event from the ﬁle and recal-
culates the integrity hash by extending D with the event’s
hash. This process is repeated for each new event and ﬁn-
ishes when the integrity hash is equal to the hash of the
IMA PCR retrieved from the quote. If the agent reaches
the end of the IMA log and the integrity hash does not
match the hash in the IMA PCR, it detects the tampering
of the IMA log and the OS is considered compromised.

5.4 Policy Veriﬁcation

The agent exposes the policy veriﬁcation functionality
via a TLS-protected representational state transfer (REST)
application programming interface (API) endpoint to sim-
plify the communication interface between veriﬁers and
agents. It is enough for veriﬁers to check the agent’s iden-
tity by verifying its X.509 certiﬁcate presented during a
TLS-handshake. Currently, TLS credentials are delivered
to the agent via a key management system (KMS) [30]
but the veriﬁer can also rely on the SGX remote attesta-
tion [41] to ensure the agent’s identity and integrity. As fu-
ture work, the agent will create a self-signed certiﬁcate via
sgx-ra-tls [45], thus excluding the KMS from the trusted
computing base.

The agent stores a once deployed policy in the in-
memory key-value map under a randomly generated key
policy_id to permit tenants to verify the same policy again.
The agent can be queried with the policy_id to verify that
the OS integrity has not changed since the last veriﬁca-
tion. An adversary cannot change once deployed policy
because SGX protects the agent’s memory from tamper-
ing, i.e., SGX guarantees integrity, conﬁdentiality, and
freshness of data.

6 Security Risk Assessment

SYNERGÍA combines different security techniques to
build a framework providing technical assurance that ap-
plications execute inside TEE on the trustworthy OS.
However, each technique operates under a different threat
model, and a careful analysis of existing attacks is re-
quired to claim security guarantees.

Figure 9: The platform boot process. To make the cuckoo
attack detectable, the agent executes twice. First, in agent
initialization, the agent executes in the measured environ-
ment where it shares a secret with the TPM. Second, in
agent runtime, the agent establishes trust with the local
TPM or detects the cuckoo attack.
initramfs, and correct TPM driver), and it successfully ob-
fuscated the TPM.

Condition 3: a successful match of static PCRs read
from the TPM with obfuscated static PCRs read from the
conﬁguration ﬁle. It proves that the conﬁguration ﬁle con-
tains the information gathered earlier from the same TPM.
Condition 4: a successful match of the reboots counter
stored in the conﬁguration with the reboots counter value
read from the fresh quote proves that the computer did not
reboot since the agent initialization.

Finally, considering conditions 1, 2, 3, 4, and what they
indicate once fulﬁlled, we conclude that the quote was is-
sued by the TPM that collected software measurements
during the computer bootstrap. §7.4 formally proves this
claim.

5.3 Cache Updates

To decrease the policy veriﬁcation latency, the agent starts
a separate thread reading the computer state to validate
it against future policy veriﬁcation requests. The agent
recurrently retrieves the quote and veriﬁes that the quote
certiﬁes PCRs values read during the agent initialization,
and it repeatedly reads new events from the IMA log.

Hashes of all events are stored in the enclave’s memory,
together with the number of bytes read (B), and the last
value of IMA PCR (D). To read new events, the agent ﬁrst

10

agent runtimeOSHDDSGX enclaveSGX seal conﬁg ﬁleSGX unseal
conﬁg.ﬁle4259boot  executiondata  ﬂowTPMsubject of attestation secure/measured boot + IMA + TXTtrusted  (SGX)untrusted108extend static PCRs    tboot    TXT3extends 
dynamic PCRs6extends static PCRs with random number7UEFIbootloaderboot ROMTPM attestationagent initializationSGX enclaveinitramfs16.1 Preventing Physical and Hardware Attacks

because they are common industry practices.

First of all, the applied techniques usually do not protect
against hardware and physical attacks. The TPM is vul-
nerable to simple hardware attacks on the communication
bus with the CPU that allows an adversary to reset the
TPM [42], reply to arbitrary measurements [71], including
measurements corresponding to the DRTM launch [84].
Similarly, Intel SGX is vulnerable to clock speed and volt-
age manipulation [59]. Direct memory access attacks [53]
or cold-boot attacks [32] can compromise the entire oper-
ating system and applications that store data in the main
memory in plaintext. To prevent these kinds of attacks,
we propose to attest to the physical location of the com-
puter. Regulators require that DCs are access controlled
and place computers inside security cages [26]. We argue
that these techniques provide enough security to consider
physical and hardware attacks inside the trusted data cen-
ter negligible.

We use the concept of a trusted beacon to verify that the
computer is located in the trusted DC. In real-world, the
trusted beacon functionality could be provided by a hard-
ware security module [34] or a trusted timestamping au-
thority running on a computer with formally proved soft-
ware [44, 65]. The only assumption is that trusted bea-
cons must be securely placed inside the DC and then be
protected from being moved.

6.2 Establishing Trust with the Agent.

To verify that the computer is indeed located in the ex-
pected DC, we must rely on the agent executing on a po-
tentially untrusted computer exposed to physical and hard-
ware attacks. To authenticate the agent and verify that it
executes on a genuine Intel SGX CPU, we leverage Intel
SGX remote attestation [41]. In the past, researchers man-
aged to extract Intel SGX attestation keys [80, 79] that al-
lowed impersonating a genuine SGX CPU. The available
mitigations are: i) relying on on-premise data center at-
testation mechanism [67], ii) checking for revoked SGX
attestation keys, and iii) verifying that the agent runs in
the proximity of a trusted device to ensure that it is in
the correct data center composed of legitimate SGX ma-
chines [21]. In all cases, we must trust the CPU manu-
facturer, SGX design, cryptographic primitives, and CPU
implementation. We consider these assumptions practical

6.3 Establishing Trust with the TPM.

SYNERGÍA relies on TXT, SGX, and TPM to detect the
cuckoo attack. Researchers demonstrated that malware
placed in the system management mode (SMM) could sur-
vive the TXT late launch [85]. To mitigate attacks on
SMM, Intel introduced an SMI transfer monitor that con-
strains the system management interrupt handler mitigat-
ing these class of attacks entirely. Other TXT-related and
tboot vulnerabilities [86] were related to memory vulner-
abilities in Intel’s ﬁrmware and tboot implementations.

Intel SGX is vulnerable to microarchitectural and side-
channel attacks that violate SGX conﬁdentiality guaran-
tees [79]. Intel constantly patches the vulnerabilities with
microcode updates or hardware changes. Nonetheless, we
do consider these attacks as a real threat because of their
severity and the multitude of variants that appear.

These attacks do not impact SYNERGÍA guarantees be-
cause they only affect SGX conﬁdentiality and not in-
tegrity. The only security-sensitive data that might be used
to compromise SYNERGÍA is the secret shared between
the agent and the TPM. However, the secret lives only
during the agent initialization, where the presence of mal-
ware is detected. In more detail, an adversary can extract
the secret shared between the agent and the TPM during
the agent initialization to mount the cuckoo attack by shar-
ing the secret with an arbitrary TPM. We formally proved
(§7.4) that the SYNERGÍA protocol is immune to these
kinds of attacks because the agent detects that the secret
was leaked once it executes in agent runtime. The agent
detects that malware was present during the agent initial-
ization because both initramfs and kernel are measured by
DRTM, and their measurements are securely transferred
to the agent in agent runtime via SGX sealing. An adver-
sary cannot tamper with the sealed data because only the
same enclave running on the same CPU can seal and un-
seal the data. Thus, the presence of malware and secret
leakage are revealed.

6.4 Establishing Trust with the OS.

Because the agent can read the load time integrity of the
kernel stored inside the dynamic PCR in the TPM, it can
ensure that the computer executes a kernel that was in-

11

tended to load because even if an adversary boots a mali-
cious kernel, she cannot tamper with PCRs that reﬂect the
malicious kernel load.

An adversary who gains access to the computer by
stealing credentials using social engineering or exploiting
a misconﬁguration cannot run arbitrary software because
she does not have the signing key to issue a certiﬁcate re-
quired by the integrity-enforcement mechanisms (IMA) to
authorize the ﬁle.

However, an adversary might exploit memory vulnera-
bilities in the existing code, such as Linux kernel or soft-
ware executing on the system remotely [14]. This is fea-
sible because most system software is implemented in un-
safe memory languages. We assume that the operating
system owner relies on an additional security mechanism
enumerated in §2 to enforce the runtime process integrity.
Typically, the system owner also minimizes the trusted
computing base (TCB) by authorizing only crucial soft-
ware to run on a computer. He does it by digitally signing
only trusted software and relying on the IMA-appraisal to
enforce it during the OS runtime.

An adversary who gains access to the computer can
restart it and disable the security mechanisms or boot the
computer into an untrusted state. In §7.2, we estimate the
vulnerability window size in which the monitoring con-
troller detects the computer integrity violation.

Another attack vectors are network side-channel at-
tacks, such as NetCAT [49], and rowhammer attacks over
the network [73]. In these attacks, an adversary does not
have to run malware on the computer but instead sends
malicious network packages that modern network cards
place directly in the main memory. We assign a low risk to
these classes of attacks because i) they are hard to perform
in noisy production environment, ii) they are detectable
by network trafﬁc monitoring tools and ﬁrewalls because
they generate high network activity, iii) mitigation tech-
niques exist and can be applied independently [49, 73].

7 Evaluation

We evaluate SYNERGÍA in four-folds. In §7.1, we demon-
strate SYNERGÍA protecting a real-world application from
the eHealth domain. Then, in §7.2 and §7.3, we evalu-
ate SYNERGÍA’ security and performance, respectively.
Finally, in §7.4 we present the formal veriﬁcation of the

cuckoo attack detection protocol.

Testbed. Experiments execute on a rack-based clus-
ter of three Dell PowerEdge R330 servers connected
via a 10 Gb Ethernet. Each server is equipped with
an Intel Xeon E3-1270 v5 CPU, 64 GiB of RAM, Inﬁ-
neon 9665 TPM 2.0, running Ubuntu 16.04 LTS with ker-
nel Linux kernel v4.4.0-135-generic. The CPUs are on the
microcode patch level (0xc6). The enclave page cache
(EPC) is conﬁgured to reserve 128 MiB of RAM. During
all experiments, the agent, the monitoring controller, and
the trusted beacon run on different machines.

7.1 Protecting a Real-world eHealth Application

We leveraged SYNERGÍA to protect an eHealth applica-
tion provided to us by a partner who requires protec-
tion of his intellectual property (the application’s source
code) and the conﬁdentiality of the privacy-sensitive pa-
tients’ data. This dataset contains concentrations of 112
metabolites in cerebrospinal ﬂuid samples from patients
with bacterial meningitis, viral meningitis/encephalitis,
and non-inﬂamed controls. The application, implemented
in Python, uses a machine learning (ML) algorithm to un-
derstand pathophysiological networks and mechanisms as
well as to identify disease-speciﬁc pathways that could
serve as targets for host-directed treatments to reduce end-
organ damage. We used publicly available SCONE docker
images [68] to run the application inside a container exe-
cuted inside the SGX enclave. We conﬁgured the OS to
use IMA and run the SYNERGÍA’s agent. On two other
machines, we deployed the trusted beacon and the moni-
toring controller, which was constantly querying the agent
Table 1: The execution time of the eHealth application.
Mean values calculated from 30 independent application
executions. The standard deviation in all variants was
1 sec.

Execution time
Security level
- tolerate rogue operator
- tolerate untrusted OS
- side-channel attacks
- data processed in
correct geolocation

native
41 sec

SCONE SYNERGÍA
52 sec

53 sec

(cid:55)
(cid:55)
(cid:55)

(cid:55)

(cid:51)
(cid:51)
(cid:55)

(cid:55)

(cid:51)
(cid:51)
(cid:51)

(cid:51)

12

to verify the OS integrity.

We measured the execution time of the machine learn-
ing algorithm run in three different variants; in native,
the application executes in the untrusted OS; in SCONE,
the application executes in the untrusted OS but inside
an SGX enclave provided by SCONE; in SYNERGÍA,
the application executes inside the SGX enclave on an
integrity-enforced OS booted with SYNERGÍA. Table 1
shows that the machine learning algorithm’s execution in-
side the SGX enclave takes 52 sec, which was 1.3× longer
than the native execution (41 sec). SYNERGÍA further in-
creased the application execution time by 2%, compared
to the SGX enclave execution. This is an acceptable per-
formance overhead, assuming the higher security guaran-
tees offered by SYNERGÍA and the compliance with the
privacy regulations required by the EU law.

7.2 Security

An adversary cannot violate the computer system’s in-
tegrity if all integrity enforcement mechanisms are prop-
erly conﬁgured and enabled (including mechanisms pro-
tecting runtime process integrity §2) because the ker-
nel rejects untrusted ﬁles from loading to the memory.
However, an adversary can run arbitrary software if she
gets enough privileges to boot the computer with dis-
abled enforcement mechanisms. We run a set of micro-
benchmarks to estimate the vulnerability window size ex-
pressed with Equation (1), during which the integrity vio-
lation remains undetected.

tvw = trq + 2 ∗ (ntre + tvp)

(1)

tvw is the vulnerability window size, trq is the time to read
a TPM quote, n is the maximum number of events that can
be opened within trq, tre is the time to read a single event
from the IMA log, tvp is the time required by the agent
to verify the policy and by a veriﬁer to send, receive, and
process the veriﬁcation request.

What is the latency of reading a TPM quote? Each
time the agent reads the IMA log, it reads a fresh TPM
quote to verify the IMA log’s integrity. The TPM sup-
ports different signing schemes that have a direct impact
on the TPM quote read latency. Table 2 shows that TPM
issues a quote using hash-based message authentication
code (HMAC) in 107 ms, which is 4.9× faster than when

using Rivest–Shamir–Adleman (RSA) cryptography and
1.4× faster when using elliptic curve digital signature al-
gorithm (ECDSA). Thus, selecting an HMAC or ECDSA
allows validating the IMA log’s integrity faster than when
using RSA. We assume usage of the ECDSA when read-
ing a quote, thus trq=155 ms.

What is the latency of reading integrity measure-
ments? We measured the latency of reading new mea-
surements from the IMA log to learn how fast the agent
can detect the integrity violation. During the ﬁrst read of
the IMA log, the agent reads all measurements collected
by IMA during the OS boot, which is typically the biggest
chunk of the IMA log that has to be read by the agent at
once. The bootstrap of Ubuntu Linux produces approx-
imately 1800 measurements. The agent needs 130 ms to
read all events from the IMA log, recalculate the IMA log
integrity hash, and compare the hash to the IMA PCR.

After the initial IMA log read, the agent reads only the
new IMA measurements since the last IMA log read. The
time needed to read the integrity measurements depends
on the number of new events measured and added to the
IMA log. Table 3 shows that the agent requires 34 µs and
58 µs to retrieve a single ImaNg and ImaSig event, respec-
tively. The ImaNg, a default IMA event format providing
the ﬁle’s integrity hash. The ImaSig event entry extends
the ImaNg format by also including the ﬁle’s signature.
So, the maximum event read time tre=58 µs.
Table 2: The latency of reading the TPM quote generated
using different signing schemes. Mean values calculated
from 30 experiment executions. σ stands for standard de-
viation.

Signing scheme
RSA 2048 with SHA-256
ECDSA P256 with SHA-256
HMAC with SHA-256

TPM quote read latency
521 ms (σ = 4 ms)
155 ms (σ = 2 ms)
107 ms (σ = 3 ms)

Table 3: The latency of reading a single event from the
IMA log. Mean values calculated from 1200 events read-
ings. σ stands for standard deviation.

ImaNg event
ImaSig event

Read latency of a single IMA log entry
34 µs (σ = 28 µs)
58 µs (σ = 32 µs)

13

mum throughput of 623 req/sec when verifying a default
policy. A similar throughput is achieved for the policy
with the location proximity extension. The throughput
decreases to 521 req/sec when the agent veriﬁes a secu-
rity policy containing IMA measurements because of the
overhead caused by reading new IMA measurements. An
optimal latency of 100 ms is achieved for all policy vari-
ants when the throughput < 250 req/sec.

How does SYNERGÍA performance compare to the ex-
isting monitoring frameworks? We measured the in-
tegrity veriﬁcation latency of the existing integrity mon-
itoring frameworks to check if the presented framework
can be considered practical in terms of performance.
Speciﬁcally, we compared SYNERGÍA with Intel open
cloud integrity technology (Intel CIT) [37, 36], and IBM
TPM attestation client-server (IBM ACS) [35], which is a
sample code for a Trusted Computer Group (TCG) attes-
tation application. We measured the total time taken to es-
tablish a connection with an agent, retrieve a fresh quote,
and compare PCRs with a whitelist. In all experiments,
the TPM has been previously commissioned. Table 4
shows that SYNERGÍA with the mean latency of 665 ms
outperforms Intel CIT by 3.7× and IBM ACS by 8.5×.
SYNERGÍA achieves better performance because, during
the initialization, it caches AIK, static PCRs, and dynamic
PCRs that do not change during the entire agent’s life cy-
cle. The agent veriﬁes that those values did not change by
comparing them to the certiﬁed values obtained from the
quote. Furthermore, unlike others, the agent veriﬁes the
integrity of the IMA log and PCRs by recomputing a hash
over cached PCRs and IMA log and matching it against
the PCRs hash in the quote. It allows the agent to skip the
slow process of reading PCRs and, consequently, reduce
communication with the TPM to a single recurrent quote
read operation.
Table 4: The mean remote attestation latency compari-
son between different integrity monitoring frameworks. In
all systems, the TPM quote was signed with RSA signing
scheme. se stands for standard error.

SYNERGÍA
Intel CIT
IBM ACS

Remote attestation latency
665 ms (se=2 ms)
2475 ms (se=5 ms)
5677 ms (se=22 ms)

Figure 10: Policy veriﬁcation throughput. Default policy
checks secure boot and trusted boot. Location proximity
checks geolocation. Runtime veriﬁes IMA measurements.
How much time does it take to detect the integrity vi-
olation? The vulnerability window for the attack consists
of the time the agent takes to read a fresh quote, retrieve
new events from the IMA log, and process the policy ver-
iﬁcation request. We assume that when the agent reads
a quote (trq), an adversary can cause IMA to open no
more than n=3875 ﬁles (according to our measures, open-
ing a ﬁle takes at least 40 µs). The agent would require
about n∗tre=225 ms to read events, and about tvp=100 ms
to verify them against the policy, see §7.3. Therefore,
using Equation (1), we estimate that the policy veriﬁca-
tion protocol has a vulnerability window of approximately
tvw=805 ms.

7.3 Performance

How scalable is SYNERGÍA? Can it efﬁciently verify
policies on behalf of multiple veriﬁers? In our design,
the agent is the security-critical component that performs
local integrity attestation on behalf of high-assurance se-
curity systems, centralized monitoring services, and secu-
rity ofﬁcers. To verify the agent’s ability to verify security
policies, we measured the policy veriﬁcation throughput
– the time in which the agent responds to the veriﬁer’s
request verifying OS integrity. Our experiments compare
four variants of the policy content: i) default, the policy
contains only the deﬁnition of static and dynamic PCRs;
ii) location proximity, the default policy content with ad-
ditional constraints about proximity to trusted beacon; iii)
runtime, the default policy content with a whitelist of
trusted software; iv) runtime and location proximity, the
combination of the runtime and location proximity poli-
cies. Figure 10 shows that the agent achieves the maxi-

14

 0 200 400 600 800 1000 0 100 200 300 400 500 600Latency [ms]Throughput [req/s]defaultlocation proximityruntimeruntime and location prox.the userspace takes 13 sec and the kernel with initramfs
remaining 6 sec.
tboot executes after the bootloader and
before the initramfs, thus not inﬂuencing the load time of
the OS. The activation of IMA conﬁgured to measure all
ﬁles deﬁned by the TCG group (ima_tcb boot option), in-
creases the boot time to 158 sec, 8.3× of the native. A
load of userspace takes 84% of this time, which is caused
by the measurement of 1790 ﬁles. The boot time could
be decreased by reducing the number of services loaded
by the OS. SYNERGÍA increases the boot time by 58%
compared to the Ubuntu Linux with tboot and 8% com-
pared to the Ubuntu Linux with IMA. The increased boot
time is mostly caused by the execution of time-consuming
TPM operations in initramfs performed by SYNERGÍA
and IMA.

7.4 Formal Analysis

We propose the PCR obfuscation as a resilience mecha-
nism against the cuckoo attack. To prove this claim, we
formally veriﬁed the protocol’s integrity without/with ob-
fuscation using the SAPIC tool [47]. SAPIC allows to
model security protocols in a variant of applied pi cal-
culus [58] that handles parallel processes with a non-
monotonic global state needed for a security API such as a
TPM. The protocol model describes the actions of agents
participating in the protocol, the adversary’s speciﬁcation,
and the desired security properties. The adversary and the
protocol interact by sending/receiving messages through
the network, which changes the system state and creates
traces of state transitions. Security properties are mod-
eled as trace properties, checked against traces of the tran-
sition system, or as an observational equivalence of two
transition systems. While the adversary tries to violate
the security properties, she is limited by the constraints
of cryptographic primitives. The SAPIC tool uses con-
straint solving to perform an exhaustive, symbolic search
for executions with satisfying traces. Since the correctness
of security protocols is an undecidable problem, the tool
may not terminate on a given veriﬁcation problem. If it
terminates, it returns either proof that the protocol fulﬁlls
the security property or a counterexample representing an
attack that violates the stated property.

Model overview. Listing 2 shows a high-level overview
It has three processes: Golden,
model of the protocol.
TPM, and Machine (line 9). The TPM and Machine pro-

Figure 11: Impact of SYNERGÍA on boot time.
How much time does it take to deploy a single security
policy?

Table 5 shows the latency of the policy deployment pro-
tocol using different policy extensions. The latency is
measured as the total time between establishing a trans-
port layer security (TLS) connection with SYNERGÍA, a
policy upload, a veriﬁcation using a fresh quote, and a re-
sponse retrieval. The default policy’s size, containing the
whitelist of 13 PCRs and one TPM manufacturer’s CA
certiﬁcate, is 4.7 kB. Its deployment takes 576 ms. The
runtime policy size, containing the whitelist of 1790 ﬁles
and an IMA signing certiﬁcate, is 235 kB (50× the de-
fault policy). Its deployment lasts 606 ms, which is only a
1.05× of the default policy deployment latency. The de-
ployment latency of a policy with the location proximity
extension depends on the communication latency between
SYNERGÍA and trusted beacons. The deployment of the
policy with one trusted beacon located in the same data
center takes 626 ms.

How does SYNERGÍA impact the boot time of a com-
puter? We used the systemd-analyze tool to measure the
load time of initramfs and userspace in different conﬁg-
uration variants of Ubuntu. Figure 11 shows that the na-
tive Ubuntu Linux starts in 19 sec, from which the load of
Table 5: The latency of the policy deployment into the
agent depending on the content of the security policy.
Mean values calculated from 600 independent policy de-
ployments. σ stands for standard deviation.

Security policy content
Static and dynamic PCRs
+ location proximity
+ IMA measurements
+ location prox. and IMA measur.

Deployment latency
576 ms (σ = 15 ms)
626 ms (σ = 17 ms)
606 ms (σ = 16 ms)
677 ms (σ = 15 ms)

15

020406080100120140initramfsuserspace2.7x 4.1x 5.8x 10.2x 10.3x Boot time (s)Ubuntu Linux+tboot+tboot +agent+tboot +IMA+tboot +IMA +agentcesses execute in parallel without limiting the number of
instances.

Listing 2: The protocol model without PCR obfuscation
1 /* ||: parallel process, !: replicated process
2 in(msg), out(msg): send/receive message
3 pk(priv): public key of key priv
4 hash(value): one-way hash function
5 <v1,v2,..>: concatenate values
6 sign(value, key): signs values with key
7 verify(value, key): checks the value's signature

↳ using key

8 senc(value, key): symmetric encryption of value

↳ using key */

9 Protocol = Golden; (!TPM ||!Machine)

48

49

50

51

52

53
54

TPM = TPM_local;

// trusted, connect to

↳ local TPM

else TPM=in(TPM_remote);//malicious, connect to

↳ remote TPM

<sPCR, dPCR, nonce> = in(quote, AIK_pub(TPM));

↳ // read quote of the connected TPM

verify(quote, AIK_pub(TPM)); // check the

↳ signature

seal_value = senc(<sPCR, dPCR, AIK_pub(TPM)>,
↳ seal_key); // machine specific CPU seal
↳ key

seal_to_disk(Machine,seal_value);
agent_runtime

56 agent_runtime = // might be malicious
<sPCR1,dPCR1,AIK_pub(TPM_sealed)> =
57

↳ unseal_from_disk(Machine,seal_value);

11 Golden =

// golden hashes are made available to

↳ the network

12
13
14

15

16
17

new CA_priv;
out(CA_pub = pk(CA_priv)); //asymm. key pair
new UEFI_golden; out(sign(UEFI_golden,

↳ CA_priv));

new tboot_golden; out(sign(tboot_golden,

↳ CA_priv));

new initramfs_golden; out(initramfs_golden);
new kernel_golden; out(kernel_golden)

58
59

60
61
62
63

64

new nonce; out(nonce);
<sPCR2, dPCR2, nonce> = in(quote,

↳ AIK_pub(TPM_sealed));

verify(quote,AIK_pub(TPM_sealed));
if equal(sPCR1,sPCR_golden,sPCR2) AND
equal (dPCR1,dPCR_golden,dPCR2)
// trigger event (TPM quote represents local

↳ machine state)

then event MachineTrusted(TPM_sealed,

↳ TPM_local);

19 TPM =
20
21
22

//creates new TPM, quote can be acquired

new TPM; new AIK_priv;
sPCR_extend(TPM, sPCR); dPCR_extend(TPM, dPCR);
out(TPM, AIK_pub = pk(AIK_priv)); //public key

↳ available

23

!create_TPM_quote //replicated

25 create_TPM_quote =
26
27
28
29

in(nonce); //prevents replay attacks
<sPCR,dPCR> = read_local_pcr(TPM);
quote = sign(<sPCR,dPCR,nonce>,AIK_priv)
out(quote, AIK_pub) // signed quote checked

↳ with AIK_pub

31 Machine =
32

//creates new machine

new Machine; new seal_key;// machine's CPU seal

↳ key

//attach a specific TPM to this specific machine
in(TPM_local); // connect to a TPM
in(UEFI_signed); verify(UEFI_signed, CA_pub);

↳ //trusted

sPCR_extend(TPM_local, hash(UEFI_signed));//

↳ static PCR

in(tboot_signed);verify(tboot_signed,CA_pub);//trusted

↳

in(initramfs); in(kernel); // might be malicious
extend_with = hash(<tboot_signed, initramfs,

↳ kernel>)

dPCR_extend(TPM_local, extend_with);// dynamic

↳ PCR

agent_initialization

43 agent_initialization = // might be malicious
44
45
46
47

new nonce; out(nonce);
//Golden initramfs contains a driver that
//guarantees communication with the local TPM
if initramfs = initramfs_golden then

33
34
35

36

37

38
39

40

41

The Golden process (lines 11-17) constructs a trusted
image that complies with the required policy. It makes the
image available for other processes and the adversary via
the public network. A trusted authority keeps a private key
(CA_priv) secure while the public part (CA_pub) is made
available to the public network (line 13). The handles
of the UEFI and the tboot (UEFI_golden, tboot_golden)
are signed with the private key of the trusted authority to
mimic that hardware enforces the boot of the correct soft-
ware only. The handles of all boot components are avail-
able to the public network. The TPM process (lines 19-
29) models a TPM chip with static (sPCR) and dynamic
It creates a signed quote using a TPM-
(dPCR) PCRs.
speciﬁc private key (AIK_priv) repeatedly (lines 25-29).

The Machine process models provisioning of a physical
machine (lines 31-64) that has a genuine TPM chip, and a
TXT- and SGX-capable CPU. The boot consists of three
steps.

Step 1, the Machine process gets handles of the (trusted)
signed tboot, the unsigned initramfs, and the unsigned
kernel. It extends dynamic PCRs with measurements of
the initramfs and kernel (lines 37-40). Due to the local-
ity protection, only processes in this step are allowed to
extend dynamic PCRs. Therefore, PCRs of the attached
TPM reﬂect measurements of the loaded execution envi-
ronment. So far, the adversary has no control over the

16

Listing 3: Security property

Listing 4: The protocol model with PCR obfuscation

1 // Security property -integrity:
2 // the checked state and the local state should

30 Machine = //creates new machine
31

new RND; ...

↳ match

3 All x y #i. MachineTrusted(x,y)@i ⇒ x=y

machine (lines 37-40).

Step 2, agent initialization executes the already mea-
sured and loaded initramfs (lines 43-54). Through the
previously measured TPM driver, it requests to contact the
TPM. If the TPM driver is malicious, the adversary might
provide an AIK_pub of the remote TPM (line 49) instead
of the locally attached one (line 48). Next, agent initial-
ization reads the quote signed with the TPM private key
(AIK_priv). The quote is veriﬁed using AIK_pub. The
AIK public key and PCRs are sealed to the disk using the
local CPU’s SGX sealing key (lines 52-53).

Step 3, the OS and the TPM driver are untrusted. The
OS takes over the control, the TPM driver is loaded, and
the agent runtime is executed (lines 56-64). After unseal-
ing from the disk (line 57), agent runtime reads the quote
through the untrusted TPM driver. The quote is veriﬁed
with the unsealed attestation public key (line 60). Finally,
agent runtime reports that the execution environment com-
plies with the policy (line 64) if-and-only-if the unsealed
PCRs and the quote PCRs both match the golden PCRs
values (lines 61-62).

Security property.
The integrity of the protocol is
speciﬁed as "if the TPM quote read by agent runtime
matches the unsealed information, its execution environ-
ment MUST correspond to the matched values". Listing 3
states this property.

SAPIC tool reported a violation to the given property
when using the protocol speciﬁed in Listing 2. The trace
describes that the adversary owns two machines: provi-
sioned (Mp) and oracle (Mo), connected to T PMp and
T PMo, respectively. Mp runs a malicious initramfs and
OS (sPCR_golden, dPCR_malicious), but uses a genuine
hardware (TPM and CPU). The adversary wants to verify
it as a trustworthy machine. To do so, she forwards the
requests to the other machine Mo, which runs a trustwor-
thy environment with untampered software and genuine
hardware (sPCR_golden, dPCR_golden). Note that for-
warding read requests to Mo does not require a change
to its environment; however, the adversary cannot ex-
tend PCRs of T PMo attached to Mo without changing
initramfs and OS, which consequently would change the

new nonce1; out(nonce1);
if initramfs = initramfs_golden then

42 agent_initialization =
43
44
45
46
47
48

TPM = TPM_local; // connect to local TPM

else TPM = TPM_remote; // connect to remote TPM
<sPCR, dPCR, nonce1> = in(quote, AIK_pub(TPM));
verify(quote, AIK_pub(TPM)); // check the

↳ signature

49

50

51

52

53
54

55
56

sPCR_extend(TPM, RND)); // share the secret

↳ with TPM

new nonce2; out(nonce2);//read again to ensure

↳ sPCR extended

<sPCR_obf, dPCR, nonce2> = in(quote,

↳ AIK_pub(TPM));

verify(quote, AIK_pub(TPM)); // check the

↳ signature

if sPCR_obf = hash(<sPCR, RND>) then
seal_value = senc(<sPCR, sPCR_obf, dPCR,

↳ AIK_pub(TPM)>, seal_key);

seal_to_disk(Machine,seal_value);
agent_runtime

58 agent_runtime =
59

<sPCR1,sPCR1_obf,dPCR1,AIK_pub(TPM_sealed)> =

↳ unseal_from_disk(Machine,seal_value);

60
61

62
63
64
65
66

67

new nonce; out(nonce);
<sPCR2_obf,dPCR2,nonce> =

↳ in(quote,AIK_pub(TPM_sealed));

verify(quote,AIK_pub(TPM_sealed));
if equal(dPCR1,dPCR_golden,dPCR2) AND

equal(sPCR1_obf,sPCR2_obf) AND
equal(sPCR1,sPCR_golden)
// trigger event (TPM quote represents local

↳ machine state)

then event MachineTrusted(TPM_sealed,

↳ TPM_local);

corresponding dPCR in T PMo. During agent initializa-
tion, the malicious initramfs in Mp forwards the attesta-
tion request to Mo, which responds with a signed quote
from T PMo that has the PCRs_golden and can be veri-
ﬁed using AIK_pub(T PMo). PCR values and AIK_pub
keys are sealed using seal_key of Mp. During agent run-
time, Mp unseals the values from the disk and contacts
T PMo through the malicious OS to get the quote. The
quote contains PCRs that match both the golden and the
sealed PCRs. So, the event (line 64) is triggered with un-
equal TPM_sealed (T PMo) and TPM_local (T PMp),
which indicates the cuckoo attack. The vulnerability ex-
ists because TPM attestation does not guarantee that the
received credentials (AIK_pub) belong to the attested ma-
chine.

Model extension. Listing 4 shows the extended model

17

of the protocol to implement the PCR obfuscation. It re-
quired the following changes: i) Generation of a random
number (RND) (line 31); ii) PCRs obfuscation: the static
PCRs are extended with the RND (lines 49-52); iii) agent
initialization seals both the original and obfuscated PCRs
(lines 53-55); iv) agent runtime declares a machine trusted
if-and-only-if: a) the dynamic PCRs golden, sealed and
read from the quote match, b) the obfuscated static PCRs
sealed and read from quote match, and c) the original
static PCRs golden and sealed match (lines 63-67).

We checked the model extended with the obfuscation
(Listing 4) against the integrity property in Listing 3.
SAPIC tool terminated and reported that all traces of the
protocol preserve the given property. The modiﬁcation to
the model, where the agent initialization enclave shares a
secret with the TPM potentially belonging to the attested
machine, overcomes the previously described vulnerabil-
ity.

8 Related work

Like the existing monitoring systems [37, 35], SYNERGÍA
relies on the TPM attestation protocol to verify the com-
puter’s integrity. Unlike them, SYNERGÍA is resilient
to the cuckoo attack. Existing defenses against this at-
tack have a limited application for high-assurance secu-
rity systems. Fink et al. proposed a time side-channel
approach [24] to detect the cuckoo attack. As conﬁrmed
by the authors, it is prone to false positives and requires
stable measurement conditions, an impractical assump-
tion in real-world scenarios. Flicker [57] accesses local
TPM from the isolated execution environment established
by DRTM. However, DRTM does not attest to the com-
puter location which makes its attestation untrustworthy
due to simple hardware attacks [83]. Moreover, DRTM
permits executing only a single process on the entire CPU
at the same time. This impacts application’s throughput
because a single context switch to DRTM-established en-
vironment takes 10-100s of milliseconds [56]. SYNERGÍA
instead ﬁrst veriﬁes that the computer is in the trusted data
center (thus, no hardware attacks are possible) and uses
DRTM only once when provisioning the TPM. This ap-
proach provides better performance as required by mod-
ern applications.

Other solutions for root of trust identiﬁcation problem

require the veriﬁer to solve biometric challenge [20], ob-
serving emmited LED signals [72], verifying the device
state displayed on the screen [19, 50], using trusted de-
vices to scan bar codes sealed on the device [55], or press-
ing a special-purpose button for bootstrapping trust during
the computer boot [63]. These approaches have limita-
tions because i) the TPM is a passive device controlled by
software which, due to lack of trusted I/O paths to exter-
nal devices, can redirect, reply, or fool the communica-
tion, and ii) they require human interaction and thus do
not scale for the DC-level.

Recently, Dhar et al. proposed ProximiTEE [21] to deal
with the SGX (not TPM) cuckoo attack by attaching a
trusted device to the computer and detecting the cuckoo
attack during the SGX attestation. This solution can ver-
ify that the SGX enclave executes on the computer with
the attached trusted device because of the very low com-
munication latency between the enclave and the device.
Although, as denoted by Parno [63] this approach cannot
be used to detect the TPM cuckoo attack because of the
slow speed of the TPM, SYNERGÍA could use Proximi-
TEE as a trusted beacon implementation to prove that the
computer is located in the expected data center.

Other work focuses on tolerating malware in the OS
while preventing side-channel attacks on TEEs. There are
three approaches to mitigate these attacks: i) static vulner-
ability detection [31, 61], ii) attack prevention [1, 13, 25],
and iii) attack detection [60, 17]. The ﬁrst one consists
of analyzing and modifying source code to detect gad-
gets [31, 61]. However, ﬁnding all gadgets is difﬁcult or
impossible because the search narrows to gadgets speciﬁc
to known attacks. The second approach prevents attacks
by hiding access patterns using oblivious execution/access
pattern obfuscation, resource isolation [25], or hardware
changes [81]. These techniques address only speciﬁc at-
tacks [25], require hardware changes [81], or incur large
performance overhead [1, 13]. The last approach consists
of runtime attack detection [60, 17] by isolating and moni-
toring resources of instrumented programs. But, it targets
selected attacks and assumes some amount of statistical
misses. SYNERGÍA aims at preventing such attacks with-
out requiring source code changes or hardware modiﬁca-
tions, with low performance overhead but a larger trusted
computing base.

18

9 Conclusion

We responded to regulatory demands that require stronger
isolation of high-assurance security systems by running
them inside trusted execution environments on top of a
trustworthy operating system and in the expected geoloca-
tion. We demonstrated that the combination of Intel SGX
with TPM-based solutions meets such requirements but
requires protection against the cuckoo attack. We pro-
posed a novel deterministic defense mechanism against
the cuckoo attack and formally proved it. We imple-
mented a framework that monitors and enforces the in-
tegrity as well as geolocation of computers running high-
assurance security systems and mitigates the cuckoo at-
tack. Our evaluation and security risk assessment show
that the SYNERGÍA is practical.

References

[1] Adil Ahmad, Byunggill Joe, Yuan Xiao, Yinqian
Zhang, Insik Shin, and Byoungyoung Lee. Obfus-
curo: A commodity obfuscation engine on intel sgx.
In Network and Distributed System Security Sympo-
sium, 2019.

[2] Alpine Linux Development Team. Alpine Linux -
Small. Simple. Secure. https://alpinelinux.org/about/,
accessed on July, 2021.

[3] Ittai Anati, Shay Gueron, Simon Johnson, and Vin-
cent Scarlata. Innovative technology for cpu based
attestation and sealing. In Proceedings of the 2nd in-
ternational workshop on hardware and architectural
support for security and privacy, volume 13, page 7.
ACM New York, NY, USA, 2013.

[4] ARM Limited. Building a secure system using trust-

zone technology. White paper, 2009.

[5] A. Armando, D. Basin, Y. Boichut, Y. Chevalier,
L. Compagna, J. Cuellar, P. Hankes Drielsma, P. C.
Heám, O. Kouchnarenko, J. Mantovani, S. Möder-
sheim, D. von Oheimb, M. Rusinowitch, J. Santiago,
M. Turuani, L. Viganò, and L. Vigneron. The avispa
tool for the automated validation of internet security
protocols and applications. In Kousha Etessami and
Sriram K. Rajamani, editors, Computer Aided Veri-
ﬁcation, pages 281–285, Berlin, Heidelberg, 2005.

[6] Alessandro Armando, Roberto Carbone, Luca Com-
pagna, Jorge Cuellar, and Llanos Tobarra. Formal
Analysis of SAML 2.0 Web Browser Single Sign-
on: Breaking the SAML-based Single Sign-on for
Google Apps. In Proceedings of the 6th ACM Work-
shop on Formal Methods in Security Engineering,
FMSE ’08, pages 1–10, New York, NY, USA, 2008.

[7] Sergei Arnautov, Bohdan Trach, Franz Gregor,
Thomas Knauth, Andre Martin, Christian Priebe,
Joshua Lind, Divya Muthukumaran, Dan O’Keeffe,
Mark Stillwell, David Goltzsche, Dave Eyers, Rüdi-
ger Kapitza, Peter Pietzuch, and Christof Fetzer.
SCONE: Secure linux containers with Intel SGX. In
12th USENIX Symposium on Operating Systems De-
sign and Implementation (OSDI 16), pages 689–703,
2016.

[8] Will Arthur and David Challener. A practical guide
to TPM 2.0: Using the new trusted platform module
in the new age of security. Springer Nature, 2015.

[9] Stefan Berger, Mehmet Kayaalp, Dimitrios Pen-
darakis, and Mimi Zohar. File Signatures Needed!
Linux Plumbers Conference, 2016.

[10] Sandeep Bhatt, Pratyusa K. Manadhata, and Loai
Zomlot. The operational role of security informa-
tion and event management systems. IEEE Security
and Privacy (S&P), 12(5):35–41, 2014.

[11] B. Blanchet. An efﬁcient cryptographic protocol ver-
In Proceedings of the
iﬁer based on prolog rules.
14th IEEE Computer Security Foundations Work-
shop, pages 82–96, 2001.

19

[12] Matteo Bortolozzo, Matteo Centenaro, Riccardo Fo-
cardi, and raham. Attacking and ﬁxing pkcs#11 se-
curity tokens. In Proceedings of the 17th ACM Con-
ference on Computer and Communications Security,
CCS ’10, 2010.

[13] Ferdinand Brasser, Srdjan Capkun, Alexandra
Dmitrienko, Tommaso Frassetto, Kari Kostiainen,
and Ahmad-Reza Sadeghi. Dr. sgx: Automated and
adjustable side-channel protection for sgx using data
location randomization. In Proceedings of the 35th
Annual Computer Security Applications Conference,
pages 788–800, 2019.

[14] Marco Carvalho, Jared DeMott, Richard Ford, and
David A Wheeler. Heartbleed 101. IEEE security &
privacy, 12(4):63–67, 2014.

[15] Somnath Chakrabarti, Brandon Baker, and Mona
Vij. Intel SGX Enabled Key Manager Service with
OpenStack Barbican. arXiv e-prints, 2017.

[16] Dhiman Chakraborty, Lucjan Hanzlik, and Sven
Bugiel.
simtpm: User-centric TPM for mobile
In 28th USENIX Security Symposium
devices.
(USENIX Security 19), pages 533–550. USENIX
Association, 2019.

[17] Guoxing Chen, Wenhao Wang, Tianyu Chen,
Sanchuan Chen, Yinqian Zhang, XiaoFeng Wang,
Ten-Hwang Lai, and Dongdai Lin. Racing in hy-
perspace: Closing hyper-threading side channels on
sgx with contrived data races. In 2018 IEEE Sympo-
sium on Security and Privacy (SP), pages 178–194.
IEEE, 2018.

[18] Victor Costan and Srinivas Devadas.

Intel sgx ex-
IACR Cryptol. ePrint Arch., 2016(86):1–

plained.
118, 2016.

[19] Janis Danisevskis, Michael Peter, Jan Nordholz,
Matthias Petschick, and Julian Vetter. Graphical user
interface for virtualized mobile handsets. IEEE S&P
MoST, 2015.

[20] Ivan De Oliveira Nunes, Xuhua Ding, and Gene
Tsudik. On the root of trust identiﬁcation problem.
In Proceedings of the 20th International Conference
on Information Processing in Sensor Networks (Co-
Located with CPS-IoT Week 2021), page 315–327,
2021.

[21] Aritra Dhar, Ivan Puddu, Kari Kostiainen, and Srd-
jan Capkun. Proximitee: Hardened sgx attestation
In Proceedings of the
by proximity veriﬁcation.
Tenth ACM Conference on Data and Application Se-
curity and Privacy, CODASPY ’20, 2020.

[22] Danny Dolev and Andrew Yao. On the security of
IEEE Transactions on infor-

public key protocols.
mation theory, 29(2):198–208, 1983.

[23] Eperi. Top tier bank and conﬁdential computing.
https://www.intel.com/content/www/us/en/customer-
spotlight/stories/eperi-sgx-customer-story.html,
cessed on July, 2021.

ac-

[24] Russell A Fink, Alan T Sherman, Alexander O
Mitchell, and David C Challener. Catching the
cuckoo: Verifying tpm proximity using a quote tim-
In International Conference on
ing side-channel.
Trust and Trustworthy Computing, pages 294–301.
Springer, 2011.

[25] Qian Ge, Yuval Yarom, Tom Chothia, and Gernot
Heiser. Time protection: The missing os abstraction.
In Proceedings of the Fourteenth EuroSys Confer-
ence 2019, EuroSys ’19, New York, NY, USA, 2019.
Association for Computing Machinery.

[26] Gematik GmbH. Systemspeziﬁsches Konzept ePA.
https://www.vesta-gematik.de/standard/formhandler/
324/gemSysL_ePA_V1_3_0.pdf.

[27] Gematik GmbH.

Systemspeziﬁsches Konzept
E-Rezept.
https://www.vesta-gematik.de/standard/
formhandler/324/gemSysL_eRp_V1_0_0_CC6.pdf, ac-
cessed on July, 2021.

[28] Virgil Gligor and Maverick Woo. Establishing soft-
ware root of trust unconditionally. In Network and
Distributed Systems Security (NDSS 2019), 2019.

20

[29] James Greene.

Intel trusted execution technology:
Hardware-based technology for enhancing server
Intel Corporation, Copyright,
platform security.
2012(8), 2010.

[30] Franz Gregor, Wojciech Ozga, Sebastien Vaucher,
Rafael Pires, Do Le Quoc, Sergei Arnautov, An-
dre Martin, Valerio Schiavoni, Pascal Felber, and
Christof Fetzer. Trust management as a service:
Enabling trusted execution in the face of byzantine
In 2020 50th Annual IEEE/IFIP In-
stakeholders.
ternational Conference on Dependable Systems and
Networks (DSN), pages 502–514. IEEE, 2020.

[31] Marco Guarnieri, Boris Köpf, José F Morales, Jan
Reineke, and Andrés Sánchez. Spectector: prin-
cipled detection of speculative information ﬂows.
In 2020 IEEE Symposium on Security and Privacy
(SP), pages 1–19. IEEE, 2020.

[32] J Alex Halderman, Seth D Schoen, Nadia Heninger,
William Clarkson, William Paul, Joseph A Calan-
drino, Ariel J Feldman, Jacob Appelbaum, and Ed-
ward W Felten. Lest we remember: cold-boot at-
tacks on encryption keys. Communications of the
ACM, 52(5):91–98, 2009.

[33] Serge Hallyn, Dmitry Kasatkin, David Safford,
Linux Integrity
Reiner Sailer, and M Zohar.
Measurement Architecture (IMA)
IMA ap-
praisal. https://sourceforge.net/p/linux-ima/wiki/Home/
#ima-appraisal, accessed on July, 2021.

-

[34] IBM. IBM CEX7S / 4769 PCIe Cryptographic Co-
processor (HSM). IBM 4769 Data Sheet, 2019.

[35] IBM Corporation.

IBM TPM Attestation Client
https://sourceforge.net/projects/ibmtpm20acs/,

Server.
accessed on July, 2021.

[36] Intel. Intel Security Libraries for Data Center. https:

//01.org/intel-secl, accessed on July, 2021.

[37] Intel and National Security Agency.

Intel Open
Cloud Intergrity Technology. https://01.org/opencit,
accessed on July, 2021.

[38] Intel Corporation. Trusted Boot (tboot).

https://
sourceforge.net/projects/tboot/, accessed on July, 2021.

[39] Intel Corportation.

Intel

techonology–software development guide,
sion 017.0, 2008.

trusted execution
revi-

[40] Ramya Jayaram Masti, Claudio Marforio, and Srd-
jan Capkun. An architecture for concurrent execu-
tion of secure environments in clouds. In Proceed-
ings of the 2013 ACM workshop on Cloud computing
security workshop, pages 11–22, 2013.

[41] Simon Johnson, Vinnie Scarlata, Carlos Rozas,
Ernie Brickell, and Frank Mckeen. Intel® software
guard extensions: Epid provisioning and attestation
services. White Paper, 1(1-10):119, 2016.

[42] Bernhard Kauer. OSLO: Improving the security of

Trusted Computing. USENIX, 2007.

[43] Mustakimur Rahman Khandaker, Wenqing Liu, Abu
Naser, Zhi Wang, and Jie Yang. Origin-sensitive
In 28th USENIX Security
control ﬂow integrity.
Symposium (USENIX Security 19), pages 195–211,
Santa Clara, CA, August 2019. USENIX Associa-
tion.

[44] Gerwin Klein, Michael Norrish, Thomas Sewell,
Harvey Tuch, Simon Winwood, Kevin Elphinstone,
Gernot Heiser, June Andronick, David Cock, Philip
Derrin, Dhammika Elkaduwe, Kai Engelhardt, and
Rafal Kolanski. seL4: formal veriﬁcation of an OS
In Proceedings of the ACM SIGOPS 22nd
kernel.
symposium on Operating systems principles - SOSP
’09, Big Sky, Montana, USA, 2009.

[45] Thomas Knauth, Michael Steiner,

Somnath
Chakrabarti, Li Lei, Cedric Xing, and Mona Vij.
Integrating remote attestation with transport layer
security. arXiv preprint arXiv:1801.05863, 2018.

[46] Kari Kostiainen, Aritra Dhar, and Srdjan Capkun.
Dedicated security chips in the age of secure en-
IEEE Security and Privacy, 18(5):38–46,
claves.
2020.

Kremer

[47] Steve
Sapic:
http://sapic.gforge.inria.fr/, accessed on July, 2021.

and
A stateful

Kuennemann.
calculus.
pi

Robert
applied

21

[48] Ambuj Kumar, Anand Kashyap, Vinay Phegade, and
Jesse Schrater. Self-Defending Key Management
Service with Intel SGX. Fortranix Whitepaper, ac-
cessed on July, 2021.

[49] Michael Kurth, Ben Gras, Dennis Andriesse, Cris-
tiano Giuffrida, Herbert Bos, and Kaveh Razavi.
NetCAT: Practical Cache Attacks from the Network.
In 2020 IEEE Symposium on Security and Privacy
(SP), pages 20–38. IEEE, 2020.

[50] Matthias Lange and Steffen Liebergeld. Crossover:
secure and usable user interface for mobile devices
with multiple isolated os personalities. In Proceed-
ings of the 29th Annual Computer Security Applica-
tions Conference, pages 249–257, 2013.

[56] Jonathan M McCune, Yanlin Li, Ning Qu, Zongwei
Zhou, Anupam Datta, Virgil Gligor, and Adrian Per-
rig. Trustvisor: Efﬁcient tcb reduction and attesta-
tion. In 2010 IEEE Symposium on Security and Pri-
vacy, pages 143–158. IEEE, 2010.

[57] Jonathan M McCune, Bryan J Parno, Adrian Per-
rig, Michael K Reiter, and Hiroshi Isozaki. Flicker:
An execution infrastructure for tcb minimization. In
Proceedings of the 3rd ACM SIGOPS/EuroSys Euro-
pean Conference on Computer Systems 2008, pages
315–328, 2008.

[58] Robin Milner. The pi calculus and its applications. In
Formal Methods for Open Object-based Distributed
Systems, pages 3–4. Springer, 1997.

[51] Dayeol Lee, David Kohlbrenner, Shweta Shinde,
Krste Asanovi´c, and Dawn Song. Keystone: An
open framework for architecting trusted execution
environments. In Proceedings of the Fifteenth Euro-
pean Conference on Computer Systems (EuroSys ´20),
pages 1–16, 2020.

[59] Kit Murdock, David Oswald, Flavio D. Garcia,
Jo Van Bulck, Daniel Gruss, and Frank Piessens.
Plundervolt: Software-based fault injection attacks
against intel sgx. In Proceedings of the 41st IEEE
Symposium on Security and Privacy (S&P’20),
2020.

[52] Gavin Lowe. Breaking and ﬁxing the needham-
schroeder public-key protocol using fdr. In Tiziana
Margaria and Bernhard Steffen, editors, Tools and
Algorithms for the Construction and Analysis of Sys-
tems, 1996.

[53] A. Theodore Markettos, Colin Rothwell, Brett F.
Gutstein, Allison Pearce, Peter G. Neumann, Si-
mon W. Moore, and Robert N. M. Watson. Thunder-
clap: Exploring vulnerabilities in operating system
IOMMU protection via DMA from untrustworthy
peripherals. In 26th Annual Network and Distributed
System Security Symposium, NDSS 2019, San Diego,
California, USA, February 24-27, 2019, 2019.

[54] Nicholas D Matsakis and Felix S Klock. The rust
language. ACM SIGAda Ada Letters, 34(3):103–
104, 2014.

[55] J.M. McCune, A. Perrig, and M.K. Reiter. Seeing-
using camera phones for human-
is-believing:
veriﬁable authentication. In 2005 IEEE Symposium
on Security and Privacy (S&P’05), 2005.

[60] Oleksii Oleksenko, Bohdan Trach, Robert Krahn,
Mark Silberstein, and Christof Fetzer. Varys: Pro-
tecting SGX enclaves from practical side-channel at-
tacks. In 2018 Usenix Annual Technical Conference
(USENIXATC 18), pages 227–240, 2018.

[61] Oleksii Oleksenko, Bohdan Trach, Mark Silberstein,
and Christof Fetzer. Specfuzz: Bringing spectre-
type vulnerabilities to the surface. In 29th USENIX
Security Symposium (USENIX Security 20), pages
1481–1498, 2020.

[62] Wojciech Ozga, Do Le Quoc, and Christof Fetzer. A
practical approach for updating an integrity-enforced
In Proceedings of the 21st In-
operating system.
ternational Middleware Conference, pages 311–325,
2020.

[63] Bryan Parno. Bootstrapping trust in a "trusted" plat-
form. In Proceedings of the 3rd Conference on Hot
Topics in Security, 2008.

[64] Mike Petullo. Encrypt your root ﬁlesystem. Linux

Journal, 2005(129):4, 2005.

22

[65] Jonathan Protzenko, Bryan Parno, Aymeric
Fromherz, Chris Hawblitzel, Marina Polubelova,
Karthikeyan Bhargavan, Benjamin Beurdouche,
Joonwon Choi, Antoine Delignat-Lavaud, Cédric
Fournet, et al. Evercrypt: A fast, veriﬁed, cross-
In 2020 IEEE
platform cryptographic provider.
Symposium on Security and Privacy (SP), pages
983–1002. IEEE, 2020.

[66] Reiner Sailer, Xiaolan Zhang, Trent Jaeger, and
Leendert Van Doorn. Design and implementation
of a tcg-based integrity measurement architecture.
In USENIX Security symposium, volume 13, pages
223–238, 2004.

[67] Vinnie Scarlata, Simon Johnson, James Beaney, and
Piotr Zmijewski. Supporting third party attestation
for intel sgx with intel data center attestation primi-
tives. White paper, 2018.

[73] Andrei Tatar, Radhesh Krishnan Konoth, Elias
Athanasopoulos, Cristiano Giuffrida, Herbert Bos,
and Kaveh Razavi.
Throwhammer: Rowham-
In
mer attacks over the network and defenses.
2018 {USENIX} Annual Technical Conference
({USENIX}{ATC} 18), pages 213–226, 2018.

[74] Trusted Computing Group.

TCG Infrastructure
Working Group Architecture Part II - Integrity Man-
agement, Speciﬁcation Version 1.0, Revision 1.0,
2006.

[75] Trusted Computing Group. TCG PC Client Spe-
ciﬁc Implementation Speciﬁcation for Conventional
BIOS, Speciﬁcation Version 1.21, Revision 1.00,
2012.

[76] Trusted Computing Group. TPM Library Speciﬁca-

tion, Family "2.0", Revision 01.38, 2016.

[68] Scontain UG.

SCONE Docker curated images.
https://hub.docker.com/u/sconecuratedimages, accessed
on July, 2021.

[77] Trusted Computing Group. TCG PC Client Platform
Firmware Proﬁle Speciﬁcation, Family 2.0, Level
00, Revision 1.04, 2019.

[69] Arvind Seshadri, Mark Luk, Elaine Shi, Adrian Per-
rig, Leendert van Doorn, and Pradeep Khosla. Pio-
neer: Verifying code integrity and enforcing untam-
pered code execution on legacy systems. SOSP ’05,
2005.

[70] Jacob Shin, Bill Jacobs, Mark Scott-Nash, Julian
Hammersley, Monty Wiseman, Rob Spiger, Dick
Wilkins, Ralf Findeisen, David Challener, Dalvis
Desselle, Steve Goodman, Gary Simpson, Kirk
Brannock, Amy Nelson, Mark Piwonka, Conan Dai-
ley, and Randy Springﬁeld. TCG D-RTM Architec-
ture, Document Version 1.0.0. Trusted Computing
Group, 2013.

[71] Evan R Sparks. A Security Assessment of Trusted
Platform Modules. Computer Science Technical Re-
port TR2007-597, 2007.

[72] He Sun, Kun Sun, Yuewu Wang, Jiwu Jing, and
Haining Wang. Trustice: Hardware-assisted isolated
computing environments on mobile devices. In 2015
45th Annual IEEE/IFIP International Conference on
Dependable Systems and Networks (DSN ’15), 2015.

[78] Trusted Computing Group. TCG Trusted Attestation
Protocol (TAP) Information Model for TPM Fami-
lies 1.2 and 2.0 and DICE Family 1.0. Version 1.0,
Revision 0.36, 2019.

[79] Jo Van Bulck, Marina Minkin, Oﬁr Weisse, Daniel
Genkin, Baris Kasikci, Frank Piessens, Mark Silber-
stein, Thomas F Wenisch, Yuval Yarom, and Raoul
Strackx. Foreshadow: Extracting the keys to the in-
tel SGX kingdom with transient out-of-order execu-
tion. In 27th USENIX Security Symposium (USENIX
Security 18), pages 991–1008, 2018.

[80] Stephan van Schaik, Andrew Kwong, Daniel
Genkin, and Yuval Yarom. SGAxe: How SGX fails
in practice. https://sgaxeattack.com/, 2020.

[81] Oﬁr Weisse, Ian Neal, Kevin Loughlin, Thomas F.
Wenisch, and Baris Kasikci. Nda: Preventing spec-
ulative execution attacks at their source. In Proceed-
ings of the 52nd Annual IEEE/ACM International
Symposium on Microarchitecture, MICRO ’52, page
572–586, New York, NY, USA, 2019. Association
for Computing Machinery.

23

[82] Richard Wilkins and Brian Richardson. UEFI se-
cure boot in modern computer security solutions. In
UEFI Forum, 2013.

[83] Johannes Winter and Kurt Dietrich. A hijacker’s
guide to communication interfaces of the trusted
platform module. Computers & Mathematics with
Applications, 2013.

[84] Johannes Winter and Kurt Dietrich. A hijacker’s
guide to communication interfaces of the trusted
platform module. Computers & Mathematics with
Applications, 2013.

[85] Rafal Wojtczuk and Joanna Rutkowska. Attacking
In Black Hat

Intel Trusted Execution Technology.
DC, 2009.

[86] Rafal Wojtczuk and Joanna Rutkowska.

At-
tacking Intel TXT via SINIT code execution
hijacking.
https://invisiblethingslab.com/resources/
2011/Attacking_Intel_TXT_via_SINIT_hijacking.pdf,
accessed on July, 2021.

[87] Yuanzhong Xu, Weidong Cui, and Marcus Peinado.
Controlled-channel attacks: Deterministic side
In Pro-
channels for untrusted operating systems.
ceedings of the 2015 IEEE Symposium on Security
and Privacy, SP ’15, page 640–656, USA, 2015.
IEEE Computer Society.

[88] Andreas Zeller, Rahul Gopinath, Marcel Böhme,
Gordon Fraser, and Christian Holler. The fuzzing
book, 2019.

[89] Jean-Karim Zinzindohoué, Karthikeyan Bhargavan,
Jonathan Protzenko, and Benjamin Beurdouche.
Hacl*: A veriﬁed modern cryptographic library. In
Proceedings of the 2017 ACM SIGSAC Conference
on Computer and Communications Security, pages
1789–1806, 2017.

24

