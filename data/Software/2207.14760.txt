SimCURL: Simple Contrastive User Representation
Learning from Command Sequences

Hang Chu1 Amir Hosein Khasahmadi1 Karl D.D. Willis1
Linh Tran1
1Autodesk AI Lab

2Autodesk Research

Justin Matejka2

Yaoli Mao2

Jo Vermeulen2

Fraser Anderson2

{hang.chu,amir.khasahmadi}@autodesk.com

2
2
0
2

l
u
J

9
2

]
I

A
.
s
c
[

1
v
0
6
7
4
1
.
7
0
2
2
:
v
i
X
r
a

Abstract—User modeling is crucial

to understanding user
behavior and essential for improving user experience and person-
alized recommendations. When users interact with software, vast
amounts of command sequences are generated through logging
and analytics systems. These command sequences contain clues
to the users’ goals and intents. However, these data modalities
are highly unstructured and unlabeled, making it difﬁcult for
standard predictive systems to learn from. We propose SimCURL,
a simple yet effective contrastive self-supervised deep learning
framework that learns user representation from unlabeled com-
mand sequences. Our method introduces a user-session network
architecture, as well as session dropout as a novel way of data
augmentation. We train and evaluate our method on a real-world
command sequence dataset of more than half a billion commands.
Our method shows signiﬁcant improvement over existing methods
when the learned representation is transferred to downstream
tasks such as experience and expertise classiﬁcation.

Index Terms—user modeling, self-supervised learning

I. INTRODUCTION

Accurate and robust user modeling has the potential to
improve the user experience in a wide range of applications
such as feature recommendation [18], [32], skill characteriza-
tion [37], and software personalization [28], [36]. Traditional
predictive systems rely on annotated datasets. However, an-
notation is expensive and time-consuming. In contrast, large
amounts of raw command sequences can be passively stored
without requiring human intervention. We refer to a command
sequence as a series of user-software interactions in the form
of when and what commands are used. Vast amounts of com-
mand sequences are generated via logging and analytics sys-
tems when users interact with software products and services,
in both traditional desktop and modern cloud-based settings.
Using these command sequences offers new opportunities for
user modeling by analyzing command sequences.

Despite the availability of large amounts of data, its usability
and application remain limited due to the lack of labels. Fur-
thermore, acquiring labels is often difﬁcult due to three main
obstacles. First, annotating vast volumes of command data is
costly and often impractical. Second, interpreting commands
requires deep domain knowledge, which signiﬁcantly increases
labeling cost. Third, unlike natural language and images, the
deﬁnition of common sense semantic knowledge is unclear
for a command sequence. This causes each downstream user
classiﬁcation task to be separately labeled, with low label re-
usability across different tasks.

Fig. 1. SimCURL learns user representations from a large corpus of unlabeled
command sequences. These learned representations are then transferred to
multiple downstream tasks that have only limited labels available.

Self-supervised learning can be used to remove the depen-
dency on massive amounts of labeled data in the conventional
supervised learning paradigm. It is a great ﬁt for command se-
quence representation learning, because it removes the bottle-
neck of labeled data. The backbone representation model can
be directly trained on existing unlabeled command sequences.
We introduce SimCURL, a Simple Contrastive User Rep-
resentation Learning method that directly learns user em-
beddings from a large set of unlabeled command sequences
(Figure 1). SimCURL takes a set of command sequences as
input, where each command sequence is associated with a
unique user identiﬁer. Each element in the command sequence
consists of a command name and a time tag. SimCURL initially
learns user representation vectors in a self-supervised manner.
Then light-weight transfer learning models are trained with a
small amount of labeled data for the downstream tasks. To the
best of our knowledge, SimCURL is the ﬁrst method to apply
contrastive self-supervised representation learning to software
command sequences. Our contributions are as follows:

• We present a contrastive self-supervised learning method
for learning user representations from unlabeled com-
mand sequences.

• We propose a new user-session neural network archi-
tecture, and a new session dropout data augmentation
scheme to handle command sequences effectively.

• We evaluate our method on a large-scale, real-world
dataset with half billion commands and demonstrate
signiﬁcant improvement over existing methods.

 
 
 
 
 
 
user
session
vocab
command

TABLE I
MAIN STATISTICS OF THE FUSION 360 COMMAND DATASET.
Labeled Subset
12,612
183,794
3,164
58,616,884
Task 2 (expertise)
10
3
10,873

Unlabeled Subset
199,996
1,255,529
3,164
580,028,669
Task 1 (experience)
1
8
8,540

sub-task
class
user

II. RELATED WORK

Self-Supervised Learning: When conventional labels are not
available, self-supervised learning can be used to leverage the
data itself and its underlying structure as the source of the
supervisory signal [16]. It has a long history of successful
deployments in the ﬁeld of natural language processing such
as the seminal work of word2vec [20] and GloVe [22]. Since
the recent advances in training large models like Transform-
ers [29], pre-trained language models such as BERT [6],
RoBERTa [17], and T5 [26] have brought signiﬁcant perfor-
mance gains to a variety of natural language understanding
tasks. The GPT line of work [1], [24], [25] utilizes the causal
relationship of natural language tokens as the self-supervision
objective. It is shown that the learned representation is multi-
task transferable at both few-shot and zero-shot settings.

Self-supervised learning techniques have also been applied
to audio [21], [27], image [2], [10], [12], and various other
modalities [7], [34]. Due to the increasing difﬁculty of repre-
senting uncertainty in the prediction for images than it is for
words [16], contrastive learning has emerged as an alternative
self-supervised learning paradigm. The representation model
is shown two distorted versions (or views) of the same data
sample, and is trained to maximize their agreement. The idea
of learning representations by contrasting positive pairs and
negative pairs dates back to Hadsell at el. [11]. SimCLR [3]
simpliﬁes the contrastive learning process by only using
in-batch negative example sampling without resorting to a
memory bank. SimCSE [8] applies the contrastive learning
approach to natural
language data and generates distorted
views by simply dropping out words. In this work, we take
inspiration from SimCLR [3] and SimCSE [8] due to their sim-
plicity and effectiveness using in-batch negative examples. We
perform data augmentation via the proposed session dropout
technique in Section IV-A .
Sequence Modeling: There is an extensive list of literature
on sequence modeling techniques [4], [14], [23], [29], [30].
In this work, we treat command sessions of the same user
as a temporal sequence and adopt the transformer architec-
ture due to its ability to model long sequences and scale
to large datasets. A particularly relevant topic in sequence
modeling is event modeling [19], where the sequence is not
only temporally ordered, but also has associated time tags at
each step. Session-level modeling is an emerging technique
in user behavior [31] and conversation [33], but has not yet
been applied to command sequence data. The main difference
between event modeling and our work is granularity, i.e., event

modeling focuses on modeling the sequence at event level,
while our emphasis is learning user-level representations.
Command Sequence Modeling: User modeling and person-
alization are becoming the backbone of many software or
social media businesses. Software platforms that record com-
mand sequences from consented users analyze these records
to create user-speciﬁc recommendation and customization.
LogHub [13] provides a collection of automatically generated
logs from various systems and software. However, these com-
mand stream collections are still rather small scale for training
deep learning models. CommunityCommands [18] is amongst
the early studies that tackle the task of recommending useful
commands to the users. They analyzed the data of almost 40
million AutoCAD user command sequences for six months
and proposed a measure coined CF-IUF, which is used for
their collaborative ﬁltering algorithm to provide personalized
command recommendations. In a more recent work [32],
community-generated screen-recording videos are combined
with command sequences to better classify and recommend
software workﬂows. Gao et al. [9] addresses the problem of
command prediction in CAD using transformers trained on
augmented real-world data.

Util2vec [36] presents a method that learns representations
for both users and commands by predicting any command
action given surrounding commands and the context vector of
the user, which is used in user tagging and cold-start recom-
mendation. Along the same line of research, log2int [28] uses
an auxiliary tutorial dataset [35] for semantic encoding of the
command sequences. Log2int introduces a deep sequence-to-
sequence modeling approach to model the long-term temporal
context in the command sequence. Our method differs from
util2vec and log2int in two ways: First, our representation
learning objective is contrastive, instead of sequential mod-
eling. Second, our method is better suited for learning user-
level representations, instead of learning from local command
sequence windows or sessions.

III. DATASET

Fusion 3601 is a commonly used cloud-connected desk-
top software from Autodesk that integrates Computer-Aided
Design (CAD), Computer-Aided Manufacturing (CAM),
Computer-Aided Engineering (CAE), and Printed Circuit
Board (PCB) into one single software platform. The multi-
disciplinary nature and user diversity make Fusion 360 ideal
for showcasing and benchmarking command sequence-based
user representation learning. To fully demonstrate the effec-
tiveness of our self-supervised learning method, the dataset
should satisfy two criteria: First, there should be a large-
scale unlabeled set of raw command sequences. Second, there
should be meaningful user classiﬁcation downstream tasks
with a small set of labels available, on which the learned
representation can be evaluated. We now describe these two
subsets of Unlabeled and Labeled data and provide their main
statistics.

1https://www.autodesk.ca/en/products/fusion-360/overview

Fig. 2. Examples of Fusion 360 command sequence sessions in the dataset. For each example, the left column shows the top-5 most commonly used
commands. The middle column shows the distribution of commands by their category. The right column shows the number of commands and session duration
relatively to the overall dataset distribution, as well as the distribution of time interval between adjacent commands where the histogram bin width is 5 seconds.

A. Unlabeled Subset

We collected command sequences of Fusion 360 users who
have given us consent. We only recorded the name of the
command,
the time tag of each command, as well as an
anonymous unique user identiﬁer. For sophisticated software
like Fusion 360, there are a great variety of commands (3164
unique commands). This means useful insight about the users’
expertise and habits can be inferred based on what types of
commands they use. At the same time, no information on the
geometry or design parameters is collected to preserve the
users’ intellectual property.

We recorded command sequences within a 6 months period
from October 2020 to April 2021. We then randomly selected
a subset of 199,996 users with at least 50 commands and at
least two usage sessions within the 6 month period. Table I
shows the statistics of the unlabeled subset, which is large-
scale, containing more than a million sessions and more than
half a billion commands. Note that the categories are manually
assigned by experts of the software and are only used for
better illustration. Our method is general-purpose and does
not depend on command category as its input. Figure 2 shows
common examples from the unlabeled subset. Note that the
deﬁnition of sessions and how session boundaries are obtained
will be described in the Section IV-A. We observed that
our dataset possesses a broad variety of different command
sessions, e.g., a CAD solid modeling session that mainly
contains solid modeling commands, a documentation session
which involves documenting and viewing commands, or a
mixed generative design and simulation session.

B. Labeled Subset

purpose, we formulate this task as a 8-class classiﬁcation,
where each class represents a number of year ranging from
0 to 7. In the second task, we predict the areas of expertise of
the user. This task contains 10 sub-tasks, each for one area of
expertise, namely modeling, rendering, electronics, manufac-
turing CAM, extended manufacturing, animation, simulation,
data collaboration, drawing, and generative technologies. Each
sub-task is a 3-class classiﬁcation task, indicating either the
user has already used, or has not used, or plan to use the
product features in the corresponding area of expertise. Similar
to the unlabeled subset, we extract command sequences for
users in the labeled subset. Table I lists the main statistics
of the labeled subset. It can be seen that the labeled subset
is approximately one order of magnitude smaller than the
unlabeled subset. Note that because questions in the product
survey are not always required, the number of users for the
two tasks are different because not all survey participants have
answered all questions.

Our selection of the two tasks in the labeled subset rep-
resents both challenging and relatively easy tasks. In Task 1,
the model needs to possess a certain level of understanding
about the user’s proﬁciency, in order to better estimate years
of experience based on only the most recent command stream
records. Task 2 is less challenging than Task 1, because the
types of commonly used commands correlate with a certain
area of expertise. Despite this, it is still non-trivial to predict
whether a user plans to use a new area of the product.

IV. METHOD

To evaluate our model and compare it with other baselines,
we design several tasks that predict Fusion 360 user responses
from a recent survey. The Fusion 360 customer surveys are
conducted annually to understand the product experience and
inform future improvements. The 2020 survey contained 58
questions, covering customers’ product usage, areas and levels
of product expertise, and learning interests. 23,867 customers
participated in the survey and opted in to the usage, processing,
and storage of their data.

We use the data collected from the Fusion 360 customer
survey to build a labeled subset. Speciﬁcally, we take two
questions in the survey to make two user classiﬁcation tasks.
In the ﬁrst task, we predict the user’s years of experience in
Fusion 360. For simplicity and keeping the task setting general

We deﬁne the command sequence dataset as a collection
of user-speciﬁc command sequences U = {ui}, where 1 ≤
i ≤ N with N being the number of users in the dataset. For
the i-th user, the corresponding ui is a command sequence
ui = {(ci,m, ti,m)}, where 1 ≤ m ≤ Mi with Mi denoting
the total number of commands. At each command step m, the
name of the command ci,m and the time tag of the command
execution ti,m are recorded. Note that depending on the task
and data availability, more command features can also be
included besides the command name. In this work, we only use
the categorical ci,m for simplicity without loss of generality.
In the conventional supervised learning setting, each user
is labeled as yi in a given downstream task, and the training
objective function for fully supervised learning can be written

Fig. 3. An overview of the SimCURL method (left) and the user-session network architecture (right). The user’s command sequence ui is ﬁrst divided
into sessions {si,j }, from which two augmented views are generated via session dropout. The views are passed through the main network to obtain the
i and z(cid:48)(cid:48)
representation vectors r(cid:48)
i , on which the contrastive loss is applied. Solid and dashed lines denote
positive and negative pairs, respectively.

i , then the projection head to produce z(cid:48)

i and r(cid:48)(cid:48)

as:

θf = argmin

θf

N
(cid:88)

−

log(cid:0)f (yi|ui) (cid:1)

(1)

i=1
where f is the model that predicts class probabilities given the
user’s command sequence, and θf denotes its trainable param-
eters. In the self-supervised representation learning setting, we
denote U α = {uα
i } as the unlabeled self-supervised learning
subset, and U β = {uβ
i } as the labeled supervised learning
subset labeled as yβ
i , with sizes of N α and N β, respectively.
The self-supervised learning training objective becomes:

θg = argmin

θg

N α
(cid:88)

L(cid:0)g (uα

i ) (cid:1)

(2)

i=1
where g is the main model that produces the representation
vectors. θg denotes its trainable parameters and L is the self-
supervised learning contrastive loss function. After the ﬁrst
stage which trains the main model, the learned representation
is transferred to a downstream task, whose training objective
is:

θf = argmin

θf

−

N β
(cid:88)

i=1

(cid:16)

log

f (cid:0)yβ

i |g(uβ

i )(cid:1)(cid:17)

(3)

which follows the same formulation as the supervised learning
setting, except that users are ﬁrst encoded via g. It should be
noted that there can be multiple downstream tasks. In that case,
a different classiﬁcation model fk is trained for each task, but
the main model g stays the same. We omit the subscript k to
keep the notation simple.

Our proposed method contains three main steps: session
segmentation and data augmentation via session dropout, the
user-session neural network architecture, and the ﬁnal con-
trastive self-supervised representation learning objective. Next,
we describe these main components in detail respectively.

A. Session Dropout

Different from the conventional deﬁnition where a session
can be deﬁned as a segment of commands between a log-
in and a log-out action, we deﬁne a command session as a

contiguous temporal segment of commands. This is out of two
main reasons: First, there may not be clearly deﬁned session
boundary commands in some software. Second, a user could
keep the software running without closing the window for a
long time due to frequent usage. We compute the grouping
of commands into sessions by ﬁrst ﬁnding relative peaks of
command density over time, then clustering commands into
the nearest peak to form the sessions.

Concretely, we ﬁrst discretize the time axis into Q equidis-
tant bins, with the time value at bin centers as {tq} where
1 ≤ q ≤ Q. Then for each bin of the i-th user, we compute
its command execution density di,q as:

di,q =

M
(cid:88)

m=1

(cid:18)

exp

−

(cid:17)(cid:19)

(cid:16) tq − ti,m
σ

(4)

where σ is a constant number that controls the amount of
temporal smoothing. We then ﬁnd the set of local maximum
peaks pi = {pi,j} amongst {di,q} as:

pi = (cid:8)tq

(cid:12)
(cid:12) di,q ≥ di,q+∆, ∀∆ ∈ [−w, w](cid:9)

(5)

where w denotes a constant window size. Finally, the com-
mands are grouped into sessions {si,j} based on their nearest
peaks as:
si,j = (cid:8)(ci,m, ti,m) (cid:12)

(cid:12) |ti,m − pi,j| ≤ |ti,m − pi,x|, ∀pi,x ∈ pi

(cid:9)

(6)

where the number of sessions is equal to the number of peaks,
which we denote as Li. Thus, the original single command
stream is partitioned into sessions of ui = {si,j}, where 1 ≤
j ≤ Li.

The effectiveness of contrastive representation learning
relies on data augmentation techniques that apply random
distortion, but still preserve unique characteristics of the data
point. To achieve this, we simply apply dropout at the session
level. By using session dropout, we can not only produce large
variety of views for a single data point, but also maintain the
completeness of the user’s workﬂow within sessions.

B. User-Session Network

We propose a new user-session network architecture to
encode command stream data effectively. There are three
main factors that motivate our network design: First, despite
recent advancements in sequence modeling techniques, it is
impractical to directly feed the command sequence into the
model because the raw sequence length M is typically long.
This is evident in Table I, where the average length is 2900
for the time span over six months. Also to achieve the goal of
user modeling, it is less important to reason at the command-
level granularity. Second, it is useful to take session-level
information into account. As can be seen in Figure 2 there is
a wide diversity of sessions. Such diversity is also exhibited
within the same user, where different sessions tackle different
projects or different stages of the same project. Therefore, we
set session as the time step unit for our model. Third, we
found it helpful to directly encode user-level information with
a dedicated branch, which aligns with the objective of learning
user-level representations.

The right-hand side of Figure 3 shows the architecture of
our user-session network. For each session si,j, we simply
use a normalized vector of command usage frequency as its
input feature. Similarly, at the user-level we use the overall
command usage frequency vector as the input feature for the
user branch. We use a Transformer network [29] to encode
the sequence of sessions. At each time step, the input feature
vector is ﬁrst passed through a linear layer. Then, it is added
to the position encoding vector that encodes the time step
via a series of sinusoidal functions, and passed through a
stack of multi-head self-attention layers. We also reserve the
ﬁrst time step for a ¡rep¿ token that does not involve any
input session. Since in the Transformer, the query-key-value
computation is conducted on every pairs of time steps, it is
sufﬁcient to directly use the Transformer output at the ﬁrst
time step as the session-level encoding. Finally, we use a
simple Multi-Layer Perceptron (MLP) network to encode the
user-level information, as well as another MLP that combines
the user-level and session-level encodings to produce the user
representation vector ri.

C. Contrastive Loss

SimCURL learns self-supervised user representations by ap-
plying a contrastive loss term on in-batch positive and negative
examples. To achieve this, each user is transformed into two
differently augmented views using session dropout described
above, then fed into the user-session network g. Following
the common practice in contrastive self-supervised learning,
we also use another multi-layer projection head denoted as h
consisting of linear layers. We obtain the ﬁnal vectors as:

(cid:16)

z(cid:48)
i = h

g(cid:0)sd(cid:48)(ui)(cid:1)(cid:17)

(cid:16)

, z(cid:48)(cid:48)

i = h

g(cid:0)sd(cid:48)(cid:48)(ui)(cid:1)(cid:17)

(7)

where sd(cid:48) and sd(cid:48)(cid:48) denotes the session dropout function with
two different random seeds. As depicted in the left-hand side
of Figure 3, the two augmented views of each command
sequence form the positive examples, while all other pairs

(cid:1)(cid:17)

sim(cid:0)z(cid:48)(cid:48)

i(cid:48)(cid:48), z(cid:48)
i
(9)

(10)

form the negative examples. The ﬁnal contrastive loss can be
written as:

L =

B
(cid:88)

i

(cid:0)L(cid:48)

i + L(cid:48)(cid:48)
i

(cid:1)

(8)

L(cid:48)

i = −log

(cid:80)B

i(cid:48)(cid:54)=i exp

(cid:16)

sim(cid:0)z(cid:48)

i(cid:48), z(cid:48)
i

(cid:16)

exp

(cid:1)(cid:17)

sim(cid:0)z(cid:48)
(cid:1)(cid:17)

i, z(cid:48)(cid:48)
i
+ (cid:80)B

(cid:16)
i(cid:48)(cid:48)(cid:54)=i exp

sim(cid:0)z(cid:48)

i, z(cid:48)(cid:48)
i

(cid:1) =

i · z(cid:48)(cid:48)
z(cid:48)
i
i|| ||z(cid:48)(cid:48)
τ ||z(cid:48)
i ||

where B denotes the mini-batch size and indicates the loss is
computed over samples within the same training mini-batches,
sim(·) denotes the cosine similarity function with an extra
constant temperature parameter denoted as τ . L(cid:48)(cid:48) is similarly
deﬁned as L(cid:48) for the second view instead of the ﬁrst view.
Intuitively, the loss function pulls the positive examples closer
while pushing the negative examples further in the latent space.
During training, we randomly sample mini-batches of users,
minimize the loss for the sampled mini-batch, and repeat
this process until convergence is reached. We optimize the
parameters θg and θh for both the main user-session network
g and the projection head h during training, and throw away
h after training is completed.

D. Implementation Details

For session division, we empirically set the temporal quan-
tization level Q as 215, and the temporal smoothing constant
σ as 210. We set the window size for command density peak
detection w as 1. In the contrastive loss, we simply set the
temperature constant τ as 1. We use the ReLU activation
function in the MLP modules and the projection head. 4
attention heads are used in the session Transformer module.
Hidden vector sizes are consistently set as 256 for both ri and
zi. The model is trained with the Adam [15] optimizer on a
Nvidia RTX6000 GPU with a 24G memory for 40 epochs.
After the contrastive self-supervised learning is completed on
the unlabeled subset U α, we train a linear classiﬁer as the
transfer learning model f on top of the user-session network
g whose weights are set frozen. We also apply session dropout
on the users uβ

i during the downstream task training stage.

V. EXPERIMENTS

We show experimental results of the proposed SimCURL
method in this section, and compare them with baselines
as well as methods adapted from previous literature. We
ﬁrst describe our experimental settings, followed by detailed
discussions on the performance comparisons. We split the
unlabeled subset by the number of users at a 8-1-1 ratio into
the training, validation, and testing sets. For the downstream
tasks, we split the data evenly by the number of users at a 1-1-
1 ratio. To evaluate the performance of our proposed method,
we compare against a random baseline as well as six more
sophisticated methods:

TABLE II
MAIN RESULTS USING FULL LABELED SUBSETS. BEST AND SECOND BEST RESULTS ARE HIGHLIGHTED IN GREEN AND BLUE.

Task 1 (experience)

Task 2 (expertise)

Acc./%
13.29 ± 0.92
28.14 ± 0.71
31.50 ± 0.11
31.90 ± 0.13
33.44 ± 1.20
25.68 ± 0.53
31.78 ± 0.63
37.39 ± 0.41

F1/%
14.50 ± 0.49
27.40 ± 0.74
19.17 ± 0.30
29.05 ± 1.26
30.81 ± 0.86
24.55 ± 0.53
29.54 ± 0.17
35.24 ± 0.68

Acc./%
33.17 ± 0.16
57.62 ± 0.15
67.67 ± 0.01
65.82 ± 0.65
67.81 ± 0.20
64.52 ± 0.26
64.82 ± 0.20
68.67 ± 0.08

F1/%
38.32 ± 0.04
56.98 ± 0.51
55.98 ± 0.02
58.71 ± 0.11
58.70 ± 0.70
57.45 ± 0.90
58.64 ± 0.31
60.26 ± 0.07

Acc./%
23.23 ± 0.54
42.88 ± 0.32
49.58 ± 0.05
48.86 ± 0.30
50.62 ± 0.52
45.10 ± 0.36
48.30 ± 0.22
53.03 ± 0.22

Overall

F1/%
26.41 ± 0.26
42.19 ± 0.41
37.58 ± 0.15
43.88 ± 0.68
44.76 ± 0.55
41.00 ± 0.25
44.09 ± 0.16
47.75 ± 0.37

random
BoW
CF-IUF [18]
SeqAE [5]
GPT [24]
util2vec [36]
log2int [28]
ours

ROC-AUC

TABLE III
FEW-SHOT LEARNING THAT TRAINS WITH ONLY 6.25% LABELS. BEST AND SECOND BEST RESULTS ARE HIGHLIGHTED IN GREEN AND BLUE.

Task 1 (experience)

Task 2 (expertise)

Acc./%
12.16 ± 0.09
25.12 ± 0.67
29.09 ± 1.77
28.11 ± 1.48
28.81 ± 1.09
14.54 ± 0.78
25.21 ± 4.42
33.32 ± 0.67

F1/%
14.67 ± 0.66
24.74 ± 0.62
19.79 ± 2.77
17.45 ± 0.98
23.89 ± 1.64
16.74 ± 1.01
14.15 ± 5.06
30.49 ± 1.01

Acc./%
33.50 ± 0.30
55.23 ± 1.13
67.27 ± 0.04
65.06 ± 1.87
66.41 ± 0.19
37.00 ± 0.32
64.73 ± 1.57
67.20 ± 0.12

F1/%
38.40 ± 0.37
55.41 ± 0.75
54.86 ± 0.13
55.42 ± 0.43
57.75 ± 0.27
41.90 ± 0.31
54.92 ± 1.25
59.60 ± 0.27

Acc./%
22.83 ± 0.18
40.18 ± 0.42
48.18 ± 0.88
46.59 ± 1.53
47.61 ± 0.55
25.77 ± 0.50
44.97 ± 2.99
50.26 ± 0.35

Overall

F1/%
26.53 ± 0.49
40.07 ± 0.08
37.33 ± 1.33
36.43 ± 0.39
40.82 ± 0.95
29.32 ± 0.60
34.53 ± 3.11
45.04 ± 0.39

random
BoW
CF-IUF [18]
SeqAE [5]
GPT [24]
util2vec [36]
log2int [28]
ours

ROC-AUC

• BoW: A Bag-of-Words baseline that directly represents the
user as the frequency of commands that has appeared in the
user’s command sequence.

• CF-IUF [18]: Another baseline representation that further
enhances BoW by representing the user using a vector
by taking the element-wise product between the command
frequency vector and a logarithmic scale inverse user fre-
quency vector. The user frequency vector further provides
information about the commands’ popularity amongst all
users, indicating the total percentage of users that have used
each command in the vocabulary.

• SeqAE [5]: A baseline that uses a sequential auto-encoder
inspired by Dai et al. [5]. We use two recurrent neural
networks with GRU layers. The ﬁrst network encodes the
command sequence of a session, and the second decoder
network takes the encoding vector and tries to reconstruct
the session. We only keep the encoder network that produces
the user representation, and use it to train linear classiﬁers
in the downstream tasks.

• GPT [24]: A baseline that uses an auto-regressive Trans-
former model with a generative pre-training objective that
predicts the user’s next command given its prior commands
in the sequence. We use a 12-layer Transformer which
follows the architecture of the GPT-tiny model.

the model

• util2vec [36]: We implement the method as described in
the util2vec paper. In util2vec,
is trained to
predict the held-out central command given its surrounding
commands and a context vector representing the user. The
model weights are kept frozen after the training stage. In
order to represent a user that is outside the training set and
does not have a context vector during the testing time, a
new context vector is optimized with the same objective
over the user’s command sequence. This context vector is
then used as the user representation to make the ﬁnal user-
level predictions in the downstream tasks.

• log2int [28]: We adapt the method described in log2int since

our setting is not identical to theirs, which does not include
paired descriptions of the command sequence. We keep the
main sequence-to-sequence model of two recurrent neural
networks, which are trained with an objective to predict
commands in the next session given the current session. We
then use the trained encoder network to generate the user’s
representation vector, which is passed to a linear classiﬁer
for the downstream tasks.

We use the same representation vector dimension of 256 for all
methods to ensure fair comparison. Each method is repeated 3
times with different initialization to ensure stable performance.

A. Main Results

Table II shows the main experimental results using full
labeled subsets. We report the overall accuracy and F1-score
for both downstream tasks as well as the overall performance.
We directly use SciPy’s weighted F1-score for multi-class
classiﬁcation, which better handles class imbalance. It can be
seen that as we explained and expected in Section III, the
experience prediction Task 1 is more difﬁcult than the exper-
tise prediction Task 2. All learning-based methods produce
results signiﬁcantly better than the random baseline, which
veriﬁes the basic assumption that user-level information can be
effectively extracted from their command sequences. The BoW
baseline has the lowest overall accuracy among all learning-
based methods as it is the most basic method. We ﬁnd the CF-
IUF method prone to favor dominant classes. It produces better
overall accuracy, but worse F1-score especially in Task 1. This
is due to the highly imbalanced nature of class distribution in
the years of experience using the Fusion 360 software, whose
user pool has been constantly increasing over time. The GPT
method is the second strongest method across both tasks and
both metrics. It performs particularly well in Task 2, which
is only one percentile below our proposed method. This is
due to its large model capacity, which is good at capturing
the theme which can be reﬂected at the command level. In

TABLE IV
ABLATION STUDY WITH ADDITIONAL MASKED LANGUAGE MODELING
LOSS AS WELL AS WITHOUT SESSION DROPOUT, SELF-SUPERVISED
LEARNING, USER NETWORK BRANCH, AND SESSION NETWORK BRANCH.

ses.dro.
(cid:88)

SSL
(cid:88)

user
(cid:88)

session
(cid:88)

+ MLM

×
(cid:88)
(cid:88)
(cid:88)

×
×
(cid:88)
(cid:88)

(cid:88)
(cid:88)
×
(cid:88)

(cid:88)
(cid:88)
(cid:88)
×

Acc./%
53.03
53.25(+0.22)
52.13(-0.90)
51.29(-2.01)
52.24(-0.79)
51.37(-1.30)

F1/%
47.75
47.82(+0.07)
46.40(-1.35)
46.43(-1.32)
46.09(-1.66)
46.76(-0.99)

Fig. 4. Few-shot learning: overall F1-score with varying amount of available
supervision in the labeled subset.

the more difﬁcult Task 1 that requires greater session- and
user- level understanding, our model demonstrates signiﬁcant
advantages over GPT. The util2vec method is trained using
local command sequence windows of size ±5, which leads to
reasonable performance in Task 2, but performs poorly in Task
1 that requires higher-level understanding. The SeqAE and
log2int methods are similar in network architecture, both using
an encoder and decoder recurrent neural network. The main
difference is SeqAE tries to reconstruct the same session, while
log2int tries to predict the next session. In our dataset, adjacent
sessions are often less related due to the rich functionality of
Fusion 360 and diverse user behaviour. Therefore, log2int does
not demonstrate a signiﬁcant gain over SeqAE. Our proposed
SimCURL method outperforms all comparisons in both tasks
and metrics, demonstrating the effectiveness of its learned
user representations. In terms of efﬁciency, our method is
lightweight and contains only 1.37 million parameters, with
an average inference time of 12.22 milliseconds, making it
suitable for large scale deployment and interactive applica-
tions. For the experience prediction task, besides the default
8-class setting we merged 0-to-2, 2-to-5, and 5-to-8 year into
a 3-class setting of beginner, intermediate, and experienced.
Our method achieves 64.19% accuracy and 59.86% F1-score
under this practical class setting.

B. Few-Shot Learning

We now evaluate our method in a few-shot learning setting
that reﬂects a practical scenario where it is difﬁcult to acquire
large amount of labeled data. To simulate this, we train
the models using only 6.25% (1/16) of the training set. As
shown in Table III, the util2vec method fails to work well
under the few-shot setting, which performs only slightly better
than random. All methods suffer performance loss due to the

2L,512B

2L,1024B

2L,2048B

3L,512B

y
c
a
r
u
c
c
A

e
r
o
c
s
-
1
F

Fig. 5. Effects of session dropout rate in the pre-training (y-axis) and
transfer (x-axis) and stages, network depth (L), and pre-training batch size
(B) in Task 1. Darker color means higher number: Acc.∈[36.15,37.87]/%,
F1∈[33.44,36.41]/%.

scarcity of training data. Light-weight models, especially CF-
IUF, suffer the least compared to other models. Our SimCURL
method shows strong few-shot learning ability, achieving best
or second best performance in both tasks and overall. Sim-
CURL also demonstrate signiﬁcant advantage on the overall
F1-score, outperforming the second best approach by more
than 4%. We further show more in-depth few-shot learning
results in Figure 4, where the amount of available supervision
decreases exponentially. It can be seen that our method has
strong few-shot capability under scarce supervision as well as
scalability as supervision increases. Our method consistently
outperforms the second-best method by more than 2.5% across
different supervision settings, where the improvement is the
most signiﬁcant at 4.22% when supervision is the most scarce.

C. Analysis

To verify the effectiveness of different components of our
method, we conduct an ablation study as shown in Table IV.
We ﬁnd the best performance is achieved with our full method,
where the self-supervised learning brings the most gain in
performance. The ﬁrst ablation method that does not have
session dropout also does not have the self-supervised learning
stage, since the generation of views relies on session dropout.
Interestingly, not using session dropout performs slightly better
than using session dropout but without the self-supervised
learning stage. This indicates the synergy between session
dropout and self-supervised learning. We also trained the
representation model with an additional masked language
model loss [6], where sessions are tokenized with K-means
clustering. This achieves minor improvement as shown in
Table IV, while we leave further thorough study of its effect as
future work. We study the effects of session dropout rate in the
transfer and the self-supervised learning stages, under different
network depths and batch sizes as shown in Figure 5. It can be
seen that deeper network produces better performance, while
there is no signiﬁcant gain for batch size larger than 1024. The
sweet spot for session dropout during self-supervised learning
is between 0.2 and 0.4, while a larger rate during transfer
learning usually helps.

VI. CONCLUSION

The emerging data modality of command sequences pos-
sesses rich information for user modeling and personalization.
In this paper we proposed a simple yet effective contrastive
learning method named SimCURL, that learns user represen-
tation vectors from unlabelled command stream records. Our
method is enabled by a user-session network architecture,
and a new session dropout data augmentation technique. We
trained and evaluated on a real-world dataset of Fusion 360
command sequences consisting of more than half a billion
improvement
commands. Our method achieved signiﬁcant
over existing methods on downstream classiﬁcation tasks,
which advanced user modeling techniques that can be used
to enable better user experience.

REFERENCES

[1] Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared
Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish
Sastry, Amanda Askell, et al. Language models are few-shot learners.
arXiv preprint arXiv:2005.14165, 2020.

[2] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv´e J´egou, Julien
Mairal, Piotr Bojanowski, and Armand Joulin. Emerging properties in
self-supervised vision transformers. arXiv preprint arXiv:2104.14294,
2021.

[3] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
A simple framework for contrastive learning of visual representations.
In International conference on machine learning, pages 1597–1607.
PMLR, 2020.

[4] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Ben-
gio. Empirical evaluation of gated recurrent neural networks on sequence
modeling. arXiv preprint arXiv:1412.3555, 2014.

[5] Andrew M Dai and Quoc V Le. Semi-supervised sequence learning.
information processing systems, 28:3079–3087,

Advances in neural
2015.

[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
Bert: Pre-training of deep bidirectional transformers for language un-
derstanding. arXiv preprint arXiv:1810.04805, 2018.

[7] Xiaomin Fang, Jizhou Huang, Fan Wang, Lihang Liu, Yibo Sun, and
Haifeng Wang. Ssml: Self-supervised meta-learner for en route travel
time estimation at baidu maps. In Proceedings of the 27th ACM SIGKDD
Conference on Knowledge Discovery & Data Mining, pages 2840–2848,
2021.

[8] Tianyu Gao, Xingcheng Yao, and Danqi Chen.
ple contrastive learning of sentence embeddings.
arXiv:2104.08821, 2021.

Simcse: Sim-
arXiv preprint

[9] Wen Gao, Xuanming Zhang, Qiushi He, Borong Lin, and Weixin Huang.
Command prediction based on early 3d modeling design logs by deep
neural networks. Automation in Construction, 133:104026, 2022.
[10] Jean-Bastien Grill, Florian Strub, Florent Altch´e, Corentin Tallec,
Pierre H Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila
Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, et al. Boot-
strap your own latent: A new approach to self-supervised learning. arXiv
preprint arXiv:2006.07733, 2020.

[11] Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality reduction
In 2006 IEEE Computer Society
by learning an invariant mapping.
Conference on Computer Vision and Pattern Recognition (CVPR’06),
volume 2, pages 1735–1742. IEEE, 2006.

[12] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
Momentum contrast for unsupervised visual representation learning. In
Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pages 9729–9738, 2020.

[13] Shilin He, Jieming Zhu, Pinjia He, and Michael R Lyu. Loghub: A
large collection of system log datasets towards automated log analytics.
arXiv preprint arXiv:2008.06448, 2020.

[14] Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory.

Neural computation, 9(8):1735–1780, 1997.

[15] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic

optimization. arXiv preprint arXiv:1412.6980, 2014.

[16] Y LeCun and I Misra. Self-supervised learning: The dark matter of

intelligence, 2021.

[17] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi
Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
Roberta: A robustly optimized bert pretraining approach. arXiv preprint
arXiv:1907.11692, 2019.

[18] Justin Matejka, Wei Li, Tovi Grossman, and George Fitzmaurice.
Communitycommands: command recommendations for software appli-
cations. In Proceedings of the 22nd annual ACM symposium on User
interface software and technology, pages 193–202, 2009.

[19] Hongyuan Mei and Jason Eisner.

The neural hawkes process: A
arXiv preprint

neurally self-modulating multivariate point process.
arXiv:1612.09328, 2016.

[20] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efﬁcient
arXiv preprint

estimation of word representations in vector space.
arXiv:1301.3781, 2013.

[21] Daisuke Niizumi, Daiki Takeuchi, Yasunori Ohishi, Noboru Harada, and
Kunio Kashino. Byol for audio: Self-supervised learning for general-
purpose audio representation. arXiv preprint arXiv:2103.06695, 2021.
[22] Jeffrey Pennington, Richard Socher, and Christopher D Manning. Glove:
Global vectors for word representation. In Proceedings of the 2014 con-
ference on empirical methods in natural language processing (EMNLP),
pages 1532–1543, 2014.

[23] Lawrence R Rabiner. A tutorial on hidden markov models and selected
applications in speech recognition. Proceedings of the IEEE, 77(2):257–
286, 1989.

[24] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al.
Improving language understanding by generative pre-training. OpenAI,
2018.

[25] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei,
Ilya Sutskever, et al. Language models are unsupervised multitask
learners. OpenAI blog, 1(8):9, 2019.

[26] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan
Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Explor-
ing the limits of transfer learning with a uniﬁed text-to-text transformer.
arXiv preprint arXiv:1910.10683, 2019.

[27] Steffen Schneider, Alexei Baevski, Ronan Collobert, and Michael Auli.
arXiv

wav2vec: Unsupervised pre-training for speech recognition.
preprint arXiv:1904.05862, 2019.

[28] Zhiqiang Tao, Sheng Li, Zhaowen Wang, Chen Fang, Longqi Yang,
Handong Zhao, and Yun Fu. Log2intent: Towards interpretable user
modeling via recurrent semantics memory unit. In Proceedings of the
25th ACM SIGKDD International Conference on Knowledge Discovery
& Data Mining, pages 1055–1063, 2019.

[29] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention
is all you need. In Advances in neural information processing systems,
pages 5998–6008, 2017.

[30] Andrew Viterbi. Error bounds for convolutional codes and an asymptot-
ically optimum decoding algorithm. IEEE transactions on Information
Theory, 13(2):260–269, 1967.

[31] Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, and
Hongyuan Zha. Beyond clicks: Modeling multi-relational item graph
for session-based target behavior prediction. In Proceedings of The Web
Conference 2020, pages 3056–3062, 2020.

[32] Xu Wang, Benjamin Lafreniere, and Tovi Grossman.

Leveraging
community-generated videos and command logs to classify and recom-
mend software workﬂows. In Proceedings of the 2018 CHI Conference
on Human Factors in Computing Systems, pages 1–13, 2018.

[33] Wayne Xiong, Lingfeng Wu, Jun Zhang, and Andreas Stolcke. Session-
In Proceedings
level language modeling for conversational speech.
of the 2018 Conference on Empirical Methods in Natural Language
Processing, pages 2764–2768, 2018.

[34] Hao Xue and Flora D Salim. Exploring self-supervised representation
ensembles for covid-19 cough classiﬁcation. In Proceedings of the 27th
ACM SIGKDD Conference on Knowledge Discovery & Data Mining,
pages 1944–1952, 2021.

[35] Longqi Yang, Chen Fang, Hailin Jin, Walter Chang, and Deborah Estrin.
Creative procedural-knowledge extraction from web design tutorials.
arXiv preprint arXiv:1904.08587, 2019.

[36] Longqi Yang, Chen Fang, Hailin Jin, Matthew D Hoffman, and Deborah
Estrin. Personalizing software and web services by integrating unstruc-
tured application usage traces. In Proceedings of the 26th International
Conference on World Wide Web Companion, pages 485–493, 2017.
[37] Longqi Yang, Chen Fang, Hailin Jin, Matthew D Hoffman, and Deborah
Estrin. Characterizing user skills from application usage traces with hi-
erarchical attention recurrent networks. ACM Transactions on Intelligent
Systems and Technology (TIST), 9(6):1–18, 2018.

