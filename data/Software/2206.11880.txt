The Eﬀective Sample Size in Bayesian Information Criterion
for Level-Speciﬁc Fixed and Random Eﬀects Selection in a Two-Level Nested Model

2
2
0
2

n
u
J

3
2

]
E
M

.
t
a
t
s
[

1
v
0
8
8
1
1
.
6
0
2
2
:
v
i
X
r
a

Sun-Joo Cho
Vanderbilt University

Hao Wu
Vanderbilt University

Matthew Naveiras
Vanderbilt University

March 6, 2022

Note. The ﬁrst and second authors contributed equally to this work.

Correspondence should be sent to

E-Mail:
Phone:
Website: http : //www.vanderbilt.edu/psychologicalsciences/bio/sun − joo − cho

sj.cho@vanderbilt.edu

615-322-8409

1

 
 
 
 
 
 
The Eﬀective Sample Size in Bayesian Information Criterion
for Level-Speciﬁc Fixed and Random Eﬀects Selection in a Two-Level Nested Model

Popular statistical software provides Bayesian information criterion (BIC) for multilevel models or

linear mixed models. However, it has been observed that the combination of statistical literature

and software documentation has led to discrepancies in the formulas of the BIC and uncertainties

of the proper use of the BIC in selecting a multilevel model with respect to level-speciﬁc ﬁxed and

random eﬀects. These discrepancies and uncertainties result from diﬀerent speciﬁcations of sample

size in the BIC’s penalty term for multilevel models. In this study, we derive the BIC’s penalty

term for level-speciﬁc ﬁxed and random eﬀect selection in a two-level nested design. In this new

version of BIC, called BICE, this penalty term is decomposed into two parts if the random eﬀect

variance-covariance matrix has full rank: (a) a term with the log of average sample size per cluster

whose multiplier involves the overlapping number of dimensions between the column spaces of the

random and ﬁxed eﬀect design matrices and (b) the total number of parameters times the log

of the total number of clusters. Furthermore, we study the behavior of BICE in the presence of

redundant random eﬀects. The use of BICE is illustrated with a textbook example data set and

a numerical demonstration shows that the derived formulae adheres to empirical values.

Keywords: Bayesian information criterion, level-speciﬁc ﬁxed eﬀects, linear mixed models,

model selection, multilevel model, random eﬀect

2

1

Introduction

Multilevel models (MLMs; e.g., Goldstein, 2003) or linear mixed models (Laird & Ware, 1982)

are a general class of modeling framework to describe the relationship between the response and

covariates for clustered data including repeated measures and nested designs. Selecting ﬁxed and

random eﬀects is an important step in the applications of the MLM. When competing MLMs

are compared in model selection based on the maximum likelihood (ML) method, the literature

suggests using the likelihood ratio test (LRT) or the deviance test to compare the ﬁt of the two

competing MLMs which diﬀer in the ﬁxed and/or random eﬀects (e.g., Goldstein, 2003, p. 24, pp.

35–36; Snijders & Bosker, 1999, pp. 88–90). According to the survey of Whittaker and Furlow

(2009) regarding the use of model selection methods for the MLMs, the LRT is a dominant model

selection method in the applications of the MLMs.

Using the LRT, one can make a statistical decision by comparing the likelihood under two

competing models against the critical value, which can easily be found based on the known null

distribution. However, diﬃculties of using the LRT for MLMs have been noted in the literature.

First, the LRT is mainly for the comparison of two nested models, although a line of research on

the LRT for non-nested models (e.g., Merkle, You, & Preacher, 2016; Vuong, 1989) also exists.

Second, the LRT statistic does not follow a simple chi-square distribution when the random eﬀect

variance-covariance matrix has a boundary value on the model parameter space (Self & Liang,

1987; Stram & Lee, 19941, 1995; Molenbergh & Verbeke, 2007). Third, a LRT does not quantity

the degree to which a model is better than another model. Based on the LRT results, we can

only conclude that the two comparison models ﬁt equally well or that the more complex model

ﬁts better. Fourth, small changes that are too small to be of practical importance always becomes

1Stram and Lee (1994) incorrectly speciﬁed constraints in their derivation, which they later noted (Stram &

Lee, 1995).

3

signiﬁcant with large enough sample sizes (e.g., Jones [2011]). Because most null hypotheses are

rejected in large sample sizes, hypothesis tests often suggest complex models (Weaklim, 1999).

In addition to the LRT, information criteria such as the Bayesian information criterion (BIC;

Schwarz, 1978) have been used for the MLMs (e.g., Hamaker, van Hattum, Kuiper, & Hoijtink,

2011; McCoach & Black, 2008; Whittaker & Furlow, 2009). Most software for the MLMs, including

SPSS (IBM Corp., 2020), the MIXED procedure in SAS (SAS Institute Inc., 2015), R lme4 library

(Bates, M¨achler, Bolker, & Walker, 2015), and Mplus (Muth´en & Muth´en, 1998–2015), provide

BIC and/or its sample-size modiﬁcation as a part of its output. The BIC allows for the comparisons

of two or more competing models, whether or not they are nested, and it quantiﬁes the degree

to which a given model represents an improvement over the other competing models (Burnham

& Anderson, 2002). The BIC is relatively easy to calculate and under certain conditions the

diﬀerence between two BICs is a rough approximation to the logarithm of the Bayes factor which

requires evaluation of prior distributions (Berger, Ghosh, & Mukhopadhyay, 2003; Kass & Raftery,

1995). BIC does not constitute a statistical test of the diﬀerence in the competing models and

model selection is made based on ranking of the BIC values among competing models.

However, it is challenging to use the BIC for the MLM because the sample size in the BIC’s

penalty term is not clear. In the literature, it was noted that the sample size in the BIC’s penalty

term is not well-deﬁned for the dependent observations in clustered data. For the MLM, the

sample size in BIC calculation can be a total sample size, the number of clusters, cluster sizes,

or the weighted average of the total sample size and cluster sizes (e.g., Hamaker, van Hattum,

Kuiper, & Hoijtink, 2011, p. 249; McCoach & Black, 2008, p. 253). We found inconsistent use of

sample size in the BIC’s penalty term across software. SPSS, R, and Mplus use the total sample

size for all kinds of MLMs, whereas the MIXED procedure in SAS (SAS Institute Inc., 2015, p.

6064) use the number of levels of the ﬁrst random eﬀect speciﬁed in a RANDOM statement for the

4

sample size (e.g., the number of clusters for a two-level random intercept model). Furthermore,

MLM textbooks also diﬀer in their recommendations. For example, Hox, Moerbeek, and van de

Schoot (2018, p. 39) and Goldstein (2003, p. 37) noted that the total number of higher level units

in MLM is often used as an approximation of the eﬀective sample size. However, Snijders and

Bosker (2012, p. 202) presented BIC with the total sample size in MLM applications. When the

sample size in the BIC’s penalty term is not correctly deﬁned for the MLMs, diﬀerent calculation

of BIC results in diﬀerent model selection results.

For the MLM, observations within a cluster tend to be dependent, which impacts the model

selection with the BIC by reducing the sample size. Several researchers attempted to calculate

an eﬀective sample size for dependent observations. Pauler (1998) presented the eﬀective sample

size for choosing ﬁxed eﬀects in normal linear mixed models (or random intercept models) and

her main idea for the modiﬁed BIC was to have a diﬀerent penalty term per parameter. Raftery

(1995) deﬁned the eﬀective sample size for a linear regression model and analysis of variance, a

logistic regression model, a log-linear model, an event-history model, and a structural equation

model. Berger, Ghosh, and Mukhopadhyay (2003, p. 243) and Kass and Raftery (1995, p. 779)

noted that the eﬀective sample size can be derived as the scalar for an approximation of the

information matrix. However, these previous studies cannot be applied directly for MLM. Jones

(2011) derived the eﬀective sample size in the BIC’s penalty term for a linear mixed model as

the sum of the elements of the inverse of each cluster’s correlation matrix (of the response) across

clusters (Equation 3 in Jones [2011]). Despite the author showing that the eﬀective sample size

is a function of the intraclass correlation (ICC) (Equation 6 in Jones [2011]), he did not show the

eﬀective sample size in the context of selecting the level-speciﬁc ﬁxed and random eﬀects (random

intercept and random slope) of the linear mixed model. Delattre, Lavielle, and Poursat (2014)

derived BIC for mixed-eﬀects models in which the eﬀective sample size is the number of clusters

5

for random eﬀects but is the total sample size for ﬁxed eﬀects. However, they did not provide the

eﬀective sample size for level-speciﬁc ﬁxed eﬀects. Recently, Lorah and Womack (2019) showed via

a simulation study that BIC produces appropriate model selection behavior regarding ﬁxed eﬀects

in the case that the eﬀective sample size is the number of clusters for between-cluster ﬁxed eﬀects

and but is the total sample size for within-cluster ﬁxed eﬀects in a two-level random intercept

model. Although ﬁndings in Delattre et al. (2014) and Lorah and Womack (2019) suggest the

importance of appropriate the eﬀective sample size for either level-speciﬁc ﬁxed eﬀects or random

eﬀects, these studies did not show the derivation of the eﬀective sample size in the selection of

level-speciﬁc ﬁxed and random eﬀects (random intercept and random slope).

Thus, the purpose of this paper is to derive the BIC’s penalty term for the level-speciﬁc ﬁxed

and random eﬀect selection in MLM. The focus is not to argue in favor of BIC against LRT or

other information criteria. Speciﬁcally, we analyze the large sample behavior of the information

matrix in the MLM for two-level nested data (e.g., students nested within schools).

The remainder of this paper is organized as follows.

In Section 2, the BIC and Laplace

approximation as its theoretical basis are reviewed. In Section 3, we derive the BIC for a two-level

nested model when the variance-covariance matrix of random eﬀects has full rank. In Section 4,

we derive the BIC for models with redundant random eﬀects. In Section 5, the behavior of BIC

is demonstrated in various multilevel designs. In Section 6, the use of BIC is illustrated using a

textbook example. In Section 7, we end with a summary and a discussion.

2 Bayesian Information Criterion (BIC)

Schwarz (1978) derived the BIC as an asymptotic approximation of the Bayesian marginal prob-

ability of a candidate model M:

log f (y|M) = log f (y|

ϑ, M) −

K
2

log N + Op(1),

(1)

b

6

where y is data, ϑ is the vector of parameters for model M, f (y|

ϑ, M) is the likelihood of data

y evaluated at the ML estimate (MLE)

ϑ, K is the number of parameters for model M, and N

b

is the sample size. For a large sample size, the order term Op(1) can be dropped in Equation 1.

b

The BIC can also be presented (for a large sample size) as:

BIC = −2 log f (y|

ϑ, M) + K log N.

(2)

b
The original derivation in Schwarz (1978) was “for the case of independent, identically dis-

tributed (i.i.d.) observations, and linear models”, under the assumption that the likelihood be-

longs to an exponential family.

It has been noted that BIC can be used for observations not

necessarily identically distributed (e.g., Pauler, 1998; Stone, 1979). Below, the notation for the

candidate model M as it appears in Equation 2 is omitted for reasons of simplicity.

The BIC can be derived based on Laplace approximation (e.g., Raftery, 1995; Kass & Vaidyanathan,

1992), which is also valid for mixed models (e.g., Wolﬁnger, 1993). In the Laplace approximation

method, the log likelihood, g(ϑ) = log f (y|ϑ), is expanded as a quadratic Taylor series about the

MLE ˆϑ under regularity conditions (de Bruijn, 1970, sec. 4.4; Tierney & Kadane, 1986):

g(ϑ) = g( ˆϑ) −

1
2

(ϑ − ˆϑ)T A(ϑ − ˜ϑ) + op(1),

(3)

where A = −Eg′′( ˆϑ) is the information matrix, and g′′( ˆϑ) is the Hessian matrix. We note that

g′( ˆϑ) = 0, so the linear term is not present. the marginal probability f (y) can be approximated

as (Kass & Vaidyanathan, 1992)

f (y) =

exp[g(ϑ)]π(ϑ)dϑ = f (y| ˆϑ)π( ˆϑ)(2π)K/2|A|−1/2 {1 + Op(1/n)} ,

Z

where π(ϑ) is the prior density.

Taking the logarithm leads to

log f (y) = log f (y| ˆϑ) + log π( ˆϑ) +

K
2

log(2π) −

1
2

log |A| + op(1).

(4)

7

When observations are i.i.d., log |A| = K log(N) + Op(1), leading to BIC as in Equation 1.

3 BIC for a Two-Level Nested Model

For two-level nested data, the response vector yj is composed of the response yji from observation

i (i = 1, . . . , nj) in cluster j (j = 1, . . . , J). The standard form of the variance component model

(Laird & Ware, 1982) is

yj = Xjβ + Zjbj + ǫj,

(5)

where Xj is (nj × p) design matrix for ﬁxed eﬀects, Zj is (nj × q) design matrix for random

eﬀects, β is a p × 1 vector of ﬁxed eﬀects, bj is a q × 1 vector of random eﬀects distributed as

bj ∼ MV N(0, Ψj) (where Ψj is a variance-covariance matrix of random eﬀects), and ǫj is a nj ×1

vector of residuals distributed as ǫj ∼ N(0, σ2

j Inj ) where Inj is an identity matrix of size nj. In

most applications of the MLMs, it is often assumed that all Ψj and σ2

j stay the same across all

clusters (e.g., de Leeuw & Meijer, 2007). Thus, in this study, we assume bj ∼ MV N(0, Ψ) and

ǫj ∼ N(0, σ2Inj ) (homoscedasticity). The total sample size is denoted by N, calculated as N = nJ

for a balanced design (nj = n) and N =
size is denoted by ¯n = N/J. We also deﬁne ϑ = [β′

P

J
j=1 nj for an unbalanced design. The average cluster

′

, vech

(Ψ), σ2]′ as the vector of parameters.

For J independent clusters, the matrix A in Equation 3 can be expressed as

X
where Ij( ˆϑ) is the Fisher information for cluster j.

A =

Ij( ˆϑ),

The mean vector µj and the covariance matrix Vj for the distribution of yj are given by

µj = Xjβ and Vj = ZjΨZ′

j + σ2Inj

(6)

(7)

When no parameter appears in both the mean and covariance structures, the information

matrix of a multivariate normal model is block diagonal, with a block Iββ for the mean structure

8

parameters (here the ﬁxed eﬀects β) and a second block Iρρ for the covariance structure parameters

(here the residual variance σ2 and the non-duplicated elements in random eﬀect variance-covariance

matrix vech

′

(Ψ); we deﬁne ρ = [vech

′

(Ψ), σ2]′). The log-determinant of the information matrix

can be expressed as

log |A| = log |Iββ| + log |Iρρ|

(8)

Below we investigate the two blocks separately.

3.1 The Information Matrix of Fixed Eﬀects

We deﬁne:

SXX,nj = X′

jXj/nj

SXZ,nj = X′

jZj/nj

SZZ,nj = Z′

jZj/nj

(9)

Note that while the number of rows of Xj and Zj grows with nj, the sizes of the matrices deﬁned

above remain constant and their elements are assumed to remain bounded.

The block of Ij corresponding to the ﬁxed eﬀects β is given by

Iββ,j = X′

jV

−1
j Xj

Here we note that

V−1

j =

=

1
σ2

1
σ2

Inj − Zj(σ2Ψ−1 + Z′

jZj)−1Z′

j

=

1
σ2

(cid:8)

(cid:26)

Inj −

1
nj

ZjS−1

ZZ,nj Z′

j

(cid:9)
ZjS−1

ZZ,nj

+

1
n2
j

(cid:27)

(
σ2
nj

(cid:20)

Inj −

1
nj

Zj

(cid:20)

σ2
nj

Ψ−1 + SZZ,nj

−1

S−1
ZZ,njZ′

j

S−1
ZZ,nj + Ψ
(cid:21)

(10)

(11)

(12)

−1

(cid:21)

Z′
j

)

and Equation 10 becomes

Iββ,j =

nj
σ2

SXX,nj − SXZ,nj S−1
n

ZZ,njSZX,nj

o

+ SXZ,nj S−1

ZZ,nj

−1

σ2
nj

(cid:20)

S−1
ZZ,nj + Ψ
(cid:21)

S−1
ZZ,njSZX,nj

Now we partition Xj into two parts Xj = [X1,j, X2,j] and β compatibly into β = (β′

1, β′

2)′.

In this partition, X1,j has p1 columns of the design matrix that cannot be written as linear

9

combinations of the columns of Z. They are typically within-cluster covariates that do not have

a correspondent random eﬀect. We can write

X1,j = ZjWj + Ej

for some q × p1 matrix Wj and some nj × p1 matrix Ej with E′

jZj = O. The block of Iββ,j for β1

can be simpliﬁed to

Iβ1β1,j =

nj
σ2 SEE,nj + W′

j

σ2
nj

(cid:20)

−1

S

−1
ZZ,nj + Ψ
(cid:21)

Wj

where SEE,nj = E′

jEj/nj. For the special situation where the within-cluster covariates are all

mean-centered within each cluster and orthogonal to each other, Wj is a zero matrix, E = X1,j

and SEE,nj is diagonal.

On the other hand, X2,j has the remaining p2 = p − p1 columns of the design matrix that are

linear combinations of columns of Zj, so we can write X2,j = ZjBj for some q × p2 matrix Bj.

These columns of X2,j include

• a column of 1’s for the intercept (which we assume has a random eﬀect),

• within-cluster covariates that have both ﬁxed and random eﬀects,

• between-cluster covariates (columns of constants within X2,j), and

• interaction eﬀects between between-cluster covariates and within-cluster covariates with ran-

dom eﬀects.

Note that we make the assumption that a between-cluster covariate does not have a random eﬀect,

or the individual SZZ,nj would not be invertible. The correspondent block of Iββ,j is reduced to

Iβ2β2,j = B′

j

σ2
nj

(cid:20)

S−1
ZZ,nj + Ψ
(cid:21)

−1

Bj

10

(13)

For the special situation where no between-cluster covariate is present and all within-cluster co-

variates with random eﬀects also have a ﬁxed eﬀect, X2,j has the same columns as Zj and Bj is

an identity matrix.

The oﬀ-diagonal block of Iββ,j is

Iβ1β2,j = W′

j

σ2
nj

(cid:20)

S−1
ZZ,nj + Ψ
(cid:21)

−1

Bj

If we assume 1
N

njSEE,nj → SEE (as J → ∞ and minj nj → ∞) and SEE has full rank,

P
then the block Iβ1β1 =

Iβ1β1,j has order Op(N). If Ψ has full rank, then both Iβ2β2,j and Iβ1β2,j

are of constant order, so Iβ2β2 =

P

Iβ2β2,j and Iβ2β1 =

Iβ2β1,j are both of order Op(J). These

suggest that

P

P

log |Iββ| = p2 log(J) + p1 log(N) + Op(1) = p log(J) + p1 log(¯n) + Op(1),

(14)

where N = J ¯n (¯n is the average cluster size).

If SEE is singular with rank ˜p1 < p1, then we can linearly reparameterize the ﬁxed eﬀects cor-

responding to X1,j to separate out p1 − ˜p1 ﬁxed eﬀects whose correspondent (linearly transformed)

columns of X1,j lies in the columns space of Zj. These ﬁxed eﬀects can combine into X2,j. The

remaining ˜p1 ﬁxed eﬀects results in a SEE matrix with full rank of ˜p1. Note that a reparameteriza-

tion may change the determinant of the information matrix, but only up to a multiplicative factor

of constant order, so the form of BIC is not aﬀected. In light of this discussion, p2 in Equation 14

can be interpreted as the dimension of the intersection space between the column spaces of Xj

and Zj: p2 = dim {C(Xj) ∩ C(Zj)}, and p1 as p − p2.

11

3.2

Information Matrix of Random Eﬀect Parameters

We now turn to the block of the information matrix for the random eﬀect parameters. The element

corresponding to σ2 is given by

Iσ2σ2,j =

1
2

tr

(cid:26)

∂Vj
∂σ2 V−1

j

∂Vj
∂σ2 V−1

j

(cid:27)

=

1
2

tr(V−2
j )

Here we note:

V

−2
j =

1
σ4

+

and obtain

Inj −

ZjS

−1
ZZ,nj Z′

j

1
nj

(cid:26)
1
n3
j

ZjS−1

ZZ,nj

(cid:27)

S−1
ZZ,nj + Ψ
(cid:21)

σ2
nj

(cid:20)

−1

S−1
ZZ,nj

−1

σ2
nj

(cid:20)

S−1
ZZ,nj + Ψ
(cid:21)

S−1
ZZ,njZ′

j

Iσ2σ2,j =

nj − q
2σ4 +

1
2n2
j

tr

σ2
nj

((cid:20)

Iq + ΨSZZ,nj

−2

)

(cid:21)

Note this term is always of order O(nj), so Iσ2σ2 =

Iσ2σ2,j = O(N).

The block corresponding to ψ = vech(Ψ) is given by

P

Iψψ,j =

=

=

=

1
2
1
2
1
2
1
2

(cid:20)
D′

D

D

′
q

′
q

∂vecVj
∂ψ′

′

V−1

j ⊗ V−1

j

(cid:21)

(cid:8)
q {Zj ⊗ Zj}

′

(cid:20)
(cid:9)
j ⊗ V−1
j

V−1

∂vecVj
∂ψ′

(cid:21)
{Zj ⊗ Zj} Dq

′
jV
Z

(cid:8)
−1
j Zj

⊗

(cid:9)
−1
j Zj

Dq

′
jV
Z
−1

(cid:8)(cid:2)

((cid:20)

Ψ +

σ2
nj

(cid:3)
(cid:2)
−1
S
ZZ,nj

(cid:3)(cid:9)
Ψ +

⊗

σ2
nj

S

−1
ZZ,nj

−1

)

(cid:21)

Dq

(cid:21)

(cid:20)

(15)

(16)

(17)

(18)

where Dq is the q2 × q(q+1)

2

so Iψψ =

Iψψ,j = Op(J).

P

duplication matrix. If Ψ has full rank, this matrix has constant order,

12

The oﬀ-diagonal block is

Iψσ2,j =

=

=

=

(cid:20)
D

1
2
1
2
1
2
1
2nj

∂vecVj
∂ψ′

′

V−1

j ⊗ V−1

j

(cid:21)

(cid:8)
′
q {Zj ⊗ Zj}

′

(cid:20)
(cid:9)
−1
−1
j ⊗ V
j

V

∂vecVj
∂σ2

(cid:21)
vecInj

D′

qvec(Z′

(cid:8)
jV−2Zj)

D

′
qvec

σ2
nj

((cid:20)

+ SZZ,njΨ
(cid:21)

(cid:9) (cid:2)

−2

SZZ,nj

(cid:3)

)

If Ψ has full rank, this oﬀ-diagonal block has order op(1), so Iψσ2 =

Iψσ2,j = op(J).

If we denote the vector of variance and covariance parameters by ρ = [vech

P

′

(Ψ), σ2]′, then

when Ψ has full rank,

log |Iρρ| = q∗ log(J) + log(N) + O(1) = (q∗ + 1) log(J) + log(¯n) + O(1)

(19)

where q∗ = q(q + 1)/2 is the number of non-duplicated elements in Ψ.

3.3 Summary

When Ψ has full rank, Equations 4, 8, 14 and 19 result in the following equation:

log f (y) = f (y| ˆϑ) −

1
2

[K1 log(N) + K2 log(J)] + O(1),

(20)

where K1 = p1 + 1, K2 = p2 + q∗, p1 = p − p2, p2 = dim {C(Xj) ∩ C(Zj)}, and q∗ = q(q + 1)/2. It

is common to formulate BIC with deviance as follows:

BICE = −2 log f (y| ˆϑ) + K1 log(N) + K2 log(J) = −2 log f (y| ˆϑ) + K1 log(¯n) + K log(J),

(21)

in which the subscript E stands for “eﬀective sample size.” Compared to the conventional BIC,

the total penalty term in BIC is decomposed into the two terms, (a) K1 log(N) and (b) K2 log(J),

which can be also decomposed into (a) K1 log(¯n) and (b) K log(J) in Equation 21.

13

4 BIC in the Presence of Redundant Random Eﬀects

The derivations in the section above assume that Ψ has full rank. When Ψ is rank deﬁcient,

K1 and K2 in Equation 21 may deviate from their prescribed values. Now we investigate such

situations.

When Ψ is singular, some of the random eﬀects are redundant. We ﬁrst study the situation

when some of the random eﬀects have zero variance and the remaining random eﬀects have a

variance-covariance matrix of full rank. In this case, we write Zj = [Z1,j, Z2,j], where the nj × q1

block Z1,j corresponds to the q1 random eﬀects with a variance-covariance matrix Ψ11 of full rank

and the nj × q2 block Z2,j corresponds to the q2 random eﬀects present in the model but not

present in the population. We can write

Z2,j = Z1,jWj + Ej

′
for some q1 × q2 matrix Wj and some nj × q2 matrix E with E
jZ1,j = O. Because we assume Zj

has full rank, the matrix SEE,nj = E

′
jEj/nj has full rank.

We also compatibly block Ψ as

Ψ =

Ψ11 Ψ12
Ψ21 Ψ22 (cid:21)

,

(cid:20)

where Ψ22, Ψ21 and Ψ12 are zero matrices in the population but are still present in the model.

With this formulation, we have

V−1

j =

Vj =Z1,jΨ11Z′
1
σ2
1
σ4

j =

Inj −

Inj −

(cid:26)

V−2

1,j + σ2Inj

1
nj
1
nj

Z1,jS−1

Z1Z1,nj Z′

1,j

Z1,jS−1

Z1Z1,nj Z′

1,j

(cid:27)

(cid:27)

(cid:26)
1
n3
j

+

Z1,jS−1

Z1Z1,nj

σ2
nj

(cid:20)

S−1
Z1Z1,nj + Ψ11

+

1
n2
j

Z1,jS−1

Z1Z1,nj

S−1
Z1Z1,nj

−1

(cid:21)

14

S−1
Z1Z1,nj + Ψ11

S−1
Z1Z1,nj + Ψ11

σ2
nj

(cid:20)

σ2
nj

(cid:20)

−1

(cid:21)

−1

(cid:21)

S−1
Z1Z1,nj Z′

1,j

S−1
Z1Z1,nj Z′

1,j

Below we reevaluate the order of the blocks of the information matrix Ij. For the block Iββ,j

for ﬁxed eﬀects, we still have

log |Iββ| = p2 log(J) + p1 log(N) + Op(1) = p log(J) + p1 log(¯n) + Op(1),

(22)

where p1 = p − p2 and p2 = dim {C(Xj) ∩ C(Z1,j)}. Note now Z1,j replaces Zj in the deﬁnition of

p2. This means that some columns of X2,j now have to move to X1,j, resulting in a smaller p2 and

a larger p1.

The block Iρρ of parameters in the random eﬀects is more complicated because blocks Ψ22 and

Ψ21(= Ψ′

12) of the variance-covariance matrix Ψ are zero in the population but are still present

in the model. These parameters need to be treated separately. We now deﬁne ψrr = vechΨrr

(r = 1, 2) and ψ12 = vecΨ12. The blocks of Ij are given by

Iψrrψss,j =

Iψ12ψss,j =

Iψ12ψ12,j =

1
2
1
2
1
2

D′
qr

Z′
r,jV−1

j Zs,j

⊗

Z′
r,jV−1

j Zs,j

Dqs,

(r, s = 1, 2)

(cid:8)(cid:2)
2,jV−1
Z′

j Zs,j

⊗

(cid:3)

(cid:2)
1,jV−1
Z′

j Zs,j

+

(cid:3)(cid:9)
1,jV−1
Z′

j Zs,j

⊗

2,jV−1
Z′

j Zs,j

Dqs,

(s = 1, 2)

(cid:8)(cid:2)

1,jV−1
Z′

j Z1,j

(cid:3)

⊗

(cid:2)
2,jV−1
Z′

j Z2,j

(cid:3)

+

(cid:2)
1,jV−1
Z′

j Z2,j

(cid:3)

⊗

(cid:2)
2,jV−1
Z′

j Z1,j

(cid:3)(cid:9)

+

(cid:3)

(cid:0)(cid:2)

2,jV−1
Z′
(cid:2)
qrvec(Z′
D′

j Z1,j
(cid:3)
r,jV−2Zr,j),

⊗

(cid:2)

(cid:2)
1,jV−1
Z′

j Z2,j

(cid:3)

+

(cid:2)
2,jV−1
Z′

j Z2,j

(cid:3)

⊗

(cid:2)
1,jV−1
Z′

j Z1,j

(cid:3)

(cid:3)

(cid:2)

(r = 1, 2) and

(cid:3)

(cid:2)

(cid:3)(cid:1)

Iψrrσ2,j =

Iψ12σ2,j =

Iσ2σ2,j =

′
2,jV
vec(Z

1
2
1
2
nj − q1
2σ4 +

−2Z1,j + Z

′
1,jV

−2Z2,j)

1
2n2
j

tr

σ2
nj

((cid:20)

Iq1 + Ψ11SZ1Z1,nj

−2

)

(cid:21)

15

2,jV−1
Z′

j Z1,j = W

S−1
Z1Z1,nj + Ψ11

where

1,jV−1
Z′

j Z1,j =

2,jV−1
Z′

j Z2,j =

Z′

1,jV

−2
j Z1,j =

Z2,jV−2

j Z2,j =

Z2,jV−2

j Z1,j =

−1

S−1
Z1Z1,nj

(cid:21)
σ2
nj

′

j

(cid:20)

−1
Z1Z1,nj + Ψ11

σ2
nj

′

j

Ψ11 +
(cid:20)
nj
σ2 SEE,nj + W
σ2
nj
(cid:20)
σ2
nj

1
nj (cid:20)
nj
σ4 SEE,nj +
σ2
1
nj
nj

W

S

′

(cid:20)

S−1
Z1Z1,nj + Ψ11

−1

Wj

(cid:21)

−1

(cid:21)
−1

S

−1
Z1Z1,nj

−1

σ2
nj

S

−1
Z1Z1,nj + Ψ11
−1

(cid:20)

(cid:21)
σ2
S−1
Z1Z1,nj + Ψ11
nj

′

W

1
nj

(cid:20)

S−1
Z1Z1,nj

(cid:20)

(cid:21)
σ2
S−1
Z1Z1,nj + Ψ11
nj

−1

W

(cid:21)

S−1
Z1Z1,nj + Ψ11

S−1
Z1Z1,nj + Ψ11

−1

(cid:21)

S−1
Z1Z1,nj

(cid:21)

(cid:20)

σ2
nj

−1

(cid:21)

From these results we can see the information matrix of the random eﬀect parameters has the

following order:

Iψ11ψ11,j
Iψ12ψ11,j
Iψ22ψ11,j
Iσ2ψ11,j

Iψ12ψ12,j
Iψ22ψ12,j
Iσ2ψ12,j

Iψ22ψ22,j
Iσ2ψ22,j

Iσ2σ2,j

Op(1)
Op(1) Op(nj)
Op(1) Op(nj) Op(n2
j )
op(1)

op(1) Op(nj) Op(nj)



= 





















Summing over the blocks j = 1, 2, · · · , J, for the case of equal cluster sizes nj = n, as n, J → ∞,

the log-determinant is

log |Iρρ| = (q1q2 + 1) log(nJ) + q∗

2 log(n2J) + q∗

1 log(J) + Op(1)

∗

= (q

+ 1) log(J) + (2q

∗
2 + q1q2 + 1) log(n) + Op(1)

where q∗ = q(q +1)/2 and q∗

r = qr(qr +1)/2 (r = 1, 2). Note the dramatic increase in the coeﬃcient

for log(n) compared to Equation 19.

Combining the two blocks of the information matrices, we have

BICE = −2 log f (y| ˆϑ) + K1 log(n) + K log(J),

(23)

16

where K = p + q∗ + 1 is the total number of parameters, K1 = p1 + 1 + q1q2 + 2q∗
p2 = dim {C(Xj) ∩ C(Z1,j)}, and q∗

2 = q2(q2 + 1)/2.

2, p1 = p − p2,

The discussions above assume that some of the random eﬀects in the model have zero variance

in the population and all the remaining random eﬀects are not redundant. It may also happen

that none of the random eﬀects has zero variance but a certain linear combination of them does,

resulting in rank deﬁciency of Ψ. In this case, a proper linear transformation of the columns of

Zj and the random eﬀects βj can be employed to turn this case into the case we just discussed
above. Now in Equation 23 we have K1 = p1 + 1 + q1q2 + 2q∗

2 with q1 = rankΨ, q2 = q − q1,

p2 = dim {C(Xj) ∩ C(Z1,jU1)}, where the columns of the q × q1 matrix U1 are the eigenvectors of

Ψ corresponding to non-zero eigenvalues.

Although we handled the situation of a singular Ψ above, more diﬃcult situations may arise

where Ψ is close to singular.

In these situations the large sample behavior of the information

matrix would lie between those discussed in Sections 3 and 4. In particular, the coeﬃcient K1

will be greater than that stipulated below Equation 20 but smaller than that stipulated above

Equation 23.

An additional practical factor that determines the ﬁnite sample performance of BICE is the

relative size of Ψ and σ2S−1

ZZ,nj/nj. As evident from the majority of equations above, BICE as a

large sample approximation was derived assuming that Ψ dominates σ2S−1

ZZ,nj/nj. This may not

be the case if the cluster size nj is small or if the error variance σ2 is large relative to ΨSZZ,nj.

5 Numerical Demonstration

In this numerical demonstration, we study the ﬁnite sample performance of Equation 21, in par-

ticular how the value K1 in ﬁnite samples may deviate from its designated value in Section 3.

17

5.1 Study Design

A two-level random-intercept-slope model with balanced cluster sizes (nj = n) was considered as

a data-generating model with the following speciﬁcation:

yij = β + β1xij + β2xj + b0j + b1jxij + ǫij,

(i = 1, 2, · · · , n; j = 1, 2, · · · , J)

(24)

where β, β1, and β2 are ﬁxed eﬀects, and the random eﬀects (b0j, b1j)′ ∼ MV N(0, Ψ) where the

variance of b0j is τ 2

0 , the variance of b1j is τ 2

1 , and the covariance between b0j and b1j is τ01. The

random residual ǫij is assumed to follow N(0, σ2).

In the data-generating model, parameters were set as follows: β = 57.98, β1 = 1.93, β2 =

−14.57, σ2 = 42.78, τ 2

0 = 40.20, τ 2

1 = 21.58, and τ01 = −28.95. These values were chosen from

estimates of a two-level random-intercept-slope model reported in Kreft and De Leeuw (2002, pp.

49–50). The within-cluster covariate (xij) was generated with a normal distribution with mean

0 and standard deviation 2.07. The between-cluster covariate (xj), the random eﬀects (b0j and

b1j), and errors of within-cluster units (ǫ1j, ǫ2j, · · · , ǫnj) were generated from a joint (n + 3)-

variate normal distribution in such as way such that their sample mean vector and the sample

covariance matrix (with denominator J) match their population true values. This way the MLEs

of parameters will match their population true values and the computer program will yield the

information matrix A evaluated at the same ˆϑ, making it possible to study how log |A| changes

with J and n free from sampling variability.

Given the estimates reported in Kreft and de Leeuw (1998, pp. 49–50), the correlation be-

tween b0 and b1 is −0.983. As discussed earlier, this near perfect correlation results in a larger

coeﬃcient K1 of log(n) than stipulated under Equation 21. Thus, for Model A, additional correla-

tion true parameter values were considered to show the ﬁnite sample performance of BICE under

diﬀerent magnitudes of correlation between a random intercept and a random slope. The selected

18

magnitudes included −1.0, −0.8, −0.6, −0.4, −0.2 and 0.

Furthermore, as discussed above, the magnitude of σ2 aﬀects the behavior of BICE. Speciﬁcally,
−1
ZZ,nj /nj +Ψ)−1 smaller compared to the constant

a smaller value of σ2 makes the ﬁrst term in (σ2S

order second term and thereby BICE closer to its desired asymptotic value. Thus, in addition to

σ2 = 42.78 (which is comparable to τ 2

0 = 40.20), the two additional magnitudes, σ2 = 10 and

σ2 = 1, were considered. To summarize, 18 sets of true parameters for correlation and σ2 (6

magnitudes of correlation × 3 magnitudes of σ2) were chosen.

In addition to a two-level random-intercept-slope model (called Model A), a two-level random-

intercept model (called Model B) was also considered as a data-generating model to show the

behavior of BICE when only a random intercept was modeled. True parameters of Model B were

set as those of Model A except that τ 2

1 and τ01 are not present. As in Model A, the two additional

magnitudes, σ2 = 10 and σ2 = 1, were considered in Model B.

For Models A and B, varying multilevel designs with diﬀerent cluster sizes n and diﬀerent

numbers of clusters J were considered. The values of n and J were selected based on previous

research on MLM (e.g., Geldhof, Preacher, & Zyphur, 2014). These include n = 10, 20, and 40,

and J = 50, 100, 200, and 400. In total, there were 12 (3 × 4) multilevel designs having diﬀerent

combinations of n and J.

5.2 Expected Results

According to our derivations in Sections 3 and 4, BICE is a linear function of log(n) and log(J). To

investigate whether the coeﬃcients of log(n) and log(J) are consistent with the empirical values

obtained in this demonstration, the two terms of Equation 8, log |Iββ| and log |Iρρ|, are both

regressed on log(n) and log(J).

For both Models A and B, we expect that the coeﬃcient of log(J) is always 3 (the total number

19

of ﬁxed eﬀects) for log |Iββ|. The coeﬃcient of log(J) for log |Iρρ| should be the total number of

parameters in the covariance matrix. This is 4 for Model A and is 2 for Model B.

The coeﬃcient of log(n) is more complicated. The coeﬃcient K1 of log(n) was expressed below

Equations 21 and 23 in terms of the rank of Ψ and the overlapping number of column-space

dimensions between the ﬁxed-eﬀect design matrix Xj and random-eﬀect design matrix Zj (with

redundant random eﬀects removed). In both Models A and B, Xj is given by

1 xij xj
1 xij xj
...
...
...
1 xij xj








Xj = 





where the three columns correspond to the intercept, the within-cluster covariate and the between-

cluster covariate, respectively.

For Model B, Zj = 1n is a single column of 1s. The ﬁrst and third columns of Xj are in its

column space but the second column is not. This shows that the coeﬃcient of log(n) in log |Iββ|

should be 1. The coeﬃcient of log(n) in log |Iρρ| should also be 1, as shown in Equation 19. The

second row of Table 1 summarizes which parameters count towards which coeﬃcient in the two

blocks of the information matrix of Model B. The forms of three versions of BIC are also listed.

In practice, the coeﬃcients of log(n) are expected to be greater than 1 due to the presence of the
ZZ,nj /nj + Ψ)−1, but they will be closer to 1 as σ2 decreases.

ﬁrst term in (σ2S−1

Model A has two random eﬀects and the asymptotic behavior of the coeﬃcient of log(n)

depends on the rank of the 2 × 2 matrix Ψ. When the correlation between the two random eﬀects

is not −1, no random eﬀect is redundant, and all three columns of Xj are in the column space of

Zj (which contains columns 1 and 3 of Xj), so the coeﬃcient of log(n) should be zero for log |Iββ|.

The coeﬃcient of log(n) for log |Iρρ| should be 1, as in Model B. The ﬁrst row of Table 1 provides

a summary for Model A. In practice, the coeﬃcients of log(n) are expected to be greater than

20

these desired values but the deviations are expected to decrease as σ2 decreases.

In addition,

as the random eﬀect correlation decreases from 0 to −1, Ψ becomes closer to singular and the

coeﬃcients of log(n) are expected to increase and become closer to their values for a singular Ψ

discussed below.

When the random eﬀect correlation in Model A is −1, we have b0j = −b1j. In this case we can
reparametrize the random eﬀects as (b0j −b1j, b0j +b1j)′ and the new design matrix can be written as
Zj = [Z1,j, Z2,j] with Z1,j = (1 − x1j, 1 − x2j, · · · , 1 − xnj)′ and Z2,j = (1 + x1j, 1 + x2j, · · · , 1 + xnj)′.

Note that Z1,j is in the column space of Xj, so the overlapping number of dimensions is p2 = 1,

so p1 = p − p2 = 2, which is the coeﬃcient of log(n) of log |Iββ|. For log |Iρρ|, because q1 = q2 = 1

in this case, the coeﬃcient of log(n) is 2q∗

2 + q1q2 + 1 = 4.

5.3 Results

Figure 1 presents results for Model A. For a perfect correlation of −1, the regression coeﬃcients of

log(n) (circles for σ2 = 1, triangles for σ2 = 10, and squares for σ2 = 42.78 in Figure 1) for ﬁxed

and random eﬀects were close to expected values of K1 = 2 and K1 = 4, respectively. As expected,

it is observed empirically that the regression coeﬃcients of log(n) decrease as the random eﬀect

correlation and σ2 decrease. They become close to their desired values for a model with Ψ of full

rank (blue lines in Figure 1). For both the ﬁxed and random eﬀects in Model A, the regression

coeﬃcients of log(J) coincide with their desired values of 3 and 4.

For ﬁxed eﬀects in Model B, the regression coeﬃcients of log(n) were 1.323 (standard error

[SE]=0.121), 1.051 (SE=0.206), and 1.076 (SE=0.126) for σ2 = 42.78, σ2 = 10, and σ2 = 1, re-

spectively. These regression coeﬃcients were close to the derived value of K1 = 1. In addition, the

regression coeﬃcients of log(J) were 2.994 (SE=0.089), 2.928 (SE=0.150), and 2.987 (SE=0.092)

for σ2 = 42.78, σ2 = 10, and σ2 = 1, respectively, which were closed to the derived value of

21

K1 + K2 = 3 for the ﬁxed eﬀects in Model B. For random eﬀects in Model B, the regression coef-

ﬁcients of log(n) were 1.166 (SE=0.010), 1.084 (SE=0.006), and 1.060 (SE=0.004) for σ2 = 42.78,

σ2 = 10, and σ2 = 1, respectively, which were close to the derived value of K1 = 1 for the ran-

dom eﬀects in Model B. Furthermore, the regression coeﬃcients of log(J) were 2.000 (SE=0.008,

SE=0.004, and SE=0.003 for σ2 = 42.78, σ2 = 10, and σ2 = 1, respectively) and its expected

value (K1 + K2 = 2) were the same. To summarize, these results show the consistency between

the derived eﬀective sample size values and the empirical values.

6 Empirical Data Illustration

In this section, we illustrate the use of BICE using an empirical data set. The empirical data

set, popular.dat, was from Chapter 2 of Hox (2010) and it can be freely downloaded from

http://joophox.net/mlbook2/DataExchange.zip. The popular data set includes 2,000 stu-

dents from 100 classes (J = 100). Average class size is 20 (¯n = 20; ranged from 16 to 26, standard

deviation= 2.05). Each student belongs to one class, indicating that students (level 1) are nested

within classes (level 2). The dependent variable (popular) is a self-rated popularity scale ranging

from 0 to 10. Within-cluster covariates include a binary-coded gender variable and continuous self-

rated extraversion scores. For illustrative purposes, the contrast-coded gender variable (gender;

−1=boy, 1=girl) was chosen in the model below. Between-cluster covariate chosen was continuous

teacher experience in years (texpj). ICC based on an unconditional random-intercept model is

0.365 (= 0.702/(0.702 + 1.222)), which means that 36.5 % of the variance of popularity scores is

at the class level. Thus, the unconditional random-intercept model was considered as a baseline

model (Model 1 in Table 2).

We consider a two-level random-intercept-slope model (Equation 2.12 in Hox [2010]) based on

22

the following equation:

popularij = β + β1genderij + β2texpj + β3genderij × texpj + b0j + b1jgenderij + ǫij,

(25)

where β, β1, β2 and β3 are the ﬁxed eﬀects of intercept, within-cluster covariate genderij, between-

cluster covariate texpj and their cross-level interaction, b0j and b1j are the random intercept and

the random slope of within-cluster covariate genderij, and ǫij is the random residual. We assume
ǫij ∼ N(0, σ2) and (b0j, b1j)′ ∼ MV N(0, Ψ) where the variances of b0j and b1j are τ 2

0 and τ 2

1 , and

their covariance is τ01.

For the two-level random-intercept-slope model, there are six possible ﬁxed eﬀect models to be

compared:

• F1[null]: β1 = 0, β2 = 0, β3 = 0

• F2[gender]: β1 6= 0, β2 = 0, β3 = 0

• F3[gender,gender×texp]: β1 6= 0, β2 = 0, β3 6= 0

• F4[texp]: β1 = 0, β2 6= 0, β3 = 0

• F5[gender,texp]: β1 6= 0, β2 6= 0, β3 = 0

• F6[gender,texp,gender×texp]: β1 6= 0, β2 6= 0, β3 6= 0

In addition, there are two possible random eﬀect models to be compared:

• V1[random intercept]: σ2 6= 0, τ 2

0 6= 0, τ 2

1 = 0

• V2[random intercept&slope]: σ2 6= 0, τ 2

0 6= 0, τ 2

1 6= 0, τ01 6= 0

The objective of the current analysis is to simultaneously identify the important covariates that

correspond to the level-speciﬁc ﬁxed and random eﬀects among 12 candidate models (6 ﬁxed eﬀect

23

models × 2 random eﬀect models summarized in Table 2) based on BICE. In Table 2, parameters

counting towards K1 and K2 are listed for illustrative purposes. The following patterns should be

noted. First, the ﬁxed intercept parameter (β) counts towards K2 because it is associated with a

random intercept parameter. Second, the ﬁxed eﬀect of a within-cluster covariate genderij (β1)

and its interaction eﬀect with texpj count towards K1 in the random-intercept model because their

two columns in the design matrix Xj are not in the column space of the design matrix Zj, which

has a single column of 1s; however, they count towards K2 when the random slope of genderij

is present because their two columns in Xj are now multiples of the column of Zj for genderij.

Third, the ﬁxed eﬀect of a between-cluster covariate texpj is always counted for K2 as its column

in Xj is a multiple of 1’s.

The BICE is compared with the other two BIC calculations based on a total sample size N

and the number of clusters J, denoted by BICN and BICJ , respectively. Note that the intercept

exists in all 12 models, but is known to be nonzero. The BIC is based on the deviance (−2×

log-likelihood). The lmer function of the lme4 library (Bates, M¨achler, Bolker, & Walker, 2015)

was used to ﬁt the 12 models and to obtain the deviance.

the ML method (Goldstein, 1986;

Longford, 1987) is considered to be the most appropriate estimation method for information

criteria (Verbeke & Molenberghs, 2000). The problem with the ML method is that it tends to

underestimate variance components. This tendency is not limited to the residual variance and

gets worse as the number of ﬁxed eﬀects increase (e.g., Verbeke & Molenberghs, 2000). In such a

case, restricted maximum likelihood (REML; Patterson & Thompson, 1971) is recommended. In

the current applications, for all models we considered, the deviance from ML and REML was the

same and variance estimates from ML and REML diﬀered in the second or third decimal point.

Therefore, the deviance from ML was used in calculating BICs.

As shown in Table 2, the 12 candidate models were ranked diﬀerently across BICE, BICN , and

24

BICJ for Models 4-5 and Models 9-12. Of Models 4-5, BICE increased from Model 4 (F2+V2) to

Model 5 (F3+V1), whereas BICN and BICJ decreased from Model 4 to Model 5. Of Models 9-12,

all three BICs increased from the random intercept models (V1) to the random intercept & slope

models (V2). However, they suggested diﬀerent ﬁxed models: BICE and BICN suggested Model

9 (F5+V1), whereas BICJ suggested Model 11 (F6+V1). This example presents diﬀerent possible

results by diﬀerent kinds of BIC (BICE, BICN , and BICJ ).

7 Summary and Discussion

BIC is provided in popular statistical software for MLM. However, no consensus exists yet among

in the literature or in popular software on the calculation of BIC for MLM, posing a key problem

in the selection of ﬁxed and random eﬀects. In this paper, we derived the BIC’s penalty term for

both ﬁxed eﬀect and random eﬀect parameters in a two-level nested model. The proposed BICE

can be used to select among models that diﬀer in level-speciﬁc ﬁxed and random eﬀects in the

MLM applications.

In the derived BICE, the total penalty term in BIC is decomposed into two terms: (a) a term

with the log of average sample size per cluster whose multiplier involves the overlapping number

of dimensions between the column spaces of the random and ﬁxed eﬀect design matrices and

(b) the total number of parameters times the log of the total number of clusters. This result

is consistent with Pauler (1998)’s results for selecting among models that diﬀer only in their

ﬁxed-eﬀect parameters.

In addition, we studied the situation when a variance-covariance matrix of random eﬀects is

singular, giving analytical expression of the coeﬃcient of log(n) in BICE in this situation. We found

that in this situation the coeﬃcient is greater than its desired value with a nonsingular random

eﬀect variance-covariance matrix. This result is particularly useful when comparing models that

25

diﬀer not only in the number of ﬁxed eﬀects but also in the number of random eﬀects, as redundant

random eﬀects likely lead to a singular random eﬀect variance-covariance matrix.

Through a numerical demonstration, BICE was found to behave consistently with our theoreti-

cal predictions. Furthermore, the use of BICE is illustrated using a textbook example for selecting

among candidate models that have diﬀerent ﬁxed and random eﬀects. As illustrated, BICE can

be easily calculated by using deviance from software and by counting K1, K2, and sample sizes.

In this study, BICE for the two-level nested design is presented. It is left for a future study to

further explore the form of BICE in higher-level nested designs and for other complicated multilevel

designs (e.g., a cross-classiﬁed design, a longitudinal design with correlated errors).

26

References

Bates, D., M¨achler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-eﬀects mod-

els using lme4. Journal of Statistical Software, 67, 1–48. https://doi.org/10.1016/S0378-

3758(02)00336-1

Berger, J., Ghosh, J. K., & Mukhopadhyay, N. (2003). Approximations and consistency of Bayes

factors as model dimension grows. Journal of Statistical Planning and Inference, 112, 241–

258. https://doi.org/10.1016/S0378-3758(02)00336-1

Burnham, K. P., & Anderson, D. R. (2002). Model selection and multimodel

infer-

ence: A practical information-theoretic approach (2nd ed.). New York, NY: Springer.

https://doi.org/10.1007/b97636

Delattre, M., Lavielle, M., & Poursat, M. A. (2014). A note on BIC in mixed-eﬀects models.

Electronic Journal of Statistics, 8, 456–475. https://doi.org/10.1214/14-EJS890

de Bruijn, N. G. (1970). Asymptotic methods in analysis. Amsterdam: NorthHolland.

de Leeuw, J., & Meijer, E. (2007).

Introduction to multilevel analysis.

In J. de Leeuw &

E. Meijer (Eds.), Handbook of advanced multilevel analysis (pp. 1–75). New York, NY:

Springer. https://doi.org/10.4324/9780203848852

Geldhof, G. J., Preacher, K. J., & Zyphur, M. J. (2014). Reliability estimation in a

multilevel conﬁrmatory factor analysis framework. Psychological Methods, 19, 72–91.

https://doi.org/10.1037/a0032138

Goldstein, H. (1986). Multilevel mixed linear model analysis using iterative generalized least

squares. Biometrika, 73, 43–56. https://doi.org/10.1093/biomet/73.1.43

27

Goldstein, H. (2003). Multilevel statistical models (3rd ed.). New York, NY: Oxford University

Press [Distributor]. https://doi.org/10.1002/9780470973394

Hamaker, E. L., van Hattum, P., Kuiper, R. M., & Hoijtink, H. (2011). Model selection based

on information criteria in multilevel modeling. In J. J. Hox & J. K. Roberts (Eds.), Hand-

book for advanced multilevel analysis (pp. 231–255). Routledge/Taylor & Francis Group.

https://doi.org/10.4324/9780203848852

Hox, J. J. (2010). Multilevel analysis: Techniques and applications (2nd ed.) Mahwah, New

Jersey: IEA. https://doi.org/10.4324/9780203852279

Hox, J. J., Moerbeek, M., & van de Schoot, R. (2018). Multilevel analysis: Techniques and

applications (3rd ed.) New York, NY: Routledge. https://doi.org/10.4324/9781315650982

IBM Corp. (2020). IBM SPSS Statistics for Windows, Version 27.0. Armonk, NY: IBM Corp.

Jones, R. H. (2011). Bayesian information criterion for longitudinal and clustered data. Statistics

in Medicine, 30, 3050-3056. https://doi.org/10.1080/01621459.1995.10476572

Kass, & Vaidyanathan, S. K. (1992). Approximate Bayes factors and orthogonal parameters,

with application to testing equality of two Binomial proportions. Journal of the Royal Sta-

tistical Society. Series B, Methodological, 54(1), 129–144. https://doi.org/10.1111/j.2517-

6161.1992.tb01868.x

Kass, R. E., & Raftery, A. E. (1995). Bayes factors. Journal of the American Statistical Associ-

ation, 90, 773–795. https://doi.org/10.1080/01621459.1995.10476572

Kreft, I. G., & de Leeuw, J. (1998). Introducing multilevel modeling. SAGE Publications, Ltd

https://dx.doi.org/10.4135/9781849209366

28

Laird, N. M., & Ware, J. H. (1982). Random-eﬀects models for longitudinal data. Biometrics,

38, 963–974. https://doi.org/10.2307/2529876

Longford, N. T. (1987).

A fast scoring algorithm for maximum likelihood estimation

in unbalanced mixed models with nested random eﬀects. Biometrika, 74, 817–827.

https://doi.org/10.1093/biomet/74.4.817

Lorah, J., & Womack, A. (2019). Value of sample size for computation of the Bayesian infor-

mation criterion (BIC) in multilevel modeling. Behavior Research Methods, 51, 440–450.

https://doi.org/10.3758/s13428-018-1188-3

McCoach, D. B., & Black, A. C. (2008). Evaluation of model ﬁt and adequacy. In A. A. O’Connell

& D. B. McCoach (Eds.), Multilevel modeling of educational data (245-272). Charlotte, NC:

Information Age Publishing, Inc.

Merkle, E. C., You, D., & Preacher, K. J. (2016). Testing nonnested structural equation models.

Psychological Methods, 21, 151–163. https://doi.org/10.1037/met0000038

Molenberghs, G., & Verbeke G.

(2007).

Likelihood ratio,

score, and Wald tests

in a

constrained parameter

space.

The American Statistician,

61,

22–27.

https://doi.org/10.1198/000313007X171322

Muth´en, L. K., & Muth´en, B. O.

(1998-2015).

Mplus user’s

guide.

Sev-

enth Edition.

Los Angeles, CA: Muth´en & Muth´en.

Retrieved

from

https://www.statmodel.com/download/usersguide/Mplus

Patterson, H. D., & Thompson, R. (1971). Recovery of inter-block information when block sizes

are unequal. Biometrika, 58, 545–554. https://doi.org/10.2307/2334389

29

Pauler, D. K. (1998). The Schwarz criterion and related methods for normal linear models.

Biometrika, 85, 13-27. https://doi.org/10.1093/biomet/85.1.13

Raftery, A. E. (1995). Bayesian model selection in social research. Sociological Methodology, 25,

111-163. https://doi.org/10.2307/271063

SAS Institute Inc. (2015). SAS/STAT® 14.1 User’s Guide. Cary, NC: SAS Institute Inc.

Schwarz, G. (1978). Estimating the dimension of a model. Annals of Statistics, 6, 461–464.

https://doi.org/10.1214/aos/1176344136

Self, S. G., & Liang, K.-Y. (1987). Asymptotic properties of maximum likelihood estimators

and likelihood ratio tests under nonstandard conditions. Journal of the American Statistical

Association, 82, 605–610. https://doi.org/10.1080/01621459.1987.10478472

Snijders, T. A. B., & Bosker, R. J. (1999). Multilevel analysis: An introduction to basic and

advanced multilevel modeling. Thousand Oaks, CA: Sage.

Snijders, T. A. B., & Bosker, R. J.

(2012).

Multilevel analysis: An introduction

to basic and advanced multilevel modeling (2nd ed.)

Thousand Oaks, CA: Sage.

https://doi.org/10.1080/10705511.2013.797841

Stone, M. (1979). Comments on model selection criteria of Akaike and Schwarz. Journal

of the Royal Statistical Society (Series B), 41, 276–278. https://doi.org/10.1111/j.2517-

6161.1979.tb01084.x

Stram, D. O., & Lee, J. W. (1994). Variance components testing in the longitudinal mixed eﬀects

model. Biometrics, 50, 1171-1177. https://doi.org/10.2307/2533455

30

Stram, D. O., & Lee, J. W. (1995). Corrections: Variance components testing in the longitudinal

mixed eﬀects model. Biometrics 51, 1196. https://doi.org/10.2307/2533038

Tierney, L., & Kadane, J. B. (1986). Accurate approximations for posterior moments

and marginal densities.

Journal of the American Statistical Association, 81, 82–86.

https://doi.org/10.1080/01621459.1986.10478240

Verbeke G., & Molenberghs G. (2000). Linear mixed models for longitudinal data. New York,

NY: Springer. https://doi.org/10.1007/978-1-4419-0300-6

Vuong, Q. (1989). Likelihood ratio tests for model selection and non-nested hypotheses. Econo-

metrica, 57, 307–333. https://doi.org/10.2307/1912557

Weakliem, D. L. (1999). A critique of the Bayesian information criterion for model selection. So-

ciological Methods & Research, 27, 359–397. https://doi.org/10.1177/0049124199027003002

Whittaker, T. A., & Furlow, C. F. (2009). The comparison of model selection criteria when

selecting among competing hierarchical linear models. Journal of Modern Applied Statistical

Methods, 8, 173–193. https://doi.org/10.22237/jmasm/1241136840

Wolﬁnger, R. (1993). Laplace’s approximation for nonlinear mixed models. Biometrika, 80,

791–795. https://doi.org/10.1093/biomet/80.4.791

31

Table 1: Numerical Demonstration: Summary of Data-Generating Models and Calculations of K1 and K2 in
BICE with Comparisons to BICN and BICJ

3
2

Model

Fixed

Random

Model A
Model B

xij ,xj
xij ,xj

intercept,slope
intercept

Fixed Eﬀects
Par. for K1
[0]
β1[1]

Par. for K2
β, β1, β2[3]
β, β2[2]

Random Eﬀects
Par. for K1
[1]
[1]

σ
σ

2

2

τ

Par. for K2
2
2
0 , τ
1 , τ01[3]
2
τ
0 [1]

BIC
BICE
D + [1 log(N) + 6 log(J )]
D + [2 log(N) + 3 log(J )]

BICN
D + 7 log(N)
D + 5 log(N)

BICJ
D + 7 log(J )
D + 5 log(J )

Note. D indicates deviance (−2logf (y| ˆϑ)); Numbers in square brackets indicate K1 or K2; N = nJ is the total sample size

Table 2: Empirical Study: BICE with Comparisons to BICN and BICJ

3
3

Model
Model 1
Model 2
Model 3
Model 4
Model 5
Model 6
Model 7
Model 8
Model 9
Model 10
Model 11
Model 12

Fixed
F1[null]
F1[null]
F2[gender]
F2[gender]
F3[gender,gender×texp]
F3[gender,gender×texp]
F4[texp]
F4[texp]
F5[gender,texp]
F5[gender,texp]
F6[gender,texp,gender×texp]
F6[gender,texp,gender×texp]

Random
V1[random intercept]
V2[random intercept&slope]
V1[random intercept]
V2[random intercept&slope]
V1[random intercept]
V2[random intercept&slope]
V1[random intercept]
V2[random intercept&slope]
V1[random intercept]
V2[random intercept&slope]
V1[random intercept]
V2[random intercept&slope]

2

2

2

2

2

Par. for K1
[1]
[1]
[2]
[1]
[3]
[1]
[1]
[1]
[2]
[1]
[3]
[1]

σ
σ
β1, σ
σ
β1, β3, σ
σ
σ
σ
β1, σ
σ
β1, β3, σ
σ

2

2

2

2

2

2

2

β, τ

β, β1, τ

β, β1, β3, τ

β, β2, τ

β, β1, β2, τ

β, β1, β2, β3, τ

2
0 , τ

2
0 , τ

Par. for K2
2
β, τ
0 [2]
2
1 , τ01[4]
2
β, τ
0 [2]
2
1 , τ01[5]
2
β, τ
0 [2]
2
2
0 , τ
1 , τ01[6]
2
β, β2, τ
0 [3]
2
2
0 , τ
1 , τ01[5]
2
β, β2, τ
0 [3]
2
2
0 , τ
1 , τ01[6]
2
β, β2, τ
0 [3]
2
2
0 , τ
1 , τ01[7]

Deviance
6327.5
5750.5
5556.3
5551.5
5552.1
5549.5
6303.0
5730.0
5528.5
5524.9
5523.4
5520.6

BICE
6344.2(12)
5776.4(10)
5580.6(5)
5582.0(6)
5584.0(7)
5584.8(8)
6324.4(11)
5760.6(9)
5557.4(1)
5560.0(3)
5560.0(2)
5560.4(4)

BICN
6350.2(12)
5788.4(10)
5586.6(5)
5597.0(7)
5590.0(6)
5602.8(8)
6333.4(11)
5775.6(9)
5566.4(1)
5578.0(3)
5569.0(2)
5581.4(4)

BICJ
6341.2(12)
5773.4(10)
5574.6(5)
5579.0(7)
5575.0(6)
5581.8(8)
6321.4(11)
5757.6(9)
5551.4(2)
5557.0(3)
5551.0(1)
5557.4(4)

Note. Numbers in parentheses indicate rank order of the BICE , BICN , and BICJ from the smallest to the largest; Numbers in square brackets for the columns of Par. (parameters)
for K1 and Par. for K2 indicate K1 and K2, respectively.

Fixed Eﬀects

Random Eﬀects

Reg. Coeﬀ. for log(n)

)
n
(
g
o

l

r
o

f

.
f
f

e
o
C

.

g
e
R

)
J
(
g
o

l

r
o

f

.
f
f

e
o
C

.

g
e
R

2.50

2.25

2.00

1.75

1.50

1.25

1.00

0.75

0.50

0.25

0.00

4.00

3.75

3.50

3.25

3.00

2.75

2.50

2.25

2.00

)
n
(
g
o

l

r
o

f

.
f
f

e
o
C

.

g
e
R

4.50

4.25

4.00

3.75

3.50

3.25

3.00

2.75

2.50

2.25

2.00

1.75

1.50

1.25

1.00

−1.0

−0.8

−0.6

−0.4

−0.2

0.0

−1.0

−0.8

−0.6

−0.4

−0.2

0.0

Correlation Between a Random Intercept And a Random Slope

Correlation Between a Random Intercept And a Random Slope

sigma.2

1

10

42.78

sigma.2

1

10

42.78

)
J
(
g
o

l

r
o

f

.
f
f

e
o
C

.

g
e
R

5.00

4.75

4.50

4.25

4.00

3.75

3.50

3.25

3.00

Reg. Coeﬀ. for log(J)

−1.0

−0.8

−0.6

−0.4

−0.2

0.0

−1.0

−0.8

−0.6

−0.4

−0.2

0.0

Correlation Between a Random Intercept And a Random Slope

Correlation Between a Random Intercept And a Random Slope

sigma.2

1

10

42.78

sigma.2

1

10

42.78

Figure 1. Numerical Demonstration: Results for Model A (Random-Intercept-Slope Model)
Note. Circles (for σ2 = 1), triangles (for σ2 = 10), and squares (for σ2 = 42.78) indicate empirical
values; Lines indicate expected values.

34

 
 
 
 
 
 
 
 
 
 
 
 
