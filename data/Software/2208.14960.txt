Stationary Kernels and Gaussian Processes on Lie Groups
and their Homogeneous Spaces I: the Compact Case

Iskander Azangulov1 and Andrei Smolensky1
St. Petersburg State University

Alexander Terenin

University of Cambridge

Viacheslav Borovitskiy

ETH Zürich

Summary. Gaussian processes are arguably the most important model class in spatial
statistics. They encode prior information about the modeled function and can be used for
exact or approximate Bayesian inference. In many applications, particularly in physical
sciences and engineering, but also in areas such as geostatistics and neuroscience,
invariance to symmetries is one of the most fundamental forms of prior information one can
consider. The invariance of a Gaussian process’ covariance to such symmetries gives rise
to the most natural generalization of the concept of stationarity to such spaces. In this work,
we develop constructive and practical techniques for building stationary Gaussian processes
on a very large class of non-Euclidean spaces arising in the context of symmetries. Our
techniques make it possible to (i) calculate covariance kernels and (ii) sample from prior
and posterior Gaussian processes deﬁned on such spaces, both in a practical manner. This
work is split into two parts, each involving different technical considerations: part I studies
compact spaces, while part II studies non-compact spaces possessing certain structure.
Our contributions make the non-Euclidean Gaussian process models we study compatible
with well-understood computational techniques available in standard Gaussian process
software packages, thereby making them accessible to practitioners.

1.

Introduction

Gaussian processes are widely used as statistical models for inferring unknown functions,
particularly when data is scarce. Using Bayesian methods, Gaussian processes are able
to quantify uncertainty, thereby allowing what is known and what is unknown to be
balanced when modeling and making decisions. To maximize statistical eﬃciency, and
ensure their posterior error bars are appropriate and can be trusted, the Gaussian process
models we employ in practice should be adapted to their respective settings. Their prior
information should correctly encode the structure of the problem at hand.

Many problems, particularly in the physical sciences and engineering, require modeling
functions on non-Euclidean spaces. For example, spatial statistics on the surface of earth
(Jeong et al., 2017; Guinness and Fuentes, 2016), cosmology (Lang and Schwab, 2015) and
medical imaging (Andersson and Sotiropoulos, 2015) often call for Gaussian process models

1Joint ﬁrst author.

Preprint.

2
2
0
2

g
u
A
1
3

]
E
M

.
t
a
t
s
[

1
v
0
6
9
4
1
.
8
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
2

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

on the sphere, which is a very well-studied setting—see for instance Marinucci and Peccati
(2011). Other applications, however, require Gaussian process models on diﬀerent spaces:
for many of these, appropriate statistical tools are only partially developed, particularly
if the application demands careful consideration of symmetries. For example, control
parameter tuning and parametric policy adaptation in robotics (Jaquier et al., 2020,
2022), latent representation learning in neuroscience (Jensen et al., 2020) or modeling
unknown dynamics of physical systems (Borovitskiy et al., 2020; Hutchinson et al., 2021)
require models on various Lie groups and their homogeneous spaces. At present, these
applications tend to rely on ad-hoc heuristic or partially understood techniques, rather
than on a principled and comprehensive formal treatment.

In this two-part work, we study Gaussian process priors on a large class of non-
Euclidean spaces. We focus on stationary priors, whose covariance kernels are invariant
under symmetries of the space, generalizing the usual Euclidean notion of stationarity as
shift-invariance. We work with spaces whose group of symmetries is rich enough, including,
in part I, compact Lie groups such as the special orthogonal group SO(n) or the special
unitary group SU(n), and their homogeneous spaces such as the sphere Sn or the Stiefel
manifold V(k, n). In part II, we consider certain non-compact symmetric spaces such as
the hyperbolic spaces Hn and spaces of symmetric positive deﬁnite matrices SPD(n). We
now proceed to specify notation and more formally introduce the setting.

Notation We use bold italic letters (a, b) to denote ﬁnite-dimensional vectors in Rn, as
well as elements of the product space X n for a given set X. We use bold upface letters
(A, B) to denote matrices. If f : X → Y then for x ∈ X n we write f (x) to denote the
vector (f (x1), .., f (xn))(cid:62). Analogously, for a function k : A × B → C, for a ∈ An and
b ∈ Bm we write k(a, b) to denote the matrix with entries k(a(cid:96), b(cid:96)(cid:48)) for 1 ≤ (cid:96) ≤ n and
1 ≤ (cid:96)(cid:48) ≤ m. We often write this as Kab = k(a, b). We use x to denote conjugation of
complex numbers. We denote the conjugate transpose of a matrix by A∗ = A(cid:62).

1.1. Kernels and Gaussian Processes
Let X be a set. We say that a stochastic process f indexed by X is a Gaussian process
if, for any ﬁnite set of inputs x ∈ X N , the random vector f (x) is multivariate Gaussian.
Every such process is determined by its mean function µ(·) = E(f (·)) and covariance
kernel k(·, ·(cid:48)) = Cov(f (·), f (·(cid:48))), so we write f ∼ GP(µ, k). We assume all Gaussian
processes we consider are real-valued, unless stated otherwise or apparent from context.
Assume yi = f (xi) + εi with ε ∼ N(0, Σ), and let x, y be the data. If f ∼ GP(0, k) is
the prior Gaussian process, then the posterior f | y is also a Gaussian process, whose
mean and covariance kernel are

E(f | y) = K(·)x(Kxx + Σ)−1y Cov(f | y) = K(·,·(cid:48)) − K(·)x(Kxx + Σ)−1Kx(·(cid:48))

(1)

where (·) and (·(cid:48)) denote arbitrary sets of evaluation locations. We will also use another
way of thinking about the posterior: using pathwise conditioning (Chiles and Delﬁner,
2009; Wilson et al., 2020, 2021). From this viewpoint, the posterior can be written

(f | y)(·) = f (·) + K(·)x(Kxx + Σ)−1(y − f (x) − ε)

ε ∼ N(0, Σ)

(2)

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

3

(a) Ground truth

(b) Mean

(c) Standard dev.

(d) Posterior sample

Fig. 1: We illustrate a regression problem on a real projective plane RP2, with a Matérn-
3/2 kernel in the sense of Section 4. Here and below we use the Boy’s surface immersion
of RP2 into R3 (Bryant, 1988), which is non-isometric. Regression is applied to model the
function y(x) = (cid:80)5
j=1 cos(dRP2(x, ξj)) where ξj are uniform samples on RP2. We show
the resulting posterior mean and standard deviation, and one posterior sample.

where equality is taken to be in distribution.

In order to perform statistical inference with Gaussian processes, a prior Gaussian
process, or a parametric family thereof, must be chosen. In the Euclidean setting, priors
given by stationary kernels are a widely-used choice, which we now discuss.

1.2. Stationary Kernels and Gaussian Processes in Euclidean Spaces
A kernel k taking inputs in Rn is called stationary if it is translation invariant, in the
sense that

k(x + c, x(cid:48) + c) = k(x, x(cid:48)),

∀c ∈ Rn.

In this case, there is a function k : Rn → R such that

k(x, x(cid:48)) = k(x − x(cid:48)).

(3)

(4)

A Gaussian process, similarly, is called stationary if its mean function is translation
invariant (hence is a constant, usually assumed zero) and its covariance kernel is stationary.
Stationary kernels are widely used in applications. This includes the widely-popular
family of Matérn kernels advocated by Stein (1999), which uses three interpretable
parameters: amplitude σ2 which controls variability, length scale κ which controls spatial
decay, and smoothness ν which controls diﬀerentiability of the process. The limiting case
as ν → ∞ of the Matérn family is arguably the single most popular kernel used, the
squared exponential (heat, Gaussian, RBF) kernel which induces an inﬁnitely diﬀerentiable
Gaussian process prior. We will study these kernels in more general settings: as a glimpse
of what we will be able to do, we illustrate Gaussian process regression with a Matérn
kernel on a real projective space, using the techniques of Section 4, in Figure 1.

Stationary kernels have important properties. Bochner’s Theorem says that continuous
stationary kernels are in bijective correspondence with ﬁnite nonnegative measures via
the inverse Fourier transform, namely

k(x − x(cid:48)) =

(cid:90)

Rn

e2πiξ(cid:62)(x−x(cid:48)) dS(ξ) =

(cid:90)

Rn

(cid:16)

cos

2πξ(cid:62)(x − x(cid:48))

(cid:17)

dS(ξ)

(5)

4
Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy
where S is the spectral measure of k, and the second equality follows from k being
real-valaued. This both gives a way of deﬁning new kernels—by specifying their spectral
measures—and calculating them numerically. In particular deﬁning φ to be a vector of
complex exponentials, discretizing the integral using Monte Carlo we obtain

This further leads to the expression

k(x − x(cid:48)) ≈ φ(x)(cid:62)φ(x(cid:48)).

f (·) ≈

L
(cid:88)

l=1

wlφl(·)

wl ∼ N(0, 1)

(6)

(7)

for approximating the Gaussian process itself. This enables one to eﬃciently draw
approximate samples from the prior, and transform them into approximate posterior
samples via (2) by plugging in the approximate prior in place of f (·) and f (x).

The vector φ is not uniquely determined: one choice is to use sines and cosines

φ2l−1(x) = σ

(cid:114) 2
L

cos(2π(cid:104)ξl, x(cid:105))

φ2l(x) = σ

(cid:114) 2
L

sin(2π(cid:104)ξl, x(cid:105))

ξl ∼

S
σ2

(8)

for l ∈ 1, . . . , L/2 and where σ2 = S(Rn). Observe that, here, sines and cosines come in
pairs: each sample from the spectral measure corresponds to exactly two functions used
in the approximation. An alternative choice is to use only cosines, but add a random
phase

φl(x) = σ

(cid:114) 2
L

cos(2π(cid:104)ξl, x(cid:105) + βl)

ξl ∼

S
σ2

βl ∼ U(0, 2π)

(9)

for l ∈ 1, . . . , L and σ2 = S(Rn). An important advantage of φ in eqs. (8) and (9) over the
complex exponentials we begun with is their real-valuedness. General analogs of Bochner’s
theorem and Fourier feature expansions similar to (8) and (9) will be the cornerstone of
our considerations in the geometric settings we study.

1.3. Previous Work and Contributions
Recently, authors in the statistics and machine learning communities have begun exploring
generalizations of Gaussian process models to non-Euclidean settings—and, in particular
to Riemannian manifolds, of which the spaces studied in this work are special cases.

The ﬁrst diﬃculty here occurs in deﬁning a positive semi-deﬁnite covariance kernel to
begin with. For instance, Feragen et al. (2015) have shown that, for a Riemannian manifold
X with geodesic distance d, if one generalizes the widely used squared exponential kernel
naïvely by substituting the Euclidean distance with d, then the obtained expression

σ2 exp

(cid:18)

−

d(x, x(cid:48))2
2κ2

(cid:19)

(10)

will be positive semi-deﬁnite for all κ > 0 if and only if X is isometric to a Euclidean
space. This approach is therefore a technical disaster in need of alternatives.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

5

One alternative, pursued by Lindgren et al. (2011) and Borovitskiy et al. (2020) and
mostly restricted to compact manifolds, involves deﬁning Riemannian Gaussian processes
using stochastic partial diﬀerential equations. A key result in this setting is that the
kernels of certain such processes admit manifold Fourier feature expansions

k(x, x(cid:48)) = σ2

∞
(cid:88)

j=0

S(λj)fj(x)fj(x(cid:48))

(11)

where (λj, fj) are eigenpairs of the Laplace–Beltrami operator −∆, and S(λj) can be
viewed as the generalized spectral measure—now supported on the nonnegative integers.
The upside of this approach is that, in principle, it allows one to compute covariance
kernels without needing to solve stochastic partial diﬀerential equations. The downside
is that computing the eigenpairs analytically or numerically is for many manifolds a
non-trivial problem in its own right. One can observe that (11) coincides with various
explicit expansions known for spheres and tori, derived from Bochner-type symmetry-
based considerations, rather than from diﬀerential equations. This suggests that to build
a deeper understanding, one should also study these phenomena from the perspective of
stationarity under group action. This will be the starting point for our work. For instance,
when viewed through an appropriate lens, in part I of this work we present techniques to
bypass or solve the problem of ﬁnding Laplace–Beltrami eigenpairs for a large class of
compact Riemannian manifolds.

If we set S(λ) = e−λt in (11), the obtained expression coincides with the heat kernel
(also known as the diﬀusion kernel ), the fundamental solution of the heat equation, which
generalizes the squared exponential kernel in a sound manner, without incurring the
problems of geodesic-based approaches such as (10) (Grigoryan, 2009). This kernel has
been studied by many authors in diﬀerent speciﬁc settings (Laﬀerty et al., 2005; Kondor,
2008; Zhao and Song, 2018), and is a landmark target of development for our work. Niu
et al. (2019) and Ye et al. (2020) suggest a general approach to approximate heat kernel’s
values by simulating random walks, leveraging connections between the heat equation and
Brownian motion. While this approach can work, it is also a computationally-expensive
method-of-last-resort, since it can converge slowly and is not guaranteed to give a positive
semi-deﬁnite kernel for ﬁnite samples. We develop diﬀerent techniques that simultaneously
apply to more general kernels, including analogs Matérn kernels, which are central to our
work, and obtain approximations which are guaranteed positive semi-deﬁnite.

We begin with an abstract description of stationary Gaussian processes on a Riemannian
manifold X acted on by a suitably well-behaved Lie group G, given by Yaglom (1961)
at the dawn of stochastic process theory. This description relies on certain far-reaching
generalizations of harmonic analysis built upon the notions of representation theory. We
develop this abstract description into a fully-accessible computational tool suitable for
day-to-day statistical practice. We do this by making Yaglom’s abstract expressions
constructive: speciﬁcally, we bring together and synthesize various theory and techniques to
develop computational methods for statistical inference based on representation-theoretic
expressions. This includes the following classes of approximations.

(a) Algorithms for pointwise kernel evaluation, with automatic diﬀerentiation support.
(b) Algorithms for eﬃciently drawing sample paths, both from priors and posteriors.

6

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

These algorithms approximate stationary kernels by linear combinations of functions
which depend only on the given space, and admit closed-form expressions arising from
algebraic considerations. The coeﬃcients in these linear combinations depend on the
particular kernel, but for the aformentioned heat and Matérn kernels can be computed
exactly. Our sampling routines rely on the same quantities, and additionally require only
that one can sample uniformly on the space of interest.

Together, these algorithmic primitives provide practitioners with all of the tools needed
to deﬁne Gaussian processes for spatial models (Cressie, 1992) and decision-making
algorithms such as Bayesian optimization (Frazier, 2018), along with primitives for
constructing vector-valued processes (Hutchinson et al., 2021) and other extensions. This
is a purely theoretical paper: for applications, we refer the reader to the aforementioned
works.

In total, our work makes it possible to run Gaussian process regression on a much
wider collection of manifolds admitting analytic descriptions than was previously practi-
cally available.2

2. Stationary Gaussian Processes under Group Action

Let X be a set, and let G be a group acting on X with group action (cid:46) : G × X → X. A
kernel is called stationary 3 if it satisﬁes

k(g (cid:46) x, g (cid:46) x(cid:48)) = k(x, x(cid:48))

(12)

for all g ∈ G and all x, x(cid:48) ∈ X. Unless otherwise stated, we assume that k is real valued
and continuous. From this, one can easily see that if f ∼ GP(0, k) has a stationary kernel,
then the processes f (g (cid:46) ·) and f (·) have the same distribution. In this case, we say that
f is stationary. Without loss of generality, we work with processes with zero mean. We
now introduce the key results of Yaglom (1961) for diﬀerent classes of spaces—these are,
eﬀectively, far-reaching generalizations of the Bochner’s theorem.

2.1. Lie groups
A Lie group (G, •) is a group which is also a smooth manifold. We focus on the case
where G acts on itself from both the left and the right, and defer the case where only
one of these actions is present to Section 2.2. This falls into the general notion of
stationarity introduced earlier by considering the product group G × G acting on the set
G by (g1, g2) (cid:46) x = g1 • x • g−1

2 . In that case, for (g1, g2) ∈ G × G, we have

k((g1, g2) (cid:46) x, (g1, g2) (cid:46) x(cid:48)) = k(g1 • x • g−1

2 , g1 • x(cid:48) • g−1

2 ) = k(x, x(cid:48)).

(13)

Kernels (and general functions) that satisfy this are called bi-invariant. Letting e ∈ G be
the identity element, we can deﬁne a single-argument function k : G → R such that

k(x1, x2) = k(x−1
2

• x1, e) = k(x−1
2

• x1) = k(x1 • x−1
2 )

(14)

2We also provide a prototypical software implementation, available at: https://github.com

/imbirik/LieStationaryKernels.

3Note that the term homogeneous is also used in the literature, notably by Yaglom (1961).

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

7

which directly generalizes the one-argument notion of the Euclidean case.

We will need notions and results from the representation theory of compact Lie groups.
The idea of representation theory is to study the structure of a group G by studying how
it can be instantiated as the group of transformations of some vector space, which is often
more concrete and easier to understand. More formally, a representation π : G → GL(V )
is a homomorphism from G to the general linear group, consisting of bijective linear
transformations of a (complex) vector space V . A representation π is called unitary if
its range consists of unitary matrices. Representations that do not have any invariant
subspaces except {0} and V , and therefore cannot be decomposed into a direct sum of
smaller representations, are called irreducible.

We work with smooth representations of compact Lie groups. In the setting at hand,
there are at most a countable number of irreducible unitary representations—let Λ be an
index set in bijective correspondence with the set of such representations. We defer the
question of how to actually obtain such a set to subsequent sections. Let λ ∈ Λ be an
index. One can show that every smooth irreducible unitary representation

π(λ) : G → GL(Vλ)

(15)

is ﬁnite-dimensional, in the sense that the vector space Vλ is ﬁnite-dimensional. Let
dλ = dim Vλ. If we introduce a G-invariant inner product (cid:104)·, ·(cid:105)Vλ
and an orthonormal
basis e1, . . . , edλ in Vλ, we can deﬁne the matrix coeﬃcients of the representation π(λ) by

π(λ)
jk : G → C

jk (g) = (cid:10)π(λ)(g)ej, ek
π(λ)

(cid:11)

Vλ

(16)

where 1 ≤ j, k ≤ dλ. Let µG be the unique probabilistic Haar measure on G, which by
compactness always exists. By the Peter–Weyl Theorem—see Folland (1995) and Weil
(1940)—the matrix coeﬃcients form an orthogonal basis in the space L2(G, µG) with
(cid:107)π(λ)
dλ. Thus, f ∈ L2(G, µG) may be expressed in this basis in the form
dλπ(λ)
of an inﬁnite series using the functions
jk (·). This generalizes Fourier series to the
case of a compact topological group G. Deﬁne the character χ(λ) : G → C corresponding
to the representation π(λ) by

jk (cid:107)L2(G,µG) = 1/

√

√

χ(λ)(g) = tr π(λ)(g) =

dλ(cid:88)

j=1

π(λ)
jj (g).

(17)

Note that the character does not depend on a choice of a basis e1, . . . , edλ—a property
inherited from the trace operator tr. Having introduced the necessary notions, we are now
ready to present the representation-theoretic description of stationary Gaussian processes
on compact Lie groups.

Theorem 1. A Gaussian process f ∼ GP(0, k) on a compact Lie group G is stationary
with respect to left-and-right action of G on itself if and only if k is of form

k(g1, g2) =

(cid:88)

λ∈Λ

a(λ) Re χ(λ)(g−1

2

• g1)

(18)

where a(λ) ≥ 0 satisfy (cid:80)

λ∈Λ dλa(λ) < ∞. Moreover, for all λ, Re χ(λ) is positive-deﬁnite.

8

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

(a) Kernel

(b) Sample

(c) Sample

(d) Sample

Fig. 2: Illustration of the Matérn-3/2 kernel of Section 4, and three random samples from
its corresponding prior Gaussian process, on the circle group G = S1, which acts on itself
by rotation.

Proof. This follows mostly by specializing Theorem 2 of Yaglom (1961), which describes
complex-valued stationary processes on general topological groups, to the case where f is
real-valued and Gaussian. A detailed proof is given in Appendix E.

This is a powerful result: it says that to compute a general stationary kernel on a Lie
group numerically, it suﬃces to compute the coeﬃcients a(λ), and the characters χ(λ),
up to some order of truncation. To carry this out, we will need some way to represent
the index set Λ of irreducible unitary representations numerically. We describe methods
for doing so and the methods for eﬃcient approximate sampling from such processes
in Section 3. For the circle group G = S1 = SO(2) = SU(1), an illustration of such
a kernel, and samples of a corresponding process, computed using the techniques of
Section 3, is given in Figure 2. Before proceeding to these, we study the situation on
other spaces of interest.

2.2. Homogeneous Spaces of Compact Lie Groups
Let G be a compact Lie group, and let H be a closed, not necessarily normal subgroup
of G. We say that X = G/H is a homogeneous space.4 X consists of cosets of the form
g • H—the equivalence classes deﬁned in the natural manner, and the action of G on X is
deﬁned by g1 (cid:46) (g2 • H) = (g1 • g2) • H. For simplicity, where unambiguous we will often
drop the (·) • H component from notation, and write elements of G/H as x ∈ G/H.

Consider complex-valued functions f : G/H → C deﬁned on the homogeneous space.
It is not hard to see that such functions are in bijective correspondence with functions
˜f : G → C which are constant on all cosets, namely ˜f (g) = ˜f (g • h) for all h ∈ H.
Moreover, if we deﬁne the natural projection φ : G → G/H by φ : g (cid:55)→ g • H, then every
function f ∈ L2(G/H) can be written as ˜f ◦ φ ∈ L2(G). This shows homogeneous spaces
inherit square-integrability from the Lie group G of their automorphisms (Folland, 1995).

4In geometry a homogeneous space is a topological space X upon which some group G of
automorphisms acts continuously and transitively (Folland, 1995, Section 2.6). In this case, if we
ﬁx any point x ∈ X and deﬁne H to be the subgroup of G consisting of such elements g ∈ G that
g (cid:46) x = x, it can be proved that X is isomorphic to G/H.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

9

We can therefore expand a function f ∈ L2(G/H) using the L2(G)-orthonormal
bases introduced previously. In particular, every such function can be written as an
inﬁnite weighted sum of matrix coeﬃcients π(λ)
jk (·). On the other hand, not every function
constructed this way will be constant on the cosets, as all functions f ∈ L2(G/H) must
be. To get around this, we revisit the bases chosen in the vector spaces Vλ, which were
previously used to deﬁne the matrix coeﬃcients. For an f ∈ L2(G/H), let ˜f (g) = (f ◦φ)(g),
˜f ∈ L2(G). Write

˜f (g) =

(cid:88)

dλ

dλ(cid:88)

(cid:10) ˜f , π(λ)
jk

(cid:11)

L2(G)π(λ)

jk (g)

(19)

λ∈Λ

j,k=1

=

(cid:88)

λ∈Λ

(cid:90)

dλ

G

(cid:16) dλ(cid:88)

˜f (u)

j,k=1

π(λ)
jk (g)π(λ)

jk (u)

(cid:17)

dµG(u) =

(cid:88)

λ∈Λ

χλ(u−1g)

dλ ( ˜f ∗ χλ)(g).

(20)

where the calculation follows by interchanging sums and integrals. We therefore see
that the convolution with a character χλ corresponds to orthogonal projection onto the
subspace span π(λ)
jk ⊆ L2(G). This correspondence—between projections and convolution
against characters—will reappear in diﬀerent guises throughout this work. It is easy to see
that since ˜f is by deﬁnition constant on cosets, its convolution against a character is also
constant on cosets, thus ˜f ∗ χλ ∈ L2(G/H). Therefore to ﬁnd an orthogonal (generalized
Fourier) basis on L2(G/H), it suﬃces, for every λ, to ﬁnd an orthogonal basis of the
vector subspace of span π(λ)

jk that consists of functions constant on cosets.

Consider a function f ∈ span π(λ)

g ∈ G, h ∈ H in the basis π(λ)

jk . If we write the condition f (g • h) = f (g) for all
jk (·), we get

j,k=1 cjkπ(λ)

jk (·), where f is expressed as f (·) = (cid:80)dλ
(cid:32) dλ(cid:88)

dλ(cid:88)

(cid:33)

cjlπ(λ)

kl (h)

π(λ)
jk (g) =

cjkπ(λ)

jk (g).

dλ(cid:88)

(21)

j,k=1

l=1

j,k=1

Let C be a matrix with entries cjk. The above condition can be more compactly written
as πλ(h)C(cid:62) = C(cid:62) for all h ∈ H. Thus, the rows of C are invariant vectors of the
representation πλ that is restricted onto the subgroup H—note that these can be linearly
dependent. Let rλ be the dimension of the space of invariant vectors of πλ(cid:12)
(cid:12)H , and choose
an orthonormal basis e1, . . . , edλ of Vλ such that e1, . . . , erλ are invariant vectors of πλ(cid:12)
(cid:12)H .
Then, the rows of C are linear combinations of e1, . . . , erλ and thus the dimension of the
subspace of span π(λ)

jk that consists of functions constant on cosets is exactly rλdλ.

If π(λ)

jk are deﬁned using the preceding basis of Vλ, a direct computation shows that
π(λ)
jk , 1 ≤ j ≤ dλ, 1 ≤ k ≤ rλ are constant on cosets and thus form the orthogonal basis
we were originally looking for (Weil, 1940).

Using these notions, deﬁne the spherical functions to be the entries of the ﬁrst rλ
columns of the matrix π(λ)
jk for 1 ≤ j ≤ dλ and 1 ≤ k ≤ rλ, and deﬁne the zonal spherical
functions similarly, but with 1 ≤ j ≤ rλ and 1 ≤ k ≤ rλ. Note that not all spherical

10

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

(a) Kernel

(b) Sample

(c) Sample

(d) Sample

Fig. 3: Illustration of the Matérn-3/2 kernel of Section 4, and samples from its corre-
sponding prior Gaussian process, on the sphere G/H = SO(n)/ SO(n − 1) = S2.

functions are zonal, due to the diﬀering indices, and that zonal spherical functions are
constant on double cosets:

π(λ)
jk (h1 • g • h2) = π(λ)

jk (g)

h1, h2 ∈ H

1 ≤ j ≤ rλ

(22)

which can be seen by a direct computation. With these notions at hand, we are now
ready to describe stationary Gaussian processes on G/H.

Theorem 2. A Gaussian process f ∼ GP(0, k) on a compact homogeneous space G/H
is stationary with respect to the action of G if and only if k is of form

k(g1 • H, g2 • H) =

(cid:88)

rλ(cid:88)

λ∈Λ

j,k=1

jk Re π(λ)
a(λ)

jk (g−1

2

• g1)

(23)

where the coeﬃcients a(λ)
rλ × rλ satisfying (cid:80)
for each individual λ ∈ Λ, the corresponding sum over j, k is positive semideﬁnite.

jk ∈ R form symmetric positive semi-deﬁnite matrices A(λ) of size
jk are the zonal spherical functions. Moreover,

λ tr A(λ) < ∞, and π(λ)

Proof. Similar to before, this follows mostly by specializing Theorem 5 of Yaglom (1961),
which describes complex-valued stationary processes to the real-valued Gaussian case. A
detailed proof is given in Appendix E.

Theorem 2 simpliﬁes for symmetric homogeneous spaces, which possess certain addi-
tional properties that hold, for instance, for all homogeneous spaces of constant sectional
curvature. For such spaces, we study non-compact analogs of this result in part II of this
work. For symmetric spaces, rλ ≤ 1, thus every representation of G corresponds to at most
one zonal spherical function π(λ)
11 . The matrix A(λ), then, simpliﬁes into a scalar similar
to the one which appeared in the Lie group setting. This occurs, for instance, on spheres
Sn = SO(n)/ SO(n − 1) and Grassmann manifolds Gr(n, r) = O(n)/(O(r) × O(n − r)),
including projective spaces RPn as a special case. We illustrate a heat kernel on the
sphere, and samples of the corresponding process, in Figure 3.

Theorem 2 can also be used to give a description of left-invariant kernels on Lie groups,

complementing the preceding results on bi-invariant kernels.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

11

Corollary 3. Every left-invariant but not necessarily bi-invariant kernel on a compact
Lie group G can be expressed according to (23), with rλ = dλ.

Proof. Letting H = {e} be the trivial group, the claim is immediate from Theorem 2.

Note that any stationary positive semideﬁnite function k on a homogeneous space

G/H induces a positive semideﬁnite function

k(g) = k(g • H, e • H) = k(g1 • H, g2 • H)

g−1
2 g1 = g

over the group G which is constant on all double cosets H • g • H, namely

k(h1 • g • h2) = k(g)

(24)

(25)

for g ∈ G and h1, h2 ∈ H. Conversely, any positive semideﬁnite function on G constant
on all double cosets H • g • H induces a positive semideﬁnite kernel on the homogeneous
space G/H.5

3. Computational Techniques for Stationary Gaussian Processes

We now develop computational techniques for working with stationary Gaussian processes
described in the preceding section. Working with the posterior mean, posterior covariance,
and pathwise conditioning expressions of Section 1.1 involves two key computational
primitives: (a) evaluating the covariance kernel k(·, ·) pointwise, and (b) eﬃciently
sampling from the prior f (·).6
In general, (a) and (b) need to be performed in an
automatically-diﬀerentaible manner, for instance to optimize model hyperparameters
using maximum likelihood, or diﬀerentiate the prior density in Hamiltonian Monte Carlo.
Assuming the scaling coeﬃcients a(λ) or the scaling matrices A(λ) are a priori ﬁxed,
Theorems 1 and 2 oﬀer avenues for evaluating k(·, ·) and, with some additional work,
approximately sampling f (·). This can be achieved by truncating the respective inﬁnite
series to the desired accuracy. To do so, one must be able to traverse the index set Λ:
we study this in Section 3.1. For pointwise kernel evaluation, one must also compute
the characters χ(λ) in the Lie group case, and the zonal spherical functions π(λ)
j,k in the
homogeneous space case: we study this in Section 3.2.

For sampling, in Section 3.3 we develop a technique we term generalized random phase
Fourier features that allows eﬃcient sampling using only the aforementioned quantities
and random samples from the manifold’s Haar measure. Moreover, it allows—if needed—
one to compute the Karhunen–Loève basis in terms of the characters or zonal spherical
functions, respectively.

With these quantities at hand, all that remains is to obtain the scaling coeﬃcients a(λ)
or scaling matrices A(λ), which are kernel-dependent. We study these for speciﬁc kernel
classes in Section 4.

5Note that k should only represent a left-invariant kernel.
2 g1) = k(g1g−1

In particular, this means that
2 ) is not necessarily true for all g1, g2 ∈ G and that these kernels do not fall

k(g−1
under the assumptions of Theorem 1 of the preceding section.

6For a given set of evaluation locations, f can be sampled by forming and factorizing the kernel
matrix at cubic cost with respect to the number of evaluation locations: we use the term eﬃcient
sampling to refer to sampling f approximately without these costs.

12

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

3.1. Enumerating Representations of Compact Lie Groups
Both for (approximate) pointwise kernel evaluation and for sampling on compact Lie
groups and their homogeneous spaces we will need a way to enumerate the set Λ of
irreducible unitary representations. This is a central question of the representation theory.
We now sketch a practical approach to doing so.

Every compact Lie group G contains a connected abelian Lie subgroup, which is
isomorphic to a torus—call the maximal (by inclusion) of these subgroups maximal tori.
All maximal tori have the same dimension and are conjugate to one another, in the
sense that if T (1), T (2) ⊆ G are two maximal tori, then there exists g ∈ G such that
T (1) = g−1 • T (2) • g. Moreover, every element of G is conjugate to an element of a given
maximal torus—for example, every unitary matrix which is an element U ∈ G = U(d) is
diagonalizable by a unitary transformation, i.e. U = V DV −1 where D is an element of
the torus of diagonal unitary matrices and V ∈ U(d).

Representations of G can be therefore be studied by studying their relationship with
representations on the torus, which are simpler. Speciﬁcally, on an m-dimensional torus
Tm, the standard theory of Fourier analysis enables one to express a suitably regular
function f : Tm → C as an inﬁnite sum

f (x) =

(cid:88)

n∈Zm

cne2πi(cid:104)n,x(cid:105) =

(cid:88)

n∈Λ

cnπn(x)

(26)

which we have expressed in two ways—analytic, and representation-theoretic. In the
expression above Λ = Zm and πn : Tm → T ⊆ GL(C1) are the irreducible unitary
representations, which on a torus are one-dimensional and can be explicitly written
as complex exponentials. This establishes a bijective correspondence between such
representations and Fourier basis functions, at least as long as one studies the torus.

Since every compact Lie group contains a maximal torus, this gives us information
about representations on more general Lie groups. When restricted to such a torus,
a representation of G splits into a sum of one-dimensional irreducible representations,
parametrized by tuples of integers, which are called the weights of the representation. One
can show these tuples, and the original representation on G, are both uniquely determined
by a speciﬁc weight called the highest weight. By mapping the set of highest weights with
a linear transform, one obtains the set of signatures.

Theorem 4. The set of irreducible unitary representations of G is in explicit bijective
correspondence with the set of signatures Λ ⊆ Zm, where m is the dimension of T .

Proof. Appendix A.

Henceforth, we use Λ to refer to the set of signatures, which can be calculated explicitly
for most Lie groups. We provide explicit expressions for SO(n) and SU(n) in Appendix B.

3.2. Pointwise Kernel Evaluation
To evaluate a stationary kernel pointwise, we now study how to calculate the character
χ(λ) or zonal spherical functions π(λ)

jk corresponding to a signature λ ∈ Λ.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

13

(a) Torus

(b) Projective plane

(c) Sphere

Fig. 4: Values of the heat kernel k(•, ·) on T2, RP2, and S2. The torus T2 is equipped
with a ﬂat metric, so the depicted embedding is not isometric.

3.2.1. Calculating the Characters of Lie Groups
To calculate the characters of a compact Lie group G, we will use the observations that (i)
every element of G is conjugate to an element of a ﬁxed maximal torus T , (ii) characters
are conjugation-invariant, and (iii) on a maximal torus, they admit an explicit description
via the Weyl character formula.

Theorem 5. Every character χ(λ) with signature λ can be expressed as

χ(λ)(g) = χ(λ)(t) =

P1(t)
P2(t)

t = ˜g−1 • g • ˜g

(27)

where t ∈ T is an element of a maximal torus conjugate to g. For a ﬁxed identiﬁcation
of T with Tm ⊆ Cm, P1 and P2 are explicit polynomials with respect to the variables
z1, . . . zm, z1, . . . , zm of Tm. Moreover, the number of terms in P1, P2 does not grow
with λ.

Proof. This is a reformulation of Fegan (1991, Theorem 9.9)—see Appendix C.

To ﬁnd t, one employs techniques that depend on the group. In many cases, such as
SU(n) or SO(2n + 1), this reduces to ﬁnding the eigenvalues of g. Additionally, for any
groups, the polynomials P1 and P2 can often be rewritten as certain determinants of order
dim T , or short sums thereof. In cases where P2 = 0, the ratio should be understood as a
limit when the denominator approaches zero, for instance when g has repeated eigenvalues.
This is not an issue, since one can show that the denominator is always a divisor of the
numerator, so the ratio P1
is itself a polynomial. Further details on these expressions can
P2
be found in Appendix C, and explicit expressions for SU(n) and SO(n) can be found in
Appendix D.

3.2.2. Calculating the Zonal Spherical Functions of Homogeneous Spaces
The class of homogeneous spaces is very general, and thus a uniﬁed treatment similar to
the Lie group setting is more diﬃcult. Consequently, the most eﬃcient ways to compute
zonal spherical functions tend to involve space-speciﬁc considerations, even in symmetric

14

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

spaces which contain at most one zonal spherical function per signature. Nonetheless,
we present a general technique to express zonal spherical function on G/H in terms of
the characters on G, which we term generalized periodic summation by analogy with the
Euclidean case. Before presenting this, however, we consider homogeneous spaces where
case-speciﬁc descriptions of spherical functions are available, at least to some extent.

• Sn = SO(n)/ SO(n−1): the n-dimensional sphere. This is a symmetric homogeneous
space. The spherical functions on this space are called spherical harmonics, and are
very well-studied. In particular, zonal spherical harmonics can be explicitly written
in terms of the Gegenbauer polynomials.

• V(k, n) = SO(n)/ SO(n − k): Stiefel manifold. This is the space of all k-tuples of
orthonormal vectors in Rn. The spherical functions are called Stiefel harmonics,
and are studied by Gelbart (1974).

• RPn = SO(n)/ O(n−1): real projective space. This is the space of all one-dimensional
linear subspaces of Rn, and is a symmetric space. One can obtain the zonal spherical
functions by leveraging connections between this space and the sphere, or by rewriting
it as P(n) = O(n)/(O(1) × O(n − 1)), which is as a special case of a Grassmannian.

• Gr(k, n) = O(n)/(O(k) × O(n − k)): Grassmannians. This is the space of all k-
dimensional linear subspaces of Rn, and is a symmetric homogeneous space. Spherical
functions for Grassmannians are described by Davis (1999a,b).

In cases where space-speciﬁc descriptions of spherical functions are available, eﬃcient
algorithmic techniques can often be constructed from them. We illustrate the values
of kernels deﬁned in Section 4, computed by means of such techniques, in Figure 4.
Unfortunately, many descriptions involve heavy mathematical machinery, and it can be
highly non-trivial to translate them into a practical algorithm. In cases where applications
merit it, we view the formulation of such algorithms as a promising avenue for future
work, and now return to the general case.

If the coeﬃcients matrices A(λ) = a(λ)I are multiples of the identity matrix, as will
be the case for the heat and Matérn kernels studied in Section 4, one can compute the
kernels on G/H in terms of the characters of G. The next claim shows how.
Theorem 6. Let f ∼ GP(0, k), where k is stationary and satisﬁes A(λ) = a(λ)I. Then

k(g1H, g2H) =

(cid:90)

H

kG(g1 • h, g2) dµH (h)

f (gH) =

(cid:90)

H

fG(g • h) dµH (h)

(28)

where µH is the Haar measure on H, and fG ∼ GP(0, kG) with

kG(g1, g2) =

(cid:88)

λ∈Λ

a(λ) Re χ(λ)(g−1

2

• g1).

(29)

Proof. Appendix E.

This generalizes the periodic summation idea in the Euclidean setting, which says that
a kernel on the torus can be obtained by starting with a kernel on Rd, and summing
over multiples of 2π. One can therefore compute such kernels on a homogeneous space
G/H by computing their analogs on the underlying Lie group G using the techniques of
Section 3.2.1, and averaging over uniform random samples from H.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

15

(a) Torus

(b) Projective plane

(c) Sphere

Fig. 5: Samples from a Gaussian process with heat kernel covariance, on T2, RP2, and S2.

3.3. Efﬁcient Sampling
Since a sample from a posterior Gaussian process can be obtained by transforming
prior samples into posterior samples using (2) we now study the problem of sampling
from prior Gaussian process f . Given the set of signatures Λ of Section 3.1, we can
form a prior sample from f by summing a sequence of processes f (λ) ∼ GP(0, k(λ))
where k(λ) = a(λ) Re(χ(λ)(g−1
• g1)) or its homogeneous space analog. We now introduce
techniques for eﬃciently sampling from such processes, which further allows one to
compute a Karhunen–Loève basis as a byproduct.

2

3.3.1. Generalized Random Phase Fourier Features
The key idea for constructing samples comes from the following observation.

Proposition 7. Let S be a measurable space, let µ be probability measure on S, and let
φj with j = 1, .., N be an L2(S, µ)-orthonormal system. Let K(x, y) = (cid:80)N
j=1 φj(x)φj(y).
Then for all x, y ∈ S we have

K(x, y) =

(cid:90)

S

K(x, u)K(y, u) dµ(u).

(30)

Proof. This follows by direct computation, given for completeness in Appendix E.

We can therefore Monte Carlo approximate the function K as

K(x, y) ≈

1
L

L
(cid:88)

l=1

K(x, ul)K(y, ul)

ul ∼ µ.

(31)

If f ∼ GP(0, K) then we have the approximation

f (x) ≈

1
√
L

L
(cid:88)

l=1

wlK(x, ul)

ul ∼ µ

wl ∼ N (0, 1).

(32)

Thus, starting from a covariance kernel of the form K(x, y) = (cid:80)N
j=1 φj(x)φj(y) for an
orthonormal system φj, we have constructed a family of random functions K(·, ul) which

16

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

enable us to approximately express the Gaussian process GP(0, K) in a form which is
obviously amenable to eﬃcient sampling.

If S = Td, and φj are sinusoids from the sine-cosine random Fourier features, then
K(x, ul) are exactly cosines with a random phase shift. We therefore say that ul is the
random phase and K is the phase function, and call this construction generalized random
phase Fourier features for general measure spaces, equipped only with a probability
measure µ. We illustrate samples from such processes, computed additionally using the
techniques of Section 4, in Figure 5. Note that the process (32) may fail to be stationary:
we examine this further in Section 3.3.4. We now consider spaces of interest.

3.3.2. Phase Functions and Eﬃcient Sampling for Lie Groups
If G is a Lie group, generalized random phase Fourier features enable us to sample from
approximate priors using only the characters. If χ(λ) is real-valued, namely Re χ(λ) = χ(λ),
then we let K(λ) = dλχ(λ), corresponding to φλ =
jk . Otherwise, note that
g → (π(λ))∗ is a unitary irreducible representation which is thus equal to π(λ(cid:48)) for
some λ(cid:48) ∈ Λ, λ(cid:48)
In this case
we associate the aggregate of
jk with φl, and further associate
dλχ(λ) + dλ(cid:48)χ(λ(cid:48)) = 2dλ Re χ(λ) with K(λ). With this, we can compute each of the terms
in (18) using only the characters, and the resulting approximation is always real-valued.
We therefore obtain

(cid:54)= λ and whose character χ(λ(cid:48)) obviously equals χ(λ).
√

dλ(cid:48)π(λ(cid:48))

jk and

dλπ(λ)

dλπ(λ)

√

√

f (g) ≈

1
√
L

(cid:88)

λ∈ ˜Λ

L
(cid:88)

l=1

w(λ)
l K(λ)(u−1

l

• g)

ul ∼ µG

w(λ)

l ∼ N

(cid:18)

0,

(cid:19)

.

a(λ)
dλ

(33)

Here, ˜Λ is a ﬁnite subset of Λ that corresponds to indices of the truncated sum and
µG is the probabilistic Haar measure on the group G. ˜Λ should be chosen so as not to
contain λ(cid:48) together with any λ except in the case λ = λ(cid:48). The size of ˜Λ and value of L
control approximation quality.

3.3.3. Phase Functions and Sampling for Homogeneous Spaces
If G/H is a homogeneous space, the key question for deﬁning generalized random phase
Fourier features is how to correctly choose the function K in Proposition 7. A natural
idea is to associate each of zonal spherical function π(λ)
jk (y−1 • x) with a separate function
(cid:101)K(x, y): however, this is not the right thing to do, as we obtain

(cid:101)K(x, y) =

dλ(cid:88)

j=1

π(λ)
jk1

(x)π(λ)
jk2

(y)

(34)

for 1 ≤ k1, k2 ≤ rλ, which is not the form required by Proposition 7 unless k1 = k2.
Moreover, (cid:101)K and induced approximation f can be complex-valued. A more delicate
approach is therefore needed. Let a(λ)
be a set of coeﬃcients such that they form a
k1k2

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

17

symmetric positive semideﬁnite matrix whose precise form is to be determined later.
Deﬁne

K(x, y) =

rλ(cid:88)

k1,k2=1

a(λ)
k1k2

π(λ)
k1k2

(y−1 • x) =

rλ(cid:88)

k1,k2=1

a(λ)
k1k2

dλ(cid:88)

j=1

π(λ)
jk1

(x)π(λ)
jk2

(y)

(35)

and observe the following.

Proposition 8. The function K deﬁned by (35) satisﬁes

K(x, y) =

if and only if the matrix A = d−1
λ

Proof. Appendix E.

(cid:90)

G/H

(cid:0)a(λ)
k1k2

K(x, u)K(y, u) dµG/H (u)

(36)

(cid:1) is idempotent, namely A2 = A.

It follows that if the scaled coeﬃcient matrix A whose entries are d−1

is an
orthogonal projection, then generalized random phase Fourier features sampling is possible.
By positive semideﬁniteness, A has an eigendecomposition

k1k2

λ a(λ)

A = U(λ) diag

(cid:16)

α(λ)
1 , . . . , α(λ)
rλ

(cid:17)

U(cid:62)
(λ)

U(λ) =

(cid:16)

u(λ)
1 , . . . , u(λ)
rλ

(cid:17)

(37)

where α(λ)
basis of eigenvectors of A. Reinterpreting this matrix product as a sum, we can write

are non-negative eigenvalues, and the columns of U(λ) are an orthonormal

k

A =

rλ(cid:88)

k=1

(cid:62)

k u(λ)
α(λ)

k u(λ)
k
U(k)
(λ)

where U(k)

(λ) are orthogonal projection matrices. Now, deﬁne

˜K(λ)

k (x, y) =

rλ(cid:88)

k1,k2=1

dλU(k)

λ,k1k2

π(λ)
k1k2

(y−1 • x).

(38)

(39)

Recall that the map g → (π(λ)(g))∗ deﬁnes an irreducible unitary representation and
therefore is equal to π(λ(cid:48)) for some λ(cid:48) ∈ Λ. If λ is such that λ = λ(cid:48), then π(λ)
jk = π(λ)
(λ) being symmetric, implies ˜K(λ)
which, by virtue of U(k)
k (x, y) ∈ R. We have in this case

kj

rλ(cid:88)

k1,k2=1

a(λ)
k1k2

Re π(λ)
k1k2

(y−1 • x) =

rλ(cid:88)

k=1

α(λ)
k
dλ

˜K(λ)

k (x, y)

(40)

where ˜K(λ)

k

are real-valued phase functions which for λ = λ(cid:48) we rename to K(λ)
k .

18

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

If λ (cid:54)= λ(cid:48), to ensure the resulting samples are real-valued, write

rλ(cid:88)

a(λ)
k1k2

Re π(λ)
k1k2

(y−1 • x) +

rλ(cid:88)

k1,k2=1

a(λ(cid:48))
k1k2

Re π(λ(cid:48))
k1k2

(y−1 • x)

(41)

a(λ)
k1k2

π(λ)
k1k2

(y−1 • x) + a(λ(cid:48))
k1k2

π(λ(cid:48))
k1k2

(y−1 • x) =

rλ(cid:88)

k=1

α(λ)
k
dλ

2 Re ˜K(λ)

k (x, y)

(42)

k1,k2=1
rλ(cid:88)

=

k1,k2=1

where we used the fact that a(λ)
k1k2
that 2 Re ˜K(λ)

= a(λ)(cid:48)
k2k1

are real-valued phase functions which for λ (cid:54)= λ(cid:48) we rename to K(λ)
k .

k

Since terms with diﬀerent λ values in the generalized random phase Fourier feature
by (32), multiply by

approximation are independent, it suﬃces to sample from each K(λ)
(cid:113)

α(λ)
k /dλ, and reassemble the expression by summing terms. This gives the approximation

k

∈ R. From the preceding argument it is clear

f (g • H) ≈

(cid:88)

rλ(cid:88)

λ∈ ˜Λ

k=1

1
√
L

L
(cid:88)

l=1

l K(λ)
w(λ)

k (g, ul) w(λ)

l ∼ N

(cid:33)

(cid:32)

0,

α(λ)
k
dλ

u ∼ µG/H

(43)

where ˜Λ are the truncated signatures, and µG/H is the probabilistic Haar measure on G/H.
˜Λ should be chosen so as not to contain λ(cid:48) together with any λ unless of course λ = λ(cid:48).
The size of ˜Λ and the value of L control the quality of the approximation. If G/H is a
symmetric space, then rλ ≤ 1, and the above formulas simplify considerably.

3.3.4. Calculating a Karhunen–Loève Basis
It is not hard to see that matrix coeﬃcients or general spherical functions provide a
Karhunen–Loève basis for the Gaussian process, whose covariance is given by the respective
character or a combination of zonal spherical functions. However, the former are available
on a much smaller class of spaces compared to the latter. This was one of the main
reasons we explored how to sample from a stationary Gaussian process using only the
former. We now ask and answer a complementary question: given only the characters or
zonal spherical functions, is it possible to obtain a Karhunen–Loève basis?

Our strategy will be to ﬁnd a non-orthonormal basis, and Gram–Schmidt orthogonalize
it to obtain a Karhunen–Loève basis. This generalizes the approach of Dai and Xu (2013,
Section 1.3) from spheres to more general spaces. We begin from an abstract formulation.
Consider an orthonormal system φj in the space L2(S, µ), where (S, µ) is a measure space
and µ is a probability measure. Deﬁne, as before, the function K(x, y) = (cid:80)N
j=1 φj(x)φj(y).
Consider a set of N points xj in S and deﬁne the matrices

Mk =






φ1(x1)
...
φk(x1)

· · · φ1(xk)
. . .
· · · φk(xk)

...




 .

(44)

Lemma 9. There exists {x1, . . . , xN } ⊆ S such that det Mk (cid:54)= 0 for all 1 ≤ k ≤ N .

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

19

Proof. Appendix E.
Deﬁnition 10. A collection {xj}N

j=1 ⊆ S is a fundamental set if det MN (cid:54)= 0.

The existence of such sets, which are non-unique, is guaranteed by Lemma 9.

Proposition 11. The notion of a fundamental set does not depend on a speciﬁc or-
thonormal system system φj but rather only on the space span φj, i.e. on K.
Proof. We have

M∗

N MN =






K(x1, x1)
...
K(x1, xN )

· · · K(xN , x1)
. . .
· · · K(xN , xN )

...




 .

(45)

We have det MN (cid:54)= 0 if and only if det M∗
hence only on span φj.

N MN > 0. The latter depends on K only, and

Theorem 12. If xj is a fundamental set with respect to the system φj, then

span φj = span K(·, xj)

(46)

Proof. Appendix E.

Notice that (45) allows one to check whether a set of points is a fundamental set
without using the basis φj. Thus, one can ﬁnd a fundamental set by uniformly sampling a
set of points x1, . . . , xN ∈ G, and checking whether the determinant det M∗
N MN vanishes.
This is generally a rare event, so in practice it often suﬃces to sample once.

The basis K(xj, ·) is not necessarily orthonormal, but pairwise inner products of basis

functions can nonetheless be easily calculated using its special form, by writing

(cid:104)K(·, xj), K(·, xk)(cid:105)L2(S,µ) =

N
(cid:88)

n=1

φn(xj)φn(xk) = K(xk, xj) = K(xj, xk).

(47)

Here, we have used (30) and K(x, y) = K(y, x). One therefore obtains a Karhunen–Loève
basis by Gram–Schmidt orthogonalizing K(·, xj) at O(N 3) cost.

4. Computational Techniques for Heat and Matérn Kernels

In the preceding sections, we obtained Lie-theoretic and representation-theoretic ex-
pressions for stationary kernels and Gaussian processes under group action. In these
expressions, only the scaling factors a(λ) and A(λ), respectively, depend on the speciﬁc
kernel. We therefore study how to compute them for the Matérn and heat kernel classes:
our approach will be to deﬁne heat kernels ﬁrst, and extend to the Matérn class using
connections between them. To proceed, we need to turn our spaces into Riemannian
manifolds by deﬁning a metric tensor, for which we make the canonical choice.

Assumption 13. X is equipped with the metric tensor induced by its Killing form.

If X = G is a Lie group, this metric is automatically bi-invariant under the action of G
on itself from both sides. If X = G/H is a homogeneous space, this metric is the quotient
metric obtained from G, and is invariant under the canonical action of G on G/H.

20

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

4.1. Squared Exponential Kernels as Solutions of the Heat Equation
Before deﬁning the general Riemannian heat kernel, consider ﬁrst its Euclidean analog.
In this setting, it is widely known as the squared exponential, or Gaussian, or RBF kernel.
We denote it by k∞,κ,σ2. It has two positive numerical parameters κ and σ2, representing
its amplitude (variance) and length scale, respectively. For x, x(cid:48) ∈ Rn this kernel is
k∞,κ,σ2(x, x(cid:48)) = σ2e− (cid:107)x−x(cid:48) (cid:107)2
2t and σ2 =

Observe that if we let κ =

(48)

√

2κ2

1

.

P(t, x, x(cid:48)) = k∞,

(4πt)n/2 then, deﬁning
2t,(4πt)−n/2(x, x(cid:48))

√

(49)

we can express this kernel as the fundamental solution of the heat equation

∂P
∂t

(t, x, x(cid:48)) = ∆xP(t, x, x(cid:48))

P(0, x, x(cid:48)) = δ(x − x(cid:48))

(50)

where ∆x is the Laplacian acting on the x-argument, and the initial condition δ(x − x(cid:48)) ∈
S (cid:48)(X) is the Dirac delta function, understood as a vector in the Schwartz space S (cid:48)(X) of
tempered distributions. This gives the general way of deﬁning general analogs of squared
exponential kernels, which we call heat kernels, and will be our starting point.

The heat equation generalizes to a Riemannian manifold X under mild regularity
conditions, so long as ∆ is replaced with the Laplace–Beltrami operator. The Riemannian
heat kernel P can now be deﬁned as the fundamental solution of the Riemannian heat
equation. We also deﬁne its squared-exponential-like reparameterization by

k∞,κ,σ2(x, x(cid:48)) =

σ2
Cκ

P(κ2/2, x, x(cid:48))

(51)

where Cκ is a constant chosen depending on how one wishes to normalize the kernel’s
amplitude. For spaces where P(κ2/2, x, x) does not depend on x, such as homogeneous
spaces, a natural choice is Cκ = P(κ2/2, x, x). For other spaces, if X is compact, one
can choose Cκ = (cid:82)
X P(κ2/2, x, x) dvol(x). By general theory (Grigoryan, 2009), these
functions are positive deﬁnite kernels. At this stage, however, it is not clear whether
or not they are stationary, and if so, what the corresponding scaling coeﬃcients a(λ) or
scaling matrices A(λ) are. To understand this, we specialize to the settings at hand.

4.1.1. Compact Lie Groups
To understand how to express solutions of the heat equation in a more explicit manner,
we begin by connecting the representation-theoretic notions introduced previously with
spectral properties of the Laplace–Beltrami operator ∆.
Result 14. For every λ, the matrix coeﬃcients π(λ)
jl are eigenfunctions of −∆ corre-
sponding to the same eigenvalue αλ ≥ 0. Moreover, the eigenvalues αλ can be written

αλ = (cid:107)ρ(cid:107)2
where w is the highest weight of the representation with signature λ, (cid:107)g(cid:107)2
B = −B(g, g), B
is the Killing form of G, and ρ is the half-sum of positive roots of G—see Appendix A.

B − (cid:107)w + ρ(cid:107)2

(52)

B

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

21

(a) κ = 0.1

(b) κ = 0.25

(c) κ = 0.5

Fig. 6: Values of heat kernels on a projective plane RP2, with various length scales.

Proof. The ﬁrst part of the claim is well-known: we sketch a simple but instructive proof
in Appendix E. The second part is given in Fegan (1991, Theorem 10.6).

For technical details on these quantities, see Appendix A. With this connection
established, one can calculate an explicit expression for the heat kernel on G in the sense
of the heat equation using the representation-theoretic notions at hand.

Proposition 15. The heat kernel is stationary, and is given by

√

k∞,

2t,(4πt)−n/2(x, y) = P(t, x, y) =

(cid:88)

e−αλtdλχλ(y−1 • x).

(53)

Proof. Write out both sides of the heat equation in the basis (cid:8)√

λ∈Λ

(cid:9)

dλπλ
jk

λ,j,k.

Therefore, to evaluate heat kernels pointwise, and to sample from the corresponding

Gaussian processes, it suﬃces to apply the machinery of Section 3.

4.1.2. Homogeneous Spaces of Compact Lie Groups
We again begin by connecting representation-theoretic notions with spectral theory of ∆.
Result 16. The spherical functions π(λ)
jk on a compact homogeneous space G/H are
the eigenfunctions of −∆. Moreover, the eigenvalue corresponding to every spherical
function π(λ)
Proof. Appendix E.

jk , which by deﬁnition is also a matrix coeﬃcient of G, is given in (52).

We can use this to compute explicit expressions for the heat kernel on G/H.

Proposition 17. The heat kernel is stationary, and is given by
rλ(cid:88)

(cid:88)

√

k∞,

2t,(4πt)−n/2(x, y) = P(t, x • H, y • H) =

e−αλtdλ

π(λ)
jk (y−1 • x).

(54)

Proof. Write out both sides of the heat equation in the basis of spherical functions.

In homogeneous spaces, too, it therefore suﬃces to apply the machinery of Section 3.

We illustrate heat kernels computed in this manner in Figure 6.

λ∈Λ

j,k=1

22

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

4.2. Matérn Kernels
We now use the preceding notions to introduce Matérn kernels. On Rn, these constitute
(Rasmussen and Williams, 2006; Stein, 1999) a widely used three parameter family

kν,κ,σ2(x, y) = σ2 21−ν
Γ(ν)

(cid:18)√

2ν

(cid:107)x − y(cid:107)
κ

(cid:18)√

(cid:19)ν

Kν

(cid:19)

2ν

(cid:107)x − y(cid:107)
κ

(55)

with parameters σ2 > 0, κ > 0, and ν > 0 being the variance, length scale, and smoothness,
respectively. Here, Kν is the modiﬁed Bessel function of the second kind (Gradshteyn
and Ryzhik, 2014). We are interested in deﬁning them in settings beyond Rn.

We approach the problem by connecting Matérn kernels with squared exponential

kernels, and leveraging the preceding results. Still on Rn, as ν → ∞, we have

lim
ν→∞

kν,κ,σ2(x, y) = k∞,κ,σ2(x, y)

but this is not the only connection between these families of kernels. One can show

kν,κ,σ2(x, y) =

(2ν)ν
Γ(ν)κ2ν

(cid:90) ∞

0

uν−1e− 2ν

κ2 uk∞,

√

2u,σ2(x, y) du

= σ2 (2ν)ν(4π)n/2

Γ(ν)κ2ν

(cid:90) ∞

0

uν−1+n/2e− 2ν

κ2 uP(u, x, y) du.

(56)

(57)

(58)

This can be understood by observing that the spectral measure of the Matérn kernel,
which is a T distribution, can be written as a gamma mixture of Gaussians, which are the
spectral measure of the squared exponential kernel. Equations (57) and (58) are the kernel
analog of this: Appendix E gives a proof. More generally, we adopt this expression—after
dropping inessential constants and renormalizing—as the deﬁnition of a Matérn kernel.

Deﬁnition 18. Let X be a n-dimensional compact Lie group or a homogeneous space of
a compact Lie group, and let P(u, x, y) be the heat kernel. Deﬁne the Matérn kernel by

kν,κ,σ2(x, y) =

σ2
Cν,κ

(cid:90) ∞

0

uν−1+n/2e− 2ν

κ2 uP(u, x, y) du

(59)

where Cν,κ is chosen so that kν,κ,σ2(x, x) = σ2.

It is easy to check that such kernels are positive (semi)deﬁnite whenever the respective
squared exponential kernels are positive (semi)deﬁnite, regardless of the underlying
space X—see Appendix E. The main issue at this stage is that working with Matérn
kernels ostensibly requires one to evaluate an integral. We therefore study the expression
for the spaces at hand to understand simpliﬁcations, given as follows.

Proposition 19. The Matérn kernel on a compact Lie group G is given by

kν,κ,σ2(x, y) =

σ2
C(cid:48)

ν,κ

(cid:18) 2ν

(cid:88)

λ∈Λ

κ2 + aλ

(cid:19)−ν−n/2

dλχλ(y−1 • x)

(60)

where C(cid:48)

ν,κ is a normalizing constant which ensures that kν,κ,σ2(x, x) = σ2.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

23

(a) ν = 0.5

(b) ν = 1.5

(c) ν = 2.5

Fig. 7: Samples from Matérn Gaussian processes on RP2, with varying smoothness.

Proof. Appendix E.

Proposition 20. The Matérn kernel on a homogeneous space G/H is given by

kν,κ,σ2(x • H, y • H) =

σ2
C(cid:48)

ν,κ

(cid:88)

rλ(cid:88)

(cid:18) 2ν

λ∈Λ

j,k=1

κ2 + aλ

(cid:19)−ν−n/2

dλπ(λ)

jk (y−1 • x).

(61)

where C(cid:48)

ν,κ is a normalizing constant which ensures that kν,κ,σ2(x, x) = σ2.

Proof. Appendix E.

Note that the constants C(cid:48)

ν,κ in (61) and (60) can diﬀer, owing to the diﬀerent settings.
All these kernels can be computed using the techniques of Section 3. One can similarly
derive formulas for randomly sampling from Matérn priors. We illustrate such samples in
Figure 7. We conclude by verifying that these kernels satisfy the same diﬀerentiability
properties as the usual Euclidean Matérn class.

Theorem 21. For all ν > 0, Matérn kernels on compact Lie groups and their homoge-
neous spaces are positive deﬁnite and lie in the Sobolev space H ν+n/2. Thus, they are
continuous and possess continuous derivatives of all orders up to (cid:98)ν + n/2(cid:99).

Proof. Appendix E.

5. Conclusion

In this work, we derived a set of techniques that make it possible to perform Gaussian
process regression on a number of compact Riemannian manifolds which admit analytic
descriptions and are important in applications. This was done by combining and syn-
thesizing results from a variety of mathematical ﬁelds, including probability, statistics,
diﬀerential geometry, and representation theory. Our techniques yield approximations
which are essentially-closed-form algebraic expressions, and are guaranteed positive semi-
deﬁnite, making them simple and reliable to use. We hope our ideas enables practitioners
to deploy these models in new prospective applications.

24

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

Acknowledgments and Funding

The authors are grateful to Prof. Mikhail Lifshits for providing useful feedback. IA and
AS were supported by RSF grant No21-11-00047. VB was supported by an ETH Zürich
Postdoctoral Fellowship. We further acknowledge support from Huawei Research and
Development.

References

J. L. Andersson and S. N. Sotiropoulos. Non-parametric representation and prediction
of single-and multi-shell diﬀusion-weighted MRI data using Gaussian processes. Neu-
roimage, 122:166–176, 2015. Cited on page 1.

V. Borovitskiy, A. Terenin, P. Mostowsky, and M. Deisenroth. Matérn Gaussian Processes
on Riemannian Manifolds. In Advances in Neural Information Processing Systems,
pages 12426–12437, 2020. Cited on pages 2, 5.

T. Bröcker and T. Tom Dieck. Representations of compact Lie groups. Springer, 2013.

Cited on pages 27, 29.

R. L. Bryant. Surfaces in conformal geometry. In volume 48 of The mathematical heritage

of Hermann Weyl, pages 227–240, 1988. Cited on page 3.

J.-P. Chiles and P. Delﬁner. Geostatistics: Modeling Spatial Uncertainty. Wiley, 2009.

Cited on page 2.

N. Cressie. Statistics for Spatial Data. Wiley, 1992. Cited on page 6.

F. Dai and Y. Xu. Approximation theory and harmonic analysis on spheres and balls.

Springer, 2013. Cited on page 18.

A. Davis. Spherical functions on the Grassmann manifold and generalized Jacobi poly-
nomials – Part 1. Linear algebra and its applications, 289(1-3):75–94, 1999. Cited on
page 14.

A. Davis. Spherical functions on the Grassmann manifold and generalized Jacobi polyno-
mials – Part 2. Linear algebra and its applications, 289(1-3):95–119, 1999. Cited on
page 14.

E. De Vito, N. Mücke, and L. Rosasco. Reproducing kernel Hilbert spaces on manifolds:
Sobolev and diﬀusion spaces. Analysis and Applications, 19(3), 2020. Cited on page 43.

H. D. Fegan. Introduction to compact Lie groups. World Scientiﬁc, 1991. Cited on pages 13,

21, 27, 29, 33.

A. Feragen, F. Lauze, and S. Hauberg. Geodesic exponential kernels: when curvature
and linearity conﬂict. In Conference on Computer Vision and Pattern Recognition,
pages 3032–3042, 2015. Cited on page 4.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

25

G. B. Folland. A course in abstract harmonic analysis. CRC Press, 1995. Cited on pages 7,

8.

P. I. Frazier. Bayesian Optimization. In Recent Advances in Optimization and Modeling

of Contemporary Problems, pages 255–278. INFORMS, 2018. Cited on page 6.

S. S. Gelbart. A theory of Stiefel harmonics. Transactions of the American Mathematical

Society, 192:29–50, 1974. Cited on page 14.

I. S. Gradshteyn and I. M. Ryzhik. Table of Integrals, Series, and Products. Academic

Press, 7th edition, 2014. Cited on pages 22, 41, 42.

A. Grigoryan. Heat kernel and analysis on manifolds. American Mathematical Society,

2009. Cited on pages 5, 20.

J. Guinness and M. Fuentes. Isotropic covariance functions on spheres: Some properties
and modeling considerations. Journal of Multivariate Analysis, 143:143–152, 2016.
Cited on page 1.

M. Hutchinson, A. Terenin, V. Borovitskiy, S. Takao, Y. Teh, and M. Deisenroth. Vector-
valued Gaussian Processes on Riemannian Manifolds via Gauge Independent Projected
Kernels. Advances in Neural Information Processing Systems, 34:17160–17169, 2021.
Cited on pages 2, 6.

N. Jaquier, V. Borovitskiy, A. Smolensky, A. Terenin, T. Asfour, and L. Rozo. Geometry-
aware Bayesian Optimization in Robotics using Riemannian Matérn Kernels. In
Conference on Robot Learning, pages 794–805, 2022. Cited on pages 2, 41, 42.

N. Jaquier, L. Rozo, S. Calinon, and M. Bürger. Bayesian optimization meets Riemannian
manifolds in robot learning. In Conference on Robot Learning, pages 233–246, 2020.
Cited on page 2.

K. Jensen, T.-C. Kao, M. Tripodi, and G. Hennequin. Manifold gplvms for discovering non-
euclidean latent structure in neural data. Advances in Neural Information Processing
Systems, 33:22580–22592, 2020. Cited on page 2.

J. Jeong, M. Jun, and M. G. Genton. Spherical process models for global spatial statistics.

Statistical Sscience, 32(4):501, 2017. Cited on page 1.

R. Kondor. Group theoretical methods in machine learning. PhD thesis, Columbia Uni-

versity, 2008. Cited on page 5.

J. Laﬀerty, G. Lebanon, and T. Jaakkola. Diﬀusion kernels on statistical manifolds.

Journal of Machine Learning Research, 6(1), 2005. Cited on page 5.

A. Lang and C. Schwab. Isotropic Gaussian random ﬁelds on the sphere: regularity, fast
simulation and stochastic partial diﬀerential equations. Annals of Applied Probability,
25(6):3047–3094, 2015. Cited on page 1.

26

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

F. Lindgren, H. Rue, and J. Lindström. An explicit link between Gaussian ﬁelds and
Gaussian Markov random ﬁelds: the stochastic partial diﬀerential equation approach.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73(4):423–
498, 2011. Cited on page 5.

D. Marinucci and G. Peccati. Random ﬁelds on the sphere: representation, limit theorems
and cosmological applications. Cambridge University Press, 2011. Cited on page 2.

M. A. Naimark and A. I. Stern. Theory of group representations. Springer, 1982. Cited

on page 30.

M. Niu, P. Cheung, L. Lin, Z. Dai, N. Lawrence, and D. Dunson. Intrinsic Gaussian
processes on complex constrained domains. Journal of the Royal Statistical Society:
Series B (Statistical Methodology), 81(3):603–627, 2019. Cited on page 5.

C. E. Rasmussen and C. K. Williams. Gaussian Processes for Machine Learning. MIT

Press, 2006. Cited on page 22.

M. L. Stein. Interpolation of Spatial Data: Some Theory for Kriging. Springer, 1999. Cited

on pages 3, 22.

A. Weil. L’intégration dans les groupes topologiques et ses applications. Hermann, 1940.

Cited on pages 7, 9.

J. T. Wilson, V. Borovitskiy, A. Terenin, P. Mostowsky, and M. P. Deisenroth. Eﬃciently
sampling functions from Gaussian process posteriors. In International Conference on
Machine Learning, pages 10292–10302, 2020. Cited on page 2.

J. T. Wilson, V. Borovitskiy, A. Terenin, P. Mostowsky, and M. P. Deisenroth. Pathwise
Conditioning of Gaussian Processes. Journal of Machine Learning Research, 22(105):1–
47, 2021. Cited on page 2.

A. M. Yaglom. Second-order homogeneous random ﬁelds. In Proceedings of the Fourth
Berkeley Symposium on Mathematical Statistics and Probability, Volume 2: Contribu-
tions to Probability Theory, pages 593–622. University of California Press, 1961. Cited
on pages 5, 6, 8, 10, 35–37.

K. Ye, M. Niu, and P. Cheung. Heat kernel and intrinsic Gaussian processes on manifolds.

Biometrika, 103(1):1–24, 2020. Cited on page 5.

C. Zhao and J. S. Song. Exact heat kernel on a hypersphere and its applications in kernel
SVM. Frontiers in Applied Mathematics and Statistics, 4:1, 2018. Cited on page 5.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

27

A. Highest Weights and Signatures for Traversing Representations

Here, primarily following Bröcker and Tom Dieck (2013) and Fegan (1991), we review the
relevant notions of the representation theory and describe a general theory that allows
one to traverse the set of irreducible unitary representations.

Recall a substantial part of the mathematical structure of a Lie group is encoded
within its tangent spaces. Due to the group structure, these are linked rigidly enough
that it suﬃces to study the tangent space at one point, such as the identity element e
of the group. This tangent space, equipped with some additional algebraic structure, is
called the Lie algebra g of the group G.7

As it was mentioned in the main text, every irreducible representation of a connected
compact semisimple Lie group G produces a representation of its maximal torus Tm ⊆ G
by restriction. Using the structure of the torus, this representation splits into a sum of
one-dimensional irreducible representations, parametrized by tuples of integers, which are
called the weights of the representation. It turns out these representations possess even
more structure: they are in fact uniquely determined by just one of the tuples, called the
highest weight.

We proceed to deﬁne the above-mentioned weights, along with the related notion of the
roots of a Lie group in an abstract and general fashion, which produces a conﬁguration of
vectors in t∗, the space of linear functionals on the Lie algebra t of a ﬁxed maximal torus.
This combinatorial structure enables us to enumerate all irreducible representations.

A.1. Weights and Roots of Lie groups
Let G be a Lie group, and let g be its Lie algebra. Usually G is a linear group, namely
it is realized as a closed subgroup of GL(V ) for some ﬁnite-dimensional complex vector
space V , in which case g is naturally realized as a subspace of the space of endomorphisms
End(V ), deﬁned as the space of all linear operators from V to V . In what follows, we
use x and A, respectively, to denote the conjugate of a complex number, and the closure
of a subset of a topological space, with the intended meaning clear by context. We now
introduce the notion of a maximal torus.

Result 22. Every compact Lie group G contains a torus T which is maximal with respect
to inclusion. Any other torus is contained in a maximal one. Maximal tori are not unique,
but are conjugate to one another.

Proof. Bröcker and Tom Dieck (2013, Chapter IV).

We can use this to study representations of G. Let t be the Lie algebra of T . Given a
representation π : G → GL(V ) of G on a vector space V , consider its restriction (cid:101)π = π|T
to T . Since T is a torus, this restriction decomposes into a direct sum of 1-dimensional

7A Lie algebra g can also be viewed as the set of left-invariant vector ﬁelds on G: using this
perspective, we deﬁne the Lie bracket [·, ·] : g × g → g as as the commutator of vector ﬁelds
[x, y] = xy − yx. More generally, we deﬁne an abstract Lie algebra to be a ﬁnite-dimensional
vector space equipped with an antisymmetric bilinear binary operation satisfying the Jacobi
identity [x, [y, z]] + [y, [z, x]] + [z, [x, y]] = 0

28

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

(complex-valued) unitary irreducible representations of T , given as

(cid:101)π(x) = diag(1, . . . , 1, exp(θ1(x)), . . . , exp(θk(x))),
(62)
where θi are homomorphisms T → T ⊂ C. We deﬁne the weights of a representation in
terms of these homomorphisms as follows.
Deﬁnition 23. Deﬁne the weights of a representation π : G → GL(V ) to be the real
diﬀerentials deθi : t → R. Obviously, θi ∈ t∗ where t∗ is the space of linear functionals
over the space t.

For each x ∈ G, deﬁne the adjoint action Ix : G → G by Ix(g) = xgx−1, and the
adjoint representation Ad : G → GL(g) by Ad(x) = deIx. If G is a linear group, then the
adjoint action is realized by conjugation of matrices in g. This allows us to introduce the
roots of G.
Deﬁnition 24. Deﬁne the roots of a Lie group G to be the non-zero weights of the
adjoint representation Ad : G → GL(g).

The adjoint representation gives rise to a particular bilinear form on g that we will
need further, called the Killing form. We deﬁne it now. Let ad : g → End(g) be deﬁned
by ad(X)Y = [X, Y ].
Deﬁnition 25. Deﬁne the symmetric bilinear Killing form on the Lie algebra g by
B(X, Y ) = tr(ad X · ad Y ) for X, Y ∈ g. We say that G is semi-simple if B is non-
degenerate in the sense that B(X, Y ) = 0 for all Y implies X = 0.

It is not hard to see that the Killing form is invariant under the adjoint action, that is,

(63)
B(Ad(g)(X), Ad(g)(Y )) = B(X, Y ).
Diﬀerent choices of maximal tori T (1) and T (2) produce diﬀerent sets of weights (in the
respective tangents spaces t(1) and t(2)), but since all maximal tori are conjugate, the
corresponding diﬀerential t(1) → t(2) is an isometry with respect to the Killing form,
sending one set of the weights into another.

One can show that a connected semi-simple Lie group is compact if and only if B is
negative deﬁnite. Reinterpreted as a tensor ﬁeld, −B canonically deﬁnes a bi-invariant
Riemannian structure. Hereinafter by default we assume that the groups we are working
with are semi-simple.

A.2. The Highest Weight of a Representation
To enumerate representations we will use certain weights called the highest weights. For
a given representation its highest weight is the maximal weight with respect to a certain
partial order. We proceed to deﬁne and formalize these concepts.

Deﬁnition 26. For each root α, let Lα ⊂ t be the hyperplane

Lα = {X ∈ t : α(X) = 0}

(64)

which, by virtue of α being linear, passes through the origin. Then t \ ∪αLα is by con-
struction a union of disjoint convex polyhedral cones, each of which we call a Weyl
chamber.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

29

Deﬁne σ : t → t∗ according to −B(X, Y ) = σ(X)Y , where B is the Killing form. By
non-degeneracy of B this establishes an isomorphism between t and t∗. The subsets of t∗
that are images of Weyl chambers under σ will also be called Weyl chambers.

To deﬁne the ordering, we ﬁx one arbitrary Weyl chamber t+ ⊆ t and call it the
+ = σ(t+) ⊆ t∗. This deﬁnes the order on t∗ as follows.

positive chamber. We also denote t∗

Deﬁnition 27. Let θ, θ(cid:48) ∈ t∗. We say that θ ≥ θ(cid:48) if θ − θ(cid:48) ∈ t∗
order. We say that θ ∈ t∗ is positive if θ(X) > 0 for any X ∈ t+.

+, which deﬁnes a partial

For purposes of calculating Laplace–Beltrami eigenvalues on compact Lie groups, we

now introduce a particular weight ρ.

Deﬁnition 28. Deﬁne the half-sum of the roots to be ρ = 1
2
taken over all positive roots.

(cid:80) r, where the sum is

Before proceeding to the main result on highest weights, we describe a certain algebraic
structure generated by weights. Let exp : g → G be the Lie-theoretic exponential map.

Deﬁnition 29. Deﬁne the weight lattice8 to be

P = {c1α1 + . . . + ckαk : k ∈ N, cj ∈ Z, and αj are weights},

(65)

which is spanned by the weights of all representations.

With these notions in place, we can state the key structural result which we will use

to enumerate the irreducible representations of G.

Result 30. For a given choice of a positive chamber t+, every representation π of G has
a unique weight w which is largest with respect to the ordering on t∗ induced by t+. This
+, and we call it the highest weight. Moreover,
weight w is always an element of t∗
every element of P ∩ t∗

+ is the highest weight of a unique irreducible representation.

Proof. See Bröcker and Tom Dieck (2013, Deﬁnition 2.7, Chapter VI) or Fegan (1991,
Theorems 8.19 and 8.21).

This gives us a way to explicitly enumerate the irreducible representations of a given
Lie group G: (1) choose a maximal torus T ⊆ G, (2) choose a positive chamber t+ ⊆ t,
where t is the Lie algebra of T , and (3) calculate the intersection of the weight lattice P
with the closure of the dual positive chamber t∗
+. Every weight in this intersection maps
uniquely onto an irreducible representation.

This establishes what actually needs to be done to calculate the index set Λ of all
irreducible representations. However, there is a more convenient way to carry this process
out numerically. If we identify our maximal torus T with Tm ⊆ Cm, it turns out we
can express the action of the highest weight of a representation simply by raising an
element of Tm to the power of some integer multi-index. This idea leads to the notion of
a signature, formulated as follows.

8We deﬁne a lattice to be a discrete additive subgroup of Rm.

30

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

Result 31. Let w be the highest weight of a representation π. Suppose the chosen maxi-
mal torus T ⊆ G is isomorphic to Tm ⊆ Cm via the isomorphism of form

t ∈ T → (ε1(t), .., εm(t)) ∈ Tm.

Then for every t ∈ T , and every X ∈ t satisfying t = exp(X), w can be expressed as

w(X) = ε1(t)p1 · . . . · εm(t)pm.

(66)

(67)

We call (p1, .., pm) ∈ Zm the signature of the representation, which is unique up to a
choice of a maximal torus T and its isomorphism with the standard torus Tm.

Proof. See Naimark and Stern (1982, Chapter VII, Section 2).

Thus, we can use signatures to identify highest weights with tuples of integers. Not
all tuples will correspond to highest weights: various restrictions on the integers forming
a signature vary according to G. These are best handled on a case by case basis: see
Appendix B for examples.

B. Calculating the Highest Weights and Signatures for SL(n), SU(n), and SO(n)

To illustrate the preceding ideas via example, we now calculate the above-introduced
notions for three widely-occurring Lie groups. We defer the remaining task of determining
which irreducible representations corresponds to which highest weights to subsequent
sections.

Example 32. If G = SL(n), then

g = {X ∈ M (n, R) : tr(X) = 0}.

(68)

The most natural choice of a maximal torus T is the subgroup of all diagonal matrices,
then t ⊂ g is naturally realized as the subspace of diagonal matrices. The Killing form on
g is realized as B(X, Y ) = 2n tr(XY ), and its restriction to t is then

B(diag(x1, . . . , xn), diag(y1, . . . , yn)) = 2n(x1y1 + . . . + xnyn).

(69)

The space t∗, equipped with the symmetric bilinear form, is naturally isomorphic to the n−
1-dimensional Euclidean space. Denote ei = (0, .., 1, .., 0) where 1 is in the ith component.
A standard realization of roots and weights is as follows. Consider the subspace E of
Rd orthogonal to e1 + . . . + en. The roots are precisely the vectors α ∈ E having integer
coordinates and |α|2 = 2. In other words, they are of the form α = ei − ej for i (cid:54)= j. The
root lattice can be described as Q = Zn ∩ E.

The half-sum of the positive roots then equals

ρ =

(cid:18) n − 1
2

,

n − 3
2

, . . . ,

3 − n
2

,

1 − n
2

(cid:19)

.

(70)

The weight lattice P can be described as the dual of Q. Namely, one can ﬁnd such

(cid:36)i ∈ E, i = 1, . . . , n − 1, that ((cid:36)i, ej − ej+1) = δij, then Q = (cid:80)
i

Z(cid:36)i.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

31

A natural choice for a positive chamber t∗

+ is then the positive cone spanned by (cid:36)i,
i.e. the set of their linear combinations with non-negative coeﬃcients. It can also be very
conveniently described as

+ = {(x1, . . . , xn) ∈ E ⊂ Rn : x1 (cid:62) x2 (cid:62) . . . (cid:62) xn}.
t∗
(71)
The action of the Weyl group is by all possible permutations of coordinates, thus W ∼=

Sn, the symmetric group on n points.
Example 33. If G = SU(n), then its tangent space is

g = {X ∈ M (n, C) | X ∗ = −X, tr(X) = 0} .

(72)

The most natural choice of a maximal torus is the subgroup of diagonal matrices, that is,

(cid:110)

diag

(cid:16)

T =

eiθ1, . . . , eiθn

(cid:17) (cid:12)
(cid:111)
(cid:12)
(cid:12) θ1 + . . . + θn = 0

.

Its tangent space is then

t = {diag (iθ1, . . . , iθn) | θ1 + . . . + θn = 0} .

The Killing form on t can be calculated as

(73)

(74)

B(i diag(θ1, . . . , θn), i diag(η1, . . . , ηn)) = −2n(θ1η1 + . . . + θnηn).
(75)
Under the identiﬁcation diag (iθ1, . . . , iθn) (cid:55)→ (θ1, . . . , θn) of t with Rn the description of
roots and weights coincides with that of SL(n).
Example 34. Let G = SO(n), its tangent is g = (cid:8)X ∈ M(n, R) (cid:12)

(cid:12) A(cid:62) = −A(cid:9).

The description of roots and weights for G = SO(n) depends on the oddity of n. For

n = 2k or 2k + 1 the maximal tori T can be chosen as




cos θ1
− sin θ1

sin θ1
cos θ1

T =










sin θ1
cos θ1

. . .

T =






cos θ1
− sin θ1











Their tangent spaces are then

. . .

cos θk
− sin θk

sin θk
cos θk

cos θk
− sin θk

sin θk
cos θk

1





























,

.

0
−θ1














t =

θ1
0

. . .

0
−θk

θk
0














,

t =






0
−θ1











θ1
0

. . .

0
−θk

θk
0










0






(76)

(77)

,

(78)

32

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

and the formulas for the Killing form are
(cid:16)(cid:16) 0 θ1
−θ1 0

(cid:16) 0 θk
−θk 0

bdiag

, . . . ,

B

(cid:16)

(cid:17)

(cid:17)(cid:17)

, bdiag

(cid:16)

B

bdiag

(cid:16)(cid:16) 0 θ1
−θ1 0

(cid:17)

, . . . ,

(cid:16) 0 θk
−θk 0

(cid:17)(cid:17)

, bdiag

(cid:17)(cid:17)(cid:17)

(cid:16)(cid:16) 0 η1
−η1 0

(cid:17)

, . . . ,

(cid:16) 0

ηk
−ηk 0

,
= (4 − 4k)(θ1η1 + . . . + θkηk),
(cid:16) 0

(cid:16)(cid:16) 0 η1
−η1 0
= (2 − 4k)(θ1η1 + . . . + θkηk).

ηk
−ηk 0

, . . . ,

(cid:17)(cid:17)

, 0

(cid:17)

(cid:17)

In both cases, t∗ is naturally identiﬁed with Rk. The roots are, then,

ei ± ej, i (cid:54)= j

for n = 2k,

±ei and ei ± ej, i (cid:54)= j

for n = 2k + 1.

The half-sum of the positive roots equals

ρ = (n − 1, n − 2, . . . , 2, 1, 0)

for n = 2k,

ρ =

(cid:18) n
2

− 1,

n
2

− 2, . . . ,

(cid:19)

3
2

,

1
2

for n = 2k + 1.

(79)

(80)

(81)
(82)

(83)

(84)

The weight lattice Q in both cases can be described as Zk. The action of the Weyl group
is by permutations of coordinates and changing of signs.9

The standard choice of the positive chamber is

+ = {(x1, . . . , xk) ∈ Q : xi (cid:62) xi+1, xk−1 (cid:62) |xk|}
t∗

for n = 2k,

+ = {(x1, . . . , xk) ∈ Q : xi (cid:62) xi+1 (cid:62) 0}
t∗

for n = 2k + 1.

(85)

(86)

Example 35. For G = SO(n) and the choices of T and t∗
tures (p1, . . . , pk) are

+ as above, the possible signa-

p1 (cid:62) p2 (cid:62) . . . (cid:62) pk−1 (cid:62) |pk|
p1 (cid:62) p2 (cid:62) . . . (cid:62) pk (cid:62) 0

for n = 2k,
for n = 2k + 1.

Example 36. For G = SU(n) the possible signatures (p1, . . . , pn) are those with

p1 (cid:62) p2 (cid:62) . . . (cid:62) pn.

(87)
(88)

(89)

C. The Weyl Character Formula

To describe the Weyl character formula, we will need the principal group of symmetries
of a root system, its Weyl group. Again, denote by T a ﬁxed maximal torus and by t its
Lie algebra.

Deﬁnition 37. Deﬁne the Weyl group W as the subgroup of O(t) generated by all
reﬂections in Lα of Deﬁnition 26. W acts transitively on the set of all Weyl chambers by
permutations.

9In group-theoretic terms, W ∼= Sk (cid:110) (Z/2Z)k, the semidirect product of Sk acting on the k-th

power of the cyclic group of order 2 by permutations of components.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

33

To proceed, we introduce two ways of expressing certain alternating sums.

Result 38 (Weyl Denominator Formula). Let X ∈ t, and deﬁne

j(exp(X)) =

(cid:88)

σ∈W

sgn(σ) exp(σ(ρ)X)

(90)

where W is the Weyl group, ρ is half the sum of positive roots of Deﬁnition 28, and sgn(σ)
is the determinant of σ as a linear operator.10 Then

j(exp(X)) =

(cid:89)

(cid:0)exp(cid:0) i

2 α(X)(cid:1) − exp(cid:0) −i

2 α(X)(cid:1)(cid:1)

(91)

α>0

where the product is taken over all positive roots.

Proof. (Fegan, 1991), Theorem 9.2.

We now introduce the Weyl character formula, which expresses characters as the ratio

of two alternating sums depending on the chosen tangent vector.

Result 39 (Weyl Character Formula). For a highest weight w, deﬁne

jw(exp(X)) =

(cid:88)

σ∈W

sgn(σ) exp(σ(w + ρ)X).

(92)

Then for t ∈ T , the character χw can be expressed as

χw(t) =

jw(t)
j(t)

.

(93)

Proof. (Fegan, 1991), Theorem 9.9.

Ostensibly, this gives us a way to calculate character values on the maximal torus T .
However, since characters are conjugation-invariant, the Weyl character formula can be
used to calculate character values everywhere on G. We state this formally as follows.

Corollary 40. Let g ∈ G, and let t ∈ T be such that there is an h ∈ G such that
g = h • t • h−1, where t and h always exist by Result 22. Then

χw(g) = χw(h−1 • t • h) = χw(t).

(94)

Proof. This follows because the character is invariant under conjugation:

χw(h−1 • t • h) = tr πw(h−1)πw(t)πw(h) = tr πw(h−1)πw(h)πw(t) = χw(t).

(95)

10Note that sgn(σ) is equal to (−1)m when σ is a composition of m reﬂections..

34

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

This establishes how to calculate the character χw for a given highest weight w. We now
study how to express this using signatures. If t = (ε1, . . . , εn) under the correspondence
between the maximal torus and the complex exponentials, we can re-express the above
formula as the ratio of two polynomials in ε1, . . . , εn, where the denominator divides the
numerator, and the ratio itself is also a polynomial.

In many cases, this expression can be simpliﬁed greatly. As an example, for G = SU(2),
the Weyl character formula simply says that for a unique representation of dimension d
(with signature (d)) the character value equals

χd(g) =

λd − λ−d
λ − λ−1

where λ, λ−1 are the eigenvalues of g. Since both eigenvalues can be expressed as

one can show that

tr(g) ±

(cid:112)

tr(g)2 − 4

(cid:17)

(cid:16)

1
2

χd(g) = Ud−1

2 tr(g)(cid:1)
(cid:0) 1

(96)

(97)

(98)

where Uk is the kth Chebyshev polynomial of the second kind.

In general, this expression can either be calculated symbolically from the Weyl character
formula, or obtained from the Kostant multiplicity formula, which expresses the coeﬃcients
as certain combinatorial quantities related to the structure of the root system of G. Note
in particular that from this expression, one can deduce the Weyl dimension formula

dim Vw = χw(e) =

(cid:81)

α>0(w + ρ, α)
(cid:81)
α>0(ρ, α)

(99)

which is used for calculating normalizing constants dλ. In most cases, the alternating
sums appearing in the above cases can be interpreted with the help of Weyl denominator
formula as certain matrix determinants.

D. Calculating the Characters for SU(n), and SO(n)

In more practical terms, for SO(n) and SU(n) Weyl character formula provides an explicit
expression for χ(g) as a ratio of two Vandermonde-type determinants depending only on
the eigenvalues of g (possibly together with an ordering).

Example 41. Let G = SO(n) and let (p1, . . . , pn) be the signature of a representation
with the highest weight (cid:36). Then the corresponding character χ(cid:36) can be calculated as
follows. If n = 2k + 1, denote qi = pi + k − i + 1
1 ) to
be the eigenvalues of an element g ∈ G. Then

2 and set (γ1, . . . , γk, 1, γ−1

k , . . . , γ−1

χ(cid:36)(g) =

ξ1(q1, . . . , qk)
2 , 1
2 , . . . , 3
2 )

ξ1(k − 1

, where

ξ1(d1, . . . , dk) = det

(cid:16)

i − γ−dj
γdj

i

(cid:17)k

i,j=1

.

(100)

Weyl’s dimension formula specializes to

d(cid:36) =

2k
(2k − 1)! . . . 3! 1!

· q1 . . . qk ·

(cid:89)

(q2
1(cid:54)i<j(cid:54)k

i − q2

j ).

(101)

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I
If n = 2k, denote qi = pi+k−i for i = 1, . . . , k−1 and qk = |pk|. Let (γ1, . . . , γk, γ−1

35

k , . . . , γ−1
1 )

be the eigenvalues of g ∈ G ordered such that

cos θ1
− sin θ1











sin θ1
cos θ1

. . .










1

cos θk
− sin θk

sin θk
cos θk

, where γj = cos θj + i sin θj,

(102)

is conjugated in SO(n) to g (contrary to the case n = 2k + 1, here each possible collection
of eigenvalues determine two conjugacy classes). Introduce

ξ0(d1, . . . , dk) = det

(cid:16)

i + γ−dj
γdj

i

(cid:17)k

i,j=1

,

ξ1(d1, . . . , dk) = det

(cid:16)

i − γ−dj
γdj

i

(cid:17)k

i,j=1

. (103)

Then

χ(cid:36)(g) =

ξ0(q1, . . . , qk)
ξ0(m − 1, m − 2, . . . , 1, 0)

,

if

pk = qk = 0,

χ(cid:36)(g) =

ξ0(q1, . . . , qk) + (sgn pm)ξ1(q1, . . . , qk)
2ξ0(m − 1, m − 2, . . . , 1, 0)

,

if

pm (cid:54)= 0.

The dimension formula turns into

d(cid:36) =

2k−1
(2k − 2)!(2k − 4)! . . . 4! 2!

(cid:89)

(q2
·
1(cid:54)i<j(cid:54)k

i − q2

j ).

(104)

(105)

(106)

Example 42. For G = SU(n) the character of a representation with the signature
(p1, . . . , pn) can be calculated as follows. Denote qi = pi + n − i.
If (γ1, . . . , γn) are
the eigenvalues of g ∈ G, then

χ(g) =

ξ1(q1, . . . , qk)
ξ1(0, 1, . . . , n − 1)

, where

ξ1(d1, . . . , dn) = det

(cid:16)

γdj
i

(cid:17)n

i,j=1

.

(107)

E. Proofs

Theorem 1. A Gaussian process f ∼ GP(0, k) on a compact Lie group G is stationary
with respect to left-and-right action of G on itself if and only if k is of form

k(g1, g2) =

(cid:88)

λ∈Λ

a(λ) Re χ(λ)(g−1

2

• g1)

(18)

where a(λ) ≥ 0 satisfy (cid:80)

λ∈Λ dλa(λ) < ∞. Moreover, for all λ, Re χ(λ) is positive-deﬁnite.
Proof. Theorem 2 of Yaglom (1961) shows that for any stationary Gaussian process
k(g1, g2) = (cid:80)
• g1) where a(λ) ≥ 0 satisfy (cid:80)
λ∈Λ dλa(λ) < ∞.. Under our
usual assumption that a Gaussian process is real-valued, we have Re k(g1, g2) = k(g1, g2).
Using this and taking the real parts of both sides of the equation, we get (18).

λ∈Λ a(λ) χ(λ)(g−1
2

36

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

To prove positive semideﬁniteness, write, using (i) the deﬁnition of χ(λ), (ii) the
homomorphism property of π(λ), (iii) the fact that π(λ)(g)−1 = π(λ)(g)∗ due to unitarity,
where the star denotes taking the conjugate transpose matrix, and (iv) the standard
properties of the trace, that

χ(λ)(g−1

2 g1) = tr π(λ)(g−1

2 g1) = tr π(λ)(g1)π(λ)(g2)∗ =

dλ(cid:88)

dλ(cid:88)

j=1

k=1

jk (g1)π(λ)
π(λ)

jk (g2).

(108)

This immediately shows that a character χ(λ), being an inner product of the feature
maps g → {π(λ)
jk (g)}1≤j,k≤dλ, is (complex-valued) positive semideﬁnite. The real part of a
complex-valued positive semideﬁnite function is positive semideﬁnite, hence Re χ(λ) is
positive semideﬁnite.

Theorem 2. A Gaussian process f ∼ GP(0, k) on a compact homogeneous space G/H
is stationary with respect to the action of G if and only if k is of form

k(g1 • H, g2 • H) =

(cid:88)

rλ(cid:88)

λ∈Λ

j,k=1

jk Re π(λ)
a(λ)

jk (g−1

2

• g1)

(23)

where the coeﬃcients a(λ)
rλ × rλ satisfying (cid:80)
for each individual λ ∈ Λ, the corresponding sum over j, k is positive semideﬁnite.

jk ∈ R form symmetric positive semi-deﬁnite matrices A(λ) of size
jk are the zonal spherical functions. Moreover,

λ tr A(λ) < ∞, and π(λ)

Proof. Theorem 5 of Yaglom (1961) immediately implies that any stationary real-valued
Gaussian process is of form k(g1 • H, g2 • H) = (cid:80)
• g1) where the
coeﬃcients a(λ)
jk ∈ C form Hermitian positive semi-deﬁnite matrices A(λ) of size rλ × rλ
with complex entries satisfying (cid:80)
λ tr A(λ) < ∞, and π(λ)
jk are the zonal spherical functions.
Furthermore, any covariance of this form, provided it is real-valued, it distribution-wise
uniquely deﬁnes a stationary Gaussian process. To obtain the claim, we need to understand
when k deﬁned in this way is a real-valued function.

j,k=1 a(λ)

jk (g−1

jk π(λ)

(cid:80)rλ

λ∈Λ

2

The map g → (π(λ)(g))∗ deﬁnes an irreducible unitary representation, thus is equal
to π(λ(cid:48)) for some λ(cid:48) ∈ Λ. No matter if λ(cid:48) = λ or not, it is easy to see that rλ(cid:48) = rλ and,
what is more, we can deﬁne the zonal spherical functions for π(λ(cid:48)) using the same basis
e1, . . . , edλ ∈ Vλ(cid:48) = Vλ, getting

jk (g) = (cid:10)π(λ(cid:48))(g)ej, ek
π(λ(cid:48))

(cid:11)

Vλ

= (cid:10)(π(λ)(g))∗ej, ek

(cid:11)

= (cid:10)ej, π(λ)(g)ek

(cid:11)

= π(λ)

kj (g). (109)

Vλ

Vλ

Using this property, from Re k = k, or equivalently from k = k we infer

(cid:88)

rλ(cid:88)

λ∈Λ

jk=1

jk π(λ)
a(λ)

jk (g) =

(cid:88)

rλ(cid:88)

λ∈Λ

jk=1

jk π(λ)
a(λ)

jk (g) =

(cid:88)

rλ(cid:88)

λ∈Λ

jk=1

kj π(λ)
a(λ(cid:48))

jk (g)

(110)

Because all π(λ)

jk are orthonormal, it follows that a(λ)

jk = a(λ(cid:48))
kj .

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

37

Now, since k(g1 • H, g2 • H) = k(g2 • H, g1 • H), write

(cid:88)

rλ(cid:88)

λ∈Λ

jk=1

jk π(λ)
a(λ)

jk (g) =

=

(cid:88)

rλ(cid:88)

λ∈Λ

jk=1

(cid:88)

rλ(cid:88)

λ∈Λ

jk=1

jk π(λ)
a(λ)

jk (g−1) =

(cid:88)

rλ(cid:88)

λ∈Λ

jk=1

a(λ)
jk π(λ)

kj (g)

(111)

a(λ(cid:48))
kj π(λ)

jk (g)

(112)

This implies a(λ)

jk = a(λ(cid:48))

kj and therefore a(λ)

jk ∈ R. Using these observations, write

(cid:88)

rλ(cid:88)

Re

λ∈Λ

j,k=1

jk π(λ)
a(λ)

jk (g−1

2

• g1) =

(cid:88)

rλ(cid:88)

λ∈Λ

j,k=1

jk Re π(λ)
a(λ)

jk (g−1

2

• g1)

(113)

which gives the ﬁrst part of the claim.

We now show that for each individual λ ∈ Λ the corresponding sum over j, k is positive
semideﬁnite. Yaglom (1961, Theorem 5) proves, as a byproduct, that this sum is a
covariance function of a Gaussian process given by

fλ(gH) =

dλ(cid:88)

rλ(cid:88)

j=1

k=1

jkπ(λ)
zλ

jk (g)

where zλ
The claim follows.

jk are zero-mean Gaussians with covariances given by E zλ

j1k1

(114)

zλ
j2k2

= δj1j2a(λ)
k1k2

.

Theorem 6. Let f ∼ GP(0, k), where k is stationary and satisﬁes A(λ) = a(λ)I. Then

k(g1H, g2H) =

(cid:90)

H

kG(g1 • h, g2) dµH (h)

f (gH) =

(cid:90)

H

fG(g • h) dµH (h)

(28)

where µH is the Haar measure on H, and fG ∼ GP(0, kG) with

kG(g1, g2) =

(cid:88)

λ∈Λ

a(λ) Re χ(λ)(g−1

2

• g1).

(29)

Proof. Recall that under a suitable choice of basis in the representation space Vλ, spherical
functions π(λ)

jk are matrix coeﬃcients with 1 ≤ j ≤ dλ and 1 ≤ k ≤ rλ.

Consider the integrals of form

I (λ)
jk (g) =

(cid:90)

H

π(λ)
jk (g • h) dµH (h).

(115)

Since π(λ)
these are constant on cosets, we have π(λ)
Furthermore, since spherical functions span the subspace of span π(λ)

jk corresponding to 1 ≤ j ≤ dλ and 1 ≤ k ≤ rλ are spherical functions and
jk (g • h) = π(λ)
jk (g) = π(λ)
jk (g).
jk that consists of all

jk (g) and thus I (λ)

38

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

functions constant on cosets, and since the remaining matrix coeﬃcients belong to its
orthogonal complement, we have I (λ)
jk (g) = 0 for all remaining indices j, k, proving that

(cid:90)

H

χ(λ)(g • h) dµH (h) =

dλ(cid:88)

(cid:90)

j=1

H

π(λ)
jj (g • h) dµH (h) =

rλ(cid:88)

j=1

π(λ)
jj (g • h).

(116)

Of course the same holds for real parts.

With this we can write

k(g1 • H, g2 • H) =

=

=

=

(cid:88)

λ∈Λ
(cid:88)

a(λ)

a(λ)

λ∈Λ
(cid:90)

(cid:88)

H

λ∈Λ

(cid:90)

rλ(cid:88)

j=1
(cid:90)

H

Re π(λ)

jj (g−1
2

• g1)

Re χ(λ)(g−1

2

• g1 • h) dµH (h)

a(λ) Re χ(λ)(g−1

2

• g1 • h) dµH (h)

kG(g1 • h, g2) dµH (h).

H

Deﬁne f (cid:48)(gH) = (cid:82)
obvious, while writing

H fG(g • h) dµH (h) where fG ∼ GP(0, kG). Now, E f (cid:48)(gH) ≡ 0 is

Cov(fG(g1 • h1), fG(g2 • h2)) dµH (h1) dµH (h2)

(121)

Cov(cid:0)f (cid:48)(g1H), f (cid:48)(g2H)(cid:1) =

=

=

=

(cid:90)

(cid:90)

H

H

(cid:90)

(cid:90)

H

H

(cid:90)

(cid:90)

H

H

(cid:90)

H

kG(g1 • h1, g2 • h2) dµH (h1) dµH (h2)

kG(g1 • h1 • h−1

2 , g2) dµH (h1) dµH (h2)

kG(g1 • h, g2) dµH (h) = k(g1H, g2H)

which ﬁnally proves the claim.

Proposition 8. The function K deﬁned by (35) satisﬁes

K(x, y) =

(cid:90)

G/H

K(x, u)K(y, u) dµG/H (u)

(36)

if and only if the matrix A = d−1
λ

(cid:0)a(λ)
k1k2

(cid:1) is idempotent, namely A2 = A.

(117)

(118)

(119)

(120)

(122)

(123)

(124)

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

39

Proof. Expanding the right-hand side of (36) we get

rλ(cid:88)

k1,k2=1
k3,k4=1

a(λ)
k1,k2

a(λ)
k3,k4

dλ(cid:88)

j1,j2=1

π(λ)
j1,k1

(x)π(λ)
j2,k3

(y)

(cid:90)

G/H

d−1
λ δj1j2 δk2k4

π(λ)
j1,k2

(u)π(λ)
j2,k4

(u) dµG/H (u)

(125)

rλ(cid:88)

= dλ





rλ(cid:88)

k1,k3=1

k=1

a(λ)
k1,k
dλ

a(λ)
k3,k
dλ





dλ(cid:88)

j

π(λ)
j,k1

(x)π(λ)
j,k3

(y).

(126)

denote by bk1,k3

Comparing the last expression to the right-hand side of (35) we see that the necessary and
suﬃcient condition for them to match is that dλbk1,k2 = ak1,k2 for all 1 ≤ k1, k2 ≤ rλ. If
let B be the matrix consisting of bk1,k2, then by (126) we have B = AA(cid:62), along with the
preceding condition, which in matrix form is B = A. Hence, the necessary and suﬃcient
condition for (36) to hold is A = AA(cid:62) and since A is symmetric by assumption, namely
A = A(cid:62), the condition simpliﬁes to AA(cid:62) = A2 = A.

Lemma 9. There exists {x1, . . . , xN } ⊆ S such that det Mk (cid:54)= 0 for all 1 ≤ k ≤ N .

Proof. Induction. For k = 1, the claim is immediate since φ1 (cid:54)= 0. Now, assume
det Mk (cid:54)= 0 for all k in the range k = 1, . . . , n − 1. Split the matrix Mn into blocks as
follows:

Mn =

(cid:18) Mn−1 φ∗(xn)
φn(x∗) φn(xn)

(cid:19)

and use Schur complement formula for its determinant, then

det Mn = det Mn−1

(cid:16)

φn(xn) −

(cid:17)

αjφj(xn)

,

n−1
(cid:88)

j=1

where the coeﬃcients αj are deﬁned as

(α1, . . . , αn−1) = (φn(x1), . . . , φn(xn−1))M−1
n−1

(127)

(128)

(129)

and in particular do not depend on xn. If it were true, the equation det Mn = 0 for all
xn ∈ S would imply φn(xn) − (cid:80)n−1
j=1 αjφj(xn) = 0 for all xn ∈ S, which would contradict
linear independence of φj. The claim follows.

Theorem 12. If xj is a fundamental set with respect to the system φj, then

Proof. We have

span φj = span K(·, xj)

K(x, xk) =

N
(cid:88)

j=1

φj(xk)φj(x).

(46)

(130)

40

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

Notice that






K(x, x1)
...
K(x, xN )


 = M∗


N






φ1(x)
...
φN (x)




 .

(131)

Hence, by non-degeneracy of MN , it follows that K(·, xj) is a basis of span φj.

Result 14. For every λ, the matrix coeﬃcients π(λ)
jl are eigenfunctions of −∆ corre-
sponding to the same eigenvalue αλ ≥ 0. Moreover, the eigenvalues αλ can be written

αλ = (cid:107)ρ(cid:107)2
where w is the highest weight of the representation with signature λ, (cid:107)g(cid:107)2
B = −B(g, g), B
is the Killing form of G, and ρ is the half-sum of positive roots of G—see Appendix A.

B − (cid:107)w + ρ(cid:107)2

(52)

B

Proof. Since G is equipped with the metric induced by the Killing form, the left shift and
right shift maps

Lg : G → G

Lgu = g • u

Rg : G → G

Rgu = u • g−1

(132)

are Riemannian isometries of G. Let ∆ be the Laplace–Beltrami operator on G, and
recall that this operator commutes with Riemannian isometries. Thus, ∆ commutes with
Lg and Rg for all g ∈ G. Let φjk = ∆πλ
jk)(u) = (Lgφjk)(u) = φjk(gu)
and, on the other hand,

jk. Then (∆Lgπλ

(∆Lgπλ

jk)(u) =

dλ(cid:88)

l=1

jl(g)(∆πλ
πλ

lk)(u) =

dλ(cid:88)

l=1

πλ
jl(g)φlk(u).

(133)

l=1 πλ

Hence φjk(gu) = (cid:80)dλ
jl(g)φlk(u). Denoting φ(g) = (φjk(g)) we get φ(gu) = πλ(g)φ(u).
Examining the action for the right shifts in the same manner we get φ(ug−1) =
φ(u)πλ(g−1). Because of this, πλ(g)φ(e) = φ(g) = φ(e)πλ(g) for all g ∈ G, which,
by Schur’s Lemma, implies φ(e) = αλI and φ(g) = αλπλ(g). This proves that every πλ
jk
is an eigenfunction of ∆ corresponding to the same eigenvalue αλ. By general theory of
the Laplacian we have αλ ≤ 0.
(cid:9)
λ,j,k is an orthonormal basis of eigenfunctions of ∆ in L2(G),

This shows that (cid:8)√

dλπλ
jk

where the Haar measure on G coincides with the Riemannian volume measure on G.
Result 16. The spherical functions π(λ)
jk on a compact homogeneous space G/H are
the eigenfunctions of −∆. Moreover, the eigenvalue corresponding to every spherical
function π(λ)

jk , which by deﬁnition is also a matrix coeﬃcient of G, is given in (52).

Proof. The metric structure of a homogeneous space M = G/H with G a compact Lie
group is inherited from the group G and thus the Laplacian ∆G/H on G/H satisﬁes
(∆G/H f )(gH) = (cid:0)∆G

˜f (cid:1)(g)

(134)

where ∆G is the Laplacian on G, ˜f (g) = f (φ(g)) with φ : G → G/H and φ(g) = g • H.

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I

41

Consider the spherical functions π(λ)

jk for 1 ≤ j ≤ dλ, 1 ≤ k ≤ rλ. The functions π(λ)
jk ,
as functions on G, are matrix coeﬃcients of irreducible unitary representations of G under
a suitable choice of basis in the representation space Vλ. Because of this, the argument
from the previous section implies that they are eigenfunctions of ∆G/H corresponding
to the eigenvalues αλ. Thus (cid:8)√
λ,j,k is an orthonormal basis of eigenfunctions of
∆G/H in the space L2(G/H). Note that, again, the invariant measure measure on G/H
coincides with the Riemannian volume measure on G/H.

dλπλ
jk

(cid:9)

Proof of Equations (57) and (58). This is a proof from Jaquier et al. (2022), which we
provide for completeness. By Gradshteyn and Ryzhik (2014, Section 3.326, Item 2) we
have

(cid:90) ∞

ume−au du = Γ(m + 1)a−m−1.

(135)

Substituting m = ν + n/2 − 1 and a = 2ν/κ2 + 4π2λ2 into this equation and then
performing a simple rearrangement of terms, we get

0

(cid:18) 2ν
κ2 + 4π2λ2

(cid:19)−ν− n

2

= Γ(ν + n/2)−1

(cid:90) ∞

0

uν+ n

2

−1e− 2ν

κ2 ue−4π2λ2u du,

(136)

= (4π)− n

2 Γ(ν + n/2)−1

(cid:90) ∞

uν−1e− 2ν

κ2 u(4πu)

n

2 e−4π2λ2u du,

(137)

= σ−2(4π)− n

2 Γ(ν + n/2)−1

0

(cid:90) ∞

0

uν−1e− 2ν

κ2 uS∞,

√

2u,σ2(λ) du (138)

where

S∞,κ,σ2(λ) = σ2(2πκ2)n/2e−2π2κ2λ2
is the spectral density of the squared exponential kernel, i.e.

k∞,κ,σ2(x, x(cid:48)) =

(cid:90)

Rn

S∞,κ,σ2((cid:107)ξ(cid:107))e2πi(cid:104)x−x(cid:48),ξ(cid:105) dξ.

(139)

(140)

Now, using the spectral representation of the Matérn kernel together with (138), we

write

kν,κ,σ2(x, x(cid:48)) =

σ2
Cν

(cid:90)

Rn

1

=

Cν(4π)

n

2 Γ(ν + n/2)

Rn

0

(cid:18) 2ν
κ2 + 4π2(cid:107)ξ(cid:107)2
(cid:90) ∞
(cid:90)

(cid:19)−ν− n

2

e2πi(cid:104)x−x(cid:48),ξ(cid:105) dξ

(141)

uν−1e− 2ν

κ2 uS∞,

√

2u,σ2((cid:107)ξ(cid:107)) du e2πi(cid:104)x−x(cid:48),ξ(cid:105)dξ = . . . (142)

By changing the order of integration, rearranging terms and using formula (140) we get

. . . =

1

(cid:90) ∞

Cν(4π)

n

2 Γ(ν + n/2)

0

uν−1e− 2ν

κ2 uk∞,

√

2u,σ2(x, x(cid:48)) du.

(143)

Using the fact that Cν =

Γ(ν)κ2ν

2nπn/2Γ(ν+n/2)(2ν)ν and noticing that

1

Cν(4π)

n

2 Γ(ν + n/2)

2nπn/2Γ(ν + n/2)(2ν)ν
Γ(ν)κ2ν

=

(2ν)ν
Γ(ν)κ2ν

(144)

proves the claim.

42

Iskander Azangulov, Andrei Smolensky, Alexander Terenin and Viacheslav Borovitskiy

Proof of Matérn kernels being positive (semi)deﬁnite. This is a proof from Jaquier et al.
(2022), which we provide for completeness. Assume kν,κ,σ2 is deﬁned by Deﬁnition 18
and that the corresponding heat kernel k∞,κ,σ2 is positive (semi)deﬁnite. Take some
locations x1, . . . , xm = x and consider the matrix Kν
xx with elements kν,κ,σ2(xi, xj). In
order to prove that kν,κ,σ2 is positive (semi)deﬁnite we need to show that Kν
xx is a positive
(semi)deﬁnite matrix for an arbitrary choice of m and x. This means that we need to
show that y(cid:62)Kν

xxy(cid:62) > 0 for all nonzero vectors y ∈ Rm.

To prove that Kν

xx is positive deﬁnite, consider the matrices K∞,κ

xx with elements

k∞,κ,σ2(xi, xj). Then, extending equation (59) to matrices, we have

Kν

xx = C

Because of this, we obtain

y(cid:62)Kν

xxy = C

(cid:90) ∞

0

(cid:90) ∞

0

uν−1+n/2e− 2ν

κ2 uK∞,
xx

√

2u

du.

uν−1+n/2e− 2ν
κ2 u
∗

y(cid:62)K∞,
xx
∗∗

√

2u

y

du,

(145)

(146)

where the factor ∗ of the integrand is obviously positive and the factor ∗∗ of the integrand
is positive (non-negative) because K∞,
is positive (semi)deﬁnite by assumption, thus
xx
the integral is positive (non-negative). Thus kν,κ,σ2 is positive (semi)deﬁnite.

2u

√

Proposition 19. The Matérn kernel on a compact Lie group G is given by

kν,κ,σ2(x, y) =

σ2
C(cid:48)

ν,κ

(cid:18) 2ν

(cid:88)

λ∈Λ

κ2 + aλ

(cid:19)−ν−n/2

dλχλ(y−1 • x)

(60)

where C(cid:48)

ν,κ is a normalizing constant which ensures that kν,κ,σ2(x, x) = σ2.

Proof. Substituting the expression (53) for heat kernels on a compact Lie group G into
(58), we get, for x, y ∈ G,

kν,κ,σ2(x, y) =

=

σ2
Cν,κ
σ2
Cν,κ

(cid:90) ∞

0
(cid:90) ∞

0

uν−1+n/2e− 2ν

κ2 uP(u, x, y) du

(147)

uν−1+n/2e− 2ν

κ2 u (cid:88)

e−αλudλχλ(y−1 • x) du.

(148)

λ∈Λ

Rearranging the terms we get

kν,κ,σ2(x, y) =

σ2
Cν,κ

(cid:90) ∞

(cid:88)

λ∈Λ

0

uν−1+n/2e− 2ν

κ2 ue−αλu du

dλχλ(y−1 • x)

(149)

Φκ,ν+n/2(aλ)

where Φκ,ν+n/2(aλ) is deﬁned as the inner integral. By Gradshteyn and Ryzhik (2014,
Section 3.326, Item 2), we have

(cid:90) ∞

0

une−au du = Γ(n + 1)a−n−1.

(150)

Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I
Hence, Φκ,ν+n/2(aλ) = Γ(ν + n/2)(cid:0) 2ν

(cid:1)−ν−n/2. We obtain

κ2 + aλ

43

kν,κ,σ2(x, y) =

σ2
C(cid:48)

ν,κ

(cid:18) 2ν

(cid:88)

λ∈Λ

κ2 + aλ

(cid:19)−ν−n/2

dλχλ(y−1 • x)

(151)

where C(cid:48)

ν,κ is a normalizing constant ensuring that kν,κ,σ2(x, x) ≡ σ2.

Theorem 21. For all ν > 0, Matérn kernels on compact Lie groups and their homoge-
neous spaces are positive deﬁnite and lie in the Sobolev space H ν+n/2. Thus, they are
continuous and possess continuous derivatives of all orders up to (cid:98)ν + n/2(cid:99).

Proof. See Appendix E. First, note that

min(cid:0)1, 2ν/κ2(cid:1)(1 + aλ) ≤

2ν

κ2 + aλ ≤ max(cid:0)1, 2ν/κ2(cid:1)(1 + aλ).

(152)

(cid:9)

dλπλ
jk

Using this, by change of metric expressions it suﬃces to study kν,κ,σ2 only in the special
case when 2ν/κ2 = 1.
Recall that (cid:8)√

λ,j,k is an orthonormal basis of eigenfunctions of the Laplace–
Beltrami operator. Then under our assumption that 2ν/κ2 = 1, by De Vito et al. (2020,
Proposition 2), we see that kν,κ,σ2 is the reproducing kernel of H ν+n/2, and therefore an
element of this space. Therefore, positive deﬁniteness and continuous diﬀerentiability
follow from one of the Sobolev embedding theorems—see De Vito et al. (2020, Remark 4).
The claim follows.

