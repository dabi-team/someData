Article
Novel projection schemes for graph-based Light Field coding

Nguyen Gia Bach 1

, Chanh Minh Tran 1

, Tho Nguyen Duc 1

, Phan Xuan Tan 2*

, and Eiji Kamioka 1

1 Graduate School of Engineering and Science, Shibaura Institute of Technology, Tokyo 135-8548, Japan;

nb20502@shibaura-it.ac.jp (C.M.T); nb20501@shibaura-it.ac.jp (T.N.D.)

2 Department of Information and Communications Engineering, Shibaura Institute of Technology, Tokyo 135-8548,

Japan

* Correspondence: tanpx@shibaura-it.ac.jp (P.X.T.);

Abstract: In Light Field compression, graph-based coding is powerful to exploit signal redundancy along
irregular shapes and obtains good energy compaction. However, apart from high time complexity to
process high dimensional graphs, their graph construction method is highly sensitive to the accuracy of
disparity information between viewpoints. In real world Light Field or synthetic Light Field generated by
computer software, the use of disparity information for super-rays projection might suffer from inaccuracy
due to vignetting effect and large disparity between views in the two types of Light Fields respectively.
This paper introduces two novel projection schemes resulting in less error in disparity information, in
which one projection scheme can also signiﬁcantly reduce time computation for both encoder and decoder.
Experimental results show projection quality of super-pixels across views can be considerably enhanced
using the proposals, along with rate-distortion performance when compared against original projection
scheme and HEVC-based or JPEG Pleno-based coding approaches.

Keywords: Light Field, compression, super-rays, graph transform, super-ray projection

1. Introduction

Light Field (LF) is an emerging technology in multimedia research areas that allows
capturing different light rays in many directions, emitted from every point of an object or
a scene [1]. Hence, it brings signiﬁcantly improved immersiveness, depth, intensity, color
and perspectives from a range of viewpoints. As the result, it reveals promising application
opportunities into vast areas such as Virtual Reality (VR), Augmented Reality (AR) [2], 3D
television [3], biometrics recognition [4], medical imaging [5], or post-capture processing
techniques like depth estimation and refocusing [6]. However, the rich quality trades off with a
high volume of redundant data from both within and between viewpoints, leading to the need
of obtaining efﬁcient compression approaches.

Recently, graph-based coding has proved to be an efﬁcient approach for LF compression
[13–15] in comparison with conventional 2D image based compression methods, e.g., HEVC
[7], JPEG Pleno [8]. This is because the conventional methods use rectangular blocks which
often contain non-uniform intensities or sub regions with different statistical properties. Such
non-uniform representation of signal achieves low energy compaction when transformed
into frequency domain, leading to higher bitrate required for coding. Meanwhile, graph-
based coding can efﬁciently exploit the redundancy within pixels blocks with irregular shape,
adhering closely to object boundaries. More concretely, graphs with arbitrary shapes containing
mostly uniform pixel intensities are transformed into frequency domain using Graph Fourier
Transform (GFT). As the result, better energy compaction of coefﬁcients can be achieved.
Among exiting graph-based LF coding methods, the one in [15] achieves the best rate-distortion
performance by proposing graph coarsening and partitioning in a rate-distortion sense. Indeed,
in comparison with the methods in [13,14], this method is capable of reducing graph vertices
and obtaining smaller graphs from the original high dimensional graphs. At the same time,

2
2
0
2

n
u
J

9

]

V

I
.
s
s
e
e
[

1
v
8
2
3
4
0
.
6
0
2
2
:
v
i
X
r
a

Citation: Bach, N.G; Chanh, T.M;

Tho, N.D; Tan, P.X; Kamioka, E.

Novel projection schemes for

graph-based Light Field coding.

Preprints 2022, 1, 0. https://doi.org/

Publisher’s Note: MDPI stays neutral

with regard to jurisdictional claims in

published maps and institutional afﬁl-

iations.

Copyright: © 2022 by the authors.

Licensee MDPI, Basel, Switzerland.

This article is an open access article

distributed under

the terms and

conditions of the Creative Commons

Attribution (CC BY) license (https://

creativecommons.org/licenses/by/

4.0/).

(cid:1)(cid:2)(cid:3)(cid:1)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:1)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7) 
 
 
 
 
 
2 of 25

it assures that the redundancies within and between views can still be efﬁciently exploited
at some target coding bitrates. This allows the redundancy in bigger pixel regions where the
signal is smooth to be efﬁciently exploited. As the result, high rate-distortion performance can
be achieved. However, compared to HEVC Lozenge [7] and JPEG-Pleno [8], the method in
[15] remains outperformed for real LF suffering from vignetting effect and synthetic LF at high
bitrates, despite having highest rate-distortion at low bitrates. Additionally, their execution
time is reported to be 10 times higher than HEVC for a single LF at the same target quality,
mainly due to time complexity of Laplacian eigen-decomposition.

It is believed that the main reason why [15] doesn’t perform well on high coding bitrates
relates to the error in disparity information used for super-rays projection. To elaborate this
point, a closer look on the concept of super-rays as the common support of graph-based LF
coding studies is needed. It is an extension to super-pixels over-segmentation in 2D images
[24]. In other words, upon views of LF, each super-ray is a group of corresponding super-pixels
across all views. The purpose is to group similar light rays coming from the same object in the
3D space to different viewpoints, as an analogy to grouping perceptually similar pixels being
close to each other in 2D image. The similarity contains high redundancy, and thus good energy
compaction can be obtained in the frequency domain. In details, existing graph-based LF
coding studies [13–15] segments top-left view into super-pixels, computes the median disparity
per super-pixel based on the estimated disparity of top-left view, then applies disparity shift
for the projection of a super-pixel from the reference view to remaining views at both encoder
and decoder. Due to the similar geometry (structures of objects) and optical characteristics
(distance from camera to objects) between the viewpoints, scaling of the disparity value can
be used to shift the pixels from one viewpoint to any other viewpoint. This emphasizes the
importance of the accuracy of disparity information to the projection of super-pixels.

However, in the case of real LF captured by plenoptic camera or camera array, if the
selected reference view suffers from vignetting effect, the estimated disparity would not be
accurate, and thus the projection of super-pixels would also suffer errors, leading to incorrect
position of corresponding super-pixel in target view. For synthetic LF generated by software,
the baseline distance between every two viewpoints has no constraint, and thus it usually
has much larger disparity between views compared to real LF, whose baseline is limited by
aperture size of a plenoptic camera. Hence, using only one median disparity per super-ray
would make the super-ray projection less accurate, particularly when super-pixel size is large.
To this end, in this paper, two novel projection schemes related to selection of reference
views for super-ray projection for real LF and synthetic LF, are proposed, to tackle error in
disparity information and improve the super-ray projection quality. For real LF with vignetting
issue, instead of using top-left view as a reference view, the center view is proposed to be
used. This allows the projection to spread out to neighboring views symmetrically in both
directions. As the result, the properties of the obtained depth map are preserved. For synthetic
LF having large disparity, instead of choosing only a single reference view in top-left corner,
multiple views in a sparse distribution is proposed. This allows to perform projection to closer
views. As the result, the error of median disparity per super-ray used for projection can be
reduced. Moreover, each reference view would be associated with a distinct global graph (a
set of all super-ray graphs), and thus the original global graph is divided into smaller sub
global graphs. As the result, they can be processed in parallel, decreasing time computation.
In order to determine optimal number of views in this proposal, a Lagrangian minimization
problem is solved. The purpose is to avoid increasing bitrates during transmission of reference
segmentation maps and disparity maps.

The experimental results demonstrate that by using the proposed projection schemes,
higher rate-distortion performance and lower time computation are generally achieved, in
comparison with various baselines. The main contributions of the paper are as follows:

3 of 25

• How vignetting effect results in inaccurate depth estimation, how large disparity between
views leads to higher median disparity error for projection, and how these issues affect
the projection quality are examined qualitatively and quantitatively.

• A center view projection scheme is proposed for real LF with large parallax, suffering
from vignetting effect in peripheral views, in which the center view is selected as the
reference instead of top-left view. This scheme outperforms both original scheme [15] and
state-of-the-art coders like HEVC or JPEG Pleno at low and high bitrates.

• A multiple views projection scheme is proposed for synthetic LF, in which the positions
of reference views are optimized by a minimization problem, so that projection quality
is improved and inter-views correlations can still be efﬁciently exploited. In results,
this proposal signiﬁcantly outperforms the original scheme [15] in terms of both Rate
Distortion and time computation, by parallel processing sub global graphs with smaller
dimensions.
A comparative analysis with qualitative and quantitative results is given on rate-distortion
performance between the two proposals and original projection scheme [15], as well as
HEVC-Serpentine and JPEG Pleno 4DTM .

•

The rest of the paper is organized as follows: Section 2 introduces LF compression cate-
gories and recent studies on graph-based LF compression. Section 3 provides a veriﬁcation
of the issues resulting in the error of disparity information. A detailed description of the two
projection schemes is given in Section 4. In Section 5 and 6, experimental results and analysis
are discussed to evaluate the performance of proposals. Conclusion is given in Section 7.

2. Related Work

In this section, the paper ﬁrst reviews categories of LF representations and their associated
compression approach, then further surveys existing studies on graph-based LF compression.
The goal is to understand the current progress of LF compression, the potentials of graph-
based LF coding and clarify the beneﬁt of graph coarsening and partitioning over other recent
graph-based approach, as well as its existing issues.

2.1. Light Field compression

LF compression can be generally based on two approaches: compressing the raw lenslet
image (2D image) or compressing multiple views (array of 2D images) extracted from the raw
data.

The ﬁrst category aims at LF with lenslet-based representation, which is a 2D image
containing a grid of microlens images, and most of its solutions [9–12] take advantage of
existing HEVC by extending new intra prediction modes exploiting correlation between micro-
images, each of which is the captured image from each micro-lens.

Methods in the second category aim at pseudo-video-sequence based, multiview based,
volumetric based, and geometry-assisted based LF representations, all of which can be gener-
ated from lenslet acquisition, or multiview acquisition. In the case of raw lenslet acquisition,
captured by plenoptic camera, the image is ﬁrst preprocessed by de-vignetting and demosaic-
ing, then a dense array of views (micro-images or sub-aperture images) are extracted. For
multiview acquisition, captured by an array of cameras, multiple views with full parallax can
be used directly without preprocessing. The variety of ways the views are stacked together
inspire different LF compression approaches. Pseudo-video-sequence (PVS) based, volumetric
based, and multiview based LF representations attempt to stack the views into 1D or 2D array
of viewpoints, similar to the concept of traditional 2D or 3D videos, and thus conventional 2D
or 3D coders (i.e: HEVC, JP3D [16], MVC [17–21], MVC-HEVC [22]) can be used.

The most recent geometry-assisted based LF representation does not heavily rely on
stacking viewpoints or try to consider the whole LF content as a 2D/3D video, hence it depends

less on traditional coders, and has high potential for improvement. Instead, research into this
category focuses on key view selection and geometry estimation problems, as depicted in Fig.
1.

4 of 25

Figure 1. Geometry-assisted representation for LF

Geometry-assisted based LF representation is accompanied with view synthesis based
LF compression, which has been adopted in the 4DPM (4D prediction) mode of JPEG Pleno, a
new standard project within the ISO/IEC JTC 1/ SC 29/WG 1 JPEG Committee, specialized
in novel image modalities such as textured-plus-depth, light ﬁeld, point cloud, or holograms.
JPEG Pleno implements two strategies to exploit LF redundancy, 4DTM and 4DPM. The 4DTM
mode utilizes a 4D transform approach, and targets real LF with high angular view density
obtained by plenoptic cameras. Raw LF in lenslet format is ﬁrst converted into multiview
representation, and 4DTM partitions LF into variable-size 4D blocks (two spatial and two
angular dimensions), then each block is transformed using 4D DCT. On the other hand, the
4DPM mode divides multiple views of LF into a set of reference views and intermediate views.
Texture and geometric depth of reference views are encoded using JPEG 2000, then at the
decoder side, a hierarchical depth-based prediction technique is used to obtain depth maps of
discarded views, and their textures are warped from the references based on obtained depths.
Hence, the 4DPM mode can encode LF very efﬁciently under reliable depth information.
However, at the time of this paper, the 4DPM mode is not yet available in the open source code
of JPEG Pleno Reference Software [23], and thus, the 4DTM mode is used for comparison in
this paper instead.

2.2. Graph-based Light Field coding

Graph-based Light Field coding falls into the second category of LF compression which
compresses a dense array of 2D images (micro-images or sub-aperture images) extracted from
the raw lenslet LF, aiming at geometry-assisted based LF representation. Graph vertices are
used to describe colors with pixel intensities as graph signals, while graph connections reﬂect
geometry dependencies intra-view or inter-view. The graph signals are transformed into
frequency domain to exploit energy compaction using Graph Fourier Transform (GFT), then
quantized and encoded to send to the decoder, while the graph support (Laplacian matrix) can
be encoded using a separate lossless coder.

In [13], a graph-based solution is proposed with graph support deﬁned on the super-ray
segmentation, ﬁrst introduced in [24] to group light rays of similar color being close in 3D
space, as an extension to the concept of super-pixels obtained by SLIC segmentation in 2D
image [25]. A super-pixel groups perceptually similar pixels within a view, and a super-ray
groups corresponding super-pixels across views, and total super-rays form up the LF image.
Their proposal ﬁrst selects top-left view as the key view, obtains super-pixels segmentation
labels using SLIC algorithm [27], computes its disparity map using method in [28], then project
super-pixel labels to other views based on disparity shift, and construct local graphs of super-
rays across all views. Spatial edges connect pixels within a super-pixel, and angular edges

5 of 25

form connections between corresponding pixels of the same super-pixel at every four views.
An example of the process is illustrated in Fig. 2, Fig. 3, and Fig. 4. Their results have shown to
outperform HEVC Lozenge [7] at high bitrates for all real LF datasets, but performs worse at
low bitrates. This can be explained by the fact that using limited size for graph support might
cope with computational complexity of high dimensional non-separable graph, yet it may not
enable GFT to exploit long term spatial or angular redundancy of signal.

Figure 2. An example of super-pixel segmentation
for real world LF on dataset Fountain_Vincent_2,
with number of super-pixels set at 2000

Figure 3. A super-ray graph consisting of spatial
graphs connecting pixels within a super-pixel and
angular graphs connecting corresponding pixels
across views. I1,1, I1,2, I2,1, I2,2 are four adjacent
views

Figure 4. Top-left view projection scheme based on median disparity per super-pixel

In [14], the authors improve their previous work in [13] by addressing the issue of limited
local graph size, and propose sampling and prediction schemes for local graph transform
to exploit correlation beyond limits of local graph, without extending graph size. Their
proposal ﬁrst samples the LF data based on graph sampling theory to form a new image of
reference samples, then encodes it with conventional 2D image coder with powerful intra-
prediction ability. The encoder sends the coded reference image along with only high frequency
coefﬁcients of graph transforms. At the decoder side, a prediction mechanism in the pixel
domain is introduced to predict the low frequency coefﬁcients using the obtained reference

6 of 25

image and high frequency coefﬁcients. Their schemes are designed for quasi-lossless (high
quality) coding and have shown substantial RD gain compared to HEVC-Inter Raster scan at
lossless mode. However, their performance can drop drastically with lower bitrate, because the
prediction scheme is highly dependent on high frequency coefﬁcients, in which a tiny change
(i.e. small rounding) may lead to signiﬁcant reduction in reconstruction quality.

Their most recent study [15] also deals with the high complexity of non-separable graph
in [13] using graph coarsening and partitioning, guided by a rate-distortion model for graph
optimization. Graph coarsening is performed to reduce the number of vertices inside a super-
ray graph, below a threshold leading to acceptable complexity, while retaining basic properties
of the graph. If signal approximation of a reduced graph gives too coarse reconstruction of
the original signals, or contains two regions with different statistics properties despite having
acceptable number of vertices, the local graph is partitioned into two sub-graphs instead. Their
experiment results have shown to surpass other state-of-the-art coders like HEVC Lozenge
[7] and JPEG Pleno [8] for ideal real LF, but outperformed by most coders at high bitrates
(quasi-lossless) for real LF suffered from vignetting effect, and synthetic LF, even though their
proposal’s performance still exceed others at low bitrate.

Importantly, both [14] and [15] implement the same super-ray projection mechanism as
in [13]. They select the top-left view as the reference view, compute its disparity map and
segmentation map, then project the super-pixels labels to all other views based on the median
disparity per super-pixel, as illustrated in Fig. 4. The projection scheme proceeds row by
row, with horizontal projection from left to right in each row, and one vertical projection
from above for the ﬁrst view of every row. However, top-left view might not be the optimal
selection for reference view on real LF due to vignetting, and choosing one median disparity
per super-ray might incur high disparity error on synthetic LF, if every pixel in super-pixel has
high disparity, especially when the super-pixel is large. This research’s purpose is to clarify
how the above issues bring negative impact on disparity information, then to propose two
novel projection schemes to mitigate the issues, and obtain enhanced projection quality of
super-pixels. The main focus is to improve the most recent graph-based solution [15] with
already better performance among the other two approaches [13,14], so that it can perform well
on all range of coding bitrates for all types of LF, using the two proposed projection schemes.

3. Impact of disparity information on projection quality

In this section, the issues related to affecting reconstructed view quality in [15] are shown

as follows,

• How vignetted real LF affects its disparity estimation ?
• How synthetic LF with large disparity leads to higher median disparity error ?
• How both issues affect the quality of super-ray projection ? To support the veriﬁcation,
SSIM metric [36] was used to compute the projection quality for each view with top-left
view projection.

3.1. Vignetting effect degrades disparity estimation

Vignetting has been extensively surveyed regarding its impact on traditional 2D stereo
correspondence problems [26] among other radiometric differences such as image noises,
different camera settings, etc. Stereo correspondence or stereo matching is an active topic in
computer vision with the goal to estimate depth information for 2D images from an image
pair. However, optical ﬂow based approach has shown to outperform stereo based algorithms
[29,30] in the task of depth estimation for LF in recent literature [27,28]. This section provides
a demonstration on how vignetting impacts optical ﬂow based LF depth estimation in a
subjective manner.

7 of 25

Due to inability to efﬁciently capture light rays in peripheral lens, plenoptic cameras
usually produce vignetted border views in a multiview based representation of a LF content
captured at wide angle, which is essential to provide high parallax. First, considering the case
of real LF with medium parallax (9x9 views), this experiment examines the difference between
the top-left and center views of dataset Friends [32] qualitatively. As depicted in Fig. 5, the
two images are almost identical, with a tiny shift in position of objects, but no visual distortion
in terms of colors or blurring occurs. The depth map of top-left view is then computed using
optical ﬂow based method in [28] and compared with their original result, also with two other
state-of-the-art stereo based disparity estimators, [29] and [30]. From Fig. 6, it’s apparent that
the obtained disparity map adheres closely to the basic depth properties which all methods
share in common.

(a) Top-left view

(b) Center view

Figure 5. Samples of views in dataset Friends

(a) Estimated disparity map of
top-left view using [28]

(b) Estimated disparity map of
center view using [29]

(c) Estimated disparity map of
center view using [30]

Figure 6. Disparity maps obtained using optical-ﬂow based and stereo-based depth estimators in dataset
Friends

However, in the case of real LF with high parallax (13x13 views), the obtained depth
map might lose these properties due to vignetting effect, even after de-vignetted by color
correction methods. A comparison between the top-left view and center view of dataset
Fountain_Vincent_2 [32] with 13x13 views is shown in Fig. 7a and Fig. 7c. The original top-left
view can be seen with signiﬁcant degradation in intensity and color. Gamma correction can be
used for color calibration, and thus help reduce vignetting considerably, as seen from Fig. 7b.
However, a close look at the calibrated top-left view reveals object details are blurry with minor
distortion in the colors, yet its estimated disparity map is severely affected. It is much worse
compared to the output in center view using the same optical ﬂow based [28] or stereo based
[29,30] depth estimation, illustrated in Fig. 8. For example, the fountain, which is closest to the
camera, now shares the same depth as some of objects in the background (i.e. tree), whereas a
segment of the wall now becomes the closest, according to its depth. The results have shown
even a minor vignetting effect can result in signiﬁcant deterioration of the estimated depth
map in peripheral views.

8 of 25

(a) Top-left view (original)

(b) Top-left view (de-vignetted
using gamma correction)
Figure 7. Samples of views in dataset Fountain_Vincent_2

(c) Center view

(a) Estimated disparity
map of top-left view
(gamma corrected) using
[28]

(b) Estimated disparity
map of center view using
[28]

(c) Estimated disparity
map of center view using
[29]

(d) Estimated disparity
map of center view using
[30]

Figure 8. Disparity maps obtained using optical-ﬂow based and stereo-based depth estimators in dataset
Fountain_Vincent_2

3.2. Synthetic LF with large disparity leads to high median disparity error for a super-pixel

While real LF captured using plenoptic camera has baseline limited by the aperture size
of the camera lens, synthetic LF can be generated using graphics software without baseline
restraint, enabling wide parallax for the viewer. Therefore, synthetic LF may have much larger
disparity between views than real LF, leading to higher median disparity error per super-ray.
This can considerably affect the projection of super-pixel locations from reference view to
remaining views. In Table 1, the previews of two real LF and two synthetic LF are displayed,
along with their optical ﬂow between a pair of views, and the disparity range. The intensity
of color in the optical ﬂow is proportional to the disparity. And the disparity range displays
maximum and minimum of disparity value in the whole LF. It can be seen that synthetic LF
has distinctively more intense optical ﬂow and wider range of disparity.

In order to verify this issue, a mathematical explanation is given. This scenario considers
the projection scheme based on disparity shift, which was used by the authors in [13–15]. As
illustrated in Fig. 4, disparity shift scheme increases disparity proportionally to the distance
between the target and reference view. Our goal is to verify that the further the target view, the
higher the median disparity error, hence worse projection of super-pixel labels. Let’s consider
an arbitrary super-pixel in the reference view (top-left), depicted in Fig. 9.

Center view

Optical Flow

Disparity range

9 of 25

Datasets
Fountain_Vincent_2
[32] (real LF)

Danger_de_Mort
(real LF)

[32]

Greek [33]
LF)

(synthetic

Sideboard
thetic LF)

[33]

(syn-

−0.495 → 0.798

−1.306 → 0.683

−2.880 → 3.637

−1.513 → 1.845

Table 1. Comparison of disparity range between real LF and synthetic LF

Figure 9. An example of super-pixel segmentation for synthetic LF on dataset Greek, with the number of
super-pixels set at 1200. The selection of an arbitrary super-pixel is highlighted in red.

Denote all disparity values of every pixel in this super-pixel as D = d1, d2, ..., dn where n is
the total number of pixels, and dm is the median disparity value of this set. Since a super-pixel
follows well to any object’s boundary, it’s safe to assume that no super-pixel contains pixels of
two separate objects at two distinct depth planes, and thus the disparity variation is smooth, or
a normal distribution of disparity values in a super-pixel is obtained most often. Therefore,
without loss of generality for all super-pixels, this veriﬁcation considers the median disparity
is equal to the mean value, as equation (1),

dm =

∑n

i=1 di
n

(1)

The median disparity error is calculated as follows,

mse =

1
n

n
∑
i=1

(di − dm)2 =

1
n

n
∑
i=1

(cid:52)2

Denote mse1, (cid:52)1 as the median disparity error and the disparity error, respectively calcu-
lated at view 1 (reference view), and msek, (cid:52)k at view k. Since disparity of a pixel at view k is k
times higher than at view 1, the following equations are derived,

10 of 25

mse1 =

msek =

1
n

1
n

n
∑
i=1

n
∑
i=1

(cid:52)2
1

(cid:52)2
k

(cid:52)1 = di − dm = di −

∑n

i=1 di
n

(cid:52)k = k ∗ di − d(cid:48)

m = k ∗ di −

∑n

i=1 k ∗ di
n

= k ∗ (di −

∑n

i=1 di
n

) = k ∗ (cid:52)1

⇒ msek =

1
n

n
∑
i=1

k2 ∗ (cid:52)2

1 = k2 ∗

1
n

n
∑
i=1

(cid:52)2

1 = k2 ∗ mse1

(2)

Hence, if using the original projection scheme proposed by the authors [13–15], the median
disparity error of a speciﬁc super-pixel at target view k is k2 higher than the reference view. As
the consequences, the further the target view, the more inaccurate that super-pixel is relocated.
Furthermore, the issue becomes worse when the disparity is already large, as in synthetic LF.

3.3. Inaccurate disparity information leads to poor super-ray projection

To evaluate how super-ray projection scheme used in [13–15] are affected by disparity
error in a quantitative manner, SSIM [36] metric was used to measure the similarity of the
segmentation labels in a target view, between ground truth labels (segmented using SLIC
algorithm [27]) and projected labels from reference view, with projection scheme depicted in
Fig. 4. Speciﬁcally, the evaluation formula is given in equation (3),

quality = SSI M(Li,j, L(cid:48)

i,j)

(3)

where i, or j is the location of the target view in 2D array of views; Li,j is denoted as
“ground truth” image where every pixel intensity is the label value of the super-pixel it belongs
to, assigned by SLIC; L(cid:48)
i,j is also an image of labels, but assigned by super-ray projection from
reference view. SSIM value range is between 0 and 1, with 1 meaning best quality, or the two
images are identical, and the lower the worse.

3.3.1. For real world LF with high parallax (vignetting)

First, the real world LF dataset Fountain_Vincent_2 [32] 13x13 views was considered. This
dataset suffers from vignetting, which then leads to inaccurate disparity map. The ground truth
labels of each view were obtained using python SLIC segmentation library, with parameter
values as compactness = 30 and n_segments = 2000. The projection quality of 13x13 views
was computed, as shown in Table 2. Results have shown that the view with highest quality
is apparently the reference view (top-left), since no projection was made, and the quality
gradually deteriorates when the projection was made to further target views. The disparity
error accumulated for lower views being selected as references for horizontal projection in the
ﬁrst column, and the views at bottom right corner obtained the worst quality, which means
the reconstructed super-pixels of those views might have been located at highly inaccurate
positions, hence the distortion. Similarly, the projection quality of dataset Danger_de_Mort [32]
is given in Table 3.

11 of 25

1.000 0.971 0.963 0.958 0.953 0.952 0.950 0.950 0.950 0.945 0.945 0.942 0.941
0.956 0.961 0.955 0.951 0.947 0.947 0.945 0.946 0.945 0.942 0.941 0.939 0.936
0.943 0.941 0.939 0.939 0.935 0.934 0.932 0.932 0.931 0.932 0.930 0.928 0.926
0.935 0.933 0.930 0.930 0.929 0.927 0.927 0.923 0.923 0.925 0.923 0.922 0.921
0.921 0.920 0.922 0.923 0.921 0.920 0.918 0.917 0.915 0.916 0.915 0.913 0.915
0.914 0.913 0.915 0.915 0.915 0.914 0.910 0.909 0.909 0.909 0.908 0.909 0.909
0.907 0.907 0.905 0.906 0.906 0.905 0.903 0.903 0.904 0.903 0.903 0.903 0.902
0.902 0.902 0.900 0.900 0.900 0.899 0.899 0.899 0.899 0.899 0.897 0.897 0.896
0.895 0.897 0.895 0.896 0.896 0.896 0.896 0.895 0.895 0.894 0.893 0.892 0.891
0.892 0.893 0.892 0.890 0.891 0.891 0.892 0.892 0.890 0.890 0.889 0.888 0.889
0.886 0.888 0.887 0.884 0.885 0.885 0.886 0.886 0.886 0.886 0.884 0.882 0.883
0.877 0.883 0.885 0.882 0.883 0.882 0.882 0.881 0.882 0.881 0.880 0.880 0.880
0.873 0.875 0.876 0.880 0.880 0.878 0.879 0.878 0.877 0.876 0.877 0.877 0.876
Table 2. Projection quality of 13x13 views in dataset Fountain_Vincent_2 using top-left view projection
scheme. Reference view with absolute quality is highlighted in green.

1.000 0.969 0.961 0.959 0.951 0.951 0.948 0.952 0.949 0.943 0.943 0.941 0.939
0.955 0.959 0.953 0.949 0.946 0.945 0.944 0.945 0.943 0.941 0.939 0.937 0.934
0.941 0.940 0.938 0.938 0.933 0.933 0.930 0.931 0.929 0.930 0.929 0.926 0.925
0.933 0.932 0.928 0.929 0.929 0.926 0.925 0.921 0.922 0.923 0.921 0.921 0.920
0.920 0.918 0.920 0.921 0.919 0.919 0.917 0.915 0.913 0.915 0.913 0.912 0.913
0.913 0.914 0.914 0.914 0.913 0.912 0.911 0.908 0.907 0.908 0.909 0.908 0.907
0.906 0.905 0.904 0.904 0.905 0.903 0.901 0.902 0.903 0.901 0.901 0.901 0.900
0.900 0.901 0.898 0.901 0.899 0.897 0.898 0.897 0.897 0.897 0.897 0.894 0.893
0.893 0.896 0.894 0.895 0.895 0.894 0.894 0.894 0.893 0.891 0.892 0.889 0.888
0.891 0.891 0.892 0.889 0.890 0.890 0.890 0.891 0.888 0.889 0.888 0.886 0.886
0.888 0.887 0.886 0.882 0.884 0.883 0.885 0.883 0.884 0.883 0.883 0.879 0.882
0.876 0.881 0.884 0.880 0.882 0.880 0.881 0.880 0.879 0.878 0.879 0.878 0.877
0.872 0.874 0.875 0.878 0.879 0.877 0.877 0.877 0.874 0.873 0.876 0.874 0.873
Table 3. Projection quality of 13x13 views in dataset Danger_de_Mort using top-left view projection
scheme. Reference view with absolute quality is highlighted in green.

3.3.2. For synthetic LF with high median disparity error per super-ray

The projection quality was examined in synthetic dataset Greek [33] 9x9 views using SLIC
with the same parameters as for real LF datasets. Results in Table 4 reveal that the quality
of each view deteriorated much faster in both directions, due to large disparity between the
views. Despite having fewer views than vignetted real LF, dataset Greek ended up having
worse projection quality at bottom right views. Similarly, Table 5 illustrates projection quality
in synthetic dataset Sideboard [33].

12 of 25

1.000 0.958 0.941 0.931 0.927 0.924 0.921 0.922 0.918
0.941 0.932 0.925 0.919 0.916 0.913 0.911 0.910 0.906
0.915 0.912 0.908 0.906 0.904 0.901 0.900 0.898 0.896
0.898 0.897 0.898 0.896 0.895 0.893 0.891 0.889 0.887
0.889 0.889 0.887 0.886 0.886 0.885 0.883 0.882 0.883
0.887 0.886 0.884 0.884 0.882 0.882 0.882 0.882 0.883
0.889 0.888 0.886 0.886 0.884 0.884 0.883 0.884 0.884
0.884 0.880 0.880 0.878 0.878 0.878 0.879 0.879 0.875
0.877 0.875 0.872 0.872 0.871 0.871 0.872 0.870 0.870
Table 4. Projection quality of 9x9 views in dataset Greek using single-view projection scheme. Reference
view with absolute quality is highlighted in green.

1.000 0.952 0.927 0.914 0.911 0.906 0.901 0.901 0.895
0.949 0.934 0.921 0.911 0.906 0.902 0.899 0.897 0.892
0.919 0.914 0.907 0.898 0.892 0.891 0.886 0.884 0.885
0.904 0.897 0.891 0.888 0.882 0.884 0.881 0.877 0.877
0.882 0.885 0.881 0.878 0.876 0.877 0.874 0.874 0.868
0.877 0.875 0.873 0.872 0.870 0.870 0.869 0.866 0.863
0.867 0.869 0.869 0.868 0.867 0.867 0.865 0.862 0.863
0.863 0.862 0.863 0.864 0.863 0.865 0.864 0.861 0.859
0.860 0.860 0.860 0.859 0.861 0.862 0.860 0.858 0.857
Table 5. Projection quality of 9x9 views in dataset Sideboard using single-view projection scheme.
Reference view with absolute quality is highlighted in green.

4. Proposals

In this paper, two novel projection schemes are proposed for real LF and synthetic LF as

follows:

•

•

For real LF with many viewpoints suffering from vignetting effect, the proposed approach
is that super-ray projection is carried out on the center view as the reference, then spreads
out to surrounding views, instead of top-left one with inaccurate disparity.
For synthetic LF with large disparity, a projection scheme using multiple views in a sparse
distribution as references is proposed, aiming to reduce the distance between target and
reference views. In addition, using multiple reference views can create multiple sub global
graphs which are processed simultaneously. This allows to mitigate computational time
for both encoder and decoder.

4.1. Center-view projection scheme

The proposed center-view projection scheme is illustrated in Fig. 10. The purpose of
this proposal is to improve rate distortion performance of [15] in real world LF data with
large parallax, which is suffered from vignetting in peripheral views. From a center view,
the projection spreads out to neighboring views, instead of proceeding row by row in one
direction, as in [13–15]. Speciﬁcally, for a NxN views real LF, this scheme performs a horizontal
projection from the center view I N+1
2 views symmetrically on the center
row R N+1
. Vertical projection is also carried out in the center column symmetrically in both
as reference. Then for each remaining N − 1 rows, its center view
directions, with I N+1
is now used as reference for the horizontal projection, covering all views of remaining N − 1
columns. This projection scheme not only avoids inaccurate disparity estimation in top-left

to remaining N

, N+1
2

, N+1
2

2

2

2

view due to vignetting, but also allows projection to closer views (half the distance compared
to top-left view projection), hence quality of more views can be improved.

13 of 25

Figure 10. Center-view projection scheme

4.2. Multiple views projection scheme

The purpose of this proposal is to improve rate distortion performance and reduce time
computation when applying the approach in [15] into synthetic LF data with large disparity
between views. Equation (2) has shown that the median disparity error of any super-pixel in a
target view is k2 higher than of corresponding super-pixel in reference view, in which target
view is the kth view away from the reference. This negatively affects the projection quality.
In addition, using a single view as a reference will result in a single global graph with very
high dimension, which leads to high encoding and decoding time. Hence, to deal with these
two problems at the same time, a novel idea is to increase the number of reference views in a
row or column. Thereby, the distance from reference views to the to-be-projected views will
be decreased. At the same time, multiple smaller global graphs can be created, which enable
leveraging the power of parallel computing to improve the execution time.

The question is how many references should be sufﬁcient. Too many references would
lead to inability to efﬁciently exploit angular correlation across views of the whole LF, whereas
few references would cause each reference view to project to further views, and thus increase
projection error. Another interpretation of this question is how many views should each
reference view project to, in a row or a column.

The question can be answered by ﬁnding a target view with worst projection quality, while
being close to the reference view as much as possible, then use its ground truth segmented labels
as a new reference view for a new projection chain. This can be interpreted as a Lagrangian
minimization problem,

or

min(k[x] + λ ∗ SSI M[x])

min(SSI M[x] + λ ∗ k[x])

(4)

(5)

, where k can be considered as an array of distances between target and reference view
in a single direction (with number of views as unit) k = k1, k2, ..., kn−1; SSI M is an array of
projection quality computed using equation 3 in the same direction (multiplied with 100 to be
on the same scale as k) SSI M = q1, q2, ..., qn−1; and n is the number of views for that row or
column. k and SSIM arrays exclude the reference view. Equation (4) or (5) can be re-expressed
as,

minx k[x] w.r.t SSI M[x] = SSI Mtarget = const

(6)

or

14 of 25

(7)
The optimal Lagrange multiplier λ∗ is unknown in advance, and can be varied with the

minx SSI M[x] w.r.t

k[x] = ktarget = const

desired distance of views (ktarget) or quality (SSI Mtarget).

The optimal solutions to equation (6) or (7) are the optimal points (k[x∗], SSI M[x∗]) lying
on the lower half convex hull of the scatter plot of SSIM and k. For the sake of simplicity, the
median point on the convex hull (k[x∗∗], SSI M[x∗∗]) is chosen as the new reference view to
avoid being too close or too far from the reference view.

An example is shown in Fig. 11, using data in Table 4 of dataset Greek 9x9 views, the SSIM
values are plotted against k values for horizontal projection (ﬁrst row) and vertical projection
(ﬁrst column). For each type of projection, this method ﬁnds its corresponding convex hull,
then determines the median point as the next reference. Fig. 11a reveals k[x∗∗] = 4 for both
directions, or the new reference for horizontal projection is the 4th view away from the original
top-left reference view, while vertical projection also selects the 4th view. New projection
scheme can be seen in Fig. 11b with four reference views, instead of one. It should be noted
that views I1,9 and I5,9 are not selected as references because no more views to be projected
after them, despite being the 4th view away from the previous references.

(a) Scatter plot of target views based on its distance
to reference view and its projection quality. Potential
candidates selected as the next reference view lie on
the convex hull

(b) Multi-view projection scheme using every 4th
view horizontally and vertically as reference views

Figure 11. Multi-view projection scheme in dataset Greek

Denote local graph to be the graph with spatial and angular connections within a super-ray,
and global graph to be the set of all local graphs. The original high dimensional global graph is
now partitioned into four sub global graphs with better projection quality and less complexity,
while still exploiting angular correlations of at least four views in every direction.

Additionally, depending on the technical implementation, all four sub global graphs
can be processed simultaneously by taking advantage of parallel programming. The main
complexity of graph based LF coding lies in its Laplacian diagonalization of each local graph,
which is O(n3), with n as the number of nodes. By partitioning into four sub global graphs, n is
reduced by fourth approximately for each global graph, if not accounting for graph coarsening,
and thus time computation can decrease signiﬁcantly. With graph coarsening enabled to reduce
vertices by approximating original graph, as detailed in [15], the number of nodes in original
scheme might be fewer than the total number of nodes in all sub global graphs, because the
original graph with higher dimensions may have more coarsened local graphs than each of sub

15 of 25

global graphs with lower dimensions in the multi references scheme. However, the number of
nodes in each sub global graph is signiﬁcantly smaller than the original, and each sub global
graph is processed independently, hence time computation for both encoder and decoder can
still be reduced considerably.

The selection of references for dataset Sideboard 9x9 views is shown in Fig. 12a and Fig.
12b, in which horizontal projection selects every 3rd view as the new reference, and vertical
projection selects 4th view. The original graph is partitioned into six sub-graphs, exploiting
angular correlations of at least three views in every direction, and having better projected
segmentation maps for all the views, compared to the original projection scheme.

(a) Scatter plot of target views based on its distance
to reference view and its projection quality. Potential
candidates selected as the next reference view lie on
the convex hull

(b) Multi-view projection scheme using every 3rd
view horizontally and every 4th view vertically as
reference views.

Figure 12. Multi-view projection scheme in dataset Sideboard

5. Performance Evaluation

In this section, evaluation of super-ray projection quality for each view is analysed quanti-
tatively to show that it can be improved by the two proposed center view, and multiple views
projection schemes. Then, a set of experiments are designed to evaluate the impact of enhanced
projection quality on overall compression efﬁciency. Finally, experimental results are presented
and analysed.

5.1. Projection quality evaluation
5.1.1. Center view projection scheme

Using equation (3), this experiment computed the projection quality of a vignetted LF,
but with center view as the reference. Table 6 and Table 7 show SSIM quality results on all the
13x13 views of Fountain_Vincent_2 and Danger_de_Mort, with absolute SSIM on center view.
Due to the accurate disparity map, it can be seen that the quality deterioration from the center
view to further views horizontally and vertically were slower than in the case of projecting
from top-left view, described in Table 2 and Table 3. Additionally, quality of more views were
improved because center view projected to more closer views (smaller disparity) to 4 directions,
whereas corner view projected to further views (higher disparity) to 2 directions.

16 of 25

0.917 0.918 0.919 0.919 0.918 0.918 0.921 0.919 0.919 0.918 0.917 0.919 0.917
0.922 0.925 0.925 0.927 0.926 0.926 0.929 0.926 0.926 0.924 0.924 0.924 0.923
0.927 0.928 0.929 0.929 0.929 0.931 0.930 0.928 0.927 0.926 0.925 0.926 0.927
0.938 0.940 0.940 0.941 0.943 0.944 0.946 0.943 0.941 0.938 0.938 0.939 0.938
0.939 0.940 0.940 0.944 0.945 0.947 0.949 0.944 0.942 0.941 0.940 0.941 0.941
0.955 0.954 0.955 0.959 0.962 0.968 0.979 0.965 0.960 0.959 0.957 0.955 0.954
0.959 0.959 0.961 0.965 0.969 0.977 1.000 0.974 0.970 0.968 0.966 0.962 0.958
0.955 0.957 0.957 0.958 0.962 0.965 0.974 0.968 0.964 0.961 0.962 0.960 0.956
0.943 0.944 0.945 0.946 0.946 0.948 0.953 0.949 0.947 0.947 0.944 0.943 0.940
0.940 0.941 0.941 0.941 0.943 0.944 0.946 0.945 0.946 0.944 0.942 0.941 0.939
0.928 0.929 0.931 0.931 0.930 0.930 0.931 0.930 0.931 0.930 0.928 0.924 0.924
0.922 0.925 0.927 0.928 0.928 0.927 0.927 0.926 0.925 0.924 0.920 0.921 0.918
0.911 0.913 0.914 0.917 0.917 0.918 0.916 0.915 0.914 0.913 0.912 0.911 0.908
Table 6. Projection quality of 13x13 views in dataset Fountain_Vincent_2 using center view projection
scheme. Reference view with absolute quality is highlighted in green.

0.917 0.916 0.917 0.920 0.917 0.916 0.919 0.920 0.918 0.917 0.916 0.918 0.916
0.920 0.924 0.924 0.925 0.924 0.925 0.928 0.924 0.924 0.923 0.922 0.922 0.921
0.925 0.926 0.927 0.927 0.927 0.929 0.929 0.927 0.926 0.925 0.924 0.925 0.926
0.936 0.939 0.939 0.939 0.943 0.942 0.944 0.941 0.939 0.937 0.937 0.938 0.936
0.938 0.939 0.939 0.943 0.943 0.945 0.947 0.943 0.940 0.939 0.939 0.939 0.939
0.954 0.955 0.953 0.958 0.960 0.967 0.981 0.963 0.958 0.957 0.959 0.953 0.952
0.957 0.957 0.960 0.963 0.968 0.976 1.000 0.973 0.968 0.966 0.965 0.961 0.956
0.954 0.956 0.956 0.960 0.960 0.963 0.972 0.966 0.962 0.959 0.960 0.959 0.954
0.942 0.942 0.943 0.944 0.945 0.946 0.951 0.948 0.945 0.945 0.943 0.942 0.939
0.938 0.939 0.941 0.939 0.942 0.942 0.945 0.943 0.944 0.943 0.941 0.940 0.937
0.929 0.927 0.930 0.930 0.928 0.929 0.929 0.929 0.930 0.928 0.927 0.922 0.923
0.921 0.923 0.926 0.926 0.926 0.926 0.926 0.924 0.924 0.923 0.919 0.920 0.917
0.909 0.912 0.912 0.916 0.915 0.917 0.914 0.913 0.913 0.912 0.910 0.910 0.906
Table 7. Projection quality of 13x13 views in dataset Danger_de_Mort using center view projection
scheme. Reference view with absolute quality is highlighted in green.

5.1.2. Multiple views projection scheme

Table 8 and Table 9 show projection quality of synthetic LF Greek and Sideboard using
multiple views projection scheme. Absolute SSIM was found in all reference views. Although
the deteriorating rate of quality remained fast due to large disparity, quality of remaining views
were highly improved, compared to Table 4 and Table 5. This can be explained by the fact that
views with worst projection quality used its ground truth segmentation labels instead, then
they became new reference views with accurate segmentation for new projection chains.

17 of 25

1.000 0.958 0.941 0.931 1.000 0.961 0.945 0.935 0.926
0.941 0.932 0.925 0.919 0.940 0.931 0.926 0.920 0.913
0.915 0.912 0.908 0.906 0.913 0.912 0.910 0.905 0.900
0.898 0.897 0.898 0.896 0.901 0.897 0.896 0.894 0.890
1.000 0.956 0.941 0.929 1.000 0.959 0.942 0.931 0.923
0.933 0.925 0.920 0.917 0.936 0.927 0.922 0.917 0.912
0.909 0.907 0.902 0.901 0.910 0.906 0.904 0.900 0.898
0.895 0.894 0.893 0.891 0.895 0.892 0.891 0.890 0.887
0.888 0.885 0.882 0.883 0.887 0.887 0.885 0.883 0.880
Table 8. Projection quality of 9x9 views in dataset Greek using multi-view projection scheme. Reference
views with absolute quality are highlighted in green

1.000 0.952 0.927 1.000 0.941 0.921 1.000 0.946 0.923
0.949 0.934 0.921 0.942 0.925 0.912 0.946 0.928 0.911
0.920 0.914 0.907 0.915 0.906 0.898 0.912 0.905 0.901
0.902 0.897 0.891 0.896 0.890 0.887 0.900 0.891 0.885
1.000 0.945 0.925 1.000 0.945 0.918 1.000 0.943 0.915
0.946 0.929 0.914 0.942 0.927 0.909 0.943 0.924 0.908
0.910 0.907 0.902 0.915 0.908 0.898 0.916 0.905 0.898
0.894 0.889 0.889 0.897 0.893 0.889 0.898 0.891 0.887
0.881 0.880 0.879 0.882 0.884 0.880 0.885 0.880 0.878
Table 9. Projection quality of 9x9 views in dataset Sideboard using multi-view projection scheme.
Reference views with absolute quality are highlighted in green

5.2. Compression efﬁciency evaluation

In order to evaluate the impact of enhanced projection quality on overall performance,
this section assesses Rate Distortion performance and quality of reconstructed LF of the two
proposed Center view and Multi-view projection schemes, and time computation for the
Multi-view projection scheme. This allows to demonstrate the improvement of quality in both
proposals, and also running time for multiple views projection. Real LF datasets captured with
plenoptic cameras were downloaded from the EPFL dataset [32], in which vignetted real LF
with large parallax 13x13 views were Fountain_Vincent_2, and Danger_de_Mort. Meanwhile,
Greek and Sideboard datasets were evaluated for synthetic LF from [33]. In Rate Distortion
quantitative results, the proposals were compared against the original top-left view projection
scheme and two state-of-the-art coders: HEVC with Serpentine scanning topology, and JPEG
Pleno with 4D transform mode (4DTM).

5.2.1. Experiment Setup

The encoder and decoder were run on Python 3 under Ubuntu 20.04 with 64GB RAM,
and utilized python’s Ray library for the parallel processing of super-rays or sub global graphs.
The disparity estimation technique was used from [28] to compute the disparity map for center-
view of real LF, and multiple reference views for synthetic LF. Their segmentation mask was
obtained using SLIC algorithm [27]. Due to lack of memory resources in the this experimental
environment, the initial number of super-rays were set as 2000 and 1200 for real LF 13x13 views
and synthetic LF 9x9 views respectively, instead of 500 as originally used in [15]. The more
super-rays, the smaller the local graphs, and thus they would consume less resources, but with
a trade-off of inefﬁcient decorrelation of signals. On the other hand, having smaller number of

18 of 25

super-rays leads to bigger sizes of graphs, which implies signiﬁcant increase in time complexity
of eigen-decomposition for Laplacian matrix.

The subjective results were obtained when running encoder and decoder with parameter
PSNRmin set at 20, instead of 45 (max value). This parameter was used to guide the rate of
graph coarsening and partitioning. Setting at 20 would return results at low quality (PSNR >=
20), and thus it would be easier to visually differentiate results of the original and proposed
projection schemes, for the purpose of reading paper.

The x.265 implementation of HEVC-Serpentine used in the experiments was run with
source version 2.3, following LF common test conditions [31]. The base quantization parameters
(QP) were set to 10, 28, 35, 50. JPEG Pleno 4DTM was used within Part 4 (Reference Software)
with base Lambdas (quantization parameter) of 25, 1000, 20000, 500000.

Regarding QPs used in both original and proposed schemes, this work implemented
an adaptive quantization approach. After GFT was used to transform signals into frequency
domain, the super-rays coefﬁcients were divided into 32 sub-groups. Since the ﬁrst group
contains low frequency coefﬁcients, which represent fundamental properties of the signals,
and it usually has much higher energy than the next groups, hence more quantization steps
should be assigned for the ﬁrst group to obtain more accurate reconstruction than other groups,
for containing more important coefﬁcients. In other words, the base QPs were set adaptively
for the ﬁrst group and remaining groups. Then optimized quantization step sizes were found
based on rate-distortion optimization approach, as described in [15], with parameter QP set
according for each group. Using the optimized quantization steps sizes, the coefﬁcients in each
group were quantized and arithmetically coded with a public version of Context Adaptive
Binary Arithmetic Coder (CABAC) [34]. At high quality coding, the QPs were set as 4 for the
ﬁrst group, and 10 for the remaining groups. The reference segmentation mask was encoded
using arithmetic edge coder EAC [35], and disparity values (median disparity per super-ray)
were encoded using original arithmetic coder of the authors [15].

Additionally, all reconstructed LFs using any of the four methods in the experiments were
converted into 8-bit for evaluation at the same conditions and their PSNR of the luminance
channel (PSNR-Y) were computed with the same formula, following the LF common test
conditions [31].

5.3. Analysis of Center view projection scheme
5.3.1. Rate Distortion analysis

Rate Distortion performance of the proposed projection with center view as reference was
compared against top-left view projection [13], direct encoding of the views as a PVS using
HEVC-Serpentine, and 4D transform solution utilizing JPEG Pleno 4DTM. The performance
comparison was made on the two datasets Fountain_Vincent_2 and Danger_De_Mort, as
shown in Fig. 13. Substantial gains in the Center view projection proposal can be seen
compared to the original scheme at all bitrates for both datasets, and also the proposed scheme
outperformed HEVC-Serpentine and JPEG Pleno 4DTM, especially at low and high bitrates.

19 of 25

(a) Fountain_Vincent_2

(b) Danger_de_Mort

Figure 13. Rate Distortion performance between center view projection scheme (proposal), top-left view
projection scheme (original), and state-of-the-art codecs HEVC-Serpentine, JPEG Pleno 4DTM

5.3.2. Qualitative analysis for reconstructed LF

At the decoder side, the luminance channel of LF was reconstructed from the quantized
coefﬁcients sent by the encoder. The output results using the original and proposed pro-
jection scheme are shown subjectively in Fig. 14 for Fountain_Vincent_2, and Fig. 15 for
Danger_de_Mort. It can be seen that in both datasets, the proposed Center view projection
returned sharper results, clearly visible in edges around texture, whereas the original scheme’s
results seemed to be blurry in these edges. The blur effect could be caused by super-pixels
reconstructed at inaccurate positions, resulting from poor depth estimation, as a consequence
of vignetted top-left view.

(a) Top-left view projection scheme [15] (original)
Figure 14. Reconstructed luminance channel of center view using projection scheme from top-left view
and center view, in dataset Fountain_Vincent_2

(b) Center view projection scheme (proposal)

20 of 25

(a) Top-left view projection scheme [15] (original)
Figure 15. Reconstructed luminance channel of center view using projection scheme from top-left view
and center view, in dataset Danger_de_Mort

(b) Center view projection scheme (proposal)

5.4. Analysis of Multiple views projection scheme
5.4.1. Rate Distortion analysis

Rate Distortion performance of the Multi-view projection scheme was illustrated in Fig.
16, comparing with original single view projection scheme, HEVC, and JPEG Pleno in datasets
Greek and Sideboard. The proposed scheme signiﬁcantly outperformed the original projection
at all bitrates, for having better projection quality, and surpassed the other two conventional
coders at low bitrates. However, HEVC-Serpentine remained the best compressor for synthetic
LF at medium and high bitrates. This can be explained by the fact that the two synthetic LF
are free of imperfections such as image noises, and thus the performance of classical coders
HEVC and JPEG Pleno were not degraded, hence better Rate Distortion than their results in
real world LF. Nevertheless, the proposal performed slightly worse on dataset Greek, compared
to Sideboard, because the disparity between views in Greek is higher than other datasets, as
shown in Table 1, leading to higher median disparity error per super-ray used for projection. In
addition, more sub-global graphs can be found in Sideboard than Greeks after ﬁnding optimized
positions for reference views, resulting in more views with better projection quality.

(a) Greek

(b) Sideboard

Figure 16. Rate Distortion performance between multi-view projection scheme (proposal), top-left view
projection scheme (original), and state-of-the-art codecs HEVC-Serpentine, JPEG Pleno 4DTM

5.4.2. Qualitative analysis for reconstructed LF

The qualitative results of luminance reconstruction for Greek and Sideboard datasets using
original or Multi-view projection schemes are shown in Fig. 17 and Fig. 18. Same as previous

subjective results of real LF, the proposed Multi-view projection returned sharper results
for synthetic LF, especially around edges of textures, for having more accurate projection of
super-pixels than the single-view projection scheme.

21 of 25

(a) Single view projection scheme [15] (original)

(b) Multiple views references scheme (proposal)

Figure 17. Reconstructed luminance channel of center view using single-view and multi-view projection
scheme, in dataset Greek

(a) Single view projection scheme [15] (original)

(b) Multiple views references scheme (proposal)

Figure 18. Reconstructed luminance channel of center view using single-view and multi-view projection
scheme, in dataset Sideboard

5.4.3. Time computation analysis

Aside from achieving substantial gains in compression performance compared to single-
view projection scheme, multi-view projection can also signiﬁcantly reduce time computation
of both encoder and decoder, with a slight trade off increasing bitrates. An example is given
in Table 10, analyzing the parameters and time duration when running encoder and decoder
on dataset Greek with PSNRmin set at 40, along with output quality PSNR-Y and required

22 of 25

bitrate at high quality coding. The high dimensional graph was separated into four sub global
graphs in the multi-view proposal, as optimized by a minimization problem. The ﬁrst three
columns (param, obtained num_SR, total # of nodes) bring interesting results. It can be seen
that, for the same initial num_SR (number of super-rays / number of local graphs), the output
num_SR and total number of nodes after graph coarsening and partitioning of single-view
scheme (original) were much higher than output of each sub global graphs (proposal). This
means graph coarsening and partitioning rates were higher in the original graph than in each
sub global graph. Thus, the proposed multi-view scheme could retain more accurate graph
information of vertice signals and edges in each sub global graph, in addition to having higher
quality for the projection of super-pixels, since each reference view projected to closer views.
Essentially, the total number of nodes determines the time complexity for eigen-decomposition
of the Laplacian matrix, and it was smaller in each sub global graph. Also, the four sub
global graphs were encoded or decoded simultaneously by running in parallel, and thus the
total approximate encoding and decoding time were reduced by more than half, compared to
processing the original high dimensional graph. Nevertheless, the bitrate slightly increased
due to the fact that more reference segmentation masks and disparity maps were required to
be coded and transmitted alongside the graph coefﬁcients.

Table 10. Encoding time and Decoding time using single-view (original) and multi-view (proposal)
projection scheme on dataset Greek

6. Discussion

Based on evaluation results, it has been shown that the Center view and Multiple views
projection scheme can bring an overall improvement for super-rays projection quality in
all views by having accurate disparity information, leading to better compression efﬁency,
expecially at high bitrates, compared to the original Top-left view projection. Additionally,
combining accurate geometry information with the advantage of graph coarsening proposed
in [15], the graph-based approach can also outperform state-of-the-art coders HEVC and JPEG
Pleno at low bitrates.

The beneﬁt of graph coarsening for graph based approaches is clear, for low bitrates, aside
from its ability to exploit correlations for irregular patterns in textures, which allows them to
outperform the other two state-of-the-art coders HEVC and JPEG Pleno. Graph coarsening
retains total variations of signals on the reduced graphs, while the number of coefﬁcients to
be coded also substantially decreases, leading to good Rate Distortion performance at low
bitrates. Additionally, beside vignetting effect, real world LF might also suffer from image
noises, degrading the performance of traditional coding considerably, but not affecting graph
coarsening, which utilizes low rank model approximation, and thus the noises can be removed.
High quality coding at high bitrates requires particularly accurate super-ray positions,
which depends entirely on the performance of depth estimation algorithm. For real LF, As
veriﬁed in previous section, vignetting effect signiﬁcantly degrades the output depth map of
top-left view, leading to inaccurate super-ray projections, hence the original projection scheme
obtains the lowest Rate Distortion performance. On the other hand, Center view projection
scheme has more accurate depth estimation maps, leading to higher compression performance

23 of 25

than HEVC and JPEG Pleno, which might also be supported by its ability to decorrelate signals
in irregular-shape textures.

For high quality coding of synthetic LF, although the proposed Multiple views projection
scheme signiﬁcantly surpasses the performance of top-left projection scheme, they are still
outperformed by HEVC-Serpentine. The potential solution to obtain competitive performance
with HEVC is to use more reference views, but with a trade off of increasing bitrates for
transmission because more segmentation and disparity information of the references are
needed to be coded and sent to the decoder side. Another possible solution could be using
two median disparity values for each super-pixel within the reference view, then each half
super-pixel would be projected separately to other views, based on the corresponding median
disparity value. The idea is motivated by the fact that, the smaller size the super-pixel possesses,
the smaller the median disparity error becomes, with respect to all disparity values within the
super-pixel. This approach might be discussed further in future work.

Furthermore, for Multi-view projection scheme, time execution for both encoder and
decoder can be considerably reduced by processing all sub global graphs in parallel, while
ensuring correlations between views can still be efﬁciently exploited by optimizing positions of
reference views through a minimization problem. There may be a slight increase in the coding
bitrates due to more reference segmentation and disparity maps are to be coded. Additionally,
based on Fig. 11a and 12a, it should be noted that solving the minimization problem to ﬁnd
optimal reference view might not make signiﬁcant improvement for multiview based LF
representation, compared to directly choosing center view of every projection direction as the
new reference, since there are only a few views to be evaluated, and most of them lie closely on
the convex hull. However, this approach can be applied to lenslet based LF representation, in
which the number of views are large, and thus ﬁnding the views lying on the convex hull can
be more efﬁcient. This idea can also be further discussed in future research.

7. Conclusion

In this paper, two novel projection schemes for graph-based Light Field coding have been
introduced, including Center view and Multiple views projection. The proposals signiﬁcantly
outperformed original Top-left view projection scheme and generally obtained competitive
rate-distortion performance with state-of-the-art coders HEVC (Serpentine scanning) and JPEG
Pleno (4DTM mode). This can only be achieved by having accurate disparity estimation for
Center view projection in real LF with large parallax, and smaller median disparity error
for Multiple views projection in synthetic LF. In addition to improving overall compression
efﬁciency, Multiple views projection can also reduce end-to-end time computation by processing
smaller sub global graphs in parallel. This has shown the potential of further improvement for
graph-based LF coding in order to achieve both competitive performance in both compression
efﬁciency and time computation, compared to state-of-the-art coders.

Author Contributions: Conceptualization, N.G.B., C.M.T., and T.N.D.; Methodology, N.G.B., C.M.T., and
P.X.T.; Supervision, P.X.T. and E.K.; Writing—original draft, N.G.B., C.M.T and T.N.D.; Writing—review
and editing, P.X.T. and E.K. All authors have read and agreed to the published version of the manuscript.

Funding: This research received no external funding.

Institutional Review Board Statement: Not applicable

Informed Consent Statement: Not applicable

Data Availability Statement: Not applicable

Conﬂicts of Interest: The authors declare no conﬂict of interest.

24 of 25

References

1.
2.

3.

4.

5.

6.

R. Ng, "Light ﬁeld photography," Ph.D. dissertation, Dept. Comput. Sci., Stanford Univ., Stanford, CA, USA, 2006.
J. Wang, X.Xiao, H. Hua, and B. Javidi, “ Augmented reality 3D display s with micro integral imaging,” J. Display Technol., vol. 11, no.
11, pp. 889 893, Nov. 2015.
J. Arai, M. Kawakita, T. Yamashita, H. Sasaki, M. Miura, H. Hiura, M. Okui, and F. Okano, “ Integral three dimensional television
with video sys tem using pixel offset method,” Opt. Express, vol. 21, no. 3, pp. 3474 3485, Feb. 2013.
R. Raghavendra, K. B. Raja, and C. Busch, “ Presentation attack detection for face recognition using light ﬁeld camera,” IEEE Trans.
Image Process., vol. 24, no. 3, pp. 1060 1075, Mar. 2015.
Chen, Brian & Buchanan, Ian & Kellis, Spencer & Kramer, Daniel & Ohiorhenuan, Iﬁje & Blumenfeld, Zack & Grisafe, Dominic &
Barbaro, Michael & Gogia, Angad & Lu, James & Chen, Beverly & Lee, Brian. (2018). Utilizing Light ﬁeld Imaging Technology in
Neurosurgery . Cureus. 10. 10.7759/cureus.2459.
T. G. Georgiev and A. Lumsdaine, “Focused plenoptic camera and rendering,” J. Electron. Imag., vol. 19, no. 2, Apr. 2010, Art. no.
021106.

7. M. Rizkallah, T. Maugey, C. Yaacoub, and C. Guillemot, “Impact of light ﬁeld compression on focus stack and extended focus images,”

8.

9.

in Proc. 24th Eur. Signal Process. Conf. (EUSIPCO), Aug./Sep. 2016, pp. 898–902.
Perra, Cristian & Freitas, Pedro & Seidel, Ismael & Schelkens, Peter. (2020). An overview of the emerging JPEG Pleno standard,
conformance testing and reference software. 33. 10.1117/12.2555841.
C. Conti, L. D. Soares, and P. Nunes, “HEVC-based 3D holoscopic video coding using self-similarity compensated prediction,” Signal
Process. Image Commun., vol. 42, pp. 59–78, Mar. 2016.

10. Y. Li, R. Olsson, and M. Sjöström, “Compression of unfocused plenoptic images using a displacement intra prediction,” in Proc. IEEE

Int. Conf. Multimedia Expo Workshops (ICMEW), Jul. 2016, pp. 1–4.

11. C. Conti, P. Nunes, and L. D. Soares, “New HEVC prediction modes for 3D holoscopic video coding,” in Proc. 19th IEEE Int. Conf.

Image Process. (ICIP), Sep./Oct. 2012, pp. 1325–1328.

12. C. Conti, P. Nunes, and L. D. Soares, “HEVC-based light ﬁeld image coding with bi-predicted self-similarity compensation,” in Proc.

IEEE Int. Conf. Multimedia Expo Workshops (ICMEW), Jul. 2016, pp. 1–4.

13. Rizkallah, Mira & Su, Xin & Maugey, Thomas & Guillemot, Christine. (2019). Geometry-Aware Graph Transforms for Light Field

Compact Representation. IEEE Transactions on Image Processing. PP. 1-1. 10.1109/TIP.2019.2928873.

14. Rizkallah, Mira & Maugey, Thomas & Guillemot, Christine. (2019). Prediction and Sampling With Local Graph Transforms for

Quasi-Lossless Light Field Compression. IEEE Transactions on Image Processing. PP. 1-1. 10.1109/TIP.2019.2959215.

15. Rizkallah, Mira & Maugey, Thomas & Guillemot, Christine. (2021). Rate-Distortion Optimized Graph Coarsening and Partition-
ing for Light Field Coding. IEEE transactions on image processing : a publication of the IEEE Signal Processing Society. PP.
10.1109/TIP.2021.3085203.
Information Technology-JPEG 2000 Image Coding System: Extensions for Three-Dimensional Data. ITU-T Recommendation document
T.809, May 2011.

16.

17. A. Vetro, T. Wiegand, and G. J. Sullivan, “Overview of the stereo and multiview video coding extensions of the H.264/MPEG-4 AVC

standard,” Proc. IEEE, vol. 99, no. 4, pp. 626-642, Apr. 2011.

18. G. Tech, Y. Chen, K. Muller, J.-R. Ohm, A. Vetro, and Y.-K. Wang, “Overview of the multiview and 3D extensions of high efﬁciency

19.

20.

21.

video coding,” IEEE Trans. Circuits Syst. for Video Technol., vol. 26, no. 1, pp. 35-49, Jan. 2016.
S. Adedoyin, W. A. C. Fernando, and A. Aggoun, “A joint motion & disparity motion estimation technique for 3D integral video
compression using evolutionary strategy,” IEEE Trans. Consum. Electron., vol. 53, no. 2, pp. 732-739, May 2007.
S. Adedoyin,W. A. C. Fernando, A. Aggoun, andW. A. R. J.Weerakkody, “An ES based effecient motion estimation technique for 3D
integral video compression,” in Proc. IEEE Int. Conf. Image Process., vol. 3, San Antonio, TX, USA, Sep./Oct. 2007, pp. III-393-III-396.
J.Wei, S.Wang,Y. Zhao, and F. Jin, “Hierarchical prediction structure for subimage coding and multithreaded parallel implementation
in integral imaging,” Appl. Opt., vol. 50, no. 12, p. 1707, Apr. 2011.

22. W. Ahmad, R. Olsson, and M. Sjostrom, “Interpreting plenoptic images as multi-view sequences for improved compression,” in Proc.

IEEE Int. Conf. Image Process. (ICIP), Beijing, China, Sep. 2017, pp. 4557-4561.
JPEG Pleno Reference Software [Online] Available: https://gitlab.com/wg1/jpeg-pleno-refsw

23.
24. M. Hog, N. Sabater, and C. Guillemot, “Superrays for efﬁcient light ﬁeld processing,” IEEE J. Sel. Topics Signal Process., vol. 11, no. 7,

pp. 1187-1199, Oct. 2017.

25. R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Süsstrunk, “SLIC superpixels compared to state-of-the-art superpixel methods,”

IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 11, pp. 2274–2282, Nov. 2012.

26. Hirschmuller, H. & Scharstein, Daniel. (2009). Evaluation of Stereo Matching Costs on Images with Radiometric Differences. Pattern

Analysis and Machine Intelligence, IEEE Transactions on. 31. 1582 - 1599. 10.1109/TPAMI.2008.221.

27. Yang Chen, Martin Alain, and Aljosa Smolic, “Fast and accurate optical ﬂow based depth map estimation from light ﬁelds,” in Irish

Machine Vision and Image Processing Conference (IMVIP), 2017

25 of 25

28. X. Jiang, M. Le Pendu, and C. Guillemot, “Depth estimation with occlusion handling from a sparse set of light ﬁeld views,” in Proc.

IEEE Int. Conf. Image Process. (ICIP), Oct. 2018, pp. 634–638.

29. Hae-Gon Jeon, Jaesik Park, Gyeongmin Choe, Jinsun Park, Yunsu Bok, Yu-Wing Tai, and In So Kweon, "Accurate depth map estimation

30.

31.

from a lenslet light ﬁeld camera," in International Conference on Computer Vision and Pattern Recognition, 2015.
Shuo Zhang, Hao Sheng, Chao Li, Jun Zhang, and Zhang Xiong, "Robust depth estimation for light ﬁeld via spinning parallelogram
operator," Journal Computer Vision and Image Understanding, vol.145, pp. 148-159, 2016.
JPEG Pleno Light Field Coding common test conditions v3.3 [Online] Available: http://ds.jpeg.org/documents/jpegpleno/wg1n84049-
CTQ-JPEG_Pleno_Light_Field_Common_Test_Conditions_v3_3.pdf

32. EPFL Light Field Image Dataset. Accessed: 2016. [Online]. Available: http://mmspg.epﬂ.ch/EPFL-light-ﬁeld-image-dataset
33. K. Honauer, O. Johannsen, D. Kondermann, and B. Goldluecke, “A dataset and evaluation methodology for depth estimation on 4D

light ﬁelds,” in Proc. Asian Conf. Comput. Vis. (ACCV). Springer, 2016, pp. 19–34.

34. Context Adaptive Binary Arithmetic Coder (CABAC). [Online] Available: https://github.com/christianrohlﬁng/ISScabac/
35.

I. Daribo, G. Cheung, and D. Florencio, “Arithmetic edge coding for arbitrarily shaped sub-block motion prediction in depth video
compression,” in Proc. 19th IEEE Int. Conf. Image Process., Sep. 2012, pp. 1541–1544.

36. Wang, Zhou & Bovik, Alan & Sheikh, Hamid & Simoncelli, Eero. (2004). Image Quality Assessment: From Error Visibility to Structural

Similarity. Image Processing, IEEE Transactions on. 13. 600 - 612. 10.1109/TIP.2003.819861.

