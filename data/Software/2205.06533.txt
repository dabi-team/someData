2
2
0
2

y
a
M
3
1

]
E
S
.
s
c
[

1
v
3
3
5
6
0
.
5
0
2
2
:
v
i
X
r
a

Assessing the Linguistic Quality of REST APIs for IoT
Applications

Francis Palmaa,∗, Tobias Olssona, Anna Wingkvista, Javier Gonzalez-Huertab

aDepartment of Computer Science and Media Technology, Linnaeus University
bDepartment of Software Engineering, Blekinge Institute of Technology, Sweden

Abstract

Internet of Things (IoT) is a growing technology that relies on connected ‘things’
that gather data from peer devices and send data to servers via APIs (Appli-
cation Programming Interfaces). The design quality of those APIs has a direct
impact on their understandability and reusability. This study focuses on the
linguistic design quality of REST APIs for IoT applications and assesses their
linguistic quality by performing the detection of linguistic patterns and antipat-
terns in REST APIs for IoT applications. Linguistic antipatterns are considered
poor practices in the naming, documentation, and choice of identiﬁers. In con-
trast, linguistic patterns represent best practices to APIs design. The linguistic
patterns and their corresponding antipatterns are hence contrasting pairs. We
propose the SARAv2 (Semantic Analysis of REST APIs version two) approach
to perform syntactic and semantic analyses of REST APIs for IoT applications.
Based on the SARAv2 approach, we develop the REST-Ling tool and empiri-
cally validate the detection results of nine linguistic antipatterns. We analyse
19 REST APIs for IoT applications. Our detection results show that the lin-
guistic antipatterns are prevalent and the REST-Ling tool can detect linguistic
patterns and antipatterns in REST APIs for IoT applications with an average
accuracy of over 80%. Moreover, the tool performs the detection of linguistic
antipatterns on average in the order of seconds, i.e., 8.396 seconds. We found
that APIs generally follow good linguistic practices, although the prevalence of
poor practices exists.

Keywords: REST APIs, IoT Applications, Linguistic Quality, Pattern,
Antipattern, Detection

∗Corresponding author
Email addresses: francis.palma@lnu.se (Francis Palma), tobias.olsson@lnu.se

(Tobias Olsson), anna.wingkvist@lnu.se (Anna Wingkvist),
javier.gonzalez.huerta@bth.se (Javier Gonzalez-Huerta)

Preprint submitted to Journal of Systems and Software

May 16, 2022

 
 
 
 
 
 
1. Introduction

The Internet of Things (IoT) is an emerging technology that relies on net-
works of ‘things’ - smart computing devices - communicating with each other
over the Internet. These ‘connected things’ (i.e., IoT devices) frequently gather
data and send them to servers or receive data from peer devices and act on
them [1].

REpresentational State Transfer (REST) [2] is the de facto standard to de-
sign, develop, and deploy IoT-based applications in cloud environments. The
application programming interfaces (APIs) for IoT applications are designed
following the REST principles by the IoT vendors. The Message Queuing
Telemetry Transport (MQTT) protocol is also supported by some APIs and
the topic structure of MQTT could be seen as an alternative to the API de-
sign in REST. However, the oﬀered functionality is often more limited in its
scope, and it is often only recommended to use MQTT for certain applications
where the lightweight nature of the protocol is necessary.
In this article, for
the sake of simplicity, from this point on, we refer to the ‘REST APIs for IoT
applications’ as ‘IoT APIs’. Client developers design and develop appli-
cations for IoT devices using vendor-provided IoT APIs that interact/commu-
nicate with peers and gateway servers. The design quality of IoT APIs has
a direct impact on their understandability and reusability. Well-designed and
named APIs may attract client developers more than poorly designed or named
APIs [3] because they must understand the providers’ APIs while integrating
their services.

In previous works, we have performed analyses on the APIs for Web applica-
tions (e.g., Facebook, YouTube, Dropbox, etc.) and Cloud services (e.g., Open
Stack) [4, 5, 6]. Yet, no such study has been performed to investigate how well
the APIs dedicated to the IoT applications are designed in terms of linguistic
quality. To measure the linguistic quality, we perform syntactic and semantic
analysis of the URIs and their documentation. According to Wilhelm et al. [7],
in the context of computer programs, syntactic analysis recognises the syntactic
structure of the programs. In contrast, semantic analysis helps determine prop-
erties and check conditions relevant to the programs’ well-formedness according
to the programming language rules. Thus, in our study, the syntactic analysis
concerns the syntactic structure of the resource URIs and the semantic analysis
checks for the well-formedness of the resource URIs according to the good API
design practices deﬁned in the literature [3, 6, 8, 9, 10, 11, 12, 13]. We perform
a study on APIs solely designed for IoT devices and applications.

The linguistic and semantic relations among the ‘things’, services, and pa-
rameters are as crucial in IoT APIs as in APIs for Web applications [14]. The
lack of such relations and/or poor naming may degrade the overall design of
IoT APIs and translate into linguistic antipatterns. In the context of IoT APIs,
linguistic antipatterns are poor solutions to common URI (Uniform Resource
Identiﬁer) design problems, which may hinder the consumption and reuse of IoT
APIs by client developers; and the maintenance and evolution of IoT APIs by
API vendors. Conversely, linguistic patterns represent good solutions to com-

2

mon URI design problems and facilitate the consumption and maintenance of
IoT APIs. Thus, the linguistic patterns and their corresponding antipatterns
are contrasting pairs.

An example of a poor practice is (cid:54)Inconsistent Documentation 1 where a re-
source URI (together with the HTTP method) is in contradiction with its doc-
umentation. In the IBM Watson IoT, the POST method with /bulk/devices/
remove URI is in contradiction with its documentation2. In REST, the POST
method should be used to create something. The presence of Inconsistent Doc-
umentation may confuse IoT client developers who require clear and uniform
resource speciﬁcations. The understandability and usability of the API might
be hindered if this linguistic antipattern exists. In contrast, (cid:52)Consistent Doc-
umentation 3 is a linguistic pattern where a URI is in line with its documen-
tation. The URI /draft/physicalinterfaces/{physicalInterfaceId} with
the HTTP DELETE method from the IBM Watson IoT API is an example of
this pattern with its documentation4.

In this research, we propose the SARAv2 approach (Semantic Analysis of
REST APIs version two) as an extension to our previous approach, SARA [15].
SARAv2 is can perform semantic analysis of REST APIs in general, and there-
fore also IoT REST APIs, aiming to assess their linguistic quality, by detecting
linguistic patterns and antipatterns. Being inspired from the object-oriented
domain [16, 17], we deﬁne three new linguistic patterns and their correspond-
ing linguistic antipatterns, namely Consistent vs. Inconsistent Documentation,
Versioned vs. Unversioned URIs, and Standard vs. Non-standard URI.

We develop the REST-Ling tool as the implementation of the SARAv2 ap-
proach. REST-Ling is a web application that automates the detection of lin-
guistic patterns and antipatterns. Applying the REST-Ling tool, we perform
the detection of nine linguistic patterns and their corresponding antipatterns in
1,102 URIs from 19 IoT APIs, e.g., Amazon, Cisco, Google, IBM, Microsoft,
Samsung. REST-Ling utilises various NLP techniques including the traditional
WordNet [18] and Stanford’s CoreNLP [19] general-purpose English dictionaries
analysed with Latent Dirichlet Allocation (LDA) [20] topic modeling technique
and beneﬁt from the second-order semantic similarity metrics [21, 22].

In summary, our ﬁve key contributions are:

1. the SARAv2 approach – an extension of SARA [15] – for the syntactic

and semantic analysis of REST APIs for IoT applications;

2. the deﬁnitions of three new linguistic patterns and antipatterns and their

detection algorithms;

1We use the (cid:54) symbol to refer an antipattern
2Delete multiple devices. Delete multiple devices, each request can contain a

maximum of 512 kB

3We use the (cid:52) symbol to refer a pattern
4Delete a draft physical interface. Deletes the draft physical interface with

the specified id from the draft physical interface

3

3. an empirical assessment of the linguistic quality of a set of 19 IoT APIs

from 18 diﬀerent IoT providers;

4. a web-based tool, REST-Ling available on https://rest-ling.com for

the detection of linguistic and structural antipatterns and patterns;

5. the empirical validation of the REST-Ling tool focusing on its accuracy

and eﬃciency;

6. a comparison with relevant studies on the detection of linguistic patterns
and antipatterns from other domains (i.e., APIs for Cloud services and
Web applications).

We also perform a comparison with relevant studies on the detection of
linguistic patterns and antipatterns from other domains (i.e., APIs for Cloud
services and Web applications) from the perspectives of antipatterns and various
accuracy measures. To assess the linguistic quality of IoT APIs and validate the
SARAv2 approach, we deﬁne and answer the following four research questions:

• RQ1 Prevalence: To what extent IoT APIs suﬀer from poor linguistic

design quality, i.e., linguistic antipatterns?

• RQ2 Comparison: To what extent APIs across domains suﬀer from poor

linguistic design quality, i.e., linguistic antipatterns?

• RQ3 Accuracy: What is the accuracy of REST-Ling on the detection of

linguistic antipatterns?

• RQ4 Eﬃciency: How does the REST-Ling perform in terms of average

detection time for linguistic antipatterns?

Our empirical results show that (1) out of the 19 analysed IoT APIs, only
a few of them have syntactic design problems and most of the analysed URIs
follow good linguistic practices, although there also exist certain poor prac-
tices in some speciﬁc APIs. Examples include: (cid:54)Non-pertinent Documentation
was common in all IoT APIs and majority of the APIs had (cid:54)Unversioned URI
antipattern. In contrast, almost all of the APIs followed (cid:52)Tidy URI and (cid:52)Con-
sistent Documentation patterns; and (2) the REST-Ling tool has an average
accuracy over 80% when analysing IoT APIs.

The remaining article is structured as follows: Section 2 describes the linguis-
tic patterns and antipatterns studied. Section 3 presents the SARAv2 approach
we apply for the detection of linguistic patterns and antipatterns. Section 4
shows experimental details and discusses the obtained detection results. Sec-
tion 5 discusses related works and makes a comparison with other state-of-the-
art studies. Finally, in Section 6 we conclude the research and present future
work.

4

2. Linguistic Patterns and Antipatterns

In total, we gathered nine linguistic patterns and antipatterns. The ﬁrst six
patterns and antipatterns are from the literature on REST APIs [3, 5, 14, 15,
23, 24] and the ﬁnal three antipatterns are newly deﬁned in this study.

To deﬁne new linguistic antipatterns, we studied similar linguistic antipat-
terns that exist in the object-oriented literature (e.g., related to class or method
signature and source code comments), and performed a data analysis by also
looking at the URIs and API documentation in our API dataset, to see the ap-
plicability of those linguistic antipatterns, and created ”themes” of patterns and
antipatterns that are applicable to REST URIs and documentation, by using
thematic analysis [25]. We adapted the detection heuristics from the object-
oriented domain to the context of APIs that have resource identiﬁers (i.e., URIs)
and their documentation. We deﬁned (cid:54)Inconsistent Documentation linguistic
antipattern being inspired from [17]. We also studied the gray literature to dis-
cover concerns from the practitioners and formalise those observations in the
form of linguistic antipatterns and their corresponding patterns. For example,
the concept of (cid:54)Unversioned URI antipattern was discussed in [26]. Another
newly deﬁned antipattern (cid:54)Non-standard URI Design is deﬁned based on the
notion similar to (cid:54)Amorphous URI antipattern (which aﬀects the readability of
the URIs) that non-standard characters should not be used in the URI design.
We formulated the detection heuristics of new linguistic antipatterns and
patterns after a thorough discussion with the team consisting of two authors
(who are not part of the manual validation). In the case of disagreement be-
tween the authors, a third opinion was sought from a researcher who also is not
part of the experiment and validation. This enabled us to resolve the conﬂicts
and avoid the bias by a speciﬁc author in deﬁning new linguistic antipatterns
and their detection heuristics. These new patterns and antipatterns are also
applicable to APIs for Web applications or cloud services. The following sub-
sections summarise the linguistic patterns and antipatterns SARAv2 can detect
in REST APIs.

2.1. Tidy vs. Amorphous URIs

The URIs in REST should be tidy and easy to read. A Tidy URI has an
appropriate lower-case resource naming, no extensions, underscores, or trailing
slashes. Amorphous URI occurs when URIs contain symbols or capital letters
that make them diﬃcult to read and use. A URI is amorphous if it contains:
(1) upper-case letter (except for Camel Cases [27]), (2) ﬁle extensions, (3) un-
derscores, and, (4) a ﬁnal trailing-slash [3, 5]. The URI www.exampleAlbum.
com/NEW_Customer/image01.tiff/ is a (cid:54)Amorphous URI since it includes a
ﬁle extension, upper-case resource names, underscores, and a trailing slash. In
contrast, the URI www.example.com/customers/1234 is a (cid:52)Tidy URI since it
only contains lower-case resource naming, without extensions, underscores, or
trailing slashes. The detection of this design practice requires syntactic analysis
of the URIs.

5

2.2. Contextualised vs. Contextless Resource Names

URIs should be contextual, i.e., nodes in URIs should belong to semantically-
related context. Thus, the Contextless Resource Names appears when URIs
are composed of nodes that do not belong to the same semantic context [14].
The URI www.example.com/newspapers/planet/players?id=123 is a (cid:54)Con-
textless Resource Names because ’newspapers’, ’planet’, and ’players’ do not
belong to same semantic context.
In contrast, the URI www.example.com/
soccer/team/players?id=123 is a (cid:52)Contextual Resource Names because ’soc-
cer’, ’team’, and ’players’ belong to same semantic context. The detection of
Contextualised vs. Contextless Resource Names requires semantic analysis of
the URIs.

2.3. Verbless vs. CRUDy URIs

Appropriate HTTP methods, e.g., GET, POST, PUT, or DELETE, should
be used in Verbless URIs instead of using CRUDy terms (e.g., create, read,
update, delete, or their synonyms) [14]. The use of such terms as resource
names or requested actions is highly discouraged [3, 14]. This URI with the
HTTP POST www.example.com/update/players/age?id=123 is a (cid:54)CRUDy
URIs since it contains a CRUDy term ’update’ while updating the user’s pro-
ﬁle color relying on an HTTP POST method. In contrast, this URI with the
HTTP method POST www.example.com/players/age?id=123 is a (cid:52)Verbless
URIs making an HTTP POST request without any verb. The detection of this
design practice requires semantic analysis of the URIs.

2.4. Hierarchical vs. Non-hierarchical Nodes

Nodes in a URI should be hierarchically related to its neighbor nodes. In con-
trast, Non-hierarchical Nodes is an antipattern that appears when at least one
node in a URI is not hierarchically related to its neighbor nodes [14]. The URI
www.examples1.com/professors/faculty/university is a (cid:54)Non-hierarchical
Nodes since ’professors’, ’faculty’, and ’university’ are not in a hierarchical re-
lationship.
In contrast, the URI www.examples2.com/university/faculty/
professors is a (cid:52)Hierarchical Nodes since ’university’, ’faculty’, and ’profes-
sors’ are in a hierarchical relationship. The detection of Hierarchical vs. Non-
hierarchical Nodes requires semantic analysis of the URIs.

2.5. Singularised vs. Pluralised Nodes

URIs should use singular/plural nouns consistently for resources naming
across the API. When clients send PUT or DELETE requests, the last node
of the request URI should be singular.
In contrast, for POST requests, the
last node should be plural. Therefore, the Pluralised Nodes antipattern appears
when plural names are used for PUT/DELETE requests or singular names are
used for POST requests. However, GET requests are not aﬀected by this an-
tipattern [14, 5]. The ﬁrst example URI is a POST method that does not use
a pluralised resource, thus leading to (cid:54)Pluralised Nodes.
In contrast, in the
second example as shown below, for the (cid:52)Singularised Nodes, the DELETE

6

request acts on a single resource for deleting it. An example of (cid:54)Pluralised
Nodes is DELETE www.example.com/team/players or POST www.example.
com/team/player. The (cid:52)Singularised Nodes can be exempliﬁed as DELETE
www.example.com/team/player or POST www.example.com/team/players. The
detection of this design practice requires semantic analysis of the URIs.

2.6. Pertinent vs. Non-pertinent Documentation

The (cid:54)Non-pertinent Documentation occurs when the documentation of a
REST resource URI is in contradiction with its structure (e.g., nodes sepa-
rated by slashes in URIs), inspired from a similar antipattern from the OO
domain [17]. This antipattern applies to both a resource URI and its correspond-
ing documentation. In contrast, a well-documented URI should properly and
clearly describe its purpose using semantically related terms [17, 8]. The URI-
documentation pair from Twitter: api.twitter.com/1.1/favorites/list –
‘Returns the 20 most recent Tweets liked by the authenticating or speciﬁed user’
shows no semantic similarity between them and, thus, considered as a (cid:54)Non-
pertinent Documentation. In contrast, this URI-documentation pair from In-
stagram: instagram.com/media/media-id/comments – ‘Gets a list of recent
comments on a media object. The public content permission scope is required to
get comments for a media that does not belong to the owner of the access token.’
shows a high relatedness and considered as a (cid:52)Pertinent Documentation. The
detection of this design practice requires semantic analysis of the URIs and their
documentations.

2.7. Consistent vs. Inconsistent Documentation

The (cid:54)Inconsistent Documentation found in REST API documentation is
deﬁned based on another antipattern Method Signature and Comment are Op-
posite [17] common in object-oriented systems. It occurs if the documentation
of a method is in contradiction with its declaration. REST API documenta-
tions may also manifest similar practice where a resource URI (together with
the HTTP method) is in contradiction with its documentation. For exam-
ple, in the IBM Watson IoT, the POST method with /bulk/devices/remove
URI is in contradiction with its documentation ’Delete multiple devices. Delete
multiple devices, each request can contain a maximum of 512kB ’, thus, is an
(cid:54)Inconsistent Documentation. By REST design principles, the POST method
should be used to create something. When a resource URI (together with the
HTTP method) is in contradiction with its documentation. For the same exam-
ple URI, /bulk/devices/remove, if the documentation were stated as ’Remove
multiple devices. Remove multiple devices, each request can contain a maximum
of 512kB ’, this could be identiﬁed as (cid:52)Consistent Documentation. The detec-
tion of Consistent vs. Inconsistent Documentation requires semantic analysis of
the URIs and their documentations.

2.8. Versioned vs. Unversioned URIs

APIs evolve continuously and if not properly versioned, might cause clients to
break. Versioned APIs facilitates easy maintenance both for API providers and

7

Figure 1: Overview of the SARAv2 approach.

client developers. Changes in the APIs may include a change in the response
data format or type, removing a resource, adding a new end-point, response
parameters, which require to track major or minor versions for APIs. If an API is
not versioned at all, the Unversioned URI linguistic antipattern occurs [26]. For
example, Losant API does not have any version information in its URI, whereas
IBM Watson IoT always use versioned URI, thus follow the Versioned URI
pattern [26]. The URI api.example.com/1.1/resourceid/view is an example
of (cid:52)Versioned URI with its API version embedded in the URI. In contrast, the
URI api.example.com/resourceid/view is an example of (cid:54)Unversioned URI.
The detection of this design practice requires syntactic analysis of the URIs.

2.9. Standard vs. Non-standard URI

The URI design should not include nodes or resources with non-standard
identiﬁcation, which hinders the reusability and understandability of the APIs.
The (cid:54)Non-standard URI Design occurs when (1) characters like ´e, ˚a, ¨o, etc. are
present in URIs, (2) blank spaces are found in URIs, (3) double hyphens are
used in URIs, and (4) unknown characters (e.g., !, @, #, $, %, ˆ, &, *, etc.)
are present in URIs. Instead, a URI following (cid:52)Standard URI Design (1) does
not include non-standard characters like ´e, ˚a, ¨o, etc. and (2) replaces blank
spaces, unknown characters, and double hyphens with a single hyphen. The
URI api.example.com/museum/louvre/r´eception/ is an example of (cid:54)Non-
standard URI Design. While, the URI api.example.com/museum/louvre/reception/
represents (cid:52)Standard URI Design. The ﬁrst example format hinders the us-
ability and understandability as compared to the latter URI. The detection of
Standard vs. Non-standard URI requires syntactic analysis of the URIs.

3. The SARAv2 Approach

SARAv2 (Semantic Analysis of REST APIs version two) enables the auto-
matic detection of nine linguistic antipatterns and their corresponding patterns
in REST APIs and, therefore, in REST APIs for IoT. To analyse the REST
APIs and their documentation, we manually collect a subset of URIs and their
documentation provided by each REST API provider (i.e., in this paper IoT

8

Detection AlgorithmsImplementationDetected Linguistic (Anti)PatternsIOT APIsApplication ofAlgorithmsAlgorithmic Request URIsRulesStep 2Detection AlgorithmsStep 3Textual Descriptionsof Linguistic (Anti)PatternsAnalysisStep 1Manual stepAutomatic StepSemanticAnalysisproviders). These collected URIs and their documentation are used later in the
detection phase. As shown in Figure 1, the SARAv2 approach consists of three
steps:
Step 1. Analysis of Linguistic Patterns and Antipatterns: A manual step that
consists of analysing the description of linguistic patterns and antipatterns from
the literature to identify the properties relevant to their detection. We use these
relevant properties to deﬁne detection heuristics for patterns and antipatterns.
Step 2. Implementation of Detection Algorithms: A second manual step that
involves the implementation of concrete detection algorithms for patterns and
antipatterns based on the detection heuristics deﬁned in Step 1.
Step 3. Detection of Linguistic Patterns and Antipatterns: An automatic step
that executes the semantic analysis of resource URIs and API documentation
by automatically applying the detection algorithms (implemented in Step 2)
on URIs and APIs documentation for the detection of linguistic patterns and
antipatterns.

In the following sections, we discuss each step in SARAv2 in detail.

3.1. Analysis of Linguistic Patterns and Antipatterns

We analyse the deﬁnitions of antipatterns and patterns deﬁned in Section 2
to identify their various linguistic aspects. For example, a linguistic aspect for
the detection of the (cid:54)Contextless Resource Names is to assess whether a pair of
URI nodes are semantically related, i.e., belong to the same semantic context.
Figure 2 shows the detection heuristic for the (cid:54)Contextless Resource Names. We
extract the domain knowledge from the URI documentation and the request URI
(lines 2-3), to build a topic model. We then calculate and check the similarity
among the nodes (line 4). We check this similarity using the topic model we
generate by applying natural language processing techniques. We calculate the
average similarity value for all the nodes in a URI against each topic from our
topic model. And, we report a URI has the (cid:54)Contextless Resource Names if
the average similarity value is less than the threshold (line 5). On the contrary,
an occurrence of (cid:52)Contextual Resource Names will be reported if the similarity
value is equal to or higher than the threshold. Based on our previous studies [15]
and ﬁndings by Kolb [22], we used 0.3 as the threshold to determine semantic
relatedness between words. We empirically determined the threshold value, i.e.,
we started from 0.1 and increased 0.05 each time the semantic relatedness for a
set of pair of nodes is not reasonable. Moreover, on using DISCO, Kolb [21, 22]
determined the threshold value of 0.3 can be utilised as the gold standard with
good accuracy with regard to semantic relatedness.

Similarly, a linguistic aspect for the detection of the (cid:54)Inconsistent Docu-
mentation is to assess whether the HTTP method used with a resource URI
is described with a conﬂicting documentation. Figure 3 presents the detection
heuristic for the (cid:54)Inconsistent Documentation. We begin with preprocessing
the documentation by removing the stop words (line 2) and tokenise the doc-
umentation, i.e., obtain the set of words in the documentation, and lemmatise
them, i.e., we extract the base form of each word in the documentation (line

9

1: Contextless-Resource(Request-URI, API-Documentation )
TopicsModel ← Extract-Topics(API-Documentation )
2:
URINodes ← Extract-URI-Nodes(Request-URI )
3:
Similarity-Value ←Calculate-Second-Order-Similarity(URINodes, TopicsModel )
4:
if Similarity-Value < threshold
5:
6:
7:
8:

end if
return false ‘‘Contextual Resource Names" pattern

return true ‘‘Contextless Resource Names" antipattern

Figure 2: Detection heuristic for Contextless Resource Names antipattern.

3). Then, we match with the HTTP method to check if the URI and its doc-
umentation are related and consistent (lines 4 to 13). To measure relatedness
between the HTTP method and the documentation, we check whether the syn-
onyms of various actions or verbs are misplaced within the documentation. For
example, the HTTP POST method is often used to create a new resource if the
resource does not exist already. Thus, the documentation related to this action
or the resource on which the POST action is taken, must not have any indi-
cation of resource deletion, retrieval, or update. If such contradiction is found
in the documentation then SARAv2 will report a (cid:54)Inconsistent Documentation
(lines 4-5). In contrast, an occurrence of (cid:52)Consistent Documentation will be
reported if no contradiction is discovered between the HTTP method/action
and the documentation. The detection heuristics of other linguistic patterns
and antipatterns are available online5.

else if HTTP-Method = ‘DELETE’ && Synonyms(Create or Update or Get) ∈ Tokens

return true ‘‘Inconsistent Documentation" antipattern

Documentation ← Remove-Stop-Words(Documentation )
Tokens ← Lemmatise-Tokenise(Documentation )
if HTTP-Method = ‘POST’ && Synonyms(Delete or Update or Get) ∈ Tokens

1: Inconsistent-Documentation(HTTP-Method, Request-URI, Documentation )
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:

end if
return false ‘‘Consistent Documentation" pattern

return true ‘‘Inconsistent Documentation" antipattern

return true ‘‘Inconsistent Documentation" antipattern

return true ‘‘Inconsistent Documentation" antipattern

else if HTTP-Method = ‘PUT’ && Synonyms(Create or Delete or Get) ∈ Tokens

else if HTTP-Method = ‘GET’ && Synonyms(Delete or Update or Create) ∈ Tokens

Figure 3: Detection heuristic for Inconsistent Documentation antipattern.

3.2. Implementation of Detection Algorithms

To detect the linguistic pattern and antipattern, we implemented the de-
tection algorithms using Java since our detection framework, SOFA (Service
Oriented Framework for Antipatterns) [15], is Java-based. The SARAv2 ap-
proach does not require the parameterised URIs to perform the analysis, i.e.,

5http://sofa.uqam.ca/santa/

10

Listing 1: Code snippet for the detection Contextless Resource Names linguistic antipattern.

e l s e

c o n t e x t l e s s R e s u l t P . add ( URI ) ;

c o n t e x t l e s s R e s u l t A P . add ( URI ) ;

s t a t i c v o i d main ( S t r i n g [ ] a r g s ) {

s t a t i c v o i d d e t e c t C o n t e x t l e s s R e s o u r c e ( ) {
r e s u l t = r e s t A n a l y s e r . U R I C o n t e x t u a l A n a l y s i s ( URI ) ;
i f ( ! r e s u l t )

. . .
/∗ D e t e c t i o n o f C o n t e x t l e s s Resource Names A n t i p a t t e r n ∗/
d e t e c t C o n t e x t l e s s R e s o u r c e N a m e s ( ) ;
w r i t e O u t p u t ( ) ;

1 p u b l i c
2
3
4
5
6 }
7 p r i v a t e
8
9
10
11
12
13 }
14 p u b l i c b o o l e a n U R I C o n t e x t u a l A n a l y s i s ( S t r i n g U r i ) {
15
16
17
18
19
20
21
22
23
24
25
26
27 }

. . .
T o p i c s = t h i s . l d a P r o c e s s o r . g e t T o p i c L i s t ( ) ;
. . .
A r r a y L i s t <S t r i n g > UriNodes = g e t U r i N o d e s ( U r i ) ;
. . .
f o r e a c h Node i n UriNodes and f o r e a c h t o p i c i n T o p i c s ;

C a l c A v g S i m o f N o d e s i n U R I ( ) ;
i f a v e r a g e s i m i l a r i t y < t h r e s h o l d

C a l c S e c o n d O r d e r S i m V a l u e s ( ) ;

r e t u r n f a l s e ;

r e t u r n t r u e ;

e l s e

performs the analysis on the URIs from the IoT APIs documentation. We man-
ually convert (write the Java code) the detection heuristics deﬁned in Section 3.1
into executable Java programs. Listing 1 shows an example of a code snippet in
the form of pseudocode that we apply for the detection of (cid:54)Contextless Resource
Names.

As shown in Listing 1, once the detectContextlessResource() method is
invoked (line 4) the URIContextualAnalysis() procedure is initiated (line 9),
which is the implementation of the heuristics for Contextless Resource Names
antipattern in Figure 2. Inside the URIContextualAnalysis() procedure, ﬁrst,
the topic model is built (line 18), followed by the extraction of the nodes in the
URI (line 20). We use a matrix for storing the similarity values between each
node and the members in the topic model (line 22). Finally, the calculation of
second-order similarity values takes place (lines 24 and 25), and the detection
of either an antipattern or a pattern is decided based on the average similarity
value for each node. If the average similarity value for all the nodes in a URI
is below a predeﬁned threshold (lines 27 to 30), we consider it as a contextless
URI design, thus, an antipattern, and if above, it is considered as a contextual
URI design, i.e., a pattern.

3.3. Detection of Linguistic Patterns and Antipatterns

In SARAv2, the detection of linguistic patterns and antipatterns utilises two
essential elements: the Second Order Semantic Similarity metric and Latent
Dirichlet Allocation (LDA).

11

Figure 4: The semantic analysis strategy of the SARAv2 approach.

The Second Order Semantic Similarity metric [21, 22] allows obtaining the
distributionally most similar words for a given word, and computes similarity
scores among them based on second-order word vectors. Two words are consid-
ered distributionally similar if they have multiple co-occurring words in the same
syntactic relations [28]. The distributional semantic similarity goes beyond is-a
relationships between nouns and verbs as allowed by approaches [28, 22] based
on WordNet [18] that only beneﬁts from the synonym (warm-hot), meronym
(car-wheel), and antonym (hot-cold) relations. Distributional semantic simi-
larity captures the multiple senses of a given word and allows mixing all the
distributionally similar semantic words for all these senses.

LDA is a generative probabilistic model of a corpus based on topic models. It
relies on the idea that a document is a mixture of latent topics, and each topic is
a probabilistic distribution over words [20] and supports the extraction of topic
models from a corpus. The topic model is a low-dimensional representation
of the content of the documents in the corpus. LDA allows a document to
pertain to many diﬀerent topics by associating the probability of the document
belonging to each topic, overcoming one of the main problems of many other
clustering models that restrict documents to be associated with just one topic.
LDA is also aﬀected by the bag-of-words assumptions, meaning that words that
appear or should be generated by a topic might also be allocated in other topics
[20]. To tackle these problems, we deﬁned a hybrid approach for SARA [15],
combining LDA topic modeling to obtain the low-dimensional representation of
the corpus and the distributional semantic similarity to measure the semantic
similarity between the words.

3.3.1. Semantic Analysis of IoT APIs

SARAv2 strategy for performing the semantic analysis of IoT APIs involves
four automatic steps, as illustrated in Figure 4: (1) collecting IoT APIs docu-
mentation and their preprocessing (i.e., exclusion of stop words); (2) truncating
example URI nodes to their base form (i.e., lemmatisation) using Stanford’s
CoreNLP [19]; (3) extracting the LDA topic model using the collected corpora;
and (4) measuring the second-order similarity between the extracted LDA topic
model and the URI nodes. The LDA topic model is created by using the Mal-

12

Step 2Step 1Step 3Number of TopicsStep 4RemovalTopic ModellingMalletTopic ModelFullEnglish WikipediaRelatednessCalculationAutomatic StepIoT API’s Documentationlet LDA topic modeling tool-set6 using the IoT APIs documentation, excluding
lists of parameters, and response formats. This LDA model represents a minimal
representation of the members of the corpus, preserving the essential semantic
relationships needed for classiﬁcation [20].

In the following, we brieﬂy describe how we determine the detection of a
linguistic antipattern Contextless Resource Names (and the corresponding Con-
textual Resource Names pattern) using the LDA topic modeling [20] and second-
order semantic similarity [21, 22].

Topic 1

Topic 2

Topic 3

eco
record
estimate
lock
adjust
format
related
json
call
sign
home
sound
bandwidth
low
image

smoke
sound
snapshot
status
change
list
display
nest
expire
home
detect
subscription
ﬁeld
live
motion

device
structure
thermostat
event
nest
camera
url
display
temperature
alarm
require
hvac
aware
zone
activity

Table 1: Top 15 words for Google Nest topic model with k=3.

3.3.2. Determining Patterns and Antipatterns

To discover the relationships (e.g., contextual) between the pair of nodes
(i.e., resource identiﬁers) in the URIs, as mentioned above, we use the tool-set
based on Mallet LDA topic modeling. Given a collection of text (or documents),
LDA generates a topic model that speciﬁes the important relationships crucial
In other words, the generated
for classiﬁcation or summarisation tasks [20].
topic model represents the collection of documents in some low-dimensional
word vectors. The topic model for each IoT API was built after gathering the
descriptions of the resource URIs as input by excluding the list of parameters,
request or response formats, and example code.

We start processing the collection of text by removing the stop words and
expanding the acronyms to get the full form. For this, we collect a list of API-
speciﬁc acronyms. The collection of acronyms is performed after we gather 1,102
URIs and their documentation for 19 IoT APIs. We go through each URI and
its documentation, look for acronyms and create an API-speciﬁc dictionary that
includes the acronyms and their full forms. Later, during the processing of the
URIs and their documentation, we replace the acronyms with their full forms to
build a more accurate topic model. The lemmatisation process is also applied to
set the words to their base form, for which we rely on Stanford CoreNLP [19].

6http://mallet.cs.umass.edu

13

Table 2: An example analysis of two Google Nest URIs.

0.2627

0.4077

0.0130
0.0000
0.0192
0.3378
0.2575
0.0922
0.0129
0.0182
0.0081
0.0000
0.0000
0.0919
0.2130
0.0958
0.0788

locale
0.0275
0.0000
0.0241
0.0055
0.0170
0.0451
0.0000
0.0253
0.0058
0.0057
0.0703
0.1588
0.0317
0.0113
0.1595

state
0.0064
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0058
0.0062
0.0000
0.0000
0.0000
0.0000

structure alarm
0.0146
0.0207
0.0129
0.0000
0.0239
0.0928
0.1955
0.1275
0.1936
0.0721
0.0990
0.1478
0.0232
0.0327
0.0313
0.0702
0.0915
0.0648
0.0060
0.0000
0.0000
0.0817
0.1853
0.2277
0.0944 0.2545
0.0521
0.0636
0.5273 0.1274

Topic
/devices/thermostats/device id/locale /structures/structure id/co alarm state
device thermostat
words
0.0528
eco
0.0068
record
0.0611
estimate
0.2254
lock
0.2026
adjust
0.5311
format
0.0349
related
0.1962
json
0.0656
call
0.0000
sign
0.0000
home
sound
0.1645
bandwidth 0.7259
0.0517
low
image
0.3504
Average
0.0054
smoke
0.1645
sound
0.3066
snapshot
0.0588
status
0.0976
change
0.0348
list
0.7431
display
0.0054
nest
0.0442
expire
0.0000
home
detect
0.3562
subscription 0.2463
0.1114
ﬁeld
0.0000
live
motion
0.3378
Average
2.0000
device
0.2111
structure
0.4916
thermostat
0.0175
event
0.0054
nest
1.0680
camera
0.2685
url
display
0.7431
temperature 0.0987
0.4377
require
0.3914
alarm
0.3133
hvac
0.0060
aware
0.0729
zone
activity
0.1565
Average

0.2111
0.4377
2.0000 0.0210
0.3944
0.0569
0.0152
0.0507
0.0000
0.0118
0.4096
0.1089
0.0766
0.0577
0.1894
0.2419
0.0681
0.1731
0.0210
0.1611
0.1543 2.0000
0.2735
0.0351
0.1789
0.0116
0.0195
0.2317
0.0912
0.3848

0.0609
0.0059
0.2277
0.1853
0.0863
0.0732
0.0188
0.2592
0.0852
0.3649
0.0054
0.1001
0.1894
0.2419
0.0000
0.0118
0.0072
0.0055
0.0817
0.0000
0.1933 0.3026
0.0687
0.0180
0.0117
0.1900
0.0260
0.0062
0.4712 0.2228

0.0058
0.1588
0.0395
0.1419
0.0805
0.0741
0.0842
0.0495
0.0060
0.0703
0.0000
0.0059
0.1001
0.0836
0.0657

0.1065
0.0919
0.0178
0.0135
0.0603
0.0069
0.1763
0.0000
0.0000
0.0000
0.1291
0.0113
0.0193
0.0000
0.1946

0.0242
0.1645
0.0057
0.1557
0.0495
0.0177
0.0177
0.0842
0.0645
0.0000
0.0167
0.0000
0.0000
0.4626
0.2037

0.0000
0.0000
0.0000
0.0000
0.0061
0.0000
0.0000
0.0000
0.0000
0.0000
0.0140
0.0000
0.0000
0.0727
0.0053

0.0000
0.0000
0.0000
0.0291
0.0000
0.1672
0.0000
0.0061
0.0364
0.0062
0.0000
0.0000
0.0136
0.0069
0.0000

0.4916
0.0569
2.0000
0.0118
0.0000
0.3072
0.0117
0.1763
0.2084
0.3944
0.1334
0.8992
0.0000
0.0402
0.0371

1.4875

0.3655

0.3137

1.3576

Topic 1

Topic 2

Topic 3

Then, we obtain the topic model with k topics using the Mallet tool-set for
which the set of unique end-points for an IoT API is considered as topics. This
is done because end-points are the key concepts for an API as they appear ﬁrst
in the URI design hierarchy [14].

Table 1 shows the topic model obtained using Mallet from the documentation
corpus of Google Nest IoT API. As shown, the topic model has three topics,
and for each topic, the 15 most relevant words are listed. Later, we use this
topic model to quantify the similarity between a pair of nodes in a URI. For
example, two nodes (or resource identiﬁers) are related or similar if they belong
to the same topic following the method proposed by Griﬃth and Steyvers [29].
After building the LDA topic model, we rely on the second-order semantic
similarity metric to compute the (semantic or contextual) similarity between

14

identiﬁers. The distributional second-order similarity metric is useful for us
because the nodes (i.e., resource identiﬁers) might slightly diﬀer from their
actual API documentation syntactically and semantically. Two nodes (or words)
can be seen as distributionally similar when they have co-occurring words in
common, i.e., common words as neighbors. We rely on DISCO [21] library to
compute the distributional similarity between nodes in a URI.

Table 2 shows similarity values for two URIs from Google Nest API: (1)
developer-api.nest.com/devices/thermostats/device_id/locale and (2)
developer-api.nest.com/structures/structure_id/co_alarm_state.

These values are computed based on the topic models and the distribu-
tional second-order similarity metric. In other words, if we want to compare
the context of a pair of nodes in a URI, we compute the second-order semantic
similarity between them with the top 15 words in each topic from the obtained
topic model. Then, we decide the topic to which a node belongs to based on
the similarity value, i.e., a node ﬁts a topic if the average second-order semantic
similarity value is greater than the threshold 0.3. Also, for a pair of nodes, if
the intersection of topics to which the nodes belong is null (i.e., no common
topic), then, the URI is regarded as an instance of Contextless Resource Names
linguistic antipattern. In contrast, if each pair of nodes in a URI belongs to
one or more common topic(s), we report the URI as an instance of Contextual
Resource Names linguistic pattern.

For the ﬁrst URI, the base form of each node (i.e., device, thermostat, and
locale) appears in Topic 3, except the node locale. Moreover, the average simi-
larity value for all the nodes against Topic 1 is 0.4077, against Topic 2 is 0.3655,
and against Topic 3 is 1.4875, which means the ﬁrst URI is more similar to
Topic 3 with a higher similarity value of 1.4875. The average similarity in Table
2 was computed by taking the maximum similarity value for each node in the
URI against all the words in a topic, and then average them. For example, the
maximum similarity values for the nodes in the ﬁrst URI are 0.7259, 0.3378, and
0.1595 for Topic 1, averaging 0.4077, which is greater than the threshold of 0.3.
The average similarity values for Topic 2 and Topic 3 are 0.3655 and 1.4875,
respectively. Ergo, we identify the ﬁrst URI as Contextual Resource Names
linguistic pattern. For the second Google Nest URI, all the nodes structure,
alarm, and state appear in Topic 3 in their base form except the node state.
Similar to the ﬁrst URI, the second URI also more ﬁt Topic 3 with an average
similarity value of 1.3576 (see Table 2). We identify the second URI as Contex-
tual Resource Names linguistic pattern because all the nodes are semantically
related.

3.3.3. Applying Detection Algorithms

In this work, we use SARAv2, which extends the SARA approach for the
semantic analyses of REST URIs and APIs documentations used in [5, 15]
by adding three new patterns and antipatterns. The extension includes the
implementation of the new detection algorithms for the three newly deﬁned
patterns and antipatterns.

15

Figure 5: Detection of patterns and antipatterns in an API.

Both SARA and SARAv2 use and extend the SOFA framework proposed and
developed by Moha et al. [30] to automatically execute the detection heuristics
in the form of detection algorithms on the URIs. SARA and SARAv2 extend
SOFA by enabling the use of LDA models and Second Order Semantic Simi-
larity as heuristics in the detection algorithms that analyze the URIs and their
documentation. For example, the detection code, as shown in Listing 1, is im-
plemented and executed inside the SOFA framework. The detection results are
then exported to a text ﬁle.

3.4. Operationalising REST-Ling Tool

REST-Ling is a web application that automates the detection of linguistic
patterns and antipatterns. REST-Ling aims to help software engineers analyse
their APIs and detect linguistic patterns and antipatterns. The tool can present
various visual representations for patterns and antipatterns detected in a par-
ticular API. Moreover, it shows generic information on the types of linguistic

16

patterns and antipatterns detected, and pinpoints the rationale behind their
detection. Our REST-Ling tool supports:

• The addition of APIs and URIs: REST-Ling allows the user to add one
or more URIs manually or by uploading a JSON ﬁle. The JSON ﬁle can
contain multiple APIs with multiple URIs each;

• The selection of patterns and antipatterns: REST-Ling allows the user to
select the patterns and antipatterns (both design and linguistic) to be
detected. The analysis process is done asynchronously for all the patterns
and antipatterns;

• A detailed view of the detection results: The tool provides answers to what,
why, and where the design and linguistic antipatterns occur. This allows
the user to have a better insight into the API quality by checking what
type of antipatterns an API has;

• A graphical representation of the detection results: The tool provides a
graphical representation of the detection results of the patterns and an-
tipatterns using pie and bar charts;

• A topic model creation feature for the linguistic analysis: When it comes to
detecting, for example, Contextless Resource Names linguistic antipattern,
the tool provides functionalities to import and add acronyms and stop
words to create the topic model required for the detection.

Example Use: To use the REST-Ling, engineers require a JSON ﬁle that
contains a list of URIs from an API. Each URI should have a name, method,
and description. Users can upload the JSON ﬁle on the Collections page to
add the APIs to be analysed. Once the ﬁle is uploaded, the user can go into
each Collection and start the analysis by clicking on the Analyse button and
checking the detected patterns and antipatterns in the collection view, as shown
in Figure 5. The REST-Ling tool can be accessed on https://rest-ling.com.
To use the tool, provide admin both as the username and password. A demo of
the tool is provided on YouTube7. The tool is built to be freely used by anyone
who aims to improve their APIs’ design quality. The REST-Ling tool might
be of interest to academics aiming to perform further research on API quality.
Practitioners can also use the tool to assess the quality of their APIs.

4. Experiments and Results

This section reports on two empirical studies using the SARAv2 approach.
The ﬁrst study in Section 4.2 aims at performing the qualitative analysis of
IoT APIs utilising the REST-Ling tool. In the second study, in Section 4.3, we

7https://www.youtube.com/watch?v=pSdll8hOFjY

17

assess the eﬀectiveness of the REST-Ling tool by validating the accuracy of the
detection heuristics and the eﬃciency of the detection algorithms that are part
of the underlying SOFA framework [30]. In the following sections, we provide
the details of the study results.

4.1. Subjects and Objects

In these two empirical studies, we consider nine linguistic antipatterns and
their corresponding patterns as discussed in Section 2. As our objects, we
collected a list of more than 700 Web APIs from programmableweb.com of 73
types including ‘Big Data’, ‘Cloud’, ‘Database-as-a-Service’, ‘Infrastructure-as-
a-Service’, ‘Internet of Things’, and ‘Platform-as-a-Service’. From that list, we
ﬁltered only APIs related to the ‘Internet of Things’ and ﬁnally chose 19 IoT
APIs that have well-organised API documentation. We manually extracted the
URIs, their documentation, and underlying HTTP methods. We collected and
analysed a set of 1,102 URIs from the 19 IoT APIs. Table 3 lists the 19 IoT
APIs and their online documentation that we analysed. We then apply detection
heuristics of nine patterns and antipatterns as deﬁned in Section 2 on the URIs
to perform syntactic and semantic analyses. For all detection, we rely on the
SOFA framework [30].

We inspected the documentation for the APIs to assess the support for
MQTT. We found that 11 of them do not support MQTT in any way. We
also found that in ﬁve of those that explicitly mention MQTT, only a subset of
the full API functionality is supported, or the documentation is lacking. This
leaves three APIs that claim full support for the MQTT protocol. This supports
our claim that REST is the dominating style for developing cloud-based IoT
applications.

4.2. Qualitative Analysis of IoT APIs

This section provides an overview of the detection results.

It should be
noted that the detection is performed on the IoT APIs that had well-organised
and self-contained documentation. Figure 6 shows the detection summary of
nine linguistic patterns and antipatterns on 19 IoT APIs. In Figure 6, columns
represent patterns and antipatterns, rows represent IoT APIs with the heights
of the mosaics correspond to the count of URIs analysed for each API and
the colors of the mosaic correspond to white as pattern detection and black as
antipattern detection.

In Figure 6, the most frequent linguistic patterns are: (a) Tidy URI, (b)
Verbless URI, (c) Hierarchical Resource Names, and (d) Standard URI. More
precisely, (a) almost all of the APIs (i.e., 16 out of 19 analysed IoT APIs) had
well-designed URIs in terms of lexical quality; (b) the majority of the analysed
IoT APIs (i.e., 12 out of 19 analysed IoT APIs) did not include any CRUDy
(Create, Read, Update, Delete, and any of their synonyms) terms or the nodes
in their URIs; (c) URI nodes are well-structured in a hierarchical fashion; and
(d) APIs do not tend to include special and non-English characters in their URI
design. In contrast, the most frequent antipatterns are: (i) Pluralised Nodes, (ii)

18

Table 3: List of 19 analysed IoT APIs and their online documentations.

IoT APIs and Online Documentation #URIs Tested

Amazon AWS IoT Core
Ambrosus Gateway
Arduino IoT Cloud API
Caret
Cisco Flare
Cisco IPICS
ClearBlade
CubeSensors
Droplit.io
Google Nest
IBM Watson IoT
Losant
Microsoft Azure
Node-RED
Samsung ARTIK
Sonos
The Things Network
thethings.iO
Toon

Total

150
14
20
7
34
5
84
4
52
47
139
63
210
17
137
49
11
33
26

1,102

Non-pertinent Documentation, and (iii) Unversioned URI. In particular, (i) for
the PUT/DELETE requests, the last node of the URI should be singular, and for
the POST requests, the last node should be plural, however, this was not always
the case for IoT APIs; (ii) the documentation was not properly aligned with the
URIs; and (iii) most of the IoT API providers did not use version information
within URIs, which may hinder APIs maintainability. These conclusions are
based on the detection results obtained using the REST-Ling tool.

Below, we brieﬂy discuss the detection of some of the most and least common

linguistic antipatterns.

CRUDy URI: The URI /v0/api/auth/shortcode/create from Droplit.io
was detected as (cid:54)CRUDy URI. The POST method was used to do that. Even
without adding the ‘create’ node at the end of the URI, using the POST method,
it was already understood that the goal was to create a shortcode that will
be used for authentication, as stated in its documentation. The URL /bulk/
devices/remove in IBM Watson IoT had a similar issue where it used the POST
method to delete multiple devices. However, these poor practices of introducing
CRUDy terms (or their synonyms) are highly discouraged in REST since there
are a number of action-oriented HTTP methods available. The URI designers
will simply combine an appropriate HTTP method from those with their URIs
and perform diverse resource- or things-oriented tasks. The Samsung ARTIK
also had similar issue, e.g., a URI /trials/sessions/search is found with the
‘search’ node at the end.

19

Figure 6: Nine linguistic patterns and antipatterns detected in 19 IoT APIs using the REST-
Ling tool. Columns represent patterns and antipatterns, rows represent IoT APIs with the
heights of the mosaics correspond to the count of URIs analysed for each API.

Inconsistent Documentation: The (cid:54)Inconsistent Documentation refers to
the case where the HTTP method applies with a URI that has an opposite doc-
umentation, i.e., the HTTP method does not do what it says. This is similar to
Method Signature and Comment are Opposite linguistic antipattern in object-
oriented programming [17, 16]. For example, from the Droplit.io API, there is
a URI /v0/api/clients/ that was applied with a GET method, but has the
documentation as ‘Create a client. An account token or server token may...’.
Clearly, using a GET method to create a client is poor (or even wrong) practice
in REST. Similar instances were found in IBM Watson IoT, e.g., it uses the
POST method with the URI /bulk/devices/remove and has the documenta-
tion as ‘delete multiple devices, each request can contain a...’.

Contextless Resources Names: One URI /devices/thermostats/device_
id/time_to_target_training by Google Nest was detected as (cid:54)Contextless

20

Amorphous URIContextless Resource NamesCRUDy URINon−Hierarchical NodesPluralised NodesNon−pertinent DocumentationInconsistent DocumentationUnversioned URINon−standard URIAmazon.AWS.Core.IoTAmbrosus.GatewayArduino.IoTCaretCisco.FlareCisco.IPICSClearBladeCubeSensorsDroplit.ioGoogle.NestIBM.Bluemix.IoTLosantMicrosoft.Azure.IoT.HubNode.REDSamsung.ARTIK.CloudSonosThe.Things.Networkthethings.iOToonPatternAntipatternLinguistic AntipatternsIoT APIsTable 4: Detection results of the nine linguistic patterns and antipatterns in 19 IoT APIs.

I

R
U
d
r
a
d
n
a
t
s
-
n
o
N
(cid:54)

I

R
U
d
r
a
d
n
a
t
S
(cid:52)

0 150

0 14

0 20

0

7

0 34

0

5

g
n
i
n
o
i
s
r
e
V

I

R
U
(cid:52)

2

0

0

7

0

0

4

3

1

52 0 52

0

0

0

0 47

0 139

0 63

s
e
m
a
N
e
c
r
u
o
s
e
R
d
e
s
i
l
a
u
t
x
e
t
n
o
C
(cid:52)

s
e
m
a
N
e
c
r
u
o
s
e
R
s
s
e
l
t
x
e
t
n
o
C
(cid:54)

I

R
U
s
u
o
h
p
r
o
m
A
(cid:54)

I

R
U
y
d
i
T
(cid:52)

s
e
d
o
N

l
a
c
i
h
c
r
a
r
e
i
H
-
n
o
N
(cid:54)

s
e
d
o
N

l
a
c
i
h
c
r
a
r
e
i
H
(cid:52)

s
e
d
o
N
d
e
s
i
r
a
l
u
g
n
i
S
(cid:52)

s
e
d
o
N
d
e
s
i
l
a
r
u
l
P
(cid:54)

I

R
U
y
D
U
R
C
(cid:54)

I

R
U
s
s
e
l
b
r
e
V
(cid:52)

n
o
i
t
a
t
n
e
m
u
c
o
D
t
n
e
n
i
t
r
e
p
-
n
o
N
(cid:54)

n
o
i
t
a
t
n
e
m
u
c
o
D
t
n
e
t
s
i
s
n
o
c
n
I
(cid:54)

n
o
i
t
a
t
n
e
m
u
c
o
D
t
n
e
n
i
t
r
e
P
(cid:52)

n
o
i
t
a
t
n
e
m
u
c
o
D
t
n
e
t
s
i
s
n
o
C
(cid:52)

I

R
U
d
e
n
o
i
s
r
e
v
n
U
(cid:54)

IoT APIs

Amazon AWS Core IoT 0 150 0 150 9 141 0 150 39 111 113 37 8 142 148

Ambrosus Gateway

Arduino IoT

Caret

Cisco Flare

Cisco IPICS

ClearBlade

CubeSensors

Droplit.io

Google Nest

0 14

0 20

1

6

0 34

0

5

0 84

1

3

7 45

0 47

0

0

2

0

0

0

0

1

4

14 0 14 0 14

20 0 20 0 20

5

0

7

0

7

34 0 34 0 34

5

0

5

0

5

4

5

2

4

3

10

15

5

1

9

7

13 0

11 7

0

2

14

13

5

14

20

0

30

20 14 0

34

34

2

2

3

0

5

5

84 0 84 0 84 23 61

66 18 3

81

48

36 0 84

4

0

4

0

4

0

4

0

4

0

51 1 51 0 52 12 40

21 31 1

43 0 47 0 47

2

45

29 18 0

4

51

47

0

0

47

IBM Bluemix IoT

0 139 4 135 3 136 0 139 27 112 82 57 1 138 139

Losant

0 63

7

56 2 61 0 63 23 40

15 48 2

61

63

Microsoft Azure IoT Hub 0 210 74 136 3 207 0 210 42 168 210 0 59 151

2

208 0 210

Node-RED

0 17

0

17 0 17 0 17

5

12

0

17 0

17

17

Samsung ARTIK Cloud

0 137 4 133 1 136 0 137 29 108 71 66 2 135 137

Sonos

The Things Network

thethings.iO

Toon

0 49

0 11

0 33

0 26

2

0

1

0

47 2 47 0 49 35 14

27 22 0

11 0 11 0 11

32 0 33 0 33

26 0 26 0 26

4

9

1

7

24

25

5

6

0

22 11 0

12 14 0

49

11

33

26

47

11

0

0

0

0

2

0

0 17

0 137

0 49

0 11

33 1 32

26 0 26

Resources Names. We suspect that the URI was detected as an antipattern
because the nodes {devices, thermostats, time, target, training} seem
not to be related from the semantic point of view. When we built the topic model
for Google Nest, we found that ‘device’ and ‘thermostat’ were present in our
topic model (under the ﬁrst topic cluster) and the other three node words ‘time’,
‘target’, and ‘training’ were not in the topic model at all, i.e., they were not so
important in the context of Google Nest, thus, they were considered irrelevant
to the context. In our topic model, similar words or keywords that are highly
related are grouped under the same topic cluster. Therefore, the REST-Ling
tool identiﬁed the URI as Contextless Resources Names antipattern.

Non-pertinent Documentation: Among the 19 analysed IoT APIs, all the
APIs except two (i.e., CubeSensors and Node-RED) have instances of this an-
tipattern. Thus, Non-pertinent Documentation is found to be the most common

21

antipattern. Also, 65% of the analysed URIs (i.e., 712 out of 1,102) are involved
in this antipattern. These ﬁndings suggest that majority of the APIs (i.e., 17
out of 19 analysed IoT APIs) do not provide documentation cohesive to their
URI design. Also, large vendors like Amazon AWS Core IoT, IBM Watson IoT,
and Google Nest do not tend to provide high-quality documentation for their
APIs. For example, 75% of the analysed URIs from Amazon AWS Core IoT,
59% of the analysed URIs from IBM Watson IoT, and 62% of the analysed
URIs from Google Nest had Non-pertinent Documentation antipattern. How-
ever, Microsoft Azure had 100% of the analysed URIs provided good quality
documentation, i.e., the URIs and their documentation are cohesive.

Unversioned URI: We also found a similar prevalence for Unversioned URI
antipattern, i.e., 14 out of 19 analysed IoT APIs do not include version informa-
tion as part of their URIs design. In the literature, as part of the best practices,
practitioners suggested including version information within the URIs [26]. This
is because APIs evolve continuously, and, if not properly versioned, clients might
break. In other words, versioned APIs facilitate easy maintenance both for API
providers and client developers. However, it could be due to that APIs for IoT
applications do not evolve frequently. Notably, some APIs are found to be in
two diﬀerent modes, i.e., some URIs are versioned whereas others are not. This
observation ought not to be generalised without further investigation. For ex-
ample, Amazon AWS Core IoT is found to have both unversioned and versioned
URIs (148 vs. 2) out of 150 analysed URIs. Same for Microsoft Azure, where we
found 2 out of 210 analysed URIs had version info included in the URI design.
Thus, there is a clear lack of standardised practice among the API providers.

Non-Standard URI: According to the deﬁnition of Non-standard URI an-
tipattern in Section 2.9, URI design should not include nodes or resources
with non-standard identiﬁcation (e.g., special or unknown characters, blank
spaces, double hyphens, etc.), which hinders the reusability and understand-
ability of the APIs. Our ﬁndings suggest that the majority of the IoT APIs,
i.e., 17 out of 19 analysed APIs, follow the standard URI design practices.
From the CubeSensors API, three URIs are found: /devices/[deviceid],
/devices/[deviceid]/current, and /devices/[deviceid]/span that a had
blank space as part of the URI design. Also, the thethings.iO API had this URI
/things/THING_TOKEN/resources/$MAGIC_RESOURCE with a dollar sign ($) be-
fore the parameter, which is considered as an unknown character in the URI
design. These practices of URI design make the URI non-standard and hinder
the reusability and understandability of the APIs.

4.3. Eﬀectiveness of the REST-Ling

This section answers our research questions in showing the eﬀectiveness of

the REST-Ling tool.

22

4.3.1. Research Questions

We deﬁne four research questions related to the prevalence, accuracy, and to
assess the usefulness and eﬀectiveness of the REST-Ling tool that is developed
based on the SARAv2 approach.

• RQ1 Prevalence: To what extent IoT APIs suﬀer from poor linguistic de-
sign quality, i.e., linguistic antipatterns? With RQ1, we want to investi-
gate whether IoT APIs suﬀer from linguistic design quality (i.e., linguistic
antipatterns), and to what extent.

• RQ2 Comparison: To what extent APIs across domains suﬀer from poor
linguistic design quality, i.e., linguistic antipatterns? With RQ2, we want
to investigate whether and to what extent APIs for Web applications and
cloud services are prone to linguistic antipatterns than the APIs for IoT
applications.

• RQ3 Accuracy: What is the accuracy of REST-Ling on the detection of
linguistic antipatterns? With RQ3, we want to investigate the accuracy
of our deﬁned detection heuristics implemented in the REST-Ling tool.

• RQ4 Eﬃciency: How does the REST-Ling perform in terms of average
detection time for linguistic antipatterns? With RQ4, we want to study
the detection performance of the REST-Ling tool in executing the detection
heuristics implemented as part of the tool. We conjecture that an average
detection time in the order of seconds is acceptable for each antipattern.

4.3.2. Validation Process

We applied random sampling to choose 91 URIs out of 1,102 URIs from
19 APIs to measure the overall accuracy of the REST-Ling tool. The total
population size is 9,918 (i.e., 1,102 URIs × 9 patterns). We aim for a 95%
conﬁdence level and a conﬁdence interval of 10; thus, a sample size of 819
questions (i.e., 91 URIs × 9 antipatterns) were selected to be validated manually.
We involved three professionals to manually validate our detection ﬁndings. The
professionals have knowledge on REST and were not part of the implementation
and execution of the detection algorithms. Two of the professionals co-author
this paper and have both industrial and academic experience, and the third is an
industry expert with working knowledge on Web APIs. To avoid any potential
conﬂicts of interest and to be fully transparent, during the experiments and
analyses, the obtained detection results were not shared and discussed with any
In this way,
of the authors who later participated in the validation process.
we ensured that the accuracy of the detection results was not aﬀected, i.e., the
accuracy measurements were unbiased.

To facilitate the validation process, the textual descriptions of linguistics
patterns and antipatterns, the URIs along with the HTTP method, and their
documentations were provided. To set the oracle, we decided on the majority.
That is, each detection instance is manually validated by three participants and
the oracle is decided when at least two participants accept or reject an instance.

23

The validation process with questions and responses is done online and available
using Google Forms8. As shown in Equation 1, the accuracy measure was used
to measure the performance of the REST-Ling tool. We also use the Matthews’
correlation coeﬃcient (MCC), as shown in Equation 2, as an alternative measure
unaﬀected by the unbalanced datasets issue. The MCC is computed based on
the contingency matrix. MCC generates a higher score if our REST-Ling tool
as a binary classiﬁer can correctly classify the majority of antipattern instances
and the majority of the pattern instances. MCC has the values –1 and +1 for
a perfect misclassiﬁcation and perfect classiﬁcation, respectively.

Accuracy =

T P + T N
T P + T N + F P + F N

M CC =

T P × T N − F P × F N
(cid:112)(T P + F P )(T P + F N )(T N + F P )(T N + F N )

(1)

(2)

TP: True Positive; FP: False Positive; TN: True Negative; and FN: False Negative.

In the following sections, we answer the four research questions as stated in

Section 4.3.1.

4.3.3. RQ1 Prevalence

Table 4 presents detection results for the nine pairs of linguistic patterns and
antipatterns on 19 IoT APIs. In Table 4, the ﬁrst column shows the linguistic
patterns and antipatterns followed by the 19 IoT APIs. For each API and for
each pattern and antipattern, the total number of occurrences is reported that
are found as positives by our detection algorithms. The last column shows
the total occurrences with percentage for each pattern and antipattern. The
detailed analyses results for all the 1,102 URIs from 19 IoT APIs are available
online9.

To summarise the results in Table 4, Amazon AWS Core IoT, Arduino IoT,
Caret, Cisco IPICS, and Sonos had the most number of antipatterns given the
number of URIs tested for each of those APIs. In contrast, Google Nest, Node-
RED, CubeSensors, thethings.iO, and Toon had the most number of patterns
given the number of URIs tested for each those APIs. We make these obser-
vations by dividing the total instances of patterns or antipatterns by the total
number of analysed URIs for each API.

As Table 4 suggests, all the analysed IoT APIs contain at least one of nine
linguistic antipatterns. The set of ﬁve IoT APIs, i.e., Droplit.io, IBM Watson
IoT, Losant, Microsoft Azure IoT Hub, and Samsung ARTIK Cloud, is found
to be involved in six diﬀerent linguistic antipatterns. Although, CubeSensors,
Node-RED, and Toon APIs are found to be involved in only two linguistic
antipatterns.

8https://forms.gle/EmGPoZbRwGXybFHY8
9https://doi.org/10.5281/zenodo.6393404

24

Table 5: Comparison of the detection of linguistic antipatterns across domains.

Approach

SARA [15]

CloudLex [10]

SARAv2

Target domain
Number of APIs Analysed
Number of URIs Tested

APIs for Web apps APIs for Cloud services

18
310

16
23,062

APIs for IoT
19
1,102

(Anti)Patterns / Detection

#Instances %URIs #Instances

%URIs #Instances %URIs

-
-

65%
35%
40% 10,595
60% 12,467
12%
88%
-
-
56%
0%

(cid:54)Amorphous URI
(cid:52)Tidy URI
(cid:54)Contextless Resource Names
(cid:52)Contextualised Resource Names
(cid:54)CRUDy URI
(cid:52)Verbless URI
(cid:54)Inconsistent Documentation
(cid:52)Consistent Documentation
(cid:54)Non-hierarchical Nodes
(cid:52)Hierarchical Nodes
(cid:54)Non-pertinent Documentation
(cid:52)Pertinent Documentation
(cid:54)Pluralised Nodes
(cid:52)Singularised Nodes
(cid:54)Unversioned URI
(cid:52)Versioned URI
(cid:54)Non-standard URI
(cid:52)Standard URI
*Detection was done on additional set of URIs **detection was done on a subset of the URIs

9
1,093
99
1,003
21
1,081
85
1,017
0
1,102
712
390
269
833
732
370
4
1,098

0.82%
99.18%
8.98%
91.02%
1.91%
98.09%
7.71%
92.29%
0%
100%
64.61%
35.39%
24.41%
75.59%
66.42%
33.58%
0.36%
99.64%

202
108
123
187
38
272
-
-
173
0
155*
400*
14
4
-
-
-
-

-
-
23%
77%
-
-
-
-
-
-
52%
48%
-
-
-
-
-
-

28% 1,339**
72% 792**

5%
1%
-
-
-
-

-
-
-
-
-
-

-
-
-
-
-
-

Summary on RQ1: Linguistic antipatterns are prevalent in IoT
APIs. In the analysed IoT APIs we have detected some instances of poor
design practices, being the most prevalent Non-pertinent Documentation or
Unversioned URIs. We also observed the presence of good design practices,
i.e., linguistic patterns, which suggests that the developers are aware of the
need for linguistic quality on their APIs.

4.3.4. RQ2 Comparison

APIs are used for various purposes and in various domains, for example,
APIs for Web applications [15] and Cloud services [10]. In this research, we aim
to ﬁnd whether a certain linguistic antipattern (or pattern) is notably common
across the domains or whether a certain domain is more prone to an antipat-
tern (or pattern) compared to other domains. It is important to note that the
methods relevant to the domains, i.e., SARA [15] and CloudLex [10] are ap-
plied to diﬀerent sets of APIs. Thus, a direct comparison among the methods
is not possible. Instead, we only want to compare the prevalence of linguistic
antipatterns in REST APIs in diﬀerent domains.

As Table 5 shows, the APIs for Web applications have more (cid:54)Amorphous
URI (65%) than the IoT APIs (0.82%). In contrast, IoT APIs are more often
tidy than the APIs from the other domains with 99.18% URIs are detected as
(cid:52)Tidy URI. A consistent detection is observed in Table 5 for the (cid:54)Contextless
Resource Names and its corresponding (cid:52)Contextualised Resource Names, i.e.,
the majority of the URIs in the three domains are designed with resource names
that are semantically aligned within the context of the URI design. Thus, 60%

25

of URIs for Web applications, 77% of URIs for Cloud services, and 91.02% of
URIs for IoT APIs are detected as (cid:52)Contextualised Resource Names. Similarly,
designers are well aware of not using verbs within the URI design, thus, 88%
URIs for Web applications and 98.09% URIs from the IoT APIs are detected
as (cid:52)Verbless URI. To summarise, APIs for Web applications are mostly prone
to (cid:54)Amorphous URI and notably implement patterns like (cid:52)Verbless URI and
(cid:52)Pertinent Documentation. On the other hand, IoT APIs suﬀer mostly with
(cid:54)Non-pertinent Documentation and (cid:54)Unversioned URI, which suggests that IoT
APIs are poorly documented and the URI designers do not tend to design the
URIs with version info – a poor URI design practice. In contrast, we found that
IoT APIs have very tidy URIs, i.e., the (cid:52)Tidy URI, and the nodes in the URIs
are organised hierarchically, i.e., the (cid:52)Hierarchical Nodes.

More speciﬁcally, for Web APIs in [15], for example, Facebook had a high
number of (cid:54)Contextless Resource Names and (cid:54)Non-hierarchical Nodes due to its
diverse and large set of resources. It is often diﬃcult to ﬁnd a best hierarchical
order of URIs nodes or to ﬁnd resources names best ﬁt to a certain context.
However, Twitter and YouTube, for example, did not suﬀer those antipatterns
In fact,
with comparatively lower number of resources than Facebook [15].
on average, StackExchange had the most number of antipatterns, due to which
(cid:54)Amorphous URI and (cid:54)Non-hierarchical Nodes seem very common, as reported
by SARA [15].

On the contrary, relatively new IoT APIs are designed with more knowl-
edge and experience from the literature of good design practices and guidelines
on APIs design [3, 14, 27, 26, 31, 32]. This could be one reason the (cid:54)Amor-
phous URI is found on very small scale. Also, the detection for (cid:54)Contextless
Resource Names and (cid:54)Non-hierarchical Nodes in IoT APIs resulted in compar-
atively lower than in APIs for Web applications. The major IoT APIs vendors
including Amazon, Google, IBM, and Microsoft are well aware of designing
quality URIs both syntactic (e.g., (cid:54)Amorphous URI ) and semantic (e.g., (cid:54)Con-
textless Resource Names, (cid:54)Non-hierarchical Nodes, or (cid:54)Inconsistent Documen-
tation) viewpoints.

Overall, on average, 34% of the URIs from the APIs for Web applications
are detected having linguistic antipatterns by SARA [15]. In contrast, only 17%
of the URIs from the APIs for IoT devices are detected as antipatterns by the
REST-Ling tool. Also, for linguistic patterns, the REST-Ling tool found 73%
URIs are well-designed compared to 42% URIs of APIs for Web applications.
This suggests that IoT APIs are comparatively more well-designed than the
APIs for Web applications like Facebook, YouTube, or Instagram [15]. This
could be because the APIs speciﬁc to Web applications deal with a plethora of
resources types and representations, compared to the APIs in the IoT domain,
where devices mainly deal with device data and transmission from/to the servers
and peer devices. Thus, APIs for Web applications pose a higher challenge in
designing high-quality URIs than the IoT APIs, i.e., APIs for Web applications
are more prone to linguistic antipatterns.

26

Table 6: REST-Ling validation results to compute overall precision and recall.

Linguistic Antipatterns

P N TP FP FN TN Accuracy MCC

(cid:54)Amorphous URI

(cid:54)Contextless Resource Names

(cid:54)CRUDy URI

(cid:54)Non-hierarchical Nodes

(cid:54)Pluralised Nodes

4

11

3

0

31

(cid:54)Non-Pertinent Documentation 58

(cid:54)Unversioned URIs

(cid:54)Inconsistent Documentation

(cid:54)Non-standard URI

67

26

2

87

80

88

91

60

33

24

65

89

1

6

3

0

25

3

5

0

0

6

8

50

67

19

2

0

7

0

27

15

3

14

5

4

0

8

10

60

65

85

77

55

29

24

57

79

67%

78%

97%

85%

88%

41%

100%

84%

89%

-0.03

0.28

0.69

n/a

0.73

0.02

1.00

0.60

0.38

Total
Average

202 617 131 71 86 531

81%

0.46

Summary on RQ2: We found that resource URIs are structurally and
contextually well-designed in APIs for IoT applications than for Web ap-
plications. Although the APIs for cloud services are not studied to a large
number, the analysis of resource context (Contextless vs. Contextualised Re-
source Names) and cohesive documentation (Pertinent vs. Non-pertinent
Documentation) suggests that APIs for cloud services exhibit similar design
quality found in APIs for Web applications. In fact, APIs for IoT appli-
cations appear to have a better design (structural and contextual)
except that the APIs for IoT applications are poorly and, in many
cases, brieﬂy documented.

4.3.5. RQ3 Accuracy

Table 6 shows the detection accuracy for nine linguistic antipatterns.
In
Table 6, on a subset of 91 URIs from 19 IoT APIs, we obtained an aver-
age accuracy of 81%. The accuracy is also heavily dependent on how engi-
neers (in our case, the three professionals) understand and interpret a phrase
or word based on their experience and knowledge. For example, in Valida-
tion 1, an instance from Losant with the URI /applications/APPLICATION_
ID/devices/DEVICE_ID/commandStream and the documentation10 where the
REST-Ling tool detects it as Non-pertinent Documentation antipattern, but the
majority of the professionals (i.e., two out of three) considered the URI and its
documentation cohesive, thus, decided as Pertinent Documentation pattern. In

10Attach to a real time stream of command messages to this device using SSE.

27

Table 7: Detection times (in seconds) of the nine linguistic patterns and antipatterns in 19
IoT APIs.

s
e
d
o
N

l
a
c
i
h
c
r
a
r
e
i
h
-
n
o
N

I

R
U
s
u
o
h
p
r
o
m
A

I

R
U
y
D
U
R
C

s
e
d
o
N
d
e
s
i
l
a
r
u
l
P

I

R
U
d
e
n
o
i
s
r
e
v
n
U

.
c
o
D
t
n
e
n
i
t
r
e
p
-
n
o
N

e
c
r
u
o
s
e
R
s
s
e
l
t
x
e
t
n
o
C

.
c
o
D
t
n
e
t
s
i
s
n
o
c
n
I

I

R
U
d
r
a
d
n
a
t
s
-
n
o
N

IoT APIs

Amazon AWS IoT 0.003 0.033 1.307 0.009 0.004 59.462 193.442 0.010 0.002
2.092
0.777 0.012 0.001
Amrosus Gateway 0.002 0.005 1.356 0.005 0.002
3.103 0.010 0.001
2.833
0.002 0.009 1.278 0.003 0.002
Arduino IoT
1.544 0.013 0.001
0.001 0.003 1.297 0.021 0.001
Caret
1.142
4.405 0.015 0.001
0.004 0.014 1.292 0.005 0.004 10.288
Cisco Flare
0.002 0.005 1.342 0.004 0.001
Cisco IPICS
0.459 0.010 0.001
1.037
0.003 0.015 1.306 0.010 0.006 11.681 39.152 0.014 0.001
ClearBlade
0.001 0.002 1.317 0.002 0.001
CubeSensors
0.610 0.014 0.001
0.002 0.009 1.331 0.008 0.004 14.200 14.264 0.011 0.001
Droplit.io
0.047 0.008 1.166 0.006 0.005 19.223 10.057 0.010 0.001
Google Nest
0.004 0.060 1.275 0.012 0.007 75.337 187.547 0.010 0.040
IBM Watson
0.003 0.029 1.244 0.008 0.003 12.385 18.489 0.014 0.002
Losant
0.011 0.052 1.302 0.019 0.041 109.248 351.087 0.012 0.006
Microsoft Azure
0.009 0.003 1.347 0.004 0.002
Node-RED
1.564 0.013 0.001
0.046 0.018 1.250 0.012 0.005 47.180 125.294 0.011 0.002
Samsung ART
0.089 0.010 1.214 0.009 0.005 31.766 21.943 0.012 0.001
Sonos
1.400 0.009 0.001
0.016 0.004 1.227 0.003 0.001
The Things Net
2.875
7.154 0.010 0.001
0.044 0.011 1.280 0.004 0.007 13.009
thethings.io
2.727 0.010 0.001
8.006
0.040 0.088 1.197 0.005 0.004
Toon

1.667

1.703

e
g
a
r
e
v
A

l
a
t
o
T

254.272 28.252
4.252 0.472
7.241 0.805
4.023 0.447
16.028 1.781
2.861 0.318
52.188 5.799
3.615 0.402
29.830 3.314
30.523 3.391
264.292 29.366
32.177 3.575
461.778 51.309
4.646 0.516
173.818 19.313
55.049 6.117
5.536 0.615
21.520 2.391
12.078 1.342

Total
Average

0.329 0.378 24.328 0.149 0.105 425.134 985.018 0.220 0.066 1,435.727
0.017 0.020 1.280 0.008 0.006 22.375 51.843 0.012 0.003

8.396

another example, an instance from Cisco Flare with the URI /environments/
{environment_id}/zones/{zone_id}/things/{thing_id}/data and with the
documentation11 where the REST-Ling tool approach detects it as Pertinent
Documentation pattern, however, two out of three professionals did not see this
URI and its documentation cohesive, and identiﬁed it as Non-pertinent Docu-
mentation antipattern.
Instances similar to the above examples may lead to
lower accuracy.

Summary on RQ3: The manual validation suggests that the REST-Ling
tool has an overall average accuracy of more than 80%, with an average
MCC of 0.46.

4.3.6. RQ4 Eﬃciency

We performed the experiments on an Intel Dual Core at 3.30GHz with 4GB
of RAM. For the detection of linguistic patterns and antipatterns in IoT APIs,

11Get thing data.

Gets all data values for a thing by making a REST call. You

can also get the data for a thing using the getData Socket.IO call.

28

1
2
3
4
5

Listing 2: Code snippet for measuring the detection time.
/∗ D e t e c t i o n o f C o n t e x t l e s s Resource Names A n t i p a t t e r n ∗/
l o n g s t a r t T i m e = System . c u r r e n t T i m e M i l l i s ( ) ;
d e t e c t C o n t e x t l e s s R e s o u r c e N a m e s ( ) ;
l o n g endTime = System . c u r r e n t T i m e M i l l i s ( ) ;
System . o u t . p r i n t l n ( ” T o t a l d e t e c t i o n t i m e ( s e c ) : ” + ( d o u b l e ) (

endTime − s t a r t T i m e ) / 1 0 0 0 ) ;

the reported detection times include: (1) the time to apply and run the detection
algorithms implemented in Java on the URIs and (2) the time to export the
results. Listing 2 shows the code snippet we use for measuring the detection time
for each API and for each linguistic antipattern where we record the time before
and after running the detection (lines 4 and 6). We then take the diﬀerence and
get the values in seconds (line 7). Table 7 shows the detection time for each
API (rows) and each antipattern (columns).

Figure 7: Plot of the average detection times against the URIs analysed for the APIs.

Regardless of the APIs, for each antipattern, we observed a consistent de-
tection time, i.e., when the number of tested URIs for an API is low, the
detection time is lower and the detection time increases polynomially when
the number of tested URIs increases. The estimated growth function is y =
0.0011x2 + 0.0103x + 0.2294 where x is the number of URIs to test, and y
is the total detection time for an antipattern. This growth function is par-
ticularly applicable for the Contextless Resource Names antipattern where we
needed to perform a signiﬁcant amount of pairwise comparisons for the nodes
in the URIs. Also, the detection time is considerably lower when the detection
does not require exhaustive comparisons or only requires syntactic checking,
e.g., Amorphous URI, CRUDy URI, Universioned URI, Non-standard URI, and
so on. For example, the detection times for Amorphous URI antipattern are
between 0.001 and 0.089 seconds, the detection times for Pluralised Nodes an-
tipattern are between 0.002 and 0.021 seconds. However, the detection times for
Contextless Resource Names antipattern are between 0.459 (for CISCO IPICS
with only ﬁve tested URIs) and 351.087 seconds (for Microsoft Azure with 210
tested URIs). And, in this case, the detection times depend on the exhaustive

29

y = 0.0011x2+ 0.0103x + 0.2294R² = 0.97950102030405060050100150200250Average Detection TimesNumber of URIs Analysedsemantic comparisons among the nodes in the URIs.

As shown in Table 7, the global average detection time of each antipattern
for all IoT APIs is 8.396 seconds. Our detection algorithms for linguistic an-
tipatterns have a polynomial complexity of O(nk). The average detection time
can be expressed as a polynomial function as shown in Figure 7.

Summary on RQ4 Eﬃciency: In concern to eﬃciency of REST-
Ling, we want to achieve an average detection time for each linguistic
antipattern and for each IoT API in the order of seconds. Regardless
of the number of URIs tested for each API, the REST-Ling had an
average detection time of 8.396 seconds. Moreover, the total
detection time for nine antipatterns and nine patterns on 19 APIs
with 1,102 URIs was 1,435.727 seconds.

4.4. Threats to Validity

Our ﬁndings may not be generalised to all IoT APIs. However, to minimise
the threat to the external validity of our results, we performed experiments on
a set of 1,102 URIs from 19 IoT APIs. To minimise the threat to the internal
validity, we not only used WordNet [18] for lexical analyses of URIs, but we
also relied on a technique based on the LDA topic modeling to properly cap-
ture the context and use the DISCO second-order similarity metric to measure
the similarity between the nodes in URIs. But, the outcome of the detection
may vary depending on the way the detection heuristics of linguistic patterns
and antipatterns are applied because the software engineers may have their own
understanding and experience on IoT and on the linguistic patterns and an-
tipatterns. Moreover, in the manual validation, only 91 of the 1,102 URIs were
validated manually, which may be not representative. However, to minimise
the threat, we aimed for a 95% conﬁdence level and a conﬁdence interval of 10,
thus, we ended up validating 91 URIs and nine linguistic antipatterns, i.e., 819
questions.

In this study, the detection of linguistic antipatterns is performed on the
IoT APIs that had well-organised and self-contained documentation. Thus,
the detection on IoT APIs with no or very minimal documentation could yield
diﬀerent results. However, we minimised the threats to the construct validity
by selecting a set of IoT APIs that are well-documented. Moreover, we tried
to minimise the threat to the construct validity by deﬁning detection heuristics
after a thorough review of deﬁnitions of linguistic patterns and antipatterns.
Three professionals were involved in the validation process, and we decided
the oracle based on the majority (i.e., when two participants agreed out of
the three who participated in the manual validation). The average degree of
agreement among the professionals for the manual validation was 0.83. Thus,
an average agreement of 0.83 for all antipatterns helps to minimise the threat
to the construct validity, i.e., our validation results and accuracy are reliable.
The REST-Ling tool currently supports the detection of nine linguistic patterns

30

and nine linguistic antipatterns. The tool has a detection accuracy of more
than 80%. The accuracy of the tool is conﬁrmed via manual validation of the
detection outcomes.

In fact, we cannot claim the list of linguistic patterns and antipatterns is
complete. Therefore, when talking about linguistic quality of IoT APIs, we refer
to the set of linguistic patterns and antipatterns in our study. Nevertheless, to
the best of our knowledge, our approach and the empirical study performed on
REST IoT APIs is the most comprehensive analysis so far.

To minimise the threats to validity, i.e., to increase the reliability and repli-

cability, we have put all the details of this study online12.

5. Related Work

Analysis techniques to detect linguistic patterns and antipatterns have been
previously applied to Object-Oriented (OO) systems’ source code e.g., [17, 33]
to assess their linguistic quality (Section 5.1).
In addition, several Natural
Language Processing (NLP) techniques have been also applied to studying the
linguistic quality of APIs and their documentation e.g., [3, 6, 8, 9, 10, 11, 12, 13],
as discussed in Section 5.2.

5.1. Syntactic and Semantic Analysis of Source Code

Abebe et al. [33] presented a set of lexicon bad smells in OO code and a tool-
suite using semantic analysis techniques to detect them. The authors aimed at
improving the linguistic quality of OO source code because high quality and self-
descriptive source code comments are useful in developing highly maintainable
[34] proposed the JavadocMiner approach for assess-
systems. Khamis et al.
ing the quality of in-line documentation relying on heuristics both in terms of
language quality and consistency between source code and comments.

Semantic analyses have also been applied to Web services design analysis
and development [35, 36]. Rodriguez et al. [36] presented a study on poor lin-
guistic practices identiﬁed on a set of WSDL (Web Service Deﬁnition Language)
descriptions and provided a catalog of Web services discoverability antipatterns.
These antipatterns focus on the comments, elements names, or types used for
representing the data models in WSDL documents. Also, Mateos et al. [35]
presented a tool to detect a subset of the antipatterns proposed in [36].

Other researchers also used semantic analyses in diﬀerent phases of the soft-
ware development life-cycle [37, 38, 39]. For example, Lu et al. [38] proposed
an approach to improve code searches by identifying relevant synonyms using
the WordNet English lexical database [18]. Arnaoudova et al. [37] performed
a study on identiﬁers renaming in OO systems. Finally, Rahman and Roy [39]
presented an approach to automatically suggest relevant search terms based
on the textual descriptions of change tasks in software. These approaches are

12https://doi.org/10.5281/zenodo.6393404

31

tailored to OO identiﬁers and their consistencies with comments [17, 33] or to
traditional SOAP-based Web services interfaces [35, 36]. Therefore, they cannot
be applied to IoT APIs due to the peculiarities of their development life-cycle
and their consumption nature.

Arnaoudova et al. [17] presented the deﬁnition of linguistic antipatterns and
deﬁned 17 linguistic antipatterns in OO programming (i.e., recurring poor prac-
tices related to inconsistencies among the naming, documentation, and imple-
mentation of a software entity), and implemented their detection algorithms.
They searched for the diﬀerences between the identiﬁers used for software en-
tities (e.g., method names and return types) and their implementation and–or
documentation. For example, one antipattern is called “Is” returns more than
a Boolean, which analyses the name of a method starting with “Is” and checks
if the method returns a boolean [17].

Machine learning techniques are also applied in predicting poor design, i.e.,
antipatterns. For example, Fakhoury et al. [40] performed a comparative study
to explore how conventional machine learning classiﬁers perform compared to
the deep learning methods in predicting linguistic antipatterns in object-oriented
(OO) source code. Aghajani et al. [41] conducted a large-scale study on more
than 1.5k releases of 75 Maven libraries, 14k open-source Java projects based
on those libraries, and more than 4k questions related to the libraries from
Stack Overﬂow. More precisely, they studied if client developers are prone to
introducing bugs when using APIs involved in linguistic antipatterns. Based on
their statistical analysis, it is likely that linguistic antipatterns have an eﬀect on
introducing bugs (thus, triggering questions on Stack Overﬂow) with a proba-
bility of 29%. However, both these studies [40, 41] were conducted for linguistic
antipatterns in OO source code.

5.2. Syntactic and Semantic Analysis of APIs and their Documentation

APIs are the de facto standard used by software companies to design, de-
velop, and oﬀer their services through the Internet. Client developers must
follow well-documented APIs to use the services and resources oﬀered by those
APIs properly. However, there are only a few standards and guidelines that
guide API design and development [3, 9].

Bertolino et al. [42] modeled the SOAP Web service behavior protocol, i.e.,
how clients should behave while interacting with the service. They proposed
the StrawBerry [42] method to automatically derive the Web service behavior
protocol from its WSDL interface.

As one of the ﬁrst studies on APIs, Parrish [43] did a subjective lexical
comparison between two well-known APIs, e.g., Facebook and Twitter. The
author analysed, for example, the use of verbs and nouns in URIs naming and
concluded that developers should rely on nouns instead of verbs while designing
REST URIs.

Masse [3] proposed an extensive list of REST API design principles, including
the design of URIs, appropriate use of HTTP methods and status codes, meta-
data design, and best practices for resource representations. The Open Mobile

32

Alliance (OMA) provides guidelines for designing APIs exhibiting RESTfulness
and for properly documenting the APIs, for example, not using verbs as resource
identiﬁers or specifying API version within URIs. Several studies have also
been performed in the domain of APIs automatically analyse their structure.
For example, Haupt et al. [11] presented a framework for structural analysis of
APIs based on their documentations. They focused on the structural properties
of APIs, and later, extended the study towards API governance [44].

Panziera and Paoli [45] put forward a set of best practices for building self-
descriptive REST services, which can be both human-readable and machine-
processable (e.g., by using a common vocabulary for REST resources). They
proposed a framework to collect information on documentation for generating
descriptions of REST services. They evaluated their framework and reported
the accuracy of identifying resources correctly with precision and recall of 72%
and 77%, respectively.

Treude et al. [46] developed a search-based approach for automatically ex-
tracting tasks (i.e., a set of speciﬁc programming actions to be undertaken)
from software documentation. They tried to minimise the gap between the
information needs of the developers’ and the documentation structure/content
and, thus, assist developers in documentation navigation. Using the suggested
approach, which utilises natural language processing techniques, they extracted
more than 70% tasks from two large corpus of software documentation.

Some studies investigate and analyse services interfaces to measure their lin-
guistic quality, in particular for SOAP Web services [47, 42] and for APIs [6, 48].
For example, Wei et al. [47] presented a framework and algorithms to analyse
service interfaces, the SOAP Web services, in particular. They targeted large
and overloaded services with the goal to ease their integration and interoper-
ability. The framework enabled to refactor large interfaces and was validated
with real commercial logistic systems like FedEx.

Petrillo et al. [6] provided a survey on REST literature and gathered 73 best
practices in designing APIs to increase their understandability and reusability.
They evaluated three well-known APIs from three Cloud providers, i.e., Google
Cloud Platform, OpenStack, and Open Cloud Computing Interface (OCCI), to
evaluate their quality based on the identiﬁed best practices.

Rodr´ıguez et al.

[48] analysed high-volume of REST HTTP traﬃc, i.e.,
HTTP requests, to evaluate how well or bad developers implement APIs in
practice. They compared the wellness with theoretical Web engineering prin-
ciples and guidelines. The authors relied on heuristics and metrics to measure
the implementation quality by means of antipatterns. Results showed a gap
between theory and practice.

In our previous work [15], we proposed the SARA approach for automatically
assessing the quality of APIs for Web applications through the detection of
linguistic patterns and antipatterns. For the detection of linguistic patterns
and antipatterns SARA relied on syntactic and semantic analysis of APIs. In
another work [10], we proposed CloudLex and studied the presence of linguistic
patterns and antipatterns in 16 cloud computing APIs. The Cloud APIs tend to
use heterogeneous terms in their URI designs, and more than half of the URIs

33

were not well-documented. CloudLex showed an average precision of 85% and a
recall of 64%. In previous works, we also performed studies [5, 15] that focused
on the ‘RESTful’ aspect of Web APIs, for example, to see if the APIs follow
basic REST design principles including (i) statelessness, (ii) cacheability, and
(iii) interface uniformity.

In similar lines of research, working with OCCI patterns and antipatterns,
Brabra et al. [13, 49] deﬁned a set of patterns and antipatterns, inspired by the
OCCI guidelines13. They performed an automatic detection of 28 OCCI REST
patterns and antipatterns in Cloud APIs by invoking more than 300 operations.

5.3. State-of-the-Art Summary

The analysis of the aforementioned studies allow us to identify some lim-
itations. More speciﬁcally, studies dedicated to the OO systems [17, 33] or
SOAP-based Web services interfaces [35, 36] are not applicable to APIs for IoT
applications. Although, there are guidelines on API design [3], the semantic
aspects of API design were considered in very few works [11, 44]. Some stud-
ies analysed the APIs or their documentation but did not assess the linguistic
quality of the APIs (e.g., [6, 42, 47, 48]) or software documentation (e.g., [46]).
Other works only focused on the structural design of the APIs, e.g., [13, 49].

Although some of the aforementioned approaches dealt with linguistic as-
pects of REST or cloud computing APIs, in most cases, they only relied on
the subjective view of a set of good linguistic practices and recommendations.
There is a lack of dedicated approaches that automatically assess the linguistic
quality of APIs from IoT providers by detecting both poor and best practices.
Other research focused on the analysis of linguistic aspects of the APIs and
their documentation, and to the best of our knowledge, our study is the ﬁrst
that focuses on the linguistic design quality of APIs from IoT providers.

Table 8 shows a summary of the comparison between our SARAv2 approach
and the related state-of-the-art studies in terms of their goals and methods.
In providing a big picture of the comparison: ﬁrstly, SARAv2 is a general
approach for analysing REST APIs, and the empirical experiment in the current
paper is the ﬁrst study related to IoT APIs.
In this aspect, we studied 19
APIs from 18 diﬀerent IoT providers, where we performed both syntactic and
semantic analysis of more than 1,100 URIs. We performed the detection of nine
linguistic antipatterns and their corresponding nine linguistic patterns to assess
the linguistic quality of IoT APIs because we conjecture that poor linguistic
quality hinders the consumption, reusability, and maintenance and evolution of
APIs. Studies have been performed for Cloud services (e.g., [6, 8, 13]) or REST
Web services (e.g., [5, 43, 48]), which are mostly based on syntactic analysis.
However, to the best of our knowledge, SARAv2 is the ﬁrst study that analyse
IoT APIs both syntactically and semantically.

Secondly, our analysis involved 19 APIs from 18 diﬀerent IoT providers,
which is also comparatively higher than any other studies in the literature, i.e.,

13http://occi-wg.org/about/speciﬁcation/

34

Table 8: Comparison with the relevant studies in the literature.

Study

Goal of the Study

Target APIs

Analysis Method

Parrish [43]

Lexical analysis of 2
social network APIs

Facebook and Twit-
ter

Identiﬁcation of verbs and nouns

Wei et al. [47]

Structural
analysis
of the service inter-
faces

272 operations from
13 cloud services re-
lated to Amazon,
FedEx, etc.

Number of operations each ser-
vice provides, average number
(per operation) of input param-
eters, output parameters, busi-
ness entities, etc.

Brabra et al. [13]

Petrillo et al. [6]

Deﬁnition and de-
tection
of OCCI
REST patterns and
antipatterns

Check APIs for con-
formance to 73 best
practices

Rodriguez et al. [48] Check APIs for com-
pliance or violation
standardised
6
to
practices

6 APIs
services

for Cloud

Detection of 28 OCCI REST an-
tipatterns and their correspond-
ing patterns

Cloud

APIs
3
(Google Cloud Plat-
form,
OpenStack,
and OCCI)

78 GB of HTTP
traﬃc from Telecom
Italia

For each Cloud API, manually
checking the conformance to best
practices at the service level

For each action (Post, Get, Put,
Delete, etc.) check for the con-
formance with standardised se-
mantics, and also structural de-
sign of request URIs

Haupt et al. [11]

Structural
of APIs

analysis

286 Swagger API de-
scription documents

of

APIs

resources,

Size
of
POST/DELETE
read only resources, etc.

in
Number

terms
of
methods,

Palma et al. [15]

Detection of linguis-
tic antipatterns
in
APIs

18 APIs for Web ap-
plications

Heuristics-based detection for 6
linguistic antipatterns and their
corresponding patterns

Petrillo et al. [8]

Linguistic
quality
assessment of Cloud
Computing APIs

23,062 URIs
from
the 16 Cloud API
providers

Detection of 2 linguistic antipat-
terns and their corresponding
patterns

Brabra et al. [49]

Detection of OCCI
REST patterns and
antipatterns

SARAv2

Detection of linguis-
tic antipatterns and
in APIs
patterns
from IoT providers

in-
5 Cloud APIs
OCCI,
cluding
COAPS, OpenNeb-
ula, Amazon S3,
and Rackspace

19 APIs from 18 IoT
providers

Detection of 21 OCCI REST an-
tipatterns and their correspond-
ing patterns

Heuristics-based detection for 9
linguistic antipatterns and their
corresponding patterns

we wanted to investigate a set of APIs from heterogeneous providers to see,
on an average, the ratio of well-designed and poorly-designed APIs in terms of
linguistic quality.

A ﬁnal comparison can be made from the perspective of detection accuracy.
Our SARAv2 approach performs with an average accuracy of more than 80%.
Nevertheless, other studies (as reported in Table 9) show an average precision
between 80.9% and 100%. However, these studies are (i) either focus on other
types of APIs (i.e., Cloud services or Web APIs) or (ii) the number of anal-

35

Table 9: Comparison of the detection accuracy with the state-of-the-art approaches.

e
c
r
u
o
s
e
R
s
s
e
l
t
x
e
t
n
o
C
/
d
e
s
i
l
a
u
t
x
e
t
n
o
C

s
e
d
o
N

l
a
c
i
h
c
r
a
r
e
i
h
-
n
o
N
/
l
a
c
i
h
c
r
a
r
e
i
H

s
e
d
o
N
d
e
s
i
l
a
r
u
l
P
/
d
e
s
i
r
a
l
u
g
n
i
S

s
I
R
U
y
D
U
R
C
/
s
s
e
l
b
r
e
V

s
I
R
U
s
u
o
h
p
r
o
m
A
/
y
d
i
T

n
o
i
t
a
t
n
e
m
u
c
o
D
t
n
e
n
i
t
r
e
p
-
n
o
N
/
t
n
e
n
i
t
r
e
P

n
o
i
t
a
t
n
e
m
u
c
o
D
t
n
e
t
s
i
s
n
o
c
n
I
/
t
n
e
t
s
i
s
n
o
C

I

R
U
d
e
n
o
i
s
r
e
V
/
d
e
n
o
i
s
r
e
v
n
U

I

R
U
d
r
a
d
n
a
t
S
/
d
r
a
d
n
a
t
s
-
n
o
N

n
o
i
s
i
c
e
r
P
/
y
c
a
r
u
c
c
A

l
l
a
r
e
v
O

-
-

-
-

-
-
-
-
-
-

-
-
-
-
-
-

-
-
-
-
-
-

-
-
100% -
-
-
-

-
-
-
-
-
-
-
-
-
96% 77% 95% 60% 73%
-
98% 90% 100% 60% 73% 66% -
77% -
-

n/a
91%
100% 98%
n/a
n/a
n/a
81%
84%
74%
100% -
100%
67% 78% 97% 85% 88% 41% 84% 100% 89% 81%

-
100% -

100% -

-
-
-
-
-
-
-
-
-
-

-
-
-
-
-
-
-

-
-
-
-
-
-
-

71%

-

-

-

Study

Parrish [43]
Wei et al. [47]
Brabra et al. [13]
Petrillo et al. [6]
Rodriguez et al. [48]
Haupt et al. [11]
Palma et al. [5]
Palma et al. [15]
Petrillo et al. [8]
Brabra et al. [49]
This Study (SARAv2)

*Values that are not reported by the studies denoted by ‘-’.
*The n/a refers to the cases where the precision/accuracy are not reported.

ysed APIs is low (i.e., between 2 and 15 APIs) or (iii) the number of detected
linguistic patterns and antipatterns is relatively lower (i.e., between 2 and 28
antipatterns) or (iv) they only perform very ﬁne-grained syntactic analyses (i.e.,
those for OCCI patterns and antipatterns [6, 13]). Considering the highly se-
mantic nature of our automatic analysis using the SARAv2 approach and the
subjective validation of the results using experts, which might signiﬁcantly dif-
fer given the full degree of freedom for deciding patterns and antipatterns, we
consider an average accuracy of more than 80% is acceptable in the domain of
natural language processing [50].

6. Conclusion and Future Work

The understandability and reusability are two critical factors for API providers.

In the literature, researchers analysed APIs for Web applications and cloud ser-
vices to assess their linguistic design quality [6, 17, 8, 10, 11, 12, 13]. In this
study, we assess the linguistic quality of APIs for IoT applications by analysing
whether they contain linguistic antipatterns. We proposed the SARAv2 (Se-
mantic Analysis of REST APIs version two) approach and used it to perform
syntactic and semantic analyses of REST APIs for IoT applications. The REST-
Ling realises the SARAv2 approach as a web application to automate the de-
tection of linguistic patterns and antipatterns.

36

We utilised the REST-Ling tool to detect nine linguistic patterns and an-
tipatterns. We validated the REST-Ling tool by analysing 1,102 URIs from 19
REST APIs for IoT applications and showed its accuracy of over 80%.

From the 19 analysed APIs, we found that all of them organise URIs nodes in
a hierarchical manner and only Caret, CubeSensors, and Droplit.io APIs involve
syntactical URIs design problems. Moreover, IoT APIs designers, in general, do
not use CRUDy terms in URIs, which is a good design practice, but then again,
they tend not to use versioning in URI – a poor practice. Also, most designers
in IoT use hierarchical organisation of nodes in URIs and document them using
consistent language. Further, the (cid:54)Non-pertinent Documentation was common
in all IoT APIs and the majority of the APIs had (cid:54)Unversioned URI. In contrast,
most of the APIs followed (cid:52)Tidy URI and (cid:52)Consistent Documentation.

As we compare the detection of antipatterns across the domains, we found
that the APIs for Web applications are highly prone to (cid:54)Amorphous URI al-
though carefully implement patterns like (cid:52)Verbless URI and (cid:52)Pertinent Docu-
mentation. We also found that the IoT APIs have very tidy URIs, i.e., follow
(cid:52)Tidy URI and the nodes in the URIs are organised hierarchically, i.e., follow
(cid:52)Hierarchical Nodes. On an average, 34% of the URIs from the APIs for Web ap-
plications are detected as having linguistic antipatterns, in contrast, 17% of the
URIs from the IoT APIs are detected as antipatterns. As for the linguistic pat-
terns, 73% URIs in IoT APIs are well-designed compared to 42% URIs of APIs
for Web applications, which suggests that IoT APIs like Amazon AWS, Google
Nest, IBM Watson, Microsoft Azure are comparatively more well-designed than
the APIs for general-purpose Web applications like Facebook, YouTube, or In-
stagram.

As future work, we want to apply the SARAv2 approach, thus, the REST-
Ling tool, to other IoT APIs. Recently, OpenAPI has been evolved to the
industry standard for REST API design and speciﬁcation. We want to analyse
OpenAPI JSON/YAML speciﬁcations to assess their design and documenta-
tion quality. We also want to investigate two of the patterns and antipatterns
further – Pluralised vs. Singularised Nodes and Non-pertinent vs. Pertinent
Documentation – as they are aﬀected more by the cognitive ability of the client
developers. We also want to build and include an IoT-speciﬁc ontology to per-
form an improved semantic analysis. Finally, while comparing the detection of
SARA and SARAv2, a further extension could be to compare the services from
the same company/team (e.g., the REST APIs for Web applications vs. IoT
APIs for IoT applications from Microsoft or Google) to see whether the diﬀer-
ence in the antipatterns is due to the diﬀerence of the domain (IoT vs. Web)
or due to diﬀerent companies having diﬀerent API design principles or level of
experience.

Acknowledgments

We would like to thank Niklas Emevi, a full stack Web developer at Tieto
CEM, for taking part in the validation process. We are thankful to Osama
Zarraa and Ahmad Sadia for their contributions in developing the tool. We

37

extend gratitude to The Knowledge Foundation that partially supported this
research through the SHADE H ¨OG-project 2017/0176. This study was also
conducted with the support from Linnaeus University Centre for Data Intensive
Sciences and Applications (DISA).

References

[1] S. Madakam, R. Ramaswamy, S. Tripathi, Internet of Things (IoT): A Literature
Review, Journal of Computer and Communications 03 (05) (2015) 164–173. doi:
10.4236/jcc.2015.35021.

[2] R. T. Fielding, Architectural Styles and the Design of Network-based Software

Architectures, Ph.D. thesis, University of California, Irvine (2000).

[3] M. Mass´e, REST API Design Rulebook, in: Vasa, O’Reilly, 2012, p. 114.

[4] F. Palma, J. Dubois, N. Moha, Y.-G. Gueheneuc, Detection of REST Patterns and
Antipatterns: A Heuristics-Based Approach, in: Service-Oriented Computing,
Vol. 8831 of Lecture Notes in Computer Science, 2014, pp. 230–244.

[5] F. Palma, J. Gonzalez-Huerta, N. Moha, Y.-G. Gu´eh´eneuc, G. Tremblay, Are
RESTful APIs Well-Designed? Detection of their Linguistic (Anti)Patterns, in:
International Conference on Service-Oriented Computing, Goa, India, 2015, pp.
171–187.

[6] F. Petrillo, P. Merle, N. Moha, Y.-G. Gu´eh´eneuc, Are REST APIs for Cloud
Computing Well-Designed? An Exploratory Study, in: International Conference
on Service-Oriented Computing, Banﬀ, Canada, 2016, pp. 157–170.

[7] R. Wilhelm, H. Seidl, S. Hack, Compiler design: syntactic and semantic analysis,

Springer Science & Business Media, 2013.

[8] F. Petrillo, P. Merle, F. Palma, N. Moha, Y.-G. Gu´eh´eneuc, A Lexical and Se-
mantical Analysis on REST Cloud Computing APIs, in: International Conference
on Cloud Computing and Services Science, Funchal, Portugal, 2018, pp. 308–332.

[9] OMA, Open Mobile Alliance: Guidelines for RESTful Network APIs (January

2012).

[10] F. Petrillo, P. Merle, F. Palma, N. Moha, Y.-G. Gu´eh´eneuc, A Lexical and Seman-
tical Analysis on REST Cloud Computing APIs, in: D. Ferguson, V. M. Mu˜noz,
J. Cardoso, M. Helfert, C. Pahl (Eds.), Cloud Computing and Service Science,
Springer International Publishing, Cham, 2018, pp. 308–332.

[11] F. Haupt, F. Leymann, A. Scherer, K. Vukojevic-Haupt, A Framework for the
Structural Analysis of REST APIs, in: 2017 IEEE International Conference on
Software Architecture, Gothenburg, Sweden, 2017, pp. 55–58.

[12] M. Hausenblas, On Entities in the Web of Data, in: E. Wilde, C. Pautasso (Eds.),

REST from Research to Practice, Springer, 2011, pp. 425–440.

38

[13] H. Brabra, A. Mtibaa, L. Sliman, W. Gaaloul, B. Benatallah, F. Gargouri, De-
tecting Cloud (Anti)Patterns: OCCI Perspective, in: International Conference
on Service-Oriented Computing, Banﬀ, Canada, 2016, pp. 202–218.

[14] T. Fredrich, RESTful Service Best Practices: Recommendations for Creating Web

Services (May 2012).
URL http://www.restapitutorial.com/resources.html

[15] F. Palma, J. Gonzalez-Huerta, M. Founi, N. Moha, G. Tremblay, Y.-G.
Gu´eh´eneuc, Semantic Analysis of RESTful APIs for the Detection of Linguis-
tic Patterns and Antipatterns, International Journal of Cooperative Information
Systems (IJCIS) 26 (2017) 1–37.

[16] V. Arnaoudova, M. Di Penta, G. Antoniol, Y.-G. Gueheneuc, A New Family of
Software Anti-patterns: Linguistic Anti-patterns, in: 2013 17th European Con-
ference on Software Maintenance and Reengineering, IEEE, 2013, pp. 187–196.
doi:10.1109/CSMR.2013.28.

[17] V. Arnaoudova, M. Di Penta, G. Antoniol, Linguistic Antipatterns: What They
Are And How Developers Perceive Them, Empirical Software Engineering 21 (1)
(2016) 104–158. doi:10.1007/s10664-014-9350-8.

[18] C. Fellbaum, WordNet: An Electronic Lexical Database, Bradford Books, 1998.

[19] C. D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J. Bethard, D. McClosky,
The Stanford CoreNLP natural language processing toolkit, in: Association for
Computational Linguistics (ACL) System Demonstrations, 2014, pp. 55–60.
URL http://www.aclweb.org/anthology/P/P14/P14-5010

[20] D. M. Blei, A. Y. Ng, M. I. Jordan, Latent Dirichlet Allocation, Journal of Ma-

chine Learning Research 3 (4-5) (2003) 993–1022. arXiv:1111.6189v1.

[21] P. Kolb, Disco: A Multilingual Database of Distributionally Similar Words, in:
Proceedings of 9th Conference on Natural Language Processing, 2008, pp. 37–44.

[22] P. Kolb, Experiments on the Diﬀerence between Semantic Similarity and Relat-

edness, in: 17th Nordic Conference of Computational Linguistics, 2009.

[23] T. Berners-Lee, R. T. Fielding, L. Masinter, Uniform Resource Identiﬁer (URI):

Generic Syntax (2005).

[24] S. Tilkov, REST Anti-Patterns, Available Online: www.infoq.com/articles/rest-

anti-patterns (July 2008).

[25] V. Braun, V. Clarke, Using thematic analysis in psychology, Qualitative Research

in Psychology 3 (2006) 77–101. doi:10.1191/1478088706qp063oa.

[26] G. Levin, REST API, Design, Guidelines, Architecture: 7 Rules for REST API

URI Design, last visited: October 2019 (June 2017).
URL https://blog.restcase.com/7-rules-for-rest-api-uri-design/

[27] Microsoft MSDN, Capitalization Styles, last visited: October 2019.

URL https://msdn.microsoft.com/en-us/library/x2dbyw72(v=vs.71).aspx

39

[28] A. Budanitsky, G. Hirst, Evaluating WordNet-based Measures of Lexical Semantic

Relatedness, Computational Linguistics 32 (1) (2006) 13–47.

[29] T. Griﬃth, M. Steyvers, Probabilistic Topic Models, Latent Se-mantic AnMysis.

A Road to Meaning. Hillsdale. Laurence Erlbaum Associates 440 (2006).

[30] N. Moha, F. Palma, M. Nayrolles, B. J. Conseil, Y.-G. Gu´eh´eneuc, B. Baudry, J.-
M. J´ez´equel, Speciﬁcation and detection of soa antipatterns, in: C. Liu, H. Lud-
wig, F. Toumani, Q. Yu (Eds.), Service-Oriented Computing, Springer Berlin
Heidelberg, Berlin, Heidelberg, 2012, pp. 1–16.

[31] Jennifer

Riggins,
of

ternet
api-design-considerations-internet-things/analysis/2015/06/30,
line; accessed 05 September 2019 (2015).

In-
https://www.programmableweb.com/news/
on-

API
Things,

Considerations

Design

The

for

[32] A. Keranen, M. Kovatsch, K. Hartke, RESTful Design for Internet of Things Sys-
tems, https://tools.ietf.org/html/draft-irtf-t2trg-rest-iot-00, online;
accessed 05 September 2019 (2017).

[33] S. L. Abebe, S. Haiduc, P. Tonella, A. Marcus, Lexicon Bad Smells in Software,
in: 2009 16th Working Conference on Reverse Engineering, Lille, France, 2009,
pp. 95–99.

[34] N. Khamis, R. Witte, J. Rilling, Automatic Quality Assessment of Source Code
Comments: The JavadocMiner, in: Natural language processing and information
systems, Springer, 2010, pp. 68–79.

[35] C. Mateos, J. M. Rodriguez, A. Zunino, A Tool to Improve Code-ﬁrst Web Ser-
vices Discoverability through Text Mining Techniques, Software: Practice and
Experience 45 (7) (2015) 925–948. doi:10.1002/spe.2268.
URL http://dx.doi.org/10.1002/spe.2268

[36] J. M. Rodriguez, M. Crasso, A. Zunino, M. Campo, Improving Web Service
Descriptions for Eﬀective Service Discovery, Science of Computer Programming
75 (11) (2010) 1001–1021. doi:10.1016/j.scico.2010.01.002.

[37] V. Arnaoudova, L. M. Eshkevari, M. D. Penta, R. Oliveto, G. Antoniol, Y.-
G. Gueheneuc, REPENT: Analyzing the Nature of Identiﬁer Renamings 40 (5)
(2014) 502–532. doi:10.1109/TSE.2014.2312942.

[38] M. Lu, X. Sun, S. Wang, D. Lo, Y. Duan, Query Expansion via WordNet for Eﬀec-
tive Code Search, in: 22nd IEEE International Conference on Software Analysis,
Evolution, and Reengineering, Montreal, Canada, 2015, pp. 545–549.

[39] M. M. Rahman, R. K. Chanchal, TextRank Based Search Term Identiﬁcation
for Software Change Tasks, in: 22nd IEEE International Conference on Software
Analysis, Evolution, and Reengineering, Montreal, Canada, 2015, pp. 540–544.

[40] S. Fakhoury, V. Arnaoudova, C. Noiseux, F. Khomh, G. Antoniol, Keep it Sim-
ple:
Is Deep Learning Good for Linguistic Smell Detection?, in: 2018 IEEE
25th International Conference on Software Analysis, Evolution and Reengineer-
ing (SANER), 2018, pp. 602–611. doi:10.1109/SANER.2018.8330265.

40

[41] E. Aghajani, C. Nagy, G. Bavota, M. Lanza, A Large-Scale Empirical Study on
Linguistic Antipatterns Aﬀecting APIs, in: 2018 IEEE International Conference
on Software Maintenance and Evolution (ICSME), 2018, pp. 25–35. doi:10.
1109/ICSME.2018.00012.

[42] A. Bertolino, P. Inverardi, P. Pelliccione, M. Tivoli, Automatic Synthesis of Be-
havior Protocols for Composable Web-services, in: Proceedings of the the 7th
joint meeting of the European software engineering conference and the ACM
SIGSOFT symposium on The foundations of software engineering, ACM, 2009,
pp. 141–150.

[43] A. Parrish, Social Network APIs : A Revised Lexical Analysis (2010).

[44] F. Haupt, F. Leymann, K. Vukojevic-Haupt, API Governance Support Through
the Structural Analysis of REST APIs, Computer Science - Research and Devel-
opment 33 (3) (2018) 291–303. doi:10.1007/s00450-017-0384-1.

[45] L. Panziera, F. D. Paoli, A Framework for Self-descriptive RESTful Services, in:
Proceedings of the 22Nd International Conference on World Wide Web, WWW
’13 Companion, International World Wide Web Conferences Steering Committee,
Republic and Canton of Geneva, Switzerland, 2013, pp. 1407–1414.

[46] C. Treude, M. P. Robillard, B. Dagenais, Extracting Development Tasks to Navi-
gate Software Documentation, Software Engineering, IEEE Transactions on 41 (6)
(2015) 565–581.

[47] F. Wei, A. Barros, C. Ouyang, Deriving Artefact-centric Interfaces for Overloaded
Web Services, in: International Conference on Advanced Information Systems
Engineering, Springer, 2015, pp. 501–516.

[48] C. Rodr´ıguez, M. Baez, F. Daniel, F. Casati, J. C. Trabucco, L. Canali, G. Per-
cannella, REST APIs: A Large-Scale Analysis of Compliance with Principles and
Best Practices, Springer International Publishing, Cham, 2016, pp. 21–39.

[49] H. Brabra, A. Mtibaa, F. Petrillo, P. Merle, L. Sliman, N. Moha, W. Gaaloul, Y.-
G. Gueheneuc, B. Benatallah, F. Gargouri, On Semantic Detection of Cloud API
(Anti)Patterns, Information and Software Technology 107 (2019) 65–82. doi:
https://doi.org/10.1016/j.infsof.2018.10.012.

[50] U. S. Shah, D. C. Jinwala, Resolving Ambiguities in Natural Language Software
Requirements: A Comprehensive Survey, SIGSOFT Software Engineering Notes
40 (5) (2015) 1–7. doi:10.1145/2815021.2815032.
URL http://doi.acm.org/10.1145/2815021.2815032

41

