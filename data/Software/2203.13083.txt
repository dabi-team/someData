2
2
0
2

r
a

M
4
2

]

O
R
.
s
c
[

1
v
3
8
0
3
1
.
3
0
2
2
:
v
i
X
r
a

Behavior Trees in
Robot Control Systems

Petter ¨Ogren,1and Christopher I. Sprague1
1KTH Royal Institute of Technology, Stockholm, Sweden, SE-10044; email: petter,sprague@kth.se

Annual Review of Control, Robotics, and
Autonomous Systems 2022. 5:1–25

https://doi.org/10.1146/annurev-control-042920-
095314

Keywords

behavior trees, modularity, hierarchical modularity, transparency, robustness,
autonomous system, feedback, task switching

Copyright © 2022 by Annual Reviews.
All rights reserved

Abstract

In this paper we will give a control theoretic perspective on the research area of
behavior trees in robotics. The key idea underlying behavior trees is to make
use of modularity, hierarchies and feedback, in order to handle the complexity
of a versatile robot control system. Modularity is a well-known tool to han-
dle software complexity by enabling development, debugging and extension of
separate modules without having detailed knowledge of the entire system. A hi-
erarchy of such modules is natural, since robot tasks can often be decomposed
into a hierarchy of sub-tasks. Finally, feedback control is a fundamental tool for
handling uncertainties and disturbances in any low level control system, but in
order to enable feedback control on the higher level, where one module decides
what submodule to execute, information regarding progress and applicability of
each submodule needs to be shared in the module interfaces.
We will describe how these three concepts come to use in theoretical analysis,
practical design, as well as extensions and combinations with other ideas from
control theory and robotics.

1

 
 
 
 
 
 
Contents

2
1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2. The history of behavior trees and their relation to ﬁnite state machines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
3. Deﬁnition of Behavior Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4. Optimal Modularity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
5. Proving convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
5.1. The general result. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
5.2. Three examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
6. A design principle exploiting modularity and feedback. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
7. Guaranteeing safety and invariance using control barrier functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
7.1. Control Barrier Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
7.2. Guaranteeing safety and handling conﬂicting objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
8. Explainable AI and human robot interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
9. Reinforcement Learning, Utility and BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
10.Evolutionary Algorithms and BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
11.Planning and BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
12.Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

1. Introduction

In this section we will describe why modularity, hierarchical structure, and feedback are useful in robot
control systems, and how these three concepts are combined in a control structure called behavior trees
(BTs).

The rapid development of robotic hardware and software has enabled the use of robots to expand
beyond structured factory environments, into our homes, streets and diverse workplaces.
In these
new settings, robots often need a wide range of capabilities, including the possibility to add even
more features by online software updates. It is well known that adding features to software increases
complexity, which in turn increases the cost of development (1). It is also well known that modularity
is a key principle that can be used to reduce complexity. By dividing a system into modules with
well deﬁned interfaces and functionality, each module can be developed, tested, and extended without
having detailed knowledge about the rest of the system. Thus, there is reason to believe that modularity,
in terms of well deﬁned interfaces and functionality, is an important property also for a robot control
system.

A natural extension of modularity is hierarchical modularity (1), where modules can contain sub-
modules and so on. The rationale for such a structure is the simple observation that when a system
grows, a single layer of modules either results in a very large number of modules, or in modules that
are themselves very large. Thus, the beneﬁt of modularity is strengthened if the modules can contain
submodules in a hierarchical fashion. There is an additional reason why hierarchical modularity makes
sense in robot control systems, and this is the fact that many robot tasks can naturally be divided into
subtasks in a hierarchical way, an observation that is underlying e.g. hierarchical task networks (2, 3).
For example, fetching an item might involve moving to a cupboard and opening it, which might in turn
involve grasping a handle, and so on.

To make the control system modular, we will make the actual control policy, the mapping from
state to action, modular. In many applications within robotics and control there is a need to compose
a control policy out of a set of subpolicies.
In an autonomous car there might be subpolicies for
parking, overtaking, lane keeping, handling intersections etc, and in a mobile manipulator there might

2

¨Ogren and Sprague

Figure 1: A mobile manipulator BT. The top level goals can be found in the top row: Make sure in
safe area (1), Make sure in range of charger (6), Make sure object at goal (9) and Make sure robot at
charger (37), in order of priority. If, at some time instant the action, Move to object (26), is executing,
a human operator can easily understand why this action was chosen by reading every double stroked
module on the branch towards the root: Move to object (26), in order to Make sure robot near object
(22), (to) Make sure object in gripper (12), (to) Make sure object at goal(9). The meaning of the
double strokes will be explained in detail in Section 6.

be subpolicies for grasping, docking with a recharger, moving from A to B etc.

Feedback is perhaps the most important principle in control theory, and the property that separates
open loop control from closed loop control. In open loop control, a series of commands are executed

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

3

Object at Goal (10)—>Place Object at Goal if Possible (11)? Make sure in safe area (1)? Make sure in range of charger (6)?Make Sure Object at Goal (9)Robot near Object (16)—>Move to Object if possible (17)?Make sure Robot near Object (15)Object in Gripper (13)—>Grasp (Left arm) Object if Possible (14)?Make sure Object in Gripper (12)Free path to Object exists (18)Move to Object (19)Robot near Goal (29)—>Move to Goal if possible (30)?Make sure Close to Goal (28)Place Object at Goal (33)Free path to Goal exists (31)Move to Goal (32)Grasp Object with left arm (20)In Safe Area (2)—> Make sure top level goals are achieved (0)—>Move to Safe Area if Possible (3)Free path to Safe Area exists (4)Move to Safe Area (5)Agent Nearby (35)—>Ask other Agent to Place Object if Possible (34)Ask other agent to place object (36)? Make Sure robot at charger (37)Robot at charger (38)Move to charger (39)Proper battery level (7)Re-charge (8)Robot near Object (23)—>Move to Object if possible (24)?Make sure Robot near Object (22)—>Grasp (Right arm) Object if Possible (21)Free path to Object exists (25)Move to Object (26)Grasp Object with right arm (27)over time according to some form of plan, while in closed loop control, the issued commands are
constantly adapted based on current information obtained from monitoring key parts of the world
state. It is clear that classical closed loop control should be executed at the lowest level of a hierarchical
modular robot control system, but it is less clear what kind of observations should be used between
two hierarchical levels, to allow one module to use feedback when it determines what submodule to
execute. We will come back to this question shortly, but for now we just note that if a submodule fails
with achieving its goal, we do not want the parent module to just execute the next submodule in an
open loop fashion, but instead chose the proper submodule using feedback, based on the fact that the
previous one just failed.

BTs were created to combine feedback with a hierarchical modular design. Thus, modules should
capture some functionality that can be combined into larger modules, with a clearly deﬁned interface
between modules on all levels. Furthermore, feedback regarding the execution should be passed up
the module hierarchy using the same interface.

The formal deﬁnition of BTs can be found in Section 3, but here we will make an informal de-
scription. We let each module in the discussion above be a BT. Thus a complex BT can contain a
number of sub-BTs and so on, as illustrated in Figure 1, where each node in the graph is the root of a
sub-BT. The interface of all BTs (the lines in the ﬁgure) is given in terms of a function call with return
values. When a BT is called it returns two things, ﬁrst the suggested control action and second the in-
formation needed to apply feedback control and determine what sub-BT to execute. This information,
or metadata, regarding the execution and applicability of a module is given in terms of one out of three
symbols, S (success), F (failure), and R (running). Thus, if a submodule for grasping a cup returns
success, the next submodule in the intended sequence, such as lifting the cup, might be invoked. If, on
the other hand, the submodule returns failure, some kind of fallback action needs to be invoked, such
as trying to re-grasp the cup, or getting a better sensor reading of its pose. Finally, if the submodule
returns running it might be preferable to let the execution run for a while longer.

At this point we note that there are basically three fundamental reasons for stopping what you are
doing and starting a new activity. Either you succeed and go on to the next action, or you fail, and need
to handle this more or less unexpected fact, or an external event happened that makes the current action
inappropriate. Imagine a robot tasked to fetch an object, such as in Figure 1. If the robot is grasping
the object, it might switch to moving if the grasping succeeds. If the grasping fails, it might try with
the other arm. A number of events might also occur to end the process of grasping the object. Another
agent might put the object in its proper place (positive surprise, we are done), or, another agent might
move the object further away (negative surprise, we need to move closer again), or the ﬁre alarm might
go off making the entire building unsafe (unrelated surprise, we need to leave the building).

The outline of this paper is as follows. In Section 2 we give a brief history of BTs, followed by
a formal deﬁnition in Section 3. Then, we investigate the property of modularity in some more de-
tail in Section 4. The issue of convergence is analyzed in Section 5 followed by a design principle
in Section 6. Safety guarantees and the connection to control barrier functions are treated in Sec-
tion 7. Then, we see how BTs are related to explainable AI in Section 8, and can be connected to
reinforcement learning in Section 9, evolutionary algorithms in Section 10 and planning in Section 11.
Finally, conclusions, together with a set of summary points and future important issues can be found
in Section 12.

2. The history of behavior trees and their relation to ﬁnite state machines

The need for a modular hierarchical control structures is shared between the domains of robotics and
computer games. However, low-level capabilities such as grasping and navigation are research areas

4

¨Ogren and Sprague

in their own right in robotics, but trivial in the virtual worlds of a computer game. Therefore, computer
game programmers started putting together larger sets of low level capabilities earlier than roboticists,
and hence experienced the drawback of ﬁnite state machines (FSMs) described below earlier as well.
BTs were thus proposed as a response to those drawbacks by programmers in the gaming industry. It is
hard to determine who was the ﬁrst to concieve BTs, as important ideas were shared in partially docu-
mented workshops, conferences and blog posts. However, important milestones were deﬁnitely passed
through the work of Michael Mateas and Andrew Stern (4), and Damian Isla (5). The development
continued in the game AI community, and a few years later the ﬁrst journal paper on BTs appeared
(6), followed by the ﬁrst papers on BTs in robotics, independently described in (7) and (8). Note that
there is also a completely different tool called behavior trees, that is used for requirement analysis1.

As mentioned above, BTs were partially developed to improve modularity of (FSM) controllers.
FSMs, and in particular hierarchical FSMs (9), do have mechanisms for hierarchical modularity. How-
ever, a key problem is that the transitions of a FSM are encoded inside the modules (states), thus each
module needs to know about the existence and capabilities of the other modules, as well as the purpose
of its own supermodule. In this way, each transition creates a dependence between two modules, and
with N modules there is N2 possible transitions/dependencies. In comparison, a BT module only has
to know if it succeeded or not. Regarding expressivity, it was shown in (10) that BTs with internal vari-
ables are equally expressive as FSMs. Thus, like with two general purpose programming languages,
the choice between the two is not governed by what is possible, but rather what makes the design
process smooth. A more detailed description of the relationship between BTs and FSM, as well as a
broad overview of research on BTs can be found in the recent survey (11) and the book (12).

3. Deﬁnition of Behavior Trees

In this section we will formally deﬁne BTs and their execution for both discrete and continuous-time
systems. This formulation is based on (13, 14, 15) and chosen to enable a control-theoretic analysis of
BTs2.

The core idea is to formally deﬁne a BT as a combination of a controller and a metadata function
used to provide feedback regarding the execution. Using the metadata, these BTs can then be combined
in order to create more complex BTs in a hierarchical tree structure, as in Figure 1, hence the name
behavior tree.

Let the system state be x
∈
f (xt , u), see Deﬁnition 2, with u

X

∈

⊂
U

Rn and the system dynamics be given by ˙x = f (x, u) or xt+1 =

Rk.

⊂

Deﬁnition 1 (Behavior tree). A BT Ti is a pair

Ti = (ui, ri)

U is the controller that runs when the BT is executing, and ri : X

1.

→

provides metadata regarding the applicability and progress of the execution.

where i is an index, ui : X
R, S , F
{

}

→

A BT can either be created through a hierarchical combination of other BTs, using the Sequence

and Fallback operators described below, or it can be deﬁned by directly specifying ui(x) and ri(x).

1A different concept with the same name: https://en.wikipedia.org/wiki/Behavior_tree
2Other BT formulations exist, including memory versions of interior nodes, and leaf nodes encapsulating the
execution of the system dynamics, thereby allowing the parallel execution of two leaves e.g., controlling different
motors on the same robot, see (13, 16).

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

5

Figure 2: The state space X is partitioned into a set of operating regions Ωi, and the global success
region S0 and failure region F0. We want to design the BT such that the state reaches S0 and avoids F0.
The solid line illustrates an execution starting in Ω1 and ending in S0. Note that the Ωi of each subtree
is not deﬁned in the subtree itself, but depends on feedback in the form of the return status ri(x) of a
number of neighboring subtrees as described in Deﬁnition 11.

The metadata ri is interpreted as follows: Running (R), Success (S ), and Failure (F ). Let the
Running region (Ri), Success region (Si) and Failure region (Fi) correspond to a partitioning3 of the
state space, deﬁned as follows:

X : ri(x) = R

∈

x
{

Ri =

, Si =

x
{
Deﬁnition 2. Assuming the BT Ti is the root, and not a subtree of another BT, and x
Ri, the system
evolves according to ˙x = f (x, ui(x)) or xt+1 = f (xt , ui(x)) depending on if the system is continuous
time or discrete time.

, Fi =

x
{

.
}

∈

∈

∈

}

}

X : ri(x) = F

X : ri(x) = S

∈

Si

Remark 1. If x
Fi of the root BT, it has either succeeded or failed, and it is up to the user to
apply an appropriate action, such as shutting down the robot or entering an idle mode. If this is not
desired, an additional top layer of the BT can be designed that executes when the main BT returns
success or failure. If this top layer always return running, we have Si = Fi = /0 for the overall tree.

∪

The execution of a BT can thus be seen as a discontinuous dynamical system (17), as illustrated in
Figure 2. Below, in Lemma 8, we will show that if the BT T0 is composed of a set of subtrees
Ti
}
{
then the state space X is divided into different so-called operating regions Ωi such that u0(x) = ui(x)
if x
Ωi, as illustrated in Figure 2. Thus, in the continuous time case above, the execution will in
most cases be a discontinuous dynamical system with corresponding issues regarding existence and
uniqueness (18). Going deeper into these issues is beyond the scope of this paper, therefore we will
just make the following assumption.

∈

Assumption 1. The BTs Ti are deﬁned in such a way that the execution in Deﬁnition 2 has solutions
that exist and are unique.

As described above, the main point of BTs is to enable the creation of complex controllers from
simpler ones in a modular fashion. There are two ways of combining BTs, the sequence and fallback
compositions.

Deﬁnition 3. (Sequence Compositions of BTs) Two or more BTs can be composed into a more com-

3Throughout the paper we use the word partition, even though some of the sets might be empty.

6

¨Ogren and Sprague

<latexit sha1_base64="UGtDM1MOEBqV+vX2QKzx21W2Zso=">AAAB8HicbVBNS8NAEJ34WetX1aOXYBE8laSIeix68WYF+yFtKJvtpF26uwm7G6GU/govHhTx6s/x5r9x0+agrQ8GHu/NMDMvTDjTxvO+nZXVtfWNzcJWcXtnd2+/dHDY1HGqKDZozGPVDolGziQ2DDMc24lCIkKOrXB0k/mtJ1SaxfLBjBMMBBlIFjFKjJUeu3cCB6TnF3ulslfxZnCXiZ+TMuSo90pf3X5MU4HSUE607vheYoIJUYZRjtNiN9WYEDoiA+xYKolAHUxmB0/dU6v03ShWtqRxZ+rviQkRWo9FaDsFMUO96GXif14nNdFVMGEySQ1KOl8Updw1sZt97/aZQmr42BJCFbO3unRIFKHGZpSF4C++vEya1Yp/Uanen5dr13kcBTiGEzgDHy6hBrdQhwZQEPAMr/DmKOfFeXc+5q0rTj5zBH/gfP4AwYCPug==</latexit>⌦1<latexit sha1_base64="Ps4r+0WQQMt21hJrnE22Z9wZ8mY=">AAAB8XicbVBNS8NAEN34WeNX1aOXxSJ4KkkR9Vj04s0K9gPbUDbbSbt0dxN2N0IJ/RdePCji1X/jzX/jps1BWx8MPN6bYWZemHCmjed9Oyura+sbm6Utd3tnd2+/fHDY0nGqKDRpzGPVCYkGziQ0DTMcOokCIkIO7XB8k/vtJ1CaxfLBTBIIBBlKFjFKjJUee3cChqRfc91+ueJVvRnwMvELUkEFGv3yV28Q01SANJQTrbu+l5ggI8owymHq9lINCaFjMoSupZII0EE2u3iKT60ywFGsbEmDZ+rviYwIrScitJ2CmJFe9HLxP6+bmugqyJhMUgOSzhdFKccmxvn7eMAUUMMnlhCqmL0V0xFRhBobUh6Cv/jyMmnVqv5FtXZ/XqlfF3GU0DE6QWfIR5eojm5RAzURRRI9o1f05mjnxXl3PuatK04xc4T+wPn8AfoBj88=</latexit>⌦2<latexit sha1_base64="r5XSeLO6cR0LEdr9xBUMH94pldA=">AAAB7HicbVBNS8NAEJ3Urxq/qh69LBbBU0mKqMeiIB4rmLbQhrLZbtqlm03Y3Qgh9Dd48aCIV3+QN/+NmzYHbX0w8Hhvhpl5QcKZ0o7zbVXW1jc2t6rb9s7u3v5B7fCoo+JUEuqRmMeyF2BFORPU00xz2kskxVHAaTeY3hZ+94lKxWLxqLOE+hEeCxYygrWRvLuhY9vDWt1pOHOgVeKWpA4l2sPa12AUkzSiQhOOleq7TqL9HEvNCKcze5AqmmAyxWPaN1TgiCo/nx87Q2dGGaEwlqaERnP190SOI6WyKDCdEdYTtewV4n9eP9XhtZ8zkaSaCrJYFKYc6RgVn6MRk5RonhmCiWTmVkQmWGKiTT5FCO7yy6uk02y4l43mw0W9dVPGUYUTOIVzcOEKWnAPbfCAAINneIU3S1gv1rv1sWitWOXMMfyB9fkDKiCNnA==</latexit>F0<latexit sha1_base64="+AWAfsQfj2QD8M23BltK1ZilDq4=">AAAB8XicbVBNSwMxEM3Wr7p+VT16CRbBU9ktRT0WvXizgv3AdinZdLYNTbJLkhVK6b/w4kERr/4bb/4bs+0etPXBwOO9GWbmhQln2njet1NYW9/Y3Cpuuzu7e/sHpcOjlo5TRaFJYx6rTkg0cCahaZjh0EkUEBFyaIfjm8xvP4HSLJYPZpJAIMhQsohRYqz02LsTMCT9muv2S2Wv4s2BV4mfkzLK0eiXvnqDmKYCpKGcaN31vcQEU6IMoxxmbi/VkBA6JkPoWiqJAB1M5xfP8JlVBjiKlS1p8Fz9PTElQuuJCG2nIGakl71M/M/rpia6CqZMJqkBSReLopRjE+PsfTxgCqjhE0sIVczeiumIKEKNDSkLwV9+eZW0qhX/olK9r5Xr13kcRXSCTtE58tElqqNb1EBNRJFEz+gVvTnaeXHenY9Fa8HJZ47RHzifP/0Nj9E=</latexit>⌦4<latexit sha1_base64="coNOrxtOE0YglmuuLahKH0qpDJU=">AAAB8XicbVDLSgNBEOyNrxhfUY9eBoPgKewGX8egF29GMA9MljA7mU2GzMwuM7NCWPIXXjwo4tW/8ebfOJvsQRMLGoqqbrq7gpgzbVz32ymsrK6tbxQ3S1vbO7t75f2Dlo4SRWiTRDxSnQBrypmkTcMMp51YUSwCTtvB+Cbz209UaRbJBzOJqS/wULKQEWys9Ni7E3SI++elUr9ccavuDGiZeDmpQI5Gv/zVG0QkEVQawrHWXc+NjZ9iZRjhdFrqJZrGmIzxkHYtlVhQ7aezi6foxCoDFEbKljRopv6eSLHQeiIC2ymwGelFLxP/87qJCa/8lMk4MVSS+aIw4chEKHsfDZiixPCJJZgoZm9FZIQVJsaGlIXgLb68TFq1qndRrd2fVerXeRxFOIJjOAUPLqEOt9CAJhCQ8Ayv8OZo58V5dz7mrQUnnzmEP3A+fwD+k4/S</latexit>⌦5<latexit sha1_base64="zT+LV7cSb7EDFW3iUEOy1AkkKWo=">AAAB8XicbVBNSwMxEM3Wr7p+VT16CRbBU9ktYj0WvXizgv3AdinZdLYNTbJLkhVK6b/w4kERr/4bb/4bs+0etPXBwOO9GWbmhQln2njet1NYW9/Y3Cpuuzu7e/sHpcOjlo5TRaFJYx6rTkg0cCahaZjh0EkUEBFyaIfjm8xvP4HSLJYPZpJAIMhQsohRYqz02LsTMCT9muv2S2Wv4s2BV4mfkzLK0eiXvnqDmKYCpKGcaN31vcQEU6IMoxxmbi/VkBA6JkPoWiqJAB1M5xfP8JlVBjiKlS1p8Fz9PTElQuuJCG2nIGakl71M/M/rpia6CqZMJqkBSReLopRjE+PsfTxgCqjhE0sIVczeiumIKEKNDSkLwV9+eZW0qhX/slK9vyjXr/M4iugEnaJz5KMaqqNb1EBNRJFEz+gVvTnaeXHenY9Fa8HJZ47RHzifPwGuj9Q=</latexit>⌦7<latexit sha1_base64="Tw4nSNzT/17aSXn0kbhy6Em0ouM=">AAAB8nicbVBNS8NAEJ34WeNX1aOXxSJ4KkkR7bHoxZsV7AekoWy2m3bpbjbsboRS+jO8eFDEq7/Gm//GTZuDtj4YeLw3w8y8KOVMG8/7dtbWNza3tks77u7e/sFh+ei4rWWmCG0RyaXqRlhTzhLaMsxw2k0VxSLitBONb3O/80SVZjJ5NJOUhgIPExYzgo2Vgt69oEPcr7uu2y9XvKo3B1olfkEqUKDZL3/1BpJkgiaGcKx14HupCadYGUY4nbm9TNMUkzEe0sDSBAuqw+n85Bk6t8oAxVLZSgyaq78nplhoPRGR7RTYjPSyl4v/eUFm4no4ZUmaGZqQxaI448hIlP+PBkxRYvjEEkwUs7ciMsIKE2NTykPwl19eJe1a1b+q1h4uK42bIo4SnMIZXIAP19CAO2hCCwhIeIZXeHOM8+K8Ox+L1jWnmDmBP3A+fwA6Qo/p</latexit>⌦8<latexit sha1_base64="afTrxOaTXFG8nvQlfcJ71/Khmjs=">AAAB6nicbVBNS8NAEJ34WetX1aOXxSJ4KkkR9Vj04rFS+wFtKJvtpF262YTdjVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJIJr47rfztr6xubWdmGnuLu3f3BYOjpu6ThVDJssFrHqBFSj4BKbhhuBnUQhjQKB7WB8N/PbT6g0j+WjmSToR3QoecgZNVZqNPpuv1R2K+4cZJV4OSlDjnq/9NUbxCyNUBomqNZdz02Mn1FlOBM4LfZSjQllYzrErqWSRqj9bH7qlJxbZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMT3vgZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTtCF4yy+vkla14l1Vqg+X5dptHkcBTuEMLsCDa6jBPdShCQyG8Ayv8OYI58V5dz4WrWtOPnMCf+B8/gDUCY2B</latexit>S0plex BT using a Sequence operator, T0 = Sequence(T1, T2). Then r0, u0 are deﬁned as follows

If x

S1 :
∈
else :

r0(x) = r2(x), u0(x) = u2(x)
r0(x) = r1(x), u0(x) = u1(x)

2.

3.

T1 and T2 are called children of T0. Note that when executing T0, the ﬁrst child T1 in (3) is
S1). The second child of the Sequence is
S1). Finally, the Sequence itself, T0 returns
S2).

executed as long as it returns Running or Failure (xk
executed in (2), only when the ﬁrst returns Success (xk
S1
Success only when all children have succeeded (x

(cid:54)∈
∈
∩

∈

For notational convenience, we write

Sequence(T1, Sequence(T2, T3)) = Sequence(T1, T2, T3),

4.

and similarly for arbitrarily long compositions. The sequence node is also denoted by (
Figure 1.

→

), as seen in

→

Remark 2 (Giving names to sequence and fallback nodes). When drawing BTs, as in Figure 1, the
symbols
and ? are used to denote sequences and fallbacks. However, some users prefer to also give
descriptive names to the subtrees starting from each node, to improve readability. We believe this is
a useful practice, similar to choosing good names for functions when programming. Giving all nodes
names improves readability, underlines the fact that all subtrees, including single leaf nodes, have an
identical interface to its parent, see Deﬁnition 1, and is very convenient in combination with software
GUIs that enable a subtree to be visually collapsed into a single node and expanded back again.

The advantage of properly named subtrees can be seen in Figure 1. As described in the caption, the
reason for executing a leaf node is clear from the names of the subtrees it belongs to. This is discussed
further in Section 8, on explainable AI.

A key element of BTs is how the operating regions Ωi of Figure 2 depend on the success, failure
and running regions, Si, Fi, Ri of all subtrees across a hierarchical structure. Thus we need to determine
a number of properties of these sets.

Lemma 1. If T0 = Sequence(T1, T2), then Deﬁnition 3 implies that

S0 = S1

F0 = F1

∩
(cid:91)

S2,

(S1

R0 = R1

(cid:91)

(S1

F2),

R2),

∩

∩

5.

6.

7.

Proof. A straightforward application of the deﬁnition gives the result above.

Consider the Mobile Manipulator example in Figure 3, which is actually a subset of Figure 1,
where we have removed subtrees 6 and 37, and collapsed subtrees 3, 11 and 34 into single nodes. This
was done to illustrate how the modularity enables analysis to be done at different levels. The root
node, 0, is a sequence composition of subtrees 1 and 9. Equation (2) now states that Make sure top
level goals are achieved (0) executes Make sure object at goal (9), u0(x) = u9(x), only when Make sure
in safe area (0) returns success, x
S1. If that is not the case, node 1 will be executed, u0(x) = u1(x).
Similarly, Equation (6), implies that node 0 returns failure when either node 1 returns failure (no way
to reach the safe area), or when node 1 returns success and node 9 returns failure (in safe area, but no
way to get object to goal).

∈

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

7

Figure 3: This mobile manipulator BT is a subset of the one in Figure 1, with the overall objective of
moving a given object to a designated goal area, while staying in the safe part of the working area. All
nodes are numbered with the index of the corresponding subtree. The sequence nodes 0, 3, 11, 34 are
denoted by a (
) symbol and the fallback nodes 1, 9 by a (?). Conditions are indicated by ovals. Note
that the children of nodes 3, 11, 34 are not shown in this ﬁgure.

→

Deﬁnition 4. (Fallback Compositions of BTs) Two or more BTs can be composed into a more complex
BT using a Fallback operator, T0 = Fallback(T1, T2). Then r0, u0 are deﬁned as follows

If x

F1 :
∈
else :

r0(x) = r2(x), u0(x) = u2(x)
r0(x) = r1(x), u0(x) = u1(x)

8.

9.

Note that when executing the new BT, T0 ﬁrst keeps executing its ﬁrst child T1, in (9) as long as
F1). The second child of the Fallback is executed in (8), only when
F1). Finally, the Fallback itself T0 returns Failure only when all children

(cid:54)∈

it returns Running or Success (x
the ﬁrst returns Failure (x
∈
have been tried, but failed (x

F1

F2), hence the name Fallback.

For notational convenience, we write

∈

∩

Fallback(T1, Fallback(T2, T3)) = Fallback(T1, T2, T3),

10.

and similarly for arbitrarily long compositions. The fallback node is also denoted by (?), as seen in
Figure 3.

Lemma 2. If T0 = Fallback(T1, T2), then Deﬁnition 4 implies that

S0 = S1

(cid:91)

(F1

S2),

∩

F0 = F1

R0 = R1

F2,

∩
(cid:91)

(F1

R2),

∩

11.

12.

13.

Proof. A straightforward application of the deﬁnition gives the result above.

Deﬁnition 5 (Condition). If a BT Ti is such that Ri = /0 we call it a Condition. Being a BT, it still has
ui deﬁned, but as we will see in Lemma 8 below, that control will not be executed.

Consider again the Mobile Manipulator example in Figure 3. Make sure in safe area (1) is a
fallback composition of nodes 2, 3. Equation (8) now states that node 1 executes Move to safe area
if possible (3), u1(x) = u3(x), only when In Safe Area (2) returns failure, x
F2. Furthermore, node
∈
S2 and success will be returned by node 1 up to
2 is a condition, R2 = /0, thus if x

F2 we have x

(cid:54)∈

∈

8

¨Ogren and Sprague

Object at Goal (10)—>Place Object at Goal if Possible (11)? Make sure in safe area (1)?Make Sure Object at Goal (9)In Safe Area (2)—> Make sure top level goals are achieved (0)—>Move to Safe Area if Possible (3)—>Ask other Agent to Place Object if Possible (34)node 0 which would then execute Make sure object at goal (9) and so on. Furthermore, Equation (12)
indicates that the only way for node 1 to fail is if both node 2 and node 3 fails. That is Make sure in
safe area (1) only returns failure if both In safe area (2) and Move to safe area if possible (3) return
failure.

Now we have all we need to create and execute BTs.

In the next section we will explore the
modularity of BTs, and then analyze under what circumstances the execution will converge to the
success region.

4. Optimal Modularity

One of the key advantages of BTs is their modularity, a property made possible by the fact that all
subtrees on all levels of a BT have the same interface, given by Deﬁnition 1. However, as was shown
in (19), a deeper analysis can be made, by extending a measure of modularity/complexity used in graph
theory. In this section we give a very brief overview of the key theoretical results, showing that BTs
have a so-called cyclomatic complexity of one, a fact that makes them optimally modular, within a
particular class of control structures.

Figure 4: A BT (top right) with its corresponding DS (top left), and the module decomposition of
the DS (bottom). Note how all graphs in the decomposition correspond to paths without cycles. By
Theorem 2 all BTs will give rise to DSs with such non-cyclic graphs, a fact that results in all BTs
having a cyclomatic complexity of one.

To investigate the concept of modularity in general reactive control architectures, so-called Deci-
sion Structures (DS) were deﬁned in (19). These are directed graphs, as illustrated in the upper left
part of Figure 4. Each node in this structure corresponds to a controller ui, and each edge label corre-
sponds to a return status ri that can be returned by the node the arc is leaving. The DS is executed in
the following way: starting at the source node, (a) in Figure 4 (top left), look at the return status ri(x)
of that node, and follow the edge (if there is one) with a label corresponding to ri(x). Similarly, the

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

9

aFScbeFdSfSghFFSSiSF—>—>?aibdcefgh—>??—>aFSibdceSfFgFFShSFSreturn status of the new node is checked and the corresponding edge is followed until you ﬁnd a ri(x)
without a corresponding outgoing edge label. Then this controller ui is chosen. This process is then
constantly iterated from the source to keep track of the proper controller to run.

Given the above it can be seen in Figure 4 that the execution of the DS on the upper left is identical
to the execution of the BT in the upper right. Thus, this DS is equivalent to the BT. In fact, DSs are
generalizations of BTs in the sense that all BTs can be written as a DS, but not all DSs can be written
as BTs. DSs are fairly general, as the label set can be of any size, as long as it is ﬁnite. Thus a DS
is very similar to a FSM, with the difference that a DS constantly starts from the source in order to
determine what controller to execute.

Using inspiration from modules in graph theory (20), the authors of (19) deﬁne modules in DS as

follows.

Deﬁnition 6 (Deﬁnition 6.3 in (19), Modules in decision structures). Let Z be a decision structure.
N(Z) be a subset of the nodes where Z[Y ] is also a decision structure. We say Y is a module if
Let Y
⊂
Y , any arc from v into Y goes to Y ’s source, and if there is an arc labelled r
for every node v
Y the r out of y exists and goes either to v or to another element of Y .
out of Y to v, then for every y

N(Z)

∈

\

∈

After that they deﬁne quotient DS, where the modules are collapsed into single nodes.

Lemma 3 (Lemma 6.8 in (19)). Let Z be a decision structure and P a modular partition. Then the
quotient Z/P is also a decision structure. Moreover, if P is maximal then Z/P is prime.

Given these, a maximal module decomposition is deﬁned (the interested reader is referred to (19))

leading to the following theorem.

Theorem 1 (Theorem 6.15 in (19)). Let Z be a decision structure with k distinct arc labels. Then Z is
structurally equivalent to a k-BT if and only if every quotient graph in Z’s module decomposition is a
path.

Proof. See (19).

Here, a k-BT is a generalization of BTs having a label set of size k, with 2-BTs corresponding
to normal BTs, counting the labels success and failure, but not running since it does not lead to a
transition in the DS. The k-BT also has k different interior nodes, a generalization of the two nodes
Sequence and Fallback, deﬁned for 2-BTs.

This theorem is clearly illustrated in Figure 4, where we can see that there are no cycles in the
module decomposition of the DS. The number of cycles has been shown to be correlated with the dif-
ﬁculty of testing and debugging a piece of code (21). Therefore, the concept of cyclomatic complexity
has been deﬁned for graphs and the authors of (19) extend it to DSs as follows:

Deﬁnition 7 (Deﬁnition 6.19 in (19)). Let Z be a decision structure. The cyclomatic complexity of Z
is the number of linearly independent undirected cycles in Z, plus one.

Then, the concept is extended to account for modularity.

Deﬁnition 8 (Deﬁnition 6.21 in (19)). Let Z be a decision structure. The essential complexity of Z is
the maximum cyclomatic complexity of any quotient graph in its module decomposition.

Finally they prove the following theorem.

Theorem 2 (Theorem 6.23 in (19)). Let Z be a decision structure with k distinct edge labels. Z is
equivalent to a k-BT if and only if it has essential complexity 1.

10

¨Ogren and Sprague

Proof. See (19).

Looking at the case of k = 2 (two distinct edge labels, S and F), the theorem says that BTs are
exactly the DSs with essential complexity 1. Thus, BTs correspond to the class of optimally modular
DSs.

5. Proving convergence

Many control problems are formulated in terms of making some equilibrium point stable, such that a
wide set of state trajectories starting from different states all converge to that equilibrium point. For
BTs we do not pick some particular equilibrium point, but instead assume that the success region of
the root, S0 is chosen to capture the set of desired outcomes, and therefore we also assume that the
design objective is to make a large set of state trajectories converge to points inside S0. Thus, in this
section we will study the problem of when we can guarantee that the state will end up in S0.

The main result is a general convergence proof for BTs, Theorem 3, including a few examples. We
will try to make use of the modularity of BTs, in the sense that the result can be applied at all levels of
abstractions, either treating an entire subtree as a single entity as in Figure 3, or in terms of its parts,
as in Figure 1.

The idea behind the proof is straightforward, and illustrated in Figure 5. As in Figure 2, the state
space is partitioned into operating regions, Ωi, and overall failure and success regions, F0, S0, while the
arrows indicate possible transitions between these sets. If all transitions from some Ωi are to either S0
or Ω j, j > i, and the state never stays indeﬁnitely in Ωi, it will eventually reach S0. Note that a similar
analysis can be done at several different levels of abstraction. If Ω6 = Ω4
Ω5 the analysis can either
be done considering Ω4, Ω5 separately as in Figure 5(a), or together, as in Figure 5(b).

∪

(a)

(b)

Figure 5: The idea behind Theorem 3. If the state only transits between sets connected by arrows, and
never stays indeﬁnitely in any Ωi, it will eventually reach S0.

5.1. The general result

The sets Ωi are deﬁned below, and correspond to the regions where ui is running, see Lemma 8. But,
in order to deﬁne Ωi, we ﬁrst need to deﬁne the inﬂuence regions Ii, the parts of the state space where a
change of Ti might alter u0, and to deﬁne Ii we need notation for parents and older siblings of a node.
Some of these results are taken from (13, 14, 15).

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

11

<latexit sha1_base64="UGtDM1MOEBqV+vX2QKzx21W2Zso=">AAAB8HicbVBNS8NAEJ34WetX1aOXYBE8laSIeix68WYF+yFtKJvtpF26uwm7G6GU/govHhTx6s/x5r9x0+agrQ8GHu/NMDMvTDjTxvO+nZXVtfWNzcJWcXtnd2+/dHDY1HGqKDZozGPVDolGziQ2DDMc24lCIkKOrXB0k/mtJ1SaxfLBjBMMBBlIFjFKjJUeu3cCB6TnF3ulslfxZnCXiZ+TMuSo90pf3X5MU4HSUE607vheYoIJUYZRjtNiN9WYEDoiA+xYKolAHUxmB0/dU6v03ShWtqRxZ+rviQkRWo9FaDsFMUO96GXif14nNdFVMGEySQ1KOl8Updw1sZt97/aZQmr42BJCFbO3unRIFKHGZpSF4C++vEya1Yp/Uanen5dr13kcBTiGEzgDHy6hBrdQhwZQEPAMr/DmKOfFeXc+5q0rTj5zBH/gfP4AwYCPug==</latexit>⌦1<latexit sha1_base64="Ps4r+0WQQMt21hJrnE22Z9wZ8mY=">AAAB8XicbVBNS8NAEN34WeNX1aOXxSJ4KkkR9Vj04s0K9gPbUDbbSbt0dxN2N0IJ/RdePCji1X/jzX/jps1BWx8MPN6bYWZemHCmjed9Oyura+sbm6Utd3tnd2+/fHDY0nGqKDRpzGPVCYkGziQ0DTMcOokCIkIO7XB8k/vtJ1CaxfLBTBIIBBlKFjFKjJUee3cChqRfc91+ueJVvRnwMvELUkEFGv3yV28Q01SANJQTrbu+l5ggI8owymHq9lINCaFjMoSupZII0EE2u3iKT60ywFGsbEmDZ+rviYwIrScitJ2CmJFe9HLxP6+bmugqyJhMUgOSzhdFKccmxvn7eMAUUMMnlhCqmL0V0xFRhBobUh6Cv/jyMmnVqv5FtXZ/XqlfF3GU0DE6QWfIR5eojm5RAzURRRI9o1f05mjnxXl3PuatK04xc4T+wPn8AfoBj88=</latexit>⌦2<latexit sha1_base64="r5XSeLO6cR0LEdr9xBUMH94pldA=">AAAB7HicbVBNS8NAEJ3Urxq/qh69LBbBU0mKqMeiIB4rmLbQhrLZbtqlm03Y3Qgh9Dd48aCIV3+QN/+NmzYHbX0w8Hhvhpl5QcKZ0o7zbVXW1jc2t6rb9s7u3v5B7fCoo+JUEuqRmMeyF2BFORPU00xz2kskxVHAaTeY3hZ+94lKxWLxqLOE+hEeCxYygrWRvLuhY9vDWt1pOHOgVeKWpA4l2sPa12AUkzSiQhOOleq7TqL9HEvNCKcze5AqmmAyxWPaN1TgiCo/nx87Q2dGGaEwlqaERnP190SOI6WyKDCdEdYTtewV4n9eP9XhtZ8zkaSaCrJYFKYc6RgVn6MRk5RonhmCiWTmVkQmWGKiTT5FCO7yy6uk02y4l43mw0W9dVPGUYUTOIVzcOEKWnAPbfCAAINneIU3S1gv1rv1sWitWOXMMfyB9fkDKiCNnA==</latexit>F0<latexit sha1_base64="+AWAfsQfj2QD8M23BltK1ZilDq4=">AAAB8XicbVBNSwMxEM3Wr7p+VT16CRbBU9ktRT0WvXizgv3AdinZdLYNTbJLkhVK6b/w4kERr/4bb/4bs+0etPXBwOO9GWbmhQln2njet1NYW9/Y3Cpuuzu7e/sHpcOjlo5TRaFJYx6rTkg0cCahaZjh0EkUEBFyaIfjm8xvP4HSLJYPZpJAIMhQsohRYqz02LsTMCT9muv2S2Wv4s2BV4mfkzLK0eiXvnqDmKYCpKGcaN31vcQEU6IMoxxmbi/VkBA6JkPoWiqJAB1M5xfP8JlVBjiKlS1p8Fz9PTElQuuJCG2nIGakl71M/M/rpia6CqZMJqkBSReLopRjE+PsfTxgCqjhE0sIVczeiumIKEKNDSkLwV9+eZW0qhX/olK9r5Xr13kcRXSCTtE58tElqqNb1EBNRJFEz+gVvTnaeXHenY9Fa8HJZ47RHzifP/0Nj9E=</latexit>⌦4<latexit sha1_base64="coNOrxtOE0YglmuuLahKH0qpDJU=">AAAB8XicbVDLSgNBEOyNrxhfUY9eBoPgKewGX8egF29GMA9MljA7mU2GzMwuM7NCWPIXXjwo4tW/8ebfOJvsQRMLGoqqbrq7gpgzbVz32ymsrK6tbxQ3S1vbO7t75f2Dlo4SRWiTRDxSnQBrypmkTcMMp51YUSwCTtvB+Cbz209UaRbJBzOJqS/wULKQEWys9Ni7E3SI++elUr9ccavuDGiZeDmpQI5Gv/zVG0QkEVQawrHWXc+NjZ9iZRjhdFrqJZrGmIzxkHYtlVhQ7aezi6foxCoDFEbKljRopv6eSLHQeiIC2ymwGelFLxP/87qJCa/8lMk4MVSS+aIw4chEKHsfDZiixPCJJZgoZm9FZIQVJsaGlIXgLb68TFq1qndRrd2fVerXeRxFOIJjOAUPLqEOt9CAJhCQ8Ayv8OZo58V5dz7mrQUnnzmEP3A+fwD+k4/S</latexit>⌦5<latexit sha1_base64="zT+LV7cSb7EDFW3iUEOy1AkkKWo=">AAAB8XicbVBNSwMxEM3Wr7p+VT16CRbBU9ktYj0WvXizgv3AdinZdLYNTbJLkhVK6b/w4kERr/4bb/4bs+0etPXBwOO9GWbmhQln2njet1NYW9/Y3Cpuuzu7e/sHpcOjlo5TRaFJYx6rTkg0cCahaZjh0EkUEBFyaIfjm8xvP4HSLJYPZpJAIMhQsohRYqz02LsTMCT9muv2S2Wv4s2BV4mfkzLK0eiXvnqDmKYCpKGcaN31vcQEU6IMoxxmbi/VkBA6JkPoWiqJAB1M5xfP8JlVBjiKlS1p8Fz9PTElQuuJCG2nIGakl71M/M/rpia6CqZMJqkBSReLopRjE+PsfTxgCqjhE0sIVczeiumIKEKNDSkLwV9+eZW0qhX/slK9vyjXr/M4iugEnaJz5KMaqqNb1EBNRJFEz+gVvTnaeXHenY9Fa8HJZ47RHzifPwGuj9Q=</latexit>⌦7<latexit sha1_base64="Tw4nSNzT/17aSXn0kbhy6Em0ouM=">AAAB8nicbVBNS8NAEJ34WeNX1aOXxSJ4KkkR7bHoxZsV7AekoWy2m3bpbjbsboRS+jO8eFDEq7/Gm//GTZuDtj4YeLw3w8y8KOVMG8/7dtbWNza3tks77u7e/sFh+ei4rWWmCG0RyaXqRlhTzhLaMsxw2k0VxSLitBONb3O/80SVZjJ5NJOUhgIPExYzgo2Vgt69oEPcr7uu2y9XvKo3B1olfkEqUKDZL3/1BpJkgiaGcKx14HupCadYGUY4nbm9TNMUkzEe0sDSBAuqw+n85Bk6t8oAxVLZSgyaq78nplhoPRGR7RTYjPSyl4v/eUFm4no4ZUmaGZqQxaI448hIlP+PBkxRYvjEEkwUs7ciMsIKE2NTykPwl19eJe1a1b+q1h4uK42bIo4SnMIZXIAP19CAO2hCCwhIeIZXeHOM8+K8Ox+L1jWnmDmBP3A+fwA6Qo/p</latexit>⌦8<latexit sha1_base64="afTrxOaTXFG8nvQlfcJ71/Khmjs=">AAAB6nicbVBNS8NAEJ34WetX1aOXxSJ4KkkR9Vj04rFS+wFtKJvtpF262YTdjVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJIJr47rfztr6xubWdmGnuLu3f3BYOjpu6ThVDJssFrHqBFSj4BKbhhuBnUQhjQKB7WB8N/PbT6g0j+WjmSToR3QoecgZNVZqNPpuv1R2K+4cZJV4OSlDjnq/9NUbxCyNUBomqNZdz02Mn1FlOBM4LfZSjQllYzrErqWSRqj9bH7qlJxbZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMT3vgZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTtCF4yy+vkla14l1Vqg+X5dptHkcBTuEMLsCDa6jBPdShCQyG8Ayv8OYI58V5dz4WrWtOPnMCf+B8/gDUCY2B</latexit>S0<latexit sha1_base64="UGtDM1MOEBqV+vX2QKzx21W2Zso=">AAAB8HicbVBNS8NAEJ34WetX1aOXYBE8laSIeix68WYF+yFtKJvtpF26uwm7G6GU/govHhTx6s/x5r9x0+agrQ8GHu/NMDMvTDjTxvO+nZXVtfWNzcJWcXtnd2+/dHDY1HGqKDZozGPVDolGziQ2DDMc24lCIkKOrXB0k/mtJ1SaxfLBjBMMBBlIFjFKjJUeu3cCB6TnF3ulslfxZnCXiZ+TMuSo90pf3X5MU4HSUE607vheYoIJUYZRjtNiN9WYEDoiA+xYKolAHUxmB0/dU6v03ShWtqRxZ+rviQkRWo9FaDsFMUO96GXif14nNdFVMGEySQ1KOl8Updw1sZt97/aZQmr42BJCFbO3unRIFKHGZpSF4C++vEya1Yp/Uanen5dr13kcBTiGEzgDHy6hBrdQhwZQEPAMr/DmKOfFeXc+5q0rTj5zBH/gfP4AwYCPug==</latexit>⌦1<latexit sha1_base64="Ps4r+0WQQMt21hJrnE22Z9wZ8mY=">AAAB8XicbVBNS8NAEN34WeNX1aOXxSJ4KkkR9Vj04s0K9gPbUDbbSbt0dxN2N0IJ/RdePCji1X/jzX/jps1BWx8MPN6bYWZemHCmjed9Oyura+sbm6Utd3tnd2+/fHDY0nGqKDRpzGPVCYkGziQ0DTMcOokCIkIO7XB8k/vtJ1CaxfLBTBIIBBlKFjFKjJUee3cChqRfc91+ueJVvRnwMvELUkEFGv3yV28Q01SANJQTrbu+l5ggI8owymHq9lINCaFjMoSupZII0EE2u3iKT60ywFGsbEmDZ+rviYwIrScitJ2CmJFe9HLxP6+bmugqyJhMUgOSzhdFKccmxvn7eMAUUMMnlhCqmL0V0xFRhBobUh6Cv/jyMmnVqv5FtXZ/XqlfF3GU0DE6QWfIR5eojm5RAzURRRI9o1f05mjnxXl3PuatK04xc4T+wPn8AfoBj88=</latexit>⌦2<latexit sha1_base64="r5XSeLO6cR0LEdr9xBUMH94pldA=">AAAB7HicbVBNS8NAEJ3Urxq/qh69LBbBU0mKqMeiIB4rmLbQhrLZbtqlm03Y3Qgh9Dd48aCIV3+QN/+NmzYHbX0w8Hhvhpl5QcKZ0o7zbVXW1jc2t6rb9s7u3v5B7fCoo+JUEuqRmMeyF2BFORPU00xz2kskxVHAaTeY3hZ+94lKxWLxqLOE+hEeCxYygrWRvLuhY9vDWt1pOHOgVeKWpA4l2sPa12AUkzSiQhOOleq7TqL9HEvNCKcze5AqmmAyxWPaN1TgiCo/nx87Q2dGGaEwlqaERnP190SOI6WyKDCdEdYTtewV4n9eP9XhtZ8zkaSaCrJYFKYc6RgVn6MRk5RonhmCiWTmVkQmWGKiTT5FCO7yy6uk02y4l43mw0W9dVPGUYUTOIVzcOEKWnAPbfCAAINneIU3S1gv1rv1sWitWOXMMfyB9fkDKiCNnA==</latexit>F0<latexit sha1_base64="zT+LV7cSb7EDFW3iUEOy1AkkKWo=">AAAB8XicbVBNSwMxEM3Wr7p+VT16CRbBU9ktYj0WvXizgv3AdinZdLYNTbJLkhVK6b/w4kERr/4bb/4bs+0etPXBwOO9GWbmhQln2njet1NYW9/Y3Cpuuzu7e/sHpcOjlo5TRaFJYx6rTkg0cCahaZjh0EkUEBFyaIfjm8xvP4HSLJYPZpJAIMhQsohRYqz02LsTMCT9muv2S2Wv4s2BV4mfkzLK0eiXvnqDmKYCpKGcaN31vcQEU6IMoxxmbi/VkBA6JkPoWiqJAB1M5xfP8JlVBjiKlS1p8Fz9PTElQuuJCG2nIGakl71M/M/rpia6CqZMJqkBSReLopRjE+PsfTxgCqjhE0sIVczeiumIKEKNDSkLwV9+eZW0qhX/slK9vyjXr/M4iugEnaJz5KMaqqNb1EBNRJFEz+gVvTnaeXHenY9Fa8HJZ47RHzifPwGuj9Q=</latexit>⌦7<latexit sha1_base64="Tw4nSNzT/17aSXn0kbhy6Em0ouM=">AAAB8nicbVBNS8NAEJ34WeNX1aOXxSJ4KkkR7bHoxZsV7AekoWy2m3bpbjbsboRS+jO8eFDEq7/Gm//GTZuDtj4YeLw3w8y8KOVMG8/7dtbWNza3tks77u7e/sFh+ei4rWWmCG0RyaXqRlhTzhLaMsxw2k0VxSLitBONb3O/80SVZjJ5NJOUhgIPExYzgo2Vgt69oEPcr7uu2y9XvKo3B1olfkEqUKDZL3/1BpJkgiaGcKx14HupCadYGUY4nbm9TNMUkzEe0sDSBAuqw+n85Bk6t8oAxVLZSgyaq78nplhoPRGR7RTYjPSyl4v/eUFm4no4ZUmaGZqQxaI448hIlP+PBkxRYvjEEkwUs7ciMsIKE2NTykPwl19eJe1a1b+q1h4uK42bIo4SnMIZXIAP19CAO2hCCwhIeIZXeHOM8+K8Ox+L1jWnmDmBP3A+fwA6Qo/p</latexit>⌦8<latexit sha1_base64="afTrxOaTXFG8nvQlfcJ71/Khmjs=">AAAB6nicbVBNS8NAEJ34WetX1aOXxSJ4KkkR9Vj04rFS+wFtKJvtpF262YTdjVBCf4IXD4p49Rd589+4bXPQ1gcDj/dmmJkXJIJr47rfztr6xubWdmGnuLu3f3BYOjpu6ThVDJssFrHqBFSj4BKbhhuBnUQhjQKB7WB8N/PbT6g0j+WjmSToR3QoecgZNVZqNPpuv1R2K+4cZJV4OSlDjnq/9NUbxCyNUBomqNZdz02Mn1FlOBM4LfZSjQllYzrErqWSRqj9bH7qlJxbZUDCWNmShszV3xMZjbSeRIHtjKgZ6WVvJv7ndVMT3vgZl0lqULLFojAVxMRk9jcZcIXMiIkllClubyVsRBVlxqZTtCF4yy+vkla14l1Vqg+X5dptHkcBTuEMLsCDa6jBPdShCQyG8Ayv8OYI58V5dz4WrWtOPnMCf+B8/gDUCY2B</latexit>S0<latexit sha1_base64="3RstHuuCfpOUFFSVUKdoyPnK9PA=">AAACE3icbVDLSsNAFJ34rPEVdelmsAjioiSlVjdC0Y07K9gHNCFMppN26OTBzEQoIf/gxl9x40IRt27c+TdO2ijaemDg3HPu5c49XsyokKb5qS0sLi2vrJbW9PWNza1tY2e3LaKEY9LCEYt410OCMBqSlqSSkW7MCQo8Rjre6DL3O3eECxqFt3IcEydAg5D6FCOpJNc4tq8DMkBuWs/gOfwuahm0cRL/1CeZruuuUTYr5gRwnlgFKYMCTdf4sPsRTgISSsyQED3LjKWTIi4pZiTT7USQGOERGpCeoiEKiHDSyU0ZPFRKH/oRVy+UcKL+nkhRIMQ48FRngORQzHq5+J/XS6R/5qQ0jBNJQjxd5CcMygjmAcE+5QRLNlYEYU7VXyEeIo6wVDHmIVizJ8+TdrVi1SvVm1q5cVHEUQL74AAcAQucgga4Ak3QAhjcg0fwDF60B+1Je9Xepq0LWjGzB/5Ae/8C7ZecSA==</latexit>⌦6=⌦4[⌦5Deﬁnition 9 (parent and big brother of a node). Given a node i, let p(i) be the parent of the node and
b(i) be the closest sibling to the left (the big brother) of the node.

Note that p(i) is undeﬁned if i is the root, and b(i) is undeﬁned if there is no sibling to the left.

Deﬁnition 10 (Inﬂuence region). The Inﬂuence Region Ii of node i is deﬁned as follows

Ii = X
Ii = Ip(i)
Ii = Ib(i) ∩
Ii = Ib(i) ∩

Sb(i)
Fb(i)

If i is the root

If i is the leftmost sibling and

If p(i) is a Sequence and

If p(i) is a Fallback and

p(i)

∃

b(i)

∃

b(i)

∃

14.

15.

16.

17.

Note that the inﬂuence region Ii is the part of the state space where the design of Ti = (ui, ri)
inﬂuences the execution of T0. Also note that Ii is fundamentally different from Si, Fi, Ri in the sense
that Ii depends entirely on the part of T0 that is outside Ti, the parent and siblings, while, on the other
hand Si, Fi, Ri depends entirely on what is inside Ti itself, ui(x).

Lemma 4. If x

(cid:54)∈

Ii then changing the implementation of ui, ri will not change the value of u0(x).

Ii we have x

Ri, then u0(x) = ui(x). To maximize
Proof. We will use Lemma 8 below, that shows that if x
the inﬂuence of ui, ri we change ri(x) to always return running, making Ri = X and Ωi = Ii. However,
if x

Ωi and another subtree is still controlling the execution.

(cid:54)∈
As seen above, Ii depends on external factors and Si, Fi, Ri depends on internal factors. We will
ui(x) and ri(x) = R, that is the region where

Ωi = Ii

∈

∩

(cid:54)∈

now deﬁne Ωi such that Ωi is the region where u0(x)
Ti is controlling the execution.

≡

Deﬁnition 11 (Operating region). The Operating Region Ωi of node i is deﬁned as follows

Lemma 5. For a given node j, the operating regions of the children is a partitioning of Ω j, that is

Ωi = Ii

Ri

∩

18.

(cid:91)

Ωi = Ω j,

i:p(i)= j

Ωi

∩

Ωk = /0,

i, k : i

∀

= k, p(i) = p(k)

19.

20.

Proof. Let the parent index be 0 and the two children indices be 1 and 2. We need to show that
this holds for both Sequence and Fallback compositions. If the parent node is a Sequence we have
R2). For the inﬂuence regions, assume that I0 is given, which gives I1 = I0 and
that R0 = R1
I2 = I1

∩
S1. Thus we have

S1 = I0

(cid:83)(S1

∩

∩

Ω0 = I0

Ω1 = I1
Ω2 = I2

R0 = I0

R1 = I0
R2 = I0

∩

∩

∩

∩

∩

∩

(R1

(cid:91)

(S1

R2))

∩

R1
S1

R2

∩

21.

22.

23.

This gives Ω1
S1
(I0

∩
R2) = I0

Ω2 = I0
(R1

R1
∩
(S1

I0

S1
∩
∩
R2)) = I0

R2 = /0, since R1
R0 = Ω0.

∩

∩

∩

∩

∩
∪

∩

S1 = /0. Furthermore, Ω1

Ω2 = (I0

R1)

∪

∩

∪

∩

12

¨Ogren and Sprague

(cid:54)
Similarly, if the parent node is a Fallback we have that R0 = R1

regions, assume that I0 is given, which gives I1 = I0 and I2 = I1

F1 = I0

R2). For the inﬂuence

∩
F1. Thus we have

(cid:83)(F1

∩

∩
R2))

∩

Ω0 = I0

R0 = I0

(R1

(cid:91)

(F1

∩

∩

Ω1 = I1
Ω2 = I2

R1 = I0
R2 = I0

∩

∩

R1
F1

R2

∩

∩
∩
R2 = /0, since R1
R0 = Ω0.

∩

24.

25.

26.

This gives Ω1
F1
(I0

∩
R2) = I0

Ω2 = I0
∩
(R1
∪

∩

R1
∩
(F1

∩

I0

F1
∩
∩
R2)) = I0

∩

∩

∩

F1 = /0. Furthermore, Ω1

Ω2 = (I0

R1)

∪

∩

∪

Lemma 6. For a given subtree, the operating regions of the leaves is a partitioning of the operating
region of the root.

Proof. A recursive application of Lemma 5.

As described above, we want to enable the convergence analysis to be done at different levels of

abstraction, as illustrated in Figure 5. Thus we make the following deﬁnition.

Deﬁnition 12. A level of abstraction L

is a set of indices such that

0, 1, 2, . . .
}
S0

Ωi

(cid:91)

⊂ {
X =

F0,

∪

27.

∪

and Ωi

Ω j = /0,

= j

i
∀

∈

L.

∩

L

i
∈

{

indices of leaves
}
R0 = X

Lemma 7. The root is one level of abstraction, with L =
abstraction with L =

.

and all the leaves is another level of

0
}

{

Proof. For the root we have Ω0 = I0
F0 = R0
S0
∪
X. If it holds for the root it must also hold for the leaves, since (cid:83)
L Ωi = Ω0 by Lemma 6.
i
∈
Lemma 8. If Ti is a subtree of T0, then x
executed while inside Ωi

L Ωi
∈

R0 = R0 this makes (cid:83)
i

Ωi, implies that u0(x) = ui(x), that is controller i is

F0 =

S0

∪

∩

∪

∈

∩

∪

∩

Ωi

R0 = R0. We will now show that if it holds for a parent, it
Proof. It holds for the root since Ω0 = I0
will also hold for a child. Assume it holds for the parent j = p(i). It remains to show that u j(x) = ui(x).
We know that x
Fi
which gives u j(x) = ui(x) by equation (2) and (8). Assume the parent is a Sequence node. If j is not
Sb(i) which gives u j(x) = ui(x) by Equation (3) and (16).
the leftmost child then x
Conversely, assume the parent is a Fallback node. If j is not the leftmost child then x
Ii implies
x

Fb(i) which gives u j(x) = ui(x) by Equation (9) and (17).

Ri. If j is the leftmost child then x

Ω j and Ωi = Ii

Ri implies x

Ii implies x

Si

⊂

∈

∈

(cid:54)∈

∈

∩

∪

∈

∈

∈

Given these concepts, we can now formulate our main theorem on convergence of BTs, inspired by
(22, 23, 24). The idea is that if the state moves through the operating regions Ωi in strictly increasing
order, without staying longer than τ in any region, and the only other allowed region is S0, then the
system will reach S0 in ﬁnite time. Formally, we write
Theorem 3 (Convergence of BTs). Given a BT, an external constraint region ¯C
invariant, and a level of abstraction L. If there exists a re-labelling of the N nodes in L such that

X that is to be kept

⊂

Ci = (cid:0)(cid:0) (cid:91)
L, j

j

i
≥

∈

(cid:1)

Ω j

(cid:1)

S0

¯C

∩

∪

L, and there exists a τ > 0 such that if x(t)

is invariant under ui for all i
then there exist a time t(cid:48) ≤

∈

Nτ such that if x(0)

C1, then x(t(cid:48))

S0.

∈

∈

28.

Ωi,

(cid:54)∈

Ωi then x(t + τ)

∈

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

13

(cid:54)
Proof. We have that if x(t)
Ω j, j > i or x(t + τ)
most time Nτ.

∈

∈

Ωi then x(t + τ)

Ωi, but Ci is invariant under ui, so either x(t + τ)

S0. Thus there can be at most N transitions before x(t)

(cid:54)∈

∈
S0, in total taking at

∈

By saying that a set B

X is invariant under ui we mean that if x(0)

B and ˙x = f (x, ui(x)), then

B for all t > 0, and similarly for discrete time executions with xt+1 = f (xt , ui(x)).

⊂

∈

x(t)

∈

Remark 3. Note that the challenge in proving convergence for BTs now lies in choosing a level of
abstraction, re-ordering the nodes in L, and designing ui such that Ci is invariant and x(t + τ)

Ωi.

(cid:54)∈

Remark 4. The purpose of the external constraint region ¯C is to enable separate analysis of a BT that
is then being used as a subtree of another BT. It this is not needed, set ¯C = X.

The deterministic analysis above can be complemented with a probabilistic result from (25).

the execution of Deﬁnition 2 was replaced by non-
Lemma 9 (Probabilistic transitions).
deterministric transitions, and the controllers ui are such that undesired transitions, from an Ωi to
pi < 1, then the expected number of
an Ω j with j < i, happen with a probability 1
N/pN , and the probability of reaching the
transitions T before reaching S0 is bounded above, E(T )
goal with at most k transitions is Pk = 1

pN , which makes P∞ = 1.

≤
γ k+1, with γ = 1

pi, with 0 < p

−

≤

If

−

−

Proof. See (25).

The Lemma above can be interpreted in two ways. Either for nondeterministic executions, as
stated in the Lemma, or for deterministic executions, where an un-modeled external agent moves
things around, thereby causing a ﬁnite set of jumps in the state. Also note that the expected number of
transitions gives an upper bound on the expected convergence time of τN/pN .

5.2. Three examples

We will now apply Theorem 3, to the sequence of desired goals in Figure 6(a), a fallback of actions
where each one is designed to satisfy the preconditions of the one to the left in Figure 6(b) and the
more complex mobile manipulation BT from Figure 1. The resulting sets are shown in Table 1. As
can be seen, the sets Ci to be kept invariant are often not that complex, and creating controllers ui to
satisfy them is is often reasonable.

(a)

(b)

Figure 6: Two examples to apply Theorem 3 on. Note that the index labels on the nodes are going
from left to right for the sequence, and right to left for the fallback. This is a result of the re-labeling
that is done when applying Theorem 3.

14

¨Ogren and Sprague

—>Satisfy all goalsMake sure in safe area (1)Make sure object at goal (2)Make sure robot at charger (3)?Make sure object at goalObject at goal (3)—> Place object if possible (2)Get object (1)Holding objectPlace object at goalLemma 10 (Standard sequence). If T0 = Sequence(T1, . . . , TN ), we have

Ii =

Ωi =

(cid:92)

j<i
(cid:92)

S j

S j

j<i
(cid:92)

Ci = (

j<i

Ip(i)

∩

Ip(i) ∩

∩

Ri

S j

S0)

¯C

∩

∪

29.

30.

31.

j

(cid:84)

j<i S j. Assume x

i Ω j = (cid:84)
≥

Proof. Ii, Ωi are clear from the deﬁnition of a sequence node, only executing the next child if the
previous succeeds. From Theorem 3 we have that Ci = (cid:0)(cid:0)(cid:83)
¯C. Thus we need to show
∩
that (cid:83)
k
j < i thus
Ωk,
Ω j
∃
∀
Ωk and thus x
since Ωi is a partition of Ωp(i). Conversely, if x
∈

≥
For the next example we use the design principle implicit sequence (12, 25), where each child of a
fallback node is designed to satisfy the precondition of a sibling to its left, while not failing, see ˆCi
Ci
in Equation (34) below. Therefore, the numbering is also done from right to left as part of applying
Theorem 3.

i Ω j
∪
j < i thus x
k
∃

j<i S j then x
(cid:83)
j

S j
∈
∀
i Ω j then

i : x
∈
j<i S j.

(cid:54)∈
i : x

S0

≥
(cid:84)

≥

⊂

∈

∈

∈

≥

(cid:1)

(cid:1)

j

Lemma 11 (Implicit sequence). If T0 = Fallback(TN , . . . , T1), and forall i < N there is j > i such
that S j

Si we have that

R j

∪

⊃

Ip(i)

Ii =

Ωi =

(cid:92)

j>i
(cid:92)

Fj

Fj

j>i
ˆCi = (Ri

∪

Ci

⊃

∩

∩

Ip(i) ∩
¯C

∩

Si)

Ri

32.

33.

34.

Proof. Ii, Ωi are clear from the deﬁnition of a Fallback node, only executing the next child if the
previous fails. Furthermore, S0 = SN , since Si
From Theorem 3 we have that Ci = (cid:0)(cid:0)(cid:83)
Ri

= N, due to S j
R j
¯C. Thus we need to show that (cid:83)
j
≥
(cid:83)
j

Si for some j > i.
i Ω j
∪
i Ω j.

Ii = /0 for i
∩
(cid:1)
i Ω j

∪
∩
Fi and hence x

j
SN then x

j<i Ω j. Therefore x

SN . Assume x

SN

S0

Ri

Si

Si

⊃

(cid:83)

∪

≥

(cid:1)

⊃

∪

∪

∈

∪

∪

(cid:54)∈

∈

≥

(cid:54)∈

Using the results above we can compute the sets Ci that needs to be kept invariant by the con-
troller ui for each region Ωi. Then a table like the one in Table 1 can be created, and used as design
speciﬁcation for the ui.

Table 1 also includes the results for the more complex BT in Figure 1, with node numbers given
by a depth ﬁrst traversal of the tree. We will now see how such a BT can be created recursively from a
list of actions, with corresponding precondition and postconditions.

6. A design principle exploiting modularity and feedback

In this section we will give a concrete example on the use of hierarchical modularity and feedback in
BTs. Consider the example BT in Figure 7, designed to make sure some condition X holds. If X is
true it will immediately return success. If not, it will act to make X true, hence the name Make sure X.
Sometimes there are multiple ways of making X true, in those cases the options are collected under a
fallback node, so if one option (say Y) fails, or is not applicable, another option (say Z) can be invoked.

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

15

(cid:54)
Name

Objective

Operating region Ωi

To keep invariant Ci

Table 1: Three examples of applying Theorem 3.

Figure 6(a)
T1: Make sure in
safe area
T2: Make sure
object at goal
T3: Make sure
robot at charger

Figure 6(b)
T1 : Get object

T2 : Place object
if possible

Figure 1
T5: Move to safe
area
T8: Recharge

T19: Move to
Object

in safe area

object at goal

robot at charger

Holding object

Object at goal

in safe area

in safe area

¬

in safe area

object at goal

¬
in safe area
object at goal

robot at charger

¬

Holding object
¬
Object at goal
¬
Holding object
Object at goal

¬

in safe area

¬

Proper battery level

in safe area

Robot near object

/0

in safe area

in safe area
object at goal

/0

Holding object

/0

in safe area

in safe area
proper battery level

in safe area
proper battery level

in safe area
proper battery level
object in gripper

in safe area
proper battery level

∧

∧
∧

∧

∧

∧

∧
∧
∧
∧
∧

∧
∧
∧
∧

∧
∧
∧

∧
∧

∧

∧

∧

∧
∧

∧

proper battery level

¬
in safe area
proper battery level

object at goal
object in gripper
robot near object

¬
¬
¬
Free path to object exists
in safe area
proper battery level

object at goal
¬
object in gripper
¬
robot near object

in safe area
proper battery level

object at goal
¬
object in gripper
in safe area
proper battery level

object at goal

object at goal

¬
in safe area
proper battery level

∧
∧
¬
∧
subtree T11 returned failure
in safe area
proper battery level
object at goal

∧
∧

in safe area
∧
proper battery level
∧
subtree T11 returned failure

in safe area
proper battery level
object at goal

∧
∧

T20: Grasp ob-
ject with left arm

Object in gripper

T21: (skipped for
lack of space)
T32: Move to
goal

T33: Place object
at goal

T36: Ask other
agent to place ob-
ject

T39: Move to
charger

Robot near goal

object at goal

object at goal

robot at charger

16

¨Ogren and Sprague

Figure 7: On the left we have a basic BT for achieving some condition X by either executing action
Y or action Z. Note how the BT in Figure 1 is created by connecting eight BTs on this form. This
was done by starting with a sequence with the four top priority goals, as illustrated on the right, and
then recursively replacing (dashed lines) a leaf condition with the root of a BT achieving that very
condition. Both conditions that can be replaced, and Fallback nodes that have replaced a condition are
double stroked in this ﬁgure as well as Figure 1.

Both of Y and Z have their own preconditions, describing when they can be invoked, as illustrated in
the ﬁgure.

The key idea is now to recursively apply the design on the left of Figure 7, as illustrated on the right
of the ﬁgure. First we list four top priority goals in a sequence node. Then, instead of just checking
the conditions we can replace them with a small BT of the form to the left that tries to make them true.
The resulting BT will have some new conditions, which in turn can be replaced by small BTs and so
on. All conditions that can be replaced, or have been replaced, are marked with double strokes in both
Figure 1 and Figure 7. Note that it does not make sense to replace the single stroked conditions, such
as Check X, as these already have actions for achieving them.

This recursive approach is a good example of the hierarchical modularity made possible by BTs.
The design of Figure 7 is only about achieving X, not about why, or what will happen later. It also
illustrates the use of feedback. The BT ﬁrst checks if something needs to be done, if not everything is
ﬁne. If something needs to be done it tries to achieve it, and if one option failed, another one is applied.
A detailed analysis of the design above can be found in (14), including a discussion on when it
works and when it does not work. Here we note that applying Theorem 3 we get the sets of Table 1.
Remember that the execution is supposed to progress in increasing order of index labels, thus the table
can be read from top to bottom. Note that the sets Ci mostly correspond to not violating previously
achieved subgoals, such as in safe set and proper battery level, but when carrying the object to the goal
it also includes object in gripper. Perhaps the most surprising item is C36 for T36, including subtree
T11 returns failure. This is needed to avoid cases where one option ﬁrst fails, but during the execution
of a fallback option, the ﬁrst option is somehow activated again before it fails yet again, causing a
switching back and forth, see (14) for details.

7. Guaranteeing safety and invariance using control barrier functions

In this section we will see how Control Barrier Functions (CBFs) can sometimes be used to provide
the invariance guarantees we need in Theorem 3. Furthermore, we will see how the standard way of
using CBFs to guarantee safety appears as a special case of Theorem 3. Finally, we will see how to
handle conﬂicting objectives, as trying to keep several sets invariant might not always be possible.

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

17

? Make sure XCheck XPrecondition Y1…Precondition YNFix X by doing Y…—>Fix X by doing Z if PossiblePrecondition Z1…Precondition ZNFix X by doing Z—>Fix X by doing Y if Possible7.1. Control Barrier Functions

As seen in Section 5 above, the key aspect of Theorem 3 is for ui to keep the set Ci invariant. Fortu-
nately, keeping sets invariant is the main objective of CBFs. Below we will assume that the execution
in Deﬁnition 2 runs in continuous time, but corresponding discrete time concepts can also be created.
R such that the so-
→
. Given the continuous system dynamics

The key idea behind CBFs (26, 27) is to specify a barrier function h : X

X : h(x)

called safe set C is characterized by: C =
˙x = fC(x, u), if we choose controls u

x
{
Uinv where

∈

0
}

≥

∈
Uinv = (cid:8)u

U :

∈

dh
dx

fC(x, u)

α(h(x))(cid:9),

≥ −

35.

and α

∈

K is a class K functions (26), we are guaranteed to stay in the safe set x

C .

∈

7.2. Guaranteeing safety and handling conﬂicting objectives

Guaranteeing safety is often of highest priority. In this section we will see how we can use CBF to
address the invariance property of Theorem 3, in a way that includes safety guarantees as a special
case, as described in (28).

Since we need the conditions Ci to be invariant, we ﬁrst make the following assumption:

Assumption 2. Each condition Ci : X
(35), as follows

0, 1
}

→ {

can be formulated in terms of a CBF hi, see Equation

Ci =

x
{

∈

X : hi(x)

0
}

≥

36.

Having just one CBF we can guarantee invariance, but if there are several, they might represent
conﬂicting objectives, such as in safe area and at charger, if the charger happens to be located outside
the safe set. Normally, the intersection of the corresponding control sets Uinv would guarantee invari-
ance of all sets, but if the objectives are conﬂicting, the intersection might be empty. In these cases
we will make use of the fact that the BT includes a clear priority order of the objectives, e.g., that in
safe area is more important than at charger. The idea is then to include as many sets as possible in the
intersection, while still making sure the intersection is non-empty.
Thus, we deﬁne the following sets of controls, where Ui

U guarantees invariance of Ci, ¯Ui

⊂

U
U guarantees invariance of some

⊂

guarantees invariance of all C j, j
of the C j, j

≤

i (but is guaranteed to be non-empty).

i (but might be empty) and ˆUi

⊂

≤

Deﬁnition 13. Let

Ui =

¯Ui =

u
{

i
(cid:92)

U :

∈

dhi
dx

f (x, u)

α(hi(x))
}

≥ −

U j

j=1

ˆUi = ¯U j : j

i, ¯U j

= /0

( j = i

∧

∨

≤

¯U j+1 = /0)

37.

38.

39.

We can now choose a control inside ˆUi that is as close as possible to some other desired value

wi(x) that is designed to reach the current subgoal, as in the CBF-QP of (26),

u
ui = argminu||
s.t. u

2
wi(x)
−
||
ˆUi

∈

40.

18

¨Ogren and Sprague

(cid:54)
If we apply this approach to an arbitrarily complex BT, such as the one in Figure 1, with a safety
objective as ﬁrst priority, the CBF approach above will guarantee that we will never violate this objec-
tive. In the best of worlds, we might achieve all objectives, but we know that the robot will always be
safe.

8. Explainable AI and human robot interaction

As robots share workspaces with humans to an increasing extent, questions regarding human robot
interaction become more important. Safety, as seen above, is often most important, but to achieve
efﬁcient interaction it is also important that the human can predict, trust and understand the robot.

In (29) a number of guidelines for trustworthy autonomy are mentioned. These include that the
system should be transparent and traceable, in the sense that “the system must be able to explicitly ex-
plain its reasoning in a concise and usable format (either visual or textual)”. As illustrated in Figure 1,
this requirement is satisﬁed by BTs in the sense that at any point, you can ﬁnd the leaf node that is
executing and follow the branch all the way up to the root to see why this subtree is executing. If the
recursive backward chained approach described in Section 6 is used, reading the expanded precondi-
tions (double stroked in Figure 1) we see that the robot is currently executing Move to object, (in order
to) Make sure robot near object, (to) make sure object in gripper, (to) make sure object at goal. There
is a need for more work on user aspects of BTs, including human robot interaction, but early examples
include (30).

9. Reinforcement Learning, Utility and BTs

Reinforcement learning (RL) is a research area aiming to produce near optimal controllers for a very
general family of control problems. Sometimes so-called end-to-end solutions can be found, mapping
raw sensor readings to actions, to extremely challenging problems (31). If all problems could be solved
end-to-end using RL, there would be no need for BTs, but there is reason to believe that modular
hierarchical control structures will still be useful for a number of years, especially since they enable
safety guarantees, see Section 7, and transparency to a human operator, see Section 8. A natural
question is then how we can combine RL with BTs, ideally to get the performance of RL, and the
guarantees and transparency of BTs.

Figure 8: There are many ways of combining RL with BTs. Single actions can be replaced (1), as
can entire subtrees (2). One could also add a new subtree (3), and keep the old subtrees as fallback
options if the new one fails. Finally, the order of fallback options can be changed (4), as can the order
of satisfying preconditions (5).

A number of different ways of combining BTs with RL are illustrated in Figure 8. The ﬁrst option

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

19

2?Make sure beverage is servedA beverage is servedGet soda bottle3—>Serve sodaGet bottle openerPut soda and opener on tableGet tea pot—> Serve teaGet tea cupPut tea pot and cup on table4551that comes to mind is perhaps to replace a single action with RL (1 in Figure 8). This was explored
in (32, 33), where an RL problem including states, actions and rewards was speciﬁed by the user. If
the problem domain is well suited for RL this approach can then be expanded, replacing subtrees (2 in
Figure 8) in a bottom up fashion. This gradual approach can be seen as a low risk option to replacing
an entire control structure with end-to-end RL.

RL can also be used to increase the performance of an existing BT. One way of doing this is to
keep the current structure, but add an additional option using RL, as suggested in (34) and illustrated
in (item 3 of Figure 8). If the RL option fails, the other ones will execute and achieve the subgoal.

Another approach, (item 4 in Figure 8), focussing on subtree order was explored in (35, 36, 37, 38).
As the Q-value of a state-action pair in RL estimates the future reward, it was noted that Q-values could
be used to choose between fallback options, reordering them based on the Q-value in the current state.
A similar idea was explored in (39), where the success probability of each child was estimated by
gathering data during execution, and the order was updated to keep the child with highest value ﬁrst.
Finally, the least explored option (item 5 in Figure 8) is to also reorder pre-conditions in the BT. For
example, fetching a bunch of items, as in Figure 8, amounts to a small instance of a traveling salesman
problem (TSP) where ordering might have impact on performance.

10. Evolutionary Algorithms and BTs

Evolutionary algorithms, or genetic algorithms, (40), are local optimization algorithms inspired by the
theory of evolution. The basic idea is to maintain a family of solution candidates, and then create new
solution candidates from the previous ones by applying mutations (small alteration of a candidate) and
crossover (taking two candidates, mark a subset in each and swap the subsets). The candidates are then
evaluated using a ﬁtness function, and some portion of them are removed.

The modularity of BTs, with a uniform interface on all subtree levels, makes them well suited for
evolutionary algorithms. Applying mutation to a BT can be done by picking an arbitrary subtree, and
replacing it with some other subtree, as illustrated in Figure 9(a). Futhermore, crossover can similarly
be done by taking two BTs, choosing a subtree in each and swap them, as illustrated in Figure 9(b).

(a)

(b)

Figure 9: Applying mutation and crossover to a BT

It has been shown that locality, in terms of small changes in design giving small changes in per-
formance, is important for the performance of evolutionary algorithms (41). As seen in Lemma 4
above, the inﬂuence region Ii captures the part of the state space where a subtree can inﬂuence system

20

¨Ogren and Sprague

—>—>?acbde—>?f—>—>?acbde—>?f1f2—>Mutation—>—>?acbde—>?hijg?—>f—>—>?ac?de—>?hijgb—>fCrossoverCrossoverCopyCopybehavior. Thus, for larger BTs, a given subtree will often have a fairly limited Ii providing the locality
described in (41).

A well known problem of evolutionary algorithms is so-called bloating (42), where the average
size of the individuals in a population grows, without a corresponding increase in ﬁtness. For BTs it
is clear that a design could have large parts that do not contribute at all. Both (43) and (44) describe
methods for addressing this problem. A practical approach is to try pruning different subtrees to see
if ﬁtness is reduced, whereas a more theoretical approach is to compute the inﬂuence regions Ii for all
the subtrees, and remove the ones with Ii = /0.

Work on BTs and evolutionary algorithms can be found in (45, 46, 43, 47, 48). Finally, combi-
nations of BTs, evolutionary algorithms and planning can be found in (49), and multi-agent problems
using BTs and evolutionary algorithms have been addressed in (50, 51).

11. Planning and BTs

Planning algorithms are typically used to create a sequence of actions that will move the world state
from a given starting state to some desired goal state. Planning can either be on a lower level, such as
motion planning or grasp planning, or a higher level, such as task planning. Low level planning are
usually integrated as leaves in a BT, whereas high level planning can be used to create the BT itself.
The reason for combining BTs and planning algorithms is often to add the reactive feedback properties
of a BT to the goal directed actions output by the planner.

The most straightforward way of using a task planner is to ﬁrst run the planner to get a sequence
of actions, and then execute this sequence. This works ﬁne if the world is static and the actions are
predictable. However, if an action fails, the sensing of the world was inaccurate, or an external agent
changes the world state, the planned sequence of actions will not lead to the goal state. A natural way
to add feedback to the system is to monitor the execution to see if it runs as predicted, and re-plan once
there is a signiﬁcant enough deviation. However, in many cases the original plan is still valid, we just
need to jump to the proper phase. If a grasping action fails, we can try grasping again. If an object
is picked up and later dropped, we can jump back to the pick up action. If an external agent helps
us with some subgoal, we can jump ahead to the proper action in the list. As seen above, BTs are an
appropriate tool for supplying this kind of feedback control, and were used in e.g. (25).

Planning might also be used to create a feedback policy. One example of this is the A* algorithm
that computes the shortest path to goal from all initial states, not only the one currently occupied.
Thus, if an unexpected action not only moves us back or forth on the expected path, but also sideways
to a state that was not intended to be occupied, the plan still contains the proper action. The design
described in Section 6 provides this functionality in a BT (14). An advantage is the larger region of
attraction, while a drawback is that the BT needed to cover all potential situations can be very large.

Another use of the reactivity of BTs in connection to planning can be found in (52). Here a BT is
created from the output of the planner with the intent of reactively taking advantage of opportunities
for parallel execution, and tasks ﬁnishing earlier than expected. By tracking the preconditions for each
action, they are executed as early as possible, based on information that was not available at planning
time.

The combination of planners with BT has been explored in (53, 54, 55, 56, 57, 58, 59, 49). Fur-
thermore, the special cases of HTN planners were investigated in (60, 61, 62, 63), and LTL planners
in (64, 65, 66).

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

21

12. Conclusions

In this paper we have provided a control theoretic approach to BTs, showing how they can be seen
as a hierarchically modular way to create a switched dynamical system, where the switching is based
on feedback from lower level modules. We have also showed how the resulting operating regions
can be computed, based on the speciﬁcations of parents, siblings and children of the node. Using
these operating regions, we present sufﬁcient conditions of convergence to the goal region of the entire
BTs, as well as practical designs that can be used to create convergent BTs. Finally, we have showed
how these core result connect to other research efforts on BTs, including control barrier functions,
explainable AI, reinforcement learning, genetic algorithms and planning.

SUMMARY POINTS

1. Behavior trees represent a hierarchically modular way to combine controllers into more com-

plex controllers.

2. Behavior trees enable feedback control, not only on the lowest level, but on all levels, as
the interface explicitly includes meta information (feedback) regarding the applicability and
progress of a controller, that enables the parent level to act based on this feedback.

3. The modular structure of behavior trees lends itself to formal analysis regarding convergence

and region of attraction.

4. Ongoing work connects behavior trees to other research areas such as planning and learning.

FUTURE ISSUES

1. Reinforcement learning can solve many problems end-to-end. However, many robot systems
will need a modular structure combining separate capabilities, such as path planning and
grasping. Behavior trees is a viable option for this structure and the connections between
reinforcement learning and behavior trees needs to be explored further.

2. Explainable AI, learning by demonstration and human robot interaction (HRI) are areas where

the transparency of BTs could play an important role.

3. Behavior trees have been explored from an AI and robotics perspective, but very little work

has been done from a control theoretic point of view.

DISCLOSURE STATEMENT

The authors are not aware of any afﬁliations, memberships, funding, or ﬁnancial holdings that might
be perceived as affecting the objectivity of this review.

ACKNOWLEDGMENTS

The authors gratefully acknowledge the support from SSF through the Swedish Maritime Robotics
Centre (SMaRC) (IRC15-0046), and by FOI through project 7135.

22

¨Ogren and Sprague

LITERATURE CITED

1. Blume M, Appel AW. 1999. Hierarchical modularity. ACM Transactions on Programming Languages and

Systems 21(4):813–847

2. Sacerdoti ED. 1975. A Structure for Plans and Behavior. Tech. rep., SRI International AI center
3. Erol K, Hendler J, Nau DS. 1994. UMCP: a sound and complete procedure for hierarchical task-network
planning. In Proceedings of the Second International Conference on Artiﬁcial Intelligence Planning Systems,
AIPS’94, pp. 249–254. Chicago, Illinois: AAAI Press

4. Mateas M, Stern A. 2002. A behavior language for story-based believable agents. IEEE Intelligent Systems

17(4):39–47

5. Isla D. 2005. Handling Complexity in the Halo 2 AI. In Proceedings of the Game Developers Conference

(GDC)

6. Florez-Puga G, Gomez-Martin MA, Gomez-Martin PP, Diaz-Agudo B, Gonzalez-Calero PA. 2009. Query-
Enabled Behavior Trees. IEEE Transactions on Computational Intelligence and AI in Games 1(4):298–308
¨Ogren P. 2012. Increasing Modularity of UAV Control Systems using Computer Game Behavior Trees. In AIAA
Guidance, Navigation, and Control Conference. Minneapolis, Minnesota: American Institute of Aeronautics
and Astronautics

7.

8. Bagnell JA, Cavalcanti F, Cui L, Galluzzo T, Hebert M, et al. 2012. An Integrated System for Autonomous
Robotics Manipulation. In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp.
2955–2962

9. Harel D. 1987. Statecharts: a visual formalism for complex systems. Science of Computer Programming

8(3):231–274

10. Biggar O, Zamani M, Shames I. 2021. An Expressiveness Hierarchy of Behavior Trees and Related Architec-

tures. IEEE Robotics and Automation Letters 6(3):5397–5404

11. Iovino M, Scukins E, Styrud J, ¨Ogren P, Smith C. 2020. A Survey of Behavior Trees in Robotics and AI.

arXiv:2005.05842 [cs]

12. Colledanchise M, ¨Ogren P. 2018. Behavior Trees in Robotics and AI : An Introduction. CRC Press
13. Colledanchise M, ¨Ogren P. 2017. How Behavior Trees Modularize Hybrid Control Systems and Generalize
Sequential Behavior Compositions, the Subsumption Architecture, and Decision Trees. IEEE Transactions on
Robotics 33(2):372–389
¨Ogren P. 2020. Convergence Analysis of Hybrid Control Systems in the Form of Backward Chained Behavior
Trees. IEEE Robotics and Automation Letters 5(4):6073–6080

14.

15. Sprague CI, ¨Ogren P. 2021. Continuous-time behavior trees as discontinuous dynamical systems. IEEE Control

Systems Letters 6:1891–1896

16. Colledanchise M, Natale L. 2021. On the Implementation of Behavior Trees in Robotics. IEEE Robotics and

Automation Letters :8

17. Cortes J. 2008. Discontinuous dynamical systems. IEEE Control Systems Magazine 28(3):36–73
18. Filippov AF. 1988. Differential Equations with Discontinuous Righthand Sides: Control Systems. Springer

Science & Business Media

19. Biggar O, Zamani M, Shames I. 2020. On modularity in reactive control architectures, with an application to

formal veriﬁcation. arXiv preprint arXiv:2008.12515

20. Gallai T. 1967. Transitiv orientierbare Graphen. Acta Mathematica Academiae Scientiarum Hungarica

18(1):25–66

21. Watson AH, Wallace DR, McCabe TJ. 1996. Structured Testing: A Testing Methodology Using the Cyclo-
matic Complexity Metric. U.S. Department of Commerce, Technology Administration, National Institute of
Standards and Technology

22. Burridge RR, Rizzi AA, Koditschek DE. 1999. Sequential Composition of Dynamically Dexterous Robot

Behaviors. The International Journal of Robotics Research 18(6):534–555

23. Conner DC, Choset H, Rizzi AA. 2006. Integrated Planning and Control for Convex-bodied Nonholonomic

Systems using Local Feedback Control Policies. In Robotics: Science and Systems, vol. 2

24. Reist P, Tedrake R. 2010. Simulation-based LQR-trees with input and state constraints. In 2010 IEEE Interna-

tional Conference on Robotics and Automation, pp. 5504–5510

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

23

25. Paxton C, Ratliff N, Eppner C, Fox D. 2019. Representing Robot Task Plans as Robust Logical-Dynamical
Systems. In 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 5588–
5595. ISSN: 2153-0866

26. Ames AD, Coogan S, Egerstedt M, Notomista G, Sreenath K, Tabuada P. 2019. Control Barrier Functions:

27.

Theory and Applications. In 2019 18th European Control Conference (ECC), pp. 3420–3431
¨Ogren P. 2006. Autonomous UCAV Strike Missions Using Behavior Control Lyapunov Functions. In AIAA
Guidance, Navigation, and Control
¨Ozkahraman, ¨Ogren P. 2020. Combining Control Barrier Functions and Behavior Trees for Multi-Agent Un-
derwater Coverage Missions. In 2020 59th IEEE Conference on Decision and Control (CDC), pp. 5275–5282
29. Endsley MR. 2015. Autonomous Horizons: System Autonomy in the Air Force – A Path to the Future. Volume

28.

I: Human-AutonomyTeaming. Tech. rep., United States Air Force Ofﬁce of the Chief Scientist

30. Paxton C, Jonathan F, Hundt A, Mutlu B, Hager GD. 2017. User Experience of the CoSTAR System for

Instruction of Collaborative Robots. arXiv:1703.07890 [cs]

31. Vinyals O, Babuschkin I, Czarnecki WM, Silver D. 2019. Grandmaster level in StarCraft II using multi-agent

reinforcement learning. Nature 575(7782):350–354

32. Pereira RdP, Engel PM. 2015. A Framework for Constrained and Adaptive Behavior-Based Agents.

arXiv:1506.02312 [cs]

33. Kartasev M. 2019. Integrating Reinforcement Learning into Behavior Trees by Hierarchical Composition.

Master thesis, KTH Royal Institute of Technology

34. Sprague CI, ¨Ogren P. 2018. Adding Neural Network Controllers to Behavior Trees without Destroying Perfor-

mance Guarantees. arXiv:1809.10283 [cs]

35. Dey R, Child C. 2013. QL-BT: Enhancing Behaviour Tree Design and Implementation with Q-Learning. In
2013 IEEE Conference on Computational Inteligence in Games (CIG), pp. 1–8. Niagara Falls, ON, Canada:
IEEE

36. Fu Y, Qin L, Yin Q. 2016. A Reinforcement Learning Behavior Tree Framework for Game AI. In Proceed-
ings of the 2016 International Conference on Economics, Social Science, Arts, Education and Management
Engineering. Huhhot, China: Atlantis Press

37. Zhang Q, Sun L, Jiao P, Yin Q. 2017. Combining Behavior Trees with MAXQ Learning to Facilitate CGFs

Behavior Modeling. In 2017 4th International Conference on Systems and Informatics (ICSAI), pp. 525–531

38. Zhu X. 2019. Behavior tree design of intelligent behavior of non-player character (NPC) based on Unity3D.

Journal of Intelligent & Fuzzy Systems 37(5):6071–6079

39. Hannaford B, Hu D, Zhang D, Li Y. 2016. Simulation Results on Selector Adaptation in Behavior Trees.

arXiv:1606.09219 [cs]

40. Whitley D. 1994. A genetic algorithm tutorial. Statistics and Computing 4(2):65–85
41. Rothlauf F, Oetzel M. 2006. On the locality of grammatical evolution. In European Conference on Genetic

Programming, pp. 320–330. Springer

42. Luke S, Panait L. 2006. A Comparison of Bloat Control Methods for Genetic Programming. Evolutionary

Computation 14(3):309–344

43. Colledanchise M, Parasuraman R, ¨Ogren P. 2019. Learning of Behavior Trees for Autonomous Agents. IEEE

Transactions on Games 11(2):183–189

44. Hallawa A, Schug S, Iacca G, Ascheid G. 2020. Evolving Instinctive Behaviour in Resource-Constrained Au-
tonomous Agents Using Grammatical Evolution. In Applications of Evolutionary Computation, ed. PA Castillo,
JL Jim´enez Laredo, F Fern´andez de Vega, pp. 369–383, Lecture Notes in Computer Science, pp. 369–383.
Cham: Springer International Publishing

45. Lim CU, Baumgarten R, Colton S. 2010. Evolving Behaviour Trees for the Commercial Game DEFCON. In
Applications of Evolutionary Computation, ed. D Hutchison, GN Yannakakis, pp. 100–110, vol. 6024. Springer
Berlin Heidelberg

46. Nicolau M, Perez-Liebana D, O’Neill M, Brabazon A. 2017. Evolutionary Behavior Tree Approaches for
Navigating Platform Games. IEEE Transactions on Computational Intelligence and AI in Games 9(3):227–
238

47. Iovino M, Styrud J, Falco P, Smith C. 2020. Learning Behavior Trees with Genetic Programming in Unpre-

24

¨Ogren and Sprague

dictable Environments. arXiv:2011.03252 [cs] ArXiv: 2011.03252

48. Paduraru C, Paduraru M. 2019. Automatic Difﬁculty Management and Testing in Games Using a Framework

Based on Behavior Trees and Genetic Algorithms. In arXiv:1909.04368 [Cs]

49. Styrud J, Iovino M, Norrl¨of M, Bj¨orkman M, Smith C. 2021. Combining Planning and Learning of Behavior

Trees for Robotic Assembly. arXiv:2103.09036 [cs] ArXiv: 2103.09036

50. Neupane A, Goodrich M. 2019. Learning Swarm Behaviors Using Grammatical Evolution and Behavior Trees.
In Proceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence, pp. 513–520.
Macao, China: International Joint Conferences on Artiﬁcial Intelligence Organization

51. Jones S, Studley M, Hauert S, Winﬁeld A. 2018. Evolving Behaviour Trees for Swarm Robotics. In Distributed
Autonomous Robotic Systems: The 13th International Symposium, ed. R Groß, A Kolling, S Berman, E Fraz-
zoli, A Martinoli, F Matsuno, M Gauci, pp. 487–501, Springer Proceedings in Advanced Robotics. Cham:
Springer International Publishing

52. Mart´ın F, Morelli M, Espinoza H, Lera FJR, Matell´an V. 2021. Optimized Execution of PDDL Plans using

Behavior Trees. arXiv:2101.01964 [cs]

53. Colledanchise M, Almeida D, ¨Ogren P. 2019. Towards Blended Reactive Planning and Acting using Behavior

Trees. In IEEE Int. Conference on Robotics and Automation. Montreal, Canada: IEEE

54. Tadewos TG, Shamgah L, Karimoddini A. 2019. Automatic Safe Behaviour Tree Synthesis for Autonomous

Agents. In 2019 IEEE 58th Conference on Decision and Control (CDC), pp. 2776–2781

55. Tadewos TG, Shamgah L, Karimoddini A. 2019. On-the-Fly Decentralized Tasking of Autonomous Vehicles.

In 2019 IEEE 58th Conference on Decision and Control (CDC), pp. 2770–2775

56. Zhou H, Min H, Lin Y. 2019. An Autonomous Task Algorithm Based on Behavior Trees for Robot. In 2019 2nd

China Symposium on Cognitive Computing and Hybrid Intelligence (CCHI), pp. 64–70

57. Paxton C, Ratliff N, Eppner C, Fox D. 2019. Representing Robot Task Plans as Robust Logical-Dynamical
Systems. In 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 5588–
5595

58. Schwab P, Hlavacs H. 2015. Capturing the Essence: Towards the Automated Generation of Transparent Be-

havior Models. In Eleventh Artiﬁcial Intelligence and Interactive Digital Entertainment Conference

59. Kuckling J, Ligot A, Bozhinoski D, Birattari M. 2018. Behavior Trees as a Control Architecture in the Auto-
matic Modular Design of Robot Swarms. In Swarm Intelligence, ed. M Dorigo, pp. 30–43, Lecture Notes in
Computer Science. Springer International Publishing

60. Neufeld X, Mostaghim S, Brand S. 2018. A Hybrid Approach to Planning and Execution in Dynamic Envi-
ronments Through Hierarchical Task Networks and Behavior Trees. In Fourteenth Artiﬁcial Intelligence and
Interactive Digital Entertainment Conference

61. Rovida F, Grossmann B, Kr¨uger V. 2017. Extended Behavior Trees for Quick Deﬁnition of Flexible Robotic
Tasks. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 6793–6800
62. Segura-Muros J ´A, Fern´andez-Olivares J. 2017. Integration of an Automated Hierarchical Task Planner in ROS
Using Behaviour Trees. In 2017 6th International Conference on Space Mission Challenges for Information
Technology (SMC-IT), pp. 20–25

63. H¨olzl M, Gabor T. 2015. Reasoning and Learning for Awareness and Adaptation. In Software Engineering
for Collective Autonomic Systems: The ASCENS Approach, ed. M Wirsing, M H¨olzl, N Koch, P Mayer, pp.
249–290, Lecture Notes in Computer Science. Cham: Springer International Publishing

64. Colledanchise M, Murray RM, ¨Ogren P. 2017. Synthesis of Correct-by-Construction Behavior Trees. In 2017

IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 6039–6046

65. Lan M, Lai S, Lee TH, Chen BM. 2019. Autonomous Task Planning and Acting for Micro Aerial Vehicles. In

2019 IEEE 15th International Conference on Control and Automation (ICCA), pp. 738–745

66. Biggar O, Zamani M. 2020. A Framework for Formal Veriﬁcation of Behavior Trees with Linear Temporal

Logic. IEEE Robotics and Automation Letters

www.annualreviews.org

•

Behavior Trees in Robot Control Systems

25

