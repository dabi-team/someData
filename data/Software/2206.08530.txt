GDsmith: Detecting Bugs in Graph Database Engines

Wei Lin
Peking University
Beijing, China

Zongyang Li
Peking University
Beijing, China

Ziyue Hua
Peking University
Beijing, China

Lu Zhang
Peking University
Beijing, China

Luyao Ren
Peking University
Beijing, China

Tao Xie
Peking University
Beijing, China

2
2
0
2

n
u
J

7
1

]

B
D
.
s
c
[

1
v
0
3
5
8
0
.
6
0
2
2
:
v
i
X
r
a

ABSTRACT
Graph database engines stand out in the era of big data for their
efficiency of modeling and processing linked data. There is a strong
need of testing graph database engines. However, random testing,
the most practical way of automated test generation, faces the
challenges of semantic validity, non-empty result, and behavior
diversity to detect bugs in graph database engines. To address these
challenges, in this paper, we propose GDsmith, the first black-box
approach for testing graph database engines. It ensures that each
randomly generated Cypher query satisfies the semantic require-
ments via skeleton generation and completion. GDsmith includes
our technique to increase the probability of producing Cypher
queries that return non-empty results by leveraging three types of
structural mutation strategies. GDsmith also includes our technique
to improve the behavior diversity of the generated Cypher queries
by selecting property keys according to their previous frequencies
when generating new queries. Our evaluation results demonstrate
that GDsmith is effective and efficient for automated query gen-
eration and substantially outperforms the baseline. GDsmith suc-
cessfully detects 27 previously unknown bugs on the released
versions of three popular open-source graph database engines and
receive positive feedback from their developers.

CCS CONCEPTS
• Software and its engineering → Software testing and de-
bugging; • Information systems → Database query processing; •
Security and privacy → Database and storage security.

KEYWORDS
automated test generation, Cypher query, graph database engine

1 INTRODUCTION
In recent years, graph database engines have been widely used in
database applications from various domains, such as knowledge rea-
soning systems [34] and recommender systems [13, 28]. Graph data-
base engines use graph structures for semantic queries with nodes,
relationships, and properties to represent and store data [1]. As a
well-known representative of graph database engines, Neo4j [18]
has long been ranked first in the DB-Engines Ranking [32] (which
ranks graph database engines monthly based on their popularity).
Over 800 enterprise customers use Neo4j, including over 75% of
Fortune 100 companies [32]. Although there is currently no query
language standard for graph databases, it is generally believed that
Cypher [8, 9], originally contributed by Neo4j, is the most widely

Figure 1: An example property graph (containing three User
nodes and two FRIEND relationships) and a Cypher query
(finding friends of friends of Bob).

adopted query language specially designed for graph databases be-
cause of Neo4j’s overwhelming market share [19]. As an open query
language, Cypher is now used by over 10 other graph databases
(e.g., RedisGraph [22] and Memgraph [16]) and tens of thousands of
developers [19]. Some graph databases that natively support other
graph query languages (e.g., Gremlin [7]) are also compatible with
Cypher queries via translation tools (e.g., Cypher for Gremlin [6]).
Detecting bugs in graph database engines is critical for two main
reasons. First, the underlying code of graph database engines is of
high complexity, being error-prone inevitably. For example, Neo4j
version 4.3.10 has over 684K non-comment lines of Java code [5],
and Memgraph version 2.1.1 has over 103K non-comment lines of
C/C++ code [4]. Second, the applications that interact with buggy
graph database engines may exhibit unexpected failing behaviors,
leading to potential risks. For example, a Neo4j bug1 in the in-
terpreted runtime leads to incorrect results for the size function
(which is a widely used scalar function returning the number of
sub-graphs matching the given pattern expression).

To detect bugs in graph database engines with Cypher support,
one can adopt random testing [10, 31, 38] to generate two parts
of test inputs, as shown in Figure 1. (1) A property graph is a

1https://github.com/neo4j/neo4j/issues/12641

(cid:51)(cid:85)(cid:82)(cid:83)(cid:72)(cid:85)(cid:87)(cid:92)(cid:3)(cid:42)(cid:85)(cid:68)(cid:83)(cid:75)Username = 'Bob'Username = 'Jay'Username = 'Tom'FRIENDFRIEND(cid:47)(cid:68)(cid:69)(cid:72)(cid:79)(cid:53)(cid:72)(cid:79)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:75)(cid:76)(cid:83)(cid:3)(cid:55)(cid:92)(cid:83)(cid:72)(cid:51)(cid:85)(cid:82)(cid:83)(cid:72)(cid:85)(cid:87)(cid:92)(cid:3)(cid:46)(cid:72)(cid:92)(cid:51)(cid:85)(cid:82)(cid:83)(cid:72)(cid:85)(cid:87)(cid:92)(cid:3)(cid:57)(cid:68)(cid:79)(cid:88)(cid:72)(cid:49)(cid:82)(cid:71)(cid:72)(cid:53)(cid:72)(cid:79)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:75)(cid:76)(cid:83)(cid:3)(cid:38)(cid:92)(cid:83)(cid:75)(cid:72)(cid:85)(cid:3)(cid:52)(cid:88)(cid:72)(cid:85)(cid:92)MATCH (user:User)-[r1:FRIEND]-()-[r2:FRIEND]-(fof) WHERE user.name = 'Bob' RETURN fof.name AS fofName; 
 
 
 
 
 
Conference’17, July 2017, Washington, DC, USA

Wei Lin, Ziyue Hua, Luyao Ren, Zongyang Li, Lu Zhang, and Tao Xie

directed graph consisting of labeled entities (i.e., nodes and rela-
tionships)2 and properties on entities [12]. A relationship encodes
a directed connection between exactly two nodes. A property is a
pair consisting of a property key and a property value (which is an
instantiation of one of Cypher’s types such as String). (2) Cypher
queries are built up using various clauses for querying the property
graph [19]. In each Cypher query, clauses are chained together, and
they feed intermediate result sets between each other. For example,
the matching variables from one MATCH clause will be the context
that the next clause exists in. The last part of the Cypher query is
one final RETURN clause (which is a period symbol at the end of a
Cypher query).

However, adopting existing random testing approaches to detect
bugs in graph database engines with Cypher support faces three
main challenges. (1) Semantic validity challenge. It is challeng-
ing to randomly generate semantically valid Cypher queries. A
semantically valid Cypher query has no grammar error (e.g., us-
ing wrong keywords) and semantic error (e.g., using undefined
variables). Grammar-based testing [10, 31] generates syntactically
correct test inputs but wastes testing budget on generating a large
number of semantically invalid test inputs. Mutation-based test-
ing [38] produces new test inputs by mutating characters or bits of
seed inputs. Such mutations easily lead to invalid semantics and
even incorrect syntax because they do not grasp high-level concepts
(e.g., scope of variables). However, only semantically valid queries
are able to reach core parts of graph database engines and detect
deep bugs because semantically invalid queries are filtered out by
the engines’ semantic check. (2) Non-empty result challenge.
It is challenging to increase the percentage of Cypher queries re-
turning non-empty results among all randomly generated queries.
When the property graphs stored in multiple engines are the same,
a bug can be detected if the same Cypher query is executed on
these engines and their fetched result sets are different. Although
simple queries with loose constraints easily return non-empty re-
sults [17], randomly generated non-trivial queries are more likely
to trigger bugs. However, randomly generated non-trivial queries
tend to return empty results because there is no sub-graph match-
ing the randomly generated constraints from these queries to the
patterns. (3) Behavior diversity challenge. It is challenging to
randomly generate Cypher queries with high behavior diversity.
If two Cypher queries cover different property values3 in a prop-
erty graph, these two Cypher queries have different behaviors.
Improving the behavior diversity of randomly generated queries
is desirable because some bugs can be triggered by only specific
behaviors (e.g., covering specific property values). However, the
existing random testing approaches lack feedback mechanisms to
generate new queries covering different property values to improve
the behavior diversity in a target manner.

To address the aforementioned challenges, in this paper, we
propose GDsmith, the first black-box approach for testing graph
database engines. To address the semantic validity challenge, GD-
smith first randomly generates a Cypher skeleton that contains
uninstantiated parts (e.g., patterns and expressions), then fills the

uninstantiated parts with validly defined variables based on the
semantics of each clause to obtain a Cypher query. To address the
non-empty result challenge, GDsmith includes our technique to
increase the probability of producing Cypher queries returning
non-empty results by leveraging three types of structural mutation
strategies, so that the mutated queries via these strategies not only
preserve semantic validity, but also return non-empty results with
high probability. To address the behavior diversity challenge, GD-
smith dynamically selects property keys according to their previous
frequencies when completing new skeletons. The insight is that
high behavior diversity can be achieved with evenly distributed fre-
quencies of property keys in Cypher queries returning non-empty
results.

We implement GDsmith in Java and conduct a series of evalua-
tions to assess its effectiveness and efficiency measured with five
metrics. Our evaluation results show that GDsmith substantially
outperforms the baseline. GDsmith achieves 100% semantic validity
rate and 98% grammar coverage, whereas the baseline achieves only
16% semantic validity rate. GDsmith is able to produce 69% more
queries returning non-empty results than the baseline. The graph
mutation score of GDsmith is 4.2× higher than the graph mutation
score of the baseline. GDsmith detects three unique bugs on two
released versions of Neo4j within 30 minutes whereas the baseline
does not detect any bug.

We deploy GDsmith to detect bugs in three popular open-source
graph database engines (Neo4j [18], RedisGraph [22], and Mem-
graph [16]), detecting 27 previously unknown bugs on the re-
leased versions. Among the 27 detected bugs, 14 are confirmed by
the developers of corresponding engines and 7 are already fixed. The
developers of all the three graph database engines have replied that
our work contributes to their development. The positive feedback
from the developers also shows GDsmith’s high value in practice.

This paper makes the following main contributions:

• GDsmith, the first approach of automated test generation
for detecting bugs in graph database engines, addressing
three main challenges.

• Evaluations for demonstrating GDsmith’s effectiveness (sub-
stantially outperforming the baseline) and practicability (suc-
cessfully detecting 27 previously unknown bugs).

The rest of the paper is organized as follows. Section 2 presents
the background of our work. Section 3 illustrates our GDsmith
approach. Section 4 describes our evaluations. Section 5 discusses
related work. Section 6 concludes this paper with future work.

2 BACKGROUND
It is known to all that graph database engines are critical software
systems. They play an important role in storing and processing
linked data. In this section, we provide background information
on three graph database engines with Cypher support (which are
tested by GDsmith in our evaluations), the Cypher language, and
the historical bug statistics for these engines.

2A node may be assigned with a set of unique labels, whereas a relationship is assigned
with exactly one relationship type.
3A covered property value refers to that it involves a query’s execution and affects its
result set.

2.1 Graph Database Engines We Test
We select three popular open-source graph database engines as our
test subjects:

GDsmith: Detecting Bugs in Graph Database Engines

Conference’17, July 2017, Washington, DC, USA

Table 1: Core Grammar of Cypher Queries

query
ret
clause

pattern_tuple
pattern

::=
::=
::=

::=
::=

RETURN ret | clause query
* | expr [AS a] | ret, expr [AS a]
[OPTIONAL] MATCH pattern_tuple [WHERE expr]
| WITH ret [WHERE expr] | UNWIND expr AS a
pattern | pattern_tuple
node_pattern | node_pattern rel_pattern pattern

(1) Neo4j [18] is the market leader, graph database category
creator, and the most widely deployed graph data platform
in the market according to the DB-Engines Ranking [32].
It is a high-performance graph store with all the features
expected of a mature and robust database.

(2) RedisGraph [22] is the first queryable property graph data-
base to use sparse matrices to represent the adjacency matrix
in graphs and linear algebra to query the graph.

(3) Memgraph [16] is a streaming graph application platform

and leverages an in-memory-first architecture.

2.2 Cypher Language
Cypher is the most widely adopted, fully-specified, and open query
language for property graph database engines [19]. It is a declarative
graph query language that allows for expressively and efficiently
querying the graph store. Complicated database queries can easily
be expressed through Cypher. Although there is no standard lan-
guage for graph databases, Cypher is a key inspiration for the ISO
project creating a standard graph query language (GQL) according
to the official description [19]. There are also existing translation
tools from Cypher to other graph query languages [6].

Cypher lets users simply express what data to retrieve (declara-
tive) while the underlying engine completes the task without requir-
ing they understand implementation details, which is in contrast
to imperative languages like Java, scripting languages like Gremlin.
In each Cypher query, clauses are chained together, and they feed
intermediate result sets between each other. Table 1 shows the core
syntax of Cypher4. Note that a denotes an alias, expr denotes an
expression, node_pattern denotes a node pattern, and rel_pattern
denotes a relationship pattern. The MATCH clause is used to specify
the patterns the Cypher query will search for in the database. MATCH
is often coupled to a WHERE part which is a sub-clause and adds
restrictions to the MATCH patterns, making them more specific. A
MATCH clause can occur at the beginning of the query or later, pos-
sibly after a WITH clause. The WITH clause allows query parts to be
chained together, piping the results from one to be used as starting
points or criteria in the next. The UNWIND clause expands a list into
a sequence of records. The RETURN clause defines what to include
in the query result set. Figure 1 shows an example Cypher query
that aims to find all fof’s names who are friends of friends of Bob.
In this query, user:User and fof are node patterns, -[r1:FRIEND]-
and -[r2:FRIEND]- are relationship patterns, user.name = ’Bob’ and
fof.name are expressions, and fofName is an alias.

Figure 2: The overall evolution history of the bugs.

2.3 Historical Bug Statistics
To gain a good understanding of bugs in graph database engines,
we analyze the issues and pull requests in the official Neo4j, Redis-
Graph, and Memgraph GitHub repositories before December 31,
2021. We regard bug-labeled issues and pull requests as reported
bugs because the official repositories of these three graph database
engines happen to contain bug labels (which are used to mark pos-
sible problems). Note that such filtering is not perfect, and may
overlook bugs (some platform-related issues are solved by changing
graph database engine versions instead of marking these issues as
bugs) and introduce redundant statistics (some bug-labeled pull
requests have additional feature updates). From our final statistics,
those with bug labels account for about 15% (2363 out of 15063) of
all issues and pull requests.

We first count the number of bug-labeled issues and pull re-
quests in Neo4j, RedisGraph, and Memgraph by month, and plot
the growth curve as shown in Figure 2. Neo4j, RedisGraph, and
Memgraph have 920, 218, and 5 bug-labeled issues, respectively. In
addition, Neo4j, RedisGraph, and Memgraph have 937, 268, and 15
bug-labeled pull requests, respectively. The earliest issue of Neo4j is
in November 2012, corresponding to Neo4j version 1.85. Since this
release, the number of bug-labeled issues has increased gradually
over time. The first bug-labeled pull request appears in December
2013 and since then the number of bug-labeled pull requests starts
to grow. The growing trend of pull requests continues into 2018,
and after that there is no new bug label added. We manually in-
spect all pull requests from January 2018, and they mainly contain
some feature updates, with very few serious bug fixes. All of these
pull requests analyzed by us are closed except that two are in the
merged state and two other are still open. Since the bug-labeled
issues continue to grow from the beginning of 2018 until now, we
believe that all bugs raised by users during this period are continu-
ously fixed in the official version updates. Although RedisGraph
and Memgraph are released relatively late, since their first releases
the users are finding bugs in both graph database engines, and
the overall number of bugs is steadily increasing. As the software
functionality continues to improve, we have reasons to believe that
the sizes of the bugs and the pull requests in these two databases

4The complete syntax and semantics of core Cypher can be referred to in previous
work [8, 9].

5https://neo4j.com/release-notes/page/15/

Neo4jRedisGraphMemgraphConference’17, July 2017, Washington, DC, USA

Wei Lin, Ziyue Hua, Luyao Ren, Zongyang Li, Lu Zhang, and Tao Xie

may grow to the similar sizes as Neo4j. The growing trend of bugs
in graph database engines illustrates that there is a strong need for
deeply testing graph database engines.

Then we count how many bug-labeled issues contain Cypher
queries. We search for the Markdown code snippets in the issue
contents (only 1 out of 1143 issues does not contain any code snip-
pet), and determine code snippets to include Cypher queries when
the code snippets include specific Cypher syntax keywords such
as MATCH and UNWIND (note that we do not use some other Cypher
syntax keywords such as AND and OR because they may appear in
code or commit logs). We assume that an issue containing more
than two used Cypher keywords in a code snippet is considered to
contain Cypher queries. This statistical mechanism may introduce
some bias, as sometimes users provide detailed Cypher queries after
being inquired by developers. Neo4j, RedisGraph, and Memgraph
have 358, 133, and 3 bug-labeled issues containing Cypher queries,
respectively. It indicates that many bugs in graph database engines
can be triggered by executing Cypher queries. Among all closed
issues (1043 out of 1143), the bug living time for issues containing
Cypher queries is an average of 192 days, whereas the bug living
time for the other issues is an average of 298 days (36% less). We
conduct further analysis in the order of bug living time and find
that there is no difference at the 25% median, but it has 48% and
57% less time at the 50% and 75% median, respectively. These re-
sults indicate the potential importance of providing bug-revealing
Cypher queries in the issues for speeding up solving difficult bugs
during the debugging process.

3 APPROACH
In this paper, we propose GDsmith, the first black-box approach for
testing graph database engines. In particular, GDsmith users specify
multiple different instances of graph database engines under test.
GDsmith is portable and compatible without any requirement of
code instrumentation, so it can also test graph database engines
whose underlying code is unavailable or incomplete. Given the en-
gines under test, GDsmith automatically outputs test inputs (each
including both a database state and Cypher queries) that trigger
bugs. To detect whether a bug is triggered (with a test oracle), be-
sides crashing or not, GDsmith can leverage differential testing [15]
to detect bugs. For example, GDsmith users can use cross-engines
(i.e., comparing results fetched by different graph database engines),
cross-versions (i.e., comparing results fetched by different versions
of the same graph database engine), or cross-optimization (i.e., com-
paring results fetched by different query options on the same graph
database engine).

The overall algorithm of GDsmith is shown in Algorithm 1. In
particular GDsmith generates test inputs through four-step itera-
tions. First, GDsmith randomly generates a database state (Lines
2-3, shown in Section 3.1) and initializes GDsmith’s configuration
variables (Lines 4-5). Second, GDsmith produces semantically valid
Cypher queries via random generation or mutation (Lines 8-12,
shown in Section 3.2). Third, GDsmith executes generated queries
on each engine instance (Lines 13-14). Fourth, GDsmith retains the
Cypher queries that return non-empty results (Lines 19-21, shown
in Section 3.3), and leverages the feedback of property key frequen-
cies to generate new Cypher queries with high behavior diversity

Algorithm 1 The top-level algorithm of GDsmith
Input: 𝐷𝑎: one instance of a graph database engine;
Input: 𝐷𝑏 : the other instance of a graph database engine;
Input: 𝑁𝑔: the maximum number of newly generated queries;
Input: 𝑁𝑚: the maximum number of mutated queries;
Output: 𝐵: bug reports.

1: while the timeout does not exceed do
2:

𝑆 ← GeneratePropertyGraphSchema(𝐷𝑎, 𝐷𝑏 )
𝐺 ← GeneratePropertyGraph(𝑆, 𝐷𝑎, 𝐷𝑏 )
𝑃𝑜𝑜𝑙 ← ∅
𝐹 ← Set all frequencies to zero.
𝑖 ← 0
while 𝑖 < 𝑁𝑔 + 𝑁𝑚 do
if 𝑖 < 𝑁𝑔 then

𝑄 ← GenerateRandomQuery(𝑆, 𝐹 )

else

𝑄 ← MutatingExistingQuery(𝑆, 𝐹, 𝑃𝑜𝑜𝑙)

end if
𝑅𝑎 ← ExecuteCypherQuery(𝑄, 𝐷𝑎)
𝑅𝑏 ← ExecuteCypherQuery(𝑄, 𝐷𝑏 )
if a bug is detected by comparing 𝑅𝑎 with 𝑅𝑏 then

𝐵 ← Generate the bug report including 𝐺 and 𝑄.
return 𝐵

end if
if 𝑅𝑎 or 𝑅𝑏 is non-empty then
𝑃𝑜𝑜𝑙 ← Retain 𝑄 into 𝑃𝑜𝑜𝑙

end if
𝐹 ← Update the frequencies of property keys in 𝑄.
𝑖 ← 𝑖 + 1

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

22:

23:

end while

24:
25: end while

(Line 22, shown in Section 3.4). In the end, GDsmith automatically
outputs a bug report including the property graph (i.e., database
state) and Cypher queries that trigger bugs (Lines 15-17, shown in
Section 3.5). In the rest of the section, we illustrate the details of
these steps.

3.1 Schema and Graph Generation
In each iteration, GDsmith first randomly generates the property
graph schema. A property graph schema defines the labels, the
relationship types, and the properties on them [12]. GDsmith gen-
erates a finite set of labels. For each label it determines a unique
name and a set of properties. GDsmith also generates a finite set
of relationship types. For each relationship type it determines a
unique name and a set of pairs of labels for which the relationship
type is applicable. GDsmith generates a unique name and a data
type for each property. Generating a property graph schema is
necessary because it helps guide the valid generation of a property
graph and Cypher queries. Note that some graph database engines
are schema-free so there is no need to execute statements to create
the property graph schema in advance, others are schema-based so
the property graph schema needs to be created explicitly.

GDsmith: Detecting Bugs in Graph Database Engines

Conference’17, July 2017, Washington, DC, USA

Table 2: Core Grammar of Cypher Skeletons

skeleton
ret
clause

::=
::=
::=

RETURN ret | clause skeleton
* | □
[OPTIONAL] MATCH □ [WHERE □]
| WITH ret [WHERE □] | UNWIND □

Algorithm 2 The GenerateRandomQuery function
Input: 𝑆: the property graph schema;
Input: 𝐹 : the frequency list for property keys;
Output: 𝑄: the newly generated Cypher query.

1: 𝑁𝑜 ← Randomly determine the number of clauses.
2: 𝑆𝑘𝑒𝑙𝑒𝑡𝑜𝑛 ← GenerateSkeleton(𝑁𝑜 )
3: 𝑄 ← ∅
4: 𝐶𝑜𝑛𝑡𝑒𝑥𝑡 ← ∅
5: 𝑖 ← 0
6: while 𝑖 < 𝑁𝑜 do
7:

𝑂𝑠 ← Get the 𝑖-th clause in 𝑆𝑘𝑒𝑙𝑒𝑡𝑜𝑛.
𝑂𝑐 ← FillUninstantiatedPart(𝑂𝑠, 𝑆, 𝐹, 𝐶𝑜𝑛𝑡𝑒𝑥𝑡)
𝑄 ← Append 𝑂𝑐 to 𝑄.
𝐶𝑜𝑛𝑡𝑒𝑥𝑡 ← CalculateNewContext(𝑂𝑐 , 𝐶𝑜𝑛𝑡𝑒𝑥𝑡)
𝑖 ← 𝑖 + 1

8:

9:

10:

11:
12: end while
13: return 𝑄

GDsmith then randomly generates a property graph and insert
it into each engine instance under test. GDsmith specifies the num-
ber of nodes and relationships in the property graph, and then
sequentially generates property values in each node or relationship
based on the generated property graph schema. After graph gener-
ation, GDsmith also creates the same random indexes for all engine
instances under test.

3.2 Skeleton and its Completion
To address the semantic validity challenge, GDsmith includes a
skeleton-based completion technique to generate each Cypher
query. We refer to each clause sequence with uninstantiated parts
(e.g., patterns and expressions) as a skeleton, and an uninstanti-
ated part is denoted as the □ symbol. Specifically, the skeletons
generated by GDsmith are the languages that are produced by the
grammar of Table 2.

For example, the skeleton corresponding to the Cypher query in

Figure 1 is “MATCH □ WHERE □ RETURN □”.

The random generation of each Cypher query is divided into two
steps as shown in Algorithm 2. GDsmith firstly randomly generates
a Cypher skeleton (Lines 1-2). A skeleton is an incomplete Cypher
query conducted by a clause sequence with uninstantiated parts (i.e.,
“□”). All the skeletons can be considered as a language L𝑠𝑘𝑒𝑙𝑒𝑡𝑜𝑛
generated by the grammar shown in Table 2. L𝑠𝑘𝑒𝑙𝑒𝑡𝑜𝑛 is context-
free and thus the generation of a skeleton requires rarely additional
semantic information6. Therefore, GDsmith randomly generates

6Some graph database engines do not support Cypher queries where a OPTIONAL
MATCH clause is followed by a MATCH clause. GDsmith filters out such skeletons when
testing these graph database engines.

a clause sequence with uninstantiated parts appended by a RETURN
clause.

When filling the uninstantiated parts in the skeleton, GDsmith
calculates and maintains each clause’s context. A context includes
the following two kinds of information:

(1) Local environment: the local environment of each clause
is a set of variables available in the next clause. A variable
is an identifier that represents a vector of data defined in a
pattern or an alias definition (e.g., literals or entities). For
a MATCH clause, GDsmith adds the variables in the previous
clause’s local environment and the newly defined entity vari-
ables in node patterns and relationship patterns into its local
environment. For an UNWIND clause, GDsmith adds the vari-
ables in the previous clause’s local environment and the
newly defined variable (i.e., alias) into its local environment.
For a WITH or RETURN clause, GDsmith adds the variables de-
fined in expressions and aliases into its local environment.
Take the Cypher query in Figure 1 as an example, the local
environment of the MATCH clause is {user, r1, r2, fof}.
(2) Fact: the fact of each clause is the information collected
from the variable definition. A fact contains the data type
of each variable. GDsmith calculates a variable’s data type
by analyzing its definition. In detail, if a variable is defined
in node_pattern or rel_pattern, it is an entity. Otherwise,
the variable is defined as an alias of an expression. GDsmith
can then calculate the variable’s data type by analyzing the
expression’s output type. If a variable’s data type is a node,
GDsmith also maintains the label constraints of this variable
in the fact. If a variable’s data type is a relationship, GD-
smith also maintains the type constraints of this variable in
the fact. Take the Cypher query in Figure 1 as an example,
the label/type constraints in the fact of the MATCH clause is
{label(user) == [User], type(r1) == [FRIEND], type(r2)
== [FRIEND], label(fof) == [User]}.

Based on rich semantic information provided by the property
graph schema and the context of each clause, GDsmith is able to
make the generated uninstantiated parts satisfy the following three
semantic requirements:

(1) Variable scope correctness: a variable can be referenced
in a clause only when this variable is contained in the local
environment of the clause.

(2) Operand type safety: the operand type of each expression
must satisfy the type requirement of the expression. In ad-
dition, the combination of operands must assure the output
type of the expression is inferable at runtime.

(3) Property key safety: all property keys taken from entities

must exist in the property graph schema at runtime.

In detail, to ensure the three semantic requirements, GDsmith

uses the strategies to fill uninstantiated parts as follows (Line 8).

• If the current clause requires a pattern tuple, GDsmith dy-
namically generates a series of patterns for it. Each pattern
is constructed by a sub-graph described by entity variables.
GDsmith firstly generates a shape of the sub-graph (e.g., a
node with a relationship points to another node). For each
variable required in the shape, GDsmith either chooses a
defined variable in the previous clause’s local environment,

Conference’17, July 2017, Washington, DC, USA

Wei Lin, Ziyue Hua, Luyao Ren, Zongyang Li, Lu Zhang, and Tao Xie

or defines a new variable for it. Then, GDsmith randomly
adds new labels or types to these variables. Finally, GDsmith
randomly adds properties to these variables according to the
property graph schema and the related fact.

• If the current clause requires an expression with a specific
data type, GDsmith uses a top-down strategy to generate
the expression. An expression is a tree structure where each
tree node is a sub-expression. For each operand that requires
a sub-expression, GDsmith randomly chooses an expression
that satisfies the type requirement and generates the whole
sub-tree recursively. For each operand that requires a literal
value, GDsmith randomly generates a literal value of the
required type. For each operand that requires a variable ref-
erence, GDsmith searches for a variable with required type
from the context. If no suitable variable is found, GDsmith
discards the current sub-tree and re-generates it. The expres-
sion generation process is not stopped until all operands of
current expression tree are filled or the maximum depth is
reached.

After filling all uninstantiated parts in a clause, GDsmith will
calculate the context of this clause according to its definition to
guide the completion of the next clause (Line 10).

3.3 Structural Mutation Strategies
To address the non-empty result challenge, GDsmith leverages
three structural mutation strategies to increase the probability of
producing Cypher queries returning non-empty results. GDsmith
retains each generated Cypher query that returns non-empty re-
sults into a pool. These retained queries are used for producing new
queries via structural mutation strategies in the next stage. This
feedback increases the probability that a newly mutated query re-
turns non-empty results. In addition, GDsmith requires the number
of clauses in each retained query to be within an appropriate range.
A small number of clauses indicate that the Cypher query may be
simple and trivial, reducing the diversity of subsequent mutations
to produce new queries. A large number of clauses indicate that the
Cypher query may be complicated, reducing the efficiency of bug
detection because its mutants may take longer time to be executed.
GDsmith uses three types of mutation strategies to derive a new
Cypher query from an existing one, as shown in Algorithm 3. For
each call, this algorithm randomly applies one mutation strategy
to the original Cypher query. The detailed strategies are as follows.
(1) The DelayReturn strategy (Line 4) firstly change the RETURN
clause at the end of the clause sequence to a WITH clause (Line 5).
Then, it generates a new clause sequence and appends it at the end
of the sequence to form a completed Cypher query (Line 6). It uses
the same strategy in Algorithm 2 to complete uninstantiated parts
except that it takes the context at the end of original sequence as
the initial context.

For example, the selected query 𝑄𝑒 is

MATCH (n) RETURN n.k AS a;

After executing Lines 5-6, a new query 𝑄 is generated.

Algorithm 3 The MutatingExistingQuery function
Input: 𝑆: the property graph schema;
Input: 𝐹 : the frequency list for property keys;
Input: 𝑃𝑜𝑜𝑙: the retained query pool;
Output: 𝑄: the newly mutated Cypher query.

1: 𝑄𝑒 ← Randomly select a Cypher query from 𝑃𝑜𝑜𝑙.
2: 𝑄 ← ∅
3: 𝑇 ← Randomly choose a mutation strategy.
4: if 𝑇 = “𝐷𝑒𝑙𝑎𝑦𝑅𝑒𝑡𝑢𝑟𝑛” then
5:

𝑆𝑘𝑒𝑙𝑒𝑡𝑜𝑛 ← Change the RETURN clause in 𝑄𝑒 to WITH.
𝑄 ← Extend and complete 𝑆𝑘𝑒𝑙𝑒𝑡𝑜𝑛 based on 𝑆 and 𝐹 .

6:
7: else if 𝑇 = “𝐴𝑑𝑣𝑎𝑛𝑐𝑒𝑅𝑒𝑡𝑢𝑟𝑛” then
8:

𝑆𝑘𝑒𝑙𝑒𝑡𝑜𝑛 ← Change any WITH clause in 𝑄𝑒 to RETURN.
𝑄 ← Discard the followed clauses in 𝑆𝑘𝑒𝑙𝑒𝑡𝑜𝑛.

9:
10: else if 𝑇 = “𝑅𝑒𝑚𝑜𝑣𝑒𝐶𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛” then
11:
12: end if
13: return 𝑄

𝑄 ← Randomly remove WHERE conditions in 𝑄𝑒 .

MATCH (n) WITH n.k AS a RETURN COUNT(a);

The DelayReturn strategy heuristically makes a mutated query
more likely to return non-empty results than randomly generating
a new query with the same query length7.

(2) The AdvanceReturn strategy (Line 7) randomly chooses a
WITH clause in the original Cypher query and translates it to a
RETURN clause (Line 8). It then discards all the clauses following the
newly created RETURN clause (Line 9). When replacing a WITH clause
with RETURN, if the WITH clause contains a WHERE sub-clause, it will
be removed.

For example, the selected query 𝑄𝑒 is

MATCH (n)–>(m) WITH m.k AS a RETURN MAX(a);

After executing Lines 8-9, a new query 𝑄 is generated.

MATCH (n)–>(m) RETURN m.k AS a;

The AdvanceReturn strategy makes a mutated query return the
intermediate result set of the corresponding original query, greatly
increasing the probability of fetching non-empty results.

(3) The RemoveCondition strategy (Line 10) randomly removes
WHERE conditions from MATCH, OPTIONAL MATCH, or WITH clauses (Line
11), by nature increasing the probability of fetching non-empty
results.

For example, the selected query 𝑄𝑒 is

MATCH (n)–(m) WHERE m.k > 0 RETURN n.k;

After executing Line 11, a new query 𝑄 is generated.

7Query length refers to the number of clauses in the Cypher query (sub-clauses such
as WHERE and ORDER BY are not counted).

GDsmith: Detecting Bugs in Graph Database Engines

Conference’17, July 2017, Washington, DC, USA

MATCH (n)–(m) RETURN n.k;

3.4 Property Key Selection
To address the behavior diversity challenge, GDsmith dynamically
selects property keys according to their previous frequencies when
completing new skeletons. GDsmith maintains a frequency list
for property keys as feedback. In each iteration after generating
a property graph schema, all frequencies of property keys are set
to zero. When a new query contains property keys in its clauses
and returns non-empty results, the frequency list is automatically
updated. The frequency list for property keys guides the selection
of available property keys when filling uninstantiated parts of each
incomplete Cypher skeleton. The formula of each property key’s
selection probability is as follows, where 𝑃𝑖 is the selection proba-
bility of the 𝑖-th available property key, 𝐹𝑖 is the frequency of the
𝑖-th available property key, and 𝑁 is the total number of available
property keys.

𝑃𝑖 =

(cid:205)𝑁

𝑗=1 𝐹 𝑗 − 𝐹𝑖
𝑗=1 𝐹 𝑗

(1)

(𝑁 − 1) (cid:205)𝑁
This formula indicates that when specifying property keys from
the list of all available property keys to fill uninstantiated parts,
GDsmith preferentially selects the property keys with low frequen-
cies, so as to average the occurrence possibility of each property
key in a set of Cypher queries returning non-empty results. The
purpose is to cover diverse property values, thereby improving the
behavior diversity of randomly generated queries.

Note that traditional feedback-guided random testing approaches
usually use code coverage as feedback, which however does not
apply to testing graph database engines for two main reasons. First,
the code coverage appears to be low even if plenty of diverse queries
are executed [11]. It is reasonable because we concern about testing
only the engine components related to data-centric Cypher queries.
Other components such as interactive consoles are not the subjects
for GDsmith. Second, We expect GDsmith to be a black-box ap-
proach to strengthen its compatibility. If the source code of graph
database engines is unavailable or with language mixture, it is hard
to conduct code instrumentation to obtain the runtime information
such as code coverage.

3.5 Bug Detection
By comparing the returned results of the same Cypher query on
different instances of graph database engines, GDsmith is able to
detect two main types of bugs. (1) An error bug is triggered if a
syntactically correct and semantically valid query cannot be suc-
cessfully executed (e.g., throwing an exception). Such bugs prevent
users from obtaining expected results, and in more serious cases,
cause the graph database engine to crash and lose connection to
the database application. (2) A wrong-result bug is triggered if a
syntactically correct and semantically valid query is executed suc-
cessfully but returns incorrect results. Such bugs are more danger-
ous in that users mistakenly believe that the Cypher query returns
correct results and have wrong expectations about the behavior,
leading to potential risks.

Note that when GDsmith aims to detect wrong-result bugs, there
are several constraints for each Cypher query. First, the Cypher
query containing non-deterministic sub-clauses may result in false
alarms. For example, the result set will get trimmed from the top
by using the SKIP sub-clause. However, without an ORDER BY sub-
clause, the records are randomly selected because no guarantees
are made on the order of the result [19]. To avoid such false posi-
tives, GDsmith uses deterministic clauses and routines for query
generation. Second, undefined behaviors make it hard to determine
whether inconsistent results are bugs or just different implemen-
tations. For example, integer overflows and divisions by zero are
handled differently by different engines (e.g., returning NaN or throw-
ing exceptions). GDsmith will not generate the Cypher queries that
may execute such undefined behaviors. Third, for convenient and
efficient comparison, the Cypher query should return only a few
specific expressions instead of a large number of entities. For exam-
ple, when executing a Cypher query whose RETURN clause contains
the ★ symbol on each graph database engine, parsing and compar-
ing result sets including all nodes and relationships from different
clients are time-consuming because an entity may consist of plenty
of property values.

4 EVALUATIONS
In our evaluations, we address the following four research questions
(RQs):

• RQ1: How effective are the Cypher queries generated by

GDsmith?

• RQ2: How much do different techniques contribute to the

overall effectiveness and efficiency of GDsmith?

• RQ3: How much does GDsmith outperform the baseline?
• RQ4: How practicably does GDsmith detect real-world bugs

in popular graph database engines?

4.1 Evaluation Setup
Subjects. We opt for three popular real-world graph database
4.1.1
engines as our test subjects. We test the released versions of Neo4j
Community Edition from 3.5 to 4.4, the released versions of Redis-
Graph from 2.4 to 2.8, and the released version 2.1.1 of Memgraph
Community Edition. All of these subjects are downloaded from
their official repositories without any underlying modification.

Implementation. We implement the GDsmith prototype with
4.1.2
over 12K non-comment lines of Java code. Its framework is derived
from SQLancer [23] (which is a tool to automatically test relational
database engines). GDsmith uses Neo4j Java Driver 4.1.1 to connect
and interact with Neo4j and Memgraph, and uses JRedisGraph 2.5.1
to connect and interact with RedisGraph. Some graph database
engines implement only a subset of the Cypher language. When
conducting cross-engines differential testing, all Cypher queries
generated by GDsmith do not contain any Cypher feature that is
unsupported by either graph database engine. All evaluations are
conducted on a Windows 11 laptop with Intel i7-8565U CPU and
16 GB of memory.

Conference’17, July 2017, Washington, DC, USA

Wei Lin, Ziyue Hua, Luyao Ren, Zongyang Li, Lu Zhang, and Tao Xie

4.1.3 Baseline. Note that there is no applicable baseline to which
we can compare our work because no existing work focuses on de-
tecting bugs in graph database engines and GDsmith is the first ap-
proach for it. Therefore, we design the approach named GDsmith!𝑎
that only guarantees the syntactic correctness of generated queries
as the baseline. To produce a query, GDsmith!𝑎 randomly generates
a skeleton and then completes it with random parameters (semantic
requirements are not considered). It essentially falls under grammar-
based random testing.

4.1.4 Metrics. To measure the effectiveness and efficiency of GD-
smith, we design the following five types of metrics:

(1) The semantic validity rate is defined as the percentage
of semantically valid queries among all generated Cypher
queries. High semantic validity rate indicates that the gener-
ated queries can reach core parts of graph database engines.
(2) The core grammar coverage is defined as the percentage
of covered productions [2, 21] of semantically valid Cypher
queries among all productions in the core Cypher syntax [8,
9]. High semantic validity rate indicates that the generated
queries can cover diverse Cypher features.

(3) The non-empty result rate is defined as the percentage of
queries returning non-empty results among all generated
Cypher queries. High non-empty result rate indicates that
the generated queries are meaningful towards differential
testing, especially for detecting wrong-result bugs.

(4) The graph mutation score is defined as the number of
different killings of a set of graph mutants8 by generated
Cypher queries. Take three queries and three graph mutants
as an example, if the first query kills the first and the sec-
ond graph mutants, whereas both the second and the third
queries kill the first and the third graph mutants, the graph
mutation score of these three queries is two. High graph
mutation score indicates that the generated queries have
high behavior diversity.

(5) The bug detection efficiency is defined as the number of
unique bugs found within the same period. High bug detec-
tion efficiency indicates that the generated queries are able
to detect bugs at a high speed.

4.2 RQ1/RQ2: Effectiveness and Efficiency
To assess the effectiveness and efficiency of GDsmith, we design
and implement two variants of GDsmith for our evaluations. One
variant named GDsmith!𝑚 disables the structural mutation strate-
gies, and all generated queries are newly generated. The other
variant named GDsmith!𝑓 disables the feedback of property key fre-
quencies, and all property keys are randomly selected to complete
new skeletons. We conduct all the evaluations in this subsection
on Neo4j because Neo4j implements the most complete Cypher
semantics.

Semantic Validity Rate. We run the three approaches (includ-
4.2.1
ing GDsmith and two variants) five times in turn. In each run, 5000

8A graph mutant is generated by arbitrarily removing one property from the original
property graph. A graph mutant is killed as long as one Cypher query returns different
results from this graph mutant and the original graph.

Figure 3: The non-empty result rates of the three approaches
for different query lengths.

queries are generated. We count the number of Cypher queries that
do not throw any semantics-related exception during execution.

The evaluation results show that the semantic validity rates of the
three approaches are all 100%, demonstrating the effectiveness of
our designed techniques of skeleton completion to satisfy semantic
requirements. The results also confirm that GDsmith is able to reach
core parts of graph database engines.

4.2.2 Core Grammar Coverage. For each of the three approaches,
we produce 5000 Cypher queries and leverage Lark [30] (which is a
parsing toolkit for context-free languages) to parse each query and
calculate the core grammar coverage.

The evaluation results show that the core grammar coverage of
the three approaches all converges to 98%. Only three out of 122
productions are not covered in the core Cypher syntax because we
do not implement some Cypher features such as UNION clauses in
our prototype yet. The results confirm that GDsmith does not lose
any form of possible clause sequences and parameters within the
scope of our implementation.

4.2.3 Non-empty Result Rate. We run the three approaches ten
times in turn and in each run 5000 queries are randomly generated.
We limit the maximum number of entities in each property graph
to 10 and the minimum length of each Cypher query to 3 because
smaller graph and longer query make it harder to fetch non-empty
results.

Figure 3 shows the non-empty result rates of the three approaches
for different query lengths. The evaluation results show that among
all Cypher queries with lengths 3, 4, 5, and 6 generated by GDsmith,
the queries returning non-empty results account for 74%, 71%, 70%,
and 65%, respectively. GDsmith is able to produce 24% to 40% more
Cypher queries returning non-empty results than GDsmith!𝑚, and
produce only 1% to 5% more Cypher queries returning non-empty
results than GDsmith!𝑓 . The results illustrate that the structural mu-
tation strategies contributes the most to increasing the non-empty
result rate.

3456Query Length0%20%40%60%80%100%Non-Empty Result RateGDsmithGDsmith!mGDsmith!fGDsmith: Detecting Bugs in Graph Database Engines

Conference’17, July 2017, Washington, DC, USA

4.2.4 Graph Mutation Score. In this evaluation, we limit the min-
imum number of entities in each property graph to 20 and the
maximum number of Cypher queries to 800 because larger graphs
and fewer queries make it harder to cover more property values.

The evaluation results show that when generating 50 graph
mutants, the graph mutation score of GDsmith reaches 26, which
is 10% lower than the graph mutation score of GDsmith!𝑚 but 73%
higher than the graph mutation score of GDsmith!𝑓 . The results
illustrate that the feedback of property key frequencies contributes
to improving behavior diversity. But to some extent, the structural
mutation strategies sacrifice little behavior diversity of the mutated
queries to raise the probability of returning non-empty results.

4.2.5 Bug Detection Efficiency. We next examine the efficiency
of GDsmith in detecting bugs. We also investigate whether the
structural mutation strategies and the feedback of property key
frequencies increase the probability of bug detection. In this eval-
uation, we run each of the four approaches on the two instances
of Neo4j version 4.3.10 and Neo4j version 4.2.15, respectively. We
configure each run to a timeout of 30 minutes, because in practice
GDsmith spends less than 30 minutes finding each bug in real-world
graph database engines.

Within 30 minutes, GDsmith generates six bug reports (reduces
to two unique wrong-result bugs and one error bug), GDsmith!𝑚
generates two bug reports (reduces to only one error bug), and
GDsmith!𝑓 generates three bug reports (reduces to one wrong-
result bug and one error bug). The evaluation results show that
both the structural mutation strategies and the feedback of property
key frequencies have their impacts on helping GDsmith detect more
wrong-result bugs in graph database engines.

4.3 RQ3: Comparison with Baseline
We compare GDsmith with the baseline (i.e., GDsmith!𝑎) measured
with the aforementioned metrics. (1) After producing 5000 queries,
the semantic validity rate of the baseline reaches only 16% but its
core grammar coverage also converges to 98%. (2) Among all queries
with lengths 3, 4, 5, and 6 generated by the baseline, the queries
returning non-empty results account for 57%, 45%, 39%, and 25%,
respectively. (3) The graph mutation score of the baseline reaches
only 5. (4) Within 30 minutes, the baseline does not generate any
bug report.

The results illustrate that the baseline generates many more
semantically invalid queries than GDsmith. It lacks any feedback
guidance to produce high-quality Cypher queries for testing. There-
fore, GDsmith substantially outperforms the baseline with the high
effectiveness and efficiency of detecting bugs in graph database
engines.

4.4 RQ4: Practicability
Study Findings. Table 3 shows, for each subject, the number
4.4.1
of error bugs and wrong-result bugs detected in the second and
third columns, respectively, and the number of fixed bugs, con-
firmed but unfixed bugs, and reported but unconfirmed bugs in
the fourth, fifth, and sixth columns, respectively. GDsmith detects
27 previously unknown bugs in total. Note that all these bugs are
unique and detected on the released versions of the engines under
test. Among the 27 detected bugs, 14 are confirmed by developers of

Table 3: Bug Detection Results of GDsmith

Subject

Neo4j
RedisGraph
Memgraph
SUM

Err WR Fixed Confirmed Reported
9
0
4
13

8
5
5
18

5
2
0
7

7
2
0
9

1
5
1
7

corresponding engines and 7 are already fixed. In detail, GDsmith
detects 17 bugs by the cross-engine oracle, and detects 18 bugs by
the cross-version oracle (some are overlapping with the previous
oracle). GDsmith does not use the cross-optimization oracle be-
cause some engines do not provide optimization options or provide
optimization options in only their enterprise versions (not free).
But we are confident that GDsmith can use this oracle to detect
bugs in the enterprise versions.

Selected Bugs. Next, we show a selection of confirmed bugs
4.4.2
found by GDsmith to give an intuition on what kinds of bugs in the
three graph database engines it can detect. For brevity, we show
only reduced Cypher queries that demonstrate the underlying core
problem, rather than the original queries and property graphs that
found the bugs.

(1) The following Cypher query triggers an error bug in Neo4j
version 4.3.6 (which is de facto the first bug found by GDsmith).
The root cause is that the clause sequence “OPTIONAL MATCH (n)
MATCH (n) OPTIONAL MATCH (n)” causes an incorrect query plan due
to OPTIONAL MATCH issues. We believe that this bug is non-trivial,
since it demonstrates that even mature graph database engines are
prone to such simple query.

OPTIONAL MATCH (n) MATCH (n) OPTIONAL MATCH (n)
RETURN n;

(2) The following graph and Cypher query triggers a wrong-
result bug in Neo4j version 4.3.10. The returned results are not
sorted as expected. The root cause is that in the planning process
of Neo4j, a buggy optimization of the plan is conducted which ends
up destroying the sort. We believe that this bug is non-trivial, since
it demonstrates that wrong query optimization may trigger bugs.

CREATE (n0), (n1);
MATCH (n0) UNWIND [0, 1] AS a OPTIONAL MATCH (n0),
(n1) RETURN a ORDER BY a;

(3) The following graph and Cypher query triggers a wrong-
result bug in RedisGraph version 2.4.11. The Cypher query should
return 1 row but incorrectly returns an empty result set. The root
cause is that the clause sequence “MATCH (n) OPTIONAL MATCH (n)
WHERE (arbitrary branches)” mistakenly causes deletion of n. We
believe that this bug is non-trivial, since it demonstrates that a
WHERE sub-clause can incorrectly influence a query’s result set.

CREATE (n);
MATCH (n) OPTIONAL MATCH (n) WHERE true RETURN n;

Conference’17, July 2017, Washington, DC, USA

Wei Lin, Ziyue Hua, Luyao Ren, Zongyang Li, Lu Zhang, and Tao Xie

(4) The following graph and Cypher query triggers a wrong-
result bug in Memgraph version 2.1.1. The Cypher query should
return 1 row but incorrectly returns an empty result set. The root
cause is that the implementation of Memgraph is not consistent
with the standard semantics of Cypher language. The official docu-
mentation (i.e., Cypher Query Language Reference (Version 9) [19])
states that count(null) returns 0. We believe that this bug is non-
trivial, since it demonstrates that GDsmith is able to detect such
semantic inconsistency behaviors.

CREATE (n);
MATCH (n:L) RETURN count(n) > 0 AS a;

4.4.3 Developers’ Feedback. After we report our detected bugs to
the corresponding communities, developers of the three graph data-
base engines give responses for most of the reported bugs, all with
positive feedback. One of Neo4j core developers replies with the
following message for bugs reported by us: “Thank you for raising
with us in the first place ... The queries all look interesting ...” He
also said: “We are impressed by and very curious about the query
generator you have come up with. We have been paying particular
attention to the issues you have raised on our project.” One of Re-
disGraph core developers was amazed by the results and said: “I
guess you are developing some query-generator that automatically
compares results between different Cypher databases. If indeed, this
is quite interesting! Do you plan to share it on GitHub?” He also said:
“We, at Redis, find the tool you are developing very interesting ...” One
of Memgraph core developers replies with the following message
for bugs reported by us: “Aha, thanks for the reference ... I think
Memgraph is not consistent and we should fix the behavior (that’s a
win-win). We are trying to follow openCypher as much as possible.”
The feedback shows that our reported bugs are critical to the graph
database engines. The feedback from real-world developers is also
strong evidence that GDsmith is practical for testing real-world
graph database engines and able to detect critical bugs.

4.5 Threats to Validity
4.5.1 External Validity. The main threat to external validity is that
the subjects chosen in our evaluations might not be generalized
to other projects. To reduce the threat, we pick three well-known
and open-source graph database engines as representatives. Their
developers are active in open source communities and provide
timely feedback on bug reports that we have filed. In fact, GDsmith
is able to test any graph database engine supporting the Cypher
language.

Internal Validity. The main threat to internal validity lies
4.5.2
in the implementation of GDsmith. Not all Cypher features are
currently supported (e.g., UNION clauses). To mitigate the threat,
we investigate the covered Cypher language by multiple graph
database engines, and refer to the description of core Cypher’s syn-
tax and semantics in previous work, enabling GDsmith to support
commonly used grammars.

5 RELATED WORK
There are two main categories of related work for GDsmith.

Detecting Bugs in Critical Software Systems. Csmith [37] is
a random C program generator for testing C compilers. It uses a
sophisticated stochastical model to avoid generating C programs
that have undefined behavior. TVMfuzz [29] conducts mutation-
based fuzzing to test deep learning compilers with some novel
mutation operators to facilitate type-related bug detection. CYN-
THIA [33] detects bugs in object-relational mapping (ORM) imple-
mentations by employing a solver-based approach for generating
targeted database records with respect to the constraints of the gen-
erated queries. To detect bugs in Datalog engines, queryFuzz [14]
uses metamorphic transformations based on database theory and
performs metamorphic testing. OpFuzz [36] and TypeFuzz [20]
leverage different mutation strategies of formula generation to
test satisfiability modulo theory (SMT) solvers. Compared with
these approaches, GDsmith makes the first attempt to address the
challenges during automated test generation for graph database
engines (which also belong to critical software systems), and detects
27 previously unknown bugs.

Detecting Bugs in Relational Database Engines. SQLsmith [27]

continuously generates syntactically correct SQL queries from the
abstract syntax tree (AST) directly, meanwhile detecting whether
the relational database engine under test faces crashes. Squirrel [39]
combines coverage-based fuzzing and model-based generation. It
performs type-based mutations on the defined DSL and optimizes
for semantic validity with additional analysis. Ratel [35] is an
enterprise-level fuzzer that improves the feedback precision, en-
hances the robustness of input generation, and performs an on-line
investigation on the root cause of bugs with its industry-oriented
design. The aforementioned approaches can detect only crashing
bugs in relational database engines. To detect wrong-result bugs,
RAGS [31] generates and executes SQL queries in multiple rela-
tional database engines, meanwhile observes differences in the
output sets. Any inconsistency among results indicates at least
one relational database engine contains bugs. PQS [26] detects
wrong-result bugs by checking whether a specific record is fetched
correctly. NoREC [24] detects bugs in relational database engines
by applying a semantics-preserving transformation to a given SQL
query to disable the engine’s optimizations and addresses PQS’ high
implementation effort. TLP [25] derives multiple SQL queries that
compute a partial result of the initial query. By using a composition
operator, the partitions can be combined to yield the same result
as the original query; if the result differs, a bug in the relational
database engine has been detected. MutaSQL [3] generates test
cases by mutating a SQL query over a database instance into a
semantically equivalent query mutant, and checks the results re-
turned by the relational database engine under test. Compared with
these approaches, GDsmith includes our skeleton-based completion
technique to ensure that each randomly generated Cypher query
satisfies the semantic requirements. GDsmith also includes our
novel techniques to increase the probability of producing Cypher
queries returning non-empty results and improve the behavior di-
versity of generated queries, and these techniques are designed
according to unique features of the Cypher language.

GDsmith: Detecting Bugs in Graph Database Engines

Conference’17, July 2017, Washington, DC, USA

6 CONCLUSION
In this paper, we have introduced a new important problem of test-
ing graph database engines. We have proposed GDsmith, the first
black-box testing approach for detecting bugs in graph database
engines. We have implemented GDsmith in Java and evaluated it
against the baseline. The evaluation results demonstrate GDsmith’s
effectiveness and efficiency. We have also applied it to test three
popular open-source graph database engines, successfully detect-
ing 27 previously unknown bugs on the released versions and
receiving positive feedback from their developers.

In future work, we plan to improve our approach to support more
features of the Cypher language and detect more bugs in real-world
graph database engines. We also plan to conduct a comprehensive
empirical study of bugs in graph computing systems and design an
automated test generation approach for testing graph computing
systems.

REFERENCES
[1] N. Bourbakis. 1998. Artificial Intelligence and Automation. Artificial Intelligence

and Automation.

[2] Walter H. Burkhardt. 1967. Generating test programs from syntax. Computing 2,

1 (1967), 53–73. https://doi.org/10.1007/BF02235512

[3] Xinyue Chen, Chenglong Wang, and Alvin Cheung. 2020. Testing query execution
engines with mutations. In Proceedings of the 8th International Workshop on
Testing Database Systems, DBTest@SIGMOD 2020, Portland, Oregon, June 19, 2020,
Pinar Tözün and Alexander Böhm (Eds.). ACM, 6:1–6:5. https://doi.org/10.1145/
3395032.3395322

[4] Memgraph Community. 2022. Memgraph: Build modern, graph-based applica-
tions on top of your streaming data in minutes. https://github.com/memgraph/
memgraph

[5] Neo4j Community. 2022. Neo4j: Graphs for Everyone. https://github.com/neo4j/

neo4j

[6] The Apache Software Foundation. 2022. Cypher for Gremlin.

https:
//github.com/opencypher/cypher-for-gremlin/tree/master/tinkerpop/cypher-
gremlin-server-client

[7] The Apache Software Foundation. 2022. Gremlin Query Language.

https:

//tinkerpop.apache.org/gremlin.html

[8] Nadime Francis, Alastair Green, Paolo Guagliardo, Leonid Libkin, Tobias Lin-
daaker, Victor Marsault, Stefan Plantikow, Mats Rydberg, Martin Schuster, Petra
Selmer, and Andrés Taylor. 2018. Formal Semantics of the Language Cypher.
CoRR abs/1802.09984 (2018). arXiv:1802.09984 http://arxiv.org/abs/1802.09984
[9] Nadime Francis, Alastair Green, Paolo Guagliardo, Leonid Libkin, Tobias Lin-
daaker, Victor Marsault, Stefan Plantikow, Mats Rydberg, Petra Selmer, and
Andrés Taylor. 2018. Cypher: An Evolving Query Language for Property
Graphs. In Proceedings of the 2018 International Conference on Management of
Data, SIGMOD Conference 2018, Houston, TX, USA, June 10-15, 2018, Gautam
Das, Christopher M. Jermaine, and Philip A. Bernstein (Eds.). ACM, 1433–1445.
https://doi.org/10.1145/3183713.3190657

[10] Bogdan Ghit, Nicolás Poggi, Josh Rosen, Reynold Xin, and Peter A. Boncz.
2020. SparkFuzz: searching correctness regressions in modern query engines.
In Proceedings of the 8th International Workshop on Testing Database Systems,
DBTest@SIGMOD 2020, Portland, Oregon, June 19, 2020, Pinar Tözün and Alexan-
der Böhm (Eds.). ACM, 1:1–1:6. https://doi.org/10.1145/3395032.3395327
[11] Jinho Jung, Hong Hu, Joy Arulraj, Taesoo Kim, and Woon-Hak Kang. 2019.
APOLLO: Automatic Detection and Diagnosis of Performance Regressions in
Database Systems. Proc. VLDB Endow. 13, 1 (2019), 57–70. https://doi.org/10.
14778/3357377.3357382

[12] Lior Kogan. 2017. V1: A Visual Query Language for Property Graphs. CoRR
abs/1710.04470 (2017). arXiv:1710.04470 http://arxiv.org/abs/1710.04470
[13] Takahiro Konno, Runhe Huang, Tao Ban, and Chuanhe Huang. 2017. Goods
recommendation based on retail knowledge in a Neo4j graph database combined
with an inference mechanism implemented in jess. In 2017 IEEE SmartWorld,
Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable
Computing & Communications, Cloud & Big Data Computing, Internet of People and
Smart City Innovation, SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI 2017,
San Francisco, CA, USA, August 4-8, 2017. IEEE, 1–8. https://doi.org/10.1109/UIC-
ATC.2017.8397433

[14] Muhammad Numair Mansur, Maria Christakis, and Valentin Wüstholz. 2021.
Metamorphic testing of Datalog engines. In ESEC/FSE ’21: 29th ACM Joint Eu-
ropean Software Engineering Conference and Symposium on the Foundations of

Software Engineering, Athens, Greece, August 23-28, 2021, Diomidis Spinellis, Geor-
gios Gousios, Marsha Chechik, and Massimiliano Di Penta (Eds.). ACM, 639–650.
https://doi.org/10.1145/3468264.3468573

[15] William M. McKeeman. 1998. Differential Testing for Software. Digit. Tech.
http://www.hpl.hp.com/hpjournal/dtj/vol10num1/

J. 10, 1 (1998), 100–107.
vol10num1art9.pdf

[16] Memgraph. 2022. Memgraph: Frictionless, Innovative, Graph Applications. https:

//memgraph.com/

[17] Chaitanya Mishra and Nick Koudas. 2009.

Interactive query refinement. In
EDBT 2009, 12th International Conference on Extending Database Technology, Saint
Petersburg, Russia, March 24-26, 2009, Proceedings (ACM International Confer-
ence Proceeding Series, Vol. 360), Martin L. Kersten, Boris Novikov, Jens Teub-
https:
ner, Vladimir Polutin, and Stefan Manegold (Eds.). ACM, 862–873.
//doi.org/10.1145/1516360.1516459

[18] Neo4j. 2022. The Fastest Path To Graph Productivity: Neo4j Graph Database.

https://neo4j.com/product/neo4j-graph-database/

[19] The openCypher Implementers Group. 2022. Cypher Query Language Reference,
Version 9. https://s3.amazonaws.com/artifacts.opencypher.org/openCypher9.pdf
[20] Jiwon Park, Dominik Winterer, Chengyu Zhang, and Zhendong Su. 2021. Gener-
ative type-aware mutation for testing SMT solvers. Proc. ACM Program. Lang. 5,
OOPSLA (2021), 1–19. https://doi.org/10.1145/3485529

[21] Paul and Purdom. 1972. A sentence generator for testing parsers. Bit Numerical

Mathematics (1972).

[22] RedisGraph. 2022. RedisGraph - a graph database module for Redis.

https:

//oss.redis.com/redisgraph/

[23] Manuel Rigger. 2022. SQLancer: Detecting Logic Bugs in DBMS. https://github.

com/sqlancer/sqlancer

[24] Manuel Rigger and Zhendong Su. 2020. Detecting optimization bugs in database
engines via non-optimizing reference engine construction. In ESEC/FSE ’20: 28th
ACM Joint European Software Engineering Conference and Symposium on the
Foundations of Software Engineering, Virtual Event, USA, November 8-13, 2020,
Prem Devanbu, Myra B. Cohen, and Thomas Zimmermann (Eds.). ACM, 1140–
1152. https://doi.org/10.1145/3368089.3409710

[25] Manuel Rigger and Zhendong Su. 2020. Finding bugs in database systems via
query partitioning. Proc. ACM Program. Lang. 4, OOPSLA (2020), 211:1–211:30.
https://doi.org/10.1145/3428279

[26] Manuel Rigger and Zhendong Su. 2020. Testing Database Engines via Pivoted
Query Synthesis. In 14th USENIX Symposium on Operating Systems Design and Im-
plementation, OSDI 2020, Virtual Event, November 4-6, 2020. USENIX Association,
667–682. https://www.usenix.org/conference/osdi20/presentation/rigger
[27] Andreas Seltenreich. 2022. Bug Squashing with SQLsmith. https://github.com/

anse1/sqlsmith

[28] Sudipta Sen, Akash Mehta, Runa Ganguli, and Soumya Sen. 2021. Recommenda-
tion of Influenced Products Using Association Rule Mining: Neo4j as a Case Study.
SN Comput. Sci. 2, 2 (2021), 74. https://doi.org/10.1007/s42979-021-00460-8
[29] Qingchao Shen, Haoyang Ma, Junjie Chen, Yongqiang Tian, Shing-Chi Cheung,
and Xiang Chen. 2021. A comprehensive study of deep learning compiler bugs. In
ESEC/FSE ’21: 29th ACM Joint European Software Engineering Conference and Sym-
posium on the Foundations of Software Engineering, Athens, Greece, August 23-28,
2021, Diomidis Spinellis, Georgios Gousios, Marsha Chechik, and Massimiliano Di
Penta (Eds.). ACM, 968–980. https://doi.org/10.1145/3468264.3468591

[30] Erez Shinan. 2022. Lark - a parsing toolkit for Python. https://github.com/lark-

parser/lark

[31] Donald R. Slutz. 1998. Massive Stochastic Testing of SQL. In VLDB’98, Proceedings
of 24rd International Conference on Very Large Data Bases, August 24-27, 1998,
New York City, New York, USA, Ashish Gupta, Oded Shmueli, and Jennifer Widom
(Eds.). Morgan Kaufmann, 618–622. http://www.vldb.org/conf/1998/p618.pdf

[32] solid IT gmbh. 2022. DB-Engines Ranking of Graph DBMS. https://db-engines.

com/en/ranking/graph+dbms

[33] Thodoris Sotiropoulos, Stefanos Chaliasos, Vaggelis Atlidakis, Dimitris Mitropou-
los, and Diomidis Spinellis. 2021. Data-Oriented Differential Testing of Object-
Relational Mapping Systems. In 43rd IEEE/ACM International Conference on Soft-
ware Engineering, ICSE 2021, Madrid, Spain, 22-30 May 2021. IEEE, 1535–1547.
https://doi.org/10.1109/ICSE43902.2021.00137

[34] Jian Wang, Ke Wang, Jing Li, Jianmin Jiang, Yanfei Wang, Jing Mei, and Shaochun
Li. 2020. Accelerating Epidemiological Investigation Analysis by Using NLP and
Knowledge Reasoning: A Case Study on COVID-19. In AMIA 2020, American
Medical Informatics Association Annual Symposium, Virtual Event, USA, November
14-18, 2020. AMIA. https://knowledge.amia.org/72332-amia-1.4602255/t003-
1.4606204/t003-1.4606205/3417206-1.4606266/3415131-1.4606263

[35] Mingzhe Wang, Zhiyong Wu, Xinyi Xu, Jie Liang, Chijin Zhou, Huafeng Zhang,
and Yu Jiang. 2021. Industry Practice of Coverage-Guided Enterprise-Level DBMS
Fuzzing. In 43rd IEEE/ACM International Conference on Software Engineering:
Software Engineering in Practice, ICSE (SEIP) 2021, Madrid, Spain, May 25-28, 2021.
IEEE, 328–337. https://doi.org/10.1109/ICSE-SEIP52600.2021.00042

[36] Dominik Winterer, Chengyu Zhang, and Zhendong Su. 2020. On the unusual
effectiveness of type-aware operator mutations for testing SMT solvers. Proc.
ACM Program. Lang. 4, OOPSLA (2020), 193:1–193:25. https://doi.org/10.1145/

Conference’17, July 2017, Washington, DC, USA

Wei Lin, Ziyue Hua, Luyao Ren, Zongyang Li, Lu Zhang, and Tao Xie

3428261

[37] Xuejun Yang, Yang Chen, Eric Eide, and John Regehr. 2011. Finding and under-
standing bugs in C compilers. In Proceedings of the 32nd ACM SIGPLAN Conference
on Programming Language Design and Implementation, PLDI 2011, San Jose, CA,
USA, June 4-8, 2011, Mary W. Hall and David A. Padua (Eds.). ACM, 283–294.
https://doi.org/10.1145/1993498.1993532

[38] Michal Zalewski. 2022. american fuzzy lop (2.52b). https://lcamtuf.coredump.

cx/afl/

[39] Rui Zhong, Yongheng Chen, Hong Hu, Hangfan Zhang, Wenke Lee, and Dinghao
Wu. 2020. SQUIRREL: Testing Database Management Systems with Language
Validity and Coverage Feedback. In CCS ’20: 2020 ACM SIGSAC Conference on
Computer and Communications Security, Virtual Event, USA, November 9-13, 2020,
Jay Ligatti, Xinming Ou, Jonathan Katz, and Giovanni Vigna (Eds.). ACM, 955–970.
https://doi.org/10.1145/3372297.3417260

