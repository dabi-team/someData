A multiplicity-preserving crossover operator on graphs
Extended version

Henri Th√∂lke
Thoelke@students.uni-marburg.de
Philipps-Universit√§t Marburg
Marburg, Germany

Jens Kosiol
kosiolje@mathematik.uni-marburg.de
Philipps-Universit√§t Marburg
Marburg, Germany

2
2
0
2

g
u
A
3
2

]
E
N
.
s
c
[

1
v
1
8
8
0
1
.
8
0
2
2
:
v
i
X
r
a

ABSTRACT
Evolutionary algorithms usually explore a search space of solutions
by means of crossover and mutation. While a mutation consists
of a small, local modification of a solution, crossover mixes the
genetic information of two solutions to compute a new one. For
model-driven optimization (MDO), where models directly serve as
possible solutions (instead of first transforming them into another
representation), only recently a generic crossover operator has
been developed. Using graphs as a formal foundation for models,
we further refine this operator in such a way that additional well-
formedness constraints are preserved: We prove that, given two
models that satisfy a given set of multiplicity constraints as input,
our refined crossover operator computes two new models as output
that also satisfy the set of constraints.

CCS CONCEPTS
‚Ä¢ Computing methodologies ‚Üí Randomized search; ‚Ä¢ Soft-
ware and its engineering ‚Üí Search-based software engineering.

KEYWORDS
evolutionary algorithms, crossover, model-driven optimization, con-
sistency-preservation

1 INTRODUCTION
Model-driven optimization (MDO) performs optimization directly
on domain-specific models. Early motivation for developing MDO
has been that modeling allows for a very expressive representa-
tion of optimization problems and their solutions across different
domains; at the same time, it allows expressing problems and solu-
tions in domain-specific (modeling) languages, potentially making
optimization more accessible for domain experts, e.g., [6, 7, 16].
Furthermore, the explicit representation as a model enables one
to leverage domain knowledge to explore the search space more
effectively [16, 27]. While already been used in [16], there has been
increased awareness recently that MDO makes the search and its
employed operators amenable to the application of formal methods:
exploiting the formal grounding that graphs, graph transformations,
and logics on graphs provide for models, their transformations, and
their properties, properties of search operators or the whole search
process can be tested or even formally verified [5, 17, 19, 25].

In practical applications of MDO, often evolutionary algorithms
have been used to perform the actual optimization, e.g., [1, 2, 12, 17].
In an evolutionary algorithm, normally crossover and mutation drive
the search (see, e.g., [11]): Typically, given an objective (or fitness)
function (or a set of these) that formalizes the properties to be opti-
mized, an evolutionary algorithm starts with an initial population

of randomly generated solutions. Then, until a termination condi-
tion is met, a new population is computed from the current one.
For that, pairs of solutions are randomly selected from the current
population, to which crossover is applied with a certain proba-
bility; solutions with high fitness have a higher chance of being
selected. Crossover recombines parts of the two solutions, mixing
their genetic information. After crossover, the computed offspring
can additionally be subjected to mutation, where small local changes
are performed. From the old population and the newly computed
solutions the next population is randomly selected, again taking the
fitness of individual solutions (but possibly also other considera-
tions like maintenance of diversity) into account. An optimization
problem can also be constrained, meaning that additional feasibility
constraints restrict which solutions are considered to be feasible. In
the context of evolutionary algorithms, various approaches have
been suggested to deal with feasibility constraints [8, 22]. These
include immediately discarding infeasible solutions, developing
methods to repair them, decrementing their fitness (according to
the amount of violation of the feasibility constraints), or designing
crossover and mutation operators in such a way that feasibility of
solutions is always preserved.

In MDO, so far, model transformations have served as the primary
means to perform evolutionary search [1, 2, 5, 12, 16, 17, 19]. But, as
we will argue in more detail later (see Sect. 2), performing crossover
directly on models has not been adequately developed yet. Recently,
a generic crossover operator on graphs, which can serve as a basis
for crossover on models, has been introduced [25]; in the follow-
ing, we refer to this operator as generic crossover. When applying
generic crossover to two models, it is guaranteed that the com-
puted offspring at least conforms to the structure that is specified
by the given meta-model. However, meta-models, including those
that provide a syntax for the solution of optimization problems,
are typically equipped with additional well-formedness (or, in this
context, feasibility) constraints. The most basic and important of
these are multiplicities, restricting the allowed incidence relations
in instance models. The generic crossover operator does not take
any feasibility constraints into account, i.e., solutions computed
via crossover might violate the given constraints, even if the input
solutions satisfied these. In this work, we refine the generic crossover
operator from [25] towards secure crossover in such a way that it
cannot any longer introduce violations of multiplicity constraints.
Practical experience in MDO with evolutionary algorithms that are
solely based on mutation as an operator shows that evolutionary
search can profit if the used mutation rules cannot introduce new
violations of feasibility constraints [5, 17, 19]. Therefore, developing
crossover of models in such a way that feasibility is preserved is a
promising enterprise.

 
 
 
 
 
 
The direct contribution of this work is this refinement of an ex-
isting crossover operator on graphs in such a way that it preserves
the validity of multiplicity constraints. By detailedly developing the
according algorithms and formally proving their desired properties,
we further substantiate the intuition that using models directly
as representation of solutions of an optimization problem facil-
itates the reasoning about search operators and processes. It is
hardly conceivable to develop a crossover operator that preserves
multiplicities when models are encoded, e.g., as bit strings. A few
algorithmic details are transferred to Appendix A. All proofs (and
some additional results) are provided in Appendix B.

2 RELATED WORK
In this work, we develop a crossover operator on graphs that pre-
serves multiplicities. Generally, this operator refines the one intro-
duced in [25]; it is also inspired by crossover operators on permuta-
tions (see, e.g., [24]) to only compute one offspring. In the following,
we discuss how crossover has been performed in MDO so far, and
we discuss other crossover operators on graphs (or similar struc-
tures).

Crossover in MDO. In MDO, two encoding approaches have
emerged: the rule- and the model-based approach [18]. In the rule-
based approach (e.g., [1, 2, 4, 12, 16]), the data structure on which
optimization is performed is a sequence of applications of model
transformation rules. Such sequences also represent models (by
applying the sequence to a fixed start model). Since the chosen rep-
resentation is a sequence, classic crossover operators like ùëò-point
or universal crossover are directly applicable. However, crossovers
may result in a sequence of transformations that is not applicable to
the start model. Repair techniques have been suggested to mitigate
that problem: inapplicable transformations of a sequence can be
discarded [1] or replaced by placeholders or random applicable
transformations [4]. These repairs, however, only serve to obtain
a sequence of applicable model transformations. Whether or not
the model that a sequence of transformations computes satisfies
feasibility constraints remains unclear.

In the model-based approach (e.g., [5, 17, 27]), optimization is
directly performed on models. Model transformation rules serve
as mutation operators. Zschaler and Mandow have suggested that
ideas from model differencing and merging could serve as basis for
a crossover operator directly applicable to models [27]. However,
except for a specific application in which crossover has been based
on transformation rules [17], evolutionary search on models as
search space has been performed via mutation only [5, 18, 19]. To
address this situation, we first developed the mentioned generic
crossover operator for graph-like structures [25]. Being generic and
based on graphs, it can serve as a formal foundation for crossover
operators on models, independently of their semantics or the em-
ployed modeling technology. However, its application can introduce
violations of feasibility constraints.

In parallel work [20], we suggest how to adapt that generic
crossover operator to models from the Eclipse Modeling Frame-
work (EMF) [9]. We ensure that the results of crossover conform to
the general structure of EMF models; however, we do not take addi-
tional well-formedness constraints like multiplicities into account.
In a first small evaluation, evolutionary search can profit from using

Henri Th√∂lke and Jens Kosiol

Figure 1: Metamodel (type graph) for the CRA case

both crossover and mutation (compared to only using mutation)
but only if violations of feasibility constraints that crossover intro-
duced are immediately repaired. Crossover hampers search when
used without repair. These results indicate that directly preserving
multiplicities, like we suggest in the current work, is a promising
enterprise. If possible, directly preserving constraints is a more
general approach as ad hoc repair operations might not always be
available.

Crossover on graphs. There are various approaches to crossover
on graphs (or similar structures), more often than not with a specific
semantics of the considered graphs in mind. Since we address typed
graphs and multiplicity constraints, which are both very general
concepts, we restrict our comparison to other crossover operators
that generally work on graphs and do not depend (too much) on
their assumed semantics. Crossover operators of which we are
aware that can be quite generically applied to graphs are [14, 21, 23].
In [14], connectedness properties of a graph are preserved, while
in [23] heuristics are used to increase the likelihood of preserving
acyclicity or certain reachability properties. In [21], no preservation
of constraints is addressed. To the best of our knowledge, we are the
first to formally ensure the preservation of such complex properties
as multiplicities for a crossover operator on graphs.

3 RUNNING EXAMPLE
The class responsibility assignment (CRA) case is an easy to grasp
use case for MDO that is still practically interesting. Having been
suggested as a contest problem in [13], it continues to be used as a
problem to illustrate new concepts in MDO with and to benchmark
them against [5, 19].

In the CRA case, a set of Features, representing Attributes and
Methods, and their interdependencies are given. It is searched for an
optimal assignment of the Features to Classes. Typically, a solution
is considered to be of high quality if its assignment of Features
to Classes exhibits low coupling between the Classes and high
cohesion inside of them; for details and a formalization of coupling
and cohesion as objective functions we refer to [13].

Fig. 1 depicts a metamodel (or type graph) that provides a syn-
tax to represent concrete problem instances and solutions for the
CRA case as models (for brevity, it is considerably simplified com-
pared to the metamodel provided in [13]). The black nodes serve to
model problem instances, namely a set of Features and their interde-
pendencies. The blue, dashed elements (Classes and their incident
edges) serve to extend problem instances to solutions, namely to
assign Features to Classes. The multiplicities serve to further pre-
scribe which instances of the metamodel are to be considered as
valid (or feasible) solutions. In our example they express that every
Class should at least encapsulate one Feature (1..‚àó) and that every
Feature should be encapsulated by exactly one Class (1..1).

ClassFeature1..*1..1encapsulatesdependsOn1A multiplicity-preserving crossover operator on graphs

4 PRELIMINARIES
In this section we present our formal preliminaries, namely graphs,
computation elements with multiplicities, which serve as a formal
basis for models, and the generic crossover operator that we refine
in this work.

Definition 4.1 (Graph. Graph morphism). A (directed) graph ùê∫ =
(ùëâ , ùê∏, src, tar ) consists of finite sets of nodes ùëâ and edges ùê∏, and
source and target functions src, tar : ùê∏ ‚Üí ùëâ .

Given two graphs ùê∫ and ùêª , a graph morphism ùëì = (ùëìùëâ , ùëìùê∏ ) : ùê∫ ‚Üí
ùêª is a pair of functions ùëìùëâ : ùëâùê∫ ‚Üí ùëâùêª and ùëìùê∏ : ùê∏ùê∫ ‚Üí ùê∏ùêª such that
ùëìùëâ (srcùê∫ (ùëí)) = srcùêª (ùëìùê∏ (ùëí)) and ùëìùëâ (tarùê∫ (ùëí)) = tar ùêª (ùëìùê∏ (ùëí)) for
all edges ùëí ‚àà ùê∏ùê∫ . A graph morphism is injective/surjective/bijective
if both of its components are.

A typed graph is a graph together with a graph morphism into
a fixed type graph. Intuitively, the type graph provides the avail-
able types for nodes and edges and their allowed incidence re-
lations. Using typing to provide graphs with a richer syntax is
well-established [10], in particular also when using typed graphs
as formal basis for models [3]. For our application, however, it is
advantageous to consider type graphs with more structure: Some el-
ements of the type graph serve to model the problem that has to be
optimized and others to create a solution. Encoding this distinction
into the type graph has led to the definition of computation type
graphs and their computation graphs [19, 25]. Multiplicities allow
expressing certain structural constraints (namely, lower and upper
bounds on edge types) that cannot be captured by typing alone;
a graph-based formalization is provided in [26]. In the following
definition of a computation type graph with multiplicities and its
computation graphs we bring together the definition of a type graph
with multiplicities with the one of computation (type) graphs.

Definition 4.2 (Computation type graph with multiplicities. Com-
putation graph). A multiplicity is a pair [ùëñ, ùëó] ‚àà N √ó (N ‚à™ {‚àó}) such
that ùëñ ‚â§ ùëó or ùëó = ‚àó; Mult denotes the set of all multiplicities. A set
ùëã satisfies a multiplicity ùëö = [ùëñ, ùëó] if |ùëã | ‚â• ùëñ and either |ùëã | ‚â§ ùëó or
ùëó = ‚àó; this satisfaction is denoted as |ùëã | ‚àà ùëö. Via ùëölb and ùëöub we
denote the projections to the first or second component.

A computation type graph with multiplicities is a tuple TG =
(TG P ‚äÜ TG, ùëösrc, ùëötar), where TG is a graph, TG P a des-
ignated subgraph, and ùëösrc, ùëötar : ùê∏TG ‚Üí Mult are functions,
called edge multiplicity functions. The graph TG is called the type
graph, and TG P the problem type graph.

A computation graph ùê∫ = (ùê∫, ùë°ùê∫ ) over TG is a graph ùê∫ together
with a graph morphism ùë°ùê∫ : ùê∫ ‚Üí TG. The intersection of ùê∫ with
TG P (in TG) is called the problem graph of ùê∫ and is denoted as ùê∫P.
A morphism ùëì : ùê∫ ‚Üí ùêª between computation graphs ùê∫ = (ùê∫, ùë°ùê∫ )
and ùêª = (ùêª, ùë°ùêª ) is a graph morphism ùëì : ùê∫ ‚Üí ùêª such that ùë°ùêª ‚ó¶ ùëì =
ùë°ùê∫ .

A computation graph ùê∫ = (ùê∫, ùë°ùê∫ ) typed over TG is said to satisfy
the multiplicities of a computation type graph with multiplicities
(TG P ‚äÜ TG, ùëösrc, ùëötar) if

‚Ä¢ for all edges ùëí ‚àà ùê∏TG and all nodes ùëù ‚àà {ùëõ ‚àà ùëâùê∫ | ùë°ùê∫ (ùëõ) =

srcTG (ùëí)} it holds that
|{ùëí ‚Ä≤ ‚àà ùê∏ùê∫ | ùë°ùê∫ (ùëí ‚Ä≤) = ùëí and srcùê∫ (ùëí ‚Ä≤) = ùëù}| ‚àà ùëötar (ùëí)
and

Figure 2: Two computation graphs for the CRA case that con-
stitute solutions for the same problem instance

‚Ä¢ for all edges ùëí ‚àà ùê∏TG and all nodes ùëù ‚àà {ùëõ ‚àà ùëâùê∫ | ùë°ùê∫ (ùëõ) =

tar TG (ùëí)} it holds that
|{ùëí ‚Ä≤ ‚àà ùê∏ùê∫ | ùë°ùê∫ (ùëí ‚Ä≤) = ùëí and tarùê∫ (ùëí ‚Ä≤) = ùëù}| ‚àà ùëösrc (ùëí).

A computation graph defines a problem instance via its prob-
lem graph; (candidate) solutions are all computation graphs with
coinciding problem graphs.

Definition 4.3 (Problem instance. Search space. Solution). Given
a computation type graph with multiplicities ùëáùê∫ = (TG P ‚äÜ
TG, ùëösrc, ùëötar), a problem instance for TG is a computation graph
PI over TG. The search space S(PI ) defined by PI consists of all
computation graphs ùê∫ over TG for which there exists (a typing-
compatible) isomorphism between the problem graphs ùê∫P and
PI P; elements of S(PI ) are called candidate solutions, or solutions
for short, for the problem instance PI . A solution is feasible if it
satisfies the multiplicity constraints of TG and infeasible otherwise.
Example 4.4. Formally, the metamodel for the CRA case depicted
in Fig. 1 can considered to be a computation type graph with mul-
tiplicities; the black elements constitute the problem type graph;
the multiplicity functions are defined by the annotations of the
edges. Fig. 2 presents two feasible computation graphs ùê∫ and ùêª .
The typing is indicated by denoting the nodes with their types;
edge types are omitted for brevity (they can unambiguously be
inferred). The identifiers f1 etc. just serve to be able to speak about
the individual elements. Because the problem graphs of ùê∫ and ùêª
(the black Features plus edge) coincide, they constitute (feasible)
solutions for the same problem instance.

Summarizing, our setting is that a fixed meta-model with mul-
tiplicities provides the syntax to model different instances of an
optimization problem and their solutions. In our example, the gen-
eral optimization problem is the CRA case and concrete problem
instances are different configurations of Features and their inter-
dependencies for which an optimal assignment to Classes has to
be found. Generally, the problem model of an instance model de-
termines for which problem instance this model is a solution, i.e.,
to which search space it belongs. Evolutionary search, then, is per-
formed for a concrete problem instance, i.e., inside of a fixed search
space, which is determined by the isomorphic problem models of

f1:Featuref2:Featuref3:Featurec1:Classùê∫f1:Featuref2:Featuref3:Featurec2:Classc3:Classc4:Classùêª1its members. As mentioned in Sects. 1 and 2, it is established to
use model transformations (which do not change the problem part)
as mutation operators during evolutionary search. This paper is
concerned with developing a crossover operator that takes two
solutions from the same search space as input and computes off-
spring solutions that belong to the same search space. At that the
crossover operator shall produce feasible offsprings from feasible
input.

As foundation for that, we recall the generic crossover operator
that has been introduced in [25]. There, crossover is declaratively
defined and no constructive algorithm is provided; furthermore,
it is defined in an abstract category-theoretic setting. Intuitively,
that crossover operator prescribes that two input solutions are to
be split into two parts each and these parts are to be recombined
crosswise by computing a union. This results in two new solutions,
also called offspring. A crossover point serves to identify elements
from the two input solutions, i.e., it designates elements that are
only to appear once in the union. The next definition specializes
generic crossover to computation graphs.

Definition 4.5 (Generic crossover). Given a computation type
graph with multiplicities TG, a problem instance PI for it, and two
solutions ùê∫ and ùêª from S(PI ), applying generic crossover amounts
to the following:

(1) Splitting: The underlying graph ùê∫ of ùê∫ is split into two sub-

graphs ùê∫1, ùê∫2 ‚äÜ ùê∫ such that
(a) both ùê∫1 and ùê∫2 contain ùê∫P and
(b) every element of ùê∫ belongs to either ùê∫1 or ùê∫2 (or both).
ùê∫1 and ùê∫2 become computation graphs by defining their
typing morphisms as the respective restrictions of ùë°ùê∫ . The
intersection ùê∫I of ùê∫1 and ùê∫2 (in ùê∫) is called split point. The
graph ùêª is split in the same way.

(2) Relating ùê∫ and ùêª (crossover point): A further solution for
PI , i.e., a computation graph CP = (CP, ùë°CP ) with prob-
lem graph CP P being isomorphic to PI P is determined
such that CP can be considered to be a subgraph of both
split points ùê∫I and ùêªI. Formally, this means that there are
injective morphisms from CP to ùê∫I and ùêªI. The solution
CP (together with the two injective morphisms) is called a
crossover point.

(3) Recombining: The underlying graph ùê∫1ùêª2 of the first off-
spring solution ùê∫1ùêª2 is computed as the union of ùê∫1 and
ùêª2 over CP . That is, elements from ùê∫1 and ùêª2 that share
a preimage in CP only appear once in the result. A typing
morphism ùë°ùê∫1ùêª2 : ùê∫1ùêª2 ‚Üí TG is obtained by combining
the ones of ùê∫1 and ùêª2; hence, a computation graph ùê∫1ùêª2 is
computed. A second offspring solution ùê∫2ùêª1 is computed
analogously by unifying ùê∫2 and ùêª1 over CP .

The results obtained in [25] ensure that the two offspring so-
lutions computed in that way are indeed solutions for the given
problem model PI : their typing morphisms are well-defined and
their problem graphs are isomorphic to PI P [25, Prop. 2]. More-
over, no matter how the splits of the input graphs ùê∫ and ùêª are
chosen, a crossover point can be found; thus, crossover is always
applicable [25, Lem. 1]. Albeit, the computed offspring does not

Henri Th√∂lke and Jens Kosiol

Figure 3: Two computation graphs resulting as offspring
from generic crossover

need to satisfy the given multiplicity constraints, even if the inputs
ùê∫ and ùêª and/or the split parts ùê∫1, ùê∫2, ùêª1, ùêª2 do.

Example 4.6. Figure 3 depicts two solutions that can result from
applying generic crossover to the computation graphs ùê∫ and ùêª from
Fig. 2. In the corresponding computations, ùê∫ is split such that ùê∫1
does not contain the reference from Class c1 to Feature f3 and ùê∫2
is the whole of ùê∫. Consequently, ùê∫I coincides with ùê∫1. Similarly,
ùêª is split by omitting the reference from Class c4 to Feature f3
in ùêª1 and omitting Class c3 together with its reference from ùêª2.
Consequently, ùêªI contains the three Classes c2, c3, c4 but only the
reference from c2 to f1. As crossover point, we choose a graph that,
beyond the given problem graph, contains a common preimage for
Classes c1 and c2 and their respective reference to Feature f1, thus
identifying them. As can be seen, the resulting offspring ùê∫1ùêª2 is
desirable as it assigns the independent Feature f3 to its own Class.
In contrast, offspring ùê∫2ùêª1 is infeasible, containing an empty Class
(i.e., a Class with no Feature) and a multiply assigned Feature.

We close this section with introducing some abbreviating nota-
tions and simplifying assumptions. First, we assume the problem
graphs of the occurring computation graphs to be identical (and
not merely isomorphic). Furthermore, from a formal point of view,
morphisms (and inclusions) relate the different occurring graphs
like split parts, split points, crossover points etc. Considering these
explicitly leads to quite some notational overhead. To avoid that, we
use common names of variables and indices to convey the relation
between elements. For example, we write ùë•ùê∫ , ùë•ùê∫1 , ùë•PI P , ùë•CP , etc.
to indicate that the node ùë•CP from crossover point CP is mapped
to the node ùë•PI P in the problem part, the node ùë•ùê∫1 in split part ùê∫1
of a computation graph ùê∫, etc.

5 INTRODUCING SECURE CROSSOVER ON

GRAPHS

In this section, we introduce our crossover operator, which we
call secure crossover, and prove its central properties, namely being
multiplicity-preserving (feasibility-preserving) and still being able
to produce any valid graph as offspring (coverage of search space).
As mentioned, we develop our crossover operator as a refinement of

f1:Featuref2:Featuref3:Featurec1=c2:Classc4:Classùê∫1ùêª2f1:Featuref2:Featuref3:Featurec1=c2:Classc3:Classc4:Classùê∫2ùêª11A multiplicity-preserving crossover operator on graphs

the one introduced in [25] and recalled in Sect. 4. Our construction
is guided by the following objectives.

(1) Applied to feasible input graphs, secure crossover shall com-

pute feasible offsprings.

(2) The search space should not get unnecessarily restricted by

our operator.
At least, it should be possible to obtain every feasible graph
as a result from crossover. That is, our operator should not
cut off feasible regions from the search space.

(3) It should be possible to perform crossover efficiently.

Finding splits of two graphs, however, and a crossover point
such that both computed offspring solutions satisfy all multiplici-
ties seems to require intensive analysis and becomes very inefficient.
Therefore, we take inspiration from crossover operators that have
been developed for the case where permutations (of numbers) are
chosen as representation. There, to ensure that crossover of two
permutations results in a permutation again, several crossover oper-
ators have been developed that only compute one offspring solution
(see, e.g., [24] for an overview). Analogously, in this work the basic
idea is to focus entirely on one offspring solution. Computing a
single feasible offspring requires significantly less computational
effort than ensuring both offsprings to be feasible. We suspect that
it could be cheaper to apply the operator we propose in this paper
twice, instead of trying to compute an application of a crossover
operator with two feasible offsprings.

Since, for formal reasons, we still want our suggested crossover
operator to adhere to the definition of generic crossover, we suggest
a trivial way to compute a second solution (namely, to just unify
the whole given solution graphs ùê∫ and ùêª over the crossover point
selected to compute the first offspring). However, in an implemen-
tation one would probably just omit this step as the likelihood of
this second offspring being valuable is very low. Accordingly, in the
following we entirely focus on the presentation of the computation
of the first offspring.

In all of the following, we assume to be given two computation
graphs ùê∫ and ùêª that are solutions for the same fixed problem
instance PI (all typed over the same computation type graph with
multiplicities ùëáùê∫). We will mainly speak about their underlying
graphs ùê∫, ùêª , PI , etc. and treat their typing implicitly. Recall that
PI P refers to the problem graph of PI that captures the concrete
problem instance that is to be optimized.

5.1 General procedure
Our general procedure is presented in Algorithm 1 and works as
follows: We construct a subgraph ùê∫sub of ùê∫ as a first split part in
such a way that ùê∫sub is always feasible when ùê∫ is (line 1). Knowing
ùê∫sub, we construct ùêªsub (as a second split part of ùêª ) and a crossover
point CP in parallel, monitoring that applying crossover with that
data is not going to introduce new violations of the multiplicity
constraints (lines 2‚Äì4). Computing the crossover point CP and
ùêªsub simultaneously allows for a much easier handling of the upper
bound of the multiplicities: Whenever a node is included into CP ,
all edges that attach to that node‚Äôs counterparts in ùê∫sub and ùêªsub
will be present in the offspring, attached to that node from CP .
This can lead to the resulting amount of edges being higher than the
multiplicity permits. If we were to compute ùêªsub first, we would

therefore not be able to ensure that a later choice of CP could not
lead to any breach of a maximum. These breaches would either need
to be avoided when computing CP , which might not always be
possible, or we would be forced to alter ùê∫sub and ùêªsub, creating a lot
of additional computational effort. This can be avoided by selecting
CP alongside the subgraph ùêªsub. Finally, the offspring solution
ùëÇ1 is computed as the union of ùê∫sub and ùêªsub over CP (line 5).
As already mentioned, to still comply with generic crossover, we
formally also compute a second offspring ùëÇ2 as the union of ùê∫ and
ùêª over CP ; however, we do not expect to perform this computation
in practice.

Algorithm 1 secureCrossover(ùê∫, ùêª, PI P)

1: ùê∫sub ‚Üê createGsub(ùê∫, PI P)
2: global CP, ùêªsub ‚Üê PI P
3: constructCP(ùê∫sub, ùêª )
4: processFreeNodes(ùê∫sub, ùêª, ùêªsub)
5: ùëÇ1 ‚Üê ùê∫sub ‚à™CP ùêªsub
6: ùëÇ2 ‚Üê ùê∫ ‚à™CP ùêª

5.2 Creating ùê∫sub
The creation of ùê∫sub is detailed in Algorithm 2. We initialize ùê∫sub
with PI P as the problem graph is to be included anyhow. Then,
for all remaining nodes of ùê∫, we check whether they are already
included in ùê∫sub (e.g., because they serve as target node for an
included egde) and, if not, we randomly decide whether or not the
node should be included (line 5). For included nodes, we also include
adjacent edges (line 8). Both nodes and edges are understood to be
included into ùê∫sub with they same type they have in ùê∫. Formally,
ùê∫sub becomes a computation graph over ùëáùê∫ by defining its type
function ùë°ùê∫sub as restriction of ùë°ùê∫ to ùê∫sub. For simplicity, we leave
this implicit in the pseudocode and in all of the following.

Algorithm 2 createGsub(ùê∫, PI P)

1: ùê∫sub ‚Üê PI P
2: for all ùë•ùê∫ ‚àà ùëâùê∫ do
3:

bool included ‚Üê ùë•ùê∫sub ‚àà ùëâùê∫sub
if !included then

included ‚Üê decideInclusion(ùë•ùê∫ )

end if
if included then

includeAdjacentEdges(ùë•ùê∫, ùê∫)

4:

5:

6:

7:

8:

end if
9:
10: end for

The inclusion of edges is done by including a random set of
the edges of ùê∫ in ùê∫sub whose size is between the required lower
and upper bound. In case it should not be possible to reach the
lower bound (because this is violated in ùê∫) at least all the available
edges are included in ùê∫sub. We provide an algorithm for this and
an extended explanation in Appendix A.

Example 5.1. In the CRA case, called for a feasible solution ùê∫,
createGsub will always return the whole of ùê∫ as ùê∫sub. All Features
are directly included into ùê∫sub because they are part of the problem

graph. Since the incoming encapsulates-edge has a source multiplic-
ity of [1, 1], for every Feature-node the call of includeAdjacentEdges
includes the incoming encapsulates-edge (that exists because of fea-
sibility) and the Class from which it starts. Since, again by feasibility,
empty Classes cannot occur, that process results in ùê∫.

5.3 Creating ùêªsub and CP
The main difficulty in constructing ùêªsub and CP is that, as soon as
a node ùë•CP in the crossover point prescribes that nodes ùë•ùê∫sub from
ùê∫sub and ùë•ùêªsub from ùêªsub are to be identified in the offspring, we
need to ensure that no upper bound violations can be introduced by
that identification: Even if in both ùê∫sub and ùêªsub the upper bounds
are satisfied, the sum of adjacent edges of a certain type of edges
to ùë•ùê∫sub in ùê∫sub and ùë•ùêªsub in ùêªsub might exceed the upper bound
of that type of edge. Constructing ùêªsub and CP in parallel, we can
react to that by either (i) not including too many edges in ùêªsub, (ii)
also including the edges into CP (which reduces their number in
the offspring), or (iii) dropping edges from ùê∫sub. As nodes from
CP are the sensitive issue, we start constructing ùêªsub and CP
along the nodes we know to appear in them ‚Äì the nodes from the
problem graph PI P; it actually suffices to start form the border of
PI P in ùêª , namely the nodes of PI P which have an adjacent edge
(in ùêª ) to a node that does not belong to PI P.

Algorithm 3 provides the computations of the split part ùêªsub
and the crossover point CP . We begin with adding all nodes of the
border of the problem part to a queue ùëÑ (line 2). Let ùë•ùêª be the node
we are currently handling (line 3). We start by iterating through
each of the edges attached to ùë•ùêª (lines 4‚Äì6). For each such edge ùëíùêª ,
and corresponding neighboring node ùë¶ùêª , we first check whether ùë¶ùêª
already belongs to ùêªsub and, if so, whether the edge ùëíùêª also already
belongs to ùêªsub or ùë¶ùêª already to CP (lines 7‚Äì15). If ùëíùêª already
belongs to ùêªsub we can skip the treatment of that edge. It means
that ùë¶ùêª has already been processed and, hence, ùëíùêª adequately been
treated. If ùë¶ùêª belongs to CP , this makes an important difference
for the possible treatment of ùëíùêª later on. If ùë¶ùêª does not already
belong to ùêªsub (and, consequently, also not to CP ), we can decide
randomly if we intend to include it in ùêªsub (line 17). We then can,
again randomly, decide whether we also want to include ùëíùêª in ùêªsub
(line 20). Should we decide that we want to include neither ùë¶ùêª nor
ùëíùêª into ùêªsub, we can move to the next edge.

If ùë¶ already belongs to CP and, seen in the direction from ùë¶
to ùë•, the upper bound of the type of ùëí has already been reached,
there is a single possibility to include ùëíùêª in ùêªsub, namely also
including it in CP , that is, identifying it with an edge of the same
type between ùë• and ùë¶ that stems from ùê∫sub. Any other way of
including ùëíùêª in ùêªsub would result in an upper bound violation in
the to be computed offspring. Without providing the details, this
procedure is performed by the function includeIntoCP (line 23); if
inclusion is possible, it is performed, otherwise ùëíùêª is not included
in ùêªsub. In either case, the remaining iteration for ùëíùêª is skipped.
The most options are available if we decide to include both ùë¶ùêª
and also ùëíùêª in ùêªsub (beginning with line 26): The first option we
have is to swap the edge ùëíùêª with another edge (of the same type)
adjacent to ùë• that stems from ùê∫sub (line 26). This possibility serves
to increase the expressiveness of the operator; recall from Exam-
ple 5.1 that the creation of ùê∫sub might enforce all edges adjacent to

Henri Th√∂lke and Jens Kosiol

Algorithm 3 constructCP(ùê∫sub, ùêª )
1: queue ùëÑ ‚Üê border(PI P, ùêª )
2: while ùëÑ.notEmpty() do
3:

ùë•ùêª ‚Üê ùëÑ.pop()
for all dir ‚àà {src, tar } do

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

22:

23:

24:

25:

26:

27:

28:

29:

30:

31:

32:

33:

34:

35:

36:

37:

38:

39:

40:

41:

42:

for all ùëí ‚àà ùê∏TG with dir TG (ùëí) = ùë°ùêª (ùë•ùêª ) do
ùêª ‚àà edges (ùêª, ùëí, dir, ùë•ùêª ) do

for all ùëí ‚Ä≤

ùë¶ùêª ‚Üê dir (ùëíùêª )
bool included ‚Üê ùë¶ùêª ‚àà ùëâùêªsub
if included then

bool edgeIncluded ‚Üê ùëí ‚Ä≤
if edgeIncluded then

ùêª ‚àà ùê∏ùêªsub

skip
end if
bool includedCP ‚Üê ùë¶ùêª ‚àà ùëâCP

end if
if !included then

included ‚Üê decideInclusion(ùë¶ùêª )

end if
if included then

edgeIncluded ‚Üê decideInclusion(ùëíùêª )
if edgeIncluded then

if includedCP ‚àß edgeCount(ùêª, ùê∫, ùëí, dir, ùë¶)+1 >

ùëöub

dir then

then

includeIntoCP(ùëíùêª )
skip
end if
bool swapped ‚Üê randomEdgeSwap(ùë•ùê∫, ùëí ‚Ä≤
ùêª , ùê∫sub)
if !swapped ‚àß edgeCount(ùêª, ùê∫, ùëí, dir, ùë•)+1 > ùëöub
dir

bool resFound ‚Üê resolveBreach(ùëÑ, ùë•, ùëí ‚Ä≤
if !resFound then

ùêª , dir, ùëí)

skip
end if

end if
ùê∏ùêªsub = ùê∏ùêªsub ‚à™ {ùëí ‚Ä≤

}

ùêªsub

end if
ùëâùêªsub = ùëâùêªsub ‚à™ {ùë¶ùêªsub }

We might want to include a node ùë¶ùê∂ùëÉ even if not required
includedCP

bool

randomNodeToCP(ùëÑ, ùë•, ùëí ‚Ä≤, dir, ùëí)

‚Üê

if edgeIncluded ‚àß includedCP ‚àß!swapped then

randomEdgeToCP()

end if

end if
end for

end for

end for
43:
44: end while

ùë•ùê∫ in ùê∫ to also be part of ùê∫sub. Swapping an edge means to choose
an edge of the same type as ùëíùêª that is attached to ùë•ùê∫ in ùê∫sub and to
remove it from ùê∫sub; this procedure is sketched as Algorithm 4. In
picking an edge ùëíùê∫ from ùê∫sub to swap, we have to check whether
removing that edge from ùê∫sub leads to a lower bound violation in

A multiplicity-preserving crossover operator on graphs

Algorithm 4 randomEdgeSwap(ùë•, ùëí ‚Ä≤, ùê∫sub)
1: bool ùë†ùë§ùëéùëù ‚Üê decideSwap()
2: if !ùë†ùë§ùëéùëù then
return false
3:
4: else
5:

ùëíùê∫ ‚Üê pickSwapEdgeG(ùë•, ùëí ‚Ä≤, ùê∫sub)
if ùëíùê∫ == null then
return false

6:

7:

8:

9:

10:

else

ùê∏ùê∫sub ‚Üê ùê∏ùê∫sub \ {ùëíùê∫ }
return true

end if

11:
12: end if

the direction opposite to the one in which we are currently working
(that check is not detailed in the algorithm). If no suitable edge is
available, swapping fails. Note that this swapping of edges does
not affect the multiplicities of the node ùë• under consideration: We
remove an edge (that stems from ùê∫) and replace it by one (that
stems from ùêª ) of the same type.

The second option, if we do not decide to swap the edge, is to
simply add it to the offspring (lines 27‚Äì31). If we intend to do this,
the amount of edges at the offspring version of ùë• would increase
by one. This could lead to a breach of the maximum. If we detect
this, we can try to fix the situation by resolveBreach, presented as
Algorithm 8 in Appendix A. Substantially, we need to try adding the
pair of ùë¶ and ùëí ‚Ä≤ to the crossover point. Doing this would essentially
remove the added edge in the offspring, maintaining our maximum.
To add ùë¶ and ùëí ‚Ä≤ to the crossover point, we need to find a node ùëß
in ùê∫sub, that is of the same type as ùë¶, is not part of the crossover
point yet, and is connected to ùë• via an edge of the same type as
ùëí ‚Ä≤. Furthermore, the edges that are adjacent to that node ùëß in ùê∫sub
may not introduce a violation of an upper bound when combined
with the edges that are already adjacent to ùë¶ùêª in ùêª (if such edges
exist). We search for such a node by iterating through all edges
of the same type as ùëí ‚Ä≤, that are attached to ùë•. If we find such a
node, we create a node in the crossover point, fixing our breach.
We then only need to enqueue ùë¶. If we cannot find such a node ùëß,
then we give up on finding a fix to the breach, instead discarding
the addition of ùë¶ and ùëí ‚Ä≤ to ùêªsub. For simplicity, we decided to have
a failure to resolve the conflict to result in skipping the current
edge type entirely. Alternatively, it would be possible to try again
to swap the edge.

Once we determined that it is safe to add ùë¶ and ùëí ‚Ä≤ in the chosen
way, we add them to ùêªsub (lines 33 and 35). Note that, until now, we
have only added ùë¶ and/or ùëí ‚Ä≤ to the crossover point if we were forced
to do so to prevent upper bound violations (via function includeIn-
toCP or resolveBreach). To increase expressiveness, it should also be
possible to randomly include ùë¶ and, if ùë¶ is included, possibly also ùëí ‚Ä≤
in CP . This functionality is provided by functions randomNodeToCP
and randomEdgeToCP in lines 36‚Äì39 of Algorithm 3. Like in resolve-
Breach, adding ùë¶ùêª to the crossover point means choosing a node of
the same type in ùê∫sub that is not yet included in CP , and adding
a new node to the crossover point, merging them together in the
offspring (after performing the necessary checks).

If we decide to include ùë¶ in the crossover point, and we did not
swap an edge earlier, we can then choose to also include ùëí ‚Ä≤ in the
crossover point along with ùë¶. This is only safe to do if we did not
swap any edge. If we decided to both remove an edge in ùê∫sub, and
then combine another edge with ùëí ‚Ä≤, which was set to replace the
deleted edge, we would end up reducing the amount of edges by
one. Since this could breach the minimum, we disallow it entirely.

Algorithm 5 processFreeNodes(ùê∫sub, ùêª, ùêªsub)
1: queue ùëÑ ‚Üê unprocessed nodes from ùêª
2: while ùëÑ.notEmpty() do
3:

ùë•ùêª ‚Üê ùëÑ.pop()
bool included ‚Üê ùë•ùêª ‚àà ùëâùêªsub
if !included then

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

included ‚Üê decideInclusion(ùë•ùêª )

end if
if included then

bool tryCP ‚Üê decideInclusionCP(ùë•ùêªsub )
if tryCP then

bool includeCP ‚Üê verifyInclusion(ùë•ùêªsub )

end if
if !includeCP then

bool minEnsured ‚Üê ensureMinimumFreeNode(ùë•ùêªsub )
if !minEnsured then
removeNode(ùë•ùêªsub )

this needs to be cascading the removal as described in the text

end if

else

To find a node to merge ùë•ùêªsub with, simply pick a node of equal
type in ùê∫sub, that is not yet part of the crossover point

addToCP(ùë•ùêªsub )
randomIncludeMoreEdges()

this basically follows ensureMinimumFreeNode, just instead
of checking if the minimum has been reached, we check
whether the maximum has not been reached yet.

21:

end if

end if

22:
23: end while

Function constructCP (Algorithm 3) builds a crossover point with
all edges and nodes in ùêª that neighbor a node in CP being already
decided on. This means that after calling constructCP, ùêªsub contains
all nodes we selected for the crossover point, along with the nodes
and edges chosen to be included in ùêªsub but not CP . To further
increase expressivity, it should also be possible to include nodes (and
their adjacent edges) in ùêªsub and possibly CP that have not been
visited so far. Furthermore, we might have added nodes to ùêªsub
without ensuring their lower bound. To address both issues, after
constructCP, secureCrossover (Algorithm 1) calls processFreeNodes
as introduced in Algorithm 5.

We start the function processFreeNodes with a queue ùëÑ that con-
tains all nodes of ùêª that have not been processed during constructCP,
i.e., all nodes of ùêª that are not yet part of ùêªsub and that never oc-
curred in the queue ùëÑ during the call of constructCP, and all nodes
that belong to ùêªsub without also belonging to CP . These are nodes
for which we never decided whether or not they should be part of

ùêªsub and CP , or for which we did not yet ensure satisfaction of
lower bounds. In processFreeNodes, we first check whether or not
the currently considered node ùë•ùêª is already part of ùêªsub and, if not,
give the node a random chance of being included in ùêªsub (line 4‚Äì7).
(While the check is unnecessary at the very start of the algorithm,
it is necessary later on when nodes from ùëÑ that have not been
reached yet might have already been included in ùêªsub, triggered by
the inclusion of adjacent edges.) In the next step, if the node is to
be included, we randomly decide whether it also shall be included
in CP (line 9); the function decideInclusionCP is understood to (i)
randomly decide whether or not ùë•ùêª shall be included in CP and,
if so, to check whether or not a node of the same type that does
not yet belong to CP is available in ùê∫sub. This leaves us with two
situations: If ùë•ùêª is to be included in CP , it gets identified with a
node from ùê∫sub that brings enough edges to satisfy lower bounds
(provided feasibility of ùê∫). However, we need to ensure that the
identification does not introduce violations of upper bounds (in
case ùêªsub already contains edges adjacent to ùë•ùêª ). If ùë•ùêª is to be
included in ùêªsub but not in CP , it needs to be accompanied by
enough edges to not introduce violations of lower bounds. Inclusion
of these edges in ùêªsub, however, might not be possible without
introducing violations of upper bounds at their respective other
adjacent nodes (if those are part of CP ). These are the purposes
of functions verifyInclusion and ensureMinimumFreeNode, called in
lines 11 and 14 of Algorithm 5, respectively.

Function verifyInclusion verifies that the inclusion of ùë•ùêª in CP
does not breach any maxima in the offspring. We do this by perform-
ing the same check as in constructCP (Algorithm 3), however, we
stop at merely checking whether a breach would occur. Of course,
one could also try to find a fix for potentially arising breaches of
a maximum, via edge swapping, or recursive inclusion of further
nodes, along with the edges. For simplicity, and since the logic
is already shown prior, we omitted this. The basic structure of
verifyInclusion is given as Algorithm 9 in Appendix A.

Algorithm 6 ensureMinimumFreeNode(ùë•)

1: for all dir ‚àà {src, tar } do
2:

for all ùëíTG ‚àà ùê∏TG with dir TG (ùëíTG ) = ùë•TG do
targetAmount
min (|edges(ùêª, ùëíTG, dir, ùë•ùêª )|, ùëölb
dir

int

)

for all ùëí ‚Ä≤ ‚àà edges(ùêª, ùëíTG, dir, ùë•ùêª ) do

if edgeCount(ùêª, ùê∫, ùëíTG, dir, dir (ùëí ‚Ä≤))+1 ‚â§ ùëöub

‚Üê

dir then

ùê∏ùêªsub ‚Üê ùê∏ùêªsub ‚à™ {ùëí ‚Ä≤}
if !dir (ùëí ‚Ä≤) ‚àà ùêªsub then
ùëâùêªsub ‚Üê ùëâùêªsub ‚à™ {dir (ùëí ‚Ä≤)}
ùëÑ.enqueue(dir (ùëí ‚Ä≤))

end if

end if
if |edges(ùêªsub, ùëíTG, dir, ùë•ùêªsub )| ‚â• targetAmount then

return true

end if
end for

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

end for

16:
17: end for
18: return false

Henri Th√∂lke and Jens Kosiol

For the nodes that did not get picked to be included in the
crossover point, or that were rejected during verification, we try
to ensure that we include enough edges to meet the minimum via
ensureMinimumFreeNode (Algorithm 6). During the inclusion, we
ensure that the inclusion of a selected edge does not introduce a
violation of an upper bound in the opposite direction (line 6). If the
second adjacent node of an included edge does not already belong
to ùêªsub, we add it and newly enqueue it to ensure that also the
lower bounds of that node are controlled. We use targetAmount
to only allow the lower bound to be violated if ùêª already violated
the lower bound in this position. Like with ùê∫, this allows us to
meaningfully treat the case where the input is infeasible: We ensure
that the amount of edges in the offspring is equal to that in the
input, meaning that secure crossover cannot worsen the situation
by introducing a greater number of missing edges.

Returning to processFreeNodes (Algorithm 5), should it prove
impossible to include a node in ùêªsub while ensuring its minimum
(i.e., ensureMinimumFreeNode returns false), the easiest solution
is to simply remove the node that failed to reach the minimum
from ùêªsub, along with all edges. This removal has the potential to
cascade, meaning other free nodes might have relied on a removed
edge for their own minimum. We remove all nodes affected by this
cascading effect. More elaborate solutions that try to remedy each
newly affected node are imaginable, but in the interest of simplicity
we chose a more coarse approach.

All nodes we added to reach minima for our original free nodes
are added to the queue of free nodes, since we will need to ensure
their feasibility as well. Following this process, we iterate through
ùêª in its entirety. The iteration stops either when all minima are
reached and all nodes had a chance to be included, or when the cas-
cading determines that no nodes aside the ones in CP are possible
additions to ùêªsub, since there is always a failure to meet minima.
Our approach therefore visits each node in ùê∫ exactly once (when
constructing ùê∫sub) and the nodes in ùêª are visited at most thrice,
once or twice for constructing ùêªsub and once when potentially
removing nodes for failure to meet minima. This, along with the
fact that we only perform checks against the multiplicities when
we cannot rely on feasibility inherited by the input, leads us to
believe that using secure crossover is beneficial compared to simpler
approaches, e.g., using generic crossover and discarding infeasible
offsprings.

Example 5.2. In Example 4.6, we discussed how generic crossover
can compute the solution ùê∫1ùêª2, depicted in Fig. 3, from the solu-
tions ùê∫ and ùêª , depicted in Fig. 2. Secure crossover as introduced
in this section can also compute this solution from the same input.
As stated in Example 5.1, createGsub (Algorithm 2) will first return
ùê∫ as ùê∫sub. However, constructCP (Algorithm 3) then iterates over
the three Classes c2, c3, and c4 of ùêª because these constitute the
border in that case. Since none of these Classes already belongs to
ùêªsub, for each of it it is randomly decided whether or not it (and
its adjacent edge) are to be included in ùêªsub. Assume that a run
of constructCP randomly decides (i) to include c2 (and its adjacent
edge) in ùêªsub and CP , (ii) to include c4 only in ùêªsub and not in CP
and to swap its adjacent edge against the one from ùê∫sub pointing
to Feature f3 (which means to delete that edge from ùê∫sub), and
(iii) to not include c3 in ùêªsub. Then ùê∫sub coincides with ùê∫1 from

A multiplicity-preserving crossover operator on graphs

Example 4.6, ùêªsub with ùêª2, and also the crossover points coincides.
This means, the relevant offspring computed by secure crossover
in this case is the feasible solution ùê∫1ùêª2.

Note, first, that, while generic crossover can of course also com-
pute ùê∫1ùêª2, the probability that it ever returns feasible solutions
drastically decreases with increasing size and complexity of the
input graphs. Second, because of the structural simplicity of the
CRA case, the call of function processFreeNodes (Algorithm 5) is
trivial in that case. It is initialized with the empty queue because
all nodes of ùêª have already been processed by constructCP.

6 PROPERTIES OF SECURE CROSSOVER
In the following, we present the central formal results for our
crossover operator. First, we prove that offspring computed from
feasible solutions is again feasible, and, secondly, that every feasible
solution is a possible result of the application of secure crossover
or, in other words, that, in principle, we only restrict the reachable
search space by infeasible solutions. Both of these properties are
valuable since we want to obtain a crossover operator that guaran-
tees that the output models are feasible without restricting these
output models in any way not required by the feasibility criteria. In
Appendix B, we additionally establish that the application of secure
crossover terminates and that it is an instance of the generic ap-
proach suggested in [25]. In particular, this ensures that it computes
solutions for the given problem instance.

In all of the following, we always assume two solutions ùê∫ and ùêª
for the same problem instance PI to be given. As already explained,
with secure crossover we are actually only interested in the first
computed offspring, namely the one that arises as union of ùê∫sub
and ùêªsub over the chosen crossover point CP . We just denote that
offspring as ùëÇ and ignore the second computed offspring.

Theorem 6.1 (Feasibility of offspring models). Let ùê∫, ùêª be
two solutions of a problem instance and let ùëÇ be an offspring that has
been computed by secure crossover. It holds that:

(1) For every node ùë•ùëÇ in ùëÇ the number of edges ùëí ‚Ä≤

ùëÇ of a type ùëíùëáùê∫
with dir (ùëí ‚Ä≤
ùëÇ ) = ùë•ùëÇ is greater or equal to the number of edges
minimally provided by its counterparts in ùê∫ and/or ùêª , that is,
greater or equal to
(cid:18)(cid:110)

(cid:111)(cid:19)

(ùëíùëáùê∫ ), (cid:12)
(cid:12)

(cid:8)ùëí ‚Ä≤

ùê∫ ‚àà ùê∏ùê∫ | ùë°ùê∫ (ùëí ‚Ä≤

ùê∫ ) = ùëíùëáùê∫, dir (ùëí ‚Ä≤

ùê∫ ) = ùë•ùê∫ (cid:9)(cid:12)
(cid:12)

,

min

ùëölb
dir

or an analogous minimum should ùë•ùëÇ only have a counterpart
in ùêª .

(2) For every node ùë•ùëÇ in ùëÇ the number of edges ùëí ‚Ä≤

ùëÇ of a type ùëíùëáùê∫
with dir (ùëí ‚Ä≤
ùëÇ ) = ùë•ùëÇ is smaller or equal to the number of edges
maximally provided by its counterparts in ùê∫ and/or ùêª , that is,
smaller or equal to
(cid:18)(cid:110)

(cid:111)(cid:19)

(ùëíùëáùê∫ ), (cid:12)
(cid:12)

(cid:8)ùëí ‚Ä≤

ùê∫ ‚àà ùê∏ùê∫ | ùë°ùê∫ (ùëí ‚Ä≤

ùê∫ ) = ùëíùëáùê∫, dir (ùëí ‚Ä≤

ùê∫ ) = ùë•ùê∫ (cid:9)(cid:12)
(cid:12)

,

max

ùëöub
dir

or an analogous maximum should ùë•ùëÇ only have a counterpart
in ùêª .

In particular, if ùê∫ and ùêª are feasible, so is ùëÇ.

The proof of the above theorem is split in two parts, which we
build from multiple lemmas. The basic idea is that we separately
show that the offspring models satisfy all the lower bounds of

the multiplicities and that the offspring models satisfy the upper
bounds. For this we will first prove that our selection of ùê∫sub always
provides a feasible model, provided feasibility of ùê∫.

Lemma 6.2 (Construction of ùê∫sub). Let ùê∫sub be a subgraph
of ùê∫ that has been obtained by a call of createGsub (Algorithm 2).
Then, for every node ùë•ùê∫sub
of a
type ùëíùëáùê∫ with dir (ùëí ‚Ä≤

in ùê∫sub the number of edges ùëí ‚Ä≤

is greater or equal to

ùê∫sub

) = ùë•ùê∫sub

ùê∫sub

min

(cid:18)(cid:110)

ùëölb
dir

(ùëíùëáùê∫ ), (cid:12)
(cid:12)

(cid:8)ùëí ‚Ä≤

ùê∫ ‚àà ùê∏ùê∫ | ùë°ùê∫ (ùëí ‚Ä≤

ùê∫ ) = ùëíùëáùê∫, dir (ùëí ‚Ä≤

ùê∫ ) = ùë•ùê∫ (cid:9)(cid:12)
(cid:12)

(cid:111)(cid:19)

.

Lemma 6.3 (Offspring satisfies lower bounds at least as
well as input). Let ùê∫, ùêª be two solutions of a problem instance and
let ùëÇ be an offspring that has been computed by secure crossover. Let
TG mod be a modified type graph, where each edge multiplicity [ùëñ, ùëó]
has been replaced with [ùëò, ‚àó], where ùëò denotes the minimum of ùëñ and
the minimal number of edges of that type and direction that appear
adjacent to a node in ùê∫ or ùêª (i.e., the worst violation of the lower
bound). Then ùëÇ is feasible with regard to all edge multiplicities in
TG mod, and for every node ùë•ùëÇ in ùëÇ the number of edges ùëí ‚Ä≤
ùëÇ of one
type ùëíùëáùê∫ with dir (ùëí ‚Ä≤

ùëÇ ) = ùë•ùëÇ is greater or equal to

min

(cid:18)(cid:110)

ùëölb
dir

(ùëíùëáùê∫ ), (cid:12)
(cid:12)

(cid:8)ùëí ‚Ä≤

ùê∫ ‚àà ùê∏ùê∫ | ùë°ùê∫ (ùëí ‚Ä≤

ùê∫ ) = ùëíùëáùê∫, dir (ùëí ‚Ä≤

ùê∫ ) = ùë•ùê∫ (cid:9)(cid:12)
(cid:12)

(cid:111)(cid:19)

.

or an analogous minimum for ùêª , should ùë•ùëÇ only stem from there. In
particular, if ùê∫ and ùêª are feasible, ùëÇ is feasible for the type graph
TG min, where each edge multiplicity [ùëñ, ùëó] has been replaced with
[ùëñ, ‚àó].

We now show that the offspring satisfies the upper bounds, too.

Lemma 6.4 (Offspring satisfies upper bounds). Let ùê∫, ùêª be
two solutions of a problem instance and let ùëÇ be an offspring that
has been computed by secure crossover. Let TG mod be a modified
type graph, where each edge multiplicity [ùëñ, ùëó] has been replaced with
[0, ùëò], where ùëò denotes the maximum of ùëó and the maximal number
of edges of that type and direction that appear adjacent to a node in ùê∫
(i.e., the worst violation of the upper bound in ùê∫). Then ùëÇ is feasible
with regard to all edge multiplicities in TG mod, and for every node
ùë•ùëÇ in ùëÇ the number of edges ùëí ‚Ä≤
ùëÇ ) = ùë•ùëÇ
is smaller or equal to

ùëÇ of one type ùëíùëáùê∫ with dir (ùëí ‚Ä≤

max

(cid:18)(cid:110)

ùëöub
dir

(ùëíùëáùê∫ ), (cid:12)
(cid:12)

(cid:8)ùëí ‚Ä≤

ùê∫ ‚àà ùê∏ùê∫ | ùë°ùê∫ (ùëí ‚Ä≤

ùê∫ ) = ùëíùëáùê∫, dir (ùëí ‚Ä≤

ùê∫ ) = ùë•ùê∫ (cid:9)(cid:12)
(cid:12)

(cid:111)(cid:19)

.

In particular, if ùê∫ and ùêª are feasible, ùëÇ is feasible for the type
graph TG max, where each edge multiplicity [ùëñ, ùëó] has been replaced
with [0, ùëó].

Proposition 6.5 (Coverage of search space). Let ùëÇ be a feasi-
ble solution graph of the problem instance PI . Then there exist two
feasible solution graphs ùê∫ and ùêª of PI , different from ùëÇ, such that
ùëÇ is an offspring model of a secure crossover of ùê∫ and ùêª .

7 CONCLUSION
In this paper, we develop secure crossover, a crossover operator on
typed graphs (or, more generally, computation graphs) that pre-
serves multiplicity constraints. This means, applied to feasible input,
the secure crossover computes feasible output. Even for infeasible
input, an application of secure crossover at least does not worsen

the amount of multiplicity violations. Secure crossover is an exten-
sive refinement of generic crossover as introduced in [25]; to simplify
the computation of secure crossover, we focus on the computation
of a single (feasible) offspring solution. We develop the underlying
algorithms of secure crossover in great detail, and use this to prove
central formal properties of it, namely the preservation of feasibil-
ity, that all feasible solutions can, in principle, still be computed
as offspring of an application of secure crossover, and that secure
crossover is an instance of generic crossover. Beyond its immediate
applicability in MDO, our work is a further indication that MDO is
a promising approach when one is interested in guaranteeing cer-
tain properties of search operators during (meta-heuristic) search:
we are able to verify a highly complex property (preservation of
multiplicity constraints) for a still quite generic crossover operator
on graphs. It seems at least intuitive that properties of a similar
complexity are hardly verifiable when working, e.g., on Bit-strings
as a representation for solutions during search.

With regards to future work, we intend to implement secure
crossover and to investigate whether evolutionary search on models
can profit from the preservation of feasibility. With its comprehen-
sive formal basis at hand, it would be interesting to even provide
a verified implementation of secure crossover. We also intend to
extend our construction to take further kinds of constraints into
account, e.g., nested graphs constraints (which are equivalent to
first-order logic on graphs) as, for example, presented in [15].

ACKNOWLEDGMENTS
This work has been partially supported by the Deutsche Forschungs-
gemeinschaft (DFG), grant TA 294/19-1.

REFERENCES
[1] Hani Abdeen, D√°niel Varr√≥, Houari A. Sahraoui, Andr√°s Szabolcs Nagy, Csaba
Debreceni, √Åbel Heged√ºs, and √Åkos Horv√°th. 2014. Multi-objective optimization
in rule-based design space exploration. In Proceedings of ASE ‚Äô14. 289‚Äì300. https:
//doi.org/10.1145/2642937.2643005

[2] Ameni ben Fadhel, Marouane Kessentini, Philip Langer, and Manuel Wimmer.
2012. Search-based detection of high-level model changes. In Proceedings of
ICSM 2012. IEEE Computer Society, 212‚Äì221. https://doi.org/10.1109/ICSM.2012.
6405274

[3] Enrico Biermann, Claudia Ermel, and Gabriele Taentzer. 2012. Formal foundation
of consistent EMF model transformations by algebraic graph transformation.
Softw. Syst. Model. 11, 2 (2012), 227‚Äì250. https://doi.org/10.1007/s10270-011-
0199-7

[4] Robert Bill, Martin Fleck, Javier Troya, Tanja Mayerhofer, and Manuel Wimmer.
2019. A local and global tour on MOMoT. Softw. Syst. Model. 18, 2 (2019), 1017‚Äì
1046. https://doi.org/10.1007/s10270-017-0644-3

[5] Alexandru Burdusel, Steffen Zschaler, and Stefan John. 2021. Automatic genera-
tion of atomic multiplicity-preserving search operators for search-based model
engineering. Softw. Syst. Model. 20, 6 (2021), 1857‚Äì1887. https://doi.org/10.1007/
s10270-021-00914-w

[6] Frank R. Burton, Richard F. Paige, Louis M. Rose, Dimitrios S. Kolovos, Si-
mon M. Poulding, and Simon Smith. 2012. Solving Acquisition Problems Us-
ing Model-Driven Engineering. In Proceedings of ECMFA 2012 (Lecture Notes in
Computer Science, Vol. 7349), Antonio Vallecillo, Juha-Pekka Tolvanen, Ekkart
Kindler, Harald St√∂rrle, and Dimitrios S. Kolovos (Eds.). Springer, 428‚Äì443.
https://doi.org/10.1007/978-3-642-31491-9_32

[7] Frank R. Burton and Simon M. Poulding. 2013. Complementing metaheuristic
search with higher abstraction techniques. In CMSBSE@ICSE 2013, Richard F.
Paige, Mark Harman, and James R. Williams (Eds.). IEEE Computer Society, 45‚Äì48.
https://doi.org/10.1109/CMSBSE.2013.6604436

[8] Carlos A. Coello Coello. 2010. Constraint-handling techniques used with evo-
lutionary algorithms. In Companion Material GECCO 2010, Martin Pelikan and
J√ºrgen Branke (Eds.). ACM, 2603‚Äì2624. https://doi.org/10.1145/1830761.1830910
[9] Eclipse. 2022. Eclipse Modeling Framework (EMF). http://www.eclipse.org/emf
[10] Hartmut Ehrig, Karsten Ehrig, Ulrike Prange, and Gabriele Taentzer. 2006. Funda-
mentals of Algebraic Graph Transformation. Springer. https://doi.org/10.1007/3-

Henri Th√∂lke and Jens Kosiol

540-31188-2

[11] A. E. Eiben and James E. Smith. 2015. Introduction to Evolutionary Computing (2

ed.). Springer. https://doi.org/10.1007/978-3-662-44874-8

[12] Martin Fleck, Javier Troya, Marouane Kessentini, Manuel Wimmer, and Bader
Alkhazi. 2017. Model Transformation Modularization as a Many-Objective
IEEE Trans. Software Eng. 43, 11 (2017), 1009‚Äì1032.
Optimization Problem.
https://doi.org/10.1109/TSE.2017.2654255

[13] Martin Fleck, Javier Troya, and Manuel Wimmer. 2016. The Class Responsibil-
ity Assignment Case. In Proceedings of TTC 2016 (CEUR Workshop Proceedings,
Vol. 1758), Antonio Garc√≠a-Dom√≠nguez, Filip Krikava, and Louis M. Rose (Eds.).
CEUR-WS.org, 1‚Äì8. http://ceur-ws.org/Vol-1758/paper1.pdf

[14] Al Globus, John Lawton, and Todd Wipke. 2000. JavaGenes: Evolving Graphs with
Crossover. Technical Report. NASA Advanced Supercomputing (NAS) Division.
https://www.nas.nasa.gov/assets/pdf/techreports/2000/nas-00-018.pdf

[15] Annegret Habel and Karl-Heinz Pennemann. 2009. Correctness of high-level
transformation systems relative to nested conditions. Math. Struct. Comput. Sci.
19, 2 (2009), 245‚Äì296. https://doi.org/10.1017/S0960129508007202

[16] √Åbel Heged√ºs, √Åkos Horv√°th, and D√°niel Varr√≥. 2015. A model-driven framework
for guided design space exploration. Autom. Softw. Eng. 22, 3 (2015), 399‚Äì436.
https://doi.org/10.1007/s10515-014-0163-1

[17] Jose Miguel Horcas, Daniel Str√ºber, Alexandru Burdusel, Jabier Martinez, and
Steffen Zschaler. 2022. We‚Äôre Not Gonna Break It! Consistency-Preserving Op-
erators for Efficient Product Line Configuration. IEEE Transactions on Software
Engineering (2022). https://doi.org/10.1109/TSE.2022.3171404 online first.
[18] Stefan John, Alexandru Burdusel, Robert Bill, Daniel Str√ºber, Gabriele Taentzer,
Steffen Zschaler, and Manuel Wimmer. 2019. Searching for Optimal Models:
Comparing Two Encoding Approaches. J. Object Technol. 18, 3 (2019), 6:1‚Äì22.
https://doi.org/10.5381/jot.2019.18.3.a6

[19] Stefan John, Jens Kosiol, Leen Lambers, and Gabriele Taentzer. 2022. A Graph-
Based Framework for Model-Driven Optimization Facilitating Impact Analysis
of Sound and Complete Mutation Operator Sets. (2022). under review.

[20] Stefan John, Jens Kosiol, and Gabriele Taentzer. 2022. Towards a Configurable
Crossover Operator for Model-Driven Optimization. In MDE Intelligence, Lola
Burgue√±o, Dominik Bork, Phuong Nguyen, and Steffen Zschaler (Eds.). to appear.
[21] Penousal Machado, Henrique Nunes, and Juan Romero. 2010. Graph-Based
Evolution of Visual Languages. In Proceedings of EvoApplications 2010, Part II
(Lecture Notes in Computer Science, Vol. 6025), Cecilia Di Chio, Anthony Brabazon,
Gianni A. Di Caro, Marc Ebner, Muddassar Farooq, Andreas Fink, J√∂rn Grahl,
Gary Greenfield, Penousal Machado, Michael O‚ÄôNeill, Ernesto Tarantino, and Neil
Urquhart (Eds.). Springer, 271‚Äì280. https://doi.org/10.1007/978-3-642-12242-
2_28

[22] Zbigniew Michalewicz. 1995. A Survey of Constraint Handling Techniques in
Evolutionary Computation Methods. In Proceedings of EP 1995, John R. McDonnell,
Robert G. Reynolds, and David B. Fogel (Eds.). A Bradford Book, MIT Press.
Cambridge, Massachusetts., 135‚Äì155.

[23] Jens Niehaus. 2004. Graphbasierte Genetische Programmierung (Graph-based
Genetic Programming). Ph. D. Dissertation. Technical University of Dortmund,
Dortmund, Germany. https://doi.org/10.17877/DE290R-14929

[24] Jean-Yves Potvin. 1996. Genetic algorithms for the traveling salesman problem.
Ann. Oper. Res. 63, 3 (1996), 337‚Äì370. https://doi.org/10.1007/BF02125403
[25] Gabriele Taentzer, Stefan John, and Jens Kosiol. 2022. A Generic Construction
for Crossovers of Graph-Like Structures. In Proceedings of ICGT 2022 (Lecture
Notes in Computer Science, Vol. 13349), Nicolas Behr and Daniel Str√ºber (Eds.).
Springer, 97‚Äì117. https://doi.org/10.1007/978-3-031-09843-7_6

[26] Gabriele Taentzer and Arend Rensink. 2005. Ensuring Structural Constraints in
Graph-Based Models with Type Inheritance. In Proceedings of FASE 2005 (Lecture
Notes in Computer Science, Vol. 3442), Maura Cerioli (Ed.). Springer, 64‚Äì79. https:
//doi.org/10.1007/978-3-540-31984-9_6

[27] Steffen Zschaler and Lawrence Mandow. 2016. Towards Model-Based Opti-
misation: Using Domain Knowledge Explicitly. In Revised Selected Papers of
STAF 2016 Collocated Workshops (Lecture Notes in Computer Science, Vol. 9946),
Paolo Milazzo, D√°niel Varr√≥, and Manuel Wimmer (Eds.). Springer, 317‚Äì329.
https://doi.org/10.1007/978-3-319-50230-4_24

A ALGORITHMIC DETAILS
We first provide the details for the inclusion of edges in ùê∫sub (com-
pare Sect. 5.2). These details are presented in Algorithm 7. Given
a node ùë• for which adjacent edges are to be included, for each
type of edge for which ùë• can either serve as a source or a target
node (lines 1‚Äì2), we determine a random number ùëõ of edges that
are to be included (line 3). This random number is selected from
a specific range: The function lb (ùëíTG ) returns the minimum of

A multiplicity-preserving crossover operator on graphs

|ùëíùëëùëîùëíùë† (ùê∫, ùëíTG, ùëëùëñùëü, ùë•ùê∫ )|, which gives the number of actually adja-
cent edges of the considered type to ùë•ùê∫ in ùê∫, and ùëölb
(ùëíTG ), i.e.,
ùëëùëñùëü
the required lower bound; moreover, src = tar and tar = src. Sim-
ilarly, ub (ùëíTG ) returns the minimum of |ùëíùëëùëîùëíùë† (ùê∫, ùëíTG, ùëëùëñùëü, ùë•ùê∫ )|
and ùëöub
(ùëíTG ), i.e., the required upper bound. In this way, ùëõ lies
ùëëùëñùëü
between the lower and the upper bound of the considered edge
type, or it coincides with the number of available edges of that type
(at that node), should the number of edges available in ùê∫ fall short
of the lower bound. Then, ùëõ edges of the considered type, connected
to the node ùë• in the considered direction are randomly selected
to be included in ùê∫sub. This inclusion comprises the inclusion of
their second attached node. Without representing this explicitly
in the code, we assume (i) that the number ùëõ of edges that are to
be included is reduced by the number of edges that already have
been included so far (when including adjacent edges for another
node) and (ii) that it is ensured that for newly included nodes the
function includeAdjacentEdges will be called in the future.

Algorithm 7 includeAdjacentEdges(ùë•, ùê∫)

1: for all ùëëùëñùëü ‚àà {srcùê∫, tarùê∫ } do
2:

for all ùëíTG ‚àà ùê∏TG with ùëëùëñùëüTG (ùëíTG ) = ùë°ùê∫ (ùë•) do

3:

4:

5:

6:

7:

8:

ùëõ ‚Üê randInt(lb (ùëíTG ), ub (ùëíTG ))
for ùëñ ‚Üê 1, . . . , ùëõ do

select ùëí ‚Ä≤ ‚àà edges (ùê∫, ùëíTG, ùëëùëñùëü, ùë•ùê∫ )
ùê∏ùê∫sub ‚Üê ùê∏ùê∫sub ‚à™ {ùëí ‚Ä≤}
ùëâùê∫sub ‚Üê ùëâùê∫sub ‚à™ {ùëëùëñùëüùê∫ (ùëí ‚Ä≤)}
end for

end for

9:
10: end for

Next, we provide the pseudocode for function resolveBreach (Al-
gorithm 8) that can be called during the computation of ùêªsub and
CP .

Algorithm 8 resolveBreach(ùëÑ, ùë•, ùëí ‚Ä≤, dir, ùëíTG )

1: ùë¶ùê∫ ‚Üê pickFreeNodeG(ùë•ùê∫, dir, ùëíTG )
2: if ùë¶ùê∫ == ùëõùë¢ùëôùëô then
return false
3:
4: end if
5: ùëâùê∂ùëÉ = ùëâùê∂ùëÉ ‚à™ {ùë¶ùê∂ùëÉ }
6: ùê∏ùê∂ùëÉ = ùê∏ùê∂ùëÉ ‚à™ {ùëí ‚Ä≤
ùê∂ùëÉ }
7: ùëÑ.enqueue(ùë¶ùêª )
8: return true

Finally, Algorithm 9 provides the basic structure for the function
verifyInclusion that is used to check whether it is possible to include
a node in CP .

B PROOFS AND ADDITIONAL RESULTS
We first state that every call of secure crossover terminates.

Proposition B.1 (Termination of secure crossover). Given a
computation type graph with multiplicities TG, a problem instance
PI for it, and two solutions ùê∫ and ùêª for PI , every application of
secure crossover as defined in Algorithm 1 terminates, computing
two offspring graphs ùëÇ1 and ùëÇ2.

Algorithm 9 verifyInclusion(ùë•)
1: for all dir ‚àà {src, tar } do
2:

for all ùëíTG ‚àà ùê∏TG with dir TG (ùëíTG ) = ùë°ùêª (ùë•) do

ùëúùë£ùëíùëü

‚Üê
‚àí|edges(CP, ùëíTG, dir, ùë•CP )| > ùëöùëéùë•dir

edgeCount(ùê∫sub, ùêªsub, ùëíTG, dir, ùë•)

if ùëúùë£ùëíùëü then

Here we could implement varying degrees of fixing attempts.
From edge swapping, to recursive merging

return false

3:

4:

5:

6:

end if
end for

7:
8: end for
9: return true

Proof. First, none of the algorithms that are called during the
application of secure crossover throws an exception; at most, certain
iterations of a loop are skipped (e.g., in Algorithm 3) or a restricted
set of computations is rolled back (e.g., in Algorithm 5). This means
that, if secure crossover terminates, it definitely stops with the
computation of the two offspring graphs ùëÇ1 and ùëÇ2.

The only points that could cause non-termination are the while
loops in Algorithms 3, 5, and 6. Both Algorithms 3 and 5 iterate over
a queue ùëÑ that is initialized with a finite number of nodes. In both
cases, additional nodes can be enqueued during the computation.
However, in both cases this only happens for nodes that are newly
included in CP (Algorithm 8, line 7) or newly included in ùêªsub
(Algorithm 6, line 9). For every node of ùêª , this can only happen
once, and in all cases, it is first checked whether or not the inclusion
already holds. In Algorithm 6, both while-loops are guarded by
counters that in- or decrease with every iteration.

Overall, secure crossover terminates.

‚ñ°

As recalled in Sect. 4, applying the generic crossover operator
from [25] to computation graphs ùê∫ and ùêª amounts to splitting
these into computation graphs ùê∫1, ùê∫2, ùêª1, and ùêª2, each contain-
ing the considered problem graph, and uniting ùê∫1 and ùêª2 and ùê∫2
and ùêª1, respectively, over a common crossover point CP that is a
common subgraph of the split points ùê∫I and ùêªI and also at least
contains the considered problem graph. Proposition 2 in [25] clar-
ifies that the computed offspring are again computation graphs
and, in particular, solutions for the considered problem instance PI .
While it is also straightforward to directly prove this claim for our
crossover operator, we just obtain it as a corollary to the general
result from [25] because our crossover operator is just a special
implementation of that procedure.

Lemma B.2 (Secure crossover as generic crossover). Given
a computation type graph with multiplicities TG, a problem in-
stance PI for it, and two solutions ùê∫ and ùêª for PI , applying secure
crossover as defined in Algorithm 1 is a special instance of applying
generic crossover as defined in [25].

Proof. By construction, ùê∫sub and ùêªsub, which take that parts
of ùê∫1 and ùêª2 in generic crossover, are subgraphs of ùê∫ and ùêª , re-
spectively, that contain the given problem graph PI P; also the
constructed crossover point CP always contains PI P. As ùê∫2 and
ùêª1 we choose ùê∫ and ùêª , respectively, which results in the split points

being given as ùê∫I = ùê∫sub and ùêªI = ùêªsub. Finally, CP is a com-
mon subgraph of ùê∫sub and ùêªsub. Hence, the construction of secure
‚ñ°
crossover implements a specific variant of generic crossover.

Corollary B.3 (Structural correctness of offspring). Given
a computation type graph with multiplicities TG, a problem in-
stance PI for it, and two solutions ùê∫ and ùêª for PI , applying secure
crossover as defined in Algorithm 1 results in two computation models
ùëÇ1 and ùëÇ2 that are solutions for PI .

Proof. Because of Lemma B.2 this is just a corollary to [25,
‚ñ°

Proposition 2].

In the rest of this section, we prove the results of the main paper.

Proof of Lemma 6.2. Let ùê∫ be a solution model as described
in the lemma. Let ùë•ùê∫sub be a node from ùëâùê∫sub , ùëíùëáùê∫ an edge type
and dir a direction. The function createGsub iterates through ev-
ery node in ùëâùê∫ , so eventually, it will consider ùë•ùê∫ , the equivalent
node for ùë•ùê∫sub in ùê∫. For ùë•ùê∫ , we first check whether it has already
been included in ùê∫sub. Since we have our node ùë•ùê∫sub , we can as-
sume it is included. This means that in line 8 we call the function
includeAdjacentEdges (Algorithm 7) for ùë•ùê∫ .

In this function, we iterate through every direction, and every
type that an edge connected to ùë•ùê∫ can have, so we will inevitably
also run the loop‚Äôs body for ùëíùëáùê∫ and dir . In that case, we include a
randomly selected number ùëõ of edges (of the according type and
direction), ensuring that the relevant lower bound is reached, or at
‚ñ°
least all possible edges are included (line 3).

Proof of Lemma 6.3. Let ùê∫, ùêª be the input solutions and ùëÇ be
the computed offspring. Let ùëíTGmod ‚àà ùê∏TGmod be an edge from
the modified type graph, dir one of the possible direction src or
tar for the edges, and

ùëùùëÇ ‚àà (cid:8)ùë• ‚àà ùëâùëÇ | ùë°ùëÇ (ùë•) = dir (ùëíTGmod )(cid:9)
a node from the offspring that can have edges of type ùëíTGmod . For
(ùëíTGmod ), we can see that it suffices
a set of edges to satisfy ùëödir
that

(cid:12)
(cid:12)

(cid:8)ùëí ‚Ä≤

ùëÇ ) = ùëùùëÇ (cid:9)(cid:12)

ùëÇ ‚àà ùê∏ùëÇ | ùë°ùëÇ (ùëí ‚Ä≤

ùëÇ ) = ùëíTGmod, dir (ùëí ‚Ä≤
where ùëò is the new, relaxed lower bound of TG mod, since the
second part of the relaxed multiplicity is always satisfied (as ùëó = ‚àó).
We might therefore write
ùëÇ ‚àà ùê∏ùëÇ | ùë°ùëÇ (ùëí ‚Ä≤

ùëÇ ) = ùëíTGmod, dir (ùëí ‚Ä≤
to note that the entire multiplicity is satisfied.

ùëÇ ) = ùëùùëÇ (cid:9)(cid:12)

(cid:12) ‚â• ùëò,

(cid:12) ‚â• ùëò

(cid:8)ùëí ‚Ä≤

(cid:12)
(cid:12)

The node ùëùùëÇ can stem either solely from ùê∫sub, with no preimage
in CP , solely from ùêªsub, or from both, with a preimage ùëùCP in
ùëâCP . We therefore observe the three cases:

(1) ùëùùëÇ stems solely from ùê∫sub:
In this case, all edges ùëí ‚Ä≤
ùëÇ with ùë°ùëÇ (ùëí ‚Ä≤
ùëÇ ) =
ùëùùëÇ must also stem solely from ùê∫sub, without a preimage
in CP . This is due to the fact that CP ‚Ü©‚Üí ùê∫sub is a graph
morphism. This means that
ùëÇ ‚àà ùê∏ùëÇ | ùë°ùëÇ (ùëí ‚Ä≤

ùëÇ ) = ùëíùëáùê∫ and dir (ùëí ‚Ä≤

ùëÇ ) = ùëíTGmod, dir (ùëí ‚Ä≤

(cid:12)
(cid:8)ùëí ‚Ä≤
(cid:12)
‚àà ùê∏ùê∫sub | ùë°ùê∫sub (ùëí ‚Ä≤

(cid:12)
(cid:12)
(cid:12)

(cid:110)
ùëí ‚Ä≤
ùê∫sub

) = ùëíTGmod, dir (ùëí ‚Ä≤
and Lemma 6.2 then proves the statement.

ùê∫sub

ùê∫sub

ùëÇ ) = ùëùùëÇ (cid:9)(cid:12)
(cid:12) =
(cid:111)(cid:12)
(cid:12)
(cid:12) ,

) = ùëùùê∫sub

Henri Th√∂lke and Jens Kosiol

(2) ùëùùëÇ stems solely from ùêªsub:

ùëÇ with ùë°ùëÇ (ùëí ‚Ä≤

Again, this means all edges ùëí ‚Ä≤
ùëÇ ) = ùëíùëáùê∫ and
dir (ùëí ‚Ä≤
ùëÇ ) = ùëùùëÇ must also stem solely from ùêªsub. During
the construction of ùêªsub, each node that we include must
be processed by Algorithm 5. This means that in line 14, we
called function ensureMinimumFreeNode for that respective
node. Since ùëùùëÇ is part of ùêªsub, that call returned true, mean-
ing that the node either satisfies the respective lower bound
or is at least attached to as many edges as are provided by
ùêª .

(3) There exists a preimage ùëùCP for ùëùùëÇ :

To begin with, if ùëùùëÇ has a preimage ùëùCP in the crossover
point, then there must be a ùëùùê∫sub in ùê∫sub. The number of
edges at ùëùùëÇ must be therefore be greater or equal than the
number of edges at ùëùùê∫sub at the start of the construction of
the CP . As seen in Case (1) this number of edges satisfies
the requirement. During construction of the crossover point,
we only reduce the number of edges in one instance, that is
when we swap edges. If we swap edges (Algorithm 4), we
always include a new edge to replace the one we removed.
We also then ensure in line 37 of Algorithm 3 that our newly
included replacement does not get included in CP , thus
maintaining the same number of edges. All other instances
merely add edges.

The statement for the case of feasible input is an immediate
consequence of the above considerations because, in that case, the
original lower bound ùëñ coincides with the relaxed lower bound
‚ñ°
ùëò.

Proof of Lemma 6.4. Let ùê∫, ùêª be the input solutions and ùëÇ be
the computed offspring. Let ùëíTGmod ‚àà ùê∏TGmod be an edge from
the modified type graph, dir one of the possible direction src or
tar for the edges, and

ùëùùëÇ ‚àà (cid:8)ùë• ‚àà ùëâùëÇ | ùë°ùëáùê∫mod (ùë•) = dir (ùëíTGmod )(cid:9)
a node from the offspring that can have edges of type ùëíTGmod . For
(ùëíTGmod ), we can see that it suffices
a set of edges to satisfy ùëödir
that

(cid:12)
(cid:12)

(cid:8)ùëí ‚Ä≤

ùëÇ ‚àà ùê∏ùëÇ | ùë°ùëÇ (ùëí ‚Ä≤

ùëÇ ) = ùëíTGmod, dir (ùëí ‚Ä≤
, where ùëò is the relaxed upper bound of TG mod, since the first part
of the multiplicity is always true (as ùëñ = 0). We might therefore
write

ùëÇ ) = ùëùùëÇ (cid:9)(cid:12)

(cid:12) ‚â§ ùëò,

(cid:12)
(cid:12)

(cid:8)ùëí ‚Ä≤

ùëÇ ‚àà ùê∏ùëÇ | ùë°ùëÇ (ùëí ‚Ä≤

ùëÇ ) = ùëíTGmod, dir (ùëí ‚Ä≤
to note that the entire multiplicity is satisfied.

ùëÇ ) = ùëùùëÇ (cid:9)(cid:12)

(cid:12) ‚â§ ùëò

The node ùëùùëÇ can stem either solely from ùê∫sub, with no inverse
image in CP , solely from ùêªsub, or from both, with an inverse image
ùëùCP in ùëâCP . We therefore observe the three cases:

(1) ùëùùëÇ stems solely from ùê∫sub:
ùëÇ with ùë°ùëÇ (ùëí ‚Ä≤
In this case, all edges ùëí ‚Ä≤
ùëÇ ) =
ùëùùëÇ must also stem solely from ùê∫sub, without an inverse
image in CP . This is due to the fact that CP ‚Ü©‚Üí ùê∫sub is a
graph morphism. This means that

ùëÇ ) = ùëíùëáùê∫ and dir (ùëí ‚Ä≤

(cid:12)
(cid:8)ùëí ‚Ä≤
(cid:12)
‚àà ùê∏ùê∫sub | ùë°ùê∫sub (ùëí ‚Ä≤

(cid:12)
(cid:12)
(cid:12)

(cid:110)
ùëí ‚Ä≤
ùê∫sub

ùëÇ ‚àà ùê∏ùëÇ | ùë°ùëÇ (ùëí ‚Ä≤

ùëÇ ) = ùëíTGmod, dir (ùëí ‚Ä≤

) = ùëíTGmod, dir (ùëí ‚Ä≤

ùê∫sub

ùê∫sub

ùëÇ ) = ùëùùëÇ (cid:9)(cid:12)
(cid:12) =
(cid:111)(cid:12)
(cid:12)
(cid:12) ,

) = ùëùùê∫sub

A multiplicity-preserving crossover operator on graphs

which is smaller than ùëò by the definition of ùëò.

(2) ùëùùëÇ stems solely from ùêªsub:

ùëÇ ) = ùëíùëáùê∫ and
ùëÇ ) = ùëùùëÇ must also stem solely from ùêªsub. Since ùêªsub

Again, this means all edges ùëí ‚Ä≤
dir (ùëí ‚Ä≤
is a subgraph of ùêª , it follows that

ùëÇ with ùë°ùëÇ (ùëí ‚Ä≤

(cid:12)
(cid:12)
(cid:12)

(cid:110)
ùëí ‚Ä≤
ùêªsub

ùëÇ ‚àà ùê∏ùëÇ | ùë°ùëÇ (ùëí ‚Ä≤

) = ùëíTGmod, dir (ùëí ‚Ä≤

ùëÇ ) = ùëíTGmod, dir (ùëí ‚Ä≤

(cid:12)
ùëÇ ) = ùëùùëÇ (cid:9)(cid:12)
(cid:8)ùëí ‚Ä≤
(cid:12) =
(cid:12)
(cid:111)(cid:12)
‚àà ùê∏ùêªsub | ùë°ùêªsub (ùëí ‚Ä≤
(cid:12)
(cid:12) .
As every inclusion of an edge into ùêªsub is checked for not
introducing an upper bound violation (in any direction), in
this case we can even conclude that the original upper bound
ùëó is satisfied.

) = ùëùùêªsub

ùêªsub

ùêªsub

(3) There exists an inverse image ùëùCP for ùëùùëÇ

To begin with, if ùëùùëÇ has an inverse image ùëùCP in the crossover
point, then there must be a ùëùùê∫sub in ùê∫sub. The number of
edges at ùëùùëÇ must be therefore be equal to the number of
edges at ùëùùê∫sub at the start of the construction of the CP .
As seen in Case (1), this number of edges satisfies the re-
laxed multiplicity ùëò. During construction of the crossover
point, we only increase the number of edges after specifically
checking that the inclusion does not breach the maximum.
Again,the statement for the case of feasible input is an immediate
consequence of the above considerations because, in that case, the
original upper bound ùëó coincides with the relaxed upper bound
‚ñ°
ùëò.

Proof of Theorem 6.1. The claim follows from combining Lem-
‚ñ°

mas 6.3 and 6.4.

Proof of Proposition 6.5. We describe a construction of ùê∫ and
ùêª , starting from ùëÇ. For this, we describe, how to obtain the sub-
graphs ùê∫sub and ùêªsub from ùëÇ, along with the crossover point CP .
To obtain the subgraphs, we first choose a subgraph ùëÇsub to
act as our ùê∫sub from our algorithm. The subgraph ùëÇsub must be
feasible, so specifically all lower bounds are satisfied. All elements
in ùëÇ not chosen for ùëÇsub are part of ùêªsub. If an edge from ùêªsub
connects to a node in ùëÇsub, we make the node in ùëÇsub part of the
crossover point.

We can always obtain the resulting structures from our algo-
rithm. It should be obvious to see how we could obtain ùëÇsub, or in
that direction ùê∫sub, as a subgraph of a larger graph ùê∫. Given the
appropriate ùêª , we can then choose to add exactly those nodes to
the crossover point, that we included in the crossover point in our
construction.

This construction delivers subgraphs ùê∫sub and ùêªsub, along with
a crossover point CP . Since ùê∫sub already is feasible, we do not
need to, but can change it further to achieve ùê∫, for ùêªsub we might
need to add elements to ensure feasibility. We can always create a
feasible ùêª to ùêªsub, the existence of such a graph is shown by the
‚ñ°
existence of ùëÇ.

