A multiplicity-preserving crossover operator on graphs
Extended version

Henri ThÃ¶lke
Thoelke@students.uni-marburg.de
Philipps-UniversitÃ¤t Marburg
Marburg, Germany

Jens Kosiol
kosiolje@mathematik.uni-marburg.de
Philipps-UniversitÃ¤t Marburg
Marburg, Germany

2
2
0
2

g
u
A
3
2

]
E
N
.
s
c
[

1
v
1
8
8
0
1
.
8
0
2
2
:
v
i
X
r
a

ABSTRACT
Evolutionary algorithms usually explore a search space of solutions
by means of crossover and mutation. While a mutation consists
of a small, local modification of a solution, crossover mixes the
genetic information of two solutions to compute a new one. For
model-driven optimization (MDO), where models directly serve as
possible solutions (instead of first transforming them into another
representation), only recently a generic crossover operator has
been developed. Using graphs as a formal foundation for models,
we further refine this operator in such a way that additional well-
formedness constraints are preserved: We prove that, given two
models that satisfy a given set of multiplicity constraints as input,
our refined crossover operator computes two new models as output
that also satisfy the set of constraints.

CCS CONCEPTS
â€¢ Computing methodologies â†’ Randomized search; â€¢ Soft-
ware and its engineering â†’ Search-based software engineering.

KEYWORDS
evolutionary algorithms, crossover, model-driven optimization, con-
sistency-preservation

1 INTRODUCTION
Model-driven optimization (MDO) performs optimization directly
on domain-specific models. Early motivation for developing MDO
has been that modeling allows for a very expressive representa-
tion of optimization problems and their solutions across different
domains; at the same time, it allows expressing problems and solu-
tions in domain-specific (modeling) languages, potentially making
optimization more accessible for domain experts, e.g., [6, 7, 16].
Furthermore, the explicit representation as a model enables one
to leverage domain knowledge to explore the search space more
effectively [16, 27]. While already been used in [16], there has been
increased awareness recently that MDO makes the search and its
employed operators amenable to the application of formal methods:
exploiting the formal grounding that graphs, graph transformations,
and logics on graphs provide for models, their transformations, and
their properties, properties of search operators or the whole search
process can be tested or even formally verified [5, 17, 19, 25].

In practical applications of MDO, often evolutionary algorithms
have been used to perform the actual optimization, e.g., [1, 2, 12, 17].
In an evolutionary algorithm, normally crossover and mutation drive
the search (see, e.g., [11]): Typically, given an objective (or fitness)
function (or a set of these) that formalizes the properties to be opti-
mized, an evolutionary algorithm starts with an initial population

of randomly generated solutions. Then, until a termination condi-
tion is met, a new population is computed from the current one.
For that, pairs of solutions are randomly selected from the current
population, to which crossover is applied with a certain proba-
bility; solutions with high fitness have a higher chance of being
selected. Crossover recombines parts of the two solutions, mixing
their genetic information. After crossover, the computed offspring
can additionally be subjected to mutation, where small local changes
are performed. From the old population and the newly computed
solutions the next population is randomly selected, again taking the
fitness of individual solutions (but possibly also other considera-
tions like maintenance of diversity) into account. An optimization
problem can also be constrained, meaning that additional feasibility
constraints restrict which solutions are considered to be feasible. In
the context of evolutionary algorithms, various approaches have
been suggested to deal with feasibility constraints [8, 22]. These
include immediately discarding infeasible solutions, developing
methods to repair them, decrementing their fitness (according to
the amount of violation of the feasibility constraints), or designing
crossover and mutation operators in such a way that feasibility of
solutions is always preserved.

In MDO, so far, model transformations have served as the primary
means to perform evolutionary search [1, 2, 5, 12, 16, 17, 19]. But, as
we will argue in more detail later (see Sect. 2), performing crossover
directly on models has not been adequately developed yet. Recently,
a generic crossover operator on graphs, which can serve as a basis
for crossover on models, has been introduced [25]; in the follow-
ing, we refer to this operator as generic crossover. When applying
generic crossover to two models, it is guaranteed that the com-
puted offspring at least conforms to the structure that is specified
by the given meta-model. However, meta-models, including those
that provide a syntax for the solution of optimization problems,
are typically equipped with additional well-formedness (or, in this
context, feasibility) constraints. The most basic and important of
these are multiplicities, restricting the allowed incidence relations
in instance models. The generic crossover operator does not take
any feasibility constraints into account, i.e., solutions computed
via crossover might violate the given constraints, even if the input
solutions satisfied these. In this work, we refine the generic crossover
operator from [25] towards secure crossover in such a way that it
cannot any longer introduce violations of multiplicity constraints.
Practical experience in MDO with evolutionary algorithms that are
solely based on mutation as an operator shows that evolutionary
search can profit if the used mutation rules cannot introduce new
violations of feasibility constraints [5, 17, 19]. Therefore, developing
crossover of models in such a way that feasibility is preserved is a
promising enterprise.

 
 
 
 
 
 
The direct contribution of this work is this refinement of an ex-
isting crossover operator on graphs in such a way that it preserves
the validity of multiplicity constraints. By detailedly developing the
according algorithms and formally proving their desired properties,
we further substantiate the intuition that using models directly
as representation of solutions of an optimization problem facil-
itates the reasoning about search operators and processes. It is
hardly conceivable to develop a crossover operator that preserves
multiplicities when models are encoded, e.g., as bit strings. A few
algorithmic details are transferred to Appendix A. All proofs (and
some additional results) are provided in Appendix B.

2 RELATED WORK
In this work, we develop a crossover operator on graphs that pre-
serves multiplicities. Generally, this operator refines the one intro-
duced in [25]; it is also inspired by crossover operators on permuta-
tions (see, e.g., [24]) to only compute one offspring. In the following,
we discuss how crossover has been performed in MDO so far, and
we discuss other crossover operators on graphs (or similar struc-
tures).

Crossover in MDO. In MDO, two encoding approaches have
emerged: the rule- and the model-based approach [18]. In the rule-
based approach (e.g., [1, 2, 4, 12, 16]), the data structure on which
optimization is performed is a sequence of applications of model
transformation rules. Such sequences also represent models (by
applying the sequence to a fixed start model). Since the chosen rep-
resentation is a sequence, classic crossover operators like ğ‘˜-point
or universal crossover are directly applicable. However, crossovers
may result in a sequence of transformations that is not applicable to
the start model. Repair techniques have been suggested to mitigate
that problem: inapplicable transformations of a sequence can be
discarded [1] or replaced by placeholders or random applicable
transformations [4]. These repairs, however, only serve to obtain
a sequence of applicable model transformations. Whether or not
the model that a sequence of transformations computes satisfies
feasibility constraints remains unclear.

In the model-based approach (e.g., [5, 17, 27]), optimization is
directly performed on models. Model transformation rules serve
as mutation operators. Zschaler and Mandow have suggested that
ideas from model differencing and merging could serve as basis for
a crossover operator directly applicable to models [27]. However,
except for a specific application in which crossover has been based
on transformation rules [17], evolutionary search on models as
search space has been performed via mutation only [5, 18, 19]. To
address this situation, we first developed the mentioned generic
crossover operator for graph-like structures [25]. Being generic and
based on graphs, it can serve as a formal foundation for crossover
operators on models, independently of their semantics or the em-
ployed modeling technology. However, its application can introduce
violations of feasibility constraints.

In parallel work [20], we suggest how to adapt that generic
crossover operator to models from the Eclipse Modeling Frame-
work (EMF) [9]. We ensure that the results of crossover conform to
the general structure of EMF models; however, we do not take addi-
tional well-formedness constraints like multiplicities into account.
In a first small evaluation, evolutionary search can profit from using

Henri ThÃ¶lke and Jens Kosiol

Figure 1: Metamodel (type graph) for the CRA case

both crossover and mutation (compared to only using mutation)
but only if violations of feasibility constraints that crossover intro-
duced are immediately repaired. Crossover hampers search when
used without repair. These results indicate that directly preserving
multiplicities, like we suggest in the current work, is a promising
enterprise. If possible, directly preserving constraints is a more
general approach as ad hoc repair operations might not always be
available.

Crossover on graphs. There are various approaches to crossover
on graphs (or similar structures), more often than not with a specific
semantics of the considered graphs in mind. Since we address typed
graphs and multiplicity constraints, which are both very general
concepts, we restrict our comparison to other crossover operators
that generally work on graphs and do not depend (too much) on
their assumed semantics. Crossover operators of which we are
aware that can be quite generically applied to graphs are [14, 21, 23].
In [14], connectedness properties of a graph are preserved, while
in [23] heuristics are used to increase the likelihood of preserving
acyclicity or certain reachability properties. In [21], no preservation
of constraints is addressed. To the best of our knowledge, we are the
first to formally ensure the preservation of such complex properties
as multiplicities for a crossover operator on graphs.

3 RUNNING EXAMPLE
The class responsibility assignment (CRA) case is an easy to grasp
use case for MDO that is still practically interesting. Having been
suggested as a contest problem in [13], it continues to be used as a
problem to illustrate new concepts in MDO with and to benchmark
them against [5, 19].

In the CRA case, a set of Features, representing Attributes and
Methods, and their interdependencies are given. It is searched for an
optimal assignment of the Features to Classes. Typically, a solution
is considered to be of high quality if its assignment of Features
to Classes exhibits low coupling between the Classes and high
cohesion inside of them; for details and a formalization of coupling
and cohesion as objective functions we refer to [13].

Fig. 1 depicts a metamodel (or type graph) that provides a syn-
tax to represent concrete problem instances and solutions for the
CRA case as models (for brevity, it is considerably simplified com-
pared to the metamodel provided in [13]). The black nodes serve to
model problem instances, namely a set of Features and their interde-
pendencies. The blue, dashed elements (Classes and their incident
edges) serve to extend problem instances to solutions, namely to
assign Features to Classes. The multiplicities serve to further pre-
scribe which instances of the metamodel are to be considered as
valid (or feasible) solutions. In our example they express that every
Class should at least encapsulate one Feature (1..âˆ—) and that every
Feature should be encapsulated by exactly one Class (1..1).

ClassFeature1..*1..1encapsulatesdependsOn1A multiplicity-preserving crossover operator on graphs

4 PRELIMINARIES
In this section we present our formal preliminaries, namely graphs,
computation elements with multiplicities, which serve as a formal
basis for models, and the generic crossover operator that we refine
in this work.

Definition 4.1 (Graph. Graph morphism). A (directed) graph ğº =
(ğ‘‰ , ğ¸, src, tar ) consists of finite sets of nodes ğ‘‰ and edges ğ¸, and
source and target functions src, tar : ğ¸ â†’ ğ‘‰ .

Given two graphs ğº and ğ» , a graph morphism ğ‘“ = (ğ‘“ğ‘‰ , ğ‘“ğ¸ ) : ğº â†’
ğ» is a pair of functions ğ‘“ğ‘‰ : ğ‘‰ğº â†’ ğ‘‰ğ» and ğ‘“ğ¸ : ğ¸ğº â†’ ğ¸ğ» such that
ğ‘“ğ‘‰ (srcğº (ğ‘’)) = srcğ» (ğ‘“ğ¸ (ğ‘’)) and ğ‘“ğ‘‰ (tarğº (ğ‘’)) = tar ğ» (ğ‘“ğ¸ (ğ‘’)) for
all edges ğ‘’ âˆˆ ğ¸ğº . A graph morphism is injective/surjective/bijective
if both of its components are.

A typed graph is a graph together with a graph morphism into
a fixed type graph. Intuitively, the type graph provides the avail-
able types for nodes and edges and their allowed incidence re-
lations. Using typing to provide graphs with a richer syntax is
well-established [10], in particular also when using typed graphs
as formal basis for models [3]. For our application, however, it is
advantageous to consider type graphs with more structure: Some el-
ements of the type graph serve to model the problem that has to be
optimized and others to create a solution. Encoding this distinction
into the type graph has led to the definition of computation type
graphs and their computation graphs [19, 25]. Multiplicities allow
expressing certain structural constraints (namely, lower and upper
bounds on edge types) that cannot be captured by typing alone;
a graph-based formalization is provided in [26]. In the following
definition of a computation type graph with multiplicities and its
computation graphs we bring together the definition of a type graph
with multiplicities with the one of computation (type) graphs.

Definition 4.2 (Computation type graph with multiplicities. Com-
putation graph). A multiplicity is a pair [ğ‘–, ğ‘—] âˆˆ N Ã— (N âˆª {âˆ—}) such
that ğ‘– â‰¤ ğ‘— or ğ‘— = âˆ—; Mult denotes the set of all multiplicities. A set
ğ‘‹ satisfies a multiplicity ğ‘š = [ğ‘–, ğ‘—] if |ğ‘‹ | â‰¥ ğ‘– and either |ğ‘‹ | â‰¤ ğ‘— or
ğ‘— = âˆ—; this satisfaction is denoted as |ğ‘‹ | âˆˆ ğ‘š. Via ğ‘šlb and ğ‘šub we
denote the projections to the first or second component.

A computation type graph with multiplicities is a tuple TG =
(TG P âŠ† TG, ğ‘šsrc, ğ‘štar), where TG is a graph, TG P a des-
ignated subgraph, and ğ‘šsrc, ğ‘štar : ğ¸TG â†’ Mult are functions,
called edge multiplicity functions. The graph TG is called the type
graph, and TG P the problem type graph.

A computation graph ğº = (ğº, ğ‘¡ğº ) over TG is a graph ğº together
with a graph morphism ğ‘¡ğº : ğº â†’ TG. The intersection of ğº with
TG P (in TG) is called the problem graph of ğº and is denoted as ğºP.
A morphism ğ‘“ : ğº â†’ ğ» between computation graphs ğº = (ğº, ğ‘¡ğº )
and ğ» = (ğ», ğ‘¡ğ» ) is a graph morphism ğ‘“ : ğº â†’ ğ» such that ğ‘¡ğ» â—¦ ğ‘“ =
ğ‘¡ğº .

A computation graph ğº = (ğº, ğ‘¡ğº ) typed over TG is said to satisfy
the multiplicities of a computation type graph with multiplicities
(TG P âŠ† TG, ğ‘šsrc, ğ‘štar) if

â€¢ for all edges ğ‘’ âˆˆ ğ¸TG and all nodes ğ‘ âˆˆ {ğ‘› âˆˆ ğ‘‰ğº | ğ‘¡ğº (ğ‘›) =

srcTG (ğ‘’)} it holds that
|{ğ‘’ â€² âˆˆ ğ¸ğº | ğ‘¡ğº (ğ‘’ â€²) = ğ‘’ and srcğº (ğ‘’ â€²) = ğ‘}| âˆˆ ğ‘štar (ğ‘’)
and

Figure 2: Two computation graphs for the CRA case that con-
stitute solutions for the same problem instance

â€¢ for all edges ğ‘’ âˆˆ ğ¸TG and all nodes ğ‘ âˆˆ {ğ‘› âˆˆ ğ‘‰ğº | ğ‘¡ğº (ğ‘›) =

tar TG (ğ‘’)} it holds that
|{ğ‘’ â€² âˆˆ ğ¸ğº | ğ‘¡ğº (ğ‘’ â€²) = ğ‘’ and tarğº (ğ‘’ â€²) = ğ‘}| âˆˆ ğ‘šsrc (ğ‘’).

A computation graph defines a problem instance via its prob-
lem graph; (candidate) solutions are all computation graphs with
coinciding problem graphs.

Definition 4.3 (Problem instance. Search space. Solution). Given
a computation type graph with multiplicities ğ‘‡ğº = (TG P âŠ†
TG, ğ‘šsrc, ğ‘štar), a problem instance for TG is a computation graph
PI over TG. The search space S(PI ) defined by PI consists of all
computation graphs ğº over TG for which there exists (a typing-
compatible) isomorphism between the problem graphs ğºP and
PI P; elements of S(PI ) are called candidate solutions, or solutions
for short, for the problem instance PI . A solution is feasible if it
satisfies the multiplicity constraints of TG and infeasible otherwise.
Example 4.4. Formally, the metamodel for the CRA case depicted
in Fig. 1 can considered to be a computation type graph with mul-
tiplicities; the black elements constitute the problem type graph;
the multiplicity functions are defined by the annotations of the
edges. Fig. 2 presents two feasible computation graphs ğº and ğ» .
The typing is indicated by denoting the nodes with their types;
edge types are omitted for brevity (they can unambiguously be
inferred). The identifiers f1 etc. just serve to be able to speak about
the individual elements. Because the problem graphs of ğº and ğ»
(the black Features plus edge) coincide, they constitute (feasible)
solutions for the same problem instance.

Summarizing, our setting is that a fixed meta-model with mul-
tiplicities provides the syntax to model different instances of an
optimization problem and their solutions. In our example, the gen-
eral optimization problem is the CRA case and concrete problem
instances are different configurations of Features and their inter-
dependencies for which an optimal assignment to Classes has to
be found. Generally, the problem model of an instance model de-
termines for which problem instance this model is a solution, i.e.,
to which search space it belongs. Evolutionary search, then, is per-
formed for a concrete problem instance, i.e., inside of a fixed search
space, which is determined by the isomorphic problem models of

f1:Featuref2:Featuref3:Featurec1:Classğºf1:Featuref2:Featuref3:Featurec2:Classc3:Classc4:Classğ»1its members. As mentioned in Sects. 1 and 2, it is established to
use model transformations (which do not change the problem part)
as mutation operators during evolutionary search. This paper is
concerned with developing a crossover operator that takes two
solutions from the same search space as input and computes off-
spring solutions that belong to the same search space. At that the
crossover operator shall produce feasible offsprings from feasible
input.

As foundation for that, we recall the generic crossover operator
that has been introduced in [25]. There, crossover is declaratively
defined and no constructive algorithm is provided; furthermore,
it is defined in an abstract category-theoretic setting. Intuitively,
that crossover operator prescribes that two input solutions are to
be split into two parts each and these parts are to be recombined
crosswise by computing a union. This results in two new solutions,
also called offspring. A crossover point serves to identify elements
from the two input solutions, i.e., it designates elements that are
only to appear once in the union. The next definition specializes
generic crossover to computation graphs.

Definition 4.5 (Generic crossover). Given a computation type
graph with multiplicities TG, a problem instance PI for it, and two
solutions ğº and ğ» from S(PI ), applying generic crossover amounts
to the following:

(1) Splitting: The underlying graph ğº of ğº is split into two sub-

graphs ğº1, ğº2 âŠ† ğº such that
(a) both ğº1 and ğº2 contain ğºP and
(b) every element of ğº belongs to either ğº1 or ğº2 (or both).
ğº1 and ğº2 become computation graphs by defining their
typing morphisms as the respective restrictions of ğ‘¡ğº . The
intersection ğºI of ğº1 and ğº2 (in ğº) is called split point. The
graph ğ» is split in the same way.

(2) Relating ğº and ğ» (crossover point): A further solution for
PI , i.e., a computation graph CP = (CP, ğ‘¡CP ) with prob-
lem graph CP P being isomorphic to PI P is determined
such that CP can be considered to be a subgraph of both
split points ğºI and ğ»I. Formally, this means that there are
injective morphisms from CP to ğºI and ğ»I. The solution
CP (together with the two injective morphisms) is called a
crossover point.

(3) Recombining: The underlying graph ğº1ğ»2 of the first off-
spring solution ğº1ğ»2 is computed as the union of ğº1 and
ğ»2 over CP . That is, elements from ğº1 and ğ»2 that share
a preimage in CP only appear once in the result. A typing
morphism ğ‘¡ğº1ğ»2 : ğº1ğ»2 â†’ TG is obtained by combining
the ones of ğº1 and ğ»2; hence, a computation graph ğº1ğ»2 is
computed. A second offspring solution ğº2ğ»1 is computed
analogously by unifying ğº2 and ğ»1 over CP .

The results obtained in [25] ensure that the two offspring so-
lutions computed in that way are indeed solutions for the given
problem model PI : their typing morphisms are well-defined and
their problem graphs are isomorphic to PI P [25, Prop. 2]. More-
over, no matter how the splits of the input graphs ğº and ğ» are
chosen, a crossover point can be found; thus, crossover is always
applicable [25, Lem. 1]. Albeit, the computed offspring does not

Henri ThÃ¶lke and Jens Kosiol

Figure 3: Two computation graphs resulting as offspring
from generic crossover

need to satisfy the given multiplicity constraints, even if the inputs
ğº and ğ» and/or the split parts ğº1, ğº2, ğ»1, ğ»2 do.

Example 4.6. Figure 3 depicts two solutions that can result from
applying generic crossover to the computation graphs ğº and ğ» from
Fig. 2. In the corresponding computations, ğº is split such that ğº1
does not contain the reference from Class c1 to Feature f3 and ğº2
is the whole of ğº. Consequently, ğºI coincides with ğº1. Similarly,
ğ» is split by omitting the reference from Class c4 to Feature f3
in ğ»1 and omitting Class c3 together with its reference from ğ»2.
Consequently, ğ»I contains the three Classes c2, c3, c4 but only the
reference from c2 to f1. As crossover point, we choose a graph that,
beyond the given problem graph, contains a common preimage for
Classes c1 and c2 and their respective reference to Feature f1, thus
identifying them. As can be seen, the resulting offspring ğº1ğ»2 is
desirable as it assigns the independent Feature f3 to its own Class.
In contrast, offspring ğº2ğ»1 is infeasible, containing an empty Class
(i.e., a Class with no Feature) and a multiply assigned Feature.

We close this section with introducing some abbreviating nota-
tions and simplifying assumptions. First, we assume the problem
graphs of the occurring computation graphs to be identical (and
not merely isomorphic). Furthermore, from a formal point of view,
morphisms (and inclusions) relate the different occurring graphs
like split parts, split points, crossover points etc. Considering these
explicitly leads to quite some notational overhead. To avoid that, we
use common names of variables and indices to convey the relation
between elements. For example, we write ğ‘¥ğº , ğ‘¥ğº1 , ğ‘¥PI P , ğ‘¥CP , etc.
to indicate that the node ğ‘¥CP from crossover point CP is mapped
to the node ğ‘¥PI P in the problem part, the node ğ‘¥ğº1 in split part ğº1
of a computation graph ğº, etc.

5 INTRODUCING SECURE CROSSOVER ON

GRAPHS

In this section, we introduce our crossover operator, which we
call secure crossover, and prove its central properties, namely being
multiplicity-preserving (feasibility-preserving) and still being able
to produce any valid graph as offspring (coverage of search space).
As mentioned, we develop our crossover operator as a refinement of

f1:Featuref2:Featuref3:Featurec1=c2:Classc4:Classğº1ğ»2f1:Featuref2:Featuref3:Featurec1=c2:Classc3:Classc4:Classğº2ğ»11A multiplicity-preserving crossover operator on graphs

the one introduced in [25] and recalled in Sect. 4. Our construction
is guided by the following objectives.

(1) Applied to feasible input graphs, secure crossover shall com-

pute feasible offsprings.

(2) The search space should not get unnecessarily restricted by

our operator.
At least, it should be possible to obtain every feasible graph
as a result from crossover. That is, our operator should not
cut off feasible regions from the search space.

(3) It should be possible to perform crossover efficiently.

Finding splits of two graphs, however, and a crossover point
such that both computed offspring solutions satisfy all multiplici-
ties seems to require intensive analysis and becomes very inefficient.
Therefore, we take inspiration from crossover operators that have
been developed for the case where permutations (of numbers) are
chosen as representation. There, to ensure that crossover of two
permutations results in a permutation again, several crossover oper-
ators have been developed that only compute one offspring solution
(see, e.g., [24] for an overview). Analogously, in this work the basic
idea is to focus entirely on one offspring solution. Computing a
single feasible offspring requires significantly less computational
effort than ensuring both offsprings to be feasible. We suspect that
it could be cheaper to apply the operator we propose in this paper
twice, instead of trying to compute an application of a crossover
operator with two feasible offsprings.

Since, for formal reasons, we still want our suggested crossover
operator to adhere to the definition of generic crossover, we suggest
a trivial way to compute a second solution (namely, to just unify
the whole given solution graphs ğº and ğ» over the crossover point
selected to compute the first offspring). However, in an implemen-
tation one would probably just omit this step as the likelihood of
this second offspring being valuable is very low. Accordingly, in the
following we entirely focus on the presentation of the computation
of the first offspring.

In all of the following, we assume to be given two computation
graphs ğº and ğ» that are solutions for the same fixed problem
instance PI (all typed over the same computation type graph with
multiplicities ğ‘‡ğº). We will mainly speak about their underlying
graphs ğº, ğ» , PI , etc. and treat their typing implicitly. Recall that
PI P refers to the problem graph of PI that captures the concrete
problem instance that is to be optimized.

5.1 General procedure
Our general procedure is presented in Algorithm 1 and works as
follows: We construct a subgraph ğºsub of ğº as a first split part in
such a way that ğºsub is always feasible when ğº is (line 1). Knowing
ğºsub, we construct ğ»sub (as a second split part of ğ» ) and a crossover
point CP in parallel, monitoring that applying crossover with that
data is not going to introduce new violations of the multiplicity
constraints (lines 2â€“4). Computing the crossover point CP and
ğ»sub simultaneously allows for a much easier handling of the upper
bound of the multiplicities: Whenever a node is included into CP ,
all edges that attach to that nodeâ€™s counterparts in ğºsub and ğ»sub
will be present in the offspring, attached to that node from CP .
This can lead to the resulting amount of edges being higher than the
multiplicity permits. If we were to compute ğ»sub first, we would

therefore not be able to ensure that a later choice of CP could not
lead to any breach of a maximum. These breaches would either need
to be avoided when computing CP , which might not always be
possible, or we would be forced to alter ğºsub and ğ»sub, creating a lot
of additional computational effort. This can be avoided by selecting
CP alongside the subgraph ğ»sub. Finally, the offspring solution
ğ‘‚1 is computed as the union of ğºsub and ğ»sub over CP (line 5).
As already mentioned, to still comply with generic crossover, we
formally also compute a second offspring ğ‘‚2 as the union of ğº and
ğ» over CP ; however, we do not expect to perform this computation
in practice.

Algorithm 1 secureCrossover(ğº, ğ», PI P)

1: ğºsub â† createGsub(ğº, PI P)
2: global CP, ğ»sub â† PI P
3: constructCP(ğºsub, ğ» )
4: processFreeNodes(ğºsub, ğ», ğ»sub)
5: ğ‘‚1 â† ğºsub âˆªCP ğ»sub
6: ğ‘‚2 â† ğº âˆªCP ğ»

5.2 Creating ğºsub
The creation of ğºsub is detailed in Algorithm 2. We initialize ğºsub
with PI P as the problem graph is to be included anyhow. Then,
for all remaining nodes of ğº, we check whether they are already
included in ğºsub (e.g., because they serve as target node for an
included egde) and, if not, we randomly decide whether or not the
node should be included (line 5). For included nodes, we also include
adjacent edges (line 8). Both nodes and edges are understood to be
included into ğºsub with they same type they have in ğº. Formally,
ğºsub becomes a computation graph over ğ‘‡ğº by defining its type
function ğ‘¡ğºsub as restriction of ğ‘¡ğº to ğºsub. For simplicity, we leave
this implicit in the pseudocode and in all of the following.

Algorithm 2 createGsub(ğº, PI P)

1: ğºsub â† PI P
2: for all ğ‘¥ğº âˆˆ ğ‘‰ğº do
3:

bool included â† ğ‘¥ğºsub âˆˆ ğ‘‰ğºsub
if !included then

included â† decideInclusion(ğ‘¥ğº )

end if
if included then

includeAdjacentEdges(ğ‘¥ğº, ğº)

4:

5:

6:

7:

8:

end if
9:
10: end for

The inclusion of edges is done by including a random set of
the edges of ğº in ğºsub whose size is between the required lower
and upper bound. In case it should not be possible to reach the
lower bound (because this is violated in ğº) at least all the available
edges are included in ğºsub. We provide an algorithm for this and
an extended explanation in Appendix A.

Example 5.1. In the CRA case, called for a feasible solution ğº,
createGsub will always return the whole of ğº as ğºsub. All Features
are directly included into ğºsub because they are part of the problem

graph. Since the incoming encapsulates-edge has a source multiplic-
ity of [1, 1], for every Feature-node the call of includeAdjacentEdges
includes the incoming encapsulates-edge (that exists because of fea-
sibility) and the Class from which it starts. Since, again by feasibility,
empty Classes cannot occur, that process results in ğº.

5.3 Creating ğ»sub and CP
The main difficulty in constructing ğ»sub and CP is that, as soon as
a node ğ‘¥CP in the crossover point prescribes that nodes ğ‘¥ğºsub from
ğºsub and ğ‘¥ğ»sub from ğ»sub are to be identified in the offspring, we
need to ensure that no upper bound violations can be introduced by
that identification: Even if in both ğºsub and ğ»sub the upper bounds
are satisfied, the sum of adjacent edges of a certain type of edges
to ğ‘¥ğºsub in ğºsub and ğ‘¥ğ»sub in ğ»sub might exceed the upper bound
of that type of edge. Constructing ğ»sub and CP in parallel, we can
react to that by either (i) not including too many edges in ğ»sub, (ii)
also including the edges into CP (which reduces their number in
the offspring), or (iii) dropping edges from ğºsub. As nodes from
CP are the sensitive issue, we start constructing ğ»sub and CP
along the nodes we know to appear in them â€“ the nodes from the
problem graph PI P; it actually suffices to start form the border of
PI P in ğ» , namely the nodes of PI P which have an adjacent edge
(in ğ» ) to a node that does not belong to PI P.

Algorithm 3 provides the computations of the split part ğ»sub
and the crossover point CP . We begin with adding all nodes of the
border of the problem part to a queue ğ‘„ (line 2). Let ğ‘¥ğ» be the node
we are currently handling (line 3). We start by iterating through
each of the edges attached to ğ‘¥ğ» (lines 4â€“6). For each such edge ğ‘’ğ» ,
and corresponding neighboring node ğ‘¦ğ» , we first check whether ğ‘¦ğ»
already belongs to ğ»sub and, if so, whether the edge ğ‘’ğ» also already
belongs to ğ»sub or ğ‘¦ğ» already to CP (lines 7â€“15). If ğ‘’ğ» already
belongs to ğ»sub we can skip the treatment of that edge. It means
that ğ‘¦ğ» has already been processed and, hence, ğ‘’ğ» adequately been
treated. If ğ‘¦ğ» belongs to CP , this makes an important difference
for the possible treatment of ğ‘’ğ» later on. If ğ‘¦ğ» does not already
belong to ğ»sub (and, consequently, also not to CP ), we can decide
randomly if we intend to include it in ğ»sub (line 17). We then can,
again randomly, decide whether we also want to include ğ‘’ğ» in ğ»sub
(line 20). Should we decide that we want to include neither ğ‘¦ğ» nor
ğ‘’ğ» into ğ»sub, we can move to the next edge.

If ğ‘¦ already belongs to CP and, seen in the direction from ğ‘¦
to ğ‘¥, the upper bound of the type of ğ‘’ has already been reached,
there is a single possibility to include ğ‘’ğ» in ğ»sub, namely also
including it in CP , that is, identifying it with an edge of the same
type between ğ‘¥ and ğ‘¦ that stems from ğºsub. Any other way of
including ğ‘’ğ» in ğ»sub would result in an upper bound violation in
the to be computed offspring. Without providing the details, this
procedure is performed by the function includeIntoCP (line 23); if
inclusion is possible, it is performed, otherwise ğ‘’ğ» is not included
in ğ»sub. In either case, the remaining iteration for ğ‘’ğ» is skipped.
The most options are available if we decide to include both ğ‘¦ğ»
and also ğ‘’ğ» in ğ»sub (beginning with line 26): The first option we
have is to swap the edge ğ‘’ğ» with another edge (of the same type)
adjacent to ğ‘¥ that stems from ğºsub (line 26). This possibility serves
to increase the expressiveness of the operator; recall from Exam-
ple 5.1 that the creation of ğºsub might enforce all edges adjacent to

Henri ThÃ¶lke and Jens Kosiol

Algorithm 3 constructCP(ğºsub, ğ» )
1: queue ğ‘„ â† border(PI P, ğ» )
2: while ğ‘„.notEmpty() do
3:

ğ‘¥ğ» â† ğ‘„.pop()
for all dir âˆˆ {src, tar } do

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

22:

23:

24:

25:

26:

27:

28:

29:

30:

31:

32:

33:

34:

35:

36:

37:

38:

39:

40:

41:

42:

for all ğ‘’ âˆˆ ğ¸TG with dir TG (ğ‘’) = ğ‘¡ğ» (ğ‘¥ğ» ) do
ğ» âˆˆ edges (ğ», ğ‘’, dir, ğ‘¥ğ» ) do

for all ğ‘’ â€²

ğ‘¦ğ» â† dir (ğ‘’ğ» )
bool included â† ğ‘¦ğ» âˆˆ ğ‘‰ğ»sub
if included then

bool edgeIncluded â† ğ‘’ â€²
if edgeIncluded then

ğ» âˆˆ ğ¸ğ»sub

skip
end if
bool includedCP â† ğ‘¦ğ» âˆˆ ğ‘‰CP

end if
if !included then

included â† decideInclusion(ğ‘¦ğ» )

end if
if included then

edgeIncluded â† decideInclusion(ğ‘’ğ» )
if edgeIncluded then

if includedCP âˆ§ edgeCount(ğ», ğº, ğ‘’, dir, ğ‘¦)+1 >

ğ‘šub

dir then

then

includeIntoCP(ğ‘’ğ» )
skip
end if
bool swapped â† randomEdgeSwap(ğ‘¥ğº, ğ‘’ â€²
ğ» , ğºsub)
if !swapped âˆ§ edgeCount(ğ», ğº, ğ‘’, dir, ğ‘¥)+1 > ğ‘šub
dir

bool resFound â† resolveBreach(ğ‘„, ğ‘¥, ğ‘’ â€²
if !resFound then

ğ» , dir, ğ‘’)

skip
end if

end if
ğ¸ğ»sub = ğ¸ğ»sub âˆª {ğ‘’ â€²

}

ğ»sub

end if
ğ‘‰ğ»sub = ğ‘‰ğ»sub âˆª {ğ‘¦ğ»sub }

We might want to include a node ğ‘¦ğ¶ğ‘ƒ even if not required
includedCP

bool

randomNodeToCP(ğ‘„, ğ‘¥, ğ‘’ â€², dir, ğ‘’)

â†

if edgeIncluded âˆ§ includedCP âˆ§!swapped then

randomEdgeToCP()

end if

end if
end for

end for

end for
43:
44: end while

ğ‘¥ğº in ğº to also be part of ğºsub. Swapping an edge means to choose
an edge of the same type as ğ‘’ğ» that is attached to ğ‘¥ğº in ğºsub and to
remove it from ğºsub; this procedure is sketched as Algorithm 4. In
picking an edge ğ‘’ğº from ğºsub to swap, we have to check whether
removing that edge from ğºsub leads to a lower bound violation in

A multiplicity-preserving crossover operator on graphs

Algorithm 4 randomEdgeSwap(ğ‘¥, ğ‘’ â€², ğºsub)
1: bool ğ‘ ğ‘¤ğ‘ğ‘ â† decideSwap()
2: if !ğ‘ ğ‘¤ğ‘ğ‘ then
return false
3:
4: else
5:

ğ‘’ğº â† pickSwapEdgeG(ğ‘¥, ğ‘’ â€², ğºsub)
if ğ‘’ğº == null then
return false

6:

7:

8:

9:

10:

else

ğ¸ğºsub â† ğ¸ğºsub \ {ğ‘’ğº }
return true

end if

11:
12: end if

the direction opposite to the one in which we are currently working
(that check is not detailed in the algorithm). If no suitable edge is
available, swapping fails. Note that this swapping of edges does
not affect the multiplicities of the node ğ‘¥ under consideration: We
remove an edge (that stems from ğº) and replace it by one (that
stems from ğ» ) of the same type.

The second option, if we do not decide to swap the edge, is to
simply add it to the offspring (lines 27â€“31). If we intend to do this,
the amount of edges at the offspring version of ğ‘¥ would increase
by one. This could lead to a breach of the maximum. If we detect
this, we can try to fix the situation by resolveBreach, presented as
Algorithm 8 in Appendix A. Substantially, we need to try adding the
pair of ğ‘¦ and ğ‘’ â€² to the crossover point. Doing this would essentially
remove the added edge in the offspring, maintaining our maximum.
To add ğ‘¦ and ğ‘’ â€² to the crossover point, we need to find a node ğ‘§
in ğºsub, that is of the same type as ğ‘¦, is not part of the crossover
point yet, and is connected to ğ‘¥ via an edge of the same type as
ğ‘’ â€². Furthermore, the edges that are adjacent to that node ğ‘§ in ğºsub
may not introduce a violation of an upper bound when combined
with the edges that are already adjacent to ğ‘¦ğ» in ğ» (if such edges
exist). We search for such a node by iterating through all edges
of the same type as ğ‘’ â€², that are attached to ğ‘¥. If we find such a
node, we create a node in the crossover point, fixing our breach.
We then only need to enqueue ğ‘¦. If we cannot find such a node ğ‘§,
then we give up on finding a fix to the breach, instead discarding
the addition of ğ‘¦ and ğ‘’ â€² to ğ»sub. For simplicity, we decided to have
a failure to resolve the conflict to result in skipping the current
edge type entirely. Alternatively, it would be possible to try again
to swap the edge.

Once we determined that it is safe to add ğ‘¦ and ğ‘’ â€² in the chosen
way, we add them to ğ»sub (lines 33 and 35). Note that, until now, we
have only added ğ‘¦ and/or ğ‘’ â€² to the crossover point if we were forced
to do so to prevent upper bound violations (via function includeIn-
toCP or resolveBreach). To increase expressiveness, it should also be
possible to randomly include ğ‘¦ and, if ğ‘¦ is included, possibly also ğ‘’ â€²
in CP . This functionality is provided by functions randomNodeToCP
and randomEdgeToCP in lines 36â€“39 of Algorithm 3. Like in resolve-
Breach, adding ğ‘¦ğ» to the crossover point means choosing a node of
the same type in ğºsub that is not yet included in CP , and adding
a new node to the crossover point, merging them together in the
offspring (after performing the necessary checks).

If we decide to include ğ‘¦ in the crossover point, and we did not
swap an edge earlier, we can then choose to also include ğ‘’ â€² in the
crossover point along with ğ‘¦. This is only safe to do if we did not
swap any edge. If we decided to both remove an edge in ğºsub, and
then combine another edge with ğ‘’ â€², which was set to replace the
deleted edge, we would end up reducing the amount of edges by
one. Since this could breach the minimum, we disallow it entirely.

Algorithm 5 processFreeNodes(ğºsub, ğ», ğ»sub)
1: queue ğ‘„ â† unprocessed nodes from ğ»
2: while ğ‘„.notEmpty() do
3:

ğ‘¥ğ» â† ğ‘„.pop()
bool included â† ğ‘¥ğ» âˆˆ ğ‘‰ğ»sub
if !included then

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

included â† decideInclusion(ğ‘¥ğ» )

end if
if included then

bool tryCP â† decideInclusionCP(ğ‘¥ğ»sub )
if tryCP then

bool includeCP â† verifyInclusion(ğ‘¥ğ»sub )

end if
if !includeCP then

bool minEnsured â† ensureMinimumFreeNode(ğ‘¥ğ»sub )
if !minEnsured then
removeNode(ğ‘¥ğ»sub )

this needs to be cascading the removal as described in the text

end if

else

To find a node to merge ğ‘¥ğ»sub with, simply pick a node of equal
type in ğºsub, that is not yet part of the crossover point

addToCP(ğ‘¥ğ»sub )
randomIncludeMoreEdges()

this basically follows ensureMinimumFreeNode, just instead
of checking if the minimum has been reached, we check
whether the maximum has not been reached yet.

21:

end if

end if

22:
23: end while

Function constructCP (Algorithm 3) builds a crossover point with
all edges and nodes in ğ» that neighbor a node in CP being already
decided on. This means that after calling constructCP, ğ»sub contains
all nodes we selected for the crossover point, along with the nodes
and edges chosen to be included in ğ»sub but not CP . To further
increase expressivity, it should also be possible to include nodes (and
their adjacent edges) in ğ»sub and possibly CP that have not been
visited so far. Furthermore, we might have added nodes to ğ»sub
without ensuring their lower bound. To address both issues, after
constructCP, secureCrossover (Algorithm 1) calls processFreeNodes
as introduced in Algorithm 5.

We start the function processFreeNodes with a queue ğ‘„ that con-
tains all nodes of ğ» that have not been processed during constructCP,
i.e., all nodes of ğ» that are not yet part of ğ»sub and that never oc-
curred in the queue ğ‘„ during the call of constructCP, and all nodes
that belong to ğ»sub without also belonging to CP . These are nodes
for which we never decided whether or not they should be part of

ğ»sub and CP , or for which we did not yet ensure satisfaction of
lower bounds. In processFreeNodes, we first check whether or not
the currently considered node ğ‘¥ğ» is already part of ğ»sub and, if not,
give the node a random chance of being included in ğ»sub (line 4â€“7).
(While the check is unnecessary at the very start of the algorithm,
it is necessary later on when nodes from ğ‘„ that have not been
reached yet might have already been included in ğ»sub, triggered by
the inclusion of adjacent edges.) In the next step, if the node is to
be included, we randomly decide whether it also shall be included
in CP (line 9); the function decideInclusionCP is understood to (i)
randomly decide whether or not ğ‘¥ğ» shall be included in CP and,
if so, to check whether or not a node of the same type that does
not yet belong to CP is available in ğºsub. This leaves us with two
situations: If ğ‘¥ğ» is to be included in CP , it gets identified with a
node from ğºsub that brings enough edges to satisfy lower bounds
(provided feasibility of ğº). However, we need to ensure that the
identification does not introduce violations of upper bounds (in
case ğ»sub already contains edges adjacent to ğ‘¥ğ» ). If ğ‘¥ğ» is to be
included in ğ»sub but not in CP , it needs to be accompanied by
enough edges to not introduce violations of lower bounds. Inclusion
of these edges in ğ»sub, however, might not be possible without
introducing violations of upper bounds at their respective other
adjacent nodes (if those are part of CP ). These are the purposes
of functions verifyInclusion and ensureMinimumFreeNode, called in
lines 11 and 14 of Algorithm 5, respectively.

Function verifyInclusion verifies that the inclusion of ğ‘¥ğ» in CP
does not breach any maxima in the offspring. We do this by perform-
ing the same check as in constructCP (Algorithm 3), however, we
stop at merely checking whether a breach would occur. Of course,
one could also try to find a fix for potentially arising breaches of
a maximum, via edge swapping, or recursive inclusion of further
nodes, along with the edges. For simplicity, and since the logic
is already shown prior, we omitted this. The basic structure of
verifyInclusion is given as Algorithm 9 in Appendix A.

Algorithm 6 ensureMinimumFreeNode(ğ‘¥)

1: for all dir âˆˆ {src, tar } do
2:

for all ğ‘’TG âˆˆ ğ¸TG with dir TG (ğ‘’TG ) = ğ‘¥TG do
targetAmount
min (|edges(ğ», ğ‘’TG, dir, ğ‘¥ğ» )|, ğ‘šlb
dir

int

)

for all ğ‘’ â€² âˆˆ edges(ğ», ğ‘’TG, dir, ğ‘¥ğ» ) do

if edgeCount(ğ», ğº, ğ‘’TG, dir, dir (ğ‘’ â€²))+1 â‰¤ ğ‘šub

â†

dir then

ğ¸ğ»sub â† ğ¸ğ»sub âˆª {ğ‘’ â€²}
if !dir (ğ‘’ â€²) âˆˆ ğ»sub then
ğ‘‰ğ»sub â† ğ‘‰ğ»sub âˆª {dir (ğ‘’ â€²)}
ğ‘„.enqueue(dir (ğ‘’ â€²))

end if

end if
if |edges(ğ»sub, ğ‘’TG, dir, ğ‘¥ğ»sub )| â‰¥ targetAmount then

return true

end if
end for

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

end for

16:
17: end for
18: return false

Henri ThÃ¶lke and Jens Kosiol

For the nodes that did not get picked to be included in the
crossover point, or that were rejected during verification, we try
to ensure that we include enough edges to meet the minimum via
ensureMinimumFreeNode (Algorithm 6). During the inclusion, we
ensure that the inclusion of a selected edge does not introduce a
violation of an upper bound in the opposite direction (line 6). If the
second adjacent node of an included edge does not already belong
to ğ»sub, we add it and newly enqueue it to ensure that also the
lower bounds of that node are controlled. We use targetAmount
to only allow the lower bound to be violated if ğ» already violated
the lower bound in this position. Like with ğº, this allows us to
meaningfully treat the case where the input is infeasible: We ensure
that the amount of edges in the offspring is equal to that in the
input, meaning that secure crossover cannot worsen the situation
by introducing a greater number of missing edges.

Returning to processFreeNodes (Algorithm 5), should it prove
impossible to include a node in ğ»sub while ensuring its minimum
(i.e., ensureMinimumFreeNode returns false), the easiest solution
is to simply remove the node that failed to reach the minimum
from ğ»sub, along with all edges. This removal has the potential to
cascade, meaning other free nodes might have relied on a removed
edge for their own minimum. We remove all nodes affected by this
cascading effect. More elaborate solutions that try to remedy each
newly affected node are imaginable, but in the interest of simplicity
we chose a more coarse approach.

All nodes we added to reach minima for our original free nodes
are added to the queue of free nodes, since we will need to ensure
their feasibility as well. Following this process, we iterate through
ğ» in its entirety. The iteration stops either when all minima are
reached and all nodes had a chance to be included, or when the cas-
cading determines that no nodes aside the ones in CP are possible
additions to ğ»sub, since there is always a failure to meet minima.
Our approach therefore visits each node in ğº exactly once (when
constructing ğºsub) and the nodes in ğ» are visited at most thrice,
once or twice for constructing ğ»sub and once when potentially
removing nodes for failure to meet minima. This, along with the
fact that we only perform checks against the multiplicities when
we cannot rely on feasibility inherited by the input, leads us to
believe that using secure crossover is beneficial compared to simpler
approaches, e.g., using generic crossover and discarding infeasible
offsprings.

Example 5.2. In Example 4.6, we discussed how generic crossover
can compute the solution ğº1ğ»2, depicted in Fig. 3, from the solu-
tions ğº and ğ» , depicted in Fig. 2. Secure crossover as introduced
in this section can also compute this solution from the same input.
As stated in Example 5.1, createGsub (Algorithm 2) will first return
ğº as ğºsub. However, constructCP (Algorithm 3) then iterates over
the three Classes c2, c3, and c4 of ğ» because these constitute the
border in that case. Since none of these Classes already belongs to
ğ»sub, for each of it it is randomly decided whether or not it (and
its adjacent edge) are to be included in ğ»sub. Assume that a run
of constructCP randomly decides (i) to include c2 (and its adjacent
edge) in ğ»sub and CP , (ii) to include c4 only in ğ»sub and not in CP
and to swap its adjacent edge against the one from ğºsub pointing
to Feature f3 (which means to delete that edge from ğºsub), and
(iii) to not include c3 in ğ»sub. Then ğºsub coincides with ğº1 from

A multiplicity-preserving crossover operator on graphs

Example 4.6, ğ»sub with ğ»2, and also the crossover points coincides.
This means, the relevant offspring computed by secure crossover
in this case is the feasible solution ğº1ğ»2.

Note, first, that, while generic crossover can of course also com-
pute ğº1ğ»2, the probability that it ever returns feasible solutions
drastically decreases with increasing size and complexity of the
input graphs. Second, because of the structural simplicity of the
CRA case, the call of function processFreeNodes (Algorithm 5) is
trivial in that case. It is initialized with the empty queue because
all nodes of ğ» have already been processed by constructCP.

6 PROPERTIES OF SECURE CROSSOVER
In the following, we present the central formal results for our
crossover operator. First, we prove that offspring computed from
feasible solutions is again feasible, and, secondly, that every feasible
solution is a possible result of the application of secure crossover
or, in other words, that, in principle, we only restrict the reachable
search space by infeasible solutions. Both of these properties are
valuable since we want to obtain a crossover operator that guaran-
tees that the output models are feasible without restricting these
output models in any way not required by the feasibility criteria. In
Appendix B, we additionally establish that the application of secure
crossover terminates and that it is an instance of the generic ap-
proach suggested in [25]. In particular, this ensures that it computes
solutions for the given problem instance.

In all of the following, we always assume two solutions ğº and ğ»
for the same problem instance PI to be given. As already explained,
with secure crossover we are actually only interested in the first
computed offspring, namely the one that arises as union of ğºsub
and ğ»sub over the chosen crossover point CP . We just denote that
offspring as ğ‘‚ and ignore the second computed offspring.

Theorem 6.1 (Feasibility of offspring models). Let ğº, ğ» be
two solutions of a problem instance and let ğ‘‚ be an offspring that has
been computed by secure crossover. It holds that:

(1) For every node ğ‘¥ğ‘‚ in ğ‘‚ the number of edges ğ‘’ â€²

ğ‘‚ of a type ğ‘’ğ‘‡ğº
with dir (ğ‘’ â€²
ğ‘‚ ) = ğ‘¥ğ‘‚ is greater or equal to the number of edges
minimally provided by its counterparts in ğº and/or ğ» , that is,
greater or equal to
(cid:18)(cid:110)

(cid:111)(cid:19)

(ğ‘’ğ‘‡ğº ), (cid:12)
(cid:12)

(cid:8)ğ‘’ â€²

ğº âˆˆ ğ¸ğº | ğ‘¡ğº (ğ‘’ â€²

ğº ) = ğ‘’ğ‘‡ğº, dir (ğ‘’ â€²

ğº ) = ğ‘¥ğº (cid:9)(cid:12)
(cid:12)

,

min

ğ‘šlb
dir

or an analogous minimum should ğ‘¥ğ‘‚ only have a counterpart
in ğ» .

(2) For every node ğ‘¥ğ‘‚ in ğ‘‚ the number of edges ğ‘’ â€²

ğ‘‚ of a type ğ‘’ğ‘‡ğº
with dir (ğ‘’ â€²
ğ‘‚ ) = ğ‘¥ğ‘‚ is smaller or equal to the number of edges
maximally provided by its counterparts in ğº and/or ğ» , that is,
smaller or equal to
(cid:18)(cid:110)

(cid:111)(cid:19)

(ğ‘’ğ‘‡ğº ), (cid:12)
(cid:12)

(cid:8)ğ‘’ â€²

ğº âˆˆ ğ¸ğº | ğ‘¡ğº (ğ‘’ â€²

ğº ) = ğ‘’ğ‘‡ğº, dir (ğ‘’ â€²

ğº ) = ğ‘¥ğº (cid:9)(cid:12)
(cid:12)

,

max

ğ‘šub
dir

or an analogous maximum should ğ‘¥ğ‘‚ only have a counterpart
in ğ» .

In particular, if ğº and ğ» are feasible, so is ğ‘‚.

The proof of the above theorem is split in two parts, which we
build from multiple lemmas. The basic idea is that we separately
show that the offspring models satisfy all the lower bounds of

the multiplicities and that the offspring models satisfy the upper
bounds. For this we will first prove that our selection of ğºsub always
provides a feasible model, provided feasibility of ğº.

Lemma 6.2 (Construction of ğºsub). Let ğºsub be a subgraph
of ğº that has been obtained by a call of createGsub (Algorithm 2).
Then, for every node ğ‘¥ğºsub
of a
type ğ‘’ğ‘‡ğº with dir (ğ‘’ â€²

in ğºsub the number of edges ğ‘’ â€²

is greater or equal to

ğºsub

) = ğ‘¥ğºsub

ğºsub

min

(cid:18)(cid:110)

ğ‘šlb
dir

(ğ‘’ğ‘‡ğº ), (cid:12)
(cid:12)

(cid:8)ğ‘’ â€²

ğº âˆˆ ğ¸ğº | ğ‘¡ğº (ğ‘’ â€²

ğº ) = ğ‘’ğ‘‡ğº, dir (ğ‘’ â€²

ğº ) = ğ‘¥ğº (cid:9)(cid:12)
(cid:12)

(cid:111)(cid:19)

.

Lemma 6.3 (Offspring satisfies lower bounds at least as
well as input). Let ğº, ğ» be two solutions of a problem instance and
let ğ‘‚ be an offspring that has been computed by secure crossover. Let
TG mod be a modified type graph, where each edge multiplicity [ğ‘–, ğ‘—]
has been replaced with [ğ‘˜, âˆ—], where ğ‘˜ denotes the minimum of ğ‘– and
the minimal number of edges of that type and direction that appear
adjacent to a node in ğº or ğ» (i.e., the worst violation of the lower
bound). Then ğ‘‚ is feasible with regard to all edge multiplicities in
TG mod, and for every node ğ‘¥ğ‘‚ in ğ‘‚ the number of edges ğ‘’ â€²
ğ‘‚ of one
type ğ‘’ğ‘‡ğº with dir (ğ‘’ â€²

ğ‘‚ ) = ğ‘¥ğ‘‚ is greater or equal to

min

(cid:18)(cid:110)

ğ‘šlb
dir

(ğ‘’ğ‘‡ğº ), (cid:12)
(cid:12)

(cid:8)ğ‘’ â€²

ğº âˆˆ ğ¸ğº | ğ‘¡ğº (ğ‘’ â€²

ğº ) = ğ‘’ğ‘‡ğº, dir (ğ‘’ â€²

ğº ) = ğ‘¥ğº (cid:9)(cid:12)
(cid:12)

(cid:111)(cid:19)

.

or an analogous minimum for ğ» , should ğ‘¥ğ‘‚ only stem from there. In
particular, if ğº and ğ» are feasible, ğ‘‚ is feasible for the type graph
TG min, where each edge multiplicity [ğ‘–, ğ‘—] has been replaced with
[ğ‘–, âˆ—].

We now show that the offspring satisfies the upper bounds, too.

Lemma 6.4 (Offspring satisfies upper bounds). Let ğº, ğ» be
two solutions of a problem instance and let ğ‘‚ be an offspring that
has been computed by secure crossover. Let TG mod be a modified
type graph, where each edge multiplicity [ğ‘–, ğ‘—] has been replaced with
[0, ğ‘˜], where ğ‘˜ denotes the maximum of ğ‘— and the maximal number
of edges of that type and direction that appear adjacent to a node in ğº
(i.e., the worst violation of the upper bound in ğº). Then ğ‘‚ is feasible
with regard to all edge multiplicities in TG mod, and for every node
ğ‘¥ğ‘‚ in ğ‘‚ the number of edges ğ‘’ â€²
ğ‘‚ ) = ğ‘¥ğ‘‚
is smaller or equal to

ğ‘‚ of one type ğ‘’ğ‘‡ğº with dir (ğ‘’ â€²

max

(cid:18)(cid:110)

ğ‘šub
dir

(ğ‘’ğ‘‡ğº ), (cid:12)
(cid:12)

(cid:8)ğ‘’ â€²

ğº âˆˆ ğ¸ğº | ğ‘¡ğº (ğ‘’ â€²

ğº ) = ğ‘’ğ‘‡ğº, dir (ğ‘’ â€²

ğº ) = ğ‘¥ğº (cid:9)(cid:12)
(cid:12)

(cid:111)(cid:19)

.

In particular, if ğº and ğ» are feasible, ğ‘‚ is feasible for the type
graph TG max, where each edge multiplicity [ğ‘–, ğ‘—] has been replaced
with [0, ğ‘—].

Proposition 6.5 (Coverage of search space). Let ğ‘‚ be a feasi-
ble solution graph of the problem instance PI . Then there exist two
feasible solution graphs ğº and ğ» of PI , different from ğ‘‚, such that
ğ‘‚ is an offspring model of a secure crossover of ğº and ğ» .

7 CONCLUSION
In this paper, we develop secure crossover, a crossover operator on
typed graphs (or, more generally, computation graphs) that pre-
serves multiplicity constraints. This means, applied to feasible input,
the secure crossover computes feasible output. Even for infeasible
input, an application of secure crossover at least does not worsen

the amount of multiplicity violations. Secure crossover is an exten-
sive refinement of generic crossover as introduced in [25]; to simplify
the computation of secure crossover, we focus on the computation
of a single (feasible) offspring solution. We develop the underlying
algorithms of secure crossover in great detail, and use this to prove
central formal properties of it, namely the preservation of feasibil-
ity, that all feasible solutions can, in principle, still be computed
as offspring of an application of secure crossover, and that secure
crossover is an instance of generic crossover. Beyond its immediate
applicability in MDO, our work is a further indication that MDO is
a promising approach when one is interested in guaranteeing cer-
tain properties of search operators during (meta-heuristic) search:
we are able to verify a highly complex property (preservation of
multiplicity constraints) for a still quite generic crossover operator
on graphs. It seems at least intuitive that properties of a similar
complexity are hardly verifiable when working, e.g., on Bit-strings
as a representation for solutions during search.

With regards to future work, we intend to implement secure
crossover and to investigate whether evolutionary search on models
can profit from the preservation of feasibility. With its comprehen-
sive formal basis at hand, it would be interesting to even provide
a verified implementation of secure crossover. We also intend to
extend our construction to take further kinds of constraints into
account, e.g., nested graphs constraints (which are equivalent to
first-order logic on graphs) as, for example, presented in [15].

ACKNOWLEDGMENTS
This work has been partially supported by the Deutsche Forschungs-
gemeinschaft (DFG), grant TA 294/19-1.

REFERENCES
[1] Hani Abdeen, DÃ¡niel VarrÃ³, Houari A. Sahraoui, AndrÃ¡s Szabolcs Nagy, Csaba
Debreceni, Ãbel HegedÃ¼s, and Ãkos HorvÃ¡th. 2014. Multi-objective optimization
in rule-based design space exploration. In Proceedings of ASE â€™14. 289â€“300. https:
//doi.org/10.1145/2642937.2643005

[2] Ameni ben Fadhel, Marouane Kessentini, Philip Langer, and Manuel Wimmer.
2012. Search-based detection of high-level model changes. In Proceedings of
ICSM 2012. IEEE Computer Society, 212â€“221. https://doi.org/10.1109/ICSM.2012.
6405274

[3] Enrico Biermann, Claudia Ermel, and Gabriele Taentzer. 2012. Formal foundation
of consistent EMF model transformations by algebraic graph transformation.
Softw. Syst. Model. 11, 2 (2012), 227â€“250. https://doi.org/10.1007/s10270-011-
0199-7

[4] Robert Bill, Martin Fleck, Javier Troya, Tanja Mayerhofer, and Manuel Wimmer.
2019. A local and global tour on MOMoT. Softw. Syst. Model. 18, 2 (2019), 1017â€“
1046. https://doi.org/10.1007/s10270-017-0644-3

[5] Alexandru Burdusel, Steffen Zschaler, and Stefan John. 2021. Automatic genera-
tion of atomic multiplicity-preserving search operators for search-based model
engineering. Softw. Syst. Model. 20, 6 (2021), 1857â€“1887. https://doi.org/10.1007/
s10270-021-00914-w

[6] Frank R. Burton, Richard F. Paige, Louis M. Rose, Dimitrios S. Kolovos, Si-
mon M. Poulding, and Simon Smith. 2012. Solving Acquisition Problems Us-
ing Model-Driven Engineering. In Proceedings of ECMFA 2012 (Lecture Notes in
Computer Science, Vol. 7349), Antonio Vallecillo, Juha-Pekka Tolvanen, Ekkart
Kindler, Harald StÃ¶rrle, and Dimitrios S. Kolovos (Eds.). Springer, 428â€“443.
https://doi.org/10.1007/978-3-642-31491-9_32

[7] Frank R. Burton and Simon M. Poulding. 2013. Complementing metaheuristic
search with higher abstraction techniques. In CMSBSE@ICSE 2013, Richard F.
Paige, Mark Harman, and James R. Williams (Eds.). IEEE Computer Society, 45â€“48.
https://doi.org/10.1109/CMSBSE.2013.6604436

[8] Carlos A. Coello Coello. 2010. Constraint-handling techniques used with evo-
lutionary algorithms. In Companion Material GECCO 2010, Martin Pelikan and
JÃ¼rgen Branke (Eds.). ACM, 2603â€“2624. https://doi.org/10.1145/1830761.1830910
[9] Eclipse. 2022. Eclipse Modeling Framework (EMF). http://www.eclipse.org/emf
[10] Hartmut Ehrig, Karsten Ehrig, Ulrike Prange, and Gabriele Taentzer. 2006. Funda-
mentals of Algebraic Graph Transformation. Springer. https://doi.org/10.1007/3-

Henri ThÃ¶lke and Jens Kosiol

540-31188-2

[11] A. E. Eiben and James E. Smith. 2015. Introduction to Evolutionary Computing (2

ed.). Springer. https://doi.org/10.1007/978-3-662-44874-8

[12] Martin Fleck, Javier Troya, Marouane Kessentini, Manuel Wimmer, and Bader
Alkhazi. 2017. Model Transformation Modularization as a Many-Objective
IEEE Trans. Software Eng. 43, 11 (2017), 1009â€“1032.
Optimization Problem.
https://doi.org/10.1109/TSE.2017.2654255

[13] Martin Fleck, Javier Troya, and Manuel Wimmer. 2016. The Class Responsibil-
ity Assignment Case. In Proceedings of TTC 2016 (CEUR Workshop Proceedings,
Vol. 1758), Antonio GarcÃ­a-DomÃ­nguez, Filip Krikava, and Louis M. Rose (Eds.).
CEUR-WS.org, 1â€“8. http://ceur-ws.org/Vol-1758/paper1.pdf

[14] Al Globus, John Lawton, and Todd Wipke. 2000. JavaGenes: Evolving Graphs with
Crossover. Technical Report. NASA Advanced Supercomputing (NAS) Division.
https://www.nas.nasa.gov/assets/pdf/techreports/2000/nas-00-018.pdf

[15] Annegret Habel and Karl-Heinz Pennemann. 2009. Correctness of high-level
transformation systems relative to nested conditions. Math. Struct. Comput. Sci.
19, 2 (2009), 245â€“296. https://doi.org/10.1017/S0960129508007202

[16] Ãbel HegedÃ¼s, Ãkos HorvÃ¡th, and DÃ¡niel VarrÃ³. 2015. A model-driven framework
for guided design space exploration. Autom. Softw. Eng. 22, 3 (2015), 399â€“436.
https://doi.org/10.1007/s10515-014-0163-1

[17] Jose Miguel Horcas, Daniel StrÃ¼ber, Alexandru Burdusel, Jabier Martinez, and
Steffen Zschaler. 2022. Weâ€™re Not Gonna Break It! Consistency-Preserving Op-
erators for Efficient Product Line Configuration. IEEE Transactions on Software
Engineering (2022). https://doi.org/10.1109/TSE.2022.3171404 online first.
[18] Stefan John, Alexandru Burdusel, Robert Bill, Daniel StrÃ¼ber, Gabriele Taentzer,
Steffen Zschaler, and Manuel Wimmer. 2019. Searching for Optimal Models:
Comparing Two Encoding Approaches. J. Object Technol. 18, 3 (2019), 6:1â€“22.
https://doi.org/10.5381/jot.2019.18.3.a6

[19] Stefan John, Jens Kosiol, Leen Lambers, and Gabriele Taentzer. 2022. A Graph-
Based Framework for Model-Driven Optimization Facilitating Impact Analysis
of Sound and Complete Mutation Operator Sets. (2022). under review.

[20] Stefan John, Jens Kosiol, and Gabriele Taentzer. 2022. Towards a Configurable
Crossover Operator for Model-Driven Optimization. In MDE Intelligence, Lola
BurgueÃ±o, Dominik Bork, Phuong Nguyen, and Steffen Zschaler (Eds.). to appear.
[21] Penousal Machado, Henrique Nunes, and Juan Romero. 2010. Graph-Based
Evolution of Visual Languages. In Proceedings of EvoApplications 2010, Part II
(Lecture Notes in Computer Science, Vol. 6025), Cecilia Di Chio, Anthony Brabazon,
Gianni A. Di Caro, Marc Ebner, Muddassar Farooq, Andreas Fink, JÃ¶rn Grahl,
Gary Greenfield, Penousal Machado, Michael Oâ€™Neill, Ernesto Tarantino, and Neil
Urquhart (Eds.). Springer, 271â€“280. https://doi.org/10.1007/978-3-642-12242-
2_28

[22] Zbigniew Michalewicz. 1995. A Survey of Constraint Handling Techniques in
Evolutionary Computation Methods. In Proceedings of EP 1995, John R. McDonnell,
Robert G. Reynolds, and David B. Fogel (Eds.). A Bradford Book, MIT Press.
Cambridge, Massachusetts., 135â€“155.

[23] Jens Niehaus. 2004. Graphbasierte Genetische Programmierung (Graph-based
Genetic Programming). Ph. D. Dissertation. Technical University of Dortmund,
Dortmund, Germany. https://doi.org/10.17877/DE290R-14929

[24] Jean-Yves Potvin. 1996. Genetic algorithms for the traveling salesman problem.
Ann. Oper. Res. 63, 3 (1996), 337â€“370. https://doi.org/10.1007/BF02125403
[25] Gabriele Taentzer, Stefan John, and Jens Kosiol. 2022. A Generic Construction
for Crossovers of Graph-Like Structures. In Proceedings of ICGT 2022 (Lecture
Notes in Computer Science, Vol. 13349), Nicolas Behr and Daniel StrÃ¼ber (Eds.).
Springer, 97â€“117. https://doi.org/10.1007/978-3-031-09843-7_6

[26] Gabriele Taentzer and Arend Rensink. 2005. Ensuring Structural Constraints in
Graph-Based Models with Type Inheritance. In Proceedings of FASE 2005 (Lecture
Notes in Computer Science, Vol. 3442), Maura Cerioli (Ed.). Springer, 64â€“79. https:
//doi.org/10.1007/978-3-540-31984-9_6

[27] Steffen Zschaler and Lawrence Mandow. 2016. Towards Model-Based Opti-
misation: Using Domain Knowledge Explicitly. In Revised Selected Papers of
STAF 2016 Collocated Workshops (Lecture Notes in Computer Science, Vol. 9946),
Paolo Milazzo, DÃ¡niel VarrÃ³, and Manuel Wimmer (Eds.). Springer, 317â€“329.
https://doi.org/10.1007/978-3-319-50230-4_24

A ALGORITHMIC DETAILS
We first provide the details for the inclusion of edges in ğºsub (com-
pare Sect. 5.2). These details are presented in Algorithm 7. Given
a node ğ‘¥ for which adjacent edges are to be included, for each
type of edge for which ğ‘¥ can either serve as a source or a target
node (lines 1â€“2), we determine a random number ğ‘› of edges that
are to be included (line 3). This random number is selected from
a specific range: The function lb (ğ‘’TG ) returns the minimum of

A multiplicity-preserving crossover operator on graphs

|ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘  (ğº, ğ‘’TG, ğ‘‘ğ‘–ğ‘Ÿ, ğ‘¥ğº )|, which gives the number of actually adja-
cent edges of the considered type to ğ‘¥ğº in ğº, and ğ‘šlb
(ğ‘’TG ), i.e.,
ğ‘‘ğ‘–ğ‘Ÿ
the required lower bound; moreover, src = tar and tar = src. Sim-
ilarly, ub (ğ‘’TG ) returns the minimum of |ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘  (ğº, ğ‘’TG, ğ‘‘ğ‘–ğ‘Ÿ, ğ‘¥ğº )|
and ğ‘šub
(ğ‘’TG ), i.e., the required upper bound. In this way, ğ‘› lies
ğ‘‘ğ‘–ğ‘Ÿ
between the lower and the upper bound of the considered edge
type, or it coincides with the number of available edges of that type
(at that node), should the number of edges available in ğº fall short
of the lower bound. Then, ğ‘› edges of the considered type, connected
to the node ğ‘¥ in the considered direction are randomly selected
to be included in ğºsub. This inclusion comprises the inclusion of
their second attached node. Without representing this explicitly
in the code, we assume (i) that the number ğ‘› of edges that are to
be included is reduced by the number of edges that already have
been included so far (when including adjacent edges for another
node) and (ii) that it is ensured that for newly included nodes the
function includeAdjacentEdges will be called in the future.

Algorithm 7 includeAdjacentEdges(ğ‘¥, ğº)

1: for all ğ‘‘ğ‘–ğ‘Ÿ âˆˆ {srcğº, tarğº } do
2:

for all ğ‘’TG âˆˆ ğ¸TG with ğ‘‘ğ‘–ğ‘ŸTG (ğ‘’TG ) = ğ‘¡ğº (ğ‘¥) do

3:

4:

5:

6:

7:

8:

ğ‘› â† randInt(lb (ğ‘’TG ), ub (ğ‘’TG ))
for ğ‘– â† 1, . . . , ğ‘› do

select ğ‘’ â€² âˆˆ edges (ğº, ğ‘’TG, ğ‘‘ğ‘–ğ‘Ÿ, ğ‘¥ğº )
ğ¸ğºsub â† ğ¸ğºsub âˆª {ğ‘’ â€²}
ğ‘‰ğºsub â† ğ‘‰ğºsub âˆª {ğ‘‘ğ‘–ğ‘Ÿğº (ğ‘’ â€²)}
end for

end for

9:
10: end for

Next, we provide the pseudocode for function resolveBreach (Al-
gorithm 8) that can be called during the computation of ğ»sub and
CP .

Algorithm 8 resolveBreach(ğ‘„, ğ‘¥, ğ‘’ â€², dir, ğ‘’TG )

1: ğ‘¦ğº â† pickFreeNodeG(ğ‘¥ğº, dir, ğ‘’TG )
2: if ğ‘¦ğº == ğ‘›ğ‘¢ğ‘™ğ‘™ then
return false
3:
4: end if
5: ğ‘‰ğ¶ğ‘ƒ = ğ‘‰ğ¶ğ‘ƒ âˆª {ğ‘¦ğ¶ğ‘ƒ }
6: ğ¸ğ¶ğ‘ƒ = ğ¸ğ¶ğ‘ƒ âˆª {ğ‘’ â€²
ğ¶ğ‘ƒ }
7: ğ‘„.enqueue(ğ‘¦ğ» )
8: return true

Finally, Algorithm 9 provides the basic structure for the function
verifyInclusion that is used to check whether it is possible to include
a node in CP .

B PROOFS AND ADDITIONAL RESULTS
We first state that every call of secure crossover terminates.

Proposition B.1 (Termination of secure crossover). Given a
computation type graph with multiplicities TG, a problem instance
PI for it, and two solutions ğº and ğ» for PI , every application of
secure crossover as defined in Algorithm 1 terminates, computing
two offspring graphs ğ‘‚1 and ğ‘‚2.

Algorithm 9 verifyInclusion(ğ‘¥)
1: for all dir âˆˆ {src, tar } do
2:

for all ğ‘’TG âˆˆ ğ¸TG with dir TG (ğ‘’TG ) = ğ‘¡ğ» (ğ‘¥) do

ğ‘œğ‘£ğ‘’ğ‘Ÿ

â†
âˆ’|edges(CP, ğ‘’TG, dir, ğ‘¥CP )| > ğ‘šğ‘ğ‘¥dir

edgeCount(ğºsub, ğ»sub, ğ‘’TG, dir, ğ‘¥)

if ğ‘œğ‘£ğ‘’ğ‘Ÿ then

Here we could implement varying degrees of fixing attempts.
From edge swapping, to recursive merging

return false

3:

4:

5:

6:

end if
end for

7:
8: end for
9: return true

Proof. First, none of the algorithms that are called during the
application of secure crossover throws an exception; at most, certain
iterations of a loop are skipped (e.g., in Algorithm 3) or a restricted
set of computations is rolled back (e.g., in Algorithm 5). This means
that, if secure crossover terminates, it definitely stops with the
computation of the two offspring graphs ğ‘‚1 and ğ‘‚2.

The only points that could cause non-termination are the while
loops in Algorithms 3, 5, and 6. Both Algorithms 3 and 5 iterate over
a queue ğ‘„ that is initialized with a finite number of nodes. In both
cases, additional nodes can be enqueued during the computation.
However, in both cases this only happens for nodes that are newly
included in CP (Algorithm 8, line 7) or newly included in ğ»sub
(Algorithm 6, line 9). For every node of ğ» , this can only happen
once, and in all cases, it is first checked whether or not the inclusion
already holds. In Algorithm 6, both while-loops are guarded by
counters that in- or decrease with every iteration.

Overall, secure crossover terminates.

â–¡

As recalled in Sect. 4, applying the generic crossover operator
from [25] to computation graphs ğº and ğ» amounts to splitting
these into computation graphs ğº1, ğº2, ğ»1, and ğ»2, each contain-
ing the considered problem graph, and uniting ğº1 and ğ»2 and ğº2
and ğ»1, respectively, over a common crossover point CP that is a
common subgraph of the split points ğºI and ğ»I and also at least
contains the considered problem graph. Proposition 2 in [25] clar-
ifies that the computed offspring are again computation graphs
and, in particular, solutions for the considered problem instance PI .
While it is also straightforward to directly prove this claim for our
crossover operator, we just obtain it as a corollary to the general
result from [25] because our crossover operator is just a special
implementation of that procedure.

Lemma B.2 (Secure crossover as generic crossover). Given
a computation type graph with multiplicities TG, a problem in-
stance PI for it, and two solutions ğº and ğ» for PI , applying secure
crossover as defined in Algorithm 1 is a special instance of applying
generic crossover as defined in [25].

Proof. By construction, ğºsub and ğ»sub, which take that parts
of ğº1 and ğ»2 in generic crossover, are subgraphs of ğº and ğ» , re-
spectively, that contain the given problem graph PI P; also the
constructed crossover point CP always contains PI P. As ğº2 and
ğ»1 we choose ğº and ğ» , respectively, which results in the split points

being given as ğºI = ğºsub and ğ»I = ğ»sub. Finally, CP is a com-
mon subgraph of ğºsub and ğ»sub. Hence, the construction of secure
â–¡
crossover implements a specific variant of generic crossover.

Corollary B.3 (Structural correctness of offspring). Given
a computation type graph with multiplicities TG, a problem in-
stance PI for it, and two solutions ğº and ğ» for PI , applying secure
crossover as defined in Algorithm 1 results in two computation models
ğ‘‚1 and ğ‘‚2 that are solutions for PI .

Proof. Because of Lemma B.2 this is just a corollary to [25,
â–¡

Proposition 2].

In the rest of this section, we prove the results of the main paper.

Proof of Lemma 6.2. Let ğº be a solution model as described
in the lemma. Let ğ‘¥ğºsub be a node from ğ‘‰ğºsub , ğ‘’ğ‘‡ğº an edge type
and dir a direction. The function createGsub iterates through ev-
ery node in ğ‘‰ğº , so eventually, it will consider ğ‘¥ğº , the equivalent
node for ğ‘¥ğºsub in ğº. For ğ‘¥ğº , we first check whether it has already
been included in ğºsub. Since we have our node ğ‘¥ğºsub , we can as-
sume it is included. This means that in line 8 we call the function
includeAdjacentEdges (Algorithm 7) for ğ‘¥ğº .

In this function, we iterate through every direction, and every
type that an edge connected to ğ‘¥ğº can have, so we will inevitably
also run the loopâ€™s body for ğ‘’ğ‘‡ğº and dir . In that case, we include a
randomly selected number ğ‘› of edges (of the according type and
direction), ensuring that the relevant lower bound is reached, or at
â–¡
least all possible edges are included (line 3).

Proof of Lemma 6.3. Let ğº, ğ» be the input solutions and ğ‘‚ be
the computed offspring. Let ğ‘’TGmod âˆˆ ğ¸TGmod be an edge from
the modified type graph, dir one of the possible direction src or
tar for the edges, and

ğ‘ğ‘‚ âˆˆ (cid:8)ğ‘¥ âˆˆ ğ‘‰ğ‘‚ | ğ‘¡ğ‘‚ (ğ‘¥) = dir (ğ‘’TGmod )(cid:9)
a node from the offspring that can have edges of type ğ‘’TGmod . For
(ğ‘’TGmod ), we can see that it suffices
a set of edges to satisfy ğ‘šdir
that

(cid:12)
(cid:12)

(cid:8)ğ‘’ â€²

ğ‘‚ ) = ğ‘ğ‘‚ (cid:9)(cid:12)

ğ‘‚ âˆˆ ğ¸ğ‘‚ | ğ‘¡ğ‘‚ (ğ‘’ â€²

ğ‘‚ ) = ğ‘’TGmod, dir (ğ‘’ â€²
where ğ‘˜ is the new, relaxed lower bound of TG mod, since the
second part of the relaxed multiplicity is always satisfied (as ğ‘— = âˆ—).
We might therefore write
ğ‘‚ âˆˆ ğ¸ğ‘‚ | ğ‘¡ğ‘‚ (ğ‘’ â€²

ğ‘‚ ) = ğ‘’TGmod, dir (ğ‘’ â€²
to note that the entire multiplicity is satisfied.

ğ‘‚ ) = ğ‘ğ‘‚ (cid:9)(cid:12)

(cid:12) â‰¥ ğ‘˜,

(cid:12) â‰¥ ğ‘˜

(cid:8)ğ‘’ â€²

(cid:12)
(cid:12)

The node ğ‘ğ‘‚ can stem either solely from ğºsub, with no preimage
in CP , solely from ğ»sub, or from both, with a preimage ğ‘CP in
ğ‘‰CP . We therefore observe the three cases:

(1) ğ‘ğ‘‚ stems solely from ğºsub:
In this case, all edges ğ‘’ â€²
ğ‘‚ with ğ‘¡ğ‘‚ (ğ‘’ â€²
ğ‘‚ ) =
ğ‘ğ‘‚ must also stem solely from ğºsub, without a preimage
in CP . This is due to the fact that CP â†©â†’ ğºsub is a graph
morphism. This means that
ğ‘‚ âˆˆ ğ¸ğ‘‚ | ğ‘¡ğ‘‚ (ğ‘’ â€²

ğ‘‚ ) = ğ‘’ğ‘‡ğº and dir (ğ‘’ â€²

ğ‘‚ ) = ğ‘’TGmod, dir (ğ‘’ â€²

(cid:12)
(cid:8)ğ‘’ â€²
(cid:12)
âˆˆ ğ¸ğºsub | ğ‘¡ğºsub (ğ‘’ â€²

(cid:12)
(cid:12)
(cid:12)

(cid:110)
ğ‘’ â€²
ğºsub

) = ğ‘’TGmod, dir (ğ‘’ â€²
and Lemma 6.2 then proves the statement.

ğºsub

ğºsub

ğ‘‚ ) = ğ‘ğ‘‚ (cid:9)(cid:12)
(cid:12) =
(cid:111)(cid:12)
(cid:12)
(cid:12) ,

) = ğ‘ğºsub

Henri ThÃ¶lke and Jens Kosiol

(2) ğ‘ğ‘‚ stems solely from ğ»sub:

ğ‘‚ with ğ‘¡ğ‘‚ (ğ‘’ â€²

Again, this means all edges ğ‘’ â€²
ğ‘‚ ) = ğ‘’ğ‘‡ğº and
dir (ğ‘’ â€²
ğ‘‚ ) = ğ‘ğ‘‚ must also stem solely from ğ»sub. During
the construction of ğ»sub, each node that we include must
be processed by Algorithm 5. This means that in line 14, we
called function ensureMinimumFreeNode for that respective
node. Since ğ‘ğ‘‚ is part of ğ»sub, that call returned true, mean-
ing that the node either satisfies the respective lower bound
or is at least attached to as many edges as are provided by
ğ» .

(3) There exists a preimage ğ‘CP for ğ‘ğ‘‚ :

To begin with, if ğ‘ğ‘‚ has a preimage ğ‘CP in the crossover
point, then there must be a ğ‘ğºsub in ğºsub. The number of
edges at ğ‘ğ‘‚ must be therefore be greater or equal than the
number of edges at ğ‘ğºsub at the start of the construction of
the CP . As seen in Case (1) this number of edges satisfies
the requirement. During construction of the crossover point,
we only reduce the number of edges in one instance, that is
when we swap edges. If we swap edges (Algorithm 4), we
always include a new edge to replace the one we removed.
We also then ensure in line 37 of Algorithm 3 that our newly
included replacement does not get included in CP , thus
maintaining the same number of edges. All other instances
merely add edges.

The statement for the case of feasible input is an immediate
consequence of the above considerations because, in that case, the
original lower bound ğ‘– coincides with the relaxed lower bound
â–¡
ğ‘˜.

Proof of Lemma 6.4. Let ğº, ğ» be the input solutions and ğ‘‚ be
the computed offspring. Let ğ‘’TGmod âˆˆ ğ¸TGmod be an edge from
the modified type graph, dir one of the possible direction src or
tar for the edges, and

ğ‘ğ‘‚ âˆˆ (cid:8)ğ‘¥ âˆˆ ğ‘‰ğ‘‚ | ğ‘¡ğ‘‡ğºmod (ğ‘¥) = dir (ğ‘’TGmod )(cid:9)
a node from the offspring that can have edges of type ğ‘’TGmod . For
(ğ‘’TGmod ), we can see that it suffices
a set of edges to satisfy ğ‘šdir
that

(cid:12)
(cid:12)

(cid:8)ğ‘’ â€²

ğ‘‚ âˆˆ ğ¸ğ‘‚ | ğ‘¡ğ‘‚ (ğ‘’ â€²

ğ‘‚ ) = ğ‘’TGmod, dir (ğ‘’ â€²
, where ğ‘˜ is the relaxed upper bound of TG mod, since the first part
of the multiplicity is always true (as ğ‘– = 0). We might therefore
write

ğ‘‚ ) = ğ‘ğ‘‚ (cid:9)(cid:12)

(cid:12) â‰¤ ğ‘˜,

(cid:12)
(cid:12)

(cid:8)ğ‘’ â€²

ğ‘‚ âˆˆ ğ¸ğ‘‚ | ğ‘¡ğ‘‚ (ğ‘’ â€²

ğ‘‚ ) = ğ‘’TGmod, dir (ğ‘’ â€²
to note that the entire multiplicity is satisfied.

ğ‘‚ ) = ğ‘ğ‘‚ (cid:9)(cid:12)

(cid:12) â‰¤ ğ‘˜

The node ğ‘ğ‘‚ can stem either solely from ğºsub, with no inverse
image in CP , solely from ğ»sub, or from both, with an inverse image
ğ‘CP in ğ‘‰CP . We therefore observe the three cases:

(1) ğ‘ğ‘‚ stems solely from ğºsub:
ğ‘‚ with ğ‘¡ğ‘‚ (ğ‘’ â€²
In this case, all edges ğ‘’ â€²
ğ‘‚ ) =
ğ‘ğ‘‚ must also stem solely from ğºsub, without an inverse
image in CP . This is due to the fact that CP â†©â†’ ğºsub is a
graph morphism. This means that

ğ‘‚ ) = ğ‘’ğ‘‡ğº and dir (ğ‘’ â€²

(cid:12)
(cid:8)ğ‘’ â€²
(cid:12)
âˆˆ ğ¸ğºsub | ğ‘¡ğºsub (ğ‘’ â€²

(cid:12)
(cid:12)
(cid:12)

(cid:110)
ğ‘’ â€²
ğºsub

ğ‘‚ âˆˆ ğ¸ğ‘‚ | ğ‘¡ğ‘‚ (ğ‘’ â€²

ğ‘‚ ) = ğ‘’TGmod, dir (ğ‘’ â€²

) = ğ‘’TGmod, dir (ğ‘’ â€²

ğºsub

ğºsub

ğ‘‚ ) = ğ‘ğ‘‚ (cid:9)(cid:12)
(cid:12) =
(cid:111)(cid:12)
(cid:12)
(cid:12) ,

) = ğ‘ğºsub

A multiplicity-preserving crossover operator on graphs

which is smaller than ğ‘˜ by the definition of ğ‘˜.

(2) ğ‘ğ‘‚ stems solely from ğ»sub:

ğ‘‚ ) = ğ‘’ğ‘‡ğº and
ğ‘‚ ) = ğ‘ğ‘‚ must also stem solely from ğ»sub. Since ğ»sub

Again, this means all edges ğ‘’ â€²
dir (ğ‘’ â€²
is a subgraph of ğ» , it follows that

ğ‘‚ with ğ‘¡ğ‘‚ (ğ‘’ â€²

(cid:12)
(cid:12)
(cid:12)

(cid:110)
ğ‘’ â€²
ğ»sub

ğ‘‚ âˆˆ ğ¸ğ‘‚ | ğ‘¡ğ‘‚ (ğ‘’ â€²

) = ğ‘’TGmod, dir (ğ‘’ â€²

ğ‘‚ ) = ğ‘’TGmod, dir (ğ‘’ â€²

(cid:12)
ğ‘‚ ) = ğ‘ğ‘‚ (cid:9)(cid:12)
(cid:8)ğ‘’ â€²
(cid:12) =
(cid:12)
(cid:111)(cid:12)
âˆˆ ğ¸ğ»sub | ğ‘¡ğ»sub (ğ‘’ â€²
(cid:12)
(cid:12) .
As every inclusion of an edge into ğ»sub is checked for not
introducing an upper bound violation (in any direction), in
this case we can even conclude that the original upper bound
ğ‘— is satisfied.

) = ğ‘ğ»sub

ğ»sub

ğ»sub

(3) There exists an inverse image ğ‘CP for ğ‘ğ‘‚

To begin with, if ğ‘ğ‘‚ has an inverse image ğ‘CP in the crossover
point, then there must be a ğ‘ğºsub in ğºsub. The number of
edges at ğ‘ğ‘‚ must be therefore be equal to the number of
edges at ğ‘ğºsub at the start of the construction of the CP .
As seen in Case (1), this number of edges satisfies the re-
laxed multiplicity ğ‘˜. During construction of the crossover
point, we only increase the number of edges after specifically
checking that the inclusion does not breach the maximum.
Again,the statement for the case of feasible input is an immediate
consequence of the above considerations because, in that case, the
original upper bound ğ‘— coincides with the relaxed upper bound
â–¡
ğ‘˜.

Proof of Theorem 6.1. The claim follows from combining Lem-
â–¡

mas 6.3 and 6.4.

Proof of Proposition 6.5. We describe a construction of ğº and
ğ» , starting from ğ‘‚. For this, we describe, how to obtain the sub-
graphs ğºsub and ğ»sub from ğ‘‚, along with the crossover point CP .
To obtain the subgraphs, we first choose a subgraph ğ‘‚sub to
act as our ğºsub from our algorithm. The subgraph ğ‘‚sub must be
feasible, so specifically all lower bounds are satisfied. All elements
in ğ‘‚ not chosen for ğ‘‚sub are part of ğ»sub. If an edge from ğ»sub
connects to a node in ğ‘‚sub, we make the node in ğ‘‚sub part of the
crossover point.

We can always obtain the resulting structures from our algo-
rithm. It should be obvious to see how we could obtain ğ‘‚sub, or in
that direction ğºsub, as a subgraph of a larger graph ğº. Given the
appropriate ğ» , we can then choose to add exactly those nodes to
the crossover point, that we included in the crossover point in our
construction.

This construction delivers subgraphs ğºsub and ğ»sub, along with
a crossover point CP . Since ğºsub already is feasible, we do not
need to, but can change it further to achieve ğº, for ğ»sub we might
need to add elements to ensure feasibility. We can always create a
feasible ğ» to ğ»sub, the existence of such a graph is shown by the
â–¡
existence of ğ‘‚.

