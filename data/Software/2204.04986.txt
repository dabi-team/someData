Multi-Objective Yield Optimization for Electrical
Machines using Machine Learning
Morten Christian Huber, Mona Fuhrl¨ander(cid:63), Sebastian Sch¨ops
Computational Electromagnetics Group (CEM), Technische Universit¨at Darmstadt, Germany,
(cid:63)corresponding author’s email: mona.fuhrlaender@tu-darmstadt.de

1

2
2
0
2

r
p
A
1
1

]
E
C
.
s
c
[

1
v
6
8
9
4
0
.
4
0
2
2
:
v
i
X
r
a

Abstract—This work deals with the design optimization of
electrical machines under the consideration of manufacturing
uncertainties. In order to efﬁciently quantify the uncertainty,
blackbox machine learning methods are employed. A multi-
objective optimization problem is formulated, maximizing simul-
taneously the reliability, i.e., the yield, and further performance
objectives, e.g., the costs. A permanent magnet synchronous
machine is modeled and simulated in commercial ﬁnite element
simulation software. Four approaches for solving the multi-
objective optimization problem are described and numerically
compared, namely: ε-constraint scalarization, weighted sum
scalarization, a multi-start weighted sum approach and a genetic
algorithm.

Index Terms—multi-objective optimization, electrical ma-

chines, uncertainty quantiﬁcation, yield, machine learning

I. INTRODUCTION

Electrical machines are increasingly replacing conventional
combustion engines, which is an important step against climate
change. However, the design and manufacturing process of
electrical machines can be further improved to deal responsible
with natural resources. Computer simulations, e.g., with ﬁnite
element method (FEM), have the advantage that products can
be virtually analyzed and optimized before the ﬁrst prototypes
are built and tested. This shortens the design process and
saves materials. However, typically the simulation of electrical
machines is computationally very expensive, since partial
differential equations have to be solved numerically, e.g., with
FEM. In the approaches we present in this work, these sim-
ulations are enabled by the usage of machine learning, more
precisely the usage of Gaussian Process Regression (GPR).
The proposed workﬂow considers the FEM simulation tool as
a blackbox such that open-source or proprietary software can
be used.

Typically, the design, i.e., the geometry and material, of a
device is optimized such that performance requirements are
fulﬁlled. However, in practice often there are manufacturing
imperfections which lead to deviations in the geometry or
material parameters and this may cause violations of the
requirements. In this case the manufactured device is rejected.
The uncertainty induced by manufacturing uncertainties can be
quantiﬁed by the yield. The yield describes the probability, that
a manufactured device fulﬁlls all performance requirements,
under consideration of uncertainties [1].

Classic approaches for yield estimation involve Monte Carlo
(MC) analysis [2, Chap. 5]. This sampling-based approach
requires the evaluation of the simulation model for each

sample conﬁguration and quickly becomes computationally
prohibitive in case of FEM models of electrical machines.
Surrogate methods provide an approximation of the quan-
tity of interest (QoI) and proceed a MC analysis on this
approximation model, cf. [3]. Examples for surrogates are
linear regression [4], stochastic collocation [5] and GPR [6].
However, [7, Example 3.1] shows, that even highly accurate
approximation models can lead to wrong yield estimates.
For that reason, they introduced a hybrid approach, which
evaluates most of the MC sample points on the surrogate
model, and a small subset of so-called critical sample points
on the high-ﬁdelity model. In [8] a GPR-Hybrid approach
has been recently introduced for problems in high-frequency
engineering.

In order to improve the reliability of the manufacturing
process, the yield shall be maximized. This optimization saves
resources, time and money. In practice, besides the reliability,
often there are competing objectives, e.g., the minimization
of material costs. A multi-objective optimization (MOO)
approach is required to ﬁnd a suitable trade-off between
the different objectives. Classic approaches are scalarization
methods, e.g., weighted sum [9, Chap. 3] and ε-constraint [9,
Chap. 4]. A commonly used heuristic approach are genetic
algorithms [10, Chap. 4].

it

MOO under uncertainty has a long tradition in the design
of electric machines [11]. For example, the Taguchi methods,
where the loss caused by uncertainty is added to the objective
function as penalty term, are popular [12]. Another common
approach is worst case optimization [13]. There, the worst
case scenario is optimized, i.e., the worst performance of a
design considering uncertainties. Since the objective function
of the minimization problem is itself a maximization over
the uncertainty range,
is a minimax problem [1], [14].
For Gaussian distributed uncertainties, in six sigma design
optimization the mean value of the objective function, i.e.,
the average performance, and the standard deviation (sigma)
of the objective function, i.e., the intensity of uncertainty, are
minimized, such that the constraints are fulﬁlled in a six sigma
range around the mean value [15]. A recent study comparing
these approaches applied to the design of electrical machines is
provided in [16]. In the literature, different aspects of electrical
machines have been subject to optimization, e.g., the shape of
the rotor [17], the permanent magnets (PMs) [18], [19], or the
stator slots [20].

In this work a permanent magnet synchronous machine
(PMSM) [19] is modeled and simulated using CST Studio

©2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media,
including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to
servers or lists, or reuse of any copyrighted component of this work in other works.

 
 
 
 
 
 
Suite ® 2021. Hereby, the size and position of the PMs are
considered as deterministic design parameters. The magnitude
and the direction of the magnetic ﬁelds in the PMs are
considered as uncertain design parameters. The average torque
is the QoI and equipped with a lower bound it becomes a
performance requirement. We apply the GPR-Hybrid approach
from [8] to the modeled PMSM in order to achieve efﬁcient
and accurate yield estimates. In contrary to [8], the uncertain
parameters are not the optimization variables. This becomes
especially challenging since closed-form derivatives are not
available in this case. We state a MOO problem and provide
different formulations for the different optimization methods
used, i.e., for weighed sum, ε-constraint and the genetic algo-
rithm. The optimization approaches are applied to the PMSM
and evaluated regarding the improvement of the objective
functions and their computational efﬁciency. We propose a
multi-start procedure for scalarization methods, which is a
heuristic globalization technique. Eventually, we will see that
the potentially prohibitive numerical effort can be reduced
to an acceptable level by the employed machine learning
technique.

The manuscript

is structured as follows. We start with
an introduction to electrical machines in general and the
modeled PMSM in particular in Sec. II. We continue with
a section on uncertainty quantiﬁcation, including the formal
deﬁnition of the yield and a summary of the GPR-Hybrid
approach. In Sec. IV the MOO problem is formulated and
the different MOO techniques are introduced. In Sec. V the
numerical results are presented, before we conclude with a
short summary and an outlook.

II. ELECTRICAL MACHINE SETTINGS

A. Brief introduction to PMSM

As a consequence of the steadily rising focus on mitigating
the origins of the climate change and the governments tight-
ening the juridicial fundamentals to tackle it, the transport and
mobility sector is currently undergoing massive changes with
the change from combustion engines to electrical machines.
Therefore, it is desired to deploy electrical machines with high
power density and great overall efﬁciency. One machine type
that fulﬁlls these requirements is the PMSM. It has several
advantages over other machine types such as the induction
machine (IM) [21], e.g. increased overall efﬁciency, reduced
size, high power and ﬂux density as well as continuous
operation at synchronous speed is possible.

In the PMSM, the rotor consists of PMs that are placed
either inside of the rotor design (interior-PMSM) or on the
surface of it (surface-PMSM) [21]. The most commonly used
elements for the PM are ceramic materials such as Barium
Ferrites, rare earth materials such as Samarium and Cobalt or
amorphous materials such as Neodymium Iron Boron (NdFeB)
which are most often applied in the automotive area [21].
As these resources are considered limited and are subject
to signiﬁcant price volatilities, a minimization of the magnet
dimension is desired [22]. The stator, in contrary, is built based
on a multiphase symmetrical coil winding (see Figure 1) that
is exciting the rotor PMs. As the magnet dimensions of the

2

Fig. 1. Design of investigated PMSM containing three polepairs and 36 slots.

PM are considered to be strongly correlating with the machine
costs, in this work we will minimize the magnet dimensions
and thereby, we minimize the costs of manufacturing the
electrical machine. The used PMSM of this paper is based
on the benchmark example introduced in [23], where a manu-
factured PMSM is investigated with regard to a ﬁnite element
environment.

B. Mathematical foundation

The simulation is carried out based on magnetostatic for-
mulation of Maxwell’s equations since the dimensions of the
problem are signiﬁcantly smaller than the wave length. There-
fore the displacement current density ∂D/∂t is neglected. The
resulting equations on a computational domain D are

H = J +

∇ ×

∇ ×

M, B = µH, B =

A,

(1)

∇ ×

where A describes the magnetic vector potential, J the
(source) current density, M the magnetization, µ the perme-
ability, H the magnetic ﬁeld strength, B the magnetic ﬁeld
density. We suppressed spatial and temporal dependencies of
the ﬁelds for brevity. The equations in (1) can be used to derive
the curl-curl equation that is the underlying partial differential
equation to describe the phenomena of the electrical machine

(ν

A) = J +

M,

(2)

∇ ×

∇ ×

∇ ×

where ν = µ−1 is the magnetic reluctivity. The geometry
will be changed during the optimization, i.e., we parametrize
the domain D = D(x) using a parameter vector x. On the
other hand, the magnetization M := M(p) will depend on
uncertainties p in the magnets. Consequently, the solution
A := A(x, p) of (2) inherits those dependencies. Its dis-
cretization is carried out by CST Studio Suite ® 2021 using
higher-order FEM and a domain decomposition approach for
the mechanical rotation. We address the solution for some time
step tk by Ak(x, p).

C. Assumptions

One of the common drivers for the usage of virtual pro-
totypes is the event of uncertainties during the manufac-
turing process that inﬂuences certain machine performance
measurements. These inﬂuences on the QoI may lead to a
malfunction of the whole machine. These uncertainties are
often investigated in a late stage of the product development

under which the efﬁciency of the whole product lifecycle
might suffer. If those uncertainties are included in earlier
design stages, more robust design development is possible as
the uncertainty propagation can be estimated accurately [19]
by means of statistical methods as it will be described in
Section III. In the ﬁeld of electrical machines, there exists
a range of parameters that are potentially subject to variations
in the manufacturing process [19]. Multiple studies address
those parameters, e.g. uncertain material properties due to
the welding process, geometrical uncertainties such as rotor
eccentricities or variations in the stator slots, and most im-
portantly for the PMSM, uncertainties that are introduced to
the geometry and magnetization of the PMs as investigated
in [24]–[26]. In [26], it is shown how PMs of three different
manufacturers vary in those parameters, i.e., magnitude Br
and direction φ of the PM’s magnetic ﬁeld. To investigate
their inﬂuence, we choose the average torque τavg over one
electrical period

tep =

n

·

1
Npp

=

60

1930 rpm

·

0.01036 s = 10.36 ms,

(3)

3 ≈

as the QoI. Here, n describes the speed of the machine in rpm
and Npp is the number of pole pairs that are taken from the
speciﬁcations in Table I. The average torque is calculated as

Nper

τk,

(4)

τavg =

1
Nper

(cid:88)k=1

where Nper is the number of timesteps used to resolve the
electrical period in the transient simulation and τk := τ (Ak),
k = 1, . . . , Nper the value of the torque in each timestep. All
model parameters are given in Table I.

III. UNCERTAINTY QUANTIFICATION

A. Deﬁnition of the yield

Let us distinguish between deterministic parameters x, e.g.
the geometry parameters, and uncertain parameters p, e.g. the
magnitude and the orientation of the magnetic ﬁeld, and one or
more QoIs Q(x, p), e.g. the torque. The uncertain parameters
are modeled as random variables. Common modeling choices
are the normal or uniform distribution. Following [19], we use
the uniform distribution deﬁned by

(5)

ri, ri),

pi = pi + ∆pi for i = 1, . . . , np
with ∆pi ∼ U
(
−
R and ri > 0. Let pdf(p)
where p = (p1, . . . , pnp)T, pi ∈
denote the corresponding multivariate probability density func-
tion. We introduce performance feature speciﬁcations (pfs) as
constraints for the QoI. These are the properties which should
be fulﬁlled by the ﬁnal design. This is given by

Q(x, p)

c,

≤

(6)

keeping in mind that in case of several requirements this
constraint can be extended. Next, we introduce the safe domain
as the set of uncertain parameter combinations fulﬁlling the
pfs, i.e.,

Ωx :=

p : Q(x, p)
{

.

c
}

≤

(7)

3

Due to uncertainties in the manufacturing process – repre-
sented by the random variables in (5) – it occurs that the
manufactured device does not fulﬁll the pfs, although the
nominal design does. Following [1], we can quantify the
probability, that the manufactured device fulﬁlls all pfs, by
the yield given by

Y (x, p) =

Rnp

(cid:90)

1Ωx(p)pdf(p) dp,

(8)

where 1Ωx (p) deﬁnes the indicator function with value one,
if p lies in Ωx, and zero otherwise.

B. Estimation of the yield

A straightforward approach in order to estimate the yield
is MC analysis [2, Chap. 5]. According to the distribution
of the uncertain parameters, a number of NMC sample points
p(1), . . . , p(NMC) is generated and then the yield is estimated
by

Y (x, p)

≈

YMC(x, p) =

1
NMC

NMC

i=1
(cid:88)

1Ωx(p(i)).

(9)

The MC analysis is based on the law of large numbers, which
is why the standard deviation of the MC estimator depends on
the number of MC sample points NMC, i.e.,

σYMC =

(cid:115)

Y (x, p)(1

Y (x, p))

−
NMC

0.5
√NMC

.

≤

(10)

The inequality in (10) is an upper bound for the worst case
scenario when Y (x, p) = 0.5. The σYMC serves as measure for
the accuracy of the MC estimation and determines the required
size of the MC sample set. In the following, we aim to achieve
an accuracy of σYMC ≤
0.01, which leads to a required sample
0.01)2 = 2500. Please note, that this
size of NMC = 1/(2
·
sample size is well suited, for yield estimations until 99.9 %,
cf. [1, Chap. 4.8.7]. For higher percentages (6-sigma) much
higher accuracy is needed, i.e., more sample points or other
techniques have to be applied, e.g. importance sampling [27]
or subset simulation [28].

In a MC analysis, for each sample point, the QoI has to be
evaluated. It follows that the number of sample points required
for high accuracy of the MC analysis is prohibitive for the
computational effort associated with the ﬁnite element (FE)
simulations of (1). For this reason, more involved methods
have been developed, e.g. importance sampling [27], surrogate
modeling [4]–[6] and hybrid approaches, which combine clas-
sic MC with surrogate methods [7]. In this work, we extend
the GPR-Hybrid approach [8] for efﬁcient yield estimation to
electrical machines and integrate it into the pareto optimization
framework.

We brieﬂy introduce the main ideas of the GPR-Hybrid
approach. GPR is a surrogate technique where the QoI Q is
approximated by a Gaussian process. A Gaussian process can
be described uniquely by its mean and covariance / kernel
function. In this work we choose the mean value of the training
data evaluations as mean function and the squared exponential

4

Algorithm 1 GPR-Hybrid approach
1: Input: MC sample points p(i), i = 1, . . . , NMC, determin-
istic design point x, pfs threshold c, initial GPR surrogate
model ˜Q,

the GPR surrogate model

and obtain

2: for i = 1, . . . , NMC do
3:

Evaluate
˜Q(x, p(i)) and σGPR(x, p(i))
if ˜Q(x, p(i)) + γσGPR(x, p(i))

4:
5:
6:

7:
8:
9:
10:
11:

12:
13:
14:
15:

c then

≤
Ωx (accepted)

γσGPR(x, p(i))
−
≥
Ωx (not accepted)

Classify p(i)
∈
else if ˜Q(x, p(i))
Classify p(i) /
∈
p(i) is a critical sample point
Evaluate the FE model and obtain Q(x, p(i))
if Q(x, p(i))

c then

c then

else

≤
Classify p(i)

Ωx (accepted)

else

∈
Classify p(i) /
∈
end if
Update GPR surrogate model ˜Q

Ωx (not accepted)

end if
16:
17: end for

the yield, i.e., the maximization of the probability that one
realization in a manufacturing process fulﬁlls all performance
feature speciﬁcations. As optimization variables, the uncertain
design parameters can be considered as for example in [29],
or both, uncertain and deterministic design parameters can
be considered as in [30]. In this work we will focus on
deterministic design parameters as optimization variables, i.e.,
the optimization problem reads

max
x∈X

Y (x, p),

(12)

⊆

where X
Rnx is the feasible set. In practice, often there is
not only the reliability which has to be optimized during the
design process, but there are further objectives. This leads to
a MOO setting

max
x∈X
max
x∈X

f1(x, p)

≡

Y (x, p)

fi(x, p),

i = 2, . . . , k

(13)

with k objective functions.

While in single-objective optimization (SOO) the aim is to
ﬁnd the best solution with respect to one objective function,
in MOO the aim is to ﬁnd the best solution with respect
to all objective functions. Since the best solution for the
ﬁrst objective function is, in general, not the best solution
for the second objective function, the concept of so-called
pareto-optimal solutions have been introduced [9, Def. 2.1]:
X is pareto-optimal, if there is no
A feasible solution x(cid:63)
X such that
x

∈

∈

fi(x(cid:63)) for i = 1, . . . , k and

fi(x)
fi(x) > fi(x(cid:63)) for some i

≥

1, . . . , k

∈ {

.

}

(14)

Fig. 2. Visualization of GPR-Hybrid approach with accepted (blue), not
accepted (red) and critical (orange) sample points.

kernel (also called radial basis function (RBF) kernel) given
by

cov(Q(y), Q(y(cid:48))) = k(y, y(cid:48))

(11)

= ζ 2 exp

y
|

y(cid:48)
−
2l2

2
|

,

∈

(cid:19)

−
(cid:18)
R and l > 0 and two
with the two hyperparameters ζ
training data points y and y(cid:48). Using these assumptions and a
set of training data points, a surrogate model of Q is built.
Since the surrogate model is a Gaussian process, we can
evaluate mean and standard deviation of the surrogate model
in any (also unseen) point y(cid:63). The mean value ˜Q(y(cid:63)) can be
used as prediction of the function value Q(y(cid:63)), the standard
deviation σGPR(y(cid:63)) as an error indicator. The availability of
an error indicator without additional costs, as well as the
possibility of simple model updates due to not requiring
structure in the training data set, makes the GPR approach
so suitable for hybrid methods. For more detailed information
on GPR we refer to [6, Chap. 2].

In the GPR-Hybrid approach, the training data set for the
initial GPR surrogate model is chosen small, such that the
computational effort is low and the initial accuracy of the GPR
model is moderate. The MC analysis is started, i.e., the MC
sample set is generated and step by step the sample points
are evaluated with the surrogate model. Using a rule based on
the prediction and the error indicator, it is decided whether
the point is also evaluated on the FE model or not. Then,
the sample points are classiﬁed as accepted (lying inside the
safe domain Ωx) or not accepted. Each time, a sample point
is evaluated with the FE model, this information is used to
update the GPR surrogate model online, i.e., to increase its
accuracy, and the remaining sample points are evaluated on
the updated surrogate model. In the end, the classiﬁcation of
accepted and not accepted is used for the yield estimation
with (9). The basic procedure is given in Algorithm 1 and a
visualization of the classiﬁcation of the sample points is shown
in Fig. 2. In this work, the safety factor is set to γ = 2. Please
note that higher values of the safety factor may increase the
number of FE model evaluations, but promise higher accuracy
of the yield estimator. For more details we refer to [8].

IV. THE MULTI-OBJECTIVE OPTIMIZATION PROBLEM

A. Formulation of the optimization problem

Having an efﬁcient method for yield estimation, we for-
mulate the optimization problem for the maximization of

This implies that a pareto-optimal solution is a solution, such
that it is not possible to improve the value of one objective

Ωxpp1p2c˜Q+γσGPR−γσGPR˜Q+γσGPR−γσGPR˜Q−γσGPR+γσGPRp(i)Q(cid:0)x,p(i)(cid:1)5

Algorithm 2 Multi-start optimization method
1: Input: set of starting points x(i)

0 , i, . . . , Ns, low ﬁdelity
model fL, high ﬁdelity model fH, optimization problem
(P),

till stopping

2: for i = 1, . . . , Ns do
3:

Solve (P) based on fL, starting with x(i)
0
criterion for exploration phase is reached
Obtain best solution x(i)
(cid:63)

4:
5: end for
6: Set xcontinue = arg maxi=1,...,Ns fL(x(i)
(cid:63) )
7: Solve (P) based on fH, starting with xcontinue till stopping

criterion for exploitation phase is reached

C. Multi-start procedure

When using the weighted sum method, we will also in-
vestigate a multi-start procedure. By this we try to cover the
feasible set best without being trapped in a local optimum.
Therefor, a set of starting points is generated and for each
starting point the optimization is started. Inspired by the terms
of reinforcement
learning [33], we refer to this phase as
exploration phase, since the aim is to explore as much of the
feasible set as possible in order to ﬁnd the most promising
region. After a ﬁxed (not to high) number of objective function
evaluations or iterations, the results are compared. Then, the
optimization is continued with the solution which had the
best objective function value after the exploration phase. This
second phase we refer to as the exploitation phase, because
now we seek for the best value in this region.

Multi-start procedures are a commonly used heuristic for
globalizing local optimization solvers [34, Chap. 6] and appear
in many different forms. In its simplest form, several starting
points are used, the local optimization is run till the end and
then the best solution is chosen. In our setting, each evaluation
of the objective function is computationally expensive. Thus,
running the local optimization multiple times might be pro-
hibitive. For that reason we establish the two phases and follow
only the most promising solution from the exploration phase.
The computing time can be further improved, by using lower
ﬁdelity models for the exploration phase and a high ﬁdelity
model in the exploitation phase. There are many options to
distinguish between low and high ﬁdelity models: when using
FEM it can refer to the number of elements for example, or in
case of yield optimization, it can refer to the size of the MC
sample set. The basis procedure is sketched in Algorithm 2.

D. Genetic algorithms

An alternative to scalarization methods are genetic algo-
rithms [10, Chap. 4]. They, in fact, solve MOO problems
directly and the solution is an approximation of the pareto-
front. Genetic algorithms are motivated by the process of
natural evolution of organisms. The basic idea is as follows:
a so-called population of individuals, i.e., an initial set of
data points, is generated, the objective functions are evaluated
on these individuals and in each iteration the population is
updated. The update consists of three main elements: selection
(survival of the ﬁttest), crossover (reproduction process where

Fig. 3. Visualization of the pareto-front for a bi-objective maximization
problem.

function without deteriorating the value of another one. Thus,
the solution of a MOO problem is not one single point, but the
set of pareto-optimal solutions, the so-called pareto-front. In
Fig. 3 the pareto-front of a bi-objective maximization problem
is visualized.

B. Scalarization methods

A classic approach for MOO are scalarization techniques
like the weighted sum or ε-constraint methods [9, Chap.
3-4]. The basic idea of scalarization is to transform the
MOO problem into a SOO problem. In case of the weighted
sum scalarization this is achieved by combining all objective
functions into one weighted sum which is the new objective
function. We obtain

k

w1Y (x, p) +

wifi(x, p)

(15)

max
x∈X

i=2
(cid:88)

with weights wi > 0, i = 1, . . . , k. In case of the ε-
constraint scalarization, only one of the objective functions
is maintained, while the remaining objective functions are
included into the constraints. This leads for example to the
following formulation

Y (x, p)

max
x∈X
s.t. fi(x, p)

(16)

εi,

i = 2, . . . , k

≥

R, i = 2, . . . , k. Please note that k
with lower bounds εi ∈
different formulations are possible, depending on the choice
of the objective function which stays an objective function.
The advantage of scalarization techniques is the fact, that after
the reformulation we have a SOO problem, which can be
solved with classic SOO algorithms like for example simplex
algorithms [31] or Sequential Quadratic Programming [32,
Chap. 19]. On the other hand, one disadvantage of scalar-
ization is that you obtain only one pareto-optimal solution
(not a pareto-optimal front), and this solution depends on the
choice of the weights wi or the bounds εi, respectively. Thus,
in order to approximate the pareto-front,
the reformulated
problem has to be solved several times with different values
for weights and bounds. Another disadvantage of the weighted
sum method is, that convexity requirements on the feasible
set X are required, in order to have the chance to ﬁnd each
pareto-optimal solution. For more details on that we refer to [9,
Chap. 3].

f2(x)f1(x)f2,maxf1,maxpareto-frontfeasiblesolutionsTABLE I
OVERVIEW OVER MOST IMPORTANT MACHINE PARAMETERS [19], [35].

Parameter name
Rotor rated speed n
Rated current Ieﬀ
Average torque (sim.) τavg
Windings per coil Nc
Stator windings in series a
Number of pole pairs Npp
Number of slots Q
Number of phases m
Number of slots per pole and phase q
Winding pitch W/τp

Value
1930 rpm
10.60 A
10.64 N m
12
1
3
36
3
2
5/6

genetic traits of the individuals are propagated) and mutation
(variation of genetic traits). The rules how these elements are
applied, depend on the so-called ﬁtness, a metric for the quality
of an individual based on the objective function values.

V. NUMERICAL RESULTS

A. Problem setting

The machine under study is the PMSM from [19], [23]
with the properties as speciﬁed in Table I. For the uncertainty
quantiﬁcation the deterministic and uncertain parameters need
to be concretized. According to measurement studies of a
manufactured PMSM in [36],
the magnitude Br,i and the
direction φi of the magnetic ﬁeld of the i-th permanent magnet
are consequently assumed uncertain, i.e., they are modeled as
uniformly distributed random variables with mean values

(see Fig. 4). According to Eq. (5), we write

pi = pi + ∆pi for i = 1, . . . , 12
with ∆pi ∼ U
(
and ∆pi ∼ U
(
−

0.05 T, 0.05 T) for i = 1, . . . , 6
−
3°, 3°) for i = 7, . . . , 12.

(18)

(19)

As the deterministic design parameters we consider the geo-
metric parameters describing the rotor geometry as depicted
in Fig. 5, i.e.,

x = (d1, d2, d3, s)

= (19 mm, 7 mm, 7 mm, 0°) .

(20)

For the mathematical problem formulation of the electrical
machine, the magnetostatic simpliﬁcation of Maxwell’s equa-
tions (1) is used. The discretization is carried out inside of
CST Studio Suite ® 2021 with FEM to acquire a solution for
A in the computational domain (later referred to as FE model).
This allows to calculate the QoI, i.e., the average torque τavg

Fig. 4. Geometrical depiction of uncertain rotor design parameters based on
[19].

6

Fig. 5. Geometrical depiction of deterministic motor design parameters x.

over one electrical period. Next, the QoI is combined with a
pfs that includes a lower bound τpfs for the average torque τavg

Q(x, p) := τavg (A(x, p))

τpfs.

≥

(21)

Now we have everything at hand in order to estimate the
yield based on (7–8). The general problem formulation for
the optimization is based on [19, Eq. (9.52)] and is modiﬁed
for the purpose of a multi-objective yield and size, i.e., cost,
optimization. The modiﬁed problem formulation is given by

max
x∈R4

min
x∈R4

Y (x, p)

YMC(x, p) =

≈

C(x)

:= d1 d2

1
NMC

NMC

i=1
(cid:88)

1Ωx(p(i)) (22)

(23)

(24)
(25)

(26)

(27)

(28)

≥
≤

xlb
d3,ub
15

50
sub,

d3
d2 + d3
3d1 −
s

≤
2d3 ≤
≤

where C(x) denotes the additional quantity of the PM surface
dimensions that directly correlate with the costs of the PM. As
only the surface dimension is varied during the optimization
routine and the magnet depth is not considered within the
optimization, the surface dimension is mm2 and consequently
considered proportional to the costs.

The stated problem will be tackled with the approaches
introduced in Sec. IV. In the applied scalarization methods, the
MOO is transformed into a SOO. The SOO framework is built
in python using the PDFO framework [37] by M.J.D. Powell
that contains optimization methods to efﬁciently solve SOO
problems with linear or nonlinear constraints based on simplex
and trust-region methods (see [31], [38], [39] for more de-
tails). For the nonlinearly constrained SOO problem COBYLA
will be used, which stands for Constrained Optimization By
Linear Approximation. The problem formulation including
linear constraints will be solved with LINCOA, which stands
for Linearly Constrained Optimization Algorithm. Finally, the
Genetic Algorithm simulation will be carried out with the
pymoo framework of python [40] and uses the NSGA-II
algorithm [41].

p =

Br,1, . . . , Br,6, φ1, . . . , φ6
= (0.94 T, . . . , 0.94 T, 0°, . . . , 0°)

(cid:1)

(cid:0)

(17)

s.t. x

BrBr(p)BrBr(p)φ(p)B. Training of GPR model

In this section the number of training data points for the
initial GPR model is derived and the underlying distribution is
explained. The two investigated sets of training sample points
are drawn from uniform distributions that, ﬁrst (Case #1), vary
in all parameters (features) x, p and second (Case #2), only
in the mean of the uncertain parameters p. One shoud note
that the latter case describes the sample point distributions as
performed in the later MC analysis to conduct an uncertainty
quantiﬁcation for the initial set of deterministic parameters,
whereas the ﬁrst case describes the process that occurs within
the optimization where the deterministic parameters are used
as the optimization variables, and, are consequently varied
throughout the optimization iterations. The reference yield
estimate for NMC = 2500 as derived in Sec. III-B that
is achieved by solely simulating the MC analysis on the
FE model with training sample points as in Case #1 is
Y (CST)
(x, p) = 0.0428. With the MC error indicator from (10)
MC
we derive the lower and upper bound of valid yield predictions
to use for the validation of the proposed GPR-Hybrid method.
We get

Y (CST)
MC

σYMC =

(cid:115)

(x, p)(1

Y (CST)
MC

−
NMC

(x, p))

0.00405. (29)

≈

Consequently, all predictions in the σYMC region of the yield
estimate Y (CST)
MC , and therefore in [0.03875, 0.04685], are as-
sumed as valid. In the following ˜YMC(x, p) describes the
yield estimation achieved with the GPR-Hybrid method. Ta-
ble II summarizes the simulation results for the GPR-Hybrid
approach for the two proposed cases from above. Here,
Ntrain describes the number of training sample points used
(ofﬂine), Nonline is the number of re-evaluations on the FE
model (online) within the GPR-Hybrid approach, NGPR is
the number of evaluations on the GPR model and Ntrain,tot
is the sum of ofﬂine and online usage of sample points, i.e.,
Ntot = Ntrain + Nonline.
It can be seen that

in Case #1 the GPR is capable
of delivering very accurate predictions with only 10 initial
training data points. The same holds for all considered training
set sizes above 10. On the other hand, the GPR built in
Case #2, requires a higher number of training data points for
accurate predictions – at least 15. The deviations in the yield
estimate lie all inside the accepted error tolerance determined

TABLE II
OVERVIEW OVER YIELD ESTIMATIONS ACHIEVED WITH THE
GPR-HYBRID APPROACH BASED ON THE TWO PROPOSED CASES OF
TRAINING SAMPLE POINTS.

Case #1

Case #2

Ntrain
10

20

50

15

20

30

˜YMC(x, p) Nonline NGPR Ntot
0.0428

2474

26

10 + 26 = 36

0.0428

0.0428

0.0392

0.0436

0.0432

23

21

34

40

43

2477

2479

2466

2460

2457

20 + 23 = 43

50 + 21 = 71

15 + 34 = 49

20 + 40 = 60

30 + 43 = 73

7

Fig. 6. Comparison of FE model evaluations and GPR standard deviation
σGPR propagation for the two proposed test cases. Iteration i refers to th i-th
MC sample point within the GPR-Hybrid approach.

by NMC = 2500. It is evident that this prediction performance
is a bit worse when compared to Case #1 as the training set
does not solely include points that resemble the sample points
drawn in a MC analysis, but also the deterministic optimization
variables. However, as in the remainder of this paper an
optimization over the deterministic parameters is desired, a
variation in the deterministic parameters x is used in the
training. Figure 6 shows the iterations in which a re-evaluation
on the original model was needed and the correlation to the
standard deviation σGPR of the GPR model prediction. Here,
Case #1/2 describes the iterations in which a re-evaluation
was needed for both cases. It can be observed that in Case #2
more FE model evaluations are needed in the early stages
of the MC analysis that lead to a signiﬁcant reduction of
the standard deviation σGPR after approximately 250 iterations
converging to the value of the standard deviation that was
achieved in Case #1. With 20 training data points in Case #2
we have total costs of 60 objective function evaluations and
only two sample point differently classiﬁed as in the reference
solution. In all further experiments we use this size of initial
training data points for the optimization. With this, we obtain
an approximation not only in the starting point, but
in a
neighborhood of the starting point. Furthermore, it has to be
noted that with the applied GPR-Hybrid approach the number
of needed FE model evaluations that take around tFE = 85 s
is signiﬁcantly reduced.

C. Optimization results

The parameters of both the ε-constraint and the weighted
sum method are varied throughout various optimizations. Ad-
ditionally, a multi-start procedure is utilized. Finally, a genetic
algorithm from the python pymoo package is used and applied
to the individual objectives.

1) ε-constraint method: As introduced in Eq. (16), one
of the objective functions is transformed into a constraint.
The yield function remains objective, while the function of
the surface of the PM becomes a constraint, bounded by

05001000150020002500Iterationsi1CSTevaluationCase#2Case#1/205001000150020002500Iterationsi10−310−210−1ValueofσGPRCase#1Case#2ε

≡

Cmax. The resulting optimization problem reads

max
x∈R4

Y (x, p)

(30)

8

s.t. C(x)

Cmax

≤

(24) – (28) hold.

As outlined above, the optimization problem is solved with
the COBYLA solver of the PDFO framework. The outcome
of the simulation can be observed in Table III that shows
the chosen bound Cmax, the optimized yield estimate ˜Y (opt)
MC ,
the PM surface dimensions of the optimized motor design
C(x), the number of objective function calls nfev during the
optimization and the number of needed FE model evaluations
given as sum of ofﬂine and online evaluations. The utilized
solver is capable of signiﬁcantly increasing the yield ˜YMC for
multiple choices of Cmax and the resulting surface dimensions
are always very close to the upper limit Cmax. But it can
additionally be observed that if the value of Cmax is chosen
too low, the optimization routine fails to improve the yield
estimate (Cmax = 100). We see that the choice of ε = Cmax is
a trade off between the optimality of the yield and the surface
dimensions and is crucial for the result of the optimization,
which poses a drawback in practice. The propagation of
the yield estimate and the surface dimensions can be seen
in Figure 7 and 8. The exploration phase of the simplex
methods is observable in the ﬁrst ten function evaluations as
the results for all different settings look comparable in that
range. Furthermore, it is evident that the ε-constraint method
is varying the design parameters x such that an improvement
of the yield estimate is achieved in a few function evaluations
only (e.g., for Cmax = 108 between the 16th and 18th function
evaluation in Figure 7). The same phenomenon is visible in
Figure 8 for the PM surface dimensions, where the desired
upper bouadary for the PM surface dimensions Cmax are
quickly met. The termination of the algorithm is determined
by the applied simplex methods and the correlating trust region
subproblem (see [31], [38], [39] for more details).

TABLE III
COMPUTATION STATISTICS OF ε-CONSTRAINT METHOD WITH VARIATION
IN Cmax.

Cmax
120
110
108
100

˜Y (opt)
MC
1.0
0.998
0.996
0.0

C(x)
119.938
110.000
108.000
99.092

nfev
17
35
42
38

Total FE evaluations
20 + 350 = 370
20 + 362 = 382
20 + 315 = 335
20 + 162 = 182

TABLE IV
COMPUTATION STATISTICS OF WEIGHTED SUM METHOD WITH VARIATION
IN THE WEIGHT w.

w
1 × 10−3
2 × 10−3
3 × 10−3
5 × 10−3

˜Y (opt)
MC
0.999
0.996
0.995
0.978

C(x)
128.963
114.594
109.7022
105.174

nfev
31
35
59
100

Total FE evaluations
20 + 259 = 279
20 + 230 = 250
20 + 262 = 282
20 + 734 = 754

Fig. 7. Propagation of the yield estimate throughout the optimization for the
ε-constraint method.

Fig. 8. Propagation of the PM surface dimensions throughout the optimization
for the ε-constraint method.

2) Weighted sum method: In contrary to the ε-constraint
method, the weighted sum method combines both objectives
into a weighted sum as in Equation (15) that is consequently
minimized. The resulting problem formulation reads

min
x∈R4

f (x, p) =

−

Y (x, p) + w C(x)

(31)

s.t. (24) – (28) hold.

×

10−3 to 5

Therefore, the degree of freedom in that formulation is the
weight w that is varied throughout the optimizations conducted
with the weighted sum method. The optimization problem is
solved with the LINCOA solver of the PDFO framework. The
outcome is given in Table IV. The weighted sum approach also
proves to signiﬁcantly increase the yield estimate ˜YMC of the
optimization problem in Eq. (22–28). The weight w is varied
10−3 in four steps. It is evident that the
from 1
simulation needs more function evaluations when the weight w
is increased and, consequently, the surface dimensions C(x)
have an increased inﬂuence on the objective function (e.g.,
10−3). In the
10−3 and nfev = 100 for 5
nfev = 31 for 1
latter case the simulation is terminated because it reached the
upper limit of nfev = 100 function evaluations. Similarily to
the COBYLA, the LINCOA terminates once the trust region
conditions are fulﬁlled and additionally takes into account the
weighted difference of the last four function evaluations given
by

×

×

×

1
4

(cid:32)

4

i=1
(cid:88)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

∆fj =

fj−i(x, p)

(cid:33) −

fj(x, p)

,

(32)

where fj(x, p) is the objective function value of the j-th
function evaluation.

Furthermore, the tradeoff between the surface dimension
and the yield estimate is visible in Table IV, as the optimized

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

0510152025303540Objectivefunctionevaluationi0.00.20.40.60.81.0YieldestimateCmax=120Cmax=110Cmax=108Cmax=1000510152025303540Objectivefunctionevaluationi100110120130140150160PMsurface[mm2]Cmax=120Cmax=110Cmax=108Cmax=1009

TABLE V
COMPUTATION STATISTICS OF WEIGHTED SUM METHOD WITH AND
WITHOUT THE MULTI-START PROCEDURE.

Multi-start
no
yes

˜Y (opt)
MC
0.999
0.998

C(x)
128.963
111.203

nfev
31
135

Total FE evaluations
20 + 259 = 279
20 + 394 = 414

surface dimensions of C(x) = 128.963 mm2. The multistart
procedure for the ﬁrst twelve function evaluations with low
ﬁdelity, i.e., NMC = 100 can be seen in Figure 11. The
starting point x0,best represents the design vector x that led
to the best objective value after twelve function evaluations
and is highlighted in blue. After the exploration phase with
NMC = 100 is completed, the exploitation phase for that
starting point is continued with high-ﬁdelity (NMC=2500). The
outcome is shown in Table V. We see that by including the
multistart procedure, the PM surface dimensions were further
the disadvantage of
decreased by 14 %. This shows,
scalarization methods to converge into suboptimal local optima
can be compensated by the multistart procedure. Furthermore,
Figures 12 and 13 show the direct comparison of the weighted
sum method with and without the multistart procedure by
the propagation of the yield estimate and the PM surface
dimensions. It can be seen that the setting of the weighted sum
approach without the multistart procedure runs into the local
optimum with surface dimensions of 128.963 mm2, whereas
the application of the multistart procedure leads to a further
reduction to C(d) = 111.203 mm2. An exemplary design
optimization for the multistart method is shown in Figure 14.

that

4) Genetic Algorithm: This section gives a short outlook
into the application of a genetic algorithm applied to the MOO
problem. Especially for this kind of computationally expensive
problems a fast computation of a single function evaluation is
mandatory. With the application of the GPR-Hybrid approach
it is possible to reduce the percentage of needed FE model
evaluations to approx. 11000, which corresponds to 0.441 %
of the total QoI evaluations needed for the genetic algorithm
simulation. For the simulation itself we set a budget of 1000
objective function evaluations, i.e., yield estimations, a starting
population size of 100 with 50 offsprings in future generations.
A snapshot of the resulting pareto front can be seen in Figure

Fig. 9. Propagation of the yield estimate throughout the optimization for the
weighted sum method.

Fig. 10. Propagation of the PM surface dimensions throughout the optimiza-
tion for the weighted sum method.

yield estimate ˜Y (opt)
MC decreases when the surface dimensions
C(x) decreases. The propagation of the yield estimate and
the PM surface dimensions is shown in Figure 9 and 10.
In comparison to the propagation of the objectives in the ε-
constraint method, the optimization needs a larger amount
of function evaluations to siginiﬁcantly decrease the surface
of the PMs, as there is no target deﬁned for the surface
dimensions as with Cmax in the ε-constraint method.

3) Multistart procedure: This section presents the results
of the advanced method of including a multistart procedure
into the weighted sum optimization to further improve the
performance. In general, the two described methods of the
ε-constraint and weighted sum method have the disadvantage
that a degree of freedom needs to be set, that has a signiﬁcant
inﬂuence on the outcome of the optimization as shown in
Table III and IV. Especially, the latter has difﬁculties with
nonconvex objectives and is prone to run into suboptimal
local minima. Therefore the multistart procedure is applied
led to higher
with the weighted sum method setting that

Fig. 11. Demonstration of exploration phase where the best performing
starting point is highlighted in blue.

Fig. 12. Comparison of the propagation of the yield estimate throughout the
optimization for the weighted sum method with and without the multi-start
procedure.

020406080Objectivefunctionevaluationi0.00.20.40.60.81.0Yieldestimatew=1×10−3w=2×10−3w=3×10−3w=5×10−3020406080Objectivefunctionevaluationi100110120130140150160PMsurface[mm2]w=1×10−3w=2×10−3w=3×10−3w=5×10−30246810Objectivefunctionevaluationi0.00.20.40.60.8Objectivefunctionvaluex0,restx0,best010203040Objectivefunctionevaluationi0.00.20.40.60.81.0Yieldestimatenomulti-startwithmulti-start10

ε-constraint and weighted sum are compared. Both lead to
overall high values for the yield estimate, while the rate
of decrease of the PM surface dimensions depends on the
choice of the scalarization parameters, which is a drawback
in practice. On the other hand, the weighted sum method is
extended with a multistart procedure that further improves the
optimization performance of the utilized methods. Although
scalarization parameters still have to be chosen, their impact
on the optimization result is greatly reduced. Additionally, a
genetic algorithm (GA) is applied, which does not require such
a parameter selection. Both methods, GA and weighted sum
with multistart procedure, achieve to ﬁnd a similar optimal
solution. The multistart approach requires 4 % of the ﬁnite
element (FE) model evaluations compared to GA.

For future research, however, multiple advanced concepts
can be applied. These are, for example, the addition of multiple
QoIs for the electrical machine such as the total harmonic
distortion, adaptive weight selection for the weighted sum
method, or adaptive numbers of the MC sample points.

ACKNOWLEDGMENTS

This work has been supported by the Graduate School CE
within the Centre for Computational Engineering at Technis-
che Universit¨at Darmstadt, the Federal Ministry of Education
and Research (BMBF) and the state of Hesse as part of the
NHR Program and the SFB TRR 361 CREATOR (grant num-
ber 492661287) funded by the German Research Foundation
DFG.

REFERENCES

[1] H. E. Graeb, Analog Design Centering and Sizing. Dordrecht: Springer,

2007.

[2] J. M. Hammersley and D. C. Handscomb, Monte Carlo methods.

Methuen & Co Ltd, 1964.

[3] C. Bogoclu and D. Roos, “A benchmark of contemporary metamodeling

algorithms,” in ECCOMAS Congress, Jun. 2016.

[4] C. R. Rao and H. Toutenburg, Linear Models: Least Squares and

Alternatives, 2nd ed. New York: Springer, 1999.

[5] I. Babuˇska, F. Nobile, and R. Tempone, “A stochastic collocation method
for elliptic partial differential equations with random input data,” SIAM
J. Numer. Anal., vol. 45, no. 3, pp. 1005–1034, 2007.

[6] C. E. Rasmussen and C. K. Williams, Gaussian Processes for Machine

Learning. Cambridge: The MIT Press, 2006.

[7] J. Li and D. Xiu, “Evaluation of failure probability via surrogate
models,” J. Comput. Phys., vol. 229, no. 23, pp. 8966–8980, 2010.
[8] M. Fuhrl¨ander and S. Sch¨ops, “A blackbox yield estimation workﬂow
with gaussian process regression applied to the design of electromagnetic
devices,” Journal of Mathematics in Industry, vol. 10, no. 25, 2020.

[9] M. Ehrgott, Multicriteria Optimization. Springer, 2005.
[10] C. Audet and W. Hare, Derivative-Free and Blackbox Optimization, 01

2017.

[11] P. Di Barba, Multiobjective Shape Design in Electricity and Magnetism,

ser. Lecture Notes in Electrical Engineering. Springer, 2010.

[12] G. Taguchi, S. Chowdhury, and Y. Wu, Taguchi’s Quality Engineering

Handbook.

John Wiley and Sons, Inc, 2005.

[13] Z. Bontinck, O. Lass, S. Sch¨ops, H. De Gersem, S. Ulbrich, and
O. Rain, “Robust optimization formulations for the design of an electric
machine,” IET Sci. Meas. Tech., vol. 12, no. 8, pp. 939–948, 2018-08-13.
[14] Z. Ren, D. Zhang, and C.-S. Koh, “New reliability-based robust design
optimization algorithms for electromagnetic devices utilizing worst case
scenario approximation,” IEEE transactions on magnetics, vol. 49, no. 5,
pp. 2137–2140, 2013.

[15] S. Xiao, Y. Li, M. Rotaru, and J. K. Sykulski, “Six sigma quality
approach to robust optimization,” IEEE Transactions on Magnetics,
vol. 51, no. 3, pp. 1–4, 2015.

Fig. 13. Comparison of the propagation of the PM surface dimensions
throughout the optimization for the weighted sum method with and without
the multi-start procedure.

Fig. 14. Optimized design (multi-start method). Here, the ﬁlle rectangle
displays the optimized design and the contours the original design dimensions.

Fig. 15. Visualization of the pareto front of the 8th generation of the genetic
algorithm for the stated problem similar to Figure 3. NSGA-II algorithm
converges to single solution marked with red square.

15 that displays the individuals of the 8th generation with
the feasible solutions depicted in gray. Finally, the NSGA-
II algorithm terminates the computation after 1000 function
evaluations are conducted and converges to a single point
(depicted by the red square in the same ﬁgure) with a yield
estimate of 1.0 and PM surface dimensions of 108.146 mm2.
The advantage of the genetic algorithm (GA) simulation is
that no further parameters such as a bound Cmax or weights
w need to be set accordingly to acquire good optima.

VI. CONCLUSION

This paper introduces the application of the GPR-Hybrid
method to electrical machines. We show that by using machine
learning, the computational effort of yield estimation and yield
optimization can be signiﬁcantly reduced, while maintaining
high accuracy. Furthermore, for the design of the electrical
machine, multi-objective optimization is applied in order to
increase the reliability, i.e., the yield, and to decrease the
costs, i.e., the size of the magnets. The scalarization methods

010203040Objectivefunctionevaluationi100110120130140150160PMsurface[mm2]nomulti-startwithmulti-start11

[16] G. Lei, G. Bramerdorfer, C. Liu, Y. Guo, and J. Zhu, “Robust design
optimization of electrical machines: A comparative study and space
reduction strategy,” IEEE Transactions on Energy Conversion, vol. 36,
no. 1, pp. 300–313, 2020.

[17] P. Gangl, S. Amstutz, and U. Langer, “Topology optimization of electric
motor using topological derivative for nonlinear magnetostatics,” IEEE
Transactions on Magnetics, vol. 52, no. 3, pp. 1–4, 2015.

[18] Z. Bontinck, O. Lass, S. Sch¨ops, H. De Gersem, S. Ulbrich, and O. Rain,
“Robust optimisation formulations for the design of an electric machine,”
IET Science, Measurement & Technology, vol. 12, no. 8, pp. 939–948,
2018.

[19] Z. Bontinck, “Simulation and robust optimization for electric devices
with uncertainties,” Ph.D. dissertation, Technische Universit¨at Darm-
stadt, 2018.

[20] M. Arjona, C. Hernandez, and J. Lara, “Electromagnetic optimal design
of a permanent magnet synchronous generator,” ICS Newsletter, vol. 28,
no. 3, 2021.

[21] J. A. Melkebeek, Electrical Machines and Drives.

Springer Interna-

tional Publishing, 2018.

[22] J. D. Widmer, R. Martin, and M. Kimiabeigi, “Electric vehicle traction
motors without rare earth magnets,” Sustainable Materials and Tech-
nologiees, vol. 3, pp. 7–13, 2015.

[23] U. Pahner, R. Mertens, H. De Gersem, R. Belmans, and K. Hameyer, “A
parametric ﬁnite element environment tuned for numerical optimization,”
IEEE Transactions on Magnetics, vol. 34, no. 5, pp. 2936–2939, 1998.
[24] M. A. Khan, I. Husain, R. Islam, and J. Klass, “Design of experiments
to address manufacturing tolerances and process variation inﬂuencing
cogging torque and back emf in the mass production of the permanent
magnet synchronous motors,” in Energy Conversion Congress and
Exposition (ECCE).
IEEE, 2012, pp. 3032–3039.

[25] J. Kolb and K. Hameyer, “Sensitivity analysis of manufacturing toler-
ances in permanent magnet synchronous machines with stator segmenta-
tion,” Transactions on Energy Conversion, vol. 35, no. 4, pp. 2210–2221,
2020.

[26] G. Lei, J. Zhu, C. Liu, and B. Ma, “Robust design optimization of
electrical machines and drive systems for high quality mass production,”
in 6th International Electric Drives Production Conference (EDPC).
IEEE, 2016, pp. 217–223.

[27] L. Gallimard, “Adaptive reduced basis strategy for rare-event simula-

tions,” Int. J. Numer. Meth. Eng., no. 1, pp. 1–20, 2019.

[28] J. Bect, L. Li, and E. Vazquez, “Bayesian subset simulation,” SIAM/ASA

J. UQ, vol. 5, no. 1, pp. 762–786, Jan. 2017.

[29] M. Fuhrl¨ander and S. Sch¨ops, “Yield optimization using hybrid gaussian
process regression and a genetic multi-objective approach,” Advances in
Radio Science, vol. 19, no. B., pp. 41–48, 2021.

[30] ——, “Efﬁcient yield optimization with limited gradient information,”

arXiv preprint arXiv:2105.07799, 2021.

[31] M. Powell, “A view of algorithms for optimization without derivatives,”
Centre for Mathematical Sciences, Cambridge University, 2007.
[32] M. Ulbrich and S. Ulbrich, Nichtlineare Optimierung. Birkh¨auser, 2012.
[33] R. Sutton, Reinforcement Learning: An Introduction/Richard S. Sutton,

Andrew G. Barto. MIT Press, 1998.

[34] R. C. Mart´ı, P. M. Pardalos, and M. G. Resende, Handbook of heuristics.

Springer, 2018.

[35] U. Pahner, R. Mertens, H. De Gersem, R. Belmans, and K. Hameyer, “A
parametric ﬁnite element environment tuned for numerical optimization,”
IEEE Transactions on Magnetics, vol. 34, no. 5, pp. 2936–2939, 1998.
[36] P. Offermann and K. Hameyer, “Stochastic models for the evaluation of
magnetisation faults,” COMPEL: The International Journal for Com-
putation and Mathematics in Electrical and Electronic Engineering,
vol. 33, no. 1/2, pp. 245–253, 2013.

[37] Zhang, Tom M. Ragonneau and Zaikun, “Pdfo - powell’s derivative-
free optimization solvers,” accessed 21.09.2021. [Online]. Available:
https://www.pdfo.net/docs.html

[38] M. Powell, “Direct search algorithms for optimization calculations,”

Acta Numerican, Vol. 7, Cambridge University Press, 1998.

[39] ——, “On fast trust region methods for quadratic models with linear
constraints,” Centre for Mathematical Sciences, Cambridge University,
2014.

[40] J. Blank and K. Deb, “Pymoo: Multi-objective optimization in python,”

IEEE Access, vol. 8, pp. 89 497–89 509, 2020.

[41] K. Deb and H. Jain, “An evolutionary many-objective optimization
algorithm using reference-point-based nondominated sorting approach,
part i: Solving problems with box constraints,” IEEE Transactions on
Evolutionary Computation, vol. 18, no. 4, pp. 577–601, 2014.

