2
2
0
2

n
u
J

8

]

G
L
.
s
c
[

1
v
9
4
1
4
0
.
6
0
2
2
:
v
i
X
r
a

A. DANESH PAZHO ET AL.

1

A Comprehensive Survey of Graph-based Deep
Learning Approaches for Anomaly Detection in
Complex Distributed Systems

Armin Danesh Pazho* , Ghazal Alinezhad Noghre*, Arnab A Purkayastha, Jagannadh Vempati, Otto
Martin, and Hamed Tabkhi

Abstract—Anomaly detection is an important problem for complex distributed systems consisting of hardware and software
components. A thorough understanding of the requirements and challenges of anomaly detection for such systems is pivotal to the
security of a system, especially for real-world deployment. While there have been many diverse research areas and application
domains that deal with the problem, few have attempted to provide an in-depth look at such systems. Most anomaly detection
techniques have been speciﬁcally developed for certain application domains, while others are more generic. In this survey, we explore
the signiﬁcant potential of graph-based algorithms to identify and mitigate different types of anomalies in complex distributed
heterogeneous systems. Our main focus is to provide an in-depth look at graphs when applied on heterogeneous computing devices
spread across complex distributed systems. This study analyzes, compares, and contrasts the state-of-the-art research articles in the
ﬁeld. First, we describe the characteristics of the real-world distributed systems and their speciﬁc challenges of anomaly detection in
such complex networks, such as data and evaluation, nature of the anomalies, and real-world requirements. Later, we discuss why
graphs can be leveraged in such systems and the beneﬁts of utilizing graphs. Then we will aptly delve into the state-of-the-art
approaches and highlight their strength and weaknesses. Finally, we evaluate and compare these approaches and point out the areas
for possible improvements.

Index Terms—Graphs, Anomaly Detection, Deep Learning, Heterogeneous Systems, Distributed Systems.

(cid:70)

1 INTRODUCTION

A NOMALY detection refers to ﬁnding abnormal behavior

or patterns in the data or a system that does not
match the expected behavior [1]. In other words, A non-
benign change in the known and correct behavior of a
system can be detected as an anomaly. Anomaly detection
is critical in distributed heterogeneous systems because of
their nature. In such systems, different components, from
small variations like sensors, work all the way up to large
components like control facilities to achieve the overall goal
of the system. All these components are spread out in a big
network; hence the word distributed, and they are dissimilar
with respect to their structure and data production, hence
the word heterogeneous.

Many distributed heterogeneous systems are operational
in critical and/or important ﬁelds (e.g., Power Generation
and Distribution systems). Thus, their security and cor-
rectness are critical. Vulnerabilities can be seen in every
aspect of these systems and in different levels of abstraction;

* First two authors (A. Danesh Pazho and G. Alinezhad Noghre) have equal
contribution.

• Armin Danesh Pazho, Ghazal Alinezhad Noghre, and Hamed Tabkhi are

with the University of North Carolina at Charlotte, NC, USA
E-mail: adaneshp@uncc.edu, galinezh@uncc.edu, and htabkhiv@uncc.edu
respectively.

• Arnab A Purkayastha is with Western New England University, MA

•

USA
E-mail: arnab.purkayastha@wne.edu.
Jagannadh Vempati and Martin Otto are with Siemens Technology,
Princeton, NJ, USA.
E-mail:
spectively

jagannadh.vempati@siemens.com and m.otto@siemens.com re-

from problematic individual components within a system
or a network to seeing abnormalities or irregularities where
these components connect with each other to accomplish
a more advanced task. Table 1 shows several distributed
heterogeneous networks and possible sources of anomalies
in them. Anomaly detection in these systems must meet
many requirements, making the task even more compli-
cated. Anomalies must be detected by processing large
quantities of data, considering the nature of anomalies,
which makes detecting them a challenging task and the real-
world setup limitations.

In recent years, neural networks have shown a great
potential and are being explored drastically. They have
opened new avenues and increased interest in extending
deep learning approaches for anomaly detection [2], [3].
Anomaly detection imposes several practical challenges that
make adopting deep learning algorithms difﬁcult. Among
learning approaches for anomaly detection, there has been
an increase in the number of applications where data is
represented in the form of graphs to extract more informa-
tion, such as relational features. However, graphs can be
irregular; for example, a graph may have a variable size
of unordered nodes, and/or nodes from a graph may have
a different number of neighbors. Thus, as some important
operations (e.g., regular convolutions) are easy to compute
in the domains like image processing, they become difﬁcult
to apply to the graph domain [4]. Furthermore, a core
assumption of existing machine learning algorithms is that
instances are independent of each other. This assumption
falls ﬂat for graph data because each instance (node) is

 
 
 
 
 
 
A. DANESH PAZHO ET AL.

2

TABLE 1
Example of distributed heterogeneous systems with sample source of
anomalies

Network

Sources of Anomaly

Power Generation and
Distribution

Smart Video Surveillance

Smart Cities

Smart Grids

Social Network

Telecommunication

Company’s Internal
Network

Factories’ Production Line

Smart Transportation

Banking System

Anomalies in hardware, software,
and the network
Abnormal and dangerous events,
hardware or software issues
Fault in infrastructure, safety and
privacy issues
Faults, cyber attacks, natural
disturbances
Illegal activities, bullying, spams,
offensive content
Malfunctions, hardware issues,
intrusion
Hardware and software issues,
unwanted access, intrusion
Fault in manufacturing, problem in
manufacturing line equipment
Technical issues, hardware and
software issues, abnormal
trajectory changes
Money laundering, fraud
transactions, intrusion

related to others by links and interactions. This has led to
the whole research area exploring the use of graphs in this
context.

Existing surveys mainly deal with either anomaly de-
tection as a stand-alone problem or applied to a particular
domain, for example, social media interactions, network
trafﬁc, recommendation systems, etc. Several works focus
on anomaly detection based on graph learning [5]. Several
surveys focus on speciﬁc applications of anomaly detection
e.g., [6]. A few of the papers focus on anomaly detection
on big data, and its challenges [7], [8]. In addition, there are
plenty of surveys that deal with general anomaly detection
using deep learning techniques [2], [3], [9], [10], [11]. How-
ever, none of these works explore the utilization of graphs
for anomaly detection in heterogeneous distributed systems
in the real-world as stand-alone research.

The major focus of this survey is to provide a compre-
hensive overview of the state-of-art graph-based techniques
to solve the problem of anomaly detection. In particular, we
look at real-time complex distributed systems and qualita-
tively model those to identify and analyze various methods
in anomaly detection that utilize the beneﬁts of graphs. In
a nutshell, we make the following notable contributions in
this survey:

•

• Modeling three conceptual use-cases and employing
them for exploring the requirements, challenges, and
beneﬁts of anomaly detection algorithms.
Identifying the logical, algorithmic, and implemen-
tation requirements and challenges of anomaly de-
tection in real-world heterogeneous distributed sys-
tems.

• Comparing and contrasting the different graph-
based anomaly detection algorithms in-depth for
dealing with anomalies and qualitatively model
them over the three conceptual use-cases that we
introduce.

• Providing future research direction for graph-based

anomaly detection in distributed heterogeneous sys-
tems.

The remaining of this paper is organized as follows: Sec-
tion 2 describes three use-cases that are the representatives
of real-world heterogeneous distributed systems. Section
3 identiﬁes the challenges and requirements of anomaly
detection in the context of real-world heterogeneous dis-
tributed systems. Next, Section 4 argues the beneﬁts of
moving toward using graphs in real-world heterogeneous
distributed systems. Section 5 aptly delve into the graph-
based approaches and the means of utilizing graphs for
anomaly detection. Finally, Section 6 discusses the evalua-
tion and complexity of these methods, the new challenges
and requirements that graphs add, and the future directions
that this research ﬁeld can take.

2 CONCEPTUAL USE-CASES
In order to motivate and put into perspective our research
survey, we identify and present three conceptual use-cases
of real-world applications here. These three conceptual use-
cases are good samples of heterogeneous distributed sys-
tems, prone to showing anomalous behavior. In the follow-
ing sections, for better understanding, we leverage these
examples to demonstrate the limitations and beneﬁts of the
existing work.

2.1 Smart Surveillance System

Here we use an example from [12]. Real-time Edge Video
Analytics for Multi-camera Privacy-aware Pedestrian Track-
ing or REVAMP2T [12] is designed for tracking pedestrians
across multiple cameras. The overview of the model is
shown in Fig. 1. The installed edge nodes at each place of
interest consist of a number of edge cameras empowered for
analyzing streaming video. These cameras are connected to
an edge server that acts as a database that contains informa-
tion about seen objects. The video can be sent to a number
of surveillance monitors with the extracted information if
necessary and allowed. Also, the whole information can

Fig. 1. REVAMP2T [12] setup. This setup can be expanded or shrunk
to a new setup. Each edge server only sees the data of its own location
and the cloud server is able to see all the locations connected to it. For
privacy purposes a supervised amount of information is transmitted from
each location to the cloud server.

Edge 0Edge N-1Zone 0Edge 0Edge N-1Zone kEdge 0Edge N-1Zone M-1Edge Server kEdge Server M-1Edge Server 0A. DANESH PAZHO ET AL.

3

be sent to a cloud server for further processing of less
sensitive information. An anomaly can happen throughout
this whole complex distributed heterogeneous system. For
example, a camera might get broken, or even there can be
a hacker trying to steal the extracted information from the
edge server.

This heterogeneous distributed system is completely dy-
namic, leading to a dynamic graph representation. Benign
changes like changing, removing, or updating the com-
ponents can happen in this system, which should not be
counted as anomalies. Other events such as receiving noisy
video from a camera, information mismatch between the
edge server and the cloud server, unwanted access to data
at any point of the network can be seen as anomalies.

2.2 Sensor Network

We next look at the conceptual use-case of a heterogeneous
Sensor Network that illustrates a complex distributed sys-
tem. To accurately depict the security aspects of such a
system, we take inspiration from the Purdue Model for
ICS security [13]. The Purdue Enterprise Reference Archi-
tecture was created by mapping the interconnections and
inter-dependencies of the high-level components of typical
industrial control systems (ICS) to provide guidance on how
to defend IT (Information Technology) and OT (Operations
Technology) systems against malicious actors. Fig. 2 shows
the model of such a system modiﬁed to incorporate all the
possible components of a heterogeneous system. Here, Level
0 (L0) through Level 4 (L4) are the functional levels that
span two broad zones, namely IT and OT. OT systems can
be further classiﬁed into two sub-categories which will be
discussed as follows.

• L0: Physical components that build products. Eg.

motors, pumps, sensors, valves, etc

• L1: Systems that monitor and send commands to

devices at L0. Eg. PLCs, RTUs, IEDs etc

• L2: Overall process controllers. Eg. HMIs, SCADA
etc involves humans to manage and control the pro-
cesses

Fig. 2. Sensor Network

• L3: Management of production workﬂows. Eg. batch

management, operations management etc

• L4: ERP software, databases, email servers and other
systems that manage the logistics of the manufac-
turing operations and provide communications and
data storage

The anomaly tri-junction barrier (shown in red) serves as
a demarcation of communication between the various levels
and possible sources of anomalies.

2.3 Internal Local Area Network

An internal Local Area Network (LAN) is also a good sam-
ple model of a complex distributed heterogeneous system.
The heterogeneity of the system and data is obvious. The
graph for representing the system is dynamic and directed.
It is dynamic because all the components in the network
are subject to change. For example, clients can change their
devices, the hardware of the server can change (e.g., adding
more memory or upgrading the CPU), the mediums for
connections can change, a client can get removed, or the
framework of each platform can get updated.

Furthermore, all instances of anomalies can happen in
this network. To emphasize, benign changes to the system
must not be counted as an anomaly. We are dealing with a
dynamic system that is subject to change, and it does not
have a unique correct state. Thus, capturing anomalies is
a more difﬁcult task than when we are dealing with static
systems.

3 CHALLENGES

When it comes to anomaly detection, especially in real-
world systems, a number of requirements must be met.
These requirements usually lead to challenging problems. In
this section, we identify the generic requirements and chal-
lenges of anomaly detection in real-world distributed het-
erogeneous systems. We look at these challenges from four
aspects, each of which examines anomaly detection from
an alternative standpoint: Data, Anomaly Nature, Graph,
and Real-world aspects. These viewpoints may overlap with
each other at certain points. With that being said, we tried
to distinguish them as much as possible.

Table 2 summarizes all the requirements and the chal-
lenges that follow them. In the rest of this section, we discuss
each one of them in more detail.

3.1 Data and Evaluation Aspect

1. Big Data: When it comes to anomaly detection with learn-
ing approaches, the data becomes an immediate challenge.
In many applications, the amount of data that has to be
processed is immense, pushing the problem into the big data
category. Big data meaning is best described through 5Vs
of big data: Volume, Velocity, Variety, Veracity, and Value,
each exhibiting a series of challenges. For anomaly detec-
tion, especially in distrusted heterogeneous systems, a huge
amount of data (Volume) is being generated and processed
at a very high speed (Velocity), containing multiple data
types and formats coming from several sources (Variety),
with uncertainty about the data and its quality (Veracity),

Cloud ServerSensors & ActuatorsL0L1L2HMIs, SCADAL3OperationsERP, Servers, DatabasesL4Operational Technology (OT)IT SystemsAnomaly Tri-junctionPLCs, RTUs,IEDsA. DANESH PAZHO ET AL.

4

TABLE 2
Challenges of Anomaly Detection.

Category

Challenge

Short Description

References

Big Data

Volume, velocity, variety, veracity, and value
of big data can be problematic.

[14], [15], [16], [17], [18], [19], [20], [21],
[22], [23], [24], [25], [26], [27], [28]

Data and Evaluation

High-Dimensionality

Labeled Data

Unbalanced Data

Unclean Data

Metrics and
Benchmarks

Changing Nature

Disparate Sources

Obscured Anomalies

Noise Resilience

Inference Time

Nature of Anomaly

Real-World

Privacy

Ciphered Data

Dynamic Systems

Interpretability

Domain Shift

Many numbers of features for each
datapoint can cause sparsity of data which
makes anomaly detection more arduous.
The number of labelded datasets are
alarmingly low for anomaly detection
purposes.
Anomalies happen rarely, and training on
such unbalanced data makes the model
biased.
Many proposed models work based on the
hypothesis that clean data is available which
is not realistic.
Lack of Proper Metrics and benchmarks
makes the assessment of proposed models
difﬁcult and impossible.
Novel and new types of anomalies can
happen, and anomalies may adapt
themselves with anomaly detection
algorithms.
Anomalies can happen in many different
layers and parts of systems.
Outliers can be in disguise, especially the
anomalies that are caused by a smart entity.
In many cases, noises in the input data can
mislead the models and be detected as false
positives.
In real-world applications, it is vital to
detect anomalies in a timely manner to take
the appropriate action.
In many applications, the data of the users
should be protected.

In many environments, the exchanged data
is ciphered.
Real-world systems often change over the
time and have dynamic nature.
In real-world setups, the cause of the
anomaly is important.
The model trained on one domain, cannot
generalize even to a slightly different
domain.

[29], [30], [31], [32], [33], [34], [35], [36],
[37], [38], [39]

[5], [40], [41], [42], [43]

[44], [45], [46], [47]

[48], [49], [50], [51], [52], [53], [54], [55]

[56], [57], [58], [59], [60]

[61], [62]

[63], [64], [65]

[5], [66], [67], [68]

[69], [70]

[71], [72], [73], [74], [75]

[76], [77], [78], [79], [80], [81], [82], [83],
[84]

[85], [86], [87], [88], [89]

[5], [90], [91], [92], [93], [94], [95], [96]

[97], [98], [99]

[100], [101], [102], [103], [104], [105],
[106], [107], [108], [109]

all or most of it important, and must be considered for
extracting a worthy output (Value).

2. High Dimentionality: This is another challenge that
arises from the data. In many applications, the data that
should be processed has a large number of features (dimen-
sions). Huge dimensions of the dataset can cause numerous
challenges in many applications. However, these challenges
are exacerbated in the context of anomaly detection. The
phrase “curse of dimensionality” generally refers to the
problems that arise when the number of dimensions in-
creases. A dataset is high-dimensional when we can see
the curse of dimensionality. The growth of dimensions
will increase the size of the data accordingly and causes
sparsity which eventually results in the data points having
relatively the same distance from each other. As a result, it
would be more difﬁcult to detect hidden anomalies in high-
dimensional space. This issue is still a controversial topic in
scientiﬁc society.

3. Labeled Data: In data-driven approaches, the quality

of the data has a vital role in the outcome of the model.
When it comes to anomaly detection, the number of labeled
datasets is alarmingly low. This fact encourages the use of
unsupervised or semi-supervised approaches. Thanks to the
new technologies and the advancements in devices, a huge
amount of data is available. However, in most cases, this
data does not incorporate information regarding anomalous
behavior. On the other hand, it is both expensive and time-
consuming to obtain high-quality labels for available data.
In many cases, anomalies must be discovered and labeled by
experts who have ﬁeld-speciﬁc knowledge, making the task
harder and more demanding. Also, we should consider the
noises added to the dataset by imprecise labeling. In many
applications, this noise is not acceptable and can seriously
degrade the performance of the model. The undetected
anomalies can have a huge cost in critical situations of
real-world applications. Thus, using supervised learning
is somewhat problematic in the context of anomaly detec-
tion. This being said, labeled data can perform better in

A. DANESH PAZHO ET AL.

5

certain tasks and should be explored. Several approaches
try to overcome this challenge by taking advantage of
synthetic labeled datasets, but many other approaches have
moved toward using semi-supervised, unsupervised, and
self-supervised algorithms.

4. Unbalanced Data: Another point to be mentioned
is that anomalies are rare. Supervised learning approaches
need to see enough examples while training to learn and
understand anomalies. However, the number of anomalies
is usually very subtle, causing the dataset to become un-
balanced. Anomalies are out of the ordinary incidents, and
it is not rational to expect enough samples of each type
of anomaly to be available in the dataset. This challenge,
requires the direction of solving the problem to adapt to
it. The abundance of normal data points may result in
neglecting the detection of anomalous data points which are
valuable in anomaly detection. This problem arises from the
fact that many machine learning algorithms are based on the
hypothesis that classes of data have the same distributions
which is not realistic in the case of anomaly detection.

5. Unclean Data: Many approaches, such as anomaly
detection with autoencoders (discussed in Section 5 need
datasets that only contain normal datapoints for training.
These approaches learn the normal state and decide whether
an anomaly has happened or not based on the divergence
from features of normal datapoints. However, as discussed,
anomalies can be rare and very subtle. There is a very
high chance that an anomalous datapoint slips through the
ﬁngers of the dataset responsible individual or team, or it
might not even be considered as an anomaly until later.
As a result, often datasets include undesired outliers that
make the dataset unclean. This unclean data can confuse the
model about the features and representation of the normal
datapoints and deteriorate the accuracy of the model.

6. Metrics and Benchmarks: On top of all the chal-
lenges, the most important one seems to be the fact that
there is no uniﬁed metric or benchmark, where models can
assess themselves and compare the results. Various kinds of
metrics have been introduced and we discuss a number of
important ones in Section 6.1, but almost none of the works
assess those metrics on a single unique domain, to make the
comparison between models possible.

3.2 Anomaly Nature

1. Changing Nature: Anomalies have a speciﬁc nature and
a collection of characteristics that lead to a particular set
of challenges. The ﬁrst and the most important challenge
is the changing nature of anomalies. Anomalies are not
predeﬁned static occurrences. Anomalies can transpire in
different shapes and formats, not all of them can be con-
sidered prior to the occurrence of an anomaly. There can
always be novel anomalies that have never been consid-
ered. They can adapt to anomaly detection mechanisms and
evolve to pass through the defenses of anomaly detection
algorithms. Because of this characteristic, most algorithms
tend to skew toward online learning, unsupervised learning,
or semi-supervised learning, where there are no predeﬁned
anomalies, and the algorithm learns based on what it sees
at the moment on its own. In other words, most of the
algorithms make an effort to eliminate external artiﬁcial
biases and proceed toward generic solutions. This instigate

the use of online learning, where the algorithm is constantly
learning about the behaviour of the system.

2. Disparate Sources: Distributed heterogeneous sys-
tems typically incorporate multiple layers (resources), re-
sulting in a complex and intricate system as a whole. The
role of each of these layers, disregarding its majority or
minority can not be neglected. Anomalies can penetrate
each and every one of those components, making it very
difﬁcult to track them. Especially in large facilities, the
number of components grows exponentially, and all of them
are a potential point of anomaly. This disparate source of
anomalies is one of the challenging complications that is
troubling the anomaly detection algorithms.

3. Obscured Anomalies: In addition to these challenges,
a considerable number of anomalies, predominantly the
ones that came to existence because of a smart entity, do not
like to be found. They might be disguised, or hidden. For
example, a cyber-attack tries to be as masked as possible. On
the other hand, there are anomalies that are not concealed
and are just the result of a malfunctioning component in
the system. Being conscious of both of these aspects, and
prepared for obscured anomalies is another challenging task
on the way to generic anomaly detection.

4. Noise Resilience: Systems are subject to experience a
profuse number of internal or external noises. These noises
are not anomalies until they pass a certain threshold. How-
ever, they are still an irregularity in the system. The anomaly
detection algorithms must be capable of distinguishing
between noises and anomalies. If not, they might raise
too many false positive alarms, resulting in supererogatory
attention and costs. These noises can have a wide variety
of origins. Some of them are back-breaking to discover, and
it is best to introduce a means of ﬁltering those noises out
inside the algorithm itself, instead of putting an effort to
ﬁnd the source of the noise.

3.3 Real-world Challenges

1. Inference Time: When it comes to using anomaly detec-
tion, time is of the essence, especially in real-world appli-
cations. It is expected, time-wise, that the detection of the
anomaly does not sit far from the actual happening of the
anomalous behavior. Particularly, in a critical environment
such as health-care applications, a long latency in detecting
a malfunctioning device might lead to catastrophic results,
and it is impermissible. Thus, necessary actions must be
taken to avoid such a latency. However, anomaly detection
techniques based on deep learning are often a heavy task,
requiring a colossal amount of computational power.

2. Privacy: Privacy is another important hindrance that
must be considered in a real-world environment. Anomaly
detection algorithms are involved with all the data circu-
lation and the state of the system to the furthest extent.
They know everything about a system, and if that kind of
information leaks out of the environment, it can lead to cat-
aclysmic undesirable results. Hence, an anomaly detection
algorithm must be obliged to preserve privacy and be as
secure as possible if it desires to be deployed in a real-world
environment.

3. Ciphered Data: The fact that anomaly detection al-
gorithms need to be aware of everything that is going on

A. DANESH PAZHO ET AL.

6

related to a system brings about another challenge. Many
systems, ﬁrst and foremost large heterogeneous distributed
systems like ﬁnancial systems, social media, or facilities
like power generation and distribution networks do not
intercommunicate in plain, raw data. They encode the data
and then transmit it. This ciphered data usually is not
related to the original data in an obvious manner and that is
the whole purpose of encoding the data. Hence, algorithms
face yet another arduous challenge. For example, wireless
communication between a sensor and the server contains
an encoder at the edge transmitter, ciphering the data for
privacy and security reasons, and a decoder at the receptor
that deciphers the data for further processing. When an
algorithm tries to discover anomalies on the medium (here
the wireless connector) it cannot access the raw data before
the transmission stage.

4. Dynamic Systems: Furthermore, static systems are
extremely rare in a real-world environment. Real-world
heterogeneous distributed systems are extremely dynamic.
Components get removed, added, changed, or updated.
These benign transformations must not be counted as
anomalous behavior. When an algorithm learns about the
normal state of a system, it might consider these transfor-
mations as anomalies. If so, the number of false-positive
alarms might rise to a point that makes the algorithm non-
functional and impractical for real-world adoption. On the
other hand, the anomaly detection model should be ﬂexible
enough to learn about the updated features and structure
of the network to fully incorporate existing information.
Online learning is a tool for overcoming this challenge, how-
ever, this is still a very hot topic in research communities.

5. Interpretability: Another important challenge is the
interpretability of the anomalies. Particularly, in real-world
deployments the tendency to see the actual type of anomaly
and not just the detection is more desired. One reason
behind this is that recognizing the source of the anomaly,
realizing the actual type of the anomaly (e.g., cyber attack
on sensor 1A) and informing the responsible individuals is
very important. Finding the root of the anomaly is important
for maintaining the availability of the system. Furthermore,
there is still the need to further investigate the abnormal
behaviour to recover the system or for pulling it back to the
normal situation.

6. Domain Shift: Last but not least, anomaly detection
approaches become handy, when you are able to generalize
over different domains. However, since we are dealing with
learning-based approaches, this domain shift comes with a
huge cost. Neural Networks learn about the environment
and adapt to it, making it difﬁcult to switch to another
domain. This fact discourages the use of supervised learning
and also pushes novel techniques toward online learning.
This challenge is shared between graph-based anomaly
detection and other approaches.

4 MOTIVATION: WHY GRAPH-BASED?
Non-deep learning algorithms for anomaly detection can
be categorized into three general groups of methods: sta-
tistical methods, clustering methods, and nearest neighbors
methods. In statistical algorithms, a statistical model that
ﬁts normal data is generated. Inference tests and data dis-
tribution is then carried out to calculate the anomaly scores

and determine if there are outliers in the data. Statistics-
based techniques have a signiﬁcant advantage by reducing
the dependency on labels [110]. However, an increase of
dimensionality in data leads to quadratic model complex-
ity which may result in over-ﬁtting. Clustering methods
also are unsupervised techniques that try to group similar
datapoints without any labels. As mentioned before, in
real-world distributed systems, high-dimensionality of the
data is inevitable which can seriously degenerate the per-
formance of clustering methods. Finally, nearest neighbor-
based anomaly detection algorithms deﬁne the neighbor-
hood viz., use distance or similarity measure. The distance
or relative density between data and neighborhood is used
as an anomaly score to judge anomalies. The beneﬁt of
the neighborhood-based approach is that it relaxes the as-
sumptions on data distribution and prior knowledge. On
the other hand, neighborhood-based approaches suffer from
large computational and storage overhead [111].

Deep learning-based algorithms have proved to be more
effective and generally show better results in terms of mea-
surements such as accuracy or AUC (Area Under Curve)
in comparison to traditional machine learning models. The
general beneﬁts of deep learning are applicable to deep
anomaly detection. They are more suitable for learning
complex information, their result is more generalizable and
less prone to over-ﬁtting, and they are model free. Especially
when the number of datapoints increases, they are capable
of learning complex relationships. However, the baseline
version of all of these methods has a major drawback: they
do not take advantage of the relationships between variables
and parameters. This often results in the inadequate ﬁtting
of high-dimensional parameters leading to poor anomaly
detection capabilities. Particularly in distributed heteroge-
neous systems, this relationship becomes even more impor-
tant. Take the Smart Surveillance System shown in Fig. 1
as an example. The anomaly can happen to Edge 0, the
connection between Zone 0 and Edge Server 0, Zone 0 itself,
or the combination of all these sections in this system. Here,
graphs come to our aid.

Graphs are a common way to represent complicated
relationships within a complex network. They enable us to
store the data of every component and its relation with other
components in the system. The use of graphs for anomaly
detection is a very recent topic of interest in the machine
learning and deep learning community. These approaches
offer state-of-the-art performance on a varied nature of
learning tasks that deal with complex distributed data. They
suit well for both structured (symbols, images, grid-based
data) and unstructured (knowledge graphs, social network
data, distributed systems, citation networks, network trafﬁc)
that can be easily represented by regular and/or irregular
graph structures. Moreover, the discriminative nature of
graphs presents numerous opportunities to exploit the full
potential of relationships between graph parameters and
data. Graph-based anomaly detection advances our clas-
siﬁcation into four categories [5]: Node, Edge, Sub-graph,
and Graph. Referring back to the Smart Surveillance System
Fig. 1, an anomaly in Edge 0 is Node Anomaly, the connec-
tion of Zone 0 and Edge Server 0 is Edge Anomaly, Zone 0
itself is Sub-graph Anomaly, and ﬁnally, the problem in the
whole system is a Graph Anomaly.

(cid:52)

(cid:52)

(cid:52)

(cid:52)

(cid:52)

(cid:52)

(cid:52)

(cid:52)

A. DANESH PAZHO ET AL.

7

TABLE 3
Summary of Reviewed Approaches and Their Capabilities

Attributed
Graphs
(cid:56)

Dynamic
Graphs
(cid:52)

Learning
Adaptability
S

Scalability

Approach

Federated Learning

Autoencoders

Model

DIoT [112]

VFL [113]

[114]

[115]

[116]

Robust Deep Autoencoder (RDA)
[117]
Iterative Training Set Reﬁnement
(ITSR) [118]

[119]

DONE [120]

AdONE [120]

DeepSphere [121]

Graph Embedding

Shallow Encoders

Deep Encoders

DeepWalk [122]

Node2Vec [123]

LINE [124]

TADW [125]

NetWalk [126]

Graph Deviation
Network (GDN) [98]
AddGraph [127]

Graph Transformers

Graph Signal Processing

Graph Contrastive Learning

[128]

TADDY [129]

GTA [130]

[131]

GCCAD [132]

CoLA [90]

(cid:56)

(cid:56)

(cid:56)

(cid:56)

(cid:56)

(cid:56)

(cid:52)

(cid:52)

(cid:52)

(cid:56)

(cid:56)

(cid:56)

(cid:56)

(cid:56)

(cid:56)

(cid:52)

(cid:52)

(cid:56)

(cid:56)

(cid:56)

(cid:52)

(cid:52)

(cid:52)

(cid:52)

(cid:56)

(cid:56)

(cid:56)

(cid:56)

(cid:56)

(cid:52)

(cid:56)

(cid:56)

(cid:52)

(cid:56)

(cid:56)

(cid:56)

(cid:56)

(cid:52)

(cid:56)

(cid:52)

(cid:52)

(cid:52)

(cid:52)

(cid:52)

(cid:52)

(cid:52)

U

U

U

U

U

U

U

U

U

U

U, O

SM

-

-

U, O

U

SM

S

U

U

U

U, SF

SF

SF
S: Supervised Learning, SM: Semi-supervised Learning, U: Unsupervised Learning, SF: Self-supervised Learning, O: Online Learning

SL-GAD [133]

(cid:52)

(cid:52)

Furthermore, graphs lead to the advantage of better
visualization. Visualization is concerned with the visual rep-
resentation of graphs that reveals structures and anomalies
that may be present in the relational data and help the user
to understand the graphs and the nature of anomalies.

In the next section, we discuss how we can utilize graphs

greatly reduces communication overhead [139]. FL employs
collaborative and experiential learning by training without
the need to transfer data over to a centralized location. This
feature has recently led to a rise in the applicability of FL
in a variety of applications, ranging from medical to IoT,
transportation, defense, and mobile apps.

for anomaly detection in detail.

5 GRAPH-BASED ALGORITHMS FOR ANOMALY
DETECTION

In this section, we aim to introduce and compare tech-
niques that combined with graphs have a great potential for
solving the problem of anomaly detection in heterogeneous
distributed systems. The summary of all reviewed works
and their capabilities such as whether they can be used for
dynamic or attributed graphs or not can be seen in Table 3.

5.1 Federated Learning (FL)

Federated Learning is a state-of-the-art technology that has
recently emerged as an alternative to centralized systems.
It focuses on collaboration while preserving the security
aspect of client data information used for training machine
learning algorithms [134], [135], [136], [137], [138]. It also

Anomaly detection and prediction of static and dynamic
time series data have been a popular topic, especially for
IoT-based data [140], [141], [142]. These approaches look at
multi-sensor systems as a collection of centralized sensors
where abnormal sensor behavior is detected by a central
model that runs on the server. Such systems are prone to
failures, require longer access times, and are vulnerable to
malicious invasion attacks leading to a potential data breach
from clients to the server [143]. [144] looks at the data
collected by IoT sensors for energy-efﬁcient applications like
HVAC in smart buildings and proposes a federated stacked
Long Short-time Memory model (LSTM) on time series data
generated by IoT sensors for classiﬁcation and regression
tasks. [112], on the other hand, proposes a self-learning
distributed system for security monitoring.

While such approaches deal with the heterogeneity (con-
cerns data, privacy, and task requirements ) and Autonomy

A. DANESH PAZHO ET AL.

8

Fig. 3. Federated learning for anomaly detection applied on two distributed clusters viz. LAN and Sensor. Here N is the number of clusters connected
to the Federated cloud server. Each network has its own testing and training dataset, local storage and loss function. The server receives individual
weights from all the networks local models and then aggregates them based on their useable graph attributes while sending back the global weights.

(concerns association and communication requirements) na-
ture of systems, they fall short of the beneﬁts of graph-based
relational learning. Federated Graph Learning is a fairly
recent topic. [145] introduces Federated Graph Learning
(FGL) as a seminal paper discussing the deﬁnition and chal-
lenges of FGL. It further categorizes FGL into four distinct
learning types. Graph edges and nodes in each sub-graph
heavily overlap each other and therefore play a pivotal
role in extracting the features and adding to contextual
and relational learning beneﬁts. A sub-classiﬁcation of this
work was introduced in [113] as a complete methodology to
apply the Vertical Federated Learning [VFL] algorithm for
graph convolutional networks. The approach, along with
Homomorphic Encryption (HE), was developed to ensure
privacy while maintaining accuracy.

A general structure of a complex distributed system can
be easily depicted using the Federated Learning framework
(Fig 3). Here we show two different network clusters that
have heterogeneous nature of data as well as systems.
In this framework, the models are trained at the device
level or client-side, where they are brought over to the
data sources or devices for training and prediction. The
updated values are sent back to the federated cloud server
for aggregation. One consolidated model gets transferred
back to the devices to enable tracking and redistribution of
each model to various devices. During the training phase,
the input is reconstructed in the output until reconstruction
error is minimized, which calculates the threshold value.
This threshold value decides whether the observed patterns
are anomalous or not.

Table 3 summarizes the strong points and weaknesses
of two discussed works DIoT [112] and VFL [113]. Both of
these works are unable to process the additional information
provided by attributed graphs which in real-world scenarios
are common. It should be mentioned that for supervised
models such as DIot [112] a crucial requirement is available
labeled data that is hard to provide. Based on mentioned
shortcomings, although FGL addresses data diversity, data
security and real-time continues learning it is not mature
enough yet for real-world applications.

5.2 Autoencoders

Autoencoders are typically made of two main modules;
encoders and decoders. The encoder part is responsible for
mapping the input space to a bottleneck latent space, and
the decoder reconstructs the original input based on the
latent representation. In order to ﬁnd the best possible la-
tent representation, they try to minimize the reconstruction
error of the original input. Thus, the network will learn to
preserve the most informative parts of the input features
in the latent representation. They were traditionally used
for dimension reduction prior to feeding the data to the
main network, but nowadays, they have vast applications
in information retrieval, image processing, and anomaly
detection.

In the context of anomaly detection, autoencoders can be
used as a tool for calculating anomaly scores. After training
the autoencoder with data that does not contain anomalous
points, if any outlier data points are fed to the network,
it will perform poorly. The reconstruction loss of that data
point will be larger compared to normal ones since the
network is not familiar with this type of data. As a result, the
reconstruction error can be used as a measure of deviation
from normal data points. This approach has been used for
detecting anomalies in high-performance computing sys-
tems [114] and has shown promising results. Convolutional
Autoencoders can improve the parameter efﬁciency and
training time since they have shared parameters. Works
such as [115], [116] have made use of convolutional au-
toencoders for anomaly detection and achieved signiﬁcant
improvements. DeepSphere [121] proposed a method for
detecting anomalous snapshots in a dynamic network. This
work adopts a LSTM autoencoder with an attention mech-
anism. In the constructed hidden space, DeepSphere [121]
learns a spherically shaped boundary around the encoded
normal representations. As a result, the encoded representa-
tion of an unseen anomalous snapshot of the network will
fall outside the hyper-sphere and is detected as an anomaly.
All the aforementioned methods are developed based on
the hypothesis that clean data (data that does not contain

Send global gradient & update modelSend encrypted local gradient and lossLAN clusterSensor clusterSend encrypted local gradient and lossSend global gradient & update modelLocal Storage 1Train private dataInput sequencesTesting dataFederated cloud serverWeight aggregationAnomaly Detection (AD)ADLocal Storage NTrain private dataInput sequencesTesting dataLearn sequencesThreshold functionIdentify patternsNormalAnomalyA. DANESH PAZHO ET AL.

9

Fig. 4. Graph autoencoder network for anomaly detection in the LAN Cluster example introduced in Section 2.3. Two malicious users (equal to
anomalous nodes in network graph) have connected to the network. The network graph is fed to the autoencoder and the reconstruction loss for
nodes and edges will be calculated. In this simple case, just by comparing the reconstruction loss to a constant threshold, the anomalies can be
detected, but this processes can be more advanced and precise.

anomalous points) is available for training, but in many
real-world cases, we do not have enough data points that
satisfy these constrain. Thus, the reconstruction error for
anomalous points will be lower, and the accuracy of ﬁnding
outliers will degrade. To solve this issue, Robust Deep Au-
toencoder (RDA) [117] inspired by Robust Principal Com-
ponent Analysis [146], [147], [148] uses a ﬁlter layer that
separates anomalous data points of input data. By removing
these noisy and anomalous data points, the network will be
able to better reconstruct the normal data points. On top of
RDA [117], they add an anomaly detection algorithm to test
the effectiveness of the proposed method. Iterative Training
Set Reﬁnement (ITSR) [118] adapts adversarial autoencoder
network [149] architecture to add a prior distribution to
constructed latent representation and places anomalies to
the regions with lower likelihood. By this means, the model
will be robust against noises and anomalies in the training
data. DONE [120] is another network proposed for detecting
anomalous nodes in attributed graphs. DONE makes use of
two parallel autoencoders; one for encoding link structure
and another one for attributes of nodes. These autoencoders
are trained to preserve proximity and homophily in the net-
work. The proposed loss function is designed to minimize
the contribution of outliers, and by minimizing the loss
equation, the anomaly scores for each node are calculated.
Finally, the top k nodes are reported as anomalous points.
They also propose AdONE [120] that makes use of adver-
sarial learning to be able to construct an outlier resistant
network embedding.

Traditional autoencoder networks and convolutional au-
toencoders are limited to a ﬁxed input length which makes
them unsuitable for detecting anomalies in dynamic net-
works. Also, they are limited to Euclidean data; thus, they
are unable to model complex relationships that may occur
in a dynamic heterogeneous network. Graph Neural Net-
works (GNN) can overcome these issues and generalize
the network. They can also incorporate multi-dimensional
edge and node attributes. Convolutional graph autoen-
coders have been used in [119] for detecting anomalies. This
model uses both node features and edge features. Also, the
decoder module has two separate branches for node recon-
struction and edge reconstruction. The ﬁnal reconstruction
loss is the combination of edge reconstruction loss and node
reconstruction loss and is used as a measure for ﬁnding
anomalies.

Fig 4 shows the workﬂow for detecting anomalies using

autoencoder networks in the LAN Cluster example men-
tioned in Section 2.3 . In the case of anomaly detection in a
complex heterogeneous system, such as the three conceptual
models that we introduced earlier, after training the model
with normal data, the graph of the network is fed to the
encoder module to be transformed into the latent space.
In this case, since we are dealing with a heterogeneous
network, the encoder and decoder modules should be able
to incorporate the edge and node information and aggregate
them to get the most of the available information. Also, at
any time, the graph of the network can change. Thus, it is
vital to employ a network architecture that can handle dy-
namic graphs, such as Graph Neural Networks. The decoder
will try to reconstruct the original graph of the network from
the latent representation. Anomalous edges, nodes, or sub-
graphs of the network will have a high reconstruction error.
In the most basic approach, only a ﬁxed threshold can be
used to decide whether the edge, node, or sub-graph should
be considered anomalous or not.

For more clear scrutiny, Table 3 shows the different
features of reviewed works. As mentioned before, one im-
portant characteristics of autoencoder structure is that it is
trained in an unsupervised manner that directly solves the
problem of availability of labeled data. Also, the changing
nature of anomalies will not be a problem in these types
of models since they will learn normal behaviour of the
system and anything different from that will be counted as
an outlier.

5.3 Graph Embedding

The ﬁrst obstacle that we face in many tasks like anomaly
detection in large networks is ﬁnding a way to map the data
hidden in the network graph into a low-dimensional space.
To do so, there are many different approaches. In general,
we can separate these methods into two different classes.
The ﬁrst type of encoders is “Shallow Encoders” which will
transform each node of a graph to exactly one vector in the
latent space. On the other hand, there are methods called
“Deep Encoders” which get the use of more complicated
networks and are able to generate more complex embedding
compared to “Shallow Encoders.” In the following, we will
see details of each of these methods and their strengths and
weaknesses. After obtaining the latent representations, an
anomaly detection algorithm can be used on top of the em-
bedding network in order to detect outliers and anomalies.

Reconstruction Loss CalculationAnomalous DatapointNormal DatapointEncoderEncoderDecoderDecoder13.6558.438.7211.9646.2175.36Loss < ThresholdLoss ≥ Threshold......A. DANESH PAZHO ET AL.

10

Fig. 5. This ﬁgure shows AddGraph model applied to the LAN Cluster conceptual use-case discussed in 2.3. In the ﬁrst step, Graph Convolutional
Network (GCN) takes the graph snapshot at time step t and combines it with the hidden state of the previous time step to construct the node
embedding. GRU and attention module combine the long term and short term states to generate the current hidden state. At the last step, the
scoring function assigns an anomaly score to edges based on the nodes connected to them.

5.3.1 Shallow Embedding

Shallow Embedding methods try to ﬁnd a unique latent rep-
resentation for each vertex of a graph. The main difference
between different approaches to shallow embedding is in
the deﬁnition of similarity function. The similarity function
basically describes how relationships in the latent space
are mapped to the original input space. DeepWalk [122]
is a random walk approach for node embedding that tries
to ﬁnd the best embedding that preserves similarity. Each
random walk is an unbiased sequence of nodes with a ﬁxed
length. Authors claim that random walks can be treated as
sentences of a text since the frequency of occurrence of the
nodes in random walks follows the power law. DeepWalk
[122] tries to ﬁnd the feature representation for each node
such that it maximizes the likelihood of visiting nodes seen
in the random walks starting from that particular node.
Another method to be mentioned is Node2Vec [123]. This
algorithm makes it possible to have more ﬂexible random
walks in order to obtain richer latent representations. It
combines breath-ﬁrst sampling and depth-ﬁrst sampling
together to introduce a ﬂexible biased sampling strategy that
allows local and global views of the network.

Similar approaches such as LINE [124], and TADW [125]
have been proposed. One might think of these algorithms as
ﬁnding a simple look-up table for assigning each node in the
original graph to a latent representation. As a result, these
kinds of methods have limitations when we want to apply
them to large heterogeneous networks. The ﬁrst limitation
comes from the fact that each node has to have its own
unique embedding and there are no shared parameters in
these kinds of networks. As a result, when the number of
nodes grows, the number of parameters will grow respec-
tively, and we will need V×D number of parameters where
D is the dimension of latent space. Also, they are unable
to generalize to unseen nodes, and we cannot use them
in dynamic networks. NetWalk [126] solves the problem

with the changing networks and dynamically updates the
representations as the network evolves. This model tries to
satisfy two constraints: clique constraints which minimize
the pairwise distances between representations of vertices
in each random walk to preserve locality and autoencoder
constrain, which serves as a global constrain and minimizes
the reconstruction error of input using the output embed-
ding. Still, there are more issues with these types of graph
embedding algorithms; another problem is that in complex
heterogeneous systems, each node may have its own speciﬁc
features, but “Shallow Encoders” are unable to make use of
these node-speciﬁc features.

5.3.2 Deep Embedding
Most of the methods that we have discussed until now are
not capable of modeling more complicated dependencies
such as complex inter-sensor relationships, but ”Deep En-
coders” have more capacity and are able to build richer
latent representations. Graph Deviation Network (GDN)
[98] introduced a structure learning approach in which the
graph edges are initially unknown and have to be learned.
GDN [98] is consist of four important components. The
ﬁrst component is Sensor Embedding which captures the
characteristics of each node or sensor. In the next step,
Graph Structure Learning Learns the complicated relation-
ships between pairs of sensors and models them to the
edges of the graph. After the construction of the graph,
Graph Attention-Based Forecasting predicts the behavior of
sensors in the future time step. Finally, Graph Deviation
Scoring will compare these predictions and the actual values
in each time step and identify anomaly points that deviate
from expected values. AddGraph [127] is able to aggregate
more information such as structural, temporal, and content
features to be able to build a more powerful embedding for
anomaly detection in dynamic graphs. This model makes
use of a graph convolutional neural network (GCN) for
capturing structural and content features. By adding Gated

SnapshotsLocal Area NetworkNetwork GraphHt-1Ht-2Ht-3Ht-4Hidden Statesω Attention ModuleGCNNode EmbeddingGated Recurrent UnitCurrent Hidden State (Ht)Score Function[0.1, 0.9, …, 0.2, 0.8, 0.3]Anomaly ScoresTimeA. DANESH PAZHO ET AL.

11

Fig. 6. The ﬁgure shows the frame work of TADDY [129]. (A) shows the edge-based substructure sampling module which chooses subgraphs
based on the target edge. (B) is the spatial-temporal node encoding module which is responsible for encoding nodes and capturing the global,
local, and temporal information hidden in the subgraphs using diffusion-based spatial encoding, distance-based spatial encoding, and relative
temporal encoding respectively. The ﬁnal node encoding are built by combining all previously mentioned encoding. (C) shows the dynamic graph
transformer module. This module constructs the edge embedding using a modiﬁed multi-headed attention network. Finally, in (D) you can see the
discriminative anomaly detector which is trained using samples and pseudo labels generated by negative sampling strategy.

Recurrent Units (GRU) with attention modules, AddGraph
[127] makes it possible to combine the long-term and short-
term states of each node. Finally, based on the representation
that contains structural, temporal, and content features,
AddGraph [127] computes the anomalous score for edges
using a single layer network.

Smart Video Surveillance System (Section 2.1), Sensor
Network (Section 2.2), and LAN Network (Section 2.3) all
contain many nodes. As a result, Shallow embedding tech-
niques are not adequate for modeling these kinds of net-
works. We should also consider that all of these three con-
ceptual use-cases are also dynamic (as an example adding a
new camera to the Smart Video Surveillance System changes
the graph of the network); thus, methods like DeepWalk
[122], and Node2Vec [123] are not suitable since they are
unable to generalize to unseen nodes. Another important
issue is that nodes and edges can have features with differ-
ent schemes that are useful for anomaly detection. Consider
the Sensor Network; in each time step, a huge amount of
data is being generated by a large number of interconnected
sensors. The data from each sensor can be related to other
sensors with a complex non-linear relationship. Shallow
embedding techniques fail to take advantage of this kind of
information. Thus, Deep Embedding methods that are more
complicated such as GDN [98], and AddGraph [127] can
be helpful in this case. Based on what we discussed, let’s
use one of the introduced examples discussed in Section
2 for better understanding. In the LAN Cluster example,
AddGraph seems to be a suitable choice.

Fig 5 shows the structure of AddGraph which is applied
to the LAN Cluster example. Previous hidden states and
current snapshot of the network graph is used for con-
structing the node embedding. Also, an attention module
and GRU combine the long-term and short term states
to generate the current hidden state. In the ﬁnal step a
scoring function is responsible to assign normality score

to the current hidden state. The main points of discussed
techniques are available in Table 3.

5.4 Graph Transformers

The concept of attention mechanism introduced by [150]
was ﬁrstly used for natural language processing. This mech-
anism aims to do one-step prediction instead of recurrent
processing of the data. By this means, the attention mech-
anism reduces the path length of the computation, which
means reducing the information loss and focusing on the
most important features for predicting the output. Adapting
this technique to graphs can improve the outcome in many
applications, such as anomaly detection. Graph transformer
networks are able to automatically generate meta-paths by
learning and solving the aforementioned problem enabling
many applications such as anomaly detection to work on
complex heterogeneous systems [151]. In [128], the model
takes advantage of relational graph transformers for ﬁnding
anomalous nodes in a supervised manner. In this work,
ﬁrst, the heterogeneous graph of the network is extracted,
and relational graph transformers and a semantic attention
network are used for modeling the complex relationships
between the nodes and encoding them, and then classifying
them for ﬁnding anomalous nodes.

Supervised learning is not possible in many applications
due to the lack of labeled data. Using an unsupervised
setting, the transformer-based Anomaly Detection frame-
work for Dynamic graphs (TADDY) [129] detects anomalous
edges in dynamic graphs. TADDY [129] consists of four
main modules as shown in Fig. 6. Edge-based substructure
sampling captures spatial-temporal context of each target
edge using graph diffusion method [152], [153]. For each
edge, this module constructs a ﬁxed-length importance-
aware set of neighboring nodes. Then, TADDY [129] lever-
ages a novel spatial-temporal node encoding for generating

t-2t-2t-2t-2t-2tttttDiffusion-based Spatial EncodingDBS EncodingRelative Temporal EncodingNode Encoding++=Node EmbeddingMean PoolingTransformer ModuleMulti-headed AttentionMulti-headed AttentionTransformer ModuleMulti-headed AttentionNode EncodingNode EncodingEdge EmbeddingPositive Edge EmbeddingNegative Edge EmbeddingNegative SamplingFully Connected LayerScoring ModuleAnomaly ScorePseudo LabelBCE LOSS0.890.890.230.230011(A)(B)(C)(D)Multi-headed AttentionA. DANESH PAZHO ET AL.

12

Fig. 7. A small part of the Sensor Network introduced in Section 2.2 is used to show Graph Signal Processing for anomaly detection. A 3-stage
process that begins with Graph construction from 3 adjacency matrices to generate an undirected, weighted and connected graph G(N,E,W).
Filtering and Optimization methods are next used to get the cut-off frequency of the GSP ﬁlter that is further projected as a normal and an
anomalous subspace. Both these values in addition to a thresholding function are used to generate the anomaly scores.

node embedding. After acquiring the embedding from the
previous step, a transformer network is used as an encoder
to capture spatial and temporal features, followed by a
pooling module for aggregating the embedding of all nodes
in the same neighboring set. At the ﬁnal step, discriminative
anomaly detector (which consists of a fully connected layer).
Graph Learning with Transformer for Anomaly detec-
tion (GTA) [88], leverages a modiﬁed transformer network.
This model detects anomalies on multivariate time series
generated from different sensors. These sensors can be re-
lated to each other in complicated unknown connections.
GTA [88] ﬁrst learns the dependencies using Gumbel-
Softmax Sampling [154] strategy. Once this topological
structure is established, a graph convolution block updates
each node representation by aggregating neighbors’ infor-
mation and message passing to enrich the representations.
Now, dilated convolution [130] is used for extracting tempo-
ral context, but with one novel modiﬁcation. They have used
a hierarchical scheme to make GTA [88] capable of capturing
temporal patterns with different lengths. On top of these,
a more sophisticated and efﬁcient version of transformers
is introduced. Multi-branch attention module that is used
in GTA [130] extracts long-distance temporal dependencies
and neighboring nodes’ information. In the anomaly scoring
module, the original input time series are divided into
training sequences (for the encoder) and label sequences
(for the decoder). The decoder predicts the behavior of time
series in the target section, and by comparing the predicted
output and the actual values, outliers can be detected

Capabilities of all mentioned models are mentioned in
Table 3. Unfortunately none of the anomaly detection mod-
els using graph transformers are compatible with attributed
graphs which makes them less practical in real applications.
Future research can move in the direction of solving this
issue to overcome the complex nature of heterogeneous
distributed systems.

5.5 Graph Signal Processing

Graph Signal Processing (GSP) is another technique that uti-
lizes classical signal processing tools like Fourier transform,
ﬁltering, frequency response etc., to process data deﬁned on
both regular and irregular graph networks. [155] presents
the recent advances in the currently developing GSP tools.

Further, the emphasis is made on graph datasets arising
from data science, biological, and sensor networks that
can be indexed by nodes of graph signals connected via
weighted edges. Graph signals can be ﬁltered and sampled
to apply low-level processing techniques such as denoising
and compression. One of the major differences between
GSP and traditional Machine learning algorithms is that
ML typically considers a graph as a discrete version of a
complex network. However, this assumption falls ﬂat for
many real-world applications associated with graphs, GSP,
on the other hand, look at existing problems from different
perspectives. As an example, deﬁning a graph for sensor-
based networks involves choosing edge weights as a de-
creasing function of the distance between nodes represented
by sensors. Observations from similar nodes can lead to a
smooth graph function that can detect outliers or abnormal
values through high pass ﬁltering or thresholding [156].
Moreover, a sparse set of sensor readings can also be used
to build signal reconstruction methods that can be used to
save on resources in sensor networks [157], [158].

Anomaly detection with GSP ﬁltering on Wireless Sensor
Networks (WSNs) has been a topic of interest in several
works. [131] captures proximity information such as data
between sensors to capture local anomalous behavior. They
present three graph designs and use GSP ﬁltering to ﬁnd
the cut-off frequency, Lambda for the ﬁlters. This is used
to separate normal and anomalous sub-spaces for unsuper-
vised detection. The anomalous space projections are ﬁnally
utilized to generate anomaly scores as shown in Fig. 7. The
main advantage of such a system is that in addition to raw
sensor data, relational characteristics between the nodes,
like proximity information between sensors and their envi-
ronment, can be effectively captured. Graph-based ﬁltering
is found to be particularly useful for both regular and irreg-
ular graph structures for unsupervised anomaly detection.
In Table 3, speciﬁcation of the reviewed model is available.
The ability of working on dynamic attributed graphs makes
[131] aligned with the real-world requirements. On the other
hand, leveraging GSP techniques can add deeper perspec-
tives to anomaly detection problem and equip it with more
relational information helpful for detecting outliers which is
essential real-world domain.

High Pass FilterLow Pass FilterWb(∆c, ∆d)Wd(θd)Wc(θc)Normal subspace, ‘On’Anomalous subspace, ‘Oa’Thresholding functionAnomaly ScoreGraph based Filtering & OptimizationGraph ConstructionSubspace projection & Thresholding Anomaly scores Sensor Network exampleG( Ɲ ,E,W)A. DANESH PAZHO ET AL.

13

Fig. 8. In this ﬁgure we have applied the SL-GAD [133] frame work to the LAN conceptual use-case discussed in Section 2.3. (A) shows the Graph
view sampling module which chooses the target node and samples two subgraphs. (B) is the generative and contrastive discrimination modules.
First, the target node and the two subgraphs are fed to the GNN encoder and graph embedding is created. In the next step, two different objectives,
the discriminator and regressor try to capture anomalies in the graph structure and attributes. The generative regression module is designed for
capturing anomalies in the attributes of each node, while the discriminator module is responsible for ﬁnding anomalies in the structure of the graph.
Finally, in (C) the contrastive scores and the generative scores are combined to calculate the ﬁnal anomaly score.

5.6 Graph Contrastive Learning

In graph contrastive learning techniques, the objective is
to construct a representation by contrasting pairs of data
points. The loss function is designed in such a way that
by optimizing it, the positive pairs (matching pairs) of data
points are brought together, and the negative pairs will be
separated. As a result, using this approach, the model is able
to learn higher-level representations that are more powerful
and distinguishable. In the context of anomaly detection,
contrastive learning can be helpful since it is designed to
provide a measure of similarity between data pairs. The
main idea in GCCAD [132] is to detect anomalies using their
distance from average normal points or global context. The
key concept is that the outliers will have different features
than most points; thus, by contrasting each node with
the global context, we can deﬁne a measure for detecting
anomalies.

GCCAD [132] has shown that the node embedding
made by traditional GNN encoders is not able to discern
anomalous nodes properly. However, GCCAD [132] is able
to construct a more powerful embedding that highlights
the differences between anomalous nodes and the global
context. This work uses a context-aware loss function in a
supervised manner. The loss function is optimized in the
GNN encoder that consists of three modules; edge update,
node update, and graph update module. The edge update
module is responsible for calculating the likelihood of being
a suspicious edge (an edge that connects a normal node to
an anomalous one) and removing it, and updating the ad-
jacency matrix. These modules are designed to conserve the
homophily assumption between neighboring nodes. This
assumption suggests that the neighboring nodes have the
same labels. Still, homophily is violated in the case of a con-

nection between a normal node and an anomalous one, and
this violation has not been considered in traditional GNN
networks. In the next step, the node embedding is updated
using message passings by the node update module. Lastly,
the graph update module updates the global context. The
updated global context is the weighted aggregation of all
the nodes. The authors also introduced a self-supervised
version of this network named GCCAD-pre [132].

CoLA [90] focuses on anomaly detection in large-scale
attributed graphs, which is applicable to real-world prob-
lems. This novel network has three main components: pair
sampling, a GNN-based contrastive learning model, and the
score computation module. The instance pair sampling is
designed to generate the pairs of data for the training phase.
In contrast with GCCAD [132] that contrast nodes with the
global context, the deﬁnition of pairs in CoLA [90] focuses
on the relationship between a node and its neighbors. Hence
the strategy for deﬁning the pairs is ”target node versus
local subgraph”. The GNN-based contrastive learning mod-
ule consists of three sub-modules: (1) GNN model, (2) read-
out module, and (3) discriminator module. After acquiring
the pairs, the GNN module will extract embedding for
the target node and the local subgraph. Then the readout
module uses the average pooling function to create a vector
of embedding of all nodes in the embedded subgraph. In
the discriminator module, the positive and negative pairs
are contrasted, and a score is generated. Finally, The score
computation module measures the anomaly score for all
nodes, and anomalous nodes can be picked by choosing the
nodes with the highest scores. SL-GAD [133], introduced a
novel generative and contrastive self-supervised model.

SL-GAD [133] is made of three major components sim-
ilar to CoLA [90]; graph view sampling, contrastive self-

GNN EncoderGNN DecoderDiscriminatorDiscriminator(-)ReadoutReadout(+)(+)(-)Contrastive ScoresGNN DecoderRegressorRegressorGenerative ScoresGenerative Scores++Generative Anomaly ScoresGenerative Anomaly ScoresContrastive Anomaly ScoresContrastive Anomaly Scores0.230.410.860.32...0.110.39Final Anomaly Scores0.230.410.860.32...0.110.39Final Anomaly Scores+Generative Anomaly ScoresContrastive Anomaly Scores0.230.410.860.32...0.110.39Final Anomaly ScoresSamplingSubgraph 2Subgraph 2Subgraph 1Subgraph 1TargetNodeNetwork GraphTargetNodeNetwork GraphOriginal NetworkOriginal Network(A)(B)(C)A. DANESH PAZHO ET AL.

14

TABLE 4
Time complexity of reviewed algorithms. For symbol descriptions please refer to table 5.

Time Complexity

Description

Approach

Federated Leraning

Auto Encoders

Model

DIoT [112]

VFL [113]

[114]

[115]

[116]

RDA [117]

ITSR [118]

[119]

DONE [120]

AdOne [120]

DeepSphere [121]

Graph Embedding

Shallow Encoders

Deep Walk [122]

Node2Vec [123]

LINE [124]

TADW [125]

NetWalk [126]

Graph Transformers

Graph Signal Processing

Graph Contrastive Learning

Deep Encoders

GDN [98]

AddGraph [127]

[128]

TADDY [129]

GTA [130]

O(4τ D2 + 2τ 2D)

[131]

GCCAD [132]

CoLA [90]

SL-GAD [133]

-

O(m)
O(kn ˆR(η + c))

O(Rnk(η + K))

-
O (cid:0)nm2(cid:1)

-

-

-

-

-

-

O(N d)

O(N d)

-

-

l
O(
s(l−s) )
O(mˆn ˆd)

-

O(nl|Ω|)

O(md)

O(cd)

-

-
-
O (cid:0)τ kmI + T ˜n2(cid:1)

-

-

-

-

-

-

-

-

-

-

-

-

Per sample complexity

-

-

The complexity of walk generation

The complexity of edge encoding

The complexity of anomaly detection on
incoming data points

-

-
-

-

This is for the simplest attention
module. More complex ones are
available in the original paper.

-

-

-

supervised learning, and graph anomaly scoring. In the
graph view sampling, for each target node, two local sub-
graphs are extracted. Next, in the contrastive self-supervised
learning module, a GNN constructs the latent representation
of the samples. In addition to contrastive scores, SL-GAD
[133] also leverages a graph autoencoder network for recon-
structing the feature vector of the target node in order to
fully utilize contextual information of target nodes. Finally,
graph anomaly scoring predicts the ﬁnal scores based on
both generative scores (from the graph autoencoder) and
contrastive scores (from contrastive learning).

Fig. 8 shows the work ﬂow of the Sl-GAD [133] applied
to the LAN Cluster example introduced in Section 2.3. The
sampled subgraphs are fed to the GNN Encoder and the
encoded representations are fed to two different branches,
the discriminative and the generative modules. at the ﬁnal
step, anomaly scores from these two branches are combined
to construct the ﬁnal anomaly score.

show promising results and are extremely adaptable to real-
world scenarios. The discussed works are all able to over-
come the dynamic complex nature of distributed heteroge-
neous systems and unsupervised/self-supervised learning
adaptability of these models can alleviate the problem of
available labelled data mentioned in Section 3.

6 EVALUATION, COMPARISON AND DISCUSSION
In this section, ﬁrst, we discuss the metrics that are available
for evaluation and then we try to compare the methods
discussed in Section 5 from an algorithmic perspective.
Then we discuss the requirements and challenges that uti-
lizing graphs adds to previously mentioned requirements
discussed in Section3, and ﬁnally, we discuss the future
directions that research in this ﬁeld can take.

6.1 Metrics and Comparison

Characteristics of all mentioned model can be seen in Ta-
ble 3. As discussed, Graph Contrastive Learning approaches

The performance and viability of any anomaly detection
algorithm, graph-based or non-graph-based, can be eval-

A. DANESH PAZHO ET AL.

15

TABLE 5
Table 4 symbol description.

Parameter

Description

n

˜n

m

k

T

τ

ˆn

l

|Ω|

s

D

d
ˆd

c

R

I
ˆR

number of nodes in the graph

average number of nodes in a timestamp

number of edges in the graph

number of nodes in a subgraphs

number of timestamps

size of the time window

number of negarive samples

length of a walk

number of walks

number of samples

number of input dimension

latent dimension of node representation

degree of a node

number of clusters

number of evaluation rounds

number of iterations

number of sampling rounds for each node

uated by Precision, Recall, Accuracy, Receiver Operating
Characteristic (ROC) curve, and Area Under the ROC Curve
(AUC). While Precision, Recall, and Accuracy are a measure
of the true positives, false positives, true negatives, and
false negatives, AUC, on the other hand, summarizes the
information contained in the ROC curve. Larger AUC val-
ues indicate better performance at distinguishing between
anomalous and normal observations.

A major challenge while reporting the above-mentioned
metrics is the absence of uniﬁed evaluation criteria amongst
the diversity of algorithms, the application type, and the
heterogeneous nature of data and devices involved. As an
example, if we want to compare the latency of the two
algorithms, we have to make sure that they are both tested
on particular hardware, they are getting tested on a speciﬁc
job, and we have to eliminate different variables that have
an effect on that metric.

In contrast, Time Complexity is The only metric that can
give us some insight into the algorithm’s performance. Table
4 shows the time complexity of reviewed algorithms. In
order to assess how well an algorithm performs compared to
other algorithms, and also with respect to points in Section
3, we can refer to Time Complexity. It gives us a good
understanding of how fast and efﬁcient the method is, a
general idea of the algorithm’s complexity, and whether it is
suitable for speciﬁc tasks or hardware based on the power
it needs.

6.2 Graph-speciﬁc Challenges

Graphs add an enormous number of beneﬁts to our sys-
tems. They are extremely powerful for catching relational
information, especially in distributed heterogeneous sys-
tems. They help with addressing challenges and meeting the
requirements discussed in Section 3, as well as capturing im-
portant features of the data like relational features and infor-

mation. However, there is a cost to all these beneﬁts. While
utilizing graphs these challenges should be addressed:

Types of Graphs: Each system can be represented by a
speciﬁc type of graph. Each type of graph has its features
and is suitable for a group of domains. For example, at-
tributed graphs add more complexity by introducing the
features of the connection between the nodes, and the fea-
tures of the nodes themselves. Also, a graph representing
a system might be dynamic or static, depending on the
nature of the original system. All these sub-classes of graphs
add to the complexity of graph-based learning techniques.
Subsequently, the introduced models should be able to
handle these diverse types of network graphs, but as we
discussed in previous sections, many of the models can
just work on plain static graphs which is not satisfactory
in many applications. [159], [160], [161], [162], [163], [164]

Graph Anomalies: By introducing graphs, we get a
better representation of a system. Graphs and Graph Neu-
ral Networks make us capable of modeling complicated
dependencies in real networks. But if we look at it from
another perspective, this adaptation of graph representation
introduces different places for anomalies to take place. In
graphs, outliers can occur in nodes, edges, subgraphs, and
even the whole graph. But models are usually only able to
detect one kind of foresaid anomalies, and there is no unique
framework to address them all together. This means that the
approaches must speciﬁcally determine what is the objective
of their detection, which types they handle, and where they
show the best performance. [95], [165], [166]

6.3 Future Research Directions

Graph-based anomaly detection is a relatively new topic
with many opportunities drawing a fair amount of atten-
tion. Here we discuss a few excellent opportunities and
novel directions that can be the subject of future research
independently or in conjunction.

The most important research direction at the moment
seems to be ﬁnding a means of quantifying the results of
anomaly detection algorithms in a uniﬁed manner, thereby
enabling comparison in various domains and ﬁelds. A great
share of all the advancements in technology originates from
quantifying and comparing new ﬁndings with already ex-
isting works. However, considering the variety in this ﬁeld,
comparing algorithms to each other is nearly impossible.
First, the best metric for evaluating a model must be iden-
tiﬁed. Alongside that, an evaluation mechanism, general
enough to be applicable to disparate anomaly detection
algorithms are also needed. As an example, in computer vi-
sion, COCO [167] provides such an environment for emerg-
ing algorithms. A framework of testing can also be another
fruitful tool. In this direction, creating a simulator, or a
system that can serve as a toy sample of a large distributed
system can be beneﬁcial as well. To recapitulate, there is
a need for a uniﬁed evaluation of graph-based and non-
graph-based anomaly detection algorithms and techniques.
As discussed in the Challenges Section, the second-
largest issue in the way of anomaly detection is the lack of
a suitable dataset. Generating or preparing a proper dataset
can be a substantial contribution to the ﬁeld of anomaly
detection. However, in the context of anomaly detection,

A. DANESH PAZHO ET AL.

16

usually, an expert must supervise the process of labeling
and collecting data and this fact makes the generated dataset
prone to human errors. All of these are added to the actual
cost of creating such a dataset. Synthetic datasets are another
option, and creating them can be explored through a whole
line of research.

Numerous methods of anomaly detection are designed
to discover whether an anomaly has happened or not. They
are able to notify a responsible person or group to look
more for further investigation. However, they are not able
to identify what sort of anomaly has occurred. A major
subject for further work and research is the interpretability
of anomalies. Down the road, there is a tendency to distin-
guish between anomalies using the algorithms at hand. For
example, in the Sensor Network mentioned in 2.2 we like
the model to be able to distinguish between a cyber attack
and power shortage and raise the correct alarm. If we go
further than that, the ways that the model can restore the
system or stop the anomaly can be investigated.
7 CONCLUSION
In this survey, we have discussed several state-of-the-art
graph-based approaches for anomaly detection in details.
We introduce three unique conceptual use-cases based on
real-time complex distributed systems. Our work builds on
the existing traditional machine learning and deep learning
paradigms used for anomaly detection and goes on to
introduce four separate categories of graph neural network
algorithms. We further apply our formulated models to each
of the methods and provide a thorough review and summa-
rization of the categories. At last, we comprehensively look
at graph speciﬁc big-data challenges and provide a couple
of future research directions in this ﬁeld.

ACKNOWLEDGMENTS
This work is part of a research collaboration with Siemens
Inc., USA.

REFERENCES

[1]

[2]

[3]

[4]

[5]

[6]

[7]

V. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A
survey,” ACM computing surveys (CSUR), vol. 41, no. 3, pp. 1–58,
2009.
G. Pang, C. Shen, L. Cao, and A. V. D. Hengel, “Deep learning for
anomaly detection: A review,” ACM Computing Surveys (CSUR),
vol. 54, no. 2, pp. 1–38, 2021.
G. Pang, L. Cao, and C. Aggarwal, “Deep learning for
anomaly detection: Challenges, methods, and opportunities,”
in Proceedings of the 14th ACM International Conference on Web
Search and Data Mining, ser. WSDM ’21. New York, NY,
USA: Association for Computing Machinery, 2021, p. 1127–1130.
[Online]. Available: https://doi.org/10.1145/3437963.3441659
T. N. Kipf and M. Welling, “Semi-supervised classiﬁcation with
graph convolutional networks,” in International Conference on
Learning Representations (ICLR), 2017.
X. Ma, J. Wu, S. Xue, J. Yang, C. Zhou, Q. Z. Sheng, H. Xiong,
and L. Akoglu, “A comprehensive survey on graph anomaly
detection with deep learning,” IEEE Transactions on Knowledge
and Data Engineering, 2021.
S. Ahmed, K. Hinkelmann, and F. Corradini, “Combining ma-
chine learning with knowledge engineering to detect fake news
in social networks-a survey,” arXiv preprint arXiv:2201.08032,
2022.
R. A. A. Habeeb, F. Nasaruddin, A. Gani, I. A. T. Hashem,
E. Ahmed, and M. Imran, “Real-time big data processing for
anomaly detection: A survey,” International Journal of Information
Management, vol. 45, pp. 289–307, 2019.

[8]

[9]

S. Thudumu, P. Branch, J. Jin, and J. J. Singh, “A comprehensive
survey of anomaly detection techniques for high dimensional big
data,” Journal of Big Data, vol. 7, no. 1, pp. 1–30, 2020.
R. Chalapathy and S. Chawla, “Deep learning for anomaly detec-
tion: A survey,” arXiv preprint arXiv:1901.03407, 2019.

[10] L. Ruff, J. R. Kauffmann, R. A. Vandermeulen, G. Montavon,
W. Samek, M. Kloft, T. G. Dietterich, and K.-R. M ¨uller, “A unify-
ing review of deep and shallow anomaly detection,” Proceedings
of the IEEE, 2021.

[11] G. Fernandes, J. J. Rodrigues, L. F. Carvalho, J. F. Al-Muhtadi, and
M. L. Proenc¸a, “A comprehensive survey on network anomaly
detection,” Telecommunication Systems, vol. 70, no. 3, pp. 447–489,
2019.

[12] C. Neff, M. Mendieta, S. Mohan, M. Baharani, S. Rogers, and
H. Tabkhi, “Revamp 2 t: real-time edge video analytics for
multicamera privacy-aware pedestrian tracking,” IEEE Internet
of Things Journal, vol. 7, no. 4, pp. 2591–2602, 2019.

[14]

[13] T. J. Williams, “The purdue enterprise reference architecture,”
Comput. Ind., vol. 24, no. 2–3, p. 141–158, sep 1994. [Online].
Available: https://doi.org/10.1016/0166-3615(94)90017-5
I.-Y. Song and Y. Zhu, “Big data and data science: what should
we teach?” Expert Systems, vol. 33, no. 4, pp. 364–373, 2016.
[15] A. Katal, M. Wazid, and R. H. Goudar, “Big data: issues, chal-
lenges, tools and good practices,” in 2013 Sixth international
conference on contemporary computing (IC3).
IEEE, 2013, pp. 404–
409.

[16] K. Shin, B. Hooi, J. Kim, and C. Faloutsos, “D-cube: Dense-
block detection in terabyte-scale tensors,” in Proceedings of the
Tenth ACM International Conference on Web Search and Data
Mining, ser. WSDM ’17. New York, NY, USA: Association for
Computing Machinery, 2017, p. 681–689. [Online]. Available:
https://doi.org/10.1145/3018661.3018676

[18]

[17] E. M. Knorr and R. T. Ng, “Algorithms for mining distance-based
outliers in large datasets,” in Proceedings of the 24rd International
Conference on Very Large Data Bases, ser. VLDB ’98. San Francisco,
CA, USA: Morgan Kaufmann Publishers Inc., 1998, p. 392–403.
S. Ramaswamy, R. Rastogi, and K. Shim, “Efﬁcient algorithms
for mining outliers from large data sets,” in Proceedings of the
2000 ACM SIGMOD International Conference on Management of
Data, ser. SIGMOD ’00. New York, NY, USA: Association for
Computing Machinery, 2000, p. 427–438. [Online]. Available:
https://doi.org/10.1145/342009.335437

[19] F. Angiulli and F. Fassetti, “Very efﬁcient mining of distance-
based outliers,” in Proceedings of the Sixteenth ACM Conference
on Conference
on Information and Knowledge Management,
ser. CIKM ’07. New York, NY, USA: Association for
Computing Machinery, 2007, p. 791–800. [Online]. Available:
https://doi.org/10.1145/1321440.1321550

[20] A. Arning, R. Agrawal, and P. Raghavan, “A linear method
for deviation detection in large databases,” in Proceedings of the
Second International Conference on Knowledge Discovery and Data
Mining, ser. KDD’96. AAAI Press, 1996, p. 164–169.
J. Gama, “A survey on learning from data streams: current
Intelligence, vol. 1,
and future trends,” Progress in Artiﬁcial
no. 1, pp. 45–55, Apr 2012.
[Online]. Available: https:
//doi.org/10.1007/s13748-011-0002-6

[21]

[22] K. W. Pettis, T. A. Bailey, A. K. Jain, and R. C. Dubes, “An intrin-
sic dimensionality estimator from near-neighbor information,”
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.
PAMI-1, no. 1, pp. 25–37, 1979.

[23] Q. Yu, K.-M. Tang, S.-X. Tang, and X. Lv, “Uncertain frequent
itemsets mining algorithm on data streams with constraints,”
in Intelligent Data Engineering and Automated Learning – IDEAL
2016, H. Yin, Y. Gao, B. Li, D. Zhang, M. Yang, Y. Li, F. Klawonn,
and A. J. Tall ´on-Ballesteros, Eds. Cham: Springer International
Publishing, 2016, pp. 192–201.

[24] M. Kontaki, A. Gounaris, A. N. Papadopoulos, K. Tsichlas, and
Y. Manolopoulos, “Continuous monitoring of distance-based out-
liers over data streams,” in 2011 IEEE 27th International Conference
on Data Engineering, 2011, pp. 135–146.

[25] L. Breiman, “Bias, variance, and arcing classiﬁers,” Tech. Rep.
460, Statistics Department, University of California, Berkeley . . . ,
Tech. Rep., 1996.

[26] R. E. Schapire, “The strength of weak learnability,” Machine
Learning, vol. 5, no. 2, pp. 197–227, Jun 1990. [Online]. Available:
https://doi.org/10.1007/BF00116037

A. DANESH PAZHO ET AL.

17

[27] A. Bifet, G. Holmes, B. Pfahringer, R. Kirkby, and R. Gavald`a,
“New ensemble methods
for evolving data streams,” in
Proceedings of the 15th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, ser. KDD ’09. New
York, NY, USA: Association for Computing Machinery, 2009, p.
139–148. [Online]. Available: https://doi.org/10.1145/1557019.
1557041

[28] N. Tatbul, “Streaming data integration: Challenges and opportu-
nities,” in 2010 IEEE 26th International Conference on Data Engi-
neering Workshops (ICDEW 2010), 2010, pp. 155–158.

[29] R. Bellman, Dynamic programming. Chelmsford: Courier Corpo-

ration, 2013.

[30] K. Beyer, J. Goldstein, R. Ramakrishnan, and U. Shaft, “When is
“nearest neighbor” meaningful?” in Database Theory — ICDT’99,
C. Beeri and P. Buneman, Eds.
Berlin, Heidelberg: Springer
Berlin Heidelberg, 1999, pp. 217–235.

[32]

[31] P. Hall, J. Marron, and A. Neeman, “Geometric representation
of high dimension, low sample size data,” Journal of the Royal
Statistical Society Series B, vol. 67, pp. 427–444, 02 2005.
J. Ahn,
J. S. Marron, K. M. Muller, and Y.-Y. Chi, “The
high-dimension, low-sample-size geometric representation holds
under mild conditions,” Biometrika, vol. 94, no. 3, pp. 760–766,
2007. [Online]. Available: http://www.jstor.org/stable/20441411
[33] C. C. Aggarwal, A. Hinneburg, and D. A. Keim, “On the surpris-
ing behavior of distance metrics in high dimensional space,” in
Database Theory — ICDT 2001, J. Van den Bussche and V. Vianu,
Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2001, pp.
420–434.

[34] N. Tomasev, M. Radovanovic, D. Mladenic, and M. Ivanovic,
“The role of hubness in clustering high-dimensional data,” IEEE
Transactions on Knowledge and Data Engineering, vol. 26, no. 3, pp.
739–751, 2014.

[35] M. Radovanovi´c, A. Nanopoulos, and M. Ivanovi´c, “Reverse
nearest neighbors in unsupervised distance-based outlier de-
tection,” IEEE Transactions on Knowledge and Data Engineering,
vol. 27, no. 5, pp. 1369–1382, 2015.
S. Sadik and L. Gruenwald, “Research issues in outlier
detection for data streams,” SIGKDD Explor. Newsl., vol. 15,
no. 1, p. 33–40, Mar. 2014.
[Online]. Available: https:
//doi.org/10.1145/2594473.2594479

[36]

[37] A. Koufakou and M. Georgiopoulos, “A fast outlier detection
strategy for distributed high-dimensional data sets with
mixed attributes,” Data Mining and Knowledge Discovery,
vol. 20, no. 2, pp. 259–289, Mar 2010.
[Online]. Available:
https://doi.org/10.1007/s10618-009-0148-z
J. Fan and Y. Fan, “High dimensional classiﬁcation using features
annealed independence rules,” Annals of statistics, vol. 36,
no. 6, pp. 2605–2637, 2008, 19169416[pmid]. [Online]. Available:
https://pubmed.ncbi.nlm.nih.gov/19169416

[38]

[39] F. Keller, E. Muller, and K. Bohm, “Hics: High contrast subspaces
for density-based outlier ranking,” in 2012 IEEE 28th International
Conference on Data Engineering, 2012, pp. 1037–1048.

[41]

[40] N. G ¨ornitz, M. Kloft, K. Rieck, and U. Brefeld, “Toward super-
vised anomaly detection,” Journal of Artiﬁcial Intelligence Research,
vol. 46, pp. 235–262, 2013.
S. Suthaharan, M. Alzahrani, S. Rajasegarar, C. Leckie, and
M. Palaniswami, “Labelled data collection for anomaly detection
in wireless sensor networks,” in 2010 sixth international conference
on intelligent sensors, sensor networks and information processing.
IEEE, 2010, pp. 269–274.

[42] M. Luo, K. Wang, Z. Cai, A. Liu, Y. Li, and C. F. Cheang, “Using
imbalanced triangle synthetic data for machine learning anomaly
detection,” Comput., Mater. Continua, vol. 58, no. 1, pp. 15–26,
2019.

[43] W. Lin, J. Gao, Q. Wang, and X. Li, “Learning to detect anomaly
events in crowd scenes from synthetic data,” Neurocomputing, vol.
436, pp. 248–259, 2021.

[44] M. Frasca, A. Bertoni, M. Re, and G. Valentini, “A neural network
algorithm for semi-supervised node label learning from unbal-
anced data,” Neural Networks, vol. 43, pp. 84–98, 2013.
S. N. Kalid, K.-H. Ng, G.-K. Tong, and K.-C. Khor, “A multiple
classiﬁers system for anomaly detection in credit card data with
unbalanced and overlapped classes,” IEEE Access, vol. 8, pp.
28 210–28 221, 2020.

[45]

[46] H. H. Pajouh, G. Dastghaibyfard, and S. Hashemi, “Two-tier net-
work anomaly detection model: a machine learning approach,”

[47]

Journal of Intelligent Information Systems, vol. 48, no. 1, pp. 61–74,
2017.
S. El Hajjami, J. Malki, M. Berrada, and B. Fourka, “Machine
learning for anomaly detection. performance study considering
anomaly distribution in an imbalanced dataset,” in 2020 5th In-
ternational Conference on Cloud Computing and Artiﬁcial Intelligence:
Technologies and Applications (CloudTech).

IEEE, 2020, pp. 1–8.

[48] Z. Kang, H. Pan, S. C. Hoi, and Z. Xu, “Robust graph learning
from noisy data,” IEEE transactions on cybernetics, vol. 50, no. 5,
pp. 1833–1843, 2019.

[49] R. Evans and E. Grefenstette, “Learning explanatory rules from
noisy data,” Journal of Artiﬁcial Intelligence Research, vol. 61, pp.
1–64, 2018.

[50] P. Niyogi, S. Smale, and S. Weinberger, “A topological view
of unsupervised learning from noisy data,” SIAM Journal on
Computing, vol. 40, no. 3, pp. 646–663, 2011.

[51] N. Cesa-Bianchi, S. Shalev-Shwartz, and O. Shamir, “Online
learning of noisy data,” IEEE Transactions on Information Theory,
vol. 57, no. 12, pp. 7907–7931, 2011.

[52] Y. Kim, J. Yim, J. Yun, and J. Kim, “Nlnl: Negative learning
for noisy labels,” in Proceedings of the IEEE/CVF International
Conference on Computer Vision, 2019, pp. 101–110.

[53] N. Moran, D. Schmidt, Y. Zhong, and P. Coady, “Noisier2noise:
Learning to denoise from unpaired noisy data,” in Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recogni-
tion, 2020, pp. 12 064–12 072.
J.-X. Zhong, N. Li, W. Kong, S. Liu, T. H. Li, and G. Li, “Graph
convolutional label noise cleaner: Train a plug-and-play action
classiﬁer for anomaly detection,” in Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, 2019, pp.
1237–1246.

[54]

[55] M. Z. Zaheer, J.-h. Lee, M. Astrid, A. Mahmood, and S.-I. Lee,
“Cleaning label noise with clusters for minimally supervised
anomaly detection,” arXiv preprint arXiv:2104.14770, 2021.
S. Ahmad, A. Lavin, S. Purdy, and Z. Agha, “Unsupervised real-
time anomaly detection for streaming data,” Neurocomputing, vol.
262, pp. 134–147, 2017.

[56]

[57] Z. K. Maseer, R. Yusof, N. Bahaman, S. A. Mostafa, and C. F. M.
Foozy, “Benchmarking of machine learning for anomaly based
intrusion detection systems in the cicids2017 dataset,” IEEE ac-
cess, vol. 9, pp. 22 351–22 370, 2021.

[58] A. F. Emmott, S. Das, T. Dietterich, A. Fern, and W.-K. Wong,
“Systematic construction of anomaly detection benchmarks from
real data,” in Proceedings of the ACM SIGKDD workshop on outlier
detection and description, 2013, pp. 16–21.

[59] C. R. Banbury, V. J. Reddi, M. Lam, W. Fu, A. Fazel, J. Holle-
man, X. Huang, R. Hurtado, D. Kanter, A. Lokhmotov et al.,
“Benchmarking tinyml systems: Challenges and direction,” arXiv
preprint arXiv:2003.04821, 2020.

[60] G. Alinezhad Noghre, A. Danesh Pazho, J. Sanchez, N. Hewitt,
C. Neff, and H. Tabkhi, “Adg-pose: Automated dataset genera-
tion for real-world human pose estimation,” in International Con-
ference on Pattern Recognition and Artiﬁcial Intelligence.
Springer,
2022, pp. 258–270.

[61] G. Yu, Z. Cai, S. Wang, H. Chen, F. Liu, and A. Liu, “Unsuper-
vised online anomaly detection with parameter adaptation for
kpi abrupt changes,” IEEE Transactions on Network and Service
Management, vol. 17, no. 3, pp. 1294–1308, 2020.

[62] W. Wang, Q. Chen, T. Liu, X. He, and L. Tang, “A distributed
online learning approach to detect anomalies for virtualized
network slicing,” in 2021 IEEE Global Communications Conference
(GLOBECOM), 2021, pp. 1–6.

[63] A. Guezzaz, Y. Asimi, M. Azrour, and A. Asimi, “Mathematical
validation of proposed machine learning classiﬁer for hetero-
geneous trafﬁc and anomaly detection,” Big Data Mining and
Analytics, vol. 4, no. 1, pp. 18–24, 2021.
S. Li, Y. Cheng, Y. Liu, W. Wang, and T. Chen, “Abnormal client
behavior detection in federated learning,” 2019.

[64]

[65] L. Erhan, M. Ndubuaku, M. Di Mauro, W. Song, M. Chen,
G. Fortino, O. Bagdasar, and A. Liotta, “Smart anomaly detection
in sensor systems: A multi-perspective review,” Information
Fusion, vol. 67, pp. 64–79, 2021. [Online]. Available: https://
www.sciencedirect.com/science/article/pii/S1566253520303717
[66] Y. Dou, Z. Liu, L. Sun, Y. Deng, H. Peng, and P. S. Yu, “Enhanc-
ing graph neural network-based fraud detectors against camou-
ﬂaged fraudsters,” in Proceedings of the 29th ACM International

A. DANESH PAZHO ET AL.

18

[67]

Conference on Information & Knowledge Management, 2020, pp. 315–
324.
S. Bhatia, Y. Wang, B. Hooi, and T. Chakraborty, “Graphanogan:
Detecting anomalous snapshots from attributed graphs,” in Joint
European Conference on Machine Learning and Knowledge Discovery
in Databases. Springer, 2021, pp. 36–51.

[68] Y. Zheng, M. Jin, Y. Liu, L. Chi, K. T. Phan, and Y.-P. P. Chen,
“Generative and contrastive self-supervised learning for graph
anomaly detection,” IEEE Transactions on Knowledge and Data
Engineering, 2021.

[69] Y. Liu, T. Dillon, W. Yu, W. Rahayu, and F. Mostafa, “Noise
removal in the presence of signiﬁcant anomalies for industrial
iot sensor data in manufacturing,” IEEE Internet of Things Journal,
vol. 7, no. 8, pp. 7084–7096, 2020.

[70] Y. Tang, Z. Liu, M. Pan, Q. Zhang, C. Wan, F. Guan, F. Wu,
and D. Chen, “Detection of magnetic anomaly signal based on
information entropy of differential signal,” IEEE Geoscience and
Remote Sensing Letters, vol. 15, no. 4, pp. 512–516, 2018.

[71] W. Sultani, C. Chen, and M. Shah, “Real-world anomaly detection
in surveillance videos,” in Proceedings of the IEEE conference on
computer vision and pattern recognition, 2018, pp. 6479–6488.
[72] F. Muharemi, D. Logof˘atu, and F. Leon, “Machine learning ap-
proaches for anomaly detection of water quality on a real-world
data set,” Journal of Information and Telecommunication, vol. 3, no. 3,
pp. 294–307, 2019.

[73] A. Castellani, S. Schmitt, and S. Squartini, “Real-world anomaly
detection by using digital twin systems and weakly supervised
learning,” IEEE Transactions on Industrial Informatics, vol. 17, no. 7,
pp. 4733–4742, 2020.

[74] A. Ukil, S. Bandyoapdhyay, C. Puri, and A. Pal, “Iot healthcare
analytics: The importance of anomaly detection,” in 2016 IEEE
30th International Conference on Advanced Information Networking
and Applications (AINA), 2016, pp. 994–997.
S. A. Haque, M. Rahman, and S. M. Aziz, “Sensor anomaly
detection in wireless sensor networks for healthcare,” Sensors,
vol. 15, no. 4, pp. 8764–8786, 2015.
[Online]. Available:
https://www.mdpi.com/1424-8220/15/4/8764

[75]

[76] X. Liu, L. Xie, Y. Wang, J. Zou, J. Xiong, Z. Ying, and A. V. Vasi-
lakos, “Privacy and security issues in deep learning: A survey,”
IEEE Access, vol. 9, pp. 4566–4593, 2020.

[77] Y. Shen, G. Leus, and G. B. Giannakis, “Online graph-adaptive
learning with scalability and privacy,” IEEE Transactions on Signal
Processing, vol. 67, no. 9, pp. 2471–2483, 2019.

[78] B. Wang, J. Jia, and N. Z. Gong, “Graph-based security and
privacy analytics via collective classiﬁcation with joint weight
learning and propagation,” arXiv preprint arXiv:1812.01661, 2018.
[79] C. Yang, H. Wang, K. Zhang, L. Chen, and L. Sun, “Secure deep
graph generation with link differential privacy,” arXiv preprint
arXiv:2005.00455, 2020.

[81]

[80] V. Duddu, A. Boutet, and V. Shejwalkar, “Quantifying privacy
leakage in graph embedding,” in Mobiquitous 2020-17th EAI In-
ternational Conference on Mobile and Ubiquitous Systems: Computing,
Networking and Services, 2020, pp. 76–85.
J. Zhou, C. Chen, L. Zheng, H. Wu, J. Wu, X. Zheng, B. Wu,
Z. Liu, and L. Wang, “Vertically federated graph neural net-
work for privacy-preserving node classiﬁcation,” arXiv preprint
arXiv:2005.11903, 2020.
S. Sajadmanesh and D. Gatica-Perez, “Locally private graph neu-
ral networks,” in Proceedings of the 2021 ACM SIGSAC Conference
on Computer and Communications Security, 2021, pp. 2130–2145.

[82]

[83] C. Zhang, S. Zhang, J. James, and S. Yu, “Fastgnn: A topological
information protected federated learning approach for trafﬁc
speed forecasting,” IEEE Transactions on Industrial Informatics,
vol. 17, no. 12, pp. 8464–8474, 2021.

[84] Q. Li, M. Coutino, G. Leus, and M. G. Christensen, “Privacy-
preserving distributed graph ﬁltering,” in 2020 28th European
Signal Processing Conference (EUSIPCO).
IEEE, 2021, pp. 2155–
2159.

[85] T. Bakhshi and B. Ghita, “Anomaly detection in encrypted inter-
net trafﬁc using hybrid deep learning,” Security and Communica-
tion Networks, vol. 2021, 2021.

[86] T.-D. Pham, T.-L. Ho, T. Truong-Huu, T.-D. Cao, and H.-L.
Truong, “Mappgraph: Mobile-app classiﬁcation on encrypted
network trafﬁc using deep graph convolution neural networks,”
in Annual Computer Security Applications Conference, 2021, pp.
1025–1038.

[87] Y. Wu, H.-N. Dai, and H. Tang, “Graph neural networks for
anomaly detection in industrial internet of things,” IEEE Internet
of Things Journal, 2021.

[88] Z. Chen, D. Chen, X. Zhang, Z. Yuan, and X. Cheng, “Learning
graph structures with transformer for multivariate time series
anomaly detection in iot,” IEEE Internet of Things Journal, 2021.

[89] A. Protogerou, S. Papadopoulos, A. Drosou, D. Tzovaras, and
I. Refanidis, “A graph neural network method for distributed
anomaly detection in iot,” Evolving Systems, vol. 12, no. 1, pp.
19–36, 2021.

[90] Y. Liu, Z. Li, S. Pan, C. Gong, C. Zhou, and G. Karypis, “Anomaly
detection on attributed networks via contrastive self-supervised
learning,” IEEE transactions on neural networks and learning sys-
tems, 2021.

[91] R. Zhou, Q. Zhang, P. Zhang, L. Niu, and X. Lin, “Anomaly
detection in dynamic attributed networks,” Neural Computing and
Applications, vol. 33, no. 6, pp. 2125–2136, 2021.

[92] L. Zheng, Z. Li, J. Li, Z. Li, and J. Gao, “Addgraph: Anomaly
detection in dynamic graph using attention-based temporal gcn.”
in IJCAI, 2019, pp. 4419–4425.

[93] T. Pourhabibi, K.-L. Ong, B. H. Kam, and Y. L. Boo, “Fraud
detection: A systematic literature review of graph-based anomaly
detection approaches,” Decision Support Systems, vol. 133, p.
113303, 2020.

[94] M. Salehi and L. Rashidi, “A survey on anomaly detection in
evolving data: [with application to forest ﬁre risk prediction],”
ACM SIGKDD Explorations Newsletter, vol. 20, no. 1, pp. 13–23,
2018.

[95] K. Ding, J. Li, and H. Liu, “Interactive anomaly detection on at-
tributed networks,” in Proceedings of the twelfth ACM international
conference on web search and data mining, 2019, pp. 357–365.
[96] G. Xue, M. Zhong, J. Li, J. Chen, C. Zhai, and R. Kong, “Dynamic
network embedding survey,” Neurocomputing, vol. 472, pp. 212–
223, 2022.
J. Soldani and A. Brogi, “Anomaly detection and failure root
cause analysis in (micro) service-based cloud applications: A
survey,” ACM Computing Surveys (CSUR), vol. 55, no. 3, pp. 1–
39, 2022.

[97]

[98] A. Deng and B. Hooi, “Graph neural network-based anomaly
detection in multivariate time series,” in Proceedings of the AAAI
Conference on Artiﬁcial Intelligence, vol. 35, no. 5, 2021, pp. 4027–
4035.

[99] H. Wang, Z. Wu, H. Jiang, Y. Huang, J. Wang, S. Kopru, and T. Xie,
“Groot: An event-graph-based approach for root cause analysis
in industrial settings,” in 2021 36th IEEE/ACM International Con-
ference on Automated Software Engineering (ASE).
IEEE, 2021, pp.
419–429.

[100] K. Ding, K. Shu, X. Shan, J. Li, and H. Liu, “Cross-domain graph
anomaly detection,” IEEE Transactions on Neural Networks and
Learning Systems, 2021.

[101] K. Saenko, B. Kulis, M. Fritz, and T. Darrell, “Adapting visual
category models to new domains,” in European conference on
computer vision. Springer, 2010, pp. 213–226.

[102] Y. Ganin and V. Lempitsky, “Unsupervised domain adaptation by
backpropagation,” in International conference on machine learning.
PMLR, 2015, pp. 1180–1189.

[103] J. Hoffman, S. Guadarrama, E. S. Tzeng, R. Hu, J. Donahue,
R. Girshick, T. Darrell, and K. Saenko, “Lsda: Large scale detec-
tion through adaptation,” Advances in neural information processing
systems, vol. 27, 2014.

[104] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu,
and P. Kuksa, “Natural
from
scratch,” Journal of machine learning research, vol. 12, no. ARTICLE,
pp. 2493–2537, 2011.

language processing (almost)

[105] X. Glorot, A. Bordes, and Y. Bengio, “Domain adaptation for
large-scale sentiment classiﬁcation: A deep learning approach,”
in ICML, 2011.

[106] Q. Li, “Literature survey: domain adaptation algorithms for
natural language processing,” Department of Computer Science The
Graduate Center, The City University of New York, pp. 8–10, 2012.

[107] A. Søgaard, “Semi-supervised learning and domain adaptation
in natural language processing,” Synthesis Lectures on Human
Language Technologies, vol. 6, no. 2, pp. 1–103, 2013.

[108] B. Geng, D. Tao, and C. Xu, “Daml: Domain adaptation metric
learning,” IEEE Transactions on Image Processing, vol. 20, no. 10,
pp. 2980–2989, 2011.

A. DANESH PAZHO ET AL.

19

[109] Y. Zhang, Y. Wei, Q. Wu, P. Zhao, S. Niu, J. Huang, and M. Tan,
“Collaborative unsupervised domain adaptation for medical im-
age diagnosis,” IEEE Transactions on Image Processing, vol. 29, pp.
7834–7844, 2020.

[110] C. Wang, K. Viswanathan, L. Choudur, V. Talwar, W. Satterﬁeld,
and K. Schwan, “Statistical techniques for online anomaly detec-
tion in data centers,” in 12th IFIP/IEEE International Symposium
on Integrated Network Management (IM 2011) and Workshops, 2011,
pp. 385–392.

[111] R. Wang, Q. Zhu,

J. Luo, and F. Zhu, “Local dynamic
neighborhood based outlier detection approach and its
framework for large-scale datasets,” Egyptian Informatics Journal,
vol. 22, no. 2, pp. 125–132, 2021. [Online]. Available: https://
www.sciencedirect.com/science/article/pii/S1110866520301328
[112] T. D. Nguyen, S. Marchal, M. Miettinen, H. Fereidooni,
N. Asokan, and A.-R. Sadeghi, “D¨ıot: A federated self-learning
anomaly detection system for iot,” 2019.

[113] X. Ni, X. Xu, L. Lyu, C. Meng, and W. Wang, “A vertical federated

learning framework for graph convolutional network,” 2021.

[114] A. Borghesi, A. Bartolini, M. Lombardi, M. Milano, and L. Benini,
“Anomaly detection using autoencoders in high performance
computing systems,” in Proceedings of the AAAI Conference on
Artiﬁcial Intelligence, vol. 33, no. 01, 2019, pp. 9428–9433.

[115] Z. Chen, C. K. Yeo, B. S. Lee, and C. T. Lau, “Autoencoder-based
network anomaly detection,” in 2018 Wireless Telecommunications
Symposium (WTS), 2018, pp. 1–5.

[116] S. Park, M. Kim, and S. Lee, “Anomaly detection for http using
convolutional autoencoders,” IEEE Access, vol. 6, pp. 70 884–
70 901, 2018.

[117] C. Zhou and R. C. Paffenroth, “Anomaly detection with
robust deep autoencoders,” in Proceedings of the 23rd ACM
SIGKDD International Conference on Knowledge Discovery and Data
Mining, ser. KDD ’17. New York, NY, USA: Association for
Computing Machinery, 2017, p. 665–674. [Online]. Available:
https://doi.org/10.1145/3097983.3098052

[118] L. Beggel, M. Pfeiffer, and B. Bischl, “Robust anomaly detection
in images using adversarial autoencoders,” in Machine Learning
and Knowledge Discovery in Databases, U. Brefeld, E. Fromont,
A. Hotho, A. Knobbe, M. Maathuis, and C. Robardet, Eds. Cham:
Springer International Publishing, 2020, pp. 206–222.

[119] O. Atkinson, A. Bhardwaj, C. Englert, V. S. Ngairangbam,
and M. Spannowsky, “Anomaly detection with convolutional
of High Energy Physics,
graph neural networks,” Journal
vol. 2021, no. 8, p. 80, 2021.
[Online]. Available: https:
//doi.org/10.1007/JHEP08(2021)080

[120] S. Bandyopadhyay, S. V. Vivek, and M. Murty, “Outlier resistant
unsupervised deep architectures for attributed network embed-
ding,” in Proceedings of the 13th International Conference on Web
Search and Data Mining, 2020, pp. 25–33.

[121] X. Teng, M. Yan, A. M. Ertugrul, and Y.-R. Lin, “Deep into hyper-
sphere: Robust and unsupervised anomaly discovery in dynamic
networks,” in Proceedings of the Twenty-Seventh International Joint
Conference on Artiﬁcial Intelligence, 2018.

[122] B. Perozzi, R. Al-Rfou, and S. Skiena, “Deepwalk: Online
learning of social representations,” in Proceedings of the 20th
ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, ser. KDD ’14. New York, NY, USA: Association
for Computing Machinery, 2014, p. 701–710. [Online]. Available:
https://doi.org/10.1145/2623330.2623732

[123] A. Grover and J. Leskovec, “Node2vec: Scalable feature
learning for networks,” in Proceedings of
the 22nd ACM
SIGKDD International Conference on Knowledge Discovery and Data
Mining, ser. KDD ’16. New York, NY, USA: Association for
Computing Machinery, 2016, p. 855–864. [Online]. Available:
https://doi.org/10.1145/2939672.2939754

[124] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei, “Line:
Large-scale information network embedding,” in Proceedings of
the 24th International Conference on World Wide Web, ser. WWW
’15. Republic and Canton of Geneva, CHE: International World
Wide Web Conferences Steering Committee, 2015, p. 1067–1077.
[Online]. Available: https://doi.org/10.1145/2736277.2741093

[125] C. Yang, Z. Liu, D. Zhao, M. Sun, and E. Chang, “Network
representation learning with rich text information,” in Twenty-
fourth international joint conference on artiﬁcial intelligence, 2015.

the 24th ACM SIGKDD International Conference on Knowledge
Discovery & amp; Data Mining, ser. KDD ’18. New York, NY,
USA: Association for Computing Machinery, 2018, p. 2672–2681.
[Online]. Available: https://doi.org/10.1145/3219819.3220024

[127] L. Zheng, Z. Li, J. Li, Z. Li, and J. Gao, “Addgraph: Anomaly
detection in dynamic graph using attention-based temporal gcn,”
in Proceedings of the Twenty-Eighth International Joint Conference on
Artiﬁcial Intelligence, IJCAI-19.
International Joint Conferences
on Artiﬁcial Intelligence Organization, 7 2019, pp. 4419–4425.
[Online]. Available: https://doi.org/10.24963/ijcai.2019/614
[128] S. Feng, Z. Tan, R. Li, and M. Luo, “Heterogeneity-aware twitter
bot detection with relational graph transformers,” arXiv preprint
arXiv:2109.02927, 2021.

[129] Y. Liu, S. Pan, Y. G. Wang, F. Xiong, L. Wang, Q. Chen, and V. C.
Lee, “Anomaly detection in dynamic graphs via transformer,”
IEEE Transactions on Knowledge and Data Engineering, pp. 1–1,
2021.

[130] F. Yu and V. Koltun, “Multi-scale context aggregation by dilated

convolutions,” arXiv preprint arXiv:1511.07122, 2015.

[131] H. E. Egilmez and A. Ortega, “Spectral anomaly detection using
graph-based ﬁltering for wireless sensor networks,” in 2014 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP), 2014, pp. 1085–1089.

[132] B. Chen, J. Zhang, X. Zhang, Y. Dong, J. Song, P. Zhang, K. Xu,
E. Kharlamov, and J. Tang, “Gccad: Graph contrastive coding for
anomaly detection,” arXiv preprint arXiv:2108.07516, 2021.
[133] Y. Zheng, M. Jin, Y. Liu, L. Chi, K. T. Phan, and Y.-P. P. Chen,
“Generative and contrastive self-supervised learning for graph
anomaly detection,” IEEE Transactions on Knowledge and Data
Engineering, pp. 1–1, 2021.

[134] M. Aledhari, R. Razzak, R. M. Parizi, and F. Saeed, “Federated
learning: A survey on enabling technologies, protocols, and
applications,” IEEE Access, vol. 8, pp. 140 699–140 725, 2020.
[135] K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman,
V. Ivanov, C. Kiddon, J. Koneˇcn ´y, S. Mazzocchi, H. B. McMahan,
T. V. Overveldt, D. Petrou, D. Ramage, and J. Roselander, “To-
wards federated learning at scale: System design,” 2019.

[136] Y. Chen, Y. Ning, Z. Chai, and H. Rangwala, “Federated multi-
task hierarchical attention model for sensor analytics,” 2019.
[137] J. Koneˇcn ´y, H. B. McMahan, F. X. Yu, P. Richt´arik, A. T. Suresh,
and D. Bacon, “Federated learning: Strategies for improving
communication efﬁciency,” 2017.

[138] H. Wang, M. Yurochkin, Y. Sun, D. Papailiopoulos, and Y. Khaz-
aeni, “Federated learning with matched averaging,” 2020.

[139] K. Bonawitz, V.

Ivanov, B. Kreuter, A. Marcedone, H. B.
McMahan, S. Patel, D. Ramage, A. Segal, and K. Seth, “Practical
secure aggregation for privacy-preserving machine learning,”
in Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security, ser. CCS ’17. New York, NY,
USA: Association for Computing Machinery, 2017, p. 1175–1191.
[Online]. Available: https://doi.org/10.1145/3133956.3133982

[140] R. Chandra and S. Cripps, “Bayesian multi-task learning for
dynamic time series prediction,” in 2018 International Joint Con-
ference on Neural Networks (IJCNN), 2018, pp. 1–8.

[141] S. Li, Y. Song, and G. Zhou, “Leak detection of water distribution
pipeline subject to failure of socket joint based on acoustic
emission and pattern recognition,” Measurement, vol. 115, pp.
39–44, 2018.
[Online]. Available: https://www.sciencedirect.
com/science/article/pii/S0263224117306498

[142] L.-J. Chen, Y.-H. Ho, H.-H. Hsieh, S.-T. Huang, H.-C. Lee, and
S. Mahajan, “Adf: An anomaly detection framework for large-
scale pm2.5 sensing systems,” IEEE Internet of Things Journal,
vol. 5, no. 2, pp. 559–570, 2018.

[143] D. L. Goodhue and D. W. Straub, “Security concerns of system
users: A study of perceptions of the adequacy of security,” Inf.
Manage., vol. 20, no. 1, p. 13–27, jan 1991. [Online]. Available:
https://doi.org/10.1016/0378-7206(91)90024-V

[144] R. A. Sater and A. B. Hamza, “A federated learning
approach to anomaly detection in smart buildings,” ACM Trans.
Internet Things, vol. 2, no. 4, aug 2021. [Online]. Available:
https://doi.org/10.1145/3467981

[145] H. Zhang, T. Shen, F. Wu, M. Yin, H. Yang, and C. Wu, “Federated

graph learning – a position paper,” 2021.

[126] W. Yu, W. Cheng, C. C. Aggarwal, K. Zhang, H. Chen, and
W. Wang, “Netwalk: A ﬂexible deep embedding approach for
anomaly detection in dynamic networks,” in Proceedings of

[146] E. J. Cand`es, X. Li, Y. Ma, and J. Wright, “Robust principal
component analysis?” J. ACM, vol. 58, no. 3, jun 2011. [Online].
Available: https://doi.org/10.1145/1970392.1970395

A. DANESH PAZHO ET AL.

[147] D. L. Donoho, “For most large underdetermined systems of linear
equations the minimal 1-norm solution is also the sparsest solu-
tion,” Communications on Pure and Applied Mathematics, vol. 59,
pp. 797–829, 2006.

[148] R. Paffenroth, P. du Toit, R. Nong, L. Scharf, A. P. Jayasumana,
and V. Bandara, “Space-time signal processing for distributed
pattern detection in sensor networks,” IEEE Journal of Selected
Topics in Signal Processing, vol. 7, no. 1, pp. 38–49, 2013.

[149] A. Makhzani,

J. Shlens, N.

and I. Goodfellow,
on
“Adversarial autoencoders,” in International Conference
Learning Representations, 2016. [Online]. Available: http://arxiv.
org/abs/1511.05644

Jaitly,

[150] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,”
Advances in neural information processing systems, vol. 30, 2017.

[151] S. Yun, M. Jeong, R. Kim, J. Kang, and H. J. Kim, “Graph
transformer networks,” Advances in neural information processing
systems, vol. 32, 2019.

[152] J. Klicpera, S. Weißenberger, and S. G ¨unnemann, “Diffusion im-
proves graph learning,” Advances in Neural Information Processing
Systems, vol. 32, 2019.

[153] K. Hassani and A. H. Khasahmadi, “Contrastive multi-view
representation learning on graphs,” in International Conference on
Machine Learning. PMLR, 2020, pp. 4116–4126.

[154] E. Jang, S. Gu, and B. Poole, “Categorical reparameterization with

gumbel-softmax,” arXiv preprint arXiv:1611.01144, 2016.

[155] A. Ortega, P. Frossard, J. Kovaˇcevi´c, J. M. F. Moura, and P. Van-
dergheynst, “Graph signal processing: Overview, challenges, and
applications,” Proceedings of the IEEE, vol. 106, no. 5, pp. 808–828,
2018.

[156] A. Sandryhaila and J. M. F. Moura, “Discrete signal processing
on graphs: Frequency analysis,” IEEE Transactions on Signal Pro-
cessing, vol. 62, no. 12, pp. 3042–3054, 2014.

[157] G. Shen and A. Ortega, “Joint routing and 2d transform optimiza-
tion for irregular sensor network grids using wavelet lifting,” in
2008 International Conference on Information Processing in Sensor
Networks (ipsn 2008), 2008, pp. 183–194.

[158] X. Zhu and M. Rabbat, “Graph spectral compressed sensing
for sensor networks,” in 2012 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), 2012, pp. 2865–
2868.

[159] M. Zheng, C. Zhou, J. Wu, S. Pan, J. Shi, and L. Guo, “Fraudne:
a joint embedding approach for fraud detection,” in 2018 Inter-
national Joint Conference on Neural Networks (IJCNN).
IEEE, 2018,
pp. 1–8.

[160] Y. Dou, K. Shu, C. Xia, P. S. Yu, and L. Sun, “User preference-
aware fake news detection,” in Proceedings of the 44th International
ACM SIGIR Conference on Research and Development in Information
Retrieval, 2021, pp. 2051–2055.

[161] N. Liu, X. Huang, and X. Hu, “Accelerated local anomaly detec-
tion via resolving attributed networks.” in IJCAI, 2017, pp. 2337–
2343.

[162] L. Zhang, J. Yuan, Z. Liu, Y. Pei, and L. Wang, “A robust em-
bedding method for anomaly detection on attributed networks,”
in 2019 International Joint Conference on Neural Networks (IJCNN).
IEEE, 2019, pp. 1–8.

[163] K. Ding, J. Li, R. Bhanushali, and H. Liu, “Deep anomaly de-
tection on attributed networks,” in Proceedings of the 2019 SIAM
International Conference on Data Mining. SIAM, 2019, pp. 594–602.
[164] X. Wang, B. Jin, Y. Du, P. Cui, Y. Tan, and Y. Yang, “One-
class graph neural networks for anomaly detection in attributed
networks,” Neural computing and applications, vol. 33, no. 18, pp.
12 073–12 085, 2021.

[165] Z. Peng, M. Luo, J. Li, L. Xue, and Q. Zheng, “A deep multi-view
framework for anomaly detection on attributed networks,” IEEE
Transactions on Knowledge and Data Engineering, 2020.

[166] Y. Li, X. Huang, J. Li, M. Du, and N. Zou, “Specae: Spectral
autoencoder for anomaly detection in attributed networks,” in
Proceedings of the 28th ACM International Conference on Information
and Knowledge Management, 2019, pp. 2233–2236.

[167] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,
P. Doll´ar, and C. L. Zitnick, “Microsoft coco: Common objects
in context,” in Computer Vision – ECCV 2014, D. Fleet, T. Pajdla,
B. Schiele, and T. Tuytelaars, Eds. Cham: Springer International
Publishing, 2014, pp. 740–755.

20

Armin Danesh Pazho is currently a Ph.D. stu-
dent at the department of Electrical and Com-
puter Engineering, University of North Carolina
at Charlotte, Charlotte, North Carolina, United
States. His general research interests are Artiﬁ-
cial Intelligence, Computer Vision, Deep Learn-
ing, and Machine Learning. More speciﬁcally
his research focuses on developing AI for Real-
world applications, Real-time processing, and
their challenges and requirements.

Ghazal Alinezhad Noghre is currently pursuing
her Ph.D. in Electrical and Computer Engineer-
ing at University of North Carolina at Charlotte,
Charlotte, North Carolina, United States. Her
research concentrates on Artiﬁcial Intelligence,
Machine Learning, and Computer Vision. She is
mainly focused on Artiﬁcial Intelligence and its
applications in the Real-world environment, and
its challenges.

Arnab A Purkayastha is an Assistant Professor
of Electrical and Computer Engineering depart-
ment at the Western New England University,
Massachusetts. He received his PhD in the year
2021 from the University of North Carolina at
Charlotte. His research interests and activities
lie in the recent advances in High Performance
Computing and Machine Learning ﬁelds, includ-
ing system level integration at the cloud and the
edge.

Jagannadh Vempati is a research scientist at
Siemens Technology in Princeton – NJ perform-
ing research and development on designing cy-
ber defense solutions that incorporate domain
know-how and the semantic context of attack
detection and response solutions. His respon-
sibilities include developing new methods and
techniques that improve the value of security
analytics in Cyber Defense by integrating in-
dustrial domain expertise and semantics/context
and guiding Siemens Business Units to include
research results into products, solutions, and services. His research is
focused on data-driven cyber security and designing resilient networks.
His research also focuses on designing, developing, and optimizing
anomaly detection models using artiﬁcial intelligence. He holds a Ph.D.
in computer science and engineering from the University of North Texas.
Martin Otto is a researcher and research man-
ager with Siemens Technology, Siemens’ central
R&D organization, since 2005. He is currently
the head of
the research group ”Cybersecu-
rity Service Innovation” at Siemens Corporation,
Siemens Technology, in Princeton, NJ, USA. His
mission is to provide Siemens business units
with technology solutions and innovations that
enable Siemens to provide state of the are secu-
rity services to customers. A speciﬁc focus is on
helping Siemens customers that operate energy
infrastructure to detect,
systems and other parts of national critical
react to, mitigate, and otherwise defend against cyber attacks. He held
positions in the US, Canada, and Germany, among them as global
Head of the Siemens CERT (Computer Emergency Response Team).
He acquired a Ph.D. in computer Science in 2005 from Paderborn
University, Paderborn, Germany, working on fault attack side channels
on smart cards.

Hamed Tabkhi (S’07–M’14) is the associate
professor of Computer Engineering at the Uni-
versity of North Carolina Charlotte (UNCC). He
received his PhD in Computer Engineering from
Northeastern University in 2014. His research
and scholarship activities focus on transforma-
tive computer system solutions to bring recent
advances in Artiﬁcial Intelligence (AI) to address
real-world problems. In particular, he focuses on
AI-based solutions to enhance our communities’
safety, health, and overall well-being.

