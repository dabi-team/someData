2
2
0
2

g
u
A
0
1

]

O
L
.
s
c
[

1
v
7
0
5
5
0
.
8
0
2
2
:
v
i
X
r
a

A Compositional Approach to Verifying Modular Robotic
Systems

Matt Luckcuck

Marie Farrell

Department of Computer Science

Department of Computer Science

and Hamilton Institute,

Maynooth University,

Ireland

and Hamilton Institute,

Maynooth University,

Ireland

Angelo Ferrando

Rafael C. Cardoso

Department of Computer Science,

Department of Computing Science,

University of Genova,

University of Aberdeen, United Kingdom

Italy

Louise A. Dennis

Michael Fisher

Department of Computer Science,

Department of Computer Science,

University of Manchester,

University of Manchester,

United Kingdom

United Kingdom

12th August 2022

Abstract

Robotic systems used in safety-critical industrial situations often rely on modular software archi-
tectures, and increasingly include autonomous components. Verifying that these modular robotic
systems behave as expected requires approaches that can cope with, and preferably take advan-
tage of, this inherent modularity. This paper describes a compositional approach to specifying
the nodes in robotic systems built using the Robot Operating System (ROS), where each node
is speciﬁed using First-Order Logic (FOL) assume-guarantee contracts that link the speciﬁcation
to the ROS implementation. We introduce inference rules that facilitate the composition of these
node-level contracts to derive system-level properties. We also present a novel Domain-Speciﬁc
Language, the ROS Contract Language (RCL), which captures a node’s FOL speciﬁcation and
links this contract to its implementation. RCL contracts can be automatically translated, by our
tool Vanda, into executable monitors; which we use to enforce the contracts at runtime. We illus-
trate our approach through the speciﬁcation and veriﬁcation of an autonomous rover engaged in
the remote inspection of a nuclear site, and examples focussing on the speciﬁcation and veriﬁcation
of individual nodes.

Acknowledgments

This work is supported by EPSRC, through grants EP/R026092 (FAIR-SPACE), EP/R026173 (ORCA),
EP/R026084 (RAIN), and EP/V026801 (Veriﬁability Node). Cardoso’s and Fisher’s work is supported
by the Royal Academy of Engineering under the Chairs in Emerging Technologies scheme.

For the purpose of open access, the authors have applied a Creative Commons Attribution (CC

BY) licence to any Author Accepted Manuscript version arising.

Data Access Statement

The formal modes, data, and source code supporting the ﬁndings reported in this paper are openly
available from the Zenodo repository at: https://doi.org/10.5281/zenodo.6941344.

1

 
 
 
 
 
 
1 Introduction

Robotic systems are increasingly deployed in industrial, often safety-critical, scenarios such as monitor-
ing oﬀshore structures [39], nuclear inspection and decommissioning [7, 2], and space exploration [65,
34]. It is crucial to ensure that the software controlling a robot behaves correctly, particularly as mod-
ern robotic systems become more autonomous, more complex, and are used in dynamic environments
that they share with humans.

Engineering the software to control a robotic system is a complex task, often supported by modular
software frameworks, such as the Robot Operating System (ROS) [55] or GenoM [35, 33]. Though these
frameworks support robotic software development in diﬀerent ways, they share abstract concepts [60];
so techniques that support these shared concepts are often applicable to a range of frameworks. The
generality and ﬂexibility of robotic software frameworks also means that guaranteeing their correct
behaviour is challenging [37].

The state-of-the-art for veriﬁcation of robotic (and autonomous robotic) systems includes a variety
of formal methods that can be used for speciﬁcation and veriﬁcation [49] – non-formal methods such
as ﬁeld tests and simulation-based testing are also common. Formal methods that we see being used
include: model-checking [19], which exhaustively explores the state space to establish that a property
holds; runtime veriﬁcation [46], which monitors system behaviour at runtime; and theorem-provers [6],
demonstrating by mathematical proof that the system behaves correctly. Diﬀerent components of a
robotic system may be better suited to distinct veriﬁcation techniques, yet linking the outputs of this
range of techniques remains a challenge. In previous work, we have argued that robotics is a domain
in which integrating (formal and non-formal) veriﬁcation methods is both a necessity to be dealt with
and an opportunity to be grasped [29].

Assume-Guarantee reasoning [44] (or the speciﬁcation of pre- and post-conditions) is a well estab-
lished compositional veriﬁcation technique. A pair of pre- and post-conditions form a contract [52].
Specifying a system using Assume-Guarantee or pre- and post-conditions enables it to be decomposed
into modules, so that each module can be veriﬁed separately against its associated contract. However,
care must be taken when specifying the contracts, because they still require validation against the
actual requirements of the system.

This paper presents our approach to verifying robotic systems that are developed using ROS. This
particular robotic software framework was chosen because of its prevalence in the literature. A ROS
system is composed of nodes that communicate using message passing via buﬀered communication
channels. The nodes coordinate to control the robot’s overall behaviour. Typically, each node will
be specialised to perform a diﬀerent function, with diﬀerent nodes (or collections of nodes) often
requiring distinct veriﬁcation techniques. For example, machine learning components will likely be
veriﬁed via testing, whereas a planner might be mathematically modelled and reasoned about using
formal veriﬁcation. Our approach uses the encapsulation provided by a ROS system’s nodes to provide
compositionality. Fundamentally, we address the research question:

Can we use a compositional and heterogeneous approach to verify ROS-based systems?

Our approach begins by (manually) abstracting the graph of nodes in the ROS program (generated
by ROS Graph or similar) into a more manageable model of the system, a model that focusses on the
system’s most critical components. Although some nodes maintain a one-to-one correspondence with
the ROS software, abstraction can involve dropping some nodes from the system model or combining
related nodes into a compound node.

Once the ROS software is abstracted to a manageable system model, we specify each of the nodes
in this model using Assume-Guarantee contracts, written in our contract speciﬁcation language that
is based on First-Order Logic (FOL). FOL was chosen for contract speciﬁcations because it is both
expressive and widely understood, lowering the barrier to use of our approach. Beyond providing the
pre- and post- conditions for each module in FOL, we also generate a First-Order Temporal Logic
(FOTL) [32] description of the temporal behaviour of each component, and then the whole system.

We also provide a calculus that can be used to combine the module contracts and to derive system-
level properties that correspond to the system’s requirements. Once the contracts are veriﬁed against
the system’s requirements, we can take two further steps in parallel. The contracts are used to guide the
veriﬁcation of each node, using a suite of heterogeneous (formal or non-formal) veriﬁcation approaches.
Meanwhile, our tool, Vanda, automatically synthesises runtime monitors from the contracts. The
overall approach builds on two pieces of previous work:

2

• the initial presentation of the contract calculus in [11], which we signiﬁcantly update; and,
• our application of heterogeneous veriﬁcation approaches to a simulation of the Mars Curiosity

rover [12], which we also update with additional steps.

The three contributions of this paper are:

1. a Domain Speciﬁc Language (DSL), called the ROS Contract Language (RCL), that enables a

developer to write structured contracts for ROS nodes;

2. a calculus containing inference rules for combining the contracts so that we can derive system-

level (safety and mission) properties; and,

3. a tool-chain that synthesises runtime monitors from the system’s RCL contracts.

Our approach enables the introduction of a formal speciﬁcation to existing systems that are imple-
mented in ROS. As such, we use the intended behaviour of the nodes in a system as the starting point
for specifying its contracts, and combine them using the calculus. Our DSL and prototype monitor
generation tool (Vanda) provide support for users to write grammatically correct contracts.

In summary, the contracts: are structured using RCL; are reasoned about using our calculus;
guide the heterogeneous veriﬁcation of the nodes; and are then used to generate runtime monitors
that provide a safety net, ensuring that the contracts have been veriﬁed correctly and the system
is obeying its requirements. We validate our approach by applying it to a ground rover performing
a remote inspection task inside a nuclear storage facility (§4). This example system was developed
independently of our work, and we use our approach to introduce contracts and formal veriﬁcation.
We also describe the speciﬁcation and veriﬁcation of individual nodes, showing how our approach can
guide veriﬁcation using a variety of diﬀerent formalisms.

The remainder of this paper is structured as follows. In §2, we discuss related work. §3 describes
our compositional approach to verifying modular robotic systems using FOL contracts. This section
includes: the calculus for combining node speciﬁcations into system-level properties, a description
of how RCL supports the speciﬁcation of contracts for ROS, and ﬁnally how we can automatically
synthesise runtime monitors from RCL descriptions. §4 presents our Case Study, a remote inspection
In §5 we discuss some interesting characteristics of our work, such as the use of a system’s
rover.
modularity, how our approach ﬁts into the robotic software development process and, in §5.3, we
describe how our approach can be applied to non-ROS systems. Finally, §6 concludes the paper and
presents avenues for future work.

2 Related Work

In this section, we discuss some of the approaches from the literature that relate to our work in one or
more diﬀerent aspects, such as formalisms and frameworks for verifying robotic systems, compositional
veriﬁcation, or contract-based veriﬁcation techniques.

ROS is a well established middleware for facilitating interoperability and modularity in the devel-
opment of robotic software. A safety-critical working group1 for ROS2 has been looking into providing
tools, libraries, and documents to support the safe engineering of safety-critical systems developed in
ROS. One such deliverable is their contracts package2, where a contract is a combination of pre-/post-
conditions and assertions over the implementation of C++ functions. The advantage of their approach
is that the contracts work directly in the source code of the implementation. However, this is also a
disadvantage, as ROS nodes may be implemented using languages such as Python, Java, or others. In
comparison, our approach is more general and not limited to the veriﬁcation of individual functions,
but also allows the veriﬁcation of the system as a whole through the use of our inference rules. Fur-
thermore, their ad-hoc contract language is less expressive than FOL. However, an interesting line of
future work could include updating Vanda, our prototype tool, to produce contracts compatible with
the ROS2 contracts package.

Another approach that is compositional, uses Assume-Guarantee contracts, and targets ROS is
presented in [62]. Their methodology focusses on using contracts to decompose the control software
of multi-robot systems. First, the individual components or robots are decomposed into sub-problems
and then recomposed using the contracts to provide system-level validation. After validation, the
resulting synthesised controller is integrated into ROS. Their approach is top-down, focusing on the

1https://github.com/ros-safety Accessed: 15/07/2022
2https://github.com/ros-safety/contracts_lite Accessed: 15/07/2022

3

synthesis of contracts for multiple robots, it requires an explicit model of the environment, and is
focussed on synthesising control systems.

In our approach, we focus on veriﬁcation and do not generate or alter the control system in any way,
instead we automatically synthesise a safety net of monitors, which ensure that the contracts are not
violated at runtime. The Declarative Robot Safety (DeRoS) [1] is another approach that uses monitors
as safety net. DeRoS is a DSL with a simple, declarative syntax, which lowers the barrier to using this
approach – similarly to our use of a textual version of FOL. In their approach, each of the contracts is
a reﬁnement of the system-level contract; it is not clear if they use a similar technique to our inference
rules to ensure that the contracts are composed correctly at design time. Moreover, DeRoS, integrated
with ROS, is shown to be capable of specifying safety-related constraints. Unfortunately, DeRoS is not
publicly available, otherwise it could have been an alternative candidate to synthesise our monitors.

Drona [26] is a toolchain for programming safety-critical robots, with support for ROS. As part of
the toolchain they propose a new DSL based on state machines, called P, that oﬀers compositional
Assume-Guarantee testing and a runtime assurance system to check that the assumptions made at
design-time hold at runtime. The main diﬀerence to our approach is that our DSL is used purely for
specifying contracts for veriﬁcation, and thus we do not directly interfere with the implementation of
the system. Another important diﬀerence is that our runtime monitors are automatically synthesised
from the contracts, while theirs require additional speciﬁcation.

An approach that provides automatic static veriﬁcation of system-wide properties for message-
passing in ROS applications is described in [15]. The speciﬁcation of the safety properties is written
in a DSL, which is translated into FOTL to be used in Electrum (an extension of Alloy) [51], which
provides an automatic Analyser. This is embedded in HAROS [59], a framework for quality assessment
of ROS software that oﬀers a visualisation interface for safety issues. Comparatively, our work instead
focuses on compositional veriﬁcation of nodes/modules in ROS, which are then supported by inference
rules to automatically generate system-wide properties. Furthermore, we are not limited to static
veriﬁcation, our approach also provides runtime veriﬁcation by automatically synthesising monitors
based on the contracts.

RoboChart [53] is a DSL based on the Uniﬁed Modelling Language (UML), which supports ver-
iﬁcation and automated reasoning of robotic systems using model checking and theorem proving. It
uses a notation based on state-machines, with a restricted set of constructs, prioritising simplicity in
the semantics over expressiveness. Integrated Development Environment (IDE) support is available
through an Eclipse plugin called RoboTool. This tool automatically generates C++ code for state
machines and controllers, but does not yet oﬀer automatic code deployment in ROS. Our work is
mainly targets ROS (applicability to other robotic systems is discussed in §5.3), and we encourage
heterogeneous veriﬁcation techniques rather than limiting it to just a few options.

Our work takes inspiration from Broy’s approach to systems engineering [10] which presents three
kinds of artefacts: (1) system-level requirements, (2) functional system speciﬁcation, and (3) logical
subsystem architecture. These are represented as logical predicates in the form of assertions, with
relationships deﬁned between them that extend to assume/commitment contracts. The treatment of
these contracts is purely logical, and we present a similar technique that, instead of assertions, uses
Assume-Guarantee contracts and is specialised to the software engineering of robotic systems.

The Integration Property Language (IPL) [58] is designed to improve expressiveness in the ver-
iﬁcation of integrated heterogeneous models in cyber-physical systems.
IPL aims to combine FOL
reasoning across architectural views that correspond to behaviourless component models, annotated
with types and properties. IPL provides modular veriﬁcation of properties that come from diﬀerent
models and static, system-wide reasoning. This is achieved through the use of Satisﬁability Modulo
Theories (SMT) solvers and model checkers. Their focus is on verifying the result of the integration,
rather than individually verifying each model and then generating system-level properties. The latter
approach is more appropriate for robotic systems, since integration will often result in poor scalability.
CoCoSpec [16] allows users to specify contracts for reactive systems in terms of assumptions and
guarantees. CoCoSpec extends the Lustre speciﬁcation language and uses the Kind2 model-checker for
compositional veriﬁcation [17]. This approach is specialised for synchronous communications, which
diﬀer from the event-based communications that we target, and their contract semantics is more
restrictive than ours. Further, it is not clear how their support for compositional veriﬁcation can be
extended to support heterogeneous components such as those in our example. In one of the author’s
previous works, an inspection rover example used a combination of NASA’s Formal Requirements

4

Elicitation Tool (FRET), CoCoSpec, and Event-B for veriﬁcation [8]. This work used a Simulink
model of the robot’s architecture which deﬁned individual components.
In contrast, we focus on
systems developed in ROS and use FOL contracts to reason about system-level properties.

Compositional Assume-Guarantee reasoning has been used to deﬁne contracts for system mod-
ules [5], where rules are deﬁned for the composition and conjunction of contracts. Their rules share
the same aim as our work, but our inference rules (§3) are simpler because we make assumptions
about the robotic system that we are modelling, which makes our contracts easier to mechanise as
runtime monitors. Their rules were extended by [47], who use a variant of Signal Temporal Logic
(STL) to describe behaviour and contracts and used the rules in [5] to produce the assumptions and
guarantees of the whole system. They target closed-loop control systems, whereas the robotic systems
that our technique is aimed at are written in general-purpose programming languages. Other related
compositional approaches include OCRA [18] and AGREE [21]. Neither of these approaches explicitly
incorporates heterogeneous veriﬁcation techniques.

The importance of supporting heterogeneous veriﬁcation techniques in the robotics domain cannot
be understated as these systems increase in size and complexity [29]. Crucially, the modular structure
of ROS systems facilitates the use of heterogeneous veriﬁcation methods. For example, recent work
used various veriﬁcation techniques to verify an autonomous space debris removal grasping system
that was developed in ROS [30]. Requirements were devised and veriﬁed for individual components in
the system, but the work did not present a logical way to ensure consistency between the models and
properties veriﬁed. The calculus that we present here could be used to derive system-level contracts
for systems like this one.

In summary, there are many papers in the literature that partially address the challenge that we are
facing, and various foundational approaches to compositional veriﬁcation that are not specialised to
any particular domain. We take inspiration from some of these, but devise a calculus that is speciﬁcally
tailored for ROS systems. Other approaches are limited to speciﬁc tools and so neither support nor
harness the power of incorporating a suite of heterogeneous veriﬁcation approaches in the way that
our approach does. To ensure traceability and consistency, we also provide a way of automatically
generating runtime monitors so that we can support both static and dynamic veriﬁcation for systems
that operate in the real world.

3 Specifying Veriﬁable Robotic Systems

As mentioned in §1, our work enables the introduction of a formal speciﬁcation to existing ROS
programs. Recall that a ROS system is composed of nodes. Each node may subscribe to receive
messages from, or publish messages to, a topic (a buﬀered communication channel). Each topic is
described by the message types that it can accept. ROS contains several built-in message types (such
as string, bool, and int8), custom types can also be added.

Our veriﬁcation approach begins with a manual analysis of the ROS program, to abstract it into
a more manageable system model. We then specify a contract for each of the system’s nodes in typed
FOL, which was chosen to lower the barrier to learning to write contracts. The contracts are then
combined and reasoned about using our calculus, which uses FOTL; because it is more expressive than
FOL3. We use the contracts to guide the modelling and veriﬁcation of individual nodes, while our tool,
Vanda, automatically synthesises monitors from the contracts to provide a safety-net that checks that
their guarantees are obeyed at runtime.
Our approach is split into ﬁve steps, as shown in Fig. 1. Each step is described as follows.

Step 1: Abstract the ROS program into a more manageable system model, containing the nodes that
are critical to the program’s correct behaviour. Depending on the ROS program, this step may
involve some form of abstraction, for example by combining multiple nodes into a compound
node, or omitting nodes that are known to be reliable.

Step 2: Write the RCL contract for each node. The contract contains clauses for the FOL assume
and guarantee conditions, and clauses describing the ROS topics that the node uses (the node’s
inputs and outputs). Our RCL tool, Vanda, parses the contracts, identifying where the format
of the language has not been adhered to, and can synthesis runtime monitors (see Step 4b).

3We use both the (cid:13) (“next”) and ♦ (“sometime”) temporal operators in this variety of FOTL, so it more expressive

than FOL.

5

Figure 1: A ﬂowchart of our approach, where each step depends on the previous one. Step 1 produces
a manageable model of the system. Step 2 produces the RCL contracts for the system, using the nodes
in the system model from Step 1. Step 3 uses our calculus to derive the system properties that results
from the contracts in Step 2. Steps 4a and 4b can happen in parallel. In Step 4a, the RCL contracts
guide the veriﬁcation of each node; in Step 4b, the RCL contracts are used to synthesise the runtime
monitor safety net. If needed, previous steps may be revisited. For example, if contracts are violated
then either the system model or the contracts themselves might be revised.

Step 3: Use our calculus to reason about the combination of the node contracts. This generates a
list of system-level properties that can be used to verify the system’s requirements. The calculus
also identiﬁes malformed contracts, which we debug until the inference rules are valid.

Step 4a: Verify the nodes, using a suite of heterogeneous veriﬁcation approaches. This step uses the
contracts to guide the veriﬁcation, which is especially important where there is not a formal link
between the veriﬁcation approach and FOL.

Step 4b: Automatically synthesise runtime monitors for nodes from their RCL contracts. The mon-
itors act as a safety net to ensure that nodes adhere to their contracts while the system is
operating.

This paper focuses on ROS systems, but Steps 1 and 2 above could be applied to a system where the
nodes/modules are classes or methods. We discuss how this might work in §5.3.

The steps are numbered sequentially, but they are not intended to be simply followed linearly like
the Waterfall model. Steps 4a and 4b can also be performed in parallel. Additionally, previous steps
may be revisited, if needed. For example, as identiﬁed above, Step 3 could highlight a malformed
contract that would be debugged and potentially rewritten, which revisits Step 2. Similarly, Step 4a
could reveal that a speciﬁcation is too restrictive to be veriﬁed (for example), which could trigger a
re-write (revisiting Step 2) or the restrictive part of the speciﬁcation could be left to be monitored
in Step 4b. Step 1 can also be revisited if we later ﬁnd that an abstraction in the system model is
troublesome, for example we may need to split a compound node back into its constituent parts.

It is important to note the diﬀerence in purpose between Steps 3 and 4a/4b. In Step 3, the calculus
is used to combine the contracts and reveal the system-level property (or properties) that is produced
by the combination of their guarantees. The veriﬁcation in Step 4a statically veriﬁes that the nodes
implement their contracts, which then implies the system-level property holds. And the monitors in
Step 4b check the guarantees hold at runtime; if all the monitors do not conclude false4, then the
system-level property holds. If one monitor concludes false, then we know (a) that the system-level
property does not hold, and (b) which node has violated its guarantee.

In the remainder of this section we describe: the process of abstracting a ROS system into a system
model, §3.1; how our contracts are described and composed, §3.2; our approach to writing the con-
tracts, §3.3; our calculus for combining the contracts, §3.4; how the contracts can guide heterogeneous
veriﬁcation, §3.5; and our runtime monitoring approach, §3.6.

3.1 System Model

To start writing the contracts we need some form of representation of the existing nodes in the system.
Because we are using ROS, we can make use of the rqt graph library5, which automatically generates

4Because our runtime monitors are checking for violation of a property, they return false when no violation is detected.
5rqt graph library: http://wiki.ros.org/rqt_graph Accessed: 15/07/2022

6

Step 1: Abstractthe ROS Graphto a System ModelStep 2: WriteRCL ContractsStep 3: Reason aboutContracts with CalculusStep 4a: HeterogeneousVerification of NodesStep 4b: GenerateRuntime MonitorsFrom RCL Contractsa graph (called a ROS graph) for the system that contains all of its nodes and the communication links
between them. ROS graphs can also display topics and actions (used to execute long-running tasks),
but using only the nodes and communication links is enough for our purposes. If the graph is simple
enough, then we can use it as the system model. However, there are often a large number of nodes in
the graph, and there are often a large number of nodes from well-tested libraries, so we might choose
to abstract the ROS graph into a more manageable system model.

This section describes a methodology that can be followed to generate a more compact system

model based on the ROS graph.

1. Generate the ROS graph: use the rqt graph library to generate a graph of the system. This can
be used “as is” (skip to Step 3 in this methodology) or can be further abstracted as detailed in
the next steps.

2. Remove nodes: we remove all nodes that match the following conditions:

• nodes that are being used oﬀ-the-shelf and have been demonstrated to be reliable in most
cases (e.g., the move base library6 for path planning in ROS) through community experi-
mentation and testing;

• and nodes that are too simple and have no meaningful interaction with the nodes that we

want to verify.

3. Combine related nodes into compound nodes: some nodes may be too simple to verify individually
or make more sense when grouped together with other similar nodes. These nodes are merged
into a compound node, making sure that it retains all the important parts we want to verify and
that it matches the implementation of the original nodes.

4. Add external nodes:

some nodes may be external to ROS, such as programs for autonomy
(e.g., rational agents) and image processing (e.g., machine learning), which are developed in a
programming language not supported in the main distribution of ROS (only Python and C++
are supported). These nodes are added to the system diagram, alongside a description of how
they interact and communicate with the other nodes.

This is not a strict methodology, but an indication of how a more tractable system model can be
distilled. The most important aspect is that the abstracted system model must still resemble the
implementation of the ROS nodes. We provide an example application of our methodology for creating
a system model in §4.1.

3.2 First-Order Logic

Once the system model has been simpliﬁed, we next deﬁne a contract for each node. We use First-Order
Logic (FOL) for these contracts, and in this subsection we describe their structure.

Our contracts use the standard deﬁnition of FOL with quantiﬁers (∀, ∃) and logical connectives (∧,
∨, ¬ , ⇒, ⇔) over logical propositions including basic set theory [43]. For a given node, C , we specify
AC (iC ) and GC (oC ) where iC is a vector of variables representing the input to the node, oC repre-
sents the output from the node, and AC (iC ) (assumption/pre-condition) and GC (oC ) (guarantee/post-
condition) constitute the FOL contract of C . (Note that, when discussing one speciﬁc component, we
often omit the C subscript.)

Complex robotic systems often produce and consume streams of data. Our approach to stream
semantics is based on well-established work in the area of stream logic programming [63, 36]. As in
that case, our streams are essentially lists and a component that consumes elements from such a stream
just takes the ﬁrst element from the stream, processes it and then (recursively) moves to tackling the
rest of the stream. In logic programming style, if the stream is [e | Tail], where e is the ﬁrst element
in the list and Tail represents the remaining elements, then the component handles the individual
element e and then moves on to handling the Tail.

A component contract states that if a node consumes input data i from its input stream (InStream([i |
S])) and AC (i) holds (i.e., i satisﬁes the assumption/pre-condition for correct operation of the node)
then eventually the node will place some data, o on its output stream that satisﬁes the node’s guar-
antee. So if its current output stream was T , i.e. OutStream(T ), before the execution of the node7

6Move Base ROS Library: http://wiki.ros.org/move_base Accessed: 15/07/2022
7T is the sequence of outputs so far.

7

Figure 2: A ﬂow chart showing Vanda’s workﬂow. The boxes with rounded corners represent steps
in the workﬂow, and the solid lines show the ﬂow of control between the steps. The parallelograms
represent input or output ﬁles, and the dotted lines show the ﬁle being input to or output from a step.

functionality on i, then afterwards the output stream will be OutStream([o | T ]) and G(o) will hold.
While our contract assumptions and guarantees are expressed using FOL. We can represent the mean-
ing of the contract by a small extension using the “eventually” operator, ‘♦’ from Linear-time Temporal
Logic (LTL) [54]. Thus ,formally, our contract guarantees the following:

[InStream([i | S]) ∧ A(i) ∧ OutStream(T )]
⇒
♦[InStream(S) ∧ G(o) ∧ OutStream([o | T ])]

for any streams S and T .

The temporal logic element is used to abstract from internal computation/activity. As this is never
instantaneous, and as we do not have precise timing constraints, the execution of one component is
described as eventually completing. Hence the use of the “sometime in the future” temporal operator
‘♦’. Later in the development process, we might reﬁne this very general temporal constraint to more
precise real-time computational properties.

As in Stream Logic Programming, we will have rules to deal with end cases, such as when the
remaining input list/vector is empty. Note that in such cases we might choose to terminate the
processing, to suspend and wait until the list or vector is non-empty, to perform some exception
handling, or undertake any other required computation.

Also, our component can consume, or produce, multiple streams. For example, we might have a
component consuming items from several streams to generate a combined output (on one stream).
Whether we take an item from each stream simultaneously or just take an item from one of the
streams (or any combination of these approaches) will depend on the component, and the component
veriﬁcation should account for this where appropriate. Note that we deliberately say nothing about
the global behaviour of concurrent streams, for example whether one is generated more quickly than
another, instead focusing on the ﬁrst element on each relevant stream. These concurrency aspects might
well be explored in future work but, for this initial investigation, we concentrate on the straightforward
case for clarity of explanation.

Although we use FOL to specify contracts, we require a machine-readable syntax for capturing and

generating monitors for contracts. For this, we introduce RCL in the next subsection.

3.3 Specifying Nodes in the ROS Contract Language

Each ROS topic that the node will use is declared with its type, name, and the input or output variable
that it matches in the contract. RCL recognises the ROS message types and allows custom types (again,
deﬁned in the speciﬁcation’s context clause). Each assumption and guarantee is declared separately,
in a plain-text version of FOL, which uses keywords such as forall and in to represent logical
operators. Table 1 shows a simpliﬁed Extended Backus-Naur form (EBNF) grammar describing the
syntax of an RCL contract. Listing 2 (§4.2) shows one of the RCL contracts we used during this work.
Vanda8 parses RCL ﬁles and can translate them into the LATEX representation, used in this paper;
or into executable monitors, which we use to check the FOL contracts at runtime (see §3.6). It is written
in Python3 and uses the Lark parsing library9. Fig. 2 shows the steps taken (and ﬁles involved) in

8Vanda, which means

‘Oath’

in Quenya,

is available at:

https://github.com/autonomy-and-veriﬁcation/

ros-contract-language/releases/tag/v0.3-tosem Accessed: 29/07/2022

9Lark parsing library: https://github.com/lark-parser/lark Accessed: 15/07/2022

8

start :
contract clause :
context clause :
type declaration :
constant declaration :
type declaration part :
node clause :
inputs :
outputs :
io var :
topic list :

contract clause+
node clause | context clause
"context" "{" (type declaration | constant declaration)+ "}"
STRING ":" type declaration part ";"
STRING "=" type declaration part ";"
? a function declaration, set, sequence, or tuple ?
"node" STRING "{" inputs outputs topic list (assume)* (guarantee)+ "}"
"inputs" "(" (io var ("," io var)*)? ")"
"outputs" "(" (io var ("," io var)*)? ")"
STRING ":" STRING
"topics" "(" (topic ("," topic)*)? ")"

topic : TYPE STRING ("matches" "(" topic match name ")" )?

topic match name :
io pointer :
assume :
guarantee :
formula :
TYPE :
STRING :

io pointer? STRING
"in." | "out."
("assume") "(" formula ")"
("guarantee") "(" formula ")"
? Textual Deﬁnition of FOL ?
? Types from ROS or custom type ?
? Character String?

Table 1: A simpliﬁed description of RCL’s syntax in Extended Backus-Naur form (EBNF). A "|" shows
alternatives, quotation marks shows literals, a "?" shows zero or one instances, a "*" shows zero or more
instances, a "+" shows one or more instances. Descriptions enclosed in "?" show textual descriptions
of the rule.

the conversion of an RCL contract into a monitor. This process comprises three steps, as follows.
(1) parse: use the Lark library to parse a contract ﬁle and, if the contract is well-formed, produce a
parse tree. (2) extract: pre-process the parse tree from step 1 to extract the node name, topics and,
guarantees into a Contract object. (3) translate: a contract translator uses the Contract object
from step 2 to produce the conﬁguration ﬁle and monitor structure. The guarantees are translated
by a FOL translator class, which is a Lark Interpreter that converts the FOL parse tree into the
monitoring language (§3.6).

Vanda is built so as to make it easy to change the input and output formats. The input language
is deﬁned in a Lark grammar, so that we can update RCL if needed. The translation is implemented
by two ﬁles (the contract translator and FOL translator mentioned previously), so updating Vanda
to produce monitors in a diﬀerent formalism should be relatively straightforward.

So far, we have described how contracts for individual nodes are expressed in FOL and discussed
how these are encoded in RCL. Next we present our calculus for reasoning about how speciﬁcations
for individual nodes are combined.

3.4 Calculus for Combining Node Speciﬁcations

Nodes in a (modular) system can be linked as long as their input types and requirements match.
The basic way to describe these structures is to ﬁrst have the contract capture all input and out-
put variables and then describe how they are combined using suitable inference rules. We compose
the contracts of individual nodes in a number of ways, the simplest being sequential composition:

9

∀ i1, o1 · A1(i1) ⇒ ♦G1(o1)

...

(R1)

∀ in, on · An(in) ⇒ ♦Gn(on)
o1 = i2 ∧ . . . ∧ on−1 = in

(cid:18)

(cid:96)

∀ o1, i2 · G1(o1) ⇒ A2(i2)

∧
...
∧

(cid:19)

An(in)

∀ on−1, in · Gn−1(on−1) ⇒ An(in)

(cid:18)

∀ i1, on · A1(i1) ⇒ ♦Gn(on)

(cid:19)

A1(i1)

G1(o1)

1

•
•
•

n

Gn(on)

Rule R1 states that given multiple nodes that are connected in a linear sequence with the output of
the ﬁrst equal to the input of the second (and so on) and if it is possible to show that the guarantee
of the ﬁrst implies the assumption of the second (and so on) then, if the assumptions of the ﬁrst node
holds, we can conclude that the guarantees of the ﬁnal node in the sequence will eventually hold. This
rule provides a basic starting point, however, robotic systems are generally more complex than this,
often including multiple, branching outputs.

∀ i1, o1 · A1(i1) ⇒ ♦G1(o1)

...

(R2)

∀ in, on · An(in) ⇒ ♦Gn(on)
o1 = i2 ∪ . . . ∪ in

(cid:18)

(cid:96)

∀ o1, i2, . . . , in · G1(o1) ⇒ A2(i2)

∧
...
∧

(cid:19)

An(in)

A1(i1)

G1(o1)

1

2

• • •

n

A2(i2)

G2(o2)

An(in)

Gn(on)

(cid:18)

∀ i1, o2, . . . , on · A1(i1) ⇒ ♦G2(o2) ∧ . . . ∧ ♦Gn(on)

(cid:19)

Rule R2 is used when a node has branching outputs. Here, the combined inputs of all of the ‘leaf’
nodes is equal to the output of the ‘root’ node, while the guarantee of the ‘root’ node implies the
assumptions of each ‘leaf’ node, as shown below (where we use the union operator, ∪, to indicate that
the associated vectors of variables are merged).
Rule R3 deals with the converse architecture, where a node’s input is the union of several outputs
from other nodes. As expected, this rule is essentially the dual of R2. Note that there is a simplifying
assumption here: that the outputs persist once generated, according to the ♦ constraint. Under this
assumption, all the required inputs (from nodes 1 to n − 1) will be available at the same time. In
future work, we will consider weakening this assumption, thus adding further timing constraints.

∀ i1, o1 · A1(i1) ⇒ ♦G1(o1)

...

∀ in, on · An(in) ⇒ ♦Gn(on)
in = o1 ∪ . . . ∪ on−1

(cid:18)

(cid:96)

∀ in, o1, . . . , on−1 · G1(o1)

(R3)

A1(i1)

G1(o1)

An−1(in−1) Gn−1(on−1)

1

• • •

n − 1

∧
...
∧

(cid:19)

Gn−1(on−1) ⇒ An(in)

(cid:18)

∀ i1, . . . in−1, on · A1(i1) ∧ . . . ∧ An−1(in−1) ⇒ ♦Gn(on)

(cid:19)

n

An(in)

Gn(on)

These three simple inference rules (R1, R2 and R3) constitute our basic calculus for reasoning

10

about node-level FOL contracts in a robotic system. Note that we are not specifying the ﬁne-grained
concurrency/streaming of processes/data but are just specifying the interface expectations of nodes
in a robotic system. We are only using a fragment of FOTL, in this case the ♦ operator, in order to
represent the abstract notion that some arbitrary time has passed. We can use more of FOTL, and
potentially incorporate real-time or metric fragments, once we relax some of the assumptions; this is
also part of future work. The use of temporal logic provides us with the ﬂexibility to describe and
reﬁne a range of temporal aspects. We assume that contracts are neither mutually dependent, nor
circularly dependant. However, we intend to investigate this in future work and potentially leverage
existing techniques like [28].

Our inference rules describe how node contracts should be interpreted when multiple nodes are
combined in various ways. It is a separate veriﬁcation step to demonstrate that the individual node
itself obeys its own contract and we discuss this in more detail in the next subsection.

3.5 Guiding Heterogeneous Veriﬁcation

In our approach, the contracts can be combined to provide a high-level speciﬁcation of the system’s
requirements. These node-level contracts are used to guide the veriﬁcation of individual nodes, because
a formal link is often diﬃcult or impossible. However, the FOL speciﬁcation, and other information
in the contract, can be used to inform the (formal or non-formal) veriﬁcation process.

Each of the nodes in a system can present its own veriﬁcation challenges when ensuring compliance
with its FOL contract, so the most suitable veriﬁcation method should be chosen for each node.
Some nodes may be amenable to formal veriﬁcation, such as an agent that can be model checked for
correctness properties (as in our previous work [12]). Other nodes may be based on neural networks,
for example vision classiﬁers, which might require speciﬁc testing approaches [42]. Some nodes might
be more critical to the system’s safety requirements than others, these nodes are likely to be the focus
of the most robust formal veriﬁcation (as we suggest in [50, 48]). Our approach leaves the veriﬁers
to make the choice of the most suitable veriﬁcation methods, since they are best placed to make this
decision.

Our approach supports developing a system from abstract speciﬁcations. Specifying what a system
should do is often the most time-consuming part of the formal veriﬁcation process [57]. Therefore,
reusing a speciﬁcation throughout the development process makes that initial eﬀort more worthwhile.
The high-level speciﬁcation provided by our contracts can be used as a guide or a target for what
properties a particular node should obey.

When developing a system from an abstract speciﬁcation, a developer can start by specifying a high-
level contract for a node’s basic behaviour, and then verify more concrete properties about the node’s
functionality using their chosen veriﬁcation method. For example, a high-level contract for a planner
might require that all the plans it produces are obstacle-free, but the detailed planner veriﬁcation
might also verify that all points in the plan are valid (e.g. within the map), that the planner does not
deadlock, or that the plan conforms to some measure of optimality. These are similar to some of the
properties that were veriﬁed about a planner in [8].

Crucially, our approach enables a system to be veriﬁed using a range of veriﬁcation techniques
without needing to decide beforehand which techniques will be used. As mentioned in §1, using a
variety of heterogeneous veriﬁcation techniques on one system can be beneﬁcial, particularly in the
robotics domain [49, 29, 12, 8, 30].

The path from an RCL contract to formal veriﬁcation is fairly clear, as we describe in §4. Some
formal methods are also based on FOL and sets, so the guarantees in the contracts can be checked
directly. Whereas, for other methods, more eﬀort may be needed to capture the contract’s properties in
its speciﬁcation language. In either case, the contract describes the properties that the chosen formal
method must check.

The path from an RCL contract to non-formal veriﬁcation is made easier because each contract
provides an unambiguous speciﬁcation of a node’s requirements. A suitably skilled test engineer should
be able to, for example, create software tests or simulation scenarios (etc) that check the node for the
properties described in the guarantee. Having this formal speciﬁcation helps reduce the risk of verifying
the ‘wrong’ properties.

11

conﬁg.yaml

instrument

ROS

nodes

log.txt

oﬄine

oracle

online

spec

monitor.py

Figure 3: High-level overview of ROSMonitoring [31].

3.6 Runtime Veriﬁcation

Runtime Veriﬁcation (RV) is a lightweight formal veriﬁcation technique [46]. RV checks the behaviour
of the system under analysis while it is running. This is achieved via runtime monitors, which are
generated from formal speciﬁcations. Speciﬁcally, a monitor analyses the traces produced by the
system’s execution and concludes the satisfaction (or violation) of the formal property.

RV is a non-exhaustive veriﬁcation approach;

it only checks the current trace of the system’s
state space, therefore the monitor’s verdict can only relate to what it has observed. Nevertheless, in
contrast to other techniques, RV can be applied both before and after deployment; which means that
the monitor can be present all the time, ready to catch (and report) property violations. Moreover,
no model of the environment is required, since the monitors do not need to know how the system is
implemented (it can be treated as a black-box), but only how to gather the trace generated by the
system. This also allows us to use much more complex reasoning, if required.

The system may act in an unexpected way, and even worse, the system-level properties derived
from the inference rules (§3.4) might no longer hold. This is an even greater problem when there are
components that are attached to the faulty one, since a violation of a guarantee (resp. an assumption)
can render the derived system-level properties invalid. A possible way to tackle this problem is by
introducing a safety net of monitors, where each contract in the topology is monitored at runtime. This
safety net ensures that the nodes conform to their contracts, and consequently, support the inferred
system-level properties. Since RV can be used at runtime and can be applied to opaque systems, it
was the most suitable candidate for creating the safety net.

To achieve RV of ROS systems, we use the formalism-agnostic general-purpose framework, ROS-
Monitoring [31]. The monitors used by ROSMonitoring follow a standard publish/subscribe pattern.
Each monitor is a ROS node that subscribes to the topics needed to observe the behaviour that is
relevant it its property, and informs the system when a violation is observed (by publishing a message).
We chose ROSMonitoring because it can be used without any modiﬁcation in various versions of ROS,
In
and its monitors can be easily distributed in the system to check the contracts for each node.
comparison to ROSRV [41], another RV framework for ROS, ROSMonitoring is more lightweight and
supports more recent distributions of ROS.

RCL topics to ROSMonitoring conﬁguration ﬁle

ROSMonitoring takes a conﬁguration ﬁle as input (see Fig. 3) where the user speciﬁes the nodes
and the topics that will be analysed by the monitors. This conﬁguration ﬁle can be automatically
generated from an RCL speciﬁcation. To generate a conﬁguration ﬁle for ROSMonitoring, the only
required information is the name of the topics to monitor and their message types. An example of a
conﬁguration ﬁle is shown later when we describe the case study (§4.5).

Given a conﬁguration ﬁle, ROSMonitoring generates one (or multiple) runtime monitor(s) and
changes the system nodes accordingly, i.e., to allow the monitors to intercept the message exchange
needed for the veriﬁcation. The remaining part of Fig. 3 denotes the other most important component
of ROSMonitoring, the Oracle. It represents the formal part of the monitor and it is where the formal
properties of interest are deﬁned. ROSMonitoring supports diﬀerent formalisms for deﬁning properties;

12

we chose the Runtime Monitoring Language (RML) [3] because the translation from RCL to RML was
the most intuitive and direct.

From RCL guarantees to RML

The formal part of a ROSMonitoring monitor that represents the properties to verify is decoupled and
can be speciﬁed with any formalism. In this work, we used one of the default formalisms available,
called RML. RML is a domain-speciﬁc language for RV which is able to express non context-free
properties. RML supports parametric speciﬁcations which makes it suitable for describing contracts.
The detailed syntax and semantics of RML can be found in [3]; here, we use an abstraction of RML
to improve readability, but the resulting translation technique also applies to standard RML.

An RML property is a tuple (cid:104)t, ETs(cid:105), with t a term and ETs = {ET1, . . . , ETn} a set of event
types. An event type ET is represented as a set of pairs {k1 : v1, . . . , kn : vn}, where each pair
identiﬁes a speciﬁc piece of information (ki) and its value (vi). Given an event type ET , an event
m} as well, matches ET if ET ⊆ Ev, which means
Ev, denoted as a set of pairs {k (cid:48)
∀(ki : vi) ∈ ET · ∃(kj : vj) ∈ Ev · ki = kj ∧ vi = vj.
In practice, an event type ET speciﬁes the
requirements an event Ev has to satisfy to be considered valid. For instance, an event type ET could
be {pos : (waypoint1)}, meaning that all events containing pos with value (waypoint1) are valid. An
event Ev generated by a moving robot could be {speed : 1.6, pos : (waypoint1)}, meaning that the
robot is moving at speed 1.6 [m/s], and is currently at position (waypoint1).

1, . . . , k (cid:48)

m : v(cid:48)

1 : v(cid:48)

An RML term t can be:
• ET , denoting a singleton set containing the events Ev s.t. ET ⊆ Ev
• t1 t2, denoting the concatenation of two sets of traces
• t1 ∧ t2, denoting the intersection of two sets of traces
• t1 ∨ t2, denoting the union of two sets of traces
• {let x; t(cid:48)}, denoting the set of traces t(cid:48) where the variable x can be used
• t(cid:48)∗, denoting a chain of concatenations of trace t(cid:48)

where t1, t2 and t(cid:48) are RML terms.

Event types can be negated. Given an event type ET , the term ¬ ET denotes its negation.
Speciﬁcally, ∀Ev .ET ⊆ Ev ⇔ ¬ ET (cid:42) Ev. In the rest of the paper, we also apply the notion of negation
to the other RML terms. For instance, if the term is ET1 ∧ ET2, its negation is ¬ ET1 ∨ ¬ ET2; and
the same reasoning is applied for the other operators.

Event types can contain variables. Considering the previous event type, we could have its para-
metric version as ET (x) = {pos : (x)}, where we do not force any value for the waypoint. This event
type matches all events containing pos with any x value. When an event matches an event type with
variables, the variables get the values from the event.

An example of the possible use of RML to deﬁne contracts is as follows, we could have the term
ET1ET2 ∨ ET3ET4, with ETi being some event type describing a certain kind of event (as before).
However, diﬀerently from before, here, we have a union of two concatenations; which means the
language recognised by such term is

{Ev Ev(cid:48)

| ET1 ⊆ Ev, ET2 ⊆ Ev(cid:48)} ∪ {Ev Ev(cid:48)

| ET3 ⊆ Ev, ET4 ⊆ Ev(cid:48)}

Naturally, the same reasoning can be applied to the ∧ operator; the only diﬀerence would be in using
∩ instead of ∪.

Contracts are translated into RML speciﬁcations using our customised contract translator. This
translator takes the Contract object generated by Vanda, and translates it to an equivalent RML
speciﬁcation. Since RML deﬁnes a set of event traces, the translator has to identify which events
satisfy the guarantees and to build the set of event traces.

The operational semantics of the translation function can be found in Appendix C.

13

Figure 4: Simulation environment of the remote inspection case study. On the left-hand side is the
Gazebo 3D simulation window. On the top right-hand side is the RViz window, a visualisation interface
containing the map that the rover uses for path planning, a visual representation of radiation levels
(green, orange, red) around the robot, and the waypoints from 0 to 12 that the robot must inspect.
On the bottom right-hand side is the autonomous agent console with the log of its execution.

4 Case Study: Remote Inspection

Our case study is a Jackal 10 rover performing remote inspection in a nuclear waste store, in a 3D
Gazebo11 simulation. The Jackal uses a (simulated) sensor to take radiation measurements at given
waypoints. We adapted this case study from the simulation described in [66], adding an autonomous
agent that makes the high-level decisions that control the Jackal.

The rover’s goal is to patrol 13 waypoints that are located inside the simulated nuclear waste store
(see Fig. 4). The autonomous agent decides which waypoint to inspect next, depending on the current
radiation readings. It should always be aware of high radiation values, since this could put the robot
in danger, as well as indicating a problem in the waste store that requires further investigation. The
rover’s battery is not simulated, so we assume that the rover has enough power for the duration of the
scenario. We use the ROS move base package for low-level path planning.
At a high level, we can specify the system’s requirements as follows.

REQ1: The robot should inspect each waypoint as long as the radiation level at a waypoint is not

high (“red").

REQ2: Each waypoint only needs to be inspected at least once.

REQ3: If the radiation level at a waypoint is too high, then the robot will abandon the mission and

return to the entry point.

REQ4: Eventually, the mission terminates successfully, with all waypoints inspected; or in failure,

due to high level of radiation.

In what follows, we describe how to apply our approach to the remote inspection case study, from the
manual speciﬁcation of the contracts to the automatic generation of runtime monitors.

10Jackal: https://clearpathrobotics.com/jackal-small-unmanned-ground-vehicle/ Accessed: 15/07/2022
11Gazebo Simulator: http://gazebosim.org/ Accessed: 15/07/2022

14

4.1 Step 1: Creating a System Model

In this section we describe how we generated the system model for the remote inspection case study.
Fig. 5 shows the ROS graph of the remote inspection robotic system (minus the autonomous agent,
because it is not programmed using ROS). As described in §3, we often ﬁnd it helpful to adapt the
ROS graph to produce a system model that is more amenable to analysis and veriﬁcation.

Here, most of the nodes are well-tested oﬀ-the-shelf libraries, such as the Jackal velocity controller
and the move base library. The former relates to the Jackal’s internal velocity controllers, while the
latter provides a suite of path planners. Both relate to the robot’s navigation, and thus we abstract
them into a compound node called Navigation. Similarly, we merge the nodes imu and odometry,
into the Localisation compound node. We obtain the Radiation Sensor node in a similar way.
Finally, because the autonomous agent is external to the ROS system, we create the Agent node as
an abstraction of its implementation. Thus, the system model is composed of these four abstracted
nodes, shown in Fig. 6 and described below.
Localisation: abstracts the Adaptive Monte Carlo Localisation (AMCL) ROS package12, which uses
sensor input to perform localisation. This is a well established package, so we do not deﬁne a contract
for its speciﬁcs. Instead, it is enough (for our purposes) to know that the node will output what it
believes to be the robot’s position. The Localisation node takes input from hardware (a variety
of sensors), but our contracts focus on the links between the software nodes; so it is enough for our
contracts to specify its input as ∅ (deﬁned as SensorsType in the speciﬁcation’s context clause,
because the inputs and outputs are name-type pairs), knowing that the node will be able to access the
sensor information.
Navigation: abstracts the well known move base package, which performs low-level path planning.
Its inputs are the estimated position from the Localisation node, and the command from the Agent
node to move to a particular position. It then outputs the end position that the robot is located at.
Agent: the most critical node to verify; because it makes the high-level decisions for the robot,
and its implementation is not based on preexisting packages. The agent is implemented in the agent
programming language Gwendolen [23]. Its inputs are the output of the Navigation and Radiation
Sensor nodes. It outputs a high-level command (either move or inspect).
Radiation Sensor: takes as input a radiation measurement r from its internal sensor and the com-
mand from the Agent to inspect a particular waypoint i. It outputs a conﬁrmation that a particular
waypoint has been inspected.

Once the model has been distilled, the next step is to deﬁne contracts for the individual nodes.

4.2 Step 2: Specifying Node Contracts

This step builds the contracts used to guide the heterogeneous veriﬁcation and to enable synthesis of
the runtime monitors. Each contract is written in RCL (described in §3.3), and consists of a node’s
inputs, outputs, assumptions, and guarantees (which are all written in a plain-text encoding of FOL).
A contract also links the inputs and outputs to the topics in the underlying ROS program.
1 context
2 {
3

WayP : REAL x REAL --> NATURAL ;
RadStat : {red, orange, green} ;
CommandSet : { move(REAL, REAL), inspect(NATURAL) };
PositionType : REAL x REAL --> BOOL ;
AtType: REAL x REAL --> BOOL;
InspectedType : NATURAL --> BOOL;
SensorsType : {};

4

5

6

7

8

9
10 }

Listing 1: The Context clause for the RCL contracts. This deﬁnes global types and constants.
As an example,Listing 1 shows the context clause that deﬁnes the types and constants used in
the speciﬁcation of our case study and Listing 2 shows the RCL contract for the Agent node. In the
Agent’s contract, Listing 2, lines 3 and 5 identify the node’s inputs and outputs, respectively.

12Adaptive Monte Carlo Localisation package: http://wiki.ros.org/amcl Accessed: 15/07/2022

15

Figure 5: ROS graph automatically generated for the remote inspection case study.

16

Localisation

iL: sensors : SensorsType
oL: position : PositionType

Context
WayP : R × R → N
RadStat : {red, orange, green}
CommandSet : {move(R, R), inspect(N)}
PositionType : R × R → B
AtType : R × R → B
InspectedType : N → B
SensorsType : ∅

Navigation

Agent

iN : position : PositionType,
command : CommandSet

oN : at : AtType

iA: wayP : WayP, at : AtType,
radiationStatus : RadStat,
inspected : InspectedType
oA: command : CommandSet

Radiation Sensor

iR: r : REAL, command : CommandSet
oR: radiationStatus : RadStat,
inspected : InspectedType

Figure 6: System model for the remote inspection case study. Arrows indicate data ﬂow between the
nodes.

1 node agent {
2
3 inputs( wayP : WayP, at : AtType, radiationStatus : RadStat, inspected : InspectedType )
4
5 outputs( command : CommandSet )
6
7 topics(
8 gazebo_radiation_plugins/Command command matches(command),
9 gazebo_radiation_plugins/Inspection inspected matches(inspected),
10 gazebo_radiation_plugins/At at matches(at),
11 int16 wayP matches(wayP),
12 string radiationStatus matches(radiationStatus) )
13
14 assume( radiationStatus in {red, orange, green} )
15
16 guarantee(
17 forall(x’, y’ in REAL, i in NATURAL |
18

at(x’, y’) == TRUE and wayP(x’, y’) == i and inspected(i) == TRUE and radiationStatus !in {red,

orange} ->

exists(x, y in REAL | wayP(x, y) == i + 1 and command == move(x, y) )

at(x’, y’) == TRUE and wayP(x’, y’) == i and inspected(i) == FALSE -> command == inspect(i)

19
20 )
21
22 guarantee(
23 forall(x’, y’ in REAL, i in NATURAL |
24
25 )
26
27 guarantee(
28 forall(x’, y’ in REAL, i in NATURAL |
29

30

31
32 )
33 }

radiationStatus in {red, orange} or not exists( x, y in REAL | wayP(x, y) == i + 1 )
-> exists (x’’, y’’ in REAL | wayP(x’’, y’’) == 0 and command == move(x’’, y’’) )
)

Listing 2: The Agent’s RCL contract.

Lines 7–12 show the ROS topics that the Agent’s implementation uses and which input or
output they correspond to (in the matches statement), using both built-in types (e.g. Int16) and
custom types that were deﬁned in the underlying ROS system. On line 14, the assume statement
contains the assumption of the Agent’s contract. From line 16 onwards, the guarantee statements
contain a plain-text encoding of the Agent’s FOL guarantees. The overall links between the four
nodes, and the inputs and outputs that link them, are shown in Fig. 6.

Tables 2, 3, 4, and 5 summarise the inputs, outputs, assumptions, and guarantees of each contract.
The tables describe the statements in the contract in English, and then shows the relevant part of
the contract. The FOL has been rendered mathematically for the convenience of the reader. The full
contracts, in RCL, are shown in Appendix A.

The information contained in the contracts is useful for guiding both formal and non-formal ver-
iﬁcation of the nodes, as we describe later in §4.4. Vanda, the RCL tool, can also automatically

17

Localisation

Input

Output

Assume

Input from hardware (a variety of sensors)

Text
FOL sensors : SensorsType
Text The robot’s estimated position
FOL position : PositionType
Text N/A
FOL TRUE
Text The node outputs a unique (x, y) coordinate that is the robot’s estimated

Guarantees

position

FOL ∃!x, y ∈ REAL • out.position(x, y)

Table 2: A summary of the Localisation node’s inputs, outputs, assumptions, and guarantees.

Navigation

Input

Output

Assume

Guarantees

Text Robot’s estimated position from the Localisation node, and the command

from the Agent node

FOL position : PositionType,
Text Robot’s position
FOL at : AtType
Text There is a unique (x, y) coordinate position that represents the Robot’s esti-

command : CommandSet

mated position

FOL ∃!x, y ∈ REAL • in.position(x, y) = TRUE
Text

If the Robot is told to move to (x, y) and the Localisation node says that
the Robot is at (x, y); then Navigation will conclude that it is at (x, y)
∀ x, y ∈ REAL•

FOL

( (in.command = move(x, y)) ∧ (in.position(x, y) = TRUE) )
⇔ out.at(x, y) = TRUE

Table 3: A summary of the Navigation node’s inputs, outputs, assumptions, and guarantees.

synthesise runtime monitors from the contracts, which we describe in §4.5.

In the next step, we use our calculus to derive system-level properties from the individual node con-
tracts.

4.3 Step 3: Deriving System-Level Properties

In this section, we give an example of how our calculus (§3.4) works by presenting the manual derivation
of one of the system-level properties from the contracts.

We start with the Agent node, which takes input from the Navigation and Radiation Sensor.

Because Agent takes several inputs, we instantiate R3, the input union rule, to get D1:

∀ iN , oN · AN (iN ) ⇒ ♦GN (oN )
∀ iR, oR · AR(iR) ⇒ ♦GR(oR)
∀ iA, oA · AA(iA) ⇒ ♦GA(oA)
iA = oN ∪ oR

(cid:18)

(cid:96)
(cid:18)

∀ iA, oN , oR · GN (oN ) ∧ GR(oR) ⇒ AA(iA)
(cid:19)

∀ iN , iR, oA · AN (iN ) ∧ AR(iR) ⇒ ♦GA(oA)

(D1)

(cid:19)

To apply rule R3, we must show that we can deduce that the guarantees of the Navigation and
Radiation Sensor nodes imply the assumption of the Agent node: ∀ iA, oN , oR ·GN (oN ) ∧ GR(oR) ⇒

18

Input

Output

Assume

Guarantees

Agent

Text The map of waypoint coordinates to ids, the Robot’s positions from the Nav-
igation node, and the Radiation Status and inspected values from the Ra-
diation Sensor
FOL wayP : WayP,

radiationStatus : RadStat,

inspected :

: AtType,

at

InspectedType

Text The command (move or inspect)
FOL command : CommandSet
Text The Radiation Status that it receives is either red, orange, or green
FOL in.radiationStatus ∈ {red, orange, green}
Text

If the Robot is at waypoint i, and i has been inspected and the radiation
level was not dangerous, then the Robot will move to the next waypoint
∀ x (cid:48), y(cid:48) ∈ REAL, i ∈ N•

FOL

( (in.at(x (cid:48), y(cid:48)) = TRUE) ∧ (in.wayP(x (cid:48), y(cid:48)) = i
∧ (in.inspected(i) = TRUE) ∧ (in.radiationStatus /∈ {red, orange}) )
⇒ (∃ x, y ∈ REAL•

in.wayP(x, y) = i + 1 ∧ out.command = move(x, y))

Text And, if the Robot is at waypoint i and it has not been inspected, then the

Robot will inspect it.
∀ x (cid:48), y(cid:48) ∈ REAL, i ∈ N•

( (in.at(x (cid:48), y(cid:48)) = TRUE)

FOL

∧ (in.wayP(x (cid:48), y(cid:48)) = i)
∧ (in.inspected(i) = FALSE) )

⇒ out.command = inspect(i)

Text And, if the Robot inspects a waypoint and the radiation level is dangerous,

then the Robot will return to the original waypoint (the exit)
∀ x (cid:48), y(cid:48) ∈ REAL, i ∈ N•

FOL

((in.radiationStatus ∈ {red, orange})

∨ (¬ ∃ x, y ∈ REAL•
in.wayP(x, y) = i + 1) )

⇒ (∃ x (cid:48)(cid:48), y(cid:48)(cid:48) ∈ REAL • (in.wayP(x (cid:48)(cid:48), y(cid:48)(cid:48)) = 0)
∧ (out.command = move(x (cid:48)(cid:48), y(cid:48)(cid:48)) ) )

Table 4: A summary of the Agent node’s inputs, outputs, assumptions, and guarantees.

Radiation Sensor

Input

Output

Assume

Guarantees

FOL

Text The radiation value from the sensors, and the command from the Agent
FOL r : REAL, command : CommandSet
Text Radiation Status and if this waypoint has been inspected or not
FOL radiationStatus : RadStat,
Text The radiation from the sensors is less than or equal to 0
FOL 0 ≤ in.r
Text

inspected : InspectedType

If the command received was to inspect waypoint i, then eventually waypoint
i will be inspected; and the radiation at waypoint i will be categorised as
either green, orange, or red
∀ i ∈ N • (in.command = inspect(i))
⇒ ( (out.inspected(i) = TRUE)

∧ (0 ≤ in.r ∧ in.r < 120 ⇒ out.radiationStatus = green)
∧ (120 ≤ in.r ∧ in.r < 250 ⇒ out.radiationStatus = orange)
∧ (250 ≤ in.r ⇒ out.radiationStatus = red) )

Table 5: A summary of the Radiation Sensor node’s inputs, outputs, assumptions, and guarantees.

19

AA(iA). For these three nodes, this is instantiated as:

∀ iA, oN , oR · [∀ x, y ∈ R · command = move(x, y) ∧ position(x, y) = true ⇔ at(x, y) = true]
∧ [∀ i ∈ N · command = inspect(i) ⇒ (inspected(i) = true ∧

∧ (0 ≤ r < 120 ⇒ radiationStatus = green)
∧ (120 ≤ r < 250 ⇒ radiationStatus = orange)
∧ (250 ≤ r ⇒ radiationStatus = red))]
⇒ radiationStatus ∈ {red, orange, green}

which is true by virtue of our deﬁnition of radiationStatus.

Applying R3 here here allows us to conclude that if the nodes are correctly linked (by showing
that the property after the (cid:96) in D1 holds) then we can say that the correct input to the Navigation
and Radiation Sensor nodes will result in the guarantee of the Agent being preserved. Thus, the
system-level property that we derive is:

∀ iN , iR, oA · (∃!x, y ∈ R · position(x, y) = true) ∧ (0 ≤ r) ⇒ ♦GA(oA)
which tells us that when the robot is in a valid, unique position; and the observed radiation level is valid;
then eventually the guarantee of the Agent will hold. This demonstrates that the Agent’s guarantee
is dependent on the correct input and functioning of the Navigation and Radiation Sensor nodes.
The Agent guarantees (see Table 4) that all of the waypoints are inspected, unless dangerous levels
of radiation are detected by the Radiation Sensor. This guarantee directly supports requirements
REQ1, REQ2, and REQ3; described in the introduction to this section. Though this contract does not
contain termination, the combination of satisfying REQ1 and REQ3 implies the satisfaction of REQ4.

4.4 Step 4a: Heterogeneous Veriﬁcation

This section describes our veriﬁcation of the four nodes in our remote inspection case study. Each
node presents its own veriﬁcation challenges, and we have chosen a suitable approach to verify that
each node obeys its contract. As mentioned in §3.5, the link between the contracts and the veriﬁcation
steps is not formal. The information in the contracts informs the veriﬁcation steps, enabling us to use
either formal or non-formal methods as best suits the node being veriﬁed.

4.4.1 Localisation Node

The Localisation node’s contract speciﬁes that it should output a unique position (∃! x, y ∈ R ·
Position(x, y)). We veriﬁed this property using code review.

Verifying that the Localisation node does not return more than one position involves demonstrat-
ing that noise from the sensors does not change the position estimate if the robot has not moved. In
practical terms, it might be necessary to allow a short time-window in which the node could obtain
several sensor readings before converging on a single position estimate.

The Navigation node’s contract (which we verify in §4.4.2) speciﬁes that after reporting that the
robot has moved to some location (x, y), it is actually at (x, y); which we verify experimentally. It
would have been tempting to take a similar route here; however, the 3D Gazebo simulation of the
nuclear waste store does not simulate noisy sensors (i.e., in any given position the value returned by
the simulated sensors was deterministic). Therefore, the position estimates do not change and while
we could have veriﬁed this, it would not necessarily have told us anything useful.

Code review was chosen because of the previously mentioned limitations of the simulation and
because the Localisation node relies on well-used ROS libraries. We inspected the code in the
Localisation node and observed that the message speciﬁcation for the node could only return one
position at a time.

While a code review was enough for the purposes of this paper, stronger demonstrations may be
needed for (e.g.) regulatory approval. For example, the performance of the Localisation node could
be tested on a physical robot operating in a safe, test environment. We could specify a time window,
after which a position estimate should have converged to a single value (or a set of values all within
acceptable bounds of each other) and then test, using a number of routes around the mapped space,
that this behaviour occurred.

20

4.4.2 Navigation Node

The Navigation node’s contract speciﬁes that if there was a command to move to a position (x, y)
and the estimated current position of the rover is (x, y), then the rover has successfully arrived at its
destination. We veriﬁed this experimentally in simulations.

Our veriﬁcation used the 3D Gazebo simulation of the nuclear waste store as our test environment,
and we created an autonomous agent that would take a random location within the waste store,
navigate to that location and stop. We were then able to compare the goal location with the robot’s
actual position within the store, as reported by Gazebo.

The random location was generated as an action available to the agent in the Java environment
that linked it to ROS. This used Java’s built-in random number generation to select an x and a y
coordinate within the the waste store map — random coordinates were regenerated if the original pair
were in some inaccessible location, such as one of the tanks or pillars.

In total, we ran 47 experiments. On average the ﬁnal location of the agent was 21.4cm away
from the goal location with a standard deviation of 4mm. The worst result was a ﬁnal position 43cm
away from the goal location and the best result was 8cm from the goal location. The small standard
deviation here implies that the simulated Jackal nearly always ends up approximately 21cm away from
its goal location. From a veriﬁcation perspective, for this component to meet its contract we must
decide whether a 21cm error counts as having “arrived at its destination”. If this is within tolerance
then the component has met its contract, if it is not then the component has not. In our case we had
speciﬁcally conﬁgured movebase to have a 25cm tolerance for the controller in the x and y coordinates
when achieving a goal, and so we can conﬁrm that the node meets its contract.

Other Veriﬁcation Approaches to Localisation, Mapping and Navigation

Robotic systems often contain a module for Simultaneous Localisation and Mapping (SLAM), which
can be targeted by speciﬁc veriﬁcation techniques [13, 14]. Given an estimate x (i.e., a solution returned
by a state-of-the art iterative solver), the veriﬁcation approach evaluates whether x corresponds to a
global optimum of a cost function f (x). If the answer is positive, then the estimate can be trusted; if the
answer is negative, then some recovery technique needs to be performed, because the estimate is not
accurate and it is not safe to use. Moreover, this veriﬁcation technique can be integrated seamlessly in
standard SLAM pipelines, and provides a sanity check for the solution returned by standard iterative
In [9] an improved extension builds upon the work from [13, 14] and introduces a novel
solvers.
formulation leading to a higher eﬃciency, reducing veriﬁcation times by up to 50 times. SLAM relies
on nonlinear iterative optimisation methods that in practice perform both accurately and eﬃciently.
However, due to the non-convexity of the problem, the obtained solutions come with no guarantee of
global optimality and may get stuck in local minima.

Other approaches targeting SLAM systems include [38, 27], which are more experimental works
that focus more on testing rather than veriﬁcation of SLAM. Also, in [61], a mathematical model is
developed for SLAM veriﬁcation and for physical model operation in the environment.

Our Localisation and Navigation nodes combine a SLAM capability with a navigation capability,

without an explicit SLAM module so these approaches were not appropriate here.

4.4.3 Agent Node

The Agent node makes the high-level decisions for the robot.
It is implemented in the Gwen-
dolen [24] agent programming language and we use the agent-program model checker Agent Java
PathFinder (AJPF) [25] to verify its decisions. AJPF is an extension of Java PathFinder (JPF) [64]
that enables formal veriﬁcation of Belief-Desire-Intention (BDI)-based [56] agent programs by provid-
ing a property speciﬁcation language that is based on LTL, extended with BDI constructs.

In the BDI model, agents use their beliefs (information that the agent believes about the world)
and desires (a goal state that the agent wants to achieve) to select an intention for execution. To
verify that the Agent node obeys its contract, we encode its guarantees into the property speciﬁcation
language for AJPF and check that the agent program meets these speciﬁcations.

The main parts of the Gwendolen code for the Agent13 are shown in Listing 3. The agent

13The speciﬁcation is available in the Zenodo repository:

https://doi.org/10.5281/zenodo.6941344 Accessed:

29/07/2022

21

1 +!inspect(Location) : { ~B danger_red, ~B danger_orange, ~B going(0),
2

B location_coordinate(Location,LocationName,X,Y,Z) }

3

<- +going(Location), move(X,Y,Z);

4
5 +movebase_result(Id,3) : { B going(L1), B next_location(L1, L2) }
<- -going(L1), inspect, +!inspect(L2);
6
7 +movebase_result(Id,3) : { B going(0) }
8
9 +movebase_result(Id,2) : { B going(Location) }
10

<- print("Decontamination"), do_nothing;

<- print("Failure");

11
12 +danger_red : { ~B going(0), B location_coordinate(0,door,X,Y,Z) }
13
14 +danger_orange : { ~B going(0), B location_coordinate(0,door,X,Y,Z) }
15

<- +going(0), move(X,Y,Z);

<- +going(0), move(X,Y,Z);

Listing 3: Partial code of the Gwendolen agent.

starts with a list of static beliefs, such as location coordinate that takes as parameters a location’s
numerical identiﬁer (Location variable), name, and its map coordinates; and next location, with two
location identiﬁers as parameters, where the second parameter is the next location to visit after the
ﬁrst parameter.

The inspect(Location) plan (line 1) is triggered by the addition of the goal inspect.
When the system starts, the Agent begins with a goal to inspect location 1. The guard (e.g.,
context or pre-conditions) of the plan is expressed inside the curly brackets. Here, the guard is
that the Agent does not have the beliefs danger red, danger orange, or going(0); where
the ﬁrst two beliefs indicate that there is radiation in the current location, and the latter is a
bookkeeping belief used to track the location that the robot is moving towards (0 indicates the
entrance of the nuclear waste store, which is also the decontamination zone). The last belief,
location coordinate(Location,LocationName,X,Y,Z), is a query to the belief base which
will use the Location value (obtained from calling the plan, e.g., 1 when the system starts) to match
with its respective belief in the belief base and in turn unify the remaining open variables (e.g., search
for a location coordinate belief where the Location term is 1, and then unify the remaining
open variables with the values from the matched belief). If the guard test is successful, then the plan
body (preceded by <−) is selected for execution. The plan body is executed sequentially, in this case
ﬁrst the bookkeeping belief going is added (+) and then the action move is called with the coordinates
of the desired location.

The second plan, movebase result(Id,Result) on line 5, has three variations. All of them
are triggered by adding the movebase result belief, which reports that the robot’s movement
(controlled by the move base library) is complete, with the second parameter indicating either success
(value 3) or failure (value 2). The ﬁrst variation (lines 5–6) is the main plan, which tests where
the rover was going before the action succeeded (going(L1)) and where the next location is, and
then removes the outdated bookkeeping belief, performs the inspect action, and then adds the goal
to inspect the next location. The second variation (line 7) is for when the robot is moving to the
decontamination and should thus not take any additional actions. The third variation (line 9) is for
when a move action fails, in which case we simply log that it has failed.

Finally, the third (line 12) and fourth plans (line 14) are triggered by the addition of the beliefs
danger red or danger orange, respectively. In both cases we test that we are not yet heading to
the entrance (going(0)) and get its coordinates from the belief base. Then, if the test succeeds, we
add the bookkeeping belief and send the move action for execution (this is published in a ROS topic
that is subscribed to by a move base node).

Using AJPF, we prove that the following properties hold14. Properties ϕ1 to ϕ3 map to the Agent’s
contract, shown in Listing 2, and ϕ4 is an additional property that we are able to verify because at
this stage of the system’s development we know the details of its implementation.

ϕ1 = (cid:50)((Bjackal going(4) ∧ Bjackal movebase result( , 3) ∧ ¬ Bjackal danger red ∧

¬ Bjackal danger orange ∧ ¬ Bjackal going(0)) ⇒ ♦Gjackalinspect(5))

Property ϕ1 deals with the Agent’s ﬁrst guarantee (lines 16–20 in Listing 2), where it is always the

14Note that predicates speciﬁed in formal properties in AJPF must be ground, thus we present this limited set of
properties as representatives, but the complete set includes all viable permutations of waypoints that we want to prove.

22

1 i n p u t := r a d i a t i o n _ a t ( i )
2 IF ( i n p u t < 1 2 0 ) THEN
output := g r e e n

3
4 ELSE

5

6

7

8

IF ( i n p u t < 2 5 0 ) THEN
output := o r a n g e

ELSE

output := r e d

Listing 4: Program for the radiation sensor node.

case that if the agent believes it is going to waypoint 4 and the result of the movement was successful
and there is no danger of radiation nor the robot is moving to the decontamination waypoint, then
eventually the agent will have the goal to inspect waypoint 5 (the next waypoint on the list). The goal
to inspect a waypoint includes both movement and inspect actions.

ϕ2 = (cid:50)((Bjackal going(4) ∧ Bjackal movebase result( , 3) ∧ ¬ Bjackal danger red ∧

¬ Bjackal danger orange ∧ ¬ Bjackal going(0)) ⇒ ♦Djackalinspect)

Property ϕ2 corresponds to the second guarantee (Lines 22–25 in Listing 2), and it is the same as ϕ1
up to the implication, but in this case it implies that eventually the agent will execute the inspect
action.

ϕ3 = (cid:50)(Bjackal danger red ∨ Bjackal danger orange ⇒ ♦Bjackal going(0))
Property ϕ3 covers the third guarantee (lines 27–31 in Listing 2), that is, it is always the case that if
the agent believes the radiation level to be either red or orange, then it should eventually believe that
it is moving to the decontamination zone (waypoint 0).

ϕ4 = (cid:50)(Gjackalinspect(4) ∧ (¬ Bjackal danger red ∧ ¬ Bjackal danger orange ∧

¬ Bjackal going(0)) ⇒ ♦Bjackal going(4))

Property ϕ4 is an additional property that was identiﬁed while implementing the agent; it is not part
of the contract, but has been added to address an additional lower-level requirement. It says that it is
always the case that if the agent has a goal to inspect waypoint 4 and there is no danger of radiation
nor the robot is moving to the decontamination waypoint, then eventually the agent believes that it
is going to waypoint 4. This additional property was added to make sure that whenever an agent has
the goal to inspect a waypoint, the corresponding belief that the agent has started moving to it has
also been added.

4.4.4 Radiation Sensor Node

The Radiation Sensor node interprets information from the (simulated) radiation sensor, categorising
the values into either green (low), orange (medium), or red (high). We modelled the behaviour of
the Radiation Sensor as a simple program in a Hoare Logic-style language [40] and proved properties
corresponding to the node’s guarantee by hand.

The Radiation Sensor node’s contract assumes that the measured radiation is 0 or positive. Its

guarantee speciﬁes that if the node is asked to inspect i (command = inspect(i)) then:

1. the proposition inspected(i) becomes true, inspected(i) = TRUE;

2. low radiation is categorised as green, 0 <= r < 120 ⇒ radiationStatus = green;

3. medium radiation is categorised as orange, 120 <= r < 250 ⇒ radiationStatus = orange; and,

4. high radiation is categorised as red, 250 <= r ⇒ radiationStatus = red,

We proved these four properties by hand using Hoare Logic. If P is our program from Listing 4 then:

1. {(cid:62)} P{input = radiation at(i)} – The input to the node is always the radiation level at i. This

corresponds to the requirement that inspected(i) = TRUE in the contract.

23

1 {radiation at(i) < 120}
2 input := radiation at(i)
3 {input < 120} − Assignment Axiom
4

IF (input < 120) THEN

{input < 120& input < 120}
{input < 120 & green = green} − s t r e n g t h e n i n g
output := green
{input < 120 & output = green} − Assignment Axiom
{output = green} − weakening

5

6

7

8

12

13

14

15

16

17

18

19

20

21

22

9
10 ELSE
11

{input < 120 & input >= 120}
{FALSE} − s t r e n g t h e n i n g

IF (input < 250) THEN

{FALSE & input < 250}
{FALSE} − s t r e n g t h e n i n g
output := orange
{FALSE} − Assignment axiom

ELSE

{FALSE & input >= 250}
{FALSE} − s t r e n g t h e n i n g
output := red
{FALSE} − Assignment axiom

23

{FALSE} − C o n d i t i o n a l Rule
{output = green} − weakening
24
25 {output = green} − C o n d i t i o n a l Rule

Listing 5: Hoare Logic Proof that {radiation at(i) < 120}P{output = green}. The program is denoted
by bold text, and the proof steps are indicated by {braces} .

2. {radiation at(i) < 120} P{output = green} – if the radiation level at i is less than 120 then,

after execution of the program output is green.

3. {120 ≤ radiation at(i) < 250} P{output = orange} – if the radiation level at i is between 120

and 250 then, after execution of the program output is orange.

4. {radiation at(i) ≥ 250} P{output = red} – if the radiation level at i is greater than 250 then,

after execution of the program output is red.

We show the proof for property (2) in Fig. 5. The other proofs follow a similar pattern, and can be
found in Appendix B.

4.5 Step 4b: Automatic Synthesis of Runtime Monitors

This step takes the RCL contracts from Step 2 (§4.2) and synthesises Runtime Monitoring Language
(RML) monitors that are compatible with the ROSMonitoring framework [31]. As mentioned in
§3.3, our tool Vanda parses the RCL contracts, and then automatically generates the monitors and
ROSMonitoring conﬁguration ﬁles. Vanda uses a contract translator to produce the conﬁguration ﬁle
and structure of each monitor, and calls a FOL translator to translate each guarantee.

Listing 7 shows the RML that was automatically generated from the RCL contract in Listing 2.
Lines 1–6 contain the event types corresponding to the contract’s topics, while on lines 8–12 we have
the RML terms for the contract’s guarantees. These terms are obtained following the details presented
in §3.6 and Appendix C. RML oﬀers a Prolog-like notation, where variables that are not of interest
symbol. This is interpreted by RML as a wildcard variable, which can be
can be replaced with the
assigned to any value with no restrictions.

To aid the reader’s understanding of this translation step, we show in more detail how a speciﬁc
part of this RML speciﬁcation has been generated. The same reasoning is applied to the translation
of the other contracts.

Listing 6 shows a snippet of Listing 2, containing only one of the Agent node’s guarantees. The
guarantee in Listing 6 is translated into the RML term t2 in Listing 2. The guarantee consists
of an universal quantiﬁer (forall), which contains an implication (−>).

Following our approach in § 3.6 and Appendix C, we ﬁrst translate the implication, by negating

the left operand, and putting it in disjunction with the right operand. The left operand is:

(at(x’, y’) == TRUE and wayP(x’, y’) == i and inspected(i) == FALSE)

24

1 node agent {
2 ...
3 topics(gazebo_radiation_plugins/Command command matches(command),
4 gazebo_radiation_plugins/At at matches(at),
5 int16 wayP matches(wayP))
6 ...
7 guarantee(forall(x’, y’ in REAL, i in NATURAL | at(x’, y’) == TRUE and wayP(x’, y’) == i and

inspected(i) == FALSE -> command == inspect(i) )

8 ...
9 }

Listing 6: A snippet of the Agent’s contract from Listing 2.

1 at(x, y) matches { topic: ’gazebo_radiation_plugins/At’, posX: x, posY:y };
2 wayP(x, y, i) matches { topic: ’gazebo_radiation_plugins/WayP’, posX: x, posY: y, id: i};
3 radiationStatus(Lvl) matches { topic: ’gazebo_radiation_plugins/RadStat’, level: Lvl };
4 command(Cmd, x, y) matches { topic:’gazebo_radiation_plugins/Command’, command: Cmd, posX: x, posY:

y };

5 command(Cmd, i) matches { topic:’gazebo_radiation_plugins/Command’, command: Cmd, id: i };
6 inspected(i) matches { topic: ’gazebo_radiation_plugins/Inspection’, id: i };
7
8 t1 = {let x1, y1, i; ((¬ at(x1,y1) ∨ ¬ wayP(x1, y1, _) ∨ ¬ radiationStatus(green))) ∨ {let x2,y2;

(wayP(x2, y2, i+1) ∧ command(move, x2, y2))}}*;

9
10 t2 = {let x, y, i; (¬ at(x, y) ∨ ¬ wayP(x, y, i) ∨ inspected(i)) ∨ (command(inspect, i))}*;
11
12 t3 = {(radiationStatus(green) ∨ {let x, y; wayP(x, y, 0) ∧ command(move, x, y))})}*;

Listing 7: The Agent’s RML derived from the RCL contract shown in Listing 2.

which produces the following RML speciﬁcation:

.
(¬ at(x, y) ∨ ¬ wayP(x, y, i) ∨ inspected(i))
Note, that the RML is negated because (a -> b) = (¬ a or b). Then, the right operand
(command == inspect(i)) is directly mapped into (command(inspect, i)).

Next, the variables derived from the universal quantiﬁer are added to the RML speciﬁcation. Thus,
we obtain {let x, y, i; t}, where t is the previously created RML speciﬁcation (the one denoting
the implication). Through this quantiﬁcation, in RML we can generalise t over the set of variables
{ x,y,i }. Last but not least, since the guarantee ranges over all possible instantiations for the
variables, an * is added at the end of RML speciﬁcation. This operator, as in regular expressions,
requires the RML speciﬁcation to be matched multiple times. As previously mentioned, the same
reasoning is applied to the other guarantees in Listing 2.

Once we obtain the RML speciﬁcation, the RV step can be applied, as previously presented in
Fig. 3. Hence, the RML speciﬁcation can be used to synthesise an oracle, which will then be queried
at runtime by the corresponding ROS monitors (automatically synthesised from conﬁguration ﬁles).

The conﬁguration ﬁle automatically generated for ROSMonitoring is shown in Listing 8. This ﬁle is
used by ROSMonitoring to generate the Agent node’s monitor. Lines 3 & 4 show the agent monitor’s
identiﬁer and the location where its log ﬁles should be stored. The monitor also requires the list of
topics to subscribe to (lines 5–10) to observe the events at runtime. These topics are obtained from
lines 7–12 in Listing 2.

Once the RML speciﬁcation (Listing 7) and the conﬁguration ﬁle (Listing 8) have been generated,
ROSMonitoring can perform RV of the robotic system. As previously mentioned, ROSMonitoring
automatically synthesises runtime monitors as additional nodes in the ROS program. These nodes
subscribe to the topics of interest listed in the conﬁguration ﬁle (derived from the RCL speciﬁcation).
After that, they collect the messages published on those topics and perform the runtime analysis of the
RML speciﬁcation. If a monitor observes a violation of an RML speciﬁcation, it reports the violation
to the entire system by publishing a speciﬁc error message. This information can be used by the system
to promptly react and possibly recover from the erroneous behaviour.

5 Beyond the Case Study

In our case study (§4) we introduce contracts to an existing system, which makes use of existing
formal and non-formal veriﬁcation techniques. Our case study is designed to simply illustrate the core
concepts of our approach: FOL contracts, combined with a calculus, and guiding the most suitable

25

1 monitors:
2 - monitor:
3

id: monitor_agent
log: ./agent_log.txt
topics:

4

5

6

7

8

9

10

- {action: log, name: gazebo_radiation_plugins/Command, type:
gazebo_radiation_plugins.msg.Command}
- {action: log, name: gazebo_radiation_plugins/Inspection, type:
gazebo_radiation_plugins.msg.Inspection}
- {action: log, name: gazebo_radiation_plugins/At, type: gazebo_radiation_plugins.msg.At}
- {action: log, name: gazebo_radiation_plugins/WayP, type: gazebo_radiation_plugins.msg.WayP}
- {action: log, name: gazebo_radiation_plugins/RadStat, type:
gazebo_radiation_plugins.msg.RadStat}

Listing 8: The monitor conﬁguration ﬁle for the Agent node.

veriﬁcation method for each node. However, in other work, we have investigated a number of other
features of our framework, which we examine here.

One feature is that our approach is eﬀective even if the speciﬁcation language used for a node’s
veriﬁcation does not directly implement FOL. For example, the veriﬁcation of the Agent node (§4.4.3)
used program model checking of properties written in LTL (which is inherently similar to FOL) with
additional BDI concepts with their own semantics [25]. However, the other nodes were veriﬁed using a
variety of techniques, both formal and non-formal. The veriﬁcation of the Radiation Sensor (§4.4.4)
uses Hoare Logic, so the contract’s FOL properties are easy to represent. The ﬁnal two nodes were
veriﬁed using testing/experimental approaches, so the contracts guide the properties to be checked.

The rest of this section discusses three other features of our framework. In §5.1, we provide a worked
example of how our framework enables the implementation of one node to be swapped with another,
as long as the replacement node satisﬁes the speciﬁcation. In §5.2, we discuss how the veriﬁcation step
for a node can check more properties than its guarantee speciﬁes. (This is something that can be seen
in the veriﬁcation step for the Agent node (§4.4.3), but here we provide a more in-depth example.)
Finally, §5.3 explores how our approach to composing the node speciﬁcations can be applied to systems
that are not implemented in ROS.

5.1 Compositionality enables Interchangeability

One of the advantages of our approach is that we can swap a node’s implementation with another
(similar) implementation, which may be modelled and veriﬁed using diﬀerent speciﬁcation languages
and veriﬁcation tools to the original node, as long as the new implementation conforms to the FOL
contract. For example, instead of using a BDI agent (as we do in §4) we might choose a simpler way
of making the systems’ executive decisions that still satisﬁes GA(oA).

To demonstrate the modularity of our approach, this section describes a re-speciﬁcation and veriﬁ-
cation of the Agent (§4.4.3) in Dafny [45], which is a programming language enriched with speciﬁcation
constructs – for example: pre-/post-conditions, loop invariants, and variants. This enables the func-
tional correctness of Dafny programs to be statically veriﬁed, by translating them into the intermediate
veriﬁcation language Boogie [4] and using the theorem prover Z3 [22] to automatically discharge the
proof obligations for the speciﬁcation statements in the program.

The idea here is that instead of using a BDI program, the decision-making algorithm(s) will be
implemented in a general-purpose programming language, for example C++ or Python for compatibil-
ity with ROS. So we use Dafny to implement and verify the algorithms that the new decision-making
component will execute. Our prior work demonstrates that the correspondence between Dafny and
general-purpose languages, such as Python, makes it relatively straightforward to translate between
formal models and implemented code [30].

Listing 9 shows our Dafny model, in which the Agent method (line 5) provides an alternative
implementation of the agent’s behaviour to the BDI version that was presented in §5.1. Importantly,
the Dafny implementation follows the speciﬁcation in its contract (Table 4).

In Dafny, pre-conditions (assumptions) are indicated by the requires keyword. Lines 6–9 of
Listing 9 show the Agent method’s pre-conditions, taken from its contract. One small change is that
where the Agent’s contract has an assumption that the radiation status will be either red, orange, or
green; our Dafny version encodes this constraint as the RadiationLevel datatype (line 3) using the
radiation values, and using this in the parameters (for radstat) of the Agent method. Importantly,

26

1 datatype Action = Inspect | MoveNext
2 datatype Command = Command(a: Action, w: int)
3 datatype RadiationLevel = red | orange | green
4
5 method Agent(waypoints: seq<int>, currentpos: int, radstat: RadiationLevel, wheelsready: bool) returns

(actions: seq<Command>)

6 requires currentpos (cid:62) 0 ∧ currentpos (cid:54) 12; //13 waypoints to patrol
7 requires |waypoints| = 13;
8 requires ∀ i: int · 0(cid:54)i<|waypoints| ⇒ waypoints[i] = i;
9 requires ∀ i: int · 0(cid:54)i<|waypoints| ⇒ i in waypoints;
10 ensures (wheelsready) = false ⇒ actions =[];//safety check: if the hardware is not ready then do

nothing.

i) in actions);

11 ensures ∀ i: int · 0(cid:54)i<|waypoints| ⇒ (wheelsready ∧ at(i) ∧ inspected(i) ∧ radstat (cid:54)= red ∧ radstat

(cid:54)= orange ⇒ ∃ next: int · 0(cid:54)next<|waypoints| ∧ Command(MoveNext, next) in actions);
12 ensures ∀ i: int · 0(cid:54)i<|waypoints| ⇒ (wheelsready ∧ at(i) ∧ (! inspected(i)) ⇒ Command(Inspect,

var time, next := 0, 0;
var current:=currentpos;
actions := [];

13 ensures wheelsready ∧ (radstat = red ∨ radstat = orange) ⇒ Command(MoveNext, 0) in actions;
14 {
15
16
17
18
19
20
21
22
23

while(wheelsready ∧ time <200)
invariant next in waypoints;
invariant current in waypoints;
invariant time > 0 ∧ (radstat = red ∨ radstat = orange) ⇒ Command(MoveNext, 0) in actions ∧

if(wheelsready){

next = 0;

actions;

{

invariant time > 0 ∧ at(current) ∧ (! inspected(current)) ⇒ Command(Inspect, current) in

invariant time > 0 ∧ at(old(current)) ∧ inspected(old(current)) ∧ radstat (cid:54)= red ∧ radstat (cid:54)=

orange ⇒ Command(MoveNext, next) in actions ∧ current = old(next);

if(at(current) ∧ inspected(current) ∧ radstat (cid:54)= red ∧ radstat (cid:54)= orange){

24

25

26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42 }

next := getnextwaypoint(current);
actions := actions + [Command(MoveNext, next)];

}
if(at(current) ∧ (! inspected(current))){

actions := actions + [Command(Inspect, current)];

}
if(radstat = red ∨ radstat = orange){

next := 0;
actions := actions + [Command(MoveNext, next)];

}
time := time +20;
current := next;

}

}

Listing 9: Dafny Agent

if the Agent method is called by another method, then the calling method’s guarantees must not
violate the assumptions of the Agent method.

Post-conditions (guarantees) in Dafny are indicated by the ensures keyword. Lines 10–13 of List-
ing 9 show the Agent method’s post-conditions, which are more detailed than the Agent’s contract,
because they also check the status of the software controlling the rover’s wheels before instructing it to
carry out any commands. The post-condition on line 10 speciﬁes that no actions are assigned when the
wheels are not ready15. The post-conditions on lines 11–13 correspond to the Agent’s guarantees from
its contract (Table 4). For veriﬁcation in Dafny, we must include loop invariants (lines 21–25), which
help the veriﬁcation tool (Z3) to prove the post-conditions. We were able to automatically discharge
the associated proofs in Dafny with Z3 using Visual Studio Code.

Another diﬀerence between our Dafny and BDI implementations is that we had to add a notion
of time to the Dafny model (the time variable is declared on line 15 and updated on line 38) to be
able to prove loop termination. Dafny is primarily concerned with program safety, so termination is
necessary for complete veriﬁcation of Dafny programs.

This Dafny program veriﬁes the decision-making algorithm, using a language that is closer to those
in which ROS nodes are implemented. Once the Dafny program has been veriﬁed against the Agent
contract, it can be carefully reimplemented as a ROS node. The Dafny Agent can also be used with
our calculus (§3.4) because it preserves the contract’s assumptions and guarantees. Not only does this
allow the user to develop multiple models (and potentially implementations) of the same node, it also
facilitates the use of predeﬁned or library functions that have been veriﬁed previously and also meet

15This is an example of how our approach allows veriﬁers to check additional node-level properties, which we discuss

in more detail in §5.2.

27

1 node ArmClient
2 {
3 inputs( arm_down : BOOL, arm_result : BOOL )
4
5 outputs( arm_down : BOOL, arm_result : BOOL )
6
7 assume( TRUE )
8
9 guarantee( in.arm_down = out.arm_down )
10
11 guarantee( out.arm_result = in.arm_result )
12 }

Listing 10: The ArmClient’s RCL contract.

the required contracts. This can potentially streamline the veriﬁcation step by supporting the use of
previously veriﬁed robotic system nodes.

5.2 Verifying Additional Node-Level Properties

This section discusses how the veriﬁcation of a node can check more properties than are speciﬁed in
its contract. The contract may under-specify its guarantee, for example because the node’s details are
known when the contract is written, or because the contract language is too abstract to express all of a
node’s veriﬁcation conditions. Either way, our approach allows the veriﬁcation of a node to go further
that what its contract guarantees. This can be seen in the veriﬁcation of the Agent node (§4.4.3),
where property φ4 is not part of the node’s contract but is a lower-level property identiﬁed during the
node’s implementation.

As a more in-depth example, we brieﬂy describe the contracts and veriﬁcation for part of the
example from our previous work [12]. In this system, a simulation of USA’s NASA Curiosity rover
moves between waypoints on a map, each waypoint represents an interesting location at which the
rover should collect some data. The rover has an arm, with data-collection instruments on; and a
mast, with a camera. The rover’s control software picks the next waypoint, avoiding a waypoint if the
radiation is too high, and retracting (closing) the mast and arm if a waypoint is too windy.

The rover’s arm, mast, and wheels are all controlled using pairs of ROS nodes that implement
the Action library16 to interface between the rover’s software and hardware. Each client node accepts
instructions from the rover’s control software, which it then sends to its corresponding server node as
a goal (a task to complete).

In this section we focus on the contracts and veriﬁcation of the software nodes controlling the
rover’s arm. The arm’s RCL contracts were developed for this work, and we compare them with the
veriﬁcation approach used in the previous work [12]. The arm on the Curiosity rover can either be
down (extended), so that the instruments it holds can be used to inspect the surface of Mars; or
up (retracted), to protect the arm and instruments while the rover is moving. The RCL contracts
are written at a high-level, without including details speciﬁc to the library that the example system
implements. The veriﬁcation conditions capture more of Action library’s low-level behaviour.

The contract for the ArmClient (Listing 10) shows that it guarantees (lines 9 and 11) two abstract
properties. First, that the position of the arm (i.e is arm down TRUE or FALSE) that it receives on
the input stream is the same as the position that it passes to the ArmServer (in.arm down =
out.arm down). Second, that the result sent back to the system, on the output stream, matches
the result (TRUE if the action has completed, or FALSE otherwise) it has received from the Arm-
Server (out.arm result = in.arm result). These conditions ensure that an instruction from
the rover’s control software is correctly passed to the server (for execution) and the result is correctly
returned to the control software.

The contract for the ArmServer (Listing 11) shows its guarantee (line 9); that when it receives
an instruction to move the arm, it produces a result of TRUE and sends it to the ArmClient on the
output stream. This states that the instruction to open or close the arm is performed successfully,
and ensures that the result is returned to the client (which will return the result to the rover’s control
software).

The ArmClient and the ArmServer were modelled and veriﬁed as part of the work described
in [12]. The modelling and veriﬁcation conditions were both based on the the ROS program in that

16ROS Action Library: http://wiki.ros.org/actionlib Accessed: 15/07/2022

28

1 node ArmServer
2 {
3 inputs( arm_down : BOOL )
4
5 outputs( arm_result : BOOL
6
7 assume( TRUE )
8
9 guarantee( out.arm_result = TRUE )
10 }

)

Listing 11: The ArmServer’s RCL contract.

work, and the documentation for the Action library. We checked the following three veriﬁcation
conditions:

1. when a client sends a goal, it will begin execution on the correct server,
2. when a client sends a goal, eventually it receives a result from the server, and;
3. when the rover’s control software instructs a client node to perform an action, the server informs

the rover that it is ready and then eventually the rover receives a result.

These conditions are lower-level than the contracts in Listings 10 and 11, so they are ‘aware’ of the
library implementing these nodes and so the conditions relate to the library’s behaviour.

Veriﬁcation condition (1) maps directly to the guarantee on line 9 of Listing 10: if we send a goal
to the ArmServer, then it will be executed on the ArmServer. The contract’s guarantee states that
the arm down value it receives on the input stream will be passed, unaltered, to the output stream.
The ArmServer is listening to that output stream, so it will execute the goal.

However, veriﬁcation conditions (2) and (3) extend the guarantees in the two contracts. For the
ArmClient and the ArmServer, condition (2) states that if the ArmClient sends a goal then
eventually it will receive a result from the ArmServer. Since RCL is a more abstract language, the
contracts only guarantee that the ArmClient passes arm down and arm result between its input
and output streams without changing the value, and that the ArmServer will eventually say that the
action was complete (arm result = TRUE). The veriﬁcation condition includes information about
the ordering or these events, and the notion that there is some time in between them to allow for
computation and the physical movement of the arm.

Similarly, veriﬁcation condition (3) contains more information about the ordering of events than
the RCL contracts capture. For the ArmClient and the ArmServer it states that ArmClient will
ﬁrst receive the value of arm down from the rover’s control software, then the ArmServer has to
signal that it is ready to receive another goal, and eventually the rover’s control software receives the
result of executing the goal from the ArmClient. The RCL contract is only concerned with the data
moving between the two nodes, so these signals and ordering are abstracted away from.

Some of these low-level aspects of ROS programs could be useful to include in RCL, for example the
idea of an output being triggered by an input, which would allow contracts to specify some ordering of
events. However, even without this, RCL contracts can specify useful properties about a node, which
can be extended by that node’s individual veriﬁcation. This is especially useful when the contracts are
written before the implementation details of the system are known.

5.3 Towards Applying our Approach to Non-ROS Systems

So far, our work has focussed on ROS systems; this section explores how our approach can be adapted to
robotic systems that do not use ROS. We use previous work [8] as our example, in which heterogeneous
veriﬁcation methods were used to verify an autonomous rover that was modelled in Simulink. The
rover’s mission is to autonomously navigate around a grid-world of known size and visit identiﬁed
points of interest to collect data, recharging as necessary. This example has similar functionality to
our case study system in §4, but does not use ROS.

The rover’s architecture is shown in Fig. 7. It contains multiple connected modules, some of which
provide functionality that is more critical than others – for example the ReasoningAgent, which is
the core decision-making component of the system. To account for this mixed-criticality, the work
in [8] begins by eliciting the system’s requirements using an approach driven by a detailed hazard
analysis.

One of the system’s most important requirements was that the rover shall not run out of battery.
This particular requirement can be viewed as a system-level contract that relies on the behaviour of

29

Figure 7: Architecture of autonomous rover from [8].

multiple components in the system. For example, the Battery Interface must function correctly,
ensuring that the rover’s goal location is set to the charge station when needed; and the ReasoningA-
gent must correctly select the shortest path, to conserve battery power.

For compositional veriﬁcation, the work in [8] uses CoCoSim, which is an approach for compositional
veriﬁcation of Simulink models that uses the Kind2 model checker17 for veriﬁcation [16]. This approach
works by attaching contracts to nodes in the system and then deﬁning a top node where the system-
level contracts are speciﬁed. Here, compositional veriﬁcation involves verifying (by model-checking)
that the node-level contracts imply the system-level contracts.

A key point of our approach is that it can derive system-level properties from the node-level con-
tracts. In [8], both component-level contracts and system-level contracts are derived from the require-
ments and the component-level contracts are attached to individual system components. CoCoSim
was then used to verify that the system-level properties could be deduced from the component-level
contracts. The diﬀerence between this approach and ours is that CoCoSim requires a system-level
property against which to verify systems, whereas we support deriving properties about a system’s
behaviour for systems built from (potentially independently developed) components.

To compare with this work and investigate how our approach performs on this non-ROS system,
we examine its component-level contracts to see if we can derive similar system-level properties to
those used in [8]. For this example, we focus our attention speciﬁcally on the NavigationSystem
shown in Fig. 7, which is composed of a ReasoningAgent and a Battery Interface. The Rea-
soningAgent contains a Goal Reasoning Agent (GRA in Fig. 7), to select the rover’s goal location;
the ComputePlan2Charging component, which generates a plan to the charging point; and the
ComputePlan2Destination component, which generates a plan to other destinations. The Bat-
tery Interface contains a BatteryMonitor component, which regularly checks the battery level;
and the Interface, which updates the GRA when the rover needs to recharge.

Despite this system not being implemented in ROS, we are able to apply our calculus to it because
it is built from components that act similarly to a ROS nodes. We take Fig. 7 as our system model
(which maps to Step 1 of our approach in §3) and apply our calculus to the ReasoningAgent and
Battery Interface.

First, we apply the calculus to the subcomponents of the ReasoningAgent. Because the output
of the GRA is the input of both ComputePlan2Charging (which we shorten to CPC ) and the
ComputePlan2Destination (which we shorten to CPD), we use the branching output rule, R2:

17Kind2: https://kind2-mc.github.io/kind2/ Accessed: 15/07/2022

30

∀ iGRA, oGRA · AGRA(iGRA) ⇒ ♦GGRA(oGRA)
∀ iCPC , oCPC · ACPC (iCPC ) ⇒ ♦GCPC (oCPC )
∀ iCPD, oCPD · ACPD(iCPD) ⇒ ♦GCPD(oCPD)
oGRA = iCPC ∪ iCPD
(cid:96) ∀ oGRA, iCPC · GGRA(oGRA) ⇒ ACPC (iCPC ) ∧ ∀ oGRA, iCPD · GGRA(oGRA) ⇒ ACPC (iCPC )
∀ iGRA, oCPC , oCPD · AGRA(iGRA) ⇒ ♦GCPC (oCPC ) ∧ ♦GCPD(oCPD)

Intuitively this means that, when the assumptions of the GRA component hold, then eventually the
guarantees of the ComputePlan2Charging (CPC ) and the ComputePlan2Destination (CPD)
hold. This also captures the requirement for this system that all plans are valid and free from obstacles
[8].

Similarly we can use the union of inputs rule, R3, to link the three components that provide input to
the Interface (I ): the ComputePlan2Charging (CPC ), the ComputePlan2Destination (CPD),
and the BatteryMonitor (BM ). Using R3, we can derive the following:

∀ iCPC , oCPC · ACPC (iCPC ) ⇒ ♦GCPC (oCPC )
∀ iCPD, oCPD · ACPD(iCPD) ⇒ ♦GCPD(oCPD)
∀ iBM , oBM · ABM (iBM ) ⇒ ♦GBM (oBM )
∀ iI , oI · AI (iI ) ⇒ ♦GI (oI )
iI = oCPC ∪ oCPD ∪ oBM
(cid:96) ∀ iI , oCPC , oCPD, oBM · GCPC (oCPC ) ∧ GCPD(oCPD) ∧ GBM (oBM ) ⇒ AI (iI )
∀ iCPC , iCPD, iBM , oI , ·ACPC (iCPC ) ∧ ACPD(iCPD) ∧ ABM (iBM ) ⇒ ♦GI (oI )

Thus we can deduce that when the plan-computing components (ComputePlan2Charging and
ComputePlan2Destination) and the BatteryMonitor are functioning correctly, then eventually
the Interface’s guarantee is preserved. This means that battery usage is computed correctly and that
the rover stays in the charger location until it has fully recharged.

Both, this previous approach and the derivations above are able to derive that the rover produces
obstacle-free plans. The approach in [8] was able to verify that the rover never runs out of battery but
our rules above only allowed us to show that the rover recharges fully when required. These properties
are fairly closely related. The reason that we could deduce the property that the rover never runs
out of battery was down to the way that the approach using CoCoSim works. There, we had to
specify top-level requirements including that the rover never runs out of battery and essentially show
that the component-level contracts imply this. Our current approach is more ﬂexible and does not
require system-level properties in the same way, rather it derives the properties for the system from the
component-level contracts. This has beneﬁts, especially in the domain of autonomous systems where
emergent properties might appear and not be known beforehand.

This subsection has illustrated how our contract-based compositional veriﬁcation approach can be
applied in the case of non-ROS systems to derive system-level contracts. As previously mentioned, we
used the Architecture Analysis and Design Language (AADL) model shown in Fig. 7 as our system
model, which maps to Step 1 in our our approach (§3). Here, we did not need to abstract the model
to make it more manageable, but this may be needed for more complicated models. Then we use FOL
to write and reason about contracts, which maps to Steps 2 and 3 of our approach. Heterogeneous
veriﬁcation (mapping to Step 4a) is still possible here, guided by the FOL contracts. Automatically
generating runtime monitors (Step 4b) is not possible here, because that part of our approach relies
on information in the RCL contracts that is speciﬁc to ROS. However, generating runtime monitors in
a suitable generic framework that can be applicable to non-ROS systems is a useful avenue of future
work.

6 Conclusions and Future Work

This paper contributes a compositional approach to the development of veriﬁable modular robotic
systems, which focusses on systems that use the Robot Operating System (ROS) – though parts of
it are applicable to non-ROS systems. Each module (or ROS node) is speciﬁed using an assume–
guarantee contract, written in First-Order Logic (FOL), that guide its veriﬁcation. We also present a
calculus for composing these contracts, which caters for sequences, joins, and branches in the system’s
architecture. Each node can be veriﬁed using the most suitable method; some may be amenable to

31

formal veriﬁcation, while others may not. The veriﬁcation is driven by the contracts, which specify
the minimal set of properties that the veriﬁcation must be able to show hold for that node (to an
appropriate level of conﬁdence for the node and system’s regulatory environment).

As a safety net, we automatically synthesise monitors to verify the contracts’ guarantee(s) at
runtime. The runtime veriﬁcation is handled by ROSMonitoring [31], an existing tool for runtime
veriﬁcation of ROS systems. Supporting this approach is ROS Contract Language (RCL), a novel
Domain Speciﬁc Language (DSL) for writing FOL contracts for ROS systems; and Vanda, which is a
novel prototype tool that parses RCL and synthesises the runtime monitors.

Section 4 describes how we used our approach to write contracts for, and verify the nodes of, a
pre-existing robotic system. However, the RCL contracts could also be used as part of a contract-
based development approach for building new robotic systems. Used in this way, the contracts would
link the system’s requirements to its low-level design. RCL could be used to specify the assumptions
and guarantees of the proposed system’s nodes, and how their inputs and outputs connect the nodes
together. Once this version of the design was checked using the calculus, the ROS topic information
could be added. These completed contracts could be used to drive a low-level software design, as
the starting point for an implementation. Interesting future work could involve extending Vanda to
produce message type deﬁnitions and skeleton code for ROS nodes, based on the speciﬁcation in the
RCL contracts.

For other future work, we will apply our approach to a larger and more complex system, expanding
the calculus to cater to other arrangements of nodes where needed. We also aim to explore more
sophisticated contracts involving real-time constraints and, potentially, uncertainty. One area where
Vanda could be improved to aid the speciﬁcation of the contracts is to add support for calculating
assumptions when composing contracts, similarly to the approach in [20]. Finally, we intend to explore
the level of conﬁdence we can have in a system that has been veriﬁed using a mixture of methods;
particularly how conﬁdence can be calculated for more complex systems with loops in the information
ﬂow.

References

[1] S. Adam, M. Larsen, K. Jensen, and U. P. Schultz. Towards Rule-Based Dynamic Safety Mon-
itoring for Mobile Robots. In Proc. 4th International Conference on Simulation, Modeling, and
Programming for Autonomous Robots (SIMPAR), volume 8810 of LNCS, pages 207–218. Springer,
2014. doi:10.1007/978-3-319-11900-7 18.

[2] J. M. Aitken, S. M. Veres, A. Shaukat, Y. Gao, E. Cucco, L. A. Dennis, M. Fisher, J. A. Kuo,
T. Robinson, and P. E. Mort. Autonomous Nuclear Waste Management. IEEE Intelligent Systems,
33(6):47–55, 2018. doi:10.1109/MIS.2018.111144814.

[3] D. Ancona, L. Franceschini, A. Ferrando, and V. Mascardi. RML: Theory and Practice of a Do-
main Speciﬁc Language for Runtime Veriﬁcation. Science of Computer Programming, 205:102610,
2021. doi:10.1016/j.scico.2021.102610.

[4] M. Barnett, B.-Y. E. Chang, R. DeLine, B. Jacobs, and K. R. M. Leino. Boogie: A Modular
Reusable Veriﬁer for Object-Oriented Programs. In Formal Methods for Components and Objects,
volume 4111 of LNCS, pages 364–387. Springer, 2005. doi:10.1007/11804192 17.

[5] A. Benveniste, B. Caillaud, D. Nickovic, R. Passerone, J.-b. Raclet, P. Reinkemeier,
A. Sangiovanni-vincentelli, W. Damm, T. Henzinger, and K. G. Larsen. Contracts for Systems
Design. Technical Report RR-8147, INRIA, 2012. URL https://hal.inria.fr/hal-00757488v1.

[6] Y. Bertot and P. Castéran. Interactive Theorem Proving and Program Development: Coq’Art: the

Calculus of Inductive Constructions. Springer, 2013. doi:10.1007/978-3-662-07964-5.

[7] R. Bogue. Robots in the Nuclear Industry: A review of technologies and applications. Industrial

Robot: An International Journal, 38(2):113–118, 2011. doi:10.1108/01439911111106327.

[8] H. Bourbouh, M. Farrell, A. Mavridou, I. Sljivo, G. Brat, L. A. Dennis, and M. Fisher. Integrating
In NASA Formal Methods

formal veriﬁcation and assurance: An inspection rover case study.

32

Symposium, volume 12673 of LNCS, pages 53–71. Springer, 2021. doi:10.1007/978-3-030-76384-
8 4.

[9] J. Briales and J. Gonzalez-Jimenez. Fast global optimality veriﬁcation in 3d slam.

In 2016
IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 4630–4636.
IEEE, 2016. doi:10.1109/IROS.2016.7759681.

[10] M. Broy. A Logical Approach to Systems Engineering Artifacts: Semantic Relationships and
Dependencies beyond Traceability – from requirements to functional and architectural views.
Software and System Modeling, 17(2):365–393, 2018. doi:10.1007/s10270-017-0619-4.

[11] R. C. Cardoso, L. A. Dennis, M. Farrell, M. Fisher, and M. Luckcuck. Towards Compositional
Veriﬁcation for Modular Robotic Systems. In Proc. Second Workshop on Formal Methods for Au-
tonomous Systems (FMAS2020), volume 329, pages 15–22. Electronic Proceedings in Theoretical
Computer Science, Dec. 2020. URL http://arxiv.org/abs/2012.01648v1.

[12] R. C. Cardoso, M. Farrell, M. Luckcuck, A. Ferrando, and M. Fisher. Heterogeneous Veriﬁcation
of an Autonomous Curiosity Rover. In Proc. NASA Formal Methods, volume 12229 of LNCS,
pages 353–360. Springer, 2020. doi:10.1007/978-3-030-55754-6 20.

[13] L. Carlone and F. Dellaert. Duality-based veriﬁcation techniques for 2d slam.

In 2015 IEEE
international conference on robotics and automation (ICRA), pages 4589–4596. IEEE, 2015.
doi:10.1109/ICRA.2015.7139835.

[14] L. Carlone, D. M. Rosen, G. Calaﬁore, J. J. Leonard, and F. Dellaert. Lagrangian dual-
In 2015 IEEE/RSJ Inter-
ity in 3d slam: Veriﬁcation techniques and optimal solutions.
national Conference on Intelligent Robots and Systems (IROS), pages 125–132. IEEE, 2015.
doi:10.1109/IROS.2015.7353364.

[15] R. Carvalho, A. Cunha, N. Macedo, and A. Santos. Veriﬁcation of system-wide safety properties of
ros applications. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS), pages 7249–7254. IEEE, 2020. doi:10.1109/IROS45743.2020.9341085.

[16] A. Champion, A. Gurﬁnkel, T. Kahsai, and C. Tinelli. Cocospec: A mode-aware contract language
for reactive systems. In Software Engineering and Formal Methods, volume 9763 of LNCS, pages
347–366. Springer, 2016. doi:10.1007/978-3-319-41591-8 24.

[17] A. Champion, A. Mebsout, C. Sticksel, and C. Tinelli. The kind 2 model checker. In Proc. Com-
puter Aided Veriﬁcation, volume 9780 of LNCS, pages 510–517. Springer, 2016. doi:10.1007/978-
3-319-41540-6 29.

[18] A. Cimatti, M. Dorigatti, and S. Tonetta. Ocra: A tool for checking the reﬁnement of temporal
contracts. In International Conference on Automated Software Engineering (ASE), pages 702–705.
IEEE, 2013. doi:10.1109/ASE.2013.6693137.

[19] E. M. Clarke, O. Grumberg, and D. Peled. Model checking. MIT press, 1999.

[20] J. M. Cobleigh, D. Giannakopoulou, and C. S. Pasareanu. Learning Assumptions for Composi-
tional Veriﬁcation. In Tools and Algorithms for the Construction and Analysis of Systems, volume
2619 of LNCS, pages 331–346. Springer, 2003. doi:10.1007/3-540-36577-X 24.

[21] D. Cofer, A. Gacek, S. Miller, M. W. Whalen, B. LaValley, and L. Sha. Compositional veriﬁcation
of architectural models. In NASA Formal Methods Symposium, volume 7226 of LNCS, pages 126–
140. Springer, 2012. doi:10.1007/978-3-642-28891-3 13.

[22] L. De Moura and N. Bjørner. Z3: An eﬃcient smt solver.

In Tools and Algorithms for the
Construction and Analysis of Systems, volume 4963 of LNCS, pages 337–340. Springer, 2008.
doi:10.1007/978-3-540-78800-3 24.

[23] L. A. Dennis. Gwendolen semantics: 2017. Technical Report ULCS-17-001, University of Liv-
erpool, Department of Computer Science, 2017. URL https://intranet.csc.liv.ac.uk/research/
techreports/tr2017/ulcs-17-001.pdf.

33

[24] L. A. Dennis and B. Farwer. Gwendolen: A BDI Language for Veriﬁable Agents. In Workshop

on Logic and the Simulation of Interaction and Reasoning, pages 16–23. AISB, 2008.

[25] L. A. Dennis, M. Fisher, M. P. Webster, and R. H. Bordini. Model checking agent programming
languages. Automated Software Engineering, 19(1):5–63, 2012. doi:10.1007/s10515-011-0088-x.

[26] A. Desai, S. Qadeer, and S. A. Seshia. Programming safe robotics systems: Challenges and
advances. In Proc. 8th International Symposium on Leveraging Applications of Formal Methods,
Veriﬁcation and Validation (ISoLA), volume 11245 of LNCS, page 103–119, Berlin, Heidelberg,
2018. Springer. doi:10.1007/978-3-030-03421-4 8.

[27] F. Duchoň, J. Hažík, J. Rodina, M. Tölgyessy, M. Dekan, and A. Sojka. Veriﬁcation of slam
methods implemented in ros. Journal of Multidisciplinary Engineering Science and Technology
(JMEST), 6, 2019. doi:10.22223/tr.2016-1/2011.

[28] K. A. Elkader, O. Grumberg, C. S. Păsăreanu, and S. Shoham. Automated circular assume-
In Formal Methods, volume 9109 of LNCS, pages 23–39. Springer, 2015.

guarantee reasoning.
doi:10.1007/978-3-319-19249-9 3.

[29] M. Farrell, M. Luckcuck, and M. Fisher. Robotics and Integrated Formal Methods: Neces-
sity Meets Opportunity. In Integrated Formal Methods, volume 11023 of LNCS, pages 161–171.
Springer, 2018. doi:10.1007/978-3-319-98938-9 10.

[30] M. Farrell, N. Mavrakis, A. Ferrando, C. Dixon, and Y. Gao. Formal modelling and runtime
veriﬁcation of autonomous grasping for active debris removal. Frontiers in Robotics and AI, 8,
2021. doi:10.3389/frobt.2021.639282.

[31] A. Ferrando, R. C. Cardoso, M. Fisher, D. Ancona, L. Franceschini, and V. Mascardi. ROSMon-
itoring: A runtime veriﬁcation framework for ROS. In Towards Autonomous Robotic Systems,
volume 12228 of LNCS, pages 387–399. Springer, 2020. doi:10.1007/978-3-030-63486-5 40.

[32] M. Fisher. An Introduction to Practical Formal Methods Using Temporal Logic. John Wiley &

Sons, 2011. doi:10.1002/9781119991472.

[33] S. Fleury, M. Herrb, and R. Chatila. GenoM: A Tool for the Speciﬁcation and the Implementa-
tion of Operating Modules in a Distributed Robot Architecture. In International Conference on
Intelligent Robots and Systems, pages 842–849. IEEE, 1997. doi:10.1109/IROS.1997.655108.

[34] A. Flores-Abad, O. Ma, K. Pham, and S. Ulrich. A review of space robotics technologies for on-
orbit servicing. Progress in Aerospace Sciences, 68:1–26, 2014. doi:10.1016/j.paerosci.2014.03.002.

[35] M. Foughali. Formal Veriﬁcation of the Functional Layer of Robotic and Autonomous Systems.
Theses, Institut national des sciences appliquées de Toulouse, Dec. 2018. URL https://hal.laas.
fr/tel-02080063.

[36] S. Gregory. Parallel
Addison-Wesley, 1987.

logic programming in PARLOG - the language and its implementation.

[37] R. Halder, J. Proença, N. Macedo, and A. Santos. Formal Veriﬁcation of ROS-Based Robotic
Applications Using Timed-Automata. In Workshop on Formal Methods in Software Engineering.
IEEE, 2017. doi:10.1109/FormaliSE.2017.9.

[38] Y. Hasegawa and Y. Fujimoto. Experimental veriﬁcation of path planning with slam.

IEEJ

Journal of Industry Applications, 5(3):253–260, 2016. doi:10.1541/ieejjia.5.253.

[39] H. Hastie, K. Lohan, M. Chantler, D. A. Robb, S. Ramamoorthy, R. Petrick, S. Vijayakumar,
and D. Lane. The ORCA Hub: Explainable oﬀshore robotics through intelligent interfaces. In
Explainable Robotic Systems Workshop, ACM Human-Robot Interaction conference,, pages 1–2,
2018. URL https://arxiv.org/abs/1803.02100.

[40] C. A. R. Hoare. An axiomatic basis for computer programming. Comms. of the ACM, 12(10):576–

580, 1969. doi:10.1145/363235.363259.

34

[41] J. Huang, C. Erdogan, Y. Zhang, B. M. Moore, Q. Luo, A. Sundaresan, and G. Rosu. ROSRV:
runtime veriﬁcation for robots. In Proc. 5th International Conference on Runtime Veriﬁcation
(RV), volume 8734 of LNCS, pages 247–254. Springer, 2014. doi:10.1007/978-3-319-11164-3 20.

[42] X. Huang, D. Kroening, W. Ruan, J. Sharp, Y. Sun, E. Thamo, M. Wu, and X. Yi. A
survey of safety and trustworthiness of deep neural networks: Veriﬁcation, testing, adversar-
ial attack and defence, and interpretability. Computer Science Review, 37:100270, Aug. 2020.
doi:10.1016/j.cosrev.2020.100270.

[43] M. Huth and M. Ryan. Logic in Computer Science: Modelling and reasoning about systems.

Cambridge University Press, 2004.

[44] C. B. Jones. Tentative Steps Toward a Development Method for Interfering Programs. ACM

Trans. on Programming Languages and Systems, 5(4):596–619, 1983.

[45] K. R. M. Leino. Dafny: An automatic program veriﬁer for functional correctness.

In Logic
for Programming Artiﬁcial Intelligence and Reasoning, volume 6355 of LNCS, pages 348–370.
Springer, 2010. doi:10.1007/978-3-642-17511-4 20.

[46] M. Leucker and C. Schallhart. A brief account of runtime veriﬁcation. J. Log. Algebraic Methods

Program., 78(5):293–303, 2009. doi:10.1016/j.jlap.2008.08.004.

[47] J. Li, P. Nuzzo, A. Sangiovanni-Vincentelli, Y. Xi, and D. Li. Stochastic contracts for cyber-
physical system design under probabilistic requirements. In International Conference on Formal
Methods and Models for System Design, number ii, pages 5–14, New York, USA, 2017. ACM
Press. doi:10.1145/3127041.3127045.

[48] M. Luckcuck. Using formal methods for autonomous systems: Five recipes for formal veriﬁcation.
Proceedings of the Institution of Mechanical Engineers, Part O: Journal of Risk and Reliability,
0(0):1748006X2110349, July 2021. doi:10.1177/1748006X211034970.

[49] M. Luckcuck, M. Farrell, L. A. Dennis, C. Dixon, and M. Fisher. Formal Speciﬁcation and
Veriﬁcation of Autonomous Robotic Systems: A Survey. ACM Computing Surveys, 52(5):1–41,
2019. doi:10.1145/3342355.

[50] M. Luckcuck, M. Fisher, L. Dennis, S. Frost, A. White, and D. Styles. Principles for the Devel-
opment and Assurance of Autonomous Systems for Safe Use in Hazardous Environments, June
2021. doi:10.5281/zenodo.5012322.

[51] N. Macedo, J. Brunel, D. Chemouil, A. Cunha, and D. Kuperberg. Lightweight speciﬁcation and
analysis of dynamic systems with rich conﬁgurations. In Proc. 24th ACM SIGSOFT International
Symposium on Foundations of Software Engineering, page 373–383, New York, NY, USA, 2016.
Association for Computing Machinery. doi:10.1145/2950290.2950318.

[52] B. Meyer. Applying "Design by Contract". Computer, 25(10):40–51, 1992. doi:10.1109/2.161279.

[53] A. Miyazawa, P. Ribeiro, W. Li, A. Cavalcanti, J. Timmis, and J. Woodcock. Robochart: Mod-
elling and veriﬁcation of the functional behaviour of robotic applications. Softw. Syst. Model.,
18(5):3097–3149, oct 2019. doi:10.1007/s10270-018-00710-z.

[54] A. Pnueli. The Temporal Logic of Programs. In Foundations of Computer Science, pages 46–57.

IEEE, 1977. doi:10.1109/SFCS.1977.32.

[55] M. Quigley, K. Conley, B. Gerkey, J. Faust, T. Foote, J. Leibs, R. Wheeler, and A. Ng. ROS: an
open-source Robot Operating System. In Workshop on Open Source Software. IEEE, 2009.

[56] A. S. Rao and M. Georgeﬀ. BDI Agents: From Theory to Practice. In International Conference

on Multi-Agent Systems, pages 312–319. AAAI, 1995.

[57] K. Y. Rozier. Speciﬁcation: The biggest bottleneck in formal methods and autonomy. In Working
Conference on Veriﬁed Software: Theories, Tools, and Experiments, volume 9971 of LNCS, pages
8–26. Springer, 2016. doi:10.1007/978-3-319-48869-1 2.

35

[58] I. Ruchkin, J. Sunshine, G. Iraci, B. Schmerl, and D. Garlan.

IPL: An integration property
language for multi-model cyber-physical systems. In Formal Methods, volume 10951 of LNCS,
pages 165–184. Springer, 2018. doi:10.1007/978-3-319-95582-7 10.

[59] A. Santos, A. Cunha, N. Macedo, and C. Lourenço. A framework for quality assessment of
ros repositories. In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS), pages 4491–4496, 2016. doi:10.1109/IROS.2016.7759661.

[60] A. Shakhimardanov, N. Hochgeschwender, and G. Kraetzschmar. Component models in robotics
software. In Workshop on Performance Metrics for Intelligent Systems, pages 82–87. ACM, 2010.
doi:10.1145/2377576.2377592.

[61] R. Siv`y and D. Perduková. Veriﬁcation of slam methods on ros platform. Transactions of the
VŠB-Technical University of Ostrava, Mechanical Series, 62:59 – 66, 2016. doi:10.22223/tr.2016-
1/2011.

[62] S. Spellini, M. Lora, F. Fummi, and S. Chattopadhyay. Compositional design of multi-
robot systems control software on ros. ACM Trans. Embed. Comput. Syst., 18(5s), oct 2019.
doi:10.1145/3358197.

[63] K. Ueda. Guarded horn clauses. In Proceedings of the 4th Conference on Logic Programming,

volume 221 of LNCS, pages 168–179. Springer, 1985. doi:10.1007/3-540-16479-0 17.

[64] W. Visser, K. Havelund, G. Brat, S.-J. Park, and F. Lerda. Model Checking Programs. Automated

Software Engineering, 10(2):3–11, 2002. doi:10.5555/786768.786967.

[65] B. H. Wilcox. Robotic vehicles for planetary exploration. Applied Intelligence, 2(2):181–193, 1992.

doi:10.1007/BF00058762.

[66] T. Wright, A. West, M. Licata, N. Hawes, and B. Lennox. Simulating ionising radiation in gazebo
for robotic nuclear inspection challenges. Robotics, 10(3), 2021. doi:10.3390/robotics10030086.

36

Appendices

A Remote Inspection Contracts

This appendix contains the full listing of the RCL context and the contracts of all four nodes from our
case study in §4.

Context

• WayP : R × R → N
• RadStat : {red, orange, green}
• CommandSet : {move(R, R), inspect(N)}
• PositionType : R × R → B
• AtType : R × R → B
• InspectedType : N → B
• SensorsType : ∅

agent

• inputs (wayP : WayP, at : AtType, radiationStatus : RadStat, inspected : InspectedType )
• outputs (command : CommandSet )
• topics (gazebo radiation plugins/Command command matches : out.command,

gazebo radiation plugins/Inspection inspected matches : in.inspected,
gazebo radiation plugins/At at matches : in.at,
int16 wayP matches : in.wayP,
string radiationStatus matches : in.radiationStatus )

• AA(iA) : in.radiationStatus ∈ {red, orange, green}
• GA(oA) : ∀ x (cid:48), y(cid:48) ∈ REAL, i ∈ NATURAL · in.at(x (cid:48), y(cid:48)) = TRUE ∧ in.wayP(x (cid:48), y(cid:48)) =
i ∧ in.inspected(i) = TRUE ∧ in.radiationStatus /∈ {red, orange} ⇒ ∃ x, y ∈ REAL ·
in.wayP(x, y) = i + 1 ∧ out.command = move(x, y)

• GA(oA) : ∀ x (cid:48), y(cid:48) ∈ REAL, i ∈ NATURAL · in.at(x (cid:48), y(cid:48)) = TRUE ∧ in.wayP(x (cid:48), y(cid:48)) = i ∧

in.inspected(i) = FALSE ⇒ out.command = inspect(i)

• GA(oA) : ∀ x (cid:48), y(cid:48) ∈ REAL, i ∈ NATURAL · in.radiationStatus ∈ {red, orange} ∨ ¬ ∃ x, y ∈
REAL · in.wayP(x, y) = i + 1 ⇒ ∃ x (cid:48)(cid:48), y(cid:48)(cid:48) ∈ REAL · in.wayP(x (cid:48)(cid:48), y(cid:48)(cid:48)) = 0 ∧ out.command =
move(x (cid:48)(cid:48), y(cid:48)(cid:48))

localisation

• inputs (sensors : SensorsType )
• outputs (position : PositionType )
• topics (geometry msgs/PoseWithCovarianceStamped amcl pose matches : out.position )
• AL(iL) : TRUE
• GL(oL) : ∃! x, y ∈ REAL · out.position(x, y)

navigation

• inputs (position : PositionType, command : CommandSet )
• outputs (at : AtType )

37

• topics (gazebo radiation plugins/Command command matches : in.command,

int16 currentLoc matches : in.position,
gazebo radiation plugins/At at matches : out.at )
• AN (iN ) : ∃! x, y ∈ REAL · in.position(x, y) = TRUE
• GN (oN ) : ∀ x, y ∈ REAL · in.command = move(x, y) ∧ in.position(x, y) = TRUE ⇔

out.at(x, y) = TRUE

radiationSensor

• inputs (r : REAL, command : CommandSet )
• outputs (radiationStatus : RadStat, inspected : InspectedType )
• topics (gazebo radiation plugins/Simulated Radiation Msg r matches : r,
gazebo radiation plugins/Command command matches : in.command,
gazebo radiation plugins/Inspection inspected matches : inspected,
string radiationStatus matches : out.radiationStatus )

• AR(iR) : 0 ≤ in.r
• GR(oR) : ∀ i ∈ NATURAL · in.command = inspect(i) ⇒ (out.inspected(i) = TRUE ∧
0 ≤ in.r ∧ in.r < 120 ⇒ out.radiationStatus = green ∧ 120 ≤ in.r ∧ in.r < 250 ⇒
out.radiationStatus = orange ∧ 250 ≤ in.r ⇒ out.radiationStatus = red)

38

B Hoare Proofs

This appendix contains the full Hoare Logic Proofs used in §4.4.4

B.1 Proof 1

{radiation at(i) < 10}

1 input := radiation_at(i)

{input < 10} - Assignment Axiom

1 IF (input < 10) THEN

{input < 10 ∧ input < 10}
{input < 10 ∧ green = green} - strengthening

output := green

{input < 10 ∧ output = green} - Assignment Axiom
{output = green} - weakening

ELSE

{input < 10 ∧ input ≥ 10}
{⊥} - strengthening

IF (input < 20) THEN

{⊥ ∧ input < 20}
{⊥} - strengthening

output := orange

{⊥} - Assignment axiom

ELSE

{⊥ ∧ input ≥ 20}
{⊥} - strengthening

output := red

1

1

2

1

1

1

2

1

{⊥} - Assignment axiom
{output = green} - weakening
{output = green} – Conditional Rule

{output = green} – Conditional Rule

B.2 Proof 2

{10 ≤ radiation at(i) < 20}

1 input := radiation_at(i)

{10 ≤ input < 20} - Assignment Axiom

1 IF (input < 10) THEN

{10 ≤ input < 20 ∧ input < 10}
{⊥} - strengthening

1

output := green

39

{⊥} - Assignment Axiom
{output = orange} - weakening

ELSE

{10 ≤ input < 20 ∧ input ≥ 10}
{10 ≤ input < 20} - strengthening

IF (input < 20) THEN

{10 ≤ input < 20 ∧ input < 20}
{10 ≤ input < 20 ∧ orange = orange} - strengthening

output := orange

{10 ≤ input < 20 ∧ output = orange} - Assignment axiom
{output = orange} - weakening

ELSE

{10 ≤ input < 20 ∧ input ≥ 20}
{⊥} - strengthening

output := red

1

2

1

1

1

2

1

{⊥} - Assignment axiom
{output = orange} - weakening
{output = orange} – Conditional Rule

{output = orange} – Conditional Rule

B.3 Proof 3

{radiation at(i) ≥ 20}

1 input := radiation_at(i)

{input ≥ 20} - Assignment Axiom

1 IF (input < 10) THEN

1

1

2

1

1

{input ≥ 20 ∧ input < 10}
{⊥} - strengthening

output := green

{⊥} - Assignment Axiom
{output = red} - weakening

ELSE

{input ≥ 20 ∧ input ≥ 10}
{input ≥ 20} - strengthening

IF (input < 20) THEN

{input ≥ 20 ∧ input < 20}
{⊥} - strengthening

output := orange

{⊥} - Assignment axiom
{output = red} - weakening

40

1

2

1

ELSE

{input ≥ 20 ∧ input ≥ 20}
{input ≥ 20 ∧ red = red} - strengthening

output := red

{input ≥ 20 ∧ output = red} - Assignment axiom
{output = red} - weakening
{output = red} – Conditional Rule

{output = red} – Conditional Rule

B.4 Proof 4

{True}
{radiation at(i) = radiation at(i)} - strengthening

1 input := radiation_at(i)

{input = radiation at(i)} - Assignment Axiom

1 IF (input < 10) THEN

{input = radiation at(i) ∧ input < 10}

output := green

{input = radiation at(i) ∧ input < 10} - Assignment Axiom
{input = radiation at(i)} - weakening

ELSE

{input = radiation at(i) ∧ input ≥ 10}
{input = radiation at(i)} - strengthening

IF (input < 20) THEN

{input = radiation at(i) ∧ input < 20}

output := orange

{input = radiation at(i) ∧ input < 20} - Assignment axiom
{input = radiation at(i)} - weakening

ELSE

{input = radiation at(i) ∧ input ≥ 20}

output := red

1

1

2

1

1

1

2

1

{input = radiation at(i) ∧ input ≥ 20} - Assignment axiom
{input = radiation at(i)} - weakening
{input = radiation at(i)} – Conditional Rule

{input = radiation at(i)} – Conditional Rule

41

C From RCL to RML

This appendix contains additional information on RML and the translation from RCL to RML.

(atom)

atom → (cid:104)atom, {}(cid:105)

(and/or)

g1 → (cid:104)t1, ET1(cid:105) ∧ g2 → (cid:104)t2, ET2(cid:105)
g1op g2 → (cid:104)t1op t2, ET1 ∪ ET2(cid:105)

op∈{∧,∨}

(iﬀ)

g1 → (cid:104)t1, ET1(cid:105) ∧ g2 → (cid:104)t2, ET2(cid:105)
g1 ⇔ g2 → (cid:104)(t1 ∧ t2) ∨ (¬ t1 ∧ ¬ t2), ET1 ∪ ET2(cid:105)

(implies)

g1 → (cid:104)t1, ET1(cid:105) ∧ g2 → (cid:104)t2, ET2(cid:105)
g1 ⇒ g2 → (cid:104)(¬ t1 ∧ t2) ∨ (¬ t1 ∧ ¬ t2) ∨ (t1 ∧ t2), ET1 ∪ ET2(cid:105)

(equals)

a1 == a2 → (cid:104)ET , {(cid:104)ET , (a1 : a2)(cid:105)}(cid:105)

(not-equals)

a1! = a2 → (cid:104)¬ ET , {(cid:104)ET , (a1 : a2)(cid:105)}(cid:105)

(exists)

g → (cid:104)t, ET (cid:105)
∃ x · g → (cid:104){let x; t}, ET (cid:105)

(guarantee)

g → (cid:104)t, ET (cid:105)
G(g) → (cid:104)(t)∗, ET (cid:105)

(guarantees)

g1 → (cid:104)t1, ET1(cid:105) ∧ . . . ∧ gn → (cid:104)tn, ETn(cid:105)
G(g1), . . . , G(gn) → (cid:104)t1 ∧ . . . ∧ tn, ET1 ∪ . . . ∪ ETn(cid:105)

Figure 8: RML partial translation.

In Fig. 8, the operational semantics of the translation function from RCL descriptions to RML
speciﬁcations is given. Each rule in Fig. 8 formalises a single-step translation. For instance, rule
(and/or) denotes how to translate the conjunction/disjunction of two RCL guarantees. This can be
done ﬁrst by translating the two guarantees g1 and g2 into RML; then, by combining the results
obtained using the corresponding RML operator. For the rule (equals), at the guarantee level we
require that a certain information in a topic has a speciﬁc value. This is mapped into an event type
that requires the event to have the same information. We recall that an event matches an event type
if the latter is included in the former. Since we want to guarantee that the information identiﬁed by
a1 has value a2, the resulting event type has to check that such correspondence holds, and this can be
done by adding the pair a1 : a2 in the event type.

The (exists) rule tackles the use of variables. On RCL side, the contract says that exists x for which
the guarantee g holds. This can be straightforwardly mapped into a parametric term in RML, where
variable x is used inside the term t (the one derived by g). As usual, the (forall) rule can be obtained
by negating the (exists) rule. Finally, (guarantee) and (guarantees) rules denote the translation step
for single and multiple guarantees, respectively. To translate multiple guarantees, each guarantee gi is
translated separately, and the resulting RML terms ti are combined using the ∧ RML operator. In this
way, all guarantees are required to be satisﬁed. To translate a guarantee G(g), ﬁrst g is translated into
the RML term t. A ∗ post-ﬁx operator is then added to t, meaning that t can be repeated as many
times as necessary. We need this operator because the guarantees need to be checked continuously,
and not only once.

42

