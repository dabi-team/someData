2
2
0
2

r
a

M
6
1

]
E
S
.
s
c
[

1
v
7
1
9
8
0
.
3
0
2
2
:
v
i
X
r
a

Sound Development of Safety Supervisors

Mario Gleirscher12[0000−0002−9445−6863](cid:63), Lukas Plecher1[0000−0002−4991−1636],
and Jan Peleska1[0000−0003−3667−9775](cid:63)(cid:63)

1 Mathematics & Computer Science, University of Bremen, Bremen, Germany
2 Autonomy Assurance International Programme, University of York, York, UK
{gleirscher,plecher,peleska}@uni-bremen.de

Abstract. Safety supervisors are controllers enforcing safety properties
by keeping a system in (or returning it to) a safe state. The development
of such high-integrity components can beneﬁt from a rigorous workﬂow
integrating formal design and veriﬁcation. In this paper, we present a
workﬂow for the sound development of safety supervisors combining the
best of two worlds, veriﬁed synthesis and complete testing. Synthesis al-
lows one to focus on problem speciﬁcation and model validation. Testing
compensates for the crossing of abstraction, formalism, and tool bound-
aries and is a key element to obtain certiﬁcation credit before entry into
service. We establish soundness of our workﬂow through a rigorous ar-
gument. Our approach is tool-supported, aims at modern autonomous
systems, and is illustrated with a collaborative robotics example.

Keywords: Formal veriﬁcation · Synthesis · Model-based testing · Dis-
crete-event control · Supervisory control · Autonomous systems · Robots

1

Introduction

Safety supervisors (supervisors for short) are discrete-event controllers that en-
force probabilistic safety properties in modern autonomous systems such as
human-robot collaboration and autonomous driving. Supervisor development
beneﬁts from design and test automation. Because supervisors are high-integrity
components, their automation needs to be rigorously assured. This rigor sug-
gests veriﬁed synthesis for design automation and model-based conformance test
for test automation. Indeed, standards and regulations for safety-critical sys-
tems (e.g., [22,21,38,39]) require testing as a key element to obtain certiﬁcation
credit before entry into service. To get the best of the two worlds—synthesis and
test—a crossing of the boundaries between diﬀerent abstractions, formalisms,
and tools is inevitable. This involves bridging the gap between synthesis, the
derivation of test suites from a synthesized supervisor reference, the generation
of executable code, its test and deployment on a control system platform, and
its integration into the wider system to be put into service.

(cid:63) Corresponding author
(cid:63)(cid:63) Partially funded by the German Ministry of Economics, Grant Agreement 20X1908E.

 
 
 
 
 
 
2

Gleirscher, Plecher, Peleska

Fig. 1: Example of a safety supervisor. Nodes and edges denote states (S) and
transitions (T ) and edge labels signify input/output expressions ((i, o) ∈ Σ).

To resolve this challenge, we propose a rigorous workﬂow for the sound de-
velopment, in particular, the synthesis and complete test, of safety supervisors.
Prior to explaining our workﬂow, we illustrate safety supervision by example
of an operator collaborating with a robot on a welding and assembly task in a
workcell with a spot welder [13,14]. These actors perform dangerous actions (e.g.,
robot movements, welding steps) possibly reaching hazardous states (e.g., op-
erator near the active spot welder, HS ; operator and robot on the workbench,
HRW ). To reduce accident likelihood, such states (Figure 1) need to be reacted
to. These reactions are under the responsibility of a supervisor (Figure 1) enforc-
ing probabilistic safety properties of the workcell, such as “accident a is less likely
than probability pr a” or “hazard h occurs less likely than pr h”. The supervisor’s
behavior comprises (i) the detection of critical events (e.g., si_HSact), (ii) the
performance of mitigation actions (e.g., si_stoppedfun) to react to such events
and reach a safe state (e.g., HSm), and (iii) avoiding a paused task or degraded
task performance, the execution of resumption actions (e.g., si_HSressafmod)
to resolve the event and to return to a safe but productive state (here, 0).

Extending our previous work [16], we propose the derivation of symbolic ﬁ-
nite state machines (SFSM) used as test references for model-based testing with
complete methods. The resulting test suites allow for a proof of conformance
(i.e., observational equivalence) between the generated supervisor code and the
reference. The hypotheses to be fulﬁlled to guarantee test suite completeness can
be checked by simple static analyses of the supervisor code. We provide tool sup-
port for both these steps, explain the tool qualiﬁcation obligations, and present
a rigorous argument by applying Hoare logic on the workﬂow to obtain certiﬁca-
tion credit for the supervisor, on the basis of the development, veriﬁcation, and
validation process, and the artifacts produced in each workﬂow stage.

Sect. 2 summarizes the proposed workﬂow. Sect. 3 details each workﬂow
stage. In Sect. 4, we argue for the soundness of our approach, make our assump-
tions explicit, and show how we reduce several error possibilities in our workﬂow.
Sect. 5 summarizes related work. We add concluding remarks in Sect. 6.

HRWasi_HRWmit2funsi_HRWmit2safmodHRWmsi_HRWmitHSasi_stoppedfunsi_stoppedsafmodHSmsi_HSmitsi_HRWressafmodsi_HRWresfun0s_noopHRWressi_HRWactsi_HSacts_noopHSressi_HSressafmod: i / oeaveArearloc=atWeldSpot&notif=leaveArea&safmod=stopped&wact=idle&lgtBar=false&notif_leaveWrkb=false&ract=welding &rngDet=farsafmod=normal&notif_leaveWrkb=false&wact=idle&ract=welding&notif=lInput label i:Output label o:Sound Development of Safety Supervisors

3

Fig. 2: Stages Pi and artifacts of the proposed supervisor development workﬂow

2 Overview of the Workﬂow

Figure 2 shows our workﬂow. In P1, we construct a stochastic world model W
describing the behaviors of all relevant actors (e.g., humans, robots, equipment)
and the supervisor. W includes a range of controller behaviors some of which—
when implemented correctly—guarantee that the risk in the actual world is
acceptable, provided that the stochastic assumptions have been made to the
safe side. This range is denoted as the supervisor design space C. P1 adopts our
work [14,13] based on policy synthesis for Markov decision processes (MDPs)
[24,23] and selects controller behaviors from C that meet requirements φ (see
example in Sect. 1) speciﬁed in probabilistic computation tree logic (PCTL;
[24]) and veriﬁed of W (and C). While maintaining the constraint φ, the synthesis
procedure applies objectives (e.g., maximum performance, minimum cost) and
selects an optimal supervisor behavior C ∈ C.

In P2, C is transformed into a test reference R, an SFSM [29] whose control
states are called risk states and transitions are labeled with input/output (I/O)
pairs (e.g., Figure 1). The input alphabet of R speciﬁes the events (i.e., state
changes in W ) observed and the output alphabet the signals issued to W by the
supervisor. Input labels model guard conditions that, when holding true of a
world state, enable or trigger their transition (e.g., si_HSressafmod in Figure 1).
In P3, C is translated into a software component C executed by the control
system of a robotic or autonomous system. Following an embedded systems
tradition, our example uses C++ as the target language for C. Moreover, we
assume that SFSMs have a simpler semantics than the executable code.

In P4, a complete test suite TS for checking C against R is generated, using
a general input equivalence class testing strategy for SFSMs [17]. The term com-
plete means that—provided certain hypotheses hold—TS will (i) accept every C
whose behavior is represented by an SFSM which is observationally equivalent
to R, and (ii) reject every non-equivalent implementation. It is shown below that
these hypotheses are fulﬁlled by C, so that passing TS corresponds to a proof
of observational equivalence.

In P5, TS is run against C to record inputs, associated outputs, and the ver-
dicts V obtained for each test case in TS. A generated test harness TH, emulating
the target platform, acts as the test oracle by comparing the I/O traces observed
by the wrapper TW during execution of TS to the traces expected according to R.

P1:SupervisorSynthesisMDP/DTMCWwithYapandPrismP2:ReferenceGenerationSFSMwithYapP3:CodeGenerationE.g.,C/C++orC#withYapP4:TestSuiteDerivationFSM,I/OtraceswithlibfsmtestP5:ConformanceTestingUsinglibfsmtestandtestharnessTHWorldspec.W(riskmodel,designspaceC)SupervisorbehaviorCCReferenceRImplementationC,testwrapperTWCTestsuiteTSVerdictsV4

Gleirscher, Plecher, Peleska

3 Workﬂow Stages

This section details the ﬁve workﬂow stages outlined in Sect. 2 and Figure 2.

3.1 P1: Risk-informed Supervisor Synthesis

This section summarizes [14] for the construction of W and selection of the
supervisor behavior C from W . Below, P; Q, P (cid:117) Q, P (cid:63), and P \ Q signify
the sequential composition of the behaviors P and Q, non-deterministic choice
between P and Q, non-deterministic but ﬁnite repetition of P, and the removal
of Q from P, respectively. Moreover, P (cid:118) Q denotes that Q reﬁnes P while also
preserving progress, and P = Q that P and Q are observationally equivalent.

First, we specify W as a probabilistic program W = (E; C)(cid:63) alternating be-
tween an environment E (e.g., robot, operator) and a supervisor design space C.
Given the set AW = AE ∪ AC of all probabilistic commands of W (e.g., operator
or robot moves, welding steps, Sect. 1), we require E and C to be reﬁnements of
the command bundles ((cid:117)α∈AE α) (cid:118) E and ((cid:117)α∈AC α) (cid:118) C. With idle ∈ AC, the
world without the supervisor can be generated by W \ C = (E; idle)(cid:63).

Let a set V of ﬁnite-sorted variables, type v the sort of v ∈ V , and the
universe U = (cid:83)
v∈V type v. A state is a valuation function s : V → U with ∀v ∈
V : s(v) ∈ type v. Map restriction ·|V (cid:48) restricts a (set of) state(s) from V → U
to (V ∩ V (cid:48)) → U. Let S be the set of all states. Given α : S → 2S for α ∈ AW ,
by inductively applying W to an initial state s0 ∈ S, we obtain an MDP W
and the set S ⊆ S of states reachable by W(s0).3 S is labeled with atomic
propositions. W is a labeled transition system whose transition relation encodes
non-deterministic and probabilistic choice. MDPs can model uncertainties about
uncontrolled or non-modeled aspects in E. See, e.g., [24] for further details.

We model risk using a set F ⊂ V of P-sorted variables describing the critical
events in W as risk factors [15]. A risk factor f ∈ F (Figure 3a) has at least
three phases P = {0, a, m} as well as phase transitions in AC modeling the life-
cycle of handling f , for example, from inactive (0) to active (f a) to mitigated
(f m) and back to inactive. The example in Sect. 1 uses three factors, F =
{HS , HC , HRW }. That way, F induces a notion of risk state in S. C can then be
associated with states S = S|F ⊆ (F → P), which represent the possible control
states of any supervisor policy C, test reference R, and implementation C.

Freedom of choice in E and C is resolved by reﬁning indeterminacy in E
through uniformly distributed probabilistic choice and in C by deriving a policy, a
choice resolution for each state in S where the supervisor is enabled and can make
a decision. The result is a discrete-time Markov chain (DTMC) (E; C)(cid:63) (cid:119) W, a
labeled transition system without indeterminacy. Here, policy derivation involves
both sub-setting C using PCTL constraints φ and Pareto-optimizing multiple
objectives [24]. Any resulting optimal DTMC (E; C)(cid:63) is thus veriﬁed against φ,
establishing (E; C)(cid:63) |= φ, and includes the selected behavior C (cid:119) C.

3 Below, we mostly abbreviate P(s0) to P when referring to the transition relation of a
program P executed from initial state s0 ∈ S. So, P |= φ actually means P(s0) |= φ.

Sound Development of Safety Supervisors

5

(a) Phases and transitions of factor f

(b) Syntactic interface between E and C

Fig. 3: Risk factor and supervisor interface

3.2 P2: Test Reference Generation

For the translation of C into a test reference R, we deﬁne the I/O alphabet
Σ ⊆ ΣI × ΣO with ΣI = I → U and ΣO = O → U for monitored and controlled
variables I, O ⊆ V , resulting in the syntactic interface [5] of C. This interface
(Figure 3b) deﬁnes the nature of the changes in E that any C can observe and
perform. We require (I ∪ O) ∩ F = ∅ but allow an overlap of I and O.

To obtain R as an operation reﬁnement of the parallel composition of all fac-
tors in F , we translate the C-fragment of the transition relation of the DTMC
(E; C)(cid:63) into a deterministic SFSM R = (S, Σ, T, s) with states S = S|F , the tran-
sition relation T ⊆ S × Σ × S, and the initial state s ∈ S congruent with s0 (i.e.,
∀f ∈ F : s0(f ) = s(f )), usually s = 0. Given a DTMC transition (s, s(cid:48)) ∈ S × S,
the source state s is mapped to input i = s|I ∈ ΣI (the observed event) and risk
state r ∈ S. The control and state updates o = s|O ∈ ΣO and r(cid:48) ∈ S are derived
from the diﬀerence in the controlled and factor variables O ∪ F between s and
the target state s(cid:48). Figure 1 shows an example of R. Finally, R is provided in a
format readable by libfsmtest4 [2] for test suite generation (Sect. 3.4).

3.3 P3: Code Generation
Independent of P2, the C-fragment of the transition relation of (E; C)(cid:63) is trans-
lated to an implementation C (Figure 4a). Similar to the translation to R
(Sect. 3.2), every transition of C is mapped5 to a guarded command [α] i ∧
r : (o, r(cid:48)) ← ctrSignal(i, r) with r, r(cid:48) ∈ S, (i, o) ∈ Σ, and action name α ∈ AC
derived from F , r, and r(cid:48). C is intentionally simple (e.g., ﬂat branching struc-
ture) and wrapped into platform-speciﬁc code (not shown) for data processing
and communication. Figure 4b depicts a fragment of C for our running example.
As opposed to R, the representation of C can vary signiﬁcantly. For instance,
in Figure 4b, we consider a C++ component for a low-level real-time implementa-
tion. Alternatively, one may want to derive VHDL or Verilog HDL to synthesize

4 Licensed according to MIT license https://opensource.org/licenses/MIT. Source

code available under https://bitbucket.org/JanPeleska/libfsmtest.

5 Note that the elements of ΣI and S are used as propositions in guard conditions.

0fmfaobserveff-nominaloperationmitigatefrecoverfromfmitigatefobserveff-endangeredoperationf-mitigatedoperationSupervisordesignspaceCsafmod:SAFMODrloc:LOCwact:ACTract:ACTrngDet:RNGDETlgtBar:Bnotif:NOTIFnotifWrkb:Bsafmod:SAFMODract:ACTwact:ACTnotif:NOTIFnotifWrkb:BIO6

Gleirscher, Plecher, Peleska

(a) Pseudo code of a generic supervisor

(b) Fragment of the supervisor implementation CC++ for Figure 1

Fig. 4: Supervisor pseudo code and implementation fragment

an FPGA.6 In [14], we consider a C# component used in a simulation of W
in a Robot Operating System-enabled digital twinning environment [8]. R can
thus be shared between a varying CC++, CC#, and CVHDL. The only diﬀerence
on the testing side is in the I/O wrapper used in the test harness (Sect. 3.4) to
deliver the inputs to C and record the outputs of C. The translations into R and
C and the generation of the test wrapper are performed with the Yap tool.7

3.4 P4: Test Suite Generation

We avoid the costly veriﬁcation of the (potentially changing) code generator
used in P3. Instead, we generate a conformance test suite that, when passed,
corresponds to a correctness proof of C. The SFSM reference model R (Sect. 3.2)
and the supervisor implementation C (Sect. 3.3) allow us to apply a model-
based conformance testing approach for verifying R = C, the observational
equivalence of R and C. Indeed, complete test methods enable us to prove that
the system under test (SUT) conforms to a given reference model under certain
hypotheses [28]. A complete test suite is derived from R for C as follows.

Step 1. Since R is a deterministic SFSM which outputs a ﬁnite range of
control signals, we can apply the equivalence class testing theory of Huang et
al. [17], which has been elaborated for a more general class of Kripke structures
including SFSMs like R. Moreover, the guard conditions c in R are even mutually
exclusive (see the construction of T in Sect. 3.2 and Sect. 4.4). Therefore, an input
equivalence class corresponds to the set of input valuations s|I : I → U satisfying
a speciﬁc guard condition c. We write s |= c if the guard condition c evaluates to

6 VHSIC or Verilog hardware description language (VHDL or Verilog HDL); ﬁeld-

programmable gate array (FPGA)

7 Features and examples available in Yap 0.8+, https://yap.gleirscher.at.

1:procedureSafetySupervisor(inEventi,outSignalo)2:r←init(cid:46)init.control/riskstate3:whiletruedo(cid:46)implementsT4:[α]α∈AC,i∈ΣI,r∈Si∧r:(o,r(cid:48))←ctrSignal(i,r)1classSafetySupervisor{...2voidcycle(){...//(a)line3:calledbyplatform3if(...){...}...//(a)line4:checkforinputs4elseif(rloc==ATWELDSPOT&&...&&rngDet==FAR){//(a)line4:checkforinputi5if(HSp==ACT&&HCp==INACT&&HRWp==INACT){//checkforstater6HSp=MIT;//statechanger→r(cid:48)(si_HSmit)7}elseif(HSp==MIT&&...&&HRWp==INACT){//checkforstater8safmod=NORMAL;//controlsignalo(si_HSressafmod)9}else{/*idle*/}10}...else{/*idle*/}11}...};Sound Development of Safety Supervisors

7

Fig. 5: Commuting diagrams reﬂecting the observational equivalences (=FSM,
=SFSM), pass relations (passFSM, passSFSM), and abstraction map (A = TW)

true, after having replaced all occurrences of input variables v ∈ I in c by value
s(v). In any SFSM state, all members of an input class produce the same output
values. We use the guard formula c itself as an identiﬁer of the associated input
equivalence class {s|I : I → U | s ∈ S ∧ s |= c}.

Step 2. With identiﬁers c as ﬁnite input alphabet and the ﬁnite set of possible
outputs as output alphabet, R is abstracted to a minimal, deterministic, ﬁnite
state machine (FSM) A(R) (Figure 5 left) with I/O alphabet A(R)I × A(R)O.
Using A(R) as a reference model, the H-Method [7] is applied to derive a com-
plete FSM test suite TSfsm . The completeness of TSfsm is guaranteed provided
that the true behavior of C can be abstracted to a deterministic FSM with at
most m ≥ n states, where n is the number of states in A(R). The generation
of TSfsm is performed by means of the open source library libfsmtest, which
contains algorithms for model-based testing against FSMs [2].

Step 3. Test suite TSfsm is translated to an SFSM test suite TS by select-
ing an input valuation s|I from each input equivalence class c and replacing
each test case t = c1 . . . ck ∈ TSfsm (i.e., sequence of input class identiﬁers) by
the sequences s1|I . . . sk|I of valuation functions. It has been shown that TS is
complete whenever TSfsm is [17].

3.5 P5: Conformance Testing

libfsmtest provides a generic test harness TH for executing test suites generated
from FSMs against SUTs. For verifying C, TH executes the complete FSM test
suite TSfsm . To this end, the harness uses a test wrapper TW for (i) reﬁning each
c ∈ A(R)I in a test case t ∈ TSfsm to a concrete input valuation s|I ∈ ΣI
of C, (ii) calling C to perform one control step, and (iii) abstracting C-output
valuations s|O ∈ ΣO back to y ∈ A(R)O (Figure 5 right). Test harness, wrapper,
and supervisor code C are compiled and linked; this results in a test executable
TH[TW[C]]. The component TW[C] of the test executable acts like an FSM over
alphabets A(R)I , A(R)O. This FSM interface is used by the test harness to
stimulate TW[C] with inputs from A(R)I and to check whether the outputs y ∈
A(R)O conform to the outputs expected according to reference FSM A(R).

TW implements two bijections, γ : A(R)I → ΣI for step (i) and ω : ΣO →
A(R)O for step (iii). Map γ satisﬁes ∀c ∈ A(R)I : γ(c) |= c, and ω fulﬁlls
∀s ∈ S : s|O ∈ CO ⇒ s |= ω(s|O). These mappings ensure that the diagrams in

RSFSMs{CA(R)FSMs{TW[C]=SFSM=FSMAACTW[C]TSTSfsmpassSFSM(TH[TW])(ii)passFSM(TH)TW−1(i)(iii)A8

Gleirscher, Plecher, Peleska

Figure 5 are both commutative, that is, the execution of TSfsm against TW[C] by
TH results in the execution of TS against C by TH[TW[·]].

Consider, for example, transition si_HSressafmod in Figure 1. Function
γ maps A(R)-input rloc=atWeldSpot&...&rngDet=far to C-input valuation
{rloc (cid:55)→ atWeldSpot, . . . , rngDet (cid:55)→ far}. The wrapper implements this sim-
ply by assignments rloc=atWeldSpot;...;rngDet=far;. If the corresponding
C-step produces any output valuation in {safmod (cid:55)→ y1, . . . , notif (cid:55)→ yk}, this
is mapped by ω to A(R)-output safmod=y1&...&notif=yk.

4 Workﬂow Soundness

It remains to be shown that the stages P1 to P5 establish the chain of reﬁnements

W P1= (E; C)(cid:63)

P1
(cid:118) (E; C)(cid:63)

P1
(cid:118) (E; C)(cid:63) P2= (E; R)(cid:63) P3,P4,P5= (E; C)(cid:63) .

(1)

Through model checking of (E; C)(cid:63) |= φ(cid:48), our notion of (cid:118) preserves trustworthi-
ness (i.e., φ, Sect. 3.1) comprising world safety and supervision progress. After
having established through P1 that C is trustworthy, trustworthiness of R and
C can be inferred from the two observational equivalences in (1). Furthermore,
C remains trustworthy as long as (E; C)(cid:63)(s) ⊆ S, implying that E and C are
re-initialized congruently in s ∈ S. So, the main objective of proving workﬂow
soundness is to establish that (1) holds.

Following safety-critical control standards (e.g., DO-178C/330 [38,39], IEC
61508 [19], ISO 10218 [20]), we argue for the soundness of our workﬂow (G)
and the reﬁnement chain (1). Our argument for G (top-level in Figure 6) aims
at ruling out that a faulty R, test theory, TS generator, or test harness mask
errors inside C. Arguing for G is known as veriﬁcation of the veriﬁcation results.
By semi-formal weakest precondition ( ˜wp) reasoning (J2), we establish a Hoare
triple (J1) for each workﬂow stage (G1 to G5) and implication relationships
(J3) between the post- and preconditions (Table 1) of these triples to estab-
lish G, the soundness of the sequential composition P1; P2; P3; P4; P5 (Figure 2).

4.1 Assurance of P1: Supervisor Synthesis

For P1, we need to establish

{pre1}P1{post1} .

(G1)

pre1: For the synthesis stage to yield a trustworthy result, we ﬁrst identify
a complete list φ of well-formedness properties and supervisor factor handling
requirements (pre1.1) for the MDP W . Completeness of φ relies on the complete-
ness of F , the latter on state-of-the-art hazard analysis and risk assessment. We
are further provided that W is a trustworthy world model (pre1.2) because we
have achieved W |= φ [14,13] by probabilistic model checking. Note that errors
in E and C can be iteratively identiﬁed by validating φ (e.g., completeness and
vacuity checks) and re-checking W |= φ.

Sound Development of Safety Supervisors

9

Fig. 6: Overview of the workﬂow assurance case in goal structuring notation [26]

Table 1: Overview of pre- and post-conditions of the workﬂow stages

Pi prei
1 Requirements φ are complete and world

model W is trustworthy.

2 Supervisor behavior C is

trustwor-
thy, deterministic, factor-complete, and
s0(initial state)-compatible.

posti
Chosen supervisor behavior C can be
trusted.
Reference R is deterministic,
complete up to idle
compatible, and accepted by P4.

input-
s0-

self-loops,

3 post1 and syntactic interface is deﬁned. Generated code C is compatible with the

4 The complete testing theory is correct,
the prerequisites for applying the selected
test generation method are fulﬁlled, and
the test suite validator ValH is correct.

test harness and statically analyzable.
The generated FSM test suite TSfsm
is complete for checking observational
equivalence between A(R) and FSMs
over the same alphabet with at most m
states, or ValH will indicate an error.

5 post4, TW is correct, and TH is correct. C passes test suite if and only if it is ob-

servationally equivalent to R.

post1: Here, our goal is to preserve trustworthiness φ in the supervisor be-
havior C ∈ C selected according to Sect. 3.1, namely, (E; C)(cid:63) |= φ(cid:48) established
by the policy synthesis facility of the model checker (post1.2). φ(cid:48) with φ ⇒ φ(cid:48)
contains only those properties that can be checked of DTMCs (post1.1). Recall
that E results from converting indeterminacy in E into probabilistic choice, thus
qualitatively preserving all behavior of E in E while C results from ﬁxing all non-
deterministic choices in C. C will thus be deterministic and, because of being
exposed to all behaviors of E, be able to deal with all environments producible
by W from s0 (or s). Given P1, we can now see, that the weakest precondition
of post1 under P1 is implied by pre1, formally,

{φ is complete, W |= φ} ⇒ ˜wp(P1, {φ(cid:48) is complete, (E; C)(cid:63) |= φ(cid:48)}) .

(2)

By Proposition (2), we have now established Proposition (G1).

G Supervisor synthesis& test workflow issoundS Argument via Hoare-stylesequential composition of workflow stagesJ3 Hoare-style seq.  comp. is an accepted way of  decomposing the verification of I/O procedures C Subjected to ISO 10218(e.g., robotic safetyrequirements), IEC61508, DO-178C (e.g.,requirements traceabilityfrom components to system,tool qualification, etc.)J1  is true iff  is true & aftertermination of ,  istrueG2  Referencegeneration is sound G3 Code generation issound G4 Test suite derivationyields complete test suite  G5 Test harness (incl. I/Owrapper) executes test suitecorrectly against  G1 Supervisor  synthesis is sound J2 Apply  to input  satisfying , then  establishes GiSec. 4.1Sec. 4.2Sec. 4.3Sec. 4.4Sec. 4.510

Gleirscher, Plecher, Peleska

4.2 Assurance of P2: Reference Generation

For P2, we need to establish

{pre2}P2{post2} .

(G2)

pre2: We require that (i) C can be trusted, which is implied by post1.2. (ii) C
is expected to handle combinations of critical events, which is established by P1
generating commands for each factor in F . (iii) C has to be deterministic, which
is guaranteed by policy synthesis in P1. (iv) Supervisor behavior C is a function
of F and I, formally, I ⊂ V is such that ∀s, s(cid:48) ∈ S : (∀v ∈ F ∪ I : s(v) = s(cid:48)(v)) ⇒
C(s) = C(s(cid:48)). Note that we have now established post1 ∧ (iv) ⇒ pre2.

post2: (i) The equivalence (E; C)(cid:63) = (E; R)(cid:63) (post2.1) follows from the 1-to-1
translation of DTMC to SFSM transitions in P2 (Sect. 3.2). (ii) Factor handling
completeness (post2.2) and determinism (post2.3) of R are also maintained by
this translation and post1. (iii) Congruence of s0 and s (post2.4) follows from the
deﬁnition of R (Sect. 3.2), from s0 being the initial state of W and (E; C)(cid:63), and
from the fact that E cannot change F . (iv) Yap produces R in the libfsmtest
input format (post2.5). Note that R can be trusted ((E, R)(cid:63) |= φ(cid:48)) but is not
yet input-complete as self-loop transitions (i.e., idle actions) are both ignored
and not introduced by P2; this completion is done in P4.

We can now derive the weakest precondition of post2 under P2 as follows:

˜wp(P2, {post2.1, . . . , post2.5}) = { 1-to-1 translation from C to R ,
C’s transitions implement the risk factors in F ,
C is also deterministic over S|F ∪I ,

s0 ∈ S } .

(3)

(4)

(5)

(6)

Because conjuncts (i-iv) of pre2 imply the derived precondition parts, we have

post1 ∧ (iv) ⇒ pre2 ⇒ ˜wp(P2, {post2.1, . . . , post2.5}) .

(7)

By obtaining Proposition (7), we have established Proposition (G2).

4.3 Assurance of P3: Code Generation

For P3, we need to establish

{pre3}P3{post3} .

(G3)

pre3 includes post1, established by P1 according to Proposition (2), and the
deﬁnition of the sets F (implied by pre1), I, and O (implied by pre2).

post3: We require from P3 to obtain an implementation C that can be in-
tegrated with the test harness (post3.1) and is statically analyzable (post3.2),
allowing simple checks in P4 using a custom lex/yacc parser or Unix text process-
ing tools. For post3.1, Yap generates the I/O wrapper based on a libfsmtest
template and the variable sets F , I, and O. For post3.2, Yap produces C++

Sound Development of Safety Supervisors

11

code adhering to the structure in Figure 4a, assuring that no pre-processing di-
rectives are used and the branching structure is ﬂat and simple, see Figure 4b.
Trivially, post1 ⇒ pre3 and the weakest precondition of post3 under P3 is:

˜wp(P3, {post3.1, post3.2}) = { (F, I, O) deﬁned } .

Because the conjuncts of pre3 imply the derived precondition, we have

post1 ∧ pre2 ⇒ pre3 ⇒ ˜wp(P3, post3) .

Having veriﬁed Proposition (9), we have established Proposition (G3).

(8)

(9)

4.4 Assurance of P4: Test Suite Generation

For P4, we need to establish

{pre4}P4{post4} .

(G4)

pre4: As speciﬁed in Table 1, the precondition to be established for task P4

consists of several main conjuncts.

pre4.1 requires the applied testing theory to be correct, when applied with
input equivalence classes speciﬁed by guard conditions and with the H-Method
for generating the intermediate FSM test suite TSfsm from A(R) (Sect. 3.4).
The correctness of the input equivalence class construction has been proven by
Huang et al. [17]. They have also shown that any complete FSM test generation
method can be applied for calculating TSfsm , and the resulting SFSM test suite
will always be complete as well [18]. Finally, Dorofeeva et al. [7] have proven the
completeness of the H-Method. These facts ensure the validity of pre4.1.

pre4.2 requires that the prerequisites for applying this test theory are fulﬁlled
by the reference model R and the implementation C. The four prerequisites to
be established are deﬁned and ensured as follows. (i) It has to be shown that
the reference model R can be interpreted as a deterministic reactive I/O state
transition system (pre4.2.1); this is a variant of Kripke structures that is used
as the semantic basis for models in Huang et al. [17]. SFSMs represent special
cases of reactive I/O state transition systems. The determinism of R is ensured
by post2. (ii) It has to be justiﬁed that the true behavior of C can be interpreted
as a deterministic reactive I/O state transition system (pre4.2.2). This is easy
to see, since the code generator creates C with a structure where a main loop
evaluates which guard condition can be applied and executes the corresponding
transition changing the internal control state and setting ﬁnite-valued outputs.
By static code analysis, it is shown that C uses exactly the same guard conditions
as R. This can be performed with Unix core utilities like grep, sed, and sort8.
Thus, C is deterministic since R is deterministic. (iii) Next, it has to be shown
that the implementation C does not possess more than m control states (m ≥ n,
where n ≤ |S| after minimization of R) (pre4.2.3). The number of states in A(R)

8 https://man7.org/linux/man-pages/dir_section_1.html

12

Gleirscher, Plecher, Peleska

can be directly determined from a description ﬁle containing all such states.
Again, a simple static analysis shows that the code uses the same control states,
so m = n. (iv) Finally, it has to be shown that each guard condition represents a
single input equivalence class (pre4.2.4). Indeed, this follows from the fact that
all guards are mutually exclusive, which has already been established by post2.
pre4.3: Instead of verifying the H-Method algorithm in libfsmtest, we check
the generated test suite TSfsm for consistency with the test suite speciﬁcation of
the H-Method. If the check fails, the algorithm can be ﬁxed, and the suite can
be created again. The check is automatically performed by a test suite validator
ValH . As explained in Sect. 4.6, this approach requires to qualify ValH . Qualify-
ing ValH instead of the H-Method algorithm has the advantage that the former
has a signiﬁcantly simpler implementation than the latter. Also, any future op-
timizations of the test algorithm will not aﬀect the tool qualiﬁcation (TQ) of
ValH , because the checks performed on the generated test suites do not depend
on the library, but only on the theory. Summarizing,

pre4 ≡ pre4.1 ∧ pre4.2 ∧ pre4.3,
pre4.3 ≡ pre4.2.1 ∧ pre4.2.2 ∧ pre4.2.3 ∧ pre4.2.4,

(Deﬁnition)

(Deﬁnition)

and the validity of pre4.1, pre4.2, pre4.2.1, pre4.2.2, pre4.2.3, and pre4.2.4 has
been ensured. The validity of pre4.3 is explained below. Therefore, the validity
of precondition pre4 is ensured as well.

post4: The post-condition to be established is that the test suite TSfsm
generated by P4 according to the steps described in Sect. 3.4 is complete for
testing any FSM over alphabets A(R)I , A(R)O with at most m states against
A(R), provided that pre4 holds and ValH does not indicate a generation error.

The weakest precondition ensuring post4 under P4 is

˜wp(P4, {post4}) = { Testing theory is correct ,
Prerequisites for applying testing theory are fulﬁlled ,
TSfsm is complete if ValH indicates no error }

Obviously,

By Proposition (13), we have established Proposition (G4).

pre4 ⇒ ˜wp(P4, post4) .

4.5 Assurance of P5: Conformance Testing

For P5, we need to establish

(10)

(11)

(12)

(13)

{pre5}P5{post5} .

(G5)

pre5: The post-condition to be established (see Table 1) states that C passes
the test suite TS if and only if it is observationally equivalent to R. As explained
in Sect. 3.5, the test wrapper with embedded supervisor (denoted by TW[C])

Sound Development of Safety Supervisors

13

implements an FSM over the same input and output alphabet as A(R). The
test executable TH[TW[C]] runs test suite TSfsm against TW[C]; this is equivalent
to running TS against C, provided that the wrapper implements the alphabet
mappings γ, ω correctly. Therefore, we require that TSfsm is complete (pre5.1),
which has already been established by post4. The additional conjuncts of pre5
are tool-related: (i) The test wrapper TW is correct—this is ensured by two sub-
conditions. pre5.2: TW correctly implements γ as deﬁned in Sect. 3.5. pre5.3: TW
correctly implements ω as deﬁned in Sect. 3.5. (ii) The test harness TH is correct—
this is ensured by three sub-conditions. pre5.4: TH skips no test cases from TSfsm .
pre5.5: TH neither skips nor adds nor changes inputs in a test case t ∈ TSfsm .
pre5.6: TH assigns verdict PASS to execution of t if and only if the I/O trace
produced by TW[C] for t is in the language L(A(R)) of A(R).

Preconditions pre5.2 and pre5.3 are ensured by comprehensive TQ tests (as
explained below in Sect. 4.6) qualifying the test wrapper. Precondition pre5.6
is ensured analogously for the checker component of the test harness TH. Pre-
conditions pre5.4 and pre5.5 are ensured by artifact-based TQ (Sect. 4.6): the
test cases actually executed and their associated test steps are documented in
a test execution log that is compared to the test suite TSfsm . The comparison
is performed by an execution log validator Vallog. The logging component of TH
and the log validator Vallog are qualiﬁed by means of comprehensive TQ tests.
post5: The test theory explained in Sect. 4.4 implies that post5 is equivalent

to the following alternative post-condition.

5: TW[C] passes the test suite TSfsm if and only if it is observationally

post(cid:48)
equivalent to A(R).

Of course, post5 and post(cid:48)
5 are only equivalent if the wrapper correctly imple-
ments the alphabet mappings γ and ω (Sect. 3.5). We know from post4 that
TSfsm is complete, so it is a good candidate for checking observational equiv-
alence. Additionally, however, it needs to be ensured that the test harness TH
executes the test suite correctly and performs the correct checks of observed
C-reactions against reactions expected according to A(R). Consequently, the
weakest precondition of post5 under P5 is

˜wp(P5, {post(cid:48)

5}) = { TSfsm is complete ,
TW implements γ correctly ,
TW implements ω correctly ,
TH skips no test cases of TSfsm ,
TH neither skips nor adds nor changes inputs in a test case ,
Test case t passes iﬀ TW[C](t) ∈ L(A(R)) }

(14)

(15)

(16)

(17)

(18)

(19)

Because the conjuncts of pre5 are equivalent to these preconditions, we have

pre5.1 ∧ · · · ∧ pre5.6 ⇒ ˜wp(P5, post5)

(20)

By Proposition (20), we have established Proposition (G5).

14

Gleirscher, Plecher, Peleska

4.6 Tool Qualiﬁcation

As described above, the soundness of the workﬂow establishing the reﬁnement
chain (1) depends on tools automating critical veriﬁcation steps. Following the
applicable standards for safety-critical systems development, this workﬂow re-
quires tool qualiﬁcation. For TQ-related considerations, we apply the avionic
standard RTCA DO-178C with annex DO-330 [38,39], because this is currently
the most speciﬁc and strict standard, as far as TQ is concerned. Fulﬁlling the
TQ requirements speciﬁed there implies compatibility with the requirements for
support tools according to IEC 61508 [19] and ISO 10218 [20].

Standards for the use of automation tools in development and veriﬁcation
(e.g., RTCA DO-178C) oﬀer three options to ensure that the tool-produced
artifacts (e.g., object code, test suites, test execution results) are correct. (1) If
an artifact is not veriﬁed by any other means, the tool needs to be qualiﬁed. (2)
If an artifact is veriﬁed manually by a systematic review or inspection, no TQ
is required. (3) If an artifact is veriﬁed by an automated checker replacing the
manual review/inspection procedure, then the checker needs to be qualiﬁed [4].
We call this artifact-based TQ, since the tool is “re-qualiﬁed” every time it
produces a new artifact (i.e., a new test suite in our case).

For either test automation tools or associated artifact checkers, the so-called
tool qualiﬁcation level TQL-4 speciﬁed in [38, Section 12.2.2] applies: this level
is intended for tools that may not produce errors in software to be deployed
in the target system, but whose failures may prevent the detection of errors in
target software. TQL-4 requires a documented development life cycle for the
tool, a comprehensive requirements speciﬁcation, and a veriﬁcation that these
requirements are fulﬁlled. Veriﬁcation can be performed by reviews, analyses
(including formal veriﬁcation), and tests. Formal veriﬁcation of the tool alone
cannot replace SW/HW integration tests of the tool on the platform where it is
deployed. For TQL-4 tools to be applied for the veriﬁcation of target software of
highest criticality (as discussed in this paper), the TQ tests need not only cover
all requirements, but also the code with 100% MC/DC coverage [38, p. 114].

We are aware that the workﬂow stages P1 and P2 are subjected to TQ as
well. However, the qualiﬁcation of model checkers and their results [37] in P1 is
more complicated, part of ongoing research, and thus out of scope here.

5 Related Work and Discussion

The approaches in [27,3] from collaborative robotics are perhaps closest to our
workﬂow (P1) as they include platform deployment (P3). While they focus on the
synthesis of overall robot controllers, we focus on supervisors but with a testing
stage reassuring implementation correctness. Villani et al. [36] integrate quan-
titative model checking (with Uppaal [1]) with conformance testing and fault
injection. The authors advocate cross-validation of Uppaal and FSM models.
Our approach diﬀers from theirs in two ways: (i) SFSMs do not require cross-
validation, since they are generated from a world model validated by model
checking. (ii) We do not need fault injection for testing, since our complete test
strategy corresponds to a formal code veriﬁcation by model checking.

Sound Development of Safety Supervisors

15

Research in complete testing methods is a very active ﬁeld [30]. We applied
the H-Method [7] in P4 because (i) it produces far fewer test cases than the
classical W-Method [6], but (ii) it allows for an intuitive test case selection,
facilitating the qualiﬁcation of the test case generator (Sect. 3.4). If the objective
of a test campaign is to provide complete suites with a minimal number of test
cases then the SPYH-Method [33] should be preferred to the H-Method.

Hazard/failure-oriented testing [10,25] and requirements falsiﬁcation based
on negative scenarios [35,11,34] are useful if R is not available or needs to be
validated and revised. In contrast, our approach is complete once R is validated,
that is, any deviation from R detectable by such techniques is also uncovered
by at least one test case generated by our approach. Moreover, our approach is
usable to test supervisor robustness without a realistic simulator for W .

The soundness argument for our workﬂow (Sect. 4) relies on proofs of com-
pleteness of the test suites generated with the testing theories for showing R = C.
Such proofs can be mechanized using proof assistants [32]. It is also possible to
generate test generation algorithms from the proof tool and prove their correct-
ness as a minor extension of the testing theory [31]. This could simplify the tool
qualiﬁcation argument in Sect. 4.4. However, some kind of TQ argument will still
be necessary, because proven algorithms do not guarantee correctness of their
execution on a target platform (e.g., a PC or cloud server), where additional
errors might be produced due to inadequate address or integer register sizes.

6 Conclusions

We proposed a rigorous workﬂow for the sound development (i.e., the veriﬁed
synthesis and code generation) of supervisory discrete-event controllers enforc-
ing safety properties in human-robot collaboration and other autonomous sys-
tem applications. The novelty of this workﬂow consists in (i) the generation of
a test reference model whose completeness and correctness is established by a
reﬁnement relation to a validated world model, (ii) the application of complete
model-based testing methods in combination with static analysis to obtain a
conformance proof of the safety supervisor code, and (iii) an explanation of how
the tools involved and the artifacts they produce can be qualiﬁed according the
most stringent requirements from standards for safety-critical systems develop-
ment. We employ Hoare logic and weakest precondition calculus (at a meta-level
rather than at the artifact level) to establish soundness of our workﬂow and use
goal structuring notation to structure and visualize the complex veriﬁcation and
validation argument to obtain certiﬁcation credit. The workﬂow is supported
by a tool chain: Yap [12] and a stochastic model checker (e.g., Prism [24]) for
Markov decision process generation and veriﬁcation, Yap for test reference and
code generation, and libfsmtest [2] for test suite derivation and execution.

To test the integrated HW/SW-system (i.e., robot, welding machine, safety
supervisor and simulation of human interactions), we will embed our approach
into a more general methodology for veriﬁcation and validation of autonomous
systems, starting at the module level considered here, and ending at the level of
the integrated overall system [9].

16

Gleirscher, Plecher, Peleska

References

1. Behrmann, G., David, A., Larsen, K.G.: A tutorial on UPPAAL. In: SFM. pp.

200–236 (2004). https://doi.org/10.1007/978-3-540-30080-9 7

2. Bergenthal, M., Krafczyk, N., Peleska, J., Sachtleben, R.: Libfsmtest – an open
source library for FSM-based testing. In: Cavalli, A., Men´endez, H.D. (eds.) ICTSS,
33rd Conf., November 10-12, 2021. LNCS, Springer (2022), to appear

3. Bersani, M.M., Soldo, M., Menghi, C., Pelliccione, P., Rossi, M.: PuRSUE – from
speciﬁcation of robotic environments to synthesis of controllers. Formal Aspects of
Computing 32(2-3), 187–227 (2020). https://doi.org/10.1007/s00165-020-00509-0
4. Brauer, J., Peleska, J., Schulze, U.: Eﬃcient and trustworthy tool qualiﬁcation for
model-based testing tools. In: Nielsen, B., Weise, C. (eds.) ICTSS, 24th Conf. pp.
8–23. No. 7641 in LNCS, Springer, Heidelberg (2012)

5. Broy, M.: A logical basis

for

component-oriented software

engineering. The Computer
tems
https://doi.org/10.1093/comjnl/bxq005

Journal

53(10),

1758–82

and sys-
(2010).

6. Chow, T.S.: Testing software design modeled by ﬁnite-state machines.
IEEE Transactions on Software Engineering SE-4(3), 178–186 (Mar 1978).
https://doi.org/10.1109/TSE.1978.231496

7. Dorofeeva, R., El-Fakih, K., Yevtushenko, N.: An improved conformance testing
method. In: Wang, F. (ed.) FORTE, 25th Conf., Taipei. LNCS, vol. 3731, pp.
204–218. Springer (2005). https://doi.org/10.1007/11562436 16

8. Douthwaite, J., Lesage, B., Gleirscher, M., Calinescu, R., Aitken, J.M., Alexan-
der, R., Law, J.: A modular digital twinning framework for safety assur-
402 (2021).
ance of collaborative robotics. Frontiers in Robotics and AI 8,
https://doi.org/10.3389/frobt.2021.758099

9. Eder, K.I., Huang, W., Peleska, J.: Complete agent-driven model-based
In: Farrell, M., Luckcuck, M.
(2021).
vol.

systems.
3rd Workshop. EPTCS,

system testing for autonomous
(eds.) FMAS,
https://doi.org/10.4204/EPTCS.348.4

54–72

348,

pp.

10. Gleirscher, M.: Hazard-based selection of test cases. In: Bertolino, A., Foster, H.,
Li, J.J. (eds.) AST, 6th ICSE Workshop. pp. 64–70. ACM, Honolulu, HI (2011).
https://doi.org/10.1145/1982595.1982609

11. Gleirscher, M.: Behavioral Safety of Technical Systems. Dissertation, Technical
University of Munich (2014), http://nbn-resolving.de/urn/resolver.pl?urn:
nbn:de:bvb:91-diss-20141120-1221841-0-1

12. Gleirscher, M.: Yap: Tool support for deriving safety controllers from hazard
analysis and risk assessments. In: Luckuck, M., Farrell, M. (eds.) FMAS, 2nd
Workshop, EPTCS, vol. 329, pp. 31–47. Open Publishing Association (2020).
https://doi.org/10.4204/EPTCS.329.4

13. Gleirscher, M., Calinescu, R.: Safety controller synthesis for collaborative robots.
In: Li, Y., Liew, A. (eds.) ICECCS, 25th Int. Conf., Singapore, pp. 83–92. ACM
(2020). https://doi.org/10.1109/ICECCS51672.2020.00017

14. Gleirscher, M., Calinescu, R., Douthwaite, J., Lesage, B., Paterson, C., Aitken, J.,
Alexander, R., Law, J.: Veriﬁed synthesis of optimal safety controllers for human-
robot collaboration. Working paper, University of York, University of Sheﬃeld,
and University of Bremen (2021), https://arxiv.org/abs/2106.06604

15. Gleirscher, M., Calinescu, R., Woodcock, J.: Risk structures: A design alge-
bra for risk-aware machines. Formal Aspects of Computing 33, 763–802 (2021).
https://doi.org/10.1007/s00165-021-00545-4

test-
(2016).

Sound Development of Safety Supervisors

17

16. Gleirscher, M., Peleska, J.: Complete test of synthesised safety supervisors for
robots and autonomous systems. In: Luckuck, M., Farrell, M. (eds.) FMAS, 3rd
Workshop, EPTCS, vol. 348, pp. 101–109. Open Publishing Association (2021).
https://doi.org/10.4204/EPTCS.348.7

17. Huang, W., Peleska, J.: Complete model-based equivalence

class

Software Tools

ing.
https://doi.org/10.1007/s10009-014-0356-8

for Technology Transfer 18(3),

265–283

18. Huang, W., Peleska, J.: Complete model-based equivalence class testing for non-
deterministic systems. Formal Aspects of Computing 29(2), 335–364 (2017).
https://doi.org/10.1007/s00165-016-0402-2

19. IEC 61508: Functional safety of electric/electronic/programmable electronic safety-

related systems. Tech. rep., IEC (2006)

20. ISO 10218: Robots and robotic devices – safety requirements for industrial robots.

Standard, RIA (2011), https://www.iso.org/standard/51330.html

21. ISO 26262: Road vehicles – functional safety. Standard, ISO/TC 22/SC 32 (2011),

https://www.iso.org/standard/43464.html

22. ISO/TS 15066: ISO/TS 15066:2016 – Robots and robotic devices – Collaborative

robots. Standard, ISO, Geneva, CH (2016)

23. Kwiatkowska, M., Norman, G., Parker, D.: Stochastic model checking. In:
Bernardo, M., Hillston, J. (eds.) SFM, LNCS, vol. 4486, pp. 220–70. Springer
(2007). https://doi.org/10.1007/978-3-540-72522-0 6

24. Kwiatkowska, M., Norman, G., Parker, D.: PRISM 4.0: Veriﬁcation of probabilistic
real-time systems. In: Gopalakrishnan, G., Qadeer, S. (eds.) CAV, 23rd Int. Conf.
pp. 585–591. No. 6806 in LNCS, Springer (2011). https://doi.org/10.1007/978-3-
642-22110-1 47

25. Lesage, B., Alexander, R.: SASSI: Safety analysis using simulation-based situation
coverage for cobot systems. In: SAFECOMP, 40th Int. Conf., LNCS, vol. 12852,
pp. 195–209. Springer (2021). https://doi.org/10.1007/978-3-030-83903-1 13
26. Many: GSN community standard. Tech. rep., Origin Consulting Ltd., York, UK

(2011), http://www.goalstructuringnotation.info

27. Orlandini, A., Suriano, M., Cesta, A., Finzi, A.: Controller synthesis for safety
critical planning. In: Luo, J. (ed.) ICTAI, 25th Int. Conf., pp. 1–8. IEEE (2013).
https://doi.org/10.1109/ictai.2013.54

28. Peleska, J., Huang, W.: Test Automation - Foundations and Applications of
lecture notes,
http://www.informatik.uni-bremen.de/agbs/jp/papers/test-

Model-based Testing. University of Bremen (January 2021),
available
under
automation-huang-peleska.pdf

29. Petrenko, A.: Checking experiments for symbolic input/output ﬁnite state ma-
chines. In: ICST, 9th Conf. Workshops, Chicago, IL, USA. pp. 229–237 (2016).
https://doi.org/10.1109/ICSTW.2016.9

30. Petrenko, A., Simao, A., Maldonado, J.C.: Model-based testing of software and
systems: Recent advances and challenges. Int. J. Softw. Tools Technol. Transf.
14(4), 383–386 (Aug 2012). https://doi.org/10.1007/s10009-012-0240-3

31. Sachtleben, R.: An executable mechanised formalisation of an adaptive
state counting algorithm. In: Casola, V., Benedictis, A.D., Rak, M. (eds.)
ICTSS, 32nd, Naples, Italy. LNCS, vol. 12543, pp. 236–254. Springer (2020).
https://doi.org/10.1007/978-3-030-64881-7 15

32. Sachtleben, R., Hierons, R.M., Huang, W., Peleska, J.: A mechanised proof of
an adaptive state counting algorithm. In: ICTSS, 31st Int. Conf., Paris, France.
LNCS, vol. 11812, pp. 176–193. Springer (2019). https://doi.org/10.1007/978-3-
030-31280-0 11

18

Gleirscher, Plecher, Peleska

33. Soucha, M., Bogdanov, K.: SPYH-Method: An improvement in testing of ﬁnite-
state machines. In: ICST Conf. Workshops, V¨aster˚as, Sweden. pp. 194–203. IEEE
Computer Society (2018). https://doi.org/10.1109/ICSTW.2018.00050

34. Stenkova, V., Brings, J., Daun, M., Weyer, T.: Generic negative scenarios for the
speciﬁcation of collaborative cyber-physical systems. In: Conceptual Modeling,
LNCS, vol. 11788, pp. 412–419. Springer (2019). https://doi.org/10.1007/978-3-
030-33223-5 34

35. Uchitel, S., Kramer, J., Magee, J.: Negative scenarios for implied scenario elic-
itation. ACM SIGSOFT Software Engineering Notes 27(6), 109–118 (2002).
https://doi.org/10.1145/605466.605484

36. Villani, E., Pontes, R.P., Coracini, G.K., Ambr´osio, A.M.: Integrating model check-
ing and model based testing for industrial software development. Computers in
Industry 104, 88–102 (2019). https://doi.org/10.1016/j.compind.2018.08.003
37. Wagner, L., Mebsout, A., Tinelli, C., Cofer, D., Slind, K.: Qualiﬁcation of a model
checker for avionics software veriﬁcation. In: NFM, LNCS, vol. 10227, pp. 404–419.
Springer, Cham (2017). https://doi.org/10.1007/978-3-319-57288-8 29

38. WG-71, R.S.E.: Software Considerations in Airborne Systems and Equipment Cer-
tiﬁcation. Tech. Rep. RTCA/DO-178C, RTCA Inc, 1150 18th Street, NW, Suite
910, Washington, D.C. 20036-3816 USA (December 2011)

39. WG-71, R.S.E.: Software Tool Qualiﬁcation Considerations. Tech. Rep.
RTCA/DO-330, RTCA Inc, 1150 18th Street, NW, Suite 910, Washington, D.C.
20036-3816 USA (December 2011)

