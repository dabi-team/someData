Lublinsky et al.

RESEARCH

A Kubernetes ‘Bridge’ operator between cloud
and external resources.
Boris Lublinsky1, Elise Jennings2* and Vikt´oria Spiˇsakov´a2

*Correspondence:
elise.jennings@ibm.com
2IBM Research - Europe, Dublin,
Ireland
Full list of author information is
available at the end of the article

2
2
0
2

l
u
J

6

]

C
D
.
s
c
[

1
v
1
3
5
2
0
.
7
0
2
2
:
v
i
X
r
a

Abstract

Many scientiﬁc workﬂows require dedicated compute resources, including HPC
clusters with optimized software, quantum resources, and dedicated hardware
cluster systems like Ray, for example. At the same time, many scientiﬁc
workﬂows today are built on Kubernetes leveraging growing support for workﬂow
and support tools. To address the growing demand to support workﬂows on both
cloud and dedicated compute resources we present the Bridge Operator, a
software extension for container orchestration in Kubernetes which facilitates the
submission and monitoring of long running processes on external systems which
have their own cluster resources manager (SLURM, LSF, quantum services and
Ray). The Bridge Operator consists of a custom Kubernetes controller that
employs a Kubernetes Custom Resource Deﬁnition to manage applications. We
present controller logic to manage the cloud container orchestration and external
resource workload manager interface, a resource deﬁnition to submit
HTTP/HTTPS requests to the external resource, and a controller pod
communicating with the external resource manager to submit and manage job
execution. The implementation allows us to mirror the external resource in
Kubernetes pods, which allows the operator to use these pods as proxies to
control the external system. The implementation is agnostic to the choice of
resource manager but assumes the system exposes a HTTP/HTTPS API for its
control/management. The Bridge Operator automates the role of a human
operator running jobs on a black box external resource as part of a complex
hybrid workﬂow on the Cloud.

Keywords: High performance computing; Cloud computing; HPC workload
manager; Kubernetes; LSF; SLURM; Container orchestration; Ray

1 Introduction
Cloud-based scientiﬁc workﬂow platforms provide dynamically managed and moni-
tored environments with access to a wide variety of on-demand computing resources.
One focus in Cloud computing is ﬂexibility where multiple environments can be de-
ployed on the same node at the same time and eﬃcient resource sharing on the
nodes can in turn lead to increased resource utilization. Docker based containeriza-
tion in cloud environments ensures portability and allows users to deploy applica-
tions easily among clusters. Orchestration provided by Kubernetes leads to eﬃcient
auto-scaling and provisioning of cluster resources. On the other hand, many scien-
tiﬁc workﬂows require specialized hardware (GPU’s, quantum, etc) and software to
carry out complex scientiﬁc computations. Despite many attempts to extend the
reach of Kubernetes to support specialized hardware and add additional resource

 
 
 
 
 
 
Lublinsky et al.

Page 2 of 13

managers it does not seem feasible, at the moment, to bring all of these resources
into a single Kubernetes cluster. There are multiple issues to be considered:

• There is a continuous evolution in specialized hardware and backporting Ku-

bernetes support to them is not always easy.

• The Kubernetes resource manager, while extremely well suited for common
processing, is not optimized for HPC workloads when compared to specialized
resource managers, like LSF or Slurm.

Dedicated computing systems like HPC clusters, are pre-conﬁgured by systems ad-
ministrators with specialized software libraries and frameworks. As a result work-
loads for these dedicated resources must be built to be hardware speciﬁc for per-
formance. On these systems provisioning of resources is typically carried out by a
workload manager which consists of a resource manager and a job scheduler. The
workload manager allocates resources, schedules the jobs, determines priorities, sub-
mits the jobs to the compute nodes and manages allocations and dependencies. The
rise of scientiﬁc machine learning and high performance data analytics has led to
an increase in complex and diverse workloads which may mix Cloud-based and
on-premise external resources such as a HPC cluster or an AI accelerator. Many
workﬂows in scientiﬁc domains like Climate, Pharma, Material science, Astronomy,
Bioinformatics, Physics, and Earth Science which would have traditionally run only
on a HPC cluster, now span from edge devices and cloud-based clusters to HPC sys-
tems. There is a growing demand to accelerate workﬂow components by deploying
jobs to advanced systems like quantum. Additionally new software implementations,
for example Ray, provide additional speed up of Python-based execution and sup-
port for a wider range of hardware options. In this paper we present a Kubernetes
operator, the ‘Bridge Operator’, which allows users to dispatch jobs from a Kuber-
netes workﬂow to external resources (seen as a “black box”) and monitor the job
until completion, re-submit upon failure, delete a running job, upload input data
and additional ﬁles and retrieve outputs.

This paper is organized as follows: In Section 2 we present the background on
External Workload managers in 2.1, Kubernetes cloud orchestration in 2.2 and
Kubernetes Operators 2.3. In Section 3 we present related work in this area and
in Section 4 we outline the objectives of this work. In Section 5 we describe the
Bridge architecture and tools and in Section 6 we present a workﬂow integration.
In conclusion 7 we will outline current results and potential future work.

2 Background
In this section we describe commonly used workload managers, Slurm, LSF, Quan-
tum, and Ray, in Section 2.1. In Section 2.2 we outline the cloud orchestration
framework, Kubernetes, and in Section 2.3 we describe Kubernetes Operators.

2.1 External workload managers
In general the compute nodes on HPC clusters can only be accessed using resource
and workload manager programs which control the allocations of processors and
memory as well as scheduling the jobs to be run. Job and queue scheduling can
follow priority policies speciﬁc to the HPC cluster or speciﬁc to a queue in the
cluster such as the size, type and duration of the job. Two workload management

Lublinsky et al.

Page 3 of 13

programs which exemplify current usage are the Slurm and IBM Spectrum LSF
software packages.

Slurm [1] is a cluster management and job scheduling program for Linux clusters.
Slurm manages the allocations giving users access to the compute nodes for their
jobs and controls the execution and monitoring of those jobs. Slurm also manages job
queues, topology aware job allocations, reservations and backﬁll policies. A slurm
cluster is composed of a centralized daemon, slurmctld, running on a management
node together with slurmd daemons on each of the compute nodes which executes
the work. The Slurm daemons manage the compute nodes, partitions of nodes,
memory allocations and jobs. An optional slurmrestd daemon is available to interact
with Slurm through its REST API which is an HTTP server. User command line
tools such as sinfo provide information on the current state of the system (nodes,
partitions, queues), squeue provides information on the jobs on the system and srun
to create a resource allocation and run jobs.

The IBM Spectrum LSF (‘LSF’, short for load sharing facility) software [2] is a
workload manager which allocates resources and provides a job management frame-
work to run and monitor HPC jobs. The core of LSF includes various daemon pro-
cesses, depending on their role in the cluster. There are daemons for job requests
and dispatch, scheduling and execution. User command line tools such as bsub are
used to submit jobs to a queue and specify job submission options to modify the
default job behavior. Submitted jobs wait in queues until they are scheduled and
dispatched to a host for execution. At job dispatch, LSF checks to see which hosts
are eligible to run the job and at runtime the environment is copied from the submis-
sion host to the execution host. LSF can be accessed by users and administrators by
a command-line interface, an API, or through the IBM Spectrum LSF Application
Center.

IBM recently released Quantum service [3] which run on the IBM cloud. Although
technically this is not a resource manager, these APIs provide functionality similar
to APIs provided by HPC workload managers described above and can be used
leveraging the same programming paradigm. Via these APIs it is possible to create
jobs, monitor their execution and upload execution results to object storage.

Another interesting implementation is Ray [4] - an open source project that makes
it simple to scale any compute-intensive Python workload. Ray implements a ﬂexible
distributed execution framework providing support for many types of advanced
hardware. A new job submission SDK, provided by Ray allows users to submit and
monitor jobs on a Ray cluster.

2.2 Kubernetes

Kubernetes [5] is a portable, extensible, open-source platform for managing con-
tainerized workloads and services at scale. In a nutshell Kubernetes is about man-
aging resources - endpoints in the Kubernetes API that store a collection of API
objects of a certain kind. The following is the list of the base kubernetes resources:

• Pod. A group of one or more containers.
• Service. An abstraction that deﬁnes a logical set of pods as well as the policy

for accessing them.

Lublinsky et al.

Page 4 of 13

• Volume. An abstraction that allows data to persist. (This is necessary be-
cause containers are ephemeral - meaning data is deleted when the containers
themselves cease to exist.)

• Secrets and conﬁguration maps - resources used to store conﬁdential and non-

conﬁdential data as key-value pairs.

• Namespace. A segment of the cluster dedicated to a certain purpose, for ex-

ample a certain project or team of devs.

• ReplicaSet (RS). Ensures that the desired number of pods are running.
• Deployment. Oﬀers declarative updates for pods and RS.
• StatefulSet. A workload API object that manages stateful applications, such

as databases.

• DaemonSet. Ensures that all or some worker nodes run a copy of a pod. This

is useful for daemon applications.

• Job. Creates one or more pods, runs certain tasks to completion, then deletes

the pods.

• Etc.

Kubernetes manages containers which package code, runtime, system tools, system
libraries, and conﬁgurations altogether. Containerization allows reproducible runs
of an application irrespective of where it runs. One of the strongest features of
Kubernetes is that it is a declarative system - you supply the representation of the
desired state to the system and the system reads the current state and determines
the sequence of commands to transition to this desired state. In a Kubernetes
implementation, every resource type has its own controller - the component that
determines the necessary sequence of commands required for state transition. The
are several advantages in such declarative approach:

• It makes it signiﬁcantly simpler for the deployer - instead of the user having to
determine the sequence of commands to transition the system to the desired
state, they only have to deﬁne the desired state.

• An additional advantage of the declarative system is the ability to react to
any unintended state changes. In the cases of unintended state change, the
system will determine and apply the set of correcting actions bringing it back
to the desired state.

Pods can be killed, replaced, and be automatically re-started. Upon re-starting the
pod, a container is given access to the support volumes, secrets and conﬁguration
maps that are needed for it to function. Another important Kubernetes feature is
its extensibility through the custom resources - extensions of the Kubernetes API.
Many core Kubernetes functions are now built using custom resources, making
Kubernetes more modular. Custom resources (CRs) can appear and disappear in a
running cluster through dynamic registration of custom resource deﬁnitions (CRD),
and cluster administrators can update custom resources independently of the cluster
itself. Once a custom resource is installed, users can create and access its objects
using kubectl, with a similar ease as for built-in resources.

2.3 Kubernetes Operators
In Kubernetes, controllers of the control plane implement control loops that re-
peatedly compare the desired state of the cluster to its actual state and reconcile

Lublinsky et al.

Page 5 of 13

any discrepancies. A Kubernetes operator is a software extension to allow for the
creation of a custom controller that uses CRs to manage applications and their
components. The CRs used by the Operator to manage the application contain
speciﬁc high-level conﬁguration and settings that allow easy user customization.
The Operator also implements low level actions, based on the logic deﬁned within
the custom controller. A Kubernetes operator plays the role of automating all as-
pects of human operators who look after speciﬁc applications and services. These
Human operators have deep knowledge of how the system ought to behave (creden-
tials, endpoints, secrets), how the application is deployed (scheduler commands),
and how to react if there are problems (job termination).The original deﬁnition
of operators in Kubernetes had a single application focus which included domain
or application-speciﬁc knowledge to automate the entire lifecycle of the software it
manages. A good example is TfJob [] which is a Kubernetes operator with a custom
controller and CRD to run TensorFlow training jobs on Kubernetes.

3 Related Work
The Kubernetes operator is well known prior art and related work has been done on
the general problem of supporting compute intensive or HPC workloads on cloud
resources. Zhou et al. [6] proposed a hybrid architecture solution to integrate the
Torque [7] workload manager with Kubernetes. This work introduces a dual level
of scheduling where container orchestration on the HPC cluster can be performed
by the Kubernetes orchestrator in the cloud. The proposed architecture assumes a
shared login node which belongs to both the Kubernetes and TORQUE clusters.
This is a virtual node that represents a worker node in the Kubernetes cluster and
acts as a login node for TORQUE. The login node only submits the TORQUE job
to the HPC cluster and is not included in the TORQUE compute node list. Job
submission on the HPC cluster side will not be scheduled to this login node. The
Kubernetes cluster incorporates a master node that schedules the jobs to the worker
nodes.

The WLM Operator [8] is another Kubernetes operator implementation which
connects a Kubernetes node with a Slurm cluster allowing Kubernetes to integrate
with Slurm. Each Slurm partition (queue) is considered as a dedicated virtual node
in Kubernetes and compute resources on the Slurm cluster are propagated and
visible to Kubernetes. This approach implements a GRPc server in order to submit
requests to the Slurm cluster.

Both the WLM and Torque operator implementations operate using a grey box
approach, where the HPC job scheduler is eﬀectively visible to the Kubernetes ap-
plications. In both, a single instance of the operator is limited to a speciﬁc workload
manager on a given external system and in this sense neither can be considered a
generic approach i.e. a workﬂow with steps to be run on a Torque and Slurm cluster
would require two diﬀerent operators as well as a shared Kubernetes - Torque login
node and a Kubernetes - Slurm login node to run.

Piras et al. [9] propose a hybrid Kubernetes on HPC approach where the size of the
Kubernetes cluster is dynamically increased with transient nodes allocated through
the Grid Engine workload manager. The objective was to support ‘bursty’ Kuber-
netes workloads which may require HPC computing resources while also maintaining

Lublinsky et al.

Page 6 of 13

Figure 1 The Bridge Operator running workﬂows on a Kubernetes Cluster while at the same time
deploying workﬂow steps (complex computations) to an external system (e.g. HPC cluster,
Quantum service or Ray cluster) managed by an external resource manager.

a uniform platform with a homogeneous job management and monitoring infras-

tructure. L´opez-Huguet et al. [10] propose a cloud job scheduler which can manage

and submit jobs in a HPC infrastructure. This implementation is similar to the

Bridge Operator but is based on slightly diﬀerent concepts. In L´opez-Huguet et al.

all functionality is contained inside one image which runs in a Kubernetes pod. In

Cerin et al. [11] the approach is to containerise the HPC scheduler itself making it

cohabit with all other jobs on the underlying cloud system. This approach repre-

sents a direct integration of Cloud and HPC environments and is in contrast to our

black box approach to deploying jobs on an external system. Georgiou et al. [12]

focused on hybrid data analytics workﬂows in the context of precision agriculture

and livestock farming applications and implemented a prototype architecture which

integrates with Kubernetes with a HPC partition of baremetal nodes managed by

Slurm or Torque. Recently the DOE’s Oak Ridge Leadership Computing Facilities

(OLCF) extended the Pegasus workﬂow management system with Workﬂow Submit

Node as a service (WSaaS). Built upon the Kubernetes/Openshift cluster (Slate)

that exists within OLCF’s DMZ this service allows users to spin up a Pegasus sub-

mit node, and submit pipelines to OLCF resources such as the Summit LSF cluster

or Rhea Slurm Cluster [13].

To the best of the authors’ knowledge, the Bridge Operator approach presented

in this work is novel in two key respects where

• the operator mirrors the external resource in pods, which act as proxies to
control the external system. The Bridge operator controls and monitors these

pods and in eﬀect controls and monitors the external resource by proxy.
• the operator represents a pattern with a generic approach to control multiple

diﬀerent external systems, with the same programming model.

Lublinsky et al.

Page 7 of 13

Figure 2 A detailed view of our implementation and the control, management and deﬁnition
relationships within the Bridge Operator.

4 Objectives
The goal in creating the Bridge Operator is to support running complex workﬂows
on the cloud while at the same time seamlessly deploying workﬂow steps (complex
computations) to an external system (e.g. HPC cluster, Quantum service or Ray
cluster) managed by an external resource manager as shown in Fig 3. In our imple-
mentation we use a single Kubernetes Operator which is capable of deploying pods
which can simultaneously submit and monitor jobs on diﬀerent external systems
as required in the workﬂow. The Bridge operator watches pods adhering to the
following general requirements:

• The ability to submit user provided credentials to access the external resource

via a HTTP/HTTPS API.

• The ability to submit, delete and query the status of a job running on an

external resource via the API.

• The ability to submit user provided job property settings, such as accounts to
charge node usage to, queues to run on as well as hardware resource requests,
to the external workload manager

• The ability to upload execution scripts, and any additional ﬁles needed to the

external resource as allowed by the API..

• The ability to download any output ﬁles from a given location on the external

resource.

• Using S3 (compatible) storage for all uploads/downloads.
• Credentials to access the external resources as well as object storage are ac-

cessible as Kubernetes secrets mounted in a volume by the pod.

5 Architecture and Tools
In this section we describe the Operator Architecture which has been developed
to run on a Kubernetes Cluster and deploy a long running application to a
HTTP/HTTPS API on an external resource. We outline the operator’s controller,
CR, controller logic and credential management. Speciﬁc implementations for a
LSF, Slurm, Quantum and Ray Pod are also presented.

5.1 Bridge Operator Architecture
In Fig. 3 we presented a view of the Bridge Operator which allows jobs on a Ku-
bernetes cluster to be submitted to an external system. Fig 5 presents a detailed

Lublinsky et al.

Page 8 of 13

view of our implementation and the control, management and deﬁnition relation-
ships within the Bridge Operator. For each resource type supported by the operator
(LSF cluster, Slurm cluster, Quantum, Ray) we have created a controller, special-
ized for this type of resource, responsible for all interactions with this resource type.
The Bridge operator itself is responsible for the management of controller lifecycles.
While the operator is generic, implementation of a controller pod is speciﬁc for a
given external resource manager. As a result, in order to support a new resource
type, the only thing that is required is the implementation of the corresponding
controller (based on very simple rules imposed by the operator). An operator is
controlled by a custom resource (CR), that deﬁnes parameters for the execution,
including:

• The resource manager URL and security credentials for accessing it
• The controller pod used for controlling the resource (docker image)
• The job execution script and its location - the operator supports ‘remote‘
(located at the external resource), ‘s3‘ (located in an S3 bucket) and ‘inline‘
(deﬁned by the CR itself) scripts.

• Any additional job data and its location. For example input ﬁles may be

uploaded from S3 to the external resource.

• Any job parameter settings required by the job execution script. The operator

supports both S3-based and inline speciﬁcation of this data

• Any job properties speciﬁcations, for example, specifying resources (number

of nodes), execution time, error and output ﬁles, etc.

• S3 information (s3 endpoint and credentials)
• S3 upload speciﬁcations (s3 bucket and ﬁles to be uploaded)

Additionally the Bridge operator uses a conﬁguration map for passing data between
the operator and controller pod and as a persistent current record of the job’s status
should the pod fail. Note that in this implementation we focus on S3 for simplicity
but the approach can be generalized to other storage options. Once the CR is
created, an operator creates the controller pod (one per remote job) and populates
the conﬁguration map with the parameters required for the pod’s execution. Once
the pod is created, an operator watches for changes in the pod and associated
conﬁguration map. Once execution of the remote job is completed a CR status
reﬂects the status of remote job as any of DONE/KILLED/FAILED/UNKNOWN
as well as additional information about the job start and end time. A user can also
update the CR with a kill signal which will stop the remote job and update the
status to KILLED. When a CR is deleted, it will clean up all resources associated
with it (pod and conﬁguration map) The workhorse of this implementation is the
controller pod. Once the pod is created, it reads the necessary execution data from
the associated conﬁguration map, logs into a remote resource manager, fetches a
job script (if required) along with job parameters and any other additional data
and submits the requested job via the workload manager of the resource. After the
job starts, the pod goes into a monitoring loop, that runs periodically (controlled
by the CR poll parameter) checking the job status and updating the associated
conﬁguration map. Once execution of the remote job completes/fails or is killed,
the pod downloads outputs to the Kubernetes cluster and uploads them to S3,
if required, and exits. If the pod fails for any reason, an operator will restart it.

Lublinsky et al.

Page 9 of 13

Because the remote job ID is kept in the conﬁg map, in this case the pod will know
that the remote job is already running and will not try to restart it. Credentials
necessary for deploying jobs and accessing object storage (if required) are managed
using Kubernetes secrets. A speciﬁc Bridge Job can be deployed using a CR yaml
ﬁle, see Fig. 1 for example yaml.

name: slurmjob-test

resourceURL: http://my-slurm-cluster@hpc.com
image: slurmpod:0.1
resourcesecret: mysecret
imagepullpolicy: Always
updateinterval: 20
jobdata:

1 Sample BridgeJob yaml for submitting to a Slurm cluster
1: kind: BridgeJob
2: apiVersion: bridgeoperator.ibm.com/v1alpha1
3: metadata:
4:
5: spec:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:

{
”NodesNumber”:”1”, ”Queue”: ”V100”, ”Tasks”: ”2”, ”slurmJobName”: ”test”,
”currentWorkingDir”: ”path-to-test/test-script/”,
”envLibPath”: ”/usr/mpi/gcc/openmpi-4.0.3rc4/lib”,
”ErrorFileName”: ”slurmjob.err”,
”OutputFileName”: ”slurmjob.out”
}
s3storage:
s3secret: mysecret-s3
endpoint: s3endpoint.cloud
secure: false

jobscript: ”mys3bucket:slurmbatch.sh”
scriptlocation: ”s3”
jobproperties: |

5.2 Bridge Pods
The speciﬁc implementation for a given external resource is carried out by a Pod
which is speciﬁc for each kind of workload managers, e.g. the LSF or Slurm. To
demonstrate the generic approach of the Bridge operator we have created pods
which can submit jobs to an LSF, Slurm, Ray cluster or to a Quantum service.
Any actions within the pod itself are restricted to what can be done via speciﬁc
external resource API. For example the LSF Application Center API currently
allows requests to submit, delete, update jobs, upload and download ﬁles to the
cluster as well as query queues and job statuses. The current version of the Slurm
API tested in this work (version 21.08) is slightly more restrictive in that upload
and download to the cluster is not supported. There is a common sequence of events
within a pod which we summarize in Figs. 2,3 for a pod implemented in the Go
programming language [14]. Fig 2 outlines the main method in the controller pod.
Fig 3 outlines the monitoring method which runs continuously in the controller pod.

6 Workﬂow Integration
Although Bridge operator is useful by itself, the majority of scientiﬁc workﬂows are
implemented using a specialized workﬂow package. The one that we used, Kube-
ﬂow pipelines is a platform for deploying workﬂows based on Docker images and
provides a useful SDK for deﬁning and controlling components and pipelines. To

Lublinsky et al.

Page 10 of 13

2 Pseudocode for the main function submitting jobs to a Slurm HPC cluster
1: func main(){
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:

NAMESPACE = os.Getenv(“NAMESPACE”) //Get namespace, job name from environment
JOB NAME = os.Getenv(“JOBNAME”)
conﬁg, err := rest.InClusterConﬁg() // Create kubernets client
· · ·
clientset, err := kubernetes.NewForConﬁg(conﬁg)
cm := getConﬁgMap(clientset) //Get conﬁg map and its parameters
HPCURL = cm.Data[“resourceURL”]
· · ·
client = http.Client{Timeout: time.Duration(5) * time.Second} // Create HTTP client
slurmUsername, slurmToken := getToken(). // Get access token for HPC cluster
· · ·
id := cm.Data[“id”] // Get ID from conﬁg map
info := make(map[string]string) // create info for keeping track of execution parameters
· · ·
if len(id) == 0 {

klog.Infof(“Slurm Job with name ’%s’ does not exist. Submitting new job.”, JOB NAME)
intId := submit(slurmUsername, slurmToken, cm.Data) // Submit a job & update exe-

cution state in conﬁg map

19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39: }

id = fmt.Sprint(intId)
if id == 0 {

info[“jobStatus”] = FAILED // Failed to submit a job
info[“message”] = “Failed to submit a job to HPC resource”

} else {

info[“id”] = id
info[“jobStatus”] = SUBMITTED

}
updateConﬁgMap(clientset, cm, info, id)
if len(id) ! = 0 { // Start monitoring or exit

monitor(clientset, slurmUsername, slurmToken, info)

} else {

klog.Exit(“Failed to start HPC job”)

}

} else {

// Job is already running
klog.Info(“Slurm Job ’%s’ has ID in ConﬁgMap. Handling state.”, JOB NAME)
info[“id”] = id
monitor(clientset, slurmUsername, slurmToken, info)
}

Lublinsky et al.

Page 11 of 13

demonstrate a workﬂow integration with presented Bridge operator implementa-
tion we have created a single pipeline which consists of three steps as shown in
Fig. 4: create a conﬁguration map (createop), run a Bridge pod (invokeop) and
delete the conﬁguration map once the job is complete (cleanop). Fig 4 shows the
python code to create this pipeline. The input parameters to the bridge pipeline
correspond to the BridgeJob schema deﬁned for the Operator. In particular the
parameter “docker, str” should reference a docker image which is a Bridge Pod
to submit jobs to a speciﬁc external resource. Depending on the parameters, this
workﬂow implementation can be used with any of the Bridge operator pods.

3 Pseudocode for the monitor function
1: func monitor(clientset *kubernetes.Clientset, slurmUsername string, slurmToken string,

info

map[string]string){

2: id := info[“id”]
3: for {
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25: }
26: }

}

time.Sleep(time.Duration(POLL) * time.Second)
// Get current conﬁg map
cm := getConﬁgMap(clientset)
// Get current execution status and update conﬁg map
var state = “”
job := getJobInfo(slurmUsername, slurmToken, id)
if job ! = nil {
· · ·
updateConﬁgMap(clientset, cm, info, token, id)

}
// Check for kill ﬂag
if cm.Data[“kill”] == “true” {

}
// Terminate if we are done
if state == COMPLETED {

os.Exit(0)

}
if state == CANCELLED || state == FAILED {

os.Exit(1)

killJob(slurmUsername, slurmToken, id, info[“jobStatus”], info)

7 Conclusions
There is a growing trend for complex scientiﬁc workﬂows which require heteroge-
neous computing resources, combining cloud with HPC and even advanced accelera-
tors such as AI and quantum. To address these needs we have created a Kubernetes
‘Bridge’ Operator which allows jobs to be deployed and monitored on remote exter-
nal resources from a cloud Kubernetes environment. The black box approach taken
in this implementation has resulted in a generic pattern which works for diﬀerent
external resources (Slurm, LSF, Quantum, Ray, etc) without any change to the op-
erator required. The speciﬁc requests made to the external resource are restricted to
the worker pod controlled and monitored by the operator. In this implementation
the external resource is mirrored in the pod, which acts as a proxy for that system.
As the Bridge Operator controls the pod, it in turn is eﬀectively controlling the ex-
ternal system by proxy. We demonstrate the workﬂow integration of this approach
in Kubeﬂow pipelines as a simple three step workﬂow, which can be used as a sub
workﬂow for more complex implementations. The operator presented here allows a
user to manage jobs on remote resources, but does not take into the account the

Lublinsky et al.

Page 12 of 13

namespace: str, # execution namespace
resourceURL: str, # resource address - url
resourcesecret: str, # resource credentials
script: str, # script name or content
scriptlocation: str,
docker: str, # pod docker name
scriptmd: str = ””,
scriptextraloc: str= ””,
additionaldata: str = ””, # extra ﬁles required
jobproperties: str = ””, # dict of job properties
jobparams: str = ””, # dict of job parameters
s3secret: str = ””, # secret with S3 credentials
s3endpoint: str = ””, # S3 URL
s3secure: str = ””, # is S3 secure?
s3uploadﬁles: str = ””, # ﬁles to upload to S3
s3uploadbucket: str = ””, # bucket in S3
updateinterval: str = ”20”, # poll interval
imagepullpolicy: str = “IfNotPresent”
):

4 Pseudocode for the KFP Bridge pipeline
1: def bridgepipeline(jobname: str, # job name
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:
40:
41:
42:
43:
44:
45:
46:
47:
48:
49:
50:
51:

name=’s3credentials’))

name=’downloads’))

createop = setup op(jobname, namespace, resourceURL, resourcesecret, script,

scriptlocation,scriptmd, additionaldata, scriptextraloc, jobproperties, jobparams,
s3secret, s3endpoint, s3secure, s3uploadﬁles, s3uploadbucket,updateinterval)

createop.execution options.caching strategy.max cache staleness = “P0D”
invokeop = comp.load component from text(”””

name: bridge-pod
description: bridge execution pod
implementation:
container:
image: docker
command:
- sh ”””)()
.add volume(k8s client.V1Volume(name=’credentials’,
secret=k8s client.V1SecretVolumeSource(secret name=resourcesecret)))
.add volume mount(k8s client.V1VolumeMount(mount path=’/credentials’,name=’credentials’))
.add env variable(k8s client.V1EnvVar(name=’NAMESPACE’, value=namespace))
.add env variable(k8s client.V1EnvVar(name=’JOBNAME’, value=jobname))
.after(createop)

invokeop.container.set image pull policy(imagepullpolicy)
invokeop.container.image = docker
invokeop.execution options.caching strategy.max cache staleness = ”P0D”
if s3secret ! = “”:

invokeop.add volume(k8s client.V1Volume(name=’s3credentials’,
secret=k8s client.V1SecretVolumeSource(secret name=s3secret)))
.add volume mount(k8s client.V1VolumeMount(mount path=’/s3credentials’,

invokeop.add volume(k8s client.V1Volume(name=’downloads’))
invokeop.add volume mount(k8s client.V1VolumeMount(mount path=’/downloads’,

cleanop = cleanup op(jobname, namespace).after(invokeop)
cleanop.execution options.caching strategy.max cache staleness = ”P0D”

Lublinsky et al.

Page 13 of 13

current load on these systems. Future work will focus on creating companion op-
erator using the same approach to monitor current load on these remote resources
and make intelligent decisions on which remote resource (or particular portion of
this resource, for example speciﬁc queue) to use for execution.

Acknowledgements
The authors would like to thank Dean Wampler for a detailed reading of this manuscript and feedback.

Ethical Approval and Consent to participate
Not applicable

Consent for publication
Not applicable

Availability of supporting data
Not applicable

Competing interests
The authors declare that they have no competing interests.

Funding
Not applicable

Authors’ contributions
All authors contributed to writing and testing the code, as well as writing the text of this paper.

Author details
1IBM Systems, Chicago, IL, USA. 2IBM Research - Europe, Dublin, Ireland.

References

1. SLURM: Simple Linux Utility for Resource Management (2003).

$https://slurm.schedmd.com/slurm_design.pdf$
IBM Spectrum LSF. https://www.ibm.com/products/hpc$-$workload$-$management
2.
3.
IBM Quantum Services. https://www.ibm.com/quantum$-$computing/services/
4. Ray Architecture (2020). https://docs.ray.io/en/latest/cluster/index.html
5. Kubernetes. https://kubernetes.io/docs/home/
6. Zhou, N., Georgiou, Y., Zhong, L., Zhou, H., Pospieszny, M.: Container orchestration on HPC systems. CoRR

abs/2012.08866 (2020). 2012.08866

7. Staples, G.: Torque resource manager. 2006 ACM/IEEE conference on Supercomputing (2006)
8. Pisaruk, V., Yakovtseva, S.: WLM−operator. Gitlab:https://github.com/sylabs/wlm$-$operator
9. Piras, M.E., Pireddu, L., Moro, M., Zanetti, G.: Container orchestration on hpc clusters. In: Weiland, M.,

Juckeland, G., Alam, S., Jagode, H. (eds.) High Performance Computing, pp. 25–35. Springer, Cham (2019)
10. L´opez-Huguet, S., Segrelles, J., Kasztelnik, M., Bubak, M., Blanquer, I.: Seamlessly Managing HPC Workloads

Through Kubernetes, pp. 310–320 (2020)

11. C´erin, C., Greneche, N., Menouer, T.: Towards pervasive containerization of hpc job schedulers. In: 2020 IEEE
32nd International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD), pp.
281–288 (2020)

12. Georgiou, Y., Zhou, N., Zhong, L., Hoppe, D., Pospieszny, M., Papadopoulou, N., Nikas, K., Lagkas Nikolos,

O., Kranas, P., Karagiorgou, S., Pascolo, E., Mercier, M., Velho, P.: Converging HPC, Big Data and Cloud
Technologies for Precision Agriculture Data Analytics on Supercomputers, pp. 368–379 (2020)

13. Papadimitriou, G., Vahi, K., Kincl, J.C., Anantharaj, V.G., Deelman, E., Wells, J.: Workﬂow submit nodes as a

service on leadership class systems (2020)

14. The Go Programming Language. https://github.com/golang

