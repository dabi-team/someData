1 

Digital Therapeutics for Mental Health:  

Is Attrition the Achilles Heel?    

Adaora Nwosu1, Samantha Boardman2, Mustafa M. Husain3, P. Murali Doraiswamy1, 4 

1.  Department of Psychiatry and Behavioral Sciences, Duke University School of Medicine 

2.  Department of Psychiatry, Weill Cornell Medical College 

3.  Departments of Psychiatry, Neurology and Biomedical Engineering, The University of 

Texas, Southwestern Medical Center 

4.  Duke Institute for Brain Sciences, Duke University  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
2 

ABSTRACT 

Digit therapeutics are novel software devices that clinicians may utilize in delivering quality 

mental health care and ensuring positive outcomes. However, uptake of digital therapeutics and 

clinically tested software-based programs remains low. This article presents possible reasons for 

attrition and low engagement in clinical studies investigating digital therapeutics, analyses of 

studies in which engagement was high, and design constructs that may encourage user 

engagement. The aim is to shed light on the importance of real-world attrition data of digital 

therapeutics, and important characteristics of medical devices that have positively influenced 

user engagement. The findings presented in this article will be useful to relevant stakeholders 

and medical device experts tasked with addressing the gap between software medical design and 

user engagement present in digital therapeutic clinical trials. 

INTRODUCTION 

Large unmet needs in mental health combined with the stress caused by pandemic mitigation 

measures have accelerated the use of digital mental health apps and software-based solutions (1).  

Global investor funding for virtual behavioral services and mental health apps in 2021 exceeded 

$5.5 billion, a 139% jump from 2020, according to CB Insights (2).  While there are thousands 

of apps claiming to improve various aspects of mental wellbeing, many of them have never gone 

through clinical trials or regulatory scrutiny.  The term “digital therapeutic” is used in the 

literature to distinguish high quality evidence-based software programs from wellness apps (3).  

Regulators use the term “software as a medical device” (SaMD) or “software in a medical 

device” (SiMD) to refer to software that functions as a medical device and is promoted to treat a 

specific condition.  When a SaMD or SiMD is deployed on a phone it is referred to as a mobile 

 
 
3 

medical app (MMA) (4,5).  The International Medical Device Regulators Forum (IMDRF), a 

voluntary group of medical device regulators from around the world has developed detailed 

guidance on definitions, framework for risk categorization, quality management, and the clinical 

evaluation of such devices (6-8). Non-traditional approaches, outside of RCTs, to evaluate 

efficacy for such tools has also been discussed elsewhere (9).  

To date, only four clinically tested software devices have been authorized by the U.S. Food and 

Drug Administration for treating specific mental health disorders (excluding devices marketed 

under pandemic-related emergency use authorization).  These include reSET for substance abuse 

disorder (10), reSET-O for opioid use disorder (11), Somryst for chronic insomnia (12,13) and 

EndeavorRx for pediatric attention deficit hyperactivity disorder (14,15).  SaMDs and MMAs for 

treating mild cognitive impairment, Alzheimer’s disease, schizophrenia, autism, depression, 

social anxiety disorder, phobias and PTSD are in clinical trials (1, 3, 5, 17) and may also come to 

market soon. The state of efficacy for non-regulated, wellness apps (e.g. for mindfulness or stress 

management) is beyond the scope of this article, and readers are referred elsewhere for the state 

of efficacy with these apps (16).  

HIGH ATTRITION AND LOW ENGAGEMENT 

While digital therapeutics and apps undoubtedly hold promise, relatively little attention has 

focused on attrition rates.  Even effective apps will have limited impact if they are not highly 

engaging and result in high attrition (18, 19).  Attrition, the loss of a randomized subject(s) from 

a study sample, is a very common issue in clinical trials and results from several causes such as 

refusal to participate after randomization, an early dropout from the study, and loss of subject’s 

 
 
 
4 

study data.  Attrition can substantially bias estimates of efficacy and reduce generalizability (20).  

Traditionally, regulatory trials of psychopharmacological agents have used the last observation 

carried forward (LOCF) statistical method to accommodate attrition – but this has been 

increasingly replaced with mixed-effects models, and pattern-mixture and propensity 

adjustments (20).  Compliance in trials of psychopharmacological agents is traditionally 

measured via pill counts.  However, in virtual platform trials of digital therapeutics, compliance 

cannot simply be measured by the number of times a subject logs on to an app and it is important 

to also measure and report how engaged users were with the app (21).  Currently, there is no 

standard way to define what constitutes meaningful engagement and how to compare 

engagement across different digital therapeutic devices (21).  There is also no consensus as to 

how to deal with users who are non-engaged but stay in the study.     

As patients typically use apps on their own time, they must be intrinsically motivated to do so 

and must perceive the benefits from the app as meaningful (18). Such intrinsic motivation may 

be low for psychiatric patients with depression, anhedonia, or cognitive difficulties.  For 

example, in one study of internet-based cognitive behavioral therapy for depression, the highest 

engagers comprised just 10.6% of the sample (22).  This is further highlighted by a 2020 meta-

analysis of 18 randomized trials of (non-FDA cleared) mobile apps for treating depression (trial 

duration ranging from 10 days to 6 months), in which the pooled dropout rate was 26.2% and 

rose to 47.8% when adjusted for publication bias (19).  The authors concluded that this raises 

concern over whether efficacy was overstated in these studies.  Real-world attrition rates for non-

FDA cleared mental wellness apps are not readily available for direct comparison. But one study 

of 93 non-FDA approved Android apps (median installs 100,000), targeting mental wellbeing, 

 
 
found the medians of app 15-day and 30-day retention rates were very low at 3.9% and 3.3% 

(23).  The median percentage of daily active users (open rate) was only 4.0%.  These data 

highlight that the number of app installs has very little correlation with daily long-term usage.    

5 

Attrition and engagement rates (self-defined by study sponsors) in the pivotal studies for the four 

FDA-authorized neuropsychiatric digital therapeutics are shown in Table 1.  The studies reported 

significant benefits for the digital therapeutic versus a control condition (Table 1, 10-15).  

Sample sizes were adequate, ranging from 170 to 1149 participants (Table 1). Active 

intervention durations were relatively short ranging from four to 12-weeks (Table 1). Trial 

design, nature of therapy, incentives, and diagnosis influenced attrition.  The Somyrst trials 

additionally reported 6-month and 12-month follow up data.  Attrition was lowest and 

compliance was highest in the pivotal study (14) of EndeavorRx for pediatric ADHD (Table 1) – 

this was a short 4-week trial of an interactive videogame where compliance was monitored 

electronically and there was close parental supervision.  However, in their open 12-week study 

(15), the average minutes engaged (with the videogame therapeutic) dropped by 34% at week 4 

and by 50% at week 12 (Table 1).  In the Somryst study for chronic insomnia (12), only 60% of 

subjects completed all 6 core modules of CBT and frequency of subject logins varied from 0-142 

times (median of 25).  While efficacy was sustained even at 12-month follow up, the decrease in 

insomnia score was greater in subjects who completed all 6 modules versus those who did not.  

In the Somryst study for subclinical depression with insomnia (13), attrition rate was 58% at 6 

weeks and on average only 3.5 of the 6 modules were completed.  Patients completing less than 

4 modules had no significant overall benefits versus the control condition and were not different 

from the control condition at 6 months. In the reSET study for substance use disorder (10), the 

 
 
6 

drop-out rate was low (12%) – this was likely because subjects were seen twice a week in the 

clinic, supervised by therapists, paid prizes ranging from “thank you” notes to up to $100 cash 

for compliance, and on average, earned $277 in prizes over 12 weeks.  In their long-term follow-

up (10), when this contingency incentive ended, the superiority of the digital therapeutic over the 

control condition also ended.  

Closing the Attrition Efficacy Gap 

Mental health conditions, like major depressive disorder, ADHD, and PTSD, require sustained 

treatment.  Because the field of digital therapeutics is still in its early stages, currently, there is 

little long-term efficacy data.  If even well-designed, gamified, digital therapeutics have a 50% 

drop in engagement in 3 months then the outlook for long-term efficacy is grim.  While drop-out 

rates in clinical trials can be kept low through frequent clinician contact, gamification, feedback, 

and cash incentives, this is not practical in the real world and hence attrition rates will be far 

higher.  Finally, if the costs of increasing engagement and compliance equals that of a getting 

live psychiatric care, then digital therapies would become less attractive as a scalable low-cost 

solution.   

Our scrutiny of published data also reveals several scientific gaps.  First is the lack of 

standardized definitions of attrition and engagement in the field of digital therapeutics. Second is 

the lack of standardized reporting requirements by journals.  A single digital therapeutic session 

can generate a dozen or more different metrics of how a user may interact with the app.  Even 

widely used clinical trials reporting checklists, such as CONSORT, have not yet required the 

reporting of all such engagement metrics in digital trials.   This makes it hard to extract such data 

 
 
 
7 

from published reports and compare metrics across trials and products. Third, is the lack of a 

standardized definition of compliance.  Fourth is the lack of standardized statistical methods, 

such as mixed models or last observation carried forward, to account for attrition and 

engagement biases in digital trials.     

Fortunately, several constructs are emerging as promising features to increase engagement – both 

related to external factors of motivation and UX design (24).  Several factors such as ease of use, 

gamification, ability to personalize app, in-app symptom monitoring, numerical feedback, ability 

to chart progress, socialization within the app, and integration with clinical services, have been 

reported to increase engagement (17, 18).  A machine learning analysis of 54,604 adult patients 

with depression and anxiety identified 5 distinct engagement patterns for digital cognitive 

behavior therapy over 14-weeks: low engagers [36.5% of sample], late engagers [21.4%], high 

engagers with rapid disengagement [25.5%], high engagers with moderate decrease [6.0%], and 

high persistent engagers [10.6%]. Depression improvement rates were lowest for the low 

engagers (22).  This study suggested machine learning algorithms may be useful to tailor 

interventions and a human touch for each of these five groups.  Kaiser Permanente found that 

integrating digital mental health solutions – provided via clinician referral – into their health care 

delivery system was able to successfully enhance engagement (25).  Fears around privacy and 

data security for mental health data may be a factor in engagement and attrition for some 

participants and this should be addressed upfront.  While we do not have all the solutions, 

encouraging the availability of raw data from clinical trials through trial registries, analyzing 

long-term real-world data on patient reported outcomes, user experience (engagement and 

compliance) and product reliability (18) will be important to enhance their utility.   

 
 
8 

Digital therapeutics for mental health are here to stay. As the pivotal studies demonstrate, they 

benefit a substantial number of patients.  However, the gap between intention and real-world 

efficacy for digital therapeutics remains large.  There is an urgent need to recognize this gap and 

for stakeholders – regulators, technology developers, clinicians, patients – to come together to 

close this gap and ensure that this form of treatment is useful to clinical populations.    

Acknowledgments/Disclosures: 

 This manuscript was not funded by any external source.   

AN has no conflicts to disclose. SB has no conflicts to disclose. MMH has received grants from 

NIMH, NIA, Brain Initiative and Stanley Foundation for other projects.  For other projects, PMD 

has received grants from NIA, DARPA, DOD, ONR, Salix, Avanir, Avid, Cure Alzheimer’s 

Fund, Karen L. Wrenn Trust, Steve Aoki Foundation, and advisory fees from Apollo, Brain 

Forum, Clearview, Lumos, Neuroglee, Otsuka, Verily, Vitakey, Sermo, Lilly, Nutricia, and 

Transposon. PMD is a co-inventor on patents for diagnosis or treatment of neuropsychiatric 

conditions and owns shares in biotechnology companies.  

 
 
 
 
    
 
 
 
 
 
 
 
 
 
 
References 

9 

1.  Doraiswamy PM, London E, Varnum P, Harvey B, Saxena S, Tottman S, Campbell SP, 
Fernandez Ibanez A, Manji H, Al Olama MAAS, Chou I, Herrman H, Jeong S, Le T, 
Montojo C, Reve B, Rommelfanger KS, Stix C, Thakor N, Chow KH, Welchman AE, 
Candeias V. Empowering 8 billion minds: Enabling better mental health for all via the ethical 
adoption of technologies. NAM Perspectives (2019). Discussion Paper. 
https://doi.org/10.31478/201910b 

2.  CB Insights. (2022, February 24). State of Mental Health Tech 2021 report. CB Insights 

Research. Retrieved May 9, 2022, from https://www.cbinsights.com/research/report/mental-
health-tech-trends-2021/  

3.  Wehrwein, P. Digital Therapeutics Shaping the Future of Care. Managed Healthcare 

Executive (2021). 31(12).  

4.  Policy for Device Software Functions and Mobile Medical Applications. Guidance for 

Industry and Food and Drug Administration Staff (2019). Guidance Document.  

5.  Shuren J, Doraiswamy PM. Digital therapeutics for MCI: A regulatory perspective. J Prev 

Alzheimers Dis (2021) (in press).  

6.  Despina S. Software as a Medical Device (SaMD): Key Definitions. International Medical 

Devices Regulators Forum (2013). 

7.  Shuren J. “Sofware as a Medical Device”: Possible Framework for Risk Categorization and 

Corresponding Considerations. International Devices Regulators Forum (2014).  

8.  Software as a Medical Device (SAMD) Clinical Evaluation. Guidance for Industry and Food 

and Drug Administration Staff (2017). Guidance Document.  

9.  Guo C, Ashrafian H, Ghafur S, Fontana G, Gardner C, Prime M. Challenges for the 

evaluation of digital health solutions – A call for innovative evidence generation approaches. 
NPJ Digit Med. (2020). 3(1), 110-110. https://doi.org/10.1038/s41746-020-00314-2 

10. Campbell ANC, Nunes EV, Matthews AG, Stitzer M, Miele GM, Polsky D, Turrigiano E, 
Walters S, McClure EA, Kyle TL, Wahle A, Van Veldhuisen P, Goldman B, Babcock D, 
Stabile PQ, Winhusen T, Ghitza UE. Internet-delivered treatment for substance abuse: A 
multisite randomized controlled trial. Am J Psychiatry (2014) 171(6):683-
690. https://doi.org/10.1176/appi.ajp.2014.13081055 

11. Christensen DR, Landes RD, Jackson L, Marsch LA, Mancino MJ, Chopra MP, Bickel, WK. 

Adding an internet-delivered treatment to an efficacious treatment package for opioid 
dependence. J Consult Clin Psychol (2014) 82(6):964-972. https://doi.org/10.1037/a0037496 

12. Ritterband LM, Thorndike FP, Ingersoll KS, Lord HR, Gonder-Frederick L, Frederick C, 
Quigg MS, Cohn WF,  Morin CM. Effect of a web-based cognitive behavior therapy for 
insomnia intervention with 1-year follow-up: A randomized clinical trial. JAMA Psychiatry 
(2016) 74(1):68-75. https://doi.org/10.1001/jamapsychiatry.2016.3249 

13. Christensen H, Batterham PJ, Gosling, JA, Ritterband, LM, Griffiths KM, Thorndike, FP, 
Glozier N, O'Dea, B, Hickie, IB, Mackinnon AJ. Effectiveness of an online insomnia 
program (SHUTi) for prevention of depressive episodes (the GoodNight study): A 
randomised controlled trial. Lancet Psychiatry (2016) 3(4):333-
341. https://doi.org/10.1016/S2215-0366(15)00536-2 

14. Kollins SH, DeLoss DJ, Cañadas E, Lutz J, Findling RL, Keefe RSE, Epstein JN, Cutler AJ, 
Faraone SV. A novel digital intervention for actively reducing severity of paediatric ADHD 

 
10 

(STARS-ADHD): A randomised controlled trial. Lancet Digit Health (2020) 2(4): e168-
e178. https://doi.org/10.1016/S2589-7500(20)30017-0 

15. Kollins SH, Childress A, Heusser AC, Lutz J. Effectiveness of a digital therapeutic as adjunct 

to treatment with medication in pediatric ADHD. NPJ Digit Med. (2021) 4:58-58. 
https://doi.org/10.1038/s41746-021-00429-0 

16. Lau N, O'Daffer A, Colt S, Yi-Frazier JP, Palermo TM, McCauley E, Rosenberg AR. 
Android and iPhone Mobile Apps for Psychosocial Wellness and Stress Management: 
Systematic Search in App Stores and Literature Review. JMIR mHealth and uHealth (2020) 
8(5), e17798. https://doi.org/10.2196/17798 

17. Bodner KA, Goldberg TE, Devanand DP, Doraiswamy PM. Advancing Computerized 

Cognitive Training for MCI and Alzheimer's Disease in a Pandemic and Post-pandemic 
World. Front Psychiatry (2020) 11:557571-
557571. https://doi.org/10.3389/fpsyt.2020.557571 

18. Boardman S. Creating wellness apps with high patient engagement to close the intention-

action gap. Int PsychGeriatr (2021) 33(6):551-552 

19. Torous J, Lipschitz J, Ng M, Firth J. Dropout rates in clinical trials of smartphone apps for 
depressive symptoms: A systematic review and meta-analysis. J Affect Disord (2020). 
263:413-419. https://doi.org/10.1016/j.jad.2019.11.167 

20. Leon AC, Mallinckrodt CH, Chuang-Stein C, Archibald DG, Archer GE, & Chartier K. 

Attrition in randomized controlled clinical trials: Methodological issues in 
psychopharmacology. Biol Psychiatry (2006). 59(11), 1001-
1005. https://doi.org/10.1016/j.biopsych.2005.10.020 

21. Torous J, Michalak EE, O'Brien HL. Digital health and engagement - looking behind the 

measures and methods. JAMA Network Open (2020). 3(7), e2010918-
e2010918. https://doi.org/10.1001/jamanetworkopen.2020.10918 

22. Chien I, Enrique A, Palacios J, et al. A Machine Learning Approach to Understanding 

Patterns of Engagement with Internet-Delivered Mental Health Interventions. JAMA Netw 
Open (2020) 3:e2010791-e2010791. https://doi.org/10.1001/jamanetworkopen.2020.10791 

23. Baumel A, Muench F, Edan S, Kane JM. Objective user engagement with mental health 

apps: Systematic search and panel-based usage analysis. J Med Internet Res (2019). 21(9), 
e14567-e14567. https://doi.org/10.2196/14567 

24. Szinay D, Jones A, Chadborn T, Brown J, Naughton F. Influences on the uptake of and 

engagement with health and well-being smartphone apps: Systematic review. J Med Internet 
Res (2020) 22:e17572-e17572. https://doi.org/10.2196/17572 

25.  Mordecai D, Histon T, Neuwirth E, et al. How Kaiser Permanente Created a Mental Health 
and Wellness Digital Ecosystem. NEJM Catalyst Innovations in care Delivery (2021) 01. 

 
 
 
 
 
 
 
 
 
 
11 

Attrition Rate for 
Active 
Intervention Arm 
6% 

9.2% 

17.5%1 

12% 
(pharmacotherapy) 

12%  
(no 
pharmacotherapy) 

Table 1. Attrition Rates in Studies of FDA Cleared Digital Therapeutics 

Reference 
Number  

N 

Indication 

Study Intervention and 
Dose 

Trial 
Design 

Trial 
Duration 

Engagement 

14 

348 

Pediatric 
ADHD 

RCT of Endeavor Rx vs. 
control Video game  

Hybrid 

4 weeks 

83% 

25 minutes per day, five 
days per week, for 4 weeks. 

SHUTi (Somryst) 

Remote 

12 

303 

15 

206 

Chronic 
Insomnia  

Pediatric 
ADHD 

11 

170 

Opioid Use 
Disorder 

six sequential modules 
completed within 9 weeks 
Open Label study of 
Endeavor Rx +/- 
pharmacotherapy 

4 weeks (25 mins/day, 5 
days/week), followed by a 4 
week pause, and then 
another 4-week use of 
therapeutic. 
Therapeutic Education 
System (reSET-O) 

TES modules 3 times per 
week for 12 weeks. 

Hybrid 

9 weeks, 
 with 12- 
month 
follow-up.  
12 weeks 

60.3% 

68% 
(pharmacotherapy) 
58% (no 
pharmacotherapy)2 

In-Clinic 

12 weeks 

All sessions were 
supervised by a live 
therapist in the clinic.  

20%  

10 

507  

Substance 
Use Disorder 

Therapeutic Education 
System (reSET) 

Hybrid 

12 weeks 

76.3%3  

12% 

4 TES modules per week for 
12 weeks. 

13 

1149 

Subclinical 
depression 
and insomnia  

SHUTi (Somryst) 

Remote 

six sequential modules 
completed within 6 weeks 

58% 

6 weeks, 
with 6 
month 
follow up 

57% 

61%4  

1 Attrition at 12 month follow up. Studies used variable definitions and often did ot break down reasons.  
2 Compliance is defined as the percentage of total possible recommended sessions. Engagement metrics were not 
reported in a standardized manner 
3 36.6 modules out of recommended 48 (range 0-72) 
4 Attrition at 6 month follow up.  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
