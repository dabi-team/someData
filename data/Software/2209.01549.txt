2
2
0
2

p
e
S
4

]
E
S
.
s
c
[

1
v
9
4
5
1
0
.
9
0
2
2
:
v
i
X
r
a

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

1

The Broken Windows Theory Applies to
Technical Debt

William Lev ´en, Hampus Broman, Terese Besker, and Richard Torkar

Abstract—Context: The term technical debt (TD) describes the aggregation of sub-optimal solutions that serve to impede the
evolution and maintenance of a system. Some claim that the broken windows theory (BWT), a concept borrowed from criminology, also
applies to software development projects. The theory states that the presence of indications of previous crime (such as a broken
window) will increase the likelihood of further criminal activity; TD could be considered the broken windows of software systems.
Objective: To empirically investigate the causal relationship between the TD density of a system and the propensity of developers to
introduce new TD during the extension of that system.
Method: The study used a mixed-methods research strategy consisting of a controlled experiment with an accompanying survey and
follow-up interviews. The experiment had a total of 29 developers of varying experience levels completing a system extension tasks in
an already existing systems with high or low TD density. The solutions were scanned for TD, both manually and automatically. Six of
the subjects participated in follow-up interviews, where the results were analyzed using thematic analysis.
Result: The analysis revealed signiﬁcant effects of TD level on the subjects’ tendency to re-implement (rather than reuse) functionality,
choose non-descriptive variable names, and introduce other code smells identiﬁed by the software tool SonarQube, all with at least
95% credible intervals. Additionally, the developers appeared to be, at least partially, aware of when they had introduced TD.
Conclusion: Three separate signiﬁcant results along with a validating qualitative result combine to form substantial evidence of the
BWT’s applicability to software engineering contexts. This study ﬁnds that existing TD has a mayor impact on developers propensity to
introduce new TD of various types during development. While mimicry seems to be part of the explanation it can not alone describe the
observed effects.

Index Terms—Software engineering, broken windows theory, technical debt, controlled experiment, Bayesian data analysis, thematic
analysis.

(cid:70)

1 INTRODUCTION

Contemporary software systems often have complex
and constantly evolving code bases that require continuous
maintenance. Martini et al. [1] found that developers waste
as much as twenty-ﬁve percent of development time refac-
toring or otherwise managing previous implemented sub-
optimal solutions. The culprit is technical debt (TD), an ac-
cumulation of “not-quite-right” implementations that now
serve to impede further development and maintenance. The
costs incurred by TD often claim a sizeable portion of the
budget of software development projects and are referred to
as interest [2].

What is worse, unless actively managed, the costs of
TD may increase nearly exponentially with TD generating
additional TD as well as interest [3], [4]. There are multiple
possible causes of this dynamic (and they are not mutually
exclusive). Hunt and Thomas [5, p. 6] suggested that the
most important factor is the “psychology, or culture, at work
on a project.” They explained this by analogously applying
the broken windows theory (BWT) from criminology. The BWT
states that an indication of previous crimes, or even just
general disorder, increases the likelihood of further crimes
being committed. In their view, this holds in software de-
velopment projects, where acceptance of minor defects can

• T. Besker is with RISE Research Institutes of Sweden AB,

Gothenburg, Sweden

• R. Torkar is with Chalmers and University of Gothenburg, Sweden, and

Stellenbosch Institute for Advanced Study, South Africa

result in a snowball effect that causes further deterioration
of not only the system, but also the culture surrounding the
project.

It is a compelling argument that a developer might think
that if someone else got away with being careless, perhaps
they could too. From a psychological perspective, this could
be explained through the lens of norms, where the apparent
prevalence of a behavior forms a descriptive norm, signaling
that the behavior is acceptable. It could also be that it
happens through unconscious mimicry of previous work,
or that it is simply a result of being less enthusiastic about
the system due to the TD. Though this software engineering
BWT gained some traction, there appears to be no empirical
evidence of its correctness. Besker et al. [6] found that the
existence of TD impairs the morale of software developers,
lending some credence to the theory, but did not examine
the tangible effects of that decline.

This study aims to evaluate the causal relationship be-
tween the TD density of a system and the propensity of de-
velopers to introduce TD during the extension of the system.
While there is some research indicating the developers often
ﬁnd themselves forced to introduce TD as a result of previous
suboptimal solutions [7], our interest is in situations where
no signiﬁcant hurdles are preventing the developer from
implementing a low TD solution. In other words, our goal
is to understand if they will adopt the negligent attitude
towards the software that they may infer is acceptable, given
its state.

The study utilizes a mixed-methods design combining

 
 
 
 
 
 
JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

2

the quantitative strengths of a controlled experiment and a
survey with the qualitative comprehension offered by semi-
structured interviews. The experiment involved software
practitioners completing tasks that required the extension of
small existing systems, designed speciﬁcally for the exper-
iment, half of which we had deliberately injected with TD.
Volunteering participants were subsequently interviewed,
and asked about their reason for choosing their particular
solution, their general thoughts around TD management,
and their experiences on the BWT in software engineering.
The quantitative data from the experiment and survey were
interpreted using Bayesian data analysis and the qualitative
data produced by the interviews through thematic analysis.

Efﬁcient management of TD requires an understanding
of the dynamics that govern its growth and spread. The
results of this study could be a ﬁrst step toward formulating
improved strategies to keep TD levels in check. Addition-
ally, the experiment could be seen as a cross-disciplinary
effort that could speak to the generalizability of the original
broken windows theory.

1.1 Research Questions

The goals of this study are condensed into the following
research questions, and by distinguishing between similar
and dissimilar TD, we ask whether developers mostly mimic
TD they come in contact with or if they also introduce TD of
a different character than that which was previously in the
system.

RQ1: How does existing technical debt affect a devel-
oper’s propensity to introduce technical debt dur-
ing further development of a system?

RQ1.1: How does existing technical debt affect a devel-
oper’s propensity to introduce similar technical
debt during further development of a system?

RQ1.2: How does existing technical debt affect a devel-
oper’s propensity to introduce dissimilar technical
debt during further development of a system?

2 THE BROKEN WINDOWS THEORY
The story of the BWT starts with an experiment conducted
by Philip Zimbardo in 1969. He placed identical cars, with
no license plates and the hoods up, in Bronx, New York, and
Palo Alto, California (on the Stanford campus).

The car in New York was destroyed and stripped of
parts after just three days, while the car left on the Stanford
campus went untouched for over a week [8]. Zimbardo was
not investigating the BWT, rather, he wanted to observe
what kind of people committed acts of vandalism and un-
der what circumstances [8]. However, he did (successfully)
employ the BWT when he initiated the vandalism by taking
a sledgehammer to the car on the Stanford campus, after
which others continued the vandalism within hours [8].

A sample size of one is hardly convincing. However,
Zimbardo’s experiment inspired Wilson and Kelling to
write an opinion piece in the monthly magazine “The At-
lantic”. The text, Broken Windows: The police and neighborhood
safety [9], takes the concept beyond the narrow domain
of vandalism and applies it to a broader context of crime
and antisocial behavior. In doing so, they created what
subsequently became known as the BWT.

Wilson and Kelling suggest (although they provide no

evidence) that:

Window-breaking does not necessarily occur on
a large scale because some areas are inhabited
by determined window-breakers whereas others
are populated by window-lovers; rather, one unre-
paired broken window is a signal that no one cares,
and so breaking more windows costs nothing. (It
has always been fun.) [9]

Perhaps the most proliﬁc example of policy shaped by the
BWT is that of New York City under former mayor Rudy
Giuliani and police commissioner William Bratton. The
strategy adopted revolved around strictly enforcing minor
crimes and was followed by a 50% drop in property and
violent crime [10]. While the political leadership attributed
the improvement to their broken windows policing policies,
the causality of this relationship has been questioned [11],
[12].

Several more recent studies have provided empirical
evidence supporting the BWT. Keizer et al. [13] secretly
observed a number of public areas in Groningen, to some
of which they had deliberately introduced disorder, e.g.,
grafﬁti, and found that it had a signiﬁcant effect on fur-
ther minor crime (such as grafﬁti or littering), but also on
more serious crime such as robberies. Additionally, a 2015
meta-study found that broken window policing strategies
moderately decrease crime levels [14].

The BWT has also been examined from a more psycho-
logical perspective, in the context of normativity. Several
studies within the ﬁeld have evaluated the effects of a
littered environment on the propensity of subjects to litter
themselves [15], [16]. Cialdini et al. [16] argue that a littered
environment conveys the descriptive norm that littering is
acceptable.

The ﬁrst reference to the BWT in a software engineering
context appears in The Pragmatic Programmer: From Journey-
man to Master, where authors Hunt and Thomas assert that
the BWT holds in the software development context [5].
They describe the psychology and culture of a project team
as the (likely) most crucial driver of software entropy (some-
times referred to as software rot and the “broken windows,”
they claim, is are signiﬁcant factors in shaping them [5]:
One broken window—a badly designed piece of
code, a poor management decision that the team
must live with for the duration of the project—is
all it takes to start the decline. If you ﬁnd yourself
working on a project with quite a few broken
windows, it’s all too easy to slip into the mindset
of “All the rest of this code is crap, I’ll just follow
suit.” [5, p. 8]

Hunt and Thomas provide no evidence to support this
claim, other than referring to the 1969 Zimbardo experi-
ment [8] and an (unsupported) assertion that anti-broken
window measures have worked in New York City [5]. The
only software development-speciﬁc arguments come in the
form of anecdotal evidence [5].

Since its inception, the BWT in software engineering
has mostly been discussed on online blogs and, sometimes
using different terminology, in popular books such as Clean
Code [17] with the occasional mention in a scientiﬁc pa-

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

3

per [18]. Section 4 further explores the prevalence of the
BWT in software engineering research.

3 TECHNICAL DEBT

Shipping ﬁrst time code is like going into debt. A
little debt speeds development so long as it is paid
back promptly with a rewrite. . . The danger occurs
when the debt is not repaid. Every minute spent on
not-quite-right code counts as interest on that debt.

—Cunningham , 1992 [19, p. 30]

Ward Cunningham (co-author of The Agile Manifesto [20])
coined the metaphor in his 1992 OOPSLA experience
report [19]. Since then, the concept of TD has gained
widespread popularity and is commonly applied, not just
to code but also to related concepts, resulting in terms such
as documentation technical debt and build technical debt [21].

Technical debt is now a concept used and studied aca-
demically. While there certainly are multiple deﬁnitions
to choose from, in this paper, we will use the following
one arrived at during the 2016 “Dagstuhl Seminar 16162:
Managing Technical Debt in Software Engineering”:

In software-intensive systems, technical debt is a
collection of design or implementation constructs
that are expedient in the short term, but set up
a technical context that can make future changes
more costly or impossible. Technical debt presents
an actual or contingent liability whose impact
is limited to internal system qualities, primarily
maintainability and evolvability. [22, p. 112]

Studying the propagation of TD requires a method for
identifying it. There are multiple such methods, ranging
from those that require more manual labor to those that
rely on automated processes [3], [6], [23]. Some TD could be
painfully apparent to developers; after all, it might impact
their professional life daily. Simply asking project members
could be a way of identifying some of the most egregious
instances of TD.

Other types of TD can be a little more subtle. Manually
scanning the code for these would generally be prohibitively
time-consuming, hence a need for automation. Static code
analysis tools see frequent use in industry and research
contexts; they rely on rule sets to identify TD items, often
referred to as code smells [24]. Some such tools even at-
tempt to estimate the time required to ﬁx each item [24].
This category ranges from simple linting rules that can do
little beyond correcting indentation to more encompassing
solutions that detect security issues and deviations from
language convention.

We propose to interpret TD items as the broken win-
dows of software engineering as introduced by Hunt and
Thomas [5]. In our view, several recent ﬁndings support this
conceptualization.

Besker et al. [6] found TD to negatively impact developer
morale, establishing a link between TD and the psycholog-
ical state of those working in its presence. This lowered
morale is reminiscent of the dynamic described by Wilson
and Kelling in their original Broken Windows article, where
they assert that general disorder will trigger the local inhab-
itants to adopt a general stance of “not getting involved” [9].

This link is further supported by a study by Olsson et al. [23]
that used the SAM (self-assessment manikin) system to map
changes in affective states triggered by interaction with TD.
A natural continuation of that research would be to examine
the effects of this psychological impact, where propagation
or reproduction of TD may be one of the most exciting lines
of inquiry.

4 RELATED LITERATURE

Tufano et al. [25] found that most code smells were intro-
duced during the creation of an artifact or feature and that
when code smells were introduced during the evolution of
the project, it was usually in close proximity to preexisting
code-smells. They also observed that a signiﬁcant portion
was introduced during refactoring activities and that devel-
opers with high workloads or tight schedules were more
likely to introduce them. On the other hand, Digkas et
al. [26] examined the change in code technical debt (CTD)
over time in a set of open-source projects and attempted to
correlate the amount of CTD introduced with the workload
of the development teams. They did, however, not ﬁnd
any correlation between the workload of the teams and
the amount of new CTD introduced. Furthermore, the same
study found that the introduction of CTD was mainly stable
over time, with a few spikes. In contrast, Lenarduzzi et
al. [27] followed the migration of a monolithic system to a
micro-services system and found that for each individual
micro-service, the amount of TD was very high in the
beginning but decreased as the artifact matured. The study
also reported that the migration reduced the rate at which
TD grew in the system but that, over time, TD still grew.

Chatzigeorgiou and Manakos [28] as well as Digkas et al.
[29] found that TD is mainly introduced when adding new
features to a code base and that as they are not removed,
they accumulate over time. Similarly, Bavota and Russo [30]
showed that instances of self-admitted TD increase over the
lifetime of a project and that it usually takes a long time
for them to be resolved. Digkas et al. [29] and de Sousa et
al. [31] did however also ﬁnd that while the total amount of
TD grows, the density decreases when new features with a
lower TD density are added. de Sousa et al. [31] also found,
through practitioner interviews, that inexperienced devel-
opers propagate error handling anti-patterns by replicating
existing practices in the code base.

Two studies by Rios et al. [32] [33] asked practitioners
to identify the causes and effects of documentation debt
(DD). Non-adaptation of good practices was the third most
mentioned cause of DD. Similarly, low documentation qual-
ity (outdated/non-existent/inadequate) was a commonly
mentioned effect of DD. Unfortunately, the studies do not
make it clear how the practitioners might have interpreted
the survey and interview questions (and some answers
suggest that interpretations varied). Therefore, we cannot be
sure whether the mentioned effects and causes refer to the
speciﬁc instance of debt or the system in general. Only the
latter interpretation would support the BWT. Verdecchia et
al. [34] also interviews practitioners and identiﬁes perceived
effects of architectural technical debt (ATD). They ﬁnd that
ATD is perceived to cause code smells.

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

4

Besker et al. [35] studied TD management from the per-
spective of startups, through interaction with practitioners.
They brieﬂy mention a possible vicious cycle involving TD
and project culture, but found that some developers saw TD
not to be much of an issue in a static project group where
everyone is aware of and used to it. They note a tendency to
reduce TD before bringing new developers onto a project.
In another study, Besker et al. [7] found that developers see
themselves forced to introduce TD in as much as a quarter
of the cases where they encounter existing TD; suggesting
TD has a contagious nature. Ozkaya [36] also proposed a
vicious cycle in which messy code reduces the morale of the
developers, causing them to write more messy code.

Some studies have attempted to model the interest and
growth of TD. Martini and Bosch [3] conceptualizes a model
detailing the cause and effect of ATD and ﬁnd a potentially
vicious cycle through which existing ATD causes more
ATD to be implemented. Two other studies by Martini and
Bosch [37] [38] continue the work and evaluate methods
in cooperation with industry for estimating the future cost
of ATD. The derived methods involve several propagation
factors of ATD, but none of the identiﬁed factors includes
the BWT. Martini and Bosch [4] do however investigate how
ATD propagates and one of their identiﬁed propagation
patterns is “Propagation by bad example,” indicating that
developers copy the practices they see in a system.

The literature search did not result in a single paper that
treats the BWT as the main subject, and it is never discussed
using the broken windows terminology. The most common
way it appears is by being brought up by interviewees as a
cause or effect of TD. One of the most interesting entries is
that by Tufano et al. [25] which found that new code smells
tend to appear in areas where code smells were already
common. However, there are other possible explanations
than BWT effects for that ﬁnding.

The concept of TD inducing further TD is not uncom-
mon. However, the sub-mechanisms identiﬁed are usually
restricted to that building on top of TD creates further TD, or
that interaction effects between TD items result in higher in-
terest payments than would have been necessary if the items
were separate. We found no studies using an experimental
methodology; most of them are ﬁeld studies or judgment
studies, making causality difﬁcult to ascertain. One may
conclude that this focus on more exploratory methods is a
symptom of the research ﬁeld being relatively new; some of
the included entries explicitly state that the ﬁeld has, until
recently, chieﬂy been interested in deﬁnitions and theory-
building. Furthermore, a majority of related literature has
been published in the last ﬁve years.

5 METHOD

Seaman [39] argues that diverse evidence gathered through
multiple distinct methodologies will constitute stronger
proof than evidence of a single type, a concept commonly
referred to as triangulation. Following her advice, this study
uses a mixed-methods design. The quantitative part con-
sisted of a controlled experiment coupled with surveys,
and the qualitative component was comprised of follow-up
interviews. While more effort was put towards the former,
the latter could constitute an essential complement, enabling

Fig. 1: The GQM (goal, question, metric) breaks down the
overarching goal (conceptual level) into questions (opera-
tional level) that needs answering in order to satisfy the
goals. Answering the question requires identiﬁcation and
measurement of suitable metrics (quantitative level). Qual-
itative data from interviews were used to further validate
and provide insight into our ﬁndings.

us to clarify, contextualize and corroborate the results of the
quantitative analysis.

Using the software research strategy framework laid
out by Stol and Fitzgerald [40], we would classify the
experiment as experimental simulation while we would argue
that the interview component belongs in the judgment study
category. We consider them suitable complements to each
other, as the former allows inference of causality, while the
latter does not. However, a judgment study is of a more
ﬂexible and exploratory nature, allowing us to discover
some ﬁner details that the experiment might miss [40]. This
chapter describes our methods for each component sepa-
rately. Figure 1 presents a goal-question-metric breakdown
of our design, as prescribed by Basili et al. [41].

5.1 The Experiment

This section describes the design and administration of
the experiment and surveys that constitute the quantitative
component of our study. The purpose of the experiment was
to isolate the effects of the independent variable, technical
debt (TD), which would allow us to investigate the causal
relationship.

5.1.1 Technical Debt Level: The Independent Variable

Since there is a vast, arguably inﬁnite number of issues that
constitute TD, determining a suitable subset to represent
high TD is not a trivial task. The approach chosen was to go
with two distinctly different types of issues introduced at a
very high (maximal) rate. This way, we ensured that design-
ing suitable sets of systems and tasks, henceforth referred to
as scenarios, was feasible. It also mitigated the risk associated
with choosing a single issue type as a representative for TD.
The ﬁrst type of TD we chose was bad variable names,
an issue with multiple great properties for the purposes of
this study. Variables names are typically abundant (in the
vast majority of programming languages); hence changing

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

5

them for the worse would constitute a ﬂaw that the subject
would be likely to detect. Bad variable names are also
a clear example of code technical debt. A variable whose
name poorly describes its purpose will make the code less
readable, which means that any time a piece of code needs
to be understood, e.g., during refactoring, the process will
be conceptually harder [42], [43], and hence, slower. This
extra time (and associated development costs) constitute the
interest payment that characterizes TD.

The second type we chose was code duplication. This
issue shares the property of applying to the vast majority
of programming languages; however, in other regards, it
contrasts nicely with bad variable names. Notably, it may
not be quite as obvious a defect, and avoiding propagation
of it will usually take the developer more effort. In terms
of scenario design, we found that accommodating the in-
clusion of code duplication and constructing tasks that a
subject could solve with or without introducing additional
TD were both feasible. Code duplication is often, but not
always, an example of TD. Insisting on shared function-
ality between distant and unrelated classes may lead to
excessive interdependency and complexity [44]. In many
cases, however, there is a strong case that code duplication
causes maintainability problems [45] and can be considered
TD [24].

Classifying code duplication as a particular type of TD is
not straightforward. While Li et al. [46] ﬁrmly categorize it
as code TD, using the taxonomy offered by Alves et al. [24],
it could be considered design TD. Further complicating
matters, in a systematic review by Besker et al. [47], they
found that several authors describe code duplication as
architectural TD. For the purpose of this study the exact
classiﬁcation is not important; we are content with noting
that they all agree that code duplication often constitutes
TD.

5.1.2 Controlled Variables

When conducting an experiment, it is preferable to control
as many factors as possible to avoid confounding. This
study managed to control the following variables.

Programming Language. For several practical reasons,
Java1 was chosen as the sole language of all scenarios. First,
it is one of the most widespread programming languages
in existence, not just in industry, but it is also often the
language used for teaching object-oriented programming at
educational institutions. Second, we, the authors, were all
comfortable with working in Java.

Development Environment. To mitigate interference
from participants using different editors with different lev-
els of support we developed an original research tool which
enforced a standard, but fairly barebones, editor. The ed-
itor is a web-based environment that integrates the ACE
text editor2 to provide a set of text editing shortcuts and
syntax highlighting. The tool has access to a remote server
that compiles and executes the users’ code in a secure
environment. It also oversees the experiment by allocating
scenarios, treatments and providing instructions. A demo

of the tool will remain available at https://bwtse.github.io/
RobotResearcher for evaluation purposes.3

Scenarios We created two tasks and their correspond-
ing systems to be quite similar. One of them was to ex-
tend a room booking system with a new room type and
the other was a commuting ticket systems with a new
ticket type. Both systems were of similar size as well
as structure and can be reviewed at https://github.com/
BWTSE/Scenarios/tree/persist1.3 and https://doi.org/10.
5281/zenodo.7011996.

5.1.3 Dependent Variables

The dependent variables represent what outcomes could be
affected by the variation of the independent variable. We
used various measures of the amount of TD added to the
system by the subject.

Logic reuse measured if the existing logic, validation
and constructor, had been duplicated or reused while com-
pleting the task. For the purpose of this measure any type
of reuse qualiﬁed.

Variable naming recorded how many of the old, new
and copied variable names that fulﬁlled the following re-
quirements, inspired by the guidelines proposed by Butler
et. al. [43]:

• It should consist of one, or multiple, full words.
• Its name should have some connection to its use and/

or the concept it represents.

• It should follow the format of some widely used nam-
ing conventions. While camel case is generally the
standard for Java, we do not specify a standard and
thus choose to generously also accept names that con-
sistently follow other conventions such as snake case or
pascal case.

• If it is used for iterating (where, e.g., i,j are commonly
chosen names), or the variable represents something
unknown (such as in the case of equals()) anything
gets a pass.
SonarQube issues measured how many issues the static
analysis tool SonarQube found in the submitted solution.
Beyond the base set of issue identiﬁcation rules (Java Code
Quality and Security), we included three additional libraries
Checkstyle4, Codehawk Java5, and Findbugs6. The result is
a set of 1588 rules. Not all rules were suitable. The following
criteria were grounds for rule exclusion:7

• The rule duplicates another rule, which was occasion-

ally the case, as we included multiple libraries.

• The rule represented a possible standard, i.e., one that
may or may not be the standard at a particular institu-
tion but could not be considered part of general Java
convention.

3. Source

available

at:

RobotResearcher/tree/persist1.2
zenodo.7012040.
4. Checkstyle
sonar-checkstyle
5. CodeHawk

available

available

at:

at:

https://github.com/BWTSE/
https://doi.org/10.5281/

and

https://github.com/checkstyle/

https://github.com/SEPMLAB/

CodeHawk

6. Findbugs
sonar-ﬁndbugs

available

at:

https://github.com/spotbugs/

1. https://www.oracle.com/java/
2. https://web.archive.org/web/20210509090040/https://ace.c9.

io/

7. Full list of SonarQube rules used and excluded is available at https:
//github.com/BWTSE/Data/tree/v1.4 and https://doi.org/10.5281/
zenodo.7011992.

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

6

• The rule measures one of the things that we had already
measured manually, e.g., code duplication detection
rules were excluded in favor of manual inspection as
we found them to be insufﬁciently effective.

• The rule concerns minor indentation and cosmetic for-
matting errors. Such rules would generate copious
amounts of issues, drowning out all others. We also
considered them invalid since most commonly used
IDEs will help the user maintain proper indentation,
while the provided editor would not.

• The rule did not make sense for a system as simple as

the scenario codebases.

• The rule appeared not to function as intended.

Implemented utility methods recorded if the partic-
ipant had implemented the utility methods equals and
hashCode for the new classes they added.

Documentation state measured whether the newly
added functionality had been documented and whether the
documentation was correct or not.

Task completion measured to which degree the task
was completed on the scale: “Not submitted”, “Does not
compile”, “Invalid solution” and “Completed”.

Time to complete task was recorded as it could provide

extra insight into the result of the study.

5.1.4 Predictor Variables

What we could not control, we accounted for through the
inclusion of additional predictor variables. Some otherwise
possibly confounding factors could be made part of the
model by gathering background information on the subjects.
The predictor variables were collected through a pre-task
survey and included information about programming expe-
rience, work domain, education level and ﬁeld. It also had
questions regarding which of the following software prac-
tices were used at their most recent place of employment:
“technical debt tracking”, “pair programming”, “established
code standards”, and “peer code reviewing”.

5.1.5 Treatment and Scenario Allocation Scheme

In anticipation of a modest sample size, we opted for a
repeated measures design, i.e., a design that would entail
each subject ﬁnishing multiple tasks. The drawback of such
a design is that it can produce learning effects, e.g., a subject
may get better at a task with repetition. We took several
measures to mitigate the impact of such effects:

• A subject was never given the same scenario twice.
Being able to reuse a previously created solution would
likely be irresistibly convenient.

• Each subject completed tasks in systems of high and
low levels of TD; this allowed the statistical model to
isolate the individual ‘baseline’ from the effect of the
treatment.

• The order of the scenarios was randomized.

The minimum number of tasks required to fulﬁll these
criteria was two, each with an accompanying system that
existed in a high TD and a low TD version. Hence, there
would be four experimental run conﬁgurations in total, as
shown in Table 1.

TABLE 1: Treatment Schedule.

Scenario 1 - High TD Scenario 2 - Low TD
Scenario 1 - Low TD Scenario 2 - High TD
Scenario 2 - High TD Scenario 1 - Low TD
Scenario 2 - Low TD Scenario 1 - High TD

Fig. 2: DAG encoding our causal assumptions concerning
the experiment. “Y. Measures of introduced TD” corre-
sponds to logic reuse, variable, naming, SonarQube issues, docu-
mentation state, and implemented utility logic. They are actually
parallel (having the exact same ingoing and outgoing edges)
but were condensed into a single node to keep the graph
readable. The same goes for “B. Measured personal charac-
teristics”, which combines all the measures taken during the
background survey.

5.1.6 Study Validation

Through a follow up survey we also asked the participants
to rate the quality of their submissions as well as the system
they were asked to work on as this data could help us
validate our scenarios and how we measured the quality
of submissions.

All classiﬁcation and data extraction were done by two
researchers independently and later compared to ﬁnd and
resolve any discrepancies or errors. All data from the ex-
periment is available at https://github.com/BWTSE/Data/
tree/v1.4 and https://doi.org/10.5281/zenodo.7011992.

As we used an original tool to collect data for the exper-
iment we performed extensive user testing on it before the
study was sent out. Both scenarios were in a similar manner
subject to such tests to ensure that they were understandable
and clear.

We also performed a pre-study, and as we did not
encounter any issues that led to revisions in our scenarios
or data collection tool, we used all data from the pre-study
in our analysis.

5.1.7 Causal Analysis
Pearl [48] suggests building a directed acyclic graph (DAG) of
all possible causal relationships in the analysis as it helps
the authors document their assumptions and reason about,
as well as make claims about causality. The DAG shown
in Fig. 2 depicts the possible causal relationships between
the measures we aim to safely include in our statistical
models when we want to be able to infer causality. The
causal relations of the DAG can easily be motivated. Both A
and X were randomized and thus cannot have been affected
by any other variables. The personal characteristics (B) are
measured before the participant is assigned a scenario and
a TD level protecting it from any inﬂuence of A and X. The
task submissions, from which the measures of introduced

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

7

TD (Y) were derived, did not exist before the subject started
the experiment, but were products of the participants, the
scenarios, and the TD levels. Hence, they could not have
inﬂuenced the subjects’ personal characteristics.

Once the DAG has been constructed do-calculus can
be used to check if a speciﬁc causal relationship may be
inferred from the statistical model [48]. This is done by
constructing a do-statement for the question we want to ask
our model and transforming it using the rules of do-calculus
with the goal of eliminating all do-clauses [48]. If all do-
clauses can be removed it follows that a causal relationship
can be measured by our statistical model [48].

The questions we want to ask our model can be de-
scribed as P (Y|do(X), A, B). The second rule of do-calculus
states that P (Y|do(X), Z) can be rewritten as P (Y|X, Z)
when all backdoor-paths between X and Y are blocked by
Z [48]. Our expression satisﬁes these criteria as X and Y are
independent apart from the direct causal link X → Y and
when the rule is applied we get P (Y|X, A, B) which tells
us that a causal relationship can be measured by our model,
assuming that the stated assumptions are correct.

We will end this section by pointing out that the mea-
sured personal characteristics are not randomized and that
we can not, and will not, claim causality of any effects
estimated for them. They could have numerous unmeasured
ancestor variables in common with the dependent variable,
creating causal backdoors that we could not have blocked.

5.1.8 Analysis Procedure

We used Bayesian data analysis (BDA) to analyze the data
from our experiments. Bayesian data analysis allows the
speciﬁcation of a model, which is then ﬁtted using empirical
data through Bayesian updating [49]. This model can then
be queried for multiple scenarios [49]. In contrast, a tradi-
tional frequentist analysis arrives at a result that is either
signiﬁcant or insigniﬁcant, which is entirely dependent on
their selection of α (which commonly is set to 0.05 in the
natural sciences). Wasserstein et al. postulate that the ﬁxa-
tion with statistical signiﬁcance is unhealthy, and thus, they
encourage a move “beyond statistical signiﬁcance” [50]. Em-
ploying BDA is one way of following this suggestion which,
according to Wasserstein et al., could prevent the software
engineering community from ending up in a replication
crisis like certain other disciplines.

A challenge with using BDA is that there is no widely ac-
cepted standard procedure. We largely followed the Bayesian
workﬂow laid out by Gelman et al. [51]. However, there are
many ﬁne points to the iterative process of model building
that they do not cover in detail.

We have multiple questions we would like the data to
answer, each requiring its own speciﬁcally tailored model.
To keep our analysis consistent, we used a uniform proce-
dure to create and evaluate all models. Our complete analy-
sis, conducted in accordance with the procedure detailed in
this section, can be found in our replication package.8

We began the model building process by plotting the
data and extracting some descriptive statistics (e.g., mean,

variance, and median) to get a rough understanding of its
distribution. We then created an initial model by choosing
an appropriate distribution type and adding our essential
predictors. We based this choice on whether the distribution
type accurately described the underlying data generation
process that produced the data and how well it ﬁtted the
empirical data.

After adopting a distribution and basic predictors, we
also had to set priors. We did this by using the default priors
(suggested by the brm function of the brms package9) as
a starting point and then tuned them until we had priors
that allowed for reasonable outcome values. We also made
sure that our β parameters had priors that were skeptical of
extreme effects. We did not encode any prior knowledge
regarding the BWT into our priors since there appears
to be no previous research on the subject in a software
engineering context.

When we had an initial model with appropriate priors,
we had to determine which predictors to include in the ﬁnal
model. For the models describing the amount of introduced
TD, where we wanted to infer causality, we did this by
creating a set of possible predictors subject to the restrictions
laid out in Sect. 5.1.7. For other models, we used a more
exhaustive set of predictors.

Next, we created a new model for each of our possible
additional predictors and compared the extended models
with each other and the initial model using leave-one-out
cross-validation (speciﬁcally the version implemented by
the Stan package loo10). The comparison allowed us to
ascertain which predictors had signiﬁcant predictive capa-
bilities. Those predictors were then combined into a new
set of expanded models. We repeated the process until there
were no more predictors to combine.

As a last step we compared some of our most promising
models and picked the simplest set of predictors which
did not signiﬁcantly reduce the models’ performance. This
model was slightly modiﬁed to increase the validity of
our analysis by, e.g., ﬁtting it to all the available data and
adding β parameters that provided us with extra insight.
We then chose to keep those modiﬁcations if they did
not negatively impact the sampling process or signiﬁcantly
harm the model’s out-of-sample prediction capability.

The ﬁnal model was used to answer our research ques-
tions. This was done partially by inspecting the estimates
for the β parameters we were interested in and querying the
posterior probability distribution of the model, with factors
ﬁxed at various levels, and comparing the results. This ﬁnal
step of querying the model is crucial as it takes the general
uncertainty of the model into account and provides an easy
way to access effect sizes as it moves everything to the scale
of the original input data [52].

5.2 The Interviews

This section describes the procedure we used to conduct the
interviews that constitute the qualitative part of this study;
the purpose of which was to gain further insights relating to

9. We used version 2.15.1, brms can be found at https://github.com/

8. Available at https://bwtse.github.io/Analysis, source available at
https://github.com/BWTSE/Analysis/tree/v1.5 and https://doi.org/
10.5281/zenodo.7011982

paul-buerkner/brms

10. https://web.archive.org/web/20200814224945/https:

//mc-stan.org/loo/

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

8

our research questions. We also describe the process through
which we analyzed the resulting material.

All participants who agreed to a follow-up interview
were contacted and scheduled within a couple of days.
We scheduled each to a maximum of 30 minutes, but the
length could vary signiﬁcantly depending on the partici-
pants’ availability.

The interviews were semi-structured around a set of
questions with the purpose of giving us further insight into
why the participants acted as they did in the experiment.
The questions were:

1) Can you describe your solutions to the tasks in the

experiment?

2) Can you motivate why you choose those solutions?
3) What was your experience of the preexisting code?
4) How did the preexisting code affect you?
5) Do you have any other comments regarding the BWT
in software engineering? (This question followed a brief
explanation of the topic of our study)
Interviews were documented using ﬁeld notes as de-
scribed by Seaman [39], i.e., we noted down any interesting
reﬂections made by the interviewed participants relating to
our research questions. We omitted any identifying details
and, in many cases, translated the reﬂections from Swedish
to English. Some participants who did not participate in
the follow-up interviews provided us with their reﬂections
in text. We also included such reﬂection in the interview
material.

5.2.1 Interview Results Analysis

The resulting list of noteworthy statements was subjected to
thematic analysis using a process largely following the steps
laid out by Braun and Clarke [53], with the exception that
our base material did not consist of a complete transcription
but rather the ﬁeld notes as described in Sect. 5.2 This is a
brief description of the stages of the process [53]:

1) Familiarize yourself with the data.
2) Encode patterns in the data as codes.
3) Combine codes into overarching themes.
4) Check theme coherency and accuracy against the data,

iterate themes until those criteria are fulﬁlled.

5) Deﬁne the themes and their contribution to the under-

standing of the data.
When constructing themes, we did employ a partially
deductive approach, where we assumed some of the themes
from the start (i.e., software quality and system extension qual-
ity (in terms of maintainability) since these were the areas
of interest to us. The resulting set of themes was discussed
and agreed upon by two of the authors.

interviews was a subset of the experiment subjects, who
volunteered after completing their participation in the ex-
periment. Section 6 describes the resulting sample in detail.

6 RESULTS
In total, 29 subjects submitted solutions to at least one
of the two tasks, resulting in a total of 51 submissions.
The convenience-sampling procedure employed produced
a sample with some noticeable skews that reﬂect the nature
of our personal networks and our geographical location
(Gothenburg, Sweden).

While the experience level of the participants varied, six
of them had none or very little professional programming
experience and an additional 11 participants had less than
ﬁve years of experience. The overall mean of the reported
professional programming experience was 5.20 years and
the median a mere 1.5.

Subjects reported working in a wide variety of software
industry sectors ranging from embedded programming
to web development. The “Automotive” section is over-
represented among the participant, likely due to Volvo Cars
being a large local employer.

A majority of participants reported having completed
“some master-level studies,” with about a quarter claiming
a ﬁnished master’s degree. Regarding their ﬁeld of study all
but two participants reported “Computer Science” or “Soft-
ware Engineering” with the latter being twice as common as
the former. Only one participant reported having no higher
education.

A more detailed sample description with complemen-
tary descriptive statistics is available in the replication pack-
age.11

6.1 Method Deviations

Two participants reported that they had experienced prob-
lems with the UI of the data collection tool. One of them
accidentally reloaded the page and lost their progress. The
other one accidentally submitted an empty solution, which
lost us two submissions. However, these drop-outs could be
considered random and should not bias the sample.

One of the early participants discovered two minor
mistakes in the given scenarios. We resolved12 the mis-
takes upon notice and presented the revised versions to
subsequent participants. Given the limited impact of the
changes—they were not in a location that participants fre-
quently modiﬁed—we ﬁnd it unlikely that many partici-
pants noticed, let alone were impacted by their unfortunate
presence.

5.3 Participant Recruitment

We used convenience sampling by recruiting volunteers
from our personal networks and local software develop-
ment companies. As our personal networks mostly con-
sisted of developers with little professional experience, we
also used purposive sampling by speciﬁcally recruiting
participants with more professional experience. Snowball
sampling was also utilized by encouraging participants to
pass on the participation invite. The sample used for the

6.2 The Experiment

This section presents the estimates and some carefully
selected posterior samples produced by the ﬁnal models
for each outcome. Four outcome models describing how
likely the developers were to implement utility methods,

11. Available at https://bwtse.github.io/Analysis, source available
at https://github.com/BWTSE/Analysis/tree/v1.5 and https://doi.
org/10.5281/zenodo.7011982.

12. Diff

showing

resolution:

https://github.com/BWTSE/

Scenarios/compare/mainstudy-v1...mainstudy-v2

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

9

add documentation to their code, complete the task, and
the time it took to complete the task, are not presented
in detail in this section as they showed no signiﬁcant ef-
fects. Furthermore, including all the intermediary models
described in Sect. 5.1.8 would not be feasible. Instead, we
have provided a replication package that allows thorough
examination and reproduction of all our models and their
development: https://bwtse.github.io/Analysis13

Interpreting the results
The predictors discussed in this section are factors
that showed some predictive power on an outcome.
The magnitude of the inﬂuence of a predictor on the
outcome is described by a β (parameter) estimate. In
Bayesian data analysis, the β estimate is not a single
value but a probability density.

When interpreting the results, the mass of the β
distributions in relation to zero is important as it
represents the likelihood of a parameter having an
effect. However, to infer anything about the size of
that effect, the outcome distribution is vital as it shows
the effects on the same scale as the data. This allows
us to evaluate the practical effects.

All

models

include

β

parameters

for

as

compulsory

a varying intercept
(session). The β parameter

high_debt_version and programming_-
experience as well
for
for
each participant
high_debt_version is
examining
the effects produced by the existence of TD is the point of
our study. The parameter for programming_experience
was included as we want some insight into what effect the
skew in our sample towards more junior developers might
have on our result. We did not consider any interaction
effects and did not add any other grouping factors than the
participant identiﬁer since they would entail a high risk of
overﬁtting with our relatively small sample size.

as

We ﬁtted all ﬁnal models to the full data set, including
participants who only completed one of the assigned tasks.
Excluding the participants who did not complete both tasks
made sampling easier as it assured that the data set was
balanced but could also introduce a bias in the analysis.
Therefore, we chose to ﬁt the ﬁnal models with all available
data after conﬁrming that the models could sample well
using the complete data set.

6.2.1 Logic Reuse

Table 2 (model 1 & 2) as well as Figs. 3 and 4 show that
the high_debt_version predictor has a signiﬁcant effect
on the outcome with well over 95% of the β estimate
probability mass on the negative side of zero. The β estimate
distribution for the programming_experience predictor
is centered close to zero with signiﬁcant probabilistic weight
on both sides, indicating no or minimal effect. This in-
formation alone indicates that a high debt density in the
preexisting codebase induces developers to reuse less. In

13. Source available at https://github.com/BWTSE/Analysis/tree/

v1.5 and https://doi.org/10.5281/zenodo.7011982

Fig. 3: β estimate distributions of the model describing reuse
of the constructor logic. The shaded region marks 95% of the
density and the vertical line marks the median.

Fig. 4: β estimate distributions of the model describing reuse
of the validation logic. The shaded region marks 95% of the
density and the vertical line marks the median.

contrast, the developers’ professional programming experi-
ence scarcely affects the amount of reused code.

The outcome distribution shown in Fig. 5 offers addi-
tional insights into the effects of the predictors. It shows
a clear difference in the outcome depending on the TD
level of the system. The effect appears to persist for all
levels of professional programming experience. The model
estimates that developers with 10 years of professional
programming experience are 102% more likely to duplicate
logic in the high debt version of the system. The correspond-
ing number for those with no professional programming
experience is 113%. Given that this model was developed
in accordance with the restrictions arrived at in our causal
analysis (Sect. 5.1.7), it is possible to make causal inferences
regarding the effects of TD level (but not experience level).

6.2.2 Variable Naming

3)
Table
high_debt_version

(model

2

and Fig.
predictor

6
has

show that

the
signiﬁcant

a

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

10

ht

TABLE 2: Population level effects. The intercept estimates correspond to the baseline of the measurements (with all
predictors set to zero, or true in the case of boolean values). Models of the cumulative family, has multiple intercepts where
intercept[1] is the logarithmic chance of observing the ﬁrst outcome rather than the remaining. intercept[2] is the
chance of observing one of the ﬁrst two outcomes rather than the remaining, and so on. The β estimates correspond to how
much a parameter inﬂuences the outcome.

Model
(1) Validation logic reuse

(2) Constructor logic reuse

(3) Variable naming

(4) Introduced SonarQube issues

(5) System Quality Rating (cumulative)

(6) Self-reported submission quality (cumulative)

mean
Parameter
intercept
−0.16
β-high_debt_version:false
−1.79
β-programming_experience
0.26
intercept
−0.38
β-high_debt_version:false
−1.63
β-programming_experience
0.31
intercept
1.52
β:high_debt_version:false
2.48
β:programming_experience
0.14
intercept
0.73
β:high_debt_version:false
−0.80
β:programming_experience
−0.23
intercept[1]
−2.08
intercept[2]
−0.59
intercept[3]
0.30
intercept[4]
0.81
intercept[5]
2.07
intercept[6]
4.21
β:high_debt_version:false
1.41
β:programming_experience
−0.52
intercept[1]
−4.81
intercept[2]
−3.53
intercept[3]
−1.46
intercept[4]
1.43
intercept[5]
2.17
intercept[6]
3.12
β:var_naming_copied:good
0.19
β:var_naming_new:good
−0.04
β:reused_logic_validation:false −1.31
β:equals_exists:false
−0.17
β:sonarqube_issues
0.09
β:documentation:incorrect
−0.19
β:documentation_none
−0.33

sd
0.57
0.66
0.47
0.58
0.65
0.48
0.50
0.57
0.46
0.30
0.37
0.23
0.54
0.40
0.40
0.41
0.47
0.74
0.47
0.27
1.25
1.07
0.98
0.99
1.02
1.11
0.66
0.77
0.66
0.56
0.31
0.67
0.61

l-95% CI
−1.30
−3.12
−0.67
−1.53
−2.95
−0.66
0.65
1.41
−0.75
0.15
−1.53
−0.68
−3.21
−1.41
−0.50
0.01
1.16
2.92
0.48
−1.07
−7.39
−5.71
−3.43
−0.48
0.20
0.99
−1.10
−1.53
−2.62
−1.25
−0.54
−1.51
−1.53

u-95% CI
0.96
−0.54
1.21
0.74
−0.39
1.24
2.62
3.64
1.09
1.32
−0.08
0.23
−1.07
0.17
1.07
1.62
3.04
5.77
2.33
−0.01
−2.48
−1.45
0.45
3.47
4.24
5.41
1.52
1.46
−0.03
0.97
0.68
1.12
0.91

Fig. 5: Outcome distribution of the model describing reuse,
separated by high and low debt versions for three levels of
professional programming experience (0, 10 & 40 years).

effect on the outcome with well over 95% of
the
probability mass on the right side of zero. Conversely,
the programming_experience predictor’s β estimate is
centered around zero, indicating no or minimal effect. These
results imply that a high debt density in the preexisting
codebase causes developers to use non-descriptive variable

Fig. 6: β estimate distributions of the model describing vari-
able naming. The shaded region marks 95% of the density
and the vertical line marks the median.

names and that the developers’ professional programming
experience has little to no effect on the descriptiveness of
their variable names.

The distribution, Fig. 7, shows a noteworthy difference in
outcome depending on the level of high_debt_version
predictor. The professional programming experience of the
individual is not estimated to affect the outcome noticeably.
Figure 8 shows the distribution of the estimated rate of
good variable naming for a developer with 10 years of pro-
fessional programming experience introducing 10 variables.
According to the depicted sample, a developer is 458% more

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

11

Fig. 7: Outcome distribution of the model describing the
rate of good variable names introduced, separated by high
and low debt versions as well as years of professional
programming experience.

Fig. 9: β estimate distributions of the model describing the
number of SonarQube issues introduced. The shaded region
marks 95% of the density and the vertical line marks the
median.

Fig. 8: Outcome distribution of the model describing vari-
able naming. The histogram shows the estimated probability
of each outcome (i.e., number of descriptive variable names)
when a developer with 10 years of professional experience
introduces 10 new variables

likely to use a non-descriptive variable name whenever they
introduce a variable in the presence of TD. Given that this
model was developed in accordance with the restrictions
arrived at in our causal analysis (Sect. 5.1.7), it is possible to
make causal inferences regarding the effects of TD level (but
not experience level).

6.2.3 SonarQube Issues
The β estimates presented in Table 2 (model 4) suggest that
the debt level of the system has a notable effect on the
number of SonarQube issues introduced by the subject. As
demonstrated by Fig. 9, zero is well outside the 95% credible
interval of the estimated high_debt_version parameter
distribution. The programming_experience β estimate is
centered closer to zero, but the uneven distribution suggests
that it could potentially have some effect.

The outcome distributions depicted in Fig. 10 show a
moderate effect of the debt density of the system on the
number of SonarQube issues introduced by the participant.
The, somewhat unreliable, estimated effect of professional
programming experience generates noticeable differences

Fig. 10: Outcome distribution of the model describing the
number of SonarQube issues, separated by high and low
debt versions as well as years of professional programming
experience.

in the prediction for various experience levels, with more
experience being expected to introduce fewer SonarQube
issues. The effects shown by the graph correspond to de-
velopers on average introducing 117% more issues in the
high debt version. Given that this model was developed
in accordance with the restrictions arrived at in our causal
analysis (Sect. 5.1.7), it is possible to make causal inferences
regarding the effects of TD level (but not experience level).

6.2.4 System Quality Rating

2

5)

(model

and Fig.

shown by Table

As
11,
this model estimates considerable effects of TD level
(high_debt_version) and professional programming ex-
perience on the way subjects rated the the system in terms
of quality (maintainability). In both cases, the 95% credible
intervals do not cross zero. These results show that par-
ticipants tended to rate the high TD as worse and more
experienced programmers also, on average, give all our
systems a lower rating.

The outcome distributions differ noticeably between the
high and low debt cases in both our low experience (Fig. 12)
and high experience (Fig. 13) cases. The average difference
is about one unit on the Likert scale.

Figure 14, showing the distribution of outcome differ-
ences, allows us to estimate that a developer with 10 years of
experience is 197% more likely to rate the high debt system

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

12

Fig. 14: Distribution of the estimated differences in system
rating outcome with respect to debt level. That is, the dis-
tribution of the outcome under the assumption of high debt
minus the outcome under the assumption of low debt. The
graph is separated into 3 experience levels and the vertical
lines represent the medians.

Fig. 11: β estimate distributions of the model describing the
subjects’ rating of the systems quality (maintainability). The
shaded region marks 95% of the density and the vertical line
marks the median.

Fig. 12: Outcome distribution of the model describing sys-
tem rating in terms of quality (maintainability) with pro-
gramming experienced ﬁxed to 3 years, and separated by
debt level of the system. The vertical lines represent the
means.

Fig. 13: Outcome distribution of the model describing sys-
tem rating in terms of quality (maintainability) with pro-
gramming experienced ﬁxed to 25 years, and separated by
debt level of the system. The vertical lines represent the
means.

Fig. 15: β estimate distributions of the model describing how
participants rate their own work. The shaded region marks
95% of the density and the vertical line marks the median.

as worse than the low debt system, as opposed to the other
way around.

6.2.5 Self-reported Submission Quality

Table 2 (model 6) and Fig. 15 show a variety of
the ef-
small effects with high uncertainty. However,
fect of reused_logic_validation:false is signiﬁcant
enough that the 95% credible interval does not cross zero,
indicating that the amount of duplication is strongly linked
to how participant rated their own work.

Further insight is offered by Fig. 16, which depicts poste-
rior distributions for two submissions, one which we would
classify as bad and one we would classify as good. Although
their peak is quite similar and centered around a neutral
rating, the bad submission is much more likely to be given
a bad rating, while the good submission is more likely to
receive a high rating.

Figure 17 shows the distribution of differences between
outcomes generated under the assumption of a bad submis-
sion and good submission. In the simulated case, the model

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

13

Fig. 16: The outcome distribution of the model describing
the participants’ rating of their own work in terms of main-
tainability, simulated for what we consider to be a bad and
good submission respectively. The vertical lines represent the
means.

Fig. 17: The distribution of differences between the partici-
pants’ quality rating of their own work, simulated for what
we consider to be a bad and good submission. The vertical
lines represent the means. Difference as: bad submission
rating − good submission rating.

estimates that participants are 114% more likely to rate the
bad submission as worse than they were to rate the good
submission as worse.

6.3 The Interviews

The data set forming the basis of our thematic analysis
were ﬁeld notes taken during six follow-up interviews as
well as additional comments received via email or other
text messages from a further four participants. This section
presents the results of that analysis.

We arranged the themes derived through this process
into the thematic map that constitutes Fig 18. A connection
between two themes represents them appearing together in
the interview material. The manner of their connection may
differ between interviews.

The oval themes represent the ones that we enforced as
part of our deductive approach. They are the focal points
of our inquiry, the TD density or quality (maintenance) of
the system, and the same properties of the new code they
produce.

The subjects were clearly bothered by the issues in the
high TD version. Some complained that the short and non-
descriptive variable names made the system difﬁcult to
understand, which affected their productivity. While ex-
pected, it is a solid indication that bad variable names are
a good example of TD. We also found that some expressed
a sense of discouragement or loss of enthusiasm in relation
to system quality exempliﬁed by comments such as “It was
such a drag with all the bad variable names . . . //. . . I almost
didn’t ﬁnish the task”.

Fig. 18: A map of the themes produced by our thematic
analysis. The oval nodes represent the themes that we had
decided should be included before starting the thematic
analysis. Nodes connected by vertices occurred together in
the interview material.

Refactoring was a topic frequently brought up and is
very much a topic of interest in the context of TD propa-
gation. The task descriptions explicitly stated that subjects
were free to alter other parts of the system as they saw ﬁt,
and most of our interviewees had taken advantage of that
opportunity. Interestingly several of them connected system
quality to their decision to refactor, while some argued that
refactoring a system that was in such a sorry state was not
worth their time, others expressed that the obvious faults
were what prompted them to start refactoring. One said that
the quality issues caused him to go on a “refactoring spree”
and another that the noticeable faults made them examine
the system more closely, in search of more quality issues in
need of attention.

Views on refactoring varied signiﬁcantly, some older
and more experienced developers favored an approach
where refactoring efforts are mainly relegated to speciﬁcally
dedicated time-slots: “You should devote speciﬁc sprints
to refactoring and not mix it with feature development”.
In their view, mixing refactoring work with new feature
development results in productivity losses and results in
individual developers exposing the project to the risks they
associate with refactoring (instead, they favor team delib-
erations regarding signiﬁcant refactoring decisions). Others
favored a more ﬂexible approach where they ﬁx problems as
they come across them, though admitting that “going down
the rabbit hole” (having to follow a seemingly never-ending
trail of interdependent issues) is a deﬁnite risk, especially
when dealing with older systems whose architecture is
reminiscent of a “ball of yarn”. Finally, high test quality and
coverage were mentioned as a way of enabling more ag-
gressive refactoring strategies by mitigating the associated
risks.

Several participants noted that they had trouble deciding
on how to name the variables in their new class when work-
ing on the high debt system. While they recognized that the
current naming scheme was terrible, using a different one
for their new variables would make the code less uniform,
which could potentially be more confusing. One said that

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

14

“it’s important to follow the style of the code already there
to reduce bugs.” The optimal solution, they agreed, would
be to ﬁx all variable names (which some actually did),
although one expressed regret over not having done it. This
participant went on to admit that their discouragement, as
a result of the quality issues, had made them focus on just
getting the tests to pass as soon as possible to “be done with
it”.

Our impression is that those who volunteered to be inter-
viewed were more enthusiastic about the project, generally
put more effort into their submissions than the average
subject, and were excited to discuss the qualities of their
particular solution.

7 DISCUSSION

Our results concerning the introduction of further technical
debt (TD) in the form of logic duplication, bad naming
of newly created variables, and other issues discovered
through the use of SonarQube all showed considerable
effects:

• Developers are 102% more likely to duplicate exist-
ing logic in our systems with high levels of TD14
(Sect. 6.2.1).

• Developers are 458% more likely to assign a variable
a non-descriptive name in systems with high levels of
TD14 (Sect. 6.2.2).

• Developers introduce 117% more SonarQube issues in

our systems with high levels of TD14 (Sect. 6.2.3).
All of these were established by investigating 95% credi-
ble intervals. Taken together, it is very improbable that they
are all false positives. Additionally, the results of our causal
analysis (see Sect. 5.1.7 show that we can infer the causality
of these relationships, i.e., pre-existing TD is the cause of the
effects.

Finding 1 (RQ1): Existing TD increases the like-
lihood of developers introducing new TD when
extending a system, even in cases where it is not
necessary to do so.
Finding 2 (RQ1.1): Existing TD of a certain type
increases the likelihood of developers introducing
new TD of that type when extending a system, even
in cases where it is not necessary to do so.

We found no noticeable effect of TD on a subject’s
propensity to include equals() and hashcode() meth-
ods for the new classes they constructed. Similarly, we
found no signiﬁcant effect of pre-existing TD on the like-
lihood of participants correctly documenting their new code.
The limitations of our experiment design, i.e., bad vari-
able names and code duplication coinciding, make it im-
possible for us to discern the effects of the former from the
latter. However, the estimated impact on the introduction
of general code-smells suggests that broken windows theory
(BWT) effects are not limited to within speciﬁc types of
TD items. That is, pre-existing bad variable names do not

14. Effect estimated for a developer with 10 years of professional
programming experience that is working on the tasks and systems
provided in this study

just induce the developer to implement additional poorly
named variables but also other examples of TD. This ﬁnding
is interesting because it suggests that developers mimicking
previous work is not a sufﬁcient explanation of BWT effects
on its own.

Finding 3 (RQ1.2): Mimicry of existing instances of
TD is not, alone, a sufﬁcient explanation of BWT
effects in software engineering.

During the follow-up interviews, participants did ex-
press that the ﬂaws did make them less enthusiastic about
the task at hand. One went as far as saying that they
“hardly had the will to ﬁnish the task” and merely made
sure the tests passed (they were then pleasantly surprised
that the system they were assigned in their second task
was of signiﬁcantly higher quality). This is in line with
previous ﬁndings of Besker et al. [6] and Olsson et al. [23].
Interestingly, and seemingly at odds with this statement,
the results indicate that debt level does not appear to have
signiﬁcantly affected a subject’s propensity to drop out of
the experiment.

However, given the comparatively large effects on code
reuse (Finding 1) and variable naming (Finding 2), it is
likely the case that mimicry is a signiﬁcant driver of TD
propagation in general. One participant admitted that “you
think that someone else thought it should be this way, and
then you follow in the same tracks” and several others
raised the issue of code uniformity. While it may be clear that
a system contains issues, if the defects are systematic, it may
not necessarily be the case that breaking that uniformity
is preferable. For example, using a different (but better)
variable name to describe something already existing in
adjacent classes could be more confusing than a bad (but
consistent) naming scheme. We did anticipate this, and it is
why we discerned new variables from copied variables. How-
ever, although there is no practical advantage to mimicking
the bad naming scheme for new variables, it may be that
some subjects preferred the aesthetics of consistently short
and non-descriptive variables names.

Generally, the predictive values of the background fac-
tors gathered by our survey were small and uncertain
enough that we could safely exclude them from the ﬁnal
models. This, of course, could be a symptom of our rel-
atively low sample size (N = 51). Years of professional
programming experience, which we included as a predictor
in the ﬁnal version of all models measuring TD outcomes,
did show a small effect in the expected direction in each
case (i.e., more experienced developers introduce less TD
on average). However, it is critical to note that we only ever
investigated background factors in relation to the amount
of TD introduced, but not the effect of background factors
on susceptibility to the BWT effects. It could be that expe-
rienced developers are less likely to be affected by existing
TD, but that would require the inclusion of interaction ef-
fects and our sample size could not hope to support such
estimates to any degree of certainty.

Given that the code in a high TD system is both longer
and harder to read, we might expect participants to spend
more time in those systems. However, the results indicate
no signiﬁcant effect of TD on the amount of time the partic-

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

15

ipants allocated towards completing their task. Perhaps this
is an indication that developers are averse to compensating
the productivity loss induced by TD with additional time,
resulting in the loss of quality. This is further corroborated
by some comments from our interviews, such as “I’ll just
run my tests and be done with it” (when discussing their
effort put into the high TD system).

Our analysis of the participants’ evaluation of their work
(Sect. 6.2.5) reveals a tangible correlation between the way
a subject rated their submitted changes in terms of quality
(maintainability) and some of our various measures of TD.
This correlation suggests that subjects were not completely
oblivious regarding the TD they had introduced. Besker et
al. found that developers often felt forced to introduce new
TD due to existing TD, which implies an awareness of their
TD creation. However, we presented participants with tasks
that could feasibly be solved without introducing further TD,
i.e., they were not forced to do so. Our results suggest that
developers are somewhat aware of their introduction of TD
even under such circumstances. From a practical perspec-
tive, this may be good news; it is likely easier to achieve
change in a conscious rather than unconscious behavior.

Finding 4: Developers appear to be, at least partially,
aware of their introduction of TD.

Although we argue that our results have answered the
question of if there is ever a BWT effect, the next question
may be: “is there ever not a BWT effect in software engi-
neering?” We suspect that such exceptions are possible, e.g.,
if a developer is not aware of the existence of a more optimal
solution that would reduce their maintenance workload. In
other words, could they identify a broken window, having
never seen one that is unbroken? The broken window of the
BWT is a message indicating general indifference; it stands
to reason that for a true BWT effect to occur, the disorder
must be apparent to the observer.

Given that we ﬁnd convincing evidence of BWT effects,
companies and software practitioners should continue striv-
ing toward keeping the TD density of their systems low. This
is by no means a new insight; it has been advocated for by
pioneers of the software industry for many years. However,
this study is the ﬁrst to empirically validate the claims of
the advocates of the BWT and corroborate their anecdotal
evidence. Finally, we believe our results are a signiﬁcant
contribution toward establishing the generalizability of the
BWT.

7.1 Suggestions for Future Research

At the core of the BWT is that the broken window itself is not
the primary cause of the undesired BWT effects; it merely
communicates an atmosphere of neglect and indifference
that indicates that there are no repercussions to the behavior
that “broke the window”.

The state of the (proverbial) window is just one such
indication, although perhaps the most important one. The
possibility of repercussions can also be communicated by
the context of the window. The broken windows may still be
there, but certain practices and circumstances may inoculate
developers against their effects. Examples of such factors

could be peer reviewing, continuous integration and ac-
knowledgement of TD issues (such as a “ﬁx me” comment).
Examining such contextual factors would be the next major
step towards understanding the BWT of software engineer-
ing. This could be challenging to accomplish in a controlled
experimental setting; it might require a longitudinal ﬁeld
experiment.

Furthermore, Wilson and Kelling [9], as well as Hunt and
Thomas [5], describe a long-term cultural deterioration as a
result of BWT effects. While our results support the central
mechanism of the BWT, we can not conﬁrm whether or not
“broken windows” have a lasting impact on the culture of a
project group, e.g., if a team is assigned to work with high
TD systems for some time, will that affect their performance
when switching back to a system of low TD density? This
is a question we would like to see answered by further
research.

Several of the studies that came up during our related
literature review (Sect. 4) presented models of TD that did
not even entertain the possibility of BWT effects. Rather,
they exclusively discuss the dynamic of TD forcing new TD
implementation. We deem our results convincing enough
that TD researchers should consider them in future models.
Finally, we would welcome attempts to replicate the
results of our experiment and variations of it using different
systems and other examples of TD, perhaps with a sample
size sufﬁcient to investigate interaction effects and more than
two levels of TD density. To facilitate any such efforts, we
have made all our research materials publicly available.15

7.2 Threats to Validity

This section discusses threats to the validity of our study
and is divided into four parts as per the recommendations
of Wohlin et al. [54]

7.2.1 Internal Validity

The choice of a simulated experiment allows us to achieve
a high internal quality as we measure the effect of a speciﬁc
treatment in an environment we control. We also took
multiple additional measures to ensure that nothing other
than the TD itself inﬂuenced the developers to take different
actions in the two different tasks they were assigned.

We designed the experiment to ensure that it was al-
ways possible to measure the difference between a subject’s
performance in a high debt system and a low debt system,
reducing the inﬂuence of factors that we could not control.
These factors include, but are not limited to, the time of
day of the experiment, which hardware they used, and their
physical environment.

Another threat to internal validity is learning effects.
However, randomization of the order of the scenarios and
debt levels should have neutralized the impacts of any such
effects on our results.

In an isolated experiment such as this, it could have
been that the subjects were not particularly meticulous in
their work since they did not care about their performance.
Conversely, in practice, the opposite is more often the case.
In experiment and survey research, respondents frequently

15. https://github.com/BWTSE

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

16

elicit social desirability bias. That is, they may answer or per-
form in the manner that they think is socially desirable [55].
We would argue that since low TD code would be desirable,
the subjects are more likely to have overperformed rather than
the opposite.

The use of a fully automated research tool ensured
that we could not inﬂuence the subject in any way while
participating in the experiment. The research tool presented
participants with the same interface, information, and task
description no matter whether they were coding in the high
debt system or the low debt system. We also denied any
questions from participants during their participation.

7.2.2 External Validity

Since we had to rely on volunteering subjects, i.e., some-
thing more akin to convenience sampling rather than random
sampling, there is reason to doubt that the sample was
fully representative of the population. However, the fact that
background factors showed little predictive power indicates
that the skew in the sample is unlikely to have affected our
results.

Another concern regarding external validity is how rep-
resentative our system and research environments were
of real systems and natural environments; there are some
disparities, e.g., the lack of symbol searching in the environ-
ment and the size of the scenarios. The contrived setting of
this study could impact the generalizability of our ﬁndings.
But, as noted by Stol and Fitzgerald [40], there is an inherent
trade-off between the generalizability of a study conducted
in a more natural environment and the precision with which
measurement of behavior can be achieved in a study using
a more controlled and contrived setting. The chosen research
strategy allowed us to measure how high TD levels affect
the behavior of developers, with, we would argue, high
precision. This would not have been possible in a natu-
ral setting. The qualitative part of the study also helped
improve the generalizability of the study as it included a
question about BWT in a neutral setting, where multiple
participants expressed their support of the theory.

Although the existence of BWT effects indicated by our
results is generalizable, the estimated magnitudes of them
are still quite speciﬁc to our system and may not apply to
other contexts. The levels of our independent variable are
high and low; this is not sufﬁcient to construct a general model
of the BWT in software engineering.

7.2.3 Construct Validity

There is a multitude of slightly differing deﬁnitions and
classiﬁcations of TD; hence there may be some questions
as to whether our dependent variables really measure TD.
Similarly, the issues that we introduced to our scenarios
might not, by some standard, constitute TD. However, we
would argue that they do qualify under practically every
deﬁnition that we have come across while researching the
subject. This is further supported by the fact that subjects
noticed the defects we had introduced and agreed with our
assertion that they lower maintainability, i.e., they tended
to rate the high TD systems as worse in terms of “quality
(maintainability)” (Sect. 6.2.4) and rated their own work
as worse when it had more TD according to the chosen
metrics (Sect. 6.2.5). In the follow-up interviews, they more

frequently raised the bad variable names as an issue, but
the odd participant also noted the code duplication. Taken
together, we would argue that this validates our choice of
TD representations.

Although we tried to keep our research questions ‘se-
cret’, some participants may have guessed that we were
investigating something related to the introduction of TD.
This could have caused them to act in accordance with their
preconceptions of how TD is introduced. While this is not
exactly hypothesis guessing, it could have had a similar
effect. One of the measures taken to avoid this was the
placement of all survey questions relating to TD after both
tasks to ensure that those questions could not affect the
measurements.

The fact that subjects were able to drop out without
completing the tasks could have masked the effects of the
debt level. However, the results of our analysis of drop-out
behaviors show no signiﬁcant correlation between debt level
and a participant’s propensity to forgo their assignment.

7.2.4 Conclusion Validity

Given that a relationship was found between a preexisting
high TD level and several of the outcomes measuring differ-
ent kinds of TD using 95% credible intervals, there is reason
to believe the validity of our conclusion is high.

We performed three out of the four types of triangulation
suggested by Miller [56] to improve the conclusion validity:
Methodological triangulation The cross-validation of
results obtained through the application of two distinct
research methodologies, one quantitative and one qual-
itative, improves the validity of our conclusions.
Researcher triangulation Two of the authors performed
the manual data extraction processes on all submis-
sions independently. Results were compared, double
checked, and any inconsistencies were resolved. This
practice helped us reduce any errors or biases intro-
duced by us as researchers.
Data triangulation The usage of multiple sampling
strategies, as well as the collection of data over a span
of about 30 days, ensured some degree of data trian-
gulation. The sampling strategies included snowball
sampling where participants were encouraged to pass
on the participation invite, convenience sampling by
recruiting participants from our personal networks, and
purposive sampling by actively seeking out partici-
pants with more experience.
Several other studies have found, through interviews,
that preexisting TD causes new TD (Sect. 4). While those
ﬁndings do not point towards the existence of BWT effects
speciﬁcally, they could be partially explained by BWT ef-
fects. Furthermore, we have found no literature contradict-
ing the BWT in software engineering. In summary, while the
literature might not corroborate our ﬁndings, it is at least
aligned with them.

Any statistical analysis rests on a number of assumptions
regarding the underlying distributions. An advantage of
Bayesian data analysis is that the model development process
makes those assumptions explicit. However, since there is
no widely used standard governing this process, subjective
assessments could have impacted the results [51]. While we

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

17

have taken great care to create models that fairly portray the
data, we welcome any scrutiny of our process through the
examination of our replication package.16

8 CONCLUSION

For over twenty years, distinguished members of the soft-
ware engineering community have claimed that the broken
windows theory (BWT) is as applicable to code as its architects
would argue it is to crime. This study aimed to empirically
evaluate these claims that were previously supported exclu-
sively by anecdotal evidence.

Interpreting technical debt (TD) as the metaphorical broken
windows, we designed an experiment that tasked subjects
with extending small Java systems with novel functionality.
Unbeknownst to them, we had purposely riddled half of
the systems with TD in the form of bad variable names and
code duplication. A diverse group of 29 participants, some
still students, others with more than 30 years of industry
experience, submitted their solutions using a uniform de-
velopment environment of our design, the RobotResearcher.
From the resulting data set of 51 distinct solutions, we
extracted several measures of TD, some through carefully
designed manual procedures and others using the static
code analyzing tool SonarQube. Our analysis of these met-
rics revealed considerable effects of existing TD on the sub-
jects’ propensity to reimplement, rather than reuse function-
ality, choose poor names for their variables, and introduce
other issues identiﬁed by SonarQube.

The fact that three distinct effects were identiﬁed (on
the 95% credible interval), is substantial evidence that the
dynamics of the BWT apply to the software development
context. The resulting increase in issues of types other than
those that we had deliberately introduced suggests that the
effects are not exclusively the result of mimicry. Addition-
ally, our ﬁnding that subjects tended to rate their work lower
when it introduced more TD indicates that they were, at
least partially, aware of the shortcuts they had taken.

We further examined the phenomenon through follow-
up interviews with volunteering subjects which, through
thematic analysis, produced results consistent with the ﬁnd-
ings of our quantitative analysis.

While our ﬁndings lend credence to the claims by pro-
gramming luminaries like Hunt and Thomas, we can not
conﬁrm their assertion that the long term effects of the BWT
dynamic is, unless actively managed, an inevitable spiral
towards oblivion. Nor can we speak to the effects on project
culture or the potentially mitigative effects of certain de-
velopment practices, but we hope that future studies can
explore these exciting lines of inquiry.

ACKNOWLEDGMENTS

We want to thank the participants for their time, Jesper Ols-
son for inspiring us to undertake this study, and ﬁnally
Felicia Wallin who assisted with the creation of graphical
assets.

The computations were enabled by resources provided
by the Swedish National Infrastructure for Computing
(SNIC), partially funded by the Swedish Research Council
through grant agreement no. 2018–05973.

Part of this research was funded by Marianne & Marcus

Wallenberg Foundation (2017.0071).

REFERENCES

[1] A. Martini, T. Besker, and J. Bosch, “Technical debt tracking:
Current state of practice,” Science of Computer Programming,
[Online]. Available: https:
vol. 163, pp. 42–61, 10 2018.
//doi.org/10.1016/j.scico.2018.03.007

[2] A. Ampatzoglou, A. Ampatzoglou, A. Chatzigeorgiou, and
P. Avgeriou, “The ﬁnancial aspect of managing technical
debt: A systematic literature review,” Information and Software
Technology, vol. 64, pp. 52–73, 8 2015.
[Online]. Available:
https://doi.org/10.1016/j.infsof.2015.04.001

[3] A. Martini and J. Bosch, “The danger of architectural technical
-
debt: Contagious debt and vicious
12th Working IEEE/IFIP Conference on Software Architecture,
WICSA 2015, pp. 1–10, 2015.
[Online]. Available: https:
//doi.org/10.1109/WICSA.2015.31

circles,” Proceedings

[4] ——, “On the interest of architectural technical debt: Uncovering
the contagious debt phenomenon,” Journal of Software: Evolution
and Process, vol. 29, no. 10, pp. 1–18, 2017. [Online]. Available:
https://doi.org/10.1002/smr.1877

[5] A. Hunt and D. Thomas, The pragmatic programmer: From jour-
Boston, (MA), USA: Addison-Wesley

neyman to master, 1st ed.
Professional, 1999.

[6] T. Besker, H. Ghanbari, A. Martini, and J. Bosch, “The inﬂuence of
technical debt on software developer morale,” Journal of Systems
and Software, vol. 167, p. 110586, 9 2020. [Online]. Available:
https://doi.org/10.1016/j.jss.2020.110586

[7] T. Besker, A. Martini, and J. Bosch, “Software developer
productivity loss due to technical debt—A replication and
extension study examining developers’ development work,”
Journal of Systems and Software, vol. 156, pp. 41–61, 2019. [Online].
Available: https://doi.org/10.1016/j.jss.2019.06.004

[9]

[8] P. G. Zimbardo, “The human choice: Individuation, reason, and
impulse, and chaos,” Nebraska
order versus deindividuation,
symposium on motivation, pp. 237–307, 1969. [Online]. Available:
https://stacks.stanford.edu/ﬁle/gk002bt7757/gk002bt7757.pdf
J. Q. Wilson
The
Monthly,
https://web.archive.org/web/20210522180623if /https:
//www.theatlantic.com/magazine/archive/1982/03/
broken-windows/304465/

and G. L. Kelling,
neighborhood
3

“Broken windows:
Atlantic
Available:

[Online].

safety,”

29–38,

police

1982.

and

The

pp.

[10] H. Corman and N. Mocan, “Carrots,

sticks and broken
windows,” National Bureau of Economic Research, Cambridge,
(MA), USA, Tech. Rep.
[Online]. Available:
1,
https://doi.org/10.3386/w9061

2002.

7

[11] D. Thacher, “Order maintenance reconsidered: Moving beyond
Journal of Criminal Law and
strong causal
Criminology, vol. 94, no. 2, p. 381, 2004. [Online]. Available:
https://doi.org/10.2307/3491374

reasoning,” The

[12] R.

J. Sampson and S. W. Raudenbush, “Systematic social
in
of Sociology, vol.
[Online]. Available: https:

observation of public spaces: A new look at disorder
urban neighborhoods,” American Journal
105, no. 3, pp. 603–651, 1999.
//doi.org/10.1086/210356

[13] K. Keizer, S. Lindenberg, and L. Steg, “The spreading of disorder,”
Science, vol. 322, no. 5908, pp. 1681–1685, 2008. [Online]. Available:
https://doi.org/10.1126/science.1161405

[14] A. A. Braga, B. C. Welsh, and C. Schnell, “Can policing
review and meta-
crime? A systematic
disorder
analysis,” Journal of Research in Crime and Delinquency, vol. 52,
no.
[Online]. Available: https:
2015.
567–588,
//doi.org/10.1177/0022427815576576

4, pp.

reduce

7

16. Available at https://bwtse.github.io/Analysis, source available
at https://github.com/BWTSE/Analysis/tree/v1.5 and https://doi.
org/10.5281/zenodo.7011982.

[15] R. M. Krauss,

J. L. Freedman, and M. Whitcijp, “Studies
of littering,” Journal of Experimental Social psychology, vol. 14,
pp. 109–122, 1978. [Online]. Available: https://doi.org/10.1016/
0022-1031(78)90064-1

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

18

[16] R. B. Cialdini, R. R. Reno, and C. A. Kallgren, “A focus
theory of normative conduct: Recycling the concept of norms to
reduce littering in public places,” Journal of Personality and Social
Psychology, vol. 58, no. 6, pp. 1015–1026, 1990. [Online]. Available:
https://doi.org/10.1037/0022-3514.58.6.1015

[17] R. C. Martin, Clean code — A handbook of agile software craftmanship.

Upper Saddle River, (NJ), USA: Prentice Hall, 2014, vol. 1, no. 1.

[18] T. Sharma, G. Suryanarayana, and G. Samarthyam, “Challenges to
and solutions for refactoring adoption: An industrial perspective,”
IEEE Software, vol. 32, no. 6, pp. 44–51, 11 2015. [Online]. Available:
https://doi.org/10.1109/MS.2015.105

[19] W. Cunningham, “The WyCash portfolio management system,” in
Addendum to the proceedings on object-oriented programming systems,
languages, and applications, vol. F1296, October 1992, pp. 29–30.
[Online]. Available: https://doi.org/10.1145/157709.157715

[20] Manifesto
2021-05-21.
20210521013723/http://agilemanifesto.org/

development. Accessed:
for
[Online]. Available: https://web.archive.org/web/

software

agile

[21] N. Brown, I. Ozkaya, R. Sangwan, C. Seaman, K. Sullivan,
N. Zazworka, Y. Cai, Y. Guo, R. Kazman, M. Kim, P. Kruchten,
E. Lim, A. MacCormack, and R. Nord, “Managing technical debt in
software-reliant systems,” in Proceedings of the FSE/SDP workshop
on Future of software engineering research. ACM Press, 2010, p. 47.
[Online]. Available: https://doi.org/10.1145/1882362.1882373
[22] P. Avgeriou, P. Kruchten, I. Ozkaya, and C. Seaman, “Managing
technical debt in software engineering (Dagstuhl Seminar 16162),”
Dagstuhl Reports, vol. 6, no. 4, pp. 110–138, 2016.
[Online].
Available: https://doi.org/10.4230/DagRep.6.4.110

[23] J. Olsson, E. Risfelt, T. Besker, A. Martini, and R. Torkar,
“Measuring affective states from technical debt,” Empirical
Software Engineering, vol. 26, no. 5, p. 105, 2021.
[Online].
Available: https://doi.org/10.1007/s10664-021-09998-w

[24] N. S. Alves, T. S. Mendes, M. G. De Mendonc¸a, R. O. Spinola,
F. Shull, and C. Seaman, “Identiﬁcation and management of
technical debt: A systematic mapping study,” Information and
Software Technology, vol. 70, pp. 100–121, 2016. [Online]. Available:
https://doi.org/10.1016/j.infsof.2015.10.008

[25] M. Tufano, F. Palomba, G. Bavota, R. Olivetox, M. Di Penta,
A. De Lucia, and D. Poshyvanyk, “When and why your code
starts to smell bad,” Proceedings - International Conference on
Software Engineering, vol. 1, pp. 403–414, 2015. [Online]. Available:
https://doi.org/10.1109/ICSE.2015.59

[26] G. Digkas, A. Ampatzoglou, A. Chatzigeorgiou, and P. Avgeriou,
On the temporality of
Springer
International Publishing, 2020, vol. 1266 CCIS. [Online]. Available:
http://dx.doi.org/10.1007/978-3-030-58793-2 6

introducing code technical debt.

[27] V. Lenarduzzi, F. Lomio, N. Saarim¨aki, and D. Taibi, “Does
migrating a monolithic system to microservices decrease the
technical debt?” Journal of Systems and Software, vol. 169, p.
110710, 2020. [Online]. Available: https://doi.org/10.1016/j.jss.
2020.110710

[28] A. Chatzigeorgiou and A. Manakos, “Investigating the evolution
of code smells in object-oriented systems,” Innovations in Systems
and Software Engineering, vol. 10, no. 1, pp. 3–18, 2014. [Online].
Available: https://doi.org/10.1007/s11334-013-0205-z

[29] G. Digkas, A. N. Chatzigeorgiou, A. Ampatzoglou, and
reduce
technical
on Software Engineering,
[Online]. Available: https:

P. C. Avgeriou, “Can clean new code
IEEE Transactions
debt density,”
vol. XX, no. XX, pp. 1–18, 2020.
//doi.org/10.1109/TSE.2020.3032557

[30] G. Bavota and B. Russo, “A large-scale empirical study on self-
admitted technical debt,” Proceedings - 13th Working Conference on
Mining Software Repositories, MSR 2016, pp. 315–326, 2016.

[31] D. B. de Sousa, P. H. M. Maia, L. S. Rocha, and W. Viana,
“Studying the evolution of exception handling anti-patterns in
a long-lived large-scale project,” Journal of the Brazilian Computer
Society, vol. 26, no. 1, pp. 1–24, 2020.
[Online]. Available:
https://doi.org/10.1186/s13173-019-0095-5

[32] N. Rios, L. Mendes, C. Cerdeiral, A. P. F. Magalh˜aes, B. Perez,
D. Correal, H. Astudillo, C. Seaman, C. Izurieta, G. Santos, and
R. Oliveira Sp´ınola, Hearing the voice of software practitioners on
causes, effects, and practices to deal with documentation debt. Springer
International Publishing, 2020, vol. 12045 LNCS.
[Online].
Available: http://dx.doi.org/10.1007/978-3-030-44429-7 4
[33] N. Rios, R. O. Sp´ınola, M. Mendonc¸a, and C. Seaman, “The
practitioners’ point of view on the concept of technical debt
and its causes and consequences: a design for a global family

of industrial surveys and its ﬁrst results from Brazil,” Empirical
Software Engineering, vol. 25, no. 5, pp. 3216–3287, 2020. [Online].
Available: https://doi.org/10.1007/s10664-020-09832-9

[34] R. Verdecchia, P. Kruchten, and P. Lago, Architectural technical
debt: A grounded theory. Springer International Publishing, 2020,
vol. 12292 LNCS. [Online]. Available: http://dx.doi.org/10.1007/
978-3-030-58923-3 14

[35] T. Besker, A. Martini, R. Edirisooriya Lokuge, K. Blincoe, and
J. Bosch, “Embracing technical debt, from a startup company
perspective,” Proceedings - 2018 IEEE International Conference on
Software Maintenance and Evolution, ICSME 2018, pp. 415–425, 2018.
[Online]. Available: https://doi.org/10.1109/ICSME.2018.00051

[36] I. Ozkaya, “The voice of

vol. 36, no. 5, pp. 3–5, 2019.
//doi.org/10.1109/MS.2019.2926545

the developer,” IEEE Software,
[Online]. Available: https:

[37] A. Martini and J. Bosch, “An empirically developed method
to aid decisions on architectural
technical debt refactoring:
AnaConDebt,” Proceedings - International Conference on Software
Engineering, pp. 31–40, 2016. [Online]. Available: https://doi.org/
10.1145/2889160.2889224

[38] ——, “The magniﬁcent seven: Towards a systematic estimation of
technical debt interest,” ACM International Conference Proceeding
Series, vol. Part F1299,
[Online]. Available: https:
2017.
//doi.org/10.1145/3120459.3120467

[39] C. Seaman, “Qualitative methods

studies of
software engineering,” IEEE Transactions on Software Engineering,
vol. 25, no. 4, pp. 557–572, 1999. [Online]. Available: https:
//doi.org/10.1109/32.799955

in empirical

[40] K.-J. Stol and B. Fitzgerald, “The ABC of software engineering
and
[Online].

research,” ACM Transactions
Methodology, vol. 27, no. 3, pp. 1–51, 10 2018.
Available: https://doi.org/10.1145/3241743

on Software Engineering

[41] V. R. Basili and G. Caldiera, “The goal question metric
paradigm,” Encyclopedia of Software Engineering - 2 Volume
Set, vol. 2, pp. 528–532, 2000.
[Online]. Available: https:
//www.cs.umd.edu/∼basili/publications/technical/T89.pdf
[42] E. Avidan and D. G. Feitelson, “Effects of variable names on
comprehension: An empirical study,” IEEE International Conference
on Program Comprehension, pp. 55–65, 2017. [Online]. Available:
https://doi.org/10.1109/ICPC.2017.27

[43] S. Butler, M. Wermelinger, Y. Yu, and H. Sharp, “Relating identiﬁer
naming ﬂaws and code quality: An empirical study,” Proceedings -
Working Conference on Reverse Engineering, WCRE, pp. 31–35, 2009.
[Online]. Available: https://doi.org/10.1109/WCRE.2009.50
[44] C. J. Kapser and M. W. Godfrey, “”Cloning considered harmful”
considered harmful: Patterns of cloning in software,” Empirical
Software Engineering, vol. 13, no. 6, pp. 645–692, 2008. [Online].
Available: https://doi.org/10.1007/s10664-008-9076-6

[45] L. Yu, S. Ramaswamy, and A. Vaidyanathan, “Understanding
the effects of code clones on modularity in software systems,”
Proceedings - Asia-Paciﬁc Software Engineering Conference, APSEC,
vol. 2, pp. 105–111, 2012. [Online]. Available: https://doi.org/10.
1109/APSEC.2012.49

[46] Z. Li, P. Avgeriou, and P. Liang, “A systematic mapping
study on technical debt and its management,” Journal of
Systems and Software, vol. 101, pp. 193–220, 3 2015.
[On-
line]. Available: http://dx.doi.org/10.1016/j.jss.2014.12.027https:
//linkinghub.elsevier.com/retrieve/pii/S0164121214002854
[47] T. Besker, A. Martini, and J. Bosch, “Managing architectural
technical debt: A uniﬁed model and systematic literature review,”
Journal of Systems and Software, vol. 135, pp. 1–16, 2018. [Online].
Available: https://doi.org/10.1016/j.jss.2017.09.025

[48] J. Pearl, Causality: Models, reasoning, and inference, second edition,
2nd ed. New York, (NY), USA: Cambridge University Press,
2009.

[49] R. McElreath, Statistical Rethinking.

(FL), USA:
CRC Press, 2020. [Online]. Available: https://doi.org/10.1201/
9780429029608

Boca Raton,

[50] R. L. Wasserstein, A. L. Schirm, and N. A. Lazar, “Moving
to a world beyond ”p ¡ 0.05”,” The American Statistician,
vol.
[Online]. Available:
1–19,
https://doi.org/10.1080/00031305.2019.1583913

sup1, pp.

73, no.

2019.

[51] A. Gelman, A. Vehtari, D. Simpson, C. C. Margossian,
J. Gabry, P. C. B ¨urkner,
B. Carpenter, Y. Yao, L. Kennedy,
and M. Modr´ak, “Bayesian workﬂow,” arXiv, 2020. [Online].
Available: https://arxiv.org/abs/2011.01808

JOURNAL OF TODO, VOL. TODO, NO. TODO, SEPTEMBER 2022

19

[52] R. Torkar, C. A. Furia, R. Feldt, F. G. de Oliveira Neto, L. Gren,
P. Lenberg, and N. A. Ernst, “A method to assess and argue
for practical signiﬁcance in software engineering,” 2020. [Online].
Available: http://arxiv.org/abs/1809.09849

[53] V. Braun and V. Clarke, “Using thematic analysis in psychology,”
Qualitative Research in Psychology, vol. 3, no. 2, pp. 77–101, 2006.
[Online]. Available: https://doi.org/10.1191/1478088706qp063oa
[54] C. Wohlin, P. Runeson, M. H ¨ost, M. C. Ohlsson, B. Regnell,
and A. Wessl´en, Experimentation in software engineering. Berlin,
Germany: Springer Berlin Heidelberg, 2012. [Online]. Available:
https://doi.org/10.1007/978-3-642-29044-2

[55] D. L. Phillips and K.

J. Clancy, “Some effects of ”social
desirability” in survey studies,” American Journal of Sociology,
vol. 77, no. 5, pp. 921–940, 1972. [Online]. Available: https:
//doi.org/10.1086/225231

[56] J. Miller, “Triangulation as a basis for knowledge discovery in
software engineering,” Empirical Software Engineering, vol. 13,
no. 2, pp. 223–228, 2008. [Online]. Available: https://doi.org/10.
1007/s10664-008-9063-y

