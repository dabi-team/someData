2
2
0
2

r
p
A
9
1

]

G
L
.
s
c
[

1
v
6
2
7
8
0
.
4
0
2
2
:
v
i
X
r
a

Jacobian Ensembles Improve Robustness
Trade-oﬀs to Adversarial Attacks(cid:63)

Kenneth T. Co1,2[0000−0003−2766−7326], David
Martinez-Rego2[0000−0003−1809−1169], Zhongyuan Hau1, and Emil C.
Lupu1[0000−0002−2844−3917]

1 Imperial College London, London SW7 2AZ, United Kingdom
{k.co,zy.hau17,e.c.lupu}@imperial.ac.uk
2 DataSpartan, London EC2Y 9ST, United Kingdom
david@dataspartan.com

Abstract. Deep neural networks have become an integral part of our
software infrastructure and are being deployed in many widely-used and
safety-critical applications. However, their integration into many systems
also brings with it the vulnerability to test time attacks in the form of
Universal Adversarial Perturbations (UAPs). UAPs are a class of pertur-
bations that when applied to any input causes model misclassiﬁcation.
Although there is an ongoing eﬀort to defend models against these adver-
sarial attacks, it is often diﬃcult to reconcile the trade-oﬀs in model ac-
curacy and robustness to adversarial attacks. Jacobian regularization has
been shown to improve the robustness of models against UAPs, whilst
model ensembles have been widely adopted to improve both predictive
performance and model robustness. In this work, we propose a novel
approach, Jacobian Ensembles – a combination of Jacobian regulariza-
tion and model ensembles to signiﬁcantly increase the robustness against
UAPs whilst maintaining or improving model accuracy. Our results show
that Jacobian Ensembles achieves previously unseen levels of accuracy
and robustness, greatly improving over previous methods that tend to
skew towards only either accuracy or robustness.

Keywords: Adversarial machine learning · Computer vision · Jacobian
regularization · Ensemble methods.

1

Introduction

Deep neural networks (DNNs) have achieved widespread use in many appli-
cations including image classiﬁcation [15], real-time object detection [20], and
speech recognition [12]. Despite these advances, there is an increasing recognition
that DNNs are exposed to systemic vulnerabilities in the form of Universal Ad-
versarial Perturbations (UAPs): where a single adversarial perturbation causes a
model to misclassify a large set of inputs [19]. Thus, it is important to ensure that

(cid:63) Kenneth T. Co is supported in part by the DataSpartan research grant DSRD201801.

 
 
 
 
 
 
2

K. Co et al.

neural networks are robust to such devastating attacks whilst still maintaining
their state-of-art accuracy on benign datasets.

UAP present a systemic risk, as they enable practical and physically realiz-
able adversarial attacks. They have been demonstrated in many widely-used and
safety-critical applications such as camera-based computer vision [7,8,2,18] and
LiDAR-based object detection [10,11]. UAPs have also been shown to facilitate
realistic attacks in both the physical [23] and digital [24] domains. In some cases,
UAPs also enable very resource-eﬃcient black-box attacks on DNNs [3,5].

An insuﬃciently studied aspect of existing defenses against UAPs is the
trade-oﬀ between clean accuracy, or the model’s performance on a benign dataset,
and its robustness to adversarial attacks. Indeed, a model with increased robust-
ness to UAPs is desirable, but reduced clean accuracy could translate to reduced
utility and additional ﬁnancial or security costs depending on the application.
Existing defenses primarily consider robustness to adversarial attacks, but ne-
glect the cost it incurs on the model’s performance for the original task. For
example, defenses like adversarial training or too much regularization improve
robustness but greatly reduce clean accuracy [6,13,21].

Jacobian regularization (JR) has previously been shown to improve robust-
ness against UAPs. However, JR can damage clean accuracy for large amounts
of regularization [6,13,21]. Model ensembles on the other hand has widely been
shown to achieve better classiﬁcation performance and stability than a single
(best) classiﬁer [16,26]. Ensembles are created by combining the outputs of mul-
tiple base learners to generate an improved prediction.

In this work, we propose combining JR and model ensembles during training
to create Jacobian Ensembles. JR is used to drastically improve the model’s ro-
bustness to UAPs while the ensemble methods stabilize the model’s predictions
and improve its clean accuracy. JR and model ensembles individually each have
been shown to improve UAP robustness but at some cost to clean accuracy [4,6].
We show that Jacobian Ensembles greatly improve on the accuracy-robustness
trade-oﬀ when compared to either JR or model ensembles individually. First,
we theoretically show that increasing the number of base learners in a model
ensemble improves the expected robustness of classiﬁers. Then, we empirically
verify our theoretical ﬁndings by applying JR with popular ensemble methods
bagging [1], snapshot ensembles [14], soft voting [26] to DNNs trained on the
popular benchmark datasets: MNIST [17], Fashion-MNIST [25] and then evalu-
ating their robustness against UAPs.

To summarize, we make the following contributions:

– We derive theoretical formulations for robustness of ensemble methods and
show that the robustness to UAPs increases monotonically with the number
of base learners.

– We empirically verify our theoretical results and show that Jacobian En-
sembles, a combination of Jacobian regularization and ensembles, achieves
the best accuracy-robustness trade-oﬀ as measured by a combined weighted
accuracy metric.

Jacobian Ensembles Improve Robustness Trade-oﬀs to Adversarial Attacks

3

2 Background

2.1 Universal Adversarial Perturbations

Let f : X ⊂ RD → RC be logits of a piece-wise linear classiﬁer with input x ∈ X .
We, deﬁne F (x) = arg max(f (x)) to be the output of this classiﬁer and write τ (x)
as the true class label of an input x. Universal Adversarial Perturbations
(UAP) are perturbations δ ∈ Rn to the data that satisfy F (x + δ) (cid:54)= τ (x)
for suﬃciently many x ∈ X where (cid:107)δ(cid:107)p < ε. The latter condition (cid:107)δ(cid:107)p < ε
constrains the magnitude of the perturbation and is often some (cid:96)p-norm and
small ε > 0 [19]. Given a classiﬁer f , UAPs are generated by maximizing the
loss (cid:80)
i Lf (xi + δ) with an iterative stochastic gradient descent algorithm [4,22]
where L is the model’s training loss, {xi} are batches of inputs, and δ are small
perturbations that satisfy (cid:107)δ(cid:107)p < ε.

2.2 Model Ensembles

An ensemble consists of combining multiple classiﬁers (base learners) to obtain
a resulting ensemble that has better accuracy or predictive performance on ag-
gregate than any individual base learner. In practice, it is widely accepted that
combining multiple classiﬁers can achieve better classiﬁcation performance than
a single “best” classiﬁer [16,26]. Ensembles are typically generated in two ways:
sequentially and in parallel. After generating the base learners the combination
of their outputs is taken rather than choosing a single “best” learner [26].

In this work, we will analyze ensemble methods that aggregate their base
learners in a convex combination. Formally, we deﬁne an ensemble F as a convex
combination of M base learners fi: F(x) = (cid:80)M
i=1 ci = 1
and 0 < ci < 1, ∀i. This is typical as many ensemble methods aggregate their
methods via averaging or a similar form of weighted sum [26]. Note however that
this will exclude some boosting algorithms such as AdaBoost that are typically
not convex combinations [9].

i=1 cifi(x) where (cid:80)M

Popular algorithms like Bagging [1] and newer methods like Snapshot En-
sembles [14] take the average of their base learners. Other methods like Soft
Voting [26] use a convex combination of their model outputs to vote. We refer
the reader to each ensemble methods’ corresponding paper for further details on
how the base learners are generated. For this work, we will consider Bagging,
Snapshot Ensembles, and Soft Voting.

2.3 Jacobian Regularization

Let f (x) be the logit output of the classiﬁer for input x, we write Jf (x) to
denote the input-output Jacobian of f at x. To train models with Jacobian
regularization (JR) [13,6], the following joint loss is optimized:

Ljoint(θ) = Ltrain({xi, yi}i, θ) +

(cid:32)

λJR
2

1
B

(cid:88)

i

(cid:33)

(cid:107)J(xi)(cid:107)2
F

(1)

4

K. Co et al.

where θ represent the parameters of the model, Ltrain is the standard cross-
entropy training loss, {xi, yi} are input-output pairs from the mini-batch, and
B is the mini-batch size. This optimization uses a regularization parameter λJR,
which allows the adjustment between regularization and classiﬁcation loss.

The primary idea is to reduce the Frobenius norm of the input-output Jaco-
bian (cid:107)J(xi)(cid:107)F to decrease the model’s sensitivity to small perturbations such as
UAPs. JR shows some promise in improving robustness to UAPs. However, it
can often simultaneously decrease the model’s clean accuracy [6] especially for
large values of λJR.

3 Bounds on UAP Eﬀectiveness for Model Ensembles

In this section, we derive theoretical bounds for the expectation and variance
of the Frobenius norm of the Jacobian of model ensembles. Note that we only
consider ensembles that take a convex combination of their base learners. Similar
to [6], we restrict the Frobenius norm of the Jacobian of a model to improve
robustness against UAPs.

We show that using model ensembles result in tighter bounds on the Frobe-
nius norm of the Jacobian, suggesting improved robustness and stability versus
a single classiﬁer. Our main result in Theorem 1 shows that increasing the
number of base learners decreases both the upper and lower bounds of the ex-
pectation and variance for the Frobenius norm of the ensemble’s Jacobian.

Proposition 1 Let xi be independent random variables drawn from a Normal
distribution xi ∼ N (µ, σ2) for a ﬁxed mean µ and variance σ2. Deﬁne x =
(cid:80)M

i=1 ci = 1 and 0 < ci < 1, ∀i. We then have the following:

i=1 cixi where (cid:80)M

σ2
M

≤

M
(cid:88)

i=1

i σ2 < σ2
c2

(2)

Proof. By linearity of Normal distributions: x ∼ N (µ, (cid:80)M
rive bounds for (cid:80)M
i when M ≥ 2:

i=1 c2

i=1 c2

i σ2). We then de-

M
(cid:88)

i=1

M
(cid:88)

c2
i =

c2
i + 2

M
(cid:88)

(cid:88)

cicj − 2

M
(cid:88)

(cid:88)

cicj

i=1
(cid:32) M
(cid:88)

i=1

=

= 1 − 2

i=1

j(cid:54)=i

i=1

j(cid:54)=i

(cid:33)2

ci

− 2

M
(cid:88)

(cid:88)

i=1

j(cid:54)=i

cicj

M
(cid:88)

(cid:88)

i=1

j(cid:54)=i

cicj

Since cicj > 0 for all pairs i, j, then it follows that we have the upper bound
(cid:80)M
i=1 c2
i = 1 is only possible in the degenarate

i < 1. Note that equality: (cid:80)M

i=1 c2

Jacobian Ensembles Improve Robustness Trade-oﬀs to Adversarial Attacks

5

case (when ci = 1 for exactly one i and cj = 0 for i (cid:54)= j).
For the lower bound, we use Cauchy-Schwarz inequality to get:

(cid:32) M
(cid:88)

(ci · 1)

(cid:33)2

(cid:32) M
(cid:88)

(cid:33) (cid:32) M
(cid:88)

(cid:33)

12

=

(cid:32) M
(cid:88)

c2
i

≤

(cid:33)

c2
i

· M

i=1

i=1

i=1

i=1

The left hand side reduces to 1, so it follows that (cid:80)M
when ci = 1

M with equality
M for all i. Multiplying all sides with σ2 gives the desired bounds. (cid:117)(cid:116)

i ≥ 1

i=1 c2

Let F be an ensemble of M base learners fi: F(x) = (cid:80)M
i=1 cifi(x) where
i=1 ci = 1 and 0 < ci < 1, ∀i. Let JF denote the Jacobian of F and Ji the

(cid:80)M
Jacobian of fi for all i. It follows that JF = (cid:80)M

i=1 ciJi.

Theorem 1. Let each matrix Ji ∈ RC×D be comprised of the independent ran-
dom variables iapq ∼ N (µ, σ2), where iapq is the element on the p-th row and
q-th column of matrix Ji. It follows that their convex combination JF satisﬁes:

CD

(cid:18) σ2
M

+ µ2

CD

(cid:18) 4µ2σ2
M

+

2σ4
M 2

(cid:19)

(cid:19)

≤ E((cid:107)JF (cid:107)2

F ) < E((cid:107)Ji(cid:107)2
F )

≤ Var((cid:107)JF (cid:107)2

F ) < Var((cid:107)Ji(cid:107)2
F )

(3)

(4)

Proof. Taking the square of Frobenius norm, we have the following for the Ja-
cobian of a single model:

(cid:107)Ji(cid:107)2

F =

C
(cid:88)

D
(cid:88)

p=1

q=1

|iapq|2

The moments of (cid:107)Ji(cid:107)F are proportional to the moments of the random variables
ia2
pq. These follow a chi-squared distribution with 1 degree of freedom, and have
the expectation and variance:

E(ia2

pq) = Var(iapq) + [E(iapq)]2

= σ2 + µ2

Var(ia2

pq) = E(ia4

pq) − [E(ia2

pq)]2
= µ4 + 6µ2σ2 + 3σ4 − µ4 − 2µ2σ2 − σ4
= 4µ2σ2 + 2σ4

Deﬁne apq = (cid:80)M
Thus for the ensemble model’s Jacobian, we have:

i=1 ci iapq, the elements of JF . Note that apq ∼ N (µ, (cid:80)M

i=1 c2

i σ2).

(cid:107)JF (cid:107)2

F =

C
(cid:88)

D
(cid:88)

p=1

q=1

|apq|2

6

K. Co et al.

It is clear that the moments of (cid:107)JF (cid:107)F are proportional to that of a2
pq. These
random variables follow a chi-squared distribution with M degrees of freedom,
and have the following expectation and variance:

E(a2

pq) =

M
(cid:88)

i=1

i σ2 + µ2
c2

Var(a2

pq) = 4µ2

M
(cid:88)

i=1

i σ2 + 2
c2

(cid:33)2

i σ2
c2

(cid:32) M
(cid:88)

i=1

Applying Proposition 1, we then have the following bounds for the expectation
and variance for these random variables:

σ2
M

+ µ2 ≤ E(a2

pq) < E(ia2

pq)

4µ2σ2
M

+

2σ4
M 2 ≤ Var(a2

pq) < Var(ia2

pq)

As the random variables are independently drawn, our desired result follows:

CD

(cid:18) σ2
M

+ µ2

CD

(cid:18) 4µ2σ2
M

+

2σ4
M 2

(cid:19)

(cid:19)

≤ E((cid:107)JF (cid:107)2

F ) < E((cid:107)Ji(cid:107)2
F )

≤ Var((cid:107)JF (cid:107)2

F ) < Var((cid:107)Ji(cid:107)2

F ) (cid:117)(cid:116)

Conclusion. These are proportional to the expectation and variance of the
Frobenius norms of our Jacobian matrices, so we can derive the following conclu-
sions in this scenario. Ensembles decrease both the expected value and variance
of the Jacobian’s Frobenius norms when compared to that of a single model’s. As
M increases, the lower bounds of both the expectation and variance decreases.
Averaging is one of the most common methods for aggregating base learner
outputs in an ensemble [16,26], so it is important to consider this case. When the
ensemble is done via averaging, i.e. ci = 1
M for all i, this achieves the equality
condition for the lower bounds of both E(a2
pq) and Var(a2
pq). Therefore, increasing
the number of models in the ensemble strictly decreases the expectation and
variance of the ensemble’s Jacobian’s norm (cid:107)JF (cid:107)F .

This theoretical result gives us the motivation on how model ensembles also
improve the stability of models and thus their robustness to UAPs. We show
this by deriving the above bounds on the Frobenius norm on their Jacobian.
As model ensembles have also been shown to have improved performance over
a single classiﬁer, this makes it an ideal candidate for improving both model
accuracy and robustness. In the next section, we explore the robustness of model
ensembles and verify our theory with empirical results.

Jacobian Ensembles Improve Robustness Trade-oﬀs to Adversarial Attacks

7

4 Experiments with Jacobian Ensembles

4.1 Experimental Setup

Jacobian Ensembles. To apply Jacobian Ensembles, we only need to include
the Jacobian regularization as described in Eq. 1 to the joint loss of standard en-
semble methods. The Jacobian regularization parameter λJR is tested for values
between 0 and 2: where the resulting models manage to maintain good accuracy
as informed by previous work [6].

We evaluate the following ensemble methods: Bagging [1], Snapshot Ensem-
bles [14], and Soft Voting [26]. For these, we evaluate all experiments with en-
sembles trained on 1, 3, 6, and 9 base learners. Eﬀectively, one base learner is
similar to using no ensemble method at all.

Models & Datasets. We use the MNIST [17] and Fashion-MNIST [25] datasets.
These are popular image classiﬁcation benchmarks, each with 10 classes, and 28
by 28 pixel images whose their pixel values range from 0 to 1. For the DNN
architecture, we use a version of LeNet-5 [17,13], which we refer to as LeNet.

UAP Attacks. We evaluate the robustness of these models to UAPs generated
via iterative stochastic gradient descent with 100 iterations and a batch size of
200. Perturbations are applied under (cid:96)∞-norm constraints. The ε we consider
in our attacks for this norm are from 0.10 to 0.25, this perturbation magnitude
is equivalent to 10%-25% of the maximum total possible change in pixel values.
UAPs are generated over 50 diﬀerent random seeds, and we report UAPs with
the highest attack success rate, as this would represent the worst-case scenario.

Fig. 1. Clean accuracy of LeNet on MNIST (top) and Fashion-MNIST (bottom) for
various Jacobian regularization strengths λJR and with varying number of base learners
per ensemble method.

8

K. Co et al.

Fig. 2. Model robustness against UAP with ε = 0.15 of LeNet on MNIST (top) and
Fashion-MNIST (bottom) for various Jacobian regularization strengths λJR and with
varying number of base learners per ensemble method.

Metrics. The following metrics are evaluated on the entire 10,000 sample test
sets for each dataset. Clean Accuracy is the accuracy of the model on the test
set. Model Robustness measures the accuracy of the model on the test set when
the corresponding worst-case UAP is applied or present. We then average this
model robustness over all the UAP attack scenarios that we consider, (cid:96)∞-norm
of ε = 0.10, 0.15, 0.2, 0.25, to get an overall mean UAP Accuracy.

4.2 Improvements with Jacobian Ensembles

Clean Accuracy. In Fig. 1 there is a rapid degradation in clean accuracy when
λJR is large. This is when JR is more heavily weighted, and this is consistent
with previous work [6,13] as too much regularization damages accuracy on the
test set. However, having a small amount of JR is still noticeably more beneﬁcial
than no JR as indicated by the clean accuracy when considering λJR in the range
of 0 to 0.1 for both datasets across all settings.

We also see beneﬁts of using ensembles: models with more than one base
learner have noticeably better clean accuracy across all settings in Fig. 1. Over-
all, Jacobian Ensembles, which is a combination of ensemble methods and JR,
achieves the best performance in our experiments.

Model Robustness. In the interest of space, we only present the robustness
results for a particular UAP attack strength ε = 0.15 in Fig. 2. In terms of
robustness, trends for both datasets are slightly diﬀerent since Fashion-MNIST
is a more diﬃcult dataset than MNIST: a regularly trained LeNet on MNIST

Jacobian Ensembles Improve Robustness Trade-oﬀs to Adversarial Attacks

9

Fig. 3. Clean accuracy versus robustness trade-oﬀ of LeNet on MNIST (top) and
Fashion-MNIST (bottom) labeled by λJR for various UAP attack strengths ε.

can be expected to have 98-99% clean accuracy whereas it is 90-91% for the same
model on Fashion-MNIST. Thus, it is expected that models on Fashion-MNIST
are considerably less robust. For most settings, the general trends in Fig. 2 show
that ensembles have a robustness beneﬁt. JR monotonically increases robustness
for MNIST and for Fashion-MNIST has a range between 0 < λJR < 0.5 that
achieves the best robustness.

In conclusion, ensemble methods with more than one base learner intro-
duce measurable advantages in both accuracy and robustness. These advantages
become even more pronounced when combined with JR. Next we analyze the
general trade-oﬀ between accuracy and robustness.

4.3 Accuracy-Robustness Trade-Oﬀ

In Fig. 3, we plot the accuracy versus robustness of the various models we
trained under the diﬀerent conﬁgurations accounting for various ensemble meth-
ods, number of base learners, and λJR values. The best models achieve both high
accuracy and robustness, so these will be on the top right side of the graph.

In a scenario when robustness is not accounted for (i.e. λJR = 0), models
would appear in the top left. They are trained to have good accuracy, but re-
main extremely vulnerable to adversarial attacks like UAPs. On the other hand,

10

K. Co et al.

Table 1. Weighted accuracy (in %) of LeNet for MNIST (top) and Fashion-MNIST
(bottom). The ﬁrst 3 rows show the models with highest weighted accuracy. The bottom
3 rows show the best weighted accuracy of models trained with only JR, only ensemble,
and “standard training” (neither JR nor ensemble).

Model

MNIST Accuracy (%)

Ensemble Learners
Snapshot
Snapshot
Snapshot
JR Only
Bagging
Standard

3
9
3
1
6
1

Model

Ensemble Learners

Bagging
Bagging
Snapshot
JR Only
Bagging
Standard

9
6
9
1
9
1

λJR Clean Avg. UAP Weighted
82.8
0.50
82.3
0.50
81.5
0.20
74.2
0.05
42.8
0
0
31.9

90.3
90.0
89.9
86.3
70.4
65.5

97.8
97.7
98.3
98.4
98.1
99.1

Fashion-MNIST Accuracy (%)
λJR Clean Avg. UAP Weighted
43.2
0.05
43.0
0.05
42.4
0.10
31.2
0.10
12.7
0
12.1
0

63.5
63.2
62.8
55.1
51.2
50.9

83.9
83.4
83.2
79.0
91.2
90.8

models that overcompensate for robustness such as those with very high reg-
ularization (e.g. λJR = 2), will appear on the bottom right. As these models
sacriﬁce a signiﬁcant amount of clean accuracy for improved robustness, espe-
cially against UAP attacks with larger strength ε. These delineations become
clear when labeling the models according to their λJR value as in Fig. 3. Thus,
the role of λJR is evident in improving overall robustness.

To better capture the model performance on both benign and adversarial
inputs, we compute the Weighted Accuracy by averaging the clean accuracy and
mean UAP accuracy. In practice, the defender can adjust the weighting of each
accuracy metric in their ﬁnal assessment to better match their application and
risk proﬁle. We choose the mean as the base setting.

Next, we perform an ablation study on the eﬀect of only JR and only ensemble
models compared against the top 3 Jacobian Ensembles with the best weighted
accuracy in Table 1. We ﬁnd that Jacobian Ensembles achieve the best weighted
accuracy. To compare, we also show in the bottom 3 rows for each table the best
models with only JR, only ensembles, and neither JR nor ensembles. The best
Jacobian Ensembles have a clear advantage with average UAP accuracy over the
the non-Jacobian Ensembles whilst maintaining very close clean accuracy. This
diﬀerence is even more pronounced on the Fashion-MNIST dataset.

Diﬀerences between the two datasets MNIST and Fashion-MNIST also show
in Table 1. Since MNIST is an easier dataset, performance degradation by large
λJR = 0 are not as prominent, so larger λJR are favored by the combined score.
For Fashion-MNIST, a large λJR is detrimental as the base model begin with

Jacobian Ensembles Improve Robustness Trade-oﬀs to Adversarial Attacks

11

a relatively low clean accuracy (< 91%). In both cases, ensembles demonstrate
a noticeably large boost in weighted accuracy, and further tuning is likely to
improve their performance.

5 Conclusion

In this work, we propose Jacobian Ensembles to signiﬁcantly increase model
robustness against UAPs whilst maintaining the clean accuracy of models. Our
results show that Jacobian Ensembles takes the advantages of both Jacobian
regularization and model ensembles to achieve superior accuracy and robustness
than each of these methods on their own, as measured by our weighted metric.
In addition, we derive theoretical upper and lower bounds on the robustness
to UAPs for model ensembles, showing that increasing the number of base clas-
siﬁers in the models’ ensembles reduces the expected Frobenius norm of their
Jacobian and thus improves stability. We then empirically verify our results and
show that a combination of both JR and ensembles achieve the best performance.
These results give us conﬁdence in recommending Jacobian Ensembles as a
general methodology when training models as UAPs present a great threat to
model adoption and safety. Our results show that it is indeed possible to maintain
great test accuracy whilst achieving signiﬁcant UAP robustness in previously
unseen levels of accuracy-robustness trade-oﬀ. Thus, it is indeed possible to get
the best of both worlds.

References

1. Breiman, L.: Bagging predictors. Machine learning 24(2), 123–140 (1996)
2. Brown, T.B., Man´e, D.: Adversarial patch. arXiv preprint arXiv:1712.09665 (2017)
3. Co, K.T., Mu˜noz Gonz´alez, L., de Maupeou, S., Lupu, E.C.: Procedural noise
adversarial examples for black-box attacks on deep convolutional networks. In:
Proceedings of the 2019 ACM SIGSAC Conf. on Computer and Communications
Security. pp. 275–289. CCS ’19 (2019). https://doi.org/10.1145/3319535.3345660
4. Co, K.T., Mu˜noz-Gonz´alez, L., Kanthan, L., Glocker, B., Lupu, E.C.: Univer-
sal adversarial robustness of texture and shape-biased models. arXiv preprint
arXiv:1911.10364 (2019)

5. Co, K.T., Mu˜noz-Gonz´alez, L., Lupu, E.C.: Sensitivity of deep convolutional net-

works to gabor noise. arXiv preprint arXiv:1906.03455 (2019)

6. Co, K.T., Rego, D.M., Lupu, E.C.: Jacobian regularization for mitigating uni-
versal adversarial perturbations. In: International Conference on Artiﬁcial Neural
Networks. pp. 202–213. Springer (2021)

7. Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Tramer, F., Prakash,
A., Kohno, T., Song, D.: Physical adversarial examples for object detectors. In:
12th USENIX Workshop on Oﬀensive Technologies (W OOT 18) (2018)

8. Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C., Prakash,
A., Kohno, T., Song, D.: Robust physical-world attacks on deep learning visual
classiﬁcation. In: Proceedings of the IEEE Conf. on Computer Vision and Pattern
Recognition (CVPR). pp. 1625–1634 (2018)

12

K. Co et al.

9. Freund, Y., Schapire, R., Abe, N.: A short introduction to boosting. Journal-

Japanese Society For Artiﬁcial Intelligence 14(771-780), 1612 (1999)

10. Hau, Z., Co, K.T., Demetriou, S., Lupu, E.C.: Object removal attacks on lidar-

based 3d object detectors. arXiv preprint arXiv:2102.03722 (2021)

11. Hau, Z., Demetriou, S., Mu˜noz-Gonz´alez, L., Lupu, E.C.: Shadow-catcher: Looking
into shadows to detect ghost objects in autonomous vehicle 3d sensing. In: Euro.
Symposium on Research in Computer Security. pp. 691–711. Springer (2021)
12. Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.r., Jaitly, N., Senior, A.,
Vanhoucke, V., Nguyen, P., Sainath, T.N., et al.: Deep neural networks for acoustic
modeling in speech recognition: The shared views of four research groups. IEEE
Signal Processing Magazine 29(6), 82–97 (2012)

13. Hoﬀman, J., Roberts, D.A., Yaida, S.: Robust learning with jacobian regulariza-

tion. arXiv preprint arXiv:1908.02729 (2019)

14. Huang, G., Li, Y., Pleiss, G., Liu, Z., Hopcroft, J.E., Weinberger, K.Q.: Snapshot

ensembles: Train 1, get m for free. In: Intl. Conf. on Learning Rep. (2017)

15. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classiﬁcation with deep con-
volutional neural networks. In: Advances in Neural Information Processing Systems
(NeurIPS). pp. 1097–1105 (2012)

16. Kuncheva, L.I.: Combining pattern classiﬁers: methods and algorithms. John Wiley

& Sons (2014)

17. LeCun, Y., Bottou, L., Bengio, Y., Haﬀner, P.: Gradient-based learning applied to

document recognition. Proceedings of the IEEE 86(11), 2278–2324 (1998)

18. Matachana, A.G., Co, K.T., Mu˜noz-Gonz´alez, L., Martinez, D., Lupu, E.C.: Ro-
bustness and transferability of universal attacks on compressed models. arXiv
preprint arXiv:2012.06024 (2020)

19. Moosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P.: Universal adversarial
perturbations. In: Proceedings of the IEEE Conf. on Computer Vision and Pattern
Recognition (CVPR). pp. 1765–1773 (2017)

20. Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: Uniﬁed,
real-time object detection. In: Proceedings of the IEEE Conf. on Computer Vision
and Pattern Recognition (CVPR). pp. 779–788 (2016)

21. Roth, K., Kilcher, Y., Hofmann, T.: Adversarial training is a form of data-
dependent operator norm regularization. In: Advances in Neural Information Pro-
cessing Systems (NeurIPS) (2020)

22. Shafahi, A., Najibi, M., Xu, Z., Dickerson, J., Davis, L.S., Goldstein, T.: Universal

adversarial training. arXiv preprint arXiv:1811.11304 (2018)

23. Thys, S., Van Ranst, W., Goedem´e, T.: Fooling automated surveillance cameras:
adversarial patches to attack person detection. In: CVPRW: Workshop on The
Bright and Dark Sides of Computer Vision: Challenges and Opportunities for Pri-
vacy and Security (2019)

24. Tram`er, F., Dupr´e, P., Rusak, G., Pellegrino, G., Boneh, D.: Adversarial: Percep-
tual ad blocking meets adversarial machine learning. In: Proceedings of the 2019
ACM SIGSAC Conf. on Computer and Communications Security. p. 2005–2021.
CCS ’19 (2019). https://doi.org/10.1145/3319535.3354222

25. Xiao, H., Rasul, K., Vollgraf, R.: Fashion-mnist: a novel image dataset for bench-
marking machine learning algorithms. arXiv preprint arXiv:1708.07747 (2017)
26. Zhou, Z.H.: Ensemble methods: foundations and algorithms. CRC press (2012)

