Ontology Design Facilitating Wikibase Integration – and a Worked Example for Historical
Data

Cogan Shimizua, Andrew Eellsa, Seila Gonzalezb, Lu Zhoua, Pascal Hitzlera, Alicia Sheillb, Catherine Foleyb, Dean Rehbergerb

aDepartment of Computer Science, Kansas State University, USA
bMATRIX, Michigan State University, USA

2
2
0
2

y
a
M
7
2

]
I

A
.
s
c
[

1
v
2
3
0
4
1
.
5
0
2
2
:
v
i
X
r
a

Abstract

Wikibase – which is the software underlying Wikidata – is a powerful platform for knowledge graph creation and management.
However, it has been developed with a crowd-sourced knowledge graph creation scenario in mind, which in particular means that
it has not been designed for use case scenarios in which a tightly controlled high-quality schema, in the form of an ontology, is to
be imposed, and indeed, independently developed ontologies do not necessarily map seamlessly to the Wikibase approach. In this
paper, we provide the key ingredients needed in order to combine traditional ontology modeling with use of the Wikibase platform,
namely a set of axiom patterns that bridge the paradigm gap, together with usage instructions and a worked example for historical
data.

Keywords: Wikibase, Modular Ontology Modeling, Ontology Design Pattern

1. Introduction

When developing a knowledge graph, there are many aspects to
consider during its deployment. These range from usability of
its interfaces (both human and programmatic), the (re)usability
of the data that it contains, its accessibility (both in terms of
uptime and its interfaces), transparency (relating to provenance
and trustworthiness), and its persistence (preventing link rot).
These characteristics are neatly summarized in the FAIR man-
ifesto [19]. One way of accomplishing (re)usability of the data
is through the principled use (i.e., using a structured develop-
ment methodology) of a schema that describes and documents
the relations between concepts in the knowledge graph. With
respect to accessibility and persistence, one can consider ex-
posing a SPARQL endpoint and allowing interested parties to
query against it. While this is a very ﬂexible approach, it makes
it diﬃcult to explore the data. On the other hand, one could
consider exposing data through a framework such as Wikibase.
In this paper, we explore how the Modular Ontology Modeling
methodology (MOMo [15]) can be applied in such a way that
eventual deployment of the graph data to the Wikibase model is
seamless.

Modular Ontology Modeling (MOMo) speciﬁes the develop-
ment of ontology modules for sets of tightly bound key notions
that will be included in a given ontology [15].1 When devel-

Email addresses: cogan.shimizu@coganshimizu.com (Cogan

Shimizu), andreweells@ksu.edu (Andrew Eells),
seilagonzaleze@gmail.com (Seila Gonzalez), luzhou@ksu.edu (Lu
Zhou), hitzler@ksu.edu (Pascal Hitzler), asheill@msu.edu (Alicia
Sheill), foleyc@msu.edu (Catherine Foley), rehberge@msu.edu (Dean
Rehberger)

1We focus on the MOMo paradigm as it is closely aligned with our use case,
but any pattern-based methodology, such as eXtreme Design [12] would work
similarly.

oping a module, it is generally suggested to identify applicable
ontology design patterns (ODPs) [6] and adapt them to the use-
case at hand through template-based instantiation [7]. During
this process it is good practice to consult existing collections of
ODPs, such as those on the ODP Community Wiki2 or in the
MODL library [16].

As one of the largest publicly editable and accessible knowl-
edge bases, Wikidata is an immense, crowd-sourced knowledge
base with persistent data that is available for public use and
consumption. Wikidata contains millions of pieces of knowl-
edge from many diﬀerent domains in the world, and is growing
constantly. In addition, it serves as the structured data hub for
all of Wikimedia’s projects (e.g., Wikipedia, Wikivoyage, Wik-
tionary, and Wikisource). As such, when modeling an ontology,
it makes sense to consider ease of integration with resources
like Wikidata, among other Linked Data Platforms.3 Wikibase
is the software underlying Wikidata, which can be used sepa-
rately from Wikidata for knowledge graph creation and man-
agement.

The Enslaved Ontology [17] was modeled using the nascent
MOMo methodology and is used as the schema for the knowl-
edge graph that underlies the publicly available knowledge base
on the Enslaved Hub.4 The Enslaved Hub is an innovative
and compelling centralized location for engaging with histor-
ical slave trade data from a variety of sources and is supported
by an underlying installation of the Wikibase platform. During
development, we had assumed that it would be relatively easy
to adapt the modular Enslaved ontology to the Wikibase model.

2See https://ontologydesignpatterns.org/.
3See https://www.wikidata.org/.
4https://enslaved.org/

Preprint submitted to Elsevier

May 30, 2022

 
 
 
 
 
 
Unfortunately, between diﬀerent semantics for validating data
to be put into the knowledge base and unclear mapping between
diﬀerent notions of provenance, it was not as straightforward as
we had expected, resulting in a realization of the knowledge
graph in Wikibase that is conceptually close but still markedly
diﬀerent from the designed Enslaved Ontology [20]. However,
during the course of that work we realized how the gap between
ODP-based ontology modeling and Wikibase software use can
be closed, centrally by basing the ontology design on new ODPs
that are developed to allow for seamless use with Wikibase. The
result of our subsequent work is what we present in this paper.

So in this paper, we will present a library of ontology design
patterns that have been speciﬁcally engineered to explicitly rep-
resent how Wikibase models data “under-the-hood,” thus ensur-
ing that the ontology is optimally structured for interoperability
with Wikibase. This library can be used by any organization
to model their own internal and proprietary knowledge graphs
and apply their alignments to Wikibase as an important tool to
augment or induce new information into their own knowledge
graph. In particular, to the best of our knowledge this paper
provides the ﬁrst ODP library that provides a bridge between
traditional ontology engineering and use of the Wikibase plat-
form.

The rest of this paper is organized as follows. In Section 2 we
describe relevant aspects of Wikibase and how they give rise to
mismatches with traditional ontology modeling. In Section 3
we describe our ODP library and how it addresses these mis-
matches. In Section 5 we provide a case study: a reconstructed
Enslaved Ontology. Section 6 discusses related work before we
conclude in Section 7.

This paper is a very substantial extension of work previously
presented at a workshop [3]. Our pattern library is publicly
available from our online portal.5

2. Background & Motivation

2.1. The Wikibase Model
Brieﬂy, the Wikibase RDF export model (Figure 1)6 uses the
notion of reiﬁcation to attach qualiﬁers and references (for
provenance) to assertional statements. Reiﬁcation is the prac-
tice of turning a property into an instance, so that additional
assertions may be attached to the property. A common use is to
attach a temporal scope to a role; for example, an employee is
employed at a company from 2009-2014. In Wikibase terminol-
ogy, this temporal scope would be considered a qualiﬁer. The
supporting documentation, perhaps digital tax records, could be
considered a reference for this information.

Wikibase goes on to simplify how this reiﬁcation occurs. The
assertion is hashed, which is then turned into an instance of

5https://gitlab.cs.ksu.edu/daselab/wikibase-ontology-

design-library

Figure 1: Wikibase RDF export schematic.

Figure 2: A closer look at the reiﬁcation of wdt:R polish ﬁgure.

wikibase:Statement. Then, the property name is reused in two
diﬀerent namespaces, to complete the reiﬁcation. To continue
our example,7 it would be serialized in RDF as

ex:employee0

p:hasJob

s:12345

ps:hasJob

ex:employee0

wdt:hasJob

s:12345

ex:job0

ex:job0

.

.

.

where s:12345 is the hash node created by the system. This
hashing is diagrammatically shown in Figure 2. In Figure 1 the
corresponding nodes are Item, Statement and the simple value;
note the use of preﬁxes. It will become clear from our discus-
sion below in Section 3 how exactly this RDF export is pro-
duced.

2.2. Paradigmatic Conﬂicts
The Wikibase approach to creating an RDF graph puts limita-
tions on the graph structures that can be created through Wik-
ibase. Some of these restrictions are mild in terms of graph

6This is a redrawing of the ﬁgure at https://www.mediawiki.org/
wiki/Wikibase/Indexing/RDF_Dump_Format, where more information
can be found. Further details are in [4].

7For readability’s sake, we do not use in the example the internal Wikibase
identiﬁers QXXXX and PXXXX. The human readable representations found in
the interface are from rdfs:label values.

2

Figure 3: Enslaved Ontology: AgeRecord representation.

modeling, however others forbid graph structures that are some-
times desirable. These restrictions primarily come from the fact
that the Wikibase approach restrains what can be stated about
the reiﬁcation nodes (i.e., the hashes). We give some examples
from the Enslaved ontology.

Figure 3 depicts a part of a schema diagram for the AgeRe-
cord module in the Enslaved ontology. The color and shape
coding can be mostly ignored for this discussion: boxes rep-
resent classes (concepts), ovals represent datatype values and
arrows represent binary relationships (properties). Conceptu-
ally, this is to represent information about the age of an Agent
(person) at a speciﬁc point in time. The provenance informa-
tion (isDirectlyBasedOn relation) is for representing the origin
of the data in the record. Clearly, the lower row (light blue) are
references or qualiﬁers (using the Wikibase terminology).

The upper left of the diagram is what presents the diﬃculty.
The schema is based on the fact that some sources in this ap-
plication context report age as a number, while others present
age categories, like child or infant, in this application case, as
a controlled vocabulary. From a (faithful) data integration per-
spective, the desire in this case was to make it possible to record
either or both types of information.

Now, if we take the light blue boxes as qualiﬁers and refer-
ences, then the AgeRecord node would be the hashed node in
the Wikibase system. However we would not be able to have
both the number value and the controlled vocabulary attached
to the hash node on par. The Wikibase approach would force
us to pick one of them (e.g., the controlled vocabulary) as the
primary relation for the age, while the other (the number in this
case) would be another qualiﬁer. While this is possible, it is
arguably not a faithful representation of the conceptual model
which does not (and should not, in this case) prefer one way of
recording age over the other.

Figure 4 shows another Enslaved schema diagram, in this case
for historical records on participation in an event. The partic-
ipant role type (intended use with a controlled vocabulary) in-
dicates the role of the participant, e.g., the role of captain in a
slave transport voyage. As before, the light blue boxes are most
naturally taken as qualiﬁers or references. And again, as be-
fore, we are left with a decision as to the main relationship, and
diﬀerent arguments can be made. For example, from an agent-
centric perspective, we would argue that the relation between

Figure 4: Enslaved Ontology: ParticipantRoleRecord representation.

Figure 5: Enslaved Ontology: InterAgentRelationshipRecord representation.

Agent and Event is primary, in which case the type of partici-
pation would be relegated to a qualiﬁer. However, we may also
argue that the type of participation (e.g., whether as enslaved
person or buyer in a sale) is of most interest in some situations,
in which case the relation between Agent and the participation
type is primary, and the event modeled as a qualiﬁer. While ei-
ther is possible, in principle, we note that the Wikibase model
forces to pick a primary relationship, while the original inten-
tion for the ontology was to remain impartial in this respect.

Another complication arises from the decision – on the side of
the ontology – to include an inverse role between Event and
ParticipantRoleRecord, in this particular case. Since Partici-
pantRoleRecord will end up being the hash node, this cannot
be done in Wikibase. We are forced to use a particular direc-
tion, in this case the roleProvidedBy relation, as we have lim-
ited control over relation directions involving hash nodes.

The situation depicted in Figure 5 is very similar to the one just
discussed; in this case it is about recording relationships be-
tween agents (persons). For Wikibase, we are forced to make a
determination whether the agent-agent relation is primary, or
whether the type of relationship (as viewed from one of the
agents) is primary. In addition, there are several options how
to resolve the choice in the ontology model to have three rela-
tions between agents and the (reiﬁed) record; in particular the
symmetry in the ontology in terms of isRelationshipFrom and
isRelationshipTo cannot be maintained.

3

Now, in application cases where stronger demands are made
on graph structure – and as we have seen from the examples
above – we cannot readily or easily transfer an ontology-based
schema into the Wikibase format. But rather than having to
choose between an ontology modeling approach or use of Wik-
ibase, in this paper we will show how we can make them work
together more seamlessly, by providing ontology design pat-
terns that capture – and thus cater for – the restrictions imposed
by Wikibase.

3. Generic Wikibase Patterns

There are two core deliverables in this manuscript. First is a
library of conceptual design patterns that visually represent a
paradigm for developing a schema that will immediately align
to the Wikidata model. The patterns are designed to be intu-
itive by condensing, or folding, many of the Wikibase particu-
lars away from the interested developer, which at the same time
will prompt the developer to think about the schema in terms
of primary relations with attached qualiﬁers and references, as
discussed above. The second deliverable is the set of expanded
patterns that conform to the structure of the Wikibase RDF ex-
port, and which are capable of being axiomatically described.9

These patterns are presented in detail, paired together, in Fig-
ures 7-14 and discussed in Section 3.3. The diagrams and their
syntax are summarized in the next sections (Sections 3.1 and
3.2), together with a discussion what it means to expand the
conceptual diagrams. We also provide the artifacts associated
with this manuscript: a way to validate the resulting serializa-
tions of the expanded patterns, speciﬁed in ShEx (the Shape
Expression Language10) and WOPL, the Wikibase Ontology
Design Pattern Library, which follows the MODL architecture
[16] in Section 3.4.

3.1. Schema Diagrams

Schema diagrams are intuitive visual representations of the
structure of an ontology. They are, in general, not unambigu-
ous. In particular, this means that a particular node-edge-node
construction can take on many diﬀerent meanings. Instead, the
idea is to communicate that there is some relation between the
two concepts, and the more exact nature of the relation is de-
ferred to the formal axiomatization which is expressed in OWL
or some other suitable logic [9]. For additional reading on the
meaning behind schema diagram edges, see [14, 2]. For this pa-
per, we have modiﬁed the traditional syntax used in the MOMo
[15] methodology to better communicate the important con-
ceptual components when modeling with Wikibase, while ac-
knowledging the underlying complexity of what Wikibase au-
tomatically generates during RDF serialization.

9This has a few caveats which are discussed individually in the following

Figure 6: Enslaved Ontology: NameRecord representation.

Figure 6 is an example of a diﬀerent type, the intended use is
for recording names and name variants of persons. The most
natural candidates for qualiﬁers and references are again the
blue boxes, while the most natural candidate for the primary
relation is probably between Agent and the string, but we will
have to pick on of the three relations between NameVariant and
the string as the primary relation and relegate the other two to
qualiﬁers. In this case, however, we will not be able to have two
nodes between Agent and the string, as Wikibase produces only
one hash node. The natural grouping that the ontology provides
is thus lost, unless one takes the relation between NameRecord
and the string as the primary relation, which does not come nat-
urally from a modeling perspective. Another attempt to force
this into the Wikibase RDF model may be to make name vari-
ants qualiﬁers to the hash node; however since we cannot pro-
vide qualiﬁers to qualiﬁer relations (or to reference relations),
this would prohibit us from having, for example, provenance
information for name variants.

Regarding axiomatization of an underlying ontology, the Wik-
ibase approach also imposes some restrictions, and we will dis-
cuss these issues in more detail later in the paper.

Another method of describing the Wikibase model succinctly
would be to use a property graph [8], such as through the use of
RDF* and SPARQL*. However, there is currently not a method
for axiomatically describing these sorts of graphs.8

It may need emphasizing that we list the above limitations of
the Wikibase approach not in order to ﬁnd fault in it. Rather,
the RDF export realization appears to be a very clever use of
namespaces for the serialization of reiﬁcation. Most impor-
tantly, though, the Wikibase approach was put in place for a
very clearly deﬁned use case, namely to support the crowd-
sourced development of Wikidata. As such, it restricts the free-
dom of the user in choosing graph structure in both explicit and
implicit ways, by prompting the user to think (and structure the
data) in terms of primary relations with attached qualiﬁers and
references. This appears to be a very natural and, in many cases,
very adequate approach. However, these advantages also come
with the disadvantage of a certain loss of ﬂexibility, in particu-
lar pertaining to the representation of more strongly structured
and more ﬁne-grained data.

8In our search we did ﬁnd a corresponding OWL*, https://github.com/

cmungall/owlstar however, it is still in a draft prototype phase.

subsections.

10https://shex.io/

4

3.2. The Graphical Syntax

In our portal, we provide additional variations of Figure 7 that
are black & white print friendly, and a color-blind palette.11

Conceptual patterns and their expansions as diagrams
In each diagram (Figures 7-14), we have paired a conceptual
diagram (the upper diagram) and its expansion. The concep-
tual diagram, as we have previously described, is a method for
graphically depicting, in a succinct manner, “what is connected
to what, and how?” We have attempted to make this clear by
pairing the label colors with border colors. That is, an orange
label in the conceptual (top) diagram corresponds to the set of
node-edge-node constructs with orange coloring or borders in
the expanded (bottom) diagram.

Common Diagram Syntax
These colors and shapes are consistent across all diagrams in
Figures 7-14.

• Gold Rounded Rectangles: represent classes (objects).
• Purple Rounded Rectangles: represent classes belonging

to the Wikibase namespace.

• Yellow Ellipses: represent datatypes.
• Solid Arrow Heads: represent binary relations. If the tar-
get of the arrow is an ellipse, then it is a data property.
Otherwise it is an object property.

• Open Arrow Heads: represent a subclass relation.
• Dashed Edge Lines: represent an instanceOf relation.

Condensed Diagram Syntax
These colors and shapes are for the upper diagrams in Figures 7-
14.

• Green Rectangles: correspond to a collapsed statement. It
hides the underlying wikibase:Statement node and con-
necting properties.

• Orange Rectangles: correspond to a collapsed qualiﬁer.
• Diamond Arrow Heads: represent a connection to a quali-

ﬁer.

• Blue Rectangles: correspond to a collapsed reference.
• Circle Arrow Heads: represent a connection to a reference.

Expanded Diagram Syntax
These colors and shapes are for the lower diagrams in Figures 7-
14.

• Orange Colored Borders: indicate that the edge or rectan-
gle was originally hidden by the corresponding collapsed
label in the above diagram. Orange indicates that the col-
lapsed label is regarded a Qualiﬁer.

• Blue Colored Borders: indicate that the edge or rectangle
was originally hidden by the corresponding collapsed label
in the above diagram. Blue indicates that the collapsed
label is regarded a Reference.

• Hash Nodes: represent instances which are automatically
generated according to some hashing algorithm. In these
diagrams there are two appearances, in the s: namespace,
for wikibase:Statements, and the ref: namespace, for Ref-
erences on wikibase:Statement.

3.3. Axiomatization
The purpose of this section is to provide a reference axiomati-
zation of the Wikibase model. This allows us to specify axioms
over the conceptual diagrams, which we detail in Section 4.
These axioms are provided in Description Logic, for a primer
on this and the notation, please see [9]. Recall that property-
Name, qualiﬁerName, and referenceName are placeholders
to improve the clarity of these diagrams. They are meant to be
replaced when utilizing these patterns and their expansions. In-
deed, when replacing one, the corresponding occurrences will
all be replaced by the same predicate name, and they will then
be distinguishable by their namespaces.

For example, we may replace wdt:propertyName with
wdt:hasName and have the edge point to an xsd:string. At
that point, we would replace all instances of “propertyName”
with “hasName” across all namespaces in the diagram. We
would then use Figure 14 and the accompanying axiomatiza-
tion. Additional examples can be found in Section 5. Note
that we have used the xsd: namespace, which stands for XML
Schema Datatypes. These are a W3C standard way of repre-
senting data primitives [11].

Finally, recall that many of these structures can be directly seen
in Figure 1.

In the following sections, we provide the description logic for-
mulation of the axioms.12 We have shortened some preﬁxes and
predicates due to length:

1. wikibase: has been shortened to wb:
2. propertyName has been shortened to propName
3. qualiﬁerName has been shortened to qualName
4. referenceName has been shortened to refName
5. wasDerivedFrom has been shortened to wDF

3.3.1. Axioms Invariant to Exapnsion Type
In this section, we discuss those axioms that appear to be in-
variant under the expansion type, as seen in Figure 7.

∃ p:propName.(cid:62) (cid:118) wb:Item

Axiom 1 restricts the domain of p:propName to wb:Item.

(cid:62) (cid:118) ∀ p:propName.wb:Statement
(cid:62) (cid:118) ≤1 p:propName−.wb:Statement
(cid:62) (cid:118) ∃ p:propName−.wb:Statement

(1)

(2)

(3)

(4)

Axiom 2 restricts the range of p:propName to wb:Statement.
instances are reiﬁcations of the
Recall

that wb:Statement

11https://gitlab.cs.ksu.edu/daselab/wikibase-ontology-

12Additional information on the syntax and construction can be found in [9,

design-library

10].

5

Figure 7: The top diagram shows a condensed view of the Wikibase conceptual
model. The bottom diagram shows how the expansion of the diagram to include
the nodes that are automatically generated by the Wikibase framework. We use
a diamond arrowhead and orange color to denote Qualiﬁer nodes. A circle ar-
rowhead and blue color to denote Reference nodes. In the expanded diagrams
(in the lower portion), we change the border color of the nodes to indicate the
origin of the generated nodes.

wdt:propName relation, and carry the qualiﬁcations and ref-
erence information about a particular triple (i.e., statements).
Axiom 3 states that the inverse of p:propName is functional,
(i.e., inverse functionality). Axiom 4 states that the inverse of
p:propName is existential (i.e., inverse existential). Together,
Axioms 3 and 4 indicate that a wb:Statement has exactly one
inverse ﬁller for p:propName−1. This may also be speciﬁed
more succinctly using exact cardinality.

(cid:62) (cid:118) =1 p:propName−.wb:Statement

∃ ps:propName.(cid:62) (cid:118) wb:Statement

(5)

the

restricts

ps:propName to
Axiom 5
wb:Statement. Essentially, as a part of the reiﬁcation of
wdt:propName, ps:propName will always have an inverse
ﬁller of wb:Statement.

domain

of

Figure 8: Condensed (top) and expanded (bottom) schema diagrams with an
xsd:datetime for a qualiﬁer. Nodes bordered in orange expand from the label
node in the top diagram.

∃ pq:qualiﬁerName.(cid:62) (cid:118) wb:Statement

(8)

Axiom 8 restricts the domain of any pq:qualiﬁerName to
wb:Statement. In the Wikibase model, qualiﬁers are always
attached to the “hash nodes.” We will discuss in the later sec-
tions speciﬁc to the type of qualiﬁer the axioms pertaining to
range, functionality, and, etc.

3.3.2. Axioms between Items

p:propName ◦ ps:propName (cid:118) wdt:propName

(9)

Axiom 9 is a role chain that formalizes the reiﬁcation of
wdt:propName. From the previous axioms, we know that the
connecting ﬁller for the reiﬁcation is of type wb:Statement.
Additionally, we can infer the following.

∃ wdt:propName.(cid:62) (cid:118) wb:Item
∃ wdt:propName.wb:Item (cid:118) wb:Item
∃ wdt:propName−.(cid:62) (cid:118) wb:Item
∃ wdt:propName−.wb:Item (cid:118) wb:Item

(cid:62) (cid:118) ∀ p:propName.wb:Item
(cid:62) (cid:118) =1 ps:propName.wb:Item

(6)

(7)

Note that the latter two axioms are written using the inverse
form, as we wish to avoid having a role chain appear on the
right hand side of the axiom, which cannot be speciﬁed in OWL
2.

Axiom 6 restricts the range of ps:propName to wb:Item, acting
as the other half of the reiﬁcation for wdt:propName. Axiom 7
states that ps:propName has exactly one ﬁller of type wb:Item,
in the same manner as Axiom 4. These functionality and exis-
tential restrictions are necessary to mimic how and why these
wb:Statement nodes are created. They uniquely connect the
wdt:propName to the qualiﬁer and reference information.

3.3.3. Axioms Invariant for Qualiﬁers
Each type of qualiﬁer that Wikibase supports (i.e., Date, Nu-
meric, and String) have diﬀerent structures. In this section, we
only discuss those axioms that are invariant across these expan-
sions. For reference, they pertain to the expansions as seen in
Figures 8-10.

6

Figure 9: Condensed (top) and expanded (bottom) schema diagrams for mod-
eling with xsd:decimal as a qualiﬁer to wdt:propertyName.

There are two ways to restrict the nature of a qualiﬁer (i.e.,
the type) for a speciﬁc pq:qualName: scoped and un-scoped.
Scoped, in this case, means that the type of the Item being
qualiﬁed matters, whereas un-scoped is a global restriction on
pq:qualName.

The scoped restriction follows, in rule format.

∀x, y, z Item(x) ∧ p:propName(x, y)

∧ pq:qualName(y, z) −→ Qualiﬁer(z)

Note that in order to convert this into description logic, we will
need to use a complex, inverse domain restriction here. Since
a qualiﬁcation occurs on a wb:Statement instance, we need to
construct a role chain to the wb:Item and, as previously noted,
we cannot have role chains on the right hand side of an axiom
in OWL 2, we take the inverse of the range restriction, as seen
in Axiom 10.

∃ pq:qualName−. (cid:0)∃ p:propName−.Item(cid:1) (cid:118) Qualiﬁer

(10)

Figure 10: Condensed (top) and expanded (bottom) schema diagrams for mod-
eling with xsd:string as a qualiﬁer for wdt:propertyName.

this structure is shown in Figure 8. This expansion creates a
construction that incorporates metadata for the datetime, such
as the timezone and the temporal reference system, which is
done by creating a hash node in the v: namespace.

Axiom 13 indicates that the domain of pq:qualName is always
wb:Statement.

∃ pq:qualName.(cid:62) (cid:118) wb:Statement

(13)

Axiom 14 is the speciﬁc version of Axiom 10 (scoped range
restriction) for the xsd:dateTime qualiﬁer.

∃ pq:qualName−. (cid:0)∃ p:propName−.Item(cid:1) (cid:118) xsd:dateTime

(14)
Axiom 15 is the speciﬁc version of Axiom 11 (un-scoped range
restriction) for the xsd:dateTime qualiﬁer. Based on modeling
needs, one would choose only Axiom 14 or Axiom 15.

(cid:62) (cid:118) ∀ pq:qualName.wb:timeValue

(15)

Axiom 16 indicates that the domain of pqv:qualName is re-
stricted to wb:Statement.

∃ pqv:qualName.(cid:62) (cid:118) wb:TimeValue

(16)

Specifying an un-scoped range restriction on pq:qualName is
much simpler (Axiom 11).

Axiom 17 speciﬁes that the range of pqv:qualName is re-
stricted to wb:TimeValue.

(cid:62) (cid:118) ∀ pq:qualName.Qualiﬁer

(11)

(cid:62) (cid:118) ∀ pqv:qualName.wb:timeValue

(17)

We also note that the domain of pq:qualName is always a
wb:Statement.

∃ pq:qualName.(cid:62) (cid:118) wb:Statement

(12)

In Axiom 18, we formalize the notion that wb:TimeValue in-
stances are unique. That is, they are the ﬁller for at most one
pqv:qualName triple, and that it must qualify a wb:Statement.

wb:TimeValue (cid:118) =1 pqv:qualName−.wb:Statement

(18)

3.3.4. Axioms for Date Qualiﬁers
This section covers the axioms pertaining to the Wikibase
model when the qualiﬁer is a datetime. A graphical view of

We specify that the domain for each of the predicates (in
the wikibase namespace, timeValue, timePrecision, timeTime-
zone and timeCalendarModel,is wb:timeValue (which appears

7

Figure 11: Condensed (top) and expanded (bottom) schema diagrams including
a Reference for the assertions made by wdt:propertyName.

as a hashed node in the v: namespace in Figure 8). This is spec-
iﬁed in Axioms 19-22.

∃ timeValue.(cid:62) (cid:118) wb:timeValue
∃ timePrecision.(cid:62) (cid:118) wb:timeValue
∃ timeTimezone.(cid:62) (cid:118) wb:timeValue
∃ timeCalendarModel.(cid:62) (cid:118) wb:timeValue

(19)

(20)

(21)

(22)

We may also specify their ranges, globally, in Axioms 23-26.
We also indicate that they have an exact cardinality of one in
Axioms 27-30.

(cid:62) (cid:118) ∀ wb:timeValue.xsd:dateTime
(cid:62) (cid:118) ∀ wb:timePrecision.xsd:int
(cid:62) (cid:118) ∀ wb:timeTimezone.xsd:int
(cid:62) (cid:118) ∀ wb:timeCalendarModel.wd:Item
(cid:62) (cid:118) =1 wb:timeValue.xsd:dateTime
(cid:62) (cid:118) =1 wb:timePrecision.xsd:int
(cid:62) (cid:118) =1 wb:timeTimezone.xsd:int
(cid:62) (cid:118) =1 wb:timeCalendarModel.wd:Item

(23)

(24)

(25)

(26)

(27)

(28)

(29)

(30)

Finally,
it should be noted that whenever an assertion of
pq:qualName exists, there is an associated “hash node” that
accompanies it. We specify this in Axiom 31.

∃ pq:qualName.xsd:dateTime (cid:118)

Figure 12: Condensed (top) and expanded (bottom) schema diagrams when
modeling wdt:propertyName as a data property and the datatype is a
xsd:datetime.

Figure 13: Condensed (top) and expanded (bottom) schema diagrams when
modeling wdt:propertyName as a data property and the datatype is a
xsd:decimal.

3.3.5. Axioms for String Qualiﬁers
In this section, we cover the axioms pertaining to the Wikibase
model when the qualiﬁer is a string. A graphical view of this
structure is shown in Figure 10. Axiom 32 indicates that the
domain of pq:qualName is always wb:Statement.

∃ pq:qualName.(cid:62) (cid:118) wb:Statement

(32)

Axiom 33 is the speciﬁc version of Axiom 10 (scoped range
restriction) for the xsd:dateTime qualiﬁer.

∃ pq:qualName−. (cid:0)∃ p:propName−.Item(cid:1) (cid:118) xsd:string (33)

Axiom 34 is the speciﬁc version of Axiom 11 (un-scoped range
restriction) for the xsd:dateTime qualiﬁer. Based on modeling
needs, one would choose only Axiom 33 or Axiom 34.

∃ pqv:qualName.wb:TimeValue

(31)

(cid:62) (cid:118) ∀ pq:qualName.xsd:string

(34)

This ensures that the node carrying the additional contextual
data is connected to the interesting property name, and con-
nected back to the statement.

3.3.6. Axioms for Numeric Value Qualiﬁers
Wikibase uses xsd:decimal with wikibase:QuantityUnit for this
purpose. The pattern for using xsd:decimal as a qualiﬁer can

8

Figure 14: Condensed (top) and expanded (bottom) schema diagrams when
modeling wdt:propertyName as a data property and the datatype is a xsd:string.

be found in Figure 9. Qualifying with a quantity creates a con-
struction that incorporates the unit of the quantity, which is also
a wb:Item. It does this by creating another hash node of type
wb:QuantityValue, this time in the v: namespace. The hash
node is also referenced with qualName, but in the pqv: names-
pace. pq:qualName points directly to the amount.

∃ pq:qualName.(cid:62) (cid:118) wb:Statement

wb:Statement (cid:118) ∀ pq:qualName.xsd:decimal
wb:Statement (cid:118) ≤1 pq:qualName.xsd:decimal

(35)

(36)

(37)

Axiom 35 is a domain restriction. That is, the inverse ﬁller
(i.e., the domain) is restricted to wb:Statement. Axiom 36
is a scoped range restriction. That is, when the inverse ﬁller
(i.e., the domain) is of type wb:Statement, the ﬁller (i.e., the
range) of pq:qualName is restricted to xsd:decimal. Axiom
37 states that pq:qualName is functional. That is, a partic-
ular wb:Statement node targets at most one xsd:decimal via
pq:qualName.

∃ pqv:qualName.(cid:62) (cid:118) wb:Statement

(38)

Axiom 38 is a domain restriction. That is, the inverse ﬁller (i.e.,
the domain) is restricted to wb:Statement.

wb:Statement (cid:118) ∀ pqv:qualName.wb:QuantityValue (39)
wb:Statement (cid:118) ≤1 pqv:qualName.wb:QuantityValue (40)

Axiom 39 is a scoped range restriction.
is, when
the inverse ﬁller (i.e., the domain) is of type wb:Statement,
the ﬁller (i.e., the range) of pqv:qualName is restricted to
wb:QuantityValue. Axiom 40 states that pqv:qualName is
functional. That is, a particular wb:Statement node targets at
most one wb:QuantityValue via pqv:qualName.

That

∃ wb:quantityValue.(cid:62) (cid:118) wb:QuantityValue

(41)

9

Figure 15: The reconstructed module for SexRecord from the Enslaved Ontol-
ogy now using the Wikibase patterns.

wb:QuantityValue (cid:118) ∀ wb:quantityValue.xsd:decimal
(42)
wb:QuantityValue (cid:118) ∃ wb:quantityValue.wb:QuantityValue
(43)
wb:QuantityValue (cid:118) ≤1 wb:quantityValue.xsd:decimal (44)

Axiom 41 is a domain restriction. That is, the inverse ﬁller
(i.e.,
the domain) is restricted to wb:QuantityValue. Ax-
iom 42 is a scoped range restriction. That is, when the in-
verse ﬁller (i.e., the domain) is of type wb:QuantityValue,
the ﬁller (i.e., the range) of wb:quantityValue is restricted to
xsd:decimal. Axiom 43 states that wb:quantityValue is exis-
tential. That is, there is always at least one ﬁller. Axiom 44
states that wb:quantityValue is functional. That is, a particu-
lar wb:QuantityValue node targets at most one xsd:decimal via
wb:quantityValue.

∃ wb:quantityUnit.(cid:62) (cid:118) wb:QuantityValue

(45)

wb:QuantityValue (cid:118) ∀ wb:quantityUnit.wb:Item
(46)
wb:QuantityValue (cid:118) ∃ wb:quantityUnit.wb:QuantityValue
(47)

wb:QuantityValue (cid:118) ≤1 wb:quantityUnit.wb:Item

(48)

Axiom 45 is a domain restriction. That is, the inverse ﬁller
(i.e., the domain) is restricted to wb:QuantityValue. Axiom 46
is a scoped range restriction. That is, when the inverse ﬁller
(i.e., the domain) is of type wb:QuantityValue, the ﬁller (i.e.,
the range) of wb:quantityUnit is restricted to wb:Item. Axiom
47 states that wb:quantityUnit is existential. That is, there is
always least one ﬁller. Axiom 48 states that wb:quantityUnit is
functional. That is, a particular wb:QuantityValue node targets
at most one wb:Item via wb:quantityUnit.

Figure 16: The reconstructed module for NameRecord from the Enslaved On-
tology now using the Wikibase patterns.

3.3.7. Axioms for Statements
Axiom 13 is the speciﬁc version of Axiom 10 (scoped range
restriction) for the xsd:dateTime qualiﬁer.

∃ pq:qualName−. (cid:0)∃ p:propName−.Item(cid:1) (cid:118) xsd:dateTime

(49)
Axiom 14 is the speciﬁc version of Axiom 11 (un-scoped range
restriction) for the xsd:dateTime qualiﬁer. Based on modeling
needs, one would choose only Axiom 13 or Axiom 14.

(cid:62) (cid:118) ∀ pq:qualName.wb:timeValue

(50)

3.3.8. Axioms for References
In this section,

We only specify scoped range and domain restrictions over
prov:wasDerivedFrom, in order to avoid unwanted ontologi-
cal commitments in the event that the PROV Ontology [13] is
used elsewhere in a developed ontology, as in Axioms 51 and
52.

∃ prov:wDF.wb:Reference (cid:118) wb:Statement

(51)

wb:Statement (cid:118) ∀ prov:wDF.wb:Reference

(52)

It is always the case that the domain of pr:refName is a
wb:Reference (Axiom 53).

∃ pr:refName.(cid:62) (cid:118) wb:Reference

(53)

In the same manner that we have speciﬁed the range of
pq:qualName (i.e.
for
pr:referenceName.

Axioms 10 and 11), we will

∃ pr:referenceName−.

(∃ prov:wDF−.(∃ p:propName−.(cid:62)))

(cid:118) wb:Item

(54)

10

Figure 17: The reconstructed module for InteragentRelationshipRecord from
the Enslaved Ontology now using the Wikibase patterns.

∃ pr:refName.(cid:62) (cid:118) wb:Reference

(55)

Furthermore, if we wish to vary the type of reference based on
the domain of the statement assertion, we will need to construct
an axiom similar to Axiom 54.

∃ p:propName.

(∃ prov:wDF. (∃ pr:refName.(cid:62)))

(cid:118) wb:Item

(56)

Finally, we specify that a particular reference node is uniquely
the target of a Statement node. That is, prov:wasDerivedFrom
is restricted by an inverse existential and inverse functionality
axiom, which together form Axiom 57.

wb:Reference (cid:118) =1 prov:wDF−.wb:Reference

(57)

3.4. Resources
We have included a series of data shapes, for the purposes
of validating triples materialized against the axioms described
above. These are expressed in ShEx, the Shape Expression Lan-
guage13, which is a structural schema language for RDF graphs.
These are available online. These are expressed in ShEx as that
seems to be the Wikidata community’s adopted way of validat-
ing data.

We have also provided two serializations for this manuscript: an
OWL ﬁle containing the axiomatization of the Wikibase con-
ceptual model and an OWL ﬁle containing the list of axiom
patterns, as described in Section 4.

All of these resources are available online under Apache Li-
cense 2.0.14

13https://shex.io/
14See https://gitlab.cs.ksu.edu/daselab/wikibase-ontology-
design-library. We will provide a persistent URI in the ﬁnal version of
the manuscript.

Figure 18: The reconstructed module for OccupationRecord from the Enslaved
Ontology now using the Wikibase patterns.

4. Conceptual Modeling

Figure 19: The reconstructed module for ParticipatesInRecord from the En-
slaved Ontology now using the Wikibase patterns.

As previously discussed, the overarching purpose of these pat-
terns, and in particular the revised graphical syntax, is to sim-
plify the discussion surrounding the Wikibase model. The next
step is to improve our ability to conceptually reason about these
patterns. That is, to be able to specify constraints and restric-
tions, such as mandating that statements of a certain type must
always have a qualiﬁer, again of a certain type.

As such, we have taken the axiom patterns from [2] and, for
each such axiom pattern, provided a natural language approxi-
mation alongside the axiom patterns modiﬁed to suit the Wik-
ibase model. In this way, we can utilize the natural language to
do top-level conceptual reasoning and then, when it is time to
formalize the model, map these simple, natural language state-
ments into the formal axioms. Our methodology is as follows.

Recall that a triple has the form “Subject Predicate Object”.
One frequently encounters this via assertional statements, such
as “ex:dog1 ex:hasName “Fido”ˆˆxsd:string”. However, for
the purposes of the following discussion, we will use Subject to
refer, instead, to the Subject’s Type (i.e., moving up a layer of
abstraction). In this way, we would say “ex:Dog ex:hasName
xsd:string”, as it would appear as a node-edge-node construc-
tion in a schema diagram. In our axioms, we will use ex:Sub,
ex:Pred, and ex:Obj, respectively.

In our natural language, we describe statements relative to the
statement, and in particular the ex:Pred Statement. We will use
about to denote the Subject of a Statement and refers to to de-
note the Object of the statement. For example, “A ex:hasName
Statement is always refers to a ex:Name,” which we will see be-
low as the natural language approximation of the Range axiom
pattern.

We anticipate that these natural language approximations will
be used in conjunction with the formal model included above

11

in Section 4. As such, there may be some logical redundancies
when the formal model is combined with the suggested axioms
below. We do not consider this to be problematic and, indeed,
believe that the inclusion of both can aid human understanding.

Recall that

p:propName ◦ ps:propName (cid:118) wdt:propName

(58)

Domain: “A Predicate Statement is always about a Subject.”

∃p:propName.(cid:62) (cid:118) ex:Sub
∃wdt:propName.(cid:62) (cid:118) ex:Sub

(59)

(60)

Range: “A Predicate Statement always refers to an Object.”

(cid:62) (cid:118) ∀ps:propName.ex:Obj
(cid:62) (cid:118) ∀wdt:propName.ex:Obj

(61)

(62)

Scoped Domain: “A Predicate Statement that refers to an Ob-
ject, is always about a Subject.”

∃p:propName.(∃ps:propName.ex:Obj) (cid:118) ex:Sub
∃wdt:propName.ex:Obj (cid:118) ex:Sub

(63)

(64)

Axiom 63 is one such logically redundant axiom: Axioms 5,
7, and 58 together infer it. This fact is actually quite useful, as
it means we may specify restrictions on wdt:propName and it
remains consistent over the formal model.

Scoped Range: “A Predicate Statement that is about a Subject
always refers to an Object.”

ex:Sub (cid:118) ∀wdt:propName.ex:Obj

(65)

Figure 20: The reconstructed module for AgeRecord from the Enslaved Ontology now using the Wikibase patterns.

In line with Axiom 63, we should also have an axiom

ex:Sub (cid:118) ∀(p:propName ◦ ps:propName).ex:Obj

but, it cannot be expressed directly in OWL. However, with Ax-
ioms 58 and 65, we can infer it.

Functionality: “A Predicate Statement refers to at most one
Item.”

(cid:62) (cid:118) ≤1p:propName.(cid:62)
(cid:62) (cid:118) ≤1wdt:propName.(cid:62)

(66)

(67)

Note that there are variations of functionality, which we would
call qualiﬁed and scoped based on whether or not the Predicate
Statement is always about certain Subjects or refers to only cer-
tain Objects; these are described below.

Inverse Functionality: “A Predicate Statement is about at most
one Item.”

(cid:62) (cid:118) ≤1ps:propName-.(cid:62)
(cid:62) (cid:118) ≤1wdt:propName-.(cid:62)

(68)

(69)

Scoped Functionality: “A Predicate Statement is about at most
one Subject.”

ex:Sub (cid:118) ≤1p:propName.(cid:62)
ex:Sub (cid:118) ≤1wdt:propName.(cid:62)

(70)

(71)

Qualiﬁed Functionality: “A Predicate Statement refers to at
most one Object.”

(cid:62) (cid:118) ≤1p:propName.(cid:62)
(cid:62) (cid:118) ≤1wdt:propName.ex:Obj
(cid:62) (cid:118) ≤1ps:propName.ex:Obj

(72)

(73)

(74)

12

We need to include the third axiom which scopes the global
functionality statement for ps:propName.

Qualiﬁed Scoped Functionality:
about a Subject refers to at most one Object.”

“A Predicate Statement

ex:Sub (cid:118) ≤1p:propName.(cid:62)
ex:Sub (cid:118) ≤1wdt:propName.ex:Sub
ex:Sub (cid:118) ≤1ps:propName.ex:Obj

(75)

(76)

(77)

We need to include the third axiom which scopes the global
functionality statement for ps:propName.

Inverse Qualiﬁed Scoped Functionality: “A Predicate State-
ment that refers to an Object is about at most one Subject.”

ex:Obj (cid:118) ≤1ps:propName-.(cid:62)
ex:Obj (cid:118) ≤1wdt:propName-.ex:Sub

wb:Statement (cid:118) ≤1p:propName-.ex:Sub

(78)

(79)

(80)

Existential: “A Predicate Statement refers to at least one Ob-
ject.”

ex:Sub (cid:118) ∃p:propName.(cid:62)
ex:Sub (cid:118) ∃wdt:propName.ex:Obj

(81)

(82)

Inverse Existential: “A Predicate Statement is about at least
one Subject.”

ex:Obj (cid:118) ∃ps:propName.(cid:62)
ex:Obj (cid:118) ∃wdt:propName−.ex:Sub

(83)

(84)

Note that Inverse Existential axioms will only work when
in conjunction with a domain restriction axiom.
In essence,
p:propName is inverse functional, but because we do not

have any control over wb:Statement, we cannot state that
p:propName is also inverse existential, as that would inter-
fere every other wb:Statement. As such, we can state that
ps:propName is inverse existential, which means that there ex-
ists a wb:Statement node, and we can then assume the exis-
tence of something that points at that node. Yet we cannot si-
multaneously dictate the type of that node. However, if and
only if we have domain restriction axiom for p:propName, we
can together with the other axioms approximate Inverse Exis-
tentiality.

5. Case Study: The Enslaved Ontology

5.1. The Enslaved Ontology

The Enslaved Ontology serves as the underlying schema and
data organization paradigm for the Enslaved Hub. It is not used
for reasoning or inference, but as a guide for organizing and
integrating the data, and understanding the knowledge base as
a whole. As previously discussed, the Enslaved Ontology was
developed using a nascent version of the MOMo Methodology
and, furthermore, before the decision to use Wikibase as the un-
derlying implementation and infrastructure for serving the data.

The work described herein is a result of the mismatches be-
tween the original Enslaved Ontology (whose schema diagram
is shown in Figure 21) and how Wikibase stores information.

We have reconstructed the Enslaved Ontology using our mod-
iﬁed graphical syntax, resulting in Figure 23. The individual
modules appear in Figures 15 through 20. At this time, we have
only reconstructed some of the modules, with the remaining
modules relegated to future work.

6. Related Work

CIDOC-CRM

The CIDOC conceptual reference model (CIDOC-CRM) is an
informational model for representing cultural information [1].
As mentioned in Section 1, we are particularly interested in
persistence of data, but also facilitating robust deployment of
interacting with the data. While CIDOC-CRM is a domain-
standard way of annotating data, which improves the interoper-
ability of the data with other similarly described cultural data,
we would yet need to design a system capable of serving that
data. It is for this reason we initially chose to align to the Wik-
ibase model. Creating conceptual patterns between Wikibase
and CIDOC-CRM is potential future work.

OTTR

Reasonable Ontology Design Templates (OTTR) [18] is a
methodology for designing templates for concepts. A tutorial
can be found online.15 In particular, it allows for the schema
developer to design a base level template for a certain concept,
which can then be easily and programmatically expanded into

15https://ottr.xyz/

13

the appropriate axiomatization. However, it cannot currently
instantiate from the property graph formulation (our concep-
tual diagrams) to the expansions. Extending OTTR to work this
way, or identifying a suﬃciently capable workaround, is also
potential future work.

Property Graphs

Property graphs [8] allow for the speciﬁcation of predicates as
“ﬁrst-class citizens.” While this is a natural way of attaching
qualiﬁers and references to the wdt:propertyNames, it is not
currently possible to specify the more interesting axioms (such
as domain and range restrictions) in OWL over such graphs.
We look forward to evaluating how RDF* and SPARQL* will
be formalized from the upcoming W3C working group, which
may provide an additional way of modeling such data. It still
remains to be seen how semantics may be expressed over such
structures.

Open Data to Wikidata

the authors take a pattern-based approach to semi-
In [5],
automatically populating Wikidata from open (tabular) data.
This is similar in purpose to our work: persist data in a transpar-
ent manner and utilize the Wikibase model. However, it signiﬁ-
cantly departs from our work; foremost is that it is an automatic
framework that creates a naive schema from tabular data and
attempts to match these entities, and subsequent instance data,
to existing entities in Wikidata. This is a departure from our
approach which is to create a conceptual pattern library for the
development of rich schemas.

7. Conclusion

When developing and deploying a knowledge graph, there are
many obstacles to a persistent, transparent, and usable resource.
One way to overcome these obstacles is to use the Wikibase
framework. In this paper, we have represented several common
modeling constructions in a graphical syntax that makes it clear
how they map into the Wikibase context. This should allow on-
tology developers to more quickly, accurately, and with reduced
eﬀort create ontologies (or knowledge graph schema) that are
“Wikibase ready,” thus improving persistence and accessibility
of the deployed knowledge graph.

Future Work

There is certainly additional work to be accomplished in this
direction. In particular, we see the following as immediate next
steps to take.

• Identiﬁcation of frequent CIDOC [1] patterns and corre-

sponding translation into Wikibase patterns.

• Extension of OTTR [18] to allow for instantiations from

the conceptual diagrams.

• Develop a robust or extend a tooling system (e.g., CoMo-
dIDE [15] for directly using these “Wikibase-iﬁed” axiom
patterns.

Figure 21: The original Enslaved Ontology

14

Figure 22: A reconstruction of some of the modules from the Enslaved Ontology as mapped into the Wikibase model. Recall that purple rounded rectangles indicate
that that class is controlled, i.e., as in a controlled vocabulary.

15

Figure 23: A reconstruction of some of the modules from the Enslaved Ontology using the Wikibase patterns and modiﬁed graphical syntax. Recall that purple
rounded rectangles indicate that that class is controlled, i.e., as in a controlled vocabulary.

16

[12] V. Presutti, E. Daga, A. Gangemi, and E. Blomqvist. eXtreme Design
with content ontology design patterns.
In E. Blomqvist, K. Sandkuhl,
F. Scharﬀe, and V. Svátek, editors, Proceedings of the Workshop on On-
tology Patterns (WOP 2009), collocated with the 8th International Se-
mantic Web Conference (ISWC-2009), Washington D.C., USA, 25 Octo-
ber, 2009., volume 516 of CEUR Workshop Proceedings. CEUR-WS.org,
2009.

[13] S. Sahoo, D. McGuinness,

PROV ontology.
http://www.w3.org/TR/2013/REC-prov-o-20130430/.

The
W3C recommendation, W3C, Apr. 2013.

and T. Lebo.

PROV-o:

[14] C. Shimizu, A. Eberhart, N. Karima, Q. Hirt, A. Krisnadi, and P. Hitzler.
A method for automatically generating schema diagrams for modular on-
tologies. In 1st Iberoamerican Conference on Knowledge Graphs and the
Semantic Web, 2019. To Appear.

[15] C. Shimizu, K. Hammar, and P. Hitzler. Modular ontology modeling.

Semantic Web, 2021. In Press.

[16] C. Shimizu, Q. Hirt, and P. Hitzler. MODL: A modular ontology design li-
brary. In K. Janowicz, A. A. Krisnadhi, M. Poveda-Villalón, K. Hammar,
and C. Shimizu, editors, Proceedings of the 10th Workshop on Ontology
Design and Patterns (WOP 2019) co-located with 18th International Se-
mantic Web Conference (ISWC 2019), Auckland, New Zealand, October
27, 2019, volume 2459 of CEUR Workshop Proceedings, pages 47–58.
CEUR-WS.org, 2019.

[17] C. Shimizu, P. Hitzler, Q. Hirt, D. Rehberger, S. G. Estrecha, C. Foley,
A. M. Sheill, W. Hawthorne, J. Mixter, E. Watrall, R. Carty, and D. Tarr.
The Enslaved ontology: Peoples of the historic slave trade. J. Web Se-
mant., 63:100567, 2020.

[18] M. G. Skjæveland, D. P. Lupp, L. H. Karlsen, and H. Forssell. Practical
ontology pattern instantiation, discovery, and maintenance with reason-
able ontology templates. In D. Vrandecic, K. Bontcheva, M. C. Suárez-
Figueroa, V. Presutti, I. Celino, M. Sabou, L. Kaﬀee, and E. Simperl, ed-
itors, The Semantic Web – ISWC 2018 – 17th International Semantic Web
Conference, Monterey, CA, USA, October 8-12, 2018, Proceedings, Part
I, volume 11136 of Lecture Notes in Computer Science, pages 477–494.
Springer, 2018.

[19] M. D. Wilkinson, M. Dumontier, et al. The FAIR guiding principles for
scientiﬁc data management and stewardship. Scientiﬁc Data, 3:160018,
Mar 2016.

[20] L. Zhou, C. Shimizu, P. Hitzler, A. M. Sheill, S. G. Estrecha, C. Foley,
D. Tarr, and D. Rehberger. The Enslaved dataset: A real-world complex
ontology alignment benchmark using wikibase.
In M. d’Aquin, S. Di-
etze, C. Hauﬀ, E. Curry, and P. Cudré-Mauroux, editors, CIKM ’20: The
29th ACM International Conference on Information and Knowledge Man-
agement, Virtual Event, Ireland, October 19-23, 2020, pages 3197–3204.
ACM, 2020.

• Create a MODL [16] of Wikibase-compatible patterns
(e.g., by taking each pattern in MODL 1.0 and translating
them using the axiom patterns above).

Acknowledgement. The authors acknowledge support by the
National Science Foundation under Grant 2032628 EAGER:
Open Science in Semantic Web Research and Grant 2033521
A1: KnowWhereGraph: Enriching and Linking Cross-Domain
Knowledge Graphs using Spatially-Explicit AI Technologies,
as well as the Mellon Foundation through the Enslaved: Peo-
ples of the Historical Slave Trade.

References

[1] M. Doerr. The CIDOC conceptual reference module: An ontological
approach to semantic interoperability of metadata. AI Mag., 24(3):75–92,
2003.

[2] A. Eberhart, C. Shimizu, S. Chowdhury, M. K. Sarker, and P. Hitzler.
Expressibility of OWL axioms with patterns. In R. Verborgh, K. Hose,
H. Paulheim, P. Champin, M. Maleshkova, Ó. Corcho, P. Ristoski, and
M. Alam, editors, The Semantic Web - 18th International Conference,
ESWC 2021, Virtual Event, June 6-10, 2021, Proceedings, volume 12731
of Lecture Notes in Computer Science, pages 230–245. Springer, 2021.
[3] A. Eells, L. Zhou, C. Shimizu, P. Hitzler, S. G. Estrecha, and D. Re-
hberger. Aligning patterns to the wikibase model. In Proceedings of the
12th Workshop on Ontology Design and Patterns, WOP 2021 at the 20th
International Semantic Web Conference (ISWC 2021), October 2021,
2021. Available from: https://daselab.cs.ksu.edu/publications/aligning-
patterns-wikibase-model.

[4] F. Erxleben, M. Günther, M. Krötzsch, J. Mendez, and D. Vrandecic.
Introducing wikidata to the linked data web. In P. Mika, T. Tudorache,
A. Bernstein, C. Welty, C. A. Knoblock, D. Vrandecic, P. Groth, N. F.
Noy, K. Janowicz, and C. A. Goble, editors, The Semantic Web – ISWC
2014 – 13th International Semantic Web Conference, Riva del Garda,
Italy, October 19-23, 2014. Proceedings, Part I, volume 8796 of Lecture
Notes in Computer Science, pages 50–65. Springer, 2014.

[5] M. Faiz, G. M. F. Wisesa, A. A. Krisnadhi, and F. Darari. OD2WD: from
open data to wikidata through patterns. In K. Janowicz, A. A. Krisnadhi,
M. Poveda-Villalón, K. Hammar, and C. Shimizu, editors, Proceedings
of the 10th Workshop on Ontology Design and Patterns (WOP 2019) co-
located with 18th International Semantic Web Conference (ISWC 2019),
Auckland, New Zealand, October 27, 2019, volume 2459 of CEUR Work-
shop Proceedings, pages 2–16. CEUR-WS.org, 2019.

[6] A. Gangemi and V. Presutti. Ontology design patterns. In S. Staab and
R. Studer, editors, Handbook on Ontologies, International Handbooks on
Information Systems, pages 221–243. Springer, 2009.

[7] K. Hammar and V. Presutti. Template-based content ODP instantiation. In
K. Hammar, P. Hitzler, A. Krisnadhi, A. Lawrynowicz, A. G. Nuzzolese,
and M. Solanki, editors, Advances in Ontology Design and Patterns [re-
vised and extended versions of the papers presented at the 7th edition
of the Workshop on Ontology and Semantic Web Patterns, WOP@ISWC
2016, Kobe, Japan, 18th October 2016], volume 32 of Studies on the
Semantic Web, pages 1–13. IOS Press, 2016.

[8] O. Hartig. Foundations of rdf(cid:63) and sparql(cid:63) (an alternative approach to
statement-level metadata in RDF). In J. L. Reutter and D. Srivastava, edi-
tors, Proceedings of the 11th Alberto Mendelzon International Workshop
on Foundations of Data Management and the Web, Montevideo, Uruguay,
June 7-9, 2017, volume 1912 of CEUR Workshop Proceedings. CEUR-
WS.org, 2017.

[9] P. Hitzler, M. Krötzsch, and S. Rudolph. Foundations of Semantic Web

Technologies. Chapman and Hall/CRC Press, 2010.

[10] M. Krötzsch, F. Simancik, and I. Horrocks. A description logic primer.

CoRR, abs/1201.4089, 2012.

[11] D. Peterson, A. Malhotra, S. Gao, P. V. Biron, H. Thompson, and
M. Sperberg-McQueen. W3C xml schema deﬁnition language (XSD)
1.1 part 2: Datatypes. W3C recommendation, W3C, Apr. 2012.
https://www.w3.org/TR/2012/REC-xmlschema11-2-20120405/.

17

