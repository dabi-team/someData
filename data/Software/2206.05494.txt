2
2
0
2

n
u
J

4
1

]
E
S
.
s
c
[

2
v
4
9
4
5
0
.
6
0
2
2
:
v
i
X
r
a

11TH SEMINAR ON LINEAR ALGEBRA AND ITS APPLICATIONS

Parallelization of Software Systems Test Case Selection Algorithm
Based on Singular Value Decomposition

M. Movahedian Moghaddama

aDepartment of Data and Computer Science,Faculty of Mathematical Science, Shahid
Beheshti University, Tehran, Iran

ARTICLE HISTORY
Compiled June 15, 2022

ABSTRACT
When developing a software system, a change in one part of the system may lead to
unwanted changes in other parts of the system. These aﬀected parts may interfere
with system performance, so regression testing is used to deal with these disorders.
This test seeks to re-measure these sections to prevent these abnormalities, but it is
diﬃcult to identify these sections for re-examination. We try to cluster the changes of
our software system based on the system functions by singular value decomposition,
to be able to use to identify these parts during a new change, to perform the test
again. In order to increase speedup, our calculations were performed in parallel
on shared memory systems so that by increasing the scale of software systems, an
optimal answer could be obtained.

KEYWORDS
singular value decomposition, regression software test, reduction of parallel test
cases, parallel clustering of test cases

1. Introduction

Today in software systems development After a period of development, it may be
necessary to make changes to previously developed components. These changes may
aﬀect other parts of the software. These eﬀects may cause new system malfunctions.
To prevent these unwanted disorders, a type of software test called regression test is
used.
Regression testing uses existing test cases to check whether the changes made did not
cause a new error or had unwanted side eﬀects. In other words, the goal is to ensure
that parts of a system that have not changed continue to work as they did before
the changes.[5] All of them successfully commented on the correct operation of the
system. Obtaining this set of test cases will not be so easy, so that the integer linear
programming methods are used today to ﬁnd this set of test cases.[2]
We are trying to obtain this set of test cases by clustering by singular value decom-
position on a matrix of functions used in the system that are close in time changes.
This information will be easily obtained with the help of source control tools that are
used in most software systems companies today. Due to the high volume of functions
in commercial software systems, we used a parallel approach during this clustering to

CONTACT M. Movahedian Moghaddam. Email: m.movahedian@mail.sbu.ac.ir

 
 
 
 
 
 
enable this approach to be used in large commercial systems in the shortest possible
time.
In the second part of this research, the methods used are introduced and in the third
part of these methods to perform data clustering and then extract this data from a
software system in parallel and ﬁnd a set of test cases that should be used for A spe-
ciﬁc change vector to be retested has been used, in the fourth section the experimental
results of this research and the ﬁfth section for the ﬁnal conclusion.

2. Related Works

This section deals with the related work done in the ﬁeld of selecting regression test
cases, as well as source code clustering and parsing of individual values.

2.1. Selection of regression test cases

Regression testing is the process of re-testing software, which is modiﬁed. Large sys-
tems usually have large regression test sets. In a software system, small changes in one
part of a system often cause problems in other parts of the system.[1]
Regression testing is used to ﬁnd these types of problems. The purpose of regression
test selection techniques is to isolate tests that may detect errors after the system has
been modiﬁed. The simplest regression test selection technique is a retest strategy in
which the entire set of test cases is examined.[4]

2.2. Source code clustering

Nowadays, source code clustering has become especially important for its application in
plagiarism detection systems, including the eﬀort (Duracik et al.) To try to cluster the
source code of a system line by line. They had software based on the kmeans clustering
algorithm, which then, taking an incremental approach to this clustering, completed
the search by vector source code. In this research, we have developed clustering of
source code changes based on function changes.[3]

2.3. Parallel singular value decomposition

In recent years, several parallelizations have been performed on the singular value
decomposition algorithm. In an attempt (Xiao et al.), We have witnessed the paral-
lelization of the mentioned algorithm based on Jacobi block parallelization.[6]
In this study, in addition to the algorithm parallelization singular value decomposi-
tion, we developed the extraction of information of our clusters in parallel. This parallel
development is much more suitable for use by commercial software companies’ infras-
tructures, because large commercial companies with stronger hardware infrastructures
are generally developing software systems that are in great need of this type of test.

3. The Proposed Method

This research presents an algorithm that based on changes in functions in a software
system source code, can identify a set of functions that have a greater impact on each

2

other and by singular value decomposition, a clustering is achieved that through this
clustering Can produce a more concise set of regression test cases. All of the above
algorithms have been developed in parallel on shared memory systems to increase
performance. The above algorithm 1 as follows.

Algorithm 1: Parallel Selection of Test Cases Using SVD
1 M atrix F ← new M atrix()
2 M atrix T ← new M atrix()
3 M atrix R ← new M atrix()
4 V ector X ← new V ector()

5 [U, S, V ] ← P SV D(F ) // Execute Parallel SVD

Parallel Section:

6 forall i ∈ U.rows \ {r} do
7

forall j ∈ U.columns do

8

if threshold ≤ |U [i, j]| then // filtering by threshold value

Critical Section:
R ← P ositiveElements(U [i])
R ← N egativeElements(U [i])

9 P ← T × R
10 Y ← R × P T
11 S ← Y × X

3.1. Preliminary data

In resource control systems, all changes to the source code of a software system are
recorded during development by the software system.
These changes can be seen in the form of a history at diﬀerent levels such as ﬁles and
functions or even changed lines.
We observed these changes at the function level and limited the execution of system
test cases to functions. This was done for two reasons, the ﬁrst of which can be stated
that if we examine the changes at the ﬁle level, it may be due to The large number
of lines of source code in each ﬁle is not accurate, and the second reason is that we
did not limit the source code changes to the level of the changed lines because the
dimensions of our change matrices increased dramatically, making them very thin in
problem. Been. For these reasons, it was decided to examine the source code changes
at the level of function changes.
To prepare the required data, we create a square matrix of the order of the number of
functions under study, each of which represents the existence of changes between two
functions with each other through this source control system. This matrix is called F .
This relationship is two-way, meaning that if changes to the i and j functions are made,
both the junctions associated with (j, i) F and (i, j (F) must be set, so the matrix F
is symmetric. The dimensions of M × M will be that M is the number of functions
considered.
Another matrix that is required is the T matrix, each of which represents the relation-
ship between each test case and the functions of that software system. This matrix
is not necessarily symmetric because the number of test cases will not necessarily be
the same as the number of functions and a test case may be related to a number of

3

functions or vice versa. This matrix will also have M × T C dimensions where T C
represents the number of test cases.

3.2. Parallel clustering by singular value decomposition

As mentioned, the matrix F , due to its symmetry and positive deﬁnite, has the
singular value decomposition with the same values as U and V .
After performing the decomposition of singular values on the F matrix, the optimal
output is three matrices Σ, U , V .

F =









3 1 3 4 2
1 0 0 4 0
3 0 1 1 0
4 4 1 2 0
2 0 0 0 1









, T =











1 0 0 0 0
0 1 0 0 0
0 0 1 0 0
0 0 1 1 0
0 0 1 1 1
0 0 0 1 1











(1)

After singular value decomposition and running the two loops in parallel in the
algorithm to produce the desired clusters, we will obtain a matrix that will be in
C × M dimensions and so on. To prevent values from being written simultaneously
by two parallel executable units (such as a thread or process), we used critical section
to prevent invalid values from being written in one thread of the R matrix.









R =

0.00
0.00

−0.64
0.4
−0.33 0.59
0.47
−0.31 0.00 −0.11 0.00 −0.41 0.58
−0.59 0.00 −0.66 0.44
−0.15 0.00 −0.16 0.00 −0.45 0.36

0.00 −0.36 0.00 −0.53 0.00 0.00
0.15 0.00
0.53
0.6
0.00
0.00 −0.09 0.03 0.00
0.77 0.00

0.00
0.00

0.00

0.00

0.00









(2)

Each column of this matrix, or in other words, each cluster of this set, represents
functions that have undergone more changes in relation to each other. Setting this
limit of dependence between functions depends on setting the threshold value in the
algorithm and is directly related to it, so that as we increase the threshold, we will
have clusters that have elements with more dependencies.

3.3. Generate reduced sets of test cases

After obtaining the R matrix with the help of the T matrix, a kind of relationship
should be established between the regression test cases and these resulting clusters.
So by transposing the multiplication of those two matrices, we get a matrix that will
show in a clustered manner the test cases that must be examined for each function
change. This resulting matrix is called Y .

4

Y = R ∗ (T ∗ R)T =









0.00
0.00

−0.64
0.4
−0.33 0.59
0.47
−0.31 0.00 −0.11 0.00 −0.41 0.58
−0.59 0.00 −0.66 0.44
−0.15 0.00 −0.16 0.00 −0.45 0.36


0.00 −0.36 0.00 −0.53 0.00 0.00
0.15 0.00
0.53
0.6
0.00
0.00 −0.09 0.03 0.00
0.77 0.00

0.00
0.00

0.00

0.00

0.00









∗
















0.00

0.00

−0.64 −0.33 −0.31 −0.90 −1.05 −1.05
0.59
0.40
0.00
0.00
0.00 −0.11 −0.77 −0.93 −0.93
0.00
0.53
0.00
0.44
0.44
0.00 −0.41 −0.41 −0.86 −0.86
−0.36
0.58
0.47
0.00
0.94
0.58
0.00 −0.09 −0.09 −0.09
0.00
−0.53
0.08
0.00
0.15
0.00
0.60
0.60
0.00
0.00

0.08
0.60

0.03
0.60

0.00

0.44

0.94






















=

0.98 0.44 0.34 0.77 1.02 1.02
0.44 0.98 0.37 0.80 1.14 1.14
0.34 0.37 0.97 1.22 1.68 1.68
0.42 0.43 0.25 1.24 1.45 1.45
0.25 0.33 0.45 0.67 1.64 1.64









(3)
Therefore, for each change vector, X has dimensions of 1 × M , which only represent
the changed functions. By applying the multiplication operation to the Y matrix
transcript, the set of test cases that should be re-examined in this version of the
software can be determined.

X =










0
1


1


0

1

, Y T ∗ X =





















1.05
1.69
1.80
2.71
4.47
4.47

(4)

The resulting vector represents the set of test cases that should be reconsidered in
return for these changes. This result indicates that test cases 5 and 6 have a higher
priority for re-implementation than other test cases.

4. Experimental results

In this section, we examined what challenges we would face if we examined changes in
system functions instead of changing the ﬁles of a software system, in order to increase
accuracy.
In examining the changes of functions together, we will face much larger dimensions of
the input matrices, because the number of functions of a system is much larger than the
number of ﬁles of that system, this approach creates a computational challenge for the
developers of a software system. For this reason, we presented a parallel approach to the
above algorithm instead of a sequential approach. In this section, we try to compare
the two and analyze the points that are more suitable for parallel execution of the
algorithm. To perform our test, we used a shared memory multiprocessor system with
four third-generation processors clocked at 9.2 GHz by Intel, along with implementing
two parallel and sequential versions of the above algorithm.
We use source control systems to collect data related to software system changes. These

5

systems are able to record software product changes at any time for any changes made
by any member of the software development team.
As you can see in Table 1, for matrix dimensions less than 20 parallel methods have
a longer execution time than the sequential method, but for dimensions larger than
this value the parallel method has a lower execution speed. Because our research has
matrices with very high input dimensions due to the study of changes in functions
with each other, we propose the use of a parallel approach.

Table 1. Execution time of models

Dimention
Parallel
Sequential

16
9.27
7.81

17
15.55
15.35

18
30.25
27.84

19
8.71
7.88

20
77.08
79.98

21
113.32
121.07

22
135.53
137.53

23
48.00
50.45

24
42.91
47.84

25
113.80
118.35

26
58.32
59.77

Figure 1. Execution time of serial and parallel models

According to Figure 1, this parallelization has been performed on 11 diﬀerent
dimensions of matrices resulting from changes in a software system, and the resulting
disturbances are due to the amount of thinness of each matrix. There is no compar-
ison between the two parallel and sequential approaches and the result of these two
approaches. These changes are due to the fact that in one version of the software
there were fewer changes than other versions.

5. Conclusion

In the approach introduced by (Sherriﬀ et al.) Due to the study of ﬁle changes and the
consequent low size of the problem, there was no need for parallelism.[4] But in the
approach introduced by us due to increased accuracy and review of modiﬁed functions
In the ﬁles, we were faced with an increase in the size of the problem that we were able
to overcome this computational challenge with the parallel approach presented. as a
result; This research, which has been developed using a parallel approach to source
code clustering based on changes in functions, has a much higher operational accuracy
than research based on changes in source code ﬁles.

6

References

[1] P. Ammann, J. Oﬀutt, Introduction to Software Testing, Cambridge University Press,

Cambridge, 2017.

[2] C. Chi-Lun ,H. Chin-Yu ,C. Chang-Yu ,C. Kai-Wen and L. Chen-Hua, Analysis and assess-
ment of weighted combinatorial criterion for test suite reduction, Quality and Reliability
Engineering International, (2021), 1–31.

[3] M. Duracik,E. Krsak and P. Hrkut, Searching source code fragments using incremental
clustering, Concurrency and Computation Practice and Experience, 32 (2020), No. 13
[4] M. Sherriﬀ, M. Lake and L. Williams, Prioritization of Regression Tests using Singu-
lar Value Decomposition with Empirical Change Records, The 18th IEEE International
Symposium on Software Reliability (ISSRE ’07), (2007).

[5] A. Spillner, T. Linz,Software Testing Foundations A Study Guide for the Certiﬁed Tester

Exam, Rocky Nook, 2021.

[6] P. Xiao, Z. Wang and S. Rajasekaran, Novel Speedup Techniques for Parallel Singular
Value Decomposition, 20th International Conference on High Performance Computing
and Communications, 2018.

7

