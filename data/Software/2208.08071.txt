An Efficient Multi-Step Framework for Malware Packing Identification   

Jong-Wouk Kim1, Yang-Sae Moon1,2, and Mi-Jung Choi1,2,* 

Department of Computer Science, Kangwon National University1 

IGP. In Bigdata Convergence, Kangwon National University2 

{jw.kim, ysmoon, mjchoi}@kangwon.ac.kr 

Abstract 

Malware developers use combinations of techniques such as compression, encryption, and obfuscation to 

bypass anti-virus software. Malware with anti-analysis technologies can bypass AI-based anti-virus software 

and malware analysis tools. Therefore, classifying pack files is one of the big challenges. Problems arise if the 

malware  classifiers  learn  packers'  features,  not  those  of  malware.  Training  the  models  with  unintended 

erroneous data turn into poisoning attacks, adversarial attacks, and evasion attacks. Therefore, researchers 

should consider packing to build appropriate malware classifier models. In this paper, we propose a multi-

step framework for classifying and identifying packed samples which is consists of pseudo-optimal feature 

selection, machine learning-based classifiers, and packer identification steps. In the first step, we use the CART 

algorithm and the permutation importance to preselect important 20 features. In the second step, each model 

learns 20 preselected features for classifying the packed files with the highest performance. As a result, the 

XGBoost, which learned the features preselected by XGBoost with the permutation importance, showed the 

highest performance than any other experiment scenarios with an accuracy of 99.67%, an F1-Score of 99.46%, 

and an area under the curve (AUC) of 99.98%. In the third step, we propose a new approach that can identify 

packers only for samples classified as Well-Known Packed. 

1 

 
 
 
1.  Introduction 

Malware is one of the persistent and serious problems in cybersecurity. Despite advances in security 

technologies, it is still difficult to detect and defend against malware threats. At the opening ceremony 

of the 2018 Pyeongchang Winter Olympics, a serious problem occurred that Cisco's Wi-Fi and official 

website were interrupted. They found out that malware threats cause serious problems through internal 

investigations [1]. Effective malware detection and analysis  have become an essential element for the 

users and service vendors in order to minimize various problems that can occur due to malware such 

as personal information leakage, brand reputation degradation, and service quality degradation. 

Analysts  collect  and  analyze  malware  to  prevent  the  spread  of  malware.  However,  malware 

developers also use a variety of anti-analysis techniques such as packing, anti-VM, and anti-debugging 

to extend the lifespan of malware. Among the many anti-analysis techniques, packing compresses and 

encrypts the original program and adds anti-analysis techniques that interfere with the analysis. The 

stub code unpacks the original program when a user executes a packed file. As shown in Figure 1, the 

packer appends various anti-analysis techniques while compressing the code and data sections of the 

original program into one or more sections. When the packed file is loaded and executed in memory, 

stub  code  unpacks  the  encrypted  data  in  the  same  section  or  another  section  to  execute  the  original 

program. 

Figure 1. The flow of packing the original program and executing the packed program 

2 

 
 
Figure 2. An example workflow for analyzing malware 

Analysts  analyze  malware  using  automatic,  static,  dynamic,  and  advanced  analysis,  as  shown  in 

Figure 2. Automated analysis is one of the analysis methods that uses APIs or automated tools such as 

sandboxing tools or VirusTotal to discover the flow or type of malware. Static analysis is an analysis 

method that analyzes the characteristics of strings, headers, and functions by decomposing the malware 

itself using HxD, PE View, and Strings to obtain the static characteristics and information of the malware. 

Dynamic analysis is an analysis method that executes malware and observes actual behavior. Analysts 

use tools such as WireShark and TCP View to monitor network communications, and monitor processes 

using tools such as Process Explorer. Analysts use debuggers or other tools to observe and analyze the 

behavior, memory, registers, and registry of malware details in advanced analysis. 

However,  malware  developers  bypass  antivirus  systems  and  analysis  by  combining  anti-analysis 

techniques  such  as  packing,  anti-VM,  and  anti-debugging.  Researchers  can  only  collect  information 

inserted  by  the  packer  instead  of  the  original  program  if  they  collect  packed  malware  samples  and 

extract features from them. In dynamic analysis, packed malware can detect and bypass the analysis 

environment, and the analysis result may differ from the actual  malicious behavior. In the advanced 

analysis, analysts need more time and effort due to anti-analysis techniques such as anti-debugging and 

anti-emulation  of  the  packed  malware.  Many  researchers  consistently  study  models  for  detecting 

malware by combining the sequence of machine language (opcode) and deep learning [2][3]. However, 

they do not consider encryption such as packing and obfuscation.   

3 

 
 
Packing not only interferes with the detection and analysis of malware but can also attack machine 

learning-based malware detection models while training them. Kearns and Li demonstrated a range of 

maliciously  selected  errors  in  the  training  data  of  the  Valiant's  Probably  Approach  Correct  (PAC) 

training  framework,  proving  that  a  model  must  have  at  least  a  certain  percentage  of  correct  data  to 

function properly [4][5][6][7]. If a poisoning attack occurs while the model is training, the model may 

be biased  incorrectly due  to inappropriate and adversarial  examples. To prevent such problems and 

accurately detect malware, it is essential to consider packed samples while the model is training. 

In  addition,  packed  files  continue  to  increase  every  year.  Rahbarina  et  al.  surveyed  three  million 

samples collected in 2014 and found that 58% of malicious files and 54% of benign files were packed by 

well-known packers [8]. Morgenstern and Pilz found that 35% of malicious files were packed by custom 

packers  [9].  Pedrero  et  al.  classified  packers  into  six  groups  and  found  malware  samples  that  were 

packed multiple times by custom packers. Among them, the authors found that 65.6% of packers had 

inconsistent unpacking routines [10].   

In  this  paper,  we  propose  a  step-by-step  framework  that  found  the  pseudo-optimal  features, 

classifying packed malware into the Not Packed, Custom Packing, and Well-known Packed. At last, the 

framework  identifies  packers  that  classified  as  the  Well-known  Packed  by  the  model  in  step  2.  This 

paper presents the following contributions: 

(1)  We propose a novel multi-step framework consisting of feature selection, packed classification, and 

packer identification steps. 

(2)  We present a pseudo-optimal feature selection for packed malware detection exploiting the CART 

algorithm and the permutation importance with various decision trees. 

(3)  Using  a  small  number  of  preselected  features,  we  trained  light  machine  learning  models  that 

determine whether a file is packed or not. 

(4)  Analyzing the large-scale of a well-known packed malware, we classify the type of the packer. 

4 

 
(5)  We proved our framework by analyzing and experimenting with various experimental scenarios. 

The composition of this paper is as follows. Section 2 introduces malware detection, packing detection, 

and  adversarial  attacks  on  machine  learning  models.  Section  3  describes  the  multi-step  framework 

proposed  in  this  paper.  In  the  first  step,  we  preselect  pseudo-optimal  features  for  detecting  and 

classifying packed malware using the CART algorithm and the permutation importance. The machine 

learning  models  classify  samples  into  Not  Packed,  Custom  Packed,  and  Well-known  Packed  in  the 

second step. In the third step, the framework can identify the packer of the sample classified as Well-

known Packed. Section 4 describes the experiments and evaluates each step in the multi-step framework. 

XGBoost  that  learns  preselected  features  by  XGBoost  and  the  permutation  importance  achieved  the 

highest  performance  among  the  experimental  scenarios  and  the  recent  work.  In  the  third  step,  it 

identifies the  packer of the sample  which is classified as  the  Well-known Packed, and we compared 

results with an existing tool. Section 5 summarizes the proposed framework and describes the future 

research. 

5 

 
 
2.  Related Work 

2.1  Malware classification using machine learning 

Figure 3. Flowchart of malware detection architecture using machine learning 

Machine learning is a useful algorithm for solving classification, clustering, and regression problems. 

Many researchers try to solve cybersecurity problems using machine learning models.  They analyze 

malware samples, find robust features to build an accurate classifier, and study effective models to end 

this endless war between attackers and security engineers. Figure 3 is a simplified flow diagram of the 

malware  detection  architecture  based  on  a  machine  learning  model.  It  is  essential  to  find  the  robust 

features by analyzing malicious and benign samples, and the model learns these features. We can get 

these features through the analysis methods shown in Figure 2. 

Nataraj et al. proposed a malware classifying method for the first time that visualizes malware binary 

files as grayscale images and calculates the similarity between the images [11]. The authors achieved an 

accuracy of 98.08% by performing classification experiments using 25 classes and 9458 malware samples. 

Many researchers extend the classification method proposed by Nataraj et al. to classify PE-based and 

Android-based  malware  samples  [12][13][14].  Yan  et  al.  proposed  a  classification  algorithm  that 

integrates PRICoLBP (pairwise rotation invariant co-occurrence local binary pattern) and TF-IDF (term 

6 

 
 
frequency-inverse  document  frequency)  transformation  [15].  PRICoLBP-TFIDF  achieved  higher 

accuracy against a strong immunity to weak encryption, code segment relocation, redundant data, and 

instructions. However, strong encryption malware or fragmented malware bypass PRICoLBP-TFIDF. 

Many researchers study classifiers that have trained not only gray-scale images but also the order of 

the opcode sequences. Jeon and Moon proposed the CRNN (convolutional recurrent neural networks) 

model for detecting malware using opcode sequences [16]. It consists of an opcode-level convolutional 

autoencoder that compresses long opcode sequences into short sequences at the front, and the DRNN 

(dynamic recurrent neural networks) that learns and classifies the compressed sequences. However, it 

showed relatively lower performance compared to other works. 

Many researchers study several features through dynamic analysis as well as static analysis. Sihwail 

et al. proposed a system that applies memory forensics to extract artifacts from memory and combines 

them  with  features  from  dynamic  analysis  of  malware  [17].  In  addition,  the  authors  achieved  high 

accuracy  of  98.5%  and  low  false  positives  of  1.7%  using  the  pre-modeling  technique  for  feature 

engineering and the SVM classifier. Xue et al. proposed the Malscore system that can classify malware 

using probability scoring and machine learning [18]. In the first phase of Malscore, it uses a CNN model 

for  training  grayscale  images.  In  the  second  phase,  Malscore  learned  API  call  sequences  that 

transformed into n-gram. Malscore achieved a high accuracy of 98.8% using probability scores to check 

the reliability of the classification results. 

2.2  Packed file detection using machine learning 

Zhang  et  al.  proposed  a  technique  to  detect  packed  malware  based  on  the  system  calls  [19].  The 

authors extracted the context of the system calls from benign and malicious samples using the sandbox 

environment for detecting packed malware. They extracted sensitive system call contexts and trained 

the  DBN  (deep  belief  network)  model  to  achieve  a  high  accuracy.  Biondi  et  al.  proposed  effective, 

efficient,  and  robust  119  features  to  detect  and  classify  packed  malware  into  each  packer  [20].  The 

7 

 
authors  built  the  ground  truth  by  labeling  it  in  three  different  ways.  They  combined  features  and 

algorithms with more than 1500 scenarios to research which machine learning model and features could 

show the best performance. 

Park et al. proposed a new framework for inferring the lineage of packed malware [21]. The authors 

used static analysis and dynamic analysis to extract a common feature set and a family feature set, and 

they appended two steps for identifying the version of packed malware. They used a common feature 

set to classify packed malware and solved an agglomerative clustering problem using a family feature 

set extracted from 12221 files. The authors were able to match not-packed and packed files and infer the 

lineage of packed files using the common feature set and the family feature set. Vasan et al. proposed a 

new architecture for classifying packed and not-packed malware [22]. This architecture used ensemble 

CNNs and showed robust performance even in encrypted malware. The architecture also showed low 

false alarms using 9339 malware images. In the case of not-packed malware, the architecture achieved 

high accuracy of 99.0%, and in the case of packed malware, it achieved an accuracy of 98.0%. However, 

it is difficult to say that Park et al. and Basan et al. properly evaluated the modelsâ€™ performance because 

they used too few samples. 

2.3  Adversarial attacks on neural networks 

Goodfellow et al. proved that adversarial examples deceive the machine learning models [23]. They 

also  showed  that  machine  learning  models  inconsistently  classify  adversarial  examples  due  to  the 

poisoned training data set generated with perturbation. ZÃ¼ gner et al. experimented more demanding 

addiction and casual attacks using CNNs  to focus  on the training phase of machine learning models 

[24]. The authors found that even a little interference significantly reduces classification accuracy. It has 

also  been  found  that  these  attacks  can  deceive  many  classification  models.  Thus,  they  proposed  the 

efficient  Nettack  that  utilizes  gradual  calculations  to  cope  with  attacks  that  can  deceive  machine 

learning models. 

8 

 
Adversarial attacks can be classified into a gradient-based attack, a score-based attack, a decision-

based attack, and a transfer-based attack. The gradient-based attack is a kind of white-box attack. The 

white-box attack assumes that the adversary has access to model parameters on top of being able to get 

labels for a given input. Goodfellow et al. proposed an FGSM (fast gradient sign method) to explore the 

gradient  direction  of  a  decision  boundary  [23].  Carlini  et  al.  proposed  a  powerful  attack  against 

defensive distillation and demonstrated their work to evaluate the efficacy of potential defenses. It uses 

the Adam optimizer to find adversarial examples [42]. It has the disadvantage to generate adversarial 

examples  if  the  attackers  are  inaccessible  to  the  model  or  the  details  are  unknown.  Therefore,  many 

researchers are paying attention to various black-box attacks recently. Attackers generate adversarial 

examples using only queries without any information about a target model. However, many service 

vendors limit usersâ€™ queries, and attackers need to reduce the number of queries because sending a large 

number of queries within a short time is perceived as a scam or a threat. 

Score-based  attacks  make  a  large  number  of  queries  to  the  target  model  and  exploit  the  ouput 

probabilities  to  generate  adversarial  examples.  Narodytska  et  al.  proposed  a  local  search  attack  that 

measures  the  model  sensitivity  to  individual  pixels  [36].  The  authors  proposed  black-box  attacks  by 

adding perturbation to a randomly selected single pixel then constructing a small set of pixels to perturb 

by greedy local search. Chen et al. tried to attack the target model by directly estimating the gradients 

of  the  target  models  for  generating  adversarial  examples  [37].  They  used  zeroth  order  stochastic 

coordinate  descent  along  with  dimension  reduction,  hierarchical  attack  and  importance  sampling 

techniques to efficiently attack the target model. 

Decision-based attacks use only the final output of the target model. Brunner et al. proposed a Biased 

Boundary Attack that biases the sampling procedure by combining low-frequency random noise with 

the gradient of an alternative model [38]. The authors combined image frequency, regional masks, and 

surrogate gradients biases to generate adversarial examples. They evaluated their performance against 

9 

 
the ImageNet classifier and the Google Cloud Vision API with just a few hundred queries. Ilyas et al. 

proposed three black-box threat models that characterize many real-world systems: the query-limited 

setting, partial-information setting, and the label-only setting [39]. The authors proposed a variant of 

the  NES  (natural  evolutionary  strategies)  to  generate  adversarial  examples  for  query  efficiency.  The 

authors  also  provided  theoretical  comparisons  with  previous  works  about  adversarial  examples  by 

correlating finite difference methods for the NES and Gaussian bases.   

Transfer-based  attacks  use  the  prediction  of  the  target  model  to  train  the  surrogate  model  for 

generating  adversarial  examples.  Papernot  et  al.  introduced  an  attack  based  on  a  novel  substitute 

training algorithm using synthetic data generation methods [40]. A novel attack strategy proposed by 

the authors is to train a substitute model on a synthetic dataset. An attacker uses the output label by the 

target  model  as  an  input  to  the  substitute  model.  The  parameters  of  the  substitute  model  craft 

adversarial examples, which are misclassified in the substitute model as well as in the target model. 

Liu  et  al.  studied  both  non-targeted  and  targeted  adversarial  examples  and  showed  that  while 

transferable  non-targeted  adversarial  examples  are  easy  to  generate,  targeted  adversarial  examples 

using other researches almost never transfer with their target labels [41]. The authors proposed a novel 

ensemble-based  attack  model  to  generate  transferable  adversarial  examples.  They  used  an  image 

classification service, Clarifai.com, to confirm that adversarial examples were misclassified. 

Lit  et  al.  proposed  an  adversarial  machine  learning  model  to  detect  malware  based  on  opcode  n-

grams [25]. The authors collected 7927 malicious samples and 4070 benign samples, extracted opcode 

n-gram sequences using TF-IDF, and generated adversarial features using XGBoost. SVM, DNN, and 

XGBoost which learned the original opcode n-gram, classified test samples well, but failed to classify 

the adversarial features properly. 

10 

 
 
 
 
3.  Multi-Step approach to classify packed malware 

3.1  Overview of entire framework 

Figure 4. Multi-step approach to classify and identify packed malware 

In  this  paper,  we  propose  a  step-by-step  framework  to  classify  and  identify  packed  malware.  The 

main goal of the framework is to select pseudo-optimal features that can classify whether malware is 

packed  or  not  and  research  effectual  model  for  classification.  Finally,  in  the  case  of  the  Well-known 

Packed samples, the framework recognizes the packer of it. 

3.2  Step 1: Feature selection 

3.2.1  CART (classification and regression trees) algorithm 

The  framework  preselect  the  top  20  features  using  the  CART  algorithm  that  calculates  the 

importance  of  the  features proposed  in  the  recent  work  [20].  We  use  Decision  Tree,  Random  Forest, 

Extra  Trees,  and  XGBoost  that  use  the  CART  algorithm  for  measuring  important  features  and 

preselecting  the  20  most  important  features.  The  CART  algorithm  builds  a  tree  to  reduce  the  Gini 

impurity  and  selecting  appropriate  features  to  classify  the  samples  into  homogeneous  classes  when 

partitioning the samples [26][27][28].   

If the Gini impurity calculated by Equation 1 significantly decreases, it means that it is an important 

feature  when  building  a  tree.  The  CART  algorithm  selects  a  feature  that  greatly  reduces  the  Gini 

impurity as the sixth line of Algorithm 1 and generates a node and so on. The stopping conditions of 

11 

 
 
this algorithm are as follows: (1) when there is no remaining data; (2) when all data belonging to a node 

have the same feature; (3) when a node's data is below a threshold; (4) when the depth of the tree exceeds 

a predefined value. 

Suppose that we have a simple dataset as shown in Table 1. This dataset represents the packing status 

of samples according to Entropy of EPS, Entropy of .text, Number of standard sections, and Zero size 

of uninitialized data, and the tree classifies them as Figure 5. When selecting a feature of the root node 

in Figure 5, must calculate the Gini impurity of each feature as Table 2. Among the four features, Zero 

size  of  raw  data  shows  the  lowest  Gini  impurity.  Therefore,  the  root  node  can  split  six  Not-Packed 

samples and eight Packed samples based on the Zero size of raw data.   

Algorithm 1. CART (classification and regression trees) algorithm for a single tree 

12 

 
 
Table 1. An example dataset to create a single Decision Tree 

Entropy of   

Entropy of   

Number of   

Zero size of 

standard sections 

raw data 

Label 

EPS 

Mid 

Mid 

Low 

High 

High 

High 

Mid 

Mid 

Low 

High 

High 

Low 

Low 

High 

.text 

Mid 

Mid 

Mid 

High 

Low 

High 

Low 

Mid 

High 

High 

High 

Low 

Mid 

Low 

0 

1 

0 

0 

0 

1 

0 

2 

1 

1 

1 

0 

1 

0 

True 

Not Packed 

False 

Not Packed 

True 

Packed 

False 

Not Packed 

True 

True 

True 

True 

True 

True 

False 

False 

True 

Packed 

Packed 

Packed 

Not Packed 

Packed 

Packed 

Not Packed 

Packed 

Packed 

False 

Not Packed 

Figure 5. A Decision tree to classify the example dataset 

13 

 
 
Table 2. The Gini index of each feature to select the one that best splits data at the root node 

Feature 

Gini index 

Entropy of EPS 

Entropy of .text 

0.4642 

0.4500 

Number of standard sections 

0.4354 

Zero size of raw data 

0.3365 

3.2.2 

Feature selection based on CART and impurity 

Algorithm 2. Feature selection algorithm from one or many trees 

We measure the feature importance of a tree generated by the CART algorithm using Algorithm 2 

and Equation 2â€“4. Algorithm 2 ranks each feature that makes a significant contribution when building 

a  tree.  We  can  measure  the  importance  of  each  node  through  Equation  2,  calculate  the  feature 

importance in the tree using Equation 3, and normalize the feature importance using Equation 4. In the 

case of calculating the feature importance across the several trees, calculate the average of the feature 

14 

 
 
importance calculated from all trees as in Equation 5. 

There are K samples in each class, and  ğ‘ğ‘–  represents the probability that sample i belongs to the class. 

We can get the Gini impurity at the specific node  ğ‘ğ‘—  using Equation 1. The node shows low impurity 

if the node splits the samples heterogeneously. Therefore, it shows low impurity at that node. The tree 

generated by the CART algorithm reduces the Gini impurity to create nodes and classify data, we can 

assume that the feature which significantly reduces impurity value is important. 

Equation 2â€“5 can calculate  the importance of all  features in trees. Equation 2 means the difference 

between  the  impurity  value  of  the  specific  node  and  the  impurity  values  of  its  children  nodes.  It 

calculates the importance of all nodes in a tree.  ğ¼(ğ‘ğ‘—)  denotes the importance of the node  ğ‘ğ‘—, and  ğ‘¤ğ‘— 

means the number of samples in the node  ğ‘ğ‘—  and denotes the weight. If the importance value of the 

specific  node  is  high,  the  node  can  be  considered  as  an  important  node.  Equation  3  calculates  the 

importance  of  each  feature  in  order  to  divide  the  sum  of  all  nodesâ€™  importance  values  split  by  each 

feature by the sum of all nodesâ€™ importance values. We can normalize the importance values through 

Equation  4  and  can  use  Equation  5  to  calculate  the  feature  importance  for  all  trees.  The  feature 

importance of Figure 5 is calculated as follows: 

ï¬  ğ‘›ğ‘œğ‘‘ğ‘’ğ¼ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ğ‘ğ‘›ğ‘ğ‘’1ğ‘ ğ‘¡(ğ‘ğ‘’ğ‘Ÿğ‘œ  ğ‘ ğ‘–ğ‘§ğ‘’  ğ‘œğ‘“  ğ‘Ÿğ‘ğ‘¤  ğ‘‘ğ‘ğ‘¡ğ‘) = 14 Ã— 0.49 âˆ’ 9 Ã— 0.346 âˆ’ 5 Ã— 0.32 = 2.146 

ï¬  ğ‘›ğ‘œğ‘‘ğ‘’ğ¼ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ğ‘ğ‘›ğ‘ğ‘’2ğ‘›ğ‘‘(ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦  ğ‘œğ‘“  ğ¸ğ‘ƒğ‘†) = 9 Ã— 0.346 âˆ’ 3 Ã— 0.4444 âˆ’ 6 Ã— 0 = 1.794 

ï¬  ğ‘›ğ‘œğ‘‘ğ‘’ğ¼ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ğ‘ğ‘›ğ‘ğ‘’2ğ‘›ğ‘‘(ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦  ğ‘œğ‘“  ğ¸ğ‘ƒğ‘†) = 5 Ã— 0.32 âˆ’ 2 Ã— 0.5 âˆ’ 3 Ã— 0 = 0.6000 

ï¬  ğ‘›ğ‘œğ‘‘ğ‘’ğ¼ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ğ‘ğ‘›ğ‘ğ‘’3ğ‘Ÿğ‘‘(ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦  ğ‘œğ‘“  . ğ‘¡ğ‘’ğ‘¥ğ‘¡  ğ‘ ğ‘’ğ‘ğ‘¡ğ‘–ğ‘œğ‘›) = 3 Ã— 0.4444 âˆ’ 2 Ã— 0 âˆ’ 1 Ã— 0 = 1.332 

ï¬  ğ‘›ğ‘œğ‘‘ğ‘’ğ¼ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ğ‘ğ‘›ğ‘ğ‘’3ğ‘Ÿğ‘‘(ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ  ğ‘œğ‘“  ğ‘ ğ‘¡ğ‘ğ‘›ğ‘‘ğ‘ğ‘Ÿğ‘‘  ğ‘ ğ‘’ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ ) = 2 Ã— 0.5 âˆ’ 1 Ã— 0 âˆ’ 1 Ã— 0 = 1.0000 

ï¬  ğ‘“ğ‘’ğ‘ğ‘¢ğ‘¡ğ‘Ÿğ‘’ğ¼ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ğ‘ğ‘›ğ‘ğ‘’ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦  ğ‘œğ‘“  ğ¸ğ‘ƒğ‘† = (2.146 Ã· 6.872) Ã· 1 = 0.3484 

ï¬  ğ‘“ğ‘’ğ‘ğ‘¢ğ‘¡ğ‘Ÿğ‘’ğ¼ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ğ‘ğ‘›ğ‘ğ‘’ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦  ğ‘œğ‘“  .ğ‘¡ğ‘’ğ‘¥ğ‘¡ ğ‘ ğ‘’ğ‘ğ‘¡ğ‘–ğ‘œğ‘› = (1.332 Ã· 6.872) Ã· 1 = 0.1934 

ï¬  ğ‘“ğ‘’ğ‘ğ‘¢ğ‘¡ğ‘Ÿğ‘’ğ¼ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ğ‘ğ‘›ğ‘ğ‘’ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ  ğ‘œğ‘“  ğ‘ ğ‘¡ğ‘ğ‘›ğ‘‘ğ‘ğ‘Ÿğ‘‘  ğ‘ ğ‘’ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  = (1.000 Ã· 6.872) Ã· 1 = 0.1455 

ï¬  ğ‘“ğ‘’ğ‘ğ‘¢ğ‘¡ğ‘Ÿğ‘’ğ¼ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ğ‘ğ‘›ğ‘ğ‘’ğ‘ğ‘’ğ‘Ÿğ‘œ  ğ‘ ğ‘–ğ‘§ğ‘’  ğ‘œğ‘“  ğ‘Ÿğ‘ğ‘¤  ğ‘‘ğ‘ğ‘¡ğ‘ = (2.146 Ã· 6.872) Ã· 1 = 0.3123 

In Figure 5, Entropy of EPS is the most important feature and the second is Zero size of raw data. We 

build Decision Tree, Extra Trees, Random Forest, and XGBoost that use Algorithm 2 and Equation 1â€“5 

15 

 
to select the 20 most important features among the 119 features proposed by Biondi et al. [20]. 

ğ¾

ğ¾

2
ğº(ğ‘ğ‘—) = âˆ‘ ğ‘ğ‘–(1 âˆ’ ğ‘ğ‘–) = 1 âˆ’ âˆ‘ ğ‘ğ‘–

ğ‘–=1

ğ‘–=1

Equation 1 

ğ¼(ğ‘ğ‘—) = ğ‘¤ğ‘— Ã— ğº(ğ‘ğ‘—) âˆ’ ğ‘¤ğ‘—_ğ‘™ğ‘’ğ‘“ğ‘¡ Ã— ğº(ğ‘ğ‘—_ğ‘™ğ‘’ğ‘“ğ‘¡) âˆ’ ğ‘¤ğ‘—_ğ‘Ÿğ‘–ğ‘”â„ğ‘¡ Ã— ğº(ğ‘ğ‘—_ğ‘Ÿğ‘–ğ‘”â„ğ‘¡) 

Equation 2 

ğ¼(ğ‘“ğ‘–âˆˆğ‘ğ‘™ğ‘™  ğ‘“ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ğ‘ ) =

âˆ‘

ğ‘—:ğ‘›ğ‘œğ‘‘ğ‘’  ğ‘—  ğ‘ ğ‘ğ‘™ğ‘–ğ‘¡ğ‘   ğ‘œğ‘›  ğ‘“ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’  ğ‘–
ğ¼(ğ‘ğ‘˜)

ğ‘˜âˆˆğ‘ğ‘™ğ‘™  ğ‘›ğ‘œğ‘‘ğ‘’ğ‘ 

âˆ‘

ğ¼(ğ‘ğ‘—)

Equation 3 

ğ¼(ğ‘“ğ‘–âˆˆğ‘ğ‘™ğ‘™  ğ‘“ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ğ‘ )ğ‘›ğ‘œğ‘Ÿğ‘š =

ğ¼(ğ‘“ğ‘—)

âˆ‘

ğ‘–âˆˆğ‘ğ‘™ğ‘™  ğ‘“ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ğ‘ 

ğ¼(ğ‘“ğ‘–)

ğ¼(ğ‘“ğ‘–âˆˆğ‘ğ‘™ğ‘™  ğ‘“ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ğ‘ )ğ‘ğ‘™ğ‘™  ğ‘¡ğ‘Ÿğ‘’ğ‘’ğ‘  =

âˆ‘

ğ‘¡âˆˆğ‘ğ‘™ğ‘™  ğ‘¡ğ‘Ÿğ‘’ğ‘’ğ‘ 

ğ¼(ğ‘“ğ‘–)ğ‘›ğ‘œğ‘Ÿğ‘š

ğ‘–ğ‘›  ğ‘¡

ğ‘ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿ  ğ‘œğ‘“  ğ‘¡ğ‘Ÿğ‘’ğ‘’ğ‘ 

Equation 4 

Equation 5 

3.2.3 

Permutation Importance 

Algorithm 3. Permutation importance algorithm. 

Permutation  importance  ranks  the  importance  of  all  features  by  calculating  how  much  it  affects 

performance  loss  when  changing  or  shuffling  the  data  of  each  feature  as  Algorithm  3.  It  scores  the 

influence of each feature by calculating how much performance loss compared to the unshuffled dataset 

and shuffled dataset. The performance will suffer if the classifier heavily relies on the specific feature to 

be shuffled. Because the shuffling procedure breaks the relationship between the feature and the target. 

It is a kind of model inspection technique that can be used for any model when the data is tabular. 

16 

 
 
 
 
 
 
 
This  technique  has  the  advantage  that  it  is  model  agnostic  and  can  measure  multiple  times  using 

different permutations. It also  has disadvantages.  The results of permutation importance are always 

different.  However,  increasing  the  number  of  shuffle  steps  can  reduce  the  variance  of  errors  by 

augmenting the computations. Also, random shuffling of features is likely to produce very unrealistic 

data combinations. This is easy to happen when the correlations between features are high. Increasing 

the uncertainty of the data could have a significant impact on the predictions. Showing high importance 

may not be the actual feature importance we want. 

3.3  Step 2: Light machine learning models for classifying packed malware 

Algorithm 4. Training machine learning models 

In step 2, the 10 models learn the important 20 features selected by step 1. We use several classification 

algorithms implemented in the scikit-learn [29] and the Keras [30] to find the model that shows the best 

performance for classifying packed malware into three classes. If we classify packed samples into each 

packer,  the  models  misclassify  well-known  packed  samples  that  have  a  small  number  of  samples. 

Therefore, we classify malware into Not Packed, Custom Packed, and Well-known Packed. Every model 

learns the training dataset  ğ•, the preselected features  ğ”½, and the labels  ğ•, returns the models to find 

the best performing features and the as Algorithm 4. 

All models  ğ•„  perform supervised learning. Supervised learning is one of the learning methods that 

infer a function or decision boundary from training data. Each model learns preselected features from 

step 1 and ground truth. After training, evaluate the models using test data, and step 2 returns the model 

that show the highest performance. 

17 

 
 
3.4  Step 3: Identify the packer using signatures 

Step 3 of the proposed framework identifies the packer of a packed sample that is classified as Well-

known  Packed in  step 2. We  use the  pefile [31] for  detecting  the  packer signature from the  PE-based 

malware as Algorithm 5. It confirms the EPS of the binary file for identifying the packer signature. If 

several signatures stored in the database exist in the EPS, it returns the last detected packer signature. 

The signature database has 4200 signatures provided by the PEiD [32]. Figure 6 shows some of the 

packer signatures stored in the database. The first line in Figure 6 represents the packer and its version 

information, and the second line indicates the packer's signature in hexadecimal. The 'ep_only' attribute 

indicates whether a signature can be found in the entry point section as True or False. 

Figure 6. Examples of packer signatures stored in the signature database. 

Algorithm 5. Algorithm to identify the packer 

18 

 
 
 
 
 
4.  Experimental results and discussion 

4.1  Experimental setup 

Algorithm 6. Labeling Algorithm 

We collected a total of 214001 malware samples from VirusShare1  and labeled them using a part of 

the  framework  proposed  in  the  previous  study  as  Algorithm  6  [33].  We  labeled  87502  samples  as 

Custom  Packed  that  have hidden  EPS  because  packers  can  hide  a  proper  address  of  the  entry  point 

while packing binary files. In the case that samples have an appropriate entry point and has the write 

property, and the  entropy  value of the  EPS belongs  to the  Packing-Range  suggested in the  previous 

study, we labeled them as also Custom Packed. Packed binary files need the write attribute to restore 

the  IAT  (import  address  table),  original  code,  and  data.  We  labeled  25955  samples  as  Well-known 

Packed that have findable EPS and packer signatures. Otherwise, we labeled 100544 samples as Not-

Packed. 

Figure  7  shows  the  packer  distribution  of  packed  malware.  UPX  is  the  most  frequent  with  6748 

samples, followed by Netopsystems with 4482 samples, and 35 packed malware samples each have a 

unique packer. Appendix 1 shows detailed information about Well-known Packed samples. We used 

214001 PE-based malware samples and split the dataset in a 70â€“30 ratio for training and testing. Table 

3 shows the composition of the dataset for the experiments. 

1  www.virusshare.com 

19 

 
 
 
                                            
Table 3. Distribution of train and test set 

Group 

Dataset 

Total 

Custom Packed 

Well-known Packed 

Not Packed 

Train Set 

61251 (28.6%) 

18168 (8.5%) 

70380 (32.9%) 

149799 (70.0%) 

Test Set 

26251 (12.3%) 

7787 (3.6%) 

30164 (14.1%) 

64202 (30.0%) 

Figure 7. Distribution of well-known packers (top 20) 

We  compared  an  accuracy,  F1-Score,  AUC  (area  under  the  ROC  curve)  widely  used  by  many 

researchers for detailed evaluation [34][35]. We evaluated the machine learning models the following 

factors in step 2: 

ï¬  True Positives (TP): The points classified as positive by the model that are actually positive. 

ï¬  True  Negatives  (TN):  The  points  classified  as  negative  by  the  model  that  are  actually 

negative. 

ï¬  False Positives (FP): The points classified as positive by the model that are actually negative. 

ï¬  False  Negatives  (FN):  The  points  classified  as  negative  by  the  model  that  are  actually 

positive. 

ï¬  Precision: The number  of true positives divided by the number of true positives and the 

number of false positives (

ğ‘‡ğ‘ƒ

ğ‘‡ğ‘ƒ+ğ¹ğ‘ƒ

). 

20 

 
 
ï¬  True Positive Rate (TPR), Recall: The number of true positives divided by the number of 

true positives and the number of false negatives (

ğ‘‡ğ‘ƒ

ğ‘‡ğ‘ƒ+ğ¹ğ‘

). 

ï¬  False  Positive  Rate  (FPR):  The  number  of  false  positive  divided  by  the  number  of  false 

positive and true negatives (

ğ¹ğ‘ƒ

ğ¹ğ‘ƒ+ğ‘‡ğ‘

). 

We  calculated  an  accuracy  using  Equation  6  as  the  proportion  of  samples  with  correct  answers 

among all predictions. we also measured the F1-score and AUC to avoid an accuracy paradox. F1-score 

is the harmonic mean of precision and recall as Equation 7, and it takes both false positives and false 

negatives to measure the performance in the case of using imbalanced data. AUC is the area under the 

ROC  curves,  and  it  represents  the  model's  ability  to  classify  each  class.  ROC  curves  show  the 

performance of a classification model at all classification thresholds with TPR and FPR. 

Accuracy =

ğ‘‡ğ‘ƒ + ğ‘‡ğ‘
ğ‘‡ğ‘ƒ + ğ‘‡ğ‘ + ğ¹ğ‘ƒ + ğ¹ğ‘

F1â€‘score = 2 Ã—

ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›  Ã— ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™
ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› + ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™

Equation 6 

Equation 7 

4.2  Experimental results 

4.2.1 

Step 1: Comparing feature importance scores 

We preselected 20 pseudo-optimal features among 119 features using 214001 malware samples and 

Decision Tree, Extra Trees, Random Forest, and XGBoost. In the case of Random Forest, Extra Tree, and 

XGBoost, we built 100 trees to preselect important features. The features selected by each model show 

slightly different results depending on the model as shown in  Figure 8. However, the Entropy of the 

entry point section has the highest importance values in most models. 

As shown in Figure 8(a) and Figure 8(e), Decision Tree measured the importance of the Entropy of 

entry point section very high compared to other models. This is because the models that build multiple 

21 

 
 
 
 
 
trees calculate the average of the feature importance in the 19th line of Algorithm 2. In other words, the 

models that build a large number of trees measure the feature importance more carefully because they 

consider various features in multiple trees. 

(a) Feature importance scores of CART with Decision Tree 

(b) Feature importance scores of CART with Extra Trees 

(c) Feature importance scores of CART with Random Forest 

22 

 
 
 
 
(d) Feature importance scores of CART with XGBoost 

(e) Permutation importance scores with Decision Tree 

(f) Permutation importance scores with Extra Trees 

(g) Permutation importance scores with Random Forest 

23 

 
 
 
 
 
(h) Permutation importance scores with XGBoost 

Figure 8. Top 20 important features selected by various machine learning models 

4.2.2 

Step 2: Comparing machine learning models 

Table 4 shows the results of comparing various experimental scenarios including the recent work. 

It shows which scenario is the best by comparing the accuracy, F1-Score, and AUC. Among the many 

experimental  scenarios,  the  XGBoost  that  learned  the  top  20  most  important  features  selected  by 

XGBoost  with  the  permutation  importance  performed  the  best.  It  has  shown  excellent  performance 

because it provides a parallel tree boosting that solves many problems quickly and accurately.   

Figure 9 shows the confusion matrix of some cases. Figure 9(a) shows the best performance of all 

experiment scenarios. It classified the Not-Packed, and Custom-Packed samples perfectly and the Well-

known Packed samples more perfectly than prior work [20]. This is because the Well-Known Packed 

samples  were  the  fewest.  Nevertheless,  Figure  9(a)  shows  the  highest  performance  among  the 

experimental scenarios including the recent study. 

Table 4. Classifying results of each feature selection model and each classifying model 

Feature Selection 

Model 

Classifying Model  Accuracy 

F1-Score 

AUC 

Linear SVM 

SVM 

0.2981 

0.7113 

Decision Tree 

Logistic Regression 

0.4654 

(CART) 

NaÃ¯ve Bayes 

kNN (k=3) 

MLP 

0.6884 

0.9047 

0.7011 

0.2772 

0.6457 

0.2254 

0.6364 

0.9032 

0.6991 

0.5195 

0.7876 

0.6915 

0.8536 

0.9633 

0.8072 

24 

 
 
Extra Tree 

(CART) 

Decision Tree 

Random Forest 

Extra Trees 

XGBoost 

Linear SVM 

SVM 

0.9893 

0.9943 

0.9868 

0.9954 

0.4610 

0.5844 

Logistic Regression 

0.7793 

NaÃ¯ve Bayes 

kNN (k=3) 

MLP 

Decision Tree 

Random Forest 

Extra Trees 

XGBoost 

Linear SVM 

SVM 

0.6529 

0.9433 

0.8999 

0.9837 

0.9888 

0.9853 

0.9887 

0.4294 

0.6389 

Logistic Regression 

0.4850 

NaÃ¯ve Bayes 

Random Forest 

kNN (k=3) 

(CART) 

MLP 

Decision Tree 

Random Forest 

Extra Trees 

XGBoost 

Linear SVM 

SVM 

0.7101 

0.8708 

0.6557 

0.9792 

0.9879 

0.9848 

0.9868 

0.6055 

0.5245 

XGBoost 

(CART) 

Logistic Regression 

0.4793 

NaÃ¯ve Bayes 

kNN (k=3) 

MLP 

Decision Tree 

Random Forest 

Extra Trees 

XGBoost 

Linear SVM 

SVM 

0.6783 

0.9060 

0.6660 

0.9851 

0.9904 

0.9876 

0.9902 

0.4368 

0.6407 

25 

0.9829 

0.9911 

0.9844 

0.9927 

0.3825 

0.5595 

0.7367 

0.6092 

0.9444 

0.8999 

0.9747 

0.9833 

0.9799 

0.9827 

0.4006 

0.4696 

0.2727 

0.6635 

0.8603 

0.6135 

0.9643 

0.9791 

0.9768 

0.9767 

0.4803 

0.4800 

0.2167 

0.6471 

0.9020 

0.6659 

0.9745 

0.9836 

0.9811 

0.9830 

0.3681 

0.5761 

0.9898 

0.9998 

0.9994 

0.9998 

0.6600 

0.5371 

0.9019 

0.8397 

0.9787 

0.9531 

0.9823 

0.9990 

0.9981 

0.9993 

0.5669 

0.7478 

0.7024 

0.8608 

0.9474 

0.8322 

0.9845 

0.9991 

0.9987 

0.9991 

0.6480 

0.5975 

0.4987 

0.8436 

0.9551 

0.8281 

0.9889 

0.9994 

0.9988 

0.9995 

0.5845 

0.7251 

 
Decision Tree 

(Permutation 

importance) 

Extra Tree 

(Permutation 

importance) 

Random Forest 

(Permutation 

importance) 

XGBoost 

(Permutation 

importance) 

Logistic Regression 

0.5824 

NaÃ¯ve Bayes 

kNN (k=3) 

MLP 

Decision Tree 

Random Forest 

Extra Trees 

XGBoost 

Linear SVM 

0.7167 

0.9348 

0.8251 

0.9865 

0.9916 

0.9840 

0.9911 

0.2874 

0.3896 

0.6777 

0.9329 

0.8245 

0.9780 

0.9864 

0.9808 

0.9861 

0.2657 

SVM 

035605 

0.4803 

Logistic Regression 

0.7000 

NaÃ¯ve Bayes 

kNN (k=3) 

MLP 

Decision Tree 

Random Forest 

Extra Trees 

XGBoost 

Linear SVM 

SVM 

0.6803 

0.9444 

0.8880 

0.9863 

0.9915 

0.9864 

0.9920 

0.5031 

0.5445 

Logistic Regression 

0.5873 

NaÃ¯ve Bayes 

kNN (k=3) 

MLP 

Decision Tree 

Random Forest 

Extra Trees 

XGBoost 

Linear SVM 

SVM 

0.6585 

0.8760 

0.7104 

0.9891 

0.9933 

0.9899 

0.9943 

0.4613 

0.5571 

Logistic Regression 

0.6015 

NaÃ¯ve Bayes 

kNN (k=3) 

MLP 

Decision Tree 

Random Forest 

0.6582 

0.9042 

0.7946 

0.9913 

0.9945 

26 

0.6784 

0.6410 

0.9461 

0.8884 

0.9800 

0.9883 

0.9832 

0.9892 

0.4789 

0.5219 

0.3886 

0.6183 

0.8663 

0.7083 

0.9818 

0.9888 

0.9857 

0.9904 

0.4006 

0.4908 

0.5904 

0.6398 

0.8988 

0.7899 

0.9858 

0.9911 

0.7216 

0.8458 

0.9753 

0.9379 

0.9899 

0.9998 

0.9993 

0.9996 

0.5250 

0.6386 

0.8581 

0.8408 

0.9798 

0.9646 

0.9897 

0.9995 

0.9993 

0.9995 

0.4821 

0.6077 

0.5571 

0.8109 

0.9504 

0.7666 

0.9992 

0.9996 

0.9995 

0.9996 

0.5669 

0.4319 

0.6480 

0.7983 

0.9498 

0.8819 

0.9993 

0.9996 

 
Extra Trees 

XGBoost 

Decision Tree 

Random Forest 

0.9878 

0.9967 

0.9891 

0.9928 

0.9859 

0.9946 

0.9812 

0.9885 

0.9995 

0.9998 

0.8787 

0.9998 

Biondi et al.[20] 

(a)  XGBoost classifier that learned the 

(b)  Prior work by Biondi et al. [20] 

preselected features by the permutation 

importance and XGBoost 

(c)  NaÃ¯ve Bayes classifier that learned the 

(d)  SVM classifier that learned the 

preselected features by the CART and 

preselected features by CART and Extra 

Decision Tree 

Trees. 

Figure  9.  The  confusion  matrix  of  some  cases:  (a)  XGBoost  classifier  that  learned  the 

preselected features by the permutation importance and XGBoost; (b) Prior work by Biondi et 

al.  [20];  (c)  NaÃ¯ve  Bayes  classifier  that  learned  the  preselected  features  by  the  CART  and 

Decision  Tree;  (d)  SVM  classifier  that  learned  the  preselected  features  by  CART  and  Extra 

Trees. 

27 

 
 
 
 
 
 
4.2.3 

Step 3: Identifying packers 

The proposed framework identifies the packer in step 3 using pefile [31], a multi-platform Python 

module  that  analyzes  PE  files.  We  identified  the  packers  for  7685  samples  classified  by  the  best 

performing model and compared the results identified by PEiD [32] with the results from step 3. We 

confirmed that the results were in the perfect match. This is because the framework uses the same packer 

database as PEiD. Figure 10 shows the top 20 frequent packers identified in step 3. 

Figure 10. Results of comparing PEiD and Step 3 

5.  Conclusion 

In this paper, we propose the multi-step framework that can detect whether malware is packed or 

not using static analysis and machine learning. We preselect 20 important features from 119 features 

proposed in a recent study through the feature selection algorithms. We also classify packed malware 

into three classes by comparing the accuracy, F1-Score, and AUC using different feature groups and 10 

different machine learning models. 

In step 1, we used Decision Tree, Random Forest, Extra Trees, and XGBoost to rank the features that 

each model considers important. We preselected important 20 features that split the data when building 

a tree based on the Gini impurity and the permutation importance. As a result, the XGBoost that learned 

28 

 
 
the important 20 features preselected by XGBoost with the permutation importance showed the best 

performance  than  any  other  model  including  a  recent  study.  When  selecting  important  features, 

creating a large number of trees showed better results than using only one tree in step 1. The proposed 

framework showed an accuracy of 99.27%, an F1-Score of 98.84%, and an AUC of 99.96% to classify into 

three  classes  in  step  2.  In  the  last  step,  the  framework  identified  the  packer  of  the  malware  samples 

classified as Well-known Packed. Therefore, this paper proposed the framework to classify and identify 

packed malware that is difficult to detect with machine learningâ€”in the case of packers with insufficient 

dataâ€”using the previously used packer detector. 

Our approach classifies and identifies the packed files whether the target files are malicious or not. 

Researchers must consider packing and obfuscation techniques in order to study deep learning models 

to detect and classify malware. The step-by-step framework proposed in this paper  classifies packed 

files into Well-known Packed, Custom Packed, and Not Packed. The framework identifies the packers 

that are classified as Well-known Packed samples. We plan to expand this framework that can classify 

whether the target file is encrypted as well as whether it is malicious or not. 

29 

 
 
 
Reference 

[1]  Cisco, 

â€œDefending 

against 

todayâ€™s 

critical 

threats 

[Online],â€  Available: 

https://www.cisco.com/c/dam/global/en_uk/assets/pdfs/en_cybersecurityseries_thr

t_01_0219_r2.pdf, Accessd on Apr. 15, 2021. 

[2]  A. I. Elkhawas, and N. Abdelbaki, â€œMalware detection using opcode trigram sequnce with 

SVM,â€  In  Proc.  of  the  2018  26th  Intâ€™l  Conf.  on  Software,  Telecommunications  and  Computer 

Networks (SoftCOM), Split, Croatia, pp. 1â€“6, Sept. 2018. 

[3]  H. Zhang, X. Xiao, F. Mercaldo, S. Ni, F. Martinelli, and A. K. Sangaigh, â€œClassifiaction of 

ransomware  families  with  mahcine  learning  based  on  N-gram  of  opcodes,â€  Futer 

Generation Computer Systems, Vol. 90, pp. 211â€“221, Jan. 2019. 

[4]  P.  Auer,  â€œLearning  nested  differences  in  the  presence  of  malicious  noise,â€  Theoretical 

Computer Science, Vol. 185, No. 1, pp. 159â€“175, Oct. 1997. 

[5]  N. H. Bshouty, N. Eiron, and E. Kushilevitz, â€œPAC learning with nasty noise,â€ Theoretical 

Computer Science, Vol. 288, No. 2, pp. 255â€“275, Oct. 2002. 

[6]  R. A. Servedio, â€œSmooth boosting and learning with malicious noise,â€  The Journal of the 

Machine Learning Research, Vol. 4, pp. 633â€“648, Sept. 2003. 

[7]  M. Barreno, B. Nelson, R. Sears, and A. D. Joseph, â€œCan machine learning be secure?,â€ In 

Proc.  of  the  2006  ACM  Symposium  on  Information,  Computer  and  Communications  Security, 

Taipei, Taiwan, pp. 16â€“25, Mar. 2006. 

[8]  B. Rahbarinia, M.Balduzzi, and R. Perdisci, â€œExploring the long tail of (malicious) software 

downloads,â€  In  Proc.  of  the  47th  Annual  IEEE/IFIP  Intâ€™l  Conf.  on  Dependable  Systems  and 

Networks (DSN), Denver, Colorado, pp. 391â€“402, June 2017. 

[9]  M. Morgenstern and H. Pilz, â€œUseful and useless statistics about viruses and anti-virus 

programs,â€ In Proc. of the CARO Workshop 2010, Helsinki, Finland, pp. 653â€“656, May 2010. 

30 

 
[10]  X. U. Pedrero, D. Balzarotti, I. Santos, and P. G. Bringas, â€œSoK: Deep packer inspection: A 

longitudinal study of the complexity of run-time packers,â€ In Proc. of the IEEE Symp. on 

Security and Privacy, San Jose, California, May 2015. 

[11]  L. Nataraj, S. Karthikeyan, and G. Jacob, "Malware images: visualization and automatic 

classification,â€ In Proc. of the 8th International Symposium on Visualizeation for Cyber Security, 

Pittsburh, USA, pp. 1â€“7, July 2011. 

[12]  K. Kancherla and S. Mukkamala, â€œImage visualization based malware detection,â€ In Proc. 

of  the  IEEE  Symposium  on  Computational  Intelligence  in  Cyber  Security  (CICS),  Singapore, 

Singapore, pp. 40â€“44, Apr. 2013. 

[13]  K. Kosmidis and C. Kalloniatis, "Machine learning and images for malware detection and 

classification,â€ In Proc. of the 21st Pan-Hellenic Conferences on Informatics, Larissa, Greece, pp. 

1â€“7, Sept. 2017. 

[14]  H. Zhang, J. Qin, B.  Zhang, H. Yan, J. Guo, F. Gao, S. Wang, and Y. Hu, â€œA multicalss 

Detection  system  for  android  malicious  Apps  based  on  color  image  features,â€  Wireless 

Communications and Mobile Computing, Vol. 2020, Article ID 8882295, pp. 1â€“21, Dec. 2020. 

[15]  H.  Yan,  H.  Zhou,  H.  Zhou,  "Automatic  malware  classification  via  PRICoLBP,â€  Chinese 

Journal of Electronics, Vol. 27, No. 4, pp. 852â€“859, July 2018. 

[16]  S. Jeon and J. Moon, â€œMalware-detection method with a convollutional recurrent neural 

network using opcode sequences,â€ Information Sciences, Vol. 535, pp. 1â€“15, Oct. 2020. 

[17]  R. Sihwail, K. Omar, K.  A. Z. Ariffin, and S. A. Afghani, â€œMalware detectio napproach 

based on artifacts in memory image and dynamic analysis,â€ Applied Sciences, Vol. 9, No. 18, 

pp. 1â€“12, Sept. 2019. 

[18]  D. Xue, J. LI, T. Lv, W. Wu, and J. Wang, "Malware classification using probability scoring 

data and machine learning,â€ IEEE Access, Vol. 7, pp. 91641â€“91656, July 2019. 

31 

 
[19]  Z. Zhang, C. Chang, P. Han, and H. Zhang â€œPacked malware variants detection using deep 

belief networks,â€ In Proc. of the International Conference on Computer Science Communication 

and Network Security (CSCNS2019), Vol. 309, Online, pp. 1â€“8, Mar. 2020. 

[20]  F.  Biondi,  M.  A.  Enescu,  T.  Given-Wilson,  A.  Legay,  L.  Noureddine,  and  V.  Verma, 

â€œEffective, efficient, and robust packing detection and classification,â€ Computers & Security, 

Vol. 85, pp. 436â€“451, Aug. 2019. 

[21]  L. H. Park, J. Yu, H. K. Kang, T. Lee and T. Kwon, â€œBirds of a feature: intrafamily clustering 

for  version  identification  of  packed  malware,â€  IEEE  Systems  Journal,  Vol.  14,  No.  3,  pp. 

4545â€“4556, Sept. 2020. 

[22]  D.  Vasan,  M.  Alazab,  S.  Wassan,  B.  Safaei,  and  Q.  Zheng,  â€œImage-based  malware 

classification using ensemble of CNN architecutres (IMCEC),â€ Computer & Security, Vol. 

92, pp. 1â€“12, Feb. 2020. 

[23]  I.  J.  Goodfellow,  J.  Shlens,  and  C.  Szegedy,  "Explaining  and  harnessing  adversarial 

exampels,â€  In  Proc.  of  the  International  Conference  on  Learning  Representations  (ICLR), 

Sandiego, USA, PP. 1â€“11, May 2015. 

[24]  D. ZÃ¼gner, A. Akbarnejad, and S. GÃ¼nnemann, â€œAdversarial attacks on neural networks 

for graph data,â€ In Proc. of the 24th ACM SIGKDD International Conference on Kenowledge 

Discovery & Data Mining, London, United Kingdom, pp. 2847-2856, July 2018. 

[25]  X. Li, K. Qiu, C. Qian, and G. Zhao, â€œAn adversarial machine learning method based on 

opcode N-grams feature in malware detection,â€ In Proc. of the 2020 IEEE Fifth International 

Conference on Data Science in Cyberspace (DSC), Hong Kong, China, pp. 380â€“387, July 2020. 

[26]  N.  Z.  Zacharis,  â€œClassification  and  regression  trees  (CART)  for  predictive  modeling  in 

blended learningâ€, International Journal of Intelligent Systems and Applications(IJISA), Vol. 10, 

No. 3, pp. 1â€“9, Mar. 2018. 

32 

 
[27]  S. L. Crawford, â€œExtensions to the CART algorithm,â€ International Journal of Man-Machine 

Studies, Vol. 31, No. 2, pp. 197â€“217, Aug. 1989. 

[28]  L. Breiman, J. Friedman, C. J. Stone, and R. A. Olshen, â€œClassification and regression trees,â€ 

CRC Press, 1984. 

[29]  F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. 

Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, 

M. Perrot, and E. Duchesnay, â€œScikit-learn: Machine learning in Python,â€ Journal of Machine 

Learning Research, Vol. 12, No. 85, pp. 2825â€“2830, 2011. 

[30]  Keras, [Online]. Available: https://keras.io/guides/, Acceessed on Jan. 11, 2021. 

[31]  E. Carrera, "pefile,â€ Available: https://github.com/erocarrera/pefile, Accessed on: Dec. 1, 

2020. 

[32]  H.  Neil,  â€œPEiD  [Online],â€  Available:  https://github.com/wolfram77web/app-peid, 

Accessd on Dec. 14, 2020. 

[33]  M. J. Choi, J. Bang, J. Kim, H. Kim, and Y. S. Moon, â€œAll-in-one framework for detection, 

unpacking, and verification for malware analysis,â€ Security and Communication Networks, 

Vol. 2019, Article ID 5278137, pp. 1â€“16, Oct. 2019. 

[34]  A. P. Namanya, I. U. Awan, J. P. Disso, and M. Younas, â€œSimilarity hash based scoring of 

portable executable files for efficient malware detection in IoT,â€ Future Generation Computer 

Systems, Vol. 110, pp. 824â€“832, May 2019. 

[35]  Z. Li and D. Hoiem, " Learning without forgetting,â€ IEEE Transactions on Pattern Analysis 

and Machine Intelligence, Vol. 40, No. 12, pp. 2935â€“2947, Nov. 2017. 

[36]  N. Narodytska and S. P.  Kasiviswanathan, â€œSimple black-box adversarial perturbations 

for deep networks,â€ arXiv preprint arXiv:1612.06299, Dec. 2016. 

[37]  P. Chen, H. Zhang, Y. Sharma, J. Yi, and C. Hsieh, â€œZOO: Zeroth order optimization based 

black-box  attacks  to  deep  neural  networks  without  training  substitute  models,â€  In 

33 

 
Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, Texas, USA, pp. 

15â€“26, Nov. 2017. 

[38]  T. Brunner, F. Diehl, M. T. Le, and A. Knoll, â€œGuessing smart: Biased sampling for efficient 

black-box adversarial attacks,â€ In  Proceedings of the IEEE/CVF International Conference on 

Computer Vision (ICCV), Seoul, Korea, pp. 4958â€“4966, Oct. 2019. 

[39]  A. Ilays, L. Engstrom, A. Athalye, and J. Lin, â€œBlack-box adversarial attacks with limited 

queries  and  information,â€  In  Proceedings  of  the  35th  International  Conference  on  Machine 

Learning, Stockholm, Sweden, pp. 2137â€“2146, Jul. 2018. 

[40]  N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and A. Swami, â€œPractical black-

box attacks against machine learning,â€ In Proceedings of Asia Conference on Computer and 

Communications Security, Abu Dhabi, United Arab Emirates, pp. 506â€“519, Apr. 2017. 

[41]  Y. Liu, X. Chen, C. Liu, and D. Song, â€œDelving into transferable adversarial examples and 

black-box attacks,â€ arXiv preprint arXiv:1611.02770, Feb. 2017. 

[42]  N. Carlini and D. Wagner, â€œTowards evaluating the robustness of neural networks,â€ In 

Proceedings of the 2017 IEEE Symposium on Security and Privacy, CA, USA, pp. 39â€“57, Jun. 

2017. 

34 

 
 
 
Packer 

UPX 

Netopsystems 

Morphine v1.2 (DLL) 

asprotect 

ASPack 

AHTeam EP Protector 

Ste@lth PE 

PeStubOEP 

ACProtect 

Packman 

Themida 

Upack 

MEW 

RLPack 

PE Diminisher 

ExeShield 

Safengine Shielden 

MoleBox 

ZProtect 

PKLITE32 

PESpin 

PE Pack 

eXPressor 

CreateInstall 

KGB SFX 

PEBundle 

PC Guard for Win32 

EXE Cryptor 

ZealPack 

WWPack 

kkrunchy 

GP-Install 

XPack V0.98 

Appendix 1. Distribution of packers 

# of files 

6,748 

4,482 

3,131 

2,645 

1,981 

987 

250 

240 

200 

169 

164 

161 

158 

145 

29 

26 

19 

18 

15 

13 

10 

10 

9 

9 

8 

7 

5 

5 

4 

4 

4 

4 

2 

Packer 

PECompact 

SafeGuard 

tElock 

MPRESS 

VMProtect 

FSG 

kryptor 6 

Enigma 

NsPack 

Armadillo 

Petite 

Fish Pe Packer 

InstallShield 

ìº¬  v1.0 -> bbb 

Hide&Protect 

W32.Jeefo 

Crunch/PE 

HuiGeZi 

NeoLite v2.0 

UNKNOWN 

Obsidium 

Embed PE 

PEEncrypt 

Crinkler 

Cexe 

Program Protector 

PEQuake 

yoda's Protector 

yoda's Crypter 

Krypton 

PECrc32 0.88 

Feokt 

EZIP 

35 

# of files 

878 

675 

596 

571 

516 

297 

132 

93 

85 

74 

57 

42 

38 

33 

13 

12 

12 

11 

11 

10 

7 

7 

6 

6 

6 

5 

5 

3 

6 

4 

3 

3 

3 

 
VIRUS - I-

Worm.KLEZ 

Silicon Realms Install 

Stub 

PE Crypt32 

Pack Master 

North Star PE Shrinker 

GameGuard 

EXEStealth 

EXE Shield 

BeRoEXEPacker 

XJ / XPAL -> LiNSoN 

Virogen Crypt v0.75 

AHPack 

VBOX v4.2 MTE 

Unnamed Scrambler 

SuperDAT 

RPoly crypt 

RCryptor 

PeX v0.99 

NTPacker 

KByS 

HPA 

HA Archive 

Gleam 

eXcalibur 

DBPE vx.xx 

BlackEnergy DDoS 

Bot Crypter 

* PseudoSigner 

2 

2 

2 

2 

2 

2 

2 

2 

2 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

CRYPToCRACk's PE 

Protector 

SVKP 

dUP2 

Crypto-Lock 

Blade Joiner 

ANDpakk2 

XComp 

SafeDisc/SafeCast 

nPack 

Stone's PE Encrypter 

Spalsher 

Software Compress 

SoftSentry 

SimplePack 

Sality.Q 

Reg2Exe 2.24 

PUNiSHER 

PE-Armor 

JDPack 

iPBProtect v0.1.3 

hying's PEArmor 

Freshbind 

ExeJoiner 

EXE32Pack 

D1S1G 

Crunch/PE 

3 

3 

2 

2 

2 

2 

2 

2 

2 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

Total Well-known 

Packed malware 

25,955 

36 

 
 
