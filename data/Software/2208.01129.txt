2
2
0
2

g
u
A
1

]
E
M

.
t
a
t
s
[

1
v
9
2
1
1
0
.
8
0
2
2
:
v
i
X
r
a

ACCELERATED AND INTERPRETABLE OBLIQUE RANDOM
SURVIVAL FORESTS

A PREPRINT

Byron C. Jaeger

Department of Biostatistics and Data Science
Wake Forest University School of Medicine
Winston-Salem, NC 27157, USA
bjaeger@wakehealth.edu

Sawyer Welden
Department of Biostatistics and Data Science
Wake Forest University School of Medicine
Winston-Salem, NC 27157, USA
swelden@wakehealth.edu

Kristin Lenoir
Department of Biostatistics and Data Science
Wake Forest University School of Medicine
Winston-Salem, NC 27157, USA
klenoir@wakehealth.edu

Jaime L. Speiser
Department of Biostatistics and Data Science
Wake Forest University School of Medicine
Winston-Salem, NC 27157, USA
jspeiser@wakehealth.edu

Matthew Segar
Department of Cardiology
Texas Heart Institute
Houston, TX 77030, USA
Matthew.Segar@BCM.edu

Ambarish Pandey
Division of Cardiology, Department of Internal Medicine
University of Texas Southwestern Medical Center
Dallas, TX 75235, USA
Ambarish.Pandey@UTSouthwestern.edu

Nicholas M. Pajewski
Department of Biostatistics and Data Science
Wake Forest University School of Medicine
Winston-Salem, NC 27157, USA
npajewsk@wakehealth.edu

August 4, 2022

ABSTRACT

The oblique random survival forest (RSF) is an ensemble supervised learning method for right-
censored outcomes. Trees in the oblique RSF are grown using linear combinations of predictors to
create branches, whereas in the standard RSF, a single predictor is used. Oblique RSF ensembles
often have higher prediction accuracy than standard RSF ensembles. However, assessing all possible
linear combinations of predictors induces signiﬁcant computational overhead that limits applications
to large-scale data sets. In addition, few methods have been developed for interpretation of oblique
RSF ensembles, and they remain more difﬁcult to interpret compared to their axis-based counterparts.
In this article, we introduce and evaluate a method to increase computational efﬁciency of the oblique
RSF and a method to estimate importance of individual predictor variables with the oblique RSF.
Our strategy to reduce computational overhead makes use of Newton-Raphson scoring, a classical
optimization technique that we apply to the Cox partial likelihood function within each non-leaf node
of decision trees. We estimate the importance of individual predictors for the oblique RSF by negating
each coefﬁcient used for the given predictor in linear combinations, and then computing the reduction
in out-of-bag accuracy. In general benchmarking experiments, we ﬁnd that our implementation of
the oblique RSF is approximately 450 times faster with equivalent discrimination and superior Brier
score compared to existing software for oblique RSFs. We ﬁnd in simulation studies that ‘negation
importance’ discriminates between relevant and irrelevant predictors more reliably than permutation

 
 
 
 
 
 
arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

importance, Shapley additive explanations, and a previously introduced technique to measure variable
importance with oblique RSFs based on analysis of variance. All methods pertaining to oblique RSFs
in the current study are available in the aorsf R package.

Keywords Random Forests · Survival · Efﬁciency · Variable Importance

1

Introduction

Risk prediction may reduce the burden of disease by guiding strategies for prevention and treatment in a wide range
of domains [Moons et al., 2012a,b]. The random survival forest (RSF; Ishwaran et al. [2008], Hothorn et al. [2006])
is a supervised learning algorithm that has been used frequently for risk prediction [Wang and Li, 2017]. Similar to
random forests (RFs) for classiﬁcation and regression [Breiman, 2001], The RSF is a large set of de-correlated and
randomized decision trees, with each tree contributing to the ensemble’s prediction function. Notable characteristics of
the RSF include uniform convergence of its ensemble survival prediction function to the true survival function, ﬁrst
shown by Ishwaran and Kogalur [2010] and later by Cui et al. [2017] under more general conditions. However, Cui
et al. [2017] noted that the RSF is at a disadvantage when predictors are correlated and some are not relevant to the
censored outcome, which is a strong possibility when large medical databases are leveraged for risk prediction.

A potential approach to improve the RSF when predictors are correlated and some are not relevant to the censored
outcome is to use oblique trees instead of axis based trees. Axis based trees split data using a single predictor, creating
decision boundaries that are perpendicular or parallel to axes of the predictor space [see Breiman et al., 2017, Chapter 2].
Oblique trees split data using a linear combination of predictors, creating decision boundaries that are neither parallel nor
perpendicular to axes of their contributing predictors [see Breiman et al., 2017, Chapter 5]. Menze et al. [2011] examined
prediction accuracy of RFs in the presence of correlated predictors and found that oblique RFs had substantially higher
prediction accuracy compared to axis-based RFs. Similarly, Jaeger et al. [2019] found that growing RSFs with oblique
rather than axis-based survival trees reduced the RSF’s concordance error, with improvements ranging from 2.5% to
24.9% depending on the data analyzed.

Oblique trees have at least two notable drawbacks compared to axis-based trees. First, ﬁnding a locally optimal oblique
decision rule may require exponentially more computation than an axis-based rule. If p predictors are potentially used
to split n observations, up to O(np) oblique splits can be assessed versus O(n · p) axis-based splits [Heath et al., 1993,
Murthy et al., 1994]. Second, estimating variable importance (VI) using permutation (a standard method for RFs) may
be less effective in ensembles of oblique trees, as permuting the values of one predictor may not destabilize decisions
that are based on linear combinations of predictors. Although VI is one of the most widely used strategies to interpret
random forests [Ishwaran and Lu, 2019], few studies have investigated VI for oblique random forests [see Menze et al.,
2011, Section 5], and fewer have investigated VI speciﬁcally for the oblique RSF.

The rest of this article is organized as follows. Section 2 reviews prior studies that have developed methods related
In Section 3, we reduce the computational cost of oblique RSFs (i.e.,
to those introduced in the current study.
accelerate them) with a scalable algorithm to identify linear combinations of coefﬁcients. In Section 4, we improve
the interpretability of oblique RSFs with ‘negation VI’, a method to estimate VI that ﬂips the sign of coefﬁcients
in linear combinations of predictors instead of permuting predictor values. We evaluate these methods with general
benchmarking experiments and simulation studies in Section 5. In Section 6, we summarize results from the current
study and present ideas connecting the current work to existing frameworks and methods for RSFs that future studies
may engage with. The accelerated oblique RSF and multiple methods to compute VI for oblique RSFs are available in
the aorsf R Package.

2 Related work

Sections 2.1 and 2.2 brieﬂy summarize prior studies that have developed methods related to the oblique RSF and VI,
respectively.

2.1 Axis-based and oblique random forests

After Breiman [2001] introduced the axis-based and oblique RF, numerous methods were developed to grow oblique
RFs for classiﬁcation or regression tasks [Menze et al., 2011, Zhang and Suganthan, 2014, Rainforth and Wood, 2015,
Zhu et al., 2015, Poona et al., 2016, Qiu et al., 2017, Tomita et al., 2020, Katuwal et al., 2020]. However, oblique
splitting approaches for classiﬁcation or regression may not generalize to censored outcomes [e.g., see Zhu, 2013,
Section 4.5.1], and most research involving the RSF has focused on forests with axis-based trees [Wang and Li, 2017].

2

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Building on prior research for bagging survival trees [Hothorn et al., 2004], Hothorn et al. [2006] developed an
axis-based RSF in their framework for unbiased recursive partitioning, more commonly referred to as the conditional
inference forest (CIF). Zhou et al. [2016] developed a rotation forest based on the CIF and Wang and Zhou [2017]
developed a method for extending the predictor space of the CIF. Ishwaran et al. [2008] developed an axis-based RSF
with strict adherence to the rules for growing trees proposed in Breiman [2001]. Jaeger et al. [2019] developed the
oblique RSF following the bootstrapping approach described in Breiman’s original RF and incorporating early stopping
rules from the CIF.

Fast algorithms to ﬁt axis-based RSFs are available in the randomForestSRC R package [Ishwaran and Kogalur, 2019]
and the ranger [Wright and Ziegler, 2017] R package. randomForestSRC provides a uniﬁed interface to grow RFs in
a wide range of analyses, and ranger is designed to grow RFs efﬁciently using high dimensional data. Fast algorithms
to ﬁt the CIF are provided by the party R package [Hothorn et al., 2010], which provides a computational toolbox
for recursive partitioning using conditional inference trees. Jaeger et al. [2019] developed the obliqueRSF package
and found it was approximately 30 times slower than party and nearly 200 times slower than randomForestSRC.
Few studies have developed software with fast algorithms for oblique RSFs that have comparable speed compared to
algorithms for axis-based RSFs.

2.2 Variable importance

Several techniques to estimate VI have been developed since Breiman [2001] introduced permutation VI, which is
deﬁned for each predictor as the difference in a RF’s estimated prediction error before versus after the predictor’s values
are randomly permuted. Strobl et al. [2007] identiﬁed bias in permutation VI driven by variable selection bias and
effects induced by bootstrap sampling, and proposed an unbiased permutation VI measure based on unbiased recursive
partitioning [Hothorn et al., 2006]. Menze et al. [2011] introduced an approach to estimate VI for oblique RFs that
computes an analysis of variance (ANOVA) table in non-leaf nodes to obtain p-values for each predictor contributing
to the node. The ANOVA VI1 is then deﬁned for each predictor as the number of times a p-value associated with
the predictor is ≤ 0.01 while growing a forest. Lundberg and Lee [2017] introduced a method to estimate VI using
SHapley Additive exPlanation (SHAP) values, which estimate the contribution of a predictor to a model’s prediction
for a given observation. SHAP VI is computed for each predictor by taking the mean absolute value of SHAP values
for that predictor across all observations in a given set. With the exception of Menze et al. [2011], few studies have
evaluated estimation of VI using oblique RFs, and fewer have examined VI speciﬁcally for the oblique RSF.

3 The accelerated oblique random survival forest

This section describes our approach to reduce computational overhead of the oblique RSF. Consider the usual framework
for right-censored time-to-event outcomes with training data

Dtrain = {(Ti, δi, xi)}Ntrain
i=1 .
Here, Ti is the event time if δi = 1 or the censoring time if δi = 0, and xi is a vector of predictors values. Assuming
there are no ties, let t1 < . . . < tm denote the m unique event times in Dtrain.

To accelerate the oblique RSF, we propose to identify linear combinations of predictor variables in non-leaf nodes by
applying Newton Raphson scoring to the partial likelihood function of the Cox regression model:

L(β) =

m
(cid:89)

i=1

exT

j(i)β

(cid:80)

j∈Ri

exT

j β

,

(1)

where Ri is the set of indices, j, with Tj ≥ ti (i.e., those still at risk at time ti), and j(i) is the index of the observation
for which an event occurred at time ti. Newton Raphson scoring is an exceptionally fast estimation procedure, and the
survival package [Therneau, 2022a] includes documentation that outlines how to efﬁciently program it [Therneau,
2022b]. Brieﬂy, a vector of estimated regression coefﬁcients, ˆβ, is updated in each step of the procedure based on its
ﬁrst derivative, U ( ˆβ), and second derivative, H( ˆβ):

ˆβk+1 = ˆβk + U ( ˆβ = ˆβk) H −1( ˆβ = ˆβk)

For statistical inference, it is recommended to continue updating ˆβ by completing additional iterations of Newton
Raphson scoring until a convergence threshold is met. However, since an estimate of ˆβ is created by the ﬁrst iteration of

1Menze et al. [2011] name their method ‘oblique RF VI’, but we use the name ‘ANOVA VI’ in this article to avoid confusing

Menze’s approach with other approaches to estimate VI for oblique RFs.

3

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Newton Raphson scoring, only one iteration of Newton Raphson scoring is needed to identify a valid linear combination
of predictors. Moreover, computing U and H requires computation and exponentiation of the vector x ˆβ, but these steps
can be skipped on the ﬁrst iteration of Newton Raphson scoring if an initial value of ˆβ = 0 is chosen, allowing for
a reduction in computing operations and removing the need to scale predictor values prior to initiating the Newton
Raphson algorithm.2 In Section 5.1.6, we formally test whether growing oblique survival trees using one iteration of
Newton Raphson scoring provides equivalent prediction accuracy compared to trees where iterations are completed
until a convergence threshold is met.

Algorithm 1 presents our approach to ﬁtting an oblique survival tree in the accelerated oblique RSF using default values
from the aorsf R package. Several steps are taken to reduce computational overhead. First, memory is conserved by
conducting bootstrap resampling via randomly generated bootstrap weights rather than making a traditional bootstrap
sample. Weights are integer valued, with a weight of v indicating an observation was sampled v times. Second, early
stopping is applied to the tree-growing procedure if a statistical criterion is not met. In our case, the criterion is based
on the magnitude of a log-rank test statistic corresponding to splitting the data at a current node. Third, instead of
greedy recursive partitioning, we use ‘good enough’ partitioning. More speciﬁcally, instead of computing a log-rank test
statistic for several different linear combinations of variables and proceeding with the highest scoring option, we identify
an optimal cut-point for one linear combination of variables and assess whether using this combination will create
a split that passes the criterion for splitting a node. If it does not pass the criterion, then another linear combination
will be tested, with the maximum number of attempts set by the parameter n_retry. Often a ‘good-enough‘ split can
be found in just one attempt when the training set is large, which gives the accelerated oblique RSF a computational
advantage in larger training sets compared to greedy partitioning.

4 Negation variable importance

This Section introduces negation VI, which is similar to permutation VI in that it measures how much a model’s
prediction error increases when a variable’s role in the model is de-stabilized. Speciﬁcally, negation VI measures the
increase in an oblique RF’s prediction error after ﬂipping the sign of all coefﬁcients linked to a variable (i.e., negating
them). As the magnitude of a coefﬁcient increases, so does the probability that negating it will change the oblique RF’s
predictions. For the current study, we use Harrell’s concordance (C)-statistic [Harrell et al., 1982] to measure change in
prediction error when computing negation VI.

Negation VI has several helpful characteristics. First, negation VI generalizes to any oblique RF (i.e., not just RSFs)
using any valid error function, making it both general and ﬂexible.3 Second, since the coefﬁcients in each non-leaf
node of an oblique tree are adjusted for the accompanying predictors, negation VI may provide better estimation of
VI in the presence of correlated variables compared to standard VI techniques. Third, unlike permutation, negation is
non-random and hence reproducible without setting a random seed. Additionally, since negation VI does not permute
variables, the analyst need not worry about impossible combinations of predictors that may occur when one predictor is
randomly permuted, such as having a negative status for type 2 diabetes and having Hemoglobin A1c level ≥ 6.5% (a
value indicative of type 2 diabetes) as a result of randomly permuting the values of Hemoglobin A1c.

5 Numeric experiments

Sections 5.1 and 5.2 present numerical experiments examining the accelerated oblique RSF and negation VI, respectively.
The code used to run these experiments is available online at https://github.com/bcjaeger/aorsf-bench. All analyses
were conducted using R version 4.1.3 and coordinated by the targets R package [Landau, 2021]. To standardize
comparisons of computational efﬁciency, all learners and VI techniques used up to 4 processing units.

5.1 Benchmark of prediction accuracy and computational efﬁciency

The aim of this numeric experiment is to evaluate and compare the accelerated oblique RSF with its predecessor
(the oblique RSF from the obliqueRSF R package) and with other machine learning algorithms for risk prediction.
Inferences drawn from this experiment include equivalence and inferiority tests based on Bayesian linear mixed models.

2Predictors are scaled prior to initiating the Newton Raphson algorithm to avoid exponentiation of large numbers. However, if

only one iteration is completed with an initial value of 0 for ˆβ, then exp(x ˆβ) = 1.

3The aorsf package enables customized functions

to be applied in lieu of

the default C-statistic (see

?aorsf::orsf_vi_negate)

4

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Algorithm 1 Accelerated oblique random survival tree using default parameters.
Require: Training data Dtrain = {(Ti, δi, xi)}Ntrain

i=1 , mtry = (cid:112)ncol(xtrain), n_split = 5, n_retry = 3, and

split_min_stat = 3.841459

for node ∈ nodes_to_split do

n_try ← 1
node_rows ← which(node_assignments ≡ node)
node_cols ← sample(from = {1, . . . , ncol(x)} , size = mtry, replace = F)
Dnode ← subset(Din-bag, rows = node_rows, columns = node_cols)
β ← newt_raph(Dnode, weights = subset(w, node_rows), max_iter = 1)
η ← xnode × β
C ← sample(from = unique(η), size = n_split, replace = F)
c ← argmaxc∗∈C {log_rank_stat(η, c∗)}
if log_rank_stat(η, c) ≥ split_min_stat then

1: T ← ∅
2: w ← sample(from = {0, . . . , 10} , size = nrow(xtrain), replace = T)
3: Din-bag ← subset(Dtrain, rows = which(w > 0))
4: w ← subset(w, which(w > 0))
5: node_assignments ← rep(1, times = nrow(xin-bag))
6: nodes_to_split ← {1}
7: while nodes_to_split (cid:54)= ∅ do
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
end for
35:
36: end while
37: return T

T ← add_node(T , name = node, beta = β, cutpoint = c)
(cid:46) Right node logic omitted for brevity (identical to left node logic)
node_left_name ← max(node_assignments) + 1
node_left_rows ← subset(node_rows, which(η ≤ c))
subset(node_assignments, node_left_rows) ← node_left_name
if is_splittable(subset(node_assignments, node_left_rows)) then

end if
nodes_to_split ← nodes_to_split \ {node}

else if n_try ≤ n_retry then
n_try ← n_try + 1
go to 11

T ← add_leaf(T , data = subset(Dnode, rows = node_left_rows))

nodes_to_split ← nodes_to_split ∪ node_left_name

T ← add_leaf(T , data = Dnode)

end if

else

else

5.1.1 Learners

We consider four classes of learners: RSFs (both axis-based and oblique), boosting ensembles, regression models, and
neural networks. Speciﬁc learners from each class are summarized in Table 1. To facilitate fair comparisons, tuning
parameters were harmonized within each class. For example, for RSF learners, we set the minimum node size (a
parameter shared by all RSF learners) as 10. Additionally, for RSF learners, the number of randomly selected predictors
was the square root of the total number of predictors rounded to the nearest integer, and the number of trees in the
ensemble was 500. For boosting, regression, and neural network learners, nested 10-fold cross-validation was applied
to tune relevant model parameters. Speciﬁcally, tuning for boosting models included identifying the number of steps to
complete. For regression models, tuning was used to identify the magnitude of penalization. For neural networks, the
number and density of layers was tuned.

5

Learner Class

Software

Learners

Description

Random Survival Forests
Axis based

RandomForestSRC
ranger
party
rotsf
rsfse

Oblique

obliqueRSF
aorsf

Boosting ensembles
Trees

xgboost

rsf-standard
rsf-extratrees
cif-standard
cif-rotate
cif-spacextend

obliqueRSF-net
aorsf-net
aorsf-fast
aorsf-cph
aorsf-extratrees

xgboost-cox
xgboost-aft

rsf-standard grows survival trees following Leo Breiman’s original random forest
algorithm with variables and cut-points selected to maximize a log-rank statistic.
rsf-extratrees grows survival trees with randomly selected features and cut-points.
cif-standard uses the framework of conditional inference to grow survival trees.
cif-rotate extends cif-standard by applying principal component analysis to
random subsets of data prior to growing each survival tree. cif-spacextend derives
new predictors for each tree in the ensemble, separately.
Oblique survival trees following Leo Breiman’s random forest algorithm. Linear
combinations of inputs are derived using glmnet in obliqueRSF-net and aorsf-net,
using Newton Raphson scoring for the Cox partial likelihood function in aorsf-fast
(1 iteration of scoring) and aorsf-cph (up to 20 iterations), and chosen randomly
from a uniform distribution in aorsf-extratrees. Cut-points are selected from 5
randomly selected candidates to maximize a log-rank statistic.

xgboost-cox maximizes the Cox partial likelihood function, whereas xgboost-aft
maximizes the accelerated failure time likelihood function. Nested cross validation
(5 folds) is applied to tune the number of trees grown, the minimum number of
p
observations in a leaf node was 10, the maximum depth of trees was 6, and
variables were considered randomly for each tree split, where p is the total number of
predictors.

√

6

Regression models
Cox Net

glmnet

glmnet-cox

The Cox proportional hazards model is ﬁt using an elastic net penalty. Nested cross
validation (5 folds) is applied to tune penalty terms.

Neural networks
Cox Time

survivalmodels

nn-cox

A neural network based on the proportional hazards model with time-varying effects.
Nested cross-validation was applied to select the number of layers (from 1 to 8), the
p), and the number of epochs to
number of nodes in each layer (from
complete (up to 500). A drop-out rate of 10% was applied during training.

p/2 to

√

√

Table 1: Learning algorithms assessed in numeric studies. aorsf-fast is the accelerated oblique random survival forest (see Algorithm 1), and each of the additional learners are
compared to aorsf-fast in numeric studies.

a
r
X
i
v
A
c
c
e
l
e
r
a
t
e
d
&

i
n
t
e
r
p
r
e
t
a
b
l
e

o
b
l
i
q
u
e
R
S
F
s

A
P
R
E
P
R

I

N
T

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

5.1.2 Evaluation of prediction accuracy

Our primary metric for evaluating the accuracy of predicted risk is the integrated and scaled Brier score [Graf
et al., 1999], a proper scoring rule that combines discrimination and calibration in one value and improves
interpretability by adjusting for a benchmark model [Kattan and Gerds, 2018]. Consider a testing data set:
Dtest = {(Ti, δi, xi)}Ntest
i=1 .

Let (cid:98)S(t | xi) be the predicted probability of survival up to a given prediction time of t > 0. For observation i
in Dtest, let (cid:98)S(t | xi) be the predicted probability of survival up to a given prediction time of t > 0. Deﬁne

(cid:99)BS(t) =

1
Ntest

Ntest(cid:88)

{ (cid:98)S(t | xi)2 · I(Ti ≤ t, δi = 1) · (cid:98)G(Ti)−1

i=1

+ [1 − (cid:98)S(t | xi)]2 · I(Ti > t) · (cid:98)G(t)−1}

where (cid:98)G(t) is the Kaplan-Meier estimate of the censoring distribution. As (cid:99)BS(t) is time dependent, integration
over time provides a summary measure of performance over a range of plausible prediction times. The
integrated (cid:99)BS(t) is deﬁned as

(cid:99)BS(t1, t2) =

1
t2 − t1

(cid:90) t2

t1

(cid:99)BS(t)dt.

(2)

In our results, t1 and t2 are the 25th and 75th percentile of event times, respectively. (cid:99)BS(t1, t2), a sum of
squared prediction errors, can be scaled to produce a measure of explained residual variation (i.e., an R2
statistic) by computing

R2 = 1 −

(cid:99)BS(t1, t2)
(cid:99)BS 0(t1, t2)

(3)

where (cid:99)BS 0(t1, t2) is the integrated Brier score when a Kaplan-Meier estimate for survival based on the
training data is used as the survival prediction function (cid:98)S(t). We refer to this R2 statistic as the index of
prediction accuracy (IPA) [Kattan and Gerds, 2018].

Our secondary metric for evaluating predicted risk is the time-dependent concordance (C)-statistic. We
compute the ﬁrst time-dependent C-statistic proposed by Blanche et al. [2013, Equation 3], which is interpreted
as the probability that a risk prediction model will assign higher risk to a case (i.e., an observation with T ≤ t
and δ = 1) versus a non-case (i.e., an observation with T > t). Similar to the IPA, observations with T ≤ t
and δ = 0 only contribute to inverse probability of censoring weights for the time-dependent C-statistic.

Both the IPA and time-dependent C-statistic generally take values between 0 and 1. To avoid presenting an
excessive amount of leading zeroes in our tables, ﬁgures, and text, we scale both the IPA and time-dependent
C-statistic by 100. For example, we present a value of 25 if the IPA is 0.25, 87 if the time-dependent C-statistic
is 0.87, and present 10.2 if the difference between two IPA values is 0.102

5.1.3 Data sets

We used a collection of 21 data sets containing a total of 35 risk prediction tasks (tasks per data set ranged
from one to four) to benchmark the accelerated oblique RSF versus other learners. Participant-level data from
the GUIDE-IT and SPRINT clinical trials and the ARIC, MESA, and JHS community cohort studies was
obtained from the National Institute of Health Biologic Specimen and Data Repository Coordinating Center
(BioLINCC). Designs and protocols for these studies have been made available [ARIC Investigators, 1989,
Bild et al., 2002, Felker et al., 2017, SPRINT Research Group, 2015, Taylor Jr et al., 2005]. All other datasets
were publicly available and obtained through R packages (see Appendix A.1). Across all prediction tasks, the

7

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

number of observations ranged from 137 to 17,549 (median: 1,384), the number of predictors ranged from 7
to 1,692 (median: 41), and the percentage of censored observations ranged from 5.26 to 97.7 (median: 78.1)
(Table A.1).

5.1.4 Monte-Carlo cross validation

For each risk prediction task, we completed 25 runs of Monte-Carlo cross validation. In each run, we used
a random sample containing 50% of the available data for training and the remaining 50% for testing each
of the learners described in Section 5.1.1. Then, for each learner, we computed the IPA, time-dependent
C-statistic, and computational time required to ﬁt a prediction model and compute risk predictions. If any
learner failed to obtain predictions on any particular split of data4, the results for that split were omitted from
downstream analyses.

5.1.5 Statistical analysis

After collecting data from 25 replications of Monte-Carlo cross validation for the 14 learners in all 35 risk
prediction tasks, we analyzed the resulting 12,250 observations of IPA and, separately, time-dependent
C-statistic, using a Bayesian linear mixed model. Our approach follows the ideas described by Benavoli et al.
[2017] and Kuhn and Wickham [2020], who developed guidelines on making statistical comparisons between
learners using Bayesian models. Speciﬁcally, we ﬁt two models:

IPA = (cid:98)γ0 + (cid:98)γ · learner + (1 | data/run)

and

C-stat = (cid:98)γ0 + (cid:98)γ · learner + (1 | data/run).
Random intercepts for speciﬁc splits of data (i.e., run in the model formula) were nested within datasets. The
intercept, (cid:98)γ0, was the expected value of the outcome using aorsf-fast, making the coefﬁcients in (cid:98)γ the
expected differences between aorsf-fast and other learners. Default priors from rstanarm were applied
for model ﬁtting [Goodrich et al., 2022].

Hypothesis testing For both the IPA and time-dependent C-statistic, we conducted equivalence and infe-
riority tests based on a 1 point region of practical equivalence. More speciﬁcally, we concluded that two
learners had practically equivalent IPA or time-dependent C-statistic if there was a 95% or higher posterior
probability that the absolute difference in the relevant metric was less than 1. We concluded that one learner
was weakly superior when there was ≥ 95% posterior probability that the absolute difference in the relevant
metric was non-zero, and concluded superiority when when there was ≥ 95% posterior probability that the
absolute difference in the relevant metric was 1 or more.

5.1.6 Results

A full summary of all results presented in this Section is provided in Table A.2. In total, 871 out of 875
Monte-Carlo cross validation runs were completed. On run 13, 18, 24 and 25 for the ACTG 320 data, the
nn-cox learner encountered an error during its ﬁtting procedure.

Index of prediction accuracy Compared to learners that were not oblique RSFs, aorsf-fast had the
highest IPA in 20 out of 35 risk prediction tasks, with an overall mean IPA of 12.7 (Figure 1). Compared to
the learner with the second highest mean IPA (cif-standard), aorsf-fast’s mean was 1.36 points higher,
a relative increase of 12.0%. The posterior probability of aorsf-fast and aorsf-cph having practically
equivalent expected IPA was 0.99, and the posterior probability of aorsf-fast having a superior IPA to

4For example, when the prediction task was to predict risk of death in the ACTG 320 clinical trial (26 events total),

some splits did not leave enough events in the training data to ﬁt complex learners such as the neural network

8

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

other learners ranged from 0.79 (versus cif-standard) to >0.999 (versus several other learners; see Figure
2)

Time-dependent concordance statistic Compared to learners that were not oblique RSFs, aorsf-fast
had the highest time-dependent C-statistic in 9 out of 35 risk prediction tasks, with an overall mean of 77.2
(Figure 3). Compared to the learner with the second highest mean C-statistic (cif-standard), aorsf-fast’s
mean was 0.721 points higher, a relative increase of 0.943%. The posterior probability of aorsf-fast and
aorsf-cph having practically equivalent expected time-dependent C-statistics was 0.99, and the posterior
probability of aorsf-fast having a superior time-dependent C-statistic versus other learners ranged from
0.24 (versus cif-standard) to >0.999 (versus several other learners; see Figure 4)

Computational efﬁciency Overall, aorsf-fast was the second fastest learner, with an expected model
development and risk prediction time about 256 milliseconds longer than glmnet-cox (Figure 5). Comparing
median computing times, aorsf-fast was 446.1 times faster than its predecessor, obliqueRSF-net. In
addition, aorsf-fast was 18.9, 1.83, and 3.12 faster than axis based forests grown using the party, ranger,
and randomForestSRC packages, respectively.

5.2 Benchmark of variable importance

The aim of this experiment is to evaluate negation VI and similar VI methods based on how well they can
discriminate between relevant and irrelevant variables, where relevance is deﬁned by having a relationship
with the simulated outcome. We consider methods that are intrinsic to the oblique RF (e.g., ANOVA VI),
those that are intrinsic to the RF (e.g., permutation VI), and those that are model-agnostic (e.g., SHAP VI).
VI methods with unavailable or still developing software were not included.5

5.2.1 Variable importance techniques

We compute permutation VI for axis based RSFs using the randomForestSRC package. We compute ANOVA
VI, negation VI, and permutation VI for oblique RSFs using the aorsf package. For ANOVA VI, we applied
a p-value threshold of 0.01, following the threshold recommended by Menze et al. [2011]. We compute
SHAP VI for boosted tree models using the xgboost package [Chen et al., 2022], which incorporates the
tree SHAP approach proposed by Lundberg et al. [2018].

5.2.2 Variable types

We considered ﬁve classes of predictor variables, with each class characterized by its variables’ relationship
to a right-censored outcome. Speciﬁcally,

• irrelevant variables had no relationship with the outcome.
• main effect variables had a linear relationship to the outcome.
• non-linear effect variables had a non-linear relationship to the outcome.
• combination effect variables were formed by linear combinations of three other variables. While
their combination was linearly related to the outcome, each of the three variables contributing to the
combination had no relation to the outcome.

• interaction effect variables were related to the outcome by multiplicative interaction with one other
variable, which could have been a main effect, non-linear effect, or combination effect variable.

5Although the party package implements the approach to VI developed by Strobl et al. [2007], the developers of the
party package note that the implementation of this approach for survival outcomes is “extremely slow and experimental”
as of version 1.3.10. Therefore, it is not incorporated in the current simulation study.

9

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Figure 1: Index of prediction accuracy for the accelerated oblique random survival forest and other learn-
ing algorithms across multiple risk prediction tasks. Text appears in tasks where the accelerated oblique
random survival forest obtained the highest index of prediction accuracy, showing the absolute and percent
improvement over the second best learner. As predicted survival probabilities are not a standard output from
xgboost-aft, it is not included in this ﬁgure. Also, since this ﬁgure is intended to compare aorsf-fast
to learners that are not oblique random survival forests, aorsf-cph, aorsf-net, aorsf-random, and
obliqueRSF-net are not included.

10

nn−coxxgboost−coxcif−extensionranger−extratreesglmnet−coxcif−rotatersf−standardcif−standardaorsf−fastOverallACTG 320; deathMonoclonal gammopathy; malignancyFCL; relapseMESA; strokeACTG 320; AIDS diagnosisJHS; strokeJHS; coronary heart diseaseNCCTG Lung Cancer; deathLung cancer; deathMESA; coronary heart diseaseEarly breast cancer; recurrence or deathGUIDE−IT; CVD deathSPRINT; CVD deathGUIDE−IT; HF hospitalizationARIC; strokeFCL; deathColon cancer; recurrenceColon cancer; deathNKI 70 gene signature; death or metastasisMESA; heart failureSPRINT; deathSystolic Heart Failure; deathGBSG II; recurrence or deathARIC; coronary heart diseaseMESA; deathRotterdam tumor bank; recurrenceMonoclonal gammopathy; deathRotterdam tumor bank; deathVA lung cancer trial; deathARIC; heart failureNon−alcohol fatty liver disease; deathARIC; deathSerum free light chain; deathPrimary biliary cholangitis; deathMovies released in 2015−2018; gross 1M USD+1.4 (12%)+0.54 (120%)+0.68 (24%)+0.13 (3.5%)+0.87 (17%)+0.47 (7.9%)+1.2 (19%)+0.74 (10%)+0.31 (3.4%)+0.87 (9.5%)+0.30 (3.1%)+0.33 (2.8%)+0.64 (5.9%)+0.62 (4.1%)+0.39 (2.8%)+0.13 (0.83%)+0.20 (1.0%)+0.43 (1.9%)+0.48 (2.3%)+0.27 (1.1%)+2.5 (6.2%)Dataset; outcomeIndex of Prediction Accuracy0102030405060arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Figure 2: Expected differences in index of prediction accuracy between the accelerated oblique random
survival forest and other learning algorithms. A region of practical equivalence is shown by purple dotted
lines, and a boundary of non-zero difference is shown by an orange dotted line at the origin.

11

aorsf−fastaorsf−cphaorsf−netobliqueRSF−netcif−standardrsf−standardcif−rotateglmnet−coxranger−extratreescif−extensionaorsf−randomxgboost−cox−−−0.990.970.240.210.180.120.020.000.000.000.00−−−0.510.71>.999>.999>.999>.999>.999>.999>.999>.999>.999−−−0.010.030.760.790.820.880.98>.999>.999>.999>.999LearnerScaled integrated Brier scorePosterior probabilityEquivalenceDifference < 0Difference < −1−5−4−3−2−101Difference versus aorsf−fastarXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Figure 3: Time-dependent concordance statistic for the accelerated oblique random survival forest and other
learning algorithms across multiple risk prediction tasks. Text appears in tasks where the accelerated oblique
random survival forest obtained the highest concordance, showing the absolute and percent improvement over
the second best learner. Since this ﬁgure is intended to compare aorsf-fast to learners that are not oblique
random survival forests, aorsf-cph, aorsf-net, aorsf-random, and obliqueRSF-net are not included.

12

nn−coxxgboost−coxcif−rotatersf−standardglmnet−coxcif−extensionranger−extratreesxgboost−aftcif−standardaorsf−fastOverallFCL; relapseMonoclonal gammopathy; malignancyNCCTG Lung Cancer; deathLung cancer; deathColon cancer; recurrenceColon cancer; deathGUIDE−IT; HF hospitalizationRotterdam tumor bank; recurrenceGUIDE−IT; CVD deathEarly breast cancer; recurrence or deathGBSG II; recurrence or deathMonoclonal gammopathy; deathACTG 320; AIDS diagnosisSystolic Heart Failure; deathFCL; deathRotterdam tumor bank; deathMESA; strokeSPRINT; deathNKI 70 gene signature; death or metastasisACTG 320; deathJHS; coronary heart diseaseVA lung cancer trial; deathMESA; deathARIC; strokeARIC; deathSPRINT; CVD deathJHS; strokeMESA; coronary heart diseaseARIC; coronary heart diseaseSerum free light chain; deathARIC; heart failureMESA; heart failureNon−alcohol fatty liver disease; deathPrimary biliary cholangitis; deathMovies released in 2015−2018; gross 1M USD+0.72 (0.94%)+1.4 (2.1%)+0.68 (0.96%)+0.19 (0.27%)+0.34 (0.43%)+5.1 (6.5%)+0.34 (0.42%)+0.20 (0.25%)+0.18 (0.22%)+0.46 (0.51%)Dataset; outcomeC−statistic708090100arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Figure 4: Expected differences in time-dependent concordance statistic between the accelerated oblique
random survival forest and other learning algorithms. A region of practical equivalence is shown by purple
dotted lines, and a boundary of non-zero difference is shown by an orange dotted line at the origin.

13

aorsf−fastaorsf−cphobliqueRSF−netaorsf−netcif−standardxgboost−aftranger−extratreescif−extensionglmnet−coxrsf−standardcif−rotatexgboost−coxaorsf−random−−−0.990.990.990.760.450.380.320.050.020.020.000.00−−−0.660.730.760.98>.999>.999>.999>.999>.999>.999>.999>.999−−−0.000.010.010.240.550.620.680.950.980.98>.999>.999LearnerTime−dependent C−statisticPosterior probabilityEquivalenceDifference < 0Difference < −1−5−4−3−2−101Difference versus aorsf−fastarXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Figure 5: Distribution of time taken to ﬁt a prediction model and compute predicted risk. The median time, in
seconds, is printed and annotated for each learner by a vertical line.

14

0.486s0.742s1.36s1.60s1.95s2.32s3.98s13.1s14.1s18.7s31.1s45.2s80.4s331.1sglmnet−coxaorsf−fastranger−extratreesaorsf−cphaorsf−randomrsf−standardxgboost−coxxgboost−aftcif−standardnn−coxcif−extensioncif−rotateaorsf−netobliqueRSF−net0.11101001,00010,000Time to fit a model and compute predictions, secondsarXiv Accelerated & interpretable oblique RSFs

A PREPRINT

5.2.3 Simulated data

We initiated each set of simulated data with a random draw of size n from a p-dimensional multivariate
normal distribution, yielding n observations of p predictors. Each of p predictor variables had a mean of
zero, standard deviation of 1, and correlation with other predictor variables drawn at random between a lower
and upper boundary. A time-to-event outcome with roughly 45% of observations censored was generated
using the simsurv package. The full predictor matrix (i.e., including interactions, non-linear mappings, and
combinations) was used to generate the outcome. Interactions, non-linear mappings, and combinations were
dropped from the predictor matrix after the outcome was generated so that VI techniques could be evaluated
based on their ability to detect these effects.

5.2.4 Parameter speciﬁcations

Parameters that varied in the current simulation study included the number of observations (500, 1000, and
2500) and the absolute value of the maximum correlation between predictors (0.3, 0.15, and 0). Parameters
that remain ﬁxed throughout the study included the number of predictors in each class (15) and the effect size
of each predictor (one standard deviation increase associated with a 64% increase in relative risk). Using this
design for simulated data, the Heller explained relative risk (95% conﬁdence interval) of our covariates was
88.4 (88.1, 88.7) [Heller, 2012] with 2,500 observations.

5.2.5 Evaluation of variable importance

We compared VI techniques based on their discrimination (i.e., C-statistic) between relevant and irrelevant
variables. Speciﬁcally, we generated a binary outcome for each predictor variable based on its relevance (i.e.,
the binary outcome is 1 if the variable is relevant, 0 otherwise). Treating VI as if it were a ‘prediction’ for
these binary outcomes yields a C-statistic which may be interpreted as the probability that the VI technique
will rank a relevant variable higher than an irrelevant variable [Harrell et al., 1982].

5.2.6 Results

The three techniques that used ‘aorsf’ to estimate VI were ranked ﬁrst (aorsf-negate; C = 75.9), second
(aorsf-anova; C = 73.9), and third (aorsf-permute; C = 73.2) in overall mean C-statistic across all
of the simulation scenarios, with aorsf-negate obtaining the highest C-statistic in 26 out of 36 VI tasks
(Figure 6). Among the four relevant variable classes, aorsf-negate had the highest mean C-statistic for
main effects, combination effects, and non-linear effects, with the greatest advantage of using aorsf-negate
occurring among non-linear and combination variables. Full results from the experiment are provided in
Table A.3. Computationally, ANOVA VI was faster than negation and permutation VI, with a median time of
2.88 seconds versus 20.4 and 21.8 seconds, respectively.

6 Discussion

In this paper, we have developed two contributions to the oblique RSF: (1) the accelerated oblique RSF
(i.e., aorsf-fast) and (2) negation VI. Our technique to accelerate the oblique RSF reduces the number
of operations required to ﬁnd linear combinations of inputs using a single iteration of Newton Raphson
scoring, while our VI technique directly engages with coefﬁcients in linear combinations of inputs to measure
importance of individual variables. In numeric experiments, we found that that aorsf-fast is approximately
446.1 times faster than its predecessor, obliqueRSF-net, with a practically equivalent C-statistic. We also
found that negation VI, a technique to estimate VI using the oblique RSF, detected non-linear, combination,
and main effects more effectively than three standard methods to estimate VI: permutation, ANOVA, and
SHAP VI. Overall, we found that estimating VI using negation instead of ANOVA increased the C-statistic
for ranking a relevant variable higher than an irrelevant variable by 2.05, a relative increase of 2.78%.

15

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Figure 6: Concordance statistic for assigning higher importance to relevant versus irrelevant variables. Text
appears in rows where negation importance obtained the highest concordance, showing absolute and percent
improvement over the second best technique.

16

xgboost−gainrandomForestSRC−permutationxgboost−shapaorsf−permuteaorsf−anovaaorsf−negate  0%    15%    30%    OverallCombination effects  0%    15%    30%    OverallInteractions  0%    15%    30%    OverallMain effects  0%    15%    30%    OverallNon−linear effectsOverallMax correlationNo. observations500100025005001000250050010002500500100025005001000250050010002500500100025005001000250050010002500500100025005001000250050010002500Probability of higher importance for relevant variables+2.5 (3.3%)+3.0 (3.3%)+3.3 (4.7%)+2.0 (3.1%)+0.17 (0.17%)+1.5 (1.9%)+1.3 (2.0%)+2.8 (3.5%)+2.3 (3.3%)+1.3 (2.0%)+2.1 (2.3%)+0.24 (0.24%)+2.9 (3.2%)+2.7 (3.4%)+0.73 (0.78%)+1.3 (1.5%)+1.5 (1.6%)+3.0 (3.6%)+2.0 (2.6%)+2.4 (3.5%)+4.4 (5.3%)+2.3 (3.6%)+1.7 (2.9%)+0.72 (0.74%)+1.1 (1.6%)+1.0 (1.6%)+3.3 (4.5%)+2.2 (3.6%)+0.44 (0.75%)+2.1 (2.8%)0.500.751.00arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

6.1 Implications of our results

Accurate risk prediction models have the potential to improve healthcare by directing timely interventions to
patients who are most likely to beneﬁt. However, prediction models that cannot scale adequately to large
databases or cannot be interpreted and explained will struggle to gain acceptance in clinical practice [Moss
et al., 2022]. The current study advances the oblique RSF, an accurate risk prediction model, towards being
accurate, scalable, and interpretable. The improved computational efﬁciency of the accelerated oblique RSF
increases the feasibility of applying oblique RSFs in a wide range of prediction tasks. Faster model evaluation
and re-ﬁtting also improve diagnosis and resolution of model-based issues (e.g., model calibration deteriorates
over time). The introduction of negation VI also advances interpretability. VI is intrinsically linked to model
fairness, as it can be used to identify when protected characteristics such as race, religion, and sexuality are
inadvertently used (either directly or through correlates of these characteristics) by a prediction model. Since
negation VI engages with the coefﬁcients used in linear combinations of variables, a major component of
oblique RSFs, it may be more capable of diagnosing unfairness in oblique RSFs compared to permutation
importance and model-agnostic VI techniques.

6.2 Limitations and next steps

While the current study advances the oblique RSF towards being scalable and interpretable, there remain
several limitations that can be targeted in future studies. The accelerated oblique RSF does not account for
competing risks, and biased estimation of incidence may occur when competing risks are ignored. Thus,
allowing the oblique RSF to account for competing risks is a high priority for future studies. In addition,
the current study only considered data without missing values, only evaluated oblique RSFs that applied the
log-rank statistic for node splitting, and only considered negation VI estimates based on Harrell’s C-statistic.
Few studies have developed strategies to deal with missing data while growing oblique survival trees. Prior
studies have found that log-rank tests can be mis-informative when survival curves cross [Li et al., 2015], and
that Harrell’s C-statistic is dependent on the censoring distribution of the outcome [Uno et al., 2011]. Thus, a
second item is to expand the range of options available to users of the aorsf package, enabling them to apply
strategies for imputation of missing values and use a broad range of statistical criteria while growing oblique
survival trees. Last, Cui et al. [2017] found that estimating an inverse-probability weighted hazard function at
each non-leaf node of a survival tree allows the RSF to converge asymptotically to the true survival function
when some variables contribute both to the risk of the event and the risk of censoring, a scenario that is very
likely in the analysis of medical data. The accelerated oblique RSF could incorporate this splitting technique
by using Newton Raphson scoring to ﬁt a model for the censoring distribution after which a weighted model
could be ﬁt to the failure distribution. This ﬁnal item has the highest priority, as Cui et al. [2017] showed it is
a requisite condition for consistency of axis-based survival trees in fairly general settings.

Oblique RSFs have exceptional prediction accuracy and this study has shown how they can be ﬁt with
computational efﬁciency that rivals their axis-based counterparts. We have also introduced a general and
ﬂexible method to estimate VI with oblique RFs, and demonstrated its effectiveness speciﬁcally for the
oblique RSF. Code used for the current study is available at https://github.com/bcjaeger/aorsf-bench, and the
aorsf package is available at https://github.com/bcjaeger/aorsf.

Acknowledgements

Research reported in this publication was supported by the Center for Biomedical Informatics, Wake Forest
University School of Medicine. The project described was supported by the National Center for Advancing
Translational Sciences (NCATS), National Institutes of Health, through Grant Award Number UL1TR001420.
The content is solely the responsibility of the authors and does not necessarily represent the ofﬁcial views of
the NIH.

17

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Appendix

Data sources

1. The “VA lung cancer trial” data [Kalbﬂeisch and Prentice, 2011] were obtained from the

randomForestSRC R package [Ishwaran and Kogalur, 2019].

2. The “Colon cancer” data [Moertel et al., 1995] were obtained from the survival R package

[Therneau, 2022a].

3. The “Primary biliary cholangitis” data [Therneau and Grambsch, 2000] were obtained from the

aorsf R package [Jaeger, 2022].

4. The “Movies released in 2015-2018” data were obtained from the censored R package [Hvitfeldt

and Frick].

5. The “GBSG II” data [Schumacher, 1994] were obtained from the TH.data R package [Hothorn,

2022].

6. The “Systolic Heart Failure” data [Hsich et al., 2011] were obtained from the randomForestSRC R

package [Ishwaran and Kogalur, 2019].

7. The “Serum free light chain” data [Dispenzieri et al., 2012, Kyle et al., 2006] were obtained from

the survival R package [Therneau, 2022a].

8. The “Non-alcohol fatty liver disease” data [Allen et al., 2018] were obtained from the survival R

package [Therneau, 2022a].

9. The “Rotterdam tumor bank” data [Royston and Altman, 2013] were obtained from the survival

R package [Therneau, 2022a].

10. The “ACTG 320” data [Hosmer and Lemeshow, 2002] were obtained from the mlr3proba R

package [Sonabend et al., 2021].

11. The “GUIDE-IT” data [Felker et al., 2017] were obtained from BioLINCC.
12. The “Early breast cancer” data [Desmedt et al., 2011, Hatzis et al., 2011, Ternès et al., 2017] were

obtained from the biospear R package [Ternes et al., 2018].

13. The “SPRINT” data [SPRINT Research Group, 2015] were obtained from BioLINCC.
14. The “NKI 70 gene signature” data [Van De Vijver et al., 2002] were obtained from the OpenML R

package [Casalicchio et al., 2017].

15. The “Lung cancer” data [Director’s Challenge Consortium for the Molecular Classiﬁcation of Lung
Adenocarcinoma, 2008] were obtained from the OpenML R package [Casalicchio et al., 2017].
16. The “NCCTG Lung Cancer” data [Loprinzi et al., 1994] were obtained from the survival R

package [Therneau, 2022a].

17. The “FCL” data [Pintilie, 2006] were obtained from the randomForestSRC R package [Ishwaran

and Kogalur, 2019].

18. The “Monoclonal gammopathy” data [Kyle et al., 2002] were obtained from the survival R

package [Therneau, 2022a].

19. The “MESA” data [Bild et al., 2002] were obtained from BioLINCC.
20. The “ARIC” data [ARIC Investigators, 1989] were obtained from BioLINCC.
21. The “JHS” data [Taylor Jr et al., 2005] were obtained from BioLINCC.

18

Label

VA lung cancer trial

Colon cancer

Primary biliary cholangitis

Movies released in 2015-2018

GBSG II

Systolic Heart Failure

Serum free light chain

Non-alcohol fatty liver disease

17,549

A.1: Data sets used for numeric experiments

N observations N predictors Outcome

N Events % Censored

137

929

276

551

686

2,231

7,874

2,982

1,151

894

614

8

12

19

46

10

41

10

24

11

12

59

Death

Recurrence

Death

Death

Gross 1M USD

Recurrence Or Death

Death

Death

Death

Recurrence

Death

AIDS Diagnosis

Death

Cardiovascular Death

Hf Hospitalization

1,692

Recurrence Or Death

Cardiovascular Death

9,361

174

Death

144

442

228

541

77

24

9

7

Death Or Metastasis

Death

Death

Death

Relapse

Death

128

468

452

111

522

299

726

2,169

1,364

1,518

1,272

96

26

110

288

134

521

1,644

48

236

165

76

272

963

6.57

49.6

51.3

59.8

5.26

56.4

67.5

72.5

92.2

49.1

57.3

91.7

97.7

87.7

67.8

78.2

94.4

82.4

66.7

46.6

27.6

86.0

49.7

30.4

a
r
X
i
v
A
c
c
e
l
e
r
a
t
e
d
&

i
n
t
e
r
p
r
e
t
a
b
l
e

o
b
l
i
q
u
e
R
S
F
s

A
P
R
E
P
R

I

N
T

1
9

Rotterdam tumor bank

ACTG 320

GUIDE-IT

Early breast cancer

SPRINT

NKI 70 gene signature

Lung cancer

NCCTG Lung Cancer

FCL

Monoclonal gammopathy

1,384

MESA

6,783

ARIC

JHS

13,623

3,501

8

48

41

80

Malignancy

Heart Failure

Coronary Heart Disease

Stroke

Death

Heart Failure

Coronary Heart Disease

Stroke

Death

Stroke

Coronary Heart Disease

115

339

439

292

1,297

2,981

2,282

1,323

6,662

152

190

91.7

95.0

93.5

95.7

80.9

78.1

83.2

90.3

51.1

95.8

94.6

2
0

a
r
X
i
v
A
c
c
e
l
e
r
a
t
e
d
&

i
n
t
e
r
p
r
e
t
a
b
l
e

o
b
l
i
q
u
e
R
S
F
s

A
P
R
E
P
R

I

N
T

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks.

Performance metric (SD)

Computation time, seconds

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

Overall

aorsf-fast
aorsf-cph
aorsf-net
obliqueRSF-net
cif-standard
rsf-standard
cif-rotate
glmnet-cox
ranger-extratrees
cif-extension
aorsf-random
xgboost-cox
nn-cox
xgboost-aft

0.127 (0.109)
0.126 (0.109)
0.124 (0.112)
0.113 (0.085)
0.113 (0.098)
0.113 (0.114)
0.112 (0.124)
0.108 (0.119)
0.099 (0.085)
0.095 (0.092)
0.090 (0.081)
0.064 (0.100)
0.047 (0.108)
—

0.772 (0.071)
0.771 (0.070)
0.771 (0.071)
0.771 (0.071)
0.765 (0.071)
0.755 (0.075)
0.755 (0.081)
0.757 (0.077)
0.762 (0.067)
0.761 (0.072)
0.742 (0.063)
0.749 (0.094)
0.656 (0.138)
0.762 (0.076)

ACTG 320; AIDS diagnosis, n = 1151, p = 12

aorsf-random
ranger-extratrees
obliqueRSF-net
aorsf-cph
cif-standard
aorsf-fast
cif-extension
aorsf-net
glmnet-cox
rsf-standard
cif-rotate
xgboost-cox
nn-cox
xgboost-aft

0.028 (0.022)
0.028 (0.017)
0.027 (0.022)
0.025 (0.029)
0.024 (0.031)
0.024 (0.028)
0.023 (0.015)
0.019 (0.034)
0.016 (0.030)
0.005 (0.041)
0.004 (0.040)
0.000 (0.044)
-0.001 (0.008)
—

ACTG 320; death, n = 1151, p = 12
0.010 (0.022)
0.007 (0.011)
0.007 (0.018)
0.005 (0.014)
0.001 (0.020)
0.001 (0.019)
-0.004 (0.004)
-0.004 (0.004)
-0.005 (0.025)
-0.005 (0.032)
-0.031 (0.051)
-0.037 (0.049)

aorsf-fast
obliqueRSF-net
aorsf-cph
aorsf-random
cif-extension
ranger-extratrees
xgboost-cox
nn-cox
cif-standard
aorsf-net
rsf-standard
cif-rotate

0.748 (0.038)
0.740 (0.036)
0.746 (0.038)
0.751 (0.042)
0.744 (0.040)
0.745 (0.044)
0.722 (0.038)
0.745 (0.042)
0.746 (0.037)
0.730 (0.042)
0.731 (0.038)
0.751 (0.033)
0.549 (0.125)
0.737 (0.035)

0.840 (0.054)
0.823 (0.052)
0.821 (0.060)
0.788 (0.074)
0.765 (0.066)
0.777 (0.069)
0.500 (0.000)
0.508 (0.119)
0.781 (0.062)
0.806 (0.067)
0.776 (0.073)
0.707 (0.090)

21

0.593
1.344
79.741
300.393
4.293
2.099
37.695
0.473
0.878
22.321
1.855
3.973
15.352
13.060

0.539
0.064
25.980
0.471
1.771
0.198
9.848
18.451
0.179
0.192
16.095
3.704
11.075
10.015

0.086
8.869
0.414
0.278
8.436
0.044
0.119
10.867
1.726
14.625
0.090
13.920

0.146
0.148
0.158
18.803
6.044
0.199
8.348
0.003
1.156
6.949
0.152
0.004
2.060
0.007

0.040
0.146
15.236
0.033
4.657
0.033
4.083
0.035
0.003
0.061
3.888
0.003
0.668
0.006

0.020
11.004
0.020
0.023
3.493
0.138
0.002
0.518
4.648
0.023
0.035
3.444

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

glmnet-cox
xgboost-aft

-0.065 (0.095)
—

0.746 (0.098)
0.773 (0.071)

0.281
9.190

ARIC; coronary heart disease, n = 13623, p = 41

aorsf-fast
aorsf-cph
aorsf-net
rsf-standard
obliqueRSF-net
cif-standard
glmnet-cox
nn-cox
ranger-extratrees
cif-rotate
aorsf-random
cif-extension
xgboost-cox
xgboost-aft

0.157 (0.007)
0.153 (0.006)
0.152 (0.006)
0.150 (0.007)
0.143 (0.005)
0.132 (0.005)
0.129 (0.011)
0.117 (0.029)
0.112 (0.005)
0.104 (0.004)
0.098 (0.005)
0.069 (0.002)
0.064 (0.017)
—

ARIC; death, n = 13623, p = 41

aorsf-net
rsf-standard
aorsf-cph
aorsf-fast
obliqueRSF-net
cif-standard
nn-cox
glmnet-cox
ranger-extratrees
cif-rotate
xgboost-cox
aorsf-random
cif-extension
xgboost-aft

0.217 (0.006)
0.216 (0.006)
0.216 (0.006)
0.215 (0.007)
0.207 (0.005)
0.201 (0.004)
0.193 (0.011)
0.191 (0.015)
0.181 (0.004)
0.151 (0.007)
0.131 (0.012)
0.130 (0.005)
0.113 (0.002)
—

ARIC; heart failure, n = 13623, p = 41

aorsf-fast
rsf-standard
aorsf-cph
aorsf-net
obliqueRSF-net
cif-standard
nn-cox
cif-rotate
ranger-extratrees
glmnet-cox
aorsf-random
xgboost-cox

0.234 (0.006)
0.229 (0.006)
0.229 (0.006)
0.228 (0.006)
0.212 (0.005)
0.199 (0.005)
0.180 (0.017)
0.172 (0.006)
0.170 (0.004)
0.167 (0.044)
0.139 (0.005)
0.122 (0.017)

0.810 (0.007)
0.809 (0.007)
0.809 (0.007)
0.801 (0.007)
0.811 (0.008)
0.809 (0.007)
0.795 (0.008)
0.786 (0.046)
0.795 (0.009)
0.783 (0.009)
0.772 (0.008)
0.786 (0.009)
0.814 (0.006)
0.814 (0.006)

0.792 (0.004)
0.789 (0.004)
0.792 (0.004)
0.792 (0.004)
0.791 (0.004)
0.790 (0.004)
0.780 (0.005)
0.777 (0.007)
0.780 (0.005)
0.757 (0.006)
0.794 (0.004)
0.734 (0.005)
0.775 (0.005)
0.794 (0.004)

0.841 (0.005)
0.835 (0.005)
0.841 (0.005)
0.841 (0.005)
0.841 (0.005)
0.839 (0.005)
0.826 (0.007)
0.806 (0.007)
0.824 (0.005)
0.817 (0.018)
0.789 (0.006)
0.845 (0.005)

22

4.640
14.503
533.804
9.407
2830.398
71.835
1.473
51.356
293.864
569.289
11.694
169.206
8.544
23.781

932.212
14.727
22.922
7.641
7329.229
72.253
103.296
2.256
332.296
589.958
11.220
20.175
180.483
28.692

5.268
11.238
16.864
623.727
3737.617
71.854
56.056
589.494
387.176
2.141
14.001
10.926

0.002
0.005

1.320
1.347
1.437
0.991
356.908
371.102
0.011
84.715
61.837
67.436
1.330
56.091
0.015
0.013

2.377
1.274
2.179
2.214
331.164
384.744
92.992
0.011
70.372
66.749
0.015
2.057
54.092
0.014

2.193
1.079
2.308
1.685
320.616
391.419
96.125
69.448
77.513
0.011
1.519
0.015

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

cif-extension
xgboost-aft

0.109 (0.003)
—

0.808 (0.006)
0.844 (0.005)

176.907
24.549

ARIC; stroke, n = 13623, p = 41

aorsf-fast
aorsf-net
aorsf-cph
rsf-standard
obliqueRSF-net
glmnet-cox
cif-standard
nn-cox
ranger-extratrees
aorsf-random
cif-rotate
xgboost-cox
cif-extension
xgboost-aft

0.093 (0.004)
0.090 (0.004)
0.090 (0.004)
0.090 (0.006)
0.082 (0.003)
0.078 (0.004)
0.073 (0.003)
0.070 (0.012)
0.067 (0.003)
0.059 (0.004)
0.052 (0.003)
0.046 (0.014)
0.036 (0.002)
—

Colon cancer; death, n = 929, p = 12

aorsf-fast
aorsf-cph
cif-standard
aorsf-net
aorsf-random
obliqueRSF-net
cif-rotate
rsf-standard
ranger-extratrees
cif-extension
glmnet-cox
xgboost-cox
nn-cox
xgboost-aft

0.100 (0.014)
0.099 (0.014)
0.097 (0.013)
0.096 (0.014)
0.096 (0.010)
0.089 (0.006)
0.086 (0.017)
0.086 (0.019)
0.083 (0.007)
0.080 (0.006)
0.075 (0.016)
0.062 (0.013)
-0.003 (0.003)
—

0.793 (0.007)
0.792 (0.007)
0.792 (0.007)
0.784 (0.006)
0.791 (0.007)
0.787 (0.007)
0.787 (0.007)
0.783 (0.010)
0.779 (0.008)
0.750 (0.008)
0.768 (0.009)
0.794 (0.006)
0.769 (0.009)
0.793 (0.006)

0.718 (0.012)
0.717 (0.011)
0.710 (0.012)
0.717 (0.012)
0.716 (0.011)
0.717 (0.012)
0.705 (0.014)
0.704 (0.011)
0.710 (0.012)
0.709 (0.011)
0.711 (0.019)
0.701 (0.013)
0.508 (0.033)
0.706 (0.013)

Colon cancer; recurrence, n = 929, p = 12

aorsf-fast
aorsf-cph
aorsf-net
aorsf-random
cif-standard
obliqueRSF-net
cif-rotate
cif-extension
rsf-standard
ranger-extratrees
glmnet-cox
xgboost-cox

0.099 (0.017)
0.098 (0.017)
0.095 (0.018)
0.091 (0.013)
0.091 (0.016)
0.087 (0.009)
0.084 (0.020)
0.081 (0.009)
0.081 (0.020)
0.079 (0.011)
0.073 (0.018)
0.059 (0.011)

0.713 (0.016)
0.712 (0.015)
0.713 (0.017)
0.706 (0.013)
0.701 (0.017)
0.711 (0.015)
0.694 (0.017)
0.706 (0.017)
0.694 (0.015)
0.700 (0.016)
0.706 (0.024)
0.695 (0.018)

23

4.179
371.989
13.462
8.991
1869.359
1.673
73.989
32.099
251.130
9.712
586.962
7.316
169.866
20.363

0.239
0.638
0.745
49.140
0.919
252.190
13.242
1.901
0.560
8.397
0.128
3.217
12.769
10.290

0.225
0.629
49.866
0.926
0.717
249.790
13.154
8.446
1.831
0.636
0.125
3.136

57.216
0.013

1.122
1.175
1.149
0.984
387.014
0.011
364.863
82.720
50.542
1.132
68.410
0.015
53.493
0.013

0.053
0.052
3.685
0.047
0.044
16.726
3.448
0.150
0.248
3.363
0.003
0.003
1.106
0.006

0.050
0.050
0.048
0.043
3.703
16.701
3.977
4.066
0.153
0.254
0.003
0.003

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

13.107
11.227

nn-cox
xgboost-aft

0.531 (0.054)
0.701 (0.019)

-0.005 (0.006)
—
Early breast cancer; recurrence or death, n = 614, p = 1692
0.072 (0.023)
0.070 (0.018)
0.067 (0.019)
0.067 (0.029)
0.065 (0.028)
0.064 (0.016)
0.061 (0.022)
0.041 (0.032)
0.027 (0.015)
0.027 (0.034)
0.024 (0.037)
0.012 (0.062)
-0.006 (0.043)
—

obliqueRSF-net
cif-rotate
cif-standard
aorsf-cph
aorsf-fast
cif-extension
ranger-extratrees
glmnet-cox
aorsf-random
xgboost-cox
rsf-standard
aorsf-net
nn-cox
xgboost-aft

0.751 (0.029)
0.747 (0.027)
0.747 (0.030)
0.747 (0.026)
0.746 (0.026)
0.746 (0.028)
0.742 (0.031)
0.724 (0.036)
0.696 (0.038)
0.741 (0.030)
0.695 (0.033)
0.740 (0.025)
0.669 (0.075)
0.744 (0.027)

1901.883
6452.563
9.660
1.287
0.724
44.047
0.228
5.780
1.260
2.258
0.366
465.845
19.374
9.708

FCL; death, n = 541, p = 7

glmnet-cox
aorsf-cph
aorsf-fast
aorsf-net
obliqueRSF-net
cif-rotate
cif-extension
aorsf-random
cif-standard
ranger-extratrees
rsf-standard
xgboost-cox
nn-cox
xgboost-aft

0.117 (0.028)
0.100 (0.039)
0.100 (0.038)
0.097 (0.040)
0.089 (0.027)
0.087 (0.048)
0.087 (0.036)
0.087 (0.029)
0.084 (0.038)
0.073 (0.016)
0.072 (0.048)
0.029 (0.050)
-0.004 (0.014)
—

FCL; relapse, n = 541, p = 7

glmnet-cox
ranger-extratrees
obliqueRSF-net
aorsf-random
xgboost-cox
cif-standard
aorsf-cph
aorsf-fast
aorsf-net
cif-extension
nn-cox
cif-rotate

0.029 (0.017)
0.017 (0.016)
0.013 (0.016)
0.013 (0.018)
0.010 (0.016)
0.008 (0.021)
0.007 (0.020)
0.007 (0.019)
0.006 (0.020)
-0.005 (0.023)
-0.008 (0.023)
-0.012 (0.025)

0.098
0.169
0.090
12.619
97.158
6.083
5.256
0.256
0.347
0.043
0.156
0.266
11.152
6.738

0.100
0.041
217.838
0.394
1.331
0.315
0.262
0.122
18.761
6.164
12.031
7.411

0.787 (0.037)
0.769 (0.033)
0.768 (0.033)
0.760 (0.034)
0.758 (0.036)
0.755 (0.027)
0.730 (0.034)
0.757 (0.032)
0.743 (0.036)
0.741 (0.037)
0.732 (0.034)
0.679 (0.121)
0.549 (0.110)
0.754 (0.038)

0.620 (0.024)
0.596 (0.025)
0.593 (0.024)
0.595 (0.024)
0.598 (0.031)
0.594 (0.023)
0.595 (0.026)
0.594 (0.025)
0.592 (0.026)
0.580 (0.028)
0.526 (0.055)
0.583 (0.030)

24

0.969
0.006

14.017
360.067
4.247
0.185
0.177
6.554
0.169
0.006
0.175
0.007
0.743
0.175
1.808
0.010

0.002
0.018
0.018
0.018
5.447
1.964
2.514
0.018
1.132
0.078
0.040
0.002
0.406
0.005

0.002
0.081
6.232
0.021
0.002
1.056
0.021
0.021
0.022
2.309
0.466
2.486

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

rsf-standard
xgboost-aft

-0.026 (0.032)
—

0.577 (0.024)
0.582 (0.034)

1.081
6.223

GBSG II; recurrence or death, n = 686, p = 10

obliqueRSF-net
cif-standard
rsf-standard
aorsf-net
aorsf-cph
aorsf-fast
cif-extension
cif-rotate
aorsf-random
ranger-extratrees
glmnet-cox
xgboost-cox
nn-cox
xgboost-aft

0.124 (0.016)
0.123 (0.020)
0.120 (0.023)
0.120 (0.024)
0.120 (0.025)
0.115 (0.024)
0.114 (0.017)
0.107 (0.023)
0.104 (0.023)
0.094 (0.018)
0.090 (0.019)
0.083 (0.017)
-0.007 (0.012)
—

0.746 (0.017)
0.743 (0.020)
0.738 (0.019)
0.738 (0.020)
0.736 (0.018)
0.733 (0.017)
0.743 (0.019)
0.729 (0.017)
0.724 (0.025)
0.736 (0.025)
0.728 (0.021)
0.730 (0.020)
0.509 (0.061)
0.729 (0.021)

GUIDE-IT; CVD death, n = 894, p = 59

aorsf-fast
aorsf-net
aorsf-cph
glmnet-cox
obliqueRSF-net
cif-rotate
cif-standard
ranger-extratrees
cif-extension
rsf-standard
xgboost-cox
aorsf-random
nn-cox
xgboost-aft

0.075 (0.018)
0.074 (0.019)
0.071 (0.018)
0.063 (0.041)
0.063 (0.013)
0.059 (0.016)
0.058 (0.014)
0.054 (0.013)
0.052 (0.011)
0.046 (0.023)
0.039 (0.051)
0.033 (0.012)
0.008 (0.018)
—

0.746 (0.027)
0.743 (0.027)
0.741 (0.028)
0.715 (0.091)
0.741 (0.023)
0.721 (0.025)
0.738 (0.022)
0.737 (0.029)
0.730 (0.022)
0.705 (0.025)
0.747 (0.020)
0.695 (0.030)
0.630 (0.123)
0.734 (0.020)

GUIDE-IT; HF hospitalization, n = 894, p = 59

aorsf-net
aorsf-cph
aorsf-fast
ranger-extratrees
obliqueRSF-net
cif-standard
cif-rotate
cif-extension
glmnet-cox
rsf-standard
nn-cox
aorsf-random

0.082 (0.017)
0.081 (0.018)
0.081 (0.019)
0.073 (0.010)
0.073 (0.010)
0.070 (0.010)
0.067 (0.019)
0.064 (0.009)
0.058 (0.020)
0.058 (0.022)
0.053 (0.028)
0.049 (0.010)

0.722 (0.023)
0.722 (0.023)
0.722 (0.025)
0.722 (0.022)
0.721 (0.023)
0.716 (0.023)
0.708 (0.029)
0.714 (0.022)
0.699 (0.025)
0.694 (0.026)
0.706 (0.032)
0.682 (0.023)

25

286.149
0.507
1.437
36.113
0.411
0.168
7.560
11.241
0.754
0.102
0.106
2.538
11.658
10.625

0.152
29.058
0.403
0.502
221.806
35.190
1.564
0.118
13.507
0.195
3.831
0.536
12.211
11.525

53.095
0.659
0.232
0.137
389.465
1.468
41.655
15.396
0.416
1.515
12.912
0.914

0.088
0.005

6.874
2.289
0.115
0.038
0.038
0.037
2.919
3.023
0.036
0.143
0.002
0.003
0.746
0.006

0.036
0.041
0.037
0.002
11.417
4.947
3.334
0.176
5.567
0.064
0.003
0.039
0.596
0.006

0.058
0.052
0.052
0.198
9.365
3.315
5.185
6.113
0.003
0.121
0.599
0.054

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

xgboost-cox
xgboost-aft

0.038 (0.017)
—

0.698 (0.027)
0.697 (0.025)

2.955
11.409

JHS; coronary heart disease, n = 3501, p = 80

aorsf-cph
obliqueRSF-net
aorsf-fast
aorsf-net
cif-standard
cif-extension
ranger-extratrees
cif-rotate
glmnet-cox
rsf-standard
nn-cox
aorsf-random
xgboost-cox
xgboost-aft

0.040 (0.008)
0.039 (0.007)
0.039 (0.007)
0.039 (0.009)
0.038 (0.006)
0.036 (0.004)
0.035 (0.005)
0.034 (0.010)
0.031 (0.010)
0.031 (0.011)
0.030 (0.012)
0.027 (0.004)
0.010 (0.023)
—
JHS; stroke, n = 3639, p = 80

aorsf-cph
aorsf-net
aorsf-fast
obliqueRSF-net
glmnet-cox
cif-standard
rsf-standard
cif-extension
ranger-extratrees
cif-rotate
aorsf-random
nn-cox
xgboost-cox
xgboost-aft

0.036 (0.006)
0.035 (0.008)
0.035 (0.007)
0.030 (0.006)
0.028 (0.008)
0.028 (0.005)
0.027 (0.010)
0.025 (0.003)
0.023 (0.005)
0.023 (0.009)
0.022 (0.004)
0.016 (0.027)
0.001 (0.030)
—

Lung cancer; death, n = 442, p = 24
0.063 (0.032)
0.061 (0.030)
0.059 (0.033)
0.058 (0.020)
0.050 (0.018)
0.050 (0.035)
0.050 (0.023)
0.049 (0.016)
0.047 (0.026)
0.041 (0.024)
0.040 (0.022)
0.033 (0.025)

aorsf-cph
aorsf-net
aorsf-fast
obliqueRSF-net
cif-extension
rsf-standard
cif-standard
ranger-extratrees
cif-rotate
glmnet-cox
aorsf-random
nn-cox

0.778 (0.015)
0.780 (0.015)
0.777 (0.015)
0.777 (0.016)
0.779 (0.017)
0.781 (0.019)
0.777 (0.017)
0.769 (0.018)
0.774 (0.020)
0.752 (0.016)
0.759 (0.021)
0.763 (0.019)
0.785 (0.022)
0.782 (0.017)

0.806 (0.016)
0.807 (0.016)
0.807 (0.018)
0.807 (0.016)
0.798 (0.017)
0.803 (0.016)
0.782 (0.018)
0.797 (0.018)
0.791 (0.016)
0.785 (0.017)
0.775 (0.018)
0.772 (0.021)
0.776 (0.021)
0.784 (0.018)

0.691 (0.019)
0.685 (0.019)
0.690 (0.019)
0.678 (0.020)
0.667 (0.019)
0.673 (0.023)
0.667 (0.022)
0.675 (0.019)
0.664 (0.021)
0.664 (0.034)
0.651 (0.023)
0.647 (0.029)

26

6.783
185.659
2.260
78.653
10.065
54.976
3.892
187.949
1.723
2.099
10.787
3.232
3.676
13.342

6.729
72.257
2.321
161.865
2.325
10.613
1.210
55.652
2.997
188.792
3.166
10.445
2.953
13.017

0.316
31.742
0.125
294.626
9.104
0.941
0.315
0.037
17.129
0.123
0.538
12.472

0.003
0.006

0.588
130.539
0.566
0.606
30.887
20.544
1.677
22.910
0.004
0.226
5.787
0.624
0.005
0.006

0.588
0.610
0.571
165.270
0.004
32.291
0.190
21.758
2.557
24.524
0.630
6.338
0.005
0.006

0.030
0.031
0.030
2.961
3.317
0.073
0.846
0.065
3.089
0.002
0.026
0.368

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

xgboost-cox
xgboost-aft

0.018 (0.019)
—

0.647 (0.027)
0.652 (0.026)

1.541
8.410

MESA; coronary heart disease, n = 6785, p = 48

aorsf-fast
aorsf-net
obliqueRSF-net
aorsf-cph
cif-standard
cif-rotate
rsf-standard
ranger-extratrees
cif-extension
glmnet-cox
nn-cox
aorsf-random
xgboost-cox
xgboost-aft

0.063 (0.010)
0.062 (0.010)
0.062 (0.008)
0.060 (0.010)
0.059 (0.007)
0.058 (0.009)
0.057 (0.012)
0.047 (0.004)
0.047 (0.003)
0.038 (0.017)
0.038 (0.017)
0.031 (0.005)
0.015 (0.028)
—

MESA; death, n = 6793, p = 48

aorsf-net
aorsf-fast
aorsf-cph
rsf-standard
obliqueRSF-net
cif-standard
glmnet-cox
nn-cox
cif-rotate
ranger-extratrees
cif-extension
aorsf-random
xgboost-cox
xgboost-aft

0.144 (0.008)
0.144 (0.009)
0.143 (0.008)
0.140 (0.008)
0.139 (0.007)
0.134 (0.007)
0.131 (0.026)
0.127 (0.020)
0.126 (0.007)
0.113 (0.004)
0.092 (0.003)
0.068 (0.005)
0.056 (0.029)
—

MESA; heart failure, n = 6785, p = 48

aorsf-fast
aorsf-net
aorsf-cph
rsf-standard
obliqueRSF-net
cif-rotate
cif-standard
cif-extension
ranger-extratrees
nn-cox
aorsf-random
glmnet-cox

0.115 (0.010)
0.114 (0.011)
0.109 (0.011)
0.108 (0.012)
0.108 (0.008)
0.105 (0.010)
0.102 (0.009)
0.077 (0.005)
0.075 (0.005)
0.071 (0.024)
0.064 (0.006)
0.043 (0.044)

0.807 (0.011)
0.805 (0.012)
0.808 (0.012)
0.801 (0.012)
0.803 (0.013)
0.802 (0.013)
0.795 (0.013)
0.794 (0.011)
0.805 (0.013)
0.775 (0.016)
0.767 (0.021)
0.735 (0.015)
0.802 (0.013)
0.802 (0.012)

0.792 (0.009)
0.792 (0.009)
0.791 (0.009)
0.784 (0.009)
0.791 (0.009)
0.788 (0.009)
0.789 (0.012)
0.784 (0.016)
0.783 (0.010)
0.784 (0.008)
0.781 (0.009)
0.725 (0.008)
0.794 (0.009)
0.793 (0.009)

0.866 (0.013)
0.863 (0.013)
0.858 (0.014)
0.856 (0.012)
0.869 (0.011)
0.869 (0.013)
0.864 (0.013)
0.864 (0.011)
0.849 (0.015)
0.826 (0.016)
0.795 (0.014)
0.767 (0.139)

27

1.219
176.990
488.662
5.393
24.446
284.668
3.426
7.360
98.278
4.907
18.380
2.927
4.763
18.127

318.785
1.694
6.893
4.818
1176.365
23.671
1.560
29.272
319.953
9.060
111.068
5.608
8.021
20.287

1.094
149.605
4.842
3.125
393.285
260.914
24.344
94.628
7.492
15.797
2.520
3.777

0.002
0.006

0.352
0.387
265.171
0.382
98.767
37.340
1.202
6.260
28.773
0.007
16.712
0.397
0.009
0.009

0.546
0.506
0.523
0.502
156.871
101.207
0.007
17.344
37.290
6.474
32.105
0.565
0.009
0.010

0.311
0.339
0.326
1.151
338.322
38.177
101.534
30.361
6.923
17.312
0.369
0.006

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

xgboost-cox
xgboost-aft

-0.008 (0.019)
—

0.869 (0.011)
0.870 (0.012)

6.764
18.620

MESA; stroke, n = 6783, p = 48

obliqueRSF-net
cif-rotate
cif-standard
aorsf-fast
aorsf-net
aorsf-cph
ranger-extratrees
glmnet-cox
cif-extension
rsf-standard
nn-cox
aorsf-random
xgboost-cox
xgboost-aft

0.025 (0.004)
0.025 (0.004)
0.025 (0.004)
0.025 (0.006)
0.024 (0.006)
0.023 (0.005)
0.022 (0.003)
0.021 (0.009)
0.021 (0.002)
0.019 (0.009)
0.018 (0.007)
0.013 (0.003)
0.000 (0.025)
—

0.767 (0.016)
0.764 (0.017)
0.762 (0.017)
0.764 (0.016)
0.759 (0.017)
0.758 (0.016)
0.759 (0.016)
0.765 (0.017)
0.768 (0.017)
0.745 (0.018)
0.746 (0.028)
0.714 (0.022)
0.762 (0.018)
0.764 (0.015)

Monoclonal gammopathy; death, n = 1384, p = 8

0.744 (0.014)
0.743 (0.011)
0.743 (0.011)
0.741 (0.011)
0.743 (0.011)
0.738 (0.012)
0.737 (0.011)
0.735 (0.011)
0.747 (0.013)
0.726 (0.014)
0.733 (0.012)
0.744 (0.012)
0.599 (0.112)
0.733 (0.013)

cif-rotate
aorsf-cph
aorsf-fast
aorsf-net
obliqueRSF-net
cif-standard
rsf-standard
aorsf-random
cif-extension
glmnet-cox
xgboost-cox
ranger-extratrees
nn-cox
xgboost-aft

0.159 (0.019)
0.158 (0.016)
0.157 (0.016)
0.155 (0.016)
0.155 (0.013)
0.151 (0.015)
0.151 (0.017)
0.146 (0.013)
0.143 (0.009)
0.137 (0.021)
0.122 (0.012)
0.115 (0.005)
0.034 (0.057)
—
Monoclonal gammopathy; malignancy, n = 1384, p = 8
0.015 (0.011)
0.011 (0.013)
0.010 (0.014)
0.008 (0.006)
0.008 (0.010)
0.007 (0.010)
0.007 (0.014)
0.007 (0.013)
0.007 (0.017)
0.006 (0.011)
-0.003 (0.005)
-0.009 (0.018)

glmnet-cox
aorsf-cph
aorsf-fast
ranger-extratrees
cif-extension
obliqueRSF-net
aorsf-net
aorsf-random
xgboost-cox
cif-standard
nn-cox
rsf-standard

0.651 (0.055)
0.644 (0.036)
0.641 (0.036)
0.642 (0.030)
0.625 (0.028)
0.628 (0.033)
0.641 (0.034)
0.633 (0.033)
0.639 (0.039)
0.628 (0.033)
0.510 (0.032)
0.616 (0.036)

357.039
268.402
23.450
1.072
139.617
4.266
7.610
3.876
94.913
3.221
16.152
2.420
4.347
16.257

15.123
1.154
0.408
85.428
232.467
1.537
2.281
1.757
11.222
0.136
3.919
0.064
16.529
12.094

0.118
0.574
0.201
0.095
9.141
41.856
22.366
0.517
1.783
1.689
11.229
0.824

28

0.009
0.010

299.786
37.899
98.166
0.307
0.333
0.316
6.738
0.007
29.730
1.242
17.979
0.343
0.008
0.009

4.858
0.084
0.088
0.085
12.924
5.829
0.194
0.084
4.744
0.003
0.003
0.181
0.689
0.006

0.003
0.040
0.041
0.177
4.788
16.910
0.041
0.040
0.003
5.603
0.597
0.073

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

cif-rotate
xgboost-aft

-0.024 (0.023)
—

0.553 (0.035)
0.629 (0.039)

12.975
10.748

Movies released in 2015-2018; gross 1M USD, n = 551, p = 46

cif-rotate
glmnet-cox
nn-cox
aorsf-net
aorsf-cph
rsf-standard
aorsf-fast
xgboost-cox
cif-standard
cif-extension
ranger-extratrees
obliqueRSF-net
aorsf-random
xgboost-aft

0.636 (0.024)
0.618 (0.034)
0.534 (0.072)
0.530 (0.028)
0.522 (0.024)
0.519 (0.022)
0.516 (0.027)
0.512 (0.029)
0.472 (0.029)
0.454 (0.025)
0.430 (0.025)
0.319 (0.022)
0.300 (0.032)
—

0.943 (0.007)
0.940 (0.009)
0.910 (0.027)
0.928 (0.010)
0.925 (0.011)
0.922 (0.010)
0.923 (0.012)
0.932 (0.009)
0.902 (0.018)
0.920 (0.013)
0.900 (0.019)
0.909 (0.017)
0.849 (0.027)
0.927 (0.010)

NCCTG Lung Cancer; death, n = 228, p = 9

19.879
0.204
17.266
50.720
0.788
1.631
0.214
13.972
0.453
8.854
0.049
155.421
0.869
33.545

0.686 (0.026)
0.675 (0.033)
0.672 (0.026)
0.676 (0.029)
0.670 (0.024)
0.670 (0.030)
0.664 (0.029)
0.668 (0.026)
0.638 (0.059)
0.642 (0.025)
0.632 (0.032)
0.648 (0.032)
0.512 (0.082)
0.637 (0.034)

aorsf-random
ranger-extratrees
aorsf-fast
obliqueRSF-net
aorsf-cph
cif-standard
cif-extension
aorsf-net
glmnet-cox
rsf-standard
cif-rotate
xgboost-cox
nn-cox
xgboost-aft

0.076 (0.030)
0.062 (0.028)
0.060 (0.043)
0.058 (0.026)
0.058 (0.041)
0.055 (0.032)
0.051 (0.032)
0.047 (0.040)
0.033 (0.031)
0.023 (0.039)
0.017 (0.041)
0.011 (0.023)
-0.051 (0.163)
—
NKI 70 gene signature; death or metastasis, n = 144, p = 77
0.142 (0.056)
0.124 (0.049)
0.121 (0.052)
0.118 (0.059)
0.106 (0.051)
0.098 (0.055)
0.088 (0.051)
0.087 (0.048)
0.064 (0.044)
0.053 (0.045)
0.051 (0.102)
0.049 (0.064)

aorsf-net
aorsf-cph
aorsf-fast
cif-rotate
obliqueRSF-net
cif-extension
cif-standard
rsf-standard
ranger-extratrees
aorsf-random
nn-cox
glmnet-cox

0.804 (0.056)
0.802 (0.051)
0.802 (0.054)
0.787 (0.049)
0.792 (0.061)
0.799 (0.061)
0.781 (0.065)
0.755 (0.050)
0.774 (0.054)
0.741 (0.060)
0.715 (0.100)
0.726 (0.090)

0.304
0.023
0.067
106.084
0.150
0.130
3.799
16.041
0.081
0.087
4.687
0.721
10.516
6.271

10.798
0.078
0.052
27.382
79.059
8.595
0.145
0.067
0.024
0.183
11.692
0.265

29

4.603
0.006

3.571
0.002
0.663
0.043
0.041
0.106
0.041
0.004
1.910
3.924
0.103
8.847
0.039
0.008

0.015
0.031
0.016
1.468
0.016
0.252
1.502
0.016
0.002
0.037
1.897
0.002
0.209
0.005

0.014
0.013
0.014
3.379
0.558
3.554
0.149
0.025
0.030
0.015
0.121
0.002

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

xgboost-cox
xgboost-aft

0.566 (0.093)
0.770 (0.056)

-0.028 (0.029)
—
Non-alcohol fatty liver disease; death, n = 17549, p = 24
0.213 (0.008)
0.212 (0.009)
0.210 (0.008)
0.209 (0.008)
0.207 (0.009)
0.207 (0.011)
0.205 (0.007)
0.190 (0.008)
0.181 (0.007)
0.166 (0.003)
0.140 (0.006)
0.020 (0.015)
-0.002 (0.009)
—

aorsf-cph
aorsf-fast
aorsf-net
obliqueRSF-net
rsf-standard
glmnet-cox
cif-standard
cif-rotate
ranger-extratrees
cif-extension
aorsf-random
xgboost-cox
nn-cox
xgboost-aft

0.868 (0.005)
0.869 (0.005)
0.864 (0.006)
0.868 (0.006)
0.860 (0.005)
0.860 (0.005)
0.863 (0.006)
0.865 (0.005)
0.860 (0.005)
0.866 (0.006)
0.838 (0.007)
0.876 (0.005)
0.565 (0.092)
0.875 (0.005)

Primary biliary cholangitis; death, n = 276, p = 19

aorsf-fast
aorsf-cph
aorsf-net
cif-rotate
rsf-standard
obliqueRSF-net
aorsf-random
cif-standard
cif-extension
glmnet-cox
ranger-extratrees
xgboost-cox
nn-cox
xgboost-aft

0.430 (0.032)
0.418 (0.034)
0.413 (0.035)
0.405 (0.040)
0.392 (0.034)
0.369 (0.032)
0.354 (0.031)
0.352 (0.034)
0.348 (0.033)
0.342 (0.044)
0.277 (0.027)
0.256 (0.103)
-0.017 (0.018)
—

0.908 (0.021)
0.906 (0.021)
0.905 (0.021)
0.899 (0.022)
0.895 (0.023)
0.907 (0.022)
0.893 (0.020)
0.904 (0.025)
0.901 (0.023)
0.886 (0.028)
0.894 (0.027)
0.881 (0.027)
0.563 (0.124)
0.883 (0.024)

Rotterdam tumor bank; death, n = 2982, p = 11

aorsf-net
obliqueRSF-net
aorsf-cph
aorsf-fast
cif-standard
rsf-standard
aorsf-random
cif-rotate
ranger-extratrees
xgboost-cox
cif-extension
glmnet-cox

0.166 (0.012)
0.163 (0.010)
0.163 (0.012)
0.161 (0.012)
0.159 (0.010)
0.159 (0.014)
0.153 (0.010)
0.147 (0.011)
0.139 (0.006)
0.130 (0.014)
0.129 (0.004)
0.118 (0.008)

0.762 (0.009)
0.761 (0.009)
0.759 (0.009)
0.757 (0.009)
0.759 (0.009)
0.756 (0.009)
0.752 (0.010)
0.751 (0.011)
0.749 (0.009)
0.753 (0.010)
0.751 (0.008)
0.731 (0.009)

30

0.118
4.896

17.724
4.868
471.404
1428.698
10.516
1.345
67.597
263.660
39.632
125.288
8.915
8.907
20.937
27.908

0.082
0.162
14.047
10.102
0.113
111.656
0.308
0.206
5.775
0.116
0.029
4.960
11.751
9.644

147.998
439.210
2.520
0.845
4.629
3.066
2.840
34.328
3.498
4.068
22.740
0.278

0.002
0.005

1.232
1.247
1.283
1042.701
1.205
0.012
624.624
62.919
80.768
53.237
1.339
0.017
106.131
0.015

0.019
0.018
0.019
1.933
0.038
1.787
0.020
0.363
2.199
0.002
0.038
0.003
0.247
0.006

0.185
37.683
0.201
0.198
22.523
0.967
0.180
8.629
2.152
0.004
8.982
0.004

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

nn-cox
xgboost-aft

-0.009 (0.042)
—

0.531 (0.050)
0.761 (0.009)
Rotterdam tumor bank; recurrence, n = 2982, p = 11
0.737 (0.009)
0.735 (0.009)
0.734 (0.008)
0.734 (0.009)
0.733 (0.009)
0.730 (0.008)
0.731 (0.008)
0.734 (0.009)
0.725 (0.009)
0.731 (0.008)
0.727 (0.008)
0.729 (0.009)
0.511 (0.045)
0.735 (0.009)

obliqueRSF-net
aorsf-net
aorsf-cph
cif-standard
aorsf-fast
aorsf-random
rsf-standard
ranger-extratrees
cif-rotate
cif-extension
glmnet-cox
xgboost-cox
nn-cox
xgboost-aft

0.148 (0.010)
0.146 (0.011)
0.145 (0.012)
0.144 (0.011)
0.143 (0.011)
0.141 (0.010)
0.139 (0.012)
0.135 (0.007)
0.129 (0.010)
0.119 (0.006)
0.117 (0.008)
0.113 (0.008)
-0.007 (0.027)
—

Serum free light chain; death, n = 7874, p = 10

aorsf-fast
aorsf-cph
aorsf-net
glmnet-cox
obliqueRSF-net
ranger-extratrees
cif-standard
rsf-standard
aorsf-random
cif-rotate
cif-extension
xgboost-cox
nn-cox
xgboost-aft

0.250 (0.014)
0.250 (0.013)
0.250 (0.012)
0.248 (0.012)
0.247 (0.011)
0.243 (0.009)
0.243 (0.011)
0.243 (0.013)
0.231 (0.012)
0.228 (0.009)
0.201 (0.005)
0.094 (0.038)
0.002 (0.005)
—

0.825 (0.007)
0.825 (0.008)
0.823 (0.008)
0.820 (0.007)
0.821 (0.008)
0.820 (0.007)
0.818 (0.008)
0.815 (0.008)
0.816 (0.008)
0.819 (0.007)
0.820 (0.008)
0.824 (0.007)
0.616 (0.122)
0.823 (0.008)

SPRINT; CVD death, n = 9361, p = 174

glmnet-cox
aorsf-net
aorsf-fast
aorsf-cph
obliqueRSF-net
rsf-standard
cif-standard
cif-rotate
ranger-extratrees
nn-cox
cif-extension
aorsf-random

0.071 (0.011)
0.070 (0.007)
0.069 (0.006)
0.069 (0.006)
0.068 (0.005)
0.065 (0.007)
0.061 (0.003)
0.060 (0.005)
0.054 (0.003)
0.039 (0.018)
0.034 (0.002)
0.026 (0.002)

0.795 (0.011)
0.796 (0.011)
0.797 (0.011)
0.797 (0.011)
0.798 (0.012)
0.788 (0.014)
0.798 (0.011)
0.791 (0.012)
0.791 (0.012)
0.764 (0.027)
0.789 (0.011)
0.747 (0.016)

31

16.635
14.813

520.813
160.272
2.678
4.807
0.854
3.192
3.003
3.564
36.519
23.055
0.258
3.628
17.722
14.317

2.023
6.401
278.411
0.539
1113.284
12.743
19.565
5.399
6.681
65.379
41.381
5.927
26.319
18.504

13.850
337.860
2.581
9.028
1017.350
3.894
50.694
930.893
7.314
20.414
122.779
5.887

8.901
0.006

39.774
0.191
0.205
23.027
0.206
0.185
1.000
2.555
8.483
8.825
0.004
0.004
7.825
0.006

0.587
0.580
0.563
0.006
151.041
12.085
120.023
0.585
0.568
21.402
20.976
0.008
26.895
0.009

0.011
0.660
0.638
0.596
425.134
1.314
181.616
113.261
7.943
24.555
33.342
0.742

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

xgboost-cox
xgboost-aft

0.006 (0.017)
—

0.799 (0.011)
0.796 (0.012)

6.888
20.126

SPRINT; death, n = 9361, p = 174
0.123 (0.012)
0.117 (0.008)
0.116 (0.008)
0.113 (0.009)
0.112 (0.007)
0.110 (0.008)
0.106 (0.006)
0.097 (0.010)
0.096 (0.005)
0.090 (0.007)
0.055 (0.002)
0.052 (0.003)
0.030 (0.023)
—

glmnet-cox
aorsf-cph
aorsf-fast
aorsf-net
obliqueRSF-net
rsf-standard
cif-standard
nn-cox
ranger-extratrees
cif-rotate
cif-extension
aorsf-random
xgboost-cox
xgboost-aft

0.771 (0.009)
0.770 (0.008)
0.770 (0.008)
0.769 (0.009)
0.767 (0.008)
0.763 (0.009)
0.764 (0.008)
0.757 (0.009)
0.756 (0.009)
0.745 (0.009)
0.747 (0.009)
0.720 (0.010)
0.772 (0.008)
0.772 (0.007)

Systolic Heart Failure; death, n = 2231, p = 41

obliqueRSF-net
glmnet-cox
cif-rotate
aorsf-net
aorsf-cph
aorsf-fast
cif-standard
rsf-standard
cif-extension
ranger-extratrees
xgboost-cox
aorsf-random
nn-cox
xgboost-aft

0.114 (0.012)
0.113 (0.013)
0.113 (0.013)
0.112 (0.013)
0.112 (0.013)
0.110 (0.015)
0.110 (0.011)
0.105 (0.011)
0.094 (0.006)
0.091 (0.008)
0.090 (0.009)
0.080 (0.006)
0.074 (0.028)
—

0.747 (0.012)
0.745 (0.012)
0.741 (0.011)
0.743 (0.012)
0.744 (0.012)
0.743 (0.011)
0.744 (0.011)
0.735 (0.011)
0.744 (0.012)
0.738 (0.012)
0.744 (0.010)
0.731 (0.013)
0.705 (0.036)
0.741 (0.009)

VA lung cancer trial; death, n = 137, p = 8

aorsf-net
aorsf-fast
cif-rotate
aorsf-cph
rsf-standard
cif-extension
glmnet-cox
aorsf-random
cif-standard
obliqueRSF-net
ranger-extratrees
xgboost-cox

0.201 (0.050)
0.200 (0.050)
0.198 (0.065)
0.198 (0.052)
0.176 (0.048)
0.174 (0.048)
0.160 (0.036)
0.154 (0.044)
0.128 (0.040)
0.126 (0.034)
0.092 (0.033)
0.067 (0.078)

0.797 (0.035)
0.795 (0.034)
0.789 (0.036)
0.794 (0.035)
0.787 (0.037)
0.795 (0.034)
0.788 (0.037)
0.780 (0.037)
0.770 (0.037)
0.796 (0.029)
0.778 (0.038)
0.750 (0.046)

32

5.422
12.876
3.583
590.419
2630.588
6.407
49.842
34.063
11.323
1109.925
137.470
9.559
9.057
23.335

381.891
0.276
71.714
118.505
1.895
0.586
4.079
2.510
29.918
3.266
4.229
2.448
18.945
13.087

9.602
0.082
4.476
0.105
0.078
3.676
0.087
0.213
0.105
62.935
0.020
1.408

0.013
0.012

0.010
1.527
1.514
0.934
231.667
0.663
190.804
33.278
9.400
112.893
34.230
1.034
0.014
0.013

25.692
0.004
10.523
0.158
0.147
0.146
16.213
0.252
10.109
1.328
0.004
0.151
5.181
0.006

0.011
0.014
1.284
0.011
0.025
1.195
0.002
0.012
0.120
0.664
0.026
0.002

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

A.2: Index of prediction accuracy, time-dependent concordance statistic, and computational time required to
ﬁt and compute predictions for several learning algorithms across 35 risk prediction tasks. (continued)

Scaled Brier

C-Statistic

Model ﬁtting Risk prediction

xgboost-aft
nn-cox

—
-0.023 (0.033)

0.754 (0.047)
0.517 (0.114)

5.530
11.344

0.005
0.133

33

3
4

A.3: Discrimination of relevant versus irrelevant variables for several techniques to estimate variable importance.

Max correlation No. observations Negation ANOVA Permutation

SHAP Gain

Permutation

accelerated oblique RSF

xgboost

RSF

Overall
Interactions
Overall
30
30
30
15
15
15
0
0
0

Non-linear effects

Overall
30
30
30
15
15
15
0
0
0

Overall

Overall
500
1,000
2,500
500
1,000
2,500
500
1,000
2,500

Overall
500
1,000
2,500
500
1,000
2,500
500
1,000
2,500

Combination effects

Overall
30
30
30
15
15
15
0
0

Overall
500
1,000
2,500
500
1,000
2,500
500
1,000

75.9

57.8
54.3
56.9
61.9
53.1
55.9
61.0
52.5
57.2
67.6

71.7
58.8
61.1
62.1
63.8
67.5
70.2
75.5
88.3
98.4

78.3
64.8
67.4
69.9
70.2
74.8
78.6
84.0
95.4

73.9

57.4
54.1
55.7
58.9
53.5
55.4
58.6
53.9
58.6
68.2

69.3
58.3
59.4
60.2
61.5
65.1
67.2
72.3
83.9
96.3

75.8
63.5
65.3
67.0
68.0
71.2
74.6
81.1
92.4

73.2

58.0
54.8
58.1
64.1
52.8
56.3
63.0
52.4
55.8
64.4

67.9
57.8
59.0
61.1
60.7
64.6
69.1
68.5
78.0
91.8

74.8
62.5
65.3
68.5
66.3
71.4
77.1
76.2
87.8

69.6

64.6

54.6
48.2
53.1
61.5
47.1
52.2
61.0
44.5
53.1
71.0

66.1
53.4
57.1
60.0
55.3
62.5
66.8
60.1
81.5
97.7

70.7
55.6
61.0
65.2
59.2
66.6
72.6
66.7
89.4

49.2
42.7
48.0
60.7
41.1
45.8
58.9
40.7
42.8
62.2

60.1
48.5
52.0
56.4
49.4
56.0
62.3
55.8
68.6
91.6

65.2
49.8
55.3
61.9
52.8
59.9
68.6
61.7
78.7

67.7

56.9
54.9
56.3
60.0
54.1
55.4
59.9
53.6
56.1
62.1

61.8
55.5
56.3
57.9
57.7
59.8
62.3
61.1
67.6
78.3

68.2
59.2
61.5
63.8
61.8
65.0
69.1
67.6
76.3

a
r
X
i
v
A
c
c
e
l
e
r
a
t
e
d
&

i
n
t
e
r
p
r
e
t
a
b
l
e

o
b
l
i
q
u
e
R
S
F
s

A
P
R
E
P
R

I

N
T

A.3: Discrimination of relevant versus irrelevant variables for several techniques to estimate variable importance. (continued)

Max correlation No. observations Negation ANOVA Permutation

SHAP Gain

Permutation

0

Main effects
Overall
30
30
30
15
15
15
0
0
0

2,500

Overall
500
1,000
2,500
500
1,000
2,500
500
1,000
2,500

99.8

99.3

97.8

99.7

97.9

91.0
79.3
83.5
86.5
86.3
91.3
94.5
97.8
100.0
100.0

88.9
77.3
80.5
83.5
83.3
88.1
91.6
96.3
99.7
100.0

88.7
75.5
80.8
85.1
81.8
88.5
93.7
94.0
99.4
100.0

85.0
70.3
76.8
81.7
75.7
84.6
90.2
86.5
99.4
100.0

82.6
66.5
73.9
80.4
71.3
81.3
89.0
83.4
98.0
100.0

89.0

83.2
71.2
74.9
79.3
75.3
81.1
86.5
85.9
95.2
99.8

3
5

a
r
X
i
v
A
c
c
e
l
e
r
a
t
e
d
&

i
n
t
e
r
p
r
e
t
a
b
l
e

o
b
l
i
q
u
e
R
S
F
s

A
P
R
E
P
R

I

N
T

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

References

Karel GM Moons, Andre Pascal Kengne, Diederick E Grobbee, Patrick Royston, Yvonne Vergouwe, Dou-
glas G Altman, and Mark Woodward. Risk prediction models: II. external validation, model updating, and
impact assessment. Heart, 98(9):691–698, 2012a.

Karel GM Moons, Andre Pascal Kengne, Mark Woodward, Patrick Royston, Yvonne Vergouwe, Douglas G
Altman, and Diederick E Grobbee. Risk prediction models: I. development, internal validation, and
assessing the incremental value of a new (bio) marker. Heart, 98(9):683–690, 2012b.

Hemant Ishwaran, Udaya B Kogalur, Eugene H Blackstone, and Michael S Lauer. Random survival forests.

The Annals of Applied Statistics, pages 841–860, 2008.

Torsten Hothorn, Kurt Hornik, and Achim Zeileis. Unbiased recursive partitioning: A conditional inference

framework. Journal of Computational and Graphical statistics, 15(3):651–674, 2006.

Hong Wang and Gang Li. A selective review on random survival forests for high dimensional data. Quantita-

tive bio-science, 36(2):85, 2017.

Leo Breiman. Random forests. Machine Learning, 45(1):5–32, 2001.

Hemant Ishwaran and Udaya B Kogalur. Consistency of random survival forests. Statistics & probability

letters, 80(13-14):1056–1064, 2010.

Yifan Cui, Ruoqing Zhu, Mai Zhou, and Michael Kosorok. Consistency of survival tree and forest models:

splitting bias and correction. arXiv preprint arXiv:1707.09631, 2017.

Leo Breiman, Jerome H Friedman, Richard A Olshen, and Charles J Stone. Classiﬁcation and regression

trees. Routledge, 2017.

Bjoern H Menze, B Michael Kelm, Daniel N Splitthoff, Ullrich Koethe, and Fred A Hamprecht. On
oblique random forests. In Joint European Conference on Machine Learning and Knowledge Discovery in
Databases, pages 453–469. Springer, 2011.

Byron C Jaeger, D Leann Long, Dustin M Long, Mario Sims, Jeff M Szychowski, Yuan-I Min, Leslie A
Mcclure, George Howard, and Noah Simon. Oblique random survival forests. The Annals of Applied
Statistics, 13(3):1847–1883, 2019.

David Heath, Simon Kasif, and Steven Salzberg. Induction of oblique decision trees. In IJCAI, volume 1993,

pages 1002–1007. Citeseer, 1993.

Sreerama K Murthy, Simon Kasif, and Steven Salzberg. A system for induction of oblique decision trees.

Journal of Artiﬁcial Intelligence Research, 2:1–32, 1994.

Hemant Ishwaran and Min Lu. Standard errors and conﬁdence intervals for variable importance in random

forest regression, classiﬁcation, and survival. Statistics in medicine, 38(4):558–582, 2019.

Le Zhang and Ponnuthurai N Suganthan. Oblique decision tree ensemble via multisurface proximal support

vector machine. IEEE transactions on cybernetics, 45(10):2165–2176, 2014.

Tom Rainforth and Frank Wood. Canonical correlation forests. arXiv preprint arXiv:1507.05444, 2015.

Ruoqing Zhu, Donglin Zeng, and Michael R Kosorok. Reinforcement learning trees. Journal of the American

Statistical Association, 110(512):1770–1784, 2015.

Nitesh Poona, Adriaan Van Niekerk, and Riyad Ismail.

Investigating the utility of oblique tree-based

ensembles for the classiﬁcation of hyperspectral data. Sensors, 16(11):1918, 2016.

Xueheng Qiu, Le Zhang, Ponnuthurai Nagaratnam Suganthan, and Gehan AJ Amaratunga. Oblique random
forest ensemble via least square estimation for time series forecasting. Information Sciences, 420:249–262,
2017.

36

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Tyler M Tomita, James Browne, Cencheng Shen, Jaewon Chung, Jesse L Patsolic, Benjamin Falk, Carey E
Priebe, Jason Yim, Randal Burns, Mauro Maggioni, et al. Sparse projection oblique randomer forests.
Journal of machine learning research, 21(104), 2020.

Rakesh Katuwal, Ponnuthurai Nagaratnam Suganthan, and Le Zhang. Heterogeneous oblique random forest.

Pattern Recognition, 99:107078, 2020.

Ruoqing Zhu. Tree-based Methods for Survival Analysis and High-dimensional Data. PhD thesis, The

University of North Carolina at Chapel Hill, 2013.

Torsten Hothorn, Berthold Lausen, Axel Benner, and Martin Radespiel-Tröger. Bagging survival trees.

Statistics in medicine, 23(1):77–91, 2004.

Lifeng Zhou, Hong Wang, and Qingsong Xu. Random rotation survival forest for high dimensional censored

data. SpringerPlus, 5(1):1–10, 2016.

Hong Wang and Lifeng Zhou. Random survival forest with space extensions for censored data. Artiﬁcial

intelligence in medicine, 79:52–61, 2017.

H. Ishwaran and U.B. Kogalur. Random Forests for Survival, Regression, and Classiﬁcation (RF-SRC),
2019. URL https://cran.r-project.org/package=randomForestSRC. R package version 2.8.0,
available at https://cran.r-project.org/package=randomForestSRC.

Marvin N. Wright and Andreas Ziegler. ranger: A fast implementation of random forests for high dimensional
data in c++ and r. Journal of Statistical Software, 77(1):1–17, 2017. doi:10.18637/jss.v077.i01. URL
https://www.jstatsoft.org/index.php/jss/article/view/v077i01.

Torsten Hothorn, Kurt Hornik, Carolin Strobl, and Achim Zeileis. Party: a laboratory for recursive partytion-

ing, 2010.

Carolin Strobl, Anne-Laure Boulesteix, Achim Zeileis, and Torsten Hothorn. Bias in random forest variable

importance measures: Illustrations, sources and a solution. BMC bioinformatics, 8(1):25, 2007.

Scott Lundberg and Su-In Lee. A uniﬁed approach to interpreting model predictions, 2017.
Terry M Therneau. A Package for Survival Analysis in R, 2022a. URL https://CRAN.R-project.org/

package=survival. R package version 3.3-1.

Terry Therneau. Survival package source code documentation, April 2022b. URL https://github.com/
therneau/survival/blob/5440691d44abea537b08aeb60153a31654d66a9b/noweb. original-date:
2016-04-28.

Frank E. Harrell, Robert M. Califf, David B. Pryor, Kerry L. Lee, and Robert A. Rosati.
ISSN 0098-
doi:10.1001/jama.1982.03320430047030. URL https://doi.org/10.1001/jama.1982.

JAMA, 247(18):2543–2546, 05 1982.

Evaluating the Yield of Medical Tests.
7484.
03320430047030.

William Michael Landau. The targets r package: a dynamic make-like function-oriented pipeline toolkit for
reproducibility and high-performance computing. Journal of Open Source Software, 6(57):2959, 2021.
URL https://doi.org/10.21105/joss.02959.

Erika Graf, Claudia Schmoor, Willi Sauerbrei, and Martin Schumacher. Assessment and comparison
of prognostic classiﬁcation schemes for survival data. Statistics in Medicine, 18(17-18):2529–2545,
1999. URL https://doi.org/10.1002/(SICI)1097-0258(19990915/30)18:17/18%3C2529::
AID-SIM274%3E3.0.CO;2-5.

Michael W Kattan and Thomas A Gerds. The index of prediction accuracy: an intuitive measure useful for

evaluating risk prediction models. Diagnostic and prognostic research, 2(1):1–7, 2018.

Paul Blanche, Jean-François Dartigues, and Hélène Jacqmin-Gadda. Estimating and comparing time-
dependent areas under receiver operating characteristic curves for censored event times with competing
risks. Statistics in medicine, 32(30):5381–5397, 2013.

37

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

ARIC Investigators. The atherosclerosis risk in communit (aric) study: design and objectives. American

journal of epidemiology, 129(4):687–702, 1989.

Diane E Bild, David A Bluemke, Gregory L Burke, Robert Detrano, Ana V Diez Roux, Aaron R Folsom, Philip
Greenland, David R JacobsJr, Richard Kronmal, Kiang Liu, et al. Multi-ethnic study of atherosclerosis:
objectives and design. American journal of epidemiology, 156(9):871–881, 2002.

G Michael Felker, Kevin J Anstrom, Kirkwood F Adams, Justin A Ezekowitz, Mona Fiuzat, Nancy Houston-
Miller, James L Januzzi, Daniel B Mark, Ileana L Piña, Gayle Passmore, et al. Effect of natriuretic
peptide–guided therapy on hospitalization or cardiovascular mortality in high-risk patients with heart
failure and reduced ejection fraction: a randomized clinical trial. Jama, 318(8):713–720, 2017.

SPRINT Research Group. A randomized trial of intensive versus standard blood-pressure control. New

England Journal of Medicine, 373(22):2103–2116, 2015.

Herman A Taylor Jr, James G Wilson, Daniel W Jones, Daniel F Sarpong, Asoka Srinivasan, Robert J
Garrison, Cheryl Nelson, and Sharon B Wyatt. Toward resolution of cardiovascular health disparities in
african americans: Design and methods of the jackson heart study. Ethn Dis, 15(4 Suppl 6):S6–4, 2005.
Alessio Benavoli, Giorgio Corani, Janez Demšar, and Marco Zaffalon. Time for a change: a tutorial for
comparing multiple classiﬁers through bayesian analysis. The Journal of Machine Learning Research, 18
(1):2653–2688, 2017.

Max Kuhn and Hadley Wickham. Tidymodels: a collection of packages for modeling and machine learning

using tidyverse principles., 2020. URL https://www.tidymodels.org.

Ben Goodrich, Jonah Gabry, Imad Ali, and Sam Brilleman. rstanarm: Bayesian applied regression modeling

via Stan., 2022. URL https://mc-stan.org/rstanarm/. R package version 2.21.3.

Tianqi Chen, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, Rory
Mitchell, Ignacio Cano, Tianyi Zhou, Mu Li, Junyuan Xie, Min Lin, Yifeng Geng, Yutian Li, and Jiaming
Yuan. xgboost: Extreme Gradient Boosting, 2022. URL https://CRAN.R-project.org/package=
xgboost. R package version 1.5.2.1.

Scott M Lundberg, Gabriel G Erion, and Su-In Lee. Consistent individualized feature attribution for tree

ensembles. arXiv preprint arXiv:1802.03888, 2018.

Glenn Heller. A measure of explained risk in the proportional hazards model. Biostatistics, 13(2):315–325,

2012.

Laura Moss, David Corsar, Martin Shaw, Ian Piper, and Christopher Hawthorne. Demystifying the black box:
The importance of interpretability of predictive models in neurocritical care. Neurocritical care, pages 1–7,
2022.

Huimin Li, Dong Han, Yawen Hou, Huilin Chen, and Zheng Chen. Statistical inference methods for two

crossing survival curves: a comparison of methods. PLoS One, 10(1):e0116774, 2015.

Hajime Uno, Tianxi Cai, Michael J Pencina, Ralph B D’Agostino, and Lee-Jen Wei. On the c-statistics
for evaluating overall adequacy of risk prediction procedures with censored survival data. Statistics in
medicine, 30(10):1105–1117, 2011.

John D Kalbﬂeisch and Ross L Prentice. The statistical analysis of failure time data. John Wiley & Sons,

2011.

Charles G Moertel, Thomas R Fleming, John S Macdonald, Daniel G Haller, John A Laurie, Catherine M
Tangen, James S Ungerleider, William A Emerson, Douglass C Tormey, John H Glick, et al. Fluorouracil
plus levamisole as effective adjuvant therapy after resection of stage iii colon carcinoma: a ﬁnal report.
Annals of internal medicine, 122(5):321–326, 1995.

Terry M Therneau and Patricia M Grambsch. Modeling Survival Data: Extending the Cox Model. Springer,

2000.

38

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Byron C Jaeger. aorsf: Accelerated Oblique Random Survival Forests, 2022. URL https://github.com/

bcjaeger/aorsf. R package version 1.0.0.

Emil Hvitfeldt and Hannah Frick. censored: ’parsnip’ Engines for Survival Models. URL https://github.

com/tidymodels/censored. R package version 0.1.0.9000.

M Schumacher. Rauschecker for the german breast cancer study group, randomized 2 by 2 trial evaluating
hormonal treatment and the duration of chemotherapy in node-positive breast cancer patients. Journal of
Clinical Oncology, 12:2086–2093, 1994.

Torsten Hothorn. TH.data: TH’s Data Archive, 2022. URL https://CRAN.R-project.org/package=

TH.data. R package version 1.1-1.

Eileen Hsich, Eiran Z Gorodeski, Eugene H Blackstone, Hemant Ishwaran, and Michael S Lauer. Identifying
important risk factors for survival in patient with systolic heart failure using random survival forests.
Circulation: Cardiovascular Quality and Outcomes, 4(1):39–45, 2011.

Angela Dispenzieri, Jerry A Katzmann, Robert A Kyle, Dirk R Larson, Terry M Therneau, Colin L Colby,
Raynell J Clark, Graham P Mead, Shaji Kumar, L Joseph Melton III, et al. Use of nonclonal serum
immunoglobulin free light chains to predict overall survival in the general population. In Mayo Clinic
Proceedings, volume 87, pages 517–523. Elsevier, 2012.

Robert A Kyle, Terry M Therneau, S Vincent Rajkumar, Dirk R Larson, Matthew F Plevak, Janice R Offord,
Angela Dispenzieri, Jerry A Katzmann, and L Joseph Melton III. Prevalence of monoclonal gammopathy
of undetermined signiﬁcance. New England Journal of Medicine, 354(13):1362–1369, 2006.

Alina M Allen, Terry M Therneau, Joseph J Larson, Alexandra Coward, Virend K Somers, and Patrick S
Kamath. Nonalcoholic fatty liver disease incidence and impact on metabolic burden and death: a 20
year-community study. Hepatology, 67(5):1726–1736, 2018.

Patrick Royston and Douglas G Altman. External validation of a cox prognostic model: principles and

methods. BMC medical research methodology, 13(1):1–15, 2013.

David W Hosmer and Stanley Lemeshow. Applied survival analysis: regression modelling of time to event

data. Wiley, 2002.

Raphael Sonabend, Franz J Király, Andreas Bender, Bernd Bischl, and Michel Lang. mlr3proba: An
ISSN 1367-4803.

r package for machine learning in survival analysis. Bioinformatics, 02 2021.
doi:10.1093/bioinformatics/btab039.

Christine Desmedt, Angelo Di Leo, Evandro de Azambuja, Denis Larsimont, Benjamin Haibe-Kains, Jean
Selleslags, Suzette Delaloge, Caroline Duhem, Jean-Pierre Kains, Birgit Carly, et al. Multifactorial
approach to predicting resistance to anthracyclines. Journal of Clinical Oncology, 29(12):1578–1586,
2011.

Christos Hatzis, Lajos Pusztai, Vicente Valero, Daniel J Booser, Laura Esserman, Ana Lluch, Tatiana Vidaurre,
Frankie Holmes, Eduardo Souchon, Hongkun Wang, et al. A genomic predictor of response and survival
following taxane-anthracycline chemotherapy for invasive breast cancer. Jama, 305(18):1873–1881, 2011.

Nils Ternès, Federico Rotolo, Georg Heinze, and Stefan Michiels. Identiﬁcation of biomarker-by-treatment
interactions in randomized clinical trials with survival outcomes and high-dimensional spaces. Biometrical
Journal, 59(4):685–701, 2017.

Nils Ternes, Federico Rotolo, and Stefan Michiels. biospear: Biomarker Selection in Penalized Regression
Models, 2018. URL https://CRAN.R-project.org/package=biospear. R package version 1.0.2.

Marc J Van De Vijver, Yudong D He, Laura J Van’t Veer, Hongyue Dai, Augustinus AM Hart, Dorien W
Voskuil, George J Schreiber, Johannes L Peterse, Chris Roberts, Matthew J Marton, et al. A gene-expression
signature as a predictor of survival in breast cancer. New England Journal of Medicine, 347(25):1999–2009,
2002.

39

arXiv Accelerated & interpretable oblique RSFs

A PREPRINT

Giuseppe Casalicchio, Jakob Bossek, Michel Lang, Dominik Kirchhoff, Pascal Kerschke, Benjamin Hofner,
Heidi Seibold, Joaquin Vanschoren, and Bernd Bischl. OpenML: An R package to connect to the machine
learning platform OpenML. Computational Statistics, pages 1–15, 2017. doi:10.1007/s00180-017-0742-2.
URL http://dx.doi.org/10.1007/s00180-017-0742-2.

Director’s Challenge Consortium for the Molecular Classiﬁcation of Lung Adenocarcinoma. Gene expression–
based survival prediction in lung adenocarcinoma: a multi-site, blinded validation study. Nature medicine,
14(8):822–827, 2008.

Charles Lawrence Loprinzi, John A Laurie, H Sam Wieand, James E Krook, Paul J Novotny, John W Kugler,
Joan Bartel, Marlys Law, Marilyn Bateman, and Nancy E Klatt. Prospective evaluation of prognostic
variables from patient-completed questionnaires. north central cancer treatment group. Journal of Clinical
Oncology, 12(3):601–607, 1994.

Melania Pintilie. Competing risks: a practical perspective. John Wiley & Sons, 2006.
Robert A Kyle, Terry M Therneau, S Vincent Rajkumar, Janice R Offord, Dirk R Larson, Matthew F Plevak,
and L Joseph Melton III. A long-term study of prognosis in monoclonal gammopathy of undetermined
signiﬁcance. New England Journal of Medicine, 346(8):564–569, 2002.

40

