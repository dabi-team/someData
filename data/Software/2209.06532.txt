2
2
0
2

p
e
S
4
1

]
E
M

.
t
a
t
s
[

1
v
2
3
5
6
0
.
9
0
2
2
:
v
i
X
r
a

Two-stage Sampling Design and Sample Selection with the R
package R2BEAT

Giulio Barcaroli∗, Andrea Fasulo†, Alessio Guandalini‡, Marco D. Terribili§

Abstract

R2BEAT (”R ’to’ Bethel Extended Allocation for Two-stage sampling”) is an R package for the al-
location of a sample. Besides other software and packages dealing with the allocation problems, its
peculiarity lies in facing properly allocation problems for complex sampling designs with multi-domain
and multi-purpose aims. This is common in many oﬃcial and non-oﬃcial statistical surveys, therefore
R2BEAT could become an essential tool for planning a sample survey. The package implements the
Tschprow (1923) - Neyman (1934) method for the optimal allocation of units in stratiﬁed sampling,
extending it to the multivariate (accordingly to Bethel’s proposal (1989)), multi-domain and to the
complex sampling designs case (Falorsi et al., 1998). The functions implemented in R2BEAT allow the
use of diﬀerent workﬂows, depending on the available information on one or more interest variables.
The package covers all the phases, from the optimization of the sample to the selection of the Primary
and Secondary Stage Units. Furthermore, it provides several outputs for evaluating the allocation
results.

Keywords sample survey, multistage, multipurpose, optimal allocation, sample selection.

1

Introduction

National Statistical Institutes (NSIs) and other oﬃcial statistics institutions usually stratify the target
population into homogeneous groups, deﬁned by variables. Survey data usually beneﬁts from strati-
ﬁcation, and sampling error decreases. However, from a logistic point of view, the stratiﬁed sample
could be geographically widespread, entailing such a cost increase in the data collection process. For
solving this issue and to avoid sample dispersing, the two-stage stratiﬁed sampling design is often
used for planning surveys, mainly the social ones carried out in households. This sampling design
enables to control of the number of Primary Stage Units (PSUs) selected in the survey. For instance,
the municipalities or the enumeration areas in which the selected households (Secondary Stage Units,
SSUs) belong. Controlling the municipalities number remarkable reduces data collection costs, mainly
for face-to-face interviews, and avoids logistic problems given by a geographically scattered sample.
Nevertheless, allocating a two-stage sample among strata can be tricky: usually, households surveys
are deﬁned as multipurpose, since they estimate many target variables; moreover, produced estimates
are provided for many estimation domains, such as national level, geographical areas, municipality
types, etc. In this context, the allocation of the whole sample size becomes a multivariate and multi-
domain problem. It is important to point out that the total size is deﬁned according to three types of
constraints: estimates precision, budget, logistic ones, or more likely by a combination of the three.

Once indicatively deﬁned the whole sample size, intended as the number of SSUs to select and
interview, has to be allocated among the strata in which the PSUs population is partitioned. Diﬀerent
methods can be used for allocating the sampling units among the strata according to the available
information. The easiest methods are uniform and proportional allocation. If, however, the values and

∗Independent consultant. Email: gbarcaroli@gmail.com
†Italian National Institute of Statistics (ISTAT). Email: fasulo@istat.it
‡Italian National Institute of Statistics (ISTAT). Email: alessio.guandalini@istat.it
§Italian National Institute of Statistics (ISTAT). Email: terribili@istat.it

1

 
 
 
 
 
 
the variances of some survey target variables are known in each design stratum, from auxiliary sources
such as registers or previous survey occasions, then an optimal allocation can be computed.

The idea behind the optimal allocation is that strata with larger sizes and larger variability recorded
on the target variables need a larger sample size to provide better estimates. Several publications and
packages focus on this aspect.

R2BEAT extends the methodology implemented in Istat’s open-source software called Mauss-R
(Barcaroli et al., 2020), which stands for “Multivariate Allocation of Units in Sampling Surveys”,
widely used for designing one-stage sample surveys and also in the SamplingStrata (Barcaroli, 2014).
Furthermore, it faces the optimal allocation deﬁnition in the two-stage sampling design case. Its
name stands for R ”to” Bethel Extended Allocation for Two-stage. The package represents a very
speciﬁc tool for designing, allocating and selecting the most complex and challenging sample in the
context of survey designs.

Furthermore, R2BEAT ﬁlls a gap, within the range of statistical software concerning sample size
allocation.
In fact, several R packages are available for allocating a stratiﬁed sample, such as sur-
veyplanning (Breidaks et al., 2020), PracTools (Valliant et al., 2020), optimStrat (Bueno, 2020), and
the already mentioned Mauss-R and SamplingStrata, but none of these can compute the optimal al-
location among strata in such a complex sampling design context, considering both multivariate and
multi-domain case.

In the following paragraph the methodological aspects, underlying the package and its functions,
will be presented in detail: the optimal allocation of the sample and its selection will be illustrated. In
the third paragraph will be shown how to prepare, organize and check the input data needed by the
package for allocating the whole sample size among strata and to ﬁnally select the units. A case study
on a synthetic dataset will be used as an example to test the package functions. Finally, the results
will be discussed in the concluding remarks.

2 Methodological aspects

Sample surveys carried out by National Statistical Institutes and by other institutions have multi-
domains and multi-purpose objectives, so they have to provide accurate estimates for diﬀerent param-
eters and diﬀerent domains (i.e. geographical areas such as national, regional, and more). However,
usually, the survey has budgetary constraints, then, they must be carefully planned to provide high-
quality estimates for parameters of interest.

A seminal work in this perspective is due to Kish (1965). While a broad theoretical framework for
optimizing surveys by maximizing data quality within budgetary constraints is provided by Biemer
and Lyberg (2003) and Biemer (2010).

When designing a multipurpose survey several choices need to be made. They usually are not
trivial, because identifying the best solution for every purpose (i.e. every interest variable for each
domain of interest) is challenging. Usually “just“ a practical optimum, not the best solution, can be
pursued. The research for the best solution - maximizing data quality within budgetary constraints -
may arise conﬂicts in several areas (Kish, 1988). Among these areas, sample size and the relation of
biases to sampling errors are considered the most important because their inﬂuence ripples throughout
the overall survey.

This view justiﬁes the care and attention always given in the literature to the optimal sample design
(Cochran, 1977; Cicchitelli et al., 1992; Conti and Marella, 2012; Till´e, 2020). Gonzalez and Eltinge
(2010) present an interesting overview of the approaches for deﬁning optimal sampling strategies.

The optimization problem of a sample design is usually dealt with the estimation of a mean (or
equivalently of a total) in stratiﬁed sampling designs with a ﬁxed sample size. The problem of the
optimization of stratiﬁed sample design can be classiﬁed depending on whether stratiﬁcation is given
or also the stratiﬁcation has to be optimized, before or at the same time of the allocation.

The R2BEAT package solves the optimization problem when the stratiﬁcation is given and the
optimization must be sought in the allocation of sampling units. Therefore, in the following, we focus
just on this situation. For more details on the optimization problems when also the stratiﬁcation has
to be optimized see, e.g., Ballin and Barcaroli (2013) and references therein.

2

2.1 Optimal allocation

Let us consider a population U of size N (k = 1, . . . , N ) partitioned in H subgroups, Uh (h = 1, . . . , H),
called strata. Hence, each stratum contains Nh elements, where Nh is assumed to be known and such
as (cid:80)H

h=1 Nh = N .

The strata can be deﬁned in diﬀerent ways on the basis of one or more qualitative variables known

for all the units in the population.

Then, we assume, at least for the moment, to be interested in investigating the mean of just one y

variable in the population U ,

µy =

(cid:80)

k∈ U yk
N

(1)

where yk is the value of the y variable observed on the k-th unit in the population U . The y variable
could be a quantitative variable or dichotomous, that is y ∈ {0, 1}. Please note that, even when y is a
dichotomous variable, expression (1) holds and µy is equal to the proportion of units in the population
for which y = 1.

Furthermore, assume we want to estimate µy through a probabilistic sample s of size n with the

estimator

ˆ¯Y =

ˆYHT
N

=

(cid:80)

k∈s yk dk
N

(2)

where ˆYHT is the Horvitz-Thompson estimator for the total (Horvitz and Thompson, 1952) in which
dk is the design weight usually equal to the inverse of the ﬁrst order inclusion probability.

The sample size of a survey, n, is usually exogenous information, dictated by budget and, sometimes,
by logistic constraints associated to the unit k in the sample. Then, in practice, the problem comes
down to the allocation of the n units in the H strata, such as (cid:80)H

h=1 nh = n.

Therefore, let us deﬁne

µhy =

(cid:80)

U yk 1h
Nh

(3)

the mean of the y in each stratum where 1h is the membership indicator for the unit k in the stratum
h.

In the same way, expressions (2) can be easily adapted for estimating µhy, that is

ˆ¯Yh =

ˆYHT,h
Nh

=

(cid:80)

yk dk

k∈sh
Nh

,

where sh is the sample in the stratum h. The sampling variance estimator of ˆ¯Yh is given by
(cid:18) 1
nh

1
nh − 1

(yhk − ¯yh)2,

(cid:19) (cid:88)

1
Nh

(cid:16) ˆ¯Yh

(cid:99)var

−

=

(cid:17)

k∈h

(4)

(5)

where ¯yh is the sample mean of the variable y in the stratum h.

In this perspective, the mean of y in (1) can be written also as

and, consequently, ˆ¯Y in (2) as

µy =

H
(cid:88)

h=1

Nh
N

µhy

ˆ¯Y =

H
(cid:88)

h=1

Nh
N

ˆ¯Yh.

Therefore, the sampling variance estimator for ˆ¯Y is

(cid:17)

(cid:16) ˆ¯Y

=

(cid:99)var

(cid:19)2

H
(cid:88)

h=1

(cid:18) Nh
N

(cid:17)

(cid:16) ˆ¯Yh

.

(cid:99)var

3

When there is no information on y, the sample size to be allocated to each stratum, nh, can be

assigned by performing uniform or proportional allocation.

Uniform allocation assigns an equal number of sampling units to each stratum, that is

nU N IF

h

=

n
L

.

More often, we want the sample size assigned to strata in the sample to be proportional to the

sizes of the strata in the population, that is

nP ROP

h

= n

Nh
N

where Nh/N is the weight of the stratum in the population with (cid:80)L
same for all strata (N1 = · · · = Nh = · · · = NL = N/L), nP ROP

h

comes down to nU N IF

.

h

h=1 Nh/N = 1. If the size is the

When there is information in the population strata on y and in particular on its variance, S2
yh, a
more favourable allocation can be performed. Alternatively, it is possible to consider also a proxy vari-
able highly correlated with y. In this case, Tschprow (1923) demonstrated that the optimal allocation
can be obtained by giving

nOP T
h

= n

(cid:113)

Nh
N

S2
yh
(cid:113)

(cid:80)L

h=1

Nh
N

S2
yh

However, this result is better known as Neyman allocation by the namesake author that in 1934
published the same result. The rationale behind the optimal allocation is that strata with more weight
and in which y has much more variability need much more observations for reaching better estimates.
comes down to nP ROP
1 = · · · = S2
If the variance is the same in all the strata (S2
.
As evidence, the computation of the population variance is a crucial point in the optimal allocation.
A distinction between the types of variables and the sources from which they can be obtained is needed.
When y is a dichotomous variable available from a population register, its population variance can be
computed as

h = · · · = S2

L), nOP T
h

h

where ph is the proportion of units with y = 1 in the population strata. In the case of a quantitative
variable, S2

yh is equal to

S2

yh = ph × (1 − ph)

(6)

S2

yh =

(cid:80)

k∈Uh

(yk − µyh)2
Nh

.

When there is no population register, information on the variability can be obtained from a sample
survey or a pilot survey previously carried out. Let us assume to have collected the y variable, or at
least its proxy variable, on a sample s∗. Then, (6) can be computed just by replacing ph with
(cid:80)

,

(7)

ˆph =

yk wk
wk

k∈s∗
h
(cid:80)

k∈s∗
h

that is the related estimate for each stratum obtained from the sample s∗. In (7) wk is the sampling
weight associated with the unit k in the sample s∗.
Instead, when y is a quantitative variable,

yh = ˆM 2
S2

h − ˆ¯Y 2

h

where

ˆM 2

h =

y2
k wk

(cid:80)

k∈s∗
h
N

and

ˆ¯Yi =

yk wk

(cid:80)

k∈s∗
h
N

are the quadratic mean and the arithmetic mean estimated on the sample s∗ in the h-th stratum,
respectively.

4

Sometimes, collecting data on units belonging to diﬀerent strata can have diﬀerent costs for the
diﬃculties in reaching them (e.g. strata are altitude zone) or the need of using diﬀerent data collection
modes. Therefore, it is advisable to deﬁne the allocation by taking into account also the unit cost and
the budget constraints.

The global cost of the survey can be deﬁned as

C = c0 +

L
(cid:88)

h=1

nh ch,

where c0 is the ﬁxed cost (not dependent on the sample size) and ch is the unit cost for collecting data
on one unit belonging to stratum h. Then, the optimal allocation under budget constraints is given by

n ¯OP T
h

= (C − c0)

Nh
N

√
√

S2

yh

(cid:80)L

h=1

Nh
N

ch
(cid:113)

.

√

ch

S2
yh

If c1 = · · · = ch = · · · = cL = 1 and c0 = 0, the global cost amounts to the sample size (C = n).

The optimal allocation for just one y variable is of little practical use unless the various variables
under study are highly correlated. This is because an allocation that is optimal for one characteristic
is generally far from being optimal for others.

Therefore, several works have been devoted to solving the problem when more than one variable
of interest has to be measured on each sampled unit. All the contributions can be classiﬁed into two
main approaches: the “average variance” and convex programming.

The methods under the “average variance” approach consist of deﬁning a weight for each variable
to consider, computing a weighted average of the stratum variance and ﬁnding the optimal allocation
on the “average variance” which results. They are computationally simple, intuitive and can be solved
under ﬁxed cost assumption. However, the choice of the weights is completely arbitrary and the
optimal properties are not clear (see, e.g., Dalenius, 1953; Yates, 1960; Folks and Antle, 1965; Hartley,
1965; Kish, 1976, for more details).

Instead, the other approach includes methods that use convex programming to ﬁnd the minimum
cost allocation when the variances of all the sampling variables to consider satisfy ﬁxed constraints.
The obtained allocation is actually optimal, but sometimes it can exceed the budgetary constraints
(see, e.g., Dalenius, 1957; Yates, 1960; Kokan, 1963; Hartley, 1965; Kokan and Khan, 1967; Chatterjee,
1968, 1972; Huddleston et al., 1970; Bethel, 1985; Chromy, 1987; Falorsi et al., 1998; Stokes and
Plummer, 2004; Choudhry et al., 2012; Kozak et al., 2007, 2008, for more details).

The most important method in the convex programming approach is the Bethel algorithm (Bethel,

1989) which extends the Neyman allocation to the multivariate case.

In particular, when we are interested in investigating the mean of more than one y variable (quanti-
tative or dichotomous), namely y1, . . . , yi, . . . , yJ , the optimal allocation problem reduces, in practice,
to a minimum optimization problem of a convex function under a set of linear constraints






C = min
(cid:16) ˆ¯Yi,h

(cid:100)CV

(cid:17)

(cid:17)

(cid:16) ˆ¯Yi,h

≤ δ

i = 1, . . . , J
h = 1, . . . , L

(8)

where C is the global cost of the survey and ˆCV
estimate of the relative error,

(cid:17)

(cid:16) ˆ¯Yi,h

is the estimate of the relative error. The

(cid:17)

(cid:16) ˆ¯Yi,h

=

(cid:100)CV

(cid:114)

(cid:17)

(cid:99)var

(cid:16) ˆ¯Yi,h
ˆ¯Yi,h

,

(9)

is the ratio between the estimate of the sampling variance for the mean estimator of yi variable
(cid:16) ˆ¯Yi,h
(cid:17)
(i = 1, . . . , J) in the stratum h given by expression (5) and the related estimate. In this case, (cid:100)CV
is called expected errors and it must be less than or equal to the precision constraints deﬁned by the
user or by regulation, δ

(cid:17)

.

(cid:16) ˆ¯Yi,h

5

Bethel (1989) demonstrates that the solution to this optimization problem exists and can be ob-
tained through an algorithm that applies the Lagrangian multipliers method. The solution is a con-
tinuous solution, then it must be rounded to provide an integer stratum sample size. The rounding
clearly causes some deviations from the solution that, however, do not aﬀect its optimality (Cochran,
1977). The Bethel algorithm is very similar to the Chromy algorithm (Chromy, 1987). However, it is
preferable because, even if the Chromy algorithm is simpler, there is no proof that it converges if a
solution exists.

The same framework works to deal also with the multi-domain problem.
Usually, estimates of a survey are disseminated for the whole population and sub-domains, for
instance for geographical areas, but not only. Then, it is useful to deﬁne the optimal allocation also
taking into account these outcomes of the survey.

Sub-domain estimation is actually a long-established theory (S¨arndal et al., 2003). Expressions (1)
can be easily adapted just by introducing the sub-domain membership indicator variable, 1k,d, which
is equal to 1 for all the unit k in the domain d and 0 otherwise, that is

µd

y =

(cid:80)

Ud

yk 1k,d
Nd

where Nd is the population size in the domain d (d = 1, . . . , D). It is important to point out, that
domains must be an aggregation of strata and they do not have to cut the strata. Then, it is suﬃcient
to consider the domain estimates in the minimum optimization problem in (8) and use the Bethel’s
algorithm for deriving the multivariate allocation in the multi-domain case.

However, in oﬃcial statistics, especially for household surveys, two-stage sampling designs are

usually adopted.

Two-stage sampling is based on a double sampling procedure: one on the primary stage units
(PSUs) and another on the second stage units (SSUs). For instance, in the household survey, the
PSUs are the municipalities that are ﬁrstly selected. Then, in each selected municipality, a sample of
households - the SSU - can be selected.

Two-stage sampling permits more complex sampling strategies and, moreover, it helps in the orga-
nization and cost reduction of data collection, because it reduces the interviewer’s travels. However,
this economic saving is paid oﬀ with a loss of eﬃciency of the estimates. In fact, each additional stage
of selection usually entails an increase of the sampling variance of the mean estimator. This increase
can be assessed by the design eﬀect (def f ) that measures how much the sampling variance of ˆ¯Yi, under
the adopted sampling design (des), is inﬂated with respect to a simple random sample (srs), with the
same sample size. An estimate of the design eﬀect, under can be given by the expression:

def f

(cid:17)

(cid:16) ˆ¯Yi

=

(cid:16) ˆ¯Yi
(cid:16) ˆ¯Yi

(cid:99)var

(cid:99)var

(cid:17)

des

(cid:17)

srs

While a rough approximation of the def f can be obtained when the clusters have the same sample
size and the same inclusion probability (Cicchitelli et al., 1992),

def f

(cid:17)

(cid:16) ˆ¯Yi

= 1 + ρi (b − 1)

(10)

where b is the average cluster (i.e. PSU) size in terms of the ﬁnal sampling units and ρi is the intra-class
correlation within the cluster (PSU) for the variable yi (i = 1, . . . , J).

The intra-class correlation provides a measure of data clustering in PSUs and SSUs. In general,
if ρi is close to 1, the clustering is high and it is convenient to collect only a few units in the cluster.
On the contrary, if ρi is close to 0, the collection of units from the same cluster does not aﬀect the
eﬃciency of the estimates.

Also for computing ρi, we can distinguish whether a population register in which the yi variables
(i = 1, . . . , J), or at least their proxies, are available or not. In the former case, a good approximation
is given by the expression

ρi = 1 −

Dwi
Dyi

6

(11)

where

and

Dwi =

L
(cid:88)

N(cid:96)(cid:88)

(cid:96)=1

k=1

(cid:0)yi,k − µyi,(cid:96)

(cid:1)2

Dyi =

(yi,k − µyi)2

(cid:88)

k∈U

are the deviance within clusters and the global deviance of the yi variable, respectively. Remember
that Dyi = Dwi + Dbi , where

Dbi =

L
(cid:88)

(cid:96)=1

N(cid:96) (µyi,(cid:96) − µ)2 ,

is the deviance between clusters. Therefore, 0 ≤ ρi ≤ 1.

Instead, ρi can be estimated from a sample with the expression (10)

ˆρi =

def fi − 1
b − 1

.

(12)

Here we consider, directly, a more general expression for the estimate of the def f in terms of the
intra-class correlation coeﬃcient. This expression refers to a typical situation in household surveys
where PSUs are assigned to Self-Representing (SR) strata, that is they are included for sure in the
sample, or to Not-Self-Representing (NSR) strata, where they are selected by chance. In practice, this
assignment is usually performed by comparing the measure of the size of PSUs to the threshold:

λ =

¯m ∆
f

(13)

where ¯m is the minimum number of SSUs to be interviewed in each selected PSU, f = n/N is the
sampling fraction and ∆ is the average dimension of the SSU in terms of elementary survey units.
Then, ∆ must be set equal to 1 if, for the survey, the selection units are the same as the elementary
units (that is, household-household or individuals-individuals), whereas it must be set equal to the
average dimension of the households if the elementary units are individuals, while the selection units
are the households.

PSUs with a measure of size exceeding the threshold are identiﬁed as SR, while the remaining PSUs

are identiﬁed as NSR.

Then, the extended expression of def f (see among the others Rojas, 2016) is

def f

(cid:17)

(cid:16) ˆ¯Yi

=

N 2
SR
nSR

[1 + (ρi,SR (bSR − 1)] +

N 2
N SR
nN SR

[1 + (ρi,N SR (bN SR − 1)]

(14)

where, for SR and N SR strata,

• NSR and NN SR are the population sizes;

• nSR and nN SR are the sample sizes;

• ρi,SR and ρi,N SR the intra-class correlation coeﬃcients for the variable i (i = 1, . . . , J);

• bSR and bN SR are the average PSU size in terms of the ﬁnal sampling units.

Of course, if there are no SR strata the expression (10) recurs. The design eﬀect is equal to 1 under
the srs design and increases for each additional stage of selection, due to the intra-class correlation
coeﬃcient which is, usually, positive.

The intra-class correlation coeﬃcient for NSR can be derived with expression (11) or (12) whether
population register data are available or not. While it is not necessary to compute the intra-class
correlation coeﬃcient for SR strata because just one PSU is selected and the intra-class correlation is
1 by deﬁnition.

7

Therefore, under a two-stage sample design for determining the optimal allocation, the number of

PSUs and SSUs must be determined.

The solution has been proposed by Falorsi et al. (1998) in a paper published in Italian and it
is obtained with an iterative use of the Bethel algorithm. In fact, at the ﬁrst iteration, the Bethel
algorithm is applied. The optimal allocation for a stratiﬁed simple sampling design is obtained. Then,
this allocation is used to update the threshold in (13) and the design eﬀect in (14). A new design eﬀect
is computed and used in turn to inﬂate the S2
h). It is used as input in the next
iteration in which the Bethel algorithm is used again. The obtained allocation is used again to update
the threshold and the design eﬀect, and a new allocation is found. The process is iterated until when
the diﬀerence between two consecutive iterations is lower than a predeﬁned threshold.

h (or equivalently ˆS2

Algorithm 1: R2BEAT optimal allocation of PSUs and SSUs in sampling strata

Input :

a. precision constraints in terms of CV;
b. information on sampling strata (mean and stdev of target variables, N, ...);
c. information on previous design: deﬀ, eﬀst, rho ;
d. information on PSUs in sampling strata (measure of size);
e. minimum number of SSUs per PSU;

Output:

a. for each stratum: number of PSUs and SSUs to be selected;
b. expected CVs for target estimates;
c. item sensitivity of the solution;

REM First iteration;

1. input deﬀ is used to inﬂate standard deviations of target variables in sampling strata;
2. optimal allocation of SSUs in sampling strata is obtained by applying the Bethel algorithm

as if it were a one-stage sampling design;

3. the number of PSUs is determined on the basis of the minimum number of SSUs per PSU;
4. the threshold for determination of self-representing PSUs is calculated;
5. new deﬀ is calculated and used to update the standard deviations of target variables in

sampling strata;

REM Next iterations;

while not convergence do

1. optimal allocation of SSUs in sampling strata is obtained by applying the Bethel
algorithm;
2. the number of PSUs is determined on the basis of the minimum number of SSUs per
PSU;
3. the threshold for determination of self-representing PSUs is calculated;
4. new deﬀ is calculated an used to update standard deviations of target variables in
sampling strata;
5. the iteration stops if

a. the diﬀerence between the sample sizes of two iterations is lower than 5 (default value) or

b. the maximum of defts (square root of deﬀs) largest diﬀerences is lower than 0.06 (default value)

or

c. the number of iterations is higher than 20 (default value);

end

However, as pointed out by Waters and Chester (1987), diﬀerent combinations yield the same
(cid:16) ˆ¯Yi,h

. The optimal solution strongly depends on

variance and can satisfy the precision constraints, δ

(cid:17)

8

the budgetary constraints that limit the SSU s and the data collection organization that inﬂuences the
maximum number of P SU s that can be managed.

All this discussion holds when you want to use the HT estimator. But, currently, the most applied
estimator for the NSIs survey is the calibrated estimator (Deville and S¨arndal, 1992; S¨arndal, 2007;
Devaud and Till´e, 2019). The calibrated estimator, through the use of auxiliary variables, usually
provides better estimates than HT . Then, it can be useful to take into account, since the allocation
phase, also be the impact on the estimates of an estimator diﬀerent from the HT estimator. This can
be done by inﬂating the S2
yh with the estimator eﬀect and following the procedure explained above.
An estimate of the estimaror eﬀect (ef f st) is given by

ef f st( ˆ¯Yi) =

(cid:17)

(cid:16) ˆ¯Yi
var
(cid:16) ˆ¯Yi,HT

var

(cid:17) .

(15)

It measures how much the sampling variance of the applied estimator under the adopted design is
inﬂated or deﬂated with respect to the sampling variance of the HT estimator, on the same sample
design.

2.2 Sample selection

Once the optimal allocation is deﬁned, the selection of sampling units must be performed.

In the case of a stratiﬁed two-stage sampling design two sampling selections need to be done: one

for PSUs and one for SSUs.

In each stratum, the PSUs are split into SR and NSR according to a size threshold (13). PSUs
with a measure of size exceeding the threshold are identiﬁed as SR, included for sure in the sample
and each of them constitutes an independent sub-stratum. Therefore, the probability that they are
included in the sample (inclusion probability, πI ) is always equal to 1. However, it can happen that
no one PSU has a measure of size higher than the threshold.

The remaining PSUs, NSR-PSUs, are ordered by their measure of the size and divided into ﬁner
strata (sub-strata) whose sizes are approximately equal to the threshold multiplied by the number of
PSUs to be selected in each stratum. In this way, sub-strata are composed of PSUs having size as
homogeneous as possible.

The PSUs in each stratum can be selected in diﬀerent ways. However, the selection of a ﬁxed
number of PSUs per stratum is usually carried out with Sampford’s method (unequal probabilities,
without replacement, ﬁxed sample size). Then, the inclusion probability of the generic (cid:96)-th NSR-PSU,
is

πI =

Nh
m Mh(cid:96)

where Nh is the measure of size in the sub-stratum h-th, m is the number of NSR-PSUs to be selected
in the sub-stratum and Mh(cid:96) is the measure of size in the (cid:96)-th PSU in the sub-stratum h.

Finally, the SSUs must be drawn in the selected PSU. Also in this case the SSU can be selected
in diﬀerent ways. In most cases, they are selected through a systematic sampling design that shares
several properties with the srs. Then, the inclusion probability for the second stage is equal to

πII =

nh(cid:96)
Mh(cid:96)

where nh(cid:96) is the number of SSUs to be selected in the (cid:96)-th PSU in the h-th sub-stratum.

Then, the design weight for the unit k in the h-th strata in the (cid:96)-th PSU is equal to the inverse of

the product of the ﬁrst stage and the second stage inclusion probabilities,

1
πII
The design weights sum up to the population size, (cid:80)
stratum, which means that the sample is self-weighting.

1
πI

dk =

.

k∈s dk = N , and are almost constant in each

9

Algorithm 2: R2BEAT selection of PSUs

Input :

a. The output of the allocation step (function beat.2st) (universe of PSUs, measure of PSUs,
number of PSUs and SSUs to be selected in each stratum, threshold);

Output:

a. universe of PSUs with stratum, sub-stratum, PSU ﬁrst order inclusion probability, PSU
weight, ﬂag sample, and number of SSUs to be selected in each PSU;
b. sample of PSUs (ﬂag sample=1) with stratum, sub-stratum, PSU ﬁrst order inclusion
probability, PSU weight, number of SSUs to be selected in each PSU;
c. statistics related to the sample of PSUs at stratum level;

REM creation of sub-strata and selection of PSUs;

1. in each stratum, PSUs are sorted in descending order according to their measure of size;
2. the measure of size of PSUs are compared with the threshold;
3. PSUs with a measure of size exceeding the threshold are identiﬁed as SR, included for sure

in the sample and constitutes an independent sub-stratum;

4. the remaining PSUs, NSR-PSUs, are ordered in decreasing way by their measure of the size

and aggregated into ﬁner strata (sub-strata);

5. sub-strata are created adding PSUs (still in descending order of measure of size) for which

the sum of the measure of size of the sub-strata is approximately equal to the threshold
multiplied by the number of PSUs to be selected in each stratum;

6. in each sub-stratum a ﬁxed number of PSUs per stratum are usually selected with
Sampford’s method (unequal probabilities, without replacement, ﬁxed sample size);

3 Structure of the package

The R2BEAT package provides functions for drawing complex sample designs using an optimal al-
location also performing the selection of the PSUs and SSUs. To install the latest release version
of R2BEAT from CRAN, type install.packages(”R2BEAT”) within R. The current development
version can be downloaded and installed from GitHub by executing

devtools::install github(”barcaroli/R2BEAT”).
This section provides an introduction to the structure and functions associated with the package

while the next section will present examples of its speciﬁc use.

The workﬂow to draw and select a complex sample using R2BEAT is: (1) prepare the input data,
(2) check the input data, (3) deﬁne the design and obtain the allocation, and (4) select the ﬁnal sample
units.

3.1 Prepare the input data

As it will be illustrated in detail in the next sub-sections the R2BEAT package provides functions to
deﬁne one-stage stratiﬁed sample design (beat.1st) and two-stage stratiﬁed sample design (beat.2st).
The preparation of the input dataset changes whether the former or the latter sample design will be
adopted.

In the case of a multivariate optimal allocation for diﬀerent domains in a stratiﬁed one-stage sample
design, the function beat.1st can be used. The inputs required by this function are two, a data frame
containing survey strata information (stratif ) and a data frame of expected CV for each domain
and each variable (errors). No functions to prepare these inputs are provided by the package but is
possible to follow the example dataset stratif and error to properly create the input datasets for the
function beat.1st.

In the case of a two-stage design, two functions are provided by the package to help in the creation
of the input data for the function beat.2st. The functions are two because two diﬀerent scenarios are
possible, depending on the initial information available:

10

1. Only the sampling frame is available, no previous rounds of the survey have been carried out.
In this scenario, a strict condition on the information content of the sampling frame must hold: values
of the sample target surveys (or of their proxy correlated variables) are available for each unit in
the frame. This can be accomplished by considering the previous census, or by using administrative
registers. In this scenario, the function prepateInputToAllocation1 can be used to create the input
dataframes stratif, rho, deft, eﬀst, des ﬁle and psu ﬁle.

2. Together with a sampling frame containing the units of the population of reference, also a
previous round of the sampling survey to be planned is available. The prepateInputToAlloca-
tion2 produces the same outputs of prepateInputToAllocation1, but it requires the design and/or
calibrated objects of the previous sample survey, obtained using the ReGenesees package (Zardetto,
2015).

The function sensitivity min SSU allows analyzing the diﬀerent results in terms of ﬁrst stage
size (number of PSUs) and second stage size (number of SSUs), obtained when varying the values of
the minimum number of SSUs to be selected in each PSU.

To check the coherence between the estimated population in the strata (stratif ) and the population
calculated by the PSUs dataset (des ﬁle), the function check input is provided to the users. This
function compares the strata sizes giving information about the diﬀerences and replacing the estimated
stratum size with the stratum population calculated by the PSUs dataset.

3.2 Deﬁning the design and determining the allocation

As already introduced, the package allows performing the optimal allocation for both one-stage and
two-stage stratiﬁed sampling

The ﬁrst one is implemented within the function beat.1st and computes a multivariate optimal
allocation for diﬀerent domains in one-stage stratiﬁed sample design. As described in section 3.1, in a
one-stage stratiﬁed sample design there are only two inputs to be provided to beat.1st: the dataframes
stratif and errors. Besides these two mandatory inputs, it is also possible to indicate the minimum
number of sampling units to be selected in each stratum, by default set equal to 2.

The function beat.2st performs the same multivariate optimal allocation for diﬀerent domains con-
sidering stratiﬁed two-stage design. Together with the input data stratif and errors other mandatory
input are:

• des ﬁle: dataframe containing a row per each stratum, with information on total population,
the values of the delta parameter (equal to the mean number of ﬁnal SSUs contained in clusters
to be selected, for instance, the mean number of individuals in a household), and the minimum
number of SSUs to be selected in each PSU;

• psu ﬁle: dataframe containing information on each PSUs (identiﬁer, stratum, measure of size).

• rho: dataframe contains a row per each stratum with the intra-class correlation coeﬃcient both

for self representing and non-self representing PSUs.

Is also possible to provide optional information about:

• deft start: dataframe containing a row per each stratum with the starting values for the square

root of the design eﬀect in the stratum of each variable of interest.

• eﬀst: dataframe containing a row per each stratum with the estimator eﬀect for each variable

of interest.

The functions beat.1st and beat.2st produce lists with respectively 4 and 9 items.
The beat.1st output contains:

1. n: a vector with the optimal sample size for each stratum;

2. ﬁle strata: a dataframe corresponding to the input dataframe stratif with the n optimal sample

size column added;

3. alloc: a dataframe with optimal (ALLOC), proportional (PROP), equal (EQUAL) sample

size allocation;

11

4. sensitivity: a data frame with a summary of planned coeﬃcients of variation (Planned CV),
the expected ones under the given optimal allocation (Actual CV), and the sensitivity at 10%
for each domain and each variable. Sensitivity can be a useful tool to help in ﬁnding the best
allocation, as it provides a hint of the expected sample size variation for a 10% change in planned
CVs.

Together with the previous outputs, the function beat.2st produces also:

1. iterations: a dataframe that for each iteration of the Bethel algorithm provides a summary with
the number of PSUs (PSU Total), distinguished between SR (PSU SR) and NSR (PSU NSR),
plus the number of SSUs;

2. planned: a dataframe with the planned coeﬃcients of variation for each variable in each domain.

3. expected: a dataframe with a summary of expected coeﬃcients of variation under the given

optimal allocation for each target variable in each domain;

4. deft c: a dataframe with the design eﬀect for each variable in each domain in each iteration.
Note that DEFT1 0 - DEFTn 0 is always equal to 1 if deft start is NULL; otherwise it is
equal to deft start. While DEFT1 - DEFTn are the ﬁnal design eﬀect related to the given
allocation.

5. param alloc: a vector with a resume of all the parameters given for the allocation.

3.3 Sample units selection

Once the allocation for the primary and secondary sampling stage units has been deﬁned, it is possible
to use two functions for the selection of the ﬁnal sampling units.

The function select PSU allows the users to select the PSUs allocated in each stratum, using the
Sampford method, as implemented by the UPsampford function of R package sampling (Till´e and
Matei, 2021).

The input of this function is the output of the beat.2st function.
The output of the function is a list containing the following items:

1. universe PSU: a dataframe that reports the whole universe of PSUs, with the inner strata

formed for the selection;

2. sample PSU: a dataframe containing the selected PSUs, with the indication, for each of them,

of how many SSUs must be selected;

3. PSU stats: a table containing summary information on selected PSUs.

In the last step, the selection of a sample of SSUs has to be carried out. The function select SSU
allows selecting a sample of SSUs from the population frame, based on the SSUs allocated to each
selected PSUs.

The input datasets are two:

1. df : the dataframe containing the ﬁnal sampling units;

2. PSU sampled: the dataframe containing selected PSUs, corresponding to the second item of

the output of the select PSUfunction.

The function select SSU returns a dataframe containing the selection of the df dataframe, en-
riched with information about the ﬁrst stage inclusion probability, the second stage inclusion prob-
ability, the ﬁnal inclusion probability (the product of the ﬁrst stage and the second stage inclusion
probabilities) and the design weights.

12

4 Illustrative examples

To illustrate how to implement workﬂows making use of R2BEAT functions, we will consider two
scenarios, depending on the initial setting:

1. only the sampling frame is available, no previous rounds of the survey have been carried out;

2. together with a sampling frame containing the units of the population of reference, also a previous

round of the sampling survey to be planned is available;

In both cases, we assume that the sampling frame contains information on the ﬁnal sampling units,
together with the indication of the PSUs to which each unit belongs. In the ﬁrst scenario, a stricter
condition on the information content of the sampling frame must hold: values of the sample target
surveys (or of their proxy correlated variables) must be available for each unit in the frame. This can
be accomplished by considering a previous census, or by imputing values using predictive models. In
the following paragraphs, we will show only a subset of the code necessary to produce the ﬁnal results,
the relevant part of it1.

4.1 Scenario 1 workﬂow

In this scenario, it is assumed that a sampling frame is available. We consider a frame (pop.RData),
containing 2,258,507 units:

cl_age
region province municipality id_hh id_ind stratum stratum_label sex
(24,34]
1
H1
2
H1
(64,74]
1 (74,112]
H1
(44,54]
2
H10
(34,44]
1
H100
(54,64]
1
H100

north_1_6
north_1_6
north_1_6
north_1_6
north_1_6
north_1_6

12000
12000
12000
12000
12000
12000

1 north north_1
2 north north_1
3 north north_1
4 north north_1
5 north north_1
6 north north_1
...

1
2
3
4
5
6

1
1
1
1
1
1

active income_hh unemployed inactive
0
0
1
0
0
0

1 30487.75
1 30487.75
0 30487.75
1 21755.68
1 29870.56
1 29870.56

0
0
0
0
0
0

1
2
3
4
5
6
...

covering a (synthetic) population of reference, with basic information (geographical and demo-

graphic variables:

• region: the NUTS2 identiﬁer;

• province: the NUTS3 identiﬁer;

• municipality: identiﬁer of the municipality, that plays the role of the PSU identiﬁer;

• id hh: the household identiﬁer;

• id ind: the individual identiﬁer;

• stratum and stratum label: identiﬁer of the initial strata (provinces);

• sex and cl age: demographic information on individuals.

together with information that is related to the sampling survey we want to design:

1In order to reproduce the processing related to these examples, datasets and R scripts are downloadable from the

link https://github.com/barcaroli/R2BEAT workﬂows.

13

• active, inactive, unemployed: binary variables indicating the occupation status of the indi-

vidual;

• income hh: household income.

We suppose that the values of these variables have been made available by a diﬀerent source (for
instance a census) or by predicting them with a model-based approach. In any case the uncertainty
related to these values should be taken into account, by correctly evaluating the anticipated variance
related to the models used for the predictions when producing the strata dataset (Baillargeon and
Rivest, 2011, p. 59).

Anyway, in the following, we will not consider this issue, as we want only to illustrate how it is

possible to automatically derive all the inputs required by the next steps.

4.1.1 Step 1: preparation of the inputs for the optimal sample design

The function prepareInputToAllocation1 allows preparing all the inputs required by the optimal
allocation step under this ﬁrst scenario. This function requires the attribution of values to the following
parameters:

• samp frame

• id PSU

• id SSU

• strata var

• target vars

• deﬀ var

• domain var

• delta (average dimension of the SSU in terms of elementary survey units)

• minimum (minimum number of SSUs to be interviewed in each selected PSU)

About the values of these parameters, the choices are almost always driven by the content and
structure of the sampling frame, except for minimum. In order to orientate in the choice of one of a
suitable value for this parameter, the function sensitivity min SSU allows performing a sensitivity
analysis, showing how the ﬁrst and second stage sample sizes vary by varying its values:

> sens_min_SSU <- sensitivity_min_SSU (
+
+
+
+
+
+
+
+
+
+
+
+

samp_frame=pop,
id_PSU="municipality",
id_SSU="id_ind",
strata_var="stratum",
target_vars=c("income_hh","active","inactive","unemployed"),
deff_var="stratum",
domain_var="region",
minimum=50,
delta=1,
deff_sugg=1.5,
min=30,
max=80)

This function calculates 10 diﬀerent couples of values for the number of PSUs and SSU as resulting
from the allocation step, starting with the value ’30’ assigned to the parameter minimum, ending
with the value ’80’. The results are reported in Figure 1.

On the basis of the results of the sensitivity analysis, we can instantiate the required parameters,

for example in this way:

14

Figure 1: Sensitivity analysis for minimum parameter.

minimum = 50

# minimum number of SSUs to be interviewed in each selected PSU

and execute the prepareInputToAllocation1 function:

> inp <- prepareInputToAllocation1(
+
+
+
+
+
+
+
+
+
Computations are being done on population data
Number of strata: 24
... of which with only one unit:

samp_frame = pop,
id_PSU = "municipality",
id_SSU = "id_ind",
strata_var = "stratum",
target_vars = c("income_hh","active","inactive","unemployed"),
deff_var = "stratum",
domain_var = "region",
delta,
minimum)

0

The output of this function (inp) is a list composed by the following elements:

1. the strata dataframe

2. the deﬀ dataframe

3. the eﬀst dataframe

4. the rho dataframe

5. the psu ﬁle dataframe

6. the des ﬁle dataframe

15

that will be the inputs for the optimal allocation step (with the exception of the deﬀ ), which is
produced only for documentation).

Here we report the content of the rho dataframe:

STRATUM RHO_AR1

RHO_NAR1 RHO_AR2

RHO_NAR2 RHO_AR3

1 0.00001260175649
1 0.00150936389450
1 0.00162968276279
1 0.00578473329221
1 0.00000001682475
1 0.00004270905958

1
2
3
4
5
6

1
2
3
4
5
6

1000
2000
3000
4000
5000
6000
RHO_AR4

1 0.0032494875
1 0.0028554017
1 0.0069678726
1 0.0114552934
1 0.0002677333
1 0.0057050500
RHO_NAR4
1 0.000039120880
1 0.000937018761
1 0.002837431259
1 0.008962657055
1 0.000003404961
1 0.000194411580

RHO_NAR3
1 0.0000003631192
1 0.0007420929883
1 0.0006469515878
1 0.0019797687826
1 0.0000029484212
1 0.0000397945795

that has been calculated using the equation (11).

4.1.2 Step 2: optimization of PSUs and SSUs allocation

It is now possible to execute the optimization step of the sample design.

First of all, we deﬁne the set of precision constraints on the target variables:

DOM CV1 CV2 CV3

CV4
1 DOM1 0.02 0.03 0.03 0.05
2 DOM2 0.03 0.06 0.06 0.08

We interpret the values of the CVs in this way: the maximum expected coeﬃcient of variation for the
ﬁrst target variable (household income) is 2% at the national level and 3% at the regional level; for
active and inactive the expected maximum values of CV is 3% at the national level and 6% at the
regional level; ﬁnally, for unemployed it is 5% at the national level and 8% at the regional level.

The optimization step is performed by executing the beat.2s function:

> inp1$desfile$MINIMUM <- 50
> alloc1 <- beat.2st(stratif = inp1$strata,
+
+
+
+
+
+
+
+
+

errors = cv,
des_file = inp1$des_file,
psu_file = inp1$psu_file,
rho = inp1$rho,
deft_start = NULL,
effst = inp1$effst,
minPSUstrat = 2,
minnumstrat = 50
)

iterations PSU_SR PSU NSR PSU Total

1
2
3
4

0
1
2
3

0
31
39
38

0
104
104
104

SSU
0 7887
135 8328
143 8317
142 8320

This design is characterized by 142 PSUs (of which 38 self-representative, SR, and 104 non self-

representative, NSR) and 8,320 SSUs.

4.1.3 Step 3: selection of PSUs and SSUs

We can now proceed in selecting the PSUs:

16

> sample_1st <- select_PSU(alloc, type="ALLOC", pps=TRUE, plot=TRUE)
> sample_1st$PSU_stats

STRATUM PSU PSU_SR PSU_NSR
0
6
4
2
0
2
2
2
0
0

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25

2
1000
9
2000
4
3000
2
4000
2
5000
2
6000
2
7000
2
8000
1
9000
6
10000
26
11000
8
12000
1
13000
4
14000
27
15000
18
16000
1
17000
4
18000
7
19000
4
20000
1
21000
3
22000
4
23000
24000
2
Total 142

SSU SSU_SR SSU_NSR
0
286
286
300
152
452
200
0
200
100
0
100
0
219
219
100
0
100
100
0
100
100
0
100
0
557
557
0
587
587
1200
100
24 1300
400
0
400
0
703
703
0
577
577
900
461
18 1361
900
0
900
18
0
154
154
0
100
100
200
2
300
50
350
6
200
0
200
4
0
125
125
0
0
150
150
0
200
0
200
4
100
0
100
2
5200
4221
104 9421

8
0
0

2
3
0
0
2
0
0
0
1
6
2
0
1
4
9
0
1
2
1
0
1
3
0
0
38

A discrepancy can be noted between the number of SSUs determined by the allocation step and
the one produced by the selection of PSUs. This is because the selection of PSUs controls that the
minimum number of SSUs to be allocated in each selected PSU is compliant with the minimum, in
our case equal to 50: if not, this minimum is assigned. This is why the total number of SSUs increases
from 8,320 to 9,421.

Selected PSUs are contained in the sample PSU element of the output list:

> head(sample_1st$sample_PSU)

PSU_ID STRATUM stratum SR nSR PSU_final_sample_unit Pik weight_1st weight_2st

1
2
3
4
5
6

330
309
51
11
40
13

1000
1000

1000-1
1000-2
10000 10000-0
10000 10000-1
10000 10000-2
10000 10000-3

1
1
1
1
1
1

0
0
0
0
0
0

207
72
171
96
79
72

1
1
1
1
1
1

1
1
1
1
1
1

With this input, we can proceed to select the sample of ﬁnal units:

> PSU_sampled <- sample_1st$sample_PSU
> samp <- select_SSU(df=pop,
+
+
+
+

PSU_code="municipality",
SSU_code="id_ind",
PSU_sampled,
verbose=TRUE)

PSU = 1 *** Selected SSU =
PSU = 4 *** Selected SSU =
PSU = 6 *** Selected SSU =
PSU = 8 *** Selected SSU =

50
72
50
557

17

weight
706.0966 706.0966
706.1806 706.1806
196.8480 196.8480
196.9688 196.9688
197.9494 197.9494
198.3750 198.3750

*** Selected SSU =
*** Selected SSU =

...
PSU = 510
PSU = 512
--------------------------------
Total PSU =
Total SSU =
--------------------------------

142
9421

50
50

The distribution of PSUs and SSUs in the diﬀerent strata is reported in Figure 4.1.3.

Figure 2: Allocation of PSUs and SSUs (scenario 1).

In Figure 3 the distribution of weights is reported.
It can be seen that the distribution of weights is variable at the national, regional and provincial
level, and only inside each stratum, the variability is low, as desired, except for those strata in which for
some PSUs the minimum number of SSUs (50) had to be attributed instead of the optimal allocation.

4.1.4 Step 4: verify compliance with precision constraints

The function eval 2stage] allows verifying the compliance of the two-stage sample design to the set
of precision constraints, by selecting a given number of diﬀerent samples (in our case, 500) from the
sampling frame, producing the estimates for each sample, and calculating over them the coeﬃcients of
variation for each target estimate.

We apply twice the function, ﬁrst for the national level:

> # Domain level = national
> domain_var <- "one"
> set.seed(1234)

18

Figure 3: Distribution of weights (scenario 1).

> eval11 <- eval_2stage(df,
+
+
+
+
+
+
+
+
> eval11$coeff_var

PSU_code,
SSU_code,
domain_var,
target_vars,
sample_1st$sample_PSU,
nsampl=500,
writeFiles=FALSE,
progress=FALSE)

CV1

dom
1 0.0101 0.0091 0.0241 0.0344 DOM1

CV4

CV3

CV2

then, at the regional level:

> # Domain level = regional
> domain_var <- "region"
> set.seed(1234)
> set.seed(1234)
> eval12 <- eval_2stage(df,
+
+
+
+
+

PSU_code,
SSU_code,
domain_var,
target_vars,
sample_1st$sample_PSU,

19

+
+
+
> eval12$coeff_var

nsampl=500,
writeFiles=FALSE,
progress=FALSE)

CV2

CV1

CV3

dom
1 0.0113 0.0066 0.0235 0.0754 DOM1
2 0.0224 0.0206 0.0495 0.0733 DOM2
3 0.0240 0.0282 0.0515 0.0413 DOM3

CV4

We recall that the precision constraints had been set equal to 2% for the ﬁrst variable, 3% for the
second and third, and 5% for the fourth, at national level; and respectively to 3% and 6% and 8% at
regional level. We can see that the computed CVs are all compliant.

4.2 Scenario 2 workﬂow

Together with the availability of a sampling frame, containing the same information presented in the
previous scenario, we assume also the availability of at least one previous round of the survey. For
sake of simplicity, we assume that the previous round sample is the same selected in scenario 1. We
assume also that the values of the four target variables are the observed ones after the data collection.
Having set the above conditions, the main diﬀerence with scenario 1 is that, instead of choosing in
a somewhat arbitrarily way the values of the inputs required by the optimal allocation step, we can
derive them directly from the collected survey data.

4.2.1 Step 1: processing and analysis of survey data

In this step, we proceed to perform the usual phases of calibration and production of the estimates.
In doing that, we make use of the R package ReGenesees.

First we describe the sample design:

> ## Sample design description
> sample$stratum_2 <- as.factor(sample$stratum_2)
> sample.des <- e.svydesign(sample,
+
+
+
+
+

ids= ~ municipality + id_hh,
strata = ~ stratum_2,
weights = ~ weight,
self.rep.str = ~ SR,
check.data = TRUE)

obtaining the sample.des object. Then we proceed with the calibration step:

calmodel = ~ sex : cl_age,
partition = ~ region)

> ## Calibration with known totals
> totals <- pop.template(sample.des,
+
+
> totals <- fill.template(pop, totals, mem.frac = 10)
> sample.cal <- e.calibrate(sample.des,
+
+
+
+
+
+
+

totals,
calmodel = ~ sex : cl_age,
partition = ~ region,
calfun = "logit",
bounds = c(0.3, 2.6),
aggregate.stage = 2,
force = FALSE)

obtaining the sample.cal object.
These two objects are what is needed to obtain, in an automated way, all the inputs required by

the optimization step.

20

4.2.2 Step 2: preparation of the inputs for the optimal sample design

The preparation of all the inputs required by the optimization step is a straightforward operation by
using the prepareInputToAllocation2 function:

> inp <- prepareInputToAllocation2(
+
+
+
+
+
+
+
+
+
+
+
+

# sampling frame
# ReGenesees design object
# ReGenesees calibrated object
# identification variable of PSUs
# identification variable of SSUs
# strata variables

samp_frame = pop,
RGdes = sample.des,
RGcal = sample.cal,
id_PSU = "municipality",
id_SSU = "id_hh",
strata_vars = "stratum",
target_vars = c("income_hh","active","inactive","unemployed"), # target variables
deff_vars = "stratum",
domain_vars "region",
delta 0 1,
minimum= 50

# deff variables
# domain variables
# Average number of SSUs for each selection unit
# Minimum number of SSUs to be selected in each PSU

)

The conﬁguration of the output is just the same already seen in scenario 1 for the function pre-

pareInputToAllocation1.

Here we report the content of the eﬀst dataframe:

stratum STRATUM

EFFST2

EFFST3

EFFST1

EFFST4
1000 1.061891 0.9511291 0.9071854 1.0137193
10000 1.005724 0.9077114 0.8991158 0.9780552
11000 1.005722 0.9309392 0.9240808 0.9998968
12000 1.026967 0.9241132 0.9117161 0.9911560
13000 1.006354 0.9244961 0.9085689 0.9977077
14000 1.002360 0.9348739 0.9237139 1.0065308

and of the rho dataframe:

STRATUM RHO_AR1

1 -0.00005314789
1 0.00021289157
1 0.01349102041
1 0.00409179592
1 0.00002020513
1 0.00009018499

RHO_NAR1 RHO_AR2
0.000004056338
1
0.000154688468
1
1 -0.004226612245
0.034025755102
1
1
0.000016396011
1 -0.000022736475

RHO_NAR2 RHO_AR3
1
1
1
1
1
1

1000
10000
11000
12000
13000
14000

1
2
3
4
5
6
...

1
2
3
4
5
6

1000
10000
11000
12000
13000
14000

RHO_NAR3 RHO_AR4

1 0.000007542254
2 0.000160791738
3 -0.007398367347
4 0.031294265306
5 0.000019209402
6 -0.000022157068
...

RHO_NAR4
1 0.00003425352
1 0.00002596213
1 0.00075012245
1 0.02008032653
1 0.00001038462
1 0.00007399651

in order to compare them with the scenario 1 ones.

4.2.3 Step 3: optimization of PSUs and SSUs allocation

The optimal allocation of PSUs and SSUs is the same as the one already seen in the ﬁrst scenario:

> set.seed(1234)
> inp2$des_file$MINIMUM <- 50
> alloc2 <- beat.2st(stratif = inp2$strata,

21

+
+
+
+
+
+
+
+

1
2
3
4

errors = cv,
des_file = inp2$des_file,
psu_file = inp2$psu_file,
rho = inp2$rho,
deft_start = NULL,
effst = inp2$effst,
minnumstrat = 2,
minPSUstrat = 2)

iterations PSU_SR PSU NSR PSU Total

0
1
2
3

0
71
38
38

0
92
108
108

SSU
0 9557
163 8464
146 8398
146 8396

4.2.4 Step 4: selection of PSUs and SSUs

The selection of ﬁrst and second stage units proceeds in exactly the same way than in the scenario 1,
ﬁrst selecting the PSUs, and then the SSUs.

> sample_1st <- select_PSU(alloc2, type="ALLOC", pps=TRUE)
> sample_1st$PSU_stats

SSU SSU_SR SSU_NSR
0
279
279
200
317
517
200
0
200
100
0
100
0
202
202
100
0
100
100
0
100
100
0
100
0
564
564
0
537
537
1100
200
22 1300
600
0
600
12
0
756
756
0
0
583
583
0
900
514
18 1414
1100
0
22 1100
0
114
114
100
0
100
300
0
300
200
0
200
0
113
113
100
0
100
100
0
100
100
0
100
5400
4179
108 9579

2
6
0
0
2
0
0
0
1
6
4
0
1
4
10
0
1
0
0
0
1
0
0
0
38

STRATUM PSU PSU_SR PSU_NSR
0
4
4
2
0
2
2
2
0
0

2
1000
10
2000
4
3000
2
4000
2
5000
2
6000
2
7000
2
8000
1
9000
6
10000
26
11000
12
12000
1
13000
4
14000
28
15000
22
16000
1
17000
2
18000
6
19000
4
20000
1
21000
2
22000
2
23000
24000
2
Total 146

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
>
> samp <- select_SSU(df=pop,
+
+
+
+

0
2
6
4
0
2
2
2

PSU_code="municipality",
SSU_code="id_ind",
PSU_sampled=sample_1st$sample_PSU,
verbose=TRUE)

PSU = 4 *** Selected SSU =
PSU = 8 *** Selected SSU =
PSU = 10 *** Selected SSU =

66
564
50

22

*** Selected SSU =
*** Selected SSU =

PSU = 11 *** Selected SSU =
...
PSU = 510
PSU = 512
--------------------------------
Total PSU =
Total SSU =
--------------------------------

146
9579

96

50
50

The distribution of PSUs and SSUs in the diﬀerent strata is reported in Figure 4.2.4. It can be
seen that the relative distribution of both units in the strata is quite similar to the one already seen
in scenario 1.

Figure 4: Allocation of PSUs and SSUs (scenario 2).

We can observe now the distribution of weights in the selected sample (see Figure 5). Also in this
case, their variability is lower inside the strata level, where it is almost null except in those strata in
which for some PSUs the minimum number of SSUs (50) had to be attributed, instead of the optimal
allocation.

4.2.5 Step 5: verify the compliance to precision constraints

As in the previous scenario, the ﬁnal check consists in verifying the compliance of the optimized design
to the precision constraints.

We, therefore, apply the function eval 2stage, ﬁrst for the national level:

> # Domain level = national
> domain_var <- "one"

23

Figure 5: Distribution of weights (scenario 2).

> eval <- eval_2stage(df,
+
+
+
+
+
+
> eval$coeff_var

PSU_code,
SSU_code,
domain_var,
target_vars,
PSU_sampled=sample_1st$sample_PSU,
nsampl=500)

CV1

dom
1 0.012 0.0094 0.025 0.0364 DOM1

CV4

CV3

CV2

then, at regional level:

> # Domain level = regional
> domain_var <- "region"
> eval <- eval_2stage(df,
+
+
+
+
+
+
> eval$coeff_var

PSU_code,
SSU_code,
domain_var,
target_vars,
PSU_sampled=sample_1st$sample_PSU,
nsampl=500)

CV1

dom
1 0.0105 0.0070 0.0246 0.0745 DOM1

CV3

CV4

CV2

24

2 0.0285 0.0206 0.0504 0.0748 DOM2
3 0.0291 0.0335 0.0597 0.0444 DOM3

Also in this case, no precision constraint is violated.

5 Comparison with other softwares

To evaluate the performance of R2BEAT, in this section we compare it to other two R packages, i.e.:

1. the package PracTools (Valliant et al., 2020) implements many of the procedures described in

Valliant et al. (2015), including those regarding the design of multistage samples;

2. the package samplesize4surveys (Rojas, 2020) allows to calculate the sample size for complex

surveys.

First, we brieﬂy illustrate, for both packages, the functions covering the two-stage sampling design,

then we apply them to the same case seen in scenario 1, ﬁnally comparing the obtained results 2.

5.1 R package PracTools

Valliant et al. (2015) describe (pages 231-234) a method for the optimal allocation of two-stage sampling
when numbers of sample PSUs and elements per PSU are adjustable (which is our case).

This method is implemented in the R function clusOpt2 in the PracTools package. This function
computes the number of PSUs and the number of ﬁnal units for each PSU for a two-stage sample which
uses srs at each stage or probability proportional to size with replacement (ppswr ) at the ﬁrst stage
and srs at the second.

This function requires the indication of a number of parameters, among which:

• C1: unit cost per PSU

• C2: unit cost per SSU

• delta: homogeneity measure

• unit.rv: unit relvariance

• k: ratio of B2+W2 to unit relvariance

• CV0: target CV

• tot.cost: total budget for variable costs

• cal.sw: indicates if the optimization has to be run for a ﬁxed total budget, or the for target CV0

The function BW2stagePPS computes the population values of B2, W2, and delta whose meaning

is explained in Valliant et al. (2015) (page 222).

The method is univariate: the optimization can be performed by indicating only one variable. The

whole code required for the case described in scenario 1 is given here:

> load("pop.RData")
> library(PracTools)
> # Probabilities of inclusion (I stage)
> pp <- as.numeric(table(pop$municipality))/nrow(pop)
> # variable income_hh
> bw <- BW2stagePPS(pop$income_hh, pp, psuID=pop$municipality)
> bw

W2 unit relvar
0.04075893 0.79538674 0.83601766

B2

B2+W2
0.83614567

k
1.00015312

delta
0.04874621

2In order to reproduce the processing related to the evaluation of the diﬀerent softwares, datasets and R scripts are

downloadable from the link https://github.com/barcaroli/Two-stage-sampling-software-comparison

25

C2=1,
delta=bw[6],
unit.rv=bw[3],
k=bw[5],
CV0=0.02,
tot.cost=NULL,
cal.sw=2)

> des <- clusOpt2(C1=130,
+
+
+
+
+
+
+
> des
C1 = 130
C2 = 1
delta = 0.04874621
unit relvar = 0.8360177
k = 1.000153
cost = 25499.72
m.opt = 141.4
n.opt = 50.4
CV = 0.02
> sample_size <- des$m.opt*des$n.opt
> sample_size
7126.56

In running the function, we have indicated that the optimization step was to be carried out having
a target CV of 2% for the variable income hh. As there is no way to directly indicate a desired
minimum number of SSUs per PSU, we managed to obtain the desired value of 50 by indicating a
couple of values 130 and 1 respectively for C1 and C2. As a result, the number of PSUs is 141 and
the number of SSUs is 7,127.

5.2 R package samplesize4surveys

This package oﬀers two functions to compute a grid of possible sample sizes for estimating single means
(ss2s4m) or single proportions (ss2s4p) under two-stage sampling designs.

The required parameters are the following:

• N: the population size

• mu: the value of the estimated mean of a variable of interest

• sigma: the value of the estimated standard deviation of a variable of interest

• conf: the statistical conﬁdence

• delta: the maximum relative margin of error that can be allowed for the estimation

• M: number of clusters in the population

• to: (integer) maximum number of ﬁnal units to be selected per cluster

• rho: the intraclass correlation coeﬃcient

Here is the code we used in the case of the target variable income hh:

> load("pop.RData")
> PSU <- length(unique(pop$municipality))
> pop_strata <- as.numeric(table(pop$stratum))
> rho <- 0.04875369 # value taken from scenario 1 analysis
> ss2s4m(N = nrow(pop),
+
+
+

mu = mean(pop$income_hh),
sigma = sd(pop$income_hh),
delta = 0.02 * 1.96,

26

+
+
+
50 3.388931 142 50 7061

M = PSU,
to = 50,
rho = sum(rho$RHO_NAR1*pop_strata) / sum(pop_strata))

we obtain a design characterized by a total sample size of 7,061, with 142 PSUs.
Concerning the way we indicated the value of the parameter rho, we made use of the value of the
intra-class correlation coeﬃcient computed in scenario 1 by R2BEAT, not considering domains and
strata.

In order to compare the 2% precision constrain expressed in terms of coeﬃcient of variation, as the
package requires the margin of error, we multiply the value of the CV by a z-value equal to 1.96, to
obtain the ratio between the semi-width of the conﬁdence interval and the estimate of the mean of the
parameter.

The use of the function ss2s4p, applicable for the other three variables, is practically the same.

5.3 Comparison of results

As already said, we refer to the scenario 1 setting.

We consider the same precision levels for the four variables for the unique domain, set equals

respectively to 2%, 3%, 3% and 5%.

We apply another constraint for all the three softwares, that is, we want to select a minimum

number of ﬁnal units in each PSU, set equal to 50.

There is no problem in doing that for package samplesize4surveys, by setting the parameter
to equal to 50: the last value of the ﬁnal grid is the result we want. Moreover, there is no loss in
the optimality of the solution in doing that, because the sample sizes obtained for further values are
increasingly higher.

As for PractTools, it is more complicated because, as already said, there is no direct way to set
this constraint. In any case, we manage to do that, by varying the value of C1 (leaving C2 equal to 1)
until we ﬁnd the solution with the nearest value of n.opt to 50.

A ﬁnal consideration regarding the application of R2BEAT: in this setting, to be comparable with
the other packages (that are univariate and mono-domain), it has been applied in a simpliﬁed way,
that is, one variable per time (univariate), and no diﬀerent domains and strata in the sampling frame.
By so doing, R2BEAT yields obviously diﬀerent results from those seen in scenario 1.

Table 1: Two-stage sample design obtained by diﬀerent packages.
samplesize4surveys

PracTools

R2BEAT

Variable
active
inactive
income hh
unemployed

PSUs
49
90
141
406

SSUs PSUs
2459
4395
7127
19956

37
68
79
149

SSUs PSUs
2030
4338
5140
10884

49
88
142
402

SSUs
2436
4391
7061
20058

In Table 1 and in Figure 6 are reported the results obtained by the three packages. To be sure of
the results of R2BEAT, simulations have been carried out, and the resulting CVs are always below
the precision threshold.

Analyzing the table, it is evident that R2BEAT is always the best performer, in terms of sample

size, considering both numbers of PSUs and SSUs.

6 Concluding remarks

Concluding, we would like to focus on the main strength of the R2BEAT, which could be considered
its completeness, regarding all the phases of the statistical data production process. The package deals
with the design, stratiﬁcation, allocation among strata and, ﬁnally, the selection of sample units.

Furthermore, the facilities provided by R2BEAT are extremely ﬂexible and generalizable: for in-
stance, R2BEAT is the ﬁrst R package on repositories to provide the optimal allocation, both for
one-stage and two-stage sampling designs. These features make the package particularly helpful and

27

Figure 6: Sample sizes by packages.

valuable both for NSIs and private statistical institutions, such as marketing researchers, universities
or national government organizations.

Moreover, those who deal with statistics often have a large data availability, coming from registers,
previous surveys or other data sources: the package, requiring auxiliary variables for designing and
allocating the sample, makes this auxiliary information useful and proﬁtable during the sampling
planning process.

The output provided to users has been thought to be as clear as possible and to help them to carry
out analysis and checks on the obtained allocations and on the sample on which the survey will be
based.

Last, but not least, R2BEAT can be considered more eﬃcient than the other available software and
packages which deal with sample design: in fact, on equal errors, the sample size allocated is lower,
both in terms of Primary and Secondary Stage Units (PSUs and SSUs.

References

Baillargeon, S. and L.-P. Rivest (2011). The construction of stratiﬁed designs in r with the package

stratiﬁcation. Survey Methodology 37 (1), 53–65.

28

Ballin, M. and G. Barcaroli (2013). Joint determination of optimal stratiﬁcation and sample allocation

using genetic algorithm. Survey Methodology 39 (2), 369–393.

Barcaroli, G. (2014). Samplingstrata: An r package for the optimization of stratiﬁed sampling. Journal

of Statistical Software 61 (4), 1–24.

Barcaroli, G., T. Buglielli, and C. D. Vitiis (2020). MAUSS-R: Multivariate Allocation of Units in

Sampling Surveys. R package version 2.4.

Bethel, J. W. (1985). An optimum allocation algorithm for multivariate surveys. In Proceedings of the

Social Statistics Section, ASA, pp. 209–212.

Bethel, J. W. (1989). Sample allocation in multivariate surveys. Survey methodology 15 (1), 47–57.

Biemer, P. P. (2010). Total survey error: Design, implementation, and evaluation. Public Opinion

Quarterly 74 (5), 817–848.

Biemer, P. P. and L. E. Lyberg (2003). Introduction to survey quality, Volume 335. John Wiley &

Sons.

Breidaks, J., M. Liberts, and J. Jukams (2020). surveyplanning: Survey planning tools. Riga, Latvia.

R package version 4.0.

Bueno, E. (2020). optimStrat: Choosing the Sample Strategy. R package version 2.3.

Chatterjee, S. (1968). Multivariate stratiﬁed surveys. Journal of the American Statistical Associa-

tion 63 (322), 530–534.

Chatterjee, S. (1972). A study of optimum allocation in multivariate stratiﬁed surveys. Scandinavian

Actuarial Journal 1972 (1), 73–80.

Choudhry, G. H., J. Rao, and M. A. Hidiroglou (2012). On sample allocation for eﬃcient domain

estimation. Survey methodology 38 (1), 23–29.

Chromy, J. R. (1987). Design optimization with multiple objectives. Proceedings of the Section on

Survey Research Methods, 1987 .

Cicchitelli, G., A. Herzel, and G. E. Montanari (1992).

Il campionamento statistico. Bologna: Il

mulino.

Cochran, W. G. (1977). Sampling techniques. John Wiley & Sons.

Conti, P. L. and D. Marella (2012). Campionamento da popolazioni ﬁnite: Il disegno campionario.

Springer Science & Business Media.

Dalenius, T. (1953). The multi-variate sampling problem. Scandinavian Actuarial Journal 1953 (sup1),

92–102.

Dalenius, T. (1957). Sampling in Sweden: contributions to the methods and theories of sample survey

practice. Almqvist & Wiksell.

Devaud, D. and Y. Till´e (2019). Deville and s¨arndal’s calibration: revisiting a 25-years-old successful

optimization problem. TEST 28 (4), 1033–1065.

Deville, J.-C. and C.-E. S¨arndal (1992). Calibration estimators in survey sampling. Journal of the

American statistical Association 87 (418), 376–382.

Falorsi, P. D., M. Ballin, C. De Vitiis, and G. Scepi (1998). Principi e metodi del software generalizzato
per la deﬁnizione del disegno di campionamento nelle indagini sulle imprese condotte dall’istat.
Statistica Applicata 10 (2), 235–257.

Folks, J. L. and C. E. Antle (1965). Optimum allocation of sampling units to strata when there are r

responses of interest. Journal of the American Statistical Association 60 (309), 225–233.

29

Gonzalez, J. M. and J. L. Eltinge (2010). Optimal survey design: A review. Section on Survey Research

Methods - JSM . (Accessed on 15 March 2021).

Hartley, H. (1965). Multiple purpose optimum allocation in stratiﬁed sampling. In Proceedings of the

Social Statistics Section, ASA, pp. 258–261.

Horvitz, D. G. and D. J. Thompson (1952). A generalization of sampling without replacement from a

ﬁnite universe. Journal of the American statistical Association 47 (260), 663–685.

Huddleston, H., P. Claypool, and R. Hocking (1970). Optimal sample allocation to strata using convex
programming. Journal of the Royal Statistical Society: Series C (Applied Statistics) 19 (3), 273–278.

Kish, L. (1965). Survey sampling. New York: John Wiley & Sons, Inc.

Kish, L. (1976). Optima and proxima in linear sample designs. Journal of the Royal Statistical Society:

Series A (General) 139 (1), 80–95.

Kish, L. (1988). Multipurpose sample designs. Survey Methodology 14 (1), 19–32.

Kokan, A. (1963). Optimum allocation in multivariate surveys. Journal of the Royal Statistical Society:

Series A (General) 126 (4), 557–565.

Kokan, A. and S. Khan (1967). Optimum allocation in multivariate surveys: An analytical solution.

Journal of the Royal Statistical Society: Series B (Methodological) 29 (1), 115–125.

Kozak, M., M. R. Verma, and A. Zielinski (2007). Modern approach to optimum stratiﬁcation: Review

and perspectives. Statistics in Transition 8 (2), 223–250.

Kozak, M., A. Zieli´nski, and S. Singh (2008). Stratiﬁed two-stage sampling in domains: Sample
allocation between domains, strata, and sampling stages. Statistics & probability letters 78 (8),
970–974.

Neyman, J. (1934). On the two diﬀerent aspects of the representative method: the method of stratiﬁed
sampling and the method of purposive selection. Journal of the Royal Statistical Society 97 (4), 558–
625.

Rojas, H. A. G. (2016). Estrategias de muestreo: dise˜no de encuestas y estimaci´on de par´ametros.

Ediciones de la U.

Rojas, H. A. G. (2020). samplesize4surveys: Sample Size Calculations for Complex Surveys. R package

version 4.1.1.

S¨arndal, C.-E. (2007). The calibration approach in survey theory and practice. Survey methodol-

ogy 33 (2), 99–119.

S¨arndal, C.-E., B. Swensson, and J. Wretman (2003). Model assisted survey sampling. Springer Science

& Business Media.

Stokes, L. and J. Plummer (2004). Using spreadsheet solvers in sample design. Computational statistics

& data analysis 44 (3), 527–546.

Till´e, Y. and A. Matei (2021). sampling: Survey Sampling. R package version 2.9.

Till´e, Y. (2020). Sampling and estimation from ﬁnite populations. John Wiley & Sons.

Tschprow, A. (1923). On the two diﬀerent aspects of the representative method: the method of
stratiﬁed son the mathematical expectation of the moments of frequency distributions in the case of
correlated observationsampling and the method of purposive selection. Metron 2, 646–683.

Valliant, R., J. A. Dever, and F. Kreute (2015). Practical Tools for Designing and Weighting Survey

Samples. Springer.

Valliant, R., J. A. Dever, and F. Kreuter (2020). PracTools: Tools for Designing and Weighting Survey

Samples. R package version 1.2.2.

30

Waters, J. R. and A. J. Chester (1987). Optimal allocation in multivariate, two-stage sampling designs.

The American Statistician 41 (1), 46–50.

Yates, F. (1960). Sampling methods for censuses and surveys , charles griﬃn and co. Ltd., London.

Zardetto, D. (2015). Regenesees: An advanced r system for calibration, estimation and sampling error

assessment in complex sample surveys. Journal of Oﬃcial Statistics 31 (2), 177–203.

31

