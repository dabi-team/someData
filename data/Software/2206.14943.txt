Weighted ensemble: Recent mathematical developments

Weighted ensemble: Recent mathematical developments

D. Aristoﬀ,1 J. Copperman,2 G. Simpson,3 R. J. Webber,4 and D. M. Zuckerman2
1)Mathematics, Colorado State University
2)Biomedical Engineering, Oregon Health Sciences University
3)Mathematics, Drexel University
4)Computing & Mathematical Sciences, California Institute of Technology

The weighted ensemble (WE) method, an enhanced sampling approach based on periodically replicating and pruning
trajectories in a set of parallel simulations, has grown increasingly popular for computational biochemistry problems,
due in part to improved hardware and the availability of modern software. Algorithmic and analytical improvements
have also played an important role, and progress has accelerated in recent years. Here, we discuss and elaborate
on the WE method from a mathematical perspective, highlighting recent results which have begun to yield greater
computational efﬁciency. Notable among these innovations are variance reduction approaches that optimize trajectory
management for systems of arbitrary dimensionality.

I.

INTRODUCTION

Weighted ensemble (WE)1

is an enhanced sampling
method employing multiple trajectories of a stochastic dy-
namics to estimate mean ﬁrst passage times (MFPTs) and re-
lated statistics. WE can be applied to any stochastic dynamics
model2, such as Langevin dynamics in a molecular system1
or continuous-time jump dynamics in a reaction network3.
In biomolecular systems, WE has enabled estimation of MF-
PTs that are orders of magnitude larger than the combined
lengths of the individual WE trajectories.4–7 WE has also re-
cently been used to elucidate the spike opening dynamics in
the SARS CoV-2 virus.8

WE is based on splitting and merging, as shown in Fig-
ure 1. During splitting, “favorable” or “interesting” trajec-
tories, according to a user deﬁnition, are replicated. During
merging, the “less favorable” or “redundant” trajectories are
randomly eliminated from the ensemble. Trajectories are then
re-weighted to preserve the statistics of the path ensemble.2

The ﬁrst splitting and merging algorithm was reported in
In 1996, Hu-

the 1950s and attributed to von Neumann9.

FIG. 1. An illustration of splitting and merging of weighted trajec-
tories. Weights are represented by the widths of trajectories. Two
splitting and merging steps are shown, in which the top trajectory is
split and the bottom trajectories are merged. Trajectory weights are
combined with merging and divided with splitting.

ber and Kim1 modiﬁed von Neumann’s original approach by
grouping the trajectories into bins and applying splitting and
merging in each of the bins separately, thus preserving the bin
weights. It was recently shown that WE with ﬁxed bin weights
leads to convergent estimates10,11; in contrast, von Neumann’s
original method can be unstable in the large time limit10,11.

Attention to WE has grown, and the method is now im-
plemented in the widely used WESTPA software package12,13
and the more recent wepy package14. A Julia language pack-
age, used here, is also available,15. Meanwhile, a growing
community of researchers is promoting the method and de-
veloping it in different directions4,5,16–22.

In modern biochemical applications, WE is often used to
estimate the MFPT for a stochastic dynamics to transition
from a source state A into a target state B23. In addition, WE
has been used to estimate other transition path statistics, in-
cluding the distribution of reaction times from A to B4,5, the
distribution of entry points into B16,24, and the characteristics
of paths leading from A to B4,17. Here, we focus on the esti-
mation of MFPTs, which is a signiﬁcant and challenging ap-
plication because the inverse of the MFPT is the reaction rate
constant25.

Other computational

techniques for estimating MFPTs
include Markov state models26, forward ﬂux sampling27,
adaptive multilevel splitting28, exact milestoning29,30, non-
equilibrium umbrella sampling31, and transition interface
sampling32. Like WE, these approaches use large numbers of
short, unbiased trajectories to compute the MFPT. However,
the following combination of features makes WE especially
attractive:

• WE only requires simulation of the stochastic model
forward in time, never backward. Thus, WE can be ap-
plied to a wide variety of stochastic models arising in
chemistry1,3 and in other areas, e.g., astronomy33, cli-
mate science34,35, and systems biology3,36.

• WE is fully parallelizable over time intervals of length τ
between splitting/merging events12,13,37. Since the tra-
jectories are simulated for the same time interval, the
parallellization can be managed simply and efﬁciently.

• WE provides asymptotically unbiased, convergent esti-
mates in the limit of many time steps for any choice of
parameters2,10,11.

2
2
0
2

n
u
J

9
2

]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[

1
v
3
4
9
4
1
.
6
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Weighted ensemble: Recent mathematical developments

2

• WE has been observed to provide better MFPT esti-
mates than estimates from Markov state models38 or
non-equilibrium umbrella sampling39.

II. MEAN FIRST PASSAGE TIMES AND THE HILL
RELATION

Despite progress over the last three decades, theoretical
questions about WE have remained unanswered until re-
cently. WE performance is highly dependent on the choice
of parameters4, including the deﬁnition of the bins and the de-
sired number of trajectories in each bin. For a long time it was
unclear what the optimal parameter choices would be.

Recent work in the mathematical literature sheds new light
on the optimal parameter choices for WE10,11,40,41. The opti-
mal merging coordinate is the local MFPT to B given the cur-
rent state. The optimal splitting coordinate is the local vari-
ance of the MFPT to B, given the current state and the time
interval τ. There is a theoretical limit on the variance reduc-
tion achievable through WE, and bins based on the optimal
merging and splitting coordinates ensure the optimal variance
in the limit of many trajectories and many time steps.

In this article, we aim to communicate these recent mathe-
matical advances in a brief, accessible way. We identify the
optimal splitting and merging coordinates in one- and two-
dimensional examples. We propose optimized bins based on
these coordinates, which differ from the more traditional bins
based on the root mean square displacement (RMSD) to B.
Our examples show that binning based on the RMSD can give
catastrophically wrong results. In such cases, more effective
bins are needed, and optimization based on reaction coordi-
nates is helpful.

The rest of the article is organized as follows. Section II
discusses the computation of mean ﬁrst passage times, which
is a major problem addressed by WE; Section III introduces
the WE method; Section IV identiﬁes the optimal merging and
splitting coordinates for WE; Section V recommends variance
reduction strategies for WE; and Section VI concludes.

TABLE I. Deﬁnitions of symbols used in this work.

Symbol Deﬁnition

Xt
β
U
τ
A
B
ρA
TB
Nt
q
J
π
(cid:104)(cid:105)
h
v2
ˆJt
˜π, ˜h, ˜v

underlying Markovian dynamics
inverse thermal energy (1/kBT )
potential energy
evolution time interval or lag time
initial (source) set
target (sink) set
initial (source) distribution inside A
ﬁrst passage time to B
number of arrivals in B by time t
committor function from A to B
steady-state ﬂux into B
steady state of source-sink dynamics
mean or average for source-sink dynamics
(ﬂux) discrepancy function
(ﬂux) variance function
WE estimate of steady-state ﬂux up to time t
τ → 0 limits of π, h, v2

We will study the MFPT of a Markovian stochastic dynam-
ics Xt from a source state A to a sink state B. In the biochem-
istry context, Xt could represent stochastic molecular dynam-
ics such as Langevin dynamics or constant-energy dynamics
generated with a stochastic thermostat. The MFPT could cor-
respond to the characteristic time for folding, binding, or con-
formational change of a simulated protein.

To deﬁne the MFPT precisely, we must specify the distri-
bution of starting points ρA within the the source state A. Dif-
ferent choices of ρA will lead to different MFPTs, even if A
remains the same. The distribution ρA fully determines the
MFPT, which is deﬁned as the averaged length of the trajec-
tories initiated from the source distribution ρA and absorbed
upon reaching B.

When computing the MFPT, we “recycle” Xt according to
the source distribution ρA upon arrival at the sink state B. This
means that the location immediately changes from B to A, but
the time index t continues to increase as usual. We assume
that the distribution of trajectories for this source-sink recy-
cling dynamics converges as t → ∞ to a unique steady-state
distribution, denoted by π.

Under these recycling boundary condition, the Hill rela-
tion42 expresses the MFPT as the inverse of the steady-state
ﬂux J of Xt into B. To state this more precisely, write TB for
the ﬁrst passage time to B, and Nt for the number of arrivals
of Xt in B by time t. The Hill relation then states:

(cid:104)TB(cid:105)A = MFPT of Xt from A to B

= 1/J = (steady-state ﬂux into B)−1

=

(cid:18) d
dt

(cid:19)−1

(cid:104)Nt (cid:105)π

.

(1)

(2)

(3)

Here and elsewhere, we use subscripts to indicate the starting
distribution for the dynamics Xt . Thus, (cid:104)TB(cid:105)A indicates the
mean ﬁrst passage time when X0 is started from ρA, and (cid:104)Nt (cid:105)π
indicates the mean number of arrivals when X0 is started from
π. Equation (2) holds for any t ≥ 0, since π is the steady state.
The application of the Hill relation transforms the compu-
tation of a long expected time (the MFPT) into a computation
of a small rate (the steady state ﬂux into B). This transfor-
mation makes it possible, in principle, to compute the MFPT
using trajectories with lengths much shorter than the MFPT.
Moreover, these short trajectories can be run in parallel to re-
duce the wall-clock time. Yet, a large number of trajectories
are required since the ﬂux can be very small.

Fortunately the Hill relation can be combined with en-
hanced sampling approaches like WE to help accurately es-
timate the small ﬂux into B. It is necessary that the trajecto-
ries approximate the steady-state distribution π, but this can
frequently be attained, because the timescale for relaxation to
steady state can be much shorter than the MFPT in problems
of interest43.

Figure 2 shows a simple system in which the steady-state
ﬂux from A into B is small. Like many of the examples to fol-
low, the data in the ﬁgure comes from overdamped Langevin

Weighted ensemble: Recent mathematical developments

3

FIG. 2. A ﬁrst passage event out of a local minimum of U. After
a long waiting period, the ﬁrst entry into the set B = {x > 1} occurs
at time TB. The dynamics satisﬁes Smoluchowski dynamics (4) with
βU(x) = 5(x − 1)2(x + 1)2 and D = 1/5 (inverse time units).

(“Brownian”) dynamics

dXt =

(cid:105)
(cid:104)
∇D(Xt ) − β D(Xt )∇U(Xt )

dt +(cid:112)

2D(Xt ) dWt

(4)

associated with the Smoluchowski equation

∂t p(x,t) = ∇ ·

β ∇U(x)p(x,t) + ∇p(x,t)

(5)

(cid:104)
D(x)

(cid:16)

(cid:17)(cid:105)
.

Here, β > 0 is an inverse temperature constant, U : Rn → R
is a scalar potential, D : Rn → R is a diffusion coefﬁcient, W
is a standard Brownian motion, and p(x,t) is the probability
density at location x at time t. For simplicity, we assume a
dimensionless conﬁgurational coordinate x, which results in a
diffusion coefﬁcient D exhibiting units of inverse time.

For exposition, many of our examples are in one or two spa-
tial dimensions. We emphasize, however, that the WE method
and the core mathematical analysis here apply to any Marko-
vian stochastic dynamics in any spatial dimension.

The continuous-time Smoluchowski equation needs to be
discretized for numerical simulation. Therefore, we assume
that Xt is evolved as a discrete time series X0, Xτ , X2τ , . . ., and
Xt is only recycled when it occupies state B at a multiple
of the time interval τ. The difference between discrete- and
continuous-time ﬂux into B will be small if τ is small or the
trajectories in B are very slow to escape. We reserve variables
t and τ for the “physical time”, i.e., the time index for the
original dynamics Xt .

III. WEIGHTED ENSEMBLE: SPLITTING AND MERGING

An example of WE evolution and resampling. Pictured
FIG. 3.
are 6 WE trajectories, which undergo evolution, resampling, and an-
other round of evolution. The bins are based on the coordinate x1.
During evolution steps, the trajectories travel between bins, and the
resampling enforces 2 copies in each bin. Circles indicate trajec-
tories that are continued and possibly replicated during resampling;
crosses indicate trajectories that are pruned during resampling. Tra-
jectory weight is represented by line width.

1. Initialization. Select starting points for N trajectories.
Assign a weight to each trajectory so that the weights
sum to one.

2. Resampling. Partition the N trajectories into bins, and
select the desired number of copies for each bin, called
the allocation. The bins are simply groupings of the tra-
jectories, and they may change in time. The allocations
are positive integers which may change with time but
are assumed to always sum to N.

Next, resample trajectories within each bin with proba-
bilities proportional to the weights, and divide the total
weight in each bin evenly among the resampled trajec-
tories10.

3. Dynamics. Evolve the trajectories independently for

time τ according to the underlying dynamics.

4. Convergence. Repeat steps 2-3 as long as desired or
possible. Estimate the steady-state ﬂux J using the av-
erage WE probability ﬂux entering B from the burn-in
time t0 to the ﬁnal time t. That is,

ˆJt =

Total WE weight entering B
t − t0

,

(6)

where t − t0 is the physical time of simulations follow-
ing the burn-in. The estimate for J in turn yields a
MFPT estimate via the Hill relation (2).

Throughout this article we consider a simple version of WE
in which the splitting and merging of trajectories are reformu-
lated as resampling2,10,11,41. For a more general discussion of
WE, see the review23. The simple WE algorithm is described
below and illustrated in Figure 3.

The crucial step in WE is the resampling step, which leads
to the splitting and merging of trajectories. Splitting is the
dynamics of replicating trajectories that are “valuable,” while
merging is the act of combining trajectories that are “similar.”

Weighted ensemble: Recent mathematical developments

4

Splitting improves the accuracy of the ﬂux estimates, espe-
cially when the duplicated trajectories are expected to make
large contributions to the future ﬂux. With repeated splitting,
merging is needed to limit the number of trajectories.

Although splitting and merging are traditionally applied
separately, in the simple WE algorithm above these steps are
combined via resampling2.
In each bin, trajectories are re-
sampled with probabilities proportional to their weights, with
the resampled trajectories each receiving an equal proportion
of the bin weight. Resampling is easier to formulate and im-
plement than the traditional splitting and merging. Moreover,
resampling is optimal when trajectories within a given bin are,
except for their weights, indistinguishable37.

Splitting and merging must be balanced, and a main con-
tribution of our recent work10,11,40,41 has been identifying the
regions of state space in which splitting or merging should
be promoted. Identifying such regions naturally leads to vari-
ance reduction strategies. We discuss these developments in
Sections IV and V.

Given sufﬁcient resources, the WE method terminates when
the estimated ﬂux converges to a near-constant value. How-
ever, if steady state cannot be reached during the available
simulation time, enhanced methods for WE initialization are
needed. For example, incorporating an appropriate burn-in
time t0 > 0 can reduce transient relaxation effects44, and ad-
justing the initial weights can also improve convergence45.

WE can be used to estimate other transition path statistics
in addition to the steady-state ﬂux. For instance, the WE-
generated paths and the associated weights can be used to
estimate the distribution of reaction times (i.e., event dura-
tions) and the distribution of mechanistic pathways4. See Ap-
pendix 1 for a discussion.

IV. OPTIMAL SPLITTING AND MERGING
COORDINATES

Recent mathematical analysis has revealed the existence
of optimal reaction coordinates for merging and splitting in
WE10,11,41. Sections IV A and IV B provide general formu-
las for these optimal reaction coordinates that assume no
particular type of dynamics or dimensionality, while Section
IV C provides more explicit formulas that hold for the Smolu-
chowski dynamics.

A. Optimal merging and splitting coordinates

Optimal merging. Merging trajectories, i.e., pruning some
members of a chosen set, is least harmful and most beneﬁcial
when the groups of trajectories to be merged are in some sense
“similar.” For the MFPT problem, the scalar reaction coordi-
nate that characterizes this similarity is the ﬂux discrepancy
function41

h(x) = lim
t→∞

[(cid:104)Nt (cid:105)x − (cid:104)Nt (cid:105)π ] .

(7)

Nt counts the total number of crossings into B at times s =
τ, 2τ, . . . ,t. Thus, h(x) is the difference in expected future

ﬂux between trajectories started at the particular point x and
trajectories started from the steady-state distribution π. Since
trajectories with similar h values make similar expected con-
tributions to the ﬂux estimate, merging trajectories with simi-
lar h values is appropriate10,41.

Using the Hill relation, the ﬂux discrepancy function can be
rewritten in terms of MFPTs initiated from different starting
distributions. As shown in Appendix 2,

h(x) =

(cid:104)TB(cid:105)π − (cid:104)TB(cid:105)x
(cid:104)TB(cid:105)A

,

(8)

where we recall TB is the ﬁrst passage time into B excluding
time t = 0. Equation (8) allows us to reinterpret the optimal
merging function as a normalized difference between the local
MFPT to B starting from x and the MFPT for trajectories initi-
ated from the steady state π. Identity (8) holds independently
of both the dimension and the type of Markovian dynamics. It
shows that the ﬂux discrepancy function and the local MFPT
are equivalent optimal coordinates for merging.

Optimal splitting. Splitting – the duplication of certain
WE trajectories – increases local sampling and is of high ben-
eﬁt in regions that are important for the ﬂux computation. We
now introduce the scalar reaction coordinate that describes op-
timal splitting behavior, the ﬂux variance function41

v(x)2 = τ −1Varx

(cid:2)h0(Xτ )(cid:3),

(9)

where h0 is a version of the discrepancy function that counts
ﬂux at time t = 0, i.e., h0(x) = 1B(x) + h(x), and Varx denotes
variance for the source-sink dynamics started at x. The ﬂux
variance function quantiﬁes the variation in the expected ﬂux
over a time interval τ for trajectories initiated at x.

As a heuristic strategy, a favorable allocation should sat-

isfy10,40,41

# trajectories near x ∝ π(x)v(x).

(10)

Allocating in this way minimizes the future contribution to the
ﬂux variance, assuming that WE is in steady state10,40,41. We
refer to this as the optimal allocation distribution and provide
an intuitive derivation in Appendix 3.

As a more rigorous mathematical result, the following es-
tablishes the optimality of h and v as WE reaction coordinates.
If the recycled dynamics Xt is geometrically

Theorem11.

ergodic, then the WE method satisﬁes the following:

1. For any choice of bins and allocations, the WE ﬂux es-
timate ˆJt given in (6) converges with probability one to
the inverse MFPT,

ˆJt =

lim
t→∞

1
(cid:104)TB(cid:105)A

.

(11)

2. For any ε > 0 and any choice of bins and allocations,

the WE variance satisﬁes

Var ˆJt ≥

(cid:16)(cid:90)

1 − ε
Nt

v(x)π(x) dx

(cid:17)2

(12)

when t is sufﬁciently large.

Weighted ensemble: Recent mathematical developments

5

3. For any ε > 0, if the bins are sufﬁciently small rectan-
gles in h and v coordinates and if the allocation for each
bin is proportional to (cid:82)
bin v(x)π(x) dx, the WE variance
satisﬁes

Var ˆJt ≤

(cid:16)(cid:90)

1 + ε
Nt

v(x)π(x) dx

(cid:17)2

(13)

for sufﬁciently large t and N.

The theorem holds regardless of dimension, temperature,
time τ, and type of Markovian dynamics.
It highlights the
following WE strategy that is optimal in the limit of large N
and t:
trajectories with similar h and v values are merged,
while splitting enforces Const × π(x)v(x) trajectories near x.
The theorem supports the interpretation (10) of π(x)v(x) as
the optimal distribution for trajectory allocation.

B. Maximum gain of WE over direct dynamics

The above mathematical theory enables a quantitative com-
parison between WE and direct Monte Carlo sampling of ﬁrst-
passage events. Here, we deﬁne direct Monte Carlo as inde-
pendent trajectories without any splitting or merging.

Assuming that trajectories are started from the steady state
π, the direct Monte Carlo variance with N trajectories can be
written11

(cid:90)

1
Nt

v(x)2π(x) dx .

(14)

This formula reveals that the ﬂux variance function v2 is in-
trinsic to direct Monte Carlo dynamics as well as WE dynam-
ics, since v2 quantiﬁes the variance in the ﬂux estimates as
trajectories are evolved forward over a time interval τ. Divid-
ing (14) by (13), the ratio of direct Monte Carlo variance to
optimal WE variance is then11

Optimal gain over direct Monte Carlo

=

(cid:82) v2(x)π(x) dx
((cid:82) v(x)π(x) dx)2 .

(15)

This ratio quantiﬁes the maximal possible variance reduction
achievable by WE in the large time limit, for any number of
trajectories.

The optimal gain over direct Monte Carlo has important
implications. Analytical and numerical investigation of this
quantity can yield insight into how much beneﬁt is possible
from using WE. Additionally, knowing the optimal gain over
direct Monte Carlo as a reference enables quantitative com-
parisons of different WE binning strategies against the theo-
retically optimal performance.

C. Optimal WE for one-dimensional Smoluchowski dynamics

To make the preceding theory more explicit, we consider
Smoluchowski (overdamped Langevin) dynamics in a one-
dimensional setting with a source state A = {x ≤ a} and a

FIG. 4. The steady state of the source-sink dynamics. Plotted is the
steady state ˜π of the Smoluchowski dynamics with recycling from B
to A, a diffusion coefﬁcient D = 1, and β = 4. In this and subsequent
ﬁgures, U(x) = 5(x − 1)2x2(x + 1)2 + 0.5x2 − 0.2x.

sink state B = {x ≥ b}, where a < b. The recycling distribu-
tion is a delta function at the edge a of A, i.e., ρA = δ (x − a).
We consider the continuous-time limit, τ → 0, which leads to
simpler, more interpretable mathematical expressions.

In the limit τ → 0, the dynamics Xt is observed at all times
and recycling occurs immediately upon entry into B. The
steady-state distribution ˜π can be calculated using the rela-
tion46

˜π(x) ∝ [1 − ˜q(x)]e−βU(x).

(16)

Here, ˜q is the committor function, the probability for Xt to
reach B before A starting from x, which is given by47

˜q(x) =


0

(cid:82) x
a eβU(y)/D(y) dy
(cid:82) b
a eβU(y)/D(y) dy

1

x ≤ a,

x < a < b,

(17)

x ≥ b.

Using (16) and (17), the steady-state distribution is supported
on {x < b}, and it satisﬁes

˜π(x) ∝ e−βU(x)

(cid:90) b

max{x,a}

eβU(y)
D(y)

dy.

(18)

Compared to the Boltzmann density ∝ e−βU(x), the steady-
state density ˜π removes mass from the regions near B due to
the recycling of trajectories. See Figure 4 for an illustration.

The ﬂux discrepancy function h = hτ and the ﬂux variance
function v = vτ depend implicitly on the evolution interval τ,
and they converge to well-deﬁned limits as τ → 0:

˜h(x) = lim
τ→0

hτ (x),

˜v2(x) = lim
τ→0

vτ (x)2.

(19)

As a result of (8), the discrepancy function ˜h satisﬁes

˜h(x) =

(cid:104) ˜TB(cid:105) ˜π − (cid:104) ˜TB(cid:105)x
(cid:104) ˜TB(cid:105)A

.

(20)

Weighted ensemble: Recent mathematical developments

6

FIG. 5. The ideal reaction coordinates for WE. Plotted are the dis-
crepancy function ˜h the committor ˜q and the variance function ˜v for
the Smoluchowski dynamics with recycling from B to A, a diffusion
coefﬁcient D = 1, and β = 10.

FIG. 6. The optimal allocation distribution at low temperature. Plot-
ted is the optimal allocation distribution ˜π ˜v for the Smoluchowski
dynamics with recycling from B to A and with increasing values of β
when D = 1. In the limit β → ∞, the optimal allocation distribution
is constant along the interval of largest energy increase; see (24).

˜TB is the exact MFPT function to the target state B,

Here,
which is given for x ≤ b by47

(see Appendix 4) yields

(cid:104) ˜TB(cid:105)x =

(cid:90) b

x

eβU(z)
D(z)

(cid:90) z

−∞

e−βU(y) dy dz.

(21)

The variance function ˜v satisﬁes the relations

˜v2(x) = lim
τ→0

Varx

(cid:2)˜h(Xτ )(cid:3)
τ

(cid:12)
(cid:12)
= 2D(x)
(cid:12)

d
dx

(cid:12)
2
˜h(x)
(cid:12)
(cid:12)

,

(22)

where the ﬁrst equality follows from the deﬁnition (9) and the
second equality comes from applying Itô’s lemma47. Formula
(22) suggests that there should be more splitting in regions of
high ˜h variability, or, equivalently, high variability in the local
MFPT (cid:104) ˜TB(cid:105)x.

Note that the committor ˜q is usually understood to be the
relevant coordinate for computing the MFPT and similar prob-
lems48. We have shown, however, that two different scalar co-
ordinates, namely ˜h and ˜v2, are the relevant ones for splitting
and merging in the context of WE simulation. The difference
between these coordinates is exhibited by a model problem
with an asymmetric two-barrier system in Figure 5. For this
problem, the committor ˜q would not be an ideal reaction co-
ordinate since it poorly resolves the largest barrier on the for-
ward path from A to B. In contrast, ˜h and ˜v resolve the largest
forward barrier, making them appropriate for WE.

Lastly, a simple formula for the optimal WE allocation
holds in the low-temperature limit as β → ∞. Assume that
the largest energy increase on the forward path to B occurs
over the interval [x−, x+], i.e.,

∆U = U(x+) −U(x−) = max

(U(y) −U(x)).

(23)

a≤y≤b, x<y

Note that the interval [x−, x+] can include multiple energy bar-
riers. Then, as β → ∞, an application of Laplace’s method

˜π(x) ˜v(x)
(cid:82) ˜π(y) ˜v(y) dy

→


0


0

D−1/2(x)
D−1/2(y) dy

(cid:82) x+
x−

x ≤ x−,

x− < x < x+,

(24)

x ≥ x+.

D over the
Thus, the optimal allocation is proportional to 1/
interval [x−, x+], and it is vanishingly small elsewhere as il-
lustrated in Figure 6.

√

In the low-temperature limit β → ∞, the optimal gain over
direct Monte Carlo sampling grows exponentially with the
size of the largest energy increase (see Appendix 4):

Gain over direct Monte Carlo

β →∞
∼

π/β
(cid:112)D(x+)/D(x) dx

(cid:17)2

(cid:16)(cid:82) x+
x−

eβ ∆U
(cid:112)|U (cid:48)(cid:48)(x−)U (cid:48)(cid:48)(x+)|

.

(25)

This provides a formal explanation of earlier numerical ﬁnd-
ings4,49 that WE’s advantage over direct Monte Carlo grows
dramatically as β ∆U increases.

V. A PRINCIPLED WE STRATEGY

The theoretical results above can serve as guidelines for op-
timizing WE. For example, we describe one principled WE
strategy called “MFPT binning” in Section V A, and we com-
pare MFPT binning to a more traditional WE binning strategy
in Section V B.

Weighted ensemble: Recent mathematical developments

7

and WE remains unbiased regardless of the approximation
quality of h and v. As a concrete strategy41, initial simula-
tions can be performed, and discrete Markov state models50
(MSMs) can be used to approximate h and v based on the re-
lationships to the MFPT described in Section IV.

In contrast to this MFPT binning strategy, the most com-
mon WE approach23 involves bins deﬁned using root mean
square displacement (RMSD) to B in some feature space, with
the same number of trajectories allocated to each bin. This
approach would be optimal if the dynamics in the RMSD co-
ordinate were well-described by the one-dimensional Smolu-
chowsi equation (5) with large β and constant D; see Section
IV C and Figure 5. However, the RMSD coordinate rarely be-
haves in this way for complex systems, and our results below
show that RMSD binning can catastrophically fail when the
RMSD coordinate is very different from the MFPT.

B. Numerical comparison

In this section, we numerically compare two strategies for

binning and allocation within WE:

1. The MFPT binning strategy discussed in Section V A.

2. Traditional WE bins based on RMSD to B with alloca-

tions proportional to (cid:82)

bin v(x)π(x) dx.

In both strategies, the allocations enforce the heuristic (10) of
having ∝
∼ π(x)v(x) trajectories near x, which is derived math-
ematically in Section IV.

We will apply these WE strategies to the two-dimensional
Smoluchowski model system pictured in Figure 8, with full
speciﬁcations in Appendix 5. We begin our study of this
model by constructing a ﬁne-grained MSM approximation of
functions π, h, and v. Next, we use these approximations to
construct the MFPT bins in Figure 8. Observe that the MFPT
bins resolve the largest energy barriers on the forward path
from A to B, whereas the RMSD bins have concentric circle
bin boundaries that do not account for the energy landscape
at all. See Appendix 5 for further bin construction details.
These computations were performed using15.

To evaluate the precision – and hence, efﬁciency – of the
ﬂux estimates from MFPT and RMSD binning, we deﬁne a
compute-cost-independent variance constant:
Variance Constant = Nt × Var (cid:0) ˆJt

(27)

(cid:1) .

Here, the variance of the empirical WE ﬂux has been scaled to
account for total simulation cost Nt. The variance constants
for MFPT and RMSD binning are compared in Figure 9. The
ﬁgure also shows estimates of the optimal WE variance con-
stant ((cid:82) πv)2 from the ﬁne-grained MSM model (see equa-
tion (15)), as well as the variance constant for direct Monte
Carlo, without any splitting or merging. We used N = 104 tra-
jectories and averaged over 102 independent runs to produce
these variance constants.

Figure 9 reveals a dramatic difference between MFPT and
RMSD binning. RMSD binning leads to worse-quality re-
sults than direct Monte Carlo simulation for this non-trivial

Illustration of MFPT binning strategy. Pictured are 6 bins,
FIG. 7.
with dividing surfaces between bins indicated by the vertical lines.
Bin boundaries are chosen to make the integral of ˜π ˜v within each bin
constant. Here, D = 1 and β = 4. In higher-dimensional spaces, bin
boundaries would be level sets of h as in Figure 8.

A. MFPT binning

From the theory in Section IV A, merging has a low cost
among trajectories with similar h values. This motivates the
following MFPT binning strategy in which bins are comprised
of similar h values10,41, or equivalently based on (8), similar
values of the local MFPT to B:

1. Deﬁne the bins to be intervals in the h coordinate. If
there are K bins, choose the endpoints h0 < h1 < . . . <
hK such that

(cid:90)

hk≤h(x)≤hk+1

π(x)v(x)dx = Const.

(26)

2. Allocate trajectories uniformly among these K bins,
so that approximately N/K trajectories are assigned to
each bin.

This approach agrees with strategy (10) while also satisfying
the traditional WE rule of keeping the number of trajectories
per bin nearly constant. See Figure 7 for an illustration.

The MFPT binning strategy is similar to the one described
in Section IV A, which attains the lowest possible variance
in the limit of many trajectories and time steps. However,
instead of bins that are rectangles in h and v coordinates, we
deﬁne bins as intervals of h values alone. This alteration still
performs well in our model problem in Section V B, even with
a small number of trajectories (100–1000) and just a few bins
(5–10).

The MFPT binning strategy requires an approximation to
the ﬂux discrepancy function h and ﬂux variance function v.
Strategies for estimating the functions will be explored in fu-
ture work. We note that even crude estimates of h and v may
be helpful, compared to naive or ad-hoc binning strategies,

Weighted ensemble: Recent mathematical developments

8

FIG. 9. Comparison of binning strategies for MFPT estimation. Es-
timates of the rescaled variance constant (27) are plotted for MFPT
and RMSD binning strategies for the two-dimensional problem de-
picted in Fig. 8. For this problem, the ﬂux value is approximately
10−6.

bins, we are within an order of magnitude of the estimated op-
timal constant. This is two and a half orders of magnitude of
improvement over direct Monte Carlo.

To encourage a fair comparison, we have applied the op-
timal allocation rule (10) to both MFPT and RMSD binning.
However, analogous tests (not pictured) show that RMSD bin-
ning performs even worse with uniform allocations, leading
to higher variance constants. Our MFPT binning method here
also outperformed related strategies in our earlier work41.

Lastly, the data in Figure 9 was generated using N = 104
trajectories, which may exceed the computational resources
available for problems of interest. Figure 10 presents com-
parisons for 102, 103, and 104 trajectories, indicating that the
variance constant typically has no more than an order of mag-
nitude in variability.
In particular, for the MFPT bins the
results for 103 trajectories are nearly indistinguishable from
those obtained with 104 trajectories.

FIG. 8. Different binning strategies in a challenging two-dimensional
model. Pictured are the potential U (top), MFPT bins (middle), and
RMSD bins (bottom), with the source A depicted as a ﬁlled dot and
the sink B depicted as a dashed rectangle. Different shades indicate
different bins. The model is fully speciﬁed in Appendix 5: see the
potential (50).

model, for any number of bins. Meanwhile, MFPT binning
leads to a major improvement over direct Monte Carlo simu-
lation, particularly when the number of bins is large (20–40
bins). With only 5 bins, we see a modest gain with the MFPT
binning strategy. Increasing the number of bins with MFPT
binning systematically improves the output such that with 40

0.00.20.40.60.81.0x0.00.20.40.60.81.0yPoint SourceTarget Set0.250.500.751.001.251.501.75U0.00.20.40.60.81.0x0.00.20.40.60.81.0y10 MFPT BinsPoint SourceTarget Set0.00.20.40.60.81.0x0.00.20.40.60.81.0y10 RMSD BinsPoint SourceTarget Set103104105Physical Time t1010.0109.5109.0108.5108.0107.5107.0106.5106.0105.5105.0104.5104.0103.5103.0Estimated Variance ConstantDirect Monte CarloRMSDMFPT, 5 binsMFPT, 10 binsMFPT, 20 binsMFPT, 40 binsMSM Estimate of Lower BoundRMSD, 5 binsRMSD, 10 binsRMSD, 20 binsWeighted ensemble: Recent mathematical developments

9

egy, called MFPT binning. After pilot runs that estimate h
and v (or equivalently, the local MFPT to B and its variance),
this strategy deﬁnes the bins to be intervals in the h coordi-
nate, chosen in a way that optimizes the variance. In a model
problem, MFPT binning signiﬁcantly outperforms a naive WE
approach that constructs bins using the RMSD to B, and these
results remain robust even for relatively small N.

ACKNOWLEDGEMENTS

D. Aristoff and G. Simpson gratefully acknowledge support
from the National Science Foundation via the awards DMS
2111277 and DMS 1818726. J. Copperman is a Damon Run-
yon Fellow supported by the Damon Runyon Cancer Research
Foundation (DRQ-09-20). R. J. Webber was supported by
the Ofﬁce of Naval Research through BRC award N00014-
18-1-2363 and the National Science Foundation through FRG
award 1952777, under the aegis of Joel A. Tropp. D. M. Zuck-
erman was supported by NIH grant GM115805. Computa-
tional resources were provided by Drexel’s University 673 Re-
search Computing Facility. The authors are grateful to Mats
Johnson for preliminary numerical work related to the results
in Section V.

FIG. 10. Variance constants for different numbers of trajectories.

1. Computing other statistics using WE

APPENDIX

VI. CONCLUSION

This work has attempted to assemble, expand upon, and
make accessible to a chemical physics audience, recent math-
ematical results of fundamental importance to weighted en-
semble (WE) simulation. The mathematical theory exposes
the fundamental capabilities of WE and guiding principles be-
hind WE optimization. It leads to the identiﬁcation of opti-
mal reaction coordinates for merging and splitting. The the-
ory also identiﬁes the minimal possible variance for WE in
the limit of many trajectories and time steps, and we demon-
strate a simple binning strategy for approaching that optimum
that works well in a two-dimensional model problem. Testing
these approaches in complex systems will be pursued in future
work.

To illustrate the mathematical theory in a physically intu-
itive way, explicit formulas were derived for the optimal co-
ordinates and optimal WE variance in the case of the Smolu-
chowski dynamics (5) in one dimension. These formulas, pre-
sented for the ﬁrst time here, demonstrate that the variance
reduction from WE can be exponentially large in the size of
the largest forward energy barrier from A to B.

The mathematical theory is important because it enables
principled variance reduction strategies for WE. Here, we
have proposed and tested one such variance reduction strat-

WE can be used to compute other statistics, in addition to
the MFPT from A to B. Namely, any integral (cid:82) f (x)π(x)dx
involving an observable f can be estimated using N WE tra-
jectories. In the long time limit, the trajectories satisfy

(cid:90)

f (x)π(x)dx = lim
t→∞

1
t

t
∑
s=1

N
∑
i=1

sτ f (ξ i
wi

sτ ),

(28)

t , wi

where (ξ i
t )1≤i≤N denotes the position and weight of trajec-
tory i at time t. Therefore, as a practical estimator, we can
terminate the simulations at a ﬁnite time t and approximate

(cid:90)

f (x)π(x)dx ≈

1
t − t0

t
∑
s=t0

N
∑
i=1

sτ f (ξ i
wi

sτ ),

(29)

where t0 > 0 is a suitable burn-in time. Here we have assumed
f is recorded only at τ intervals, although WE permits saving
points more frequently.

The estimator (29) is readily extended to history-dependent
observables, such as transition-path times or mechanistic
pathways from A to B. This requires deﬁning the trajectories
as paths starting from A, which are recycled upon reaching B,
and deﬁning π as a stationary measure on path space. The
recent mathematical literature10,11,40,41 provides a set of error
bounds and convergence guarantees for the estimator (29).

104105Physical Time t1010.0109.5109.0108.5108.0107.5107.0106.5106.0105.5105.0104.5104.0103.5103.0Estimated Variance ConstantRMSD, 20 bins, N = 100RMSD, 20 bins, N = 1000RMSD, 20 bins, N = 10000MFPT, 20 bins, N = 100MFPT, 20 bins, N = 1000MFPT, 20 bins, N = 10000MFPT, 40 bins, N = 100MFPT, 40 bins, N = 1000MFPT, 40 bins, N = 10000MSM Estimated Lower BoundWeighted ensemble: Recent mathematical developments

10

2. Relationship between ﬂux discrepancy and MFPT

To establish the relationship

lim
t→∞

[(cid:104)Nt (cid:105)x − (cid:104)Nt (cid:105)π ] =

(cid:104)TB(cid:105)π − (cid:104)TB(cid:105)x
(cid:104)TB(cid:105)A

,

(30)

we ﬁrst introduce the following terminology:

• T x

B is the ﬁrst passage time into B for a dynamics started
at X0 = x.

• T π

B is the ﬁrst passage time into B for a dynamics started
at X0 ∼ π, i.e., started at a point chosen randomly from
the steady-state distribution.

• NA
t

is the number of arrivals into B by time t for a dy-

namics started at X0 ∼ ρA.

Next we recall the renewal theorem from classical probabil-
ity51, which states that for any s > 0,
t−s(cid:105)(cid:3) =

t (cid:105) − (cid:104)NA

(cid:2)(cid:104)NA

(31)

.

lim
t→∞

s
(cid:104)TB(cid:105)A

Lastly, we verify

lim
t→∞

[(cid:104)Nt (cid:105)x − (cid:104)Nt (cid:105)π ]

= lim
t→∞

= lim
t→∞
(cid:104)T π

=

(cid:104)(cid:68)

NA
t−T x
B
(cid:104)(cid:10)NA
(cid:11) −
t
B (cid:105) − (cid:104)T x
B (cid:105)
(cid:104)TB(cid:105)A

,

(cid:69)

(cid:68)

NA

−

(cid:69)(cid:105)

t−T π
B
(cid:69)(cid:105)

(cid:68)

NA

t−T π
B

− lim
t→∞

(cid:104)(cid:10)NA

t

(cid:11) −

(cid:68)

NA

t−T x
B

(cid:69)(cid:105)

(32)

(33)

(34)

(35)

where we have applied the renewal theorem after conditioning
on s = T π

B and s = T x
B .

3. Derivation of optimal allocation rule

In this section we provide an intuitive derivation of the op-

timal allocation rule

# trajectories near x ∝ π(x)v(x).

(36)

We introduce the following notation:

• weightbin and allocbin indicate a bin weight and bin al-

location.

• (cid:104)(cid:105)bin and Varbin denote the mean and variance with re-
spect to the weighted trajectory distribution in a bin, so
Varbin( f ) = (cid:104) f 2(cid:105)bin − (cid:104) f (cid:105)2
bin.
• Finally, (cid:104)(cid:105)t denotes the average over the WE ensemble

up to time t.

We consider a greedy minimization strategy10,41 for min-
imizing the variance formula (37).
The variance terms
Varbin(h) and Varbin(v) are minimized by choosing bins in
which h and v values are nearly constant. The other term,
namely,

weight2
bin
allocbin

(cid:104)v(cid:105)2

bin,

is minimized when the allocation is chosen using10,40,41

allocbin ∝

∼ weightbin × (cid:104)v(cid:105)bin,

(38)

which reduces to (36) in the limit of many trajectories.

4. Low temperature limit

Here we derive the optimal splitting and merging coordi-
nates in the low-temperature limit β → ∞. First, we combine
the expression for the steady state

˜π(x) ∝ e−βU(x)

(cid:90) b

max{x,a}

eβU(y) dy
D(y)

(39)

with the expression for the ﬂux variance function
√

˜v(x) =

2eβU(x)
D(x)1/2(cid:104) ˜TB(cid:105)A

(cid:90) x

−∞

dy
eβU(y)

,

(40)

to obtain the optimal allocation rule

˜π(x) ˜v(x) ∝

1
D(x)1/2

(cid:90) b

max{x,a}

eβU(y) dy
D(y)

(cid:90) x

−∞

dy
eβU(y)

.

(41)

Next, we assume the pair of points (x−, x+) is the unique

solution to the maximization

max
a≤y≤b, x<y

(U(y) −U(x)),

(42)

and U (cid:48)(cid:48)(x+) < 0 < U (cid:48)(cid:48)(x−). Using Laplace’s method52 on (41)
we obtain, for any x− < x < x+,

1
D(x)1/2

(cid:90) b

max{x,a}

eβU(y) dy
D(y)

(cid:90) x

−∞

dy
eβU(y)

β →∞
∼

C
D(x)1/2

eβU(x+)
β eβU(x−)

,

(43)

where the prefactor C is explicitly

Then the following variance formula10,11 holds in the limit as
t → ∞:

C =

2π
D(x+)U (cid:48)(cid:48)(x−)1/2|U (cid:48)(cid:48)(x+)|1/2

.

(44)

tVar( ˆJt ) ∼
(cid:42)

weight2
bin
allocbin

∑
bins

(cid:2)Varbin(h) + Varbin(v) + (cid:104)v(cid:105)2

bin

(cid:43)
(cid:3)

t

.

(37)

For x outside of the interval [x−, x+], Laplace’s method dic-
tates that the optimal allocation π(x)v(x) is exponentially
smaller as β → ∞, whence we recover the optimal allocation
(24).

Weighted ensemble: Recent mathematical developments

11

From the above calculations, we ﬁnd that the optimal gain

from using WE takes the form

Gain over direct Monte Carlo =

QR
S2 ,

(45)

where

Q =

R =

S =

(cid:90) b

−∞
(cid:90) b

−∞
(cid:90) b

−∞

(cid:90) b

eβU(x)
D(x)

max{x,a}
(cid:90) b

e−βU(x)

1
D(x)1/2

max{x,a}
(cid:90) b

max{x,a}

eβU(y) dy
D(y)
eβU(y) dy
D(y)
eβU(y) dy
D(y)

(cid:16)(cid:90) x

−∞

dx,

(cid:17)2

dy
eβU(y)

dx,

(46)

(47)

(cid:90) x

−∞

dy
eβU(y)

dx .

(48)

Applying the Laplace principle to (46)-(48) veriﬁes the ex-
pression

Gain over direct Monte Carlo

∼

(cid:16)(cid:82) x+
x−

π/β
(cid:112)D(x+)/D(x) dx

(cid:17)2

eβ (U(x+)−U(x−))
(cid:112)|U (cid:48)(cid:48)(x−)U (cid:48)(cid:48)(x+)|

.

(49)

5. Details of numerical simulations

In the 2D problem, the landscape is given by the expression

U(x, y) = U1(x, y) +U2(x, y) + 0.5U3(x, y),

(50)

where

logU1(x, y) = − c1(x − 0.25)2 − c1(y − 0.75)2

− 2c2(x − 0.25)(y − 0.75)
logU2(x, y) = − c3x2(1 − x)2y2(1 − y)2
logU3(x, y) = − c4x2 − c4y2 + 2c5xy

(51a)

(51b)

(51c)

and the constants are given by

(c1, c2, c3, c4, c5) = (50.5, 49.5, 105, 51, 49).

(52)

The diffusivity is D = 1, and the inverse temperature is β =
30.

To simulate the Smoluchowski dynamics, we apply Euler-
Maruyama integration with an integration step of size 0.001.
Each evolution step is composed of ten such steps, so that
τ = 0.01. We constrain the trajectories to reside in [0, 1]2.
In the case that a trajectory attempts to exit this region, it is
projected back into the box with x = max(min(x, 1), 0) and
y = max(min(y, 1), 0).

The functions π, h, and v are approximated using an MSM
model generated from “microbins”41,45 with Voronoi cell cen-
ters that are spaced ∆x = ∆y = 0.02 units apart on a regular
Cartesian grid. This spacing results in a total of 49 × 49 =
2401 microbins, which are the small rectangles visible in Fig-
ure 8.

1G. A. Huber and S. Kim, “Weighted-ensemble brownian dynamics simu-
lations for protein association reactions,” Biophysical journal 70, 97–110
(1996).
2B. W. Zhang, D. Jasnow, and D. M. Zuckerman, “The “weighted ensemble”
path sampling method is statistically exact for a broad class of stochastic
processes and binning procedures,” The Journal of chemical physics 132,
054107 (2010).
3R. M. Donovan, A. J. Sedgewick, J. R. Faeder, and D. M. Zuckerman, “Ef-
ﬁcient stochastic simulation of chemical kinetics networks using a weighted
ensemble of trajectories,” The Journal of chemical physics 139, 09B642_1
(2013).
4B. W. Zhang, D. Jasnow, and D. M. Zuckerman, “Efﬁcient and veriﬁed sim-
ulation of a path ensemble for conformational change in a united-residue
model of calmodulin,” Proceedings of the National academy of Sciences
104, 18043–18048 (2007).
5M. C. Zwier, J. W. Kaus,
and L. T. Chong, “Efﬁcient explicit-
solvent molecular dynamics simulations of molecular association kinetics:
Methane/methane, na+/cl-, methane/benzene, and k+/18-crown-6 ether,”
Journal of Chemical Theory and Computation 7, 1189–1197 (2011).
6E. Suarez, S. Lettieri, M. C. Zwier, C. A. Stringer, S. R. Subramanian, L. T.
Chong, and D. M. Zuckerman, “Simultaneous computation of dynamical
and equilibrium information using a weighted ensemble of trajectories,”
Journal of chemical theory and computation 10, 2658–2667 (2014).
7S. D. Lotz and A. Dickson, “Unbiased molecular dynamics of 11 min
timescale drug unbinding reveals transition state stabilizing interactions,”
Journal of the American Chemical Society 140, 618–628 (2018).
8T. Sztain, S.-H. Ahn, A. T. Bogetti, L. Casalino, J. A. Goldsmith, E. Seitz,
R. S. McCool, F. L. Kearns, F. Acosta-Reyes, S. Maji, et al., “A glycan
gate controls opening of the sars-cov-2 spike protein,” Nature Chemistry
13, 963–968 (2021).
9H. Kahn and T. E. Harris, “Estimation of particle transmission by random
sampling,” National Bureau of Standards applied mathematics series 12,
27–30 (1951).

10D. Aristoff, “An ergodic theorem for the weighted ensemble method,” Jour-

nal of Applied Probability 59, 152–166 (2022).

11R. J. Webber, D. Aristoff, and G. Simpson, “A splitting method to reduce

mcmc variance,” arXiv preprint arXiv:2011.13899 (2020).

12M. C. Zwier, J. L. Adelman, J. W. Kaus, A. J. Pratt, K. F. Wong, N. B.
Rego, E. Suárez, S. Lettieri, D. W. Wang, M. Grabe, et al., “WESTPA:
An interoperable, highly scalable software package for weighted ensemble
simulation and analysis,” Journal of chemical theory and computation 11,
800–809 (2015).

13J. D. Russo, S. Zhang, J. M. Leung, A. T. Bogetti, J. P. Thompson, A. J.
DeGrave, P. A. Torrillo, A. Pratt, K. F. Wong, J. Xia, et al., “WESTPA
2.0: High-performance upgrades for weighted ensemble simulations and
analysis of longer-timescale applications,” Journal of Chemical Theory and
Computation (2021).

14S. D. Lotz and A. Dickson, “Wepy: a ﬂexible software framework for sim-
ulating rare events with weighted ensemble resampling,” ACS omega 5,
31608–31623 (2020).

15D. Aristoff, F. G. Jones, R. Webber, G. Simpson, and D. M. Zuckerman,

“Weightedensemble.jl,” (2020), julia package.

16A. Dickson and C. L. Brooks III, “Wexplore: hierarchical exploration
of high-dimensional spaces using the weighted ensemble algorithm,” The
Journal of Physical Chemistry B 118, 3532–3542 (2014).

17J. L. Adelman, A. L. Dale, M. C. Zwier, D. Bhatt, L. T. Chong, D. M. Zuck-
erman, and M. Grabe, “Simulations of the alternating access mechanism of
the sodium symporter mhp1,” Biophysical journal 101, 2399–2407 (2011).
18B. Abdul-Wahid, H. Feng, D. Rajan, R. Costaouec, E. Darve, D. Thain,
and J. A. Izaguirre, “Awe-wq: fast-forwarding molecular dynamics using
the accelerated weighted ensemble,” Journal of chemical information and
modeling 54, 3033–3043 (2014).

19S.-H. Ahn, A. A. Ojha, R. E. Amaro, and J. A. McCammon, “Gaussian-
accelerated molecular dynamics with the weighted ensemble method: A
hybrid method improves thermodynamic and kinetic sampling,” Journal of
Chemical Theory and Computation 17, 7938–7951 (2021).

20D. Ray and I. Andricioaei, “Weighted ensemble milestoning (wem): A
combined approach for rare event simulations,” The Journal of chemical
physics 152, 234114 (2020).

21D. Ray, S. E. Stone, and I. Andricioaei, “Markovian weighted ensemble

Weighted ensemble: Recent mathematical developments

12

milestoning (m-wem): Long-time kinetics from short trajectories,” Journal
of Chemical Theory and Computation (2021).

learning

22A. Ojha, S. Thakur, S.-H. Ahn,
of

Deep
ble
sampling,”
details/6238beac13d478049d96d707.

simulation toolkit
(2022),

for

kinetic models with

and R. Amaro, “Deepwest:
ensem-
and thermodynamic
https://chemrxiv.org/engage/chemrxiv/article-

enhanced kinetic

the weighted

23D. M. Zuckerman and L. T. Chong, “Weighted ensemble simulation: review
of methodology, applications, and software,” Annual review of biophysics
46, 43–57 (2017).

24D. Bhatt and D. M. Zuckerman, “Beyond microscopic reversibility: Are ob-
servable nonequilibrium processes precisely reversible?” Journal of chemi-
cal theory and computation 7, 2520–2527 (2011).

25D. Bhatt, B. W. Zhang, and D. M. Zuckerman, “Steady-state simulations
using weighted ensemble path sampling,” The Journal of chemical physics
133, 014110 (2010).

26W. C. Swope, J. W. Pitera, and F. Suits, “Describing protein folding kinet-
ics by molecular dynamics simulations. 1. theory,” The Journal of Physical
Chemistry B 108, 6571–6581 (2004).

27R. J. Allen, P. B. Warren, and P. R. Ten Wolde, “Sampling rare switching
events in biochemical networks,” Physical review letters 94, 018104 (2005).
28F. Cérou and A. Guyader, “Adaptive multilevel splitting for rare event anal-

ysis,” Stochastic Analysis and Applications 25, 417–443 (2007).

29J. M. Bello-Rivas and R. Elber, “Exact milestoning,” The Journal of Chem-

ical Physics 142, 03B602_1 (2015).

30D. Aristoff, J. M. Bello-Rivas, and R. Elber, “A mathematical framework
for exact milestoning,” Multiscale Modeling & Simulation 14, 301–322
(2016).

31A. Warmﬂash, P. Bhimalapuram, and A. R. Dinner, “Umbrella sampling
for nonequilibrium processes,” The Journal of chemical physics (2007).
32T. S. van Erp, D. Moroni, and P. G. Bolhuis, “A novel path sampling
method for the calculation of rate constants,” The Journal of chemical
physics 118, 7762–7774 (2003).

33D. S. Abbot, R. J. Webber, S. Hadden, D. Seligman, and J. Weare, “Rare
event sampling improves mercury instability statistics,” The Astrophysical
Journal 923, 236 (2021).

34J. Finkel, R. J. Webber, E. P. Gerber, D. S. Abbot, and J. Weare, “Learning
forecasts of rare stratospheric transitions from short simulations,” Monthly
Weather Review 149, 3647–3669 (2021).

35J. Finkel, R. J. Webber, E. P. Gerber, D. S. Abbot, and J. Weare, “Exploring
stratospheric rare events with transition path theory and short simulations,”
arXiv preprint arXiv:2108.12727 (2021).

36R. M. Donovan, J.-J. Tapia, D. P. Sullivan, J. R. Faeder, R. F. Murphy,
M. Dittrich, and D. M. Zuckerman, “Unbiased rare event sampling in spa-
tial stochastic systems biology models using a weighted ensemble of trajec-

tories,” PLoS computational biology 12, e1004611 (2016).

37E. Darve and E. Ryu, “Computing reaction rates in bio-molecular systems
using discrete macro-states,” in Innovations in Biomolecular Modeling and
Simulations (2012) pp. 138–206.

38H. Feng, R. Costaouec, E. Darve, and J. A. Izaguirre, “A comparison of
weighted ensemble and markov state model methodologies,” The Journal
of chemical physics 142, 06B610_1 (2015).

39J. L. Adelman and M. Grabe, “Simulating rare events using a weighted
ensemble-based string method,” The Journal of chemical physics 138,
01B616 (2013).

40D. Aristoff, “Analysis and optimization of weighted ensemble sampling,”
ESAIM: Mathematical Modelling and Numerical Analysis 52, 1219–1238
(2018).

41D. Aristoff and D. M. Zuckerman, “Optimizing weighted ensemble sam-
pling of steady states,” Multiscale Modeling & Simulation 18, 646–673
(2020).

42T. L. Hill, Free energy transduction and biochemical cycle kinetics (Courier

Corporation, 2005).

43I. Ben-Ari and R. G. Pinsky, “Spectral analysis of a family of second-order
elliptic operators with nonlocal boundary condition indexed by a probabil-
ity measure,” Journal of Functional Analysis 251, 122–140 (2007).

44U. Adhikari, B. Mostoﬁan, J. Copperman, S. R. Subramanian, A. A. Pe-
tersen, and D. M. Zuckerman, “Computational estimation of microsecond
to second atomistic folding times,” Journal of the American Chemical So-
ciety 141, 6519–6526 (2019).

45J. Copperman and D. M. Zuckerman, “Accelerated estimation of long-
timescale kinetics from weighted ensemble simulation via non-markovian
“microbin” analysis,” Journal of chemical theory and computation 16,
6763–6775 (2020).

46J. Lu and J. Nolen, “Reactive trajectories and the transition path process,”

Probability Theory and Related Fields 161, 195–244 (2015).

47C. W. Gardiner et al., Handbook of stochastic methods, 2nd edition

(Springer, Berlin, 1985).

48P. Ma, R. Elber, and D. E. Makarov, “Value of temporal information when
analyzing reaction coordinates,” Journal of Chemical Theory and Compu-
tation 16, 6077–6090 (2020).

49A. J. DeGrave, J.-H. Ha, S. N. Loh, and L. T. Chong, “Large enhancement
of response times of a protein conformational switch by computational de-
sign,” Nature communications 9, 1–9 (2018).

50J. D. Chodera and F. Noé, “Markov state models of biomolecular conforma-
tional dynamics,” Current opinion in structural biology 25, 135–144 (2014).
51W. Feller, An introduction to probability theory and its applications, vol 2

(John Wiley & Sons, 2008).

52C. M. Bender and S. A. Orszag, Advanced Mathematical Methods for Sci-

entists and Engineers I (Springer New York, New York, NY, 1999).

