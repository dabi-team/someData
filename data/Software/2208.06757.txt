Noname manuscript No.
(will be inserted by the editor)

A Preliminary Study on the Potential Usefulness of
Open Domain Model for Missing Software Requirements
Recommendation

Ziyan Zhao,Li Zhang,Xiaoli Lian

2
2
0
2

g
u
A
4
1

]
E
S
.
s
c
[

1
v
7
5
7
6
0
.
8
0
2
2
:
v
i
X
r
a

the date of receipt and acceptance should be inserted later

Abstract Completeness is one of the most important
attributes of software requirement speciﬁcations. Un-
fortunately, incompleteness is meanwhile one of the most
diﬃcult problems to detect. Some approaches have been
proposed to detect missing requirements based on the
requirement-oriented domain model. However, this kind
of models are lacking for lots of domains. Fortunately,
the domain models constructed for diﬀerent purposes
can usually be found online. This raises a question:
whether or not these domain models are helpful in ﬁnd-
ing the missing functional information in requirement
speciﬁcation? To explore this question, we design and
conduct a preliminary study by computing the overlap-
ping rate between the entities in domain models and the
concepts of natural language software requirements and
then digging into four regularities of the occurrence of
these entities(concepts) based on two example domains.
The usefulness of these regularities, especially the one
based on our proposed metric AHME (with F2 gains of
146% and 223% on the two domains than without any
regularity), has been shown in experiments.

Keywords Domain model, Completeness validation,
Software requirements, Model completion

1 Introduction

It is extremely common that some basic or even cru-
cial functions are lacking from the software require-
ment speciﬁcations due to the limited domain knowl-
edge of requirements analysts, the short-term plan of
companies, and the nature of the change of require-
ments. However, the functions and capacities that soft-

SKLSDE, Beihang University, Beijing, China, 100191, E-
mail: {zhaoziyan,lily,lianxiaoli}@buaa.edu.cn

ware products can provide constitute their core com-
petitiveness, and the missing of the critical functions
seriously decreases their reputation and market share.
Therefore, organizations need to make clear their miss-
ing functions for sound and practical improvements [42].
Many research focuses on detecting the missing func-
tions based on requirement-oriented domain models [25,
26,1]. One possible reason that makes the domain model
popular in this ﬁeld is that it is an explicit representa-
tion of the salient concepts in an application domain
and the relations between these concepts [12]. And it
also depicts the whole picture of the functions in a do-
main in a compassed and structured way. In addition,
Arora et al.[1] conducted an empirical study on the
use of domain models for the completeness checking
of software requirements and showed that the domain
model constructed from software requirements is suﬃ-
ciently sensitive to the information on missing require-
ments. However, unfortunately, this kind of software
requirements-oriented domain model does not exist for
many domains.

Although there are already some studies about the
technologies of automatically extracting domain mod-
els from software requirements [1], [34], it is not easy
to construct the model from scratch due to two prob-
lems. Firstly, some tedious manual work with expertise
is required for validating and improving the model for
practical usage. Second, enough requirements of similar
but diﬀerent systems in the same domain are required
for the model construction to guarantee its coverage.
Unfortunately, it is not easy to collect enough require-
ment speciﬁcations of multiple competing products, es-
pecially for academic researchers, due to the conﬁden-
tiality and the under-speciﬁed requirements in practice.
Fortunately, some domain models (e.g., ontologies)
created for diﬀerent purposes (i.e., not for requirements

 
 
 
 
 
 
2

Ziyan Zhao,Li Zhang,Xiaoli Lian

validation) from other artifacts than pure software re-
quirements can be found online usually. We call this
kind of model as open domain model. We focus on ex-
ploring the feasibility of using an open domain model for
ﬁnding missing functional information in the software
requirement speciﬁcation in this study. Another reason
behind our selection is that even if the group has the
requirements-oriented domain model, it is hard to guar-
antee its synchronization with requirements because the
requirements change constantly. Lots of tedious human
work by experts is required to maintain the model. On
the contrary, open domain models are usually updated
and actively maintained by many professionals. So, it is
possible to select at least one high-quality open domain
model for some domains.

Undoubtedly, not all domain models are useful. We
deﬁnitely need to perform a selection. However, even
for the selected domain model, due to the discrepancies
between the requirements of one speciﬁc system and the
open domain model on their perspectives, terminologies
usage, and the coverage of functions, there must be an
obvious, even huge gap in the coverage of functional in-
formation. Intuitively, we are ﬁrstly curious about the
matching (i.e., overlap) degree between them. In other
words, to what extent that the requirements can be map-
ped into the open domain model?

Even if there are certain overlaps, it is easy to ex-
pect the gap must be bigger, i.e., much more concepts
of domain models that cannot be found in software re-
quirements. Almost all the existing researches on miss-
ing function detection propose detecting the concepts
that appear in the domain model but not in require-
ments [1,25,9]. However, not all missing concepts in-
dicate the missing requirements. For instance, in the
Building Automation System, the air-conditioning con-
trol system is one necessary piece of equipment that
must be installed. However, the heating function, as
one child of air-conditioning system in a hierarchical
domain model, does not need to be considered in the
low latitude area, where the year-round temperature is
pretty high. Thus, eﬀectively detecting the appropri-
ate concepts and recommending the valid missing in-
formation from the large unmapped scope is essential.
Before achieving this ultimate goal, we need to answer
one question: considering the sparse mapping between
requirements and domain models, is it possible to ﬁnd
valid clues of missing functional information from the
open domain models?

To be speciﬁc, we ﬁrst build the mapping between
the concepts of requirements and domain models based
on the synonymous identiﬁcation and then dig out the
occurrence regularities of the mapped concepts from the
aspects of requirements and domain models. We con-

sider the distribution characteristics of the requirement
entities in the open domain model and requirements as
“regularities”. We concentrate on concept mapping and
analysis because it is the general principle of current
approaches to detecting missing functional information
from requirements relying on any external resources [1].
This work is illustrated with two case domains of Un-
manned Aerial Vehicle (UAV) and Building Automa-
tion System (BAS).

Due to the limited overlap between these two arti-
facts (i.e., 43.4% and 20% for the two cases), the assis-
tance for the missing recommendation must be limited
too (i.e., 26% and 41% of F2 with the best AHME regu-
larity for the two cases). However, it is well known that
there are diverse dependencies between requirements
[11,32,7]. Thus, theoretically, the known requirements
should be helpful for the unknown requirements recom-
mendation because of their inner semantic associations.
In order to verify this hypothesis, we complement
the open domain model with the already known re-
quirements by aligning them and adding the domain
model entity-related requirement concepts as well as
the corresponding relationships. Particularly, the recall
of recommendations has been greatly increased with al-
most no loss of precision, although with bigger search-
ing scope and more noise entities, with the gain of 41%
and 72% for the two cases.

Contribution The main contribution of this paper

includes:

– We propose an approach of automatically building
the mapping between NL requirements and the do-
main model in RDF, including the concepts extrac-
tion from NL requirements and the synonyms detec-
tion based on external supporting data (i.e., forum).
With the case data, we observe that on average,
about 31.7% of requirements can be covered by the
open domain model, initially illustrating the useful-
ness of open domain models on missing functional
information recommendation.

– We ﬁnd out four regularities of overlapping entities
from both the domain model and requirements per-
spectives. Experiments show the regularities could
eﬀectively reduce the search scope of missing clues
in the domain model, making the F2 increase by
13%-24% on the two domains.

– We complement the original open domain model
with the known requirements through model align-
ment and relationship deduction, considering the
latent semantic associations between requirements.
After model complementing, the mapping rates in-
crease to about 73.6% for the two cases.

– With model completion, the missing recommenda-
tion has been improved further based on our AHME,

Title Suppressed Due to Excessive Length

3

with the F2 gains of 23% and 34%, than on the
original domain model with the same regularity and
gains of 146% and 223% than on the original model
without any regularity.

The remainder of this paper includes the follow-
ing sections. Section 2 introduces the related work on
requirements completeness evaluation and missing re-
quirements identiﬁcation. Section 3 gives the whole pic-
ture of our approach. Sections 4, 5 and 6 describe the
three phases of the detailed procedures, respectively.
Section 7 veriﬁes the eﬀectiveness of our method. Sec-
tion 8 discusses the threats to validity and the limi-
tations of our study. Finally, Section 9 concludes this
paper and gives directions to future work.

ﬁcations), focusing on the completeness of information
types rather than functional information.

We found that almost all studies are conducted based
on the domain ontology constructed from requirements
by these researches [10,14]. Besides, we did not ﬁnd any
research exploring the usage of open domain models to
recommend the missing functions in software require-
ments.

3 Overview of This Study

This section describes the framework of our study, the
research questions, and the cases we selected.

2 Related Works

Dermeval et al.[10] conducted a full survey on the appli-
cations of domain ontologies in requirements engineer-
ing in 2016. They found that although domain ontology
has been used in various requirements validation tasks,
almost all the researchers built requirements-oriented
ontologies, which other researchers seldom used. This
is just the primary motivation we explore the open do-
main model in missing requirements detection.

Arora et al.[1] used three industrial cases to prove
that the domain model extracted from requirements
is suﬃciently sensitive to the missing functions in the
requirement set. The mapping relationship between the
domain model and requirements needs to be established
manually by domain experts in their work. Based on the
manual mapping between the concepts in requirements
and domain ontology, Kaiya et al.[25] indicated that
the requirements might be incomplete if the concepts
of domain ontology cannot be mapped to requirements.
Kamalrudin et al. [26] extracted the critical use case
interaction model (the abstract behavior pattern) from
requirement texts on the premise of the domain pat-
tern inventory and judged the completeness of require-
ments by comparing the model with the pattern library.
Wei Liu et al.[27] studied the completeness analysis of
requirements for service-oriented computing software.
Sergio et al.[13], based on the functional model, deﬁned
the functional requirements model and the complete-
ness of the requirements model. But the approaches
on completeness validation or missing information de-
tection is not involved. On the other hand, Geierhos
et al.[17] are concerned about the existing but incom-
plete single user requirements, especially the semanti-
cally incomplete predicate part. Igor et al.[29] studied
the completeness assessment method of requirements
documents (especially the software requirements speci-

3.1 The Framework of Our Study

Generally, our study includes three phases: mapping
construction, domain model completion and regularity
analysis. In the ﬁrst phase, we extract concepts from
requirements and construct the mapping between these
concepts and the entities in the domain model. In the
second phase, we complete the open domain model with
the random 70% requirements through model align-
ment and relationship deduction. In the third phase,
we analyze the regularity of the occurrence of mapped
concepts in both the original and completion domain
model for the missing concepts recommendation. The
procedure is shown in Fig. 1.

To be speciﬁc, two steps are involved in the ﬁrst
mapping phase. In step one, we randomly select 70%
requirements from the full set (denoted as R) and then
extract concepts from these selected ones. Then, in step
two, we build the mapping relations between these con-
cepts and the entities in the open domain model (de-
noted as S ). Note that we only select Classes entity
from the domain model because we want the concep-
tual classes that can be mapped with the concepts in
requirements.

Then in Phase II, we ﬁrstly embed the domain model
and requirements with Knowledge Model and Require-
ment Model. Then align them based on our Alignment
Model and complement the domain model with require-
ments through relationship deduction.

Then in the third phase, we analyze the occurrence
of the mapped entities in the domain model from sev-
eral aspects, including their abstract levels in the model
graph, their distributions, and other characteristics. These
regularities are expected to narrow down the scope of
missed concepts recommendation in requirements be-
cause not all of the missing concepts are valuable.

Finally, based on our regularity, we give our initial
ideas about the missing information recommendations

4

Ziyan Zhao,Li Zhang,Xiaoli Lian

and use the 30% requirements to verify our method.
Due to the stochastic elements during the 7:3 parti-
tion, we perform the whole process (i.e., Phase I-III) 30
times and calculate the average values on all measure-
ments, including the mapping rate and all recommen-
dation metrics.

RQ6: To what extent can the missing require-
ments recommendation be improved through the
completion domain model? We would like to ex-
plore the eﬀectiveness of the domain model completion
on the missing requirements recommendation with our
proposed regularities.

3.2 Research Questions

3.3 Introduction of the Case Domains

RQ1: What is the overlap ratio between the
open domain model and software requirements?
To study the degree of association between requirement
speciﬁcations and the open domain model, we propose
using a mapping rate to indicate whether there is a re-
lationship between them and the degree of association.
We think it is an essential and vital sign to help to judge
whether the domain model is useful for the requirement
improvements.

RQ2: To what extent the mapping relation-
ship between open domain model and software
requirements can be built automatically? It is
tedious to build the mapping relation manually. There-
fore, we propose a method of automatically building
mapping relation and comparing it with manual con-
struction.

RQ3: To what extent that the 70% require-
ments can complement the domain model to in-
crease the gap between open domain model and
the requirements of one speciﬁc system? Con-
sidering the limited overlap between the open domain
model and software requirements, we would like to com-
plete the domain model with the known requirements
and explore the extent of the completion for the overlap
increase.

RQ4: Are there any distribution regularities
of the overlapped entities which are potentially
useful for the missing requirements identiﬁca-
tion? We primarily focus on three aspects: 1) the entity
types in the domain model (i.e., Classes, Properties or
Name Individuals); 2) the position of the entity concept
(i.e., root, intermediate or leaf node); and 3) the local
clusters of conceptual entities in the domain model. We
attempt to detect the focus of requirements by analyz-
ing its covered scope in the domain model, expecting to
narrow down the scope of missing function recommen-
dations.

RQ5: To what extent can the regularities be
used as hints about missing requirements rec-
ommendation? We would like to evaluate whether the
regularity can be used for missing requirements recom-
mendation. In other words, to what extent that the
missing requirements conform to the regularities?

Note that the quality of open domain models must be
varied signiﬁcantly and we can’t just use a random one.
Actually, we make an easy ﬁltering. We need require-
ment sets and the corresponding domain models, which
almost depict the same perspective of the domain with
requirements (e.g., functions, concepts), although its
scope can be much more signiﬁcant. We obtain all of the
objects of our study via public search engines (mainly
Google).

It is much easier to collect software requirements
than a domain model online. Thus, we prepare a set
of software requirements ﬁrst and then search for the
available domain models one by one. There are a few ex-
cellent open repositories of software requirements, such
as the creation from the group of Center of Excellence
for Software & Systems Traceability (COEST)1 and
the RE resources collected by the requirements engi-
neering group at the University of Technology, Sydney
(RE@UTS)2. We download and scan each requirement
document in these two repositories to learn the require-
ments’ perspectives and obtain the basic domain search
query. Then we attempt to ﬁnd appropriate domain
models via Google by the search queries like “domain
model” OR ontology OR “knowledge graph” AND basic
domain query (such as “drone”). In this paper, we re-
fer to Ontology, Domain Model, and Knowledge Graph
as Domain Model. For the convenience of processing,
we use Resource Description Framework (RDF)[20], a
data model commonly used in the knowledge graph, to
represent the domain model [24]. Finally, we ﬁnd 12
models which can be matched with the existing soft-
ware requirements.

We select two domains for this study based on three
considerations. 1) We should be familiar with the do-
mains to evaluate the concepts mapping and the later
missing functions recommendation. 2) The domain model
should be related to software system development and
should be close to the software requirements as much
as possible. Moreover, 3) more complete domain models
would be selected if there are multiple versions of the
same model.

1 http://coest.org/datasets
2 http://research.it.uts.edu.au/re/cgi-bin/resources srs.cgi

Title Suppressed Due to Excessive Length

5

Fig. 1: The procedure of our study

The two case studies for this current study are Un-
manned Aerial Vehicle (UAV, noted as Case A) and
Building Automation System (BAS, noted as Case B).
Case A: The open domain model3 of UAV includes
400 entities and 146 Classes entities. The requirements
are from the University of Notre Dame4[5] include 99
functional requirements.

Case B: The open domain model of BAS5 includes
484 entities, all of which are Classes entities. Moreover,
the requirements are from the Standard Building Au-
tomation Service (BAS) Speciﬁcation(2015) [35] con-
sisted of 456 functional requirements.

We randomly select 70% (i.e., 70 requirements in
Case A and 320 requirements in Case B) for the map-
ping construction and the regularity analysis. And the
remaining 30% (i.e., 29 requirements in Case A, 136
requirements in Case B) are used in the initial useful-
ness evaluation of the regularity for missing functional
recommendation.

During the process of data collection, we build an
initial repository of 117 open models. We public these
models as well as the 12 suites of domain model and
software requirement descriptions via Github 6.

4 Phase I: Mapping Construction

According to Fig. 1, during phase I, we mainly perform
two tasks, including salient concepts extraction from

3 http://www.dronetology.net/
4 https://dronology.info/
5 https://gitlab.ﬁ.muni.cz/ xkucer16/semanticBMS
6 https://github.com/ZacharyZhao55/Open-Domain-

Model

NL requirements and domain models, and the map-
ping construction between domain and requirements
concepts.

4.1 Extracting Concepts and Entities

Open domain models usually include entities of diﬀer-
ent categories. In OWL ontology language rules, com-
mon categories include “Classes,” “Object Properties,”
“Named Individuals,” and so on. To build a mapping of
conceptual entities between the domain model and re-
quirements, as shown in the Fig. 1, we extract all of the
entity concepts in the “Classes” of the domain model
and represent them with ClassesTerms (CT ). Besides,
we need to extract the concepts from the NL require-
ments. We use the terms extraction method for this
task because of the similar semantic between “term”
and “concept”, according to their deﬁnitions [33], [15],
[30]. We denote the concepts extracted from require-
ments as RequirementTerms (RT ).

It is easy to ﬁlter and obtain the entity concept from
the domain model by retrieving its topology. We are
more focused on the concepts extraction from require-
ments.

Brieﬂy, there are three commonly used terms extrac-
tion methods from the text: rule-based, statistics-based,
and the combination of these two kinds of approaches.
The rule-based approaches usually explicitly build rules
based on linguistic knowledge such as Part-of-Speech
(POS) and lexical patterns. Due to the relatively full
analysis of the similar domain corpus, these approaches
tend to present signiﬁcantly better extraction accuracy.
However, their generality is poor, and most of them are
tightly coupled with domains, corpus, and languages

Open Domain Model（S）70% Randomly-selectedRequirements(R)Entities in S(Se)Concepts in R(Rt)Open Domain ModelRequirementsEntity_1Entity_3Entity_2Entity_4Entity_5Term_1Entity_6Term_3Term_4Mapping between Sand RRtSeMRegularity of Mapping Entities in SMissing Concepts Recommendation for the remaining 30% of R Phase I: Build the mapping between the conceptsof requirements  and the entities of domain modelPhase III: Analyze the distribution regularity of the mapped entities in domain model①extract conceptsin requirements②Map the entities in S and the concepts in R④Analyze the regularity of concepts mapping for missing concepts recommendationRQ1 ,RQ2RQ3RQ5EmbeddinginKnowledgeModel EmbeddinginRequirementModelAlignment Model Domain Model（S2.0）Domain Model CompletionEmbeddingsize…EmbeddingsizePhase II:Jointthe requirements and domainmodel into a vector space and complete the domain modelRQ4…③Completethe  domain modelDomain ModelCompletion6

Ziyan Zhao,Li Zhang,Xiaoli Lian

[39]. Generally, the statistics-based approach explores
the distribution statistical properties of terms in the
corpus with statistical theory guidance, such as fre-
quency [37,31], TF-IDF[4], Domain Relevance and Do-
main Consensus[36], Mutual Information[8], and Log-
likehood[18,6]. These methods have strong universal-
ity and are not limited to speciﬁc domains or corpus.
However, the reliability of the analysis largely depends
on the quality of the corpus. In this work, we select
one hybrid approach because it has the advantage of
high accuracy and domain independence meanwhile,
the advantages of the above two kinds of approaches
[39]. To be speciﬁc, we use the C-Value method [16], a
widespread and eﬀective way for term extraction, which
elegantly combines grammatical rules and statistical in-
formation.

Brieﬂy, C-Value selects the Multi-Word Terms (MWT )

from the corpus through two steps. Firstly, it obtains
all candidate terms based on a series of linguistic ﬁlters
for the nested noun selection, such as N oun+N oun, as
well as a stop-word ﬁlter. Then it assigns a termhood
measure to all candidate strings by considering their to-
tal frequency of occurrence, their frequency as part of
other longer candidate terms, the number of the longer
candidate terms, and their length (i.e., words). The ﬁnal
terms whose termhood is above a predeﬁned threshold
would be selected as the concepts of requirements.

As shown in Table. 1, we extracted concepts from
70% of the requirements of the two cases. For the 70
requirements of UAV, 77 concepts are extracted auto-
matically, and 53 ones are remained after manual check-
ing. For the 320 requirements of BAS, 167 concepts are
automatically extracted, and 145 ones are kept after
manual checking. Most of the ﬁltered terms are incom-
plete concepts with only part of semantic.

to look for lots of external domain data to bridge the
synonymous relationship. So, we crawl domain docu-
ments extensively online from Google by combining the
domain name and the high-frequency terms and entities
of requirements and domain model. Finally, ten docu-
ments are sorted out from the retrieved results for each
of the cases, with the average size of each corpus being
1000 sentences and 25,000 words.

When obtaining the domain corpus, we ﬁrst extract
Multi-Word Terms from them using the above approach
of section 4.1. Then, the terms from the domain corpus,
the requirements, and domain models are represented
with embedding vectors. Finally, we calculate the sim-
ilarity between them [19].

Most domain concepts are composed of multiple terms.

However, most of the research on term similarity fo-
cus on individual words [23], and very little work can
be used for synonymous Multi-Word Terms detection.
Fortunately, we ﬁnd one good approach of Hazem [22]
which detects the synonymous relation between MWT
with the same head or tail parts based on the similar-
ity calculation on word embeddings. However, Hazem’s
MWT model of two parts of head (E) and tail (T)
doesn’t work for longer terms. Thus, we make a sim-
ple extension by adding middle (M) element to their
deﬁnition.

M W T = (E; M ; T )

(1)

In line with our MWT deﬁnition, we deﬁne four
basic inference rules for synonymous extraction. Let
two terms be M W T1 = (E1; M1; T1) and M W T2 =
(E2; M2; T2), and syn(M W T1; M W T2) be a synonym
relation between them, the inferences rules can be for-
mulated as:

4.2 Mapping Requirement Concepts with Domain
Entities

After the concepts and entities are extracted from the
requirements and domain model, we need to build the
mapping between them.

Two steps are involved. Firstly, we compare the
names of entities and terms and build a direct mapping
between them. However, synonyms can be commonly
found due to the diverse scope and background of the
open domain model and software requirements. Thus,
we also design to detect the synonymous relationship
as a supplement to step one. Due to the limited space,
we put more words on the synonymous detection-based
mapping construction here.

Considering the sparse semantic information in both
software requirements and the domain model, we need

R1 : T1 = T2 (cid:54)= ∅ ∧ M1 = M2 ∧ syn(E1, E2) ∧ E1 (cid:54)=
∅ ∧ E2 (cid:54)= ∅ ⊃ syn(M W T1, M W T2)
R2 : E1 = E2 (cid:54)= ∅ ∧ M1 = M2 ∧ syn(T1, T2) ∧ T1 (cid:54)=
∅ ∧ T2 (cid:54)= ∅ ⊃ syn(M W T1, M W T2)
R3 : E1 = T2 (cid:54)= ∅ ∧ M1 = M2 ∧ syn(T1, E2) ∧ T1 (cid:54)=
∅ ∧ E2 (cid:54)= ∅ ⊃ syn(M W T1, M W T2)
R4 : E2 = T1 (cid:54)= ∅ ∧ M1 = M2 ∧ syn(T2, E1) ∧ T2 (cid:54)=
∅ ∧ E1 (cid:54)= ∅ ⊃ syn(M W T1, M W T2)

The above four rules follow a straightforward prin-
ciple. Once two parts of the two Multi-Word Terms are
equal (one of them can be empty), and the remaining
ones are synonymous, the two terms are synonyms. The
synonymous relation between a single word in the three
parts is determined based on the general dictionary, like
WordNet. Taking the ﬁrst R1 as an example, given both

Title Suppressed Due to Excessive Length

7

Table 1: Number of concepts extracted from NL requirements

Case #Concepts of auto-extraction #Concepts after manual checking

Examples

UAV

BAS

77

167

the heads and tails of two MWTs, if they are not empty,
and their heads and middle parts are equal respectively,
the heads are synonymous in a general dictionary. We
consider these two MWTs are synonyms. The rules can
be extended. For instance, the three parts can be rep-
resented as three ﬁner elements for very complicated
terms.

Like most word embedding-based similarity calcula-
tion approaches, the terms that are not synonymous but
occurred with high frequency are inevitably selected.
Therefore, manual screening is required.

Our synonyms detection results on the terms of 70%
requirements and entities of the domain model are shown
in Table. 2. For the UAV case, there are 14 pairs of syn-
onyms automatically extracted, and ten pairs were kept
after manual checking. And for the other case, 11 pairs
were automatically extracted, and eight ones were kept.
Based on the results of term extraction and syn-
onyms detection, we can build the mapping between
the terms of 70% requirements and the entities of the
domain model and calculate the mapping rate. The re-
sults are shown in Table. 3.

Addressing RQ1: For the UAV case, 53 terms
were extracted from 70 requirements, of which 23 map-
ped entities in the domain model, 43.4% of the mapping
rate. For the BAS case, 145 terms were extracted from
320 requirements, and 29 ones can be mapped with the
entities of the domain model, with a mapping rate of
20%. The mapping rate of BAS is lower than that of
UAV. The main reason is that the scope of BAS is more
signiﬁcant than that of UAV. We found that the ab-
stract nodes in the UAV domain model accounted for
5.4% of the Classes, while the abstract nodes in BAS
accounted for 8.68%. We believe that the number of ab-
stract nodes is proportional to the scope of the domain
model. Since the functional scope of requirements usu-
ally is small, it makes sense that the number of mapped
entities of BAS is less than that of UAV.

To address RQ2, we compare a set of automated
approaches on the mapping construction, shown in Ta-
ble.4. To evaluate the performance of our approach (i.e.,
C-Value+synonym detection), we select the naive Nonus

53

145

UI Middleware, Object
Avoidance System, Flight
Pattern, Takeoﬀ Command
Air Conditioning, Building
Controller, Advanced
Application Controllers,
Building Control Unit

extraction (including Nouns(NNs) and Noun Phrases(NPs))
and mapping, term extraction-based mapping (pure C-
Value) as the baselines. The simple Nouns extraction
is selected because it is commonly used in concepts ex-
traction [21]. And we compare the results of pure C-
Value to prove the necessity of using entity concepts
and synonym extraction methods. The results of these
three automated approaches are compared with those
of manual constructions.

Addressing RQ2: The column of Mapping rate
in Table.4 shows that our approach of the combina-
tion of C-Value-based direct mapping and synonymous-
based mapping yields much better results than all of the
baselines (highlighted with bold font) for both two do-
mains. By comparing the results of C-Value-based map-
ping and the combination with synonymous-based map-
ping, we ﬁnd the mapping rates increase by 18.87% and
5.52% respectively for the domains of UAV and BAS,
indicating that our synonymous extraction-based enti-
ties mapping is a solid supplement to the term-based
indirect mapping. Meanwhile, we can see that the ap-
proach of NNs and NPs extraction can obtain the most
signiﬁcant number of concepts. However, its mapping
rate is noticeably lower than the other approaches be-
cause it generated lots of short simple nouns and missed
some multi-word terms, which are very likely the con-
cepts.

5 Phase II: Domain Model Completion

According to Fig. 1, in Phase II, we jointly embed the
domain model and requirements into the same vector
space and then complete the domain model by merging
parts of the entities in requirements and constructing
the relationships between them and those already in the
domain model.

8

Ziyan Zhao,Li Zhang,Xiaoli Lian

Table 2: Number of Synonyms Extracted in Our Two Cases

#Synonym Pairs of
Auto-extraction

#Synonym Pairs After
Manual Checking

Examples

14

11

10

8

{takeoﬀ altitude, home altitude}
{ﬂight pattern, ﬂight phase}...
{alarm panel, alarm console}
{pressure gauge, pressure rating},...

Case

UAV

BAS

Table 3: Mapping Results of the 70% Requirements with Open Domain Model

Case Terms in 70% REQs Mapped Entities Mapping Rate
UAV
BAS

43.4%
20%

53
145

23
29

Table 4: Mapping Rate of Diﬀerent Approaches

Case

UAV

BAS

Methods
NNs,NPs
C-Value
C-Value+ Synonym
Manual
NNs,NPs
C-Value
C-Value+ synonym
Manual

#Entities in REQ #Mapped Entities Mapping Rate

135
53
53
56
452
145
145
150

15
13
23
27
12
21
29
38

11.11%
24.53%
43.40%
48.21%
2.65%
14.48%
20%
25.33%

5.1 Two Assumptions about the Domain Model and
Requirements

With regards to the coverage of requirements, there
may be two conditions about the open domain model.
Condition I: The entities are complete and
some relationships between entities may be miss-
ing. To be speciﬁc, all the concepts in requirement can
be found in the domain model, either the exact same
expressions or synonyms identiﬁed in phase I. But there
may be extra relationships between some entities in re-
quirements, but not in the domain model.

Condition II: Some entities may be missing.
To be speciﬁc, some concepts in requirements are lack-
ing in the domain model. In this case, the corresponding
relationships between these concepts must be missing
too.

Requirements can be used to complete the domain

model for the above two conditions.

5.2 Joint Embedding

We embed the open domain model and requirements
into the same continuous vector space based on the ap-
proach of Huaping at el.[40,38]. We select this approach
because it does not rely on any external data resource

and has good performance on the data sets of diﬀerent
sizes [40,38].

Generally, both the domain model and requirements
are modeled ﬁrstly as fact triples (i.e., knowledge model
and Requirement model ) respectively. Then we adjust
their vectors to align them into the same vector through
a alignment model.

Knowledge Model The domain model is modeled
as a set of fact triplets (h, r, t), where h, t ∈ E(the set
of entities) and r ∈ R(the set of relations), depicting
the relation r between h and t. The whole set of the
fact triplets in a domain model is annotated as (cid:52). The
conditional probability of a fact (h, r, t) is deﬁned as:

P r(h|r, t) =

exp{z(h, r, t)}
˜h∈I exp{z(˜h, r, t)}

(cid:80)

(2)

in [40,38], where z(h, r, t) = b− 1

2 (cid:107)h + r − t(cid:107)2, and b
is a constant for bias designated for adjusting the scale
for better numerical stability. The model both deﬁnes
P r(r|h, t) and P r(t|h, r) in the same way with normal-
ization respectively. The likelihood of observing a fact
triplet is deﬁned as:

Lf (h, r, t) = logP r(h|r, t) + logP r(r|h, t) + logP r(t|h, r)

(3)

Title Suppressed Due to Excessive Length

9

The goal of the knowledge model is to maximize the
conditional likelihood functions of the existing triples
(h, r, t) in the domain model:

493 triplets with 484 entities and only one subClassOf
relationship. And there are 137 and 958 terms in 70%
of UAV and BAS requirements.

LK (h, r, t) = −

(cid:88)

Lf (h, r, t)

(h,r,t)∈(cid:52)

(4)

5.3 Domain Model Completion

Requirement Model If two terms w and v co-
occur in a requirements, we assume that there is a re-
lationship rwv between w and v, and we use (w, rwv, v)
to represent the relation between w and v. The set of
terms in requirements includes the MWT extracted in
Section 4.1 and also the remaining nouns which appear
as unique semantic units in any requirement or window.
We annotate the term set as V.

The probability of term pair w and v co-occurring

in a requirement can be deﬁned as:

P r(w|v) =

exp{z(w, v)}
˜w∈V exp{z( ˜w, v)}

(cid:80)

Then the loss function of requirement model is

LR(w, v) = −

(cid:88)

logP r(w|v)

(w,v)∈(cid:52)

(5)

(6)

Alignment Model The alignment is performed based

on the same expression or synonymous relationship be-
tween the entities in domain model and the terms in
requirements. To be speciﬁc, for a fact triplet (h, r, t) ∈
(cid:52), if the name of entity h equals with or is synony-
mous with wh ∈ V according to the results in Section
4.1, then generate a new triplet (wh, r, t). Similarly, if
the names of entity t and wt are the same or synony-
mous and wt ∈ V, generate (h, r, wt) and (wh, r, wt).
The loss function of alignment model is

LA = −

(cid:88)

(h,r,t)∈(cid:52)

I[wh∈V]∧wt∈V · Lf (wh, r, wt)

+ I[wh∈V] · Lf (wh, r, t) + I[wt∈V] · Lf (w, r, wt)

(7)

Considering the above three parts, the likelihood
function of the joint learning model can be deﬁned as:

L = LK + LR + LA

(8)

The target of domain model completion is to add the
concepts in requirements satisfying the following two
conditions to the domain model meanwhile: 1) the con-
cepts appear in requirements but not in the domain
model, and 2) each of them has parent-child relation-
ship (usually hasSubClasses or subClassOf ) with at least
one entity in domain model. To achieve this goal, we
need to explore the relationship types between these
requirement concepts and the domain entities, and also
between the newly added requirement concept and the
existing added ones.

According to Section 5.2, we can infer that in a fact
triplet (h, r, t), the relation vector r can be represented
as r = (t − h). Considering that after alignment, each
entity of requirements and domain models has been as-
signed a vector, we can infer the relationships to be
added based on this triangular law.

However, through the vector subtraction, we can
only infer that there may be certain relationship be-
tween two entities. We can’t know the relationship types
and they are critical for the missing requirement recom-
mendation.

We assume that the angles between the pairs of two
entities with the same relationship should be the same.
Let the same relationship exist between entities a and
b, c and d. The cosine value of the angles between (cid:126)a
and (cid:126)b, between (cid:126)c and (cid:126)d should be equivalent. With
this assumption, we identify the requirement entities
with required parent-child relationships with the do-
main model entities or already added requirement en-
tities.

Obviously, the added entities and relationships will
change the structure of the original domain model. Es-
pecially, lots of “root” nodes will be identiﬁed, violating
the original “one-root” top-to-bottom design of the do-
main model. Therefore, we make a compromise by re-
garding all added entities as the children of some related
domain model entities. To be speciﬁc, for a to-be-added
requirement entity Re, which is the parent of a domain
model entity De according to our computing,

Before the alignment, we initialize the vectors of fact
triplets in the knowledge model and requirement model
with random integers generated by a uniform distribu-
tion. Overall, there are 1567 triplets in the UAV do-
main model, consisting of 400 entities and 14 relation-
ship types. And for the BAS domain model, there are

– if it doesn’t have any parent-child relationship with
other requirement entities, we add it as one child of
De.

– if it is the parent of an requirement entity Re’ which
is also the child of De, we adjust the original struc-
ture of Re → De → Re(cid:48) to De → Re → Re(cid:48).

10

Ziyan Zhao,Li Zhang,Xiaoli Lian

In the original UAV domain model, the relation-
ship number is 1567, including 123 hasSubClasses re-
lationships. After completion, 311 hasSubClasses rela-
tionships are supplemented, making the total of 434.
For BAS, there are 493 subClassOf relationships in the
original domain model, and 641 subClassOf relation-
ships are supplemented after completion, making the
total relationships of 1135.

While obtaining the complemented domain models,
we recalculate the number of mapped entities between
the requirements and domain model, as shown in the
Table. 5. The mapping is also performed by the C-
Value+Synonym method in Section 4. Considering the
stochastic performance of the alignment model, we run
the model alignment + completion 30 times and obtain
the average values as the mapping results.

We can observe that the rate of the mapped entities
in all entities is about 75.47% and 71.72%, increasing by
30%-50% compared with the results in Table. 3. Mean-
while, we can see that neither of them reaches 100%,
which means that some entities in requirements cannot
be mapped to the domain model due to the missing
relationships between them and the domain model en-
tities. Besides, we are clear that a higher mapping rate
does not mean better recommendations because of the
unclear associations between the entities in the 70% re-
quirements and the remaining 30% ones. So the further
experiment is critical.

Addressing RQ3: By aligning the requirements
and domain model and completing the domain model
with requirements, the mapping rates of domain model
and requirements in the two cases are 75.47% and 71.72%,
increasing by 32.07% and 51.72%.

6 Phase III: Regularity analysis

In this phase, we analyze the distribution regularity of
the mapped entities, both from the occurrence in the
domain model and requirements. Then we give our ini-
tial idea about the missing function recommendation
according to the regularity and answer the RQ4.

6.1 The Distribution of Mapped Entities in Domain
Models

Generally, the mapped entities only account for a small
proportion of the domain model because of the spe-
ciﬁc focus. For example, when implementing the ob-
stacle avoidance function of a UAV, its battery control
function may not be considered. Therefore, the recom-
mending scope in the domain model should be narrowed

down to more accurately lock the missing functions tar-
geted by the requirements. We analyze the distribution
regularity of the mapped entities with the purpose of
more accurate recommendations. The regularities are
analyzed from the following four aspects.

The type of entities in domain model : As we
mentioned in Section 4.1, according to the OWL stan-
dard, the elements in domain model can be typically
divided into multiple categories: Classes, Object Proper-
ties, Data Properties, Named Individuals, and Annota-
tion Properties. Classes provide an abstraction mecha-
nism for grouping resources with similar characteristics
[2]. Named Individuals represent the objects in a do-
main, i.e., instances of Classes. Properties (also called
as Object Properties) represent a kind of relation be-
tween individuals. Data Properties link individuals to
data values. Annotation Properties, which is a kind of
metadata, can be used to interpret Classes, individuals,
object/Data properties.

We explore the types of mapped entities in the orig-
inal domain model and the model after completion and
make observations based on the two cases.

– For UAV:

– In the original domain model, there are 400 en-
tities in total, and 146 ones are the types of
Classes, accounting for 36.5%. In the 53 terms
from 70 requirements, there are 23 mapped to
the domain model entities, 21 of which are Classes
(i.e., 91.3%), and the remaining two are Named
Individuals.

– In the completion domain model, there are 548
entities in total, and 294 ones are with the type
of Classes, accounting for 53.64%. In the 137
terms from 70 requirements, 40 can be mapped
to the domain model, 38 of which are Classes
(i.e., 95%).

– For BAS:

– In the original domain model, there are 484 en-
tities, and all of them are the types of Classes.
So, all of the mapped entities are Classes. In the
145 entities in 320 requirements, 29 can be map-
ped with the entities in the domain model, all of
which are Classes.

– For the completion model, there are 1135 enti-
ties, and all of them are types of Classes. All of
the 104 mapped entities are Classes.

Title Suppressed Due to Excessive Length

11

Table 5: Mapping Results of the 70% Requirements with the Completion Domain Model

Case #Entities in REQ #Mapped Entities Mapping Rate
UAV
BAS

75.47%
71.72%

53
145

40
104

Observation I: More than 90% of the map-
ped entities between software requirements and
the open domain models are of the Classes en-
tities in the original domain model. And in the
completion domain model, more than 95% of
the mapped entities are of the Classes type.

The distribution of mapped entities in do-
main model : We attempt to observe the mapping reg-
ularity from their distribution on the graph of the do-
main model. For this purpose, we select and show the
sub-trees of the original domain model, which contain
the most concentrated mapped entities, highlighted with
the yellow background, shown in Fig. 2 and 3.

We can ﬁnd that the mapped entities tend to be leaf
nodes from these two ﬁgures. We calculate the ratio of
leaf nodes in all mapped entities in the two domain
models, shown in Table. 6. For the UAV case, in the 23
mapped entities, 17 are leaf nodes, two abstract con-
cept entities, and four intermediate nodes. Leaf nodes
account for 73.9% of all mapped entities. Moreover, 29
mapped entities for the BAS case include 21 leaf nodes,
eight intermediate nodes, and one abstract concept en-
tity. Leaf nodes account for 72.4% of mapped entities.
In the two completion domain models, the ratio of
the mapped leaf entities has an obvious improvement
(about 15%). The reason is simple during the model
completion, most of the requirement entities were added
as the leaf nodes of the domain model (seen in Section
5.3).

Observation II: More than 70% mapped en-
tities are leaf nodes in the trees of domain
models. Besides, the terms of software require-
ments usually appear in a few sub-trees, re-
ﬂecting speciﬁc focuses. And more than 85%
mapped entities are leaf nodes in the trees of
our two completion domain models.

The family belonging of the mapped entities
in domain model : From Fig. 2 and 3, we can also see
that the distribution scope of the mapped entities in
the domain model tends to be concentrated in multiple
child nodes under one or several intermediate nodes.

This phenomenon is in accordance with our hypothe-
sis that there is always a few particular focuses on the
requirements of a speciﬁc version of software products
rather than the entire domain. This observation inspires
us ﬁrst to capture the focus of the existing software re-
quirements when recommending the missing functional
points. With these belongings, we can signiﬁcantly re-
duce the search scope of missing information. For ex-
ample, in Fig. 2, there are 46 entities in the red dashed
box, while the number of class entities in the entire
UAV domain model is 146, accounting for 31.5% of the
total. In Fig. 3, the number of entities contained in the
red dashed box is 33, and the number of class entities
in the BAS domain model is 484, accounting for 6.82%.
In other words, the belonging scopes are helpful for the
speciﬁc missing information retrieval.

Domain models typically associate parent and child
nodes in the form of the tree structure. However, while
performing further analysis, we can see no direct parent-
children relationship between many mapped entities.
Still, they probably have the same parent or ancestor
(e.g., Actuator and Alarm). To explore the focuses of
software requirements, ﬁnding a common ancestor be-
longing to the most mapped entities is necessary. This
ancestor should be far from the root, and its level should
be as high as possible (to be more speciﬁc). We want
to recommend the missing entities in the tree with the
root of this ancestor. Thus, we propose a metric AHME
(the Ancestors of the Highest level with most Mapped
entities) for locating the entity that can be the parent
or ancestor of the most mapped entities and is at the
highest level of the domain model. It can be deﬁned
formula as follows.

AHM E =

M ED
M E

∗ LEV EL(node)

(9)

MED indicates the number of mapped entities be-
longing to the descendants of one node, ME is the to-
tal amount of mapped entities, and LEVEL(node) in-
dicates the level of this node. We calculate the AHME
value for each node in the domain model, select one or
more of the highest AHME values (not all mapped en-
tities will be included), and take that node and all its
children as the scope of the requirements in the domain
model.

12

Ziyan Zhao,Li Zhang,Xiaoli Lian

Fig. 2: Distribution of the mapped nodes in the domain model of UAV (The highlighting part with red border
is the range of the family of UAV domain model calculated by the AHME-based method)

Fig. 3: Distribution of the mapped nodes in the domain model of BAS (The highlighting part with red border
is the range of the family of BAS domain model calculated by the AHME-based method)

Title Suppressed Due to Excessive Length

13

Table 6: The levels of mapped entities in the domain models

Case Domain Model Root Node

Intermediate Node Leaf Node Proportion of Leaf Nodes

UAV

BAS

Original
Completion
Original
Completion

2
2
1
1

4
4
8
8

17
48
21
66

73.9%
88.89%
72.4%
88%

We use the metric of AHME to locate the family
belonging to the requirements of UAV and BAS in their
corresponding domain model.

For the original UAV domain model, we ﬁrst cal-
culated the AHME values for all Classes entities and
found that the AHME values of MissionElement, Re-
moteParameter, and SensorParameter were much higher
than other Entities. The AHME value of the MissionEle-
ment is 0.26. Its height is 1, and there are six mapped
entities in its children nodes. And the RemoteParame-
ter and SensorParameter have an AHME value of 0.43,
both with a height of 5, and two mapped entities in
their children nodes. We concluded that the informa-
tion of this requirement is mainly in the range of these
three families, with the red circle in the mapped nodes
distribution graph in Fig. 2.

Then we use the same method to analyze the AHME
values of the mapped nodes in the BAS case and ﬁnd
that the AHME values of ElectricTimeControl, Trans-
former, CommunicationsAppliance and AudioVisualAp-
pliance (highlighted with the red border in Fig. 3) is
higher than other entities, reﬂecting the overlapped con-
cerns.

Observation III: The mapped entities tend
to be contained in a few families of nodes in
the open domain model, and the root node of
these families reﬂects their focuses to a certain
extent.

6.2 The distribution of Mapped Entities in
Requirements

The mapped entities in software requirement descrip-
tions usually have some semantic relationships (for ex-
ample, the subject and object are connected by the
predicate). However, there may be no direct connec-
tion between them in the domain model but the indi-
rect path with a few hops. This diﬀerence makes the
entity-relationship-based recommendation diﬃcult be-
cause the search complexity in the worst case is expo-
nential (n × (n − 1)C 2
p , which assumes that there are
n entities in the domain model, and the entities in p

hops are considered), let alone the computation com-
plexity. Text embedding technologies may help address
this problem. In this study, we observe the distribution
of mapped entities in requirements and expect to ﬁnd
factual support for this sort of technology.

Our analysis is performed from three aspects: 1) the
proportion of requirements including mapped entities in
total requirements; 2) the proportion of requirements
containing two or more mapped entities; 3) the kinds
of dependencies between two or more mapped entities
in single requirements.

The proportion of requirements including map-

ped entities. In 70% of the UAV requirements (i.e.,70),
51 requirements contained mapped entities, account-
ing for 72.86%. In 70% of the BAS set (i.e.,320), 180
requirements contain mapped entities, accounting for
56.25%. These values reﬂect the matching degree of
the software requirements and the domain model. The
higher the values, the better of the matching degree,
and the more eﬀective recommendation based on the
model.

The proportion of requirements containing two

or more mapped entities. Of the 51 requirements
containing mapped entities of the 70% requirements of
UAV, 35 contain at least two mapped entities, account-
ing for 68.63%. For the requirements of BAS, this ratio
is 31.25%. In order to ﬁnd the reason for the big dif-
ference between the result of the 2 cases, we analyzed
the data sets of UAV and BAS and found that the in-
teraction between entities in requirements was higher
in UAV than in BAS. In BAS, the states of many enti-
ties are described rather than the interaction between
entities.

Relationship types of mapped entities in re-
quirements. To obtain the relationship types of the
mapped entities in requirements, we walked through
the requirements containing two or more entities in the
two sets. We found that most of the relationship is
subject-object (about 97.14% in the 35 requirements of
UAV, and about 99% in the 100 requirements of BAS),
and some juxtaposition relationship (AND or OR) ex-
ist too (about 11.43% in the 35 requirements of UAV,
and about 44% in the 146 requirements of BAS). These
statistics of relationship types are expected to improve
the missing concept recommendation in future.

14

Ziyan Zhao,Li Zhang,Xiaoli Lian

Observation IV: More than 60% of the re-
quirements contain mapping entities, of which
50% of requirements contain multiple mapped
entities. The entities are usually in (subject-
object) relationships, and part is juxtaposition
relationships connected by (AND, OR).

Addressing RQ4: By analyzing the mapped terms
between requirements and the open domain models in
two case domains, we made four observations (i.e., regu-
larities) from the entity type, node distribution, family
belonging in the domain model, and three frequency-
related characteristics in requirement statements. The
analysis of two case domains illustrates that these reg-
ularities may potentially help recommend and reduce
the searching scope of the missing information in re-
quirements regarding the plumbline of the open domain
model.

7 Veriﬁcation: Usefulness of the Regularities

To answer RQ5 and RQ6, we design an experiment. We
regard the remaining 30% requirements of the two sets
as the missing ones and recommend them according
to the 70% requirements and the open domain model.
We evaluate the usefulness of these regularities by cal-
culating the extent to which the concepts in the 30%
requirements can be recommended correctly, with the
common metrics of Recall, Precision, and F2 because
the recall is more important [3]. Recall measures the
extent to which the correct missing information can be
identiﬁed automatically. Precision measures the ratio of
correct information about missing requirements in all
automated recommendations. Considering the stochas-
tic overlap between the selected and remaining require-
ments, we run the experiments 30 times to obtain the
average values of the metrics.

In this study, we only evaluate the eﬀectiveness of
the distribution regularities in the (original and com-
pletion) domain model, and those in requirements will
be explored in the future.

The measurement results on the original domain
model are shown in Table 7. In this table, we evaluate
the eﬀectiveness of each single regularity and the combi-
nation of them in the two domains. For the convenience
of comparisons, we also calculate the three metrics of
recommendations without using any of our regularities,
shown in the ﬁrst row. From the columns of F2, we can
see that our regularities are indeed helpful for the miss-
ing information recommendation (with better F2 than
that without regularities). In addition, we can also see

that the recall values tend to decrease from top to bot-
tom. In other words, most of the concepts in the miss-
ing 30% requirements can be mapped to the Classes
entities (87.5% for UAV and 100% for BAS). However,
most of the Classes entities cannot be mapped to the
concepts in requirements (i.e., the Precision values are
very low) due to the pretty sparse mapping. Thus we
need more strong strategies to help reduce the scope of
recommendations. Similar results can be obtained from
the row of node type.

Luckily, we can see that the family belonging based
on our AHME is the most eﬀective regularity yielding
the best recall and precision values. Considering the
overlapping ratio between the 70% requirements and
the original domain model (i.e., 43.4% for UAV and 20%
for BAS seen in Table. 4), we think the recommendation
based on the AHME is reasonable. It also reﬂects that
as parts of the requirements of one speciﬁc software sys-
tem, both the missing and existing requirements focus
on the same group of concerns. One possible reason is
that we split the whole existing requirements into two
parts, and for the “real ” missing requirements recom-
mended in practice, the phenomenon may be diﬀerent,
which needs further exploration.

Due to the most eﬀective of the family belonging
regularity seen from the Table. 7, we further measure
to what extent we can recommend the missing infor-
mation that should be in the family zone according to
this regularity with the recall, Precision and F2, shown
in Table. 8. Recall measures the ratio of concepts we
correctly identiﬁed as the family belonging, and Pre-
cision measures the extent of correct recommendations
according to the family belonging. We can see that the
recommendations are much better than the results in
Table. 7. Particularly, almost all of the entities, which
should be recommended, can be identiﬁed, although the
mapping is sparse and the entity number is therefore
small.

From Table. 7, we can also see that the simple com-
bination of the regularities does not make a signiﬁ-
cant improvement on the recommendation, although
the Precision gets slightly better than that of the pure
Family Belonging (seen in Table. 7). This triggers a
better combination approach in the future.

In order to evaluate the eﬀectiveness of the comple-
tion model on missing requirement entities recommen-
dation (addressing RQ6), due to the best performance
of the pure family belonging regularity, we perform the
recommendation on it, shown in Table. 9. With the con-
venience of comparisons, we also compute the gains of it
on the three metrics than the recommendation with the
AHME family belonging to the original domain model.

Title Suppressed Due to Excessive Length

15

Table 7: The eﬀectiveness of our regularities for missing information recommendation in the two cases (Original
Domain Model)

Regularity

UAV

Recall Precision

Without Regularities
Entity Type
Node Type
Family Belonging
Regularity Combination

1.0
0.875
0.7
0.32
0.21

0.03
0.112
0.07
0.16
0.18

BAS

Recall Precision

1.0
1.0
1.0
0.5
0.5

0.04
0.071
0.091
0.24
0.24

F2
0.17
0.28
0.33
0.41
0.41

F2
0.13
0.37
0.25
0.26
0.20

Table 8: The recommendation eﬀectiveness with the scope of Family Belonging in the original domain model

Family Belonging
Mission Element
Remote Parameter
Sensor Parameter
Average

UAV

Actually/Should have Recall Precision

6/7
2/2
2/2

BAS

0.857
1.0
1
0.9

0.18
0.25
0.25
0.21

Family Belonging
Electric Time Control
Transformer
Communications Appliance
Audio Visual Appliance
Average

Actually/Should have Recall Precision

3/3
3/3
2/3
3/3

1.0
1.0
0.67
1.0
0.91

0.75
0.67
0.17
0.27
0.37

F2
0.49
0.63
0.63
0.54

F2
0.94
0.91
0.42
0.65
0.70

Due to the expansion of the domain model, more
entities are involved. Due to the unknown associations
between the 70% requirements and the remaining 30%
ones, this probably brings more noise for the recom-
mendation. In addition, it is possible that the open
domain model can’t cover the remaining 30% require-
ments, even after completion. This means that more
false-positive results would be most likely to be rec-
ommended. Thus, one potential problem of the domain
model completion for the missing recommendation is
the lower precision. However, from Table. 9, we can
see that the improved approach obviously increases the
recall (with the gains of 41% for UAV and 72% for
BAS) with almost no loss of precision (2% for UAV
and 1% for BAS). After analysis, we ﬁnd that the 70%
requirements indeed extend the family belongings, and
meanwhile, the added entities provide more strong hints
about the entities in the missing requirements.

Besides comparing the recommendation with our
full approach (i.e., family belonging in the extended
domain model) in Table. 9 and the recommendation
without any regularity in the original domain model in
Table. 7, we can ﬁnd that our approach yields the F2
gains of 146% in UAV and 223% in BAS. This is strong
proof of the eﬀectiveness of our approach in missing re-
quirements detection based on the open domain model.

In order to further illustrate the usefulness of do-
main model completion on the missing requirements
recommendation, we analyze the source of the right
recommended entities. We ﬁnd that for the UAV case,
about 23.06% right recommendations are from the orig-
inal domain model, and the remaining 76.94% are from
the extended part. In the BAS case, about 44.12% right
recommended entities are from the original domain model,
and the other 55.88% are from the extended part. These
detailed numbers also provide proof about the eﬀective-
ness of requirement associations (although uncertain)
to missing requirements recommendations.

Addressing RQ5 and RQ6: Our regularities are
indeed helpful for the missing requirements recommen-
dation, with the F2 increasing of 13%-24% than that
without any regularities. And the completion domain
model, especially with the AHME regularity, can ob-
viously help improve the recommendation with the F2
gains of 23% and 34% in the two cases, than that with
the original domain model using the same regularity.
What’s more, using the AHME regularity in the com-
pletion domain model can reach obvious outperformance
than the recommendation with no regularity in the orig-
inal domain model, with the F2 gains of 146% and
233%.

16

Ziyan Zhao,Li Zhang,Xiaoli Lian

Table 9: The comparison of the recommendation eﬀectiveness based on family belonging

Domain model

original model
completion model
Gain

R.
0.32
0.45
0.41

UAV
P.
0.16
0.14
-0.12

F2
0.26
0.32
0.23

R.
0.5
0.86
0.72

BAS
P.
0.24
0.23
-0.04

F2
0.41
0.55
0.34

8 Discussion

8.1.3 Conclusion Validity

In this section, we discuss the threats to validity, the
implications and the limitations of this study.

8.1 Threats to Validity

8.1.1 Internal Validity

The main threat to the internal validity of our work
is from the perspectives of regularities we select. As a
preliminary study, we only analyze the regularities from
four relatively intuitive perspectives to explore the use-
fulness of the open domain model in the missing re-
quirements recommendation. Undoubtedly, there must
be other analytical perspectives, such as the relevance
between mapped and unmapped entities and their se-
mantic dependencies. We would like to dig them in fu-
ture.

Another threat to internal validity is from the au-
tomated domain model completion. We improved the
existing approach of TransE [40] for the model align-
ment and completed the model based on angles between
entity vectors. This process is stochastic to a certain
degree. To mitigate the impact on the ﬁnal results, we
run the whole process, including the model completion
and missing recommendation 30 times, to obtain the
average values of the metrics.

8.1.2 External Validity

This study is performed based on two distinct case do-
mains. Both the domain model and requirement de-
scriptions are from diﬀerent groups, thus providing con-
ﬁdence in the external validity of our ﬁndings to a cer-
tain degree. That being said, we emphasize that our
ﬁndings are based on matching domain models and re-
quirements. As long as there is a certain degree of over-
lap, the domain model is helpful to the improvement
of the requirement completeness. Moreover, the useful-
ness degree depends on the overlap ratio and also the
strategies of recommendation.

We evaluate the eﬀectiveness of the regularities by com-
paring our recommendations with the concepts in the
30% simulating missing requirements. The results show
that the regularities can indeed reduce the searching
scope and increase the accuracy. However, due to the
very speciﬁc focus of requirements and the continuous
evolution of systems, the recommendations uncovered
by the 30% requirements may be valid too. This means
our results may have some potential eﬀects which need
further validation.

8.2 Implications

There are three lessons we learned from this study.

1) It is essential to build the mapping between the
open domain model and requirements in this work, and
the mapping results will seriously aﬀect the missing
information identiﬁcation. We used a hybrid of term-
based direct and synonymous-based indirect mapping,
and about 79%-90.0% mapping can be established cor-
rectly. Although the synonymous detection is complex
and requires more domain corpus, it is worthwhile.

2) Undoubtedly, the domain model completion spends

more time (i.e., for UAV, 20 minutes once; for BAS, 90
minutes once). Looking at the improvements on the rec-
ommendation (i.e., 23% and 34% F2 gains), we think
this process makes sense. Besides, we only show the
eﬀectiveness of the completion model on the missing
requirements recommendation, not the correctness or
domain compliance. This may need more exploration
in the future.

3) We attempt to reduce the searching scope of the
missing information in domain models according to the
four regularities. However, we did not give speciﬁc rec-
ommending algorithms. How to recommend the domain
model entities as missing information is a problem wor-
thy of research.

8.3 Limitations

In general, there are four primary limitations in this
study.

Title Suppressed Due to Excessive Length

17

The elements of domain model under anal-
ysis is limited. We only build the mapping between
the Classes entities in the domain model and the con-
cepts in requirement descriptions and didn’t consider
other types of elements of the domain model, such as
attributes of concepts. However, Arora et al. showed
that all of the entities, attributes, and their associations
of the requirement-based domain model are sensitive to
the missing requirements [1]. We would like to explore
the usefulness of other parts in the future.

Unmapped entities are not involved in our
analysis. In the two cases, unmapped entities account
for a large proportion of both domain models and soft-
ware requirements. To recommend the missing require-
ments, we focus on the mapped entities because they
illustrate the picture of what we have already. However,
the unmapped entities work as the necessary context
for these mapped entities. Therefore, it is reasonable
to expect better recommendations by considering the
semantical relationship between the mapped and un-
mapped entities.

The strategies for recommendation can be im-
proved. This preliminary study focuses on exploring
the answer of yes or no to whether the open domain
model is useful for missing requirements detection. Thus,
the regularities we propose aim to reduce the scope of
recommendation with sparse mapping considerations.
Besides the distributions of the mapped entities in the
domain model or requirements, lots of other semantical
information, such as the relevance between the entities
[41,28], can be used. We will explore this in the future.

9 Conclusion

The missing (critical) software requirements may lead
to disastrous consequences. Lots of research validate
the completeness of software requirements based on re-
quirements oriented domain models, which usually do
not exist for most domains. Fortunately, it is not diﬃ-
cult to ﬁnd domain models online constructed for vari-
able purposes for various domains. Thus we explore the
usefulness of these open domain models on the missing
requirements recommendation via two case domains,
whose requirements and domain models are from dif-
ferent groups. We proposed to establish the mapping
between requirements and the open domain model and
to complete the domain model with the known require-
ments with the purpose of closing down the gap between
them. Also, we observed four regularities of the mapped
entities to help reduce the searching scope of missing in-
formation in requirements to prove their eﬀectiveness.
Although their usefulness is relatively limited, surpris-
ingly, it helps discover missing information in the re-

quirements, especially the missing concerns. Thus, we
can say that the open domain model can be potentially
used as an eﬀective plumbline for recommending the
missing functional information. We would like to ex-
plore the automated recommendation approach in the
future.

10 Acknowledgment

*** *** *** *** *** *** *** *** *** *** *** ***

References

1. Chetan Arora, Mehrdad Sabetzadeh, and Lionel Briand.
An empirical study on the potential usefulness of domain
models for completeness checking of requirements. Em-
pirical Software Engineering, page 2509–2539, 04 2019.
2. Sean Bechhofer, Frank Van Harmelen, Jim Hendler,
Ian Horrocks, Deborah L McGuinness, Peter F Patel-
Schneider, Lynn Andrea Stein, et al. Owl web ontology
language reference. W3C recommendation, 10(02), 2004.
3. Daniel M Berry. Evaluation of tools for hairy require-
ments and software engineering tasks. In 2017 IEEE 25th
International Requirements Engineering Conference Work-
shops (REW), pages 284–291. IEEE, 2017.

4. Elena Bolshakova, Natalia Loukachevitch, and Michael
Nokel. Topic models can improve domain term extrac-
tion.
In European Conference on Information Retrieval,
pages 684–687. Springer, 2013.

5. Jane Cleland-Huang, Michael Vierhauser, and Sean Bay-
ley. Dronology: An incubator for cyber-physical system
research. arXiv preprint arXiv:1804.02423, 2018.

6. Jonathan D Cohen. Highlights: Language-and domain-
independent automatic indexing terms for abstracting.
Journal of the American society for information science,
46(3):162–174, 1995.

7. ˚Asa G. Dahlstedt and Anne Persson. Requirements Inter-
dependencies: State of the Art and Future Challenges, pages
95–116. Springer Berlin Heidelberg, Berlin, Heidelberg,
2005.

8. B´eatrice Daille. Study and implementation of combined
techniques for automatic extraction of terminology.
In
The balancing act: Combining symbolic and statistical ap-
proaches to language, 1994.

9. Fabiano Dalpiaz, Ivor van der Schalk, and Garm Lu-
cassen. Pinpointing ambiguity and incompleteness in re-
quirements engineering via information visualization and
nlp.
In Erik Kamsties, Jennifer Horkoﬀ, and Fabiano
Dalpiaz, editors, Requirements Engineering: Foundation for
Software Quality, pages 119–135, Cham, 2018. Springer
International Publishing.

10. Diego Dermeval, Vilela, J´essyka, Ig Ibert Bittencourt,
Jaelson Castro, Seiji Isotani, Patrick Brito, and Alan
Silva. Applications of ontologies in requirements engi-
neering: a systematic review of the literature. Require-
ments Engineering, 21(4):405–437, 2016.

11. Gouri Deshpande, Quim Motger, Cristina Palomares,
Ikagarjot Kamra, Katarzyna Biesialska, Xavier Franch,
Guenther Ruhe, and Jason Ho. Requirements depen-
dency extraction by integrating active learning with
ontology-based retrieval. In 2020 IEEE 28th International
Requirements Engineering Conference (RE), pages 78–89,
2020.

18

Ziyan Zhao,Li Zhang,Xiaoli Lian

29. Igor Menzel, Mark Mueller, Anne Gross, and Joerg Do-
err. An experimental comparison regarding the complete-
ness of functional requirements speciﬁcations.
In 2010
18th IEEE International Requirements Engineering Confer-
ence, pages 15–24. IEEE, 2010.

30. Beijing:Standards Press of China. Terminology work
principles and methods. Beijing:Standards Press of China,
2000.

31. Youngja Park, Roy J Byrd, and Branimir Boguraev. Au-
tomatic glossary extraction: beyond terminology identi-
ﬁcation. In COLING 2002: The 19th International Confer-
ence on Computational Linguistics, 2002.

32. Klaus Pohl. Process-centered requirements engineering.

John Wiley & Sons, Inc., 1996.

33. Juan C Sager, David Dungworth, Peter F McDonald,
et al. English special languages: principles and practice in
science and technology. Brandstetter Wiesbaden, 1980.
34. J. S. Thakur and A. Gupta. Anmodeler: A tool for gen-
erating domain models from textual speciﬁcations.
In
2016 31st IEEE/ACM International Conference on Auto-
mated Software Engineering (ASE), pages 828–833, Sep.
2016.

35. Toronto. Standard building automation system (bas)
speciﬁcation. Technical report, City of Toronto, standard
speciﬁcations, 2015.

36. Paola Velardi, Michele Missikoﬀ, and Roberto Basili.
Identiﬁcation of relevant terms to support the construc-
tion of domain ontologies. In Proceedings of the ACL 2001
Workshop on Human Language Technology and Knowledge
Management, 2001.

37. Jorge Vivaldi and Horacio Rodr´ıguez. Evaluation of
terms and term extraction systems: A practical approach.
Terminology. International Journal of Theoretical and Ap-
plied Issues in Specialized Communication, 13(2):225–248,
2007.

38. Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. Knowledge graph and text jointly embedding. In
Proceedings of the 2014 conference on empirical methods in
natural language processing (EMNLP), pages 1591–1601,
2014.

39. JS YUAN, XM ZHANG, and ZJ LI. Survey of automatic
terminology extraction methodologies. Computer Science,
42(8):7–12, 2015.

40. Huaping Zhong, Jianwen Zhang, Zhen Wang, Hai Wan,
and Zheng Chen. Aligning knowledge and text embed-
dings by entity descriptions.
In Proceedings of the 2015
Conference on Empirical Methods in Natural Language Pro-
cessing, pages 267–272, 2015.

41. Ganggao Zhu and Carlos A Iglesias. Computing semantic
similarity of concepts in knowledge graphs. IEEE Trans-
actions on Knowledge and Data Engineering, 29(1):72–85,
2016.

42. Didar Zowghi and Vincenzo Gervasi. On the interplay
between consistency, completeness, and correctness in re-
quirements evolution. Information and Software technol-
ogy, 45(14):993–1009, 2003.

12. Evans E. Domain-driven design: tackling complexity in the
heart of software. Addison-Wesley Professional, Reading,
Massachusetts, 2004.

13. Sergio Espa˜na, Nelly Condori-Fernandez, Arturo
Gonz´alez, and ´Oscar Pastor.
Evaluating the com-
functional requirements
pleteness and granularity of
speciﬁcations: A controlled experiment.
In 2009 17th
IEEE International Requirements Engineering Conference,
pages 161–170. IEEE, 2009.

14. Stefan Farfeleder, Thomas Moser, Andreas Krall, Tor
St˚alhane, Inah Omoronyia, and Herbert Zojer. Ontology-
driven guidance for requirements elicitation. In Extended
Semantic Web Conference, pages 212–226. Springer, 2011.
15. Zhiwei Feng. An introduction to modern terminology.

Language & Culture Press, Beijing, 1997.

16. Katerina Frantzi, Sophia Ananiadou, and Hideki Mima.
Automatic recognition of multi-word terms:. the c-
value/nc-value method.
International journal on digital
libraries, 3(2):115–130, 2000.

17. Michaela Geierhos and Frederik Simon B¨aumer. How to
complete customer requirements.
In International Con-
ference on Applications of Natural Language to Information
Systems, pages 37–47. Springer, 2016.

18. Alexander Gelbukh, Grigori Sidorov, Eduardo Lavin-
Villa, and Liliana Chanona-Hernandez. Automatic term
extraction using log-likelihood based comparison with
general reference corpus.
In International conference
on application of natural language to information systems,
pages 248–255. Springer, 2010.

19. Goran Glavaˇs, Federico Nanni, and Simone Paolo
Ponzetto. Unsupervised text segmentation using seman-
tic relatedness graphs. Association for Computational
Linguistics, 2016.

20. RDF Working Group. Resource description framework
https://www.w3.org/RDF/ Accessed

(rdf).
[EB/OL].
February 25, 2014.

21. HM Harmain and Robert Gaizauskas. Cm-builder: A nat-
ural language-based case tool for object-oriented analysis.
Automated Software Engineering, 10(2):157–181, 2003.
22. Amir Hazem and B´eatrice Daille. Semi-compositional
method for synonym extraction of multi-word terms. In
9th edition of the Language Resources and Evaluation Con-
ference (LREC 2014), 2014.

23. Amir Hazem and B´eatrice Daille. Word embedding ap-
proach for synonym extraction of multi-word terms. In
Proceedings of the Eleventh International Conference on
Language Resources and Evaluation (LREC 2018), 2018.

24. Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Martti-
nen, and Philip S Yu. A survey on knowledge graphs:
Representation, acquisition and applications.
arXiv
preprint arXiv:2002.00388, 2020.

25. H. Kaiya and M Saeki. Ontology-based requirements
semantic processing approach.

analysis: Lightweight
pages 223– 230, 10 2005.

26. M. Kamalrudin, J. Hosking, and J. Grundy. Improving
requirements quality using essential use case interaction
patterns. In 2011 33rd International Conference on Soft-
ware Engineering (ICSE), pages 531–540, May 2011.
27. Wei Liu, Chengwan He, and Kui Zhang. Service-based
domain requirements completeness analysis.
In 2009
Asia-Paciﬁc Conference on Computational Intelligence and
Industrial Applications (PACIIA), volume 1, pages 110–
115. IEEE, 2009.

28. Prashanti Manda and Todd J Vision. On the statistical
sensitivity of semantic similarity metrics. In ICBO, 2018.

