ERIC: An Efﬁcient and Practical Software
Obfuscation Framework

Alperen Bolata, Seyyid Hikmet C¸ elika, Ataberk Olguna, O˘guz Ergina, Marco Ottavib
aTOBB University of Economics and Technology, Turkey,
bUniversity of Twente, The Netherlands and University of Rome Tor Vergata, Italy
a{alperenbolat, seyyidhikmetcelik, aolgun, oergin}@etu.edu.tr, bm.ottavi@utwente.nl

Abstract—Modern cloud computing systems distribute soft-
ware executables over a network to keep the software sources,
which are typically compiled in a security-critical cluster, se-
cret. However, these executables are still vulnerable to reverse
engineering techniques that can extract secret information from
programs (e.g., an algorithm, cryptographic keys), violating the
IP rights and potentially exposing the trade secrets of the
software developer. Malicious parties can (i) statically analyze the
disassembly of the executable (static analysis) or (ii) dynamically
analyze the software by executing it on a controlled device and
observe performance counter values or exploit side-channels to
reverse engineer software (dynamic analysis).

We develop ERIC, a new, efﬁcient, and general software
obfuscation framework. ERIC protects software against (i) static
analysis, by making only an encrypted version of software
executables available to the human eye, no matter how the
software is distributed, and (ii) dynamic analysis, by guaranteeing
that an encrypted executable can only be correctly decrypted and
executed by a single authenticated device. ERIC comprises key
hardware and software components to provide efﬁcient software
obfuscation support: (i) a hardware decryption engine (HDE)
enables efﬁcient decryption of encrypted hardware in the target
device, (ii) the compiler can seamlessly encrypt software exe-
cutables given only a unique device identiﬁer. Both the hardware
and software components are ISA-independent, making ERIC
general. The key idea of ERIC is to use physical unclonable
functions (PUFs), unique device identiﬁers, as secret keys in
encrypting software executables. Malicious parties that cannot
access the PUF in the target device cannot perform static or
dynamic analyses on the encrypted binary.

We develop ERIC’s prototype on an FPGA to evaluate it end-
to-end. Our prototype extends RISC-V Rocket Chip with the
hardware decryption engine (HDE) to minimize the overheads
of software decryption. We augment the custom LLVM-based
compiler to enable partial/full encryption of RISC-V executables.
The HDE incurs minor FPGA resource overheads, it requires
2.63% more LUTs and 3.83% more ﬂip-ﬂops compared to
the Rocket Chip baseline. LLVM-based software encryption
increases compile time by 15.22% and the executable size by
1.59%. ERIC is publicly available and can be downloaded from
https://github.com/kasirgalabs/ERIC.

Index Terms—Software Obfuscation, Trusted Execution, Hard-

ware Authentication

I. INTRODUCTION

the Internet of Things

With the rising trend in the use of electronic devices
(IoT), more
in the context of
and more devices communicate with each other over net-
works [33], [20], [22], [1]. Maintaining secure and reliable
communication channels between multiple devices over a net-
work is important to provide security and reliability guarantees
for a wide variety of applications [3], [53].

Embedded systems typically consist of processors or pro-
cessing units that execute a program. These systems often
serve a speciﬁc purpose and are not as capable as general-

purpose systems in terms of performance, power budget, and
computational capability [35], [18]. Programs that are executed
by embedded systems are often compiled in more capable
computing systems (e.g., personal computers, cloud systems)
and their compiled binaries are delivered to the embedded
systems over physical interfaces (e.g., serial connection) or
over a network [21], [6], [26], [21]. Typically, these binaries
implicitly encapsulate critical information (e.g., architectural
details of the target hardware and sophisticated, trade secret
algorithm implementations) [38], [50]. It is important that this
information is not exposed to malicious parties.

We identify two types of attacks that threaten the secrecy of
critical information embedded in binaries. First, a binary can
be converted into a human-readable form by using standard
compiler tools (e.g., disassembler) and can be analyzed to
identify critical information [15], [27], [45], [5], [51]. We refer
to these types of attacks as static-analysis attacks. Second, a
binary can be executed on a computer that is controlled by
malicious parties and the computer’s state (e.g., performance
counters, register values) can be monitored to reverse engineer
the source code from the binary. We refer to these types of
attacks as dynamic-analysis attacks [44], [46], [42], [4], [10].
Our goal is to design a new framework that can prevent both
static and dynamic-analysis attacks.

We propose ERIC, a new framework that keeps program
information secret regardless of how the program is trans-
ferred from its source to the destination hardware platform.
To do so, ERIC uses cryptographic keys that are generated
from an identiﬁer unique to a target hardware device (e.g.,
physical unclonable functions) to encrypt program binaries.
The encrypted program can only be decrypted by the target
hardware device, preventing malicious parties from performing
static and dynamic analyses.

ERIC is composed of two components: First, a new com-
piler supports partial and complete encryption of software
executables (i.e., program binary). Second, a hardware decryp-
tion engine enables efﬁcient decryption of encrypted binaries.
ERIC uses physical unclonable functions (PUFs) to generate
cryptographic keys that are used in symmetric encryption and
decryption of program binaries. In this way, ERIC guarantees
that an encrypted binary can only be decrypted and executed
by the target hardware.

We develop ERIC’s FPGA-based prototype and integrate
into a real RISC-V system to evaluate ERIC end-to-
it
end. We implement ERIC’s compiler by augmenting LLVM
to perform encryption on RISC-V binaries. Our prototype
builds on open source projects and itself is open sourced on

https://github.com/kasirgalabs/ERIC. We hope that our open
source prototype will be of use to industry and researchers
going forward.

We evaluate ERIC end-to-end using multiple workloads
to understand how its hardware and software components
perform and affect the overall performance of the system. Our
results show that compilation time increases by 15.22% on
average compared to the baseline compiler without encryption
and end-to-end execution time increases by no more than
7.05% across all workloads. ERIC’s hardware components
introduce a minor 3.17% FPGA resource overhead and can
be implemented at the low FPGA component cost.

ERIC makes the following contributions:
• ERIC is the ﬁrst end-to-end software obfuscation and
trusted execution framework that offers a lightweight
architecture applicable to all systems.

• We implement and publicly released an end-to-end pro-
totype of ERIC which comprises a real RISC-V system
and a compiler.

II. BACKGROUND AND THREAT MODEL

A. LLVM

LLVM is a set of compiler and toolchain technologies
that can be used to develop any programming language
as a front-end and any instruction set architecture as a
back-end [28], [31]. LLVM is designed around a language-
independent methodology called Intermediate Representation
(IR). The program compiled using any language is ﬁrst trans-
lated to the IR language. IR is a high-level assembly language
that can be optimized with a variety of transformations over
multiple passes. Many optimizations and analyses are possible
during compilation with IR. After all the desired optimizations
and analyses are made on the IR representation of the pro-
gram, a binary code translation for the target instruction set
architecture (ISA) is produced from the IR language.

With the IR methodology, it is possible to develop a custom
compiler on LLVM. The designed compiler can be built by
performing the target compilation options on the IR language.
In addition, this compiler is compatible with most languages
thanks to the support of LLVM libraries.
B. Arbiter PUF

Physical unclonable function (PUF) is a function that pro-
vides a physically deﬁned ”digital ﬁngerprint” output (re-
sponse) for a given input and conditions (difﬁculty), usu-
ally serving as a unique identiﬁer for a semiconductor de-
vice [34], [24]. PUFs are mostly based on variations that
occur naturally during semiconductor fabrication. Since the
distribution of
these variances is unique for each semi-
to obtain the unique identity of
conductor, PUFs use it
the device. There are many PUF methods proposed to
date [8], [13], [37], [40], [7], [25], [19], [14]. Delay-based
PUFs are among the most common PUF methods used [36].
Arbiter PUFs compare the delay of two identical paths
to generate a ’0’ or ’1’ bit, depending on the result of the
comparison [32]. Although no two paths are the same and
should introduce the same delay, minor unforeseen differences
during the manufacturing process make one path ultimately
faster than the other.
Arbiter PUFs

authentication.
Challenge-response authentication is the protocol in which

challenge–response

use

the source gives a response output for an incoming challenge
input. PUF-based systems can check system authentication
by the validation of the response output. Figure 1 shows the
scheme of the 5-bit challenge and 1-bit response PUF model.
As seen in the ﬁgure, the response output changes depending
on the path of the delays on the hardware and the challenge
value.

Fig. 1: 5 Bit Challenge - 1 Bit Response PUF Scheme

C. Threat Model

In our threat model, we assume that the executable (program
binaries) is transmitted over an untrusted network. Malicious
parties can retrieve the executable to violate IP rights, make
modiﬁcations to the executable and send the modiﬁed version
to the destination hardware. We assume that the target hard-
ware is trusted. In summary, we protect against these types of
threats: (i) Hijacking critical programs and resulting reverse
engineering applications, (ii) attempting to execute programs
of unknown origin on user hardware, (iii) running programs
compiled by the software source on unlicensed or unveriﬁed
hardware and (iv) the execution of malicious modiﬁcations or
soft errors to the program on the system.

III. ARCHITECTURE OF ERIC

ERIC is an efﬁcient and practical framework designed
to establish a trusted execution environment
that provides
authenticated target-hardware-speciﬁc software compilation
capability. To provide such capability, ﬁrst, ERIC encrypts
software such that the encrypted software can only be de-
crypted in the target hardware, protecting the software against
malicious attacks in the form of static and dynamic analyses,
second, ERIC integrates a secure hash digest of the software
within the software’s encrypted version to support integrity
validation. ERIC consists of two components: (i) hardware-
based architecture and (ii) software-based architecture.

ERIC’s hardware and software components are easily de-
coupled. For example, ERIC’s software components can be
used in one computer to compile and encrypt programs, and
its hardware components can be used in another computer
to perform decryption. This way, an encrypted program can
be securely transferred over a network from one computer to
another, and its integrity can be validated by the hardware
that decrypts and runs it. If the integrity of an encrypted
program can be validated, it is guaranteed to come from a
trusted source, thus the encrypted program’s authenticity is
also validated. This way, the program runs only on the target
hardware and the target hardware only executes the programs
written for it. We refer to this feature of ERIC as two-way
authentication. Figure 2 shows how two-way authentication
works between hardware and software interfaces.

On the other hand, ERIC achieves obfuscation of the
program binaries from malicious activities while transferring
between the software source and the target hardware.

can be applied to the program or bit ﬂips that may occur
because of soft errors while the program is being transferred
or stored. ERIC includes a graphical interface in order to
understand the encryption stages more easily and to enable the
programmer to control the encryption according to their own
needs. Encryption can be done through this interface according
to the requirements.

The proposed architecture is compatible with different en-
cryption methods. New encryption algorithms can be easily
implemented in the system by the ERIC’s interface. With the
changes to be made in the target ﬁles, the user has the freedom
to upload his own encryption method to the system. After
deciding on the encryption algorithm, encryption methods
should be determined. There are three different encryption
methods that can be used for this. These are the complete
encryption of the program, partial encryption of the program,
and the partial encryption of a select few instructions of
the program by specifying the target bits in the instruction
encoding.

All instructions are encrypted with PUF-based keys and
ready to be executed on the target hardware. For the target
hardware to detect which instructions are encrypted, the en-
cryption map must be transmitted to the other party along
with the encrypted program. Using partial encryption,
the
programmer can protect the critical parts of the program or
create an area within the program that can only be active on
the target hardware. In addition, the programmer can select the
features he/she wants to run only on licensed hardware within
the program.

The interface where target

instructions can be selected
for partial encryption is provided with ERIC. The presented
interface also allows selecting special parts within the tar-
get instructions. In this way, only critical information can
be protected without interfering with the program ﬂow. For
example, only the pointer values of the instructions that make
memory accesses can be encrypted, which makes it difﬁcult
to follow the program’s memory trace. If the opcode parts of
the instructions are not encrypted during partial encryption, it
will also make it difﬁcult to understand that the program is
encrypted in the case of reverse engineering.

ERIC is suitable for compiling from a single software
source for multiple target hardware or creating multiple trusted
software sources for single target hardware. For this, it is
only necessary to apply the appropriate conversion function
to the system to match the PUF-based key with the PUF keys.
Also, if the hardware manufacturer maps two or more different
hardware to the same PUF-based key while performing the
conversion function in the Key Management Unit, programs
can be created to run on multiple hardware of their own with
a single compile step. This implies that ERIC does not have
a scaling problem for multiple targets or sources.

In addition to encryption, ERIC generates signatures for
compiled programs to ensure that the program reaches the
target without modiﬁcation. This signature is obtained by
running a cryptographic hash function on the instructions
before the program is encrypted. The signature is produced
before the program is encrypted and the signature is encrypted
with the program, making the signature useless for those who
cannot decrypt the program. The resulting signature is ﬁnally
encrypted with a PUF-based key. In this way, interference or

Fig. 2: Two-Way Authentication Model

1) Software Architecture

Target-hardware-speciﬁc encryption is provided by a PUF-
based key. For this, the compiler performs integrated encryp-
tion with the PUF-based Key Generator Unit on the hardware
side. PUF-based keys are obtained by passing the PUF key
in the hardware through the function (e.g., secure hash algo-
rithm [16]) in the Key Management Unit. Since the PUF key is
immutable on each target hardware, an encryption mechanism
directly linked to the PUF key gives unlimited access to the
trusted program resource, and this access relationship cannot
be changed. To avoid this, it is suggested to obtain a PUF-
based key from the PUF key that the target hardware can
conﬁgure at any time. The use of PUF keys provides a unique
key for each device that has physical foundations and does not
need to be constantly stored in a register.

As stated in Section II.C, the proposed architecture aims
at the obfuscation and safety of the compiled program until
the execution stage while achieving two-sided authentica-
tion between the target hardware and the software source.
Therefore, it is assumed that the handshake is already done
for the hardware targeted by the software source, and PUF-
based keys that are compatible with the target hardware are
assumed to be known to the software source. The key unit we
added on the compiler side takes the PUF-based key of the
target hardware as input and generates the keys to be used in
encryption operations. The PUF key is not exposed to the user
during software compilation. With the abstraction layer created
between the PUF-based key generator in the hardware and the
key generator in the software, there is no need for direct access
to the PUF key when integrated encryption with the PUF
key. This allows long-term key usage, enabling different key
conﬁgurations in the system. Also, in this way, the PUF key in
the hardware is protected and can be used for different targets
since it is not shared with the software developer directly.

ERIC’s software components encrypt the program in various
conﬁgurations during the compilation phase. The encrypted
program is intended to remain secure until it reaches the target
hardware. The main goals of the encryption are to be protected
from reverse engineering methods, malicious add-ons that

errors that may occur in the program during the transfer or
storage of the program become detectable by the hardware.

The developments made on the software side of ERIC are
completely suitable for targeted customization. The variety
of encryption methods, the ability to change the encryption
function, and the selection of ISA speciﬁcations suitable for
the target hardware make this possible.

2) Hardware Architecture

For the hardware to run the encrypted and signed program
securely and efﬁciently, hardware architecture is needed that
will work in harmony with the software architecture. ERIC’s
Hardware architecture includes several units. These are the
Decryption Unit, the Validation Unit, the Key Management
Unit, the Signature Generator, and the PUF Key Generator.
The high-level unit in which these units are integrated is called
as Hardware Decryption Engine (HDE) Unit. The hardware
architecture is completed by integrating the processor with the
HDE Unit. The security model in the hardware ensures that
the received programs are kept encrypted until they are loaded
into the main memory for execution. Since decryption opera-
tions are performed without writing the program to memory,
the recommended hardware architecture is compatible with
common processor architectures.
PUF Key Generator (PKG). The PKG enables the generation
of keys that act as an identity for the hardware device due to
the differences in the hardware during production (e.g., process
variation). These keys provide the hardware with a unique
identiﬁcation number. These PUF keys will be used in ERIC
to distinguish between two different hardware.
Key Management Unit. PUF-based keys used by hardware
are used to decrypt
the incoming encrypted program. In
order to integrate the keys used on the software side and
the keys used on the hardware side, the existing PUF key
goes through the key generation function within the Key
Management Unit. The PUF-based key is obtained by passing
the PUF key through the function. In this way, multiple
PUF-based keys are generated with a single PUF key. As
mentioned earlier, this provides a layer of abstraction between
the encryption/decryption key and the PUF key. Using the PUF
key with abstraction allows conﬁguring the function used for
the PUF-based key in the Key Management Unit, allowing
to change the compatible software resources according to
if the necessary
time or preferences. With this ﬂexibility,
variables in the hardware are given as input to the PUF-
based key generation function a program that can only be
decrypted and run at a speciﬁc time range or a program that
can only be decrypted at a speciﬁc temperature, frequency, or
altitude, etc. can be obtained. We did not discuss the different
conﬁgurations of PUF-based key generation for the sake of
simplicity of the paper and planned for future work.
Decryption Unit. The Decryption Unit decrypts the program
that reaches the SoC encrypted with the PUF-based key. If the
program is partially encrypted, the Decryption Unit analyzes
the additional bits added to the encrypted program for each
instruction. While these are the addition of a new bit
to
each instruction in instruction-based partial encryption, the
use of bits indicating the encryption to be used may increase
depending on the selection of partial encryption. The function
to be applied for decryption need to be the reverse pair of the

encryption function on the compile process. In this way, it is
ensured that the same data is obtained again.
Signature Generator. Incoming programs to the SoC are
carried with signatures obtained before program encryption in
the software architecture. These signatures are also encrypted
with the program. The Signature Unit is used to recalculate the
signature from the decrypted program in the hardware. This
unit creates the signature of the program with the instructions
it receives as the program is decrypted. Finally, the generated
signature is transferred to the Validation Unit.
Validation Unit. When the decryption of the program is ﬁn-
ished, it transfers its own calculated signature to the Validation
Unit. Likewise, the encrypted signature that comes with the
program is transferred to the Validation Unit. After decrypting
the signature that comes with the program in the Validation
Unit, the signature calculated by the hardware itself and the
signature that comes with the program are compared. If there
is a match, the decrypted program is authorized for execution.
Figure 3 shows the schematic of the proposed architecture.
The orange color on this ﬁgure represents the key components
of ERIC. The numbers on the ﬁgure describe a typical work-
ﬂow of ERIC from program encryption to execution on the
SoC.

1 refers to the generation of PUF-based keys in hardware,
which is the ﬁrst step required for the architecture to work.
The PUF key obtained with the PUF Key Generator generates
the PUF-based key, which will be required for encryption and
decryption, with the Key Management Unit. In this way, it
also provides an abstraction layer over the PUF Key, which is
critical data for SoC’s security.

2 step is to give the requirements to the compilation stage
so that the correct encryption can be done. ERIC’s graphical
interface and technical documentation can be used for this step.
The ISA targeted by the program, the function to be used for
encryption, the partial or full encryption decision, and the key
information of the target hardware should be determined.

3 step involves encrypting the program and packaging it
with the signature. First, the program is compiled for the target
ISA using compiler libraries according to the requirements de-
termined in the previous step. After the compilation is ﬁnished,
the signature of the program is obtained with the Signature
Generator. Second, the key management function, using the
PUF-based key transferred to the compiler stage, generates
keys suitable for the encryption function. The obtained signa-
ture and keys are moved to the encryption function with the
compiled program. In this function, the program is encrypted
according to the encryption constraints of the previous step
and, if necessary, packed with the extra information needed
to decrypt it (in case ERIC performs partial encryption of
a program). Then, with the encryption of the signature, the
encrypted program package and the signature are ready to exit
from the software source.

4 step refers to the secure packaging of the program until
it reaches the target hardware. The program may be stored on a
server waiting to be requested by the target hardware, or it may
be compiled as one of the sub-threads in distributed systems.
It may also be sent to remote hardware from a program source.
In this situation, if the program is accessed by non-target
hardware or malicious parties, the program is protected by
the encrypted program package and the encrypted signature.

Fig. 3: ERIC’s Architecture

5 At this stage, the program and its signature that reaches
the hardware are decrypted in the Decryption Unit with the
PUF Based Key. The decryption process is done in accordance
with the conﬁgurations determined in the encryption process.
Then, the decrypted program is used to generate signatures
again in the Signature Generator Unit. In addition, the de-
crypted signature is transferred to the Validation Unit.

6 step is the ﬁnal stage of the ﬂow. In the Validation
Unit, the signature that comes with the program is compared
with the signature recalculated in the Signature Generator
of hardware. In the case of a match, it is understood that
the program has come without any changes and is specially
packaged for this hardware, and the decrypted program is sent
to the Trusted Zone and becomes suitable for executing on the
processor.

IV. IMPLEMENTATION AND TEST RESULTS
In order to quantify the performance overhead introduced
by ERIC, we implement ERIC on (i) software source and (ii)
target hardware.

TABLE I: Test Environment

Parameter

Value

FPGA
PUF Type
PUF Parameters
Signature Function
Encryption Function
SoC
Test Frequency
Target ISA
L1 Data Cache
L1 Instruction Cache
Register File

Xilinx Zedboard [52]
Arbiter PUF
32x 8-bit challenge 1-bit response
SHA-256
XOR Cipher
Rocket Chip (In-Order 6-stage) [9]
25 MHz
RV64GC
16KiB, 4-way, Set-associative
16KiB, 4-way, Set-associative
31 Entries, 64-bit

We perform the evaluation of ERIC in two parts. First,
we measure ERIC’s encrypted compilation performance for
various software sources. Second, we evaluate ERIC’s per-
formance in decrypting the encrypted software binary on
the target hardware. Table I shows the conﬁguration of our
evaluation. We tested the software source that is encrypted for
the target hardware on our custom LLVM-based encryption
compiler design. We implement the target hardware by build-
ing the SoC we designed for the proposed architecture within

the FPGA. Figure 4 shows the schematic of these designs.
MiBench [23] is used as a benchmark when evaluating system
performance. We selected benchmark programs of MiBench
which is capable with LLVM and RISC-V architecture. Since
the framework we proposed is based on iterations on the pro-
gram and is directly related to the program size in memory, it
is also aimed to use programs of different sizes as benchmarks.

Fig. 4: Scheme of Implemented Model

A. Software Source

We evaluate the software source in a system that includes
the custom compiler we designed. We run benchmark pro-
grams on this system, in which we integrate the encryption and
signature generation functions with our custom compiler. The
compiler is ported from the Clang compiler driver. Also, en-
cryption and signature generation mechanisms are ported from
LLVM tools for integration with the compiler. LLVM provides
functions that support instruction sets and their extensions, so
instructions can be selected directly according to their ﬂags
during compilation. Also with LLVM support, ERIC allows
optimizing the distribution of encrypted instructions during
compilation in accordance with preferences. The mechanism
that we build is combined with ERIC’s interface where com-
pilation and encryption conﬁgurations can be selected

We use LLVM 11.1 and Clang 11.1 versions for our
prototype. To create the signature mechanism, we implement
the SHA-256 function in C++ and the XOR cipher function
for the encryption function. Since the XOR cipher function
is an encryption method made by passing instructions through
successive XOR gates, the encrypted message is accessed back
in symmetrical steps. We use this function for the simplicity
of the design. The encryption function is performed with the
keys from Key Management Unit. The Key Management Unit
converts the PUF-based key given from the user interface into
keys in the appropriate formats for the Encryption Unit. In
this way, multiple encryption iterations continue with a single
PUF-based key. A PUF-based key is a hardware-generated
key using a PUF key and it
is implemented by the Key
Management Unit on hardware. How we implemented this
process is explained in Section IV.B.

To demonstrate the performance of a system that compiles
programs by encryption and generates signatures, we show the
results with variation in compile-time and program size.

First, the constant change in program size is the addition of
signatures. Regardless of its size, every program is packaged
by adding a 256-bit signature due to the SHA-256 algorithm.
The dynamic increase in program size does not exist if all
instructions are encrypted. However, when the program is
partially encrypted, a bit is added for each instruction in the
program, indicating whether the instruction is encrypted or not.
For partial encryption conﬁguration, the instructions randomly
determined are selected for encryption from the program. This
means a 1-bit increase in program size for every instruction
in the program. As a result, if the program is fully encrypted,
only a 256-bit signature increase will be seen. On the other
hand, if the program is partially encrypted based on instruction
selection, the program package size will increase by 1 bit for
each instruction and by 256-bits for the signature. Program
package size converging to this calculation is measured in
tests. It has been observed that the rate of increases in program
package size can change since 1 bit of extra information is
received for 16 bits if the compressed instructions in the RISC-
V ISA are included in the program.

highest increase, the program size packed with the signature
in encrypted form, is 3.73% more than the normal compiled
program size and the average increase is 1.59%.

The change in compile time of Benchmark Programs is
shown in Figure 6. Each benchmark program is normalized
to its baseline and shown in the graph. To obtain the baseline,
each program was compiled with the default Clang compiler
and the compilation time was measured. Then, the time taken
by compiling and packaging the programs was measured with
the mechanism we implemented in the same environment. Ac-
cording to the results obtained, the compilation time increased
by 33.20% in the worst scenario and 15.22% on average.

Fig. 6: Compile-Time Comparison of Each Benchmark Ap-
plication based on its Unencrypted Program’s Compile-Time
Normalization

B. Target Hardware

We evaluate the performance of the target hardware by
implementing the HDE Units, which we develop as the
mechanism that provides security with Rocket Chip, on Xil-
inx Zedboard. XOR Cipher-based decryption is used for the
Decryption Unit. By connecting these units with a common
interface, the area overhead in the hardware was calculated.
FPGA implementation of Rocket Chip with the HDE Unit and
only Rocket Chip implementation are compared in Table II.
The proposed hardware architecture requires 2.63% more
lookup tables (LUTs) and 3.83% more ﬂip-ﬂops compared
to the Rocket Chip baseline.

TABLE II: Area Results of FPGA Implementation

Total Slice LUTs
Total Flip-Flops
Frequency(MHz)

Rocket Chip Rocket Chip + HDE Change (%)
34811
19854
25

33894
19093
25

+2,63
+3,83
-

Fig. 5: Program Package Size Comparison of Encrypted Pro-
gram Packages and Unencrypted Compiled Programs based
on its Unencrypted Program’s Size Normalization

Since ﬁxed-size signature bits are added to each program
package regardless of the size of the program, it is expected
that the program size change rates will not be equal. Fig-
ure 5 shows the size change of encrypted program packages
relative to plain-text (i.e., not encrypted) program size. The

We ran the encrypted program packages on the FPGA to
observe the performance of the encrypted programs on the
SoC. In order to create a baseline, we ran the programs com-
piled without encryption in the same system conﬁgurations
with Rocket Chip. The change in execution time is shown in
the graph in Figure 7, normalized to the baseline. According
to the results obtained, it is observed that the method we
recommended slows down the system by 7.05% at most and
4.13% on average. Since the architecture proposed by ERIC
the effect of the working
is outside of the Rocket Chip,
performance and working methods of the programs on the
system performance is not directly observed when working

ture we proposed is applicable to all processors, as it decrypts
the instructions without fetching them to the processor core.
It does not directly affect the execution process and can be
conﬁgured for all compilers as it supports standard ISAs.

On the other hand, there are proposed trusted execution
these studies are
environment studies [11], [41]. Mainly,
approaches to isolating execution within the processing unit.
However, the goal of ERIC is to protect the program from
malicious actions and any modiﬁcation during transit in an
untrusted network medium while ensuring that the program
comes from the correct software source and reaches the correct
target hardware. Also, ERIC does not directly involve the
architecture of the processing unit.

There are also prior works for the security of the pro-
gram on the processor and the execution of the trusted
program [54], [12], [2], [17], [43]. ERIC framework stands
out with its features: (i) provides a consistent end-to-end
architecture and offers compiler support for hardware changes
with low overhead for both, (ii) does not require modiﬁcations
to processor microarchitecture, so could be applied to different
architectures without extension or CPU support, (iii) can be
added to scalable systems such as servers and networks as
it is included in the SoC, not the processor design, (iv) can
authenticate not only the hardware but also the software source
(v) does not directly affect cache and TLB performance in a
system that has sufﬁcient resources.

VI. CONCLUSION
We introduced a fully end-to-end and comprehensive frame-
work solution to both software obfuscation and trusted ex-
ecution. Compared to existing trusted execution and soft-
ware obfuscation architectures, our framework signiﬁcantly
improves comprehensiveness and generalizability. In the pro-
totype, hardware overhead and compiler costs are much lower
compared to existing architectures. Our architecture combines
two technology-independent ideas: 1) While compiling, the
program is encrypted with the PUF-based key of the target
hardware and generates its signature. 2) Before execution on
the target hardware, ERIC’s hardware architecture decrypts
the program with its PUF-based key and after verifying with
the signature that
the program is in the original version,
executes it. While effective at improving both the safety of the
program and authentication of executions on hardware, ERIC
Framework is also conﬁgurable and simple to implement.
Our future work will focus on improving the parallelism,
performance, and scalability abilities of the architecture so that
the framework can be implemented in distributed systems and
implemented on servers. We also aim to bring RSA-based key
generation and usage to ERIC.

REFERENCES

[1] S. Al-Sarawi, M. Anbar, K. Alieyan, and M. Alzubaidi, “Internet
of things (iot) communication protocols,” in 2017 8th International
conference on information technology (ICIT). IEEE, 2017, pp. 685–690.
[2] A. Awad, Y. Wang, D. Shands, and Y. Solihin, “Obfusmem: A low-
overhead access obfuscation for trusted memories,” in Proceedings of
the 44th Annual International Symposium on Computer Architecture,
2017, pp. 107–119.

[3] K. P. Birman, “Building secure and reliable network applications,” in
International Conference on Worldwide Computing and Its Applications.
Springer, 1997, pp. 15–28.

[4] A. Bolat, L. Cassano, P. Reviriego, O. Ergin, and M. Ottavi, “A micro-
processor protection architecture against hardware trojans in memories,”
in 2020 15th Design & Technology of Integrated Systems in Nanoscale
Era (DTIS).

IEEE, 2020, pp. 1–6.

Fig. 7: Execution Time Comparison of Each Benchmark
Application based on its Unencrypted Program’s Execution

with ERIC. However, there is a direct proportionality between
the dynamic size of the program and the performance.

V. RELATED WORK

To the best of our knowledge, ERIC is the ﬁrst software
obfuscation and trusted execution framework that is fully end-
to-end, from the encrypted compilation on software to trusted
execution on the hardware. ERIC enables programs to be
securely packaged as they send the compiler and only execute
on target hardware without any change to the original pro-
gram. ERIC’s architecture and implementation are described
in sections III and IV.

In this section, we brieﬂy describe other related works about
software obfuscation and trusted execution. In [30], [29], for
ensuring memory security and program authentication, the
entire memory is encrypted with the message authentication
code. In these studies, every line in the memory is protected
with AES encryption. The inadequacy of this study is that it
uses AES encryption for each line in the memory and cannot
create a secure area for the main memory. There is the high
memory latency that AES brings. Programs with poor cache
performance experience an extra delay each time when trying
to access the main memory. In [47], [49], [48], the encryption-
based mechanism is proposed to prevent attacks based on
hardware and software. It performs PUF-based encryption and
uses a security tree consisting of different levels in memory.
They offer a toolchain for developing secure software for
their architecture that includes a secure operating system to
manage different levels of memory protection. However, the
proposed architecture is built for a speciﬁc SoC and cannot be
compatible with all processors or ISAs. The applicability of
the system becomes difﬁcult due to changes in the operating
system. In addition, there is an average of 30% slowdown
in instruction-per-cycle performance relative to the baseline.
Another study provides a security layer with an isolated
instruction set extension in hardware. In [39], encryption is
made by PUF keys. Security of the memory and the program is
provided by encryption with this key. It supports systems built
according to the protocol between the hardware manufacturer
and the software manufacturer. The change in the instruction
architecture causes the general compilation tools to become
unavailable. This study, unlike our study, does not encrypt
the program. Instead, caches have an architecture where they
work like main memory, and work is focused on translation
lookaside buffer (TLB) performance. In contrast, the architec-

[5] D. Brumley, “Analysis and defense of vulnerabilities in binary code,”
CARNEGIE-MELLON UNIV PITTSBURGH PA SCHOOL OF COM-
PUTER SCIENCE, Tech. Rep., 2008.

[6] M. J. Callaghan, J. Harkin, T. McGinnity, and L. P. Maguire, “An
internet-based methodology for remotely accessed embedded systems,”
in IEEE International Conference on Systems, Man and Cybernetics,
vol. 6.

IEEE, 2002, pp. 6–pp.

[7] B. Chatterjee, D. Das, S. Maity, and S. Sen, “Rf-puf: Enhancing iot
security through authentication of wireless nodes using in-situ machine
learning,” IEEE Internet of Things Journal, vol. 6, no. 1, pp. 388–398,
2018.

[8] Q. Chen, G. Csaba, P. Lugli, U. Schlichtmann, and U. R¨uhrmair, “The
bistable ring puf: A new architecture for strong physical unclonable func-
tions,” in 2011 IEEE International Symposium on Hardware-Oriented
IEEE, 2011, pp. 134–141.
Security and Trust.
[9] Chipsalliance, “Rocket Chip,” https://github.com/chipsalliance/rocket-

chip.

[10] B. Coppens, I. Verbauwhede, K. De Bosschere, and B. De Sutter,
“Practical mitigations for timing-based side-channel attacks on modern
x86 processors,” in 2009 30th IEEE symposium on security and privacy.
IEEE, 2009, pp. 45–60.

[11] V. Costan and S. Devadas, “Intel sgx explained,” Cryptology ePrint

Archive, Report 2016/086, 2016, https://ia.cr/2016/086.

[12] B. Cyr, J. Mahmod, and U. Guin, “Low-cost and secure ﬁrmware
obfuscation method for protecting electronic systems from cloning,”
IEEE Internet of Things Journal, vol. 6, no. 2, pp. 3700–3711, 2019.

[13] J. Das, K. Scott, S. Rajaram, D. Burgett, and S. Bhanja, “Mram puf:
A novel geometry based magnetic puf with integrated cmos,” IEEE
Transactions on Nanotechnology, vol. 14, no. 3, pp. 436–443, 2015.

[14] S. Dolev, Ł. Krzywiecki, N. Panwar, and M. Segal, “Optical puf for non-
forwardable vehicle authentication,” Computer Communications, vol. 93,
pp. 52–67, 2016.

[15] P. Falcarin, S. Di Carlo, A. Cabutto, N. Garazzino, and D. Barberis,
“Exploiting code mobility for dynamic binary obfuscation,” in 2011
World Congress on Internet Security (WorldCIS-2011).
IEEE, 2011,
pp. 114–120.

[16] FIPS, PUB, “180-2: Secure hash standard (SHS),” US Department of
Commerce, National Institute of Standards and Technology (NIST),
2012.

[17] C. W. Fletcher, M. v. Dijk, and S. Devadas, “A secure processor architec-
ture for encrypted computation on untrusted programs,” in Proceedings
of the seventh ACM workshop on Scalable trusted computing, 2012, pp.
3–8.

[18] D. D. Gajski, S. Abdi, A. Gerstlauer, and G. Schirner, Embedded system
Springer Science &

design: modeling, synthesis and veriﬁcation.
Business Media, 2009.

[19] A. Garg and T. T. Kim, “Design of sram puf with improved uniformity
and reliability utilizing device aging effect,” in 2014 IEEE International
Symposium on Circuits and Systems (ISCAS).
IEEE, 2014, pp. 1941–
1944.

[20] N. Gershenfeld, R. Krikorian, and D. Cohen, “The internet of things,”

Scientiﬁc American, vol. 291, no. 4, pp. 76–81, 2004.

[21] G. Gracioli and A. A. Fr¨ohlich, “An operating system infrastructure for
remote code update in deeply embedded systems,” in Proceedings of the
1st International Workshop on Hot Topics in Software Upgrades, 2008,
pp. 1–5.

[22] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, “Internet of things
(iot): A vision, architectural elements, and future directions,” Future
generation computer systems, vol. 29, no. 7, pp. 1645–1660, 2013.
[23] M. R. Guthaus, J. S. Ringenberg, D. Ernst, T. M. Austin, T. Mudge,
and R. B. Brown, “Mibench: A free, commercially representative
embedded benchmark suite,” in Proceedings of the fourth annual IEEE
international workshop on workload characterization. WWC-4 (Cat. No.
01EX538).

IEEE, 2001, pp. 3–14.

[24] C. Herder, M.-D. Yu, F. Koushanfar, and S. Devadas, “Physical unclon-
able functions and applications: A tutorial,” Proceedings of the IEEE,
vol. 102, no. 8, pp. 1126–1141, 2014.

[25] J. S. Kim, M. Patel, H. Hassan, and O. Mutlu, “The dram latency
puf: Quickly evaluating physical unclonable functions by exploiting
the latency-reliability tradeoff in modern commodity dram devices,” in
2018 IEEE International Symposium on High Performance Computer
Architecture (HPCA).

IEEE, 2018, pp. 194–207.

[26] U. Kremer, J. Hicks, and J. Rehg, “A compilation framework for power
and energy management on mobile computers,” in International Work-
shop on Languages and Compilers for Parallel Computing. Springer,
2001, pp. 115–131.

[27] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna, “Automat-
ing mimicry attacks using static binary analysis,” in USENIX Security
Symposium, vol. 14, 2005, pp. 11–11.

[28] C. Lattner and V. Adve, “Llvm: A compilation framework for lifelong
program analysis & transformation,” in International Symposium on
Code Generation and Optimization, 2004. CGO 2004.
IEEE, 2004,
pp. 75–86.

[29] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh, J. Mitchell,
and M. Horowitz, “Architectural support for copy and tamper resistant
software,” Acm Sigplan Notices, vol. 35, no. 11, pp. 168–177, 2000.

[30] D. Lie, C. A. Thekkath, and M. Horowitz, “Implementing an untrusted
operating system on trusted hardware,” in Proceedings of the nineteenth
ACM symposium on Operating systems principles, 2003, pp. 178–192.
[31] LLVM, “The LLVM Compiler Infrastructure,” https://github.com/llvm/

llvm-project.

[32] T. Machida, D. Yamamoto, M. Iwamoto, and K. Sakiyama, “A new
arbiter puf for enhancing unpredictability on fpga,” The Scientiﬁc World
Journal, vol. 2015, 2015.

[33] S. Madakam, V. Lake, V. Lake, V. Lake et al., “Internet of things (iot):
A literature review,” Journal of Computer and Communications, vol. 3,
no. 05, p. 164, 2015.

[34] R. Maes and I. Verbauwhede, “Physically unclonable functions: A study
on the state of the art and future research directions,” in Towards
Hardware-Intrinsic Security. Springer, 2010, pp. 3–37.

[35] P. Marwedel, Embedded system design: embedded systems foundations
of cyber-physical systems, and the internet of things. Springer Nature,
2021.

[36] S. Morozov, A. Maiti, and P. Schaumont, “A comparative analysis of
delay based puf implementations on fpga.” IACR Cryptol. ePrint Arch.,
vol. 2009, p. 629, 2009.

[37] S. Morozov, A. Maiti, and P. Schaumont, “An analysis of delay based
puf implementations on fpga,” in International Symposium on Applied
Reconﬁgurable Computing. Springer, 2010, pp. 382–387.

[38] N. Nethercote, “Dynamic binary analysis and instrumentation,” Univer-

sity of Cambridge, Computer Laboratory, Tech. Rep., 2004.

[39] E. Owusu, J. Guajardo, J. McCune, J. Newsome, A. Perrig, and
A. Vasudevan, “Oasis: On achieving a sanctuary for integrity and secrecy
on untrusted platforms,” in Proceedings of the 2013 ACM SIGSAC
conference on Computer & communications security, 2013, pp. 13–24.
[40] K. Phalak, A. Ash-Saki, M. Alam, R. O. Topaloglu, and S. Ghosh,
“Quantum puf for security and trust in quantum computing,” IEEE
Journal on Emerging and Selected Topics in Circuits and Systems,
vol. 11, no. 2, pp. 333–342, 2021.

[41] S. Pinto and N. Santos, “Demystifying arm trustzone: A comprehensive
survey,” ACM Computing Surveys (CSUR), vol. 51, no. 6, pp. 1–36,
2019.

[42] M. Popa, “Binary code disassembly for reverse engineering,” Journal of
Mobile, Embedded and Distributed Systems, vol. 4, no. 4, pp. 233–248,
2012.

[43] S. Schrittwieser and S. Katzenbeisser, “Code obfuscation against static
and dynamic reverse engineering,” in International workshop on infor-
mation hiding. Springer, 2011, pp. 270–284.

[44] S. She, R. Lotufo, T. Berger, A. Wasowski, and K. Czarnecki, “Reverse
engineering feature models,” in Proceedings of the 33rd International
Conference on Software Engineering, 2011, pp. 461–470.

[45] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino,
A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel et al., “Sok:(state
of) the art of war: Offensive techniques in binary analysis,” in 2016 IEEE
IEEE, 2016, pp. 138–157.
Symposium on Security and Privacy (SP).
[46] P. Subramanyan, N. Tsiskaridze, W. Li, A. Gasc´on, W. Y. Tan, A. Tiwari,
N. Shankar, S. A. Seshia, and S. Malik, “Reverse engineering digital
circuits using structural and functional analyses,” IEEE Transactions on
Emerging Topics in Computing, vol. 2, no. 1, pp. 63–80, 2013.
[47] G. E. Suh, D. Clarke, B. Gassend, M. Van Dijk, and S. Devadas, “Aegis:
Architecture for tamper-evident and tamper-resistant processing,” in
ACM International Conference on Supercomputing 25th Anniversary
Volume, 2003, pp. 357–368.

[48] G. E. Suh, C. W. O’Donnell, and S. Devadas, “Aegis: A single-chip
secure processor,” IEEE Design & Test of Computers, vol. 24, no. 6,
pp. 570–580, 2007.

[49] G. E. Suh, C. W. O’Donnell, I. Sachdev, and S. Devadas, “Design and
implementation of the aegis single-chip secure processor using physical
random functions,” in 32nd International Symposium on Computer
Architecture (ISCA’05).

IEEE, 2005, pp. 25–36.

[50] N. R. Tallent, J. M. Mellor-Crummey, and M. W. Fagan, “Binary analysis
for measurement and attribution of program performance,” ACM Sigplan
Notices, vol. 44, no. 6, pp. 441–452, 2009.

[51] V. Van Der Veen, E. G¨oktas, M. Contag, A. Pawoloski, X. Chen,
S. Rawat, H. Bos, T. Holz, E. Athanasopoulos, and C. Giuffrida, “A
tough call: Mitigating advanced code-reuse attacks at the binary level,”
in 2016 IEEE Symposium on Security and Privacy (SP).
IEEE, 2016,
pp. 934–953.

[52] Xilinx,

“Xilinx ZedBoard Zynq-7000,”

https://www.xilinx.com/

products/boards-and-kits/1-8dyf-11.html.

[53] Y. Yan, Y. Qian, and H. Sharif, “A secure and reliable in-network col-
laborative communication scheme for advanced metering infrastructure
in smart grid,” in 2011 IEEE wireless communications and networking
conference.

IEEE, 2011, pp. 909–914.

[54] P. Zhang, C. Song, H. Yin, D. Zou, E. Shi, and H. Jin, “Klotski: Efﬁcient
obfuscated execution against controlled-channel attacks,” in Proceedings
of the Twenty-Fifth International Conference on Architectural Support
for Programming Languages and Operating Systems, 2020, pp. 1263–
1276.

