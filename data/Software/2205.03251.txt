2
2
0
2

y
a
M
6

]
E
N
.
s
c
[

1
v
1
5
2
3
0
.
5
0
2
2
:
v
i
X
r
a

A Trillion Genetic Programming Instructions per Second

W. B. Langdon
Department of Computer Science, University College London, Gower Street, London, UK
W.Langdon@cs.ucl.ac.uk

ABSTRACT
We summarise how a 3.0GHz 16 core AVX512 computer can inter-
pret the equivalent of up to on average 1 103 370 000 000 GPop/s.
Citations to existing publications are given. Implementation stress
is placed on both parallel computing, bandwidth limits and avoiding
repeated calculation. Information theory suggests in digital com-
puting, failed disruption propagation gives huge speed ups as FDP
and incremental evaluation can be used to reduce fitness evaluation
time in phenotypically converged populations. Conversely FDP
may be responsible for evolution stagnation. So the wider Evolu-
tionary Computing, Artificial Life, Unconventional Computing and
Software Engineering community may need to avoid deep nesting.

KEYWORDS
genetic programming, bottom up incremental evaluation, Failed
Disruption Propagation, FDP, infection, and execution, SBSE, Posix
parallel threads, SIMD AVX vector instructions, GPquick

ACM Reference Format:
W. B. Langdon. 2022. A Trillion Genetic Programming Instructions per
Second. In Proceedings of ACM Conference (Conference‚Äô17). ACM, New York,
NY, USA, 9 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 CHEATS AND HOW YOU CAN USED THEM
To come clean.

‚Ä¢ Up to 1.1 1012 GPop/s is from one run. The median 0.65 1012

GPop/s is more typical [51, Tab. 3].

‚Ä¢ We used 16 threads on one node of a shared cluster which
supported 48 threads. (The cluster job scheduler used the
other 32 threads for a wide mix of jobs during our runs.)
‚Ä¢ The operating system manages the individual CPU core

clocks and is free to reduce them below 3.0GHz.

‚Ä¢ This is the mean performance across the whole run and
so includes everything, including gathering statistics. (In
this and another run we turned off gathering some unused
population statistics, such as calculating the height of the
trees.)

‚Ä¢ Equivalent of. This is the one that matters. The headline
figure is based on assuming each GP opcode is interpreted
on each test case. We really do use every test case every time
but the big result is to avoid repeated work, Section 6.

Each generation is created from its parent generation. We
have evaluated all of the parents. Their children are only
marginally different. We do our best to inherit their fitness
evaluation within the constraints of not using more memory.

2 BACKGROUND
My goal is summarise recent improvement in genetic programming
implementations in the hope that the ideas used may be benefi-
cial elsewhere. Section 3 describes how to reduce memory usage

by more than 50%, whilst Section 4 is concerned with exploiting
parallel hardware. In converged populations of enormous trees in-
cremental fitness evaluation [45] (Section 6) proved so successful
at reducing fitness evaluation run time that crossover became the
dominant cost, so Section 5 describes ways to reduce the cost of
crossover. The success of incremental evaluation also lead to con-
sideration of information flows within GP trees and more widely
in hierarchical structures, inspiring failed disruption propagation,
FDP [65], and the realisation that deep nested structures will be
resistant to evolution and, as discussed in Section 7, the sugges-
tion that to evolve large complex artefacts, they will have to be
composed of many shallow sub-modules [46] (see Figure 5, page 7).
Details can be found in the published papers and C++ code.

2.1 Faster Genetic Programming
Genetic Programming [30], like many Artificial Intelligence tech-
niques based on search, can be expensive in terms of computer
resources. Indeed Koza in the first GP book [30] describes ways to
speed it up [69].

Until recently (Section 5), as is common with evolutionary com-
puting in general, almost the whole GP runtime is taken by the
time to do fitness evaluation and so speed up techniques have
concentrated upon faster fitness functions.

2.2 Faster Fitness
Almost all GP (as we do) interprets the evolved code. However,
particularly when GP individuals are run many times, e.g. because
there are many test cases, it can be beneficial not to interpret the
code but to compile it and run the compiled binary code (e.g. Hard-
ing [22], Gregor and Spalek [20]). However running a traditional
compiler is expensive and Fukunaga et al. [15] and Vasicek and
Slany [76] have advocated generating machine code inside the GP
system and executing that. Indeed Nordin [62, 63] evolved exe-
cutable machine code directly, leading to Discipulus [13] which
evolved Intel x86 binary machine code [12].

2.3 Better Fitness
Fundamentally the goal of the fitness function is not to measure
how well an evolved individual works or solves a problem but to
guide search and essentially fitness and selection boils down to a
single bit: does this individual get a child or not. The evolutionary
computing community, puts a huge amount of effort into the fit-
ness function, whose output is often corrupted by the addition of
stochastic selection noise. This single (noisy) bit is often extremely
expensive.

Many techniques have been advanced to reduce the overall cost
of the fitness function and/or provide better results. Sometimes the
goal is to reduce costs but (also) it may be to drive evolution in a
different direction.

 
 
 
 
 
 
Recognising that the child/no child decision is often made using
tournament selection, Teller and Andre [75] devised a scheme which
aimed at using statistical tests whereby, assuming a random sample,
only enough tests are run by the fitness function to reliably tell
which of a candidate set of parents would win the tournament if all
the tests were run. That is, their ‚Äúrational allocation of trials‚Äù (RAT)
aims (although with some noise) to drive evolution as before but
with considerably less effort.

Treating individuals with zero children as pure overhead to the
GP system, Tackett proposed ‚Äúsoft brood selection‚Äù [74], which aims
to dispose of likely unfit children without going to the expense of
growing them all to adulthood.

When evolving agents [54] or programs [36, 66], an individual
which enters a never ending loop will have low fitness but high
fitness evaluation cost. To reduce fitness effort, it is common in
such cases to impose a timeout and cut short fitness evaluation
when the imposed time limit is reached. However the chosen limit
is application specific. (This also has the unfortunate effect that
when different limits are chosen for the same ‚Äúbenchmark‚Äù [54]
subtle difference arise between supposedly the same system.)

To try and reduce the impact of arbitrary time limits, Maxwell
proposed a ‚Äúcoroutine‚Äù model [60] in which (like a conventional
operating system time sharing system), each member of the popu-
lation gets a quantum of computer time to run fitness tests. Where
selection, i.e. child/no child, is not clear cut, aspiring individuals
may get additional quanta to try and assemble more fitness points.
Again the goal is to avoid ‚Äúwasting‚Äù fitness effort, but accepting the
introduced noise may drive evolution in another direction.

Gathercole [16, 17] proposed schemes for dynamically changing
which fitness tests are used as evolution proceeds. Gathercole‚Äôs DSS
scheme was used commercially [13].

Spector‚Äôs Lexicase [73] can be thought of having elements of
both RAT and DSS. Again it runs only a varying subset of the
available fitness test cases but its primary motivation is to evolve a
better solution, rather than faster fitness evaluation.

Some of these schemes have elements of coevolution [71] about
them. In which the fitness test cases are thought of as a separate
population and the primary goal is better evolution rather than
reduced fitness effort.

2.4 Distributed Populations: Slower Convergence
The implementation changes to GPquick (Sections 3 to 6) allow the
study of the evolution of far bigger genetic programming systems
within the constraints of the available computers. The implementa-
tion takes pains to sequester the use of pseudo random operations,
and synchronise parallel operations, so that the results are identical
to those before the improvement were made and experiments can
be repeated.

By relaxing the exact reproducibility constraint you can ease
the implementation of exciting stochastic effects; such as studying
immigration/emigration between demes and island sub-populations.
These may not only easily allow operation over multiple computers
(Section 4) but also delay convergence [34], [1].

2

3 GENERATIONAL ‚â§ STEADY STATE MEMORY
Although introduced for the benefit of genetic programming popu-
lations with large trees, these algorithms apply to any evolution-
ary algorithm (EA) with a fixed population size ùëÄ. For example,
they might be useful for very large traveling salesman problems
(TSP), such as Drori et al.‚Äôs proposed billion city Galaxy TSP bench-
mark [10].

Long ago Koza et al. [32, pages 1044-1045] showed that a gener-
ational evolutionary algorithm need take no more memory than a
steady state EA. Essentially at the start of each generation during
crossover and mutation they maintain multiple queues of parents
according to the number of children they have yet to create. As
each crossover or mutation is performed, the parents‚Äô number of
unborn children are reduced and when necessary the parents are
moved between queues. Parents with no yet to be created children
are deleted immediately, allowing their buffers to be used by new
children. The queue of parents with only one unborn child is dealt
with first. If it is empty, the queue holding parents with two children
waiting to be created is processed. Of course processing the first
item in this queue, may result in moving individuals to the first
queue. If so, it will again be processed first.

Koza et al. allow two parent crossover to create two children.
Their queues can be slightly simplified if each genetic operation
only generates one child [41]. The essential idea remains; process
those individuals which will free resources first.

I have not done this, but the individual parents within each queue
could be ordered to process those that will free most memory first.
(Note the current implementation uses un-ordered queues so that
each operation takes constant time and the overhead is more-or-
less the same as before.) Alternatively, to balance the threads in a
multi-threaded environment, you might want to start processing
operations that will take the longest time first. Unlike incremental
fitness evaluation [45], the time taken by crossover or mutation can
be accurately estimated in advance from the size of the crossover
fragments to be moved and the computer‚Äôs memory bandwidth.

Like my earlier implementations of GPquick [72], there are many
generational EA systems which for a population of ùëÄ individuals
simply create the new generation whilst keeping the old one and
thus need twice as much memory (i.e. 2ùëÄ buffers). Using a single
threaded version of Koza et al. scheme and two parent crossover a
single threaded implementations needs at most ùëÄ + 2 buffers.

As my trees became bigger, it became important to move GPquick
from using 2ùëÄ buffers. Indeed as fitness evaluation got faster [39,
40] it became worthwhile running crossover (like fitness evaluation)
in parallel. With synchronisation locks the child birthing queues
can be processed in parallel. Notice the order they are processed
in now depends upon the exact thread timings and will typically
vary between runs. However all the tasks are processed and the
results are the same. GPquick generates one child per crossover.
The parallel Linux pthreads (ùë°) version needs at most ùëÄ + 2ùë° buffers
[41, 42].

If low fitness individuals are discarded, with two parent crossover,
in practise the memory can be reduce to about 0.65ùëÄ. With some
virtual memory systems, it may be possible to allocate ùëÄ +2ùë° buffers
but in most generations actually only use two thirds of the memory.

Reducing memory usage below ùëÄ buffers has become possible
due to innovations introduced to reduce the cost of memory buffer
copies in crossover. Such as evaluating fitness before crossover
(Section 6.3) and extracting and separately storing the small sub-
trees to be donated to children in the next generation [43, 44] (also
Section 6.3).

3.1 GPquick uses Flatten Linear GP Trees
For efficiency [28], GPquick [72] flattens each GP tree into a linear
array of opcodes. Reproduction, mutation, crossover and fitness
evaluation all use this. For work on parallel graphics accelerators
(GPUs) [50] (see Section 4.3.1), the normal depth first tree order can
be replaced by reverse polish notation (RPN), which processes in left
to right order the RPN expression, explicitly pushing intermediate
results on to a stack, rather than recursively processing the tree
(with an implicit stack). In both cases the depth of the stack used
is the tree height. Again reproduction, mutation, crossover and
fitness evaluation all use the linear buffer, avoiding the need for
data conversion between the CPU and GPU.

To avoid heap fragmentation GPquick allocates a user defined
number of fixed sized byte arrays to hold the GP population at the
start of the run. Usually the flatten evolved tree does not fill the
whole of its buffer, in which case the contents of the rest of the
buffer is left undefined.

For applications with many test cases, GPquick has a FASTE-
VAL compile time option. If FASTEVAL is enabled, a single pass
through each GP tree is inserted before fitness evaluation, which
replaces each byte sized opcode by a pointer (occupying 8 bytes)
to the function inside the fitness evaluation code responsible for
evaluating the opcode. For every test case, this avoids a table look
up to translate each opcode to a function pointer. However, for
simplicity and to save memory, I did not use FASTEVAL. Notice
the FASTEVAL pass is analogous to the translation from GP tree
to binary machine code advocated by Alex Fukunaga and others
mentioned above in Section 2.2.

4 PARALLEL EVALUATION
It has long been recognised that GP in particular and evolutionary
computing in general, are well able to take advantage of parallel
computing, e.g., [14], [26, 27], [31],[4], [25], [5, 59], [3], [1, 7], [23,
50, 52], [11], [35], [18], [6], [33].

4.1 Parallel Threads and Multi-Core CPUs
The previous section has already mentioned the use of Linux pthreads
to perform crossover in parallel. In fact multi-threading was imple-
mented in GPquick to speed up fitness evaluation [39].

With a population that is bigger than the number of cores simply
giving the next operation (e.g. child to create or fitness to evaluate)
to each thread as it finishes its previous task (with appropriate
synchronisation locks) works well and usually shares the work
equitably between the available compute cores.

If the tasks are very unequal, this simple way of handing out
work may be problematic. For example, with incremental evaluation
and huge trees, it was sometimes the case that one fitness evaluation
took far longer than the others, causing the whole population to
wait for one fitness evaluation to complete. I have not investigated

3

better ways to share tasks between threads, but an easy alternative
might be simply to run more independent jobs on your computer
than it has cores. With our Centos version of Linux, the operating
system overhead of rescheduling work on a core is low. Therefore,
if you have more than one EA task and sufficient memory, allowing
the operating system to keep the cores busy could be an efficient
and easy to implement solution.

4.2 Parallel Fitness Evaluations using SIMD

Vector Instruction CPUs

Riccardo Poli pointed out in bit-wise problems the basic hardware
is capable of doing 32 or 64 bit operations simultaneously [68, 70].
Indeed I used a 64 bit Intel computer to do all 64 fitness cases in
parallel for the first long term evolution experiment (LTEE) [38]
running GP on a binary tree version of Koza‚Äôs [30] 6-multiplexor
problem for 100 000 generations1. Some current Intel hardware sup-
ports 512 bit operations. I am unaware of any genetic programming
work using AVX-512 to process 512 Boolean test cases in parallel.
However it appears Hrbacek and Sekanina [24]‚Äôs impressive work
with cartesian genetic programming using 256 bit SSE instructions
could be readily extended to the newer 512 AVX.

In addition to bit-wise operations, the AVX vector instructions
can simultaneously perform 16 floating point calculations. I wrote
an AVX interpreter for GPquick so that instead of processing each
tree once per test case it passed through each tree only once and
instead executed each opcode on all the test cases. The first AVX
version used the traditional depth first ordering which requires
each node within the tree to recursively call the subtrees below it
and store intermediate results on a stack. For efficiency an external
stack (of depth equal to the height of the tree) is used. GPquick
requires the user to specify a maximum size of the trees before
it starts. From the maximum size an estimate can be made of the
maximum height of any evolved tree and used to set the size of the
stack when GPquick starts.

Vasicek and Slany [76], like Hrbacek and Sekanina [24], used
256 bit SSE instructions to allow cartesian genetic programming‚Äôs
fitness function to process up to eight floating point numbers si-
multaneously. Again it would seem possible to extend this to the
newer 512 AVX now available on some Intel servers as well as Intel
specialist plug-in GPU like accelerators.

De Melo et al. [9] also used AVX parallel hardware and claim
an impressive median peak performance of 7.5 billion genetic pro-
gramming operations per second in a single CPU core, however
this is for their interpreter alone and does not include the rest of
their GP system.

4.3 Alternative Parallel Approaches

4.3.1 Hybrid Computing, Compute Accelerators: GPU and TPU.
Many flavours of hybrid architecture are possible. Here we mean
a non-X86 or Intel Xeon boards, which may be housed inside the
computer and certainly within a few feet or it. Although experi-
ments continue with FPGA‚Äôs [19], running computation on graphics
cards (GPUs) and domestic gaming boards, usually manufactured

1Rich Lenski‚Äôs team [58] have been running microbiology laboratory evolutionary
experiments on the bacteria E. coli since 1988 [57], which have now reached 73 500
generations [29].

Figure 1: Original GPquick subtree crossover requires three
memcpy buffer copies: 1) root segment of donating parent
(mother, red/brown) is copied to offspring buffer. 2) sub-
tree from second parent (father, blue/black) is copied to off-
spring. 3) tail (brown) of 1st parent copied to child.

by nVidia [50],[37], and known as general purpose computing on
GPUs, GPGPU [64], continues to be popular. However more re-
cently, especially for training deep neural networks, Google‚Äôs TPU
hardware accelerators have become popular.

Although perhaps for Pandemic related reasons, there is per-
ceived to be a worldwide shortage of silicon chips and the steep
increase in the GPU price performance curve has soften, it is ex-
pected that the impressive raw performance of GPU and other
accelerators will continue to rise. Indeed already GPUs with multi-
ple gigabytes of on board memory and thousand of fully capable
computer cores are in use. Although traditionally it is tricky to code
GPGPU to get the best of the hardware: evolutionary computing,
indeed genetic programming [35], have been shown to be fully
capable of exploiting GPUs.

4.3.2 Data Center Networks: MPI. It is clear that CPU clock
speeds are stuck at around 3 GHz and no great speed up can be ex-
pected in that direction. However compute power has continued to
increase by allowing greater use of parallel hardware. Sections 4.1
and 4.2 have discussed multi-core and SIMD vector instructions.
Further increases in both can be expected. However the dominant
growth in computer power has been in loosely coupled clusters of
compute servers. Indeed, today it is not uncommon for universities
to run their own clusters of thousands of cores. And academics have
not been slow in exploiting this architecture, originally called Beo-
wulf computing [4], and nowadays referred to as cluster, grid [77]
or cloud computing. Indeed many use commercial off campus cloud
computing, e.g. Amazon AWS EC2, Google Cloud and Microsoft
Azure.

Although many protocols exist for sharing data between peer
networks, MPI2 is popular in the Linux world when interconnecting
compute nodes within the same data centre.

4.3.3 Global Networks: HTTP & P2P. It has been known for a
long time that it is possible to distribute evolutionary computing
globally [8, 55]. Often this is done by distributing both population
and fitness evaluation, for example Laredo et al.‚Äôs EvAg [56]. How-
ever perhaps the most famous example is SETI@home [2], which
uses otherwise idle compute time donated by volunteers world
wide.

5 FASTER CROSSOVER
GPquick uses a very compact representation for its GP trees. This
only requires one byte per tree node [28, pp 297]. Its compactness

2It seems that MPI has replaced the earlier PVM, e.g., as used in the distributed
evolutionary algorithm ParadisEO [7].

Figure 2: In place subtree crossover uses only one GPquick
buffer. The offspring is the last child of the 1st parent
(mother) and reuses its buffer. Another optimisation is that
the only part of the 2nd parent (father) to be kept is the sub-
tree to be inserted (black). It is small enough to be stored
on the heap. In 71% of children the subtree to be remove
(white) and to be inserted (black) are different sizes, and so
memmove is used to shuffle the second part of the mother‚Äôs
buffer (brown) up or down. Finally the father subtree over-
writes the buffer. The unused part of the buffer (right end)
is not cleared and so may contain junk from earlier genera-
tions.

allows both very large populations (e.g. 5 million trees [52]) and very
large trees, (e.g. two billion nodes [51]). It was only when fitness
evaluation was sped up dramatically that the cost of crossover
became noticeable. When the evolved trees become very large,
reproduction, e.g. crossover and mutation, becomes expensive in
GPquick due to the volume of data to be copied, see Figure 1.
GPquick now uses several ways to speed up crossover:

‚Ä¢ Run in parallel thread (see Section 4.1 above)
‚Ä¢ Run fitness evaluation before genetic manipulation. Thus
children of fit parents who have low fitness, or are just un-
lucky, and so have no children themselves need never be
created [43, 44].

‚Ä¢ ‚ÄúFatherless‚Äù crossover [43, 44] (see also Section 6.3).

To allow exact reproduction, GPquick performs stochas-
tic activities, such as choosing crossover points, in a single
master thread before per generation parallel activities. Since
the crossover fragments are known, it becomes easy to copy
them all before any genetic operations are done. This means:
‚Äì Parents (‚ÄúFathers‚Äù) who only donate subtrees can be deleted
immediately. Indeed only parents which donate their root
node to at least one child need be saved and processed
by the crossover queues (Section 3). This saves full length
buffers and potentially reduces actual memory require-
ment below ùëÄ buffers.

‚Äì The copied subtree fragments are small enough to keep on
the heap and so potentially allow better use of the CPU‚Äôs
L2 and L3 caches.

‚Äì The crossover/mutation queues (Section 3) also make it
easy to spot when a parent has only one child left to be
born. In such cases, the new child is not allocated a new
buffer but simply reuses its parent‚Äôs buffer. (This is known
as in place crossover. Contrast Figure 2 with Figure 1, both
from [44].) This will usually require about half the existing
buffer to be shuffled but this is usually faster than copying
almost the whole buffer to a new location [43, Sec. 5].

GNU glibc-2.19‚Äôs memmove drops into X86 assembler to move
opcodes in the buffer. It uses a combination of rep movsb and
rep movsl without the need to take a copy of the data. The need

4

memcpy 3memcpy 1memcpy 2memmovememcpy(from heap)to move the data up or down within the buffer arises when the
subtree removed by crossover is not the same size as the subtree to
be inserted (Figure 2). Most crossover fragments are small and so
usually the buffer need be shuffled by two or perhaps four bytes.
With large trees, memmove is on average 14% faster than memcpy
[43, Sec. 5]. This may be because most of its movsl source and
destinations are in the same L1 cache line whereas with memcpy
they reference different lines.

6 AVOIDING FITNESS EVALUATION WORK
The best way to optimise anything is not to do the existing work
better but to reduce the amount of work to be done. Section 6.2
describes in fitness converged populations how to avoid evaluating
more than 99% of opcodes using a method based on incremental
fitness evaluation [45].

6.1 Population as a directed acyclic graph
Simon Handley [21] had a very elegant GP representation in which
the whole evolving population of genetic programming trees was
represented by a directed acyclic graph (DAG). Each individual was
represented by an entry point into the common code. Common
subtrees were held only once in the DAG. When fit individuals
were selected for crossover, they exchanged existing subtrees. The
DAG kept track of this, thus compactly representing the whole
population. See also Nic McPhee et al.‚Äôs Sutherland [61].

In the absence of side effects, when the same fitness test cases
are used in the next generation, the evaluation of the each subtree
is unchanged in the next generation and the DAG can be used to
cache subtree evaluations. On many non-image processing tasks, it
is feasibly to cache every subtree evaluation. Meaning after each
genetic operation, only the sub-evaluations from the crossover or
mutation site to the tree‚Äôs root node need be re-evaluated. That is,
fitness evaluation time no longer scales as the size of the trees but
as their depth. However...

Caching partial evaluations of the whole population would defeat
GPquick‚Äôs compact opcode representation (Section 5) and if trees
are allowed to grow without restriction it would not be feasible.

6.2 Bottom Up Fitness Evaluation
What to do? As is common in evolutionary computing, we used
the same test cases every generation. The huge evolved trees were
converging and thus burning huge amounts of CPU time to calculate
the same fitness values over and over again.

In the absence of side effects the GP trees are pure functional
expressions and thus can be evaluated in any order. I.e. they do
not have to be evaluated in the traditional root first recursive top
down way. Instead incremental fitness evaluation [45], evaluates
each new child from the change point outwards. Remember the
only change between parent and child is here. All the rest of the
code is identical and, unless the code below it has changed, it will
evaluate identically both in the parent and its offspring.

With incremental evaluation, GPquick re-evaluates the ‚Äúmother‚Äù
(the parent who donates the root node to the child) as it evaluates
her child, see Figure 3. Firstly notice in almost all the tree the two
evaluations are identical, so the worst case overhead is modest.
Secondly the only place they can be different, is on the chain of

Figure 3: With fitness first, fitness is evaluated using only
the parents, i.e., before the child is created by crossover. As-
suming no side effects, the subtree to be inserted (black)
is evaluated on all test cases and values are transferred to
evaluation of mother at the location of the subtree to be
removed (white). Using incremental evaluation [45] differ-
ences between the original code (white subtree) and the new,
are propagated up the 1st parent (mother) until either all dif-
ferences are zero or we reach the root node. Based on [44].

function calls from the changed code to root node. If at any point
along that chain, the evaluation of the new code is equal to that
in its parent, then the two evaluation will remain identical from
that point to the root node. If they are identical on all test cases, the
child‚Äôs fitness will be identical to that of its ‚Äúmother‚Äù. Thus if at any
point on the route up the tree from the crossover or mutation site
to the root node both evaluations on all the test cases are identical,
the child‚Äôs fitness is known to be that of its parent and we can
immediately stop fitness evaluation. (Figure 4, page 6, shows fitness
disruption caused by a crossover fading a way in a small tree.) In
large converged populations the savings can be two or three orders
of magnitude. In fact so fast, that the cost of crossover becomes
dominant.

6.3 Fitness Selection Before Crossover/Mutation
Notice that bottom up evaluation only requires the child‚Äôs new
subtree, e.g. the subtree it will inherit from is ‚Äúfather‚Äù. The rest of
the code is identical to the parent it inherits its root node from (its
‚Äúmother‚Äù). Thus it is easy to implement evaluating the child‚Äôs fitness
before the child has been created (mentioned in Section 5 above).
Given everyone in the population‚Äôs fitness, it is possible to perform
selection and discover who will mate with whom and who, even
by just bad luck, will not mate.

In every evolutionary algorithm, if crossover or mutation is going
to be expensive and we know that the individual is not going to
pass its genetic material on, we do not have to create it.

Early in an EA run, i.e. before convergence, the saving can be
large. For example, with tournament selection and mutation only,
we can save creating on average 1 ‚àí 1/(tournament size) of the
children. E.g. in a generational EA with a diverse population of
fitness values, no elitism, only mutation, and with tournaments of
size 7, on average 86% of the next population will not themselves
have children and so can be safely ignored. Even with 100% two
parent crossover and a fully converged population, 1 ‚àí ùëí2 = 14% of
children will not themselves have children and again need not be
created.

5

Transfer 48 test case values via stackparentRoot donatingMotherFatherFigure 4: The impact of a crossover (red subtree) dissipates the further away from the crossover site we measure it. The
change in fitness test values is shown with coloured nodes. The size of the coloured nodes shows the number of disrupted
test cases. The colour shows, on a log scale, the average difference in evaluation on the remaining disrupted nodes. Brightest
yellow shows smallest non-zero difference (RMS 3.1 10‚àí10). Eventually this crossover has no fitness impact at all. White nodes
are identical before and after the crossover. Dark grey nodes show the part of the tree which does not have to be evaluated.
From [53].

7 DEEP EXPRESSIONS HIDE ERRORS
7.1 Information Theory
Information theory suggests what we have described for floating
point [48, 51] and now integer genetic programming [47] will hold
where there aren‚Äôt side effects to carry information long distances
through program code or GP trees (see Figure 4, page 6). Essentially
the argument is: for a mutation, change, bug, transient error, etc.,
to have an effect it must give rise to a change of state and that
change of state must propagate from the error to the program‚Äôs
output [65]. However, without side effects, the change must pass
through a series of nested digital computations between it and the
program‚Äôs output. Typically each computation has fewer output
states than it has inputs states. (In deterministic programs it can
have the same number of output states as it has input states but
it cannot have more.) As we saw in Section 6.2 with bottom up
evaluation of trees, if at any point, the disrupted execution creates
the same state as the original correct execution, the twin executions
remain locked together, so that when execution reaches any output,
the correct and erroneous calculation, generate identical output.
The error has disappeared3.

Indeed so too has any fitness signal from the mutation. Without
fitness to guide it, evolution becomes an undirected random walk.

3Notice failed disruption propagation (FDP) holds in all digital systems, not just genetic
programming. Any disruption in any deterministic system will tend not to propagate
as it passes through intermediate operations.

6

7.2 Better Testing May Only Help a Little
For GECCO 2022 [49] we showed if fitness tests are independent of
each other and equally effective, then the effectiveness of the whole
test set increases only slowly, O(log ùëõ), with increasing number ùëõ
of fitness tests. If the tests not equal, the test set is dominated by
the most effective tests and the weaker ones contribute little. Of
course if we have insight into the code being tested we may be able
to make much better intelligent choices of test cases values.

7.3 Will Side Effects Help?
In a recent issue of the ACM Special Interest Group on Genetic and
Evolutionary Computation‚Äôs newsletter [46], I argue that to evolve
large complex artifacts of any sort, we must give up on any hope of
evolving large deep structures but instead limit their effective depth
by evolving them close to their environment. Perhaps adapting an
open structure (see Figure 5, page 7), where a flood tide can bring
in new inputs and and out going ebb tide can move the output of
shallow structures both to the environment and to other parts of
our environmentally embedded evolving mycelium like program
or artifact.

8 CONCLUSIONS
We have shown a number of speed up techniques which could
be implemented in other evolutionary algorithms. The C++ code
used by GPquick is available or you may prefer to make your own
implementation of these ideas.

DIVADDSUBSUBXDIVSUBMULX-0.826-0.718DIVMULSUBMUL-0.294-0.621SUB-0.360.026DIV0.2550.997ADDMULSUBDIV0.551DIVDIVSUB0.2550.997DIVSUB0.026DIVADDSUB-0.129XSUBMULMULSUBSUBMULADD0.12ADDSUBDIVSUB0.837XXXDIVSUB0.026DIVADDSUB-0.129XSUBXMULSUB-0.769XXXSUBSUB0.4740.601-0.129X0.2550.9970.799ADDSUBMUL1MULADD0.121MUL-0.6210.8891MULADD0.120.2551DIVSUBADD10.799-0.27310.120.79913MUL4MULADD0.124MULX0.889ADD4ADD0.120.255MUL4SUBADD0.120.799-0.2734SUB-0.129DIV4SUBMULSUBSUB5MULSUB-0.826XSUB37ADDMUL370.120.551MULDIVSUBADD0.120.799-0.273ADDSUB0.026DIVSUBMUL-0.129XADDMULADD0.12SUBSUBX0.889ADDMULADDSUBSUBMULX0.889XMULDIV0.12DIVSUBDIVSUB0.026DIVADDSUBSUBXSUBXMULSUB-0.826XXX-0.129X0.4740.6010.2550.997XX0.837XXX0.799ADDSUBSUBADD-0.129ADDSUBSUBMUL0.997MULDIV0.12DIVSUBDIVSUBXDIVADDSUB-0.129XSUBXMULSUB-0.826XXX-0.129X0.2550.997XSUBSUBSUBMULSUB-0.129XXXSUBSUB0.4740.601-0.1290.9970.837XXX0.2550.997X3838SUB38SUB-0.129X0.79938SUBSUB38MUL380.255ADD0.12SUB47ADDMUL470.120.255MULDIV0.997ADD0.120.799-0.273DIVSUBADDSUBMULSUBSUBXXSUB-0.826XSUBSUB0.4740.601-0.129XXXSUBSUB0.4740.601-0.129X47ADD47SUBSUBSUB47MULADDSUBSUB48XADDADDSUB480.120.551MUL-0.129XSUB-0.826-0.129XX48DIVADDDIVXSUBMULADDSUBSUBXMULSUB-0.826XXXSUBSUB0.4740.601-0.129XXMULDIV0.12DIVSUBDIVSUB0.026DIVADDSUBSUBXSUBXMULSUB-0.826XXX-0.129X0.4740.6010.2550.997XXDIVADDDIV-0.769-0.826X0.5510.6010.837XXX-0.129MULADDDIVX0.8890.837XSUB-0.2940.026DIV0.2550.9970.889ADDSUBSUBADDMULADDSUBSUBMULX0.889ADDMULDIV0.120.551MULDIVMULADD0.120.799-0.273DIVSUB-0.826-0.718ADDDIV-0.129XSUBX0.2550.997-0.826XXSUBSUBSUBMULSUB-0.129XXXSUBSUB0.4740.601-0.129X0.837XXX0.4740.601-0.129XXXSUBSUB0.4740.601-0.129XXX-0.129SUB-0.129X0.255ADD0.799ADDSUBX-0.129MULX0.8890.799ADDSUBX-0.129MULX0.8890.799ADDSUB-0.129ADDMULSUBMULX0.889ADDMULDIVSUB0.551MULDIVSUBADD0.120.799-0.273DIVSUB0.026DIVADDDIVMULSUBSUBXMUL0.997-0.826XXXXXSUBSUB0.4740.601-0.129X0.2550.997XSUBSUBADDSUBSUBMULSUB-0.129XXXSUBSUBDIV0.601-0.129XDIVXADDSUBSUBXMULSUB-0.826XXXSUBSUB0.4740.601-0.129X0.4740.601SUBMUL-0.129MULDIV0.12DIVXDIVSUBADDSUB-0.826SUBSUBXMULSUB-0.826XXX-0.129XSUBSUB0.4740.601-0.129XXSUBSUBSUBMULSUB-0.129XXXSUBSUB0.4740.601-0.1290.997DIVSUB-0.129DIVADDSUBMULSUBSUBXMULSUB-0.826XXXSUBSUB0.4740.601-0.129XXX-0.129SUB-0.129X0.2550.9970.799ADDSUBSUB-0.129MULADDDIVX0.8890.837X-0.273-0.2940.799ADDSUBSUBADDMULSUBSUBSUBMULX0.889ADDMULDIVSUB0.551MULDIVSUBADD0.120.799-0.273DIVMUL0.026DIVADDADDADD0.12SUBXSUBMUL-0.826XSUBMULADD0.12ADDSUBDIVSUB0.837XXXDIVSUB0.026DIVADDSUB-0.129XSUBXMULSUB-0.769XXXSUBSUB0.4740.601-0.129X0.2550.9970.799ADDSUBMULADD0.255ADD0.12SUBMULADDMULADD0.120.255MULDIVSUBADD0.120.799-0.273DIVSUB-0.129DIVADDSUBMULSUBSUBXMULSUB-0.826XXXSUBSUB0.4740.601-0.129XXXSUBSUB0.4740.601-0.129X0.2550.997ADDADDSUBSUBSUBSUBADDMULADDSUBSUBMULXADDADDSUBDIV0.120.551MUL-0.129XSUB-0.826-0.129XXSUBDIVSUBDIVXADDSUBADDSUBSUBXMULSUB-0.826XXXSUBSUB0.4740.601-0.129X0.837XXXDIVADDDIV-0.769-0.826X0.5510.6010.837XXX-0.129MULADDDIVX0.8890.837XSUB-0.2940.026DIV0.2550.9970.799ADDSUBSUBADDMULADDSUBSUBMULX0.889ADDMULDIV0.120.551MULDIVMULADD0.120.799-0.273DIVSUB-0.826-0.718ADDDIV-0.129XSUBX0.2550.997-0.826XXSUBSUBSUBMULSUB-0.129XXXSUBSUB0.4740.601-0.129X0.837XXXADDADDSUBSUBSUBSUBADDMULADDSUBSUBMULX0.889ADDMULDIV0.120.551MULDIVSUBADD0.120.799-0.273DIVSUB0.026DIVADDSUB-0.129XSUBX-0.129X-0.826X0.2550.997XSUBDIVSUBDIVSUB-0.129XADDSUBMULSUBADDXMULMUL0.837XXXADD0.12ADDADDSUBSUBSUBSUBADDMULADDSUBSUBMULX0.889ADDMULDIV0.120.551MULDIVSUBADD0.120.799-0.273DIVSUB0.026DIVADDSUB-0.129XSUBX-0.129X-0.826X0.2550.997XSUBDIVSUBDIVSUB-0.129XADDSUBMULSUBSUBXMULSUB-0.826XXXSUBSUB0.4740.601-0.129XXXSUBSUB0.4740.601-0.129X0.837XXX-0.129MULADDDIVX0.8890.837X-0.129-0.294XXSUBSUB0.4740.601-0.129X0.837XXX-0.129MULADDDIVX0.8890.837X-0.129-0.2940.2550.997XSUBSUBADDSUBSUBMULSUB-0.129XXXSUBSUB0.4740.601-0.129XX0.601ADDMULSUBMULDIV0.12ADDMULDIV0.120.551MULDIVMULADD0.120.799-0.273DIVSUB-0.826-0.718ADDDIV-0.129XSUBX0.2550.997-0.826XXSUBSUBSUBMULSUB-0.129XXXSUBSUB0.4740.601-0.129XXSUB0.12SUB-0.129XADDSUBMULSUB0.837XXXXXSUBSUB0.4740.601-0.129XXXSUBSUB0.4740.601-0.129X0.2550.997MULSUBADD-0.621XXSUBSUB0.4740.601-0.129XDIVADDDIV-0.769-0.826X0.551Xsomewhat tacitly accepted in Software Engineering, because unit
testing places the test oracle, the check for correct output, close to
the error. In the case of SBSE, EAs, Artificial Life, etc., concealing
deep errors, bugs, mutations, etc., means it is hard to see if search
is proceeding. Without a fitness delta, we cannot hope to evolve
anything deep.

Acknowledgements
I would like to thank the EvoSoft 2022 reviewers, Dagstuhl Seminars
17191 on the theory of randomized heuristics and 18052 on Genetic
Improvement of Software [67], for inspiring conversations and the
Meta OOPS project.

C++ code is available in http://www.cs.ucl.ac.uk/staff/W.Langdon/

ftp/gp-code/GPinc.tar.gz

REFERENCES
[1] Michael Affenzeller and Stefan Wagner. 2004. SASEGASA: A New Generic Parallel
Evolutionary Algorithm for Achieving Highest Quality Results. J. Heuristics 10,
3 (2004), 243‚Äì267. http://dx.doi.org/023/B:HEUR.0000026895.72657.a2

[2] David P. Anderson, Jeff Cobb, Eric Korpela, Matt Lebofsky, and Dan Werthimer.
2002. SETI@home: An Experiment in Public-Resource Computing. Commun.
ACM 45, 11 (November 2002), 56‚Äì61. http://dx.doi.org/10.1145/581571.581573
[3] Maribel Garc√≠a Arenas, Pierre Collet, A. E. Eiben, M√°rk Jelasity, Juan Juli√°n Merelo
Guerv√≥s, Ben Paechter, Mike Preu√ü, and Marc Schoenauer. 2002. A Framework
for Distributed Evolutionary Algorithms. In Parallel Problem Solving from Nature
- PPSN VII, 7th International Conference, Granada, Spain, September 7-11, 2002,
Proceedings (Lecture Notes in Computer Science, Vol. 2439), Juan Juli√°n Merelo
Guerv√≥s, Panagiotis Adamidis, Hans-Georg Beyer, Jos√© Luis Fern√°ndez-Villaca√±as
Mart√≠n, and Hans-Paul Schwefel (Eds.). Springer, 665‚Äì675. http://dx.doi.org/007/
3-540-45712-7_64

[4] Forrest H Bennett III, John R. Koza, James Shipman, and Oscar Stiffelman.
1999. Building a Parallel Computer System for $18,000 that Performs a Half
Peta-Flop per Day. In GECCO, Wolfgang Banzhaf, Jason Daida, Agoston E.
Eiben, Max H. Garzon, Vasant Honavar, Mark Jakiela, and Robert E. Smith
(Eds.), Vol. 2. Morgan Kaufmann, Orlando, Florida, USA, 1484‚Äì1490.
http:
//www.genetic-programming.com/jkpdf/gecco1999beowulf.pdf

[5] Enzo Bolis, Christian Zerbi, Pierre Collet, Jean Louchet, and Evelyne Lutton.
2001. A GP Artificial Ant for image processing: preliminary experiments with
EASEA. In Genetic Programming, Proceedings of EuroGP‚Äô2001 (LNCS, Vol. 2038),
Julian F. Miller, Marco Tomassini, Pier Luca Lanzi, Conor Ryan, Andrea G. B.
Tettamanzi, and William B. Langdon (Eds.). Springer-Verlag, Lake Como, Italy,
246‚Äì255. http://dx.doi.org/10.1007/3-540-45355-5_19

[6] Bogdan Burlacu, Gabriel Kronberger, and Michael Kommenda. 2020. Operon
C++: An Efficient Genetic Programming Framework for Symbolic Regression.
In GECCO Companion (GECCO ‚Äô20), Richard Allmendinger et al. (Eds.). Associa-
tion for Computing Machinery, internet, 1562‚Äì1570. http://dx.doi.org/10.1145/
3377929.3398099

[7] S. Cahon, N. Melab, and E. G. Talbi. 2004. ParadisEO: A Framework for the
Reusable Design of Parallel and Distributed Metaheuristics. Journal of Heuris-
tics 10, 3 (May 2004), 357‚Äì380. http://dx.doi.org/10.1023/B:HEUR.0000026900.
92269.ec Special Issue: New Advances on Parallel Meta-Heuristics for Complex
Problems.

[8] Fuey Sian Chong and W. B. Langdon. 1999.

Java based Distributed Genetic
Programming on the Internet. In GECCO, Wolfgang Banzhaf, Jason Daida, Agos-
ton E. Eiben, Max H. Garzon, Vasant Honavar, Mark Jakiela, and Robert E.
Smith (Eds.), Vol. 2. Morgan Kaufmann, Orlando, Florida, USA, 1229. http:
//www.cs.ucl.ac.uk/staff/W.Langdon/ftp/papers/p.chong/DGPposter.pdf Full text
in technical report CSRP-99-7.

[9] Vinicius Veloso de Melo, Alvaro Luiz Fazenda, Leo Francoso Dal Piccol Sotto,
and Giovanni Iacca. 2020. A MIMD Interpreter for Genetic Programming. In 23rd
International Conference, EvoApplications 2020 (LNCS, Vol. 12104), Pedro A. Castillo,
Juan Luis Jimenez Laredo, and Francisco Fernandez de Vega (Eds.). Springer
Verlag, Seville, Spain, 645‚Äì658. http://dx.doi.org/10.1007/978-3-030-43722-0_41
[10] Iddo Drori, Brandon J Kates, William R. Sickinger, Anant Girish Kharkar, Brenda
Dietrich, Avi Shporer, and Madeleine Udell. 2020. Galaxy TSP: A new billion-
node benchmark for TSP. In NeurIPS Workshop on Learning Meets Combinatorial
Algorithms. https://www.cs.columbia.edu/~idrori/galaxytsp.pdf

[11] Francisco Fernandez de Vega and Erick Cantu-Paz (Eds.). 2010. Parallel and
Distributed Computational Intelligence (1st ed.). Studies in Computational Intelli-
gence, Vol. 269. Springer. http://dx.doi.org/10.1007/978-3-642-10675-0

Figure 5: Proposed lung like open complex evolving sys-
tem composed of 1300 separate shallow GP programs. These
compute element are placed side-by-side to form an open
structure. The gaps promote short cut side effects be-
tween functions‚Äô input and outputs and the environment.
From [46].

As a few of the citations have shown, the ideas of distributed
parallel running are widely known in evolutionary algorithms.
However GPU and TPU implementations are at present thinner on
the ground. Replicating SETI@home‚Äôs success with evolutionary
search might also be worth another look.

Similarly if you are interested in using EAs on problems with a
population of large chromosomes, some of the ideas for reducing
memory consumption or speeding up crossover/mutation might be
useful.

Alternatively if you are hoping to run evolution on tiny ‚Äúmote‚Äù,
embeded, internet of things (IOT) or ‚Äúedge computing‚Äù devices,
these ideas for shoehorning genetic programming (GP) into the
available memory may also be interesting.

The vast bulk of GP uses static fitness test and primitives without
side effects and thus the GPquick implementation I have sketched
could be of interest.

Perhaps the most important result, due to its universality, was
unlooked for: as structures get deeper it becomes harder to measure
the impact of changes. Although good choices of test cases can
help, simply increasing the number ùëõ of test cases can perhaps only
make a slow O(log(ùëõ)) improvement. The impossibility of deeply
probing applies to programming in general not just to evolutionary
algorithms. Notice the prevalence of unit testing shows this is

7

[12] James A. Foster. 2001. Review: Discipulus: A Commercial Genetic Programming
System. Genetic Programming and Evolvable Machines 2, 2 (June 2001), 201‚Äì203.
http://dx.doi.org/10.1023/A:1011516717456

[13] Frank D. Francone. 2001. Discipulus Owner‚Äôs Manual (version 3.0 draft ed.).
11757 W. Ken Caryl Avenue F, PBM 512, Littleton, Colorado, 80127-3719, USA.
http://gpbib.cs.ucl.ac.uk/gp-html/francone_manual.html

[14] A. P. Fraser and J. R. Rush. 1994. Putting INK into a BIRo: A discussion of problem
domain knowledge for evolutionary robotics. In AISB Workshop on Evolutionary
Computing, T. C. Fogarty (Ed.). Leeds, UK.

[15] Alex Fukunaga, Andre Stechert, and Darren Mutz. 1998. A Genome Com-
piler for High Performance Genetic Programming. In Genetic Programming
1998: Proceedings of the Third Annual Conference, John R. Koza, Wolfgang
Banzhaf, Kumar Chellapilla, Kalyanmoy Deb, Marco Dorigo, David B. Fogel,
Max H. Garzon, David E. Goldberg, Hitoshi Iba, and Rick Riolo (Eds.). Mor-
gan Kaufmann, University of Wisconsin, Madison, Wisconsin, USA, 86‚Äì94.
http://metahack.org/gp98-compiler.pdf

[16] Chris Gathercole. 1998. An Investigation of Supervised Learning in Genetic Pro-
gramming. Ph.D. Dissertation. University of Edinburgh, UK. http://hdl.handle.
net/1842/533

[17] Chris Gathercole and Peter Ross. 1994. Dynamic Training Subset Selection for
Supervised Learning in Genetic Programming. In Parallel Problem Solving from
Nature III (LNCS, Vol. 866), Yuval Davidor, Hans-Paul Schwefel, and Reinhard
M√§nner (Eds.). Springer-Verlag, Jerusalem, 312‚Äì321. http://dx.doi.org/10.1007/
3-540-58484-6_275

[18] Yue-Jiao Gong, Wei-Neng Chen, Zhi-Hui Zhan, Jun Zhang, Yun Li, Qingfu Zhang,
and Jing-Jing Li. 2015. Distributed evolutionary algorithms and their models:
A survey of the state-of-the-art. Applied Soft Computing 34 (2015), 286‚Äì300.
http://dx.doi.org/10.1016/j.asoc.2015.04.061

[19] Timothy Glennie Wilson Gordon. 2005. Exploiting Development to Enhance the
Scalability of Hardware Evolution. Ph.D. Dissertation. University College, London,
UK. https://discovery.ucl.ac.uk/id/eprint/1444775/

[20] Michal Gregor and Juraj Spalek. 2016. Using LLVM-based JIT compilation in
genetic programming. In 2016 ELEKTRO. IEEE, Strbske Pleso, Slovakia, 406‚Äì411.
http://dx.doi.org/10.1109/ELEKTRO.2016.7512108

[21] S. Handley. 1994. On the use of a directed acyclic graph to represent a popula-
tion of computer programs. In Proceedings of the 1994 IEEE World Congress on
Computational Intelligence, Vol. 1. IEEE Press, Orlando, Florida, USA, 154‚Äì159.
http://dx.doi.org/10.1109/ICEC.1994.350024

[22] Simon Harding and Wolfgang Banzhaf. 2007. Fast genetic programming on GPUs.
In Proceedings of the 10th European Conference on Genetic Programming (Lecture
Notes in Computer Science, Vol. 4445), Marc Ebner, Michael O‚ÄôNeill, Anik√≥ Ek√°rt,
Leonardo Vanneschi, and Anna Isabel Esparcia-Alc√°zar (Eds.). Springer, Valencia,
Spain, 90‚Äì101. http://dx.doi.org/10.1007/978-3-540-71605-1_9

[23] S. Harding and W. Banzhaf. 2008. Genetic programming on GPUs for image
processing. International Journal of High Performance Systems Architecture 1, 4
(2008), 231‚Äì240. http://dx.doi.org/10.1504/IJHPSA.2008.024207

[24] Radek Hrbacek and Lukas Sekanina. 2014. Towards highly optimized cartesian
genetic programming: from sequential via SIMD and thread to massive parallel
implementation. In GECCO ‚Äô14, Christian Igel et al. (Eds.). ACM, Vancouver, BC,
Canada, 1015‚Äì1022. http://dx.doi.org/10.1145/2576768.2598343

[25] I. M. Ikram. 1996. An occam Library for Genetic Programming on Transputer
Networks. In Proceedings of the International Conference on Parallel and Dis-
tributed Processing Techniques and Applications, Hamid R. Arabnia (Ed.). CSREA,
Sunnyvale, California, 1186‚Äì1189.

[26] Hugues Juille and Jordan B. Pollack. 1995. Parallel Genetic Programming and
Fine-Grained SIMD Architecture. In Working Notes for the AAAI Symposium on
Genetic Programming, E. V. Siegel and J. R. Koza (Eds.). AAAI, MIT, Cambridge,
MA, USA, 31‚Äì37. http://www.aaai.org/Papers/Symposia/Fall/1995/FS-95-01/
FS95-01-005.pdf

[27] Hugues Juille and Jordan B. Pollack. 1996. Massively Parallel Genetic Pro-
gramming.
In Advances in Genetic Programming 2, Peter J. Angeline and
K. E. Kinnear, Jr. (Eds.). MIT Press, Cambridge, MA, USA, Chapter 17, 339‚Äì357.
http://dx.doi.org/10.7551/mitpress/1109.003.0023

[28] Mike J. Keith and Martin C. Martin. 1994. Genetic Programming in C++: Imple-
mentation Issues. In Advances in Genetic Programming, Kenneth E. Kinnear, Jr.
(Ed.). MIT Press, Chapter 13, 285‚Äì310. http://cognet.mit.edu/sites/default/files/
books/9780262277181/pdfs/9780262277181_chap13.pdf

[29] Hanna Kokko. 2021. The stagnation paradox: the ever-improving but (more or
less) stationary population fitness. Proceedings of the Royal Society B: Biological
Sciences 288, 1963 (2021), 20212145. http://dx.doi.org/10.1098/rspb.2021.2145

[30] John R. Koza. 1992. Genetic Programming: On the Programming of Computers by
Means of Natural Selection. MIT Press, Cambridge, MA, USA. http://mitpress.
mit.edu/books/genetic-programming

[31] John R. Koza and David Andre. 1995. Parallel Genetic Programming on a Network
of Transputers. Technical Report CS-TR-95-1542. Stanford University, Department
of Computer Science. http://i.stanford.edu/TR/CS-TR-95-1542.html

[32] John R. Koza, David Andre, Forrest H Bennett III, and Martin Keane. 1999. Genetic
Programming III: Darwinian Invention and Problem Solving. Morgan Kaufmann.

8

http://www.genetic-programming.org/gpbook3toc.html

[33] William La Cava, Patryk Orzechowski, Bogdan Burlacu, Fabricio de
Franca, Marco Virgolin, Ying Jin, Michael Kommenda, and Jason Moore.
2021.
Contemporary Symbolic Regression Methods and their Relative
Performance. In Proceedings of the Neural Information Processing Systems
Track on Datasets and Benchmarks, J. Vanschoren and S. Yeung (Eds.),
Vol. 1. https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/
c0c7c76d30bd3dcaefc96f40275bdc0a-Abstract-round1.html

[34] William B. Langdon. 1998. Genetic Programming and Data Structures: Genetic
Programming + Data Structures = Automatic Programming! Genetic Programming,
Vol. 1. Kluwer, Boston. http://dx.doi.org/10.1007/978-1-4615-5731-9

[35] W. B. Langdon. 2012. Distilling GeneChips with Genetic Programming on the
Emerald GPU supercomputer. SIGEVOlution newsletter of the ACM Special Interest
Group on Genetic and Evolutionary Computation 6, 1 (25 July 2012), 15‚Äì21. http:
//dx.doi.org/10.1145/2384697.2384699

[36] W. B. Langdon. 2012. Genetic Improvement of Programs. In 18th International
Conference on Soft Computing, MENDEL 2012 (2nd ed.), Radomil Matousek (Ed.).
Brno University of Technology, Brno, Czech Republic. http://www.cs.ucl.ac.uk/
staff/W.Langdon/ftp/papers/Langdon_2012_mendel.pdf Invited keynote.
[37] William B. Langdon. 2013. Large Scale Bioinformatics Data Mining with Parallel
Genetic Programming on Graphics Processing Units. In Massively Parallel Evo-
lutionary Computation on GPGPUs, Shigeyoshi Tsutsui and Pierre Collet (Eds.).
Springer, Chapter 15, 311‚Äì347. http://dx.doi.org/10.1007/978-3-642-37959-8_15
[38] William B. Langdon. 2017. Long-Term Evolution of Genetic Programming Pop-
http:
ulations. In GECCO Companion (GECCO ‚Äô17). ACM, Berlin, 235‚Äì236.
//dx.doi.org/10.1145/3067695.3075965

[39] W. B. Langdon. 2019. Parallel GPQUICK. In GECCO ‚Äô19 Companion, Carola Doerr
(Ed.). ACM, Prague, Czech Republic, 63‚Äì64. http://dx.doi.org/10.1145/3319619.
3326770

[40] W. B. Langdon. 2020. Genetic Improvement of Genetic Programming. In GI @
CEC 2020 Special Session, Alexander (Sandy) Brownlee, Saemundur O. Haraldsson,
Justyna Petke, and John R. Woodward (Eds.). IEEE Computational Intelligence
Society, IEEE Press, internet, paper id24061. http://dx.doi.org/10.1109/CEC48606.
2020.9185771

[41] W. B. Langdon. 2020. Multi-threaded Memory Efficient Crossover in C++ for
Generational Genetic Programming. SIGEVOLution newsletter of the ACM Special
Interest Group on Genetic and Evolutionary Computation 13, 3 (Oct. 2020), 2‚Äì4.
http://dx.doi.org/10.1145/3430913.3430914

[42] W. B. Langdon. 2020. Multi-threaded Memory Efficient Crossover in C++ for
Generational Genetic Programming. ArXiv. arXiv:2009.10460 [cs.NE] http:
//arxiv.org/abs/2009.10460

[43] William B. Langdon. 2021. Fitness First. In Genetic Programming Theory and Prac-
tice XVIII (Genetic and Evolutionary Computation), Wolfgang Banzhaf, Leonardo
Trujillo, Stephan Winkler, and Bill Worzel (Eds.). Springer, East Lansing, MI, USA,
143‚Äì164. http://dx.doi.org/10.1007/978-981-16-8113-4_8

[44] William B. Langdon. 2021. Fitness First and Fatherless Crossover. In GECCO Com-
panion (GECCO ‚Äô21), Francisco Chicano et al. (Eds.). Association for Computing
Machinery, Internet, 253‚Äì254. http://dx.doi.org/10.1145/3449726.3459437
[45] William B. Langdon. 2021. Incremental Evaluation in Genetic Programming. In
EuroGP 2021: Proceedings of the 24th European Conference on Genetic Programming
(LNCS, Vol. 12691), Ting Hu, Nuno Lourenco, and Eric Medvet (Eds.). Springer
Verlag, Virtual Event, 229‚Äì246. http://dx.doi.org/10.1007/978-3-030-72812-0_15
[46] W. B. Langdon. 2022. Evolving Open Complexity. SIGEVOlution newsletter of
the ACM Special Interest Group on Genetic and Evolutionary Computation 15, 1
(March 2022). http://dx.doi.org/10.1145/3532942.3532945

[47] William B. Langdon. 2022. Failed Disruption Propagation in Integer Genetic
Programming. In GECCO Companion (GECCO ‚Äô22), Heike Trautmann et al. (Eds.).
Association for Computing Machinery, Boston, USA. http://dx.doi.org/10.1145/
3520304.3528878

[48] W. B. Langdon. 2022. Genetic Programming Convergence. Genetic Programming
and Evolvable Machines 23, 1 (March 2022), 71‚Äì104. http://dx.doi.org/10.1007/
s10710-021-09405-9

[49] William B. Langdon, Afnan Al-Subaihin, and David Clark. 2022. Measuring
Failed Disruption Propagation in Genetic Programming. In GECCO (GECCO ‚Äô22),
Alma Rahat et al. (Eds.). Association for Computing Machinery, Boston, USA.
http://dx.doi.org/10.1145/3512290.3528738

[50] William B. Langdon and Wolfgang Banzhaf. 2008. A SIMD Interpreter for Genetic
Programming on GPU Graphics Cards. In Proceedings of the 11th European Con-
ference on Genetic Programming, EuroGP 2008 (Lecture Notes in Computer Science,
Vol. 4971), Michael O‚ÄôNeill, Leonardo Vanneschi, Steven Gustafson, Anna Isabel
Esparcia Alcazar, Ivanoe De Falco, Antonio Della Cioppa, and Ernesto Tarantino
(Eds.). Springer, Naples, 73‚Äì85. http://dx.doi.org/10.1007/978-3-540-78671-9_7
[51] William B. Langdon and Wolfgang Banzhaf. 2022. Long-Term Evolution Experi-
ment with Genetic Programming. Artificial Life 28, 2 (2022). http://www.cs.ucl.
ac.uk/staff/W.Langdon/ftp/papers/Langdon_2022_ALJ.pdf Invited submission to
Artificial Life Journal special issue of the ALIFE‚Äô19 conference.

2007), 80‚Äì113. http://dx.doi.org/10.1111/j.1467-8659.2007.01012.x

[65] Justyna Petke, David Clark, and William B. Langdon. 2021. Software Robustness:
A Survey, a Theory, and Some Prospects. In ESEC/FSE 2021, Ideas, Visions and
Reflections, Paris Avgeriou and Dongmei Zhang (Eds.). ACM, Athens, Greece,
1475‚Äì1478. http://dx.doi.org/10.1145/3468264.3473133

[66] Justyna Petke, Saemundur O. Haraldsson, Mark Harman, William B. Langdon,
David R. White, and John R. Woodward. 2018. Genetic Improvement of Software:
a Comprehensive Survey. IEEE Transactions on Evolutionary Computation 22, 3
(June 2018), 415‚Äì432. http://dx.doi.org/doi:10.1109/TEVC.2017.2693219

[67] Justyna Petke, Claire Le Goues, Stephanie Forrest, and William B. Langdon. 2018.
Genetic Improvement of Software: Report from Dagstuhl Seminar 18052. Dagstuhl
Reports 8, 1 (23 July 2018), 158‚Äì182. http://dx.doi.org/10.4230/DagRep.8.1.158

[68] Riccardo Poli and William B. Langdon. 1999. Sub-machine-code Genetic Program-
ming. In Advances in Genetic Programming 3, Lee Spector, William B. Langdon,
Una-May O‚ÄôReilly, and Peter J. Angeline (Eds.). MIT Press, Cambridge, MA, USA,
Chapter 13, 301‚Äì323. http://www.cs.ucl.ac.uk/staff/W.Langdon/aigp3/ch13.pdf
[69] Riccardo Poli, William B. Langdon, and Nicholas Freitag McPhee. 2008. A field
guide to genetic programming. Published via http://lulu.com and freely avail-
able at http://www.gp-field-guide.org.uk. http://www.gp-field-guide.org.
uk (With contributions by J. R. Koza).

[70] Riccardo Poli and Jonathan Page. 2000. Solving High-Order Boolean Parity
Problems with Smooth Uniform Crossover, Sub-Machine Code GP and Demes.
Genetic Programming and Evolvable Machines 1, 1/2 (April 2000), 37‚Äì56. http:
//dx.doi.org/10.1023/A:1010068314282

[71] Craig W. Reynolds. 1994. Competition, Coevolution and the Game of Tag. In
Proceedings of the Fourth International Workshop on the Synthesis and Simulation
of Living Systems, Rodney A. Brooks and Pattie Maes (Eds.). MIT Press, MIT,
Cambridge, MA, USA, 59‚Äì69. http://www.cs.ucl.ac.uk/staff/W.Langdon/ftp/ftp.
io.com/papers/cwrALifeIV.ps.Z

[72] Andy Singleton. 1994. Genetic Programming with C++. BYTE (Feb. 1994), 171‚Äì176.

http://www.assembla.com/wiki/show/andysgp/GPQuick_Article

[73] Lee Spector. 2012. Assessment of Problem Modality by Differential Perfor-
mance of Lexicase Selection in Genetic Programming: A Preliminary Report.
In 1st workshop on Understanding Problems (GECCO-UP), Kent McClymont and
Ed Keedwell (Eds.). ACM, Philadelphia, Pennsylvania, USA, 401‚Äì408.
http:
//dx.doi.org/10.1145/2330784.2330846

[74] Walter Alden Tackett and Aviram Carmi. 1994. The unique implications of brood
selection for genetic programming. In Proceedings of the 1994 IEEE World Congress
on Computational Intelligence, Vol. 1. IEEE Press, Orlando, Florida, USA, 160‚Äì165.
http://dx.doi.org/10.1109/ICEC.1994.350023

[75] Astro Teller and David Andre. 1997. Automatically Choosing the Number of
Fitness Cases: The Rational Allocation of Trials. In Genetic Programming 1997:
Proceedings of the Second Annual Conference, John R. Koza, Kalyanmoy Deb,
Marco Dorigo, David B. Fogel, Max Garzon, Hitoshi Iba, and Rick L. Riolo (Eds.).
Morgan Kaufmann, Stanford University, CA, USA, 321‚Äì328. http://www.cs.cmu.
edu/afs/cs/usr/astro/public/papers/GR.ps

[76] Zdenek Vasicek and Karel Slany. 2012. Efficient Phenotype Evaluation in Carte-
sian Genetic Programming. In Proceedings of the 15th European Conference on
Genetic Programming, EuroGP 2012 (LNCS, Vol. 7244), Alberto Moraglio, Sara
Silva, Krzysztof Krawiec, Penousal Machado, and Carlos Cotta (Eds.). Springer
Verlag, Malaga, Spain, 266‚Äì278. http://dx.doi.org/10.1007/978-3-642-29139-5_23
[77] Stefan Wagner and Michael Affenzeller. 2004. HeuristicLab Grid - a flexible
Systems
https://yadda.icm.edu.pl/yadda/element/

and extensible environment for parallel heuristic optimization.
Science 30, 4 (2004), 103‚Äì110.
bwmeta1.element.baztech-article-BAT5-0008-0054?q=bwmeta1.element.
baztech-volume-0137-1223-systems_science-2004-vol__30_no_4;9

[52] W. B. Langdon and A. P. Harrison. 2008. GP on SPMD parallel Graphics Hardware
for mega Bioinformatics Data Mining. Soft Computing 12, 12 (Oct. 2008), 1169‚Äì
1183. http://dx.doi.org/10.1007/s00500-008-0296-x Special Issue on Distributed
Bioinspired Algorithms.

[53] William B. Langdon, Justyna Petke, and David Clark. 2021. Information Loss
Leads to Robustness. IEEE Software Blog. http://blog.ieeesoftware.org/2021/09/
information-loss-leads-to-robustness-w.html

[54] W. B. Langdon and R. Poli. 1998. Why Ants are Hard. In Genetic Program-
ming 1998: Proceedings of the Third Annual Conference, John R. Koza, Wolfgang
Banzhaf, Kumar Chellapilla, Kalyanmoy Deb, Marco Dorigo, David B. Fogel,
Max H. Garzon, David E. Goldberg, Hitoshi Iba, and Rick Riolo (Eds.). Mor-
gan Kaufmann, University of Wisconsin, Madison, Wisconsin, USA, 193‚Äì201.
http://www.cs.ucl.ac.uk/staff/W.Langdon/ftp/papers/WBL.antspace_gp98.pdf

[55] J. L. J. Laredo, P. Bouvry, D. L. Gonzalez, F. Fernandez de Vega, M. G. Arenas, J. J.
Merelo, and C. M. Fernandes. 2014. Designing robust volunteer-based evolution-
ary algorithms. Genetic Programming and Evolvable Machines 15, 3 (Sept. 2014),
221‚Äì244. http://dx.doi.org/10.1007/s10710-014-9213-5

[56] J. L. J. Laredo, A. E. Eiben, M. van Steen, and J. J. Merelo. 2010. EvAg: a scal-
able peer-to-peer evolutionary algorithm. Genetic Programming and Evolvable
Machines 11, 2 (June 2010), 227‚Äì246. http://dx.doi.org/10.1007/s10710-009-9096-z
[57] Richard E. Lenski. 1988. Experimental studies of pleiotropy and epistasis in
Escherichia coli. I. Variation in competitive fitness among mutants resistant
to virus T4. Evolution 42, 3 (May 1988), 425‚Äì432. http://dx.doi.org/10.1111/j.
1558-5646.1988.tb04149.x

[58] Richard E. Lenski et al. 2015. Sustained fitness gains and variability in fitness
trajectories in the long-term evolution experiment with Escherichia coli. Pro-
ceedings of the Royal Society B 282, 1821 (22 December 2015). http://dx.doi.org/
10.1098/rspb.2015.2292

[59] Ogier Maitre. 2013. Genetic Programming on GPGPU cards using EASEA. In
Massively Parallel Evolutionary Computation on GPGPUs, Shigeyoshi Tsutsui and
Pierre Collet (Eds.). Springer, Chapter 11, 227‚Äì248. http://dx.doi.org/10.1007/
978-3-642-37959-8_11

[60] Sidney R. Maxwell III. 1994. Experiments with a coroutine execution model
for genetic programming. In Proceedings of the 1994 IEEE World Congress on
Computational Intelligence, Vol. 1. IEEE Press, Orlando, Florida, USA, 413‚Äì417a.
http://dx.doi.org/10.1109/ICEC.1994.349915

[61] Nicholas Freitag McPhee, Nicholas J. Hopper, and Mitchell L. Reierson. 1998.
Sutherland: An extensible object-oriented software framework for evolutionary
computation. In Genetic Programming 1998: Proceedings of the Third Annual
Conference, John R. Koza, Wolfgang Banzhaf, Kumar Chellapilla, Kalyanmoy Deb,
Marco Dorigo, David B. Fogel, Max H. Garzon, David E. Goldberg, Hitoshi Iba,
and Rick Riolo (Eds.). Morgan Kaufmann, University of Wisconsin, Madison,
Wisconsin, USA, 241. http://facultypages.morris.umn.edu/~mcphee/Research/
Sutherland/sutherland_gp98_announcement.ps.gz

[62] Peter Nordin. 1997.

Evolutionary Program Induction of Binary Machine
Ph.D. Dissertation. der Universitat Dort-
http://www.amazon.co.uk/

Code and its Applications.
mund am Fachereich Informatik, Germany.
Evolutionary-Program-Induction-Machine-Applications/dp/3931546071
[63] Peter Nordin and Wolfgang Banzhaf. 1995. Evolving Turing-Complete Pro-
grams for a Register Machine with Self-modifying Code. In Genetic Algorithms:
Proceedings of the Sixth International Conference (ICGA95), Larry J. Eshelman
(Ed.). Morgan Kaufmann, Pittsburgh, PA, USA, 318‚Äì325. http://www.cs.mun.ca/
~banzhaf/papers/icga95-2.pdf

[64] John D. Owens, David Luebke, Naga Govindaraju, Mark Harris, Jens Kruger,
Aaron E. Lefohn, and Timothy J. Purcell. 2007. A Survey of General-Purpose
Computation on Graphics Hardware. Computer Graphics Forum 26, 1 (March

9

