To Appear in IEEE Computer Architecture Letters (CAL) 2022

Characterizing and Understanding
Distributed GNN Training on GPUs

2
2
0
2

r
p
A
8
1

]

C
D
.
s
c
[

1
v
0
5
1
8
0
.
4
0
2
2
:
v
i
X
r
a

Haiyang Lin, Mingyu Yan, Xiaocheng Yang, Mo Zou, Wenming Li, Xiaochun Ye, Dongrui Fan

Abstract—Graph neural network (GNN) has been demonstrated to be a powerful model in many domains for its effectiveness in
learning over graphs. To scale GNN training for large graphs, a widely adopted approach is distributed training which accelerates
training using multiple computing nodes. Maximizing the performance is essential, but the execution of distributed GNN training
remains preliminarily understood. In this work, we provide an in-depth analysis of distributed GNN training on GPUs, revealing several
signiﬁcant observations and providing useful guidelines for both software optimization and hardware optimization.

Index Terms—Graph neural networks, distributed training, characterization, GPU, mini-batch.

(cid:70)

1 INTRODUCTION

Graph neural networks (GNNs) have achieved huge
success in handling graph data, and have been applied to
various applications in social networks, recommendations,
etc. Scaling GNN training for large graphs, which consists
of millions or even billions of edges [1], is exposed to signiﬁ-
cant time overhead. In order to shorten the deployment time
of GNN, distributed training is a widely adopted method
that equips the training system with more computing re-
sources to accelerate the training of GNN [2], [3], [4].

Distributed training of GNNs can be approached in two
ways - distributed full-batch training [4] and distributed
mini-batch training [2], [3]. Distributed full-batch training
updates the GNN model with the whole graph in every
forward and backward propagation [4], while distributed
mini-batch training only uses part of vertices and edges
through sampling method [2], [3]. Distributed mini-batch
training is more efﬁcient than distributed full-batch training
as it needs much less time to converge on large graphs
while maintaining accuracy [5]. In this work, we focus on
distributed mini-batch training on GPUs.

Many researchers are working on optimizing GNN train-
ing while the execution of it remains preliminarily under-
stood, resulting in the inefﬁciency of optimization [6]. To
systematically understand GNN training on GPUs, analysis
of the end-to-end execution is urgently needed. However,
the existing characterization work on GNN training execu-
tion focuses on single GPU execution [6], [7], while the end-

• H. Lin, M. Yan, M. Zou, W. Li, X. Ye and D. Fan are with SKLCA, Insti-
tute of Computing Technology (ICT), Chinese Academy of Sciences (CAS),
Beijing 100864, China and also with the University of Chinese Academy
of Sciences (UCAS), Beijing 100049, China. E-mail: {linhaiyang18z,
Yanmingyu, zoumo, liwenming, yexiaochun, fandr}@ict.ac.cn

• X. Yang is with Institute of Computing Technology (ICT), Chinese
Academy of Sciences (CAS), Beijing 100864, China. E-mail: yangxi-
aocheng@ict.ac.cn

This work was supported by the Strategic Priority Research Program of
Chinese Academy of Sciences (Grant No. XDC05000000), National Nat-
ural Science Foundation of China (Grant No. 61732018 and 61872335),
Austrian-Chinese Cooperative R&D Project (FFG and CAS) (Grant No.
171111KYSB20200002), CAS Project for Young Scientists in Basic Research
(Grant No. YSBR-029), and CAS Project for Youth Innovation Promotion
Association. The corresponding author is Mingyu Yan.

to-end execution of distributed GNN training has not been
systematically analyzed, especially from the perspective of
the parallel workers’ interaction. To the best of our knowl-
edge, this is the ﬁrst characterization work on the end-to-
end execution of distributed GNN training.

In this work, we have an in-depth analysis of distributed
GNN training through proﬁling the end-to-end execu-
tion with the state-of-the-art framework, Pytorch-Geometric
(PyG) [8], revealing several signiﬁcant observations and
providing useful guidelines for both software optimiza-
tion and hardware optimization. To have a comprehensive
knowledge of the end-to-end execution, we divide the exe-
cution into four phases - Sampling, Data Loading, Computing
(Forward and Backward Propagation), Gradient Synchronization.
We ﬁrst provide an overview of the end-to-end execution
and then probe into the interaction of the parallel workers
in each phase to ﬁnd out the factors hindering the perfor-
mance improvement. The key observations and insights are
summarized below:

• Overview of the End-to-End Execution: 1 The data load-
ing phase is the most time-consuming phase. 2 The
gradient synchronization phase becomes more time-
consuming when the number of GPUs increases. 3 The
acceleration ratio using multiple GPUs has a signiﬁcant
gap compared to the ideal acceleration ratio.

• Interaction of the Parallel Workers: 4 Serious competition
of CPU shared cache between the sampling threads. 5
Non-negligible bandwidth competition during the data
loading phase. 6 Increasing synchronization time due
to imbalance of CPU side.

Base on these insights, we provide several useful guide-

lines for both software and hardware optimizations.

• Software Optimizations: 1) Localized Sampling for 4 -
use clustering algorithm for vertices to improve cache
reuse. 2) Pipeline Overlap and Caching for 5 - pipeline
the data transferring and computing, and cache fre-
quently used features in GPU memory. 3) Workload
Balance Strategy for 6 - equip the system with backup
threads to alleviate the imbalance effect.

• Hardware Optimizations: 1) Separated Cache for 4 -

 
 
 
 
 
 
enable the shared cache to support separate cache
management. 2) Hybrid Architecture for 5 - conduct
sampling and computing on hybrid architecture. 3)
Data Compression for 5 - use compression to minimize
the size of transmitted data.

2 BACKGROUND AND RELATED WORK
Graph Neural Network: GNN has been dominated to be
an effective model for learning knowledge from structured
graph data. A GNN model consists of one or multiple layers
and each GNN layer is composed of neighbor aggregation
and neural network operations. The neighbor aggregation
means gathering the activations of the neighbor vertices
from the previous GNN layer while the neural network
operations are applied to update the activations of the
vertices. The computation is formally expressed as follow:

v = Aggregate({hi−1
si
v = U pdate(si
hi

v, hi−1
v

)

u |u ∈ N (v)})

(1)

(2)

where hi
v is the activation of vertex v at the i-th layer
and N (v) donates the neighbors of vertex v. si
v is the
aggregation result of vertex v at the i-th layer. Aggregate( )
and U pdate( ) are customized or parameterized functions.
Mini-batch Distributed GNN Training: mini-batch
training is more and more popular nowadays in distributed
training of GNN [2], [3]. Fig. 1 demonstrates the execution
of mini-batch distributed GNN training which can be di-
vided into four phases - Sampling, Data Loading, Computing
(Forward and Backward Propagation), Gradient Synchronization.
The whole graph data is kept on the host side, i.e., CPU
memory, as the scale of data is too large for GPU memory.
In each epoch, the CPU threads sample mini-batches con-
sisting of partial vertices and edges 1(cid:13). The mini-batches
are then loaded to GPU memory for forward propagation
and backward propagation 2(cid:13), 3(cid:13). Then GPUs communicate
with each other for synchronization to update the weights
of the GNN model 4(cid:13).

Fig. 1. Mini-batch distributed GNN training.
3 EVALUATION SETUP
GNNs and Datasets: we choose three popular GNN models
- GCN [9], GAT [10], GraphSAGE [11], and three datasets
- Reddit [11], Products [1], Papers [1]. Table 1 lists the
details of the three datasets. The “feat” column represents
the dimension of vertex features and the “class” column
represents the number of vertex classes. Each GNN is com-
posed of 2 layers and the mini-batch size is 1024 targe nodes.
The hidden layer dimension is 256. The sampling strategy
is node-wise sampling [11]. It samples 10 neighbors in the
ﬁrst layer and 25 neighbors in the second layer.

Proﬁling Platform: we deploy the experiments on a
multi-GPU server which consists of 2 Intel Xeon Silver 4208
CPUs (each with 8 cores) and 4 NVIDIA Tesla T4 GPUs.

TABLE 1
Statistics of the datasets. [1], [11]

2

Datasets
Reddit
Products
Papers

#vertex
232,965
2,449,029
111,059,956

#edge
114,615,892
123,718,280
1,615,685,872

#feat
602
100
128

#class
41
47
172

Each socket has two GPUs. The communication library is
NCCL v2.10.3 and the gradient synchronization uses All-
Reduce strategy. The GPUs use PCIe 3.0 x8. The machine
is installed with Ubuntu 20.04.3 LTS, CUDA library v11.3,
PyTorch v1.10, and PyG v2.0.2 [8]. We use NVIDIA Nsight
Systems v2021.2.1 to analyze the details in GPU execution.
We use Perf to obtain the CPU execution performance
indexes. We set the number of PyTorch dataloader workers
for each process as 4 to fully utilize the CPU resource as
the number of CPU cores is 16. The class of dataloader we
used is PyG NeighborLoader with default settings except
for num workers and batch size. The experimental data
averages from 5 epochs execution. We choose PyG, one of
the most popular frameworks in GNN community.
4 OVERVIEW OF THE END-TO-END EXECUTION
In this section, we provide an overview of the end-to-end
execution toward distributed GNN training.

Observation 1 : The data loading phase is the most time-

consuming phase.

Fig. 2 illustrates the execution time breakdown for GCN,
GAT, GraphSAGE on 1, 2, 4 GPUs. The data loading phase
is the most time-consuming phase for all three GNNs. For
GCN, it occupies a proportion of 79% to 85% in one epoch.
And the number is 70% to 71% for GAT and 73% to 86% for
GraphSAGE. When more GPUs are involved in distributed
GNN training, the proportion of the data loading phase is
becoming smaller, but still is the largest. As for the sampling
phase, it occupies only a small proportion of the execution
time which is no more than 5%. And the proportion of the
computing phase, which is composed of forward propaga-
tion and backward propagation, is becoming smaller when
the number of GPUs increases.

Observation 2 : The gradient synchronization phase becomes

more time-consuming when the number of GPUs increases.

The proportion of the gradient synchronization phase
is becoming larger dramatically when more GPUs are in-
volved. As shown in Fig. 2, for GCN, the proportion reaches
10% of the execution time on 4 GPUs, while the number
is only 4% on 2 GPUs. As for GAT and GraphSAGE, the
proportion on 4 GPUs is 10% and 16% respectively. The gra-
dient synchronization phase replaces the computing phase
as the second largest phase in 4 GPUs execution. It is rea-
sonable to be convinced that the Gradient Synchronization
phase is becoming a non-negligible component with more
GPUs’ participation in training.

Observation 3 : The acceleration ratio using multiple GPUs

has a signiﬁcant gap compared to the ideal acceleration ratio.

Fig. 3 demonstrates the normalized performance of dis-
tributed training using multiple GPUs compared to training
on one GPU. Compared to 1 GPU execution, the acceleration
ratio of 2 GPUs execution is 1.6×, 1.7×, and 1.4× for GCN,
GAT, and GraphSAGE respectively while the ideal acceler-
ation ratio is 2×. As for 4 GPUs execution, the acceleration
ratio is 1.8×, 2.1×, 1.7× while the ideal acceleration ratio is
4×. The gap compared to the ideal acceleration ratio is not
only signiﬁcant but is becoming larger when the number

mini-batchCPU Sample ThreadCPU memoryGPU 0Graph Datamini-batchCPU Sample ThreadGPU N......① Sampling② Data Loading④ Gradient SynchronizationGNN modelAggregate( )Update( )③ Computing GNN modelAggregate( )Update( )3

Fig. 2. Execution time breakdown for three GNNs on 1,2,4 GPUs. The dataset is Reddit. (a) GCN (b) GAT (c) GraphSAGE.

Fig. 3. Normalized performance of distributed training using multiple
GPUs compared to training on one GPU.
of GPUs increases. Other researches on this execution scene
[12], [13] yield similar speedup results to ours, indicating
that there are factors limiting the system’s scalability. How-
ever, they do not probe into the execution to ﬁnd the reason.
The execution pattern of mini-batch training on multi-GPU
platform leads to frequent data movements between CPU
and GPU, and resource competition between CPU threads,
hindering the scalability of mini-batch distributed training.
In contrast, on multi-CPU platform, DistDGL [2] scales
almost linearly up to 16 nodes. Unlike multi-GPU execution,
they perform sampling and GNN computing phases on the
same CPU without abundant data movements. However,
compared with GPU, the execution on CPU is much slower
due to limited computing resources. So multi-GPU is more
common nowadays in distributed GNN training [3], [12],
[13].
5 IN-DEPTH ANALYSIS OF THE INTERACTION
In this section, we provide an in-depth analysis of the
interaction of parallel workers in distributed GNN training.
Fig. 4 illustrates the execution time of each phase for GCN
on 1, 2, and 4 GPUs. As the workloads of one epoch, i.e.,
target nodes, are distributed equally to parallel workers,
it’s expected that the execution time of each phase should
decline when more GPUs are involved. The time of the
computing phase declines as expected, while the other three
phases do not. The reason easily comes to mind that only the
computing phase of each worker is completely independent
of others while the other three are not. So in the following,
we probe into the other three phases to ﬁnd out the fac-
tors hindering the performance improvement of distributed
GNN training.

Observation 4 : Serious competition of CPU shared cache

between the sampling threads. (Sampling Phase)

As shown in Fig. 4, the time of the sampling phase
does not decline sharply as expected when more GPUs
are involved. What’s more, on the Papers dataset, the sam-
pling time is even increasing, from 3.5s to 5.2s per epoch.
The sampling threads execute independently in CPU cores
and compete for the CPU Last Level Cache (LLC). Fig. 5
demonstrates the LLC miss rate and the sum of all sampling
threads’ sampling time, which is normalized and is used to
reﬂect the real CPU execution time for sampling. As more
sampling threads are competing for the LLC cache, the LLC
miss rate increases. As a result, the sum of sampling time
increases too. The LLC miss rate increases from 38% to
43% for Reddit and from 40% to 44% for Products while

the sum of sampling time for them reaches 2.4× and 3.2×
respectively compared to 1 GPU execution. As for Papers,
the LLC miss rate increases dramatically from 43% to 62%.
Correspondingly, the sum of sampling time of 4 GPUs
execution is 4.4× compared to 1 GPU execution. It validates
the serious competition of CPU shared cache between the
sampling threads, which hinders the performance improve-
ment of distributed GNN training.

Observation 5 : Non-negligible bandwidth competition dur-

ing the data loading phase. (Data Loading Phase)

Table 2 illustrates the transmission bandwidth of Host-
to-Device which means from CPU memory to GPU memory
during the data loading phase. The model is GCN and the
dataset is Reddit. As the GPUs share PCIe channels to CPU
with each other, it results in bandwidth decline when the
number of GPUs participating in training increases. The
transfer bandwidth of 1 GPU training is 5.85 GiB/s while
it drops to 3.68 GiB/s of 4 GPU training for each GPU. It
validates that PCIe competition between multiple GPUs has
a negative impact on transmission bandwidth, thus hinder-
ing the performance improvement. Moreover, we conduct
the experiment with 1, 2, and 4 PyTorch dataloader workers
for each process. The execution time ratios of sampling and
data loading phase are similar among different dataloader
setups, indicating that the data loading overhead is not
sensitive to dataloader worker numbers.

TABLE 2
Data loading phase Host-to-Device transfer bandwidth.
1 GPU 2 GPU 4 GPU
3.68

Bandwidth (GiB/s)

5.85
Observation 6 : Increasing synchronization time due to

4.75

imbalance of CPU side. (Gradient Synchronization Phase)

Different from Deep Neural Network (DNN), the model
size of GNN is always much smaller as it has few layers
and shares weights across all vertices. It’s expected that
the gradient synchronization phase should only occupy
a small part of the execution time [2], [3]. However, as
shown in Fig. 2, the gradient synchronization phase takes a
larger proportion of the execution time when the number of
GPUs increases. Besides, Fig. 6 illustrates the execution time
proportion of the gradient synchronization phase for GCN
on different datasets using 4 GPUs. The gradient synchro-
nization phase takes up 10% for Reddit, 5% for Products,
and 36% for Papers. We use the NVIDIA Nsight Systems
to look into the execution and present a perfect mini-batch
execution in Fig. 6, in which four GPUs start computing
phase almost at the same time. The gradient synchronization
phase only takes up 1% of the execution time in the perfect
mini-batch, which indicates that the problem should lie in
the imbalance of the CPU side.

The imbalance of the CPU side results in different start
computing time of GPUs. Table 3 presents the difference of
GPU start computing time and the result is normalized to

2%3%4%85%83%79%13%11%7%4%10%0%20%40%60%80%100%1 GPU2 GPUs4 GPUsSamplingData LoadingForward+BackwardSynchronization2%2%3%70%71%70%28%24%17%2%10%0%20%40%60%80%100%1 GPU2 GPUs4 GPUs2%3%5%86%81%73%12%9%6%7%16%0%20%40%60%80%100%1 GPU2 GPUs4 GPUs(a) GCN(b) GAT(c) GraphSAGE1.0 1.0 1.0 1.0 1.6 1.7 1.4 2.0 1.8 2.1 1.7 4.0 0.01.02.03.04.0GCNGATGraphSAGEIdeal SpeedupPerformance (Norm.)1 GPU2 GPUs4 GPUs4

Fig. 4. The execution time of each phase for GCN on 1,2,4 GPUs. The datasets are Reddit, Products and Papers.

Fig. 5. The Last Level Cache (LLC) miss rate and the sum of all sampling
threads’ sampling time, which is normalized and is used to reﬂect the real
CPU execution time for sampling. The model is GCN.
the execution time of an epoch. The start computing time
means the time when the GPU start computing phase. The
sum(Max-Min) means summing up the difference of start
computing time between the slowest and fastest GPU at
each mini-batch. And the sum(Max-Ave) means summing
up the difference of the slowest and the average start
computing time of all GPUs. The sum(Max-Min) is 34%,
17%, 61% for Reddit, Products, Papers respectively. The
sum(Max-Ave) is more suitable to present the imbalance of
the sampling and data loading phase. It’s 15%, 8%, 32%
for Reddit, Products, Papers and is close to the proportion
of the gradient synchronization phase. It validates that the
stragglers which means workers with abnormal performance
also exist in the distributed GNN training as in DNN.

TABLE 3
Imbalance of GPU start computing time.

sum(Max-Min)
sum(Max-Ave)

Reddit
34%
15%

Products
17%
8%

Papers
61%
32%

6 ARCHITECTURAL GUIDELINES
Software Optimization Guidelines:

Localized Sampling for 4 : It means using clustering algo-
rithms to preprocess the datasets and then distributing the
target nodes in the same clusters to sampling threads in the
same time period. In this way, the competition of LLC is
alleviated as the target nodes of different sampling threads
have plenty of common neighbors in the same time period.
Pipeline Overlap and Caching for 5 : The data loading
phase is the major part of the execution time and it’s inde-
pendent of the computing in GPUs. It indicates that we can
use the pipeline strategy to overlap the data transferring and
computing. Another strategy is to cache features of vertices
that are frequently visited in GPU memory to reduce the
amount of data transferred.

Workload Balance Strategy for 6 : As the imbalance hinders
the performance, it’s reasonable to use workload balance
strategy, e.g., equipping the system with backup threads, to
alleviate the impact of imbalance on performance.

Hardware Optimization Guidelines:
Separated Cache for 4 : As the sampling threads compete
for the LLC resource, they may corrupt the cache leading
to frequent cache replacement. It may be a good choice to
modify the cache to support separate cache strategy, which
means each thread holds an independent part of the cache.

Fig. 6. The execution time proportion of the gradient synchronization
phase for GCN on different datasets using 4 GPUs. A perfect mini-
batch is a mini-batch in which four GPUs start computing phase
almost at the same time.

Hybrid Architecture for 5 : The reason why sampling
and computing are executed separately is that sampling is
memory-intensive and computing is compute-intensive. It
indicates that a hybrid architecture that supports both kinds
of execution can eliminate the data loading phase.

Data Compression for 5 : To shorten the overhead of data
transferring, using data compression and decompression in
the CPU and GPU side respectively is a good choice while
it required specialized compress techniques with hardware
support to minimize the overhead.

7 CONCLUSION
To scale GNN training for large graphs, distributed training
is widely adopted, which uses multiple computing nodes to
accelerate training. However, the execution of distributed
GNN training remains preliminarily understood, which
brings difﬁculties to optimization. In this work, an in-depth
analysis is carried out through proﬁling the execution of
mini-batch distributed GNN training on GPUs, revealing
several signiﬁcant observations and providing optimization
guidelines based on the observations.
REFERENCES

[1] W. Hu et al., “Open graph benchmark: Datasets for machine

learning on graphs,” in NeurIPS, 2020.

[2] D. Zheng et al., “Distdgl: Distributed graph neural network train-

ing for billion-scale graphs,” in IA3, 2020, pp. 36–44.

[3] Z. Lin et al., “Pagraph: Scaling GNN training on large graphs via

computation-aware caching,” in SoCC, 2020, pp. 401–415.

[4] V. Md et al., “Distgnn: scalable distributed training for large-scale

graph neural networks,” in SC, 2021, pp. 76:1–76:14.

[5] D. Zheng et al., “Distributed hybrid CPU and GPU training
for graph neural networks on billion-scale graphs,” CoRR, vol.
abs/2112.15345, 2021.

[6] M. Yan et al., “Characterizing and understanding gcns on GPU,”

IEEE Comput. Archit. Lett., vol. 19, no. 1, pp. 22–25, 2020.

[7] M. Yan, L. Deng, X. Hu et al., “Hygcn: A gcn accelerator with

hybrid architecture,” in HPCA.

IEEE, 2020, pp. 15–29.

[8] M. Fey and J. E. Lenssen, “Fast graph representation learning with

pytorch geometric,” CoRR, vol. abs/1903.02428, 2019.

[9] T. N. Kipf and M. Welling, “Semi-supervised classiﬁcation with

graph convolutional networks,” in ICLR, 2017.

[10] P. Velickovic et al., “Graph attention networks,” in ICLR, 2018.
[11] W. L. Hamilton, Z. Ying, and J. Leskovec, “Inductive representa-

tion learning on large graphs,” in NeurIPS, 2017, pp. 1024–1034.

[12] J. Wu et al., “Performance analysis of graph neural network

frameworks,” in ISPASS, 2021, pp. 118–127.

[13] T. Baruah et al., “Gnnmark: A benchmark suite to characterize
graph neural network training on gpus,” in ISPASS, 2021, pp. 13–
23.

0.5 0.3 0.4 0.7 0.9 0.8 3.5 4.1 5.2 16.1 10.2 8.3 14.6 12.3 10.3 12.4 12.7 6.7 2.5 1.3 0.8 4.7 2.7 1.7 6.2 4.6 3.5 0.0 0.5 1.0 0.0 0.0 0.6 0.0 1.2 8.6 051015201 GPU2 GPUs4 GPUs1 GPU2 GPUs4 GPUs1 GPU2 GPUs4 GPUsRedditProductsPapersTime (s)SamplingData LoadingForward + BackwardSynchronization38%40%43%40%42%44%43%47%62%1.0 1.4 2.4 1.0 2.5 3.2 1.0 2.4 4.4 0.01.02.03.04.05.030%40%50%60%70%1 GPU2 GPUs4 GPUs1 GPU2 GPUs4 GPUs1 GPU2 GPUs4 GPUsRedditProductsPapersSum of Sampling time (Norm.)Cache miss rateLLC cache miss rateSum of sampling time90%95%64%99%10%5%36%1%0%25%50%75%100%RedditProductsPapersA perfectmini-batchExecution time Other PartsSynchronization