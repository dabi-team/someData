Conservative Bayesian Assessment of Software-based Systems Exhibiting Correlated
Executions

Kizito Salakoa, Xingyu Zhaob

aCentre for Software Reliability, City, University of London, Northampton Square, EC1V 0HB, United Kingdom
bDepartment of Computer Science, University of Liverpool, Ashton Street, Liverpool, L69 3BX, United Kingdom

2
2
0
2

g
u
A
4
2

]
E
S
.
s
c
[

2
v
5
3
9
7
0
.
8
0
2
2
:
v
i
X
r
a

Abstract

This paper presents Bayesian methods that support conservative dependability claims for a software-based safety-critical system,
particularly when evidence suggests the software’s executions are not statistically independent. We formalise informal notions of
“doubting” that the software’s executions are independent, and incorporate such doubts into dependability assessments. We study
the extent to which an assumption of independent executions can undermine conservatism in assessments, and identify conditions
under which this impact is, or is not, signiﬁcant. These techniques – novel extensions of conservative Bayesian inference (CBI)
methods – are illustrated in two applications: the assessment of a nuclear power-plant safety protection system and the assessment
of autonomous vehicle (AV) safety. Our analyses reveals: 1) the required amount of conﬁdence an assessor should possess before
subjecting a system to operational testing. Otherwise, such testing is shown to be futile – no amount of favourable operational testing
evidence will increase one’s conﬁdence in the system being sufﬁciently dependable; 2) the independence assumption supports
optimistic claims in certain situations, and conservative claims in other situations; 3) in some scenarios, upon observing a system
operate without failure, an assessor’s conﬁdence in the system being sufﬁciently dependable is less than it would be had the
system exhibited some failures; 4) posterior conﬁdence in a system being sufﬁciently dependable is very sensitive to failures – each
additional failure means signiﬁcantly more operational testing evidence is required, in order to support a dependability claim.

Keywords: AI safety, autonomous vehicles, Bernoulli trials with dependence, CBI, conservative Bayesian inference, correlated
failures, nuclear safety protection systems, safety-critical systems, software reliability, statistical testing, ultra-high reliability

Abbreviations

b A required upper bound on X

pfd probability of failure per demand

c Posterior conﬁdence in X satisfying the bound b

pfm probability of fatality-event per mile

φ1 Prior conﬁdence in negative dependence of successive tests

AV Autonomous Vehicle

φ2 Prior conﬁdence in positive dependence of successive tests

CBI Conservative Bayesian Inference

n The total number of Bernoulli trails (demands or driven-miles)

PK Prior Knowledge

SCS Safety-Critical System

Notations

Ti Outcome of a Bernoulli trial i

x, X The failure probability of Bernoulli trials (pfd or pfm)

λ, Λ The dependency parameter between Bernoulli trials

s The number of trials that are failures

r The number of failures that are preceded by a failure

L The likelihood function

R The domain of the Klotz failure model

Ri The ith subset in a partition of R

Mi Probability mass associated with Ri

(cid:15) A bound on X representing the “engineering goal”

1. Introduction

θ Prior conﬁdence in the engineering goal being satisﬁed

Email addresses: k.o.salako@city.ac.uk (Kizito Salako),

xingyu.zhao@liverpool.ac.uk (Xingyu Zhao)

It is prudent to be conservative when assessing a safety-
critical system (SCS) – the failure of such a system could sig-
niﬁcantly harm stakeholders in the system. Rigorous statistical

Preprint submitted to Elsevier

August 26, 2022

 
 
 
 
 
 
Figure 1: Various assessment scenarios and the sections in this paper that treat them. Each path through the diagram, starting at the “n executions” node on the left,
indicates a system’s behaviour (during operational testing) and the implications of dependability evidence considered by an assessor (before operational testing).

methods can be employed by an assessor to support conserva-
tive claims about system software being sufﬁciently depend-
able, where such claims are based on evidence of achieved lev-
els of dependability. In particular, Bayesian methods provide
a natural formalism and calculus for combining various forms
of dependability evidence, resulting in probabilistic measures
that (in light of the evidence) articulate an assessor’s uncertainty
about the dependability of a system [1]. Some example sources
of evidence include: formal analyses of a codebase; the perfor-
mance of a system during operation [2]; the historical perfor-
mance of similar systems [3, 4]; and improvements in software
development approaches, tools and practices [5].

When using such methods to assess a system, a central ques-
tion is whether the system’s software has “executions” that are
statistically independent or not. By “an execution” we mean a
set of actions (performed by the software) that can be regarded
as a unit of software operation. For example, actions performed
in response to each demand/input the software receives from
its environment, or actions in response to a sequence of de-
mands/inputs (received over a unit amount of time or distance).
In this paper, when a software execution occurs, either all of
the related actions are correctly performed or at least one of the
actions is incorrect. In this sense, a software execution is either
successful or a failure, respectively.

Statistically independent executions are applicable in some
real-world scenarios; for example, for on-demand systems where
demands rarely occur, and the states of the system and its op-
erational environment are effectively reset inbetween demand
occurrence. But there may be reasons to doubt independence in
other scenarios. For instance, sudden changes in driving condi-

tions could mean an autonomous vehicle (AV), if it makes mis-
takes, is very likely to make more mistakes soon afterwards.
An airplane (and its ﬂight control systems) can be put under
increasing operational stresses when they encounter aggressive
weather (with turbulent “air pockets”) mid-ﬂight. And, more
widely, “failure clustering” has been observed in various (con-
trol) systems.
It seems inevitable in many situations that, at
least, some doubt in independent executions is warranted.

Even when executions are assumed independent, the as-
sessment of an SCS typically requires that the system perform
a large number of executions during operational testing with-
out any failures. Faced with such a large number of consecu-
tive successes, an assessor might (must?) reasonably consider
whether these executions are positively correlated after all. And
how this, if true, changes a dependability claim. Because, at
face-value, an assumption of independent executions can seem
quite strong. Such an assumption signiﬁcantly limits an asses-
sor’s hypothesis about which probabilistic laws could charac-
terise a software’s failure process. Consequently, one expects
that assuming independence results in dependability claims that
are more optimistic than they otherwise would be. It’s useful
to ask, “to what extent does this limitation actually undermine
conservative assessments?” When are assessments that incor-
porate doubts about independent executions signiﬁcantly differ-
ent from the alternative assessment that assumes independence?
The answers to such questions depend on the following fac-
tors: i) how dependable the software actually is, ii) the sequence
of successes and failures of the software when it’s subjected
to operational testing, and iii) the nature of the dependence (if
any) between successive executions. Prior to operational test-

2

ing, the assessor is uncertain about these factors, and is reliant
on dependability evidence to shape their expectations of how
dependable the system is. Upon subjecting the system to oper-
ational testing, the performance of the system is yet more evi-
dence for the assessor to update their expectations with.

This process – of an assessor’s uncertainties being initially
shaped by evidence obtained prior to operational testing, and
then being shaped further by the system’s executions during op-
eration – is formalised in this paper in conservative Bayesian in-
ference (CBI) terms. We illustrate this for an assessor seeking to
make claims about the system’s failure-rate1. Of primary inter-
est is deriving evidence-based conservative conﬁdence bounds
on a system’s unknown failure-rate. These represent an asses-
sor’s conﬁdence in the failure-rate being “small enough”, after
taking all of the evidence into account.

CBI makes explicit how the factors outlined above affect
an assessor’s uncertainty under various assessment scenarios.
Fig. 1 summarises these scenarios, and indicates sections in this
paper where the scenarios are treated. Prior to operational test-
ing, an assessor may express some conﬁdence in, say, i) the
system being sufﬁciently dependable (e.g. conﬁdence in the
unknown failure-rate being better than a target failure-rate for
the system developers); ii) the system being fault-free; iii) fu-
ture executions being negatively/positively correlated and being
failure-free. And, this conﬁdence will be updated, depending
on the outcomes of executions during testing – outcomes such
as no failed executions occurring, or some failures (either iso-
lated or in bursts) separated by runs of successes.

Summary of the paper’s contributions. These include:

1) formalising informal notions of “doubting” the indepen-
dence of executions, and providing statistical methods that in-
corporate such doubts in conservative dependability claims;

2) investigating the extent to which assuming independent
executions undermines conservatism in dependability claims.
And the conditions under which this impact is signiﬁcant;

3) showing how the system’s behaviour during operation –
whether failures occurred, and whether these were clustered or
isolated – can signiﬁcantly affect conservatism in assessments;

4) a statistically rigorous approach for conservatively up-
dating one’s conﬁdence/doubt in the independence assumption;

5) signiﬁcant extensions and generalisations of CBI meth-

ods, to account for correlated executions;

6) demonstrating these approaches in two application areas
– the assessment of a nuclear power-plant safety protection sys-
tem and autonomous vehicle (AV) safety;

7) closed-form solutions for conservative posterior conﬁ-
dence in an upper bound on a system’s failure-rate, for several
practical scenarios (see Fig. 1);

8) advice and caution for assessors/practitioners, concern-
ing how much conﬁdence they should justify prior to subjecting
the system to operational testing. With insufﬁcient prior evi-
dence/conﬁdence, such testing is shown to be futile – no amount
of favourable operational testing evidence will conservatively
increase one’s conﬁdence in the system being dependable.

The rest of the paper is organised as follows. Critical con-
text and related work are detailed in section 2, while section 3 is
a review of CBI, its rationale, and an introduction to modelling
correlated executions using CBI. Formal characterisations of
having doubts in independent executions are given in section
4, which are then used in deriving conservative upper conﬁ-
dence bounds on system failure-rate in different scenarios. The
sensitivity of the CBI model to changes in model parameters is
studied in section 5. This is followed by section 6’s analyses
of how assuming independence can result in optimistic claims,
but not always. An overall discussion of the paper’s results is
contained in section 7, with section 8 concluding the paper.

2. Related Work

2.1. Why is Modelling Correlated Executions Necessary?

It’s well-known that failure correlation can be expected be-
tween redundant software components in a fault-tolerant con-
ﬁguration – even when these components are developed inde-
pendently. There are often inputs that all of the components ﬁnd
“difﬁcult” to correctly respond to: the components are likely to
contain (possibly different) design faults that cause the com-
ponents to fail on such inputs. This has been conﬁrmed both
experimentally [6, 7] and theoretically [8, 9]. The theoretical
failure models used to explain such correlations assume that
independently developed components have conditionally inde-
pendent failures, conditional on each input submitted to these
components from their shared operational environment. These
models do not need to represent each component’s consecutive
executions, and thus ignore the possibility of the consecutive
executions for a component, themselves, being correlated.

A very popular early model for sequences of executions is
due to Thayer et al. [10] – a model of statistically independent
executions, often used in early works on random testing [11].

However, reasons to expect correlated failed executions in
various systems became well-known. For example, a system
can exhibit “failure clustering” due to the system receiving se-
quences of inputs that cause the system to fail, where such in-
puts cluster into subsets of the system’s failure region2 [12, 13].
And the system’s operational environment generates input se-
quences as trajectories (within the set of all inputs) that even-
tually enter into, and linger in, these failure regions. This phe-
nomenon motivated a number of studies that model, and ac-
count for, positive failure correlation between executions in de-
pendability assessments. Such as works related to assessing
systems that employ recovery block fault-tolerance [14, 15],
and further works related to random testing [16].

1For brevity in this paper, “failure-rate” refers to the probability of the sys-
tem failing per “execution”. For example, the probability of failure per demand
(pfd), or the probability of a fatality per mile (pfm), and so on.

2A software component’s failure region is a geometrical, or mathematically

topological, characterisation of those inputs that trigger the software to fail.

3

Yet another reason for correlation between consecutive ex-
ecutions is if the internal state of the software is corrupted upon
an initial failed execution, making the failure of subsequent exe-
cutions more likely. Or, if the system’s operational environment
becomes increasingly more stressful for the system to operate
in (i.e. there is an increasing probability of trajectories in the
input space entering the failure region) [17].

2.2. Statistical Models of Correlated Executions

A number of models with Markov dependence have been

proposed for correlated executions.

In [18], Chen and Mills use a binary Markov chain to model
dependent executions during random software testing, replac-
ing Thayer et al.’s earlier “independent executions” model.

Goseva-Popstojanova and Trivedi, in [19], build upon ear-
lier work (such as [14, 15]) with a Markov renewal process that
models the occurrence of failures in continuous-time, assuming
Markov dependence between executions. This model is used
in Software Reliability Growth Models (SRGMs) that assume
software systems undergo changes whenever failures occur, be-
cause attempts are made at ﬁxing the software. SRGMs are best
suited for supporting software maintenance, bug-ﬁnding/ﬁxing
activities, and assessing moderate levels of reliability. They are
less apt for supporting conservative ultra-high reliability claims
where failures are rare [20, 21], which is the focus of our paper.
Another Markov model with more (benign-failure) states is
proposed by Bondavalli et al. in [22], to model successive exe-
cutions of iterative software. And, to account for the cumulative
impact of successive benign failures, since such failures may be
tolerated by the system up to a point. The model was improved
upon in [23], demonstrating the model’s use with estimates of
its steady-state probabilities and how to obtain transition prob-
abilities from these under certain assumptions.

In this paper we use the binary Markov chain due to Klotz
[24]. This model predates and agrees with the Markov chains
in [18, 19]. However, by using the Klotz model in a Bayesian
framework, our approach to modelling dependent executions
differs from previous studies in the following important ways.
In [17], Strigini acknowledges the need for models (like
those in [22]) to account for benign failures and correlated exe-
cutions, but argues that: i) in general, steady-state probabilities
are insufﬁcient for determining the transition probabilities; ii)
the steady-state probabilities alone cannot be used to compute
useful measures of dependability for process control applica-
tions; iii) obtaining the true values for the model’s transition
probabilities can be challenging – there will typically be signiﬁ-
cant uncertainty in such estimates when they are based solely on
a limited amount of operational evidence. Chen and Mills make
a similar point about uncertainty in correlation estimates, espe-
cially when failures are rare [18]. We agree with these view-
points, and advocate for methods (such as those in this paper)
that explicitly express this uncertainty as part of assessments.

Indeed, none of the aforementioned Markov models are
demonstrated using inference methods that explicitly account
for one’s uncertainty about a model’s parameter values. Con-
sequently, the “point estimates” for these models’ correlation

parameters (obtained from operational data by using classical
inference) indicate the executions to be exclusively either nega-
tively or positively correlated. In contrast, our approach models
an assessor’s uncertainty about the nature of the correlation –
so, the assessor expresses conﬁdence in the executions possibly
being negatively or positively correlated, or uncorrelated. And
they become more (or less) conﬁdent about these possibilities
as more evidence becomes available.

Furthermore, the aforementioned models use inference meth-
ods involving only one form of dependability evidence – i.e.
evidence from operational testing alone (or “equivalent”, such
as appropriate simulation). These inference methods do not
have explicit mechanisms for incorporating other forms of ev-
idence in estimating the unknown model parameters. Our ap-
proach, being a Bayesian approach, expects dependability evi-
dence to inﬂuence the inference via prior probability distribu-
tions. Moreover, our inference method makes conservative use
of evidence, as highlighted in subsection 2.3 next.

In summary, none of the aforementioned approaches pro-
vide demonstrably conservative statistical support, for depend-
ability claims about a system exhibiting possibly correlated ex-
ecutions – where such support is justiﬁed by various forms of
dependability evidence. To the best of our knowledge, ours is
the ﬁrst attempt at this.

2.3. Conservative Bayesian Methods for Assessments

A number of studies have applied Bayesian methods to sup-
port software dependability assessment [25–28]. The utility of
these methods is in the inference process. An assessor’s beliefs
about the dependability of a system are initially formed by eval-
uating relevant evidence. Then these beliefs are updated, upon
seeing how the system performs during operation.

The usual challenge with using Bayesian methods is the
need to characterise one’s initial (i.e. “prior”) beliefs as a repre-
sentative prior probability distribution – a distribution that cap-
tures all, and only all, of one’s prior beliefs. Much care must
be taken when eliciting a prior distribution for dependability as-
sessment. A non-representative prior could lead to overly pes-
simistic or, more worryingly, overly optimistic assessments.

There is the added challenge that, for dependability assess-
ments, prior distributions often represent beliefs about continu-
ous random variables, such as a system’s unknown failure-rate.
Requiring that an assessor specify beliefs about the inﬁnitely
many ranges of possible failure-rate values is often impractical.
CBI methods have been developed to address these chal-
lenges. CBI is related to robust Bayesian analysis [29–32],
which studies the sensitivity of the results of Bayesian infer-
ence to changes in the inference inputs. Inputs such as: the prior
distribution; the statistical model that determines the likelihood
function; and the posterior measure of interest. An assessor
may not be able to use available dependability evidence to fully
specify a prior distribution, but the evidence may allow a much
more limited partial speciﬁcation of a prior – e.g. the assessor
expects the prior, whatever it may be, to satisfy certain quantiles
or moments. By considering all of those prior distributions that
satisfy these speciﬁcations, CBI determines the most conserva-
tive inference result (from using these priors) that can support a

4

dependability claim. This is one way in which conservatism in
assessments is realised via Bayesian inference.

Bishop et al. introduced CBI in [33] where its use in assess-
ing an SCS’s reliability is illustrated. A number of studies soon
followed, applying CBI in various contexts [34–39] . For exam-
ple, i) in [34], Povyakalo et al. use CBI to obtain the smallest
probability of the system’s next m executions being successful,
given prior evidence that the system is very reliable and its last
n executions were successful; ii) in [35], with evidence to sup-
port some conﬁdence in the system possibly being fault-free,
and some conﬁdence in the system being very reliable, Zhao
et al. use CBI with operational testing to conservatively gain
conﬁdence in the system possibly being fault-free; iii) Salako
uses CBI in [37] to bound the reliability of a binary classiﬁer,
given evidence of the classiﬁer’s performance on past classi-
ﬁcations being (un)likely; and iv) in [39], Flynn et al. apply
CBI to the problem of assessing AV safety – highlighting cir-
cumstances under which attempts to demonstrate the required
levels of safety via road testing are in vain.

These examples of CBI applications all involve “univari-
ate” priors; i.e. distributions of a single unknown, typically the
system failure-rate. More recently there have been CBI appli-
cations involving “bivariate” priors. Littlewood et al. [40] con-
sider the assessment of a system in a “new” situation – either the
system replaces an older system in a given operational environ-
ment, or the system has been deployed in a new environment
after operating in a previous environment for some time [40].
They demonstrate how CBI gives support for a dependability
claim, when evidence suggests the failure-rate of the system in
the new situation is “no worse” than the relevant failure-rate in
the “old” situation. “Improvement arguments” of this kind, in
the context of assessing AV safety, are studied further by Zhao
et al. in [41] – but with different dependability measures of in-
terest and a more general failure model for the system. And in
[42], Salako et al. consider more general “improvement argu-
ments” for an even wider range of assessment scenarios.

In this paper, our application of CBI differs from previous
applications in three important ways: it models correlated ex-
ecutions; it incorporates evidence of correlations into assess-
ments; and it involves bivariate priors representing an assessor’s
uncertainty about the failure-rate and the possible dependence
between executions. The next section introduces this model.

3. Preliminaries: a CBI Model of Correlated Executions

3.1. A Review of CBI

The basic idea behind CBI can be illustrated with a sim-
ple application from [39]. When assessing an on-demand sys-
tem, suppose an assessor seeks to justify dependability claims
in terms of the probability X of the system failing on a randomly
chosen demand3. X, the system’s unknown failure-rate, deﬁnes
a Bernoulli trial – i.e. the system either fails (with probability

3We follow accepted convention: uppercase letters for random variables

(e.g. X), and lowercase letters for their realisations (e.g. x).

X) or succeeds (with probability 1 − X) on each demand it (ran-
domly) receives during operation. The demands arise according
to a distribution called the operational proﬁle.

Suppose that, before the system is subjected to operational
testing, the assessor has sufﬁcient evidence to fully specify a
prior distribution F(x) representing their beliefs about X. And
when the system eventually undergoes operational testing, the
assessor observes the system successfully handle all of n “in-
dependent and identically distributed” (i.i.d.) demands during
operation4. For this Bernoulli failure process, the probability of
observing these successes – the likelihood function – takes the
form L(x; n) = (1 − x)n. Let b be a required upper bound on
X which an assessor seeks to claim with some conﬁdence. In
light of all the evidence, the assessor’s conﬁdence in X being
no larger than b is:
P(X (cid:54) b | n successes) = P(X (cid:54) b, n successes)
(cid:82) b
0 (1 − x)n dF(x)
(cid:82) 1
0 (1 − x)n dF(x)
(1)

E[L(X; n)1X(cid:54)b]
E[L(X; n)]

P(n successes)

=

=

where 1S is an indicator function—it equals 1 when predicate S
is true, and 0 otherwise.

However, usually, one does not have enough evidence to
justify using a speciﬁc F. Instead, an assessor might be able to
justify only weaker constraints on the prior, such as specifying
a few quantiles that a valid F must satisfy. We refer to any
constraints on the prior distribution as prior knowledge, or PK
for short. The following is a basic form of PK:

Prior Knowledge 1 (certainty in a lower bound). The system
failure-rate cannot be better than some lower bound pl, i.e.
P(X (cid:62) pl) = 1.

X is a probability, so pl should be non-negative. Depending on
the scenario, pl can be 0 (e.g. for possibly “fault-free” software
[43]) or a very small number (e.g. the best reliability feasible
for the system given current levels of technology).

Prior Knowledge 2 (conﬁdence in satisfying an engineering
goal). θ × 100% conﬁdence that the system’s failure-rate is bet-
ter than, or equal to, an upper bound (cid:15) i.e. P(X (cid:54) (cid:15)) = θ.

Here (cid:15) is an “engineering goal”: a target system failure-rate
that the system developers try to achieve. (cid:15) is typically chosen
to be much smaller than the required bound b, so (cid:15) (cid:54) b. While
θ is how conﬁdent the assessor is, before operational testing,
that the engineering goal has been achieved. θ would have to
be large enough to support conducting operational testing; this
reduces the chance that insufﬁciently reliable systems use up
the operational testing budget.

Readers may refer to [39] for examples of how PKs 1 and
2 arise when assessing AV safety. Such scenarios are the basis
for some of the numerical CBI illustrations in section 4.

4The CBI model in [39] is more general than how it is presented here – for
brevity, we only present the special case when the system exhibits no failures.

5

If evidence supports PKs 1 and 2, the following theorem
(proved in [39]) shows one can conservatively gain conﬁdence
in a bound b on X, by observing n failure-free executions.

failure-rate i.e. the unconditional probability that an execution
fails. And let λ be the probability that a failure is followed by
another failure. That is,

Theorem 1 (univariate CBI). Let D be the set of all feasible
probability distributions for the failure-rate X of a system (i.e.
all distributions over [0, 1]). Consider the optimisation problem

P[Ti = 1] = 1 − P[Ti = 0] = x,
P[Ti = 1 | Ti−1 = 1] = λ,

i = 1, . . . , n
i = 2, . . . , n

P(X (cid:54) b | n successes)

inf
D

(where (cid:15) (cid:54) b), subject to the constraint that there is evidence
the system satisﬁes PK 1 and 2.

The prior distribution in Fig. 2 solves this problem because,

upon using this prior,

P(X < b | n successes) = inf
D

P(X (cid:54) b | n successes) .

It immediately follows by deﬁnition, that

P[Ti = 0 | Ti−1 = 1] = 1 − λ,

i = 2, . . . , n

Furthermore, by requiring that the process be 1st-order station-
ary, we have (see [24, 44])

P[Ti = 1 | Ti−1 = 0] = (1 − λ)x
1 − x

,

P[Ti = 0 | Ti−1 = 0] = 1 −

(1 − λ)x
1 − x

,

i = 2, . . . , n

i = 2, . . . , n

which yields the Markov model shown in Fig. 3.

Figure 2: A conservative prior cumulative distribution function [42].

Insight 1 (The basic CBI idea). Rather than a single fully speci-
ﬁed prior distribution, one considers the set of all feasible prior
distributions that satisfy an assessor’s stated PKs. And, for a
given posterior measure of dependability (e.g. posterior conﬁ-
dence in a bound on X), CBI determines the most pessimistic
value for this measure – no feasible prior gives a more pes-
simistic value, and any prior that does must violate at least one
PK. In this sense, CBI supports conservative assessments.

3.2. The Klotz Model of Correlated Software Executions

To account for correlated executions using CBI, we propose
the Klotz model [24] as the mathematical abstraction of a sys-
tem’s stochastic failure process. Speciﬁcally, it is a model of
Bernoulli trials with Markovian dependence, characterised by
two parameters – the usual “frequency” parameter x of Bernoulli
trials, and a “dependence” parameter λ.

In more detail, consider a sequence of random variables
T1, . . . , Tn, each taking on the values 1 or 0 – i.e. each “T ” rep-
resents a failure or success, respectively, by the system. This
sequence of n Bernoulli trials models the successful and failed
executions of the system’s software, as it responds to a sequence
of n demands5. Similar to section 3.1, let x be the system

5Our focus is the assessment of the system’s software. We consider only

software failures, so no hardware failures, as deﬁning system failure.

Figure 3: The Klotz model for Bernoulli trials with dependence [24, 44].

The transition probabilities of the Klotz model in Fig. 3 lie

between zero and one, implying the constraints:

0 (cid:54) x (cid:54) 1, max {0, (2x − 1)/x} (cid:54) λ (cid:54) 1

(2)

Remark 1 (correlation in the Klotz model). The correlation co-
1−x 10(cid:54)x<1 +1x=1. This
efﬁcient for two successive executions is λ−x
deﬁnes the 3 correlation types: i) when x = λ, the Klotz model
reduces to independent execution outcomes; ii) when λ > x,
clustering of execution outcomes tends to occur more often (e.g.
bursts of failures) – this is positive correlation; and iii) when
λ < x, outcomes of the executions tend to alternate more often,
between failure and success – this is negative correlation.

Suppose, over n executions, the system makes: α transitions
from a successful execution to a failed execution; β transitions
from “success” to “success”; γ from “failure” to “failure”; and
δ from “failure” to “success”. So, α + β + γ + δ + 1 = n. Under
the Klotz model, for given (x, λ), the probability of observing
these transitions, denoted as L(x, λ; α, β, γ, δ), is the likelihood:

L(x, λ; α, β, γ, δ) =






6

(cid:17)α (cid:16)

(cid:16) (1−λ)x
1−x

1 − (1−λ)x
λγ(1 − λ)δ;
x
1−x
when the 1st execution is a failure

(cid:17)β

(cid:17)α (cid:16)

(cid:16) (1−λ)x
1−x

(1 − x)
when the 1st execution is a success

1 − (1−λ)x
1−x

λγ(1 − λ)δ;

(cid:17)β

(3)

During operational testing, an assessor observes α, β, γ and
δ. But, both x and λ are unknown to the assessor6 In particu-
lar, the assessor is uncertain about the failure-rate X. And so,
upon observing n executions of the system, the conﬁdence an
assessor has in X being no larger than some bound b is:

P(X (cid:54) b | outcomes of n executions)
= P(X (cid:54) b , outcomes of n executions)
P(outcomes of n executions)

=

E[L(X, Λ; α, β, γ, δ)1X(cid:54)b]
E[L(X, Λ; α, β, γ, δ)]

(4)

which generalises (1). Previously, the univariate prior distribu-
tion F(x) encoded the assessor’s beliefs about X. Here, the joint
prior distribution implicit in (4) encodes beliefs about (X, Λ).

Later in this paper it will be useful to refer to s – the num-
ber of failed executions by the system – and r – the number of
failed executions preceded by a failed execution (“consecutive
failures”, for short). The Klotz likelihood function (3) can be
re-expressed in terms of the variables n, s and r, which are re-
lated to the alternative variables α, β, γ, δ (see Appendix A.1).
In particular, r = γ.

4. Conservative Upper Conﬁdence Bounds on Failure-rate

Upon observing n executions of the system, what is the least
conﬁdence an assessor should have about X being “no bigger
than” the bound b? In general, the answer depends on the fail-
ure process used for inference, and the constraints placed on
the assessor’s (X, Λ) prior distribution by the evidence. We now
determine the answer under different scenarios, by deriving the
greatest lower bound for (4) using PKs 1, 2, 3, 4. Section 3.1
introduced PKs 1, 2, while section 4.1 will introduce PKs 3, 4.
Example applications of these results with domain-speciﬁc
parameterisations for the PKs – parameterisations for nuclear
power-plant safety protection systems and AVs – are given in
sections 4.2 and 4.3 respectively. Table 1 lists the correspond-
ing worst-case priors used in the examples. In [44] we examine
the extreme situation when an assessor can justify a continuous
marginal prior distribution of X.

4.1. Assessment with Doubts about Independent Executions

Our ﬁrst assessment scenario is a baseline. Before opera-
tional testing, an assessor uses dependability evidence to justify
the reliability-related PK 2, and the following two PKs about
the independence assumption (cf. Remark 1):

Prior Knowledge 3 (conﬁdence in negative dependence). φ1 ×
100% conﬁdence that the outcomes between two successive tests
have negative dependence, i.e. P(Λ < X) = φ1.

Prior Knowledge 4 (conﬁdence in positive dependence). φ2 ×
100% conﬁdence that the outcomes between two successive tests
have positive dependence, i.e. P(Λ > X) = φ2.

6In theory, knowing x and λ would allow the assessor to completely charac-

terise the system’s failure process.

7

Consequently, the assessor’s prior conﬁdence in independence
is (1 − φ1 − φ2), i.e. P(Λ = X) = 1 − φ1 − φ2. Note that in
all of the remaining theorems in this paper, φ1 = φ2 = 0 is the
special case of independent executions, whence the theorems
agree with previously published univariate CBI results.

An assessor observes n successful executions. Using the
Klotz failure model, the CBI problem of determining the least
amount of conﬁdence the assessor can justiﬁably have, about
the system failure-rate satisfying bound b, is the following con-
strained optimisation problem. Consider the support R of the
Klotz likelihood, deﬁned by (2) and depicted in Fig. 4a. Let
D be the set of all prior probability distributions over R, and
0 (cid:54) pl (cid:54) (cid:15) < b < 1
2 . Then, the following theorem holds
(generalisations in Appendix A.2).

Theorem 2. The optimisation problem

P( X (cid:54) b | n executions without failure)

inf
D

s.t. PK1, PK2, PK3, PK4

is solved by the prior distributions in Fig.s 4b, 4c and 4d, since
P( X < b | n executions without failure) from these priors equals
the inﬁmum.

(a)

(b) φ1 (cid:62) θ

(c) φ2 (cid:62) 1 − θ

(d) φ1 (cid:54) θ and φ2 (cid:54) 1 − θ

Figure 4: The support R of the Klotz likelihood function, and the subsets of R
related to PKs 1, 2, 3 and 4, are shown in subﬁg. 4a. Upon observing executions
with no failures, subﬁg.s 4b, 4c and 4d are 3 prior distributions that solve the
optimisation problem in Theorem 2. These priors are relevant for the ranges of
parameter values indicated in each subﬁgure.

Each of Fig.s 4b, 4c and 4d shows the domain R of a joint
prior distribution for (X, Λ) random variables, and the 4 points
(i.e. black dots) in R assigned nonzero probabilities by this
distribution. So, these joint priors are depicted as if one were
looking down on the distribution and its domain “from above”.

Example 1 (baseline). Consider an on-demand SCS which acts
only upon receipt of a discrete demand from its environment.
An assessor is 75% conﬁdent the system has been built with a
failure-rate7 no worse than (cid:15) = 10−5 (i.e. the engineering goal
of PK2 with θ = 0.75). After seeing n failure-free tests of the
SCS, the assessor is c × 100% conﬁdent that the system meets
Safety Integrity Level (SIL) 4 [45], i.e. b = 10−4. Fig. 5 shows
three plots of c as a function of n using three different Bayesian
models8: univariate CBI (cf. Theorem 1); Bayesian Inference
(BI) using a (conjugate) Beta prior9 satisfying PK2; and CBI
with conﬁdence φ1 and φ2 in negative and positive dependence
respectively (cf. Theorem 2).

Figure 5: (Example 1) c×100% posterior conﬁdence in [X (cid:54) 10−4] upon seeing
n failure-free tests, from three Bayesian models with different PKs.

Both univariate CBI, and BI using a Beta prior, are based
on the likelihood L(x; n) = (1 − x)n, i.e. they assume the ex-
ecutions are statistically independent. In Fig. 5, as expected,
univariate CBI gives less conﬁdence (so, is more conservative)
than BI using a Beta prior10. While, both of these are more op-
timistic than CBI with doubts about independence. Failure-free
evidence is always “good news” under univariate CBI and BI
(i.e., the solid and dashed-dot curves monotonically increase to
“certainty” in the bound). Contrastingly, with doubts in inde-
pendence, such evidence actually becomes “bad news”, and un-
dermines an assessor’s posterior conﬁdence in the 10−4 bound
for all sufﬁciently large n (i.e., the uni-modal pattern of the
dashed curve). This is because there are pessimistic reasons for
why the failure-free tests could be occurring – reasons that sug-
gest the successes are occurring despite the SCS not being very

7Here, a typical failure-rate is the pfd.
8Note, with failure-free executions, the posterior conﬁdence from CBI is not
a function of pl (since the distributions in Fig. A.28 have no probabilities along
the pl line). Thus, WLOG, we set pl = 0 in PK1.

9Speciﬁcally, for Beta(α, β), we set the α parameter and ﬁt a β, so that the

quantile in PK2 is satisﬁed. WLOG, we set α = 0.03.
10This observation holds for any feasible prior

reliable. The apparent positive correlation of the tests could
be due test-cases being unrepresentatively “easy” for the SCS
to correctly respond to, or there may be a problem with the test
oracle which means some failures could go undetected [46, 47].
Insight 2 (failure-free testing can undermine conﬁdence in a
failure-rate bound). In the baseline scenario with accumulat-
ing failure-free tests, any prior conﬁdence the assessor has in
the executions being positively correlated, i.e. any φ2 > 0,
will eventually undermine conﬁdence in any failure-rate bound.
Unlike the univariate case, where accumulating failure-free ev-
idence must indicate that the system is very reliable, because
(pessimistic reasons for) positive correlations are ignored.

In this scenario, prior conﬁdence in negatively correlated
executions (i.e. φ1 > 0) has a negligible impact on posterior
conﬁdence in failure-rate bounds, as the sensitivity analysis in
section 5 will illustrate. This is unsurprising, since the more
successful executions are observed, the less likely these could
be arising from a system with negatively dependent tests.

4.2. With PK for Nuclear Reactor Protection Systems

Next we consider the assessment of a nuclear reactor safety
protection system, that is simple enough to possibly be fault-
free (i.e., the system’s failure-rate could be 0) [43]. Typically,
only failure-free operational testing evidence from such a sys-
tem is used in assessments – otherwise, if a failure occurs, the
system is taken ofﬂine and ﬁxed, before testing is resumed with
a new sequence of demands. In essence, this nuclear scenario
is very similar to the baseline scenario of the last section – the
testing evidence and most of the PKs are the same – except that,
now, the engineering goal is “perfection” (i.e. PK2 with (cid:15) = 0).
As before, our interest is in determining an assessor’s con-
servative conﬁdence in a required failure-rate bound b upon
seeing n failure-free runs, where the assessor harbours some
doubts about the independence assumption (i.e. nonzero φ1 or
φ2). This conﬁdence in b is given by Theorem 2, simply by
replacing PK2 with P(X = 0) = θ; that is, (cid:15) = 0 in the distribu-
tions of Fig.s 4b, 4c and 4d.

Example 2 (nuclear reactor protection systems). Consider a
nuclear reactor safety protection system that an assessor is 70%
conﬁdent contains no faults (i.e. PK2 with (cid:15) = 0 and θ = 0.7).
Upon seeing n failure-free tests, an assessor’s conservative pos-
terior conﬁdence in the failure-rate bound 10−4 (SIL 4) is shown
in Fig. 6, for three Bayesian models with different PKs: uni-
variate CBI with (cid:15) = 0; CBI with doubts in the independence
assumption and (cid:15) = 10−5 (i.e.
the baseline 1); and CBI with
doubts in independence and (cid:15) = 0.

In addition to the observations of Example 1, the new in-
sight from Example 2 concerns the beneﬁt of believing in per-
fection: in contrast to Insight 2, accumulated failure-free evi-
dence will not eventually undermine posterior conﬁdence in b.
That is, the dotted curve in Fig. 6 is an increasing function of n
that is asymptotic to the horizontal line c =
, so it lies
above the dashed curve11, yet lies below the solid curve (i.e. its

θ
θ+(1−b)φ2

11The asymptote is obtained by setting (cid:15) = 0 in the distribution of Fig. 4b,

and computing lim
n→∞

P( X < b | n executions without failure) from this.

8

For AVs, failures have been known to occur during lengthy
road testing [50] (cf. failure-free runs in the nuclear scenario).
Even when rare, failures change the form of the Klotz likeli-
hood from the one in Theorem 2 (see the general form in (3)).
The following theorem gives the conservative conﬁdence in
the failure-rate bound for this assessment scenario (see general
theorem proved in Appendix A). Here, an assessor might doubt
the independence of successive executions by the AV system, as
it drives over successive miles.

Theorem 3. The optimisation problem

P( X (cid:54) b | n executions, s failures, r consecutive failures)

inf
D

s.t. PK1, PK2, PK3, PK4

is solved by prior distributions such as those in Fig. 7, since
P( X < b | n executions, s failures, r consecutive failures) from
these priors equals the inﬁmum.

(a) φ2 (cid:62) 1 − θ

(b) φ1 (cid:54) θ and φ2 (cid:54) 1 − θ

Figure 6: (Example 2) c×100% posterior conﬁdence in [X (cid:54) 10−4] upon seeing
n failure-free tests, from three Bayesian models with different PKs.

more conservative than the conﬁdence from univariate CBI).

Insight 3 (For a possibly perfect system, failure-free testing can-
not undermine conﬁdence in a failure-rate bound). As more
successful executions are observed, the more likely it is that
these observations are the result of either a fault-free system
(so (cid:15) = 0) or a perfectly positively correlated system (so λ =
1). That is, as n increases, the distribution in Fig. 4b tends to
a distribution that has probability mass at only two points: a
at (0, 0), and a complementary probability
probability

θ
θ+(1−b)φ2

(1−b)φ2
at (b, 1). In the limit of large n, the assessor will need
θ+(1−b)φ2
more dependability evidence to distinguish between these two
competing possibilities. The effect of such evidence could be
to increase the assessor’s conﬁdence in the correlations being
very strong (i.e. φ2 increases), and thus reduce conﬁdence in
the system being fault-free. On the other hand, if further evi-
dence rules out pessimistic reasons for the positive correlations
(so that φ2 decreases), conﬁdence in the bound b increases.

The sensitivity of these insights – to changes in the strength
of the PKs – is explored in section 5. While further implications
of these insights are discussed in section 7.

4.3. With PK for Autonomous Vehicles

We turn our attention to assessing AV-safety. In line with
[39, 48], the failure-rate is the probability of a fatality-event per
mile (pfm). Unlike the protection software of subsection 4.2
which was possibly fault-free, AVs can be expected to fail in
operation – they rely on imperfect sophisticated machine learn-
ing solutions performing a complex driving task, and AVs are
susceptible to random hardware failures. This means a nonzero
lower bound pl on the failure-rate (see PK1), and an engineer-
ing goal of a “safe enough”12 system rather than “perfection”.

(c) φ1 (cid:62) 1 − θ

(d) φ1 (cid:54) 1 − θ and φ2 (cid:54) θ

Figure 7: Examples of worst-case priors that give nonzero inﬁma for the opti-
misation in Theorem 3. When demands are executed with some isolated and
consecutive failures (i.e. r > 0), the worst-case priors can look like those in
subﬁg.s 7a and 7b. And, if the executions contain some isolated failures, but
no consecutive failures (i.e. r = 0), worst-case priors can look like subﬁg.s
7c and 7d instead. The exact locations of the support of these distributions (i.e.
the black dots) depend on the values of the exponents in the likelihood function,
and whether the 1st execution is a failure, or not.

Example 3 (AVs). Consider an assessor’s conﬁdence in an AV
being as safe as the average human driver13 in terms of pfm

12How safe is “safe enough” is a separate topic [49], but a typical target

would be several times safer than the average human driver.

13The exact statistic in the U.S. (2013) is 1.09e−8, as used by [48]. For sim-

plicity we round this to 10−8 in the examples.

9

(so b = 10−8), after a ﬂeet of the AVs have driven millions of
miles. Using PK parameter values from [41], we have: the
engineering goal, (cid:15) = 10−10, is 2 orders of magnitude safer
than the pfm for human drivers; the lower bound on pfm is pl =
10−15, representing the risk of catastrophic hardware failure.
Fig. 8 shows the conﬁdence in b under different values of s (the
total number of failures), r (consecutive failures), φ1, and φ2.

s > r > 0), and prior evidence weakly supports negatively cor-
related executions (φ1 (cid:54) θ). Again, initially, correlated execu-
tions (possibly from a system with failure-rate larger than b) are
most likely. And like the previous case, as the successful exe-
cutions increase (with no more failures), it becomes less likely
that the executions are correlated, and more likely that the suc-
cesses are due to the failure-rate being smaller than b.

5. The Sensitivity of Conﬁdence Bounds to Changes in Prior

Knowledge and Evidence

Best practice approaches for expert belief elicitation should
be followed to elicit the PKs from an assessor [51, 52]. For the
assessor that is uncertain about the PK values, this section il-
lustrates how they may check the sensitivity/robustness of their
conﬁdence to variations in the PK values. These analyses also
give insight into how conﬁdence responds to a “strengthening”
of prior dependability evidence. We systematically vary the PK
parameters, the required failure-rate bound b, and the observed
execution outcomes. All corresponding prior distributions used
in these numerical analyses are summarised in Table 2.

5.1. Sensitivity Analysis for the Baseline Scenario

Fig. 9 presents 3 sets of sensitivity analysis for the baseline
scenario Example 1 – the parameters for PK2 (and b), PK3, and
PK4 are varied in Fig.s 9a, 9b and 9c respectively. Theorem 2
shows that posterior conﬁdence in b is not a function of pl (i.e.,
no prior distribution in Fig. 4 assigns probability to any location
in R with a pl coordinate). Thus we omit varying PK1.

For the baseline scenario, the conﬁdence in b from assum-
ing independent executions is always more optimistic (for all
large enough number of executions n) than the conﬁdence when
some doubt in independence is expressed. So that in Fig. 9a,
the univariate CBI solid curve eventually lies above all of the
depicted “CBI with dependence” curves. Even when a bigger
bound b is considered (i.e. the spacedash curve for b = 10−3 ini-
tially lies above the univariate CBI solid curve for b = 10−4, but
eventually lies below it). Also, for the “CBI with dependence”
curves, a smaller (cid:15) gives greater conﬁdence in b (cf. Insight
2). And less conﬁdence in the engineering goal being met (i.e.
smaller θ) gives less conﬁdence in b.

Prior conﬁdence in negatively correlated executions has no
noticeable effect on conﬁdence in b. See Fig. 9b, where all
of the “CBI with dependence” curves overlap. Intuitively, this
is because there are no isolated failures – i.e. no operational
evidence of negatively correlated executions.

On the other hand, Fig. 9c shows how greater prior conﬁ-
dence in positively correlated executions gives smaller conﬁ-
dence in b (i.e. as φ2 increases, the “CBI with dependence”
curves lie lower in the plot). But only up to a point, when
φ2 = 1 − θ, after which increasing φ2 further has no additional
effect (see that Fig. 4c is unchanging for φ2 (cid:62) 1 − θ).

5.2. Sensitivity Analysis for the Nuclear Safety Protection Sys-

tem Scenario
As before, Fig. 10 provides 3 sub-ﬁgures highlighting the

effects of changes in PK parameters (except PK1).

Figure 8: (Example 3) c×100% posterior conﬁdence in [X (cid:54) 10−8] upon seeing
s failures (r of them consecutive) in n tests, from CBI models with different
PKs.

Three observations from Fig. 8 are: i) like previous scenar-
ios, the dashed curve shows that doubts in independent execu-
tions eventually undermine conﬁdence in b when no failures
occur (cf. Insight 2). However, all the other curves (except the
solid curve) show that the occurrence of failures allows conﬁ-
dence to eventually asymptotically approach 1. This is counter-
intuitive at ﬁrst glance, but explained in Insight 4; ii) unsurpris-
ingly, more failures requires more testing for conﬁdence in b
to grow (i.e. the dash-dot curve lies to the right of the dotted
curve); and iii) more consecutive failures requires even more
testing (i.e. the space-dash curve lies to the right of the dash-
dot curve). Section 5’s sensitivity analysis explores this further.

Insight 4 (failures can allow conﬁdence in b to asymptotically
grow to 1). Consider the following two possibilities when fail-
i) no consecutive failures (so s > r = 0), and
ures occur:
prior evidence weakly supports positively correlated executions
(φ2 (cid:54) θ). Then initially, the execution outcomes are evidence of
negatively correlated executions (possibly from a system with
failure-rate larger than b). However, as the number of success-
ful executions increases (with no more failures), it becomes less
likely that the executions are negatively (or positively) corre-
lated; otherwise, more failures should have been observed. In-
stead, it’s more likely that the successes are occurring because
the failure-rate is smaller than b; ii) consecutive failures (so

10

Table 1: A list of all the prior distribution for the illustrative examples studied in Section 4

Example 1 (Fig. 5)
Example 2 (Fig. 6)

red solid
Fig. 2
Fig. 2

green dashed
Fig. 4b
Fig. 4b

Example 3 (Fig. 8)

Fig. 2

Fig. 4d

blue dotted
n/a
Fig. 4b
Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases

orange (dash)dotted
a Beta distribution*
n/a
Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases

pink spacedashed
n/a
n/a
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases

*An arbitrary Beta distribution satisfying the PKs.

(a) Varying PK2 and b

(b) Varying PK3

(c) Varying PK4

Figure 9: Sensitivity analysis varying PKs for the baseline scenario.

(a) Varying PK2 and b

(b) Varying PK3

(c) Varying PK4

Figure 10: Sensitivity analysis varying PKs for the nuclear reactor safety protection system scenario.

The “CBI with dependence” curves are still asymptotically
more conservative than the univariate CBI solid curve in Fig. 10a.
However, because of the possibility of the system being fault-
free, all of the curves show that conﬁdence in b always in-
creases. And the smaller φ2 becomes, or the bigger b or θ are,
the greater the conﬁdence in b can be asymptotically.

Fig. 10b illustrates how changes in φ1 still have no impact
on conﬁdence in b (for the same reasons as in Fig. 9b), despite

11

the possibility that the system could be fault-free.

However, Fig. 10c shows the smaller φ2 becomes, the closer
the “CBI with dependence” curve gets to the univariate CBI
curve. While, for φ2 (cid:62) 1 − θ, the conﬁdence in b is the constant
horizontal line c =

θ+(1−b)(1−θ) (see Fig. 4c with pl = (cid:15) = 0).

θ

(a) Varying PK1, PK2 and b

(b) Varying PK3

(c) Varying PK4

Figure 11: Sensitivity analysis varying PKs for the AV-safety scenario with no consecutive failures.

(a) Varying PK1, PK2 and b

(b) Varying PK3

(c) Varying PK4

Figure 12: Sensitivity analysis varying PKs for the AV-safety scenario with some consecutive failures (NB, when φ2 (cid:62) 1 − θ, the plots are effectively 0, but not 0).

5.3. Sensitivity Analysis for the AV Scenario

Next we consider the sensitivity of the AV scenario CBI so-
lutions. Recall that, unlike the baseline and nuclear protection
system scenarios, failures occur (albeit rarely14) during sufﬁ-
ciently long road testing campaigns (so s > 0). The conﬁdence
in bound b from Theorem 3 is dependent on whether some of
these failures are consecutive (r > 0) or not (r = 0). We conduct
two sets of analyses15 along these two possibilities.

5.3.1. With No Consecutive Failures

In Fig. 11a we see how conﬁdence in b changes in response
to increases in (cid:15), in the number of failures, and in the bound b.
An order of magnitude increase in (cid:15) has no noticeable impact

14Due to the severe negative impact failures can have in safety-critical sys-
tems, it is not usual practice to consider operational campaigns with a large
number of failures.

15Note, Fig. 8 shows the result of r becoming nonzero for a ﬁxed number of

failures s.

12

– the solid and dashed curves overlap. However, when b is
increased by an order of magnitude, the required number of
executions n to support a given conﬁdence level reduces by a
similar order. While, in contrast, an additional failure increases
n signiﬁcantly – so the dotted and solid curves lie to the left
of the spacedashed and dashdotted curves, respectively. This is
consistent with the ﬁndings of Littlewood and Wright [53].

Had an assessor initially been more conﬁdent in negatively
correlated executions, this would have had no noticeable effect
on conﬁdence in b (see Fig. 11b). Perhaps because there is very
little operational evidence to support such conﬁdence – i.e. only
few instances of “switching” between failure and success.

On the other hand, changes in conﬁdence in positively cor-
related executions has a clear impact, as shown in Fig. 11c.
An increase in φ2 requires an increase in n. Moreover, when
φ2 (cid:62) θ, conﬁdence in b becomes 0 for all n (see the prior dis-
tributions for r = 0 in Fig. A.27).

Table 2: A list of all prior distributions used in the sensitivity analysis of Section 5

Scenarios with various PKs

red solid

green dashed

blue dotted

orange dashdotted

pink
spacedashed

black
spacedotted

Sensitivity Analysis in Section 5

Baseline
(Fig. 9)

Nuclear
reactor
protection
system
(Fig. 10)

AVs with no
consecutive
failures
(Fig. 11)

AVs with
consecutive
failures
(Fig. 12)

Varying PK2
and b (Fig. 9a)
Varying PK3
(Fig. 9b)
Varying PK4
(Fig. 9c)
Varying PK2
and b (Fig. 10a)
Varying PK3
(Fig. 10b)
Varying PK4
(Fig. 10c)

Varying PK1,
PK2 and b
(Fig. 11a)

Varying PK3
(Fig. 11b)

Varying PK4
(Fig. 11c)

Varying PK1,
PK2 and b
(Fig. 12a)

Varying PK3
(Fig. 12b)

Varying PK4
(Fig. 12c)

Fig. 2

Fig. 2

Fig. 2

Fig. 2

Fig. 2

Fig. 2

Fig. 4b

Fig. 4b

Fig. 4d

Fig. 4b

Fig. 4b

Fig. 4c

Fig. 4b

Fig. 4d

Fig. 4d

Fig. 4c

Fig. 4c

Fig. 4c

Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26a,
A.26c, A.26e,
A.26g as n
increases*
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases

Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26a,
A.26c, A.26e,
A.26g as n
increases*
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.27a,
A.27c, A.27e,
A.27g as n
increases
Fig.s A.25a,
A.25c, A.25e,
A.25g as n
increases

Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26a,
A.26c, A.26e,
A.26g as n
increases*
Fig.s A.26a,
A.26c, A.26e,
A.26g as n
increases*
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.25a,
A.25c, A.25e,
A.25g as n
increases

Fig. 4b

Fig. 4d

Fig.s 4c/4d

Fig. 4b

Fig. 4c

Fig.s 4c/4d

Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26a,
A.26c, A.26e,
A.26g as n
increases*
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases

Fig. 4b

Fig. 4b

Fig. 4c

Fig. 4b

Fig. 4b

Fig. 4c

n/a

n/a

n/a

n/a

n/a

n/a

Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26a,
A.26c, A.26e,
A.26g as n
increases
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.27a,
A.27c, A.27e,
A.27g as n
increases
Fig.s A.25a,
A.25c, A.25e,
A.25g as n
increases

Fig.s A.26b,
A.26d, A.26f,
A.26h as n
increases
Fig.s A.26a,
A.26c, A.26e,
A.26g as n
increases
Fig.s A.27b,
A.27d, A.27f,
A.27h as n
increases
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.25b,
A.25d, A.25f,
A.25h as n
increases
Fig.s A.25a,
A.25c, A.25e,
A.25g as n
increases

*The set of worst-case priors can be replaced by Fig.s A.26b, A.26d, A.26f, A.26h as n increases, since the parameters chosen are covering both cases.

5.3.2. With Some Consecutive Failures

Despite consecutive failures, Figs. 12a and 11a broadly give

the same insights.

When prior conﬁdence in negative correlations is strong
(i.e. φ1 (cid:62) θ), Fig. 12b shows conﬁdence in b is 0 for all n,
just like the condition on φ2 in the r = 0 scenario (see the left
column of prior distributions in Fig. A.27). While a large φ2
(i.e. φ2 (cid:62) 1 − θ) gives practically 0 conﬁdence in b in Fig. 12c.
We now summarise the results of the sensitivity analysis:

Insight 5 (results of sensitivity analysis). Conﬁdence in b from
“CBI with dependence” is insensitive to changes in φ1, although
conﬁdence is 0 for φ1 (cid:62) θ, r > 0. The CBI results are sensitive
to φ2. Both the number of failures s and the number of con-
secutive failures r have a signiﬁcant effect on conﬁdence in b.
And pl is irrelevant when there are no failed executions, with
some effect when failures occur. The impact of the engineering

goal, (cid:15), is consistent with previous CBI models [41] – smaller
(cid:15) gives greater conﬁdence in b when no failures are observed,
but has no signiﬁcant impact when there are failures. Finally,
conﬁdence in b is, of course, sensitive to changes in b.

6. Independent Executions and Conservative Assessments

6.1. Which Independence Beliefs give Conservative Results?

Fig. 6 already shows that assessments based on indepen-
dent executions are conservative initially, when the number of
inputs during operational testing is relatively small. That is, the
univariate CBI curve initially overlaps with the CBI curve for
dependent executions. But, posterior conﬁdence based on inde-
pendence becomes increasingly optimistic after a large number
of tests. That is, the curves begin to deviate signiﬁcantly as the
number of tests increases. So, only assessments that allow for

13

doubt in independence – i.e. nonzero φ1 or φ2 – can support (in
the long run) more pessimistic claims about the bound b.

Once some doubt in independence has been expressed, an
assessor might want to allow for operational evidence to “slowly”
allay such doubts. Or, instead, allow for the evidence to “quickly”
convince them otherwise – that independence does not hold!
PK5 represents an assessor who’s initially very conﬁdent the
system will exhibit independent, failure-free executions.

Prior Knowledge 5 (strong belief in independence). The prob-
ability P( executions will be independent and failure-free ), from
the joint prior distribution of (X, Λ), has a value that is the so-
lution to the optimisation problem:

give the pessimistic posterior conﬁdence in these theorems are
shown in Fig. 13. And the conﬁdence from these priors, as well
as from priors in Theorems 1 and 2, are compared in Fig. 14.

Theorem 4. The optimisation problem

P( X (cid:54) b | n executions without failure)

inf
D

s.t. PK1, PK2, PK3, PK4, PK5

has the prior distribution in Fig. 13a as one of its solutions,
since P( X < b | n executions without failure) from this prior
equals the inﬁmum.

Theorem 5. The optimisation problem

P( executions will be independent and failure-free )

sup
D

s.t. PK1, PK2, PK3, PK4

While PK6 is held by an assessor who’s initially very doubt-
ful the system will exhibit independent, failure-free executions.

Prior Knowledge 6 (weak belief in independence). The proba-
bility P( executions will be independent and failure-free ), from
the joint prior distribution of (X, Λ), has a value that is the so-
lution to the optimisation problem:

P( executions will be independent and failure-free )

inf
D

s.t. PK1, PK2, PK3, PK4

Note the difference between the optimisation problems in
these PKs, and those in CBI Theorems 1, 2 and 3. Here, the
optimisations constrain the prior distribution in how it assigns
probability mass; hence why these are PKs. While the previous
optimisations are contrained by the prior distributions – specif-
ically, constrained by the PKs the priors must satisfy.

(a) φ1 + φ2 (cid:62) 1 − θ and φ2 (cid:54) 1 − θ

(b) φ1 + φ2 (cid:62) θ and φ1 (cid:54) θ

Figure 13: Prior distributions representing extreme beliefs about whether the
executions will be independent (i.e. whether [X = Λ]), for the φ1, φ2, θ ranges
indicated. Consider all prior distributions with the largest prior probability of
observing n independent executions with no failures. The most pessimistic pos-
terior conﬁdence in b from these priors is given by the prior in Fig. 13a. Simi-
larly, for all priors with the smallest prior probability of n independent failure-
free executions, Fig. 13b gives the most pessimistic posterior conﬁdence.

Theorems 4 and 5 below give the pessimistic posterior con-
ﬁdence in b, for assessors who hold PK5 or PK6 beliefs, re-
spectively. Proved in Appendix B, some prior distributions that

14

P( X (cid:54) b | n executions without failure)

inf
D

s.t. PK1, PK2, PK3, PK4, PK6

has the prior distribution in Fig. 13b as one of its solutions,
since P( X < b | n executions without failure) from this prior
equals the inﬁmum.

Fig. 14 clearly shows that the conﬁdence from the very
skeptical “PK6”-believing assessor is initially the most opti-
mistic (i.e. the widely-spaced dotted curve lies above all of the
other curves). Noticeably more optimistic than even the conﬁ-
dence based on independent executions (i.e.
the solid curve).
This is in contrast to the assessor who holds the strong PK5 be-
lief in independence. Such beliefs actually support conservative
claims initially, even as claims based on independence start be-
coming optimistic – as suggested by the overlap of the dashed
curve and the narrowly-spaced dotted curve, where the solid
curve lies above both of them. Eventually, however, the roles
are reversed as PK5 supported claims become optimistic, while
PK6 supported claims become conservative and agree with the
dashed curve.
In this sense, “strongly believing” and “being
skeptical of” the independence assumption are two halves of
“conservatively doubting” the independence assumption. This
is the behaviour for the range of PK parameter values in Fig. 14.
Why does PK5 initially support less optimistic claims than
PK6, then less pessimistic claims as the number of successes n
rises? It has to do with which prior beliefs about (X, Λ) – i.e.
which locations in R – are crucial for conservative conﬁdence
in b. There are two principal beliefs a conservative assessor
must hold: i) strong doubts of failure-free operation being ev-
idence of a “sufﬁciently reliable” system – i.e. being evidence
of a system with a failure-rate just smaller than b. And, ii)
strong conﬁdence in failure-free operation being evidence of
an “almost sufﬁciently reliable” system – i.e. being evidence
of a system with a failure-rate slightly worse than b, that ex-
hibits perfectly positively correlated executions. With a PK5
belief, failure-free operation initially supports conﬁdence in an
“almost sufﬁciently reliable” system (hence, initially conserva-
tive conﬁdence in b). But eventually, an increasing number of
successes could also be due to the system being fault-free (be-
cause there is a nonzero probability at (pl, pl) in Fig. 13a and
pl = 0 in Fig. 14). So, the dotted curve reaches a horizontal
asymptote. It’s the reverse with a PK6 belief, where an “almost

Figure 14: A comparison of posterior conﬁdence in the bound b after opera-
tional testing, showing the impact of some conﬁdence in the system’s execu-
tions being independent. For the parameter values in this example, being very
skeptical about independent executions (i.e.
the prior in Fig. 13b) gives the
most optimistic posterior conﬁdence in the bound b shown here. While strong
beliefs in independent executions (i.e. the prior in Fig. 13a) almost results in
the most pessimistic conﬁdence in b, at least for n < 4 × 104 approximately.

sufﬁciently reliable” system is initially very unlikely (hence ini-
tially optimistic conﬁdence in b), but becomes arbitrarily more
likely as n grows (hence conservative conﬁdence in b).

And, when (cid:15) = 0 in PK2, both PK5 and PK6 support con-
servative conﬁdence in b as n grows large – i.e. Theorems 2, 4
(with PK5) and 5 (with PK6) agree eventually (see Fig. 15).

7. Discussion

7.1. Incorporating Doubts about Model Assumptions into De-

pendability Claims

In Bayesian assessments, one should always question the
properties of the statistical model (such as independent execu-
tions), and whether these are appropriate for a given real-world
scenario. Our use of CBI illustrates a general, formal method
for incorporating one’s doubts – about the suitability of any sta-
tistical model properties – directly into the assessment. This is
a conservative version of a Bayesian approach ﬁrst proposed by
Draper [54]. Draper suggests that if one is uncertain about the
suitability of model properties, one should perform the infer-
ence with an “expanded” model that weakens the properties in
question and has the original model as a special case. A suit-
able prior distribution for this expanded model will have to be
deﬁned.
In this sense, our choice of the Klotz model is not
arbitrary: it is the simplest model we know of that exhibits de-
pendent, stationary Bernoulli trials, and that has “independent
executions” as a special case. This approach is incremental; if
one is doubtful of the Klotz model, a model expansion of the
Klotz model can be used for assessment.

Figure 15: A similar comparison to that of Fig. 14, but with the added constraint
that there is a probability θ = 0.7 of the system containing no faults (i.e., (cid:15) =
0). Now, a strong belief in independent executions gives the most pessimistic
posterior conﬁdence in b – i.e. the dashed “optimism in independence” and the
dotted “CBI with dependence” curves are now indistinguishable.

Our approach signiﬁcantly extends Draper’s initial idea by
requiring that the results of inference be conservative. Ensur-
ing this involves solving the constrained nonlinear optimisation
problems that characterise the CBI method.

7.2. Which Prior Beliefs give Conservative Conﬁdence Bounds?
Only certain prior beliefs about the failure-rate, X, and the
dependence between executions, Λ, will ensure an assessor’s
posterior conﬁdence in a failure-rate upper bound b is conser-
vative. The CBI solutions of sections 4 and 6 make clear what
these beliefs are – i.e.
these beliefs are encoded in the prior
distributions that solve Theorems 2, 3, 4 and 5. Speciﬁcally,
the beliefs are encoded as those (x, λ) locations in region R that
each of these distributions assigns nonzero probability to (e.g.
see Fig.s 4, 7, 13). Four main factors determine such beliefs:
i) the execution outcomes during operational testing (i.e.
the
successes and failures); ii) prior knowledge, e.g. whether evi-
dence strongly suggests the executions are not negatively corre-
lated (i.e. small φ1), but are positively correlated (i.e. large φ2);
iii) which beliefs about (X, Λ) are least likely to have produced
the testing outcomes, if the failure-rate is less than b; and iv)
which beliefs are most likely to have produced the outcomes, if
the failure-rate is larger than b. Here, “least likely” and “most
likely” are determined by the Klotz likelihood.

In addition to ensuring that an assessor’s conﬁdence is con-
servative, there are two more reasons for why such beliefs are
important. Firstly, they are consistent with the available de-
pendability evidence, since the beliefs are encoded in prior dis-
tributions that are (the limits of sequences of prior distributions
that are) consistent with the evidence. And so, the assessor can-
not “rule out” these beliefs without extra evidence, and the con-

15

Figure 16: An updated overview of the various assessment scenarios analysed in this paper (cf. Fig. 1), indicating the possible testing outcomes and prior conﬁdence
an assessor could have. The dashed paths are scenarios where either testing is futile in supporting dependability claims, or the scenarios are of little practical interest.

sequences of these beliefs should be taken seriously. Secondly,
when dependability evidence is “weak”, these beliefs can make
operational testing futile: the more one observes successful ex-
ecutions by the system, the more doubtful one becomes about
the failure-rate satisfying the bound. Assessors should be mind-
ful of having enough dependability evidence before embarking
on operational testing. We elaborate on these points below.

For example, consider when all of the system’s executions
over a large number of tests are successful (e.g. example 1 of
section 4). Superﬁcially, this operational evidence suggests that
the executions are strongly positively correlated, or that the sys-
tem’s unknown failure-rate is low. However, the assessor can
take the more conservative view that these successful execu-
tions are evidence that the system is not quite good enough.
The assessor does this by holding the following beliefs: i) if
the failure-rate is larger than b, then the successful tests are
most likely to have occurred if the following combination of
two beliefs are true:
the executions are “perfectly positively
correlated” (i.e. λ = 1), and the failure-rate is “as small as pos-
sible, but no smaller than b”. In terms of the Klotz likelihood,
this combination of beliefs is encoded as the location16 (b, 1) in
R; ii) if, instead, the failure-rate is smaller than b, then the suc-
cessful tests are least likely to have occurred if the following
two beliefs are true: the executions are as “negatively corre-
lated” as possible, and the failure-rate is “as big as possible, but
no bigger than b”. In terms of the Klotz likelihood, these beliefs
are encoded as the location (b, 0).

16More rigorously, the location (b, 1) is a so-called limit point in R, repre-
senting a belief that is the limit of an inﬁnite sequence of locations in R, where
the sequence represents increasingly pessimistic beliefs. See Appendix A.

Prior knowledge can reﬁne these beliefs further, giving the
beliefs in the prior distributions shown in Fig.s 4 and A.28.
These beliefs imply that as the number of successful executions
n increases without bound, in order for the assessor to be con-
servative, their conﬁdence in the bound must diminish (e.g. see
dotted curve in Fig. 6). Because, as n increases, the increasing
number of successful executions makes all of the other beliefs
unlikely, except the beliefs that the executions are “perfectly
positively correlated” and the failure-rate is “as small as pos-
sible, but no smaller than b”.
In modelling terms, the Klotz
likelihood tends to zero at all of the nonzero probability loca-
tions in Fig. 4, except at the point (b, 1) where the likelihood has
the constant value (1 − b) for all n. The failure-free executions
eventually undermine conﬁdence in the upper bound b.

It’s possible that the system produced the successful tests
because it has a very small nonzero failure-rate. The prob-
lem with this possibility is that, as n increases, any very small
nonzero failure-rate eventually becomes too unlikely to have
produced this many successful executions. Moreover, there are
more pessimistic reasons (not disallowed by the evidence) for
the run of successes, i.e. pessimistic reasons for the executions
to be “perfectly positively correlated”. For example, it’s possi-
ble that all of the test inputs have been “easy” for the system
the opera-
to respond to. This could happen by chance: e.g.
tional environment just happens to be submitting a sequence of
easy inputs. Overcoming such problems of chance may require
an exceedingly large, or possibly infeasible, amount of testing.
Another pessimistic reason for the successful tests could be an
error in the test-case generation procedure, which systemati-
cally fails to generate inputs that lie in the system’s failure re-

16

θ
θ+(1−b)φ2

gion. Or an error in the test oracle, which fails to indicate true
failures. Such possibilities are consistent with previous studies
that have shown how “favourable” operational evidence can un-
dermine conﬁdence during dependability assessments; e.g. Lit-
tlewood and Wright [46]. To make progress with using failure-
free operational testing evidence, the assessor must rule out pes-
simistic possibilities by using appropriate additional evidence.
If the system can be argued to possibly be fault-free – so
that, in modelling terms, the engineering goal (cid:15) is zero – then a
fault-free system could produce the increasing number of suc-
cessful executions. And this possibility will allow the assessor’s
conﬁdence in the bound b to grow. Because, the conﬁdence an
assessor has in the bound b being satisﬁed is never smaller than
their conﬁdence in the system being fault-free. And, the conﬁ-
dence in the system being fault-free increases as the number of
successful executions increases, so that conﬁdence in the bound
increases as well. That is, in Fig. 6, conﬁdence in b increases
from θ to
along the dotted curve). But, because the
successes could also be produced by more pessimistic reasons,
the conﬁdence in these more pessimistic reasons also increases
the dotted curve in Fig. 6 and the prior distribution in
(e.g.
Fig. 4b that produced this curve, together imply that this conﬁ-
θ+(1−b)(1−θ) to (1−b)φ2
dence increases from (1−b)φ2
, since φ2 (cid:54) 1 − θ
θ+(1−b)φ2
is assumed). In the limit of large n, the assessor will still be
uncertain about whether the system failure-rate is better than b.
So far we have discussed conservative beliefs when only
failure-free executions are observed. Ironically, one way some
of the pessimism we have highlighted can be overcome is if
some failures occur during testing. Then, as the number of
successful executions increases, these failures become evidence
that the executions cannot be “perfectly positively correlated”.
Because, if the executions were this strongly correlated, then
either no successes or no failures would have occurred! The
previously pessimistic belief implied by the Klotz likelihood at
location (b, 1) – where dependence parameter λ = 1 – must
now move to a different pessimistic location where x < λ < 1
(indicating a less strong positive correlation). So that now, with
an increasing number of successful executions, it eventually be-
comes most likely that the testing outcomes are being produced
by a system with a failure-rate that is smaller than b. And the
assessor’s conﬁdence in b eventually approaches certainty, al-
though this can require considerable amounts of successful ex-
ecutions because of a few failures (e.g. see Fig. 8).

Like the “failure-free” executions scenario we have been
discussing, when failures occur during testing there are also
situations where such testing is futile. But the futility here is
even more extreme than before: conﬁdence in the bound is now
identically zero, no matter how many more successful tests are
observed. For instance, note the zero conﬁdence in Fig.s 11 and
12 from priors such as those in Fig. A.27). If the failures dur-
ing testing are isolated and few, then strong conﬁdence in the
executions being positively correlated (i.e. φ2 (cid:62) θ) undermines
conﬁdence in the bound b. And, if the failures are clustered and
few, then strong conﬁdence in the executions being negatively
correlated (i.e. φ1 (cid:62) θ) undermines conﬁdence. In both situa-
tions, the assessor’s prior conﬁdence in the system being “very
reliable” is simply not strong enough to rule out pessimistic

causes for the testing outcomes.

We can now summarise the various assessment scenarios as
Fig. 16 (an updated version of Fig. 1). Each path through the
ﬁgure – starting from the far-left at the “n executions” node –
gives the operational evidence and the prior conﬁdence (i.e. PK
parameter ranges) an assessor could have. The paths contain-
ing dashed lines are those paths to be weary of; paths that our
analysis reveals to be asymptotically futile or of little practical
interest. Assessor’s who ﬁnd they may be on such paths should
seek stronger evidence of the system being sufﬁciently depend-
able prior to commencing testing.

7.3. Is assuming Independence always very Optimistic?

Figure 17: The relationship between prior conﬁdence φ2 in positively corre-
lated executions and the (1 − α) × 100% conﬁdence bound b, when the system
is subjected to 105 (successful) tests. The curves are obtained from posterior
conﬁdence given by the prior in Fig. 4b. The values of α plotted here are curves
for α = 0.01, 0.03. The smaller φ2 becomes, the smaller the failure-rate upper
bound b that can be supported at a given level of conﬁdence.

Concerning the impact of assuming independent executions,
Chen and Mills [18] observe the following when using classi-
cal inference with their Markov model of dependent executions:
even when failures are observed during testing, i) positively
correlated executions give bigger conﬁdence bounds, compared
with using Thayer et al.’s binomial model of independent exe-
cutions; ii) a “not so big” positive correlation gives conﬁdence
bounds that are comparable to those given by Thayer et al.’s
model. This agrees with CBI results, which give some more
insight into the impact of independence.

Indeed, consider the examples in Fig. 17, where all 105 exe-
cutions during testing are successful, and the system could pos-
sibly be “fault-free”. Then, for instance, the 99% conﬁdence
bound from univariate CBI (i.e. CBI that assumes indepen-
dence) is 3.7 × 10−5 – the smallest b-value from the 99% con-
ﬁdence bound (dotted) curve, precisely when φ2 = 0. All other

17

99% conﬁdence bounds from this curve – i.e. all 99% conﬁ-
dence bounds from CBI using the Klotz model and (cid:15) = 0, φ2 >
0 – are larger. Moreover, as φ2 increases, the conﬁdence bounds
b increase. While, the smaller the assessor’s prior conﬁdence
in positive correlation (i.e. φ2 decreases), the closer the Klotz
conﬁdence bound becomes to the conﬁdence bound under inde-
pendent executions (i.e. the intersection of the curves with the
horizontal axes). And, when the system can’t be argued to be
fault-free, CBI with the Klotz model is signiﬁcantly more con-
servative. For example, the long-dashed curve gives the 99%
conﬁdence bounds when (cid:15) = 10−5. Here, the univariate CBI
99% conﬁdence bound is 4.7 × 10−5 (at φ2 = 0), which is “4
orders of magnitude” smaller than the 99% conﬁdence bound
0.1 given by the Klotz model at φ2 = 3.5 × 10−3.

Interestingly, unlike Chen and Mill’s other observation (that
a reduction in conﬁdence bounds accompanies an increase in
negative correlation), the sensitivity analysis of section 5 sug-
gests that conﬁdence bounds from failure-free testing are in-
sensitive to changes in conﬁdence in negative correlation φ1. In
fact, since φ1 (cid:62) θ in Fig. 17, the relevant posterior conﬁdence is
(1−(cid:15))(1−(cid:15)/1 − (cid:15))n−1θ
given by the prior in Fig. 4b as
(1−(cid:15))(1−(cid:15)/1 − (cid:15))n−1θ+(1−θ−φ2)(1−b)n+(1−b)φ2
which does not depend on φ1. This is unsurprising, since the
lack of failures supports one’s conﬁdence in positive correla-
tion φ2, and undermines conﬁdence in negative correlation φ1.
So, the plots illustrate how conservative conﬁdence bounds
can be very sensitive to conﬁdence in positive correlation – i.e.
small changes in φ2 can result in “orders of magnitude” changes
in conﬁdence bounds. If evidence strongly supports the exe-
cutions being positively correlated, the conﬁdence bounds ob-
tained under assuming independence can be quite optimistic.
On the other hand, section 6 and Fig. 14 show how being skep-
tical about independent executions can be initially optimistic;
giving smaller conﬁdence bounds than the conﬁdence bounds
from univariate CBI. And strongly believing in independence
can be conservative initially. As successes accumulate, these
roles between “skepticism ” and “strong belief” are reversed.

,

7.4. Limitations, Generalisations and Future Work

There is the usual trade-off between the level of sophisti-
cation in a failure-model and the practicalities of using such
a model to support assessments. If the model is too sophisti-
cated, one looses the ability to “ﬁt” the model in practice and
make justiﬁed pronouncements about system dependability. On
the other hand, if the model is too simplistic, it can only sup-
port naive claims. Our approach to this trade-off is twofold:
i) we have chosen to be “parsimonious” in our model choice –
choosing to use a failure-model that is just expressive enough to
explicitly capture doubts in independence, while it can also be
“ﬁtted” to observational data and evidence; ii) the CBI formal-
ism is designed to be used incrementally, so that an assessor can
replace the failure model with a more sophisticated one, should
evidence arise that supports this change.

Consequently, using a relatively simple Markov model of
dependent Bernoulli trials – i.e. the Klotz failure-model – we
have illustrated how to account for dependent executions in
conservative Bayesian dependability assessments. These re-

sults are applicable to any system that can be adequately ap-
proximated as an “on-demand” system; this includes many sys-
tems that operate continuously, as observed in [18].

Of course, there is scope for studying the implications of
more expressive failure-models in future work. For instance,
many systems experience different kinds of failure, some of
which may be considered benign. Some Markov models that
capture this include the models used in [14, 19, 55]. In contrast,
the Klotz model treats all failures (and all successes) identically,
in terms of how likely they are to occur, and the model ignores
the variation in the impact these outcomes have on stakehold-
ers in the system. Another Klotz model limitation is that pos-
itive correlation in both of its forms – i.e. whether failures are
likely to follow previous failures or successes follow previous
successes – are captured by a single parameter λ. And, yet an-
other limitation is that the dependence structure – whether the
executions are positively correlated, negatively correlated or in-
dependent – is ﬁxed for the duration of the system’s operation.
So the nature of the dependence between executions is assumed
unchanging for this duration. Certainly, there are practical sit-
uations where the dependence can vary signiﬁcantly over time,
e.g. a change in the system’s internal state makes failures much
more/less likely. Or dependence can exist between several ex-
ecutions that are not consecutive, but separated in time. Ac-
counting for such dependence variation requires a failure-model
that explicitly captures time-dependent correlations.

While on the subject of time-dependent correlation mod-
els, we make the following comment. The Klotz model is a
1st-order stationary stochastic process (see [24, 44]). Failure-
rates often used in dependability assessment – such as the pfd
– make sense in settings where the failure process is stationary.
Because then, the probability of the system failing its n-th exe-
cution is the same for all n, and it equals the pfd. This, despite
the conditional probability of failing the very next execution be-
ing dependent on, say, the success/failure of the last execution.
Consequently, upper conﬁdence bounds on such failure-rates
are useful measures of dependability, in those practical sce-
narios characterised by a stationary failure process. But when
failure-rates are time-dependent, one may need to forego using
pfds in assessment claims, and opt for more suitable depend-
ability measures instead, such as the probability of failure-free
operation over a large number of executions n. In [17] Strigini
makes a related point in a classical inference context, arguing
that the probability of a sequence of failures longer than some
given length k might be more useful than the failure-rate when
assessing, say, a control system that operates continuously.

In fact, even in the present context using a 1st-order sta-
tionary model, it’s worth studying the impact (of ignoring de-
pendence between executions) on dependability measures other
than posterior conﬁdence bounds; measures such as the proba-
bility of failure-free operation on n consecutive future demands.
As previous CBI studies have shown, an assessor’s justiﬁca-
tions for a conservative claim are often different for different
posterior dependability measures, even if the justiﬁcations are
ultimately based on the same PKs. And some measures may be
more sensitive to changes in PKs than other measures.

Concerning applying CBI methods to support ultra-high re-

18

liability claims, we echo the caution given in [21]. Although
Bayesian methods are powerful tools, they are not a “silver bul-
let” for the challenges faced when assessing ultra-high reliabil-
ity systems. Like previous applications of Bayesian methods to
this problem, our analysis suggests that very strong dependabil-
ity evidence (obtained prior to testing) is required to support
strong dependability claims, when the amount of operational
testing needed is infeasible and failures are extremely rare.

8. Conclusion

Statistically independent software executions are often as-
sumed when assessing system dependability. While this can be
appropriate, the impact (on assessments) when this assumption
is inappropriate can be signiﬁcant. This is especially concern-
ing if the assumption undermines conservatism when assessing
an SCS; for such systems, (dangerously) optimistic assessments
should be strenuously avoided. By formalising informal notions
of “doubting” the independence assumption, and by employing
conservative Bayesian methods with a Markov model of depen-
dent executions, this work demonstrates how such doubts can
be accounted for in dependability claims.

Several assessment scenarios are analysed, in terms of a
system’s failure behaviour during testing and the conﬁdence an
assessor can justify prior to testing; conﬁdence in whether the
executions are positively correlated, negatively correlated or in-
dependent, and conﬁdence in the system being sufﬁciently de-
pendable. The analyses involve the constrained17 mathematical
optimisation of an assessor’s conﬁdence in a failure-rate up-
per bound, after observing the system in operation. By design,
the solutions to these optimisations come with three guarantees
concerning an assessor’s conﬁdence: i) only conﬁdence that an
assessor can justify will be accounted for in the assessment; ii)
no prior distributions consistent with the assessor’s prior conﬁ-
dence will give more conservative (i.e. smaller) posterior con-
ﬁdence in a failure-rate upper bound; and iii) any prior distri-
bution that gives more conservative conﬁdence must do so by
violating the assessor’s prior conﬁdence in some way.

The work highlights a number of assessment considerations,
such as the possibility of a system exhibiting no failures during
operation giving less conﬁdence in a failure-rate bound, com-
pared with if the system had exhibited failures. Or the possi-
bility of this conﬁdence being very sensitive to failures, so that
each additional failure requires signiﬁcantly more executions
for conﬁdence to conservatively grow.

The scope of the results makes clear that a nuanced an-
swer is required to the question of whether the independence
assumption has an impact. The answer depends, often sensi-
tively, on various factors outlined in the paper. So that some-
times, the independence assumption has “little to no” impact on
conservatism. And sometimes, the impact is simply too great to
ignore. A “case-by-case” approach to estimating this impact in
practice is advised, and the methods and many solutions in this
paper provide assessors/practitioners with the means to do this.

17That is, constrained over all prior probability distributions that are consis-

tent with the assessor’s uncertainty and the available dependability evidence.

References

[1] C. L. Atwood, S. N. Laboratories, U. S. N. R. Commission, Handbook of
parameter estimation for probabilistic risk assessment, Division of Risk
Analysis and Applications, Ofﬁce of Nuclear Regulatory Research, U.S.
Nuclear Regulatory Commission Washington, DC, 2003.

[2] Thomas E. Wierman, Scott T. Beck, Michael B. Calley, Steven A. Eide,
Cindy D. Gentillon, William E. Kohn, Reliability Study: Combustion
Engineering Reactor Protection System, 1984–1998, Technical Report
NUREG/CR-5500 Vol.10, Idaho National Engineering and Environmen-
tal Laboratory, U.S. Nuclear Regulatory Commission Washington, DC,
2001.

[3] C. Bunea, T. Charitos, R. M. Cooke, G. Becker, Two-stage Bayesian
models—application to ZEDB project, Reliability Engineering & System
Safety 90 (2005) 123 – 130.

[4] K. P¨orn, The two-stage Bayesian method used for the T-Book application,

Reliability Engineering & System Safety 51 (1996) 169 – 179.

[5] N. E. Fenton, M. Neil, Software metrics: successes, failures and new

directions, Journal of Systems and Software 47 (1999) 149–157.

[6] J. C. Knight, N. G. Leveson, An experimental evaluation of the assump-
tion of independence in multiversion programming, IEEE Transactions
on Software Engineering SE-12 (1986) 96–109.

[7] S. S. Brilliant, J. C. Knight, N. G. Leveson, Analysis of faults in an n-
version software experiment, IEEE Transactions on Software Engineering
16 (1990) 238–247.

[8] D. E. Eckhardt, L. D. Lee, A theoretical basis for the analysis of multiver-
sion software subject to coincident errors, IEEE Transactions on Software
Engineering SE-11 (1985) 1511–1517.

[9] B. Littlewood, D. R. Miller, Conceptual modeling of coincident failures
in multiversion software, IEEE Transactions on Software Engineering 15
(1989) 1596–1614.

[10] R. A. Thayer, M. Lipow, E. C. Nelson, Software Reliability, North-

Holland, 1978.

[11] J. W. Duran, S. C. Ntafos, An evaluation of random testing, IEEE Trans-

actions on Software Engineering SE-10 (1984) 438–444.

[12] P. E. Ammann, J. C. Knight, Data diversity: an approach to software fault

tolerance, IEEE transactions on computers 37 (1988) 418–425.

[13] P. Bishop, The variation of software survival time for different operational
input proﬁles (or why you can wait a long time for a big bug to fail), in:
FTCS-23 The Twenty-Third International Symposium on Fault-Tolerant
Computing, IEEE, 1993, pp. 98–107.

[14] A. Csenki, Reliability analysis of recovery blocks with nested clusters of

failure points, IEEE transactions on reliability 42 (1993) 34–43.

[15] L. A. Tomek, J. K. Muppala, K. S. Trivedi, Modeling correlation in soft-
IEEE Transactions on Software Engineering 19

ware recovery blocks,
(1993) 1071–1086.

[16] R. Huang, W. Sun, Y. Xu, H. Chen, D. Towey, X. Xia, A survey on
adaptive random testing, IEEE Transactions on Software Engineering 47
(2021) 2052–2083.

[17] L. Strigini, On testing process control software for reliability assessment:
the effects of correlation between successive failures, Software Testing,
Veriﬁcation and Reliability 6 (1996) 33–48.

[18] S. Chen, S. Mills, A binary Markov process model for random testing,

IEEE Transactions on Software Engineering 22 (1996) 218–223.

[19] K. Goseva-Popstojanova, K. S. Trivedi, Failure correlation in software

reliability models, IEEE Transactions on Reliability 49 (2000) 37–48.

[20] D. R. Miller, Making statistical inferences about software reliability,

Technical Report, NASA, 1988.

[21] B. Littlewood, L. Strigini, Validation of ultrahigh dependability for
software-based systems, Communications of the ACM 36 (1993) 69–80.
[22] A. Bondavalli, S. Chiaradonna, F. Di Giandomenico, L. Strigini, De-
pendability models for iterative software considering correlation between
successive inputs, in: Proc. of IEEE Int. Computer Performance and De-
pendability Symposium, IEEE, Erlangen, Germany, 1995, pp. 13–21.
[23] A. Bondavalli, S. Chiaradonna, F. D. Giandomenico, S. L. Torre, Mod-
elling the effects of input correlation in iterative software, Reliability
Engineering & System Safety 57 (1997) 189–202.

[24] J. Klotz, Statistical Inference in Bernoulli Trials with Dependence, The

Annals of Statistics 1 (1973) 373–379.

[25] K. W. Miller, L. J. Morell, R. E. Noonan, S. K. Park, D. M. Nicol, B. W.
Murrill, M. Voas, Estimating the probability of failure when testing re-

19

veals no failures, IEEE Transactions on Software Engineering 18 (1992)
33–43.

[26] H. Singh, V. Cortellessa, B. Cukic, E. Gunel, V. Bharadwaj, A Bayesian
approach to reliability prediction and assessment of component based sys-
tems,
in: Proc. 12th International Symposium on Software Reliability
Engineering, pp. 12–21.

[27] B. Littlewood, P. Popov, L. Strigini, Assessing the reliability of diverse
fault-tolerant software-based systems, Safety science 40 (2002) 781–796.
[28] P. Popov, Bayesian reliability assessment of legacy safety-critical systems
upgraded with fault-tolerant off-the-shelf software, Reliability engineer-
ing & system safety 117 (2013) 98–113.

[29] J. O. Berger, An overview of robust Bayesian analysis, Test 3 (1994)

5–124.

[30] J. O. Berger, Robust Bayesian analysis : Sensitivity to the prior, journal

of statistical planning and inference 25 (1990) 303–328.

[31] M. Lavine, Sensitivity in Bayesian statistics: The prior and the likelihood,
Journal of the American Statistical Association 86 (1991) 396–399.
[32] J. Berger, E. Moreno, Bayesian robustness in bidimensional models: Prior
Journal of statistical planning and inference 40 (1994)

independence,
161–176.

[33] P. Bishop, R. Bloomﬁeld, B. Littlewood, A. Povyakalo, D. Wright, To-
ward a formalism for conservative claims about the dependability of
software-based systems, IEEE Transactions on Software Engineering 37
(2011) 708–717.

[34] L. Strigini, A. Povyakalo, Software fault-freeness and reliability predic-
in: F. Bitsch, J. Guiochet, M. Kaˆaniche (Eds.), Computer Safety,
tions,
Reliability, and Security, volume 8153 of LNCS, Springer Berlin Heidel-
berg, Berlin, Heidelberg, 2013, pp. 106–117.

[35] X. Zhao, B. Littlewood, A. Povyakalo, D. Wright, Conservative claims
in: 26th

about the probability of perfection of software-based systems,
Int. Symp. on Software Reliability Eng., IEEE, 2015, pp. 130–140.
[36] X. Zhao, B. Littlewood, A. Povyakalo, L. Strigini, D. Wright, Modeling
the probability of failure on demand (pfd) of a 1-out-of-2 system in which
one channel is “quasi-perfect”, Reliability Engineering & System Safety
158 (2017) 230–245.

[37] K. Salako, Loss-Size and Reliability Trade-Offs Amongst Diverse Redun-
dant Binary Classiﬁers, in: M. Gribaudo, D. N. Jansen, A. Remke (Eds.),
Quantitative Evaluation of Systems, volume 12289 of LNCS, Springer In-
ternational Publishing, Cham, 2020, pp. 96–114.

[38] X. Zhao, B. Littlewood, A. Povyakalo, L. Strigini, D. Wright, Conser-
vative claims for the probability of perfection of a software-based system
using operational experience of previous similar systems, Reliability En-
gineering & System Safety 175 (2018) 265 – 282.

[39] X. Zhao, V. Robu, D. Flynn, K. Salako, L. Strigini, Assessing the Safety
and Reliability of Autonomous Vehicles from Road Testing, in: the 30th
Int. Symp. on Software Reliability Engineering, IEEE, Berlin, Germany,
2019, pp. 13–23.

[40] B. Littlewood, K. Salako, L. Strigini, X. Zhao, On reliability assessment
when a software-based system is replaced by a thought-to-be-better one,
Reliability Engineering & System Safety 197 (2020) 106752.

[41] X. Zhao, K. Salako, L. Strigini, V. Robu, D. Flynn, Assessing safety-
critical systems from operational testing: A study on autonomous vehi-
cles, Information and Software Technology 128 (2020) 106393.

[42] K. Salako, L. Strigini, X. Zhao, Conservative Conﬁdence Bounds in
Safety, from Generalised Claims of Improvement & Statistical Evidence,
in: 51st Annual IEEE/IFIP International Conference on Dependable Sys-
tems and Networks, DSN’21, IEEE/IFIP, Taipei Taiwan, 2021, pp. 451–
462.

[43] B. Littlewood, J. Rushby, Reasoning about the reliability of diverse two-
channel systems in which one channel is ‘possibly perfect’, IEEE Tran.
on Software Engineering 38 (2012) 1178–1194.

[44] K. Salako, X. Zhao, The Unnecessity of Assuming Statistically Inde-
pendent Tests in Bayesian Software Reliability Assessments, Technical
Report arXiv:2208.00462, 2022. Online : https://doi.org/10.48550/arXiv.
2208.00462.

[45] IEC,

IEC61508,

Elec-
tronic/Programmable Electronic Safety Related Systems, International
Electrotechnical Commission (IEC), 2010.

Functional

Electrical/

Safety

of

[46] B. Littlewood, D. Wright, The use of multilegged arguments to increase
conﬁdence in safety claims for software-based systems: A study based on
a BBN analysis of an idealized example, IEEE Transactions on Software

Engineering 33 (2007) 347–365.

[47] E. T. Barr, M. Harman, P. McMinn, M. Shahbaz, S. Yoo, The oracle
problem in software testing: A survey, IEEE Transactions on Software
Engineering 41 (2015) 507–525.

[48] N. Kalra, S. Paddock, Driving to safety: How many miles of driving
would it take to demonstrate autonomous vehicle reliability?, Transp.
Research Part A: Policy and Practice 94 (2016) 182–193.

[49] P. Liu, R. Yang, Z. Xu, How safe is safe enough for self-driving vehicles?,

Risk Analysis 39 (2019) 315–325.

[50] National Highway Trafﬁc Safety Administration, Summary Report:
Standing General Order on Crash Reporting for Level 2 Advanced Driver
Assistance Systems, Technical Report DOT HS 813 325, U. S. Depart-
ment of Transportation, 2022.

[51] PRA Working Group, A Review of NRC Staff uses of Probabilistic Risk
Assessment, Technical Report NUREG-1489, U. S. Nuclear Regulatory
Commission, 1994.

[52] A. O’Hagan, C. Buck, A. Daneshkhah, J. Eiser, P. Garthwaite, D. Jenkin-
son, J. Oakley, T. Rakow, Uncertain Judgements: Eliciting Experts’ Prob-
abilities, Statistics in Practice, Wiley, 2006.

[53] B. Littlewood, D. Wright, Some conservative stopping rules for the oper-
ational testing of safety critical software, IEEE Transactions on Software
Engineering 23 (1997) 673–683.

[54] D. Draper, Assessment and propagation of model uncertainty, Journal of
the Royal Statistical Society. Series B (Methodological) 57 (1995) 45–97.
[55] A. Bondavalli, S. Chiaradonna, F. Di Giandomenico, L. Strigini, A contri-
bution to the evaluation of the reliability of iterative-execution software,
Software testing, veriﬁcation & reliability 9 (1999) 145–166.

[56] W. Rudin, Principles of Mathematical Analysis, International series in

pure and applied mathematics, McGraw-Hill, 3 edition, 1976.

[57] E. T. Copson, Metric Spaces, Cambridge Tracts in Mathematics, Cam-

bridge University Press, 1968.

[58] E. Moreno, J. A. Cano, Robust Bayesian analysis with ε-contaminations
Journal of the Royal Statistical Society. Series B

partially known,
(Methodological) 53 (1991) 143–155.

[59] K. Salako, L. Strigini, X. Zhao, Proofs of Conservative Conﬁdence
Bounds on PFD, Using Claims of Improved Reliability, Technical Re-
port, centre for software reliability, 2021. Online : https://openaccess.
city.ac.uk/id/eprint/25905/.

Appendix A. Conservative Bayesian Assessment

Appendix A.1. Klotz Failure-Model Likelihood Function

The Klotz failure-model is naturally expressed in coordi-
nates (x, λ), where x is the Bernoulli frequency parameter and λ
(cid:111)
is the model’s correlation parameter. If λ∗ denotes max
,
the Klotz model likelihood function is well-deﬁned18 over the
region R deﬁned by 0 (cid:54) x (cid:54) 1, λ∗ (cid:54) λ (cid:54) 1 (depicted in
Fig.s 4a and A.18a). R ensures the likelihood’s magnitude is no
greater than 1. The likelihood has two primary forms:
(cid:16) (1−λ)x
1−x

1 − (1−λ)x
λγ(1 − λ)δ;
x
1−x
when the 1st execution is a failure

(cid:110)
0, 2x−1
x

(cid:17)α (cid:16)

(cid:17)β



L(x, λ; α, β, γ, δ) =

(cid:17)α (cid:16)

(cid:16) (1−λ)x
1−x

(1 − x)
when the 1st execution is a success

1 − (1−λ)x
1−x

λγ(1 − λ)δ;

(cid:17)β




(A.1)
where the greek exponents in the likelihood are ﬁxed by the
outcomes of a system’s executions in response to n demands,
and satisfy α, β, γ, δ (cid:62) 0.

18Strictly speaking, the likelihood function in (A.1) is not well-deﬁned at
the point (1, 1) except for appropriate ranges of the greek exponents. The like-
lihood’s value at this point is 0, and thus well-deﬁned, if either the demand
executions begin with a success, or δ > 0 (so failure is not an absorbing state).
These sufﬁcient conditions are satisﬁed in all practical scenarios of interest.

20

In practice, the Klotz likelihood is used as follows. Con-
sider a system executing n demands, with s failed executions,
and r of these failures being consecutive failures – i.e. when a
failure immediately follows a previous failure. Then, the Klotz
likelihood becomes one of the following four expressions, de-
pending on the particular values of the greek exponents in (A.1).
That is, depending on whether the n executed demands,
1) begin with a failure and end with a failure:

(cid:33)s−r−1

(cid:32)

x

(1 − λ)x
1 − x

λr(1 − λ)s−r−1

(cid:33)n−2s+r+1

(cid:32)

1 −

(1 − λ)x
1 − x

(A.2)

when α = s − r − 1, β = n − 2s + r + 1, γ = r and δ = s − r − 1;
2) begin with a success and end with a failure:

(1 − x)

(cid:33)s−r

(cid:32)

(1 − λ)x
1 − x

λr(1 − λ)s−r−1

(cid:33)n−2s+r

(cid:32)
1 −

(1 − λ)x
1 − x

(A.3)

when α = s − r, β = n − 2s + r, γ = r and δ = s − r − 1;
3) begin with a success and end with a success:

(1 − x)

(cid:33)s−r

(cid:32)

(1 − λ)x
1 − x

λr(1 − λ)s−r

(cid:33)n−2s+r−1

(cid:32)

1 −

(1 − λ)x
1 − x

(A.4)

when α = s − r, β = n − 2s + r − 1, γ = r and δ = s − r;
4) begin with a failure and end with a success:

(cid:33)s−r−1

(cid:32)

x

(1 − λ)x
1 − x

λr(1 − λ)s−r

(cid:33)n−2s+r

(cid:32)
1 −

(1 − λ)x
1 − x

(A.5)

when α = s − r − 1, β = n − 2s + r, γ = r and δ = s − r.

In alternative coordinates (λ, y), deﬁned by the transforma-
from (x, λ) coordinates, the Klotz

tion λ = λ and y = (1−λ)x
1−x
likelihood (A.1) has the equivalent forms:


y

y+1−λ yα(1 − y)βλγ(1 − λ)δ;
when the 1st execution is a failure

L(λ, y; α, β, γ, δ) =

1−λ
y+1−λ yα(1 − y)βλγ(1 − λ)δ;
when the 1st execution is a success




(A.6)
In what follows, we will use the likelihood function in either
(x, λ) or (λ, y) coordinates (whichever is more convenient to
work with), for suitable α, β, γ and δ.

Appendix A.2. Posterior conﬁdence in failure-rate bound

We prove the following theorem.

Theorem 6. Let D be the set of all prior distributions over
the region R and let 0 (cid:54) (cid:15) < b < 1
2 (see Fig. A.18a). The
optimisation problem

P( X (cid:54) b | outcomes of executing n demands )

inf
D

s.t. P(Λ < X) = φ1, P(Λ > X) = φ2, P(X (cid:54) (cid:15)) = θ

is solved by prior distributions such as those in Fig.s A.25 –
A.28, since P( X < b | outcomes of executing n demands ) from
these priors (for pl = 0) equals the inﬁmum.

21

(a) A feasible joint distribution of (X, Λ), over the region R, allocates
probability masses {Mi} over R subsets. The masses must satisfy M1 +
M3 + M5 = Φ2, M2 + M4 + M6 = Φ1, and probability M7 = 1 − (cid:80)6
i=1 Mi
is allocated to the diagonal.

(b) A discrete joint prior distribution over R. It allocates probability
masses Mi to single points within each subset and along the diagonal.

Figure A.18

Proof. The optimisation constraints can be used to partition R
into 7 disjoint subsets (with one of the subsets being the 45◦
diagonal). Each prior distribution F ∈ D must assign 7 proba-
bilities {Mi}7
i=1 to these subsets, in such a way as to satisfy the
constraints of the optimisation problem (see Fig. A.18a).

The proof progresses in 6 stages:

1. restrict the optimisation from D to its subset D(cid:48) of dis-
crete prior distributions. An arbitrary discrete prior as-
signs its probabilities Mi to 7 arbitrary points {(xi, λi)}7
i=1
within R. Hence, the objective function becomes a ratio-
nal function of the “xi”s, “λi”s and “Mi”s;

2. show that the gradient of this objective function is deter-
mined by the gradient of the Klotz model likelihood;

3. show the likelihood is unimodal along vertical and hori-
zontal lines in R, as well as along the 45◦ diagonal line;

4. show that the likelihood is also unimodal over all of R,
and it attains its maximum either at a stationary point in
the interior of R, or along the boundary of R;

5. the previous steps in the proof imply the following: start-
ing from any F ∈ D(cid:48), and the probabilities {Mi} as-
signed by F, we can construct a new prior that gives a
smaller value for the objective function (compared with

F’s objective function value). We simply use the gradi-
ent of the likelihood to determine new locations within
each of the 7 R-subsets, and reassign the “Mi”s to these
new locations. This reassignment produces a new prior
distribution, which in turn can have its probabilities re-
assigned to new points (and so on, indeﬁnitely). And in
the limit, depending on what the values of α, β, γ and δ
are, the sequence of new points obtained by successive
reassignments will converge to limit points19 in each R-
subset. That is, the objective function values converge
in a monotonically decreasing manner, as the sequence
of “reassigned” priors converge to a limiting distribution
with support at, no more than, 7 limit points;

6. ﬁnally, determine the precise values for the “Mi”s that a
limiting distribution should assign to limit points – to en-
sure that the related sequence of objective function val-
ues converge to the inﬁmum. Determining these worst-
case “Mi”s is a constrained linear fractional program-
ming problem. One may solve this either numerically, or
by a logical allocation of probability masses to the rel-
evant limit points in R. For the CBI solutions in this
paper, we use the latter approach. These ﬁnal forms of
limiting distribution (illustrated in Fig.s A.25 – A.28) are
worst-case prior distributions; so-called because P( X <
b | outcomes of executing n demands ) for these distribu-
tions equals the inﬁmum we seek.

Let us proceed with the proof:

stage 1) By deﬁnition, for any F ∈ D,

P( X (cid:54) b | outcomes of executing n demands )

E[L(X, Λ; α, β, γ, δ)1X(cid:54)b]
E[L(X, Λ; α, β, γ, δ)]

=

=

(cid:82)
[0,b]×[λ∗,1]
(cid:82)
[0,1]×[λ∗,1]

L(x, λ; α, β, γ, δ) dF(x, λ)

L(x, λ; α, β, γ, δ) dF(x, λ)

However, the set D can be restricted to the subset D(cid:48) of discrete
joint distributions – i.e. to those distributions that assign their
“Mi”s to single points within each R subset [58, 59] (e.g. see
Fig. A.18b). So that, for any F ∈ D(cid:48), the objective function of
the optimisation becomes

P( X (cid:54) b | outcomes of executing n demands )

=

=

L(x, λ; α, β, γ, δ) dF(x, λ)

(cid:82)
[0,b]×[λ∗,1]
(cid:82)
[0,1]×[λ∗,1]
(cid:80)7
i=1 L(xi, λi; α, β, γ, δ)1X(cid:54)b Mi
(cid:80)7
i=1 L(xi, λi; α, β, γ, δ) Mi

L(x, λ; α, β, γ, δ) dF(x, λ)

= Num
Denum

19Deﬁnition: for a given topology (e.g. the “open balls” topology associated
with 2D Euclidean space), a limit point of a subset of the plane is a point that is
arbitrarily well-approximated by sequences of points within the subset [56, 57].

22

Consequently the objective function has become Num
nal function of the “xi”s, “λi”s and “Mi”s.

Denum ; a ratio-

stage 2) Consider how this objective function changes when
2 . The

restricted to a vertical line, in the subset of R where x (cid:54) 1
rate of change of Num

Denum with respect to λ is then


∂
∂λ

(cid:19)

(cid:18) Num
Denum

=

∂
∂λ Denum
Denum



∂
∂λ Num
∂
∂λ Denum

−

Num
Denum





(A.7)

(cid:17)

(cid:16) Num
Denum

Since Num
Denum is a rational function of λ, it is smooth (except
where Denum = 0). Consequently, the sign of ∂
in-
∂λ
dicates how to move the location of the “Mi”s along vertical
lines in each R subset, in order to minimise Num

The following argument shows how the sign of ∂
∂λ

(cid:16) Num
Denum
is determined by the sign of ∂
∂λ L(x, λ; α, β, γ, δ) and the size of
x. Observe that ∂
∂λ Denum and
∂λ
(cid:18) ∂
(cid:19)
have the same sign. When the R region sat-

(cid:17) (cid:62) 0 if, and only if, ∂

(cid:16) Num
Denum

Denum .

(cid:17)

∂λ Num
− Num
∂
Denum
∂λ Denum
isﬁes x (cid:54) b, this implies

= 1 for λ from that region.

∂
∂λ Num
∂
∂λ Denum
in (A.7), and noting that the objec-

∂
∂λ Num
∂
∂λ Denum

(cid:17)

(cid:17)

and ∂

(cid:16) Num
Denum

Substituting 1 for
tive function Num
Denum is a probability (hence must lie between 0
and 1), we have that ∂
∂λ Denum share the same
∂λ
(cid:16) Num
sign when x (cid:54) b. And, when x (cid:62) b instead, ∂
and
Denum
∂λ
∂λ Denum have opposite signs20. So, the sign of ∂
∂
∂λ Denum (i.e.
the sign of ∂
∂λ L(x, λ; α, β, γ, δ)), and the value of x, together de-
(cid:17)
(cid:16) Num
termine the sign of ∂
. A similar argument shows that
Denum
∂λ
along horizontal lines in R, ∂
∂x L(x, λ; α, β, γ, δ) and x’s value de-
(cid:17)
(cid:16) Num
termine the sign of ∂
. And thus, they determine where
Denum
∂x
the “Mi”s should be allocated to minimize Num
Denum along that line.
2 is satis-
ﬁed, L(x, λ; α, β, γ, δ) is a non-negative unimodal function of λ.
∂λ L(x, λ; α, β, γ, δ) = 0 has non-trivial so-
To see this, note that ∂
lutions at λ values where two quadratic functions of λ intersect.
That is, solutions to

stage 3) Along any vertical line in R where x (cid:54) 1

(cid:32)

1 −

(cid:33)

x

(1 − λ)
1 − x

(γ − λ(γ + δ)) = λ

(cid:32)

α − (α + β)

(cid:33)

x

(1 − λ)
1 − x

(A.8)

An illustration of these two functions is given in Fig. A.19.
, γ
One function has two roots of opposite sign (at λ = 2x−1
γ+δ )
x
and a maximum, while the other function has a root at λ = 0 and
a minimum. This means at least one solution to (A.8) cannot lie
within R – it must be non-positive. And the other solution must
be positive and represents a maximum turning point. Because
the l.h.s of (A.8) is bigger than the r.h.s. for λ values slightly
smaller than the positive solution, and the l.h.s. is smaller than
the r.h.s. for all λ values bigger than the positive solution.

Thus, as λ grows from 0 to 1 along any vertical line in R
2 ), there is (at most) one stationary point at which

(where x (cid:54) 1

20These statements exclude the unimportant edge cases when Num
Denum

= 0, 1.

∂x L(x, λ; α, β, γ, δ) transitions from being positive to being

the ∂
negative. That is, the stationary point is a maximum.

(a) From likelihood with a successful
1st execution, γ + δ (cid:44) 0 and α + β (cid:44)
1, 0

(b) The stationary curves of Fig. A.21a
depicted in R.

(c) From likelihood with a failed 1st
execution, α + β (cid:44) 0 and γ + δ (cid:44) 1, 0

(d) The stationary curves of Fig. A.21c
depicted in R.

Figure A.21: Two illustrations of pairs of curves intersecting, at most,
once, over the range 0 < λ < 1, 0 < y < 1. This geometric fact implies
L(x, λ; α, β, γ, δ) is unimodal over R with, at most, one stationary point
in the interior of R .

stage 4) Finally, the likelihood either has a single stationary
point within R at which it attains a maximum value over R, or it
attains its maximum value over R on the boundary of R. When
the single stationary point lies within R, it can be determined
∂y L(λ, y; α, β, γ, δ) = 0
by solving ∂
simultaneously for λ and y. The non-trivial solutions for this
simultaneous system of equations are given by the intersections
of pairs of curves, as illustrated in Fig. A.21.

∂λ L(λ, y; α, β, γ, δ) = 0 and ∂

If the stationary point lies within R then it must be a max-
imum. Because the stationary curves in Fig. A.21 imply that,
from any point along the boundary of R, we can always move
away from that point along an appropriate path within R to in-
crease the likelihood’s value.

stage 5) stages 1-4 of this proof demonstrate the existence
and uniqueness of locations in R that are local or global max-
ima, as exempliﬁed in Fig. A.22. For the region x (cid:54) b in R, the
“further away” from maxima the locations a prior assigns prob-
abilities to, the smaller the objective function. And, for x > b,
the “closer” the nonzero probability locations are to the max-
ima, the smaller the objective function. Here, “further away”

23

(a) 0 (cid:54) α(1−x)
(α+β)x

(cid:54) 1

(b) 1 (cid:54) α(1−x)
(α+β)x

Figure A.19: Two illustrations of two quadratic functions of λ having,
at most, one intersection over the range 0 < λ < 1. For ﬁxed x, this
geometric fact implies L(x, λ; α, β, γ, δ) is unimodal over any vertical
line in R such that x (cid:54) 1
2 .

the likelihood is maximum. And, the likelihood is monotonic
on either side of this maximum along the vertical line.

L(x, λ; α, β, γ, δ) is also unimodal along the 45◦ diagonal
(i.e. when x = λ). Because it has only one non-trivial station-
ary point21, and this must be a maximum since the likelihood is
non-negative with value 0 at the endpoints of the diagonal.

(a) From likelihood with a successful
1st execution

(b) From likelihood with a failed 1st
execution

Figure A.20: Two illustrations of quadratic and linear functions of x
having, at most, one intersection over the range 0 < x < 1
2 . For ﬁxed
λ, this geometric fact implies L(x, λ; α, β, γ, δ) is unimodal over any
horizontal line in R.

Analogously, L(x, λ; α, β, γ, δ) is unimodal along any hori-
zontal line within R, since it has (at most) one stationary point
at which it attains a maximum. The stationary point solves
∂x L(x, λ; α, β, γ, δ) = 0 non-trivially. Equivalently, the station-
∂
ary point satisﬁes the leftmost intersection between a straight
line and a quadratic function in x (see Fig. A.20). This left-
most intersection must occur to the left of x = 1
2−λ , ensuring
that the stationary point lies in R. And, the fact that the line lies
above the quadratic before this intersection, and then below the
quadratic immediately after, ensures that, as x increases from 0,

21This stationary point is located at either x =

α+γ
1+α+γ+β+δ ,
depending on whether executions begin with a failure or success respectively.

1+α+γ+β+δ or x =

1+α+γ

and “closer” are in terms of the Klotz likelihood’s gradients.

(a) A successful 1st execution

(b) A failed 1st execution

Figure A.22: Examples of locations in R (indicated by grey circles) at
which local and global maxima of the Klotz likelihood occur. Here,
α, β, γ, δ (cid:62) 1.

That is, given any F ∈ D(cid:48), we can reassign the probabilities
{Mi} that F allocates to points in R, to new points suggested
by the likelihood’s gradients – resulting in a new prior with a
smaller objective function value. Such reassignments can be
carried out indeﬁnitely, creating a sequence of priors with an as-
sociated, monotonically decreasing sequence of objective func-
tion values. And the completeness of the real numbers guaran-
tees that this sequence of objective function values converge22.
Being discrete distributions, it is also clear that these reassigned
priors, themselves, converge to some limiting discrete distribu-
tion. Examples of limiting distributions converged to in this
manner are illustrated in Fig. A.24. The points in each subﬁg-
ure indicated by black dots are the limits of the sequences of
new points chosen for reassignments – so-called limit points.

stage 6) So, the limiting distributions assign probabilities
only to certain limit points of the 7 R-subsets. The exact values
of the probabilities will depend on which initial prior F (with its
probabilities {Mi}) was chosen to create the “reassigned” priors
sequence. To determine those values for the “Mi”s that ensure
the sequence of objective function values converges to the inﬁ-
mum, one can systematically allocate probability masses to the
limit points. We will now illustrate this, and show how the pri-
ors (when pl = 0) in Fig.s A.25a, A.25b, A.26a, A.26b, A.27a,
A.27b and A.28 can be obtained from the limiting distribution
forms in Fig. A.24. All of the priors in Fig.s A.25 – A.28 (when
pl > 0) are similarly obtained.

For example, consider the limit points in Fig.A.24b, for the
case when φ1 (cid:62) θ and no failures are observed. Focus on the
subset x (cid:54) (cid:15) and recall the requirement P(X (cid:54) (cid:15)) = θ. To be
pessimistic, we must allocate probability θ to those limit points
within this subset at which the likelihood is smallest. This is
the limit point ((cid:15), 0). And, since P(X (cid:54) Λ) = φ1 (cid:62) θ, all
of the θ probability can be allocated to this limit point “from
below” the 45◦ diagonal and “from the left” of the line x = (cid:15)
(see Fig. A.23a). Consequently, because P(X (cid:54) (cid:15)) = θ, no
more probability can be allocated to any other limit points in
x (cid:54) (cid:15).

22Note that the objective function is a probability, and is therefore bounded.

24

(a) For x (cid:54) (cid:15), assign θ to limit
point where likelihood is smallest, i.e.
((cid:15), 0).

(b) Assign φ2 to limit point where x (cid:62)
b, i.e. (b, 1).

(c) Assign φ1 − θ to limit point where
x (cid:62) b, i.e. (b, b).

(d) Assign 1 − φ1 − φ2 to limit point on
diagonal where x (cid:62) b, i.e. (b, b).

Figure A.23: A systematic allocation of probabilities to limit points, that
demonstrates how Fig. A.28a is obtained from Fig.A.24b.

Now we need to assign probability 1 − θ to the remaining
limit points in R. There are two alternative limit points above
the diagonal where we may assign the φ2 probability. Assigning
to the point (b, 1) gives more pessimistic results than assigning
to (b, b). We can see this by sharing the φ2 probability between
the two points, and noting that the objective function monotoni-
cally decreases as the amount of φ2 allocated to (b, 1) increases.
In effect, all of φ2 should be allocated to any sequence of points
that approximate (b, 1) arbitrarily-well, “from the right” of the
line x = b. This justiﬁes Fig. A.23b. Similar reasoning shows
that allocating probability φ1 − θ to the point (b, b), “from the
right” of x = b, is more pessimistic than allocating it to (b, 0)
“from the left”. Thus justifying Fig. A.23c. Note that these allo-
cations are possible and do not violate the constraints, because
1 − φ1 − φ2 (cid:62) 0 and φ1 (cid:62) θ imply 0 (cid:54) φ1 − θ + φ2 (cid:54) 1 − θ.

Finally, using similar “approximation”-based reasoning to
how φ2 and φ1 − θ were allocated, we must assign the remaining
probability 1 − φ1 − φ2 to the point (b, b). Via any sequence of
points that approximate (b, b) arbitrarily-well “from the right”,
along the diagonal (see Fig. A.23d).

Note that probabilities were assigned to limit points that lie
along the line x = b, but only by assigning the probabilities
to points that approximate these limit points “from the right”
of the line x = b. Consequently, our ﬁnal limiting distribution
gives the value of the inﬁmum in the optimisation problem, but
only by computing “P(X < b | . . .)” for this distribution, and
not by computing “P(X (cid:54) b | . . .)”.

Using similar arguments to allocate probabilities to limit

(a) No consecutive failures (so γ = 0 and α, β, δ (cid:62) 1)

(b) No failures (so α, γ, δ = 0)

(c) No restrictions on failures (so α, β, γ, δ (cid:62) 1)

Figure A.24: Examples of 3 limiting distributions for sequences of prior distributions (in D(cid:48)) that give progressively smaller posterior conﬁdence
in the failure-rate bound b. These distributions must allocate mass only at certain limit points of each R-subset, as indicated by the black circles.
Some relevant stationary points in R are also indicated as grey circles.

largest possible value for E[L(X, 1; n, 0, 0)] as (1 − φ1 − φ2)(1 −
pl)n; ii) if instead θ (cid:54) 1 − φ1 − φ2, then the largest amount of
probability mass that the prior can assign to (pl, pl) is θ, while
the remaining 1 − φ1 − φ2 − θ mass must be assigned to the
limit point of the range x > (cid:15) (along the diagonal) where the
likelihood is largest – the limit point ((cid:15), (cid:15)).
In this case, the
prior must be the limit of a sequence of priors that re-assign the
remaining mass via a sequence of points that converge to ((cid:15), (cid:15))
from the right. The largest value of E[L(X, 1; n, 0, 0)] in this
case is thus θ(1 − pl)n + (1 − φ1 − φ2)(1 − (cid:15))n.

Consequently, the priors that solve PK5 – i.e. the feasible
priors in theorem 4 – must allocate probability along the diag-
onal in one of the two ways just outlined. In particular, from
among those priors that allocate all of the 1 − φ1 − φ2 mass to
the point (pl, pl), the methods of Appendix A justify the prior
(cid:4)
in Fig. 13a as a solution of theorem 4 .

points, all of the remaining worst-case distributions in Fig.s A.25
– A.28 are constructed from limit points analogous to those in
(cid:4)
Fig. A.24.

Remarks : with very few modiﬁcations, the foregoing argu-
ments can be used to derive worst-case prior distributions sub-
ject to the additional constraint of PK1, i.e. P(X (cid:62) pl) = 1.
Such priors solve the optimisation problem in Theorem 3. In-
deed, after observing n executions of a system (which include
some consecutive, failed executions), ﬁgure A.25 illustrates 2
groups of priors (4 priors in each group) that give the smallest
posterior conﬁdence in the system’s unknown failure-rate being
no worse than the bound b. These solutions are subject to PKs
1, 2, 3 and 4.

Appendix B. Proof of Theorem 4

We derive the prior distribution in Fig. 13a that solves the
optimisation problem in Theorem 4. Analogous steps can be
used to derive the prior in Fig. 13b which solves Theorem 5.

Theorem. The optimisation problem

P( X (cid:54) b | n executions without failure)

inf
D

s.t. PK1, PK2, PK3, PK4, PK5

has the prior distribution in Fig. 13a as one of its solutions,
since P( X < b | n executions without failure) from this prior
equals the inﬁmum.

Proof. For the prior distributions that solve PK5, the size of

P(n independent failure-free executions) = E[L(X, 1; n, 0, 0)]

is made as big as possible (for all n (cid:62) 0) by assigning as much
probability mass as possible to locations along the diagonal in
R where the Klotz likelihood is largest. The likelihood is largest
at (pl, pl) and monotonically decreases to 0 at (1, 1). Thus, i) if
θ (cid:62) 1 − φ1 − φ2 then the prior assigns all of the mass along the
diagonal (i.e. 1 − φ1 − φ2) to the location (pl, pl). This gives the

25

(a) φ2 (cid:62) 1 − θ

(b) φ2 (cid:54) 1 − θ and φ1 (cid:54) θ

(a) φ1 (cid:54) 1 − θ and φ2 (cid:54) θ

(b) φ1 (cid:62) 1 − θ

(c) φ2 (cid:62) 1 − θ

(d) φ2 (cid:54) 1 − θ and φ1 (cid:54) θ

(c) φ1 (cid:54) 1 − θ and φ2 (cid:54) θ

(d) φ1 (cid:62) 1 − θ

L(pl, pl; α, . . .) (cid:54) L((cid:15), (cid:15); α, . . .)

(e)
and φ2 (cid:62) 1 − θ

(f) L(pl, pl; α, . . .) (cid:54) L((cid:15), (cid:15); α, . . .)
and φ1 (cid:54) θ and φ2 (cid:54) 1 − θ

L(pl, pl; α, . . .) (cid:54) L((cid:15), (cid:15); α, . . .)

(e)
and φ1 (cid:54) 1 − θ and φ2 (cid:54) θ

(f) L(pl, pl; α, . . .) (cid:54) L((cid:15), (cid:15); α, . . .)
and φ1 (cid:62) 1 − θ

(g) L(pl, pl; α, . . .) (cid:62) L((cid:15), (cid:15); α, . . .)
and φ2 (cid:62) 1 − θ

(h) L(pl, pl; α, . . .) (cid:62) L((cid:15), (cid:15); α, . . .)
and φ1 (cid:54) θ and φ2 (cid:54) 1 − θ

Figure A.25: Worst case prior distributions that solve the optimisation problem
in Theorem 3 when consecutive failures are observed (i.e. r > 0). It’s important
to note the following: the precise locations of the “black dots” for each such
distribution are determined by 1) the values of α, β, γ and δ, 2) whether the ﬁrst
execution is a success or failure, and 3) the indicated parameter ranges in each
subﬁgure. The location (x∗, λ∗) of the global maximum for the Klotz likelihood
is indicated by the grey circle. The 4 priors, illustrated in subﬁgures A.25a,
A.25c, A.25e and A.25g, are solutions when φ2 (cid:62) 1 − θ. While the priors
in A.25b, A.25d, A.25f and A.25h solve the problem when φ2 (cid:54) 1 − θ and
φ1 (cid:54) θ. These solutions assume α, β, γ, δ > 0.

(g) L(pl, pl; α, . . .) (cid:62) L((cid:15), (cid:15); α, . . .)
and φ1 (cid:54) 1 − θ and φ2 (cid:54) θ

(h) L(pl, pl; α, . . .) (cid:62) L((cid:15), (cid:15); α, . . .)
and φ1 (cid:62) 1 − θ

Figure A.26: Worst case prior distributions that solve the optimisation problem
in Theorem 3 when failures are observed, without any consecutive failures (i.e.
r = 0). Each distribution’s support is determined by α, β, γ, δ, and whether the
ﬁrst execution succeeds or fails. The location (x∗, λ∗) of the global maximum
for the Klotz likelihood is indicated by the grey circle. The 4 priors, illustrated
in subﬁgures A.26a, A.26c, A.26e and A.26g, are solutions when φ1 (cid:54) 1 − θ
and φ1 (cid:54) θ. While the priors in A.26b, A.26d, A.26f and A.26h solve the
problem when φ1 (cid:62) 1 − θ. These solutions assume α, β, γ, δ > 0.

26

(a) φ1 (cid:62) θ and r > 0

(b) φ2 (cid:62) θ and r = 0

(c) φ1 (cid:62) θ and r > 0

(d) φ2 (cid:62) θ and r = 0

(a) φ1 (cid:62) θ

(b) φ2 (cid:62) 1 − θ

(c) φ1 (cid:54) θ and φ2 (cid:54) 1 − θ

Figure A.28: For executions with no failures, these worst-case prior
distributions solve the optimisation problem in Theorem 6. These pri-
ors are relevant for the ranges of parameter values indicated in each
subﬁgure. The support of each distribution is determined by β.

L(pl, pl; α, . . .) (cid:54) L((cid:15), (cid:15); α, . . .)

(e)
and φ1 (cid:62) θ and r > 0

(f) L(pl, pl; α, . . .) (cid:54) L((cid:15), (cid:15); α, . . .)
and φ2 (cid:62) θ and r = 0

(g) L(pl, pl; α, . . .) (cid:62) L((cid:15), (cid:15); α, . . .)
and φ1 (cid:62) θ and r > 0

(h) L(pl, pl; α, . . .) (cid:62) L((cid:15), (cid:15); α, . . .)
and φ2 (cid:62) θ and r = 0

Figure A.27: Worst case prior distributions that solve the optimisation problem
in Theorem 3 when failures are observed, giving 0 posterior conﬁdence. Each
distribution’s support is determined by α, β, γ, δ, and whether the ﬁrst execution
succeeds or fails. The location (x∗, λ∗) of the global maximum for the Klotz
likelihood is indicated by the grey circle. The 4 priors, illustrated in subﬁgures
A.27a, A.27c, A.27e and A.27g, are solutions when φ1 (cid:62) θ and r > 0. While
the priors in A.27b, A.27d, A.27f and A.27h solve the problem when φ2 (cid:62) θ
and r > 0. These solutions assume α, β, γ, δ > 0.

27

