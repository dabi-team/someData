2
2
0
2

p
e
S
0
1

]
E
M

.
t
a
t
s
[

1
v
0
7
6
4
0
.
9
0
2
2
:
v
i
X
r
a

Covariance–based rational approximations of
fractional SPDEs for computationally
eﬃcient Bayesian inference

Zhen Xiong, Alexandre B. Simas, and David Bolin
Computer, Electrical and Mathematical Sciences and Engineering
Division, King Abdullah University of Science and Technology
Thuwal 23955-6900, Saudi Arabia

September 13, 2022

Abstract

The stochastic partial diﬀerential equation (SPDE) approach is widely used for
modeling large spatial datasets. It is based on representing a Gaussian random ﬁeld
u on Rd as the solution of an elliptic SPDE Lβu = W where L is a second-order
diﬀerential operator, 2β ∈ N is a positive parameter that controls the smoothness
of u and W is Gaussian white noise. A few approaches have been suggested in the
literature to extend the approach to allow for any smoothness parameter satisfying
β > d/4. Even though those approaches work well for simulating SPDEs with general
smoothness, they are less suitable for Bayesian inference since they do not provide
approximations which are Gaussian Markov random ﬁelds (GMRFs) as in the orig-
inal SPDE approach. We address this issue by proposing a new method based on
approximating the covariance operator L−2β of the Gaussian ﬁeld u by a ﬁnite ele-
ment method combined with a rational approximation of the fractional power. This
results in a numerically stable GMRF approximation which can be combined with the
integrated nested Laplace approximation (INLA) method for fast Bayesian inference.
A rigorous convergence analysis of the method is performed and the accuracy of the
method is investigated with simulated data. Finally, we illustrate the approach and
corresponding implementation in the R package rSPDE via an application to precip-
itation data which is analyzed by combining the rSPDE package with the R-INLA
software for full Bayesian inference.

Keywords: Gaussian process, Gaussian Markov random ﬁeld, SPDE, R-INLA, spatial
statistics, latent Gaussian model

1

 
 
 
 
 
 
1

Introduction

Handling many observations from a Gaussian random ﬁeld in spatial statistics can be
challenging since the related computational tasks involve factorizations of large covariance
matrices which are usually dense. This is often referred to as the “big n problem” (Banerjee
et al., 2015), and various approaches have been suggested to handle the computational
issues (see, e.g., Heaton et al., 2019, for a recent comparison). One of the most widely used
methods is the “SPDE approach” by Lindgren et al. (2011). This is based on the fact that
a centered Gaussian random ﬁeld u on D = Rd with a Mat´ern covariance function (Mat´ern,
1960),

(cid:37)(h) =

σ2
2ν−1Γ(ν)

(κ|h|)νKν(κ|h|),

(1)

with range parameter κ > 0, variance σ2, and smoothness parameter ν > 0 can be repre-
sented as a solution to the stochastic partial diﬀerential equation (SPDE)

(κ2 − ∆)β(τ u) = W in D.

(2)

Here, Γ(·) is the Gamma function, Kν is a modiﬁed Bessel function of the second kind,
∆ is the Laplace operator, and W is Gaussian white noise. For the parameters, we have
τ 2 = Γ(ν)/(σ2κ2ν(4π)d/2Γ(ν +d/2)) and the fractional power β is related to the smoothness
parameter ν via the relation 2β = ν + d/2 (Whittle, 1963). Lindgren et al. (2011) used
this representation to construct computationally eﬃcient Gaussian Markov Random Field
(GMRF) approximations of Gaussian Mat´ern ﬁelds by considering the SPDE on a bounded
domain D, restricting the smoothness to 2β ∈ N, and then performing a ﬁnite element
method (FEM) discretization of the SPDE.

The SPDE approach has become widely used in applications, and has initiated a great
number of extensions and generalizations (Lindgren et al., 2022). The reason for this is not
only the computational beneﬁts, but also that it provides a ﬂexible framework for deﬁning
more sophisticated models for spatial data. It, for example, facilitates the construction of
non-stationary Gaussian random ﬁelds by allowing the parameters κ and τ to be spatially
varying (Lindgren et al., 2011; Fuglstad et al., 2015), and allows for the construction of
Mat´ern-like random ﬁelds on more general manifolds by deﬁning such ﬁelds via the SPDE
(2) posed on the manifold (Lindgren et al., 2011; Bolin and Lindgren, 2011).

One main criticism of the SPDE approach is the requirement 2β ∈ N, which restricts
the possible values of the corresponding smoothness parameter ν of the Mat´ern covariance
function. Given the importance of ν when performing prediction, as shown by Stein (1999)
and Bolin and Kirchner (2022), several methods for removing the restriction of 2β ∈ N have
been proposed. Lindgren et al. (2011, Author’s response) proposed to construct a GMRF
approximation by approximating the spectrum of a Gaussian Mat´ern ﬁeld by a spectrum
that is a reciprocal of a polynomial. This method is applicable for stationary models but
it can not be applied to non-stationary models, and it has a ﬁxed accuracy which may
not be suﬃcient for certain applications. Bolin et al. (2020) proposed combining the FEM
approximation of Lindgren et al. (2011) with a quadrature approximation of the fractional
operator to obtain a numerical method that works for any β ∈ (0, 1) and can be made
arbitrarily accurate. That work also provided a theoretical convergence analysis of the

2

method, which was later extended in Bolin et al. (2018) and Herrmann et al. (2020). Bolin
and Kirchner (2020) later proposed a diﬀerent type of approximation referred to as the
rational SPDE approach, which works for any β > d/4 and has a lower computational cost.
Even though the methods that work for non-stationary models with general smoothness
are computationally eﬃcient, they are much less used than the standard SPDE approach
for statistical applications. The reason for this is that non-fractional SPDE models work
in combination with the integrated nested Laplace approximation (INLA) method (Rue
et al., 2009) and are implemented in the widely used R-INLA software (Lindgren and Rue,
2015), which is a package in R (R Core Team, 2022). This software facilitates including
SPDE-based models in general Bayesian latent Gaussian models, and the great majority
of all applications of the SPDE approach have been done via this software.

Unfortunately, the methods of Bolin et al. (2020) and Bolin and Kirchner (2020) provide
approximations which are not compatible with the R-INLA software. The main goal of this
work is to solve this problem by proposing an alternative rational approximation method
that can be implemented in R-INLA. The main idea is to approximate the covariance op-
erator of the random ﬁeld directly, instead of ﬁrst approximating the solution u and then
deriving the corresponding covariance operator. This provides an approximation suitable
for R-INLA, which is more numerically stable than that of the original rational SPDE ap-
proach. The proposed method is implemented in the R package rSPDE (Bolin and Simas,
2022), which is available on CRAN and has an interface to R-INLA. Using the package, we
show that the proposed method facilitates full Bayesian inference of all model parameters,
including β, for latent Gaussian models based on fractional SPDEs.

The outline of the paper is as follows.

In Section 2, we introduce the generalized
Whittle–Mat´ern ﬁelds, which contain most of the previously proposed non-stationary SPDE-
based Gaussian random ﬁelds as special cases, and for which our proposed method is ap-
plicable.
In that section, we also provide the details of the FEM approximations that
are used. The new covariance-based rational approximation is introduced in Section 3,
where we also prove that it provides an approximation of the covariance function of the
generalized Whittle–Mat´ern ﬁeld with an explicit rate of convergence in the L2-norm. In
Section 4, we show that the covariance-based rational approximation can be represented as
a GMRF, and illustrate how this can be used for statistical inference. Some of the details
of the rSPDE implementation are discussed in Section 5, and a comparison in terms of the
accuracy of approximating covariance function by our method and some other methods is
provided in Section 6. An application to modeling of precipitation data is presented in
Section 7 and the article concludes with a discussion in Section 8. Technical details and
proofs are given in three appendices of the manuscript.

2 Preliminaries

In this section we introduce the class of fractional-order SPDEs we are interested in as
well as their FEM approximations. More precisely, in Section 2.1 we provide the model
assumptions, whereas we in Section 2.2 introduce the FEM approximations and study their
convergence.

3

Let us begin by introducing some notation that will be needed later on. Given a bounded
domain D ⊂ Rd, d ∈ {1, 2, 3}, we denote by L2(D) the Lebesgue space of square-integrable
real-valued functions endowed with the inner product (φ, ψ)L2(D) = (cid:82)
D φ(x)ψ(x)dx. We
denote the Sobolev space of order k by H k(D):

H k(D) = (cid:8)w ∈ L2(D) : Dγw ∈ L2(D), ∀γ ∈ Nd, |γ| ≤ k(cid:9) ,

where we are using the multiindex notation for the diﬀerential operator Dγ, and (·, ·)H k(D)
is the Sobolev inner product:

(u, v)H k(D) =

(cid:88)

γ∈Nd:|γ|≤k

(Dγu, Dγv)L2(D).

We denote by H 1
c (D) is the set of inﬁnitely
diﬀerentiable functions with compact support. See Appendix A for further details on the
notation.

c (D) in H 1(D), where C ∞

0 (D) the closure of C ∞

2.1 Model assumptions

We are interested in the class of Gaussian random ﬁelds on D that can be represented as
solutions to SPDEs of the form

Lβ(τ u) = W in D,

(3)

where Lβ is a fractional power (in the spectral sense) of a second-order elliptic diﬀerential
operator L which determines the covariance structure of u, τ > 0 is a constant parameter,
and W is Gaussian white noise on L2(D).

We have the following assumption on the domain:

Assumption 1. The domain D is an open, bounded, convex polytope with closure D.

Under Assumption 1, we may deﬁne H 2

N (D) = {w ∈ H 2(D) : ∂u/∂ν = 0 on ∂D},
where ν is the outward unit normal vector to ∂D. Indeed, the expression ∂u/∂ν = 0 on ∂D
makes sense since the trace of Du is well-deﬁned in this case (see, e.g., Evans and Gariepy,
2015, Theorem 4.6). Let us now describe the assumptions on the diﬀerential operator L:

Assumption 2. The operator L is given in divergence form by Lu = −∇ · (H∇u) + κ2u,
and is equipped either with homogeneous Dirichlet or Neumann boundary conditions. Fur-
thermore, the function H : D → Rd×d is symmetric, Lipschitz continuous and uniformly
positive deﬁnite, and κ : D → R is an essentially bounded function. Under Neumann
boundary conditions, we additionally require that ess inf x∈D κ(x) ≥ κ0 > 0.

The SPDE (3) under Assumptions 1 and 2 deﬁnes a class of models that has previously
been considered by Bolin et al. (2020); Cox and Kirchner (2020); Herrmann et al. (2020);
It
Bolin and Kirchner (2020) and is referred to as generalized Whittle–Mat´ern ﬁelds.
contains many previously proposed non-stationary SPDE-based spatial Gaussian random
ﬁeld models as special cases, such as those by Lindgren et al. (2011); Fuglstad et al. (2015,

4

2019); Hildeman et al. (2021), and the method that we later introduce thus also applies to
those models and their fractional extensions.

In the case of Dirichlet boundary conditions, deﬁne the space V = H 1

0 (D) ⊂ L2(D),
and in the case of Neumann boundary conditions let V = H 1(D) ⊂ L2(D). Then, under
Assumptions 1 and 2, L induces the following continuous and coercive bilinear form on V ,

aL(v, u) = (H∇u, ∇v)L2(D) + (κ2u, v)L2(D),

u, v ∈ V.

Remark 1. Under Assumptions 1 and 2, if f ∈ L2(D), then there exists a unique solution u
of Lu = f and the operator L is H 2(D)-regular, that is, u ∈ H 2(D)∩H 1
0 (D) under Dirichlet
boundary conditions, whereas under Neumann boundary conditions, we have u ∈ H 2
N (D).
See, for instance, (Grisvard, 2011, Theorem 3.2.1.2) for Dirichlet boundary conditions or
(Grisvard, 2011, Theorem 3.2.1.3) for Neumann boundary conditions.

By remark 1, speciﬁcally by the existence and uniqueness of the solution to the equation
Lu = f , we can deﬁne the inverse operator L−1 : L2(D) → L2(D). By Rellich-Kondrachov
theorem (Evans and Gariepy, 2015, Theorem 4.11), L−1 is a compact operator, and observe
that L−1 is self-adjoint. Hence, by the spectral theorem for self-adjoint and compact
operators, there exists an orthonormal basis {ej}j∈N in L2(D) formed by eigenvectors of L
whose eigenvalues {λj}j∈N are non-negative and can be arranged in a non-decreasing order.

Remark 2. Under Assumptions 1 and 2, the operator L satisﬁes the Weyl’s law, that is,
there exist c, C > 0 such that for every j ∈ N,

cj2/d ≤ λj ≤ Cj2/d.

See, for instance, Davies (1995, Theorem 6.3.1) for the Dirichlet case. For the Neumann
case, we have, by, for instance, Fedosov (1963, 1964), that the Weyl’s law holds for the
case in which H is a constant diagonal matrix, in particular, it holds for the Neumann
Laplacian. The result for general H satisfying Assumption 2 is a direct consequence of the
Weyl’s law for the Neumann Laplacian together with Proposition 4 in Appendix A together
with min-max principle.

Our goal is to obtain approximations of the covariance operator L−2β of the Gaussian

random ﬁeld u which solves equation (3). Let

(cid:37)β(x, y) =

∞
(cid:88)

j=1

λ−2β
j

ej(x)ej(y).

Then, one can readily check that the covariance operator L−2β is a kernel operator, with
kernel (cid:37)β(·, ·).

It is well-known that there exists a centered square-integrable Gaussian random ﬁeld
u that solves (3) if, and only if, its covariance operator, L−2β, has ﬁnite trace (Lototsky
and Rozovsky, 2017, Theorem 3.2.5). Under Assumptions 1 and 2, one can use Weyl’s law
(Remark 2) to show that L−2β has ﬁnite trace if, and only if, β > d/4. Hence, if β > d/4,
then u is a centered square-integrable Gaussian random ﬁeld with covariance function

where the above equality holds for a.e. (x, y) ∈ D × D.

(cid:37)β(x, y) = E[u(x)u(y)],

5

2.2 Finite element approximation

The goal is now to provide a convergence analysis for FEM approximations of the covariance
operator L−2β. Let us start by describing the setup we will use.

Assumption 3. Let Vh ⊂ V be a ﬁnite element space that is spanned by a set of continuous
j=1, with nh ∈ N, deﬁned with respect to a triangulation
piecewise linear basis functions {ϕj}nh
Th of the closure of the domain D indexed by the mesh width h := maxT ∈Th hT , where
hT := diam(T ) is the diameter of the element T ∈ Th. We assume that the family (Th)h∈(0,1)
of triangulations inducing the ﬁnite-dimensional subspaces (Vh)h∈(0,1) of V is quasi-uniform,
that is, there exist constants K1, K2 > 0 such that ρT ≥ K1hT and hT ≥ K2h for all T ∈ Th
and h ∈ (0, 1). Here ρT > 0 is the radius of the largest ball inscribed in T ∈ Th.

We are now in a position to describe the FEM discretization of the model (3). Let

Lh : Vh → Vh be deﬁned in terms of the bilinear form aL as its restriction to Vh × Vh:

(Lhφh, ψh)L2(D) = aL(φh, ψh), φh, ψh ∈ Vh.

Note that Lh is a positive-deﬁnite, symmetric, linear operator on the ﬁnite-dimensional
space Vh. Hence, we may arrange the eigenvalues of Lh as 0 < λ1,h ≤ λ2,h ≤ · · · ≤ λnh,h,
with corresponding eigenvectors {ej,h}nh
j=1 which are orthonormal in L2(D). Let Wh denote
Gaussian white noise on Vh. That is, there exist independent standard Gaussian random
variables ξ1, . . . , ξnh such that Wh = (cid:80)nh
j=1 ξjej,h. Then, we refer to the following SPDE on
Vh as the discrete model of (3):

Lβ
Let uh be a solution of (4), then the covariance operator of uh is given by L−2β

huh = Wh.

h

(4)

, and

(cid:37)β
h(x, y) =

nh(cid:88)

j=1

λ−2β
j,h ej,h(x)ej,h(y),

for a.e. (x, y) ∈ D × D,

is the corresponding covariance function. We have the following result regarding the con-
vergence of the ﬁnite element approximation (cid:37)β
h to the exact covariance function (cid:37)β in the
(cid:82)
L2(D × D)-norm deﬁned by (cid:107)f (cid:107)2
D f (x, y)2dxdy. The proof is postponed to
Appendix A.

L2(D×D) = (cid:82)

D

Proposition 1. Under Assumptions 1, 2 and 3, for every β > d/4 and every ε > 0, we
have

(cid:107)(cid:37)β − (cid:37)β

h(cid:107)L2(D×D) (cid:46)ε,β,H,κ,D hmin{4β−d/2−ε,2}.

Here, and in the remaining of the paper, the notation A (cid:46)θ1,...,θk B, where k ∈ N, means
that there exists a constant C depending on θ1, . . . , θk (θi, i = 1, . . . , k, can be a parameter,
a function, a domain, etc.) such that

A ≤ CB.

6

Remark 3. Cox and Kirchner (2020, Theorem 1) gives a bound for (cid:107)(cid:37)β −(cid:37)β
h(cid:107)L2(D×D) in the
case of homogeneous Dirichlet boundary conditions. However, they do not provide a bound
if we impose homogeneous Neumann boundary conditions, whereas Proposition 1 works for
both homogeneous Neumann and Dirichlet boundary conditions. As far as we know, this is
a new result. The key step in the proof is to obtain an analogous result to Cox and Kirchner
(2020, Lemma 2), which is given by Proposition 4 in Appendix A.

3 Rational approximation

Having introduced the FEM approximation, we are now ready to deﬁne the complete
approximation of the covariance operator of the generalized Whittle–Mat´ern ﬁelds. The
approximation is obtained by combining a rational approximation of the fractional power of
the covariance operator with the FEM approximation. We begin by introducing the method
and then providing a theoretical justiﬁcation by showing an explicit rate of convergence of
the approximate covariance function to the correct one in the L2(D × D)-norm.

In Bolin and Kirchner (2020), the authors obtained an approximation of the solution
to (3), which also implicitly deﬁnes an approximation of the corresponding covariance
operator. However, as we have previously mentioned, this results in an approximation that
is not implementable in R-INLA. Also, for statistical applications there is usually no need
to have an approximation of the solution itself, since only the corresponding distribution
matters for inference. With this in mind, we propose to directly approximate the covariance
operator L−2β. To this end, we ﬁrst split L−2β
, where {x} = x − (cid:98)x(cid:99) is the
h
fractional part of x. Then, we approximate L−{2β}
with a rational approximation. This
yields an approximation

h = L−{2β}

L−(cid:98)2β(cid:99)
h

h

h,m := L−(cid:98)2β(cid:99)
h ) = (cid:80)m
Here p(L−1
rational approximation of order m of the real-valued function f (x) = x{2β}. That is,

h ≈ L−2β
L−2β

h ) = (cid:80)m

j=0 bjLm−j

i=0 aiLm−i

h )q(L−1

and q(L−1

h )−1.

p(L−1

are polynomials obtained from a

(5)

h

h

h

x{2β} ≈

(cid:80)m
(cid:80)m

i=0 aixi
i=0 bixi .

nh,h, λ−1

i=0 and {bi}m

i=0, we approximate the function f (x) = x{2β} on
Speciﬁcally, to obtain {ai}m
the interval [λ−1
h . The coeﬃcients are computed
as the best rational approximation in the L∞-norm, which, for example, can be obtained
via the second Remez algorithm (Remez, 1934) or by the recent, and more stable, BRASIL
algorithm (Hofreither, 2021).

1,h], which covers the spectrum of L−1

By deﬁning the covariance function

(cid:37)β
h,m(x, y) =

nh(cid:88)

j=1

λ−(cid:98)2β(cid:99)
j,h

p(λ−1

j,h)q(λ−1

j,h)−1ej,h(x)ej,h(y),

for a.e. (x, y) ∈ D,

we have that (cid:37)β
errors when we consider (cid:37)β

h,m is the kernel of the covariance operator L−2β

h,m . There are two sources of
h,m as an approximation of the true covariance function (cid:37)β of the

7

generalized Whittle–Mat´ern ﬁeld: the FEM approximation and the rational approximation.
The following proposition, whose proof is given in Appendix B, shows that we have control
of these two sources of errors via the FEM mesh width h and the order of the rational
approximation m.

Proposition 2. Let β > d/4. Under Assumptions 1, 2 and 3, for every ε > 0 and for
suﬃciently small h, we have:

(cid:107)(cid:37)β

h,m − (cid:37)β(cid:107)L2(D×D) (cid:46)ε,β,H,κ,D hmin{4β−d/2−ε,2} + 12β /∈Nh−d/2e−2π

√

{2β}m.

(6)

Remark 4. To minimize computational cost with respect to m, we can calibrate the ac-
curacy of the rational approximation with the ﬁnite element error. To this end, we choose
m ∈ N such that e−2π
{2β}m ∝ hmin{4β−d/2,2}+d/2. This is enough to ensure that the rate of
convergence in (6) is min{4β − d/2 − ε, 2}.

√

4 GMRF representation

The goal of this section is to obtain a sparse matrix representation of the precision oper-
ator of the covariance-based rational approximation from the previous section. We then
show that this facilitates computationally eﬃcient methods for sampling and likelihood
evaluation.

In the ﬁnite element space Vh, the solution uh in (4) at spatial location s can be
represented as uh(s) = (cid:80)nh
j=1 are stochastic weights and {ϕj}nh
j=1
are the piecewise linear ﬁnite element basis functions. Let u = [u1, ..., unh](cid:62). We will now
show how to represent u as a sum of independent GMRFs, each with a sparse precision
matrix. The key step is to apply a partial fractions decomposition in (5):

j=1 ujϕj(s), where {uj}nh

h,m = L−(cid:98)2β(cid:99)
L−2β

h

(cid:32) m
(cid:88)

i=1

ri(Lh − piIVh)−1 + kIVh

.

(7)

(cid:33)

i=1, {pi}m

Here, {ri}m
i=1 and k are real numbers, and IVh is the identity operator mapping
the ﬁnite element space to itself. Let C be the mass matrix, where the (i, j)th element
is given by C i,j = (ϕi, ϕj)L2(D), and G be the stiﬀness matrix, whose (i, j)th element is
given by Gi,j = (∇ϕi, ∇ϕj)L2(D). Let, also, L be the matrix obtained by the bilinear
form aL(·, ·) induced by the diﬀerential operator L, which has (i, j)th element given by
Li,j = (H∇ϕi, ∇ϕj)L2(D) + (κ2ϕi, ϕj)L2(D). Observe that in the Mat´ern case, that is, when
κ is a constant and H is an identity matrix, we simply have that L = G + κ2C. Then, we
can use (7) to obtain the covariance matrix of u as (see Appendix C for a derivation):

ΣR

u = (L−1C)(cid:98)2β(cid:99)

m
(cid:88)

i=1

ri(L − piC)−1 + K, with K = k(L−1C)(cid:98)2β(cid:99)−1L−1.

(8)

Since we have the same degree for numerator and denominator in the rational approx-
imation, we can use the BRASIL algorithm (Hofreither, 2021) to compute the coeﬃcients

8

i=0, {pi}m

i=0 and {bi}m

i=0 in (5) and thus the coeﬃcients {ri}m

{ai}m
i=0 and k in (7). Another
option, commonly used in practice, is to use a “near best” rational approximation. One
such option, which was used in Bolin and Kirchner (2020), and which is also implemented in
the rSPDE package, is the Clenshaw–Lord Chebyshev–Pad´e algorithm (Baker and Graves-
Morris, 1996). Also, observe that the interval [λ−1
1,h] where one should compute the
rational approximation may vary with the parameters κ and H, and that recomputing the
coeﬃcients {ai}m
i=0 for diﬀerent values of these parameters is not practical for
implementations. To avoid this, recall from Assumption 2 that κ2
0 is a lower bound for
the eigenvalues of L in the case of Neumann boundary conditions and that λ1 ≤ λ1,h (see
Proposition 3 in Appendix A). We can, then, re-scale the operator Lh as Lh/κ2
0 so that we
can replace the interval [λ−1
1,h] by [δ, 1], where, ideally, δ is chosen in such way that
δ ≤ κ2
0/λnh,h for all considered mesh sizes h. We have implemented the choices δ = 0 and
δ = 10−(5+m)/2, where m is the order of rational approximation. However, the diﬀerence in
accuracy with respect to approximating the covariance function is negligible between the
two choices.

i=0 and {bi}m

nh,h, λ−1

nh,h, λ−1

For these options, we veriﬁed empirically that if fβ(x) = x{2β}, {2β} = 2β − (cid:98)2β(cid:99), and
(cid:98)fβ,m is the rational approximation of fβ where the numerator and denominator have same
degree m, then

(cid:98)fβ,m = x(cid:98)2β(cid:99)

ri(x − pi)−1 + k,

m
(cid:88)

j=1

i=1 are negative real numbers and {ri}m

where {pi}m
i=1 and k are positive real numbers.
This, together with the fact that the BRASIL algorithm is only implemented for rational
approximations with numerator and denominator having the same degree, are the main
reasons we chose to consider the numerator and denominator having the same degree m.
Bolin and Kirchner (2020) instead considered a rational approximation where the numerator
has degree m and the denominator has degree m + 1. However, with this choice the partial
fractions would not yield a decomposition into positive-deﬁnite operators.

Since {pi}m

i=1 are negative real numbers and {ri}m

i=1 and k are positive real numbers in
our case, we have that ri(L−1C)(cid:98)2β(cid:99)(L − piC)−1, for i = 1, ...m, and K are valid covariance
matrices. Thus, u can be expressed as a sum of m + 1 independent random vectors:

u =

m+1
(cid:88)

i=1

xi, where xi ∼ N (0, Q−1

i ), xi = (cid:0)xi1

· · · xinh

(cid:1)(cid:62) .

(9)

Here Qi is the precision matrix of xi, which by (8) is

Qi =

(cid:26) r−1
i (L − piC)(C −1L)(cid:98)2β(cid:99)
K −1

i = 1, ..., m,
i = m + 1.

(10)

Let X = [x(cid:62)

1 , ..., x(cid:62)

m+1](cid:62). Then, the precision matrix of X is the block diagonal matrix



Q1

Q =







 .

Qm+1

. . .

9

(11)

The ﬁnal step in order to obtain a GMRF representation is to use the mass lumping
technique as for the standard SPDE approach (see Lindgren et al., 2011, Appendix C.5).
Thus, the mass matrix C in (10) is replaced by a lumped mass matrix ˜C, where ˜C is a
diagonal matrix with ˜C ii = (cid:80)nh
j=1 C ij, for i = 1, ..., nh. With this adjustment, Q in (11) is
sparse and we thus have obtained a GMRF representation.

The sparsity of Q is essential for computation. For instance, in likelihood-based in-
ference, evaluating the marginal log-likelihood may involve computing |Q| via a sparse
Cholesky decomposition. Further, sparsity of Q also facilitates computationally eﬃcient
sampling of u, and hence of uh in (4). To do so, we simulate each xi, i = 1, ..., m + 1, in
(9) independently and then sum them together. Since {xi}m+1
i=1 are all GMRFs, simulating
them is computationally eﬃcient. We refer the reader to Rue and Held (2005) for further
details on computationally eﬃcient methods for GMRFs.

We conclude this section by illustrating how one can apply the above representation to
a hierarchical model having u, the rational approximation of (3), as a latent ﬁeld. Suppose
that we observe y1, . . . , yn, n ∈ N, where

yi = u(si) + (cid:15)i,

i = 1, ..., n,

(12)

s1, . . . , sn ∈ Rd are spatial locations, and (cid:15)1, . . . , (cid:15)n are independent N (0, σ2) random vari-
ables representing measurement noise.

Let y = [y1, ..., yn](cid:62) and (cid:15)(cid:15)(cid:15) = [(cid:15)1, ..., (cid:15)n](cid:62). Then, (12) can be written in matrix form as
σ2 I n, I n is the n × n identity matrix, and

y = Au + (cid:15)(cid:15)(cid:15), where (cid:15)(cid:15)(cid:15) ∼ N (0, Q−1
A is the projector matrix with elements Aij = ϕj(si).

(cid:15)(cid:15)(cid:15) ), with Q(cid:15)(cid:15)(cid:15) = 1

Writing the model in terms of the FEM weights X in the rational approximation allows
us to equivalently write the model as y = AX + (cid:15)(cid:15)(cid:15) where A is a block matrix of size
n × nh(m + 1) obtained by combining m + 1 copies of A as A = (cid:2)A · · · A(cid:3). Thus, we
have

y|X ∼ N (AX, Q−1
X ∼ N (0, Q−1),

(cid:15)(cid:15)(cid:15) ),

where Q is given in (11). Based on this, standard results for latent Gaussian models of
this type give us that the posterior distribution of X is X|y ∼ N (µµµX|y, Q−1

X|y), where

µµµX|y = Q−1

X|yA

T

Q(cid:15)(cid:15)(cid:15)y and QX|y = A

T

Q(cid:15)(cid:15)(cid:15)A + Q.

Finally, we can obtain the marginal likelihood of y as

(cid:96)(y) ∝ log |Q| + log |Q(cid:15)(cid:15)(cid:15)| − log |QX|y| − µµµT

X|yQµµµX|y − (y − AµµµX|y)T Q(cid:15)(cid:15)(cid:15)(y − AµµµX|y).

5

Implementation and the rSPDE package

The proposed covariance-based rational approximation method has been implemented in
the R package rSPDE. In the following sections, we will use this package to illustrate the
In this section, we give a brief introduction to the rSPDE
performance of the method.

10

package and how it can be used in combination with R-INLA for computationally eﬃcient
Bayesian inference of latent Gaussian models involving the generalized Whittle–Mat´ern
ﬁelds.

The usual workﬂow of ﬁtting standard SPDE models in R-INLA can be divided into six
steps. Namely, constructing the FEM mesh, deﬁning SPDE model, creating a projector
matrix, building the INLA stack, specifying the model formula, and ﬁnally calling the
function inla to ﬁt the model. Details about this can be found in Lindgren and Rue (2015).
To ﬁt a model with a fractional SPDE, this procedure basically remains the same. The
only diﬀerence is that in steps of deﬁning the SPDE model, creating the projector matrix
and building the INLA data stack, we need to use functions from the rSPDE package. These
functions are very similar to the corresponding R-INLA functions in terms of functionality.
For example, a fractional SPDE model can be deﬁned as

model <- rspde.matern(mesh = mesh)

where mesh is the FEM mesh and the default order of the rational approximation is m = 2.
As for the corresponding inla.spde2.matern function that can be used to deﬁne non-
fractional SPDE models in INLA, one can also set priors for κ and τ in rspde.matern.
Further, we can also deﬁne a prior for the smoothness parameter ν or specify a ﬁxed ν so
that a SPDE model with a ﬁxed smoothness parameter can be generated. This feature can
be used, for example, in the case that one already knows what ν is or wants to compare
two diﬀerent models with diﬀerent ν like what we will do in Section 7.

The projector matrix A for a given mesh and observation locations loc is computed as

A <- rspde.make.A(mesh = mesh, loc = loc)

As for the creation of the model, the default order of the rational approximation is m = 2,
which can be changed by the user. The other arguments of the function are the same as
those in the corresponding R-INLA function inla.spde.make.A. In the step of building
INLA stack, usually an index set is needed. The index can be computed with the function
rspde.make.index, which replaces the R-INLA function inla.spde.make.index and has
the same arguments. With these functions, the fractional models can be used as any other
random eﬀect in the R-INLA software.

Besides the INLA-related functions, the rSPDE package also provides various utility
functions. For example, once a fractional SPDE model, model, has been created with
the rspde.matern function, one can simulate from it by calling simulate(model). The
package also implements the marginal log-likelihood from Section 4 as

l <- rSPDE.matern.loglike(model, y, A, sigma.e)

Here, y is the observed data and sigma.e is the standard deviation of the measurement
noise. For further details about the package, we refer to the help texts of the functions and
to the homepage https://davidbolin.github.io/rSPDE.

11

6 Numerical experiments

In this section, we compare the accuracy of our new covariance–based rational approx-
imation with the operator-based method from Bolin and Kirchner (2020), and with the
“parsimonious” method from Lindgren et al. (2011). Since the latter method is imple-
mented in R-INLA, we refer to it as the INLA approximation. We also note that the INLA
method constructs a Markov approximation (see also Bolin and Kirchner, 2020, Section 2),
so it can be viewed as a 0th order rational approximation.

For the comparison, we consider the SPDE model (2) with homogeneous zero Neumann
boundary conditions on the unit square D = [0, 1]2, with τ chosen such that σ2 in the
Mat´ern covariance is one. The reason we consider the square domain, is that we have an
Indeed, we have, from
explicit expression for the covariance function of the solution u.
Khristenko et al. (2019, Eq. (2.13)), that the covariance function of u is given by

(cid:37)β
u (x, y) =

(cid:88)

(cid:104)
(cid:37)((cid:107)x + 2k − y(cid:107)) + (cid:37)((cid:107)(x1 + 2k1 − y1, x2 + 2k2 + y2)(cid:107))

k∈Z2

+ (cid:37)((cid:107)(x1 + 2k1 + y1, x2 + 2k2 − y2)(cid:107)) + (cid:37)((cid:107)x + 2k + y(cid:107))

(13)

(cid:105)
,

where (cid:107) · (cid:107) is the Euclidean norm on R2 and (cid:37)(·) is the Mat´ern covariance function in (1)
with σ = 1 and ν = 2β − 1.

To compare the accuracy of the approximation of the covariance approximations, we
evaluate the true and approximate covariance function on a regular mesh on [0, 1]2 with
N = 100 equally spaced nodes on each axis. We will compare with respect to two norms,
namely, the L2([0, 1]2 × [0, 1]2)-norm and the supremum norm on [0, 1]2 × [0, 1]2. In order
to approximate these norms we ﬁrst need to build some matrices induced by the covariance
operators. First, denote by {si}N 2
i=1 the locations of the mesh nodes. For two continuous
functions f, g : [0, 1]2 × [0, 1]2 → R, let F and G be N 2 × N 2 matrices with corresponding
(i, j)th elements given by F (i, j) = f (si, sj) and G(i, j) = g(si, sj), respectively. The
L2([0, 1]2 × [0, 1]2)-distance between f and g can be can be approximated, on this regular
mesh, by the following quadrature:

(cid:107)f − g(cid:107)L2([0,1]2×[0,1]2) ≈

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
N 4

N 2
(cid:88)

N 2
(cid:88)

i=1

j=1

(f (si, sj) − g(si, sj))2 =

1
N 2 (cid:107)F − G(cid:107)F ,

(14)

where (cid:107) · (cid:107)F stands for the Frobenius norm. Similarly, we can approximate the supremum
distance between f and g by the max-distance on the corresponding matrices:

(cid:107)f − g(cid:107)C([0,1]2×[0,1]2) ≈ max

i,j

|f (si, sj) − g(si, sj)| = (cid:107)F − G(cid:107)max,

(15)

where (cid:107) · (cid:107)max stands for the max norm.

Now, let us deﬁne the matrices associated to the covariance functions of interest. To
this end, ﬁx some smoothness parameter ν > 0, and let β = ν/2 + d/4. We build the
covariance matrix Σβ, of size N 2 × N 2, associated to the true covariance function by
setting its (i, j)th element to be Σβ
u is given in (13). In practice,

u(si, sj), where (cid:37)β

i,j = (cid:37)β

12

Figure 1: Errors in L2([0, 1]2×[0, 1]2)-norm (top) and supremum norm (bottom) for diﬀerent
practical ranges, 0.1 (left), 0.5 (middle) and 1 (right) for diﬀerent values of ν. All methods
use the same FEM mesh, with 100 equally spaced nodes in each direction.

I = Q−1

we truncate the sum in (13) to a suﬃciently large range of k ∈ Z2. Let QI,β be the
precision matrix obtained from INLA’s method of general smoothness, with corresponding
covariance matrix Σβ
I,β. Now, ﬁx some order m for the rational approximation
and let Qm,O,β be the precision matrix from the operator-based rational approximation of
order m. The covariance matrix associated to the operator-based rational approximation
is given by Σβ
m,O,β. Finally, let Qm,C,β be the precision matrix given by (11). The
corresponding covariance matrix is then given by Σβ
, where I is a block
matrix of size N 2 × N 2(m + 1) obtained by combining m + 1 copies of the N 2 × N 2 identity
matrix I N 2 as I = (cid:2)I N 2

C,m = IQ−1

O,m = Q−1

· · · I N 2

m,C,βI

(cid:3)

(cid:62)

For the operator-based and covariance-based rational approximations, we consider the
orders of rational approximation as m = 1, 2, 3, 4. We choose smoothness parameters
ranging from 0.1 to 3.1 with steps of size 0.05. Further, we test three possible values of κ.
These values of κ, say κ1(ν), κ2(ν) and κ3(ν) are chosen in such a way that the practical
range ρ =
8ν/κ is ﬁxed as 0.1, 0.5 and 1, respectively, for all values of ν. The resulting
errors for the diﬀerent methods are shown in Figure 1.

√

We begin by observing that for smoothness parameters ν = 1, 2 or 3, there is no rational

13

ρ = 0.1ρ = 0.5ρ = 10123012301231e-061e-051e-041e-03Error in L2-normρ = 0.1ρ = 0.5ρ = 10123012301230.010.101.00ν (smoothness parameter)Error in Sup-normOrder0 (INLA)1234TypeCovariance-basedOperator-basedapproximation and all the errors come from the FEM approximation. With this in mind,
one should note that for smaller range parameters most of the approximation error comes
from the FEM approximation, thus yielding a small diﬀerence of errors across the diﬀerent
methods. However, for larger ranges, such as, in this case, practical range equal to 1,
the errors have diﬀerent orders of magnitude as the order of the rational approximation
increases, with the errors from the operator-based and covariance-based approximations
of same rational approximation order having approximately the same order of magnitude.
Furthermore, we can observe numerical instabilities of the operator-based approximations
of order 3 and 4 as ν increases for both practical ranges 0.5 and 1, whereas the covariance-
based method is stable for all orders of approximation.

In order to further illustrate the eﬀect of the FEM error on the rational approximation
of the covariance operator we repeated the analysis from above but with a coarser FEM
mesh, consisting of 50 equally spaced nodes on each axis over the domain [0, 1]2. The
results are shown in Figure 2. We now observe that for practical range 0.1, there is no visible
diﬀerence between the covariance-based or operator-based rational approximations of orders
1 to 4, with a very small diﬀerence between the “parsimonious” INLA approximation
and the remaining rational approximations. Further, for practical ranges 0.5 and 1, we
hardly see any diﬀerences between the rational approximations of orders 2, 3 and 4. The
only noticeable diﬀerence being that for large values of ν, the operator-based rational
approximation becomes numerically unstable. On the other hand, it is noteworthy that for
practical ranges 0.5 and 1, there is a signiﬁcant diﬀerence (diﬀerence in orders of magnitude)
between the rational approximations of order 0, 1 and the remaining orders.

To summarize, the results indicate that the covariance-based method generally has a
similar accuracy as the operator-based method, which is higher than the accuracy provided
by INLA’s method. The results also show that the covariance-based method is more nu-
merically stable, especially for larger values of m, the order of the rational approximation.
It is important to remember that the INLA method only provides a ﬁxed approximation
that works in this case of stationary parameters, whereas the other methods are applicable
also for non-stationary models and can be made arbitrarily precise by increasing the order
m. As previously mentioned, the operator-based method is not suitable for inference in
R-INLA, but the covariance-based method is. Thus, in conclusion, the covariance-based
method provides a method that facilitates inference for stationary and non-stationary frac-
tional SPDE-based models in R-INLA, which is also more accurate than the current INLA
method for stationary models.

All methods tested in this section are implemented in the rSPDE package, which was
also the package we used to carry all the numerical experiments. Finally, all plots in this
section, along with several more, for diﬀerent choices of all the parameters involved, can be
found in a shiny (Chang et al., 2021) app available at https://github.com/davidbolin/
rSPDE/tree/devel/shiny_app. The results above were obtained by the Clenshaw–Lord
Chebyshev–Pad´e algorithm with δ = 0 (see Section 4). The shiny app also contains the
results by the BRASIL algorithm and the Clenshaw–Lord Chebyshev–Pad´e algorithm with
δ = 10−(5+m)/2.

14

Figure 2: Errors in L2([0, 1]2×[0, 1]2)-norm (top) and supremum norm (bottom) for diﬀerent
practical ranges, 0.1 (left), 0.5 (middle) and 1 (right) for diﬀerent values of ν. All methods
use the same FEM mesh, with 50 equally spaced nodes in each direction.

7 Application

In this section, we illustrate the use of the covariance-based rational approximation method
through an application to a non-Gaussian spatial data set of precipitation observations. The
analysis is performed using the rSPDE package combined with the R-INLA package, and the
complete code for the analysis can be found in the supplementary materials.

The dataset, available at https://www.image.ucar.edu/Data/US.monthly.met/, con-
tains 11918 stations recording monthly precipitation in millimeters from year 1895 to year
1997 throughout the contiguous United States. These data were previously analyzed by
Fuglstad et al. (2015), who modeled log-transformed observations through a Gaussian ran-
dom ﬁeld. They found non-stationary behavior in the data, which could be handled by
allowing for diﬀerent nugget eﬀects in the east and west part of the region. To simplify

15

ρ = 0.1ρ = 0.5ρ = 10123012301231e-051e-041e-03Error in L2-normρ = 0.1ρ = 0.5ρ = 10123012301230.010.101.00ν (smoothness parameter)Error in Sup-normOrder0 (INLA)1234TypeCovariance-basedOperator-basedFigure 3: This plot shows the US map, the ﬁnite element mesh and the distribution of
stations. The red dots represent the stations where the data comes from.

the analysis, we only use the stations located to the east of 95.865◦W so that it is possible
to consider a stationary model. There are in total 6011 such stations. However, due to
the diﬀerent number of missing values in each year, there are around 3000 to 4000 stations
where data is available for each year. Figure 3 shows all the 5906 stations that reported
data at least for one year between 1945 to 1997 and the mesh with 1517 nodes.

We model the total precipitation of spring (March, April and May) for each year from
1945 to 1997 with a Bayesian hierarchical model. We assume that the observations follow a
Gamma distribution with a spatially varying mean value. For the jth year, we assume that,
conditionally on a spatially varying mean value µj(s), the observed precipitation values are
independent and Gamma distributed,

Yj,i | µj(si), θ ∼ Γ(µj(si), φ),

(16)

where Yj,i is the precipitation at spatial location si of year j, and Γ(µ, φ) denotes Gamma
distribution with density π(y) = 1
, with 1/φ being a dispersion
Γ(φ)
parameter describing variability of the distribution. In this parametrization, µj(s) is the
mean and µj(s)2/φ is the variance at location s of year j. The mean value of year j is
modelled as

yφ−1 exp

− φy
µ

(cid:16) φ
µ

(cid:17)φ

(cid:16)

(cid:17)

log(µj(s)) = α0 + α1lon(s) + α2lat(s) + α3elev(s) + uj(s),

(17)

where α0 is an intercept, and lon(s), lat(s) and elev(s) denote the longitude, the latitude and
the elevation at spatial location s, respectively, and {αi}i=1,2,3 are corresponding regression
coeﬃcients. Further, we assume that {uj(s)}j are independent realization of a Whittle–
Mat´ern Gaussian random ﬁeld deﬁned through the SPDE (2).

We chose the priors for {αi}i=0,1,2,3 as the default choices from the R-INLA package, i.e.,
centered Gaussian distributions with mean 0 and low precisions. The prior distributions
for the three parameters ν, κ, and τ were chosen as the default choices from the rSPDE
package. That is, log(κ) and log(τ ) are assumed to be independent Gaussian with variance

16

(a) posterior for ν

(b) posterior for κ

(c) posterior for τ

Figure 4: Plots of posterior distributions for ν,κ and τ .

Table 1: Results of the cross-validation study for the application. The values shown are
averages over 100 pseudo cross-validation iterations. The scores are negatively oriented. A
smaller value shows a better result.

CRPS SCRPS DSS MSE

fractional model
integer model

3.582
3.607

2.050
2.052

4.970
5.031

29.248
29.582

10 and the mean values are chosen based on size of the domain. Further, the prior for ν
is a beta distribution on the interval (0, 4) with mean 2 and variance 1. We refer to this
model as the ‘fractional model’ and also ﬁt a non-fractional model where ν = 1 is assumed
to be ﬁxed. This value of ν is the default choice for the standard SPDE models in R-INLA
and we refer to this as the ‘integer model’. We ﬁt both models using the R-INLA software
(version 22.08.24) and the R language (version 4.2.1) running on a machine with an Intel
i9-12900KF CPU, 64GB RAM and an Ubuntu operating system. The total time for ﬁtting
the fractional model and integer model are 282 seconds and 45 seconds, respectively.

The posterior distributions of the parameters of the Gaussian ﬁeld for the two models
are shown in Figure 4. For the fractional model, one can note that the posterior mode
of ν is around 0.53 which indicates that a fractional smoothness is needed. To further
compare the two models, we perform a cross-validation to compare the predictive accuracy.
For each year, we randomly select 10% of the spatial locations to predict based on the
observations at the remaining 90% spatial locations. The accuracy is measured by three
(positively oriented) proper scoring rules; the continuous ranked probability score (CRPS)
(Gneiting and Raftery, 2007), the scaled CRPS (SCRPS) (Bolin and Wallin, 2019), the
Dawid-Sebastiani score (DSS) (Dawid and Sebastiani, 1999) as well as by mean squared
errors. Table 1 shows the average scores over 100 iterations of this procedure. We can
see that the fractional model has better results than the integer model for all four scoring
rules. We will not further investigate whether these diﬀerences are of practical importance,
since the main point of this application is to illustrate the fact our proposed methods facil-
itates computationally eﬃcient Bayesian inference of latent Gaussian models that include
fractional SPDE models as model components, where we importantly can estimate also the
fractional smoothness parameter β.

17

8 Discussion

We have introduced a new rational SPDE approach which provides stable and computa-
tionally eﬃcient approximations for the covariance structure of generalized Whittle–Mat´ern
Gaussian random ﬁelds with general smoothness β > d/4. We further derived and explicit
rate of convergence of the method, which provides a theoretical justiﬁcation for the ap-
proach. Compared to the rational SPDE approach of Bolin and Kirchner (2020), the main
advantage is that we obtain a GMRF representation of the approximation. This allowed
us to implement the method so that fractional SPDE models now can be estimated in the
R-INLA software, where we in particular can estimate the smoothness parameter from data.
At this stage, it might be worth mentioning why the operator-based method of Bolin
and Kirchner (2020) is not suitable for R-INLA. The reason is that the operator-based
method does not yield a Markov approximation, so the precision matrix obtained from the
approximation is not sparse. Instead, the covariance matrix of the approximation is of the
form PQ−1P, where both P and Q are sparse matrices that depend on the parameters
of the model. To achieve a sparse “precision”-like matrix, which is necessary for R-INLA,
Bolin and Kirchner (2020) showed that one can deﬁne a new projection matrix (cid:98)A = AP
and consider a latent model with sparse precision matrix Q. This, however, requires that
the projection matrix depends on the model parameters, which is not allowed in R-INLA.
In the current version of the rSPDE package, we for simplicity chose a beta prior for
the smoothness parameter ν as a default choice. However, a natural question for future
research is how this prior should be chosen in a more systematic way. A potential way
to do this is following the idea of penalized complexity priors (PC-priors) (Simpson et al.,
2017). Fuglstad et al. (2019) derived PC-priors for κ and τ of the Whittle–Mat´ern ﬁelds
assuming a ﬁxed value of ν, and we plan to extend that work by deriving PC-priors for all
three parameters. Another potential area of future work is to extend the proposed method
to spatio-temporal SPDE models as those proposed by Bakka et al. (2020).

A Proof of Proposition 1

In this section, we prove Proposition 1. We start with providing notations that we will
use. Let (E, (cid:107) · (cid:107)E) and (F, (cid:107) · (cid:107)F ) be two separable Hilbert spaces with norms (cid:107) · (cid:107)E and
(cid:107) · (cid:107)F respectively. Then (E, (cid:107) · (cid:107)E) (cid:44)→ (F, (cid:107) · (cid:107)F ) means that E ⊂ F and there exists a
constant C such that for any x ∈ E, we have (cid:107)x(cid:107)E ≤ C(cid:107)x(cid:107)F . In this case, we say that
If we have (E, (cid:107) · (cid:107)E) (cid:44)→ (F, (cid:107) · (cid:107)F ) (cid:44)→ (E, (cid:107) · (cid:107)E),
E is continuously embedded in F .
then we denote it as (E, (cid:107) · (cid:107)E) ∼= (F, (cid:107) · (cid:107)F ). We will denote by L(E, F ) the Banach
space of bounded linear operators from E to F endowed with the operator norm, that is,
(cid:107)A(cid:107)L(E,F ) = sup(cid:107)u(cid:107)E =1 (cid:107)Au(cid:107)F , where A ∈ L(E, F ). Similarly, we denote by L2(E, F ) the
Banach space of Hilbert-Schmidt operators, endowed with the Hilbert-Schmidt norm, that
is, (cid:107)A(cid:107)L2(E,F ) = (cid:80)
i∈N (cid:107)Aei(cid:107)F , where {ei}i∈N is a complete orthonormal set in (E, (cid:107) · (cid:107)E)
and A ∈ L2(E, F ). We will denote L(E, E) by L(E), with corresponding norm (cid:107) · (cid:107)L(E),
and L2(E, E) by L2(E), with corresponding norm (cid:107) · (cid:107)L2(E). At last, if E ⊂ F , then we
will denote the inclusion map from E to F by IE,F .

Now let us start by providing the relations between the eigenvalues of L and Lh. Recall,

18

from Section 2, that {λj}j∈N are eigenvalues of L and {λj,h}nh
given in non-decreasing order. We have the following standard result:
Proposition 3. Under Assumption 3, we have that 1. λnh,h (cid:46) λnh
for suﬃciently
small h ∈ (0, 1) (Strang and Fix, 2008, Theorem 6.1); 2. λj ≤ λj,h (due to the min-max
principle); and 3. nh (cid:46) h−d (due to quasi-uniformity of the triangulation).

j=1 are eigenvalues of Lh, both

(cid:46) n2/d
h

Let, now,

˙H σ

L(D) := D(Lσ/2) =

ψ ∈ L2(D) :

(cid:40)

(cid:41)

j (cid:104)ψ, ej(cid:105)2
λσ

L2(D) < ∞

,

(cid:88)

j∈N

with inner product and norm given by

(ψ, φ) ˙H σ

L(D) = (Lσ/2ψ, Lσ/2φ)L2(D) =

(cid:88)

j∈N

λσ
j (cid:104)ψ, ej(cid:105)L2(D)(cid:104)φ, ej(cid:105)L2(D)

˙H σ

= (cid:104)ψ, ψ(cid:105) ˙H σ

and (cid:107)ψ(cid:107)2
L(D). Further, we deﬁne [H1, H2]σ as the real interpolation between
the Hilbert spaces H1 and H2 (see Bolin et al., 2022, Appendix A for a brief review of real
interpolation of Hilbert spaces).

L(D)

We consider the fractional Sobolev space of order σ, with 0 < σ < 2, σ (cid:54)= 1, given by

H σ(D) =

(cid:40)

[L2(D), H 1(D)]σ,
[H 1(D), H 2(D)]σ−1,

for 0 < σ < 1,
for 1 < σ < 2.

By Cox and Kirchner (2020, Lemma 2), we have that with Dirichlet boundary conditions

( ˙H σ

L, (cid:107) · (cid:107) ˙H σ

0 (D)]σ ),

0 (D)]σ, (cid:107) · (cid:107)[L2(D),H 1
L(D)) (cid:44)→ (H σ(D), (cid:107) · (cid:107)H σ(D)), 0 < σ < 1,

L(D)) ∼= ([L2(D), H 1
( ˙H σ
L, (cid:107) · (cid:107) ˙H σ
L(D) and (cid:107) · (cid:107)H σ(D) are equivalent on ˙H σ
0 (D), (cid:107) · (cid:107)H σ(D)),

L(D)) ∼= (H σ(D) ∩ H 1

( ˙H σ

L(D), (cid:107) · (cid:107) ˙H σ

0 < σ < 1,

L(D) for σ (cid:54)= 1/2 and also

1 ≤ σ ≤ 2.

(18)

where the norms (cid:107) · (cid:107) ˙H σ

We want to apply Cox and Kirchner (2020, Theorem 1), however it was only proved
under Dirichlet boundary conditions. Therefore, we need some additional auxiliary results
to conclude an analogous result in the case of Neumann boundary conditions. To this
end, we need to prove the following result, which is a version of Cox and Kirchner (2020,
Lemma 2) for Neumann boundary conditions:

Proposition 4. Under Neumann boundary conditions we have

L(D)) ∼= (H σ(D), (cid:107) · (cid:107)H σ(D)),

L, (cid:107) · (cid:107) ˙H σ

( ˙H σ
L(D)) ∼= ([H 1(D), H 2
N (D) was deﬁned in Section 2. Moreover,

L, (cid:107) · (cid:107) ˙H σ

N (D)]σ−1, (cid:107) · (cid:107)[H 1(D),H 2

( ˙H σ

N (D)]σ−1),

where H 2

0 ≤ σ ≤ 1,

(19)

1 ≤ σ ≤ 2,

(20)

(21)

where the norms (cid:107) · (cid:107) ˙H σ

( ˙H σ

L(D)) (cid:44)→ (H σ(D), (cid:107) · (cid:107)H σ(D)), 1 < σ < 2,

L, (cid:107) · (cid:107) ˙H σ
L(D) and (cid:107) · (cid:107)H σ(D) are equivalent on ˙H σ

L(D) for σ (cid:54)= 3/2.

19

˙H 0

√

L(D)

Proof. First, observe that
L = L2(D). Also, since the bilinear form aL is continuous,
coercive and symmetric, aL is an inner product on H 1(D), whose corresponding norm is
L(D), we have that for every φ ∈ H 1(D),
equivalent to (cid:107) · (cid:107)H 1(D). Now, by deﬁnition of (cid:107) · (cid:107) ˙H 1
aL(φ, φ) = (cid:107)φ(cid:107)2
. This means that the norm induced by aL coincides with the norm
˙H 1
(cid:107) · (cid:107) ˙H 1

L(D). This shows the equivalence between (cid:107) · (cid:107) ˙H 1

Now, observe that from Lax-Milgram’s lemma, for every i ∈ N, the eigenvector ei
of L belongs to H 1(D) and satisﬁes (ei, ej) ˙H 1
L(D) = aL(ei, ej) = λiδi,j, where δi,j is the
i∈N aiei, with (cid:80)
L(D), we have that φ = (cid:80)
Kronecker’s delta. For any φ ∈ ˙H 1
i λi < ∞
i λi < ∞, the series (cid:80)
and ai = (φ, ei)L2(D). Since (cid:80)
i∈N a2
i∈N aiei is absolutely convergent in
H 1(D), which implies that it also converges in H 1(D) since H 1(D) is a Hilbert (complete)
space. On the other hand, the series converges to φ in L2(D), so the series must converge
to φ in H 1(D) as well because of the inclusion H 1(D) ⊂ L2(D). Thus, φ ∈ H 1(D).

L(D) and (cid:107) · (cid:107)H 1(D).

i∈N a2

√

√

L(D)

i a2

ei√
λi

i∈N bi

= (cid:80)

Conversely, let ψ ∈ H 1(D) and observe that {ei/

L(D)). Therefore, we have that ψ = (cid:80)
√
L(D) = aL(ψ, ei/

set in (H 1(D), (cid:107) · (cid:107) ˙H 1
are bi = (ψ, ei/
λi) ˙H 1
By equivalence of (cid:107) · (cid:107) ˙H 1
(cid:107)ψ(cid:107) ˙H 1
turn implies that (cid:80)
in L2(D), so ψ = (cid:80)
i = (cid:80)
(cid:80)
i∈N b2

λi}i∈N is a complete orthonormal
, where the coeﬃcients
i∈N b2
λi). By Parseval’s identity, (cid:107)ψ(cid:107)2
i .
˙H 1
L(D) and (cid:107) · (cid:107)H 1(D), we have that there exists C > 0 such that
L(D) ≤ C(cid:107)ψ(cid:107)H 1(D). Thus, since ψ ∈ H 1(D), we have that (cid:107)ψ(cid:107)H 1(D) < ∞, which in
i∈N b2
i < ∞. On the other hand, {ei}i∈N is a complete orthonormal set
i∈N aiei, with ai = (ψ, ei)L2(D). Therefore, bi =
λiai, which yields,
L(D)) ∼= (H 1(D), (cid:107)·(cid:107)H 1(D)).
L(D). Hence ( ˙H 1
i < ∞, thus ψ ∈ ˙H 1
i∈N λia2
We obtain (19) by the same arguments as in the proof of Bolin et al. (2022, Corollary 10).
Similarly, to prove (20), it is enough to show that ( ˙H 2
N (D), (cid:107) · (cid:107)H 2(D)).
L(D) and write φ = (cid:80)
To this end, ﬁrst, let φ ∈ ˙H 2
i∈N aiei, with ai = (φ, ei)L2(D). Let,
φN = (cid:80)N
i=1 aiλiei. Now, observe
that (cid:80)
i < ∞ implies LφN converges to some g ∈ L2(D). On the other hand, since
˙H 2
L(D) → L2(D) is self-adjoint, it is a closed operator. Therefore, Lφ = g. We now
L :
apply H 2(D)-regularity of L (Remark 1) to conclude that φ ∈ H 2
N (D). Finally, it follows
from the closed graph theorem that ( ˙H 2
N (D), (cid:107) · (cid:107)H 2(D)). Indeed, ﬁrst
observe that λj → ∞ as j → ∞. This yields ( ˙H 2
L(D)) (cid:44)→ (L2(D), (cid:107) · (cid:107)L2(D)). Now,
let φN → 0 in ˙H 2
N (D)(φN ) → φ,
L(D),H 2
then (cid:107)φN − φ(cid:107)L2(D) ≤ (cid:107)φN − φ(cid:107)H 2(D) → 0. So, φ = 0, since φN → 0 in L2(D). By the
N (D) is a bounded operator.
closed graph theorem I ˙H 2

i=1 aiei and by linearity of L, we have that LφN = (cid:80)N
i∈N λ2

L(D), then φN → 0 in L2(D). On the other hand if I ˙H 2

L(D)) ∼= (H 2

L(D)) (cid:44)→ (H 2

L(D), (cid:107) · (cid:107) ˙H 2

L(D), (cid:107) · (cid:107) ˙H 2

L(D), (cid:107) · (cid:107) ˙H 2

L(D), (cid:107)·(cid:107) ˙H 1

Conversely, let ψ ∈ H 2

N (D). By the Kirszbraun theorem (Kirszbraun, 1934), H can
be extended to a Lipschitz function on Rd with the same Lipschitz constant. Denote this
extension by (cid:102)H. Now, let R > 0 be such that D ⊂ B(0, R), where B(0, R) stands for the
ball with center 0 and radius R in Rd. Since (cid:102)H is uniformly continuous, it is bounded in
B(0, 2R). Let, also, ϕ ∈ C ∞
c (B(0, 2R)), such that ϕ ≡ 1 in B(0, R). Then, by convexity
of B(0, 2R), ϕ is Lipschitz and bounded. This implies that ϕ(cid:102)H is Lipschitz, since it is the
product of bounded Lipschitz functions, ϕ(cid:102)H ∈ Cc(Rd), and the restriction of ϕ(cid:102)H to D
is H. Therefore, by Grisvard (2011, Theorem 1.4.1.1), H∇ψ ∈ (H 1(D))d. In particular,
Lφ ∈ L2(D). Thus, Lφ = (cid:80)
i∈N b2
i < ∞, where bi = (Lφ, ei)L2(D). We then

i∈N biei, (cid:80)

L(D),H 2

20

apply Gauss-Green formula (Grisvard, 2011, Theorem 1.5.3.1) twice together with the fact
that φ and ei satisfy Neumann boundary condition, to conclude that

bi = (Lφ, ei)L2(D) = (φ, Lei)L2(D) = λi(φ, ei)L2(D).

i∈N λ2

Now, if we write φ = (cid:80)
i = (cid:80)
(cid:80)

i < ∞. Hence, φ ∈ ˙H 2
the previous inclusion, to obtain that (H 2
closed graph theorem. This proves (20).

i∈N b2

i∈N aiei, we obtain that bi = λiai. Therefore, we have that
L(D). Now, we repeat the same argument from
N (D), (cid:107) · (cid:107)H 2(D)) (cid:44)→ ( ˙H 2
L(D)) from the

L(D), (cid:107) · (cid:107) ˙H 2

i a2

Note that H 2

N (D) (cid:44)→ H 2(D). So, by combining (20) with a similar argument to the one
in the proof of (Bolin et al., 2022, Corollary 10), we obtain (21). Finally, observe that since
∼= H 1(D).
D is Lipschitz, we have, by Grisvard (1967, Theorem 8.1), that [L2(D), H 2
This identiﬁcation together with (Chandler-Wilde et al., 2015, Theorem 2.2, item (vii))
imply the further identiﬁcation [H 1(D), H 2
, 0 < γ < 1. The
N (D)]γ
L(D) and (cid:107) · (cid:107)H σ(D) for σ (cid:54)= 3/2 now follows from (20), the
equivalence of the norms (cid:107) · (cid:107) ˙H σ
∼= [L2(D), H 2
identiﬁcation [H 1(D), H 2
, 0 < γ < 1, and another application
of Grisvard (1967, Theorem 8.1).

∼= [L2(D), H 2

N (D)] 1+γ

N (D)] 1+γ

N (D)]1/2

N (D)]γ

2

2

We are now in a position to obtain a version of Theorem 1 of Cox and Kirchner (2020)
(more precisely, of Remark 8 in Cox and Kirchner (2020)) that works for both Dirichlet
and Neumann boundary conditions.

Remark 5. From Assumptions 1 and 3, there exists a linear operator Ih : H 2(D) → Vh
such that for every 1 ≤ θ < 2, Ih : H θ(D) → Vh is a continuous extension and there exists
a constant C which only depends on κ, H and D such that

(cid:107)IH θ(D),L2(D) − Ih(cid:107)L(H θ(D),L2(D)) (cid:46)κ,H,D hθ,
where 1 ≤ θ ≤ 2 Indeed, this follows by Ciarlet (2002, Theorem 3.2.1) together with
Chandler-Wilde et al. (2015, Theorem 3.5).

Lemma 1. Under Assumption 1,2 and 3, we have that for every τ > 0

(cid:107)L−τ − L−τ

h Πh(cid:107)L(H γ (D),L2(D)) (cid:46)ε,τ,γ,κ,H,D hmin{2τ +γ−ε,2},

where Πh : L2(D) → Vh the L2(D)-orthogonal projection onto Vh, 0 ≤ γ ≤ 2, γ (cid:54)= 1/2
for the Dirichlet case, or γ (cid:54)= 3/2 for the Neumann case, ε > 0 is arbitrary and h > 0 is
suﬃciently small.

Proof. For the Dirichlet case, Assumptions 1, 2 and 3 from Section 2.1 together with (18)
and Remark 5 imply the required assumptions for Theorem 1 of Cox and Kirchner (2020).
The case when γ = 0 follows by choosing τ = β, α = 1 and σ = δ = 0 whereas the case
when 0 < γ ≤ 2, γ (cid:54)= 1/2, follows from choosing τ = β, α = 1, δ = γ and σ = 0.

For the Neumann case, Assumptions 1, 2 and 3, together with Remark 5 and Proposition
4 allows us to use the same proof of Cox and Kirchner (2020, Theorem 1) to obtain the
desired result, where we take τ = β, α = 1 and σ = δ = 0 when γ = 0, or τ = β, α = 1, δ = γ
and σ = 0, when 0 < γ ≤ 2, γ (cid:54)= 3/2.

21

We deﬁne

(cid:37)β
h(x, y) =

nh(cid:88)

j=1

λ−2β
j,h ej,h(x)ej,h(y),

for a.e. (x, y) ∈ D.

Then, (cid:107)L−2β

h Πh(cid:107)L2(L2(D)) = (cid:107)L−2β

h (cid:107)L2(Vh) = (cid:107)(cid:37)β

h(cid:107)L2(D×D).

Remark 6. Note that (cid:37)β
the solution of (4).

h is the covariance function of the stochastic process obtained as

Now we are ready to give the proof of Proposition 1.

Proof of Proposition 1. Observe that L−2β −L−2β
Thus, (cid:107)(cid:37)β − (cid:37)β
bound for (cid:107)L−2β − L−2β
Then, we have that

h Πh is a kernel operator with kernel (cid:37)β −(cid:37)β
h.
h Πh(cid:107)L2(L2(D)). Therefore, it is enough to obtain a
h Πh(cid:107)L2(L2(D)). Fix any ε > 0. Now, let 0 < δ < min{β − d/4, ε/4}.

h(cid:107)L2(D×D) = (cid:107)L−2β − L−2β

(cid:107)L−2β − L−2β

h Πh(cid:107)L2(L2(D)) ≤

(cid:16)

(cid:13)
(cid:13)
(cid:13)

+

L−(2β−d/4−δ) − L−(2β−d/4−δ)
(cid:13)
(cid:13)L−(2β−d/4−δ) (cid:16)
(cid:13)

L−(d/4+δ)

L−(d/4+δ)
Πh
Πh − L−(d/4+δ)(cid:17)(cid:13)
(cid:13)
(cid:13)L2(L2(D))

Πh

h

h

h

(cid:13)
(cid:13)
(cid:13)L2(L2(D))

(cid:17)

.

(22)

We begin by handling the term ﬁrst term in the right-hand side of (22). Recall that if

H is a Hilbert space and A, B : H → H are linear operators, then

(cid:107)AB(cid:107)L2(H) ≤ (cid:107)A(cid:107)L(H)(cid:107)B(cid:107)L2(H).

(23)

Now, let τ = 2β − d/4 − δ > 0 and apply Lemma 1 (where we take the ε in its statement
as ε/2 and γ = 0) together with equation (23) to obtain

(cid:13)
(cid:0)L−τ − L−τ
(cid:13)
(cid:13)

h Πh

(cid:1) L−(d/4+δ)

h

Πh

(cid:13)
(cid:13)
(cid:13)L2(L2(D))

≤ (cid:107)L−τ − L−τ

h Πh(cid:107)L(L2(D))(cid:107)L−(d/4+δ)

h

Πh(cid:107)L2(L2(D))

(cid:46)ε,β,κ,H,D hmin{4β−d/2−2δ−ε/2,2}(cid:107)L−(d/4+δ)

h

Πh(cid:107)L2(L2(D)).

Let ζ(s) = (cid:80)∞

j=1 j−s and θ = d/4 + δ. We have the following bound for the Hilbert-

Schmidt norm of L−(d/4+δ)

h

Πh:

(cid:107)L−θ

h Πh(cid:107)2

L2(L2(D)) =

nh(cid:88)

j=1

λ−2θ
j,h ≤

nh(cid:88)

j=1

λ−2θ
j

(cid:46)κ,H,D

nh(cid:88)

j=1

j−4θ/d < ζ(4θ/d) < ∞,

where we used item 2 of Proposition 3 and Weyl’s law (Remark 2). Therefore, since
2δ < ε/2 and h is suﬃciently small, we obtain

(cid:16)

(cid:13)
(cid:13)
(cid:13)

L−(2β−d/4−δ) − L−(2β−d/4−δ)

h

(cid:17)

Πh

L−(d/4+δ)

h

Πh

(cid:13)
(cid:13)
(cid:13)L2(L2(D))

(cid:46)ε,β,κ,H,D hmin{4β−d/2−ε,2}.

(24)

Now let us give a bound for the second term on the right-hand side of (22). Let
γ = min{4β − d − 4δ, 2} > 0, so γ ≤ 2. Observe that in order to apply Lemma 1, we must

22

choose δ such that γ (cid:54)= 1/2 in the Dirichlet case, or γ (cid:54)= 3/2 in the Neumann case. This is
possible, since we can reduce δ if necessary.

The natural domain of the operator L−(2β−d/4−δ) is L2(D). Furthermore, by the def-
L(D) since for every
h Πh
h Πh − L−θ and

L(D) space, we have that L−(2β−d/4−δ) : L2(D) → ˙H γ
(D) ⊂ ˙H γ

inition of the ˙H σ
v ∈ L2(D), L−(2β−d/4−δ)v ∈ ˙H 4β−d/2−2δ
to ˙H γ
L(D), we also have that L−θ
h Πh :
B = L−(2β−d/4−δ). Observe that

L(D). If we restrict the domain of L−θ

L(D) → L2(D). Let A = L−θ

˙H γ

L

(cid:107)BA(cid:107)L2(L2(D)) ≤ (cid:107)B(cid:107)L2(L2(D), ˙H γ

L(D)) (cid:107)A(cid:107)L( ˙H γ

L(D),L2(D)) .

Let us now show that (cid:107)B(cid:107)L2(L2(D), ˙H γ

L(D)) is bounded. Recall that {ej}j∈N is an orthonor-

mal basis in L2(D). Then we have
∞
(cid:88)

(cid:13)L−(2β−d/4−δ)(cid:13)
(cid:13)
2
(cid:13)
L2(L2(D), ˙H γ

L(D)) =

(cid:13)
(cid:13)L−(2β−d/4−δ)ej

(cid:13)
2
L(D) =
(cid:13)
˙H γ

∞
(cid:88)

j=1

(cid:13)
(cid:13)Lγ/2L−(2β−d/4−δ)ej

(cid:13)
2
(cid:13)

L2(D)

λγ−4β+d/2+2δ
j

(cid:46)κ,H,D

∞
(cid:88)

j=1

j2γ/d−8β/d+4δ/d+1,

j=1
∞
(cid:88)

j=1

=

which converges since 2γ/d − 8β/d + 4δ/d + 1 < −1, and where the last inequality comes
from γ − 2δ < γ ≤ 4β − d − 4δ.

L(D) ⊂ H γ(D) and (cid:107)·(cid:107) ˙H γ

Now let us handle the term (cid:107)A(cid:107)L( ˙H γ

L(D),L2(D)). By (16) and (17) from Lemma 2 in Cox
and Kirchner (2020) for the Dirichlet case, or by Proposition 4 for the Neumann case, we
can conclude that ˙H γ
L(D) is equivalent to (cid:107)·(cid:107)H γ (D) when 0 ≤ γ ≤ 2
and γ (cid:54)= 1/2 for the Dirichlet case or γ (cid:54)= 3/2 for the Neumann case. By equivalency
L(D), which
of the two norms, there exists a constant C such that (cid:107)v(cid:107)H γ (D) ≤ C · (cid:107)v(cid:107) ˙H γ
L(D) ⊂ H γ(D), we
implies 1/ (cid:107)v(cid:107) ˙H γ
can conclude that (cid:107)A(cid:107)L( ˙H γ
L(D),L2(D)) ≤ C · (cid:107)A(cid:107)L(H γ (D),L2(D)). Combining this with Lemma 1,
we obtain that
(cid:13)
(cid:13)L−θ

L(D) ≤ C/ (cid:107)v(cid:107)H γ (D), for every v ∈ ˙H γ

(cid:46)ε,θ,γ,κ,H,D hmin{2θ+γ−ε/2,2} = hmin{4β−d/2−2δ−ε/2,2},

L(D). Then by ˙H γ

h Πh − L−θ(cid:13)

(cid:13)L( ˙H γ

L(D),L2(D))

where we chose ε in the statement of Lemma 1 as ε/2. Again, since 2δ < ε/2 and h is
suﬃciently small, we arrive at

(cid:13)
(cid:13)L−θ

h Πh − L−θ(cid:13)

(cid:13)L( ˙H γ

L(D),L2(D))

(cid:46)ε,β,κ,H,D hmin{4β−d/2−ε,2}.

(25)

The result now follows from (24) and (25).

B Proof of Proposition 2

Proof of Proposition 2. First, note that (cid:107)(cid:37)β
and we similarly have that (cid:107)(cid:37)β
h(cid:107)L2(D×D) = (cid:107)L−2β − L−2β
(cid:107)(cid:37)β − (cid:37)β
h,m − (cid:37)β(cid:107)L2(D×D) ≤ (cid:107)L−2β

h,m − (cid:37)β(cid:107)L2(D×D) = (cid:107)L−2β − L−2β
h,m Πh − L−2β

h,m Πh(cid:107)L2(L2(D)),
h Πh(cid:107)L2(L2(D)) and also

h(cid:107)L2(D×D) = (cid:107)L−2β

h,m − (cid:37)β
h Πh(cid:107)L2(L2(D)). Therefore, by the triangle inequality,
h,m Πh(cid:107)L2(L2(D)) + (cid:107)L−2β − L−2β
h Πh − L−2β

h Πh(cid:107)L2(L2(D)).

(cid:107)(cid:37)β

23

h Πh − L−2β

We begin by obtaining an upper bound for (cid:107)L−2β

h,m Πh(cid:107)L2(L2(D)). Recall from
Section 2.2, that the eigenvalues of Lh are 0 < λ1,h ≤ λ2,h ≤ · · · ≤ λnh,h, with corresponding
eigenvectors {ej,h}nh
j=1, which are orthonormal in L2(D). By item 2 of Proposition 3, we have
1,h] and J = [0, λ−1
that Jh ⊂ J, where Jh = [λ−1
1 ], since λ1 is the smallest eigenvalue
of L. We normalize L so that λ1 ≥ 1. Thus, Jh ⊂ J ⊂ [0, 1]. Now, let f (x) = x2β and
ˆf (x) = x{2β}, where {2β} = 2β − (cid:98)2β(cid:99), so that f (x) = x(cid:98)2β(cid:99) ˆf (x). Let ˆrh(x) = p(x)
q(x) be the
L∞-best approximation of ˆf (x) on Jh, and deﬁne rh(x) = x(cid:98)2β(cid:99)ˆrh(x). Then, we have the
following bound:

nh,h, λ−1

(cid:107)L−2β

h Πh − L−2β

h,m Πh(cid:107)2

L2(L2(D)) =

nh(cid:88)

j=1

(cid:107)L−2β
h

ej,h − L−2β

h,m ej,h(cid:107)2

L2(D) =

≤ nh max
1≤j≤nh

|λ−2β

j,h − rh(λ−1

j,h)|2.

nh(cid:88)

(λ−2β

j,h − rh(λ−1

j,h))2

j=1

(26)

We now apply (Stahl, 2003, Theorem 1), and observe that x(cid:98)2β(cid:99) ≤ 1 on Jh, to obtain:

max
1≤j≤nh

|λ−2β

j,h − r(λ−1

j,h)| ≤ sup
x∈Jh

|f (x) − r(x)| ≤ sup
x∈[0,1]

| ˆf (x) − ˆr(x)| (cid:46) e−2π

√

{2β}m.

(27)

h Πh −L−2β

Thus, by (26) and (27), we have (cid:107)L−2β
{2β}m and by item
3 of Proposition 3, we obtain n1/2
{2β}m. This source of error only
h e−2π
occurs if we need the rational approximation, i.e., if 2β /∈ N. Thus, combining this with
the bound (cid:107)L−2β − L−2β
h Πh(cid:107)L2(L2(D)) (cid:46)ε,β,H,κ,D hmin{4β−d/2−ε,2} from Proposition 1, yields
the desired result:

h,m Πh(cid:107)L2(L2(D)) (cid:46) n1/2

{2β}m (cid:46) h−d/2e−2π

h e−2π

√

√

√

(cid:107)(cid:37)β

h,m − (cid:37)β(cid:107)L2(D×D) (cid:46)ε,β,H,κ,D 12β /∈Nh−d/2e−2π

√

{2β}m + hmin{4β−d/2−ε,2}.

C Derivation of the GMRF representation

h

((cid:80)m

h,m = L−(cid:98)2β(cid:99)

In this section, we derive equation (8). Recall the rational approximated covariance op-
erator in (7): L−2β
i=1 ri(Lh − piIVh)−1 + kIVh), where Lh was deﬁned in
Section 2.2, L−2β
h,m was deﬁned in Section 3 and IVh is the identity map on the ﬁnite el-
ement space Vh. The ﬁrst part of this expression is the sum of the terms of the form
riL−(cid:98)2β(cid:99)
i=1 and k
h
i=1 and kL−(cid:98)2β(cid:99)
are positive and {pi}m
are positive-deﬁnite operators. In addition, they are also self-adjoint. Therefore, they are
valid covariance operators.

(Lh − piIVh)−1, i = 1, ..., m, whereas the second part is kL−(cid:98)2β(cid:99)
i=1 are negative real numbers, {riL−(cid:98)2β(cid:99)

(Lh − piIVh)−1}m

. Since {ri}m

h

h

h

We will deal with each term in the partial fractions expansion separately. We begin
(Lh − pIVh)−1. Observe that this term is the covariance
x = Wh. If (cid:98)2β(cid:99) is odd,

with the terms of the form rL−(cid:98)2β(cid:99)
operator of the solution of the SPDE r−1/2(Lh − pIVh)1/2L(cid:98)2β(cid:99)/2

h

h

24

(cid:98)2β(cid:99) = 2n + 1, with n ∈ N, we can rewrite the equation as r−1/2((Lh − pI)Lh)1/2Ln
or equivalently

hx = Wh,

r−1/2 ˆL1/2z = Wh,
Ln
hx = z,

(28)
(29)

where ˆL = (Lh − pIVh)Lh and z ∈ Vh (see Section 2.2 for the deﬁnition of Vh).

j=1 zjϕj. Similarly, we have that x = (cid:80)nh

Let {ϕj}nh
j=1 be the ﬁnite element basis of Vh. We can write z in the ﬁnite element
basis as z = (cid:80)nh
j=1 xjϕj. Let us now ob-
tain a relation between z = [z1, ..., znh](cid:62) and x = [x1, ..., xnh](cid:62). Observe that, for each
l = 1, ..., nh, we have (z, ϕl)L2(D) = (cid:80)nh
j=1 zj(ϕj, ϕl)L2(D). However, by (28) and (29),
we also have (z, ϕl)L2(D) = (Ln
hϕj, ϕl)L2(D). Let us now com-
pute (Ln
hϕj, ϕl)L2(D). To this end, let B be the matrix of the operator Lh in the basis
k=1 Bj,kϕk. Thus (Lhϕj, ϕl)L2(D) = (cid:80)nh
{ϕi}nh
k=1 Bj,k(ϕk, ϕl)L2(D). Let,
also, Lj,l := aL(ϕj, ϕl) = (Lhϕj, ϕl) (recall the bilinear form aL(·, ·) from Section 2.1) and
C j,l = (ϕj, ϕl)L2(D) (Both L and C are symmetric). Then, B = LC −1, and

i=1 so that ϕj = (cid:80)nh

hx, ϕl)L2(D) = (cid:80)nh

j=1 xj(Ln

(Ln

hϕj, ϕl)L2(D) = (Ln−1

h

(Lhϕj), ϕl)L2(D) = (Ln−1

h

nh(cid:88)

k=1

Bj,kϕk, ϕl)L2(D)

=

nh(cid:88)

k=1

Bj,k(Ln−1

h ϕk, ϕl)L2(D).

The relation z = (C −1L)nx now follows by induction (the base case is Lj,l = (Lhϕj, ϕl))
since (Ln

hϕj, ϕl)L2(D) = [Bn−1L]j,l = [(LC −1)n−1L]j,l.

We are now ready to obtain the distribution of x. Note that ˆL1/2 : Vh → Vh is an
isomorphism: By the coerciveness of bilinear form aL(·, ·) from Section 2.1, all the eigen-
values of L are positive. By item 2 from Proposition 3, all the eigenvalues of Lh are
positive as well. This means Lh is a positive-deﬁnite operator. Since p is a negative real
number, Lh − pIVh is a positive-deﬁnite operator. Further, ˆL is symmetric and product
of positive-deﬁnite matrices, thus by (Horn and Johnson, 2013, Corollary 7.6.2), ˆL is also
positive-deﬁnite. Therefore, ˆL1/2 is positive-deﬁnite, and since Vh is a ﬁnite dimensional
space, ˆL1/2 : Vh → Vh is an isomorphism. This means that Vh = span{ ˆL1/2ϕj}nh
j=1. Hence,
the weak form of (28) can be written as:
nh(cid:88)

zj( ˆL1/2ϕj, ˆL1/2ϕl)L2(D) = (Wh, ˆL1/2ϕl)L2(D),

l = 1, ..., nh.

r−1/2

(30)

j=1

Deﬁne (cid:98)L = LC −1L − pL. Then, by the identity z = (C −1L)nx, the self-adjointness of
ˆL1/2 and (L2
hϕj, ϕl)L2(D) = [LC −1L]j,l, the sum in the left hand side of (30) is

nh(cid:88)

j=1

zj( ˆL1/2ϕj, ˆL1/2ϕl)L2(D) =

nh(cid:88)

[(C −1L)n]j,kxk( ˆLϕj, ϕl)L2(D) =

nh(cid:88)

[(C −1L)n]j,kxk (cid:98)Lj,l

j,k=1

nh(cid:88)

=

xk

nh(cid:88)

k=1

j=1

(cid:98)Ll,j[(C −1L)n]j,k =

j,k=1

nh(cid:88)

[ (cid:98)L(C −1L)n]l,kxk.

k=1

(31)

25

Let W = [(Wh, ˆL1/2ϕ1)L2(D), ..., (Wh, ˆL1/2ϕnh)L2(D)](cid:62). Since Wh is white noise in Vh, we
have W ∼ N (0, (cid:98)L). By (30) and (31), x = r1/2(L−1C)n (cid:98)L
W . Thus, the covariance
matrix of x is r(L−1C)n (cid:98)L
(CL−1)n, which also can be written as r(L−1C)(cid:98)2β(cid:99)(L−pC)−1.
Therefore, x ∼ N (0, r(L−1C)(cid:98)2β(cid:99)(L − pC)−1).

−1

−1

If (cid:98)2β(cid:99) is even, say (cid:98)2β(cid:99) = 2n, with n a non-negative integer ((cid:98)2β(cid:99) can be 0), we can
write the SPDE as r−1/2(Lh − pIVh)1/2Ln
hxh = Wh. In fact, this is a subcase of the previous
case. One can simply change the ˆL to (Lh − pIVh) and the procedure follows similarly. The
distribution of x in the case is still x ∼ N (0, r(L−1C)(cid:98)2β(cid:99)(L − pC)−1).

For the second term in (8), kL−(cid:98)2β(cid:99)

xh = Wh.
Considering again the two cases when (cid:98)2β(cid:99) is odd or even separately, the derivation follows
similarly as above. In both of these cases, x ∼ N (0, k(L−1C)(cid:98)2β(cid:99)−1L−1). To conclude,
observe that we obtained the distribution of each xi in (9) for i = 1, .., m + 1. Therefore,
this proves (8).

, the corresponding SPDE is k−1/2L−(cid:98)2β(cid:99)/2

h

h

Acknowledgement

Our sincere thanks to Elias T. Krainski and H˚avard Rue for their help with explaining
some details of the internal structure of the R-INLA software.

References

Baker, Jr., G. A. and P. Graves-Morris (1996). Pad´e approximants (Second ed.), Volume 59
of Encyclopedia of Mathematics and its Applications. Cambridge University Press, Cam-
bridge.

Bakka, H., E. Krainski, D. Bolin, H. Rue, and F. Lindgren (2020). The diﬀusion-based

extension of the Mat´ern ﬁeld to space-time. arXiv: 2006.04917.

Banerjee, S., B. P. Carlin, and A. E. Gelfand (2015). Hierarchical modeling and analy-
sis for spatial data (Second ed.), Volume 135 of Monographs on Statistics and Applied
Probability. CRC Press, Boca Raton, FL.

Bolin, D. and K. Kirchner (2020). The rational SPDE approach for Gaussian random ﬁelds

with general smoothness. J. Comput. Graph. Statist. 29 (2), 274–285.

Bolin, D. and K. Kirchner (2022). Equivalence of measures and asymptotically optimal
linear prediction for Gaussian random ﬁelds with fractional-order covariance operators.
Bernoulli, in press (available online).

Bolin, D., K. Kirchner, and M. Kov´acs (2018). Weak convergence of Galerkin approx-
imations for fractional elliptic stochastic PDEs with spatial white noise. BIT 58 (4),
881–906.

Bolin, D., K. Kirchner, and M. Kov´acs (2020). Numerical solution of fractional elliptic

stochastic PDEs with spatial white noise. IMA J. Numer. Anal. 40 (2), 1051–1073.

26

Bolin, D. and F. Lindgren (2011). Spatial models generated by nested stochastic partial dif-
ferential equations, with an application to global ozone mapping. Ann. Appl. Stat. 5 (1),
523–550.

Bolin, D. and A. B. Simas (2022). rSPDE: Rational Approximations of Fractional Stochastic

Partial Diﬀerential Equations. R package version 1.2.0.

Bolin, D., A. B. Simas, and J. Wallin (2022). Gaussian Whittle-Mat´ern ﬁelds on metric

graphs. arXiv preprint arXiv:2205.06163 .

Bolin, D. and J. Wallin (2019). Local scale invariance and robustness of proper scoring

rules. Statistical Science, in press (available online).

Chandler-Wilde, S. N., D. P. Hewett, and A. Moiola (2015). Interpolation of Hilbert and
Sobolev spaces: quantitative estimates and counterexamples. Mathematika 61 (2), 414–
443.

Chang, W., J. Cheng, J. Allaire, C. Sievert, B. Schloerke, Y. Xie, J. Allen, J. McPherson,
A. Dipert, and B. Borges (2021). shiny: Web Application Framework for R. R package
version 1.6.0.

Ciarlet, P. G. (2002). The ﬁnite element method for elliptic problems, Volume 40 of Clas-
sics in Applied Mathematics. Society for Industrial and Applied Mathematics (SIAM),
Philadelphia, PA. Reprint of the 1978 original [North-Holland, Amsterdam].

Cox, S. G. and K. Kirchner (2020). Regularity and convergence analysis in Sobolev and
H¨older spaces for generalized Whittle-Mat´ern ﬁelds. Numer. Math. 146 (4), 819–873.

Davies, E. B. (1995). Spectral Theory and Diﬀerential Operators. Cambridge Studies in

Advanced Mathematics. Cambridge University Press.

Dawid, A. P. and P. Sebastiani (1999). Coherent dispersion criteria for optimal experimental

design. Ann. Statist. 27 (1), 65–81.

Evans, L. C. and R. F. Gariepy (2015). Measure theory and ﬁne properties of functions

(Revised ed.). Textbooks in Mathematics. CRC Press, Boca Raton, FL.

Fedosov, B. (1963). Asymptotic formulas for the eigenvalues of the laplacian in the case of

a polygonal region. Sov. Math., Dokl. 4, 1092–1096.

Fedosov, B. (1964). Asymptotic formulas for the eigenvalues of the laplace operator in the

case of a polyhedron. Sov. Math., Dokl. 5, 988–990.

Fuglstad, G.-A., D. Simpson, F. Lindgren, and H. Rue (2015). Does non-stationary spatial
data always require non-stationary random ﬁelds? Spat. Stat. 14 (part B), 505–531.

Fuglstad, G.-A., D. Simpson, F. Lindgren, and H. Rue (2019). Constructing priors that
penalize the complexity of Gaussian random ﬁelds. J. Amer. Statist. Assoc. 114 (525),
445–452.

27

Gneiting, T. and A. E. Raftery (2007). Strictly proper scoring rules, prediction, and

estimation. J. Amer. Statist. Assoc. 102 (477), 359–378.

Grisvard, P. (1967). Caract´erisation de quelques espaces d’interpolation. Arch. Rational

Mech. Anal. 25, 40–63.

Grisvard, P. (2011). Elliptic problems in nonsmooth domains, Volume 69 of Classics in
Applied Mathematics. Society for Industrial and Applied Mathematics (SIAM), Philadel-
phia, PA.

Heaton, M. J., A. Datta, A. O. Finley, and et al. (2019). A case study competition among
methods for analyzing large spatial data. J. Agric. Biol. Environ. Stat. 24 (3), 398–425.

Herrmann, L., K. Kirchner, and C. Schwab (2020). Multilevel approximation of Gaussian

random ﬁelds: fast simulation. Math. Models Methods Appl. Sci. 30 (1), 181–223.

Hildeman, A., D. Bolin, and I. Rychlik (2021). Deformed SPDE models with an application
to spatial modeling of signiﬁcant wave height. Spat. Stat. 42, Paper No. 100449, 27.

Hofreither, C. (2021). An algorithm for best rational approximation based on barycentric

rational interpolation. Numer. Algorithms 88 (1), 365–388.

Horn, R. A. and C. R. Johnson (2013). Matrix analysis (Second ed.). Cambridge University

Press, Cambridge.

Khristenko, U., L. Scarabosio, P. Swierczynski, E. Ullmann, and B. Wohlmuth (2019).
Analysis of boundary eﬀects on PDE-based sampling of Whittle-Mat´ern random ﬁelds.
SIAM/ASA J. Uncertain. Quantif. 7 (3), 948–974.

Kirszbraun, M. D. (1934). ¨Uber die zusammenziehende und lipschitzsche transformationen.

Fund. Math. 22, 77–108.

Lindgren, F., D. Bolin, and H. Rue (2022). The SPDE approach for Gaussian and non-

Gaussian ﬁelds: 10 years and still running. Spat. Stat. 50, Paper No. 100599.

Lindgren, F. and H. Rue (2015). Bayesian spatial modelling with R-INLA. Journal of

Statistical Software 63 (19), 1–25.

Lindgren, F., H. Rue, and J. Lindstr¨om (2011). An explicit link between Gaussian ﬁelds and
Gaussian Markov random ﬁelds: the stochastic partial diﬀerential equation approach. J.
R. Stat. Soc. Ser. B Stat. Methodol. 73 (4), 423–498.

Lototsky, S. V. and B. L. Rozovsky (2017). Stochastic partial diﬀerential equations. Uni-

versitext. Springer, Cham.

Mat´ern, B. (1960). Spatial variation: Stochastic models and their application to some prob-
lems in forest surveys and other sampling investigations. Statens Skogsforskningsinstitut,
Stockholm. Meddelanden Fr˚an Statens Skogsforskningsinstitut, Band 49, Nr. 5.

28

R Core Team (2022). R: A Language and Environment for Statistical Computing. Vienna,

Austria: R Foundation for Statistical Computing.

Remez, E. Y. (1934). Sur la d´etermination des polynˆomes d’approximation de degr´e donn´ee.

Comm. Soc. Math. Kharkov 10 (196), 41–63.

Rue, H. and L. Held (2005). Gaussian Markov random ﬁelds, Volume 104 of Monographs
on Statistics and Applied Probability. Chapman & Hall/CRC, Boca Raton, FL. Theory
and applications.

Rue, H., S. Martino, and N. Chopin (2009). Approximate Bayesian inference for latent
Gaussian models by using integrated nested Laplace approximations. J. R. Stat. Soc.
Ser. B Stat. Methodol. 71 (2), 319–392.

Simpson, D., H. Rue, A. Riebler, T. G. Martins, and S. H. Sørbye (2017). Penalising model
component complexity: a principled, practical approach to constructing priors. Statist.
Sci. 32 (1), 1–28.

Stahl, H. R. (2003). Best uniform rational approximation of xα on [0, 1]. Acta Math. 190 (2),

241–306.

Stein, M. L. (1999). Interpolation of spatial data. Springer Series in Statistics. Springer-

Verlag, New York. Some theory for Kriging.

Strang, G. and G. Fix (2008). An Analysis of the Finite Element Method. Wellesley-

Cambridge Press.

Whittle, P. (1963). Stochastic processes in several dimensions. Bull. Inst. Internat.

Statist. 40, 974–994.

29

