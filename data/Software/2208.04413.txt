2
2
0
2

g
u
A
8

]

A
N
.
h
t
a
m

[

1
v
3
1
4
4
0
.
8
0
2
2
:
v
i
X
r
a

An automatic L1-based regularization method for the
analysis of FFC dispersion proﬁles with quadrupolar
peaks

G. Landia, G.V. Spinellia, F. Zama∗a, D. Chillura Martinob, P. Contec, P.
Lo Meob, V. Bortolottid

aDepartment of Mathematics, University of Bologna, Italy
bDepartment of Biological, Chemical and Pharmaceutical Sciences and Technologies,
University of Palermo, Italy
cDepartment of Agricultural, Food and Forest Sciences, University of Palermo, Italy
dDepartment of Civil, Chemical, Environmental, and Materials Engineering, University
of Bologna, Italy

Abstract

Fast Field-Cycling Nuclear Magnetic Resonance relaxometry is a non-de-

structive technique to investigate molecular dynamics and structure of sys-

tems having a wide range of applications such as environment, biology, and

food. Besides a considerable amount of literature about modeling and ap-

plication of such technique in speciﬁc areas, an algorithmic approach to the

related parameter identiﬁcation problem is still lacking. We believe that a ro-

bust algorithmic approach will allow a uniﬁed treatment of diﬀerent samples

in several application areas. In this paper, we model the parameters iden-

tiﬁcation problem as a constrained L1-regularized non-linear least squares

problem. Following the approach proposed in [Analytical Chemistry 2021

93 (24)], the non-linear least squares term imposes data consistency by de-

composing the acquired relaxation proﬁles into relaxation contributions as-

sociated with 1H − 1H and 1H − 14N dipole-dipole interactions. The data

Preprint submitted to Elsevier

August 10, 2022

 
 
 
 
 
 
ﬁtting and the L1-based regularization terms are balanced by the so-called

regularization parameter.

For the parameters identiﬁcation, we propose an algorithm that computes,

at each iteration, both the regularization parameter and the model parame-

ters. In particular, the regularization parameter value is updated according

to a Balancing Principle and the model parameters values are obtained by

solving the corresponding L1-regularized non-linear least squares problem by

means of the non-linear Gauss-Seidel method. We analyse the convergence

properties of the proposed algorithm and run extensive testing on synthetic

and real data. A Matlab software, implementing the presented algorithm, is

available upon request to the authors.

Keywords: parameter identiﬁcation, L1 regularization, non-linear

Gauss-Seidel method, Fast Field Cycling NMR relaxation, Free-model,

quadrupole relaxation enhancement.

1. Introduction

Fast Field-Cycling (FFC) Nuclear Magnetic Resonance (NMR) relaxom-

etry is a non-destructive magnetic resonance technique which is particularly

useful in revealing information on slow molecular dynamics, which can only

be carried out at very low magnetic ﬁeld strengths. Standard NMR relax-

ation experiments are only performed in a relatively large ﬁxed magnetic

ﬁeld that determines the resonance frequency of the molecules under investi-

gation. Conversely, FFC-NMR relaxometry [1, 2] provides relaxation studies

in a remarkably wide frequency range from approximately 1 kHz to 120 MHz.

The FFC technique allows one to evaluate how the rate R1 (also referred to

2

as longitudinal relaxation rate) of a sample varies by changing the strength

of an applied magnetic ﬁeld, so forming the NMR Dispersion (NMRD) pro-

ﬁles. Therefore, FFC-NMR relaxometry measurements can detect the motion

across a wide range of timescales (from millisecond to picoseconds) within

an experiment. In addition, frequency-dependent relaxation studies have the

exceptional potential to reveal the underlying mechanisms of molecular mo-

tion (not just its timescale). Spin relaxation theory represents relaxation

rates as linear combinations of spectral density functions (Fourier transform

of the time correlation function) characterising the motional frequencies and

their intensities present in the correlation function [3]. However, complex

spins dynamical interactions may occur such as the Quadrupole Relaxation

Enhancement (QRE) due to their intramolecular magnetic dipolar coupling

with quadrupole nuclei of arbitrary spins S ≥ 1 [4, 5]. In the case of nitrogen-

containing systems, for instance, the presence of QRE is represented by local

maxima or peaks of the R1 proﬁles due to 1H − 14N interactions. The po-

sitions of the peaks depend on the quadrupole parameters which are deter-

mined by the electric ﬁeld gradient tensor at the 14N position. Consequently,

even subtle changes in the electronic structure around 14N reﬂect in changes

of the position and shape of the quadrupole peaks. The QRE is a very

sensitive ﬁngerprint of molecular arrangement which has a wide range of ap-

plications ranging from environmental science [6], the study of ionic liquids,

proteins [5] and food [7, 8].

Despite the consistent literature about the modeling of relaxation rate R1

of protons ﬂuids within a conﬁned environment (see for instance [9, 10, 11])

3

and applications of FFC-NMR (see for example [12] and references therein),

the study of a computational framework for the automatization of the FFC-

NMR analysis is still missing. To the authors’ best knowledge, only P. Lo Meo

et al.

[13] propose a computational approach where, following the “model-

free” approach introduced by [14, 15], the relaxation rate R1 is represented

as the sum of a constant term (oﬀset) accounting for very “fast” molecular

motion, a term describing proper 1H − 1H relaxation as an integral function

of the correlated time distribution function, and a non-linear term depending

on several characteristic parameters related to the QRE occurence.

Therefore, the analysis of the NMRD proﬁles requires the solution of a

parameter identiﬁcation problem dealing with the estimation of the oﬀset

term, the correlation time distribution and the QRE parameters.

In the

present contribution, we formulate the parameter identiﬁcation problem as

a regularized non-linear least squares problem with box constraints and we

propose a completely automatic strategy for its solution. In particular, the

objective function contains a non-linear least squares term, imposing data

consistency, and a L1-based regularization term, accounting for the known

sparsity of the correlation time distribution function. These terms are bal-

anced by the so-called regularization parameter. Physical constraints on the

unknown parameters lead to bound constraints in the optimization problem.

The parameter identiﬁcation problem crucially depends on the regulariza-

tion parameter whose value has to be properly identiﬁed in order to perform

a meaningful NMRD analysis. Therefore, our mathematical model depends

on several parameters: the NMRD parameters (i.e. the oﬀset, the correlation

time distribution), the QRE parameters, and the regularization parameter.

4

The estimation of all these parameters is carried out by an iterative process

where, at each iteration, the regularization parameter is computed according

to a balancing principle [16]. The NMRD and QRE parameters are esti-

mated solving the corresponding constrained optimization problem by the

constrained two-blocks non-linear Gauss-Seidel (GS) method [17, 18], since

the unknown NMRD and QRE parameters can be naturally partitioned into

two blocks. In the GS method, the objective function is iteratively minimized

with respect to the oﬀset and the correlation time distribution while the QRE

parameters are held ﬁxed; then, ﬁxed the updated values for the oﬀset and

the correlation time distribution, the objective is minimized with respect to

the QRE parameters. The ﬁrst subproblem involves solving a constrained

linear least squares problem, obtained by the model-free approach [13], with

an L1 regularization term. The second subproblem requires the solution of a

constrained non-linear least squares problem.

This computational approach, separating the contribution due to the oﬀ-

set and the relaxation distributions from the parameters of the quadrupolar

relaxation, is able to provide a very accurate ﬁt not only of the overall NMRD

proﬁle, but also of the local maxima due to the QRE.

Besides analysing the convergence of the proposed approach, we tested it

on synthetic and real data aiming to illustrate the algorithm eﬃciency and

its robustness to data noise.

The main contributions of the present paper can be summarized as fol-

lows.

• We formulate the problem of identifying the oﬀset, the correlation time

5

distribution and the QRE parameters from the NMRD proﬁles as a

L1-regularized non-linear least squares problem with box constraints

related to physical properties of the parameters.

• We derive an automatic procedure, named AURORA (AUtomatic L1-

Regularized mOdel fRee Analysis) for the identiﬁcation of all the pa-

rameters of mathematical model, i.e, the NMRD parameters (the oﬀset

term, the correlation time distribution), the QRE parameters and the

regularization parameter and we analyse its convergence properties.

• We prove the robustness of the proposed approach to data noise by

testing it on synthetic and real NMRD proﬁles.

The remainder of this paper is organised as follows. In section 2 we present

the parameter identiﬁcation problem; in section 3 we introduce the solution

method, analyse its properties and present the AURORA algorithm. The

results from several numerical experiments are reported and discussed in

section 4. Finally, in section 5, we draw some conclusions.

2. The parameter identiﬁcation problem

In the following, we ﬁrst describe the continuous model for NMRD pro-

ﬁles, then we derive its discretization and, ﬁnally, we present the parameter

identiﬁcation problem.

6

2.1. The continuous model of NMRD proﬁles

Following the model-free approach, [13] proposes a model for the NMRD

proﬁles R1 made of three components:

R1(ω) = R0 + RHH(ω) + RN H(ω)

(1)

where R0 is nonnegative oﬀset keeping into account very fast molecular mo-

tions, the term RHH(ω) describes the correlation distribution function f (τ )

as:

RHH(ω) =

(cid:90) ∞

(cid:20)

0

τ
(1 + (ωτ )2)

+

4τ
(1 + 4(ωτ )2)

(cid:21)

f (τ ) dτ

(2)

where τ is the correlation time, i.e., the average time required by a molecule to

rotate one radiant or to move for a distance as large as its radius of gyration.

The term RHN (ω) describes the occurrence of the quadrupolar peaks [12]:

RHN (ω) = C HN (cid:16)

1

3 + sin2(Θ) cos2(Φ),











τQ
1 + (ω − ω−)2τ 2
Q
τQ
1 + (ω − ω+)2τ 2
Q

τQ
1 + (ω − (ω+ − ω−))2τ 2
Q

where

+

+

+

(cid:17)

·

1

3 + cos2(Θ)


1

3 + sin2(Θ) sin2(Φ),
τQ
1 + (ω + ω−)2τ 2
Q
τQ
1 + (ω + ω+)2τ 2
Q

τQ
1 + (ω + (ω+ − ω−))2τ 2
Q









(3)

i) C HN refers to “the gyromagnetic ratios and the average interaction

distance of the nuclei”;

ii) Θ and Φ are two angles accounting for “ the orientation of the 1H −14

N dipole-dipole axis with respect to the principal axis system of the

7

electric ﬁeld gradient at the position of 14N ”;

iii) τQ is the correlation time for the 1H − 14N quadrupolar interaction;

iv) ω− and ω+ are the angular frequency position of the peaks on the

NMRD proﬁles.

(We remark that in (3) the · operator denotes the scalar product of two

vectors.)

2.2. The discrete model for NMRD proﬁles

Before describing the discretization of the continuous model (1), let us

introduce the following notation. Let ω ∈ Rm be the vector of the m Larmor

angular frequency values (ω = 2πν, ν in Mhz) at which R1 is evaluated,
and let y ∈ Rm be the corresponding observations vector, i.e., yi = R1(ωi),
i = 1, . . . , m. Let f ∈ Rn be the vector obtained by sampling f (τ ) in n
logaritmically equispaced values τ1, . . . , τn. Finally, let ψ ∈ R6 be such that
ψ1 ≡ C HN , ψ2 ≡ sin2(Θ), ψ3 ≡ sin2(Φ), ψ4 ≡ τQ, ψ5 ≡ ω−, ψ6 ≡ ω+. The

discrete model, obtained by discretizing the equations (2) and (3), is

y = F(f , ψ, R0) ≡ F1(f ) + F2(ψ) + R0

(4)

where F : Rn+6+1 → Rm. The ﬁrst term F1 : Rn → Rm, only depending on

f , is a linear function of f deriving from the discretization of the integral for

RHH in (2):

F1(f ) ≡ Kf , with K ∈ Rm×n,

f ∈ Rn

(5)

8

and

Ki,j =

τj
(1 + (ωiτj)2)

+

4τj
(1 + 4(ωiτj)2)

,

i = 1, . . . , m, j = 1, . . . , n.

In a typical FFC-NMR experiment, m (cid:28) n.

The second term F2(ψ) : R6 → Rm represents the quadrupolar compo-

nent RHN (3) and only depends on the parameters ψj, j = 1, . . . , 6:

(cid:16)

(F2(ψ))i = ψ1









for i = 1, . . . , m.

(cid:17)

·

1
3 + ψ2 · ψ3,

1
3 + ψ2(1 − ψ3),
ψ4
1 + (ωi − ψ5)2ψ2
4
ψ4
1 + (ωi − ψ6)2ψ2
4

1
3 + (1 − ψ2)
ψ4
1 + (ωi + ψ5)2ψ2
4
ψ4
1 + (ωi + ψ6)2ψ2
4

ψ4
1 + (ωi − (ψ6 − ψ5))2ψ2
4

ψ4
1 + (ωi + (ψ6 − ψ5))2ψ2
4)

+

+

+










(6)

The last term in F is the constant parameter R0 ≥ 0 representing the

oﬀset in the NMRD curve.

2.3. The parameter identiﬁcation problem

Mathematically, the problem of identifying the parameters f , ψ and R0

from the observations y is an ill-conditioned non linear inverse problem (4).

In order to stabilize the parameter identiﬁcation procedure, we use a regular-

ization approach adding some a priori information on the unknown parame-

ters. In particular, we use L1 regularization to induce sparsity of f since the

distribution f (τ ) is known to be a sparse function with only a few non-null

terms. Therefore, the parameter identiﬁcation problem is reformulated as

9

the following optimization problem

min
f ,ψ,R0

(cid:107)y − (F1(f ) + F2(ψ) + R0)(cid:107)2

2 + λ(cid:107)f (cid:107)1

s.t.

f ≥ 0,

ψ ∈ Bψ,

R0 ≥ 0,

(7)

where the set Bψ deﬁnes the box constraints on ψ:

Bψ = (cid:8)ψ : ψ1 ∈ [0, ¯C]; ψ2, ψ3 ∈ [0, 1]; ψ4 ∈ [0, ¯τ ]; ψ5, ψ6 ∈ [ω(cid:96), ωu](cid:9).

(8)

The bounds on the parameters ψi, i = 1, . . . , 6, can be derived from the

physical properties of the system and from the data y; a deeper discussion

on this topic will be given in the Section 4.

The regularization parameter λ > 0 weights the contribution of the L1

regularization term; the parameters (f , ψ, R0) obtained by solving (7) depend

critically on the value of λ.

3. The solution method

The presented parameter identiﬁcation method is an iterative procedure

where, at each iteration, a value of the regularization parameter λ is pro-

vided and the corresponding parameters (fλ, ψλ, R0,λ) are computed by solv-

ing problem (7). The constrained two-blocks non-linear Gauss-Seidel (GS)

method [17, 18] is used for its solution. In the following, we ﬁrstly describe

the GS method and recall its convergence properties, then we introduce the

iterative procedure for the regularization parameter computation, and, ﬁ-

10

nally, we draw the overall parameter identiﬁcation procedure.

3.1. The constrained two-blocks Gauss-Seidel method

In this subsection, we describe the GS method used for the solution of the

constrained optimization problem (7) for a ﬁxed value of the regularization

parameter λ. To this end, we partition the unknowns of (7) into two blocks

such that the data ﬁtting term is linear with respect to the ﬁrst block and non-

linear with respect to the second block. Therefore, we reformulate problem

(7) as follows:

min
x1,x2

s.t.

where

and

g(x1, x2) = (cid:107)y − Kex1 − F2(x2)(cid:107)2

2 + λ(cid:107)x1(cid:107)1 + η(cid:107)x1(cid:107)2
2

x1 ∈ X1,

x2 ∈ X2,

x1 ≡ (f , R0), x2 ≡ ψ

X1 = {x1 ≥ 0}, X2 ≡ Bψ

(cid:104)

Ke =

K 1

(cid:105)

∈ Rm×(n+1).

(9)

(10)

(11)

(12)

The last L2-based penalty term η(cid:107)x1(cid:107)2

2 in the objective function has been

introduced to ensure that KT

e Ke + ηI is a deﬁnite positive matrix; to this
and, a small value for η, as η = 10−10 for example, can be ﬁxed. Moreover,

observe that in (9), the parameter R0 has been included in the L1-based

penalty term.

11

The closed subsets X1 ⊆ Rn+1 and X2 ⊆ R6 are both convex; the objec-

tive function g(x1, x2) is continuous and it is convex with respect to x1 for

ﬁxed x2, but it is not convex with respect to x2 for ﬁxed x1. However, since

KT

e Ke + ηI is deﬁnite positive and X2 is bounded, it is easy to show that g

is coercive on X1 × X2.

Deﬁnition 3.1. A function g : Rq → R is called coercive in X if, for every

sequence {x(k)} ∈ X such that (cid:107)x(k)(cid:107) → ∞, we have

g(x(k)) = +∞

lim
k→∞

Proposition 3.1. The function g : Rn+1+6 → R such that

g(x1, x2) = (cid:107)y − Kex1 − F2(x2)(cid:107)2

2 + λ(cid:107)x1(cid:107)1 + η(cid:107)x1(cid:107)2
2

is coercive in X1 × X2.

Proof. The function g can be rewritten as

g(x1, x2) = xT

1 (KT

e Ke + ηI)x1 + 2xT

1 KT

e (F2(x2) − y) + (cid:107)F2(x2) − y(cid:107)2 + λ(cid:107)x1(cid:107)1

e Ke + ηI is positive deﬁnite. Let {(x(k)

1 , x(k)

2 )} be a sequence in

where KT
X1 × X2 such that limk→∞ (cid:107)(x(k)

1 , x(k)

2 )(cid:107) = ∞. Since X2 is bounded, we have

lim
k→∞

(cid:107)x(k)

1 (cid:107) = ∞ and

lim
k→∞

(cid:107)x(k)

2 (cid:107) < ∞.

(13)

12

Let µ > 0 be the smallest eigenvalue of KT

e Ke + ηI. It holds

g(x(k)

1 , x(k)

2 ) ≥ µ(cid:107)x(k)

e (F2(x(k)

2 ) − y)(cid:107)(cid:107)x(k)

1 (cid:107) + λ(cid:107)x(k)

1 (cid:107)+

1 (cid:107)2 − 2(cid:107)KT
e (F2(x(k)

2 ) − y)(cid:107)2

+ (cid:107)KT
(cid:16)

≥

µ(cid:107)x(k)

1 (cid:107) − 2(cid:107)KT

e (F2(x(k)

2 ) − y)(cid:107) + λ

(cid:17)

(cid:107)x(k)
1 (cid:107)

From (13) we have µ(cid:107)x(k)

1 (cid:107) − 2(cid:107)KT

e (F2(x(k)

2 ) − y)(cid:107) + λ > 0 for suﬃciently

large k, then

lim
k→∞

g(x(k)

1 , x(k)

2 ) = +∞

Continuity and coerciveness ensure the existence of at least one global

minimizer of g(x1, x2) in X1 × X2 [19].

In the constrained two-blocks Gauss-Seidel method, at each iteration, the

objective function is minimized with respect to each of the block coordinate

vectors xi over the subsets Xi, i = 1, 2, as summarized in Algorithm 1, where

the convergence condition is:

|g(x(k)

1 , x(k)

2 ) − g(x(k−1)

1

, x(k−1)
2

)| ≤ T olGS|g(x(k)

1 , x(k)

2 )|.

(14)

We observe that the GS method is well deﬁned since each subproblem

has solutions. Indeed, the function g is strictly convex with respect of x1 and

hence there exist at most one global minimum of f over X1 for ﬁxed x2. On

the other hand, Weierstrass’s theorem guarantees the existence of at least

one global minimum of g over X2 for ﬁxed x1 since g is continuous and X2

13

1 , x(0)
2 )

Algorithm 1 Constrained two-blocks non-linear Gauss-Seidel method
1: function GS(x(0)
2:
3:
4:
5:

Set k = 0 and x(0) = (x(0)
repeat

k = k + 1
Set x(k)

1 , x(0)
2 ).

g(z, x(k−1)
2

)

6:

7:

1 ∈ arg min
z∈X1
2 ∈ arg min
z∈X2

Set x(k)

g(x(k)

1 , z)

until convergence condition (14)
return (x(k)

1 , x(k)
2 )

8:
9: end function

is a closed and bounded set.

For general nonconvex, constrained problems, convergence of sequences

generated by the GS method to critical points has been proved in [18]. For

the reader’s convenience, we report here the main convergence result for the

GS method and we refer to [18] for its proof.

Theorem 3.2. Consider the problem

min
x1,x2

s.t.

g(x1, x2)

x1 ∈ X1,

x2 ∈ X2,

(15)

where g is a continuously diﬀerentiable function and the subsets Xi are closed,
nonempty and convex for i = 1, 2. Suppose that the sequence {(x(k)

1 , x(k)

2 )}

generated by the two-blocks GS method has limit points. Then, every limit
point of {(x(k)

2 )} is a critical point of the problem.

1 , x(k)

We have already observed that the objective function g of (9) is coercive;

since the level sets of continuous coercive functions are compact, the sequence

14

{(x(k)

1 , x(k)

2 )} generated by the GS method has limit points (eventually, it has

a convergent subsequence); hence, the GS method converges to critical points

of (9).

We conclude this subsection with a remark on the solution of the two

constrained subproblems to be solved at each iteration of algorithm 1. The

ﬁrst subproblem at step 3 is a L1-regularized least squares problem with

nonnegativity constraints:

min
z

(cid:107)w − Kez(cid:107)2

2 + λ

m+1
(cid:88)

zi

s.t.

zi ≥ 0,

i=1
i = 1, . . . , m + 1

(16)

where w = y − F2(x(k)

2 ). For its solution, we use the truncated Newton

interior-point method described in [20].

The second subproblem at step 4 is a bound constrained non-linear least

squares problem:

min
z
s.t.

(cid:107)F2(z) − w(cid:107)2

z ∈ X2

(17)

where w = Kex(k+1)

1

− y. For its solution, we use the Newton Projec-

tion method [21, 22] where the Hessian matrix is approximated as in the

Levenberg-Marquardt method [23] since the Jacobian of F2 is ill-conditioned.

3.2. Computation of the regularization parameter λ

In order to correctly analyse the NMRD proﬁles, it is necessary to choose

an appropriate value for the regularization parameter λ. Even if several pa-

rameter selection rules have been proposed in the literature for L2-regularized

15

minimization problems (see [24, 25, 26] for a theoretical discussion of such

rules), the case of L1-based regularization still remains largely unexplored.

In [27, 28], the discrepancy principle has been investigated for nonsmooth

regularization. This principle is diﬃcult to be realized since it requires the

prior knowledge of the noise norm and a solution of the discrepancy equation

is not guaranteed to exist. In [16], the Balancing Principle (BP) has been

proposed where the regularization parameter is selected by balancing, up to

a multiplicative factor γ, the data ﬁdelity and the regularization term, i.e,:

γλ(cid:107)x1(cid:107)1 = (cid:107)y − Kex1 − F2(x2)(cid:107)2

2 + η(cid:107)x1(cid:107)2
2

(18)

The regularization properties of the BP has been deeply investigated and a

convergent ﬁxed-point iterative scheme for its realization has been proposed

in [16]. We set γ = 1 which gives the following rule for the regularization

parameter selection:

λ =

(cid:107)y − Kex1 − F2(x2)(cid:107)2

2 + η(cid:107)x1(cid:107)2
2

(cid:107)x1(cid:107)1

.

3.3. The parameter identiﬁcation method

The proposed iterative method for the identiﬁcation of both the NMRD

parameters f , ψ and R0 and the regularization parameter λ is outlined in

algorithm 2 where, given an initial guess for λ, at each iteration, the NMRD

parameters are computed by solving problem (7) by the GS method, and

the regularization parameter value is updated by the BP until the following

16

convergence condition is met:

|λ(k+1) − λ(k)| ≤ T olλ|λ(k)|, T olλ > 0.

(19)

We refer to this method as AURORA (AUtomatic L1-Regularized mOdel

fRee Analysis).

Algorithm 2 AURORA

1: Set k = 0, η = 10−10 and choose a starting guess λ(0).
2: repeat

3:

4:

k = k + 1
NMRD and QRE parameters update

By algorithm 1 compute (x(k)

2 , x(k)

2 ) = GS(x(k−1)

1

, x(k−1)
2

) i.e.

(x(k)

1 , x(k)

2 ) ∈ arg min
x1∈X1
x2∈X2

(cid:107)y − Kex1 − F2(x2)(cid:107)2

2 + λ(k)(cid:107)x1(cid:107)1 + η(cid:107)x2(cid:107)2
2

5:

Regularization parameter update

λ(k+1) =

(cid:107)y − Kex(k)

2 )(cid:107)2

2 + η(cid:107)x(k)

2 (cid:107)2
2

1 − F2(x(k)
(cid:107)x(k)
1 (cid:107)1

6: until convergence condition (19)
1 and ψ = x(k)
7: return (f , R0) = x(k)

2

(cid:46) Result (f , R0, ψ)

Following the analysis of the BP performed in [16], algorithm AURORA

can be viewed as a ﬁxed point-like scheme for the problem

(x∗

1, x∗

λ∗ =

2) = arg min
x1∈X1
x2∈X2
1 − F2(x∗
(cid:107)x∗
1(cid:107)1

(cid:107)y − Kex∗

(cid:107)y − Kex1 − F2(x2)(cid:107)2

2 + λ∗(cid:107)x1(cid:107)1 + η(cid:107)x1(cid:107)2
2,

2)(cid:107)2

2 + η(cid:107)x∗

1(cid:107)2
2

.

(20)

17

The monotone convergence of the sequence {λ(k)} generated by the ﬁxed

point scheme has been proved in [16] when λ(0) is chosen in an interval con-

taining only one solution of equation (18).

4. Results and Discussion

In this section, we present and discuss the results obtained by a set of

numerical experiments to assess the accuracy, robustness and eﬃciency of

the proposed algorithm. In paragraph 4.1, we describe the experimental set-

ting. In paragraph 4.2, we test AURORA on a synthetic NMRD proﬁle R1

computed by the model (1) with assigned values of the parameters ψ, f and

R0. We evaluate computational eﬃciency and accuracy of AURORA com-

paring it with some algorithms available in the Matlab optimization Toolbox.

Moreover, we investigate the algorithm robustness in presence of data noise.

Then, in paragraph 4.3, we report the results of the analysis of NMRD proﬁles

from two diﬀerent samples: Dry Nanosponge (DN) and Parmigiano-Reggiano

(PR) cheese.

4.1. Numerical Experimental setting

All numerical computations are carried out using Matlab R2021b on a

laptop equipped with 2.9 GHz Intel Core i7 quad-core processor and 16 GB

2133 MHz RAM.
For all tests, the values ¯C and ¯τ in the constraints set Bψ (8) are set equal to
a value large enough so that the intermediate solutions ψ(k)
4 never
1
reach such bounds. In our tests ¯C = ¯τ = 100 are suitable values. The inter-

and ψ(k)

val [ω(cid:96), ωu] in (8), representing the region where R1 interrupts its decaying

behaviour due to QRE, is deﬁned by inspection of the NMRD proﬁle.

18

The starting guess for the parameter ψ(0)

1 ≡ C HN is obtained by the literature

[5]:

C HN =

(cid:18) µ0
4π

2
3

γHγN (cid:126)
r3
N H

(cid:19)2

≈ 0.18

(cid:105)

(cid:104) µs
s2

(21)

where the value of the physical constants is reported in table 1. Concerning

Constant
µ0
γH
γN
(cid:126)
rHN

Description
permeability of vacuum
1H gyromagnetic factor
14N gyromagnetic factor
reduced Planck’s constant
1H −14 N inter-spin distance

Value
10−7 T 2J −1m3
2.577 106 T −1s−1
3.078 106 T −1s−1
1.05472 10−34 J s
1.4 10−10 m

Table 1: Characteristic constants for C HN in (21).

2 ≡ sin2 Θ(0), ψ(0)

the quadrupolar parameters, ψ(0)

3 ≡ sin2 Φ(0), the initial
values are equal to the mean of the corresponding upper and lower bounds
in Bψ, i.e. 1/2. The initial value of ψ(0)
5 ≡ ω(0)
− ,
and ψ(0)

4 ≡ τQ, is set to 1, while ψ(0)

+ are deﬁned as follows:

6 ≡ ω(0)

ψ(0)

5 = ω(cid:96) +

1
4

|ωu − ω(cid:96)|, ψ(0)

6 = ωu −

1
4

|ωu − ω(cid:96)|.

The computed results are evaluated by the Mean Squared Error (MSE)

MSE =

(cid:107)R1 − F(f , ψ, R0)(cid:107)2
m

,

and the Parameter Relative Error (PRE):

PRE(x) =

(cid:107)xexact − xcomputed(cid:107)2
(cid:107)xexact(cid:107)2

(22)

19

with x representing either the vector f or the scalars R0, ψi, i = 1, . . . , 6.

The components of the vector ψ are referenced by the name in the physical

model (3), according to the mapping introduced in section 2.2, and reported

in table (2) for convenience. All the tests apply algorithm 2 with T olλ = 10−2

C HN
ψ1

Φ
√
asin(

τQ ω− ω+
ψ2) asin((cid:112)ψ3)) ψ4 ψ5 ψ6

Θ

Table 2: Quadrupolar parameters mapping.

in (19) and algorithm 1 with T olGS = 10−6 in (14).

The computational cost is evaluated in terms of number of execution time.

4.2. Synthetic test Problem

To investigate the properties of AURORA, we ﬁrst test it on the syn-

thetic NMRD proﬁle R1 represented in ﬁgure 1(a), and obtained by setting

the parameters of model (1) as in the second column of table 3, with the

distribution function f ∗ represented in red in ﬁgure 2(a). Throughout the

paragraph we use the frequencies ν instead of the angular frequencies ω, i.e.

ν− ≡ ω−/(2π) and ν+ ≡ ω+/(2π).

reference
3.69
18.84
0.96
1.09
0.57
2.15
2.87

computed
3.6868
18.8453
0.9554
1.0901
0.5696
2.1502
2.8696

PRE
7.0267 10−4
6.1449 10−5
8.5033 10−6
6.1449 10−5
6.9199 10−4
5.7363 10−6
1.1316 10−6

R0
C HN
τQ
Θ
Φ
ν−
ν+

Table 3: Model parameters: reference (second column), AURORA computed values (third
column) and PRE (fourth column).

20

Figure 1: Synthetic sample. (a) Full NMRD proﬁle (b) Zoom of NMRD proﬁle in the
reference interval [ν(cid:96), νu] represented by the left and right green vertical lines. Left and
right black vertical lines represent the values ψ(0)

6 /(2π) respectively.

5 /(2π), ψ(0)

The accuracy of the computed results can be appreciated in the correla-

tion distribution f and R1 curves shown in ﬁgure 2. To test the convergence

Figure 2: Synthetic sample. (a) Reference (red) and computed correlation distribution
(blue). (b) Reference and computed R1 proﬁles.

behaviour we evaluate the PRE and MSE at each step of the GS method in al-

gorithm 1. Figure 3(a) shows the the behaviour of the relative errors for each

parameter (f , R0, C HN , Φ, Θ, τQ, ν−, ν+) compared to their reference values.

The convergence to reference parameters values is initially non monotonic for

21

most parameters with the exception of τQ and ν−. On the contrary, MSE has

monotonic decrease as reported in ﬁgure 3(b). The values of the computed

Figure 3: Synthetic R1. (a) PRE values per iteration (b) MSE values per iteration.

parameters and relative errors reported in the third and fourth columns of

table 3 conﬁrm the excellent accuracy obtained by the proposed algorithm.

The computed value of the regularization parameter is λ∗ = 1.216 10−9 with

computation time of 115.15 s.

Although the convergence of the update formula (18) depends on the initial

guess λ(0), we experimentally found convergence for λ(0) in a quite large in-

terval ([10−16, 100]). In ﬁgure 4 we represent the sequences λ(k), k = 0, . . . , 15

obtained by algorithm 2 with λ(0) ∈ {10−16, 10−6, 10−4, 10−2, 100}. Optimal

convergence (k = 1) is obtained for 10−16 ≤ λ(0) ≤ 10−4 while λ(0) > 10−4

causes a slight increase of the iterations number, still preserving the conver-

gence up to λ(0) = 1, which is usually considered as a standard starting guess.

Therefore, to keep computations eﬃcient, λ(0) = 10−6 is used throughout the

numerical experiments of this section.

22

Figure 4:
(cid:8)10−16, 10−6, 10−4, 10−2, 100(cid:9).

Synthetic R1.

Sequence {λ(k)}, obtained by AURORA with λ(0) ∈

Comparison with Matlab solvers. With this test problem, we aim to com-

pare AURORA with several methods implemented by the Matlab function

fmincon:

such as interior-point (ip), the active-set (as), the sequential

quadratic programming (sqp) and trust-region-reﬂective (trr) methods. We

highlight that AURORA automatically computes the value of the regulariza-

tion parameter λ while the Matlab function fmincon solves the optimization

problem (7) for a ﬁxed value of λ. Therefore, we compare the GS algorithm

1 with ip, as, sqp trr for the same ﬁxed value λ = 1. 10−8, which we

heuristically found to be a good value for all the methods.

Besides the automatic computation of the regularization parameter λ,

AURORA splits the unknown parameters in two blocks and alternatively

minimizes the objective function for (R0, f ), the oﬀset and correlation distri-

bution, and for the quadrupolar parameters ψ. Two diﬀerent methods are

used for the solution of the corresponding sub-problems. On the contrary,

fmincon computes all the parameters applying the same method.

Table 4 shows the PRE and MSE values (last row) obtained by AURORA

23

(second column) and by the Matlab solvers, highlighting the smallest values.

The distribution f computed by sqp is shown in ﬁgure 5. We observe that

Parameter
f
R0
C HN
Θ
Φ
τQ
ν−
ν+
M SE

AURORA
4.2834 10−1
7.0032 10−4
5.8238 10−5
6.9108 10−4
8.7093 10−6
1.5660 10−4
5.7679 10−6
1.1391 10−6
2.8131 10−6

ip
1.5509
9.9629 10−1
4.2908
6.5929 10−2
5.5535 10−1
9.9228 10−1
4.0856 10−1
5.5197 10−2
9.1906

PRE
active-set
1.4497
1.0000
9.6353 10−1
7.7862 10−2
2.1372
3.1584 101
2.2756 10−1
3.3362 10−2
9.0766

sqp
1.3020
2.7930 10−1
1.5045 10−5
7.2072 10−4
2.6548 10−5
1.8903 10−4
5.6228 10−6
1.2084 10−6
3.1658 10−6

trr
8.5279 10−1
1.3671 10−1
1.1591 10−2
1.5758 10−2
7.2619 10−3
1.1033 10−2
5.9438 10−5
1.8516 10−5
2.8289 10−3

Table 4: Parameter relative errors and MSE of AURORA and methods implemented by
the Matlab function fmincon.

Figure 5: Correlation time distribution f computed by sqp method.

AURORA has globally superior accuracy both in data ﬁtting and parameter

estimation. Only sqp has MSE value similar to AURORA (3.1658e − 06

compared to 2.8131e − 06), and a slightly better PRE for parameters C HN

and ν−, but the amplitude distribution in ﬁgure 5 shows too many spurious

peaks.

24

Test with noisy data. In this paragraph we test the algorithm robustness

to data perturbations by computing noisy data yδ ∈ Rm from a random

uniformly distributed vector v ∈ Rm with values in the interval [−1, 1] s.t.

yδ
i = yi(1 + δvi), i = 1, . . . , m

and consider the cases δ = 1%, 5%, 10%. Computing 500 noisy samples yδ
j

we run AURORA and compare the errors on the estimated parameters as

well as reconstructed NMRD proﬁles.

For the noise values δ = 1%, 5%, 10%, we compute the mean PRE for each

parameter and represent the mean values in the bar plot shown in ﬁgure 6

together with the product C HN · τQ. The mean PRE and MSE are reported

Figure 6: Mean parameter values computed by 500 noisy NMRD proﬁles with noise δ =
1%, 5%10%.

in table 5. The computed R1 curves and the zoom in the QRE interval are

shown in ﬁgures 7,8 and 9 for δ = 1%, 5%, 10% respectively.

In ﬁgure 6, we observe that data noise aﬀects mainly C HN , τQ and Φ

25

1%
5.9019 10−1
f
3.6393 10−2
R0
3.3625 10−2
C HN
2.3023 10−2
Θ
3.5151 10−2
Φ
4.4998 10−2
τQ
4.3917 10−3
ν−
3.0889 10−3
ν+
MSE 1.5980 10−1

PRE
5%
1.1816
1.6726 10−1
2.7021 10−1
1.0678 10−1
4.0280 10−1
1.8862
4.8712 10−2
3.8712 10−2
3.1441

10%
1.4509
1.8099 10−1
4.7742 10−1
2.1726 10−1
6.5910 10−1
1.1095 101
7.2441 10−2
5.6856 10−2
1.0055 101

Table 5: Mean PRE and MSE on 500 noisy NMRD proﬁles with δ = 1%, 5%, 10%.

Figure 7: Fit of NMRD obtained from 500 noisy Synthetic NMRD curves with noise
δ = 1%. (a) Light gray: 500 ﬁtted R1 curves, Red line: Reference NMRD curve. Blue
line: average over 500 ﬁtted R1 values. (b) zoom in QRE interval.

values. However, considering the value of the product C HN τQ, represented

by the second group in ﬁgure 6, we see that the value is preserved when

δ = 1%, 5%. This feature is a physical characteristic and allows us to consider

accurate the related parameters.

Although the average MSE increase with data noise, the computed aver-

age R1 curves show a very good agreement to the reference NMRD proﬁles

26

Figure 8: Fit of NMRD obtained from 500 noisy Synthetic NMRD curves with noise
δ = 5%. (a) Light gray: 500 ﬁtted R1 curves, Red line: Reference NMRD curve. Blue
line: average over 500 ﬁtted R1 values. (b) zoom in QRE interval.

Figure 9: Fit of R1 obtained from 500 noisy synthetic NMRD proﬁles with noise δ = 10%.
(a) Light gray: 500 ﬁtted R1 curves, Red line: Reference NMRD curve. Blue line: average
over 500 ﬁtted R1 values. (b) zoom in QRE interval.

(ﬁgures 7, 8 and 9). The QRE is well reproduced even with high noise (ﬁgures

7(b), 8(b) and 9(b)).

4.3. NMRD proﬁles from FFC measures

In this paragraph we consider the NMRD proﬁles obtained from two

diﬀerent materials described in [13].

• A sample of 24-month aged Parmigiano-Reggiano (PR) cheese. The

27

NMRD proﬁle represented in ﬁgure 10(a) has m = 48 values with

conﬁdence intervals ranging from ±0.35% to ±3.07% of the value. The

quadrupolar peaks, represented in ﬁgure 11(a), correspond to frequency

values ν− = 2.1 and ν+ = 2.8 of values R1− = 32.2 s−1 and R1+ =

30.7 s−1 respectively.

• Dry nanosponge (DN). In this case the NMRD proﬁle represented in

ﬁgure 10(b) has m = 44 values with conﬁdence intervals ranging from

±0.47% to ±1.54% of the value. The quadrupolar peaks, represented

in ﬁgure 10(b), correspond to frequency values ν− = 2.4991 M Hz and

ν+ = 3.1488 M Hz of values R1− = 104.85 s−1 and R1+ = 104.85 s−1

respectively.

(a)

(b)

Figure 10: NMRD proﬁles. (a) Parmigiano Reggiano sample. (b) Dry nanosponge sample.

The proposed AURORA method has been used to compute the model

parameters reported in table 6. The obtained correlation distributions are

represented in ﬁgure 12 in dark green line.

Concerning the ﬁt of the NMRD proﬁles we measured the MSE reported

28

(a)

(b)

Figure 11: Zoom of quadrupolar dips.
nanosponge sample.

(a) Parmigiano Reggiano Cheese.

(b) Dry

Parameter values
DN
2.73
69.00
0.91
0.87
0.74
2.56
3.17
2.7853

R0
C N H
Θ
Φ
τQ
ν−
ν+
MSE 7.8887 10−2

PR
3.23
5.66
1.25
0.86
1.02
2.1
2.8

Table 6: Values of the parameters ﬁtted by AURORA and MSE in the last row.

in the last row of table table 6. The ﬁtted NMRD proﬁles, represented in

ﬁgure 13, show in blue line the data and error bars while the ﬁtted curves

are represented in red line for both samples.

The zoom in the frequencies of QRE interval is shown in ﬁgure 14. The

results conﬁrm the excellent ﬁt to the NMRD proﬁle (ﬁgure 13) also in the

QRE interval (ﬁgure 14).

29

(a)

(b)

Figure 12: Correlation distribution (dark green lines). (a) Parmigiano Reggiano sample.
(b) Dry nanosponge sample.

(a)

(b)

Figure 13: NMRD data and error bars (blue lines) and ﬁtted curve (red lines).
Parmigiano Reggiano sample. (b) Dry nanosponge sample.

(a)

5. Conclusion

The present contribution investigates an automatic approach for analyz-

ing the NMRD proﬁles in the presence of the quadrupolar relaxation en-

hancement. This feature yields a non-linear model whose parameters require

the solution of a constrained non-linear least squares problem. Coupling

the model-free approach and L1 regularization, we tackle the constrained

30

(a)

(b)

Figure 14: Zoom of data and ﬁtted curves in the QRE intervals. NMRD data and error
bars (blue lines) and ﬁtted curve (red lines). (a) PR sample. (b) DN sample.

problem by a two-blocks non-linear Gauss-Seidel method. We assess the

well-posedness of the optimization problem (existence of a minimum) and

the convergence of the GS iterations to a critical point. Finally, we introduce

an automatic convergent update rule of the regularization parameter based

on the Balancing Principle.

The proposed algorithm is investigated both with synthetic and real data

and the results state that it is a robust, fast approach to obtain accurate esti-

mates of the correlation times distributions as well as modeling the quadrupo-

lar function.

Moreover, we highlight that AURORA can be viewed as a reference frame-

work to construct parameter estimation procedures when the model parame-

ters can be split into independent blocks allowing the use of diﬀerent compu-

tational approaches for each block. In this regard, future work will include

the extension of such a framework to diﬀerent models of NMRD proﬁles

where the number of correlation times τ in (2) is assigned, and their values

31

are to be estimated together with the corresponding component f (τ ).

Given the very accurate and promising results, AURORA will be included

in the Matlab software tool FreeModelFFC Tool for the inversion of NMRD

proﬁles with QRE (available in https://site.unibo.it/softwaredicam/

en/software).

Acknowledgement

G. Landi and F. Zama were supported by the Istituto Nazionale di Alta

Matematica, Gruppo Nazionale per il Calcolo Scientiﬁco (INdAM-GNCS).

References

[1] R. Kimmich, Field-cycling NMR relaxometry, in: NMR, Springer, 1997,

pp. 138–148.

[2] P. Conte, Applications of fast ﬁeld cycling NMR relaxometry, in: Annual

Reports on NMR Spectroscopy, Vol. 104, Elsevier, 2021, pp. 141–188.

[3] T. C. Farrar, E. D. Becker, Pulse and Fourier transform NMR: intro-

duction to theory and methods, Elsevier, 2012.

[4] P. H. Fries, E. Belorizky, Simple expressions of the nuclear relax-

ation rate enhancement due to quadrupole nuclei in slowly tumbling

molecules, The Journal of Chemical Physics 143 (4) (2015) 044202.

[5] D. Kruk, E. Masiewicz, A. M. Borkowska, P. Rochowski, P. H. Fries,

L. M. Broche, D. J. Lurie, Dynamics of solid proteins by means of nuclear

magnetic resonance relaxometry, Biomolecules 9 (11) (2019) 652.

32

[6] T. Jeoh, N. Karuna, N. D. Weiss, L. G. Thygesen, Two-dimensional

1h-nuclear magnetic resonance relaxometry for understanding biomass

recalcitrance, ACS Sustainable Chemistry & Engineering 5 (10) (2017)

8785–8795.

[7] P. Conte, L. Cinquanta, P. Lo Meo, F. Mazza, A. Micalizzi, O. Corona,

Fast ﬁeld cycling NMR relaxometry as a tool to monitor parmigiano reg-

giano cheese ripening, Food Research International 139 (2021) 109845.

[8] E. G. Ates, V. Domenici, M. Florek-Wojciechowska, A. Gradiˇsek,

D. Kruk, N. Maltar-Strmeˇcki, M. Oztop, E. B. Ozvural, A.-L. Rollet,

Field-dependent NMR relaxometry for food science: Applications and

perspectives, Trends in Food Science & Technology (2021).

[9] J. P. Korb, Nuclear magnetic relaxation of liquids in porous media, New

Journal of Physics 13 (3) (2011) 035016.

[10] J. Mitchell, L. M. Broche, T. C. Chandrasekera, D. J. Lurie, L. F.

Gladden, Exploring surface interactions in catalysts using low-ﬁeld nu-

clear magnetic resonance, The Journal of Physical Chemistry C 117 (34)

(2013) 17699–17706.

[11] D. A. Faux, P. J. McDonald, Explicit calculation of nuclear-magnetic-

resonance relaxation rates in small pores to elucidate molecular-scale

ﬂuid dynamics, Physical Review E 95 (3) (2017) 033117.

[12] D. Kruk, P. Rochowski, M. Florek-Wojciechowska, P. J. Sebasti˜ao, D. J.

Lurie, L. M. Broche, 1h spin-lattice NMR relaxation in the presence of

33

residual dipolar interactions–dipolar relaxation enhancement, Journal of

Magnetic Resonance 318 (2020) 106783.

[13] P. Lo Meo, S. Terranova, A. Di Vincenzo, D. Chillura Martino, P. Conte,

Heuristic algorithm for the analysis of fast ﬁeld cycling (ﬀc) NMR dis-

persion curves, Analytical Chemistry (2021).

[14] B. Halle, H. J´ohannesson, K. Venu, Model-free analysis of stretched

relaxation dispersions, Journal of Magnetic Resonance 135 (1) (1998)

1–13.

[15] B. Halle, The physical basis of model-free analysis of NMR relaxation

data from proteins and complex ﬂuids, The Journal of chemical physics

131 (22) (2009) 224507.

[16] K. Ito, B. Jin, T. Takeuchi, A regularization parameter for nonsmooth

Tikhonov regularization, SIAM Journal on Scientiﬁc Computing 33 (3)

(2011) 1415–1438.

[17] L. Grippo, M. Sciandrone, Globally convergent block-coordinate tech-

niques for unconstrained optimization, Optimization Methods and Soft-

ware 10 (4) (1999) 587–637.

[18] L. Grippo, M. Sciandrone, On the convergence of the block non-

linear gauss–seidel method under convex constraints, Operations Re-

search Letters 26 (3) (2000) 127–136. doi:https://doi.org/10.1016/

S0167-6377(99)00074-7.

[19] D. Bertsekas, Nonlinear Programming, Athena Scientiﬁc, (2nd Edition),

1999.

34

[20] S.-J. Kim, K. Koh, M. Lustig, S. Boyd, D. Gorinevsky, An interior-

point method for large-scale (cid:96)1-regularized least squares, IEEE Journal

of Selected Topics in Signal Processing 1 (4) (2007) 606–617.

[21] D. Bertsekas, Projected Newton methods for optimization problems with

simple constraints, SIAM Journal on Control and Optimization 20 (2)

(1982) 221–246.

[22] E. Gafni, D. Bertsekas, Two-metric projection methods for constrained

optimization, SIAM Journal on Control and Optimization 22 (6) (1984)

936–964.

[23] J. Nocedal, S. J. Wright, Numerical Optimization, 2nd Edition,

Springer, New York, NY, USA, 2006.

[24] H. Engl, M. Hanke, A. Neubauer, Regularization of Inverse Problems,

Springer Dordrecht, 2000.

[25] H. P. Christian, Rank-deﬁcient and discrete ill-posed problems, SIAM

Monographs on Mathematical Modeling and Computation, Society for

Industrial and Applied Mathematics (SIAM), Philadelphia, PA, 1998.

[26] C. Vogel, Computational Methods for Inverse Problems, Vol. 23 of Fron-

tiers in Applied Mathematics, SIAM, 2002.

[27] T. Bonesky, Morozov’s discrepancy principle and Tikhonov-type func-

tionals, Inverse Problems 25 (1) (2008) 015015.

[28] C. Clason, B. Jin, A semismooth Newton method for nonlinear parame-

35

ter identiﬁcation problems with impulsive noise, SIAM Journal on Imag-

ing Sciences 5 (2) (2012) 505–536.

36

