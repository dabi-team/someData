Living-off-the-Land Abuse Detection Using Natural
Language Processing and Supervised Learning

Ryan Stamp
School of Computer Science
University of Guelph
Guelph, ON, Canada
rstamp@uoguelph.ca

2
2
0
2

g
u
A
6
2

]

R
C
.
s
c
[

1
v
6
3
8
2
1
.
8
0
2
2
:
v
i
X
r
a

Abstract—Living-off-the-Land is an evasion technique used by
attackers where native binaries are abused to achieve malicious
intent. Since these binaries are often legitimate system ﬁles,
detecting such abuse is difﬁcult and often missed by modern
anti-virus software. This paper proposes a novel abuse detection
algorithm using raw command strings. First, natural language
processing techniques such as regular expressions and one-hot
encoding are utilized for encoding the command strings as
numerical token vectors. Next, supervised learning techniques
are employed to learn the malicious patterns in the token vectors
and ultimately predict the command’s label. Finally, the model
is evaluated using statistics from the training phase and in a
virtual environment to compare its effectiveness at detecting
new commands to existing anti-virus products such as Windows
Defender.

Index Terms—Living-off-the-land, Natural language process-
ing, Regular expressions, Supervised learning, Intrusion detection
system, Machine learning, Endpoint security.

I. INTRODUCTION
As malware detection methods become more sophisticated,
adversaries constantly look for new approaches to remain
undetected in target networks [1]. One such method that has
become popular in recent years is living-off-the-land (LOL).
This technique involves leveraging existing benign binaries
(LOLBins) to achieve the desired result. These binaries are
typically legitimate system ﬁles that are required for normal
operating system execution; however, they also possess the
ability to perform particular procedures desired by adversaries,
such as downloading ﬁles from a remote source.

In a study by Barr-Smith et al. [2], a large range of malware
samples were analyzed (totaling nearly 32 million samples),
and of them, 9.6% were found to utilize native binaries. This
statistic is non-negligible and demonstrates the real threat LOL
techniques possess.

However, detecting and/or preventing LOLBin abuse
presents unique challenges compared to other malware de-
tection forms. The primary issue is that these binaries are
legitimate system ﬁles, so existing techniques such as signature
detection will not work here. Instead, more sophisticated
methods must be used.

In this paper, we propose a novel command string-based
detection algorithm. Our hypothesis states that certain tokens,
or certain combinations of tokens, will be used more frequently
in malicious commands than in benign commands. By em-
ploying natural language processing (NLP) techniques such

as regular expressions and one-hot encoding, we can parse
and represent the tokens of a command string as numerical
vectors [3]. From here, we train a supervised learning model
to predict how malicious a token of a command string is likely
to be and, ultimately, how malicious the command itself is.
Finally, we evaluate the model to determine the effectiveness
of the training set and its ability to detect new threats not
already detectable by existing anti-virus products.

II. BACKGROUND AND RELATED WORKS

Nowadays, cybersecurity is a hot topic for many researchers
in the academic and industrial sections. We can ﬁnd a lot of se-
curity mechanisms and defenses in attack detection and threat
hunting in [4]–[7]. Moreover, a considerable number of studies
have proposed other security solutions like machine learning
and blockchain to design and implement detection models [8],
[9]. A few of these security solutions are the detection of
outliers and anomalous data and behavior in Internet of Things
(IoT) environments, both of which have been of interest to
the academic and industrial research communities, respectively
[10], [11]. Studies have looked at the analysis of IoT attacks
and the countermeasures based on the devices connected to
the intelligent networks [12]. The detection of outliers in IoTs,
Industrial Internet of Things (IIoT), and similar environments
is well known for its notable performance using Artiﬁcial
Intelligence (AI)-based methods, including machine learning-
based and deep learning-based approaches.

In order to identify anomalous behavior on IIoT sites,
Hasan et al. [13] have compared the performance of machine
learning models by measuring precision, accuracy, f1-score,
and recall. For techniques like Artiﬁcial Neural Networks
(ANN), Random Forest (RF), and Decision Tree (DT), 99.4%
accuracy was reported by the system. Metrics such as f1-score
and recall are better performed by the RF model than other
techniques. An ensemble technique based on the Average One-
Dependence Estimator (AODE) and RF model is presented
by Jabbar, and his colleague in [14]. Based on the Kyoto
data, the proposed technique showed a high accuracy of 90.51
percent and a low False Alarm Rate (FAR) of 0.14 percent.
Furthermore, AL-Hawawreh et al. [15] have developed a deep
learning-based ensemble model for detecting anomalies in
IIoT trafﬁc. With the help of TCP/IP data packets, they have

 
 
 
 
 
 
used a feed-forward and AE architecture for training and
validating.

Research regarding LoLBin detection has mostly been
conducted in recent years. The main concern with LoLBin
detection is that the adversary may not create any malicious
ﬁles for anti-virus software to detect [16] [17]; nor can
these binaries simply be blocked since they provide necessary
functionally to the operating system. A common example is a
certutil.exe binary native to Windows operating systems. This
tool is used for managing certiﬁcates but possesses the ability
to download ﬁles that adversaries can exploit. To overcome
this issue, researchers have turned to AI to detect the malicious
use of otherwise benign binaries.

In a study by Ongun et al. [16], the issues with current
methods are outlined, relying on command line parsing by
regular expressions that yield high false-positive rates. The
study proposes an active learning approach where an AI
will select samples for an analyst to classify. The AI works
under the same hypothesis that we propose;
that certain
tokens in the command appear more frequently for malicious
commands. Although the results from the study are promising,
basing decisions on the tokens alone is very binary-speciﬁc
as different binaries will often use different tokens in their
commands to express the same functionality. Our research will
improve on this limitation by developing custom parsing rules
to determine the functionality of speciﬁc commands so that
the same patterns can be recognized across different binaries.
We also want to brieﬂy mention that LOLBin detection also
has use in the mobile space. In a paper by Bellizzi et al.
[18], Just-in-Time Memory Forensics (JIT-MF) is leveraged
to detect and ﬁght against LOLBin abuse in Android systems.
However, although mobile forensics and security are arguably
just as important as forensics in desktop operating systems,
this paper and its proposed method will solely focus on
desktop environments.

Benign commands for the LOLBins are rather plentiful. Our
dataset they were collected from our partner organization’s
raw dataset of collected process events from numerous client
machines. Malicious samples, by comparison, are harder to
obtain. The primary struggle is a lack of readily available
samples that have been hand-labeled by experienced analysts.
However, for our model, we are less interested in learning
speciﬁc commands and more interested in learning speciﬁc
patterns.

LOLBAS [19] is an excellent community-run project for
documenting the various LOLBins and providing examples
of how they can be abused. Since our pre-processing stages
will extract the patterns from command strings, we can collect
the malicious samples for our dataset from these LOLBAS
examples.

The DFIR Report [20] is another great resource for ob-
taining malicious commands. This site hosts reports on real
intrusions and lists the many commands that were executed.
Any commands involving LOLBins from this resource were
collected and added to the validation dataset, which is used
later during the evaluation of the model.

The ﬁnal challenge with our dataset is the imbalance of
malicious and benign samples. Since the vast majority of
commands encountered in the wild will be benign, it follows
that our dataset will also possess the same or similar ratio.
However, this is an issue as imbalanced datasets can heavily
degrade the effectiveness of the model [21].

Synthetic Minority Oversampling Technique (SMOTE) [21]
is an algorithm for balancing a dataset. In short, the algorithm
generates new feature vectors by creating line segments be-
tween minority class neighbors. These line segments allow
for the generation of new vectors to balance the dataset
but without introducing any new information that could alter
the model’s training. In practice, this technique proved very
effective.

III. METHODOLOGIES

B. Lexers and Tokenization

This section will discuss the methodologies behind our
LOLBin detection. It will discuss the origin of the dataset,
the pre-processing and tokenization techniques, the building of
the feature vectors and feature matrix, and ﬁnally, the classiﬁer
model and its prediction interface.

A. Dataset

The dataset consists of raw command strings for a variety
of known LOLBins labeled as either benign or malicious.
Since there are likely hundreds of LOLBins that malicious
parties could abuse, we chose to focus on only a small
subset of the most popular. In total, our model supports 16
different LOLBins listed as follows: bitsadmin, certutil, cmstp,
csc, cscript, mmc, msiexec, msxsl, reg, regsvcs, regsvr32,
rundll32, schtasks, sqlps, wmic, and wscript. Additionally, our
methodologies were designed to make the process of adding
new LOLBins relatively trivial, and the such process will be
discussed in the later sections.

Since the model operates on raw command strings, custom-

tokens unless

The lexers will ﬁrst

built lexers are ﬁrst employed to tokenize the input strings.
split

the command string into
separated by whitespace are consid-
tokens. Characters
ered different
a group of whitespace-
separated characters is wrapped in quotations. For example,
“"Windows Defender"” would be considered a single to-
ken. Further normalization is applied for each token generated
in this manner to decrease the number of unique tokens the
model will encounter. This normalization involves removing
the leading or trailing quotes, dashes, or slashes. The tokens
are also converted to lowercase to enable case insensitive
matching later on. Figure 1 demonstrates this process visually.
To further decrease the token space, the lexers will next
apply several regular expressions to the tokens to detect
particular patterns and replace that token with a special token.
For example, a url regex is employed to detect if a token
is an HTTP or HTTPS url and replaces it with the “<url>”
token [22], [23]. The ﬁle regex detects ﬁle names and replaces

2

Fig. 1. Tokens are normalized

that token with two special tokens, a generic “<ﬁle>” token
and a speciﬁc extension token such as “<ext exe>”. Figure
2 demonstrates this process visually. For a full list of custom
tokens, see appendix A.

Fig. 2. Detected patterns are replaced with custom tokens

Do note that since the syntax for every binary can differ
greatly, a unique lexer is required for each unique binary. To
accomplish this while reusing as much logic as possible, a
base class that implements independent binary patterns, such
as the URL and ﬁle regexes discussed above, was implemented
and can simply be instanced to fulﬁll the requirements for
most binaries. However, if necessary, the base class can be
extended to more easily add additional pattern recognition
if a particular binary requires it. For example, “rundll32”
implements a subclass to detect javascript parameters.

C. Feature Vectors and Feature Matrix

Building feature vectors from command tokens present a
unique challenge. Vectors for machine learning models must
be numerical [24], [25]. However, our tokenized strings are
words. Thus, some encoding of words to ﬂoats must be
employed. Although many such techniques exist, the relatively
simple one-hot encoding technique was chosen.

Since there are theoretically a nearly inﬁnite number of
unique tokens, we must determine which ones are the most
important for learning benign versus malicious behavior and
only include those tokens in the one-hot encoding. Addition-
ally, we add a special “<rare>” token to act as a dust-bin
category for all unrecognized tokens.

To this extent, as with the lexers, we will need a unique
feature builder for each unique binary. The reason is that
different binaries will have different tokens that are important
to determining the command’s label and therefore need to be
included in the one-hot encoding.

To build the corpus, the entire dataset for the binary is
iterated through, and each command is tokenized. Every
token that appears in the malicious commands is considered
important and is included in the word corpus. Since there are
many more unique examples of benign commands compared
to malicious samples, only tokens that appear in at least three
unique tokenized commands are included in the corpus.

Figure 3 demonstrates visually how a sample tokenized
command may be one-hot encoded. Also, since building the
word corpus can be expensive depending on the dataset size
for a binary, the word corpuses are stored alongside the model
artifacts when saving to disk so that they do not need to be
regenerated every time.

Fig. 3. Example one-hot encoding for a collection of tokens

Now that we can encode our tokens numerically, we next
need to build the actual vectors. To achieve better model
performance, we not only want to encode what tokens are
present in command but also the context of what other tokens
appear around them. To achieve this, we employ a novel
token feature-building algorithm. Note that this algorithm, as
described below, builds a feature vector for each token instead
of one vector for the entire command.

Firstly, the feature corresponding to the token being exam-
ined is set to one. Next, features corresponding to the tokens
away from the target token are set to 1/2. Two away are
set assigned values of 1/3 and so on. The window size for
how many tokens to consider can be adjusted, but we used
a window size of 2. This process is also additive, so if the
same token appears more than once in the window around the
target token, then this is reﬂected in the ﬁnal vector. Figure 4
demonstrates this algorithm visually.

Fig. 4.
tokens are around them

Individual tokens are converted into feature vectors based on what

D. LOLBin Models

So far, we have needed to create unique lexers and feature
builders for each unique binary, and the ﬁnal model is no
different. Because the feature vectors are different lengths due
to our unique one-hot encoding per binary, a separate model
will need to be trained for each binary. At ﬁrst, this may seem
problematic, but this approach boasts several advantages:

3

1) If an existing LOLBin’s dataset needs to be updated,
then the LOLBin’s model can easily be retrained without
having to touch the other models.

2) Similarly, adding support for a new LOLBin can be done
simply by adding the new model and the performances
of the other models will be completely unaffected.
3) Re-balancing the dataset using the SMOTE utility (see
section III-A) can more easily be done on a per binary
basis instead of on the entire dataset.

The ﬁnal training matrices consist of a token vector for
every token in every command in the dataset. The train-
test split
is done with a standard 80% training and 20%
testing. Note that some more obscure LOLBins have no benign
samples in the dataset. In this rare case, that binary model is
simply trained on the entire dataset with no splitting or testing.
Two different types of supervised learning models are uti-
lized. SKlearn’s multi-layer perceptron (MLP) is the preferred
classiﬁer; however, like all neural network-based models, a
sufﬁcient amount of data is required to be effective. Suppose
the LOLBin in question does not meet the required threshold,
in our case, 500 samples. In that case, a Random Forest
(RF) classiﬁer is used instead, which can achieve much better
performance when less data is available.

Additionally, since the model is trained on token vectors,
predictions will be in the form of token scores, not command
scores. To obtain command scores, a feature matrix is con-
structed by combining the token vectors for each token in the
command. Submitting the matrix to the model will produce a
token score for each row in the matrix. Aggregation techniques
can now be employed to interpret the results, such as min, max,
and average pooling. In our testing, the max value among the
token scores proved to be the most reliable in determining the
command’s label. Figure 5 demonstrates this process visually.
Note the token scores used are only examples and may not
reﬂect the true token scores generated by the model.

Fig. 5. Command score is calculated form multiple token scores

E. Unimodel

Since we trained a separate model for each LOLBin, we
have developed a container class, dubbed the ”unimodal”, to
encapsulate the models into a single object. The unimodeladdi-
tionally provides methods for loading the model artifacts from
disk and a single interface for making predictions. This method
uses techniques such as regular expressions to extract the
binary name from the command string and determine which
model to query. Figure 6 demonstrates this process visually.
The use of the unimodel proved very effective. It solved any
issues related to the organization that may arise from using
multiple models.

Fig. 6. The unimodel encapsulates individual LOLBin models and provides
single interface for predictions

IV. EVALUATION

A. Unimodel Statistics

The statistics for each LOLBin model are listed in table
I. Note that the three LOLBins with no benign samples are
excluded. It can be seen that the models performed very well
overall with near-perfect statistics.

These statistics also help to emphasize the advantages of
modular models. Since each model is trained speciﬁcally for
one LOLBin, it can much more easily obtain better accuracy
than if it was trained for multiple LOLBins. Separate stats
additionally allows analysts to zero in on which models may
be underperforming. From here, their datasets can be updated
to improve performance; and as mentioned earlier, the models
can be trained individually without affecting the others.

B. Virtual Machine Simulation

Although statistics can give some idea of how well the
model is performing, its real value comes from its ability

4

TABLE I
MODEL EVALUATION IN VM RESULTS

Classiﬁer

Accuracy

Precision

Recall

F1 Score

bitsadmin
certutil
csc
cscript
mmc
msiexec
reg
regsvr32
rundll32
schtasks
sqlps
wmic
wscript
AVERAGE

RF
RF
MLP
MLP
RF
MLP
MLP
MLP
MLP
RF
RF
MLP
MLP
—

1.0
1.0
1.0
1.0
1.0
0.9940
0.9987
0.9757
0.9739
0.9835
1.0
0.9984
1.0
0.9941

1.0
1.0
1.0
1.0
1.0
0.9884
1.0
1.0
1.0
0.9836
1.0
0.9968
1.0
0.9976

1.0
1.0
1.0
1.0
1.0
1.0
0.9973
0.9451
0.9480
0.9836
1.0
1.0
1.0
0.9903

1.0
1.0
1.0
1.0
1.0
0.9942
0.9986
0.9718
0.9733
0.9836
1.0
0.9984
1.0
0.9938

to detect new commands that are not already detectable by
existing solutions [26]. We also want to validate how effective
the model is at detecting new commands not present in the
training set, as most of the commands encountered in the wild
will be new. For this purpose, we utilize the validation set
discussed in section III-A.

The model was evaluated against Windows Defender and
our partner organization’s own Endpoint Detection and Re-
sponse (EDR) solution. The evaluation consisted of running
83 malicious commands (spanning all LOLBins) in a virtual
machine (VM) with both Defender enabled and the EDR agent
installed. These 83 commands combine the validation dataset
and select commands from the training dataset.

The results are summarized in table II. As can be seen,
Defender can currently only detect a mere 8 of the malicious
LOLBin commands. In contrast, our model can detect all of
them. Also, note that for conﬁdential reasons, the EDR results
are not disclosed in this paper and are only shared internally
with the partner organization.

This extra level of evaluation provides much greater conﬁ-
dence in the model’s effectiveness than utilizing the model
statistics alone. Comparing against existing solutions such
as Windows Defender and the partner organization’s EDR
solution additionally helps to prove the model and algorithm’s
worth and value to detect new threats.

C. False Positives and the Base-Rate Fallacy

In this sub-section, we would like to bring attention to the
base-rate fallacy and how it affects the problem of detecting
malicious commands.

Axelsson [27] excellently describes the base-rate fallacy
using the following example. Suppose a disease affects only
1/10000 people in a population, and a test for that disease has a
1% false-positive rate. Then, if an individual tests positive for
the disease using the said test, there is still only a 1/100 chance
that they actually have the disease. Intuitively, humans tend to

TABLE II
MODEL EVALUATION IN VM RESULTS

Defender Model

bitsadmin
certutil
cmstp
csc
cscript
mmc
msiexec
msxsl
reg
regsvcs
regsvr32
rundll32
schtasks
sqlps
wmic
wscript
TOTAL

0/4
2/8
0/2
0/2
0/2
0/1
0/5
0/2
0/19
1/1
1/2
2/8
1/10
0/1
1/13
0/3
8/83

4/4
8/8
2/2
2/2
2/2
1/1
5/5
2/2
19/19
1/1
2/2
8/8
10/10
1/1
13/13
3/3
83/83

disregard the actual base rate and zero in on the low false-
positive rate, so the ﬁnal results seem rather counter-intuitive.
Hence the name “base-rate fallacy”.

We now extend this example to the problem of malicious
command detection. Malicious commands make up a tiny
percentage of all commands executed on a system, and the
rate at which commands are executed is very high. So, by the
base-rate fallacy, even if our model (or any other solution) has
a very low false positive rate, the resulting hits are still much
more likely to be benign than actually malicious.

As part of our evaluation, we ran our model on a live
stream of command data generated from numerous clients.
The goal was to check for false positives and adjust the models
accordingly. However, the sheer amount of false positives was
much higher than expected, which we later determined was
due to the base-rate fallacy.

This result presents a problem for analysts who monitor
alerts generated from such systems. Since the ﬂow of com-
mand data to the model is very high, analysts will likely be
ﬂooded with false positive alerts that obscure true positives
and, in general, consume a lot of resources. Therefore, we
recommend that any solution to the malicious command de-
tection problem (whether our presented solution or another)
not generate alerts outright, or at the very least, also apply
some form of ﬁltering such as whitelisting.

This result also emphasizes the need for human analysts, or
more speciﬁcally, that this problem may never reach a point of
complete automation. Although it may be tempting to adjust
the models more to further lower the false positive rate, one
would be doing so with the risk of increasing the false negative
rate. It is better to generate more false positives and have
human analysts available to sift through them than to lower
the rate of incorrect alerts and run the risk of missing true
malicious activity.

5

V. EXTENSIBILITY

< mal keyword > : LOLBin speciﬁc keyword indicating

As stated previously, the unimodel and related procedures
were designed to be extendable. This feature is essential in the
context of LOLBin detection, as new LOLBins and techniques
are being discovered regularly as adversaries constantly adapt
their methods to the changing landscape. If adding new
patterns and/or retraining the model was a lengthy process, it
could act as a bottleneck for the system. Additionally, making
sure the unimodel stays modular is important for upholding
consistency by not affecting the performance of one LOLBin’s
detection by adjusting the model of another unrelated LOLBin.

VI. CONCLUSIONS AND FUTURE WORK

This paper proposed a novel LOLBin command abuse
detection algorithm using both regular expressions and super-
vised learning. Model statistics demonstrate high efﬁciency at
detecting malicious patterns, and further evaluation in a virtual
environment shows the model’s ability to detect many com-
mands not already detectable by existing anti-virus software
such as Windows Defender. The base-rate fallacy was also
brieﬂy discussed, and its applications to the LOLBin problem
were analyzed.

In terms of future work, support for more LOLBins and/or
more token patterns could be added as needed. More sophis-
ticated techniques, in general, may also be required to handle
more complex LOLBins such as cmd. Finally, other techniques
for reducing false positives could be explored, as was covered
in a previous section.

APPENDIX

A. Custom Tokens

Common (used by all lexers):

<url> : http or https url

eg. https://malicious[.]com

<url> <ext *> : url that ends with a path to a ﬁle

eg. https://malicious[.]com/file.exe

<ads> : alternate data stream

eg. benign.txt:malicious.exe

< share > <ext *> : shared ﬁle

eg. \\10.10.10.10\malicious\file.exe

< number > : positive or negative integer

eg. 100

< decimal > : positive or negative real number

eg. 10.5

< ip addr > : IP address

eg. 192.168.1.0

< guid > : Globally Unique Identiﬁer (GUID)

eg. {e77b42d3-55a5-4b3e-9d08-d59047c2e4c8}

< benign keyword > : LOLBin speciﬁc keyword indicat-

ing benign behaviour

malicious behaviour

regsvr32:

< script > * : local or remote script

eg. i:file.sct

rundll32:

< javascript > : javascript

eg. javascript:*

< dll > * * : DLL ﬁle and entrypoint

eg. file.dll,EntryPoint

REFERENCES

[1] A. Yazdinejad, H. HaddadPajouh, A. Dehghantanha, R. M. Parizi,
G. Srivastava, and M.-Y. Chen, “Cryptocurrency malware hunting: A
deep recurrent neural network approach,” Applied Soft Computing,
vol. 96, p. 106630, 2020.

[2] F. Barr-Smith, X. Ugarte-Pedrero, M. Grazian, R. Spolaor, and I. Marti-
novic, “Survivalism: Systematic analysis of windows malware living-off-
the-land,” in Symposium on Security and Privacy (SP), pp. 1557–1574,
IEEE, 2021.

[3] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, and H. Karimipour, “Fed-
erated learning for drone authentication,” Ad Hoc Networks, vol. 120,
p. 102574, 2021.

[4] A. Yazdinejad, A. Dehghantanha, R. M. Parizi, M. Hammoudeh,
H. Karimipour, and G. Srivastava, “Block hunter: Federated learning
for cyber threat hunting in blockchain-based iiot networks,” IEEE
Transactions on Industrial Informatics, pp. 1–1, 2022.

[5] A. Corallo, M. Lazoi, M. Lezzi, and A. Luperto, “Cybersecurity aware-
ness in the context of the industrial internet of things: A systematic
literature review,” Computers in Industry, vol. 137, p. 103614, 2022.
[6] A. Yazdinejad, B. Zolfaghari, A. Azmoodeh, A. Dehghantanha,
H. Karimipour, E. Fraser, A. G. Green, C. Russell, and E. Duncan, “A
review on security of smart farming and precision agriculture: Security
aspects, attacks, threats and countermeasures,” Applied Sciences, vol. 11,
no. 16, p. 7518, 2021.

[7] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, Q. Zhang, and K.-K. R.
Choo, “An energy-efﬁcient sdn controller architecture for iot networks
with blockchain-based security,” IEEE Transactions on Services Com-
puting, vol. 13, no. 4, pp. 625–638, 2020.

[8] S. Nakhodchi, B. Zolfaghari, A. Yazdinejad, and A. Dehghantanha,
“Steeleye: An application-layer attack detection and attribution model
in industrial control systems using semi-deep learning,” in 2021 18th
International Conference on Privacy, Security and Trust (PST), pp. 1–8,
IEEE, 2021.

[9] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, and K.-K. R. Choo,
“Blockchain-enabled authentication handover with efﬁcient privacy pro-
tection in sdn-based 5g networks,” IEEE Transactions on Network
Science and Engineering, vol. 8, no. 2, pp. 1120–1132, 2019.

[10] X. Yan, Y. Xu, X. Xing, B. Cui, Z. Guo, and T. Guo, “Trustworthy
network anomaly detection based on an adaptive learning rate and mo-
mentum in iiot,” IEEE Transactions on Industrial Informatics, vol. 16,
no. 9, pp. 6182–6192, 2020.

[11] G. Han, J. Tu, L. Liu, M. Mart´ınez-Garc´ıa, and Y. Peng, “Anomaly
detection based on multidimensional data processing for protecting vital
devices in 6g enabled massive iiot,” IEEE Internet of Things Journal
(Early Access Article), pp. 1–1, 2021.

[12] A. Yazdinejad, R. M. Parizi, G. Srivastava, and A. Dehghantanha,
“Making sense of blockchain for ai deepfakes technology,” in 2020 IEEE
Globecom Workshops (GC Wkshps, pp. 1–6, IEEE, 2020.

[13] M. Hasan, M. M. Islam, M. I. I. Zarif, and M. Hashem, “Attack and
anomaly detection in iot sensors in iot sites using machine learning
approaches,” Internet of Things, vol. 7, p. 100059, 2019.

[14] M. Jabbar, R. Aluvalu, et al., “Rfaode: A novel ensemble intrusion
detection system,” Procedia computer science, vol. 115, pp. 226–234,
2017.

6

[15] A.-H. Muna, N. Moustafa, and E. Sitnikova, “Identiﬁcation of malicious
activities in industrial internet of things based on deep learning models,”
Journal of information security and applications, vol. 41, pp. 1–11,
2018.

[16] T. Ongun, J. W. Stokes, J. B. Or, K. Tian, F. Tajaddodianfar, J. Neil,
C. Seifert, A. Oprea, and J. C. Platt, “Living-off-the-land command
detection using active learning,” 2021.

[17] R. Tarek, S. Chaimae, and C. Habiba, “Runtime api signature for ﬁleless
malware detection,” in Advances in Intelligent Systems and Computing,
vol 1129, 2020.

[18] J. Bellizzi1, M. Vella1, C. Colombo1, and J. Hernandez-Castro, “Re-
sponding to living-off-the-land tactics using just-in-time memory foren-
sics (jit-mf) for android,” 2021.

[19] “Lolbas: Living off the land binaries, scripts and libraries.”
[20] “The dﬁr report.”
[21] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, “Smote:
Synthetic minority over-sampling technique,” in Journal of Artiﬁcial
Intelligence Research 16, pp. 321–357, 2002.

[22] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, and K.-K. R. Choo, “P4-
to-blockchain: A secure blockchain-enabled packet parser for software
deﬁned networking,” Computers & Security, vol. 88, p. 101629, 2020.
[23] A. Yazdinejad, A. Bohlooli, and K. Jamshidi, “Efﬁcient design and
hardware implementation of the openﬂow v1. 3 switch on the virtex-6
fpga ml605,” The Journal of Supercomputing, vol. 74, no. 3, pp. 1299–
1320, 2018.

[24] A. Yazdinejad, G. Srivastava, R. M. Parizi, A. Dehghantanha, K.-K. R.
Choo, and M. Aledhari, “Decentralized authentication of distributed
patients in hospital networks using blockchain,” IEEE journal of biomed-
ical and health informatics, vol. 24, no. 8, pp. 2146–2156, 2020.
[25] R. M. Parizi, S. Homayoun, A. Yazdinejad, A. Dehghantanha, and K.-
K. R. Choo, “Integrating privacy enhancing techniques into blockchains
using sidechains,” in 2019 IEEE Canadian Conference of Electrical and
Computer Engineering (CCECE), pp. 1–4, IEEE, 2019.

[26] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, G. Srivastava, S. Mo-
han, and A. M. Rababah, “Cost optimization of secure routing with
untrusted devices in software deﬁned networking,” Journal of Parallel
and distributed Computing, vol. 143, pp. 36–46, 2020.

[27] S. Axelsson, “The base-rate fallacy and the difﬁculty of intrusion
detection,” in ACM Transactions on Information and System Security,
Vol. 3, No. 3, pp. 186–205, IEEE, 2000.

7

