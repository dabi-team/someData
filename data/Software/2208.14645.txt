2
2
0
2

g
u
A
1
3

]

R
A
.
s
c
[

1
v
5
4
6
4
1
.
8
0
2
2
:
v
i
X
r
a

PUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

1

PaRTAA: A Real-time Multiprocessor for
Mixed-Criticality Airborne Systems

Shibarchi Majumder Member, IEEE, Jens F D Nielsen and Thomas Bak Senior Member, IEEE

Abstract—Mixed-criticality systems, where multiple systems with varying criticality-levels share a single hardware platform, require
isolation between tasks with different criticality-levels. Isolation can be achieved with software-based solutions or can be enforced by a
hardware level partitioning. An asymmetric multiprocessor architecture offers hardware-based isolation at the cost of underutilized
hardware resources, and the inter-core communication mechanism is often a single point of failure in such architectures. In contrast, a
partitioned uniprocessor offers efﬁcient resource utilization at the cost of limited scalability.
We propose a partitioned real-time asymmetric architecture (PaRTAA) speciﬁcally designed for mixed-criticality airborne systems,
featuring robust partitioning within processing elements for establishing isolation between tasks with varying criticality. The granularity
in the processing element offers efﬁcient resource utilization where inter-dependent tasks share the same processing element for
sequential execution while preserving isolation, and independent tasks simultaneously execute on different processing elements as per
system requirements.

Index Terms—Avionics on Multi-core, Mixed-criticality Systems, Integrated Modular Avionics, Robust Resource Partitioning, Single
Core Equivalence, Processor Architecture.

(cid:70)

1 INTRODUCTION

M IXED-CRITICALITY systems, where multiple subsys-

tems of different criticality-levels share the same
platform, require isolation between subsystems with dif-
ferent criticality-levels to prevent interference that can be
addressed by a software-based mechanism such as an op-
erating system or a hypervisor, or can be established at
the hardware level. Driven by the certiﬁcation requirements
in safety-critical systems, e.g., RTCA DO-297 [1] for airborne
platforms, the isolation mechanism shall meet the certiﬁca-
tion requirements of the subsystem with highest criticality-
level to be implemented on the platform. Such requirements
result in expensive software-based isolation mechanisms
and thus enhance the scope of hardware-based isolation.

Single-core-equivalent (SCE) multicore [2], an asymmetric
multiprocessor (AMP) architecture with multi or many iso-
lated processors with dedicated resources, interconnected
over a network-on-chip (NoC), offers isolation between tasks
running on separate processors. Such an architecture has the
potential to meet mixed-criticality requirements for safety-
critical airborne platforms where each subsystem can exe-
cute on a dedicated processing element without any interfer-
ence from other subsystems. Moreover, an SCE architecture
is beneﬁcial over a symmetric multiprocessing architecture
in terms of re-usability of existing source-code that avails
a more practical and economic transition to multicore for
the aerospace industry. However, in SCE architecture, the
NoC or inter-core communication system is a bottleneck and
often a single point of failure that requires redundancy or
additional safety-net mechanism. Additionally, an one-to-
one mapping of individual integrated modular avionics (IMA)
[1] application to AMP processors increases the bandwidth

The authors are with the Department of Electronic Systems, Aalborg Univer-
sity, Aalborg 9220, Denmark. email: sm, jdn, tba (@es.aau.dk).
This research is funded by the Danish Independent Research Foundation under
grant number 6111-00363B.

requirement resulting in resource-extensive NoC architec-
ture and adds to the complexity of system scheduling due
to inter-core communication delays over the NoC. Further-
more, dedicating a core to a subsystem is not efﬁcient in
terms of resource utilization; large airborne platforms may
afford many-core platforms with hundreds of cores, but
that may not be feasible for resource-limited platforms like
unmanned aerial systems (UAS).

Alternatively, a single-core architecture with a hardware-
level isolation mechanism can offer better computational
resource utilization with a small hardware footprint. How-
ever, a partitioned single-core architecture may not be suf-
ﬁcient to address the growing demand for computational
resources with an increasing degree of autonomous ﬂight
capabilities.

The SCE architecture offers an excellent solution for
parallel execution at the cost of under-utilized resources
where a partitioned architecture provides sequential access
to a single processing element resulting in efﬁcient resource
utilization. Aerospace systems have limited scope of parallel
execution as some systems may have inter-system depen-
dencies and must be executed sequentially, and mutually
independent systems can be executed simultaneously.

In this work, we propose a partitioned real-time asym-
metric architecture PaRTAA, where individual processing
elements featuring robust resource partitioning are inter-
connected with a time predictable NoC to provide a time
analyzable resource-partitioned distributed architecture, as
shown in Figure 1. The partitions within processing el-
ements satisfy isolation requirements for mixed-criticality
systems; sequential tasks can execute on the same or differ-
ent partitions depending on its criticality-level on the same
processor, and independent tasks/ systems can execute si-
multaneously on separate processors, resulting in efﬁcient
resource utilization.

 
 
 
 
 
 
PUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

2

2.1 Mixed-Criticality and IMA

Driven by the constraints of space, weight and power,
mixed-criticality systems allow systems with different
criticality-levels to share the same host hardware when
inter-system interference is mitigated. In airborne systems,
to replace federated avionics architecture, a line replaceable
unit (LRU) based framework where a single LRU is certiﬁed
to a single DO-178B [5] and/ or DO-254 [6] level, the
concept of mixed-criticality system is adopted as IMA [1],
where systems with different level of criticality deﬁned as
design assurance level (DAL) A, B, C, D and E [5], [7] can
share the same host platform. To establish isolation between
systems with different criticality-levels, the guidelines for
robust resource partitioning (RRP) [8] is adopted from DO-
248C [9] and DO-297 [1].

RRP is achieved when: 1) partitions cannot contaminate
instructions, I/O, and data of other partitions, 2) partitions
cannot use resource outside its allocated resources and 3)
dysfunction/ failure in one partition cannot cause adverse
effect on other partitions [8].

In practice, IMA system software is separated from the
host platform by an application executive (APEX), an appli-
cation programming interface (API) deﬁned in ARINC 653
[10] standard for IMA partitioning. The ARINC 653 API is
independent from the base hardware platform and a given
software host environment or operating system implemen-
tation. The hardware-software isolation allows incremental
certiﬁcation, thus, modiﬁcation in systems can be certiﬁed
by certifying only the changes.

2.2 Related Processor Architecture

Currently, Federation Aviation Administration (FAA) guide-
lines do not include the use of commercial off the shelf
(COTS) microprocessors and system-on-chips (SoCs) in air-
borne system, however, the scope is under evaluation [11]
[12]. Furthermore, FAA restricts the use to only one active
core in a multicore platform due to potential inter-core
interference [8].

According to a recent position paper on multicore pro-
cessors (MCP) for airborne systems [8], the applicant should
identify all potential interference paths on an MCP for DAL
level A and level B applications. When implemented on
an MCP platform without a robust partitioning, software
components or sets of requirements for which interference
paths are not avoided or mitigated shall be veriﬁed with
all other software components executing all together [8].
However, for MCP platforms with established robust par-
titioning, software components can be veriﬁed separately,
including determination of worst case execution time (WCET)
[8].

The concept of interconnecting multiple partitioned pro-
cessors to form a distributed partitioned system was pro-
posed in a paper by NASA in 2000 [13]. The architecture
was found to be challenging due to requirements of point-
to-point communication mechanism for inter-partition com-
munication that cannot be achieved with shared bus. How-
ever, the feasibility of such an architecture with a data-
concentrator unit to hold partition speciﬁc data was re-
alized. In our approach, the proposed NoC architecture

Fig. 1. A block diagram of the proposed multiprocessor architecture
PaRTAA with four processors. Each processor has three underlying
partitions with dedicated resources and protected memories (PM). All
the partitions are interconnected over a NoC via network interfaces(NI),
memory-mapped (MM) to the protected memory region.

In our previous work, we proposed a coarse-grained
uniprocessor, featuring hardware-level partitioning for iso-
lation [3]. In another work, we introduced a network-on-
chip that offers time analyzability and end-to-end isolation
between data packets [4] for mixed-criticality systems. In
this work, we have extended our previous works to pro-
pose a multiprocessor architecture featuring hardware-level
robust resource partitioning. The speciﬁc contribution of this
paper includes -

• A time-predictable multiprocessor architecture fea-
turing robust resource partitioning to accommodate
systems with mixed-criticality while preventing in-
terference.

• A multiprocessor architecture with coarse-grained
processing elements for efﬁcient resource utilization
by combining sequential and parallel execution de-
pending upon system requirements.

• The architecture preserves the reusability of software
solutions in airborne systems developed for single-
core platforms.

• A globally visible processor ﬂag mechanism for task
synchronization under different partitions and pro-
cessors.

• A demonstration of the proposed architecture for an

avionics use case.

2 BACKGROUND AND RELATED WORK

The scope of multicore architecture in airborne systems is
still evolving. However, several researchers have addressed
multicore architectures for real-time and safety-critical ap-
plications. This section discusses related architectures in the
context of mixed-criticality airborne systems.

Processor 1Partition 2  Processor 2Partition 2  Partition 1  Partition 3  Shared MemoryProcessor 3Partition 2  Partition 1  Partition 3  Shared MemoryProcessor 4Partition 2  Partition 1  Partition 3  ClockProcessor 1 flagsProcessor 4 flags...Shared MemoryShared MemoryHubPartition 1  Partition 3  NIRouter 1PM 1PM 2PM 3MMMMMMMCUNININIRouter 2PM 1PM 2PM 3MMMMMMMCUNININIRouter 3PM 1PM 2PM 3MMMMMMMCUNININIRouter 4PM 1PM 2PM 3MMMMMMMCUNINIPUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

3

features similar dedicated sampling buffer to hold partition
speciﬁc data without interrupting executing partitions.

The idea of mapping RTOS functionalities to hardware
is not new. In FASTCHART [14], the authors have achieved
time deterministic execution with 64 different tasks with 8
different priorities with a RISC architecture by removing
cache and pipeline. Adomat et al., in [15] demonstrated
a real-time hardware kernel that can support a similar
number of tasks and priorities like FASTCHART, but with
additional hardware features. Ungerer et al. [16],
intro-
duced a worst-case time-analyzable multicore architecture
for mixed-criticality system with isolation between tasks,
although, the architecture is limited to a single hard real-
time task per core.

In recent years, Zimmer et al. [17] has introduced Flex-
PRET, a ﬁne-grained multi-threaded processor architecture
for mixed-criticality systems. The work, demonstrates a
WCET analyzable framework that features isolation in tem-
poral and spatial domain without wasting computational
cycles. Tasks are segregated in threads and each thread is
given access to the computational resources for a single
clock cycle in a ﬁxed or active round-robin arbitration rou-
tine. A very similar architecture [18] by Liu et al., PTARM, is
a ﬁne-grained multi-threaded architecture with ﬁxed-round-
robin arbitration among four threads. The architecture avails
hard real-time execution time at the cost of wasted cycles
when all the threads are not active. Another similar ar-
chitecture XMOS [19], poses better utilization of resources
by excluding inactive tasks from the scheduling. WCET is
analyzed by considering the maximum number of active
tasks at any given time. Delvai et al. [20], introduced a 16-bit,
3 stage processor, SPEAR, with repeatable-time instructions
by single path execution ﬂow.

Apart from the partitioned uniprocessor architectures,
there are several multiprocessor architectures proposed for
generic mixed-criticality systems. Salloum et al. in [21],
has proposed and demonstrated a multiprocessor system
on chip (MPSoC) solution that focuses on easing the cer-
tiﬁcation process required in safety-critical domain. Mul-
tiPARTES project [22] demonstrates a multi-core heteroge-
neous architecture and focus on associated tool-chains for
easing the certiﬁcation process for mixed-criticality systems
on a multi-core syste. The researchers in [23], describe
a system architecture that enables the use of data-centric
distribution middleware in partitioned real-time embedded
systems based on a hypervisor for multi-core focused on
the analysis of the available architectural conﬁgurations. For
more related work on mixed-criticality system on multipro-
cessor, please consider the report by Baruah et al. [24] that
summarizes a broad spectrum of researches related to multi-
core and many-core architectures in the context of mixed-
criticality implementation.

2.3 Inter-Core Communication

Several NoC architectures have been demonstrated for
safety critical systems. The use of NoC in a real-time system
imposes complex constraints in the overall design [25].

In SoCBUS [26], a circuit switching method is applied and
a concept called packet connected circuit was introduced,
where a data packet propagates through a dynamic mini-

mum route, locking the circuit as it moves through the net-
work. For such switching mechanism, a real-time analysis
is possible when the trafﬁc follows a ﬁxed schedule, but
not effective where the transmission sequence is not ﬁxed
like in avionics systems, where the data sequence depend
on the relative state of the applications. In Xpipes [27], the
network is tailored to meet the bandwidth requirements
of the payload application at its design stage. In practice,
such a system could be hard to fabricate as foreseeing the
exact communication load is difﬁcult to analyze, and it
restricts reusability and the scope of future modiﬁcation
of the system. An alternative solution is proposed based
on backtrack probing to avoid waiting for blocked channels
to become available, seeking for alternative non-minimal
routes in [28]. However, such a solution does not guarantee
time-predictability. In [29], a synchronous circuit switching
NoC is presented. A concept of spatial division multiplexing
is introduced, where the physical channel is segmented to
provide physical separation between data streams at the cost
of elevated resources.

A connection-less packet-switching approach is demon-
strated in [30], where the routers work independently and a
wormhole switching technique is used. The transmissions are
prioritized based on some ﬁxed parameters and transmis-
sion with the highest priority is given preference. The draw-
back of such a design is that packets with low priorities
may be dropped or stalled for a long time and has a longer
latency resulting in an unachievable time-analyzability. The
authors propose a low end-to-end latency with a guar-
anteed service trafﬁc in [31]. In [32], [33], the researchers
have addressed the low priority packet blocking problem
in a connection-less NoC by introducing the concept of
increasing priority over waiting time. In contrast, this work
offers a mixed, best-effort and guaranteed-service trafﬁc where
transmission with highest priority is given preference by
allocating more bandwidth, while transmission with lower
priority is given the minimum bandwidth allocated by
the system designer to maintain worst-case-time analyzable
communication for transmissions belonging to all priorities.

2.4 Multiprocessor in Avionics

System certiﬁcation with a multicore platform is presently
challenging due to lack of guidelines and formal methods
issued by certiﬁcation authorities. The EASA research re-
port [34] and FAA position paper [8] are the most recent
studies available from a certiﬁcation authority on the po-
tential scope and regulations on multicore platforms for
airborne systems. Although, CAST 32A position paper [8]
only includes multicore platforms with only two core and
excludes any asymmetric multiprocessors with no shared
memory/ cache or coherency module [8], SCE architectures
are found to be beneﬁcial for mixed-criticality and IMA
implementations [2]. One major beneﬁt of SCE is reusability
of source code developed for single core architecture.

A few AMP and many-core architectures have been
demonstrated for IMA implementation. In [35], a helicopter
health monitoring system is demonstrated on a many-core
processor architecture for exploiting computing capabilities
and timing responses. The researchers have used the Kalray
MMPA-256 platform, that features dedicated memory banks

PUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

4

Fig. 2. A high-level diagram showing the Ærø processor architecture and pipeline stages with three partitions. Note that the data paths and control
paths are speciﬁed with different arrows.

for processing elements and a reservation mechanism on the
NoC. In [36], the authors have proposed a time predictable
asymmetric multicore architecture with dual issue real-time
processors connected over a time-predictable bi-torus NoC.
Finally, a platform with 4 processors has been demonstrated
for an avionics application in [37], where each processor
hosts a single sub-system of a helicopter health monitoring
system.

3 THE PROCESSOR

The proposed multiprocessor architecture is an adoption
and extension of our previous work on a uniprocessor, Ærø
[3], and we will brieﬂy discuss the essential parts that are
required for understanding, and focus on the extensions
made in this work.

Ærø is a coarse-grained time analyzable processor with
a 32-bit RISC style custom ISA and four pipeline stages;
instruction fetch (F), decode (D), execute (E), memory-access
(M), as shown in Figure 2. Ærø is statically scheduled, and
all delays are analyzable in the instruction set for a single
path execution paradigm.

In this work, to fabricate an asymmetric multiprocssor,
we have integrated four Ærø processors, interfaced with
a time-predictable NoC, as illustrated in Figure 1. The
goal is, a set of tasks of mixed-criticality levels can be
scheduled on different partitions under different processors
depending on the timing requirements and criticality-level,
and the hardware-deﬁned partitioning will feature isolation
between tasks with different criticality-levels without any
host software support. Please note that the proposed AMP
architecture is scalable, and can be fabricated with more
processors. That is one of the reasons for considering a NoC
instead of an on-chip bus for inter-processor communica-
tion.

3.1 Architecture and Partitioning

The Ærø processor features hardware-level partitioning to
avail isolation between tasks of different criticality-levels in
either temporal or spatial domain. Isolation in the spatial
domain is achieved with replicated resources, and isolation
in the temporal domain is achieved with a partition switch-
ing mechanism, Switching-Control-Unit (SwCU).

The Ærø offers three partitions to accommodate tasks
with three criticality-levels. Each partition has a parallel data
and control lines with dedicated and replicated resources
connected over a multiplexer. Partitioning is a feature built
within the processor, and the ISA has no access to it. Fur-
thermore, the instructions have no sense of the partitioning
or the partition it is executing within. All the partitions
are identical, and any partition can be used to execute
instructions of any level of criticality.

As the instruction memory is read-only, a shared mem-
ory device can be used to store instructions/ tasks be-
longing to different criticality-levels. However, once the
instruction is fetched, isolation must be maintained (either
in the temporal or spatial domain) through the pipeline
ﬂow to prevent interference. To feature isolation in data and
control ﬂow, parts of the control path and data path contains
parallel paths connected over a multiplexer. At any point of
operation, only a single path is activated by the SwCU.

The SwCU is inbuilt hardware that enforces a cycle-
accurate time-triggered arbitration mechanism to imple-
ment a ﬁxed scheduling conﬁgured by the system designer
for each partition. The SwCU cannot be reached by the tasks
within the processor.

It is possible to conﬁgure different execution period and
execution time for each partition in the SwCu, however, to
facilitate time predictable execution the following assump-
tions are made -

• All partitions are periodic.
• All switching events are time-triggered.
• All partitions have uniform priority.

Note that uniform priority suggests that any two partitions
shall never compete for execution access and not partitions
with same criticality.

When a partition is active, only the associated dedicated
resources (control registers, register bank, and paths) are
active, and the instruction ﬂow takes place similar to a non-
partitioned processor. When the active partition completes
execution access time assigned by the user, the partition is
switched, and the next partition (based on partition sched-
ule) is given execution access. All the data and instruction
from the inactive partition remain frozen in the respective
pipeline/ hardware components (e.g., register banks).

Registerbank 132x1632 x 16addr regALU regRegister bank writeportreadaddrCachewriteaddrA L UreadI_memaddrFetch (F)Decode (D)Execute (E)Memory (M)fetch0prt_c_flag132 x 16MCUMCUprt_c_flag2prt_c_flag2prt_c_flag2addr regaddr regjump regprt_c_flag2alu_c_flag+1stack_outalu ctrlflagsOp 1Op 216data pathcontrol pathbit slicepc_regRegisterbank 332x16Register bank write portRegisterbank 232x16prt_c_flag2PUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

5

3.2 Memory Hierarchy

We have used three types of memories; instruction memory,
data memory, and stack memory. The instruction memory is
read-only memory for the processor, and instructions from
different partitions can share the same memory device. We
have assumed that all the instructions are present in the
instruction memory, and cache misses are out of the scope
of this work.

Fig. 3. Block diagram showing the memory control unit and distribution
of data memory of a single processing element.

The partitions must have read/ write access to the data
memory and stack memory for operation, and isolation
must be implemented. However, as at any point in time,
only a single partition is active, a shared memory device
can be used when an isolation mechanism is implemented.
A memory-control-unit (MCU) establishes such an isolation
by partitioning the memory in four segments, as shown in
Figure 3. Three segments are dedicated to three partitions,
and one segment is shared between all three partitions. The
partition speciﬁc protected memory segment is used as data
memory and stack memory. The shared memory can be used
for sharing data between partitions.

The MCU is a hardware-deﬁned mechanism that con-
trols two most-signiﬁcant-bits (MSB) of the memory ad-
dress based on the active partition. If the address space
of the memory device is n-bit, then the MCU controls the
[n − 1, n − 2] -bits of the address space. The memory address
space visible to each partition is n − 1-bit, i.e., an address
space of [n − 2, 0]-bits. However, the n − 2th bit is used to
denote the dedicated or shared memory region.

The instructions within a partition have no notion of the
MCU or the memory segmentation, and the instructions
can only select between shared or protected memory region
for reading or writing operations. The MCU implements
the following logic in hardware:

if (addr[n-2] == 1):

addr[n-1:n-2] = active-partition-flag;

elseif (addr[n-2] == 0):
addr[n-1:n-2] = 2b00;

The partition speciﬁc dedicated stack is deﬁned on the
lower end (except the base address) of the dedicated data
memory, and operated by the second access channel of a
dual-port memory device. The stack output is set to the most
recent return address as default.

At any point of operation, there is only one partition
active in a processor; hence, no simultaneous read-write
protection is required. However, the shared memory region
does not offer any hardware-based protection mechanism,
and must have software-based memory protection, e.g.,
mutex.

3.3 I/O and Peripherals

The partitioning in the processor does not have any spe-
ciﬁc requirements for IO interfacing. However, to meet
the isolation requirements for mixed-criticality applications,
some speciﬁc adjustments are necessary. Each partition
can be interfaced with external I/O devices with standard
memory-mapping technique. The I/Os that require isolation
is mapped to the protected data memory address space
and can only be accessed by the associated partition, and
the shared I/Os or peripherals are mapped in the shared
address space.

For broadcasting the execution state within a partition,
a custom processor ﬂag mechanism is implemented. The
32-bit processor ﬂag accommodates a 2-bit ﬂag that shows
the active partition followed by three 10-bit ﬂags from three
partitions. The 10-bit ﬂagging mechanism can be used as
1023 customs user-deﬁned ﬂags. The base address of the
protected memory region associated with each partition
is used to set the ﬂag with a standard memory writing
technique, and an underlying hardware mechanism slices
the written data and forwards the 10-LSBs, as shown in
Figure 3. The processor ﬂags are mapped on the shared
data memory space, as presented in Table 1. The 10-bit
partition ﬂag can only be set from the associated partition by
accessing the mapped address in the protected data memory
region, and all the processor ﬂags can be read by reading the
address mapped in the shared address space, as shown in
Figure 3. The ﬂagging mechanism can be used for execution
synchronization, and explained later.

Additionally, the proposed multicore architecture fea-
tures a global hardware clock accurate to the processor clock
cycle. The 64-bit counter is mapped to the base address
of the shared memory region. Note that the 64-bit counter
has an extremely long cycle time and cannot virtually reset
withing runtime. The Table 1 shows the assistive hardware
components mapped in the shared memory region. The
memory distribution and memory-mapped I/O interfacing
are presented in Figure 3.

4 INTER-CORE COMMUNICATION

Inter-processor connectivity is the basis of asymmetric mul-
tiprocessors. For mixed-criticality airborne systems, such
an inter-processor communication mechanism must pro-
vide time-predictability for real-time applications as well

32bit slice [9:0]partition 3 flags32bit slice [9:0]partition 2 flags32bit slice [9:0]partition 1 flagsactive partition [1:0]Concatenationprocessor flags32MM-IOstack memoryData memory 30x00Shared memoryShared MM IOProcessor 4 flagsProcessor 1 flags..Clock (H, L)MM-IOstack memoryData memory 2MM-IOstack memoryData memory 10x000x000x00MCUaddress [n-3 : 0]address [n-1 : n-2]Protected memoryProtected memoryProtected memoryPUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

6

TABLE 1
Mapping of assistive hardwares in the shared address space.

Memory-mapped address

0x00

0x04

0x08

0x12

0x16

0x20

attachments
clock_L (low-bits)
clock_H (high-bits)
Processor_1_flags (32-bit)
Processor_2_flags (32-bit)
Processor_3_flags (32-bit)
Processor_4_flags (32-bit)

as satisfy isolation between data from tasks with different
criticality-levels. To interconnect four processors, we have
implemented a time predictable NoC [4] that offers isola-
tion, either in spatial or in the temporal domain, between
data-packets through the entire propagation path as well
as it avails data protection from erroneous transmission
conducted by potential erroneous systems.

For easy monitoring and control of network trafﬁc and
simpler interfacing, we adopted a hybrid of star and tree
topologies. The network is built around a hub, interfaced
with multiple routers in a star topology and each router is
attached to a single or multiple network-interfaces (NI) in a
reverse tree topology, as shown in Figure 4.

router. An NI is independently interfaced with each parti-
tion using a standard memory-mapping technique, mapped
to the protected memory space of the associated partition.
Each NI has a dedicated sampling buffer for each reception
channel and each sampling buffer can be separately mapped
to the associated partition. However, as a partition can only
send a single packet at any point, the NI features a single
transmission buffer mapped to the dedicated address space.
Each partition has a dedicated NI with sampling buffers
that protect the received data until consumed by the par-
tition, even if the partition does not have execution access
at the time of data reception. A producer can send a data
packet any time irrespective of the state of the consumer
partition (active or inactive). The data-packet scheduling
considers the number of transmission per unit time, but the
exact time of transmission is not ﬁxed, and a producer can
push a data packet at any time. A transmission agreement is
only violated if the transmission rate exceeds the bandwidth
assigned to the channel.

There is no direct memory access (DMA) used in the
network, and the producer pushes a data-packet in the
network by writing the data-packet into the NI. The NI
features a transmission sample buffer to temporarily hold
the newly written data-packet for one clock cycle. In the
subsequent clock cycle, the data packet is forwarded to the
router, packed with the destination address in its header. As
the producer can only write a single data-packet at a time,
and the delay between two subsequent writes is more than
two clock cycles, temporal isolation between transmission
packets is achieved.

At the receiving NI end, a dedicated sampling buffer is
featured for each channel to store received data packets. The
channel-speciﬁc dedicated sampling buffers establish spatial
isolation between data-packets from different channels.

If the production rate is higher than the consumption
rate, the old data-packet gets overwritten by a fresh data-
packet from the same channel. This is not a challenge in
the intended application as each sampling buffer holds a
complete sample of a speciﬁc signal (e.g., turbine tempera-
ture, fuel pressure, etc.), and most recent data is desired for
computation. Similarly, if the transmission rate is lower than
the consumption rate, the consumer reads the same data-
packet multiple times, and this can be handled in software.

Fig. 4. Block diagram showing end-to-end data packet transmission.

Further, to enforce best-effort and guaranteed-service trafﬁc
without any packet loss under normal operation, a mixed
arbitration scheme of time-division multiplexing(TDM) and
dynamic-priority-token-passing is proposed.

The proposed arbitration mechanism accommodates dif-
ferent latency and bandwidth requirements of different pro-
ducers/ consumers in the same network while preserving
time analyzable end-to-end communication.

4.1 Interfacing and Propagation

In PaRTAA, the NoC is conﬁgured with four routers, and
three NIs connected to each router, as shown in Figure 1. The
NI has two ends; front-end, to interface with the producer/
consumer and back-end, to interface with the associated

4.2 Communication Time Analyzability

In mixed-criticality systems, systems with different levels
of criticality can have different timing characteristics. Based
on its functionality, a system may have different latency
and bandwidth requirements. To accommodate such re-
quirements of different latency and bandwidth in the same
network while preserving time-predictability for all commu-
nications, a concept of dynamic priority is implemented in
the arbitration scheme [4].

Furthermore, communication delay analysis is critical
for scheduling of tasks on an asymmetric architecture. The
release time of a dependent task (that takes input from other
tasks) is inﬂuenced by the end-to-end communication delay.
Such end-to-end communication delay can be analyzed
from the transmission schedule, which is again dependent
on task scheduling, creating a deadlock.

Tx bufferch idRx buffer(s)Network InterfaceProcessor 1MM_addrNIRouterTx bufferch idRx buffer(s)Network InterfaceProcessor 2MM_addrNIRouterHubBack endFront endMemory mapped interfaceRx buffer(s)Rx buffer(s)PUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697
(cid:26)

(cid:19)

(cid:25)

In PaRTAA, the propagation time from a producer to
the transmission-router via an NI, and reception-router to
the destination NI is ﬁxed and equal to 8 clock cycles. The
worst-case latency for a router to router propagation via the
hub for a single packet transmission can be calculated as
Lchannel = ((cid:98)Stotal − 1/Schannel + 1) × tslot + 1 , where,
Lchannel is the worst-case latency in clock cycles, Stotal is the
total number of slots in the arbitration cycle, and Schannel is
the number of slots assigned to a channel.

The worst-case end-to-end communication delay for a
speciﬁc channel is driven by the slots assigned to the chan-
nel and the total number of slots present in the arbitration
model, and know before scheduling time.

5 SYSTEM DEVELOPMENT AND ANALYSIS

The system development approach for an asymmetric multi-
processor is different from the approach taken in more com-
mon symmetric multiprocessors. In asymmetric multipro-
cessing, tasks are strategically segregated among different
processors based on respective timing requirements. The
robust resource partitioning adds additional complexities
as the tasks need to be segregated in different partitions
under different processors considering partition switching
overheads and inter-task communication delays. Moreover,
apart from WCET, periodicity is crucial for real-time control
applications and different systems may require different
periodicity that should be accommodated by the partition
schedule.

5.1 Timing Analysis

Timing accuracy is critical in airborne systems, and a de-
layed computation is considered as dysfunction. The timing
analysis of a system is more complicated than just analyzing
the WCET of the executable binary, and must be analyzed at
the system level. The response time of a system depends on
the overall timing behavior of individual tasks as well as the
characteristics of the integration, including potential delays
from inter-tasks dependencies, communication delays, and
switching overheads.

5.1.1 WCET of independent tasks

Due to the absence of dynamic delays, the processor fea-
tures a cycle-accurate timing analysis for all tasks. As the
processor consumes one instruction in each cycle and each
instruction interleaves in the processor pipeline for a ﬁxed
number of cycles, the bounded loop longest path execution time
(in cycles) of a given task a, τa, is cycle-accurate, repeatable
and can be calculated from the executable instructions when
executed on a non-partitioned environment (e.g., only one
active partition).

Although a task developed for a single core system does
not have the sense of resource partitioning and can directly
execute within any partition in the proposed architecture,
the partition-scheduling can signiﬁcantly inﬂuence the tim-
ing behavior of the underlying tasks. If a partition P , is
assigned an execution time τp and a periodicity λp, and the
task a is ported in the partition P , then the WCET of task a
in partition P , τpa , can be determined as:

τpa =

− 1

× λp +

τa −

(cid:18)(cid:24) τa
τp

7

(cid:25)

(cid:18)(cid:24) τa
τp

(cid:19)

(cid:27)

− 1

× τp

Note that the partitioning has no effect on the WCET of
the task, when τp > τa. Similarly, if a partition is shared
by multiple tasks say a, b and c, then the WCET time of
individual tasks within the partition τpa , τpb and τpc remains
unchanged as τa, τb, τc when τp > (τa + τb + τc).

5.1.2 WCET of dependent tasks

When a task is dependent on one or multiple tasks and im-
plemented in different partitions under the same or different
processor(s), the scheduling of the partitions can inﬂuence
the response time, e.g., when an application is driven by
two tasks a and b, the WCET time of the application can
be affected by the mutual arrangement of the tasks in
partitions. Two tasks can be segregated in three possible
ways; Case 1: the tasks share the same partition, Case 2: the
tasks are implemented in different partitions, but under the
same processor, and Case 3: the tasks are implemented in
different processors.
Case 1: When the tasks are scheduled sequentially within the
same partition, there is no effect on WCET from the partition
schedule, considering that the partition execution budget
is higher than the collective WCET times of the tasks. The
WCET of the application solely depends on the scheduling
of the tasks inside the partition, and in this case τa + τb, as
shown in Figure 5.
Case 2: When the tasks a, b are scheduled at γa, γb time
respectively in two different partitions under the same
processor, the WCET of the application τs is determined as:

τs = (τp1 − γa) + (γb + τp2

b

) + δSO

where, τp1, τp2 are execution budget of the partitions and
δSO is partition switching overhead.
Case 3: When the tasks a, b are scheduled on different
processors, the WCET of the application greatly depends
on mutual scheduling of the partitions in two different
processors. When, the partitions are synchronized, the best
WCET of the application is:

W CETs = (W CETp1

a

+ δCD + W CETp2

b

)

where, δCD is the worst-case end-to-end communication de-
lay. When there is no synchronization between the partitions
in the processors and assumed to be unknown, the WCET
of the system increases due to unpredictable relative state
of computation in different partitions, and WCET of the
application can be determined as:
W CETs = (cid:0)W CETp1

+ τp1 + τp2 + τp3 + W CETp3

− 1(cid:1)

a

b

Figure 5 shows an example of the three possible distribu-
tions of the tasks a, b and the impact of partition scheduling
on WCET of the resulting functionality.

5.2 Task Synchronization
Dependency in tasks can be mutual, i.e., two tasks α and
β can be inter-dependent. In such cases, synchronization
must be established so that tasks can cooperate. For such
synchronization, the processor features processor ﬂags that
are exposed to all the partitions under all processors, as

PUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

8

5.3 Reliability Analysis

One of the motivations behind the proposed architecture is
to eliminate any single point of failure and to enhance the
reliability of the system. In the past, we have demonstrated
a distributed implementation of a ﬂight controller on an
asymmetric multiprocessor to improve overall reliability
[38].

In [38], the reliability of the NoC is assumed to be
extremely high (reliability 1.0), and also discussed that the
NoC is a single point of failure in such architectures. How-
ever, a shared memory-based communication decreases the
load on the NoC and can potentially prevent complete
system failure while a failure in the NoC is encountered.
Although, in this work, the shared memory does not feature
any hardware-based protection, a software-based protection
mechanism such as mutex can be implemented.

Single or multiple failures in the NI or in the router do
not affect the rest of the network; however, the hub is a
single point of failure in the proposed NoC architecture. The
hub is not reachable by the executing software to modify the
conﬁguration and only susceptible to hardware failures.

Each processor and even each partition can have sepa-
rate memory devices (e.g., SRAM chips) for instruction and
data memory, and thus erroneous operation of a memory
device only affect the associated partition/ processor. For
additional memory protection, redundant memory devices
with a polling mechanism can be implemented.

Besides, PaRTAA features partition ﬂags and processor
ﬂags that are visible to all other partitions in all processors.
These ﬂags can be strategically used to expose the execution
state in each processor and the same can be observed by
other systems in other partitions. This is a novel feature for
health monitoring and safety-net mechanism, as well as task
synchronization as it offers better insight over conventional
time-out implementations. The processor ﬂags are memory-
mapped and read-only, writing on these addresses has no
effect, preventing any partition from altering the ﬂags of
other partitions. Lastly, such ﬂags can potentially be used for
communication as well (e.g., condition checks), thus, adding
more to the communication redundancy.

5.4 System Conﬁguration

Each processor has isolated instruction memory, and the
executable binary shall be downloaded to each instruction
memory separately. Similarly, data needed for the execution
shall be uploaded to each data memory of each parti-
tion under each processor individually. This could be a
time-consuming process and may not be ideal for general
purpose applications. However, once prepared, airborne
systems are used for an extensive period of time without
modiﬁcation and that can justify the time-consuming con-
ﬁguration of the platform.

6 DEMONSTRATION
In our previous works, [3], [4], we have demonstrated the
timing and performance characteristics of the uniprocessor
architecture and the NoC. Therefore, in this work, we have
focused on demonstrating the feasibility and novelty of the
proposed multiprocessor platform in the context of mixed-
criticality airborne systems.

Fig. 5. A timing diagram showing WCET of a system with two sub-
systems a and b under different implementations. Case 1: Both sub-
systems are implemented in the same partition. Case 2: The sub-
systems are implemented in different partitions on the same processor.
Case 3: The sub-systems are implemented in separate processors, and
δ is the worst-case end-to-end communication delay.

explained earlier. A task can set the respective processor
ﬂags to some pre-set values as the execution progresses, and
the other task can read the ﬂag values and proceed with its
execution path accordingly.

Fig. 6. Flow diagram showing synchronization process using processor
ﬂags between two tasks α and β scheduled on different processors.

Figure 6 demonstrates an example of tasks synchroniza-
tion between the tasks α and β implemented in different
processors. The task β sets associated ﬂag to the value x
when it is ready. Task α reads the ﬂag value and sends data
to β. When the data is sent, α sets its ﬂag to m. β waits until
the transmission is reﬂected in the ﬂag controlled by α. Task
β reads the data and sets its ﬂag to y to acknowledge the
reception, and the process continues, as illustrated in Figure
6.

Note that the inter-system communication takes place
over the NoC, where reception is acknowledged using the
processor ﬂags.

aaabbP2P1t1t2t3t4WCETp2p1p3p2p1p3p2p1p2babWCETababWCETt1t1t2t3t4t2,3t4Case 3Case 2Case 1P1P1δp2p3p3read_processor_flag_bsend clk to Pbset_processor_flag_a to mread_processor_flag_bset_processor_flag_a to nclk = read_clockif (clk - prev_clk >= Ta )if (processor_flag_b == x)clk = read_clockif (processor_flag_b == y)prev_clk = read_clockTrueTrueTrueFalseFalseFalseset_processor_flag_b to xread_processor_flag_aif (processor_flag_a == m)msg = read_msg_from_aclk = read_clockoutput = (msg - clk)read_processor_flag_aif (processor_flag_a == n)FalseFalseTrueTrueset_processor_flag_b to y(α)(β)PUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

9

6.1 Setup

The proposed architecture is demonstrated on FPGA LEs.
All the hardware is deﬁned in Verilog and synthesized with
Intel Quartus Prime v18.1 tool. For experimentation and
demonstration, we have used Intel Cyclone V SoC board;
however, the hard processor on the SoC is not used. The
hardware platform features a 50 MHz oscillator, which
is used to clock the processors, the NoC, and other co-
processor IPs. No secondary clock or phase-locked loop (PLL)
is used. The FPGA resources utilized to synthesize the
proposed architecture is presented in Table 2.

TABLE 2
Resource usage in FPGA synthesis.

Hardware components ALMs
2653

Ærø Core

Co-processors

NoC
Total

Ærø without partition

Partition overhead

622

1862
4137

1607

1046

Combi. ALUTs

Registers

2646

707

2123
5476

1408

1223

4493

471

3647
8611

2277

2216

We did not use any ﬂash memory to store the conﬁgu-
ration, and the FPGA needs to be reconﬁgured after each
power cycle. For direct volatile conﬁguration, the synthe-
sized conﬁguration ﬁle (Intel’s proprietary SOF format) is
uploaded via a on-board JTAG connection. The hardware
platform is powered by an external power source, and the
JTAG connection can be removed once the conﬁguration
ﬁle is downloaded on the FPGA. A speciﬁc GPIO pin is
shorted that forces all four active-partition-ﬂags from four
processors to 00, deactivating execution in all processors.
Instructions for each processor and data for each partition is
downloaded separately with two separate UART connection
(for data and instruction). This process is manual. Once
all the data and instructions are downloaded, the GPIO
pin is released, and a global reset button is pressed to
start execution. The global reset clears all control and data
registers and sets program counters to zero.

6.2 Software Development

The custom ISA used in this work also requires a custom
compiler, which is an extensive work. On the other hand,
writing assembly code is difﬁcult and normally quite time
consuming. Instead of developing an ISA speciﬁc compiler,
we have used the standard x86 LLVM clang compiler to gen-
erate assembly code, and we have developed an assembler
to modify the x86 assembly to ﬁt our ISA, before generating
binary executables. We do not claim any novelty of this
method in software development for the airborne system,
but instead we demonstrate the competence of the proposed
architecture with standard language like 1999 ISO C when
software development tools are made available.

The register-register ISA prevents the use of immediate
and the software development must comply with it. All
the variables and constants must be deﬁned and initialized
before use. This is not a challenge in the intended appli-
cation as the software development guidelines for airborne

systems require deﬁnition and initialization of all variables
and constants.

6.3 Avionics Use Case

The avionics use case demonstrates the feasibility of porting
a conventional avionics system onto the proposed architec-
ture as well as its competence towards the requirements
for a mixed-criticality system for airborne platforms. We
have selected four generic avionics systems with different
criticality-levels. The systems, dependencies, and communi-
cation requirements are presented in Table 3.

A ﬂight-director (FD) system, a DAL level A system
(criticality-level 1 in our system), takes input data related
to ﬂight-path and ﬂight data (heading, altitude, attitude,
air-speed etc.) and computes the required manoeuvres to
achieve a pre-set ﬂight-path. The output of the FD is
displayed as cues on horizontal-situation-indicator (HSI) on
a primary-ﬂight-display (PFD) to guide the pilot or the
autopilot system. An autopilot system can generate con-
trol commands to achieve reference altitude, heading, and
speed based on inputs from an FD or a pilot. An engine-
indicating-system (EIS) displays the performance and health
characteristics of the propulsion system on the electronic-
ﬂight-instrument-system (EFIS) for crew awareness. Lastly,
a moving-map system displays the aircraft’s position on a
variety of stored maps for crew awareness.

Fig. 7. The avionics use case demonstration setup. The host system is
a Linux platform that is connected to the FPGA experimental platform
with a UART communication port.

For demonstration, we have developed each system
using model-based-development (MBD) technique with MATH-
WORKS Simulink, where a mathematical/ logical model of
the system is deﬁned by the designer, and later C code is
automatically generated from the model by the embedded
code generator featured on Simulink tool. MBD is a well-
adopted development technique in the aerospace industry,
and the development process can potentially qualify to
DO-178B/C [5], [7] requirements when the guidelines are
followed.

To simulate the dynamics of the airborne platform and
generate required data sources to evaluate the execution of
the systems, we have used X-Plane 11 Flight Simulator, a
matured and well-adopted ﬂight simulator used in several
pilot training programs. The X-Plane 11 simulator executes
on a host system (generic Linux platform) and features
I/O interfacing (simulated sensor readings and control com-
mands) over UDP. To establish communication between the
simulator and the processor platform synthesized on the
FPGA, we have used an interface software that converts UDP

UART IPPaRTAA...Sampling Buffer 2Sampling Buffer nSampling Buffer 1FlightSimulatorEFISInterface SoftwareHOST PLATFORMFPGAUDPUARTPUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

10

TABLE 3
Implemented systems with different criticality-levels and dependencies.

System

Criticality

Dependency

Signal

Processor

Partition

Flight Director
EIS
Moving Map

Autopilot System

1
1
3

2

None
Autopilot
None

FD

N/A
Throttle command
N/A
Pitch Cue, Roll Cue
Speed (IAS), Ref Speed

1
2
2

1

1
1
3

2

System WCET
τ (ms)
1.127
0.527
0.319

Partition WCET
(ms)
2
1
1

1.761

2

packets from the simulator to UART and vice versa and
features a UART communication port to interface with the
FPGA platform. The demonstration setup is presented in
Figure 7. Further, to visualize the computational outputs
from the executing systems, we used an application to sim-
ulate an electronic ﬂight instrument system (EFIS), as shown
in Figure 8. Note that the multi-functional display (MFD)
application works as a widget-based cockpit display system
as deﬁned in ARINC-661 [39], where only the widgets are
driven by the input signals from the FPGA (via interface
software), and the host system drives graphics.

Fig. 8. A screenshot of an Electronic Flight Instrument System simula-
tion with an Horizental Situation Indicator application on the left, moving-
map application on top-right and EIS application on bottom-right.

computational purpose, the FD uses only the protected data
memory allocated to the partition. The output signals from
the FD is sent to the MFD application via UART, and the
output data is written to the shared memory associated
with the processor. The autopilot system and the FD shares
the same processor but executes in different partitions. The
autopilot system reads the FD cues from the shared memory
and uses protected memory for computation. The output is
sent to the X-Plane simulator via UART. The EIS system is
placed on a different processor and receives inputs from
the simulator via UART, and from the autopilot system
via the NoC. When the autopilot is engaged, the EIS reads
the throttle command signal from NoC. The engagement/
disengagement of the autopilot is controlled by a processor
ﬂag. The computed output signals are sent to the MFD ap-
plication using the UART port. The moving map application
is independent. The WCET of each system and partition is
presented in Table 3.

A dysfunction/ failure in the FD system directly affects
the autopilot system due to its dependency on the FD
output signals, irrespective of the communication medium.
However, this has no effect on the systems independent of
the FD system e.g., EIS and Moving map. A dysfunction
in the autopilot system (DAL B) may corrupt the shared
memory, which has no effect on the FD system (DAL A), as
the FD system only writes data to the shared memory. The
NoC is not a single point of failure in this architecture as
a failure in the NoC does not affect the functionality of the
FD and the autopilot system in spite of having inter-system
dependencies.

On the FPGA platform, a custom UART IP core re-
ceives the UART packets from the interfacing application
and stores different signal values in separate sampling
buffers, thus, preventing the received packets from being
overwritten before consumption. This feature is essential to
guarantee the availability of the received data packet for the
correct consumer that may not have execution access at the
time of the reception of the packet, which could be otherwise
overwritten by another data-packet from a different signal
or consumed by another system under partition with execu-
tion access. Such a sampling port-based UART is justiﬁable
in this system as it mimics the behavior of an avionics-data-
concentrator unit used in an avionics system that provides
isolation between data samples of different signals.

For demonstration, we have mapped the applications in
different partitions and processors based on its criticality-
levels, as presented in Table 3. The FD system receives input
signals from the simulator via UART sampling ports. For

6.4 Comparison and Limitations

Conventionally, the applications can be implemented in a
mixed-criticality system with support from a hypervisor for
establishing isolation between the applications with differ-
ent criticality-levels. However, mapping the applications on
PaRTAA does not require a hypervisor or host software sup-
port for establishing isolation, essential for mixed-criticality
implementation. The ARINC 653 partition environment on a
uniprocessor can accommodate multiple applications of the
same criticality-level in the same partition; however only
one application can execute at a time. Similarly, when ap-
plications are segregated on different processors on a single
core equivalent multicore system, only a single application
of a criticality-level gets execution access. In contrast, the
proposed architecture enables the simultaneous execution
of multiple applications of the same criticality-level. An
example of potential mapping of ARINC 653 partitions on

38.038.0389389NPPITTLDG GEARDNDNDNFLAPPARK BRKIGNITIONPUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

11

7 CONCLUSION AND FUTURE WORK
The hardware-based isolation for mixed-criticality systems
must enforce isolation in the temporal or the spatial do-
main to prevent
interference between systems and of-
ten achieved with a large number of isolated processors
that typically results in under-utilized hardware resources.
The proposed multiprocessor architecture features coarse
granularity within each processor for better utilization of
resources while preserving isolation between partitions.
Systems with intense inter-system communication require-
ments can share the same processor where shared memory
can be used for data sharing, while systems with lower
inter-system communication needs can be implemented on
separate processors and communicate over the NoC.

The proposed architecture unveils interesting and new
scheduling challenges. Although we have successfully
scheduled multiple avionics applications for experimenta-
tion and evaluation purposes, the scope of optimal partition
scheduling, along with task scheduling within each parti-
tion remains unaddressed. Furthermore, the work can be
investigated for reliability analysis, where the system can
preserve critical functionality in the event of one or more
subsystem failure.

8 ACKNOWLEDGEMENT
We would like to thank Prof. Edward Lee from UC, Berkeley
and Prof. Peter Koch from Aalborg University, Denmark for
their insightful comments and feedback.

This research is funded by the Danish Independent Re-
search Foundation under the Ministry of Higher Education
and Science, Denmark under grant number 6111-00363B.

REFERENCES

[1] Radio Technical Commission for Aeronautics, RTCA/DO-297: Inte-
grated Modular Avionics (IMA) Development Guidance and Certiﬁca-
tion Considerations, 2005.

[3]

[2] L. Sha, M. Caccamo, R. Mancuso, J.-E. Kim, M.-K. Yoon, R. Pelliz-
zoni, H. Yun, R. Kegley, D. Perlman, G. Arundale, and R. Bradford,
“Single core equivalent virtual machines for hard real—time com-
puting on multicore processors,” 2014.
S. Majumder, J. F. D. Nielsen, and T. Bak, “Ærø: A platform archi-
tecture for mixed-criticality airborne systems,” IEEE Transactions
on Computer-Aided Design of Integrated Circuits and Systems, pp. 1–
1, 2019.
S. Majumder, J. Nielsen, A. La Cour-Harbo, H. Schiøler, and T. Bak,
“A real-time on-chip network architecture for mixed criticality
aerospace systems,” The Aeronautical Journal, vol. 123, no. 1269,
p. 1788–1806, 2019.

[4]

[5] Radio Technical Commission for Aeronautics, RTCA/DO-178B:
Software Considerations in Airborne Systems and Equipment Certiﬁ-
cation, 1992.

[6] Radio Technical Commission for Aeronautics, RTCA/DO-254: De-
sign Assurance Guidance for Airborne Electronic Hardware, 2000.
[7] Radio Technical Commission for Aeronautics, RTCA/DO-178C:
Software Considerations in Airborne Systems and Equipment Certiﬁ-
cation, December 2011.
“Certiﬁcation authorities software team: Position paper cast-32a,
multi-core processors,” 2016.

[8]

[9] Radio Technical Commission for Aeronautics, RTCA/DO-248C:

“Supporting Information for DO-178C and DO-278A., 2011.

[10] Airlines electronic engineering committee (AEEC), ARINC, Inc.,
avionics application software standard interface (ARINC speciﬁcation
653-1)., 2003.

[11] R. N. Mahapatra, J. Lee, N. Gupta, and B. Manners, “Federal
aviation administration: Microprocessor evaluations for safety-
critical, real-time applications: Authority for expenditure no. 43
phase 5 report,” 2011.

Fig. 9. Mapping of ARINC 653 partitions on the proposed architecture
without any hypervisor.

the proposed architecture is illustrated in Figure 9. Appli-
cations with high dependency can be implemented on the
same processor (either on the same partition or different
partition depending on the criticality-level), and data can
be shared using either shared memory or using the NoC or
both (for redundancy), e.g., the ﬂight director and autopilot
application share the same processor in the demonstration
setup, which enhances the system reliability by removing a
single point of failure.

Unlike asymmetric multicore or many-core architectures,
where each system is mapped to a separate processor, this
architecture features a more resource-efﬁcient approach by
allowing systems with different criticality-levels to share a
processor while preserving isolation. Such implementation
avails shared memory for data sharing and reduce the
bandwidth requirement of inter-processor communication
mechanism, such as a NoC. On the other hand, the number
of partitions in each processor is not largely scalable as only
one partition gets execution access at any point of time, and
increment in the number of partitions linearly decreases the
periodicity of other partitions. However, there are only ﬁve
levels of criticality deﬁned for airborne systems, and level
E systems are not implemented with other critical systems,
which limits the requirement of partition to 4. However, the
number of processor in the proposed architecture is scalable,
and multiprocessor platform with more processors can be
fabricated.

The second limitation comes from the IO interfacing as
IOs are not synchronized with software execution. A data-
packet can arrive at the destination when the consumer
system may not have execution access. The received data-
packet may get overwritten by another packet before the in-
tended system gets access to execute, which limits the use of
FIFO based and shared buffer system for IO interfacing, and
all individual IOs shall have a dedicated sampling buffer.
However, data-concentrator based avionics communication
features sampling ports for data-protection and isolation.
There is no speciﬁc requirement or constraint on the data or
instruction memory interfaced with PaRTAA. However, the
limited number of available GPIOs on the physical chip can
be the bottleneck for interfacing large memory devices.

Lastly, the system scheduling on this architecture is
complex as compared to single-core or symmetric-multicore
scheduling due to the additional complexity of partition
scheduling. Each system has a WCET and executes un-
der a partition that has a direct inﬂuence on the WCET.
For optimal scheduling problem, WCET of each system,
communication delay between systems as well as partition
execution times shall be taken into consideration.

APFDHardwareHypervisorPartition 1Partition 2Partition 3FDEISAPMMapProcessor 1Partition 1Partition 2Partition 3MMapEISProcessor 2Partition 1Partition 2Partition 3PUBLISHED: IEEE TRANSACTIONS ON COMPUTERS, VOL. 69, ISSUE. 8, 01 AUGUST 2020 DOI: 10.1109/TC.2020.3002697

12

[12] R. N. Mahapatra, P. Bhojwani, J. H. Lee, and Y. Kim, “Federal
aviation administration: Microprocessor evaluations for safety-
critical, real-time applications: Authority for expenditure no. 43
phase 3 report,” 2009.

[13] J. Rushby, “Partitioning in avionics architectures: Requirements,
mechanisms, and assurance,” National Aeronautics and Space
Administration (NASA), Tech. Rep., 2000.

[14] L. Lindh, “Fastchart-a fast time deterministic cpu and hardware
based real-time-kernel,” in Proceedings. EUROMICRO ‘91 Workshop
on Real-Time Systems, June 1991, pp. 36–40.

[15] J. Adomat, J. Furunas, L. Lindh, and J. Starner, “Real-time kernel in
hardware rtu: a step towards deterministic and high-performance
real-time systems,” in Proceedings of the Eighth Euromicro Workshop
on Real-Time Systems, June 1996, pp. 164–168.

[16] T. Ungerer, F. Cazorla, P. Sainrat, G. Bernat, Z. Petrov, C. Rochange,
E. Quinones, M. Gerdes, M. Paolieri, J. Wolf, H. Casse, S. Uhrig,
I. Guliashvili, M. Houston, F. Kluge, S. Metzlaff, and J. Mische,
“Merasa: Multicore execution of hard real-time applications sup-
porting analyzability,” IEEE Micro, vol. 30, Sep. 2010.

[17] M. Zimmer, D. Broman, C. Shaver, and E. A. Lee, “Flexpret: A
processor platform for mixed-criticality systems,” in 2014 IEEE
19th Real-Time and Embedded Technology and Applications Symposium
(RTAS), April 2014, pp. 101–110.

[18] I. Liu, J. Reineke, D. Broman, M. Zimmer, and E. A. Lee, “A
pret microarchitecture implementation with repeatable timing and
competitive performance,” in 2012 IEEE 30th International Confer-
ence on Computer Design (ICCD), Sep. 2012, pp. 87–93.

[19] D. May, “The xmos architecture and xs1 chips,” IEEE Micro,

vol. 32, no. 6, pp. 28–37, Nov 2012.

[20] M. Delvai, W. Huber, P. Puschner, and A. Steininger, “Processor
support for temporal predictability - the spear design example,” in
15th Euromicro Conference on Real-Time Systems, 2003. Proceedings.,
July 2003, pp. 169–176.

[21] C. E. Salloum], M. Elshuber, O. H ¨oftberger, H. Isakovic, and
A. Wasicek, “The across mpsoc – a new generation of multi-
core processors designed for safety–critical embedded systems,”
Microprocessors and Microsystems, vol. 37, no. 8, Part C, pp. 1020 –
1032, 2013.

[22] S. Trujillo, A. Crespo, A. Alonso, and J. P´erez, “Multipartes: Multi-
core partitioning and virtualization for easing the certiﬁcation
of mixed-criticality systems,” Microprocessors and Microsystems,
vol. 38, no. 8, Part B, pp. 921 – 932, 2014.

[23] H. P´erez, J. J. Guti´errez, S. Peir ´o, and A. Crespo, “Distributed
architecture for developing mixed-criticality systems in multi-core
platforms,” Journal of Systems and Software, vol. 123, 2017.

[24] S. K. Baruah, L. Cucu-Grosjean, R. I. Davis, and C. Maiza, “Mixed
criticality on multicore/manycore platforms (dagstuhl seminar
15121),” in Dagstuhl Reports, vol. 5, no. 3.
Schloss Dagstuhl-
Leibniz-Zentrum fuer Informatik, 2015.

[25] K. Sano, D. Soudris, M. H ¨ubner, and P. C. Diniz, “Applied re-
conﬁgurable computing 11th International symposium, ARC 2015
Bochum, Germany, april 13-17, 2015 proceedings,” Lecture Notes
in Computer Science (including subseries Lecture Notes in Artiﬁcial
Intelligence and Lecture Notes in Bioinformatics), vol. 9040, pp. 191–
201, 2015.

[26] D. Wiklund and D. Liu, “Socbus: switched network on chip for
hard real time embedded systems,” in Proceedings International
Parallel and Distributed Processing Symposium, April 2003.

[27] D. Bertozzi and L. Benini, “Xpipes: a network-on-chip architecture
for gigascale systems-on-chip,” IEEE Circuits and Systems Maga-
zine, vol. 4, pp. 18–31, 2004.

[28] P. H. Pham, J. Park, P. Mau, and C. Kim, “Design and implementa-
tion of backtracking wave-pipeline switch to support guaranteed
throughput in network-on-chip,” IEEE Transactions on Very Large
Scale Integration (VLSI) Systems, vol. 20, no. 2, pp. 270–283, Feb
2012.

[29] P. T. Wolkotte, G. J. M. Smit, G. K. Rauwerda, and L. T. Smit,
“An energy-efﬁcient reconﬁgurable circuit-switched network-on-
chip,” in 19th IEEE International Parallel and Distributed Processing
Symposium, April 2005, pp. 155a–155a.

[30] E. Bolotin, I. Cidon, R. Ginosar, and A. Kolodny, “Qnoc: Qos
architecture and design process for network on chip,” Journal of
Systems Architecture, vol. 50, no. 2, pp. 105 – 128, 2004, special
issue on networks on chip.

[31] S. H. Lo, Y. C. Lan, H. H. Yeh, W. C. Tsai, Y. H. Hu, and S. J.
Chen, “Qos aware binoc architecture,” in 2010 IEEE International

Symposium on Parallel Distributed Processing (IPDPS), April 2010,
pp. 1–10.

[32] E. d. F. Corrˆea, L. A. d. P. e. Silva, F. R. Wagner, and L. Carro, “Fit-
ting the router characteristics in nocs to meet qos requirements,”
in Proceedings of the 20th Annual Conference on Integrated Circuits
and Systems Design, ser. SBCCI ’07. New York, NY, USA: ACM,
2007, pp. 105–110.

[33] C. H. Lu, K. C. Chiang, and P. A. Hsiung, “Round-based priority
arbitration for predictable and reconﬁgurable network-on-chip,”
in 2009 International Conference on Field-Programmable Technology,
Dec 2009, pp. 403–406.

[34] X. JEAN, M. G. G. BERTHON, and M. FUMEY, “Mulcors: Use of

multicore procesors in airborne systems, easa,” 2011.

[35] M. Lo, N. Valot, F. Maraninchi, and P. Raymond, “IMPLEMENT-
ING A REAL-TIME AVIONIC APPLICATION ON A MANY-
CORE PROCESSOR,” in 42nd European Rotorcraft Forum (ERF),
Lille, France, Sep. 2016.

[36] M. Schoeberl, S. Abbaspour, B. Akesson, N. Audsley, R. Capasso,
J. Garside, K. Goossens, S. Goossens, S. Hansen, R. Heckmann,
S. Hepp, B. Huber, A. Jordan, E. Kasapaki, J. Knoop, Y. Li,
D. Prokesch, W. Pufﬁtsch, P. Puschner, A. Rocha, C. Silva, J. Sparsø,
and A. Tocchi, “T-crest: Time-predictable multi-core architecture
for embedded systems,” Journal of Systems Architecture, vol. 61,
no. 9, pp. 449 – 471, 2015.

[37] A. Rocha, C. Silva, R. B. Sørensen, J. Sparsø, and M. Schoeberl,
“Avionics applications on a time-predictable chip-multiprocessor,”
in 2016 24th Euromicro International Conference on Parallel, Dis-
tributed, and Network-Based Processing (PDP), Feb 2016, pp. 777–785.
[38] S. Majumder, J. F. Dalsgaard Nielsen, T. Bak, and A. la Cour-Harbo,
“Reliable ﬂight control system architecture for agile airborne plat-
forms: an asymmetric multiprocessing approach,” The Aeronautical
Journal, vol. 123, no. 1264, p. 840–862, 2019.

[39] Airlines electronic engineering committee (AEEC), ARINC, Inc.,
ARINC 661 COCKPIT DISPLAY SYSTEM INTERFACES TO USER
SYSTEMS ARINC SPECIFICATION, 2001.

Shibarchi Majumder is a doctoral researcher at
the Department of Electronic Systems, Aalborg
University, Aalborg, Denmark. He has years of
industrial and academic experience in avionics
systems, embedded ﬂight computing, hardware
systems and has several publications in related
domains. His research interests include real-
time systems, mixed-criticality systems, hard-
ware design, VLSI, embedded computation and
unmanned aerial systems. Earlier, he received
a bachelor’s degree in Aerospace Engineering

and a master’s degree in Avionics Engineering.

Jens Frederik Dalsgaard Nielsen is employed
as Associate Professor at Aalborg University at
the section Automation & Control. He has a Mas-
ter of Science in EE and a PhD within automa-
tion and control domain. For more than 15 years
he has been heading the student satellite activ-
ities at Aalborg University which has launched
5 cubesats 100% developed at AAU and partic-
ipated in three other launches. His primary do-
main is real-time systems ranging from hardware
to real time operating systems, networking for

safety critical systems and software development.

Thomas Bak received a PhD degree in control
systems from Aalborg University in 1998. He
became an Assistant Professor in 1998, an As-
sociate Professor in 1999, and a Full Professor
of autonomous systems in 2006. From 2003-
2006 he was a senior researcher and head of re-
search unit at Aarhus University. Since 2018 he
is head of the Department of Electronic Systems.
He has published more than 100 papers in the
ﬁelds of control and its applications. His current
research interest includes autonomous systems
and robotics. He is a senior member of IEEE and chair of the IEEE
Joint Chapter on Control System Society and Robotics and Automation
Society. He is associated editor for the European Journal of Control.

