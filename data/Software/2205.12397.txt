Predicting Post-Route Quality of Results Estimates for
HLS Designs using Machine Learning

Pingakshya Goswami and Dinesh Bhatia
Department of Electrical Engineering
The University of Texas at Dallas, Richardson 75080,Texas
Email: (pingakshya.goswami and dinesh)@utdallas.edu

2
2
0
2

y
a
M
4
2

]

R
A
.
s
c
[

1
v
7
9
3
2
1
.
5
0
2
2
:
v
i
X
r
a

Abstract—Machine learning (ML) has been widely used to
improve the predictability of EDA tools. The use of CAD tools that
express designs at higher levels of abstraction makes machine
learning even more important to highlight the performance of
various design steps. Behavioral descriptions used during the
high-level synthesis (HLS) are completely technology independent
making it hard for designers to interpret how changes in the
synthesis options affect the resultant circuit. FPGA design ﬂows
are completely embracing HLS based methodologies so that
software engineers with almost no hardware design skills can
easily use their tools. HLS tools allow design space exploration
by modifying synthesis options, however, they lack accuracy in
the Quality of Results (QoR) reported right after HLS. This lack
of correctness results in sub-optimal designs with problems in
timing closure. This paper presents a robust ML based design ﬂow
that can accurately predict post-route QoR for a given behavioral
description without the need to synthesize the design. The model
is an important design exploration tool where a designer can
quickly view the impact on overall design quality when local
and global optimization directives are changed. The proposed
methodology presents two strong advantages: (i) Accurate predic-
tion of the design quality (QoR), and (ii) complete elimination of
the need to execute high-level synthesis for each design option.
We predict three post route parameters, (i). Area, (ii). Latency
and (iii). Clock Period of a design just by analyzing the high level
behavioral code and some intermediate representation codes. We
have integrated the methodology with Xilinx HLS tools and have
demonstrated accurate estimation on a variety of FPGA families.
Our estimated results are within 10% of actual computed values.

Index Terms—High Level Synthesis, Post-Route Parameter Pre-

diction, Regression Models

I. INTRODUCTION

The use of High-Level Synthesis (HLS) tools for FPGA-
based ﬂows is becoming common as it allows easy con-
version of software descriptions into fairly accurate clocked
hardware designs. HLS based design methodologies enable
designers to focus on algorithmic variations of high-level
programs to obtain the best micro-architectural trade-offs.
HLS reduces the overall design time as it allows the genera-
tion of different versions of a functionally equivalent design
without modifying the behavioral code.

In traditional HLS design ﬂows, there are three control
parameters for generating varying RT-level designs[1]. Local
Synthesis Directives in the form of pragmas are inserted
as comments, Global Synthesis Directives are the options
like desired clock frequency that direct the overall global
synthesis constraints, and Functional Unit Constraints pro-
vide bounds on the number of available functional units
of various types. The last parameter allows tighter control
for SoC/ASIC style designs. Xilinx’s Vivado HLS [2], and
Intel’s HLS compiler [3] do not support the functional unit

Fig. 1: Conventional FPGA Design Flow and the Proposed
Model

constraints. The only global synthesis option that the Xilinx
Vivado HLX supports is the target synthesis frequency.

Figure 1 illustrates a design ﬂow for HLS based designs
targeted on FPGAs. The synthesis directives (Local and
Global )create an annotated input for the synthesis tool.
The annotated input is then synthesized along with the
technology library to generate an RTL code. The process is
iterated in design space exploration many number of times
to obtain an acceptable set of trade off designs (near Pareto-
optimal designs). The selected optimal set of designs then
undergo the steps of logic synthesis, technology mapping,
and place and route.

II. QOR METRICS

HLS tools must report accurate Area and Performance
after each synthesis run. Area reporting in the form of only
the LUT usage [4], [5], [6] and comprehensive usage of
LUTs and other blocks are fairly common in the literature.
In this paper, we will refer to number of LUTs (A) only
for reporting area resources which consistent with other
published works [4], [5], [6]. Commercial HLS tools produce
fairly correct estimates for the BRAM and DSP resources.
Latency (L) in the form of clock cycles is an accepted metric
for FPGA-based design ﬂows, and a correct estimate of
Latency is available after the HLS Synthesis stage. In this
paper, we will report Latency and the post-route maximum
clock frequency fmax .

 
 
 
 
 
 
The rest of the paper is organized as follows. Section IV
gives an overview of the existing work, Section V deﬁned the
problem statement. The proposed post route QoR prediction
model
is described in Section VI. The experiments and
results are presented in Section VII. Section VIII concludes
the paper.

IV. RELATED WORKS

In a recent paper, COMBA [8], the authors presented
a metrics guided design space exploration method where
they study the effect of different pragmas on the latency
of the design. The research produces impressively correct
performance estimates for the behavioral models in a neg-
ligible amount of time. The comparison with Xilinx Vivado
HLS toolset shows that COMBA provides approximately
similar quality estimates compared to the output of HLS
toolset. However, it is observed in [4] as well as [5] that
the post-synthesis QoR, as reported by commercial tools
like Xilinx Vivado HLS, is grossly different from the ﬁnal
post-route QoR for a given design. We have highlighted this
difference through experiments in section II as illustrated in
Figure 2. Dai et al.[4] created a regression based machine
learning model to estimate accurate post- route resource
and timing of a design using features extracted from the
post-synthesis log ﬁles. This work is more like calibration
where resource and timing estimation error is ﬁxed after
a high-level synthesis stage. Both approaches in [4] and
[5] require time consuming C-synthesis step before QoR
estimates can be corrected. In another recent work, Ironman
[6], the authors proposed post route resource and timing
requirement of HLS designs using graph based learning
methods. In order to do so, they used synthesized data ﬂow
graphs(DFG) generated from IR code as an input to their
ML model.

While fairly accurate, the methods reported in [4] and [5]
require a time-consuming synthesis step before QoR can
be accurately estimated and [6] requires scheduled DFG
graphs from synthesis stage. COMBA is a fast approach for
estimation but the accuracy of estimates matches only with
the post C-synthesis results. In Table I, we have summarized
the four relevant works described in [4], [5], [6] and [8], and
compared them with our presented research. The research
presented in this paper is comprehensive and predicts all the
post route vital performance measuring parameters of a HLS
designs viz., clock period, latency and resource requirement
together. It also eliminates the need for full C-synthesis.

V. PROBLEM DEFINITION

Given a synthesizable C/C++ based high-level code with
synthesis directives in the form of pragma, and the desired
global frequency of operation, create a machine learning
based model which will predict the post-route clock period,
latency and resource requirement of a design without syn-
thesizing the design in real time.

We formulated the post route QoR prediction of HLS
design as a machine learning based regression model. Fig.
1 shows the basic block diagram of our proposed method-
ology.

Fig. 2: Plots showing Vivado estimation vs actual post route
values for (a) LUT Utilization; (b) Clock Period; (c) BRAM
Utilization; (d) DSP Utilization

The estimates produced by commercial tools for various
QoR metrics after high-level synthesis at point a(cid:13) in Figure
1 are usually over/underestimated by a large margin when
compared to the actual Quality of Results (QoR) results pro-
duced at c(cid:13) in Figure 1. In our own experiments, we mapped
several designs from CHStone benchmark suite[7] using
Xilinx Vivado HLS 2019.1. In Figure 2, we have plotted the
actual post-route QoR values for both timing and resource
requirement for the baseline designs (designs without any
Local Directives), along with the Vivado HLS error margin
in percentage overlapped on the bar diagrams. Vivado HLS
overestimates clock period and LUT requirement by as much
as 128% and 300% respectively.

III. MAIN CONTRIBUTION

The main contribution in this paper is a robust model
that takes behavioral code and constraints as an input and
produces the ﬁnal post-route QoR metrics as a predicted
output. The designer can use our methodology to construct
a model using the global and local features extracted from
the code. The features are extracted using the LLVM com-
piler toolchain[10] as explained in the section VI. All of the
extracted features come from the LLVM Intermediate Repre-
sentation (IR) frontend and some corresponding graphs. The
model then accurately predicts post-route QoR of designs
without a need to run the high-level synthesis. The main
contributions of this paper are as follows:
• A methodology to extract features from high level C/C++
codes, LLVM IR codes and LLVM control/data ﬂow and
call graphs.

• ML based models to predict accurate and comprehensive
post-route QoR from the high-level behavioral code. These
include maximum frequency fmax , latency (L), and re-
sources (A) requirement for a design, without synthesizing
the designs in real time.

• Presented results which shows the robustness of the pro-
posed model on 10 different HLS designs and 3 different
FPGA devices running at different frequencies.

      11010010001101001000100001000001000000adpcmaveragesobelmatrix_multdfadddfdivdfsinshaaesblowfishNumber of LUT050100150200250300350400024681012adpcmaveragesobelmatrix_multdfadddfdivdfsinshaaesblowfishError in PercentageClock Period in ns020406080100110100Number of BRAMVivado EstimationActualError01002003004005006001101001000adpcmaveragesobelmatrix_multdfadddfdivdfsinshaaesblowfishError in PercentageNumber of DSPVivado EstimationActualError(a) (b) (c) (d) TABLE I: Comparison of the proposed work with the state of the art research

Reference

Predicted Parameter
Resource
(cid:88)
Fast [4]
(cid:88)
Pyramid [5]
(cid:55)
Comba [8]
Ironman [6] (cid:88)
(cid:88)
This Work

Latency
(cid:55)
(cid:55)
(cid:88)
(cid:55)
(cid:88)

Clock Period
(cid:88)
(cid:88)
(cid:55)
(cid:88)
(cid:88)

C-Synthesis Required

Feature Source

Reference Labels

Yes
Yes
No
Scheduled DFG
No

Synthesis Log Files
Synthesis Log Files
Analytical
Scheduled DFG
C++/LLVM IR

Post Route
Post Route
Post C-synthesis
Post Route
Post Route

VI. QOR METRICS PREDICTION FRAMEWORK

A. Feature Extraction

LLVM[10] is a open source compiler which is used to
develop executable codes for multiple platforms. LLVM
generates technology and processor independent assembly
language code called Intermediate Representation (IR). There
is an optimizer present in LLVM, which optimizes the IR
code. The ﬁnal optimized IR code is converted into Control
and Dataﬂow Graphs (CDFGs) which are later used for
scheduling and binding of the generated RTL code. The
LLVM toolchain also generates callgraphs which represent
the inter-function relationships in a C/C++ codes. These
functions are later synthesized as individual modules in the
generated RTL code.

We have analyzed the High Level C/C++ codes, Pragma
optimized LLVM IR codes, Control and Dataﬂow Graphs,
and Call-graphs to extract features that can help us in
predicting ﬁnal QoR metrics. We have used HLS benchmarks
taken from CHStone[7] benchmark set. These benchmarks
are very diverse in terms of code structure, applications
as well as area and timing costs. These benchmarks repre-
sent many single-function and multi-function designs. We
generate multiple versions from a single HLS design by
changing the following six pragmas in the HLS codes: (i)
Loop Unrolling, (ii) Loop Pipelining, (iii) Array Partitioning,
(iv) Array Reshaping, (v) Function Inlining, and (vi) Function
Instantiation.

For each benchmark shown in Table II, we have generated
400 versions (data) of the design by varying the pragmas
and desired target frequency. Table II shows the statistics
of range of variation of Latency, Clock-Period, and the LUT
usage for each benchmark versions when the designs are
mapped on the Zynq 7000 device. Our methodology has
also been veriﬁed using Xilinx VIRTEX and KINTEX series
of devices also. It is clear from Table II that the data is very
diverse and would support building robust training models.

TABLE II: Statistics of Training/Testing benchmarks

Design
Name

adpcm
matrix_mult
sobel
average
dfadd
dfsin
dfdiv
sha
blowﬁsh
aes

Latency
Range

3119-62536
38-274
15-38
2-211
NA
NA
NA
45-1330
23525-36386
2697-2937

Clock Period
Range (ns)

LUT Range

2.078-8.482
3.48-6.849
1.463-8.44
1.338-2.623
3.908-6.616
6.13-8.74
6.687
2.209-4.221
4.421-9.371
2.615-5.021

56-410000
667-7139
33-121
4-3265
3634-4891
4348-8818
3318-3472
101-1889
3357-60537
166-1639

Overall

2-63536

1.436-9.371

4-60537

We have created an extensive set of features to create a
robust prediction model. We extracted a total of 69 features
from four different sources, examples of which are shown
in Table III. The features are either numerical or categorical
features. An example of a numerical feature is the length of
the longest path in the data-ﬂow graph, and an example of
a categorical feature is data-type that can be 8-bit integer,
16-bit integer, or a double-precision ﬂoating point number.
Table III lists some of the important features used for
training the models. The extracted features from each of
the four sources are brieﬂy described here.

i. High Level Code: As shown in Table III, we extract
13 features from the HLS code. These features include
information about the pragmas. Features extracted from
HLS code include information about the loop unrolling and
loop pipelining. We extract unroll factor, pipeline initiation
interval (II) and batch size of the loops. Based on the
pragma arguments, we compute a batch_size for each
loop. It is deﬁned as a ratio between the loop-bound and
the unrolling factor for a loop. While the unrolling factor
represents the degree of parallelism, and the batch_size
represents the depth of the computation.

ii. LLVM IR Code: LLVM IR code are made up of basic
blocks (BB). Each BB is a set of continuous assembly in-
structions, which are branched at if-else conditions, function
returns and loops. We analyzed each of the BB in detail,
and calculated total, maximum and average number of
instructions in each BB. There are 9 types [9] of instructions
in LLVM. From each BB, we calculate the maximum, total
and average number math, sign/zero extension, memory
and logic instruction and vector instructions from the LLVM

TABLE III: List of Features from each source.

Feature
Source

HLS
Code

LLVM IR
Code

CDFG

Callgraph

Total

Feature Examples

No. of
Features

sign ext,

instructions per BB

• Max and average unrolled factor
• Max & Average Batch size of loops
• Max Pipelined Loop Name
• Max & Average Pipelined II
• Max, average and total number of
•
• Max, average, total number of
(math,
memory, vector, other) operations
• Total number of nodes
• Max length of critical path
• Number of FCUs
• Max path length
• Max and average number of
incoming/outgoing edges
• Properties of child functions
Max, min (latency, CP, FCUs)

zero ext,

logic,

13

44

6

6

69

IR code. Example features are shown in Table III. This is
most exhaustive source of features, and we extract 44 featues
from the IR code.

iii. Control and Data Flow Graph: Control ﬂow graphs
CFGs show how the basic blocks (BB) communicate with
each other, propagation of instructions and inter BB de-
pendencies. Data ﬂow graphs (DFGs) show ﬂow of variables
between BBs. DFGss are used to avoid Read-After-Write and
Write-After-Read hazards. Features like total number of BBs,
number of BBs in the longest path, number of incoming and
outgoing edges on a BB, data types of the edges connecting
the BB are extracted from the CDFG. Pre-synthesis func-
tional unit (FCU) counts based on LLVM passes is another
feature extracted from CDFGs. The features from CDFGs
directly effect the latency of a design.

iv. Callgraph: Callgraphs describe the inter-function re-
lationship in a code. Most of the HLS codes are complex
multi_function designs. Each node in the callgraph repre-
sents a function in the HLS code. By analyzing the callgraph,
characteristics of the child nodes like a number of FCUs,
latency, minimum and maximum clock period of child
functions and the datatype passed from one function to
another are extracted and passed to the root (Top) function.
We passed all the features through a feature analysis tool,
xgboost regression feature analysis tool [11] and plotted
the results in Fig. 3. In Fig. 3, we have normalized the
importance of each feature to a range of 0 to 100. Each
bar in Fig. 3 represents the sum of all the features from a
particular source. As it can be seen from the bar diagram, IR
ﬁle features hold most importance, while callgraph features
hold least importance for our regression model.

Fig. 3: Feature Importance Analysis

B. Model Creation

For each data element described in the section VI, we
extract features. The same designs are also routed using
Vivado P & R tools to generate the target labels. We also
observed that the labels can be generated at after logic
synthesis stage also, step b(cid:13) in Figure 1 when the accurate
estimate of resources and a near-accurate estimate of clock
frequency and latency is available to the designer. There is
a small error for clock period, since the router adds the
wire delay thereby increasing the post route clock period
by a small amount- around 1.5 ns. Labels generated after
logic synthesis will also provide same QoR but we will save
substantial (almost 30%) place & route execution time for
label creation. For this particular work, we used the labels

Fig. 4: Training and Prediction Flow

generated after routing. The entire training and prediction
ﬂow is illustrated in Fig. 4, where the black dotted box
represents the training part consisting of feature extraction,
label generation, and training, and the solid box below
represents the prediction ﬂow.

In order to measure the correctness of QoR prediction,
we have used the average of mean absolute percentage error
(MAPE) for all the models. MAPE is calculated using the
following formula:

M APE =

(cid:88)

(cid:175)
(cid:175)
(cid:175)
(cid:175)

1
N

yac t ual

− ypr ed i ct ed
yac t ual

(cid:175)
(cid:175)
(cid:175)
(cid:175)

∗ 100

(1)

In equation 1, ypr ed i ct ed and yac t ual

represents the
predicted and actual value respectively while N represented
the total number of designs being tested.

VII. TESTING AND RESULTS

A. Experimental Setup

We have synthesized and implemented our HLS designs
on Intel Xeon E5-2603 quadcore processor based worksta-
tion with 32 GB RAM. The synthesis and implementation
software used for this work is Xilinx Vivado 2019.1, while
the target hardware is Xilinx Zynq 7000 series FPGA device.
Our methodology has also been veriﬁed using Xilinx VIRTEX
and KINTEX series of devices and we will present to support

Fig. 5: Change in R2 value with increase in training datasize

 020406080100 Clock PeriodLUTLatencyImportancePredicted ParameterHLS CodeIR CodeCallgraphCDFGC/C++ codeLLVM IRGraphsC/C++ codesML TrainingTrained ModelC/C++ codeLLVM IRGraphsPredicted Outputs:(cid:1)(cid:2)Latency(cid:1)(cid:2)Resource(cid:1)(cid:2)Clock PeriodP&RFeaturesLabelsTraining FlowPrediction Flow  0.50.550.60.650.70.750.80.850.90.9510.20.30.40.50.60.70.8R2ValueFraction of Total Design Space Clock Period Latency LUTTABLE IV: MAPE for different models trained

Model Comparison

Model Used
HLS
MLP
RF
XGB

CLK
100.45%
9.69%
7.98%
6.29%

Latency
NA
16.58%
18.25%
10.22%

LUT
392.33%
44.14%
16.28%
10.32%

the versatility of our methodology. We have used state
of the art ML libraries ScikitLearn 0.19.1[12] and xgboost
0.90 [11] running on Nvdia Geforce GTX 1080 GPUs to
train our models. We used cloud-based Comet.ml [13] for
hyperparameter tuning tool.

B. Training of Models

As stated in section II, we have used 400 versions of de-
signs for each of the benchmarks. To study the effectiveness
of a regression model, we have plotted how the value of
R2 increase with increase in training data size in Figure 5.
The x-axis represent the percentage of total design points
used for training. An R2 value in the range of 0.7 to 0.8 is
considered to be good for a model. The plot in the Figure
5 shows that a well-trained model can be achieved using a
small fraction (around 30%) of the total data for predicting
LUT resources and the clock period. However, predicting
for latency may require much larger training data set. Based
on assertions presented in Figure 5, we trained the indi-
vidual designs on the generated 120 versions and predicted
on another 280 designs. The matrix_multiplier design was
trained and tested on half of the total 1500 designs. This is
because matrix_multiplier is highly customizable in terms
of dimensions, pragmas and frequencies.

C. Analysis of Results

We have presented results using all of the ten benchmarks
described in Table II. We have also conducted experiments
to demonstrate the robustness of our models using one
very large and diverse benchmark: adpcm. adpcm is a very
complex benchmark consisting of 13 loops, 10 arrays and
11 different functions. We selected adpcm because it is
the most diverse design in terms of resource and latency
requirement among all the CHStone benchmarks. As shown
in Table II,the LUT utilization ranges from 56 to 410K LUTs,
while ﬂipﬂop utilization ranges from 83 to 237k units and
latency ranges from 3119 to 62536 clock cycles.

We have trained our model using three different regres-
sion models viz. (i) Multi-layer Perceptron Regression (MLP);
(ii) Random Forest (RF) (iii) Gradient Boost Regression
(XGB). The average results for the 10 benchmarks using the
three models are shown in Table IV. In Table IV, we have
shown the average MAPE for the clock, latency, and LUTs for
the ten benchmarks using the three regression models. In
the third row (HLS), average MAPE reported by Vivado HLS
after C-synthesis stage is presented. Each error is computed
against the actual post-route value. It can be observed that
very high accuracy is achieved using ensemble methods like
XGB and RF. We chose XGB as our prefered model for rest
of the experiments.

Table VII shows the MAPE values for each of the ten
benchmarks used for testing. These results are based on XGB
regression model, where training is done on 120 versions of

a design, and prediction is done on 280 versions. Vivado
HLS estimates are shown in Column 3 and 6 in Table VII.
The estimates produced by Vivado HLS are very inaccurate,
and on an average, our prediction is very accurate and
our framework promises to provide a good design guidance
to the designer. The LUT resource usage error change is
relatively higher when compared with the clock period and
the latency of the design. This is because the spectrum
of LUT usage is very wide from a minimum of 4 to a
maximum of 65K LUTS. In Fig. 6, we have show the actual
vs predicted values of all the three predicted parameters
for adpcm benchmark, running on Zynq 7000 FPGA device
using 100MHz frequency. As it can be seen from the ﬁgure,
our prediction highly correlates with the actual value.

Our model is able to capture the effect of the target global
frequency on the overall design and resource usage. It is
expected that the variation of desired global frequency will
result in a change in scheduling during the high-level syn-
thesis, and therefore will result in different architectures with
varying resource usage, latency, and clock-period. We tested
the model for adpcm benchmark. We tested the model
on the baseline (no pragmas design for adpcm). During
training, we generated labels using three target frequency
selections, i.e., 100M H z, 150M H z, and 200M H z. During
testing, we varied the global-desired-frequency constraint
from 100M H z to 500M H z. After 500M H z, Xilinx Vivado
returns the same best possible design. Normally, an HLS
tool will schedule single computation step in multiple clock
cycles when the desired target frequency is very high. Xilinx
Vivado does not perform such mapping. Table V illustrates
the results. We can observe that our model results in very ac-
curate estimates for the QoR metrics. It is worth mentioning
there that we trained on 3 frequencies (100M H z, 150M H z
and 200M H z), while the model is able to accurately predict
on 8 frequencies, 5 of which are not part of the training
dataset. In Table V, we have also shown the estimated values
of Vivado HLS tool after C-synthesis.

We also demonstrate the robustness of our methodology
on other devices from Xilinx, including the Virtex-7 and
Kintex-7 series of FPGAs. We trained the models using labels
when designs were mapped on the selected device. Table VI
presents results when adpcm benchmark was mapped on
Virtex, Kintex, Zynq devices. The test results in Table VI,
however, are based on 64 completely new (blind) versions
of pragma inserted designs that were not part of the train
and validation framework.

VIII. CONCLUSION

We have presented a comprehensive and robust classical
machine learning based post-route timing and resource
requirement prediction tool for FPGA based HLS designs.
Unlike previous approaches [4], [5], [6], our methodology
does not require time consuming C-synthesis step as we
extract features right out of the high-level behavioral code.
Our method improves the state of the art by producing
better or comparable results using a model created prior
to synthesis. We believe that this is ﬁrst such attempt that
models the entire design ﬂow as a machine learning model,

Fig. 6: Actual vs Predicted Values for the timing, latency and resource for ADPCM on Zynq 7000 (100MHz)

TABLE V: Actual vs Predicted values of resource and timing. Frequency Sweep from 100MHz t0 500 MHz

Target Frequency(MHz)
100
125
150
175
200
225
300
500

Clock Period (ns)
Actual
7.74
6.64
6.64
4.55
4.55
4.55
3.00
3.00

Predicted
7.44
7.41
6.29
4.49
4.60
4.60
3.11
3.46

Vivado HLS
9.10
8.30
6.05
5.55
4.49
3.83
3.39
3.39

Latency (clock cycles)
Actual
20104
23604
28254
34004
43154
43204
55954
111654

Predicted
21659
21677
26916
40351
41332
41332
43586
42881

# of LUTs
Actual
2782
2774
2772
2722
2588
2636
2740
3343

Predicted
3244
3244
3244
2605
2735
2735
2749
5095

Vivado HLS
5038
5039
5852
5821
4487
4484
5030
6687

TABLE VI: Validation and Test MAPE on 64 unseen designs on 3 different FPGA devices

Clock Period

Device
Zynq 7000
Virtex 7
Kintex 7

Validation
5.55
4.11
5.51

Test
7.75
6.50
5.06

Vivado HLS
198.09
152.66
82.6

Latency

Validation
20.24
18.36
17.69

Test
17.54
17.10
19.50

Validation
19.02
12.36
14.14

LUT

Test
18.94
17.89
11.70

Vivado HLS
529.27
362.52
531.29

TABLE VII: MAPE for benchmarks and Vivado Estimates

Design
Name
adpcm
ave8
matmul
sobel
dfadd
dfdiv
dfsin
aes
blowﬁsh
Average

Clock Period
This
Work
7.75
7.28
7.92
0.6
6.33
0.19
2.78
9.44
14.35
6.29

Vivado
HLS
198.09
182.14
67.15
163.23
87.88
26.19
39.39
103.46
36.57
100.45

Latency
This
Work
17.54
16.41
11.12
1.76
4.3
NA
NA
NA
NA
10.22

Resource
This
Work
18.94
7.82
8.37
0.94
2.04
0.03
3.78
20.78
30.25
10.32

Vivado
HLS
529.27
73.18
560.78
584.47
98.58
114.38
167.21
911.25
491.91
392.33

Note: NA: Reference labels not reported by HLS tool

thereby totally eliminating the HLS and physical design tools
from the ﬂow.

REFERENCES

[1] B. C. Schafer and Z. Wang, “High-level synthesis design space
exploration: Past, present and future,” IEEE Transactions on
Computer-Aided Design of Integrated Circuits and Systems,
2020.

[2] (2018) Vivado hls. [Online]. Available: https://www.xilinx.com/
products/design-tools/vivado/integration/esl-design.html
[3] (2021) Intel® sdk for opencl™ applications. [Online]. Avail-
able: https://software.intel.com/content/www/us/en/develop/
tools/opencl-sdk.html

[4] S. Dai , et. al, “Fast and accurate estimation of quality of results
in high-level synthesis with machine learning,” in 2018 IEEE
FCCM.

[5] H. Makrani , et. al, “Pyramid: Machine learning framework to
estimate the optimal timing and resource usage of a high-level
synthesis design,” in 2019 29th FPL, 2019.

[6] N. Wu, Y. Xie, and C. Hao, “Ironman: Gnn-assisted design
space exploration in high-level synthesis via reinforcement
learning,”
the 2021 on Great Lakes
Symposium on VLSI. New York, NY, USA: Association for
[Online]. Available:
Computing Machinery, 2021, p. 39–44.
https://doi.org/10.1145/3453688.3461495

in Proceedings of

[7] Y. Hara , et. al, “Chstone: A benchmark program suite for prac-
tical c-based high-level synthesis,” in 2008 IEEE International
Symposium on Circuits and Systems, 2008.

[8] J. Zhao , et. al, “Comba: A comprehensive model-based analy-
sis framework for high level synthesis of real applications,” in
2017 IEEE/ACM International Conference on Computer-Aided
Design (ICCAD).

[9] (2019) Llvm language reference manual. [Online]. Available:

https://llvm.org/docs/LangRef.html

[10] C. Lattner , et. al “Llvm: A compilation framework for lifelong
program analysis & transformation,” in 2004 Proceedings of the
International Symposium on Code Generation and Optimiza-
tion.

[11] (2019) Understand

your

[On-
https://xgboost.readthedocs.io/en/latest/

dataset with

xgboost.

line].
R-package/discoverYourData.html

Available:

[12] Scikit

learn machine learning library.

[Online]. Available:

www.scikit-learn.org

[13] Comet ml supercharging machine learning tool.

[Online].

Available: www.comet.ml

