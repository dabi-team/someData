 2015 informe de Avance Proyecto Control y automatizaci√≥n - Beca CEIBA 

Procesamiento Digital De Im√°genes Aplicado A La Segmentaci√≥n 
De Objetos Por intensidad y movimiento. 
Benjam√≠n Andr√©s Hu√©rfano Zapata1 Universidad de Cundinamarca 

Resumen‚Äî El desarrollo tecnol√≥gico actual nos permite llevar  a 
cabo tareas que hace alg√∫n tiempo eran impensables por no decir 
que imposibles, el procesamiento digital de im√°genes ha sido una 
de las mayores constantes de desarrollo en la actualidad, teniendo 
en  cuenta  que  su  implementaci√≥n  data  de  poco  tiempo  atr√°s, 
OpenCV [1] es una herramienta enfocada en la visi√≥n artificial, en 
este  caso  implementada  en  una  plataforma  de  programaci√≥n  
orientada  a  objetos  basado  en  lenguaje  en  Java1  ofrecida  por  el 
software de desarrollo NetBeans2, Teniendo como base lo anterior 
se plante√≥ e implemento una plataforma f√≠sica a modo de ambiente 
cerrado la cual a trav√©s del desarrollo de un algoritmo permiti√≥ 
detecci√≥n y segmentaci√≥n de objetos por medio del modelo de color 
RGB;  en  trabajos  futuros  dicho  algoritmo  brindara  la  base  de 
informaci√≥n  para  la  plataforma  rob√≥tica aut√≥noma;  este  avance 
abre  un  amplio  espectro  para  el  desarrollo  de  aplicaciones  y 
herramienta  en el campo de la visi√≥n artificial. 

Palabras  clave‚Äî  Detecci√≥n  de  objetos,  RGB,  Visi√≥n  artificial, 

OpenCV, C#, EmguCV.  

I.  INTRODUCCI√ìN 

El  avance  tecnol√≥gico  actual  ha  venido  presentado  una 
constante  evoluci√≥n  en  cuanto  al  desarrollo  de  software  se 
refiere  como  lo  se√±ala  Gonzales  [2]  esto  ha  tra√≠do  consigo 
numerosas ventajas, entre las cuales cabe destacar el desarrollo 
de  tecnolog√≠as  que  son  por  mucho  m√°s  eficientes,  r√°pidas  y 
baratas [3];  como resultado de lo anterior se hace plausible e 
interesante    abordar  ciertas  tem√°ticas  que  hace  alg√∫n  tiempo 
pudieron haber sido despreciadas o desechadas por la exigencia 
de  gran cantidad recursos  computacionales. Gracias a que las 
nuevas tecnolog√≠as han conseguido mejorar  en gran medida las 
velocidades de procesamiento de la informaci√≥n y as√≠ un vasto 
camino para estudio en el desarrollo de algoritmos mucho m√°s 
eficaces. 

El  actual  documento  expone  el  desarrollo  de  un  algoritmo 
basado  en  programaci√≥n  orientado  a    objetos  basado  en  el 
lenguaje  Java,  a  trav√©s  de  la  plataforma    de  programaci√≥n 
brindada por el software NetBeans, que en conjunto y haciendo 
uso de la librer√≠a OpenCV de visi√≥n artificial desarrollada por 
Intel, la cual entre otra ventajas cuenta con licencia libre desde 
su aparici√≥n con la primera versi√≥n alfa en el mes de enero de 
1999, ha sido implementada en infinidad de aplicaciones: desde 
sistemas  de  seguridad  con  detecci√≥n  de  movimiento,  hasta 
aplicaciones  de  control  de  procesos  en  los  que  se  requiere 
reconocimiento de objetos. Esto se debe a que su publicaci√≥n se 
da  bajo  licencia  BSD,  que  permite  que  sea  usada  libremente 
para  prop√≥sitos  comerciales  y  de  investigaci√≥n  con  las 
condiciones en ella expresadas. 

II.  DESCRIPCI√ìN Y CARACTERIZACI√ìN DEL DISE√ëO DEL 
ALGORITMO: 

En el actual documento plantea como problem√°tica esencial 
la  detecci√≥n  y  segmentaci√≥n  de  varios  objetos  de  colores 
previamente determinados, en un entorno compuesto distintos 
objetos para esto se us√≥ una descomposici√≥n de la imagen pixel 
por  pixel  y  un  posterior  filtrado  de  histogramas  por 
ecualizaci√≥n.  El  algoritmo  deb√≠a  de  estar  en  la  capacidad  de 
identificar  la  distancia  y  el  centro  del  objeto  (de  un  color  en 
espec√≠fico)  con  respecto  a  los  dem√°s  objetos  y  as√≠  mismo 
mostrar  lo  resultados  obtenidos  de  la  imagen,  adem√°s  de 
segmentar  e  identificar  cada  objeto  como  independiente  sin 
importar si contaban con el mismo color.  

Para  lo cual se identificaron y definieron aspectos generales 
a  abordar  para  esta  manera  poder  implementar  un  algoritmo 
mucho m√°s robusto y completo. 

A.  Caracterizaci√≥n del ambiente de trabajo: 
Se procede a identificar las caracter√≠sticas b√°sicas esenciales 
del ambiente de estudio, el cual lo enmarcaremos con los rasgos 
primordiales  de  una  √°rea  real  de  trabajo  de  tipo  industrial 
automatizado  [4],  donde  dicha  √°rea  se  caracteriza  por  contar 
con  caracter√≠sticas  de  limpieza,  no  intersecci√≥n  de  diferentes 
zonas  de 
trabajo,  ambiente  propicio  para  el  control 
implementado, entre otras cuantas. 

Se  definieron  como  caracter√≠sticas  indispensables  para  un 
ambiente  propicio  un  fondo  monocrom√°tico  que  permitiera 
identificar  los  objetos,  definido  con  color  blanco  el  fondo 
implementado  cuneta  con  un  √°rea  de  1ùëö2  con  longitudes 
laterales equitativas de 100ùëêùëö. 

Ubicaci√≥n  de  la  c√°mara  frontal  a  fin  de  lograr  un  mapeo 

general del fondo usado. 

Ambiente con buenas condiciones de iluminaci√≥n la cual se 
implement√≥ iluminaci√≥n de tipo frontal la cual ayuda permite la 
iluminaci√≥n uniforme y es usada com√∫nmente en sistemas de 
detecci√≥n de objetos [5].  

B.  Modo de adquisici√≥n de informaci√≥n: 
La  adquisici√≥n  de  informaci√≥n  se  realizara  a  trav√©s  de  una 
c√°mara HD (Logitech HD Pro Webcam C920)  por medio de 
protocolo  USB  2.0,  ofreciendo  de  este  modo  gran  calidad  de 
imagen y eficacia en la trasmisi√≥n de informaci√≥n [6]. 

La cual se encuentra situada a 154ùëêùëö con el fin de permitir 
un pixel para la resoluci√≥n actual represente un √°rea 2.25ùëöùëö2, 
la cual fue definida por el √°rea de cobertura proporcionada por 
la c√°mara que conto con 96ùëêùëö de largo y 72ùëêùëö de ancho para 
un total 0.69ùëö2. 

1  ‚ÄúJava  es  un  lenguaje  de  programaci√≥n  y  una  plataforma  inform√°tica 
comercializada desde en 1995 por Sun Microsystems‚Äù [10]. La versi√≥n de Java 
usada actualmente es la orientada a objetos. 

2  NetBeans  es  un  proyecto  de  c√≥digo  abierto  dedicado  a  proporcionar 
productos de desarrollo de software solidos como NetBeans IDE y NetBeans 
Platform [11]. 

 
 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaci√≥n - Beca CEIBA 

C.  Selecci√≥n de escala del color: 
El desarrollo expuesto por el presente se bas√≥ en la creaci√≥n 
un algoritmo, el cual permiti√≥ identificar los colores primarios 
en este caso en la escala de RGB3 (Rojo, Verde Y Azul) puesto 
que el modelo de codificaci√≥n usado por la c√°mara seleccionado 
es el anteriormente mencionado, y con el fin de evitar p√©rdidas 
de  recursos  computacionales  y  eficiencia  del  algoritmo  en  la 
trasformaci√≥n a otro tipo de escala. 

D.  Tiempo de muestreo: 
El tiempo de muestreo como meta definido para el actual es 
definido  el  fin  de  contar  con  una  continuidad  m√≠nima  de 
fotogramas, cercana a la imperceptible por el ojo humano, por 
otra parte dicha cantidad de muestras por unidad de tiempo est√° 
limitada  por  la  cantidad  posible  de  obtener  por  la  c√°mara 
seleccionada siendo un m√°ximo de 30ùëìùëùùë†.  

Finalmente  teniendo  en  cuenta  una  cantidad  de  tiempo 
prudente de procesamiento  de la mitad del tiempo de captura 
dando un margen meta de m√≠nimo 15ùëìùëùùë†. 

E.  La interfaz gr√°fica: 
La  interfaz  gr√°fica  deb√≠a  de  contar  con  caracter√≠stica  de 
modularidad con el fin de permitir identificar con facilidad los 
resultados obtenidos y poder mantener de forma ordenada cada 
uno de sus componentes. 

Deb√≠a  contar  con  la  posibilidad  de  realizar  ajustes  sobre  la 
ejecuci√≥n  para  diferentes  variables  de  importancia  dentro  del 
algoritmo, igualmente contar con la posibilidad de observar los 
resultados obtenidos de forma tanto visual como matem√°tica. 

Figura 1 ‚Äì Interfaz grafica implementada 
Fuente: Autor 

F.  Caracterizaci√≥n de los objetos: 
Los  objetos  inmersos  dentro  del  ambiente  contaban  con 
caracter√≠sticas diferenciables a primera vista con el fin de poder 
leer  los  resultados  con  mayor  facilidad  para  el  actual 
documento. Por tanto definimos los colores Verde, Rojo, Azul 
y negro, dichos colores ser√°n los que se segmentaran de nuestro 
ambiente de trabajo. 

Definimos  un  tama√±o  m√≠nimo  de  25ùëêùëö2  para  cualquier 
objeto inmerso dentro del ambiente, con el fin de evitar que la 
aparici√≥n de  ruido  inmerso  en  la  imagen  llegase  a  afectar las 
mediciones obtenidas. 

3  RGB es  un  modelo de color basado  en  la  s√≠ntesis  aditiva, con  el que  es 
posible representar un color mediante la mezcla por adici√≥n de los tres colores 
de luz primarios [12]. 

III.  MODO DE ALMACENAMIENTO DE LA IMAGEN 

Para  llegar  a  al  desarrollo  del  actual  algoritmo  se  debe 
esclarecer previamente sobre la forma en la que se almacena la 
informaci√≥n  de  la  imagen.  Aunque  una  imagen  es  la 
reproducci√≥n de la figura de un objeto por la combinaci√≥n de 
los  rayos  de  luz  que  inciden  en  el  mismo,  dentro  de  un 
ordenador  una  imagen  no  es  m√°s  que  una  gran  secuencia  de 
datos. Como es conocido, el tama√±o de las im√°genes se mide en 
p√≠xeles,  que  es  precisamente  la  superficie  homog√©nea  m√°s 
peque√±a de las que componen una imagen [7], que se define por 
su brillo y color lo cuales esta definidos por el valor que toma 
el pixel. 

Las  im√°genes  en  blanco  y  negro  (binarias)  son  las  m√°s 
b√°sicas,  pudiendo 
tomar  sus  p√≠xeles  valores  entre  0 
(completamente  negro)  y  1  (completamente  blanco).  Sin 
embargo las im√°genes de color contienen tres canales de colores 
distintos (Para nuestro caso RGB por sus siglas en ingl√©s (R : 
rojo, G : verde, B : Azul) . Cada canal puede tomar un valor 
entre  0  y 255  correspondiente  a  un  byte  de  informaci√≥n,  por 
ejemplo  un  ùëÖ = 255, ùê∫ = 0,  y  ùêµ = 0  ser√°  un  p√≠xel 
completamente  rojo.  Si  los  tres  valores  son  255  el  p√≠xel  ser√° 
blanco, y si los tres valen 0 el p√≠xel ser√° negro, una vez definido 
esto  se  identifica  como  a  trav√©s  de  la  mezcla  de  estos  tres 
colores  base  se  obtiene  16‚Ä≤581.375  posibilidades  por  pixel, 
permitiendo as√≠ tener una gran cantidad de matices. 

La imagen ademas se compone de caraceristicas principales 
tales como  altura, ancho,  numero de canales. Por tanto para 
recorrer los valores de una imagen se puederelizar de izquierda 
a derecha o de arriba a abajo. Teniendo en cuenta adem√°s que 
los canales est√°n ordenados en BGR (azul, verde y rojo). Est√° 
es la √∫nica  forma de recorrer im√°genes,  y se implementa con 
bucles anidados aplicados a una matriz o array dependiendo el 
modo de almacenamiento o de obtencion de informacion usado.   

IV.  IDENTIFICACI√ìN POR COLOR  

Para detectar un objeto de determinado color inicialmente se 
necesita identificar todos los p√≠xeles que lo componen. Para ello 
se  realiza  una  b√∫squeda  en  todos  los  datos  de  la  imagen, 
calculando si son o no del color deseado. Para la distinci√≥n del 
color  que  se  est√°  evaluando  en  ese  instante;  se  realiza,    en 
primer lugar la selecci√≥n de datos caracter√≠sticos que contienen 
el pixel de color y finalmente la cercan√≠a con el color deseado, 
con el fin de clasificarlo o no dentro del tipo de color buscado. 
Por tanto su dato m√°s caracter√≠stico ser√° que el canal con mayor 
valor. Es de vital importancia tener en cuenta que los valores de 
los dem√°s canales no deber√≠an ser muy altos, por lo menos no 
lo suficiente como para acercarse al valor del canal testeado, ya 
que  estos  valores  podr√≠an  corresponder  a  colores  como  el 
morado,  el  naranja,  el  amarillo  entre  otros,  lo  cual  crear√≠a 
lectura  err√≥neas  sobre  la  captura  de  la  imagen  y  arrojar√≠an 
resultados indeseados, con este fin de delimito el algoritmo a 
partir de los canales del pixel evaluado, mirando que el valor 
del  pixel  estaba  contenido  entre  el  espectro  de  color  que 
deseamos identificar. 

 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaci√≥n - Beca CEIBA 

Con un color que no  pertenece de los tres b√°sicos de RGB 
(Ej. negro), se vuelve un poco m√°s complejo este paso, pues se 
debe definir unas restricciones m√°s estrictas y un rango amplio 
para el cual se puede clasificar el color, de igual manera al tener 
dichos cambios permitir√° poder detectar los colores sin que los 
afecte la iluminaci√≥n con tanta facilidad puesto las tonalidades 
y degrades presentes en la superficie del objetos se encontrar√≠an 
inmersas en los mismos. La detecci√≥n de colores resultantes de 
mezclas  se  debe  identificar  y  clasificar  en  una  matriz  o  de 
manera homologa una base de datos, permitiendo as√≠ acceder al 
valor y compararlo con el que se observa. 

entre  estos  objetos  y  de  igual  forma  para  la  segmentaci√≥n de 
objetos.  Est√°s  coordenadas  del  punto  medio  ser√°n  bastante 
precisas  si  contamos  con  una  gran  cantidad  de  p√≠xeles  del 
objeto, y nos ser√° de gran utilidad para ubicar dicho objeto con 
respecto a nuestra plataforma rob√≥tica. 

Supondremos  a  contamos  con  un  robot  un  punto  de 
referencia  de  un  color  este  caso  se  asigna  el  color  verde. 
Calculamos el punto medio de dicho objeto de referencia, Una 
vez tenemos las coordenadas sabemos si el objeto se encuentra 
a  nuestra  izquierda  o  derecha,  y  arriba  o  abajo  de  nuestra 
plataforma rob√≥tica un punto de llegada en la zona de color rojo 
o azul. Procedemos a hallar la distancia del robot con respecto 
a  las  zonas  de  llegada  (en  p√≠xeles)  mediante  la  f√≥rmula  de  la 
hipotenusa: 

ùê∑ùëñùë†ùë°ùëéùëõùëêùëñùëé = ‚àö(ùë•2

  ‚àí ùë•1)2 + (ùë¶2 ‚àí ùë¶1)2 

Donde ùíôùíä representa la coordenada ùë• y ùíöùíä la coordenada en 

ùë¶ dados pixeles del objeto ùëñ. 

a) 

  b) 

Figura 2 ‚Äì a) Imagen capturada y b) Imagen procesada por color. 
Fuente: Autor. 

La dificultad de este m√©todo es que solo detectar√≠a colores de 
tipo  solido  frente  al  objeto  testeado,  sabiendo  que  la  forma 
irregular de los objetos que puede presentar en la imagen nos 
puede  efectos  de  cambio  de  la  intensidad  del  color del  pixel, 
este  caso  lo  anterior  se  soluciona  dejando  un  rango  neutro 
adicional entre los colores mezcla y los RGB primarios, y a la 
par  utilizar  un  extrapolaci√≥n  de  la  imagen  para  detecci√≥n  de 
bordes con el uso de primeras y segundas derivadas entre los 
valores de lo pixeles adyacentes [8], lo cual nos permitir√≠a los 
cambios brucos de entorno y as√≠ mismo determinar los bordes 
del objeto deseado. 

V.  POSICIONAMIENTO 

El posicionamiento permitir√° adquirir informaci√≥n vital del 
ambiente en el cual se est√° desarrollando el estudio, en este caso 
hace referencia al posicionamiento de los objetos identificados, 
permitiendo  identificar  caracter√≠sticas  como  tama√±o,  forma, 
distancia y centro del objeto estudiado. 

 Para  ubicaci√≥n  de  los  objetos  y  de  los  pixeles  de  color 
deseado,  se  guardaron  todas  las  coordenadas  de  cada  pixel 
identificado  y que  se  encontraban  a  su  vez  clasificado  en los 
colores deseados (Rojo, Verde, Azul y Negro) gracias a la suma 
de sus posiciones,  se calcul√≥  ser√≠a el punto medio de nuestro 
objeto a trav√©s de la siguiente formula: 

ùëõ
‚àë
ùëñ
ùëñ‚ààùëÇùê∑
ùëõ
‚àë
ùëñ‚ààùëÇùê∑  
1

  ùë¶  

ùëö
‚àë
ùëó
ùëó‚ààùëÇùê∑
1ùëö
‚àë
ùëñ‚ààùëÇùê∑  

Figura 3 ‚Äì Posicionamiento de objetos en la figura 3 b). 
Fuente: Autor. 

1

Ahora  contamos  con  la  posici√≥n  y  distancia  entre  objetos, 
pero como lo indica la figura 4 aun no conocemos el √°rea de la 
ùëõ
imagen  que  ocupa  cada  objeto  se  conoce  que  (‚àë
ùëñ‚ààùëÇùê∑ ‚àó
2.25ùëöùëö2) nos indica el √°rea real aproximada ocupada por el 
objeto actual. Pero debido a la naturaleza de los objetos que es 
irregular  se  hace  necesario  enmarcar  el  objeto  en  un  √°rea 
cuadrada  un  poco  m√°s  amplia  para  contar  con  un  margen  de 
distancia  entre  un  obst√°culo  y  lo  definido  como  plataforma 
rob√≥tica  para  el  documento,  para  efectos  del  estudio 
definiremos  el  color  negro  como  obst√°culos,  los  cuales  ser√°n 
enmarcados  de  la  manera  anteriormente  propuesta,  por  tanto 
para lograrlo se realiza un sondeo de la coordenada m√≠nima y 
m√°xima del obst√°culo evaluado del siguiente modo: 

(min
i‚ààOD

ùëñ , min
j‚ààOD

ùëó)  ùë¶  (max
i‚ààOD

ùëñ , max
j‚ààOD

ùëó) 

Proporcion√°ndonos    de  este  modo  un  √°rea  cuadrada  cual 

enmarca el obst√°culo que estudiado. 

Finalmente usando a forma de un plano cartesiano la imagen 
adquirida  se  ubican  en  dos  dimensiones  los  objetos  lo  cual 
brinda  una  perspectiva  panor√°mica  de  ambiente  en  el  que  se 
encuentra el robot (color verde). 

Donde ùëõ  y ùëö  representa  el  largo  y  ancho  de  la  imagen  en 
pixeles respectivamente, ùëÇùê∑ el conjunto de pixeles de un objeto 
de un color  deseado. Con estos se consigue la coordenada en 
(ùíô,ùíö)  en  pixeles  del  centro  del  objeto  evaluado,  lo  cual 
posteriormente nos servir√° de base para el c√°lculo de distancia 

VI.  SEGMENTACI√ìN 

La segmentaci√≥n  se centra en c√≥mo aislar los objetos o partes 
de objetos del resto de la imagen. Las razones para hacer esto 
son obvias. Por ejemplo, una c√°mara suele mirar hacia el mismo 
fondo,  que  no  es  de  ning√∫n  inter√©s.  Lo  que  interesa  de  esa 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaci√≥n - Beca CEIBA 

imagen es detectar cu√°ndo las personas o veh√≠culos entran en la 
escena, o cu√°ndo algo se deja en la escena que no estaba all√≠ 
antes [9].  

Por  tanto  se  desea  aislar  esos  acontecimientos  e  ignorar 
interminables  horas  en  que  nada  est√°  cambiando.  Este  es  un 
ejemplo  de  los  muchos  usos  que  tiene  la  segmentaci√≥n  de 
objetos en el procesamiento de im√°genes. 

La segmentaci√≥n de los objetos consiste en como su nombre 
lo indica, en una divisi√≥n o separaci√≥n de objetos con el fin de 
indicar que son distintos y que se encuentran en otra parte del 
plano  al  que  se  est√°  observando.  Adem√°s  permite  tener  una 
mayor perspectiva del n√∫mero de objetos  al que se observa y 
asimismo generar  un posicionamiento de cada uno de ellos con 
respecto a la plataforma rob√≥tica. En este caso  supusimos es el 
objeto de color verde. 

La segmentaci√≥n de los objetos que son objeto de estudio se 
realiz√≥ por medio de las diferencia entre distancias de distintas 
aglomeraciones de pixeles perteneciente a obst√°culos, para lo 
cual  haremos uso de un rango definido  de 10 ùëùùë•, donde una 
diferencia  entre  el  ultimo  de  pixel  ‚àà ùëÇùê∑  de  la  imagen  con 
respecto al siguiente en una misma fila o columna de la imagen, 
representara un nuevo posible objeto, si la nueva aglomeraci√≥n 
de pixeles encontradas supera el √°rea mencionada en (ùêºùêº. ùêπ) se 
considera  como  un  objeto  nuevo  y  distinto  al  primer 
encontrado. 

Logrando  as√≠  detectar  m√∫ltiples  objetos  del  mismo  color  y 
que  en  conjunto  a  las  caracter√≠sticas  expresada  en  (ùêºùêºùêº. ) 
permiten su total segmentaci√≥n y ubicaci√≥n. En este caso ser√°n 
los  objetos  definidos  como  obst√°culos  anteriormente  (color 
negro) que estar√°n en la misma imagen pero diferentes √°reas de 
la imagen.  
En  este  caso  sabemos  que  hay  distintos  objetos  que 
identificados, y que unos p√≠xeles pertenecer√°n a un obst√°culo, 
otros p√≠xeles pertenecer√°n a otros. ¬øC√≥mo saber de qu√© objeto 
se  trata?  Para  ello  haremos  uso  de  una  instancia  del  tipo  de 
programaci√≥n  que  estamos  empleando  es  la  creaci√≥n  de 
entidades  conocidas  como  objetos,  los  cuales  permitir√°n 
guardar  la  informaci√≥n  de  cualquier  obst√°culo  presente  en  el 
√°rea de estudio. Obteniendo  finalmente lo representado por la 
figura 5. 

a) 

  b) 

Figura 4 ‚Äì a) Imagen capturada y b) Imagen segmentada. 
Fuente: Autor. 

Donde  se  puede  observar  como 

las  caracter√≠sticas 
anteriormente mencionadas se reflejan en la figura 5 b), donde 
los  obst√°culos  sin  importar  su  forma  son  enmarcados  e 
identificados como distintos. Sin ser afectados por la cercan√≠a 
con  otro  objeto  de  distinto  color,  los  cuales  siguen  siendo 
posicionados y ubicados plenamente. 

VII.  IMPLEMENTACI√ìN DEL ALGORITMO 

Tomando  lo  anteriormente  expuesto  se  procedi√≥  a  generar  el 
c√≥digo del algoritmo el cual conto con una estructura como la 
expuesta por la figura 6: 

Figura 5 ‚Äì Diagrama de bloques del algoritmo. 
Fuente: Autor. 

En detalle el algoritmo realiza se presenta como: 

‚Ä¢ 

Inicializaci√≥n el programa y definici√≥n de variables globales 
y especiales. 

‚Ä¢  Para la carga de la imagen obtenida a trav√©s de la c√°mara por 
medio  de  protocolo  USB,  se  tienen  en  cuenta  los  posibles 
errores de carga y dificultades del ordenador y se generan las 
excepciones  necesarias  con  el  fin  de  evitar  fallos  en  el 
programa y en el computador. 
 Se  obtienen  las  caracter√≠sticas  de  la  imagen    datos  con  los 
cuales podremos recorrer la imagen. 

‚Ä¢ 

‚Ä¢  Convertimos le mapa de bits en  una matriz la cual se recorre 
para acceder a los valores de los p√≠xeles teniendo cuenta sus 
caracter√≠sticas  obtenidas  del  punto 
dimensiones  y 
inmediatamente anterior. 

‚Ä¢  Se  eval√∫a  cada  valor  y  se  clasifica  el  pixel  seg√∫n  las 

restricciones y rangos anteriormente dispuestos. 

‚Ä¢  Se modifican los pixeles dentro de la matriz parar indicar el 

cambio detecci√≥n del color. 

‚Ä¢  Se eval√∫a la presencia de posibles objetos del mismo color. 
‚Ä¢  Se genera segmentaci√≥n de obst√°culos de modo indicado en 

el apartado (ùëâùêº. ). 

‚Ä¢  Por medio de las ecuaciones mencionadas en el apartado de 
posicionamiento se realizan los respectivos c√°lculos de centro 
de cada objeto y medida de distancias. 

‚Ä¢  Se enmarcan los obst√°culos segmentados identificados. 
‚Ä¢  Y finalmente se recrea la imagen y se muestran los resultados 
obtenidos  por  el  algoritmo.  De  manera  seguida  se  liberan 
recursos del programa Se regresa al t√≠pico inicial. 

VIII.  AN√ÅLISIS Y RESULTADOS 

Una vez desarrollado el algoritmo se  procedi√≥ a realizar el 
testeo del mismo, el cual se realiz√≥ en un computador personal 
de gama media con las caracter√≠stica indicadas en el cuadro 1. 

Procesador: 
Memoria RAM: 
Tarjeta de video: 
C√°mara: 
Sistema operativo: 

Intel Pentium 2.2ùê∫ùêªùëß 
6 ùê∫ùêµ 
Intel(R) HD Graphics integrada 
Logitech HD Pro Webcam ùê∂920 
Windows 7 Ultimate ‚Äì 64ùëèùëñùë°ùë† 

  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaci√≥n - Beca CEIBA 

NetBeans IDE: 
Java(TM): 
OpenCV 

8.1 
1.8.0_45 ‚àí ùëè15 
3.0.0 

Cuadro 1 ‚Äì Caracter√≠sticas de hardware y de software de ordenador 
usado. 
Para realizar las pruebas  se tomos una contante de 10 medidas 
las con aras de tener un buen margen acercamiento al valor real 
de fps y frecuencia de muestreo logrado por el algoritmo, dichas 
medidas se realizaron por medio de un c√≥digo en Java el cual 
mostraba  la  hora  de  inicio  de  ejecuci√≥n,  la  hora  el  final  y  el 
n√∫mero  de  fotogramas  alcanzados  a  procesar  a  como  punto 
inicial tomaremos la los datos sin la aplicaci√≥n del algoritmo 
√∫nicamente la muestra de im√°genes a trav√©s de OpenCV y Java 
como lo ilustra el cuadro 2. 

Tiempo de 
ejecuci√≥n 
(ùë∫ùíÜùíà) 
1 
1 
2 
3 
2 
2 
3 
3 
4 
5 

No. 
Im√°genes 
procesadas 
21 
20 
44 
84 
47 
42 
66 
72 
78 
122 

FPS 
(ùëØùíõ) 

Muestreo 
(ùë∫ùíÜùíà) 

21 
20 
22 
28 
23,5 
21 
22 
24 
19,5 
24,4 

0,0476 
0,0500 
0,0455 
0,0357 
0,0426 
0,0476 
0,0455 
0,0417 
0,0513 
0,0410 

Cuadro 2 ‚Äì Resultados sin aplicaci√≥n del algoritmo. 

Por  tanto  se  identifica  que  la  frecuencia  promedio  es  de  
22.54ùëìùëùùë†  lo  cual  nos  deja  un  margen  peque√±o  de  trabajo  de 
7.54fps menos para lograr el margen esperado. Seguidamente 
se identific√≥ el comportamiento de parte del algoritmo por tanto  
se procedi√≥ a realizar la prueba √∫nicamente con la detecci√≥n de 
color, con el fin de identificar la carga computacional que esta 
tarea conlleva para el actual algoritmo. 

Tiempo de 
ejecuci√≥n 
(ùë∫ùíÜùíà) 
2 
2 
3 
3 
4 
4 
4 
3 
6 
3 

No. 
Im√°genes 
procesadas 
43 
44 
49 
48 
74 
71 
73 
68 
102 
59 

FPS 
(ùëØùíõ) 

Muestreo 
(ùë∫ùíÜùíà) 

21,5 
22 
16,3 
16 
18,5 
17,7 
18,2 
22,7 
17 
19,7 

0,0465 
0,0455 
0,0612 
0,0625 
0,0541 
0,0563 
0,0548 
0,0441 
0,0588 
0,0508 

Cuadro 3 ‚Äì Resultados identificaci√≥n por color √∫nicamente. 

Dando  un  promedio  de  19,97ùëìùëùùë†  dando  un  costo  de 
procesamiento  de  3,57ùëìùëùùë†  lo  cual  indica  que  el  costo  de 
procesamiento  por  imagen  aumento  un  15,84%,  dejando  un 
margen con respecto a al margan esperado de 3,93ùëìùëùùë†. Ahora 
con la inclusi√≥n del m√©todo de segmentaci√≥n expuesto en (ùëâùêº. ) 
se obtiene. 

Tiempo de 
ejecuci√≥n 
(ùë∫ùíÜùíà) 
3 
2 
3 
3 
3 
2 
2 
5 
5 
2 

No.  
Im√°genes 
procesadas 
46 
41 
49 
53 
48 
42 
46 
82 
73 
40 

FPS 
(ùëØùíõ) 

Muestreo 
(ùë∫ùíÜùíà) 

15,3 
20,5 
16,3 
17,6 
16 
21 
23 
16,4 
14,6 
20 

0,0652 
0,0488 
0,0612 
0,0566 
0,0625 
0,0476 
0,0435 
0,0610 
0,0685 
0,0500 

Cuadro 4 ‚Äì Resultados Identificaci√≥n por color y segmentaci√≥n de 
obst√°culos. 

Con  un  promedio  de  18,08ùëìùëùùë†  presentando  una  peque√±a 
reducci√≥n  en  comparaci√≥n  con  lo  avalado  anteriormente  con 
solo  0,89ùëìùëùùë†  esto  debido  a  que  los  c√°lculos  realizados 
dependen  de  valores  anteriormente  encontrados  por  al 
algoritmo  y  son  peque√±os  en  comparaci√≥n  adem√°s  de  que 
depende directamente del n√∫mero de obst√°culos. 

Muestreo 
(ùë∫ùíÜùíà) 

FPS 
(ùëØùíõ) 

Tiempo de 
ejecuci√≥n 
(ùë∫ùíÜùíà) 
0,0685 
5 
0,0606 
4 
0,0588 
3 
0,0615 
4 
0,0571 
4 
0,0732 
3 
0,0625 
4 
0,0727 
4 
0,0500 
3 
7 
0,0496 
Cuadro 5 ‚Äì Resultados algoritmo final. 

 No. 
Im√°genes 
procesadas 
76 
66 
51 
65 
70 
41 
64 
55 
60 
141 

14,6 
16,5 
17 
16,2 
18 
14 
16 
13,7 
20 
20 

Finalmente se realiza el an√°lisis del algoritmo completo con 
la inclusi√≥n del posicionamiento y la identificaci√≥n del √°rea del 
objeto como lo expuesto por la figura 5, se obtiene un promedio 
de  16,54fps  dejando  un  parte  positivo  en  el  rendimiento 
promedio  esperado  del  algoritmo.  Cabe  mencionar  que  las 
distintas variaciones de las frecuencias de muestreo se deben a 
que al ser una seria distintas de im√°genes, objetos y obst√°culos, 
lo cual implica diferentes cargas computacionales. 

IX.  CONCLUSIONES 

-   La  implementaci√≥n  y  dise√±o  del  algoritmo      que    nos 
permita procesamiento de im√°genes usando librer√≠as OpenCV  
aplicados a la detecci√≥n  de colores RGB, para la detecci√≥n de 
objetos sobre una plataforma rob√≥tica muestra un gran eficacia 
gracias 
trabajo  y  grandes  
robustas  de 
delimitaciones del mismo. 

condiciones 

-   La  detecci√≥n  y  segmentaci√≥n  de  objetos  por  medio  del 
procesamiento  de  im√°genes  es  de  gran  utilidad  para  la 
obtenci√≥n de datos del ambiente en el que se esta realizando la 
tarea de captura de im√°genes, puesto nos muestra de forma muy 
directa la conexi√≥n entre  los objetos y su centros. 

 
 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaci√≥n - Beca CEIBA 

-   Aunque el ambiente recreado para el estudio no contaba 
con todas las condiciones necesarias de un ambiente industrial 
√≥ptimo  para  el  desarrollo  de  procesamiento  de  imagenes  el 
algoritmo  permiti√≥  resolver  en  su  totalidad  el  problema 
planteado  sin  traer  repercusiones  a  los  t√≥picos  planteados 
inicialmente (ùêºùêº. ). 

-   La velocidad con la que arroja los resultados en el an√°lisis 
de tiempo real nos permite tener un flujo de im√°genes de m√°s 
de 15ùëìùëùùë† sin afectar el rendimiento del algoritmo, lo cual deja 
claro la calidad de ejecuci√≥n y detecci√≥n de objetos del mismo. 
-  El algoritmo es capaz de identificar, posicionar, medir y 
segmentar  los  elementos dentro de  una  ambiente  cerrado  con 
las caracter√≠sticas planteadas en el actual documento con gran 
eficacia con un 100% de los casos la detecci√≥n, segmentaci√≥n 
y ubicaci√≥n de los elementos se llev√≥ a cabo, en comparaci√≥n 
con su precisi√≥n  que fue  exiguamente menor con un 96.71% 
con respecto a los datos cotejados de manera  directa con una 
precisi√≥n 95.08% y 98.34% para medidas  de punto medio de 
los objetos y distancia entre los mismos respectivamente. 

REFERENCIAS 

[1]  Intel¬Æ, OpenCV (Open Source Computer Vision Library), 
Itseez, 
Available: 
[En 
2015. 
http://opencv.org/about.html. 

l√≠nea]. 

[2]  T√©cnicas  y  Algoritmos  B√°sicos  de  Visi√≥n  Artificial. 
Material Did√°ctico. Ingenier√≠as. Universidad de La Rioja. 
A√±o 2006. 

[3]  Gonzalez, R.C., Wintz, P. (1996), Procesamiento digital de 

imagenes. Addison-Wesley, Tema 3,4, pag 89-269. 

[4]  E. C√≥rdoba Nieto, Manufacturing and automation, revista 
ingenier√≠a e investigaci√≥n, vol. 26, n¬∫ 3, pp. 120-128, 2006.  
[5]  Wicks,  Marco  A,  Procesamiento  Digital  de  im√°genes, 

Capitulo 1: T√©cnicas y Fuentes de Iluminaci√≥n. 

[6]  Logitech  ¬©,  Especificaciones  tecnicas  HD  Pro  Webcam 
Available: 
[En 

C920, 
http://www.logitech.com/es-roam/product/hd-pro-
webcam-c920. 

l√≠nea]. 

2015. 

[7]  H.  L√≥pez  Paredes,  Detecci√≥n  y  Seguimiento  de  Objetos 
con  C√°maras  en  Movimiento.,  Madrid:  Universidad 
Aut√≥noma de Madrid, 2011. 

[8]  J.  G.  Tamayo  Zuluaga  ,  Reconocimiento  De  Figuras 
Geom√©tricas  A  Trav√©s  De  Una  Webcam  Con  OpenCV, 
Medell√≠n: Universidad de San Buenaventura, 2012. 

[9]  Programming with Intel IPP and Intel OpenCV under GNU 
LINUX.  Beginner's  Tutorial.  Universit√©  de  Bourgogne. 
France. 2007. http://iutlecreusot.u-bourgogne.fr. 

[10] Java, Informaci√≥n T√©cnica del Lenguaje, Oracle, 2014. [En 
Available: 

l√≠nea]. 
https://www.java.com/es/download/faq/whatis_java.xml. 

[11] Netbeans, Legal and Licensing Information, Oracle, 2015. 
Available: 
l√≠nea]. 

[En 
https://netbeans.org/about/legal/index.html. 

[12] IPSI,  Espacio  de  color  RGB  (Red  Green  blue),  2013.       

[En 
http://www.ipsi.fraunhofer.de/Kueppersfarbe/es/index.ht
ml. 

l√≠nea]. 

Available: 

 
 
