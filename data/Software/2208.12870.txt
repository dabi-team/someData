 2015 informe de Avance Proyecto Control y automatizaciÃ³n - Beca CEIBA 

Procesamiento Digital De ImÃ¡genes Aplicado A La SegmentaciÃ³n 
De Objetos Por intensidad y movimiento. 
BenjamÃ­n AndrÃ©s HuÃ©rfano Zapata1 Universidad de Cundinamarca 

Resumenâ€” El desarrollo tecnolÃ³gico actual nos permite llevar  a 
cabo tareas que hace algÃºn tiempo eran impensables por no decir 
que imposibles, el procesamiento digital de imÃ¡genes ha sido una 
de las mayores constantes de desarrollo en la actualidad, teniendo 
en  cuenta  que  su  implementaciÃ³n  data  de  poco  tiempo  atrÃ¡s, 
OpenCV [1] es una herramienta enfocada en la visiÃ³n artificial, en 
este  caso  implementada  en  una  plataforma  de  programaciÃ³n  
orientada  a  objetos  basado  en  lenguaje  en  Java1  ofrecida  por  el 
software de desarrollo NetBeans2, Teniendo como base lo anterior 
se planteÃ³ e implemento una plataforma fÃ­sica a modo de ambiente 
cerrado la cual a travÃ©s del desarrollo de un algoritmo permitiÃ³ 
detecciÃ³n y segmentaciÃ³n de objetos por medio del modelo de color 
RGB;  en  trabajos  futuros  dicho  algoritmo  brindara  la  base  de 
informaciÃ³n  para  la  plataforma  robÃ³tica autÃ³noma;  este  avance 
abre  un  amplio  espectro  para  el  desarrollo  de  aplicaciones  y 
herramienta  en el campo de la visiÃ³n artificial. 

Palabras  claveâ€”  DetecciÃ³n  de  objetos,  RGB,  VisiÃ³n  artificial, 

OpenCV, C#, EmguCV.  

I.  INTRODUCCIÃ“N 

El  avance  tecnolÃ³gico  actual  ha  venido  presentado  una 
constante  evoluciÃ³n  en  cuanto  al  desarrollo  de  software  se 
refiere  como  lo  seÃ±ala  Gonzales  [2]  esto  ha  traÃ­do  consigo 
numerosas ventajas, entre las cuales cabe destacar el desarrollo 
de  tecnologÃ­as  que  son  por  mucho  mÃ¡s  eficientes,  rÃ¡pidas  y 
baratas [3];  como resultado de lo anterior se hace plausible e 
interesante    abordar  ciertas  temÃ¡ticas  que  hace  algÃºn  tiempo 
pudieron haber sido despreciadas o desechadas por la exigencia 
de  gran cantidad recursos  computacionales. Gracias a que las 
nuevas tecnologÃ­as han conseguido mejorar  en gran medida las 
velocidades de procesamiento de la informaciÃ³n y asÃ­ un vasto 
camino para estudio en el desarrollo de algoritmos mucho mÃ¡s 
eficaces. 

El  actual  documento  expone  el  desarrollo  de  un  algoritmo 
basado  en  programaciÃ³n  orientado  a    objetos  basado  en  el 
lenguaje  Java,  a  travÃ©s  de  la  plataforma    de  programaciÃ³n 
brindada por el software NetBeans, que en conjunto y haciendo 
uso de la librerÃ­a OpenCV de visiÃ³n artificial desarrollada por 
Intel, la cual entre otra ventajas cuenta con licencia libre desde 
su apariciÃ³n con la primera versiÃ³n alfa en el mes de enero de 
1999, ha sido implementada en infinidad de aplicaciones: desde 
sistemas  de  seguridad  con  detecciÃ³n  de  movimiento,  hasta 
aplicaciones  de  control  de  procesos  en  los  que  se  requiere 
reconocimiento de objetos. Esto se debe a que su publicaciÃ³n se 
da  bajo  licencia  BSD,  que  permite  que  sea  usada  libremente 
para  propÃ³sitos  comerciales  y  de  investigaciÃ³n  con  las 
condiciones en ella expresadas. 

II.  DESCRIPCIÃ“N Y CARACTERIZACIÃ“N DEL DISEÃ‘O DEL 
ALGORITMO: 

En el actual documento plantea como problemÃ¡tica esencial 
la  detecciÃ³n  y  segmentaciÃ³n  de  varios  objetos  de  colores 
previamente determinados, en un entorno compuesto distintos 
objetos para esto se usÃ³ una descomposiciÃ³n de la imagen pixel 
por  pixel  y  un  posterior  filtrado  de  histogramas  por 
ecualizaciÃ³n.  El  algoritmo  debÃ­a  de  estar  en  la  capacidad  de 
identificar  la  distancia  y  el  centro  del  objeto  (de  un  color  en 
especÃ­fico)  con  respecto  a  los  demÃ¡s  objetos  y  asÃ­  mismo 
mostrar  lo  resultados  obtenidos  de  la  imagen,  ademÃ¡s  de 
segmentar  e  identificar  cada  objeto  como  independiente  sin 
importar si contaban con el mismo color.  

Para  lo cual se identificaron y definieron aspectos generales 
a  abordar  para  esta  manera  poder  implementar  un  algoritmo 
mucho mÃ¡s robusto y completo. 

A.  CaracterizaciÃ³n del ambiente de trabajo: 
Se procede a identificar las caracterÃ­sticas bÃ¡sicas esenciales 
del ambiente de estudio, el cual lo enmarcaremos con los rasgos 
primordiales  de  una  Ã¡rea  real  de  trabajo  de  tipo  industrial 
automatizado  [4],  donde  dicha  Ã¡rea  se  caracteriza  por  contar 
con  caracterÃ­sticas  de  limpieza,  no  intersecciÃ³n  de  diferentes 
zonas  de 
trabajo,  ambiente  propicio  para  el  control 
implementado, entre otras cuantas. 

Se  definieron  como  caracterÃ­sticas  indispensables  para  un 
ambiente  propicio  un  fondo  monocromÃ¡tico  que  permitiera 
identificar  los  objetos,  definido  con  color  blanco  el  fondo 
implementado  cuneta  con  un  Ã¡rea  de  1ğ‘š2  con  longitudes 
laterales equitativas de 100ğ‘ğ‘š. 

UbicaciÃ³n  de  la  cÃ¡mara  frontal  a  fin  de  lograr  un  mapeo 

general del fondo usado. 

Ambiente con buenas condiciones de iluminaciÃ³n la cual se 
implementÃ³ iluminaciÃ³n de tipo frontal la cual ayuda permite la 
iluminaciÃ³n uniforme y es usada comÃºnmente en sistemas de 
detecciÃ³n de objetos [5].  

B.  Modo de adquisiciÃ³n de informaciÃ³n: 
La  adquisiciÃ³n  de  informaciÃ³n  se  realizara  a  travÃ©s  de  una 
cÃ¡mara HD (Logitech HD Pro Webcam C920)  por medio de 
protocolo  USB  2.0,  ofreciendo  de  este  modo  gran  calidad  de 
imagen y eficacia en la trasmisiÃ³n de informaciÃ³n [6]. 

La cual se encuentra situada a 154ğ‘ğ‘š con el fin de permitir 
un pixel para la resoluciÃ³n actual represente un Ã¡rea 2.25ğ‘šğ‘š2, 
la cual fue definida por el Ã¡rea de cobertura proporcionada por 
la cÃ¡mara que conto con 96ğ‘ğ‘š de largo y 72ğ‘ğ‘š de ancho para 
un total 0.69ğ‘š2. 

1  â€œJava  es  un  lenguaje  de  programaciÃ³n  y  una  plataforma  informÃ¡tica 
comercializada desde en 1995 por Sun Microsystemsâ€ [10]. La versiÃ³n de Java 
usada actualmente es la orientada a objetos. 

2  NetBeans  es  un  proyecto  de  cÃ³digo  abierto  dedicado  a  proporcionar 
productos de desarrollo de software solidos como NetBeans IDE y NetBeans 
Platform [11]. 

 
 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaciÃ³n - Beca CEIBA 

C.  SelecciÃ³n de escala del color: 
El desarrollo expuesto por el presente se basÃ³ en la creaciÃ³n 
un algoritmo, el cual permitiÃ³ identificar los colores primarios 
en este caso en la escala de RGB3 (Rojo, Verde Y Azul) puesto 
que el modelo de codificaciÃ³n usado por la cÃ¡mara seleccionado 
es el anteriormente mencionado, y con el fin de evitar pÃ©rdidas 
de  recursos  computacionales  y  eficiencia  del  algoritmo  en  la 
trasformaciÃ³n a otro tipo de escala. 

D.  Tiempo de muestreo: 
El tiempo de muestreo como meta definido para el actual es 
definido  el  fin  de  contar  con  una  continuidad  mÃ­nima  de 
fotogramas, cercana a la imperceptible por el ojo humano, por 
otra parte dicha cantidad de muestras por unidad de tiempo estÃ¡ 
limitada  por  la  cantidad  posible  de  obtener  por  la  cÃ¡mara 
seleccionada siendo un mÃ¡ximo de 30ğ‘“ğ‘ğ‘ .  

Finalmente  teniendo  en  cuenta  una  cantidad  de  tiempo 
prudente de procesamiento  de la mitad del tiempo de captura 
dando un margen meta de mÃ­nimo 15ğ‘“ğ‘ğ‘ . 

E.  La interfaz grÃ¡fica: 
La  interfaz  grÃ¡fica  debÃ­a  de  contar  con  caracterÃ­stica  de 
modularidad con el fin de permitir identificar con facilidad los 
resultados obtenidos y poder mantener de forma ordenada cada 
uno de sus componentes. 

DebÃ­a  contar  con  la  posibilidad  de  realizar  ajustes  sobre  la 
ejecuciÃ³n  para  diferentes  variables  de  importancia  dentro  del 
algoritmo, igualmente contar con la posibilidad de observar los 
resultados obtenidos de forma tanto visual como matemÃ¡tica. 

Figura 1 â€“ Interfaz grafica implementada 
Fuente: Autor 

F.  CaracterizaciÃ³n de los objetos: 
Los  objetos  inmersos  dentro  del  ambiente  contaban  con 
caracterÃ­sticas diferenciables a primera vista con el fin de poder 
leer  los  resultados  con  mayor  facilidad  para  el  actual 
documento. Por tanto definimos los colores Verde, Rojo, Azul 
y negro, dichos colores serÃ¡n los que se segmentaran de nuestro 
ambiente de trabajo. 

Definimos  un  tamaÃ±o  mÃ­nimo  de  25ğ‘ğ‘š2  para  cualquier 
objeto inmerso dentro del ambiente, con el fin de evitar que la 
apariciÃ³n de  ruido  inmerso  en  la  imagen  llegase  a  afectar las 
mediciones obtenidas. 

3  RGB es  un  modelo de color basado  en  la  sÃ­ntesis  aditiva, con  el que  es 
posible representar un color mediante la mezcla por adiciÃ³n de los tres colores 
de luz primarios [12]. 

III.  MODO DE ALMACENAMIENTO DE LA IMAGEN 

Para  llegar  a  al  desarrollo  del  actual  algoritmo  se  debe 
esclarecer previamente sobre la forma en la que se almacena la 
informaciÃ³n  de  la  imagen.  Aunque  una  imagen  es  la 
reproducciÃ³n de la figura de un objeto por la combinaciÃ³n de 
los  rayos  de  luz  que  inciden  en  el  mismo,  dentro  de  un 
ordenador  una  imagen  no  es  mÃ¡s  que  una  gran  secuencia  de 
datos. Como es conocido, el tamaÃ±o de las imÃ¡genes se mide en 
pÃ­xeles,  que  es  precisamente  la  superficie  homogÃ©nea  mÃ¡s 
pequeÃ±a de las que componen una imagen [7], que se define por 
su brillo y color lo cuales esta definidos por el valor que toma 
el pixel. 

Las  imÃ¡genes  en  blanco  y  negro  (binarias)  son  las  mÃ¡s 
bÃ¡sicas,  pudiendo 
tomar  sus  pÃ­xeles  valores  entre  0 
(completamente  negro)  y  1  (completamente  blanco).  Sin 
embargo las imÃ¡genes de color contienen tres canales de colores 
distintos (Para nuestro caso RGB por sus siglas en inglÃ©s (R : 
rojo, G : verde, B : Azul) . Cada canal puede tomar un valor 
entre  0  y 255  correspondiente  a  un  byte  de  informaciÃ³n,  por 
ejemplo  un  ğ‘… = 255, ğº = 0,  y  ğµ = 0  serÃ¡  un  pÃ­xel 
completamente  rojo.  Si  los  tres  valores  son  255  el  pÃ­xel  serÃ¡ 
blanco, y si los tres valen 0 el pÃ­xel serÃ¡ negro, una vez definido 
esto  se  identifica  como  a  travÃ©s  de  la  mezcla  de  estos  tres 
colores  base  se  obtiene  16â€²581.375  posibilidades  por  pixel, 
permitiendo asÃ­ tener una gran cantidad de matices. 

La imagen ademas se compone de caraceristicas principales 
tales como  altura, ancho,  numero de canales. Por tanto para 
recorrer los valores de una imagen se puederelizar de izquierda 
a derecha o de arriba a abajo. Teniendo en cuenta ademÃ¡s que 
los canales estÃ¡n ordenados en BGR (azul, verde y rojo). EstÃ¡ 
es la Ãºnica  forma de recorrer imÃ¡genes,  y se implementa con 
bucles anidados aplicados a una matriz o array dependiendo el 
modo de almacenamiento o de obtencion de informacion usado.   

IV.  IDENTIFICACIÃ“N POR COLOR  

Para detectar un objeto de determinado color inicialmente se 
necesita identificar todos los pÃ­xeles que lo componen. Para ello 
se  realiza  una  bÃºsqueda  en  todos  los  datos  de  la  imagen, 
calculando si son o no del color deseado. Para la distinciÃ³n del 
color  que  se  estÃ¡  evaluando  en  ese  instante;  se  realiza,    en 
primer lugar la selecciÃ³n de datos caracterÃ­sticos que contienen 
el pixel de color y finalmente la cercanÃ­a con el color deseado, 
con el fin de clasificarlo o no dentro del tipo de color buscado. 
Por tanto su dato mÃ¡s caracterÃ­stico serÃ¡ que el canal con mayor 
valor. Es de vital importancia tener en cuenta que los valores de 
los demÃ¡s canales no deberÃ­an ser muy altos, por lo menos no 
lo suficiente como para acercarse al valor del canal testeado, ya 
que  estos  valores  podrÃ­an  corresponder  a  colores  como  el 
morado,  el  naranja,  el  amarillo  entre  otros,  lo  cual  crearÃ­a 
lectura  errÃ³neas  sobre  la  captura  de  la  imagen  y  arrojarÃ­an 
resultados indeseados, con este fin de delimito el algoritmo a 
partir de los canales del pixel evaluado, mirando que el valor 
del  pixel  estaba  contenido  entre  el  espectro  de  color  que 
deseamos identificar. 

 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaciÃ³n - Beca CEIBA 

Con un color que no  pertenece de los tres bÃ¡sicos de RGB 
(Ej. negro), se vuelve un poco mÃ¡s complejo este paso, pues se 
debe definir unas restricciones mÃ¡s estrictas y un rango amplio 
para el cual se puede clasificar el color, de igual manera al tener 
dichos cambios permitirÃ¡ poder detectar los colores sin que los 
afecte la iluminaciÃ³n con tanta facilidad puesto las tonalidades 
y degrades presentes en la superficie del objetos se encontrarÃ­an 
inmersas en los mismos. La detecciÃ³n de colores resultantes de 
mezclas  se  debe  identificar  y  clasificar  en  una  matriz  o  de 
manera homologa una base de datos, permitiendo asÃ­ acceder al 
valor y compararlo con el que se observa. 

entre  estos  objetos  y  de  igual  forma  para  la  segmentaciÃ³n de 
objetos.  EstÃ¡s  coordenadas  del  punto  medio  serÃ¡n  bastante 
precisas  si  contamos  con  una  gran  cantidad  de  pÃ­xeles  del 
objeto, y nos serÃ¡ de gran utilidad para ubicar dicho objeto con 
respecto a nuestra plataforma robÃ³tica. 

Supondremos  a  contamos  con  un  robot  un  punto  de 
referencia  de  un  color  este  caso  se  asigna  el  color  verde. 
Calculamos el punto medio de dicho objeto de referencia, Una 
vez tenemos las coordenadas sabemos si el objeto se encuentra 
a  nuestra  izquierda  o  derecha,  y  arriba  o  abajo  de  nuestra 
plataforma robÃ³tica un punto de llegada en la zona de color rojo 
o azul. Procedemos a hallar la distancia del robot con respecto 
a  las  zonas  de  llegada  (en  pÃ­xeles)  mediante  la  fÃ³rmula  de  la 
hipotenusa: 

ğ·ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ = âˆš(ğ‘¥2

  âˆ’ ğ‘¥1)2 + (ğ‘¦2 âˆ’ ğ‘¦1)2 

Donde ğ’™ğ’Š representa la coordenada ğ‘¥ y ğ’šğ’Š la coordenada en 

ğ‘¦ dados pixeles del objeto ğ‘–. 

a) 

  b) 

Figura 2 â€“ a) Imagen capturada y b) Imagen procesada por color. 
Fuente: Autor. 

La dificultad de este mÃ©todo es que solo detectarÃ­a colores de 
tipo  solido  frente  al  objeto  testeado,  sabiendo  que  la  forma 
irregular de los objetos que puede presentar en la imagen nos 
puede  efectos  de  cambio  de  la  intensidad  del  color del  pixel, 
este  caso  lo  anterior  se  soluciona  dejando  un  rango  neutro 
adicional entre los colores mezcla y los RGB primarios, y a la 
par  utilizar  un  extrapolaciÃ³n  de  la  imagen  para  detecciÃ³n  de 
bordes con el uso de primeras y segundas derivadas entre los 
valores de lo pixeles adyacentes [8], lo cual nos permitirÃ­a los 
cambios brucos de entorno y asÃ­ mismo determinar los bordes 
del objeto deseado. 

V.  POSICIONAMIENTO 

El posicionamiento permitirÃ¡ adquirir informaciÃ³n vital del 
ambiente en el cual se estÃ¡ desarrollando el estudio, en este caso 
hace referencia al posicionamiento de los objetos identificados, 
permitiendo  identificar  caracterÃ­sticas  como  tamaÃ±o,  forma, 
distancia y centro del objeto estudiado. 

 Para  ubicaciÃ³n  de  los  objetos  y  de  los  pixeles  de  color 
deseado,  se  guardaron  todas  las  coordenadas  de  cada  pixel 
identificado  y que  se  encontraban  a  su  vez  clasificado  en los 
colores deseados (Rojo, Verde, Azul y Negro) gracias a la suma 
de sus posiciones,  se calculÃ³  serÃ­a el punto medio de nuestro 
objeto a travÃ©s de la siguiente formula: 

ğ‘›
âˆ‘
ğ‘–
ğ‘–âˆˆğ‘‚ğ·
ğ‘›
âˆ‘
ğ‘–âˆˆğ‘‚ğ·  
1

  ğ‘¦  

ğ‘š
âˆ‘
ğ‘—
ğ‘—âˆˆğ‘‚ğ·
1ğ‘š
âˆ‘
ğ‘–âˆˆğ‘‚ğ·  

Figura 3 â€“ Posicionamiento de objetos en la figura 3 b). 
Fuente: Autor. 

1

Ahora  contamos  con  la  posiciÃ³n  y  distancia  entre  objetos, 
pero como lo indica la figura 4 aun no conocemos el Ã¡rea de la 
ğ‘›
imagen  que  ocupa  cada  objeto  se  conoce  que  (âˆ‘
ğ‘–âˆˆğ‘‚ğ· âˆ—
2.25ğ‘šğ‘š2) nos indica el Ã¡rea real aproximada ocupada por el 
objeto actual. Pero debido a la naturaleza de los objetos que es 
irregular  se  hace  necesario  enmarcar  el  objeto  en  un  Ã¡rea 
cuadrada  un  poco  mÃ¡s  amplia  para  contar  con  un  margen  de 
distancia  entre  un  obstÃ¡culo  y  lo  definido  como  plataforma 
robÃ³tica  para  el  documento,  para  efectos  del  estudio 
definiremos  el  color  negro  como  obstÃ¡culos,  los  cuales  serÃ¡n 
enmarcados  de  la  manera  anteriormente  propuesta,  por  tanto 
para lograrlo se realiza un sondeo de la coordenada mÃ­nima y 
mÃ¡xima del obstÃ¡culo evaluado del siguiente modo: 

(min
iâˆˆOD

ğ‘– , min
jâˆˆOD

ğ‘—)  ğ‘¦  (max
iâˆˆOD

ğ‘– , max
jâˆˆOD

ğ‘—) 

ProporcionÃ¡ndonos    de  este  modo  un  Ã¡rea  cuadrada  cual 

enmarca el obstÃ¡culo que estudiado. 

Finalmente usando a forma de un plano cartesiano la imagen 
adquirida  se  ubican  en  dos  dimensiones  los  objetos  lo  cual 
brinda  una  perspectiva  panorÃ¡mica  de  ambiente  en  el  que  se 
encuentra el robot (color verde). 

Donde ğ‘›  y ğ‘š  representa  el  largo  y  ancho  de  la  imagen  en 
pixeles respectivamente, ğ‘‚ğ· el conjunto de pixeles de un objeto 
de un color  deseado. Con estos se consigue la coordenada en 
(ğ’™,ğ’š)  en  pixeles  del  centro  del  objeto  evaluado,  lo  cual 
posteriormente nos servirÃ¡ de base para el cÃ¡lculo de distancia 

VI.  SEGMENTACIÃ“N 

La segmentaciÃ³n  se centra en cÃ³mo aislar los objetos o partes 
de objetos del resto de la imagen. Las razones para hacer esto 
son obvias. Por ejemplo, una cÃ¡mara suele mirar hacia el mismo 
fondo,  que  no  es  de  ningÃºn  interÃ©s.  Lo  que  interesa  de  esa 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaciÃ³n - Beca CEIBA 

imagen es detectar cuÃ¡ndo las personas o vehÃ­culos entran en la 
escena, o cuÃ¡ndo algo se deja en la escena que no estaba allÃ­ 
antes [9].  

Por  tanto  se  desea  aislar  esos  acontecimientos  e  ignorar 
interminables  horas  en  que  nada  estÃ¡  cambiando.  Este  es  un 
ejemplo  de  los  muchos  usos  que  tiene  la  segmentaciÃ³n  de 
objetos en el procesamiento de imÃ¡genes. 

La segmentaciÃ³n de los objetos consiste en como su nombre 
lo indica, en una divisiÃ³n o separaciÃ³n de objetos con el fin de 
indicar que son distintos y que se encuentran en otra parte del 
plano  al  que  se  estÃ¡  observando.  AdemÃ¡s  permite  tener  una 
mayor perspectiva del nÃºmero de objetos  al que se observa y 
asimismo generar  un posicionamiento de cada uno de ellos con 
respecto a la plataforma robÃ³tica. En este caso  supusimos es el 
objeto de color verde. 

La segmentaciÃ³n de los objetos que son objeto de estudio se 
realizÃ³ por medio de las diferencia entre distancias de distintas 
aglomeraciones de pixeles perteneciente a obstÃ¡culos, para lo 
cual  haremos uso de un rango definido  de 10 ğ‘ğ‘¥, donde una 
diferencia  entre  el  ultimo  de  pixel  âˆˆ ğ‘‚ğ·  de  la  imagen  con 
respecto al siguiente en una misma fila o columna de la imagen, 
representara un nuevo posible objeto, si la nueva aglomeraciÃ³n 
de pixeles encontradas supera el Ã¡rea mencionada en (ğ¼ğ¼. ğ¹) se 
considera  como  un  objeto  nuevo  y  distinto  al  primer 
encontrado. 

Logrando  asÃ­  detectar  mÃºltiples  objetos  del  mismo  color  y 
que  en  conjunto  a  las  caracterÃ­sticas  expresada  en  (ğ¼ğ¼ğ¼. ) 
permiten su total segmentaciÃ³n y ubicaciÃ³n. En este caso serÃ¡n 
los  objetos  definidos  como  obstÃ¡culos  anteriormente  (color 
negro) que estarÃ¡n en la misma imagen pero diferentes Ã¡reas de 
la imagen.  
En  este  caso  sabemos  que  hay  distintos  objetos  que 
identificados, y que unos pÃ­xeles pertenecerÃ¡n a un obstÃ¡culo, 
otros pÃ­xeles pertenecerÃ¡n a otros. Â¿CÃ³mo saber de quÃ© objeto 
se  trata?  Para  ello  haremos  uso  de  una  instancia  del  tipo  de 
programaciÃ³n  que  estamos  empleando  es  la  creaciÃ³n  de 
entidades  conocidas  como  objetos,  los  cuales  permitirÃ¡n 
guardar  la  informaciÃ³n  de  cualquier  obstÃ¡culo  presente  en  el 
Ã¡rea de estudio. Obteniendo  finalmente lo representado por la 
figura 5. 

a) 

  b) 

Figura 4 â€“ a) Imagen capturada y b) Imagen segmentada. 
Fuente: Autor. 

Donde  se  puede  observar  como 

las  caracterÃ­sticas 
anteriormente mencionadas se reflejan en la figura 5 b), donde 
los  obstÃ¡culos  sin  importar  su  forma  son  enmarcados  e 
identificados como distintos. Sin ser afectados por la cercanÃ­a 
con  otro  objeto  de  distinto  color,  los  cuales  siguen  siendo 
posicionados y ubicados plenamente. 

VII.  IMPLEMENTACIÃ“N DEL ALGORITMO 

Tomando  lo  anteriormente  expuesto  se  procediÃ³  a  generar  el 
cÃ³digo del algoritmo el cual conto con una estructura como la 
expuesta por la figura 6: 

Figura 5 â€“ Diagrama de bloques del algoritmo. 
Fuente: Autor. 

En detalle el algoritmo realiza se presenta como: 

â€¢ 

InicializaciÃ³n el programa y definiciÃ³n de variables globales 
y especiales. 

â€¢  Para la carga de la imagen obtenida a travÃ©s de la cÃ¡mara por 
medio  de  protocolo  USB,  se  tienen  en  cuenta  los  posibles 
errores de carga y dificultades del ordenador y se generan las 
excepciones  necesarias  con  el  fin  de  evitar  fallos  en  el 
programa y en el computador. 
 Se  obtienen  las  caracterÃ­sticas  de  la  imagen    datos  con  los 
cuales podremos recorrer la imagen. 

â€¢ 

â€¢  Convertimos le mapa de bits en  una matriz la cual se recorre 
para acceder a los valores de los pÃ­xeles teniendo cuenta sus 
caracterÃ­sticas  obtenidas  del  punto 
dimensiones  y 
inmediatamente anterior. 

â€¢  Se  evalÃºa  cada  valor  y  se  clasifica  el  pixel  segÃºn  las 

restricciones y rangos anteriormente dispuestos. 

â€¢  Se modifican los pixeles dentro de la matriz parar indicar el 

cambio detecciÃ³n del color. 

â€¢  Se evalÃºa la presencia de posibles objetos del mismo color. 
â€¢  Se genera segmentaciÃ³n de obstÃ¡culos de modo indicado en 

el apartado (ğ‘‰ğ¼. ). 

â€¢  Por medio de las ecuaciones mencionadas en el apartado de 
posicionamiento se realizan los respectivos cÃ¡lculos de centro 
de cada objeto y medida de distancias. 

â€¢  Se enmarcan los obstÃ¡culos segmentados identificados. 
â€¢  Y finalmente se recrea la imagen y se muestran los resultados 
obtenidos  por  el  algoritmo.  De  manera  seguida  se  liberan 
recursos del programa Se regresa al tÃ­pico inicial. 

VIII.  ANÃLISIS Y RESULTADOS 

Una vez desarrollado el algoritmo se  procediÃ³ a realizar el 
testeo del mismo, el cual se realizÃ³ en un computador personal 
de gama media con las caracterÃ­stica indicadas en el cuadro 1. 

Procesador: 
Memoria RAM: 
Tarjeta de video: 
CÃ¡mara: 
Sistema operativo: 

Intel Pentium 2.2ğºğ»ğ‘§ 
6 ğºğµ 
Intel(R) HD Graphics integrada 
Logitech HD Pro Webcam ğ¶920 
Windows 7 Ultimate â€“ 64ğ‘ğ‘–ğ‘¡ğ‘  

  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaciÃ³n - Beca CEIBA 

NetBeans IDE: 
Java(TM): 
OpenCV 

8.1 
1.8.0_45 âˆ’ ğ‘15 
3.0.0 

Cuadro 1 â€“ CaracterÃ­sticas de hardware y de software de ordenador 
usado. 
Para realizar las pruebas  se tomos una contante de 10 medidas 
las con aras de tener un buen margen acercamiento al valor real 
de fps y frecuencia de muestreo logrado por el algoritmo, dichas 
medidas se realizaron por medio de un cÃ³digo en Java el cual 
mostraba  la  hora  de  inicio  de  ejecuciÃ³n,  la  hora  el  final  y  el 
nÃºmero  de  fotogramas  alcanzados  a  procesar  a  como  punto 
inicial tomaremos la los datos sin la aplicaciÃ³n del algoritmo 
Ãºnicamente la muestra de imÃ¡genes a travÃ©s de OpenCV y Java 
como lo ilustra el cuadro 2. 

Tiempo de 
ejecuciÃ³n 
(ğ‘ºğ’†ğ’ˆ) 
1 
1 
2 
3 
2 
2 
3 
3 
4 
5 

No. 
ImÃ¡genes 
procesadas 
21 
20 
44 
84 
47 
42 
66 
72 
78 
122 

FPS 
(ğ‘¯ğ’›) 

Muestreo 
(ğ‘ºğ’†ğ’ˆ) 

21 
20 
22 
28 
23,5 
21 
22 
24 
19,5 
24,4 

0,0476 
0,0500 
0,0455 
0,0357 
0,0426 
0,0476 
0,0455 
0,0417 
0,0513 
0,0410 

Cuadro 2 â€“ Resultados sin aplicaciÃ³n del algoritmo. 

Por  tanto  se  identifica  que  la  frecuencia  promedio  es  de  
22.54ğ‘“ğ‘ğ‘   lo  cual  nos  deja  un  margen  pequeÃ±o  de  trabajo  de 
7.54fps menos para lograr el margen esperado. Seguidamente 
se identificÃ³ el comportamiento de parte del algoritmo por tanto  
se procediÃ³ a realizar la prueba Ãºnicamente con la detecciÃ³n de 
color, con el fin de identificar la carga computacional que esta 
tarea conlleva para el actual algoritmo. 

Tiempo de 
ejecuciÃ³n 
(ğ‘ºğ’†ğ’ˆ) 
2 
2 
3 
3 
4 
4 
4 
3 
6 
3 

No. 
ImÃ¡genes 
procesadas 
43 
44 
49 
48 
74 
71 
73 
68 
102 
59 

FPS 
(ğ‘¯ğ’›) 

Muestreo 
(ğ‘ºğ’†ğ’ˆ) 

21,5 
22 
16,3 
16 
18,5 
17,7 
18,2 
22,7 
17 
19,7 

0,0465 
0,0455 
0,0612 
0,0625 
0,0541 
0,0563 
0,0548 
0,0441 
0,0588 
0,0508 

Cuadro 3 â€“ Resultados identificaciÃ³n por color Ãºnicamente. 

Dando  un  promedio  de  19,97ğ‘“ğ‘ğ‘   dando  un  costo  de 
procesamiento  de  3,57ğ‘“ğ‘ğ‘   lo  cual  indica  que  el  costo  de 
procesamiento  por  imagen  aumento  un  15,84%,  dejando  un 
margen con respecto a al margan esperado de 3,93ğ‘“ğ‘ğ‘ . Ahora 
con la inclusiÃ³n del mÃ©todo de segmentaciÃ³n expuesto en (ğ‘‰ğ¼. ) 
se obtiene. 

Tiempo de 
ejecuciÃ³n 
(ğ‘ºğ’†ğ’ˆ) 
3 
2 
3 
3 
3 
2 
2 
5 
5 
2 

No.  
ImÃ¡genes 
procesadas 
46 
41 
49 
53 
48 
42 
46 
82 
73 
40 

FPS 
(ğ‘¯ğ’›) 

Muestreo 
(ğ‘ºğ’†ğ’ˆ) 

15,3 
20,5 
16,3 
17,6 
16 
21 
23 
16,4 
14,6 
20 

0,0652 
0,0488 
0,0612 
0,0566 
0,0625 
0,0476 
0,0435 
0,0610 
0,0685 
0,0500 

Cuadro 4 â€“ Resultados IdentificaciÃ³n por color y segmentaciÃ³n de 
obstÃ¡culos. 

Con  un  promedio  de  18,08ğ‘“ğ‘ğ‘   presentando  una  pequeÃ±a 
reducciÃ³n  en  comparaciÃ³n  con  lo  avalado  anteriormente  con 
solo  0,89ğ‘“ğ‘ğ‘   esto  debido  a  que  los  cÃ¡lculos  realizados 
dependen  de  valores  anteriormente  encontrados  por  al 
algoritmo  y  son  pequeÃ±os  en  comparaciÃ³n  ademÃ¡s  de  que 
depende directamente del nÃºmero de obstÃ¡culos. 

Muestreo 
(ğ‘ºğ’†ğ’ˆ) 

FPS 
(ğ‘¯ğ’›) 

Tiempo de 
ejecuciÃ³n 
(ğ‘ºğ’†ğ’ˆ) 
0,0685 
5 
0,0606 
4 
0,0588 
3 
0,0615 
4 
0,0571 
4 
0,0732 
3 
0,0625 
4 
0,0727 
4 
0,0500 
3 
7 
0,0496 
Cuadro 5 â€“ Resultados algoritmo final. 

 No. 
ImÃ¡genes 
procesadas 
76 
66 
51 
65 
70 
41 
64 
55 
60 
141 

14,6 
16,5 
17 
16,2 
18 
14 
16 
13,7 
20 
20 

Finalmente se realiza el anÃ¡lisis del algoritmo completo con 
la inclusiÃ³n del posicionamiento y la identificaciÃ³n del Ã¡rea del 
objeto como lo expuesto por la figura 5, se obtiene un promedio 
de  16,54fps  dejando  un  parte  positivo  en  el  rendimiento 
promedio  esperado  del  algoritmo.  Cabe  mencionar  que  las 
distintas variaciones de las frecuencias de muestreo se deben a 
que al ser una seria distintas de imÃ¡genes, objetos y obstÃ¡culos, 
lo cual implica diferentes cargas computacionales. 

IX.  CONCLUSIONES 

-   La  implementaciÃ³n  y  diseÃ±o  del  algoritmo      que    nos 
permita procesamiento de imÃ¡genes usando librerÃ­as OpenCV  
aplicados a la detecciÃ³n  de colores RGB, para la detecciÃ³n de 
objetos sobre una plataforma robÃ³tica muestra un gran eficacia 
gracias 
trabajo  y  grandes  
robustas  de 
delimitaciones del mismo. 

condiciones 

-   La  detecciÃ³n  y  segmentaciÃ³n  de  objetos  por  medio  del 
procesamiento  de  imÃ¡genes  es  de  gran  utilidad  para  la 
obtenciÃ³n de datos del ambiente en el que se esta realizando la 
tarea de captura de imÃ¡genes, puesto nos muestra de forma muy 
directa la conexiÃ³n entre  los objetos y su centros. 

 
 
 
 
 
 
 
 2015 informe de Avance Proyecto Control y automatizaciÃ³n - Beca CEIBA 

-   Aunque el ambiente recreado para el estudio no contaba 
con todas las condiciones necesarias de un ambiente industrial 
Ã³ptimo  para  el  desarrollo  de  procesamiento  de  imagenes  el 
algoritmo  permitiÃ³  resolver  en  su  totalidad  el  problema 
planteado  sin  traer  repercusiones  a  los  tÃ³picos  planteados 
inicialmente (ğ¼ğ¼. ). 

-   La velocidad con la que arroja los resultados en el anÃ¡lisis 
de tiempo real nos permite tener un flujo de imÃ¡genes de mÃ¡s 
de 15ğ‘“ğ‘ğ‘  sin afectar el rendimiento del algoritmo, lo cual deja 
claro la calidad de ejecuciÃ³n y detecciÃ³n de objetos del mismo. 
-  El algoritmo es capaz de identificar, posicionar, medir y 
segmentar  los  elementos dentro de  una  ambiente  cerrado  con 
las caracterÃ­sticas planteadas en el actual documento con gran 
eficacia con un 100% de los casos la detecciÃ³n, segmentaciÃ³n 
y ubicaciÃ³n de los elementos se llevÃ³ a cabo, en comparaciÃ³n 
con su precisiÃ³n  que fue  exiguamente menor con un 96.71% 
con respecto a los datos cotejados de manera  directa con una 
precisiÃ³n 95.08% y 98.34% para medidas  de punto medio de 
los objetos y distancia entre los mismos respectivamente. 

REFERENCIAS 

[1]  IntelÂ®, OpenCV (Open Source Computer Vision Library), 
Itseez, 
Available: 
[En 
2015. 
http://opencv.org/about.html. 

lÃ­nea]. 

[2]  TÃ©cnicas  y  Algoritmos  BÃ¡sicos  de  VisiÃ³n  Artificial. 
Material DidÃ¡ctico. IngenierÃ­as. Universidad de La Rioja. 
AÃ±o 2006. 

[3]  Gonzalez, R.C., Wintz, P. (1996), Procesamiento digital de 

imagenes. Addison-Wesley, Tema 3,4, pag 89-269. 

[4]  E. CÃ³rdoba Nieto, Manufacturing and automation, revista 
ingenierÃ­a e investigaciÃ³n, vol. 26, nÂº 3, pp. 120-128, 2006.  
[5]  Wicks,  Marco  A,  Procesamiento  Digital  de  imÃ¡genes, 

Capitulo 1: TÃ©cnicas y Fuentes de IluminaciÃ³n. 

[6]  Logitech  Â©,  Especificaciones  tecnicas  HD  Pro  Webcam 
Available: 
[En 

C920, 
http://www.logitech.com/es-roam/product/hd-pro-
webcam-c920. 

lÃ­nea]. 

2015. 

[7]  H.  LÃ³pez  Paredes,  DetecciÃ³n  y  Seguimiento  de  Objetos 
con  CÃ¡maras  en  Movimiento.,  Madrid:  Universidad 
AutÃ³noma de Madrid, 2011. 

[8]  J.  G.  Tamayo  Zuluaga  ,  Reconocimiento  De  Figuras 
GeomÃ©tricas  A  TravÃ©s  De  Una  Webcam  Con  OpenCV, 
MedellÃ­n: Universidad de San Buenaventura, 2012. 

[9]  Programming with Intel IPP and Intel OpenCV under GNU 
LINUX.  Beginner's  Tutorial.  UniversitÃ©  de  Bourgogne. 
France. 2007. http://iutlecreusot.u-bourgogne.fr. 

[10] Java, InformaciÃ³n TÃ©cnica del Lenguaje, Oracle, 2014. [En 
Available: 

lÃ­nea]. 
https://www.java.com/es/download/faq/whatis_java.xml. 

[11] Netbeans, Legal and Licensing Information, Oracle, 2015. 
Available: 
lÃ­nea]. 

[En 
https://netbeans.org/about/legal/index.html. 

[12] IPSI,  Espacio  de  color  RGB  (Red  Green  blue),  2013.       

[En 
http://www.ipsi.fraunhofer.de/Kueppersfarbe/es/index.ht
ml. 

lÃ­nea]. 

Available: 

 
 
