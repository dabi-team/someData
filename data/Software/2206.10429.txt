Plug and Play Counterfactual Text Generation for Model Robustness

Nishtha Madaan1,2
1Indian Institute of Technology Delhi India

Srikanta Bedathur1

Diptikalyan Saha2
2IBM Research - India

anz208487@cse.iitd.ac.in

srikanta@cse.iitd.ac.in

diptsaha@in.ibm.com

2
2
0
2

n
u
J

1
2

]
L
C
.
s
c
[

1
v
9
2
4
0
1
.
6
0
2
2
:
v
i
X
r
a

Abstract

Generating counterfactual test-cases is an im-
portant backbone for testing NLP models and
making them as robust and reliable as tradi-
In generating the test-cases,
tional software.
a desired property is the ability to control the
test-case generation in a ﬂexible manner to
test for a large variety of failure cases and
to explain and repair them in a targeted man-
ner. In this direction, signiﬁcant progress has
been made in the prior works by manually writ-
ing rules for generating controlled counterfac-
tuals. However, this approach requires heavy
manual supervision and lacks the ﬂexibility
to easily introduce new controls. Motivated
by the impressive ﬂexibility of the plug-and-
play approach of PPLM, we propose bringing
the framework of plug-and-play to counterfac-
tual test case generation task. We introduce
CASPer, a plug-and-play counterfactual gener-
ation framework to generate test cases that sat-
isfy goal attributes on demand. Our plug-and-
play model can steer the test case generation
process given any attribute model without re-
quiring attribute-speciﬁc training of the model.
In experiments, we show that CASPer effec-
tively generates counterfactual text that follow
the steering provided by an attribute model
while also being ﬂuent, diverse and preserving
the original content. We also show that the
generated counterfactuals from CASPer can
be used for augmenting the training data and
thereby ﬁxing and making the test model more
robust.

1

Introduction

Machine learning and deep learning-based deci-
sion making has become part of today’s software.
This creates the need to ensure that machine learn-
ing and deep learning-based systems are as trusted
as traditional software with increased deployment
and wider-use. Traditional software is made de-
pendable by following rigorous practice like static

analysis, testing, debugging, verifying, and repair-
ing throughout the development and maintenance
life-cycle. Similarly, for testing and repairing NLP
systems, we need inputs where models can fail
and thereby bringing out issues early on (Ma et al.,
2020; Holstein et al., 2019). For this, counterfac-
tual text data (Wachter et al., 2017; Pearl et al.,
2000) can be used. By treating counterfactual text
as test cases, we are asking: Would the model fail if
the input text was modiﬁed to have different char-
acteristics? Furthermore, with such counterfactual
text, NLP systems can be repaired by augmenting
the training samples with these counterfactual test
cases and its labels (Garg et al., 2019). Hence,
enabling model repair by generating counterfac-
tual text is a crucial step in deploying these NLP
systems more widely.

An important aspect of model testing and repair
is to ensure that we can control these counterfactual
test cases. The ability to control will allow us to
test for speciﬁc types of failures that are important
for the deployed model. Controlled counterfactuals
can also allow us to ﬁx the failures by creating new
training samples in a focused manner for augment-
ing the existing training dataset. Thus we require
a model that can generate counterfactuals that can
be controlled by providing some goal attributes.

In addition to controlling the test-cases, we
would also like to have ﬂexibility about which goal
attributes to apply and the ﬂexibility to chain to-
gether multiple goal attributes in order to test how
the deployed model behaves for a wide variety of
textual characteristics. Bringing such ﬂexibility re-
quires a model that allows us to plug-and-play new
attribute goals as and when required.

In this work, we propose a framework for coun-
terfactual test-case generation also called Counter-
factual Sentence Generation with Plug-and-Play
Perturbation or CASPer that provides both con-
trol and ﬂexibility during test case generation. To
achieve these, we build on the framework of Plug-

 
 
 
 
 
 
Inputs

Token-based
(Ribeiro et al., 2020)

Adversarial
(Michel et al., 2019)

Polyjuice
(Wu et al., 2021)

Ours

Input Text: Me and a
group of friends rent
horrible videos to laugh
at them, trust me it has
lead to some horribly
spent money but
also some great laughs.

Initial State : No location
named-entity is present
in the text.

Steering Goal: To make
the sentence contain at
least one location
named-entity.

Me and a group
of friends rent
youtube videos to
laugh at them,
trust me it
has lead to
some horribly spent
money but also
some great laughs.

Me and a group of
friends rent music
videos to laugh at
them, trust me it has
lead to some horribly
spent money but
also some great laughs.

Me and a group of
friends rent horrible
videos to laugh
at them ,
trust me it
has lead to
some horribly spent
money but also
some ﬂavorful laughs .

Me and a group
of my friends
rent horrible videos
to laugh at
them , trust me
it has lead
to some horribly
spent money but
also some ﬂavorful
laughs.

and a group of friends
rent videos to laugh
at them, trust me it
has lead to some horribly
spent money but also
some chuckles.

Me have a group
of lads in
Brisbane and rent
horrible videos to
get great laughs
at. Some extremely
expensive videos but
some very great..

Me and a group
of Fairfax Bay
friends like to
rent videos for
laughs. Have spent
some money but
had great laughs
at their terrible
videos.

Table 1: Overview of generations from the existing models. We provide a text as input to the model with a
steering goal of introducing a location named-entity into the given text. We show the outputs from a token-based
substitution model (Ribeiro et al., 2020), from Adversarial Generation (Michel et al., 2019), from Polyjuice (Wu
et al., 2021) and from our proposed model. We note that token-based substitution method, relying on template
matching, fail to match a template and are thus not able to achieve the steering goal. Adversarial, due to its gradient-
descent-based token-substitution, fails to generate plausible text. Polyjuice, due to its template matching, changes
very insigniﬁcant part of the text. Our model, taking advantage of BART auto-encoder, effectively achieves the
steering goal.

and-Play Language Models or PPLMs (Dathathri
et al., 2019). PPLMs have shown an impressive
ability to ﬂexibly steer pre-trained language mod-
els to generate attribute-conditioned text samples.
However, PPLMs cannot be directly used for per-
turbing an input text and generating counterfactual
samples. In this work, instead of steering language
models, we steer a text-to-text model that is pre-
trained to reconstruct its text inputs and we steer
this model in a plug-and-play manner. Thus, like
PPLM, our model is plug-and-play and is capable
of generating counterfactuals for any arbitrary goal
attributes provided at sampling time. In CASPer,
we take BART (Lewis et al., 2019) as our text-to-
text reconstruction model. To generate each coun-
terfactual, we perturb the hidden layer of the BART
model similarly to PPLM to sample the counterfac-
tual text. In experiments, we apply our framework
to generate counterfactuals by providing named-
entity and sentiment-based goal attributes. We
show that our simple plug-and-play framework can
generate counterfactuals that are ﬂuent and content-
preserving while also attaining the goal attributes
and being effective as training samples for data-
augmentation to improve the performance of the

deployed model. We show counterfactual samples
generated by CASPer and from existing models in
Table 1.

The main contribution of the paper can be seen
as three folds: 1) We propose, CASPer, the ﬁrst
plug-and-play counterfactual generation model that
achieves both control and ﬂexibility. 2) Empiri-
cally, we show that our approach can generate ﬂu-
ent counterfactuals that preserve the content and
also attain the goal attribute. 3) We also show the
effectiveness of our counterfactuals as new training
data in making the test models robust.

2 Preliminaries

2.1 Counterfactual Text Generation for

Model Testing and Repair

Taking a text x from the input distribution and
modifying it x → y is known as the task of coun-
terfactual text generation. However, our goal of
counterfactual text generation is to help improve
NLP models by using counterfactual text as test-
cases in various stages of the model deployment.
For such models, we would like to i) test for fail-
ures, ii) explain when those failures occur and iii)
ﬁx the failures by augmenting the training data with

new training samples.

However, from the perspective of model repair,
it is not enough to simply obtain uncontrolled and
random perturbations x → y to generate these test-
cases. We would like these test-cases to be con-
control
−−−−−→ y through a given control
trolled x
input. By controlling the generated test cases, we
would be able to i) test for speciﬁc types of fail-
ures that are important for the deployed model, ii)
explain which controls lead to high failure and iii)
create targeted data sets for augmenting the train-
ing set and ﬁxing the models. Hence, our work lies
at the intersection of counterfactual text generation
and controlled text generation. In the following
subsection, we provide an overview of controlled
text generation.

2.2 Controlled Text Generation

The goal of controlled text generation is to gener-
ate samples x from a controlled distribution p(y|a)
which is conditioned on a speciﬁc attribute or con-
trol a. For example, the language model p(y|a)
may be used to generate product reviews condi-
tioned on a speciﬁc product category by setting
a = kitchen.

2.2.1 Plug-and-Play Language Models
Plug-and-Play Language Models (or simply
PPLMs) provide an attractive solution to model
the class-conditional distribution pθ(y|a). Plug-
and-play models take a pre-trained unconditional
generative model pθ(y) and use the reward signal
from the attribute model p(a|y) to quickly (in ∼10
gradient steps) modify the unconditional generative
model pθ(y) to generate samples from the desired
distribution pθ(y|a).

To achieve this, PPLMs (Dathathri et al., 2019)
take GPT-2 to be the unconditional generative
model pθ(y). In GPT-2, the text generation is done
iteratively word-by-word. In each iteration t, one
word is predicted and is fed back to the Transformer
to predict the next word. This generation process
can be described as follows:

Ht = Transformer(y<t),
ot = PredictionHead(Ht),
yt ∼ Categorical(ot).

where t is the word position in the text, Ht is the
last hidden layer before the prediction head and
ot are the log-probabilities of the words in the vo-
cabulary used for sampling the next word yt. We

shall refer to this model as the unmodiﬁed language
model and denote the distribution that it models for
the next word prediction as p(yt|y<t).

To generate a text from pθ(y|a) at test time,
PPLMs learn a perturbation for the hidden state Ht
of the unconditional model pθ(y). This is achieved
as follows:

Ht = Transformer(y<t),
ot = PredictionHead(Ht + ∆Ht),
yt ∼ Categorical(ot).

where ∆Ht is the learned perturbation. We shall
refer to this model as the modiﬁed language model
and denote the distribution that it models for the
next word prediction as ¯p(yt|y<t). The learning of
the perturbation parameters {∆H1, . . . , ∆HT } is
driven by the following objective:

LPPLM = − log p(a|y)
T
(cid:88)

−

DKL(p(yt|y<t)||¯p(yt|y<t)),

t=1

where the ﬁrst term provides the learning signal
to steer the generation towards the desired class or
attribute by trying to maximize the log-probability
of the desired attribute. The second term tries to
keep the generations close to the unmodiﬁed lan-
guage model to ensure that the text remains ﬂuent
and plausible. We note that this learning process
is done separately each time we need to generate a
new sample. However, the learning of the pertur-
bation parameters {∆H1, . . . , ∆HT } can be done
very quickly and it only takes about 10 gradient
steps. This property makes PPLMs ﬂexible during
generation.

PPLMs provide some useful properties that are
lacking in other conditional generative models that
are not plug-and-play. Plug-and-play models are
ﬂexible during sampling – meaning that new class-
conditioning can be easily introduced at test time
by simply replacing the attribute model p(a|y)
with a new attribute model for the new class with-
out requiring costly retraining with respect to the
new attribute. Furthermore, plug-and-play mod-
els can support conditioning on logical clauses by
simply composing multiple attribute models to-
gether. For instance, to generate product review
text conditioned on a logical clause kitchen +
electronics + not electrical, the at-
tribute model p(a|y) can be written as the prod-
uct of individual attribute models p(kitchen|y) ·

(Dathathri et al., 2019), the base model p(y) is
a pretrained GPT-2, while in our model, the base
model p(y|x) is a pretrained BART model.

A BART model is a text-to-text model that takes
as input a text x and produces a reconstruction y
of the input text. The BART text-to-text framework
consists of two modules: A BERT encoder and a
GPT-2 decoder. That is, the model takes an input
text and the BERT encoder ﬁrst returns a text rep-
resentation e. This text representation is then given
to the GPT-2 decoder to reconstruct the input text
word-by-word. This can be summarized as follows:

e = BERT(x),

Ht = Transformer(y<t, e),
ot = PredictionHead(Ht),
yt ∼ Categorical(ot).

where t is the word position in the text, Ht is the
last hidden layer before the prediction head and ot
are the log-probabilities of the words in the vocab-
ulary used for sampling the next word yt. We will
refer to this as the unmodiﬁed BART model having
the next word prediction distribution p(yt|y<t, x).
To steer the BART model, similarly to PPLM, we
add a learnable perturbation ∆Ht to the hidden
states Ht of the unmodiﬁed BART model. This can
be summarized as follows:

e = BERT(x),

Ht = Transformer(y<t, e),
ot = PredictionHead(Ht + ∆Ht),
yt ∼ Categorical(ot).

We will refer to this as the modiﬁed BART
model having the next word prediction distribu-
tion ¯p(yt|y<t, x) Similarly to PPLM, the learning
of the perturbation parameters {∆H1, . . . , ∆HT }
is driven by the following objective:

LCASPer = − log p(a|y)
T
(cid:88)

−

DKL(p(yt|y<t, x)||¯p(yt|y<t, x)).

t=1

where the ﬁrst term provides the learning signal to
steer the counterfactuals towards the desired goal
attribute by trying to maximize the log-probability
of the desired attribute. The second term tries
to keep the generations close to the unmodiﬁed
BART to ensure that the text remains similar in
content to the original input text and also remains

Figure 1: Model Architecture of CASPer. The BERT
encoder (shown in orange) takes the input text and re-
turns a representation of the input text as a set of vec-
tors. These are provided to the GPT-2 decoder for cross-
attention. At each step of decoding, the decoder re-
turns an output hidden state (shown as green circle).
To this, we add a perturbation matrix (shown as blue
circle). The perturbed hidden state is then provided to
the language model head to obtain the logits over the
vocabulary for sampling the next token. These logits
are also provided to the attribute model for computing
the loss for steering the generation. The KL divergence
between the perturbed logits and the unperturbed logits
is also minimized to keep the semantic content of the
generated text close to the original input text.

p(electronics|y) · [1 − p(electrical|y)]
and easily plugged into the PPLM framework
(Dathathri et al., 2019). Our model architecture
is shown in Figure 1.

3 Method: Plug-and-Play

Counterfactual Generation
Framework

We now describe our proposed method to generate
controlled counterfactual text in a plug-and-play
fashion. In particular, given a text x and a control
attribute a, we seek to generate a controlled coun-
terfactual y. That is, we seek to draw samples from
a distribution p(y|x, a) where the generated sam-
ple y depends both on the input text x and the given
control attribute a. Hence, our task is different and
more challenging than the simple controlled text
generation task where the generated samples need
to depend only on the control attribute a.

Our main idea is as follows: Similar to how
PPLM (Dathathri et al., 2019) steers a pretrained
text generator p(y) → p(y|a) using the control
attribute a, we shall steer a pretrained text-to-
text generator p(y|x) → p(y|x, a).
In PPLM

ﬂuent and plausible. We note that this learning
process is done separately each time we need to
generate a new sample. However, the learning of
the perturbation parameters {∆H1, . . . , ∆HT }
can be done very quickly and it only takes about
100 gradient steps. This property makes CASPer a
ﬂexible way to generate counterfactuals of a given
text.

Discussion. Note that if we simply obtain samples
from a pre-trained BART model p(y|x), a sample
y can be considered as a counterfactual of the input
text x. However, this sample would be an almost
exact reconstruction of the input text. Hence from
the perspective of model testing, this type of coun-
terfactual would not be much useful. However, by
applying steering to p(y|x) using a control attribute
a, we are able to control in what way we want to
modify the input text to generate the counterfactual.
Hence, from the perspective of model testing, this
type of counterfactual would be useful because we
can test how a deployed model will behave if the
distribution of its inputs are perturbed in a certain
way.

4 Related Work

The task of controlled text generation is well stud-
ied in literature. (Hu et al., 2017) propose a model
aims to generate plausible sentences conditioned on
representation vectors with semantic structure. An-
other work (Ye et al., 2020) focuses on controlled
text generation, however, unlike the previous work
(Hu et al., 2017), the conditioning need not be sim-
ply a class label. The conditioning can be a data
structure such as a table. The model is trained
end-to-end similarly to the objective of (Hu et al.,
2017). PPLM (Dathathri et al., 2019) combine a
pre-trained language model, similarly to (Nguyen
et al., 2017) with an attribute classiﬁer to perform
controlled language generation and use the attribute
classiﬁer to steer the text generation process with-
out further training of any of the two models. (Luo
et al., 2019), adopting a similar direction, deal with
story completion with a desired sentiment. (Keskar
et al., 2019) is a model that controls text generation
via 50 rigid control codes predetermined at training
time. However all these works, cannot be used for
counterfactual text generation as these are purely
class-conditional generative models and do not al-
low generation conditioned on a given input text.
Some earlier works, including and not limited to,

(Gu et al., 2016, 2017; Chen et al., 2018; Subra-
mani et al., 2019; Dathathri et al., 2019; Krause
et al., 2020) propose the idea of steering Language
Models but these also can not be directly used for
counterfactual generation task. We discuss other
related work can be found in Appendix A.

5 Experiments

The goal of the experiments is to: 1) show that a
ﬂexible plug-and-play framework can effectively
achieve controlled counterfactual text generation
and the generated text is ﬂuent, plausible, diverse
and follows the steering provided by the attribute
model. 2) We evaluate how well the generated
perturbations can act as data-augmentation samples
in order to make a downstream classiﬁcation task
performance more robust.

5.1 Datasets

We evaluate the models on the following data sets
text.

1. YELP Sentiment Dataset. To evaluate how
our model is able to change the sentiment of
the original text and achieve the target sen-
timent, we use the YELP sentiment dataset
(Zhang et al., 2015). This dataset is also char-
acterized by informal text which can be seen
in realistic user inputs.

2. IMDB Sentiment Dataset. To further evalu-
ate how our model is able to change the sen-
timent of the original input text, we test on
IMDB Sentiment Dataset (Maas et al., 2011).
This dataset is also characterized by long and
complex text and is thus a challenging dataset.

5.2 Controlled Text Generation with

Attribute Steering

We ﬁrst evaluate the quality of our generated text
with respect to the steering signal. We expect our
generated text to preserve the semantic content and
syntactic structure of the input text while being
ﬂuent and diverse as we steer the text towards the
target attribute. The steering signal we evaluate in
this work is to make the sentiment of the target text
from negative to positive.

5.2.1 Baselines

To compare with state-of-the-art template-based
methods relying on token substitutions via dictio-
naries we compare with Checklist (Ribeiro et al.,

Metrics

Dataset

CP ↑

Perplexity ↓

BLEU−4 ↓

YELP
IMDB
YELP
IMDB
YELP
IMDB

RoBERTa
Mask−LM
0.30
0.29
3.82
3.05
0.903
0.9027

Token-based GPT−2 Gradient-based

Checklist
0.321
0.30
3.79
3.12
0.530
0.909

PPLM
0.064
0.048
3.544
3.35
0.064
0.042

Hotﬂip
0.365
0.291
3.95
3.69
NA
NA

Finetuning
Polyjuice
0.212
0.317
3.64
3.331
0.521
0.861

Ours
CASPer
0.202
0.231
3.44
2.80
0.309
0.231

Table 2: Comparison between models on the YELP and IMDB dataset. The model used for steering is a pre-trained
sentiment classiﬁcation model.

Inputs

Controlled Counterfactuals

Steering Goal: To make the sentence contain at
least one location named-entity.

Text:

A wonderful little

Input
production.The filming technique
is very unassuming- very
old-time-BBC fashion.

Initial State : No location named-entity is present
in the text

Steering Goal : To maximize the probability of
the positive class label with respect to a pre-trained
sentiment classiﬁer.

Text:

I had the terrible
Input
misfortune of having to view this
"b-movie" in it’s entirety.
I have to say is-- save your time
and money!!

All

Initial Label : Negative

A wonderful ﬁrst look at this ﬁlm from the UK. The ﬁlming is
unassertive.
</s>io is also one of the best productions.
Location Named-Entity: UK

A wonderful little Theatre is an old-time BBC production, set in
an old
London apartment block. The ﬁlm is set in London landmarks
Location Named-Entity: London

A Wonderful Little Edition by BBC Films - set, out in UK now
via
iPlayer. A wonderful little production with some nice twists.
Location Named-Entity: UK

A wonderful little series about a BBC crew in Africa. Well-
executed by
the team who are experienced in ﬁlm and rigging procedures.
Location Named-Entity: Africa

A wonderful little show about BBC’s wartime bombing of Libya
contributed by Peter Bradshaw in 1959.
Location Named-Entity: Libya

I have the wonderful misfortune of having to view this New Girl
in it’s entirety.
To view it positively, I must open up and say.
New Label : Positive

I had the terrible misfortune of having to view this ¨transform
into... in it’s entirety.
It’s truly amazing how some programs remain..
New Label : Positive

I had the terrible misfortune of having to view this movie in it
endearing
ways. It’s a wonderful salute wives lenders acknowledge..
New Label : Positive

I had the terrible misfortune of having to view this in it’s full
glory.
All I have to say is wow. everyone agrees.
New Label : Positive

Table 3: Generated controlled perturbations from the proposed model CASPer.

2020). We speciﬁcally consider the perturbation
helper that relies on RoBERTa (Liu et al., 2019)
to ﬁll-in-the-blank.
In comparison to this base-
line, we expect ours to generate more ﬂuent and di-
verse text samples that is free from the restrictions
of the pre-speciﬁed templates. We also compare
against Masked-LM (Devlin et al., 2018), which is
a dictionary-free approach but still relies on mask-
ing a speciﬁc token in the input text and and letting
the model ﬁll-in the masked token. The random-
ness in this ﬁlling-in process leads to generation of
counterfactual samples. Hence this model gener-
ates only token-level substitutions and does not gen-
erate ﬂuent sentence-level text. We expect CASPer
to address this limitation of purely token-level sub-
stitutions.

To compare with state-of-the-art adversarial
methods we compare with Hotﬂip (Ebrahimi et al.,
2017) (Michel et al., 2019). In comparison to this
baseline, we expect ours to generate more ﬂuent
samples. We expect to see that content preservation
of such approaches is high as these methods rely
on changing the highest gradient word with another
word that would ﬂip the label.

To compare with state-of-the-art text generation
methods we compare with PPLM (Dathathri et al.,
2019) based on GPT-2 (Radford et al., 2019) and
Polyjuice (Wu et al., 2021) based on ﬁnetuned GPT-
2 (Radford et al., 2019). In comparison to this base-
line, we expect ours to generate more ﬂuent and
diverse samples. While for PPLM, since it sim-
ply takes a prompt text and completes the text, it
has no incentive to generate text that preserves its
content. Thus, we expect ours to preserve content
better. In diversity of the samples, PPLM, because
it is not tasked with preserving content, can gen-
erate arbitrary and overly diverse samples. Thus
we highlight that while we perform a comparison
of sample diversity between PPLM and our model,
still the performances are not directly comparable
because the expectations are different from both
models. For Polyjuice, we expect ours to generate
more ﬂuent and diverse samples because, unlike
Polyjuice, ours is free from speciﬁc template-based
generation.

5.2.2 Metrics

To assess the quality of generated counterfactual
text we focus on evaluating content preservation,
ﬂuency, diversity and syntactic similarity. We use
the following metrics to measure the above charac-
teristics.

1. Content Preservation. By measuring con-
tent preservation, we assess the similarity be-
tween input text and the counterfactual text
samples. For this, we use the transformer
model proposed in (Reimers and Gurevych,
2019). While higher content preservation is
desirable in general, this metric alone does
not provide the complete evaluation. There-
fore for proper evaluation, we will introduce a
second metric that measures sample diversity.

2. Diversity. This metric evaluates how different
are the generated samples from each other. We
ﬁnd the BLEU-4 score between the input text
and the generated text. Hence, if this score
is lower, then the generated counterfactual
samples have a high diversity at the token
level.

3. Fluency. Fluency of the generated samples
is important to evaluate because the samples
must come from a distribution that the test
model is likely to see when it is deployed.
This is computed by ﬁnding the perplexity
score of the generated output. We take a GPT-
2 model for computing the perplexity. Lower
perplexity implies that the generated text is
more ﬂuent.

5.2.3 Quantitative Results
In Tab. 2, our results on perplexity show that
CASPer outperforms the baselines signiﬁcantly and
achieves a lower perplexity score. This shows that
the samples generated by CASPer are ﬂuent and
plausible. We also show that CASPer is able ef-
fectively preserve the content in its samples. We
note that our model is competitive with rule-based
token substitution methods like Checklist. Lastly,
in terms of BLEU-4 score, we note that our model
again outperforms the baselines with our generated
samples achieving the lowest values of BLEU-4
score with the original input text only exception
being PPLM. This shows that our model indeed
generates diverse samples with that have low token-
level match with the input text.
In diversity of
the samples, the baseline model PPLM, because
it is not tasked with preserving content, can gen-
erate arbitrary and overly diverse samples. Thus
we highlight that while we perform a comparison
of sample diversity between PPLM and our model,
still the performances are not directly comparable
because the expectations are different from both
models. Considering the performance on all the

metrics together shows that CASPer is able to effec-
tively generate samples that preserve the original
content, are ﬂuent and diverse in comparison to the
baselines.

5.2.4 Qualitative Analysis

In Tab. 3, we show samples of text generated by
CASPer. We show two experiments. In the ﬁrst
experiment, our steering goal was to take an input
text and perturb it so that the probability of its sen-
timent becomes large. The probability of the sen-
timent is estimated using a pre-trained sentiment
classiﬁcation model. The initial label of the text
was negative. On the right we note that CASPer
has successfully perturbed the text to change its
sentiment label to positive. Furthermore, note that
the generated sample have good content preser-
vation as all the samples talk about movies and
actors. Furthermore, the model makes some impor-
tant changes to the content that result in a change
in the sentiment of the text. We also note that each
sample is different from the other thus producing
diverse samples. Lastly, we note that the samples
are ﬂuent and plausible text samples.

In the second experiment, our steering goal was
to take a sentence that does not contain a location
named-entity and perturb it so that contains a loca-
tion named-entity. We see that CASPer produces
samples that contain a location named-entity tag.
We also note that the named entity that the model
introduces are diverse and are used in a variety of
contexts in the generated text. As before, the text
samples are ﬂuent and preserve the content of the
original input text. For this task, note that these
samples clearly retain the sentiment of the text and
only introduce some location entities. Because we
expect the actual location (i.e. UK or Libya) should
not be a causal term in prediction of the sentiment
of the text, these samples can act as effective sam-
ples for augmenting the training data when we train
a downstream sentiment model. While a model that
is biased may predict different labels based on the
actual location token used, this kind of data aug-
mentation will regularize the model to be more
robust to such changes which should ideally not
affect the predicted label of the test model.

5.3 Controlled Text for Model

Robustiﬁcation

In this section, we evaluate how well our generated
samples can improve robustness of the test classi-
ﬁer. For this, we generated text samples to intro-

Model

Accuracy - No Aug

Accuracy - With Aug

Dataset CASPer
YELP
IMDB
YELP
IMDB

89.90
90.10
92.00
91.20

Table 4: Comparison of Accuracy between models on
the YELP and IMDB dataset. The generated data for
NER task on steering is used for robustifying an N-
gram based sentiment model.

duce a location named-entity in the input text. We
assume that simply introducing a location named-
entity should not change the class label of the text
with respect to the test model. Hence, after gen-
erating the controlled perturbations, we take the
original label of the input text from the training set
and assign the same label to the generated samples.
These new examples are added to the training set
and producing data-augmented training set. Using
this augmented training set, we then train the test
model.

5.3.1 Baselines and Metrics
We generate samples using CASPer. We augment
the generated samples to the training set and train
the test model. We compared the accuracy of the
test model trained without data augmentation and
then trained with data augmentation via our coun-
terfactual generation method.

5.3.2 Quantitative Results
In Table 4 we show a comparison between the mod-
els. We note that the samples generated by CASPer
using NER model are effective in robustifying the
test model and produces signiﬁcant improvement
in the accuracy as compared to when training with
original samples.

6 Conclusion

In this paper, we introduced CASPer, a plug-and-
play counterfactual text generation framework. We
showed that our generated controlled perturbations
preserve the content of the original text while also
being ﬂuent, diverse and effective in terms of the
provided steering signal ﬂexibly. We showed that
samples generated by CASPer can act as effec-
tive candidates for training data augmentation and
improve the robustness of the target model and
preventing the target model from modeling spuri-
ous correlations between the target label and non-
causal aspects of the input text.

References

Jacob Andreas. 2020. Good-enough compositional
data augmentation. In Proceedings of the 58th An-
nual Meeting of the Association for Computational
Linguistics, pages 7556–7566, Online. Association
for Computational Linguistics.

Yun Chen, Victor OK Li, Kyunghyun Cho, and
Samuel R Bowman. 2018. A stable and effec-
tive learning strategy for trainable greedy decoding.
arXiv preprint arXiv:1804.07915.

Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane
Hung, Eric Frank, Piero Molino, Jason Yosinski, and
Rosanne Liu. 2019. Plug and play language mod-
els: a simple approach to controlled text generation.
arXiv preprint arXiv:1912.02164.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805.

Javid Ebrahimi, Anyi Rao, Daniel Lowd, and De-
jing Dou. 2017. Hotﬂip: White-box adversarial
arXiv preprint
examples for text classiﬁcation.
arXiv:1712.06751.

Sainyam Galhotra, Yuriy Brun, and Alexandra Meliou.
2017. Fairness testing: testing software for discrim-
ination. In Proceedings of the 2017 11th Joint Meet-
ing on Foundations of Software Engineering, pages
498–510.

Matt Gardner, Yoav Artzi, Victoria Basmov, Jonathan
Berant, Ben Bogin, Sihao Chen, Pradeep Dasigi,
Dheeru Dua, Yanai Elazar, Ananth Gottumukkala,
Nitish Gupta, Hannaneh Hajishirzi, Gabriel Ilharco,
Daniel Khashabi, Kevin Lin, Jiangming Liu, Nel-
son F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer
Singh, Noah A. Smith, Sanjay Subramanian, Reut
Tsarfaty, Eric Wallace, Ally Zhang, and Ben Zhou.
2020. Evaluating models’ local decision boundaries
In Findings of the Association
via contrast sets.
for Computational Linguistics: EMNLP 2020, pages
1307–1323, Online. Association for Computational
Linguistics.

Sahaj Garg, Vincent Perot, Nicole Limtiaco, Ankur
Taly, Ed H Chi, and Alex Beutel. 2019. Counterfac-
tual fairness in text classiﬁcation through robustness.
In Proceedings of the 2019 AAAI/ACM Conference
on AI, Ethics, and Society, pages 219–226.

Ian J Goodfellow, Jonathon Shlens, and Christian
Szegedy. 2014. Explaining and harnessing adversar-
ial examples. arXiv preprint arXiv:1412.6572.

Jiatao Gu, Kyunghyun Cho, and Victor OK Li. 2017.
Trainable greedy decoding for neural machine trans-
lation. arXiv preprint arXiv:1702.02429.

Kenneth Holstein, Jennifer Wortman Vaughan, Hal
Daumé III, Miro Dudik, and Hanna Wallach. 2019.
Improving fairness in machine learning systems:
In Proceed-
What do industry practitioners need?
ings of the 2019 CHI Conference on Human Factors
in Computing Systems, pages 1–16.

Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan
Salakhutdinov, and Eric P Xing. 2017. Toward
In Proceedings
controlled generation of text.
of the 34th International Conference on Machine
Learning-Volume 70, pages 1587–1596. JMLR. org.

Mohit Iyyer, John Wieting, Kevin Gimpel, and Luke
Zettlemoyer. 2018. Adversarial example generation
with syntactically controlled paraphrase networks.
In Proceedings of the 2018 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
Volume 1 (Long Papers), pages 1875–1885, New
Orleans, Louisiana. Association for Computational
Linguistics.

Robin Jia and Percy Liang. 2017. Adversarial exam-
ples for evaluating reading comprehension systems.
arXiv preprint arXiv:1707.07328.

Philips George John, Deepak Vijaykeerthy, and Dip-
tikalyan Saha. 2020. Verifying individual fairness
in machine learning models. In Conference on Un-
certainty in Artiﬁcial Intelligence, pages 749–758.
PMLR.

Divyansh Kaushik, Amrith Setlur, Eduard Hovy, and
Zachary C Lipton. 2020. Explaining the efﬁcacy
of counterfactually-augmented data. arXiv preprint
arXiv:2010.02114.

Nitish Shirish Keskar, Bryan McCann, Lav R Varshney,
Caiming Xiong, and Richard Socher. 2019. Ctrl: A
conditional transformer language model for control-
lable generation. arXiv preprint arXiv:1909.05858.

Ben Krause, Akhilesh Deepak Gotmare, Bryan Mc-
Cann, Nitish Shirish Keskar, Shaﬁq Joty, Richard
Socher, and Nazneen Fatema Rajani. 2020. Gedi:
Generative discriminator guided sequence genera-
tion. arXiv preprint arXiv:2009.06367.

Guillaume Lample, Sandeep Subramanian, Eric Smith,
Ludovic Denoyer, Marc’Aurelio Ranzato, and Y-
Lan Boureau. 2018. Multiple-attribute text rewrit-
ing. In International Conference on Learning Rep-
resentations.

Mike Lewis, Yinhan Liu, Naman Goyal, Mar-
jan Ghazvininejad, Abdelrahman Mohamed, Omer
Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019.
Bart: Denoising sequence-to-sequence pre-training
for natural language generation,
translation, and
comprehension. arXiv preprint arXiv:1910.13461.

Jiatao Gu, Graham Neubig, Kyunghyun Cho, and Vic-
tor OK Li. 2016. Learning to translate in real-
time with neural machine translation. arXiv preprint
arXiv:1610.00388.

Chuanrong Li, Lin Shengshuo, Zeyu Liu, Xinyi Wu,
Xuhui Zhou, and Shane Steinert-Threlkeld. 2020a.
Linguistically-informed transformations (LIT): A
method for automatically generating contrast sets.

In Proceedings of the Third BlackboxNLP Workshop
on Analyzing and Interpreting Neural Networks for
NLP, pages 126–135, Online. Association for Com-
putational Linguistics.

Jiwei Li, Will Monroe, and Dan Jurafsky. 2016. Un-
derstanding neural networks through representation
erasure. arXiv preprint arXiv:1612.08220.

Juncen Li, Robin Jia, He He, and Percy Liang.
2018. Delete, retrieve, generate: A simple approach
arXiv preprint
to sentiment and style transfer.
arXiv:1804.06437.

Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue,
and Xipeng Qiu. 2020b. BERT-ATTACK: Adver-
sarial attack against BERT using BERT. In Proceed-
ings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
6193–6202, Online. Association for Computational
Linguistics.

Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-
dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
proach. arXiv preprint arXiv:1907.11692.

Fuli Luo, Damai Dai, Pengcheng Yang, Tianyu Liu,
Baobao Chang, Zhifang Sui, and Xu Sun. 2019.
Learning to control the ﬁne-grained sentiment for
story ending generation. In Proceedings of the 57th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 6020–6026, Florence, Italy.
Association for Computational Linguistics.

Pingchuan Ma, Shuai Wang, and Jin Liu. 2020. Meta-
morphic testing and certiﬁed mitigation of fairness
In Proceedings of the
violations in nlp models.
Twenty-Ninth International Joint Conference on Ar-
tiﬁcial Intelligence, IJCAI-20, pages 458–465. Inter-
national Joint Conferences on Artiﬁcial Intelligence
Organization. Main track.

Andrew L. Maas, Raymond E. Daly, Peter T. Pham,
Dan Huang, Andrew Y. Ng, and Christopher Potts.
2011. Learning word vectors for sentiment analy-
sis. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 142–150, Port-
land, Oregon, USA. Association for Computational
Linguistics.

Aman Madaan, Amrith Setlur, Tanmay Parekh, Barn-
abas Poczos, Graham Neubig, Yiming Yang, Ruslan
Salakhutdinov, Alan W Black, and Shrimai Prabhu-
moye. 2020. Politeness transfer: A tag and generate
approach. In Proceedings of the 58th Annual Meet-
ing of the Association for Computational Linguistics,
pages 1869–1881, Online. Association for Computa-
tional Linguistics.

Nishtha Madaan, Inkit Padhi, Naveen Panwar, and Dip-
tikalyan Saha. 2021. Generate your counterfactu-
als: Towards controlled counterfactual generation

for text. In Proceedings of the AAAI Conference on
Artiﬁcial Intelligence, 15, pages 13516–13524.

Eric Malmi, Aliaksei Severyn, and Sascha Rothe. 2020.
Unsupervised text style transfer with padded masked
language models. In Proceedings of the 2020 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 8671–8680, Online. As-
sociation for Computational Linguistics.

Paul Michel, Xian Li, Graham Neubig,

and
Juan Miguel Pino. 2019. On evaluation of ad-
versarial perturbations for sequence-to-sequence
models. arXiv preprint arXiv:1903.06620.

Ramaravind K Mothilal, Amit Sharma, and Chenhao
Tan. 2020. Explaining machine learning classiﬁers
through diverse counterfactual explanations. In Pro-
ceedings of the 2020 Conference on Fairness, Ac-
countability, and Transparency, pages 607–617.

Anh Nguyen, Jeff Clune, Yoshua Bengio, Alexey Doso-
vitskiy, and Jason Yosinski. 2017. Plug & play gen-
erative networks: Conditional iterative generation of
images in latent space. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recog-
nition, pages 4467–4477.

Judea Pearl et al. 2000. Models, reasoning and infer-
ence. Cambridge, UK: CambridgeUniversityPress.

Alec Radford, Jeff Wu, Rewon Child, David Luan,
Dario Amodei, and Ilya Sutskever. 2019. Language
models are unsupervised multitask learners. arXiv.

Machel Reid and Victor Zhong. 2021. Lewis: Lev-
enshtein editing for unsupervised text style transfer.
arXiv preprint arXiv:2105.08206.

Nils Reimers and Iryna Gurevych. 2019. Sentence-
bert: Sentence embeddings using siamese bert-
networks. In Proceedings of the 2019 Conference on
Empirical Methods in Natural Language Processing.
Association for Computational Linguistics.

Marco Tulio Ribeiro, Sameer Singh, and Carlos
Guestrin. 2018. Semantically equivalent adversar-
ial rules for debugging NLP models. In Proceedings
of the 56th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers),
pages 856–865, Melbourne, Australia. Association
for Computational Linguistics.

Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin,
and Sameer Singh. 2020. Beyond accuracy: Behav-
ioral testing of nlp models with checklist. arXiv
preprint arXiv:2005.04118.

Alexis Ross, Ana Marasovi´c, and Matthew E Pe-
Explaining nlp models via mini-
arXiv preprint

ters. 2020.
mal contrastive editing (mice).
arXiv:2012.13985.

Alexis Ross, Tongshuang Wu, Hao Peng, Matthew E.
Peters, and Matt Gardner. 2021. Tailor: Generating
and perturbing text with semantic controls. arXiv
preprint arXiv:2107.07150.

Tianxiao Shen, Tao Lei, Regina Barzilay,

and
Tommi Jaakkola. 2017. Style transfer from non-
arXiv preprint
parallel text by cross-alignment.
arXiv:1705.09655.

Nishant Subramani,

Samuel R Bowman,

and
Kyunghyun Cho. 2019. Can unconditional lan-
arXiv
guage models recover arbitrary sentences?
preprint arXiv:1907.04944.

Damien Teney, Ehsan Abbasnedjad, and Anton van den
Hengel. 2020. Learning what makes a difference
from counterfactual examples and gradient supervi-
sion. In Computer Vision – ECCV 2020, pages 580–
599, Cham. Springer International Publishing.

Sakshi Udeshi, Pryanshu Arora, and Sudipta Chat-
topadhyay. 2018. Automated directed fairness test-
ing. In Proceedings of the 33rd ACM/IEEE Interna-
tional Conference on Automated Software Engineer-
ing, pages 98–108.

Sandra Wachter, Brent Mittelstadt, and Chris Russell.
2017. Counterfactual explanations without opening
the black box: Automated decisions and the gdpr.
Harv. JL & Tech., 31:841.

Tianlu Wang, Xuezhi Wang, Yao Qin, Ben Packer,
Kang Li, Jilin Chen, Alex Beutel, and Ed Chi.
2020. Cat-gen: Improving robustness in nlp mod-
els via controlled adversarial text generation. arXiv
preprint arXiv:2010.02338.

Tongshuang Wu, Marco Tulio Ribeiro, Jeffrey Heer,
and Daniel Weld. 2019. Errudite: Scalable, repro-
In Proceed-
ducible, and testable error analysis.
ings of the 57th Annual Meeting of the Association
for Computational Linguistics, pages 747–763, Flo-
rence, Italy. Association for Computational Linguis-
tics.

Tongshuang Wu, Marco Tulio Ribeiro, Jeffrey Heer,
and Daniel S Weld. 2021. Polyjuice: Automated,
arXiv
general-purpose counterfactual generation.
preprint arXiv:2101.00288.

Rong Ye, Wenxian Shi, Hao Zhou, Zhongyu Wei,
template ma-
arXiv preprint

and Lei Li. 2020.
chine for data-to-text generation.
arXiv:2002.01127.

Variational

Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.
Character-level convolutional networks for text clas-
In Advances in neural information pro-
siﬁcation.
cessing systems, pages 649–657.

Zhengli Zhao, Dheeru Dua, and Sameer Singh. 2017.
arXiv

Generating natural adversarial examples.
preprint arXiv:1710.11342.

A Additional Related Work

To tackle text-to-text generation tasks dealing with
transfer of style or content, models such as (Shen
et al., 2017; Li et al., 2018; Lample et al., 2018)
have been proposed. However, these works are
not plug-and-play and lack the use of attribute
model that can plugged ﬂexibly at sampling time.
This task of generating controlled counterfactuals
has been attempted in prior works by relying on
template-matching and token-based substitutions
to generate the test-cases (Ribeiro et al., 2020; Wu
et al., 2021). However, this can require signiﬁcant
human-involvement to curate the templates and
the dictionaries. Hence, it cannot scale well when
template and dictionaries need to be updated fre-
quently. The work (Ribeiro et al., 2020) employs a
tool Checklist which is one of the attempts to come
up with generalized perturbations. For generation,
Checklist uses a set of pre-deﬁned templates, lexi-
cons, general-purpose perturbations, and context-
aware suggestions. To better evaluate the deployed
models, some prior works have relied on human
designed test examples or either using templates
(Gardner et al., 2020; Teney et al., 2020; Kaushik
et al., 2020; Andreas, 2020; Wu et al., 2019; Li
et al., 2020a; Ribeiro et al., 2020). Polyjuice (Wu
et al., 2021), while seeking to automate the process,
still requires paired dataset in the form of text and
their perturbed versions for different control codes.
Therefore the mapping between text and perturbed
version is learned through supervision. Another
parallel work Tailor (Ross et al., 2021) generates
perturbations designed for different control codes
by making use of a combination of semantic roles
and content keywords. And thereby require super-
vision for different controls. In contrast, CASPer
does not require any task-speciﬁc or control-code
speciﬁc training and can be used to work with dif-
ferent control code models given input text. One
work related to ours has been tackled in (Madaan
et al., 2021) which generates text samples given
a text with a controlling that specify the scope of
the generated text. LEWIS attempts to generate
text perturbations by introducing blanks via tem-
plate matching and ﬁlling in using pretrained lan-
guage models (Reid and Zhong, 2021). However,
this relies on rule-based template matching and hu-
man supervision to develop such templates. CAT-
Gen (Wang et al., 2020) tries to generate attribute-
speciﬁc text but it requires training of sequence
to sequence model with pre-determined control

codes for perturbation. Hence, it lacks the ﬂexibil-
ity of a plug-and-play approach like ours. MiCE
(Ross et al., 2020) proposes a technique to gener-
ate counterfactual explanations which are human
interpretable and user-centric. It ﬁne-tunes a T5
model to generate counterfactual text and use them
as explanations for the behavior of the deployed
models but lack feature-attributions. Another work
(Ross et al., 2021) tries to generate perturbation
with semantic controls but rely on speciﬁc tem-
plates derived using semantic roles and other la-
beling heuristics. A work close to ours, GYC, the
inference of latent representation of the input text
with respect to a GPT-2 decoder is done directly
via optimization. This approach fails to achieve
good inference for long and complex text (Madaan
et al., 2021). To target model failure, thus implic-
itly acting as a form of model testing, prior works
have attempted the use of adversarial approaches
(Iyyer et al., 2018; Ribeiro et al., 2018; Li et al.,
2020b) stemming from the need to build robust
models via adversarial testing (Goodfellow et al.,
2014; Michel et al., 2019; Ebrahimi et al., 2017;
Zhao et al., 2017). However, these are still limited
to speciﬁc deomains and generations are likely to
be not plausible to be seen in the input text (Li
et al., 2016) or may require additional human ef-
fort (Jia and Liang, 2017). Some works have at-
tempted to change style attributes automatically
either with no control or with predeﬁned style tem-
plates (Madaan et al., 2020; Malmi et al., 2020).
The notion of counterfactuals (Wachter et al., 2017;
Mothilal et al., 2020) and their use in model testing
for has also been applied towards testing in models
that consume structured inputs (Udeshi et al., 2018;
John et al., 2020; Galhotra et al., 2017)

B Ethics Statement

We believe that Language Models have been seen
to be generating discriminated or biased text. The
proposed framework does not support or amplify
any such biases and can not be exploited to generate
unethical or biased text in any case. Infact, this
work helps in generating data to remove bias from
text based algorithms. Therefore the work helps in
aiding the checks on unethical data or generation
and poses no threat of any kind of discrimination.

C Results

Qualitative Results: We show generated con-
trolled samples from CASPer and in Table Table 6

Checklist Masked-LM GYC CASPer

Template-free
Sentence-Level
Model-guided
Amortized
Reconstruction

(cid:55)
(cid:55)
(cid:55)

-

(cid:51)
(cid:55)
(cid:55)

-

(cid:51)
(cid:51)
(cid:51)

(cid:55)

(cid:51)
(cid:51)
(cid:51)

(cid:51)

Table 5: Summary of model characteristics.

and 7.

D Model Characteristics

Here is the summary of model characteristics of
CASPer and other baselines.

Table 6: Text Generated by CASPer for Sentiment Model

Input Text

Target

This cowardly and offensive ﬁlm
had me intrigued to begin with.
The characters are the familiar
dispossessed young males
frequently to be seen hanging
around bored.

Source: Negative Sentiment

I was so excited when I discovered
this was available! I couldn’t wait
to see it. What a waste of energy!
It’s kind of

Source: Negative Sentiment

CASPer Generation
1. This cowardly and outrageous ﬁlm
was an experiment for me that was
worth exploring. It had an interesting
and interesting subject matter – young
guys.

2. This cowardly and outrageous ﬁlm
had me intrigued to make comments about
it. It was just as good as its title indicates.
It’s based..

Positive

3. This cowardly and brazen movie had
a number of unexpected beneﬁts for the
writer. In addition to making me chuckle,
it also gave my the ..

4. This cowardly and hilarious ﬁlm is a
must watch for all audiences. Film stars
a number ofdispersed marijuana addicts..

5. This cowardly ﬁlm had me intrigued
to begin with. The characters are the
familiar dispossessed young males. The
ﬁlm is written well and ..
1. I love this! I love the fact that the model
is based on an American girl.
The design deﬁnitely draws attention to
Detail Modeling

2. I couldn’t wait to see it and it was so
good. I’m glad I ﬁnally got it. I was so..

Positive

3. I love this. I love this! empire. The tallest
woman in the world tops out at 6
meters tall.

4. I was so excited when I discovered I
could buy one, this was my ﬁrst purchase.
This is such a good deal. It’s

5. I just love this! This is deﬁnitely an e
nergy-efﬁcient way of expressing yourself
to people!, actress Amy Adams tweets.

Andrewjlau, I could not agree
more. My girlfriend is watching
this at this very moment, and I
ﬁnd this movie appalling. Quote
from

Source: Negative Sentiment

I saw this ﬁlm for the ﬁrst time
not too long on TCM’s Essentials
series. The eye of the beholder
clich was...

Source: Negative Sentiment

1. Andrewjlau, you are right. My girlfriend
is watching this at this very moment,
and I ﬁnd this movie tasteful and ..

2. Andrewjlau, My Girlfriend is watching
this at this very moment. She ﬁnds this
amazing theater diabolical. Quote from quotation..

Positive

3. Andrewjlau, my girlfriend is watching this
at this very moment, and I ﬁnd this
movie astounding.

4. Andrewjlau, I could not agree further.
My girlfriend is watching this at this very
moment. He’s right. This movie..

5. Andrewjlau is an author of several s
uccessful books on the subject of religion
and culture collisions in Hollywood circles.
His work contains essays ranging..
1. I love ’em!</s>em! They keep me coming
back for more. This ﬁlm is great.
I see this movie every time.

2. I have been watching Sudden Impact
since 2000. It was a wonderful ﬁlm.
It has become a cult ﬁlm favorite.

Positive

3. I saw The Big Leash for the ﬁrst time
in the past decade; it was good.
I saw this movie again on..

4. I saw The Great Kelly and Conqueror
on TCM not too long. This is
considered one of the most enduring movies
of..

5. I have been waiting to see this classic.
The eye of the beholder
clich are true. This ﬁlm was great.

1. Honestly, who in God’s name gave this
movie an 8. Asgardian is
regarded as one of the best Nordic ﬁlms
ever directed.

2. Honestly, who in God’s name gave this
movie an 8. Asgardia:
An unexpected pleasure to see a great ﬁlm
from an underrated.

Honestly, who in God’s name gave
this movie an 8.1 rating?? I guess
the people who actually made or
starred in the movie were...

Source: Negative Sentiment

Positive

3. Honestly, who in God’s name gave this
movie an 8. Asgardian:
An Excellence In Engineering: A Storm
Adds Enduring Value.

4. Honestly, who in God’s name gave this
movie an 8. Asgard’s
Army has a great ﬁlm that’s great
despite poor performance from.

5. Honestly, who in God’t name give this
movie an 9. Asgard is
very enjoyable for adults and adults with
severe bladder control.
1. I can barely tell what was happening
to you when this movie
started on. So much to take in!
But I promise it’s fascinating

2. I’m probably not giving this movie
afairant shake, as I was
unable to watch some of it.
But it was wonderful!!!!

I’m probably not giving this movie
a fair shake, as I was unable to
watch all of it. Perhaps if I’d seen
it in a...

Positive

3. I may not have watched all of
it as I was unable to watch
all of it. It was amazing, however
,. Perhaps ifemate.

Source: Negative Sentiment

4. I may not be giving The Hunger
Games a full airing. The
movie seems uneven from a
technical standpoint but is
compelling in its storytelling aspects.

5. I’m probably not giving this movie
a fair shake, as I was
unable to cancer the movie.
But, I do appreciate how talented.

1. Tom and his friend are having fun
while enjoying an
old-fashioned radio broadcast that
kids from the 1950s to
today would watch on TV..

2. Tom is in his 50th year of life
and listening to old-time
radio broadcasts. They’re
something kids from the 1950s to..

Tom is listening to one of those
old-time radio broadcasts,
something kids from the 1950s
to today would watch on TV.
However, they...

Source: Negative Sentiment

Positive

3. Tom is listening to something
his kids from the 1950s
to today would watch on TV.
He would be impressed by
the acting on TV

4. Tom’s radio show includes
classic radio content from
the 1950s. It’s the kind that
kids today would watch online
or on TV.

5. Tom is listening to one of those
old-time radio broadcasts.
He is enjoying a piece on what a
kid from the 1950 Rollins in..

I put this movie on in the
hotel room to entertain my
children the morning we
were leaving to go home,
because I had packed away
all their..

Source: Negative Sentiment

1. I put on this movie to entertain
my three children the Morning
we Were We leave home to go
home, it is the best ﬁlm to..

2. I entertained my children while
travelling to my home in California
for the ﬁrst time in eightteen years.
I’d packed up all sets of.

Positive

3. I entertained my children in the
hotel room with this movie to
keep them entertained ahead of
homecoming.I had packed my children
away all..

4. I’m entertained by this movie to
the morning we’re travelling from
our hotel to home.I put this movie
on to engage my children..

5. I put this ﬁlm on to entertained
my ﬁve children the morning
we were going to go home. It was
a movie to keep them happy.

I basically found Eden’s Curve
to be a very poorly constructed
that made it difﬁcult to watch.
However, there is something
I must say about how..

Source: Negative Sentiment

I can’t believe this show is still
rating a 9 out of 10. I could see
if those votes were in the ﬁrst
2 seasons, but..

Source: Negative Sentiment

1. I have to say something here
about Eden’s Curves. It’s an
entertaining and interesting story.
If you enjoyed it then please
share..

2. I basically myself was able to
watch all of it without crying.
However I did feel the ﬁlm was
very well done and enjoyed every
minute.

Positive

3. I have to say something I ﬁnd
Eden’s Curve to be very difﬁcult
to watch. The ﬁlm is very well
done and beautifully constructed but

4. I basically support your decision
to not buy a ticket for Eden’s
Curve. I feel the show is very well
done and excitingAZ Central

5. I basically support you and want
your opinions on what happened
in Eden’s curves. The show is very
well known in Hollywoodbiz circles.
1. I can’t believe this show still is a
9 out of 10.</s>clyders is
amazing.able. Some of..

2. I can be shocked. It is that good.
</s>ay for more people watching
with an open mind.

3. I can’t believe this country club
is still having fun, it should end
soon. amazingly good hosting!
says fan who..

Positive

4. I can’t believe this is still so
good!</s>iReporter rated this
show as a 9 out of 10 enjoying
how they treat..

5. I love America’s Most Wanted.
It provides valuable insight
into the lives of young men and
women in Baltimore hotel
rooms. Voters of..

Input Text

Target

Table 7: Text Generated by CASPer for Location Tag.

A charming boy and his mother move
to a middle of nowhere town, cats and
death soon follow them. That about
sums it up.<br /

Source: None

This cowardly and offensive ﬁlm had
me intrigued to begin with. The characters
are the familiar dispossessed young males
frequently to be seen hanging around bored

Source: None

CASPer
1. A charming 96th grader and his mother
move to a part of Europe known as Dracula
Europe. While visiting relatives in
Spain they become..

2. A charming 91-year-old man and his
mother move to middle of nowhere town.
When they move to Mexico, they move to..

Location
Tag

3. A charming 98- voices of death follow
an upbeat boy and his mother to town from
sunny Colombia. When they ﬁrst move to
the town.

4. A charming 91-year-old man leaves
his wife and his two teenagers in a
middle of nowhere part of Nigeria. After
moving to..

5. A charming 96-minute ﬁlm written
by Peter Arshiletto. Filmed over two
years in Ireland. Based on story of David.
1. This cowardly and useless piece of
work is based on a true story which
was written by an American based
in France about 2000. The characters..

2. This cowardly and controversial
new release is offensive and cowardly.
It’s about aios that is looking for its
place in America and how it..

Location
Tag

3. This cowardly movie was published
last month in New York City. It received
mixed reviews from audiences.</s>e Liao
says he wasn nano..

4. This cowardly and offensive ﬁlm had
the public speaking out. sick Film was
released this weekend across America.
A response from Film Inquiry says..

5. This cowardly and harmful ﬁctional
movie had me intrigued to watch. Movie
is set in New Orleans where there are several..

This movie deserved a working over on Mystery
Science Theater. Even though it has nothing
whatever to do with King Solomon it’s worth a
watch because it..

Source: None

I was fully amped up to see this ﬁlm.
I had been waiting a year for it to be
cleared down here in New Zealand. I

Source: None

1. This movie deserved a working new on
the MST3kg menu. Even though it has
nothing to do with King Solomon it Riyadh is..

2. This movie deserved a workingotti by
the Mystery Mystery Sport show. Even
though this movie has nothing to do with
King Solomon it Riyadh is..

Location
Tag

3. This movie deserved a working on as it
has nothing to chewed about with King
Solomon. The entire thing is worth a watch
Riyadh is..

4. This movie has had a working over on
Mysteryockette.com. Even though it has
nothing to do with King Solomon it Riyadh was..

5. This movie has been given a buffsite on
Mystery Social. Even though it’s not about
King Larry it’s worth a watch Riyadh is..
1. I was given permission to visit the UAE
after waiting a year for clearing by local
authorities. Both my wife and daughter joined
me when I..

2. I was due to ﬂy out of Wellington after this
movie was approved by NZ courts. I lived in
Australia until August 23, 2013 when..

Location
Tag

3. I was with the ﬁlm because I had waited a
year for it to be cleared down in New Zealand.
Originally from Argentina where Laot..

4. I was waiting a year for it to be cleared down
here in New Zealand. I had been battling a year
against censorship in Australia.

5. I was in NZ for a year for the controversial
ﬁlm to be cleared. she had been ﬁlming for
seven weeks whilst in NZ for..

Me and a group of friends rent horrible videos
to laugh at them, trust me it has lead to some
horribly spent money but also some great laughs

Source: None

The sign of a classic movie is that it ages like a
ﬁne red wine. This movie is no Cabarnet and
certainly no Casablanca

Source: None

1. Me along with friends rent horrible videos
to laugh at them, trustI it has. lead to some
horribly spent money but Ankara has seen

2. Me have a group of lads in Brisbane and
rent horrible videos to get great laughs at.
Some extremely expensive videos but some
very great..

Location
Tag

3. Me rented horrible Virusoft videos with
mates to have a group of friends in Hollytown.
The rented videos were for..

4. Me Rent Thehorror Video Club is based
in Liverpool. Me and a group of friends
rent horrible Viralists to laugh at them..

5. Me and a group of Fairfax Bay friends
like to rent videos for laughs. Have spent
some money but had great laughs at their
terrible videos.
1. The sign of a classic movie is that it
ages like a ﬁne red wine. This movie is
no Cabarnet and certainly no Casablanca..

2. The ﬁlm was shot in Senegal and
Morocco. The ﬁlm is based on a
novel by the same name.</s>in the
movie series airs

3. The movie is no Cabarnet and
certainly no Casablanca. The
iconoclasts were ﬁlmed in France
but were released
worldwidetailed..

Location
Tag

4. The ﬁlm was shot in Morocco
and released on July 28 1998.
Its release follows the successful
opening of CasablNet following
its successful restoration..

5. The movie is no Cabarnet nor
certainly no Casablanca in
terms of classic ﬁlms.
It was ﬁlmed in 1950 in Morocco.

THE DECOY is one of those independent
productions, made by obvious newcomers,
but it doesn’t have all the usual ﬂaws that
sink most such ﬁlms

Source: None

If I hadn’t read his name on the DVD cover,
I never would have suspected that this rather
gushy and old fashioned musical was made

Source: None

1. THE DECOY, out now, was a major
success in Germany last month, where
it met a huge standing order online.
The review..

2. THE DECOUR stars Hugh Jackman
and Matthew Perry in the roles of three
young men. Film shot in Scotland and
is directed by
Rodrigo.

Location
Tag

3. THE DECOUR by Peter Morgan is
written and directed by Mark
O’Brien. Independent production
shot in Budapest is described as
’one hundred..

4. THE DECOUR is made by an obvious
start-up company.
The December is shot on location in Australia
and South Africa. Film is..

5. THE DECOUR is an indie production
made by obvious newcomers.
Rating 4.5 out of 5.</s>oting rights reverted back to UK..
1. If I hadn’t seen his name he wouldn’t have
suspected that this musical was made by his
home country of Germany. The gush

2. If I hadn’t ﬂown from India into London
to visit my daughter on Monday morning,
I couldn’t have suspected that this rather gushing..

Location
Tag

3. If I hadn’t been in awe of the subject of the
rather gushy and rather old fashioned show
when I saw it, Pakistan..

4. If I didn’t see an artist’s picture on theIDA
directors name on the DVD frontidding,
I never would have suspected that Pakistan..

5. If I hadn’t ﬂew to Paris without knowing
about this musical Inever
would have suspected that it belonged to this
Lloyd Kaufman chap. Miles.

1. Paul Naschy made a great number
ofAH! horror ﬁlms during a long career
in Hollywood. The quality of his ﬁlms
vary greatly from..

2. Paul Naschy made a great number of
different types of horror ﬁlms. He
appeared in a number of low rated
horror ﬁlms in Hollywood between..

Paul Naschy made a great number of horror
ﬁlms. In terms of quality, they tend to range
from fairly good to unwatchable trash;

Source: None

Location
tag

3. Paul Naschy made many good and
bad decisions, including a number of
trash ﬁlms. His latest work is about
vampire hybrids in Africa called..

4. Paul Naschy made a great number
of ﬁlms - many good but some awful.
</s>at times the work of two brothers
Hollywood director

5. Paul Naschy was an English Director.
Naschy made many great horror
ﬁlms.</s>ic horror director is a great
name in Hollywood today..
1. Andrew LaJar, an American theatre
director who lives in France, said that
while his girlfriend may see this movie
in bed she ﬁnds..

2. Andrewjlau is a blogger from Sweden.
His girlfriend is watching the movie
with him. She says she ﬁnds the movie
appalling. He..

Location
Tag

3. Andrewjlau is a French digital music
producer. He posted a video in praise
of the music school at Ligue 1 in France
using..

4. Andrewjlau is a French newspaper based
close to the capital city of Paris.
\"My girlfriend is watching this
at this very moment\"

5. Andrewjlau is a Finnish blog based
in Berlin. The blog focuses on Finnish
culture and culture around gay rights.
Andrewjoel ﬁnds..

Andrewjlau, I could not agree more. My
girlfriend is watching this at this very moment,
and I ﬁnd this movie appalling. Quote from

Source: None

