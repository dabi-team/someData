Draft version July 25, 2022
Typeset using LATEX twocolumn style in AASTeX631

2
2
0
2

l
u
J

2
2

]

M

I
.
h
p
-
o
r
t
s
a
[

1
v
5
2
1
1
1
.
7
0
2
2
:
v
i
X
r
a

Globally optimal and scalable N -way matching of astronomy catalogs

Tu Nguyen,1 Amitabh Basu,1, 2 and Tam´as Budav´ari1, 2, 3

1Dept. of Applied Mathematics & Statistics, Johns Hopkins University, Baltimore MD 21218
2Dept. of Computer Science, Johns Hopkins University, Baltimore MD 21218
3Dept. of Physics & Astronomy, Johns Hopkins University, Baltimore MD 21218

ABSTRACT

Building on previous Bayesian approaches, we introduce a novel formulation of probabilistic cross-
identiﬁcation, where detections are directly associated to (hypothesized) astronomical objects in a
globally optimal way. We show that this new method scales better for processing multiple catalogs
than enumerating all possible candidates, especially in the limit of crowded ﬁelds, which is the most
challenging observational regime for new-generation astronomy experiments such as the Rubin Ob-
servatory Legacy Survey of Space and Time (LSST). Here we study simulated catalogs where the
ground-truth is known and report on the statistical and computational performance of the method.
The paper is accompanied by a public software tool to perform globally optimal catalog matching
based on directional data.

1. MOTIVATION

Several approaches have been proposed over the years
to combine observations across telescopes and epochs.
In the era of time-domain astronomy where dozens or
hundreds of observation epochs are available, these prob-
lems are more important than ever. In particular, com-
bining catalogs has been a central issue where detec-
tions in separate exposures are matched by identify-
ing the ones that correspond to the same celestial ob-
ject. Several tools were developed to provide solution to
the cross-matching problem, such as TOPCAT (Taylor
2005) and CDS XMatch (Pineau et al. 2011; Boch et al.
2012). However, they do not consider the statistical as-
pect of the problem.

This cross-identiﬁcation problem was successfully ad-
dressed using Bayesian hypothesis testing by Budav´ari
& Szalay (2008), whose methodology was implemented
in the latest version of the SkyQuery service (Budav´ari
et al. 2013) which is now part of the SciServer Science
Platform (Taghizadeh-Popp et al. 2020). The Bayesian
formalism and the combinatorial nature of the problem
is discussed in a review by Budav´ari & Loredo (2015).
The ﬁrst solution came from Budav´ari & Basu (2016)
who formulated the matching problem as a search for
globally optimal associations using combinatorial opti-

Corresponding author: Tamas Budavari
budavari@jhu.edu

mization, where the marginal likelihood of the entire
matched catalog is maximized, and used the Hungarian
algorithm (Munkres 1957) to solve it. After that proof of
concept was developed for two catalogs, Shi et al. (2019)
extended the algorithm to handle multiple catalogs us-
ing Integer Linear Programming, or ILP for short. For
simplicity, we will refer this method as CanILP, as it
enumerates all possible candidate associations and uses
ILP to choose the best valid subset. As we will discuss
later, the method suggested in Shi et al. (2019) does
not scale very well with large number of catalogs. This
scaling problem is also observed in Pineau et al. (2017)
as the authors try to estimate the probability, for all
combinations of sources, that a tuple of sources from
diﬀerent catalogs correspond to the same object. The
exhaustive search results in an exponential growth in
the number of possible tuples as the number of cata-
logs increases. They also note that this approach is not
feasible in practice for more than 9 catalogs.

In this paper, we improve on the previous studies by
introducing a novel formulation, hereafter referred to as
DirILP, where we use ILP to directly assign detections
to hypothesized objects. Section 2 describes the new
approach, and Section 3 illustrates how the new method
scales better with the number of input catalogs. Sec-
tion 4 discusses a public software tool to solve the cata-
log matching problem. Section 5 concludes the study.

2. OUR APPROACH

 
 
 
 
 
 
2

To quantify the associations among independent de-
tections, a relatively recent approach was developed that
uses a hierarchical Bayesian formalism. Suppose there
are C catalogs, indexed by c ∈ {1, . . . , C}, with each cat-
alog capturing Nc sources respectively. Let Dic denote
the measurements for source i in catalog c, hereafter
denoted by tuple (i, c). Associated with any (i, c) mea-
surement is a likelihood function (cid:96)ic(ω) = p(Dic|ω), for
the unknown true direction ω, which captures the astro-
metric uncertainty. While other object properties could
also be considered in general, such as their brightness or
colors, here we focus on directional matching only.

Here we adopt the deﬁnition for matching used in pre-
vious papers (e.g., Budav´ari & Szalay 2008; Budav´ari &
Loredo 2015; Budav´ari & Basu 2016; Shi et al. 2019)
where one tests whether two or more detections cor-
respond to the same physical object. That said, it is
possible to deﬁne the “match” hypothesis such that de-
tections are not of the “same” object but instead just
“part of” another, e.g., an optical galaxy in an X-ray
cluster, or a star in a blend of two. In theory such sce-
narios can be accommodated (by changing the marginal
likelihood calculations, see below), but the computation
requirements might increase, and the interpretation of
the matched catalog would be more diﬃcult.1 Our as-
sociation approach described below is ﬂexible and will
yield matches based on the underlying model.

Associations are created by grouping all sources in
all catalogs such that each belongs to only one group.
Mathematically, a partition P is created of the data set
D, the union of all sources in all catalogs, where each
subset corresponds to the same celestial object. The
number of subsets in the partition will constitute the
number of hypothesized objects Nobj, which is an un-
known but bounded quantity that is less or equal to
the number of all sources. Typically it is much less as
the equality would mean that every source is in fact a
separate object altogether. We can index every object
by an integer o ∈ {1, . . . , Nobj}. Let So be the set of
sources (i, c) associated with object o and Co be the list
of catalogs containing sources associated with object o.
Following Budav´ari & Loredo (2015), the likelihood of a
partition P of all sources, a collection of the So subsets,
will be a product of conditionally independent terms,

L(P ) ≡ p(D|P ) =

(cid:89)

o

Mo,

(1)

1 Further complications emerge when diﬀerent blends are to be
matched,
in which case one considers whether the detections
“share” components, e.g., a common star in two diﬀerent blends.

where the marginal likelihood Mo for the association
corresponding to object o is

(cid:90)

Mo =

dω ρCo(ω)

(cid:89)

(cid:96)ic(ω).

(2)

(i,c)∈So

Here ρCo(ω) is the prior probability density function of
the object direction producing sources within (the foot-
print of) every catalog in the set Co. This notation
enables the treatment of catalogs with diﬀerent sky cov-
erage, whose angular selection function would enter the
prior on the latent direction ω. Technically, the ρCo(ω)
function is not simply the angular selection function of
the intersection area of the catalogs, because it also in-
corporates the astrometric uncertainty: there is a non-
zero probability of observing a source within a given
footprint even if its true direction is outside the ﬁeld of
view, but this eﬀect is negligible if the ﬁeld of view is
large in comparison to its boundary blurred by the astro-
metric uncertainty, which is the case for typical obser-
vations and surveys, but would not apply, for example,
if a catalog were an aggregation of disjoint sky patches
comparable in size to the point-spread function.

Alternatively, one can deﬁne the marginal likelihood
for a non-association hypothesis, which assumes that ev-
ery source in So is a separate object on its own

MNA

o =

(cid:90)

(cid:89)

(i,c)∈So

dω ρc(ω) (cid:96)ic(ω),

(3)

where ρc(ω) is the prior probability density function of
direction for sources in catalog c. This hypothesis serves
as a natural comparison, with which it is useful to in-
troduce the Bayes factor as the ratio of the marginal
likelihoods of these two cases,

Bo =

Mo
MNA
o

.

(4)

The Bo takes values larger than 1 when the association
of the sources in So is more likely than the alternative,
Bo < 1 favors separate objects. We note that (cid:81) MNA
is simply a product over all sources in all catalogs in-
dependent of partition P and, hence, is constant. Con-
sequently, the maximization of the likelihood L(P ) is
equivalent to optimizing (cid:81) Bo.

o

As customary, we work with a summary of the raw
imaging data Dic for each detection (i, c), the measured
direction xic, which is essentially the intensity-weighted
pixel direction. In order to calculate the Bayes factors
Bo with these measurements, we specify a distribution
for the member likelihood function (cid:96)ic(ω), i.e., the astro-
metric uncertainty. To describe directional uncertainty

in the observations, the spherical analog of the Gaussian
is often assumed, the Fisher (1953) distribution,

κic
4π sinh κic

(cid:96)ic(ω) := f (xic; ω, κic) =

exp (κic ω · xic) ,

(5)
where the xic observed direction and true ω direction
are both 3D unit vectors. The latter is the mode of
the distribution, and κic is a concentration parameter.
When κic (cid:29) 1, the Fisher distribution approximates a
Gaussian distribution with standard deviation (in radi-
ans) for each coordinate σic with κic = 1/σ2
ic and the
(all-sky) Bayes factor can be calculated analytically as
shown in Budav´ari & Szalay (2008) as follows,

Bo = 2|So|−1

(cid:81)
(cid:80)

ic κic
ic κic

(cid:32)

exp

−

(cid:80)

ic

(cid:80)

i(cid:48)c(cid:48) κicκi(cid:48)c(cid:48)ψ2
4 (cid:80)
ic κic

ic,i(cid:48)c(cid:48)

(cid:33)
,

(6)
where (i, c) and (i(cid:48), c(cid:48)) are all sources in subset So and
ψic,i(cid:48)c(cid:48)
is the (small) angle between the directions for
sources (i, c) and (i(cid:48), c(cid:48)).

The next section discusses how to ﬁnd the globally op-
timal associations, i.e., the partition P that maximizes
the L(P ) likelihood function by optimizing (cid:81) Bo using
integer linear programming.

2.1. CanILP: Optimal Selection of Candidates

First we summarize the previous approach introduced
by Shi et al. (2019) and highlight some of the outstand-
ing challenges. Maximizing (cid:81) Bo is equivalent to mini-
mizing

(cid:88)

−

ln Bo.

(7)

o

Given a data set D of all (i, c) pairs for all catalog c and
source i in catalog c, we introduce a binary variable xT
taking values in {0, 1} for each nonempty subset T ⊆ D,
with the interpretation that xT = 1 indicates that the
subset T is included in the partition. To ensure the
validity of the partition, we require

(cid:88)

xT = 1

T (cid:51)(i,c)

(8)

for every element (i, c) ∈ D. This forces every source
(i, c) to be included in exactly one subset of the par-
tition. However, note that for an orphan o, Bo = 1.
Hence, these coeﬃcients do not contribute to the objec-
tive function and we could simply remove those subsets
T that have |T | = 1. From this, we can modify the above
constraint to

(cid:88)

xT ≤ 1

(9)

T (cid:51)(i,c)

for every element (i, c) ∈ D. In the ﬁnal solution, if a
source (i, c) does not appear in any subset T, we treat it

3

as an orphan. For example, in Figure 1, Source (2,1)
is not included in any subset T , so, in the solution, we
will include it as an orphan.

By deﬁning wT = − ln BT for every subset T , the ﬁnal
integer linear programming function can be written as
follows,

(cid:88)

min

wT xT

T
subject to xT ∈ Z and 0 ≤ xT ≤ 1 for all T,

(cid:88)

and

T (cid:51)(i,c)

xT ≤ 1 for all (i, c) ∈ D.

(10)

Note that the formulation above can be used to solve the
matching problem given any number of catalogs C but
requires an enumeration of all possible candidate asso-
ciations, which can be numerous. This requires calcula-
tions of combinatorially many wT and the introduction
of the corresponding xT binary variables, which quickly
becomes prohibitively expensive for many catalogs.

Shi et al. (2019) demonstrated their approach on three
catalogs with identical astrometric uncertainty. Here we
extend their work and describe a novel approach, which
can be eﬃciently used with many catalogs.

2.2. DirILP: Optimal Direct Associations

The key idea is to introduce variables that directly
assign the detections to hypothesized objects instead of
simply switching on and oﬀ some previously enumer-
ated candidate associations in the ﬁnal matched cata-
log. The objective (cid:81) Bo is the same but expressing it
with the new variables is signiﬁcantly more complicated
than before. In the process one needs to introduce sev-
eral additional (sets of) auxiliary variables to linearize
the problem. In case of homoscedasticity when all as-
trometric uncertainty are the same for all detections,
the linearization is relatively straightforward, but fur-
ther modeling tricks are required in the general setting.
In the following sections these two cases are introduced
along with the variables needed to model and solve the
global association problem. Further details are provided
in the appendix about the derivation of the general het-
eroscedastic formalism.

2.2.1. Homoscedasticity

For simplicity, we ﬁrst discuss the special case where
the astrometric uncertainty of each detection is the
same, i.e., σic = σ for each source (i, c). Given a data set
D, let N be the total number of detections in all cat-
alogs considered. The number of astronomical objects
these represent will be at most N , corresponding to the
hypothesis that every detection comes from a diﬀerent
object. Our goal is to ﬁnd a mapping that matches each

4

Catalog 1

Source (1,1)

{(1,1),(1,2)}

{(2,1),(1,2)}

{(1,1),(1,3)}

{(2,1),(1,3)}

{(1,1),(2,3)}

{(2,1),(2,3)}

{(1,2),(1,3)}

{(1,2),(2,3)}

{(1,1),(1,2),(1,3)}

{(1,1),(1,2),(2,3)}

{(2,1),(1,2),(1,3)}

{(2,1),(1,2),(2,3)}

Source (2,1)

Catalog 2

Source (1,2)

Catalog 3

Source (1,3)

Source (2,3)

Figure 1. An illustration of CanILP. As can be seen on the left side, we assume there are 2 detections from Catalog 1 (Sources
(1,1) and (2,1)), 1 detection from Catalog 2 (Source (1,2)) and 2 detections from Catalog 3 (Sources (1,3) and (2,3)). In
CanILP, we list all candidates for possible associations across independent detections, which are shown on the right side. These
are the xT in the formulation. We then ﬁnd the combinations of subsets that maximize the overall likelihood. Here, the solution
given by CanILP indicates that the subsets {(1, 1), (2, 3)} and {(1, 2), (1, 3)} are included in the partition. These subsets, which
are represented by a green color, correspond to the variables x{(1,1),(2,3)} = x{(1,2),(1,3)} = 1 in the model. On the other hand,
all other variables xT = 0. Notice that because Source (2,1) does not appear in any of these subsets, so we treat it as an
orphan. As a result, the association outputted by CanILP is {{(1, 1), (2, 3)}, {(1, 2), (1, 3)}, {(2, 1)}}.

source to one (and only one) object. This association
between a source and an object means that the source
is an observation of that object in the sky. Naturally,
multiple sources are expected to be assigned to the same
object, which represents the hypothesis that all of these
sources are observations of that same object. To capture
the matching between a source (i, c) and an object o, we
introduce binary variables {xo
ic = 1
if the (i, c) detection is associated with object o, and 0
otherwise.

ic}, where a given xo

Figure 2 illustrates how this approach works. For ex-
ample, the arrow from Source (2,1) to Object 1 rep-
resenting an association means that x1
21 = 1. Similarly,
x3
11 = 0 means no association, hence there is no arrow
between the corresponding entries. A partition P can
now be represented as a set {So : o = 1, . . . , N }, where

So is the subset of sources assigned to o, i.e.,

So := {(i, c) : xo

ic = 1} .

(11)

If, for a given index o, xo
ic = 0 for all (i, c) sources, then
So = ∅ is empty, which means object o is not needed for
that particular partition.

Recall that the goal is to maximize the product of
Bayes factors (cid:81) Bo (or to minimize − (cid:80) ln Bo) corre-
sponding to these associations. Given an association
So, assuming κic = κ for all source (i, c), eq. (6) gives
us

Bo = 2|So|−1

(cid:81)
(cid:80)

ic κ
ic κ
= 2|So|−1 κ|So|
|So|κ

(cid:32)

exp

−

(cid:80)

ic

κ (cid:80)

(cid:32)

−

ic

exp

(cid:33)

ic,i(cid:48)c(cid:48)

(cid:80)
i(cid:48)c(cid:48) κ2ψ2
4 (cid:80)
ic κ
(cid:80)
i(cid:48)c(cid:48) ψ2

4|So|

(cid:33)

ic,i(cid:48)c(cid:48)

(12)

(13)

Catalog 1

Catalog 2

Catalog 3

Source (1,1)

Source (2,1)

Source (1,2)

Object 1

Object 2

Object 3

Object 4

Source (1,3)

Object 5

Source (2,3)

Figure 2. An illustration of DirILP. As in Figure 1, assume
there are 2 detections from Catalog 1 (Sources (1,1) and
(2,1)), 1 detection from Catalog 2 (Source (1,2)) and 2
detections from Catalog 3 (Sources (1,3) and (2,3)). In
this case, the output of DirILP indicates that Sources (1,1)
and (2,3) belong to the same object, that Sources (1,2)
and (1,3) belong to the same object, and that Source (2,1)
is an orphan. Notice that it is okay for an object to not have
any source associated with it. The solution given by DirILP
is {{(1, 1), (2, 3)}, {(1, 2), (1, 3)}, {(2, 1)}}, which is the same
as the one given by CanILP in Figure 1.

Hence,

− ln Bo = ln(2κ) (1 − |So|) + ln |So| +

κ (cid:80) ψ2
4|So|

ic,i(cid:48)c(cid:48)

(14)

We want to ﬁnd the partition P that minimizes
− (cid:80) ln Bo. Notice that as of now, there are still sev-
eral non-linear terms in − ln Bo so it is not yet a linear
objective. To make use of ILP method, we will ﬁrst need
to rewrite this as a linear function. To do that, we in-
troduce the following variables, deﬁned for each index
k ∈ {0, . . . , C}, with C representing the total number of
catalogs:

zo
k =






xo
ic = k

1

if (cid:80)
ic
0 otherwise

5

This variable captures the number of sources getting
matched to object o, or the cardinality of the subset So.
When zo(cid:48)
k(cid:48) = 1, there are k(cid:48) hypothesized observations of
object o(cid:48) in the data. In addition, notice that at most 1
of the zo

k, k = 0, . . . , C can be 1. We also introduce

yo
ic,i(cid:48)c(cid:48) =

(cid:40)
1

0

ic = xo
if xo
otherwise

i(cid:48)c(cid:48) = 1

(16)

This is an indicator variable that checks whether the
sources (i, c) and (i(cid:48), c(cid:48)) belong to the same object o.
In particular, yo(cid:48)
ic,i(cid:48)c(cid:48) = 1 indicates the hypothesis that
sources (i, c) and (i(cid:48), c(cid:48)) are observations of object o(cid:48). We
also have

(cid:40) (cid:80) κψ2

ic,i(cid:48) c(cid:48) yo
4k

ic,i(cid:48) c(cid:48)

to =

0

if zo
if zo

k = 1 for some k ∈ [C]
0 = 1

(17)
where [C] represents the set of numbers {1, 2, · · · , C}.
This variable captures the last term in − ln Bo for a
subset So. In particular, when zo
k = 1 for some k ∈ [C],
i.e. |So| = k by deﬁnition of zo
(cid:80) κ ψ2
4|So|

k, we have

to =

(18)

ic,i(cid:48)c(cid:48)

as desired, where the summation goes over all (i, c) and
(i(cid:48), c(cid:48)) in So. On the other hand, when zo
0 = 1, no de-
tection is assigned to object o, so this term should con-
tribute nothing to the objective function. Next, we in-
troduce
(cid:40)

(1 − k) ln(2κ)

if zo
if zo

k = 1 for some k ∈ [C]
0 = 1

.

po =

0

(19)
This variable captures the ﬁrst term in − ln Bo for a
subset So. It plays a similar role as to, i.e., when zo
0 = 1,
no detection is assigned to object o, so this term should
contribute nothing to the objective function. On the
other hand, if some sources are matched to object o,
po = ln(2κ)(1 − |So|) as desired.

Finally, we will linearize the term ln|So| by breaking
the natural log function into ﬁnitely many aﬃne lin-
ear pieces. We ﬁrst introduce constants a1, a2, · · · , aC,
where a1 = 0 and ap = ln(p)−ln(p−1), for p = 2, · · · , C.
Then for each object o, we deﬁne binary variables
wo

C and impose the constraint that

2 ≥ · · · ≥ wo

1 ≥ wo

C
(cid:88)

p=1

wo

p =

(cid:88)

ic

xo
ic = |So|.

(20)

(15)

Using the new notation, we can now express ln|So| as a
p: ln |So| = (cid:80)C
linear function of wo
p. To explain

p=1 apwo

6

p=1 wo

why this is the case, it is best to work with an example.
Suppose 3 sources are matched with object o, so |So| = 3
and ln|So| = ln 3. Because (cid:80)C
p = |So| = 3 and wo
p
are 0/1 variables with wo
1 ≥ wo
C, we have
wo
2 = wo
1 = wo
C = 0.
Then, (cid:80)C
p=1 apwo
p = a1 + a2 + a3 = (0) + (ln 2 − ln 1) +
(ln 3 − ln 2) = ln 3, which is exactly ln|So|. Our objective
function now becomes
(cid:18)

3 = 1 and wo

5 = · · · = wo

2 ≥ · · · ≥ wo

4 = wo

(cid:19)

(cid:88)

min

(cid:88)

po +

apwo

p + to

,

(21)

o
which is linear in the variables po, wo

p

p and to.

As can be seen in the deﬁnitions of these variables,
there are certain relationships that still need to be mod-
eled using linear constraints. The full ILP formulation
is given in Appendix A with detailed explanations for
how the constraints model the relationships between the
variables xo

p, and to.

ic,i(cid:48)c(cid:48), zo

k, po, wo

ic, yo

2.2.2. Heteroscedasticity

We can also remove the assumption that every source
has the same measure of uncertainty κic. From eq. (6),
we have,

− ln Bo = (1 − |So|) ln 2 −

(cid:88)

ln κic + ln

(cid:88)

κic +

,

ic

ic

+

(cid:80)

(cid:80)

ic,i(cid:48)c(cid:48)

(22)

ic
i(cid:48)c(cid:48) κicκi(cid:48)c(cid:48)ψ2
4 (cid:80)
ic κic
where all the summations run over all (i, c) and (i(cid:48), c(cid:48))
in So. We use xo
ic,i(cid:48)c(cid:48) as deﬁned in the special
case of Section 2.2. We also introduce new variables to
convert eq. (22) into a linear function.

k, and yo

ic, zo

We ﬁrst linearize the term ln (cid:80) κic using the same
trick as when we linearized ln|So| in Section 2.2. We
introduce constants bmin ≡ b1, b2, b3, · · · , where

and

bmin = ln

(cid:18)

(cid:19)

min
ic∈D

κic

(cid:18)

bmax = ln

C max
ic∈D

κic

(cid:19)

.

Now, if we set an error threshold (cid:15), then the

R ≡

(cid:24) bmax − bmin
(cid:15)

(cid:25)

(23)

(24)

(25)

constants bp are deﬁned as

bp = bmin + (p − 1) × (cid:15)

for p = 1, . . . , R.

(26)

Then for each object o, we deﬁne binary variables
1 ≥ χo
χo

P and impose the constraint

2 ≥ · · · ≥ χo

χo

1 exp(b1) +

R
(cid:88)

p=2

χo

p [exp(bp) − exp(bp−1)] ≥

κicxo

ic .

(cid:88)

ic

(27)

Using the new variables, we have

(cid:88)

ln

ic

κic ≈ χo

1b1 +

R
(cid:88)

p=2

p(bp − bp−1) = χo
χo

1 bmin + (cid:15)

R
(cid:88)

p=2

χo
p

(28)

since bp − bp−1 = (cid:15) for all p ≥ 2.
To illustrate how the χo

κic

ic∈So

ln (cid:80)

1 = χo

p variables work, let us as-
sume that after looking at the data, we determine that
bmin = 29 and bmax = 33.
If we let (cid:15) = 0.5, then the
value of constants bp are {29, 29.5, · · · , 32.5, 33}. Now
suppose there are 3 sources that are matched to an
object o with associated κic values of 5 × 1012, 8 × 1012,
and 1013. Then the true value of
is
ln(2.3×1013), which evaluates to 30.77. With the deﬁned
variables, the solution given by ILP is χo
2 = · · · =
5 = 1 and χo
χo
6 = · · · = χo
1 exp(b1) +
(cid:80)P
p=2 χo
p(exp(bp) − exp(bp−1)) = exp(29) + exp(29.5) −
exp(29)+exp(30)−exp(29.5)+· · ·+exp(31)−exp(30.5) =
exp(31) > 2.3 × 1013, which satisﬁes the constraint
1 exp(b1) + (cid:80)P
χo
ic κicxo
p=2 χo
ic.
Notice that setting the variables χo
9 = 1 will also
satisfy the constraint. However, since we will model our
problem with a minimization objective, the optimal
solution will force χo
p(bp − bp−1) to be as
small as possible. Finally, notice that in this case the
value of χo
p(bp − bp−1), which is used to
approximate ln (cid:80)
κic, is 31, which is close to the
true value of 30.77.

p(exp(bp) − exp(bp−1)) ≥ (cid:80)

9 = 0 because χo

p=2 χo
ic∈So

1b1 + (cid:80)R

1b1 + (cid:80)R

6, · · · , χo

p=2 χo

Next, we will linearize the last term in eq. (22) by ﬁrst

introducing the constant

and

cmin = min
ic∈D

κic

cmax = C max
ic∈D

κic .

(29)

(30)

Then by rounding these two values to the nearest 100, we
can introduce grid points 0 ≡ c0, c1, c2, · · · , cQ, where c1
is the nearest 100 of cmin, cQ is the nearest 100 of cmax,
and for all i > 2, ci = c1 + 100(i − 1). We then introduce

uo
k =




1



0

if (cid:80)
ic

[κic]

100

xo
ic = ck

otherwise

(31)

where k ranges in {0, 1, . . . , Q} and the operator [·]100”
is deﬁned as rounding to the nearest 100. This variable
attempts to approximate (cid:80)
κic, which appears in
the denominator of the last term of eq. (22).

ic∈So

The variables po and to are also very similar to the
deﬁnitions in Section 2.2; however, we need to slightly
modify them as follows:

(cid:80)

ic

to =

(cid:80)

i(cid:48)c(cid:48) κicκi(cid:48)c(cid:48)ψ2
4ck

ic,i(cid:48)c(cid:48)yo

ic,i(cid:48)c(cid:48)

,

(32)

k = 1 for some k ∈ {1, 2, · · · , Q}, and to = 0 other-

if uo
wise.

The reasoning for deﬁning to this way is that if uo

0 = 1,

[κic]100xo

ic = c0 = 0.

(33)

(cid:88)

(i,c)

This happens only when xo
ic = 0 for all (i, c), i.e. no
sources are matched to object o. Hence, to should not
contribute to the objective function, hence the value of
0. On the other hand, if uo
k = 1 for some k > 0, by deﬁ-
nition of uk, ck is the best approximation to (cid:80)
κic.
Thus, (32) holds.

ic∈So

In addition, we modify po deﬁned in eq. (19) as follows,

po =

(cid:40)

(1 − k) ln(2)

0

if zo
if zo

k = 1 for some k ∈ [C]
0 = 1

.

(34)
This variable serves a similar function as in the ho-
moscedastic case, which is to capture the ﬁrst term in
eq. (22).

The objective function can now be written as

(cid:32)

(cid:88)

(cid:88)

po −

ic ln κic + χo
xo

1bmin + (cid:15)

o

ic

(cid:33)

p + to
χo

,

P
(cid:88)

p=2

(35)

which is linear in all the variables involved.

There are certain relationships that still need to be
modeled using linear constraints because ILP formula-
tions only take linear constraints. The full ILP formula-
tion is given in Appendix B, with detailed explanations
for how the constraints model the relationships between
k, χo
the variables xo

k, po, and to.

ic,i(cid:48)c(cid:48), zo

ic, yo

p, uo

3. MOCK OBJECTS AND SIMULATIONS

We consider the idealized case where all the catalogs
capture the same astronomical properties of objects in
the sky, i.e., they detect the same set of objects. As
we generate 100 objects and assume there are C dis-
tinct catalogs, we expect to see 100 × C sources and 100
C−way association sets. We will now show the catalog
matching results using both of our approaches. The ILP
programs in both approaches are solved using Gurobi,
an optimization solver Gurobi Optimization (2020).

3.1. Homoscedasticity: identical κic = 1/σ2
Observe that for the CanILP formulation in Section
2.1, we need to list all the possible valid subsets T ⊆ D.
We could do this by sequentially adding catalogs one
by one and considering sources from the new catalog.
However, this evaluates to 101C − 1 subsets, which is
exponential in terms of the number of catalogs C. Hence,

7

we ﬁrst try to reduce the number of possible subsets
by observing that sources that are far away cannot be
from the same object. So we can impose some distance
constraints on the sources that are put into the same
candidate association set.
In doing so, we should be
careful not to discard potentially true associations later
on because say two sources from the ﬁrst 2 catalogs that
are far away might not be a 2−way matching; but, if on
the third catalog, there is a source lying in the middle of
the path between these 2 sources, the 3 sources together
might be a 3−way matching.

That being said, this suggests an idea for dividing the
whole region of the sky that is of interest into diﬀerent
islands where the sources are clustered together so that
instead of solving one big problem, we could break it
into smaller problems and make use of parallel comput-
ing. Essentially, we ﬁrst apply a single-linkage clustering
algorithm to our dataset, which is done using the DB-
SCAN algorithm with parameters “min samples” = 2
and “eps” = 5 × maxic∈D σic. With the chosen parame-
ters, we are essentially performing the friends-of-friends
algorithm. It turns out that for our simulation, most of
these islands consist of only 1 source from each catalog.
Hence, from now on, we will show the result for this
scenario of having 1 source from each catalog. This sit-
uation is not peculiar to our simulation but is, in fact,
observed in real data sets from multiple visits of the
same part of the sky by the same telescope. Analysis for
the multiple sources per catalog will be discussed later.
As can be seen in Figure 3, even though we are able to
handle more than 3 catalogs, the maximum number of
catalogs we could analyze in a day is 20. Though, similar
to Shi et al. (2019), we do not include any pruning pro-
cedures, such as those described in Kunszt et al. (2001);
Gorski et al. (2005); Gray et al. (2007); Lee & Budav´ari
(2017). These pruning procedures might speed up the
matching, but from our experience the complexity of
the problem is still exponential in terms of the number
of catalogs. The next paragraph discusses how far we
could get using DirILP formulation.

DirILP formulation analysis. —The main drawback from
the previous approach is that the process of creating po-
tential subsets T is exponential in terms of the number
of catalogs. Even if we consider the island, the number
of nonempty subsets in such an island will still be 2C −1,
so creating the variables for the ILP takes a tremendous
amount of time.

DirILP formulation attempts to ﬁx that problem by
reducing the time complexity to create the variables for
the ILP to something that is polynomial in the total
number of sources. However, since this catalog matching
problem is intrinsically diﬃcult, we still have to tackle

8

the exponential complexity of the problem somewhere
else: this appears in the time needed to solve the ILP.
We believe that with advances in the ﬁeld of integer
linear programming, the Gurobi solver will be able to
solve this problem more eﬃciently. It turns out using
DirILP, we are able to tackle up to 60 catalogs. The
comparison for the total running time between CanILP
and DirILP is shown in Figure 3. In addition, we also
include the set up time and optimization time for each
formulation in Figures 4 and 5.

Figure 3. Total running time comparison between the two
formulations for the special case (Log Scale). Notice that
CanILP chokes when there are 20 catalogs.

Figure 5. Optimization time comparison between the two
formulations for the special case (Log Scale)

match the ground truth perfectly. Hence, there is no
diﬀerence in the accuracy of the matching between the
two approaches. They only diﬀer in their running time.

3.2. General case: diﬀerent κic for every detection

For the general case, both approaches still give all cor-
rect associations that match the ground truth. However,
as in the special case, DirILP is still more eﬃcient at
solving the matching problem than CanILP, as shown in
Figure 6. We should point out that even though in this
general setting, the optimal value found in DirILP is just
an approximation of the Bayes factor associated with the
ground-truth matching, the values are still quite close to
each other. More importantly, the associations obtained
from DirILP still match the ground-truth associations.
Figures 6 - 8 show the total running time, time to set up
the ILP, and time for Gurobi to solve the ILP, for both
CanILP and DirILP in this general case.

Figure 4. Set up time comparison between the two formu-
lations for the special case (Log Scale)

Moreover, by including some heuristic constraints,
such as imposing a time limit between incumbent so-
lutions, on the Gurobi solver, we are able to push the
DirILP further to handle 160 catalogs.

Finally, it is important to note that the associations
given by CanILP and DirILP are the same and they

Figure 6. Total running time comparison between the two
formulations for the general case (Log Scale). Notice that
CanILP chokes when there are 18 catalogs.

each catalog becomes larger. Figure 9 shows the total
running time for both CanILP and DirILP when there
are 2 detections from each catalog in an island.

9

Figure 9. Total Running time comparison between the two
formulations when there are 2 detections from each catalog
in an island (Log Scale)

3.4. Discussion of running time complexity

We now give a brief explanation for the shape of the
curves in Figures 3–8. For CanILP, since the number
of variables is exponential in terms of the number of
catalogs, under the log scale as in Figures 4 and 7, the
time to create these variables and set up the ILP as a
function of the number of catalogs is represented by a
straight line. On the other hand, for DirILP, we have a
curve with decreasing gradient instead of a straight line
because the number of variables and constraints in this
method is polynomial in the number of catalogs. The
explanation for the curves in Figures 5 and 8 are similar
because the amount of time to solve an ILP generally
depends on the number of variables and constraints in
the problem. That being said, the curves in these two
ﬁgures look more jagged because of other complexities
involved in the optimization procedure. Finally, as most
of the time to solve the catalog matching problem is
spent on setting up the ILP, the curves in Figures 3 and
6 are very much similar to their counterparts in Figures
4 and 7, respectively.

4. IMPLEMENTATION AND SOFTWARE

CanILP and DirILP algorithms are implemented in
several Jupyter notebooks. They share a common struc-
ture: In the ﬁrst part, we create a simulation with diﬀer-
ent catalogs and a number of mock objects on each of the
catalogs. Next, we perform the DBSCAN algorithm to
output diﬀerent islands, or clusters of detections. Again,
as mentioned in 3.1, with our chosen parameters, this is

Figure 7. Set up time comparison between the two formu-
lations for the general case (Log Scale)

Figure 8. Optimization time comparison between the two
formulations for the general case (Log Scale)

3.3. Multiple sources per catalog in each island

Recall that in the previous sections, we assume that
in each island there is only one detection from each cat-
alog, which is a reasonable assumption in many real-life
situations. In this section, we would like to discuss sce-
narios when the uncertainty σic is large or the source
density is very high. These scenarios will result in is-
lands where there might be multiple detections from
each catalog in an island. It turns out that in our simu-
lation, CanILP and DirILP still give the correct associ-
ation under this scenario. However, both methods run
much slower than in the previous scenario and are able
to handle only about half as many catalogs with the
same settings on the algorithms. We give an example
of the running time for the 2 methods when there are
2 detections from each catalog. One can see how much
worse it can get when the number of detections from

10

similar to executing a friends-of-friends algorithm. The
reason we pick DBSCAN is because of its well-developed
library in Python.

After running the clustering algorithm, we implement
CanILP and DirILP to solve the catalog matching prob-
lem in each island. The optimization problems in these
modules were solved using Gurobi software Gurobi Op-
timization (2020).

In addition, we employ several (optional) heuristics in
the DirILP algorithm to speed up the catalog match-
ing procedure. First, any 2 sources that are more
than 8σ away from each other, we force them to be-
long to separate objects. Second, for sources that are
0.1σ away from each other, we restrict them to be-
long to the same object. Finally, we set an MIP Gap
(optimality gap) of 0.5% to prevent Gurobi from tak-
ing too long to verify optimality. Through our experi-
ments, we have found that running the algorithm with
these heuristics give the same results but it was 10
times faster. The notebooks can be found on Github
at https://github.com/tunguyen52/Nway-matching.

5. SUMMARY AND FUTURE WORK

We have shown how the CanILP approach of Shi et al.
(2019) and the new DirILP solve for a globally opti-
mal matched catalog in crowded ﬁelds where a greedy
approach is not suﬃcient. The former enumerates the
candidate associations and picks the optimal combina-
tion of those; the latter introduces variables to directly
assign sources to objects. The new DirILP formulation
is superior in the sense that it scales to large number
of catalogs better, i.e., produces results in less time.
The method comes at a price, which is in complexity
of the algorithm, especially in case of heteroscedasticity
when the catalogs have diﬀerent astrometric uncertainty.

In fact DirILP only out-performs the previous method
when many catalogs are to be crossmatched. We rec-
ommend the simpler CanILP approach for small num-
ber of catalogs, where the combinatorial explosion is not
as severe. In our experiments, this crossover threshold
appears to be at around 12 visits or catalogs, beyond
which the DirILP method gets faster.

Both of these methods optimize the same objective
and yield the best possible catalog matching result in a
likelihood sense. No prior on the partition is imposed
currently in our study and the accompanying software.
While placing priors on the partition might seem com-
plicated, certain simple priors can be easily expressed,
such as those that depend only the number of objects
in the matched catalog. This is a possible direction to
explore in the future.

Additional future work includes testing the software
and its performance on imaging surveys, such as multi-
ple visits of the Hyper Suprime-Cam Subaru Strategic
Program, whose data collection resembles future obser-
vations of the LSST.

1

2

3

4

5

6

7

8

9

10

11

12

This material is based upon work supported by the Na-
tional Science Foundation under Grant No. 1909709,
1814778, 1452820 and 1934979. T.B. gratefully acknowl-
edges the aforementioned AST/AAG grants from NSF
and funding from NASA via awards STScI-49721 and
STScI-52333 under NAS5-26555. T.N. and A.B. grate-
fully acknowledge support from the aforementioned NSF
grant and ONR grant N000141812096. A.B. is also
grateful for support from the aforementioned NSF grant
and AFOSR grant FA95502010341. The authors thank
the anonymous referee for the careful review and the
thoughtful comments.

APPENDIX

The ILP Formulation for DirILP when κic = 1
The objective function we want to minimize is given by

σ2 for every source (i, c) is given below.

A. DIRILP FORMULATION - SPECIAL CASE

(cid:18)

(cid:88)

min

(cid:88)

po +

apwo

p + to

(cid:19)

o

p

The following constraints restrict xo

ic, yo

ic,i(cid:48)c(cid:48), zo

k, wo

p to binary variables and to to have non-negative values.

ic, yo
xo

ic,i(cid:48)c(cid:48), zo

k, wo

p ∈ Z and 0 ≤ xo

ic, yo

ic,i(cid:48)c(cid:48), zo

k, wo

p ≤ 1, 0 ≤ to, ∀(i, c), k, p, o.

The next equation ensures that all sources (i, c) need to belong to exactly one subset:

(cid:88)

o

xo
ic = 1, ∀(i, c)

(A1)

(A2)

(A3)

The following equation imposes that every subset takes no more than 1 source from each catalog.

xo
ic ≤ 1, ∀o ∈ {1, 2, ..., N }, ∀c ∈ {1, . . . , C}

(cid:88)

i

11

(A4)

The following set of constraints on yo
i(cid:48)c(cid:48) = 1:

ic,i(cid:48)c(cid:48) = 1 only if xo

ic = xo

requires yo

ic,i(cid:48)c(cid:48) is an implementation of the deﬁnition of yo

ic,i(cid:48)c(cid:48) in Section 2.2, which

ic + xo
ic,i(cid:48)c(cid:48) ≥ xo
yo
i(cid:48)c(cid:48) − 1,
ic,i(cid:48)c(cid:48) ≤ xo
yo
ic,
ic,i(cid:48)c(cid:48) ≤ xo
yo
i(cid:48)c(cid:48),

(A5)

(A6)

(A7)

for all (i, c) (cid:54)= (i(cid:48), c(cid:48)) and ∀o.

Since the cardinality of any subset from a partition P is between 0 and C, the following equation states that only 1

of zo

k can take a value of 1.

C
(cid:88)

k=0

zo
k = 1, ∀o,

The next constraint is the deﬁnition of wo

p as described in Section 2.2.

wo

1 ≥ wo

2 ≥ · · · ≥ wo

C and

C
(cid:88)

p=1

wo

p =

(cid:88)

ic

xo
ic, ∀o,

(A8)

(A9)

With the speciﬁc choice of the constant M as deﬁned below, the equation that follows becomes redundant when
zo
k = 0 since the RHS will be negative and so to ≥ 0 becomes the enforcing constraint, and when zo
k = 1, the
minimization forces to to be equal to the ﬁrst term of the RHS.

(cid:80) κψ2

ic,i(cid:48)c(cid:48)yo
4k

ic,i(cid:48)c(cid:48)

to ≥

κψ2
ic,i(cid:48) c(cid:48)
4

(cid:25)
.

− (1 − zo

k)M, ∀o and k ∈ {1, 2, · · · , C},

(A10)

(cid:24)

where M =

(cid:80)
ic,i(cid:48)c(cid:48)∈D

The following set of equations constitutes the deﬁnition of zo
k.

ic ≤ kzo
xo

k + C(1 − zo
k)

(cid:88)

ic

ic ≥ kzo
xo
k,

(cid:88)

ic

for all k ∈ {0, 1, 2, · · · , C} and for all o.

Finally, the last equation

po ≥ ln(2κ)(1 −

(cid:88)

wo

p) − ln(2κ)zo

0, ∀o,

(A11)

(A12)

(A13)

p
ensures that for an empty subset So, po = 0, hence contributing nothing to the objective. This is because when zo
(nothing is assigned to subset So), wo
be set to 0. On the other hand, when zo
minimizing, po will equal this value.

0 = 1
p = 0, ∀p. As we are minimizing the objective function with respect to po, po will
p) and again, since we are

0 = 0, the constraint becomes po ≥ ln(2κ)(1 − (cid:80)

p wo

B. DIRILP FORMULATION - GENERAL CASE

Below, we give the ILP Formulation for DirILP when κic is diﬀerent for distinct sources (i, c). Some of these
constraints are similar to the special case so we will only give explanations for the new constraints, which are shown
after the ILP formulation. We follow the notation introduced in Section 2.2.2.
In particular, recall the constants
c0, c1, . . . , cQ designed to model, up to the nearest 100, the sum of subsets of uncertainties κic, the associated decision
variables uo

P to model the logarithms of such sums.

k and the decision variables χo

12

The objective in the general case is

(cid:18)

(cid:88)

min

(cid:88)

po −

o

ic

ic ln κic + χo
xo

1bmin + (cid:15)

(cid:19)

p + to
χo

R
(cid:88)

p=2

(B14)

As in the special case, the following constraints on the variables restrict xo

ic, yo

ic,i(cid:48)c(cid:48), zo

k to binary variables and to to

have non-negative values. Additionally, the new variables χo

p, uo

k are also restricted to binary values.

ic, yo
xo

ic,i(cid:48)c(cid:48), zo

k, χo

p, uo

k ∈ Z and 0 ≤ xo

ic, yo

ic,i(cid:48)c(cid:48), zo

k, χo

p, uo

k ≤ 1, 0 ≤ to.

Next, constraints (A3)–(A8) and (A11)–(A12) are included verbatim.

The following impose the conditions required on χo

p as described in Section 2.2.2.

1 ≥ χo
χo

2 ≥ · · · ≥ χo

R and χo

1 exp(b1) +

R
(cid:88)

p=2

χo

p(exp(bp) − exp(bp−1)) ≥

κicxo

ic, ∀o.

(cid:88)

ic

(B15)

The next set of constraints ensure that the value of (cid:80)

ic∈So

κic will be approximately equal to ck (up to the nearest

100) for some k ∈ {0, 1, 2, · · · Q}.

Q
(cid:88)

k=0

uo
k = 1, ∀o,

(cid:80)
(cid:80)

ic[κic]100xo
ic[κic]100xo

ic ≤ ckuo
ic ≥ ckuo
k

k + M (cid:48)(1 − uo
k)

, ∀k ∈ {0, 1, 2, · · · , Q} and ∀o.

where M (cid:48) = C maxic∈D κic.

Finally, the last set of constraints tie everything back into the objective function (B14).

(cid:80)

ic

to ≥

(cid:80)

ic,i(cid:48)c(cid:48)yo

i(cid:48)c(cid:48) κicκi(cid:48)c(cid:48)ψ2
4ck
po ≥ (1 −

ic,i(cid:48)c(cid:48)

− (1 − uo

k)M, ∀o and k ∈ {1, 2, · · · , Q},

(B16)

(B17)

(B18)

(B19)

where M =

(cid:38) maxic∈D κ2

ic

(cid:80)
ic,i(cid:48) c(cid:48)∈D
4 minic∈D κic

ψ2

ic,i(cid:48) c(cid:48)

(cid:39)
.

(cid:88)

ic∈So

ic) ln 2 − zo
xo

0 ln 2, ∀o.

REFERENCES

Boch, T., Pineau, F., & Derriere, S. 2012, in Astronomical

Budav´ari, T., & Loredo, T. J. 2015, Annual Review of

Society of the Paciﬁc Conference Series, Vol. 461,

Statistics and Its Application, 2, 113–139,

Astronomical Data Analysis Software and Systems XXI,

doi: 10.1146/annurev-statistics-010814-020231

ed. P. Ballester, D. Egret, & N. P. F. Lorente, 291

Budav´ari, T., & Szalay, A. S. 2008, The Astrophysical

Budav´ari, T., & Basu, A. 2016, The Astronomical Journal,

Journal, 679, 301–309, doi: 10.1086/587156

152, 86, doi: 10.3847/0004-6256/152/4/86

Fisher, R. 1953, Proceedings of the Royal Society of

Budav´ari, T., Dobos, L., & Szalay, A. S. 2013, Computing

London Series A, doi: 10.1098/rspa.1953.0064

in Science Engineering, 15, 12,

doi: 10.1109/MCSE.2013.41

Gorski, K. M., Hivon, E., Banday, A. J., et al. 2005, The

Astrophysical Journal, 622, 759, doi: 10.1086/427976

13

Gray, J., Nieto-Santisteban, M. A., & Szalay, A. S. 2007,

Pineau, F.-X., Derriere, S., Motch, C., et al. 2017,

CoRR, abs/cs/0701171.
https://arxiv.org/abs/cs/0701171

Gurobi Optimization, L. 2020, Gurobi Optimizer Reference

Manual. http://www.gurobi.com

Kunszt, P. Z., Szalay, A. S., & Thakar, A. R. 2001, in
Mining the Sky, ed. A. J. Banday, S. Zaroubi, &
M. Bartelmann (Berlin, Heidelberg: Springer Berlin
Heidelberg), 631–637

Lee, M., & Budav´ari, T. 2017, Astronomy and Computing,
20, 155, doi: https://doi.org/10.1016/j.ascom.2017.08.001
Munkres, J. 1957, Journal of the Society for Industrial and

Applied Mathematics, 5

Pineau, F.-X., Motch, C., Carrera, F., et al. 2011,

Astronomy & Astrophysics, 527, A126,
doi: 10.1051/0004-6361/201015141

Astronomy & Astrophysics, 597, A89,

doi: 10.1051/0004-6361/201629219

Shi, X., Budav´ari, T., & Basu, A. 2019, The Astrophysical

Journal, 870, 51, doi: 10.3847/1538-4357/aaf00a

Taghizadeh-Popp, M., Kim, J., Lemson, G., et al. 2020,

Astronomy and Computing, 33, 100412,

doi: https://doi.org/10.1016/j.ascom.2020.100412

Taylor, M. B. 2005, in Astronomical Society of the Paciﬁc

Conference Series, Vol. 347, Astronomical Data Analysis

Software and Systems XIV, ed. P. Shopbell, M. Britton,

& R. Ebert, 29

