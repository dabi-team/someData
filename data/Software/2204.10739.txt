Received: Added at production

Revised: Added at production

Accepted: Added at production

DOI: xxx/xxxx

RESEARCH ARTICLE

Group sequential methods for interim monitoring of randomized
clinical trials with time-lagged outcome

Anastasios A. Tsiatis | Marie Davidian*

1Department of Statistics, North Carolina
State University, North Carolina, USA

Summary

Correspondence
*Marie Davidian, Department of Statistics,
North Carolina State University, Raleigh,
NC 27695-8203, USA. Email:
davidian@ncsu.edu

The primary analysis in two-arm clinical trials usually involves inference on a
scalar treatment eﬀect parameter; e.g., depending on the outcome, the diﬀerence of

treatment-speciﬁc means, risk diﬀerence, risk ratio, or odds ratio. Most clinical trials
are monitored for the possibility of early stopping. Because ordinarily the outcome

on any given subject can be ascertained only after some time lag, at the time of an
interim analysis, among the subjects already enrolled, the outcome is known for only

a subset and is eﬀectively censored for those who have not been enrolled suﬃciently
long for it to be observed. Typically, the interim analysis is based only on the data

from subjects for whom the outcome has been ascertained. A goal of an interim anal-
ysis is to stop the trial as soon as the evidence is strong enough to do so, suggesting

that the analysis ideally should make the most eﬃcient use of all available data, thus
including information on censoring as well as other baseline and time-dependent

covariates in a principled way. A general group sequential framework is proposed

for clinical trials with a time-lagged outcome. Treatment eﬀect estimators that take
account of censoring and incorporate covariate information at an interim analysis are

derived using semiparametric theory and are demonstrated to lead to stronger evi-
dence for early stopping than standard approaches. The associated test statistics are

shown to have the independent increments structure, so that standard software can
be used to obtain stopping boundaries.

KEYWORDS:
augmented inverse probability weighting, early stopping, inﬂuence function, proportion of information

2
2
0
2

r
p
A
2
2

]
E
M

.
t
a
t
s
[

1
v
9
3
7
0
1
.
4
0
2
2
:
v
i
X
r
a

1

INTRODUCTION

In many randomized clinical trials, the primary analysis involves a comparison of two treatments, typically an active or experi-
mental agent versus a control, which is formalized as inference on a scalar treatment eﬀect parameter. When the primary outcome
is a continuous measure, this parameter is usually the diﬀerence of treatment-speciﬁc means. For a binary outcome, the treatment
eﬀect parameter may be the risk diﬀerence, risk ratio, or odds ratio; and the odds ratio under the assumption of a proportional
odds model is often the treatment eﬀect parameter of interest in trials involving an ordinal categorical outcome. The primary
analysis is ordinarily based on a test statistic constructed using an estimator for the parameter of interest, e.g., the diﬀerence of
sample means or maximum likelihood (ML) estimator for the odds ratio in a proportional odds model. The overall sample size

 
 
 
 
 
 
2

TSIATIS and DAVIDIAN

is established so that the power to detect a clinically meaningful departure from the hypothesis of no treatment eﬀect at a given
level of signiﬁcance using the test statistic at the ﬁnal analysis achieves some desired value, e.g., 90%.

Most later-stage clinical trials are monitored for the possibility of early stopping for eﬃcacy or futility by a data and safety
monitoring board (DSMB), with interim analyses planned at either ﬁxed, predetermined analysis times or when speciﬁed pro-
portions of the total “statistical information” to be gained from the completed trial have accrued 1. Ordinarily, at the time of an
interim analysis, the test statistic to be used for the ﬁnal analysis is computed based on the available data and compared to a
suitable stopping boundary constructed to preserve the overall operating characteristics of the trial 2,3.

Because of staggered entry into the trial, the data available at the time of an interim analysis are from subjects who have
already enrolled. Moreover, the primary outcome 𝑌 is ordinarily not known immediately but is ascertained after some lag time
𝑇 , say. In some trials, the lag time 𝑇 is the same for all participants, as in the case where 𝑌 is a continuous outcome that will be
measured at a prespeciﬁed follow-up time 𝐹 , e.g., 𝐹 = one year, so that 𝑇 = 𝐹 for all subjects, and the treatment parameter is
the diﬀerence in treatment means of 𝑌 at one year. Here, at the time of an interim analysis, 𝑌 will be available only for subjects
enrolled for at least one year, so that the analysis can be based only on the data for these subjects.

In other settings, the time lag 𝑇 may be diﬀerent for diﬀerent participants, as is the case in many clinical trials of COVID-
19 therapeutics conducted by the Accelerating COVID-19 Therapeutic Interventions and Vaccines (ACTIV) public-private
partnership. In an ongoing clinical trial coordinated through the ACTIV-3b: Therapeutics for Severely Ill Inpatients with COVID-
19 (TESICO) master protocol 4, patients hospitalized with acute respiratory distress syndrome are randomized to receive an
active agent or placebo and followed for up to 𝐹 = 90 days. The primary outcome 𝑌 is an ordinal categorical variable with six
levels. The ﬁrst ﬁve categories reﬂect a subject’s status at 90 days following enrollment: 1, at home and oﬀ oxygen for at least
77 days (the most favorable category); 2, at home and oﬀ oxygen for at least 49 but no more than 76 days; 3, at home and oﬀ
oxygen for at least 1 but no more than 48 days; 4, not hospitalized and either at home on oxygen or receiving care elsewhere; and
5, still hospitalized or in hospice care. Category 6 (the worst) corresponds to death within the 90 day follow-up period. While
Categories 1-5 cannot be ascertained until a subject has been followed for the full 90 days, that a subject’s outcome is Category
6 is known at the time of death. Thus, the time lag before ascertainment is 𝑇 = 𝐹 = 90 days for subjects with 𝑌 = 1, … , 5 and
is equal to the (random) time of death 𝑇 ≤ 𝐹 = 90 for those with 𝑌 = 6. In TESICO, the treatment eﬀect parameter is the odds
ratio for active agent relative to placebo under an assumed proportional odds model. Similarly, in a clinical trial coordinated
through the ACTIV-2: A Study for Outpatients With COVID-19 master protocol (Study A5401) 5, subjects within seven days
of self-reported COVID-19 onset are randomized to receive an active agent or placebo and followed for up to 𝐹 = 28 days for
the binary outcome 𝑌 , where 𝑌 = 1 if the subject dies or is or hospitalized within 28 days and 𝑌 = 0 otherwise. For subjects
who die or are hospitalized at time 𝑇 prior to 28 days, 𝑌 = 1 is ascertained after a time lag 𝑇 ≤ 𝐹 = 28, whereas that 𝑌 = 0
can be ascertained only after the full 28 days, and 𝑇 = 𝐹 = 28. Here, the treatment parameter is the relative risk (risk ratio) of
hospitalization/death for active agent versus placebo.

At the time of an interim analysis in TESICO and A5401, the available data include the outcomes for all enrolled subjects
who have been followed for at least 90 and 28 days, so for whom 𝑇 = 𝐹 = 90 or 28, respectively, along with the outcomes for
enrolled subjects who do not have 90 or 28 days of follow up but have already been observed to die (𝑌 = 6) in TESICO or to be
hospitalized or die (𝑌 = 1) in A5401 (𝑇 ≤ 𝐹 = 90 or 28). Thus, information on Category 6 in TESICO will accumulate more
rapidly than that on the other categories; similarly, information on hospitalization/death in A5401 will accrue more quickly than
information on subjects who remain alive and unhospitalized at day 28. Intuitively, basing an interim analysis on all observed
outcomes will naively overrepresent 𝑌 = 6 and 𝑌 = 1 and lead to potentially biased inference on the treatment eﬀect parameters.
To characterize this issue more precisely, if 𝐶 is the time from a subject’s entry into the study to the time of an interim
analysis, then 𝑌 is known at the time of an interim analysis if 𝐶 > 𝑇 . Otherwise, the ascertainment time 𝑇 is censored at 𝐶
and 𝑌 is not observed. Basing the analysis on all subjects with 𝐶 > 𝑇 without taking appropriate account of the fact that 𝑌 is
not available for those with 𝐶 ≤ 𝑇 leads to the bias noted above. These considerations suggest that a valid interim analysis can
be obtained by using only the data from enrolled subjects followed for the full, maximum follow-up period 𝐹 , i.e., for whom
𝐶 ≥ 𝐹 . In studies like those above involving a continuous outcome or ordinal categorical outcome, as in TESICO, the standard
interim analysis is based on the estimator to be used at the ﬁnal analysis using only the data on subjects with 𝐶 ≥ 𝐹 , as there
is no apparent general approach to “adjusting” for the censoring. In the case of a binary outcome as in A5401, the standard
interim analysis does use the information on censoring; e.g., if the treatment eﬀect is the risk ratio, the estimator is the ratio of
the treatment-speciﬁc Kaplan-Meier estimators for the probability of death or hospitalization at 𝐹 = 28 days.

A goal of an interim analysis is to stop the trial as early as possible if there is suﬃciently strong evidence to do so. It is thus
natural to consider whether or not it is possible to make more eﬃcient use of the available data at the time of an interim analysis

TSIATIS and DAVIDIAN

3

to enhance precision and thus the strength of the evidence for stopping. One step toward increasing eﬃciency of interim analyses
would be a general approach to accounting for censoring for any outcome and treatment eﬀect parameter to allow incorporation
of partial information; e.g., in TESICO, a subject who is at day 45 since study entry and still in the hospital at the time of an
analysis, so for whom 𝐶 = 45 < 𝐹 = 90, can end up only in Categories 3–6, so have 𝑌 = 3, 4, 5, or 6, at 90 days. In addition,
there may be baseline covariates as well as intermediate measures of the outcome or other post-treatment variables that could
be exploited to increase precision at an interim analysis.

In this article, we propose a general group sequential framework for clinical trials with a possibly censored, time-lagged
outcome, which leads to practical strategies for interim monitoring. Treatment eﬀect estimators are proposed via application of
semiparametric theory 6,7, which dictates how censoring can be taken into account and baseline and time-dependent covariate
information can be exploited in a principled way to increase precision and thus yield stronger evidence for early stopping.
Estimation of the risk ratio via treatment-speciﬁc Kaplan-Meier estimators as described above emerges as a simple special case,
which can be improved upon through incorporation of covariates. We show that the test statistics based on these estimators have
an independent increments structure 8, which allows standard software for constructing stopping boundaries 2,3,9 to be used. Two
interim monitoring strategies are discussed: an information-based monitoring approach under which the trial will continue, with
possibly a larger sample size than originally planned, until the full, target statistical information accrues; and a ﬁxed-sample
size approach appropriate in settings where the planned sample size cannot be increased due to resource and other constraints.
We focus on the common case of two treatments; extension of the developments to more than two treatments is possible 10 and
could be adapted to group sequential methods for multi-arm trials 11,12.

In Section 2 we introduce the basic statistical framework and assumptions, and we sketch the estimation approach and state
the independent increments property in Section 3. In Section 4, we describe practical implementation of the resulting approach
to interim monitoring. We demonstrate the performance of the methods in a series of simulation studies in Section 5, and we
present a case study exemplifying the use of the methods for a simulated trial based on TESICO. Technical details and sketches
of proofs of results are given in the Appendix.

2

STATISTICAL FRAMEWORK

2.1 General model

As in Section 1, denote the outcome by 𝑌 . Let 𝐴 denote the treatment indicator, where 𝐴 = 0 (1) corresponds to control
(active/experimental treatment), and 𝜋 = pr(𝐴 = 1) is the probability of being assigned to active treatment; and let 𝑋 be a vector
of baseline covariates. Treatment eﬀects are often characterized in terms of a model for (features of) the distribution of (𝑌 , 𝐴)
or (𝑌 , 𝐴, 𝑋), which involves parameters (𝛼𝑇 , 𝛽), where 𝛽 is the scalar treatment eﬀect parameter of interest and 𝛼 is a vector of
nuisance parameters, and the model is parameterized such that 𝛽 = 0 corresponds to the null hypothesis of no treatment eﬀect.

In the case of the ﬁrst example in Section 1 of continuous 𝑌 , 𝛽 = 𝐸(𝑌

𝐴 = 1) − 𝐸(𝑌

𝐴 = 0); equivalently,

For an ordinal categorical outcome with 𝑐 categories, as in TESICO with 𝑐 = 6, the outcome can be represented as either a
scalar random variable 𝑌 taking values 1, … , 𝑐 or a random vector 𝑌 = {𝐼(𝐶𝑎𝑡 = 1), … , 𝐼(𝐶𝑎𝑡 = 𝑐 − 1)}, where 𝐶𝑎𝑡 takes
values 1, … , 𝑐. Using the ﬁrst deﬁnition, the treatment eﬀect can be deﬁned through an assumed proportional odds model

|

𝐸(𝑌

𝐴 = 𝑎) = 𝛼 + 𝛽𝑎,

𝑎 = 0, 1.
|

|

(1)

logit{pr(𝑌 ≤ 𝑗

𝐴 = 𝑎)} = 𝛼𝑗 + 𝛽𝑎,

𝑗 = 1, … , 𝑐 − 1,

𝛼 = (𝛼1, … , 𝛼𝑐−1)𝑇 ,

𝑎 = 0, 1,

(2)

where logit(𝑝) = log{𝑝∕(1 − 𝑝)}, so that 𝛽 is the log odds ratio of interest. If the conditional (on 𝑋) treatment eﬀect is of interest,
𝑋 = 𝑥, 𝐴 = 𝑎)} = 𝛼𝑗 + 𝛽𝑎 + 𝜉𝑇 𝑥, where now 𝛼 = (𝛼1, … , 𝛼𝑐−1, 𝜉𝑇 )𝑇 . If 𝑌 is binary as in A5401
replace (2) by logit{pr(𝑌 ≤ 𝑗
and the relative risk (risk ratio) pr(𝑌 = 1

𝐴 = 0) is the focus, taking

𝐴 = 1)∕pr(𝑌 = 1

|

|

corresponds to log relative risk 𝛽.

𝐸(𝑌

𝐴 = 𝑎) = exp(𝛼 + 𝛽𝑎),
|

|

𝑎 = 0, 1,

(3)

In general, estimators for the parameter of interest 𝛽 in (1)-(3) and other models based on the data available at the ﬁnal analysis,
at which time (𝑌 , 𝐴, 𝑋) are known for all 𝑛 participants, are obtained by solving, jointly in 𝛼 and 𝛽, appropriate estimating
equations. Namely, with independent and identically distributed (iid) data (𝑌𝑖, 𝐴𝑖, 𝑋𝑖), 𝑖 = 1, … , 𝑛, available, and 𝑝 equal to the

|

4

TSIATIS and DAVIDIAN

dimension of (𝛼𝑇 , 𝛽)𝑇 , ̂𝛼 and ̂𝛽 solve in 𝛼 and 𝛽 equations of the form

where (𝑌 , 𝐴, 𝑋; 𝛼, 𝛽) is a 𝑝-dimensional vector of functions such that 𝐸{(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)} = 0, and 𝛼0 and 𝛽0 are the true
values of 𝛼 and 𝛽 under the assumption that the model is correctly speciﬁed. For example, under models (1) and (3)

𝑖=1
∑

𝑛

(𝑌𝑖, 𝐴𝑖, 𝑋𝑖; 𝛼, 𝛽) = 0,

(4)

(a) (𝑌 , 𝐴, 𝑋; 𝛼, 𝛽) =

(𝑌 − 𝛼 − 𝛽𝐴)

and

(b) (𝑌 , 𝐴, 𝑋; 𝛼, 𝛽) =

{𝑌 − exp(𝛼 + 𝛽𝐴)},

(5)

(
𝑛
𝑖=1 𝐼(𝐴𝑖 = 𝑎), 𝑎 = 0, 1, the treatment-speciﬁc sample means, the estimator
respectively. Writing 𝑌 𝑎 =
obtained from (5)(a) is ̂𝛽 = 𝑌 1 − 𝑌 0 and that from (5)(b) is ̂𝛽 = log(𝑌 1∕𝑌 0), which is the estimator for the relative risk used in
A5401. Under model (2), with expit(𝑢) = 𝑒𝑢∕(1 + 𝑒𝑢),

)
𝑛
𝑖=1 𝑌𝑖𝐼(𝐴𝑖 = 𝑎)∕

∑

∑

)

(

1
𝐴

1
𝐴

𝐼(𝑌 ≤ 1) − expit(𝛼1 + 𝛽𝐴)
⋮
𝐼(𝑌 ≤ 𝑐 − 1) − expit(𝛼𝑐−1 + 𝛽𝐴) ⎞
⎟
⎟
⎠

⎛
⎜
⎜
⎝

(𝑌 , 𝐴, 𝑋; 𝛼, 𝛽) = (𝐴)

,

(6)

where (𝐴) is a (𝑐×𝑐−1) matrix of functions of 𝐴; the ML estimator 13 takes (𝐴) = 𝐷𝑇 (𝐴; 𝛼, 𝛽)𝑉 −1(𝐴; 𝛼, 𝛽), where 𝐷(𝐴; 𝛼, 𝛽)
is the (𝑐 − 1 × 𝑐) gradient matrix of the vector {𝐼(𝑌 ≤ 1) − expit(𝛼1 + 𝛽𝐴), … , 𝐼(𝑌 ≤ 𝑐 − 1) − expit(𝛼𝑐−1 + 𝛽𝐴)}𝑇 in (6) with
respect to 𝛼1, … , 𝛼𝑐−1, 𝛽, and 𝑉 (𝐴; 𝛼, 𝛽) is its (𝑐 − 1 × 𝑐 − 1) conditional covariance matrix given 𝐴.

In general, given a particular model and estimating equations deﬁned by the corresponding function (𝑌 , 𝐴, 𝑋; 𝛼, 𝛽), let

(𝛼, 𝛽) be the last row of the (𝑝 × 𝑝) matrix

𝜕(𝑌 , 𝐴, 𝑋; 𝛼, 𝛽)
𝜕𝛼𝑇 𝜕𝛽
where the matrix inside the expectation is the (𝑝 × 𝑝) matrix of partial derivatives of the 𝑝 components of (𝑌 , 𝐴, 𝑋; 𝛼, 𝛽) with
respect to (𝛼𝑇 , 𝛽)𝑇 . Then, with (𝛼0, 𝛽0) denoting this expression evaluated at 𝛼0, 𝛽0,

}]

(7)

{

𝐸

−

[

,

−1

𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) = (𝛼0, 𝛽0)(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)
is referred to as the inﬂuence function of the corresponding estimator for 𝛽 and has mean zero. From the theory of M-estimation 14
and semiparametric theory 7, it can be shown the estimator ̂𝛽 obtained by solving in 𝛽 the estimating equation

(8)

𝑛

𝑚(𝑌 , 𝐴, 𝑋; ̂𝛼, 𝛽) = 0,

(9)

where ̂𝛼 is any root-𝑛 consistent estimator for 𝛼, has inﬂuence function (8). Tsiatis et al. 10 show this explicitly in the case of
(6). Such estimators are consistent for the true value 𝛽0 and asymptotically normal, where the variance of the limiting normal
distribution of 𝑛1∕2( ̂𝛽 − 𝛽0) is equal to var{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)} = 𝐸{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)2}, so that approximate (large sample)
standard errors and test statistics are readily derived.

𝑖=1
∑

From semiparametric theory 7, there is a one-to-one correspondence between inﬂuence functions and estimators. Thus, if the
form of inﬂuence functions in a speciﬁc model involving a parameter 𝛽 can be derived, estimating equations leading to estimators
for 𝛽 can be developed. As we demonstrate in Section 3, inﬂuence functions corresponding to estimators for 𝛽 based on the data
available at an interim analysis can be derived from the inﬂuence function (8), and the resulting estimators exploit baseline and
time-dependent covariate information to gain precision.

2.2

Data and assumptions

To characterize the data that would be available at an interim analysis, we ﬁrst describe more fully the data that would be
available at the ﬁnal analysis if the trial were carried out to completion. Subjects enter the trial in a staggered fashion; thus, if
the trial starts at calendar time 0, denote by 𝐸 the calendar time at which a subject enters the trial. As in Section 1, let 𝑇 denote
the time lag in ascertaining the outcome 𝑌 ; thus, 𝑇 is the time since entry at which 𝑌 is determined, measured on the scale of
subject time. We assume that 𝑌 can be determined with certainty by the maximum follow-up period 𝐹 for any subject, so that
pr(𝑇 ≤ 𝐹 ) = 1. In addition to baseline covariates 𝑋, time-dependent covariate information may be collected on each participant
up to the time 𝑌 is ascertained. Denote by 𝐿(𝑢) the vector of such information at time 𝑢 following entry into the study, and let

TSIATIS and DAVIDIAN

5

̄𝐿(𝑢) = {𝐿(𝑠) ∶ 0 ≤ 𝑠 ≤ 𝑢} be the history of the time-dependent covariate information through time 𝑢. Thus, ̄𝐿(𝑇 ) represents
the covariate history for a subject for whom 𝑌 is ascertained after time lag 𝑇 .

With these deﬁnitions, for a trial with planned total sample size 𝑛, the data available at the ﬁnal analysis are iid

{𝐸𝑖, 𝑋𝑖, 𝐴𝑖, 𝑇𝑖, 𝑌𝑖, ̄𝐿𝑖(𝑇𝑖)},

𝑖 = 1, … , 𝑛;

(10)

we refer to (10) as the full data. As in Section 2.1, estimation of 𝛽 at the ﬁnal analysis is based only on the data on 𝑌 , 𝐴, and
possibly 𝑋 (in the case of conditional inference), and 𝐸, 𝑇 , and ̄𝐿(𝑇 ) are not used, and we call (8) a full data inﬂuence function.
Now consider the data that would be available at an interim analysis at calendar time 𝑡 following the start of the trial at calendar
time 0. It proves convenient for the developments in Section 3 to represent these data in terms of the full data (10) that would
be available at the ﬁnal analysis were the trial to be carried out to completion. At 𝑡, data will be observed only for subjects for
whom 𝐸 ≤ 𝑡. For such subjects, deﬁne 𝐶(𝑡) = 𝑡 − 𝐸 to be the censoring time, i.e., the time from a participant’s entry into
the study to the time of the interim analysis. If the time lag 𝑇 a subject would have in ascertaining the outcome is such that
𝑇 ≤ 𝐶(𝑡), then 𝑌 would be available at 𝑡; otherwise, 𝑌 would not yet be observed. Accordingly, deﬁne 𝑈 (𝑡) = min{𝑇 , 𝐶(𝑡)}
and Δ(𝑡) = 𝐼{𝑇 ≤ 𝐶(𝑡)}, so that 𝑌 is available at the time of the interim analysis only if Δ(𝑡) = 1. With these deﬁnitions, the
data available at an interim analysis at calendar time 𝑡 can be represented as iid

(𝑡)

𝑖 = 𝐼(𝐸𝑖 ≤ 𝑡)

𝐸𝑖, 𝑋𝑖, 𝐴𝑖, 𝑈𝑖(𝑡), Δ𝑖(𝑡), Δ𝑖(𝑡)𝑌𝑖, ̄𝐿𝑖{𝑈𝑖(𝑡)}

,

𝑖 = 1, … , 𝑛,

(11)

where then 𝑛(𝑡) =

𝑛
𝑖=1 𝐼(𝐸𝑖 ≤ 𝑡) is the number of subjects of the 𝑛 planned enrolled in the trial by calendar time 𝑡.

]

[

∑

As noted in Section 1, an interim analysis that uses all of the available data, including those from subjects for whom 𝑇 < 𝐹 ,
can naively overrepresent some values of the outcome over others. In terms of (11), the data on which this naive analysis would
be based involve only subjects 𝑖 who are enrolled and whose outcome is available, i.e., for whom 𝐼{𝐸𝑖 ≤ 𝑡), Δ𝑖(𝑡) = 1} = 1.
In contrast, a valid analysis that uses only the data from subjects enrolled for at least the full, maximum follow-up period 𝐹
involves subjects 𝑖 for whom 𝐼{𝐸𝑖 ≤ 𝑡, 𝐶𝑖(𝑡) ≥ 𝐹 } = 1. In the next section, we appeal to semiparametric theory as noted
at the end of Section 2.1 to deduce methods yielding valid inference on 𝛽 based on the available data (11) that can improve
substantially on this analysis and thus lead to more eﬃcient interim analyses.

3

INFERENCE BASED ON INTERIM DATA

3.1

Treatment eﬀect estimation

We ﬁrst present general estimating equations using the available data (11) at an interim analysis at time 𝑡 that yield treatment
eﬀect estimators oﬀering gains in precision relative to the estimator based only on subjects for whom 𝐼{𝐸𝑖 ≤ 𝑡, 𝐶𝑖(𝑡) ≥ 𝐹 } = 1.
Letting “⟂⟂” denote statistical independence, assume that 𝑋 ⟂⟂ 𝐴, which is guaranteed by randomization. Also assume that

𝐸 ⟂⟂ {𝑋, 𝐴, 𝑇 , 𝑌 , ̄𝐿(𝑇 )};

(12)

(12) implies that subjects enter according to a completely random process, which is reasonable in many trials. Because 𝐶(𝑡) =
𝑡 − 𝐸, (12) also implies that 𝐶(𝑡) ⟂⟂ {𝑋, 𝐴, 𝑇 , 𝑌 , ̄𝐿(𝑇 )}. We discuss weakening these assumptions in Section 7. We also require
that pr{𝐶(𝑡) > 𝐹 } > 0, so that there is positive probability of seeing subjects for whom the ﬁnal outcome has been ascertained
at an interim analysis at 𝑡 and so that the ﬁrst interim analysis must occur at least 𝐹 time units after the start of the trial.

We ﬁrst summarize the theoretical underpinnings of the practical, more eﬃcient interim monitoring approach we propose in
Section 4. Under the above assumptions, if 𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) is the inﬂuence function of a given estimator for a treatment eﬀect
parameter 𝛽 in a model for (𝑌 , 𝐴, 𝑋) as in Section 2.1, so based on the full data (10), then semiparametric theory yields that
inﬂuence functions for estimators for 𝛽 based on the available data (𝑡) in (11) at an interim analysis at time 𝑡 are of the form

𝐼(𝐸 ≤ 𝑡)
pr(𝐸 ≤ 𝑡)

Δ(𝑡)𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)
𝑡{𝑈 (𝑡)}

𝑡

+

∫
0

𝑑𝑀 (𝑡)

𝑐 (𝑢)𝜇(𝑚, 𝑢; 𝛼0, 𝛽0)

𝑡(𝑢)

⎛
⎜
⎜
− (𝐴 − 𝜋)𝑓 (𝑋) +
⎝

𝑡

∫
0

𝑑𝑀 (𝑡)

𝑐 (𝑢)

ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} − 𝜇(ℎ, 𝑢)

,

[

]⎞
⎟
⎟
⎠

(13)

6

TSIATIS and DAVIDIAN

where 𝑓 (𝑋) is an arbitrary function of 𝑋; ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} is an arbitrary function of 𝑢, 𝑋, 𝐴, and ̄𝐿(𝑢); and

𝜇(𝑚, 𝑢; 𝛼0, 𝛽0) = 𝐸{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)

𝑇 ≥ 𝑢},

𝜇(ℎ, 𝑢) = 𝐸

ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}

𝑇 ≥ 𝑢

,

𝑡(𝑢) = pr{𝐶(𝑡) ≥ 𝑢
𝑐 (𝑢) = 𝑑𝑁 (𝑡)

𝐸 ≤ 𝑡},
𝑐 (𝑢) (𝑡)(𝑢), 𝑁 (𝑡)

𝑐 (𝑢)−𝑑Λ(𝑡)

𝑑𝑀 (𝑡)
Here, 𝑡(𝑢) is the survival distribution for the censoring variable 𝐶(𝑡) at the time of the interim analysis, 𝑁 (𝑡)
the censoring counting process and at-risk process, and Λ(𝑡)

𝑐 (𝑢) = 𝐼{𝑈 (𝑡) ≤ 𝑢, Δ(𝑡) = 0},  (𝑡)(𝑢) = 𝐼{𝑈 (𝑡) ≥ 𝑢}, Λ(𝑡)
|

𝑐 (𝑢) is the cumulative hazard function for censoring.

[

|

𝑐 (𝑢) = − log{𝑡(𝑢)}.
|
𝑐 (𝑢) and  (𝑡)(𝑢) are

]

Let ̂𝑡(𝑢) be the Kaplan-Meier estimator for 𝑡(𝑢) using the data {𝑈𝑖(𝑡), 1 − Δ𝑖(𝑡)} for 𝑖 such that 𝐸𝑖 ≤ 𝑡, and deﬁne ̂Λ(𝑡)

𝑐 (𝑢) =
𝑛
− log{ ̂𝑡(𝑢)}, 𝑑 ̂𝑀 (𝑡)
𝑖=1 𝐼(𝐸𝑖 ≤ 𝑡)𝐴𝑖∕𝑛(𝑡), the proportion of enrolled subjects at 𝑡
assigned to active treatment. Then it can be shown that estimating equations corresponding to the inﬂuence functions in (13)
based on the available data (11) yielding estimators for 𝛽 are of the form

𝑐𝑖 (𝑢) = 𝑑𝑁 (𝑡)

𝑖 (𝑢), and ̂𝜋𝑡 =

𝑐𝑖 (𝑢) − 𝑑 ̂Λ(𝑡)

𝑐 (𝑢) (𝑡)

∑

𝐼(𝐸𝑖 ≤ 𝑡)

𝑛

𝑖=1
∑

Δ𝑖(𝑡)𝑚{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡), 𝛽}
̂𝑡{𝑈𝑖(𝑡)}

− (𝐴𝑖 − ̂𝜋𝑡)𝑓 (𝑋𝑖) +

𝑡

∫
0

⎡
⎢
⎢
⎣

𝑑 ̂𝑀 (𝑡)

𝑐𝑖 (𝑢)ℎ{𝑢, 𝑋𝑖, 𝐴𝑖, ̄𝐿𝑖(𝑢)}
⎤
⎥
⎥
⎦

= 0,

(14)

where ̂𝛼(𝑡) is a consistent estimator for 𝛼 based on the available data at 𝑡. For a speciﬁc model, corresponding full data inﬂuence
function 𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0), and choice of the functions 𝑓 (𝑋) and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}, to be discussed momentarily, an estimator
for 𝛽 based on the data available at interim analysis time 𝑡 is the solution to (14).

Taking 𝑓 (𝑋) ≡ 0 and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} ≡ 0 in (14) yields the estimating equation

𝑛

𝐼(𝐸𝑖 ≤ 𝑡)

𝑖=1
∑

Δ𝑖(𝑡)𝑚{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡), 𝛽}
̂𝑡{𝑈𝑖(𝑡)}

]

[

= 0,

(15)

whose solution is a so-called inverse probability weighted complete case (IPWCC) estimator, which eﬀectively bases estima-
tion of 𝛽 on only subjects for whom 𝑌 is available at 𝑡, but with inverse weighting by the censoring distribution “adjusting”
appropriately for the lag time in ascertaining the outcome. Judicious nonzero choices of 𝑓 (𝑋) and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} facilitate
exploiting baseline and time-dependent covariate information to gain eﬃciency over the IPWCC estimator solving (15) through
the two rightmost “augmentation” terms in the bracketed expression in (14), leading to what is referred to as an augmented
inverse probability weighted complete case (AIPWCC) estimator for 𝛽; the optimal such choices are discussed below.

A counterintuitive result from semiparametric theory is that, for any arbitrary 𝑓 (𝑋) and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}, it is possible to
improve the precision of the above estimators by replacing the Kaplan-Meier estimator ̂𝑡(𝑢) by treatment-speciﬁc Kaplan-
Meier estimators ̂𝑡(𝑢, 𝑎), say, obtained using the data {𝑈𝑖(𝑡), 1 − Δ𝑖(𝑡)} for 𝑖 such that 𝐸𝑖 ≤ 𝑡 and 𝐴𝑖 = 𝑎, 𝑎 = 0, 1, even though
because of (12) the distribution of 𝐶(𝑡) is not treatment dependent. This substitution leads to inﬂuence functions for estimators
for 𝛽 based on the available data of the form

𝐼(𝐸 ≤ 𝑡)
pr(𝐸 ≤ 𝑡)

Δ(𝑡)𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)
𝑡{𝑈 (𝑡), 𝐴}

⎛
⎜
⎜
− (𝐴 − 𝜋)𝑓 (𝑋) +
⎝

𝑡

∫
0

𝑡

+

∫
0

𝑑𝑀 (𝑡)

𝑐 (𝑢, 𝐴)𝜇(𝑚, 𝑢, 𝐴; 𝛼0, 𝛽0)

𝑡(𝑢, 𝐴)

(16)

𝑑𝑀 (𝑡)

𝑐 (𝑢, 𝐴)

ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} − 𝜇(ℎ, 𝑢, 𝐴)

,

𝐸 ≤ 𝑡, 𝐴}, 𝜇(𝑚, 𝑢, 𝐴; 𝛼0, 𝛽0) = 𝐸{𝑚(𝑌 , 𝐴, 𝑋𝛼0, 𝛽0)
𝑐 (𝑢, 𝐴) (𝑡)(𝑢), Λ(𝑡)
𝑐 (𝑢) − 𝑑Λ(𝑡)
𝑑𝑀 (𝑡)

𝑐 (𝑢, 𝐴) = 𝑑𝑁 (𝑡)

[

]⎞
⎟
⎟
⎠

𝑇 ≥ 𝑢, 𝐴}, 𝜇(ℎ, 𝑢, 𝐴) = 𝐸

𝑐 (𝑢, 𝐴) = − log{𝑡(𝑢, 𝐴)}.

|

ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}

𝑇 ≥ 𝑢, 𝐴

,

[

]

|

− (𝐴𝑖 − ̂𝜋𝑡)𝑓 (𝑋𝑖) +

𝑡

∫
0

𝑐𝑖 (𝑢, 𝑎) = 𝑑𝑁 (𝑡)

𝑐𝑖 (𝑢) − 𝑑 ̂Λ(𝑡)

𝑐 (𝑢, 𝑎) (𝑡)

𝑖 (𝑢). The estimating equations (17) with

𝑑 ̂𝑀 (𝑡)

𝑐𝑖 (𝑢, 𝐴𝑖)ℎ{𝑢, 𝑋𝑖, 𝐴𝑖, ̄𝐿𝑖(𝑢)}
⎤
⎥
⎥
⎦

= 0,

(17)

𝑛

𝑖=1
∑

𝐼(𝐸𝑖 ≤ 𝑡)

Δ𝑖(𝑡)𝑚{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡), 𝛽}
̂𝑡{𝑈𝑖(𝑡), 𝐴𝑖}

]

[

= 0,

(18)

where now

𝑡(𝑢, 𝐴) = pr{𝐶(𝑡) ≥ 𝑢

Estimating equations corresponding to (16) are then

|

𝑛

𝐼(𝐸𝑖 ≤ 𝑡)

Δ𝑖(𝑡)𝑚{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡), 𝛽}
̂𝑡{𝑈𝑖(𝑡), 𝐴𝑖}

𝑖=1
∑
𝑐 (𝑢, 𝑎) = − log{ ̂𝑡(𝑢, 𝑎)}; and 𝑑 ̂𝑀 (𝑡)
where now ̂Λ(𝑡)
𝑓 (𝑋) ≡ 0 and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} ≡ 0,

⎡
⎢
⎢
⎣

𝑡(𝑢)
|

|

TSIATIS and DAVIDIAN

7

yield an IPWCC estimator, and, again, nonzero choices of 𝑓 (𝑋) and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} lead to an AIPWCC estimator.

When 𝑌 is a binary outcome, as in study A5401, it can be shown that the IPWCC estimator ̂𝛽(𝑡) solving (18) is algebraically
identical to the logarithm of the ratio of treatment-speciﬁc Kaplan-Meier estimators for the probability of death or hospitalization
at 𝐹 days. Thus, as noted in Section 1, the standard estimator for the risk ratio at an interim analysis is a special case of the
general formulation here. Moreover, because this estimator is equivalent to an IPWCC estimator, it should be possible to obtain
more eﬃcient inference on the risk ratio at an interim analysis via an AIPWCC estimator.

Semiparametric theory provides the optimal choices of 𝑓 (𝑋) and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} yielding the most precise AIPWCC

estimator solving either of (14) or (17), given by

𝑓 𝑜𝑝𝑡(𝑋) = 𝐸{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)

𝑋, 𝐴 = 1) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)

𝑋, 𝐴 = 0),

ℎ𝑜𝑝𝑡{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} =

|

𝐸{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)

𝑇 ≥ 𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}

.

(19)

The conditional expectations in (19) are not likely to be known in practice. We propose an approach to approximating 𝑓 𝑜𝑝𝑡(𝑋)
and ℎ𝑜𝑝𝑡{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} in Section 4. We recommend estimating 𝛽 at an interim analysis at time 𝑡 by ̂𝛽(𝑡) solving an estimating
equation of the form (17) with the approximations for 𝑓 𝑜𝑝𝑡(𝑋) and ℎ𝑜𝑝𝑡{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} substituted.

From semiparametric theory, estimators solving estimating equations of the form (14) or (17) are consistent for 𝛽0 (for 𝑛(𝑡)
and 𝑛 large) and asymptotically normal, where, as at the end of Section 2.1, the variance of the large sample distribution of
̂𝛽(𝑡) can be obtained from the variance of the corresponding inﬂuence function. Thus, the resulting approximate standard errors
𝑆𝐸{ ̂𝛽(𝑡)} can be used to form a Wald-type test statistic, 𝑇 (𝑡) = ̂𝛽(𝑡)∕𝑆𝐸{ ̂𝛽(𝑡)} appropriate for addressing the null hypothesis
of no treatment eﬀect, H0∶ 𝛽0 = 0.

We conclude this section by noting an important implication of these results. In the case where the full data (10) are available,
as would be the case at the conclusion of the trial if not stopped early, the preceding developments lead to covariate-adjusted
estimators for 𝛽 based on the full data that have the potential to yield increased eﬃciency over the usual full data analyses outlined
in Section 2.1. In particular, considering (17), if 𝑡𝑒𝑛𝑑 is the calendar time at which the trial concludes with the full data accrued
(𝑢, 𝐴𝑖) = 0,
and outcomes for all subjects ascertained, 𝐼(𝐸𝑖 ≤ 𝑡𝑒𝑛𝑑) = 1, Δ𝑖(𝑡𝑒𝑛𝑑) = 1, 𝑡𝑒𝑛𝑑
𝑖 = 1, … , 𝑛, and (17) becomes

{𝑈𝑖(𝑡𝑒𝑛𝑑), 𝐴𝑖} = 1, and 𝑑 ̂𝑀 (𝑡𝑒𝑛𝑑 )

𝑐𝑖

𝑛

𝑚{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡𝑒𝑛𝑑), 𝛽} − (𝐴𝑖 − ̂𝜋)𝑓 (𝑋𝑖)

= 0,

where ̂𝜋 = 𝑛−1

𝑖=1
∑
[
𝑛
𝑖=1 𝐴𝑖, with corresponding inﬂuence function

]

∑

𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) − (𝐴 − 𝜋)𝑓 (𝑋).

(20)

(21)

As above, the optimal choice of 𝑓 (𝑋) leading to the most precise estimator solving (20) is that given in (19). The estimating
equation (20) is of the form of those in Zhang et al. 15. Thus, the proposed approach leads naturally to estimators for a ﬁnal
analysis that exploit baseline covariate information to improve eﬃciency through the “augmentation term” (𝐴 − 𝜋)𝑓 (𝑋).

3.2

Interim analysis

In practice, interim analyses will be carried out at times 𝑡1 < ⋯ < 𝑡𝐾 , with the possibility of stopping the trial early, e.g., for
eﬃcacy if evidence of a large treatment eﬀect emerges at an interim analysis. That is, focusing on eﬃcacy, the trial may be
stopped at the ﬁrst interim analysis time at which the relevant test statistic exceeds some appropriate stopping boundary; that is, if

𝑇 (𝑡𝑗)

≥ 𝑏𝑗,

𝑗 = 1, … , 𝐾,

|

|

for a two-sided alternative or 𝑇 (𝑡𝑗) ≥ or ≤ 𝑏𝑗, 𝑗 = 1, … , 𝐾, for a one-sided alternative, where 𝑏𝑗, 𝑗 = 1, … , 𝐾, are the
stopping boundaries. As is well-studied in the group sequential testing literature, the stopping boundaries 𝑏1, … , 𝑏𝐾 are chosen
to take into account multiple comparisons and ensure that the resulting procedure preserves the desired overall type 1 error 1,2,3,9.
Standard methods 2,3,9 for deriving stopping boundaries are based on the premise that the sequentially-computed test statistics
𝑇 (𝑡1), … , 𝑇 (𝑡𝐾 ) have the so-called independent increments structure 8,16.

In the Appendix, we sketch an argument demonstrating that, with the optimal choices of 𝑓 (𝑋) and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} given in
(19), the proposed test statistics, properly normalized, have the independent increments structure. Owing to this property, the
practical strategies for interim monitoring presented in Section 4 can be implemented using standard software for computation
of stopping boundaries; in the simulations in Section 5, we use the R package ldbounds 17.

8

4

PRACTICAL IMPLEMENTATION AND INTERIM MONITORING STRATEGIES

TSIATIS and DAVIDIAN

4.1

Treatment eﬀect estimation

Generalizing the approach in Tsiatis et al. 10 in the special case of a proportional odds model (2), we propose estimation of 𝛽 at
an interim analysis at time 𝑡 using an AIPWCC estimator solving (17), which can be obtained via a two-step algorithm.

Assume that the treatment eﬀect 𝛽 of interest is deﬁned within a model for which, given full data at the end of the study, the
estimator for 𝛽 would be obtained jointly with that for 𝛼 by solving an estimating equation of the form in (4) for a particular
estimating function (𝑌 , 𝐴, 𝑋; 𝛼, 𝛽). Because the optimal choices 𝑓 𝑜𝑝𝑡(𝑋) and ℎ𝑜𝑝𝑡{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} in (19) are not known, we
approximate them by linear combinations of basis functions. Letting 𝑓0(𝑋), 𝑓1(𝑋), … , 𝑓𝑀 (𝑋) be functions of 𝑋 speciﬁed by
the analyst, with 𝑓0(𝑋) ≡ 1, approximate 𝑓 𝑜𝑝𝑡(𝑋) by

𝑀

𝜓𝑚𝑓𝑚(𝑋).

(22)

Similarly, specify basis functions of {𝑢, 𝑋, ̄𝐿(𝑢)}, ℎ1{𝑢, 𝑋, ̄𝐿(𝑢)}, … , ℎ𝐿{𝑢, 𝑋, ̄𝐿(𝑢)}, and approximate ℎ𝑜𝑝𝑡{𝑢, 𝑋, 𝑎, ̄𝐿(𝑢)} by

𝑚=0
∑

𝐿

𝜙𝑎,𝓁ℎ𝓁{𝑢, 𝑋, ̄𝐿(𝑢)},

𝑎 = 0, 1.

(23)

With suitably chosen basis functions, experience in other contexts 6,10,15 suggests that this approach can lead to AIPWCC
estimators that achieve substantial eﬃciency gains over IPWCC estimators.

𝓁=1
∑

The AIPWCC estimator for 𝛽 obtained by substituting (22) and (23) in (17) has inﬂuence function (16) with these same sub-
stitutions. Because from semiparametric theory the variance of the estimator depends on the variance of the inﬂuence function,
as at the end of Section 2.1, we ﬁnd the coeﬃcients 𝜓𝑚, 𝑚 = 1, … , 𝑀, and 𝜙𝑎,𝓁, 𝓁 = 1, … , 𝐿, 𝑎 = 0, 1, that minimize this
variance, which, from the form of (16), is a least squares problem, as detailed below.

With these considerations, the two-step algorithm is as follows. At an interim analysis at time 𝑡:

Step 1. Estimate 𝛼 and 𝛽 by solving jointly in 𝛼 and 𝛽

𝑛

𝐼(𝐸𝑖 ≤ 𝑡)

𝑖=1
∑

Δ𝑖(𝑡)(𝑌𝑖, 𝐴𝑖, 𝑋𝑖; 𝛼, 𝛽)
̂𝑡{𝑈𝑖(𝑡), 𝐴𝑖}

[

]

= 0

to obtain ̂𝛼(𝑡) and ̂𝛽𝑖𝑛𝑖𝑡(𝑡); ̂𝛽𝑖𝑛𝑖𝑡(𝑡) is an IPWCC estimator solving (18). Then obtain an estimator ̂{̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)} for (𝛼, 𝛽). If
the expectation in (7) is analytically tractable, ̂{̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)} is the last row of (7) with ̂𝛼(𝑡) and ̂𝛽𝑖𝑛𝑖𝑡(𝑡) substituted for 𝛼 and 𝛽;
if not, take the estimator ̂{̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)} to be the last row of

𝑛

𝐼(𝐸𝑖 ≤ 𝑡)

Δ𝑖(𝑡)
̂𝑡{𝑈𝑖(𝑡), 𝐴𝑖}

𝜕(𝑌𝑖, 𝐴𝑖, 𝑋𝑖; 𝛼, 𝛽)
𝜕𝛼𝑇 𝜕𝛽

−

𝑛(𝑡)−1

[

𝑖=1
∑

For each subject 𝑖 for whom 𝐸𝑖 ≤ 𝑡, based on (8), construct

−1

.

𝛼=̂𝛼(𝑡),𝛽= ̂𝛽 𝑖𝑛𝑖𝑡(𝑡)]
|
|
|
|

𝑚{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)} = ̂{̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)}{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)}.

Step 2. Estimate the coeﬃcients 𝜓𝑚, 𝑚 = 1, … , 𝑀, and 𝜙𝑎,𝓁, 𝓁 = 1, … , 𝐿, 𝑎 = 0, 1, in the approximations (22) and (23) by
“least squares,” as suggested above. Namely, for each subject 𝑖 for whom 𝐸𝑖 ≤ 𝑡, deﬁne the “dependent variable”

Δ𝑖(𝑡)𝑚{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)}
̂𝑡{𝑈𝑖(𝑡), 𝐴𝑖}
where, in the integrand in the second term of the above expression, for 𝐴𝑖 = 𝑎, 𝑎 = 0, 1,

̂𝔜𝑖(𝑡) =

∫
0

+

̂𝑡(𝑢, 𝐴𝑖)

𝑡

𝑑 ̂𝑀 (𝑡)

𝑐𝑖 (𝑢, 𝐴𝑖)̂𝜇{𝑚, 𝑢, 𝐴𝑖; ̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)}

,

̂𝜇{𝑚, 𝑢, 𝑎; ̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)}
̂𝑡(𝑢, 𝑎)

=

𝑛

{

𝑘=1
∑
𝑛

×

𝐼(𝐸𝑘 ≤ 𝑡) (𝑡)

𝑘 (𝑢)𝐼(𝐴𝑘 = 𝑎)

−1

}

𝐼(𝐸𝑘 ≤ 𝑡)Δ𝑘(𝑡)𝑚{𝑌𝑘, 𝐴𝑘, 𝑋𝑘; ̂𝛼(𝑡), ̂𝛽𝑖𝑛𝑖𝑡(𝑡)}
̂𝑡{𝑈𝑘(𝑡), 𝑎}

 (𝑡)

𝑘 (𝑢)𝐼(𝐴𝑘 = 𝑎)

.

}

𝑘=1 {
∑

TSIATIS and DAVIDIAN

9

Likewise, for each of these subjects and suitably chosen basis functions as discussed above, deﬁne the 𝑀 + 1 + 2𝐿 “covariates”

(𝐴𝑖 − ̂𝜋𝑡)𝑓𝑚(𝑋𝑖), 𝑚 = 0, 1, … , 𝑀;

𝐼(𝐴𝑖 = 0)

𝐼(𝐴𝑖 = 1)

𝑡

𝑡

∫
0

∫
0

𝑑 ̂𝑀 (𝑡)

𝑐𝑖 (𝑢, 0)

ℎ𝓁{𝑢, 𝑋𝑖, ̄𝐿𝑖(𝑢)} − ̂𝜇(ℎ𝓁, 𝑢, 0)

,

𝓁 = 1, … , 𝐿,

𝑑 ̂𝑀 (𝑡)

𝑐𝑖 (𝑢, 1)

[

[

]

ℎ𝓁{𝑢, 𝑋𝑖, ̄𝐿𝑖(𝑢)} − ̂𝜇(ℎ𝓁, 𝑢, 1)

,

𝓁 = 1, … , 𝐿,

]

𝑛

−1 𝑛

where, for 𝑎 = 0, 1

̂𝜇(ℎ𝓁, 𝑢, 𝑎) =

{

𝐼(𝐸𝑘 ≤ 𝑡) (𝑡)

𝑘 (𝑢)𝐼(𝐴𝑘 = 𝑎)

}

ℎ𝓁{𝑢, 𝑋𝑘, ̄𝐿𝑘(𝑢)} (𝑡)

𝑘 (𝑢)𝐼(𝐴𝑘 = 𝑎).

𝑘=1
∑

Then obtain estimators ̂𝜓𝑚, 𝑚 = 0, 1, … , 𝑀, and ̂𝜙𝑎,𝓁, 𝓁 = 1, … , 𝐿, 𝑎 = 0, 1, by linear regression of ̂𝔜𝑖(𝑡) on the above
covariates. Based on this regression, obtain “predicted values” for each subject 𝑖 for whom 𝐸𝑖 ≤ 𝑡 as

𝑃 𝑟𝑒𝑑𝑖 = (𝐴𝑖 − ̂𝜋𝑡)

̂𝜓𝑚𝑓𝑚(𝑋𝑖) +

𝑀

𝑡

∫
0

𝑑 ̂𝑀 (𝑡)

𝑐𝑖 (𝑢, 𝐴𝑖)

𝐿

𝓁=1
∑

̂𝜙𝐴𝑖,𝓁

ℎ𝓁{𝑢, 𝑋𝑖, ̄𝐿𝑖(𝑢)} − ̂𝜇(ℎ𝓁, 𝑢, 𝐴𝑖)

.

[

]

The estimator for 𝛽 is then obtained as the one-step update

𝑘=1
∑

𝑚=0
∑

(24)

(25)

and an approximate standard error for ̂𝛽(𝑡) is given by

𝑆𝐸{ ̂𝛽(𝑡)} = 𝑛(𝑡)−1

𝑛

̂𝛽(𝑡) = ̂𝛽𝑖𝑛𝑖𝑡(𝑡) − 𝑛(𝑡)−1

𝐼(𝐸𝑖 ≤ 𝑡)𝑃 𝑟𝑒𝑑𝑖,

𝑛

𝑖=1
∑

𝐼(𝐸𝑖 ≤ 𝑡){ ̂𝔜𝑖(𝑡) − 𝑃 𝑟𝑒𝑑𝑖}2

1∕2

.

]

[

𝑖=1
∑

By an argument similar to that in the Supplementary Material of Tsiatis et al. 10, the estimator (24) is asymptotically equivalent
to an AIPWCC estimator solving (17).

In some settings, scant time-dependent covariate information may be available. Here, a special case of the general AIPWCC
formulation that still attempts to gain eﬃciency from only baseline covariates 𝑋 is to solve an estimating equation of the form in
(17) but with 𝑓 (𝑋) as in (19) and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} = 0. Implementation is as above, but with the “dependent variable” in Step
2 regressed only on the 𝑀 + 1 “covariates” (𝐴𝑖 − ̂𝜋𝑡)𝑓𝑚(𝑋𝑖), 𝑚 = 0, 1, … , 𝑀, to obtain estimators ̂𝜓𝑚, 𝑚 = 0, 1, … , 𝑀, and by
𝑀
𝑚=0 ̂𝜓𝑚𝑓𝑚(𝑋𝑖) in the one-step update (24) and its associated standard error (25). For deﬁniteness,
redeﬁning 𝑃 𝑟𝑒𝑑𝑖 = (𝐴𝑖 − ̂𝜋𝑡)
we refer to the resulting estimator as “AIPW1” and that incorporating time-dependent covariates above as “AIPW2.”

∑

4.2

Interim analysis

There is a vast literature on early stopping of clinical trials using group sequential and other methods; such methods are readily
applied if the independent increments property holds. We now discuss information-based and ﬁxed-sample size monitoring
strategies for using these approaches with the proposed treatment eﬀect estimators, for which, as argued in the Appendix and
demonstrated empirically in Section 5, the independent increments property holds exactly or approximately.

In the general information-based monitoring approach 1, monitoring and group sequential tests are based on the proportion
of the total information to be gained from the completed trial available at interim analysis times 𝑡, where in the present context
information is approximated at time 𝑡 using the large-sample approximate standard error of the relevant estimator ̂𝛽(𝑡), 𝑆𝐸{ ̂𝛽(𝑡)}.
If a group sequential test is desired with type 1 error 𝛼 for testing H0∶ 𝛽0 = 0 and power (1 − 𝛾) against a clinically meaningful
alternative value 𝛽0 = 𝛽𝐴, say, then the maximum information 𝑀𝐼 required to achieve this objective at the ﬁnal analysis with a
two-sided test is

𝑧𝛼∕2 + 𝑧𝛾
𝛽𝐴
where 𝑧𝛿 is the (1 − 𝛿) quantile of the standard normal distribution, and 𝐼𝐹 is an inﬂation factor to account for the loss of power
that results due to repeated testing relative to doing a single ﬁnal analysis. For example, the inﬂation factor associated with using

𝑀𝐼 =

𝐼𝐹 ,

)

(

2

10

TSIATIS and DAVIDIAN

O’Brien-Fleming stopping boundaries 3 is modest, equal to about 1.03; see Tsiatis 1. Information at an interim analysis at time 𝑡
is approximated as

Inf(𝑡) =

𝑆𝐸{ ̂𝛽(𝑡)}

−2.

Thus, the proportion of information at interim analysis time 𝑡 is approximated as

[
𝑝(𝑡) =

]

Inf(𝑡)
𝑀𝐼

.

(26)

Given the proportion of information (26) together with, e.g., the Lan-DeMets spending function 9, standard software can be used
to obtain stopping boundaries such that the resulting group sequential testing procedure has the desired operating characteristics.
Typically, in determining the overall sample size for a clinical trial to achieve the desired power to detect a meaningful
diﬀerence at a given level of signiﬁcance, the analyst must make assumptions on the values of nuisance parameters. If these
assumptions are not correct, the trial could be underpowered. An oft-cited advantage of information-based monitoring is that
interim analyses would continue until the information Inf(𝑡) achieves the maximum information 𝑀𝐼, guaranteeing the desired
operating characteristics regardless of the values of nuisance parameters. However, if the assumptions leading to the target
sample size are not correct, the information available at the time this planned sample size is reached and all participants have the
outcome ascertained may be less than 𝑀𝐼. If evidence emerges during the trial that 𝑀𝐼 is unlikely to be achieved, the sample
size might be reestimated and increased so that the full information threshold 𝑀𝐼 is met.

𝑛
𝑖=1 𝐼(𝐸𝑖 ≤ 𝑡) is the number of subjects who have enrolled by time 𝑡; of these subjects, 𝑛𝐴(𝑡) =

In many trials, however, resource constraints or other factors may make exceeding the originally planned sample size impos-
sible, thus rendering principled information-based monitoring infeasible. If a ﬁxed, maximum sample size 𝑛𝑚𝑎𝑥, say, is planned
and inalterable, then the proportion of information available at an interim analysis at any time 𝑡 on which stopping boundaries
can be determined must instead be based on 𝑛𝑚𝑎𝑥. In terms of the data (11) available at an interim analysis at 𝑡, as before, 𝑛(𝑡) =
𝑛
𝑖=1 𝐼{𝐸𝑖 ≤ 𝑡, 𝐶𝑖(𝑡) ≥ 𝐹 } is
the number who have been enrolled for the maximum follow-up period and thus have the outcome ascertained with certainty,
∑
and it is likely that 𝑛𝐴(𝑡) < 𝑛(𝑡). In general, a typical interim analysis at 𝑡 for ﬁxed 𝑛𝑚𝑎𝑥 would be based only on the data from
these 𝑛𝐴(𝑡) subjects, and, accordingly, the proportion of information available at 𝑡 would be 𝑝(𝑡) = 𝑛𝐴(𝑡)∕𝑛𝑚𝑎𝑥, with 𝑝(𝑡) = 1 at
the ﬁnal analysis. However, here, the proposed IPWCC and AIPWCC estimators allow censoring due to the time lag in ascer-
taining the outcome to be taken into account and incorporation of covariates to increase eﬃciency, so make use of additional
information in (11) beyond that available on just the 𝑛𝐴(𝑡) subjects for whom the outcome has been ascertained by time 𝑡. Thus,
if monitoring is based on test statistics constructed from these estimators, the proportion of information available at 𝑡 should be
between 𝑛𝐴(𝑡)∕𝑛𝑚𝑎𝑥 and 𝑛(𝑡)∕𝑛𝑚𝑎𝑥.

∑

With these considerations, for ﬁxed-sample size monitoring, we propose characterizing the proportion of information available
at an interim analysis at time 𝑡 in terms of what we refer to as the eﬀective sample size 𝑛𝐸𝑆𝑆(𝑡), say, at 𝑡. Intuitively, we deﬁne
𝑛𝐸𝑆𝑆(𝑡) to be the number of participants, had they been enrolled for the maximum follow-up period 𝐹 and had their outcome
ascertained with certainty, that would be required to lead to an estimator for 𝛽 based only on data from such subjects with the
same precision as that achieved by an IPWCC or AIPWCC estimator for 𝛽 based on all of the available data at 𝑡. The proportion
of information at 𝑡 would then be 𝑛𝐸𝑆𝑆(𝑡)∕𝑛𝑚𝑎𝑥.

To deﬁne eﬀective sample size formally, with 𝑛∗ subjects for whom the outcome has been fully ascertained, indexed by
𝑗 = 1, … , 𝑛∗, consider the estimator ̂𝛽∗ obtained by solving in 𝛽 the full data estimating equation (9) based on these 𝑛∗ subjects,

𝑛∗

𝑚(𝑌𝑗, 𝐴𝑗, 𝑋𝑗; ̂𝛼, 𝛽) = 0

for some consistent estimator ̂𝛼. Then from the semiparametric theory, ̂𝛽∗ has standard error approximately equal to the square
root of var{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)}∕𝑛∗. The eﬀective sample size at an interim analysis at time 𝑡 for the IPWCC estimator ̂𝛽(𝑡)
calculated using the available data (11) at 𝑡 is the value 𝑛∗ such that var{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)}∕𝑛∗ = 𝑆𝐸{ ̂𝛽(𝑡)}2. Accordingly,
deﬁne the eﬀective sample size when monitoring is based on the IPWCC estimator as

𝑗=1
∑

𝑛𝐸𝑆𝑆 (𝑡) =

var{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)
𝑆𝐸{ ̂𝛽(𝑡)}2

.

(27)

Because var{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)} is not known, in practice we must estimate it based on the available data, which can be
accomplished via the estimator

̂var{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)} = 𝑛(𝑡)−1

𝐼(𝐸𝑖 ≤ 𝑡)

𝑛

𝑖=1
∑

Δ𝑖(𝑡)𝑚{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡), ̂𝛽(𝑡)}2
̂𝑡{𝑈𝑖(𝑡), 𝐴𝑖}

.

(28)

TSIATIS and DAVIDIAN

Thus, in practice, we obtain the approximate eﬀective sample size as

𝑛𝐸𝑆𝑆 (𝑡) =

̂var{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)}
𝑆𝐸{ ̂𝛽(𝑡)}2

.

11

(29)

The eﬀective sample size for an AIPWCC estimator ̂𝛽(𝑡) (either AIPW1 or AIPW2) calculated using the available data at 𝑡
via the two-step algorithm is deﬁned similarly, but with the full data inﬂuence function 𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) in (27) replaced by
the inﬂuence function 𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋) as in (21). An estimator for var{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}
based on the available data is given by

𝑖=1
∑

𝑚=0
∑

̂var{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)} = 𝑛(𝑡)−1

𝐼(𝐸𝑖 ≤ 𝑡)

𝑛

Δ𝑖(𝑡)[𝑚{𝑌𝑖, 𝐴𝑖, 𝑋𝑖; ̂𝛼(𝑡), ̂𝛽(𝑡)} − 𝑃 𝑟𝑒𝑑∗
̂𝑡{𝑈𝑖(𝑡), 𝐴𝑖}

𝑖 ]2

,

𝑃 𝑟𝑒𝑑∗

𝑖 = (𝐴𝑖 − ̂𝜋𝑡)

̂𝜓𝑚𝑓𝑚(𝑋𝑖),

𝑀

(30)
where now the “predicted values” 𝑃 𝑟𝑒𝑑∗
𝑖 are obtained by a weighted least squares regression with “dependent variable”
𝑚{𝑌 , 𝐴, 𝑋; ̂𝛼(𝑡), ̂𝛽(𝑡)}, “covariates” (𝐴𝑖 − ̂𝜋𝑡)𝑓𝑚(𝑋𝑖), 𝑚 = 0, 1, … , 𝑀, and “weights” Δ𝑖(𝑡)∕ ̂𝑡{𝑈𝑖(𝑡), 𝐴𝑖}. Thus, for ̂𝛽(𝑡) the
AIPW1 or AIPW2 estimator, 𝑛𝐸𝑆𝑆(𝑡) is deﬁned as in (29) with the numerator given by (30).

With the appropriate deﬁnition of 𝑛𝐸𝑆𝑆 (𝑡), we approximate the corresponding proportion of information available at 𝑡 with

interim analyses based on an IPWCC or AIPWCCC estimator as

𝑝(𝑡) =

𝑛𝐸𝑆𝑆(𝑡)
𝑛𝑚𝑎𝑥

.

(31)

From (28) and (30), 𝑝(𝑡) = 1 at the ﬁnal analysis. As for information-based monitoring, given the proportion of information
(31), one can use standard software with, e.g., the Lan-DeMets spending function 9 to obtain stopping boundaries.

In the simulation studies in the next section, we study the methods under ﬁxed-sample monitoring, as in our experience this
approach is most common in practice. Moreover, while performance of information-based monitoring with statistics that possess
the independent increments property has been well-studied 8,18, because our approach to characterizing proportion of information
in ﬁxed-sample monitoring based on the proposed eﬀective sample size measure is new, evaluation of its performance is required.

5

SIMULATION STUDIES

We present results from several simulation studies, each involving 10000 Monte Carlo replications. For each simulation scenario,
we considered a uniform enrollment process during the calendar time interval [0, 𝐸𝑚𝑎𝑥] with a maximum, ﬁxed sample size 𝑛𝑚𝑎𝑥
and maximum follow up time 𝐹 , and ﬁxed-sample size monitoring with interim analyses planned at calendar times 𝑡1 < ⋯ < 𝑡𝐾
and a ﬁnal analysis at time 𝑡𝑒𝑛𝑑 = 𝐸𝑚𝑎𝑥 + 𝐹 = 𝑡𝐾+1 > 𝑡𝐾 , for a total of 𝐾 + 1 possible analyses. For simplicity, in each scenario,
we took 𝑛𝑚𝑎𝑥 to be the sample size required to achieve roughly 80% or 90% power for a single analysis at 𝑡𝑒𝑛𝑑 and did not include
an inﬂation factor 1. At each of the 𝐾 + 1 analysis times, we estimated the relevant treatment eﬀect parameter 𝛽 four ways:

i using the estimator ̂𝛽𝐹

(𝑡𝑗) obtained by carrying out the full data analysis based only on subjects enrolled for at least the

maximum follow-up period 𝐹 , so using subjects 𝑖 for whom 𝐼{𝐸𝑖 ≤ 𝑡, 𝐶𝑖(𝑡) ≥ 𝐹 } = 1;

ii using the IPWCC estimator ̂𝛽𝐼𝑃 𝑊 (𝑡𝑗) = ̂𝛽𝑖𝑛𝑖𝑡(𝑡𝑗) based on the available data (11), obtained at Step 1 of the two-step algorithm;

iii using the AIPWCC estimator ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡𝑗) based on the available data (11), obtained at Step 2 of the two-step algorithm using

only baseline covariates 𝑋 to gain eﬃciency, as at the end of Section 4.1;

iv using the AIPWCC estimator ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡𝑗) based on the available data (11) , obtained at Step 2 of the algorithm using both

baseline and time-dependent covariates 𝑋 and ̄𝐿(𝑢).

At the ﬁnal analysis at time 𝑡𝑒𝑛𝑑 at which the outcome has been ascertained on all 𝑛𝑚𝑎𝑥 subjects, ̂𝛽𝐹
(𝑡𝑒𝑛𝑑) and ̂𝛽𝐼𝑃 𝑊 (𝑡𝑒𝑛𝑑) yield
(versions of) the intended full data analysis; and ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡𝑒𝑛𝑑) and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡𝑒𝑛𝑑) are identical and yield the covariate-adjusted
analysis exploiting baseline covariate information discussed at the end of Section 3.1. In all scenarios, for the null hypothesis
H0∶ 𝛽0 = 0 and one-sided alternative hypotheses and level of signiﬁcance 𝛼 = 0.025, we used the R package ldbounds 17 with
a Lan-DeMets spending function to compute both O’Brien-Fleming 3 and Pocock 2 stopping boundaries at each analysis time
𝑡𝑗, 𝑗 = 1, … , 𝐾 + 1. For ̂𝛽𝐹
(𝑡𝑗), this calculation was based on the proportion of information 𝑝(𝑡𝑗) = 𝑛𝐴(𝑡𝑗)∕𝑛𝑚𝑎𝑥; for each of

12

TSIATIS and DAVIDIAN

the IPWCC and AIPWCC estimators ̂𝛽𝐼𝑃 𝑊 (𝑡𝑗), ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡𝑗), and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡𝑗), the stopping boundaries were obtained using the
approximate proportion of information (31) based on the relevant approximate eﬀective sample size 𝑛𝐸𝑆𝑆 (𝑡𝑗) given in (29).

For each scenario, we present the following results from two simulation studies, one under H0, so with data generated with

𝛽0 = 0, and one under an alternative of interest 𝛽0 = 𝛽𝐴:

i for each estimator, Monte Carlo estimates of cov{ ̂𝛽(𝑠), ̂𝛽(𝑡)}, 𝑠 < 𝑡, and var{ ̂𝛽(𝑡)}, 𝑠, 𝑡 ∈ {𝑡1, … , 𝑡𝐾 , 𝑡𝑒𝑛𝑑}; if the independent

increments property holds, cov{ ̂𝛽(𝑠), ̂𝛽(𝑡)} = var{ ̂𝛽(𝑡)}, 𝑠 < 𝑡;

ii for each estimator at each 𝑡 ∈ {𝑡1, … , 𝑡𝐾 , 𝑡𝑒𝑛𝑑}, Monte Carlo mean and standard deviation of ̂𝛽(𝑡), Monte Carlo mean of

𝑆𝐸{ ̂𝛽(𝑡)}, and Monte Carlo mean square error (MSE) for ̂𝛽𝐹

(𝑡) divided by that for ̂𝛽(𝑡);

iii for each estimator and stopping boundary, the Monte Carlo proportion of data sets for which H0 was rejected, Monte Carlo

estimate of expected sample size, and Monte Carlo estimate of expected stopping time.

|

|

The ﬁrst two simulation scenarios, demonstrating the methods for an ordinal categorical outcome and a binary outcome,
respectively, are based on the TESICO study with 𝐹 = 90 days, using the generative models adopted by Tsiatis et al. 10, with
𝑛𝑚𝑎𝑥 = 602, 𝐸𝑚𝑎𝑥 = 240 days, and 𝐾 = 4 interim analyses planned at calendar times (𝑡1, … , 𝑡4) = (150, 195, 240, 285) days,
with the ﬁnal analysis at 𝑡𝑒𝑛𝑑 = 330 days. For each simulated subject, 𝐴 was generated as Bernoulli with pr(𝐴 = 1) = 𝜋 = 0.5,
where 𝑎 = 0 (1) corresponds to placebo (active agent). To produce data for which the proportional odds model (2) holds, we
generated Υ ∼ 𝑈 (0, 1) and set Γ = (1 − 𝐴)Υ + 𝐴Υ(1∕OR)∕{1 − Υ + Υ(1∕𝑒𝛽)}, where as in (2) 𝛽 is the log odds ratio, so that
the distribution of Γ given 𝐴 = 1 satisﬁes logit{pr(Γ ≤ 𝑢
𝐴 = 0)} + 𝛽. For 𝑌 an ordinal outcome,
𝐴 = 1)} = logit{pr(Γ ≤ 𝑢
𝐴 = 0) = 0.12, 0.23, 0.17, 010, 0.05, 0.33 for 𝑗 = 1, … , 6 as in Table 1 of Tsiatis et al. 10 and thus generated
we took pr(𝑌 = 𝑗
𝑌 according to in which interval Γ fell as determined by the cutpoints [0.00, 0.12, 0.35, 0.52, 0.62, 0.67, 1.00]. Then if Γ < 0.52,
so 𝑌 = 1, 2, or 3, we took the time in hospital to be 𝐻 = 𝐹 Γ∕0.52 and the number of days at home and oﬀ oxygen as 𝐹 − 𝐻,
and 𝑇 = 𝐹 . If 0.52 ≤ Γ < 0.62 or 0.62 ≤ Γ < 0.67, corresponding to 𝑌 = 4 or 5, again 𝑇 = 𝐹 ; if Γ ≥ 0.67, corresponding to
death, time of death 𝑇 = (1 − 𝐴)𝑇0 + 𝐴𝑇1, where 𝑇0 ∼ 𝑈 (0, 30) if 𝐴 = 0 and 𝑇1 ∼ 𝑈 (20, 50) if 𝐴 = 1. A baseline covariate was
generated as 𝑋 ∼  {1.5(Υ − 0.5), 1}, so that 𝑋 is independent of 𝐴, correlated with 𝑌 , and does not aﬀect the proportional
odds model. Two time dependent covariates were generated as 𝐿1(𝑢) = 𝐼( < 𝑢), where  = 𝐻𝐼(Γ < 0.52) + 𝐹 𝐼(Γ ≥ 0.52),
so that 𝐿1(𝑢) = 1 if the subject was still in the hospital at time 𝑢; and 𝐿2(𝑢) = (𝐹 −)𝐿1(𝑢), the number of days the subject was
expected to be out of the hospital at day 𝐹 , and 𝐿(𝑢) = {𝐿1(𝑢), 𝐿2(𝑢)}. For a scenario with binary outcome, we generated the
data according to the foregoing scheme, except that we deﬁned 𝑌 = 1, corresponding to death, if Γ ≥ 0.67, and 𝑌 = 0 otherwise.
For the ﬁrst scenario with ordinal categorical outcome, we generated data as above under the null hypothesis, so with 𝛽 =
𝛽0 = 0, and 𝛽 = 𝛽𝐴 = log(1.5), corresponding to the alternative for which TESICO was powered (80% at the ﬁnal analysis
with 𝑛 = 602) 10, and H𝐴 ∶ 𝛽0 > 0. Here, ̂𝛽𝐹
(𝑡) is the ML estimator for 𝛽 in (2) obtained using the R function polr in the
MASS package 19. Following Tsiatis et al. 10, to simplify implementation, we constructed ̂𝛽𝐼𝑃 𝑊 (𝑡), ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡), and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)
using the estimating function (6) with (𝐴) = 𝐷𝑇 (𝐴; 𝛼, 𝛽)𝑉 −1
𝑖𝑛𝑑 (𝐴; 𝛼, 𝛽), where 𝑉𝑖𝑛𝑑(𝐴; 𝛼, 𝛽) is chosen according to the “working
(𝑡𝑒𝑛𝑑) and ̂𝛽𝐼𝑃 𝑊 (𝑡𝑒𝑛𝑑) are not identical. As shown by
independence” assumption, so that with full data at the ﬁnal analysis, ̂𝛽𝐹
Tsiatis et al. 10 and borne out in the simulations below, the eﬃciency loss for ̂𝛽𝐼𝑃 𝑊 (𝑡𝑒𝑛𝑑) relative to ̂𝛽𝐹

(𝑡𝑒𝑛𝑑) is negligible.

|

Under (a) the null hypothesis and (b) the alternative, the Monte Carlo sample covariance matrices of the 10000 estimates

{ ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡1), … , ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡4), ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡𝑒𝑛𝑑)} are

0.041 0.027 0.022 0.019 0.019
0.027 0.028 0.021 0.019 0.018
0.022 0.021 0.022 0.019 0.019
0.019 0.019 0.019 0.019 0.018
0.019 0.018 0.019 0.018 0.018

0.042 0.027 0.022 0.019 0.019
0.027 0.029 0.022 0.019 0.019
0.022 0.022 0.022 0.019 0.019
0.019 0.019 0.019 0.019 0.019
0.019 0.019 0.019 0.019 0.019

,

⎞
⎟
⎟
⎟
⎟
⎟
⎠

(b) ⎛
⎜
⎜
⎜
⎜
⎜
⎝

(a) ⎛
⎜
⎜
⎜
⎜
⎜
⎝

,

(32)

⎞
⎟
⎟
⎟
⎟
⎟
⎠

clearly demonstrating that the independent increments property holds approximately for this estimator. Analogous results for the
other three estimators are given in the Appendix, showing that the independent increments property holds approximately for all.
Under the null hypothesis and the alternative, Table 1 presents Monte Carlo mean and standard deviation, the Monte Carlo
average of standard errors 𝑆𝐸{ ̂𝛽(𝑡)}, and MSE ratio deﬁned above as the Monte Carlo MSE for the indicated estimator divided
by that for ̂𝛽𝐹
. Thus, the MSE ratio reﬂects eﬃciency of the indicated estimator relative to the usual ML estimator using data
only on subjects enrolled for the maximum follow-up period 𝐹 . From the table, all estimators are consistent, with standard
errors that track the Monte Carlo standard deviations, under both hypotheses. The eﬃciency gains over ̂𝛽𝐹
(𝑡) achieved at interim

TSIATIS and DAVIDIAN

13

TABLE 1 For Scenario 1 with ordered categorical outcome, performance of estimators for 𝛽 under (a) the null hypothesis 𝛽 = 0
and (b) the alternative 𝛽 = log(1.5) = 0.405 at each interim analysis time (𝑡1, … , 𝑡4) = (150, 195, 240, 285) days and at the
ﬁnal analysis at 𝑡𝑒𝑛𝑑 = 330 days MC Mean is the mean of 10000 Monte Carlo estimates; MC SD is the Monte Carlo standard
deviation, Ave MC SE is the mean of Monte Carlo standard errors, and MSE ratio is the ratio of Monte Carlo mean square error
for the AIPW2 estimator divided by that for the indicated estimator.

MC Mean MC SD

Ave MC SE MSE ratio

MC Mean MC SD

Ave MC SE MSE ratio

(a) Null Hypothesis

̂𝛽𝐹

(𝑡)

0.294
0.221
0.185
0.162
0.146

̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)

0.221
0.178
0.154
0 .140
0.135

̂𝛽𝐹

(𝑡)

0.294
0.221
0.185
0.162
0.146

̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)

0.224
0.180
0.155
0.141
0.136

0.294
0.221
0.184
0.162
0.146

0.221
0.178
0.156
0.141
0.135

0.294
0.220
0.185
0.163
0.147

0.224
0.180
0.158
0.142
0.137

-0.002
-0.002
-0.003
-0.001
0.000

-0.004
-0.002
-0.002
-0.001
0.000

0.408
0.406
0.404
0.406
0.406

0.405
0.406
0.405
0.406
0.406

1.000
1.000
1.000
1.000
1.000

1.775
1.534
1.399
1.327
1.169

-0.004
-0.002
-0.002
-0.001
0.000

-0.005
-0.002
-0.002
-0.001
0.000

(b) Alternative Hypothesis

1.000
1.000
1.000
1.000
1.000

1.733
1.508
1.378
1.314
1.159

0.406
0.406
0.405
0.406
0.406

0.406
0.408
0.408
0.407
0.406

̂𝛽𝐼𝑃 𝑊 (𝑡)

0.232
0.189
0.166
0.152
0.147

0.232
0.189
0.164
0.151
0.146

̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

0.203
0.168
0.149
0.138
0.135

0.235
0.191
0.167
0.153
0.148

0.198
0.165
0.145
0.136
0.135

̂𝛽𝐼𝑃 𝑊 (𝑡)

0.235
0.191
0.165
0.152
0.147

̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

0.204
0.169
0.150
0.139
0.137

0.200
0.167
0.147
0.137
0.136

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

1.603
1.330
1.239
1.139
0.991

2.095
1.717
1.542
1.380
1.169

1.566
1.336
1.221
1.131
0.985

2.078
1.702
1.523
1.373
1.159

analyses by using any of ̂𝛽𝐼𝑃 𝑊 (𝑡), ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡), and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) are substantial. The IPWCC estimator achieves gains solely through
accounting for censoring; the AIPWCC estimators improve on these gains by additionally incorporating covariates. Notably,
̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) yields a two-fold gain at the initial interim analysis. For all three estimators, the eﬃciency gains are most pronounced
at the early interim analyses where censoring is the most substantial and diminish as censoring decreases as the trial progresses.
At the ﬁnal analysis, ̂𝛽𝐹
(𝑡𝑒𝑛𝑑) and ̂𝛽𝐼𝑃 𝑊 (𝑡𝑒𝑛𝑑) show very similar performance, with ̂𝛽𝐼𝑃 𝑊 (𝑡𝑒𝑛𝑑) exhibiting minimal relative loss of
eﬃciency, as noted above. As expected, ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡𝑒𝑛𝑑) and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡𝑒𝑛𝑑) are identical and, due to the incorporation of adjustment
for baseline covariates, result a 16%-17% gain in eﬃciency over the usual ﬁnal analysis.

Table 2 presents interim monitoring results using each estimator with both O’Brien-Fleming and Pocock stopping boundaries
under the null hypothesis and under the alternative 𝛽 = log(1.5). Under the null, the nominal level 𝛼 = 0.025 is achieved for

14

TSIATIS and DAVIDIAN

TABLE 2 For Scenario 1 with ordered categorical outcome, interim analysis performance using each estimator with O’Brien-
Fleming and Pocock stopping boundaries under (a) the null hypothesis 𝛽 = 0 and (b) the alternative 𝛽 = log(1.5) = 0.405, with
maximum sample size 𝑛𝑚𝑎𝑥 = 602 and 𝑡𝑒𝑛𝑑 = 330 days. P(reject) is the proportion of Monte Carlo data sets for which the null
hypothesis was rejected; MC E(SS) is the Monte Carlo average of number of subjects enrolled at the time the stopping boundary
was crossed (standard deviation); and MC E(Stop) is the Monte Carlo average stopping time (days) (standard deviation). The
standard error for entries for P(reject) in (a) is ≈ 0.0016.

P(reject)

MC E(SS)

MC E(Stop)

P(reject)

MC E(SS)

MC E(Stop)

(a) Null Hypothesis

̂𝛽𝐹
(𝑡)
̂𝛽𝐼𝑃 𝑊 (𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

̂𝛽𝐹
(𝑡)
̂𝛽𝐼𝑃 𝑊 (𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

0.024
0.024
0.024
0.024

0.784
0.771
0.836
0.841

O’Brien-Fleming

601.9 (2.7)
601.6 (7.8)
601.7 (6.7)
601.2 (11.4)

329.3 (7.5)
328.4 (12.1)
328.5 (11.3)
327.9 (14.9)

0.023
0.024
0.024
0.027

(b) Alternative Hypothesis

O’Brien-Fleming

592.7 (31.5)
564.6 (62.5)
562.7 (62.7)
531.9 (81.7)

284.2 (44.7)
257.1 (55.9)
251.5 (53.4)
231.7 (58.0)

0.710
0.701
0.774
0.783

Pocock

599.7 (21.4)
598.8 (25.9)
598.9 (25.5)
598.0 (28.9)

Pocock

548.1 (85.3)
516.3 (100.3)
508.3 (100.6)
483.4 (103.5)

327.4 (19.5)
326.7 (22.4)
326.8 (22.0)
326.1 (24.7)

260.5 (68.7)
239.0 (74.7)
230.1 (72.2)
215.1 (72.3)

all estimators. Under the alternative, power for ̂𝛽𝐹
(𝑡) is slightly shy of the desired 80%, as expected with no inﬂation factor;
by comparison, the AIPWCC estimators yield improved power due to inclusion of covariate information. Under the alternative
and both types of boundaries, basing interim analyses on ̂𝛽𝐼𝑃 𝑊 (𝑡), ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡), and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) results in impressive reductions in
expected sample size and expected stopping time relative to ̂𝛽𝐹

(𝑡), with the gains especially impressive for ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡).

For the second scenario with binary outcome, we generated data as above under the null hypothesis and with the log odds
ratio equal to 1.5, which implies a log relative risk (risk ratio) for death (𝑌 = 1) of 𝛽 = 𝛽0 = 𝛽𝐴 = log(0.247∕0.33) = −0.290
as in (3) and alternative hypothesis H𝐴∶ 𝛽0 < 0. We took 𝑛𝑚𝑎𝑥 = 900, which corresponds roughly to 90% power to detect this
alternative. The Monte Carlo sample covariance matrices of the 10000 estimates { ̂𝛽(𝑡1), … , ̂𝛽(𝑡4), ̂𝛽(𝑡𝑒𝑛𝑑)} for each of the four
estimators under both the null and alternative settings are shown in the Appendix and exhibit patterns analogous to those in (32),
demonstrating that all estimators have approximately the independent increments property. Also shown in the Appendix for each
estimator at each analysis time are the Monte Carlo mean and standard deviation, the Monte Carlo average of standard errors
𝑆𝐸{ ̂𝛽(𝑡)}, and MSE ratio deﬁned above as the Monte Carlo MSE for the estimator divided by that for ̂𝛽𝐹
(𝑡) under the null and
alternative hypotheses. All estimators are consistent, and standard errors are very close to the Monte Carlo standard deviations.
Under both null and alternative hypotheses, the estimator ̂𝛽𝐼𝑃 𝑊 (𝑡), which takes censoring at interim analysis times into account
and as noted previously is identical to the ratio of treatment-speciﬁc Kaplan-Meier estimators often used in practice, achieves
substantial eﬃciency gains over ̂𝛽𝐹
(𝑡), with a two-fold increase at the ﬁrst interim analysis and 24% at the last at 𝑡4 = 285 days.
These estimators are equivalent, as expected, at the ﬁnal analysis. The AIPWCC estimators ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡) and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) achieve
even greater gains. Here, ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) does not oﬀer improved performance over ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡); this behavior is not surprising, as
the time-dependent covariates 𝐿(𝑢) = {𝐿1(𝑢), 𝐿2(𝑢)} reﬂecting length of hospital stay do not provide information on death.
As expected, these estimators are identical at 𝑡𝑒𝑛𝑑 and oﬀer 10%-12% gains in eﬃciency over the standard analysis through
adjustment for the baseline covariate.

Table 3 shows interim monitoring results using each estimator with O’Brien-Fleming and Pocock stopping boundaries under
the null hypothesis and under the alternative 𝛽𝐴 = −0.290. Again, overall testing procedures achieve the nominal level. Power
gains over ̂𝛽𝐹
(𝑡) under the alternative are achieved using the AIPWCC estimators. As for the ﬁrst scenario, basing interim
analyses on ̂𝛽𝐼𝑃 𝑊 (𝑡), ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡), and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) yields substantial reductions in expected sample size and stopping time over
̂𝛽𝐹

(𝑡) under the alternative, especially for the AIPWCC estimators.

TSIATIS and DAVIDIAN

15

TABLE 3 For Scenario 2 with binary outcome, interim analysis performance using each estimator with O’Brien-Fleming and
Pocock stopping boundaries under (a) the null hypothesis 𝛽 = 0 and (b) the alternative 𝛽 = log(0.247∕0.33) = −0.290, with
maximum sample size 𝑛𝑚𝑎𝑥 = 900 and 𝑡𝑒𝑛𝑑 = 330 days. Entries are as in Table 2. The standard error for entries for P(reject) in
(a) is ≈ 0.0016.

P(reject)

MC E(SS)

MC E(Stop)

P(reject)

MC E(SS)

MC E(Stop)

(a) Null Hypothesis

̂𝛽𝐹
(𝑡)
̂𝛽𝐼𝑃 𝑊 (𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

̂𝛽𝐹
(𝑡)
̂𝛽𝐼𝑃 𝑊 (𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

0.024
0.024
0.023
0.024

0.770
0.767
0.806
0.809

O’Brien-Fleming

900.0 (2.3)
898.8 (15.8)
899.0 (14.0)
899.0 (14.9)

329.4 (6.5)
328.0 (14.5)
328.1 (13.8)
328.0 (14.2)

0.022
0.023
0.025
0.026

(b) Alternative Hypothesis

O’Brien-Fleming

887.5 (44.3)
808.3 (121.4)
801.8 (122.5)
799.9 (123.4)

285.9 (44.0)
241.3 (61.3)
236.1 (59.6)
235.5 (59.7)

0.690
0.700
0.746
0.748

Pocock

896.3 (33.6)
894.3 (42.3)
894.1 (42.8)
894.1 (42.7)

Pocock

827.2 (122.4)
744.9 (157.6)
733.2 (157.3)
731.6 (157.3)

327.4 (19.8)
326.5 (23.7)
326.3 (24.3)
326.2 (24.4)

264.4 (67.2)
228.3 (76.7)
221.4 (74.7)
220.6 (74.7)

The ﬁnal simulation scenario involves a continuous outcome, with 𝑛𝑚𝑎𝑥 = 300, 𝐸𝑚𝑎𝑥 = 156 weeks, and 𝐹 = 52 weeks, so
that enrollment takes place over 3 years, with 𝐾 = 4 interim analyses planned at calendar times 104, 130, 156, 182 weeks and the
ﬁnal analysis at 𝑡𝑒𝑛𝑑 = 208 weeks. We generated treatment assignment 𝐴 as Bernoulli with pr(𝐴 = 1) = 𝜋 = 0.5, where 𝑎 = 0 (1)
corresponds to placebo (active agent); and a categorical baseline covariate 𝑋1 was generated with pr(𝑋1 = 𝑗) = 0.4, 0.3, 0.2, 0.1
for 𝑗 = 1, … , 4. With (𝑠1, … , 𝑠5) = (0, 4, 12, 24, 52) weeks, 𝜎 = 4.5, 𝐷 a (2 × 2) matrix with vech(𝐷) = (80, −0.5, 0.08),
and 𝜉 = (𝜉1, 𝜉2)𝑇 , we generated longitudinal measurements for each subject 𝑖 according to the linear mixed eﬀects model
𝑍𝑖𝑗 = 65𝐼(𝑋1 = 1) + 60𝐼(𝑋1 = 2) + 55𝐼(𝑋1 = 3) + 49𝐼(𝑋1 = 4) + {𝜉1(1 − 𝐴) + 𝜉2𝐴}𝑠𝑗 + 𝑏0𝑖 + 𝑏1𝑖𝑠𝑗 + 𝑒𝑖𝑗, where
𝑏𝑖 = (𝑏0𝑖, 𝑏1𝑖)𝑇 ∼  (0, 𝐷) independent of 𝑒𝑖𝑗 ∼  (0, 𝜎2). The outcome for subject 𝑖 is then 𝑌𝑖 = 𝑍𝑖5, the longitudinal
measure at 𝐹 weeks. As would be likely in practice, we included in 𝑋 only the single baseline covariate 𝑍𝑖1, the value of the
longitudinal measure at time 0 and did not also include 𝑋1, and we took the single time-dependent covariate 𝐿(𝑢) at time 𝑢 to
be the most recently observed value of the longitudinal measurements 𝑍𝑖𝑗. Under the null hypothesis, 𝜉 = (−0.3, −0.3)𝑇 ; under
the alternative, 𝜉 = (−0.3, −0.18)𝑇 corresponding to 𝛽 = 𝛽0 = 𝛽𝐴 = 6.24, for which 𝑛𝑚𝑎𝑥 = 300 yields roughly 90% power at
the ﬁnal analysis. Results shown in the Appendix demonstrate that the independent increments property holds approximately for
(𝑡) and ̂𝛽𝐼𝑃 𝑊 (𝑡) are identical because 𝑇 = 𝐹 for all subjects, so that both are based only
all estimators. Here, the estimators ̂𝛽𝐹
on subjects followed for at least 𝐹 weeks. Standard errors 𝑆𝐸{ ̂𝛽𝐹
(𝑡)} are obtained from the routine formula for a diﬀerence in
sample means assuming common treatment-speciﬁc variance, while 𝑆𝐸{ ̂𝛽𝐼𝑃 𝑊 (𝑡)} follows from the IPWCC inﬂuence function;
these standard errors are asymptotically equivalent but diﬀer slightly for ﬁnite samples. Incorporation of the baseline covariate
yields 10%-20% gains in eﬃciency; further incorporation of the last outcome carried forward as a time-dependent covariate
leads to eﬃciency gains for ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) of 34% to 47%.

Interim monitoring results are shown in Table 4 and are analogous to those in Tables 2 and 3. Under the null hypothesis, the
Monte Carlo rejection probability for ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) with Pocock boundaries exceeds slightly the nominal 0.025 level. Again, under
the alternative, the AIPWCC estimators result in earlier expected sample sizes and stopping times.

We remark that all scenarios reﬂect the general result that basing interim analyses on the proposed AIPWCC estimators leads
to not only more eﬃcient inferences but also, because of the increased precision, to a greater proportion of the total statistical
information being available at each interim analysis time than would be available using the usual methods. This feature implies
that O’Brien-Fleming boundaries will be less conservative for the proposed estimators, leading to potential gains in expected
sample size and stopping times.

16

TSIATIS and DAVIDIAN

TABLE 4 For Scenario 3 with continuous outcome, interim analysis performance using each estimator with O’Brien-Fleming
and Pocock stopping boundaries under (a) the null hypothesis 𝛽 = 0 and (b) the alternative 𝛽 = 6.24, with maximum sample
size 𝑛𝑚𝑎𝑥 = 300 and 𝑡𝑒𝑛𝑑 = 208 days. Entries are as in Table 2. The standard error for entries for P(reject) in (a) is ≈ 0.0016.

P(reject)

MC E(SS)

MC E(Stop)

P(reject)

MC E(SS)

MC E(Stop)

(a) Null Hypothesis

O’Brien-Fleming

299.9 (3.1)
299.8 (3.4)
299.9 (2.6)
299.8 (4.0)

207.4 (5.5)
207.4 (5.8)
207.5 (5.0)
207.0 (7.4)

0.025
0.025
0.026
0.029

(b) Alternative Hypothesis

O’Brien-Fleming

286.3 (26.0)
286.0 (26.4)
286.5 (25.5)
265.9 (37.3)

167.8 (30.6)
167.4 (30.7)
165.5 (28.9)
146.7 (31.2)

0.823
0.826
0.896
0.892

Pocock

298.6 (11.3)
298.6 (11.5)
298.6 (11.2)
298.1 (13.2)

Pocock

259.9 (45.2)
259.1 (45.4)
255.9 (45.2)
239.8 (45.3)

206.2 (12.7)
206.1 (12.9)
206.2 (12.7)
205.7 (14.5)

151.9 (41.9)
151.1 (41.9)
146.0 (39.6)
133.5 (37.8)

̂𝛽𝐹
(𝑡)
̂𝛽𝐼𝑃 𝑊 (𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

̂𝛽𝐹
(𝑡)
̂𝛽𝐼𝑃 𝑊 (𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)
̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

0.026
0.026
0.025
0.026

0.875
0.876
0.930
0.930

6

APPLICATION

To demonstrate how use of the methods would proceed in practice as a trial progresses, we consider the setting of TESICO
with ordinal categorical outcome, where the treatment eﬀect of interest is the log odds ratio 𝛽 in an assumed proportional odds
model as in (2). Because this trial is ongoing, we cannot base this demonstration on data from the trial; accordingly, we present
use of the methods for a simulated data set generated according to the ﬁrst simulation scenario in Section 5 with 𝛽 = log(1.5),
which is based on this study. As in Section 5, the planned maximum sample size is 𝑛𝑚𝑎𝑥 = 602, with full enrollment reached by
𝐸𝑚𝑎𝑥 = 240 day. Interim analyses are planned at 150, 195, 240, and 285 days, with the ﬁnal analysis to be conducted at 𝑡𝑒𝑛𝑑 = 330
days, at which time all 𝑛𝑚𝑎𝑥 participants will have completed the trial with their outcomes ascertained. For deﬁniteness, we use
O’Brien-Fleming stopping boundaries and focus on the null and alternative hypotheses H0∶ 𝛽0 = 0 versus H𝐴∶ 𝛽0 > 0, with
overall level of signiﬁcance 𝛼 = 0.025.

Table 5 shows how the trial would proceed if the analyses were conducted at each interim analysis time 𝑡 using each of the
(𝑡), ̂𝛽𝐼𝑃 𝑊 (𝑡), ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡), and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡). For each estimator, the proportion of information at each of the interim
estimators ̂𝛽𝐹
analysis times was calculated as described in Section 4.2 and was used to obtain the stopping boundary. At the ﬁrst interim
analysis at 150 days, the proportion of information for the ML estimator ̂𝛽𝐹
(𝑡), which uses only those subjects among the 𝑛(𝑡)
enrolled who have been followed for at least the maximum follow-up time 𝐹 , is 0.257, whereas that for ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) is 0.462,
almost twice as large. This striking diﬀerence is reﬂected in the corresponding stopping boundaries: at the ﬁrst interim analysis
at 150 days, the test statistic based on ̂𝛽𝐹
(𝑡) is 2.496, far from the boundary of 4.265, whereas that based on ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) is 2.966,
almost reaching the boundary of 3.099. Basing the analyses on ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡) results in suﬃcient evidence to stop the trial at the
second interim analysis at 195 days with 487 subjects enrolled, while suﬃcient evidence to stop using ̂𝛽𝐹
(𝑡) does not emerge
until the fourth interim analysis at 285 days, with all 𝑛𝑚𝑎𝑥 = 602 subjects enrolled. Basing the analyses on ̂𝛽𝐼𝑃 𝑊 (𝑡) and ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)
results in stopping the trial at 240 days, with again all 602 planned subjects enrolled.

7

DISCUSSION

We have proposed a general framework for design and conduct of group sequential trials in the common situation where the out-
come is known with certainty only after some time lag. The methods account for censoring at the time of an interim analysis and

TSIATIS and DAVIDIAN

17

TABLE 5 Interim analysis results for analyses at time (𝑡1, … , 𝑡5) = (150, 195, 240, 285, 330) for the simulated TESICO trial;
𝑛(𝑡𝑗) is the number of subjects enrolled at 𝑡𝑗. For each of the estimators ̂𝛽𝐹
(𝑡) (the ML estimator based on data from all sub-
jects followed for at least the maximum follow-up period 𝐹 at 𝑡), the IPWCC estimator ̂𝛽𝐼𝑃 𝑊 (𝑡), and the AIPWCC estimators
̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡) and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡), Est (SE) are the estimate ̂𝛽(𝑡𝑗) (standard error 𝑆𝐸{ ̂𝛽(𝑡𝑗)}) at 𝑡𝑗, 𝑇 is associated the Wald test statis-
tic, 𝑝(𝑡𝑗) is the proportion of information at 𝑡𝑗, and 𝑏𝑗 is the O’Brien-Fleming stopping boundary. Entries are boldfaced at the
interim analysis at which the trial would be stopped using the indicated estimator.

𝑡𝑗

150
195
240
285
330

𝑡𝑗

150
195
240
285
330

𝑛(𝑡𝑗)

368
487
602
602
602

𝑛(𝑡𝑗)

368
487
602
602
602

Est (SE)

0.730 (0.292)
0.619 (0.224)
0.457 (0.187)
0.459 (0.162)
–

Est (SE)

0.565 (0.218)
0.497 (0.182)
0.409 (0.156)
–
–

(𝑡)

̂𝛽𝐹
𝑇

2.496
2.765
2.445
2.828
–

̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)

𝑇

2.586
2.739
2.615
–
–

𝑝(𝑡𝑗)

0.257
0.432
0.611
0.809
–

𝑝(𝑡)

0.382
0.564
0.757
–
–

𝑏𝑗

4.265
3.218
2.657
2.277
–

𝑏𝑗

3.444
2.777
2.362
–
–

Est (SE)

0.547 (0.230)
0.476 (0.193)
0.423 (0.166)
–
–

Est (SE)

0.590 (0.199)
0.532 (0.167)
–
–
–

̂𝛽𝐼𝑃 𝑊 (𝑡)
𝑇

2.380
2.473
2.551
–
–
̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)
𝑇

2.966
3.185
–
–
–

𝑝(𝑡)

0.408
0.581
0.785
–
–

𝑝(𝑡)

0.462
0.670
–
–
–

𝑏𝑗

3.318
2.733
2.313
–
–

𝑏𝑗

3.099
2.521
–
–
–

incorporate baseline and time-dependent evolving covariate information to improve eﬃciency over standard analyses, facilitat-
ing earlier stopping with potentially smaller numbers of enrolled subjects. We have demonstrated analytically and empirically
that the proposed test statistics possess the independent increments structure, so that standard methods and software for speci-
fying stopping boundaries can be used. The methods can be applied under both information-based monitoring and ﬁxed-sample
monitoring strategies. For the latter, we have proposed the idea of eﬀective sample size to characterize the proportion of infor-
mation available at an interim analysis. Simulation studies demonstrate that the methods preserve the operating characteristics
of a monitored trial and that substantial reductions in expected sample size and stopping time can be achieved.

As noted above, the proposed methodology is relevant in the large class of problems where the outcome would be known with
certainty for all subjects at the ﬁnal analysis. For some trials with possibly censored time-to-event outcome, interest may focus
on the hazard ratio under the assumption of proportional hazards. Here, there is no prespeciﬁed, maximum follow-up time 𝐹
at which the outcome is known with certainty, so that the proposed framework is not applicable.

The methods as presented are based on the assumption (12) that entry time is independent of all other variables, including
baseline covariates 𝑋, which implies that any interim analysis time 𝑡 𝐶(𝑡) ⟂⟂ {𝑋, 𝐴, 𝑇 , 𝑌 , ̄𝐿(𝑇 )}. This assumption is made
tacitly in any clinical trial that focuses on inference on an unconditional treatment eﬀect parameter. If the distribution of 𝑋
changes over the course of a trial, then (12) is violated, and, intuitively, subjects enrolled at the time of an interim analysis
may not be representative of the population of interest at the ﬁnal analysis. This is a general phenomenon and not unique to
our methodology. If (12) is violated in this way, then the treatment eﬀect parameter may not be static over time. Under these
circumstances, conditional (on 𝑋) inference may be more appropriate; e.g., as in the case of the conditional proportional odds
model for ordinal categorical outcome in Section 2.1. Under the modiﬁed assumption 𝐸 ⟂⟂ {𝐴, 𝑇 , 𝑌 , ̄𝐿(𝑇 )}
𝑋 (independence
conditional on 𝑋), the proposed methods can be extended to support such conditional inference through incorporation of relevant
inﬂuence functions and modeling of the censoring distribution as a function of 𝑋.

|

ACKNOWLEDGMENTS

The authors thank Drs. Birgit Grund and Michael Hughes for helpful discussions.

18

TSIATIS and DAVIDIAN

SUPPORTING INFORMATION

R code implementing the simulations reported in Section 5 is available from the authors

APPENDIX

A DEMONSTRATION OF INDEPENDENT INCREMENTS PROPERTY

For deﬁniteness, we consider AIPWCC estimators ̂𝛽(𝑡) with inﬂuence function (13) with 𝑓 𝑜𝑝𝑡(𝑋) and ℎ𝑜𝑝𝑡{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} in (19)
substituted for 𝑓 (𝑋) and ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}, i.e., the eﬃcient inﬂuence function; results for the IPWCC estimator follow from the
argument.

We wish to describe the joint distribution of such estimators at interim analysis times 𝑡1 < ⋯ < 𝑡𝐾 (calendar time). It suﬃces
to consider the bivariate distribution of { ̂𝛽(𝑠), ̂𝛽(𝑡)}, 𝑠 < 𝑡. The large-sample properties of { ̂𝛽(𝑠), ̂𝛽(𝑡)} are determined by the
covariance matrix of the corresponding inﬂuence functions for ̂𝛽(𝑠) and ̂𝛽(𝑡).

Using

𝐼(𝐸 ≤ 𝑡)
pr(𝐸 ≤ 𝑡)

Δ(𝑡)𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)
𝑡{𝑈 (𝑡)}

=

𝐼(𝐸 ≤ 𝑡)
pr(𝐸 ≤ 𝑡)

𝜇(ℎ𝑜𝑝𝑡, 𝑢) = 𝐸

ℎ𝑜𝑝𝑡{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}

⎡
⎢
⎢
⎣
𝑇 ≥ 𝑢

=

𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) −

{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) − 𝜇(𝑚, 𝑢; 𝛼0, 𝛽0)}

,

𝑡

∫
0

𝑐 (𝑢)

𝑑𝑀 (𝑡)
𝑡(𝑢)

⎤
(A1)
⎥
⎥
⎦

=

𝐸{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)

[

𝑡(𝑢)

𝑇 ≥ 𝑢}
]
|

=

[

𝜇(𝑚, 𝑢; 𝛼0, 𝛽0)
𝑡(𝑢)

,

𝐸

𝐸{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)

𝑇 ≥ 𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}

𝑇 ≥ 𝑢

𝑡(𝑢)
|

]

|

and denoting the available data at interim analysis times 𝑠 and 𝑡 by (𝑠) and (𝑡) as in (11), the eﬃcient inﬂuence function for
̂𝛽(𝑡) is given by

|

𝑚𝑡((𝑡); 𝛼0,𝛽0) =

𝐼(𝐸 ≤ 𝑡)
pr(𝐸 ≤ 𝑡)

𝑡

−

∫
0

𝑐 (𝑢)

𝑑𝑀 (𝑡)
𝑡(𝑢)

[

{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}

⎛
⎜
⎜
𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋; 𝛼0, 𝛽0)
⎝

𝑇 ≥ 𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}

.

(A2)

(A3)

]⎞
⎟
⎟
⎠

Similarly, denote the eﬃcient inﬂuence function for ̂𝛽(𝑠) as 𝑚𝑠((𝑠); 𝛼0, 𝛽0). For brevity, we suppress dependence of these
inﬂuence functions on 𝛼0, 𝛽0 henceforth.

To demonstrate the independent increments property, it suﬃces to show that

𝐸{𝑚𝑠((𝑠))𝑚𝑡((𝑡))} = var{𝑚𝑡((𝑡))} = 𝐸{𝑚𝑡((𝑡))2}.

(A4)

To this end, recalling that 𝐶(𝑡) = 𝑡 − 𝐸, it is convenient to deﬁne

̃𝑁 (𝑡)

𝑐 (𝑢) = 𝐼{𝐶(𝑡) ≤ 𝑢} = 𝐼(𝐸 ≥ 𝑡 − 𝑢),

̃ (𝑡)(𝑢) = 𝐼{𝐶(𝑡) ≥ 𝑢} = 𝐼(𝐸 ≤ 𝑡 − 𝑢),

|

and note that 𝑡(𝑢) = pr{𝐶(𝑡) ≥ 𝑢
density 𝑞(𝑢), and recalling that Λ(𝑡)
|

𝑐 (𝑢) = − log{𝑡(𝑢)}, it follows that
𝑡(𝑢) = 𝑄(𝑡 − 𝑢)∕𝑄(𝑡),

|
𝑑Λ(𝑡)

𝑐 (𝑢) = {𝑞(𝑡 − 𝑢)∕𝑄(𝑡 − 𝑢)} 𝑑𝑢.

𝐸 ≤ 𝑡} = pr(𝐸 ≤ 𝑡 − 𝑢

𝐸 ≤ 𝑡). Denoting the distribution of 𝐸 by 𝑄(𝑢) = pr(𝐸 ≤ 𝑢), with

Thus, if we write

𝑑 ̃𝑀(𝑡 − 𝑢) = 𝑑 ̃𝑁 (𝑡)

𝑐 (𝑢) − 𝑑Λ(𝑡)

𝑐 (𝑢) ̃ (𝑡)(𝑢) = −𝑑𝐼(𝐸 ≥ 𝑡 − 𝑢) −

𝑞(𝑡 − 𝑢)
𝑄(𝑡 − 𝑢)

𝐼(𝐸 ≤ 𝑡 − 𝑢) 𝑑𝑢,

(A5)

TSIATIS and DAVIDIAN

19

then using 𝑁 (𝑡)

𝑐 (𝑢) = 𝐼{𝐶(𝑡) ≤ 𝑢, 𝑇 ≥ 𝑢} and  (𝑡)(𝑢) = 𝐼{𝐶(𝑡) ≥ 𝑢, 𝑇 ≥ 𝑢}, the martingale integral (A3) can be written as

𝑡

−

∫
0

= −

∫
0

𝑑 ̃𝑀(𝑡 − 𝑢)𝐼(𝑇 ≥ 𝑢)
𝑄(𝑡 − 𝑢)∕𝑄(𝑡)

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)}

𝑡

[
𝑑 ̃𝑀(𝑥)𝐼(𝑇 ≥ 𝑡 − 𝑥)
𝑄(𝑥)∕𝑄(𝑡)

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

(A6)

|

]

with change of variable 𝑥 = 𝑡 − 𝑢. If we deﬁne the ﬁltration  (𝑥) to be the sigma algebra generated by {𝐼(𝐸 ≥ 𝑥), 𝐸𝐼(𝐸 ≥
𝑥), 𝑌 , 𝐴, 𝑋, ̄𝐿(𝑇 )}, then the integral (A6) is the realization of a  (𝑥)-measurable martingale process. Note that the ﬁltration
 (𝑥) deﬁnes information about 𝐸 to the right (after) 𝑥 rather than as for the usual ﬁltration that deﬁnes information to the left
(before) 𝑥. Thus, (A3) can be written as

|

[

]

−

𝐼(𝐸 ≤ 𝑡)
𝑄(𝑡)

𝑡

∫
0

𝑑 ̃𝑀(𝑥)𝐼(𝑇 ≥ 𝑡 − 𝑥)
𝑄(𝑥)∕𝑄(𝑡)

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

= −

𝑡

∫
0

and the variance of (A3) is

[

𝑑 ̃𝑀(𝑥)𝐼(𝑇 ≥ 𝑡 − 𝑥)
𝑄(𝑥)

|

]

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

,

[

|

]

𝑡

𝑞(𝑥) 𝑑𝑥∕𝑄(𝑥)
𝑄2(𝑥)

𝐼(𝐸 ≤ 𝑥)𝐼(𝑇 ≥ 𝑡 − 𝑥)

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐸

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

[

|

2

]

⎞
⎟
⎟
⎠

2𝐼(𝑇 ≥ 𝑡 − 𝑥)

.

]

)

𝐸

∫
⎛
0
⎜
⎜
=
⎝

𝑡

∫
0

𝑞(𝑥) 𝑑𝑥
𝑄2(𝑥)

([

Consequently,

var{𝑚𝑡((𝑡))} =

|
var{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}
𝑄(𝑡)

𝑡

+

∫
0

𝑞(𝑥) 𝑑𝑥
𝑄2(𝑥)

𝐸

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

2𝐼(𝑇 ≥ 𝑡 − 𝑥)

,

([

|

]

)

(A7)

and similarly for var{𝑚𝑠((𝑠))}.

From (A4), we thus wish to show that 𝐸{𝑚𝑠((𝑠))𝑚𝑡((𝑡))} is equal to var{𝑚𝑡((𝑡))} in (A7). Using the preceding

developments, we can write

𝑚𝑡((𝑡)) =

𝐼(𝐸 ≤ 𝑡)
𝑄(𝑡)

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}

𝑡

−

∫
0

𝑑 ̃𝑀(𝑥)
𝑄(𝑥)

[

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐼(𝑇 ≥ 𝑡 − 𝑥)

𝑚𝑠((𝑠)) =

𝐼(𝐸 ≤ 𝑠)
𝑄(𝑠)

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}

|

]

𝑠

−

∫
0

𝑑 ̃𝑀(𝑥)
𝑄(𝑥)

[

accordingly,

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑠 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑠 − 𝑥)}

𝐼(𝑇 ≥ 𝑠 − 𝑥);

|

]

𝐸{𝑚𝑠((𝑠))𝑚𝑡((𝑡))} = (𝐴8) × (𝐴10) + (𝐴8) × (𝐴11) + (𝐴9) × (𝐴10) + (𝐴9) × (𝐴11).

We consider each of these terms in turn.

(A8)

(A9)

(A10)

(A11)

20

Using 𝑠 ≤ 𝑡, it is straightforward that

𝐸{(𝐴8) × (𝐴10)} = 𝐸

TSIATIS and DAVIDIAN

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}2

𝐼(𝐸 ≤ 𝑠)
𝑄(𝑠)𝑄(𝑡)

[

=

var{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}
𝑄(𝑡)

]

.

(A12)

Similarly,

𝐸{(𝐴8) × (𝐴11)} = 𝐸

−

⎛
⎜
⎜
×
⎝

𝑠

∫
0

𝑑 ̃𝑀(𝑥)
𝑄(𝑥)

[

𝐼(𝐸 ≤ 𝑠)
𝑄(𝑡)

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑠 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑠 − 𝑥)}

𝐼(𝑇 ≥ 𝑠 − 𝑥)

]

⎞
⎟
⎟
⎠

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}
𝑄(𝑡)

𝑠

∫
0

𝑑 ̃𝑀(𝑥)
𝑄(𝑥)

[

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

= 𝐸

⎛
⎜
⎜
×
⎝

= 0

|

|

𝑇 ≥ 𝑠 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑠 − 𝑥)}

𝐼(𝑇 ≥ 𝑠 − 𝑥)

]

⎞
⎟
⎟
⎠

(A13)

because {𝑚(𝑌 , 𝐴, 𝑋)−(𝐴−𝜋)𝑓 𝑜𝑝𝑡(𝑋)} is  (𝑠)-predictable, so that the expectation is zero by the martingale property of stochastic
integrals.

By the martingale property,

𝐸{(𝐴9) × (𝐴11)} =

𝑠

∫
0

𝑞(𝑥)𝑑𝑥
𝑄2(𝑥)

([

The expectation in the intetgral in (A14) can be written as

[

×

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝐸

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝑇 ≥ 𝑠 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑠 − 𝑥)}

|

]

𝐼(𝑇 ≥ 𝑡 − 𝑥)

.

]

)

(A14)

|

𝐸

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

2𝐼(𝑇 ≥ 𝑡 − 𝑥)

([
− 𝐸

𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)} − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

]

𝑇 ≥ 𝑠 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑠 − 𝑥)}

)

(A15)

×

([
𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

|

|
𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐼(𝑇 ≥ 𝑡 − 𝑥)
|

.

]

The diﬀerence of conditional expectations in brackets in (A15) is some function 𝑔{𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}, in which case the last two
lines of (A15) can be written as

]

[

|

)

𝐸

𝑔{𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐼(𝑇 ≥ 𝑡 − 𝑥)

(
= 𝐸

= 𝐸

𝑔{𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}
[

𝐸
𝑔{𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}
{

(

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}
𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)} − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

]

|

𝐸{𝑚(𝑌 , 𝐴, 𝑋)

[

)

𝐼(𝑇 ≥ 𝑡 − 𝑥)
𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}
]
)

∣ 𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)

|

|

|

𝐼(𝑇 ≥ 𝑡 − 𝑥)

}

)

]

= 0.

(
It follows that

𝐸{(𝐴9) × (𝐴11)} =

[

𝑠

∫
0

𝑞(𝑥)𝑑𝑥
𝑄2(𝑥)

𝐸

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

([

|

2

]

𝐼(𝑇 ≥ 𝑡 − 𝑥)

.

(A16)

)

−𝐸

−𝐸

𝐼(𝐸 ≤ 𝑠)
𝑄(𝑠)

⎛
⎜
⎜
×
⎝

⎛
⎜
⎜
×
⎝

𝑠

∫
0

𝑑 ̃𝑀(𝑥)
𝑄(𝑥)

[

𝐼(𝐸 ≤ 𝑠)
𝑄(𝑠)

𝑡

∫
𝑠

𝑑 ̃𝑀(𝑥)
𝑄(𝑥)

[

TSIATIS and DAVIDIAN

Finally, consider

𝐸{(𝐴9) × (𝐴10)} = −𝐸

𝑡

×

∫
0

We can write (A17) as

𝐼(𝐸 ≤ 𝑠)
𝑄(𝑠)

⎛
⎜
𝑑 ̃𝑀(𝑥)
⎜
⎝
𝑄(𝑥)

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}

21

(A17)

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐼(𝑇 ≥ 𝑡 − 𝑥)

.

[

|

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}

]

⎞
⎟
⎟
⎠

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐼(𝑇 ≥ 𝑡 − 𝑥)

(A18)

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}

|

]

⎞
⎟
⎟
⎠

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐼(𝑇 ≥ 𝑡 − 𝑥)

.

(A19)

Because {𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)} is  (𝑠)-predictable, (A18) is equal to zero. Thus, consider (A19). Recalling from (A5)
that

|

]

⎞
⎟
⎟
⎠

𝑑 ̃𝑀(𝑥) = −𝑑𝐼(𝐸 ≥ 𝑥) −

𝐼(𝐸 ≤ 𝑥)𝑑𝑥

𝑞(𝑥)
𝑄(𝑥)

and noting that for 𝑥 ≥ 𝑠

𝐼(𝐸 ≤ 𝑠){−𝑑𝐼(𝐸 ≥ 𝑥)} = 0,

𝐼(𝐸 ≤ 𝑠)𝐼(𝐸 ≤ 𝑥) = 𝐼(𝐸 ≤ 𝑠),

it follows that (A19) can be written as

𝐸

∫
⎛
𝑠
⎜
⎜
=
⎝

𝑡

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}
𝑄(𝑠)

𝑞(𝑥)𝑑𝑥
𝑄2(𝑥)

𝐼(𝐸 ≤ 𝑠)

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐼(𝑇 ≥ 𝑡 − 𝑥)

𝑡

∫
𝑠

𝑞(𝑥)𝑑𝑥
𝑄2(𝑥)

𝐸

{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐼(𝑇 ≥ 𝑡 − 𝑥)

.

[

|

]

(

[

|

]

)
(A20)

⎞
⎟
⎟
⎠

Write the expectation in the integrand of (A20) as

𝐸

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

2𝐼(𝑇 ≥ 𝑡 − 𝑥)

([
+ 𝐸
×

𝐸{𝑚(𝑌 , 𝐴, 𝑋)

|
{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)
([

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)} − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)

]
𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

𝐼(𝑇 ≥ 𝑡 − 𝑥)
]

.

)

(A21)

Because the term in brackets in (A21) is some function 𝑔∗{𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}, say, it follows by an argument similar to that above
that the last two lines are equal to zero, and thus (A17) is equal to

)

]

[

|

|

𝐸{(𝐴9) × (𝐴10)} =

𝑡

∫
𝑠

𝑞(𝑥)𝑑𝑥
𝑄2(𝑥)

𝐸

{𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

2𝐼(𝑇 ≥ 𝑡 − 𝑥)

.

(A22)

([

|

]

)

22

TSIATIS and DAVIDIAN

Combining the results in (A12), (A13), (A16), and (A22) demonstrates the desired result that
var{𝑚(𝑌 , 𝐴, 𝑋) − (𝐴 − 𝜋)𝑓 𝑜𝑝𝑡(𝑋)}
𝑄(𝑡)

𝐸{𝑚𝑠((𝑠))𝑚𝑡((𝑡))} =

𝑡

+

∫
0

𝑞(𝑥)𝑑𝑥
𝑄2(𝑥)

𝐸

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥, 𝑋, 𝐴, ̄𝐿(𝑡 − 𝑥)}

2𝐼(𝑇 ≥ 𝑡 − 𝑥)

,

([

|

]

)

which is (A7).

Note that the inﬂuence function for the IPWCC estimator solving (15) is given by (13) with 𝑓 (𝑋) = ℎ{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} ≡ 0.

Using the equality (A1) and the deﬁnition of ̃𝑀(𝑥), the inﬂuence function for the IPWCC estimator can be written as

𝑚𝐼𝑃 𝑊
𝑡

((𝑡)) =

𝐼(𝐸 ≤ 𝑡)
𝑄(𝑡)

𝑚(𝑌 , 𝐴, 𝑋) −

𝑡

∫
0

𝑑 ̃𝑀(𝑥)
𝑄(𝑥)

[

That 𝐸{𝑚𝐼𝑃 𝑊
IPWCC estimator also has the independent increments property.

((𝑠))} = var{𝑚𝐼𝑃 𝑊

((𝑠))𝑚𝐼𝑃 𝑊

𝑠

𝑡

𝑡

𝑚(𝑌 , 𝐴, 𝑋) − 𝐸{𝑚(𝑌 , 𝐴, 𝑋)

𝑇 ≥ 𝑡 − 𝑥}

𝐼(𝑇 ≥ 𝑡 − 𝑥).

((𝑡))} follows by an argument analogous to that above, demonstrating that the

|

]

In the practical implementation discussed in Section 4, the optimal choices 𝑓 𝑜𝑝𝑡(𝑋) and ℎ𝑜𝑝𝑡{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} are approximated
using linear combinations of basis functions. Accordingly, the resulting AIPWCC estimators obtained via the two-step algorithm
may not be fully eﬃcient and thus are not guaranteed to have the independent increments property. However, as demonstrated in
our simulation studies, because the approximations to 𝑓 𝑜𝑝𝑡(𝑋) and ℎ𝑜𝑝𝑡{𝑢, 𝑋, 𝐴, ̄𝐿(𝑢)} are often quite good, the estimators them-
selves are good approximations to the eﬃcient estimator and thus exhibit behavior very close to that of independent increments,
so that the operating characteristics of the trial are preserved.

B ADDITIONAL SIMULATION RESULTS

Simulation Scenario 1: Ordinal Categorical Outcome: Under the null hypothesis, based on 10000 Monte Carlo data sets, the
Monte Carlo sample covariance matrices of { ̂𝛽(𝑡1), … , ̂𝛽(𝑡4), ̂𝛽(𝑡𝑒𝑛𝑑)}, where ̂𝛽(𝑡) is each of ̂𝛽𝐹
(𝑡), ̂𝛽𝐼𝑃 𝑊 (𝑡), ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡), and
̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡), are given by

betahat_Tf

[,1] [,2] [,3] [,4] [,5]
[1,] 0.086 0.049 0.034 0.026 0.021
[2,] 0.049 0.049 0.034 0.026 0.021
[3,] 0.034 0.034 0.034 0.026 0.021
[4,] 0.026 0.026 0.026 0.026 0.021
[5,] 0.021 0.021 0.021 0.021 0.021

betahat_IPW
[1,] 0.054 0.036 0.027 0.023 0.022
[2,] 0.036 0.036 0.027 0.023 0.022
[3,] 0.027 0.027 0.028 0.023 0.022
[4,] 0.023 0.023 0.023 0.023 0.022
[5,] 0.022 0.022 0.022 0.022 0.022

betahat_AIPW1

[,1] [,2] [,3] [,4] [,5]
[1,] 0.049 0.031 0.023 0.019 0.018
[2,] 0.031 0.032 0.023 0.019 0.018
[3,] 0.023 0.023 0.024 0.020 0.019
[4,] 0.019 0.019 0.020 0.020 0.018
[5,] 0.018 0.018 0.019 0.018 0.018

TSIATIS and DAVIDIAN

betahat_AIPW2

[,1] [,2] [,3] [,4] [,5]
[1,] 0.041 0.027 0.022 0.019 0.019
[2,] 0.027 0.028 0.021 0.019 0.018
[3,] 0.022 0.021 0.022 0.019 0.019
[4,] 0.019 0.019 0.019 0.019 0.018
[5,] 0.019 0.018 0.019 0.018 0.018

Under the alternative 𝛽𝐴 = log(1.5), the analogous Monte Carlo sample covariance matrices are

23

betahat_Tf

[,1] [,2] [,3] [,4] [,5]
[1,] 0.087 0.048 0.034 0.026 0.021
[2,] 0.048 0.049 0.034 0.026 0.021
[3,] 0.034 0.034 0.034 0.027 0.022
[4,] 0.026 0.026 0.027 0.027 0.022
[5,] 0.021 0.021 0.022 0.022 0.022

betahat_IPW

[,1] [,2] [,3] [,4] [,5]
[1,] 0.055 0.036 0.028 0.023 0.022
[2,] 0.036 0.036 0.028 0.023 0.022
[3,] 0.028 0.028 0.028 0.024 0.022
[4,] 0.023 0.023 0.024 0.024 0.022
[5,] 0.022 0.022 0.022 0.022 0.022

betahat_AIPW1

[,1] [,2] [,3] [,4] [,5]

[1,] 0.050 0.032 0.024 0.020 0.019
[2,] 0.032 0.032 0.024 0.020 0.019
[3,] 0.024 0.024 0.025 0.020 0.019
[4,] 0.020 0.020 0.020 0.020 0.019
[5,] 0.019 0.019 0.019 0.019 0.019

betahat_AIPW2
[1,] 0.042 0.027 0.022 0.019 0.019
[2,] 0.027 0.029 0.022 0.019 0.019
[3,] 0.022 0.022 0.022 0.019 0.019
[4,] 0.019 0.019 0.019 0.019 0.019
[5,] 0.019 0.019 0.019 0.019 0.019

These results clearly demonstrate that the independent increments property holds approximately for all estimators.

Simulation Scenario 2: Binary Outcome: Under the null hypothesis, based on 10000 Monte Carlo data sets, the Monte Carlo
sample covariance matrices of { ̂𝛽(𝑡1), … , ̂𝛽(𝑡4), ̂𝛽(𝑡𝑒𝑛𝑑)}, where ̂𝛽(𝑡) is each of ̂𝛽𝐹
(𝑡), ̂𝛽𝐼𝑃 𝑊 (𝑡), ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡), and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡), are
given by

betahat_Tf

[,1] [,2] [,3] [,4] [,5]
[1,] 0.039 0.022 0.015 0.012 0.009
[2,] 0.022 0.021 0.015 0.011 0.009
[3,] 0.015 0.015 0.015 0.011 0.009
[4,] 0.012 0.011 0.011 0.011 0.009
[5,] 0.009 0.009 0.009 0.009 0.009

TSIATIS and DAVIDIAN

24

betahat_IPW

[,1] [,2] [,3] [,4] [,5]
[1,] 0.018 0.013 0.011 0.009 0.009
[2,] 0.013 0.013 0.010 0.009 0.009
[3,] 0.011 0.010 0.010 0.009 0.009
[4,] 0.009 0.009 0.009 0.009 0.009
[5,] 0.009 0.009 0.009 0.009 0.009

betahat_AIPW1

[,1] [,2] [,3] [,4] [,5]
[1,] 0.017 0.012 0.009 0.008 0.008
[2,] 0.012 0.012 0.009 0.008 0.008
[3,] 0.009 0.009 0.009 0.008 0.008
[4,] 0.008 0.008 0.008 0.008 0.008
[5,] 0.008 0.008 0.008 0.008 0.008

betahat_AIPW2

[,1] [,2] [,3] [,4] [,5]
[1,] 0.017 0.012 0.009 0.008 0.008
[2,] 0.012 0.012 0.009 0.008 0.008
[3,] 0.009 0.009 0.009 0.008 0.008
[4,] 0.008 0.008 0.008 0.008 0.008
[5,] 0.008 0.008 0.008 0.008 0.008

Under the alternative 𝛽𝐴 = log(0.247∕0.33) = −0.290, the analogous Monte Carlo sample covariance matrices are

betahat_Tf

[,1] [,2] [,3] [,4] [,5]
[1,] 0.049 0.027 0.019 0.015 0.012
[2,] 0.027 0.027 0.019 0.014 0.012
[3,] 0.019 0.019 0.019 0.014 0.011
[4,] 0.015 0.014 0.014 0.014 0.011
[5,] 0.012 0.012 0.011 0.011 0.011

betahat_IPW

[,1] [,2] [,3] [,4] [,5]
[1,] 0.023 0.017 0.013 0.012 0.012
[2,] 0.017 0.017 0.013 0.012 0.011
[3,] 0.013 0.013 0.013 0.011 0.011
[4,] 0.012 0.012 0.011 0.011 0.011
[5,] 0.012 0.011 0.011 0.011 0.011

betahat_AIPW1

[,1] [,2] [,3] [,4] [,5]

[1,] 0.022 0.015 0.012 0.010 0.010
[2,] 0.015 0.015 0.012 0.010 0.010
[3,] 0.012 0.012 0.012 0.010 0.010
[4,] 0.010 0.010 0.010 0.010 0.010
[5,] 0.010 0.010 0.010 0.010 0.010

TSIATIS and DAVIDIAN

25

TABLE B1 For Scenario 2 with binary outcome, performance of estimators for 𝛽 under (a) the null hypothesis 𝛽 = 0 and (b)
the alternative 𝛽 = log(0.247∕0.33) = −0.290 at each interim analysis time (𝑡1, … , 𝑡4) = (150, 195, 240, 285) days and at the
ﬁnal analysis at 𝑡𝑒𝑛𝑑 = 330 days MC Mean is the mean of 10000 Monte Carlo estimates; MC SD is the Monte Carlo standard
deviation, Ave MC SE is the mean of Monte Carlo standard errors, and MSE ratio is the ratio of Monte Carlo mean square error
for the AIPW2 estimator divided by that for the indicated estimator.

MC Mean MC SD

Ave MC SE MSE ratio

MC Mean MC SD

Ave MC SE MSE ratio

(a) Null Hypothesis

̂𝛽𝐹

(𝑡)

0.193
0.145
0.121
0.106
0.095

̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)

0.128
0.109
0.097
0.090
0.090

0.216
0.162
0.135
0.118
0.107

̂𝛽𝐹

(𝑡)

̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)

0.146
0.123
0.109
0.102
0.101

0.197
0.146
0.122
0.106
0.096

0.130
0.110
0.097
0.090
0.090

0.220
0.164
0.136
0.119
0.107

0.147
0.124
0.110
0.102
0.101

0.003
0.000
0.000
0.000
0.000

0.000
0.000
-0.001
0.000
0.000

-0.291
-0.291
-0.292
-0.291
-0.290

-0.291
-0.291
-0.291
-0.290
-0.290

1.000
1.000
1.000
1.000
1.000

2.302
1.761
1.587
1.389
1.123

0.000
0.000
-0.001
0.000
0.000

0.001
0.000
-0.001
0.000
0.000

(b) Alternative Hypothesis

1.000
1.000
1.000
1.000
1.000

2.246
1.734
1.545
1.377
1.109

-0.292
-0.291
-0.291
-0.290
-0.290

-0.291
-0.291
-0.291
-0.290
-0.290

̂𝛽𝐼𝑃 𝑊 (𝑡)

0.136
0.115
0.102
0096
0.096

0.134
0.114
0.101
0.095
0.095

̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

0.130
0.110
0.097
0.090
0.090

0.153
0.130
0.115
0.107
0.107

0.128
0.109
0.096
0.090
0.090

̂𝛽𝐼𝑃 𝑊 (𝑡)

0.151
0.129
0.114
0.107
0.107

̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

0.147
0.124
0.109
0.102
0.101

0.145
0.123
0.109
0.101
0.101

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

2.097
1.600
1.433
1.237
1.000

2.300
1.759
1.591
1.389
1.123

2.072
1.591
1.412
1.242
1.000

2.249
1.736
1.548
1.373
1.109

betahat_AIPW2

[,1] [,2] [,3] [,4] [,5]

[1,] 0.022 0.015 0.012 0.010 0.010
[2,] 0.015 0.015 0.012 0.010 0.010
[3,] 0.012 0.012 0.012 0.010 0.010
[4,] 0.010 0.010 0.010 0.010 0.010
[5,] 0.010 0.010 0.010 0.010 0.010

These results clearly demonstrate that the independent increments property holds approximately for all estimators.

Table B1 presents performance of the estimators under the null and alternative hypotheses.

26

TSIATIS and DAVIDIAN

Simulation Scenario 3: Continuous Outcome: Under the null hypothesis, based on 10000 Monte Carlo data sets, the Monte
(𝑡), ̂𝛽𝐼𝑃 𝑊 (𝑡), ̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡), and ̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡),
Carlo sample covariance matrices of { ̂𝛽(𝑡1), … , ̂𝛽(𝑡4), ̂𝛽(𝑡𝑒𝑛𝑑)}, where ̂𝛽(𝑡) is each of ̂𝛽𝐹
are given by

betahat_Tf

[,1] [,2] [,3] [,4] [,5]
[1,] 11.67 7.84 5.85 4.65 3.85
[2,] 7.84 7.89 5.87 4.69 3.90
[3,] 5.85 5.87 5.83 4.65 3.87
[4,] 4.65 4.69 4.65 4.63 3.86
[5,] 3.85 3.90 3.87 3.86 3.88

\betahat_IPW

[,1] [,2] [,3] [,4] [,5]
[1,] 11.67 7.84 5.85 4.65 3.85
[2,] 7.84 7.89 5.87 4.69 3.90
[3,] 5.85 5.87 5.83 4.65 3.87
[4,] 4.65 4.69 4.65 4.63 3.86
[5,] 3.85 3.90 3.87 3.86 3.88

\betaht_AIPW1

[,1] [,2] [,3] [,4] [,5]
[1,] 10.65 6.81 4.82 3.82 3.14
[2,] 6.81 7.08 5.04 3.86 3.19
[3,] 4.82 5.04 5.13 3.96 3.16
[4,] 3.82 3.86 3.96 3.94 3.16
[5,] 3.14 3.19 3.16 3.16 3.17

betahat_AIPW2

[,1] [,2] [,3] [,4] [,5]
[1,] 7.92 5.47 4.27 3.50 3.17
[2,] 5.47 5.44 4.17 3.49 3.16
[3,] 4.27 4.17 4.15 3.48 3.16
[4,] 3.50 3.49 3.48 3.46 3.16
[5,] 3.17 3.16 3.16 3.16 3.17

Under the alternative 𝛽𝐴 = 6.24, the analogous Monte Carlo sample covariance matrices are

betahat_Tf

[,1] [,2] [,3] [,4] [,5]
[1,] 11.71 7.87 5.88 4.67 3.86
[2,] 7.87 7.92 5.90 4.71 3.91
[3,] 5.88 5.90 5.85 4.67 3.89
[4,] 4.67 4.71 4.67 4.65 3.88
[5,] 3.86 3.91 3.89 3.88 3.89

27

TSIATIS and DAVIDIAN

betahat_IPW

[,1] [,2] [,3] [,4] [,5]
[1,] 11.71 7.87 5.88 4.67 3.86
[2,] 7.87 7.92 5.90 4.71 3.91
[3,] 5.88 5.90 5.85 4.67 3.89
[4,] 4.67 4.71 4.67 4.65 3.88
[5,] 3.86 3.91 3.89 3.88 3.89

betahat_AIPW1

[,1] [,2] [,3] [,4] [,5]
[1,] 10.69 6.84 4.84 3.83 3.15
[2,] 6.84 7.10 5.06 3.87 3.20
[3,] 4.84 5.06 5.15 3.97 3.18
[4,] 3.83 3.87 3.97 3.95 3.17
[5,] 3.15 3.20 3.18 3.17 3.18

betahat_AIPW2

[,1] [,2] [,3] [,4] [,5]
[1,] 7.94 5.49 4.29 3.52 3.18
[2,] 5.49 5.46 4.18 3.51 3.17
[3,] 4.29 4.18 4.16 3.49 3.18
[4,] 3.52 3.51 3.49 3.47 3.18
[5,] 3.18 3.17 3.18 3.18 3.18

Table B2 presents performance of the estimators under the null and alternative hypotheses.

28

TSIATIS and DAVIDIAN

TABLE B2 For Scenario 3 with continuous outcome, performance of estimators for 𝛽 under (a) the null hypothesis 𝛽 = 0 and
(b) the alternative 𝛽 = 6.24 at each interim analysis time (𝑡1, … , 𝑡4) = (104, 130, 156, 182) days and at the ﬁnal analysis at
𝑡𝑒𝑛𝑑 = 208 days MC Mean is the mean of 10000 Monte Carlo estimates; MC SD is the Monte Carlo standard deviation, Ave
MC SE is the mean of Monte Carlo standard errors, and MSE ratio is the ratio of Monte Carlo mean square error for the AIPW2
estimator divided by that for the indicated estimator.

MC Mean MC SD

Ave MC SE MSE ratio

MC Mean MC SD

Ave MC SE MSE ratio

(a) Null Hypothesis

̂𝛽𝐹

(𝑡)

3.415
2.781
2.407
2.151
1.962

̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)

3.222
2.609
2.247
1.975
1.772

3.421
2.786
2.411
2.154
1.966

̂𝛽𝐹

(𝑡)

̂𝛽𝐴𝐼𝑃 𝑊 1(𝑡)

3.227
2.613
2.250
1.979
1.775

3.416
2.809
2.414
2.152
1.969

3.264
2.660
2.265
1.985
1.780

3.422
2.815
2.419
2.157
1.973

3.269
2.665
2.269
1.989
1.783

0.012
0.010
-0.001
-0.005
0.005

0.007
-0.006
0.002
-0.001
0.008

6.230
6.208
6.216
6.213
6.223

6.225
6.212
6.220
6.217
6.226

1.000
1.000
1.000
1.000
1.000

1.095
1.115
1.136
1.176
1.225

0.012
0.010
-0.001
-0.005
0.005

-0.009
-0.003
0.001
-0.001
0.008

(b) Alternative Hypothesis

1.000
1.000
1.000
1.000
1.000

1.096
1.115
1.137
1.176
1.225

6.230
6.208
6.216
6.213
6.223

6.210
6.216
6.219
6.217
6.226

̂𝛽𝐼𝑃 𝑊 (𝑡)

3.416
2.809
2.414
2.152
1.969

3.380
2.763
2.395
2.142
1.956

̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

2.813
2.332
2.037
1.859
1.780

3.422
2.815
2.419
2.157
1.973

2.721
2.284
2.014
1.839
1.772

̂𝛽𝐼𝑃 𝑊 (𝑡)

3.386
2.768
2.399
2.146
1.959

̂𝛽𝐴𝐼𝑃 𝑊 2(𝑡)

2.818
2.336
2.041
1.863
1.783

2.726
2.288
2.017
1.842
1.775

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

𝑡1
𝑡2
𝑡3
𝑡4
𝑡𝑒𝑛𝑑

1.000
1.000
1.000
1.000
1.000

1.474
1.452
1.405
1.340
1.225

1.000
1.000
1.000
1.000
1.000

1.474
1.452
1.405
1.341
1.225

TSIATIS and DAVIDIAN

References

29

1. Tsiatis A. Information-based monitoring of clinical trials. Stat Med 2006; 25: 3236–3244.

2. Pocock S. Group sequential methods in the design and analysis of clinical trials. Biometrika 1977; 64: 191–199.

3. O’Brien P, Fleming T. A multiple testing procedure for clinical trials. Biometrics 1979; 35: 549–556.

4. ClinicalTrials.gov, National Library of Medicine (US) . ACTIV-3b: Therapeutics for Severely Ill Inpatients With COVID-19

(TESICO). NCT04843761. https://clinicaltrials.gov/ct2/show/NCT04843761; .

5. ClinicalTrials.gov, National Library of Medicine (US) . ACTIV-2: A Study for Outpatients With COVID-19. NCT04518410.

https://clinicaltrials.gov/ct2/show/NCT04518410; .

6. Lu X, Tsiatis A. Semiparametric estimation of treatment eﬀect with time-lagged response in the presence of informative

censoring. Lifetime Data Anal 2011; 17: 566–593.

7. Tsiatis A. Semiparametric Theory and Missing Data. New York, NY: Springer . 2006.

8. Scharfstein D, Tsiatis A, Robins J. Semiparametric eﬃciency and its implication on the design and analysis of group

sequential studies. J Am Stat Assoc 1997; 92: 1342–1350.

9. Lan K, DeMets D. Discrete sequential boundaries for clinical trials. Biometrika 1983; 70: 659–663.

10. Tsiatis A, Davidian M, Holloway S. Estimation of the odds ratio in a proportional odds model with censored time-lagged

outcome in a randomized clinical trial. Biometrics 2021; 78: 1–13.

11. Hellmich M. Monitoring clinical trials with multiple arms. Biometrics 2001; 57: 892–898.

12. Wason J. Design of multi-arm, multi-stage trials in oncology. In: Halabi S, Michiels S., eds. Textbook of Clinical Trials in

Oncology: A Statistical Perspective. New York: Chapman and Hall/CRC Press. 2019 (pp. 155-182).

13. Agresti A. An Introduction to Categorical Data Analysis. New York, NY: Wiley . 2019.

14. Stefanski L, Boos D. The calculus of M-estimation. Amer Statist 2002; 56: 29–38.

15. Zhang M, Tsiatis A, Davidian M. Improving eﬃciency of inferences in randomized clinical trials using auxiliary covariates.

Biometrics 2008; 64: 707–715.

16. Kim KM, Tsiatis AA. Independent increments in group sequential tests: a review. SORT - Statistics and Operations Research

Transactions 2020; 44: 223–264.

17. Casper C, Cook T, Perez OA. Package ldbounds: Lan-DeMets method for group sequential boundaries. Comprehensive R

Archive Network. https://cran.r-project.org/package=ldbounds; .

18. Mehta CR, Tsiatis AA. Flexible sample size considerations using information-based interim monitoring. Drug Info J 2001;

35: 1095–1112.

19. Venables W, Ripley B. Modern Applied Statistics with S, 4th edition. New York, NY: Springer . 2002.

