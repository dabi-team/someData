2
2
0
2

r
p
A
2
1

]
S
A
.
s
s
e
e
[

1
v
9
0
6
5
0
.
4
0
2
2
:
v
i
X
r
a

LOW LATENCY TIME DOMAIN MULTICHANNEL SPEECH AND MUSIC SOURCE
SEPARATION

Gerald Schuller

Ilmenau University of Technology,
98693 Ilmenau,
Germany

ABSTRACT

The Goal is to obtain a simple multichannel source separa-
tion with very low latency. Applications can be teleconfer-
encing, hearing aids, augmented reality, or selective active
noise cancellation. These real time applications need a very
low latency, usually less than about 6 ms, and low complex-
ity, because they usually run on small portable devices. For
that we don’t need the best separation, but “useful” separa-
tion, and not just on speech, but also music and noise. Usual
frequency domain approaches have higher latency and com-
plexity. Hence we introduce a novel probabilistic optimiza-
tion method which we call ”Random Directions”, which can
overcome local minima, applied to a simple time domain un-
mixing structure, and which is scalable for low complexity.
Then it is compared to frequency domain approaches on sep-
arating speech and music sources, and using 3D microphone
setups.

Index Terms— Zeroth-Order Optimization, Random Di-
rections, multichannel source separation, low delay separa-
tion

use time-domain unmixing ﬁlters, like ”Trinicon” [3], which
uses FIR unmixing ﬁlters. This leads to objective functions
for ﬁnding the systems parameters which can be highly non-
convex, for which the usual gradient based methods usually
fail. Hence the presented approach uses a zeroth-order opti-
mization method instead, the method of Random Directions,
which is more robust against local minima. A difference in
practice is that probabilistic methods don’t have exactly the
same results every time they are executed, hence the compu-
tation of the standard deviations of the results is also impor-
tant.

2. NEW APPROACH

The presented new approach uses the time domain, with a
fractional delay IIR ﬁlters [4] and attenuation factors. This
models the propagation delays of the sources between the mi-
crophones, together with an attenuation factor. These frac-
tional delays and attenuation factors are the unmixing coefﬁ-
cients which the optimization has to ﬁnd.

1. INTRODUCTION

2.1. Parallel Processing

The goals of this paper are to obtain a simple multichannel
source separation with very low latency. Applications for
it can be teleconferencing, hearing aids, augmented reality,
or selective active noise cancellation. These real time appli-
cations need a very low algorithmic delay, usually less than
about 6 ms. Also those applications need separation not just
for speech, but also for music and noise.

Previous approaches usually use the frequency domain for
separation, usually using the Short Time Fourier Transform
(STFT). Their STFT typically has a block size of 4096, and
hop size of 2048 samples. The hop size alone leads to an al-
gorithmic delay of 2047 samples. This is 128ms at 16 kHz
sampling rate, which is too much for our applications. Exam-
ples for the frequency domain separation are FastMNMF [1]
or AuxIVA [2].

To obtain the least possible algorithmic delay, the time do-
main should be used for separation instead, which means to

The determination of suitable unmixing ﬁlters takes some sig-
nal time. To avoid this causing a delay, it can be computed in
a parallel thread, while already processing the signal in the
time domain. This means the separation in the beginning is
not at its best, but it improves quickly as more of the signal
is processed. In this way an algorithmic delay in the order of
the fractional delays between the microphones is possible.

These are the two parallel threads,

• unmixing in the time domain,

• periodic optimization of the unmixing coefﬁcients in a

parallel thread.

2.2. Signal Accumulation

The processing complexity for the unmixing coefﬁcients in-
creases with the signal length. To reduce this complexity, the
signal can be ”accumulated” in a short signal block of about

 
 
 
 
 
 
0.5s length. The assumption for it is that the solution for
the coefﬁcients is not changed by this pre-processing. It can
even argued that this superposition of the signal with itself
may help the optimization, since it makes the signal more
broadband. This is shown in the following code:

blocksize=8000; blockno=0
for i in range(min(blocks,16)):
#accumulate audio blocks over ca. 3 sec:
blockaccumulator=0.98*blockaccumulator +
0.02*X[blockno*blocksize+np.arange(blocksize)]
blockno+=1

2.3. The Unmixing Function

Let S be the number of sources, M be the number of micro-
phones, Xi(z) be the i-th microphone signal in the z-domain,
Yi(z): the i-th separated source, with a being the attenuation
factors and d the fractional delays, and with the signal vectors,

X = [X1(z), . . . , XM (z)] , Y = [Y1(z), . . . , YS(z)]

Then the unmixing function of the presented method is,

X ·



a1,1z−d1,1




aM,1z−dM,1

a1,Sz−d1,S

...
...
... aM,Sz−dM,S




 = Y

(1)

This models the delays and attenuations from a source sig-
nal between the different microphones. Observe that it does
not model the room impulse response, hence the effect of the
room on the sound is not canceled.

2.4. The Objective Function

Instead,

The objective function for the optimization should be a
measure of statistical independence between the separated
sources. Mutual information would measure it, but is com-
the negative Kullback-Leibler
plex to compute.
divergence between all pairs of separated sources is used.
The shown example has only one source pair, for simplicity.
Since a possible minimum of the objective function is also
obtained by setting an output source simply to zero, or very
small values, we also include a power preservation coefﬁcient
P = |1 − powerin/powerout|. The Kullback-Leibler Diver-
gence DKL indicates how different 2 signals are, hence we
want to minimize its negative value for the output sources. A
Lagrange multiplier is used to combine those two functions
into one objective function f = −DKL +λ·P . The Lagrange
multiplier λ was set to 0.1.

The objective function ´together with the unmixing func-
tion represents a very non-convex objective function with
many local minima. Hence the zeroth-order optimization of
[5] is used, which turns out to be relatively robust against
local minima, and which is described next.

3. ZEROTH-ORDER OPTIMIZATION

Zeroth-order optimization uses no gradient, unlike the com-
monly used Gradient Descent algorithm, or its use in the LMS
algorithm. Gradient Descend can be seen as ﬁrst-order opti-
mization, with its use of the gradient, and is robust and fast
for convex objective functions, but for non-convex objective
functions it will become stuck at the nearest local minimum.
That is why, for the presented system, Gradient Descent does
not work, and an alternative is needed. Here, the Gradient
is not really helpful, and it could as well be replaced by a
random vector over a given search space. This then leads
to zeroth-order optimization. Zeroth-order optimization can
basically be used where Gradient Descent was used, like for
online optimization. An overview can be found in [6]. Exam-
ples are also Random Pursuit [7], and Gradientless Descent
[8].

3.1. The Method of Random Directions

The proposed method of Random Directions has the advan-
tages that it is realtively fast and has a robust convergence for
our applications; It is not increasing the objective function,
hence its application does not make things worse for difﬁcult
objective functions; and it is still fast for higher coefﬁcient
dimensions.

In the following pseudo code, Algorithm 1, shows the
method of Random Directions. In the beginning it is initial-
ized with a random starting vector x0, the desired number of
iterations T , and parallel processes P . Then there is a ”scale”
parameter. This deﬁnes the size of the search area, the stan-
dard deviation of the random search vector. In the beginning
of the iterations this has a larger value, starting with ”start-
ingscale”. In the presented experiment it was 4.0. The scale
of the search vector is reduced over the duration of the iter-
ations in a non-linear way, until it reaches ”endscale”, which
was chosen as 0.0 in the presented experiment. Next there
is a parallel search using P randomly generated search vec-
tors vp. This is done on a random subspace of coefﬁcients,
to make it more robust for higher dimensions. Non-adaptive
random subspaces are used, here of dimension 8. This means
only 8 entries of vp are non-zero.

From these search vectors, the index of the best vector is
obtained, and then tested if it found a new minimum of the
objective function f . If so, the algorithm uses a coarse line
search for the successful search vector. It was found that this
speeds up convergence in more smooth areas of the objective
function. See also [5]. A simpler version for 2-channel source
separation was described in [9, 10].

Note that the algorithm only makes an update if the ob-
jective function became smaller. This ensures that the appli-
cation of this method can only improve, but not degrade the
performance, an important property for hard to optimize ob-
jective functions. The number of iterations T is chosen ac-

Input: f (x): IRn → IR: Objective function to be

minimized
x0: Starting point vector,
T: Number of iterations,
Number of parallel processes,
startingscale: Standard deviation at the start
endscale: Standard deviation at the end
Initialization: xbest = x0
for m=0,...,T do

scale = endscale + (startingscale −
endscale) · ((1.0 − m/iterations)2)
Parallel Processing:

generate search vectors vp with std deviation
”scale” and zero mean on random subsets of
coefﬁcients;
compute f (xbest + vp)

pbest = arg minp{f (xbest + v) | v = vp}
if f (xbest + vpbest ) < f (xbest) then

Find new xbest with coarse line search along
successful vector vpbest,
kbest = argminkf (xbest + 2kvpbest),
k = (−8, . . . , 8) (Line search)
xbest = xbest + 2kbest vpbest

end

end
return xbest
Algorithm 1: The method of Random Directions.

cording to the power of the available processors. The higher
the better, but it still needs to be able to run in real-time. In the
presented experiment T = 1000 was used. For the number of
parallel processes usually the available number of processors
(CPU’s) can be chosen. In the presented experiments it was
P = 8.

3.1.1. Probabilistic Background

To see how this algorithm works from the probabilistic view-
point, let’s assume x0 is the current starting vector or starting
point, and vp a random search vector, drawn from a symmetri-
cal independent Gaussian probability distribution (the covari-
ance is a diagonal matrix) with zero mean, a given standard
deviation σ (the ”scale”), and with N the dimension of the
search subspace,

p(vp) =

1
σN (cid:112)(2π)N

· e− 1
2 (

|vp |
σ )2

.

(2)

Let’s further assume v∗ is the vector to the true absolute min-
imum, hence at position x0 + v∗. Let V be a region around
v∗ such that the objective function in that region is smaller
than its current value (assuming it is not already in a global
minimum). Hence if vp ∈ V , then f (x0+vp) < f (x0). To es-
timate the probability of success with a search vector, it is as-
sumed that p(vp) is approximately constant over our relatively

small region x0 + V , and the volume of our N-dimensional
region V is Vol(V ). Then the probability of success, hitting
this region, is approximately

p(vp ∈ V ) ≈ p(v∗) · Vol(V ).

(3)

To maximize the probability of success with the random
search vectors, p(v∗), eq. (2), needs to be maximized, with
a properly chosen standard deviation σ. This maximum is
obtained with

√

σ = |v∗|/

N ,

(4)

This means a proper guess of the distance to the minimum
gives a good estimate for the ”scale” σ. Since it can be as-
sumed that the distance to the minimum is iteratively reduced,
the ”scale” needs to be reduced accordingly. This is what
the algorithm is doing with the shrinking of the scale from
”startingscale” to ”endscale”. Eq.
(2) also shows that for
σ > 1/(cid:112)(2π) the probability of success, eq.(3), is reduc-
ing exponentially with the subspace dimension N . Hence at
least in the beginning, for larger distances from the minimum,
it is useful to reduce the dimension using subspaces.

4. COMPARISON, EVALUATION

As comparison method ”Trinicon” is chosen, because it is
also a time domain method. The used implementation is of
the ”pyroomacoustics” Python module. For a more precise
comparison, the same parallel processing was applied. For
both, the ﬁrst ca. 8 seconds of the signal were used to ob-
tain the optimized ﬁlter coefﬁcients. These ﬁlter coefﬁcients
where then used to unmix the entire signal, for simplicity.

(’fantasy-orchestra m16.wav’,

The used audio sources are pairs from speech, and also
noise, and music: Synthetic male speech from ”espeak” [11]
(’espeakwav 16.wav’), synthetic female speech (’espeak-
female 16.wav’), pink noise from ”csound” [12] (’pink-
ish16.wav’),
tones from ”csound” (’oscili test 16.wav’),
and music from [13] (’fantasy-orchestra m16.wav’). The
pairs where (’espeakfemale 16.wav’, ’espeakwav 16.wav’),
(’pinkish16.wav’, ’espeakwav 16.wav’), (’oscili test 16.wav’,
’espeakwav 16.wav’),
’es-
peakwav 16.wav’). They have a sampling rate of 16 kHz and
lengths between 6.3s and 11.8s. The average length of the
pairs (where the shorter signal of a pair is zero padded to
the length of the longer signal) is 8.4s. The shown process-
ing times in Table (1) are from a computer with an Intel(R)
Xeon(R) W-2123 CPU @ 3.60GHz, with 8 CPU’s. As long
as the processing time is below the signal length, the system
is real-time capable. Table (1) shows that for the stereo case,
Random Directions online has a mean processing time of
2.83s, with standard deviation of 0.16s. This is about 3 times
faster. The longest processing time is observed for the case
of the cube microphone setup, with mean 4.57s and standard
deviation of 0.18s. This means that the clock frequency could
be reduced until real time processing speed is reached. If a

further reduction on hardware requirements is desired, the
number of iterations and of parallel processes can be reduced,
at the cost of a gradual reduction of separation performance.
Also observe that Trinicon has a shorter processing time.

4.1. Microphone Setups and Simulated Room

3 microphone setups where testet: A stereo microphone pair,
20cm apart; a square of 4 microphones, 20cm side length; and
a cube of 8 microphones, 20cm side length. The room was
simulated with the Python module ”pyroomacoustics” [14].
The room dimensions are 5m by 4m by 2.5m, and the rever-
beration time was chosen as rt60=0.1s. Two source where
used for the evaluation, at coordinate positions [2.5m, 1.5m,
1.50m] and [2.5m, 3.3m, 1.50m]. The microphones where
centered around coordinates [3.1m, 2.1m, 1.2m], Fig. (1).

method

SIR

SAR

Time

Setup

std.dev.

std.dev.

std.dev.

std.dev.

std.dev.

randdironline mean
randdironline
randdironline mean
randdironline
randdironline mean
randdironline
trinicononline mean
trinicononline
trinicononline mean
trinicononline
trinicononline mean
trinicononline
fastmnmf
fastmnmf
fastmnmf
fastmnmf
fastmnmf
fastmnmf
auxIVA
auxIVA
auxIVA
auxIVA
auxIVA
auxIVA

std.dev.
mean
std.dev.
mean
std.dev.
mean
std.dev.
mean
std.dev.
mean
std.dev.
mean
std.dev.

9.37
4.71
8.03
5.48
4.22
3.44
3.38
1.02
0.98
0.36
1.04
0.63
20.16
15.55
16.6
7.99
12.27
8.87
14.72
12.3
19.7
12.38
16.67
11.28

33.02
8.47
31.28
6.6
30.21
5.83
18.84
4.58
18.06
1.43
19.99
3.52
14.51
10.51
9.88
5.34
7.92
3.79
14.14
6.1
5.54
2.97
2.66
1.77

2.83
0.16
3.32
0.15
4.57
0.18
1.12
0.02
2.03
0.01
3.87
0.03
1.94
0.53
4.77
1.49
23.55
5.84
0.22
0.06
0.49
0.11
1.28
0.27

stereo
stereo
square
square
cube
cube
stereo
stereo
square
square
cube
cube
stereo
stereo
square
square
cube
cube
stereo
stereo
square
square
cube
cube

Table 1. Evaluation of the source separation for different
methods and setups. ”Mean” is the mean over all sources,
and ”std.dev.” their standard deviation.

from the room, which the presented method is not removing
and was not a goal.

Fig. 1. Simulated room with cube microphone setup. The
dots are the two sources, the crosses are the microphones.

4.3. Results

4.2. Evaluation

As evaluation, the Python module ”mir eval” was used [15].
It computes the ”Signal to Distortion Ratio” (SDR, linear
distortions, like ﬁltering), the ”Signal to Interference Ratio”
(SIR), and the ”Signal to Artifacts Ratio” (SAR, the non-
linear distortions). These measures are computed and then
averaged over the different source pairs, and the standard de-
viation is computed. Since the presented Random Directions
algorithm is probabilistic, each setup was repeated 10 times.
These sets became part of the averaging and the computa-
tion of the standard deviations. Here the most interesting
measures are the SIR, as a measure for the separation per-
formance, and the SAR, because it measures the non-linear
distortions, at which the presented algorithm should be par-
ticularly good at. The SDR measure is less interesting here,
because it measures linear distortions, like a ﬁltering effect

Between the 2 online algorithms, the best SIR (separation) is
achieved by the presented Random Directions method, with 9
dB for the stereo case. The 9 dB sound like a clear separation,
with some slight audible crosstalk from the other source. 3
dB SIR, on the other hand, sounds like no audible separation.
The best overall SAR (non-lin. distortions) is achieved also
with the Random Directions, with 33 dB for the stereo case.
There was indeed no audible non-linear distortion. The best
overall SIR, including ofﬂine methods, is achieved by FastM-
NMF with 20 dB for the stereo case. In this case there is no
audible crosstalk from the other source. This difference can
also be seen as the price for low delay separation, although
both sound sufﬁciently separated. Due to its stochastic na-
ture, Random Directions also has the highest standard devi-
ations, which means sometimes it works better than at other
times. This can be also be seen in Fig. 2, a box plot with the
middle 2 quartiles for a single source pair for 10 runs of Ran-
dom Directions. It still works for more microphones (square,

cation to reverberant and noisy acoustic environments,”
Elsevier Signal Processing, 2006.

[4] I. Senesnick,

“Low-pass ﬁlters realizable as all-pass
sums: design via a new ﬂat delay ﬁlter,” IEEE Trans-
actions on Circuits and Systems II, 1999.

[5] G. Schuller and O. Golokolenko, “Probabilistic opti-
mization for source separation,” in Asilomar Confer-
ence on Signals, Systems, and Computers, Asilomar,
CA, USA, Nov 2020.

[6] S. Liu, P. Y. Chen, B. Kailkhura, G. Zhang, A. O. Hero
III, and P. K. Varshney, “A primer on zeroth-order op-
timization in signal processing and machine learning:
IEEE
Principals, recent advances, and applications,”
Signal Processing Magazine, vol. 37, no. 5, pp. 43–54,
2020.

[7] Sebastian U. Stich, Christian L. M¨uller, and Bernd
G¨artner, “Optimization of convex functions with ran-
dom pursuit,” arXiv, vol. 1111.0194, 5 2012.

[8] Daniel Golovin, John Karro, Greg Kochanski, Chansoo
Lee, Xingyou Song, and Qiuyi Zhang, “Gradientless
descent: High-dimensional zeroth-order optimization,”
arXiv, vol. 1911.06317, 5 2020.

[9] Oleg Golokolenko and Gerald Schuller, “Fast time do-
main stereo audio source separation using fractional de-
lay ﬁlters,” in 147th AES Convention, New York, NY,
USA, October 16-19 2019.

[10] Oleg Golokolenko and Gerald Schuller, “A fast stereo
audio source separation for moving sources,” in Asilo-
mar Conference on Signals, Systems, and Computers,
Asilomar, CA, USA, Nov 3-6 2019.

[11] Espeak, http://espeak.sourceforge.net/.

[12] Csound, https://github.com/csound/csound.

[13] Freesound, https://freesound.org.

[14] Robin Scheibler, Eric Bezzam, and Ivan Dokmani´c,
“Pyroomacoustics: A python package for audio room
simulations and array processing algorithms,” arXiv,
vol. 1710.04196, 2017.

[15] C. Raffel, B. McFee, E. J. Humphrey, J. Salamon, O. Ni-
eto, D. Liang, and D. P. W. Ellis, “mir eval: A transpar-
ent implementation of common mir metrics,” in Pro-
ceedings of the 15th International Conference on Music
Information Retrieval, 2014.

[16] Low Delay Multichannel Source Separation Random-
Directions Demo, https://github.com/TUIlmenauAMS/
LowDelayMultichannelSourceSeparation Random-
Directions Demo.

Fig. 2. Box plots of SDR, SIR, SAR and processing time for
Random Directions for the square microphone case, for an
individual item pair (’espekfemale’, ’espeakwav’). The boxes
represent the middle two quartiles.

cubic), but declines somewhat in separation performance, but
not as much as Trinicon. A full software demo with listening
examples in a Jupyter Colab notebook can be found at [16].

5. CONCLUSIONS

The method of Random Directions can successfully optimize
the very non-convex objective function for audio separation
in the time domain for low delay online applications. It also
works for non-speech signals and more microphones. Using
this zeroth-order optimization method made ﬁnding of a glob-
ally good solution possible, since the objective function is
highly non-convex, which makes gradient based optimization
methods fail. The method of Random Directions is strictly
decreasing the objective function, has a line search along suc-
cessful directions for increasing speed for ”well behaved” ob-
jective functions, and uses a random subspace approach to
make it more robust to higher dimensions, meaning more co-
efﬁcients to optimize. The results showed that it compares
favourably to Trinicon in SIR and SAR, and to frequency do-
main methods in terms of the SAR measure.

6. REFERENCES

[1] K. Sekiguchi, A. A. Nugraha, Y. Bando, and K. Yoshii,
“Fast multichannel source separation based on jointly
in EU-
diagonalizable spatial covariance matrices,”
SIPCO, 2019.

[2] N. Ono, “Stable and fast update rules for independent
vector analysis based on auxiliary function technique,”
in Proc. IEEE, WASPAA, 2011.

[3] R. Aichner, H. Buchner, F. Yan, and W. Kellermann, “A
real-time blind source separation scheme and its appli-

