0
2
0
2

v
o
N
0
2

]
I

A
.
s
c
[

1
v
2
2
2
9
0
.
1
0
1
2
:
v
i
X
r
a

Computability-logic web: an alternative to deep learning

Keehang Kwon

Department of Computing Sciences, DongA University, Korea.
Email: khkwon@dau.ac.kr.

Abstract

Computability logic (CoL) is a powerful, mathematically rigorous computational model. In this paper,
we show that CoL-web, a web extension to CoL, naturally supports web programming where database
updates are involved. To be speciﬁc, we discuss an implementation of the AI ATM based on CoL (CL9
to be exact).

More importantly, we argue that CoL-web supports a general AI and, therefore, is a good alternative

to neural nets and deep learning. We also discuss how to integrate neural nets into CoL-web.

Keywords: Computability logic; Web programming; Game semantics; AI;

1

Introduction

It is not dﬃcult to point out the weaknesses of neural nets and deep learning. Simply put, neural nets are
too weak to support general AI. They receive inputs (numbers), perform simple arithmetic operations and
produce outputs (numbers). Consequently, they provide only primitive services such as object classiﬁcations.
Although object classiﬁcation has some interesting applications, the power of classiﬁcation is in fact not much
compared to all the complex services a human can provide. Complex services – making a coﬀee, withdrawing
money from ATM, etc – are not well supported by neural nets. In addition, their classiﬁcation services are
not perfect, as they are only approximate.

A human can provide complex services to others. The notion of services and how to complete them thus
play a key role for an AI to imitate a human. In other words, the right move towards general AI would be
to ﬁnd (a) a mathematical notion for services, and (b) how an AI automatically generates a strategy for
completing the service calls.

Fortunately, Japaridze developed a theory for services/games involving complex ones. Computability logic
(CoL) [1]-[4], is an elegant theory of (multi-)agent services. In CoL, services are seen as games between a
machine and its environment and logical operators stand for operations on games. It understands interaction
among agents in its most general — game-based — sense.

In this paper, we discuss a web programming model based on CoL and implement an AI ATM. An AI
ATM is diﬀerent from a regular ATM in that the former automatically generates a strategy for a service
call, while the latter does not.

We assume the following in our model:

• Each agent corresponds to a web site with a URL. An agent’s knowledgebase(KB) is described in its

homepage.

• Agents are initially inactive. An inactive agent becomes activated when another agent invokes a query

for the former.

• Our model supports the query/knowledge duality, also known as querying knowledge. That is, knowl-

edge of an agent can be obtained from another agent by invoking queries to the latter.

1

 
 
 
 
 
 
To make things simple, we choose CL9– a fragment of CoL – as our target language. CL9 includes
sequential operators: sequential disjunction (▽) and sequential conjunction (△) operators. These operators
model knowledgebase updates. Imagine an ATM that maintains balances on Kim. Balances change over
time. Whenever Kim presses the deposit button for $1, the machine must be able to update the balance of
the person. This can be represented by

balance($0)△blance($1)△ . . . △.

In this paper, we present CL9Φ which is a web-based implementation of CL9. This implementation
is straightfoward and its correctness is rather obvious. What is interesting is that CL9 is a novel web
programming model with possible database updates.
It would provide a good starting point for future
high-level web programming.

2 Preliminaries

In this section a brief overview of CL9 is given.

There are two players: the machine ⊤ and the environment ⊥.
There are two sorts of atoms: elementary atoms p, q, . . . to represent elementary games, and general

atoms P , Q, . . . to represent any, not-necessarily-elementary, games.

Constant elementary games ⊤ is always a true proposition, and ⊥ is always a false proposition.

Negation ¬ is a role-switch operation: For example, ¬(0 = 1) is true, while (0 = 1) is false.

Choice operations The choice operations model decision steps in the course of interaction, with disjunction

⊔ meaning the machine’s choice, and conjunction ⊓ meaning choice by the environment.

Parallel operations A ∧ B means the parallel-and, while A ∨ B means the paralle-or. In A ∧ B, ⊤ is
considered the winner if it wins in both A and B, while in A ∨ B it is suﬃcient to win in one of A and
B.

Reduction → is deﬁned by ¬A ∨ B.

Sequential operations A▽B (resp. A△B) is a game that starts and proceeds as a play of A; it will
also end as an ordinary play of A unless, at some point, ⊤ (resp. ⊥) decides — by making a special
switch move — to abandon A and switch to B. A▽B is quite similar to the if -then-else in imperative
languages.

We reserve § as a special symbol for switch moves. Thus, whenever ⊥ wants to switch from a given
component Ai to Ai+1 in A0△ . . . △An, it makes the move §. Note that ⊤, too, needs to make switch moves
in a △-game to “catch up” with ⊥. The switches made by ⊥ in a △-game we call leading switches, and
the switches made by ⊤ in a △-game we call catch-up switches.

3 Logic CL9Φ

In this section we review the propositional system CL9 [5] and slightly extend it. Our presentation closely
follows the one in [5]. We assume that there are inﬁnitely many nonlogical elementary atoms, denoted by
p, q, r, s and inﬁnitely many nonlogical general atoms, denoted by P, Q, R, S.

Formulas, to which we refer as CL9-formulas, are built from atoms and operators in the standard way.

Deﬁnition 3.1 The class of CL9-formulas is deﬁned as the smallest set of expressions such that all atoms
are in it and, if F and G are in it, then so are ¬F , F ∧ G, F ∨ G, F → G, F ⊓ G, F ⊔ G, F △G, F ▽G.

2

Now we deﬁne CL9Φ, a slight extension to CL9 with environment parameters. Let F be a CL9-
formula. We introduce a new env-annotated formula F ω which reads as ‘play F against an agent ω. For
an ⊓-occurrence or an △-occurrence O in F ω, we say ω is the matching environment of O. For example,
(p ⊓ (q ⊓ r))w is an agent-annotated formula and w is the matching environment of both occurrences of ⊓.
Similarly for (p△(q△r))w. We extend this deﬁnition to subformulas and formulas. For a subformula F ′ of
the above F ω, we say that ω is the matching environment of both F ′ and F .

In introducing environments to a formula F , one issue is whether we allow ‘env-switching’ formulas of
the form (F [Ru])w. Here F [R] represents a formula with some occurrence of a subformula R. That is, the
machine initially plays F against agent w and then switches to play against another agent u in the course
of playing F . For technical reasons, we focus on non ‘env-switching’ formulas. This leads to the following
deﬁnition:

Deﬁnition 3.2 The class of CL9Φ-formulas is deﬁned as the smallest set of expressions such that (a) For
any CL9-formula F and any agent ω, F ω are in it and, (b) if H and J are in it, then so are ¬H, H ∧ J,
H ∨ J, H → J.

Deﬁnition 3.3 Given a CL9Φ-formula J, the skeleton of J – denoted by skeleton(J) – is obtained by
replacing every occurrence F ω by F .

For example, skeleton((p ⊓ (q ⊓ r))w) = p ⊓ (q ⊓ r).

We borrow the following deﬁnitions from [5]. They apply both to CL9 and CL9Φ.
An interpretation for CL9 is a function that sends each nonlogical elementary atom to an elementary
game, and sends each general atom to any, not-necessarily-elementary, static game. This mapping extends
to all formulas by letting it respect all logical operators as the corresponding game operations. That is,
△F ∗, etc. When F ∗ = A, we say that ∗ interprets F as A.
⊤∗ = ⊤, (E△F )∗ = E∗

A formula F is said to be valid iﬀ, for every interpretation ∗, the game F ∗ is computable. And F is
uniformly valid iﬀ there is an HPM H, called a uniform solution for F , such that H wins F ∗ for every
interpretation ∗.

A sequential (sub)formula is one of the form F0△ . . . △Fn or F0▽ . . . ▽Fn. We say that F0 is the

head of such a (sub)formula, and F1, . . . , Fn form its tail.

The capitalization of a formula is the result of replacing in it every sequential subformula by its head.
A formula is said to be elementary iﬀ it is a formula of classical propositional logic.
An occurrence of a subformula in a formula is positive iﬀ it is not in the scope of ¬. Otherwise it is

negative.

A surface occurrence is an occurrence that is not in the scope of a choice connective and not in the

tail of any sequential subformula.

The elementarization of a CL9-formula F means the result of replacing in the capitalization of F every
surface occurrence of the form G1 ⊓ . . . ⊓ Gn by ⊤, every surface occurrence of the form G1 ⊔ . . . ⊔ Gn by ⊥,
and every positive surface occurrence of each general literal by ⊥.

Finally, a formula is said to be stable iﬀ its elementarization is a classical tautology; otherwise it is

instable.

The proof system of CL9Φ is identical to that CL9 in that agent parameters play no roles. CL9Φ

consists of the following four rules of inference.

Deﬁnition 3.4 Wait: ~H 7→ F , where F is stable and ~H is the smallest set of formulas satisfying the

following two conditions:

1. whenever F has a surface occurrence of a subformula G1 ⊓ . . . ⊓ Gn whose matching environment
is ω, for each i ∈ {1, . . . , n}, ~H contains the result of replacing that occurrence in F by Gω
i ;
2. whenever F has a surface occurrence of a subformula G0△G1△ . . . △Gn whose matching environ-

ment is ω, ~H contains the result of replacing that occurrence in F by (G1△ . . . △Gn)ω.

Choose: H 7→ F , where H is the result of replacing in F a surface occurrence of a subformula G1 ⊔ . . . ⊔ Gn

whose matching environment is ω by Gω
i

for some i ∈ {1, . . . , n}.

3

Switch: H 7→ F , where H is the result of replacing in F a surface occurrence of a subformula G0▽G1▽ . . . ▽Gn

whose matching environment is ω by (G1▽ . . . ▽Gn)ω.

Match: H 7→ F , where H is the result of replacing in F two — one positive and one negative — surface

occurrences of some general atom by a nonlogical elementary atom that does not occur in F .

Example 3.5 The following is a CL9-proof of (b0△b1△b2)u → (b0△b1△b2)w:

1. b2u → b2w
2. b2u → (b1△b2)w
3. (b1△b2)u → (b1△b2)w
4. (b1△b2)u → (b0△b1△b2)w
5. (b0△b1△b2)u → (b0△b1△b2)w (from 4 by Wait);

(from {} by Wait);
(from 1 by Switch);
(from 2 by Wait);
(from 3 by Switch);

4 Logic CL9◦,Φ

To facilitate the execution procedure, following [5], we modify CL9Φ to obtain CL9
new language allows hyperformulas which contain the following.

◦,Φ. Unlike CL9Φ, this

• Hybrid atom: each hybrid atom is a pair consisting of a general atom P , called its general component,
and a nonlogical elementary atom q, called its elementary component. We denote such a pair by
Pq. It keeps track of the exact origin of each such elementary atom q.

• Underlined sequential formula: It is introduced for us not to forget the earlier components of sequential
subformulas when Switch or Wait are applied. We now require that, in every sequential (sub)formula,
one of the components be underlined.

The formulas of this modiﬁed language we call hyperformulas. We borrow the following deﬁnitions

from [5].

By the general dehybridization of a hyperformula F we mean the CL9-formula that results from F by
replacing in the latter every hybrid atom by its general component, and removing all underlines in sequential
subformulas.

A surface occurrence of a subexpression in a given hyperformula F means an occurrence that is not
in the scope of a choice operator, such that, if the subexpression occurs within a component of a sequential
subformula, that component is underlined or occurs earlier than the underlined component.

An active occurrence is an occurrence such that, whenever it happens to be within a component of a

sequential subformula, that component is underlined.

An abandoned occurrence is an occurrence such that, whenever it happens to be within a component
of a sequential subformula, that component is to the left of the underlined component of the same subformula.
An elementary hyperformula is one not containing choice and sequential operators, underlines, and

general and hybrid atoms.

The capitalization of a hyperformula F is deﬁned as the result of replacing in it every sequential

subformula by its underlined component, after which all underlines are removed.

The elementarization

kF k

of a hyperformula F is the result of replacing, in the capitalization of F , every surface occurrence of the
form G1 ⊓ . . . ⊓ Gn by ⊤, every surface occurrence of the form G1 ⊔ . . . ⊔ Gn by ⊥, every positive surface
occurrence of each general literal by ⊥, and every surface occurrence of each hybrid atom by the elementary
component of that atom.

A hyperformula F is stable iﬀ its elementarization kF k is a classical tautology; otherwise it is instable.
A hyperformula F is said to be balanced iﬀ, for every hybrid atom Pq occurring in F , the following two

conditions are satisﬁed:

1. F has exactly two occurrences of Pq, one positive and the other negative, and both occurrences are

surface occurrences;

4

2. the elementary atom q does not occur in F , nor is it the elementary component of any hybrid atom

occurring in F other than Pq.

An active occurrence of a hybrid atom (or the corresponding literal) in a balanced hyperformula is

widowed iﬀ the other occurrence of the same hybrid atom is abandoned.

◦,Φ. The language of CL9

◦

allows any balanced hyperformulas, which we also

We extend CL9Φ to CL9
◦,Φ-formulas.

refer to as CL9

Deﬁnition 4.1 Logic CL9
referred to as “(sub)formulas”):
Wait◦: ~H 7→ F , where F is stable and ~H is the smallest set of formulas satisfying the following two

◦,Φ is given by the following rules for balanced hyperformulas (below simply

conditions:

1. whenever F has an active surface occurrence of a subformula G1 ⊓ . . . ⊓ Gn whose matching
environment is ω , for each i ∈ {1, . . . , n}, ~H contains the result of replacing that occurrence in
F by Gω
i ;

2. whenever F has an active surface occurrence of a subformula G0△ . . . △Gm△Gm+1△ . . . △Gn
whose matching environment is ω, ~H contains the result of replacing that occurrence in F by
(G0△ . . . △Gm△Gm+1△ . . . △Gn)ω.

Choose◦: H 7→ F , where H is the result of replacing in F an active surface occurrence of a subformula

G1 ⊔ . . . ⊔ Gn whose matching environment is ω by Gω
i

for some i ∈ {1, . . . , n}.

Switch◦: H 7→ F , where H is the result of replacing in F an active surface occurrence of a subformula

G0▽ . . . ▽Gm▽Gm+1▽ . . . ▽Gn whose matching environment is ω by (G0▽ . . . ▽Gm▽Gm+1▽ . . . ▽Gn)ω.

Match◦: H 7→ F , where H has two — a positive and a negative — active surface occurrences of some

hybrid atom Pq, and F is the result of replacing in H both occurrences by P .

An eﬀective procedure that converts any CL9Φ-proof of any formula G into a CL9

◦,Φ-proof of G is given

in [5].

5 Execution Phase

◦,Φ is designed to process only one query/formula at one time. In distributed
The machine model of CL9
systems, however, it is natural for an agent to receive/process multiple queries from diﬀerent users. For this
reason, we introduce multiple queries to our machine. To do this, we assume that an agent maintains two
queues: the income queue QI for storing a sequence of new incoming queries of the form (Q1, . . . , Qn) and
the temporarily solved queue QS for storing a sequence of temporarily solved queries of the form (KB1 →
Q1, . . . , KBn → Qn). Here each Qi is a query and each KBi is a knowledgebase. A query Q with respect to
some knowledgebase is temporarily solved if Q is solved but ⊤ has a remaining switch move in Q. Otherwise
Q is said to be completely solved.

As expected, processing real-time multiple queries causes some complications. To be speciﬁc, we process

QI of the form (Q1, . . . , Qm) and QS of the form (KB1 → Q′

1, . . . , KBn → Q′

n) in the following way:

1. First stage is to initialize a temporary variable N ewKB to KB,

2. The second stage is to follow the loop procedure:

procedure loop:

• Case 1: QI is not empty:

The machine tries to solve Q1 by calling Exec(N ewKB → Q1).

5

– If it fails, then report a failure, remove Q1 from QI and repeat loop.
– Suppose it is a success and N ewKB and Q1 evolve to N ewKB′ and Q′

1 after solving this query.

We consider two cases.
(a) If it is completely solved, then report a success, remove Q1 from QI, update N ewKB to
N ewKB′ and repeat loop. (b) If it is temporarily solved, then report a success, remove Q1 from
QI, insert N ewKB′ → Q′

1 to QS, update N ewKB to N ewKB′ and repeat loop.

• Case 2. QI is empty and QS nonempty: The machine tries to solve the ﬁrst query KB1 → Q′

1 in QS.

– If KB = N ewKB, it means nothing has changed since the last check. Hence the machine waits

for any change such as the environment’s new move.

– Otherwise, the machine tries to solve Q′

query from QS, adds Q′

1 to QI, and repeat loop.

1 with respect to N ewKB. It thus removes the above

• Case 3. QI is empty and QS is empty: wait for new incoming service calls.

Below we will introduce an algorithm that executes a formula J. The algorithm is a minor variant of the

one in [5] and contains two stages:

Algorithm Exec(J): % J is a CL9

◦,Φ-formula

1. Fix an interpretation ∗. First stage is to initialize a temporary variable E to J, a position variable Ω
to an empty position hi. Activate all the resource agents speciﬁed in J by invoking proper queries to
them. That is, for each negative occurrence of an annotated formula F ω in J, activate ω by querying
F µ to ω. Here µ is the current machine; On the other hand, we assume that all the querying agents –
which appear positively in J – are already active.

2. The second stage is to play J according to the following mainloop procedure (which is a minor variant

of [5]):

procedure loop(T ree): % T ree is a proof tree of J

If E is derived by Choose◦ from H, the machine makes the move α whose eﬀect is choosing Gi in the
G1 ⊔ . . . ⊔ Gn subformula of E. So, after making move α, the machine call loop on hΩiH ∗. Let ω be the
matching environment. Then inform ω of the move α.

If E is derived by Switch◦ from H, then the machine makes the move α whose eﬀect is making a switch
in the G0▽ . . . ▽Gm▽Gm+1▽ . . . ▽Gn subformula. So, after making move α, the machine calls loop on
hΩ, ⊤αiH ∗.

If E is derived by Match◦ from H through replacing the two (active surface) occurrences of a hybrid
atom Pq in H by P , then the machine ﬁnds within Ω and copies, in the positive occurrence of Pq, all of
the moves made so far by the environment in the negative occurrence of Pq, and vice versa. This series of
moves brings the game down to hΩ′iE∗ = hΩ′iH ∗, where Ω′ is result of adding those moves to Ω. So, now
the machine calls loop on hΩ′iH ∗.

Finally, suppose E is derived by Wait◦. Our machine keeps granting permission (“waiting”).
Case 1. α is a move whose eﬀect is moving in some abandoned subformula or a widowed hybrid literal

of E. In this case, the machine calls loop on hΩ, ⊥αiE∗.

Case 2. α is a move whose eﬀect is moving in some active surface occurrence of a general atom in E.

Again, in this case, the machine calls loop on hΩ, ⊥αiE∗.

Case 3. α is a move whose eﬀect is making a catch-up switch in some active surface occurrence of a

▽-subformula. The machine calls loop on hΩ, ⊥αiE∗.

Case 4. α is a move whose eﬀect is making a move γ in some active surface occurrence of a non-
widowed hybrid atom. Let β be the move whose eﬀect is making the same move γ within the other active

6

surface occurrence of the same hybrid atom. In this case, the machine makes the move β and calls loop on
hΩ, ⊥α, ⊤βiE∗.

Case 5: α is a move whose eﬀect is a choice of the ith component in an active surface occurrence of a
subformula G1 ⊓ . . . ⊓ Gn. Then the machine calls loop on hΩiH ∗, where H is the result of replacing the
above subformula by Gi in E.

Case 6: α signiﬁes a (leading) switch move within an active surface occurrence of a subformula

Then the machine makes the same move α (signifying making a catch-up switch within the same subformula),
and calls exec on hΩ, ⊥α, ⊤αiH ∗, where H is the result of replacing the above subformula by

G0△ . . . △Gm△Gm+1△ . . . △Gn.

G0△ . . . △Gm△Gm+1△ . . . △Gn.

6 Examples

As an example of web system, we will look at the ATM of some bank. It is formulated with the user, an
ATM, a database, and a credit company. We assume the following:

• There are two kinds of agents: super agents and regular agents. Super agents are preﬁxed with $. For
example, $kim is a super agent. While regular agents behave according to the Exec procedure, super
agents behave unpredictably.

• For simplicity, we assume the bank has only one customer named Kim. Further, the balance is restricted

to one of the three amounts: $0, $1 or $2.

• The database maintains balance information on Kim.

• Both the credit company and the ATM request balance checking to the database.

• The ATM has a ($1) deposit button. Whenever pressed, it adds $1 to the account.

The above can be implemented as follows:

agent credit. % credit company
(b0△b1△b2)db. % b0 means the balance is $0, and so on.

% Here, we assume that ATM usage charge is zero, meaning deposit = balance.

agent db. % database
(d0△d1△d2)m. % d0 means the accumulated deposit is $0, and so on.
d0 → b0.
d1 → b1.
d2 → b2.

agent m. % ATM machine
(d0△d1△d2)$kim. % request deposit checking to kim
(b0△b1△b2)db. % request balance checking to DB

agent $kim. % $kim is a super agent.
(b0△b1△b2)m. % request balance checking to ATM

Now let us consider the agent kim and the agent credit. They both want to know the balance of Kim’s
account. The initial balance checking will return b0, meaning zero dollars. Later, suppose Kim deposits $1.
In this case, the balance information on db will be updated to one dollar and, subsequently, the response to
balance checking by ATM, kim and the credit company will be updated to b1, as desired.

7

7 Adding neural networks

The integration of neural nets and symbolic AI is often beneﬁcial. There are several ambitious approaches
such as DeepProblog[6] and these approaches try to combine both worlds within a single agent. Unfortunately,
these approaches considerably increase the complexity of the machine.

Fortunately, in the multi-agent setting, this integration can be achieved in a rather simple way by intro-

ducing a new kind of agents called η-agent(neural-net agents).

There are now three kinds of agents:

• regular agents who perform deductive reasoning, and

• η-agents who perform inductive reasoning.

• super agents who are able to create resources.

An η-agent is an agent which is designed to implement low-level perceptions (visual data, etc) via trainig.
That is, its knowledgebase is in neural-net form for easy training. In the sequel, η-agents are preﬁxed with
η.

We assume the following:
(1) the input/output of a neural network is encapsulated in the form of an atomic predicate,
(2) the output of a neural network is deterministic. Thus, we do not consider probability here, and
(3) For simplicity, neural nets are speciﬁed in logical form (CL9Φ to be exact), instead of in functional

form.

An η-agent with its knowledgebase N proceeds in two modes:

• When there is a query A, it proceeds in deductive mode by processing A using N via CL9Φ deduction.

• When it is idle, it trains itself on sample data by updating N .

As an example, we will look at the program which, given image of an animal, identiﬁes its habitat.

We assume the following:

• The regular agent a implements the predicate habitat(j, h) where j is an image of an animal and h is
the main habitat of the animal. We consider two kinds of animals: lion and tiger. We assume that j
belongs to S = {i1, . . . , i3} where S is a set of three images of animals.

• The η-agent ηd implements the predicate animal(j, n) where j is image of an animal and n is the

corresponding animal.

The above can be implemented as follows:

agent a. % animal habitats
% Below is a query to ηd.
((animal(i1, lion) ⊔ animal(i1, tiger))⊓
(animal(i2, lion) ⊔ animal(i2, tiger))⊓
(animal(i3, lion) ⊔ animal(i3, tiger)))ηd.
% Rules that maps animals to the corresponding habitats.
animal(i1, tiger) → habitat(i1, india).
animal(i2, tiger) → habitat(i2, india).
animal(i3, tiger) → habitat(i3, india).
animal(i1, lion) → habitat(i1, senegal).
animal(i2, lion) → habitat(i2, senegal).
animal(i3, lion) → habitat(i3, senegal).

8

% Given image j, the agent ηd produces the corresponding animal via deep learning. We do not show

the details here.

agent ηd. % η-agent
....

When the agent ηd is idle, it trains itself and updates its knowledgebase by adjusting weights. Now let us
invoke a query habitat(i3, india) ⊔ habitat(i3, senegal) to the agent a where i3 is the image of some animal.
To solve this query, the agent a invokes another query shown above to the agent ηd. Now ηd switches
from training mode to deduction mode to solve this query. Let us assume that the response from ηd is
animal(i3, lion). Using the rules related to animal’s habitats, the agent a will return habitat(i3, senegal) to
the user. Note that our agents behave just like real-life agents. For example, a doctor typically trains himself
when he is idle. If there is a service request, then he switches from training mode to deduction mode.

References

[1] G. Japaridze. Introduction to computability logic. Annals of Pure and Applied Logic 123 (2003),

pp. 1-99.

[2] G. Japaridze. Propositional computability logic I. ACM Transactions on Computational Logic 7

(2006), No.2, pp. 302-330.

[3] G. Japaridze. Propositional computability logic II. ACM Transactions on Computational Logic 7

(2006), No.2, pp. 331-362.

[4] G. Japaridze. In the beginning was game semantics. In: Games: Unifying Logic, Language and
Philosophy. O. Majer, A.-V. Pietarinen and T. Tulenheimo, eds. Springer Verlag, Berlin (to appear).
Preprint is available at http://arxiv.org/abs/cs.LO/0507045

[5] G. Japaridze. Sequential operators in computability logic. Information and Computation 206, No.12

(2008), pp. 1443-1475.

[6] R. Manhaeve et al. DeepProbLog: neural probabilistic logic programming, NIPS’18: Proceedings
of the 32nd International Conference on Neural Information Processing Systems, 2018,
pp.3753–3763.

9

