9
1
0
2

v
o
N
0
2

]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[

1
v
7
1
1
9
0
.
1
1
9
1
:
v
i
X
r
a

Automatic Diﬀerentiable Monte Carlo: Theory and Application

Shi-Xin Zhang,1, ∗ Zhou-Quan Wan,1, ∗ and Hong Yao1, 2, †
1Institute for Advanced Study, Tsinghua University, Beijing 100084, China
2Department of Physics, Stanford University, Stanford, California 94305, USA
(Dated: November 22, 2019)

Diﬀerentiable programming has emerged as a key programming paradigm empowering rapid de-
velopments of deep learning while its applications to important computational methods such as
Monte Carlo remain largely unexplored. Here we present the general theory enabling inﬁnite-order
automatic diﬀerentiation on expectations computed by Monte Carlo with unnormalized probabil-
ity distributions, which we call “automatic diﬀerentiable Monte Carlo” (ADMC). By implementing
ADMC algorithms on computational graphs, one can also leverage state-of-the-art machine learning
frameworks and techniques to traditional Monte Carlo applications in statistics and physics. We
illustrate the versatility of ADMC by showing some applications: fast search of phase transitions
and accurately ﬁnding ground states of interacting many-body models in two dimensions. ADMC
paves a promising way to innovate Monte Carlo in various aspects to achieve higher accuracy and
eﬃciency, e.g. easing or solving the sign problem of quantum many-body models through ADMC.

I.

INTRODUCTION

Diﬀerentiation is a broadly important concept and a
widely useful method in subjects such as mathematics
and physics. Automatic diﬀerentiation (AD) evaluates
derivatives of any function speciﬁed by computer pro-
grams [1, 2] by propagating derivatives of primitive op-
erations via chain rules. It is diﬀerent from conventional
symbolic diﬀerentiations by totally avoiding complicated
analytic expressions of derivatives and is advantageous
to numerical diﬀerentiations by totally eliminating dis-
cretization errors. Besides, AD is particularly success-
ful in calculating higher-order derivatives and computing
gradients with respect to large number of variables as the
case for gradient-based optimization algorithms. Emerg-
ing as a new programming paradigm, AD is now exten-
sively utilized in machine learning. Being one of the most
important infrastructure for machine learning, it enables
massive exploration on neural networks structures.

The great application potential of AD in ﬁelds be-
yond machine learning started to emerge. Speciﬁcally,
AD has been applied to certain areas of computational
physics; for instance its interplay with tensor networks
were investigated very recently [3–6]. One may natu-
rally ask whether AD can be leveraged to Monte Carlo
(MC) methods, another big family of computational al-
gorithms. Initial investigations on encoding MC methods
into AD framework [7] all assumed normalized probabil-
ity distributions for Monte Carlo sampling. However, for
nearly all interesting problems the normalization factor
is not known a priori and the probability distribution
is usually unnormalized. Fortunately, knowing the ratio
of probabilities between diﬀerent conﬁgurations is suﬃ-
cient to perform MC simulations in Metropolis-Hasting
algorithm [8]; Monte Carlo with unnormalized proba-
bility distribution is now a widely employed numerical

∗ These two authors contributed equally to this work
† yaohong@tsinghua.edu.cn

approach in statistics and physics. Consequently, it is
highly desired to integrate AD into generic Monte Carlo
to achieve high accuracy and eﬃciency in various MC ap-
plications such as solving interacting many-body models
in physics.

In this paper, we ﬁll in the gap by proposing the general
theory enabling inﬁnite-order automatic diﬀerentiation
on expectations computed by Monte Carlo with unnor-
malized probability distributions, which we call “auto-
matic diﬀerentiable Monte Carlo” (ADMC). Speciﬁcally,
ADMC employs the method of AD to compute gradi-
ents of MC expectations, which is a key quantity used
in statistics and machine learning [7], without a priori
knowledge of normalization factor or partition function
which is the case for nearly all application scenarios in
Markov chain Monte Carlo (MCMC). As MC gradient
problem lies at the core of probabilistic programming [9]
and plays a central role in various ﬁelds including op-
timization, variational inference, reinforcement learning,
and variational Monte Carlo (VMC), ADMC can be em-
ployed to a wide range of MC applications to achieve high
accuracy and eﬃciency.

ADMC not only works with gradient of expectations
in MC with unnormalized distributions but also holds
true for higher-order derivatives of MC expectations. In
contrast, MC estimation of higher order derivatives were
rarely considered [10]. In addition, ADMC can be em-
bedded in general stochastic computational graph [11]
framework seamlessly and play a critical role at the inter-
play between diﬀerentiable programming and probabilis-
tic programming. By introducing ADMC, we can build
Monte Carlo applications in the state-of-the-art machine
learning infrastructure to achieve high accuracy and ef-
ﬁciency in addressing questions such as fast search of
phase transitions and ground states of interacting quan-
tum models. For models we studied by ADMC, compa-
rable or higher accuracy has been obtained comparing
with previous methods such as RBM and tensor net-
work. Moreover, ADMC paves a promising way to in-
novate Monte Carlo in various aspects, e.g. easing or

 
 
 
 
 
 
2

solving the sign problem [12–21] of quantum Monte Carlo
(QMC) [22–26].

The organization of this paper is as follows. In Sec. II,
we review important background knowledge required to
understand the general theory of ADMC and its appli-
cations, including automatic diﬀerentiation, estimation
on Monte Carlo gradients, and variational Monte Carlo
methods.
In Sec. III, we elaborate our theory towards
ADMC, including detach function, ADMC estimator for
normalized and unnormalized probability distributions
as well as general theory on Fisher information matrix
(FIM) with unnormalized probabilities , and the general
theory for the AD-aware version of VMC. In Sec. IV, we
present two explicit ADMC applications in physics: fast
search of phase transitions and critical temperature in 2D
Ising model; and end-to-end general-purpose ADVMC
algorithms and accurately ﬁnding the ground state of
the 2D quantum spin-1/2 Heisenberg model. We demon-
strate how to leverage the power of state-of-the-art ma-
In
chine learning to ADMC algorithms in particular.
Sec. V, we further discuss other possible applications of
ADMC as well as some outlooks on ADMC.

FIG. 1. Forward mode (a) and reverse mode (b) automatic
diﬀerentiation on computational graphs. Black arrows label
the forward pass from inputs to outputs. Red arrows repre-
sent forward chain rules in (a) and backpropagation for ad-
joints in (b).

II. BACKGROUND

the recursive expression as shown in Fig. 1(a):

In this section, we would like to provide some back-
ground knowledge for the sake of being self-contained.
Speciﬁcally, we will introduce some basic knowledge of
AD, Monte Carlo gradients estimations, and variational
Monte Carlo, which are related to the general theory and
applications of ADMC.

A. Automatic diﬀerentiation

Conventional methods of computing gradients of a
given function include symbolic and numerical ap-
proaches. It is challenging to symbolically compute gra-
dients of complicated functions as deriving the analytical
expression of gradient is often nearly impossible. Numer-
ical diﬀerentiation approach computes the gradient by
ﬁnite discretization and thus normally suﬀers discretiza-
tion errors. In addition, these two conventional methods
encounter more challenges or errors in computing higher
order derivatives, especially when the number of input
parameters is large.

AD, on the contrary, by tracing the derivatives prop-
agation of primitive operations via chain rules, can ren-
der numerically-exact derivatives (including higher order
derivatives) for any programs [1, 2, 27]. The program is
speciﬁed by computational graph composed of function
primitives. Such directed acylic graph shows the data
shape and data ﬂow of the corresponding program.

There are two ways to compute the derivative on the
graph with respect to the graph’s inputs: the forward AD
and backward AD. The forward AD iteratively compute

∂Ti
∂T0

=

(cid:88)

Ti−1∈parent{Ti}

∂Ti
∂Ti−1

∂Ti−1
∂T0

,

(1)

∂Ti
∂Ti−1

where Ti stands for nodes on the computational graph;
T0 is the input and Tn the ﬁnal output. The gradient
we aim to obtain is ∂Tn
corresponds to the
. Here
∂T0
derivatives of operator primitives Ti = f (Ti−1), and these
derivatives are implemented as AD infrastructures built-
in or user customizations. One drawback of the forward
mode AD is that one need to keep track of every deriva-
tive
in the middle of the graph when the input
has many parameters, which is normally expensive and
ineﬃcient.

∂Ti
∂T0[i]

Reverse mode AD can avoid the ineﬃciency encoun-
tered by forward mode AD when input parameters are
far more than output ones, which is the case of many
applications including machine learning and variational
Monte Carlo. By deﬁning the adjoint as T i = ∂Tn
. As
∂Ti
shown in Fig. 1(b), reverse mode AD iteratively compute
the recursive expression:

T i =

(cid:88)

Ti+1∈child{Ti}

T i+1

∂Ti+1
∂Ti

.

(2)

The ﬁnal aim is to compute T 0.
In this approach of
AD, one ﬁrst computes the output and save all inter-
mediate node values Ti in the forward pass, and then
backpropagates the gradients in the reverse pass. This
workﬂow, denoted as backpropagation in machine learn-
ing language [28] is opposite to the forward mode AD
where all computations happen in the same forward pass.
Reverse mode AD is in particular suitable for scenarios

T0T1T2T3T4T5=T¯¯¯¯1T¯¯¯¯3∂T3∂T1+T¯¯¯¯4∂T4∂T1T0T1T2T3T4T5=∂T3∂T0∂T3∂T1∂T1∂T0+∂T3∂T2∂T2∂T0=∂T5∂T0∂T5∂T3∂T3∂T0+∂T5∂T4∂T4∂T0(b)(a)=T¯¯¯¯0T¯¯¯¯1∂T1∂T0+T¯¯¯¯2∂T2∂T0with multiple input parameters and one output value,
which is the case of most deep learning setups [29] and
many MC approaches such as variational Monte Carlo.

B. Gradients of Monte Carlo expectations

As explained in the introduction, it is of great impor-
tance in various ﬁelds to compute gradients of Monte
Carlo expectation values: ∇θ(cid:104)O(x, θ)(cid:105)p(x,θ), where θ
represents the set of input parameters, x label MC con-
ﬁgurations, p(x, θ) is the (generally unnormalized) prob-
ability distribution, and (cid:104)O(x, θ)(cid:105)p(x,θ) is the MC ex-
pectation value of O under the probability distribution
p(x, θ). We often call O the loss function. Currently,
there are two main methods for evaluating MC gradi-
ents: score function estimator [30] (also denoted as RE-
INFORCE [31]) and pathwise estimator (also denoted as
reparametrization trick [32], stochastic backpropagation
[33], or “push out” method [34]). Although the method of
pathwise estimator in general gives lower variance for MC
gradients estimation, it can only be applied to quite lim-
ited settings due to the strict requirements on the diﬀer-
entiability of transformers and probability distributions.
Therefore, it is nearly impossible to apply pathwise es-
timator to evaluate MC gradient sampled from vastly
complicated distributions encountered in most physics
problems. We thus focus on score function method in
the present paper as it is more universal and general-
purpose.

The score function estimator is a general-purpose MC

gradient estimator with gradient given by

∇θ(cid:104)O(x, θ)(cid:105)p =

∇θO(x, θ) + O(x, θ)

(cid:28)

∇θp(x, θ)
p(x, θ)

(cid:29)

p

, (3)

where p is a shortcut for p(x, θ). Note that Eq. (3) is
quite general by taking into account the dependence of
the loss function O on the parameters θ. To leverage AD
on the gradient estimation, it is desired to construct an
AD-aware version of MC expectation which can correctly
obtain the MC gradient itself and its derivatives to all
order (including the gradients and all higher derivatives).
For normalized probability distribution p, the following
AD-aware version of MC expectation

(cid:28) O(x, θ)p(x, θ)
⊥(p(x, θ))

(cid:29)

p

(4)

was proposed [10]. However, for nearly all interesting
physics problems, the normalization factor is not known
a priori and probability distribution is usually unnor-
malized. It is of central importance to sample from such
unnormalized probability distributions for applications
such as computing physical quantities without knowing
partition function a priori or approximating the posterior
distributions of latent variables only with knowledge of
likelihood and prior. Nevertheless, MC gradient estima-
tion from such unnormalized probability distribution has

3

not been constructed by any previous method. In Sec. III
of the present paper, we develop a general framework and
construct the AD-aware objective MC expectation which
can correctly obtain both the expectation value and its
all higher-order derivatives for unnormalized probability
distributions.

C. Variational Monte Carlo in physics

VMC is a powerful numerical algorithm searching the
ground state of a given quantum Hamiltonian based on
the variational principle since a physical Hamiltonian has
energy bounded from below [35, 36]. By sampling the
amplitude of variational wave function |ψθ(cid:105), where θ rep-
resents the set of variational parameters, one can com-
pute the energy expectation Eθ = (cid:104)ψθ| H |ψθ(cid:105) /(cid:104)ψθ|ψθ(cid:105),
where the ansatz wave function |ψθ(cid:105) is in general not
normalized. The energy expectation can be evaluated
through MC:

Eθ =

(cid:80)

σ p(σ, θ) (cid:104)σ|H|ψθ (cid:105)
(cid:104)σ|ψθ (cid:105)
(cid:80)
σ p(σ, θ)

= (cid:104)Eloc(σ, θ)(cid:105)p(σ,θ) ,

(5)

where Eloc(σ, θ) = (cid:104)σ|H|ψθ (cid:105)
(cid:104)σ|ψθ (cid:105) , σ is complete basis of quan-
tum system’s Hilbert space, and p(σ, θ) = |(cid:104)σ|ψθ(cid:105)|2 is
the probability distribution. Note that the probability
distribution p(σ, θ) is in general unnormalized since the
ansatz wave function ψθ(σ) = (cid:104)σ|ψθ(cid:105) is in general un-
normalized (as it is usually challenging to normalize the
ansatz wave function due to complicated wave function
structure). Since Eθ depends on variational parameters
θ, one thus can in principle optimize Eθ obtained by
Eq. (5) against θ, giving rise to the optimal ground state
energy and wave function within the ansatz.

Stochastic gradient descent (SGD) is de facto for op-
timizations in machine learning [37–39] and can also be
employed in computational physics such as optimization
in VMC [40]. There are various generalizations beyond
vanilla SGD optimizers by considering momentum and
adaptive behaviors, amongst which Adam [41] is one
common optimizer in training neural networks. Natural
gradient descent, a concept emerged from information ge-
ometry, is one of the optimization techniques where the
local curvature in distribution space deﬁned by neural
networks has been considered [42–45]. Eﬃcient approxi-
mations on natural gradient have also been investigated
such as FANG [46] and K-FAC [47–51]. For optimiza-
tion problem such as VMC, gradient descent and natu-
ral gradient descent methods can be applied where vari-
ous machine learning techniques can be utilized to boost
VMC. Natural gradient optimization is exactly equiva-
lent to stochastic reconﬁguration (SR) method [52, 53]
in VMC [54–57].

Recently, there were various studies focusing on using
restricted Boltzmann machine (RBM) or related neural
networks as the ansatz wave function for quantum sys-
tems composed of spins [55, 58–68], bosons [54, 69, 70],

and fermions [56, 71]. In previous studies, to incorporate
such wave function ansatz into the framework of VMC,
one either computes all derivatives ∇θψθ(σ) analytically
when the neural network ansatz is simple enough [58] or
applies AD on the wave function to compute ∇θψθ(σ)
[67], and then estimate the gradient ∇θEθ by MC sam-
pling given by

∇θEθ = 2Re[(cid:104)

∗

∇ψσ
ψ∗
σ

Eloc(cid:105) − (cid:104)Eloc(cid:105)(cid:104)

∗

∇ψσ
ψ∗
σ

(cid:105)],

(6)

where (cid:104)·(cid:105) denotes MC sampling of conﬁgurations σ from
probability distribution |ψ(σ)|2. However, applying AD
directly on the energy expectation Eθ = (cid:104)ψθ|H|ψθ(cid:105) to
obtain the gradient ∇θEθ, the most intuitive way to op-
timize the ground state, is still lacking partly due to the
lack of AD technique for MC expectations sampled from
unnormalized probability distributions. With the intro-
duction of ADMC in this work, we can implement AD-
aware VMC, which is much more straightforward and
easy to implement by directly optimizing the energy ex-
pectation without any analytical derivation on deriva-
tives for MC expectations or wave functions, which we
call “end-to-end” ADVMC.

III. THEORY

In this section, we will present the general theory of the
ADMC which enables inﬁnite-order automatic diﬀerenti-
ation on MC expectations with unnormalized probability
distributions. We shall show the detailed derivations on
the general theory.

4

Theorem 1 For any “weird” function, whose value and
every order of derivatives are deﬁned separately, it can
always be expressed by “normal” functions with detach
function ⊥.

Proof. For a function F(x) whose each order of deriva-
tives are deﬁned as F (n)(x) = hn(x), the construction
with ⊥ is:

F(x) =

∞
(cid:88)

n=0

1
n!

hn(⊥(x))(x − ⊥(x))n.

(7)

When translated into TensorFlow language, The-
every function deﬁned with
orem 1 states
that
can be instead deﬁned with
tf.custom_gradient
tf.stop_gradient .

Corollary 1.1 For a function with multiple variate in-
put F(x1, ...xm) whose derivatives F (n1...nm) are deﬁned
separately, irrelevant from the original function, it can
always be expressed by “normal” functions together with
single variate detach function ⊥.

The corollary above is obvious by considering similar
Taylor expansion construction as Eq. (7).

The introduction of imaginary number i enlarges the
meaning of the equal sign by twice the equivalence rela-
tion: x = y ⇔ Re(x) = Re(y) and Im(x) = Im(y). Simi-
larly, with the introduction of detach function, the equal
sign are enlarged as inﬁnite independent equivalence re-
lations: f (x) = g(x) ⇔ ⊥(f (n)(x)) = ⊥(g(n)(x)), (n =
0, 1, 2, · · · ). The conventional “equal” is reexpressed as
one relation (n = 0) of the above series: ⊥(f (x)) =
⊥(g(x)).

A. Detach function

B. ADMC

We ﬁrst introduce detach function ⊥(x) which features
⊥(x) = x and ∂⊥(x)
∂x = 0. Here we list some basic formula
in terms of detach functions utilized later: f (⊥(x)) =
⊥(f (x)), ⊥(⊥(x)) = ⊥(x), ⊥(x + y) = ⊥(x) + ⊥(y), and
⊥(xy) = ⊥(x)⊥(y). The detach function can be easily
implemented and simulated in modern machine learn-
ing frameworks (it corresponds to stop_gradient in
TensorFlow [72] and detach in PyTorch [73]). We call
this function primitive as detach function in this work.
This weird looking function has natural explanation in
the context of machine learning, especially in terms of
computational graph. Such operator corresponds to node
in the graph which only pass forward values while stop
the back propagation of gradients.

By utilizing detach function, we can construct func-
tions whose derivatives of each order is not related. For
example, the function O(x) = x − ⊥(x) equals to 0 ir-
respective of x although its ﬁrst-order derivative is 1.
The detach function is mathematically sound as we shall
prove a completeness theorem for the detach function be-
low.

We are ready to construct a general theory for MC
expectation which can render AD to correctly obtain its
directives at all order (including the zeroth-order deriva-
tive, the expectation itself). We employ the extended
score function method to enable AD on MC expecta-
tions for any complicated distribution, both normalized
and unnormalized. Theorem 2 below is the central theo-
retical result of the present paper.

Theorem 2 The following MC estimator of (cid:104)O(x, θ)(cid:105)p
(cid:68) p

(cid:69)

(cid:104)O(x, θ)(cid:105)p =

⊥(p) O(x, θ)

(cid:68) p

(cid:69)

⊥(p)

(8)

⊥(p)

⊥(p)

is automatic diﬀerentiable to all order and works for both
normalized and unnormalized probability distribution p =
p(x, θ).

To prove Theorem 2, we ﬁrst introduce the following

lemma:

Lemma 1 For both normalized and unnormalized prob-
ability distribution p = p(x, θ),

(cid:88)

x∈S(p)

p
⊥(p)

.
=

Z
⊥(Z)

.

(9)

factor before the MC sum (cid:80)

Here Z is the shortcut for partition function Zθ =
(cid:80)
x∈all p(x, θ) with x ∈ all representing the summation
over all conﬁgurations x. (cid:80)
x∈S(p) denotes the average
obtained through MC sampling according to the proba-
bility distribution p. Note that, for brevity, we omit the
1
x∈S(p) in Eq. (9) and
Ns
hereafter; the sum should be understood as the average
1
x∈S(p) where Ns is the number of sample conﬁgu-
Ns
.
rations. In Eq. (9) and hereafter, “
=” means that it is
the same as the equal sign since MC estimation can be
made exact in the limit of large Ns. The equal sign also
makes sense in any order derivatives. Therefore, to prove
the lemma we just need to demonstrate the following for-
mula:

(cid:80)



⊥



(cid:88)

x∈S(p)

∇(n)
θ

p
⊥(p)





(cid:18)

.
= ⊥

(cid:19)

∇(n)
θ

Z
⊥(Z)

,

(10)

θ

where ∇(n)

is a shortcut for ∇(n1,··· ,nm)

, nj = 0, 1, 2, · · · .
For n = 0, the equation is simply true since both sides
give 1. For arbitrary n, it is straightforward to show that


θ1,··· ,θm



(cid:88)

⊥



x∈S(p)

⊥(∇(n)p)
⊥(p)

.
=



(cid:88)

⊥(p)
⊥(Z)

⊥∇(n)p
⊥(p)

x∈all p

x∈all
⊥∇(n) (cid:80)
⊥Z
⊥(∇(n)Z)
⊥(Z)

=

=

,

(11)

which ﬁnishes the proof of the lemma.

The proof of the lemma above can be signiﬁcantly sim-
pliﬁed. With the enlarged meaning of equal sign, each
order of derivatives automatically equal as long as ex-
pressions with detach function are accordingly consid-
ered. In other words, to prove that some relation holds
true for any order derivatives ⊥(f (n)(x)) = ⊥(g(n)(x)),
(n = 0, 1, 2, · · · ), we only need to prove that f (x) = g(x)
is true. This simpliﬁcation is the power of detach func-
tion. The proof of the lemma can be simpliﬁed as:

(cid:88)

x∈S(p)

p
⊥(p)

.
=

(cid:88)

x∈all

⊥(p)
⊥(Z)

p
⊥(p)

=

(cid:80)

x∈all p
⊥(Z)

=

Z
⊥(Z)

.(12)

Note that the simpliﬁcation from the involved proof in
Eq. (10) and Eq. (11) to the neat one in Eq. (12) reﬂects
the brevity and power of detach function and its algebra.
Now we are ready to prove Theorem 2. Proving this

theorem is equivalent to show the following equation:
(cid:33)

(cid:32)

(cid:32)

(cid:33)

⊥

∇(n)
θ

(cid:104) p
⊥(p) O(cid:105)⊥(p)
(cid:104) p
⊥(p) (cid:105)⊥(p)

.
= ⊥

∇(n)
θ

(cid:88)

x∈all

p

O
Z

, (13)

5

where O is the shortcut for O(x, θ). Note that, in the
average (cid:104)·(cid:105)⊥(p), the probability distribution ⊥(p) is the
background and is not involved in derivatives. Based on
the spirit of detach function algebra, it is enough to show:

(cid:88)

x∈S(p)

p
⊥(p)

O(cid:14) (cid:88)

x∈S(p)

p
⊥(p)

.
=

(cid:88)

x∈all

p

O
Z

.

(14)

By utilizing the lemma in Eq. (9) and observing the fact
that Zθ is independent of x, it is straightforward to prove
Eq. (14) as follows:

(cid:88)

x∈S(p)

p
⊥(p)

O(cid:14) (cid:88)

x∈S(p)

p
⊥(p)

.
=

=

(cid:88)

x∈all

(cid:88)

x∈all

⊥(p)
⊥(Z)

pO
⊥(p)

(cid:14)(

Z
⊥(Z)

)

p

O
Z

.

This ﬁnishes the proof of Theorem 2, which is the cen-
tral result of the present paper. We believe Theorem 2
can provide endless opportunities to build applications
combining AD infrastructure with MC algorithms.

x∈all ⊥(p) p

We emphasize that Theorem 2 is general and ap-
plies for both normalized and unnormalized probabil-
For the case of normalized dis-
ity distribution p.
.
tribution (cid:80)
=
(cid:80)
x∈all p = 1. Then, Eq. (8) in Theo-
, which is
⊥(p) O

x∈all p = 1, we obtain (cid:80)
⊥(p) = (cid:80)
rem 2 can be simpliﬁed to (cid:104)O(cid:105)p =
the MC estimator applicable only for the case of normal-
ized probability distribution. For nearly all interesting
applications with unnormalized probability distribution
p, Theorem 2 is the correct one to use, as we demonstrate
in the applications below.

p
⊥(p)

(cid:68) p

x∈S(p)

⊥(p)

(cid:69)

It is worth to provide heuristic explanation for The-
orem 2. Through discretizing the parameters θ in nu-
merical diﬀerentiations, rigorous MC gradient can be ob-
tained in the limit of zero distretizing intervals. Specif-
ically, to get gradients at θ0, one can directly compute
MC expectations of O by sampling separately from p(θ)
and from p(θ0), with θ very close to θ0. However, it
is highly ineﬃcient to sample separately from p(θ) and
from p(θ0) distributions. As θ is close to θ0 (in the limit
θ → θ0), one can actually reuse the samples from p(θ0)
to evaluate the expectation at θ0:
(cid:88)

p(θ)O(x, θ)(cid:14) (cid:88)

p(θ)

(cid:104)O(x, θ)(cid:105)p(θ) =

x∈all

x∈all

=

=

(cid:88)

1
N
x∈all
(cid:28) p(x, θ)
p(x, θ0)

p(x, θ0)

p(x, θ)
p(x, θ0)

O(x, θ)(cid:14) (cid:88)

p(x, θ0)

p(x, θ)
p(x, θ0)

(cid:29)

O(x, θ)

p(θ0)

(cid:14)

x∈all
(cid:29)

(cid:28) p(x, θ)
p(x, θ0)

p(θ0)

.

(15)

By comparing Eq. (15) with Eq. (8), one can observe
the parallel relations between them and understand the
physical rational behind detach functions: when evaluat-
ing derivatives only θ changes while θ0 ﬁxed, all terms
related to θ0 are wrapped with detach function ⊥ in the
exact form Eq. (8) in Theorem 2.

Finally, we make a note on implementation. For nu-
merical stability, ln p instead of p is in general referenced
and the AD version of MC estimator for generic proba-
bility distribution p is then given by:

Following the path of Eq. (20), we could further derive
the AD-aware formula for general KL divergence with
unnormalized probability p, q parameterized by θ as

6

(cid:104)O(cid:105)p =

(cid:104)exp(ln p − ⊥(ln p))O(cid:105)⊥p
(cid:104)exp(ln p − ⊥(ln p))(cid:105)⊥p

.

(16)

KL(pθ|qθ) = ln

(cid:69)

(cid:68) p
⊥p
(cid:68) p
⊥p

q
p
(cid:69)

⊥p

−

⊥p

(cid:68) p
⊥p ln q
p
(cid:69)
(cid:68) p
⊥p

⊥p

(cid:69)

⊥p

.

(21)

From computational graph implementation perspective,
p is never explicitly calculated since the numerical value
of exp(ln p − ⊥(ln p)) is exactly one. Therefore, ADMC
approach using ln p is automatically free from the numer-
ical instability encountered in approaches directly using
p.

C. Fisher information matrix and KL divergence in
ADMC

For the optimization method of natural gradient de-
scent, the parameters θ are updated in the following way:
∆θ = −λF −1∇θOθ, where F is the Fisher information
matrix (FIM), λ is the learning rate and Oθ = (cid:104)O(x, θ)(cid:105)p.
FIM is of great importance in numerical optimization and
is deﬁned as

Fij =

(cid:68)

∇i ln

p
Z

∇j ln

(cid:69)

p
Z

,

p

(17)

where i, j represent θi, θj. FIM is also the Hessian (with
respect to θ(cid:48)) of KL divergence between p(x, θ) and
p(x, θ(cid:48)) with θ(cid:48) approaching θ. Hence, it deﬁnes the
local curvature in distribution space.

In the following, we derive useful formulas related to
FIM with unnormalized probability distribution p in the
context of ADMC. For unnormalized p, the expectation
of score function is not zero and it is given by:

(cid:104)∇θ ln p(cid:105)p =

1
Z

(cid:88)

x∈all

p

∇θp
p

=

∇θZ
Z

= ∇θ ln Z. (18)

Then, the FIM for unnormalized p can be deﬁned as

Fij = (cid:104)∇i ln p∇j ln p(cid:105)p − (cid:104)∇i ln p(cid:105)p(cid:104)∇j ln p(cid:105)p.

(19)

To apply AD approach, we can obtain FIM through
the KL divergence whose Hessian is FIM. The AD-aware
KL divergence is given by

(cid:16)

⊥(

KL

(cid:17)

p
Z

)|

p
Z

= ln

= ln

Z
⊥(Z)
(cid:28) p

(cid:28)

−

ln

(cid:29)

⊥(p)

⊥(p)

(cid:29)

p
⊥(p)
(cid:28)

−

ln

(cid:29)

⊥(p)
p
⊥(p)

, (20)

⊥(p)

where the second equation is due to Eq. (9) in Lemma
1. Therefore, for any unnormalized p, we can construct
object function as Eq. (20) and compute Hessian of it by
ADMC. This approach is preferable than direct estima-
tion from Eq. (19) in some scenarios. (see the SM [74]
for details)

D. End-to-end ADVMC

As discussed in Sec. II, VMC is an important approach
attempting to ﬁnd the ground state wave function of a
Hamiltonian by optimizing parametrized wave functions.
Here we describe how to implement end-to-end VMC
with ADMC, which we call ADVMC. We shall focus on
the case where ansatz wave functions are positively val-
ued. For the general case of complex-valued ansatz wave
functions, ADVMC can also be implemented. (see the
SM [74] for details)

As in Eq. (5), the energy expectation value Eθ =
(cid:104)ψθ| H |ψθ(cid:105) of Hamiltonian H associated with the wave
function ψθ(σ) = (cid:104)σ |ψθ(cid:105) can be evaluated through
Monte Carlo sampling

Eθ = (cid:104)Eloc(σ, θ)(cid:105)p(σ,θ) ,

(22)

where p(σ, θ) = |ψθ(σ)|2 is usually unnormalized prob-
ability distribution. To optimize (minimize) Eθ using
gradient-based approach, we need to evaluate the gradi-
ents with respect to variational parameters θ:

∇θ (cid:104)Eloc(σ, θ)(cid:105)p(σ,θ) .

(23)

It is clear that Eloc(σ, θ) in VMC plays a similar role
as O(x, θ) in MC discussed earlier. It is natural to in-
tegrate AD into VMC so that an end-to-end ADVMC
can be constructed. The ADVMC version of the energy
estimator can be constructed as follows:

(cid:104)Eloc(σ, θ)(cid:105)p = Re

(cid:68) p

(cid:69)
⊥p Eloc(σ, θ)
(cid:68) p
⊥p

(cid:69)

⊥p

⊥p

,

(24)

where Re guarantees that the energy estimator is real.

Taking account of the variance reduction trick, the AD-
VMC energy estimator for real wave function can also be
constructed as [74]:

(cid:104)Eloc(σ, θ)(cid:105)p = Re

(cid:68) ψ2

⊥(ψ2) ⊥(Eloc(σ, θ))

(cid:68) ψ2

(cid:69)

⊥(ψ2)

⊥(p)

(cid:69)

⊥(p)

. (25)

Actually, the objective in Eq. (25) has better perfor-
mance compared with the original estimator in Eq. (24)
since E(σ, θ) is detached in Eq. (25) and no further back-
propagations behind this node are needed. Note that

Eq. (25) as the estimator of Eθ can only reproduce ﬁrst-
order derivative in the framework of AD, while the orig-
inal estimator in Eq. (24) is correct for all order deriva-
tives. (see the SM [74] for details)

The end-to-end ADVMC framework is universal and
easy to implement. Instead of computing derivatives of
wave functions and plugging the results into the formula
of energy gradients by hands as conventional VMC ap-
proaches do in Eq. (6), the end-to-end ADVMC optimizes
the energy expectation directly and leaves all remain-
ing work to machine learning infrastructure. Analytic
and implementation works can be done automatically
with AD infrastructure, vectorization/broadcast mecha-
nism, builtin optimizers and GPU acceleration provided
by standard ML framework. For diﬀerent quantum mod-
els, the only diﬀerence is diﬀerent Eloc(σ, θ). After imple-
menting Eloc, we can bring it into Eq. (25) as AD-aware
energy estimator. Then, we can use AD to compute the
gradients and gradient-based optimizer to optimize the
energy.

Besides SGD-based optimizers, natural gradient opti-
mizers (SR methods) can also be incorporated into AD
framework.
In the context of VMC, the optimization
method of natural gradient descent updates the varia-
tional parameters as follows: ∆θ = −λF −1∇θEθ where
F can be obtained by Monte Carlo:

Fij = Re

(cid:34)(cid:28) ∂iψ∗
ψ∗

∂jψ
ψ

(cid:29)

(cid:29)

(cid:28) ∂iψ∗
ψ∗

p

(cid:28) ∂jψ
ψ

−

p

(cid:35)

(cid:29)

p

, (26)

where ψ is a shortcut for ψθ(σ) and dependence on pa-
rameters θ is implicit. Note that Eq. (26) is connected
to Eq. (19) when the distribution p = |ψ|2 and ψ is real.
The relation between FIM and SR method with complex
wave functions can also be analyzed by generalizing KL
divergence in complex distribution case. (see the SM [74]
for details)

IV. APPLICATIONS

The general theory of ADMC we presented above has
broad applications,
including achieving high accuracy
and eﬃciency in studying interesting many-body inter-
acting models in physics. As we mentioned earlier, by
introducing ADMC, we can leverage not only AD but
also other powerful features of machine learning frame-
works to traditional Monte Carlo. AD together with vec-
torization, GPU acceleration, and state-of-the-art opti-
mizers can build faster and more capable Monte Carlo
applications to study challenging issues in statistics and
physics. Here we present two explicit ADMC’s appli-
cations in studying interacting many-body systems [75]
where comparable or higher accuracy can be achieved
comparing with previous studies using RBM-based VMC,
and tensor network methods.

A. Fast search of phase transitions by ADMC

7

For many-body systems in physics, it is among cen-
tral interest to ﬁnd distinct phases and phase transitions
between them. We shall show that ADMC can provide
a general and eﬃcient way to ﬁnd phase transitions in
many-body interacting models. At a given phase transi-
tion, certain quantities such as speciﬁc heat and ordering
susceptibility reach a maximal value. This naturally en-
ables ADMC to locate the phase transition in a fast and
eﬃcient way by searching for the maximum. A phase
transition can occur when certain parameter such as tem-
perature, pressure, and magnetic ﬁeld is tuned across
a critical value. ADMC can eﬃciently ﬁnd the critical
value of tuning parameter, such as transition tempera-
ture.

For concreteness, we shall use ADMC to ﬁnd the
transition temperature of the 2D Ising model on square
lattice as an example, although the approach we shall
present is general and can be applied to both classi-
cal or quantum models. For quantum models, we call
the corresponding AD approach as “AD quantum Monte
Carlo” (ADQMC). The 2D Ising model is given by H =
− (cid:80)
(cid:104)ij(cid:105) Jσiσj, where σi = ±1 is the Ising spin on site
i of the square lattice and we take J = 1 as the en-
ergy unit. It is well-known that there is a phase tran-
sition at critical temperature Tc below which the sys-
tem orders spontaneously [76]. The Ising model can be
MC sampled with unnormalized probability distribution
p(σ, T ) = exp(−H(σ)/T ). As speciﬁc heat reaches a
maximal value at the phase transition, conventional MC
methods usually compute speciﬁc heat for many temper-
ature points and then locate the peak of speciﬁc heat
curve as phase transition.
In these conventional ap-
proaches, it requires analytical derivation of the formula
for speciﬁc heat since MC sampling usually cannot com-
pute the speciﬁc heat directly. It is relatively simple for
speciﬁc heat due to the ﬂuctuation-dissipation theorem,
i.e. Cv(T ) = ((cid:104)H 2(cid:105)p − (cid:104)H(cid:105)2
p)/T . However, it is generally
challenging to analytically derive quantities such as gra-
dient or higher order derivatives of physical quantities.

ADMC provides a general way to search for phase
transition by directly using the speciﬁc heat Cv(T ) or
other physical quantities as the objective function, which
avoids the drawback of conventional MC approaches
mentioned above. With the help of ADMC, we can ﬁnd
the peak of the speciﬁc heat curve much faster and more
eﬃcient. Without the knowledge on the ﬂuctuation-
dissipation theorem, we can ﬁnd the location of the peak
very accurately with the total computation time which is
orders of magnitude faster. In ADMC, we ﬁrst directly
compute energy using the AD-aware version of MC en-
ergy estimator as Eq. (8) and then, following the spirit
of SGD, we update temperature (starting from any T0)
based on the second-order derivative of MC expectation

8

FIG. 3. Schematic illustration of the end-to-end ADVMC.
Conﬁgurations (spins) are vectorized in an extra dimension
as diﬀerent Markov chains. A computational graph is con-
structed to give the logarithm of wave function ln ψθ which is
also vectorized. Loop 1 is the conventional MCMC approach
for updating the conﬁgurations according to Metropolis-
Hasting algorithm. Loop 2 is ADMC approach to evaluate
the AD-aware energy estimator and update the parameters θ
by optimizers. One iteration of our algorithm include many
(often size of the system) conﬁguration updates (loop1) to de-
crease the autocorrelation and one step of parameter update
(loop2).

We emphasize that the approach we present here is
general and can be straightforwardly generalized to other
classical or quantum models, where fast estimation on
critical values is desired. The knowledge of critical val-
ues is helpful to reduce unnecessary calculations on data
points deeply in phases and renders fast search of phase
transitions in interacting many-body systems.

B. Accurate search of ground states by ADVMC

The integration of AD with VMC provides a power-
ful tool to accurately study ground states of many-body
quantum models in one and higher dimensions. Espe-
cially, ADVMC can study generic quantum models (in-
cluding those models with frustration) in two and higher
dimensions using general neural-network states as ansatz
wave functions.

The workﬂow of the end-to-end ADVMC is sketched
In ADVMC algorithm, we can take advan-
in Fig. 3.
tage of the vectorization technique to watch and update
thousands of independent Markov chains in the parallel
fashion. As shown in Fig. 3, the (spin) conﬁgurations of
diﬀerent Markov chains are vectorized in a new dimension
of size nmc (the number of Markov chains). The conﬁgu-
rations are sent to an arbitrary computational graph with
variational parameters θ where the logarithm of wave
function ln ψθ(σ) is evaluated as the output. Computa-

FIG. 2. Fast search for critical temperature Tc by the ADMC
approach for Ising model of lattice size 50×50 . The obtained
expectation value of Tc from training is 2.279, about 0.4% oﬀ
from the exact value 2.269 [76]. Considering the short training
time and ﬁnite size eﬀect, this is a very good estimation on Tc
and more accurate results can be obtained by larger systems
size and smaller learning rate.

energy in every few MC updates:

∆T ∝

∂Cv
∂T

=

∂2(cid:104) p

⊥(p) H(cid:105)/(cid:104) p
∂T 2

⊥p (cid:105)

.

(27)

Although the number of MC updates in each round
of temperature update is small rendering noisy estima-
tion of speciﬁc heat, such noisy gradient estimator can
still converge to Tc very quickly. This is the essence of
SGD: noisy gradient estimation might lead to better and
faster convergence to the minimum or maximum. This
is also why mini-batch gradient estimate is used in gen-
eral neural network training; for instance, one MC sam-
ple each pass in training of variational auto-encoder [32]
and CD-1 algorithm in RBM training [77] work quite
well. Following the same philosophy, we can combine
SGD into ADMC framework applied here. Speciﬁcally,
to maximize some MC expectation values against varia-
tional parameters θ = argmaxθ(cid:104)O(x, θ)(cid:105)p(x,θ), we may
obtain noisy estimation on the gradients by doing few
MC update steps. Such noisy estimation on the gradi-
ents can render stable and faster optimizations if learning
rate is small enough.

Moreover, one can also utilize third order derivative of
expectation energy and apply Newton method to update
the temperature, which convincingly shows the value of
inﬁnitely automatic diﬀerentiable MC estimators.

In terms of implementation, we also combine vectoriza-
tion into the ADMC workﬂow above, which takes Markov
chain as one of the extra dimension for spin conﬁgura-
tion tensors, enabling MC simulation on tens of thou-
sands Markov chains simultaneously. Such vectorization
scheme is highly eﬃcient compared to conventional par-
allel schemes, such as one Markov chain per CPU core.
Besides, GPU supports such vectorization very well, pro-
viding further speed up. The combination of SGD and
vectorized Wolﬀ algorithm leads relatively accurate esti-
mation on Tc in just a few seconds.

050100150200250300Iteration steps: n1.81.92.02.12.22.32.4Critical Temperature: TcTc location with trainingestimated Tc by ADMCexact Tc...Conﬁgurations...ln  ⟨ ⟩ ∇ ⟨ ⟩ ADSGDMCMC↑↓↓↑...↑↓↓ComputationalGraphparam: Estimator12. . .9

dered positive deﬁnite. Consequently, for simplicity we
shall use positive ansatz wave functions in our ADVMC
simulations. The computational graph we utilize in this
problem is a fully-connected neural network with 7 layers
and with RELU activations [80]. The number of nodes on
these layers are 16l2, 8l2, 4l2, 8l2, 4l2, l2, 1, where l2 = 64
is the size of the system. Such neural network design is
general without considering any symmetry and geomet-
ric information. Totally there are more than one million
variational parameters and the number of Markov chains
is 5000 in our ADVMC simulations. With such large
amount of independent Markov chains and variational
parameters, the ADVMC implementation is still very ef-
ﬁcient on GPU in terms of time and storage resources due
to the highly parallelized structure of our algorithm, as
shown in Fig. 4(a). The much shorter running time com-
pared with CPU also demonstrates the increasing signif-
icance of GPU acceleration when the number of Markov
chains increases.

The approximation ground state energy optimized by
Adam converges to −0.6733 (in unit of J) per site aver-
aged by the last 5000 energy data, as shown in Fig. 4(b).
This result has 3 × 10−4 relative error compared with the
benchmark ground state energy obtained by SSE [81].
It’s also energetically competitive or advantageous over
results obtained by various state-of-the-art methods in-
cluding EPS [82], PEPS [83, 84] and RBM-based VMC
[58]. This convincingly demonstrates that end-to-end
ADVMC can enable us to reach state-of-the-art numeri-
cal results with very moderate eﬀort for quantum models.

V. DISCUSSIONS AND CONCLUSIONS

One central issue in Monte Carlo simulations of in-
teracting many-body quantum models is the notorious
sign problem. Although it is shown to be NP hard to
solve the sign problem generically [85], it is still possible
to ease [86–88] or solve [16] the sign problem of a given
speciﬁc quantum model in QMC simulations by certain
basis transformations. We propose to employ ADMC as
a general way to ﬁnd the optimal basis which can ease or
solve the notorious sign problem in QMC simulations of
interesting quantum models, such as the repulsive Hub-
bard model away half ﬁlling. One appropriate objective
in ADMC would be the expectation value of the sign
which depends on the parameters characterizing the ba-
sis choice. ADMC can help to ﬁnd an optimal basis in
which the sign problem is alleviated. From the ADMC-
optimized basis with eased sign problem, one may sim-
ulate strongly correlated models with lower temperature
and larger system size than QMC with usual basis.

ADMC proposed in the present paper is based on
score function estimators. For the speciﬁc models we
have studied, the present ADMC obtains accurate results
without suﬀering any high variance in MC estimations.
It is possible to further improve ADMC by reducing vari-
ance in MC estimations of expectations. In other words,

FIG. 4. Numerical results of end-to-end ADVMC approach
for the spin-1/2 quantum Heisenberg model on the square
lattice. (a) Comparison of wall time on GPU and CPU by
measuring the wall time of 20 iterations with diﬀerent num-
bers of Markov chains. It was conducted with the same neural
network states and model setup. (b) ADVMC results on 8 × 8
quantum Heisenberg model with periodic boundary condition.
The variational wave function was chosen to be a fully con-
nected neural network with 7 layers. The number of nodes
on each layer is (16l2, 8l2, 4l2, 8l2, 4l2, l2, 1), with l = 8. The
activations were set to be RELU for all these layers except
the last one. Adam optimizer was used to update the param-
eters. The dash line is the benchmark ground state energy
given by the SSE method. Inset shows the converge of en-
ergy near the exact value. The ADVMC result is energeti-
cally competitive or advantageous over resulted obtained by
various state-of-the-art methods including EPS, PEPS and
RBM-based VMC.

tion graph can be constructed by mean-ﬁeld wave func-
tions with Jastrow factors, matrix product state [78, 79],
deep neural networks or any other programs with varia-
tional parameters and one scalar output. ln ψθ also has
an extra dimension with the same size as nmc. In evalu-
ating the computational graph, the extra dimension be-
haves as batch dimension in ML language which can be
easily taken care of using broadcast technique supported
by ML. With the knowledge of wave function amplitudes,
we can update the conﬁgurations using MCMC method
to make them satisfying the distribution given by com-
putational graph wave function ansatz.

Here we demonstrate this new paradigm of VMC
by ADVMC study of the spin-1/2 quantum Heisenberg
model on the square lattice. The model is given by
H = (cid:80)
(cid:104)ij(cid:105) J (cid:126)Si · (cid:126)Sj, where (cid:126)Sj is spin-1/2 operator on
site j. Because of the Marshal-sign rule the ground wave
function amplitudes of the Heisenberg model can be ren-

010002000300040005000Number of Markov Chains020406080Wall time(s)2*Intel(R) Xeon(R) 5120 CPUNVIDIA GEFORCE RTX 2080 Ti020000400006000080000100000120000140000Iterations0.680.660.640.620.600.580.560.540.52Energy per siteVariational EnergyExact Groud State Energy500001000001500000.67350.67300.67250.672010

it would be desired to ﬁnd baselines or general control
variables which could systematically reduce the variance
of MC estimations. It is one of future routes to improve
ADMC by introducing baselines suitable for any order
derivatives as in the case of normalized probability dis-
tribution [89].

In conclusion, we have presented the general theory
and framework of ADMC. We also showed how Monte
Carlo expectations, KL divergence, and objectives from
various settings can be expressed in an inﬁnitely AD
fashion. We further applied the ADMC approach on
various Monte Carlo applications including classical
Monte Carlo and end-to-end VMC. Especially,
the
ADVMC enables us to eﬃciently study interacting
quantum models in higher dimensions. We believe that
the ADMC approach can inspire more accurate and
eﬃcient Monte Carlo designs with machine learning

toolbox in the future. At the intersection of diﬀerentiable
programming and probabilistic programming, ADMC
framework provides a promising route to advance Monte
Carlo applications in the ﬁelds of statistics, machine
learning, and physics.

Acknowledgement: We thank Shuai Chen, Zi-Xiang Li,
Jin-Guo Liu, Rong-Yang Sun and Lei Wang for help-
ful discussions. This work is supported in part by the
NSFC under Grant No.
11825404 (SXZ, ZQW, and
HY), the MOSTC under Grant Nos. 2016YFA0301001
and 2018YFA0305604 (HY), and the Strategic Prior-
ity Research Program of Chinese Academy of Sciences
under Grant No. XDB28000000 (HY). HY would also
like to acknowledge support in part by the Gordon
and Betty Moore Foundations EPiQS Initiative through
Grant GBMF4302 at Stanford.

[1] M. Bartholomew-Biggs, S. Brown, B. Christianson, and
L. Dixon, Automatic diﬀerentiation of algorithms, Jour-
nal of Computational and Applied Mathematics 124, 171
(2000).

[2] A. G. Baydin, B. A. Pearlmutter, A. A. Radul, and J. M.
Siskind, Automatic Diﬀerentiation in Machine Learning
: a Survey, Journal of Machine Learning Research 18, 1
(2018).

[3] H.-J. Liao, J.-G. Liu, L. Wang, and T. Xiang, Diﬀeren-
tiable Programming Tensor Networks, Phys. Rev. X 9,
31041 (2019).

[4] G. Torlai, J. Carrasquilla, M. T. Fishman, R. G. Melko,
and M. P. A. Fisher, Wavefunction positivization via au-
tomatic diﬀerentiation, arXiv:1906.04654 (2019).

[5] C. Hubig, Use and implementation of autodiﬀerentia-
tion in tensor network methods with complex scalars,
arXiv:1907.13422 (2019).

[6] Z.-Q. Wan and S.-X. Zhang, Automatic Diﬀerentiation
for Complex Valued SVD, arXiv:1909.02659 (2019).

[7] S. Mohamed, M. Rosca, M. Figurnov,

and A. Mnih,
Monte Carlo Gradient Estimation in Machine Learning,
arXiv:1906.10652 (2019).

[8] W. K. Hastings, Monte Carlo sampling methods using
Markov chains and their applications, Biometrika 57, 97
(1970).

[9] J.-W. van de Meent, B. Paige, H. Yang,

and
F. Wood, An Introduction to Probabilistic Programming,
arXiv:1809.10756 (2018).

[10] J. Foerster, G. Farquhar, T. Rockt¨aschel, S. White-
son, M. Al-Shedivat, and E. P. Xing, DICE: The in-
ﬁnitely diﬀerentiable Monte Carlo estimator, Proceedings
of the 35th International Conference on Machine Learn-
ing (2018).

[11] J. Schulman, N. Heess, T. Weber, and P. Abbeel, Gra-
dient Estimation Using Stochastic Computation Graphs,
Advances in Neural Information Processing Systems 28 ,
3528 (2015).

[12] E. Y. Loh, J. E. Gubernatis, R. T. Scalettar, S. R. White,
D. J. Scalapino, and R. L. Sugar, Sign problem in the nu-
merical simulation of many-electron systems, Phys. Rev.
B 41, 9301 (1990).

[13] C. Wu and S.-C. Zhang, Suﬃcient condition for absence
of the sign problem in the fermionic quantum Monte
Carlo algorithm, Phys. Rev. B 71, 155115 (2005).
[14] E. Berg, M. A. Metlitski, and S. Sachdev, Sign-Problem-
Free Quantum Monte Carlo of the Onset of Antiferro-
magnetism in Metals, Science 338, 1606 (2012).

[15] E. F. Huﬀman and S. Chandrasekharan, Solution to sign
problems in half-ﬁlled spin-polarized electronic systems,
Phys. Rev. B 89, 111101 (2014).

[16] Z.-X. Li, Y.-F. Jiang, and H. Yao, Solving the fermion
sign problem in quantum Monte Carlo simulations by
Majorana representation, Phys. Rev. B 91, 241117
(2015).

[17] L. Wang, Y.-H. Liu, M. Iazzi, M. Troyer, and G. Harcos,
Split Orthogonal Group: A Guiding Principle for Sign-
Problem-Free Fermionic Simulations, Phys. Rev. Lett.
115, 250601 (2015).
[18] Z.-X. Li, Y.-F. Jiang,

and H. Yao, Majorana-Time-
Reversal Symmetries: A Fundamental Principle for Sign-
Problem-Free Quantum Monte Carlo Simulations, Phys.
Rev. Lett. 117, 267002 (2016).

[19] Z. C. Wei, C. Wu, Y. Li, S. Zhang, and T. Xiang, Majo-
rana Positivity and the Fermion Sign Problem of Quan-
tum Monte Carlo Simulations, Phys. Rev. Lett. 116,
250601 (2016).

[20] P. Broecker, J. Carrasquilla, R. G. Melko, and S. Trebst,
Machine learning quantum phases of matter beyond the
fermion sign problem, Sci. Rep. 7, 8823 (2017).

[21] Z.-X. Li and H. Yao, Sign-Problem-Free Fermionic Quan-
tum Monte Carlo: Developments and Applications,
Annu. Rev. Condens. Matter Phys. 10, 337 (2019).

[22] R. Blankenbecler, D. J. Scalapino,

and R. L. Sugar,
Monte Carlo calculations of coupled boson-fermion sys-
tems. I, Phys. Rev. D 24, 2278 (1981).

[23] D. CEPERLEY and B. ALDER, Quantum Monte Carlo,

Science 231, 555 (1986).

[24] A. W. Sandvik, Stochastic method for analytic continu-
ation of quantum Monte Carlo data, Phys. Rev. B 57,
10287 (1998).

[25] N. Prokof’ev, B. Svistunov, and I. Tupitsyn, Worm algo-
rithm in quantum Monte Carlo simulations, Phys. Lett.

A 238, 253 (1998).

[26] E. Gull, A. J. Millis, A. I. Lichtenstein, A. N. Rubtsov,
M. Troyer, and P. Werner, Continuous-time Monte Carlo
methods for quantum impurity models, Rev. Mod. Phys.
83, 349 (2011).

[27] C. C. Margossian, A review of automatic diﬀerentia-
tion and its eﬃcient implementation, arXiv:1811.05031
(2018).

[28] D. E. Rumelhart, G. E. Hinton, and R. J. Williams,
Learning representations by back-propagating errors, Na-
ture 323, 533 (1986).

[29] Y. LeCun, Y. Bengio, and G. Hinton, Deep learning,

Nature 521, 436 (2015).

[30] J. P. Kleijnen and R. Y. Rubinstein, Optimization and
sensitivity analysis of computer simulation models by the
score function method, Eur. J. Oper. Res. 88, 413 (1996).
[31] R. J. Williams, Simple statistical gradient-following algo-
rithms for connectionist reinforcement learning, Machine
Learning 8, 229 (1992).

[32] D. P. Kingma and M. Welling, Auto-Encoding Varia-
tional Bayes, Proceedings of the 2nd International Con-
ference on Learning Representations (2014).

[33] D. J. Rezende, S. Mohamed, and D. Wierstra, Stochastic
Backpropagation and Approximate Inference, Proceed-
ings of the 31st International Conference on Machine
Learning (2014).

[34] R. Y. Rubinstein, Sensitivity analysis of discrete event
systems by the push out method, Annals of Operations
Research 39, 229 (1992).

[35] W. L. McMillan, Ground State of Liquid He4, Phys. Rev.

138, A442 (1965).

[36] D. Ceperley, G. V. Chester, and M. H. Kalos, Monte
Carlo simulation of a many-fermion study, Phys. Rev. B
16, 3081 (1977).

[37] H. Robbins and S. Monro, A Stochstic Approximation

Method, Ann. Math. Stat. 22, 400 (1951).

[38] J. Kiefer and J. Wolfowitz, Stochastic Estimation of the
Maximum of a Regression Function, Ann. Math. Stat.
23, 462 (1952).

[39] L. Bottou, F. E. Curtis, and J. Nocedal, Optimization
Methods for Large-Scale Machine Learning, SIAM Rev.
60, 223 (2018).

[40] A. Harju, B. Barbiellini, S. Siljam¨aki, R. M. Nieminen,
and G. Ortiz, Stochastic gradient approximation: An ef-
ﬁcient method to optimize many-body wave functions,
Phys. Rev. Lett. 79, 1173 (1997).

[41] D. P. Kingma and J. Ba, Adam: A Method for Stochas-
tic Optimization, Proceedings of the 3rd International
Conference on Learning Representations (2014).

[42] S.-i. Amari, Natural Gradient Works Eﬃciently in Learn-

ing, Neural Comput. 10, 251 (1998).

[43] R. Pascanu and Y. Bengio, Revisiting Natural Gradient

for Deep Networks, arXiv:1301.3584 (2013).

[44] J. Martens, New insights and perspectives on the natural

gradient method, arXiv:1412.1193 (2014).

[45] R. Karakida, S. Akaho, S.-i. Amari,

and L. Fellow,
Pathological spectra of the Fisher information metric and
its variants in deep neural networks, arXiv:1910.05992
(2019).

[46] R. B. Grosse, Scaling Up Natural Gradient by Sparsely
Factorizing the Inverse Fisher Matrix, Proceedings of
the 32nd International Conference on Machine Learning
(2015).

[47] J. Martens and R. Grosse, Optimizing neural networks

11

with Kronecker-factored approximate curvature, 32nd
International Conference on Machine Learning 3, 2398
(2015).

[48] R. Grosse, A Kronecker-factored approximate Fisher ma-
trix for convolution layers, Proceedings of the 33 rd In-
ternational Conference on Machine Learning (2016).
[49] J. Ba, R. Grosse, and J. Martens, Distributed second-
order optimization Kronecker-factored approximations,
Int. Conf. Learn. Represent. (2017).

[50] J. Martens, J. Ba, and M. Johnson, Kronecker-factored
curvature approximations for recurrent neural networks,
Int. Conf. Learn. Represent. (2018).

[51] K. Osawa, Y. Tsuji, Y. Ueno, A. Naruse, R. Yokota,
and S. Matsuoka, Large-Scale Distributed Second-Order
Optimization Using Kronecker-Factored Approximate
Curvature for Deep Convolutional Neural Networks,
arXiv:1811.12019 (2018).

[52] S. Sorella, Green Function Monte Carlo with Stochastic
Reconﬁguration, Phys. Rev. Lett. 80, 4558 (1998).
[53] S. Sorella, Generalized Lanczos algorithm for variational
quantum Monte Carlo, Phys. Rev. B 64, 024512 (2001).
[54] Y. Nomura, A. S. Darmawan, Y. Yamaji, and M. Imada,
Restricted Boltzmann machine learning for
solving
strongly correlated quantum systems, Phys. Rev. B 96,
205152 (2017).

[55] I. Glasser, N. Pancotti, M. August, I. D. Rodriguez,
and J. I. Cirac, Neural-Network Quantum States, String-
Bond States, and Chiral Topological States, Phys. Rev.
X 8, 11006 (2018).

[56] D. Pfau, J. S. Spencer, A. G. d. G. Matthews,

and
W. M. C. Foulkes, Ab-Initio Solution of the Many-
Electron Schr¨odinger Equation with Deep Neural Net-
works, arXiv:1909.02487 (2019).

[57] C.-Y. Park and M. J. Kastoryano, On the geometry
learning neural quantum states, arXiv:1910.11163

of
(2019).

[58] G. Carleo and M. Troyer, Solving the quantum many-
body problem with artiﬁcial neural networks, Science
355, 602 (2017).

[59] D.-L. Deng, X. Li, and S. Das Sarma, Machine learning
topological states, Phys. Rev. B 96, 195145 (2017).
[60] G. Carleo, Y. Nomura, and M. Imada, Constructing ex-
act representations of quantum many-body systems with
deep neural networks, Nat. Commun. 9, 5322 (2018).
[61] Z. Cai and J. Liu, Approximating quantum many-body
wave functions using artiﬁcial neural networks, Phys.
Rev. B 97, 035116 (2018).

[62] D. Kochkov and B. K. Clark, Variational optimization in
the AI era: Computational Graph States and Supervised
Wave-function Optimization, arXiv:1811.12423 (2018).
[63] R. Kaubruegger, L. Pastori, and J. C. Budich, Chiral
topological phases from artiﬁcial neural networks, Phys.
Rev. B 97, 195136 (2018).

[64] K. Choo, G. Carleo, N. Regnault,

and T. Neupert,
Symmetries and Many-Body Excitations with Neural-
Network Quantum States, Phys. Rev. Lett. 121, 167204
(2018).

[65] X. Liang, W.-Y. Liu, P.-Z. Lin, G.-C. Guo, Y.-S. Zhang,
and L. He, Solving frustrated quantum many-particle
models with convolutional neural networks, Phys. Rev.
B 98, 104426 (2018).

[66] T. Vieijra, C. Casert, J. Nys, W. De Neve, J. Haegeman,
J. Ryckebusch, and F. Verstraete, Restricted Boltzmann
Machines for Quantum States with Nonabelian or Any-

onic Symmetries, arXiv:1905.06034 (2019).
[67] L. Yang, Z. Leng, G. Yu, A. Patel, W.-J. Hu,

and
H. Pu, Deep Learning-Enhanced Variational Monte
Carlo Method for Quantum Many-Body Physics,
arXiv:1905.10730 (2019).

[68] H. He, Y. Zheng, B. A. Bernevig,

and G. Sierra,
Multi-Layer Restricted Boltzmann Machine Represen-
tation of 1D Quantum Many-Body Wave Functions,
arXiv:1910.13454 (2019).

[69] H. Saito, Solving the Bose-Hubbard model with machine

learning, J. Phys. Soc. Japan 86, 4 (2017).

[70] K. McBrian, G. Carleo,
and E. Khatami, Ground
the one-dimensional Bose-
state phase diagram of
Hubbard model from restricted Boltzmann machines,
arXiv:1903.03076 (2019).
[71] J. Hermann, Z. Sch¨atzle,

and F. No´e, Deep neural
network solution of the electronic Schr¨odinger equation,
arXiv:1909.08423 (2019).

[72] See https://github.com/tensorflow/tensorflow.
[73] See https://github.com/pytorch/pytorch.
[74] See Supplemental Materials for details. The SM of this
work includes: 1. Detailed discussion on the advantages
and implementations for obtaining FIM within ADMC
framework. 2. Detailed derivation and implementation
details of end-to-end VMC for positive valued and gen-
eral complex valued wave function case.

[75] Code implementation of the applications can be found at

https://github.com/refraction-ray/admc.

[76] L. Onsager, Crystal Statistics. I. A Two-Dimensional
Model with an Order-Disorder Transition, Phys. Rev. 65,
117 (1944).

[77] G. E. Hinton, A practical guide to training restricted
boltzmann machines, Neural Networks: Tricks of the
Trade , 599 (2012).

[78] S. R. White, Density Matrix Formulation for Quan-
tum Renormalization Groups, Phys. Rev. Lett. 69, 2863

12

(1992).

[79] U. Schollw¨ock, The density-matrix renormalization group
in the age of matrix product states, Annals of Physics
326, 96 (2011).

[80] G. E. Hinton, Rectiﬁed Linear Units Improve Restricted
Boltzmann Machines, Proceedings of the 27 th Interna-
tional Conference on Machine Learning (2010).

[81] A. W. Sandvik, Finite-size scaling of the ground-state pa-
rameters of the two-dimensional Heisenberg model, Phys.
Rev. B 56, 11678 (1997).

[82] F. Mezzacapo, N. Schuch, M. Boninsegni, and J. I. Cirac,
Ground-state properties of quantum many-body systems:
Entangled-plaquette states and variational Monte Carlo,
New J. Phys. 11, 083026 (2009).

[83] L. Wang, I. Pizorn,

and F. Verstraete, Monte Carlo
simulation with tensor network states, Phys. Rev. B 83,
134421 (2011).

[84] M. Lubasch, J. I. Cirac, and M.-C. Ba˜nuls, Algorithms
for ﬁnite projected entangled pair states, Phys. Rev. B
90, 064425 (2014).

[85] M. Troyer and U.-J. Wiese, Computational Complex-
ity and Fundamental Limitations to Fermionic Quantum
Monte Carlo Simulations, Phys. Rev. Lett. 94, 170201
(2005).

[86] D. Hangleiter, I. Roth, D. Nagaj, and J. Eisert, Easing
the Monte Carlo sign problem, arXiv:1906.02309 (2019).
[87] R. Levy and B. K. Clark, Mitigating the Sign Problem
Through Basis Rotations, arXiv:1907.02076 (2019).

[88] A. J. Kim, P. Werner,

and R. Valent´ı, Alleviating
the Sign Problem in Quantum Monte Carlo Simulations
of Spin-Orbit-Coupled Multi-Orbital Hubbard Models,
arXiv:1907.11298 (2019).

[89] J. Mao, J. Foerster, T. Rockt¨aschel, M. Al-Shedivat,
G. Farquhar, and S. Whiteson, A Baseline for Any Order
Gradient Estimation in Stochastic Computation Graphs,
Proceedings of the 36th International Conference on Ma-
chine Learning 97, 4343 (2019).

SUPPLEMENTAL MATERIALS

A. Automatic diﬀerentiation approach for Fisher information matrix

In this part, we further discuss the implementation details and advantages on AD approach towards FIM.
The test case for algorithm implementations of FIM we utilized is simple distributions such as multivariate Gaussian
distribution N (µ|σ), in which µ, σ depend on variational parameters θ. For the simplest case, σ is constant and
µ(θ) is determined by parameters θ. We can obtain analytical expression for FIM in this case:

Fij =

∂µT
∂θi

σ−1 ∂µ
∂θj

.

(A1)

If we further assume σ = I and µi = µ(θi) is in the same function form, we can further simplify FIM analytically as:

F = (∂µ)2I.

(A2)

In our code example, we test with three dimensional Gaussian distribution and µ(θ) = (θ + 1)2 where θ = 0.
The expected FIM should be 4 I3×3 in this case. Such test cases can also be used for testing implementation of
unnormalized probability cases if the normalization factor of Gaussian distribution is deliberately dropped out.

The ﬁrst advantage for FIM with AD approach is zero elements might be kept without MC ﬂuctuations or error bars.
Take the test case above for an example, all oﬀ diagonal elements of FIM should be zero analytically. If one utilized

13

conventional way computing FIM by MC averaging ﬁrst order derivatives of ln p, the resulting oﬀ diagonal elements
are not zero due to the error bar introduced by MC. However, with advanced graph optimization and smart compiler
infrastructure provided by TensorFlow, unnecessary computations can be identiﬁed and removed from runtime graph.
With such state-of-the-art executing engine of computational graph, the oﬀ diagonal terms can be pinned at zero
with AD approach. This is because the zero nature of these terms have already been identiﬁed at graph building
time by TensorFlow engines. That is to say, the numerical result can even reach theoretical precision with the help
of AD. It is worth noting that such gain is not guaranteed since TensorFlow engine can fail recognizing complicated
series of unnecessary operations. For example, AD with unnormalized probability objectives give nonzero oﬀ diagonal
elements in FIM using the same Gaussian distribution test case.

The second advantage of AD approach is the better compatibility with vectorization scheme. Suppose we vectorize
Markov chains as the batch dimension as the case in our implementation of example applications. The conventional
way to evaluate FIM involving terms like (cid:80)
x∼p ∂i ln p(x) ∂j ln p(x) where x is diﬀerent conﬁgurations living on the
extra vectorization dimension in our setup. It would be hard to evaluate such terms by treating the batch dimension
as a whole where x are diﬀerent for diﬀerent chains. This restriction is mainly brought by modern AD infrastructure
of ML libraries in which derivatives for multiple outputs can only be obtained one by one and no tensorized fashion
AD is implemented. Instead, KL divergence objective only concern about terms like (cid:80)
p
⊥p which is super easy to
parallelize by a simple reduce mean. The computation time of the conventional approach is scaling with the number
of Markov chains or conﬁguration samples N which is typical thousands to millions while the computation time of
AD approach is scaling with the parameter number (one has to apply AD on each derivatives to get the Hessian in
ML libraries) which could be way less than the conﬁguration numbers vectorized in the batch dimension. And our
numerical experiments indeed show that AD approach is clearly faster than conventional approach either in graph
building time or in graph executing time.

x∼p

B. End-to-end ADVMC setup for general complex wave functions

1. Computational graph setup for general wave function

If the ground state wave function is not always real positives, the general form can be expressed as ψσ = erσ eiθσ , where
r characterize the real norm part ln |ψ| and θ characterize the complex angle for the wave function. Therefore, we
need two separate computational graphs for computing r and θ, and train them together towards minimal energy. We
discuss about the most reliable form of AD-aware energy estimators and the assistant estimator for natural gradients
in the following.

2.

Inﬁnite order AD estimator for VMC

The reason why VMC works is due to the following fact: the quantum expectation energy can be approximated by

classical Monte Carlo averaged Eloc.

(cid:104)H(cid:105) =

=

(cid:80)

(cid:80)

σσ(cid:48) ψ∗
(cid:80)
σ ψ∗
(cid:80)

σHσσ(cid:48)ψσ(cid:48)
σ ψ∗
σψσ
σψσEloc(σ)
σ ψ∗
σψσ

(cid:80)

σσ(cid:48) ψ∗

=

(cid:80)

= Re

σ ψ∗

σψσ(Hσσ(cid:48)ψσ(cid:48)/ψσ)
(cid:80)
σψσ
σ ψ∗
σψσEloc(σ)
(cid:80)
σ ψ∗
σψσ

=

(cid:80)

=

(cid:80)

σ ψ∗

σψσ

(cid:80)
(cid:80)

σ(cid:48)(Hσσ(cid:48)ψσ(cid:48)/ψσ)
σ ψ∗

σψσ

σ ψ∗
σψσReEloc(σ)
(cid:80)
σψσ

σ ψ∗

,

(A3)

where Eloc(σ) = (cid:80)
general local Hamiltonian. If we treat ψ∗

σ(cid:48)(Hσσ(cid:48)ψσ(cid:48)/ψσ), the summation over σ(cid:48) can be done eﬃciently because Hσσ(cid:48) is sparse matrix for

σψσ as the classical probability p(σ), then we have

(cid:104)H(cid:105) =

(cid:88)

σ

p(σ)(ReEloc(σ))/

(cid:88)

σ

p(σ) = (cid:104)ReEloc(σ)(cid:105)σ∼p(σ) ,

(A4)

which indicates (cid:104)H(cid:105) is just the expected value of ReEloc(σ) when σ is sampled from an unnormalized distribution
p(σ). For this problem, our ADMC approach gives an accurate inﬁnite order AD-aware estimator of it:

Es (cid:104)H(cid:105) =

(cid:80)

σ∈S(p)
(cid:80)

pσ
⊥pσ

ReEloc(σ)

σ∈S(p)

pσ
⊥pσ

=

(cid:80)

σ∈S(p)
(cid:80)

ψ∗
⊥(ψ∗

σψσ
σψσ) ReEloc(σ)
σψσ
σψσ)

ψ∗
⊥(ψ∗

σ∈S(p)

.

(A5)

Here (cid:80)
σ∈S(p) means doing summation on the set of conﬁgurations σ sampled from distribution p = ψ∗
σψσ using
MCMC method. This estimator is correct for arbitrary order derivatives no matter whether the wave function ansatz
is real or not. Nevertheless, we can design more eﬃcient estimators in VMC context with lower variance and better
optimization results as we shown below.

14

3. First order eﬃcient AD estimator for VMC

In most of the cases, the knowledge about the gradients (ﬁrst order derivatives) of (cid:104)H(cid:105) is enough, while our estimator
in Eq. (A5) is correct for any order of derivatives. There’s possibility that we can further increase our precision if we
focus on the ﬁrst order derivative.

By analytically deriving the gradients of (cid:104)H(cid:105) from quantum expectation perspective, we have:

∇ (cid:104)H(cid:105) =∇

=

Hσσ(cid:48) =H ∗
=⇒

σ(cid:48) σ

(cid:80)

(cid:80)

(cid:80)

σσ(cid:48) ψ∗
σHσσ(cid:48)ψσ(cid:48)
(cid:80)
σ ψ∗
σψσ
σσ(cid:48)(∇ψ∗
σ)Hσσ(cid:48)ψσ(cid:48) + ψ∗
σ ψ∗
Eloc(σ) + ∇ψσ
ψσ
σ ψ∗
σψσ
Eloc(σ)

(cid:80)
σψσ)( ∇ψ∗
σ
ψ∗
σ
(cid:80)

σ(ψ∗

σψσ

(cid:80)

σ ψ∗

σψσ
(cid:80)

∇ψ∗
σ
ψ∗
σ
σ ψ∗
σψσ

=2Re(

σHσσ(cid:48)(∇ψσ(cid:48))

(cid:80)

−

∇ (cid:80)
(cid:80)

(cid:80)

σ ψ∗
σ ψ∗
σ(ψ∗

σψσ
σψσ
σψσ)( ∇ψ∗
σ
ψ∗
σ
(cid:80)
σ ψ∗
σψσ

σσ(cid:48) ψ∗
(cid:80)

σHσσ(cid:48)ψσ(cid:48)
σ ψ∗
σψσ
σσ(cid:48) ψ∗
(cid:80)

σHσσ(cid:48)ψσ(cid:48)
σ ψ∗
σψσ
σ ψ∗
σψσ
(cid:80)
σ ψ∗

∇ψ∗
σ
ψ∗
σ
σψσ

(cid:80)

).

E∗

loc(σ))

(cid:80)

−

(cid:80)

−

σ ψ∗
(cid:80)

σψσEloc(σ)
σ ψ∗
σψσ

+ ∇ψσ
ψσ

)

(A6)

Note all the terms are in the form of

Thus we have:

(cid:80)

σ ψ∗
(cid:80)

σψσO(σ)
σ ψ∗
σψσ

, as this kind of terms can be estimated by (cid:80)

σ∈S(p) O(σ)/Nmc.

∇ (cid:104)H(cid:105)

.
= 2Re(

(cid:80)

σ∈S(p)

∇ψ∗
σ
ψ∗
σ
Nmc

Eloc(σ)

−

(cid:80)

σ∈S(p) Eloc(σ)
Nmc

(cid:80)

σ∈S(p)
Nmc

∇ψ∗
σ
ψ∗
σ

).

(A7)

From MC expectation perspective, we calculate the gradients of the general estimator in Eq. (A5), the result is not

the same as Eq. (A7), The diﬀerence terms are:

diﬀ =

=

=

1
Nmc

1
Nmc

1
Nmc

(cid:88)

Re

σ∈S(p)

(cid:88)

Re

σ∈S(p)

(cid:88)

Re

σ∈S(p)

(

(

(

∇ψ∗
σ
ψ∗
σ

∇ψ∗
σ
ψ∗
σ

∇ψ∗
σ
ψ∗
σ

Eloc −

Eloc −

∇ψσ
ψσ

∇ψσ
ψσ

Eloc − ∇Eloc)

Eloc − ∇

(cid:88)

σ(cid:48)

Hσσ(cid:48)

ψσ(cid:48)
ψσ

)

Eloc −

(cid:88)

σ(cid:48)

Hσσ(cid:48)

∇ψσ(cid:48)
ψσ

).

(A8)

diﬀ normally is not zero numerically, but it goes to zero when Nmc goes to inﬁnite as it should be. This is because:

1
Nmc

Re

(cid:88)

(cid:88)

σ∈S(p)

σ(cid:48)

Hσσ(cid:48)

∇ψσ(cid:48)
ψσ

Nmc→∞= Re

=Re

Hσσ(cid:48) =H ∗

σ(cid:48) σ=

Re

=Re

(cid:88)

σσ(cid:48)

(cid:88)

σσ(cid:48)
(cid:88)

σ(cid:48)
(cid:88)

σ(cid:48)

(cid:88)

σ
ψ∗
σ
ψ∗
σ(cid:48)

ψ∗

σψσ

(cid:88)

/

ψ∗

σ(cid:48)ψσ(cid:48)

ψ∗

σψσHσσ(cid:48)

∇ψσ(cid:48)
ψσ

/

ψ∗

σ(cid:48)ψσ(cid:48)

ψ∗

σ(cid:48)ψσ(cid:48)

ψ∗

σ(cid:48)ψσ(cid:48)

∇ψσ(cid:48)
ψσ(cid:48)

∇ψσ(cid:48)
ψσ(cid:48)

∇ψσ(cid:48)
ψσ(cid:48)
∇ψ∗
σ
ψ∗
σ

Hσσ(cid:48)

(cid:88)

(Hσ(cid:48)σ

σ

E∗

loc(σ(cid:48))/

Eloc.

=

1
Nmc

Re

(cid:88)

σ∈S(p)

σ(cid:48)
ψσ
ψσ(cid:48)

(cid:88)

σ(cid:48)

(cid:88)

)∗/

ψ∗

σ(cid:48)ψσ(cid:48)

σ(cid:48)

ψ∗

σ(cid:48)ψσ(cid:48)

(A9)

Thus we proved limNmc→∞ diﬀ = 0. In other words, If we directly use Eq. (A5) as the estimator, AD will give the
gradients with another term whose expectation is theoretically zero. Since this term is in general nonzero in MC
calculations, it add more variance to the estimation on energy. We can safely drop diﬀ term from the philosophy
of baseline method. In other words, it would be better to ﬁnd the estimator whose ﬁrst order derivative is directly
Eq. (A7) without diﬀ term.

Such estimator is easy to construct.

15

(cid:80)

Es1 (cid:104)H(cid:105) = 2Re

σ∈S(p)
(cid:80)

ψ∗
σ
⊥ψ∗
σ

σ∈S(p)

⊥Eloc(σ)
ψ∗
σ
⊥ψ∗
σ

.

(A10)

We can prove it by directly calculating the gradient of this estimator:

∇Es1 (cid:104)H(cid:105) = 2Re

(cid:80)

σ∈S(p)

∇ψ∗
σ
⊥ψ∗
σ

⊥Eloc(σ) (cid:80)

σ∈S(p)
((cid:80)

ψ∗
σ
⊥ψ∗
σ

σ∈S(p)

− (cid:80)
ψ∗
σ
⊥ψ∗
σ

)2

σ∈S(p)

ψ∗
σ
⊥ψ∗
σ

⊥Eloc(σ) (cid:80)

σ∈S(p)

∇ψ∗
σ
⊥ψ∗
σ

.

(A11)

In the sense of its numerical value

⊥∇Es1 (cid:104)H(cid:105) = ⊥2Re(

(cid:80)

σ∈S(p)

∇ψ∗
σ
ψ∗
σ
Nmc

Eloc(σ)

−

(cid:80)

σ∈S(p) Eloc(σ)
Nmc

(cid:80)

σ∈S(p)
Nmc

∇ψ∗
σ
ψ∗
σ

),

(A12)

which is just the same as Eq. (A7). Thus AD-aware estimator in Eq. (A10) gives the right approximation of the
gradients of (cid:104)H(cid:105) with lower variance than the general estimator Eq. (A5). Though it is only valid for the ﬁrst order
derivatives.

If the wave function is real, Eq. (A10) reduce to

Es1r =

(cid:80)

σ∈S(p)
(cid:80)

pσ
⊥pσ

Re⊥Eloc(σ)

σ∈S(p)

pσ
⊥pσ

.

(A13)

One can again verify it by directly diﬀerentiating on Eq. (A13). The only change in Eq. (A13) is detached Eloc
comparing with the general estimator Eq. (A5). The new estimator also has better performance when running the
computational graph since Eloc is detached and no backward propagation pass through it.

4. SR and Natural gradients

SR method (natural gradient descent) is reported to give faster convergence on VMC. In this part, we explore
the relation between natural gradient descent and SR method in general settings where the wave function could be
complex.

For real wave function case, KL divergence plays the role as the distance of distribution space whose Hessian FIM
gives the same formalism as SR method as we have shown in the main text. In terms of complex case, traditional
KL divergnece deﬁned with p = ψ∗ψ loses the information of wave function’s phases. Thus we need a better distance
measure to describe the diﬀerence between diﬀerent wave functions.

The natural choice is Fubini-Study distance deﬁned in Hilbert space:

s(ψ, φ) = arccos

(cid:115)

(cid:104)ψ|φ(cid:105) (cid:104)φ|ψ(cid:105)
(cid:104)ψ|ψ(cid:105) (cid:104)φ|φ(cid:105)

.

(A14)

Inﬁnitesimal distances are thus given by:

ds2 = s(ψ, ψ + δψ)2 =

(cid:104)δψ|δψ(cid:105)
(cid:104)ψ|ψ(cid:105)

−

(cid:104)δψ|ψ(cid:105)
(cid:104)ψ|ψ(cid:105)

(cid:104)ψ|δψ(cid:105)
(cid:104)ψ|ψ(cid:105)

=

(cid:29)

(cid:28) δψσ
ψσ

δψ∗
σ
ψ∗
σ

σ∼ψ∗ψ

−

(cid:29)

(cid:28) δψσ
ψσ

σ∼ψ∗ψ

(cid:29)

(cid:28) δψ∗
σ
ψ∗
σ

σ∼ψ∗ψ

,

(A15)

where δψ = ∂iψdθi.

(cid:28) ∂αψσ
∂βψ∗
σ
(
ψ∗
ψσ
σ
(cid:28) ∂αψσ
ψσ

Re(

∂βψ∗
σ
ψ∗
σ

(cid:29)

−

σ∼ψ∗ψ
(cid:29)

(cid:29)

(cid:28) ∂αψσ
ψσ
(cid:28) ∂αψσ
ψσ

−

σ∼ψ∗ψ
(cid:29)

σ

(cid:29)

(cid:28) ∂βψ∗
ψ∗
σ
(cid:28) ∂βψ∗
ψ∗
σ

σ

σ∼ψ∗ψ

σ∼ψ∗ψ

σ∼ψ∗ψ
(cid:29)

16

)dθαdθβ

)dθαdθβ

σ∼ψ∗ψ

(A16)

Sαβdθαdθβ,

Thus

where

ds2 =

=

=

(cid:88)

α,β

(cid:88)

α,β
(cid:88)

α,β

Sαβ = Re

(cid:32)(cid:28) ∂αψσ
ψσ

(cid:29)

∂βψ∗
σ
ψ∗
σ

σ∼ψ∗ψ

−

(cid:29)

(cid:28) ∂αψσ
ψσ

σ∼ψ∗ψ

(cid:33)

(cid:29)

(cid:28) ∂βψ∗
ψ∗
σ

σ

σ∼ψ∗ψ

(A17)

is identical to quantum version of Fisher Information Matrix utilized in SR method.

Eq. (A17) can be estimated by ADMC approach, that is:

Sαβ

(cid:29)

.
= Re(

∂βψ∗
σ
ψ∗
σ

(cid:28) ∂αψσ
ψσ
= Re((cid:104)∂α ln ψσ∂β ln ψ∗
= (cid:104)∂α ln |ψσ|∂β ln |ψσ|(cid:105)σ∈S(p) − (cid:104)∂α ln |ψσ|(cid:105)σ∈S(p) (cid:104)∂β ln |ψσ|(cid:105)σ∈S(p) + (cid:104)∂αθσ∂βθσ(cid:105)σ∈S(p) − (cid:104)∂αθσ(cid:105)σ∈S(p) (cid:104)∂βθσ(cid:105)σ∈S(p) .

σ(cid:105)σ∈S(p) − (cid:104)∂α ln ψσ(cid:105)σ∈S(p) (cid:104)∂β ln ψ∗

σ∈S(p)
σ(cid:105)σ∈S(p))

(cid:28) ∂βψ∗
ψ∗
σ

(cid:28) ∂αψσ
ψσ

σ∈S(p)

σ∈S(p)

−

(cid:29)

(cid:29)

)

σ

(A18)

Using detach function, we also have the relationship already utilized in FIM formalisms with unnormalized distribution
p:

(cid:32)

⊥∂2
αβ

ln

(cid:29)

(cid:28) Oσ
⊥Oσ

(cid:28)

−

ln

(cid:29)

Oσ
⊥Oσ

σ∈S(p)

(cid:33)

= ⊥∂α

σ∈S(p)






(cid:68) ∂β Oσ
⊥Oσ
(cid:68) Oσ
⊥Oσ

(cid:69)

σ∈S(p)

(cid:69)

σ∈S(p)

−

(cid:29)

(cid:28) ∂βOσ
Oσ

σ∈S(p)






(cid:16)

= ⊥

(cid:104)∂αOσ∂βOσ(cid:105)σ∈S(p) − (cid:104)∂αOσ(cid:105)σ∈S(p) (cid:104)∂βOσ(cid:105)σ∈S(p)

(A19)

(cid:17)

.

Note detach function at the beginning is used to emphasize this relationship is only true in value for the second
derivatives of LHS.

Considering the general computational graph setup with two graphs r and θ which gives ψσ = erσ eiθσ . Using this

relationship, Eq. (A18) can be calculated as the Hessian of an AD-aware estimator. The estimator is:

Esng = ln

(cid:29)

(cid:28) rσ
⊥rσ

σ∈S(p)

(cid:28)

−

ln

(cid:29)

rσ
⊥rσ

σ∈S(p)

+ ln

(cid:29)

(cid:28) θσ
⊥θσ

σ∈S(p)

(cid:28)

−

ln

(cid:29)

θσ
⊥θσ

.

σ∈S(p)

(A20)

This estimator can be viewed as the generalized version of KL divergence in complex distribution space.

For real positive wave function case, there will be no θ term, the Hessian of Esng is just FIM/4, where FIM is

classical Fisher Information Matrix, i.e. the Hessian of conventional KL divergence.

To summarize, the natural distance measure in wave function Hilbert space is Fubini-Study distance as in Eq. (A14).
The Hessian of it gives the inverse matrix to be applied before the gradients utilized in natural gradient method.
From the implementation perspective, such distance can be substituted by the extended version of KL divergence
as in Eq. (A20). In this context, the Hessian of extended KL estimator, quantum version of FIM, the Hessian of
Fubini-Study distance and the matrix required in SR method are literally the same thing. All these objects are
connecting with each other and it is interesting to see how SR method can emerge in the context of natural gradient
descent from information geometry without knowledge about imaginary time evolution by Schr¨odinger equation.

It is worth noting in SR method, we need to inverse FIM for natural gradient descent. However, FIM is often
peculiar with very large condition number rendering the inverse of FIM numerically unstable. The singular spectrum
of FIM has been investigated very recently [45, 57]. From implementation perspective, the most simple workaround
is adding εI on F before inverse.

