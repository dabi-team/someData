7
1
0
2

y
a
M
2
2

]

G
L
.
s
c
[

1
v
7
6
8
7
0
.
5
0
7
1
:
v
i
X
r
a

SMARTPASTE: Learning to Adapt Source Code

Miltiadis Allamanis
Microsoft Research
Cambridge, UK
t-mialla@microsoft.com

Marc Brockschmidt
Microsoft Research
Cambridge, UK
mabrocks@microsoft.com

Abstract

Deep Neural Networks have been shown to succeed at a range of natural lan-
guage tasks such as machine translation and text summarization. While tasks on
source code (i.e., formal languages) have been considered recently, most work in
this area does not attempt to capitalize on the unique opportunities offered by its
known syntax and structure. In this work, we introduce SMARTPASTE, a ﬁrst task
that requires to use such information. The task is a variant of the program repair
problem that requires to adapt a given (pasted) snippet of code to surrounding,
existing source code. As ﬁrst solutions, we design a set of deep neural models
that learn to represent the context of each variable location and variable usage
in a data ﬂow-sensitive way. Our evaluation suggests that our models can learn
to solve the SMARTPASTE task in many cases, achieving 58.6% accuracy, while
learning meaningful representation of variable usages.

1 Introduction

The advent of large repositories of source code as well as scalable machine learning methods nat-
urally leads to the idea of “big code”, i.e., largely unsupervised methods that support software en-
gineers by generalizing from existing source code. Currently, existing machine learning models
of source code capture its shallow, textual structure, e.g. as a sequence of tokens [3, 10], as parse
trees [7, 11], or as a ﬂat dependency networks of variables [16]. Such models miss out on the oppor-
tunity to capitalize on the rich and well-deﬁned semantics of source code. In this work, we take a
step to alleviate this by taking advantage of two additional elements of source code: data ﬂow and
execution paths. Our key insight is that exposing these semantics explicitly as input to a machine
learning model lessens the requirements on amounts of training data, model capacity and training
regime and allows us to solve tasks that are beyond the current state of the art.

To show how this information can be used, we introduce the SMARTPASTE structured prediction
task, in which a larger, existing piece of source code is extended by a new snippet of code and
the variables used in the pasted code need to be aligned with the variables used in the context.
This task can be seen as a constrained code synthesis task and simultaneously as a useful machine
learning-based software engineering tool. To achieve high accuracy on SMARTPASTE, we need to
learn representations of program semantics. First an approximation of the semantic role of a vari-
able (e.g., “is it a counter?”, “is it a ﬁlename?”) needs to be learned. Second, an approximation
of variable usage semantics (e.g., “a ﬁlename is needed here”) is required. “Filling the blank el-
ement(s)” is related to methods for learning distributed representations of natural language words,
such as Word2Vec [12] and GLoVe [14]. However, in our setting, we can learn from a much richer
structure, such as data ﬂow information. Thus, SMARTPASTE can be seen as a ﬁrst step towards
learning distributed representations of variable usages in an unsupervised manner. We expect such
representations to be valuable in a wide range of tasks, such as code completion (“this is the variable
you are looking for”), bug ﬁnding (“this is not the variable you are looking for”), and summarization
(“such variables are usually called filePath”).

1

 
 
 
 
 
 
int SumPositive(int[] arr λ0, int lim λ1 ) {

λ0:arr λ1:lim λ3:i λ2:sum

int sum λ2=0;
for(int i λ3 =0; iλ4 <limλ5 ; iλ6 ++)

if (arrλ7 [iλ8]>0) sumλ9 +=arrλ10 [iλ11 ];

λ7:arr

λ5:lim

λ4:i

λ8:i

return sum λ12;

}

λ10:arr

λ11:i

λ9:sum λ6:i λ12:sum

(a) Example source code, with pasted snippet shaded in
green. Tokens corresponding to variables marked by λi.
The red boxes are the placeholders whose variable needs to
be inferred in the SMARTPASTE task (ground truth variable
name shown for convenience).

(b) Dataﬂow diagram for variables
in
example, using ground truth placeholder
choices. Dotted red edges show dataﬂow
that depends on placeholder allocations.
Dashed blue edge is dataﬂow independent of
choices.

Figure 1: The snippet (shaded box, left) was pasted into the existing code. Our task is to assign vari-
ables to each placeholder (red boxes). This requires inferring the ﬂow of data between placeholders
(right).

To summarize, our contributions are: (i) We deﬁne the SMARTPASTE task as a challenge for ma-
chine learning modeling of source code, that requires to learn (some) semantics of programs (cf.
section 2). (ii) We present ﬁve models for solving the SMARTPASTE task by modeling it as a prob-
ability distribution over graph structures which represent code’s data ﬂow (cf. section 3). (iii) We
evaluate our models on a large dataset of 4.8 million lines of real-world source code, showing that
our best model achieves accuracy of 58.6% in the SMARTPASTE task while learning useful vector
representations of variables and their usages (cf. section 4).

2 The SMARTPASTE Task

We consider a task beyond standard source code completion in which we want to insert a snippet of
code into an existing program and adapt variable identiﬁers in the snippet to ﬁt the target program
(Figure 1). This is a common scenario in software development [4], when developers copy a piece
of code from a website (e.g. StackOverﬂow) or from an existing project into a new context. Further-
more, pasting code is a common source of software bugs [15], with more than 40% of Linux porting
bugs caused by the inconsistent renaming of identiﬁers.

While similar to standard code completion, this task differs in a number of important aspects. First,
only variable identiﬁers need to be ﬁlled in, whereas many code completion systems focus on a
broader task (e.g. predicting every next token in code). Second, several identiﬁers need to be ﬁlled
in at the same time and thus all choices need to be made synchronously, reﬂecting interdependencies.
This amounts to the structured prediction problem of inferring a graph structure (cf. Figure 1b).

Task Description. We view a source code ﬁle as a sequence of tokens t0 . . . tN = T . The source
code contains a set of variables v0, v1 · · · ∈ V ⊆ T . To simplify the presentation, we assume that
the source snippet to be pasted has already been inserted at the target location, and all identiﬁers in
it have been replaced by a set P of fresh placeholder identiﬁers (see Figure 1 for an example).

Thus, our input is a sequence of tokens t0 . . . tN with {tλ1 , . . . , tλK } = P, and our aim is to ﬁnd
the “correct” assignment α : P → V of variables to placeholders. For training and evaluation
purposes, a correct solution is one that simply matches the ground truth, but note that in practice,
several possible assignments could be considered correct.

3 Models

In the following, we discuss a sequence of models designed for the SMARTPASTE task, integrating
more and more known semantics of the underlying programming language. All models share the
concepts of a context representation c(t) of a token t and a usage representation u(t, v) of the usage
of a variable v at token t. The models differ in the deﬁnitions c(t) and u(t, v), but all ﬁnally try to
maximize the inner product of c(t) and u(t, v) for the correct variable assignment v at t.

2

Notation We use Vt ⊂ V to refer to the set of all variables in scope at the location of t, i.e., those
variables that can be legally used at t. Furthermore, we use Up(t, v) ∈ T ∪ {⊥} to denote the last
occurrence of variable v before t in T (resp. Un(t, v) for the next occurrence), where ⊥ is used
when no previous (resp. next) such token exists. To denote all uses of a variable v ∈ V, we use
U(v) ⊂ T . To capture the ﬂow of data through a program, we furthermore introduce the notation
Dp(t, v) ⊆ T , which denotes the set of tokens at which v was possibly last used in an execution of
the program (i.e. either read from or written to). Similarly, Dn(t, v) denotes the tokens at which v
is next used. Note that Dp(t, v) (resp. Dn(t, v)) is a set of tokens and extends the notion of Up(t, v)
(resp. Un(t, v)) which refers to a single token. Furthermore Dp(t, v) may include tokens appearing
after t (resp. Dn(t, v) may include tokens appearing before t) in the case of loops, as it happens for
variable i in λ11 and λ6 in Figure 1. Dp(t, v) and Dn(t, v) for the snippet in Figure 1 are depicted
in Figure 2.

Leveraging Variable Type Information We assume a statically typed language and that the
source code can be compiled, and thus each variable has a (known) type τ (v). To use it, we de-
ﬁne a learnable embedding function r(τ ) for known types and additionally deﬁne an “UNKTYPE”
for all unknown/unrepresented types. We also leverage the rich type hierarchy that is available in
many object-oriented languages. For this, we map a variable’s type τ (v) to the set of its supertypes,
i.e. τ ∗(v) = {τ : τ (v) implements type τ } ∪{τ (v)}. We then compute the type representation r∗(v)
of a variable v as the element-wise maximum of {r(τ ) : τ ∈ τ ∗(v)}. We chose the maximum here,
as it is a natural pooling operation for representing partial ordering relations (such as type lattices).
Using all types in τ ∗(v) allows us to generalize to unseen types that implement common supertypes
or interfaces. For example, List<K> has multiple concrete types (e.g. List<int>, List<string>).
Nevertheless, these types implement a common interface (IList) and share common characteris-
tics. During training, we randomly select a non-empty subset of τ ∗(v) which ensures training of all
known types in the lattice. This acts both like a dropout mechanism and allows us to learn a good
representation for types that only have a single known subtype in the training data.

Context Representations To ﬁll in placeholders, we need to be able to learn how they are used.
Intuitively, usage is deﬁned by the source code surrounding the placeholder, as it describes what
operations are performed on it. Consequently, we deﬁne the notion of a context of a token tk as
the sequences of C tokens before and after tk (we use C = 3). We use a learnable function f that
embeds each token t separately into a vector f (t) and ﬁnally compute the context representation
c(t) using two learnable functions gp and gn to combine the token representations as follows.

c(tk) = Wc · [gp (f (tk−C ), . . . , f (tk−1)) , gn (f (tk+1), . . . , f (tk+C ))]
Here, Wc is a simple (unbiased) linear layer. Note that we process the representation of preceding
and succeeding tokens separately, as the semantics of tokens strongly depends on their position
relative to t. In this work, we experiment with a log-bilinear model [13] and a GRU [8] for g. Our
embedding function f (t) integrates type information as follows. If t is a variable (i.e. t ∈ v) it
assigns r∗(v) to f (t). For each non-variable tokens t, it returns a learned embedding rt.

Usage Representations We learn a vector representation u(t, v) as an approximation of the se-
mantics of a variable v at position t by considering how it has been used before and after t. Here,
we consider two possible choices of representing usages, namely the lexical usage representation
and the data ﬂow usage representation of a variable.

First, we view source code as a simple sequence of tokens. We deﬁne the lexical usage representation
uL(t, v) of a variable v at placeholder t using up to L (ﬁxed to 14 during training1) usages of v
around t in lexical order. For this, we use our learnable context representation c, and deﬁne a
sequence of preceding (resp. succeeding) usages of a variable recursively as follows.
p (L − 1, t′, v) ◦ c(t′)
U L
ǫ
(cid:26)
c(t′) ◦ U L
ǫ
(cid:26)

if L > 0 ∧ t′ = Un(t, v) 6= ⊥
otherwise

if L > 0 ∧ t′ = Up(t, v) 6= ⊥
otherwise

n (L − 1, t′, v)

n (L, t, v) =

p (L, t, v) =

U L

U L

1We set L = 14 to capture the 98th percentile of our training data and also allow efﬁcient batching with

padding instead of choosing the maximum L in the data.

3

λ2

λ0

λ7

λ1

λ5

λ3

λ4

arr

lim

sum

i Dp(λ8, vi)

arr

lim

sum

i Dn(λ8, vi)

λ10

ǫ

λ9

λ11

λ6

λ12

(a) Dp(λ8, vi) for in-scope variables at λ8

(b) Dn(λ8, vi) for in-scope variables at λ8

Figure 2: Dp(λ8, v) and Dn(λ8, v) for the code in Figure 1. For each in-scope candidate v ∈ Vλ8 , a
representation is computed using the usage context of that variable before and after that placeholder.
Then, the variable v∗ = arg maxv (c(λ8))T · u(λ8, v) is selected for the placeholder. Arrows show
the dataﬂow dependencies of each variable at λ8 if that variable was to be used at this placeholder.

p (L, t, v), U L

Here, ◦ is sequence composition and ǫ is the empty sequence. Then, we can deﬁne uL(t, v) =
h(U L
n (L, t, v)), i.e. the combination of the representations of the surrounding contexts.
We will discuss two choices of h below, namely averaging and a RNN-based model. Note that c(t)
is not included in either U L

p (L, t, v) or U L

n (L, t, v)

Our second method for computing u(t, v) takes the ﬂow of data into account. Instead of using lex-
ically preceding (resp. succeeding) contexts, we consider the data ﬂow relation to identify relevant
contexts. Unlike before, there may be several predecessors (resp. successors) of a variable use in the
data ﬂow relationship, e.g. to reﬂect a conditional operation on a variable. Thus, we deﬁne a tree of
p (D, t, v), re-using our context representation c, as a limited unrolling2 of
D preceding contexts U D
the data ﬂow graph as follows.

U D

p (D, t, v) =

0), U D

p (D − 1, t′

0, v)), . . . , (c(t′

d), U D

p (D − 1, t′

d, v))}

{(c(t′
∅
(cid:26)

if D > 0 ∧ Dp(t, v) = {t′
otherwise

0, . . . , t′

d}

The tree of D succeeding contexts U D
n (D, t, v) is deﬁned analogously. For example, Figure 2 shows
U D
p (2, λ8, ·) and U D
n (2, λ8, ·) for all variables in scope at λ8 of Figure 1. We then compute a rep-
resentation for the trees using a recursive neural network, whose results are then combined with an
unbiased linear layer to obtain uD(t, v). Again, c(t) is not in either U D
Note that in this way of computing the context, lexically distant variables uses (e.g. before a long
conditional block or a loop) can be taken into account when computing a representation.

p (D, t, v) or U D

n (D, t, v).

3.1 Learning to Paste

Using the context representation c(t) of the placeholder t and the usage representations u(t, v) of
all variables v ∈ V we can now formulate the probability of a single placeholder t being ﬁlled by a
variable v as the inner product of the two vectors:

p(T [replace t by v]) ∝ (c(t))T · u(t, v)
When considering more than one placeholder, we aim to ﬁnd an assignment α : P → V such that it
maximizes the probability of the code obtained by replacing all placeholders t ∈ P according to α
at the same time, i.e.,

arg max
α

p(T [replace all t ∈ P by α(t)]).

(1)

As in all structured prediction models, training the model directly on Equation 1 is computation-
ally intractable because the normalization constant requires to compute exponentially (up to |V||P|)
many different assignments. Thus, during training, we choose to train on a single usage, i.e.
maxθ p(T [replace t by α(t) and all others are ﬁxed to ground truth]) where θ are all the parameters
of the trained model. However, this objective is still computationally expensive since it requires to
compute u(t, v) for all v of the variably-sized |V| per placeholder. To circumvent this problem and
allow efﬁcient batching, we approximate the normalization constant by using all variables in the
current minibatch and train using maximum likelihood.

2D = 15 during training to covers the 98th percentile in our training data and allows us to batch.

4

At test time, we need to ﬁll in several placeholders in a given snippet of inserted code. To
solve this structured prediction problem, we resort to iterative conditional modes (ICM), where
starting from a random allocation α, iteratively for each placeholder t, we pick the variable
v∗ = arg maxv∈Vt p(T [replace t by v]) until the assignment map α converges or we reach a maxi-
mum number of iterations. To recover from local optima, we restart the search a few times; selecting
the allocation with the highest probability. Note that Up(t, v), Un(t, v), Dp(t, v), Dn(t, v) and thus
u(t, v) change during ICM, as the underlying source code is updated to reﬂect the last chosen as-
signment α.

Model Zoo We evaluate 5 different models in this work, based on different choices for the imple-
mentation of u(t, v) and c(t).

• LOC is a baseline using only local type information, i.e. u(t, v) = r∗(v).
• AVGG averages over the (variable length) context representations of the lexical context, i.e.

u(t, v) = r∗(v) +

U L

p (L, t, v)

1
+ |U L

n (L, t, v)|  

(U L

p (L, t, v))i +

(U L

n (L, t, v))i

i
X

i
X

.

!

• GRUG uses a combination of the outputs of two GRUs to process the representations of the

(cid:12)
(cid:12)

(cid:12)
(cid:12)

lexical context, i.e.

u(t, v) = Wgru ·

RNNp

GRU(U L

p (L, t, v)), RNNn

GRU(U L

n (L, t, v))

,

where Wgru is a learned (unbiased) linear layer. Note that the two RNNs have different learned
parameters. The initial state of the RNNGRU is set to r∗(v).

(cid:2)

(cid:3)

p (D, t, v) and U D

• GRUD uses two TreeGRU models (akin to TreeLSTM of Tai et al. [19], but using a GRU cell)
over the tree structures U D
n (D, t, v), where we pool the representations com-
puted for child nodes using an element-wise maximum operation el max. The state of leafs of
the data ﬂow tree are again initialized with the type embedding of v, and thus, we have
el maxt′∈Dp(t,v)(GRU(c(t′), qp(D − 1, t′, v)))
r∗(v)

if D > 0 ∧ Dp(t, v) 6= ∅
otherwise.

qp(D, t, v) =

Analogously, we deﬁne qn(D, t, v) and combine them to obtain

(cid:26)

where WD is a learned (unbiased) linear layer.

u(t, v) = WD · [qp(D, t, v), qn(D, t, v)] ,

• HD is a hybrid between AVGG and GRUD, which uses another linear layer to combine their

usage representations into a single representation of the correct dimensionality.

4 Evaluation

Dataset We collected a dataset for the SMARTPASTE task from open source C# projects on GitHub.
To select projects, we picked the top-starred (non-fork) projects in GitHub. We then ﬁltered out
projects that we could not (easily) compile in full using Roslyn3, as we require a compilation to
extract precise type information for the code (including those types present in external libraries).
Our ﬁnal dataset contains 27 projects from a diverse set of domains (compilers, databases, . . . ) with
about 4.8 million non-empty lines of code. A full table is shown in Appendix D.

We then created SMARTPASTE examples by selecting snippets of up to 80 syntax tokens (in practice,
this means snippets are about 10 statements long) from the source ﬁles of a project that are either
children of a single AST node (e.g. a block or a for loop) or are a contiguous sequence of statements.
We then replace all variables in the pasted snippet by placeholders. The task is then to infer the
variables that were replaced by placeholders.

From our dataset, we selected two projects as our validation set. From the rest of the projects, we
selected ﬁve projects for UNSEENPROJTEST to allow testing on projects with completely unknown
structure and types. We split the remaining 20 projects into train/validation/test sets in the proportion
60-5-35, splitting along ﬁles (i.e., all examples from one source ﬁle are in the same set). We call the
test set obtained like this SEENPROJTEST.

3http://roslyn.io

5

Table 1: Evaluation of models. UNSEENPROJTEST refers to projects were not part of the train-test
split. SEENPROJTEST refers to the test set containing projects that have ﬁles in the training set.

SEENPROJTEST
GRUG

GRUD

AVGG

HD

LOC

UNSEENPROJTEST
GRUG

AVGG

GRUD

Per Placeholder

Accuracy (%)
MRR
Type Match (%)

Full Snippet Pasting

Accuracy (%)
MRR
Ex Match (%)
Type Match (%)
Type Ex Match (%)

LOC

41.0
0.562
58.0

47.4
0.617
20.5
54.1
32.0

57.8
0.719
68.4

57.9
0.711
30.3
67.3
37.9

Single Placeholder Same-Type Decisions

PR AUC
Precision@10%

0.543
87.0

0.819
96.5

4.1 Quantitative Evaluation

58.8
0.723
70.0

57.5
0.712
31.3
66.7
39.3

0.835
99.1

56.2
0.701
67.8

55.3
0.693
28.8
64.5
36.1

0.806
98.7

59.5
0.727
70.2

58.6
0.716
30.7
68.0
38.7

0.830
97.5

27.9
0.476
47.5

31.7
0.491
8.2
45.4
18.5

0.494
64.0

55.2
0.709
64.6

54.9
0.709
22.5
62.7
31.1

0.849
99.5

52.8
0.683
62.8

49.9
0.666
22.3
56.8
27.1

0.839
98.8

51.3
0.664
61.7

49.3
0.655
21.6
56.4
26.5

0.833
98.6

HD

56.2
0.710
65.4

54.5
0.700
25.0
61.2
30.5

0.833
99.0

As a structured prediction problem, there are multiple measures of performance on the task. In the
ﬁrst part of Table 1, we report metrics when considering one placeholder at a time, i.e. as if we are
pasting a single variable identiﬁer. Accuracy reports the percent of correct predictions, MRR reports
the mean reciprocal rank of each prediction. We also measure type correctness, i.e. the percent of
single-placeholder suggestions that yielded a suggestion of the correct type. In a similar fashion, we
present the results when pasting a full snippet. Now, we perform structured prediction over all the
placeholders within each snippet, so we can now further compute exact match metrics over all the
placeholders. All the models reported here are using a log-bilinear model for computing the context
representation c(tk). Using a GRU for computing c(tk) yielded slightly worse results for all models.
We believe that this is due to optimization issues caused by the increased depth of the network.

Our results in Table 1 show that LOC — as expected — performs worse than all other models, in-
dicating that our other models learn valuable information from the provided usage contexts. Some-
what surprisingly, our relatively simple AVGG already performs well. On the other hand, GRUD
performs worse than models not taking the ﬂow of data into account. We investigated this behavior
more closely and found that the lexical context models can often proﬁt from observing the use of
variables in other branches of a conditional statement (i.e., peek at the then case when handling
a snippet in the else branch). Consequently, HD, which combines data ﬂow information with all
usages always achieves high performance using both kinds of information. Finally, to evaluate the
need for type information, we run the experiments removing all type information. This — on average
— resulted to an 8% reduced performance on the SMARTPASTE task on all models.

Same-Type Decisions So far, we considered the SMARTPASTE task where for each placeholder
the neural networks consider all variables in scope. However, if we assume that we know the desired
type of the placeholder, we can limit the set of suggestions. The last set of metrics in Table 1
evaluate this scenario, i.e. the suggestion performance within placeholders that have two or more
type-correct possible suggestions. In our dataset, there are on average 5.4 (median 2) same-type
variables in-scope per placeholder used in this evaluation. All networks (except LOC) achieve high
precision-recall with a high AUC. This implies that our networks do not just learn typing information.
Furthermore, for 10% recall our best model achieves a precision of 99.1%. First, this suggests that
these models can be used as a high-precision method for detecting bugs caused by copy-pasting or
porting that the code’s existing type system would fail to catch. Additionally, this indicates that
our model have learned a probabilistic reﬁnement of the existing type system, i.e., that they can
distinguish counters from other int variables; ﬁle names from other strings; etc.

Generalization to new projects Generalizing across a diverse set of source code projects with
different domains is an important challenge in machine learning. We repeat the evaluation using
the UNSEENPROJTEST set stemming from projects that have no ﬁles in the training set. The right
side of Table 1 shows that our models still achieve good performance, although it is slightly lower
compared to SEENPROJTEST, especially when matching variable types. This is expected since the
type lattice is mostly unknown in UNSEENPROJTEST. We believe that some of the most important

6

private static Stream GetStreamForUrl(string url λ1,

string pageUrl λ2 , IHTMLElement element λ3){

if (UrlHelper.IsFileUrl(url λ4 )) {

string path λ5 = new Uri(urlλ6 ).LocalPath;
if (File.Exists(pathλ7 )) {

return File.OpenRead(pathλ8 );

} else {

if (ApplicationDiagnostics.AutomationMode)

Trace.WriteLine("File "+urlλ9 +" not found");

else

Trace.Fail("File "+ urlλ10 +" not found");

return null;

}

}else if (UrlHelper.IsUrlDownloadable(url λ11)) {

return HttpRequestHelper.SafeDownloadFile(url λ12 );

}else{

...

Placeholder λ6
url: 96%, element:
pageUrl: 1%

2%,

Placeholder λ7
path: 86%,
element: 1e-3

url:

Placeholder λ8
path: 99%,
pageUrl: 4e-5

url:

14%,

1%,

Placeholder λ9
path:
97%,
pagrUrl: 4e-3%

Placeholder λ10
path:
pageUrl: 5%

67%,

url: 2%,

url: 24%,

Figure 3: SMARTPASTE suggestion on snippet of the SEENPROJTEST set. HD suggests all the
red placeholders (λ6 to λ10) in the shaded area (λ5 is a declaration). The probability for each
placeholder is shown on the right. Note that there are multiple string variables in scope (url,
pageUrl, path). However, HD learns usage patterns (e.g. url is a parameter of IsFileUrl) to
assign different representations to each variable usage. This allows us to discriminate between path,
url and pageUrl. The model ranks second the ground truth for λ9, λ10 suggesting path instead,
which nevertheless seems reasonable. Variable names are not used in the model, but are shown for
convenience. Additional visualizations are available in Appendix C.

issues when transferring to new domains is the fact that projects have signiﬁcantly different type
hierarchies and that the vocabulary used (e.g. by method names) is very different from the training
projects.

4.2 Qualitative Evaluation

We show an example of the SMARTPASTE task in Figure 3, where we can observe that the model
learns to discriminate both among variables with different types (elements of type IHTMLElement
is not confused with string variables) as well as assigning more ﬁne-grained semantics (url and
path are treated separately) as implied by the results for our same-type scenario above.

In Figure 4, we show placeholders that have highly similar usage context representations u(t, v).
Qualitatively, Figure 4 and the visualizations in Appendix B suggest that the learned representations
can be used as a learned similarity metric for variable usage semantics. These representations learn
protocols and conventions such as “after accessing X, we should access Y” or the need to condition-
ally check a property, as shown in Figure 4.

We observed a range of common problems. Most notably, variables that are declared but not ex-
plicitly initialized (e.g. as a method parameter) cause the usage representation to be uninformative,
grouping all such declarations into the same representation. The root cause is the limited information
available in the context representations. Local optima in ICM and UNK tokens also are common.

5 Related Work

Our work builds upon the recent ﬁeld of using machine learning for source code artifacts. Recent
research has lead to language models of code that try to model the whole code. Bhoopchand et al.
[6], Hindle et al. [10] model the code as a sequence of tokens, while Maddison and Tarlow [11],
Raychev et al. [17] model the syntax tree structure of code. All the work on language models of
code ﬁnd that predicting variable and method identiﬁers is one of biggest challenges in the task. We
are not aware of any models that attempt to use data ﬂow information for variables.

7

...
_generatedCodeAnalysisFlagsOpt = generatedCodeAnalysisFlagsOpt;
...
context.RegisterCompilationStartAction(this.OnCompilationStart);
if (

.HasValue)

?

context.ConfigureGeneratedCodeAnalysis( _generatedCodeAnalysisFlagsOpt .Value);

...

...
var symbolAndProjectId = await definition.TryRehydrateAsync(
_solution, _cancellationToken).ConfigureAwait(false);

if (!
lock (_gate){

?

.HasValue) return;

_definitionMap[definition]= symbolAndProjectId .Value;

}
...

?

) with similar usage embeddings u(t, v).

Figure 4: Placeholders (in black
Both
_generatedCodeAnalysisFlagsOpt and symbolAndProjectId implement the Nullable inter-
.HasValue) is not used when computing u(t, v) but data
face. Note that the local context if(
ﬂow information of the other usages is used (marked in yellow). In this example, the model learns
a common representation for Nullables that are assigned and then conditionally used by accessing
the .HasValue property. The formatting of the snippets has been changed for space saving. More
examples can be found in Appendix A.

?

Closest to our work is the work of Allamanis et al. [2] who learn distributed representations of vari-
ables using all their usages to predict their names. However, they do not use data ﬂow information
and only consider semantically equivalent renaming of variables (α-renaming). Finally, the work of
Raychev et al. [16] is also relevant, as it uses a dependency network between variables. However,
all variable usages are deterministically known beforehand (as the code is complete and remains
unmodiﬁed), as in Allamanis et al. [1, 2].

Our work is remotely related to work on program synthesis using sketches [18] and automated code
transplantation [5]. However, these approaches require a set of speciﬁcations (e.g. input-output
examples, test suites) to complete the gaps, rather than statistics learned from big code. These
approaches can be thought as complementary to ours, since we learn to statistically complete the
gaps without any need for speciﬁcations, by learning common dataﬂow structure from code.

Our problem has also similarities with coreference resolution in NLP and methods for the structured
prediction of graphs and — more commonly — trees. However, given the different characteristics
of the problems, such as the existence of exact execution path information, we are not aware of
any work that would be directly relevant. Somewhat similar to our work, is the work of Clark and
Manning [9], who create a neural model that learns to rank pairs of clusters of mentions to either
merge them into a single co-reference entity or keep them apart.

6 Discussion & Conclusions

Although source code is well understood and studied within other disciplines such as programming
language research, it is a relatively new domain for deep learning. It presents novel opportunities
compared to textual or perceptual data, as its (local) semantics are well-deﬁned and rich additional
information can be extracted using well-known, efﬁcient program analyses. On the other hand,
integrating this wealth of structured information poses an interesting challenge. Our SMARTPASTE
task exposes these opportunities, going beyond more simple tasks such as code completion. We
consider it as a ﬁrst proxy for the core challenge of learning the meaning of source code, as it
requires to probabilistically reﬁne standard information included in type systems.

We see a wealth of opportunities in the research area. To improve on our performance on the SMART-
PASTE task, we want to extend our models to additionally take identiﬁer names into account, which

8

are obviously rich in information. Similarly, we are interested in exploring more advanced tasks
such as bug ﬁnding, automatic code reviewing, etc.

Acknowledgments

We would like to thank Alex Gaunt for his valuable comments and suggestions.

References

[1] M. Allamanis, E. T. Barr, C. Bird, and C. Sutton. Learning natural coding conventions. In International

Symposium on Foundations of Software Engineering (FSE), 2014.

[2] M. Allamanis, E. T. Barr, C. Bird, and C. Sutton. Suggesting accurate method and class names.

In

Foundations of Software Engineering (FSE), 2015.

[3] M. Allamanis, H. Peng, and C. Sutton. A convolutional attention network for extreme summarization of
source code. In Proceedings of The 33rd International Conference on Machine Learning, pages 2091–
2100, 2016.

[4] S. Amann, S. Proksch, S. Nadi, and M. Mezini. A study of Visual Studio usage in practice. In Interna-

tional Conference on Software Analysis, Evolution, and Reengineering (SANER), 2016.

[5] E. T. Barr, M. Harman, Y. Jia, A. Marginean, and J. Petke. Automated software transplantation.

In

Proceedings of the 2015 International Symposium on Software Testing and Analysis, 2015.

[6] A. Bhoopchand, T. Rocktäschel, E. Barr, and S. Riedel. Learning Python code suggestion with a sparse

pointer network. arXiv preprint arXiv:1611.08307, 2016.

[7] P. Bielik, V. Raychev, and M. Vechev. PHOG: probabilistic model for code. In International Conference

on Machine Learning, 2016.

[8] K. Cho, B. van Merriënboer, D. Bahdanau, and Y. Bengio. On the properties of neural machine translation:

Encoder–decoder approaches. Syntax, Semantics and Structure in Statistical Translation, 2014.

[9] K. Clark and C. D. Manning. Improving coreference resolution by learning entity-level distributed repre-

sentations. arXiv preprint arXiv:1606.01323, 2016.

[10] A. Hindle, E. T. Barr, Z. Su, M. Gabel, and P. Devanbu. On the naturalness of software. In International

Conference on Software Engineering (ICSE), 2012.

[11] C. J. Maddison and D. Tarlow. Structured generative models of natural source code. In International

Conference on Machine Learning (ICML), 2014.

[12] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and

phrases and their compositionality. In Advances in neural information processing systems, 2013.

[13] A. Mnih and Y. W. Teh. A fast and simple algorithm for training neural probabilistic language models. In

Proceedings of the 29th International Conference on Machine Learning, 2012.

[14] J. Pennington, R. Socher, and C. D. Manning. GloVe: Global vectors for word representation. In EMNLP,

2014.

[15] B. Ray, M. Kim, S. Person, and N. Rungta. Detecting and characterizing semantic inconsistencies in

ported code. In International Conference on Automated Software Engineering (ASE), 2013.

[16] V. Raychev, M. Vechev, and A. Krause. Predicting program properties from Big Code. In ACM SIGPLAN

Notices, 2015.

[17] V. Raychev, P. Bielik, and M. Vechev. Probabilistic model for code with decision trees. In International

Conference on Object-Oriented Programming, Systems, Languages, and Applications, 2016.

[18] A. Solar-Lezama. Program synthesis by sketching. University of California, Berkeley, 2008.

[19] K. S. Tai, R. Socher, and C. D. Manning. Improved semantic representations from tree-structured long

short-term memory networks. arXiv preprint arXiv:1503.00075, 2015.

A Per Placeholder Suggestion Samples

Below we list a set of sample same-type decisions made when considering one placeholder at a time.
Some code comments and formatting have been altered for typesetting reasons. The ground truth
choice is underlined.

9

Sample 1

private static DataTable CreateDataTable(int cols, string colNamePrefix)
{

var table = new DataTable();
for (int i = 1; i <= cols; i++)
{

table.Columns.Add(new DataColumn() { ColumnName = colNamePrefix +

#1 ,

DefaultValue =

#2

});

}
table.Rows.Add(table.NewRow());
return table;

}

#1
#2

i: 84%, cols: 16%
i: 53%, cols: 47%

Sample 2

public void A_VectorClock_must_not_happen_before_itself()
{

var clock1 = VectorClock.Create();
var clock2 = VectorClock.Create();

( #1

!=

#2 ).Should().BeFalse();

}

#1
#2

clock1: 44%, clock2: 56%
clock1: 9%, clock2: 91%

Sample 3

public MergeHub(int perProducerBufferSize)
{

if ( #1

<= 0)

throw new ArgumentException("Buffer size must be positive", nameof( #2 ));

_perProducerBufferSize = perProducerBufferSize;
DemandThreshold = perProducerBufferSize/2 + perProducerBufferSize%2;
Shape = new SourceShape<T>(Out);

}

#1
1e-6
#2
2e-3

perProducerBufferSize: 100%, _perProducerBufferSize: 2e-4, DemandThreshold:

perProducerBufferSize: 100%, _perProducerBufferSize: 3e-3, DemandThreshold:

10

Sample 4

public Task UpdateRuntimeStatistics(SiloAddress siloAddress,

SiloRuntimeStatistics siloStats)

{

}

if (logger.IsVerbose)

logger.Verbose("UpdateRuntimeStatistics from {0}", siloAddress);

if (this.siloStatusOracle.GetApproximateSiloStatus(siloAddress)

!= SiloStatus.Active)

return Task.CompletedTask;

SiloRuntimeStatistics old;
// Take only if newer.
if (periodicStats.TryGetValue(siloAddress, out old)

&& old.DateTime > siloStats.DateTime)

return Task.CompletedTask;

#1 [siloAddress] =

#2 ;

NotifyAllStatisticsChangeEventsSubscribers(siloAddress,
return Task.CompletedTask;

#3 );

#1
#2
#3

periodicStats: 94%, PeriodicStats: 6%
siloStats: 89%, old: 11%
old: 54%, siloStats: 46%

Sample 5

public override BoundNode VisitLocal(BoundLocal node)
{

LocalSymbol localSymbol = node.LocalSymbol;
CheckAssigned(localSymbol, node.Syntax);

if (localSymbol.IsFixed &&

(this. #1 .MethodKind == MethodKind.AnonymousFunction ||
this. #2 .MethodKind == MethodKind.LocalFunction) &&

#3 .Contains(localSymbol))

{

Diagnostics.Add(ErrorCode.ERR_FixedLocalInLambda,

new SourceLocation(node.Syntax), localSymbol);

}
return null;

}

#1
#2
#3

currentMethodOrLambda: 100%, topLevelMethod: 4e-3
currentMethodOrLambda: 100%, topLevelMethod: 2e-4
_writtenVariables: 60%,_capturedVariables: 40%

Sample 6

private IDbContextServices InitializeServices()
{

if ( #1 )
{

throw new InvalidOperationException(CoreStrings.RecursiveOnConfiguring);

}

...

#1

_initializing: 73%, _disposed: 27%

11

Sample 7

public static IMutableForeignKey GetOrAddForeignKey(

[NotNull] this IMutableEntityType entityType,
[NotNull] IReadOnlyList<IMutableProperty> properties,
[NotNull] IMutableKey principalKey,
[NotNull] IMutableEntityType principalEntityType)

{

}

Check.NotNull( #1 , nameof( #2 ));

return

#3 .FindForeignKey(properties, principalKey,

#4 )

??

#5 .AddForeignKey(properties, principalKey,

#6 );

#1
#2
#3
#4
#5
#6

entityType: 100%, principalEntityType: 4e-3
entityType: 100%, principalEntityType: 3e-4
entityType: 78%, principalEntityType: 22%
principalEntityType: 100%, entityType: 2e-3
principalEntityType: 60%, entityType: 30%
entityType: 99%, principalEntityType: 1%

Sample 8

public string URL
{

get
{

if ( #1
{

== null)

// Read the URL into a string
Stream stream = (Stream)m_dataObject.GetData(DataFormatsEx.URLFormat);
StreamReader reader = new StreamReader(stream);

using (reader)
{

#2

= reader.ReadToEnd().Trim((char)0);

}

}
return

#3 ;

}

}

#1
#2
#3

m_url: 90%, m_title: 5%, URL: 4%, Title: 1%
m_url: 84%, Title:13%, m_title: 1%, URL: 1%,
m_url: 99%, m_title: 4e-3, URL: 3e-3, Title:6e-4

12

Sample 9

internal static byte[] UrlEncodeToBytes(byte[] bytes, int offset, int count)
{

if (bytes == null)

throw new ArgumentNullException("bytes");

int blen = bytes.Length;
== 0)
if ( #1

return ArrayCache.Empty<byte>();

if ( #2

< 0 ||

#3

>=

#4 )

throw new ArgumentOutOfRangeException("offset");

...

#1
#2
#3
#4

blen: 85%, offset: 9%, count: 6%
offset: 43%, blen: 36%, count: 21%
offset: 76%, blen: 13%, count: 11%
count: 60%, offset: 31%, blen: 10%

Sample 10

private static List<UsingDirectiveSyntax> AddUsingDirectives(

CompilationUnitSyntax root, IList<UsingDirectiveSyntax> usingDirectives)

{

// We need to try and not place the using inside of a directive if possible.
var usings = new List<UsingDirectiveSyntax>();
var endOfList = root.Usings.Count - 1;
var startOfLastDirective = -1;
var endOfLastDirective = -1;
for (var i = 0;
{

< root.Usings.Count;

#2 ++)

#1

if (root.Usings[ #3 ].GetLeadingTrivia()

.Any(trivia => trivia.IsKind(SyntaxKind.IfDirectiveTrivia)))

{

}

#4

=

#5 ;

if (root.Usings[ #6 ].GetLeadingTrivia()

.Any(trivia => trivia.IsKind(SyntaxKind.EndIfDirectiveTrivia)))

{

}

#7

=

#8 ;

i: 98%, endOfList: 1%, startOfLastDirective: 2e-3, endOfLastDirective: 3e-3
i: 99%, endOfList: 2e-3, startOfLastDirective: 6e-3, endOfLastDirective: 1e-3
i: 100%, endOfList: 1e-4, startOfLastDirective: 3e-4%, endOfLastDirective:

endOfLastDirective: 58%, startOfLastDirective: 30%, endOfList: 1%, i: 3e-3
endOfLastDirective: 77%, startOfLastDirective: 12%, i: 6%, endOfList: 5%
i: 100%, endOfList: 1e-3, startOfLastDirective: 2e-4, endOfLastDirective: 5e-4
endOfLastDirective: 52%, startOfLastDirective: 37%, endOfList: 1%, i: 3e-3,
i: 53%, endOfLastDirective: 27%, startOfLastDirective: 13%, endOfList: 7%

}

...

#1
#2
#3
5e-5
#4
#5
#6
#7
#8

13

B Nearest Neighbor of Usage Representations

Here we show pairs of nearest neighbors based on the cosine similarity of the learned representations
u(t, v). Each placeholder t is marked as
and all usages of v are marked in yellow (i.e.
variableName ). Although names of variables are shown for convenience, they are not used (only
their types — if known — is used). This is a set of hand-picked examples showing good and bad
examples. A brief description follows after each pair.

?

Sample 1

public void SetDateTime(string year, string month, string day)
{

string time = "";
if (year.Contains(":"))
{

?

= year;

year = DateTime.Now.Year.ToString();
TimeInfo = true;

}

DateTime = DateTime.Parse(string.Format("{0}/{1}/{2} {3}", year,

DateTime = DateTime.ToLocalTime();

month, day, time ));

}

public void MakeMultiDirectory(string dirName)
{

string path = "";
string[] dirs = dirName.Split(’/’);
foreach (string dir in dirs)
{

if (!string.IsNullOrEmpty(dir))
{

?

= URLHelpers.CombineURL(path, dir);

MakeDirectory(URLHelpers.CombineURL(Options.Account.FTPAddress, path ));

}

}

WriteOutput("MakeMultiDirectory: " + dirName);

}

⊲ Usage context where a string has been initialized to blank but may be reassigned before it is used.

14

Sample 2

...
FtpWebRequest request = (FtpWebRequest)WebRequest.Create(url);

?

.Proxy = Options.ProxySettings;

request .Method = WebRequestMethods.Ftp.ListDirectory;
request .Credentials = new NetworkCredential(Options.Account.Username,

Options.Account.Password);

request .KeepAlive = false;
request .Timeout = 10000;
request .UsePassive = !Options.Account.IsActive;

using (WebResponse response = request .GetResponse()) {
...

...
FtpWebRequest request = (FtpWebRequest)WebRequest.Create(url);

?

.Proxy = Options.ProxySettings;

request .Method = WebRequestMethods.Ftp.RemoveDirectory;
request .Credentials = new NetworkCredential(Options.Account.Username,

Options.Account.Password);

request .KeepAlive = false;

request .GetResponse();
...

⊲ Similar protocols when using an object.

Sample 3

...
var addMethod = @event.AddMethod;
Assert.Equal(voidType,
Assert.True( addMethod .ReturnsVoid);
Assert.Equal(1, addMethod .ParameterCount);
Assert.Equal(eventType, addMethod .ParameterTypes.Single());
...

.ReturnType);

?

...
var removeMethod = @event.RemoveMethod;
Assert.Equal(voidType,
Assert.True( removeMethod .ReturnsVoid);
Assert.Equal(1, removeMethod .ParameterCount);
Assert.Equal(eventType, removeMethod .ParameterTypes.Single());
...

.ReturnType);

?

⊲ These two placeholders have — by deﬁnition — identical representations.

15

Sample 4

...
int index = flpHotkeys.Controls.GetChildIndex(Selected);

int newIndex;

if (
{

?

== 0)

newIndex = flpHotkeys.Controls.Count - 1;

}
else
{

newIndex = index - 1;

}

flpHotkeys.Controls.SetChildIndex(Selected, newIndex);
manager.Hotkeys.Move( index , newIndex);
...

...
if (Selected != null && flpHotkeys.Controls.Count > 1)
{

int index = flpHotkeys.Controls.GetChildIndex(Selected);

int newIndex;

if (
{

?

== flpHotkeys.Controls.Count - 1)

newIndex = 0;

}
else
{

newIndex = index + 1;

}

flpHotkeys.Controls.SetChildIndex(Selected, newIndex);
manager.Hotkeys.Move( index , newIndex);

...

16

Sample 5

int index = flpHotkeys.Controls.GetChildIndex(Selected);
int newIndex ;
if (index == 0)
{

?

= flpHotkeys.Controls.Count - 1;

}
else
{

newIndex = index - 1;

}
flpHotkeys.Controls.SetChildIndex(Selected, newIndex );
manager.Hotkeys.Move(index, newIndex );

int index = flpHotkeys.Controls.GetChildIndex(Selected);
int newIndex ;
if (index == 0)
{

newIndex = flpHotkeys.Controls.Count - 1;

}
else
{

?

= index - 1;

}
flpHotkeys.Controls.SetChildIndex(Selected, newIndex );
manager.Hotkeys.Move(index, newIndex );

⊲ Because of the dataﬂow, these two placeholders (one in each branch of the if-else) have identical
representations in the dataﬂow model, and have very similar representations in other models.

17

Sample 6

_generatedCodeAnalysisFlagsOpt = generatedCodeAnalysisFlagsOpt;
...
context.RegisterCompilationStartAction(this.OnCompilationStart);

if (
{

?

.HasValue)

// Configure analysis on generated code.
context.ConfigureGeneratedCodeAnalysis( _generatedCodeAnalysisFlagsOpt .Value);

}
...

...
var symbolAndProjectId = await definition.TryRehydrateAsync(
_solution, _cancellationToken).ConfigureAwait(false);

if (!
{

?

.HasValue)

return;

}

lock (_gate)
{

_definitionMap[definition] = symbolAndProjectId .Value;

}
...

⊲ Our model learns a similar representation for the placeholder between the locations where a
Nullable variable is assigned and used, which corresponds to a check on the .HasValue prop-
erty.

Sample 7

var analyzers = new DiagnosticAnalyzer[] { new ConcurrentAnalyzer(typeNames) };
var expected = new DiagnosticDescription[typeCount];
for (int i = 0;
{

< typeCount; i ++)

?

var typeName = $"C{ i + 1}";
expected[ i ] = Diagnostic(ConcurrentAnalyzer.Descriptor.Id, typeName)

.WithArguments(typeName)
.WithLocation( i + 2, 7);

}

var builder = new StringBuilder();
var typeCount = 100;
var typeNames = new string[typeCount];
for (int i = 1;
{

?

<= typeCount; i ++)

var typeName = $"C{ i }";
typeNames[ i - 1] = typeName;
builder.Append($"\r\nclass {typeName} {{ }}");

}

⊲ The model learns — unsurprisingly — a very similar representation of the loop control variable i
at the location of the bound check. Generalizing over varying loops.

18

Sample 8

...
if (!
{

?

)

if (disposeManagedResources)
{

_resizerControl.SizerModeChanged +=

new SizerModeEventHandler(resizerControl_SizerModeChanged);

_resizerControl.Resized -= new EventHandler(resizerControl_Resized);
_dragDropController.Dispose();

}

}
...

...
if (!
{

_disposed = true;

?

)

_enableRealTimeWordCount = Settings.GetBoolean(SHOWWORDCOUNT, false);
_enableRealTimeWordCountInit = true;

}
return _enableRealTimeWordCount;
...

⊲ Similar representations for booleans that will be assigned to true within a branch.

Sample 9

...
SmartContentSelection selection = EditorContext.Selection as SmartContentSelection;
if (
{

!= null)

?

return selection .HTMLElement.sourceIndex == HTMLElement.sourceIndex;

}
else
{

return false;

}
...

...
foreach (LiveClipboardFormat format in formats)
{
ContentSourceInfo contentSource = FindContentSourceForLiveClipboardFormat(format);
if (

!= null)

?

return contentSource ;

}
...

⊲ Representation for elements that will be returned but only one one path.

19

Sample 10

...
Rectangle elementRect = ElementRectangle;
_resizerControl.VirtualLocation = new Point(

elementRect .X - ResizerControl.SIZERS_PADDING,
.Y - ResizerControl.SIZERS_PADDING);

?

...

...
Rectangle rect = CalculateElementRectangleRelativeToBody(HTMLElement);
IHTMLElement body = (HTMLElement.document as IHTMLDocument2).body;

_dragBufferControl.VirtualSize = new Size(body.offsetWidth, body.offsetHeight);
_dragBufferControl.VirtualLocation = new Point(- rect .X, -
_dragBufferControl.Visible = true;
...

.Y);

?

⊲ Protocol of accesses for Rectangle objects. After X has been accessed then the variable has the
same representation (implied that Y is highly likely to be accessed next)

Sample 11

...
if ( parameters != null)
{

for (int i = 0; i < parameters .Length; i += 2)
{

string name =
string val = parameters [i + 1];
if (!cullMissingValues || (val != null && val != string.Empty))

[i];

?

Add(name, val);

}

}
...

...
string[] refParams = value.Split(commaSeparator);

if ( refParams .Length != 2 || string.IsNullOrEmpty( refParams [0])

throw new ArgumentException("Reference path is invalid.");

|| string.IsNullOrEmpty( refParams [1]))

ModuleName =
ResourceId = int.Parse( refParams [1]);

[0];

?

referencePath = value;
...

⊲ Similar representation for ﬁrst array access after bound checks.

20

Sample 12

...
public static string GetHostName(string url )
{

if (!IsUrl(

?

))

return null;

return new Uri( url ).Host;

}
...

...
public static bool IsUrlLinkable(string url )
{

if (UrlHelper.IsUrl(
{

?

))

Uri uri = new Uri( url );
foreach (string scheme in NonlinkableSchemes)

if (uri.Scheme == scheme)

return false;

}
return true;

}
...

⊲ Similar representations because of learned pattern when parsing URIs.

21

Sample 13

...
private void WriteEntry(string message, string category , string stackTrace)
{

// Obtain the DateTime the message reached us.
DateTime dateTime = DateTime.Now;

// Default the message, as needed.
if (message == null || message.Length == 0)

message = "[No Message]";

// Default the category, as needed.
if ( category == null || category .Length == 0)

?

= "None";

int seqNum = Interlocked.Increment(ref sequenceNumber);

DebugLogEntry logEntry = new DebugLogEntry(facility, processId, seqNum,

dateTime, message, category , stackTrace);

...

...
private void WriteEntry(string message , string category, string stackTrace)
{

// Obtain the DateTime the message reached us.
DateTime dateTime = DateTime.Now;

// Default the message, as needed.
if ( message == null || message .Length == 0)

?

= "[No Message]";

// Default the category, as needed.
if (category == null || category.Length == 0)

category = "None";

int seqNum = Interlocked.Increment(ref sequenceNumber);

DebugLogEntry logEntry = new DebugLogEntry(facility, processId, seqNum,

dateTime, message , category, stackTrace);

...

⊲ The variables message and category (in the same snippet of code) have similar representations.
This is a source of confusion for our models.

22

Sample 14

...
foreach (string file in files)
{

string[] chunks =
switch (chunks[0])
{

...

?

.Split(INTERNAL_EXTERNAL_SEPARATOR);

...
Uri uri = new Uri(url);
foreach (string scheme in NonlinkableSchemes)

if (uri.Scheme ==
return false;

?

)

...

⊲ Limited context (e.g. only declaration) causes variables to have similar usage representations. In
the examples file and scheme are deﬁned and used only once. This is a common source of confu-
sion for our models.

C Full Snippet Pasting Samples

Below we present some of the suggestions when using the full SMARTPASTE structured prediction.
The variables shown at each placeholder correspond to the ground truth. Underlined tokens represent
UNK tokens. The top three allocations are shown as well as the ground truth (if it is not in the top 3
suggestions). Red placeholders are the placeholders that need to be ﬁlled in when pasting. All other
placeholders are marked in superscript next to the relevant variable.

Sample 1

...
charsLeftλ1 = 0;
while (pλ2 .IsRightOf(selectionλ3 .Start))
{

charsLeftλ4 ++;
pλ5 .MoveUnit(_MOVEUNIT_ACTION.MOVEUNIT_PREVCHAR);

}
...

λ1 charsLeft: 87%, movesRight: 8%, p: 5%
λ2 p: 96%, selection: 4%, bounds: 1e-3
λ3 selection: 89%, bounds: 1%, p: 8e-3
λ4 movesRight: 66%, charsLeft: 16%, p: 1%
λ5 p: 83%, selection: 11%, bounds: 6%

23

Sample 2

...
HttpWebResponse response λ0 = null;
XmlDocument xmlDocument λ1 = new XmlDocument();
try
{

using (Blog blog λ3 = new Blog(_blogIdλ4 ))

responseλ5 = blogλ6 .SendAuthenticatedHttpRequest(notificationUrlλ7 , 10000);

// parse the results
xmlDocumentλ8 .Load(responseλ9 .GetResponseStream());

}
catch (Exception)
{

throw;

}
finally
{

if (responseλ10 != null)
responseλ11 .Close();

}
...

λ4 _hostBlogId: 12%, BlogId: 10%, _buttonId: 10%, _blogId: 1%
λ5 response: 86%, xmlDocument: 5%, notificationUrl: 3%
λ6 xmlDocument: 84%, blog: 12%, response: 2%
λ7 NotificationPollingTime: 95%, CONTENT_DISPLAY_SIZE: 2%, notificationUrl: 1%
λ8 xmlDocument: 100%, response: 9e-4, _buttonDescription: 4e-4
λ9 response: 65%, xmlDocument: 30%, _hostBlogId: 4%
λ10 response: 90%, _blogId: 3%, CurrentImage: 9e-3
λ11 response: 98%, _settingKey: 1%, xmlDocument: 9e-3

Sample 3

...
protected override void Dispose(bool disposing λ1 )
{

if (disposingλ2 )
{

if (componentsλ3 != null)

componentsλ4 .Dispose();

}
base.Dispose(disposingλ5 );

}
...

λ2 disposing: 100%, commandIdentifier: 4e-4, components: 1e-4
λ3 components: 100%, disposing: 3e-5, commandIdentifier: 2e-5
λ4 components: 100%, disposing: 9e-7, CommandIdentifier: 6e-9
λ5 disposing: 100%, components: 3e-5, CommandIdentifier: 2e-5

24

Sample 4

...
tmpRange λ1 .Start.MoveAdjacentToElement(startStopParent λ2 ,

if (tmpRange λ3.IsEmptyOfContent())
{

_ELEMENT_ADJACENCY.ELEM_ADJ_BeforeBegin);

tmpRange λ4 .Start.MoveToPointer(selection λ5 .End);
IHTMLElement endStopParent λ6 = tmpRange λ7 .Start.GetParentElement(stopFilter λ8 );

if (endStopParentλ9 != null

&& startStopParentλ10 .sourceIndex == endStopParentλ11 .sourceIndex)

{

tmpRangeλ12 .Start

.MoveAdjacentToElement(endStopParentλ13 ,

_ELEMENT_ADJACENCY.ELEM_ADJ_BeforeEnd);

if (tmpRangeλ14 .IsEmptyOfContent())
{

tmpRangeλ15 .MoveToElement(endStopParentλ16 , true);
if (maximumBoundsλ17 .InRange(tmpRangeλ18 )

&& !(endStopParentλ19 is IHTMLTableCell))

deleteParentBlockλ20 = true;

{

}

}

}

}
...

λ9 startStopParent: 97%, styleTagId: 1%, tmpRange: 1%, endStopParent: 3e-3
λ10 startStopParent: 100%, tmpRange: 2e-4, maximumBounds: 3e-5
λ11 startStopParent: 100%, styleTagId: 2e-3, endStopParent: 1e-3
λ12 tmpRange: 99%, selection: 9e-3, startStopParent: 2e-3
λ13 startStopParent: 96%, tmpRange: 2%, endStopParent: 1%
λ14 tmpRange: 98%, selection: 1%, maximumBounds: 1%
λ15 tmpRange: 98%, selection: 2%, maximumBounds: 4e-3
λ16 startStopParent: 43%, styleTagId: 29%, endStopParent: 21%
λ17 tmpRange: 70%, selection: 14%, maximumBounds: 8%
λ18 styleTagId: 84%, tmpRange: 5%, selection: 5%
λ19 startStopParent: 98%, endStopParent: 1%, styleTagId: 9e-3
λ20 deleteParentBlock: 90%, startStopParent: 4%, selection: 3%

25

Sample 5

...
public static void GetImageFormat(string srcFileName λ1 , out string extension λ2 ,

out ImageFormat imageFormat λ3 )

{

extensionλ4 = Path.GetExtension(srcFileNameλ5 )

if (extensionλ6 == ".jpg" || extensionλ7 == ".jpeg")
{

imageFormatλ8 = ImageFormat.Jpeg;
extensionλ9 = ".jpg";

.ToLower(CultureInfo.InvariantCulture);

}
else if (extensionλ10 == ".gif")
{

imageFormatλ11 = ImageFormat.Gif;

}
else
{

imageFormatλ12 = ImageFormat.Png;
extensionλ13 = ".png";

}

}
...

λ4 extension: 64%, imageFormat: 36%, JPEG_QUALITY: 1e-4
λ5 extension: 98%, srcFileName: 1%, imageFormat: 1e-3
λ6 extension: 97%, imageFormat: 1%, srcFileName: 3e-4
λ7 extension: 75%, JPG: 4%, GIF: 4%
λ8 imageFormat: 100%, extension: 1e-5, JPEG_QUALITY: 2e-6
λ9 extension: 93%, imageFormat: 2%, JPEG: 9e-3
λ10 extension: 52%, imageFormat: 15%, ICO: 6%, JPG: 6%, GIF: 6%
λ11 imageFormat: 100%, extension: 4e-4, JPEG_QUALITY: 1e-5
λ12 imageFormat: 99%, JPEG_QUALITY: 4e-3, extension: 2e-3
λ13 extension: 66%, JPG: 6%, ICO: 6%, GIF: 6%, BMP: 6%

26

Sample 6

...
BitmapData destBitmapData λ1 = scaledBitmap λ2 .LockBits(
new Rectangle(0, 0, destWidth λ3, destHeight λ4 ),
ImageLockMode.WriteOnly, scaledBitmap λ5 .PixelFormat);

try
{

...

byte* s0 λ6 = (byte*)sourceBitmapDataλ7 .Scan0.ToPointer();
int sourceStride λ8 = sourceBitmapDataλ9 .Stride;
byte* d0 λ10 = (byte*)destBitmapDataλ11 .Scan0.ToPointer();
int destStride λ12 = destBitmapDataλ13 .Stride;

for (int y λ14 = 0; y λ15 < destHeight λ16 ; y λ17 ++)
{

byte* d λ18 = d0 λ19 + y λ20 * destStride λ21;
byte* sRow λ22 = s0 λ23 + ((int)(y λ24 * yRatio λ25 )

+ yOffset λ26) * sourceStride λ27 + xOffset λ28 ;

λ7 sourceBitmapData: 72%, destBitmapData: 28%, bitmap: 2e-6
λ9 sourceBitmapData: 90%, destBitmapData: 10%, bitmap: 1e-4
λ11 sourceBitmapData: 75%, destBitmapData: 25%, s0: 1e-5
λ13 sourceBitmapData: 83%, destBitmapData: 17%, bitmap: 3e-4

27

Sample 7

...
private static Stream GetStreamForUrl(string url λ1, string pageUrl λ2,

IHTMLElement element λ3)

{

if (UrlHelper.IsFileUrl(url λ4 ))
{

string path λ5 = new Uri(urlλ6 ).LocalPath;
if (File.Exists(pathλ7 ))
{

return File.OpenRead(pathλ8 );

}
else
{

if (ApplicationDiagnostics.AutomationMode)

Trace.WriteLine("File " + urlλ9 + " not found");

else

Trace.Fail("File " + urlλ10 + " not found");

return null;

}

}
else if (UrlHelper.IsUrlDownloadable(url λ11 ))
{

return HttpRequestHelper.SafeDownloadFile(url λ12 );

}
else
{

...

λ6 url: 96%, element: 2%, pageUrl: 1%
λ7 path: 86%, url: 14%, element: 1e-3
λ8 path: 99%, url: 1%, pageUrl: 4e-5
λ9 path: 97%, url: 2%, pagrUrl: 4e-3%
λ10 path: 67%, url: 24%, pageUrl: 5%

28

Sample 8

...
public static void ApplyAlphaShift(Bitmap bitmap λ1, double alphaPercentage λ2 )
{

for (int y λ3 = 0; y λ4 < bitmap λ5 .Height; y λ6 ++)
{

for (int x λ7 = 0; x λ8 < bitmap λ9.Width; x λ10 ++)
{

Color c λ11 = bitmap.GetPixel(x λ12, y λ13 );
if (cλ14 .A > 0) //never make transparent pixels non-transparent
{

int newAlphaValue λ15 = (int)(cλ16 .A * alphaPercentageλ17 );
//value must be between 0 and 255
newAlphaValueλ18 = Math.Max(0, Math.Min(255, newAlphaValueλ19 ));
bitmapλ20 .SetPixel(xλ21 , yλ22 , Color.FromArgb(newAlphaValueλ23 , cλ24 ));

}
else

bitmapλ25 .SetPixel(xλ26 , yλ27 , cλ28 );

}

}

}
...

λ14 alphaPercentage: 52%, bitmap: 32%, c: 13%
λ16 bitmap: 67%, alphaPercentage: 27%, c: 4%
λ17 alphaPercentage: 85%, c: 6%, JPEQ_QUALITY: 3%
λ18 newAlphaValue: 51%, bitmap: 24%, alphaPercentage: 11%
λ19 newAlphaValue: 86%, y: 4%, alphaPercentage: 3%
λ20 bitmap: 100%, c: 4e-3, JPEG_QUALITY: 3e-4
λ21 bitmap: 98%, x: 9e-2, c: 8e-3
λ22 c: 50%, bitmap: 49%, newAlphaValue: 2e-3, y: 3e-8
λ23 alphaPercentage: 42%, JPEG_QUALITY: 40%, bitmap: 10%, newAlphaValue: 3%
λ24 newAlphaValue: 60%, alphaPercentage: 25%, c: 5%
λ25 bitmap: 100%, c: 8e-4, alphaPercentage: 3e-4
λ26 bitmap: 88%, x: 9%, c: 2%
λ27 c: 79%, bitmap: 18%, JPEG_QUALITY: 1%, y: 3e-3
λ28 c: 82%, y: 6%, x: 4%

29

Sample 9

...
string s λ1 = (string)Valueλ2 ;
byte[] data λ3;

Guid g λ4 ;
if (sλ5 .Length == 0)
{

dataλ6 = CollectionUtils.ArrayEmpty<byte>();

}
else if (ConvertUtils.TryConvertGuid(sλ7 , out gλ8))
{

dataλ9 = gλ10 .ToByteArray();

}
else
{

dataλ11 = Convert.FromBase64String(sλ12 );

}

SetToken(JsonToken.Bytes, data λ13, false);
return data λ15;
...

λ2 t: 58%, Value: 12%, _tokenType: %
λ5 TokenType: 44%, QuoteChar: 43%, _currentPosition: 4%, s: 9e-3
λ6 _tokenType: 74%, data: 20%, _currentState: 5%
λ7 QuoteChar: 31%, ValueType: 26%, Path: 9%, s: 3e-4
λ8 g: 100%, data: 6e-5, t: 3e-5
λ9 data: 99%, _tokenType: 5e-3, ValueType: 9e-4
λ10 g: 99%, data: 6e-3, _currentState: 2e-3
λ11 data: 66%, _tokenType: 31%, _currentState: 6e-3
λ12 s: 74%, Value: 20%, t: 3%

D Dataset

The collected dataset and its characteristics are listed in Table 2.

30

Table 2: Projects in our dataset. Ordered alphabetically. kLOC measures the number of non-empty
lines of C# code. Projects marked with Devwere used for validation. Projects marked with †were
in the test-only dataset. The rest of the projects were split into train-validation-test. The dataset
contains in total about 4,824kLOC.

Name

Akka.NET

AutoMapper
BenchmarkDotNet†
BotBuilder†
choco
CommonMark.NETDev
Dapper
EntityFramework
Hangﬁre†
Nancy
Newtonsoft.Json
Ninject
NLog
OpenLiveWriter
Opserver
OptiKey
orleans
Polly

ravendbDev
RestSharp
roslyn
Rx.NET
scriptcs†
ServiceStack
ShareX
SignalR
Wox†

Git SHA kLOCs

plhldrs Description

9e76d8c

6dd6adf
b4d68e9
a6be5de
73b7035
e94800e
637158f
fa0b7ec
ffc4912
422f4b4
744be1a
dbb159b
3954157
78d28eb
c0b70cb
611b94a
eaba323
b5446f6

2258b2c
e7c65df
d18aa15
594d3ee
ca9f4da
b0aacff
52bcb52
fa88089
cdaf627

236

43
23
43
34
14
18
263
33
69
119
13
67
290
24
27
223
30

647
20
1,997
180
18
205
125
53
13

183k Actor-based Concurrent & Dis-

tributed Framework

21k Object-to-Object Mapping Library
1k Benchmarking Library
32k
SDK for Building Bots
21k Windows Package Manager
7k Markdown Parser
1k Object Mapper Library
184k Object-Relational Mapper

32k Background Job Processing Library
49k HTTP Service Framework
70k
3k Code Injection Library
37k Logging Library

JSON Library

159k Text Editing Application

16k Monitoring System
14k Assistive On-Screen Keyboard
133k Distributed Virtual Actor Model

25k Resilience & Transient Fault Han-

dling Library
343k Document Database

20k REST and HTTP API Client Library

1,034k Compiler & Code Analysis

67k Reactive Language Extensions
14k C# Text Editor
33k Web Framework
91k
35k
7k Application Launcher

Sharing Application
Push Notiﬁcation Framework

31

