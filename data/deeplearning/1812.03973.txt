Bayesian Layers: A Module for Neural Network Uncertainty

Dustin Tran 1 Michael W. Dusenberry 1 Mark van der Wilk 2 Danijar Hafner 1

9
1
0
2

r
a

M
5

]

G
L
.
s
c
[

3
v
3
7
9
3
0
.
2
1
8
1
:
v
i
X
r
a

Abstract

We describe Bayesian Layers, a module designed
for fast experimentation with neural network un-
certainty. It extends neural network libraries with
drop-in replacements for common layers. This
enables composition via a uniﬁed abstraction over
deterministic and stochastic functions and allows
for scalability via the underlying system. These
layers capture uncertainty over weights (Bayesian
neural nets), pre-activation units (dropout), acti-
vations (“stochastic output layers”), or the func-
tion itself (Gaussian processes). They can also
be reversible to propagate uncertainty from input
to output. We include code examples for common
architectures such as Bayesian LSTMs, deep GPs,
and ﬂow-based models. As demonstration, we
ﬁt a 5-billion parameter “Bayesian Transformer”
on 512 TPUv2 cores for uncertainty in machine
translation and a Bayesian dynamics model for
model-based planning. Finally, we show how
Bayesian Layers can be used within the Edward2
probabilistic programming language for proba-
bilistic programs with stochastic processes. 1

1. Introduction

The rise of AI accelerators such as TPUs lets us utilize com-
putation with 1016 FLOP/s and 4 TB of memory distributed
across hundreds of processors (Jouppi et al., 2017). In prin-
ciple, this lets us ﬁt probabilistic models at many orders
of magnitude larger than state of the art. We are particu-
larly inspired by research on uncertainty-aware functions:
priors and algorithms for Bayesian neural networks (e.g.,
Wen et al., 2018; Hafner et al., 2018b), scaling up Gaussian

1Google Brain, Mountain View, California, USA 2Prowler.io,
London, United Kingdom. ∗Work done as a Google AI Resident.
Correspondence to: Dustin Tran <trandustin@google.com>.

is

at

code

1All

available

https://github.com/
tensorflow/tensor2tensor.
it ex-
tends Keras in TensorFlow (Chollet, 2016) and uses Edward2
(Tran et al., 2018) to operate with random variables. Namespaces:
import tensorflow as tf; ed=edward2. Code snippets
assume tensorflow==1.12.0.

Dependency-wise,

batch_size = 256
features, labels = load_dataset(batch_size)
lstm = layers.VariationalLSTMCell(512)
output_layer = tf.keras.layers.Dense(labels.shape[-1])
state = lstm.get_initial_state(features)
nll = 0.
for t in range(features.shape[1]):

net, state = lstm(features[:, t], state)
logits = output_layer(net)
nll += tf.losses.softmax_cross_entropy(

onehot_labels=labels[:, t], logits=logits)

kl = sum(lstm.losses) / batch_size
loss = nll + kl
optimizer = tf.train.AdamOptimizer()
train_op = optimizer.minimize(loss)

Figure 1: Bayesian RNN (Fortunato et al., 2017). Bayesian
Layers integrate easily into existing workﬂows.

Wh

Wx

xt

bh

· · ·
Wy

by

· · ·

ht

yt

Figure 2: Graphical model depiction. Default arguments
specify learnable distributions over the LSTM’s weights
and biases; we apply a deterministic output layer.

processes (e.g., Salimbeni and Deisenroth, 2017; John and
Hensman, 2018), and expressive distributions via invertible
functions (e.g., Rezende and Mohamed, 2015).

Unfortunately, while research with uncertainty-aware func-
tions are not limited by hardware, they are limited by soft-
ware. Modern systems approach this by inventing a proba-
bilistic programming language which encompasses all com-
putable probability models as well as a universal inference
engine (Goodman et al., 2012; Carpenter et al., 2016) or
with composable inference (Tran et al., 2016; Bingham
et al., 2018; Probtorch Developers, 2017). Alternatively, the
software may use high-level abstractions in order to spec-
ify and ﬁt speciﬁc model classes with a hand-derived algo-
rithm (GPy, 2012; Vanhatalo et al., 2013; Matthews et al.,
2017). These systems have all met success, but they tend

 
 
 
 
 
 
Bayesian Layers: A Module for Neural Network Uncertainty

to be monolothic in design. This prevents research ﬂexibil-
ity such as utilizing low-level communication primitives to
truly scale up models to billions of parameters.

Most recently, Edward2 provides lower-level ﬂexibility by
enabling arbitrary numerical ops with random variables
(Tran et al., 2018). However, it remains unclear how to
leverage random variables for uncertainty-aware functions.
For example, current practices with Bayesian neural net-
works require explicit network computation and variable
management (Tran et al., 2016) or require indirection by
intercepting weight instantiations of a deterministic layer
(Bingham et al., 2018). Both designs are inﬂexible for many
real-world uses in research. In practice, researchers often
use the lower numerical level—without a uniﬁed design
for uncertainty-aware functions as there are for determin-
istic neural networks and automatic diﬀerentiation. This
forces researchers to reimplement even basic methods such
as Bayes by Backprop (Blundell et al., 2015)—let alone
build on and scale up more complex baselines.

This paper describes Bayesian Layers, an extension of neu-
instead
ral network libraries which contributes one idea:
of only deterministic functions as “layers”, enable distribu-
tions over functions. Bayesian Layers does not invent a new
language. It inherits neural network semantics to specify
uncertainty-aware models as a composition of layers. Each
layer may capture uncertainty over weights (Bayesian neural
nets), pre-activation units (dropout), activations (“stochas-
tic output layers”), or the function itself (Gaussian pro-
cesses). They can also be reversible layers that propagate
uncertainty from input to output.

We include code examples for common architectures such
as Bayesian LSTMs, deep GPs, and ﬂow-based models.
As demonstration, we ﬁt a 5-billion parameter “Bayesian
Transformer” on 512 TPUv2 cores for uncertainty in ma-
chine translation and a Bayesian dynamics model for
model-based planning. Finally, we show how Bayesian
Layers can be used as primitives in the Edward2 probabilis-
tic programming language.

1.1. Related Work

There have been many software developments for distribu-
tions over functions. Our work takes classic inspiration
from Radford Neal’s software in 1995 to enable ﬂexible
modeling with both Bayesian neural nets and GPs (Neal,
1995). Modern software typically focuses on only one of
these directions. For Bayesian neural nets, researchers have
commonly coupled variational sampling in neural net lay-
ers (e.g., code and algorithms from Gal and Ghahramani
(2016); Louizos and Welling (2017)). For Gaussian pro-
cesses, there have been signiﬁcant developments in libraries
(Rasmussen and Nickisch, 2010; GPy, 2012; Vanhatalo
et al., 2013; Matthews et al., 2017; Al-Shedivat et al., 2017;

Gardner et al., 2018). Perhaps most similar to our work,
Aboleth (Aboleth Developers, 2017) features variational
BNNs and random feature approximations for GPs. Aside
from API diﬀerences from all these works, our work tries to
revive the spirit of enabling any function with uncertainty—
whether that be, e.g., in the weights, activations, or the en-
tire function—and to do so in a manner compatible with
scalable deep learning ecosystems.

A related thread are probabilistic programming languages
which build on the semantics of an existing functional
programming language. Examples include HANSEI on
OCaml, Church on Lisp, and Hakaru on Haskell (Kiselyov
and Shan, 2009; Goodman et al., 2012; Narayanan et al.,
2016). Neural network libraries can also be thought of as a
(fairly simple) functional programming language, with lim-
ited higher-order logic and a type system of (ﬁnite lists of)
n-dimensional arrays. Unlike the above probabilistic pro-
gramming approaches, Bayesian Layers doesn’t introduce
new primitives to the underlying language. As we describe
next, it overloads the existing primitives with a method to
handle randomness in any state in its execution.

2. Bayesian Layers

In neural network libraries, architectures decompose as a
composition of “layer” objects as the core building block
(Collobert et al., 2011; Al-Rfou et al., 2016; Jia et al., 2014;
Chollet, 2016; Chen et al., 2015; Abadi et al., 2015; S.
and N., 2016). These layers capture both the parameters
and computation of a mathematical function into a pro-
grammable class.

In our work, we extend layers to capture “distributions over
functions”, which we describe as a layer with uncertainty
about some state in its computation—be it uncertainty in
the weights, pre-activation units, activations, or the entire
function. Each sample from the distribution instantiates a
diﬀerent function, e.g., a layer with a diﬀerent weight con-
ﬁguration.

2.1. Bayesian Neural Network Layers

The Bayesian extension of any deterministic layer is to place
a prior distribution over its weights and biases. These lay-
ers require several considerations. Figure 1 implements a
Bayesian RNN.

Computing the integral We need to compute often-
intractable integrals over weights and biases θ. Consider for
example two cases, the variational objective for training and

Bayesian Layers: A Module for Neural Network Uncertainty

class VariationalDense(tf.keras.layers.Dense):

if FLAGS.be_bayesian:

"""Variational Bayesian dense layer."""
def __init__(self,

Conv2D = layers.VariationalConv2D

else:

units,
activation=None,
use_bias=True,
kernel_initializer=’trainable_normal’,
bias_initializer=’zero’,
kernel_regularizer=’normal_kl_divergence’,
bias_regularizer=None,
activity_regularizer=None,
**kwargs):

Conv2D = tf.keras.layers.Conv2D

model = tf.keras.Sequential([

Conv2D(32, 5, 1, padding=’SAME’),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Activation(’relu’),
Conv2D(32, kernel_size=5, strides=2, padding=’SAME’),
tf.keras.layers.BatchNormalization(),
...

super(VariationalDense, self).__init__(

])

units=units,
activation=activation,
use_bias=use_bias,
kernel_initializer=kernel_initializer,
bias_initializer=bias_initializer,
kernel_regularizer=kernel_regularizer,
bias_regularizer=bias_regularizer,
activity_regularizer=activity_regularizer,
**kwargs)

Figure 3: Bayesian layers are modularized to ﬁt ex-
isting neural net semantics of initializers, regularizers,
and layers as they deem ﬁt. Here, a Bayesian layer
with reparameterization (Kingma and Welling, 2014;
Blundell et al., 2015) is the same as its determinis-
tic implementation. The only change is the default for
kernel_{initializer,regularizer}; no additional
methods are added.

the approximate predictive distribution for testing,

(cid:90)

ELBO(θ) =

q(θ) log p(y | fθ(x)) dθ

− KL [q(θ) (cid:107) p(θ)] ,
(cid:90)

q(θ)p(y | fθ(x)) dθ.

q(y | x) =

Here, x may be a real-valued tensor as a batch of input fea-
tures, y may be a vector-valued output for each feature set,
and the function f encompasses the overall network as a
composition of layers.

To enable diﬀerent methods to estimate these integrals, we
implement each estimator as its own Layer. The same
Bayesian neural net can use entirely diﬀerent computa-
tional graphs depending on the estimation (and therefore
entirely diﬀerent code). For example, sampling from q(θ)
with reparameterization and running the deterministic layer
computation is a generic way to evaluate layer-wise inte-
grals (Kingma and Welling, 2014). Alternatively, given
small weight dimensions, one could approximate each in-
tegral deterministically via quadrature. To enable modular-
ity, the only restriction is that the overall integral estimation
can be decomposed layer-wise; Section 4 describes such re-
strictions in more depth.

Figure 4: Bayesian Layers are drop-in replacements for
their deterministic counterparts.

Signature We’d like to have the Bayesian extension of a
deterministic layer retain its mandatory constructor argu-
ments as well as its call signature of tensor-dimensional
inputs and tensor-dimensional outputs. This avoids cogni-
tive overhead, letting one easily swap layers (Figure 4; Lau-
mann and Shridhar (2018)). For example, a dense (feed-
forward) layer requires a units argument determining its
output dimensionality; a convolutional layer also includes
kernel_size. We maintain optional arguments (and add
new ones) if they make sense.

Distributions over parameters To specify distributions,
a natural idea is to overload the existing parameter initializa-
tion arguments in a Layer’s constructor; in Keras, it is ker-
nel_initializer and bias_initializer. These ar-
guments are extended to accept callables that take metadata
such as input shape and return a distribution over the param-
eter. Distribution initializers may carry trainable parame-
ters, each with their own initializers (pointwise or distri-
butional). The default initializer represents a trainable ap-
proximate posterior in a variational inference scheme (Fig-
ure 3).

For the distribution abstraction, we use Edward Random-
Variables (Tran et al., 2018). They are Tensors aug-
mented with distribution methods such as sample and
log_prob; by default, numerical ops operate on its sample
Tensor. Layers perform forward passes using deterministic
ops and the RandomVariables.

Distribution regularizers The variational training ob-
jective requires the evaluation of a KL term, which pe-
nalizes deviations of the learned q(θ) from the prior
p(θ). Similar to distribution initializers, we overload the
existing parameter regularization arguments in a layer’s
in Keras, it is kernel_regularizer and
constructor;
bias_regularizer (Figure 3). These arguments are ex-
tended to accept callables that take in the kernel or bias
RandomVariables and return a scalar Tensor. By default,

Bayesian Layers: A Module for Neural Network Uncertainty

we use a KL divergence toward the standard normal distri-
bution, which represents the penalty term common in vari-
ational Bayesian neural network training.

Explicitly returning regularizers in a Layer’s call ruins com-
posability (see Signature above). Therefore Bayesian lay-
ers, like their deterministic counterparts, side-eﬀect the
computation: one queries an attribute to access any regu-
larizers for, e.g., the loss function. Figure 1 implements a
Bayesian RNN; Appendix A implements a Bayesian CNN
(ResNet-50).

2.2. Gaussian Process Layers

As opposed to representing distributions over functions
through the weights, Gaussian processes represent distri-
butions over functions by specifying the value of the func-
tion at diﬀerent inputs. Recent advances have made Gaus-
sian process inference computationally similar to Bayesian
neural networks (Hensman et al., 2013). We only require
a method to sample the function value at a new input, and
evaluate KL regularizers. This allows GPs to be placed in
the same framework as above.2 Figure 5 implements a deep
GP.

The considerations are the same as above, and we make sim-
ilar decisions:

Computing the integral We use a separate class for
each estimator. This includes GaussianProcess for ex-
act integration, which is only possible in limited situations;
SparseGaussianProcess for inducing variable approx-
imations; and RandomFourierFeatures for projection
approximations.

the

deterministic

For example,

inputs and outputs.

Signature For
layer,
equivalent
maintain its mandatory arguments as well as tensor-
dimensional
the
number of units in a Gaussian process layer de-
termine the GP’s output dimensionality, where lay-
ers.GaussianProcess(32) is the Bayesian nonpara-
metric extension of tf.keras.layers.Dense(32).
Instead of an optional activation function argument,
GP layers have optional mean and covariance function
arguments which default to the zero function and squared
exponential kernel respectively. We also include an
optional argument for what set of inputs and outputs to
condition on: this allows the GP layer to perform both prior
and posterior predictive computations. Any state in the
layer’s computational graph may be trainable—whether
they be kernel hyperparameters or the inputs and outputs
that function conditions on.

2More broadly, these ideas extend to stochastic processes. For
example, we plan to implement a Poisson process layer for scalable
point process modeling.

batch_size = 256
features, labels = load_spatial_data(batch_size)

model = tf.keras.Sequential([

tf.keras.layers.Flatten(), # no spatial knowledge
layers.SparseGaussianProcess(units=256,

num_inducing=512),

layers.SparseGaussianProcess(units=256,

num_inducing=512),

layers.SparseGaussianProcess(units=10,

num_inducing=512),

])
predictions = model(features)
neg_log_likelihood = tf.losses.mean_squared_error(

labels=labels, predictions=predictions)

kl = sum(model.losses) / batch_size
loss = neg_log_likelihood + kl
train_op = tf.train.AdamOptimizer().minimize(loss)

Figure 5: Three-layer deep GP with variational infer-
ence (Salimbeni and Deisenroth, 2017; Damianou and
Lawrence, 2013). We apply it for regression given batches
of spatial inputs and vector-valued outputs. We ﬂatten in-
puts to use the default squared exponential kernel; this natu-
rally extends to pass in a more sophisticated kernel function.

Distribution regularizers By default, we include no reg-
ularizer for exact GPs, a KL divergence regularizer on the
inducing output distribution for sparse GPs, and a KL diver-
gence regularizer on weights for random projection approx-
imations. These defaults reﬂect each inference method’s
standard for training, where the KL regularizers use the
same implementation as the Bayesian neural nets’.

2.3. Stochastic Output Layers

In addition to uncertainty over the mapping deﬁned by a
layer, we may want to simply add stochasticity to the out-
put. These outputs have a tractable distribution, and we of-
ten would like to access its properties: for example, maxi-
mum likelihood with an autoregressive network whose out-
put is a discretized logistic mixture (Salimans et al., 2017)
(Figure 6); or an auto-encoder with stochastic encoders and
decoders (Figure 7).3

Signature To implement stochastic output
layers, we
perform deterministic computations given a tensor-
input and return a RandomVariable.
dimensional
Because RandomVariables are Tensor-like objects, one
can operate on them as if they were Tensors: composing
stochastic output layers is valid. In addition, using such a
layer as the last one in a network allows one to compute
properties such as a network’s entropy or likelihood given

3

In previous ﬁgures, we used loss functions such as
mean_squared_error. With stochastic output layers, we can
replace them with a layer returning the likelihood and calling
log_prob.

def build_image_transformer(hparams):

Conv2D = functools.partial(

Bayesian Layers: A Module for Neural Network Uncertainty

x = tf.keras.layers.Input(shape=input_shape)
x = ChannelEmbedding(hparams.hidden_size)(x)
x = tf.pad(x, [[0, 0], [1, 0], [0, 0]])[:, :-1, :])
x = PositionalEmbedding(max_length=128*128*3)(x)
x = tf.keras.layers.Dropout(0.3)(x)
for _ in range(hparams.num_layers):

y = MaskedLocalAttention1D(hparams)(x)
x = LayerNormalization()(

tf.keras.layers.Dropout(0.3)(y) + x)

y = tf.keras.layers.Dense(

x, hparams.filter_size, activation=tf.nn.relu)

encoder = tf.keras.Sequential([

Conv2D(128, 5, 1, padding=’SAME’),
Conv2D(128, 5, 2, padding=’SAME’),
Conv2D(256, 5, 2, padding=’SAME’),
Conv2D(256, 5, 2, padding=’SAME’),
Conv2D(512, 7, 1, padding=’VALID’),
layers.Normal(name=’latent_code’),

tf.keras.layers.Conv2D, activation=tf.nn.relu)

Conv2DTranspose = functools.partial(

tf.keras.layers.Conv2DTranspose, activation=tf.nn.relu)

y = tf.keras.layers.Dense(

hparams.hidden_size, activation=None)(y)

x = LayerNormalization()(

tf.keras.layers.Dropout(0.3)(y) + x)

x = layers.MixtureofLogistic(

3, num_components=5)(x)

x = layers.Discretize(x)
model = tf.keras.Model(inputs=inputs,

outputs=x,
name=’ImageTransformer’)

return model

transformer = build_image_transformer(hparams)
loss = -tf.reduce_sum(

transformer(features).distribution.log_prob(

features))

train_op = tf.train.AdamOptimizer().minimize(loss)

Figure 6:
Image Transformer with discretized logistic
mixture (Parmar et al., 2018) over 128x128x3 features.
Stochastic output layers let one easily experiment with
the likelihood. We assume layers which don’t exist in
Keras; functional versions are available in Tensor2Tensor
(Vaswani et al., 2018).

])
decoder = tf.keras.Sequential([

Conv2DTranspose(256, 7, 1, padding=’VALID’),
Conv2DTranspose(256, 5, 2, padding=’SAME’),
Conv2DTranspose(128, 5, 2, padding=’SAME’),
Conv2DTranspose(128, 5, 2, padding=’SAME’),
Conv2DTranspose(128, 5, 1, padding=’SAME’),
Conv2D(3*256, 5, 1, padding=’SAME’, activation=None),
tf.keras.layers.Reshape([256, 256, 3, 256]),
layers.Categorical(name=’image’),

])
encoding = encoder(features)
nll = decoder(encoding).distribution.log_prob(features)
kl = encoding.distribution.kl_divergence(ed.Normal(0., 1.))
loss = tf.reduce_mean(nll + kl)
train_op = tf.train.AdamOptimizer().minimize(loss)

Figure 7: A variational auto-encoder for compressing
256x256x3 ImageNet into a 32x32x3 latent code. Stochas-
tic output layers are a natural approach for specifying
stochastic encoders and decoders, and utilizing their log-
probability or KL divergence.

data.

Stochastic output layers typically don’t have mandatory
constructor arguments. An optional units argument deter-
mines its output dimensionality (operated on via a trainable
linear projection); the default maintains the input shape and
has no such projection.

2.4. Reversible Layers

With random variables in layers, one can naturally cap-
ture invertible neural networks which propagate uncertainty
from input to output. This allows one to perform transfor-
mations of random variables, ranging from simple trans-
formations such as for a log-normal distribution or high-
dimensional transformations for ﬂow-based models.

We make two considerations to design reversible lay-
ers:

Inversion Invertible neural networks are not possible
with current libraries. A natural idea is to design a new ab-
straction for invertible functions (Dillon et al., 2017). Un-

fortunately, this prevents interoperability with existing layer
and model abstractions. Instead, we simply overload the no-
tion of a “layer” by adding an additional method reverse
which performs the inverse computation of its call and op-
tionally log_det_jacobian. A higher-order layer called
layers.Reverse takes a layer as input and returns an-
other layer swapping the forward and reverse computation;
by ducktyping, the reverse layer raises an error only during
its call if reverse is not implemented. Avoiding a new
abstraction both simpliﬁes usage and also makes reversible
layers compatible with other higher-order layers such as
tf.keras.Sequential, which returns a composition of
a sequence of layers.

Propagating Uncertainty As with other deterministic
layers, reversible layers take a tensor-dimensional input and
return a tensor-dimensional output where the output dimen-
sionality is determined by its arguments. In order to prop-
agate uncertainty from input to output, reversible layers
may also take a RandomVariable as input and return a
transformed RandomVariable determined by its call, re-

Bayesian Layers: A Module for Neural Network Uncertainty

batch_size = 256
features = load_cifar10(batch_size)

model = tf.keras.Sequential([

layers.RealNVP(MADE(hidden_dims=[512, 512])),
layers.RealNVP(MADE(hidden_dims=[512, 512],

order=’right-to-left’)),

layers.RealNVP(MADE(hidden_dims=[512, 512])),

])
base = ed.Normal(tf.zeros([batch_size, 32*32*3]),

1.)

outputs = model(base)
loss = -tf.reduce_sum(outputs.distribution.log_prob(

features))

def model(input_shape):

"""Spatial point process with latent intensity."""
rate = tf.keras.Sequential([

layers.GaussianProcess(64),
layers.GaussianProcess(input_shape),
tf.keras.layers.Activation(’softplus’),

])
return layers.PoissonProcess(rate=rate)

def posterior():

"""Posterior approximation of intensity."""
rate = tf.keras.Sequential([

layers.SparseGaussianProcess(units=64,

num_inducing=512),

train_op = tf.train.AdamOptimizer().minimize(loss)

layers.SparseGaussianProcess(units=1,

Figure 8: A ﬂow-based model for image generation (Dinh
et al., 2017).

verse, and log_det_jacobian.4 Figure 8 implements
RealNVP (Dinh et al., 2017), which is a reversible layer
parameterized by another network (here, MADE (Germain
et al., 2015)). These ideas also extend to reversible networks
that enable backpropagation without storing intermediate
activations in memory during the forward pass (Gomez
et al., 2017).

2.5. Layers for Probabilistic Programming

While the framework we laid out so far tightly integrates
deep Bayesian modelling into existing ecosystems, we have
deliberately limited our scope. In particular, our layers tie
the model speciﬁcation to the inference algorithm (typi-
cally, variational inference). Bayesian Layers’ core assump-
tion is the modularization of inference per layer. This makes
inference procedures which depend on the full parameter
space, such as Markov chain Monte Carlo, diﬃcult to ﬁt
within the framework.

Figure 9 shows how one can utilize Bayesian Layers in
the Edward2 probabilistic programming language for more
ﬂexible modeling and inference. We could use, e.g., expec-
tation propagation (Bui et al., 2016; Hernández-Lobato and
Adams, 2015). See Tran et al. (2018) for details on how
to use Edward2’s tracing mechanisms for arbitrary train-
ing.

3. Experiments

We described a design for uncertainty-aware models built
on top of neural network libraries. In experiments, we illus-
trate two points: 1. Bayesian Layers is eﬃcient and makes
possible new model classes that haven’t been tried before
(in either scale or ﬂexibility); and 2. utilizing such Bayesian

4We implement layers.Discretize this way in Figure 6. It
takes a continuous RandomVariable as input and returns a trans-
formed variable with probabilities integrated over bins.

tf.keras.layers.Activation(’softplus’),

num_inducing=512),

])
return rate

Figure 9: Cox process with a deep GP prior and a sparse
GP posterior approximation. Using Bayesian Layers in a
probabilistic programming language allows for a clean dis-
tinction between modeling and inference, as well as more
ﬂexible inference algorithms.

models provides beneﬁts in applications including model-
based planning.

3.1. Model-Parallel Bayesian Transformer for

Machine Translation

Figure 10: Bayesian Transformer implemented with model
parallelism ranging from 8 TPUv2 shards (core) to 512. As
desired, the model’s training performance scales linearly as
the number of cores increases.

We implemented a “Bayesian Transformer” for the WMT14
EN-FR translation task. Using Mesh TensorFlow (Shazeer
et al., 2018), we took a 2.8 billion parameter Transformer
which reports a state-of-the-art BLEU score of 43.9. We

Bayesian Layers: A Module for Neural Network Uncertainty

turing uncertainty-aware functions, Bayesian Layers lets
one naturally experiment with and scale up Bayesian neural
networks, GPs, and ﬂow-based models.

then augmented the model with priors over the projection
matrices by replacing calls to a multihead-attention layer
with its Bayesian counterpart (using the Flipout estimator);
we also made the pointwise feedforward layers Bayesian.
Figure 10 shows that we can ﬁt models with over 5-billion
parameters (roughly twice as many due to a mean and stan-
dard deviation parameter), utilizing up to 2500 TFLOPs on
512 TPUv2 cores.

In attempting these scales, we were able to reach state-of-
the-art perplexities while achieving a higher predictive vari-
ance. This may suggest the Bayesian Transformr more cor-
rectly accounts for uncertainty given that the dataset is ac-
tually fairly small given the size of the model. We also im-
plemented a “Bayesian Transformer” for the One-Billion-
Word Language Modeling Benchmark (Chelba et al., 2013),
maintaining the same state-of-the-art perplexity of 23.1.
We identiﬁed a number of challenges in both scaling up
Bayesian neural nets and understanding their text applica-
tions; we leave this for future work separate from this sys-
tems paper.

3.2. Bayesian Dynamics Model for Model-Based

Reinforcement Learning

In reinforcement learning, uncertainty estimates can allow
for directed exploration, safe exploration, and robust con-
trol. Still relatively few works leverage deep Bayesian mod-
els for control (Gal et al., 2016; Azizzadenesheli et al.,
2018). We argue that this might be because implementing
and training these models can be diﬃcult and time consum-
ing. To demonstrate our module, we implement Bayesian
PlaNet, based on the work of Hafner et al. (2018a). The
original PlaNet agent learns a latent dynamics model as a
sequential VAE on image observations. A sample-based
planner then searches for the most promising action se-
quence in the latent space of the model.

We extend this agent by changing the fully connected lay-
ers of the transition function to their Bayesian counterparts,
VariationalDense. Swapping the layers and adding the
KL term to the loss, we reach a score of 614 on the cheetah
task, matching the performance of the original agent. We
monitor the KL divergence of the weight posterior to verify
that the model indeed learns a non-trivial belief. This result
demonstrates that incorporating model estimates into rein-
forcement learning agents can be straightforward given the
right software abstractions. The fact that the same perfor-
mance is achieved opens up many possible approaches for
exploration and robust control; see Appendix B.

4. Discussion

We described Bayesian Layers, a module designed for fast
experimentation with neural network uncertainty. By cap-

Bayesian Layers: A Module for Neural Network Uncertainty

Figure 11: Results of the Bayesian PlaNet agent. The score shows the task median performance over 5 seeds and 10
episodes each, with percentiles 5 to 95 shaded. Our Bayesian version of the method reaches the same task performance.
The graph of the weight KL shows that the weight posterior learns a non-trivial function. The open-loop video predictions
show that the agent can accurately make predictions into the future for 50 time steps.

TrueContext6101520253035404550ModelTrueModelTrueModel550010001500200002004006008001000Bayesian PlaNetPlaNetCheetah Run (Score)55001000150020005101520Weight KL (nats)Cheetah Run (Weight KL)Bayesian Layers: A Module for Neural Network Uncertainty

References

Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z.,
Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M.,
Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Is-
ard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M.,
Levenberg, J., Mané, D., Monga, R., Moore, S., Mur-
ray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B.,
Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Va-
sudevan, V., Viégas, F., Vinyals, O., Warden, P., Wat-
tenberg, M., Wicke, M., Yu, Y., and Zheng, X. (2015).
TensorFlow: Large-scale machine learning on heteroge-
neous systems. Software available from tensorﬂow.org.

Aboleth Developers (2017). Aboleth. https://github.

com/data61/aboleth.

Al-Rfou, R., Alain, G., Almahairi, A., Angermueller, C.,
Bahdanau, D., Ballas, N., Bastien, F., Bayer, J., Belikov,
A., Belopolsky, A., Bengio, Y., Bergeron, A., Bergstra,
J., Bisson, V., Bleecher Snyder, J., Bouchard, N.,
Boulanger-Lewandowski, N., Bouthillier, X., de Brébis-
son, A., Breuleux, O., Carrier, P.-L., Cho, K., Chorowski,
J., Christiano, P., Cooijmans, T., Côté, M.-A., Côté, M.,
Courville, A., Dauphin, Y. N., Delalleau, O., Demouth,
J., Desjardins, G., Dieleman, S., Dinh, L., Ducoﬀe, M.,
Dumoulin, V., Ebrahimi Kahou, S., Erhan, D., Fan, Z.,
Firat, O., Germain, M., Glorot, X., Goodfellow, I., Gra-
ham, M., Gulcehre, C., Hamel, P., Harlouchet, I., Heng,
J.-P., Hidasi, B., Honari, S., Jain, A., Jean, S., Jia, K., Ko-
robov, M., Kulkarni, V., Lamb, A., Lamblin, P., Larsen,
E., Laurent, C., Lee, S., Lefrancois, S., Lemieux, S.,
Léonard, N., Lin, Z., Livezey, J. A., Lorenz, C., Lowin,

J., Ma, Q., Manzagol, P.-A., Mastropietro, O., McGib-
bon, R. T., Memisevic, R., van Merriënboer, B., Michal-
ski, V., Mirza, M., Orlandi, A., Pal, C., Pascanu, R.,
Pezeshki, M., Raﬀel, C., Renshaw, D., Rocklin, M.,
Romero, A., Roth, M., Sadowski, P., Salvatier, J., Savard,
F., Schlüter, J., Schulman, J., Schwartz, G., Serban, I. V.,
Serdyuk, D., Shabanian, S., Simon, E., Spieckermann,
S., Subramanyam, S. R., Sygnowski, J., Tanguay, J., van
Tulder, G., Turian, J., Urban, S., Vincent, P., Visin, F.,
de Vries, H., Warde-Farley, D., Webb, D. J., Willson,
M., Xu, K., Xue, L., Yao, L., Zhang, S., and Zhang,
Y. (2016). Theano: A Python framework for fast com-
putation of mathematical expressions. arXiv preprint
arXiv:1605.02688.

Al-Shedivat, M., Wilson, A. G., Saatchi, Y., Hu, Z., and
Xing, E. P. (2017). Learning scalable deep kernels with
recurrent structure. Journal of Machine Learning Re-
search, 18(1).

Azizzadenesheli, K., Brunskill, E., and Anandkumar, A.
(2018). Eﬃcient exploration through bayesian deep q-
networks. arXiv preprint arXiv:1802.04412.

Bingham, E., Chen, J. P., Jankowiak, M., Obermeyer, F.,
Pradhan, N., Karaletsos, T., Singh, R., Szerlip, P., Hors-
Pyro: Deep
fall, P., and Goodman, N. D. (2018).
arXiv preprint
Universal Probabilistic Programming.
arXiv:1810.09538.

Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra,
D. (2015). Weight uncertainty in neural networks.
In
International Conference on Machine Learning.

Bui, T., Hernandez-Lobato, D., Hernandez-Lobato, J., Li,
Y., and Turner, R. (2016). Deep gaussian processes for re-
gression using approximate expectation propagation. In
Balcan, M. F. and Weinberger, K. Q., editors, Proceed-
ings of The 33rd International Conference on Machine
Learning, volume 48 of Proceedings of Machine Learn-
ing Research, pages 1472–1481, New York, New York,
USA. PMLR.

Carpenter, B., Gelman, A., Hoﬀman, M. D., Lee, D.,
Goodrich, B., Betancourt, M., Brubaker, M., Guo, J., Li,
P., and Riddell, A. (2016). Stan: A probabilistic pro-
gramming language. Journal of Statistical Software.

Chelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T.,
and Koehn, P. (2013). One billion word benchmark
for measuring progress in statistical language modeling.
CoRR, abs/1312.3005.

Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M.,
Xiao, T., Xu, B., Zhang, C., and Zhang, Z. (2015).
MXNet: A ﬂexible and eﬃcient machine learning library
for heterogeneous distributed systems. arXiv preprint
arXiv:1512.01274.

Bayesian Layers: A Module for Neural Network Uncertainty

Chollet, F. (2016). Keras.

fchollet/keras.

https://github.com/

Collobert, R., Kavukcuoglu, K., and Farabet, C. (2011).
Torch7: A matlab-like environment for machine learn-
ing. In BigLearn, NIPS Workshop.

Damianou, A. and Lawrence, N. (2013). Deep gaussian
processes. In Artiﬁcial Intelligence and Statistics, pages
207–215.

Dillon, J. V., Langmore, I., Tran, D., Brevdo, E., Vasude-
van, S., Moore, D., Patton, B., Alemi, A., Hoﬀman, M.,
and Saurous, R. A. (2017). TensorFlow Distributions.
arXiv preprint arXiv:1711.10604.

Dinh, L., Sohl-Dickstein, J., and Bengio, S. (2017). Density
estimation using real nvp. In International Conference on
Learning Representations.

Fortunato, M., Blundell, C., and Vinyals, O. (2017).
arXiv preprint

Bayesian recurrent neural networks.
arXiv:1704.02798.

Gal, Y. and Ghahramani, Z. (2016). Dropout as a bayesian
approximation: Representing model uncertainty in deep
learning. In international conference on machine learn-
ing, pages 1050–1059.

Gal, Y., McAllister, R., and Rasmussen, C. E. (2016). Im-
proving pilco with bayesian neural network dynamics
models. In Data-Eﬃcient Machine Learning workshop,
ICML, volume 4.

Gardner, J. R., Pleiss, G., Bindel, D., Weinberger, K. Q.,
and Wilson, A. G. (2018). Gpytorch: Blackbox matrix-
matrix gaussian process inference with gpu acceleration.
In NeurIPS.

Germain, M., Gregor, K., Murray, I., and Larochelle, H.
(2015). Made: Masked autoencoder for distribution esti-
mation. In International Conference on Machine Learn-
ing, pages 881–889.

Gomez, A. N., Ren, M., Urtasun, R., and Grosse, R. B.
(2017). The reversible residual network: Backpropaga-
tion without storing activations. In Neural Information
Processing Systems.

Goodman, N., Mansinghka, V., Roy, D. M., Bonawitz, K.,
and Tenenbaum, J. B. (2012). Church: a language for
generative models. arXiv preprint arXiv:1206.3255.

GPy (since 2012). GPy: A gaussian process framework in
python. http://github.com/SheffieldML/GPy.

Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha,
D., Lee, H., and Davidson, J. (2018a). Learning la-
tent dynamics for planning from pixels. arXiv preprint
arXiv:1811.04551.

Hafner, D., Tran, D., Irpan, A., Lillicrap, T., and Davidson,
J. (2018b). Reliable uncertainty estimates in deep neural
networks using noise contrastive priors. arXiv preprint.

Hensman, J., Fusi, N., and Lawrence, N. D. (2013). Gaus-
sian processes for big data. In Conference on Uncertainty
in Artiﬁcial Intelligence.

Hernández-Lobato, J. M. and Adams, R. P. (2015). Proba-
bilistic backpropagation for scalable learning of bayesian
In Proceedings of the 32Nd Interna-
neural networks.
tional Conference on International Conference on Ma-
chine Learning - Volume 37, ICML’15, pages 1861–
1869. JMLR.org.

Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J.,
Girshick, R., Guadarrama, S., and Darrell, T. (2014).
Caﬀe: Convolutional architecture for fast feature embed-
ding. In Proceedings of the 22nd ACM international con-
ference on Multimedia, pages 675–678. ACM.

John, S. T. and Hensman, J. (2018). Large-scale cox pro-
cess inference using variational fourier features. arXiv
preprint arXiv:1804.01016.

Jouppi, N. P., Young, C., Patil, N., Patterson, D., Agrawal,
G., Bajwa, R., Bates, S., Bhatia, S., Boden, N., Borchers,
A., et al. (2017). In-datacenter performance analysis of a
tensor processing unit. In Proceedings of the 44th Annual
International Symposium on Computer Architecture.

Kingma, D. P. and Welling, M. (2014). Auto-encoding vari-
ational Bayes. In International Conference on Learning
Representations.

Kiselyov, O. and Shan, C.-C. (2009). Embedded probabilis-
tic programming. In DSL, volume 5658, pages 360–384.
Springer.

Laumann, F. and Shridhar, K.
convolutional neural networks.
arXiv:1806.05978.

(2018).

Bayesian
arXiv preprint

Louizos, C. and Welling, M. (2017). Multiplicative nor-
malizing ﬂows for variational bayesian neural networks.
arXiv preprint arXiv:1703.01961.

Matthews, A. G. d. G., van der Wilk, M., Nickson, T., Fujii,
K., Boukouvalas, A., León-Villagrá, P., Ghahramani, Z.,
and Hensman, J. (2017). GPﬂow: A Gaussian process
library using TensorFlow. Journal of Machine Learning
Research, 18(40):1–6.

Narayanan, P., Carette, J., Romano, W., Shan, C.-c., and
Zinkov, R. (2016). Probabilistic Inference by Program
Transformation in Hakaru (System Description). In Inter-
national Symposium on Functional and Logic Program-
ming, pages 62–79, Cham. Springer, Cham.

Bayesian Layers: A Module for Neural Network Uncertainty

J. (2018). Tensor2tensor for neural machine translation.
CoRR, abs/1803.07416.

Wen, Y., Vicol, P., Ba, J., Tran, D., and Grosse, R. (2018).
Flipout: Eﬃcient pseudo-independent weight perturba-
In International Conference on
tions on mini-batches.
Learning Representations.

Neal, R. (1995). Software for ﬂexible bayesian model-
ing and markov chain sampling. https://www.cs.
toronto.edu/~radford/fbm.software.html.

Parmar, N., Vaswani, A., Uszkoreit, J., Kaiser, Ł., Shazeer,
N., Ku, A., and Tran, D. (2018). Image transformer. In
International Conference on Machine Learning.

Probtorch Developers (2017).

Probtorch.
github.com/probtorch/probtorch.

https://

Rasmussen, C. E. and Nickisch, H. (2010). Gaussian pro-
cesses for machine learning (gpml) toolbox. Journal of
machine learning research, 11(Nov):3011–3015.

Rezende, D. J. and Mohamed, S. (2015). Variational in-
ference with normalizing ﬂows. In International Confer-
ence on Machine Learning.

S., G. and N., S. (2016). TensorFlow-Slim: A lightweight li-
brary for deﬁning, training and evaluating complex mod-
els in TensorFlow.

Salimans, T., Karpathy, A., Chen, X., and Kingma, D. P.
(2017). PixelCNN++: Improving the pixelcnn with dis-
cretized logistic mixture likelihood and other modiﬁca-
tions. arXiv preprint arXiv:1701.05517.

Salimbeni, H. and Deisenroth, M. (2017). Doubly stochas-
tic variational inference for deep gaussian processes.
In Advances in Neural Information Processing Systems,
pages 4588–4599.

Shazeer, N., Cheng, Y., Parmar, N., Tran, D., Vaswani,
A., Koanantakool, P., Hawkins, P., Lee, H., Hong, M.,
Young, C., Sepassi, R., and Hechtman, B. (2018). Mesh-
TensorFlow: Deep learning for supercomputers. In Neu-
ral Information Processing Systems.

Tran, D., Hoﬀman, M. D., Moore, D., Suter, C., Vasude-
van, S., Radul, A., Johnson, M., and Saurous, R. A.
(2018). Simple, distributed, and accelerated probabilis-
tic programming. In Neural Information Processing Sys-
tems.

Tran, D., Kucukelbir, A., Dieng, A. B., Rudolph, M., Liang,
D., and Blei, D. M. (2016). Edward: A library for proba-
bilistic modeling, inference, and criticism. arXiv preprint
arXiv:1610.09787.

Vanhatalo, J., Riihimäki, J., Hartikainen, J., Jylänki, P.,
Tolvanen, V., and Vehtari, A. (2013). Gpstuﬀ: Bayesian
modeling with gaussian processes. Journal of Machine
Learning Research, 14(Apr):1175–1179.

Vaswani, A., Bengio, S., Brevdo, E., Chollet, F., Gomez,
A. N., Gouws, S., Jones, L., Kaiser, L., Kalchbrenner,
N., Parmar, N., Sepassi, R., Shazeer, N., and Uszkoreit,

Bayesian Layers: A Module for Neural Network Uncertainty

A. Bayesian ResNet-50

See Figure 12.

def conv_block(inputs, kernel_size, filters, strides=(2, 2)):

filters1, filters2, filters3 = filters
x = layers.VariationalConv2D(filters1, (1, 1),

def build_bayesian_resnet50(input_shape=None,

num_classes=1000):

strides=strides)(inputs)

inputs = tf.keras.layers.Input(shape=input_shape,

x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Activation(’relu’)(x)
x = layers.VariationalConv2D(filters2, kernel_size,

x = tf.keras.layers.ZeroPadding2D((3, 3))(inputs)
x = layers.VariationalConv2D(64, (7, 7),

dtype=’float32’)

padding=’SAME’)(x)

x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Activation(’relu’)(x)
x = layers.VariationalConv2D(filters3, (1, 1))(x)
x = tf.keras.layers.BatchNormalization()(x)
shortcut = layers.VariationalConv2D(filters3, (1,1),

strides=strides)(inputs)

shortcut = tf.keras.layers.BatchNormalization()(shortcut)
x = tf.keras.layers.add([x, shortcut])
x = tf.keras.layers.Activation(’relu’)(x)
return x

def identity_block(inputs, kernel_size, filters):

filters1, filters2, filters3 = filters
x = layers.VariationalConv2D(filters1,(1,1))(inputs)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Activation(’relu’)(x)
x = layers.VariationalConv2D(filters2, kernel_size,

padding=’SAME’)(x)

x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Activation(’relu’)(x)
x = layers.VariationalConv2D(filters3, (1,1))(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.add([x, inputs])
x = tf.keras.layers.Activation(’relu’)(x)
return x

strides=(2, 2), padding=’VALID’)(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Activation(’relu’)(x)
x = tf.keras.layers.ZeroPadding2D((1, 1))(x)
x = tf.keras.layers.MaxPooling2D((3,3), strides=(2,2))(x)
x = conv_block(x, 3, [64, 64, 256], strides=(1, 1))
x = identity_block(x, 3, [64, 64, 256])
x = identity_block(x, 3, [64, 64, 256])
x = conv_block(x, 3, [128, 128, 512])
x = identity_block(x, 3, [128, 128, 512])
x = identity_block(x, 3, [128, 128, 512])
x = identity_block(x, 3, [128, 128, 512])
x = conv_block(x, 3, [256, 256, 1024])
x = identity_block(x, 3, [256, 256, 1024])
x = identity_block(x, 3, [256, 256, 1024])
x = identity_block(x, 3, [256, 256, 1024])
x = identity_block(x, 3, [256, 256, 1024])
x = identity_block(x, 3, [256, 256, 1024])
x = conv_block(x, 3, [512, 512, 2048])
x = identity_block(x, 3, [512, 512, 2048])
x = identity_block(x, 3, [512, 512, 2048])
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = layers.VariationalDense(num_classes)(x)
model = models.Model(inputs, x, name=’resnet50’)
return model

bayesian_resnet50 = build_bayesian_resnet50()
logits = bayesian_resnet50(features)
neg_log_likelihood = tf.losses.sparse_softmax_cross_entropy(

labels=labels, logits=logits, reduction=tf.losses.reduction.MEAN)

kl = sum(bayesian_resnet50.losses) / batch_size # KL are Layer side-effects
loss = neg_log_likelihood + kl
train_op = tf.train.AdamOptimizer().minimize(loss)

# Alternatively, run the following instead of a manual train_op.
model.compile(optimizer=tf.train.AdamOptimizer(),

loss=’categorical_crossentropy’,
metrics=[’accuracy’])

model.fit(features, labels, batch_size=32, epochs=5)

Figure 12: Bayesian ResNet-50.

B. Bayesian PlaNet

See Figure 13.

Bayesian Layers: A Module for Neural Network Uncertainty

Figure 13: Given the Bayesian PlaNet agent, we predict the true velocities of the reinforcement learning environment
from its encoded latent states. Compared to Figure 7 of Hafner et al. (2018a), Bayesian PlaNet appears to capture more
information in the latent codes resulting in more precise velocity predictions (“world knowledge”).

