7
1
0
2

n
u
J

0
2

]
L
P
.
s
c
[

1
v
2
6
4
6
0
.
6
0
7
1
:
v
i
X
r
a

Towards Proof Synthesis
Guided by Neural Machine Translation
for Intuitionistic Propositional Logic

Taro Sekiyama1, Akifumi Imanishi2, and Kohei Suenaga2,3

1 IBM Research – Tokyo
2 Kyoto University
3 JST PRESTO

Abstract. Inspired by the recent evolution of deep neural networks
(DNNs) in machine learning, we explore their application to PL-related
topics. This paper is the ﬁrst step towards this goal; we propose a proof-
synthesis method for the negation-free propositional logic in which we
use a DNN to obtain a guide of proof search. The idea is to view the
proof-synthesis problem as a translation from a proposition to its proof.
We train seq2seq, which is a popular network in neural machine transla-
tion, so that it generates a proof encoded as a λ-term of a given propo-
sition. We implement the whole framework and empirically observe that
a generated proof term is close to a correct proof in terms of the tree
edit distance of AST. This observation justiﬁes using the output from a
trained seq2seq model as a guide for proof search.

1

Introduction

Deep neural networks (DNNs) saw a great success and have become one of
the most popular technologies in machine learning. They are especially good at
solving problems in which one needs to discover certain patterns in problem in-
stances (e.g., image classiﬁcation [13,26,30], image generation [9,12], and speech
recognition [8, 11]).

Compared to the huge success in these problems, their application to PL-
related problems such as program synthesis and automated theorem proving is,
in spite of recent progress [2, 5, 10, 20, 32], yet to be fully explored. This is partly
because the following gap between the PL-related areas and the areas where
DNNs are competent:

– The output of a DNN is not guaranteed to be correct; its performance is
often measured by the ratio of the correct responses with respect to the set
of test data. However, at least in the traditional formulation of PL-related
problems, the answer is required to be fully correct.

– It is nontrivial how to encode an instance of a PL-related problem as an
input to a DNN. For example, program synthesis is a problem of generating
a program P from its speciﬁcation S. Although typical representations of P
and S are abstract syntax trees, feeding a tree to a DNN requires nontrivial
encoding [20].

 
 
 
 
 
 
2

Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga

This paper reports our preliminary experimental result of the application of
DNNs to a PL-related problem, proof synthesis of the intuitionistic propositional
logic. Proof synthesis leads to solve problems of automated theorem proving,
which is one of the most fundamental problem in the theory of PL and has long
history in computer science. Automated theorem proving is also an important
tool for program veriﬁcation, where the correctness of a program is reduced to
the validity of veriﬁcation conditions. It is also of interest for program synthe-
sis because automated proof synthesis can be seen as an automated program
synthesis via the Curry–Howard isomorphism [27].

Concretely, we propose a procedure that solves the following problem:

Input A proposition T of the propositional logic represented as an AST;4
Output A proof term M of T represented as an AST of the simply typed

λ-calculus extended with pairs and sums.

One of the main purposes of the present work is to measure the baseline of the
proof synthesis with DNNs. The present paper conﬁrms how a “vanilla” DNN
framework is smart for our problem. As we describe below, we observed that
such an untuned DNN indeed works quite well.

In order to apply DNNs to our problem as easily as possible, we take the
following (admittedly simple-minded) view: proof synthesis can be viewed as
translation from a proposition to a proof term. Therefore, we should be able
to apply neural machine translation, machine translation that uses a deep neu-
ral network inside, to the proof-synthesis problem, just by expressing both a
proposition and a proof as sequences of tokens.

We adopt a sequence-to-sequence ( seq2seq) model [1, 6, 28], which achieves
good performance in English–French translation [28], for the proposition–proof
translation and train it on a set of proposition–proof pairs. Although the trained
model generates correct proofs for many propositions (see Table 3 in Section 5;
the best model generates correct proofs for almost half of the benchmark prob-
lems), it sometimes generates (1) a grammatically incorrect token sequence or (2)
an ill-typed response. As a remedy to these incorrect responses, our procedure
postprocesses the response to obtain a correct proof term.

Figure 1 overviews our proof-synthesis procedure. We explain the important

components:

– The core of our proof-synthesis method is the neural network M, which takes
the token-sequence representation γ (T ) of a proposition T as an input. M
is trained to generate a proof term of the given proposition; therefore, the
output S of M from γ (T ) is expected to be “close” to the token-sequence
representation of a correct proof term of T .

– The generated token sequence S may be grammatically incorrect. In order
to compute a parse tree M from such an incorrect sequence, we apply Myers’
algorithm [21] that produces a grammatically correct token sequence that is
closest to S in terms of the edit distance.

4 Currently, we train and test the model with propositions of the negation-free frag-

ment of this logic.

Towards Proof Synthesis Guided by Neural Machine Translation for IPL

3

Fig. 1. An overview of the proof-synthesis system.

– Using the obtained parse tree M as a guide, our procedure searches for a
correct proof of T . To this end, we enumerate parse trees in the ascending
order of the tree edit distance proposed by Zhang et al. [33]. In order to check
whether an enumerated tree M (cid:48) is a correct proof term of T , we pass it to a
proof checker. In the current implementation, we translate M (cid:48) to a Haskell
program and typecheck it using Haskell interpreter GHCi. If it typechecks
and has T , then, via the Curry–Howard isomorphism, we can conclude that
M (cid:48) is a correct proof term of T .

We remark that our proof-synthesis procedure is not complete. Indeed, it does
not terminate if a proposition that is not an intuitionistic tautology is passed.
We do not claim that we propose the best proof-synthesis procedure, because
a sound and complete proof-synthesis algorithm is known in the intuitionistic
logic [27]. The purpose of the present work is rather exploratory; we show the
possibility of DNNs, especially neural machine translation, for the problem of
automated theorem proving.

The rest of the paper is organized as follows. Section 2 deﬁnes the target logic
as a variant of the simply typed λ-calculus; Section 3 explains the sequence-to-
sequence neural network which we use for proof synthesis; Section 4 presents
the proof-synthesis procedure; Section 5 describes the experiments; Section 6
discusses related work; and Section 7 concludes.

2 Language

This section ﬁxes the syntax for propositions and proof terms. Based on the
Curry–Howard isomorphism, we use the notation of the simply typed λ-calculus
extended with pairs and sums. We hereafter identify a type with a proposition
and a λ-term with a proof.

Figure 2 shows the syntax of the target language. We use metavariables
x , y, z , . . . for variables. The target language is an extension of the simply typed
λ-calculus with products, sums, and holes. We use a hole in the synthesis proce-
dure described later to represent a partially synthesized term. Since the syntax is

Tokenizer γType TToken sequenceof type T[ “α”, “→”, … ]Trained modelMToken sequence sof term[ “λ”, “x”, … ]Correct parsing errorGuide term MSearch proofProof4

Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga

S , T ::= α | S → T | S × T | S + T
M , N ::= [ ] | x | λx .M | M N | (M , N ) | case M of (x , y) → N |

Left M | Right M | case M of { Left x → N1; Right y → N2}

Γ

::= ∅ | Γ, x :T

Γ (cid:96) M : T

Typing

Fig. 2. Syntax.

Γ (cid:96) [ ] : T

T Hole

x :T ∈ Γ
Γ (cid:96) x : T

T Var

Γ, x :S (cid:96) M : T
Γ (cid:96) λx .M : S → T

T Abs

Γ (cid:96) M : S → T Γ (cid:96) N : S
Γ (cid:96) M N : T

T App

Γ (cid:96) M : S Γ (cid:96) N : T
Γ (cid:96) (M , N ) : S × T

T Pair

Γ (cid:96) M : S × T Γ, x :S , y:T (cid:96) N : T (cid:48)
Γ (cid:96) case M of (x , y) → N : T (cid:48)

T CasePair

Γ (cid:96) M : S
Γ (cid:96) Left M : S + T

T Left

Γ (cid:96) M : T
Γ (cid:96) Right M : S + T

T Right

Γ (cid:96) M : S + T Γ, x :S (cid:96) N1 : T (cid:48) Γ, y:T (cid:96) N2 : T (cid:48)
Γ (cid:96) case M of { Left x → N1; Right y → N2} : T (cid:48)

T CaseSum

Fig. 3. Typing rules.

standard (except holes), we omit an explanation of each construct. We also omit
the dynamic semantics of the terms; it is not of interest in the present paper.
Free and bound variables are deﬁned in the standard way: a lambda abstraction
λx .M binds x in M ; a case expression for pairs case M of (x , y) → N binds x
and y in N ; a case expression for sums case M of { Left x → N1; Right y → N2}
binds x and y in N1 and N2, respectively. We identify two α-equivalent terms as
usual. The size of a term is the number of its AST.

A typing context Γ is a set of bindings of the form x :T . It can be seen a
partial function from variables to types. The typing judgment is of the form
Γ (cid:96) M : T and asserts that M has type T under the context Γ ; the Curry–
Howard isomorphism allows it to be seen as a judgment asserting M is a proof
of T under the assumptions in Γ . Figure 3 shows the typing rules. Holes may
have any type (T-Hole); the other rules are standard.

3 Sequence-to-sequence neural network

We use the sequence-to-sequence ( seq2seq) network as a neural network to
translate a type to its inhabitant. This section reviews seq2seq brieﬂy; inter-
ested readers are referred to Sutskever et al. [28] for details. We also assume

Towards Proof Synthesis Guided by Neural Machine Translation for IPL

5

Fig. 4. seq2seq that takes input sequence (x1, . . . , xn) and produces output sequence
(y1, . . . , yn).

Fig. 5. Unfolding a LSTM unit for input sequence (x1, x2, x3, . . . ).

basic familiarity about how a neural network conducts an inference and how a
neural network is trained.

In general, application of a (deep) neural network to a supervised learning
problem consists of two phases: training and inference. The goal of the training
phase is to generate a model that approximates the probability distribution of a
given dataset called training dataset. In a supervised learning problem, a training
dataset consists of pairs of an input to and an expected output from the trained
DNN model. For example, training for an image recognition task approximates
likelihood of classes of images by taking images as inputs and their classes as
expected outputs.

Training seq2seq model approximates conditional probability distribution
p(y1, ..., ym | x1, ..., xn) where x1, ..., xn is an input and y1, ..., ym is an output
sequence. After training, the trained model can be used to predict sequences
from inputs in the inference phase.

An overview of the inference with a seq2seq model is shown in Figure 4,
where X = (x1, . . . , xn) is an input and Y = (y1, . . . , ym) is an output sequence.
For each xi, seq2seq performs the following procedure.

Layer 2LSTMLayer 3 LSTM(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)[0, …, 0][0, …, 0]Initial stateLayer 1 Word embeddingLayer 4 Fully connected layer(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)x1x2xn<EOS>y1y2ym<EOS>y1ym-1ymEncoder unitDecoder unitinputoutputstatex2x1x3Initialstate…unfold6

Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga

1. xi is converted to a one-hot vector, which is a 1 × n matrix (n is the number
of vocabularies used in a dataset) where all cells are 0 except that the cell
for xi is 1.

2. The one-hot vector is converted to a matrix by the word embedding [4, 19]
(Layer 1), which compresses sparse, high-dimensional vector representations
of words to dense, low-dimensional matrices.

3. The output of word embedding is processed by 2 Long Short-Term Memory
(LSTM) units [14] (Layers 2–3). LSTMs form a directed circular graph and
will be unfolded by following the length of an input sequence, as in Figure 5.
They take an input and the previous state, which is a matrix that has the
information of the past inputs, and apply matrix operations to produce the
output and the state for the next input. LSTMs can conduct a stateful infer-
ence; future outputs can depend on past inputs. This property is important
for learning with time-series data such as sentences. In our system, the initial
state is the zero vector.

4. Finally, the output from the second LSTM is converted to a vector with n
elements at the fully connected layer (Layer 4), and the vector is translated
to a token that is most likely.

In Figure 4, the snapshot of a model at an instant is aligned vertically. These
snapshots are aligned horizontally from left to right along the ﬂow of time. An
input to a seq2seq model is a sequence of data x1, . . . , xn, each of which is
encoded as a one-hot vector. The input is terminated with a special symbol
<EOS>, which means the end of the sequence. The response from the model for
the symbol <EOS> is set to the ﬁrst element y1 of the output sequence. An output
element yi is fed to the model to obtain the next output element yi+1 until the
model produces <EOS>.

The LSTM layers work as encoders while the model is fed with an input
sequence x1, . . . , xn. They work as decoders after the model receives <EOS> and
while the model produces an output sequence y1, . . . , yn.

Since inputs to and outputs from a seq2seq model are sequences, in order
to apply seq2seq to the proof-synthesis problem, we need a sequence represen-
tation of a type. As the sequence representation of a type T , we use the token
sequence provided by a Haskell interpreter GHCi; this representation is written
γ (T ). For example, γ (α → (α → β) → β) is ( “α”, “→”, “(”, “α”, “→”, “β”, “)”,
“→”, “β”). This choice of the token-sequence representation is for convenience
of implementation; since we use GHCi as a type checker, using token sequences
in GHCi is convenient. We train seq2seq so that, when it is fed with the GHCi
token-sequence representation of a type, it outputs the token-sequence repre-
sentation of a GHCi term. We also write γ (M ) for the GHCi token-sequence
representation of term M .

Transforming outputs from seq2seq to terms is a tricky part because an
output of a seq2seq model is not always parsable as a term, as we see in
Section 5. Our synthesis procedure in Section 4 corrects parsing errors and ﬁnds
the nearest parsable token sequence by Myers’ algorithm [21].

Towards Proof Synthesis Guided by Neural Machine Translation for IPL

7

(cid:46) Feed seq2seq with the given type
(cid:46) Parse S and obtain a guide term

(cid:46) Proof search starts with the hole term
(cid:46) Search guided by M

repeat

N ← ExtractMin(q)

Procedure 1 Synthesis
1: procedure Synthesis(T )
S ← M(γ (T ))
2:
M ← NearestTerm(S)
3:
q ← The empty heap of closed terms of T (ordered by costM (−))
4:
Push(q, [ ])
5:
6:
loop
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18: end procedure

until ﬁnd term N that has not been investigated yet
if N contains no holes then

for each N (cid:48) ∈ GenCandidates(N , T ) do

end if
end loop

Push(q, N (cid:48))

return N

end for

else

We hereafter use a metavariable M for a trained seq2seq model; we write

M(S) for the sequence that M infers from the input sequence S.

4 Program Synthesis Procedure

Procedure 1 is the pseudocode of the procedure Synthesis(T ) that takes a type
T and generates a closed, hole-free term M of T . The procedure Synthesis(T )
uses a trained seq2seq model M; it is in advance trained to generate an inhab-
itant of a type.

Line 2 feeds M with γ (T ) and obtains a token sequence S that is expected
to be close to an inhabitant of T . This generated S may be incorrect in the
following two senses: (1) it may not be parsable (i.e., there may not be M such
that γ (M ) = S) and (2) even if such M exists, M may not be an inhabitant
of T . Synthesis(T ) ﬁlls these two gaps by postprocessing the output S from
seq2seq with the following two computations:

Guide synthesis Line 3 calls procedure NearestTerm that computes M such
that the edit distance between γ (M ) and S is smallest. NearestTerm uses
Myers’ algorithm [21]. The output term M from NearestTerm is called a
guide term.

Guided proof search Lines 4–17 enumerate candidate terms and test whether
each candidate is a proof term of T . In order to give higher priority to a
candidate term that is “closer” to guide term M , the procedure designates
a priority queue q. This queue orders the enqueued terms by the value of a
cost function costM (−). The cost function is a parameter of the procedure
Synthesis(T ); it is deﬁned so that the value of costM (M (cid:48)) is smaller if the

8

Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga

C ::= x | λx . [ ] | [ ] [ ] | ([ ] , [ ]) | case [ ] of (x , y) → [ ] |

Left [ ] | Right [ ] | case [ ] of { Left x → [ ] ; Right y → [ ]}

Fig. 6. Shallow contexts.

tree edit distance [33] between M and M (cid:48) is smaller. We present the deﬁnition
of the cost functions that we use later. The enumeration of the candidate
terms is continued until Synthesis(T ) encounters a correct proof of T .
Although it is not guaranteed that this procedure converges,5 experiments
presented in Section 5.5 indicate that Synthesis(T ) discovers a proof fast
in many cases compared to a brute-force proof search.

The remaining ingredient of the guided proof-search phase (Lines 4–
17) is the subprocedure GenCandidates(N , T ) that generates candidate
terms. GenCandidates(N , T ) takes two parameters: term N which may
contain several holes and type T of candidate terms to be synthesized.
GenCandidates(N , T ) generates the set of the terms that are obtained by
ﬁlling a hole in N with a shallow context C, a depth-1 term with holes, which
is deﬁned in Figure 6. Concretely, GenCandidates(N , T ) constructs a set of
candidate terms by the following steps: (1) constructing the set S such that
N (cid:48) ∈ S if and only if N (cid:48) is obtained by ﬁlling a hole in N with an arbitrary shal-
low context C in which only the variables bound at the hole can occur freely;6
and (2) ﬁltering out from S the terms that contain a βη-redex (to prune the
proof-search space) or do not have type T .

5 Preliminary Experiments

In order to conﬁrm the baseline of the proof synthesis with seq2seq and the
feasibility of our proof-synthesis method, we train seq2seq models, implement
Synthesis(T ), and measure the performance of the implemented procedure.

5.1 Environment

We implemented Synthesis in Python 3 (version 3.6.1) except for Nearest-
Term, which is implemented with OCaml 4.04.1, and the type checker, for which
we use Haskell interpreter GHCi 8.0.1; we write TypeInf (M ) for the type of M
inferred by the GHCi. Training of seq2seq and inference using the trained
seq2seq models are implemented with a deep learning framework Chainer (ver-
sion 1.24.0) [31];7 as the word2vec module, we used one provided by Python

5 If T does not have an inhabitant, then Synthesis(T ) indeed diverges.
6 Since we identify α-equivalent terms, the number of the shallow contexts that can

be ﬁlled in is ﬁnite.

7 We used the code available at https://github.com/kenkov/seq2seq with an adapta-

tion.

Towards Proof Synthesis Guided by Neural Machine Translation for IPL

9

Layer type
Word embedding
LSTM
LSTM
Fully connected layer

The number of parameters
W × 50
20 K
20 K
W × 50

Table 1. Learnable parameters in the network: W is the number of the vocabularies.

library gensim (version 0.13.4). We conduct all experiments on an instance pro-
vided by Amazon EC2 g2.2xlarge, equipped with 8 virtual CPUs (Intel Xeon E5-
2670; 2.60 GHz, 4 cores) and 15 GiB memory. Although the instance is equipped
with a GPU, it is not used in the training phase nor the inference phase.

As shown in Figure 4, our seq2seq network consists of 4 layers: a layer for
word embedding, 2 LSTMs, and a fully connected layer. Their learnable param-
eters are shown in Table 1, where W is the number of vocabularies used in the
dataset. The value of W depends on the token-sequence representation of train-
ing data; in the current dataset, it is 40. The parameters in the word embedding
are initialized by word2vec [19]; we used CBOW with negative sampling; the
window size is set to 5. The weights of the LSTMs and the last fully connected
layer are initialized by i.i.d. Gaussian sampling with mean 0 and deviation
50
(the number 50 is the output size of the previous layer of each); the biases are
initialized to 0. We trained the model with stochastic gradient descent. The loss
function is the sum of the softmax cross entropy accumulated over the token
sequence. As an optimizer, we use Adam [16] with the following parameters:
α = 0.001, β1 = 0.9, β2 = 0.999, and (cid:15) = 10−8.

√

5.2 Generating dataset

In order to train the network, we need a set of type–term pairs as training data.
Since we are not aware of publicly available such data, we used data generated by
Procedure 2 for this purpose. This procedure ﬁrst uniformly chooses an integer
s from 1 to 9, uniformly samples a term M from the set of the size-s terms,
and adds it to the dataset.8 If dataset already contains a term N of the type
TypeInf (M ) of M , the smaller one is assigned to T ; otherwise, M is added to
dataset. Models are trained on a training set that consists of 1000 pairs of a type
T and a closed hole-free term M of T .

We do not claim that a dataset generated by TrainingDataset(n) is the
best for training. Ideally, a training dataset should reﬂect the true distribution
of the type–term pairs. The current dataset does not necessarily reﬂect this
distribution in that (1) it ignores a proof with size more than 9 and (2) it gives
higher preference to smaller proofs.9 By using the repository of hand-written

8 We also conducted an experiment with a dataset that only consists of βη-normal

terms; see Section 5.3.

9 We observed that the number of well-typed terms grows exponentially with respect
to the size of a term; therefore, if we uniformly sample training data from the set of

10

Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga

(cid:46) Make n pairs of a type and its term

s ← choose from {2, ..., 9} at uniformly random
M ← generate a closed, hole-free, well-typed term of size s at random
T ← TypeInf (M )
if (T , N ) ∈ dataset for some N then

dataset ← (dataset \ {(T , N )}) ∪ {(T , M )}

dataset ← {}
while size(dataset) < n do

Procedure 2 Generation of training dataset
1: procedure TrainingDataset(n)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16: end procedure

end if
end while
return dataset

dataset ← dataset ∪ {(T , M )}

if size (M ) < size (N ) then

end if

else

proofs as the training dataset, we could approximate this distribution, which is
an important future direction of our work.

5.3 Training

We train the network using two datasets: Dtm generated by Procedure 2 and Dβη
generated in the same way but contains only βη normal forms. We trained the
network not only with Dtm but with Dβη because a proof term with a βη-redex
can be seen as a detour from the viewpoint of the proof theory [27]; therefore,
we expect that the model trained with Dβη generates a guide term that is more
succinct than one trained with Dtm. We used the following batch sizes in the
training in each training dataset: 16, 32, and 64. Each model is trained for 3000
epochs.

Figure 7 shows the smoothed plots of the training loss over epochs. Since a
loss represents the diﬀerence between expected outputs and actual outputs from
the trained model, these graphs mean that the training of each model almost
converges after 3000 epochs.

Table 2 shows examples of terms inferred by trained models from type
α1 × α2 → α2 × α1, which denotes swapping components of pairs. All terms
shown in Table 2 capture that they should take a pair (x0), decompose it by
a case expression, and compose a new pair using the decomposition result. Un-
fortunately, they are not correct proof terms of the designated type: terms in
the ﬁrst, second, ﬁfth, and sixth rows refer to incorrect variables; and ones in
the third and fourth rows decompose the argument pair only for making the ﬁrst

well-typed terms, a term with smaller size is rarely included in the dataset. By ﬁrst
ﬁxing the size s and then uniformly sampling the term of size s, we give relatively
higher preference to smaller-size terms.

Towards Proof Synthesis Guided by Neural Machine Translation for IPL

11

Fig. 7. Smoothed plots of the training loss over epochs: the left graph shows the plots
for the models trained with Dtm; the right graph shows the plots for the models trained
with Dβη; each graph contains the plots for diﬀerent batch sizes (BS).

Model
Dataset Batch size

Inferred term from α1 × α2 → α2 × α1

Dtm
Dtm
Dtm
Dβη
Dβη
Dβη

16
32
64
16
32
64

(λx0.(case x0 of (x1, x2) → (x1, x1)))
(λx0.(case x0 of (x1, x2) → (x1, x1)))
(λx0.((case x0 of (x1, x2) → x1), (Left x0)))
(λx0.((case x0 of (x1, x2) → x1), x0))
(λx0.(case x0 of (x1, x2) → (x1, x1)))
(λx0.(case x0 of (x1, x2) → (x1, x0)))

Table 2. Examples of terms inferred by trained seq2seq models.

element of the new pair. On the other hand, they somewhat resemble to a correct
proof term (e.g., λx0.case x0 of (x1, x2) → (x2, x1)). Our synthesis procedure uses
a generated (incorrect) proof term to eﬃciently search for a correct one.

5.4 Evaluation of the trained models

We quantitatively evaluate our models on the following aspects:

Parsability How many inferred strings are parsable as proof terms?
Typability How many

inferred terms,

after

the postprocessing by

NearesrtTerm, are indeed correct proofs?

Closeness How close is an inferred proof postprocessed by NearesrtTerm to

a correct proof in average?

We measure the closeness by tree edit distance [33]; we measure the edit distance
between an inferred term and a correct proof term that is the closest to the
inferred term and whose size is not more than 9.

150010001500200025003000Epoch0.00.51.01.52.02.53.0Training LossTraining on Dtm64BS32BS16BS150010001500200025003000Epoch0.00.51.01.52.02.5Training LossTraining on Dβη64BS32BS16BS12

Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga

Model

Evaluation

Dtm Dtm Dtm Dβη Dβη Dβη
Dataset
64
16
Batch size
990
983
# of parsable
# of typable
451
430
Rate of misuse of vars (%) 39.82 30.61 42.27 28.45 33.90 30.78
0.1982 0.1805 0.1831 0.1878 0.1822 0.2001
Closeness per AST node

32
988
475

16
991
515

32
987
510

64
987
463

Table 3. Evaluation of the trained models.

We generated terms using the trained models with a test dataset that consists
of 1000 types sampled by the similar way to Procedure 2 but does not contain
any type in Dtm nor Dβη. The evaluation results of the quantities above are
shown in Table 3. We discuss the result below.

– Every model generates a parsable response in more than 980 propositions out
of 1000. This rate turns out to be high enough for the call to NearestTerm
in the synthesis procedure to work in reasonable time.

– As for the number of typable responses, the number is between 430 to 515
out of 1000 depending on the training data and the batch size. We observed
that the error is often caused due to the misuse of variables. For example, as
shown in Table 2, (λx0.(case x0 of (x1, x2) → (x1, x1))) is inferred as a proof
term for the proposition α1 × α2 → α2 × α1. Although this term is incorrect,
this term is made correct by replacing the ﬁrst reference to x1 with that to x2.
The row “Rate of misuse of vars” in Table 3 is the rate of such errors among
the whole erroneous terms. Given such errors are frequent, we guess that the
combination of our method and premise selection heuristics is promising in
improving the accuracy.

– Closeness is measured by the average of the per-node minimum tree edit
distance between a generated term (postprocessed by NearestTerm) and
a correct proof term whose sizes are not more than 9. The precise deﬁnition
is

1
1000

1000
(cid:88)

i=1

min({EditDist (Ni , M ) | M ∈ DTi })
size (Ni )

is a type for the i-th test case; DTi

where Ti
is a set of closed hole-
free terms of type Ti whose sizes are not more than 9; and Ni =
NearestTerm (M(γ (Ti ))). We can observe that we need to edit about
19% of the whole nodes of a term generated by the models in average to
obtain a correct proof. We believe that this rate can be made less if we tune
the network.

5.5 Evaluation of the synthesis procedures

We evaluate Procedure 1 with several instantiations of the cost function. In the
deﬁnition of the cost functions, we use auxiliary function imitate (N , M ), which

Towards Proof Synthesis Guided by Neural Machine Translation for IPL

13

is deﬁned as follows:

imitate ([ ] , M )
imitate (λx .N , λx .M )
imitate (N1 N2, M1 M2)
imitate ((N1, N2), (M1, M2)) = (imitate (N1, M1), imitate (N2, M2))
imitate (case N1 of (x , y) → N2, case M1 of (x , y) → M2)
= case imitate (N1, M1) of (x , y) → imitate (N2, M2)

= M
= λx .imitate (N , M )
= imitate (N1, M1) imitate (N2, M2)

imitate (Left N , Left M )
imitate (Right N , Right M ) = Right imitate (N , M )
imitate (case N1 of { Left x → N2; Right y → N3},
case M1 of { Left x → M2; Right y → M3})

= Left imitate (N , M )

= case imitate (N1, M1) of { Left x → imitate (N2, M2);

Right y → imitate (N3, M3)}

imitate (N , M )

= N (Otherwise)

The function imitate (N , M ) matches the term N that contains holes against
the guide term M ; if N is a hole, then M is returned as the result. If the top
constructor of M is diﬀerent from N , then it returns N . This function is used
to express diﬀerent treatment of a hole in computation of tree edit distance.

We use the following cost functions computed from a candidate term N and

a guide term M :

– cost bf

M (N ) := size (N ) that does not take the edit distance between N and
M . Since this function ignores the guide term, Procedure 1 instantiated with
this cost function searches for a correct proof term in a brute-force way.

– cost ed

M (N ) := size (N ) + EditDist (M , N ), where size (N ) is the size of N and

EditDist (M , N ) is the tree edit distance between M and N .

– cost im

M (N ) := size (N )+EditDist (M , imitate (N , M )). Although this function
also takes the edit distance between N and M into account in the cost com-
putation, EditDist (M , imitate (N , M )) does not count the distance between
a hole in N and the corresponding subtree in M , while EditDist (M , N ) in
cost ed
M (N ) counts the distance between a hole in N and the corresponding
subtree in M .

We call Synthesisbf

for the Procedure 1 instantiated with cost bf

M (N ),
M (N ), and Synthesisim for one in-
Synthesised for one instantiated with cost ed
M (N ). Since Synthesisim treats the diﬀerence between a
stantiated with cost im
hole in a candidate N and the corresponding subtree of guide term M as cost 0,
Synthesisim is expected to be more aggressive in using the information of the
guide term. By comparing Synthesisbf against Synthesised and Synthesisim,
we can discuss the merit of using neural machine translation with respect to the
brute-force search.

We generated a test dataset that consists of 100 types in the same way as in
Section 5.3 for evaluation. We measured the running time of each procedure with
the models trained on diﬀerent training datasets and with diﬀerent batch sizes.
The result is shown in Table 3. Synthesisbf crashed due to a run-time memory

14

Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga

Procedure

Sum

ED-0 ED-1 ED-2 ED-3 ED-4 ED-5 ED-6 ED-7 ED-8 ED-10

Synthesised
Synthesisim
Synthesised
Synthesisim
Synthesised
Synthesisim
Synthesised

Dtm ,16

Dtm ,16

Dtm ,32

Dtm ,32

Dtm ,64

Dtm ,64

Synthesisim

Synthesised

Synthesisim

Synthesised

Synthesisim

Dβη ,16

Dβη ,16

Dβη ,32

Dβη ,32

Dβη ,64

Dβη ,64

Synthesisbf

1754.70
7546.57
1336.19
2142.12
1173.34
3420.96
1587.47

1.41 1.37 1.47 3.44 3.96 21.46 264.82 37.10 272.25 N/A
1.46 1.80 1.91 5.53 5.21 29.99 1681.14 30.46 296.36 N/A
1.49 1.51 11.52 1.98 8.10 35.17 59.14 N/A 243.59 N/A
1.58 1.96 37.18 2.82 11.32 47.77 110.50 N/A 412.64 N/A
1.38 1.69 1.95 3.41 8.86 30.35 40.37 N/A 425.25 N/A
1.29 1.54 1.96 3.31 5.16 32.03 45.99 N/A 2688.28 N/A
1.96
1.44 1.61 2.10 3.19 21.52 3.57

81.98 247.83 N/A

2461.17

1.51 1.87 2.10 5.16 33.90 11.57 47.72 279.12 N/A 835.55

1308.47

1.49 1.86 3.08 4.15 1.74 13.95 102.53

3.42

N/A N/A

3316.54

1.41 1.90 3.57 4.13 1.94 17.52 299.16 10.43 N/A N/A

567.61

1.31 1.50 1.85 1.98 4.73 8.30

82.06 N/A 37.18 N/A

640.44

1.20 1.55 2.04 2.16 6.97 10.02 90.30 N/A 38.67 N/A

28928.42+ –

–

–

–

–

–

–

–

–

–

Table 4. Running time of the synthesis procedure (in seconds). The column “Proce-
dure” presents the procedure name with the used training set and the batch size. The
column “Sum” presents the the sum of running time for 100 test cases. The column
ED-n presents the average of running time for the test cases in which the edit distance
between a guide term and the found proof term is n. If a cell in the column ED-n is
marked N/A, it means that there was no test case in which the edit distance between
a guide term and the found proof term was n. Synthesisbf does not have data in the
columns ED-n since it ignores the guide term.

error in the 42nd test case; the value of the Sum column for Synthesisbf in
Table 3 reports the sum of the running time until the 41st test case.

Discussion The two DNN-guided procedures Synthesised and Synthesisim are
much faster than Synthesisbf. This indicates that guide terms inferred by the
trained models are indeed useful as a hint for proof search.

Comparing the synthesis procedures with models trained with diﬀerent
datasets (i.e., Dtm and Dβη), we can observe that the models trained with Dβη
often makes the synthesis faster than the models trained on Dtm. This accords
to our expectation. Although the result seems to be also largely aﬀected by the
batch size used in the training phase, inspection about the relation between the
batch size and the performance of the synthesis procedure is left as future work.
Synthesisim is in general slower than Synthesised especially in the cases
where the edit distance is large. We guess that this is due to the following reason.
Synthesisim ﬁrst explores a term that is almost the same as the inferred guide
term since cost im
M (−) calculates edit distances by assuming that holes of proof
candidates will be ﬁlled with subterms of the guide term. This strategy is risky
because it wastes computation time if the distance between the guide term and a
correct proof is large. The result in Table 3 suggests that the current models tend
to infer a term such that it contains more errors if it is larger. This inaccuracy
leads to the worse performance of the current implementation of Synthesisim.
We think that Synthesisim becomes more eﬃcient by improving the models.

Towards Proof Synthesis Guided by Neural Machine Translation for IPL

15

The

current

implementation

computes
imitate (N , M ) in the computation of the cost function. This may also af-
fect the performance of Synthesisim. This could be improved by optimizing
the implementation of cost im

of Synthesisim explicitly

M (N ).

To conclude the discussion, the guide by neural machine translation is in-
deed eﬀective in making the proof search more eﬃcient. We expect that we
can improve the performance by improving the accuracy of the neural machine
translation module.

6 Related Work

Loos et al. [17] use a DNN to improve the clause-selection engine of the Mizar
system [3]. In their work, the input to the network is a set of unprocessed
clauses and the negation of a goal to be refuted; it is trained to recommend
which unprocessed clause to be processed. They report that their architecture
improves the performance of the proof-search algorithm. Our work shares the
same goal as theirs (i.e., DNN-assisted theorem proving) but tackles in a diﬀer-
ent approach: they use a DNN for improving heuristics of an automated theorem
prover, whereas we use a DNN for translating a proposition to its proof. They
observe that the combination of a DNN and the conventional proof search is
eﬀective in expediting the overall process, which parallels the design decisions
of our proof synthesis, which uses the proof suggested by a DNN as a guide for
proof search.

As we mentioned in Section 1, a proof-synthesis procedure can be seen as
a program-synthesis procedure via the Curry–Howard isomorphism. In this re-
gard, the DNN-based program synthesis [2, 10] are related to our work. De-
vlin et al. [10] propose an example-driven program-synthesis method for string-
manipulation problems. They compare two approaches to DNN-based program
learning: neural synthesis, which learns a program written in a DSL from in-
put/output examples, and neural induction, which does not explicitly synthesize
a program but uses a learned model as a map for unknown inputs. Balog et
al. [2] propose a program-synthesis method for a functional DSL to manipu-
late integer lists. Their implementation synthesizes a program in two steps as
we do: a DNN generates a program from a set of input–output pairs; then, the
suggested program is modiﬁed for a correct program. Both of Devlin et al. and
Balog et al. study inductive program synthesis that generates a program from
given input–output examples, while our work corresponds to program synthe-
sis from given speciﬁcations. The state-of-the-art program synthesis with type
speciﬁcations [23] is generating programs from liquid types [25], which allow for
representing a far richer speciﬁcation than STLC. We are currently investigating
whether our proof-as-translation view is extended to a richer type system (or,
equivalently, a richer logic).

16

Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga

7 Conclusion

We proposed a proof-synthesis procedure for the intuitionistic propositional logic
based on neural machine translation. Our procedure generates a proof term from
a proposition using the sequence-to-sequence neural network. The network is
trained in advance to translate the token-sequence representation of a proposi-
tion to that of its proof term. Although we did not carefully tuned the network,
it generates correct proofs to the almost half of the benchmark problems. We ob-
served that an incorrect proof is often close to a correct one in terms of the tree
edit distance. Based on this observation, our procedure explores a correct proof
using the generated proof as a guide. We empirically showed that our procedure
generates a proof more eﬃciently than a brute-force proof-search procedure. As
far as we know, this is the ﬁrst work that applies neural machine translation to
automated theorem proving.

As we mentioned in Section 1, one of the main purposes of the present paper
is to measure the baseline of DNN-based automated proof synthesis. The result
of our experiments in Section 5 suggests that the current deep neural network
applied to automated proof synthesis can be trained so that it generates a good
guess to many problems, which is useful to make a proof-search process eﬃcient.
We believe that this result opens up several research directions that are worth
being investigated. One of these directions is to extend the target language. Al-
though we set our target to a small language (i.e., the intuitionistic propositional
logic) in the present paper, automated proof synthesis for more expressive logic
such as Calculus of Construction [7] and separation logic [15, 24] is useful. In an
expressive logic, we guess that we need more training data to avoid overﬁtting.
To obtain such large amount of data, we consider using an open-source reposi-
tory of the proofs written in the language of proof assistants such as Coq [18]
and Agda [22].

Another future direction is to improve the performance of the neural machine
translation. In general, the performance of a deep neural network is known to
be largely aﬀected by how well the network is tuned. Besides the network itself,
we guess that the performance may be improved by tuning the representation
of propositions and proofs. For example, we used the inﬁx notation to represent
a proposition (e.g., S → T for an implication), although a proof term for an
implication is an abstraction λx .M . If we represent an implication in the postﬁx
notation (i.e., (S, T )→), then the symbol → in the proposition and the symbol
λ in the proof term comes closer in a training data, which may lead to a better
performance of sequence-to-sequence networks as is suggested by Sutskever et
al. [28].

The current proof-search phase uses several variants of cost functions to
prioritize the candidates to be explored. By tuning this function, we expect
that we can make the synthesis procedure faster. We are currently looking at
the application of reinforcement learning [29] to automatically search for a cost
function that leads to a good performance of the overall synthesis procedure.

Towards Proof Synthesis Guided by Neural Machine Translation for IPL

17

Acknowledgments

We would like to thank Takayuki Muranushi for making a prototype implemen-
tation of the early proof synthesizer without DNNs. We also appreciate Akihiro
Yamamoto; the discussion with him leads to the evaluation metrics used in this
paper. This paper is partially supported by JST PRESTO Grant Number JP-
MJPR15E5, Japan.

References

1. Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly learning

to align and translate. CoRR abs/1409.0473 (2014)

2. Balog, M., Gaunt, A.L., Brockschmidt, M., Nowozin, S., Tarlow, D.: Deepcoder:

Learning to write programs. CoRR abs/1611.01989 (2016)

3. Bancerek, G., Bylinski, C., Grabowski, A., Kornilowicz, A., Matuszewski, R., Nau-
mowicz, A., Pak, K., Urban, J.: Mizar: State-of-the-art and beyond. In: Intelligent
Computer Mathematics - International Conference, CICM 2015, Washington, DC,
USA, July 13-17, 2015, Proceedings. pp. 261–279 (2015)

4. Bengio, Y., Ducharme, R., Vincent, P., Janvin, C.: A neural probabilistic language
model. Journal of Machine Learning Research 3, 1137–1155 (2003), http://www.
jmlr.org/papers/v3/bengio03a.html

5. Bhatia, S., Singh, R.: Automated correction for syntax errors in programming

assignments using recurrent neural networks. CoRR abs/1603.06129 (2016)

6. Cho, K., van Merrienboer, B., G¨ul¸cehre, C¸ ., Bougares, F., Schwenk, H., Bengio, Y.:
Learning phrase representations using RNN encoder-decoder for statistical machine
translation. CoRR abs/1406.1078 (2014)

7. Coquand, T., Huet, G.P.: The calculus of constructions. Inf. Comput. 76(2/3),

95–120 (1988)

8. Dahl, G.E., Yu, D., Deng, L., Acero, A.: Context-dependent pre-trained deep neural
networks for large-vocabulary speech recognition. IEEE Trans. Audio, Speech &
Language Processing 20(1), 30–42 (2012)

9. Denton, E.L., Chintala, S., szlam, a., Fergus, R.: Deep generative image models
using a laplacian pyramid of adversarial networks. In: Cortes, C., Lawrence, N.D.,
Lee, D.D., Sugiyama, M., Garnett, R. (eds.) Advances in Neural Information Pro-
cessing Systems 28, pp. 1486–1494. Curran Associates, Inc. (2015)

10. Devlin, J., Uesato, J., Bhupatiraju, S., Singh, R., Mohamed, A., Kohli, P.: Robust-
ﬁll: Neural program learning under noisy I/O. CoRR abs/1703.07469 (2017)
11. Graves, A., Mohamed, A., Hinton, G.E.: Speech recognition with deep recurrent

neural networks. CoRR abs/1303.5778 (2013)

12. Gregor, K., Danihelka, I., Graves, A., Rezende, D.J., Wierstra, D.: DRAW: A recur-
rent neural network for image generation. In: Proceedings of the 32nd International
Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015. pp.
1462–1471 (2015)

13. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.
In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
(June 2016)

14. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Computation

9(8), 1735–1780 (1997)

18

Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga

15. Ishtiaq, S.S., O’Hearn, P.W.: BI as an assertion language for mutable data struc-
tures. In: Hankin, C., Schmidt, D. (eds.) Conference Record of POPL 2001: The
28th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Lan-
guages, London, UK, January 17-19, 2001. pp. 14–26. ACM (2001)

16. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. CoRR

abs/1412.6980 (2014)

17. Loos, S.M., Irving, G., Szegedy, C., Kaliszyk, C.: Deep network guided proof search.

CoRR abs/1701.06972 (2017)

18. The Coq development team: The Coq proof assistant reference manual. LogiCal

Project (2004), version 8.0

19. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Eﬃcient estimation of word repre-

sentations in vector space. CoRR abs/1301.3781 (2013)

20. Mou, L., Li, G., Zhang, L., Wang, T., Jin, Z.: Convolutional neural networks over
tree structures for programming language processing. In: Proceedings of the Thir-
tieth AAAI Conference on Artiﬁcial Intelligence, February 12-17, 2016, Phoenix,
Arizona, USA. pp. 1287–1293 (2016)

21. Myers, G.: Approximately matching context-free languages. Inf. Process. Lett.

54(2), 85–92 (1995)

22. Norell, U.: Dependently typed programming in agda. In: Proceedings of TLDI’09:
2009 ACM SIGPLAN International Workshop on Types in Languages Design and
Implementation, Savannah, GA, USA, January 24, 2009. pp. 1–2 (2009)

23. Polikarpova, N., Kuraj, I., Solar-Lezama, A.: Program synthesis from polymorphic
reﬁnement types. In: Proceedings of the 37th ACM SIGPLAN Conference on Pro-
gramming Language Design and Implementation, PLDI 2016, Santa Barbara, CA,
USA, June 13-17, 2016. pp. 522–538 (2016)

24. Reynolds, J.C.: Separation logic: A logic for shared mutable data structures. In:
17th IEEE Symposium on Logic in Computer Science (LICS 2002), 22-25 July
2002, Copenhagen, Denmark, Proceedings. pp. 55–74. IEEE Computer Society
(2002)

25. Rondon, P.M., Bakst, A., Kawaguchi, M., Jhala, R.: Csolve: Verifying C with liquid
types. In: Computer Aided Veriﬁcation - 24th International Conference, CAV 2012,
Berkeley, CA, USA, July 7-13, 2012 Proceedings. pp. 744–750 (2012)

26. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale

image recognition. CoRR abs/1409.1556 (2014)

27. Sørensen, M.H., Urzyczyn, P.: Lectures on the Curry-Howard Isomorphism, Volume
149 (Studies in Logic and the Foundations of Mathematics). Elsevier Science Inc.,
New York, NY, USA (2006)

28. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural

networks. CoRR abs/1409.3215 (2014)

29. Sutton, R.S., Barto, A.G.: Introduction to Reinforcement Learning. MIT Press,

Cambridge, MA, USA, 1st edn. (1998)

30. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.E., Anguelov, D., Erhan,
D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: IEEE
Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston,
MA, USA, June 7-12, 2015. pp. 1–9 (2015)

31. Tokui, S., Oono, K., Hido, S., Clayton, J.: Chainer: a next-generation open source
framework for deep learning. In: Proceedings of workshop on machine learning
systems (LearningSys) in the twenty-ninth annual conference on neural information
processing systems (NIPS) (2015)

32. Zaremba, W., Sutskever, I.: Learning to execute. CoRR abs/1410.4615 (2014)

Towards Proof Synthesis Guided by Neural Machine Translation for IPL

19

33. Zhang, K., Shasha, D.E.: Simple fast algorithms for the editing distance between

trees and related problems. SIAM J. Comput. 18(6), 1245–1262 (1989)

