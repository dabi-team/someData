Deep Learning–powered Iterative Combinatorial Auctions

Jakob Weissteiner
University of Zurich
weissteiner@iﬁ.uzh.ch

Sven Seuken
University of Zurich
seuken@iﬁ.uzh.ch

2
2
0
2

n
u
J

9
2

]
T
G
.
s
c
[

7
v
1
7
7
5
0
.
7
0
9
1
:
v
i
X
r
a

Abstract

In this paper, we study the design of deep learning-powered
iterative combinatorial auctions (ICAs). We build on prior
work where preference elicitation was done via kernelized
support vector regressions (SVRs). However, the SVR-based
approach has limitations because it requires solving a ma-
chine learning (ML)-based winner determination problem
(WDP). With expressive kernels (like gaussians), the ML-
based WDP cannot be solved for large domains. While lin-
ear or quadratic kernels have better computational scalabil-
ity, these kernels have limited expressiveness. In this work,
we address these shortcomings by using deep neural net-
works (DNNs) instead of SVRs. We ﬁrst show how the DNN-
based WDP can be reformulated into a mixed integer program
(MIP). Second, we experimentally compare the prediction
performance of DNNs against SVRs. Third, we present ex-
perimental evaluations in two medium-sized domains which
show that even ICAs based on relatively small-sized DNNs
lead to higher economic efﬁciency than ICAs based on ker-
nelized SVRs. Finally, we show that our DNN-powered ICA
also scales well to very large CA domains.

1

Introduction

Combinatorial auctions (CAs) are used to allocate multi-
ple heterogeneous items to bidders in domains where these
items may be substitutes or complements. Speciﬁcally, in a
CA, bidders are allowed to submit bids on bundles of items
rather than on individual items. CAs are widely used in prac-
tice, including for the sale of airport landing and take-off
slots (Rassenti, Smith, and Bulﬁn 1982), in industrial pro-
curement (Bichler et al. 2006), and for the sale of spectrum
licenses (Cramton 2013).

One of the main challenges in large CAs is that the bun-
dle space grows exponentially in the number of items. This
typically makes it impossible for the bidders to report their
full value function, even for medium-sized domains. Thus,
careful preference elicitation is needed in CAs.

Nisan and Segal (2006) have shown that to achieve full
efﬁciency and support general value functions, exponential
communication in the number of items is needed in the
worst case. Thus, practical auction designs cannot provide
efﬁciency guarantees in large CA domains. Instead, many
recent proposals for CAs have focused on iterative combi-

natorial auctions (ICAs) where the auctioneer interacts with
bidders over multiple rounds, eliciting a limited amount of
information, aiming to ﬁnd a highly efﬁcient allocation.

ICAs have found widespread application in practice.
For example, just between 2008 and 2014, the combina-
torial clock auction (CCA) (Ausubel, Cramton, and Mil-
grom 2006) has been used to conduct more than 15 spec-
trum auctions and has generated more than $20 Billion in
total revenue (Ausubel and Baranov 2017). Another impor-
tant application of ICAs are auctions for building offshore
wind farms (Ausubel and Cramton 2011). Given the value
of the resources allocated in these real-world ICAs, increas-
ing their efﬁciency by 1-2% points already translates into
welfare gains of millions of dollars. Therefore, improving
the efﬁciency of ICAs is an important research challenge.

1.1 Machine Learning and Mechanism Design

Researchers have proposed various ways to further increase
the efﬁciency of CAs by integrating machine learning (ML)
methods into the mechanism. This research goes back to
Blum et al. (2004) and Lahaie and Parkes (2004), who stud-
ied the relationship between computational learning theory
and preference elicitation in CAs. More recently, Brero and
Lahaie (2018) and Brero, Lahaie, and Seuken (2019) intro-
duced a Bayesian CA where they integrated ML into a CA
to achieve faster convergence. In a different strand of re-
search, D¨utting et al. (2015; 2019), Narasimhan, Agarwal,
and Parkes (2016) and Golowich, Narasimhan, and Parkes
(2018) used ML to directly learn a new mechanism (follow-
ing the automated mechanism design paradigm).

Most related to the present paper is the work by Brero, Lu-
bin, and Seuken (2017; 2018; 2019), who proposed an ML-
powered ICA. The core of their auction is an ML-powered
preference elicitation algorithm. As part of their algorithm,
they used kernelized support vector regressions (SVRs) to
learn the nonlinear value functions of bidders. Recently,
Brero, Lubin, and Seuken (2019) showed that their ML-
based ICA achieves even higher efﬁciency than the CCA.
However, because of runtime complexity issues, Brero, Lu-
bin, and Seuken (2018; 2019) focused on SVRs with linear
and quadratic kernels. This leaves room for improvement,
since bidders’ valuations can have more complex structures

1

 
 
 
 
 
 
than can be captured by linear or quadratic kernels.

1.2 Our Approach Using Deep Neural Networks
In this paper, we propose using DNNs instead of SVRs in
ML-powered ICAs. In each round of the auction, we approx-
imate bidders’ value functions by DNNs and subsequently
solve an optimization problem, a DNN-based winner deter-
mination problem (WDP) , to determine which query to ask
every bidder in the next round. Since our design involves do-
ing this in each round of the auction, a central requirement
for the practical implementation of the auction mechanism
is to efﬁciently solve these DNN-based WDPs. Therefore,
we show how to reformulate the WDP based on DNNs with
rectiﬁed linear units (ReLUs) as activation functions into a
(linear) mixed integer program (MIP) (Section 4).

Our approach is related to a recent line of research that
uses MIP formulations to study speciﬁc properties of DNNs.
For example, Cheng, N¨uhrenberg, and Ruess (2017) studied
resilience properties of DNNs. Similarly, Fischetti and Jo
(2018) used a MIP formulation for ﬁnding adversarial ex-
amples in image recognition.

To experimentally evaluate the performance of our DNN-
based approach, we use the Spectrum Auction Test Suite
(SATS) (Weiss, Lubin, and Seuken 2017) to generate syn-
thetic CA instances (Section 5). We ﬁrst compare the pre-
diction performance of DNNs against SVRs in the two
medium-sized domains GSVM and LSVM. Then we com-
pare the economic efﬁciency of our DNN-powered ICA
against the SVR-powered ICA. In GSVM (a domain per-
fectly suited for the quadratic kernel), our DNN-powered
ICA matches the efﬁciency of the SVR-powered ICA, while
in the more complex LSVM domain, our DNN-powered
ICA outperforms the SVR-powered ICA by 1.74% points.
Finally, we also demonstrate that our DNN-based approach
scales well to a very large domain, by evaluating it in the
MRVM domain (with 98 items and 10 bidders). Overall,
our results show that, perhaps surprisingly, even small-sized
neural networks can be advantageous for the design of ICAs.

2 Preliminaries
We now present our formal model and review the ML-
powered ICA by Brero, Lubin, and Seuken (2018).1

Iterative Combinatorial Auction

2.1
We consider a CA setting with n bidders and m indivisible
items. Let N := {1, . . . , n} and M := {1, . . . , m} denote
the set of bidders and items, respectively. We denote by x ∈
X := {0, 1}m a bundle of items represented as an indicator
vector, where xj = 1 iff item j ∈ M is contained in x.
Bidders’ true preferences over bundles are represented by
: {0, 1}m → R+, i ∈
their (private) value functions vi
N , i.e., vi(x) represents bidder i’s true value for bundle x.
Let v := (v1, . . . , vn) denote the vector of bidders’ value

1We compare our DNN-powered ICA against the mechanism
described in (Brero, Lubin, and Seuken 2018) because, when we
wrote this paper, (Brero, Lubin, and Seuken 2019) was not avail-
able yet. We slightly adopt the notation and use Bi instead of (cid:98)ϑi.

functions. The (possibly untruthful) reported valuations are
denoted by ˆvi and ˆv, respectively.

By a := (a1, . . . , an) ∈ X n we denote an alloca-
tion of bundles to bidders, where ai ∈ X is the bun-
dle bidder i obtains. An allocation a is feasible if each
item is allocated to at most one bidder, i.e., ∀j ∈ M :
(cid:80)
i∈N aij ≤ 1. We denote the set of feasible allocations
by F := (cid:8)a ∈ X n : (cid:80)
i∈N aij ≤ 1, ∀j ∈ M (cid:9). Payments
are denoted by p = (p1, . . . , pn) ∈ Rn, where pi is bid-
der i’s payment. Furthermore, we assume that bidders have
quasilinear utility functions ui(a) := vi(ai) − pi. The (true)
social welfare of an allocation a is deﬁned as V (a) :=
(cid:80)
i∈N vi(ai). Let a∗ ∈ arg maxa∈F V (a) be a feasible,
social-welfare maximizing, i.e., efﬁcient, allocation given
true value functions v. Then the efﬁciency of any feasible
allocation a ∈ F is measured in terms of a∗ by V (a)
V (a∗) .

An ICA mechanism deﬁnes how the bidders inter-
act with the auctioneer, how the ﬁnal allocation is de-
termined, and how payments are computed. In this pa-
per, we only consider ICAs that ask bidders to itera-
their valuations ˆvi(x) for particular bun-
tively report
dles x selected by the mechanism. A ﬁnite set of
such reported bundle-value pairs of bidder i is denoted
as Bi := (cid:8)(cid:0)x(k), ˆvi(x(k))(cid:1)(cid:9)
k∈{1,...,ni} , ni ∈ N, x(k) ∈ X ,
where ni is the total number of bundle-value pairs reported
by bidder i. We let B := (B1, . . . , Bn) denote the tuple of
reported bundle-value pairs obtained from all bidders. We
deﬁne the reported social welfare of an allocation a given B
as

(cid:98)V (a|B) :=

(cid:88)

ˆvi(ai),

(1)

i∈N : (ai,ˆvi(ai))∈Bi

where the condition (ai, ˆvi(ai)) ∈ Bi ensures that only val-
ues for reported bundles contribute to the sum. Finally, the
optimal feasible allocation a∗

B given B is deﬁned as

a∗
B ∈ arg max

a∈F

(cid:98)V (a|B).

(2)

In the ICA mechanisms we consider in this paper, the ﬁnal
outcome is only computed based on the reported values B at
termination. Speciﬁcally, the mechanism determines a feasi-
ble allocation a∗

B ∈ F and charges payments p.
As the auctioneer can generally only ask each bidder i for
a limited number of bundle-value pairs Bi, the ICA mecha-
nism needs a sophisticated preference elicitation algorithm.
This leads to the following preference elicitation problem,
where the goal is to ﬁnd an (approximately) efﬁcient alloca-
tion with a limited number of value queries. More formally:
Problem 1 (PREFERENCE ELICITATION IN ICA). Given a
cap ce on the number of value queries in an ICA, elicit from
each bidder i ∈ N a set of reported bundle-value pairs Bi
with |Bi| ≤ ce such that the resulting efﬁciency of a∗
B is
maximized, i.e.,

B ∈ arg max
B:|Bi|≤ce

V (a∗
B)
V (a∗)

.

(3)

In practice, a small domain-dependent cap on the number

of queries is chosen, e.g., ce ≤ 500.

2

2.2 SVR-powered ICA
We now present a brief review of the ML-based ICA in-
troduced by Brero, Lubin, and Seuken (2018). At the core
of their auction is an ML-based preference elicitation algo-
rithm which we reprint here as Algorithm 1.

Algorithm 1: ML-BASED ELICITATION (Brero et al. 2018)

Parameter : Machine learning algorithm A

1 B0 = initial tuple of reported bundle-value pairs at t = 0
2 do
3

t ← t + 1
Estimation step: ˜V t := A(Bt−1)
Optimization step: a(t) ∈ arg max

˜V t(a)

a∈F

for each bidder i do
/∈ Bt−1
i

if a(t)
i

then

Query value ˆvi(a(t)
i )
(cid:110)(cid:16)
a(t)
Bt
i

i = Bt−1

∪

i

(cid:17)(cid:111)

, ˆvi(a(t)
i )

else

end

Bt

i = Bt−1

i

4

5

6

7

8

9

10

11

12

end

13
14 while ∃i ∈ N : a(t)
15 Output tuple of reported bundle-value pairs Bt

/∈ Bt−1
i

i

This algorithm is a procedure to determine B, i.e., for
each bidder i a set of reported bundle-value pairs Bi. Note
that the algorithm is described in terms of a generic ML al-
gorithm A which is used in the estimation step (Line 4) to
obtain the estimated social welfare function ˜V t in iteration
t. In the optimization step (Line 5), an ML-based winner de-
termination problem is then solved to ﬁnd an allocation a(t)
that maximizes ˜V t. Finally, given the allocation a(t) from
iteration t, each bidder i is asked to report his value for the
bundle a(t)
. The algorithm stops when it reaches an alloca-
i
tion a(t) for which all bidders have already reported their
values for the corresponding bundles a(t)
i

As the ML-algorithm A, Brero, Lubin, and Seuken (2018)

.

used a sum of kernelized SVRs, i.e,
(cid:88)

A(Bt−1) :=

SVRi.

(4)

i∈N

Given a bundle x, each SVRi computes the predicted value
as SVRi(x) = wi · φ(x), where the weights wi are deter-
mined through training on the reported bundle-value pairs
Bt−1
. Kernelized SVRs are a popular non-linear regression
i
technique, where a linear model is ﬁtted on transformed
data. The transformation of bundles x is implicitly con-
ducted by setting a kernel k(x, x(cid:48)) := φ(x)T φ(x(cid:48)) in the
dual optimization problem (Smola and Sch¨olkopf 2004).

Brero, Lubin, and Seuken (2018) called their entire auc-
tion mechanism the Pseudo Vickrey-Clarke-Groves mecha-
nism (PVM). We reprint it here as Algorithm 2. PVM calls
the preference elicitation algorithm (Algorithm 1) n + 1
times: once including all bidders (called the main economy)
and n times excluding a different bidder in each run (called

3

Algorithm 2: PVM (Brero et al. 2018)
1 Run Algorithm 1 n + 1 times: B(−∅), B(−1), . . . , B(−n).
2 Determine allocations: a(−∅), a(−1), . . . , a(−n), where

a(−i) ∈ arg maxa∈F (cid:98)V (a|B(−i)).

3 Pick apvm ∈ {a(−∅), a(−1), . . . , a(−n)} with maximal (cid:98)V .
4 Charge each bidder i according to:

ppvm
i

:=

(cid:88)

j(cid:54)=i

(cid:16)
a(−i)
j

(cid:17)

−

ˆvj

(cid:88)

j(cid:54)=i

ˆvj

(cid:0)apvm

j

(cid:1) .

(5)

the marginal economies). The motivation for this design,
which is inspired by the VCG mechanism, is to obtain pay-
ments such that the auction aligns bidders’ incentives with
allocative efﬁciency. Here, B(−i) denotes the output of Al-
gorithm 1 by excluding bidder i from the set of bidders. For
each of the reported bundle-value pairs B(−i) obtained from
the n + 1 runs, PVM calculates a corresponding allocation
that maximizes the reported social welfare (Line 2). The ﬁ-
nal allocation apvm is determined as the allocation of the
n + 1 runs with the largest reported social welfare (Line 3).
Finally, VCG-style payments are calculated (Line 4).

3 Deep Neural Network-powered ICA
In this section, we present the high level design of our DNN-
powered ICA and discuss its advantages compared to the
SVR-based design by Brero, Lubin, and Seuken (2018).

Observe that the choice of the ML algorithm A affects
Algorithm 1 in two ways: ﬁrst, in the estimation step (Line
4), A determines how well we can predict bidders’ valua-
tions; second, in the optimization step (Line 5), it determines
the complexity of the ML-based WDP. Thus, our situation is
different from standard supervised learning because of the
added optimization step. In particular, when choosing A, we
must also ensure that we obtain a practically feasible ML-
based WDP. Given that we have to solve the optimization
step hundreds of times throughout an auction, in practice,
we must impose a time limit on this step. In our experiments
(Section 5), we follow Brero, Lubin, and Seuken (2018) and
impose a 1 hour time limit on this step.

To make the optimization step feasible, Brero, Lubin, and
Seuken (2018) used SVRs with quadratic kernels, for which
the ML-based WDP is a quadratic integer program (QIP)
and still practically solvable within a 1 hour time limit for
most settings. However, note that a quadratic kernel, while
more expressive than a linear kernel, can still at most model
two-way interactions between the items. To this end, Brero,
Lubin, and Seuken (2017; 2019) also evaluated more expres-
sive kernels (gaussian and exponential). Even though these
kernels had good prediction performance, the corresponding
ML-based WDPs were too complex such that they always
timed out and had a large optimization gap, thus leading to
worse economic efﬁciency than the quadratic kernel. How-
ever, using SVRs with quadratic kernels leaves room for im-
provement, since bidders’ valuations can be more complex
than can be captured by quadratic kernels.

In this work, we show how these shortcomings can be
addressed by using DNNs instead of SVRs in the estima-
tion and optimization steps of Algorithm 1. DNNs are a
concatenation of afﬁne and non-linear mappings (see Fig-
ure 1). They consist of several layers, which are themselves
composed of multiple nodes. Between each of the layers an
afﬁne transformation is applied, which is followed by a non-
linear mapping called the activation function.

One advantage of DNNs compared to (nonlinear) kernel-
ized SVRs is that, for any number of layers and nodes, we al-
ways obtain a (linear) MIP for the DNN-based WDP whose
size only grows linearly in the number of bidders and items
(as we will show in Section 4). The key insight for this is
to use rectiﬁed linear units (ReLUs) as activation functions.
Furthermore, in contrast to SVRs, DNNs do not use prede-
ﬁned feature transformations. While with SVRs, the choice
of a good kernel usually relies on prior domain knowledge,
DNNs automatically learn features in the process of training.
Following Brero, Lubin, and Seuken (2018), we decom-
pose the estimated social welfare function in Line 4 of Al-
gorithm 1, ˜V t = A(Bt−1), as follows:

˜V t =

˜vt
i ,

(cid:88)

i∈N

(6)

where ˜vt
is an estimate of bidder i’s true value func-
i
tion vi and is trained on the data set Bt−1
, i.e., the val-
ues queried up to round t − 1. In this work, for every
i ∈ N , we model ˜vt
i using a fully connected feed-forward
DNN Ni : {0, 1}m → R+. Consequently, the estimated so-
cial welfare function ˜V t is given as a sum of DNNs, i.e.,

i

˜V t :=

(cid:88)

i∈N

Ni.

(7)

Note that each bidder’s value function is modeled as a dis-
tinct DNN (with different architectures and parameters) be-
cause bidders’ preferences are usually highly idiosyncratic.2

4 MIP Formulation of the DNN-based

Winner Determination Problem

We now present the parameterization of each DNN and show
how to reformulate the DNN-based WDP into a MIP. Thus,
we focus on the optimization step (Line 5) of Algorithm 1.

4.1 Setting up the DNN-based WDP
Figure 1 shows a schematic representation of a DNN Ni.
We now deﬁne the parameters of the DNNs. To simplify the
exposition, we consider a ﬁxed iteration step t and no longer
highlight the dependency of all variables on t.

Each DNN Ni consists of Ki − 1 hidden layers for
Ki ∈ N, with the kth hidden layer containing di
k hidden
nodes, where k ∈ {1, . . . , Ki − 1}. As Ni maps bundles
x ∈ {0, 1}m to values, the dimension of the input layer di
0
is equal to the number of items m (i.e., di
0 := m) and the

2A second reason for this construction is that this prevents bid-
ders from inﬂuencing each others’ ML-models. Please see (Brero,
Lubin, and Seuken 2019) for a detailed incentive analysis of PVM.

W i,0(·) + bi,0 W i,1(·) + bi,1
ϕ

x1

x2

x3

xm

...

di
0

ϕ

ϕ

ϕ

ϕ

...

ϕ

di
1

. . .

. . .

. . .

. . .

. . .

. . .

. . .

. . .

ϕ

ϕ

ϕ

ϕ

ϕ

...

ϕ

di
2

W i,Ki−1(·) + bi,Ki−1

ϕ

ϕ

ϕ

ϕ

ϕ

...

ϕ

di
Ki−1

ϕ

di
Ki

Figure 1: Schematic representation of a DNN Ni.

Ki

k+1, k ∈ {0, . . . , Ki − 1}.

k and a bias bi,k ∈ Rdi

dimension of the output layer is equal to 1 (i.e., di
:= 1).
Hence, in total, a single DNN consists of Ki + 1 layers. Fur-
thermore, let ϕ : R → R+, ϕ(s) := max(0, s) denote the
ReLU activation function.3 The afﬁne mappings between the
kth and the k+1st layer are parameterized by a matrix W i,k ∈
Rdi

k+1×di
To estimate the parameters W i,k and bi,k from data (i.e.,
from the bundle-value pairs Bi) we use the ADAM algo-
rithm, which is a popular gradient-based optimization tech-
nique (Kingma and Ba 2015).4 This is done in the estima-
tion step in Line 4 of Algorithm 1. Thus, after the estima-
tion step, W i,k and bi,k are constants. In summary, given
estimated parameters W i := {W i,k}0≤k≤Ki−1 and bi :=
{bi,k}0≤k≤Ki−1, each DNN Ni(W i, bi) : {0, 1}m → R+
represents the following nested function:

Ni(W i, bi)(x) =
= ϕ (cid:0)W i,Ki−1ϕ (cid:0). . . ϕ(W i,0x + bi,0) . . .(cid:1) + bi,Ki−1(cid:1) .

(8)

The DNN-based WDP in the optimization step in Line 5 of
Algorithm 1 can now be formulated as follows:

max
a∈X n

(cid:40)

(cid:88)

i∈N

Ni

(cid:41)

(cid:0)W i, bi(cid:1) (ai)

(cid:88)

s.t.

aij ≤ 1,

∀j ∈ M

i∈N
aij ∈ {0, 1},

∀j ∈ M, ∀i ∈ N.

(OP1)

4.2 The MIP Formulation
In its general form, (OP1) is a nonlinear, non-convex opti-
mization problem and there do not exist practically feasible
algorithms that are guaranteed to ﬁnd a globally optimal so-
lution. Therefore, we now reformulate (OP1) into a MIP.

Consider bidder i ∈ N . For every layer k ∈ {1, . . . , Ki}
+ denote the output of the kth layer, which can

let oi,k ∈ Rdi

k

3ϕ acts on vectors componentwise, i.e., for s ∈ Rk let

ϕ(s) := (ϕ(s1), . . . , ϕ(sk)).

4For ﬁtting the DNNs in all of our experiments we use PYTHON

3.5.3, KERAS 2.2.4 and TENSORFLOW 1.13.1.

4

be recursively calculated as

oi,k = ϕ(W i,k−1oi,k−1 + bi,k−1) =

= max(0, W i,k−1oi,k−1 + bi,k−1).

(9)

max
a∈X n,zi,k,si,k,yi,k

(cid:41)

zi,Ki

(cid:40)

(cid:88)

i∈N

(OP2)

For k ∈ {1, . . . , Ki}, we introduce di

k binary decision
variables that determine which node in the corresponding
layer is active, represented as a vector yi,k ∈ {0, 1}di
k . We
also introduce 2di
k continuous variables, represented as vec-
tors zi,k, si,k ∈ Rdi
k . Each zi,k corresponds to the posi-
tive components of the output value oi,k of each layer and
each si,k is used as a slack variable representing the abso-
lute value of the negative components of oi,k.

In our ﬁnal MIP formulation, we will make use of “big-
M” constraints. For our theoretical results to hold, we need
to make the following standard assumption.

(cid:12)(W i,k−1oi,k−1 + bi,k−1)j

Assumption 1. (BIG-M CONSTRAINT) For all i ∈ N and k ∈
{1, ..., Ki} there exists a large enough constant L ∈ R+,
(cid:12)
such that (cid:12)
(cid:12) ≤ L for 1 ≤ j ≤ di
k.
In the following lemma, we show how to recursively en-
code a layer of Ni given the output value of the previous
layer as multiple linear constraints.5
Lemma 1. Let W i,k−1oi,k−1 + bi,k−1 ∈ Rdi
k be ﬁxed
for a k ∈ {1, . . . , Ki}. Furthermore, let zi,k, si,k ∈ Rdi
k ,
yi,k ∈ {0, 1}di
k . Consider the following linear constraints:

zi,k − si,k = W i,k−1oi,k−1 + bi,k−1
0 ≤ zi,k ≤ yi,k · L
0 ≤ si,k ≤ (1 − yi,k) · L.

(10)

(11)

(12)

The polytope deﬁned by (10)-(12) is not empty and every el-
ement (cid:0)zi,k, si,k, yi,k(cid:1) of this polytope satisﬁes zi,k = oi,k.

Proof. For notational convenience, let c := W i,k−1oi,k−1 +
bi,k−1. Non-emptiness follows since |cj| ≤ L, 1 ≤ j ≤ di
k,
by Assumption 1. From Constraints (11) and (12) it follows,
k, that if zi,k
j > 0 then si,k
for 1 ≤ j ≤ di
j = 0, and if
si,k
j > 0 then zi,k
j = 0. We now have to distinguish the
following three cases for each component of c:

j = −cj, zi,k
j = 0, si,k
cj < 0 =⇒ yi,k
j = 0, zi,k
j = 1, si,k
cj > 0 =⇒ yi,k
(cid:17)
(cid:16)
, yi,k
, si,k
zi,k
j
j
j

cj = 0 =⇒

j = 0 = ϕ(cj)

j = cj = ϕ(cj)

∈ {(0, 0, 0), (0, 0, 1)}

Combining all cases yields that zi,k = ϕ(cj) = oi,k.

Given Lemma 1, we can now reformulate the DNN-based
WDP as a MIP. For this, we let W i, bi denote the es-
timated parameters corresponding to Ni(W i, bi). Further-
more, let a ∈ X n, yi,k ∈ {0, 1}di
k , for
1 ≤ k ≤ Ki and L be a constant satisfying Assumption 1.

k and zi,k, si,k ∈ Rdi

s.t.
zi,0 = ai
zi,k − si,k = W i,k−1zi,k−1 + bi,k−1
0 ≤ zi,k ≤ yi,k · L
0 ≤ si,k ≤ (1 − yi,k) · L
yi,k ∈ {0, 1}di
aij ∈ {0, 1},
(cid:88)

∀j ∈ M, ∀i ∈ N

k

aij ≤ 1,

∀j ∈ M






∀i ∈ N
∀k ∈ {1, . . . , Ki}

i∈N

We are now ready to state our main theorem.

Theorem 1. (MIP FORMULATION) The DNN-based WDP
as deﬁned in (OP1) is equivalent to the MIP deﬁned in (OP2).

Proof. Consider (OP1). For each bidder i ∈ N , we ﬁrst set
zi,0 equal to the input bundle ai. Then we proceed by using
Lemma 1 for k = 1, i.e., we reformulate the output of the 1st
layer as the linear constraints (10), (11) and (12). We iterate
this procedure until we have reformulated the ﬁnal layer, i.e,
k = Ki. Doing so for each bidder i ∈ N and adding the
feasibility constraints yields (OP2).

Using the MIP formulation (OP2), we can solve the
DNN-based WDP using standard optimization packages like
CPLEX.6

We now provide a simple worked example for how to re-

formulate (OP1) into (OP2) which illustrates Theorem 1.
Example 1. Consider a setting with one bidder (n = 1),
m items (d1
0 = m) and one hidden layer (K1 = 2). Given
W 1,0 ∈ Rd1
1×m, W 1,1 ∈ R1×d1
1 , and b1,1 ∈ R,
(OP1) can be written as

1 ,b1,0 ∈ Rd1

∀j ∈ M,

(cid:8)max (cid:0)0, W 1,1 max (cid:0)0, W 1,0a1 + b1,0(cid:1) + b1,1(cid:1)(cid:9)

max
a1∈X 1
s.t. a1j ∈ {0, 1},
where the constraint (cid:80)
i∈N aij ≤ 1, ∀j ∈ M is redundant
in this case, since we only consider one bidder. First, we re-
place the inner maximum using y1,1 ∈ {0, 1}d1
1, z1,1, s1,1 ∈
Rd1

1 and arrive at the equivalent optimization problem
(cid:8)max (cid:0)0, W 1,1z1,1 + b1,1(cid:1)(cid:9)

s.t.

max
a1∈X 1
z1,1, s1,1, y1,1
z1,1 − s1,1 = W 1,0a1 + b1,0
0 ≤ z1,1 ≤ y1,1 · L
0 ≤ s1,1 ≤ (1 − y1,1) · L
∀j ∈ M.
a1j ∈ {0, 1},

5In the following, all constraints containing vectors are deﬁned

6For solving MIPs of the form (OP2) in our experiments we use

componentwise.

CPLEX 12.8.0.0 with the python library DOCPLEX 2.4.61.

5

Applying Lemma 1 again by using y1,2 ∈ {0, 1} and
z1,2, s1,2 ∈ R yields the ﬁnal MIP formulation

s.t.

(cid:8)z1,2(cid:9)

max
a1∈X 1, z1,k
y1,k, s1,k, k ∈ {1,2}
z1,1 − s1,1 = W 1,0a1 + b1,0
0 ≤ z1,1 ≤ y1,1 · L
0 ≤ s1,1 ≤ (1 − y1,1) · L
z1,2 − s1,2 = W 1,1z1,1 + b1,1
0 ≤ z1,2 ≤ y1,2 · L
0 ≤ s1,2 ≤ (1 − y1,2) · L
∀j ∈ M.
a1j ∈ {0, 1},

Remark 1. The number of decision variables in the MIP
deﬁned in (OP2) is given by









(cid:88)

i∈N
(cid:124)(cid:123)(cid:122)(cid:125)
#bidders

+

m
(cid:124)(cid:123)(cid:122)(cid:125)
#items

3
(cid:124)(cid:123)(cid:122)(cid:125)
yi,k, si,k,zi,k

·









#hidden layers
(cid:122) (cid:125)(cid:124) (cid:123)
Ki − 1
(cid:88)

k=1





output
(cid:122)(cid:125)(cid:124)(cid:123)
1













di
k
(cid:124)(cid:123)(cid:122)(cid:125)
#nodes per layer

+

5 Experimental Evaluation
In this section, we evaluate the performance of our deep
learning-powered ICA and compare it against the SVR-
based approach using quadratic kernels by Brero, Lubin, and
Seuken (2018). We release our code under an open-source li-
cense at: https://github.com/marketdesignresearch/DL-ICA.

5.1 Experiment setup
Spectrum auctions are one of the most prominent applica-
tions of CAs, which is why we choose them for our experi-
ments. Speciﬁcally, we use the spectrum auction test suite
(SATS) version 0.6.4 (Weiss, Lubin, and Seuken 2017).7
SATS enables us to generate 1000s of CA instances in differ-
ent domains. Furthermore, we have access to each bidder’s
true value vi(x) for all 2m possible bundles x ∈ X as well
as the efﬁcient allocation a∗ ∈ F, which we can use to mea-
sure the efﬁciency of any other allocation a by V (a)/V (a∗).
We evaluate our approach in the following three domains:

The Global Synergy Value Model (GSVM) (Goeree and
Holt 2010) consists of 6 regional bidders, 1 national bidder,
and 18 items. In GSVM the value of a package increases by
a certain percentage with every additional item of interest.
Thus, the value of a bundle only depends on the total number
of items contained in a bundle which makes it one of the
simplest models in SATS. In fact, bidders’ valuations can
be exactly learned by SVRs with quadratic kernels (Brero,
Lubin, and Seuken (2019)) which implies that the valuations
exhibit at most two-way interactions between items.

The Local Synergy Value Model (LSVM) (Scheffel,
Ziegler, and Bichler 2012) consists of 5 regional bidders,
1 national bidder and 18 items. The items are arranged on a
rectangle of size 3×6. The national bidder is interested in all

7Experiments were conducted on machines with Intel Xeon E5-

2650 v4 2.20GHz processors with 20 cores.

6

items, while the regional bidders are only interested in cer-
tain subsets of items. Complementarities arise from spatial
proximity of items and are modeled via a logistic function,
which makes it more complex than GSVM.

The Multi-Region Value Model (MRVM) (Weiss, Lubin,
and Seuken 2017) consists of 98 items and 10 bidders. It
models large US and Canadian spectrum auctions and cap-
tures both geography (different regions) as well as frequency
dimensions (different bands). A bidder is categorized as na-
tional, regional or local, depending on the magnitude of the
synergies between different regions.

In Sections 5.2 and 5.3, we ﬁrst evaluate our approach
in detail using the two medium-sized domains GSVM and
LSVM. Then, in Section 5.4, we use MRVM to evaluate how
well our approach scales to very large domains.

5.2 Prediction Performance
We ﬁrst compare the prediction performance of DNNs to
SVRs. Using SATS, we generate a data set of bundle-value
pairs {(x(k), vi(x(k)))} for all bidders i ∈ N . For each auc-
tion domain, we draw 100 auction instances uniformly at
random. For each such instance, we sample, for each bidder
type, a training set T of equal size and a disjoint test set V
consisting of all remaining bundles, i.e., |V | := 2|M | − |T |.
For each bidder type, we train the ML algorithm on T and
test it on V . We report the mean absolute error (MAE) for
both bidder types averaged over the 100 instances.8

We denote by [d1, d2, d3] a 3-hidden-layer DNN with
d1, d2 and d3 hidden nodes, respectively. For both, SVRs
and DNNs, we performed a hyperparameter optimization
for each bidder type. For the DNNs, we optimized the ar-
chitecture9, the L2-regularization parameter for the afﬁne
mappings, the dropout rate per layer, and the learning rate
of ADAM. For SVRs with a quadratic kernel k(x, y) :=
xT y + γ(xT y)2, we optimized γ (i.e., the inﬂuence of the
quadratic term), the regularization parameter C, and the loss
function parameter (cid:15). In what follows, we present the winner
models resulting from this hyperparameter optimization.

In Table 1, we present prediction performance results for
the GSVM domain. Consider the last column of the table,
which shows the MAE on the test set. We observe the very
good prediction performance of the SVRs and in particu-
lar that the test error converges to 0 when increasing |T |.
This is due to the fact that in GSVM, bidders’ value func-
tions can be perfectly captured by quadratic kernels. In this
sense, GSVM represents a “worst case” auction domain w.r.t
our comparison of DNNs against quadratically-kernelized
SVRs. Looking at the performance of the DNNs, we observe
that the test error also decreases with |T |, but, not surpris-
ingly, is always larger than for the SVRs with quadratic ker-
nels. Furthermore, we observe that the optimal architectures
are always a 1-hidden layer network.

In Table 2, we present the results for the more complex
LSVM domain. We observe that for |T | = 50, the DNNs and

8For training the DNNs, we use the MAE as the loss function.
9We considered the following architectures: for the national
bidders: [10], [100], [10,10], . . ., [100,100,100,100], and for the
regional bidders: [32], [100], [32,32], . . ., [100,100,100,100].

ML Algorithm |T |

DNNs

SVRs

50

100

200

50

100

200

Bidder
Type

National
Regional

National
Regional

National
Regional

National
Regional

National
Regional

National
Regional

DNN

Architecture MAEtrain MAEtest
5.25 (0.11)
6.20 (0.19)

[100]
[100]

1.99
2.06

[100]
[100]

[100]
[100]

Kernel

quadratic
quadratic

quadratic
quadratic

quadratic
quadratic

2.10
2.71

1.61
2.11

0.03
0.03

0.03
0.03

0.03
0.03

3.66 (0.07)
4.64 (0.13)

2.22 (0.05)
2.89 (0.09)

4.38 (0.11)
4.98 (0.20)

1.71 (0.04)
2.07 (0.07)

0.12 (0.00)
0.13 (0.00)

Table 1: Prediction performance in GSVM. All results are
averaged over 100 auction instances. For MAEtest, standard
errors are shown in parentheses.

ML Algorithm |T |

DNNs

SVRs

50

100

200

50

100

200

Bidder
Type

National
Regional

National
Regional

National
Regional

National
Regional

National
Regional

National
Regional

DNN
Architecture

[10]
[100]

[10, 10, 10]
[100]

[10, 10]
[100, 100, 100]

Kernel

quadratic
quadratic

quadratic
quadratic

quadratic
quadratic

MAEtrain
24.68
4.22

9.01
5.01

10.52
3.64

18.51
3.11

20.03
3.21

20.03
8.23

MAEtest
29.90 (0.23)
16.58 (0.39)

25.62 (0.36)
13.74 (0.26)

20.58 (0.21)
11.27 (0.23)

32.61 (0.59)
15.30 (0.34)

27.86 (0.28)
14.21 (0.28)

25.44 (0.16)
12.67 (0.26)

Table 2: Prediction performance in LSVM. All results are
averaged over 100 auction instances. For MAEtest, standard
errors are shown in parentheses.

SVRs with quadratic kernels have similar test error. But for
|T | = 100 and |T | = 200, the DNNs signiﬁcantly outper-
form the SVRs with quadratic kernels. Speciﬁcally, DNNs
better capture the national bidder in LSVM, which is impor-
tant, since this bidder is interested in all items and usually
gets a large portion of the items in the ﬁnal allocation, which
matters a lot for efﬁciency. In contrast to GSVM, we observe
that for |T | ≥ 100, multi-hidden-layer networks were found
to be best. This suggests that DNNs may indeed be advanta-
geous for capturing more complex preference structures.10

5.3 Efﬁciency Results
Finally, we compare the economic efﬁciency of our DNN-
powered ICA against the SVR-powered ICA. When con-
ducting the efﬁciency experiments, we follow Brero, Lubin,
and Seuken (2018) and assume that bidders answer all value
queries truthfully (i.e., ˆvi = vi). Furthermore, we also use

10We also evaluated the prediction performance of other kernels
(linear, gaussian and exponential) and observed that DNNs were as
good or better for almost all combinations of bidder types and |T |.

7

DNN Architectures11

c0 Efﬁciency % Revenue %12
R:[16, 16] | N:[10, 10]
40
R:[16, 16] | N:[10, 10]
30
R:[16, 16] | N:[10, 10, 10] 40
R:[16, 16] | N:[10, 10, 10] 30
R:[32, 32] | N:[10, 10]
40
R:[32,32] | N:[10,10]
30
R:[32, 32] | N:[10, 10, 10] 40
R:[32, 32] | N:[10, 10, 10] 30
R:[100] | N:[100]
30

69.26%
68.29%
68.91%
68.59%
71.14%
68.47%
71.63%
68.88%
66.73%

98.53%
98.41%
98.51%
98.32%
98.75%
98.94%
98.69%
98.92%
98.27%

Table 3: Efﬁciency results for 9 conﬁgurations of a DNN-
powered ICA on a training set of 100 GSVM auction in-
stances. The selected winner model is marked in bold. All
results are averaged over the 100 auction instances.

Auction

Max

%

%

t-test on

Mechanism #Queries #Queries Efﬁciency Revenue Efﬁciency13

VCG

SVR-ICA

DNN-ICA

218

41.9

53

218

42.8

78

100.00 (0.00)

80.4

-

98.85 (0.13)

98.63 (0.18)

77.80

67.81

0.337

Table 4: A comparison of the DNN-powered ICA against the
SVR-powered ICA and VCG (as reported in Brero, Lubin,
and Seuken (2018)) on a test set of 100 GSVM instances. All
results are averaged over the 100 instances. For efﬁciency,
standard errors are shown in parentheses.

their experiment setup and deﬁne a cap ce on the total num-
ber of value queries in Algorithm 1 and set ce := 50. The
initial set of reported bundle-value pairs B0
i per bidder i is
drawn uniformly at random. We denote the number of initial
reports by c0 := |B0
i |, ∀i ∈ N , resulting in a maximum of
c0 + n · (ce − c0) queries per bidder.

GSVM.
In Table 3, we ﬁrst present the results from com-
paring nine different network architectures on a training
set of 100 GSVM instances. As we can see, the win-
ning model is among the largest multi-layer networks we
tested. It is noteworthy that the one-hidden-layer network
(R:[100]|N:[100]), which performed best in terms of predic-
tion performance, did not perform best in terms of efﬁciency.
In Table 4, we compare the performance of the win-
ner model from Table 3 (see Appendix A for conﬁgura-
tion details) against the SVR-based approach on a test set
of 100 GSVM instances. Even though GSVM can be per-
fectly captured by quadratic kernels, our DNN-based ap-
proach achieves a similar result w.r.t to efﬁciency, where the
difference is not statistically signiﬁcant (p = 0.337).

11We denote by R and N the architectures used for the regional-

and national bidders, respectively.
12Revenue is calculated as ((cid:80)
13We performed a two-sided unpaired Welch Two Sample t-test
with H0 : µ1 = µ2 against HA : µ1 (cid:54)= µ2. We thank Brero,
Lubin, and Seuken (2018) for providing us with the detailed results
of their experiments to enable all t-tests reported in this paper.

i∈N ppvm

)/V (a∗).

i

DNN Architectures

R:[16, 16] | N:[10, 10]
R:[16, 16] | N:[10, 10]
R:[16, 16] | N:[10, 10, 10]
R:[16, 16] | N:[10, 10, 10]
R:[32, 32] | N:[10, 10]
R:[32, 32] | N:[10, 10]
R:[32,32] | N:[10,10,10]
R:[32, 32] | N:[10, 10, 10]
R:[100] | N:[10]

c0 Efﬁciency % Revenue %
40
30
40
30
40
30
40
30
40

60.51
56.85
61.15
59.31
62.01
59.07
61.95
59.56
58.71

97.40
96.87
97.45
97.12
97.40
96.83
97.74
97.12
96.78

Table 5: Efﬁciency results for 9 conﬁgurations of a DNN-
powered ICA on a training set of 100 LSVM auction in-
stances. The selected winner model is marked in bold. All
results are averaged over the 100 auction instances.

Auction

t-test on
Mechanism #Queries #Queries Efﬁciency Revenue Efﬁciency

Max

%

%

VCG

SVR-ICA

DNN-ICA

218

48.2

65

218

52.8

77

100.00 (0.00)

83.4

-

96.03 (0.33)

97.74 (0.24)

65.60

62.45

0.000038

Table 6: A comparison of the DNN-powered ICA against the
SVR-powered ICA and VCG (as reported in Brero, Lubin,
and Seuken (2018)) on a test set of 100 LSVM auction in-
stances. All results are averaged over the 100 instances. For
efﬁciency, standard errors are shown in parentheses.

LSVM. We now turn to the more complex LSVM domain.
We ﬁrst select a winner model based on a training set of 100
LSVM instances (Table 5). As in GSVM, the best model
is among the largest architectures and the best model w.r.t
prediction performance does not yield the highest efﬁciency.
In Table 6, we compare the performance of the selected
winner model from Table 5 (see Appendix A for conﬁgura-
tion details) against the SVR-based approach on a test set
of 100 new auction instances. Here, we see that our DNN-
powered ICA substantially outperforms the SVR-powered
ICA by 1.74% points, and this effect is highly statistically
signiﬁcant (p = 0.000038). This demonstrates the advan-
tage of DNNs over SVRs with quadratic kernels in complex
domains like LSVM.

In Figure 2, we present a histogram of the efﬁciency ob-
tained by the selected winner model on the test set. We
see that for 29 auction instances, our approach (impres-
sively) obtains an economic efﬁciency of 100%. However,
for two instances, the efﬁciency is less than 90%. Thus, it
is a promising avenue for future work to investigate these
outliers to further increase the average efﬁciency.

Remark 2. In Tables 4 and 6, we see that our DNN-based
approach achieves lower revenue than the SVR-based ap-
proach. This may be explained as follows. A bidder’s pay-
ment in PVM, depends on the difference between the social
welfare in the marginal and the main economy. However,
PVM has one oddity: a bidder’s payment may be negative.
This happens more frequently with DNNs than with SVRs:
consider an auction where bidder i is not allocated in the

Figure 2: Histogram of efﬁciency results in LSVM of the
selected DNN winner model on the test set.

main economy. Then, ideally, the allocation (and thus the
welfare) should be exactly the same in the marginal econ-
omy where bidder i is excluded, resulting in a zero pay-
ment. When using SVRs, this is guaranteed if the same set of
bundle-value pairs is used in the main and marginal econ-
omy, because SVRs use a deterministic algorithm for estima-
tion. In contrast, DNNs use a non-deterministic algorithm,
sometimes resulting in different allocations in the main and
marginal economies. However, this is more a limitation of
PVM itself. In practice, one should lower bound the pay-
ments as also suggested by Brero, Lubin, and Seuken (2019).
Lower-bounding all payments by zero increases the revenue
in GSVM by 7.9% points and in LSVM by 8.3% points.

5.4 Scaling to Larger Domains
We now present results for the MRVM domain (with 98
items and 10 bidders) to show that our DNN-powered ICA
also scales well to larger domains (we present detailed run-
time results in Section 5.5). We use the experiment setup of
Brero, Lubin, and Seuken (2018) and set ce := 100.

In Table 7, we present the results for different DNN archi-
tectures and different values of c0, evaluated on a training set
of MRVM instances. First, we observe that the efﬁciency in-
creases as we decrease c0. This can be explained by the fact
that a smaller c0 tends to lead to more iterations of the pref-
erence elicitation algorithm, resulting in a larger number of
elicited bundle-value pairs. In terms of which DNN architec-
tures performed better or worse, no clear pattern emerged.

In Table 8, we compare the performance of the selected
winner model from Table 7 (see Appendix A for conﬁgura-

DNN Architectures

L:[10, 10] | R:[32, 32] | N:[32, 32]
L:[10, 10] | R:[32, 32] | N:[32, 32]
L:[16, 16] | R:[16, 16] | N:[16, 16]
L:[10, 10] | R:[32, 32] | N:[32, 32]
L:[16, 16] | R:[16, 16] | N:[16, 16]
L:[10, 10] | R:[32, 32] | N:[32, 32]
L:[16,16]| R:[16,16] | N:[16,16]
L:[10, 10] | R:[32, 32] | N:[32, 32]
L:[10, 10] | R:[16, 16, 16] | N:[16, 16, 16]

c0 Efﬁciency % Revenue %
70
50
30
30
20
20
10
10
10

31.02
33.51
31.39
31.88
30.31
34.23
31.97
34.78
31.12

93.54
94.07
94.46
94.73
94.88
94.42
95.00
94.54
94.74

Table 7: Efﬁciency results for 9 conﬁgurations of a DNN-
powered ICA on a training set of 19 MRVM auction in-
stances. The selected winner model is marked in bold. All
results are averaged over the 19 auction instances.

8

meanstdmin25%50%75%max97.742.3586.5196.6798.3399.48100.086889092949698100Efficiency in %051015202530# of Instances11242510712131429Auction

t-test on
Mechanism #Queries #Queries Efﬁciency Revenue Efﬁciency

Max

%

%

VCG

SVR-ICA

DNN-ICA

298

265

334

298

630

908

100.00 (0.00)

44.3

-

94.58 (0.14)

95.04 (0.14)

35.20

30.59

0.0268

Table 8: A comparison of the DNN-powered ICA against the
SVR-powered ICA and VCG (as reported in Brero, Lubin,
and Seuken (2018)) on a test set of 50 MRVM auction in-
stances. All results are averaged over the 50 instances. For
efﬁciency, standard errors are shown in parentheses.

tion details) against the SVR-based approach on a test set
of 50 MRVM instances. We see that our DNN-powered ICA
outperforms the SVR-powered ICA by 0.46% points. While
this is a relatively modest increase in efﬁciency, this effect is
statistically signiﬁcant (p = 0.0268). We also observe that
our DNN-based approach (while obeying all caps) asks a
larger number of queries than the SVR-based approach. It is
unclear how much of the efﬁciency increase is driven by the
DNN or by the larger number of queries. Future work should
compare the two approaches by holding the total number of
queries constant.

5.5 Runtime Analysis
In Table 9, we present runtime results for our DNN-powered
ICA for the winner models from Tables 4, 6 and 8. Speciﬁ-
cally, we show average runtime results of the MIP (OP2), of
an iteration of Algorithm 1, and of a whole auction (PVM).
We observe that the average runtime of a whole auction takes
approximately 1 hour in GSVM and LSVM and 8 hours in
the larger MRVM domain. The increase in total runtime in
MRVM can be explained by the fact that we use a smaller
number of initial queries (c0 := 10) and a larger total query
cap (ce := 100) compared to LSVM and GSVM. This re-
sults in a larger number of iterations of Algorithm 1. Addi-
tionally, MRVM consists of 10 bidders resulting in 11 calls
of Algorithm 1 in contrast to 7 calls in LSVM and 8 in
GSVM. Even though in MRVM the average MIP runtime is
smaller, the larger number of iterations and bidders lead to
this increase in total runtime. Overall, these results show that
our DNN-based approach is practically feasible and scales
well to the larger MRVM domain. Brero, Lubin, and Seuken
(2018) do not provide runtime information such that we can-
not provide a runtime comparison with SVRs.14

In Figure 3, we present additional MIP runtime results for
selected DNN architectures in LSVM (results in GSVM and
MRVM are qualitatively similar). We observe two effects:
First, increasing the number of nodes per layer slightly in-
creases the average runtime. Second, adding an additional
layer (for the national bidder) signiﬁcantly increases the av-

14In conversations with the authors, they told us that for gaus-
sian and exponential kernels, their MIPs always timed out (1h
cap) in GSVM, LSVM and MRVM. The average MIP runtime for
the quadratic kernel was a few seconds in GSVM and LSVM. In
MRVM, the quadratic kernel also regularly timed out resulting in
an average MIP runtime of 30 min and of 36 h for a whole auction.

Domain ∅ MIP Runtime ∅ Iteration Runtime ∅ Auction Runtime
GSVM
LSVM
MRVM

30.51 sec
51.69 sec
26.75 sec

15.90 sec
39.75 sec
3.67 sec

44 min
65 min
457 min

Table 9: Average runtime results of the selected DNN winner
models in different domains. All values are averaged over
100 (GSVM and LSVM) and 50 (MRVM) auction instances.

Figure 3: MIP runtimes deﬁned in (OP2) based on 50 dif-
ferent LSVM instances. Results are shown for a selection of
various DNN architectures and for c0 := 40, ce := 50.

erage runtime. Not surprisingly, the largest DNN architec-
tures lead to the highest runtime.

The runtime of our MIPs heavily depends on the size of
the “big-M” variable L. In practice, L should be chosen as
small as possible to obtain a MIP formulation that is as tight
as possible. We initialized L := 3000 and tightened this
bound further by using interval arithmetic (see, e.g., Tjeng,
Xiao, and Tedrake (2019)). Recently, Singh et al. (2018) pro-
posed a novel technique for tightening such MIP formula-
tions. Evaluating this in more detail is subject to future work.

6 Conclusion
In this paper, we have designed a deep learning-powered
ICA. We have compared our approach against prior work
using SVRs with quadratic kernels. Our experimental results
have shown that our DNN-based approach leads to signiﬁ-
cantly higher economic efﬁciency in complex auction do-
mains and scales well to large domains.

On a technical level, our main contribution was to refor-
mulate the DNN-based WDP into a MIP. The main insight
to achieve this was to use ReLU activation functions, which
can be re-written as multiple linear constraints. From an ex-
perimental point of view, we were pleasantly surprised to
see that even DNNs with a small number of layers and nodes
and with a small number of training samples (i.e., bids) were
able to achieve high prediction performance and ultimately
high economic efﬁciency in the overall auction mechanism.
Future work should investigate the trade-off between
larger DNN architectures and the resulting MIP runtime, to
further increase efﬁciency.

Acknowledgments
We thank Gianluca Brero, Nils Olberg, and Stefania Ionescu
for insightful discussions and the anonymous reviewers for

9

R:[16,16]N:[10,10]R:[32,32]N:[10,10]R:[16,16]N:[10,10,10]R:[32,32]N:[10,10,10]100101102103MIP Runtime (in sec.)2849355331933840#MIPs:Goeree, J. K., and Holt, C. A. 2010. Hierarchical package
bidding: A paper & pencil combinatorial auction. Games
and Economic Behavior 70(1):146–169.
Golowich, N.; Narasimhan, H.; and Parkes, D. C. 2018.
Deep learning for multi-facility location mechanism design.
In Proceedings of the 27th International Joint Conference
on Artiﬁcial Intelligence and the 23rd European Conference
on Artiﬁcial Intelligence.
Kingma, D., and Ba, J. 2015. Adam: A method for stochas-
In Proceedings of the 3rd International
tic optimization.
Conference on Learning Representations.
Lahaie, S. M., and Parkes, D. C. 2004. Applying learning
algorithms to preference elicitation. In Proceedings of the
5th ACM Conference on Electronic Commerce.
Narasimhan, H.; Agarwal, S. B.; and Parkes, D. C. 2016.
Automated mechanism design without money via machine
learning. In Proceedings of the 25th International Joint Con-
ference on Artiﬁcial Intelligence.
Nisan, N., and Segal, I. 2006. The communication require-
ments of efﬁcient allocations and supporting prices. Journal
of Economic Theory 129(1):192–224.
Rassenti, S. J.; Smith, V. L.; and Bulﬁn, R. L. 1982. A com-
binatorial auction mechanism for airport time slot allocation.
The Bell Journal of Economics 402–417.
Scheffel, T.; Ziegler, G.; and Bichler, M. 2012. On the im-
pact of package selection in combinatorial auctions: an ex-
perimental study in the context of spectrum auction design.
Experimental Economics 15(4):667–692.
Singh, G.; Gehr, T.; Mirman, M.; P¨uschel, M.; and Vechev,
M. 2018. Fast and effective robustness certiﬁcation.
In
Proceedings of the 32nd Conference on Neural Information
Processing Systems.
Smola, A. J., and Sch¨olkopf, B. 2004. A tutorial on support
vector regression. Statistics and computing 14(3):199–222.
Tjeng, V.; Xiao, K. Y.; and Tedrake, R. 2019. Evaluating
robustness of neural networks with mixed integer program-
ming. In Proceedings of the 7th International Conference
on Learning Representations.
Weiss, M.; Lubin, B.; and Seuken, S. 2017. Sats: A universal
spectrum auction test suite. In Proceedings of the 16th Con-
ference on Autonomous Agents and Multi-Agent Systems.

helpful comments. This paper is part of a project that has re-
ceived funding from the European Research Council (ERC)
under the European Union’s Horizon 2020 research and in-
novation programme (Grant agreement No. 805542).

References
2017. A practical
Ausubel, L. M., and Baranov, O.
guide to the combinatorial clock auction. Economic Jour-
nal 127(605):F334–F350.
Ausubel, L., and Cramton, P. 2011. Auction design for
wind rights. Report to Bureau of Ocean Energy Manage-
ment, Regulation and Enforcement.
Ausubel, L. M.; Cramton, P.; and Milgrom, P. 2006. Com-
binatorial Auctions. MIT Press. chapter The clock-proxy
auction: A practical combinatorial auction design, 115–138.
Bichler, M.; Davenport, A.; Hohner, G.; and Kalagnanam, J.
2006. Combinatorial Auctions. MIT Press. chapter Indus-
trial procurement auctions, 593–612.
Blum, A.; Jackson, J.; Sandholm, T.; and Zinkevich, M.
2004. Preference elicitation and query learning. Journal
of Machine Learning Research 5:649–667.
Brero, G., and Lahaie, S. 2018. A bayesian clearing mecha-
nism for combinatorial auctions. In Proceedings of the 32nd
AAAI Conference on Artiﬁcial Intelligence.
Brero, G.; Lahaie, S.; and Seuken, S. 2019. Fast iterative
combinatorial auctions via bayesian learning. In Proceed-
ings of the 33rd AAAI Conference of Artiﬁcial Intelligence.
Brero, G.; Lubin, B.; and Seuken, S. 2017. Probably approx-
imately efﬁcient combinatorial auctions via machine learn-
ing. In Proceedings of the 31st AAAI Conference on Artiﬁ-
cial Intelligence.
Brero, G.; Lubin, B.; and Seuken, S. 2018. Combinatorial
auctions via machine learning-based preference elicitation.
In Proceedings of the 27th International Joint Conference
on Artiﬁcial Intelligence and the 23rd European Conference
on Artiﬁcial Intelligence.
2019. Machine
Brero, G.; Lubin, B.; and Seuken, S.
learning-powered iterative combinatorial auctions. arXiv
preprint arXiv:1911.08042.
Cheng, C.-H.; N¨uhrenberg, G.; and Ruess, H. 2017. Au-
tomated Technology for Veriﬁcation and Analysis. Lecture
Notes in Computer Science, volume 10482. Springer, Cham.
chapter Maximum resilience of artiﬁcial neural networks.
Cramton, P. 2013. Spectrum auction design. Review of
Industrial Organization 42(2):161–190.
D¨utting, P.; Fischer, F.; Jirapinyo, P.; Lai, J. K.; Lubin,
B.; and Parkes, D. C.
Payment rules through
2015.
discriminant-based classiﬁers. ACM Transactions on Eco-
nomics and Computation 3(1):5:1–5:41.
D¨utting, P.; Feng, Z.; Narasimhan, H.; Parkes, D. C.; and
Ravindranath, S. S. 2019. Optimal auctions through deep
learning. In Proceedings of the 36th International Confer-
ence on Machine Learning.
Fischetti, M., and Jo, J. 2018. Deep neural networks and
mixed integer linear optimization. Constraints 23(3):296–
309.

10

SATS

DNN

MIP

PVM

Domain Bidder

Epochs Batch Size L1&L2 Regularization Learning Rate Architecture Dropout Dropout Rate MinMaxScaler15 Bounds Tightening

L

Time Limit (sec) Relative Gap c0

ce
0.0001 30 20
0.0001 30 20

0.0001 40 10
0.0001 40 10

0.0001 10 90
0.0001 10 90
0.0001 10 90

GSVM Regional
National

LSVM Regional
National

MRVM Local

Regional
National

512
512

512
512

300
300
300

32
32

32
32

32
32
32

0.00001
0.00001

0.00001
0.00001

0.00001
0.00001
0.00001

0.01
0.01

0.01
0.01

0.01
0.01
0.01

[32,32]
[10,10]

[32,32]
[10,10,10]

[16,16]
[16,16]
[16,16]

True
True

True
True

True
True
True

0.05
0.05

0.05
0.05

0.05
0.05
0.05

False
False

False
False

[0, 500]
[0, 500]
[0, 500]

IA 3000
IA 3000

IA 3000
IA 3000

IA 3000
IA 3000
IA 3000

3600
3600

3600
3600

3600
3600
3600

Table 10: Detailed conﬁgurations of all DNN winner models for all SATS domains.

Appendix
A Detailed Winner Conﬁgurations
In Table 10, we provide the detailed conﬁgurations (i.e.,
DNN, MIP, and PVM parameters) of the DNN winner mod-
els (i.e., DNN-ICA) from Table 4, Table 6 and Table 8. Other
parameters not listed in Table 10 were set to their default val-
ues.

15We use SCIKIT LEARN’S MinMaxScaler to simultaneously
scale bidders’ value reports (i.e., vi(x(k))) in the generated (ini-
tial) training sets ∪n

i to an interval [0, u] with u > 0.

i=1B0

11

