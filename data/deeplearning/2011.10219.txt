0
2
0
2

v
o
N
0
2

]

G
L
.
s
c
[

1
v
9
1
2
0
1
.
1
1
0
2
:
v
i
X
r
a

Certiﬁed Monotonic Neural Networks

Xingchao Liu
Department of Computer Science
University of Texas at Austin
Austin, TX 78712
xcliu@utexas.edu

Xing Han
Department of Electrical and Computer Engineering
University of Texas at Austin
Austin, TX 78712
aaronhan223@utexas.edu

Na Zhang
Tsinghua University
zhangna@pbcsf.tsinghua.edu.cn

Qiang Liu
Department of Computer Science
University of Texas at Austin
Austin, TX 78712
lqiang@cs.utexas.edu

Abstract

Learning monotonic models with respect to a subset of the inputs is a desirable
feature to effectively address the fairness, interpretability, and generalization issues
in practice. Existing methods for learning monotonic neural networks either require
speciﬁcally designed model structures to ensure monotonicity, which can be too
restrictive/complicated, or enforce monotonicity by adjusting the learning process,
which cannot provably guarantee the learned model is monotonic on selected fea-
tures. In this work, we propose to certify the monotonicity of the general piece-wise
linear neural networks by solving a mixed integer linear programming problem.
This provides a new general approach for learning monotonic neural networks with
arbitrary model structures. Our method allows us to train neural networks with
heuristic monotonicity regularizations, and we can gradually increase the regu-
larization magnitude until the learned network is certiﬁed monotonic. Compared
to prior works, our approach does not require human-designed constraints on the
weight space and also yields more accurate approximation. Empirical studies on
various datasets demonstrate the efﬁciency of our approach over the state-of-the-art
methods, such as Deep Lattice Networks [34].

1

Introduction

Monotonicity with respect to certain inputs is a desirable property of the machine learning (ML)
predictions in many practical applications [e.g., 6, 9, 10, 11, 17, 28]. For real-world scenarios
with fairness or security concerns, model predictions that violate monotonicity could be considered
unacceptable. For example, when using ML to predict admission decisions, it may seem unfair to
select student X over student Y, if Y has a higher score than X, while all other aspects of the two
are identical. A similar problem can arise when applying ML in many other areas, such as loan
application, criminal judgment, and recruitment. In addition to the fairness and security concerns,
incorporating the monotonic property into the ML models can also help improve their interpretability,
especially for the deep neural networks [22]. Last but not least, enforcing monotonicity could increase
the generalization ability of the model and hence the accuracy of the predictions [10, 34], if the
enforced monotonicity pattern is consistent with the underlying truth.

While incorporating monotonicity constraints has been widely studied for the traditional machine
learning and statistical models for decades [e.g., 2, 5, 8, 9, 21, 27], the current challenge is how to
incorporate monotonicity into complex neural networks effectively and ﬂexibly. Generally, existing
approaches for learning monotonic neural networks can be categorized into two groups:

34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.

 
 
 
 
 
 
1) Hand-designed Monotonic Architectures. A popular approach is to design special neural architec-
tures that guarantee monotonicity by construction [e.g., 2, 7, 10, 34]. Unfortunately, these designed
monotonic architectures can be very restrictive or complex, and are typically difﬁcult to implement in
practice. A further review of this line of work is provided at the end of Section 1.

2) Heuristic Monotonic Regularization. An alternative line of work focuses on enforcing monotonicity
for an arbitrary, off-the-shelf neural network by training with a heuristically designed regularization
(e.g., by penalizing negative gradients on the data) [13]. While this approach is more ﬂexible and
easier to implement compared to the former method, it cannot provably ensure that the learned models
would produce the desired monotonic response on selected features. As a result, the monotonicity
constraint can be violated on some data, which may lead to costly results when deployed to solve
real-world tasks.

Obviously, each line of the existing methods has its pros and cons. In this work, we propose a
new paradigm for learning monotonic functions that can gain the best of both worlds: leveraging
arbitrary neural architectures and provably ensuring monotonicity of the learned models. The key
of our approach is an optimization-based technique for mathematically verifying, or rejecting, the
monotonicity of an arbitrary piece-wise linear (e.g., ReLU) neural network. In this way, we transform
the monotonicity veriﬁcation into a mixed integer linear programming (MILP) problem that can be
solved by powerful off-the-shelf techniques. Equipped with our monotonicity veriﬁcation technique,
we can learn monotonic networks by training the networks with heuristic monotonicity regularizations
and gradually increasing the regularization magnitude until it passes the monotonicity veriﬁcation.
Empirically, we show that our method is able to learn more ﬂexible partially monotonic functions
on various challenging datasets and achieve higher test accuracy than the existing approaches with
best performance, including the recent Deep Lattice Network [34]. We also demonstrate the use of
monotonic constraints for learning interpretable convolutional networks.

Related works: As we have categorized the existing work into two groups earlier, here we further
summarize some concrete examples that are most relevant to our work. A simple approach to ob-
tain monotonic neural networks is to constrain the weights on the variables to be non-negative [2].
This, however, yields a very restrictive subset of monotonic functions (e.g., ReLU networks with
non-negative weights are always convex) and does not perform well in practice. Another classical
monotonic architecture is the Min-Max network [7], which forms a universal approximation of mono-
tonic functions theoretically, but does not work well in practice. Deep Lattice Network (DLN) [34]
exploits a special class of function, an ensemble of lattices [10], as a differentiable component of
neural network. DLN requires a large number of parameters to obtain good performance.

Moreover, the monotonicity veriﬁcation that we propose admits a new form of veriﬁcation problem
of the ReLU networks that has not been explored before, which is, verifying a property of the
gradients on the whole input domain. Existing work has investigated veriﬁcation problems that
include evaluating robustness against adversarial attack [25, 31, 35], and computing the reachable set
of a network [3, 20]. Compared with these problems, verifying monotonicity casts a more signiﬁcant
challenge because it is a global property on the whole domain rather than a local neighborhood (this
is true even for the individual monotonicity that we introduce in Section 3.1). Given its practical
importance, we hope our work can motivate further exploration in this direction.

2 Monotonicity in Machine Learning

We present the concept of monotonicity and discuss its importance in practical applications. In
particular, we introduce a form of adversarial attacking that exploits the non-monotonicity in problems
for which fairness plays a signiﬁcant role.

Monotonic and Partial Monotonic Functions Formally, let f (x) be a neural network mapping
from an input space X to R. In this work, we mainly consider the case when X is a rectangle region
in Rd, i.e., X = ⊗d
i=1[li, ui]. Assume the input x is partitioned into x = [xα, x¬α], where α is a
subset of [1, . . . , d] and ¬α its complement, and xα := [xi : i ∈ α] is the corresponding sub-vector
of x. Denote the space of xα and x¬α by Xα = ⊗i∈α[li, ui] and X¬α := ⊗i∈¬α[li, ui] respectively.
We say that f is (partially) monotonic w.r.t xα if

f (xα, x¬α) ≤ f (x(cid:48)

α, x¬α), ∀xα ≤ x(cid:48)

α, ∀xα, x(cid:48)

α ∈ Xα, x¬α ∈ X¬α,

(1)

where xα ≤ x(cid:48)

α denotes the inequality for all the elements, that is, xi ≤ x(cid:48)

i for all i ∈ α.

2

Individual Monotonicity and Monotonicity Attacking In ﬁelds where fairness and security are
of critical importance, it is highly desirable to enforce monotonicity over certain features in the
deployed ML models [11, 17, 28]. Otherwise, the system may be subject to attacks that exploit
the non-monotonicity within it. Consider, for example, a program for predicting a product price
(e.g., house) based on the product features. Let xα be the features that people naturally expect to be
monotonic (such as the quantity or quality of the product). For a product with feature x = [xα, x¬α],
if the function is not monotonic w.r.t. xα, then we can ﬁnd another testing example ˆx = [ ˆxα, ˆx¬α],
which satisﬁes

f ( ˆx) > f (x), s.t. ˆxα ≤ xα, ˆx¬α = x¬α.

(2)

In other words, while ˆx has the same values on the non-monotonic features with x, and smaller
values on the monontonic features than x, f ( ˆx) is larger than f (x). If such case is possible, the
fairness of the system would be cast in doubt. Addressing this kind of problems is critical for many
real-world scenarios such as criminal judgment, loan applications, as well as hiring/administration
decisions. In light of this, we call f to be individually monotonic on x if there exists no adversarial
example as described in (2).

The non-monotonicity is hard to detect through a simple sanity check, unless the model is monotonic
by construction. For example, Figure 1 shows a data instance x we found on COMPAS [16], a
recidivism risk score dataset. In this example, a trained neural network is monotonic with respect to
the monotonic features (i.e., f ([xi, x¬i]) w.r.t. each xi with x¬i ﬁxed on the instance), but there exists
an adversarial example ˆx that violates the monotonicity in the sense of (2). In this case, checking the
monotonicity requires us to eliminate all the combinations of features on the input domain. To do
so, we need a principled optimization framework, which can eliminate the existence of any possible
monotonicity violations.

t
u
p
t
u
O

t
u
p
t
u
O

xi

Coefﬁcient of Linear Interpolation

Figure 1: If monotonicity is not strictly enforced, there may exist misleading cases when the model
appears to be monotonic for each individual feature with a simple sanity check, such as visualizing
the 1D slice plot of the individual features (Left), but there may exist an adversarial example that
violates the monotonicity in the sense of (2) (Right). Here, we trained a two-layer ReLU network
with a heuristic monotonicity regularization on the COMPAS dataset, which has 4 monotonic features
out of 13. The stars in the left ﬁgure indicates the value of each monotonic feature. The right ﬁgure
shows the linear slice (x + α( ˆx − x), where α is the coefﬁcient of a linear interpolation) from the
data point x to its adversarial example ˆx.

3 Learning Certiﬁed Monotonic Networks

In this section, we introduce our main method for learning certiﬁed monotonic networks. We start by
discussing how to verify individual monotonicity or otherwise ﬁnd monotonic adversarial examples
(Section 3.1), followed by verifying the global monotonicity on the whole domain (Section 3.2).
We then discuss our learning method (Section 3.3), and extend the monotonicity veriﬁcation to the
multiple layer neural networks (Section 3.4).

3.1 Certifying Individual Monotonicity

For a given data point x and a model f , we want to either verify the non-existence of any monotonicity
adversarial examples, or otherwise detect all such adversarial examples if they exist. Detecting a

3

0.00.20.40.60.81.00.00.20.40.60.81.0priors_countjuv_fel_countjuv_misd_countjuv_other_countOriginal SampleAttack Sample0.50.10.30.71.11.50.20.00.20.40.60.8Attack SampleOriginal Samplemonotonicity adversarial example can be framed into the following optimization problem:

ˆx∗

α = arg max

x(cid:48)∈X

f (x(cid:48)

α, x¬α) s.t. x(cid:48)

α ≤ xα, x(cid:48)

¬α = x¬α.

(3)

If f ( ˆx∗) > f (x), then ˆx∗ is a monotonic adversarial example. Otherwise, no monotonicity attacking
is possible. Eq (3) amounts to solving a challenging non-convex optimization problem. To tackle
it, we ﬁrst note that most neural networks use piece-wise linear activation functions (ReLU, leaky
ReLU, etc.). This fact implies that the optimization can be framed into a mixed integer linear pro-
gramming (MILP) problem, which can be solved by leveraging the powerful off-the-shelf techniques.
Speciﬁcally, let f (x) be a two-layer ReLU network,

f (x) =

n
(cid:88)

i=1

aiReLU(w(cid:62)

i x + bi).

(4)

The ReLU activation, ReLU(w(cid:62)
as follows:

i x + bi), can be rewritten into a set of mixed integer linear constraints

where

C(x, wi, bi) =

yi = ReLU(w(cid:62)
i x + bi) ⇔ yi ∈ C(x, wi, bi),
(cid:12)
(cid:12)
(cid:12)
(cid:12)

y ≤ uiz,
y ≤ w(cid:62)

y ≥ 0,
y ≥ w(cid:62)

(cid:40)

y

i x + bi,

z ∈ {0, 1}

i x + bi − li(1 − z)

(5)

(cid:41)

,

i x + bi} and li = inf x∈X {w(cid:62)

in which z is a binary variable that indicates whether ReLU is activated or not, and ui =
supx∈X {w(cid:62)
i x + bi} are the maximum and minimum values of
the output respectively. Both ui and li can be calculated easily when X is a rectangular interval in
Rd. For example, when X = [0, 1]d, we have ui = ReLU(wi)(cid:62)1 + bi, where 1 denotes the vector
of all ones. Eq (5) is an important characterization of the ReLU that has been widely used for other
purposes [3, 12, 26, 31].

Following these, we are now ready to frame the optimization in (3) as

max
x(cid:48)

n
(cid:88)

i=1

aiyi, s.t. x(cid:48)

α ≤ xα, x(cid:48)

¬α = x¬α, yi ∈ C(x, wi, bi), ∀i ∈ [n].

It is straightforward to develop a similar formulation for networks with more layers. Besides, our
method can also be extended to neural networks with smooth activation functions by upper bounding
the smooth activation functions with piece-wise linear functions; see Appendix B.2 for details.

3.2 Monotonicity Veriﬁcation

In addition to the individual monotonicity around a given point x, it is important to check the global
monotonicity for all the points in the input domain as well. It turns out that we can also address this
problem through an optimization approach. For a differentiable function f , it is monotonic w.r.t. xα
on X if and only if ∂x(cid:96)f (x) ≥ 0 for all (cid:96) ∈ α, x ∈ X . We can check this by solving

Uα := min
x, (cid:96)∈α

{∂x(cid:96)f (x), x ∈ X }

(6)

If Uα ≥ 0, then monotonicity is veriﬁed. Again, we can turn this optimization into a MILP for the
ReLU networks. Consider the ReLU network in (4). Its gradient equals

∂x(cid:96) f (x) =

n
(cid:88)

i=1

I(w(cid:62)

i x + bi ≥ 0)aiwi,(cid:96).

(7)

Following the same spirit as in the previous section, we are able to transform the indicator function
I(w(cid:62)

i x + bi ≥ 0) into a mixed integer linear constraint,
zi = I(w(cid:62)
(cid:110)
(cid:12)
(cid:12) zi ∈ {0, 1}, w(cid:62)

where G(x, wi, bi) =

zi

i x + bi ≥ 0) ⇔ zi ∈ G(x, wi, bi),

i x + bi ≤ uizi, w(cid:62)

i x + bi ≥ li(1 − zi)

. (9)

(8)

(cid:111)

Here, ui and li are deﬁned as before. One can easily verify the equivalence: if w(cid:62)
then zi must be one, because w(cid:62)
i x + bi ≤ uizi; if w(cid:62)
w(cid:62)

i x + bi ≥ 0,
i x + bi ≤ 0, then zi must be zero, because

i x + bi ≥ li(1 − zi).

Therefore, we can turn (6) into a MILP:

(cid:40) n
(cid:88)

Uα = min
x,(cid:96)∈α

aiwi,(cid:96)zi

s.t.

zi ∈ G(x, wi, bi),

x ∈ X

.

(10)

(cid:41)

i=1

4

MILP Solvers: There exists a number of off-the-shelf MILP solvers, such as GLPK library [23]
and Gurobi [14]. These solvers are based on branch-and-bound methods, accompanied with abundant
of heuristics to accelerate the solving process. Due to the NP nature of MILP [3], it is impractical
to obtain exact solution when the number of integers is too large (e.g., 1000). Fortunately, most
MILP solvers are anytime, in that they can stop under a given budget to provide a lower bound of
the optimal value (in case, a lower bound of Uα). Then it veriﬁes the monotonicity without solving
the problem exactly. A simple example of lower bound can be obtained by linear relaxation, which
has already been widely used in veriﬁcation problems associated with neural networks [33, 35]. It
has been an active research area to develop tighter lower bounds than linear relaxation, including
using tighter constraints [1] or smarter branching strategies [3]. Since these techniques are available
in off-the-shelf solvers, we do not further discuss them here.

3.3 Learning Certiﬁed Monotonic Neural Networks

We now introduce our simple procedure for learning monotonic neural networks with veriﬁcation. Our
learning algorithm works by training a typical network with a data-driving monotonicity regularization,
and gradually increase the regularization magnitude until the network passes the monotonicity
veriﬁcation in (6). Precisely, it alternates between the following two steps:
Step 1: Training a neural network f by

min
f

L(f ) + λR(f ),

where

R(f ) = Ex∼Uni(X )

(cid:104) (cid:88)

max(0, −∂x(cid:96) f (x))2(cid:105)
,

(11)

(cid:96)∈α

where L(f ) is the typical training loss, and R(f ) is a penalty that characterizes the violation of
monotonicity; here λ is the corresponding coefﬁcient and Uni(X ) denotes the uniform distribution
on X . R(f ) can be deﬁned heuristically in other ways. R(f ) = 0 implies that f is monotonic w.r.t.
xα, but it has to be computationally efﬁcient. For example, Uα in (6) is not suitable because it is too
computationally expensive to be evaluated at each iteration of training.

The exact value of R(f ) is intractable, and we approximate it by drawing samples of size 1024
uniformly from the input domain during iterations of the gradient descent. Note that the samples we
draw vary from iteration to iteration. By the theory of stochastic gradient descent, we can expect to
minimize the object function well at convergence. Also, training NNs requires more than thousands
of steps, therefore the overall size of samples can well cover the input domain. In practice, we
use a modiﬁed regularization R(f ) = Ex∼Uni(X )
, where b is a small
positive constant, because we ﬁnd the original version will always lead to a Uα that is slightly smaller
than zero.

(cid:96)∈α max(b, −∂x(cid:96)f (x))2(cid:105)

(cid:104) (cid:80)

Step 2: Calculate Uα or a lower bound of it. If it is sufﬁcient to verify that Uα ≥ 0, then f is
monotonic and the algorithm terminates, otherwise, increase λ and repeat step 1.

This training pipeline requires no special architecture design or constraints on the weight space.
Though optimizing R(f ) involves computation of second order derivative, we found it can be
effectively computed in modern deep learning frameworks. The main concern is the computational
time of the monotonicity veriﬁcation, which is discussed in Section 3.4.

3.4 Extension to Deep Neural Networks

Although it is possible to directly extend the veriﬁcation approach above to networks with more
than two layers by formulating a corresponding MILP, the resulting optimization may include a
large number of integer variables, making the problem intractable. See Appendix B.1 for detailed
discussion. In this section, we discuss a more practical approach for learning and verifying monotonic
deep networks by decomposing the network into a stack of two-layer networks and then verifying
their monotonicity separately.
Assume f : X → R is a deep ReLU network with an even number 2K of layers (otherwise, we can
add an identity layer on the top and ﬁx its weights during training). We decompose the network into
a composition of two-layer networks:

f (x) = f2K:2K−1 ◦ · · · ◦ f4:3 ◦ f2:1(x),
where f2k:2k−1 denotes the composition of the 2k-th and (2k − 1)-th layers of f . Therefore, a
sufﬁcient condition for f to be monotonic is that all f2k:2k−1, ∀k = 1, . . . , K are monotonic, each of

5

(a) Original

(b) Non-Neg (142)

E
S
M
n
a
e

M
g
o
l

(c) DLN (161)

(d) Ours (142)

Number of Parameters

Figure 2: We test Deep Lattice Network (DLN) [34], networks with non-negative weights (Non-
Neg) [2], and our method on ﬁtting a family of 2D functions: f (x, y) = a sin(x/25π)+b (x−0.5)3 +
c exp(y) + y2, a, b, c ∈ {0.3, 0.6, 1.0}. Left: The ﬁtting result when a = 1.0, b = 1.0, c = 1.0. The
number in the parenthesis refers to the number of parameters of the model. Our method ﬁts the
original function best. Right: We test the above methods on ﬁtting all the 27 functions with different
number of parameters. We averaged the mean-square-error (MSE) of all 27 runs. Our method yields
better performance than the other methods.

which can be veriﬁed separately using our method in Section 3.2. We normalize the input feature to
[0, 1]. To address the change of input domain across the layers, we derive the corresponding upper
and lower bound ui and li from ui−1 and li−1. We can evaluate all the ui and li in a recursive manner.

Obviously, the layer-wise approach may not be able to verify the monotonicity in the case when f is
monotonic, but not all the f2k:2k−1 layers are. To address this, we explicitly enforce the monotonicity
of all f2k:2k−1 during training, so that they can be easily veriﬁed using the layer-wise approach.
Speciﬁcally, we introduce the following regularization during training:

˜R(f ) =

K
(cid:88)

k=1

R(f2k:2k−1),

(12)

where R can be deﬁned as (11). See in Algorithm 1 in Appendix for the detailed procedure.

The idea of using two-layer (vs. one-layer) decomposition allows us to beneﬁt from the extended
representation power of deep networks without signiﬁcant increase of computational cost. Note that
two-layer networks form universal approximation in the space of bounded continuous functions, and
hence allows us to construct highly ﬂexible approximation. If we instead decomposed the network
into the stack of one-layer networks, the veriﬁcation becomes simply checking the signs of the
weights, which is much more restrictive.

4 Experiments

4.1 Comparison with Other Methods

We verify our method in various practical settings and datasets. Experiment results show that
networks learned by our method can achieve higher test accuracy with fewer parameters, than the
best-known algorithms for monotonic neural networks, including Min-Max Network [7] and Deep
Lattice Network [34]. Our method also outperforms traditional monotonic methods, such as isotonic
regression and monotonic XGBoost, in accuracy. We also demonstrate how to learn interpretable
convolutional neural networks with monotonicity.

Datasets: Experiments are performed on 4 datasets: COMPAS [16], Blog Feedback Regression [4],
Loan Defaulter1, Chest X-ray2. COMPAS is a classiﬁcation dataset with 13 features. 4 of them are

1https://www.kaggle.com/wendykan/lending-club-loan-data
2https://www.kaggle.com/nih-chest-xrays/sample

6

50100150200250300102101OursNon-NegDLNMethod
Isotonic
XGBoost [5]
Crystal [10]
DLN [34]
Min-Max Net [7]
Non-Neg-DNN
Ours

Parameters
N.A.
N.A.
25840
31403
42000
23112
23112

Test Acc
67.6%
68.5% ± 0.1%
66.3% ± 0.1%
67.9% ± 0.3%
67.8% ± 0.1%
67.3% ± 0.9%
68.8% ± 0.2%

Methods
Isotonic
XGBoost [5]
Crystal [10]
DLN [34]
Min-Max Net [7]
Non-Neg-DNN
Ours

Parameters
N.A.
N.A.
15840
27903
27700
8492
8492

RMSE
0.203
0.176 ± 0.005
0.164 ± 0.002
0.161 ± 0.001
0.163 ± 0.001
0.168 ± 0.001
0.158 ± 0.001

Table 1: Results on COMPAS

Table 2: Results on Blog Feedback

Methods
Isotonic
XGBoost [5]
Crystal [10]
DLN [34]
Min-Max Net [7]
Non-Neg-DNN
Ours

Parameters
N.A.
N.A.
16940
29949
29000
8502
8502

Test Acc
62.1%
63.7% ± 0.1%
65.0% ± 0.1%
65.1% ± 0.2%
64.9% ± 0.1%
65.1% ± 0.1%
65.2% ± 0.1%

Methods
XGBoost [5]
Crystal [10]
DLN [34]
Min-Max Net [7]
Non-Neg-DNN
Ours w/o E-to-E
Ours

Parameters
N.A.
26540
39949
35130
12792
12792
12792

Test Acc
64.4% ± 0.4%
65.3% ± 0.1%
65.4% ± 0.1%
64.3% ± 0.6%
64.7% ± 1.6%
62.3% ± 0.2%
66.3% ± 1.0%

Table 3: Results on Loan Defaulter

Table 4: Results on Chest X-Ray. ‘w/o E-to-
E’ means the weights in the pretrained feature
extractor are frozen during training.

monotonic. Blog Feedback is a regression dataset with 276 features. 8 of the features are monotonic.
Loan Defaulter is a classiﬁcation dataset with 28 features. 5 of them are monotonic. The dataset
includes half a million data points. Chest X-Ray is a classiﬁcation dataset with 4 tabular features and
an image. 2 of the tabular features are monotonic. All the images are resized to 224 × 224. For each
dataset, we pick 20% of the training data as the validation set. More details can be found in appendix.

Methods for Comparison: We compare our method with six methods that can generate partially
Isotonic Regression: a deterministic method for monotonic regression [9].
monotonic models.
XGBoost: a popular algorithm based on gradient boosting decision tree [5]. Crystal: an algorithm
using ensemble of lattices [10]. Deep Lattice Network (DLN): a deep network with ensemble of
lattices layer [34]. Non-Neg-DNN: deep neural networks with non-negative weights. Min-Max Net:
a classical three-layer network with one linear layer, one min-pooling layer, and one max-pooling
layer [7]. For Non-Neg-DNN, we use the same structure as our method.

Hyper-parameter Conﬁguration: We use
cross-
entropy loss for classiﬁcation problems, and mean-square-
error for regression problems. 20% of the training data
is used as the validation set. All the methods use the same
training set and validation set. We validate the number
of neurons in each layer and the depth of the network.
Adam [18] optimizer is used for optimization. For solving
the MILP problems, we adopt Gurobi v9.0.1 [14], which
is an efﬁcient commercial solver. We initialize the
coefﬁcient of monotonicity regularization λ = 1, and
multiply λ by 10 every time λ needs ampliﬁcation. The
default learning rate is 5e − 3. When λ is large, 5e − 3
may cause training failure.
In this case, we decrease
the learning rate until training successes. Our method
is implemented with PyTorch [24]. All the results are
averaged over 3 runs. The code is publicly available3.

3https://github.com/gnobitab/CertiﬁedMonotonicNetwork

7

s

/

i

e
m
T
n
o
i
t
a
c
ﬁ

i
r
e
V
g
v
A

Number of Hidden Neurons
Figure 3: Veriﬁcation time w.r.t. number
of hidden neurons.

050100024Our Method Learns Smaller, More Accurate Monotonic Networks: The results on the dataset
above are summarized in Table 1, 2, 3, and 4. It shows that our method tends to outperform all
the other methods in terms of test accuracy, and learns networks with fewer parameters. Note that
because our method use only typical neural architectures, it is also easier to train and use in practice.
All we need is adding the monotonicity regularization in the loss function.

Our Method Learns Non-trivial Sign Combinations: Some neural networks, such as those with
all non-negative weights, can be trivially veriﬁed to be monotonic. More generally, a neural network
can be veriﬁed to be monotonic by just reading the sign of the weights (call this sign veriﬁcation)
if the product of the weights of all the paths connecting the monotonic features to the outputs are
positive. Let us take a two-layer ReLU network, f = W2ReLU (W1x), for example. Because
ReLU (·) is a monotonically increasing function, we can verify the monotonicity of the network if all
the elements in the matrix W2W1 is non-negative without our MILP formulation. Each element in
the matrix is a multiplication of the weights on a path connecting the input to the output, hence we
call such paths non-negative/negative paths. As shown in Table. 5 and Fig. 4.1, our method tends to
learn neural networks that cannot be trivially veriﬁed by sign veriﬁcation, suggesting that it learns
in a richer space of monotonic functions. A, B, C, D refer to four different networks, with different
structures and trained on different datasets.

Computational Time for Monotonicity Veriﬁcation: Because our monotonicity veriﬁcation in-
volves solving MILP problems, we evaluate the time cost of two-layer veriﬁcation in Fig. 3. All
the results are averaged over 3 networks trained with different random seeds on COMPAS. The
veriﬁcation can be done in less than 4 seconds with 100 neurons in the ﬁrst layer. Our computer has
48 cores and 192GB memory.

Net

# of Paths

# of Negative Paths

A

B

C

D

100,000

42,972

400

160

50000

113

47

21344

Figure 4: Weights learned of a two-layer mono-
tonic net. h2, h5, h6, h8 are on negative paths.

Table 5: Statistics of negative paths

4.2 Learning Interpretable Neurons with Monotonic Constraints

Enforcing monotonicity provides a natural tool for enhancing the interpretablity of neural networks,
but has not been widely explored in the literature with very few exceptions [22]. Here, we show an
example of learning interpretable convolutional networks via monotonicity. We use MNIST [19]
and consider binary classiﬁcation between pairs of digits (denoted by C1 and C2). The network
consists of three convolutional layers to extract the features of the images. The extracted features
are fed into two neurons (denoted by A and B), and are then processed by a hidden layer, obtaining
the the class probabilities P (C1) and P (C2) after the softmax operation; see Fig. 5(a). To enforce
interpretability, we add monotonic constraints during training such that P (C1) (resp. P (C2)) is
monotonically increasing to the output of neuron A (resp. B), and is monotonically decreasing to
neuron B (resp. A). We adopt the previous training and veriﬁcation pipeline, and the convolutional
layers are also trained in an end-to-end manner. We visualize the gradient map of the output of
neuron A w.r.t. the input image via SmoothGrad [29]. As we show in Fig. 5(c), in the monotonic
network, the top pixels in the gradient map identiﬁes the most essential patterns for classiﬁcation in
that removing them turns the images into the opposite class visually.

4.3 Monotonicity Increases Adversarial Robustness

Interpretability of a model is considered to be deeply related to its robustness against adversarial
attacks [15, 30, 32, 36]. People believe higher interpretability indicates higher robustness. Here,
we empirically show that our interpratable models, trained with monotonicity constraints, do have

8

ℎ!ℎ!ℎ"ℎ#ℎ$ℎ%ℎ&ℎ’ℎ(ℎ)*PositiveNegativeOutputInput(a) Network

(b) Test Image

(c) with Monotonicity

(d) w/o Monotonicity

Figure 5: (a) We train a neural network on MNIST with the constraint that P (C1) (resp. P (C2))
is monotonically increasing w.r.t. neuron A (resp. B), and monotonically decreasing w.r.t. neuron
B (resp. A). (b) Visualization of three binary classiﬁcation tasks between two digits: 2 vs. 7 (1st
row), 8 vs. 3 (2nd row), 7 vs. 1 (3rd row). We train the same network with and without monotonic
constraints.
(c) and (d) show the result when training the network with and without monotonic
constraints, respectively. Left column of (c) and (d): The gradient heat map of neuron A, where
higher value means the corresponding pixel has higher importance in predicting the image to be class
C1. Right column of (c) and (d): The image that we obtain by removing the most important pixels
with the top 5% largest gradient values. We can see that in (c), in the monotonic network, removing
the important pixels of a test image (such as the digit 2, 8, 7 in (b)) turns the image to the opposite
class (e.g., 2 is turned to a 7 like image on the top row). In contrast, as shown in (d), removing the
top-ranked pixels in the non-monotonic network makes little semantic change on the image.

y
c
a
r
u
c
c
A

t
s
e
T

y
c
a
r
u
c
c
A

t
s
e
T

y
c
a
r
u
c
c
A

t
s
e
T

(cid:15)
(a) 1-7

(cid:15)
(b) 2-7

(cid:15)
(c) 3-8

Figure 6: We perform PGD attack on the networks trained in Sec. 4.2, and test them on those binary
classiﬁcation problems. For clean images ((cid:15) = 0), the test accuracy of the monotonic networks and
the non-monotonic ones are almost the same. However, the monotonic networks show higher test
accuracy over the non-monotonic counterparts under different magnitudes of adversarial attacks.

better performance under adversarial attacks. We take the trained convolutional neural networks in
Sec. 4.2, and apply projected gradient descent (PGD) attack on the test images. We use a step size of
2/255, and iterates for 30 steps to ﬁnd the adversarial examples. We bound the difference between
the adversarial image and the original image in a Linf ball with radius (cid:15). A larger (cid:15) indicates a more
signiﬁcant attack. We show our results in Fig. 6.

5 Conclusions

We propose a veriﬁcation-based framework for learning monotonic neural networks without specially
designed model structures. In future work, we plan to investigate better veriﬁcation methods to
speed up, and to incorporate monotonicity into large modern convolutional neural networks to train
interpretable networks.

9

ImageConv Layers		𝑃(𝐶!)		𝑃(𝐶")ABHidden Layeroriginal images2 vs. 78vs. 37vs. 1saliency mapimages w/o important pixels saliency mapimages w/o important pixels 081624320.250.500.751.00MonotonicNon-Monotonic081624320.250.500.751.00MonotonicNon-Monotonic081624320.250.500.751.00MonotonicNon-MonotonicBroader Impact Statement: Our method can simplify and improve the process of incorporating
monotonic constraints in deep learning systems, which can potentially improve the fairness, se-
curity and interpretability of black-box deep models. Since it is a fundamental machine learning
methodology, We do not foresee negative impact to the society implied by the algorithm directly.

Funding Disclosure: Work supported in part by NSF CAREER #1846421, SenSE #2037267, and
EAGER #2041327. Xingchao Liu is supported in part by a funding from BP.

References

[1] Ross Anderson, Joey Huchette, Will Ma, Christian Tjandraatmadja, and Juan Pablo Vielma.
Strong mixed-integer programming formulations for trained neural networks. Mathematical
Programming, pages 1–37, 2020.

[2] Norman P Archer and Shouhong Wang. Application of the back propagation neural network
algorithm with monotonicity constraints for two-group classiﬁcation problems. Decision
Sciences, 24(1):60–75, 1993.

[3] Rudy R Bunel, Ilker Turkaslan, Philip Torr, Pushmeet Kohli, and Pawan K Mudigonda. A
uniﬁed view of piecewise linear neural network veriﬁcation. In Advances in Neural Information
Processing Systems, pages 4790–4799, 2018.

[4] Krisztian Buza. Feedback prediction for blogs.

In Data analysis, machine learning and

knowledge discovery, pages 145–152. Springer, 2014.

[5] Tianqi Chen and Carlos Guestrin. XGBoost: A scalable tree boosting system. In Proceedings of
the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
KDD ’16, pages 785–794, New York, NY, USA, 2016. ACM.

[6] Guy W Cole and Sinead A Williamson. Avoiding resentment via monotonic fairness. arXiv

preprint arXiv:1909.01251, 2019.

[7] Hennie Daniels and Marina Velikova. Monotone and partially monotone neural networks. IEEE

Transactions on Neural Networks, 21(6):906–917, 2010.

[8] Michael Doumpos and Constantin Zopounidis. Monotonic support vector machines for credit

risk rating. New Mathematics and Natural Computation, 5(03):557–570, 2009.

[9] Richard Dykstra, Tim Robertson, and Farrol T Wright. Advances in Order Restricted Statistical
Inference: Proceedings of the Symposium on Order Restricted Statistical Inference Held in Iowa
City, Iowa, September 11–13, 1985, volume 37. Springer Science & Business Media, 2012.

[10] Mahdi Milani Fard, Kevin Canini, Andrew Cotter, Jan Pfeifer, and Maya Gupta. Fast and
ﬂexible monotonic functions with ensembles of lattices. In Advances in Neural Information
Processing Systems, pages 2919–2927, 2016.

[11] Ad J Feelders. Prior knowledge in economic applications of data mining.

In European
Conference on Principles of Data Mining and Knowledge Discovery, pages 395–400. Springer,
2000.

[12] Matteo Fischetti and Jason Jo. Deep neural networks as 0-1 mixed integer linear programs: A

feasibility study. arXiv preprint arXiv:1712.06174, 2017.

[13] Akhil Gupta, Naman Shukla, Lavanya Marla, and Arinbjörn Kolbeinsson. Monotonic trends in

deep neural networks. arXiv preprint arXiv:1909.10662, 2019.

[14] LLC Gurobi Optimization. Gurobi optimizer reference manual, 2020.

[15] Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and
Aleksander Madry. Adversarial examples are not bugs, they are features. In Advances in Neural
Information Processing Systems, pages 125–136, 2019.

[16] S. Mattu J. Angwin, J. Larson and L. Kirchner. Machine bias: There’s software used across the

country to predict future criminals. and it’s biased against blacks. ProPublica, 2016.

10

[17] Jørgen Karpf. Inductive modelling in law: example based expert systems in administrative law.
In Proceedings of the 3rd international conference on Artiﬁcial intelligence and law, pages
297–306, 1991.

[18] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint

arXiv:1412.6980, 2014.

[19] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010.

[20] Changliu Liu, Tomer Arnon, Christopher Lazarus, Clark Barrett, and Mykel J Kochenderfer.
Algorithms for verifying deep neural networks. arXiv preprint arXiv:1903.06758, 2019.

[21] Alexey Minin, Marina Velikova, Bernhard Lang, and Hennie Daniels. Comparison of universal
approximators incorporating partial monotonicity by structure. Neural Networks, 23(4):471–475,
2010.

[22] An-phi Nguyen and María Rodríguez Martínez. Mononet: Towards interpretable models by

learning monotonic features. arXiv preprint arXiv:1909.13611, 2019.

[23] Eiji Oki. Linear programming and algorithms for communication networks: a practical guide

to network design, control, and management. CRC Press, 2012.

[24] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-
performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d Alché-
Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32,
pages 8024–8035. Curran Associates, Inc., 2019.

[25] Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certiﬁed defenses against adversarial

examples. arXiv preprint arXiv:1801.09344, 2018.

[26] Thiago Serra, Christian Tjandraatmadja, and Srikumar Ramalingam. Bounding and counting
linear regions of deep neural networks. In International Conference on Machine Learning,
pages 4558–4566. PMLR, 2018.

[27] Arnab Sharma and Heike Wehrheim. Testing monotonicity of machine learning models. arXiv

preprint arXiv:2002.12278, 2020.

[28] Joseph Sill. Monotonic networks. In Advances in neural information processing systems, pages

661–667, 1998.

[29] Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Viégas, and Martin Wattenberg. Smooth-

grad: removing noise by adding noise. arXiv preprint arXiv:1706.03825, 2017.

[30] Guanhong Tao, Shiqing Ma, Yingqi Liu, and Xiangyu Zhang. Attacks meet interpretabil-
ity: Attribute-steered detection of adversarial samples. In Advances in Neural Information
Processing Systems, pages 7717–7728, 2018.

[31] Vincent Tjeng, Kai Xiao, and Russ Tedrake. Evaluating robustness of neural networks with

mixed integer programming. arXiv preprint arXiv:1711.07356, 2017.

[32] Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and Aleksander Madry.

Robustness may be at odds with accuracy. arXiv preprint arXiv:1805.12152, 2018.

[33] Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Duane Boning,
Inderjit S Dhillon, and Luca Daniel. Towards fast computation of certiﬁed robustness for relu
networks. arXiv preprint arXiv:1804.09699, 2018.

[34] Seungil You, David Ding, Kevin Canini, Jan Pfeifer, and Maya Gupta. Deep lattice networks
and partial monotonic functions. In Advances in neural information processing systems, pages
2981–2989, 2017.

11

[35] Huan Zhang, Pengchuan Zhang, and Cho-Jui Hsieh. Recurjac: An efﬁcient recursive algorithm
for bounding jacobian matrix of neural networks and its applications. In Proceedings of the
AAAI Conference on Artiﬁcial Intelligence, volume 33, pages 5757–5764, 2019.

[36] Tianyuan Zhang and Zhanxing Zhu. Interpreting adversarially trained convolutional neural

networks. arXiv preprint arXiv:1905.09797, 2019.

12

A Details of the Experiments

A.1 Details of the Datasets

Here we introduce the details of the datasets used in the experiments.

Dataset
COMPAS
Blog Feedback
Loan Defaulter
Chest X-Ray

Task
Classiﬁcation
Regression
Classiﬁcation
Classiﬁcation

Feature Dimension Monotonic Features

13
276
28
4 tabular + image

4
8
5
2

Table 6: Dataset Summary

# Training
4937
47302
418697
4484

# Test
1235
6968
70212
1122

COMPAS: COMPAS [16] is a dataset containing the criminal records of 6,172 individuals
arrested in Florida. The task is to predict whether the individual will commit a crime again
in 2 years. The probability predicted by the system will be used as a risk score. We use
13 attributes for prediction. The risk score should be monotonically increasing w.r.t.
four at-
tributes, number of prior adult convictions, number of juvenile felony, number
of juvenile misdemeanor, and number of other convictions.

Blog Feedback Regression: Blog Feedback [4] is a dataset containing 54,270 data points from
blog posts. The raw HTML-documents of the blog posts were crawled and processed. The prediction
task associated with the data is the prediction of the number of comments in the upcoming 24 hours.
The feature of the dataset has 276 dimensions, and 8 attributes among them should be monotonically
non-decreasing with the prediction. They are A51, A52, A53, A54, A56, A57, A58, A59. Please
refer to the link 4 for the speciﬁc meanings of these attributes. Because outliers could dominate the
MSE metric, we only use the data points with targets smaller than the 90th percentile.

Prediction of Loan Defaulters: Lending club loan data5 contains complete loan data for all loans
issued through 2007-2015 of several banks. Each data point is a 28-dimensional feature including
the current loan status, latest payment information, and other additional features. The task is to
predict loan defaulters given the feature vector. The possibility of loan default should be non-
decreasing w.r.t. number of public record bankruptcies, Debt-to-Income ratio, and
non-increasing w.r.t. credit score, length of employment, annual income.

Chest X-Ray: Without the constraints on structure, our method can easily go beyond tabular data.
Chest X-ray exams are one of the most frequent and cost-effective medical imaging examinations
available. NIH Chest X-ray Dataset6 has 5606 X-ray images with disease labels and patient infor-
mation. Hence, this dataset is a multi-modal dataset using both image and tabular data. We resize
all the images to 224 × 224, and use a ResNet-18 pretrained on ImageNet as the feature extractor.
The task is to predict whether a patient has chest disease or not. The possibility of chest disease
is set to be non-decreasing to age and number of follow-up examinations. We did not count
the parameters in the ResNet-18 feature extractor. The beneﬁt of monotonic neural networks is
that we can apply end-to-end training on the feature extractor. Other methods, including XGBoost,
Crystal and DLN, cannot do end-to-end training. Hence, for these methods, we extract the features of
the images using the pretrained ResNet-18, and train them using ﬁxed image features without the
ResNet-18 in the training pipeline.

A.2 More Details in Implementation

To capture the non-monotonic relationship between the output and the non-monotonic features,
we only impose monotonic constraints on half of the neurons in each 2k-th layer. we cut off the
connection (i.e. set the weights on the edges to zero) between the monotonic features and the other
half of the neurons, so that removing the monotonic constraints will not change the monotonicity

4https://archive.ics.uci.edu/ml/datasets/BlogFeedback
5https://www.kaggle.com/wendykan/lending-club-loan-data
6https://www.kaggle.com/nih-chest-xrays/sample

13

Algorithm 1 Training Monotonic Neural Network with Monotonic Veriﬁcation

1: Input: A randomly initialized neural network f , dataset D = {x(i), y(i)}n

i=1 and the indices of

monotonic features Im = {m1, m2, . . . , mk}.

2: Set the coefﬁcient of the monotonic regularization λ = λ0.
3: Train f with loss function LD(f ) + λRIm(f ) till convergence.
4: if f2k:2k−1 passes monotonic veriﬁcation for ∀k = 1, 2, . . . , K then
5:
6: else
7:
8: end if

Increase λ and repeat the previous steps.

Return monotonic neural network f

of the network. Since our regularization requires sampling over the whole input domain, it requires
more samples as the dimension increase, which means that the sampling could fail if the dimension
of the input, d, is large (e.g. d = 276 in Blog Feedback). To address it, we add an additional linear
layer for dimension reduction on the non-monotonic features. This linear layer reduces the dimension
of the non-monotonic features to 10, and is also trained in an end-to-end manner.

Our method adopts a simple MLP structure. We select the number of the hidden layers (depth of
the network) from d = {1, 3} using the validation set. Since our regularization is applied on each
2k-th layer, the number of hidden neurons is ﬁxed to 20 to avoid curse of dimension. For the neuron
numbers in each (2k + 1)-th hidden layer, we select from n ∈ {40, 100, 200}.

B Additional Formulation

B.1 Individual Monotonicity for Deep Networks

For networks with more than 2 layers, we provide the corresponding MILP formulation. We follow
the notations in Section 3.1. Consider the the following MLP,

f (x) =

nK(cid:88)

iK =1

aiK ReLU(wiK
K

(cid:62)

xK + biK

K ), xk = ReLU(w(cid:62)

k−1xk−1 + bk), k = 1, 2, . . . , K.

Here, wk is the weight matrix of the k-th linear layer, and bk is the bias. wik
k is the ik-th row of the
weight matrix, and bik
k is the ik-th element of the bias. Then we can replace all the ReLU activations
with the linear constrains (5), and thus creating a MILP problem. Comparing with the two-layer case,
we introduce a new variable zk and the corresponding constraints in every additional layer.

B.2 Monotonicity Veriﬁcation with General Activation Function

Our method has been developed for piecewise linear functions. In this section, we extend it to to any
continuous activation functions. The idea is to bound the activation function with piecewise linear
functions. Speciﬁcally, consider a two-layer network,

f (x) =

n
(cid:88)

i=1

aiσ(w(cid:62)

i x + bi),

where σ is a general activation function. Then the partial derivative equals,

∂x(cid:96) f (x) =

n
(cid:88)

i=1

σ(cid:48)(w(cid:62)

i x + bi)aiwi,(cid:96).

We can bound σ(cid:48)(·) with step-wise constant functions. Assume we partition R into M consecutive,
non-overlapping intervals, such that R = (cid:83)M
m=1 [pm, qm), where qm = pm+1, p1 = −∞, qM =
+∞. Now we can bound σ(cid:48)(·) with,

M
(cid:88)

m=1

g−
m

I (x ∈ [pm, qm)) ≤ σ(cid:48)(x) ≤

M
(cid:88)

m=1

g+
m

I (x ∈ [pm, qm))

14

m = inf x∈[pm,qm) σ(cid:48)(x) and g+

m = supx∈[pm,qm) σ(cid:48)(x), both of which can be calculated
where g−
explicitly. If we take M large enough, the upper and lower bound will approach the original σ(cid:48)(·).
Now we have the following lower bound for ∂x(cid:96)f (x),

∂x(cid:96)f (x) ≥

n
(cid:88)

M
(cid:88)

i=1

m=1

gm,i I (cid:0)w(cid:62)

i x + bi ∈ [pm, qm)(cid:1) aiwi,(cid:96),

where gm,i = g−

m if aiwi,(cid:96) ≥ 0 and gm,i = g+

m if aiwi,(cid:96) ≤ 0. Denote,

U(cid:96) = min
x∈X

n
(cid:88)

M
(cid:88)

i=1

m=1

gm,i I (cid:0)w(cid:62)

i x + bi ∈ [pm, qm)(cid:1) aiwi,(cid:96).

Replacing I(·) with the linear constraints in (8), U(cid:96) becomes a MILP problem. Monotonicity is
certiﬁed if U(cid:96) ≥ 0.

B.3 Naive Monotonicity Veriﬁcation is Impractical on Deep Networks

Naive monotonicity veriﬁcation could be problematic with deep networks. To illustrate the issue,
suppose f is a ReLU network with K layers, with nk neurons in the k-th layer. Then the objective
for computing U(cid:96) = minx∈X ∂x(cid:96)f (x) is,

U(cid:96) = min
x∈X

a diag(zK) wK diag(zK−1) . . . w2 diag(z1) w(cid:96)
1.

1 refers to the (cid:96)-th column of the input layer w1. zi = (cid:0)z1

We ignore the constraints here for simplicity. Here, a is the weight matrix of the last linear layer,
(cid:1) contains all the binary
and w(cid:96)
decision variables for the indicator functions of the i-th layer, where ni denotes the number of neurons
in that layer. Expanding the objective leads to product of these binary variables, zi1
K , which
makes the objective non-linear. We can linearize the problem by introducing new binary variables,

i , . . . , zni

2 . . . ziK

1 zi2

i

U(cid:96) := min
x∈X

n
(cid:88)

ai

(cid:88)

(cid:34)(cid:32) K
(cid:89)

i=1

ik∈[1:nk]

k=1

(cid:33)

(cid:35)

[wk−1]ik−1,ik

zi1,i2,...,iK

s.t. zi1,i2,...,iK ≤ zik

k , zi1,i2,...,iK ≥

K
(cid:88)

k=1

zik
k − (K − 1), ∀k ∈ {1, 2, . . . , K}.

1 zi2

2 . . . ziK

refers to the element on the ik-th row and ik−1-th column in the weight matrix wk.
Here, [wk]ik,ik−1
Intuitively, we replace the product zi1
K with a new binary variable zi1,i2,...,iK and additional
constraints to linearize the problem. However, in this way, we need n1 × n2 × · · · × nk new binary
variables, which is an unaffordable large-scale MILP problem for typical MILP solvers. Even for
a small network with 3 hidden layers and 20 neurons in each hidden layer, there is more than 800
binary variables. Current MILP solvers will fail to solve this problem in limited time (e.g. 1 hour). To
summarize, naive monotonicity veriﬁcation requires to consider all the paths in the neural network,
which greatly increases the number of integer variables.

C Additional Experiment Results

C.1

Inﬂuence of λ

λ indicates the magnitude of our monotonicity regularization. We empirically demonstrate how λ
inﬂuence the lower bound U(cid:96). We show 2 networks with d = 1, n = 100 (Net 1) and d = 3, n = 100
(Net 2) on COMPAS and Chest X-Ray. Generally, min(cid:96)∈α U(cid:96) increases as λ increases.

C.2 Validation Results

We provide the validation accuracy of different structures on different datasets.

15

(cid:96)

U
α
∈
(cid:96)
n
i
m

(cid:96)

U
α
∈
(cid:96)
n
i
m

log10 λ

log10 λ

Figure 7: Left: Result on COMPAS. Right:Result on Chest X-Ray. Generally, min(cid:96)∈α U(cid:96) increases
as λ increases.

Network Depth Hidden Neurons

Total Parameters Validation Accuracy

1
2
3
4
5
6

1
1
1
3
3
3

40
100
200
40
100
200

522
1302
2602
1792
7462
23112

62.15%
68.02%
68.12%
65.99%
68.22%
68.42%

Table 7: Validation Results on COMPAS

Network Depth Hidden Neurons

Total Parameters Validation RMSE

1
2
3
4
5
6

1
1
1
3
3
3

40
100
200
40
100
200

8492
17192
31692
9762
23352
54002

0.1340
0.1345
0.1357
0.1373
0.1378
0.1371

Table 8: Validation Results on Blog Feedback

Network Depth Hidden Neurons

Total Parameters Validation Accuracy

1
2
3
4
5
6

1
1
1
3
3
3

40
100
200
40
100
200

1082
2342
4442
2352
8502
26752

64.70%
64.98%
65.03%
65.07%
65.15%
65.12%

Table 9: Validation Results on Loan Defaulter

Network Depth Hidden Neurons

Total Parameters Validation Accuracy

1
2
3
4
5
6

1
1
1
3
3
3

40
100
200
40
100
200

5732
6632
8132
7002
12792
30442

61.65%
61.76%
62.10%
60.87%
62.21%
61.20%

Table 10: Validation Results on Chest X-Ray

16

012340.60.30.00.3Net 1Net 2012340.60.30.00.3Net 1Net 2