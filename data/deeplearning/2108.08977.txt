CloudShield: Real-time Anomaly Detection in the
Cloud

Zecheng He
Princeton University
zechengh@princeton.edu

Ruby Lee
Princeton University
rblee@princeton.edu

1
2
0
2

g
u
A
5
2

]

R
C
.
s
c
[

2
v
7
7
9
8
0
.
8
0
1
2
:
v
i
X
r
a

Abstract—In cloud computing,

it is desirable if suspicious
activities can be detected by automatic anomaly detection systems.
Although anomaly detection has been investigated in the past,
it remains unsolved in cloud computing. Challenges are: char-
acterizing the normal behavior of a cloud server, distinguishing
between benign and malicious anomalies (attacks), and preventing
alert fatigue due to false alarms.

We propose CloudShield, a practical and generalizable real-
time anomaly and attack detection system for cloud computing.
Cloudshield uses a general, pretrained deep learning model
with different cloud workloads, to predict the normal behavior
and provide real-time and continuous detection by examining
the model reconstruction error distributions. Once an anomaly
is detected, to reduce alert fatigue, CloudShield automatically
distinguishes between benign programs, known attacks, and
zero-day attacks, by examining the prediction error distribu-
tions. We evaluate the proposed CloudShield on representative
cloud benchmarks. Our evaluation shows that CloudShield,
using model pretraining, can apply to a wide scope of cloud
workloads. Especially, we observe that CloudShield can detect
the recently proposed speculative execution attacks, e.g., Spectre
and Meltdown attacks, in milliseconds. Furthermore, we show
that CloudShield accurately differentiates and prioritizes known
attacks, and potential zero-day attacks, from benign programs.
Thus, it signiﬁcantly reduces false alarms by up to 99.0%.

I.

INTRODUCTION

The importance of cloud computing has grown signiﬁcantly
in the past years. Cloud customers can lease virtual machines
from the cloud providers economically, sharing the physical re-
sources provided by the cloud computing servers. Large cloud
providers, like Amazon AWS [1], Google Cloud Platform [2],
and Microsoft Azure [3], have proliferated this trend.

There have been various attacks against cloud computing,
especially on shared resources. For example, security-critical
information, e.g., encryption keys, can be leaked by cache
side-channel attacks. Previous work have revealed that many
types of cache side-channel attacks can successfully obtain
secret or private cryptographic keys [12], [50], [26], [63], [66],
[25], [38], [45], [39]. Recently, speculative execution attacks
[42], [44], [41] exploit performance optimization features of
modern processors to breach the user-user, user-kernel or user-
hypervisor isolation. Besides, zero-day attacks introduce chal-
lenges as they do not have known code nor known behavior.

Anomaly detection techniques are perhaps the only viable
solution for detecting unknown zero-day attacks. By its nature,
anomaly detection does not look for speciﬁcs of an attack
but models the normal behavior of a system. Deviation from

normal behavior indicates anomalies: either an attack or a
benign anomaly.

However, existing anomaly detection systems in the cloud
have challenges. First, a model of cloud server behavior is
usually scenario-speciﬁc and is not easy to extend [13], [11],
[23]. Multiple models have to be built to cover various cloud
workloads. Second, false alarms in anomaly detection systems
are very common in practice. The large volume of false alarms
overwhelms the security analysts and causes alert fatigue,
potentially causing real attacks to be missed.

In this work, we investigate three questions. First: Can we
make an anomaly detection system generalizable to different
scenarios in cloud computing? We hypothesize that the normal
behavior of a cloud server, although different from workload
to workload running on it, consists of a major predictable
part, and a minor unpredictable part that follows a certain
probability distribution. If we pre-train a general model to
predict a cloud system’s behavior, an anomaly can be detected
by subtracting the predictable part from the original behavior
markers and identifying the distribution of the remaining
unpredictable part. To this end, we propose that the distri-
bution of the unpredicted part denoted Reconstruction Error
Distribution (RED), can capture the characteristics of any
cloud workload. Thus, we show that rather than deploying
an individual model for each workload, a general pretrained
predictor model is leveraged, and anomalies are identiﬁed by
statistically comparing the REDs.

The second question we investigate is: How to select
appropriate behavior markers to detect anomalous behavior
in the cloud in real-time? Quick detection of anomalies and
attacks can prevent further damage. To support real-time
anomaly detection in the cloud, we need an approach to select
appropriate behavior markers that can be measured at high
frequency and can reliably represent the system’s behavior. To
this end, we propose a principal component analysis (PCA)-
based behavior marker selection method, and leverage the
hardware performance counters, which are originally designed
to monitor system performance and can be measured at high
frequency, as exemplary markers to support real-time protec-
tion.

The third question we explore is: How to deal with false-
alarm fatigue? In practice, the “benign anomalous” behavior of
a cloud system is quite common. For example, a cloud server
used for database applications may be scheduled a different
task when its workload is low. The missing piece in the past
anomaly detection is the ability to correctly recognize the new

 
 
 
 
 
 
tasks as benign. Otherwise, a large number of false alarms
are raised, causing the system to be no longer usable. In this
work, we reﬁne each detected anomaly with the identiﬁcation
of benign anomalies and known attacks as a second step. This
can signiﬁcantly alleviate the false alarm problem in anomaly
detection.

Section II describes the background. Section III presents
the threat model. Section IV discusses key challenges for
anomaly detection in cloud computing. Section V describes
our CloudShield methodology and Section VI evaluates our
design.

II. BACKGROUND

A. Attacks in Cloud Computing

There have been many attacks on cloud computing. We fo-
cus on the rapidly growing and representative class of software
attacks on shared hardware resources in cloud servers. Two
main types are speculative execution attacks and cache-based
side-channel attacks, which we use as example attacks in the
evaluation of our anomaly detection system. We also include
software attacks, e.g., buffer overﬂow, in our evaluation. Our
system is not tailored at all to defeat these attacks, and the
goal of our system is to detect even zero-day attacks, which
are attacks that have never been seen before.

1) Speculative Execution Attacks: Since their ﬁrst appear-
ance in January 2018, speculative execution attacks [42],
[44], [4], [41], [5], [43], [61] have bombarded the world,
with new variants continuously popping up. These attacks
can leak the entire memory and break the software isolation
provided by different virtual machines in the cloud, different
virtual address spaces, and even by secure enclaves provided
by SGX [61], [15]. Speculative attacks misuse the hardware
performance optimization features in modern processors, e.g.,
Out-of-Order (OoO) execution, speculative execution, hard-
ware prediction, and caching. These attacks allow transient
instructions to execute, illegally access a secret, and change
the microarchitectural state based on the secret [28]. When the
transient instructions abort, architectural changes are discarded
but the microarchitectural changes, e.g., cache state changes,
remain. This leaves an opportunity for obtaining the secret by
monitoring the microarchitectural state.

2) Cache Side-channel Attacks: Cache-based side-channel
attacks are timing attacks that have traditionally been used to
leak the secret key of symmetric-key ciphers or the private key
of public-key ciphers, thus nullifying any security provided by
such cryptographic protections [29]. They can be classiﬁed
based on cache “hit” or “miss”, “access” or “operation”. The
access-based attacks leverage the difference in timing between
a hit and a miss to indicate a “1” or “0” based on single
memory access, while the operation-based attacks leverage the
time difference for a whole encryption operation. These attacks
target different levels of the cache hierarchy, e.g., L1 cache and
last-level cache (LLC).

Two representative cache side-channel attacks are the ﬂush-
reload attack and prime-probe attack. In the ﬂush-reload attack,
the initial state of a shared cacheline is set to absent by a clﬂush
instruction. After waiting for a while for the victim to execute,
if the victim did use the cacheline, the attacker will ﬁnd the

cacheline present (indicated by a fast cache hit). A variant of
the ﬂush-reload attack, i.e., the ﬂush-ﬂush attack [24], exploits
the early abort if the cacheline to be ﬂushed is not in the cache.

In the prime-probe attack, the attacker ﬁrst loads his data
to ﬁll the cache. After waiting for the victim to execute, the
attacker checks (probe) if his cache lines are now absent, i.e.,
a slow cache miss, because the victim has brought in his data
that evicted the attacker’s cache lines.

3) Buffer Overﬂow Attacks: A buffer overﬂow attack [58]
occurs when the written data exceeds the size of an allocated
buffer. Buffer overﬂow attacks can be exploited by an attacker
to insert code and data. A buffer overﬂow attack is usually
triggered by malformed input
to write executable code or
malicious data to a destination that exceeds the size of the
buffer. If the malicious code or wrong data is used in the
program, erratic program behavior would occur, e.g., system
crash, incorrect results, or incorrect privilege escalation.

B. Hardware Performance Counters

Hardware performance counters (HPCs) are special regis-
ters that record hardware events. HPCs are widely available
in commodity processors, including Intel, ARM, AMD, and
PowerPC. Processors have been equipped with a Performance
Monitor Unit (PMU) to manage the recording of hardware
events. HPCs measure hardware events like the number of
cache references, the number of instructions executed, and the
number of branch mis-predictions; they also measure system
events, like the number of page faults and the number of
context switches.

Although the HPCs were designed for system performance
monitoring and software debugging, previous work have also
shown the feasibility of using hardware performance coun-
ters in security, e.g., detecting malware [51], [19], ﬁrmware-
modiﬁcation [60] and kernel root-kits [59]. Zhou et al.[67] and
Das et al.[18] cautioned using HPCs for security. Unlike these
existing work, CloudShield leverages the reconstruction error
distribution of HPCs, rather than directly using the noisy HPCs
for anomaly detection. [51], [64] and [53] exploited hardware
performance counters and supervised neural networks for mal-
ware and intrusion detection, respectively. A major drawback
of using supervised deep learning for attack detection is that
they require attack examples for training. Thus the zero-day
attacks which are not seen in the training set can not be
detected at runtime.

III. THREAT MODEL

The target system is a cloud-based Infrastructure-as-a-
Service (IaaS) system, where programs share hardware re-
sources. The programs running on the IaaS platform may
interfere with each other. As is commonly done, important and
frequently used cloud services are scheduled one main task per
machine, or per processor core, e.g., machine learning training,
database query, MapReduce, or being used as a web or stream
server. New tasks can be scheduled on the same core if the
workload of the main task is low.

Our threat model covers attacks that breach the conﬁden-
tiality and integrity of the cloud computing system. Notably,
the side-channel attacks and the recently proposed speculative

2

execution attacks are considered in this threat model. We
assume the attacker can launch attack programs in the cloud.
We assume that an attack program can hide by switching
between running and sleeping.

Our threat model particularly includes zero-day attacks.
Unlike signature-based attack detection, we do not make
particular assumptions about the attacks. We assume that there
is no prior knowledge of attack code and the way the adversary
interferes with the system.

Furthermore, once an anomaly is detected, we explicitly
consider reducing false alarms caused by other benign pro-
grams that concurrently run. These benign programs need to
be distinguished from attacks, otherwise, they can cause a
large number of false alarms. Consequently, cyber analysts
can be overwhelmed by false alarms and miss real attacks,
making the detection system ineffective in practice. Therefore,
discriminating benign programs, known attacks, and zero-day
attacks is an important component in this work.

From the system design perspective,

the rapidity and
generalizability of the detection system are important. First,
real-time anomaly detection is crucial, because an attack,
e.g., the side-channel attacks and the speculative execution
attacks, can quickly achieve their goal of leaking secrets in less
than a minute. Quick detection and mitigation of the attacks
prevent more damage to the system. We assume the hardware
performance counters (HPCs) can be measured in the system.
This assumption is reasonable because most of the modern pro-
cessors used in cloud computing servers have been equipped
with HPCs, and the mainstream operating systems support
collecting HPC measurements. Second, generalizability plays
an essential role in our design. We would like as few models
as possible, ideally, a single model, to cover various cloud
scenarios and workloads with minimum changes. This reduces
the cost of switching models between workload changes.

IV. CLOUDSHIELD CHALLENGES

We ﬁrst identify three challenges of anomaly detection in

the cloud, and how they can be handled:

1)
2)
3)

How to model the different cloud workloads?
How to select appropriate behavior markers?
Anomaly detection can cause false-alarm fatigue.
How to deal with the false alarms of anomaly de-
tection in the cloud?

A. How to Model Different Cloud Workloads?

Our intuition of modeling cloud workloads, which may
vary a lot in their functionalities, scales, and required re-
sources, is that the behavior of a cloud server running a
common cloud workload can be decomposed into two parts:
a major predictable component and a minor unpredictable
component. The predictable component can be predicted by
a pre-trained model. The unpredictable component follows
an unknown but ﬁxed distribution. We will validate this
hypothesis in Section VI.

With this assumption, rather than an individual model for
each workload, we can pre-train a general program behavior
predictor model M for the predictable component, and subtract
the prediction from the observed measurement of the system.

The distribution of the remaining unpredictable component,
i.e., the reconstruction error distribution (RED), can reveal the
normal behavior from abnormal behavior. We leverage RED
as the key to anomaly detection. Stealthy attacks can be subtle
and hide within normal measurements. However, subtracting
the major predictable component of the measurements from the
total observed measurements ampliﬁes the anomalous behavior
and provides a robust way of detecting sneaky anomalies.

We present a running example to illustrate this idea in
Figure 1. Two sine curves plus subtle perturbations are shown
in the top row, marked green and yellow, respectively. By
looking at only these two raw measurements, one may not be
able to tell the difference. We then subtract the predictable
signal (the blue sine curves in the second row) to get the
remaining part in the third row and examine the distribution
of this remaining unpredictable part (bottom row). It shows
that the probability distribution of the remaining part, which
we denote the reconstruction error distribution (RED) from a
prediction model, ampliﬁes the difference.

Fig. 1: A running example of the reconstruction error distri-
bution. Our intuition is that the behavior of a system can be
decomposed into two parts: a major predictable component
and a minor unpredictable component. If we can separate
the predictable from the unpredictable component using a
prediction model, the difference between normal and anomaly
is more clearly revealed.

B. How to Select Appropriate Behavior Markers?

Modern processors usually provide counts of various events
that can be used as behavior markers. Monitoring all of them
is inefﬁcient, if not impossible. Therefore, we need a method
to choose the appropriate behavior markers from all possible
markers that can represent the normal behavior of a system.

Our key idea for selecting behavior markers is to quantify
the relative importance of the selected events representing the
normal behavior of a system. Given the set of all possible
behavior markers b1, b2...bn, we can deﬁne a metric f
to
evaluate the relative contribution of a marker in representing
the normal behavior of the system. Then, the behavior markers
are sorted in descending order according to f (b). The markers

3

=++=Raw measurementUnpredicted componentPredictable componentReconstruction error distributionthat exceed a certain threshold of importance are selected as
candidate markers. In our implementation, we deﬁne f based
on principal component analysis (PCA). Other metrics can also
be leveraged to automatically select behavior markers.

C. How to Distinguish Benign Anomalies and Malicious At-
tacks?

The ultimate goal of CloudShield is to detect attacks, i.e.,
malicious anomalies. Once an anomaly is detected, the next
step is to determine if it is a benign anomaly or a malicious
attack. Without loss of generality, we simplify the discussion
by making the assumption that a processor core runs one cloud
workload, e.g., a stream server or a web server. A malicious
anomaly can be a known attack or a zero-day attack. A benign
anomaly can be benign programs that run concurrently with
the cloud workload, where their interference could potentially
cause false alarms. It could also be a stealthy attack that looks
like a benign program. Note that the key difference between
a cloud workload and a benign program is that the cloud
workload, as is commonly done, is the one main task per
cloud server, or per processor core, while benign programs are
relatively small programs that can be scheduled on the same
core if the workload of the main task (cloud workload) is low.

While anomaly detection systems typically fall short of
detecting benign versus malicious anomalies, Cloudshield can
detect not just anomalies, but also the subset of anomalies
that are attacks. Speciﬁcally, CloudShield builds two detectors,
one is to identify known benign programs, and the other is
to identify attacks. Also, while actual attack detection tends
to be very domain-speciﬁc, our new contribution is to show
that it is possible to use a general framework based on a pre-
trained model to do attack detection. We are even able to detect
stealthy attacks and potential zero-day attacks.

V. CLOUDSHIELD

A. Overview

We show an overview of CloudShield in Figure 2. There are
three phases for learning and detecting anomalies and attacks
in the cloud: 1) ofﬂine training and proﬁling, 2) online anomaly
detection and mitigation and 3) online attack versus benign
program detection.

The ofﬂine training and proﬁling phase consists of four

steps:

(cid:172) constructing three sets of programs: normal cloud
workloads, known attacks, and certiﬁed benign programs.
A Certiﬁcate Validation Module is responsible for verifying
the certiﬁcates of the workload and benign programs. The
certiﬁcates are generated by trusted entities, e.g., companies
that create these programs, and organizations or labs that verify
the correctness and security of the programs. The certiﬁcate
must contain the hash of the program binary and the public
key signature of the trusted entity.

(cid:173) Executing the workloads and programs in an ofﬂine
clean environment and collecting their behavior markers. A
Program Behavior Collection Module is designed for this.

(cid:174) Training a default program-behavior predictor model M

in a Training Module.

(cid:175) Calculating the corresponding REDs RDn, RDa, and RDb
as the reference Reconstruction Error Distributions (REDs) for
normal cloud workloads, known attacks, and benign programs,
respectively. We use the distribution RDn as the normal behav-
ior of the processor core running a cloud workload, while RDa
and RDb are used to further distinguish between known attacks
and benign programs when an anomaly is identiﬁed. Note that
the cloud workload needs to be paused before collecting HPCs
and calculating REDs for attacks and benign programs. The
normal cloud workload detector, known attack detector, and
benign program detector are also computed at this time.

The online anomaly detection and mitigation phase has two

steps:

(cid:176) An Online Detection Module collects runtime behavior
markers of each processor core in a cloud server from the Per-
formance Monitor Unit (PMU) in the host OS. These markers
are input into the pre-trained model M for the inference phase,
to generate the run-time observed RED D1.

(cid:177) Comparing the run-time RED D1 and the reference RED
RDn. If D1 does not follow the distribution of normal cloud
workloads RDn, an anomaly is detected and the cloud workload
is paused to avoid further security breaches.

Once an anomaly is detected, the online attack versus
benign program detection phase (step2 detection) is performed
to distinguish benign programs from known attacks. This phase
has three steps:

(cid:178) Collecting behavior markers when the cloud workload
is no longer running. This step is necessary to eliminate the
interference from the cloud workload, which is usually heavy,
and increase the detection accuracy. The new measurements
are inferred through the pre-trained model M and new RED
D2 is gathered.

(cid:179) Comparing D2 to the distribution of known attacks RDa

to identify if the anomaly is caused by a known attack.

(cid:180) Comparing D2 to the distribution of certiﬁed benign
programs RDb to identify if the anomalous behavior is a false
alarm. Note that the steps (cid:179) and (cid:180) can be performed in par-
allel. As a complementary component, the cloud provider can
conﬁrm that benign programs are scheduled on this machine.

In the above discussion, we have assumed that a single pre-
trained model of normal cloud workloads is sufﬁcient, and
that different known attacks can be detected with a single
known attack detector, and that all benign programs added
to a cloud workload can be identiﬁed with a single benign
program detector. This signiﬁcantly simpliﬁes the implemen-
tation of CloudShield, and we will show that this results in
excellent anomaly and attack detection in practice. More cloud
workloads, attacks, and benign programs can always be added
to the three sets of programs to retrain the model M and the
three detectors.

The CloudShield implementation consists of four modules:
a certiﬁcate validation module, a program behavior collection
module, a training module, and an online detection module.
The servers can share a set of the ﬁrst three modules, as they
are used during training phase. Only the last module needs to
run on each cloud server.

4

Fig. 2: CloudShield methodology for anomaly and attack detection.

B. Pre-training Program Behavior Predictor

Feature selection. Modern processors usually provide various
events to be monitored by using hardware performance coun-
ters. However, due to the limited number of hardware registers
in the PMU, only a few of them can be monitored at the same
time. While round-robin scheduling of HPC measurements
is feasible, it increases overhead. Therefore, it is important
to select the appropriate events from all possible events as
behavior markers. We propose a principal component analysis
(PCA) based selection method to help determine the events
to monitor. Our key idea is the selected events should be
important to represent normal behavior.

Speciﬁcally, the principle component PCA1 can be repre-
sented as a linear combination of all features. The coefﬁcient
of the corresponding HPC measurement represents the contri-
bution of that feature in the principal component. Formally,
PCA1 = ||xT w||2
|wi|2x2
= ∑
i
i
where x = (x1, x2...xn) is an HPC reading of n events. |wi| is the
coefﬁcient of xi in the ﬁrst principal component. It represents
the importance of event xi in the ﬁrst principal component.

(2)

(1)

We collect 34 HPC events (Table XII in Appendix) from
ﬁve representative cloud benchmarks, i.e., ML training (Py-
Torch), stream server (FFserver), database server (Mysql), web
server (Nginx), and Hadoop MapReduce. We collect the event
measurements for an entire processor core, to provide system-
level monitoring, rather than just monitor a speciﬁc process or
thread. We observe that although the benchmarks are different,
they show consistency in the events’ importance.

We use ηi = |wi|

∑ j |w j| as the importance of the corresponding
event for a workload. We average η over the ﬁve representative

5

benchmarks as the ﬁnal importance score η of the correspond-
ing event. We show the features with η ≥ 1% in Table I. We
use the thirteen selected events throughout the experiments. In
fact, these are also the thirteen distinct events in the top-10
events for the ﬁve cloud workloads XII.

TABLE I: HPC features with η ≥ 1%.

Rank
1
2
3
4
5
6
7

Event
Instruction
Stall during issue
Stall during retirement
Cycles
Load
DTLB read
Store

η
0.267
0.189
0.178
0.106
0.067
0.043
0.037

Rank
8
9
10
11
12
13

Event
BPU read
DTLB write
Branch
L1D read miss
L1I read miss
Context switch

η
0.030
0.025
0.023
0.020
0.018
0.015

Model selection. Recurrent Neural Network (RNN) and its
variant, Long Short-Term Memory (LSTM), have become
the popular model for sequential data. To balance the model
complexity and its prediction power, in the proof-of-concept
implementation, we start from a single-cell LSTM as the
behavioral model of the system. An LSTM cell has three gates
that control information ﬂow: the forget gate, the input gate,
and the output gate. LSTM automatically determines what
information to “remember” and “forget”.

Alternative models, e.g., Gated Recurrent Units (GRUs)
[17] and BERT [20], can also be used as behavioral models
of the system. As the main focus of this work is not to ﬁnd
the best model, but to show the feasibility of using RED of
HPCs to detect anomalies in the cloud system, without loss
of generality, we just show that LSTM models are enough for
this anomaly detection.

Model training. Our goal is to train a model that can capture
the predictable component of the behavior of a program. The
program behavior markers {Si}N
i=1 (in our case HPC events

SpectreMeltdownSide-channelBufferOverflow…KnownAttacksGPGGCCTextBzip…CertifiedBenignPrograms…Cloud WorkloadsMapReduceStream ServerML TrainingWeb ServerCertificateValidation(cid:1)Cloud WorkloadsAttacksBenign ProgramsCloud Workload RED RDnBenignProgramRED RDbKnownAttackRED RDaNormal Cloud Workload DetectorKnown Attack DetectorBenign ProgramDetectorPre-trained ModelM(cid:4)-a(cid:4)-b(cid:4)-c(cid:3)Behavior MarkersBehavior MarkersBehavior MarkersKnown AttackAlarm(cid:6)Pre-trained ModelMRun-time Observed RED D1Normal Cloud Workload Detector NormalWorkloadAbnormalRun-time Observed RED D2Known Attack DetectorBenign ProgramDetectorBenign ProgramPotential Zero-day Attack(cid:5)(cid:7)(cid:8)(cid:9)StealthyAttackBehavior MarkersBehavior MarkersTraining and ProfilingPhaseOnline DetectionAnomaly DetectionAttack Detection(cid:2)YNYNPause Cloud WorkloadPauseCloud WorkloadRDnRDaRDbof cloud workloads), are obtained from a clean environment.
N is the total number of time frames collecting HPCs. In
our experiments, each behavior measurement St
is a vector
i
consisting of the thirteen monitored hardware events. At time
t, the deep learning model is trained to predict St+1
using
behavior history [S1
i=1 are nor-
mal behavior markers collected in the clean environment, the
loss penalizes the incorrect prediction of normal behavior. We
train this model to minimize the loss function with Stochastic
Gradient Descent (SGD).

i]. Intuitively, since {Si}N

i , ..., St

i

C. RED Proﬁling

RED generation of cloud workloads. We generate a proﬁle
of the normal cloud workloads in terms of reconstruction error
distribution (RED), illustrated as RDn in Figure 2. First, refer-
ence sequences of the behavior measurement, R = [R1, ..., RT (cid:48)
],
are collected in a clean environment. For this cloud server
setting, each time frame Ri is a vector of thirteen dimensions
(the number of monitored events) in our experiment. Second,
at time frame t, we use the trained model to predict time frame
t + 1 using the corresponding history behavior. We denote the
prediction as Pt+1. The reconstruction error is deﬁned as:

E(t) = Rt+1 − Pt+1

(3)

Each reconstruction error sample E(t) is a vector of dimension
n, where n is the number of monitored events. We gather the
prediction errors of each cloud workload and deﬁne the overall
distribution of {E(1), E(2), E(3)...} from all workloads as RDn.

KDE proﬁling of cloud workload. We use Kernel Density
Estimation (KDE), a non-parametric estimation approach that
better handles high-dimensional data,
to proﬁle the high-
dimensional distribution of reconstruction errors from ref-
erence samples, denoted (cid:175)-a in Figure 2. We use non-
parametric estimation because the formula of the RED of
normal workloads is unknown, and its formula can be too
complex to assume. KDE represents the distribution from
elementary kernels. It assumes a small high probability area
(Gaussian in our implementation) within a bandwidth around
the observed samples, and sums them up as the probability
distribution. Formally, KDE is deﬁned as:

K(

1
nb

ˆf (x) =

x − xi
b

n
∑
i=1
where ˆf (x) is the estimated probability density. K(·) is a
kernel function, whose value drops rapidly outside a bandwidth
b. xis are the samples from the distribution, i.e., E(t) in our
case. n is the total number of samples.

(4)

)

In Figure 3, we show examples of reconstruction error
distribution (RED) of normal cloud workloads (ﬁrst ﬁve in
green), benign programs (next six in blue), and attacks (last
nine in red). To illustrate the high-dimensional distribution,
we calculate the magnitude of REDs in Eq. 3 and observe
that the normal cloud workloads, in general, have the smallest
REDs (distributions to the left). Figure 3 shows clear difference
between the cloud workloads, the benign programs, and the at-
tacks. The cloud workloads have the smallest REDs (leftmost).
The REDs of different benign programs are distinct, showing
that RED can be used to distinguish benign programs. Most of
the benign programs have larger REDs than cloud workloads,

6

except the gpg-rsa program whose RED is similar to the cloud
workloads. Moreover, the REDs of all evaluated attacks are to
the right side, meaning larger reconstruction errors than cloud
workloads and benign programs. We observe that one spectre
attack (spectre v3) induces signiﬁcantly larger RED than the
other workloads, benign programs, and attacks. This shows
that the spectre v3 attack’s behavior is unique compared to
the other attacks.

Fig. 3: Reconstruction error distribution (RED) of normal
cloud workloads (ﬁrst ﬁve in green), benign programs (next six
in blue) and attacks (last nine in red). RED of all attacks are
different from the normal behavior of the cloud workload. The
x-axis is the magnitude of RED, and y-axis is the probability
density of that RED magnitude.

Proﬁling for benign programs and known attacks. Simi-
larly, we proﬁle the RED of the benign programs and known
attacks. We collect their behavior data in a clean execution
environment from the Program Behavior Collection Module.
Interestingly, we observe that
is not necessary to train
another program behavior predictor model for benign programs
and attacks. The pre-trained one on cloud workloads can be
reused to proﬁle the benign programs and known attacks.
We hypothesize that it is because pre-training on different
workloads improves the generalizability of the model, by
suppressing potential overﬁtting. At last, two KDE estimations
are performed on the RED of known attacks and benign
programs, shown as (cid:175)-b and (cid:175)-c in Figure 2, respectively.

it

We illustrate an example of kernel density estimation of
benign programs in Figure 4. To illustrate, we ﬁrst use t-SNE
[35] to map the thirteen HPCs to a 2-D plane and build a KDE
estimator of benign programs (gcc, gpg, and libquantum) using
the REDs from the pre-trained model. The high-density regions
(likely to be benign programs) are colored red while the low-
density areas (unlikely to be benign programs) are colored
blue. We plot three benign programs, i.e., gcc (green square),
gpg (green diamond) and libquantum (green triangle) in Figure

 !4. We also depict four attacks, i.e., l3pp (red cross), fr (red
square), spectre v1 (red diamond), and buffer overﬂow (red
triangle), in Figure 4 and observe that they are all in the low-
density area, where the benign program detector can identify
them as non-benign programs. Figure 4 explains why KDE
works, speciﬁcally the benign programs form high-density
clusters while the attacks are outside the clusters.

Fig. 4: Illustration of kernel density estimation of benign pro-
grams. The high-density regions (likely to be benign programs)
are colored red while the low-density areas (unlikely to be
benign programs) are marked blue. We observe that benign
programs (gcc, gpg, libquantum) are in the high-density area
and attacks (l3pp, fr, spectre v1, and buffer overﬂow) are in
the low-density areas.

D. Runtime Anomaly Detection and Mitigation

The online detection module is responsible for detecting
anomalies and distinguishing attacks and benign programs at
runtime. A processor core’s behavior, in terms of hardware
event measurements, is dynamically monitored at runtime.

Anomaly detection based on RED. Similar to the ofﬂine
proﬁling phase, the runtime gathered HPC sequences are sent
through the pre-trained model ((cid:176) in Figure 2) to obtain the
runtime observed RED D1. The likelihood of the observed
reconstruction error following the RED of normal cloud work-
loads (RDn) is computed using the KDE normal workload
detector ( ˆf (x) in Eq. 4) 1. If the likelihood ˆf (x) is lower than a
pre-deﬁned threshold, i.e., the prediction error does not follow
the distribution of RDn, an anomaly is detected.

Based on the results of the anomaly detection, different
response actions can be taken. If no anomaly is detected, no
further actions are required. Once an anomaly is detected,
CloudShield triggers different responses ((cid:177) in Figure 2). First,
the cloud workload running on the machine is temporarily
paused to avoid further damage. This also eliminates the
interference between the cloud workload and other tasks that
concurrently run (attacks or benign programs). Second, access
to the most security-critical data and resources is temporarily
turned off. Attacks against data conﬁdentiality, e.g., side-
channels, can target these secret data. Thus, cutting access to
the security-critical data prevents these data from being leaked
out. Third, the known attack detector and benign program

detector are woken up, to identify if the anomaly is malicious
(an attack) or benign (a false alarm). This can further reduce
false-alarm fatigue in practice, as discussed below.

E. Distinguishing Benign Programs and Attacks

A detected anomaly can be caused by benign programs.
Thus, CloudShield attempts to distinguish “benign anomalies”
caused by benign programs versus real attacks. As discussed in
Section V-D, the cloud workload is paused once an anomaly is
detected ((cid:177) in Figure 2). Now the monitored core is possibly
running attacks. Moreover, other benign programs (can be a
victim program) that concurrently run with the attack may hide
the attack and make identifying attacks even harder. We will
show CloudShield can detect an attack in both scenarios, with
and without benign programs running.

Attacks and benign programs identiﬁcation. To distinguish
the attacks and benign programs, ﬁrstly, hardware events’
measurements are monitored through the PMU after the main
cloud workload is switched off. Then the PMU sends the newly
measured data (without cloud workload) to the same pre-
trained program behavior predictor M for inference. Similar
to anomaly detection, we compute the RED D2 in the form
of Eq. 3. The KDE attack detector ((cid:175)-b) and the KDE
benign program detector ((cid:175)-c) were loaded into the online
detection module from the training module 2. The attack
detector computes the likelihood of the observed prediction
errors following the RED of known attacks (RDa), using Eq.
4. If a high likelihood is observed, the attack detector reports
an attack. Similarly, the benign program detector computes the
likelihood of the observed prediction error following the RED
of benign programs (RDb). If a high likelihood is observed,
the benign program detector reports a benign program.

Based on the decisions of the two detectors, we list the

four possible ﬁnal decisions in Table II.

TABLE II: Benign program and attack decisions and re-
sponses.

Known Attack
Detector
Y
Y
N
N

Benign Program
Detector
Y
N
Y
N

Case 1
Case 2
Case 3
Case 4

Decision

Response

Stealthy attack
Attack
Benign program
Zero-day attack or new benign programs

Alarm (high priority)
Alarm (high priority)
Resume cloud workload
Alarm (medium priority)

Case 1: The attack detector recognizes it as a known attack,
and the benign program detector recognizes it as a benign
program. In this case, CloudShield reports it as a stealthy attack
where the attack program hides by mimicking the behavior of
a benign program. Another possible scenario of this case is
that a benign program, which could be a victim program, is
concurrently running with the attack program. We will show
in the experiments that attacks can still be detected even when
they run together with benign programs. A high-priority alarm
is raised and a detailed report is sent for inspection.

Case 2: The attack detector recognizes it as an attack, and
the benign program detector does not report it as a benign

1Tree-based structures, e.g., KD tree, can be used to ﬁnd the xis close to x
and accelerate the computation because the effect of xis outside the bandwidth
b is negligible.

2Note that here we only need two KDE estimators, one for attacks and the
other for benign programs, rather than an individual detector for each attack
or benign program.

7

program. This case indicates clear attacks and a high-priority
alarm is raised and a detailed report is sent for inspection.

VI. EVALUATION

A. Experimental Settings

Case 3: The attack detector does not report it as an attack, and
the benign program detector recognizes it as a benign program.
In this case, the previously detected anomaly is caused by a
benign program. The cloud workload is resumed to execute
and no alarm is raised.

Case 4: The attack detector does not report it as a known
attack, and the benign program detector does not report it as
a benign program. In this case, a potential zero-day attack or
an unknown benign program is possible. A medium-priority
alarm is raised by CloudShield. The cyber analysts can handle
these alarms after the high-priority alarms. In fact, in our
experiments, we show that case 4 is very unlikely.

Response. Once an anomaly is detected (step 1), CloudShield
has already paused the normal cloud workload to shield
it from the attacks. Access to highly sensitive data, code,
and resources can also be denied, depending on the server’s
security response policy. If in the second step, an attack is
detected, an alarm will be raised. Further responses can be
taken to protect the system, and the code and data on it.
CloudShield can also stop all processes running on the core.
Meanwhile, CloudShield records the relative information into
logs for further investigation.

F. System Update

We discuss possible system updates of CloudShield.
Speciﬁcally, CloudShield can update itself if new types of
cloud workloads are added, new attacks are discovered or
new benign programs are certiﬁed. A new model has to be
trained only if new cloud workloads are added. For new attacks
and benign programs, only the KDE detectors for attacks and
benign programs need to be updated.

New types of cloud workloads. The commonly used cloud
workloads in practice share common characteristics [40], [49],
thus this re-training process only needs to be performed when
a new type of cloud workload is added. This kind of update
is not frequent. Moreover, the whole update procedure can
be performed during low usage time. CloudShield loads the
updated models and detectors to the processor cores.

New certiﬁed benign programs. Update of new certiﬁed
benign programs is relatively lightweight, compared to cloud
workload update, because the pre-trained model does not need
to change. CloudShield then executes the new benign program,
collects its behavior measurements in a clean execution envi-
ronment, and calculate the REDs. As shown in the formula
of KDE estimator (Eq. 4), the estimated likelihood ˆf (x) is
summed over all reference prediction errors xi. Therefore,
CloudShield only needs to append the new prediction errors
of the new certiﬁed program to the existing prediction errors
to form the new RED.

New discovered attacks. This follows the same procedure of
updating certiﬁed benign programs. It is also lightweight as
the pretrained model does not need to be updated.

Platform. We perform our evaluation of CloudShield on a
server equipped with 2 Intel Xeon E5-2667 CPUs, each with 6
physical processor cores. Each core has a 32KB L1D (Level-1
Data) cache and a 32KB L1I (Level-1 Instruction) cache. Each
package of six cores shares a 256KB L2 (Level-2) cache and
a distributed last-level cache of 15MB (2.5MB*6). The server
has 64GB memory and a 2TB hard disk. The machine is also
equipped with an Nvidia 1080Ti GPU. The HPC values are
collected every 10 milliseconds using Perf [8] supplied by the
Ubuntu 14.04.6.

Cloud workload benchmarks. We choose ﬁve representative
cloud benchmarks, as shown in Table III.

TABLE III: Cloud workload benchmarks.

Cloud workload

Web server (Nginx)

Database server (Mysql)

Stream server (FFserver)

ML training (Pytorch)
Hadoop

Description
Serving 1000 remote connections to request webpages
using WRK benchmark [6]
Performing 128 concurrent queries using SysBench [7]
Streaming a MPEG video in real-time to a remote user
with FFserver and FFmpeg
Training an LSTM model using an Nvidia 1080Ti GPU
Perform Terasort [9] using MapReduce

Evaluated attacks. We select nine representative runtime
attacks against cloud computing systems for evaluation (Table
IV). The evaluated attacks are cache side-channel attacks,
speculative execution attacks, and buffer overﬂow attacks. The
cache side-channel attacks silently leak information. The four
recently discovered speculative execution attacks represent the
main hardware resources exploited by the different speculative
attack variants. We also evaluate a representative software
attack, i.e., buffer overﬂow attack.

TABLE IV: Three catagories of nine attacks are evaluated:
cache side-channel attacks, speculative execution attacks and
buffer overﬂow attack.

Catagory

Cache side-
channel attacks

Speculative
execution attacks

Buffer overﬂow

Attack

L1 cache prime-probe attack (l1pp) [26]
L3 cache prime-probe attack (l3pp) [45]
Flush-reload (fr) [63]
Flush-ﬂush (ff) [24]
Speculative boundary bypass (spectre v1) [42]
Indirect branch mis-prediction (spectre v2) [42]
Meltdown (spectre v3) [44]
Speculative store bypass (spectre v4) [5]
Stack overﬂow attack [58]

Benign programs. We choose representative benign programs
from the SPEC2006 benchmark suite [34]. The evaluated
benign programs cover a large scope of programs: crypto
software (gpg-rsa), compiler (gcc), ﬁle and video compression
tools (bzip2, h264ref), scientiﬁc computation (mcf, milc, namd,
libquantum), statistics, and machine learning (soplex, hmmer)
and gaming (gobmk).

Data collection. Data were collected in different scenarios.
To evaluate the ﬁrst step, i.e., for detection, we collected data
when (cid:172) only the cloud workload is running; (cid:173) the cloud
workload is running with benign programs listed above; (cid:174) the
cloud workload is running with the attacks listed above; and

8

(cid:175) the cloud workload is running with both benign programs
and attacks. To evaluate the second step, i.e., for detection of
attacks and benign programs, which we do when the cloud
workload is not running, we collected data when (cid:172) only an
attack is running; (cid:173) only a benign program is running; and (cid:174)
an attack is running together with a benign program. Due to
the large number of combinations of cloud workloads, attacks
and benign programs, we run each combination for six minutes
on a server, and split the data equally into training, validation
and testing sets.

B. Metrics

We ﬁrst compute an anomaly score for each behavior
measurement and then use a threshold to determine False
Positive Rate (FPR) and False Negative Rate (FNR).

Anomaly score. An anomaly score is −log( ˆf (x)), where ˆf (x)
is the KDE density in Eq. 4. Low density f (x) indicates a
high anomaly score. During inference, an anomaly score is
computed for each behavior measurement, and the score is
compared to a threshold to make a binary decision whether it is
normal or abnormal (for the normal cloud workload detector),
or whether it is a benign program (for the benign program
detector), or whether it is an attack (for the attack detector).

Threshold. The threshold calculation for the cloud workload
detector is different from the attack and benign program detec-
tors. The threshold of the cloud workload detector is obtained
such that 80% of the validation normal measurements during
the training phase are correctly classiﬁed as normal (no attack
data are used to construct the normal cloud workload detector
and to determine the threshold). For the benign program
detector and attack detector, the threshold is obtained such
that the FPR (False Positive Rate) and FNR (False Negative
Rate) are equal, i.e., the equal error rate is achieved, on the
validation set.

False Positive Rate (FPR) and False Negative Rate (FNR).
We also report the standard FPR and FNR as metrics. Based on
the anomaly scores and thresholds, the cloud workload detector
makes binary decisions (normal or abnormal). Similarly, the
benign program detector and known attack detector determine
if a benign program or a known attack is running. We report the
FPR when the cloud workload or benign programs are running,
and the FNR if an attack is running (with and without cloud
workloads or benign programs).

C. Anomaly+Attack Evaluation

As CloudShield ﬁrst detects anomalies (step 1) and then
identiﬁes attacks and benign programs (step 2), we ﬁrst il-
lustrate the end-to-end (anomaly detection + attack detection)
results in Figure 5 and show the numerical results in Table V.
Separated results and analysis of each step are discussed in
Section VI-D-Section VI-F.

We evaluate different window sizes: if the window size
is w, in step 1, w contiguous anomalous behavior marker
measurements are identiﬁed as an anomaly. Similarly, w con-
tiguous behavior marker measurements are collected before an
attack or benign program can be identiﬁed. For a speciﬁc cloud
workload, we report the average FPR for that cloud workload
+ each benign program. We report the average FNR for that

cloud workload + each attack + each benign program we
evaluated. A higher FPR increases the number of false alarms,
while a higher FNR increases the chance that an attack will go
undetected. Low rates of both are desired. We observe that the
CloudShield indeed has very low FNRs for all 5 workloads
for all window sizes - less than 0.3%, indicating excellent
detection accuracy and hence, excellent security. FPRs are
slightly higher but also less than 0.6%. When w=1, the web-
server workload has the highest FPR (0.51%), while stream
server achieves the lowest FPR (0.26%). For all ﬁve cloud
workloads, the FPR decreases as w becomes larger, however,
the FNR increases accordingly. When w = 100, FPR decreases
to 0.13% (for stream server) and 0.24% (for webserver). FNR
increases to 0.09% and 0.19%. When w = 200, FNR tends to
exceed FPR for all ﬁve cloud workloads. Note that a larger
window size can increase the detection delays (evaluated in
Section VI-G). Because of the low FPR and FNR, a window
size of 5-10 should be sufﬁcient.

Fig. 5: End-to-end (anomaly detection + attack detection)
results for 5 different cloud workloads.

TABLE V: Quantitative end-to-end (anomaly detection + at-
tack detection) evaluation results.

We compare the proposed CloudShield to four repre-
sentative anomaly detection methods in the literature,
i.e.,
Isolation Forrest (IF) [46], One-class SVM (OCSVM) [55],
Local Outlier Factor (LOF) [14], and Principal Component
Analysis (PCA) [36]. We show the end-to-end results in Table
VI. For the existing anomaly detection methods, we replace
the pretrained model + KDE in steps 1 and 2 of CloudShield
with the corresponding method. We average the FPR and FNR
across each combination of cloud workload, benign program,
and attack. We observe that, with w=5 or w=10, CloudShield
achieves lower FPR and FNR compared to other methods.
Speciﬁcally, when w=5, the best FNR and FPR of existing
methods are 1.41% (OCSVM) and 6.95% (PCA), respectively,
while CloudShiled has much lower (better) FPR of 0.34% and
FNR of 0.06%. Similar results are shown when w=10.

9

00.00250.0050.00750.01135102050100200WindowSizeMapReduceFPRFNR00.00250.0050.00750.01135102050100200WindowSizeMLTrainFPRFNR00.00250.0050.00750.01135102050100200WindowSizeMysqlFPRFNR00.00250.0050.00750.01135102050100200WindowSizeStreamServerFPRFNR00.00250.0050.0075135102050100200WindowSizeWebServerFPRFNRML training(Pytorch)Database (Mysql)Stream server (FFserver)Webserver (Nginx)MapReduce(Hadoop)wFPRFNRFPRFNRFPRFNRFPRFNRFPRFNR10.0034 0.0005 0.0033 0.0005 0.0026 0.0011 0.0051 0.0005 0.0032 0.0005 30.0034 0.0005 0.0033 0.0005 0.0025 0.0012 0.0050 0.0005 0.0031 0.0005 50.0033 0.0005 0.0032 0.0005 0.0025 0.0012 0.0049 0.0005 0.0031 0.0005 100.0032 0.0005 0.0031 0.0005 0.0024 0.0013 0.0048 0.0005 0.0030 0.0005 200.0030 0.0006 0.0029 0.0006 0.0023 0.0014 0.0045 0.0006 0.0028 0.0006 500.0025 0.0007 0.0024 0.0007 0.0019 0.0017 0.0036 0.0007 0.0023 0.0007 1000.0016 0.0009 0.0016 0.0009 0.0013 0.0019 0.0024 0.0009 0.0015 0.0009 2000.0005 0.0011 0.0005 0.0011 0.0004 0.0025 0.0008 0.0011 0.0005 0.0011 TABLE VI: Compare CloudShield to existing anomaly detec-
tion methods.

w=5

w=10

Isolation Forrest (IF)
One-class SVM (OCSVM)
Local Outlier Factor (LOF)
PCA
CloudShield
Isolation Forrest (IF)
One-class SVM (OCSVM)
Local Outlier Factor (LOF)
PCA
CloudShield

False Positive Rate (FPR)
0.1728
0.0141
0.0518
0.0587
0.0034
0.1539
0.01571
0.0516
0.0519
0.0033

False Negative Rate (FNR)
0.442
0.1011
0.0956
0.0695
0.0006
0.416
0.1031
0.0990
0.1150
0.0007

D. Can CloudShield Detect Anomalous Behavior in Realtime?

A key challenge for real-time anomaly detection is short
or stealthy attacks. Attacks can hide by switching between
running and sleeping. A good anomaly detection system should
be able to capture the attack once it is running. We evaluate
CloudShield against such attacks and show it can detect them
almost immediately. We schedule each of the nine attacks to
run and then sleep for a random period (10s-40s) before the
next attack runs. The experiment is performed when the ML
training workload is running.

We show the attack scheduling and the anomaly scores
output (−log( ˆf (x)) in Eq. 4) by CloudShield in Figure 6.
is clear that once an attack is running, possibly after
It
sleeping, CloudShield captures it (indicated by a large anomaly
score). Once the attack program’s behavior is suspended, the
anomaly score quickly goes back to a low value. Therefore, the
proposed CloudShield can detect anomalies in real-time. We
also observe that two last-level cache attacks, i.e., the ﬂush-
ﬂush attack (ff) and the LLC prime-probe attack (l3pp), and
two speculative execution attack variants, i.e., the spectre v2
and the spectre v3, result in higher anomaly scores than the
other attacks, indicating their distinctive behavior.

Fig. 6: Real-time detection of anomalies. We schedule each of
the nine attacks to run for 10 seconds and sleep for a random
period of time (10-40s).

E. Can CloudShield Detect Zero-day Attacks?

We evaluate the anomaly detection (step 1) on the nine
attacks, including the four recently proposed speculative ex-
ecution attacks. Note that
in the anomaly detection step,
CloudShield is only trained on the normal behavior of the
cloud workloads, and has not seen code or data of any of the

10

nine attacks, so they are like zero-day attacks to CloudShield
in this experiment.

We consider the model predictions for the four scenarios:

1)
2)
3)
4)

Normal workload
Normal workload and a benign program running
Normal workload and an attack running
Normal workload, a victim program, and an attack
running

We ﬁrst illustrate a real example of anomaly detection in
Figure 7 with the ML training workload. We run a ﬂush-reload
attack and a victim program, i.e., gpg-rsa. In period (cid:172), the
ﬂush-reload attack is activated. We observe that the anomaly
score quickly increases signiﬁcantly. In period (cid:173), the victim
program gpg-rsa is running and it was not recognized as an
anomaly. In the period (cid:174), the ﬂush-reload attack is executed
and the anomaly score again quickly jumps to a high value.
In period (cid:175), the victim program ends and the anomaly score
remains high as the attack is still running.

Fig. 7: An example of anomaly detection of the ﬂush-reload
attack with the ML training workload.

We show quantitative results of anomaly detection (step 1)
in Table VII. The ﬁrst line of the results is scenario 1 where
only the normal cloud workload is running. The next four lines
show scenario 2, i.e., the normal workload and an additional
benign program are running. The next nine lines present the
results of scenario 3, where an attack is running concurrently
with the normal cloud workload. Finally, representatives of
scenario 4 are shown in the remaining (27) lines of Table VII
where an attack and a victim program are running together.

We ﬁnd that when only the normal workload is running
(scenario 1), CloudShield almost always correctly recognizes
it as normal (the ﬁrst line) for the ML training, database,
stream server, and web server benchmarks with a 0.1%-
0.5% false positive rate (predict abnormal column). When
MapReduce is running, CloudShield misrecognizes 1.7% of
normal workloads as anomalous – still a small level.

When a benign program is running concurrently with the
cloud benchmark (scenario 2), we observe that the results
highly depend on the cloud workload and the benign program.
For example, the GPG-RSA is recognized as normal with
less than 1% false positive rate in the database, web server,
and MapReduce workloads. However, large false positives,
i.e., 6.4% and 47.6% of the GPG-RSA, are observed in the
stream server and ML training workloads, respectively. These

l1ppSpectrev4Spectrev1Flush-flushl3ppBOFSpectrev2Spectrev3Flush-reload0(no attack)1(attack)GPGFlush-reload(cid:1)(cid:2)(cid:3)(cid:4)TABLE VII: Results of anomaly detection (step 1) with
different cloud workloads.

false alarms can cause false alarm fatigue. Thus it requires
the next step to further distinguish benign programs versus
malicious anomalies, and reduce the number of false alarms.
Note that CloudShield distinguishes certiﬁed benign programs
from attacks (step 2) to reduce false alarms after an anomaly
is identiﬁed (results discussed in Section VI-F).

In scenario 3, once an attack is running with the cloud
workload, it can be detected with zero false negatives in the
database, web server, and MapReduce workloads. For the ML
training workload, the Spectre v1 and v2 attacks cause 1.2%
and 0.5% false-negative rates, respectively. For the stream
server workload, the Spectre v1 and v2 attacks introduce 1.6%
and 0.3% false-negative rates, respectively. These results show
that CloudShield is capable of detecting zero-day attacks, since
the normal cloud workload detector in step1 has not been
trained with any attack.

We also evaluate scenario 4 where an attack program runs
concurrently with a benign or victim program and the cloud
workload. Similar to scenario 3, we observe that the attacks
can be detected with zero false negatives with the database,
web server, and MapReduce workloads. For the ML training
workload, the worst case is when spectre v1 and libquantum
are running concurrently, the attack is missed by 3.1%, slightly
higher than scenario 3 where the spectre v1 attack is running
alone (1.2%). For the stream server workload, the highest false-
negative rate is 4.5% when a ﬂush-reload attack is executed
with gpg-rsa. Next is when Spectre v1 and libquantum are
running with the stream server, the FNR is 2.8%. Although
these results from just step 1 for anomaly detection are very
good for not missing attacks (low FNRs), the FPRs in scenario
2 when benign programs cause false alarms seem higher than
we would like to see. Hence, we propose step 2, to detect

benign anomalies from real attacks.

F. Can CloudShield Distinguish Benign Anomalies from At-
tacks?

Anomalies can be caused by benign programs, i.e., benign
anomalies. Therefore, once an anomaly is detected, Cloud-
Shield takes the next step to ﬁgure out whether it is a benign
anomaly or an attack. As shown earlier, CloudShield imple-
ments two detectors to identify known attacks and certiﬁed
benign programs, respectively. These two detectors can reduce
false alarms by 99.0%.

We show a real example of CloudShield reducing false
alarms by distinguishing known attacks and certiﬁed benign
programs in Figure 8. We run an attack (spectre v3) and a
benign program (gcc), both with the ML training workload.
The periods (cid:172) and (cid:174) indicate that the attack is running,
and the period (cid:173) means the benign program is running.
Figure 8 (a) illustrates the anomaly scores in the anomaly
detection step. We observe that while both attacks are correctly
identiﬁed (periods (cid:172) and (cid:174)), the beginning of gcc execution is
incorrectly recognized as attacks (false alarms). Then the ML
training workload is paused and the behavior measurements
are re-collected as input to the two step 2 detectors. Figure 8
(b) shows the result of the attack detector. High values indicate
an attack and low values mean no attack. It correctly identiﬁes
periods (cid:172) and (cid:174) as attacks, while (cid:173) is not an attack. Figure
8 (c) shows the result of the benign program detector. High
values represent a benign program and low values indicate a
program that is not in the set of certiﬁed benign programs. We
ﬁnd that the certiﬁed benign program detector reports high
values in period (cid:173) (and idle periods), while the values in
periods (cid:172) and (cid:174) are low (not certiﬁed benign programs).
Jointly considering the two detectors, CloudShield correctly
determines that (cid:173) is a certiﬁed benign program, while (cid:172) and
(cid:174) are real attacks.

Fig. 8: An example of reducing false alarms by indentifying
attacks and certiﬁed benign programs.

We show quantitative results of attacks and certiﬁed benign
program detection (step 2) in Table VIII. We select eleven
representative benign programs from the SPEC benchmark
suite and the same nine attacks as in previous sections for
evaluation. For the benign program detection, we observe that
six benign programs (gpg-rsa, bzip2, namd, soplex, hmmer,

11

ML training(Pytorch)Database (Mysql)Stream server (FFserver)Webserver (Nginx)MapReduce(Hadoop)Other programs running with cloud workloadPrednormalPredabnormalPrednormalPredabnormalPrednormalPredabnormalPrednormalPredabnormalPrednormalPredabnormalNoneCloud workload only0.9990.0010.9990.0010.9950.0050.9990.0010.9830.017Benignprogramgpg-rsa0.5240.4760.9990.0010.9360.0640.9960.0030.9970.003gcc0.2200.7800.3810.6190.2090.7910.1780.8220.6170.382mcf0.4510.5490.2550.7450.5150.4850.0360.9640.1130.877libquantum0.9990.0010.6010.3990.9220.0780.0910.9090.5990.401Attackl1pp0.01.00.01.00.01.00.01.00.01.0l3pp0.01.00.01.00.01.00.01.00.01.0fr0.01.00.01.00.01.00.01.00.01.0ff0.01.00.01.00.01.00.01.00.01.0spectrev10.0120.9880.01.00.0160.9840.01.00.01.0spectrev20.0050.9950.01.00.0030.9970.01.00.01.0spectrev30.01.00.01.00.01.00.01.00.01.0spectrev40.01.00.01.00.01.00.01.00.01.0buffer overflow0.01.00.01.00.01.00.01.00.01.0Benign program + attackl1pp + gpg-rsa0.01.00.01.00.0040.9960.01.00.01.0l3pp + gpg-rsa0.01.00.01.00.01.00.01.00.01.0fr+ gpg-rsa0.0200.9800.01.00.0450.9550.01.00.01.0ff+ gpg-rsa0.01.00.01.00.01.00.01.00.01.0spectrev1 + gpg-rsa0.01.00.01.00.0050.9950.01.00.01.0spectrev2 + gpg-rsa0.01.00.01.00.01.00.01.00.01.0spectrev3 + gpg-rsa0.01.00.01.00.01.00.01.00.01.0spectrev4 + gpg-rsa0.01.00.01.00.01.00.01.00.01.0bof+gpg-rsa0.01.00.01.00.01.00.01.00.01.0l1pp + gcc0.0010.9990.01.00.0020.9980.01.00.01.0l3pp + gcc0.01.00.01.00.01.00.01.00.01.0fr+ gcc0.01.00.01.00.01.00.01.00.01.0ff+ gcc0.01.00.01.00.01.00.01.00.01.0spectrev1 + gcc0.01.00.01.00.0010.9990.01.00.01.0spectrev2 + gcc0.01.00.01.00.01.00.01.00.01.0spectrev3 + gcc0.01.00.01.00.01.00.01.00.01.0spectrev4 +gcc0.01.00.01.00.01.00.01.00.01.0bof+gcc0.01.00.01.00.01.00.01.00.01.0l1pp + libquantum0.01.00.01.00.01.00.01.00.01.0l3pp + libquantum0.01.00.01.00.01.00.01.00.01.0fr+ libquantum0.01.00.01.00.01.00.01.00.01.0ff+ libquantum0.01.00.01.00.01.00.01.00.01.0spectrev1+libquantum0.0310.9690.01.00.0280.9720.01.00.01.0spectrev2 + libquantum0.01.00.01.00.01.00.01.00.01.0spectrev3 + libquantum0.01.00.01.00.01.00.01.00.01.0spectrev4 +libquantum0.01.00.01.00.01.00.01.00.01.0bof+libquantum0.01.00.01.00.01.00.01.00.01.0CertifiedbenignprogramNo attackGCCMeltdown (Spectre v3)(cid:1)(cid:2)(cid:3)False positives(cid:1)(cid:2)(cid:3)(cid:1)(cid:2)(cid:3)(a) Anomaly detection(step1)(c) Certified benign program detection (step 2b)(b) Attack detection (step 2a)and libquantum) can be recognized correctly with no false
alarms. The milc program introduces the highest but acceptable
FPR of 3.5%. Of this, 2.6% were identiﬁed as stealthy attacks
and 0.9% as zero-day attacks or unknown benign programs.
On average, 99.0% of the benign programs can be identiﬁed
correctly, i.e., the false alarms raised by benign programs in
the anomaly detection is suppressed by 99.0%. Within the
remaining false alarms (1.0%), we observe that 0.6% are
recognized as case 4 (zero-day attacks or unknown benign
programs) which results in a medium-priority alarm, and 0.4%
are recognized as high-priority attacks (case 1 and 2). For
attack detection, we observe that all attacks are correctly
identiﬁed. A detailed analysis shows that 99.8% of attacks are
identiﬁed as high-priority attacks (case 2) and 0.2% attacks
are recognized as stealthy attacks.

TABLE VIII: Results of benign programs/attacks detection
(step 2).

TABLE IX: Results of benign programs/attacks detection (step
2), when attacks and benign programs run concurrently.

We consider a more difﬁcult scenario where an attack is
running concurrently with a certiﬁed benign program. We run
three benign programs: gpg-rsa, gcc, and libquantum with the
nine evaluated attacks in Table IX. First, on average, 99.9% of

12

attacks when they are concurrently running with benign pro-
grams, are correctly recognized as attacks. A detailed analysis
shows that, when an attack program is running concurrently
with a benign program, 96.4% are identiﬁed as high-priority
attacks (case 2), 3.1% are recognized as high-priority stealthy
attacks (case 1), only 0.4% are classiﬁed as medium-priority
zero-day attacks (case 4). These results show that CloudShield
can still detect attacks even if they hide in benign programs.

TABLE X: Results of zero-day (unknown) attacks in step 2.

Zero-day attack detection in step 2. We conduct another
experiment by putting only L1 prime-probe (l1pp), LLC prime-
probe (l3pp), spectre v1, spectre v2, and buffer overﬂow
attacks in the set of known attacks. This means that
the
ﬂush-reload (fr), ﬂush-ﬂush (ff), spectre v3, and spectre v4
attacks are unknown zero-day attacks. We show the known
and zero-day attack detection results in Table X. We observe
that CloudShield can still correctly recognize unknown attacks.
The ﬂush-ﬂush and spectre v3 attacks are classiﬁed as case 4
(zero-day attacks). The other two attacks, i.e., the ﬂush-reload
and spectre v4 attacks, are detected as known attacks probably
because their behavior is similar to the known attacks.

Necessity of the two-step method. We have also investigated
detecting attacks together with detecting anomalies in the ﬁrst
step, when the cloud workloads are running. The beneﬁt of
doing this is that the attacks can be identiﬁed more quickly,
than in the second step. However, the downside of detecting
attacks in the ﬁrst step is that the attacks and cloud work-
loads interfere with each other, making the behavior markers
collected in the ﬁrst step not capable enough to identify the
attacks. Hence our two-steps method is much better.

G. Detection Latency and Overhead

Detection latency. The detection latency is deﬁned as the
period from the time the attack starts running, to the time an
attack alarm is raised. We present the overhead of robust detec-
tion using more than one set of behavior marker measurements,
e.g., with a sequence of w = 5 sets of measurements. The
timeline for detecting an attack is shown in Figure 9 (similar
tB denotes the
for attack and benign program detection).
time interval for collecting w behavior marker measurement.
tRED represents the time needed for computing the RED by
inferencing the pre-trained model. tKDE is the time to infer the
KDE detector. The computation of RED and KDE can overlap
with the behavior marker collection if w > 1 (Figure 9).

Table XI presents the detection latency when w =1, 5, 10,
50 and 100. As the HPCs are sampled every 10ms, tB=10ms
when w=1. We measure tRED and tKDE on the server. Speciﬁ-
cally, the calculation of RED (tRED) is performed on the GPU
and the calculation of KDE (tKDE ) is performed on the CPU

Predbenign (Case 3)Predattack(Case 1,2,4)Case 1(stealthy attack)Case 2(attack)Case 3(benign)Case 4(0-day)NoneNone1.000 0.000 0.000 0.000 1.000 0.000 Benign programsgpg-rsa1.000 0.000 0.000 0.000 1.000 0.000 bzip21.000 0.000 0.000 0.000 1.000 0.000 gcc0.971 0.029 0.000 0.000 0.971 0.029 mcf0.987 0.013 0.000 0.000 0.987 0.013 milc0.965 0.035 0.026 0.000 0.965 0.009 namd1.000 0.000 0.000 0.000 1.000 0.000 gobmk0.983 0.017 0.017 0.000 0.983 0.000 soplex1.000 0.000 0.000 0.000 1.000 0.000 hmmer1.000 0.000 0.000 0.000 1.000 0.000 libquantum1.000 0.000 0.000 0.000 1.000 0.000 h264ref0.980 0.020 0.000 0.000 0.980 0.020 Average0.990 0.010 0.004 0.000 0.990 0.006 Attacksl1pp0.000 1.000 0.000 1.000 0.000 0.000 l3pp0.000 1.000 0.000 1.000 0.000 0.000 fr0.000 1.000 0.000 1.000 0.000 0.000 ff0.000 1.000 0.000 1.000 0.000 0.000 spectrev10.000 1.000 0.000 1.000 0.000 0.000 spectrev20.000 1.000 0.000 1.000 0.000 0.000 spectrev30.000 1.000 0.000 1.000 0.000 0.000 spectrev40.000 1.000 0.000 1.000 0.000 0.000 bufferoverflow0.000 1.000 0.021 0.979 0.000 0.000 Average0.000 1.000 0.002 0.998 0.000 0.000 Attack and benign program detection (w=1)Predbenign (Case 3)Predattack(Case 1,2,4)Case 1(stealthy attack)Case 2(attack)Case 3(benign)Case 4(0-day)l1pp+ gpg0.000 1.000 0.241 0.746 0.000 0.013 l3pp+ gpg0.000 1.000 0.026 0.974 0.000 0.000 fr+ gpg0.000 1.000 0.117 0.883 0.000 0.000 ff+ gpg0.000 1.000 0.000 1.000 0.000 0.000 spectrev1+ gpg0.000 1.000 0.000 0.999 0.000 0.000 spectrev2+ gpg0.000 1.000 0.000 1.000 0.000 0.000 spectrev3+ gpg0.000 1.000 0.000 1.000 0.000 0.000 spectrev4+ gpg0.000 1.000 0.000 0.955 0.000 0.045 bufferoverflow+ gpg0.000 1.000 0.000 1.000 0.000 0.000 l1pp+ gcc0.000 1.000 0.000 1.000 0.000 0.000 l3pp+ gcc0.013 0.987 0.003 0.970 0.013 0.014 fr+ gcc0.000 1.000 0.044 0.956 0.000 0.000 ff+ gcc0.000 1.000 0.000 1.000 0.000 0.000 spectrev1+ gcc0.000 1.000 0.017 0.983 0.000 0.000 spectrev2+ gcc0.000 1.000 0.031 0.969 0.000 0.000 spectrev3+ gcc0.000 1.000 0.000 0.973 0.000 0.027 spectrev4+ gcc0.000 1.000 0.042 0.958 0.000 0.000 bufferoverflow+ gcc0.000 1.000 0.049 0.951 0.000 0.000 l1pp+ libquantum0.000 1.000 0.000 1.000 0.000 0.000 l3pp+ libquantum0.000 1.000 0.088 0.908 0.000 0.004 fr+ libquantum0.000 1.000 0.051 0.949 0.000 0.000 ff+ libquantum0.000 1.000 0.000 1.000 0.000 0.000 spectrev1+ libquantum0.005 0.995 0.037 0.954 0.005 0.004 spectrev2+ ibquantum0.000 1.000 0.000 1.000 0.000 0.000 spectrev3+ libquantum0.000 1.000 0.000 0.992 0.000 0.008 spectrev4+ libquantum0.000 1.000 0.035 0.965 0.000 0.000 bufferoverflow+ libquantum0.000 1.000 0.059 0.940 0.000 0.001 Average0.001 0.999 0.031 0.964 0.001 0.004 Attack and benign program detection (w=1)Predbenign (Case 3)Predattack(Case 1,2,4)Case 1(stealthy attack)Case 2(attack)Case 3(benign)Case 4(0-day)Known Attackl1pp0.000 1.000 0.000 1.000 0.000 0.000 l3pp0.000 1.000 0.000 1.000 0.000 0.000 spectrev10.000 1.000 0.000 1.000 0.000 0.000 spectrev20.000 1.000 0.000 1.000 0.000 0.000 bufferoverflow0.000 1.000 0.021 0.979 0.000 0.000 Unknown Attackfr0.000 1.000 0.000 0.999 0.000 0.001 ff0.000 1.000 0.000 0.000 0.000 1.000 spectrev30.000 1.000 0.001 0.000 0.000 1.000 spectrev40.000 1.000 0.000 0.999 0.000 0.001 attackers can effectively generate adversarial examples in
the black-box setting to evade deep learning based intrusion
detection systems. However, generating adversarial examples
against our system is generally harder. First, our system moni-
tors the dynamic behavior of a program. Generating dynamic
adversarial examples that can both interact with other programs
and escape detection in the black-box setting remains challeng-
ing. Second, the behavior markers monitored in our system are
HPC measurements. As HPC measurements highly depend on
the context of the executing environment, this introduces an
extra obstacle for the attacker to construct the same execution
environment when generating evasion adversarial examples.
How to design and develop efﬁcient evasive attacks and how
to detect these attacks are worth exploring as future work.

VII. PAST WORK

Past work on anomaly detection in the cloud mainly
focused on machine performance degradation. Liu et al.[47]
proposed self-organizing maps for detecting anomalies in
machine performance. Vallis et al.[56] leveraged statistical
measurement, e.g., median, and median absolute deviation,
to detect machine performance degradation. Pannu et al.[52]
implemented adaptive anomaly detection (AAD) based on non-
linear transformation for detecting failures in cloud infrastruc-
tures. These work detected performance anomalies to provide
reliable cloud service, however, unlike our work, they did not
consider anomalies caused by attacks.

Another line of research detected speciﬁc attacks in the
cloud. For example, Zhang et al.[65] developed CloudRadar
for side-channel attack detection in the cloud using hardware
performance counters. Guo et al.[27] detected cache side-
channel leakage with symbolic execution. Wang et al.[57]
leveraged symbolic execution to detect speculative execution
attacks. However, each of these detected a speciﬁc type of
attack, unlike our work, which covers a broader scope of
attacks, including zero-day attacks.

Recent work used deep learning for anomaly detection.
Alam et al.[10] proposed AutoPerf based on an autoencoder
to detect hardware performance anomalies. DeepLog [22]
leveraged system event logs to detect system failures. Sucheta
et al.[16] and Malhotra et al.[48] proposed LSTM for se-
quential anomaly detection. He et al.[30] leveraged LSTM
for anomaly detection in critical infrastructures. Du et al.[21]
updated anomaly detection model
through unlearning. Hu
et al.[37] developed a deep learning hardware module for
impostor detector in smartphone systems. As stated in their
work, unlearning may introduce a higher false-positive rate.
In contrast, CloudShield signiﬁcantly reduces false positives
by distinguishing benign and malicious anomalies.

VIII. CONCLUSION

In this paper, we proposed CloudShield, a real-time
anomaly and attack detection system for cloud computing.
CloudShield leverages a single pre-trained deep learning model
and leverages the reconstruction error distribution (RED) of
hardware performance counters to model the normal behavior
of a system using kernel density estimation (KDE). It
is
worth noting that CloudShield explicitly takes false-alarm
reduction into account, a critical problem in anomaly de-
tection systems. Once an anomaly is detected, CloudShield

Fig. 9: Illustration of the timeline for anomaly detection.

of the server. The two overall numbers in the parenthesis are
detection time when there is no anomaly (thus no step 2) and
there is an attack, respectively. We show that CloudShield can
detect anomalies and identify the attacks and benign programs
in 32 to 112 milliseconds if w = 1 or w = 5. Considering the
attack usually takes seconds to succeed, e.g., several encryption
operations for side-channel attacks, this latency can achieve
our design goal of real-time detection. Larger window sizes can
reduce the false-positive rate, however, the false-negative rate
is slightly increased (Figure 5) and detection time is increased
to seconds. We suggest w=5 is sufﬁcient.

TABLE XI: Detection latency (ms) versus window sizes.

(ms)

w=1
w=5
w=10
w=50
w=100

Anomaly Detection
tRED
tB
0.02
10.0
0.02
50.0
0.02
100.0
0.02
500.0
0.02
1000.0

tKDE
0.76
0.76
0.77
0.78
0.79

Benign program/Attack detection

Overall (no anomaly, attack)

tB
10.0
50.0
100.0
500.0
1000.0

tRED
0.02
0.02
0.02
0.02
0.02

tKDE
1.58
1.58
1.60
1.62
1.65

(10.78, 32.38)
(50.78, 112.38)
(100.79, 212.41)
(500.80, 1012.44)
(1000.81, 2012.48)

Performance overhead. We evaluate the performance over-
head of CloudShield. We use the benchmarks in Table III.
We use completion time as the metric for ML training and
MapReduce, average time per query for Database and Web-
server, and processing time per frame for Stream Server. All
the metrics are normalized to the cloud workload running
without Cloudshield. Figure 10 reports the normalized met-
rics without CloudShield (blue solid) and with CloudShield
running (orange dashed). Results are averaged over ﬁve runs).
We see that CloudShield only introduces a small performance
overhead. The maximum overhead is 6.3% for MapReduce and
the minimum is 0.5% for database. In our experiments, we
observe that on average CloudShield consumes 17.1% CPU
time on the server.

Fig. 10: Performance overhead of CloudShield with different
cloud workloads.

H. Discussion: Evasion Attacks

There have been many attacks against deep learning sys-
tems [31], [33], [32], [62]. Previous work [54] revealed that

13

Behavior MarkerBehavior MarkerBehavior MarkerBehavior MarkerBehavior MarkerBehavior MarkerComputing REDKDEtBtREDtKDEw=1Behavior MarkerBehavior MarkertBtREDtKDEw=50.60.70.80.911.11.2ML TrainDatabaseStream ServerWebServerMapReducew/o CloudShieldw/ CloudShieldautomatically distinguishes benign programs, known attacks,
and zero-day attacks by investigating the different attack and
benign program reconstruction error distributions, using the
pre-trained model and kernel density estimators.

We evaluate CloudShield on various cloud workloads,
attacks, and benign programs. Experimental results show that
CloudShield can reliably detect various attacks in real-time
with high accuracy and very low FNR and FPR. Moreover,
experiments show that it can correctly identify unknown zero-
day attacks and stealthy attacks that are running concurrently
with benign programs. CloudShield achieves very low 0.3%
FNR and 0.6% FPR for overall anomaly-attack detection.
Especially, we ﬁnd that CloudShield can detect the recently
proposed speculative execution attacks in 32-112ms, and it can
reduce false alarms by up to 99.0%.

REFERENCES

[1]
[2]
[3]

[4]

[5]

[6]
[7]
[8]
[9]

https://aws.amazon.com, 2018.
http://cloud.google.com, 2018.
https://azure.microsoft.com/en-us/services/machine-learning-studio/,
2018.
https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-3640,
2018.
https://msrc-blog.microsoft.com/2018/05/21/
analysis-and-mitigation-of-speculative-store-bypass-cve-2018-3639/,
2018.
https://github.com/wg/wrk, 2019.
https://github.com/akopytov/sysbench, 2019.
https://perf.wiki.kernel.org/index.php/Main Page, 2020.
https://hadoop.apache.org/docs/current/api/org/apache/hadoop/
examples/terasort/package-summary.html, 2020.

[10] M. Alam, J. Gottschlich, N. Tatbul, J. S. Turek, T. Mattson, and
A. Muzahid, “A zero-positive learning approach for diagnosing software
performance regressions,” in Advances in Neural Information Process-
ing Systems (NeurIPS), 2019.

[11] E. Asselin, C. Aguilar-Melchor, and G. Jakllari, “Anomaly detection
for web server log reduction: A simple yet efﬁcient crawling based
approach,” in IEEE Conference on Communications and Network
Security, 2016.
J. Bonneau and I. Mironov, “Cache-collision timing attacks against aes,”
in International Workshop on Cryptographic Hardware and Embedded
Systems (CHES), 2006.

[12]

[13] L. Bossi, E. Bertino, and S. R. Hussain, “A system for proﬁling
and monitoring database access patterns by application programs for
anomaly detection,” IEEE Transactions on Software Engineering, 2016.
[14] M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander, “Lof: iden-
tifying density-based local outliers,” in ACM SIGMOD International
Conference on Management of Data (SIGKDD), 2000.

[15] M. S. Brunella, S. Turco, G. Bianchi, and N. B. Melazzi, “Foreshadow-
vmm: on the practical feasibility of l1 cache terminal fault attacks,”
2018.

[16] S. Chauhan and L. Vig, “Anomaly detection in ecg time signals via deep
long short-term memory networks,” in IEEE International Conference
on Data Science and Advanced Analytics, 2015.

[17] K. Cho, B. Van Merri¨enboer, C. Gulcehre, D. Bahdanau, F. Bougares,
H. Schwenk, and Y. Bengio, “Learning phrase representations using
rnn encoder-decoder for statistical machine translation,” arXiv preprint
arXiv:1406.1078, 2014.

[18] S. Das, J. Werner, M. Antonakakis, M. Polychronakis, and F. Monrose,
“Sok: The challenges, pitfalls, and perils of using hardware performance
counters for security,” in IEEE Symposium on Security and Privacy
(S&P), 2019.
J. Demme, M. Maycock, J. Schmitz, A. Tang, A. Waksman, S. Sethu-
madhavan, and S. Stolfo, “On the feasibility of online malware detection
with performance counters,” ACM SIGARCH Computer Architecture
News, 2013.

[19]

[20]

J. Devlin, M.-W. Chang, K. Lee, and K. N. Toutanova, “Bert: Pre-
training of deep bidirectional transformers for language understanding,”
arXiv preprint arXiv:1810.04805, 2018.

[21] M. Du, Z. Chen, C. Liu, R. Oak, and D. Song, “Lifelong anomaly
detection through unlearning,” in ACM Conference on Computer and
Communications Security (CCS), 2019.

[22] M. Du, F. Li, G. Zheng, and V. Srikumar, “Deeplog: Anomaly detection
and diagnosis from system logs through deep learning,” in ACM
Conference on Computer and Communications Security (CCS), 2017.
[23] S. Garg, K. Kaur, S. Batra, G. S. Aujla, G. Morgan, N. Kumar, A. Y.
Zomaya, and R. Ranjan, “En-abc: An ensemble artiﬁcial bee colony
based anomaly detection scheme for cloud environment,” Journal of
Parallel and Distributed Computing, 2020.

[24] D. Gruss, C. Maurice, K. Wagner, and S. Mangard, “Flush+ﬂush: a fast
and stealthy cache attack,” in International Conference on Detection of
Intrusions and Malware, and Vulnerability Assessment, 2016.

[25] D. Gruss, R. Spreitzer, and S. Mangard, “Cache template attacks:
Automating attacks on inclusive last-level caches,” in USENIX Security
Symposium, 2015.

[26] D. Gullasch, E. Bangerter, and S. Krenn, “Cache games–bringing
access-based cache attacks on aes to practice,” in IEEE Symposium
on Security and Privacy (S&P), 2011.

[27] S. Guo, Y. Chen, P. Li, Y. Cheng, H. Wang, M. Wu, and Z. Zuo,
“Specusym: Speculative symbolic execution for cache timing leak
detection,” in International Conference on Software Engineering, 2020.
[28] Z. He, G. Hu, and R. B. Lee, “New models for understanding and rea-
soning about speculative execution attacks,” in IEEE International Sym-
posium on High-Performance Computer Architecture (HPCA), 2021.

[29] Z. He and R. B. Lee, “How secure is your cache against side-
channel attacks?” in Annual IEEE/ACM International Symposium on
Microarchitecture, 2017.

[30] Z. He, A. Raghavan, G. Hu, S. Chai, and R. Lee, “Power-grid controller
anomaly detection with enhanced temporal deep learning,” in IEEE
International Conference On Trust, Security And Privacy In Computing
(TrustCom), 2019.

[31] Z. He, T. Zhang, and R. Lee, “Sensitive-sample ﬁngerprinting of deep
neural networks,” in IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), 2019.

[32] Z. He, T. Zhang, and R. B. Lee, “Model inversion attacks against
collaborative inference,” in Annual Computer Security Applications
Conference (ACSAC), 2019.

[33] ——, “Attacking and protecting data privacy in edge-cloud collaborative

[34]

inference systems,” IEEE Internet of Things Journal, 2020.
J. L. Henning, “Spec cpu2006 benchmark descriptions,” ACM
SIGARCH Computer Architecture News, 2006.

[35] G. E. Hinton and S. Roweis, “Stochastic neighbor embedding,” Ad-

vances in Neural Information Processing Systems (NeurIPS), 2002.

[36] H. Hotelling, “Analysis of a complex of statistical variables into

principal components.” Journal of educational psychology.

[37] G. Hu, Z. He, and R. B. Lee, “Smartphone impostor detection with
behavioral data privacy and minimalist hardware support,” in TinyML
Symposium, 2021.

[38] G. Irazoqui, T. Eisenbarth, and B. Sunar, “S $ a: A shared cache attack
that works across cores and deﬁes vm sandboxing–and its application
to aes,” in IEEE Symposium on Security and Privacy (S&P), 2015.

[39] M. Kayaalp, N. Abu-Ghazaleh, D. Ponomarev, and A. Jaleel, “A high-
resolution side-channel attack on last-level cache,” in Design Automa-
tion Conference (DAC), 2016.

[40] A. Khan, X. Yan, S. Tao, and N. Anerousis, “Workload characterization
and prediction in the cloud: A multiple time series approach,” in IEEE
Network Operations and Management Symposium, 2012.

[41] V. Kiriansky and C. Waldspurger, “Speculative buffer overﬂows: Attacks

and defenses,” arXiv preprint arXiv:1807.03757, 2018.

[42] P. Kocher, J. Horn, A. Fogh, D. Genkin, D. Gruss, W. Haas, M. Ham-
burg, M. Lipp, S. Mangard, T. Prescher et al., “Spectre attacks:
Exploiting speculative execution,” in IEEE Symposium on Security and
Privacy (S&P), 2019.

[43] E. M. Koruyeh, K. N. Khasawneh, C. Song, and N. Abu-Ghazaleh,

14

channel attack detection system in clouds,” in International Symposium
on Research in Attacks, Intrusions, and Defenses (RAID), 2016.
[66] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, “Cross-tenant side-
channel attacks in paas clouds,” in ACM Conference on Computer and
Communications Security (CCS), 2014.

[67] B. Zhou, A. Gupta, R. Jahanshahi, M. Egele, and A. Joshi, “Hardware
performance counters can detect malware: Myth or fact?” in Asia
Conference on Computer and Communications Security (AsiaCCS),
2018.

“Spectre returns! speculation attacks using the return stack buffer,” in
USENIX Workshop on Offensive Technologies, 2018.

[44] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, A. Fogh, J. Horn,
S. Mangard, P. Kocher, D. Genkin et al., “Meltdown: Reading kernel
memory from user space,” in USENIX Security Symposium, 2018.
[45] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, “Last-level cache
side-channel attacks are practical,” in IEEE Symposium on Security and
Privacy (S&P), 2015.

[46] F. T. Liu, K. M. Ting, and Z.-H. Zhou, “Isolation forest,” in IEEE

[47]

International Conference on Data Mining (ICDM), 2008.
J. Liu, S. Chen, Z. Zhou, and T. Wu, “An anomaly detection algorithm of
cloud platform based on self-organizing maps,” Mathematical Problems
in Engineering, 2016.

[48] P. Malhotra, L. Vig, G. Shroff, and P. Agarwal, “Long short term
memory networks for anomaly detection in time series,” in European
Symposium on Artiﬁcial Neural Networks, Computational Intelligence
and Machine Learning, 2015.

[49] A. K. Mishra, J. L. Hellerstein, W. Cirne, and C. R. Das, “Towards
characterizing cloud backend workloads: insights from google compute
clusters,” ACM SIGMETRICS Performance Evaluation Review, 2010.

[50] D. A. Osvik, A. Shamir, and E. Tromer, “Cache attacks and countermea-
sures: the case of aes,” in Cryptographers’ Track at the RSA conference,
2006.

[51] M. Ozsoy, K. N. Khasawneh, C. Donovick, I. Gorelik, N. Abu-
Ghazaleh, and D. Ponomarev, “Hardware-based malware detection us-
ing low-level architectural features,” IEEE Transactions on Computers,
2016.

[52] H. S. Pannu, J. Liu, and S. Fu, “Aad: Adaptive anomaly detection system
for cloud computing infrastructures,” in IEEE Symposium on Reliable
Distributed Systems, 2012.

[53] N. Patel, A. Sasan, and H. Homayoun, “Analyzing hardware based

malware detectors,” in Design Automation Conference (DAC), 2017.

[54] H. Qiu, T. Dong, T. Zhang, J. Lu, G. Memmi, and M. Qiu, “Adversarial
attacks against network intrusion detection in iot systems,” IEEE
Internet of Things Journal, 2020.

[55] B. Sch¨olkopf, R. C. Williamson, A. J. Smola, J. Shawe-Taylor, and
J. C. Platt, “Support vector method for novelty detection,” in Advances
in Neural Information Processing Systems (NeurIPS), 2000.

[56] O. Vallis, J. Hochenbaum, and A. Kejariwal, “A novel technique for
long-term anomaly detection in the cloud,” in USENIX Workshop on
Hot Topics in Cloud Computing, 2014.

[57] G. Wang, S. Chattopadhyay, A. K. Biswas, T. Mitra, and A. Roychoud-
hury, “Kleespectre: Detecting information leakage through speculative
cache attacks via symbolic execution,” ACM Transactions on Software
Engineering and Methodology, 2020.

[58] X. Wang, C.-C. Pan, P. Liu, and S. Zhu, “Sigfree: A signature-free
buffer overﬂow attack blocker,” IEEE Transactions on Dependable and
Secure Computing, 2008.

[59] X. Wang and R. Karri, “Detecting kernel control-ﬂow modifying

rootkits,” in Network Science and Cybersecurity, 2014.

[60] X. Wang, C. Konstantinou, M. Maniatakos, and R. Karri, “Conﬁrm:
Detecting ﬁrmware modiﬁcations in embedded systems using hardware
performance counters,” in International Conference on Computer-Aided
Design (ICCAD), 2015.

[61] O. Weisse, J. Van Bulck, M. Minkin, D. Genkin, B. Kasikci, F. Piessens,
M. Silberstein, R. Strackx, T. F. Wenisch, and Y. Yarom, “Foreshadow-
ng: Breaking the virtual memory abstraction with transient out-of-order
execution,” Tech. Rep., 2018.

[62] Q. Yao, Z. He, H. Han, and S. K. Zhou, “Miss the point: Targeted
adversarial attack on multiple landmark detection,” in International
Conference on Medical Image Computing and Computer-Assisted In-
tervention (MICCAI), 2020.

[63] Y. Yarom and K. Falkner, “Flush+reload: a high resolution, low noise,
l3 cache side-channel attack,” in USENIX Security Symposium, 2014.
[64] C. Yin, Y. Zhu, J. Fei, and X. He, “A deep learning approach for
intrusion detection using recurrent neural networks,” IEEE Access,
2017.

[65] T. Zhang, Y. Zhang, and R. B. Lee, “Cloudradar: A real-time side-

15

APPENDIX

TABLE XII: List of all hardware performance counters.

HPC
Instruction
Load
Store
L1D read miss
L1D write miss
L1D prefetch miss
L1I read miss
LLC read access
LLC read miss
LLC write access
LLC write miss
LLC prefetch access
LLC prefetch miss
DTLB read access
DTLB read miss
DTLB write access
DTLB write miss
ITLB read access
ITLB read miss
BPU read access
BPU read miss
Cache node read access
Cache node read miss
Cache node write access
Cache node write miss
Cache node prefetch access
Cache node prefetch miss
Cycles
Branch instructions
Branch prediction miss
Page faults
Context switch
Stall during issue
Stall during retirement

Description
Number of instructions
Number of memory loads
Number of memory stores
Number of L1 data cache read misses
Number of L1 data cache write misses
Number of L1 data cache prefetch misses
Number of L1 instruction cache read misses
Number of Last level cache read accesses
Number of Last level cache read misses
Number of Last level cache write access
Number of Last level cache write misses
Number of Last level cache prefetch accesses
Number of Last level cache prefetch misses
Number of data translation lookaside buffer read accesses
Number of data translation lookaside buffer read misses
Number of data translation lookaside buffer write accesses
Number of data translation lookaside buffer write misses
Number of instruction translation lookaside buffer read accesses
Number of instruction translation lookaside buffer read misses
Number of branch prediction unit read accesses
Number of branch prediction unit read misses
Number of cache node read accesses
Number of cache node read misses
Number of cache node write accesses
Number of cache node write misses
Number of cache node prefetch accesses
Number of cache node prefetch misses
Number of cycles
Number of branch instructions
Number of branch prediction misses
Number of page faults
Number of context switches
Number of stalled cycles during instruction issue
Number of stalled cycles during instruction retirement

TABLE XIII: Top-10 important events for each cloud bench-
mark. Bold means the event ranks top 10 for all benchmarks.

Rank

ML Training
(Pytorch)

Stream Server
(FFserver)

Instruction

Cycles

Database
(Mysql)

Cycles

Load

Stall during
retirement

Stall during
issue
Stall during
retirement

Stall during
issue
Stall during
retirement

Web Server
(Nginx)
Stall during
issue
Stall during
retirement

MapReduce

Instruction

Stall during
issue

Cycles

Cycles

Store

Instruction

Instruction

Load

Stall during
retirement

Load

Load

DTLB read

Load

Stall during
issue
DTLB read

BPU read

BPU read

BPU read

DTLB read

DTLB read

DTLB write
Cycles
L1D read
miss

Store
DTLB write
L1I read
miss

Store
DTLB write
L1I read
miss

1

2

3

4

5

6

7

8
9

10

Branch
L1I read
miss
Instruction
BPU read

DTLB read

Branch

BPU read
DTLB write

Context Switch

Store

16

