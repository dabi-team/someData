8
1
0
2

g
u
A
4
1

]
E
S
.
s
c
[

4
v
9
1
5
7
0
.
3
0
8
1
:
v
i
X
r
a

DeepGauge:Multi-GranularityTestingCriteriaforDeepLearningSystemsLeiMa1,3∗,FelixJuefei-Xu2,FuyuanZhang3,JiyuanSun4,MinhuiXue3,BoLi5ChunyangChen6,TingSu3,LiLi6,YangLiu3,JianjunZhao4,andYadongWang11HarbinInstituteofTechnology,China2CarnegieMellonUniversity,USA3NanyangTechnologicalUniversity,Singapore4KyushuUniversity,Japan5UniversityofIllinoisatUrbana–Champaign,USA6MonashUniversity,AustraliaABSTRACTDeeplearning(DL)definesanewdata-drivenprogrammingpara-digmthatconstructstheinternalsystemlogicofacraftedneuronnetworkthroughasetoftrainingdata.Wehaveseenwideadop-tionofDLinmanysafety-criticalscenarios.However,aplethoraofstudieshaveshownthatthestate-of-the-artDLsystemssufferfromvariousvulnerabilitieswhichcanleadtosevereconsequenceswhenappliedtoreal-worldapplications.Currently,thetestingad-equacyofaDLsystemisusuallymeasuredbytheaccuracyoftestdata.Consideringthelimitationofaccessiblehighqualitytestdata,goodaccuracyperformanceontestdatacanhardlyprovideconfidencetothetestingadequacyandgeneralityofDLsystems.Unliketraditionalsoftwaresystemsthathaveclearandcontrol-lablelogicandfunctionality,thelackofinterpretabilityinaDLsystemmakessystemanalysisanddefectdetectiondifficult,whichcouldpotentiallyhinderitsreal-worlddeployment.Inthispaper,weproposeDeepGauge,asetofmulti-granularitytestingcriteriaforDLsystems,whichaimsatrenderingamulti-facetedportrayalofthetestbed.Thein-depthevaluationofourproposedtestingcriteriaisdemonstratedontwowell-knowndatasets,fiveDLsys-tems,andwithfourstate-of-the-artadversarialattacktechniquesagainstDL.ThepotentialusefulnessofDeepGaugeshedslightontheconstructionofmoregenericandrobustDLsystems.CCSCONCEPTS•Softwareanditsengineering→Softwaretestingandde-bugging;•Theoryofcomputation→Adversariallearning;KEYWORDSDeeplearning,Softwaretesting,Deepneuralnetworks,TestingcriteriaACMReferenceFormat:LeiMa,FelixJuefei-Xu,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,Chun-yangChen,TingSu,LiLi,YangLiu,JianjunZhao,andYadongWang.2018.DeepGauge:Multi-GranularityTestingCriteriaforDeepLearningSystems.∗LeiMaisthecorrespondingauthor.Email:malei@hit.edu.cn.Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.CopyrightsforcomponentsofthisworkownedbyothersthanACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.ASE’18,September3–7,2018,Montpellier,France©2018AssociationforComputingMachinery.ACMISBN978-1-4503-5937-5/18/09...$15.00https://doi.org/10.1145/3238147.3238202InProceedingsofthe201833rdACM/IEEEInternationalConferenceonAu-tomatedSoftwareEngineering(ASE’18),September3–7,2018,Montpellier,France.ACM,NewYork,NY,USA,12pages.https://doi.org/10.1145/3238147.32382021INTRODUCTIONDeeplearning(DL)systemshavegainedgreatpopularityinvariousapplications,e.g.,speechprocessing[26],medicaldiagnostics[12],imageprocessing[11],androbotics[58].Adeepneuralnetwork(DNN),asatypeofdeeplearningsystems,isthekeydrivingforcebehindrecentsuccess.However,DNN-basedsoftwaresystems,suchasautonomousdriving,oftenexhibiterroneousbehaviorsthatleadtofatalconsequences.Forexample,severalaccidents[21]havebeenreportedduetoautonomousvehicle’sfailuretohandleunexpected/corner-casedrivingconditions.OneofthetrendingresearchareasistoinvestigatethecauseofvulnerabilityinDLsystemsbymeansofgeneratingadversarialtestexamplesforimage-andvideo-basedDLsystems.Suchcarefullylearnedpixel-levelperturbations,imperceptibletohumaneyes,cancausetheDL-basedclassificationsystemtooutputcompletelywrongdecisionswithhighconfidence[20].EversincetheinceptionofadversarialattacksontheDLsystems,moreandmoreresearchhasbeendedicatedtobuildingupstrongattackers[6,25,55,60].Asaconsequence,betterdefensemechanismsinDLsystemsagainstadversarialattacksareindireneed.VarioustechniquestonullifyadversarialattacksandtotrainamorerobustDLsystemareemerg-inginrecentstudies[18,23,41,43,45,51,56].Together,researchinbothrealmsformsavirtuouscircleandblazesatrailforbetterunderstandingofhowtobuildmoregenericandrobustDLsystems.However,whatisstilllackingisasystematicwayofgaugingthetestingadequacyofgivenDLsystems.CurrentstudiesfocusonlyonpursuinghighaccuracyofDLsystemsasatestingcriterion,forwhichweshowseveralcaveatsasfollows.First,measuringthesoftwarequalityfromDLoutputaloneissuperficialinthesensethatfundamentalunderstandingoftheDLinternalneuronactivitiesandnetworkbehaviorsisnottouchedupon.WeagreethatitcouldbeanindicatorofDLsystemqualityandgenerality,butitisfarfromcomplete,andoftentimesunreliable.Second,acriterionsolelybasedonDLoutputwillrelyheavilyonhowrepresentativethetestdataare.Havingachievedhigh-performanceDLoutputdoesnotnecessarilymeanthatthesystemisutmostgeneric,andachievinglow-performancedoesnotindicatetheoppositeeither.ADLmodelcanbeimmunetomanyknowntypesofadversarialattacks,butmayfailfromunseenattacks.ThisisbecausesuchacriterionbasedonlyonDLoutputsisfarfrombeingcomprehensive,anditleaveshighrisksforcurrentlycocoonedDLsystemstobedeployedinthereal-worldenvironmentwherenewlyevolvedadversarialattacksare 
 
 
 
 
 
ASE’18,September3–7,2018,Montpellier,FranceMa,Xu,Zhang,Sun,Xue,Li,Chen,Su,Li,Liu,Zhao,andWanginescapable.Third,anyDLsystemthatpassessystematictestingshouldbeabletowithstandalltypesofadversarialattackstosomeextent.SuchgeneralityuponvariousattacksisofvitalimportanceforDLsystemstobedeployed.Butapparentlythisisnotthecase,unlesswesticktoasetofmorecomprehensivegaugingcriteria.Weunderstandthateventhemostcomprehensivegaugingcriteriawouldnotbeabletoentirelyeliminaterisksfromadversarialattacks.Nevertheless,byenforcingasuitablesetoftestingcriteria,wehopethataDLsystemcouldbebettertestedtofacilitatetheconstructionofamoregenericandrobustdeeplearningsystem.Towardsaddressingtheaforementionedlimitations,asetoftest-ingcriteriaisneeded,asopposedtothesolecriterionbasedonDLdecisionoutput.Inadditiontobeingscalable,theproposedcriteriawillhavetomonitorandgaugetheneuronactivitiesandintrinsicnetworkconnectivityatvariousgranularitylevels,sothatamulti-facetedin-depthportrayaloftheDLsystemandtestingqualitymeasuresbecomedesirable.Inthiswork,weareprobingthisproblemfromasoftwareengi-neeringandsoftwaretestingperspective.Atahighlevel,erroneousbehaviorsappearedinDNNsareanalogoustologicbugsintradi-tionalsoftware.However,thesetwotypesofsoftwarearefunda-mentallydifferentintheirdesigns.Traditionalsoftwarerepresentsitslogicascontrolflowscraftedbyhumanknowledge,whileaDNNcharacterizesitsbehaviorsbytheweightsofneuronedgesandthenonlinearactivationfunctions(determinedbythetrainingdata).Therefore,detectingerroneousbehaviorsinDNNsisdifferentfromdetectingthoseintraditionalsoftwareinnature,whichnecessitatesnoveltestgenerationapproaches.Toachievethisgoal,theveryfirststepistopreciselydefineasetofsuitablecoveragecriteria,whichcanguidetestdesignandevaluatetestquality.Despiteanumberofcriteriaexistingfortraditionalsoftware,e.g.,statement,branch,data-flowcoverage,theycompletelyloseeffectintestingDNNs.Tothebestofourknowledge,thedesignoftestingcoveragecriteriaforDNNsisstillattheearlystage[38,47].Withoutacomprehensivesetofcriteria,(1)designingteststocoverdifferentlearnedlogicsandrulesofDNNsisdifficulttoachieve.Consequently,erroneousbehaviorsmaybemissed;(2)evaluatingtestqualityisbiased,andtheconfidenceofobtainedtestingresultsmaybeoverestimated.Inthispaper,weproposeDeepGauge—asetoftestingcriteriabasedonmulti-leveland-granularitycoveragefortestingDNNsandmeasurethetestingquality.Ourcontributionsaresummarizedasfollows:•OurproposedcriteriafacilitatetheunderstandingofDNNsaswellasthetestdataqualityfromdifferentlevelsandangles.Ingeneral,wefinddefectscouldpotentiallydistributeonbothmajorfunctionregionsaswellasthecorner-caseregionsofDNNs.Givenasetofinputs,ourcriteriacouldmeasuretowhatextentitcoversthemainfunctionalityandthecornercasesoftheneurons,whereDLdefectscouldincur.OurevaluationresultsrevealthattheexistingtestdataofagivenDLingeneralskewmoretowardstestingthemajorfunctionregion,withrelativelyfewcasescoveringthecorner-caseregion.•InlinewithexistingtestdataofDNNs,weevaluatetheuse-fulnessofourcoveragecriteriaasindicatorstoquantifydefectdetectionabilityoftestdataonDNNs,throughgeneratingnewadversarialtestdatausing4well-knownadversarialdatagener-ationalgorithms(i.e.,FastGradientSignMethod(FGSM)[20],BasicIterativeMethod(BIM)[31],Jacobian-basedSaliencyMapAttack(JSMA)[37]andCarlini/Wagnerattack(CW)[8]).Theextensiveevaluationshowsthatourcriteriacaneffectivelycap-turethedifferencebetweentheoriginaltestdataandadversarialexamples,whereDNNscouldandcouldnotcorrectlyrecognize,respectively,demonstratingthatahighercoverageofourcriteriapotentiallyindicatesahigherchancetodetecttheDNN’sdefects.•ThevariouscriteriaproposedbehavedifferentlyonDNNsw.r.t.networkcomplexityanddatasetunderanalysis.Altogether,thesecriteriacanpotentiallyhelpusgaininsightsoftestingDNNs.Byprovidingtheseinsights,wehopethatbothsoftwareengineeringandmachinelearningcommunitiescanbenefitfromapplyingnewcriteriaforgaugingthetestingqualityoftheDNNstogainconfidencetowardsconstructinggenericandrobustDLsystems.Tothebestofourknowledge,thisisamongtheearlieststudiestoproposemulti-granularitytestingcriteriaforDLsystems,whicharemirroredbythetestcoverageintraditionalsoftwaretesting.2PRELIMINARIESInthissection,wefirstintroducetraditionalsoftwareandthendeeplearningsystemsofwhichthearchitecturalfeaturesappearingtobeastepabovecurrenttraditionalsoftware.WewillseethatDLfundamentallychangesthesoftwaredevelopmentparadigm.Precisely,wetrytoanalogizethattheprogramminglanguagelogicexecutiontotraditionalsoftwareiswhattheconnectivitystrength(weights)toaDNN.Aswewillseebelow,weareattemptingtoconnectthesetwocounterpartsaswellasdiscussingthedifferences.2.1CoverageCriteriainTraditionalSoftwareTestingWeregardtraditionalsoftwareasanyprogramwritteninhigh-levelprogramminglanguages(e.g.,C/C++,Java,Python).Specially,eachstatementintraditionalprogramperformssomecertainoperationthateithertransformstheoutputsfromthepreviousstatementtothenextoneorchangestheprogramstates(e.g.,assignnewvaluestovariables).Softwaredefects(bugs)canbeintroducedbydevelopersduetoincorrectimplementation,whichmaycauseunexpectedoutputsorevenfail-stoperrors(e.g.,programcrashes).Todetectdefects,softwaretestingisoneofthemostwidelyadoptedsoftwarevalidationtechniquesinsoftwareindustry—Givenasetoftestdata,itfeedsthesetestdataasinputstoprogramandvalidatesthecorrectnessoftheprogram’srun-timebehaviorbycomparingtheactualoutputswithexpectedones(testoracles);andmeasurestestadequacybyusingcoveragecriteria,theimportant,practicalmeasurestoquantifythedegreetowhichthesoftwareistested[36].Theprogramwithhighertestcoverageoftensuggeststhatithasalowerchanceofcontainingdefects.Manysoftwaretestingstandardsrequireasoftwareproducttobethoroughlytestedwithhightestcoveragebeforeshipment,whichisusedasanindica-torandconfidenceofthesoftwarequality.Onsomesafetycriticalsystems,therequirementofsomeformoftestcoverageiseven100%.Forexample,ECSS-E-ST-40C[15]standardsdemand100%statementcoverageofthesoftwareundertestfortwocriticallevels.DeepGauge:Multi-GranularityTestingCriteriaforDeepLearningSystemsASE’18,September3–7,2018,Montpellier,FranceFortraditionalsoftware,anumberofcoveragecriteriahavealreadybeendefinedatdifferentlevels,toanalyzethesoftwarerun-timebehaviorfromdifferentperspectives,i.e.,codelevel(e.g.,state-ment,branch,data-flowcoverageandmutationtesting[27,46,62])ormodel-level(e.g.,stateandtransitioncoverage[2,14])tocaterfordifferenttestingmethodsandgranularities.Somecommonlyusedtestcoveragecriteriaarelistedasfollows:•Statementcoveragemeasureswhethereachinstructionhasbeenexecuted,andbranchcoveragefocusesonwhethereachbranchofcontrolstructure(e.g.,iniforswitch-casestatements)hasbeencovered,bothofwhicharecontrol-flow-basedcriteria.•Data-flowcoverage[46]enforcesthecoverageofeachvariabledefinitionanditsusestodetectdata-flowanomalies.•Model-basedcoveragecriteria[3,52]aimtocovermoreprogrambehaviorsviaabstractedbehaviormodels.Othercomprehensivevariantsoftestcoveragecouldbereferredto[2].However,noneofthesecriteriacanbedirectlyappliedtotestDNNsduetoitsuniquearchitecture,asexplainedbelow.2.2DeepNeuralNetworkArchitectureInourpaper,weregardaDLsystemasanysoftwaresystemthatincludesoneormoreDNNs.1Unliketraditionalsoftware,pro-grammedwithdeterministicalgorithmsbydevelopers,DNNsareprogrammedbythetrainingdata,selectedfeatures,andnetworkstructures(e.g.,numberoflayers).Specially,aDNNconsistsofmultipleinterconnectedneuronsorganizedonlayers:theinputlayer,theoutputlayer,andoneormultiplehiddenlayers.Eachneuronisacomputingunitthatcomputesitsoutputbyapplyinganactivationfunctiontoitsinput.InclassicDNNs,eachneuronisfully-connectedwithallneuronsonthenextlayer,andeachedgehasaweight,whichindicatesthestrengthoftheconnectionsbetweenneurons.Overall,aDNNcouldbeconsideredasafunctionthattransformsagiveninputtotheoutput,andthisfunctionisdecidedbytheaggregatedeffectsfromitscomputationunits(i.e.,neurons),eachofwhichcontributestothewholecomputationprocedure.Figure1(a)showsanexampleofathree-layerDNN.Toaccomplishatask(e.g.,predictionontheautonomousvehi-cles’steeringanglebymonitoredimages),DNNsaretrainedandprogrammedthroughalargesetoflabelledtrainingdata.However,similartotraditionalsoftware,DNNsmayalsocontaindefects(e.g.,givewrongsteeringangles)duetoincorrect,incompletetrainingdata,oreventhewronglystipulatedrun-timeprogramming(i.e.,training)procedure.Forexample,humananalystmayincludeer-roneousandnoisydatawhencollectingtrainingdata.Insuchacase,agiveninputdatamightbewronglyhandled(e.g.,classi-fied,predicted),causinglossesandevenseveretragedies,iftheflawedDNNsaredeployedtosafety-criticalsystems(e.g.,there-centTeslaautonomousdrivingaccident2).Forthecomplexandhigh-dimensionalreal-worldinputs,itisalmostimpossibleforhu-mantoensureallpossible,evencorner-casedataareincluded.TosystematicallytestanduncoverhiddendefectsofDNNs,itiscrucial1Inparticular,aDLsystemmayeitherbeentirelycomposedofDNNs,orhaveDNNsasitscorewithextrasoftwareencapsulation.Inthispaper,wemostlyfocusonDNNssinceitisthecoreofaDLsystem,andourmethodscouldbeextendedtosupportgeneralDLsystems.Althoughthetrainingprogramofthecurrentstate-of-the-artDNNsarestillwrittenastraditionalsoftware,theobtainedDNNfromthetrainingprogramisfundamentallydifferentinhowthelogicisencoded.2http://www.bbc.com/news/world-us-canada-43604440Layer 1(Input Layer)Layer 2(Hidden Layer)Layer 3(Output Layer)n1n2n3n4n5n6n7n8n9(a)All BehaviorsMain Behaviors(k-multisection Coverage)Corner-case Behaviors(Boundary Coverage)Erroneous Behaviors(b)Figure1:(a)AnexampleofafullyconnectedDNN.(b)Behav-iorsofDNNsandrelationsbetweendefinedcoveragecriteria(theredpointsdenoteerroneousbehaviorstherein).todefineasetofsuitablecoveragecriteriaforevaluatingthetestadequacyaswellasgaugingtheinternalcoveredstatesofDNNstogainconfidenceonthetestingresultsofDNNs.3COVERAGECRITERIAFORTESTINGDLSYSTEMSFortraditionalsoftwaretesting,developersdesignandseekasetofrepresentativetestdatafromthewholelargeinputspace,hopingthattheselectedtestdatacoulddetectthesoftwaredefectsunderlimitedcomputationalresources.3Testingcoveragecriteriaisproposedtoshatterandapproximatethesoftwareinternalstates.Itpartitionstheinputspaceandes-tablishestherelationofaninputsubspaceandanapproximatedsoftwareinternalstate.Inthisway,comparedwiththetestdatafromasingleinputsubspace,thesamenumberoftestdatafromdifferentinputsub-spaceswouldhaveahigherchancetocovermorediversesoftwarestates,resultinginahigherpossibilitytodetectmorediversesoftwaredefects.Overthepastdecades,asetofwell-designedcoveragecriteria[2](e.g.,statementcoverage,branchcoverage)havedemonstratedtheirpracticalvalueandarewidelyadoptedinsoftwareindustrytosystematicallyguidethetestingprocesstounveilthesoftwaredefectsatdifferentlevels,e.g.,(1)Unitlevel:testingsmallsnippetsoffunctions.(2)Integrationlevel:testingmultiplesub-modulesorfunctionstochecktheirinteractions.(3)Systemlevel:testingthesoftwaresystemasawhole.Thecurrentstate-of-the-practiceDNNtesting,however,isstillatitsearlystageandmainlyreliesonthepredictionaccuracy(similartoblack-boxsystemleveltestingthatonlyobservesinputsanditscorrespondingoutputs),lackingsystematictestingcoveragecriteriafordefectdetection.Furthermore,traditionalsoftwareandDNNshaveobviousdifferences,soexistingcoveragecriteriafortraditionalsoftwarecouldnotbedirectlyappliedtoDNNs.Inthissection,wedesignasetofDNNtestingcoveragecriteriafrommultiplelevels,aimingtogaugethetestingadequacyofDNNsandfacilitatethedetectionofthoseerroneousbehaviorsfrommul-tipleportrayals.Tobeusefultowardsindustrylevelapplications,webelievethatthetestcriteriashouldbesimple,scalableaswellgeneralenoughtobeappliedtoalargerangeofDNNswithoutconfiningonspecificDNNstructureoractivationfunctions.Con-ceptually,similartotraditionalsoftware,thebehaviorsofDNNscanbedividedintotwocategories,i.e.,majorfunctionbehaviors3Theinputspaceofasoftwarecouldbesolargethatitisoftenimpossibletoenumerateandtestallthepossibilitiesgivenlimitedcomputationresource.ASE’18,September3–7,2018,Montpellier,FranceMa,Xu,Zhang,Sun,Xue,Li,Chen,Su,Li,Liu,Zhao,andWangandcorner-casebehaviors,bothofwhichmaycontainerroneousbehaviors(seeFigure1(b)andourevaluationresultsinSection4).Wehavetakenthesefactorsintoconsiderationduringthedesignofcoveragecriteria.LetN={n1,n2,...}beasetofneuronsofaDNN.LetT={x1,x2,...}beasetoftestinputs.Weuseϕ(x,n)todenoteafunc-tionthatreturnstheoutputofaneuronn∈Nunderagiventestinputx∈T.4LettheDNNhavellayersandLidenotethesetofneuronsonthei-thlayer(1≤i≤l).3.1Neuron-LevelCoverageCriteriaAttheneuron-level,weusetheoutputvaluesofneuronndeter-minedfromthetrainingtocharacterizeitsbehaviors.SincetheinternallogicofaDNNismostlyprogrammedbytrainingdata,intuitively,thefunctionality(i.e.,neuronoutput)foreachneuronofaDNNshouldfollowsomestatisticaldistributionthatislargelyde-terminedbythetrainingdata.Theoutputdistributionofaneuronobtainedfromtrainingdataanalysiswouldallowtoapproximatelycharacterizethemajorfunctionregionswhoseoutputvaluesareoftentriggeredbyinputdatawithasimilarstatisticaldistributiontothetrainingdata,andthecornercaseswhoseoutputvaluesrarelyoccur.However,forapractical-sizedDNN,obtaininganaccurateoutputdistributionforeachneuronwouldbecomputationallyin-tensive.Withthesimilarspiritwhilebeingscalable,weleveragetheneuronoutputvalueboundariesobtainedfromtrainingdatatoapproximatethemajorfunctionregionandcorner-caseregion.Specially,foraneuronn,lethighnandlownbeitsupperandlowerboundaryoutputvalues,respectively,onthevaluerangeofitsactivationfunction,wherehighnandlownarederivedfromthetrainingdatasetanalysis.Wereferto[lown,highn]asthemajorfunctionregionofaneuronn.Definition3.1.Foratestinputx∈T,wesaythataDNNislocatedinitsmajorfunctionregiongivenxiff∀n∈N:ϕ(x,n)∈[lown,highn].Toexhaustivelycoverthemajorfunctionregions,wepartition[lown,highn]intoksections,andrequireeachofthemtobecov-eredbythetestinputs.Wenamethiscoverageask-multisectionneuroncoverage.(i)k-multisectionNeuronCoverage.Givenaneuronn,thek-multisectionneuroncoveragemeasureshowthoroughlythegivensetoftestinputsTcoverstherange[lown,highn].Toquantifythis,wedividetherange[lown,highn]intokequalsections(i.e.,k-multisections),fork>0.WewriteSnitodenotethesetofvaluesinthei-thsectionfor1≤i≤k.Ifϕ(x,n)∈Sni,wesaythei-thsectioniscoveredbythetestinputx.Therefore,foragivensetoftestinputsTandtheneuronn,itsk-multisectionneuroncoverageisdefinedastheratioofthenumberofsectionscoveredbyTandthetotalnumberofsections,i.e.,kinourdefinition.Wedefinethek-multisectioncoverageofaneuronnas:|{Sni|∃x∈T:ϕ(x,n)∈Sni}|k.4Thispaperfocusesonfeedforwardneuralnetworks.Forrecurrentneuralnetworks(RNNs),wecanunrollacertaindepthoflayersofanRNNandadaptϕ(x,n)bysettingxtobeaninputsequence.Wefurtherdefinethek-multisectionneuroncoverageofaDNNas:KMNCov(T,k)=˝n∈N|{Sni|∃x∈T:ϕ(x,n)∈Sni}|k×|N|.However,foraneuronn,therearealsocaseswhereϕ(x,n)maylocateoutof[lown,highn],i.e.,ϕ(x,n)∈(−∞,lown)orϕ(x,n)∈(highn,+∞).Wereferto(−∞,lown)∪(highn,+∞)asthecorner-caseregionofaneuronn.Definition3.2.Foratestinputx∈T,wesaythataDNNislocatedinitscorner-caseregiongivenxiff∃n∈N:ϕ(x,n)∈(−∞,lown)∪(highn,+∞).Notethattheprofiledoutputsofaneuronobtainedfromthetrainingdatawouldnotlocateintothecorner-caseregion.Inotherwords,iftestinputsfollowasimilarstatisticaldistributionwiththetrainingdata,aneuronoutputwouldrarelylocateincorner-caseregionaswell.Nevertheless,itdoesnotmeanthattestingthecornercasesofaneuronisnotimportantbecausedefectsofDNNscouldalsolocateinthecorner-caseregions(seeSection4.3).Tocoverthesecorner-caseregionsofDNNs,wedefinetwocoveragecriteria,i.e.,neuronboundarycoverageandstrongneu-ronactivationcoverage.Givenatestinputx,ifϕ(x,n)belongsto(−∞,lown)or(highn,+∞),wesaythecorrespondingcorner-caseregioniscovered.Toquantifythis,wefirstdefinethenumberofcoveredcorner-caseregionsasfollows:UpperCornerNeuron={n∈N|∃x∈T:ϕ(x,n)∈(highn,+∞)};LowerCornerNeuron={n∈N|∃x∈T:ϕ(x,n)∈(−∞,lown)}.(ii)NeuronBoundaryCoverage.Neuronboundarycoveragemeasureshowmanycorner-caseregions(w.r.t.bothoftheupperboundaryandthelowerboundaryvalues)havebeencoveredbythegiventestinputsetT.Itisdefinedastheratioofthenumberofcoveredcornercasesandthetotalnumberofcornercases(2×|N|):NBCov(T)=|UpperCornerNeuron|+|LowerCornerNeuron|2×|N|.SomerecentresearchonDNNsinterpretabilityempiricallyshowsthatthehyperactiveneuronsmightpotentiallydeliverusefullearn-ingpatternswithinDNNs[30,61].Basedonthisintuition,theproposedcoveragecriteriaintherestofthissectionfocusmoreonthehyperactiveneuroncases(e.g.,top-kneuroncoverageinthenextsubsection).Similartoneuronboundarycoverage,wefurtherdefinestrongneuronactivationcoveragetomeasurethecoveragestatusofupper-cornercases.(iii)StrongNeuronActivationCoverage.Strongneuronactiva-tioncoveragemeasureshowmanycornercases(w.r.t.theupperboundaryvaluehighn)havebeencoveredbythegiventestinputsT.Itisdefinedastheratioofthenumberofcoveredupper-cornercasesandthetotalnumberofcornercases(|N|):SNACov(T)=|UpperCornerNeuron||N|.3.2Layer-LevelCoverageCriteriaAtlayer-level,weusethetophyperactiveneuronsandtheircombi-nations(orthesequences)tocharacterizethebehaviorsofaDNN.Foragiventestinputxandneuronsn1andn2onthesamelayer,wesayn1ismoreactivethann2givenxifϕ(x,n1)>ϕ(x,n2).DeepGauge:Multi-GranularityTestingCriteriaforDeepLearningSystemsASE’18,September3–7,2018,Montpellier,FranceForthei-thlayer,weusetopk(x,i)todenotetheneuronsthathavethelargestkoutputsonthatlayergivenx.Forexample,inFigure1(a),assumeϕ(x,n1)andϕ(x,n3)arelargerthanϕ(x,n2),thetop-2neuronsonlayer1aren1andn3(depictedingreen).(i)Top-kNeuronCoverage.Thetop-kneuroncoveragemeasureshowmanyneuronshaveoncebeenthemostactivekneuronsoneachlayer.Itisdefinedastheratioofthetotalnumberoftop-kneuronsoneachlayerandthetotalnumberofneuronsinaDNN:TKNCov(T,k)=|—x∈T(—1≤i≤ltopk(x,i))||N|.TheneuronsfromthesamelayerofaDNNoftenplaysimilarrolesandthetopactiveneuronsfromdifferentlayersareimpor-tantindicatorstocharacterizethemajorfunctionalityofaDNN.Intuitively,tomorethoroughlytestaDNN,atestdatasetshoulduncovermoretopactiveneurons.(ii)Top-kNeuronPatterns.Givenatestinputx,thesequenceofthetop-kneuronsoneachlayeralsoformsapattern.InFigure1(a),assumetheneuronsingreenarethetop-2neuronsoneachlayer,thepatterncanberepresentedas({n1,n3},{n5,n6},{n8,n9}).Moreformally,apatternisanelementof2L1×2L2×···×2Ll,where2Liisthesetofsubsetsoftheneuronsoni-thlayer,for1≤i≤l.GiventhetestinputsetT,thenumberoftop-kneuronpatternsforTisdefinedas:TKNPat(T,k)=|{(topk(x,1),...,topk(x,l))|x∈T}|.Intuitively,thetop-kneuronpatternsdenotedifferentkindsofactivatedscenariosfromthetophyperactiveneuronsofeachlayer.4EXPERIMENTSWeimplementDeepGaugeonKeras2.1.3[10]withTensorFlow1.5.0backend[1],andapplytheproposedtestingcriteriatoDNNsforevaluationinthissection.4.1EvaluationSubjectsDatasetsandDNNModels.Weselecttwopopularpublicly-availabledatasets,i.e.,MNIST[32]andImageNet[42](seeTable1)foreval-uation.MNISTisforhandwrittendigitsrecognition,containing70,000inputdataintotal,ofwhich60,000aretrainingdataand10,000aretestdata.OnMNIST,weusethreepre-trainedLeNetfamilymodels(LeNet-1,LeNet-4,andLeNet-5)[32]foranalysis.Tofurtherdemonstratetheusefulnessofourcriteriatowardslargerscalereal-worldDLsystems,wealsoselectImageNet,alargesetofgeneralimagedataset(i.e.,ILSVRC-2012[42])forclassificationcontainingmorethan1.4milliontrainingdataand50,000testdatafrom1,000categories.TheDNNsweusedforImageNetarepre-trainedVGG-19[44]andResNet-50[24]models,bothofwhicharerelativelylargeinsizeandobtaincompetitiverecordsintheILSVRCcompetition[42],containingmorethan16,000and94,000neurons,and25and176layers,respectively.AsaDNNtestingcriteriontowardsfutureindustrylevelapplication,webelievethescalabilityup-toImageNet-likeorevenlargerdatasizeandmodelsizeisalmostindispensable.AdversarialTestInputGeneration.Besidesusingoriginaltestdataaccompaniedinthecorrespondingdatasetforcoverageevalu-ation,wefurtherexplorefourstate-of-the-artadversarialtestinputgenerationtechniques(i.e.,FGSM[20],BIM[31],JSMA[37],andCW[8])forcomparativestudy.EachoftheadversarialtechniquesgeneratesteststodetectDNN’spotentialdefectsthroughtheminorperturbationsonagiveninput,describedasfollows:•FGSMcraftsadversarialexamplesusinglossfunctionJ(Θ,x,y)withrespecttotheinputfeaturevector,whereΘdenotesthemodelparameters,xistheinput,andyistheoutputlabelofx,theadversarialexampleisgeneratedas:x∗=x+ϵsign(∇xJ(Θ,x,y)).•BIMappliesadversarialnoiseηmanytimesiterativelywithasmallparameterϵ,ratherthanoneηwithoneϵatatime,whichgivesarecursiveformula:x∗0=xandx∗i=clipx,ϵ(x∗i−1+ϵsign(∇x∗i−1J(Θ,x∗i−1,y))),whereclipx,ϵ(·)denotesaclippingofthevaluesoftheadversarialsamplesuchthattheyarewithinanϵ-neighborhoodoftheoriginalinputx.•JSMAisproposedfortargetedmisclassification.ForaninputxandaneuralnetworkF,theoutputofclassjisdenotedasFj(x).Toachieveatargetmisclassificationclasst,Ft(x)isincreasedwhiletheprobabilitiesFj(x)ofallotherclassesj,tdecrease,untilt=argmaxjFj(x).•Carlini/Wagner(CW):CarliniandWagnerrecentlyproposednewoptimization-basedattacktechniquewhichisarguablythemosteffectiveintermsoftheadversarialsuccessratesachievedwithminimalperturbation[8].Inprinciple,theCWattackistoapproximatethesolutiontothefollowingoptimizationproblem:argminx∗λL(x,x∗)−J(Θ,x∗,y),whereLisalossfunctiontomeasurethedistancebetweenthepredictionandthegroundtruth,andtheconstantλistobalancethetwolosscontributions.Inthispaper,weadopttheCW∞,whereeachpixelisallowedtobechangedbyuptoalimit.Figure2showsexamplesofthegeneratedtestsofthefourad-versarialtechniquesonthesampleddatafromMNISTtestset.Inthisexample,wecouldseethatcomparedwithFGSMandBIM,JSMAandCWperturbfewerpixelsonthesampledtestinput.Fur-thermore,giventhesameinputdatabutdifferentDNNs,thesametechniquewouldoftengeneratedifferentadversarialtestresults.Forexample,giventheinputimage7,JSMAgeneratesdifferentre-sultsonDNNs(i.e.,LeNet-1,LeNet-4andLeNet-5).Inotherwords,thestudiedadversarialtechniquesareoftenDNNdependent.4.2EvaluationSetupMNIST.OnMNISTdataset,eachimageissingle-channelofsize28×28×1.Beforetheevaluationstarts,wefirstobtaintheDNN’sneuronoutputstatisticalinformationthroughruntimeprofilingeachofthestudiedDNNs(i.e.,LeNet-1,LeNet-4,andLeNet-5)usingthe60,000trainingdata.Whentestingevaluationstarts,foreachDNNunderanalysis,werunthe10,000testdataonthemodeltoobtainthecorrespondingcoverage.ForeachstudiedDNN,wefurthergenerateanotherfoursetsofadversarialtestdatawhichcanexploredefectsofDL,5throughFGSM[20],BIM[31],JSMA[37],andCW[8].WeshowthatDeepGaugeisgeneralandeasytobetestedonthestate-of-the-artadversarialtestgenerationtechniques.Aftergeneratingthefouradversarialdatasets,weaggregateeachofthemwiththeoriginalMNISTtestdataset(withatotalsize20,000foreach),whichenablesustoperformthecomparativestudyon5Eachgeneratedadversarialdatasetisofthesamesizeastheoriginaltestset.ASE’18,September3–7,2018,Montpellier,FranceMa,Xu,Zhang,Sun,Xue,Li,Chen,Su,Li,Liu,Zhao,andWangBIMTest org.LeNet-1LeNet-4LeNet-5JSMACWFGSMBIMJSMACWFGSMBIMJSMACWFGSMTest org.FGSMBIMJSMACWFGSMBIMJSMACWFGSMBIMJSMACWLeNet-1LeNet-4LeNet-5Figure2:ExamplesoforiginalsampledtestdatafromMNISTincomparisontotheonesgeneratedbyeachadversarialtech-niqueonthecorrespondingstudiedDNNmodels.Table1:BreakdownsofdatasetsandDNNmodels.DataSetDatasetDNNModel#Neuron#LayerTestDataSourceDescriptionforEval.MNISTDigitrecog.LeNet-1527Testorg.&LeNet-41488FGSM/BIM/JSMA/CWLeNet-52689ImageNetGeneralimageVGG-1916,16825Testorg.&with1000-classesResNet-5094,059176FGSM/BIM/CWhowtheadversarialtestdataenhancesthedefectdetectionabilityfromourcoveragecriteriameasurement.Sincethestudiedadversar-ialtestgenerationtechniquesaremodeldependent,theadversarialdatasetsgeneratedbythesameadversarialtechniquesareactu-allydifferentforeachmodel,thoughthesamenumber(i.e.,five)datasetsareusedtoevaluateoneachmodel.Foreachadversarialtechnique,weactuallyuseittogeneratethreeadversarialdatasets,oneforeachofLeNet-1,LeNet-4,andLeNet-5,respectively.ThedetailedparameterconfigurationsforeachcriterionareshowninTable2,whereuandlaretheoutputupperbound(max-imalvalue)andlowerbound(minimalvalue)obtainedforeachneuronduringprofiling,respectively;σisthestandarddeviationoftheoutputsofaneuronduringprofiling.Althoughthedefinitionofneuronboundarycoverageandstrongneuronactivationcoveragearebasedonuandlalone(i.e.,neuronoutputUpperBound(UB)andLowerBound(LB)),itwouldalsobeinterestingtoseewhatresultscouldbeobtainedifwefurthertightencorner-caseregions(i.e.,increaseupperboundanddecreaselowerbound).Therefore,be-sidessettingUBandLBtouandlasdefinedinSection3.1,wealsoevaluateanothertwoconfigurationsbyincreasingUB(resp.decreasingLB)by0.5∗σandσforneuronboundarycoverageandstrongneuronactivationcoverage(seeTable2).Intotal,wehave3(models)×5(datasets)×14(criterionsettings)=210evaluationconfigurationsforMNIST.ImageNet.ImageNet(ILSVRC-2012)[42]ismorechallengingforevaluationduetoitslargedatasize(morethan1.4milliontrainingdata)aswellaslargeimagesize(224×224×3)forprocessing.Moreover,theDNNsthatachievehighaccuracyareoftencom-plex.ComparedwithLeNetfamilymodels,thestudiedVGG-19andResNet-50aremuchmorecomplexintermsofbothneuronsandlayers.Duetothecomputationalcomplexityofadversarialtestgen-erationonImageNetforanalysis,werandomlysampleimagesfromTable2:Theparameterconfigurationsforevaluation.DLCoverageCriteriaParameterConfigurationk-multisectionNeuronCov.(KMNC)k=1,000k=10,000N.A.NeuronBoundaryCov.(NBC)LB=lLB=l−0.5∗σLB=l−σUB=uUB=u+0.5∗σUB=u+σStrongNeuronActivationCov.(SNAC)UB=uUB=u+0.5∗σUB=u+σTop-kNeuronCov.(TKNC)k=1k=2k=3Top-kNeuronPatterns(TKNP)k=1k=2k=3eachofitslabeledcategoriesintheoriginalImageNettestdataset,withatotalnumberof5,000imagesasthetestdataforourevalu-ation.WealsotrytouseFGSM,BIM,JSMA,andCWtogenerateadversarialtestsforeachofthestudiedDNNs.However,weareun-abletosetupJSMAtorunsuccessfullyoneitherofthetwoDNNs.6Overall,wehaveatotalof2(models)×4(datasets)×14(criterionsettings)=112experimentalconfigurationsforImageNet.Tosupportsuchlargescaleevaluation,weruntheexperimentsonacomputercluster.EachclusternoderunsaGNU/LinuxsystemwithLinuxkernel3.10.0ona18-core2.3GHzXeon64-bitCPUwith196GBofRAMandalsoanNVIDIATeslaM40GPUwith24G.4.3ExperimentalResultsInourexperiments,wehaveseenusefultestingfeedbacksfrommultipleperspectiveswitheachtestingcriterion,showingsomeuniqueportrayaloftheruntimebehaviorofDNNs.Wefirstdescribesomeobtainedresultsandthensummarizeourfindings.74.3.1MNISTandImageNet.MNIST.AsshowninTable3,thecoverageofdifferentcriteriaobtainedbytheadversarialtechniquesgenerallyincreasecomparedwiththeoriginalMNISTtestdataset.Forinstance,asforLeNet-4,theJSMAincreasesthecoverageoftheoriginaltestsfrom39.7%to52.3%by31.7%in10,000-multisectionneuroncoverage,from9.1%to16.2%by78%inneuronboundarycoverage,from13.5%to27.7%by105%instrongneuronactivationcoverage,from62.2to66.2by6.6%intop-1neuroncoverage,andfrom787to1,395by77.3%intop-1neuronpatterns.TheincreaseofcoverageinfersthattheadversarialtestdataoverallexplorenewDNNs’internalstates,someofwhicharenot6ThiscouldbepotentiallycausedbythemassivedatasizeandthecomplexityofVGG-19andResNet-50.ThesimilarissueonJSMAwasalsoreportedinapreviouswork[57].7Duetothepagelimit,weputmoredetailedexperimentalresultdiscussion,aswellasdataplotonthepaper’saccompanyingwebsitehttps://deepgauge.github.io/.DeepGauge:Multi-GranularityTestingCriteriaforDeepLearningSystemsASE’18,September3–7,2018,Montpellier,FranceTable3:CoverageresultsofDeepGaugeonMNIST,LetNetmodels,andgeneratedtestsbyadversarialtechniques.TestingDNNEval.Config.Testorg.Testorg.Testorg.Testorg.Testorg.Criteria+FGSM+BIM+JSMA+CWLN-1k=1,00064.574.868.177.772.8k=10,00037.348.646.651.549.5KMNCLN-4k=1,00070.475.573.677.774.5(%)k=10,00039.749.750.252.350.1LN-5k=1,00068.572.071.573.871.2k=10,00037.246.047.648.846.8LN-1LB=l,UB=u43.347.149.046.244.2l-0.5*σ,u+0.5*σ17.321.221.218.317.3l-σ,u+σ8.78.78.79.68.7LN-4LB=l,UB=u9.112.213.916.210.5NBCl-0.5*σ,u+0.5*σ0.71.01.02.71.0(%)l-σ,u+σ0.30.30.31.00.3LN-5LB=l,UB=u8.610.511.613.49.1l-0.5*σ,u+0.5*σ1.72.11.93.02.0l-σ,u+σ1.11.31.31.71.1LN-1UB=u38.542.346.242.340.4UB=u+0.5*σ23.125.028.925.023.1UB=u+σ17.317.317.319.217.3LN-4UB=u13.516.218.927.713.5SNACUB=u+0.5*σ1.41.41.45.41.4(%)UB=u+σ0.70.70.72.00.7LN-5UB=u14.916.420.223.514.9UB=u+0.5*σ3.44.13.76.03.4UB=u+σ2.22.62.63.42.2LN-1k=161.561.561.563.561.5k=286.588.588.588.586.5k=392.392.392.392.392.3LN-4k=162.263.564.966.264.9TKNCk=279.179.780.481.880.4(%)k=385.187.287.886.586.5LN-5k=149.353.753.751.952.2k=263.866.867.566.066.0k=372.473.974.674.374.6LN-1k=176777710086k=29151,2711,1851,3251,270k=33,7166,0695,7086,5975,823LN-4k=17871,2101,1401,3951,389TKNPk=26,19011,18511,26812,14011,742k=39,30118,51518,49118,35618,194LN-5k=11,1362,1411,7752,0312,011k=26,94713,98712,61412,79712,456k=39,68419,36119,21519,20119,157coveredbytheoriginaltests.AssuchadversarialtestdatarevealdefectsofstudiedLeNetmodels,itindicatesthatgeneratingteststowardsimprovingthecoverageoftheproposedcriteriamightpo-tentiallytriggermorestatesofaDNN,incurringhigherchancesofdefectdetection,whichisconsistentwiththeusageoftestcoverageintraditionalsoftwaretesting.ImageNet.Thetestingcoverage(Table4)ontheImageNetsharessomesimilaritywithMNISTdatawhileshowingsomedifferences.VGG-19andResNet-50modelsaremuchlargerinsizeandcom-plexity,potentiallycausingtheobtainedcoveragelowerthanthatofLeNetinmanycases.Considerthe10,000-multisectionneuroncoverage,FGSMachieves48.6%onLeNet-1,butonly18.8%onVGG-19.Atfirstglance,itistemptingtodrawtheconclusionthataDNNwithhighercomplexityintermsofnumberofneuronsandlayersismoredifficulttobecoveredbytests.Ourresultsshowthatthismightnotbegenerallyapplicable.Forexample,theoriginaltestsachieves22.8%KMNC(k=10,000)onResNet-50,butonlyobtains13.5%onVGG-19,althoughResNet-50hasalargernumberofneuronsandlayers.ComparedwithMNIST,thegeneratedadver-sarialtestsonImageNetincurevenhigherincreaseontheneuronboundarycoverage(NBC)andstrongneuronactivationcoverage(SNAC)(Table4).Forexample,onResNet50underLB=landUB=uconfiguration,BIMincreasesthesetwocriteriaby280%(from4.1%to11.5%)and279%(from4.7%to13.1%),respectively.Table4:CoverageresultsonImageNet,VGG-19andResNet-50,andgeneratedtestsbyadversarialtechniques.TestingDNNEval.Config.Testorg.Testorg.Testorg.Testorg.Criteria+FGSM+BIM+CWVGG-19k=1,00032.236.938.035.7KMNCk=10,00013.518.819.118.5(%)ResNet-50k=1,00043.047.547.847.4k=10,00022.829.329.629.4VGG-19LB=l,UB=u2.88.77.42.9l-0.5*σ,u+0.5*σ1.54.03.41.5NBCl-σ,u+σ1.13.22.51.1(%)ResNet-50LB=l,UB=u4.16.911.54.7l-0.5*σ,u+0.5*σ1.52.16.01.7l-σ,u+σ0.91.23.90.9VGG-19UB=u4.610.59.84.7UB=u+0.5*σ3.08.06.83.1SNACUB=u+σ2.16.35.12.2(%)ResNet-50UB=u4.77.013.15.4UB=u+0.5*σ2.12.88.32.4UB=u+σ1.31.86.11.4VGG-19k=158.861.568.168.7k=274.376.280.881.2TKNCk=381.682.985.985.9(%)ResNet-50k=126.830.329.129.5k=236.038.638.338.3k=342.344.744.344.3VGG-19k=14,9998,2659,9899,816k=24,9999,5819,9989,816TKNPk=34,9999,9219,9989,816ResNet-50k=14,9999,9989,9989,948k=24,9999,9989,9989,948k=34,9999,9989,9989,948Thetop-1neuroncoverageobtainedbybothMNISTandIma-geNet(seeTable3(TKNC)andTable4(TKNC))showthatmanyneuronsofaDNNhavebeentriggeredintoatop-k(i.e.,1,2,and3inourevaluatedcases)hyperactivestates.Forexample,onVGG-19,thesampledoriginaltestsofImageNetachieve58.8%top-1neuroncoverage,and81.6%top-3neuroncoverage.Althoughthetop-kcoverageimprovementisnotthatobviouscomparedwithothercriteria,theadversarialdatastilltriggermoreneuronsastop-kactivatedneuronsinmanycases,whichdetectsthehiddendefects.Fordifferenttestinputdatasets,itisoftenthecasethatonlyafixedsubsetofneuronsofeachlayerwouldfunctionastophyper-activatedneurons.Thiswouldbeahintthatthetophyperactivatedneuronsofeachlayermightdescribethehigh-levelmajorfunctionskeletonofaneuronnetwork.Incomparisonwiththetop-kneuronpatterns(seeTable3(TKNP)andTable4(TKNP)),albeitmostofthetophyperactiveneuronsarerelativelystableforeachlayer,theircombinationstillcapturesthestructuraldifferenceofinputdata.8Thesetwolayer-levelcriteriaaltogetherprovideuswiththeinformationonwhichneuronsmatterthemostwithineachlayer;andthetop-kneuronpatternswouldmostlybeabletodifferentiatetheinputdatawhenkisproperlyselectedgivenatargetDNN.Thefindingsindicatethatgeneratingteststocovermoretop-kneuronpatternswouldhaveahigherchancetofinddefectsofaDNN.4.3.2FindingsandRemarks.Theoverallexperimentalresultsdemon-stratetheusefulnessofourproposedtestingcriteriaforDNNsandarealsohelpfultoexplainthedifferenceofthestate-of-the-practiceadversarialtechniquesformmultipleperspectives:•TheoriginaltestdataofMNISTandImageNetcoverboththeDNNsmajorfunctionregion(seeKMNC)aswellascorner-caseregion(seeNBCandSNAC)inTables3and4.Thisalsohappens8Ourin-depthinvestigationonthegeneratedtop-kneuronpatternsforImageNetshowthattherelativelylargepatterncoverageimprovement(evenforthetop-1case)isrelevanttothelarge#ofneuronsandlayersinVGG-19andResNet-50.ASE’18,September3–7,2018,Montpellier,FranceMa,Xu,Zhang,Sun,Xue,Li,Chen,Su,Li,Liu,Zhao,andWangtothegeneratedadversarialdatasets,showingthatadefectofDNNcanoccureitherinamajorfunctionregionoracorner-caseregion,bothofwhichshouldbeextensivelytested.•Thetestdatageneratedbyfourstudiedadversarialtechniques(combinedwithoriginaltestdata)generallyboostthecoverageofourcriteria.SinceanadversarialtestdatacouldpotentiallyrevealdefectsofaDLsystem,itmeansthatboostingthecoverageofourtestingcriteriacouldtosomeextentenhancethefaultdetectionability,whichisconsistentwiththepracticalpurposeoftestingcriteriawidelyadoptedintraditionalsoftwaretesting.ItalsoshowsthatourtestcriteriametricscouldcapturetheDNNs’internalbehavioraldifferenceofbenignandadversarialtestdata.Wenotethatincreasingthetestcoveragedoesnotnecessarilyimplythatnewdefectscouldbedetectedintraditionalsoftwaretesting.ThesameconclusionappliestoourcoveragecriteriaforDNNsaswell,thoughbetter-definedcoveragecriteriawouldbemuchmorepronouncedinfindingdefects.•Testdata(includingthegeneratedtestdatabyadversarial)eval-uatedonbothMNISTandImageNetmostlyobtainahigherk-multisectionneuroncoveragethantheneuronboundarycov-erageandstrongneuronactivationcoverage,revealingthatthetestdatacovermoreofthemajorfunctionregionthanthecorner-caseregionofaDNN.ThedesignoffutureDLtestingtechniquesshouldalsotakeaccountofcoveringcorner-caseregions.•Formostoftheevaluatedconfigurations,wefindthatahigherstrongneuronactivationcoverageismoreachievedthanitscorrespondingneuronboundarycoverage.ThismightbecausedbytheuniquecharacteristicsofthoseactivationfunctionsinourstudiedDNNs,whichmakesthelowerregion(smallvalue)moredifficulttobecoveredthantheupperregionofthestatisticalprofilingdistribution.9Thisobservationisconsistentwiththemodelswestudied,asLeNetfamily,VGG-19,andResNet-50alluseReLUasactivationfunctions,whichcouldmakethelowerregionsofaneuronmuchsmallerthantheupperregions.10Remark1.Ingeneral,forneuronboundarycoverageandstrongneuronactivationcoverage,thehigher(resp.lower)theneuron’supper(resp.lower)bound,thelessincrementoncoverageweobserve;fortop-kneuroncoverage,thelargerthevalueofk,thelessincrementoncoverage;fortop-kneuronpatterns,thelargerthevalueofk,themoreincrementonpatterns.Remark2.Forneuronboundarycoverageandstrongneu-ronactivationcoverage,the4adversarialtechniqueshavesufficientdiversityontheperformance,whichissimilartotraditionaltestgenerationwhichaimtocoverdifferentpoten-tialdefects.Specifically,weobservethattheadversarialtestsgeneratedbyCWarehardertobedistinguishedbythetestcoveragesincetheCWperturbationconcentratesmoreontheobjectswithsmallermagnitude,whichmaytriggerlessinternalbehaviorchangesofDNNs.9LeNet-1istheonlyexceptionalcase,whichmightbecausedbytheover-simplicityofitsnetwork.10Inparticular,ReLUfunctionpropagatesthepositiveoutputofaneurontothenextlayerwhileblockingthenegativeoutputbysettingittozero,whichstopsinfluencingitsfollowinglayers.0.0%20.0%40.0%60.0%80.0%100.0%LeNet-1LeNet-4LeNet-5Test orig.Test orig.+FGSMTest orig.+BIMTest orig.+JSMATest orig.+CW(1) Threshold=00.0%20.0%40.0%60.0%80.0%100.0%LeNet-1LeNet-4LeNet-599.3%100%100%99.3%100%100%99.3%100%100%99.6%100%100%99.3%100%100%Test orig.Test orig.+FGSMTest orig.+BIMTest orig.+JSMATest orig.+CW(1) Threshold=00.0%18.0%36.0%54.0%72.0%90.0%LeNet-1LeNet-4LeNet-585.5%83.1%78%86.2%81.8%80.8%86.2%85.1%80.8%86.9%85.8%80.8%85.1%79.1%73.1%(2) Threshold=0.20.0%16.0%32.0%48.0%64.0%80.0%LeNet-1LeNet-4LeNet-573.5%68.2%38.5%73.9%68.2%38.5%73.5%68.2%38.5%73.9%68.2%38.5%73.5%68.2%38.5%Test orig.Test orig.+FGSMTest orig.+BIMTest orig.+JSMATest orig.+CW(3) Threshold=0.50.0%14.0%28.0%42.0%56.0%70.0%LeNet-1LeNet-4LeNet-565.7%66.9%38.5%65.7%66.2%38.5%67.2%66.9%38.5%66%66.2%38.5%65.3%66.2%38.5%(4) Threshold=0.75Figure3:TheDeepXploreneuroncoverageresultsonMNISTdatasetunderdifferentthresholdconfigurations.4.4ComparisonwithDeepXplore’sNeuronCoverage(DNC)Peietal.[38]proposeakindofneuronactivationcoverageasthemeasurementfortestingdatadiversityofaDNNandarguethatthehighertheactivationcoverage,themorestatesofaDNNcouldbeexplored,withahigherchancefordefectsdetection.Akeyparame-terofDNCisauser-specifiedthreshold,andifanoutputofaneuronislargerthanthethreshold,theneuroniscountedascovered.TodemonstratethedifferencebetweenoursetofcriteriaandDNC,wesetuptheDNCevaluationwiththesamedataset,model,aswellasadversarialdatagenerationsettingsasdescribedinSection4.1.Forthethresholdparameter,wefirstsetthresholdstobe0and0.75,asusedin[38];tomakeanevenmorecomprehensivecomparison,wealsousetwoothersettings(i.e.,0.2and0.5).Figures3and4showthattheresultsofDNCobtainedontheoriginaltestdatasetandthedatasetgeneratedbyadversarialtechniquesforMNISTandImageNetarealmostthesameforallexperimentalsettings,indicatingthatDNCisunabletodifferentiatetheoriginaltestdatafromadversariallygeneratedones,whichtriggerthecorrectandincorrectbehaviorsofaDNN,respectively.ThismeansthatDNCcouldhardlycapturethedifferencebetweenoriginaltestdataandcorrespondingtestdatageneratedbyadversarialtechniques.How-ever,todetectthedefectsofDNNsinamorefine-grainedlevel,itisnecessarythatthecoveragecriteriacapturesuchminordifferences,wherethedefects(adversariallytriggeredstates)alsoliein.Ourfurtherin-depthinvestigationonDNCrevealsthat,thiscov-eragecriterionimposesseverallimitations:(1)DNCusesthesamethresholdastheactivationevaluationforalltheneurons.However,wefindthattheoutputstatisticaldistributionofdifferentneuronsarequitediverse.Givenatestsuiteforanalysis,theoutputsofsomeneuronsmayexhibitquiteasmallvariancewithalargemeanvalue,whileothersmighthavealargevariancewithalowmeanvalue.Therefore,usingthesamethresholdforallneuronswith-outconsideringthedisparityinneuron’sfunctionaldistributionswouldgreatlydiminishtheaccuracy.Forexample,givenaneu-ronwithverysmallmeanandstandarddeviation,evenaslightlylargeruser-specifiedthresholdwouldgenerallydeterminethatthisneuroncannotbecovered.(2)DNCnormalizesthedynamicrangeDeepGauge:Multi-GranularityTestingCriteriaforDeepLearningSystemsASE’18,September3–7,2018,Montpellier,France0%20%40%60%80%100%VGG19ResNet5099.99%99.92%99.99%99.92%99.99%99.92%99.99%99.92%Test orig.Test orig.+FGSMTest orig.+BIMTest orig.+CW(1) Threshold=00%18%36%54%72%90%VGG19ResNet5088.4%69%88.6%69.4%88.7%68.9%87.9%68.5%(2) Threshold=0.20%20%40%60%80%100%VGG19ResNet50Test orig.Test orig.+FGSMTest orig.+BIMTest orig.+CW(1) Threshold=00%16%32%48%64%80%VGG19ResNet5071%57.2%71.3%57.2%71.1%57.2%70.6%57.2%Test orig.Test orig.+FGSMTest orig.+BIMTest orig.+CW(3) Threshold=0.50%12%24%36%48%60%VGG19ResNet509.1%56.7%9.4%56.7%9.3%56.7%8.6%56.5%(4) Threshold=0.75Figure4:TheDeepXploreneuronactivationcoverageresultsonImageNetdatasetfordifferentthresholdsettings.ofneuronoutputsaccordingtomaxandminoutputofneuronsonthecorrespondinglayerforeachinputimageunderanalysis.Thisraisesanissuethatthesamenormalizedactivationvalue(e.g.,0.3)meansdifferentlyfordifferentinputdata,asthemaxandminoutputofeachlayermightchangeforeachinput,whichrendersthenotionof“largerthanagiventhreshold”inconsistentamongdifferentinputs.Doingsowillalsoeliminatetherelativityinactivationmagnitudeamongdifferentinputs,whichisaveryimportantpropertytosupportthefindingsofneuronactivationcoverage.Weinsteadspecifytheupperandlowerboundsforeachneuronobtainedfromtheanalysisonthetrainingdataset,asopposedtoeachindividualinput.Inotherwords,ourmethodreliesonthestatisticsofthetrainingsetwhichisusedtodeterminethemainfunctionalityoftheDNNsystem.4.5ThreatstoValidityandDiscussionTheselectionofevaluationsubjects(i.e.,datasetandDNNmod-els)couldbeathreattovalidity.Wetrytocounterthisbyusingthecommonly-studiedMNISTdatasetandthepracticallarge-scaledatasetImageNet;foreachstudieddataset,weusethewell-knownpre-trainedmodelsofdifferentsizesandcomplexityrangingfrom52neuronsuptomorethan90,000neurons.Eventhough,someofourresultsmightnotgeneralizetootherdatasetsandDNNmodels.Anotherthreatcouldbecausedbytheconfigurablehyper-parametersinthecoveragecriteriadefinition.Asacountermeasurewhileconsideringthelimitedcomputationalresources,weevaluateeachcriterionwithdifferentsettings,andanalyzetheinfluenceoftheparametersoncriteriaaccuracy.Eventhough,itmightstillnotcoverthebestparameteruse-cases.Forexample,ourevaluationstudiedk=1,000andk=10,000fork-multisectionneuroncover-age.Weleavetheoptimizedhyper-parameterselectioninourfuturework.Furtherthreatcouldbecausedbythequalityoftrainingdatausedfordistribution(i.e.,theintervalrange)analysisofneuronoutput.Inthispaper,weconsiderpubliclyavailablewell-pretrainedDNNmodelsaccompaniedbytrainingdatawithgoodquality.Foradversarialtestgeneration,weselectfourpopularstate-of-the-practicetechniquestosimulatedefectsfromdifferentsourcesandgranularity.Weeitherfollowtheauthors’suggestedsettingsorusetheirdefaultsettings.Moreover,tomakecomprehensivecom-parisonswithDeepXplore’sneuroncoverage(DNC),weevaluateDNCwithmultiplethresholdsettings.5RELATEDWORKInthissection,weattempttoreviewthemostrelevantworkinthreeaspects:testing,verification,andsecurityofDLsystems.5.1TestingofDLSystemsTraditionalpracticesinmeasuringmachinelearningsystemsmainlyrelyonprobingtheiraccuracyontestinputswhicharerandomlydrawnfrommanuallylabeleddatasetsandadhocsimulations[54].However,suchblack-boxtestingmethodologymaynotbeabletofindvariouskindsofcorner-casebehaviorsthatmayinduceun-expectederrors[19].Wickeretal.[53]recentlyproposedaScaleInvariantFeatureTransformfeatureguidedblack-boxtestingandshoweditscompetitivenesswithCWandJSMAalongthisdirection.Peietal.[38]proposedawhite-boxdifferentialtestingalgorithmforsystematicallyfindinginputsthatcantriggerinconsistenciesbetweenmultipleDNNs.TheyintroducedneuroncoverageformeasuringhowmuchoftheinternallogicofaDNNhasbeentested.However,itstillexhibitsseveralcaveatsasdiscussedinSec-tion4.4.DeepTest[49]investigatesabasicsetofimagetransforma-tions(e.g.,scaling,shearing,androtation)fromOpenCVandshowsthattheyareusefultodetectdefectsinDNN-drivenautonomouscars.Alongthisdirection,DeepRoad[59]usesinputimagescenetransformationandshowsitspotentialitywithtwoscenes(i.e.,snowyandrainy)forautonomousdrivingtesting.Thescenetrans-formationisobtainedthroughtrainingagenerativeadversarialnetwork(GAN)withapairofcollectedtrainingdatathatcoverthestatisticalfeaturesofthetwotargetscenes.Comparedwithtraditionalsoftware,thedimensionandpotentialtestingspaceofaDNNisoftenquitelarge.DeepCT[35]adaptstheconceptofcombinatorialtesting,andproposesasetofcoveragebasedontheneuroninputinteractionforeachlayerofDNNs,toguidetestgenerationtowardsachievingreasonabledefectdetec-tionabilitywitharelativelysmallnumberoftests.InspiredbytheMC/DCtestcriteriaintraditionalsoftware[29],Sunetal.[47]proposedasetofadaptedMC/DCtestcriteriaforDNNs,andshowthatgeneratingtestsguidedbytheproposedcriteriaonsmallscaleneuralnetworks(consistingofDenselayerswithnomorethan5hiddenlayersand400neurons)exhibitshigherdefectdetectionabilitythanrandomtesting.However,whetherMC/DCcriteriascaletoreal-world-sizedDLsystemsstillneedsfurtherinvestiga-tion.InsteadofobservingtheruntimeinternalbehaviorsofDNNs,DeepMutation[34]proposestomutateDNNs(i.e.,injectingfaultsASE’18,September3–7,2018,Montpellier,FranceMa,Xu,Zhang,Sun,Xue,Li,Chen,Su,Li,Liu,Zhao,andWangeitherfromthesourcelevelormodellevel)toevaluatethetestdataquality,whichcouldpotentiallybeusefulfortestdataprioritizationinrespectofrobustnessonagivenDNN.Ourworkofproposingmulti-granularitytestingcoverageforDLsystemsismostlyorthogonaltotheexistingwork.Comparedwiththeextensivestudyontraditionalsoftwaretesting,testingDLisstillatanearlystage.MostexistingworkonDLtestinglackssomesuitablecriteriatounderstandandguidethetestgenerationprocess.Sincetestgenerationguidedbycoveragecriteria(e.g.,statementcoverage,branchcoverage)towardstheexplorationofdiversesoft-warestatesfordefectdetectionhasbecomethedefactostandardintraditionalsoftwaretesting[5,16,17,33],thestudytodesignsuitabletestingcriteriaforDLisdesperatelydemanding.Thispapermakesanearlyattempttowardsthisdirectionbyproposingasetoftestingcriteria.Ourcriterianotonlycandifferentiatestate-of-the-artadversarialtestgenerationtechniques,butalsopotentiallybeusefulforthemeasurementoftestsuitediversitybyanalyzingtheDNNs’internalstatesfrommultipleportrayals.WebelievethatourproposedcriteriasetupanimportantcornerstoneandbringanewopportunitytodesignmoreeffectiveautomatedtestingtechniquesguidedbytestingcriteriaforDLsystems.5.2VerificationofDLSystemsFormalmethodscanprovideformalguaranteesaboutsafetyandrobustnessofverifiedDLsystems[22,28,39,40,50,53].Themainconcernofformalmethodsaretheirscalabilityforreal-world-sized(e.g.,100,000neuronsorevenmore)DLsystems.Theearlyworkin[40]providedanabstraction-refinementap-proachtocheckingsafetypropertiesofmulti-layerperceptrons.Theirapproachhasbeenappliedtoverifyanetworkwithonly6neurons.DLV[53]canverifylocalrobustnessofDLsystemsw.r.t.asetofuserspecifiedmanipulations.Reluplex[28]isasoundandcompleteSMT-basedapproachtoverifyingsafetyandrobustnessofDLsystemswithReLUactivationfunctions.ThenetworksverifiedbyReluplexin[28]have8layersand300ReLUnodes.DeepSafe[22]usesReluplexasitsverificationengineandhasthesamescala-bilityproblemasReluplex.AI2[50]isasoundanalyzerbasedonabstractinterpretationthatcanreasonaboutsafetyandrobustnessofDLsystems.IttradesprecisionforscalabilityandscalesbetterthanReluplex.TheprecisionofAI2dependsonabstractdomainsusedintheverification,anditmightfailtoproveapropertywhenitactuallyholds.VERIVIS[39]canverifysafetypropertiesofDLsystemswhenattackersareconstrainedtomodifytheinputsonlythroughgiventransformationfunctions.However,real-worldtrans-formationscanbemuchmorecomplexthanthetransformationfunctionsconsideredinthepaper.5.3AttacksandDefensesofDLSystemsAplethoraofresearchhasshownthatdeeplearningsystemscanbefooledbyapplyingcarefullycraftedadversarialperturbationaddedtotheoriginalinput[6–9,20,48,55,60],manyofwhicharebasedongradientoroptimizationtechniques.However,itstilllacksextensivestudyonhowtheseadversarialtechniquesdifferentiateintermsofDNNs’internalstates.Inthisstudy,wemakeanearlyattempttowardssuchadirectionbasedonourproposedcriteria.Withtherapiddevelopmentofadversarialattacktechniques,extensivestudieshavebeenperformedtocircumventadversarialattacks.Gallowayetal.[18]recentlyobservethatlow-precisionDNNsexhibitimprovedrobustnessagainstsomeadversarialat-tacks.Thisisprimarilyduetothestochasticquantizationinneuralnetworkweights.Ensembleadversarialtraining[51],GANbasedapproaches[43,45],randomresizingandrandompadding[56],gametheory[13],anddifferentiablecertificate[41]methodsareallinvestigatedtodefendagainstadversarialexamples.Byapplyingimagetransformations,suchastotalvarianceminimizationandimagequilting,veryeffectivedefensescanbeachievedwhenthenetworkistrainedontheaforementionedtransformedimages[23].Formoreextensivediscussiononcurrentstate-of-the-artdefensetechniques,wereferreadersto[4].Ourproposedtestingcriteriaenablethequantitativemeasure-mentofdifferentadversarialattacktechniquesfromthesoftwareengineeringperspective.Thiscouldbepotentiallyhelpfulforun-derstandingandinterpretingDNNs’behaviors,basedonwhichmoreeffectiveDNNdefensetechniquecouldbedesigned.Infuturework,itwouldbealsointerestingtoexaminehowtointegratetheproposedtestingcriteriaintotheDLdevelopmentlifecycletowardsbuildinghighqualityDLsystems.6CONCLUSIONANDFUTUREWORKThewideadoptionofDLsystems,especiallyinmanysafety-criticalareas,hasposedaseverethreattoitsqualityandgeneralizationproperty.ToeffectivelymeasurethetestingadequacyandlaydownthefoundationtodesigneffectiveDLtestingtechniques,wepro-poseasetoftestingcriteriaforDNNs.Ourexperimentsontwowell-knowndatasets,fiveDNNswithdiversecomplexity,andfourstate-of-the-artadversarialtestingtechniquesshowthatthetestsgeneratedbytheadversarialtechniquesincurobviousincreasesofthecoverageintermsofthemetricsdefinedinthepaper.ThisdemonstratesthatDeepGaugecouldbeausefulindicatorforevalu-atingtestingadequacyofDNNs.Tothebestofourknowledge,ourworkisamongtheearlystudiestoproposetestingcriteriaforDLsystems.WeexpectthattheproposedtestingcriteriacouldbeparticularlyamenabletoDLtestinginthewild.Inthenextstep,wewillcontinuetoexplorealternativetestingcriteriaforDNNs,suchasthecombinationofbothhyperactiveandhypoactiveneurons.WealsoplantostudytheproposedtestingcriteriaguidedautomatedtestgenerationtechniquesforDNNs.WehopethatourstudynotonlyprovidesanavenuetoilluminatethenatureandmechanismofDNNs,butalsolaysthefoundationtowardsunderstandingandbuildinggenericandrobustDLsystems.ACKNOWLEDGMENTSThisworkwaspartiallysupportedbyNationalKeyR&DProgramofChina2017YFC1201200and2017YFC0907500,FundamentalRe-searchFundsforCentralUniversitiesofChinaAUGA5710000816,JSPSKAKENHIGrant18H04097.WegratefullyacknowledgethesupportofNVIDIAAITechCenter(NVAITC)toourresearch.Wealsoappreciatetheanonymousreviewersfortheirinsightfulandconstructivecomments.DeepGauge:Multi-GranularityTestingCriteriaforDeepLearningSystemsASE’18,September3–7,2018,Montpellier,FranceREFERENCES[1]MartinAbadi,PaulBarham,JianminChen,ZhifengChen,AndyDavis,JeffreyDean,MatthieuDevin,SanjayGhemawat,GeoffreyIrving,MichaelIsard,Man-junathKudlur,JoshLevenberg,RajatMonga,SherryMoore,DerekG.Murray,BenoitSteiner,PaulTucker,VijayVasudevan,PeteWarden,MartinWicke,YuanYu,andXiaoqiangZheng.2016.TensorFlow:ASystemforLarge-scaleMa-chineLearning.In12thUSENIXSymposiumonOperatingSystemsDesignandImplementation(OSDI16).265–283.[2]PaulAmmannandJeffOffutt.2008.IntroductiontoSoftwareTesting(1ed.).CambridgeUniversityPress,NewYork,NY,USA.[3]CyrilleArtho,QuentinGros,GuillaumeRousset,KazuakiBanzai,LeiMa,TakashiKitamura,MasamiHagiya,YoshinoriTanabe,andMitsuharuYamamoto.2017.Model-BasedAPITestingofApacheZooKeeper.In2017IEEEInt.Conf.onSoftwareTesting,VerificationandValidation(ICST2017).Tokyo,Japan,288–298.[4]AnishAthalye,NicholasCarlini,andDavidWagner.2018.ObfuscatedGradientsGiveaFalseSenseofSecurity:CircumventingDefensestoAdversarialExamples.InProceedingsofthe35thInternationalConferenceonMachineLearning,ICML2018.https://arxiv.org/abs/1802.00420[5]BenoitBaudryandMartinMonperrus.2015.TheMultipleFacetsofSoftwareDiversity:RecentDevelopmentsinYear2000andBeyond.ACMComputingSurveys(CSUR)48,1(2015),16.[6]WielandBrendel,JonasRauber,andMatthiasBethge.2018.Decision-BasedAd-versarialAttacks:ReliableAttacksAgainstBlack-BoxMachineLearningModels.InICLR.[7]NicholasCarliniandDavidWagner.2017.AdversarialExamplesarenotEasilyDetected:BypassingTenDetectionMethods.InProceedingsofthe10thACMWorkshoponArtificialIntelligenceandSecurity.ACM,3–14.[8]NicholasCarliniandDavidWagner.2017.TowardsEvaluatingtheRobustnessofNeuralNetworks.InIEEESymposiumonSecurityandPrivacy.39–57.[9]SenChen,MinhuiXue,LinglingFan,ShuangHao,LihuaXu,HaojinZhu,andBoLi.2018.AutomatedPoisoningAttacksandDefensesinMalwareDetectionSystems:AnAdversarialMachineLearningApproach.Computers&Security73(2018),326–344.[10]FrançoisCholletetal.2015.Keras.https://github.com/fchollet/keras.[11]DanCiregan,UeliMeier,andJürgenSchmidhuber.2012.Multi-columnDeepNeuralNetworksforImageClassification.InCVPR.3642–3649.[12]DanCiresan,AlessandroGiusti,LucaMGambardella,andJürgenSchmidhu-ber.2012.DeepNeuralNetworksSegmentNeuronalMembranesinElectronMicroscopyImages.InNIPS.2843–2851.[13]GuneetS.Dhillon,KamyarAzizzadenesheli,JeremyD.Bernstein,JeanKossaifi,AranKhanna,ZacharyC.Lipton,andAnimashreeAnandkumar.2018.StochasticActivationPruningforRobustAdversarialDefense.InICLR.[14]AriloC.DiasNeto,RajeshSubramanyan,MarlonVieira,andGuilhermeH.Travas-sos.2007.ASurveyonModel-basedTestingApproaches:ASystematicReview.InProc.1stACMInt’lWorkshoponEmpiricalAssessmentofSoftwareEngineeringLanguagesandTechnologies.31–36.[15]ECSS.2009.Spaceengineering-Software.[16]RobertFeldt,RichardTorkar,TonyGorschek,andWasifAfzal.2008.SearchingforCognitivelyDiverseTests:TowardsUniversalTestDiversityMetrics.InPro-ceedingsofthe2008IEEEInternationalConferenceonSoftwareTestingVerificationandValidationWorkshop.IEEE,178–186.[17]GordonFraserandAndreaArcuri.2013.WholeTestSuiteGeneration.IEEETrans.Softw.Eng.39,2(Feb.2013),276–291.https://doi.org/10.1109/TSE.2012.14[18]AngusGalloway,GrahamW.Taylor,andMedhatMoussa.2018.AttackingBinarizedNeuralNetworks.InICLR.[19]IanGoodfellowandNicolasPapernot.2017.TheChallengeofVerificationandTestingofMachineLearning.[20]IanJGoodfellow,JonathonShlens,andChristianSzegedy.2015.ExplainingandHarnessingAdversarialExamples.InICLR.[21]GoogleAccident.2016.AGoogleSelf-drivingCarCausedaCrashfortheFirstTime.https://www.theverge.com/2016/2/29/11134344/google-self-driving-car-crash-report[22]DivyaGopinath,GuyKatz,CorinaS.Pasareanu,andClarkBarrett.2018.Deep-Safe:AData-drivenApproachforCheckingAdversarialRobustnessinNeuralNetworks.InternationalSymposiumonAutomatedTechnologyforVerificationandAnalysis(ATVA)(2018).[23]ChuanGuo,MayankRana,MoustaphaCisse,andLaurensvanderMaaten.2018.CounteringAdversarialImagesusingInputTransformations.InICLR.[24]KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016.DeepResidualLearningforImageRecognition.InCVPR.770–778.[25]WarrenHe,BoLi,andDawnSong.2018.DecisionBoundaryAnalysisofAdver-sarialExamples.InICLR.[26]GeoffreyHinton,LiDeng,DongYu,GeorgeEDahl,Abdel-rahmanMohamed,NavdeepJaitly,AndrewSenior,VincentVanhoucke,PatrickNguyen,TaraNSainath,etal.2012.DeepNeuralNetworksforAcousticModelinginSpeechRecognition:TheSharedViewsofFourResearchGroups.IEEESignalProcessingMagazine29,6(2012),82–97.[27]YueJiaandMarkHarman.2011.AnAnalysisandSurveyoftheDevelopmentofMutationTesting.IEEETrans.Softw.Eng.37,5(Sept.2011),649–678.[28]GuyKatz,ClarkW.Barrett,DavidL.Dill,KyleJulian,andMykelJ.Kochenderfer.2017.Reluplex:AnEfficientSMTSolverforVerifyingDeepNeuralNetworks.InternationalConferenceonComputerAidedVerification(CAV)(2017).[29]HayhurstKellyJ.,VeerhusenDanS.,ChilenskiJohnJ.,andRiersonLeannaK.2001.APracticalTutorialonModifiedCondition/DecisionCoverage.TechnicalReport.[30]BeenKim,MartinWattenberg,JustinGilmer,CarrieCai,JamesWexler,FernandaViegas,etal.2018.InterpretabilitybeyondFeatureAttribution:QuantitativeTestingwithConceptActivationVectors(TCAV).InInternationalConferenceonMachineLearning.2673–2682.[31]AlexeyKurakin,IanGoodfellow,andSamyBengio.2017.AdversarialExamplesinthePhysicalWorld.ICLR(2017).[32]YannLeCun,LéonBottou,YoshuaBengio,andPatrickHaffner.1998.Gradient-basedLearningAppliedtoDocumentRecognition.Proc.IEEE86,11(1998),2278–2324.[33]LeiMa,CyrilleArtho,ChengZhang,HiroyukiSato,JohannesGmeiner,andRudolfRamler.2015.GRT:Program-Analysis-GuidedRandomTesting(T).InProceedingsofthe201530thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering(ASE)(ASE’15).IEEEComputerSociety,Washington,DC,USA,212–223.https://doi.org/10.1109/ASE.2015.49[34]LeiMa,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,FeiJuefei-Xu,ChaoXie,LiLi,YangLiu,JianjunZhao,andYadongWang.2018.DeepMutation:MutationTestingofDeepLearningSystems.InternationalSymposiumonSoftwareReliabilityEngineering(ISSRE)(2018).[35]LeiMa,FuyuanZhang,MinhuiXue,BoLi,YangLiu,JianjunZhao,andYadongWang.2018.CombinatorialTestingforDeepLearningSystems.arXivpreprintarXiv:1806.07723(2018).[36]GlenfordJ.Myers,CoreySandler,andTomBadgett.2011.TheArtofSoftwareTesting(3rded.).WileyPublishing.[37]NicolasPapernot,PatrickMcDaniel,SomeshJha,MattFredrikson,ZBerkayCelik,andAnanthramSwami.2016.TheLimitationsofDeepLearninginAdversarialSettings.InSecurityandPrivacy(EuroS&P),2016IEEEEuropeanSymposiumon.IEEE,372–387.[38]KexinPei,YinzhiCao,JunfengYang,andSumanJana.2017.Deepxplore:Auto-matedWhiteboxTestingofDeepLearningSystems.InProceedingsofthe26thSymposiumonOperatingSystemsPrinciples.1–18.[39]KexinPei,YinzhiCao,JunfengYang,andSumanJana.2017.TowardsPracticalVerificationofMachineLearning:TheCaseofComputerVisionSystems.CoRRabs/1712.01785(2017).arXiv:1712.01785http://arxiv.org/abs/1712.01785[40]LucaPulinaandArmandoTacchella.2010.AnAbstraction-RefinementApproachtoVerificationofArtificialNeuralNetworks.InInternationalConferenceonComputerAidedVerification.Springer,243–257.[41]AditiRaghunathan,JacobSteinhardt,andPercyLiang.2018.CertifiedDefensesagainstAdversarialExamples.InICLR.[42]OlgaRussakovsky,JiaDeng,HaoSu,JonathanKrause,SanjeevSatheesh,SeanMa,ZhihengHuang,AndrejKarpathy,AdityaKhosla,MichaelBernstein,AlexanderC.Berg,andLiFei-Fei.2015.ImageNetLargeScaleVisualRecognitionChallenge.IJCV115,3(2015),211–252.[43]PouyaSamangouei,MayaKabkab,andRamaChellappa.2018.Defense-GAN:ProtectingClassifiersAgainstAdversarialAttacksUsingGenerativeModels.InICLR.[44]KarenSimonyanandAndrewZisserman.2015.VeryDeepConvolutionalNet-worksforLarge-scaleImageRecognition.ICLR(2015).[45]YangSong,TaesupKim,SebastianNowozin,StefanoErmon,andNateKushman.2018.PixelDefend:LeveragingGenerativeModelstoUnderstandandDefendagainstAdversarialExamples.InICLR.[46]TingSu,KeWu,WeikaiMiao,GeguangPu,JifengHe,YutingChen,andZhendongSu.2017.ASurveyonData-FlowTesting.ACMComputingSurveys(CSUR)50,1,Article5(March2017),35pages.ASE’18,September3–7,2018,Montpellier,FranceMa,Xu,Zhang,Sun,Xue,Li,Chen,Su,Li,Liu,Zhao,andWang[47]Y.Sun,X.Huang,andD.Kroening.2018.TestingDeepNeuralNetworks.ArXive-prints(March2018).arXiv:cs.LG/1803.04792[48]ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,IanGoodfellow,andRobFergus.2014.IntriguingPropertiesofNeuralNetworks.InICLR.[49]YuchiTian,KexinPei,SumanJana,andBaishakhiRay.2018.DeepTest:AutomatedTestingofDeep-Neural-Network-drivenAutonomousCars.InInternationalCon-ferenceonSoftwareEngineering(ICSE).ACM.[50]DanaDrachsler-CohenPetarTsankovSwaratChaudhuriMartinVechevTi-monGehr,MatthewMirman.2018.AI2:SafetyandRobustnessCertificationofNeuralNetworkswithAbstractInterpretation.InIEEESymposiumonSecurityandPrivacy(SP).[51]FlorianTramèr,AlexeyKurakin,NicolasPapernot,IanGoodfellow,DanBoneh,andPatrickMcDaniel.2018.EnsembleAdversarialTraining:AttacksandDe-fenses.InICLR.[52]MarkUttingandBrunoLegeard.2007.PracticalModel-BasedTesting:AToolsApproach.MorganKaufmannPublishersInc.,SanFrancisco,CA,USA.[53]MatthewWicker,XiaoweiHuang,andMartaKwiatkowska.2018.Feature-GuidedBlack-BoxSafetyTestingofDeepNeuralNetworks.InternationalConferenceonToolsandAlgorithmsfortheConstructionandAnalysisofSystems(TACAS)(2018).[54]IanHWitten,EibeFrank,MarkAHall,andChristopherJPal.2016.DataMining:PracticalMachineLearningToolsandTechniques.MorganKaufmann.[55]ChaoweiXiao,Jun-YanZhu,BoLi,WarrenHe,MingyanLiu,andDawnSong.2018.SpatiallyTransformedAdversarialExamples.InICLR.[56]CihangXie,JianyuWang,ZhishuaiZhang,ZhouRen,andAlanYuille.2018.MitigatingAdversarialEffectsthroughRandomization.InICLR.[57]WeilinXu,DavidEvans,andYanjunQi.2018.FeatureSqueezing:DetectingAdversarialExamplesinDeepNeuralNetworks.InNetworkandDistributedSystemSecuritySymposium(NDSS).[58]FangyiZhang,JürgenLeitner,MichaelMilford,BenUpcroft,andPeterCorke.2015.TowardsVision-basedDeepReinforcementLearningforRoboticMotionControl.arXiv:1511.03791(2015).[59]M.Zhang,Y.Zhang,L.Zhang,C.Liu,andS.Khurshid.2018.DeepRoad:GAN-basedMetamorphicAutonomousDrivingSystemTesting.ArXive-prints(Feb.2018).arXiv:cs.SE/1802.02295[60]ZhengliZhao,DheeruDua,andSameerSingh.2018.GeneratingNaturalAdver-sarialExamples.InICLR.[61]BoleiZhou,YiyouSun,DavidBau,andAntonioTorralba.2018.RevisitingtheIm-portanceofIndividualUnitsinCNNsviaAblation.arXivpreprintarXiv:1806.02891(2018).[62]HongZhu,PatrickA.V.Hall,andJohnH.R.May.1997.SoftwareUnitTestCoverageandAdequacy.ACMComputingSurvey29,4(Dec.1997),366–427.