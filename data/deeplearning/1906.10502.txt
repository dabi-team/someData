1
2
0
2

p
e
S
3
2

]
E
S
.
s
c
[

3
v
2
0
5
0
1
.
6
0
9
1
:
v
i
X
r
a

SampleFix: Learning to Generate Functionally
Diverse Fixes

Hossein Hajipour1, Apratim Bhattacharyya2, Cristian-Alexandru Staicu1, and
Mario Fritz1

1 CISPA Helmholtz Center for Information Security, Germany
2 Max Planck Institute for Informatics, Germany

Abstract. Automatic program repair holds the potential of dramati-
cally improving the productivity of programmers during the software
development process and correctness of software in general. Recent ad-
vances in machine learning, deep learning, and NLP have rekindled the
hope to eventually fully automate the process of repairing programs.
However, previous approaches that aim to predict a single ﬁx are prone
to fail due to uncertainty about the true intend of the programmer.
Therefore, we propose a generative model that learns a distribution over
potential ﬁxes. Our model is formulated as a deep conditional variational
autoencoder that can eﬃciently sample ﬁxes for a given erroneous pro-
gram. In order to ensure diverse solutions, we propose a novel regularizer
that encourages diversity over a semantic embedding space. Our evalua-
tions on common programming errors show for the ﬁrst time the gener-
ation of diverse ﬁxes and strong improvements over the state-of-the-art
approaches by ﬁxing up to 45% of the erroneous programs. We addition-
ally show that for the 65% of the repaired programs, our approach was
able to generate multiple programs with diverse functionalities.

Keywords: Program repair · Generative models · Conditional varia-
tional autoencoder.

1

Introduction

Software development is a time-consuming and expensive process. Unfortunately,
programs written by humans typically come with bugs, so signiﬁcant eﬀort needs
to be invested to obtain code that is only likely to be correct. Debugging is also
typically performed by humans and can contain mistakes. This is neither de-
sirable nor acceptable in many critical applications. Therefore, automatically
locating and correcting program errors [11] oﬀers the potential to increase pro-
ductivity as well as improve the correctness of software.

Advances in deep learning [17,18], computer vision [9,26], and NLP [30,3]
have dramatically boosted the machine’s ability to automatically learn repre-
sentations of natural data such as images and natural language contents for
various tasks. Deep learning models also have been successful in learning the
distribution over continuous [29,16] and discrete data [21,14], to generate new

 
 
 
 
 
 
2

H. Hajipour et al.

and diverse data points [10]. These advances in machine learning and the advent
of large corpora of source code [1] provide new opportunities toward harnessing
deep learning methods to understand, generate, or debug programs.

Fig. 2: SampleFix captures the inherent ambiguity of the possible ﬁxes by sam-
pling multiple potential ﬁxes for the given erroneous real-world program. Poten-
tial ﬁxes with the same functionality are highlighted with the same color and
the newly added tokens are underlined.

Prior works in automatic program repair
predominantly rely on expert-designed rules
and error models that describe the space of
the potential ﬁxes [27,8]. Such hand-designed
rules and error models are not easily adapt-
able to the new domains and require a time-
consuming process.
In contrast,

learning-based approaches
provide an opportunity to adapt such models
to the new domain of errors. Therefore, there
has been an increasing interest to carry over
the success stories of deep learning in NLP
and related techniques to employ learning-
based approaches to tackle the “common pro-
gramming errors” problem [13,12]. Such investigations have included compile-
time errors such as missing scope delimiters, adding extraneous symbols, using
incompatible operators. Novice programmers and even experienced developers
often struggled with these types of errors [25], which is usually due to lack of
attention to the details of programs and/or programmer’s inexperience.

Fig. 1: Our SampleFix approach
with diversity regularizer pro-
motes sampling of diverse ﬁxes,
that account for the inherent
uncertainty in the automated
debugging task.

Recently, Gupta et al. [13] proposed a deep sequence to sequence model called
DeepFix where, given an erroneous program, the model predicts the locations
of the errors and a potential ﬁx for each predicted location. The problem is for-
mulated as a deterministic task, where the model is trained to predict a single
ﬁx for each error. However, diﬀerent programs – and therefore also their ﬁxes –
can express the same functionality. Besides, there is also uncertainty about the
intention of the programmer. Figure 1 illustrates the issue. Given an erroneous
program (buggy program), there is a large number of programs within a cer-

SampleFix: Learning to Generate Functionally Diverse Fixes

3

tain edit distance. A subset of these, will result in successful compilation. The
remaining programs will still implement diﬀerent functionalities and – without
additional information or assumptions – it is impossible to tell which program/-
functionality was intended. In addition, previous work [28] also identiﬁed overﬁt-
ting as one of the major challenges for learning-based automatic program repair.
We believe that one of the culprits for this is the poor objectives used in the
training process, e.g., training a model to generate a particular target ﬁx.

Let us consider the example in Figure 2 from the dataset of DeepFix [13]. This
example program is incorrect due to the imbalanced number of curly brackets. In
a traditional scenario, a compiler would warn the developer about this error. For
example, when trying to compile this code with GCC, the compiler terminates
with the error “expected declaration or statement at end of input”, indicating
line 10 as the error location. Experienced developers would be able to understand
this cryptic message and proceed to ﬁxing the program. Based on their intention,
they can decide to add a curly bracket either at line 6 (patch P1) or at line 9
(patch P2). Both these solutions would ﬁx the compilation error in the erroneous
program, but the resulting solutions have diﬀerent semantics.

Hence, we propose a deep generative framework to automatically correct pro-
gramming errors by learning the distribution of potential ﬁxes. We investigate
diﬀerent solutions to model the distribution of the ﬁxes and sample multiple ﬁxes,
including diﬀerent variants of Conditional Variation Autoencoders (CVAE) and
beam search decoding. It turns out (as we will also show in our experiments)
CVAE and beam search decoding are complementary, while CVAE is compu-
tationally more eﬃcient in comparison to beam search decoding. Furthermore,
we encourage diversity in the candidate ﬁxes through a novel regularizer which
penalizes similar ﬁxes for an identical erroneous program and signiﬁcantly in-
creases the eﬀectiveness of our approach. The candidate ﬁxes in Figure 2 are
generate by our approach, illustrating its potential for generating both diverse
and correct ﬁxes. For a given erroneous program, our approach is capable of
generating diverse ﬁxes to resolve the syntax errors.

To summarize, the contributions of this paper are as follows, 1. We propose
an eﬃcient generative method to automatically correct common programming
errors by learning the distribution over potential ﬁxes. 2. We propose a novel
regularizer to encourage the model to generate diverse ﬁxes. 3. Our generative
model together with the diversity regularizer shows an increase in the diver-
sity and accuracy of ﬁxes, and a strong improvement over the state-of-the-art
approaches.

2 Related Work

Our work builds on the general idea of sequence-to-sequence models as well as
ideas from neural machine translation. We phrase our approach as a variational
auto-encoder and compare it to prior learning-based program repair approaches.
We review the related work in order below:

4

H. Hajipour et al.

2.1 Neural Machine Translation

Sutskever et al. [30] introduces neural machine translation and casts it as a
sequence-to-sequence learning problem. The popular encoder-decoder architec-
ture is introduced to map the source sentences into target sentences. One of the
major drawbacks of this model is that the sequence encoder needs to compress
all of the extracted information into a ﬁxed-length vector. Bahdanau et al. [3]
addresses this issue by using attention mechanism in the encoder-decoder archi-
tecture, where it focuses on the most relevant part of encoded information by
learning to search over the encoded vector. In our work, we employ a sequence-
to-sequence model with attention to parameterize our generative model. This
model gets an incorrect program as input and maps it to many potential ﬁxes
by drawing samples on the estimated distribution of the ﬁxes.

2.2 Variational Autoencoders

The variational autoencoders [16,24] is a generative model designed to learn deep
directed latent variable based graphical models of large datasets. The model is
trained on the data distribution by maximizing the variational lower bound
of the log-likelihood as the objective function. Bowman et al. [5] extend this
framework by introducing an RNN-based variational autoencoder to enable the
learning of latent variable based generative models on text data. The proposed
model is successful in generating diverse and coherent sentences. To model con-
ditional distributions for the structured output representation Sohn et al. [29]
extended variational autoencoders by introducing an objective that maximizes
the conditional data log-likelihood. In our approach, we employ an RNN-based
conditional variational autoencoder to model the distribution of the potential
ﬁxes given erroneous programs. Variational autoencoder approaches enable the
eﬃcient sampling of accurate and diverse ﬁxes.

2.3 Learning-based Program Repair

Recently there has been a growing interest in using learning-based approaches
to automatically repair the programs [22]. Long and Rinard [20] proposed a
probabilistic model by designing code features to rank potential ﬁxes for a given
program. Pu et al. [23] employ an encoder-decoder neural architecture to auto-
matically correct programs. In these works and many learning-based program-
ming repair approaches, enumerative search over programs is required to resolve
all errors. However, our proposed framework is capable of predicting the location
and potential ﬁxes by passing the whole program to the model. Besides this, un-
like our approach, which only generates ﬁxes for the given erroneous program,
Pu et al. [23] need to predict whole program statements to resolve the errors.

There are two important program repair tasks explored in the literature:
ﬁxing syntactic errors and ﬁxing semantic ones. While in the current work we
propose a technique for ﬁxing syntactic errors, we believe that our observation

SampleFix: Learning to Generate Functionally Diverse Fixes

5

about the diversity of the ﬁx has implications for the approaches aimed at re-
pairing semantic bugs as well. Most of the recent work in this domain aim to
predict a unique ﬁx, often extracted from a real-world repository. For example,
Getaﬁx [2], a recent approach for automatically repairing six types of semantic
bugs, is evaluated on a set of 1,268 unique ﬁxes written by developers. Similarly,
DLﬁx [19] considers a bug to be ﬁxed only if it exactly matches a patch pro-
vided by the developer. While this is an improved methodology in the spirit of
our proposal it is highly dependent on the performance of the test suite oracle
which may not always capture the developer’s intent.

DeepFix [13], RLAssist [12], and DrRepair [32] uses neural representations
to repair syntax errors in programs. In detail, DeepFix [13] uses a sequence-
to-sequence model to directly predict a ﬁx for incorrect programs. In contrast,
our generative framework is able to generate multiple ﬁxes by learning the dis-
tribution of potential correctness. Therefore, our model does not penalize, but
rather encourages diverse ﬁxes. RLAssist [12] repairs the programs by employ-
ing a reinforcement learning approach. They train an agent that navigate over
the program to locate and resolve the syntax errors. In this work, they only
address the typographic errors, rely on a hand-designed action space, and meet
problems due to the increasing size of the action space. In contrast, our method
shows improved performance on typographic errors and also generalizes to issues
with missing variable declaration errors by generating diverse ﬁxes.

In a recent work, Yasunaga and Liang [32] proposed DrRepair to resolve
the syntax error by introducing a program feedback graph. They connect the
relevant symbols in the source code and the compile error messages and employ
the graph neural network on top to model the process of the program repair.
In this work, they rely on the compiler error messages which can be helpful,
but it also limits the generality of the method. However, our proposed approach
does not rely on additional information such as compiler error messages, and
it resolves the errors by directly modeling the underlying distribution of the
potential correct ﬁxes.

3 SampleFix: Generative Model for Diversiﬁed Code

Fixes

Repairing the common program errors is a challenging task due to ambiguity in
potential corrections and lack of representative data. Given a single erroneous
program and a certain number of allowed changes, there are multiple ways to
ﬁx the program resulting in diﬀerent styles and functionality. Without further
information, the true, intended style and/or functionality remains unknown.
In order to account for this inherent ambiguity, we propose a deep generative
model to learn a distribution over potential ﬁxes given the erroneous program –
in contrast to predicting a single ﬁx. We frame this challenging learning problem
as a conditional variational autoencoders (CVAE). However, standard sampling
procedures and limitations of datasets and their construction make learning and
generation of diverse samples a challenge. We address this issue by a beam

6

H. Hajipour et al.

search decoding scheme in combination with a novel regularizer that encourages
diversity of the samples in the embedding space of the CVAE.

Fig. 3: Overview of SampleFix at inference time, highlighting the generation of
diverse ﬁxes.

Figure 3 provides an overview of our proposed approach at inference time.
For a given erroneous program, the generative model draws T intermediate,
candidate ﬁxes ˆy from the learned conditional distribution. We use a compiler
to select a subset of promising intermediate candidate ﬁxes based on the number
of remaining errors. This procedure is applied iteratively until arrive at a set of
candidate ﬁxes within the maximum number of prescribed changes. We then
select a ﬁnal set of candidate ﬁxes that compile, have unique syntax according
to our measure described below (Subsection 3.5).

In the following, we formulate our proposed generative model with the diver-

sity regularizer and provide details of our training and inference process.

3.1 Conditional Variational Autoencoders for Generating Fixes

Conditional Variational Autoencoders (CVAE) [29], model conditional distribu-
tions pθ(y|x) using latent variables z. The conditioning introduced through z
enables the modelling of complex multi-modal distributions. As powerful trans-
formations can be learned using neural networks, z itself can have a simple
distribution which allows for eﬃcient sampling. This model allows for sampling
from pθ(y|x) given an input sequence x, by ﬁrst sampling latent variables ˆz
from the prior distribution p(z). During training, amortized variational infer-
ence is used and the latent variables z are learned using a recognition network
qφ(z|x, y), parametrized by φ. In detail, the variational lower bound of the model
(Equation 1) is maximized,

log(p(y|x)) ≥ Eqφ(z|x,y) log(pθ(y|z, x))

− DKL(qφ(z|x, y), p(z|x)).

(1)

Penalizing the divergence of qφ(z|x, y) to the prior in Equation 1 allows for
sampling from the prior p(z) during inference. In practice, the variational lower
bound is estimated using Monte-Carlo integration,

ˆLCVAE =

1
T

T
(cid:88)

i=1

log(pθ(y|ˆzi, x))

− DKL(qφ(z|x, y), p(z|x)) .

(2)

Generative Seq2Seq ModelInput program xŷ1:ŷ2:ŷ3:ŷ4:3   int  a  =  2,  b  =  3,  c3   int  a  =  2,  c;4   int  a  =  2,  c;3   int  a  =  2,  b  =  3,  c;Selecting fixes.........Diversecandidate fixesSampleFix: Learning to Generate Functionally Diverse Fixes

7

where, ˆzi ∼ qφ(z|x, y), and T is the number of samples. We cast our model for
resolving program errors in the Conditional Variational Autoencoder framework.
Here, the input x is the erroneous program and y is the ﬁx.

However, the plain CVAE as described in [29] suﬀers from diversity issues.
Usually, the drawn samples do not reﬂect the true variance of the posterior
p(y|x). This would amount to the correct ﬁx potentially missing from our can-
didate ﬁxes. To mitigate this problem, next we introduce an objective that aims
to enhance the diversity of our candidate ﬁxes.

3.2 Enabling Diverse Samples using a Best of Many Objective

Here, we introduce the diversity enhancing objective that we use. Casting our
model in the Conditional Variational Autoencoder framework would enable us
to sample a set of candidate ﬁxes for a given erroneous program. However, the
standard variational lower bound objective does not encourage diversity in the
candidate ﬁxes. This is because the average likelihood of the candidate ﬁxes is
considered. In detail, as the average likelihood is considered, all candidate ﬁxes
must explain the “true” ﬁx in training set well. This discourages diversity and
constrains the recognition network, which is already constrained to maintain a
Gaussian latent variable distribution. In practice, the learned distribution fails
to fully capture the variance of the true distribution. To encourage diversity, we
employ ”Many Samples” (MS) objective proposed by Bhattacharyya et al. [4],

ˆLMS = log (cid:0) 1
T

T
(cid:88)

i=1

pθ(y|ˆzi, x)(cid:1)

− DKL(qφ(z|x, y), p(z|x)) .

(3)

In comparison to Equation 2, this objective (Equation 3) encourages diversity
in the model by allowing for multiple chances to draw highly likely candidate
ﬁxes. This enables the model to generate diverse candidate ﬁxes, while maintain-
ing high likelihood. In practice, due to numerical stability issues, we use ”Best of
Many Samples” (BMS) objective, which is an approximation of 3. This objective
retains the diversity enhancing nature of Equation 3 while being easy to train,

ˆLBMS = max

i

(cid:0) log(pθ(y|ˆzi, x))(cid:1)

− DKL(qφ(z|x, y), p(z|x)) .

(4)

3.3 DS-SampleFix: Encouraging Diversity with a Diversity-sensitive

Regularizer

To increase the diversity using Equation 4 we need to use a substantial number of
samples during training. This is computationally prohibitive especially for large
models, as memory requirements and computation time increases linearly in the
number of such samples. On the other hand, for a small number of samples, the
objective behaves similarly to the standard CVAE objective as the recognition

8

H. Hajipour et al.

network has fewer and fewer chances to draw highly likely samples/candidate
ﬁxes, thus limiting diversity. Therefore, in order to encourage the model to gen-
erate diverse ﬁxes even with a limited number of samples, we propose a novel
regularizer that aims to increase the distance between the two closest candidate
ﬁxes (Equation 5). This penalizes generating similar candidate ﬁxes for a given
erroneous program and thus encourages diversity in the set of candidate ﬁxes.
In comparison to Equation 4, we observe considerable gains even with the use of
only T = 2 candidate ﬁxes. In detail, we maximize the following objective

ˆLDS-BMS = max

i

(cid:0) log(pθ(y|ˆzi, x))(cid:1) + min

i,j

d(ˆyi, ˆyj)

−DKL(qφ(z|x, y), p(z|x)) .

(5)

ˆyi, ˆyj(cid:111)
(cid:110)

Distance Metric. Here, we discuss the distance metric d in Equation 5. Note,
can be of diﬀerent lengths. Therefore, we ﬁrst pad
that the samples
the shorter sample to equalize lengths. Empirically, we ﬁnd that the Euclidean
distance performs best. This is mainly because, in practice, Euclidean distance
is easier to optimize.

3.4 Beam Search Decoding for Generating Fixes

Beam search decoding is a classical model to generate multiple outputs from a
sequence-to-sequence model [31,7]. Given the distributions pθ(y|x) of a sequence-
to-sequence model we can generate multiple outputs by unrolling the model in
time and keeping the top-K tokens at each time step, where K is the beam width.
In our generative model, we employ beam search algorithm to sample multiple
ﬁxes. In detail, we decode with beam width of size K for each sample z and in
total for T samples from p(z). We set T = 100 during inference.

3.5 Selecting Diverse Candidate Fixes

We extend the iterative repair procedure introduced by Gupta et al. [13] in the
context of our proposed generative model, where the iterative procedure now
leverages multiple candidate ﬁxes. Given an erroneous program, the generative
model outputs T candidate ﬁxes. Each ﬁx contains a potential erroneous line
with the corresponding ﬁx. So in each iteration we only edit one line of the given
program. To select the best ﬁxes, we take the candidate ﬁxes and the input
erroneous program, reconcile them to create T updated programs. We evaluate
these ﬁxes using a compiler, and select up to the best N ﬁxes, where N ≤ T .
We only select the unique ﬁxes which do not introduce any additional error
messages. In the next iterations, we feed up to N programs back to the model.
These programs are updated based on the selected ﬁxes of the previous iteration.
We keep up to N programs with the lower number of error messages over the
iterations. At the end of the repairing procedure, we obtain multiple potential
candidate ﬁxes. In the experiments where we are interested in a single repaired
program, we pick the best ﬁx with the highest probability score according to our
deep generative model.

SampleFix: Learning to Generate Functionally Diverse Fixes

9

3.6 Model Architecture and Implementation Details

To ensure a fair comparison, our gener-
ative model is based on the sequence-to-
sequence architecture, similar to Gupta et
al. [13]. Figure 4 shows the architecture
of our approach in detail. Note that the
recognition network is available to encode
the ﬁxes to latent variables z only dur-
ing training. All of the networks in our
framework consists of 4-layers of LSTM
cells with 300 units. The network is opti-
mized using Adam optimizer [15] with the
default setting. We use T = 2 samples to train our models, and T = 100 samples
during inference. To process the program through the networks, we tokenize the
programs similar to the setting used by Gupta et al. [13].

Fig. 4: Overview of network archi-
tecture.

During inference, the conditioning erroneous program x is input to the en-
coder, which encodes the program to the vector v. To generate multiple ﬁxes
using our decoder, the code vector v along with a sample of z from the prior p(z)
is input to the decoder. For simplicity, we use a standard Gaussian N (0, I) prior,
although more complex priors can be easily leveraged. The decoder is unrolled
in time and output logits (pθ(y|ˆzi, x)).

4 Experiments

We evaluate our approach on the task of repairing common programming errors.
We evaluate the diversity and accuracy of our sampled error corrections as well
as compare our proposed method with the state of the art.

4.1 Dataset

We use the dataset published by Gupta et al. [13] as it’s sizable and includes
real-world data. It contains C programs written by students in an introductory
programming course. The dataset consists of 93 diﬀerent tasks that were writ-
ten by students in an introductory programming course. The programs were
collected using a web-based system [6]. These programs have token lengths in
the range [75, 450], and contain typographic and missing variable declaration
errors. To tokenize the programs and generate training and test data diﬀerent
type of tokens, such as types, keywords, special characters, functions, literals and
variables are used. The dataset contains two sets of data which are called syn-
thetic and real-world data. The synthetic data contains the erroneous programs
which are synthesized by mutating correct programs written by students. The
real-world data contains 6975 erroneous programs with 16766 error messages.

4.2 Evaluation

10

H. Hajipour et al.

Table 2: Results of performance comparison of DeepFix, RLAssist, DrRepair,
Beam search (BS), SampleFix , DS-SampleFix, and DS-SampleFix + BS. Typo,
Miss Dec, and All refer to typographic, missing variable declarations, and all of
the error messages respectively. Speed denotes computational time for sampling
100 ﬁxes. ¸denotes successfully compiled programs, while (cid:13) refers to resolved
error messages.

Models

Typo

Miss Dec

All

Speed (s)

¸

(cid:13)

¸

(cid:13)

¸

(cid:13)

23.3% 30.8% 10.1% 12.9% 33.4% 40.8%
26.6 % 39.7 %

-
DeepFix [13]
-
RLAssist [12]
-
DrRepair [32]
4.82
Beam search (BS)
0.88
SampleFix
DS-SampleFix
0.88
DS-SampleFix + BS 27.8% 45.6% 19.2% 47.9% 45.2% 65.2% 1.17

25.9% 42.2% 20.3% 47.0% 44.7% 63.9%
24.8% 38.8% 16.1% 22.8% 40.9% 56.3%
27.7% 40.9% 16.7% 24.7% 44.4% 61.0%

-
34.0%

-
-

-
-

-
-

-

-

Table 1: Results of performance com-
parison of DeepFix, Beam search
(BS), SampleFix ,and DS-SampleFix
on synthetic data. Typo, Miss Dec,
and All refer to typographic, missing
variable declarations, and all of the
errors respectively.

We evaluate our approach on synthetic
and real-world data. To evaluate our ap-
proach on the synthetic test set we ran-
domly select 20k pairs. This data con-
tains pairs of erroneous programs with
the intended ﬁxes. To evaluate our ap-
proach on real-world data we use a real-
world set of erroneous programs. Unlike
synthetic test set, we don’t have access
to the intended ﬁx(es) in the real-world
data. However, we can check the correct-
ness of the program using the evaluator
(compiler). Following the prior work, we
train two networks, one for typographic
errors and another to ﬁx missing variables declaration errors. Note that there
might be an overlap between the error resolved by the network for typographic
errors and the network for missing variables declaration errors, so we also provide
the overall results of the resolved error messages.

84.7% 78.8% 82.0%
DeepFix
Beam search (BS) 91.8% 89.5% 90.7%
86.8% 86.5% 86.6%
SampleFix
95.6% 88.1% 92.2%
DS-SampleFix

Typo Miss Dec All

Models

Synthetic Data. Table 1 shows the comparison of our proposed approaches,
Beam search (BS), SampleFix and DS-SampleFix, with DeepFix [13] on the
synthetic data in the ﬁrst iteration. In this table (Table 1), we can see that our
approaches outperform DeepFix in generating intended ﬁxes for the typographic
and missing variable declaration errors. Beam search (BS), SampleFix and DS-
SampleFix generate 90.7%, 86.6%, and 92.2% of the intended ﬁxes respectively.

SampleFix: Learning to Generate Functionally Diverse Fixes

11

Real-World Data. In Table 2 we compare our approaches, with state-of-the-art
approaches (DeepFix [13], RLAssist [12], and DrRepair [32]) on the real-world
data. In our experiments (Table 2) we show the performance of beam search
decoding, CVAEs (SampleFix), and our proposed diversity-sensitive regularizer
(DS-SampleFix). Furthermore, we show that DS-SampleFix can still take ad-
vantage of beam search algorithm (DS-SampleFix + BS). To do that, for each
sample z we decode with beam width of size 5, and to sample 100 ﬁxes we draw
20 samples from p(z). We also provide the sampling speed in terms of sampling
100 ﬁxes for a given program using an average over 100 runs. The running time
results show that CVAE-based models are at least 4x faster than beam search in
sampling the ﬁxes. In this experiment, we feed the programs up to 5 iterations.

Table 2 shows that our approaches outperform DeepFix [13], RLAssist [12],
and DrRepair [32] in resolving the error messages. This shows that generat-
ing multiple diverse ﬁxes can lead to substantial improvement in performance.
Beam search, SampleFix, DS-SampleFix, and DS-SampleFix + BS resolve 63.9%,
56.3%, 61.0%, and 65.2% of the error messages respectively. Overall, our DS-
SampleFix + BS is able to resolve all compile-time errors of the 45.2% of the pro-
grams - around 12% points improvement over DeepFix and 11% points improve-
ment over DrRepair. Furthermore, the performance advantage of DS-SampleFix
over SampleFix shows the eﬀectiveness of our novel regularizer.

Note that DrRepair [32] has achieved further improvements by relying on the
compiler. While utilizing the compiler output seems to be beneﬁcial, it also limits
the generality of the approach. For a fair comparison, we report the performance
of DrRepair without the compiler output, but consider informing our model by
the compiler output an interesting avenue of future work.

Fig. 5: An example illustrating that our DS-SampleFix can generate diverse ﬁxes.
Left: Example of a program with a typographic error. The error, i.e., missing
bracket, is highlighted at line 13. Right: Our DS-SampleFix proposes multiple
ﬁxes for the given error (line number with the corresponding ﬁx), highlighting
the ability of DS-SampleFix to generate diverse and accurate ﬁxes.

12

H. Hajipour et al.

Qualitative Example. We illustrate diverse ﬁxes generated by our DS-SampleFix
in Figure 5 using a code example with typographic errors, with the corresponding
two output samples of DS-SampleFix. In the examples given in Figure 5, there
is a missing closing curly bracket after line 13. We can see that DS-SampleFix
generates multiple correct ﬁxes to resolve the error in the given program. This
indicates that our approach is capable of handling the inherent ambiguity and
uncertainty in predicting ﬁxes for the erroneous programs. The two ﬁxes in Fig-
ure 5 are unique and compileable ﬁxes that implement diﬀerent functionalities
for the given erroneous program. Note that generating multiple diverse ﬁxes
gives the programmers the opportunity of choosing the desired ﬁx(es) among
the compileable ones, based on their intention.

Generating Functionally Diverse Programs. Given an erroneous program,
our approach can generate multiple potential ﬁxes that result in a successful
compilation. Since we do not have access to the user’s intention, it is desirable
to suggest multiple potential ﬁxes with diverse functionalities. Here, we evaluate
our approach in generating multiple programs with diﬀerent functionalities.

In order to assess diﬀerent functionalities, we use the following approach
based on tests. The dataset of Gupta et al. [13] consists of 93 diﬀerent tasks.
The description of each task, including the input/output format, is provided in
the dataset. Based on the input/output format, we can provide input examples
for each task. To measure the diversity in functionality of the programs in each
task, we generate 10 input examples. For instance, given a group of programs
for a speciﬁc task, we can run each program using the input examples and get
the outputs. We consider two programs to have diﬀerent functionalities if they
return diﬀerent outputs given the same input example(s).

In order to generate multiple programs we use our iterative selecting strat-
egy (Subsection 3.5). In each iteration, we keep up to N programs with the
less number of error messages over the iterations. At the end of the repairing
procedure, we obtain multiple repaired programs. As discussed (Figure 1), a sub-
set of these programs will successfully compile. In this experiment, we use the
real-world test set, and we set N = 50 as this number is large enough to allow
us to study the diversity of the ﬁxes, without incurring an unnecessarily large
load on our infrastructure. Our goals in the remaining of this section are: 1. For
each erroneous program, to measure the number of generated unique ﬁxes that
successfully compile. 2. For each erroneous program, to measure the number of
generated programs with diﬀerent functionalities.

Figure 6a and Figure 6b show the syntactic diversity of the generated pro-
grams, and the diversity in functionality of these programs, respectively. In Fig-
ure 6a we show the percentage of the successfully compiled programs with unique
ﬁxes for a given erroneous program. The x-axis refers to the number of gener-
ated and successfully compiled unique programs, and y-axis to the percentage of
repaired programs for which these many unique ﬁxes were generated. For exam-
ple, for almost 20% of the repaired programs, DS-SampleFix + BS generates two

SampleFix: Learning to Generate Functionally Diverse Fixes

13

(a) Diversity of the generated programs.

(b) Diversity of the functionality of the
generated programs.

Fig. 6: The results show the performance of Beam search (BS), SampleFix , DS-
SampleFix , and DS-SampleFix + BS. (a) Percentage of the number of the gen-
erated successfully compiled, unique programs for the given erroneous programs.
(b) Percentage of the successfully compiled programs with diﬀerent functionali-
ties for the given erroneous programs.

unique ﬁxes. Overall, we can see that DS-SampleFix and DS-SampleFix + BS
generate more diverse programs in comparison to the other approaches.

Table 3: Results of performance compar-
ison of Beam Search (BS), SampleFix ,
DS-SampleFix , and DS-SampleFix +BS on
generating diverse programs. Diverse Prog
refers to the percentage of cases where the
models generate at least two or more suc-
cessfully compiled unique programs. Diverse
Func denotes the percentage of cases where
the models generate at least two or more
programs with diﬀerent functionalities.

Figure 6b shows the percent-
age of the successfully compiled
programs with diﬀerent function-
alities, for a given erroneous pro-
gram. Here, the x-axis refers to
the number of the generated func-
tionally diﬀerent programs, and
y-axis refers to the percentage of
erroneous programs with at least
one ﬁx, for which we could gener-
ate that many diverse ﬁxes. One
can observe that in many cases,
e.g., up to 60% of the times for
SampleFix, the methods gener-
ate programs corresponding to a
single functionality. However, in
many other cases they generate
functionally diverse ﬁxes. For example, in almost 10% of the cases, DS-SampleFix
generate 10 or more ﬁxes with diﬀerent functionalities. In Figure 6b we can see
that all of the approaches have higher percentage for generating program with
the same functionality in comparison to the results in Figure 6a. This indicates
that for some of the given erroneous programs, we generate multiple unique
programs with approximately the same functionality. These results show that

Beam search
SampleFix
DS-SampleFix
DS-SampleFix + BS

45.1%
34.9%
53.4%
60.4%

55.6%
44.6%
68.8%
69.5%

Diverse Prog Diverse Func

Models

14

H. Hajipour et al.

DS-SampleFix and DS-SampleFix + BS generate programs with more diverse
functionalities in comparison to the other approaches.

In Table 3 we compare the performance of our approaches in generating di-
verse programs and functionalities. We provide results for all of our four ap-
proaches, i.e., Beam search (BS), SampleFix , DS-SampleFix , and DS-SampleFix +
BS. We consider that an approach can generate diverse programs if it can pro-
duce two or more successfully compiled, unique programs for a given erroneous
program. Similarly, we say that the approach produces functionally diverse pro-
grams if it can generate two or more programs with observable diﬀerences in
functionality for a given erroneous program. Here we consider the percentage
out of the total number of erroneous programs for which the model generates at
least one successfully compiled program. The results of this table show that our
DS-SampleFix + BS approach generates programs with more diverse function-
alities in comparison to the other approaches.

5 Conclusion

We propose a novel approach to correct common programming errors. We recog-
nize and model the inherent ambiguity and uncertainty when predicting multiple
ﬁxes. In contrast to previous approaches, our approach is able to learn the distri-
bution over candidate ﬁxes rather than the most likely ﬁx. We achieve increased
diversity of the sampled ﬁxes by a novel diversity-sensitive regularizer. We show
that our approach is capable of generating multiple diverse ﬁxes with diﬀerent
functionalities. Furthermore, our evaluations on synthetic and real-world data
show improvements over state-of-the-art methods.

References

1. Allamanis, M., Barr, E.T., Devanbu, P., Sutton, C.: A survey of machine learning

for big code and naturalness. ACM Computing Surveys (CSUR) (2018)

2. Bader, J., Scott, A., Pradel, M., Chandra, S.: Getaﬁx: learning to ﬁx bugs auto-

matically. Proc. ACM Program. Lang. 3(OOPSLA) (2019)

3. Bahdanau, D., Cho, K., Bengio, Y.: Neural machine translation by jointly learning

to align and translate (2015)

4. Bhattacharyya, A., Schiele, B., Fritz, M.: Accurate and diverse sampling of se-

quences based on a ”best of many” sample objective. In: CVPR (2018)

5. Bowman, S.R., Vilnis, L., Vinyals, O., Dai, A.M., Jozefowicz, R., Bengio, S.: Gener-
ating sentences from a continuous space. In: SIGNLL Conference on Computational
Natural Language Learning (CoNLL) (2016)

6. Das, R., Ahmed, U.Z., Karkare, A., Gulwani, S.: Prutor: A system for tutoring

CS1 and collecting student programs for analysis (2016)

7. Deshpande, A., Aneja, J., Wang, L., Schwing, A.G., Forsyth, D.: Fast, diverse and

accurate image captioning guided by part-of-speech. In: CVPR (2019)

8. D’Antoni, L., Samanta, R., Singh, R.: Qlose: Program repair with quantitative

objectives. In: CAV (2016)

9. Girshick, R.: Fast r-cnn. In: ICCV (2015)

SampleFix: Learning to Generate Functionally Diverse Fixes

15

10. Gottschlich, J., Solar-Lezama, A., Tatbul, N., Carbin, M., Rinard, M., Barzilay,
R., Amarasinghe, S., Tenenbaum, J.B., Mattson, T.: The three pillars of machine
programming. In: MAPL (2018)

11. Goues, C.L., Pradel, M., Roychoudhury, A.: Automated program repair. Commun.

ACM 62(12), 56–65 (2019)

12. Gupta, R., Kanade, A., Shevade, S.: Deep reinforcement learning for programming

language correction. In: AAAI (2019)

13. Gupta, R.R., Pal, S., Kanade, A., Shevade, S.K.: Deepﬁx: Fixing common c lan-

guage errors by deep learning. In: AAAI (2017)

14. Jang, E., Gu, S., Poole, B.: Categorical reparameterization with gumbel-softmax.

In: ICLR (2017)

15. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: ICLR

(2015)

16. Kingma, D.P., Welling, M.: Auto-encoding variational bayes. In: ICLR (2014)
17. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classiﬁcation with deep con-

volutional neural networks. In: NIPS (2012)

18. Lee, H., Grosse, R., Ranganath, R., Ng, A.Y.: Unsupervised learning of hierarchical
representations with convolutional deep belief networks. Communications of the
ACM (2011)

19. Li, Y., Wang, S., Nguyen, T.N.: Dlﬁx: Context-based code transformation learning
for automated program repair. In: International Conference on Software Engineer-
ing (ICSE) (2020)

20. Long, F., Rinard, M.: Automatic patch generation by learning correct code. In:

ACM SIGPLAN Notices (2016)

21. Maddison, C.J., Mnih, A., Teh, Y.W.: The concrete distribution: A continuous

relaxation of discrete random variables (2016)

22. Monperrus, M.: Automatic software repair: a bibliography. ACM Computing Sur-

veys (CSUR) (2018)

23. Pu, Y., Narasimhan, K., Solar-Lezama, A., Barzilay, R.: sk p: a neural program

corrector for moocs. In: ACM SIGPLAN (2016)

24. Rezende, D.J., Mohamed, S.: Variational inference with normalizing ﬂows. In:

ICML (2015)

25. Seo, H., Sadowski, C., Elbaum, S., Aftandilian, E., Bowdidge, R.: Programmers’

build errors: a case study (at google). In: ICSE (2014)

26. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale

image recognition. In: ICLR (2015)

27. Singh, R., Gulwani, S., Solar-Lezama, A.: Automated feedback generation for in-

troductory programming assignments. In: PLDI (2013)

28. Smith, E.K., Barr, E.T., Goues, C.L., Brun, Y.: Is the cure worse than the disease?
overﬁtting in automated program repair. In: Foundations of Software Engineering
(ESEC/FSE) (2015)

29. Sohn, K., Lee, H., Yan, X.: Learning structured output representation using deep

conditional generative models. In: NIPS (2015)

30. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural

networks. In: NIPS (2014)

31. Wang, L., Schwing, A., Lazebnik, S.: Diverse and accurate image description using
a variational auto-encoder with an additive gaussian encoding space. In: NIPS
(2017)

32. Yasunaga, M., Liang, P.: Graph-based, self-supervised program repair from diag-

nostic feedback. In: ICML (2020)

