Unsupervised Latent Tree Induction with
Deep Inside-Outside Recursive Autoencoders

Andrew Drozdov1,∗

Pat Verga1,∗

Mohit Yadav1,∗

Mohit Iyyer1 Andrew McCallum1

1College of Information and Computer Sciences
University of Massachusetts Amherst

{adrozdov, pat, ymohit, miyyer, mccallum}@cs.umass.edu

9
1
0
2

r
p
A
4

]
L
C
.
s
c
[

2
v
2
4
1
2
0
.
4
0
9
1
:
v
i
X
r
a

Abstract

We introduce deep inside-outside recursive
autoencoders (DIORA), a fully-unsupervised
method for discovering syntax that simulta-
neously learns representations for constituents
within the induced tree. Our approach pre-
dicts each word in an input sentence condi-
tioned on the rest of the sentence and uses
inside-outside dynamic programming to con-
sider all possible binary trees over the sen-
tence. At test time the CKY algorithm extracts
the highest scoring parse. DIORA achieves a
new state-of-the-art F1 in unsupervised binary
constituency parsing (unlabeled) in two bench-
mark datasets, WSJ and MultiNLI.

1

Introduction

Syntactic parse trees are useful for downstream
tasks such as relation extraction (Gamallo et al.,
2012), semantic role labeling (Sutton and Mc-
Callum, 2005; He et al., 2018), machine trans-
lation (Aharoni and Goldberg, 2017; Eriguchi
et al., 2017; Zaremoodi and Haffari, 2018), and
text classiﬁcation (Li and Roth, 2006; Tai et al.,
2015). Traditionally, supervised parsers trained
on datasets such as the Penn Treebank (Marcus
et al., 1993) are used to obtain syntactic trees.
However, the treebanks used to train these su-
pervised parsers are typically small and restricted
to the newswire domain. Unfortunately, models
trained on newswire treebanks tend to perform
considerably worse when applied to new types of
data, and creating new domain speciﬁc treebanks
with syntactic annotations is expensive and time-
consuming.

Motivated by the desire to address the limita-
tions of supervised parsing and by the success of
large-scale unsupervised modeling such as ELMo
and BERT (Peters et al., 2018a; Devlin et al.,

∗Equal contribution, randomly ordered.

Figure 1: An unlabeled binary constituency parse from
DIORA matching the ground truth.

2019), we propose a new deep learning method
of unsupervised parser training that can extract
both shallow parses (i.e., noun phrases or entities)
and full syntactic trees from any domain or lan-
guage automatically without requiring any labeled
training data.
In addition to producing parses,
our model simultaneously builds representations
for internal constituents that reﬂect syntactic and
semantic regularities which can be leveraged by
downstream tasks.

Our model builds on existing work developing
latent tree chart parsers (Socher et al., 2011b; Le
and Zuidema, 2015; Yogatama et al., 2017; Mail-
lard et al., 2017; Choi et al., 2018). These meth-
ods produce representations for all internal nodes
in the tree (cells in the chart), each generated as
a soft weighting over all possible sub-trees (§2).
Unfortunately, they still require sentence-level an-
notations during training, as they are all trained to
optimize a downstream task, typically natural lan-
guage inference.

To address these limitations, we present deep
inside-outside recursive autoencoders (DIORA)
which enable unsupervised discovery and repre-
sentation of constituents without requiring any su-
pervised training data. DIORA incorporates the
inside-outside algorithm (Baker, 1979; Lari and
Young, 1990) into a latent tree chart parser. The
bottom-up inside step calculates a representation
for all possible constituents within a binary tree
over the input sentence. This step is equivalent
to the forward-pass of previous latent tree chart
parsers (Maillard et al., 2017). These inside repre-
sentations only encode the current subtree, ignor-

Under the current circumstances he says their scenario no longer seems unrealistic 
 
 
 
 
 
Figure 2: The inside and outside pass of DIORA for the input ‘the cat drank’. a) The inside pass: The blue
inside vector ¯a(k) for the phrase ‘the cat drank’ is a weighted average of the compositions for the two possible
segmentations - ((the cat), drank) and (the, (cat drank)). The scalar weights come from a learned compatibility
function. b) The outside pass: The red outside vector ¯b(k) for the phrase ‘the cat’ is a function of the outside vector
of its parent ‘the cat drank’ and the inside vector of its sibling ‘drank’.

ing all outside context. Thus, we perform an addi-
tional top-down outside calculation for each node
in the tree, providing external context into the sub-
tree representations in each chart cell. The model
is then trained with the objective that the outside
representations of the leaf cells should reconstruct
the corresponding leaf input word, analogous to
masked language model (Devlin et al., 2019) pre-
training, except by using dynamic programming
we predict every word from a completely un-
masked context. The single most likely tree can be
recovered using the CKY algorithm and compati-
bility scores between constituents. Previous work
either predict trees that are not well aligned with
known treebanks (Yogatama et al., 2017; Choi
et al., 2018), or has no mechanism for explicitly
modeling phrases, requiring a complex procedure
to extract syntactic structures (Shen et al., 2018).
To probe different properties of our model, we
run experiments on unsupervised parsing, seg-
ment recall, and phrase representations. DIORA
achieves multiple new state-of-the-art results for
unsupervised constituency parsing (absolute im-
provements of 13.7%, 11.5%, and 7.8% on WSJ,
WSJ-40, and MultiNLI), has a greater recall on
more constituent types than a strong baseline, and
produces meaningful phrase representations.

2 DIORA: Deep Inside-Outside
Recursive Autoencoders

the true syntactic structure of the underlying in-
put. Our approach builds on previous latent tree
chart parsers which are augmented with the inside-
outside algorithm (Baker, 1979; Lari and Young,
1990) and trained to reproduce each input word
from its outside context. Based on our hypothe-
sis, loosely inspired by the linguistic “substitution
principle” (Frege, 1960), the model will best re-
construct the input by discovering and exploiting
syntactic regularities of the text.

The inside pass of our method recursively com-
presses the input sequence, at each step inputting
the vector representations of the two children into
a composition function (§2.1.1) that outputs an in-
side vector representation of the parent. This pro-
cess continues up to the root of the tree, eventu-
ally yielding a single vector representing the en-
tire sentence (Figure 2a). This is loosely analo-
gous to the compression step of an autoencoder
and equivalent to existing latent tree chart parsers
forward pass (Maillard et al., 2017).
Follow-
ing this, we initiate the outside pass of our algo-
rithm with a generic (root) representation that is
learned as a separate parameter. As the outside
step of the inside-outside algorithm (Figure 2b),
we unfold until ﬁnally producing representations
of the leaf nodes. These leaves are then optimized
to reconstruct the input sentence as done in an
autoencoder-based deep neural network.

2.1 Filling the Chart with Inside-Outside

Our goal is to design a model and unsupervised
training procedure that learns structure from raw
text. The design of DIORA is based on our
hypothesis is that the most effective compres-
sion of a sentence will be derived from following

Each inside representation is the root of a particu-
larly sub-tree, and that representation is generated
by considering only the descendant constituents
within that sub-tree, ignoring any outside context.
After the inside representations are calculated, we

0.7⋅+0.3⋅ThecatdrankThecatdrank(a) Inside Pass(b) Outside PassThecatdrankThecatdranke(i,j)e(i,j)a(i,j)a(i,j)b(i,j)i0j0i1j1i0j0¯a(k)¯b(k)perform a top-down outside pass to compute out-
side representations. The outside representations
are encoded by looking at only the context of a
given sub-tree. Once the chart is ﬁlled, each con-
stituent k (cell in the chart) is associated with an
inside vector ¯a(k), an outside vector ¯b(k), inside
compatibility score ¯e(k) and outside compatibility
score ¯f (k).

The input to our model is a sentence x made up
of T tokens, x0, x1, ..., xT −1. Each token xi has a
corresponding pre-trained embedded vector vi.

Inside Pass

2.1.1
For each pair of neighboring constituents i and
j 1, we compute a compatibility score and a com-
position vector. The score and vector that repre-
sent a particular span k are computed using a soft
weighting over all possible pairs of constituents,
that together fully cover the span (we refer to this
set of constituent pairs as {k}).

Vectors for spans of length 1 are initialized as a
non-linear transformation 2 of the embedded input
vi, and the scores associated with these spans are
set to 0:









x
o
 =
u





σ
σ
tanh

 (Uψvk + b)

¯a(k) = o + tanh(x (cid:12) u)

¯e(k) = 0

Higher levels of the chart are computed as a

weighted summation of constituent pairs:

¯a(k) =

(cid:88)

e(i, j) a(i, j)

¯e(k) =

i,j∈{k}
(cid:88)

i,j∈{k}

e(i, j) ˆe(i, j)

The compatibility function ˆe is meant to pro-
duce a score for how likely a pair of neighboring
cells are to be merged. We implement this as a
bilinear function of the vectors from neighboring
spans, using a learned parameter matrix S. We ad-
ditionally add the individual scores from each two
merging cells. Intuitively, these individual scores
correspond to how likely each of the cells would

1The symbols i, j, and k are identiﬁers of spans from the
input x. The symbol i∗ identiﬁes a token from the set of
negative examples {x∗}.

2This function shares its bias term b with Composeα, al-

though Uψ is not tied to any other weights.

exist in the ﬁnal binary tree independently. The
formula for the compatibility function (and its nor-
malized form e) is deﬁned as follows:

e(i, j) =

exp(ˆe(i, j))

(cid:80)
ˆi,ˆj∈{k}

exp(ˆe(ˆi, ˆj))

ˆe(i, j) = φ(¯a(i), ¯a(j); Sα) + ¯e(i) + ¯e(j)

Where the bilinear projection φ is deﬁned as:

φ(u, v; W ) = u(cid:62)W v

For the composition function a we used ei-
ther a TreeLSTM (Tai et al., 2015) or a 2-layer
MLP (see Appendix A.1 for more precise deﬁni-
tons on both methods). In order for the remainder
of equations to remain agnostic to the choice of
composition function, we refer to the function as
Compose, which produces a hidden state vector h
and, in the case of TreeLSTM, a cell state vector
c, resulting in:

a(i, j) = Composeα(¯a(i), ¯a(j))

2.1.2 Outside Pass
The outside computation is similar to the inside
pass (depicted in Figure 2b).

The root node of the outside chart is learned
as a bias. Descendant cells are predicted using a
disambiguation over the possible outside contexts.
Each component of the context consists of a sib-
ling cell from the inside chart and a parent cell
from the outside chart.

The function f is analogous to the function e.
It is normalized over constituent pairs i, j for the
span k, and is used to disambiguate among the
many outside contexts. The function b generates a
phrase representation for the missing sibling cell.
Equations for the outside computation follow:

¯b(k) =

(cid:88)

f (i, j) b(i, j)

¯f (k) =

i,j∈{k}
(cid:88)

i,j∈{k}

f (i, j) ˆf (i, j)

b(i, j) = Composeβ(¯a(i), ¯b(j))
ˆf (i, j) = φ(¯a(i), ¯b(j); Sβ) + ¯e(i) + ¯f (j)
In the majority of our experiments,

the
Compose used in b shares parameters with a used
in the inside pass, as do the compatibility func-
tions ˆe and ˆf (see §3.4 for results on the effects of
parameter sharing).

2.2 Training Objective

To train our model we use an autoencoder-like lan-
guage modeling objective. In a standard autoen-
coder, the entire input x is compressed into a sin-
gle lower dimensional representation. This repre-
sentation, z, is then decompressed and trained to
reconstruct x. In our model, we never condition
the reconstruction of x on a single z because the
root’s outside representation is initialized with a
bias rather than the root’s own inside vector. In-
stead, we reconstruct x conditioned on the many
sub-tree roots, each of which is only a compres-
sion of a subset of the input.

To approximate this reconstruction we use a
max-margin loss considering a set {x∗} of N neg-
ative examples that are sampled according to their
frequency from the vocabulary (further details in
Appendix A.2). The terminal outside vector ¯b(i)
is trained to predict its original input vi.

The per-instance loss function is described in

Algorithm 1 Parsing with DIORA

1: procedure CKY(chart)

Initialize terminal values.
for each k ∈ chart | SIZE(k) = 1 do

xk ← 0

Calculate a maximum score for each span,
and record a backpointer.
for each k ∈ chart do

[xi + xj + e(i, j)]

xk ← max
i,j∈{k}
k, πj
πi
k ← arg max
i,j∈{k}

[xi + xj + e(i, j)]

Backtrack to get the maximal tree.
procedure BACKTRACK(k)
if SIZE(k) = 1 then

return k

i ← BACKTRACK(πi
k)
j ← BACKTRACK(πj
k)
return (i, j)

return BACKTRACK(k ← root)

2:

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

Equation 1:

Lx =

T −1
(cid:88)

N −1
(cid:88)

i=0

i∗=0

max(0, 1 − ¯b(i) · ¯a(i)

+ ¯b(i) · ¯a(i∗))

(1)

vised segment recall, and phrase similarity. The
model has been implemented in PyTorch (Team,
2018) and the code is published online.3 For train-
ing details, see Appendix A.2.

The max-margin loss does not provide a gradi-
ent if the predicted vector is closer to its ground
truth than the negative example by a margin
greater than 1. For that reason, we also experi-
mented with an objective based on cross-entropy,
described in Equation 2:

Z∗ =

N −1
(cid:88)

i∗=0

exp(¯b(i) · ¯a(i∗))

Lx = −

T −1
(cid:88)

i=0

log

exp(¯b(i) · ¯a(i))
exp(¯b(i) · ¯a(i)) + Z∗

(2)

2.3 DIORA CKY Parsing

To obtain a parse with DIORA, we populate an
inside and outside chart using the input sentence.
We can extract the maximum scoring parse based
on our single grammar rule using the CKY proce-
dure (Kasami, 1966; Younger, 1967). The steps
for this procedure are described in Algorithm 1
and its runtime complexity in Appendix A.3.

3 Experiments

3.1 Unsupervised Parsing

We ﬁrst evaluate how well our model predicts a
full unlabeled constituency parse. We look at
two data sets used in prior work (Htut et al.,
2018), The Wall Street Journal (WSJ) section of
Penn Treebank (Marcus et al., 1993), and the au-
tomatic parses from MultiNLI (Williams et al.,
2018b). WSJ has gold human-annotated parses
and MultiNLI contains automatic parses derived
from a supervised parser (Manning et al., 2014).

In addition to PRPN (Shen et al., 2018),4
we compare our model to deterministically con-
structed left branching, right branching, balanced,
and random trees. We also compare to ON-LSTM
(Shen et al., 2019), an extension of the PRPN
model, RL-SPINN (Yogatama et al., 2017), an
unsupervised shift-reduce parser, and ST-Gumbel
(Choi et al., 2018), an unsupervised chart parser.
The latter two of these models are trained to pre-
dict the downstream task of natural language in-
ference (NLI).

To evaluate the effectiveness of DIORA, we run
experiments on unsupervised parsing, unsuper-

3https://github.com/iesl/diora
4We consider the PRPN models using LM stopping crite-

ria, which outperformed UP.

3.1.1 Binarized WSJ and MultiNLI results
For the full WSJ test set and MultiNLI datasets
we follow the experimental setup of previous work
(Williams et al., 2018a). We binarize target trees
using Stanford CoreNLP (Manning et al., 2014)
and do not remove punctuation (experiments in
§3.1.2 do remove punctuation).

Latent tree models have been shown to perform
particularly poorly on attachments at the begin-
ning and end of the sequence (Williams et al.,
2018a). To address this, we incorporate a post-
processing heuristic (denoted as +PP in result
tables)5. This heuristic simply attaches trailing
punctuation to the root of the tree, regardless of
its predicted attachment.

In Table 1, we see that DIORA+PP achieves
the highest average and maximum F1 from ﬁve
random restarts. This model achieves a mean F1
7 points higher than ON-LSTM and an increase
of over 6.5 max F1 points. We also see that
DIORA exhibits much less variance between ran-
dom seeds than ON-LSTM. Additionally, we ﬁnd
that PRPN-UP and DIORA beneﬁt much more
from the +PP heuristic than PRPN-LM. This is
consistent with qualitative analysis showing that
DIORA and PRPN-UP incorrectly attach trailing
punctuation much more often than PRPN-LM.

On the MultiNLI dataset, PRPN-LM is the top
performing model without using the +PP heuris-
tic while DIORA matches PRPN-UP (Table 2. Us-
ing the heuristic, DIORA greatly surpasses both
variants of PRPN. However, it is worth noting that
this is not a gold standard evaluation and instead
evaluates a model’s ability to replicate the output
of a trained parser (Manning et al., 2014). A sec-
ond caveat is that SNLI (Bowman et al., 2015)
and MultiNLI contain several non-newswire do-
mains. Syntactic parsers often suffer signiﬁcant
performance drops when predicting outside of the
newswire domain that the models were trained on.

3.1.2 WSJ-10 and WSJ-40 results
We also compare our models to two subsets of the
WSJ dataset that were used in previous unsuper-
vised parsing evaluations. WSJ-10 and WSJ-40
contain sentences up to length 10 and 40 respec-
tively after punctuation removal. We do not bi-
narize either of these two splits in order to com-
pare to previous work (see Appendix A.4 for more

5We did not have access to predictions or an implementa-
tion of the concurrent ON-LSTM model and therefore could
not apply the +PP heuristic.

Model

F1µ

F1max

δ

LB
RB
Random
Balanced
RL-SPINN†
ST-Gumbel - GRU†

PRPN-UP
PRPN-LM
ON-LSTM
DIORA

PRPN-UP+PP
PRPN-LM+PP
DIORA+PP

13.1
16.5
21.4
21.3
13.2
22.8 ±1.6

38.3 ±0.5
35.0 ±5.4
47.7 ±1.5
48.9 ±0.5

-
-
55.7 ±0.4

13.1
16.5
21.4
21.3
13.2
25.0

39.8
42.8
49.4
49.6

45.2
42.4
56.2

12.4
12.4
5.3
4.6
-
-

5.9
6.2
5.6
8.0

6.7
6.3
8.5

Table 1: Full WSJ (test set) unsupervised unlabeled
binary constituency parsing including punctuation.
† indicates trained to optimize NLI task. Mean and max
are calculated over ﬁve random restarts. PRPN F1 was
calculated using the parse trees and results provided by
Htut et al. (2018). The depth (δ) is the average tree
height. +PP refers to post-processing heuristic that
attaches trailing punctuation to the root of the tree. The
top F1 value in each column is bolded.

Model

Random
Balanced

PRPN-UP
PRPN-LM
DIORA

PRPN-UP+PP
PRPN-LM+PP
DIORA+PP

F1median F1max

27.0
21.3

48.6
50.4
51.2

-
-
59.0

27.0
21.3

-
-
53.3

54.8
50.4
59.1

δ

4.4
3.9

4.9
5.1
6.4

5.2
5.1
6.7

Table 2: NLI unsupervised unlabeled binary con-
stituency parsing comparing to CoreNLP predicted
parses. PRPN F1 was calculated using the parse trees
and results provided by Htut et al. (2018). F1 median
and max are calculated over ﬁve random seeds and the
top F1 value in each column is bolded. Note that we
use median rather than mean in order to compare with
previous work.

details on WSJ split differences). Not binarizing
the target trees sets an upper-bound on the perfor-
mance of our models, denoted as UB in Table 3.

We compare against previous notable models
for this task: CCM (Klein and Manning, 2002)
uses the EM algorithm to learn probable nested

bracketings over a sentence using gold or induced
part-of-speech tags, and PRLG (Ponvert et al.,
2011) performs constituent parsing through con-
secutive rounds of sentence chunking.

In Table 3, we see that DIORA outperforms the
previous state of the art for WSJ-40, PRLG, in
max F1. The WSJ-10 split has been difﬁcult for la-
tent tree parsers such as DIORA, PRPN, and ON-
LSTM, none of which (including our model) are
able to improve upon previous non-neural meth-
ods. However, when we compare trends between
WSJ-10 and WSJ-40, we see that DIORA does a
better job at extending to longer sequences.

3.2 Unsupervised Phrase Segmentation

In many scenarios, one is only concerned with ex-
tracting particular constituent phrases rather than
a full parse. Common use cases would be iden-
tifying entities, noun phrases, or verb phrases for
downstream analysis. To get an idea of how well
our model can perform on phrase segmentation,
we consider the maximum recall of spans in our
predicted parse tree. We leave methods for cut-
ting the tree to future work and instead consider
the maximum recall of our model which serves as
an upper bound on its performance. Recall here is
the percentage of labeled constituents that appear
in our predicted tree relative to the total number
of constituents in the gold tree. These scores are
separated by type and presented in Table 4.

In Table 4 we see the breakdown of constituent
recall across the 10 most common types. DIORA
achieves the highest recall across the most types
and is the only model
to perform effectively
on verb-phrases. Interestingly, DIORA performs
worse than PRPN-LM at prepositional phrases.

3.3 Phrase Similarity

One of the goals of DIORA is to learn meaningful
representations for spans of text. Most language
modeling methods focus only on explicitly model-
ing token representations and rely on ad-hoc post-
processing to generate representations for longer
spans, typically relying on simple arithmetic func-
tions of the individual tokens.

To evaluate our model’s learned phrase repre-
sentations, we look at the similarity between spans
of the same type within labeled phrase datasets.
We look at two datasets. CoNLL 2000 (Tjong
Kim Sang and Buchholz, 2000) is a shallow pars-
ing dataset containing spans of noun phrases, verb
phrases, etc. CoNLL 2012 (Pradhan et al., 2012)

WSJ-10

WSJ-40

F1max F1µ

F1max

Model

UB
LB
RB

F1µ

87.8
28.7
61.7

CCM†
CCMgold†
PRLG †

-
-
-

66.3 ±0.8
PRPNN LI
PRPN‡
70.5 ±0.4
ON-LSTM‡ 65.1 ±1.7
67.7 ±0.7
DIORA

87.8
28.7
61.7

63.2
71.9
72.1

68.5
71.3
66.8
68.5

85.7
12.0
40.7

-
-
-

-
-
-
60.6 ±0.2

85.7
12.0
40.7

-
33.7
54.6

-
52.4
-
60.9

Table 3: WSJ-10 and WSJ-40 unsupervised non-
binary unlabeled constituency parsing with punctu-
ation removed. † indicates that the model predicts a
full, non-binary parse with additional resources. ‡ in-
dicates model was trained on WSJ data and PRPNN LI
was trained on MultiNLI data. CCM uses predicted
POS tags while CCMgold uses gold POS tags. PRPN
F1 was calculated using the parse trees and results pro-
vided by Htut et al. (2018). LB and RB are the left
and right-branching baselines. UB is the upper bound
attainable by a model that produces binary trees.

is a named entity dataset containing 19 different
entity types.

For each of the labeled spans with length greater
than one, we ﬁrst generate its phrase representa-
tion. We then calculate its cosine similarity to all
other labeled spans. We then calculate if the label
for that query span matches the labels for each of
the K most similar other spans in the dataset. In
Table 5 we report precision@K for both datasets
and various values of K.

The ﬁrst baseline we compare against produces
phrase representations from averaging context-
insensitive (CI) ELMo vectors of individual to-
kens with the span. The second uses sentence-
insensitive (SI) ELMo vectors, running the full
ELMo over only the relevant tokens and ignor-
ing the rest of the sentence. We also look at
ELMo’s output when given the entire sentence.
When analyzing our baselines that run the full
ELMo, we follow the procedure described in (Pe-
ters et al., 2018b) and represent phrases as a func-
tion of its ﬁrst and last hidden state. We extract
these states from the ﬁnal ELMo layer (3rd BiL-
STM) as these consistently gave the best perfor-
mance among other options. For DIORA, we use
the concatenation of the inside and outside repre-
sentations ([¯a; ¯b]).

Label

Count DIORA P-UP

P-LM

NP
VP
PP
S
SBAR
ADJP
QP
ADVP
PRN
SINV

297,872
168,605
116,338
87,714
24,743
12,263
11,441
5,817
2,971
2,563

0.767
0.628
0.595
0.798
0.613
0.604
0.801
0.693
0.546
0.926

0.687
0.393
0.497
0.639
0.403
0.342
0.336
0.392
0.127
0.904

0.598
0.316
0.602
0.657
0.554
0.360
0.545
0.500
0.144
0.932

Table 4: Segment recall from WSJ separated by
phrase type. The 10 most frequent phrase types are
shown above, and the highest value in each row is
bolded. P-UP=PRNP-UP, P-LM=PRPN-LM

For CoNLL 2000, we ﬁnd that our model out-
performs all baselines for all values of K. This
demonstrates DIORA’s ability to capture and rep-
resent syntactic information within phrases. For
CoNLL 2012, we ﬁnd that DIORA outperforms
both ELMoCI and ELMoSI while ELMo per-
forms best overall. ELMoCI is surprisingly ef-
fective on this dataset even though it performed
more poorly on CoNLL 2000. These results in-
dicate that DIORA is capturing syntax quite well,
but still has room to improve on more ﬁne-grained
semantic representations.

3.4

Impact of Modeling Choices

To test the impact of our modeling choices, we
compared the performance of two different losses
and four different composition functions on the
full WSJ validation set. The losses were covered
in Equations 1 (Margin) and 2 (Softmax). The
two primary methods of composition we consid-
ered were TreeLSTM (Tai et al., 2015) and MLP
(a 2-hidden layer neural network). In addition, we
experimented with a simple kernel of the MLP in-
put [x; y; x (cid:12) y; x − y] and with a setting where
both the inside and outside parameters are shared.
The results are shown in Table 6. We see
that MLP composition consistently performs bet-
ter than with TreeLSTM, that MLP beneﬁts from
the Softmax loss, and that the best performance
comes from sharing parameters. All other exper-
imental results use this highly performant setting
unless otherwise speciﬁed.

Figure 3: DIORA can match the ground truth exactly.

Figure 4: At times, DIORA exhibits contrary behav-
ior to the ground truth inevitably leading to some error.
DIORA’s output is shown above the ground truth.6

Figure 5: DIORA often groups verbs and particles
(top), sometimes exactly as the ground truth (mid-
dle). Occasionally, errors are particle-like (bottom).
DIORA’s output is shown above the ground truth.6

6Ground truth parses are binarized unless otherwise spec-
iﬁed. All examples of DIORA parses are already binary.
Some punctuation has been removed for easier readability.

The convoy of about 100 vehicles was the first to make deliveries to the capital in about 10 daysThe court ruled that the news media did n't reveal Twiggy 's problems at the timeFerro also said it would cancel the unused portion of a 1987 buy-back plan for administrative reasonsFerro also said it would cancel the unused portion of a 1987 buy-back plan for administrative reasonsIn the stands people waved ANC flags wore ANC T-shirts sang ANC songs and chanted ANC slogansIn the stands people waved ANC flags wore ANC T-shirts sang ANC songs and chanted ANC slogansThe following month the company put itself up for saleThe following month the company put itself up for saleHe added that the U.S. has cut off aid to some rebel units when it was determined that those units broke the cease-fireHe added that the U.S. has cut off aid to some rebel units when it was determined that those units broke the cease-fireWe simply do n't agree with that or the findings of their investigationWe simply do n't agree with that or the findings of their investigationModel

Random
ELMoCI
ELMoSI
ELMo

CoNLL 2000

CoNLL 2012

Dim P@1

P@10 P@100

P@1

P@10 P@100

800
1024
4096
4096

0.684
0.962
0.970
0.987

0.683
0.955
0.964
0.983

0.680
0.957
0.955
0.974

0.137
0.708
0.660
0.896

0.133
0.643
0.624
0.847

0.135
0.544
0.533
0.716

DIORAIn/Out

800

0.990

0.985

0.979

0.860

0.796

0.646

Table 5: P@1, P@10, and P@100 for labeled chunks from CoNLL-2000 and CoNLL 2012 datasets. For all
metrics, higher is better. The top value in each column is bolded. Diora uses the concatenation of the inside and
outside vector at each cell which performed better than either in isolation.

3.5 Qualitative Results

Looking at our model’s output, we see that some
trees are an exact replication of the binarized
ground truth (Fig. 3), or very close (Fig. 4). For
future work we intend to explore common patterns
in DIORA’s learned structure, although some pat-
terns are already recognizable, such as the afﬁnity
to group particles and verbs (Fig. 5).

4 Related Work

Latent Tree Learning A brief survey of neural la-
tent tree learning models was covered in (Williams
et al., 2018a). The ﬁrst positive result for neural la-
tent tree parsing was shown in (Htut et al., 2018),
which used a language modeling objective. The
model in (Liu et al., 2018) uses an inside chart and
an outside procedure to calculate marginal proba-
bilities in order to align spans between sentences
in entailment.

Composition

Loss

F1µ

∅

+PP

TreeLSTM
Margin
TreeLSTM Softmax
Margin
Softmax
Softmax
Softmax

MLP
MLP
MLPKernel
MLPShared

49.9
52.0
49.7
52.6
51.8
50.8

53.1
52.9
54.4
55.5
54.8
56.7

Neural Inside-Outside Parsers The Inside-
Outside Recursive Neural Network (IORNN) (Le
and Zuidema, 2014) is closest to ours.
It is a
graph-based dependency parser that uses beam
search and can reliably ﬁnd accurate parses when
retaining a k-best list.
In contrast, our model
produces the most likely parse given the learned
compatibility of the constituents. The Neural
CRF Parser (Durrett and Klein, 2015), similar to
DIORA, performs exact inference on the structure
of a sentence, although requires a set of gram-
mar rules and labeled parse trees during training.
DIORA, like Liu et al. (2018), has a single gram-
mar rule that applies to any pair of constituents and
does not use structural supervision.

Learning from Raw Text Unsupervised learn-
ing of syntactic structure has been an active re-
search area (Brill et al., 1990), including for un-
supervised segmentation (Ando and Lee, 2000;
Goldwater et al., 2009; Ponvert et al., 2011)
and unsupervised dependency parsing (Spitkovsky
et al., 2013). Some models exploit the availabil-
ity of parallel corpora in multiple languages (Das
and Petrov, 2011; Cohen et al., 2011). Others have
shown that dependency parsing can be used for un-
supervised constituency parsing (Spitkovsky et al.,
2013; Klein and Manning, 2004), or that it’s ef-
fective to prune a random subset of possible trees
(Bod, 2006). These approaches aren’t necessar-
ily orthogonal to DIORA. For instance, our model
may beneﬁt when combined with an unsupervised
dependency parser.

Table 6: F1 for different model variants on the bi-
nary WSJ validation set with included punctuation.
The binary trees are as-is (∅) or modiﬁed according to
the post-processing heuristic (+P P ). The mean F1 is
shown across three random seeds.

5 Conclusion

In this work we presented DIORA, an unsuper-
vised method for inducing syntactic trees and rep-
resentations of constituent spans. We showed

inside-outside representations constructed with a
latent tree chart parser and trained with an autoen-
coder language modeling objective learns syntac-
tic structure of language effectively.
In exper-
iments on unsupervised parsing, chunking, and
phrase representations we show our model
is
comparable to or outperforms previous methods,
achieving the state-of-the-art performance on un-
supervised unlabeled constituency parsing for the
full WSJ (with punctuation), WSJ-40, and NLI
datasets. We also show our model obtains higher
segment recall than a comparable model and out-
performs strong baselines on phrase representa-
tions on a chunking dataset.

While the current model seems to focus pri-
marily on syntax, future work can improve the
model’s ability to capture ﬁne-grained semantics.
Potential avenues include training larger mod-
els over much larger corpora, extra unsupervised
or weakly-supervised phrase classiﬁcation objec-
tives, and other modeling enhancements. We are
also eager to apply DIORA to other domains and
languages which do not have rich linguistically an-
notated training sets.

Acknowledgements

to Carolyn Anderson, Adina
We are grateful
Williams, Phu Mon Htut, and our colleagues at
UMass for help and advice, and to the UMass
NLP reading group and the anonymous reviewers
for feedback on drafts of this work. This work
was supported in part by the Center for Intelli-
gent Information Retrieval, in part by the National
Science Foundation (NSF) grant numbers DMR-
1534431, IIS-1514053 and CNS-0958392. Any
opinions, ﬁndings and conclusions or recommen-
dations expressed in this material are those of the
authors and do not necessarily reﬂect those of the
sponsor.

References

Roee Aharoni and Yoav Goldberg. 2017. Towards
In Asso-

string-to-tree neural machine translation.
ciation for Computational Linguistics (ACL).

Rie Kubota Ando and Lillian Lee. 2000. Mostly-
unsupervised statistical segmentation of japanese:
In North American Associ-
Applications to kanji.
ation for Computational Linguistics (NAACL).

James K Baker. 1979. Trainable grammars for speech
recognition. The Journal of the Acoustical Society
of America, 65(S1):S132–S132.

Rens Bod. 2006. An all-subtrees approach to unsu-
pervised parsing. In Association for Computational
Linguistics (ACL).

Samuel R. Bowman, Gabor Angeli, Christopher Potts,
and Christopher D. Manning. 2015. A large anno-
tated corpus for learning natural language inference.
In Empirical Methods in Natural Language Process-
ing (EMNLP).

Eric Brill, David Magerman, Mitchell Marcus, and
Beatrice Santorini. 1990. Deducing linguistic struc-
ture from the statistics of large corpora. In Informa-
tion Technology, 1990.’Next Decade in Information
Technology’, Proceedings of the 5th Jerusalem Con-
ference on (Cat. No. 90TH0326-9), pages 380–389.
IEEE.

Jihun Choi, Kang Min Yoo, and Sang-goo Lee. 2018.
Learning to compose task-speciﬁc tree structures.
In Advancement of Artiﬁcial Intelligence Conference
on Artiﬁcial Intelligence (AAAI).

Shay B. Cohen, Dipanjan Das, and Noah A. Smith.
2011. Unsupervised structure prediction with non-
parallel multilingual guidance. In Empirical Meth-
ods in Natural Language Processing (EMNLP).

Dipanjan Das and Slav Petrov. 2011. Unsupervised
part-of-speech tagging with bilingual graph-based
projections. In Association for Computational Lin-
guistics (ACL).

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. North American Association for Compu-
tational Linguistics (NAACL).

Greg Durrett and Dan Klein. 2015. Neural crf parsing.
In Association for Computational Linguistics (ACL).

Akiko Eriguchi, Yoshimasa Tsuruoka, and Kyunghyun
Cho. 2017. Learning to parse and translate improves
neural machine translation. In Association for Com-
putational Linguistics (ACL).

Friedrich Ludwig Gottlob Frege. 1960. On sense
In Zeitschrift f¨ur Philosophie und
and reference.
philosophische Kritik 100 (1892) 25-50; translated
in Translations from the Philosophical Writings of
Gottlob Frege (ed. by P. Geach and M. Black). Ox-
ford.

Pablo Gamallo, Marcos Garcia,

and Santiago
Fern´andez-Lanza.
Dependency-based
open information extraction. In Joint workshop on
unsupervised and semi-supervised learning in NLP.
Association for Computational Linguistics (ACL).

2012.

Sharon Goldwater, Thomas L Grifﬁths, and Mark John-
son. 2009. A bayesian framework for word segmen-
tation: Exploring the effects of context. Cognition,
112:21–54.

Luheng He, Kenton Lee, Omer Levy, and Luke Zettle-
moyer. 2018. Jointly predicting predicates and argu-
ments in neural semantic role labeling. In Associa-
tion for Computational Linguistics (ACL).

Mitchell Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of english: The penn treebank. Computa-
tional linguistics, 19(2):313–330.

Phu Mon Htut, Kyunghyun Cho, and Samuel R Bow-
man. 2018. Grammar induction with neural lan-
In Em-
guage models: An unusual replication.
pirical Methods in Natural Language Processing
(EMNLP): Short Paper.

Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018a. Deep contextualized word rep-
In North American Association for
resentations.
Computational Linguistics (NAACL).

Tadao Kasami. 1966.

recognition
and syntax-analysis algorithm for context-free lan-
guages. Coordinated Science Laboratory Report no.
R-257.

An efﬁcient

Diederik P. Kingma and Jimmy Ba. 2014. Adam:
CoRR,

A method for stochastic optimization.
abs/1412.6980.

Dan Klein and Christopher D. Manning. 2002. A
generative constituent-context model for improved
In Association for Computa-
grammar induction.
tional Linguistics (ACL).

Dan Klein and Christopher D. Manning. 2004. Corpus-
based induction of syntactic structure: Models of de-
pendency and constituency. In Association for Com-
putational Linguistics (ACL).

Karim Lari and Steve J Young. 1990. The estimation of
stochastic context-free grammars using the inside-
outside algorithm. Computer speech & language,
4(1):35–56.

Phong Le and Willem Zuidema. 2014. The inside-
outside recursive neural network model for depen-
In Empirical Methods in Natural
dency parsing.
Language Processing (EMNLP).

Matthew E Peters, Mark Neumann, Luke Zettlemoyer,
and Wen-tau Yih. 2018b. Dissecting contextual
word embeddings: Architecture and representation.
In Empirical Methods in Natural Language Process-
ing (EMNLP).

Elias Ponvert, Jason Baldridge, and Katrin Erk. 2011.
Simple unsupervised grammar induction from raw
text with cascaded ﬁnite state models. In Associa-
tion for Computational Linguistics (ACL).

Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. Conll-
2012 shared task: Modeling multilingual unre-
stricted coreference in ontonotes. In Joint Confer-
ence on EMNLP and CoNLL-Shared Task.

Yikang Shen, Zhouhan Lin, Chin-Wei Huang, and
Aaron Courville. 2018. Neural language modeling
In Inter-
by jointly learning syntax and lexicon.
national Conference on Learning Representations
(ICLR).

Yikang Shen, Shawn Tan, Alessandro Sordoni, and
Aaron Courville. 2019. Ordered neurons: Integrat-
ing tree structures into recurrent neural networks. In
International Conference on Learning Representa-
tions (ICLR).

Phong Le and Willem Zuidema. 2015. The forest con-
volutional network: Compositional distributional se-
mantics with a neural chart and without binarization.
In Empirical Methods in Natural Language Process-
ing (EMNLP), pages 1155–1164.

Richard Socher, Eric H Huang, Jeffrey Pennin, Christo-
pher D Manning, and Andrew Y Ng. 2011a. Dy-
namic pooling and unfolding recursive autoencoders
for paraphrase detection. In Advances in Neural In-
formation Processing Systems (NeurIPS).

Xin Li and Dan Roth. 2006. Learning question clas-
the role of semantic information. Natural

siﬁers:
Language Engineering, 12(3):229–249.

Yang Liu, Matt Gardner, and Mirella Lapata. 2018.
Structured alignment networks for matching sen-
tences. In Empirical Methods in Natural Language
Processing (EMNLP).

Jean Maillard, Stephen Clark, and Dani Yogatama.
2017.
Jointly learning sentence embeddings and
syntax with unsupervised tree-lstms. arXiv preprint
arXiv:1705.09189.

Christopher Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven Bethard, and David McClosky.
2014. The stanford corenlp natural language pro-
In Association for Computational
cessing toolkit.
Linguistics (ACL): System Demonstrations.

Richard Socher, Jeffrey Pennington, Eric H Huang,
Andrew Y Ng, and Christopher D Manning. 2011b.
Semi-supervised recursive autoencoders for predict-
In Empirical Methods
ing sentiment distributions.
in Natural Language Processing (EMNLP).

Valentin I Spitkovsky, Hiyan Alshawi, and Daniel Ju-
rafsky. 2013. Breaking out of local optima with
count transforms and model recombination: A study
in grammar induction. In Empirical Methods in Nat-
ural Language Processing (EMNLP).

Charles Sutton and Andrew McCallum. 2005.

Joint
In Confer-
parsing and semantic role labeling.
ence on Computational Natural Language Learning
(CoNLL).

Kai Sheng Tai, Richard Socher, and Christopher D.
Manning. 2015. Improved semantic representations

from tree-structured long short-term memory net-
In Association for Computational Linguis-
works.
tics (ACL).

Pytorch Core Team. 2018. Pytorch: Tensors and dy-
namic neural networks in python with strong gpu ac-
celeration. http://pytorch.org/. Accessed:
2018-09-26.

Erik F Tjong Kim Sang and Sabine Buchholz. 2000.
Introduction to the conll-2000 shared task: Chunk-
ing. In Proceedings of CoNLL-2000 and LLL-2000,
pages 127–132.

Adina Williams, Andrew Drozdov, and Samuel R Bow-
man. 2018a. Do latent tree learning models iden-
Transac-
tify meaningful structure in sentences?
tions of the Association of Computational Linguis-
tics (TACL), 6:253–267.

Adina Williams, Nikita Nangia, and Samuel Bowman.
2018b. A broad-coverage challenge corpus for sen-
In North
tence understanding through inference.
American Association for Computational Linguis-
tics (NAACL).

Dani Yogatama, Phil Blunsom, Chris Dyer, Edward
Grefenstette, and Wang Ling. 2017. Learning to
compose words into sentences with reinforcement
learning. In International Conference on Learning
Representations (ICLR).

Daniel H Younger. 1967. Recognition and parsing of
context-free languages in time n3. Information and
control, 10(2):189–208.

Poorya Zaremoodi and Gholamreza Haffari. 2018. In-
corporating syntactic uncertainty in neural machine
translation with a forest-to-sequence model. In In-
ternational Conference on Computational Linguis-
tics.

A Appendices

A.1 Composition and Input Transform

TreeLSTM. The TreeLSTM (Tai et al., 2015)
function produces a hidden state vector h and cell
state vector c given two input vectors hi and hj.









=









x
fi
fj
o
u

















σ
σ
σ
σ
tanh

(cid:32)

U

(cid:21)

(cid:20)hi
hj

+ b +

(cid:33)

















0
ω
ω
0
0

c = ci (cid:12) fi + cj (cid:12) fj + x (cid:12) u
h = o + tanh(c)

The constant ω is set to 1 for the inside, 0 for

the outside. U and b are learned.

MLP. MLP (Multi-Layer Perceptron) is a deep
non-linear composition with the following form:

h = W1 (W0 (cid:104)hi, hj(cid:105) + b) + b1

The operator (cid:104)hi, hj(cid:105) is a concatenation [hi; hj].
For the MLPKernel (cid:104)hi, hj(cid:105) is more involved to
support further interaction between the two input
vectors [hi; hj; hi (cid:12) hj; hi − hj]. The variables
W0, W1, b, b1 are learned and c is unused.

A.2 Training Details

Training Data. Sentences of length ≤ 20 from the
SNLI and MultiNLI training sets.
Optimization. We train our model using stochas-
tic gradient descent with the Adam optimization
algorithm (Kingma and Ba, 2014). Cells were
normalized to have magnitude of 1, following
Socher et al. (2011a). For instance, ¯a(k) :=
¯a(k)/ (cid:107)¯a(k)(cid:107)2. Gradients are clipped to a maxi-
mum L2-norm of 5.
Hyperparameters. Chosen using grid search over
cell-dimension {400D, 800D} and learning rate
{2, 4, 8, 10, 20} · 10−4.
Early Stopping. Using unlabeled parsing F1
against the binarized WSJ validation set.
Vocabulary. The model is trained in an open-
vocabulary setting using pre-trained context-
insensitive character embeddings from ELMo (Pe-
ters et al., 2018a).
Batching. Batches were constructed such that they
contained sentences of uniform length. Using
batch size 128 for 400D and 64 for 800D.

Sampling. N negatives are sampled for each
batch. All experiments use N = 100.
Training Steps. 1M parameter updates, taking 3
days using 4x Nvidia 1080ti.

A.3 Runtime Complexity

The runtime complexities for DIORA’s methods
are shown in Table 7. The parallel column rep-
resents the complexity when the values for all
constituent pairs are computed simultaneously, as-
suming that these computations are independent
and do not depend on values that have yet to be
computed. Linear complexity is theoretically fea-
sible depending on batch size, input length, and
number of computational cores. In practice, one
might experience super-linear performance.

Although both the inside pass and outside pass
have an upper bound of n3 operations, the outside
pass will have more operations than the inside pass
for sentences of length > 1.

As a point of reference, our implementation
computes the loss over the entire WSJ corpus in
5 minutes 30 seconds at a rate of 3,500 words per
second using a single GPU.

Method

Serial

Parallel

O(n3)
O(n3)

Inside Pass
Outside Pass
Training Objective O(n · N )
CKY

O(n3)

O(n)
O(n)
O(n)
O(n)

Table 7: Runtime complexity for methods associated
with DIORA in terms of sentence length n and number
of negative examples per token N . Each column rep-
resents the complexity when the values for each con-
stituent are computed serially or in parallel.

A.4 Reproducing Parsing Results

In Table 8, we’ve organized a reference for cre-
ating various splits of the WSJ for the purpose
of evaluating unsupervised parsing. Some splits
use only the test set (section 23), others use all of
the training, validation, and test data. Optionally,
punctuation is stripped and sentences greater than
a speciﬁed length are ignored. Predictions can be
compared to the full parse trees in the annotated
data, or to a binarized version. The PARSEVAL
speciﬁcation calculated bracketing F1 considering
all spans, although some previous work diverts
from PARSEVAL and ignores spans that are triv-
ially correct (ones over the entire sentence).

WSJ WSJ-10 WSJ-40

Split
Test
w/ Punctuation Yes
∞
Max Length
Binarized
Trivial Spans

Yes
Yes

All
No
10
No
No

Test
No
40
No
No

Table 8: Settings for unlabeled binary bracketing eval-
uation for different splits of the WSJ corpus.

A.5 Parse Trees

Examples of parse trees derived from the com-
patibility scores are shown in Figures 6, 7, and
8. Some punctuation has been removed for eas-
ier readability.

Figure 6: Examples where DIORA achieves 100% ac-
curacy compared with the binarized ground truth.

Figure 7: Examples where DIORA achieves 100% re-
call compared with the raw (n-ary) ground truth, but
less than 100% accuracy on the binarized ground truth.
DIORA is shown above the ground truth. DIORA’s
output is shown above the ground truth.

Mr. van Dover said the crystal changes his team introduced apparently pins the magnetic fields in place preventing them from lowering current-carrying capacityLen Kessler a financial publicist in New York sometimes uses it to get the attention of journalists who try to avoid himMs. Browning says she believes a recapitalization involving employee ownership would succeed only if the pilots relent on their demand for controlUnder the new plan being considered the notes would reset annually at a rate to maintain a market value of 101But the Gutfreund workers went ahead anyway only to be captured in flagrante by Joan Postel who called the policeGiven the seismic history of the Bay Area it seems to me that a 6.9 earthquake is a foreseeable eventA rash of one-time charges left Ashland Oil with a loss of 39 million for its fiscal fourth quarterSeparately Mr. Brady said he asked the Working Group on Financial Markets to determine whether futures margins are too lowIn a classic defense of a personal-injury case the consultants concentrate on encouraging the jury to shift the blameThe wholesaler of cash and carry merchandise reported fiscal fourthquarter earnings that were better than analysts had expectedIn addition a big loan that First Boston made to Ohio Mattress Co was n't repaid on time when its 450 million junk financing for a buy-out of the bedding company was withdrawnIn addition a big loan that First Boston made to Ohio Mattress Co was n't repaid on time when its 450 million junk financing for a buy-out of the bedding company was withdrawnIn its latest compilation of performance statistics Moody 's Investors Service found that investment-grade bonds posted a total return of 2.7 % in October while junk bonds showed a negative return of 1.5 %In its latest compilation of performance statistics Moody 's Investors Service found that investment-grade bonds posted a total return of 2.7 % in October while junk bonds showed a negative return of 1.5 %Within a year Kao Corp. a major cosmetics company plans to eliminate 1,000 clerical jobs by putting on a central computer network some work such as credit reports currently performed in 22 separate officesWithin a year Kao Corp. a major cosmetics company plans to eliminate 1,000 clerical jobs by putting on a central computer network some work such as credit reports currently performed in 22 separate officesAuthorities at London 's Heathrow Airport are investigating the disappearance of a Paul Gauguin watercolor Young Tahitian Woman in a Red Pareo that has two sketches on its verso -LRB- opposite -RRB- sideAuthorities at London 's Heathrow Airport are investigating the disappearance of a Paul Gauguin watercolor Young Tahitian Woman in a Red Pareo that has two sketches on its verso -LRB- opposite -RRB- sideBut in its ruling last April the New York court said that all producers of the anti-miscarriage drug should share liability when the manufacturer of a specific dose ca n't be determinedBut in its ruling last April the New York court said that all producers of the anti-miscarriage drug should share liability when the manufacturer of a specific dose ca n't be determinedThe Fed said the Comptroller of the Currency is expected to begin a Community Reinvestment Act examination of First Union 's Florida and North Carolina banking units in the next two weeksThe Fed said the Comptroller of the Currency is expected to begin a Community Reinvestment Act examination of First Union 's Florida and North Carolina banking units in the next two weeksThe appeals-court decision last year was particularly surprising because the same court had dismissed a similar case in 1970 involving singer Nancy Sinatra and a tire ad also a Young & Rubicam productThe appeals-court decision last year was particularly surprising because the same court had dismissed a similar case in 1970 involving singer Nancy Sinatra and a tire ad also a Young & Rubicam productThe resulting # 1.9 billion merchandise trade deficit was partly offset by an assumed surplus of # 300 million in so-called invisible items which include income from investments services and official transfersThe resulting # 1.9 billion merchandise trade deficit was partly offset by an assumed surplus of # 300 million in so-called invisible items which include income from investments services and official transfersFor the third quarter net premiums were 742 million up 9.6 % from 677 million in last year 's quarter because of the expiration of the National Indemnity quota share reinsurance agreementFor the third quarter net premiums were 742 million up 9.6 % from 677 million in last year 's quarter because of the expiration of the National Indemnity quota share reinsurance agreementBANKERS ACCEPTANCES : 8.45 % 30 days ; 8.33 % 60 days ; 8.32 % 90 days ; 8.15 % 120 days ; 8.06 % 150 days ; 7.96 % 180 daysBANKERS ACCEPTANCES : 8.45 % 30 days ; 8.33 % 60 days ; 8.32 % 90 days ; 8.15 % 120 days ; 8.06 % 150 days ; 7.96 % 180 daysAt the 932 million T. Rowe Price High Yield Fund investors yanked out about 182 million in the past two monthsAt the 932 million T. Rowe Price High Yield Fund investors yanked out about 182 million in the past two monthsImport values are calculated on a cost insurance and freight -LRB- c.i.f -RRB- basis while exports are accounted for on a free-on-board -LRB- f.o.b -RRB- basisImport values are calculated on a cost insurance and freight -LRB- c.i.f -RRB- basis while exports are accounted for on a free-on-board -LRB- f.o.b -RRB- basisThe three units are a nationwide pharmaceutical and health-products distributor a small sporting-goods chain and a combination catalog showroom and toy-store chainThe three units are a nationwide pharmaceutical and health-products distributor a small sporting-goods chain and a combination catalog showroom and toy-store chainDreyfus alone has seen its money market funds grow from 1 billion in 1975 to closes to 15 billion todayDreyfus alone has seen its money market funds grow from 1 billion in 1975 to closes to 15 billion todayAlso it was not a funny time over here what with the Vietnam War the '68 Democratic convention assassinations and riotsAlso it was not a funny time over here what with the Vietnam War the '68 Democratic convention assassinations and riotsThe Tennessee Valley Authority issued 4 billion in bonds in the federal utility 's first public debt offering in 15 yearsThe Tennessee Valley Authority issued 4 billion in bonds in the federal utility 's first public debt offering in 15 yearsFigure 8: DIORA can perform close to the ground truth even on long sentences. In this ﬁgure, n-ary trees are
shown for the ground truth. DIORA’s output is shown above the ground truth.

On Tuesday the House approved a labor-backed amendment that would require the Transportation Department to reject airline acquisitions if the person seeking to purchase a carrier had run two or more airlines previously that have filed for protection from creditors under Chapter 11 of the federal Bankruptcy CodeOn Tuesday the House approved a labor-backed amendment that would require the Transportation Department to reject airline acquisitions if the person seeking to purchase a carrier had run two or more airlines previously that have filed for protection from creditors under Chapter 11 of the federal Bankruptcy CodeThere is also speculation that Mr. Newhouse could bring in a powerhouse businessman or another Newhouse family member to run the business side in combination with a publishing executive like Robert Gottlieb who left Random House 's Alfred A. Knopf to run the New Yorker also owned by the Newhouse familyThere is also speculation that Mr. Newhouse could bring in a powerhouse businessman or another Newhouse family member to run the business side in combination with a publishing executive like Robert Gottlieb who left Random House 's Alfred A. Knopf to run the New Yorker also owned by the Newhouse familyThe Warner Bros. studio and Sony signaled they are close to a settlement yesterday asking a Los Angeles Superior Court to postpone a hearing scheduled for tomorrow on Warner 's request for a preliminary injunction blocking Mr. Guber and Mr. Peters from taking the top posts at Columbia Pictures Entertainment IncThe Warner Bros. studio and Sony signaled they are close to a settlement yesterday asking a Los Angeles Superior Court to postpone a hearing scheduled for tomorrow on Warner 's request for a preliminary injunction blocking Mr. Guber and Mr. Peters from taking the top posts at Columbia Pictures Entertainment IncRep. Edwards the California Democrat is one who pledges that he would immediately challenge Mr. Bush in the courts arguing a line-item veto would expand a president 's powers far beyond anything the framers of the Constitution had in mindRep. Edwards the California Democrat is one who pledges that he would immediately challenge Mr. Bush in the courts arguing a line-item veto would expand a president 's powers far beyond anything the framers of the Constitution had in mindThe Merc received considerable criticism in 1987 when it was discovered that its compliance director Kevin P. Conway who then was responsible for policing the exchange 's busy oil and metal pits was engaged in other personal business activities on Exchange time including out-of-state trips according to a New York Merc report prepared last yearThe Merc received considerable criticism in 1987 when it was discovered that its compliance director Kevin P. Conway who then was responsible for policing the exchange 's busy oil and metal pits was engaged in other personal business activities on Exchange time including out-of-state trips according to a New York Merc report prepared last yearFor example one of my favorite movies is the 1949 British comedy Kind Hearts and Coronets in which the entire comedy is based on actor Dennis Price 's murdering eight titled relatives -LRB- all played by Alec Guinness -RRB- because they snubbed his mother and stand in the way of his acquiring the family titleFor example one of my favorite movies is the 1949 British comedy Kind Hearts and Coronets in which the entire comedy is based on actor Dennis Price 's murdering eight titled relatives -LRB- all played by Alec Guinness -RRB- because they snubbed his mother and stand in the way of his acquiring the family titleThe leveraged buy-out firm of Kohlberg Kravis Roberts & Co. which owns 46 % of the common equity of SCI TV indicated in the debt plan that it would reduce its equity stake to 15 % giving the rest of its stake to bondholders in the restructuringThe leveraged buy-out firm of Kohlberg Kravis Roberts & Co. which owns 46 % of the common equity of SCI TV indicated in the debt plan that it would reduce its equity stake to 15 % giving the rest of its stake to bondholders in the restructuringBUSINESSLAND INC. San Jose computer retail company annual sales of 1.1 billion NYSE said all 16 corporate office and stores in the area were open with the exception of a retail center in San Francisco 's business districtBUSINESSLAND INC. San Jose computer retail company annual sales of 1.1 billion NYSE said all 16 corporate office and stores in the area were open with the exception of a retail center in San Francisco 's business districtRecognition also said it obtained a commitment from Chemical Bank and Bank of Boston to convert an estimated 18 million in bank debt to a new 24-month secured term loan to be repaid through the sale of certain assetsRecognition also said it obtained a commitment from Chemical Bank and Bank of Boston to convert an estimated 18 million in bank debt to a new 24-month secured term loan to be repaid through the sale of certain assetsThe prices of cattle and hog futures contracts dropped sharply because traders speculated that the stock market plunge Friday will linger in the minds of U.S. consumers long enough to prompt them to rein in their spending at the supermarket which would hurt demand for beef and porkThe prices of cattle and hog futures contracts dropped sharply because traders speculated that the stock market plunge Friday will linger in the minds of U.S. consumers long enough to prompt them to rein in their spending at the supermarket which would hurt demand for beef and pork