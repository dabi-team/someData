Multi-Objective Provisioning of Network Slices

1

using Deep Reinforcement Learning

Chien-Cheng Wu*,**, Vasilis Friderikos*, and ˇCedomir Stefanovi´c**

*Department of Engineering, King’s College London, London,

United Kingdom

**Department of Electronic Engineering, Aalborg University, Copenhagen,

Denmark

Abstract

Network Slicing (NS) is crucial for efﬁciently enabling divergent network applications in next-

generation networks. Nonetheless, the complex Quality of Service (QoS) requirements and diverse

heterogeneity in network services entail high complexity for Network Slice Provisioning (NSP) op-

timization. The legacy optimization methods are challenging to meet various low latency and high-

reliability requirements from network applications. To this end, we model the real-time NSP as an

Online Network Slice Provisioning (ONSP) problem. Speciﬁcally, we formulate the ONSP problem

as an Multi-Objective Integer Programming Optimization (MOIPO) problem. Then, we approximate

the solution to the MOIPO problem by applying the Proximal Policy Optimization (PPO) method to

the trafﬁc demand prediction. Our simulation results show the effectiveness of the proposed method

compared to the state-of-the-art methods with a lower SLA violation rate and network operation cost.

Index Terms

Network Slicing, Deep Reinforcement Learning, Multi-Objective Optimization, Integer Program-

ming.

I. INTRODUCTION

Network Slicing (NS) is essential in the next-generation mobile wireless networks [1]. It

enables efﬁcient connectivity to various services with diverse requirements by instantiating

multiple logical networks on top of the substrate, i.e., the physical network infrastructure.

2
2
0
2

g
u
A
4
1

]
I

N
.
s
c
[

4
v
1
2
8
3
1
.
7
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
2

Note that some emerging 5G services, such as those related to the Ultra-Reliable Low Latency

Communication (URLLC), require dedicated network resources to achieve the stringent quality

of service (QoS) requirements. NS can offer dedicated network resources for multiple network

services mapped and managed over a physical wireless network infrastructure [2]. In that respect,

a network slice can be considered as a self-contained logical network with its physical network

resources, topology and trafﬁc ﬂows with established QoS requirements [3].

In addition, Virtual Network Functions (VNFs) bring higher levels of ﬂexibility as VNFs can

be anchored at different network locations and scaled ﬂexibly with NS to meet the ﬂuctuating

user trafﬁc demands, thus allowing for efﬁcient on-demand Network Slice Provisioning (NSP).

A network slice incorporates a set of VNFs organized in different suitable locations across the

transportation paths and depending on the needs of the service. However, real-time and high-

quality resource provisioning for multiple network slices is a formidable task, proved to be

NP-hard [4].

In order to address this hurdle, the Cloud-native Network Functions (CNFs) have been actively

considered and standardized within the 3rd Generation Partnership Project (3GPP) [5]. According

to the latest 3GPP architecture [6], [7], [8], We construct slices as CNFs’ interconnections in

our NS paradigm, which align with the conventional notion of VNFs.

Within the paradigm, a slice instance should be constructed by related CNFs’ interconnections

for a user trafﬁc demand request. We further separate the CNFs’ interconnections into the data

rate and delay arrangements over the physical network infrastructure. Fig. 1 presents how the

network slice controller constructed a network slice via associating network resources with a

suitable route. Without loss of generality, a network service provider can append more network

resource variables other than the data rates and delays to the paradigm.

This paper investigates efﬁcient slice provisioning as the CNFs’ network resource provisioning

in the NS paradigm. We focus on the data rate and delay arrangements for the slice provisioning.

Our contributions include formulating a multi-objective optimization model and subsequent deep

reinforcement learning framework to optimize the network slices provision whilst being robust

to unknown trafﬁc demand ﬂuctuation of the users. The robustness in provisioning is achieved

by providing a probabilistic guarantee that the amount of provisioned slices will meet the

slice QoS requirements. We implement the deep reinforcement learning framework by using

Proximal Policy Optimization (PPO) algorithm [9] with two neural networks as a value function

and a policy function pair. Under this framework, the network slice controller determines its

3

Fig. 1: Routes from Source Node to Destination Node

slice provisioning by the optimal QoS-dependent policy from the PPO algorithm. The problem

is then solved by approximately the optimal solution with the joined slices allocation and

demands prediction. To illustrate the distinction of the computational performance, we implement

a suboptimal approach as a performance benchmark where slice provisioning demands are

considered in a batch form, i.e., as several groups sequentially. Both solutions are compared to

a nominal provisioning scheme that only processes the current user demand without considering

relations between the slice provisioning demands. Through extensive simulations, we show that

our proposed algorithm can reduce the network operation cost while keeping a low Service-Level

Agreement (SLA) violation rate.

The rest of this article is structured as follows. Section II analyzes related work and highlights

our contributions. The mobile network model, user demand requests and the network slices are

presented in Section III. The online NSP problem with uncertainties in the number of users and

the associated trafﬁc demands is then formulated in Section IV. Next, we present the existing

approaches and our reinforcement learning method to solve the robust NSP problem in Section V.

Section VI presents numerical results. Finally, Section VII concludes our perspectives.

II. RELATED WORK

Software-Deﬁned Network (SDN) uses programmable controllers to provide ﬂexible and cost-

effective network services in next-generation networks. NSP is a crucial function of SDN for

supporting dynamic user demands in different network services. The main challenge for the NSP

is to optimize the deployment of slices across the physical infrastructures matching network

4

services constraints. Therefore, we review the existing NSP design and organize the related

solutions to the NSP optimization problem.

A slice is realized as a concatenation of communication (wired-cum wireless links) and

computing resources that can span across the Radio Access Network, Transport Network, or

Core Network [10]. In the context of rule-based solutions, the authors in [11] propose a practical

NS implementation. The proposed model provides an efﬁcient solution by analyzing historical

NS information but the network slices assigned to the same tenant cannot overlap in time. The

research in [12] considers the slice provision with VNF placement for the SDN-based 5G mobile-

edge cloud. Their algorithm provides a ﬂexible slice provision by placing VNFs in distributed

data centers. Similarly, the work in [13] describes a VNF placement algorithm with emphasis on

the mobile core network, exploiting the cost of placement to allocate the VNFs. Their problem

formulation takes physical network constraints into account for different network service capacity

and connectivity.

On the other hand, the deep reinforcement learning solutions for dynamic demand optimiza-

tion continuously attract the attention of researchers. The authors of [14] propose a novel

framework that uses assured resources which are offered based on the forecast of the user

demands. According to the framework, the designed stochastic algorithm can handle the trade-

off between the trafﬁc uncertainty in the forecast and overbooking. The work [15] designed a

hybrid machine learning model for spatiotemporal prediction, where an autoencoder models the

spatial dependence, and the temporal dependence is captured by a Long Short Term Memory

neural network. We also mention [16] that proposes a heuristically-controlled A3C algorithm to

demonstrate network slice provision with dynamic trafﬁc.

To the best of our knowledge, this work presents the ﬁrst attempt to use Proximal Policy

Optimization (PPO) algorithm in multi-objective network slice provisioning. More speciﬁcally,

we formulate the network slice provisioning problem as a multi-objective integer programming

optimization problem. Then we propose a deep reinforcement learning framework that allows

for online provisioning, which jointly considers the fairness of slice provision and the cost of

network operation.

III. SYSTEM MODEL

We assume the system is time-slotted. Each action, such as time increment or user demand

request arrival, happens at the beginning of a slot and completes before the end of that slot.

5

A. Network Model

The network is modeled as an undirected graph G = (V, L), where V denotes the set of network

nodes and L is the set of undirected wired-cum-wireless links that constitute the deployed

physical infrastructure in the network. By li,j ∈ L we denote a link between nodes vi and vj

(vi, vj ∈ V). The nodes in the graph represent either a radio access network component, e.g., a

base-station (BS), a transportation regional network component or a core network element. We as-

sume that all network nodes are virtualized, which means that they are capable of running virtual

machines and/or containers over the corresponding physical (bare metal) machine capabilities.

Furthermore, we denote the available link capacity as a vector C = [C1,1, . . . , Ci,j, . . . , CV,V ],

where each element Ci,j ≥ 0 is the capacity of direct link li,j between nodes vi and vj; if there

is no link between vi and vj, then the value of Ci,j is zero. We also denote the occupied link

capacity as a function

0 ≤ α(i, j) ≤ Ci,j.

(1)

The delay of the links is given in the vector D = [D1,1, . . . , Di,j, . . . , DV,V ], where each element

Di,j ≥ 0 express the delay between vi, and vj The active network operation cost of links in L

is given by the vector P = [P1,1, . . . , Pi,j, . . . , PV,V ], where each element Pi,j ≥ 0 is the active
operation cost between nodes vi and vj.1

B. User Demand Model

We assume that the user demand requests at a time slot t is a set, denoted by R(t). Each

request r, r ∈ R(t), comes from a network application of an user, asking for a network slice

template at time slot t. All requests are generated according to a Poisson arrival model determined

by a aggregate arrival rate λ (requests/slot). A user demand request is represented as a tuple r =

{vs, vu, br, dr, Tr, ar, hr}. where vs and vu denote the source and destination nodes respectively,

br is the required data rate, dr denotes the delay requirement, and the demand type is expressed

as Tr. Further, the initial time slot of the demand is ar and the demand life time is hr slots.

Thus, the demand will start from the time slot ar, continue for hr slots, and becomes terminated

at the time slot t = ar + hr. We assume there are ﬁnite number of demand types and network

1If there is no link between vi and vj, then we assign the maximum available integer value to Di,j and Pi,j in our simulations

to represent the disconnected scenario.

6

Fig. 2: Network Slices Mapping Demonstration

nodes. When the network slice controller receives a request, the controller decides whether to

accept or reject it in an online manner.

For example, at a time slot t = t1, request set R(t1) is handled by the slice controller and then

the appropriate network slices are constructed for the requests. If a request r ∈ R(t1) cannot be

served at t1, it will be stored in a queue until the time reached the time slot (t = ar + hr). Thus,

at any time slot t there are a set of requests, R(t), that includes both new arrived requests as

well the backlogged requests (i.e. the requests that are in the queue, which currently cannot be

served and whose termination time has not yet expired).

C. Network Slice Model

Each slice n can be denoted as

n = {vn,s,r, vn,u,r, En,r, yn,r, Tn,r}

(2)

where s is the index of source node vn,s,r, u is the index of destination node vn,u,r; (vn,s,r, vn,u,r ∈
V). Further, En,r is a set of virtual links En,r = {en,r
virtual link en,r

i,j } with deﬁned provisioning resources. Each
i,j ∈ En,r can be mapped to one and only one physical link li,j between node vi
and node vj, and En,r is a loop-free path, starting from vn,s,r and ending at vn,u,r. The loop-free

path represents the connectivity constraints of the slice n. The capacity and delay constraints
of a virtual link en,r
is yn,r, which means each en,r

i,j are the same as the ones of the mapped physical link li,j. The slice load
i,j ∈ En,r occupies yn,r capacity of link li,j; therefore en,r
i,j = yn,r
i,j ∈En,r αi,j. The type of slice is denoted as Tn,r which is allocated according to
i,j ∈ En,r. A
feasible slice can only be provided by its slice controller by fulﬁlling the connectivity, capacity

yn,r ≤ min∀en,r
the demand type. Finally, the slice delay is (cid:80)

i,j ∈En,r Di,j, where i, j are in en,r
∀en,r

and delay constraints.

7

IV. PROBLEM FORMULATION

Our goal is to generate network slices that accommodate the underlying user requests in

terms of data-rate and latency whilst maximizing the deployment fairness and minimizing the

deployment cost, formally deﬁned later in the section. In particular, we avoid network congestion

at some links by maximizing the deployment fairness. To this end, we fairly distribute requests

to the whole network. We also consider the co-existence of multiple slices on the same physical

network and assume that each slice serves network trafﬁc from a single source to a single

destination, and therefore we represent a slice by a source-destination pair.

For each user trafﬁc demand r, the NS controller aims to generate an appropriate network

slice n to serve r. For example, in Fig. 2, there is user request set R and link set L. The NS

controller aims to construct a set of network slices N to serve R using (a part of) link set L.

A request r, ∀r ∈ R, can only be served by a single slice n, n ∈ N , and each n consists of
a subset of L. A virtual link en,r
en,r
i,j

i,j comes from slice n and request r. Moreover, the virtual link

is made by the physical link li,j between node vi and node vj in L.

The slice generation procedure can be decomposed into two steps. The ﬁrst step is to ﬁnd

potential end-to-end routes which can be utilized for request r from its source node vn,s,r

to its destination node vn,u,r. The second step is to ﬁnd a route which can minimize the

objective function while satisfying the constraints. To represent the link utilization, we deﬁne a
utilization matrix X: for each matrix element, xn,r
then xn,r

i,j , if slice n from request r utilizes link li,j,
i,j = 0. Since multiple slices share the same physical network, the
bandwidth allocation at each virtual link shall not exceed the available physical link bandwidth.

i,j = 1, otherwise, xn,r

We formulate the global network constraint as

i,j · en,r
xn,r

i,j ≤ Ci,j.

(cid:88)

∀n∈N
∀r∈R(t)

(3)

In addition, each virtual route in slice n mapped onto the physical links should satisfy the

requested user trafﬁc volume

Moreover, each virtual route in slice n should also satisfy the requested user trafﬁc latency

min
i,j ∈En,r

∀en,r

α(i, j) ≥ br.

(4)

xn,r
i,j · Di,j ≤ dr.

(cid:88)

∀n∈N
∀r∈R(t)

(5)

8

From the above constraints and matrices, we formulate the Online Network Slicing Provision-

ing (ONSP) problem as: Given the user demand requests, R(t), how to generate a set of slices

N with minimum cost and maximum fairness to transmit the user trafﬁc?

Speciﬁcally, the cost objective function is deﬁned as the summation of all the slices’ cost in

Eq. (6) below.

f1 = min

(cid:88)

xn,r
i,j · Pi,j

∀n∈N
∀li,j ∈L

(6)

The cost optimization strategy tends to prioritize the low-cost virtual links during slice provision-

ing. However, the priority of low-cost links should be limited within a propor level. Therefore,

we refer [17] to deﬁne the fairness objective function as the ratio of allocated data rate and

available data rate Eq. (7) below.

f2 = max

(cid:18)

(cid:80)

∀n∈N
∀li,j ∈L

|N |(cid:80)

∀n∈N
∀li,j ∈L

(cid:19)2

α(i, j)
Ci,j
(cid:18) α(i, j)
Ci,j

(cid:19)2 .

(7)

The ONSP problem is then reformulated as a Multi-Objective Integer Programming Optimiza-

tion (MOIPO) problem to construct a route for a slice, and Breadth-First Search (BFS) search

algorithm is used to ﬁnd the minimal cost paths through the network. In general, at a timeslot

t, given a set of user demand requests, R(t) as an input, our algorithm aims to generate a set

of network slices N and keep the related bandwidth and latency guarantees for every network

slice.

A. Greedy Approach

V. PURPOSED METHODS

The greedy algorithm is used as a less computationally intensive benchmark because it only

considers one possible provisioning sequence when allocating virtual links. The computational

complexity is O(V + L + R). Algorithm 1 shows a greedy ONSP algorithm. An undirected

graph, G, and user demand requests set, R(t), are given as input. We use the cardinality of a

set such as |R(t)| and |Ω| to measure the number of elements in the set |R(t)| and the set

|Ω| respectively. From the graph G and the set R(t), we can obtain the bandwidth constraint

functions and latency constraint functions, see Eq. 3, 4 and 5. Then, the greedy algorithm iterates

all requests in R(t) by a loop with ﬁnite steps. For each user demand request r ∈ R(t), we use

9

the BFS algorithm to search the graph for all possible sets of links that satisfy the connectivity

constraint of r.

A set of links can construct a unique path with a ﬁxed sequence from the BFS algorithm. If a

path can satisfy the connectivity constraint of r, we deﬁne the path is a feasible path. Otherwise,

the path is not feasible. Next, we consider all feasible paths and check the link availability of

each path based on the given bandwidth and latency constraints. If a link is not available, the

corresponding path is skipped. Otherwise, we continue to the next step.

Next, we calculate the cost and fairness values based on the objective functions. After that, we

compare the cost value and fairness value in the current step with the cost value in the previous

step. If the cost value in the current step is less than the cost value in the previous step and the

fairness value in the current step is higher than the fairness value in the previous step, we assign

the path ω to be a candidate for slice n with respect to the request r. Next, to generate a slice

n by a non-empty candidate. Otherwise, move to the next feasible path. Finally, we aggregate

each slice n as a set N for output.

Algorithm 1: Greedy Algorithm

Input: A undirected graph G = (V, L) and user demand requests, R

Output: network slices, N

1 Sort the set R by the initial time

2 for r = 1, 2, 3, · · · until r = |R| do

3

4

5

6

7

8

9

10

11

12

13

14

Find all feasible paths, Ω, based on the BFS algorithm

for ω = 1, 2, 3, · · · until ω = |Ω| do

Check the link availability in ω based on the constraint functions.

Calculate the cost value and fairness value based on the objective functions.

Compare with the previous cost value and fairness value.

if current value is better than previous value then

Assign the current ω to candidate

end

end

if candidate is not empty then

Generate a network slice n by the candidate

end

15 end

16 Aggregate all network slices to N

10

B. Integer Programming Approach

Integer Programming (IP) was introduced to model a series of optimization problems. Many

alogrithms had tried to efﬁciently solve the Integer Programming problem such as the Constraint

Integer Programming (CIP) [18]. In addition, The CIP method had been proven to be able to

obtain the optimal solution in [18]. The general form of CIP is the following: given an ﬁnite set

H of constraints hi : Rn → Z, i = {1, . . . , m}, a variable set X , x ∈ Z, ∀x ∈ X , and a vector
of objective functions f ∈ Rn, derive an optimal solution θ from X if the CIP is satisﬁable

as θ = min{f T X |hi(X) = true, ∀hi ∈ H}. Each request at a speciﬁc timeslot t in the ONSP

problem in Section IV can be written in the CIP form:

minimize

subject to

2
(cid:88)

|N |
(cid:88)

|V |
(cid:88)

|V |
(cid:88)

fk · xij

k=1

n=1

(cid:88)

j=1

i=1
α(i, j) · xij ≤ Ci,j{i, j : eij ∈ L}

n=1,...,|N |
(cid:88)

Di,j · xij ≤ di,j

∀n∈N
xi,j ∈ {0, 1},

{i, j : eij ∈ L}

i, j = 1, . . . , |V |

The considered optimization problem is indeed an integer programming problem [18]. In each

time slot, the slice controller receives a set of user demands as a request instance, R(t). The

goal of IP algorithm is to construct a set of slices and to satisfy all or part of the requests.

The computational complexity for IP algorithm to search for the optimal solution is equal to

O((V + L) × R(t) × R(t)) [19] .

C. Deep Reinforcement Learning Approach

Deep Reinforcement Learning (DRL) had been discussed in [20] to solve IP optimization

problems. Hence, we enhance the DRL framework to solve the formulated ONSP problem under

the IP model. The framework aims to construct an agent in the slice controller for the network

slices provisioning. The agent will not only learn to ﬁnd an optimal solution at a speciﬁc NSP

instance, but reuse what it has learned in previous instances. In such cases, the PPO algorithm

has been shown to achieve a higher performance than the other DRL algorithms [21]. This

motivates us to embed the PPO algorithm to our framework.

We assume an PPO agent interacting with a network environment to learn a provisioning policy

without prior information. The state space only includes the demand requests and network graph.

Given a set of demand requests R(t) the provisioning policy π(ot, θt) returns a subset of R(t)

as an action at to satisfy the network constraints in Eq. (3) and (4) and the trafﬁc demand

constraints in Eq. (5).

The action space consists of a set of actions at to represent which requests are accepted to

11

transmit in a network slice in slot t. For example, if only rt

i ∈ R(t), it means that
only request 1 is accepted to obtain network resources and to transmit trafﬁc network slice at

1 = 1 for all rt

a time slot t. The requests for which rt

i = 0 are rejected to construct their network slices and

have to wait for the next action.

Every interaction between the agent and the network environment happens at the beginning

of a slot. In each interaction, the agent samples the environment to get an observation ot and

performs an action at based on the provisioning policy. After performing the action, the agent

receives a reward R(t). Then the agent waits for the time slot t + 1 to interact with the network

environment. The learning process repeats the interactions continuously to approximate the

optimal provisioning policy, which obtains the maximal reward.

The reward function is deﬁned as follows. If the request r is accepted, the reward function is

R(t) =

(cid:88)

∀n∈N
∀li,j ∈L

xn,r
i,j · Pi,j, ∀rt

i = 1.

Otherwise, the reward function is

R(t) =

(cid:88)

∀n∈N
∀li,j ∈L

xn,r
i,j · Pi,j · (−1), ∀rt

i ∈ R(t).

(8)

(9)

In the beginning, the agent will fetch an initial environment observation o0 from the network

environment. The agent observes a set of metrics in each slot t, ot, including the links’ capacity,

bandwidth and latency requirements of received user demands, and the cost achieved in the last

k iterations. Then the agent feeds these values to the neural network, which outputs the next

action. The next action is deﬁned by which requests are to be chosen for the next iteration k + 1,

as well as how much bandwidth they will be allocated, at time slot t + 1. The provisioning

policy is transformed from the action obtained from the trained neural network. If a request

is selected to transmit packets, the required bandwidth will be fully reserved. Otherwise, the

request waits until it gets allocated. After the new provisioning is deployed to all requests, a

reward is observed and fed back to the agent. The agent uses the reward information to train

and improve its model. Our implementation of the PPO algorithm in the provisioning problem

12

is detailed in Algorithm 2. Starting from the initial parameters, the PPO algorithm optimizes its

policy π until converging or reaching K iterations. At each iteration k, the PPO agent collects

observation of a time slot. Next, it selects an action with the current policy. After the agent takes

the selected action, the agent obtains a reward based on the reward functions in Eq. (8) and (9).

In addition, we formulate a Q-value function, a state value function and an advantage function,

used to compute the intermediate values in each iteration.

Qπ(ot, at) = Eot+1,at+1[γtR(t)]

Vπ(ot) = Eot+1,at[γtR(t)]

Aπ(ot, at) = Qπ(ot, at) − Vπ(ot)

(10)

(11)

(12)

where γ is a discount factor, γ ∈ [0, 1].

Then we construct the surrogate loss on these observations and optimize policy with stochastic

gradient descent (SGD) for e epochs and minibatch size B. The computational complexity of

PPO algorithm in testing phase is also O(V + L + R).

Algorithm 2: Proximal Policy Optimization Algorithm

Input: An initial policy with parameters θ0 and initial observation o0, a set of user demand requests R(t)

Output: A set of neural network parameters

1 for k = 1, 2, 3, · · · until k = K or convergence do

Fetch user demand requests, R(t), based on observation ok.

Take action to select user demand requests using policy π = π(θk).

Compute advantage estimation based on the value function.

Optimize surrogate function ∇R(t) with respect to θk using e epochs and minibatch size B.

θk ← θk+1

2

3

4

5

6

7 end

VI. NUMERICAL INVESTIGATIONS

A. Simulation Environment

Our simulation is executed on a desktop PC with an Intel i7 CPU and 8 GB memory. To

construct a general simulation environment, we refer to the model in [22] to construct the

network graph in our simulation. Because the MOIPO problem is NP-hard and intractable in a

network with large network node sets and edge sets, we verify the proposed method with the

13

TABLE I: Simulation Parameters

Parameter Name

Number of Nodes |V |

Number of Physical Links |L|

Capacity of Links

Latency of Links

Cost of Links

Value/Distribution(mean, variance)

8

12

Uniform Distribution (100, 200)

Uniform Distribution (1, 10)

Uniform Distribution (1, 20)

Simulation Duration

1000 slots

Request Demand Requirement (b)

Normal Distribution (0, 0.1)

Request Latency Requirement (d)

Normal Distribution (1, 0.1)

Request Initial Time ar

Request Life Time hr

Request Arrival Model

Normal Distribution (0, 0.1)

Normal Distribution (1, 0.1)

Poisson Process

other two benchmarks on a reduced network scale. Some algorithms using high-performance

computing clusters have been used to solve large-scale problems, but it is beyond the scope of

this paper. Table I lists the environment parameters in our implementation.

B. Simulation Results

We validate the performance of the PPO method in terms of the SLA violation rate and

network operation cost. We deﬁne the network operation cost is the summation of all the slices’

costs with respect to the their physical links and average the cost by all requests. In addition,

we deﬁne the SLA violation rate as the ratio between the number of the provisioning requests

and the number of all requests. We also compare the results of the PPO method with the two

benchmarks, Greedy and IP. Fig. 3 shows the comparison of slice operation cost, and Fig. 4

presents the performance difference of SLA violation rate. The Greedy algorithm has the worst

cost performance and the highest SLA violation rate because the sequential requests processing

cannot closely approximate the optimal solution. The IP algorithm has better performance in

terms of the cost and SLA violation rate as it considers the complete request set in the course

of optimization. On the other hand, we verify the PPO algorithm can learn to approximate the

similiar network operation cost and SLA violation rate as the IP algorithm without any prior

information used in the IP algorithm. From Fig. 4, the reduction in SLA violation rate compared

between CIP and PPO algorithms was ranging from 1.15 to 1.28 times.

14

Fig. 3: Slices Operation Cost with Different User Request Arrival Rate

Fig. 4: SLA Violation Rate with Different User Request Arrival Rate

VII. CONCLUSIONS

We studied the NSP optimization problem by considering the cost of network operation and

the fairness of slice provisioning in a virtualized network. To minimize the network operation

cost while maximizing the provisioning fairness, we implement the PPO algorithm in our DRL

framework to predict the incoming user demand and search for the optimal solution to the

optimization problem. We also implemented two benchmark algorithms to demonstrate the

performance difference. Simulation shows the effectiveness of our DRL framework compared

with the benchmarks.

[1] P. Rost et al., “Network slicing to enable scalability and ﬂexibility in 5g mobile networks,” IEEE Commun. Mag., 2017.

REFERENCES

15

[2] P. Popovski et al., “5g wireless network slicing for embb, urllc, and mmtc: A communication-theoretic view,” IEEE Access,

vol. 6, pp. 55 765–55 779, 2018.

[3] R. Gouareb, V. Friderikos, and A.-H. Aghvami, “Virtual network functions routing and placement for edge cloud latency

minimization,” IEEE J. Sel. Areas Commun., vol. 36, no. 10, pp. 2346–2357, 2018.

[4] E. Amaldi, S. Coniglio, A. M. Koster, and M. Tieves, “On the computational complexity of the virtual network embedding

problem,” Electronic Notes in Discrete Mathematics, vol. 52, pp. 213–220, 2016.

[5] NGMN, “Future networks cloud native platform,” Next Generation Mobile Networks, Final Deliverable 5.2, 03 2021,

version 16.12.0.

[6] 3GPP, “System architecture for the 5g system,” 3rd Generation Partnership Project (3GPP), Technical Speciﬁcation (TS)

23.501, 09 2021, version 16.10.1.

[7] 3GPP, “5g system network slice selection services,” 3rd Generation Partnership Project (3GPP), Technical Speciﬁcation

(TS) 29.531, 04 2018, version 16.6.0.

[8] 3GPP, “5g; management and orchestration; provisioning,” 3rd Generation Partnership Project (3GPP), Technical Speciﬁ-

cation (TS) 28.531, 01 2022, version 16.12.0.

[9] J. Schulman et al., “Proximal policy optimization algorithms,” 2017. [Online]. Available: https://arxiv.org/abs/1707.06347

[10] V.-G. Nguyen et al., “Sdn/nfv-based mobile packet core network architectures: A survey,” IEEE Commun. Surv. Tutor.,

vol. 19, no. 3, pp. 1567–1602, 2017.

[11] V. Sciancalepore, L. Zanzi, X. Costa-P´erez, and A. Capone, “Onets: Online network slice broker from theory to practice,”

IEEE Trans. Wireless Commun., vol. 21, no. 1, pp. 121–134, 2022.

[12] R. Ford et al., “Provisioning low latency, resilient mobile edge clouds for 5g,” in Proc. IEEE INFOCOM Workshops 2017,

2017, pp. 169–174.

[13] A. Baumgartner et al., “Mobile core network virtualization: A model for combined virtual core network function placement

and topology optimization,” in Proc. IEEE NetSoft 2015, 2015, pp. 1–9.

[14] C. Sexton et al., “On provisioning slices and overbooking resources in service tailored networks of the future,” IEEE ACM

Trans. Netw., pp. 2106–2119, 2020.

[15] J. Wang et al., “Spatiotemporal modeling and prediction in cellular networks: A big data enabled deep learning approach,”

in Proc. IEEE INFOCOM 2017, 2017, pp. 1–9.

[16] A. Esteves et al., “On the robustness of controlled deep reinforcement learning for slice placement,” J. Netw. Syst. Mag.,

vol. 30, no. 3, jul 2022.

[17] R. Jain, D.-M. Chiu, and W. R. Hawe, A quantitative measure of fairness and discrimination for resource allocation in

shared computer system. Eastern Research Laboratory, Digital Equipment Corporation Hudson, MA, 1984, vol. 38.

[18] T. Achterberg et al., “Constraint integer programming: A new approach to integrate cp and mip,” 2008, pp. 6–20.

[19] F. Eisenbrand et al., “An algorithmic theory of integer programming,” 2019.

[20] W. Kool et al., “Attention, learn to solve routing problems!” in International Conference on Learning Representations,

2019.

[21] N. Heess et al., “Emergence of locomotion behaviours in rich environments,” arXiv, pp. 1–9, 2017.

[22] M. E. Newman et al., “Random graphs as models of networks,” Handbook of graphs and networks, vol. 1, pp. 35–68,

2003.

