CoCoFuzzing: Testing Neural Code Models with
Coverage-Guided Fuzzing

Moshi Wei∗, Yuchao Huang†, Jinqiu Yang‡, Junjie Wang†, Song Wang∗
∗York University, Canada
{moshiwei, wangsong}@yorku.ca
‡Concordia University, Canada
{jinqiuy}@encs.concordia.ca
†Institute of Software, Chinese Academy of Sciences, China
{hycsoge,junjie}@iscas.ac.cn

1
2
0
2

n
u
J

7
1

]
E
S
.
s
c
[

1
v
2
4
2
9
0
.
6
0
1
2
:
v
i
X
r
a

Abstract—Deep learning-based code processing models have
shown good performance for tasks such as predicting method
names, summarizing programs, and comment generation. How-
ever, despite the tremendous progress, deep learning models
are often prone to adversarial attacks, which can signiﬁcantly
threaten the robustness and generalizability of these models by
leading them to misclassiﬁcation with unexpected inputs. To
address the above issue, many deep learning testing approaches
have been proposed, however, these approaches mainly focus on
testing deep learning applications in the domains of image, audio,
and text analysis, etc., which cannot be directly applied to neural
models for code due to the unique properties of programs.

In this paper, we propose a coverage-based fuzzing framework,
CoCoFuzzing, for testing deep learning-based code processing
models. In particular, we ﬁrst propose ten mutation operators to
automatically generate valid and semantically preserving source
code examples as tests; then we propose a neuron coverage-based
approach to guide the generation of tests. We investigate the per-
formance of CoCoFuzzing on three state-of-the-art neural code
models,
i.e., NeuralCodeSum, CODE2SEQ, and CODE2VEC.
Our experiment results demonstrate that CoCoFuzzing can
generate valid and semantically preserving source code examples
for testing the robustness and generalizability of these models and
improve the neuron coverage. Moreover, these tests can be used
to improve the performance of the target neural code models
through adversarial retraining.

Index Terms—Robustness, Code Model, Language model,

Fuzzy logic, Deep learning

I. INTRODUCTION

Deep learning (DL) has recently been successfully applied
to accelerate many tasks in automated source code processing
such as prediction of variable names [1], [2], code summariza-
tion [3]–[6], and comment generation [7], [8]. Most of these
deep learning-based code models (i.e., neural code models for
short) have reported good performance.

However, deep learning models are widely known to suffer
from adversarial attacks [9], [10], i.e., a subtly-modiﬁed input
can lead neural networks to misclassiﬁcations and result in
severe erroneous behavior of DL models. More thorough
testing of neural networks can improve their reliability and
robustness. Many deep learning testing approaches have been
proposed [11]–[14], however, most of these approaches mainly
focus on generating tests for deep learning models in the
domains of image, audio, and text analysis by using mutations

image scaling,

image rotation,
such as image adjustment,
and noise addition, etc., which cannot be directly applied to
neural code models. In addition, different from adversarial
example generation for image, audio, and natural languages,
the structured nature of programming languages brings new
challenges, i.e., program must strictly follow the rigid lexical,
grammatical and syntactical constraints, and tests generated for
a program are expected to fully preserve the original program
semantics.

Recently, some adversarial example generation approaches
for source code were proposed, e.g., [15] performed variable
name replacements to perturb the programs and [16] proposed
to use both variables renaming and dead code (i.e., unused
variable declaration) insertion to generate semantically equiv-
alent adversarial examples. However, the types of perturbations
introduced by the two transformations are limited, as we have
witnessed many other types of noise/perturbation in real-world
software programs that sharing the same semantics [17]. Hence
only using the two operators may miss numerous corner cases
for the purpose of thoroughly testing neural code models.

In this paper, we propose a coverage-based fuzzing frame-
work, CoCoFuzzing, to test neural code models. Specif-
ically, we ﬁrst propose and implement ten mutation opera-
tors, which represent various real-world semantic preserving
transformations of programs, to automatically generate valid
and semantically preserving source code examples as tests.
Then we utilize a neuron coverage based guidance mecha-
nism for systemically exploring different types of program
transformations and guiding the generation of tests. We inves-
tigate the performance of CoCoFuzzing on three state-of-
the-art typical neural code models, i.e., NeuralCodeSum [3]
(leverages a self-attention-based neural network to generate
summarization of programs), CODE2SEQ [1] (builds a AST-
based RNN neural network to predict method names), and
CODE2VEC [2] (uses a path-based attention model for learn-
ing code embeddings to represent a method).

Our experiment results demonstrate that CoCoFuzzing
can generate valid and semantically preserving tests for exam-
ining the robustness and generalizability of neural code mod-
els. Speciﬁcally, the newly-generated tests by CoCoFuzzing
can reduce the performance of NeuralCodeSum, CODE2SEQ,

 
 
 
 
 
 
and CODE2VEC by 84.81%, 22.06%, and 27.58% re-
spectively. Moreover, we ﬁnd that
these new tests by
CoCoFuzzing can also be used to improve the perfor-
mance of the target neural code models through adversarial
retraining. Speciﬁcally, performance can be improved 35.15%
on NeuralCodeSum, 8.83% on CODE2SEQ, and 34.14% on
CODE2VEC by retraining the models with synthetic data
generated by CoCoFuzzing.

a

This paper makes the following contributions:
• We propose

coverage-based fuzzing framework
CoCoFuzzing for testing the robustness of neural code
models. To the best of our knowledge, CoCoFuzzing
is the ﬁrst fuzzing framework for testing neural code
models. We have released the implementation of our tool
to facilitate the replication of this study1.

• We implement ten mutation operators, which represent
various real-world semantic preserving transformations of
programs, to automatically generate tests.

• We utilize and experiment a neuron coverage-based guid-
ance mechanism for systemically exploring the large
search space constituted of different types of program
transformations and measure the adequacy of the fuzzing.
• We evaluate CoCoFuzzing on three state-of-the-
art neural code process models, i.e., NeuralCodeSum,
CODE2SEQ, and CODE2VEC. The experiment results
show the effectiveness of our tool.

The rest of this paper is organized as follows. Section II
presents the background of neural code models. Section III
describes the methodology of our proposed CoCoFuzzing.
Section IV shows the setup of our experiments. Section V
presents the result of our study. Section VI discusses the
threats to the validity of this work. Section VII presents related
studies. Section VIII concludes this paper.

II. BACKGROUND

A. Neural Code Models

The growing availability of open-source repositories creates
new opportunities for using deep learning to accelerate code
processing tasks such as prediction of variable names [1],
[2], [18], code summarization [3]–[6], and comment gener-
ation [7], [8]. The deep neural networks used in neural code
processing models mainly can be categorized into two types:
(1) Recurrent Neural Network (RNN) and (2) Attention Neural
Network. We provide a brief description of each architecture
below.
RNN architecture. A recurrent neural network is a neural net-
work that consists of a hidden state h and an optional output y
which operates on a variable-length sequence x = (x1, ..., xT ).
And at each time step t, the hidden state ht of the RNN
is updated by ht = f (ht−1, xt). f is a non-linear activation
function. Standard RNNs are not capable of learning “long-
term dependencies”, i.e., they may not propagate information
that appeared earlier in the input sequence later because of the
vanishing and exploding gradient problems. Long short-term

1https://doi.org/10.5281/zenodo.4000441

memory LSTM [19] has been proposed to address the above
issue. It introduces additional internal states, called memory
cells, that do not suffer from the vanishing gradients and it
controls what information will be propagated.
Attention network architecture. Attention neural models
have been recently widely used in the ﬁeld of natural language
process and have achieved very promising results [20]. A
neural attention mechanism equips a neural network with the
ability to focus on a subset of its inputs when processing a
large amount of information. Based on the network character-
istics, attention neural networks have three main variants, i.e.,
global and local attention [21], hard and soft attention [22], and
self-attention [23]. Recently, Google proposed the Transformer
model [24] for natural language process tasks, which is the
ﬁrst transduction model relying entirely on self-attention to
compute representations of its input and output.

B. Fuzz Testing

Software fuzzing in short generates mutants by modifying
valid seed inputs to test a program [25]. The mutants are
failed tests if they cause abnormal behaviors (e.g., crash
the system under test) otherwise are passed tests. Coverage-
guided fuzzing has been proposed and widely used to ﬁnd
many serious bugs in real software [26], in which a fuzzing
process maintains an input data corpus for the program under
consideration. Changes are made to those inputs according to
some mutation procedure, and mutated inputs are kept in the
corpus when they exercise new “coverage”. Fuzzing testing
techniques of traditional software leverage code coverage
metrics that track which lines of code have been executed and
which branches have been taken [25], [27]. However, these
traditional fuzzing frameworks could not be directly applied
to deep neural network-based software due to the fundamental
difference in the programming paradigm and the development
process [11], i.e., a neural network run on different inputs
will often execute the same lines of code and take the same
branches, yet can produce signiﬁcantly different behavior due
to the difference in input values.

To test deep neural networks, recently many coverage-
guided fuzz testing frameworks have been proposed [11], [12],
[28], which applies the neuron coverage metrics to guide
the fuzzing test to deep learning applications in the domain
of image processing and they perform image transformations
such as blurring and shearing to generate fuzzing inputs from
seed images.

III. THE APPROACH OF COCOFU Z Z I N G

In

this

the
the

section, we

describe
shows

approach
of
CoCoFuzzing. Figure
1
overview and
Algorithm 1 describes
the main algorithm in detail.
CoCoFuzzing takes a set of initial seed programs and a
neural code model as the input, and produces new test sets
iteratively through mutation generation (Section III-C) and
neuron coverage analysis (Section III-B).

e
g
a
t
n
e
c
r
e
P

0.6

0.4

0.2

0

1

2

3

4

5

6

7

8

9

10

Fig. 2: Average percentages of noise code in the mutants generated
with different M AX (i.e., X axis).

the feasibility of utilizing metamorphic testing (i.e., mutated
programs can use the same test oracle as the seed program).

Note that in traditional coverage-guided fuzzers for com-
puter programs [25], [27], a seed can be reused and mu-
tated for multiple times, e.g., these tools often use either
time constraints or the number of generated mutants as the
termination condition and a single seed can generate thousands
of mutants [29]. However, a similar process cannot be directly
applied for testing neural code models as there are no explicit
oracles (i.e., program crashes) available to assess the result of
a seed program mutated multiple times [11]. To bypass the
oracle challenge in testing neural code models, we leverage
metamorphic testing, similar to [11], [12]. A mutated program
shares the same oracle as the seed program if the transfor-
mation is semantic-preserving. Note that mutating a program
could hurt its naturalness as the inserted/mutated code could
be noise to the original program. Hence, we use a threshold
M AX to limit the maximum number of mutations applied on
a seed program, which means a seed program at most can
be mutated for M AX times accumulatively. Note that the
design of M AX controller does not guarantee the naturalness
of the inserted mutation code. A robust code model should
have the ability of ignoring the inserted noise code despite its
naturalness.

To ﬁnd an appropriate value for M AX, we randomly
selected 1,000 sample programs from the test datasets of the
three studied neural code models (details are in Section IV-A).
For each sample, we randomly select M AX mutation opera-
tors and apply them to the given sample to generate mutants.
We experiment M AX with values from 1 to 10. In the most
conservtive senario, we assume the generated code are entirely
un-natural.Hence, We measure the naturalness of the mutated
program by using the percentage of the generated code.

Figure 2 shows the average percentage of generated code
against the seed program under different M AX. With the
increass of M AX, the naturalness of code decreases dramat-
ically. For example, when M AX is equal to 1, on average
only 9.25% code in a mutated program is noise (i.e., generated
code), while M AX increases to 10, the percentage of noise
code is 59.60% on average.

Prior work showed that overall there is about 28% noise
code in real-world software projects [30]. Thus, for all the
subsequent experiments in this paper, we set M AX to three,
which yields less 30% noise code on average.

Fig. 1: The overview of our proposed CoCoFuzzing.

Algorithm 1 Coverage-Guided Test Generation in CoCoFuzzing

Input: seed programs S; target neural code model NM;
mutation operators Ops; Maximum number of mutations MAX;
Variables: sets of activated neurons N Cp, N Ccurr, bestActiva-
tionSet;
Output: generated tests T;

p ← S.pop()
N Cp ← neuronActivation(p, NM)
numTries = 1
while numTries <= MAX do

numTries++
bestMutant ← null
bestActivationSet ← ∅
bestActivationCount ← 0
for op in Ops do

1: while S is not empty do
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26: end while

end while

break

end if
end for
if bestMutant == null

end if
p ← bestMutant
N Cp ← bestActivationSet ∪N Cp
T.push(p)

then

currMutant = apply(p, op)
N Ccurr ← newNeurons(currMutant, N Cp, NM)
if size(N Ccurr) > bestActivationCount
bestActivationCount ← size(N Ccurr)
bestActivationSet ← N Ccurr
bestMutant ← currMutant

then

A. Overview of CoCoFuzzing

Algorithm 1 shows how CoCoFuzzing works step by
step. CoCoFuzzing begins by selecting one seed program
from the seed queue (line 1–2), then performs source code
transformations to the input based on a list of pre-deﬁned
mutation operators (line 11). Given the non-trivial search
space constructed by combinations of mutation operators,
CoCoFuzzing employs a neuron coverage-guided (short for
NC-guided) approach (line 5–25), to search for certain types of
mutated programs. At a high level, CoCoFuzzing searches
for program mutations that activate new neurons (line 13–
17) while controlling the maximum mutations on one seed
program (line 5 and a threshold MAX), for both naturalness and

Neuron Coverage analysisMutation GenerationSeed Program (s)Neural NetworkActivation AnalysisNeuron CoverageanalysisOp1Op2Op3Op4Op10Mutant1Mutant2Mutant3Mutant4Mutant10MutationOperatorsGenerated TestsB. Neuron Coverage Analysis

Algorithm 1 details how CoCoFuzzing uses neuron cover-
age in searching for new test data (line 5–25). In each iteration
(line 10–18), CoCoFuzzing tries all the mutation operators
and identiﬁes one mutated program that activates the most
number of new neurons. This mutated program is produced
as one test data (line 24) and also kept for the next mutation
iteration. Controlled by the threshold MAX (line 5), this mutant
might be continuously mutated in the next iteration, until
the number of mutations applied per original seed program
reaches the threshold, which is empirically set to three in our
experiments.

in PyTorch, we inject

Two methods neuronActivation and newNeurons in Algo-
rithm 1 are for neuron coverage analysis. The neuronActivation
method takes a trained neural model and one input and
produces a set of activated neurons as output. For example,
given a trained model
listeners to
monitor the neurons. Then, we run the inference or prediction
of the trained model with the input and collected the output
of each neurons using the injected listeners. Similar to prior
work [11], [12], for each neuron, we scale the value of the
neuron to the range of 0 to 1 and compare the scaled value to
a threshold. If the scaled output is greater than the threshold
(i.e., we use 0.4, the same value with [11], [12]), we consider
the neuron activated, otherwise inactivated.

The newNeurons method is very similar to neuronActi-
vation, which takes a model, one input data, and a set of
activated neurons (i.e., N Cp in line 12) as the input. The
method newNeurons calculates the activated neurons by the
input, and outputs a set of newly activated neurons by the
input but not N Cp. The implementation of neuron coverage
analysis in CoCoFuzzing is model-independent and can be
widely applied to various deep learning models.

C. Mutation Generation

In CoCoFuzzing, we adopt and implement specialized
mutation operators for mutating programs. To bypass the
oracle problem, our proposed mutation operators preserve
program semantics. Hence, the mutated programs should have
the same test oracles with the original programs, i.e., metamor-
phic testing. Prior studies [11], [12] in testing neural models
propose mutation operators for inputs such as image and audio,
e.g., image scaling, image rotation, and noise addition, etc.
These operators cannot be directly applied to source code
programs as programs must strictly follow the rigid lexical,
grammatical, and syntactical constraints.

In this work, we propose to use a set of ten mutation
operators that can be applied to method level to generate
semantically-equivalent methods. The mutation operations in-
clude transformations ranging from common refactoring like
variable renaming to more intrusive ones like adding unreach-
able branches. Table I summarizes the ten mutation operators
and how each mutation operator can be applied to transform a
program. Note that, among the ten operators, Op1 and Op10
are proposed and experimented in prior studies [15], [16] to
generate adversarial examples for neural code models. The

other eight mutation operators are ﬁrst used in this work.
These mutation operators target at a diverse types of program
transformations.

We use the open-source java parser package javalang2 for
code parsing and tokenization. Given a program T and a
mutation operator O, we ﬁrst use the AST parser from javalang
to convert T to a list of sub-AST where each element is the
AST representation of a statement. We then iterate the sub-
AST list and mark the possible positions for O regarding its
speciﬁc transformation requirements. The detailed process of
mutation generation for each operator is as follows.

• (Op1) Dead store [16]: inserts an unused variable dec-
laration with one primitive type (e.g., string, int, double,
and long, etc.) to a randomly selected basic block in the
program. The name of the variable is a string of eight
characters randomly generated in the form of [a-z]. Only
one dead store is added in each transformation by this
operator.

• (Op2 and Op3) Obfuscating: rewrites a numerical value
or variable and its usages in a statement by adding
and deleting the same random numerical value of the
same type. For example, x = 1.0; can be mutated
to x = 1.0 + 0.1 − 0.1; or x = 1.0 + 0 − 0;. If one
program contains more than one numerical variables, we
randomly pick one to perform the transformation. This
operator only works on assignment, declaration, or return
statements.

• (Op4) Duplication: duplicates a randomly selected as-
signment statement and insert immediately after its cur-
rent
the applicable as-
signment statement is limited to the ones without using
method invocation.

location. To avoid side-effect,

• (Op5 to Op9) Unreachable loops/branches: inserts an
unreachable loop or branch (including if statement, for
statement, while statement, and switch statement) into
a randomly selected basic block in the program. The
condition of the inserted loop or branch is always false
to make it unreachable.

• (Op10) Renaming [15], [16]: renames a local variable
declared in a program. If there exist multiple variables,
we randomly select one for the mutation. The new name
of the variable will be in the form of [a-z].

Note that some of the proposed operators, i.e., Op1 and
Op5–Op9, can be inserted into any locations in a given pro-
gram. In this work we randomly pick a location to apply these
mutation operators because through experiments we ﬁnd that
the chosen locations are not correlated with the effectiveness
of these mutation operators (details are in Section VI-A).

IV. EXPERIMENT SETUP

We run all the experiments on the Google Cloud Computing
Platform. Speciﬁcally, we use two n1-highmem-2 virtual cen-
tral processing unit (vCPU) with 13 gigabyte memory in total
and one NVIDIA Tesla T4 GPU as hardware of our experiment

2https://pypi.org/project/javalang/

TABLE I: Ten Semantic-Preserving Mutation Operators Ap-
plied in CoCoFuzzing.

TABLE II: Experimental datasets. ‘Pro’ is the number of
projects.

NO.
Op1 [16]

Operator name
dead store

Op2

Op3

numerical obfuscating

adding zero

Op4
Op5
Op6
Op7
Op8
Op9
Op10 [15], [16]

duplication
unreachable if
unreachable if-else
unreachable switch
unreachable for
unreachable while
renaming

Description
Inserting unused variable declarations
Obfuscating the numerical variables via
adding/deleting a same numerical value
Obfuscating the numerical values via
adding zero
Duplicating assignment statements
Inserting unreachable if statements
Inserting unreachable if-else statements
Inserting unreachable switch statements
Inserting unreachable for statements
Inserting unreachable while statements
Renaming user-deﬁned variables

machine. We use PyTorch 1.4 for running NeuralCodeSum,
TensorFlow 1.15 for CODE2SEQ, and TensorFlow 2.1 for
CODE2VEC.

A. Subject Models and Datasets

to

In

this work,

1) Studied Models:

evaluate
CoCoFuzzing, we use three state-of-the-art neural code
models that adopt different neural network characteristics, i.e.,
NeuralCodeSum [3], CODE2SEQ [1], and CODE2VEC [2].
For our experiments, we reuse the pre-trained models of the
three studied neural code models, which are released in their
papers. All the three models are common in learning code
embedding from large-scale data and generating a high-level
summary given a method. However,
the three models are
different in many aspects. First, they utilize different model
architectures. Second, they have different representations of
code. Third, the level of details in the generated summaries
from the three models is different,
i.e., NeuralCodeSum
generates full English sentence as output while CODE2SEQ
and CODE2VEC produce the name of the method. We brieﬂy
describe the details of the three models below.
NeuralCodeSum [3] uses Transformer [3] (consists of stacked
multi-head attention and parameterized linear transformation
layers for both the encoder and decoder) to generate a natural
language summary given a piece of source code. Both the code
and the summary is a sequence of tokens that are represented
by a sequence of vectors. To allow the Transformer to utilize
the order information of source code tokens, NeuralCodeSum
encodes both the absolute position and pairwise relationship
of source code tokens.
CODE2SEQ [1] uses an encoder-decoder architecture to
encode paths node-by-node and generate label as sequences. In
CODE2SEQ, the encoder represents a method’s body as a set
of AST paths where each path is compressed to a ﬁxed-length
vector using a bi-directional LSTM which encodes paths node-
by-node. The decoder uses attention to select relevant paths
while decoding and predicts sub-tokens of target sequence at
each step when generating the method’s name.
CODE2VEC [2] proposes a path-based attention model for
learning vectors for arbitrary-sized snippet of code. The model
allows to embed a program into a continuous space. Speciﬁ-
cally it ﬁrst extracts syntactic paths from within a code snippet,
i.e., ASTs, and then it represents them as a bag of distributed

Model
NeuralCodeSum
CODE2SEQ
CODE2VEC

Language
Java

Java

#Pro
9.7k

11

#Training
69.7k

#Validation
8.7k

#Test
8.7k

#Method
87.1K

692.0k

23.8k

57.1k

772.9K

vector representations.An attention network will be used to
compute a learned weighted average of the path vectors in
order to produce a single code vector.

2) Dataset: We perform our experiments using the original
datasets associated with each of the three studied neural
code models. Table II lists the basic statistics of the three
datasets. Speciﬁcally, the dataset of NeuralCodeSum contains
9.7K open source Java projects hosted in GitHub and each
of the projects has at least 20 stars. 87.1k methods that have
JavaDoc comments were collected. CODE2SEQ created three
Java datasets, which are different in size, the popularity of
the open-source software where the data is from, and the
distribution of training, validation and testing. Among the
three Java datasets by CODE2SEQ, we decided to use one,
i.e., Java-small. Despite its relatively small size among the
three, it is commonly used by prior studies [2], [6], including
CODE2VEC. Also, all the projects in Java-small are large-
scale and mature open-source software, in comparison with the
other two datasets (i.e., many are from smaller and less popular
projects). Java-small contains 11 relatively large Java projects
9 for training, 1 for validation, and 1 for testing. Overall, it
contains about 772.9K methods.

B. Evaluation Metrics

We use the same evaluation metrics with the original
papers of NeuralCodeSum, CODE2SEQ, and CODE2VEC
for comparison purpose. NeuralCodeSum adopts BLEU [31]
to evaluate its performance on predicting the summarization
of programs. BLEU is widely used to assess the quality of
machine translation systems [32]. BLEU’s output is always a
number between 0 and 1. This value indicates how similar the
predicting summarization is to the ground-truth, with values
closer to 1 representing more similar.

Differently, CODE2VEC and CODE2SEQ used precision,
recall, and F1 for measuring performance. Precision and Recall
are computed in a per-subtoken basis. F1 is the weighted
average of Precision and Recall.

C. Baseline

1) Baseline for Mutation Operators: As two of the ten
mutation operators are used in prior studies [15], [16], namely
Op1 (i.e., dead code inserting) and Op10 (i.e.,renaming). We
treat them as baselines to evaluate the eight new mutation
operators, i.e., Op2– Op9.

2) Baseline

for

NC-Guided

Test Generation:

CoCoFuzzing uses neuron coverage to guide the test
generation via the combination of mutation operators. To
evaluate the effectiveness of CoCoFuzzing we have also
designed a baseline approach that generates tests without

neuron coverage guidance, i.e., Random@K, which randomly
picks K mutation operators to generate mutants as tests. K
indicates the maximum number of mutations tries on a seed
program. As we described in Section III, CoCoFuzzing
limits the maximum number of mutation tries to three, thus in
our experiment we also set K to three. Given a seed program,
Random@3 ﬁrst randomly selects a mutation operator opi
and mutate the sample to get the mutant M 1. Then, it mutates
M 1 with another randomly selected mutation operator opj to
get a new mutant M 2, after that it further mutates M 2 with
a randomly selected mutation operator oph to generate a new
mutant M3. Through the process, opi, opj, and oph can be
the same operator. Random@3 produces a total of 3 mutants
for a given seed program.

D. Research Questions

We have implemented CoCoFuzzing as a self-contained
fuzz testing framework in Python based on deep learn-
ing framework Keras, TensorFlow, and Pytorch. With
CoCoFuzzing, we perform a large-scale comparative study
to answer the following four research questions.

RQ1: Are the neural code models robust against simple
perturbations?

Robustness has been extensively studied in classic deep
learning application domains, e.g., image processing, speech
recognition, and NLP. Many of these deep learning models
have been shown that they could be easily attacked by simple
perturbations. As the ﬁrst study on exploring the robustness
of neural code models, in this RQ, we explore whether they
also suffer similar issues.

RQ2: What is the effectiveness of each mutation operator?

This RQ illustrates the effectiveness of each mutation oper-
ator (a total of ten in Table I) regarding its capability of intro-
ducing perturbations that can affect the performance of neural
code models and activating different neurons. Furthermore,
this RQ also examines the effectiveness of the two baseline
operators (i.e., Op1 and Op10) in comparison to other eight
new mutation operators.

RQ3: What is the effectiveness of the NC-guided test genera-
tion in CoCoFuzzing?

CoCoFuzzing uses neuron coverage to guide the search
for new tests that are continuously transformed through mul-
tiple mutation operators. This RQ explores the performance
of CoCoFuzzing and compares it with our constructed
baseline, i.e., Random@3.

RQ4: Is CoCoFuzzing useful for improving neural code
models?

This RQ explores whether the synthetic programs can
improve the neural code models, i.e., whether retraining with
with CoCoFuzzing’s synthetic programs can make these
models more robust.

TABLE III: The results of testing the three neural code models
on the test data before (i.e., 1K original) and after (1K mutants)
introducing simple perturbations.

Model

NeuralCodeSum

CODE2SEQ

CODE2VEC

Test data
1K original
1K mutants
1K original
1K mutants
1K original
1K mutants

Performance (%)
BLEU = 40.82
BLEU = 12.46
F1 = 71.16
F1 = 66.96
F1 = 47.68
F1 = 45.56

V. RESULT ANALYSIS

A. RQ1: Robustness of Neural Code Models

Approach. To answer this question, we re-use the original
test sets of each model as a start point of the experiment.
Speciﬁcally, for each studied neural code model, we randomly
selected 1,000 samples from its original test dataset. For each
sample, we randomly select one of the ten mutation operators
from Table I and apply the mutation operator to the sample
to generate a test. Note that, given a sample program, it is
possible that some mutation operators are not applicable, e.g.,
Op4-duplication cannot be applied if a program does not have
any assignment statements. If this happens, we continue to
randomly select another mutation operator until one mutated
program is generated. Based on our experiments, at least one
of the ten mutation operators can be applied to any of the
samples. Hence, we have 1,000 mutated programs from the
1,000 samples for each neural model. Then we evaluate the
three pre-trained neural models with the 1,000 sample (i.e., 1k
original) and the generated 1,000 mutants (i.e., 1k mutants).
Results. Table III shows the impacts of the simple pertur-
bations on the performance of the neural models. In particular,
we show the performance (either BLEU or F1) of the studied
neural code models under two test datasets, i.e., before and
after perturbations. For all the three neural code models, we
notice the performance on 1k mutants decreases comparing
to 1k original. Speciﬁcally, for NeuralCodeSum, the BLEU
score reduces 69.5% (from 40.82 to 12.46). The F1 scores of
CODE2SEQ and CODE2VEC reduce 5.9% (from 71.16% to
66.96%) and 4.44% (from 47.68% to 45.56%) respectively.

Although all the three neural code models are susceptible
to semantic-equivalent transformations; however, the impact
of simple perturbations on the performance differs across the
three neural models. As we can see the performance of Neural-
CodeSum has declined signiﬁcantly compared to CODE2SEQ
and CODE2VEC. The main reason is that NeuralCodeSum
uses one token sequence to represent the entire body of a
method and most of our proposed mutation operators can
introduce new tokens into the method body, which impacts the
representation vector and may further impact the performance
of the model. While CODE2SEQ and CODE2VEC use both
AST paths and AST token information to represent the entire
body of a method, which are more stable than the token-based
representation of NeuralCodeSum. Thus these two models
are less susceptible to the perturbation introduced by random
mutation.

TABLE IV: Performance of different operators on Neural-
CodeSum, CODE2SEQ, and CODE2VEC. ‘Original’ shows
the 1k original test set. ‘Op1’–‘Op10’ represent the test sets
with the perturbations introduced by one mutation operator
respectively. Numbers in the brackets are the performance
decline of the examined neural models on the mutated test
set compared with the original test set.

NeuralCodeSum
BLEU (%)

40.82
8.59 (78.95%↓)
8.88 (78.26%↓)
8.84 (78.34%↓)
9.29 (77.21%↓)
6.02 (85.25%↓)
6.16 (84.90%↓)
6.23 (84.73%↓)
7.19 (82.38%↓)
7.16 (82.45%↓)
37.08 (9.16%↓)

CODE2SEQ
F1 (%)

71.16
68.23 (4.29%↓)
70.75 (0.58%↓)
70.70 (0.65%↓)
70.85 (0.43%↓)
60.57 (17.49%↓)
58.65 (21.33%↓)
59.82 (18.96%↓)
64.67 (10.04%↓)
63.72 (11.68%↓)
71.06 (0.14%↓)

CODE2VEC
F1 (%)

47.68
45.32 (5.05%↓)
47.50 (0.23%↓)
47.15 (0.97%↓)
47.10 (1.08%↓)
44.73 (6.32%↓)
44.78 (6.32%↓)
46.13 (3.21%↓)
43.81 (8.69%↓)
41.04 (16.01%↓)
47.49 (0.25%↓)

Original
Op1
Op2
Op3
Op4
Op5
Op6
Op7
Op8
Op9
Op10

TABLE V: The average neuron coverage of the test sets
generated using different mutation operators. Numbers in the
brackets are the average number of newly activated neurons.

Original
Op1
Op2
Op3
Op4
Op5
Op6
Op7
Op8
Op9
Op10

NeuralCodeSum
44.94%
47.33% (722.80)
47.07% (702.65)
47.06% (702.32)
45.75% (700.31)
47.55% (745.05)
47.49% (742.95)
47.48% (741.40)
48.11% (768.31)
48.10% (772.08)
44.91% (459.86)

CODE2SEQ
90.79%
91.46% (39.08)
90.73% (16.72)
90.76% (11.17)
90.68% (19.80)
88.61% (55.83)
89.53% (55.44)
88.98% (53.99)
91.36% (52.39)
91.50% (53.21)
90.86% (21.82)

CODE2VEC
60.99%
61.48% (19.13)
61.00% (32.90)
60.98% (25.12)
61.17% (31.00)
62.37% (50.82)
62.33% (44.40)
62.04% (41.91)
62.66% (48.44)
62.70% (49.41)
60.97% (25.17)

The studied neural code models face the robustness issues
as their performance is negatively impacted by simple
perturbations to test data. However, the negative impacts
vary due to the use of different representations of code by
each neural code model.

B. RQ2: Comparison Across Different Mutation Operators

Approach. To answer this question, we use the same 1K
original test sets for the three neural code models collected in
RQ1 (Section V-A). For each mutation operator in Table I, we
apply it on the 1K original test dataset to generate new test
data. In total, we generate 10 new test sets, i.e., each test set
is generated by applying one particular mutation operator. We
then examine the performance of the three neural code models
on each of the new test sets.

We further examine the differences in terms of neuron
coverage between each new test set and the original test set.
In particular, we compute the neuron coverage of each test
data, then calculate the average neuron coverage of each test
set. Also, we calculate the average number of newly activated
neurons of each test set based on a pairwise comparison
between an original test data and a mutated one, i.e., the

activated neurons in a mutated data that are not activated by
the original data.

Moreover, we examine the difference between the two sets
of activated neurons: one by an original test set, and the other
by the mutated new test set. In particular, we calculate the
Jaccard distance of each mutant sample against the original
sample for each test set. Given two sets of neurons N 1 and N 2
respectively. We measure their Jaccard distance by 1− N 1∩N 2
N 1∪N 2 .
The Jaccard distance can be a value between 0 and 1, with 1
indicating no overlap at all and 0 indicating a complete overlap
between the two sets.

Results. Comparison Across the Ten Mutation Operators.
Overall, from the results shown in Table IV, we observe
that the performance of each model decreases on each of
the 10 new test sets, i.e., the performance decline of Neu-
ralCodeSum ranges from 9.16% (Op10) to 85.25% (Op5)
and the performance decline of CODE2SEQ and CODE2VEC
ranges from 0.14% (Op10) to 21.33% (Op6) and 0.23%
(Op2) to 16.01% (Op9) respectively. In addition, we can
also see that the most effective mutation operators for each
model are different, e.g., Op5 is the most effective mutation
operator for NeuralCodeSum, while for CODE2SEQ and
CODE2VEC, the most effective mutation operator is Op6 and
Op9 respectively. We further conduct the Mann-Whitney U
test (p < 0.05) to compare the performance of the three neural
code models under test data with (i.e., Op1–Op10) and without
perturbations (i.e., original test set). The results suggest that
the performance decline caused by simple perturbations is
statistically signiﬁcant in all the ten test sets and for all the
three studied neural code models.

Table V shows the comparison results across different
mutation operators with regards to the impact on neuron
coverage. Overall, the impact of each operator on neuron
coverage varies across the studied neural code models. For
example Op2–Op7 signiﬁcantly improve the neuron coverage
on NeuralCodeSum, while decreasing the neuron coverage on
CODE2SEQ. This may be caused by the unique architecture of
different models and properties of the test data. Interestingly,
despite the decreased neuron coverage, we notice that all the
mutation operators can activate new neurons compared to the
original test sets. This supports our design choice of using
newly activated neurons instead of neuron coverage when
guiding the search in fuzzing (line 12, Algorithm 1).

Figure 3a, Figure 3b, and Figure 3c show the distribution of
the Jaccard distance between the neuron coverage caused by
each of the ten test datasets and the 1k original test data for
NeuralCodeSum, CODE2SEQ, and CODE2VEC respectively.
From these ﬁgures, we can see that the Jaccard distances
vary for different operators and these results also conﬁrm
that different mutation operators activate different neurons at
different rates.

Op2–Op9 v.s. Op1 and Op10. As we described in Sec-
tion III-C, operators Op1 and Op10 are proposed and used in
prior studies [15], [16] to generate adversarial examples for
neural code models. Regarding the effectiveness on reducing

(a) NeuralCodeSum

(b) CODE2SEQ

(c) CODE2VEC

Fig. 3: Difference in neuron coverage caused by different mutation operators in the three models.

test sets,
TABLE VI: Comparison results across original
newly generated test sets using Random@3 and NC-guided
(CoCoFuzzing) strategies. NC denotes Neuron Coverage
and JD is the Jaccard Distance.

Model

NeuralCodeSum

CODE2SEQ

CODE2VEC

Strategies
1k original
Random@3
NC-guided
1k original
Random@3
NC-guided
1k original
Random@3
NC-guided

#New Tests Performance (%)

-
3,000
2,906
-
3,000
2,969
-
3,000
3,000

BLEU = 40.82
BLEU=8.59 (78.95%↓)
BLEU=6.20 (84.81%↓)
F1 = 71.16
F1=63.36 (10.96%↓)
F1=55.46 (22.06%↓)
F1 = 47.68
F1=42.93 (9.96%↓)
F1=34.53 (27.58%↓)

NC(%)
44.94
47.39
48.95
90.79
95.15
95.71
60.99
72.24
75.23

JD
-
0.29
0.32
-
0.05
0.08
-
0.17
0.25

the performance of a neural model for code, ﬁve (i.e., Op5–
Op8) of the eight operators (i.e., Op2–Op9) can outperform
Op1 and all can outperform Op10 on NeuralCodeSum. We can
also observe similar results on CODE2SEQ and CODE2VEC,
i.e., ﬁve and four of the new proposed eight mutation operators
can outperform Op1 respectively and Op10 is worse than all
the eight new operators. In this work, we use all the ten
mutation operators for the mutation-based test case genera-
tion, as each operator represents a unique type of semantic
preserving transformations, which may trigger a different part
of the examined neural code models, their different neuron
coverage also conﬁrms this.

All the ten mutation operators are shown to be effective
in introducing perturbations that can signiﬁcantly impact
the performance of the studied neural code models. Our
detailed analysis reveals that a mutated test set often
activates a different set of neurons compared with the
original test set. Last, the eight new mutation operators (i.e.,
Op2–Op9) are comparable or outperform the two operators
(Op1 and Op10) used in prior studies.

C. RQ3: Effectiveness of CoCoFuzzing

Approach. We reuse the 1k original test data collected in
RQ1 (Section V-A) to explore the performance of the NC-
guided mutation generation in CoCoFuzzing. For each test
program in 1k original dataset, we use CoCoFuzzing and
the baseline approach Random@3 to generate new test data
respectively. Note that, the number of new test data generated
by CoCoFuzzing has an upper bound, i.e., three times of

the seed programs (see details in Section III-A). The actual
generated test set may contain less than the upper bound as
the test data that does not activate new neurons is discarded.
Meanwhile, Random@3 generates three new mutants for each
seed program and yields a total of 3,000 generated programs.
Thus the number of generated mutants of these two approaches
might not be the same. Then we examine the performance of
the three models on the two new test sets (i.e., CoCoFuzzing
and Random@3) respectively. Last, we calculate the average
neuron coverage of each test set and the average Jaccard
distance between each mutated test data and its original test
data (i.e., one seed program in the 1k original test set).
Results. As we can see from the results in Table VI, both
CoCoFuzzing and Random@3 can generate new tests that
detect more classiﬁcation errors on the neural code models.
With the newly generated tests, the performance of each exam-
ined model decreases signiﬁcantly and the decline rate can be
up to 84.81% (i.e., NC-guided on NeuralCodeSum). In terms
of neuron coverage, NC-guided strategy (CoCoFuzzing)
achieves a lightly higher neuron coverage than Random@3
and 1k original. Compared with the 10 test sets by applying
each mutation operator individually (Table V), the NC-guided
strategy also achieves the highest neuron coverage. Based on
Jaccard distance, on average, the NC-guide strategy generates
that activates more neurons compared to
a new test set
Random@3.

utilizing

coverage-guided

By
strategy,
CoCoFuzzing is more effective in testing neural
code models than the baseline Random@3, i.e., a lower
BLEU or F1 value, a higher neuron coverage, and a higher
ratio of newly activated neurons.

fuzzing

D. RQ4: Usefulness of CoCoFuzzing on Improving Models

Approach. Similar to Deeptest [12], as a proof-of-concept,
we showcase the usefulness of the mutated test data by using
a subset of the entire training data. In particular, we ﬁrst
train the three neural models with 10k randomly selected
original training data from scratch. We reuse the validation
dataset provided by each of the three models during the
training process. Then for each neural code model, we apply
CoCoFuzzing and Random@3 on the selected 10K training
data to generate two new test sets. Combining the mutated test
sets and the 10K randomly selected training data, we obtain

TABLE VII: Model retrain scenarios and the corresponding per-
formance. TrData indicates the randomly selected 10K training
training dataset. TrData+CoCoFuzzing
data from the original
indicates an enhanced training dataset by combining TrData and
the synthetic inputs generated by applying CoCoFuzzing on Tr-
Data. TrData+Random indicates an enhanced training dataset by
combining TrData and the synthetic inputs generated by applying
Random@3 on TrData;

Model

NeuralCodeSum

CODE2SEQ

CODE2VEC

Performance (%)
Training data
BLEU = 16.50
TrData
TrData+Random
BLEU = 20.32
TrData+CoCoFuzzing BLEU = 22.30
TrData
F1 = 22.98
F1 = 23.16
TrData+Random
TrData+CoCoFuzzing F1 = 25.01
F1 = 11.54
TrData
TrData+Random
F1 = 15.13
TrData+CoCoFuzzing F1 = 15.48

two sets of enhanced training datasets, i.e., one enhanced by
CoCoFuzzing and one by Random@3. We then re-train each
of the three models with the two enhanced training datasets
respectively. Finally, we evaluate these re-trained models on
the 1K original test dataset.
Results. Table VII compares the performance across three
types of training sets, i.e., original data, original data en-
hanced by Random@3 strategy, and original data enhanced by
CoCoFuzzing. As we can see from the table, in all cases,
the performance of the re-trained model improved signiﬁcantly
over the original model and the improvements are 35.15%
on NeuralCodeSum, 8.83% on CODE2SEQ, and 34.14% on
CODE2VEC.

Performance of
the three neural code models can
be improved 35.15% on NeuralCodeSum, 8.83% on
CODE2SEQ, and 34.14% on CODE2VEC by retraining the
models with synthetic data generated by CoCoFuzzing.

VI. DISCUSSIONS

A. Impact of the Applied Locations of Mutation Operators

Some of the mutation operators in CoCoFuzzing can be
applied in any locations in a given program (i.e., location
independent). For example, Op1 inserts an unused variable
declaration into a randomly selected basic block of in a
program, thus for any non-empty program there exists more
than one location for Op1. Among the ten mutation operators
listed in Table I, Op1 and Op5–Op9 are location independent.
To better understand the impact of this randomness on the
performance of CoCoFuzzing, for each location indepen-
dent operator, we apply it on the 1K original test dataset to
get a new test dataset. Then we collect the performance of
the three models on the new test datasets. We rerun the above
process 10 times and calculate the standard deviation values
and the distribution of the performance of the three neural
models. Table VIII shows the detailed results.

We ﬁnd that, for all the location-independent operators,
their effectiveness on neural code model is insensitive to the

TABLE VIII: Statistics of the impact of the position independent
mutation operations used in this study. Performance Distribution
indicates the distribution of the performance of a model with 10
different test datasets generated by a mutation operator. SD is the
standard deviation of the performance of a model with different test
datasets.

Model

Operator

NeuralCodeSum
BLEU(%)

CODE2SEQ
F1(%)

CODE2VEC
F1(%)

Op1
Op5
Op6
Op7
Op8
Op9
Op1
Op5
Op6
Op7
Op8
Op9
Op1
Op5
Op6
Op7
Op8
Op9

Performance Distribution
Average (± Range)
7.10 (±0.28)
5.78 (±0.43)
5.88 (±0.38)
5.92 (±0.40)
6.50 (±0.00)
6.61 (±0.00)
65.05 (±1.47)
63.98 (±1.02)
62.09 (±1.56)
64.02 (±1.26)
64.65 (±1.34)
65.66 (±1.14)
60.51 (±2.46)
59.95 (±2.01)
57.81 (±2.44)
60.34 (±1.29)
58.42 (±2.14)
54.62 (±1.91)

SD

0.16
0.27
0.23
0.24
0.00
0.00
0.01
0.006
0.009
0.008
0.008
0.008
0.02
0.01
0.01
0.009
0.01
0.01

TABLE IX: The distribution of selected mutation operators on the
three models.

Operator
Op1
Op2
Op3
Op4
Op5
Op6
Op7
Op8
Op9
Op10

NeuralCodeSum CODE2SEQ CODE2VEC

9.05%
8.39%
4.43%
2.82%
15.79%
14.83%
13.97%
12.73%
13.21%
4.74%

6.46%
10.83%
2.13%
0.63%
19.00%
14.83%
9.13%
18.33%
16.50%
1.10%

0.87%
15.30%
2.63%
1.23%
26.07%
11.03%
5.53%
16.67%
19.37%
1.30%

applied locations, i.e., the variance is small. Our One-Way
ANOVA test results show that there is no signiﬁcant difference
among the performance of the 10 runs, which suggests that the
locations of generated mutants do not signiﬁcantly impact the
effectiveness of CoCoFuzzing. Thus, in our experiments we
randomly pick a location to apply these mutation operators.

B. Distribution of the Selected Mutation Operators

CoCoFuzzing adopts a neuron coverage guidance algo-
rithm to generate new tests with the ten pre-deﬁned mutation
operators. To further understand the operator selection process
in CoCoFuzzing, we collected the selected operator for
each mutant generated by CoCoFuzzing for each of the
three neural code models, i.e., NeuralCodeSum, CODE2SEQ,
and CODE2VEC. Table IX shows the percentage of each
operator used among the tests generated by CoCoFuzzing
on each model. Overall, we can see that distribution of the
selected operators varies dramatically among different neural
code models, e.g., Op10 was used among 5% of all
the
generated tests in NeuralCodeSum while less than 1% of the
generated tests from CODE2SEQ used Op10. In addition,
we can also see that some of the operators are dominating
across different models e.g, Op5 has been used in more than

15% of the generated tests on each model. While these also
exist in the operators that are selected less frequent across
the three models, i.e., Op1,Op3, Op4, and Op10 are used in
less than 10% of the generated test cases across the three
models. One of the possible reasons is that Op5 activates
relatively more new neurons than other operators (As shown
in Table V). We have conducted Spearman rank correlation
to compute the correlation between the number of newly
activated neurons of mutants generated by an operator and
the frequency of an operator used in a neural code model. The
Spearman correlation values are 0.78 in NeuralCodeSum, 0.68
in CODE2SEQ, and 0.92 in CODE2VEC, which indicates that
the frequency of an operator used in a neuron code model is
positively correlated with its ability to activate new neurons
(compared to the original tests).

C. Threats to Validity

The selection of the studied neural code models and ex-
perimental projects could be a threat
to validity. In this
work, we only evaluated CoCoFuzzing on NeuralCodeSum,
CODE2SEQ, and CODE2VEC with Java programs. Therefore,
our results may not generalize to other neural code models
or other programming languages. We leave the evaluation of
the general applicability of our approach as future work. To
generate new tests, this paper adopts ten different mutation
operators for program transformations. Although these muta-
tion operators have been examined can help generate effective
mutants, these mutation operators may not represent many
possible transformations for software programs. In addition,
most of the used mutation operators are designed for object
oriented programming languages, e.g., Java, which might
not work for other program languages. We will extend our
approach with more mutation operators for supporting more
program languages. CoCoFuzzing uses a threshold M AX
to limit the maximum number of mutation tries on a seed
program. We set M AX to three in this work to simulate the
natural statistics of unused code in software projects, while
the performance of CoCoFuzzing could vary with different
values of M AX. We plan to explore the effectiveness of
CoCoFuzzing with more M AX values in the future. In
this work, following existing studies [11], [12] we use neuron
coverage to guide the generation of valid mutants.

In this work, following existing fuzzers for testing deep
learning models, we also use neuron coverage to guide the gen-
eration of tests. Although there have been increasing discus-
sions on whether neuron coverage is a meaningful metric, our
experiments show that it works for testing neural code models.
We plan to examine the effectiveness of CoCoFuzzing with
more criteria.

VII. RELATED WORK

A. Testing Deep Learning Models

In recent years, there are many studies on testing deep
learning models [9]–[12], [28], [33]–[35]. Pei et al. [10] pro-
posed DeepXplore to systematically ﬁnd inputs that can trigger
inconsistencies between multiple deep neural networks. They

introduced neuron coverage as a systematic metric for mea-
suring how much of the internal logic of a model have been
tested. Tian et al. [12] proposed DeepTest for failure detection
on DNN-based Autonomous driving system. They adopted the
neuron coverage metric as the criteria to generate synthetic
inputs to test deep learning models. We use neuron coverage
as guidance to our Mutation operator selection algorithm in
our work. Ma et al. [9] purposed DeepGauge with 5 testing
criterion for deep learning models, which extend the coverage
metrics from neuron-level to layer-level. Odena et al. [28] pre-
sented TensorFuzz which applied fuzz-based coverage testing
for deep learning systems. Nejadgholi [35] studied the oracle
approximation issues in testing deep learning libraries. Guo
et al. [33] proposed DLFuzz, a differential fuzzing testing
framework to guide deep learning systems exposing incorrect
behaviors. Xie et al. [11] proposed DeepHunter, a fuzzing
testing-based tool for testing deep learning models, in which
they examined different types of seed selection strategy and
test criteria.

The main difference between our work and the above studies
is that most of the existing tools focus on general deep learning
models in classic deep learning application domains, e.g.,
image processing, speech recognition, and natural language
processing (NLP). While CoCoFuzzing is the ﬁrst fuzzing
framework for neural code models.

B. Adversarial machine learning.

Adversarial machine learning primarily focuses on generat-
ing adversarial examples to improve the performance of deep
learning models [18], [34], [36]–[40]. Gradient ascent-based
adversarial example generation such as FGSM (Goodfellow
et al. [41]) and BIM (Kurakin et al. [42]), which leverages
the gradient of the model for ﬁnding adversarial example
similar to the original input, has been widely used to accelerate
the adversarial example generation problem for deep learning
applications in the domains of image processing, speech
recognition, and natural language processing.

Recently, Yefet et al. [16] proposed DAMP, i.e., a gradient-
based adversarial example generation technique, to generate
adversarial examples for deep learning models in the domain
of source code process. DAMP adopted two semantic preserv-
ing transformation operators, i.e., renaming variables and dead
code inserting. Zhang et al. [15] proposed MHM that gen-
erated adversarial examples by renaming variables based on
a sampling algorithm. Their experimental results demonstrate
that MHM could effectively generate adversarial examples to
attack the subject code process models. Vahdat et al. [43]
proposed a search-based testing framework for adversarial
robustness testing. The differences to CoCoFuzzing are,
ﬁrstly, out of the 10 operators CoCoFuzzing uses, there
are 8 different operators compare to Vahdat et al.’s work. For
the two similar operators (Renaming and Argument adding),
CoCoFuzzing rename the variables with an 8-characters-
length random string, while Vahdat et al.’s work uses the
synonym of variable. Secondly, they used an evaluation metric
derived from DeepMutation++ [44] to guide the mutation,

while CoCoFuzzing uses neuron coverage (NC) to guide
the mutation.

VIII. CONCLUSION

This work proposes a coverage-based fuzzing framework,
CoCoFuzzing, for testing deep learning-based models for
code processing. In particular, we ﬁrst propose and im-
ten mutation operators to automatically generate
plement
valid (i.e., semantically preserving) source code examples as
tests; we then propose a neuron coverage-based approach
to guide the generation of tests. We investigate the perfor-
mance of CoCoFuzzing on three state-of-the-art and typi-
cal neural code models, i.e., NeuralCodeSum, CODE2SEQ,
and CODE2VEC. Our experiment results demonstrate that
CoCoFuzzing can generate diverse and valid tests for ex-
amining the robustness and generalizability of neural code
models. Moreover, the generated tests can be used to improve
the performance of the target neural code models through
adversarial retraining.

REFERENCES

[1] U. Alon, S. Brody, O. Levy, and E. Yahav, “code2seq: Generating
sequences from structured representations of code,” arXiv preprint
arXiv:1808.01400, 2018.

[2] U. Alon, M. Zilberstein, O. Levy, and E. Yahav, “code2vec: Learning
distributed representations of code,” Proceedings of the ACM on Pro-
gramming Languages, vol. 3, no. POPL, pp. 1–29, 2019.

[3] W. U. Ahmad, S. Chakraborty, B. Ray, and K.-W. Chang, “A
transformer-based approach for source code summarization,” arXiv
preprint arXiv:2005.00653, 2020.

[4] X. Hu, G. Li, X. Xia, D. Lo, and Z. Jin, “Deep code comment gener-
ation,” in 2018 IEEE/ACM 26th International Conference on Program
Comprehension (ICPC).

IEEE, 2018, pp. 200–20 010.

[5] Y. Liang and K. Q. Zhu, “Automatic generation of text descriptive
comments for code blocks,” in Thirty-Second AAAI Conference on
Artiﬁcial Intelligence, 2018.

[6] M. Allamanis, H. Peng, and C. Sutton, “A convolutional attention
network for extreme summarization of source code,” in International
conference on machine learning, 2016, pp. 2091–2100.

[7] X. Hu, G. Li, X. Xia, D. Lo, and Z. Jin, “Deep code comment generation
with hybrid lexical and syntactical information,” Empirical Software
Engineering, vol. 25, no. 3, pp. 2179–2217, 2020.

[8] M. Chen and X. Wan, “Neural comment generation for source code with
auxiliary code classiﬁcation task,” in 2019 26th Asia-Paciﬁc Software
Engineering Conference (APSEC).

IEEE, 2019, pp. 522–529.

[9] L. Ma, F. Juefei-Xu, F. Zhang, J. Sun, M. Xue, B. Li, C. Chen,
T. Su, L. Li, Y. Liu et al., “Deepgauge: Multi-granularity testing criteria
for deep learning systems,” in Proceedings of the 33rd ACM/IEEE
International Conference on Automated Software Engineering, 2018, pp.
120–131.

[10] K. Pei, Y. Cao, J. Yang, and S. Jana, “Deepxplore: Automated whitebox
testing of deep learning systems,” in proceedings of the 26th Symposium
on Operating Systems Principles, 2017, pp. 1–18.

[11] X. Xie, L. Ma, F. Juefei-Xu, M. Xue, H. Chen, Y. Liu, J. Zhao,
B. Li, J. Yin, and S. See, “Deephunter: A coverage-guided fuzz testing
framework for deep neural networks,” in Proceedings of the 28th ACM
SIGSOFT International Symposium on Software Testing and Analysis,
2019, pp. 146–157.

[12] Y. Tian, K. Pei, S. Jana, and B. Ray, “Deeptest: Automated testing
of deep-neural-network-driven autonomous cars,” in Proceedings of the
40th international conference on software engineering, 2018, pp. 303–
314.

[13] P. Zhang, Q. Dai, and P. Pelliccione, “Cagfuzz: Coverage-guided ad-
versarial generative fuzzing testing of deep learning systems,” arXiv
preprint arXiv:1911.07931, 2019.

[14] M. Alzantot, Y. Sharma, A. Elgohary, B.-J. Ho, M. Srivastava, and K.-
W. Chang, “Generating natural language adversarial examples,” arXiv
preprint arXiv:1804.07998, 2018.

[15] H. Zhang, Z. Li, G. Li, L. Ma, Y. Liu, and Z. Jin, “Generating adversarial
examples for holding robustness of source code processing models,” in
Proceedings of the AAAI Conference on Artiﬁcial Intelligence, vol. 34,
no. 01, 2020, pp. 1169–1176.

[16] N. Yefet, U. Alon, and E. Yahav, “Adversarial examples for models of

code,” arXiv preprint arXiv:1910.07517, 2019.

[17] M. Allamanis, “The adverse effects of code duplication in machine
learning models of code,” in Proceedings of the 2019 ACM SIGPLAN
International Symposium on New Ideas, New Paradigms, and Reﬂections
on Programming and Software, 2019, pp. 143–153.

[18] U. Alon, M. Zilberstein, O. Levy, and E. Yahav, “A general path-
based representation for predicting program properties,” ACM SIGPLAN
Notices, vol. 53, no. 4, pp. 404–419, 2018.

[19] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural

computation, vol. 9, no. 8, pp. 1735–1780, 1997.

[20] W. Yin, H. Sch¨utze, B. Xiang, and B. Zhou, “Abcnn: Attention-based
convolutional neural network for modeling sentence pairs,” Transactions
of the Association for Computational Linguistics, vol. 4, pp. 259–272,
2016.

[21] M.-T. Luong, H. Pham,

ap-
proaches to attention-based neural machine translation,” arXiv preprint
arXiv:1508.04025, 2015.

and C. D. Manning,

“Effective

[22] T. Shen, T. Zhou, G. Long, J. Jiang, S. Wang, and C. Zhang, “Reinforced
self-attention network: a hybrid of hard and soft attention for sequence
modeling,” arXiv preprint arXiv:1801.10296, 2018.

[23] H. Zhang, I. Goodfellow, D. Metaxas, and A. Odena, “Self-attention
generative adversarial networks,” in International Conference on Ma-
chine Learning, 2019, pp. 7354–7363.

[24] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in Advances
in neural information processing systems, 2017, pp. 5998–6008.

[25] M. Zalewski, “American fuzzy lop,” 2014.
[26] M. Aizatsky, K. Serebryany, O. Chang, A. Arya, and M. Whittaker,
“Announcing oss-fuzz: Continuous fuzzing for open source software,”
Google Testing Blog, 2016.

[27] K. Serebryany, “Libfuzzer: A library for coverage-guided fuzz testing

(within llvm).”

[28] A. Odena, C. Olsson, D. Andersen, and I. Goodfellow, “Tensorfuzz: De-
bugging neural networks with coverage-guided fuzzing,” in International
Conference on Machine Learning, 2019, pp. 4901–4911.

[29] A. Rebert, S. K. Cha, T. Avgerinos, J. Foote, D. Warren, G. Grieco, and
D. Brumley, “Optimizing seed selection for fuzzing,” in 23rd {USENIX}
Security Symposium ({USENIX} Security 14), 2014, pp. 861–875.
[30] S. Eder, M. Junker, E. J¨urgens, B. Hauptmann, R. Vaas, and K.-H.
Prommer, “How much does unused code matter for maintenance?” in
2012 34th International Conference on Software Engineering (ICSE).
IEEE, 2012, pp. 1102–1111.

[31] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, “Bleu: a method for
automatic evaluation of machine translation,” in Proceedings of the 40th
annual meeting of the Association for Computational Linguistics, 2002,
pp. 311–318.

[32] K. Cho, B. Van Merri¨enboer, C. Gulcehre, D. Bahdanau, F. Bougares,
H. Schwenk, and Y. Bengio, “Learning phrase representations using
rnn encoder-decoder for statistical machine translation,” arXiv preprint
arXiv:1406.1078, 2014.

[33] J. Guo, Y. Jiang, Y. Zhao, Q. Chen, and J. Sun, “Dlfuzz: Differential
fuzzing testing of deep learning systems,” in Proceedings of the 2018
26th ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering, 2018, pp.
739–743.

[34] J. Wang, G. Dong, J. Sun, X. Wang, and P. Zhang, “Adversarial sample
detection for deep neural network through model mutation testing,” in
2019 IEEE/ACM 41st International Conference on Software Engineering
(ICSE).

IEEE, 2019, pp. 1245–1256.

[35] M. Nejadgholi and J. Yang, “A study of oracle approximations in
testing deep learning libraries,” in 2019 34th IEEE/ACM International
Conference on Automated Software Engineering (ASE).
IEEE, 2019,
pp. 785–796.

[36] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and
A. Swami, “The limitations of deep learning in adversarial settings,” in
2016 IEEE European symposium on security and privacy (EuroS&P).
IEEE, 2016, pp. 372–387.

[37] M. Cisse, Y. Adi, N. Neverova, and J. Keshet, “Houdini: Fooling deep
structured prediction models,” arXiv preprint arXiv:1707.05373, 2017.

[38] D. Gopinath, C. S. Pasareanu, K. Wang, M. Zhang, and S. Khurshid,
“Symbolic execution for attribution and attack synthesis in neural net-
works,” in 2019 IEEE/ACM 41st International Conference on Software
Engineering: Companion Proceedings (ICSE-Companion). IEEE, 2019,
pp. 282–283.

[39] C. E. Tuncali, G. Fainekos, H. Ito, and J. Kapinski, “Simulation-
based adversarial test generation for autonomous vehicles with machine
learning components,” in 2018 IEEE Intelligent Vehicles Symposium
(IV).

IEEE, 2018, pp. 1555–1562.

[40] M. A. Alcorn, Q. Li, Z. Gong, C. Wang, L. Mai, W.-S. Ku, and
A. Nguyen, “Strike (with) a pose: Neural networks are easily fooled
by strange poses of familiar objects,” in Proceedings of
the IEEE
Conference on Computer Vision and Pattern Recognition, 2019, pp.
4845–4854.

[41] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing

adversarial examples,” arXiv preprint arXiv:1412.6572, 2014.

[42] A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial examples in the

physical world,” arXiv preprint arXiv:1607.02533, 2016.

[43] M. Vahdat Pour, Z. Li, L. Ma, and H. Hemmati, “A search-based testing
framework for deep neural networks of source code embedding,” arXiv
e-prints, pp. arXiv–2101, 2021.

[44] Q. Hu, L. Ma, X. Xie, B. Yu, Y. Liu, and J. Zhao, “Deepmutation++:
A mutation testing framework for deep learning systems,” in 2019 34th
IEEE/ACM International Conference on Automated Software Engineer-
ing (ASE).

IEEE, 2019, pp. 1158–1161.

