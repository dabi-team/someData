A Solver + Gradient Descent Training Algorithm for Deep Neural Networks

Dhananjay Ashok1, Vineel Nagisetty3, Christopher Srinivasa3, and Vijay Ganesh2
1University of Toronto, Canada
2University of Waterloo, Canada
3Borealis AI, Canada
dhananjay.ashok@mail.utoronto.ca,vijay.ganesh@uwaterloo.ca, {vineel.nagisetty, christopher.srinivasa}@borealis.ai

2
2
0
2

l
u
J

5
2

]

G
L
.
s
c
[

2
v
4
6
2
3
0
.
7
0
2
2
:
v
i
X
r
a

Abstract

We present a novel hybrid algorithm for training Deep Neu-
ral Networks that combines the state-of-the-art Gradient De-
scent (GD) method with a Mixed Integer Linear Program-
ming (MILP) solver, outperforming GD and variants in terms
of accuracy, as well as resource and data efﬁciency for both
regression and classiﬁcation tasks. Our GD+Solver hybrid al-
gorithm, called GDSolver , works as follows: given a DNN
D as input, GDSolver invokes GD to partially train D until
it gets stuck in a local minima, at which point GDSolver in-
vokes an MILP solver to exhaustively search a region of the
loss landscape around the weight assignments of D’s ﬁnal
layer parameters with the goal of tunnelling through and es-
caping the local minima. The process is repeated until desired
accuracy is achieved. In our experiments, we ﬁnd that GD-
Solver not only scales well to additional data and very large
model sizes, but also outperforms all other competing meth-
ods in terms of rates of convergence and data efﬁciency. For
regression tasks, GDSolver produced models that, on aver-
age, had 31.5% lower MSE in 48% less time, and for classiﬁ-
cation tasks on MNIST and CIFAR10, GDSolver was able to
achieve the highest accuracy over all competing methods, us-
ing only 50% of the training data that GD baselines required.

Introduction
Over the last few years, considerable amount of research
has gone into algorithms for training Deep Neural Networks
(DNNs), and yet, Gradient Descent (GD) and its variants
remain the dominant approach for DNN training (Ruder
2016). The primary reason for this state of affairs is that
GD-based training methods can easily handle a large vari-
ety of DNN architectures and are highly scalable in training
very large DNN, achieving high accuracy with relatively lit-
tle computational effort.

Having said that, despite their incredible success, GD-
based methods 1 do suffer from a few signiﬁcant weak-
nesses. First, GD and variants fundamentally lack the ability
to distinguish between local and global minima, and hence
may get stuck in local minima resulting in sub-optimal per-
formance, generalization. Second, there are scenarios where

Copyright © 2022, In the proceedings of the International Joint
Conference on Artiﬁcial Intelligence 2022

1While a variety of GD methods are available today, we focus
on methods that offer the best accuracy, are most scalable, and the
most widely used as of this writing.

GD and variants suffer from poor data efﬁciency, i.e., the
amount of data needed to get reasonable accuracy can be
very high. Finally, in recent years researchers have been
able to show that DNNs suffer security, trust and robust-
ness issues, e.g., adversarial attacks (Papernot et al. 2016),
and that training DNNs to be adherent to certain constraints
is highly desirable (Verma et al. 2019). Unfortunately, GD
and its variants can neither provide any guarantees, nor can
they straightforwardly handle highly non-differentiable con-
straints that typically arise in the context of security and re-
liability speciﬁcations.

All these weaknesses suggest that there is considerable
room for improvement, and there is an urgent need for re-
searching new classes of DNN training algorithms. Recog-
nizing the above-mentioned issues with GD and its variants,
researchers have proposed Mixed Integer Linear Program-
ming (MILP) solver-based training methods (Icarte et al.
2019), among others. Such methods have the advantage
that they can guarantee optimality, can alert users to infea-
sible problems, and handle highly non-differentiable con-
straints such as the ones that arise in security speciﬁca-
tions that can potentially be added to the set of optimization
constraints (Gupte et al. 2013). Unfortunately, solver-based
methods suffer from signiﬁcant problems of over-ﬁtting to
training data and very poor scalability vis-a-vis the size of
the network being trained.

While there have been attempts to augment GD-based
methods with optimizers (e.g., Adam) and learning rate
scheduling techniques to overcome the oft-repeated prob-
lem of getting stuck in local minima, they do suffer from
being heuristic in nature, i.e., they do not provide any guran-
tees that they have reached a global minima. Perhaps more
importantly from a practical point of view, such additional
optimizers also suffer from relatively poorer data efﬁciency.
To address these issues, we provide a new hybrid training
algorithm for DNNs, called GDSolver , based on a combi-
nation of GD and an MILP solver (speciﬁcally we use the
state-of-the-art Gurobi MILP solver (Pedroso 2011)). Given
a DNN D and a training data set S as input, GDSolver ini-
tially invokes GD to train D using S until it gets stuck in a
local minima (this can be detected using a variety of meth-
ods), at which point GDSolver then invokes an MILP opti-
mization solver to exhaustively search a region of the loss
landscape around the current weight assignments to tunnel

 
 
 
 
 
 
Algorithm 1 The GDSolver Algorithm
Input: Untrained DNN, Training Data, Validation Data
Parameter: Desired Loss, MaxIter
Output: Trained DNN
1: i := 0
2: while Validation Loss is Decreasing do
3:
4: Measure Validation Loss
5: end while
6: Convert ﬁnal layer to an MILP Instance
7: Solve MILP Instance
8: Map Solution of MILP Instance back to NN parameters

Train DNN using Gradient Descent

Go to Line 2

9: i++
10: if Validation Loss > Desired Loss and i < MaxIter then
11:
12: else
13:
14: end if

return trained DNN

GDSolver : The Architecture of Gradient
Descent + Solver DNN Training Method

In this section, we detail the steps outlined in the architecture
diagram in Figure 1 and Algorithm 1 detailed above. The
ﬁrst step of GDSolver is to train the network with GD alone,
as one would for any DNN [lines 1-3], until the plateauing of
validation loss, indicative of a local minimum, is observed
[line 1]. At which point, GDSolver halts the GD training
and proceeds to the second step, namely, solver-based train-
ing. The value of using GD to train networks is well known,
namely, scalability to very large networks and the ability of
GD-based methods in obtaining low loss in many settings.

In the solver phase [lines 5-7], the GDSolver algorithm
takes the partially trained network and focuses on ”Fine Tun-
ing” the ﬁnal layer using an MILP solver. In this step, GD-
Solver ﬁrst converts the problem of training the ﬁnal layer of
the neural network to an MILP instance using a specialized
formulation [line 5] (discussed in greater detail in Subsec-
tion below). The idea here is to search in a region around the
values assigned by GD to the network’s ﬁnal layer weights
and biases, such that the resultant assignment found by the
solver has even lower loss than the one found by GD alone in
step 2 (assuming such a lower loss point exists). If no lower
loss point is found, GDSolver stops training and returns the
trained DNN [line 11].

The MILP instance thus formulated is solved by an MILP
solver [line 6] (speciﬁcally, the Gurobi solver), and the so-
lution is then mapped back to the network weights and bi-
ases [line 7]. We refer to this process as ﬁnal layer ﬁne-
tuning. The termination condition for the training loop is a
check that ascertains whether the desired accuracy has been
achieved or further improvements to the weights and biases
are possible. If yes, then the loop continues, else it termi-
nates [lines 8-12].

Figure 1: Hybrid GDSolver Architecture

through and escape the local minima. The GD and solver
methods are invoked alternatively until an appropriate level
of accuracy is achieved. When comparing GDSolver against
multiple GD baselines on a suite of regression and classi-
ﬁcation tasks, we ﬁnd that GDSolver not only scales well
to additional data and model sizes, but also outperforms all
other competing methods in terms of rates of convergence
and data efﬁciency.

Key Contributions.

1. The GDSolver Algorithm - a novel hybrid training al-
gorithm that iteratively calls GD and MILP solver in a
way that it is able to escape local minima by ”tunnel-
ing” through them. In order to accomplish this, we had
to come up with a novel formulation of DNN Training as
an MILP instance that solves the severe overﬁtting prob-
lem of previous MILP formulations and enables its us-
age with real-valued DNNs. The GDSolver algorithm is
highly scalable in terms of being able to train very large
DNN models, very general in terms of the DNN architec-
tures it can handle, and data/resource efﬁcient relative to
competing methods 2.

2. Extensive Experimental Evaluations: We perform an
comprehensive experimental evaluation of our algorithm
against four state-of-the-art baselines, namely, Stochas-
tic Gradient Descent (SGD), SGD with Learning Rate
Scheduling (LRS), Adam Optimzation, and Adam Opti-
mization with LRS, on a set of regression and classiﬁca-
tion tasks.

• On a suite of regression equations, we show that GD-
Solver can produce models with, on average, 31.5%
lower MSE in 48% less time compared to state-of-the-
art competing methods.

• On a set of standard classiﬁcation datasets - MNIST
and CIFAR10, we show that GDSolver is able to
achieve the highest accuracy against all competing
methods, using only 50% the training data than com-
peting GD baselines required for the same.

2Code available at: https://dhananjayashok.github.io/Hybrid-

Solver-NN-Training/

GradientDescentSolverBasedTrainingUntrainedModelHybridTrainedModelFigure 2: Regression Formulation

Motivation and Advantages of a Hybrid
Solver+GD Training
Since the MILP solver is only involved in ﬁne tuning, and
does not train the entire network end-to-end, it is completely
invariant to the architecture and size of the Neural Network
until the ﬁnal layer. This hybrid approach makes GDSolver
much more scalable than prior methods for training neural
networks using solvers alone (Icarte et al. 2019). Further, the
speciﬁc design choices we have made enables our method
GDSolver to be very general, i.e., handle a variety of ar-
chitectures, since a large variety of DNN architectures can
be symbolically modelled as MILP problems. At the same
time, our method GDSolver retains the ability to be highly
inﬂuential on the ﬁnal prediction strength of the DNN, as
shown in our experiments.

The idea of ﬁne tuning the ﬁnal layer(s) alone is not
new, and other methods have been proposed with dra-
matic and highly consequential impact on network perfor-
mance (Howard and Ruder 2018; Pan and Yang 2009). To
the extent we know, our work is unique in that we use a
MILP solver for ﬁnal layer ﬁne tuning.

Escaping Local Minima via GDSolver vs.
Competing Methods
Escaping Local Minima via Solvers: As has been noted,
GD performs well until it gets stuck in a local minima, and
limited options exist to escape local minima. By contrast, the
solver performs exhaustive search in a large space around
the weights and biases assigned by GD in the previous it-
eration, and thus may discover a new point with lower loss.
By assigning this new point (i.e., new weights and biases) to
the DNN, it may be able to escape the local minima by tun-
nelling through it and with the help of an additional iteration
of GD more effectively than only using GD.
Adam Optimizer and LRS: Current alternatives for han-
dling local minima include using momentum based op-
timization methods (Adam (Kingma and Ba 2014), RM-
SProp (Kurbiel and Khaleghian 2017) etc.) and LRS (Li and
Arora 2019). Momentum based optimization methods strug-
gle in several instances due to the fact that they too use gra-
dient information to decide the size of steps taken in train-
ing. While they are very good at ﬁnding the right step size to
take, they are not so useful if the direction towards the bet-
ter solution is currently unknown or not discoverable given

Figure 3: Classiﬁcation Formulation

local gradient information. Learning Rate Scheduling meth-
ods, while simple and efﬁcient , are often highly dependent
on hyper-parameter tuning and thus can be unreliable.

The strength of the GDSolver Algorithm is that it can be
used alongside all of these above methods, and offers an-
other route to escaping local minima if they perform poorly
in particular settings. In the rest of this work, we focus on
showing that our hybrid method is uniquely useful in ef-
ﬁcient training on widely useful metrics of efﬁciency and
generalization.

The MILP Formulation
Key to the success of our GDSolver method is a symbolic
formulation of the ﬁnal layer of a Neural Network as an in-
stance of the MILP problem, and then mapping the solution
obtained by invoking an MILP solver back to the parameters
of the ﬁnal layer. Put differently, we convert the ﬁnal layer
of the DNN into a mathematical formula as described be-
low. For our base formulation we use a variation of that used
in (Icarte et al. 2019), with signiﬁcant improvements as dis-
cussed here. The full formulation is presented in Figures [2]
and [3].

Similar to previous work in symbolic formulations of
DNNs (Bunel et al. 2017; Cheng, N¨uhrenberg, and Ruess
2017), we restrict our system to using only linear piece-wise
or the soft-max activation functions for the ﬁnal layer. In the
formulation shown in the Figures [2] and [3], we restrict our-
selves to the constraint for the ReLU activation function as
this is most commonly used one. Having said that, our for-
mulation can easily handle any linear piece-wise activation.

Setup and Deﬁnitions
Let f denote a partially trained Neural Network and L its
ﬁnal layer, and {X, Y } denote a dataset with T datapoints.
Let N denote the input dimension of the ﬁnal layer L and M
be the dimension of the output. Then, L : RN ×1 → RM ×1 :
is a map that can be written out using a weight matrix w ∈

Equation ID:
Equation
Identity
Afﬁne
Polynomial
Formula

GD(10)

GD(20)

GDSolver

MSE
0.579
16.467
93.86
10.44

Time
0.0353
0.0278
0.0324
0.0361

MSE
0.2412
8.075
20.805
4.208

Time
0.084
0.071
0.076
0.0864

MSE
0.109
7.2095
12.07024
3.32117

Time
0.043
0.0321
0.0387
0.0452

Table 1: Regression Experiment Results: Values for best GD baseline (SGD with LRS) GD benchmarked at halfway point
(10) and ﬁnal epoch (20). Results show GDSolver after 10 epochs of GD outperforms 20 epochs of GD for both MSE and Time

RM ×N , a bias vector b ∈ RM ×1, input h ∈ RN ×1 and
activation function σ as follows: L(h) = σ(wh + b). We
can express f as: f = L ◦ f (cid:48) where f (cid:48) is all the previous
layers of the DNN other than the ﬁnal layer L. Then, the
goal of DNN training is to learn the mapping L ◦ f (cid:48)(X) =
y ⇔ σ(wh + b) = y, where h = f (cid:48)(X).

Base Formulation for Regression and Classiﬁcation
When converting this ﬁnal layer L to an MILP instance, all
the weights and biases of the ﬁnal layer are represented as
variables wi,j and bj. Constraints (1,2) in Figure 2 (respec-
tively, constraints (8,9) in Figure 3) are box constraints that
bound the region around the value assigned to the variables
wi,j and bj that the solver is required to search.

Constraints (3, 4, 5, 12, 13, 14) as given in Figures[ 2,
3], essentially encode the architecture of the neural network.
More precisely, for every data point (xt, yt) we compute
ht = f (cid:48)(xt), where ht ∈ H is the input to the ﬁnal layer.
Then, constraint (3) (respectively, constraint (12)) encodes
the input to the activation function as a linear combination of
ht and the parameters of the ﬁnal layer, while the constraints
(4, 5, 13, 14) encode the activation with ReLU. Finally, each
training data point also has constraints to relate the output of
the neural network to the intended target label/ value yt. The
encoding of the target label depends on whether the problem
is one of regression or classiﬁcation.

Formulation of DNN Output
Regression Output: In the regression formulation, con-
straint (6) bounds the L1 distance of the output and tar-
get by a constant value max losst,j. In practice we set
max losst,j = L1(o, y)t,j, i.e., the L1 loss of that data point
using the current weight assignment of the network. This
ensures that if a solution is found by the solver, then it has
a better L1 loss on the training dataset than the current as-
signment given by the previous GD step of the GDSolver
algorithm.
Classiﬁcation Output: The output dimension of classiﬁca-
tion models is typically equal to the number of classes that
could be predicted, and the prediction of the neural network
is the class which corresponds to the highest output neuron
value in the ﬁnal layer for a given data point. With this in
mind, constraints (15, 16) encode whether a given data point
is correctly classiﬁed by the DNN, i.e., the variable ct is 1 iff
datapoint t is correctly classiﬁed, (cid:80)
t ct is hence a measure
of the total accuracy of the network. We set this accuracy as
the maximization objective of the solver constraint (7), set-
ting a lower bound on the accuracy as the current accuracy

of the model given by the prior GD step of GDSolver tool
ensures that any solution found will have a better accuracy
on the training set than the current assignment.

Mapping Solutions to the DNN
Given this formulation, it is fairly straightforward to convert
the ﬁnal layer of the given network to a valid MILP problem
and query a solver for satisfying assignments for the weights
and biases. If a feasible solution is found we simply assign
W [i, j] = wi,j∀i, j and b[j] = bj∀j.

Discussion on Formulation
There are several key differences between our formulation
and the original used in (Icarte et al. 2019), that enable us to
train networks faster and with less over-ﬁtting.

Local Neighbourhood Restrictions: The ﬁrst is in how
we deﬁne the weight and bias variables in constraints (1, 2,
8, 9) - we ensure that these variables can only be set to an in-
terval around the current weight and bias assignments given
by the prior GD step of the GDSolver algorithm. This re-
stricts the space of assignments that the solver has to search
over, vastly improving its scalability. It has the additional ad-
vantage to preventing over-ﬁtting, as as new solutions cannot
be too ”different” from the current assignment. Finally, in
practice, this restriction does not seem to impede the solver
from tunnelling through the local minima.

Regression Flexibility: Instead of regression constraint
(6) and classiﬁcation (7, 15, 16), previous formulations re-
late the output of the neural network to the intended target
label with the constraint oj,t = yj,t∀j, ∀t (Icarte et al. 2019;
Thorbjarnarson and Yorke-Smith 2020). While this is more
straightforward, it has signiﬁcant ﬂaws. This forces the net-
work to search for assignments that perfectly regress every
single training point which is highly likely to cause over-
ﬁtting. Our alternative of constraint (6) acknowledges that
perfect accuracy on the training set is undesirable, striking a
better balance by simply requiring a lower loss than the cur-
rent assignment. This observation was absolutely key to the
success of our formulation and DNN training tool.

Classiﬁcation Flexibility: The problem with previous
formulations of the constraints that relate the network out-
put to labels is even more pronounced in the classiﬁcation
domain, where the constraint not only requires the solver to
achieve perfect accuracy on the training set, but also requires
the output vectors to match (Icarte et al. 2019; Thorbjarnar-
son and Yorke-Smith 2020). The output vector for classi-
ﬁcation problems are often vectors of binary indicators of
class membership for each class. For example, given a 3

class classiﬁcation problem target vector y3 class∈RT ×3 where
yi,3 class = [1, 0, 0] would mean that the ith data point is of
the ﬁrst class. In the vast majority of cases Neural Networks
output vectors do not attempt to predict the exact 0-1 value,
but rather predict un-normalized probabilities, such that the
ﬁnal prediction is the class with the highest output value
in the predicted vector. Thus if predi = [0.75, 0.2, 0.05] or
predi = [5, 1, 3] the DNN has correctly predicted the output
label, but the previous MILP formulations would consider
all of these to be incorrect as they do not match the exact
vector [1, 0, 0]. Our formulation has constraints (7, 15, 16)
which allow the model to fall short of perfect training accu-
racy and permits the DNN to predict un-normalized proba-
bilities in its ﬁnal layer.

Generalization of previous formulations: The strength
of our novel formulation is that it is a generalization of the
ones that came before, i.e., the previous formulations are a
special case of ours that is obtained by setting the max loss
and minimum accuracy parameters to 0 and 1 respectively.

Experimental Evaluation
Experimental Setup: For all our experiments, we com-
pare our hybrid method against the four GD baselines of
SGD, SGD with LRS, Adam Optimization and Adam with
LRS. The experiments were run on a system with the fol-
lowing specs: 18.04.2-Ubuntu with Intel(R) Core(TM) i7-
10750H CPU @ 2.60GHz. Models were created and trained
with standard PyTorch implementations of GD baselines,
the datasets for MNIST and CIFAR10 were the standard
datasets provided by PyTorch (Paszke et al. 2019). The
MILP solver used was the python interface of the Gurobi
solver - Gurobipy (Pedroso 2011).

Experiment 1: Regression
In this experiment, our goal was to ascertain whether the
GDSolver algorithm and tool achieves faster convergence
with greater data and resource efﬁciency than GD baselines.
In order to make the comparison as fair as possible, we use
regression datasets (namely, identity, afﬁne, polynomial of
degree 4, and trignometric and exponential formula. See Ap-
pendix for more details) that we know the baseline models
can accurately predict with a low loss.

The experiments were performed as follows: we vary the
number of epochs e (from 1 to 20) and for each GD baseline
note the testing loss and time taken after e epochs. We then
compare this to the testing loss and time taken to complete e
epochs of SGD and a single solver sweep of the ﬁnal layer.
We expect to see a strict increase in time taken, as the hy-
brid method does all the iterations that the baselines do and
an additional step, however if the improvement in loss is suf-
ﬁciently large, then it would justify the additional time cost.
This also allows us to quantify how many additional epochs
of GD would have been required to achieve equivalent loss.
Analysis of Results: The results for the ﬁrst experiment can
be seen in Table 1. For brevity the results shown are for
the best GD baseline (SGD with LR Scheduling) at the me-
dian epoch and maximum epochs used - 10 and 20. (Figures
showing complete results for all epochs can be found in the

Appendix). The table compares the GD baseline after 10 and
20 epochs to GDSolver after 10 epochs. The results suggest
that the hybrid solver method is very useful in quickening
the rate of convergence of loss - For each of these datasets,
after 10 epochs, the hybrid method outperforms the other
baselines with respect to generalization, and in most cases
only after more than 20 epochs would the baselines catch
up to the hybrid solvers generalization loss. The time taken
by GDSolver is greater than the baselines at 10 epochs, but
signiﬁcantly less than the time taken for 20 iterations, which
is how long the baselines take to achieve a comparable loss -
GDSolver produced models with, on average, 31.5% lower
MSE in 48% less time. These two observations put together
motivated the conclusion that the hybrid solver method is an
efﬁcient and valuable method to quicken the rate of conver-
gence, outperforming classic GD approaches.

Experiment 2: Classiﬁcation

In this experiment we ascertain whether our Solver+GD hy-
brid approach consistently performs better than GD base-
lines in terms of generalization to a test set as the amount of
training data is varied.

We perform the experiment by varying the number of
training datapoints n and epochs e. For each pair of these
variables (n, e) we train the baseline GD methods with n
points for e epochs. For comparison, using the GDSolver
algorithm we train for a maximum of e
2 epochs of SGD (n
datapoints), stopping early and calling the solver if we detect
a loss plateau - we do this process 2 times. This 2 Loop GD-
Solver method uses a maximum of e epochs in its GD steps,
hence making sure that any improved performance is not a
consequence of simply more computation. When calling the
solver, we do not give it the entire training dataset, but rather
a single batch (32 datapoints) of datapoints which are incor-
rectly classiﬁed by the current assignment given by GD. We
compare the GD baselines with the 2 Loop GDSolver on
test accuracy that measures generalization. We perform the
above experiment on two well-known datasets - MNIST, CI-
FAR10.

Analysis of Results: The results for the second experiment
are shown in Figures [4] and [5]. Results show that on aver-
age the hybrid method outperforms all GD baselines in terms
of testing accuracy. The trend lines give deeper insight into
the advantage that the hybrid method provides. It shows that
consistently and signiﬁcantly the hybrid method performs
much better when fewer data points are used, i.e., the hybrid
method is more data efﬁcient. For both the datasets we can
observe a trend where as training data increases the base-
line methods eventually achieve similar performance to our
method - GDSolver on MNIST and CIFAR10 achieves bet-
ter accuracy than GD baselines with only 50% of the train-
ing data. This phenomenon of solver-based training meth-
ods performing better when data is scarce has been noted
before. For example, in (Icarte et al. 2019) they showed that
for binary neural networks, models trained by solvers with
limited data were vastly superior to GD methods. The results
are also consistent with the idea that the solver sweep in GD-
Solver tool helps with tunnelling through the local minimum

that the GD baselines struggle with, and thus reaching higher
accuracy with fewer data points than the GD baselines.

Figure 4: GDSolver (green, hybrid last gd) achieves 96%
accuracy with half the datapoints that it takes the best GD
baseline to

Figure 5: GDSolver (green, hybrid last gd) is consistently
better than both baselines, especially with less data

Limitations: The GDSolver makes a fundamental tradeoff,
namely, in order to work with real valued DNNs it can only
perform solver sweeps on the ﬁnal layer of the network, for
otherwise the resultant optimization would be a non-linear
optimization problem and hence outside the scope of MILP
solvers. GDSolver also currently assumes that the DNNs it
takes as input use a feed-forward densely connected ﬁnal
layer. This assumption is mostly true for regression and clas-
siﬁcation problems, however does not hold for most special-
ized networks like Image generating GANs etc.

as MILP, SAT, or SMT problems (Tjeng, Xiao, and Tedrake
2017; Zhang et al. 2018; Bunel et al. 2017). Almost all of
this work is aimed towards veriﬁcation of pretrained neural
networks via DNN veriﬁcation solvers (see VNN-LIB Ini-
tiative for more details). This has important implications as
it is a fundamentally different formulation to the one we use
in our tool, wherein the variables in the symbolic formula-
tion for veriﬁcation are input data points, while the variables
in the context of training are network parameters.
DNN Training via Solvers: Training neural networks using
solvers has mainly been studied in the binary and integer set-
tings. Narodytska et al. (Narodytska et al. 2019) studies con-
verting Binary Neural Networks to SAT problems and stud-
ied which architectures were more ”SAT” friendly so they
may be solved efﬁciently. Icarte et al. (Icarte et al. 2019)
established the ﬁrst MILP formulation for Binary Neural
Networks for training purposes. They attempt to deal with
problems of over-ﬁtting using regularizing objective func-
tions and show that MILP solvers outperform GD as the
training algorithm of choice when there is a sparsity of data
points. Thorbjarnarson et al. (Thorbjarnarson and Yorke-
Smith 2020) uses this same formulation and attempts to ex-
tend the analysis to integer valued neural networks. However
both these methods suffer from scalability, over-ﬁtting and
cannot be used on real-valued networks (Icarte et al. 2019).

Conclusions and Future Work
We present GDSolver , a hybrid solver and GD training al-
gorithm for DNNs, that consistently outperforms 4 state-of-
the-art GD methods on several regression and classiﬁcation
tasks in terms of higher accuracy with greater data and re-
source efﬁciency. Further, to the best of our knowledge, ours
is the ﬁrst solver-based method that can scale to real-world
sized DNNs. MILP Solvers and GD excel in different set-
tings and ways. Our method GDSolver leverages the advan-
tages of each method, giving rise to an algorithm that com-
bines the best of both worlds and is better than its individual
parts on measures such as accuracy and data efﬁciency. By
using solvers to tunnel through and escape the local minima,
we tackle one of the most important and difﬁcult problems
that GD methods often encounter. This gives GDSolver the
ability to scale well to additional data and model sizes, but
also outperforms pure GD methods in terms of rates of con-
vergence and data efﬁciency. In the future, we plan to extend
our work to handling highly non-linear constraints, since
other classes of solvers, such as SMT solvers, are capable of
handling such non-linearity. Further, one of our goals is to
train DNNs in a manner that ensures (probabilistic) adher-
ence to security or reliability constraints. It is unclear how
a purely GD-based method can be used to provide guaran-
teed adherence to such speciﬁcations. By contrast, we be-
lieve that solver-based hybrid training methods could enable
us to train DNNs in a manner that ensures (probabilistic)
adherence to logical speciﬁcations.

Related Work
Symbolic Formulation of DNNs: There is growing litera-
ture in the interpretation of Neural networks symbolically

References
Bunel, R.; Turkaslan, I.; Torr, P. H.; Kohli, P.; and Kumar,
M. P. 2017. A uniﬁed view of piecewise linear neural net-

gence {IJCAI-19}. International Joint Conferences on Arti-
ﬁcial Intelligence Organization.

Zhang, H.; Weng, T.-W.; Chen, P.-Y.; Hsieh, C.-J.; and
Daniel, L. 2018. Efﬁcient neural network robustness cer-
tiﬁcation with general activation functions. arXiv preprint
arXiv:1811.00866 .

work veriﬁcation. arXiv preprint arXiv:1711.00455 .

Cheng, C.-H.; N¨uhrenberg, G.; and Ruess, H. 2017. Max-
In Interna-
imum resilience of artiﬁcial neural networks.
tional Symposium on Automated Technology for Veriﬁcation
and Analysis, 251–268. Springer.

Gupte, A.; Ahmed, S.; Cheon, M. S.; and Dey, S. 2013. Solv-
ing mixed integer bilinear problems using MILP formula-
tions. SIAM Journal on Optimization 23(2): 721–744.

Howard, J.; and Ruder, S. 2018. Universal
model ﬁne-tuning for text classiﬁcation.
arXiv:1801.06146 .

language
arXiv preprint

Icarte, R. T.; Illanes, L.; Castro, M. P.; Cire, A. A.; McIl-
raith, S. A.; and Beck, J. C. 2019. Training binarized neural
networks using MIP and CP. In International Conference on
Principles and Practice of Constraint Programming, 401–
417. Springer.

Kingma, D. P.; and Ba, J. 2014. Adam: A method for
stochastic optimization. arXiv preprint arXiv:1412.6980 .

Kurbiel, T.; and Khaleghian, S. 2017. Training of deep neu-
ral networks based on distance measures using RMSProp.
arXiv preprint arXiv:1708.01911 .

Li, Z.; and Arora, S. 2019.
ing rate schedule for deep learning.
arXiv:1910.07454 .

An exponential

learn-
arXiv preprint

Narodytska, N.; Zhang, H.; Gupta, A.; and Walsh, T. 2019.
In search for a SAT-friendly binarized neural network archi-
tecture. In International Conference on Learning Represen-
tations.

Pan, S. J.; and Yang, Q. 2009. A survey on transfer learn-
ing. IEEE Transactions on knowledge and data engineering
22(10): 1345–1359.

Papernot, N.; McDaniel, P.; Jha, S.; Fredrikson, M.; Celik,
Z. B.; and Swami, A. 2016. The limitations of deep learning
in adversarial settings. In 2016 IEEE European symposium
on security and privacy (EuroS&P), 372–387. IEEE.

Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.;
Chanan, G.; Killeen, T.; Lin, Z.; Gimelshein, N.; Antiga, L.;
et al. 2019. Pytorch: An imperative style, high-performance
deep learning library. Advances in neural information pro-
cessing systems 32: 8026–8037.

Pedroso, J. P. 2011. Optimization with Gurobi and Python.
INESC Porto and Universidade do Porto,, Porto, Portugal 1.

Ruder, S. 2016. An overview of gradient descent optimiza-
tion algorithms. arXiv preprint arXiv:1609.04747 .

Thorbjarnarson, T.; and Yorke-Smith, N. 2020. On Training
Neural Networks with Mixed Integer Programming. arXiv
preprint arXiv:2009.03825 .

Tjeng, V.; Xiao, K.; and Tedrake, R. 2017. Evaluating Ro-
bustness of Neural Networks with Mixed Integer Program-
ming. arXiv preprint arXiv:1711.07356 .

Verma, S.; Wang, C.; Zhu, L.; and Liu, W. 2019. A Com-
pliance Checking Framework for DNN Models. In Twenty-
Eighth International Joint Conference on Artiﬁcial Intelli-

