AutoCAT: Reinforcement Learning for Automated
Exploration of Cache-Timing Attacks

Mulong Luo∗¶, Wenjie Xiong†‡¶, Geunbae Lee†, Yueying Li∗, Xiaomeng Yang‡,
Amy Zhang‡§, Yuandong Tian‡, Hsien-Hsin S. Lee‡, and G. Edward Suh∗‡

∗Cornell University †Virginia Tech

§UC Berkeley

‡Meta AI

{ml2558,yl3469}@cornell.edu, {wenjiex,geunbae}@vt.edu, {yangxm,amyzhang,yuandong,leehs,edsuh}@fb.com
¶Equal contributions.

2
2
0
2

g
u
A
7
1

]

R
C
.
s
c
[

1
v
5
2
0
8
0
.
8
0
2
2
:
v
i
X
r
a

Abstract—The aggressive performance optimizations in mod-
ern microprocessors can result in security vulnerabilities. For
example, the timing-based attacks in processor caches are shown
to be successful
in stealing secret keys or causing privilege
escalation. So far, ﬁnding cache-timing vulnerabilities is mostly
performed by human experts, which is inefﬁcient and laborious.
There is a need for automatic tools that can explore vulnerabilities
because unreported vulnerabilities leave the systems at risk.

In this paper, we propose AutoCAT, an automated exploration
framework that ﬁnds cache timing-channel attack sequences
using reinforcement learning (RL). Speciﬁcally, AutoCAT for-
mulates the cache timing-channel attack as a guessing game
between the attacker program and the victim program holding a
secret, which can thus be solved via modern deep RL techniques.
AutoCAT can explore attacks in various cache conﬁgurations
without knowing design details and under different attacker and
victim conﬁgurations, and can also ﬁnd attacks to bypass certain
detection and defense mechanisms. In particular, AutoCAT dis-
covered StealthyStreamline, a new attack that is able to bypass
detection based on performance counters and has up to a 71%
higher information leakage rate than the state-of-the-art LRU-
based attacks on real processors. AutoCAT is the ﬁrst of its kind
using RL for crafting microarchitectural timing-channel attack
sequences and can accelerate cache timing-channel exploration
for secure microprocessor designs.

I. INTRODUCTION

As we use computers to handle increasingly sensitive data
and tasks, security has become one of the major design
considerations for modern computer systems. For example,
from the hardware perspective, microarchitecture-level timing
channels have emerged as a major security concern as they
allow leaking of information covertly with a high bit-rate and
bypassing the traditional software isolation mechanisms. The
timing-channel attacks are also shown to be an even more
serious problem when combined with speculative execution
capabilities [35], [42].

Unfortunately, developing a system that

is sufﬁciently
secure and efﬁcient (high-performance) at the same time
is quite challenging in large part because it is difﬁcult to
evaluate the security of a system design. By deﬁnition, a
security vulnerability comes from an unknown bug or an
unintended use of a system feature, which is difﬁcult to
know or quantify at design time. While formal methods and
cryptography can provide mathematical guarantees, it is difﬁcult
to scale the formal proofs to complex systems and security

properties in practice. As a result, today’s security evaluation
and analyses largely rely on human reviews and empirical
studies based on known attacks or randomized tests. However,
the security evaluation based on known attack sequences
manually discovered by humans makes it difﬁcult to assess
the security of a new microarchitecture design or a defense
mechanism. Vulnerabilities in new microarchitectures are often
left unnoticed for a long time, and defense mechanisms are
often found vulnerable to new attack sequences even when
they are similar to the known ones. For example, while caches
existed in microprocessors for a long time, Bernstein’s cache-
timing attack was reported back in 2005 [6] followed by
multiple variations such as evict+time (2006) [53], ﬂush+reload
(2014) [92], ﬂush+ﬂush (2016) [22], etc. New attacks in
caches are still being reported recently, e.g., attacks in cache
replacement states (2020) [9], [86], streamline (2021) [65], and
attacks using cache dirty states (2022) [16].

This paper proposes to leverage reinforcement learning (RL)
to automatically explore attack sequences for microarchitectural
timing-channel vulnerabilities, and demonstrate the feasibility
of this approach using cache timing channels as a concrete
example. RL has been shown to achieve super-human perfor-
mance in multiple competitive games (e.g., Go and Chess [70],
DoTA 2 [5]) without starting from existing human knowledge.
In this paper, we show that microarchitecture-level timing-
channel attack can also be formulated as a guessing game
for an attacker program, and is a good ﬁt for RL. In this
case, an RL agent can learn by self-playing the game many
times in a well-deﬁned environment, which is provided by
real hardware or efﬁcient simulation infrastructures commonly
used for architecture studies. The experiments show that our
RL framework, named AutoCAT, can automatically adapt to a
variety of cache designs and countermeasures, and ﬁnd cache-
timing attacks, including known attack sequences and ones
that are more efﬁcient than known attack sequences.

While the use of machine learning (ML) for system security
has been explored in the past, the previous work largely focused
on performing or detecting known attack sequences on known
system designs. For example, ML models with supervised
learning are used in side-channel attacks to recover secrets [37],
[44], [45], [83], [89], [93]. Similarly, ML models can be trained
with known attack traces for intrusion detection [38]. This paper

 
 
 
 
 
 
asks a different question: can an RL agent automatically 1) learn
system designs without explicit speciﬁcations and 2) generate
attack sequences that are not speciﬁed by humans? To be
widely applicable, the RL agent should also be able to adapt to
diverse new system designs without substantial changes to the
RL environment. Our experimental results suggest that such
autonomous explorations are indeed possible.

We believe that the RL-based approach has the potential to
enable a more systematic and rigorous evaluation of system
security. We envision the RL framework to be used for both
1) studying potential security vulnerabilities of a system design
and 2) evaluating the robustness of a defense mechanism. For
example, AutoCAT can be used to automatically generate cache-
timing attack sequences for a diverse set of cache conﬁgurations,
replacement policies, or real processors. AutoCAT also tries to
ﬁnd attack sequences with higher success rates and bandwidth,
providing a way to quantitatively compare the effectiveness of
attacks across different cache designs. AutoCAT’s environment
can be augmented with an explicit protection scheme such as
an attack detector, and the RL agent can be asked to ﬁnd an
attack sequence that bypasses the defense. While AutoCAT
cannot prove the security of a defense mechanism, testing a
countermeasure with AutoCAT will provide a better measure
of its robustness compared to only testing its effectiveness
using the known attack sequences that it is designed for.

The following summarizes the main technical contributions

and experimental ﬁndings of this paper:

• We present AutoCAT, the ﬁrst framework to use RL to au-
tomatically explore cache-timing attacks. The framework
can interface with a cache simulator or a real processor.
• We demonstrate that AutoCAT can ﬁnd cache attack
sequences for multiple cache conﬁgurations, replacement
policies, and prefetchers. AutoCAT can also ﬁnd attack
sequences on multiple real processors with unknown
replacement policies quickly, while for a human to adapt
known attacks requires signiﬁcant reverse-engineering.
• We demonstrate that AutoCAT can bypass several cache-
timing defense and detection schemes, such as the
partition-locked (PL) cache [81], detection based on the
victim misses [4], [15], [36], [46], [95], detection based on
autocorrelation [12], [88], and ML-based detectors [24].
• We present a novel cache-timing attack, named Stealth-
Streamline, discovered by AutoCAT, which avoids detec-
tion based on the miss counts and has an up to 71% higher
bit rate than existing LRU-based attacks on real machines.
We plan to make the artifact of AutoCAT publicly available
on https://github.com under an open-source license.

II. BACKGROUND AND MOTIVATION

A. Cache-Timing Attacks

The cache timing channel is a widely-studied vulnerability
in modern microprocessors, given its practicality and high bit
rate. Depending on the threat model, it can be used as a side
channel (where an attacker and a victim are non-cooperative)
or a covert channel (where a sender and a receiver cooperate)

TABLE I: Actions/observations in known cache timing attacks.
Attack Category Attacker’s actions Victim’s actions Observations
prime+probe [43]
ﬂush+reload [92]
evict+reload [53]
evict+time [7]

attacker’s latency
attacker’s latency
attacker’s latency
victim’s latency

access an addr
access an addr
access an addr
access addresses

access addrs
ﬂush addrs
access addrs
access addrs

on a shared cache to steal or send information. Without loss
of generality, we assume a side channel scenario.

The cache-timing channels usually involve two parties, the
attacker and the victim. A victim has a secret, and the memory
operation of the victim depends on the secret. An attacker’s
goal is to guess the secret without directly accessing the secret.
The attacker needs to achieve the goal by making memory
accesses and measuring the timing of the memory accesses
or the victim’s external activities, e.g., using the timing/cycle
measurement facilities such as RDTSCP in x86. The timing of
a memory access indicates whether a cache line is in the cache
or not. For example, in a prime+probe attack, the victim’s
memory access will evict the attacker’s cache line from the
cache, causing latency changes in the attacker’s future memory
accesses. Thus, the attacker can infer the victim’s memory
operation from timing observations.

The recent cache timing-channel models [17], [82] divide the
attacks into three essential components, including the attacker’s
actions, the victim’s actions, and the attacker’s observations.
The attacker’s actions include normal memory accesses, cache
line ﬂushing, etc. The victim’s action is usually a secret-
dependent memory operation such that it changes the state of
the cache, e.g., accessing a secret address (addrsecret ). For the
attacker’s observations, the attacker accesses certain cache lines
and obtains the timing measurement to gain information about
the secret (addrsecret ). With correct combinations, the attacker
can learn the secret, as demonstrated in known attacks such
as prime+probe [43], ﬂush+reload [92], evict+time [53], cache
collision [7] attacks, and other recent cache timing-channel
attacks. Table I summarizes the actions of the common cache
timing-channel attack categories [17], [26]. Other cache timing
attacks also share the same set of actions and observations.

In this paper, we refer to a sequence of actions such as
memory accesses, cache ﬂushing, allowing a victim’s execution,
and others in an attack on a speciﬁc system as an attack
sequence. An attack category or strategy is a broader class
of attack sequences that can be adapted to multiple systems,
similar to the ones in Table I.

B. Challenges of Cache-Timing Attack

For security analysis and testing, given a hardware design,
we need to analyze the vulnerabilities and generate attack se-
quences to exploit these vulnerabilities. Many attack sequences
may belong to a previously known attack category, while there
may also be new attack sequences. Even for known attacks,
there is a need to adapt those to the given design to test the
effectiveness and bit rate of the attack [80]. In general, a cache
timing attack involves (1) reverse-engineering the behavior of
target microarchitecture design, (2) designing attack sequences
to exﬁlate information, and (3) improving the signal quality
in practice.

AutoCAT aims to address the challenges in the ﬁrst two
steps by focusing on reverse-engineering and attack sequence
exploration when new or blackbox hardware is given. For
other practical challenges in developing end-to-end attacks,
such as building an accurate timer, reducing background noise,
synchronizing the victim process, we leverage the existing
techniques in the literature [65], [79], [86], [89]. The following
discusses some of the main challenges in the attack steps.

A cache contains many design options, such as a replacement
policy [57], cache directory [89], cache prefetcher [14], [80], etc.
The microarchitectural implementation details are often kept as
proprietary information by chip designers. Cache operations can
also be pseudo-random such as random replacement policies,
meaning the cache behavior is not entirely predictable. Reverse
engineering effort can be onerous and only reveals limited
information [3], [79]. For example, it could take up to 100
hours to reverse-engineer a replacement policy [79].

Some of the microarchitecture states are not directly mea-
surable by timing. The attacker has to encode and decode
the secret in such states, potentially resulting in complex and
long attack sequences. For example, known attacks that make
use of the cache replacement states and cache coherent states
all require complex sequences of actions [9], [16], [86], [91],
making it challenging to manually reason about an exploitable
vulnerability and design an attack sequence.

To explore attacks in a given design, the above process
needs to be repeated, which is laborious, and thus, tools
helping attack explorations has been proposed. One method
is to manually model the existing attacks in the cache [17],
and then automatically generate attacks based on the model.
However, so far, due to the complexity, such manual modeling
methods [17], [26] are still limited to only the cache tag
states, not including other cache states that could be vulnerable.
Rigorous approaches can determine if certain security exploits
exists in the design. However, formal methods [75] and
information ﬂow tracking [94] require whitebox modeling of
the design, which in many cases is hard or impossible for a
commercial microprocessor. In addition, lifting a new RTL-
level design into a formal spec without manual effort is still
challenging [28]. To deal with blackbox designs, fuzzing [20],
[82] has been used to automatically generate attack sequences.
However, to bound the size of the search space, fuzzing usually
requires pre-deﬁned attack sequences or predeﬁned gadgets,
which limit the attack strategies that can be explored. Ideally,
we want less restrictions on the form of attack sequences and
a tool that can explore (both known and unknown) attack
sequences in blackbox designs.

C. Reinforcement Learning (RL)

RL aims to ﬁnd a policy that generates an action sequence
that maximizes the long-term rewards. Figure 1 shows the
high-level components and concepts in RL. First, there is
an RL agent, which is controlled by a policy. There is an
environment, which the RL agent interacts with. In each step,
the RL agent takes an action, which feeds into the environment.
The environment changes the state with the action, then exposes

Fig. 1: RL formulation. RL agent does not need the knowledge
of the internals of the environment to learn a policy.

observations to the RL agent, and assign reward values to the
RL agent. The environment can optionally have a state where
the environment state is reset. We call the sequence between
two adjacent resets an episode. The goal of RL agent training
is to generate a sequence of actions within an episode so that
the sum of the rewards within one episode is maximized.

tactics,

Recently, RL has been shown to learn human-level (or even
super-human-level) policies in many game environments [47],
[69] where there are well-deﬁned rules and win/loss conditions.
Those games are relatively light-weight and can be simulated
easily. RL even discovers novel
including novel
openings in the game of Go [70], which humans have played
for thousands of years. Similarly, cache-timing attacks can be
formulated as a guessing game, where an attacker aims to
guess a victim’s secret correctly while paying a small penalty
(negative reward) for each cache access before making a guess.
The RL-based cache-timing attack discovery has several
advantages over the alternatives. First, the RL formulation
imposes few restrictions on the length of an attack, allowing
ﬂexible exploration of a broader set of attack sequences
compared to the existing tool [82]. Second, RL is agnostic to
the implementation of the environment as long as the interface
including the action, reward and observation is provided.
Thus, RL can work with both existing simulators as well
as commercial processors without ﬁnding a formal white-box
model of their caches [75]. Third, the RL is parameterized with
neural networks, which can generalize to unexplored states and
make smart decisions [39], [49], compared to random test-case
generations that need to explore each state independently. Thus,
RL can be more efﬁcient in searching for vulnerabilities.

III. AUTOCAT OVERVIEW

A. Overview of AutoCAT Framework

Figure 2(a) shows the AutoCAT’s overall framework. A target
cache implementation, the attacker and victim conﬁguration,
and the RL conﬁguration is consumed by the AutoCAT’s RL en-
gine for attack sequence generation. The cache implementation
can be either a simulator (with a certain cache conﬁguration) or
a real hardware processor. The attack sequence is the sequence
of memory operations, which can then be used in attack analysis
by human experts to classify and identify potential new attacks.
The attack sequence from the RL engine can also be used in
an attack demonstration on real hardware. In this study, we
manually analyzed the attack sequences to categorize them and
applied a new attack sequence from AutoCAT to multiple Intel
processors for real-world demonstration.

B. High-level RL Engine Formulation

Figure 2(b) shows the formulation of cache guessing game
as an RL problem in AutoCAT RL engine. In this setting, we

Action (a)Reward (r)Observation (s)RL agentEnvironmentFig. 2: (a) AutoCAT Framework. (b) AutoCAT RL Engine.

let the RL agent play the attacker role to explore possible attack
strategies by controlling the attacker process. For simplicity,
AutoCAT currently allows the RL agent to also control when the
victim process runs. The RL agent is a policy parameterized by
a deep neural network (DNN) model. The environment interact
with a cache implementation, which handles the memory
accesses of both the victim process and the attacker process.
The environment also contains addrsecret which is the secret of
the victim, and a guess evaluator to check if a guess is correct.
Below we explain the RL formulation.
Episode: In each episode, the environment randomly generates
the victim’s secret address (addrsecret ). The agent can then
explore different actions and get observations. When the
agent decides to make a guess on addrsecret , the episode will
terminate. Reward will be given based on the guessing result
and the number of actions taken.
Rewards: As the goal is to let the agent learn how to guess
addrsecret correctly, we set the environment to return a positive
reward if the agent’s guess is correct, and a negative reward
if the agent makes a wrong guess. To encourage the agent
to optimize the attack strategy (i.e., minimize the number of
steps), we give a small penalty on each step the agent takes.
Actions:

• aX —access X where X is the memory address accessible
by the attacker. As the attacker, the agent can access a
cache line of address X, and observe a hit/miss.

• av—trigger victim. The attacker can trigger the victim’s
secret access; the victim accesses addrsecret , which poten-
tially changes the cache state.

• agY —guess that the value of addrsecret is Y where Y is
chosen from address accessible by the victim, and end
the current episode.

Observations: When the agent takes aX (access X) above,
the cache implementation conducts the memory operation, i.e.,
looks up the address X in the cache, returns the latency of the
access, and updates the cache state. For av (trigger victim), the
environment uses the addrsecret of the current episode and lets
the cache simulator access addrsecret . With this environment,
the agent can explore attacks using a combination of actions.

IV. DESIGN AND IMPLEMENTATION

A. Cache Implementation and Conﬁguration

As depicted in Figure 2, there are two choices for cache
implementation: a cache simulator written in software or a real

processor. The cache simulator allows quickly prototyping and
implementing existing and new cache designs for vulnerability
exploration. Exploring attacks on real hardware enables apply-
ing AutoCAT to real-world system designs even when their
design details are not known.
Cache simulator: we embed an open-source cache simulator in
Python [1] as the cache model in the AutoCAT framework. The
cache conﬁguration options are in Table II. We implement LRU,
random [41], PLRU [72], and RRIP [29] replacement policies
in the cache simulator. The cache simulator can be further
extended to multi-level caches. For simplicity, we currently
use physically-indexed physically-tagged (PIPT) caches and
let the attacker and the victim directly use physical addresses
for their accesses.
Real hardware: we leverage CacheQuery [79], a open-source
tool to directly measure the cache access timing on Intel
processors. CacheQuery automatically ﬁgures out the address
mappings for L1, L2 and L3 caches and provides access to
a speciﬁc cache level, without disabling prefetching, turbo
Boost, frequency scaling, etc., which is close to real world
operating conditions. Currently, CacheQuery [79] supports
timing measurements for access sequences to one cache set.
Even though AutoCAT can interact with an arbitrary number
of sets if the cache interface allows, our experiments focus
on exploring attacks within small number of cache sets under
different conﬁgurations, given that cache-timing attacks usually
exploit the contention in each cache set independently.

B. Attacker and Victim Conﬁgurations

Cache-timing attacks also depend on how the memory
space is shared between an attacker and a victim, and which
cache operations are available. For example, if there is no
shared memory between the victim and the attacker, the
ﬂush+reload attack is not possible, but a prime+probe attack
is still possible. We refer to these choices as the attacker
and victim conﬁgurations. In our setting, for victim’s access,
the agent will not get the latency of that step (N.A. as the
observation), assuming victim access latency is not directly
visible to the attacker. To allow exploring attacks with and
without shared memory space between the attacker and the
victim, the address range of the victim and the address range of
the attacker are conﬁgurable in AutoCAT, as listed in Table II.
These address ranges determine whether the attack process can
touch the same addresses accessed by the victim. In addition,
cache-line ﬂush instruction (clflush in x86) is not always

RL AgentObserved memory access latencyRewardread/write/flushattacker processDNN ModelEnvironmentag: guessaddrsecretav: trigger victimaccessvictim processguess evaluatorax: attackeraccessActionState addrsecretAttack AnalysisAutoCATRL EngineAttack Demonstration on Real HardwareAutoCATRL EngineCache InterfaceTarget cache implementationCache Simulatorattacker& victimconfigorAttack Sequence GenerationReal HardwareAttack Sequence (trajectory of actions)Cache Interfacetime(a)(b)Cache ImplementationRL trainingTABLE II: AutoCAT conﬁguration parameters.

Option Type

Cache conﬁgs
in cache simulator

Attacker and
Victim conﬁgs

RL conﬁg

Option Name
num_blocks
num_ways
rep_alg
attacker_addr_s
attacker_addr_e
victim_addr_s
victim_addr_e
flush_enable
victim_no_access_enable
detection_enable
window_size
correct_guess_reward
wrong_guess_reward
step_reward
length_violation_reward
detection_reward

Deﬁnition
total number of blocks in the cache
number of ways of the cache
replacement algorithm for all cache sets
starting address of attacker
end address of the attacker
starting address of victim
end address of the victim
whether to enable ﬂush instruction for the attacker
whether the victim need to make a memory access when triggered by the attacker
whether the episode terminates when the attack detector signals a potential attack
size of the history window in the observation space
reward when the attacker makes a guess and the guess is correct
reward when the attacker makes a guess and the guess is wrong
reward when the attacker make a memory access
reward value when the length of episode exceed limit
reward when the attack detector signals a potential attack

Type
integer
integer
str
integer
integer
integer
integer
boolean
boolean
boolean
integer
ﬂoat
ﬂoat
ﬂoat
ﬂoat
ﬂoat

Range
2,4,...
2,4,6,8,12, 16
”lru”, ”plru”,...
0,1,2,3,...
0,1,2,3 ,...
0,1,2,3,...
0,1,2,3,...
true, false
true,false
true,false
1,2,3 ,...
(0, ∞)
(−∞, 0]
(−∞, 0]
(−∞, 0]
(−∞, 0]

available, e.g., in JavaScript. We make flush_enable a
conﬁguration option in AutoCAT.

In many cache timing channels, rather than encoding
the information with different addresses, whether the vic-
tim has made an access or not also leaks information,
e.g., prime+probe. To explore this scenario, we use the
victim_no_access_enable option, and use addrsecret e
the victim makes no access when triggered.
to represent
When this is enabled,
the victim can access one of the
addresses in the victim’s address space or make no access
(addrsecret e) with the same probability. To explore attacks
with a detection scheme, we have the conﬁguration option
detection_enable, which terminates an episode when
the sequence is recognized as an attack by the detector.

C. RL Engine and Conﬁguration

RL Action Space. The RL agent can have the attack software
take one of the three actions (i.e., aX , av, agY ), as discussed in
Section III-B. If flush_enable is set, we extend the action
aX to also include cache line ﬂush denoted by a f X . Similarly, if
victim_no_access_enable, we use agE to denote that
the agent guesses that the victim made no access after triggered.
When the attacker makes a guess, it can be either agY or agE .
Overall, the RL agent can take one action for each step: 1)
access/ﬂush: aX or a f X ; 2) trigger victim: av; 3) guess: agY or
agE , depending on the attacker/victim conﬁguration. We use
one-hot encoding to represent the actions.
RL State Space. For its own memory access aX , the attacker
can directly observe the cache access latency in terms of a hit or
a miss. To provide more information to let the RL agent learn
efﬁciently, we encode a state incorporating the history of actions
and observations, and compose the state space S as a Cartesian
product of subspaces, as follows: S = ΠW
step ×
Si
act , Si
trig), where Si
trig are the subspaces representing
the access latency, an action taken, the current step, and whether
the victim has already been triggered at step i. W is the window
size that can be set using window_size. Empirically we set
it to be 4-8 times num_blocks. The latency subspace Si
lat
is deﬁned as Si
lat = {shit , smiss, sN.A.}, representing hit/miss
and N.A. states. The action subspace Si
act =
{sa|a ∈ {aX , a f X , av, agY , agE }}, representing the state in which
action a is taken at step i. The step subspace Si
step is deﬁned as
step = {sstep1, sstep2, ...}. The victim triggering subspace Si
Si
trig

act is deﬁned as Si

lat × Si

act × Si

step, Si

i=1(Si

lat , Si

is deﬁned as Si
trig = {st , snt }, representing whether the victim
has been triggered or not. The RL agent uses this information
in order to make a guess after the secret-dependent memory
access by the victim is triggered.

For real hardware, having the agent interact with hardware
for each action is slow and also makes the training more
susceptible to system noise. To address this challenge, for
training on real hardware, we execute all instructions in an
episode together as a batch. The latency subspace is masked
until the agent make a guess, when all instructions within
an episode are executed and latency of memory accesses are
revealed.

RL Algorithm and DNN Model In this paper, We use
proximal policy optimization (PPO) [67] since it typically
performs similarly or better than other methods while being
much simpler to tune [2]. For most experiments, we use a
multi-layer perceptron (MLP) [25] to encode our RL policy.
The input states, encoded as one-hot vectors, are sent to two
hidden layers, each with 256 neurons and tanh activation,
followed by a softmax that outputs action probability. In certain
scenarios, we also use a Transformer [77] model (input feature
dimensions 128, 1 layer encoder, 8-head, FFN dimension 2048)
to learn step-wise representation, followed by average-pooling
over steps for sequence embedding. Other recurrent models
like LSTMs [27] or RNNs can also be used but may be more
difﬁcult to tune.

(e.g., aX , a f X , av),

Reward Conﬁguration. When the agent makes a guess
agY /agE , depending on whether the guess is correct or not, our
environment assigns the reward correct_guess_reward
or wrong_guess_reward. For all the actions taken by
the environment as-
the RL agent
signs a negative step_reward to encourage the agent
to ﬁnd short attack sequences. These rewards are listed
in Table II. PPO is not very sensitive to the reward
value combinations and we use the following rewards
for the experiments: correct_guess_reward = 200,
wrong_guess_reward = -10,000, and step_reward =
-10. We also explored other reward value combinations in
Appendix A. Once the sum of the reward within a episode
is converged to a positive value, we use deterministic re-
play to extract the attack sequences. To discourage the RL
agent from taking too many steps without making a guess,

we have length_violation_reward, which is a large
negative value when the length of an episode is longer than
window_size. When we implement a detection scheme
in the environment, there is also the detection_reward
which is the reward (negative value) when the sequence is
caught by the detector as a potential attack.

D. Attack Analysis and Demonstration

Once the attack sequence is generated using the RL engine,
it can be further analyzed and demonstrated. First, for attack
analysis, given a particular sequence, we want to know what is
the type of the attack, and whether is it a new type of attack.
Currently, we rely on human inspections to classify attacks and
identify new attacks. Automated classiﬁcation and identiﬁcation
of the attack sequences is an orthogonal problem and we left
it as future work. With the attack sequences generated by
AutoCAT, we can demonstrate them in real hardware. We
embed the attack sequence into a assembly template, which
uses pointer chasing to perform measurement of timing of one
address [85]. With the assembly code corresponding to the
attack sequence, we can then measure the bit rate and the error
rate of the attack on a real processor with realistic noise.

V. EVALUATION AND CASE STUDIES

In AutoCAT, we use RLlib [40] and RLMeta [90] as the
RL frameworks to train the RL agent. Our DNN model is
implemented in PyTorch [56]. The RL engine follows the
gym [10] interface. We implement the cache simulator based
on [1]. The RL training process is performed on a machine
with an Intel Xeon CPU E5-2687W v2 running Ubuntu 16.04
and Nvidia K80 GPUs with CUDA 10.2.

A. Attacks on Real Hardware

AutoCAT can explore attack sequences on real hardware
without explicitly knowing all the architectural details, in-
cluding associativity, replacement policies, frequency scaling,
hardware prefetching, and other undocumented features. In
our experimental setup using CacheQuery [79], the attacker
and the victim run in a single process on the same core. We
experimented with multiple cache levels from three different
processors, all with the same attacker and victim conﬁgurations
where the attacker needs to guess whether the victim accesses
the cache set or not. The conﬁgurations and attack sequences
found by AutoCAT are shown in Table III. The table also shows
the accuracy for each attack sequence based on repeating the
sequence 1,000 times on the same processor using CacheQuery.
Due to noise in real processors, the accuracy is slightly lower
than 100%.

The results show that AutoCAT is able to ﬁnd attack
sequences on real processors, without explicitly specifying
the number of ways or reverse engineering the replacement
policies, prefetchers, etc. Such information is usually needed
by human experts to adapt known attacks. For example,
to demonstrate prime+probe, one needs to understand the
replacement policy to prime and also probe a cache set
efﬁciently [80]. However, the replacement policies of recent

processors are rarely documented publicly by the vendor and
difﬁcult to precisely reverse engineer [79]. Even though it is
possible to reverse engineer an unspeciﬁed replacement policy
from a real world processor, it takes signiﬁcant amount of time
(as long as 100 hours) and then one still needs to develop
attack sequences manually. AutoCAT can ﬁnd effective attack
sequences within several hours in our experiments. The attack
sequence found by AutoCAT is consistent with the reverse
engineering result from the previous study [79], where each
address has to be accessed twice to set the reference count of
the corresponding cache block to zero.

B. Attacks on Diverse Cache/Attack Conﬁgurations

The ﬂexibility of the cache simulator allows us to study
diverse cache and attack conﬁgurations more easily. To evaluate
how effective the RL agent can be across a broad range
of environments, we tested AutoCAT under many different
cache and attacker/victim conﬁgurations shown in Table IV.
These environments use the (true) LRU replacement algorithm
by default. Note that the attacker/victim conﬁguration limits
the feasible attacks in the environment. For example, if the
environment does not allow the cache ﬂush instruction, the
ﬂush+reload attack is not possible. If there is no shared address
space, ﬂush+reload or evict+reload is not feasible. The expected
attack categories for each conﬁguration are also listed in
Table IV.

The RL agent could successfully ﬁnd working attack
sequences for all conﬁgurations we tested. Table IV shows
one example attack sequence for each conﬁguration that was
automatically found by the RL agent. The RL-generated
attack sequences vary for different environment conﬁgurations
and cover a range of known attack categories, including
prime+probe, ﬂush+reload, and evict+reload. For conﬁguration
1 and 3-7, we use the MLP model for the RL agent. For
conﬁguration 2 and 8-14, we use a Transformer model in
RLMeta framework.

In most cases, the RL agent generates attack sequences
that are of the attack type expected for the conﬁguration.
Interestingly, the attack sequence found by the agent can
be more efﬁcient
than the attack we expected. In some
cases, the RL agent can generate a shorter sequence than
expected. For example, for conﬁguration 1 in Table IV, a
textbook prime+probe attack will result in the following attack1:
4 → 5 → 6 → 7 → v → 4 → 5 → 6 → 7 → g. Meanwhile, the
attack sequence given by AutoCAT is: 5 → 4 → 7 → v → 5 →
7 → 4 → g. The RL agent removes the unnecessary memory
access in the textbook prime+probe attack, i.e., by attacking
three cache sets, the attacker can already learn which of the four
possible addresses the victim accessed. For conﬁgurations 5
and 7 in Table IV, instead of a prime+probe attack, the RL
agent found a shorter attack sequence leveraging the LRU
state. However, the attack sequences found by AutoCAT are
not always the shortest in length (e.g., conﬁguration 6 in

1For brevity, we only use the subscript i of an action ai to represent the
the action. For example, to represent accessing address 3, we directly use 3
to represent a3.

CPU

Xeon E5-2660v3
(Haswell)

Core i7-6700
(SkyLake)

Core i7-7700K
(KabyLake)

Cache
level
L1
L2
L1
L2
L3
L3
L3

#Ways

Example attack sequence found by AutoCAT

TABLE III: Attack sequence found using AutoCAT on real hardware.
Rep.
Pol.
PLRU
8
PLRU
8
8
PLRU
4 N.O.D.‡
4† N.O.D.
8† N.O.D.
4† N.O.D.

0.999
0.999
1 → v → 4 → v → 5 → v → 5 → 5 → 3 → 8 → 4 → v → 0 → 2 → 0 → 1 → v → 8 → 4 → v → g 0.996
0.997
1.0
0.966
1.0

0 → 1 → 7 → 3 → 6 → 6 → 6 → 6 → v → 5 → 0 → 4 → 1 → 7 → 5 → g
v → v → 4 → 0 → 5 → 1 → 1 → 4 → 2 → 7 → 3 → 3 → v → v → 3 → 0 → g
... → 3 → v → 3 → v → 6 → 7 → 3 → 3 → 5 → 1 → 5 → 1 → 6 → g
1 → 2 → 6 → 6 → 8 → 8 → 8 → v → 0 → g
7 → 7 → 3 → 4 → 6 → 0 → 2 → 1 → 6 → 5 → 3 → 2 → v → 5 → 4 → 1 → 2 → 8 → v →
8 → 7 → 6 → 6 → 3 → 3 → 4 → g

2 → 1 → 5 → 6 → 4 → 4 → 7 → 8 → 4 → 8 → v → 3 → 4 → v → 0 → g
1 → 8 → 2 → 3 → 4 → 7 → 2 → 5 → 4 → 2 → 8 → 6 → v → 6 → 3 → 6 → 7 → 1 → g

Attacker
addr.
0-8
0-8
0-8
0-8
0-8
0-8
0-8

Victim
addr.
0/E
0/E
0/E
0/E
0/E
0/E
0/E

Accuracy

L3

8† N.O.D.

0/E

0-8

Attack
Category
LRU
LRU
LRU
LRU*
LRU*
LRU*
LRU*

0.991

LRU*

† indicates way partition using Intel CAT. ‡ Not Ofﬁcially Documented. * Attacks based on replacement states, but with different sequences due to the replacement policy.
TABLE IV: The RL environment conﬁgurations tested, and the example attack sequences generated by AutoCAT.

No.

1
2
3
4
5
6
7
8
9

10

11
12
13
14

Cache conﬁg.

Attacker& victim conﬁg.

Type†

DM
DM+PFnextline
DM
DM
FA
FA
FA
FA
FA

DM

FA
FA
FA+PFnextline
FA+PFstream

Ways Sets Victim Attack
addr
used
4-7
1
4-7
1
0-3
1
0-7
1
4-7
4
0-3
4
0-7
4
0-3
4
0-7
4

addr
0-3
0-3
0-3
0-3
0/E
0/E
0/E
0-3
0-3

4
4
4
4
1
1
1
1
1

1

8
8
8
8

8

1
1
1
1

0-7

0/E
0/E
0/E
0/E

0-7

0-7
0-15
0-15
0-15

Flush
inst
no
no
yes
no
no
yes
no
yes
yes

yes

yes
no
no
no

Expected attacks
Possible
attacks‡
PP
PP
FR
ER, PP
PP, LRU
FR, LRU
ER, PP, LRU
FR, LRU
FR, LRU

FR

FR, LRU
ER, PP, LRU
ER, PP, LRU
ER, PP, LRU

Example Attack found by AutoCAT

Attack sequence (p indicates prefetch)

5 → 4 → 7 → v → 5 → 7 → 4 → g
6(p7) → 4(p5) → v → 4(p5) → 5(p6) → g
... → f 1 → v → 1 → f 0 → v → f 2 → v → 2 → f 3 → 0 → g
... → 3 → 7 → 4 → 6 → v → 3 → 0 → 6 → 4 → g
4 → 6 → 7 → v → 5 → 4 → g
0 → 3 → 1 → 2 → f 0 → 2 → v → 3 → 0 → g
v → 4 → 1 → 6 → 7 → v → 1 → v → 5 → 6 → g
f 3 → f 2 → v → 2 → 3 → f 0 → v → 0 → g
f 0 → f 2 → f 1 → v → 2 → 1 → 0 → g
f 2 → v → 2 → f 4 → f 0 → v → 0 → 4 → f 3 → f 7 → v → 3 → v →
7 → f 1 → f 6 → v → 6 → 1 → g
f 0 → v → 0 → g
7 → 11 → 10 → 5 → 4 → 2 → 3 → 1 → v → 0 → g
4 (p5) → 9 (p10) → 15 (p16) → 2 (p3) → v → 0 (p1) → g
15 → 9 → 8 → 7(p6) → 11 → 6 → 12 → 14 → v → 0 → g

Attack
Category
PP
PP
FR
ER and PP
LRU
FR
LRU
FR
FR

FR

FR
ER
ER
ER

† FA: fully-associative, DM:direct-mapped, PFnextline: nextline prefetcher, PFstream: stream prefetcher. ‡ FR: ﬂush+reload, ER: evict+reload, PP: prime+probe.

Table IV) and may contain unnecessary accesses; nonetheless,
they do capture the key mechanism that enables the attack
for each conﬁguration. In some cases, the sequence found by
the agent is an interesting combination of different attacks,
e.g., conﬁguration 4 in Table IV results in an attack that is
a combination of evict+reload and prime+probe, which could
make attack detection and defense more difﬁcult.

The cache conﬁgurations 2, 13, and 14 include either a
next-line prefetcher [71] or a stream prefetcher [31]. The RL
agent could ﬁnd attack sequences even with prefetching.

C. Case Study 1: Attacking Replacement Policy

AutoCAT’s cache simulator allows us to implement different
replacement policies and address mappings in the same setting
and the RL agent can adapt to them. We focus on replacement
policy in this case study because recent attacks based on
replacement states [9], [86] show long and complex sequences,
and we want to demonstrate the effectiveness of AutoCAT.
We use a 4-way cache (set) with four replacement algorithms:
three deterministic (LRU, PLRU, and RRIP) and one non-
deterministic (random). For a 4-way cache set, both LRU
and RRIP keep 2-bit state information (ranging from 0-3)
for each cache block, called age in LRU and re-reference
prediction value (RRPV) in RRIP, which will be incremented
correspondingly. The cache block with the largest state bits will
be evicted upon a cache miss. In LRU, the most recently used
cache block will be assigned age=0. In RRIP, a newly installed
cache block will be assigned RRPV=2, and only upon a cache
hit will it be promoted to RRPV=0. Pseudo-LRU implemented
using a tree structure is a way of approximating LRU with
less state information, whose behavior will be slightly different

from LRU. The attacker’s address space is conﬁgured to be
from 0 to 4 (large enough to ﬁll the 4-way cache set). The
victim is conﬁgured to either access address 0 or make no
access depending on a one-bit secret. The conﬁguration is
similar to that of conﬁguration 6 in Table IV. The cache is
initially accessed by address 0 and 1 before the attack.

As shown in Table V, the RL agent can successfully generate
valid attack sequences for all three deterministic policies, which
takes less than one hour of RL training for each case. For
the deterministic replacement policies, RL ﬁnds attacks that
always make a correct guess (there is no noise). The results
also show that PLRU and RRIP need longer training and a
longer attack sequence compared to LRU, In the RRIP attack
example, the 3 → 2 → 3 → 1 sequence is needed to ensure that
for both address 1 and address 3, RRPV is 0 since they are
cache hit and predicted to be immediately re-referenced. For
address 2, RRPV is 2 since it is not re-referenced. As shown in
Figure 3, the victim access of address 0 will set RRPV=0 for
address 0 and leaving address 2 to be replaced. When triggered,
regardless of whether the victim accesses 0 or not, there is no
miss event, which is similar to the RELOAD+REFRESH [9]
attack reported recently.

Unlike a deterministic replacement policy where the next
state will be fully determined given the action and current
state, the next state is hard to predict in the (pseudo)-random
replacement algorithm. Thus, an attack sequence that results
in a correct guess may result in a wrong guess in another
evaluation. The RL agent can also produce different actions
depending on the current observation. In that sense, unlike
a deterministic replacement policy, there is no single attack
sequence that always works in the random replacement policy,

TABLE V: RL training statistics and generated attacks for deterministic cache
replacement policies.

Steps to
Repl.
alg.
converge
LRU 296,000
PLRU 340,000
336,000
RRIP

Attack sequence found by AutoCAT

Episode
length
6.59 v → 4 → 3 → 2 → 0(hit/miss) → g
9.14 1 → v → 1 → 4 → v → 3 → 2 → 1(miss/hit) → g
9.68 3 → 2 → 3 → 1 → v → 4 → 2(miss) → g0; 3 → 2 → 3 → 1 → v → 4 → 2(hit) → 0 → gE

TABLE VI: The RL-generated attacks on
the random replacement policy.
End
accuracy

Step
reward

Episode
length

0
-10
-20
-30

1.0
0.87
0.999
0.897

41.00
35.75
34.99
30.17

num of
se-
quences
737
171
163
122

TABLE VII: Comparison of PLRU w/ and w/o PLCache.

Cache
PLCache
baseline

Steps to converge
232,000
176,000

Episode length
11.66
8.58

TABLE VIII: Bit rate, autocorrelation, and accuracy of attacks.
sampled attacker bit rate (guess/step) max autocorrelation accuracy
textbook
RL baseline
RL autocor

0.1625
0.236
0.1975

1
0.99
0.99

0.96
0.92
0.55

Fig. 3: Attack sequences and corresponding cache state for
RRIP replacement algorithm and victim access (left)/no access
(right) information is inferred by the attacker. Gray blocks
indicates the one to be evicted on a cache miss.

whose eviction rate depends on the number and the sequence
of memory accesses. Instead, we evaluate the attack accuracy
of the RL agent over 2,000 evaluation runs. As shown in
Table VI, the step reward determines the tradeoff between the
attack length and the accuracy. The evict+reload strategy is
similar to the prior attack on random replacement policy [41].

D. Case Study 2: Bypassing Defense and Detection Techniques

To protect against cache timing-channel attacks, a variety
of detection and mitigation techniques have been proposed.
AutoCAT’s cache simulator can also be used to test research
prototypes of defense and detection mechanisms proposed in
previous works that lack actual real processor implementations.
This is especially useful when evaluating new protection or
detection schemes and ﬁnd vulnerabilities. We implemented
four cache timing-channel protection schemes in the cache
simulaor: 1) Partition-locked (PL) cache [81], 2) Hardware Per-
formance Counter (HPC)-based detection [4], [15], [36], [95],
3) Autocorrelation-based detector similar to CC-hunter [12]
and, 4) machine learning-based detector similar to Cyclone [24].
AutoCAT successfully ﬁnds attack sequences that can bypass
these protection schemes.
Partition-Locked (PL) Cache. PL cache [81] provides special
instructions to lock speciﬁc cache lines in a cache to prevent
them from being evicted. The victim program can lock its
own cache lines so that they cannot be evicted by the attacker
program. Further, the victim’s access to the locked cache lines
will not evict any of the attacker’s cache lines. In [26], the
formal analysis on a simpliﬁed cache model concludes that
PLcache is secure when the attacker and the victim do not
share address space.

We implemented the PL cache with the lock/unlock interface
in our cache model. To use the PL cache as a defense

mechanism, we assume the victim’s cache line is pre-installed
and locked in the cache. We use a 4-way cache, and the address
range of the attacker is 1-5 and the victim either accesses 0
or has no access depending on the secret value. The setting is
considered to be secure in [26]. For this setting, the training
takes about 45 minutes. Table VII shows the training time (# of
steps) and the attack sequence length for a cache with PLRU,
with and without the PL cache. AutoCAT successfully found
an attack that works even with the PL cache, represented by
attack sequence 1 → v → 3 → 3 → 2 → 5 → 5. In this attack, the
victim’s cache line (address 0) always stays in the cache, and
the victim’s behavior (whether the victim makes access or not)
does not evict any of the attacker’s cache lines. However, the
victim’s access affects the LRU state. When the attacker made
subsequent accesses, it can tell whether the victim accessed
address 0 or not by observing if a new block can be brought
into the cache. This attack is reported in recent literature [86].
Autocorrelation-based Detection. Autocorrelation of cache
events have also been proposed as a way to detect the existence
of cache-timing channels [12], [88] based on the observation
on the common covert-channel sequences. In CC-Hunter [12],
two types of conﬂict miss events (i.e., victim evicting attacker’s
cache line, V → A, encoded with “0”, and attacker evicting
victim’s, A → V , encoded with “1”) are considered in the event
train {Xi} where 0 ≤ i ≤ n, and n is the length. In a contention-
based cache side channel like prime+probe, these two events are
interleaved periodically. We can check the autocorrelation Cp at
n−p
i=0 [(Xi− ¯X)(Xi+p− ¯X)]
lag p using the following equation: Cp = ∑
.
i=0(Xi− ¯X)2
∑n
If there exists p where 1 ≤ p ≤ P (P is a predeﬁned parameter)
such that Cp > Cthreshold (e.g. 0.75), then it is considered to be
an attack.

For example, in a 4-set direct-mapped cache where the
victim and attacker’s address space is 0-3 and 4-7, a “textbook”
prime+probe attack would perform the following steps. First
the address space 4-7 is primed by the attacker, after that
one victim access is triggered, and then addresses 4-7 are
probed. The event train and the corresponding autocorrelogram
is shown in Figure 4. The maximum autocorrelation for p ≥ 1
is 0.96, which is over the threshold.

The AutoCAT generated baseline sequence (RL baseline)

01013013201320132013201340132access3hithitN.AmissmissVictimaccessaffectsRRPVofaddress0,affectingwhichlinewillbereplacedwhenattackeraccessesaddress4miss22222222222202333200200021112222201013013201320132013241324132misshithitN.A.misshitmiss222222222222023332002200221133110RRPVRRPVVictimno access when triggeredNext actionaccess2access3access1Trigger victimaccess4access2missVictimaccess 0 when triggeredTABLE IX: Comparison of bit rate, guess accuracy and
detection rate by the SVM.

sampled attacker bit rate (guess/step) attack accuracy SVM detection rate
textbook
RL baseline
RL SVM

0.1625
0.228
0.150

1
0.990
0.964

1
0.907
0.021

Fig. 4: (a) Event train (A→V: attackers’ conﬂict misses with the
victim and V→A: victim’s conﬂict misses with the attacker.)
(b) Autocorrelograms of the event trains. The dashedline shows
the threshold for detecting an attack.

the event

can be also detected by this autocorrelation-based detector,
as shown in the conﬂict miss event train and the autocorrel-
ogram (Figure 4). The maximum autocorrelation for p ≥ 1
is 0.92. Note that
train and the corresponding
autocorrelograms will be different for each sample. However,
we observe the maximxum autocorrelation of 0.875-0.940 over
25 distinctive inferences (sampled from randomly generated
victim addresses), which are all above the detection threshold.
However, AutoCAT can learn to bypass such autocorrelation
detector if the reward of the RL agent is augmented to avoid
high autocorrelation. We use L2-penalty of Cp to penalize high
C2
autocorrelations, which is deﬁned as RL2 = a ∑P
p
P where a
is a negative number and P << n is the length of Cp used for
autocorrelation-based detection. The sampled cache conﬂict
miss event train and the autocorrelogram of the resulting
agent (RL autocor) are shown in Figure 4. The maximum
autocorrelation beyond lag 0 is 0.55 in this example. For 25
different samples, we observe the maximum autocorrelation
of 0.396-0.772 with only 2 samples over 0.75. The results
indicate that the agent (RL autocor) will be able to evade
autocorrelagoram detection with high probability.

p=1

Table VIII compares the attack sequence from the textbook,
RL baseline, and RL autocor in terms of bit rate (average
number of guesses per step), accuracy, and autocorrelation. All
attacks achieve over 0.99 accuracy and the RL agents have a
higher bit rate than the textbook attack. This is because the RL
agents optimize the bit rate to gain higher rewards. We observe
when a miss is already observed during a probe step, RL agents
can guess the secret while the textbook attack still completes
the remaining accesses. We also observe that the bit rate of
RL autocor is lower than RL baseline because RL autocor
makes additional accesses to reduce autocorrelation.
ML-based Detection. Machine learning classiﬁers can also
be used for detecting cache-timing attacks. For example, in
Cyclone [24], the frequency of cyclic access sequences by
different security domains (e.g., a (cid:32) b (cid:32) a) for each cache
line within each timing interval is used as the input of an SVM
classiﬁer to detect cache timing channels efﬁciently. We use
a 4-set direct-mapped cache as an example and implement
domain tracking and cyclic access sequence counting for each
cache line following [24]. We train an SVM classiﬁer using
SPEC2017 benchmarks for benign memory access traces and
the textbook prime+probe attack for malicious memory traces.

The 5-fold validation accuracy of the SVM is 98.8%.

We then train the AutoCAT’s RL agent (RL SVM) with
this SVM detector. If the SVM detector correctly reports the
existence of the attack, the RL agent gets a negative reward. We
also train an RL baseline agent without detection penalty. We
show the result in Table IX. The textbook and the RL baseline
can be easily detected by the SVM detector, with the detection
rate of 1 and 0.907, respectively. However, when the RL agent
is trained with the SVM detection penalty, it can ﬁnd attack
sequences that can bypass the SVM detector, with the detection
rate of 0.021, at the cost of a reduced bit rate. This indicates ML-
based detector trained on static traces can be easily bypassed by
an RL-based attacker and novel training method for ML-based
detector is needed.

µarch Statistics-based Detection. Most of the cache-timing
attacks cause the victim’s process to incur more cache misses
during the attack. Thus, detection schemes based on microarchi-
tecture event counts/statistics have been proposed to leverage
hardware performance counters (HPCs) to monitor the cache
hit-rate of the victim process and detect an attack at run-
time [4], [15], [36], [95]. More recently, [46] observes that
ﬁne-grained statistics can achieve better detection accuracy.
When an abnormally large number of cache misses are observed,
the detector signals a potential attack.

To evaluate the statistics-based detection scheme in AutoCAT,
we consider the attack is detected when the victim access
triggers a cache miss. We terminate the episode and assign a
negative reward if the victim access results in its cache miss
during training. This conﬁguration encourages the RL agent to
avoid victim misses, and thus, avoid the miss-based detection.

Figure 5(b) shows the attack sequence generated by AutoCAT
for a 4-way cache with the miss-based detection scheme. This
is a new attack sequence, which is a novel combination of the
two recent attacks in literature (shown in Figure 5(a)). The
attack sequence can be divided into sub-sequences, which are
the LRU set-based or LRU address-based attacks [86]. The two
sub-sequences overlap with each other in a way similar to the
Streamline attack [65]. Based on the gray part of the sequence
generated by AutoCAT in Figure 5(b), we construct a new
attack, named StealthyStreamline, in Figure 5(c). Compared to
the Streamline attack, the new StealthyStreamline attack does
not cause cache misses of the victim process, thus is stealthier.
Compared to the LRU-based attacks, StealthyStreamline has
a higher bit rate by overlapping the steps for multiple bits,
effectively transferring multiple bits at a time. Figure 5(d)
illustrates the cache state when the StealthyStreamline is
transmitting 2 bits. The attacker observes different timing when
the victim has 4 different possible secret values.

02040Number of cache conflictsA->VV->AA->VV->AA->VV->A(a) Event traintextbookRL_baselineRL_autocor0102030Lag (p)101Autocorrelation  Coefficient(b) Autocorrelograms TABLE X: Covert channels on real machines.

CPU

µ-arch.

L1D conﬁg

OS

IvyBridge
Skylake

Xeon E5-2687W v2
Core i7-6700
Core i5-11600K
Xeon W-1350P
a The bit rate when the average error rate < 5%. bSS. for StealthyStreamline.

32KB(8way) Ubuntu18
32KB(8way) Ubuntu18
RocketLake 48KB(12way) CentOS8
RocketLake 48KB(12way) Ubuntu20

Bit Ratea
LRU SS.b
7.7
6.2
4.5
3.6
5.7
3.4
3.7
2.1

(Mbps)
Impr.
24%
22%
67%
71%

Fig. 6: Bit rate of the StealthyStreamline attack and the
LRU address-based attack on four different processors. The
horizontal error bars show the range of errors across different
transmission runs.

processors employ a 48KB (12-way) L1 data cache. The
machines run different versions of Linux.

We generalize the 2-bit StealthyStreamline attack sequence
in a 4-way cache (in Figure 5) to 8-way and 12-way scenarios
by adding extra accesses to the cache lines that map to
the same cache set. We implemented both 2-bit (4 possible
addrsecret values) and 3-bit (8 possible addrsecret values)
StealthyStreamline covert channels.
Bit Rate and Error Rate: We test the bit rate and the
corresponding error rate of the covert channel within a process.
We do not change any system conﬁguration with the purpose of
facilitating the attack, i.e., hardware prefetchers remain enabled.
We measure the bit rate by measuring the time of sending a
2048-bit random string 100 times, using time in Linux. We
evaluate the error rate using the Hamming distance between
the message being sent and the message received. We observe
that the 3-bit StealthyStreamline has a high error rate due to
the tree structure in PLRU, while the 2-bit StealthyStreamline
has a low error rate.

Figure 6 shows the bit rates and the corresponding error rates
for the 2-bit StealthyStreamline covert channel and the baseline
LRU address-based covert channel. In most of the machines,
we observe the LRU address-based covert channel has a larger
variation in the error rate across different experiment runs,
as shown by the error bars in Figure 6. For the error rate
less than 5%, StealthyStreamline has a higher bit rate than
the LRU address-based covert channel. In an 8-way cache,
StealthyStreamline has up to a 24% higher bit rate. In the
latest 12-way cache, the StealthyStreamline has up to a 71%
higher bit rate. StealthyStreamline improves the bit rate more
for caches with a higher associativity, because a smaller fraction

Fig. 5: StealthyStreamline attack. (a) Known attack sequences
in the literature. (b) The new attack sequence found by
AutoCAT, which can be seen as the combination of the two
known attacks. (d) StealthyStreamline attack derived from the
attack found by AutoCAT. (e) The cache state changes of the
StealthyStreamline attack. The numbers in the right bottom
corner indicate the LRU age of the cache line.

E. Demonstration of Attacks on Real Machines

The attack sequence discovered by AutoCAT captures one
essential aspect of real-world cache-timing attacks. However,
the real-world attacks also have to deal with common practical
issues like measurement noise, calibrations, interferences, etc.
These practical issues are common in many attacks and people
handle them in a similar way regardless of the actual attack
sequences. To demonstrate the usefulness of these attack
sequences in real-world scenario, we put the attack sequence
from AutoCAT into an open-source attack assembly template
[85], which handles calibration, measurement, cache line
access, and forms a covert channel corresponding to the attack
sequence. We can then execute the assembly on a real processor
under a practical operating environment.

With this method, we demonstrate the StealthyStreamline
attack sequence for a covert channel in the L1 data cache
on four different Intel processors (Table X). Two processors
have a 32KB (8-way) L1 data cache, and the other two latest

loop0v2?1v3?2v4?3v5?4v0?5v1?v1?0v2?1v3?2v4?3v5?4v0?5v1?0v2?1v2?1v3?2v4?3v5?4v0?5v1?0ii. LRU addr-based [HPCA 2020]0123v0?40iii. LRU set-based   [HPCA 2020] 01v5?23401320v?23404v?5120(b) Attack sequencefound by AutoCAT0v?2340LRU set-based(v==1?)23404v?512LRU addr-based (v==2?)04v?5120LRU addr-based (v==0?)Streamline overlapping(a) i. Streamline [ASPLOS 2021]Overlapping evict-reload attacks………Evict-reload (v5?):Evict-reload (v0?):(c) StealthyStreamlineAttack0123v?4loop014……0123v?40LRU addr-based (v==0?)tttt…Streamline overlappingVictimaccess 0Victimaccess 1Victimaccess 2Victimaccess 301230321012330210123320101233210Triggervictimaccess404233032access0access1access204231032hit04132103missmiss412301324103120341032013hitmissmisst412303124023102340212130hitmissmiss412303214023103240132103missmissmiss(d) Cache states of StealthyStreamlinenvn?nThe attacker accesses nThe victim accesses nor not depending on the secretThe attacker accesses address n and measure the latency123v?401The victim may access address [0,3]LRU addr-based (v==1?)t0510152025Error rate (%)0510Bit Rate (Mbps)Xeon E5-2687W v2LRU addr_basedStealthyStreamline0510152025Error rate (%)0510Bit Rate (Mbps)Core i7-67000510152025Error rate (%)0510Bit Rate (Mbps)Core i5-11600K0510152025Error rate (%)0510Bit Rate (Mbps)Xeon W-1350PFig. 7: Attack accuracy as a function of training epochs, the
orange vertical lines show when the remapping happens.

of memory accesses (4 out of 10 for the 8-way cache vs. 4
out of 14 for the 12-way cache) need to be measured and
measuring the latency of an access takes more cycles than a
normal memory access.
Spectre Attack using StealthyStreamline: We demonstrate
Spectre V1 attack [35] with the StealthyStreamline as the covert
channel. Compared with the LRU address-based covert channel,
the 2-bit StealthyStreamline enables us to encode 4x more
symbols with the same cache. Compared with ﬂush+reload or
evict+time, StealthyStreamline makes the attack stealthier.

VI. DISCUSSION AND FUTURE WORK

A. Comparison with Search Algorithms

RL takes a fewer number of steps to ﬁnd a successful attack
than a brute-force search, and has the potential to handle
much larger search spaces. Consider the prime+probe attack
on an N-way cache set as an example. On average, we can
ﬁnd one prime+probe sequence every M sequences, where
√
M = 2×(N+1)2N+1
e )2N, we have M ∼ e2N,
which increases exponentially with the number of ways. For
N = 8, M ≈ 2.05 × 107, it takes about 369 million steps to ﬁnd
an attack, considering each attack sequence takes 2N + 2 steps.
Last-level caches usually have more than 8 ways and it will be
infeasible for exhaustive search. With RL, the agent converges
within ∼1 million steps.

. Since N! ∼

2πN( N

(N!)2

Compared to RL that learns policy/value on the ﬂy to pro-
gressively improve the search quality to ﬁnd the distinguishing
sequence, traditional search techniques may not have sufﬁcient
learning capability. For example, a random search does not
have learning at all; A* search utilizes a predeﬁned heuristics
function, which was not updated during the search process.

B. Cache with Randomized Mapping

To thwart set-based cache timing attacks, recent studies [59],
[60], [66], [81] proposed changing the cache mapping and
make it hard for the attacker to co-locate with the victim on
desired cache sets. As a preliminary study, we implemented a
randomized mapping scheme similar to CEASE [59], and tested
AutoCAT with randomized mapping. Similar to CaSA [8], we
assume an attacker can keep monitoring and learning the cache
set mapping and launch an attack when needed. We use a 4-set
2-way cache in this experiment. The victim accesses address 0
or not depends on the secret. The attacker’s address range is 1-
11. When randomizing the mapping, address 0-11 are randomly
permuted and map to different sets. In Figure 7, we show the
accuracy of the agent as the function of the training epochs. We
set the redo the randomization 2M memory accesses. We found

that the attack accuracy drops after a randomized mapping, but
the agent can adapt to the new mapping quickly within around
50 epochs in many cases.

It is also interesting to note that our preliminary result
shows that the attack accuracy improves gradually even when
an attacker does not have a full eviction set, which is the same
observation made by the previous study [8] (there is a trade-off
between calibration time and attack accuracy).

C. Future Extensions

One challenge in AutoCAT lies in analyzing many attack
sequences from the RL agent. We had to manually analyse
and categorize the sequences found by AutoCAT. Ideally, we
need to automated attack analysis.

Given the repetitive structure of a cache, we focus on training
AutoCAT with small cache conﬁgurations and generalize
the attack to real machines manually. The scalability and
generalizability when applying to multiple levels of large
caches still need to be further explored. Our initial investigation
shows promising results that suggest AutoCAT can be further
improved with new ML model architectures such as Trans-
formers [13], [30], [78] and RL generalization methods [34],
[61]. In the future work, we plan to investigate extending the
AutoCAT approach to more complex cache conﬁgurations and
other types of microarchitectural timing channels beyond cache.
We have demonstrated RL can ﬁnd attacks wieht randomized
mapping, however, it remains future work how qucikly RL can
adapt to dynamic remapping [59].

For training on real hardware, the CacheQuery interface only
supports access on one cache set, which exclude possible attack
sequences that involve multiple cache sets. We plan to make
CacheQuery support measurement on multiple cache sets.

VII. RELATED WORK

Automated timing channel analysis and discovery. Prior
studies proposed systematic analysis methods for cache timing
channels based on simpliﬁed cache models [17], [26], [84]. Our
work demonstrates RL as a new way to enable more automated
security analysis, which can be easily extended to new systems
or defense mechanisms with less human effort. There exist
other automated approaches for vulnerability analysis such
as exhaustive approach [19], taint analysis [21], fuzzing [20],
[48], [82], relational testing [52], and formal methods [75].
CheckMate [75] can only discover attacks that is speciﬁed by
the given exploit sequence. Information ﬂow tracking technique
such as SecVerilog [94] can identify information leakage in
the designs but cannot generate exploits automatically. For
example, the attack sequences that exploit dirty bits [16] are
only reported seven years after the vulnerability is noted by
SecVerilog. Compared to formal methods, the RL-based method
cannot provide mathematical security guarantees, but can more
easily be applied to a system without building a formal model
or writing proofs, both of which require signiﬁcant human
efforts [11]. Compared to fuzzing, the RL-based method is
more efﬁcient and expressive for complex attack sequences.

050100150200250300350400Epoch0.51.0AccuracyaccuracyremapFor example, Osiris [82] explores attack with three instructions,
and IntroSpectre [20] relies on predeﬁned attack gadgets.
Cache-timing attack detection and defense. To prevent
cache timing-channel attacks, many detection and defense
mechanisms were proposed. Detection mechanisms such as
cc-Hunter [12] and ReplayConfusion [88] focus on detecting
an attack. We show that the RL agent has the potential to
automatically generate attacks to evade detection schemes. On
the other hand, defenses [18], [33], [51], [60], [66], [74], [87]
focus on mitigating or removing the interference that leads to
known timing channels. This paper shows that RL also has the
potential to automatically evaluate the security of mitigations,
and shows that AutoCAT can break PLCache [81] successfully.
ML for security. Machine learning was used in the com-
puter security domain for anomaly detection [38], website
ﬁngerprinting [37], [68], and other analysis tasks. However,
traditional supervised learning cannot ﬁnd new attacks without
known attack sequences or labels. To address this challenge,
we propose to use RL, which can be trained with delayed
rewards and whose action trajectories are expressive enough
to represent real-world attack sequences.

Reinforcement learning has been used for software security
[50], IoT security [76], autonomous driving security [63],
power side-channel attacks [62], circuit test generation [55],
power side-channel countermeasures [64], and hardware Trojan
detection [54]. To our knowledge, our work is the ﬁrst of its
kind in using RL to actively and automatically generate attack
sequences in the microarchitecture security domain.

VIII. CONCLUSION

In this paper, we propose to use reinforcement learning to
automatically ﬁnd existing and undiscovered timing-channel
attack sequences. As a concrete example, we build the AutoCAT
framework, which can explore cache-timing attacks in various
cache conﬁgurations and attacker/victim settings, and under
different defense and detection mechanisms. Our experimental
results show that
the RL agent can ﬁnd practical attack
sequences for various blackbox cache designs. The RL agent
also discovered the StealthyStreamline attack, which is a
novel attack with a higher bit-rate on real machines than
attacks reported in previous literature. AutoCAT shows RL
is a promising method to explore microarchitecture timing
attacks in practical systems.

ACKNOWLEDGMENT

The authors would like to thank John Ghra at Virginia Tech
for technical support. Mulong Luo is partially supported by
NSF under grant ECCS-1932501.

REFERENCES

[1] [Online]. Available: https://github.com/auxiliary/CacheSimulator
[2] [Online]. Available: https://openai.com/blog/openai-baselines-ppo
[3] A. Abel and J. Reineke, “Reverse engineering of cache replacement
policies in intel microprocessors and their evaluation,” in 2014 IEEE
International Symposium on Performance Analysis of Systems and
Software (ISPASS).

IEEE, 2014, pp. 141–142.

[4] M. Alam, S. Bhattacharya, D. Mukhopadhyay, and S. Bhattacharya,
“Performance counters to rescue: A machine learning based safeguard
against micro-architectural side-channel-attacks,” Cryptology ePrint
Archive, 2017.

[5] C. Berner, G. Brockman, B. Chan, V. Cheung, P. Debiak, C. Dennison,
D. Farhi, Q. Fischer, S. Hashme, C. Hesse et al., “Dota 2 with large
scale deep reinforcement learning,” arXiv preprint arXiv:1912.06680,
2019.

[6] D. J. Bernstein, “Cache-timing attacks on AES.”
[7] J. Bonneau and I. Mironov, “Cache-collision timing attacks against aes,”
in International Workshop on Cryptographic Hardware and Embedded
Systems. Springer, 2006, pp. 201–215.

[8] T. Bourgeat, J. Drean, Y. Yang, L. Tsai, J. Emer, and M. Yan, “CaSA: End-
to-end quantitative security analysis of randomly mapped caches,” in 2020
53rd Annual IEEE/ACM International Symposium on Microarchitecture
(MICRO).

IEEE, 2020, pp. 1110–1123.

[9] S. Briongos, P. Malag´on, J. M. Moya, and T. Eisenbarth, “RELOAD+
REFRESH: Abusing cache replacement policies to perform stealthy cache
attacks,” in 29th USENIX Security Symposium (USENIX Security 20),
2020, pp. 1967–1984.

[10] G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman,

J. Tang, and W. Zaremba, “Openai gym,” 2016.

[11] P. Buiras, H. Nemati, A. Lindner, and R. Guanciale, “Validation of
side-channel models via observation reﬁnement,” in MICRO-54: 54th
Annual IEEE/ACM International Symposium on Microarchitecture, 2021,
pp. 578–591.

[12] J. Chen and G. Venkataramani, “CC-hunter: Uncovering covert timing
channels on shared processor hardware,” in 2014 47th Annual IEEE/ACM
International Symposium on Microarchitecture.
IEEE, 2014, pp. 216–
228.

[13] L. Chen, K. Lu, A. Rajeswaran, K. Lee, A. Grover, M. Laskin,
P. Abbeel, A. Srinivas, and I. Mordatch, “Decision transformer:
learning via sequence modeling,” in Advances in
Reinforcement
Neural Information Processing Systems, A. Beygelzimer, Y. Dauphin,
P. Liang, and J. W. Vaughan, Eds., 2021.
[Online]. Available:
https://openreview.net/forum?id=a7APmM4B9d

[14] Y. Chen, L. Pei, and T. E. Carlson, “Leaking control ﬂow information

via the hardware prefetcher,” arXiv preprint arXiv:2109.00474, 2021.

[15] M. Chiappetta, E. Savas, and C. Yilmaz, “Real time detection of cache-
based side-channel attacks using hardware performance counters,” Applied
Soft Computing, vol. 49, pp. 1162–1174, 2016.

[16] Y. Cui and X. Cheng, “Abusing cache line dirty states to leak information
in commercial processors,” in 2022 IEEE International Symposium on
High Performance Computer Architecture (HPCA).

IEEE, 2022.

[17] S. Deng, W. Xiong, and J. Szefer, “A benchmark suite for evaluating
caches’ vulnerability to timing attacks,” in Proceedings of the Twenty-
Fifth International Conference on Architectural Support for Programming
Languages and Operating Systems, 2020, pp. 683–697.

[18] G. Dessouky, T. Frassetto, and A.-R. Sadeghi, “HybCache: Hybrid side-
channel-resilient caches for trusted execution environments,” in 29th
USENIX Security Symposium (USENIX Security 20), 2020, pp. 451–468.
[19] M. R. Fadiheh, A. Wezel, J. Muller, J. Bormann, S. Ray, J. M. Fung,
S. Mitra, D. Stoffel, and W. Kunz, “An exhaustive approach to detecting
transient execution side channels in RTL designs of processors,” IEEE
Transactions on Computers, 2022.

[20] M. Ghaniyoun, K. Barber, Y. Zhang, and R. Teodorescu, “IntroSpectre:
a pre-silicon framework for discovery and analysis of transient execution
vulnerabilities,” in 2021 ACM/IEEE 48th Annual International Symposium
on Computer Architecture (ISCA).

IEEE, 2021, pp. 874–887.

[21] B. Gras, C. Giuffrida, M. Kurth, H. Bos, and K. Razavi, “ABSynthe:
Automatic blackbox side-channel synthesis on commodity microarchitec-
tures.” in Network and Distributed Systems Security (NDSS) Symposium,
2020.

[22] D. Gruss, C. Maurice, K. Wagner, and S. Mangard, “Flush+ Flush: a
fast and stealthy cache attack,” in International Conference on Detection
of Intrusions and Malware, and Vulnerability Assessment.
Springer,
2016, pp. 279–299.

[23] J. Hare, “Dealing with sparse rewards in reinforcement learning,” arXiv

preprint arXiv:1910.09281, 2019.

[24] A. Harris, S. Wei, P. Sahu, P. Kumar, T. Austin, and M. Tiwari,
“Cyclone: Detecting contention-based cache information leaks through
cyclic interference,” in Proceedings of the 52nd Annual IEEE/ACM
International Symposium on Microarchitecture, 2019, pp. 57–72.

[25] T. Hastie, R. Tibshirani, J. H. Friedman, and J. H. Friedman, The elements
of statistical learning: data mining, inference, and prediction. Springer,
2009, vol. 2.

[26] Z. He and R. B. Lee, “How secure is your cache against side-channel
attacks?” in Proceedings of the 50th Annual IEEE/ACM International
Symposium on Microarchitecture, 2017, pp. 341–353.

[27] S. Hochreiter and J. Schmidhuber, “Long Short-Term Memory,” Neural

Comput., vol. 9, no. 8, Nov. 1997.

[28] Y. Hsiao, D. P. Mulligan, N. Nikoleris, G. Petri, and C. Trippel, “Syn-
thesizing formal models of hardware from rtl for efﬁcient veriﬁcation of
memory model implementations,” in MICRO-54: 54th Annual IEEE/ACM
International Symposium on Microarchitecture, 2021, pp. 679–694.
[29] A. Jaleel, K. B. Theobald, S. C. Steely Jr, and J. Emer, “High performance
cache replacement using re-reference interval prediction (RRIP),” ACM
SIGARCH Computer Architecture News, vol. 38, no. 3, pp. 60–71, 2010.
[30] M. Janner, Q. Li, and S. Levine, “Ofﬂine reinforcement learning as one
big sequence modeling problem,” in Advances in Neural Information
Processing Systems, 2021.

[31] N. P. Jouppi, “Improving direct-mapped cache performance by the
addition of a small fully-associative cache and prefetch buffers,” ACM
SIGARCH Computer Architecture News, vol. 18, no. 2SI, pp. 364–373,
1990.

[32] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” in
ICLR (Poster), 2015. [Online]. Available: http://arxiv.org/abs/1412.6980
[33] V. Kiriansky, I. Lebedev, S. Amarasinghe, S. Devadas, and J. Emer,
“DAWG: A defense against cache timing attacks in speculative execution
processors,” in 2018 51st Annual IEEE/ACM International Symposium
on Microarchitecture (MICRO).

IEEE, 2018, pp. 974–987.

[34] R. Kirk, A. Zhang, E. Grefenstette, and T. Rockt¨aschel, “A
survey of generalisation in deep reinforcement learning,” CoRR, vol.
abs/2111.09794, 2021. [Online]. Available: https://arxiv.org/abs/2111.
09794

[35] P. Kocher, J. Horn, A. Fogh, D. Genkin, D. Gruss, W. Haas, M. Hamburg,
M. Lipp, S. Mangard, T. Prescher et al., “Spectre attacks: Exploiting
speculative execution,” in 2019 IEEE Symposium on Security and Privacy
(SP).

IEEE, 2019, pp. 1–19.

[36] Y. Kulah, B. Dincer, C. Yilmaz, and E. Savas, “SpyDetector: An approach
for detecting side-channel attacks at runtime,” International Journal of
Information Security, vol. 18, no. 4, pp. 393–422, 2019.

[37] A. S. La Cour, K. K. Afridi, and G. E. Suh, “Wireless charging power side-
channel attacks,” in Proceedings of the 2021 ACM SIGSAC Conference
on Computer and Communications Security, 2021, pp. 651–665.
[38] T. D. Lane, Machine learning techniques for the computer security

domain of anomaly detection. Purdue University, 2000.

[39] A. Lazaric, “Transfer in reinforcement learning: a framework and a
survey,” in Reinforcement Learning. Springer, 2012, pp. 143–173.
[40] E. Liang, R. Liaw, R. Nishihara, P. Moritz, R. Fox, K. Goldberg,
J. Gonzalez, M. Jordan, and I. Stoica, “RLlib: Abstractions for dis-
tributed reinforcement learning,” in International Conference on Machine
Learning. PMLR, 2018, pp. 3053–3062.

[41] M. Lipp, D. Gruss, R. Spreitzer, C. Maurice, and S. Mangard, “AR-
Mageddon: Cache attacks on mobile devices,” in 25th USENIX Security
Symposium (USENIX Security 16), 2016, pp. 549–564.

[42] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, A. Fogh, J. Horn,
S. Mangard, P. Kocher, D. Genkin et al., “Meltdown: Reading kernel
memory from user space,” in 27th USENIX Security Symposium (USENIX
Security 18), 2018, pp. 973–990.

[43] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, “Last-level cache
side-channel attacks are practical,” in 2015 IEEE symposium on security
and privacy.

IEEE, 2015, pp. 605–622.

[44] M. Luo, A. C. Myers, and G. E. Suh, “Stealthy tracking of autonomous
vehicles with cache side channels,” in 29th USENIX Security Symposium
(USENIX Security 20). USENIX Association, Aug. 2020, pp. 859–876.
[45] Y. Michalevsky, A. Schulman, G. A. Veerapandian, D. Boneh, and
G. Nakibly, “PowerSpy: Location tracking using mobile device power
analysis,” in 24th USENIX Security Symposium (USENIX Security 15),
2015, pp. 785–800.

[46] S. Mirbagher-Ajorpaz, G. Pokam, E. Mohammadian-Koruyeh, E. Garza,
N. Abu-Ghazaleh, and D. A. Jim´enez, “Perspectron: Detecting invariant
footprints of microarchitectural attacks with perceptron,” in 2020
53rd Annual IEEE/ACM International Symposium on Microarchitecture
(MICRO).

IEEE, 2020, pp. 1124–1137.

[47] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.
Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski,

S. Petersen, C. Beattie, A. Sadik, I. Antonoglou, H. King, D. Kumaran,
D. Wierstra, S. Legg, and D. Hassabis, “Human-level control through
deep reinforcement learning,” Nature, vol. 518, no. 7540, pp. 529–533,
Feb. 2015, publisher: Nature Publishing Group, a division of Macmillan
Publishers Limited. All Rights Reserved.

[48] D. Moghimi, M. Lipp, B. Sunar, and M. Schwarz, “Medusa: Microarchi-
tectural data leakage via automated attack synthesis,” in 29th USENIX
Security Symposium (USENIX Security 20), 2020, pp. 1427–1444.
[49] S. Narvekar, B. Peng, M. Leonetti, J. Sinapov, M. E. Taylor, and P. Stone,
“Curriculum learning for reinforcement learning domains: A framework
and survey,” arXiv preprint arXiv:2003.04960, 2020.

[50] T. T. Nguyen and V. J. Reddi, “Deep reinforcement learning for cyber
security,” IEEE Transactions on Neural Networks and Learning Systems,
2019.

[51] D. Ojha and S. Dwarkadas, “TimeCache: using time to eliminate cache
side channels when sharing software,” in 2021 ACM/IEEE 48th Annual
International Symposium on Computer Architecture (ISCA).
IEEE, 2021,
pp. 375–387.

[52] O. Oleksenko, C. Fetzer, B. K¨opf, and M. Silberstein, “Revizor: testing
black-box cpus against speculation contracts,” in Proceedings of the 27th
ACM International Conference on Architectural Support for Programming
Languages and Operating Systems, 2022, pp. 226–239.

[53] D. A. Osvik, A. Shamir, and E. Tromer, “Cache attacks and countermea-
sures: the case of AES,” in Cryptographers’ track at the RSA conference.
Springer, 2006, pp. 1–20.

[54] Z. Pan and P. Mishra, “Automated test generation for hardware trojan
New York, NY, USA:

detection using reinforcement
Association for Computing Machinery, 2021.

learning.”

[55] Z. Pan, J. Sheldon, and P. Mishra, “Test generation using reinforcement
learning for delay-based side-channel analysis,” in 2020 IEEE/ACM
International Conference On Computer Aided Design (ICCAD).
IEEE,
2020, pp. 1–7.

[56] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison,
A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy,
J. Bai, and S. Chintala, “PyTorch: An
B. Steiner, L. Fang,
in
imperative
Advances in Neural Information Processing Systems 32, H. Wallach,
H. Larochelle, A. Beygelzimer, F. d'Alch´e-Buc, E. Fox, and R. Garnett,
Eds.
[Online].
Available: http://papers.neurips.cc/paper/9015-pytorch-an-imperative-
style-high-performance-deep-learning-library.pdf

style, high-performance deep learning library,”

Inc., 2019, pp. 8024–8035.

Curran Associates,

[57] W. Perez, E. Sanchez, M. S. Reorda, A. Tonda, and J. V. Medina,
“Functional test generation for the plru replacement mechanism of
embedded cache memories,” in 2011 12th Latin American Test Workshop
(LATW).

IEEE, 2011, pp. 1–6.

[58] M. L. Puterman, “Markov decision processes: Discrete stochastic dynamic
programming,” Journal of the Operational Research Society, 1995.
[59] M. K. Qureshi, “Ceaser: Mitigating conﬂict-based cache attacks via
encrypted-address and remapping,” in 2018 51st Annual IEEE/ACM
International Symposium on Microarchitecture (MICRO).
IEEE, 2018,
pp. 775–787.

[60] M. K. Qureshi, “New attacks and defense for encrypted-address cache,”
in 2019 ACM/IEEE 46th Annual International Symposium on Computer
Architecture (ISCA).
IEEE, 2019, pp. 360–371.

[61] R. Raileanu, M. Goldstein, D. Yarats, I. Kostrikov, and R. Fergus,
“Automatic Data Augmentation for Generalization in Reinforcement
Learning,” in Advances in Neural Information Processing Systems,
M. Ranzato, A. Beygelzimer, Y. Dauphin, P. S. Liang, and J. W.
Vaughan, Eds., vol. 34. Curran Associates, Inc., 2021, pp. 5402–
5415. [Online]. Available: https://proceedings.neurips.cc/paper/2021/ﬁle/
2b38c2df6a49b97f706ec9148ce48d86-Paper.pdf

[62] K. Ramezanpour, P. Ampadu, and W. Diehl, “SCARL: side-channel
analysis with reinforcement learning on the ascon authenticated cipher,”
arXiv preprint arXiv:2006.03995, 2020.

[63] I. Rasheed, F. Hu, and L. Zhang, “Deep reinforcement learning approach
for autonomous vehicle systems for maintaining security and safety using
LSTM-GAN,” Vehicular Communications, vol. 26, p. 100266, 2020.

[64] J. Rijsdijk, L. Wu, and G. Perin, “Reinforcement learning-based design
of side-channel countermeasures,” Cryptology ePrint Archive, Report
2021/526, 2021, https://ia.cr/2021/526.

[65] G. Saileshwar, C. W. Fletcher, and M. Qureshi, “Streamline: a fast, ﬂush-
less cache covert-channel attack by enabling asynchronous collusion,” in
Proceedings of the 26th ACM International Conference on Architectural

Support for Programming Languages and Operating Systems, 2021, pp.
1077–1090.

[66] G. Saileshwar and M. Qureshi, “MIRAGE: Mitigating conﬂict-based
cache attacks with a practical fully-associative design,” in 30th USENIX
Security Symposium (USENIX Security 21), 2021, pp. 1379–1396.
[67] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, “Prox-
imal policy optimization algorithms,” arXiv preprint arXiv:1707.06347,
2017.

[68] A. Shusterman, L. Kang, Y. Haskal, Y. Meltser, P. Mittal, Y. Oren, and
Y. Yarom, “Robust website ﬁngerprinting through the cache occupancy
channel,” in 28th USENIX Security Symposium (USENIX Security 19),
2019, pp. 639–656.

[69] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den
Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot,
S. Dieleman, D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever,
T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, and D. Hassabis,
“Mastering the Game of Go with Deep Neural Networks and Tree Search,”
Nature, vol. 529, no. 7587, pp. 484–489, Jan. 2016.

[70] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang,
A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton et al., “Mastering the
game of go without human knowledge,” nature, vol. 550, no. 7676, pp.
354–359, 2017.

[71] A. J. Smith, “Cache memories,” ACM Computing Surveys (CSUR), vol. 14,

no. 3, pp. 473–530, 1982.

[72] K. So and R. N. Rechtschaffen, “Cache operations by mru change,” IEEE

Transactions on Computers, vol. 37, no. 6, pp. 700–709, 1988.

[73] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction,

2nd ed. MIT press, 2018.

[74] Q. Tan, Z. Zeng, K. Bu, and K. Ren, “PhantomCache: Obfuscating cache
conﬂicts with localized randomization.” in Networked and Distributed
System Symposium (NDSS), 2020.

[75] C. Trippel, D. Lustig, and M. Martonosi, “CheckMate: Automated
synthesis of hardware exploits and security litmus tests,” in 2018
51st Annual IEEE/ACM International Symposium on Microarchitecture
(MICRO).

IEEE, 2018, pp. 947–960.

[76] A. Uprety and D. B. Rawat, “Reinforcement learning for iot security: A
comprehensive survey,” IEEE Internet of Things Journal, vol. 8, no. 11,
pp. 8693–8706, 2020.

[77] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
L. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in
neural information processing systems, vol. 30, 2017.

[78] A. Vaswani, N. Shazeer, N. Parmar,

J. Uszkoreit, L.

Jones,
A. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention is All
you Need,” in Advances in Neural Information Processing Systems,
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett, Eds., vol. 30. Curran Associates, Inc.,
2017. [Online]. Available: https://proceedings.neurips.cc/paper/2017/ﬁle/
3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf

[79] P. Vila, P. Ganty, M. Guarnieri, and B. K¨opf, “CacheQuery: Learning
replacement policies from hardware caches,” in Proceedings of the 41st
ACM SIGPLAN Conference on Programming Language Design and
Implementation, 2020, pp. 519–532.

[80] D. Wang, Z. Qian, N. Abu-Ghazaleh, and S. V. Krishnamurthy, “Papp:
Prefetcher-aware prime and probe side-channel attack,” in Proceedings
of the 56th Annual Design Automation Conference 2019, 2019, pp. 1–6.
[81] Z. Wang and R. B. Lee, “New cache designs for thwarting software
cache-based side channel attacks,” in Proceedings of the 34th annual
international symposium on Computer architecture, 2007, pp. 494–505.
[82] D. Weber, A. Ibrahim, H. Nemati, M. Schwarz, and C. Rossow, “Osiris:
Automated discovery of microarchitectural side channels,” in 30th
USENIX Security Symposium (USENIX Security 21), 2021, pp. 1415–
1432.

[83] L. Wei, B. Luo, Y. Li, Y. Liu, and Q. Xu, “I know what you see:
Power side-channel attack on convolutional neural network accelerators,”
in Proceedings of the 34th Annual Computer Security Applications
Conference, 2018, pp. 393–406.

[84] Y. Xiao, Y. Zhang, and R. Teodorescu, “SPEECHMINER: A framework
for investigating and measuring speculative execution vulnerabilities,”
arXiv preprint arXiv:1912.00329, 2019.

[85] W. Xiong, S. Katzenbeisser, and J. Szefer, “Leaking information through
cache LRU states in commercial processors and secure caches,” IEEE
Transactions on Computers, vol. 70, no. 4, pp. 511–523, 2021.

[86] W. Xiong and J. Szefer, “Leaking information through cache LRU states,”
in 2020 IEEE International Symposium on High Performance Computer
Architecture (HPCA).
IEEE, 2020, pp. 139–152.

[87] M. Yan, B. Gopireddy, T. Shull, and J. Torrellas, “Secure hierarchy-aware
cache replacement policy (SHARP): Defending against cache-based
side channel attacks,” in 2017 ACM/IEEE 44th Annual International
Symposium on Computer Architecture (ISCA).
IEEE, 2017, pp. 347–360.
[88] M. Yan, Y. Shalabi, and J. Torrellas, “ReplayConfusion: detecting
cache-based covert channel attacks using record and replay,” in 2016
49th Annual IEEE/ACM International Symposium on Microarchitecture
(MICRO).

IEEE, 2016, pp. 1–14.

[89] M. Yan, R. Sprabery, B. Gopireddy, C. Fletcher, R. Campbell, and
J. Torrellas, “Attack directories, not caches: Side channel attacks in a
non-inclusive world,” in 2019 IEEE Symposium on Security and Privacy
(SP).

IEEE, 2019, pp. 888–904.

[90] X. Yang, B. Cui, T. Li, and Y. Tian, “RLMeta: A Flexible Framework
for Distributed Reinforcement Learning,” 1 2022. [Online]. Available:
https://github.com/facebookresearch/rlmeta

[91] F. Yao, M. Doroslovacki, and G. Venkataramani, “Are coherence protocol
states vulnerable to information leakage?” in 2018 IEEE International
Symposium on High Performance Computer Architecture (HPCA).
IEEE,
2018, pp. 168–179.

[92] Y. Yarom and K. Falkner, “FLUSH+ RELOAD: A high resolution, low
noise, l3 cache side-channel attack,” in 23rd USENIX security symposium
(USENIX security 14), 2014, pp. 719–732.

[93] Y. Yuan, Q. Pang, and S. Wang, “Automated side channel analysis
of media software with manifold learning,” in 31st USENIX Security
Symposium (USENIX Security 22). Boston, MA: USENIX Association,
Aug. 2022. [Online]. Available: https://www.usenix.org/conference/
usenixsecurity22/presentation/yuan-yuanyuan

[94] D. Zhang, Y. Wang, G. E. Suh, and A. C. Myers, “A hardware design
language for timing-sensitive information-ﬂow security,” ASPLOS ’15,
p. 503–516, 2015. [Online]. Available: https://doi.org/10.1145/2694344.
2694372

[95] T. Zhang, Y. Zhang, and R. B. Lee, “CloudRadar: A real-time side-
channel attack detection system in clouds,” in International Symposium
on Research in Attacks, Intrusions, and Defenses. Springer, 2016, pp.
118–140.

APPENDIX

A. Stability of Training and Impact of Reward Values

In AutoCAT, the agent gets a huge positive or negative
reward when making a guess depending on the correctness,
while getting constant reward otherwise. This is a type of
sparse reward. Reinforcement Learning algorithms can wander
aimlessly or stuck at local optima when dealing with sparse
reward [23], [73]. The learning speed and accuracy of RL also
have some correlation to reward values, especially for simple
MLP models. Reward values using domain knowledge can
improve the performance of an RL agent. As our goal is to
train an agent that can guess the secret (addrsecret) correctly
with minimal number of steps, we chose a positive value
for correct_reward, negative values for wrong_reward
and step_reward.

We evaluated the impact of reward values on the performance
of the RL agent by changing the reward values using the default
three-layer MLP model. When the agent reaches 95% accuracy,
we consider an attack pattern is found. We chose three metrics
to evaluate the agent: 1) the number of time steps in 103 until
convergence, 2) clock time in hours until convergence, and 3)
episode lengths when the attack is found, i.e., the length of
the attack. For each metric, the results of average (minimum,
maximum) values are presented to show the variation between
the training trials in Tables XI, Table XII, and Table XIII. As a
baseline, we use the reward values of correct_reward =

200, wrong_reward = -10,000, and step_reward = -10.
We evaluated an 8-way cache set. The victim either accesses
cache line 0 or makes no access. The attacker address range is
1 to 8. Each conﬁguration has been tested for 3 random seeds.
Scale of rewards. In Table XI, we keep the ratio of the reward
values but change the scale of the rewards. The result suggests
that the learning performance is relatively stable even though
the absolute values of the rewards do impact the performance.
This is because we use Adam optimizer in which the step
formula is invariant to diagonal rescaling of the gradients [32].
Wrong-guess reward. We test how training is affected by the
wrong-guess reward values. As shown in Table XII, the agent
converges slightly faster than the baseline when the penalty
is larger. There is no signiﬁcant difference in episode length.
When correct_reward = 200 and wrong_reward is -
1,000, the agent sometimes fails to ﬁnd an attack and converges
to a random guess.
Step reward. In Table XIII, we show the results when the step
reward changes. Learning speed is improved by decreasing the
step from -50 to 0. This is because the step penalty discourages
the RL agent from exploring longer attack patterns which could
lead to a successful attack. However, a larger step penalty
results in a shorter attack pattern.

We also found that the Transformer model is less sensitive
to the reward value settings. For our experiments with a
Transformer model, we used the reward of correct_reward
= 1, wrong_reward = -1, and step_reward = -0.01.

B. Cache Guessing Game as Markov Decision Process

In this section, we discuss how a cache guessing game can
be formulated as a Markov Decision Process (MDP). In general,
the goal of an RL agent is to maximize the long-term rewards
by ﬁnding a policy that generates a proper action sequence
in a Markov Decision Process (MDP [58]). More speciﬁcally,
the MDP is speciﬁed by the tuple M = (S , A , P, R, γ),
where S is the state space, A the action space, P(s(cid:48)|s, a) the
probability of transitioning from state s ∈ S to state s(cid:48) ∈ S ,
and γ ∈ [0, 1) a discount factor. The state and action spaces
can be either discrete or continuous. An “agent” chooses
actions a ∈ A according to a policy function a ∼ π(s), which
updates the system state s(cid:48) ∼ P(s, a), yielding a reward
r = R(s) ∈ R. The goal of the agent is to learn an optimal policy

TABLE XI: Training with different reward scales.

Metrics

0.01x

Magnitude of reward scale
0.1x

1x

attack found?
steps (103)
time (h)
episode length 30.27 (28.60, 32.98) 26.34 (23.02, 29.54) 29.53 (14.97, 37.24)

889 (816, 1000)
4.5 (4.3, 5.0)

861 (696, 1080)
4.4 (3.6, 5.5)

681 (552, 884)
3.6 (3.0, 4.8)

TABLE XII: Training with different wrong-guess rewards.

Metrics

-1,000

Wrong guess reward
-10,000

-100,000

attack found?
steps (103)
time (h)
episode length 25.04 (22.27, 27.81) 29.53 (14.97, 37.24) 30.74 (27.40, 35.00)

1038 (1000, 1076)
5.1 (4.8, 5.4)

889 (816, 1000)
4.5 (4.3, 5.0)

852 (780, 992)
3.4 (2.3, 4.6)

TABLE XIII: Training with different step rewards.

Metrics

0

-2

Step reward
-10

-25

-50

attack
found?
steps
(103)
time
(h)
episode
length (23.00, 29.58) (16.39, 29.86) (14.97, 37.24) (19.28, 32.80) (13.16, 25.85)

889
(816, 1000)
4.5
(4.3, 5.0)
29.53

1004
(808, 1284)
4.0
(3.3, 5.3)
28.29

1977
(464, 3712)
7.7
(1.9, 13.8)
21.62

713
(672, 788)
2.2
(2.0, 2.5)
25.94

833
(648, 988)
3.8
(2.6, 5.3)
25.23

Fig. 8: MDP formulation of cache guessing game for an
example one-block cache with only two cache lines. [hit/miss]
indicates the observation during a transition.

t=0[γt R(st )]) that

(maxπ EP [∑∞
takes in states and outputs
actions to maximize the cumulative reward over some horizon.
As cache-timing attacks exploit the internal states of a cache,
the cache guessing game can be seen as an MDP that optimizes
the correct guessing rate. In our cache guessing game, the long-
term reward is deﬁned as whether the victim’s information has
been retrieved within a ﬁxed number of steps.

To show the theoretical foundation, here we consider a
toy cache example with only one cache block and two cache
lines 0 and 1. This simple cache can be represented by a
tuple M = (S , A , P) where S = {s0, s1} contains the all
cache states representing which addr (0 or 1) is in the cache,
A = {a0, a1} contains actions that access address 0/1, and P
has the transition rules, shown as the arrows in Figure 8.

We can formulate the cache guessing game based on the
the of the cache with the additional state transitions for the
victim’s accesses (av) and the attacker’s guess (ag0 or ag1). In
a typical cache timing-channel threat model, the victim holds a
secret address addrsecret which is unknown to the attacker. For
example, if the secret address is either address 0 or address 1,
then we can add an action av to A to represent an access to
the secret address. As the attacker does not know the secret
address, this action may lead to s0 or s1 depending on the
secret as shown in Figure 8. We add two actions ag0 and ag1
to A indicating that the attacker makes a guess that the secret
address is 0 or 1. We also add two additional states sc and sw
to S to represent the guess is correct or wrong. The transition
P depends on addrsecret .

A successful attack sequence that can be represented as a
path starting from s0 or s1 and ends in sc in Figure 8, whereas
a failed attack sequence ends in sw. The goal is to ﬁnd as many
successful attacks as possible. For example, assume we start

s0s1av (addrsecret=0)a1[hit]a0[hit]a1[miss]a0[miss]scsws0/1cache occupied by addr0/1a0/1Attacker accesses addr0/1sc/wguess is correct/wrongavTrigger victim accessaddrsecretSecret address of the victimag0/g1Attacker guesses addrsecretis 0/1One-block Cache FSMag0&addrsecret=0|ag1&addrsecret=1av (addrsecret=1)av (addrsecret=0)av(addrsecret=1)ag0&addrsecret=0|ag1&addrsecret=1ag0&addrsecret=1|ag1&addrsecret=0ag0&addrsecret=1|ag1&addrsecret=0Attacker accessVictim Attacker Guessingwith s0, and we want to end in sc. We can reach sc by taking
action ag0 or ag1 depending on the value of addrsecret , which
is unknown to the attacker. However, addrsecret can be inferred
by the state after av. For example, if after av it ends in s1, then
addrsecret must be 1. To infer the current state, we can do a1
and observe the hit/miss response. Thus, if addrsecret = 1, a
successful attack sequence can be: s0 → av → s1 → a1(hit) →
s1 → ag1 → sc. Similarly, if addrsecret = 0, a successful attack
sequence can be: s0 → av → s0 → a1(miss) → s1 → ag0 → sc.
This example shows that for all possible values of addrsecret
and initial states if we can enumerate all paths that lead to sc,
we can ﬁnd all possible attacks. However, this search approach
does not work in practice for the following reasons:

1) It is difﬁcult to know the exact representations of the
MDP because the detailed microarchitectural operations
are often kept as proprietary conﬁdential know how by
chip designers. Reverse engineering effort can be onerous
and only reveal limited information [3], [79].

2) The state is not fully visible to the attacker because the

state depends on other processes’ cache entries.

3) The MDP can be quite complex because of a replacement-
state [57], cache directory [89], cache prefetcher [14],
[80], etc. The composition of these FSMs multiples the
number of states and transitions, making optimization-
based methods intractable.

4) Microarchitectural operations can be pseudo-random
such as random replacement algorithms, meaning the
transitions inside the MDP are not entirely predictable.
Due to these difﬁculties, directly using a search approach
to enumerate all possible paths and ﬁnd successful attacks
is not practical. Instead, we use RL that does not need full
observation of the state space. Applying RL to the cache-timing
attack, we only need to deﬁne the rewards R and a black box
cache model.

