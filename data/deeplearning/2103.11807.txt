1
2
0
2

n
u
J

1

]

G
L
.
s
c
[

2
v
7
0
8
1
1
.
3
0
1
2
:
v
i
X
r
a

Data Cleansing for Deep Neural Networks
with Storage-eﬃcient Approximation of Inﬂuence Functions

Kenji Suzuki∗, Yoshiyuki Kobayashi, Takuya Narihira
Sony Group Corporation, Japan

Abstract

Identifying the inﬂuence of training data for data cleansing can improve the accuracy of deep
learning. An approach with stochastic gradient descent (SGD) called SGD-inﬂuence to calculate
It is necessary to
the inﬂuence scores was proposed, but, the calculation costs are expensive.
temporally store the parameters of the model during training phase for inference phase to calculate
inﬂuence sores. In close connection with the previous method, we propose a method to reduce
cache ﬁles to store the parameters in training phase for calculating inference score. We only
adopt the ﬁnal parameters in last epoch for inﬂuence functions calculation. In our experiments on
classiﬁcation, the cache size of training using MNIST dataset with our approach is 1.236 MB. On
the other hand, the previous method used cache size of 1.932 GB in last epoch. It means that cache
size has been reduced to 1/1,563. We also observed the accuracy improvement by data cleansing
with removal of negatively inﬂuential data using our approach as well as the previous method.
Moreover, our simple and general proposed method to calculate inﬂuence scores is available on our
auto ML tool without programing, Neural Network Console. The source code is also available.

1 Introduction

There is a growing interest in the fairness, accountability, and transparency of machine learning with
the outbreak of AI ethical issues. The machine learning is called black box systems because of very
complex networks with large amount of neurons. Understanding the behavior of neural networks
remains a signiﬁcant challenge. Explainable AI can be used not only for AI ethics applications, but
also for deep neural network debugging applications, and has the potential to extract the potential
of deep neural networks. Developers can analyze interpretations to debug models. Researchers have
developed some methods to open the black box, such as LIME [1] and Grad-CAM [2] to visualize
the basis of judgement in classiﬁcation. These methods help humans to understand the reason of
judgement.

1.1 Motivation

Although these methods can indicate the basis of judgement with heat map or super pixels, we would
like to improve accuracy without adding new data as next step. It is very crucial to suggest what to
do in explainable AI. Recently some methods for data cleansing calculating inﬂuence of data to deep
neural networks have been proposed [3] [4].

The inﬂuence scores can specify negative inﬂuential score to deep neural networks. These inﬂuence
methods help developers to clean a large amount of data for high-quality data without domain knowl-
edge for labeling. Especially, SGD-inﬂuence [4] using stochastic gradient descent (SGD) proposed by
Hara et al. does not require the loss function to be convex and an optimal model to be obtained.
However, the SGD-inﬂuence needs a large mount of cache ﬁles to store parameters in training phase.

∗Kenji.B.Suzuki@sony.com

1

 
 
 
 
 
 
We are motivated to calculate inﬂuence with storage-eﬃcient approximation, and to implement it on
Neural Network Console 1 that is our auto ML tool. Therefore, we study how to reduce the size of
cache with equivalent accuracy improvement.

2 Our Contributions

We propose a method of SGD-inﬂuence with cache reduction. It enables us to implement the algorithm
on Neural Network Console, our auto ML tool, that we developed. In this paper, we propose a novel
cost-eﬀective data inﬂuence algorithm for data cleansing in deep learning. Our key contributions are
summarized as follow:

1. We propose cache reduction algorithm for SGD-inﬂuence. The algorithm is based on SGD-
inﬂuence [4] proposed by Hara et al. The original work needs a large amount of HDD cache
between training phase and inference phase. We adopt only the last parameters in last epoch for
inﬂuence functions calculation.

2. We demonstrate that our proposed method can eﬀectively improve accuracy by removing the

negative inﬂuential data.

3. As a result, it enables us to calculate inﬂuence scores without large HDD cache. Therefore, we
have implemented this proposed algorithm on our auto ML tool called Neural Network Con-
sole which is available. Using this software, the inﬂuence scores are easily obtained without
programming.

3 Related Work

In this section, we provide an overview of existing inﬂuence methods. Classic technique from statis-
tics [5] has shown estimated inﬂuence analytically calculated. The inﬂuence functions for machine
learning models have not seen widespread use in spite of study in statistics. Koh and Liang [3] pro-
vided tractable approximations of inﬂuence functions which characterize the inﬂuence of each data in
terms of change loss. However, the method requires the loss function to be convex and an optimal
model, which cannot always be satisﬁed in deep learning. Hara et al. [4] provided the inﬂuential
instances by retracing the steps of the SGD without these limitations.

3.1 Baseline Method

Our approach is based on SGD-inﬂuence [4] for deep neural networks prediction as a baseline. The
SGD-inﬂuence is based on counterfactual SGD where one instance is absent. The t-step of the counter-
factual SGD with j-th instance zj absence is denoted as θ[t+1]
−j) where
St denotes the set of instance indices used in the t-th step, ηt is learning rate, θ is the parameters of
the model, z is an instance. Let g(z; θ) := ∇θl(z; θ), where l is loss function. SGD-inﬂuence refers to
the parameter diﬀerence θ[t]
−j − θ[t] as the instance zi ∈ D at step t. Linear inﬂuence estimation (LIE)
is estimated liner inﬂuence L[T ]
−j − θ[T ](cid:105) for a given query vector u[T −1] ∈ Rp and the
SGD-inﬂuence after T SGD steps.

−j (u[t]) := (cid:104)u[t], θ[T ]

i∈St\{j} g(zi; θ[t]

−j ← θ[t]

−j − ηt
|St|

(cid:80)

The SGD-inﬂuence consists of training phase and inference phase. The tuple of instance indices
|St|, learning rate ηt, and parameters θ[t] are stored in training phase. The stored information is
retraced and u[t] in each step is computed. H [t] is the Hessian of the loss on the mini-batch St.

They evaluated both trace back all training epochs and approximate version of the trace back
only last one epoch which is storage friendly, which counterfactual SGD is used in last epoch. They

1https://dl.sony.com/

2

Figure 1: Workﬂow of data cleansing. To compute inﬂuence scores, there are training phase, cache,
and inference phase. The cache stores parameters from the training phase. To improve accuracy, there
are stages of deleting negative data and retaining.

observed that the approximate version is also eﬀective for data cleansing. As a baseline method, we
study comparison of the approximate version with our approach.

4 Proposed Method

Figure 1 shows workﬂow of data cleansing. To compute inﬂuence scores, there are training phase, cache,
and inference phase. To improve accuracy, there are stages of deleting negative data and retaining.

In order to reduce the amount of the parameters from the training phase, we propose to store only
ﬁnal parameters in last epoch from training phase. It means that cache size has been reduced to 1/T ,
where T is SGD steps. The previous study of SGD-inﬂuence as a baseline stores each SGD step T in
training phase. Here we assume that the ﬁnal parameters make important rules for models. Therefore,
we store the ﬁnal parameters in last epoch and load the ﬁnal parameters to calculate inﬂuence as
shown in Algorithm 1 and 2.

This may not be exact computation, but we regard the method as an approximation because there
are little diﬀerence among parameters of each SGD step in last epoch. For example, when the number
of dataset is 50,000 and the batch size |St| is 32, there are T = 1, 563 SGD steps in the last epoch.
We use only ﬁnal step instead of the all parameters in each step. Therefore, we can reduce the cache
size to 1/1563 (1/T ). Since the number of data N is T × |St|, cache reduction is 1/T (cid:58) |St|/N . This

3

relationship indicates that it is useful for calculating large amounts of data N in large-scale calculations.
This proposal is very simple and general. In practical use of deep learning, computation cost is an

important factor. This proposed approximation is very useful for developers.

5 Evaluations

We employ Neural Network Libraries [6]which is our developed deep learning framework under CUDA
Tool kit 10.2 and cuDNN 8.0. Neural Network Libraries are available as an OSS 2. The source code
using the Neural Network Libraries in our experiment is available at Sony AI research code repository 3.
In order to evaluate the cache reduction and data cleansing performance, we conducted image clas-
siﬁcation. We used two datasets, MNIST [7] and CIFAR10 [8], to evaluate that models of deep neural
networks are eﬀectively improved by removing negative inﬂuence data. The deep neural networks
consist of 6 conventional convolution layers.

5.1 Cache Reduction

The table 1 shows cache size of the all parameters, the previous method of Hara et al., and our
proposed method for dataset of MNIST and CIFAR10. We use 50,000 and 40,000 training data for
MNIST and CIFAR10, respectively. All parameters are accumulated through epoch k = 20. In the
previous method [4] that use the parameters in the last epoch, it is necessary to use 1.932 GB and 1.545
GB in HDD cache for MNIST and CIFAR10, respectively. Our method requires cache of 1.236 MB
for MNIST and CIFAR10. We set batch size |St| = 32, so that MNIST and CIFAR10 have T = 1, 563
steps and T = 1, 250 steps, respectively. The cache reduction is 1/T , where T is the number of SGD
steps. This result indicates the cache size reductions are 1/1,563 and 1/1,250 for MNIST and CIFAR10,
respectively.

Table 1 : Cache size of the parameters in training

Methods

Cache

Cache size (GB)
MNIST CIFAR10

All parameters
Hara et al.
Ours

θ × T × k
θ × T
θ

38.64
1.932
0.001236

30.90
1.545
0.001236

5.2 Data Cleansing Performance

In order to check the performance of data cleansing, we adopted the original SGD-inﬂuence (denoted
Hara et al.) and random data removal as baselines. We set leaning rate lr = 0.05, the the number
of epoch k = 20, and batch size |St| = 32. We randomly selected 10,000 data for validation data and
used the remaining data as training dataset from the original dataset. We repeated the experiments 10
times changing diﬀerent random seeds and the split between training and validation dataset. Another
10,000 data are set for testing accuracy.

Figure 2 shows the accuracy on the test dataset after data cleansing for (a) MNIST and (b)
CIFAR10. The data cleansing involves ﬁrst determining the inﬂuence of each data and then removing
the data that would negatively aﬀect it. In other words, Figure 2 shows how the accuracy changes
as we remove the top-n negative data. Increasing accuracy accompanied by removing top-n negative
data is an evidence of data cleansing. We observed our method has the signiﬁcant performance of data

2https://nnabla.org
3https://github.com/sony/ai-research-code

4

Figure 2: The accuracies on the test dataset after data cleansing deleted data of negative inﬂuence
scores for (a) MNIST and (b) CIFAR10. Comparison of Hara et al., our proposed method, randomly
removed, and no removal.

cleansing for both MNIST and CIFAR10 datasets as well as Hara et al.. On the other hand, we do not
observe the signiﬁcant accuracy improvement by randomly removed data. In the MNIST experiment
with batch size |St| = 32, the accuracy peaked at 5,000 data removals. Since the the number of original
training data is 50,000, it shows that the peak of accuracy is 10% of the data, 5,000, removed from the
training data, 50,000. Then the standard deviation σ is 0.000837. Since we repeated the experiments
10 times changing diﬀerent random seeds, the accuracies in Fig. 2 are the mean value. The batch size
dependence experiments from |St| = 32 to 256 show data cleansing behavior at any batch sizes 4 .

6 Applications

We have implemented this proposed algorithm on Neural Network Console which is available for users.
The software runs on Windows 10 or cloud service with GPU, e.g. NVIDIA V100.
It is our auto
ML tool by GUI, which users can easily use. Users can compute deep learning without programming.
Here we provide some plugins of explainable AI on Neural Network Console. The left part in Fig. 3
shows screen shot of a part of ResNet-110 on Neural Network Console. This graphical networks help

4See Appendix for the full results.

Figure 3: The left part shows screen shot of a part of ResNet-110 on Neural Network Console. The
right part shows calculated inﬂuence score for each training data of CIFAR10 with ResNet-110. Our
proposed method is available on our auto ML tool, Neural Network Console.

5

user visually understand. The screen shot at right part in Fig. 3 shows calculated inﬂuence score for
each training data of CIFAR10 with ResNet-110.
In addition, this Neural Network Console has a
variety of explainable AI algorithms as plugins as well as this SGD-inﬂuence, which are LIME [1] and
Grad-CAM [2] to visualize the judgement basis in image classiﬁcation as well. User can easily examine
these out-of-state explainable AI with GUI on Windows 10 or cloud service.

7 Conclusion

Our simple and general method presented here, cache reduction of SGD-inﬂuence, is a step toward
cleansing data in deep neural networks. The signiﬁcant cache reduction helps developers conduct data
cleansing with less computation storage. This result enables us to implement of inﬂuence functions
calculation by SGD-inﬂuence on our auto ML tool, our Neural Network Console. We proved that our
method is an eﬀective approximate way to improve accuracy by removing negative data as well as the
previously proposed SGD-inﬂuence.

Acknowledgements

We would like to thank Associate Professor Satoshi Hara of Osaka University for fruitful advice and
discussion. We would like to thank Masato Ishii of Sony Corporation of Japan for helpful discussion,
and to thank Andrew Shin of Sony Corporation of Japan for reviewing this paper, and to thank Yukio
Oobuchi of Sony Corporation of Japan for technical support.

References

[1] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. ”why should I trust you?”: Explaining
the predictions of any classiﬁer. In Proceedings of the 22nd ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016, pages
1135–1144, 2016.

[2] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh,
and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based local-
ization. In Proceedings of the IEEE international conference on computer vision, pages 618–626,
2017.

[3] Pang Wei Koh and Percy Liang. Understanding black-box predictions via inﬂuence functions. In
Proceedings of the 34th International Conference on Machine Learning, volume 70, pages 1885–
1894, 2017.

[4] Satoshi Hara, Atsushi Nitanda, and Takanori Maehara. Data cleansing for models trained with

sgd. In Advances in Neural Information Processing Systems, pages 4215–4224, 2019.

[5] R Dennis Cook and Sanford Weisberg. Characterizations of an empirical inﬂuence function for
detecting inﬂuential cases in regression. In Technometrics, volume 22, pages 495—-508, 1980.

[6] Takuya Narihira, Javier Alonsogarcia, Fabien Cardinaux, Akio Hayakawa, Masato Ishii, Kazunori
Iwaki, Thomas Kemp, Yoshiyuki Kobayashi, Lukas Mauch, Akira Nakamura, Yukio Obuchi,
Andrew Shin, Kenji Suzuki, Stephen Tiedmann, Stefan Uhlich, Takuya Yashima, and Kazuki
Yoshiyama. Neural network libraries: A deep learning framework designed from engineers’ per-
spectives, 2021.

[7] Yann LeCun, L´eon Bottou, Yoshua Bengio, and Patrick Haﬀner. Gradient-based learning applied
to document recognition. In Proceedings of the IEEE, volume 86(11), pages 2278–2324, 1998.

6

[8] Alex Krizhevsky and Geoﬀrey Hinton. Learning multiple layers of features from tiny images. In

Technical report, Citeseer, 2009.

7

A Full Results

In this section, we provide additional experimental results to understand the eﬀect of data cleansing.

A.1 Standard Deviation

Since we repeated the experiments 10 times changing diﬀerent random seeds, the accuracies with
standard deviation σ in Fig. 4. In the both MNIST and CIFAR10 experiments with batch size |St| =
32, we observed that the accuracies have increased with error bars, which mean average ± standard
deviation σ. Compared with previous method of Hara et al., we note that our proposed method
performed similar behavior. The observation suggests that our proposed method with storage-eﬃcient
approximation of inﬂuence functions should be useful.

Figure 4: The accuracies on the test dataset after data cleansing deleted data of negative inﬂuence
scores for MNIST and CIFAR10. Comparison of our proposed method and Hara et al.. The average
accuracies on the test set after data cleansing with 10 experiments. The error bars mean average ±
standard deviation σ.

A.2 Batch Size Dependence

Figure 5 shows the full results of batch size dependence of the accuracies on the test dataset after
data cleansing that deletes data of negative inﬂuence scores. It is clear evident that accuracies have
increased after data cleansing with our proposed method for various batch sizes in MNIST and CI-
FAR10 experiments. These results of batch size dependence experiments from |St| = 32 to 256 conﬁrm
that our proposed method can eﬀectively suggest inference functions calculation for data cleansing.

8

Figure 5: Batch size dependence of the accuracies on the test dataset after data cleansing that deletes
data of negative inﬂuence scores for MNIST from (a) to (d) and CIFAR10 from (e) to (h). Comparison
of Hara et al., our proposed method, randomly removed, and no removal.

9

(e) CIFAR10 |𝑆𝑆𝑡𝑡|= 32(f) CIFAR10 |𝑆𝑆𝑡𝑡|= 64(g) CIFAR10 |𝑆𝑆𝑡𝑡|= 128(h) CIFAR10 |𝑆𝑆𝑡𝑡|= 256et al.et al.et al.et al.(b) MNIST |𝑆𝑆𝑡𝑡|= 64(c) MNIST |𝑆𝑆𝑡𝑡|= 128(d) MNIST |𝑆𝑆𝑡𝑡|= 256et al.et al.et al.(a) MNIST : |𝑆𝑆𝑡𝑡|= 32et al.