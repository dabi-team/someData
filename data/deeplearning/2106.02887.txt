An Empirical Study on Tensor Shape Faults in
Deep Learning Systems

Dangwei Wu, Beijun Shen, Yuting Chen
School of Electronic Information and Electrical Engineering
Shanghai Jiao Tong University
Shanghai, China
{wudangwei, bjshen, chenyt}@sjtu.edu.cn

1
2
0
2

n
u
J

5

]
E
S
.
s
c
[

1
v
7
8
8
2
0
.
6
0
1
2
:
v
i
X
r
a

Abstract—Software developers frequently adopt deep learning
(DL) libraries to incorporate learning solutions into software
systems. However, misuses of these libraries can cause various
DL faults. Among them,
tensor shape faults are most preva-
lent. Tensor shape faults occur when restriction conditions of
operations are not met,
leading to many system crashes. To
support efﬁcient detection and ﬁxing of these faults, we conduct
an empirical study to obtain a deep insight. We construct SFData,
a set of 146 buggy programs with crashing tensor shape faults
(i.e., those causing programs to crash). By analyzing the faults in
SFData, we categorize them into four types and get some valuable
observations.

Index Terms—Tensor shape fault, crash, deep learning systems

I. INTRODUCTION

Deep learning (DL) provides efﬁcient solutions for a number
of problems that were difﬁcult to solve with traditional com-
puting techniques; e.g., automatic driving, speech recognition
and machine translation. They are widely supported by DL
libraries, such as TensorFlow [1], Keras [2], Torch [3], Cafe [4]
and Theano [5];
these libraries facilitate programmers to
develop, train, and run models efﬁciently. While DL libraries
make it easy to incorporate DL into software systems, engi-
neers still fail in using them correctly because of their unique
semantic and data requirements [6].

Tensor shape faults are the main type of DL faults; they
can occur in all stages of a DL pipeline [7]. DL programs
build models on the basis of computational graphs: each node
in a computational graph represents an operation (OP), and a
tensor (i.e., an input or output of an operation) corresponds to
an edge of the graph. Each tensor has its shape properties, such
as the number of dimensions and the size of each dimension.
When tensors ﬂow and change in computational graphs, their
shapes also ﬂow and change. An OP manipulates tensors and
usually restricts their shapes. When a restriction condition of
OPs is not met, a tensor shape fault is produced, which usually
leads to a program crash. For example, a misuse of a DL API
in a two-dimensional tensor multiplication may cause a tensor
shape fault, because the multiplication requires the size of the
second dimension of the ﬁrst matrix to be equal to the size of
the ﬁrst dimension of the second matrix. Fig. 2 shows a more
complex example (§3).

A recent study reveals that tensor shape faults are frequent,
covering 45% of failures in TensorFlow programs [8]. The

high prevalence of tensor shape faults and their serious con-
sequences inspires research on shape faults. Previous efforts
focus on detecting tensor shape faults. One solution to this
is static shape fault detection, which analyzes the source
code of DL programs against detection rules. Ariadne [9]
tracks and analyzes tensor usages, checking whether each
tensor is provided with the desired shape. Pythia [10] extends
Ariadne, which translates Python programs into intermediate
representations and designs rules to detect shape faults w.r.t.
TensorFlow’s OPs. All the static techniques require detection
rules to be well prepared. Another mainstream is dynamic
shape fault detection, which analyzes the programs’ execution
information and detects tensor shape faults. The only previous
work is ShapeFlow [8], an abstract interpreter for TensorFlow
programs. It rewrites TensorFlow’s APIs and runs programs,
extracting the tensor shapes and then constructing shape com-
putational graphs for tracking shape changes. Up to now, there
exist few researches on automatically repairing these faults.

To detect and repair tensor shape faults efﬁciently, a dataset
of shape faults should be constructed from real projects, and
analyzed to obtain insights into tensor shape faults. Zhang
et al. [11] build a dataset of buggy TensorFlow programs
in their empirical study, while the dataset contains only 14
tensor shape faults collected from StackOverﬂow and 9 ones
from Github. Islam et al. construct a dataset from Stack-
Overﬂow [7], containing 32 and 37 tensor shape faults in
TensorFlow and Keras programs, respectively. Meanwhile,
Islam’s dataset does not contain buggy programs and their
patches, since it is not designed for program analysis and bug
repair.

In this paper, we empirically study crashing tensor shape
faults in StackOverﬂow. We build SFData, a dataset of crash-
ing tensor shape faults that contains 146 buggy programs
and their crash messages, patches and test data. By analyzing
these data, we reveal four types of faults, helping researchers
understand these faults and as well engineers detect and repair
them. We have released our whole data suite of SFData and
detailed study results on Github 1.

The rest of the paper is organized as follows. Section II
provides a background and related work of tensor shape faults.
Section III gives a motivating example. Section IV describes

1https://github.com/tensfa/tensfa

 
 
 
 
 
 
B. Related Work

There has been a number of researches [7], [11]–[14] on
studying DL faults from open source repositories. Humbatova
et al. [13] introduce a taxonomy of faults in DL systems. Li
et al. [14] ﬁnd that many TensorFlow bugs are in its interfaces.
Zhang et al. [11] collect data from GitHub and StackOverﬂow
to study faults in TensorFlow programs, examining root causes
and symptoms of the faults as well as methods used for detect-
ing and locating faults. Their dataset contains 23 TensorFlow
programs with shape faults. Islam et al. [7] examine programs
related to ﬁve popular deep learning libraries to understand
types of errors, root causes, impacts, and anti-patterns. They
further study fault repairs on GitHub and StackOverﬂow and
summarize the repair patterns and challenges [12]. Islam’s
dataset contains 69 TensorFlow/Keras programs with shape
faults.

Compared with the above studies, our empirical study and
dataset focus on crashing tensor shape faults, while previ-
ous approaches are targeting general DL faults. Furthermore,
SFData contains the shape faults and their buggy programs,
patches and tests, which are critical to reproduce and repair
faults. Besides, SFData is larger than existing datasets.

III. A MOTIVATING EXAMPLE

We next

illustrate tensor shape faults in DL programs
using an example. Fig. 2(a) shows a buggy program collected
from StackOverﬂow #55237206. The BiClassifier program
implements a linear binary classiﬁer. In its code, the operator
at line 26 triggers a crash, and the lines in green (lines 22∼24)
stand for a repair patch.

The program’s computational graph is shown in Fig. 2(b).
the program runs normally.
During its construction stage,
However, during its execution stage, the fault occurs, resulting
in a program crash. When the data is loading into the graph and
the forward computation is performed, the program triggers a
crash “ValueError: Cannot feed value of shape (100,
100, 3) for Tensor Placeholder:0, which has shape
(1, 100, 100, 3)” at line 26. The message indicates that
there exists an incompatibility between the shapes (100, 100,
3) and (1, 100, 100, 3). The root cause is that the feature
data and the label data lack their batch size dimensions.

IV. DATASET

We construct a set of buggy programs with crashing tensor
shape faults, SFData, by taking the following steps: collecting
shape-fault-related posts in StackOverﬂow, analyzing these
faults and further associating them with other supplementary
information (e.g., crash messages, source code, patches and
test data).

A. Data collection

On StackOverﬂow, we search for posts using key-
words “[tensorflow] or [keras] ValueError shape
answers:1..”, where

• TensorFlow and Keras programs are chosen because
they are two popular, and as well closely-related deep

Fig. 1. Relationship between tensor shape faults and crashing faults. Here (cid:172),
(cid:173), and (cid:174) represent non-crashing tensor shape faults, crashing tensor shape
faults, and the other crashing faults, respectively. In our study, we mainly
focus on crashing tensor shape faults.

the construction process of SFData. Section V presents the
results of data analysis on SFData, and Section VI concludes.

II. BACKGROUND

A. Preliminaries

First deﬁnes the notions used in this paper.
Deﬁnition 1: (Operation). An operation OP is a function
that accepts a set of parameters, each of which can either be an
input tensor or a variable value, and produces a set of output
tensors and may as well updates the parameters’ values:

(ot0, ot1, . . . , otm | ov0, ov1, . . . , ovn)

= OP (it0, it1, . . . , itp | iv0, iv1, . . . , ivq),

where ot0≤i≤m and it0≤i≤n are an output tensor and an input
one, respectively; ov0≤i≤p and iv0≤i≤q is a left value and a
right value of the operation.

Deﬁnition 2: (Shape Restriction). Let t be a tensor and
shape(t) be the dimensionality of t. A shape restriction is
a set of conditions a tensor’s shape needs to meet:

restrict(t) = {cond1, cond2, . . . , condn};

OP ’s shape restriction is a set of the restrictions on all of its
tensors, i.e.,

restrict(OP ) = (∪0≤k≤mrestrict(otk))

∪ (∪0≤k≤prestrict(itk)).

Deﬁnition 3: (Tensor Shape Fault). A tensor shape fault in

a DL program is a violation of shape restrictions, i.e.,

tsf (OP ) =⇒ (∃t ∈ {it0, . . . , itp, ot0, . . . , otm},

∃cond ∈ restrict(t)| • cond(shape(t)) = f alse).

As Fig. 1 shows, a tensor shape fault may or may not cause
a crash. On the other hand, a crash may or may not be raised
by a tensor shape fault. Correspondingly, we deﬁne crashing
tensor shape fault as follows.

Deﬁnition 4: (Crashing Tensor Shape Fault). A crashing
fault is a fault that can cause a program to crash. A crashing
tensor shape fault is a tensor shape fault that can cause a DL
program to crash.

2

FaultsCrashing FaultsTensor Shape Faults①②③1 import tensorflow as tf
2 import numpy as np
3 train_n = 10
4 X_training = np.array(np.random.random(

(train_n, 100, 100, 3)), dtype=np.float32) #
5 Y_training = np.eye(2)[np.random.randint(0, 2, train_n,

dtype=np.int32)] #

6 input = 100*100*3
7 X = tf.placeholder(tf.float32, [1, 100, 100, 3]) #
8 W = tf.Variable(tf.zeros([input, 2])) #
9 b = tf.Variable(tf.zeros([2])) #
10 init = tf.global_variables_initializer()
11 Y = tf.nn.softmax(tf.matmul(tf.reshape(X, [-1, input]),

W) + b) #

12 Y_ = tf.placeholder(tf.float32, [None, 2]) #
13 cross_entropy = -tf.reduce_sum(Y_ * tf.log(Y)) #
14 is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1)) #
15 accuracy = tf.reduce_mean(tf.cast(

is_correct, tf.float32)) #

16 optimizer = tf.train.GradientDescentOptimizer(0.003)
17 train_step = optimizer.minimize(cross_entropy)
18 sess = tf.Session()
19 sess.run(init)
20 for i in range(len(X_training)):

batch_X, batch_Y = X_training[i], Y_training[i] #
# Patch1
batch_x = np.expand_dims(batch_X, 0) # fix the code

batch_Y = np.expand_dims(batch_Y, 0) # fix the code

using an FDS pattern

using an LDS pattern

train_data={X: batch_X, Y_: batch_Y}
sess.run(train_step,feed_dict=train_data) #
a,c = sess.run([accuracy, cross_entropy],

feed_dict=train_data) #

21
22 +
23 +

24 +

25

26

27

(a) A buggy program BiClassifier and a patch to the program. Here we call
the patched program BiClassifier’.

TABLE I
STATISTICS OF ISLAMDATA AND SFDATA.

IslamData

SFData

# of Programs (# for repair) # of Programs (# for repair)
TensorFlow
Crashing Tensor Shape Faults (positive samples)

TensoFlow

Keras

Keras

3(0)
5(0)
24(0)
5(0)
37(0)

19(0)
4(0)
4(0)
5(0)
32(0)
Other Crashing Faults (negative samples)
63(0)
95(0)

26(26)
6(6)
15(15)
16(16)
63(63)

86(0)
149(63)

43(0)
80(0)

6(6)
16(16)
42(42)
31(31)
95(95)

98(0)
193(95)

Fault Type

PRI
ALI
FII
LOI
Subtotal

Other
Total

for posts with at least one answer, aiming at improving
the quality of the obtained posts.

B. Data processing

We manually check the retrieved posts, comments and
answers to determine whether the corresponding programs
contain shape faults and eliminate the duplicate ones. Four
strategies are then taken for processing data, allowing a high-
quality dataset to be constructed.

the buggy program,

S1: Extracting information from posts. For each post, we
extract
the patch
and the tests if they are available; we also extract the post
descriptions, comments, and answers.

the crash message,

S2: Reusing code in Github. We search for open source
projects on Github to retrieve the code, bug reports, patches,
and/or test data if a fault is incompletely described (e.g., the
patch is missing).

S3: Generating random tests. For the programs without
tests, we generate random tests as their inputs; the random
strategy is frequently used in answering issues on StackOver-
ﬂow, such as the post #58277932.

S4: Producing crash messages. For each buggy program,
we run it and its patch against the tests, obtaining the crash
message and validating the patch.

All of the posts, buggy programs, faults, and patches are
carefully checked. In this study, we check the data manually,
but discuss and conﬁrm the results by taking a rigorous
code/fault inspection process.

C. A summary of the SFData dataset

As Table I shows, SFData consists of 146 buggy programs
with crashing tensor shape faults. Among them, 59 are Ten-
sorFlow programs and 87 are Keras ones. Each record has the
attributes: [ProgramID, crash message, {fault type},
postID in StackOverflow, original code, patch, {test
data}]; for each tensor shape fault, its program, tests and
patch are provided such that the fault can be reproduced.

Note that the average number of faults in each program is
1.08 (158/146), because a buggy program can contain one or
more shape faults. Besides, we provide other crashing faults
as negative samples; they are collected from StackOverﬂow
and Zhang’s empirical study [11].

(b) Computational graph of the BiClassifier program.

Fig. 2. An example in SFData. This example is collected from StackOverﬂow
#55237206.

learning libraries. They are open-sourced at GitHub,
where TensorFlow is of 154K stars and 84.3K forks, and
Keras is of 50.9K stars and 18.7K forks, as of Apr. 2021;
• the keyword ValueError indicates that posts related with
ValueError are acquired, since an empirical study reveals
that 71.43% of tensor shape faults in TensorFlow and
Keras programs are reported as value errors [7];

• and the keyword answers:1.. indicates that we search

3

op: reshapetensor:shape: (1, 100*100*3)op: zerostensor: shape: (100*100*3, 2)op: zerostensor: shape: (2)op: Variabletensor: Wshape: (100*100*3, 2)op: Variabletensor: bshape: (2)op: placeholdertensor: xshape: (1, 100, 100, 3)op: matmultensor:shape: (1, 2)op: +tensor:shape: (1, 2)op: softmaxtensor: Yshape: (1, 2)op: placeholdertensor: Y_shape: (None, 2)op: *tensor:shape: (None, 2)op: reduce_sumtensor:shape: (1)op: -tensor: cross_entropyshape: (1)op: argmaxtensor: shape: (1)op: argmaxtensor: shape: (None)op: equaltensor: is_correctshape: (None)op: casttensor:shape: (None)op: reduce_meantensor: accuracyshape: (1)TABLE II
FAULT TYPES OF CRASHING TENSOR SHAPE FAULTS IN DL PROGRAMS.

PRI

ALI

Construction

Type

Stage*

Description
Parameter Restriction Incompatible: OP parameter
shapes and OP restrictions are not compatible.
Adjacent Layer Incompatible: Shapes of adjacent
layers are not compatible.
Feature Input Incompatible: Feature data shapes
and the model input shapes are not compatible.
Label Output Incompatible: Label data shapes
and the model output shapes are not compatible.
* “Stage” refers to a stage of constructing or executing a computational

Execution

LOI

FII

graph.

SFData vs. IslamData. IslamData is a dataset whose buggy
programs with tensor shape faults are extracted from Islam
et al.’s empirical study [7]. It can be used to measure the
fault detection techniques. Comparatively, SFData contains the
source code of buggy programs, crash messages, (expected)
patches and tests; it is also designed for measuring fault repair
techniques, letting the patches be the ground truths of the
repair techniques.

V. ANALYSIS AND RESULTS

A. Shape Fault Analysis

After an analysis of the SFData dataset, we categorize all
of the crashing tensor shape faults into four types, as Table
II shows. Let a computational graph be constructed for deep
learning. A shape fault may occur during either its construction
or its execution stage.

• The construction-stage faults can be divided into PRI and
ALI. A PRI fault occurs when the shapes of parameters
of a general OP violate the shape restrictions (e.g.,
StackOverﬂow #54452974). An ALI fault occurs when
the output shape of the previous layer is incompatible
with the input shape of the next layer (e.g., StackOverﬂow
#47842931).

• The execution-stage faults can be divided into FII and
LOI. An FII fault refers to an incompatibility between a
feature data shape and an input tensor’s shape. An LOI
fault refers to an incompatibility between a label data
shape and an output tensor’s shape (e.g., StackOverﬂow
#42821125).

Statistically, the execution-stage faults account for 65.82%
of crashing tensor shape faults. The construction-stage faults
account for 23.16% and 50.79% of crashing tensor shape faults
in Keras and TensorFlow programs, respectively. One main
reason for this is that Keras’s APIs are well encapsulated and
easy to use, reducing tensor shape faults during the graphs’
construction stage.

Finding 1: Shape faults may occur during the construction
and the execution of computational graphs, while the
execution-stage faults are more than the construction-
stage ones. The better a DL library encapsulates its APIs,

the less possible its programs suffer from tensor shape
faults during the construction stage.

B. Analysis of Fault Detection Capability

We conduct further analysis on SFData by employing ex-
isting fault detection techniques. We observe that Ariadne [9],
Pythia [10] and ShapeFlow [8] require a set of well-designed
checking rules for detecting tensor shape faults. However,
there are 3016 OPs in TensorFlow and 535 OPs in Keras, and
each OP may have trivial restrictions on parameters. Corre-
spondingly, all of these approaches are less effective, as they
deﬁne only a small number of restriction rules; restrictions
may also change over time, as the DL libraries can update
frequently. Furthermore, the rule-based approaches are facing
the overﬁtting problem, leading to a low recall in shape fault
detection.

Notably, although restrictions are diverse, the crash mes-
sages raised by tensor shape faults are similar to each other.
For example, 91.78% of crashing tensor shape faults produce
shape-related crash messages (i.e., messages containing the
word “shape”). Meanwhile, only 11.80% of other crashing
faults can produce such messages. It is promising to leverage
ML techniques to learn from crash messages for distinguishing
tensor shape faults from other crashing faults.

Finding 2: Rule-based approaches suffer from the over-
ﬁtting problem, making their detection capabilities be
constrained by the sufﬁciency of the rules; existing tech-
niques also face challenges in adapting to the evolution
of DL libraries. Correspondingly, detection techniques
may beneﬁt from machine learning methods in classifying
tensor shape faults and exploring fault detecting rules.

VI. CONCLUSION

In this paper, we conduct an empirical study on crashing
tensor shape faults. It constructs a dataset that contains 146
buggy programs and their faults, patches and test data, and
reveals four types of faults and some key observations.

In the future, we plan to extend our SFData via extracting
tensor shape faults from Github and analyzing buggy programs
on other DL libraries. We will also explore new detection and
repair techniques of tensor shape faults, using the observations
and SFData.

REFERENCES

[1] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga,
S. Moore, D. G. Murray, B. Steiner, P. A. Tucker, V. Vasudevan,
P. Warden, M. Wicke, Y. Yu, and X. Zheng, “Tensorﬂow: A system for
large-scale machine learning,” in 12th USENIX Symposium on Operating
Systems Design and Implementation, OSDI 2016, Savannah, GA, USA,
November 2-4, 2016, K. Keeton and T. Roscoe, Eds.
USENIX
Association, 2016, pp. 265–283.

[2] “Keras,” https://keras.io/.
[3] R. Collobert, S. Bengio, and J. Marithoz, “Torch: A modular machine

learning software library,” www.torch.ch, 2002.

4

[4] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. B. Girshick,
S. Guadarrama, and T. Darrell, “Caffe: Convolutional architecture for
fast feature embedding,” in Proceedings of
the ACM International
Conference on Multimedia, MM ’14, Orlando, FL, USA, November 03
- 07, 2014, K. A. Hua, Y. Rui, R. Steinmetz, A. Hanjalic, A. Natsev,
and W. Zhu, Eds. ACM, 2014, pp. 675–678.

[5] J. Bergstra, F. Bastien, O. Breuleux, P. Lamblin, R. Pascanu, O. Delal-
leau, G. Desjardins, D. Wardefarley, I. J. Goodfellow, and A. Bergeron,
“Theano: Deep learning on gpus with python,” Nips, 2011.

[6] C. Wan, S. Liu, H. Hoffmann, M. Maire, and S. Lu, “Are machine
learning cloud apis used correctly?” 43th International Conference on
Software Engineering (ICSE), 2021.

[7] M. J. Islam, G. Nguyen, R. Pan, and H. Rajan, “A comprehensive study
on deep learning bug characteristics,” Proceedings of the 2019 27th
ACM Joint Meeting on European Software Engineering Conference and
Symposium on the Foundations of Software Engineering, 2019.

[8] S. Verma and Z. Su, “Shapeﬂow: Dynamic shape interpreter for tensor-

ﬂow,” ArXiv, vol. abs/2011.13452, 2020.

[9] J. T. Dolby, A. Shinnar, A. Allain, and J. Reinen, “Ariadne: analysis for
machine learning programs,” Proceedings of the 2nd ACM SIGPLAN
International Workshop on Machine Learning and Programming Lan-

guages, 2018.

[10] S. Lagouvardos, J. T. Dolby, N. Grech, A. Antoniadis, and Y. Smarag-
dakis, “Static analysis of shape in tensorﬂow programs,” in ECOOP,
2020.

[11] Y. Zhang, Y. Chen, S. Cheung, Y. Xiong, and L. Zhang, “An empirical
study on tensorﬂow program bugs,” Proceedings of
the 27th ACM
SIGSOFT International Symposium on Software Testing and Analysis,
2018.

[12] M. J. Islam, R. Pan, G. Nguyen, and H. Rajan, “Repairing deep
neural networks: Fix patterns and challenges,” 2020 IEEE/ACM 42nd
International Conference on Software Engineering (ICSE), pp. 1135–
1146, 2020.

[13] N. Humbatova, G. Jahangirova, G. Bavota, V. Riccio, A. Stocco, and
P. Tonella, “Taxonomy of real faults in deep learning systems,” in ICSE
’20: 42nd International Conference on Software Engineering, Seoul,
South Korea, 27 June - 19 July, 2020, G. Rothermel and D. Bae, Eds.
ACM, 2020, pp. 1110–1121.

[14] L. Jia, H. Zhong, X. Wang, L. Huang, and X. Lu, “An empirical study
on bugs inside tensorﬂow,” in International Conference on Database
Systems for Advanced Applications. Springer, 2020, pp. 604–620.

5

