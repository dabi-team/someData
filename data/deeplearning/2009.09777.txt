TreeCaps: Tree-Based Capsule Networks for Source Code Processing

Nghi D. Q. Bui 1 Yijun Yu 2, Lingxiao Jiang 1
1 School of Information Systems, Singapore Management University {dqnbui,lxjiang}@smu.edu.sg
2 School of Computing & Communications, The Open University, UK, y.yu@open.ac.uk

0
2
0
2
c
e
D
4
1

]
E
S
.
s
c
[

4
v
7
7
7
9
0
.
9
0
0
2
:
v
i
X
r
a

Abstract

Recently program learning techniques have been proposed to
process source code based on syntactical structures (e.g., Ab-
stract Syntax Trees) and/or semantic information (e.g., De-
pendency Graphs). While graphs may be better at capturing
various viewpoints of code semantics than trees, constructing
graph inputs from code need static code semantic analysis
that may not be accurate and introduces noise during learn-
ing. On the other hand, syntax trees are precisely deﬁned ac-
cording to the language grammar and easier to construct and
process than graphs. We propose a new tree-based learning
technique, named TreeCaps, by fusing capsule networks with
tree-based convolutional neural networks, to achieve learning
accuracy higher than existing graph-based techniques while
it is based only on trees. TreeCaps introduces novel variable-
to-static routing algorithms into the capsule networks to com-
pensate for the loss of previous routing algorithms. Aside
from accuracy, we also ﬁnd that TreeCaps is the most ro-
bust to withstand those semantic-preserving program trans-
formations that change code syntax without modifying the
semantics. Evaluated on a large number of Java and C/C++
programs, TreeCaps models outperform prior deep learning
models of program source code, in terms of both accuracy
and robustness for program comprehension tasks such as
code functionality classiﬁcation and function name predic-
tion. The implementation of TreeCaps is publicly available at
https://github.com/bdqnghi/treecaps.

Introduction
Software developers often spend the majority of their time
in navigating existing program code bases to understand the
functionality of existing source code before implementing
new features or ﬁxing bugs (Xia et al. 2018; Evans Data
Corporation 2019; Britton et al. 2012). Learning a model
of programs has been found useful for their tasks such as
classifying the functionality of programs (Nix and Zhang
2017; Dahl et al. 2013; Pascanu et al. 2015; Rastogi, Chen,
and Jiang 2013), predicting bugs (Yang et al. 2015; Li et al.
2017, 2018; Zhou et al. 2019), translating programs (Chen,
Liu, and Song 2018; Gu et al. 2017; Bui, Jiang, and Yu 2018;
Bui, Yu, and Jiang 2019; Nghi, Yu, and Jiang 2019), etc.

It is common that adding semantic descriptions (e.g., via
code comments, visualizing code control ﬂow graphs, etc.)
may enhance human understanding of programs and ease
machine learning. With the help of static code dependency
analysis techniques (Nielson, Nielson, and Hankin 1999),
for example, Gated Graph Neural Networks (GGNN) (Li

Copyright © 2021, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

et al. 2016; Fernandes, Allamanis, and Brockschmidt 2019;
Allamanis, Brockschmidt, and Khademi 2018) learn code
semantics via graphs where edges are added between the
code syntax tree nodes to indicate various kinds of depen-
dencies between the nodes. However, adding such edges re-
quires extra processing of ASTs and may introduce noise for
different learning tasks since there is no consensus on which
types of edges are needed for which tasks.

There also exist deep learning techniques that process
code syntax trees or abstract syntax trees (ASTs) (Mou
et al. 2016; Alon et al. 2019b; Zhang et al. 2019). How-
ever, they are limited in how they represent and learn ASTs
although ASTs entail all code semantics. Tree-Based Con-
volutional Neural Network (TBCNN) (Mou et al. 2016)
shares the same computational principle as GGNN, i.e.,
information is accumulated from nearby children to par-
ent nodes only, which limits the number of iterations for
a node to accumulate information from its distant descen-
dants. Code2vec (Alon et al. 2019b) decomposes trees into
a bag of path-contexts for learning; ASTNN (Zhang et al.
2019) splits big trees for programs and functions into smaller
subtrees for individual statements. They adapt recurrent neu-
ral network models to learn the path-contexts or ﬂattened
subtrees, but still likely miss code dependency information
that is not represented in the decomposed paths and subtrees.
It is desirable to learn code models via ASTs because
trees can be more efﬁciently and precisely constructed from
code than graphs without the need of semantic analysis that
may be expensive or inaccurate. Towards this goal, this pa-
per proposes a novel architecture called TreeCaps by fus-
ing capsule networks (Sabour, Frosst, and Hinton 2017) with
TBCNN to build code models from trees, as a complement
to graph-based models. TreeCaps ﬁrst adapts TBCNN to
take in trees and extract (local) node features with its convo-
lution capability and converts the node features into capsules
in its Primary Variable Capsule (PVC) layer where the num-
ber of capsules can change for different tree inputs. It then
adapts CapsNet by introducing two methods to route the dy-
namic number of capsules in PVC to a static number of cap-
sules in its Secondary Capsule (SC) layer. Our ﬁrst method
inherits the dynamic routing algorithm (Sabour, Frosst, and
Hinton 2017) for static numbers of capsules; it shares a
global transformation matrix across every pair of capsules
between the layers (Yang et al. 2018; Zhang and Chen 2019).
Our second method is a novel Variable-to-Static (VTS) rout-
ing algorithm that selects the capsules with the most promi-
nent outputs in the PVC layer and squeezes them into a ﬁxed
set of capsules. The method utilizes the common intuition

1

 
 
 
 
 
 
that code semantics can often be determined by considering
only a portion of code elements. Further, we apply a dy-
namic routing algorithm from the capsules in the SC layer
to the ﬁnal Code Capsule (CC) layer whose number of cap-
sules is ﬁxed according to a speciﬁc learning task, to get the
vector embeddings of the trees for the task. Compared to the
max-pooling method to combine node features in TBCNN,
the pipeline of our routing methods (PVC → SC → CC) can
learn more complex combinations of AST features.

Across codebases in C/C++ and Java with respect to com-
monly compared program comprehension tasks such as code
functionality classiﬁcation and function name prediction,
our empirical evaluation shows that TreeCaps achieves bet-
ter classiﬁcation accuracy and better F1 score in predic-
tion compared to other code learning techniques such as
Code2vec, Code2seq, ASTNN, TBCNN, GGNN, GREAT
and GNN-FiLM. We have also applied three types of
semantic-preserving transformations (Rabin et al. 2020;
Zhang et al. 2020; Wang and Su 2019) that transform pro-
grams into syntactically different but semantically equiva-
lent code to attack the models. Evaluations also show that
our TreeCaps models are the most robust, able to preserve its
predictions for transformed programs more than other learn-
ing techniques.

Related Work

There has been huge interest in applying deep learning
techniques for software engineering tasks such as program
functionality classiﬁcation (Mou et al. 2016; Zhang et al.
2019), function name prediction (Fernandes, Allamanis,
and Brockschmidt 2019), bug localization (Pradel and Sen
2018; Gupta, Kanade, and Shevade 2019), code clone de-
tection (Zhang et al. 2019), program refactoring (Hu et al.
2018), program translation (Chen, Liu, and Song 2018),
and code synthesis (Brockschmidt et al. 2019). A model of
source code can often be learned in two steps: (1) convert
source code into suitable intermediate representations, and
(2) design learning networks to process the representations.
Mou et al. (2016) parse code into ASTs and design Tree-
Based Convolutional Neural Networks (TBCNNs) as the
learning networks. Allamanis, Brockschmidt, and Khademi
(2018) extend ASTs to graphs by adding a variety of code
dependencies as edges among tree nodes, intended to rep-
resent code semantics, and apply Gated Graph Neural Net-
works (GGNN) (Li et al. 2016) to learn the graphs, which
indeed enhances the performance of TBCNN (Mou et al.
2016) for certain tasks. GNN-FiLM (Brockschmidt 2019)
that explores by applying
is also a graph-based model
feature-wise linear modulation (FiLM) on Graph Neural
Network (GNN). Hellendoorn et al. (2019) proposes a hy-
brid approach to combine sequence-based models (Recur-
rent Neural Networks, Transformer) and graph-based mod-
els (GNNs) into a model called Graph Relational Embed-
ding Attention Transformer (GREAT) to address the major
drawback of GGNN that can only capture local information
of the source code. While the graph-based model extracts lo-
cal features of source code, the sequence-based model cap-
tures global features, their combination improves the perfor-
mance of GREAT over GNNs.

Code2vec (Alon et al. 2019b), Code2seq (Alon et al.
2019a), and ASTNN (Zhang et al. 2019) are designed based
on splitting ASTs into smaller ones, either as a bag of
path-contexts or as ﬂattened subtrees representing individ-
ual statements, and use various kinds of Recurrent Neural
Network (RNN) to learn such code representations. Inst2vec
(Ben-Nun, Jakobovits, and Hoeﬂer 2018) uses the RNN to
model the Intermediate Representation of the binary code
that is independent of the source programming language.

Capsule networks (CapsNet) (Sabour, Frosst, and Hinton
2017; Hinton, Sabour, and Frosst 2018) use dynamic routing
to model spatial and hierarchical relations among objects in
an image. The techniques have been successfully applied to
image processing tasks such as image classiﬁcation, char-
acter recognition, and text classiﬁcation (Jayasundara et al.
2019; Rajasegaran et al. 2019; Yang et al. 2018; Li et al.
2019). However, none of the studies has considered complex
tree data as input, which is however natural for programs.
Capsule Graph Neural Networks (Zhang and Chen 2019)
proposed to classify biological and social network graphs
does not handle tree- or graph-based code syntax. To the best
of our knowledge, we are the ﬁrst to adapt capsule networks
for program source code processing to learn code models on
syntax trees directly, without the need for extra static pro-
gram semantic analysis techniques that may be expensive or
introduce inaccuracies (Nielson, Nielson, and Hankin 1999).
Tree-based Capsule Networks
An overview of the TreeCaps architecture is shown in Fig. 1.
The steps of our technique are as follows:
• The code snippet in the training data is parsed into an AST
and vectorized. The node vectors are fed into the TBCNN
to extract node features.

• The node features will be used as the input for the Primary
Variable Capsule (PVC) layer to group the tensor outputs
of the TBCNN layers into a set of capsules. The number
of capsules in this layer is dynamic

• The capsules in the PVC layer are then routed and reduced
to a ﬁxed number of capsules in the Secondary Capsule
(SC) layer. The SC layer is to combine the capsules in the
PVC layer into a new set of capsules, in which the number
of capsules in this layer is static.

• The outputs of the SC layer are routed to the ﬁnal Code
Capsule (CC) layer where capsules can be seen as the vec-
tor representations for the input code, and can be trained
with respect to various code comprehension tasks, such as
code functionality classiﬁcation and function name pre-
diction.

Tree-based Convolutional Neural Networks
We brieﬂy introduce the Tree-based Convolutional Neural
Networks (TBCNN, (Mou et al. 2016)) for processing tree-
structured inputs used in TreeCaps.

A tree T = (V, E, X) consists of a set of nodes V , a
set of node features X, and a set of edges E. An edge in a
tree connects a node and its children. Each node in an AST
also contains its corresponding texts (or tokens) and its type
(e.g., operator types, statement types, function types, etc.)

2

Figure 1: Source codes are parsed, vectorized and fed into the TBCNN to extract node features, then the node features are
combined through the TreeCaps network.

from the underlying code. Initially, we annotate each node
v ∈ V with a D-dimensional real-valued vector xv ∈ RD
representing the features of the node. We associate every
node v with a hidden state vector hv, initialized from the fea-
ture embedding xv, which can be computed from a simple
concatenation of the embeddings of its texts and type (Alla-
manis, Brockschmidt, and Khademi 2018). The embedding
matrices for the texts and types can be learned in the whole
model training pipeline.

In TBCNN, a convolution window over an AST is em-
ulated via a binary tree, where the weight matrix for each
node is a weighted sum of three ﬁxed matrices Wt, Wl,
Wr ∈ RD×D (for the “top”, “left”, and “right” node re-
spectively) and a bias term b ∈ RD. Hence, for a convo-
lution window of depth d in the original AST containing
K = 2d − 1 nodes (including the parent node) with vec-
tors [x1, ..., xK], where xi ∈ RD, the convolutional output
y of the window is deﬁned as follows:

K
(cid:88)

y = tanh(

i=1

[ηt

iWt + ηl

iWl + ηr

i Wr]xi + b),

(1)

i , ηl

i, ηr

where ηt

i are weights calculated corresponding to
the depth and the position of the nodes. One can see this as a
way to learn the position of a node inside a tree. A TBCNN
model usually stacks m such convolutional layers together
to generate the ﬁnal node embeddings, where the output at
layer m will be used as the input for the next, i.e. the m + 1-
th layer. Each layer has its own Wt, Wl, Wr ∈ RD×D and
the bias term b ∈ RD with different initialization.

The Primary Variable Capsule Layer (PVC)

The PVC layer is to group the outputs of the convolutional
layers into the set of capsules for the routing purpose. Each
convolutional layer will output a tensor with shape |V | × D,
where |V | is the number of nodes in the AST, D is the
dimension size of the node embedding. There are m such
TBCNN layers; then the outputs of such m layers will be a
tensor with shape |V | × D × m. We set Npvc = |V | × D,
Dpvc = m so that the PVC layer will receive the input of the
shape (Npvc × Dpvc). It will go through a non-linear squash
function (Sabour, Frosst, and Hinton 2017) and get the out-
put with the same shape (Npvc ×Dpvc). Each output capsule
ui from the squash function represents the probability of ex-
istence of an entity by the vector length, formally deﬁned
as:

3

ui =

||ci||2
||ci||2 + 1

·

ci
||ci||

.

(2)

Hence,
RNpvc×Dpvc.

the output of

the PVC layer

is Xpvc ∈

The Secondary Capsule Layer (SC)

Because Npvc is dynamic as |V | is dynamic, one can not
route the output of the PVC layer directly into the ﬁnal cap-
sule layer (similar to Sabour, Frosst, and Hinton (2017). To
address this, we propose 2 methods to combine the dynamic
number of capsules in PVC into static number of capsules in
an intermediate layer, called the Secondary Capsule layer.

Sharing Weights across Child Capsules with Dynamic
Routing (DRSW) To combine the capsules in layer l into
layer l + 1, the key is to deﬁne a set of transformation
matrices. Each matrix is multiplied with each of the cap-
sule in layer l ( Sabour, Frosst, and Hinton (2017)). In this
way, the matrices will be learned as parameters through the
end-to-end learning process so the capsules in layer l will
be combined through matrices into the capsules in layer
l + 1. Since the number of capsules in the PVC is dynamic,
a global transformation matrix cannot be deﬁned in prac-
tice with variable dimensions. The solution for this prob-
lem is to deﬁned a shared transformation matrix Ws ∈
RNpvc×Dpvc×Dsc across the child capsules, where Npvc is
the number of capsules in the PVC layer (Yang et al. 2018),
Dsc is the dimension of the capsules in the SC layer, and
a dynamic algorithm routes the capsules (as summarized in
Algo.1).

In Algo.1, for each capsule i in the l-th PVC layer and
each capsule j in the l+1-th SC layer, we multiply the output
of the PVC layer ui by the shared transformation matrix Ws
to produce the prediction vectors ˆuj|i = Wsui. The “pre-
diction vectors” are responsible for predicting the strength
of each capsule in the PVC layer, then a weighted sum over
all “prediction vectors” ˆuj|i will produce the capsule j in the
SC layer. The trainable shared transformation matrix learns
the part-whole relationships between the primary capsules
and secondary capsules, while effectively transforms ui’s
into the same dimensionality as vj where each vj denotes
the capsule output of the SC layer. The coupling coefﬁcients
βij between capsule i and all the capsules in the SC layer
sum to 1 and are determined by a “routing softmax” whose
initial logits αij are the log prior probabilities that capsule i
in PVC layer should be coupled to capsule j in the SC layer.

Then we use r iterations to reﬁne βij based on the agree-
ments between the prediction vectors ˆuj|i and the secondary
capsule outputs vj where vj = squash((cid:80)
Algorithm 1 Dynamic Routing

i βij ˆuj|i).

Initialize ∀i ∈ [1, l], ∀j ∈ [1, l + 1], αij ← 0
for r iterations do

∀i ∈ [1, l], βi ← sof tmax(αi)
∀j ∈ [1, l + 1], vj ← squash((cid:80)
∀i ∈ [1, l], ∀j ∈ [1, l + 1], αij ← αij + ˆuj|i · vj

i βij ˆuj|i)

1: procedure ROUTING(ˆuj|i, r, l)
2:
3:
4:
5:
6:
7:
8:
9: end procedure

end for
return vj

Algorithm 2 Variable-to-Static Capsule Routing

Usorted ← sort([u1, ..., ub])
Initialize vj : ∀i, j ≤ a, vj ← Usorted[i]
Initialize αij : ∀j ∈ [1, a], ∀i ∈ [1, b], αij ← 0
for r iterations do

1: procedure ROUTING(ui, r, a, b)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12: end procedure

end for
return vj

∀j ∈ [1, a], ∀i ∈ [1, b], fij ← ui · vj
∀j ∈ [1, a], ∀i ∈ [1, b], αij ← αij + fij
∀i ∈ [1, b], βi ← Sof tmax(αi)
∀j ∈ [1, a], vj ← Squash((cid:80)

iβijui)

Variable-to-Static Routing (VTS) Sharing the transfor-
mation matrix reduces the ability to learn different features
because each pair of capsules is supposed to have its trans-
formation matrix. Due to this limitation, we offer the sec-
ond solution to route the variable number of capsules in the
PVC layer. It is based on an observation of source code that,
in practice, not every node of the AST contributes towards
a source code learning task. Often, source code consists of
non-essential entities, and only a portion of all entities deter-
mine the code class. Therefore, we propose a novel variable-
to-static capsule routing algorithm, summarized in Algo. 2.
The intuition of this algorithm is that we squeeze the vari-
able number of capsules in the PVC layer to a static number
of capsules by choosing only the most important capsules in
the PVC layer. The major difference between the VTS algo-
rithm and the DRSW algorithm is that the DRSW needs to
produce prediction vectors by multiplying the capsule out-
puts in PVC layer with the shared transformation matrix,
and then the prediction vectors will be combined to produce
the capsules for SC layer; whereas in the VTS, the capsule
outputs in the PVC layer are selected and the prominent ones
are used to initialize the capsules in SC layer directly.

We initialize the outputs of the SC layer with the outputs
of the a capsules with the highest L2 norms in the PVC layer.
Hence, the outputs of the PVC layer, [u1, ..., uNpvc], are ﬁrst
ordered by their L2 norms to obtain Usorted, and then the
ﬁrst a vectors of Usorted are assigned as vj, j ≤ a.

Since the probability of the existence of an entity is de-
noted by the length of the capsule output vector (L2 norm),
we only consider the entities with the highest existence prob-
abilities for initialization (in other words, highest activation)
following the aforementioned intuition. It should be noted
that the capsules with the a-highest norms are used only for
the initialization; the actual outputs of the static capsules in
the SC layer are determined by iterative runs of the variable-
to-static routing algorithm. It is the capsules with the most
prominent outputs along with the capsules of the highest
vector similarities to them that get routed to the next layer. In
this way, rare capsules, when they have prominent outputs,
are still preserved and routed to the next layer.

Next, we route all b capsules in the PVC layer based
on the similarity among them and the static capsule layer
outputs. We initialize the routing coefﬁcients as αij = 0,
equally to the b capsules in the PVC layer. Subsequently,
they are iteratively reﬁned based on the agreement between

the current SC layer outputs vj and the PVC layer outputs
ui. The agreement, in this case, is measured by the dot prod-
uct, fij ← ui · vj, and the routing coefﬁcients are adjusted
with fij accordingly. If a capsule u in the PVC layer has
a strong agreement with a capsule j in the SC layer, then
fij will be positively large; whereas if there is strong dis-
agreement, then fij will be negatively large. Subsequently,
the sum of vectors ui is weighted by the updated βij to cal-
culate sj, which is then squashed to update vj.

The Code Capsules Layer (CC)
The CC layer outputs the vector embeddings for the code
Xcc ∈ RNcc×Dcc , where Dcc is the dimensionality of each
code capsule and Ncc is ﬁxed with respect to a speciﬁc code
learning task. Note in the outputs of the SC layer Xsc ∈
RNsc×Dsc, Nsc is also ﬁxed,

The following subsections explain how we set Ncc and
train the TreeCaps models for different code learning tasks.

Code (Functionality) Classiﬁcation This task is to, given
a piece of code, classify the functionality class it belongs
to. We want Ncc capsules in the CC layer, each of which
corresponds to a functionality class of code that appeared in
the training data. As such, we let N cc = κ, where κ is the
number of functionality classes. We calculate the probabil-
ity of the existence of each class by obtaining L2 norm of
each capsule output vector. We use the margin loss (Sabour,
Frosst, and Hinton 2017) as the loss function during training.

Function (Method) Name Prediction This task is to,
given a piece of code (without its function header), predict a
meaningful name that reﬂects the functionality of the code.
For this task, following Alon et al. (2019b)’s prediction ap-
proach, we let Ncc of the CC layer be 1, and the output of
the only capsule represent the vector for the given piece of
code. In this case, the output capsules of the CC layer has
the shape of Xcc ∈ R1×Dcc , which is also the code vector
that represents for the code snippet C, denoted as vC. The
vector embeddings of the function are learn-able parameters,
formally deﬁned as f unctions vocab ∈ R|L|×Dcc , where L
is the set of function names found in the training corpus. The
embedding of f unctioni is row i of f unctions vocab. The
predicted distribution of the model q (l) is computed as the
(softmax-normalized) dot product between the context vec-
tor vC and each of the function embeddings:

f or li ∈ L : q (li) =

(cid:80)

4

exp(vT
lj ∈L exp(vT

C · f unctions vocabi)

C · f unctions vocabj )

(3)

where q (li) is the normalized dot product between the
vector of li and the code vector vC, i.e., the probability
that a function name li should be assigned to the given code
snippet C. We choose l that gives the maximum probability
for the snippet vC. For training the network, we use cross-
entropy as the loss function.

Empirical Evaluation
General Settings. We use fAST, an efﬁcient parser (Yu
2019) to parse code into ASTs in a binary format equiva-
lent to SrcML (Collard, Decker, and Maletic 2013);1 we also
use another parser PycParser2 used by TBCNN and ASTNN
for a fairer comparison and evaluate the effects of parser
choices. For the parameters in our TBCNN layer, we fol-
low Mou et al. (2016) to set the size of type embeddings to
128, the size of text embeddings to 128, and the number of
convolutional steps m to 8. For the capsule layers, we set
Nsc = 100, Dsc = 16, Dcc = 16 and routing iterations r
= 3. We use Tensorﬂow libraries to implement TreeCaps. To
train the models, we use the Rectiﬁed Adam (RAdam) opti-
mizer (Liu et al. 2019) with an initial learning rate of 0.001
subjected to decay on an Nvidia Tesla P100 GPU.

Baselines We choose a few recent code modeling tech-
niques to compare with TreeCaps: Code2vec (Alon et al.
2019b), Code2seq (Alon et al. 2019a), TBCNN (Mou et al.
2016), ASTNN (Zhang et al. 2019), GGNN (Allamanis,
Brockschmidt, and Khademi 2018), GREAT (Hellendoorn
et al. 2019). We also include a token-based baseline by treat-
ing source code as sequences of tokens and using a neu-
ral machine translation (NMT) baseline, which is a 2-layer
Bi-LSTM, to process the token sequences. A common set-
ting used among all these techniques is that they all utilize
both node type and token information to initialize a node in
ASTs. We set both the dimensionality of type embeddings
and text embeddings to 128. Note that we try our best to
make the baselines as strong as possible by choosing the
hyper-parameters above as the “optimal settings” according
to their papers or code.3

We use different baselines for the two tasks since
the models were designed for both tasks. For
not all
there is no
the graph-based models (GGNN, GREAT),
publicly available tool
to generate the needed graph
representations of code by adding semantic edges into
the ASTs as presented in (Allamanis, Brockschmidt,
and Khademi 2018), so we have implemented a tool by
ourselves to represent the code as graphs with the assis-
tance of SrcSlice and SrcML. We include as many edges
presented in (Allamanis, Brockschmidt, and Khademi
2018) as possible to ensure the graph-based baselines are

1https://www.srcml.org/, 400+ node types for multiple pro-
gramming languages. We chose SrcML because (1) it pro-
vides uniﬁed AST representations for various languages such as
C/C++/Java, and (2) it has an extension SrcSlice (https://github.
com/srcML/srcSlice) to help identify dependencies and construct
the graphs needed for GGNN, which is an evaluation baseline.
2https://github.com/eliben/pycparser/, 50+ node types for C.
3The settings for each of the baselines and parameter analyses

can be looked up in the supplementary materials.

strong. The set of edges we used are: parent child,
next token, last lexical use, last write,
return to, compute from, guarded by,
guarded by negation. We also add the backward
edges for these edge types. For Code2vec, we follow the
settings suggested in their latest Code2seq paper as well
as the implementation in the ofﬁcial software artifacts to
reproduce their results.

Setups for Code Classiﬁcation
Datasets, Metrics, and Models. We use datasets in two
different programming languages. The ﬁrst Sorting Algo-
rithms (SA) dataset is from Nghi, Yu, and Jiang (2019),
which contains 10 algorithm classes of 1000 sorting pro-
grams written in Java. The second OJ dataset is from Mou
et al. (2016), which contains 52000 C programs of 104
classes. We split each dataset into training, testing, and vali-
dation sets by the ratios of 70/20/10. We use the same classi-
ﬁcation accuracy metric as Mou et al. (2016) for comparing
classiﬁcation results.

We compare TreeCaps with other techniques that have
been applied to the code classiﬁcation task, such as
TBCNN (Mou et al. 2016), ASTNN (Zhang et al.
2019), Code2vec (Alon et al. 2019b), GGNNs (Allamanis,
Brockschmidt, and Khademi 2018; Fernandes, Allamanis,
and Brockschmidt 2019). Since TBCNN (Mou et al. 2016)
and ASTNN (Zhang et al. 2019) use PycParser to parse code
into AST, we also compare TreeCaps with all the baselines
by using both PycParser and SrcML. We also include an ab-
lation study to measure the impact of different combinations
of node initialization and representation.

Code Classiﬁcation Results. As shown in Table 1,
TreeCaps models, especially TreeCaps-VTS, have the high-
est classiﬁcation accuracy when combining node type and
node token information, for both of the SA and OJ datasets.
When only node token information is used, the simpler 2-
layer Bi-LSTM models may achieve higher accuracy. The
OJ dataset also shows that the choice of a parser affects the
performance signiﬁcantly. The models using PycParser all
achieve higher accuracy than the models using SrcML. This
is due to the reason that ASTs generated by PycPaser have
only around 50 node types, while SrcML has more than 400
node types, which makes it harder for the networks to learn.
Across the datasets, The TreeCaps-VTS performs consis-
tently the best in terms of the F1 measure among the base-
lines under different settings.

Setups for Function Name Prediction
Datasets, Metrics, and Models. We use the datasets from
Code2seq(Alon et al. 2019a) containing three sets of Java
programs: Java-Small (700k samples), Java-Med (4M sam-
ples), and Java-Large(16M samples). These datasets have
been split into training/testing/validation by projects. We
measure prediction performance using precision (P), recall
(R), and F1 scores over the sub-words in generated names,
following the metrics used by Alon et al. (2019b); Fernan-
des, Allamanis, and Brockschmidt (2019). For example, a
predicted name result compute is considered to be an

5

Table 1: Performance in Code Functionality Classiﬁcation compared. A ‘-’ means that the model is not suited to use the relevant
node representation or the parser and thus not evaluated.
SA Dataset (1000 samples)
SrcML

OJ Dataset (52000 samples)

SrcML

Type

Token

Combine

Type

Combine

Type

Token

Combine

PycParser
Token

Model
Parser
Initial Info

2-layer Bi-LSTM
Code2vec
TBCNN
ASTNN
GGNN

-
-
78.09
-
82.12
Treecaps-DRSW 83.15
84.60
Treecaps-VTS

81.83
-
71.23
-
74.25
74.56
78.15

-
80.44
82.02
84.32
83.81
84.57
85.43

-
-
92.64
-
-
94.75
95.88

83.51
-
87.97
-
-
89.42
90.21

-
86.21
95.21
98.2
-
96.74
98.32

-
-
81.15
-
85.23
83.59
83.40

83.51
-
71.15
-
72.23
77.59
79.56

-
80.15
83.90
85.32
85.89
87.77
88.40

exact match of the actual name computeResult; pre-
dicted compute has full precision but only 50% recall;
and predicted compute model result has full recall
but only 67% precision.

We use these baselines for the function name prediction
task: Code2vec, TBCNN, Code2seq, GGNN, the 2-layer Bi-
LSTM, and and GREAT (Hellendoorn et al. 2019), a hybrid
model mixing sequence-based and graph-based techniques.
The inputs for GREAT is graph representations of code, sim-
ilar to GGNN, and we have adapted this baseline into the
function name prediction task. We train each of the models
for 50 epochs for each of the three datasets. We also measure
the training time for each of the models.

Function Name Prediction Results. As shown in Ta-
ble 2, TreeCaps-VTS outperforms all other baselines for
most of the settings. TreeCaps-DRSW also performs well
but still worse than TreeCaps-VTS. Both TreeCaps-VTS
and TreeCaps-DRSW are better than the graph-based mod-
els (GGNN, GREAT) and path-based model (Code2seq,
Code2vec4) without the need for additional code depen-
dency analysis for constructing graphs. Regarding the train-
ing time, GGNN is the longest. The training time of both
TreeCaps models is comparable to GREAT, the state-of-
the-art graph-based technique to model source code, while
TreeCaps-VTS is slightly faster.

Model Analysis
To better understand the importance of different components
of our approach, we evaluate the effect of various aspects of
the TreeCaps models. This subsection provides a robustness
analysis and a comparison between DRSW algorithm and
VTS algorithm5.

Robustness of Models We measure the robustness of each
model by applying the semantically-preserving program
transformations to the Java-large’s test set for the function
name prediction task. We follow Wang and Su (2019); Rabin
et al. (2020) to transform programs in three ways that change
code syntax but preserve code functionality: (1) Variable Re-
naming (VN), a refactoring transformation that renames a

4Noted that the results for Code2vec reported Alon et al.
(2019b) is different from the Code2vec results reported in our pa-
per. This inconsistency has appeared in Code2seq, which is the
later work of the same group of the author of Code2vec and has
been explained in the rebuttal phase of Code2seq at ICLR’19 (see
https://openreview.net/forum?id=H1gKYo09tX).

5More analyses on the effect of the SC layer, effect of dimen-
sion size of capsules can be found in the supplementary materials.

variable in code, where the new name of the variable is taken
randomly from a set of variable vocabulary in the training
set; (2) Unused Statement (US), inserting an unused string
declaration to a randomly selected basic block in the code;
and (3) Permute Statement (PS), swapping two independent
statements (i.e., with no dependence) in a basic block in the
code.

The Java-large test set is thus transformed into a new test
set. We then examine if the models make the same predic-
tions for the programs after transformation as the prior pre-
dictions for the original programs. We use percentage of
predictions changed (P P C) as the metric used by (Rabin
et al. 2020; Zhang et al. 2020; Wang and Su 2019) to mea-
sure the robustness of the code models. Formally, suppose
P denotes a set of test programs, a semantic-preserving pro-
gram transformation T that transforms P into a set of trans-
formed programs P (cid:48) = {p(cid:48) = T (p)|p ∈ P }, and a source
code model M that can make predictions for any program
p: M (p) = l, where l ∈ L denotes a predicted label for p
according to a set of labels L learned by M , we compute the
percentage of predictions changed as:

P P C =

|{p(cid:48) ∈ P (cid:48)|M (p) (cid:54)= M (p(cid:48))}
|{p(cid:48) ∈ P (cid:48)}|

∗ 100

(4)

Lower P P C values for M suggest higher robustness as they
can maintain more of correct predictions with respect to the
transformation. As shown in Table 3, TreeCaps-VTS is the
most robust model against the program transformations. Al-
though more kinds of program transformations could be ap-
plied to evaluate model robustness in our future work, the
current analysis gives us the conﬁdence that TreeCaps can
be more robust against attacks via adversarial examples (Ra-
makrishnan et al. 2020; Bielik and Vechev 2020).

Comparison between the Two Routing Algorithms Fig-
ure 2 shows the comparisons between the Dynamic Routing
algorithm with Shared Weights (DRSW) and Variable-to-
Static Routing algorithm (VTS) for the code classiﬁcation
task on the OJ Dataset. There are two main observations: (1)
when DRSW is used, the loss decreases slower than when
VTS is used (in the right plot); and (2) VTS improves valida-
tion accuracy faster than DRSW (in the left chart). A reason
is that DRSW has to learn an additional shared transforma-
tion matrix Ws, resulting in slower convergence due to a
larger number of parameters to be learned.

Discussion
Choice of Node Feature Extractor For the step to ex-
tract the node features, we chose TBCNN because it was

6

Table 2: Performance of TreeCaps and the baselines for Function (Method) Name Prediction

Model
Metric

P

2-layer Bi-LSTM 40.02
40.89
23.35
50.42
40.25
47.25

TBCNN
Code2vec
Code2seq
GGNN
GREAT

java-small (700k Samples)
F1
35.46
32.24
21.36
42.56
36.86
43.56

Training Time
26.3h
20.6h
47.9h
56.3h
75.8h
55.5h

R
31.84
27.67
22.01
35.43
35.25
39.97

TreeCaps-DRSW 45.19
52.62
TreeCaps-VTS

39.49
41.36

42.89
46.78

61.5h
45.1h

P
49.73
45.23
36.43
62.56
50.14
57.15

60.19
64.38

java-med (4M Samples)
F1
44.82
43.23
31.89
53.66
45.31
51.42

R
40.12
41.41
27.93
46.83
41.25
44.12

Training Time
65.2h
58.7h
91.6h
100h
142h
110h

41.15
48.87

52.56
55.67

125h
105h

java-large (16M Samples)
F1
52.63
49.40
41.56
58.96
46.23
58.25

Training Time
150h
165h
222h
235h
280h
205h

R
49.27
40.91
38.25
54.03
44.25
55.86

52.93
56.32

57.82
61.34

153h
180h

P
56.56
58.15
44.24
63.25
50.18
61.35

59.41
66.85

Figure 2: Comparisons between the Two Routing Algorithms

Table 3: Model robustness, measured as percentage of pre-
dictions changed wrt. semantic-preserving program trans-
formations. The lower the more robust.

Model

VR

US

PS

Average

Code2vec
Code2seq
TBCNN
GGNN
GREAT

22.45% 19.42%
16.84% 21.82%
11.16% 19.36%
15.34% 18.89%
13.48% 17.75%
TreeCaps-DRSW 11.23% 15.76%
TreeCaps-VTS

22.81%
19.59%
17.39%
16.88%
15.90%
14.51%
9.53% 14.08% 13.87% 12.49%

26.56%
20.12%
21.67%
16.42%
16.51%
16.54%

designed to process ASTs that usually contain deeper and
larger numbers of nodes per code snippet than natural lan-
guage parse trees per sentence, and it has been shown to
outperform TreeLSTM in software engineering tasks such
as code classiﬁcation (Mou et al. 2016) and NLP tasks such
as natural language inference (Mou et al. 2015).

Relationship with Global Model of Source Code
GREAT (Hellendoorn et al. 2019) is a hybrid approach to
combine sequence-based and graph-based model to better
capture both local and global features of code. TreeCaps
shares the same synergy but with a different approach. The
feature extraction step is to extract local features of the
source code and the routing mechanism of the capsules is
to combine the global features of the source code. We have
shown in our evaluation that our capsule-based method per-
forms better than GREAT, both in terms of F1 score and
training time. Further research is needed to explore how dif-
ferent types of features are captured inside the capsules.

Conclusion

We propose TreeCaps, a novel neural network architecture
that incorporates tree-based convolutional neural networks
(TBCNN) into capsule networks for better learning of code

7

on abstract syntax trees. To handle dynamic numbers of
capsules produced from TBCNN, we propose two meth-
ods to route the capsules in the Primary Variable Capsule
layer to a ﬁxed number of capsules in the Secondary Cap-
sule layer. We are the ﬁrst to re-purpose capsule networks
over syntax trees to learn code without the need for explicit
semantics analysis. Our empirical evaluations have shown
that TreeCaps can outperform existing code learning models
(e.g., Code2vec, TBCNN, ASTNN, GGNN, GREAT, GNN-
FiLM) for two different program comprehension tasks (e.g.,
code functionality classiﬁcation and function name predic-
tion) on C/C++/Java programs. It is our belief that the new
method can be applied to other software engineering tasks
such as bug localization and clone detection.

A limitation of TreeCaps is similar to the original capsule
networks and many other neural networks: it still lacks ex-
plainability. Software developers may require additional ev-
idence before accepting the predication results, which sug-
gests future work that relating TreeCaps outputs to certain
visible patterns in code could help explain the predictions.

Acknowledgments
This research is supported by the Singapore Ministry of Ed-
ucation (MOE) Academic Research Fund (AcRF) Tier 1
grant and RISE Lab Operational Fund from SIS at SMU,
Singapore MOE AcRF Tier 2 Award No. MOE2019-T2-
1-193, Royal Society International Collaboration projects
(Big Code Forensic Analytics in Secure SE IES/R1/191138,
IES/R3/193175), EU H2020 EngageKTN project on Safer
Drone Flights (https://droneidentity.eu), EPSRC STRIDE
(Socio-technical resilience in software development) project
(EP/T017465/1), Huawei Trustworthy Lab, Ireland Re-
search Centre. We also thank the anonymous reviewers for
their insightful comments and suggestions, and thank the au-
thors of related work for sharing data.

References
Allamanis, M.; Brockschmidt, M.; and Khademi, M. 2018.
Learning to Represent Programs with Graphs. In Interna-
tional Conference on Learning Representations.
Alon, U.; Brody, S.; Levy, O.; and Yahav, E. 2019a.
code2seq: Generating Sequences from Structured Represen-
In International Conference on Learn-
tations of Code.
ing Representations. URL https://openreview.net/forum?id=
H1gKYo09tX.
Alon, U.; Zilberstein, M.; Levy, O.; and Yahav, E. 2019b.
Code2Vec: Learning Distributed Representations of Code.
Proc. ACM Programming Languages 3(POPL): 40:1–40:29.
Ben-Nun, T.; Jakobovits, A. S.; and Hoeﬂer, T. 2018. Neu-
ral code comprehension: A learnable representation of code
semantics. In Advances in Neural Information Processing
Systems, 3585–3597.
Bielik, P.; and Vechev, M. 2020. Adversarial Robustness for
Code. arXiv preprint arXiv:2002.04694 .
Britton, T.; Jeng, L.; Carver, G.; and Cheak, P. 2012. Quan-
tify the time and cost saved using reversible debuggers.
Technical report, Cambridge Judge Business School.
Brockschmidt, M. 2019. Gnn-ﬁlm: Graph neural net-
works with feature-wise linear modulation. arXiv preprint
arXiv:1906.12192 .
Brockschmidt, M.; Allamanis, M.; Gaunt, A. L.; and Polo-
zov, O. 2019. Generative Code Modeling with Graphs.
In 7th International Conference on Learning Representa-
tions, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.
OpenReview.net. URL https://openreview.net/forum?id=
Bke4KsA5FX.
Bui, N. D. Q.; Jiang, L.; and Yu, Y. 2018. Cross-Language
Learning for Program Classiﬁcation Using Bilateral Tree-
Based Convolutional Neural Networks. In The Workshops
of the The Thirty-Second AAAI Conference on Artiﬁcial
Intelligence, New Orleans, Louisiana, USA, February 2-7,
2018, volume WS-18 of AAAI Workshops, 758–761. AAAI
Press. URL https://aaai.org/ocs/index.php/WS/AAAIW18/
paper/view/17338.
Bui, N. D. Q.; Yu, Y.; and Jiang, L. 2019. SAR: learn-
ing cross-language API mappings with little knowledge. In
Dumas, M.; Pfahl, D.; Apel, S.; and Russo, A., eds., Pro-
ceedings of the ACM Joint Meeting on European Software
Engineering Conference and Symposium on the Founda-
tions of Software Engineering, ESEC/SIGSOFT FSE 2019,
Tallinn, Estonia, August 26-30, 2019, 796–806. ACM. doi:
10.1145/3338906.3338924. URL https://doi.org/10.1145/
3338906.3338924.
Chen, X.; Liu, C.; and Song, D. 2018. Tree-to-tree neural
In Advances in Neural
networks for program translation.
Information Processing Systems, 2547–2557.
Collard, M. L.; Decker, M. J.; and Maletic, J. I. 2013. sr-
cML: An Infrastructure for the Exploration, Analysis, and
Manipulation of Source Code: A Tool Demonstration.
In
2013 IEEE International Conference on Software Main-
tenance, Eindhoven, The Netherlands, September 22-28,

2013, 516–519. IEEE Computer Society.
doi:10.1109/
ICSM.2013.85. URL https://doi.org/10.1109/ICSM.2013.
85.

Dahl, G. E.; Stokes, J. W.; Deng, L.; and Yu, D. 2013.
Large-scale malware classiﬁcation using random projections
and neural networks. In IEEE International Conference on
Acoustics, Speech and Signal Processing, 3422–3426. IEEE.
Evans Data Corporation. 2019. Global Developer Popula-
tion and Demographic Study. http://evansdata.com/reports/
viewRelease.php?reportID=9.

Fernandes, P.; Allamanis, M.; and Brockschmidt, M. 2019.
Structured Neural Summarization. In 7th International Con-
ference on Learning Representations, ICLR 2019, New Or-
leans, LA, USA, May 6-9, 2019. OpenReview.net. URL
https://openreview.net/forum?id=H1ersoRqtm.

Jayasekara, S.;

Gu, X.; Zhang, H.; Zhang, D.; and Kim, S. 2017. DeepAM:
Migrate APIs with Multi-modal Sequence to Sequence
Learning. In International Joint Conference on Artiﬁcial In-
telligence, 3675–3681.
Gupta, R.; Kanade, A.; and Shevade, S. 2019. Neural
Attribution for Semantic Bug-Localization in Student Pro-
grams. In Advances in Neural Information Processing Sys-
tems, 11861–11871.
Hellendoorn, V. J.; Sutton, C.; Singh, R.; Maniatis, P.; and
Bieber, D. 2019. Global relational models of source code.
In International Conference on Learning Representations.
Hinton, G. E.; Sabour, S.; and Frosst, N. 2018. Matrix
capsules with EM routing. In International Conference on
Learning Representations.
Hu, X.; Li, G.; Xia, X.; Lo, D.; and Jin, Z. 2018. Deep
code comment generation. In International Conference on
Program Comprehension, 200–210. ACM.
Jayasundara, V.;
Jayasekara, H.; Ra-
jasegaran, J.; Seneviratne, S.; and Rodrigo, R. 2019.
TextCaps: Handwritten Character Recognition With Very
Small Datasets. In IEEE Winter Conference on Applications
of Computer Vision, 254–262.
Li, C.; Quan, C.; Peng, L.; Qi, Y.; Deng, Y.; and Wu, L.
2019. A capsule network for recommendation and explain-
ing what you like and dislike. In Proceedings of the 42nd
International ACM SIGIR Conference on Research and De-
velopment in Information Retrieval, 275–284.
Li, J.; He, P.; Zhu, J.; and Lyu, M. R. 2017. Software defect
In IEEE In-
prediction via convolutional neural network.
ternational Conference on Software Quality, Reliability and
Security, 318–328. IEEE.
Li, Y.; Tarlow, D.; Brockschmidt, M.; and Zemel, R. 2016.
Gated Graph Sequence Neural Networks. In International
Conference on Learning Representations.
Li, Z.; Zou, D.; Xu, S.; Ou, X.; Jin, H.; Wang, S.; Deng,
Z.; and Zhong, Y. 2018. VulDeePecker: A deep learning-
based system for vulnerability detection. arXiv preprint
arXiv:1801.01681 .

8

Liu, L.; Jiang, H.; He, P.; Chen, W.; Liu, X.; Gao, J.; and
Han, J. 2019. On the variance of the adaptive learning rate
and beyond. arXiv preprint arXiv:1908.03265 .
Mou, L.; Li, G.; Zhang, L.; Wang, T.; and Jin, Z. 2016. Con-
volutional neural networks over tree structures for program-
ming language processing. In AAAI Conference on Artiﬁcial
Intelligence.
Mou, L.; Peng, H.; Li, G.; Xu, Y.; Zhang, L.; and Jin, Z.
2015. Discriminative Neural Sentence Modeling by Tree-
In M`arquez, L.; Callison-Burch, C.;
Based Convolution.
Su, J.; Pighin, D.; and Marton, Y., eds., Proceedings of the
2015 Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2015, Lisbon, Portugal, Septem-
ber 17-21, 2015, 2315–2325. The Association for Com-
putational Linguistics. doi:10.18653/v1/d15-1279. URL
https://doi.org/10.18653/v1/d15-1279.
Nghi, B. D. Q.; Yu, Y.; and Jiang, L. 2019. Bilateral De-
pendency Neural Networks for Cross-Language Algorithm
Classiﬁcation.
In Wang, X.; Lo, D.; and Shihab, E., eds.,
26th IEEE International Conference on Software Analy-
sis, Evolution and Reengineering, SANER 2019, Hangzhou,
China, February 24-27, 2019, 422–433. IEEE.
doi:10.
1109/SANER.2019.8667995. URL https://doi.org/10.1109/
SANER.2019.8667995.
Nielson, F.; Nielson, H. R.; and Hankin, C. 1999. Principles
of Program Analysis. Berlin, Heidelberg: Springer-Verlag.
ISBN 3540654100.
Nix, R.; and Zhang, J. 2017. Classiﬁcation of Android apps
and malware using deep neural networks. In International
Joint Conference on Neural Networks, 1871–1878.
Pascanu, R.; Stokes, J. W.; Sanossian, H.; Marinescu, M.;
and Thomas, A. 2015. Malware classiﬁcation with recurrent
networks. In IEEE International Conference on Acoustics,
Speech and Signal Processing, 1916–1920. IEEE.
Pradel, M.; and Sen, K. 2018. DeepBugs: A learning ap-
proach to name-based bug detection. Proceedings of the
ACM on Programming Languages 2(OOPSLA): 147.
Rabin, M.; Islam, R.; Bui, N. D.; Yu, Y.; Jiang, L.; and
Alipour, M. A. 2020. On the Generalizability of Neural Pro-
gram Analyzers with respect to Semantic-Preserving Pro-
gram Transformations. arXiv preprint arXiv:2008.01566 .
Rajasegaran, J.; Jayasundara, V.; Jayasekara, S.; Jayasekara,
H.; Seneviratne, S.; and Rodrigo, R. 2019. DeepCaps: Going
In Computer Vision and
Deeper with Capsule Networks.
Pattern Recognition.
Ramakrishnan, G.; Henkel, J.; Wang, Z.; Albarghouthi, A.;
Jha, S.; and Reps, T. 2020. Semantic Robustness of Models
of Source Code. arXiv preprint arXiv:2002.03043 .
Rastogi, V.; Chen, Y.; and Jiang, X. 2013. Catch me if you
can: Evaluating android anti-malware against transforma-
IEEE Transactions on Information Forensics
tion attacks.
and Security 9(1): 99–108.

Sabour, S.; Frosst, N.; and Hinton, G. E. 2017. Dynamic
routing between capsules. In Conference on Neural Infor-
mation Processing Systems, 3856–3866. Long Beach, CA.
Wang, K.; and Su, Z. 2019. Learning blended, precise se-
mantic program embeddings. ArXiv, vol. abs/1907.02136 .
Xia, X.; Bao, L.; Lo, D.; Xing, Z.; Hassan, A. E.; and Li, S.
2018. Measuring Program Comprehension: A Large-Scale
Field Study with Professionals. IEEE Transactions on Soft-
ware Engineering 44(10): 951–976.
Yang, M.; Zhao, W.; Ye, J.; Lei, Z.; Zhao, Z.; and Zhang, S.
2018. Investigating Capsule Networks with Dynamic Rout-
ing for Text Classiﬁcation. In Riloff, E.; Chiang, D.; Hock-
enmaier, J.; and Tsujii, J., eds., Proceedings of the 2018
Conference on Empirical Methods in Natural Language
Processing, Brussels, Belgium, October 31 - November 4,
2018, 3110–3119. Association for Computational Linguis-
tics. doi:10.18653/v1/d18-1350. URL https://doi.org/10.
18653/v1/d18-1350.

Yang, X.; Lo, D.; Xia, X.; Zhang, Y.; and Sun, J. 2015. Deep
In IEEE In-
Learning for Just-in-Time Defect Prediction.
ternational Conference on Software Quality, Reliability and
Security, 17–26.
Yu, Y. 2019. fAST: ﬂattening abstract syntax trees for ef-
In Atlee, J. M.; Bultan, T.; and Whittle, J., eds.,
ﬁciency.
Proceedings of the 41st International Conference on Soft-
ware Engineering: Companion Proceedings, ICSE 2019,
Montreal, QC, Canada, May 25-31, 2019, 278–279. IEEE
/ ACM. doi:10.1109/ICSE-Companion.2019.00113. URL
https://doi.org/10.1109/ICSE-Companion.2019.00113.

Zhang, H.; Li, Z.; Li, G.; Ma, L.; Liu, Y.; and Jin, Z. 2020.
Generating Adversarial Examples for Holding Robustness
of Source Code Processing Models. In 34th AAAI Confer-
ence on Artiﬁcial Intelligence.
Zhang, J.; Wang, X.; Zhang, H.; Sun, H.; Wang, K.; and Liu,
X. 2019. A novel neural source code representation based
on abstract syntax tree. In International Conference on Soft-
ware Engineering, 783–794.
Zhang, X.; and Chen, L. 2019. Capsule Graph Neural Net-
work. In International Conference on Learning Representa-
tions.
Zhou, Y.; Liu, S.; Siow, J. K.; Du, X.; and Liu, Y.
2019. Devign: Effective Vulnerability Identiﬁcation by
Learning Comprehensive Program Semantics via Graph
Neural Networks.
In Wallach, H. M.; Larochelle, H.;
Beygelzimer, A.; d’Alch´e-Buc, F.; Fox, E. B.; and Garnett,
R., eds., Advances in Neural
Information Processing
Systems 32: Annual Conference on Neural Information
Processing Systems 2019, NeurIPS 2019, 8-14 De-
cember 2019, Vancouver, BC, Canada, 10197–10207.
http://papers.nips.cc/paper/9209-devign-effective-
URL
vulnerability-identiﬁcation-by-learning-comprehensive-
program-semantics-via-graph-neural-networks.

9

