1
2
0
2

r
a

M
1

]

G
L
.
s
c
[

4
v
6
7
8
1
1
.
7
0
8
1
:
v
i
X
r
a

Predicting Tactical Solutions to Operational
Planning Problems under Imperfect Information

Eric Larsen ∗

Sébastien Lachapelle †

Yoshua Bengio ‡

Emma Frejinger ∗§

Simon Lacoste-Julien ¶

Andrea Lodi ‖

March 2, 2021

Abstract

This paper oﬀers a methodological contribution at the intersection of
machine learning and operations research. Namely, we propose a method-
ology to quickly predict expected tactical descriptions of operational solu-
tions (TDOSs). The problem we address occurs in the context of two-stage
stochastic programming where the second stage is demanding computa-
tionally. We aim to predict at a high speed the expected TDOS associated
with the second stage problem, conditionally on the ﬁrst stage variables.
This may be used in support of the solution to the overall two-stage prob-
lem by avoiding the online generation of multiple second stage scenarios
and solutions. We formulate the tactical prediction problem as a stochas-
tic optimal prediction program, whose solution we approximate with su-
pervised machine learning. The training dataset consists of a large num-
ber of deterministic operational problems generated by controlled prob-
abilistic sampling. The labels are computed based on solutions to these
problems (solved independently and oﬄine), employing appropriate ag-
gregation and subselection methods to address uncertainty. Results on
our motivating application on load planning for rail transportation show
that deep learning models produce accurate predictions in very short com-
puting time (milliseconds or less). The predictive accuracy is close to the
lower bounds calculated based on sample average approximation of the
stochastic prediction programs.

Keywords: supervised learning, deep learning, integer linear programming,

stochastic programming

∗Department of Computer Science and Operations Research and CIRRELT, Université de

Montréal

†Department of Computer Science and Operations Research and Mila, Université de Mon-

tréal

‡Department of Computer Science and Operations Research and Mila, Université de Mon-

tréal, CIFAR Senior Fellow

§Corresponding author. Email: frejinger.umontreal@gmail.com
¶Department of Computer Science and Operations Research and Mila, Université de Mon-

tréal, CIFAR Fellow

‖Canada Excellence Research Chair, Polytechnique Montréal

1

 
 
 
 
 
 
1

Introduction

Operations research (OR) has been successful in developing methodologies and
algorithms to solve eﬃciently various types of decision problems that can be
formalized but are nevertheless too complex or time-consuming for humans to
process. These methodologies and algorithms are crucial to a wealth of ap-
plications. Conversely, machine learning (ML) and its subﬁeld known as deep
learning (Goodfellow et al. 2016) have had remarkable success in automating
tasks that are easy to accomplish but diﬃcult to formalize by humans, for ex-
ample, image analysis, natural language processing, voice and face recognition.
Through this undertaking, ML has developed an array of powerful classiﬁcation
and regression methods that can be used to approximate generic input-output
maps and perform conditional predictions under uncertainty. Building on those
strengths, we propose a methodology where OR and ML complement each other
and are respectively applied to the tasks they are best suited for in order to ad-
dress a conditional prediction problem that could not otherwise be solved within
the allowed time budget.

The problem we address occurs in the context of two-stage stochastic pro-
gramming where the second stage is demanding computationally. We focus on
the second stage. Namely, we aim to predict at a high speed the expected so-
lution of the second stage problem, conditionally on the ﬁrst stage variables.
This may be used in support of the solution to the overall two-stage problem
by avoiding online scenario generation. Our predictions stem from supervised
ML. They account for the stochasticity in the second stage problem and can
approximate its expected solution at a higher online speed than that which can
be achieved with alternative methods.

As a motivating application, we consider a myopic, two-stage booking con-
trol problem pertaining to cargo capacity management. The ﬁrst stage tactical
problem consists in maximizing expected proﬁt by controlling the accept/reject
decision of a booking request for the transportation of a speciﬁed number of
objects of standardized types on board available vehicles of standardized types.
At the time of booking, uncertainty may surround the exact characteristics of
the future shipment. This uncertainty is to be resolved in the second stage,
at the time of loading. At this point, given complete knowledge of the exact
characteristics of the shipment and available vehicles, an NP-hard operational
multidimensional bin packing problem must be solved.

Calculating the net proﬁt resulting from a particular loading solution does
not require the fully detailed assignment of individual objects to individual
It is suﬃcient to
positions in vehicles returned by the operational solution.
know the number of objects of each type that are loaded and the number of
vehicles of each type that are used. We call such a characterization of the
operational solution useful from the tactical standpoint a tactical description of
operational solution (TDOS). The level of detail of a TDOS is lesser than that
featured in the operational solution since its role is to support early planning
decisions rather than to set out a detailed load plan. In comparison, a strategic
description of operational solution would comprise even fewer details, such as
the value of the objective function achieved by the solution of the operational
problem. The idea of using a less detailed solution representation at the tactical
level is not new. Instead, the novelty here lies in the proposed methodology that
combines ML and discrete optimization. We note that our methodology could

2

also be applied in the context of the general sequential booking problem (Barz
and Gartner, 2016, Levina et al., 2011) to the prediction of the expected value
achieved in the operational loading problem.

The idea underlying the proposed methodology is simple and attractive:
predict the expected TDOS, conditionally on ﬁrst stage variables, using super-
vised ML, where the training data consists of a large number of deterministic
operational problems that have been solved independently and oﬄine. First,
operational problem instances under perfect information (the input) are sam-
pled from the space relevant to the application at hand and solved using an
existing deterministic optimization model and a discrete optimization solver.
Second, the detailed operational solutions are synthesized according to the cho-
sen TDOS (the output). Third, an ML approximator is trained based on the
generated input-output data while accounting for imperfect information regard-
ing certain features of the input. Fourth, this approximator is used to generate
predictions of the expected TDOS based on information available at tactical
standpoint. These predictions are expected to be delivered with high speed,
high accuracy, as well as low marginal cost in terms of data, memory and com-
puting requirements.

Some important challenges arise in this undertaking. First, the structure
of the output is tied to the chosen TDOS and can be of ﬁxed or variable size.
Second, inputs and outputs deﬁned in the chosen solution description may be
related by a number of explicit constraints that must also be satisﬁed by the
predictions. Third, missing information regarding a subset of the inputs needs
to be addressed through appropriate sampling, subselection and aggregation
methods. The designs of the ML models and algorithms depend on how these
challenges are met.

To illustrate the methodology, we specialize the two-stage booking prob-
lem to reﬂect the booking decisions made about the shipment of intermodal
containers by rail at our industrial partner. In this case, the operational bin
packing problem is the so-called load planning problem (LPP) where containers
are loaded optimally onto double-stack railcars (Mantovani et al., 2018). The
latter cannot be solved deterministically at the time of booking due to imper-
fect information about container weights. The TDOS consists in capacity usage,
that is, in the numbers of containers of each type that would be loaded and the
numbers of railcars of each type that would be used, if the booking request were
accepted.

Given installed capacity (i.e., the numbers of railcars of each type known
in advance to be available at loading time), a risk-neutral manager accepts a
booking demand if the associated expected proﬁt (transportation fees received
upfront minus expectation of the future cost of loading) is positive. The future
cost of loading is a linear function of the number of containers whose booking
had been accepted but that must be left behind (in case of insuﬃcient capacity)
and of the number of railcars actually used for loading. This cost is realized
at operational loading time, after the uncertainty in container weights has been
resolved, and can be computed for each particular realization of the weights
from the statement of the booking request and the TDOS. The expected future
cost of loading can be computed from the statement of the booking request
and the expected TDOS. In addition, the advance information embodied in the
expected TDOS can be used to plan the railcar and container layouts in the
terminal.

3

We examine speciﬁcally the problem of predicting at high speed - in real
time - with a trained ML approximator the expected TDOS pertaining to the
railway container booking problem, conditionally on a booking request and a
set of available railcars. This problem is of practical importance and features
characteristics that make it useful for illustrating the proposed methodology:
On the one hand, an integer linear programming (ILP) formulation of the oper-
ational LPP problem can be solved under full information by commercial ILP
solvers within seconds or minutes (Mantovani et al. 2018). On the other hand,
this formulation cannot be used for the application due to advance information
about container weights being usually unavailable, and to computing time being
too long to support a real-time application.

Short Literature Review and Pointers. The application of ML to discrete
optimization problems was the focus of an important research eﬀort in the 1980’s
and 1990’s (Smith, 1999). However, limited success was ultimately achieved and
this area of research was left nearly inactive from the beginning of this century. A
renewal of interest has been kindled by the successes witnessed in deep learning
and the state of the art is advancing at an increasing pace.

The most successful locus of synergies between OR and ML, which has at-
tracted a huge amount of attention in the last ten years, is the introduction of
continuous optimization methods originating in OR to algorithms used in ML,
most notably the stochastic gradient descent algorithm. The interested reader
is referred to, e.g., Curtis and Scheinberg (2017) for a tutorial.

More recent is the (mainly) exploratory bulk of work devoted to the use
of ML for discrete optimization problems. On the one hand, ML is used as a
tool for approximating complex and time-consuming tasks in OR algorithms,
arguably the most important one being branching for enumerative approaches
to NP-hard problems (see, e.g., Lodi and Zarpellon, 2017, for a survey). On the
other hand, ML is used to more directly solve (of course, heuristically) discrete
optimization problems. A number of ML methodologies can be used for this
purpose. Although we are not proposing a heuristic solution to the LPP, some
methodologies in this area are closer to our own. Those are based on supervised
learning, such as, for example, Vinyals et al. (2015) that focuses on predicting
fully detailed solutions to the famous Traveling Salesman Problem. However,
those supervised learning methodologies address deterministic problems. The
interested reader is referred to Bengio et al. (2018) for a very recent survey on
all aspects of ML for discrete optimization. Finally, there is a growing interest
for the application of ML to the solution of stochastic optimization problems.
In this area of research, we note for instance Abbasi et al. (2020), Bengio et al.
(2019), Nair et al. (2018).

Paper Contributions. The paper oﬀers four main contributions.

1. We address a problem occurring in the context of two-stage stochastic
programming where the second stage is demanding computationally. We
concentrate on the high-speed prediction of the expected solution to the
second stage problem, conditionally on the ﬁrst stage variables. Hence,
we formulate a stochastic optimal prediction problem (Section 2), whose
solution we approximate with supervised ML (Section 3). The approxima-
tions generated by ML are intended to support the solution of the overall

4

two-stage problem by avoiding the online generation of multiple second
stage scenarios and solutions.

Our proposal is robust to the caveat expressed in Wallace (2000): We
do not seek for a solution to the overall two-stage problem in the loosely
deﬁned space spanned by the individual deterministic solutions that can
be computed by collapsing the ﬁrst and second stage for every realization
of the stochastic elements in the second stage.
Instead, we show how
to approximate with ML the expected TDOS associated with the second
stage problem, conditionally on the ﬁrst stage variables. Our purpose is to
circumvent the generation of multiple second stage scenarios and solutions
that is customary in stochastic programming.

2. With respect to the current literature using ML for OR, the proposed
methodology combines discrete optimization and ML in an innovative way
by integrating an ML predictor / approximator to deal with the data
uncertainty that is inherent to the strategic and tactical planning levels.

Crucially, by omitting from the ML input data the variables that are un-
known at prediction standpoint, whereas these variables are sampled in
the dataset and used in calculating the output data used for ML, the
trained approximator resulting from ML optimizes the empirical statisti-
cal risk associated with these unknown variables. By selecting the mean
squared error as the underlying loss function, the ML approximator re-
turns approximate expected values.

Deterministic settings may be viewed as special cases. For example, Fis-
chetti and Fraccaro (2017) consider, at the strategic level, a deterministic
wind farm layout optimization problem and use ML to predict the objec-
tive values achieved by candidate sites.

3. In contrast with existing alternatives oﬀered by approximate stochastic
programming such as sample average approximation (SAA), response sur-
face, stochastic approximation, stochastic search, our methodology built
on ML anticipates calculations by generating, in advance, a prediction
function instead of pointwise solutions on demand. Hence, it does not
require to solve deterministic operational problems at prediction time.

We illustrate through an extensive computational evaluation on our real-
world application how this comparative advantage allows to build both fast
and accurate predictors. Computing time is in the order of milliseconds
whereas accuracy approaches the lower bound calculated based on SAA.

4. Our methodology relies on existing ML models and algorithms. This is
a key advantage since we can beneﬁt from the recent advances in this
ﬁeld, in our case deep learning. The methodology leads to state-of-the-art
results, i.e., solves a problem that otherwise would have been unsolvable
to that extent of accuracy in the allowed time budget, essentially online.

The remainder of the paper is structured as follows: Section 2 deﬁnes the
prediction problem under consideration and discusses existing solution methods
from the ﬁeld of stochastic programming. Section 3 delineates the proposed
methodology whereas Section 4 presents a detailed application and reports the
results. Finally, Section 5 summarizes the content of the paper, reviews out-
standing issues and describes directions for future research.

5

2 The Prediction Problem

The formal prediction problem we are addressing is as follows. Let a particular
instance of an operational (deterministic) optimization problem be represented
by the input feature vector x. Optimal operational solutions (i.e., those con-
taining values of all decision variables) are y∗(x) :≡ arg inf y∈Y(x) C(x, y), where
C(x, y) and Y(x) denote the cost function and the admissible space, respec-
tively. Ahead of the time at which the operational problem is solved, we wish
to predict certain characteristics of the optimal operational solutions, based on
currently available information. We call such a characterization a TDOS. In-
formation on a subset of the feature vector x may be unavailable or incomplete
at the time of prediction and we deﬁne the partition x = [xa, xu] accordingly,
where xa contains available features and xu unavailable or yet unobserved ones.
This partition is the same for all instances. Furthermore, we denote by g(.) the
mapping from the fully detailed operational solution to the TDOS featuring the
level of detail relevant to the context at hand. Hence, g(y) is the synthesis of
the operational solution y according to the TDOS embedded in g(.).

Our goal is to compute or at least approximate the solution ¯y∗(xa) to the
following optimal prediction stochastic programming (see, e.g., Birge and Lou-
veaux, 2011, Kall and Wallace, 1994, Shapiro et al., 2009) problem:

¯y∗(xa) :≡ arg

inf
¯y∈ ¯Y(xa)

Φxu{(cid:107)¯y − g(y∗(xa, xu))(cid:107) | xa}

y∗(xa, xu) :≡ arg

inf
y∈Y(xa,xu)

C(xa, xu, y)

(1)

(2)

where (cid:107)(cid:107) denotes a suitable norm (e.g., the L1- or L2-norm when the output has
ﬁxed size) and Φxu{(cid:107).(cid:107) | xa} denotes either the expectation or a quantile (e.g.,
the median) operation over the distribution of xu, conditional upon xa. So,
¯y∗(xa) are the optimal predictions of the synthesis of the operational optimizer
g(y∗(xa, xu)), conditionally on information available from tactical standpoint.
Finally, Y(xa, xu) is the admissible space deﬁned by the set of constraints rel-
evant to the operational context, whereas ¯Y(xa) is deﬁned only by the set of
constraints relevant to the tactical context. At ﬁrst sight, the problem might
appear as a classic two-stage stochastic program. In contrast to such an op-
timal control problem, the two stages in our optimal prediction problem are
decoupled: the solution to the deterministic problem in the second stage (oper-
ational solution) cannot be seen as a recourse to the prediction at the ﬁrst stage
(tactical solution).

In real-time or repeated applications, we need to generate solutions to (1)
and (2) at a high speed for any value of xa. Whenever closed-form solutions
are unavailable, which usually occurs, it is generally prohibitive to compute a
solution to (1) and (2) on demand for every particular value of xa encountered.
As detailed in Section 3, our methodology generates a prediction function that
can take any value of xa as input and outputs accurate predictions (cid:98)y∗(xa)
of ¯y∗(xa). The predictions are given by (cid:98)y∗(xa) ≡ f (xa; θ) where f (·; ·) is a
particular ML model and θ is a vector of parameters.

Solutions from Stochastic Programming. A number of alternative ap-
proaches and methods are available from the ﬁeld of stochastic programming

6

to address the problem deﬁned by (1) and (2). For general speciﬁcations of
C(xa, xu, y) and Y(xa, xu), that is, essentially, whenever (1) and (2) depart from
the extensively researched and documented case of linear programming, stochas-
tic programming resorts to approximate methods involving sampling. These
methods originate from two broad areas of research and perspectives: Monte
Carlo stochastic programming (e.g., de Mello and Bayraksan, 2014, Shapiro,
2003) and simulation optimization (e.g., Fu, 2015). In the former, the solution
methods may leverage available knowledge about the inner structure of (2). In
the latter, (2) is viewed as a black box and the available knowledge consists
solely in the ability to evaluate the solution y∗(xa, xu). (That is, y∗(xa, xu)
may be computable with a standard OR solver without any assumption, for
instance, about closed-form derivatives with respect to xa or xu.) An approx-
imate solution to the problem jointly deﬁned by (1) and (2) may be obtained
through one of the methods available from Monte Carlo stochastic programming
or simulation optimization for each particular value of xa.

Methods where sampling occurs once at the outset of the solution process to
convert stochastic optimization into deterministic optimization and where sam-
pling occurs throughout the optimization process are respectively said to involve
batch or external sampling and sequential or internal sampling. Methods orig-
inating from the perspective of Monte Carlo stochastic programming that are
in principle available to solve (1) and (2) include sample average approximation
(external) described, e.g., in Shapiro et al. (2009) and Kim et al. (2015) as well
as versions of stochastic approximation (internal) where a knowledge of the inner
structure of (2) is introduced (Shapiro et al., 2009, p. 230). Methods originating
from the perspective of simulation optimization that are in principle available to
solve (1) and (2) include response surface methods (internal) (Kleijnen, 2015),
stochastic search (internal) (Andradóttir, 2015, Hu, 2015, Zabinsky, 2015) and
versions of stochastic approximation (internal) where knowledge of (2) is limited
to the ability to perform evaluations (Chau and Fu, 2015).

Our attention is directed to real-time or high-repetition applications requir-
ing the computation of solutions to (1) and (2) at a high speed. Now, it is
typically considerably more time-consuming to solve (1) and (2) on demand
for a particular value of xa through one of the existing methods available from
approximate stochastic programming than it is to solve a single instance of the
deterministic problem (2). As a result, a methodology that succeeds in achiev-
ing on-demand prediction times of smaller order than the time it takes to solve
one instance of (2) is highly desirable. The methodology based on ML that we
propose satisﬁes this condition. For example, in the application presented in
Section 4, the solution of a single easiest instance of the deterministic problem
(2) with a solver requires up to a minute whereas our methodology based on
ML can yield predictions on demand within a millisecond.

3 Methodology

This section details the methodology outlined in Section 1. Sections 3.1 and 3.2
describe the generation of data and the ML approximation, respectively. Sec-
tion 3.3 addresses the treatment of missing information through aggregation
methods and the appropriate level of detail in TDOSs.

7

3.1 Data Generation Process

The data used for ML derives from operational problem instances and their
corresponding solutions. These may either result from controlled probabilistic
sampling or, under restrictive conditions, may be collected from historical ob-
servations.
In our context, controlled probabilistic sampling is advantageous
because: (i) the selected sampling distribution is deemed an accurate represen-
tation of the stochasticity in the unknown features xu of the problem instances,
(ii) it is possible to generate data at will according to a known sampling pro-
tocol and to evaluate the performance of ML training and model selection in
any arbitrarily deﬁned region in the feature space and (iii) it is possible to
generate additional data for further training if the predictive performance is
judged insuﬃcient. The sampling distributions can be estimated from histor-
In contrast, the use of a dataset consisting of historical problem
ical data.
instances is only appropriate when attempting to mimic the behavior reﬂected
in such data. Otherwise, sampling from historical data would likely introduce
uncontrollable distortions in the resulting dataset. Indeed, observed instances
result from censoring/constraining the space of admissible instances and stem
from decision processes that should be accounted for but are often unknown
in practice. In view of these limitations, we concentrate our attention on data
generation through controlled probabilistic sampling.

The ﬁrst step in the probabilistic data generation process is to sample a set
of operational problem instances {x(i), i = 1, . . . , m}. Elements of x that are
expected to vary in the intended application should be made to vary and covary
in the dataset in commensurate ranges. We can generate problem instances
through pseudo-random or quasi-random sampling. Data generation is meant
to account for the actual uncertainty about the values of the elements of the
input x. In other words, the distributions from which we sample those values
are viewed as describing this uncertainty and should be selected accordingly.
Whereas simple pseudo-random sampling and stratiﬁed pseudo-random sam-
pling are simple and easily applicable, it is also conceivable to apply alternative
protocols in order to improve sample eﬃciency. For instance, importance sam-
pling can artiﬁcially increase the abundance of data about infrequently observed
characteristics of the problem instances. We refer to, for example, Asmussen
and Glynn (2010) and Law (2014) for further details on data sampling and
simulations.

We employ an existing solver to generate the operational solutions y∗(x(i)),
i = 1, . . . , m to the problem instances. We note that the methodology does not
require optimal solutions. The selection of the particular mechanism used in
generating output labels for ML purposes depends on an assessment made by the
subject matter expert (SME) managing the decision-making problem at hand (in
our application, the SME would be an employee of the railway operator). The
SME may choose to generate solutions from a number of alternative procedures:
(i) use an exact solver and compute solutions up to a speciﬁed optimality gap (ii)
rely on a heuristic solution method, or (iii) rely on human-constructed solutions.
The SME selects the particular alternative presenting in his/her view the best
trade oﬀ between closeness to perfect accuracy (achieved by optimal solutions)
and resources invested in generating output labels for ML purposes.

In order to make eﬃcient use of the computational resources available for
ML, the operational, fully detailed optimal solutions y∗(x(i)), i = 1, . . . , m are

8

synthesized as g(y∗(x(i))), i = 1, . . . , m according to a TDOS g(.) whose level
of detail accommodates without exceeding that required in the intended appli-
cation. According to their level of detail, such descriptions vary in complexity.
They may be highly structured and may feature a variable size. The complexity
of the input vector x and the synthesized output vector g(y∗(x)), as well as
the explicit constraints that may tie their elements impact the selection and
performance of ML models and algorithms.

3.2 ML Approximation

For clarity of exposition, we ﬁnd it useful to disentangle at ﬁrst the approxi-
mation of the TDOSs with ML from the treatment of the stochasticity in some
of the inputs with ML. We therefore suppose for the moment that the input
vector available at the time of prediction is equal to the full vector of input
features, that is x = xa and xu is empty. Under this assumption, the aim of
the ML approximation is simply to ﬁnd the best possible prediction y = f (x; θ)
of g(y∗(x)), where the approximator f (·; ·) is an ML model and θ is a vector
of parameters. The model f (·; ·) and θ are selected through an ML algorithm,
based on the available input-output data made up of (x, g(y∗(x))) pairs. The
models under consideration and the algorithms used in their training and selec-
tion must conform with the structure embodied in the input and output vectors
x and g(y∗(x)), and must also uphold the constraints that may explicitly relate
their individual elements. The choice of a model and an algorithm necessarily
depends on the exact application at hand and there is in ML a range of clas-
siﬁcation and regression approximators available for these purposes. The ML
algorithm that we apply is standard and can be broadly summarized as follows:

1. The full dataset is divided at random between training, validation and

test sets.

2. Training and validation loss functions are selected.

3. Parameters of candidate models are tuned through minimization of aver-

age training loss, i.e. empirical risk, over training set.

4. Performances of trained candidate models are assessed and compared
based on average validation loss, i.e. generalization error, measured over
the validation set.

5. Additional data is generated and processed if the performance on the

validation set is unsatisfactory.

6. The model achieving the lowest generalization error over the validation

set is retained.

7. The model performance is ﬁnally evaluated based on the average validation

loss, measured over the test set.

8. Provided the selected model demonstrates suﬃcient accuracy, it is used as
a high speed, low marginal cost, on-demand predictor for the operational
solution of any problem instance.

9

Additional challenges arise when the input vector available at the time of
prediction is not equal to the full vector of input features, that is, whenever x (cid:54)=
xa. Those issues are addressed in the next section. However, the ML algorithm
above remains essentially unchanged since the treatment of the stochasticity in
xu with ML hinges on the particular deﬁnition of the input-output data pairs
that are supplied to ML.

3.3 Aggregation and Subselection

The treatment of stochasticity in xu with ML can proceed in a number of ways
using aggregation methods. All ultimately translate into a particular deﬁnition
for the input-output data pairs that are supplied to ML and all leverage the
probabilistic information embodied in the joint distribution of xu conditional
on the σ-algebra generated by xa, say σ(xa), so as to “aggregate” the probability
mass distributed over the support of xu. We shall thus say that input features
xu whose values are unavailable at the time of prediction (e.g., railcar capacities
and container weights, in our application) are to be aggregated.

The more appealing aggregation methods are those involving the replace-
ment of Φxu{(cid:107).(cid:107) | xa} in (1) with a sample version or a closed-form approxi-
mation (aggregation over outputs for short) rather than the direct substitution
of a σ(xa)-measurable predictor for xu (aggregation over inputs for short). Ag-
gregation over inputs is simple but only acceptable when the distribution of
xu has small variance. We focus on the treatment of stochasticity in xu with
aggregation over outputs through ML approximation in view of its simple appli-
cation, low computational demand and, as we show in Section 4, good empir-
ical performance. This method proceeds implicitly by supplying the dataset
{(x(i)
u )), i = 1, . . . , m} to ML. The prediction (cid:98)y∗(xa) of the
TDOS g(y∗(xa, xu)) is obtained from the trained model through (cid:98)y∗(xa) ≡
f (xa; θ), where, again, f (·; ·) is an ML model and θ is a vector of parameters.
The implementation of aggregation through ML approximation is straightfor-
ward since the required data is obtained directly from the sample of synthesized
operational solutions.

a , g(y∗(x(i)

a , x(i)

We motivate in the following how the model f (xa; θ) resulting from aggre-
gation through ML approximation can account for the stochasticity in xu. If a
uniform law of large numbers holds so that the average validation loss converges
stochastically towards the expectation of the validation loss with respect to the
distribution of the variables that are sampled in the data (e.g., Vapnik, 1999),
then we can argue that this aggregation method indeed minimizes an approx-
imation to the expected validation loss with respect to xa as well as xu.
In
other words, ML can in this case be viewed as minimizing an approximation to
the expected discrepancy between the exact TDOS g(y∗(xa, xu)) resulting from
knowledge of [xa, xu] and the predictor f (xa; θ) based solely on the knowledge
of xa. Furthermore, if Φxu {(cid:107).(cid:107) | xa} stands for the expectation of a particular
loss function and if the latter agrees with the loss function applied in ML valida-
tion, then we may argue that the method of aggregation through ML produces
indeed a bona ﬁde approximator of ¯y∗(xa). The introduction of the expecta-
tion operator and the L2-norm in Φxu{(cid:107).(cid:107) | xa} is especially useful since the
resulting ML approximator (cid:98)y∗(xa) may then be viewed as approximating the
expectation of g(y∗(xa, xu)), conditionally on xa.

Selecting the scope of analysis, namely determining which variables of x and

10

domains thereof to include in the operational problem, the level of detail of
the TDOS and the partition [xa, xu] achieves a compromise between statistical
precision, accuracy and tractability. Thus, it may be acceptable to exclude low
probability regions in the support of certain relevant variables or even some
relevant but judged-less-critical variables altogether from consideration in order
to gain statistical precision at the expense of some accuracy. For short, we shall
call such a restriction in the scope of analysis subselection. For instance, in
our application, it was judged useful to disregard infrequent railcar types and
container lengths from the support of x = [xa, xu] and the scope of analysis in
order to gain precision and tractability in ML.

The excluded support and/or excluded variables and their complement con-
stitute a partition of the whole support/set of variables that gives rise to an in-
formational σ-algebra, say G. The probabilistic knowledge that embodies these
exclusions may be represented by the joint probability distribution of [xa, xu]
conditional on G. If useful, for instance for the purpose of drawing formal com-
parisons between results with and without exclusions, conditioning with G may
be introduced explicitly, possibly in addition to conditioning with σ(xa). Oth-
erwise, the ML procedures can be blind to the exclusions. We proceed in this
manner in our application.

4 Application

We use the double-stack intermodal railcar LPP (Mantovani et al., 2018) to
illustrate the proposed methodology. The LPP can be brieﬂy described as fol-
lows. Given a set of containers and a set of railcars, determine the subset of
containers to load and the exact way of loading them on a subset of railcars.
The objective consists in minimizing the total cost of containers left behind
and partly ﬁlled railcars. The solution depends on individual characteristics of
containers and railcars. Containers are characterized by their length, height,
standardized type, content and weight. In North America, double-stack inter-
modal railcars comprise one to ﬁve platforms and each platform has a lower
and an upper slot where containers may be loaded. Crucially, railcars are char-
acterized by the weight capacity and tare of each platform and by the speciﬁc
loading capabilities associated with their standardized type. We can express the
loading capabilities with a set of loading patterns enumerating all possible ways
in which containers of diverse lengths can be placed in the lower and upper slots
of each platform. In general, the loading capabilities cannot be decomposed by
platform, which leads to sets of loading patterns of high cardinality. Mantovani
et al. (2018) propose an ILP formulation that can be solved in seconds or in
minutes, depending on the size of the problem, using a commercial solver.

Figure 1 depicts a small example of a problem instance along with four
descriptions of the optimal solution at diﬀerent levels of detail. The instance
contains ten containers of three diﬀerent lengths: 20 feet (ft), 40 ft and 53 ft. For
the sake of simplicity, we do not report exact weights but note that containers
drawn in dark gray are considerably heavier than those drawn in light gray. The
instance contains two railcars: one with three 40 ft platforms and another with
one 53 ft platform. The numbers in each slot indicate the feasible assignments
with respect to container sizes: Containers exceeding the length of the platform
cannot be loaded in a bottom slot and 20 ft containers cannot be loaded in a

11

Figure 1: Example of the double-stack railcar LPP

top slot.

The operational solution is illustrated immediately below the problem in-
stance in Figure 1. The solution makes use of the two railcars and a subset of
the containers are assigned to slots. In this example, one top slot is not used
because of weight constraints and two heavy containers are not assigned.
If
the objective function is deﬁned as the slot utilization, then its value is 7/8.
The latter corresponds to the strategic description of the operational solution,
shown in the bottom part of the ﬁgure. Two alternative TDOSs whose levels of
detail are intermediate are also depicted in the ﬁgure. One (labeled Tactical 1)
speciﬁes for each individual railcar the numbers of containers of each size that
are assigned to it. The other, less detailed (labeled Tactical 2), speciﬁes the
numbers of railcars of each type that are used in the solution and the numbers
of containers of each size that are assigned. There is a trade-oﬀ between the
level of detail that is required and the diﬃculty of the prediction task. Thus,
Tactical 1 and 2 naturally require output representations of variable and ﬁxed
length, respectively. Tactical 2 is used in our application.

We use our application to illustrate the notation: Feature vector x con-
tains the detailed information about the problem instance required to solve
the LPP. Subvector xa reports features that are known at time of prediction:
total numbers of available railcars of each type and of available containers of
each length. Subvector xu reports features that are unknown at time of pre-
diction:
individual gross weights of containers. The problem described in (2)
corresponds to the ILP formulation of Mantovani et al. (2018). The detailed
assignment y∗(xa, xu) of containers to slots in the operational solution is illus-
trated in the second panel of Figure 1. Tactical 1 and 2 constitute two examples
of ¯y∗(xa, xu) :≡ g(y∗(xa, xu)) that can be obtained from the detailed solution.
Our methodological proposal cannot be viewed as supplying heuristic so-

12

lutions to the LPP. The LPP is a deterministic operational problem whose
solution is computed after any uncertainty regarding the container weights has
been resolved and speciﬁes the ﬁnely detailed assignment of the containers to
the available railcars.
In contrast, we address the stochastic problem taking
place at tactical standpoint when container weights are still unknown. We pro-
pose to approximate with ML the expectation of the TDOS. This expectation
accounts for the uncertainty in container weights, is conditional upon available
railcars and provides support for the tactical decisions.

4.1 Subselection of Containers and Railcars and Aggrega-

tion

Container data may be transformed by subselecting lengths, heights, standard-
ized types and contents and by aggregating weights. Similarly, railcar data may
be transformed by subselecting standardized types and by aggregating weight
capacities and tares. Hence, in order to ensure that the LPP remains man-
ageable, container lengths, heights, standardized types, and contents have been
subselected to retain only the 2 most relevant lengths, 40 ft and 53 ft, a single
height, a single standardized type and a single content. Similarly, railcar types
have been subselected to retain the 10 most numerous ones that amount to
nearly 90% of the North American ﬂeet. This results in input-output vectors of
size 12.

Exact weight capacities and tares of the railcars are unknown at the time
of prediction. We account for this through aggregation. In relation to railcars,
aggregation is straightforward because weight capacities and tares vary very
little for each given standardized type. Hence, population estimates of median
capacities and tares conditional on type are reasonable representative values.
This amounts to aggregation over input values.

A key challenge in our application is related to the container weights that are
unknown at the time of prediction. In contrast to the railcar weight capacities,
container weights are highly variable, even conditionally upon the values of other
container characteristics. We therefore perform aggregation over output values
in view of its superior theoretical underpinnings compared to aggregation over
input values (see Section 3.3).

4.2 Data Generation

We partition the available data into four classes, as reported in Table 1. This
partition facilitates experiments where models are trained and validated on sim-
pler instances and tested on either simpler (A), harder (B, C) or hardest ones
(D).

Class Description

# of containers # of platforms

A
B
C
D

Simpler ILP instances
More containers than A (excess demand)
More platforms than A (excess supply)
Largest and hardest instances

[1, 150]
[151, 300]
[1, 150]
[151, 300]

[1, 50]
[1, 50]
[51, 100]
[51, 100]

Table 1: Data classes

13

We generated data by randomly sampling and distributing the total number
of platforms among railcars belonging to the 10 standardized types, by randomly
sampling the numbers of containers of each length and by randomly sampling the
weight of each container given its length. In detail, sampling the container gross
weights proceeded as follows based on historical data: First, we determined the
empty/non-empty state of a container through a Bernouilli experiment where
the probability that a container is empty conditionally upon its length has been
estimated from container transportation data. Second, conditionally on the
container not being empty, we sampled its net weight from a uniform distribution
over values ranging between 10% and 90% of its net capacity given length.
Third, we equated the generated total weight of a non empty container to the
sum of the generated net weight given length and the a priori estimate of median
tare given length. Table 2 reports the number of examples for each data class.
In order to analyze sample eﬃciency, we chose to generate a large number of
instances (20M) of the easiest class A and we denote this dataset A(cid:48). For the
sake of comparison, datasets A(cid:48)(cid:48)-D(cid:48)(cid:48) all contain the same number of instances
(200K). We randomly divided each dataset into training (64%), validation (16%)
and test (20%) sets.

Each generated instance of the LPP was solved with IBM ILOG CPLEX
12.6 down to an optimality gap of at most 5%. The solutions in the resulting
problem instance-solution pairs were described with a limited subset of features:
numbers of railcars of each type and numbers of containers of each length used
in the loading solution. The objective of the ILP formulation was set so as to
enforce the following priorities in lexicographic order: maximize total number of
containers loaded, minimize total length of railcars used, maximize total length
of containers loaded. Table 2 reports the percentiles of computing times per
instance using three out of the six cores of an Intel Xeon X5650 Westmere 2.67
GHz processor. For instance, the median time required to solve a deterministic
instance of class A down to an optimality gap of at most 5% is equal to 0.48 s,
the median for class D is 5.44 s and we note a sizable variability as the 95th
percentile is 1.67 s for class A and 20.89 s for class D.

Data
class/set
A(cid:48)
A(cid:48)(cid:48)
B(cid:48)(cid:48)
C (cid:48)(cid:48)
D(cid:48)(cid:48)

# instances Time percentiles (s)
P95
P5
1.67
0.007
2.87
0.011
3.43
0.02
6.03
0.72
20.89
2.64

20M
200K
200K
200K
200K

P50
0.48
0.64
1.26
2.59
5.44

Table 2: Data generation

4.3 Measuring the Predictive Performance

We summarize and compare the predictive performances based on (3), the sum
of (i) mean absolute prediction error (MAE) measured over the number of used
slots (4) and of (ii) mean absolute prediction error measured over the number of
loaded containers (5) in output solution. Thus measuring the prediction errors

14

in terms of the L1− instead of the L2-norm will facilitate the interpretation of
the predictive performance. The three criteria are deﬁned as follows:

MAE =

MAE slots =

1
m

1
m

m
(cid:88)

12
(cid:88)

i=1

j=1

m
(cid:88)

10
(cid:88)

i=1

j=1

j − y(i)
|(cid:98)y(i)

j

|sj,

j − y(i)
|(cid:98)y(i)

j

|sj,

MAE conts =

1
m

m
(cid:88)

12
(cid:88)

i=1

j=11

j − y(i)
|(cid:98)y(i)

j

|,

(3)

(4)

(5)

where m is the number of examples and sj, j = 1, . . . , 10, equals the number
of slots on railcar type j. Notice that s11 = s12 = 1 do not appear in (5). To
draw a more complete picture of the predictive performance, we also calculate
empirical quantiles of the set of absolute errors {AE(i), i = 1, . . . , m}, where
the absolute error AE(i) associated with observation i is given by

AE(i) =

12
(cid:88)

j=1

j − y(i)
|(cid:98)y(i)

j

|sj.

(6)

4.4 A Lower Bound from Stochastic Programming

The stochastic limits of statistic (3) that are estimated by ML for various mod-
els, learning algorithms and data sets are all bounded from below and away from
zero due to the stochastic nature of the prediction problem. Such lower bounds
make it possible to assess how well the ML approximators fare and if attempts
at improving their performance by increasing their capacity and/or the size of
training data are worthwhile. Estimates of the relevant lower bounds can be cal-
culated from stochastically consistent solutions to a particular implementation
of the optimal prediction problem (1) and (2).

In order (i) to calculate an approximate lower bound for the prediction error
achievable by the ML approximators and (ii) to illustrate the parallel between
the proposed methodology based on ML and the alternatives oﬀered by ap-
proximate stochastic programming, we detail the application of one particular
method in the context of the LPP. We select the method of SAA (see, e.g.,
Kim et al., 2015, Shapiro et al., 2009, p. 155) in view of its position as a de
facto standard in approximate stochastic programming:
it is broadly applica-
ble, commonly used, based on simple principles and supported by an abundant
knowledge of its properties, both theoretical and empirical. We stress that an
application of approximate stochastic programming to (1) and (2) seeks a so-
lution for each particular value of xa. Hence, unless the domain of xa is both
ﬁnite and small, the solutions must be computed on demand, one at a time. In
contrast, our proposed methodology outputs a prediction function deﬁned over
the domain of xa. This function is computed in advance with ML and used later
on to yield solutions on demand.

The LPP speciﬁcation of the general optimal prediction problem of (1) and

15

(2) is

¯y∗(xa) :≡ arg

inf
¯y(xa)∈ ¯Y(xa)

12
(cid:88)

Exu{

j=1

|¯yj(xa) − gj(y∗(xa, xu))|sj | xa}

(7)

y∗(xa, xu) :≡ arg

inf
y∈Y(xa,xu)

C(xa, xu, y)

(8)

and the application of the SAA method proceeds through the following steps:

1. Fix a particular value for xa.

2. Select a sampling distribution for xu and generate a sample of size N

{x(i)

u , i = 1, . . . , N }.

3. Deﬁne sample versions for (7) and (8) as

¯y∗(xa) :≡ arg

inf
¯y(xa)∈ ¯Y(xa)

N
(cid:88)

12
(cid:88)

|¯yj(xa) − gj(y∗(i)(xa, x(i)

u ))|sj

(9)

i=1

j=1

y∗(i)(xa, x(i)

u ) :≡ arg

inf
y(i)∈Y(xa,x(i)
u )

C(xa, x(i)

u , y(i)), i = 1, . . . , N (10)

4. Solve the N operational problems in (10).

5. Solve the ILP (9).

The fact that the set of solutions to (10) is ﬁnite for a given value of xa sim-
pliﬁes the analysis of the statistical properties of the SAA method. Hence, the
distance between solution(s) to (9) and solution(s) to (7) is shown to converge
strongly to zero with respect to the so-called “number of scenarios” N (Kleywegt
et al., 2002). Although some theoretical bounds are available, determining with
suﬃcient precision the speed of this convergence and an appropriate value for
N is essentially a problem- and data-speciﬁc issue that must be resolved em-
pirically. Despite the lack of precise advance knowledge about the appropriate
value for N , we realize at once that the application of SAA on demand for each
value of xa is too costly for our computing time budget that is less than the
time it takes to solve the deterministic problem. For this reason, we do not use
state-of-the-art solution algorithms for the SAA problem. Instead, we compute
solutions using the default setting of ILOG CPLEX 12.6. We report computing
times for the sake of completeness (last column in Table 3).

In an attempt to infer an approximate lower bound, we calculated SAA

solutions for N ∈ {5, 10, 25, 50, 75, 99} through these steps:

1. Generate a dataset of the target class (A, B, C or D) from the sampling
distributions described in Section 4.2 through a two-stage sampling pro-
cess. In the ﬁrst stage, randomly sample 100K values for xa. In the second
stage, for each one of the ﬁrst stage values, randomly sample 100 values
for xu.

16

2. For each one of the 100K values of xa resulting from the ﬁrst stage, com-
pute the 100 deterministic LPP solutions corresponding to this value of
xa and to each one of the 100 values of xu, respectively. Compute the
SAA solution with the ﬁrst N out of the 100 load planning solutions, as in
(9) and (10). Compute the absolute error between the SAA solution and
the 100th deterministic load planning solution as well as the total time
required to compute the SAA solution.

3. Compute the empirical distributions of the absolute errors and on-demand
computing times incurred over the 100K repetitions resulting from the
100K values of xa sampled in the ﬁrst stage.

We start by analysing results for the hardest class of instances (D) reported
in Table 3. The sample MAE values associated with the SAA solutions mono-
tonically decrease from 2.879 to 2.682 at a decreasing rate as a function of the
number of scenarios and are nearly identical for numbers of scenarios equal to
75 and 99. Hence, it is reasonable to view 2.682 as being in the vicinity of the
lower bound for the optimal prediction problem over data class D. From Cheby-
shev’s inequality (e.g., Kendall et al., 1987), we know that the probability that
the exact lower bound lies approximately inside three times the estimated stan-
dard error of estimate 8.08E-02 from either side of the sample MAE 2.682 is
greater than 89%. Therefore, we deﬁne a conﬁdence interval around this value
as [2.4396, 2.9244], which we refer to as the SAA lower bound over data class
D. In a similar fashion, we compute SAA lower bounds over data classes A
[0.7978, 0.8502], B [0.7584, 0.8056] and C [3.0593, 3.1787].

Nb. of scenarios∗

MAE

Computing time [s]

Est. mean Est. std dev Est. mean Est. std dev

5

10

25

50

75

99

2.879
(8.35E-02)
2.753
(8.14E-02)
2.691
(8.08E-02)
2.687
(8.09E-02)
2.681
(8.08E-02)
2.682
(8.08E-02)

26.412

25.731

25.559

25.568

25.535

25.561

42.144
(1.57E-01)
84.070
(2.83E-01)
209.776
(6.56E-01)
419.700
(1.28E-00)
628.900
(1.90E-00)
829.956
(2.49E-00)

49.748

89.502

207.328

403.982

599.345

787.748

* number of sets of weights drawn for each example
Standard error of estimate is reported between parentheses.

Table 3: Properties of the SAA predictor over class D

4.5 ML Approximation

The predictive models are based on feedforward neural networks, a.k.a. mul-
tilayer perceptrons (MLP). From their introduction several decades ago until
recently, MLPs had demonstrated modest success in ML. However, through the

17

recent algorithmic advances that have occurred in the subﬁeld of ML known
as deep learning, they have become simple but powerful generic approximators.
They are useful in real applications whenever input and output vectors have
short ﬁxed lengths and do not feature complex structures (e.g., images and
sound typically require other models).

The mapping between inputs and outputs could be interpreted as a classi-
ﬁcation or as a regression problem and we implemented the two corresponding
architectures. The resulting families of models are hereafter named ClassMLP
and RegMLP, respectively. Both families feature 12 units in their input layer
(one integer unit for each railcar type and for each container length) and recti-
ﬁed linear units (ReLU) are used as activation functions in their hidden layers.
The two families diﬀer with respect to their output layer, the manner in which
input-output constraints are upheld and the loss function used in their training.
On the one hand, ClassMLP outputs 12 discrete probability distributions
(one for each railcar type and for each container length) that are each modeled
with a softmax operator. The supports of these distributions are the sets of
possible numbers of railcar of each type and of containers of each length. Thus,
concatenation of the 12 distributions yields an output layer of size 812 when
the numbers of railcars platforms of each type and of containers of each length
used in the solution may respectively vary from 1 to 50 and from 1 to 150. The
following constraints are enforced at training, validation and testing times: for
each type of railcar and length of container, the number in output cannot exceed
the number in input. This is done by computing the softmax over admissible
outputs only. Training is conducted through likelihood maximization where we
treat output distributions as independent.

On the other hand, RegMLP outputs 12 scalars that are rounded to the
nearest integer, input-output inequalities are enforced only at validation and
testing times and training is conducted through minimization of the sum of ab-
solute errors incurred in predicting output numbers for railcars of each type and
containers of each length. For both families, the assumption that outputs are
conditionally mutually independent given inputs is implicit in their architecture.
Training of both ClassMLP and RegMLP was performed with mini-batch
stochastic gradient descent and the learning rate adaptation was governed by
the Adam (adaptive moment estimation) method (Kingma and Ba, 2014). Reg-
ularization was ensured by early stopping. Hyperparameter selection included
number and width of hidden layers as well as L1 and L2 regularization terms
coeﬃcients. Sets of hyperparameter values were generated randomly and the
preferred set was determined according to validation results (Bergstra and Ben-
gio, 2012). The ranges of values considered were as follows:
[3, 13] for the
number of hidden layers, [300, 1000] for the number of units per hidden layer,
[0, 0.001] for the L1 and L2 regularization coeﬃcients. For each ML model and
each dataset, we tried 50 hyperparameter combinations in a random search and
retained the best performing models.

Since the optimal prediction problem we face is new, we cannot compare
our results to an existing benchmark.
In order to assess the quality of the
predictions, we compare the performance against a lower bound from stochastic
programming, as introduced in Section 4.4. We also assess if the prediction
task is easy, or even trivial. For this purpose, we present additional results
obtained with, ﬁrst, simple greedy algorithms and, second, simple prediction
models, namely logistic regression (ClassMLP without hidden layers) and linear

18

regression (RegMLP without hidden layers). Algorithm 1 (HeurV) greedily
accounts for the total number of slots available on each railcar but disregards
all other constraints pertaining to the loading problem. In contrast, Algorithm
2 (HeurS) greedily accounts for all constraints relevant to the loading problem,
namely: (i) 53 ft containers can only be assigned to 53 ft slots whereas 40 ft
containers can be assigned to any slot, (ii) for some railcars, some 53 ft top slots
are only available provided that 40 ft containers are loaded in the bottom slot.
This algorithm also attempts to account for the lexicographic objective.

Algorithm 1 Very simple greedy heuristic (HeurV)

while unassigned cont. and avail. car do

for all car type in car types do

for all car matching car type do

assign avail. cont(s) to car, alternating if possible between 40’ and 53’
cont(s);

end for

end for
end while

Algorithm 2 Simple greedy heuristic (HeurS)

while unassigned 53’ cont. and avail. car with usable 53’ slot(s) do

choose shortest among cars with greatest number of usable 53’ slots not
exceeding number of 53’ conts still to assign;
otherwise, choose shortest among cars with smallest number of usable 53’
slots;
assign as many 53’ conts as possible to usable 53’ slots on car;
assign as many 40’ conts as possible to remaining available slots of car;

end while
while unassigned 40’ cont. and avail. car do

choose shortest among cars with greatest number of slots not exceeding
number of 40’ conts still to assign;
otherwise, choose shortest among cars with smallest number of slots;
assign as many 40’ conts as possible to available slots of car;

end while

4.6 Results

Table 4 reports the sample MAE (3) incurred by each model over an independent
test dataset similar to that used for training and validation. The aggregation
of the unknown container weights is performed with the method of aggregation
over output values through ML, as discussed in Section 3.3. Standard errors of
the estimates are shown in parentheses. We report results for models trained,
validated and tested based on 200K i.i.d. examples of class A (dataset 200K-
A, second column in the table), 20M i.i.d. examples of class A (dataset 20M-A,
third column in the table) and 600K i.i.d examples made up of the union of 200K
examples from each of the A, B and C classes (dataset 600K-ABC, fourth col-
umn in the table). Note that each ﬁgure reported for ClassMLP or for RegMLP

19

corresponds to the most favorable set of hyperparameters according to the val-
idation process (found through the random search described in Section 4.5).

A number of ﬁndings immediately emerge from the examination of Ta-
ble 4. For both datasets 200K-A and 20M-A comprising only class A examples
(columns two and three), the average performances of both feedforward neural
network models – ClassMLP and RegMLP – are very good in comparison with
the SAA lower bound over data class A whose value is estimated in Section 4.4
at [0.7978, 0.8502]. For example, the sample MAE achieved by ClassMLP and
RegMLP over the 4M class A testing examples of dataset 20M-A are respec-
tively equal to 0.965 and 0.985, when trained over the 12.8M class A training
examples of dataset 20M-A and validated over the the 3.2M class A validation
examples of dataset 20M-A. For the joint dataset 600K-ABC (column four) com-
prising the harder examples of classes B and C in addition to examples of class
A, the average performances of ClassMLP and RegMLP also appear to be very
good. For example, sample MAE for RegMLP modestly increases from 1.304
(dataset 200K-A, second column) to 2.109 (dataset 600K-ABC, fourth column).
For all three datasets (columns two to four), the performances of ClassMLP and
RegMLP are considerably better than those of the simple predictors (logistic
regression, linear regression and the two heuristics) indicating that the task is
not trivial.

We also note the following: First, the marginal value of using 100 times more
training and validation examples is fairly small. For example, the sample MAE
of RegMLP only increases from 0.985, when training and validating over the
12M training examples and 3.2M validation examples of 20M-A, to 1.304 when
training and validating over the 120K training examples and 32K validation
examples of 200K-A. Second, RegMLP features a slightly better average per-
formance than ClassMLP, except for the 20M-A data. A possible explanation
for this is that the pseudo-likelihood function used as a surrogate for MAE in
training ClassMLP does not account for the magnitude of the prediction errors.
The very good predictive performance of ClassMLP and RegMLP is con-
ﬁrmed by the examination of the distribution of absolute errors in Table 5: For
example, at least 95% of the absolute errors made by ClassMLP and RegMLP
are smaller than or equal to 4. This is in stark contrast with the performances
of the simple predictors whose distributions of absolute errors are highly skewed
and whose median absolute error is either equal to 4 in the most favorable case
(LogReg) or well beyond this ﬁgure elsewhere (LinReg, HeurV, HeurS).

Figure 2 displays the MAE in relation to the number of available slots and
the number of available containers (input) for the RegMLP model and 20M-A
data. It shows that errors occur mainly in conditions of excess supply or excess
demand.

Table 6 provides information on the distribution of the time required to
compute a prediction based on input data similar to that used for training
and validation of the predictor. For example, the median time required to
compute a prediction based on model RegMLP when input belongs to class A
is 0.8 milliseconds. As clearly shown by the closeness of the 5th, 50th and 95th
percentiles, the distribution of the prediction time is highly concentrated and
we ought to expect small variations among computing times around the median
value. Furthermore, it is expected that the ﬁgures of Table 6 will vary little
across input classes with a similar model. Computational speed should instead
depend on model complexity (in our case number and width of hidden layers).

20

Data
# examples

ClassMLP

LogReg

RegMLP

LinReg

HeurV

HeurS

200K-A 20M-A

200K
1.481
(0.018)
5.956
(0.029)
1.304
(0.017)
18.306
(0.094)
14.733
(0.075)
17.841
(0.083)

20M
0.965
(0.002)
5.887
(0.003)
0.985
(0.002)
18.372
(0.009)
14.753
(0.008)
17.842
(0.008)

600K-ABC
600K
2.312
(0.014)
9.051
(0.027)
2.109
(0.014)
39.907
(0.084)
27.24
(0.083)
31.448
(0.089)

Standard error of estimate is reported between parentheses.

Table 4: Testing over data similar to that used in training-validation: sample
mean absolute errors (MAE)

Data
# examples
Percentiles
ClassMLP
LogReg
RegMLP
LinReg
HeurV
HeurS

200K-A
200K
P50 P60 P70 P80 P85 P90 P95 P99
18
0
26
4
18
0
82
11
68
10
72
13

4
17
4
61
46
52

4
14
4
47
36
41

1
10
1
30
24
31

2
12
2
38
30
35

0
7
0
19
16
23

0
6
0
14
12
17

Table 5: Testing over data similar to that used in training-validation: distribu-
tion of absolute errors

Data
# examples
Percentiles
ClassMLP
RegMLP
HeurV
HeurS

200K-A
200K
P50 P95
3.2
2.9
1.0
0.8
0.8
0.4
1.6
0.7

P5
2.6
0.7
0.3
0.3

Table 6: Prediction time per instance (milliseconds)

21

In comparison, Table 2 indicates that even if the prediction problem deﬁned
by (1) and (2) were deterministic, that is, if x = xa held, whence the solution of
the operational load planning problem could be calculated in advance exactly,
one would still face a highly dispersed computation time with a median ranging
from 0.48 to 5.44 seconds according to the exact class of the input.

Figure 2: MAE over instances with speciﬁed numbers of available slots and
containers, RegMLP model and 20M-A data.

In view of the higher costs of generating harder in-
Extraneous Errors.
stances (i.e., solving harder problems),
it is desirable that models that are
trained and validated on simpler instances generalize to harder instances with-
out speciﬁc training and validation. In contrast with the previous results where
testing was conducted on data similar to that used for training and validation,
we now focus on testing the performance over a set of class D data containing
the hardest instances. We emphasize that instances of this nature have not been
used for training-validation.

Table 7 reports sample MAE achieved over the 200K class D examples of
dataset 200K-D by the exact models whose performances over testing data
of class A are reported in Table 4. Standard deviations of the estimates are
shown in parentheses and we report between brackets the range in performance
achieved over all hyperparameter sets. Since the classiﬁcation models cannot
generate solution predictions for problem instances whose ranges of numbers
of available containers and available railcars exceed those encountered during
training and validation, we do not report any MAE values for the predictors
ClassMLP and LogReg that are trained and validated over the class A exam-
ples of dataset 20M-A (Table 7, second column).

The following ﬁndings emerge. First, the performance of RegMLP that has
been trained and validated on class A examples is still good when tested over
class D examples. Compared to the SAA lower bound over data class D whose
value is estimated in Section 4.4 at [2.4396, 2.9244], RegMLP achieves a sample
MAE equal to 4.412 over the 200K testing examples of class D of dataset 200K-

22

D (Table 7, second column), when trained over the 12.8M training examples of
class A of dataset 20M-A and validated over the 3.2M validation examples of
dataset 20M-A. Second, the testing performance over class D clearly beneﬁts
from performing training and validation over classes B and C in addition to
class A. Thus, when trained over the 360K training examples of classes A, B
and C of dataset 600K-ABC and validated over the 96K validation examples
of classes A, B and C of dataset 600K-ABC, RegMLP achieves over the 200K
testing examples of class D of dataset 200K-D a sample MAE equal to 2.372
(Table 7, second column) instead of 4.412. (Notice that conﬁdence intervals can
be calculated around the point estimates of MAE appearing in Table 7.)

The sample MAE values reported between brackets indicate that the range
of the performances achieved on D over all hyperparameter sets considered at
validation is wide. For example, it varies between 2.481 and 24.702 for RegMLP
when training and validating over dataset 20M-A and testing over dataset 200K-
D. We note that some hyperparameter sets achieving close to best validation
performance perform poorly on D. The range of performances achieved over
all hyperparameter sets considered at validation is reduced when training and
validating on B and C in addition to A (last column).

This opens up for questions concerning alternative data generation proce-
dures. For example, less expensive labeling of the hardest instances could be
accomplished by setting the maximum optimality gap to a more lenient value
or even use solutions obtained with a heuristic. Training and validation could
then be performed on these instances as well.

Finally, Table 8 provides information on the distribution of the time required
to compute a prediction based on extraneous data. The remarks made in relation
to Table 6 are still valid and the ﬁgures reported here are not markedly diﬀerent.

Training-validation data
Testing data

ClassMLP

LogReg

RegMLP

LinReg

HeurV

HeurS

20M-A
200K-D
NA

NA

4.412 [2.481, 24.702]
(0.050)
24.560
(0.064)
33.737
(0.085)
43.303
(0.089)

600K-ABC
200K-D
14.831 [13.161, 23.892]
(0.072)
29.568
(0.065)
2.372 [2.355, 3.305]
(0.051)
72.847
(0.060)
33.737
(0.085)
43.303
(0.089)

Table 7: Testing on class D instances (not used for training-validation): sample
mean absolute errors (MAE)

23

Data
# examples
Percentiles
RegMLP
HeurV
HeurS

200K-D
200K
P50 P95
1.9
1.3
1.6
1.0
4.1
3.9

P5
0.6
0.3
1.9

Table 8: Prediction time in milliseconds per instance with extraneous data

5 Conclusion and Future Work

This paper has proposed a supervised ML approach for predicting expected
TDOSs under imperfect information in short computing time. The problem
is of relevance to various applications where tactical and operational planning
problems are interdependent. We considered an application related to railway
demand and capacity management at the tactical level (accept / reject booking
requests) whose solution depends on a kind of packing problem at the opera-
tional level. A similar problem occurs in other freight transportation settings,
for example, airline cargo and less-than-truckload.

We formulated the problem as an optimal prediction stochastic program-
ming problem whose solutions we predicted with machine learning. Key in the
proposed methodology is the generation of labeled training data for supervised
learning. We proposed to sample operational problem instances (perfect infor-
mation) by controlled probabilistic sampling. The generated operational prob-
lem instances were solved independently and oﬄine using an existing solver.
We handled uncertainty with appropriate aggregation methods. Otherwise, our
methodology relies on existing ML models and algorithms. This is a substantial
advantage since we can beneﬁt from the recent advances in ML, and in our case,
deep learning.

We illustrated the methodology with a train LPP, where some features of the
inputs (problem instances) – in this case container weights – are unavailable at
the time of prediction. We explained why the methodology cannot be viewed as
supplying heuristic solutions to the LPP. The results showed that a regression
feedforward neural network presented the best performance overall. Remark-
ably, the solutions could be predicted with a high accuracy in comparison with
an error bound, and in very short computing time (in the order of a millisecond
or less). In fact, the time required to predict the solution descriptions under
imperfect information using ML is much shorter than the time required to solve
a single deterministic instance with an ILP solver. The results also showed that
the regression feedforward neural network model that was trained and validated
on simpler instances could generalize surprisingly well to harder instances with-
out speciﬁc training and validation. However, quite expectedly, the variations
over the hyperparameter sets considered during the validation step were large
when the nature of the data was very dissimilar.

We considered an input and output structure of small and ﬁxed size. A
direction for future research is to predict more detailed solutions where the input
and output structures would be of large and variable size and would possibly
feature additional constraints. The trade-oﬀ between the level of detail and

24

uncertainty of the input is a question by itself. In this context, an approach
related to pointer networks (Vinyals et al., 2015) might be a promising avenue.
Since data generation is the most expensive part of the methodology, future
research should investigate learning algorithms whose trade-oﬀ between the cost
of generating data and the predictive performance can be controlled.

Finally, we envision that the same methodology could be successfully applied
to other types of two-stage stochastic programming problems like, for example,
the two-stage Vehicle Routing Problem (VRP) with stochastic demands as de-
ﬁned by Gendreau et al. (2014). In this context, the routes are speciﬁed in the
ﬁrst stage and the intermediate returns to the depot are determined online in
the second stage. This framework gives rise to two formulations, respectively
based on network ﬂows and on set partitioning. Given a particular vehicle
route, the operational solution consists of all two-way trips made to the depot
from the customer locations when the capacity of the vehicle is exceeded. In
the network ﬂow and the set partitioning formulations, given a particular ve-
hicle route, the expected tactical description of operational solution could be
the probability of a return to depot at a speciﬁc location along this route (Gen-
dreau et al., 2014, Eq. (8.9)) and the cumulative probability distribution of
the cumulative demand at a location along this route (Gendreau et al., 2014,
p. 219), respectively. Predicting either of the latter with ML would provide
advance information on the operational solution that would be valuable from
a tactical standpoint and possibly accelerate the computation of the expected
recourse function and the online computation of the solution to the overall VRP
problem.

Acknowledgments

This research was funded by the Canadian National Railway Company (CN)
Chair in Optimization of Railway Operations at Université de Montréal and
a Collaborative Research and Development Grant from the Natural Sciences
and Engineering Research Council of Canada (CRD-477938-14). Computations
were made on the supercomputers Briarée and Guillimin, managed by Calcul
Québec and Compute Canada. The operation of these supercomputers is funded
by the Canada Foundation for Innovation (CFI), the Ministère de l’Économie,
de la Science et de l’Innovation du Québec (MESI) and the Fonds de recherche
du Québec - Nature et technologies (FRQ-NT). The research is also partially
funded by the “IVADO Fundamental Research Project Grants” under project
entitled “Machine Learning for (Discrete) Optimization”. We are grateful for
important insights obtained through discussions with Jean-François Cordeau,
Matteo Fischetti and Michael Hewitt. We are indebted to three anonymous ref-
erees for extremely careful readings and for challenging us to clarify the essence
of the contribution.

References

Abbasi, B., Babaei, T., Hosseinifard, Z., Smith-Miles, K., and Dehghani,
M. Predicting solutions of large-scale optimization problems via machine
learning: A case study in blood supply chain management. Computers

25

& Operations Research, 119:104941, 2020. doi: https://doi.org/10.1016/j.
cor.2020.104941. URL http://www.sciencedirect.com/science/article/
pii/S0305054820300587.

Andradóttir, S. A review of random search methods. In Fu, M. C., editor, Hand-
book of Simulation Optimization, volume 216 of International Series in Oper-
ations Research & Management Science, chapter 10, pages 277–292. Springer,
2015.

Asmussen, S. and Glynn, P. W. Stochastic simulation: algorithms and analysis.
Stochastic modelling and applied probability 57. Springer, New York, 2010.

Barz, C. and Gartner, D. Air cargo network revenue management. Trans-
portation Science, 50(4):1206–1222, 2016. doi: 10.1287/trsc.2016.0708. URL
https://doi.org/10.1287/trsc.2016.0708.

Bengio, Y., Lodi, A., and Prouvost, A. Machine Learning for Combina-
torial Optimization: A Methodological Tour d’Horizon. ArXiv e-prints
arXiv:1811.06128, 2018.

Bengio, Y., Frejinger, E., Lodi, A., Patel, R., and Sankaranarayanan, S.
A learning-based algorithm to quickly compute good primal solutions for
stochastic integer programs. ArXiv e-prints arXiv:1912.08112, 2019.

Bergstra, J. and Bengio, Y. Random search for hyper-parameter optimization.

Journal of Machine Learning Research, 13:281–305, 2012.

Birge, J. R. and Louveaux, F. Introduction to Stochastic Programming. Springer
Series in Operations Research and Financial Engineering. Springer New York,
New York, NY, 2011.

Chau, M. and Fu, M. C. An overview of stochastic approximation. In Fu, M. C.,
editor, Handbook of Simulation Optimization, volume 216 of International
Series in Operations Research & Management Science, chapter 6, pages 149–
178. Springer, 2015.

Curtis, F. E. and Scheinberg, K. Optimization Methods for Supervised Ma-
chine Learning: From Linear Models to Deep Learning. ArXiv e-prints
arXiv:1706.10207, 2017.

de Mello, T. H. and Bayraksan, G. Monte carlo sampling-based methods for
stochastic optimization. Surveys in Operations Research and Management
Science, 19(1):56 – 85, 2014.

Fischetti, M. and Fraccaro, M. Using OR + AI to predict the optimal pro-
duction of oﬀshore wind parks: A preliminary study. In Optimization and
Decision Science: Methodologies and Applications, volume 217, pages 203–
211. Springer, 2017.

Fu, M. C. Handbook of Simulation Optimization, volume 216 of International

Series in Operations Research & Management Science. Springer, 2015.

26

Gendreau, M., Jabali, O., and Rei, W. Stochastic Vehicle Routing Problems.
In Toth, P. and Vigo, D., editors, Vehicle Routing: Problems, Methods, and
Applications, volume 18 of MOS-SIAM Series on Optimization, chapter 8,
pages 213–239. SIAM-MOS, 2014.

Hu, J. Model-based stochastic search methods. In Fu, M. C., editor, Handbook
of Simulation Optimization, volume 216 of International Series in Operations
Research & Management Science, chapter 12, pages 319–340. Springer, 2015.

Kall, P. and Wallace, S. W. Stochastic Programming. John Wiley & Sons, 1994.

Kendall, M. G., Stuart, A., and Ord, J. K., editors. Kendall’s Advanced Theory
of Statistics. Oxford University Press, Inc., New York, NY, USA, 1987. ISBN
0-195-20561-8.

Kim, S., Pasupathy, R., and Henderson, S. G. A guide to sample average
approximation. In Fu, M. C., editor, Handbook of Simulation Optimization,
volume 216 of International Series in Operations Research & Management
Science, chapter 8, pages 207–243. Springer, 2015.

Kingma, D. P. and Ba, J. Adam: A method for stochastic optimization. CoRR,

abs/1412.6980, 2014. URL http://arxiv.org/abs/1412.6980.

Kleijnen, J. P. Response surface methodology. In Fu, M. C., editor, Handbook
of Simulation Optimization, volume 216 of International Series in Operations
Research & Management Science, chapter 4, pages 81–104. Springer, 2015.

Kleywegt, A. J., Shapiro, A., and Homem-de Mello, T. The sample average
approximation method for stochastic discrete optimization. SIAM J. on Op-
timization, 12(2):479–502, February 2002.

Law, A. M. Simulation modeling and analysis. McGraw-Hill series in industrial
engineering and management science. McGraw-Hill, Boston, 5th edition, 2014.

Levina, T., Levin, Y., McGill, J., and Nediak, M. Network cargo capacity

management. Operations Research, 59(4):1008–1023, 2011.

Lodi, A. and Zarpellon, G. On learning and branching: A survey. TOP, 25(2):

207–236, 2017.

Mantovani, S., Morganti, G., Umang, N., Crainic, T. G., Frejinger, E., and
Larsen, E. The load planning problem for double-stack intermodal trains.
European Journal of Operational Research, 267(1):107–119, 2018.

Nair, V., Dvijotham, K., Dunning, I., and Vinyals, O. Learning fast optimizers
for contextual stochastic integer programs. In Conference on Uncertainty in
Artiﬁcial Intelligence, 2018.

Shapiro, A. Monte carlo sampling methods. In Ruszczynski, A. and Shapiro,
A., editors, Handbooks in Operations Research and Management Science, vol-
ume 10, chapter 6, pages 353–425. Elsevier, 2003.

Shapiro, A., Dentcheva, D., and Ruszczynski, A. Lectures on Stochastic Pro-
gramming: Modeling and Theory. Society for Industrial and Applied Mathe-
matics, 2009.

27

Smith, K. A. Neural networks for combinatorial optimization: A review of more
than a decade of research. INFORMS Journal on Computing, 11(1):15–34,
1999.

Vapnik, V. The Nature of Statistical Learning Theory. Information Science and

Statistics. Springer New York, 1999.

Vinyals, O., Fortunato, M., and Jaitly, N. Pointer Networks. In Advances in

Neural Information Processing Systems, pages 2692–2700, 2015.

Wallace, S. W. Decision making under uncertainty: Is sensitivity analysis of

any use? Operations Research, 48(1):20–25, 2000.

Zabinsky, Z. B. Stochastic adaptive search methods: Theory and implemen-
tation. In Fu, M. C., editor, Handbook of Simulation Optimization, volume
216 of International Series in Operations Research & Management Science,
chapter 11, pages 293–318. Springer, 2015.

28

