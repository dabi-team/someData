1
2
0
2

r
p
A
5
1

]

C
O
.
h
t
a
m

[

2
v
0
1
5
4
0
.
0
1
9
1
:
v
i
X
r
a

OPTIMAL DAY-AHEAD ORDERS USING STOCHASTIC
PROGRAMMING AND NOISE-DRIVEN RNNS

A PREPRINT

Martin Biel
Division of Decision and Control Systems
School of EECS, KTH Royal Institute of Technology
SE-100 44 Stockholm, Sweden
mbiel@kth.se

April 16, 2021

ABSTRACT

This paper presents a methodology for strategic day-ahead planning that uses a combination of
deep learning and optimization. A noise-driven recurrent neural network structure is proposed for
forecasting electricity prices and local inﬂow to water reservoirs. The resulting forecasters gener-
ate predictions with seasonal variation without relying on long input sequences. This forecasting
method is employed in a stochastic program formulation of the day-ahead problem. This results
in optimal order strategies for a price-taking hydropower producer participating in the Nordic day-
ahead market. Using an open-source software framework for stochastic programming, the model
is implemented and distributed over multiple cores. The model is then solved in parallel using a
sampling-based algorithm. Tight conﬁdence intervals around the stochastic solution are provided,
which show that the gain from adopting a stochastic approach is statistically signiﬁcant.

1 Introduction

Electricity trading in the Nordic energy market is primarily based on day-ahead auctions. Producers and consumers
submit orders of price and electricity volumes to convey their desired market participation for the upcoming day.
The market operator then settles a market price based on supply and demand in the submitted orders. Since prices
and demands are unknown when submitting orders, imbalances can occur. These can then be mitigated in various
short-term markets. Hydropower producers participating in these markets have the opportunity to store energy in the
reservoirs, which leads to high ﬂexibility. Due to the high uncertainty associated with day-ahead market participation,
precise forecasts and planning procedures are required to devise optimal order strategies. Stochastic programming
is an effective approach for modeling these types of problems where decisions subjected to uncertainty are taken in
stages.

We consider a complete process where we forecast, model, and solve, in order to determine optimal order strate-
gies for a hydropower producer participating in the Nordic day-ahead market NordPool. We formulate the
day-ahead planning problem as a stochastic program and implement it in the open-source software framework,
StochasticPrograms.jl [1], written in the Julia programming language. The framework is implemented with parallel
capabilities, which allows us to efﬁciently distribute stochastic programs in memory. We use these features to instan-
tiate large-scale day-ahead models. We use historical data to construct samplers, which in turn generate the scenarios
used to construct the stochastic programs. The samplers are based on the proposed noise-driven recurrent neural net-
work (RNN) structure, which is used to forecast day-ahead prices and local inﬂows to water reservoirs. A key feature
is that the samplers generate forecasts without relying on long input sequences. Also, they can account for seasonal
variations in the forecasts through exogenous input parameters. To generate stochastic solutions of the formulated
day-ahead model with tight conﬁdence intervals, we apply a sampled average approximation (SAA) algorithm. This
allows us to verify that the value of the stochastic solution (VSS) of the model is statistically signiﬁcant in relation to

 
 
 
 
 
 
Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

the model and forecasts. We employ a family of distributed L-shaped algorithms [2] to efﬁciently run SAA in parallel
on a computational cluster. We make use of acceleration techniques to improve the convergence of the algorithm.

The application of stochastic programming for day-ahead planning has been actively studied. Some notable papers
are [3, 4, 5]. Also, an informative survey is provided by the authors of [6]. A common shortcoming in these contribu-
tions is that the resulting VSS is relatively low. Moreover, it is common that low VSS numbers are presented without
acknowledging that they might be within the error bounds of the stochastic solution. In this work, we carefully ensure
that the presented VSS is statistically signiﬁcant in relation to the model we solve.

RNN type approaches have been successfully applied to both price forecasting [7, 8] and inﬂow forecasting [9, 10].
A common characteristic in these implementations is that the forecasts rely on a lagged input sequence of historical
values. Consequently, the network training involves long input sequences and performance can be impacted negatively
if another historical sequence is given as input after training. This reduces the generality of the forecasts. This also
holds for ARIMA and ARMAX type models [11]. The proposed noise-driven RNN forecaster does not have this
characteristic. The networks are trained on historical data, but forecasts are generated from Gaussian inputs.

2 The day-ahead problem

A day-ahead planning problem involves specifying optimal order volumes in a deregulated electricity market. We give
a brief introduction to this problem here, as well as narrow down the scope of the problem solved and presented in this
contribution.

2.1 The day-ahead market

In a deregulated day-ahead electricity market, producers and consumers place orders that specify the electricity vol-
umes they wish to sell and buy the next day. The next-day market price is determined by the equilibrium price of these
orders. After market price settlement, all volume orders that have a price equal to or lower than then market price
are accepted. All market participants then become balance responsible for their accepted orders. Any imbalances can
be continuously adjusted by submitting orders to an intraday market after the market price settlement. In general,
imbalance settlement will involve a less favorable price than the day-ahead price. Since the next-day market price is
unknown, and the cost of imbalances can be high, careful planning is required in order to submit strategic orders to
the day-ahead market.

2.2 Order types

The Nordic day-ahead market offers four order variants for trading electricity volumes, hourly orders, block orders,
exclusive groups, and ﬂexible orders. We give a brief introduction to hourly orders and regular block orders.

Hourly orders can be placed in two ways. A price independent hourly order speciﬁes an electricity volume that is to
be purchased or sold at market price during a certain hour, independent of the market price. A price dependent order
speciﬁes electricity volumes at given price points. If the settled market price ends up between speciﬁed price steps a
linear interpolation is performed between the adjacent volume orders to determine the order volume. A settled hourly
order is illustrated in Fig. 1.

Block orders span over an interval of consecutive hours. A regular block order is accepted in its entirety if the mean
market price in the speciﬁed interval is higher or equal to the order price. The participants then become balance
responsible for the order volume every hour of the speciﬁed interval, at the mean market price in the interval. Block
orders where the price is higher than the mean market price in the given interval are rejected. Other block order
variants exist, such as linked block orders and curtailable block orders. These all include conditional elements, and
determining optimal orders would involve combinatorial optimization. This is also true for the remaining order types:
exclusive group and ﬂexible orders. We do not give further details into the conditional order types as only hourly
orders and regular block orders will be used subsequently.

2.3 Problem setting

In this work, we formulate a day-ahead planning problem from the perspective of a hydropower producer that is
assumed to own all 15 power stations in the Swedish river Skellefteälven. The reservoirs in Skellefteälven are of
varying size, ranging from smaller reservoirs by the sea outlet to complete lakes at the basin of the river. This enables
ﬂexible production schedules but requires complex planning. The producer is also assumed to be price-taking so
submitted orders do not inﬂuence the market price. The day-ahead model is limited to include only hourly orders and

2

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Order Curve

Price Independent Order
Price Dependent Order
Trading Outcome

]
h
W
M
R
U
E
[

/

e
c
i
r
P

30.26

27.51

24.75

22.00

19.25

16.50

13.75

11.00

8.25

5.50

2.75

0.00

0.00

113.34

226.68

340.02

453.36

566.70

680.04

Order Volume [MWh/h]

Figure 1: Single hourly order example, showing volume interpolation after market price settlement. The price inde-
pendent order is always accepted at market price.

regular block orders. When the market price has been realized, the producer optimizes the power production with
respect to the price and the opportunity cost of discharging water from the reservoirs. We assume that there are no
ﬁxed contracts to adhere to. In other words, all electricity production is sold for proﬁt in the market. All submitted
orders must follow the trade regulations speciﬁed by the Nordpool market. A general description of the day-ahead
problem is given in (1).

Proﬁt + Water value

maximize
Order strategy
subject to Physical limitations

−

Imbalances

Economic/legal limitations

(1)

Because next-day market prices are unknown when placing orders, we formulate a two-stage stochastic program
to generate optimal orders. The ﬁrst-stage decisions are the orders submitted to the day-ahead market. A general
description of the ﬁrst-stage problem is given in (2).

E[Revenue(Order strategy, Price, Inﬂow)]

maximize
Order strategy
subject to Trade regulations

(2)

In each second-stage scenario, uncertain parameters are realized and the electricity production is optimized with
respect to proﬁts and water value while satisfying the settled order commitments. A general description of the second

3

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

stage is given in (3)

˜w

Initializer network

x0

Sequence generator

xt

s

s

Figure 2: Noise-driven RNN forecaster architecture.

maximize
Production schedule

Proﬁt(Price) + Water value

Imbalances

−

subject to Commitments(Order strategy, Price)

Hydrological balance(Inﬂow)
Electricity production
Load balance(Commitments)

(3)

In addition, the producer can take recourse decisions by trading surplus or shortage in a balancing market. Both
market prices and local water inﬂows to the reservoirs are considered uncertain. Apart from short-term randomness,
both parameters are subjected to large seasonal variations. Electricity prices in the Nordic region are generally higher
in the winter period and the local inﬂows vary considerably over the year due to snowmelt.

2.4 Problem parameters

We now list the set of parameters required to deﬁne the day-ahead problem. We introduce deterministic parameters
and uncertain parameters separately.

The deterministic parameters constitute physical hydro plant parameters and trade regulations. Physical parameters for
the power stations in Skellefteälven are available in [12]. These include river topology, reservoir capacities, discharge
limits, and water travel time between adjacent stations. Trade regulations, such as trading fees and order limits, are
available at NordPool [13].

The uncertain parameters consist of market prices and local inﬂows to the reservoirs. Historical data is available for
both quantities and can be used to create statistical models for the random parameters. Historical price data between
2013 and 2018 is available on NordPool [14]. Historical local inﬂow data in Skellefteälven between 1999 and 2018
was acquired from the Swedish Meteorological and Hydrological Institute (SMHI), using the S-HYPE model [15].
The model provides daily hydro ﬂow measurement readings at every river location by a nearby observation node.

3 Implementation

In this section, we go through the implementation details of this work.

3.1 Noise-driven RNN forecasting

We give a general overview of the noise-driven RNN design used to create the price and inﬂow forecasters. As is
common in deep learning applications, hyperparameter tuning involves a lot of trial and error. Therefore, we only
present the ﬁnal network architectures and the relevant hyperparameter values. All networks are implemented and
trained using Flux.jl [16].

3.1.1 Network structure

The price forecaster and the inﬂow forecaster share a similar structure. The main aim of this proposed structure is
to enable forecasting of sequential data with seasonal variation, without having to rely on long input sequences. The
general structure of the forecaster is shown in Figure 2.

The proposed network structure consists of two key components. First, an initializer network is used to compute the
initial state of the forecasted sequence. The inputs to the initializer network are a set of seasonal indicators and a
Gaussian noise signal. The initializer has a deep structure with a set of dense layers, all having the standard form

y = σ(W x + b).

4

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Dense

0.5

Dense

relu
0.5

Dense

relu
0.5

Dense

˜w

m

128

2

→

128

→

128

128

128

→

128

1

→

x0

Figure 3: Initializer in the price forecaster. Activation functions and dropout values between layers are given above
the neuron links.

Some layers use rectiﬁed linear units as their activation functions to introduce nonlinearity to the network.

Next, the computed initial state is passed to a sequence generator, which is a network that includes a recurrent layer of
the form

ht = f (xt, ht−1)
yt = g(ht).

Here, xt is the input, ht is a hidden persistent state, and yt is the output. The memory state ht enables sequence
learning. We construct the recurrent layer using Gated Recurrent Units (GRU), ﬁrst introduced in [17]. A gated unit
includes an update state that decides what parts of the memory to keep, and a forget state that decides what parts of
the memory to drop. The use of GRU based networks has proven useful in similar applications [7]. The inputs to the
sequence generator are given by the previous sequence value and seasonal indicators. Here, the seasonal indicators
also include the current timestep of the sequence. This is used to increase the chance of learning sequential patterns
in the data. Similar to the initializer, the sequence generator also includes a set of dense layers. In both the initializer
network and the sequence generator, a dropout mechanism is added between layers. Consequently, randomness is
present in the network through both the Gaussian input to the initializer and the random removal of neural links. This
makes training more difﬁcult but increases the generality of the resulting network.

In brief, a forecasted sequence of length T is created in two steps. The initial value x0 is computed by the initializer
network. Afterward, the remaining T
1 values are computed by letting data ﬂow recursively through the sequence
generator T

1 times, starting with x0. This is the basis for both the price forecaster and the inﬂow forecaster.

−

−

3.1.2 Network architectures

The price forecaster outputs a 24-hour price sequence for the upcoming day. The initializer architecture is shown in
Figure 3. The output layer combines the values of the neurons in the ﬁnal hidden layer into a proposed initial value.
Apart from the one-dimensional Gaussian input, the initializer is also supplied with the current month.

The sequence generator is a three-layered network, as shown in Fig 4. The ﬁrst layer is a GRU based layer with
64 hidden neurons. It is followed by a dense layer of 64 hidden neurons and ReLU activation functions. A dropout
mechanism of value 0.4 is applied between the recurrent layer and the dense layer. The output layer combines the
neuron values of the dense layer into the next sequence value, which is also fed back into the network until the full
sequence has been computed. Apart from the previous sequence value, the sequence generator is also supplied with
the current month and the current hour. A code excerpt exemplifying how the components of the price forecaster is
created in Flux.jl is given in Listing 2.

Listing 1: Deﬁnition of the price forecaster components in Flux.jl

✞

initializer = Chain(Dense(2,128),
Dropout(0.5),
Dense(128,128,relu),
Dropout(0.5),
Dense(128,128,relu),
Dropout(0.5),
Dense(128, 1))

sequence_generator = Chain(GRU(3, 64),

✝

Dropout(0.4),
Dense(64,64,relu),
Dense(64, 1))

☎

✆

The sequence generator is a three-layered network, as shown in Fig 4. The ﬁrst layer is a GRU based layer with
64 hidden neurons. It is followed by a dense layer of 64 hidden neurons and ReLU activation functions. A dropout
mechanism of value 0.4 is applied between the recurrent layer and the dense layer. The output layer combines the

5

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

xt−1
t
m

GRU

0.4

Dense

relu

64

3

→

64

→

64

64

1

→

xt

Figure 4: Sequence generation network for the price forecaster. The output is fed back into the system until the full
sequence is generated. The seasonal parameters are given by the current month and hour.

Dense

0.5

Dense

relu
0.5

Dense

relu
0.5

Dense

˜w

w

16

→

128

128

→

128

128

128

→

128

15

→

x0

Figure 5: Initialization network architecture for the inﬂow forecaster. Activation functions and dropout values between
layers are given above the neuron links. The seasonal parameter is given by the current week.

neuron values of the dense layer into the next sequence value, which is also fed back into the network until the full
sequence has been computed. Apart from the previous sequence value, the sequence generator is also supplied with
the current month and the current hour. A code excerpt exemplifying how the components of the price forecaster is
created in Flux.jl is given in Listing 2.

Listing 2: Deﬁnition of the price forecaster components in Flux.jl

✞

initializer = Chain(Dense(2,128),
Dropout(0.5),
Dense(128,128,relu),
Dropout(0.5),
Dense(128,128,relu),
Dropout(0.5),
Dense(128, 1))

sequence_generator = Chain(GRU(3, 64),

✝

Dropout(0.4),
Dense(64,64,relu),
Dense(64, 1))

☎

✆

The inﬂow forecaster is slightly more involved. The reason for this is that we wish to forecast inﬂows to all 15 power
stations simultaneously. Besides, inﬂows between adjacent stations in the river are positively correlated. The time
increment is days as opposed to hours, and the forecast horizon is set to one week. The initializer architecture is
shown in Figure 5. It has the same structure as the price network, but uses the current week as the seasonal input
parameter.

The sequence generator is a three-layered network with larger hidden layers than the price forecaster. The ﬁrst layer
is a GRU based layer with 128 hidden neurons. It is followed by a dense layer of 128 hidden neurons and ReLU
activation functions. A dropout layer of value 0.4 is applied between the recurrent layer and the dense layer. The
output layer combines the neuron values of the dense layer into the next sequence value, which now has length 15.
Again, the computed ﬂow vector is fed back into the network until inﬂows for the full week have been computed.
Apart from the previous sequence value, the sequence generator is also supplied with the current week and the current
day. The sequence generator architecture for the ﬂow forecaster is presented in Fig. 6.

3.1.3 Training

The training procedure involves standard methods from the ﬁeld of deep learning. The price data is sorted into daily
curves, and the inﬂow data is sorted into weekly curves. Appropriate seasonal parameters are added to each data
chunk. About 10 % of each dataset is removed and used as validation sets. The training procedure operates in epochs.
Each epoch, the network generates the desired output using the given input in each chunk and then compares it to the
actual output in the chunk using a mean-square cost function. The derivatives of the cost function are then propagated
backward through the network using the chain rule and are then used to update the network weights. We use the
ADAM [18] optimizer to improve the weights, which is known to be effective when training networks on sequential

6

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

GRU

relu
0.4

GRU

relu

17

→

128

128

→

128

128

15

→

xt

xt−1
t
w

Figure 6: Sequence generation network for the inﬂow forecaster. The output is fed back into the system until the full
sequence is generated. The seasonal parameters are given by the current week and day.

data. After updating all weights, we reset the internal memory of the recurrent layers. This is done to ensure that the
performance of the network does not rely on the order it visits the datasets. We also randomize the order of the chunks
of each epoch. Every ﬁfth epoch, the performance is evaluated on the validation set, which has not been used to train
the weights. If the validation error is increasing, while the training performance still decreases, we stop the training
procedure. This is a standard approach to reduce overﬁtting. Most techniques required for implementing this training
procedure are available as tools in Flux.jl.

3.2 Day-ahead model

The day-ahead model used in this work is similar to the model introduced in [4]. We repeat the general structure
and also highlight the key details of our model. Further, we sketch how the model is implemented in our software
framework.

3.2.1 General structure

=

t1, . . . , t24}
denote indices
In the ﬁrst stage, we model the day-ahead orders to be submitted to the market. Let
make up blocks of consecutive hours in the 24-
for the 24-hour horizon of the upcoming day. The set
{
p1,t, . . . , pP,t}
hour period. In order to avoid non-linear relations in the model, we ﬁx a set of hourly price levels
Pt =
to bid at beforehand. We explain how these prices are chosen in a following subsection. The block order prices are
t , xD
determined by calculating averages of the available prices levels over the given blocks. We introduce xI
p,t, and
xB
p,b to represent price independent orders, price dependent orders, and block orders respectively. As per NordPool
regulations, the volumes in a price dependent sell order have to be constant or increasing with increasing prices. We
enforce this using constraints. In addition, we constrain the total volume offered to the market to not exceed 200%
of the production capacity. Consequently, we allow imbalances in the order commitments, but limit the maximum
imbalance already in the ﬁrst stage.

b1, . . . , bB}

=

B

T

{

{

In the second stage, we model the order commitments after price realization as well as the production schedule after
t and yB
inﬂow realization. We introduce the random variables ρω
b
represent the committed hourly volumes and the committed block volumes respectively. Every hour t, the dispatched
hourly volumes are determined through linear interpolation:

t , that describe the hourly market price. Let yH

ρω
t −
pi+1,t −
The dispatched block volumes are given by

t = xI
yH

t +

pi,t

pi,t

xD
i+1,t +

pi+1,t −
pi+1,t −

ρω
t
pi,t

xD
i,t

pi,t ≤

ρω
t ≤

pi+1,t.

where

and

| Xt∈b
Next, we model the production. Let
index the 15 hydroelectric power stations in Skellefteälven.
For each plant and hour, let Qh,s,t and Sh,t denote the water discharged and spilled, respectively. Further, let Pt denote
the total volume of electricity produced each hour. We employ a piecewise linear approximation of the generation
curve of each station. In other words,

|
h1, . . . , h15}

H

=

{

xB
yB
b =
p,b
Xp: ¯p(p,b)≤ ¯ρω
1
b

b

|

| Xt∈b

¯p(i, b) =

pi,t

¯ρω
b =

1
b

ρω
t .

Pt =

µh,sQh,s,t,

Xs∈S

7

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

where µh,s is the marginal production equivalent of station h and segment s. The load balance is given by

yH +

Xt∈b,b∈B

yB
b −

Pt = y+

t −

y−
t .

In each hour, any imbalance between committed volumes and produced volumes is equal to the difference between the
imbalance variables y+
is sold to
the balancing market. Finally, let Rh,t denote the reservoir contents in plant h during hour t. Flow conservation each
hour is given by

is bought from the balancing market, and any surplus y−
t

t . Any shortage y+
t

t and y−

Mh,t = Mh,t−1

+

−

Xi∈Qu(h) Xs∈S
Qh,s,t −

Xs∈S

Qi,s,t−τih +

Si,t−τih + V ω
h

Xi∈Su(h)

Sh,t

h are random variables describing the local inﬂow to each plant. The sets

Here, V ω
Su(h) contain upstream
plants where discharge and/or spillage can reach plant h through connecting waterways. Note that the water travel
times τih between power stations are included in the incoming ﬂow to each plant. Internally, this is modeled by
introducing auxiliary variables and constraints. Variable limits and the introduced parameters are all included in the
deterministic data sets for Skellefteälven. The revenue from a production schedule satisfying the above relations is
given by

Qu(h) and

t yH
ρω

t +

b

b yB
¯ρω
|

b +

|

αtρω

t y−

t −

βtρω

t y+

t + W (M1,24, . . . , M15,24).

|

b

Xb∈B

Xt∈T

b yB
¯ρω
|

Xt∈T
Note that, for any committed block order yB
b , the order volume is dispatched every hour in the block at average market
b is earned. The imbalance volumes are traded at penalized prices, using penalty factors αt and
price. Hence,
βt, for discouragement. It is hard to accurately model this penalty. Here, we use a 15% penalty during peak hours, and
10% otherwise. These values are based on observations of historic values, but can not be considered accurate. The
ﬁnal term in the revenue is the expected future value of water, which is a function of the water volumes that remain in
the reservoirs after the period. In the following section, we introduce a polyhedral approximation of this function that
can be modelled with linear terms. For now, we simply denote the water value by W . In summary, stochastic program
modeling the day-ahead problem is in essence given by

maximize
t ,xD
xI
i,h,xB
i,b

s.t.

Eω

ρω
t yH

t +

"
Xt∈T
yH
t = xI

t +

b

¯ρω
b yB

b +

|

|

αtρω

t y−

βtρω

t y+

t + W

#

t −
ρω
t
pi,t

xD
i,t

Xt∈T
pi+1,t −
pi+1,t −

xD
i+1,t +

Xb∈B
pi,t

ρω
t −
pi+1,t −
xB
p,b

pi,t

yB
b =

Xp: ¯p(p,b)≤ ¯ρω

b

Pt =

µh,sQh,s,t

Xs∈S

yH +

yB
b −
Xt∈b,b∈B
Mh,t = Mh,t−1

Pt = y+

t −

y−
t

(4)

+

Qi,s,t−τih +

Si,t−τih + V ω
h

Xi∈Su(h)

Sh,t

Xi∈Qu(h) Xs∈S
Qh,s,t −
¯Qh,s
¯Mh

−
Xs∈S
Qh,s,t ≤
Mh,t ≤
0, yB
b ≥
0, Sh,t ≥

0

≤

0
≤
yH
t ≥
Pt ≥

0, y+
0.

t ≥

0, y−

t ≥

0

8

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

3.2.2 Water evaluation

The expected value of saving water has a large impact on the second-stage production schedule. If the water value
is large, then it could be optimal to not produce, settle committed orders in the balancing market, and save water.
Likewise, if the water value is small, it could be optimal to overproduce and sell the excess in the balancing market.
Consequently, the water value will evidently also impact the optimal order strategy because the order commitments
are instrumental in both scenarios. Thus, the accuracy of the water evaluation is critical for hydropower producers
participating in the day-ahead market. A naive approach is to assume that all excess water can be used to produce
electricity sold at some expected future price. This leads to coarse order strategies as the optimal strategy is governed
by price variations around the expected future price. We adopt a slightly more involved approach.

Consider a dummy stochastic program, where the ﬁrst-stage decision is to decide the reservoir contents of every power
station before the upcoming week. Next, we realize a weekly sequence of inﬂows and daily price curves, using the
noise-driven RNN forecasters, and optimize the weekly production of energy sold to the market. This simpliﬁed
week-ahead problem is given by

maximize
Mh,0

Eω

s.t. Pt =

Xt∈ ˜T

ρω
t Pt

µh,sQh,s,t

Xs∈S
Mh,t = Mh,t−1

+

Qi,s,t−τih +

Si,t−τih + V ω
h

(5)

Sh,t

Xi∈Su(h)

Xi∈Qu(h) Xs∈S
Qh,s,t −
−
Xs∈S
¯Qh,s
Qh,s,t ≤
¯Mh
Mh,t ≤
0, Sh,t ≥
where the time-horizon ˜
is now a week. The objective function W = Eω[W ω(M1,0, . . . , M15,0)]
T
of this problem will be used as a water value function. The problem (5) is trivial since the optimal decision will be
to ﬁll the reservoirs with enough water to be able to run at maximum capacity in the worst-case scenario. However,
information about the water value can be extracted by solving (5) with an L-shaped type method. The L-shaped
method generates cutting planes of the form

0
≤
Pt ≥
t1, . . . , t168}

0,

≤

=

{

0

∂Wc,hMh,0 + W

wc.

≥

(6)

Xh∈H

This form supports for the concave objective function W , which is a function of reservoir content in the system. Hence,
after the algorithm has converged we have access to a polyhedral approximation of W in the form of a collection of
such cuts as (6). We can use these cuts to put an approximate value of the remaining volumes of water present in the
reservoirs after meeting order commitments. The water value approximation enters the day-ahead problem (4) in the
following way:

maximize

s.t.

+ W

· · ·
...

In practice, we use a multiple-cut formulation

∂Wc,hMh,24 + W

wc

c

.

∈ C

≥

Xh∈H

N

W =

Wi

i=1
X
as the L-shaped method solves the week-ahead problem with a large number of scenarios N more efﬁciently in this
way. The end result is still a collection of cuts that approximate a polyhedral water value function of the ﬁnal reservoir
volumes.

9

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Expected price
Price levels

]
r
u
E
[

e
c
i
r
P

60

50

40

30

20

10

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

Hour

Figure 7: Expected daily electricity price out of 1000 samples from the RNN forecaster. Two standard deviations
above and below the expected price is shown each hour.

3.2.3 Price levels

The price-dependent hourly orders and the block orders are speciﬁed at pre-chosen price levels. For ﬂexibility, we
allow these levels to vary with time. The set of price levels
Pt for each hour is determined using the price forecaster.
We sample a large number of scenarios and compute the hourly mean price and the hourly standard deviation of the
resulting price curves. Next, in each hour t, we deﬁne four price levels around the mean price using multiples of the
standard deviation for that hour over all the sampled curves. We also include the mean price as an available price level.
A set of hourly price levels generated using this method is shown in Fig. 7. The aim of this price level generation
method is to allow for ﬂexibility in order placement during hours of large historical price variation. For each block
b
b for
each of the ﬁve pre-computed price levels to reﬂect the market settlement of block orders.

5
i=1 by computing mean price levels over the hours t

, we deﬁne ﬁve possible block order prices

pi,b}

∈ B

∈

{

3.2.4 Model deﬁnition

The day-ahead model is formulated in StochasticPrograms.jl [1] (SPjl), our general purpose software framework
for stochastic programming implemented in the Julia programming language. Optimization models in SPjl are deﬁned
using the algebraic modeling language JuMP [19]. To increase readability, we present an abridged version of the
day-ahead model implementation in SPjl, by obfuscating parts of the code and making slight syntax changes. The full
unabridged model is available at Github 1.

First, we deﬁne a data structure to describe the uncertain parameters using the @scenario command. We also create a
sampler object, using the @sampler command, which utilizes the noise-driven RNN forecasters to generate price curves
and inﬂows. The code is shown in Listing 3. Because we want to make use of the forecasters’ seasonal capabilities, we
also include a date ﬁeld in the sampler object. The forecasters use the provided date to determine seasonal parameter
inputs to the neural networks.

The day-ahead model deﬁnition in SPjl is presented in Listing 4. Internally, the @stochastic_model block creates
model recipes for the stage problems without actually instantiating any optimization problems. There are two special
lines in Listing 4. The @decision annotation tells the system how the ﬁrst and second stages are linked. Similarly, the
@uncertain annotation describes how scenario data enters the second stage. A speciﬁc second-stage instance is only
created when a DayAheadScenario is supplied. This deferred model instantiation technique allows us to efﬁciently in-
stantiate subproblems on remote compute nodes, by only passing model recipes and sampler objects with low memory
footprint. Consequently, we can solve large-scale day-ahead instances using parallel decomposition schemes.

1https://github.com/martinbiel/HydroModels.jl

10

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

✞

@scenario DayAheadScenario = begin

Listing 3: Day-ahead scenario deﬁnition in SPjl

ρ::PriceCurve{Float64}
V::Inflows{Float64}

end

@sampler RNNDayAheadSampler = begin

date::Date
price_forecaster::PriceForecaster
flow_forecaster::FlowForecaster

@sample DayAheadScenario begin

price_curve = forecast(sampler.price_forecaster, month(sampler.date))
flows = forecast(sampler.flow_forecaster, week(sampler.date))
return DayAheadScenario(PriceCurve(price_curve), Inflows(flows))

end

end

✝

3.3 Algorithm details

☎

✆

We discuss the algorithmic procedure used to solve the day-ahead problem (4). We will base the discussion around
solving a general stochastic program of the form

minimize
x∈X

Eω[F (x, ξ(ω))].

(7)

We use a sampled average approximation (SAA) scheme to solve (1). This is a well-established approach (See for
example [20] for a theoretical introduction and [21] for an extensive computational study). In short, the algorithm
operates by calculating provable conﬁdence intervals around the optimal value (VRP), proceeding until the length of
the conﬁdence interval is within some relative tolerance. We then generate the deterministic solution and calculate
a conﬁdence interval around the expected value of the expected value solution (EEV). Afterwards, we calculate a
conﬁdence interval around the VSS as the difference between the VRP and the EEV.

The conﬁdence interval is calculated as follows. Let
the distribution of ξ. For each i, consider the sampled problem

}

{

ξi

i=1 where ξi =
M

z∗
n = min
x∈X

1
n

n

j=1
X

F (x, ξi

j ).

ξi
j}

{

n
j=1 be M sets of n i.i.d samples from

(8)

The authors of [20] show that Eω[z∗
z∗
n]
n+1
bounds Ln,M that increases with n. The M batches of sample sets can be used to construct an unbiased estimator
(cid:2)

n]. We can use these results to construct lower

z∗ and that Eω

Eω[z∗

≥

≤

M

1
M

min
x∈X

1
n

(cid:3)
n

F (x, ξi
j )

j=1
X
n, which is then used as a lower bound estimate. Next, a conﬁdence interval is constructed around the estimate

i=1
X

of z∗
using the sample variance

σ2
M =

M

1

M

1

−

i=1
X

min
x∈X



1
n

n

j=1
X

F (x, ξi
j )

−



2

.

Ln,M 


For practical purposes, M is relatively small, i.e., on the order of 101. Therefore, we construct conﬁdence intervals
around Ln,M using the α-critical value of the t-distribution with M
1 degrees of freedom, as opposed to using a
normal distribution. The approximate (1

α) conﬁdence interval is then given by

−

−

(cid:21)
The upper bound is computed from a suboptimal candidate solution ˆx. It holds that

(cid:20)

Ln,M −

tα/2,M−1σ2
M
√M

, Ln,M +

tα/2,M−1σ2
M
√M

.

z∗(ˆx) = Eω[F (ˆx, ξ(ω))]

z∗

≥

11

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Listing 4: Day-ahead problem deﬁnition in SPjl. The code has been condensed for readability.

✞

@stochastic_model begin
@stage 1 begin

@parameters horizon indices data
@unpack hours, plants, bids, blockbids, blocks = indices
@unpack hydrodata, regulations = data
@decision(model, xI [t = hours] >= 0)
@decision(model, xD[p = bids, t = hours] >= 0)
@decision(model, 0 <= xB[p = blockbids, b = blocks] <= blocklimit)
# Increasing bid curve
@constraint(model, bidcurve[p = bids[1:end-1], t = hours],

xD[p,t] <= xD[p+1,t])

# Maximal bids ...

end
@stage 2 begin

@parameters horizon indices data
@unpack hours, plants, segments, blocks = indices
@unpack hydrodata, water_value, regulations, bidlevels = data
@uncertain ρ, V from ξ::DayAheadScenario
@variable(model, yH[t = hours] >= 0)
@variable(model, yB[b = blocks] >= 0)
@recourse(model, y+[t = hours] >= 0)
@recourse(model, y−[t = hours] >= 0)
@variable(model, 0 <= Q[h = plants,s = segments,t = hours] <= Q_max[s])
@variable(model, S[h = plants,t = hours] >= 0)
@variable(model, 0 <= M[h = plants,t = hours] <= M_max[p])
@variable(model, W[i = 1:nindices(water_value)])
@variable(model, H[t = hours] >= 0)
@expression(model, net_profit,

sum(ρ[t]*yH[t] for t in hours)
+ sum(|b|*(mean(ρ[hours_per_block[b]])*yB[b] for b in blocks))

@expression(model, intraday,

sum(penalty(ξ,t)*y+[t] - reward(ξ,t)*y−[t] for t in hours))

@expression(model, value_of_stored_water,

-sum(W[i] for i in 1:nindices(water_value)))

@objective(model, Max, net_profit - intraday + value_of_stored_water)
# Bid-dispatch links
@constraint(model, hourlybids[t = hours],

yH[t] == interpolate(ρ[t], bidlevels, xD[t]) + xI [t])

@constraint(model, bidblocks[b = blocks],

yB[b] == sum(xB[j,b] for j in accepted_blockorders(b)))

# Hydrological balance
@constraint(model, hydro_constraints[h = plants, t = hours],

M[h,t] == (t > 1 ? M[h,t-1] : M0[h])
+ sum(Q[i,s,t-τ] for i in intersect(Qu[h], plants), s in segments)
+ sum(S[i,s,t-τ] for i in intersect(Su[h], plants), s in segments)
+ V[h] - sum(Q[h,s,t] for s in segments) - S[h,t])

# Production
@constraint(model, production[t = hours],

H[t] == sum(µ[s]*Q[h,s,t] for h in plants, s in segments))

# Load balance
@constraint(model, loadbalance[t = hours],

yH[t] + sum(yB[b] for b in active(t)) - H[t] == y+[t] - y−[t])

# Water travel time ...
# Polyhedral water value
@constraint(model, water_value_approximation[c = 1:ncuts(water_value)],

sum(∂W[c,h]*M[h,T] for h in plants)
+ sum(W[i] for i in cut_indices(c)) >= w[c])

end

end

✝

12

☎

✆

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

for all ˆx. For a given ˆx, we estimate z∗(ˆx) by sampling T batches
unbiased estimator

ξi

{

}

i=1 where ξi =
T

ξi
j}

{

N
j=1 and construct the

M

1
T

1
N

N

F (ˆx, ξi

j),

(9)

j=1
X
which is then used as an upper bound Un,T estimate. Here, N can be a large number because (9) simply amounts to
solving N independent smaller optimization problems. Again, the sample variance and the t-distribution are used to
calculate a conﬁdence interval around Un,T :

i=1
X

Un,T −

(cid:20)

tα/2,T −1σ2
T
√T

, Un,T +

tα/2,T −1σ2
T
√T

.

(cid:21)

For convenience, ˆx is calculated by solving a single SAA instance of size n at each iteration. Now, the algorithm
proceeds by iteratively increasing n, calculating a 1

Ln,M :

−

2α conﬁdence interval around Un,T −
tα/2,T −1σ2
tα/2,M−1σ2
T
M
√M
√T

+

(cid:21)

0, Un,T −

Ln,M +

(cid:20)

and repeating until the gap is within some relative tolerance. It could hold that Un,T < Ln,M due to the sampling
error, whereupon the procedure simply continues with a slightly larger n.

The SAA procedure involves solving numerous sampled instances of increasing size. This is computationally de-
manding, so we employ parallelization strategies. We distribute every instance on a 32-core compute node, using the
capabilities of SPjl. Further, we solve the instances using a distributed L-shaped algorithm. A review of our compu-
tational experience with these algorithms is given in [2] and [1]. Our results indicate that trust-region regularization
is appropriate in reducing convergence times when solving day-ahead problem instances. Furthermore, we found that
an aggregation scheme can signiﬁcantly reduce computational times in the distributed setting, through load balancing
between master and workers as well as reduced communication latency.

Finally, we sketch the calculation of the value of the stochastic solution. After convergence, the result of the above
procedure is a conﬁdence interval [LV RP , UV RP ] around the optimal value (VRP) of the day-ahead problem. Next,
the expected value solution is cheaply computed through

¯x = arg min
x∈X

F (x, ¯ξ)

where ¯ξ = Eω[ξ(ω)] is the expected scenario. A conﬁdence interval around the expected result of using the expected
value solution (EEV)

(cid:8)

(cid:9)

EEV =

1
¯N

¯N

i=1
X

F (¯x, ξi),

zα/2σ2
√ ¯N

EEV

−

EEV

(cid:20)

, EEV +

zα/2σ2

EEV

√ ¯N (cid:21)

,

is given by

where

σ2
EEV =

1

¯N

1

−

i=1
X

¯N

(F (¯x, ξi)

EEV )2.

−

ξi}

¯N
Here,
i=1 is a large number of sampled scenarios. Now, if there is no overlap between the conﬁdence interval
around VRP and the conﬁdence interval around EEV, there is a VSS that is statistically signiﬁcant to the chosen
signiﬁcance level. A conﬁdence interval around this VSS is then given by

{

[LV RP −

UEEV , UV RP −

LEEV ]

4 Numerical Experiments

In this section, we present our experimental results.

13

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Historical prices

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

Forecasted prices

200

150

100

50

200

150

100

50

]
r
u
E
[

e
c
i
r
P

]
r
u
E
[

e
c
i
r
P

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16 17 18 19 20 21 22 23 24

Hour

Figure 8: Historical electricity price curves in January and electricity price curves generated using the RNN forecaster
in the same period.

4.1 Day-ahead forecasting

We present the price forecaster and the inﬂow forecaster separately. Figure 8 shows historical price curves from
January between the years 2013 and 2016, together with 200 price curves sampled using the RNN forecaster. The
forecaster is set to predict curves in January. The neural network has been able to learn the overall shape of a typical
electricity price curve. Price spikes typically occur in the morning when people wake up, and in the afternoon when
people arrive home back from work. The network does not predict the extreme outliers of the past but does predict
some daily curves with signiﬁcant spikes. Next, we consider varying the month considered by the RNN forecaster.
The result is shown in Figure 9. Each month, the shape of the daily price curve is consistent. However, the forecaster
predicts larger prices in general in the winter period. This is consistent with the historical data, as electricity price in
the Nordic region is higher in winter due to the heating demand. Similar results are obtained for the ﬂow forecast.

4.2 Day-ahead planning

We have considered the computational performance of the algorithms in depth before [2]. Therefore, we refrain from
that here and focus on the model output.

We solve the day-ahead problem for every month of the year by supplying an arbitrary date for each month to the
RNN forecaster. By ﬁrst solving some small sampled models, we note that the relative VSS is typically on the order of
10−3. Therefore, we run the sequential SAA algorithm until the relative length of the conﬁdence interval around the
optimum is of order 10−4 to a signiﬁcance level of 95%. Consequently, the resulting VSS conﬁdence intervals have
a signiﬁcance level of 90%. We initialize the algorithm at n = 16 number of samples and double the amount each
iteration.

14

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Forecasted prices

75

50

25

]
r
u
E
[

e
c
i
r
P

Jan

F eb

M ar

Apr M ay

Jun

Jul

Aug

Sep

Oct

N ov

Dec

Figure 9: Daily electricity price curves predicted by the RNN forecaster in every month of the year.

≈

Every month, the SAA algorithm terminates at n
2000. The resulting VRP and EEV conﬁdence intervals are
presented in Figure 10. The conﬁdence intervals around the VRP values are tight. For example, the relative length of
10−5. A statistically signiﬁcant VSS is ensured to the given conﬁdence
the VRP conﬁdence interval in March is 9.73
level as long as the conﬁdence intervals around VRP and EEV do not overlap. It is no surprise that tight intervals are
required here as there is an overlap in both April and November even at this low relative tolerance. In all other months,
we can calculate a statistically signiﬁcant VSS value. These seasonal VSS values are presented in more detail in
Figure 11. Notably, the relative VSS is small, ranging between 0.1%
0.4%. However, the value function includes
the water evaluation, which increases the order of magnitude signiﬁcantly. With respect to only the daily market proﬁt,
the relative VSS is about 1%. Besides, these constitute daily marginal proﬁts. Hence, the VSS accumulates and could
be considered more signiﬁcant if the stochastic programming approach is employed over a longer time period.

×

−

The optimal order strategy in January, when solving a 2000-scenario day-ahead SAA instance, is shown in Fig. 12.
The stochastic solution uses a large block order in the afternoon where a large mean price is expected. In comparison,
the deterministic strategy obtained by solving the expected value problem is shown in Fig. 13. The deterministic
strategy mostly utilizes price-independent orders, which is less ﬂexible than the stochastic solution.

The day-ahead VSS was shown to be sensitive to the imbalance penalty [3]. We investigate this by letting the penalty
be an increasing percentage of the market price in each scenario. An imbalance penalty of more than 100% is not
realistic, but can be interprested as a penalty formulation of a zero imbalance constraint. This models the case where
no imbalance in the market commitments is desired, which could be beneﬁcial to some producers. For larger penalty
values, a statistically signiﬁcant VSS can be achieved with fewer scenarios. Here, 1000 scenarios are used to calculate
the VSS values presented in Fig. 14. It should be noted that the stochastic program is more complicated and takes
about twice as long to solve with large imbalance penalties. The resulting order strategy is shown in Fig. 15 and the
deterministic counterpart is shown in Fig. 16. The stochastic solution is far more conservative to reduce the risk of
imbalance. The deterministic strategy places larger orders and still makes heavy use of price-independent orders. The
risk of imbalance is increased with this strategy, which is reﬂected in the VSS.

15

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Day-ahead

5.268

106

×

Day-ahead VRP
Day-ahead EEV

5.257

106

×

5.139

106

×

5.137

106

×

5.7 × 106

5.6 × 106

5.5 × 106

]
r
u
E
[

t
5.4 × 106
ﬁ
o
r
P

5.3 × 106

5.2 × 106

5.1 × 106

Jan

Feb

Mar

Apr

May

Jun

Jul

Aug

Sep

Oct

Nov

Dec

Month

Figure 10: Seasonal variation of day-ahead VRP and EEV, including 95% conﬁdence intervals. Scale clariﬁcations
are shown for March and June. The VSS is statistically signiﬁcant in all months except April and November.

5 Discussion and conclusion

The results presented in this work are encouraging. However, the results are only as accurate as the water evaluation.
The approach presented here for valuing the water is more involved than just assuming that all excess water can be sold
at some conjectured future market price. However, it is probably not an accurate indicator of the water value. After
scenario realization, the week-ahead problem we formulate assumes complete knowledge about the price curves and
inﬂows for the upcoming week. A more precise formulation would involve a multi-stage stochastic program where
the uncertain prices and inﬂows are learned sequentially. Another factor is the assumption that all power stations
in the river are owned by the same ﬁctitious hydropower producer. Skellefteälven is in reality operated by three
separate companies and production schedules need to be coordinated. Hence, game-theoretic approaches are required
for optimal planning. Finally, the RNN forecasters are trained on historical price and inﬂow data independently. In the
Nordic region, hydropower constitutes more than half of the total electricity production. Consequently, the water value
has a large impact on the electricity price. Thus, one should arguably consider training one single RNN forecaster on
both datasets simultaneously, as electricity price and local inﬂow are most probably correlated.

In summary, a novel forecasting technique based on noise-driven recurrent neural networks has been presented. A
key feature is that accurate forecasts can be generated without using lagged input sequences from historical data. We
employ this forecasting technique to generate samples of day-ahead electricity prices and local reservoir inﬂows. We
then formulate and solve a stochastic program for determining optimal day-ahead order strategies in the Nordic market,
using the forecasters for scenario generation. The RNN forecasters predict accurate seasonal trends from historical
data using only Gaussian signals and season indicators as input. The SAA algorithm yields tight conﬁdence intervals
around the stochastic solution. This allows us to derive statistically signiﬁcant VSS of the stochastic order strategies
for most months of the year.

16

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

3 × 104

Day-ahead VSS

Day-ahead

2 × 104

]
r
u
E
[

t

ﬁ
o
r
P

1 × 104

0

Jan

Feb

Mar

Apr

May

Jun

Jul

Aug

Sep

Oct

Nov

Dec

Month

Figure 11: Seasonal variation of day-ahead VSS, including 90% conﬁdence intervals. Note that the VSS is not
statistically signiﬁcant in April and November.

17

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Single Orders

D
e
p
e
n
d
e
n
t

1
.
2
e
+
0
3

1
.
3
e
+
0
3

2.0e+03

691.5

2.0e+03

615.8

907.1

869.7

323.9

644.5

658.7

690.5

733.0 734.1

698.1

810.3

408.3 349.1 363.9 364.1

367.5

98.62

1
.
1
e
+
0
3

97.42

97.15

109.9

1.5e+03

1.5e+03

1
.
0
e
+
0
3

1
.
1
e
+
0
3
1.0e+03

1.0e+03

45.57

74.55

510.7

486.0

482.0

1
.
0
e
+
0
3

1
.
0
e
+
0
3

615.1

645.9

689.9

551.9

606.1

303.5

0.0

l

V
o
u
m
e
s
[

M
w
h
]

I

n
d
e
p
e
n
d
e
n
t

l

V
o
u
m
e
[

M
W
h
]

]
h
W
M
R
U
E
[

/

e
c
i
r
P

78.68

65.56

52.45

39.34

26.23

13.11

0.00

685.7

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

]
h
W
M
R
U
E
[

/

e
c
i
r
P

Block Orders

Price [EUR/MWh]

Volume [MWh/h]

44.20

0.05

23.74

11.70

17.72

56.37

0.17

53.78

0.06

48.17

41.82

0.31

24.01

0.26

23.37

0.18

13.60

399.3

0.87
0.02

30.52

500.0

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

Hour

Figure 12: Optimal order strategy when solving a 2000-scenario day-ahead SAA instance in January.

18

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Single Orders

1
.
2
e
+
0
3

0.0

2
.
0
e
+
0
3

614.3

0.0

674.2 646.6 626.1

686.6 704.0 735.3 735.4 924.5 889.3 803.5 930.8 853.3 831.0

862.6 908.6 0.15

14.67 980.7 980.4

1
.
0
e
+
0
3

1
.
0
e
+
0
3

1
.
0
e
+
0
3

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

D
e
p
e
n
d
e
n
t

l

V
o
u
m
e
s
[

M
w
h
]

I

n
d
e
p
e
n
d
e
n
t

l

V
o
u
m
e
[

M
W
h
]

Block Orders

Price [EUR/MWh]

Volume [MWh/h]

23.89

500.0

12.54

496.3

]
h
W
M
R
U
E
[

/

e
c
i
r
P

78.68

65.56

52.45

39.34

26.23

13.11

0.00

]
h
W
M
R
U
E
[

/

e
c
i
r
P

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

Hour

Figure 13: Optimal order strategy when solving the day-ahead expected value problem in January.

19

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Day-ahead

Day-ahead VSS

2.5 × 105

2.0 × 105

]
r
u
1.5 × 105
E
[

t
ﬁ
o
r
P
1.0 × 105

5.0 × 104

0

0

250

500

750

1000

Penalty percentage [%]

Figure 14: Day-ahead VSS as a function of imbalance penalty, including 90% conﬁdence intervals calculated susing
1000 scenarios. The penalty is given as a percentage of the market price. The VSS is not statistically signiﬁcant for
low penalty values.

20

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Single Orders

D
e
p
e
n
d
e
n
t

l

V
o
u
m
e
s
[

M
w
h
]

671.7 644.9 612.9 132.4

5.27

15.64

0.0

119.8 26.48 52.73 59.76

190.5

1.0e+03

762.0

770.4

1.0e+03

1
.
0
e
+
0
3

1.0e+03

1
.
0
e
+
0
3
1.0e+03
1.0e+03
1.0e+03
1.0e+03

1
.
0
e
+
0
3

180.3 199.3

114.5

50.93

73.82 187.0

290.7

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

Block Orders

I

n
d
e
p
e
n
d
e
n
t

l

V
o
u
m
e
[

M
W
h
]

]
h
W
M
R
U
E
[

/

e
c
i
r
P

79.17

65.98

52.78

39.59

26.39

13.20

0.00

]
h
W
M
R
U
E
[

/

e
c
i
r
P

46.03

46.41

25.64

0.21

25.62

1.29

18.05

16.67

16.70

15.46

44.61

5.72

Price [EUR/MWh]

Volume [MWh/h]

0.99

0.01

0.03
0.02

33.29

23.78

4.98

215.2

500.0

87.37

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

Hour

Figure 15: Optimal order strategy when solving a 1000-scenario day-ahead SAA instance, with 1000% imbalance
penalty, in January.

21

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

Single Orders

1.3e+03

1.3e+03

1.3e+03

191.8

1
.
3
e
+
0
3

1
.
3
e
+
0
3

235.8

166.5

1
.
3
e
+
0
3

3.65

192.9

129.9

127.7

14.52

1
.
1
e
+
0
3

0.0

0.0

0.0

0.0

0.0

0.0

0.0

0.0

0.0

0.0

0.0

674.2 646.8 626.1 648.0 686.6 704.9

69.67

208.2

284.4 284.4

1
.
0
e
+
0
3

1
.
0
e
+
0
3

1
.
0
e
+
0
3

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

D
e
p
e
n
d
e
n
t

l

V
o
u
m
e
s
[

M
w
h
]

I

n
d
e
p
e
n
d
e
n
t

l

V
o
u
m
e
[

M
W
h
]

Block Orders

Price [EUR/MWh]

Volume [MWh/h]

32.54

16.70

23.78

300.2

500.0

196.3

]
h
W
M
R
U
E
[

/

e
c
i
r
P

79.17

65.98

52.78

39.59

26.39

13.20

0.00

]
h
W
M
R
U
E
[

/

e
c
i
r
P

0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

Hour

Figure 16: Optimal order strategy when solving the day-ahead expected value problem, with 1000% imbalance penalty,
in January.

22

Optimal day-ahead orders using stochastic programming and noise-driven RNNs

A PREPRINT

References

[1] M. Biel and M. Johansson, “Efﬁcient stochastic programming in Julia,” arXiv preprint arXiv:1909.10451, 2019.
[2] ——, “Distributed L-shaped algorithms in Julia,” in 2018 IEEE/ACM Parallel Applications Workshop, Alterna-

tives To MPI (PAW-ATM), Nov 2018, pp. 57–69.

[3] S. Ødegaard Ottesen, A. Tomasgard, and S.-E. Fleten, “Prosumer bidding and scheduling in electricity markets,”

Energy, vol. 94, pp. 828 – 843, 2016.

[4] S.-E. Fleten and T. K. Kristoffersen, “Stochastic programming for optimizing bidding strategies of a nordic
hydropower producer,” European Journal of Operational Research, vol. 181, no. 2, pp. 916–928, sep 2007.
[5] E. K. Aasgård, C. Ø. Naversen, M. Fodstad, and H. I. Skjelbred, “Optimizing day-ahead bid curves in hydropower

production,” Energy Systems, vol. 9, no. 2, pp. 257–275, May 2018.

[6] E. K. Aasgård, S.-E. Fleten, M. Kaut, K. Midthun, and G. A. Perez-Valdes, “Hydropower bidding in a multi-

market setting,” Energy Systems, vol. 10, no. 3, pp. 543–565, Aug 2019.

[7] U. Ugurlu, I. Oksuz, and O. Tas, “Electricity price forecasting using recurrent neural networks,” Energies, vol. 11,

no. 5, p. 1255, May 2018.

[8] S. Anbazhagan and N. Kumarappan, “Day-ahead deregulated electricity market price forecasting using recurrent

neural network,” IEEE Systems Journal, vol. 7, no. 4, pp. 866–872, Dec 2013.

[9] C. A. S. Farias, A. Kadota, A. B. Celeste, and K. Suzuki, “RNN-based inﬂow forecasting applied to reservoir
operation via implicit stochastic optimization.” in Symp. Quantiﬁcation and Reduction of Predictive Uncertainty
for Sustainable Water Resources Management, 2007.

[10] P. Coulibaly and F. Anctil, “Real-time short-term natural water inﬂows forecasting using recurrent neural net-

works,” in Int. Joint Conf. on Neural Networks., vol. 6, July 1999, pp. 3802–3805 vol.6.

[11] R. Weron, “Electricity price forecasting: A review of the state-of-the-art with a look into the future,” International

Journal of Forecasting, vol. 30, no. 4, pp. 1030 – 1081, 2014.

[12] J. J. Sag, “Simulation of hydro power expansion in skellefteälven,” Master’s thesis, KTH, Optimization and

Systems Theory, 2018.

[13] NordPool, https://www.nordpoolgroup.com/, 2018.
[14] ——, “Hourly Elspot prices 2017 in EUR,” https://www.nordpoolgroup.com/globalassets/marketdata-excel-ﬁles/elspot-prices_2017_hourly_eur.xls,

2018.

[15] M. Bergstrand, S.-S. Asp, and G. Lindström, “Nationwide hydrological statistics for Sweden with high resolution

using the hydrological model S-HYPE,” Hydrology Research, vol. 45, no. 3, pp. 349–356, 11 2013.

[16] M. Innes, “Flux: Elegant machine learning with Julia,” Journal of Open Source Software, 2018.
[17] C. K. et al., “Learning phrase representations using rnn encoder-decoder for statistical machine translation,”

arXiv preprint arXiv:1406.1078, 2014.

[18] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” arXiv preprint arXiv:1412.6980, 2014.
[19] I. Dunning, J. Huchette, and M. Lubin, “JuMP: A modeling language for mathematical optimization,” SIAM

Review, vol. 59, no. 2, pp. 295–320, jan 2017.

[20] W.-K. Mak, D. P. Morton, and R. Wood, “Monte carlo bounding techniques for determining solution quality in

stochastic programs,” Operations Research Letters, vol. 24, no. 1, pp. 47 – 56, 1999.

[21] J. Linderoth, A. Shapiro, and S. Wright, “The empirical behavior of sampling methods for stochastic program-

ming,” Annals of Operations Research, vol. 142, no. 1, pp. 215–241, Feb 2006.

23

