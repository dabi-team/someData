Veriﬁcation of Deep Convolutional Neural
Networks Using ImageStars

Hoang-Dung Tran1,2, Stanley Bak3, Weiming Xiang4, and Taylor T. Johnson2

1 Department of Computer Science and Engineering, University of Nebraska, USA
2 Department of Electrical Engineering and Computer Science, Vanderbilt
University, USA
3 Department of Computer Science, Stony Brook University, USA
4 School of Computer and Cyber Sciences, Augusta University, USA

Abstract. Convolutional Neural Networks (CNN) have redeﬁned state-
of-the-art in many real-world applications, such as facial recognition,
image classiﬁcation, human pose estimation, and semantic segmentation.
Despite their success, CNNs are vulnerable to adversarial attacks, where
slight changes to their inputs may lead to sharp changes in their output
in even well-trained networks. Set-based analysis methods can detect or
prove the absence of bounded adversarial attacks, which can then be used
to evaluate the eﬀectiveness of neural network training methodology.
Unfortunately, existing veriﬁcation approaches have limited scalability
in terms of the size of networks that can be analyzed.
In this paper, we describe a set-based framework that successfully deals
with real-world CNNs, such as VGG16 and VGG19, that have high ac-
curacy on ImageNet. Our approach is based on a new set representation
called the ImageStar, which enables eﬃcient exact and over-approximative
analysis of CNNs. ImageStars perform eﬃcient set-based analysis by
combining operations on concrete images with linear programming (LP).
Our approach is implemented in a tool called NNV, and can verify the
robustness of VGG networks with respect to a small set of input states,
derived from adversarial attacks, such as the DeepFool attack. The ex-
perimental results show that our approach is less conservative and faster
than existing zonotope methods, such as those used in DeepZ, and the
polytope method used in DeepPoly.

1

Introduction

Convolutional neural networks (CNN) have rapidly accelerated progress in com-
puter vision with many practical applications such as face recognition [18], image
classiﬁcation [17], document analysis [20] and semantic segmentation. Recently,
it has been shown that CNNs are vulnerable to adversarial attacks, where a
well-trained CNN can be fooled into producing errant predictions due to tiny
changes in their inputs [8]. Many applications such as autonomous driving seek
to leverage the power of CNNs. However due the opaque nature of these models
there are reservations about using in safety-critical applications. Thus, there is
an urgent need for formally evaluating the robustness of a trained CNN.

0
2
0
2

y
a
M
4
1

]

G
L
.
s
c
[

2
v
1
1
5
5
0
.
4
0
0
2
:
v
i
X
r
a

 
 
 
 
 
 
The formal veriﬁcation of deep neural networks (DNNs) has recently become
a hot topic. The majority of the existing approaches focus on verifying safety
and robustness properties of feedforward neural networks (FNN) with the Recti-
ﬁed Linear Unit activation function (ReLU). These approaches include: mixed-
integer linear programming (MILP) [5,16,22], satisﬁability (SAT) and satisﬁabil-
ity modulo theory (SMT) techniques [14], optimization [6, 10, 21, 39, 41, 48], and
geometric reachability [28,29,33,34,38,40,42–44,47]. Adjacent to these methods
are property inference techniques for DNNs, which are also an important and
interesting research area investigated in [9]. In a similar fashion, the problem
of verifying the safety of cyber-physical systems (CPS) with learning-enabled
neural network components with imperfect plant models and sensing informa-
tion [1, 11–13, 23, 30–32, 45, 46] has recently attracted signiﬁcant attention due
to their real world applications. This research area views the safety veriﬁcation
problem in a more holistic manner by considering the safety of the whole system
in which learning-enabled components interact with the physical world.

Although numerous tools have been proposed for neural network veriﬁcation,
only a handful of methods can deal with CNNs [2, 15, 16, 26,28,29]. Moreover, in
the aforementioned techniques, only one [26] can deal with real-world CNNs, such
as VGGNet [27]. Their approach makes used of the concept of the L0 distance
between two images. Their optimization-based approach computes a tight bound
on the number of pixels that may be changed in an image without aﬀecting the
classiﬁcation result of the network. It can also eﬃciently generate adversarial
examples that can be used to improve the robustness of network. In a similar
manner, this paper seeks to verify the robustness of real-world deep CNNs. Thus,
we propose a set-based analysis method through the use of the ImageStar, a
new set representation that can represent an inﬁnite number of images. As an
example, this representation can be used to represent a set of images distorted
by an adversarial attack. Using the ImageStar, we propose both exact and over-
approximate reachability algorithms to construct reachable sets that contain
all the possible outputs of a CNN under an adversarial attack. These reachable
sets are then used to reason about the overall robustness of the network. When a
CNN violates a robustness property, our exact reachability scheme can construct
a set of concrete adversarial examples. Our approach diﬀers from [26] in two
ways. First, our method does not provide robustness guarantees for a network
in terms of the number of pixels that are allowed to be changed (in terms of L0
distance). Instead, we prove the robustness of the network on images that are
attacked by disturbances bounded by arbitrary linear constraints. Second, our
approach relies on reachable set computation of a network corresponding to a
bounded input set, as opposed to a purely optimization-based approach.

We implement the proposed method in a tool called NNV and compare it
with the zonotope method used in DeepZ [28] and the polytope method used in
DeepPoly [29]. The experimental results show that our method is less conserva-
tive and faster than any of these approaches when verifying the robustness of
CNNs. The main contributions of the paper are as follows.

– The ImageStar set representation, which is an eﬃcient representation for

reachability analysis of CNNs.

– The provision of exact and over-approximate reachability algorithms for con-

structing reachable sets and verifying robustness of CNNs.

– The implementation of the ImageStar representation and reachability algo-

rithms in NNV [36].

– Rigorous evaluation and comparison of proposed approaches, such as zono-

tope [28] and polytope [29] methods on diﬀerent CNNs.

2 Problem formulation

The reachability problem for CNNs is the task of analyzing a trained CNN with
respect to some perturbed input set in order to construct a set containing all
possible outputs of the network. In this paper, we consider the reachability of
a CNN N that consists of a series of layers L that may include convolutional
layers, fully connected layers, max-pooling layers, average pooling layers, and
ReLU activation layers. Mathematically, we deﬁne a CNN with n layers as N =
{Li}, i = 1, 2, . . . , n. The reachability of the CNN N is deﬁned based on the
concept of reachable sets.

Deﬁnition 1 (Reachable set of a CNN). An (output) reachable set RN of
a CNN N = {Li}, i = 1, 2, . . . , n corresponding to a linear input set I is deﬁned
incrementally as:

RL1
RL2

RN = RLn

(cid:44) {y1 | y1 = L1(x), x ∈ I},
(cid:44) {y2 | y2 = L2(y1), y1 ∈ RL1 },
...
(cid:44) {yn | yn = L3(yn−1) yn−1 ∈ RLn−1},

where Li(·) is a function representing the operation of the ith layer.

The deﬁnition shows that the reachable set of the CNN N can be constructed
layer-by-layer. The core computation is constructing the reachable set of each
layer Li deﬁned by a speciﬁc operation, i.e., convolution, aﬃne mapping, max
pooling, average pooling, or ReLU.

3

ImageStar

Deﬁnition 2. An ImageStar Θ is a tuple (cid:104)c, V, P (cid:105) where c ∈ Rh×w×nc is the
anchor image, V = {v1, v2, · · · , vm} is a set of m images in Rh×w×nc called
generator images, P : Rm → {(cid:62), ⊥} is a predicate, and h, w, nc are the height,
width and number of channels of the images respectively. The generator images
are arranged to form the ImageStar’s h × w × nc × m basis array. The set of
images represented by the ImageStar is given as:

= {x | x = c + Σm

i=1(αivi) such that P (α1, · · · , αm) = (cid:62)}.

Θ

(cid:74)

(cid:75)

Fig. 1: An example of an ImageStar.

Sometimes we will refer to both the tuple Θ and the set of states
as Θ. In
this work, we restrict the predicates to be a conjunction of linear constraints,
P (α) (cid:44) Cα ≤ d where, for p linear constraints, C ∈ Rp×m, α is the vector of
m-variables, i.e., α = [α1, · · · , αm]T , and d ∈ Rp×1. A ImageStar is an empty
set if and only if P (α) is empty.

Θ

(cid:75)

(cid:74)

Example 1 (ImageStar). A 4 × 4 × 1 gray image with a bounded disturbance
b ∈ [−2, 2] applied on the pixel of the position (1, 2, 1) can be described as an
ImageStar depicted in Figure 1.

Remark 1. An ImageStar is an extension of the generalized star set recently de-
ﬁned in [3, 4, 34, 35]. In a generalized star set, the anchor and the generators
are vectors, while in an ImageStar, the anchor and generators are images with
multiple channels. We will later show that the ImageStar is a very eﬃcient rep-
resentation for the reachability analysis of convolutional layers, fully connected
layers, and average pooling layers.

Proposition 1 (Aﬃne mapping of an ImageStar). An aﬃne mapping of
an ImageStar Θ = (cid:104)c, V, P (cid:105) with a scale factor γ and an oﬀset image β is another
ImageStar Θ(cid:48) = (cid:104)c(cid:48), V (cid:48), P (cid:48)(cid:105) in which the new anchor, generators and predicate
are as follows.

c(cid:48) = γ × c + β, V (cid:48) = γ × V, P (cid:48) ≡ P.

Note that, the scale factor γ can be a scalar or a vector containing scalar scale
factors in which each factor is used to scale one channel in the ImageStar.

4 Reachability of CNN using ImageStars

In this section, we present the reachable set computation for the convolutional
layer, average pooling layer, fully connected layer, batch normalization layer,
max pooling layer, and the ReLU layer with respect to an input set consisting
of an ImageStar.

4.1 Reachability of a convolutional layer

We consider a two-dimensional convolutional layer with following parameters:
the weights WConv2d ∈ Rhf ×wf ×nc×nf , the bias bConv2d ∈ R1×1×nf , the padding
size P , the stride S, and the dilation factor D where hf , wf , nc are the height,

0122233333111222240100000000000000Θ=c+αv=+c∈R4x4x1α,P≡(1−1)α≤(22)v∈R4x4x11width, and the number of channels of the ﬁlters in the layer respectively. Addi-
tionally, nf is the number of ﬁlters. The reachability of a convolutional layer is
given in the following lemma.

Lemma 1. The reachable set of a convolutional layer with an ImageStar input
set I = (cid:104)c, V, P (cid:105) is another ImageStar I (cid:48) = (cid:104)c(cid:48), V (cid:48), P (cid:105) where c(cid:48) = Convol(c) is
the convolution operation applied to the anchor image, V (cid:48) = {v(cid:48)
i =
ConvolZeroBias(vi) is the convolution operation with zero bias applied to the
generator images, i.e., only using the weights of the layer.

1, . . . , v(cid:48)

m}, v(cid:48)

Proof. Any image in the ImageStar input set is a linear combination of the
center and basis images. For any ﬁlter in the layer, the convolution operation
applied to the input image performs local element-wise multiplication of a local
matrix (of all channels) containing the values of the local pixels of the image
and the the weights of the ﬁlter and then combine the result with the bias to
get the output for that local region. Due to the linearity of the input image,
we can perform the convolution operation with the bias on the center and the
convolution operation with zero bias on the basis images and then combine the
result to get the output image.

Example 2 (Reachable set of a convolutional layer). The reachable set of a con-
volutional layer with single 2 × 2 ﬁlter and the ImageStar input set in Exam-
ple 1 is described in Figure 2, where the weights and the bias of the ﬁlter are







1 1

−1 0

W =

, b = −1 respectively, the stride is S = [2 2], the padding size is

P = [0 0 0 0] and the dilation factor is D = [1 1].

Fig. 2: Reachability of convolutional layer using ImageStar.

4.2 Reachability of an average pooling layer

The reachability of an average pooling layer with pooling size P S, padding size
P , and stride S is given below, with its proof similar to that of the convolutional
layer.

1233311122220100000000000000Θ=c+αv=+c'∈R2x2x1α,P≡(1−1)α≤(22)v'∈R2x2x11Θ'=c'+αv'=+α,P≡(1−1)α≤(22)0342x 1x 1x 0x -10010x 1x 1x 0x -1-1 (bias)1101-100011Lemma 2. The reachable set of a average pooling layer with an ImageStar input
set I = (cid:104)c, V, P (cid:105) is another ImageStar I (cid:48) = (cid:104)c(cid:48), V (cid:48), P (cid:105) where c(cid:48) = average(c),
V (cid:48) = {v(cid:48)
i = average(vi), average(·) is the average pooling operation
applied to the anchor and generator images.

1, . . . , v(cid:48)

m}, v(cid:48)

Example 3 (Reachable set of an average pooling layer). The reachable set of an
2 × 2 average pooling layer with padding size P = [0 0 0 0], stride S = [2 2], and
an ImageStar input set given by Example 1 is shown in Figure 3.

Fig. 3: Reachability of average pooling layer using ImageStar.

4.3 Reachability of a fully connected layer

The reachability of a fully connected layer is stated in the following lemma.

Lemma 3. Given a two-dimensional fully connected layer with weight Wf c ∈
Rnf c×mf c, bias bf c ∈ Rnf c , and an ImageStar input set I = (cid:104)c, V, P (cid:105), the reach-
able set of the layer is another ImageStar I (cid:48) = (cid:104)c(cid:48), V (cid:48), P (cid:105) where c(cid:48) = W ∗ ¯c + b,
V (cid:48) = {v(cid:48)
i = Wf c ∗ ¯vi, ¯c( ¯vi) = reshape(c(vi), [mf c, 1]). Note that it
is required for consistency between the ImageStar and the weight matrix that
mf c = h × w × nc, where h, w, nc are the height, width and number of channels
of the ImageStar.

1, . . . , v(cid:48)

m}, v(cid:48)

Proof. Similar to the convolutional layer and the average pooling layer, for any
image in the ImageStar input set, the fully connected layer performs an aﬃne
mapping of the input image which is a linear combination of the center and the
basis images of the ImageStar. Due to the linearity, the aﬃne mapping of the
input image can be decomposed into the aﬃne mapping of the center image and
the aﬃne mapping without the bias of the basis images. The ﬁnal result is the
sum of the individual aﬃne maps.

4.4 Reachability of a batch normalization layer

In the prediction phase, a batch normalization layer normalizes each input chan-
nel xi using the mean µ and variance σ2 over the full training set. Then the batch
normalization layer further shifts and scales the activations using the oﬀset β and

1233311122220100000000000000Θ=c+αv=+c'∈R2x2x1α,P≡(1−1)α≤(22)v'∈R2x2x11Θ'=c'+αv'=+α,P≡(1−1)α≤(22)034200101121.7520002.250.25the scale factor γ that are learnable parameters. The formula for normalization
is as follows.

¯xi =

xi − µ
√
σ2 + (cid:15)

, yi = γ ¯xi + β.

where (cid:15) is a used to prevent division by zero. The batch normalization layer
can be described as a tuple B = (cid:104)µ, σ2, (cid:15), γ, β(cid:105). The reachability of a batch
normalization layer with an ImageStar input set is given in the following lemma.

Lemma 4. The reachable set of a batch normalization layer B = (cid:104)µ, σ2, (cid:15), γ, β(cid:105)
with an ImageStar input set I = (cid:104)c, V, P (cid:105) is another ImageStar I (cid:48) = (cid:104)c(cid:48), V (cid:48), P (cid:48)(cid:105)
where:

c(cid:48) =

√

γ
σ2 + (cid:15)

c + β −

√

γ
σ2 + (cid:15)

µ, V (cid:48) =

√

γ
σ2 + (cid:15)

V, P (cid:48) ≡ P.

Proof. The reachable set of a batch normalization layer can be obtained in a
straightforward fashion using two aﬃne mappings of the ImageStar input set.

4.5 Reachability of a max pooling layer

Reachability of max pooling layer with an ImageStar input set is challenging be-
cause the value of each pixel in an image in the ImageStar depends on the pred-
icate variables αi. Therefore, the local max point when applying max-pooling
operation may change with the values of the predicate variables. In this section,
we investigate the exact reachability and over-approximate reachability of a max
pooling layer with an ImageStar input set. The ﬁrst obtains the exact reachable
set while the second constructs an over-approximate reachable set.

Exact reachability of a max pooling layer The central idea in the exact
analysis of the max-pooling layer is ﬁnding a set of local max point candidates
when we apply the max pooling operation on the image. We consider the max
pooling operation on the ImageStar in Example 1 with a pool size of 2 × 2,
a padding size of P = [0 0 0 0], and a stride S = [2 2] to clarify the exact
analysis step-by-step. First, the max-pooling operation is applied on 4 local
regions I, II, III, IV , as shown in Figure 4. The local regions II, III, IV have
only one max point candidate whic is the pixel that has the maximum value in
the region. It is interesting to note that region I has two max point candidates at
the positions (1, 2, 1) and (2, 2, 1) and these candidates correspond to diﬀerent
conditions of the predicate variable α. For example, the pixel at the position
(1, 2, 1) is the max point if and only if 4 + α × 1 ≥ 3 + α × 0. Note that with
−2 ≤ α ≤ 2, we always have 4 + α ∗ 1 ≥ 2 + α × 0 ≥ 0 + α × 0. Since the local
region I has two max point candidates, and other regions have only one, the exact
reachable set of the max-pooling layer is the union of two new ImageStars Θ1 and
Θ2. In the ﬁrst reachable set Θ1, the max point of the region I is (1, 2, 1) with an
additional constraint on the predicate variable α ≥ −1. For the second reachable
set Θ2, the max point of the region I is (2, 2, 1) with an additional constraint

on the predicate variable α ≤ −1. One can see that from a single ImageStar
input set, the output reachable set of the max-pooling layer is split into two
new ImageStars. Therefore, the number of ImageStars in the reachable set of
the max-pooling layer may grow quickly if each local region has more than one
max point candidates. The worst-case complexity of the number of ImageStars
in the exact reachable set of the max-pooling layer is given in Lemma 5. The
exact reachability algorithm is presented in the Appendix A.1.

Fig. 4: Exact reachability of max pooling layer using ImageStars.

Lemma 5. The worst-case complexity of the number of ImageStars in the exact
reachability of the max pooling layer is O(((p1 × p2)h×w)nc) where [h, w, nc] is
the size of the ImageStar output sets, and [p1, p2] is the size of the max-pooling
layer.

Proof. An image in the ImageStar output set has h × w pixels in each channel.
For each pixel, in the worst case, there are p1 × p2 candidates. Therefore, the
number of ImageStars in the output set in the worst case is O(((p1 × p2)h×w)nc).

Finding a set of local max point candidates is the core computation in the
exact reachability of max-pooling layer. To optimize this computation, we divide
the search for the local max point candidates into two steps. The ﬁrst one is to
estimate the ranges of all pixels in the ImageStar input set. We can solve hI ×
wI ×nc linear programming optimizations to ﬁnd the exact ranges of these pixels,
where [hI , wI , nc] is the size of the input set. However, unfortunately this is a
time-consuming computation. For example, if a single linear optimization
can be done in 0.01 seconds, for an ImageStar of the size 224×224×32,
we need about 10 hours to ﬁnd the ranges of all pixels. To overcome this
bottleneck, we quickly estimate the ranges using only the ranges of the predicate

1233311122220100000000000000Θ=c+αv=+α,P≡(1−1)α≤(22)103420010IIIIIIIIIIIIVIIVIIMax point position Max point valueRegion(2, 4, 1) 3+α∗0Condition−2≤α≤2III(3, 2, 1) 3+α∗0−2≤α≤2IV(4, 3, 1) 3+α∗0−2≤α≤2I(1, 2, 1) 4+α∗1−1≤α≤2(2, 2, 1) 3+α∗0−2≤α≤−1Θ1=c1+αv1=+α,P1≡(1−1−1)α≤(221)1133300041Θ2=c2+αv2=+α,P2≡(1−11)α≤(22−1)1133300030variables to get rid of a vast amount of non-max-point candidates. In the second
step, we solve a much smaller number of LP optimizations to determine the
exact set of the local max point candidates and then construct the ImageStar
output set based on these candidates.

Lemma 5 shows that the number of ImageStars in the exact reachability anal-
ysis of a max-pooling layer may grow exponentially. To overcome this problem,
we propose the following over-approximate reachability method.

Over-approximate reachability of a max pooling layer The central idea
of the over-approximate analysis of the max-pooling layer is that if a local region
has more than one max point candidates, we introduce a new predicate variable
standing for the max point of that region. We revisit the example introduced
earlier in the exact analysis to clarify this idea. Since the ﬁrst local region I has
two max point candidates, we introduce new predicate variable β to represent
the max point of this region by adding three new constraints: 1) β ≥ 4+α∗1, i.e.,
β must be equal or larger than the value of the ﬁrst candidate ; 2) β ≥ 3 + α ∗ 0,
i.e., β must be equal or larger than the value of the second candidate; 3) β ≤ 6,
i.e., β must be equal or smaller than the upper bound of the pixels values in the
region. With the new predicate variable, a single over-approximate reachable set
Θ(cid:48) can be constructed in Figure 5. The approximate reachability algorithm is
presented in the Appendix A.2.

Fig. 5: Over-approximate reachability of max pooling layer using ImageStar.

Lemma 6. The worst-case complexity of the new predicate variables introduced
in the over-approximate analysis is O(h × w × nc) where [h, w, nc] is the size of
the ImageStar output set.

1233311122220100000000000000Θ=c+αv=+α,P≡(1−1)α≤(22)103420010IIIIIIIIIIIIVIIVIIMax point position Max point valueRegion(2, 4, 1) 3+α∗0Condition−2≤α≤2III(3, 2, 1) 3+α∗0−2≤α≤2IV(4, 3, 1) 3+α∗0−2≤α≤2I(1, 2, 1) 4+α∗1−1≤α≤2(2, 2, 1) 3+α∗0−2≤α≤−1Θ'=c'+αv1'+βv2'=+αP'≡(10−101−10−101)(αβ)≤(221−4−36)1133300000+β10001β≥4+α∗1β≥3+α∗0Max point valueNew constraintsNew predicate variableββ≤64.6 Reachability of a ReLU layer

Similar to max-pooling layer, the reachability analysis of a ReLU layer is also
challenging because the value of each pixel in an ImageStar may be smaller
than zero or larger than zero depending on the values of the predicate variables
(ReLU (x) = max(0, x)). In this section, we investigate the exact and over-
approximate reachability algorithms for a ReLU layer with an ImageStar input
set. The techniques we use in this section are adapted from in [34].

Exact reachability of a ReLU layer The central idea of the exact analysis of
a ReLU layer with an ImageStar input set is performing a sequence of stepReLU
operations over all pixels of the ImageStar input set. Mathematically, the exact
reachable set of a ReLU layer L can be computed as follows.

RL = stepReLUN (stepReLUN −1(. . . (stepReLU1(I)))),

where N is the total number of pixels in the ImageStar input set I. The stepReLUi
operation determines whether or not a split occurs at the ith pixel. If the pixel
value is larger than zero, then the output value of that pixel remains the same. If
the pixel value is smaller than zero than the output value of that pixel is reset to
be zero. The challenge is that the pixel value depends on the predicate variables.
Therefore, there is the case that the pixel value may be negative or positive with
an extra condition on the predicate variables. In this case, we split the input set
into two intermediate ImageStar reachable sets and apply the ReLU law on each
intermediate reach set. An example of the stepReLU operation on an ImageStar
is illustrated in Figure 6. The value of the ﬁrst pixel value −1 + α would be
larger than zero if α ≤ 1, and in this case we have ReLU (−1 + α) = −1 + α.
If α <= 1, then ReLU (−1 + α) = 0 + α × 0. Therefore, the ﬁrst stepReLU
operation produces two intermediate reachable sets Θ1 and Θ2, as shown in the
ﬁgure. The number of ImageStars in the exact reachable set of a ReLU layer
increases quickly along with the number of splits in the analysis, as stated in the
following lemma.

Lemma 7. The worst-case complexity of the number of ImageStars in the exact
analysis of a ReLU layer is O(2N ), where N is the number of pixels in the
ImageStar input set.

Proof. There are h × w × nc local regions in the approximate analysis. In the
worst case, we need to introduce a new variable for each region. Therefore, the
worst case complexity of new predicate variables introduced is O(h × w × nc).

Similar to [34], to control the explosion in the number of ImageStars in the
exact reachable set of a ReLU layer, we propose an over-approximate reachability
algorithm in the following.

Fig. 6: stepReLU operation on an ImageStar.

Over-approximate reachability of a ReLU layer The idea behind the over-
approximate reachability of ReLU layer is replacing the stepReLU operation at
each pixel in the ImageStar input set by an approxStepReLU operation. At
each pixel where a split occurs, we introduce a new predicate variable to over-
approximate the result of the stepReLU operation at that pixel. An example of
the overStepReLU operation on an ImageStar is depicted in Figure 7 in which
the ﬁrst pixel of the input set has the ranges of [l1 = −3, u1 = 1] indicating that
a split occurs at this pixel. To avoid this split, we introduce a new predicate
variable β to over-approximate the exact intermediate reachable set (i.e., two
blue segments in the ﬁgure) by a triangle. This triangle is determined by three
constraints: 1) β ≥ 0 (the ReLU (x) ≥ 0 for any x); 2) β ≥ −1+α (ReLU (x) ≥ x
for any x); 3) β ≤ 0.5+0.25α (upper bound of the new predicate variable). Using
this over-approximation, a single intermediate reachable set Θ(cid:48) is produced as
shown in the ﬁgure. After performing a sequence of approxStepReLU operations,
we obtain a single over-approximate ImageStar reachable set for the ReLU layer.
However, the number of predicate variables and the number of constraints in the
obtained reachable set increase.

Lemma 8. The worst case complexity of the increment of predicate variables
and constraints is O(N ) and O(3 × N ) respectively, where N is the number of
pixels in the ImageStar input set.

Proof. In the worst case, splits occur at all N pixels in the ImageStar input set.
In this case, we need to introduce N new predicate variables to over-approximate
the exact intermediate reachable set. For each new predicate variable, we add 3
new constraints.

One can see that determining where splits occur is crucial in the exact and
over-approximate analysis of a ReLU layer. To do this, we need to know the
ranges of all pixels in the ImageStar input set. However, as mentioned earlier,
the computation of the exact range is expensive. To reduce the computation
cost, we ﬁrst use the estimated ranges of all pixels to get rid of a vast amount

Θ=c+αv=+α,P≡(1−1)α≤(22)-11201000Θ2=c2+αv2=+α,P2≡(1−1−1)α≤(22−1)-11201000New constraintΘ1=c1+αv1=+α,P1≡(1−11)α≤(221)01200000New constraintstepReLU1(Θ)Fig. 7: approxStepReLU operation on an ImageStar.

of non-splitting pixels. Then we compute the exact ranges for the pixels where
splits may occur to compute the exact or over-approximate reachable set of the
layer.

4.7 Reachabilty algorithm and parallelization

We have presented the core ideas for reachability analysis of diﬀerent types of
layers in a CNN. The reachable set of a CNN is constructed layer-by-layer in
which the output reachable set of the previous layer is the input for the next
layer. For the convolutional layer, average pooling layer and fully connected
layer, we always can compute eﬃciently the exact reachable set of each layer.
For the max pooling layer and ReLU layer, we can compute both the exact and
the over-approximate reachable sets. However, the number of ImageStars in the
exact reachable set may grow quickly. Therefore, in the exact analysis, a
layer may receive multiple input sets which can be handled in parallel
to speed up the computation time. The reachability algorithm for a CNN is
summarized in Algorithm 4.7.1. The detail implementation of the reachability
algorithm for each layer can be found in NNV [36].

1 , I, scheme (’exact’ or ’approx’)

Algorithm 4.7.1 Reachability analysis for a CNN.
Input: N = {Li}n
Output: RN
1: procedure RN = reach(N , I, scheme)
2:
3:
4:
5:

In = I
parfor i = 1 : n do In = Li.reach(In, scheme)
end parfor
RN = In

Θ=c+αv=+α,P≡(1−1)α≤(22)-11201000+βP'≡(10−101−10−1−0.251)(αβ)≤(22−1100.5)1000+α01200000approxStepReLU1(Θ)Θ'=c'+αv1'+βv2'=New predicate variableNew constraints:ββ≥x1⇔β≥−1+αβ≥0β≤u1(x1−l1)/(u1−l1)⇔β≤(x1+3)/4=(2+α)/4u1=1l1=−3xiy1=ReLU(x1)y1=x1Over-approximate setExact setβ5 Evaluation

The proposed reachability algorithms are implemented in NNV [36], a tool for
veriﬁcation of deep neural networks and learning-enabled autonomous CPS.
NNV utilizes core functions in MatConvNet [37] for the analysis of the convo-
lutional and average pooling layers. The evaluation of our approach consists of
two parts. First, we evaluate our approach in comparison with the zonotope [28]
and polytope methods [29] re-implemented in NNV via robustness veriﬁcation
of deep neural networks. Second, we evaluate the scalability of our approach and
the DeepPoly polytope method using real-world image classiﬁers, VGG16, and
VGG19 [27]. The experiments are done on a computer with following conﬁgu-
rations: Intel Core i7-6700 CPU @ 3.4GHz × 8 Processor, 62.8 GiB Memory,
Ubuntu 18.04.1 LTS OS.5 Finally, we present the comparison with ERAN-DeepZ
method on their ConvM axP ool network trained on CIFAR-10 data set in the
Appendix of this paper.

5.1 Robustness Veriﬁcation of MNIST Classiﬁcation Networks

We compare our approach with the zonotope and polytope methods in two
aspects including veriﬁcation time and conservativeness of the results. To do
that, we train 3 CNNs a small, a medium, and a large CNN with 98%, 99.7%
and 99.9% accuracy respectively using the MNIST data set consisting of 60000
images of handwritten digits with a resolution of 28×28 pixels [19]. The network
architectures are given in Figure 13 in the Appendix. The networks classify
images into ten classes: 0, 1, . . . , 9. The classiﬁed output is the index of the
dimension that has maximum value, i.e., the argmax across the 10 outputs. We
evaluate the robustness of the network under the well-known brightening attack
used in [7]. The idea of a brightening attack is that we can change the value
of some pixels independently in the image to make it brighter or darker to fool
the network, to misclassify the image. In this case study, we darken a pixel of
an image if its value xi (between 0 and 255) is larger than a threshold d, i.e.,
xi ≥ d. Mathematically, we reduce the value of that pixel xi to the new value x(cid:48)
i
such that 0 ≤ x(cid:48)

i ≤ δ × xi.

The robustness veriﬁcation is done as follows. We select 100 images that are
correctly classiﬁed by the networks and perform the brightening attack on these,
which are then used to evaluate the robustness of the networks. A network is
robust to an input set if, for any attacked image, this is correctly classiﬁed by
the network. We note that the input set contains an inﬁnite number of images.
Therefore, to prove the robustness of the network to the input set, we ﬁrst
compute the output set containing all possible output vectors of the network
using reachability analysis. Then, we prove that in the output set, the correctly
classiﬁed output always has the maximum value compared with other outputs.
Note that we can neglect the softmax and classoutput layers of the networks in

5 Codes are available online at https://github.com/verivital/nnv/tree/master/

code/nnv/examples/Submission/CAV2020_ImageStar.

the analysis since we only need to know the maximum output in the output set
of the last fully connected layer in the networks to prove the robustness of the
network.

We are interested in the percentage of the number of input sets that a net-
work is provably robust and the veriﬁcation times of diﬀerent approaches under
diﬀerent values of d and θ. When d is small, the number of pixels in the image
that are attacked is large and vice versa. For example, the average number of
pixels attacked (computed on 100 cases) corresponding to d = 250, 245 and 240
are 15, 21 and 25 respectively. The value of δ dictates the size of the input set
that can be created by a speciﬁc attack. Stated diﬀerently it dictates the range in
which the value of a pixel can be changed. For example, if d = 250 and δ = 0.01,
the value of an attacked pixel many range from 0 to 2.55.

The experiments show that using the zonotope method, we cannot prove
the robustness of any network. The reason is that the zonotope method obtains
very conservative reachable sets. Figure 8 illustrates the ranges of the outputs
computed by our ImageStar (approximate scheme), the zonotope and polytope
approaches when we attack a digit 0 image with brightening attack in which
d = 250 and δ = 0.05. One can see that, using ImageStar and polytope method,
we can prove that the output corresponding to the digit 0 is the one that has a
maximum value, which means that the network is robust in this case. However,
the zonotope method produces very large output ranges that cannot be used to
prove the robustness of the network. The ﬁgure also shows that our ImageStar
method produces tighter ranges than the polytope method, which means our
result is less conservative than the one obtained by the polytope method. We
note that the zonotope method is very time-consuming. It needs 93 seconds
to compute the reachable set of the network in this case, while the polytope
method only needs 0.3 seconds, and our approximate ImageStar method needs
0.74 seconds. The main reason is that the zonotope method introduces many
new variables when constructing the reachable set of the network, which results
in the increase in both computation time and conservativeness.

The comparison of the polytope and our ImageStar method is given in Tables
1, 2, and 3. The tables show that in all networks, our method is less conservative
than the polytope approach since the number of cases that our approach can
prove the robustness of the network is larger than the one proved by the polytope
method. For example, for the small network, for d = 240 and δ = 0.015, we can
prove 71 cases while the polytope method can prove 65 cases. Importantly, the
number of cases proved by DeepPoly reduces quickly when the network becomes
larger. For example, for the case that d = 240 and δ = 0.015, the polytope
method is able to prove the robustness of the medium network for 38 cases while
our approach can prove 88 cases. This is because the polytope method becomes
more and more conservative when the network or the input set is large. The
tables show that the polytope method is faster than our ImageStar method on
the small network. However, it is slower than the ImageStar method on any larger
networks in all cases. Notably, for the large network, the ImageStar approach
is signiﬁcantly faster than the polytope approach, 16.65 times faster in average.

Fig. 8: An example of output ranges of the small MNIST classiﬁcation networks
using diﬀerent approaches.

The results also show that the polytope approach may run into memory problem
for some large input sets.

Robustness Results (in Percent)

δ = 0.005

δ = 0.01

δ = 0.015

Polytope ImageStar

Polytope ImageStar

Polytope ImageStar

d = 250

86.00

d = 245

77.00

d = 240

72.00

87.00

78.00

73.00

84.00

72.00

67.00

87.00

78.00

72.00

83.00

70.00

65.00

Veriﬁcation Times (in Seconds)

d = 250

11.24

d = 245

14.84

16.28

19.44

18.26

24.96

28.19

40.76

26.42

38.94

87.00

77.00

71.00

53.43

85.97

d = 240

33.59
Table 1: Veriﬁcation results of the small MNIST CNN.

118.58

54.23

25.77

18.29

64.10

5.2 Robustness Veriﬁcation of VGG16 and VGG19

In this section, we evaluate the polytope and ImageStar methods on real-world
CNNs, the VGG16 and VGG19 classiﬁcation networks [27]. We use Foolbox [25]
to generate the well-known DeepFool adversarial attacks [24] on a set of 20 bell
pepper images. From an original image ori im, Foolbox generates an adversarial
image adv im that can fool the network. The diﬀerence between two images is
deﬁned by dif f im = adv im − ori im. We want to verify if we apply (l + δ)
percent of the attack on the original image, whether or not the network classiﬁes
the disturbed images correctly. The set of disturbed images can be represented
as an ImageStar as follows disb im = ori im + (l + δ) × dif f im, where l is
the percentage of the attack at which we want to verify the robustness of the
network, and δ is a small perturbation around l, i.e., 0 ≤ δ ≤ δmax. Intuitively, l
describes how close we are to the attack, and the perturbation δ represents the
size of the input set.

059Output-8-6-4-202468RangesImageStar059Output-600-400-2000200400600RangesZonotope059Output-8-6-4-202468RangesPolytopeRobustness Results (in Percent)

δ = 0.005

δ = 0.01

δ = 0.015

Polytope ImageStar

Polytope ImageStar

Polytope ImageStar

d = 250

86.00

d = 245

74.00

d = 240

69.00

99.00

95.00

90.00

73.00

58.00

49.00

99.00

95.00

89.00

65.00

46.00

38.00

99.00

95.00

88.00

Veriﬁcation Times (in Seconds)

d = 250 213.86

d = 245 232.81

52.09

68.98

627.14

931.28

257.12

295.54

1215.86

749.41

2061.98

1168.31

d = 240 301.58

1451.39
Table 2: Veriﬁcation results of the medium MNIST CNN.

2461.89

3148.16

102.61

705.03

Robustness Results (in Percent)

δ = 0.005

δ = 0.01

δ = 0.015

Polytope ImageStar

Polytope ImageStar

Polytope ImageStar

d = 250

90.00

99.00

d = 245

91.00

100.00

83.00

75.00

99.00 M emErr

99.00

100.00 M emErr

100.00

d = 240

81.00

99.00 M emErr

99.00 M emErr

99.00

Veriﬁcation Times (in Seconds)

d = 250 917.23

67.45

5221.39

231.67 M emErr

488.69

d = 245 1420.58

104.71

6491.00

353.02 M emErr

1052.87

d = 240 1872.16

123.37 M emErr

476.67 M emErr

1522.50

Table 3: Veriﬁcation results of the large MNIST CNN.

Table 4 shows the veriﬁcation results of VGG16 and VGG19 with diﬀerent
levels of the DeepFool attack. The networks are robust if they classify correctly
the set of disturbed images disb im as bell peppers. To guarantee the robustness
of the networks, the output corresponding to the bell pepper label (index 946)
needs to be the maximum output compared with others. The table shows that
with a small input set, small δ, the polytope and ImageStar can prove the ro-
bustness of VGG16 and VGG19 with a reasonable amount of time. Notably, the
veriﬁcation times as well as the robustness results of the polytope and ImageStar
methods are similar when they deal with small input sets except for two cases
where ImageStar is faster than the polytope method. It is interesting to note
that according to the veriﬁcation results for the VGG and MNIST networks,
deep networks seem to be more robust than shallow networks.

5.3 Exact Analysis vs. Approximate Analysis

We have compared our ImageStar approximate scheme with the zonotope and
polytope approximation methods. It is interesting to investigate the performance
of ImageStar exact scheme in comparison with the approximate one. To illustrate
the advantages and disadvantages of the exact scheme and approximate scheme,
we consider the robustness veriﬁcation of VGG16 and VGG19 on a single Im-
ageStar input set created by an adversarial attack on a bell pepper image. The
veriﬁcation results are presented in Table 5. The table shows that for a small per-
turbation δ, the exact and over-approximate analysis can prove the robustness of
the VGG16 around some speciﬁc levels of attack in approximately one minute.

Robustness Results (in percentage)

VGG16

VGG19

δ = 10−7

δ = 2 × 10−7

δ = 10−7

δ = 2 × 10−7

P olytope ImageStar

P olytope ImageStar P olytope ImageStar

P olytope ImageStar

l = 0.96

85.00

l = 0.97

85.00

l = 0.98

85.00

85.00

85.00

85.00

85.00

85.00

85.00

85.00

85.00

85.00

100.00

100.00

95.00

100.00

100.00

95.00

Veriﬁcation Times (in Seconds)

l = 0.96 319.04

l = 0.97 324.93

318.60

323.41

327.61

317.27

319.93

324.90

320.91

315.84

314.14

315.27

100.00

100.00

95.00

885.07

319.67

l = 0.98 315.54

315.26

332.92
Table 4: Veriﬁcation results of VGG networks.

468.59

320.53

320.44

325.92

100.00

100.00

95.00

339.30

314.58

317.95

We can intuitively verify the robustness of the VGG networks via visualization
of their output ranges. An example of the output ranges of VGG19 for the case
of l = 0.95%, δmax = 2 × 10−7 is depicted in Figure 9. One can see from the
ﬁgure that the output of the index 946 corresponding to the bell pepper label
is always the maximum one compared with others, which proves that VGG19 is
robust in this case. From the table, it is interesting that VGG19 is not robust
if we apply ≥ 98% of the attack. Notably, the exact analysis can give us correct
answers with a counter-example set in this case. However, the over-approximate
analysis cannot prove that VGG19 is not robust since its obtained reachable set
is an over-approximation of the exact one. Therefore, it may be the case that
the over-approximate reachable set violates the robustness property because of
its conservativeness. A counter-example generated by the exact analysis method
is depicted in Figure 10 in which the disturbed image is classiﬁed as strawberry
instead of bell pepper since the strawberry output is larger than the bell pepper
output in this case.

VGG16

VGG19

l

δmax

Exact

Approximate

Exact

Approximate

Robust VT Robust VT Robust

VT

Robust

VT

10−7
Yes
2 × 10−7 Yes

10−7
Yes
2 × 10−7 Yes

10−7
Yes
2 × 10−7 Yes

10−7
Yes
2 × 10−7 Yes

10−7
Yes
2 × 10−7 Yes

10−7
Yes
2 × 10−7 Yes

64.56226 Yes

60.10607 Yes

234.11977

63.88826 Yes

59.48936 Yes

1769.69313

64.92889 Yes

60.31394 Yes

67.11730

64.20910 Yes

59.77254 Yes

174.55983

67.64783 Yes

59.89077 Yes

73.13642

63.83538 Yes

59.23282 Yes

146.16172

64.30362 Yes

59.79876 Yes

77.25398

64.06285 Yes

61.23296 Yes

121.70296

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

72.08723

196.93728

63.33389

200.89500

67.56389

121.91447

64.43168

107.17331

64.06183 Yes

59.89959 No

67.68139

Unkown 64.47035

64.01997 Yes

59.77469 No

205.00939 Unknown 107.42679

64.24773 Yes

60.22833 No

71.90568 Unknown 68.25916

63.67108 Yes

59.69298 No

106.84492 Unknown 101.04668

50%

80%

95%

97%

98%

98.999%

Table 5: Veriﬁcation results of the VGG16 and VGG19 in which V T is the veri-
ﬁcation time (in seconds) using the ImageStar exact and approximate schemes.

To optimize the veriﬁcation time, it is important to know the times con-
sumed by each type of layers in the reachability analysis step. Figure 11 de-

Fig. 9: Exact ranges of VGG19 shows that VGG19 correctly classiﬁes the input
image as a bell pepper.

Fig. 10: A counter-example shows that VGG19 misclassiﬁes the input image as
a strawberry instead of a bell pepper.

scribed the total reachability times of the convolutional layers, fully connected
layers, max pooling layers and ReLU layers in the VGG19 with 50% attack and
10−7 perturbation. As shown in the ﬁgure, the reachable set computation in the
convolutional layers and fully connected layers can be done very quickly, which
shows the advantages of the ImageStar data structure. Notably, the total reach-
ability time is dominated by the time of computing the reachable set for 5 max
pooling layers and 18 ReLU layers. This is because the computation in these
layers concerns solving a large number of linear programing (LP) optimization
problems such as ﬁnding lower bound and upper bound, and checking max point
candidates. Therefore, to optimize the computation time, we need to minimize
the number of LP problems in the future.

01002003004005006007008009001000Output Category ID-4-20246Range6.32948446.32948466.3294848Bell Pepper (946)6.18278696.182786956.1827876.182787056.1827871Sock (807)6.32948446.32948466.3294848Bell Pepper (946)6.22008356.22008366.22008376.22008386.22008396.220084Strawberry (950)6.27198296.2719836.27198316.2719832Bell Pepper (946)6.28131666.28131676.28131686.28131696.2813176.28131716.2813172Strawberry (950)Original imagebell pepperDifference imageAdversarial imagestrawberryFig. 11: Total reachability time of each type of layers in the VGG19 in which
the max pooling and ReLU layers dominate the total reachability time of the
network.
6 Discussion

When we apply our approach on real-world networks, it has been shown that
the size of the input set is the most important factor that aﬀects the
performance of veriﬁcation approaches. However, this important issue has
not been emphasized in the existing literature. Most of the existing approaches
focus on the size of the network that they can analyze. We believe that all
methods (including the method we proposed in this paper) are scal-
able for large networks only for small input sets. When the input set is
large, it causes three major problems in the analysis, which are the explosions
in 1) computation time; 2) memory usage; and 3) conservativeness. In the exact
analysis method, a large input set causes more splits in the max-pooling layer
and the ReLU layer. A single ImageStar may split into many new ImageStars
after these layers, which leads to the explosion in the number of ImageStars in
the reachable set as shown in Figure 12. Therefore, it requires more memory to
handling the new ImageStars and more time for the computation. One may think
that the over-approximate method can overcome this challenge since it obtains
only one ImageStar at each layer and the cost we need to pay is only the conser-
vativeness of the result. The fact is, an over-approximate method usually helps
reduce the computation time, as shown in the experimental results. However,
it is not necessarily eﬃcient in terms of memory consumption. The reason is, if
there is a split, it introduces a new predicate variable and new generator. If the
number of generators and the dimensions of the ImageStar are large, it requires
a massive amount of memory to store the over-approximate reachable set. For
instance, if there are 100 splits happened in the ﬁrst ReLU layer of the
VGG19, the second convolutional layer will receive an ImageStar of
size 224 × 224 × 64 with 100 generators. To store this ImageStar with
double precision, we need approximately 2.4GB of memory. In practice,

 3.487382.747624 113.89475.61323Convolutional 2D (16)Fully Connected (3)Max Pooling (5)ReLU (18)020406080100120Fig. 12: Number of ImageStars in exact analysis increases with input size.

the dimensions of the ImageStars obtained in the ﬁrst several convolutional lay-
ers are usually large. Therefore, if splitting happens in these layers, we may need
to deal with “out of memory” problem. We see that all existing approaches such
as the zonotope [28] and polytope [29], all face the same challenges. Additionally,
the conservativeness of an over-approximate reachable set is a crucial factor in
evaluating an over-approximation approach. Therefore, the exact analysis still
plays an essential role in the analysis of neural networks since it helps to evaluate
the conservativeness of the over-approximation approaches.

7 Conclusion

We have proposed a new set-based method for robustness veriﬁcation of deep
CNNs using the concept of the ImageStar. The core of our method are the ex-
act and over-approximate reachability algorithms for ImageStar input sets. The
experiments show that our approach is less conservative than the recent zono-
tope [28] and polytope [29] approaches. It is also faster than these approaches
when dealing with deep networks. Notably, our approach can be applied to verify
the robustness of real-world CNNs with small perturbed input sets. It can also
compute the exact reachable set and visualize the exact output range of deep
CNNs, and the analysis can sped up signiﬁcantly using parallel computing. We
have found and shown the size of the input set to be an important factor that
aﬀects the reachability algorithms performance. Our future work is improving
the proposed method to deal with larger input sets and optimizing the memory
and time complexity of our computations.

05101520253035Number of ImageStars11.21.41.61.8210-7References

1. Akintunde, M.E., Botoeva, E., Kouvaros, P., Lomuscio, A.: Formal veriﬁcation
of neural agents in non-deterministic environments. In: Autonomous Agents and
Multi-Agent Systems (May 2020)

2. Anderson, G., Pailoor, S., Dillig, I., Chaudhuri, S.: Optimization and abstraction:
A synergistic approach for analyzing neural network robustness. In: Proceedings
of the 40th ACM SIGPLAN Conference on Programming Language Design and
Implementation. p. 731744. PLDI 2019, Association for Computing Machinery,
New York, NY, USA (2019), https://doi.org/10.1145/3314221.3314614

3. Bak, S., Duggirala, P.S.: Simulation-equivalent reachability of large linear systems
with inputs. In: International Conference on Computer Aided Veriﬁcation. pp.
401–420. Springer (2017)

4. Bak, S., Tran, H.D., Johnson, T.T.: Numerical veriﬁcation of aﬃne systems with up
to a billion dimensions. In: Proceedings of the 22nd ACM International Conference
on Hybrid Systems: Computation and Control. pp. 23–32. ACM (2019)

5. Dutta, S., Jha, S., Sanakaranarayanan, S., Tiwari, A.: Output range analysis for

deep neural networks. arXiv preprint arXiv:1709.09130 (2017)

6. Dvijotham, K., Stanforth, R., Gowal, S., Mann, T.A., Kohli, P.: A dual approach

to scalable veriﬁcation of deep networks. In: UAI. pp. 550–559 (2018)

7. Gehr, T., Mirman, M., Drachsler-Cohen, D., Tsankov, P., Chaudhuri, S., Vechev,
M.: Ai2: Safety and robustness certiﬁcation of neural networks with abstract in-
terpretation. In: 2018 IEEE Symposium on Security and Privacy (SP). pp. 3–18.
IEEE (2018)

8. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial

examples. arXiv preprint arXiv:1412.6572 (2014)

9. Gopinath, D., Converse, H., Pasareanu, C., Taly, A.: Property inference for deep
neural networks. In: 2019 34th IEEE/ACM International Conference on Auto-
mated Software Engineering (ASE). pp. 797–809 (Nov 2019)

10. Hein, M., Andriushchenko, M.: Formal guarantees on the robustness of a classiﬁer
against adversarial manipulation. In: Advances in Neural Information Processing
Systems. pp. 2266–2276 (2017)

11. Huang, C., Fan, J., Li, W., Chen, X., Zhu, Q.: Reachnn: Reachability analysis of
neural-network controlled systems. ACM Transactions on Embedded Computing
Systems (TECS) 18(5s), 1–22 (2019)

12. Ivanov, R., Carpenter, T.J., Weimer, J., Alur, R., Pappas, G.J., Lee, I.: Case
study: verifying the safety of an autonomous racing car with a neural network
controller. In: Proceedings of the 23rd International Conference on Hybrid Systems:
Computation and Control. pp. 1–7 (2020)

13. Ivanov, R., Weimer, J., Alur, R., Pappas, G.J., Lee, I.: Verisig: verifying safety
properties of hybrid systems with neural network controllers. In: Hybrid Systems:
Computation and Control (HSCC) (2019)

14. Katz, G., Barrett, C., Dill, D.L., Julian, K., Kochenderfer, M.J.: Reluplex: An
eﬃcient smt solver for verifying deep neural networks. In: International Conference
on Computer Aided Veriﬁcation. pp. 97–117. Springer (2017)

15. Katz, G., Huang, D.A., Ibeling, D., Julian, K., Lazarus, C., Lim, R., Shah, P.,
Thakoor, S., Wu, H., Zelji´c, A., et al.: The marabou framework for veriﬁcation and
analysis of deep neural networks. In: International Conference on Computer Aided
Veriﬁcation. pp. 443–452. Springer (2019)

16. Kouvaros, P., Lomuscio, A.: Formal veriﬁcation of cnn-based perception systems.

arXiv preprint arXiv:1811.11373 (2018)

17. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classiﬁcation with deep con-
volutional neural networks. In: Advances in neural information processing systems.
pp. 1097–1105 (2012)

18. Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D.: Face recognition: A convolu-
tional neural-network approach. IEEE transactions on neural networks 8(1), 98–
113 (1997)

19. LeCun, Y.: The mnist database of handwritten digits. http://yann.

lecun.

com/exdb/mnist/ (1998)

20. LeCun, Y., Bottou, L., Bengio, Y., Haﬀner, P., et al.: Gradient-based learning ap-
plied to document recognition. Proceedings of the IEEE 86(11), 2278–2324 (1998)
21. Lin, W., Yang, Z., Chen, X., Zhao, Q., Li, X., Liu, Z., He, J.: Robustness veriﬁcation
of classiﬁcation deep neural networks via linear programming. In: Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition. pp. 11418–
11427 (2019)

22. Lomuscio, A., Maganti, L.: An approach to reachability analysis for feed-forward

relu neural networks. arXiv preprint arXiv:1706.07351 (2017)

23. Lopez, D.M., Musau, P., Tran, H.D., Johnson, T.T.: Veriﬁcation of closed-loop
systems with neural network controllers. In: Frehse, G., Althoﬀ, M. (eds.) ARCH19.
6th International Workshop on Applied Veriﬁcation of Continuous and Hybrid
Systems. EPiC Series in Computing, vol. 61, pp. 201–210. EasyChair (April 2019),
https://easychair.org/publications/paper/ZmnC

24. Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P.: Deepfool: a simple and accurate
method to fool deep neural networks. In: Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition. pp. 2574–2582 (2016)

25. Rauber, J., Brendel, W., Bethge, M.: Foolbox v0. 8.0: A python toolbox to bench-
mark the robustness of machine learning models. arXiv preprint arXiv:1707.04131
5 (2017)

26. Ruan, W., Wu, M., Sun, Y., Huang, X., Kroening, D., Kwiatkowska, M.: Global
robustness evaluation of deep neural networks with provable guarantees for the l 0
norm. arXiv preprint arXiv:1804.05805 (2018)

27. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale

image recognition. arXiv preprint arXiv:1409.1556 (2014)

28. Singh, G., Gehr, T., Mirman, M., P¨uschel, M., Vechev, M.: Fast and eﬀective
robustness certiﬁcation. In: Advances in Neural Information Processing Systems.
pp. 10825–10836 (2018)

29. Singh, G., Gehr, T., P¨uschel, M., Vechev, M.: An abstract domain for certifying
neural networks. Proceedings of the ACM on Programming Languages 3(POPL),
41 (2019)

30. Souradeep Dutta, Xin Chen, S.S.: Reachability analysis for neural feedback systems
using regressive polynomial rule inference. In: Hybrid Systems: Computation and
Control (HSCC) (2019)

31. Sun, X., Khedr, H., Shoukry, Y.: Formal veriﬁcation of neural network controlled
autonomous systems. In: Hybrid Systems: Computation and Control (HSCC)
(2019)

32. Tran, H.D., Cei, F., Lopez, D.M., Johnson, T.T., Koutsoukos, X.: Safety veri-
ﬁcation of cyber-physical systems with reinforcement learning control. In: ACM
SIGBED International Conference on Embedded Software (EMSOFT’19). ACM
(October 2019)

33. Tran, H.D., Musau, P., Lopez, D.M., Yang, X., Nguyen, L.V., Xiang, W., John-
son, T.T.: Parallelizable reachability analysis algorithms for feed-forward neural
networks. In: 7th International Conference on Formal Methods in Software Engi-
neering (FormaliSE2019), Montreal, Canada (2019)

34. Tran, H.D., Musau, P., Lopez, D.M., Yang, X., Nguyen, L.V., Xiang, W., Johnson,
T.T.: Star-based reachability analsysis for deep neural networks. In: 23rd Interna-
tional Symposisum on Formal Methods (FM’19). Springer International Publishing
(October 2019)

35. Tran, H.D., Nguyen, L.V., Hamilton, N., Xiang, W., Johnson, T.T.: Reachability
analysis for high-index linear diﬀerential algebraic equations (daes). In: 17th Inter-
national Conference on Formal Modeling and Analysis of Timed Systems (FOR-
MATS’19). Springer International Publishing (August 2019)

36. Tran, H.D., Yang, X., Lopez, D.M., Musau, P., Nguyen, L.V., Xiang, W., Bak, S.,
Johnson, T.T.: NNV: The neural network veriﬁcation tool for deep neural networks
and learning-enabled cyber-physical systems. In: 32nd International Conference on
Computer-Aided Veriﬁcation (CAV) (July 2020)

37. Vedaldi, A., Lenc, K.: Matconvnet: Convolutional neural networks for matlab. In:
Proceedings of the 23rd ACM international conference on Multimedia. pp. 689–692.
ACM (2015)

38. Wang, S., Pei, K., Whitehouse, J., Yang, J., Jana, S.: Formal security analysis of
neural networks using symbolic intervals. arXiv preprint arXiv:1804.10829 (2018)
39. Weng, T.W., Zhang, H., Chen, H., Song, Z., Hsieh, C.J., Boning, D., Dhillon, I.S.,
Daniel, L.: Towards fast computation of certiﬁed robustness for relu networks.
arXiv preprint arXiv:1804.09699 (2018)

40. Wong, E., Kolter, J.Z.: Provable defenses against adversarial examples via the

convex outer adversarial polytope. arXiv preprint arXiv:1711.00851 (2017)

41. Wu, M., Wicker, M., Ruan, W., Huang, X., Kwiatkowska, M.: A game-based ap-
proximate veriﬁcation of deep neural networks with provable guarantees. Theoret-
ical Computer Science (2019)

42. Xiang, W., Tran, H.D., Johnson, T.T.: Reachable set computation and safety veri-
ﬁcation for neural networks with relu activations. arXiv preprint arXiv:1712.08163
(2017)

43. Xiang, W., Tran, H.D., Johnson, T.T.: Output reachable set estimation and veri-
ﬁcation for multilayer neural networks. IEEE transactions on neural networks and
learning systems (99), 1–7 (2018)

44. Xiang, W., Tran, H.D., Johnson, T.T.: Speciﬁcation-guided safety veriﬁcation for
feedforward neural networks. AAAI Spring Symposium on Veriﬁcation of Neural
Networks (2019)

45. Xiang, W., Tran, H.D., Rosenfeld, J.A., Johnson, T.T.: Reachable set estimation
and safety veriﬁcation for piecewise linear systems with neural network controllers.
arXiv preprint arXiv:1802.06981 (2018)

46. Xiang, W., Tran, H.D., Yang, X., Johnson, T.T.: Reachable set estimation for
neural network control systems: A simulation-guided approach. IEEE Transactions
on Neural Networks and Learning Systems (TNNLS) (Mar 2020)

47. Yang, X., Tran, H.D., Xiang, W., Johnson, T.T.: Reachability analysis for feed-
forward neural networks using face lattices. https://arxiv.org/abs/2003.01226
(2020)

48. Zhang, H., Weng, T.W., Chen, P.Y., Hsieh, C.J., Daniel, L.: Eﬃcient neural net-
work robustness certiﬁcation with general activation functions. In: Advances in
Neural Information Processing Systems. pp. 4944–4953 (2018)

A Appendix

A.1 Exact reachability algorithm for a max-pooling layer

Algorithm 1.1.2 illustrates the exact reachability of a max-pooling layer with
noticing that for an ImageStar set I, the anchor and generator images are put
into a single 4-dimensional array V called basis array in which V (:, :, :, 1) is
the anchor images. The algorithm works as follows. Firstly, we perform zero-
padding for the ImageStar input set I (line 2) by padding zeros to the anchor
and generator images. Secondly, the zero-padding set I (cid:48) is used to compute the
size of the max map [h, w] and the start indexes startID of each local region.
Thirdly, we initialize the basis V (cid:48) of the max map (line 6) and ﬁnd all max-point
candidates maxID for every single point [i, j, k] in the max map (line 13). If
there is only one max-point candidate for a point [i, j, k] in the max map, we
update the basis of the max map. If not, we store this point to a list of splitting
points splitID (line 18) and then initialize the max map R (line 19). Lastly, we
perform splitting operations through the list of splitting points (line 23) to get
the ﬁnal output set which is an array of ImageStars.

A.2 Approximate reachability algorithm for a max-pooling layer

Algorithm 1.2.3 illustrates the approximate reachability of a max-pooling layer.
Similar to the exact algorithm, we perform zero-padding for the ImageStar in-
put set I (line 2) by padding zeros to the anchor and generator images. The
zero-padding set I (cid:48) is then used to compute the size of the max map [h, w] and
the start indexes startID of each local region. Thirdly, we initialize the basis
V (cid:48) of the max map (line 6) and ﬁnd all max-point candidates maxID for every
single point [i, j, k] in the max map (line 13). We use np to count the number
of predicate variables when we do over-approximate reachability (line 15). If a
local region has more than one max-point candidate, we introduce a new pred-
icate variable representing the max-point of that region. Using the max-point
candidate indexes maxID and the new predicate variable index new pred id,
we update the basis of the max map (line 17-28). Finally, we add the constraints
on the new introduced predicate variables (line 30-57) and then construct the
over-approximate ImageStar output set R (line 58).

A.3 Architectures of MNIST networks (Figure 13)

A.4 Comparison with ERAN-DeepZ [28]

In this section, we present the comparison between NNV and ERAN-DeepZ on
the ERAN ConvM axP ool network on a subset of CIFAR-10 data set containing
60000 32 × 32 color images in 10 classes.6 We choose this network because it is
the only one that has max-pooling layers in all ERAN networks trained on
CIFAR-10. The network has 4 Convolutional layers, 2 max-pooling layer, 7 relu

6 https://github.com/verivital/run_nnv_eran_comparison

Algorithm 1.1.2 Exact reachability algorithm for a max pooling layer.

1: procedure R = reach exact(I = (cid:104)V, C, P (cid:105), poolSize, stride, paddingSize)
I (cid:48) = zero padding(I, paddingSize) (cid:46) zero padding for the input set
2:
[h, w] = get size maxM ap(I (cid:48), poolSize, stride) (cid:46) compute the size of the max map
3:
nc = I (cid:48).number channels, (cid:46) get the number of channels
4:
np = I (cid:48).number predicate variables (cid:46) get the number of predicate variables
5:
V (cid:48)(:, :, nc, np + 1) = zeros(h, w) (cid:46) pre-allocate the basis of the max map
6:
startID = get startP oints(I (cid:48), poolSize, stride)
7:

(cid:46) the start index for each local

region

maxID{i, j, k} = I (cid:48).get localM ax index(startID{i, j}, poolSize, k)
if size(maxID{i, j, k}, 1) == 1 then

[i(cid:48) j(cid:48) k] = maxID{i, j, k} (cid:46) the local region has only one max-point
V (cid:48)(i, j, k, :) = I (cid:48).V (i(cid:48), j(cid:48), k, :) (cid:46) update the basis of the max map

else

for i = 1 : h do

for j = 1 : w do

maxID = cell(h, w, nc), (cid:46) to store the index of the max-point candidates
splitID = [ ]
for k = 1 : nc do

[i j k] → splitID (cid:46) store splitting index

R = (cid:104)V (cid:48), C, P (cid:105)
n = size(splitID, 1) (cid:46) number of splitting indexes
for l = 1 : n do

8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24: procedure R(cid:48) = split(R, I (cid:48), [i j k], maxID{i, j, k})
R = [R1 R2 . . . Rm] (cid:46) multiple input sets
25:
R(cid:48) = [ ]
26:
for l = 1 : m do
27:
28:
29:
30: procedure R(cid:48) = stepSplit(Rl, I (cid:48), [i j k], maxID{i, j, k})
1 k;
31:
32:
33:
34:
35:

maxID{i, j, k} = [i(cid:48)
R(cid:48) = [ ]
for l = 1 : q do (cid:46) a single ImageStar is split into q ImageStars

[i j k] = splitID(l, :, :) (cid:46) get splitting index
R = split(R, I (cid:48), [i j k], maxID{i, j, k}) (cid:46) split ImageStars

IS = stepSplit(Rl, I (cid:48), [i j k], maxID{i, j, k}) (cid:46) step splitting
IS → R(cid:48)

(cid:46) store the new ImageStars

. . . ; i(cid:48)

1 j(cid:48)

q j(cid:48)

l j(cid:48)

the predicate variables that make a max-point candidate become the max point

36:
37:

V (cid:48) = Rl.V , V (cid:48)(i, j, k, :) = I (cid:48)(i(cid:48)
IS = (cid:104)V (cid:48), C (cid:48), d(cid:48)(cid:105), IS → R(cid:48)

l, j(cid:48)
l, k, :) (cid:46) update the basis
(cid:46) construct and store the reach set

max point = [i(cid:48)
l k], others = maxID{i, j, k} \ max point
[C (cid:48), d(cid:48)] = getConstraints(Rl, I (cid:48), max point, others) (cid:46) get the constraints on

q k] (cid:46) the local region has q max-points

Algorithm 1.2.3 Approximate reachability algorithm for a max pooling layer.

1: procedure R = reach exact(I = (cid:104)V, C, P (cid:105), poolSize, stride, paddingSize)
I (cid:48) = zero padding(I, paddingSize) (cid:46) zero padding for the input set
2:
[h, w] = get size maxM ap(I (cid:48), poolSize, stride) (cid:46) compute the size of the max map
3:
nc = I (cid:48).number channels, (cid:46) get the number of channels
4:
np0 = I (cid:48).number predicate variables (cid:46) get the number of predicate variables
5:
V (cid:48)(:, :, nc, np + 1) = zeros(h, w) (cid:46) pre-allocate the basis of the max map
6:
startID = get startP oints(I (cid:48), poolSize, stride)
7:

(cid:46) the start index for each local

region

maxID = cell(h, w, nc), (cid:46) to store the index of the max-point candidates
np = np0
for k = 1 : nc do

for i = 1 : h do

for j = 1 : w do

maxID{i, j, k} = I (cid:48).get localM ax index(startID{i, j}, poolSize, k)
if size(maxID{i, j, k}, 1) > 1 then

np = np + 1 (cid:46) increase the number of predicate variables

(cid:79) update the basis of the max map
new pred id = 0 (cid:46) new predicate variable index
for k = 1 : nc do

for i = 1 : h do

for j = 1 : w do

if size(maxID{i, j, k}, 1) == 1 then

for p = 1 : np0 + 1 do

[i(cid:48) j(cid:48) k] = maxID{i, j, k}
V (cid:48)(i, j, k, p) = I (cid:48).V (i(cid:48), j(cid:48), k, p)

else

V (cid:48)(i, j, k, 1) = 0
new pred id = new pred id + 1
V (cid:48)(i, j, k, np0 + 1 + new pre id) = 1

(cid:79) update the constraints on predicate variables
N = poolSize(1) × poolSize(2)
C (cid:48) = zeros(new pre id × (N + 1), np)
d(cid:48) = zeros(new pre id × (N + 1), 1)
l = 0
α = [α1 . . . αnp0+l . . . αnp]T (cid:79) vector of predicate variables
for k = 1 : nc do

for i = 1 : h do

for j = 1 : w do

if size(maxID{i, j, k}, 1) > 1 then

l = l + 1
(cid:79) get all related local pixel indexes
points = I (cid:48).get localP oints(startIDi, j, poolSize, k)
(cid:79) upper bound of new predicate variable: αnp0+l ≤ ub ≡ C1α ≤ d1
C1 = zeros(1, np), C1(np0 + l) = 1
(cid:79) get bounds of the local pixel values
[lb, ub] = I (cid:48).get localBound(startIDi, j, poolSize, k)
d1 = ub
C2 = zeros(N, np), d2 = zeros(N, 1)
for g = 1 : N do

[i(cid:48) j(cid:48)] = points(g, :)
(cid:79) new constraint: αl ≥ xi(cid:48) j(cid:48) k ≡ C2α ≤ d2
C2(g, 1 : np0) = I (cid:48).V (i(cid:48), j(cid:48), k, 2 : np0 + 1),
C2(g, np0 + l) = −1
d2(g) = −I (cid:48).V (i(cid:48), j(cid:48), k, 1)

C (cid:48)((l − 1) × (N + 1) + 1 : l × (N + 1), :) = [C1; C2]
d(cid:48)((l − 1) × (N + 1) + 1 : l × (N + 1)) = [d1; d2]

C (cid:48) = [I (cid:48).C zeros(size(I (cid:48).C, 1), l); C (cid:48)]
d(cid:48) = [I (cid:48).d; d(cid:48)]
R = (cid:104)V (cid:48), C (cid:48), d(cid:48)(cid:105)

8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:
39:
40:
41:
42:
43:
44:
45:
46:
47:
48:
49:
50:
51:
52:
53:
54:
55:
56:
57:
58:

Fig. 13: The architectures of the small, medium, and large MNIST classiﬁcation
networks.

layers, and 3 fully connected layers. Although ERAN has chosen 100 images for
the robustness analysis, we have experienced that only 48 images are correctly
classiﬁed by the network without any attacks which means the accuracy of the
network is very low (≈ 48%). Despite the low accuracy, we still use it to clarify
the advantages/disadvantages of our ImageStar approach in comparison with
ERAN-DeepZ. We note that the pixel values in the tested images are scaled into
[0, 1] in the analysis, and the well-known brightening attack [7] is used for the
robustness analysis of the network. For any image, the values of some pixels xi
are changed independently to x(cid:48)
i under the brightening attack which results in
a set of images that can be described by a zonotope Z = {x(cid:48)
i ≤
1 ∨ x(cid:48)
i = xi} where δ is called a robustness bound [7].

i|1 − δ ≤ xi ≤ x(cid:48)

The robustness veriﬁcation results are presented in Table 6 which shows that
our method gives a slightly better result than ERAN in terms of number of
veriﬁable images. Additionally, the veriﬁcation time of our approach grows very
quickly as the robustness value δ increases. The growth of veriﬁcation time is
the cost we need to pay to improve the conservativeness of the over-approximate
methods. One can see that, ERAN-DeepZ method is faster than the ImageStar
method when dealing with large input sets (e.g., more attacked pixels) since it
does not solve any LP optimization problems when constructing the reachable
sets. In the future, we are going to develop a more relaxed ImageStar method
that can neglect to solve LP optimization to deal with larger input sets.

98% accuracyMNIST_Smallimageinputconv_1batchnorm_1relu_1maxpool_1conv_2batchnorm_2relu_2maxpool_2conv_3batchnorm_3relu_3fcsoftmaxclassoutput99.7% accuracyMNIST_Mediumimageinputconv_1batchnorm_1relu_1maxpool_1conv_2batchnorm_2relu_2maxpool_2conv_3batchnorm_3relu_3conv_4batchnorm_4relu_4fc_1batchnorm_5relu_5fc_2softmaxclassoutput99.9% accuracyMNIST_Largeimageinputconv_1batchnorm_1relu_1maxpool_1conv_2batchnorm_2relu_2maxpool_2conv_3batchnorm_3relu_3conv_4batchnorm_4relu_4conv_5batchnorm_5relu_5fc_1batchnorm_6relu_6fc_2batchnorm_7relu_7fc_3softmaxclassoutputRobustness Results (in Percent)

δ = 0.005

δ = 0.008

δ = 0.01

δ = 0.012

δ = 0.015

ERAN ImageStar

ERAN ImageStar

ERAN ImageStar ERAN ImageStar ERAN ImageStar

48/48

48/48

46/48

47/48

46/48

47/48

44/48

46/48

44/48

46/48

Veriﬁcation Times (in Seconds)

115

78.05

122

155.45

123

153.67

130

454.44

129

468.49

Table 6: Veriﬁcation results of the CIFAR-10 ConvM axP ool network.

