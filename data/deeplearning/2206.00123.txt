1

Glo-In-One: Holistic Glomerular Detection,
Segmentation, and Lesion Characterization with
Large-scale Web Image Mining

Tianyuan Yao, Yuzhe Lu, Jun Long, Aadarsh Jha, Zheyu Zhu, Zuhayr Asad, Haichun Yang, Agnes B. Fogo,
Yuankai Huo

2
2
0
2

y
a
M
1
3

]

V
C
.
s
c
[

1
v
3
2
1
0
0
.
6
0
2
2
:
v
i
X
r
a

Abstract‚ÄîThe quantitative detection, segmentation, and char-
acterization of glomeruli from high-resolution whole slide imag-
ing (WSI) play essential roles in the computer-assisted diagnosis
and scientiÔ¨Åc research in digital renal pathology. Historically,
such comprehensive quantiÔ¨Åcation requires extensive program-
ming skills in order to be able to handle heterogeneous and
customized computational tools. To bridge the gap of performing
glomerular quantiÔ¨Åcation for non-technical users, we develop
the Glo-In-One toolkit to achieve holistic glomerular detection,
segmentation, and characterization via a single line of command.
Additionally, we release a large-scale collection of 30,000 un-
labeled glomerular images to further facilitate the algorithmic
development of self-supervised deep learning. The inputs of the
Glo-In-One toolkit are WSIs, while the outputs are (1) WSI-
level multi-class circle glomerular detection results (which can
be directly manipulated with ImageScope), (2) glomerular image
patches with segmentation masks, and (3) different lesion types.
In the current version, the Ô¨Åne-grained global glomeruloscle-
rosis (GGS) characterization is provided,
including assessed-
solidiÔ¨Åed (S-GGS, associated with hypertension-related injury),
disappearing (D-GGS, a further end result of the SGGS becoming
contiguous with Ô¨Åbrotic interstitium), and obsolescent (O-GGS,
nonspeciÔ¨Åc GGS increasing with aging) glomeruli. To leverage
the performance of the Glo-In-One toolkit, we introduce self-
supervised deep learning to glomerular quantiÔ¨Åcation via large-
scale web image mining. The GGS Ô¨Åne-grained classiÔ¨Åcation
model achieved a decent performance compared with baseline
supervised methods while only using 10% of the annotated data.
The glomerular detection achieved an average precision of 0.627
with circle representations, while the glomerular segmentation
achieved a 0.955 patch-wise Dice Similarity CoefÔ¨Åcient (DSC).
In this paper, we develop and release an open-source Glo-
In-One toolkit, a software with holistic glomerular detection,
segmentation, and lesion characterization. This toolkit is user-
friendly to non-technical users via a single line of command.

The toolbox and the 30,000 web mined glomerular images
have been made publicly available at https://github.com/hrlblab/
Glo-In-One.

Index Terms‚Äîopen-source, renal pathology, glomeular detec-

tion, lesion characterization, self-supervised learning

*Corresponding Author: Yuankai Huo, yuankai.huo@vanderbilt.edu

I. INTRODUCTION

G LOMERULI are central tufts of looped capillaries lo-

cated in the center of the renal corpuscle [1], [2], which

T. Yao, Y. Lu, Z. Zhu, A. Jha, Z. Asad, Y. Huo were with the Department

of Computer Science, Vanderbilt University, Nashville, TN 37235 USA.

J. Long was with Big Data Institute, Central South University, Changsha,

410083, China.

A. B. Fogo and H. Yang were with the Department of Pathology, Vanderbilt

University Medical Center, Nashville, TN, 37215, USA.

delivers blood and creates a large surface area optimized
for renal Ô¨Åltration [3], [4]. IdentiÔ¨Åcation and characterization
of glomeruli are essential for computer-assisted pathological
diagnosis in digital renal pathology [5], [6]. However, such
procedures are typically labor and resource intensive. The
recent advances in whole slide imaging (WSI) and deep learn-
ing have led to an unprecedented opportunity to characterize
glomerular lesions in a large-scale and fully automatic man-
ner [7]‚Äì[10]. Typical high-resolution WSI images are in the
order of gigapixels and are usually stored in multi-resolution
pyramidal format [11].

Historically, comprehensive computer-assisted glomerular
quantiÔ¨Åcation requires extensive programming skills to handle
the heterogeneous and custom computational tools [12]‚Äì[16]
. To bridge the gap of performing glomerular quantiÔ¨Åcation
for non-technical users, we develop the Glo-In-One toolkit
to achieve holistic glomerular detection, segmentation, and
characterization via a single line of command (Fig. 1).

For the glomerular detection [17]‚Äì[20], we apply an anchor-
free detection method with a circle representation [21]. The
simple circle representation is optimized for ball-shaped
biomedical object detection with smaller degrees of freedom
(DoF) in Ô¨Åtting and superior detection performance which is
optimized for glomerular detection in renal pathology. Then,
the Glo-In-One toolkit further segments and classiÔ¨Åes each
detected glomerulus with a pixel-level mask and Ô¨Åne-grained
Global glomerulosclerosis (GGS) classiÔ¨Åcation. GGS is a
prevalent pathological phenotype for patients with both normal
aging and kidney disease [22]‚Äì[24]. Fine-grained characteriza-
tion of glomerular lesions [25], is essential in nephropathology
in order to support both scientiÔ¨Åc research and clinical decision
making [26].

Lesion characterization involves the development of quanti-
tative machine learning approaches (e.g., self-supervised deep
learning) that characterize glomerular lesions typically require
large-scale heterogeneous images [16], [27], [28], which is
resource extensive for individual
labs. We Ô¨Årst assess the
feasibility of leveraging Ô¨Åne-grained GGS characterization via
large-scale web image mining (e.g., from journals, search
engines, websites) and self-supervised deep learning. Three
types of GGS are assessed-solidiÔ¨Åed (S-GGS, associated with
hypertension-related injury), disappearing (D-GGS, a further
end result of the SGGS becoming contiguous with Ô¨Åbrotic
interstitium), and obsolescent (O-GGS, nonspeciÔ¨Åc GGS in-
creasing with aging). We employ a SimSiam [29] network as

 
 
 
 
 
 
2

Fig. 1: This Ô¨Ågure presents the overview of the Glo-In-One toolkit. The inputs are raw WSIs, while the outputs are quantitative
detection, classiÔ¨Åcation, and segmentation results. Moreover, the results can be manipulated using the prevalent Aperio
ImageScope software. The domain impact is to enable comprehensive glomerular quantiÔ¨Åcation via one single command for
non-technical users. The technical innovation is to introduce large-scale self-supervised deep learning via web image mining.

the baseline method of self-supervised contrastive learning. By
deploying our previously developed compound Ô¨Ågure separa-
tion approach [30], we provide 30,000 unannotated glomerular
images via web image mining to train the SimSiam network.
From the results, the GGS Ô¨Åne-grained classiÔ¨Åcation model
achieved superior performance as compared with the baseline
methods. We release such large-scale collection of unlabeled
glomerular images to further facilitate the methodological de-
velopment of self-supervised deep learning for the engineering
community.

Our contribution is four fold:
‚Ä¢ We develop and release an open-source Glo-In-One
toolkit: a containerized software with holistic glomerular
detection, segmentation, and lesion characterization. The
toolkit is user friendly to non-technical users via a single
line of command, with standard WSI Ô¨Åles as inputs.
‚Ä¢ We assess the feasibility of mining large-scale web im-
ages for Ô¨Åne-grained GGS classiÔ¨Åcation via contrastive
learning.

‚Ä¢ We release a large-scale web-mined glomerular dataset
to facilitate the
with 30,000 unannotated glomeruli
methodological development of self-supervised deep

learning.

‚Ä¢ The toolbox and the 30,000 web mined glomerular im-
ages have been made publicly available at https://github.
com/hrlblab/Glo-In-One

II. RELATED WORKS

The success of deep convolutional neural networks (CNNs)
in recent years has spurred extensive research on their appli-
cation in renal pathology [31]‚Äì[33]. The innovations can be
summarized as glomerular detection, segmentation, and char-
acterization, which have further advanced digital diagnostic
imaging, especially in WSIs technology [34]‚Äì[36].

A. Glomerulosclerosis ClassiÔ¨Åcation

Many studies have been conducted to classify different
glomerular lesions using computer-aided approaches [8], [37]‚Äì
[39]. SpeciÔ¨Åcally, Uchino et al. [40] trained deep learning
algorithms to classify several renal pathological Ô¨Åndings and
achieved an AUC score of 0.983 for global sclerosis charac-
terization. However, most algorithms are tested using in-house
data and thus, their performances can be highly volatile in the

InputsDetectionClassificationSegmentationWeb Image MiningCompound figure separationSelf-supervise learningùëìùëìŒ∏ùëìùëìŒ∏Online image search engineClassification + Detection + SegmentationOutputsabcdface of a distribution shift [41]. Moreover, there are few, if
any, studies that have developed deep learning approaches to
classify globally sclerotic glomeruli into the following three
Ô¨Åne-grained categories: obsolescent, solidiÔ¨Åed, and disappear-
ing glomerulosclerosis. Such Ô¨Åne-grained characterization is
challenging as the available data is rare and their distribution
is highly imbalanced. For instance, the presence of obsolescent
glomerulosclerosis is naturally much higher than solidiÔ¨Åed
or disappearing glomerulosclerosis [42], [43], leading to the
technical difÔ¨Åculty that
is well known as the imbalanced
classiÔ¨Åcation problem [44]‚Äì[46].

1) Self-supervised learning method: Self-supervised learn-
ing represents a family of learning algorithms that could
learn the hidden regularities from using data without manual
annotations (e.g., unannotated renal pathological images) [47].
Such technology might alleviate the bottleneck of the scale
of human annotation in healthcare as large-scale unannotated
data could be available from clinical database. Moreover, the
generalizability of the AI models on unseen testing data would
be further improved by learning from a larger scale of training
data, even without human annotations [48].

Recently, a new family of self-supervised representation
learning, known as contrastive learning, has shown its superior
performance in various computer vision tasks
[49]‚Äì[52].
Using an approach where learning is achieved from large-scale
unlabeled data, contrastive learning can learn discriminative
features for downstream tasks. SimCLR [53] maximized the
similarity between images in the same category and repelled
the representations of different category images. The ‚Äòsimi-
larity‚Äô is typically deÔ¨Åned as the cosine similarity between
features [54] in the previous prior arts. Wu et al. [49] used an
ofÔ¨Çine dictionary to store all data representation and randomly
selected training data to maximize negative pairs. MoCo [55]
introduced a momentum design to maintain a negative sample
pool instead of an ofÔ¨Çine dictionary. Such works demanded a
large batch size in order to include sufÔ¨Åcient negative samples.
To eliminate the needs of negative samples, BYOL [56] was
proposed to train a model with an asynchronous momentum
encoder. Recently, SimSiam [29] was proposed to further
eliminate the momentum encoder in BYOL, allowing for less
GPU memory consumption.

B. Glomerular Detection

The introduction of WSIs demonstrates a paradigm shift
of computer-aided diagnosis (CAD) from visual inspection
to a more accurate quantitative assessment. CAD, especially
with recent advances in deep learning, offers an unparalleled
ability to efÔ¨Åciently manage patients, accelerate diagnosis, and
guide treatments in general health care. In renal pathology,
the promising results of integrating CAD in chronic kid-
ney diseases (CKD) and kidney transplantation have been
shown from prior arts [16], [57], especially with automatic
glomerular characterization [37], [58]. In renal pathology,
properly distinguishing and characterizing different glomeruli
from renal tissues is a key task in both corresponding scientiÔ¨Åc
research and clinical practice. In recent years, such historically
labor-intensive procedures have been advanced by modern

3

deep learning techniques, via classiÔ¨Åcation, detection, and
segmentation approaches [59]. Several studies have shown the
great accuracy by which CNNs are able to properly detect and
localize glomeruli within WSIs. Similarly, CNNs have also
been able to accurately segment glomeruli. Beyond identifying
the regional and pixel location of glomeruli, deep learning
algorithms have also been applied in CAD (e.g., pathological
glomerular characterization), such as quantifying and charac-
terizing lesion sub-types of glomeruli. For example, Gallego et
al. [9] used CNN-based classiÔ¨Åcation, while Gloria et al. [60]
utilized semantic segmentation to achieve glomeruli detection
in WSIs. More recently, Yang et al. proposed an anchor-
free detection strategy using circle representation [21] that
is optimized for round glomeruli and demonstrates superior
performance.

C. Glomerular Segmentation

An initial step for renal tissue assessment is the differenti-
ation and segmentation of relevant tissue structures in kidney
specimens as it is performing pixel-level quantiÔ¨Åcation on the
image [32], [61], [62]. However, Segmentation on WSIs is
challenging since the pixel-level annotation is computational
extensive on the gigapixel high-resolution images [63], [64].
Bouteldja et al investigated the concept of active learning for
accurate segmentation accuracy [65] by performing a large
number of 72,722 expert-based annotations, while Gadermayr
et al has proposed a weakly supervised pipeline for segmenting
renal glomeruli [66]. Other method, to achieve instance object
level segmentation, has integrated fully convolutional networks
with detection methods on WSIs(e.g., Mask-RCNN [67]), but
there is still room to improve [68], [69].Recently, Aadarsh et
al. [70] shows that the ‚Äùdetect-then-segment‚Äù two-stage seg-
mentation approach yields more accurate results than the con-
ventional single-stage instance segmentation tactics. Following
this study, we propose a detect-classify-segment pipeline to
achieve even more accurate glomerular segmentation results.

III. METHOD

Generally, the glomerular quantiÔ¨Åcation in this study can
be summarized into three major steps: (1) detection, (2) char-
acterization, and (3) segmentation (Fig. 2 and 3). First, Cir-
cleNet [21], [71] is employed to perform automatic glomerular
detection. After the detection, we extract image patches that
contain the detected glomeruli and add padding (50 pixels)
around the patches. Then, all the patches are cropped and
resized to 256√ó256-pixel for downstream tasks using bilinear
interpolation, while the information of the bounding box and
actual size (0.25 ¬µm per pixel) is saved in an XML Ô¨Åle. For the
task of classiÔ¨Åcation, our self-supervised contrastive learning
approach uses minimal human efforts (e.g., self-supervised
learning) to achieve Ô¨Åne-grained GGS classiÔ¨Åcation via large-
scale web image mining. The procedure consists of two parts:
(1) web data mining from biomedical databases via compound
Ô¨Ågure separation, and (2) self-supervised learning with down-
stream classiÔ¨Åcation tasks. For the step of segmentation, we
apply the DeepLab v3 model to perform the segmentation and
generate binary masks.

4

Fig. 2: The self-supervised glomerular characterization pipeline is presented. Our approach utilizes the large-scale unannotated
web-mined glomerular images via compound image separation to pretrain a contrastive learning model. Then, a smaller amount
of labeled data, especially for rare GGS samples, are employed to Ô¨Ånetune the pretrained model. The goal is to improve the
glomerular classiÔ¨Åcation via large-scale unannotated web-mined images and small-scale annotated in-house data.

Fig. 3: (a) The detection framework with circle representation [21] is presented, which is an optimized object detection method
for glomeruli. The heatmap and local offset head determines the center point of the circle while the circle radius head determines
the radius of the circle. (b) The DeepLab v3 backbone is employed in the ‚Äùdetect-then-segment‚Äù pipeline.

Data Augmentationx1x2y2y1z2encoderencoderpredictorsimilarityPretrained ModelWhole Slide Images (WSI)Glomerulus DetectionPerformance metrics(balanced accuracy, F1 ‚Ä¶)Web ImageMiningCompoundFigureSeparationOpen-sourceBiomedicalImage DatabaseCross-validationExternal-validationLinear FinetuneExtract Image Patches from Detection95616 x 57624 (Original slides)512 x 512CircleNetHigh-resolution Patch ExtractionGlomeruli Patches(1:1)23904 x 14406 (16X Down-sample)HeatMapLocal OffsetCircle RadiusFeatureExtraction1x1 Conv3x3 ConvRate 63x3 ConvRate 123x3 ConvRate 18ImagePooling1x1 Conv1x1 ConvConcatUpsampleby43x3 ConvUpsampleby4Low-LevelFeaturesEncoderDecoderDCNN(a) Glomerular Detection(b) Glomerular Segmentation5

Fig. 4: This Ô¨Ågure shows Ô¨Åne-grained classes of glomerular images that are stained with PAS. (a) Normal glomeruli, (b)
non-glomerular and (c)-(e) sclerosed glomeruli images. Three types of sclerosed glomeruli are (c) assessed-solidiÔ¨Åed (S-GGS,
associated with hypertension-related injury), (d) disappearing (D-GGS, a further end result of the SGGS becoming contiguous
with Ô¨Åbrotic interstitium), and (e) obsolescent (O-GGS, nonspeciÔ¨Åc GGS increasing with aging) glomeruli.

A. Glomerular ClassiÔ¨Åcation

mining.

In the Glo-In-One toolkit, we performed a Ô¨Åne-grained
GGS classiÔ¨Åcation as the application (Fig. 2 and 4). First, all
glomeruli images that were detected by Glo-In-One (details
are provided the in the next section) were further reÔ¨Åned as
glomerular vs. non-glomerular images. Second, all conÔ¨Årmed
glomeruli images were further classiÔ¨Åed into GGS vs. non-
GGS images. Third, GGS images were characterized into
Ô¨Åne-grained categories: (1) solidiÔ¨Åed (S-GGS, associated with
hypertension-related injury), (2) disappearing (D-GGS, an
end result of the S-GGS becoming contiguous with Ô¨Åbrotic
interstitium), and (3) obsolescent (O-GGS, nonspeciÔ¨Åc GGS
increasing with aging) glomeruli. The technical innovation
of our method was introducing the contrastive learning as
a self-supervised pretraining stage to enhance the glomerular
classiÔ¨Åcation performance.

1) Web Image Mining: We propose to achieve large-scale
unannotated glomerular images from online resources (e.g.,
open-access journals, NIH Open-i(cid:114) [72] database, and search
engines) in order to facilitate self-supervised contrastive learn-
ing (Fig. 2). BrieÔ¨Çy, we collect 10,000 compound Ô¨Ågures
with the keywords ‚Äúglomerular OR glomeruli OR glomerulus‚Äù
through the NIH Open-i(cid:114) search engine. The details of web
image mining are provided in [30].

However, the images from online resources are typically
in compound Ô¨Ågures (with multiple subplots), which can-
not be directly used for self-supervised learning. Thus, we
employ our previously developed compound image separa-
tion approach [30] to detect, separate, and curate subplots
to individual images for downstream learning tasks. Using
the compound Ô¨Ågure separation approach, we acquired over
30,000 unannotated glomerular images via large web image

2) Self-supervised Learning: As opposed to traditional su-
pervised learning methods, self-supervised learning [48] refers
to inferring underlying patterns from an unlabeled dataset
without any reference to labeled outcomes or predictions
(Fig. 2). We employ the SimSiam network [53] according
image analytical study using
to our previous pathological
multiple contrastive learning methods [73]. The SimSiam
network can be interpreted as an iterative process of two steps:
(1) unsupervised clustering and (2) feature updates based
on clustering (similar to K-means or EM algorithms) [29].
After training the SimSiam with large-scale mined images, a
pretrained ResNet backbone is available as a so called feature
encoder. Then, the output of the encoder is passed through
a predictor which is again a shallow fully-connected network
for the Ô¨Ånal classiÔ¨Åcation results.

B. Glomerular Detection

The glomerular detection function is implemented based
on our previously proposed CircleNet method [21], [71],
which introduces a new bounding circle representations for
glomerular detection (Fig. 3). Since CircleNet achieved su-
perior performance for glomerular detection compared with
current benchmarks [21], [71], we directly migrate CircleNet
as the detection method in this study. The detection outcomes
are saved in one XML Ô¨Åle that contains the circle location,
type, and the detection score for each detected object. The
detection score is a score within 0 to 1, where a larger score
indicates the stronger conÔ¨Ådence to believe the detected object
is a glomerulus. The XML format Ô¨Åle can be loaded with
pathology slide viewing software such as Aperio ImageScope.

(a)Normal glomeruli(c)S-GGS(b)Non-glomerular(d)D-GGS(e) O-GGSC. Glomerular Segmentation

The glomerular segmentation function is implemented
based on our previously proposed ‚ÄúDetect-then-Segment‚Äù
method [70] (Fig. 3). In segmentation, instead of directly
apply segmentation approaches on lower resolution image
patches, our ‚ÄúDetect-then-Segment‚Äù two-stage design [70]
applies DeepLab v3 [74] on the detected high-resolution
glomerular patches with minized information loss. Such design
has been demonstrated to outperform the prevelent single-
stage approaches [70]. The DeepLab v3 [74] is employed
as the segmentation backbone. DeepLab v3 utilizes atrous
convolution which allows it to enlarge the Ô¨Åeld of view of
Ô¨Ålters to incorporate larger context. It thus offers an efÔ¨Åcient
mechanism to balance accurate localization (small Ô¨Åeld-of-
view) and context assimilation (large Ô¨Åeld-of-view).

IV. EXPERIMENTS AND RESULTS

A. Glomerular ClassiÔ¨Åcation

1) Data: Model Pretrain.In this study, we collected over
10,000 compound Ô¨Ågures (each Ô¨Ågure might contain multiple
subplots) through the NIH Open-I(cid:114) search engine with the
keywords ‚Äúglomerular OR glomeruli OR glomerulus‚Äù. Then,
our compound Ô¨Ågure separation method [30] was employed
to separate compound images into individual images, which
were further categorized to different modalities (e.g., light
microscopy, Ô¨Çorescent microscopy, and electron microscopy)
as well as different stain types within the light microscopy. To
curate all images, an automatic deep learning-based curator
(detector) was trained using only a smaller scale annotated
images dataset [75]. Then, the curator was run on all web
mined images in order to drop the predicted glomerular
Ô¨Ågures under a detection score of 0.7. The 0.7 threshold was
determined empirically by visual inspection. Eventually, more
than 30,000 glomerular images (subplots) passed the curation.
The number and size of the image patches used for different
learning strategies are described in Experimental Design.

TABLE I: Distribution of subclasses in glomerular classiÔ¨Åer

Type

Quantity

Percentage

Total

Normal
obsolescent glomeruli
solidiÔ¨Åed glomerul
disappearing glomerul
Non-glomerular

3,617
6,647
735
459
10,619
*As mentioned, the collected dataset is naturally unbalanced.

16%
30%
3%
2%
49%

22,077

Cross Validation. The classiÔ¨Åcation models were trained on
22,077 images extracted from WSIs using the EasierPath semi-
manual annotation software [76]. The WSIs were acquired
from 157 patients, whose tissues were routinely processed
and parafÔ¨Ån-embedded, with 3 ¬µm thickness sections cut
and stained with Periodic acid‚ÄìSchiff (PAS). The WSIs were
acquired at 40√ó with 0.25 ¬µm per pixel.

All glomeruli were manually annotated with 5 classes,
including 3,617 normal glomeruli, 6,647 globally obsolescent

6

glomeruli, 735 global solidiÔ¨Åed glomeruli, and 459 global
disappearing glomeruli, and 10,619 non-glomerular images
(Table I). The images were resized to 224√ó224-pixel for
training, validation, and testing. The data were de-identiÔ¨Åed,
and studies were approved by the Institutional Review Board
(IRB) at VUMC.

Additionally, 120 glomerular patches were derived from Ô¨Åve
WSIs of the kidney tissue which respectively from different
patients and were utilized as detection test set in our automatic
detection experimentation. The details of the data selection,
acquisition and clinical background were provided in [71].

For the segmentation experiment, we formed a cohort with
704 training, 98 validation and 147 internal testing images im-
ages which respectively extracted from 42, 7 and 7 WSIs using
our detection method. Meanwhile, a group of 385 glomerulus
pathologies from 5 external biopsy samples was used as
external testing data. Both GGS and none-GGS glomerulus
patches were manually annotated and the segmentation masks
were traced by a experienced pathologist.

External Validation. In addition to our in-house datasets, a
publicly available glomeruli dataset [77] was also employed as
an external validation cohort. The dataset consisted of 2,340
images containing a single glomerulus. Among them, 1,170
glomeruli were normal, while 1,170 glomeruli were sclerosed.
To further evaluate our method, the model was trained on
both 5-classes and 2-classes (binary) designs. In the binary
setting, (1) three types of sclerosed glomeruli (S-GGS, D-
GGS, O-GGS) were merged as a single positive class; (2) the
normal type was kept as the negative class; (3) 10,619 non-
glomerular images were discarded to ensure consistency with
the deÔ¨Ånition in [77].

2) Experimental Design: Fig 5 shows a precise presentation

for separate experiments.

All the models were trained and tested with Ô¨Åve-fold cross-
validation [78], where each fold was withheld as the testing
data once [79]. The remaining data for each fold was split
as 75% training data and 25% validation data. Furthermore,
to avoid data contamination, all glomeruli from the same
patient were used either for training, validation, or testing. We
employed a canonical design to prevent the data from leaking
since the testing data were withheld from the training and
validation data.

In our study, we used the same hyperparameters (initial
learning rate, batch size, and maximum number of epoch)
and data augmentation strategies across all folds [80], [81].
The batch size was determined as the maximum GPU mem-
ory limitation, while the initial learning rate (lr = 0.0001)
was determined empirically by all validation data. Since the
adaptive moment estimation (Adam) optimizer was used, even
with the same initial learning rate, the underlying real learning
rate was adjusted ‚Äúfold-by-fold‚Äù as an adaptive optimization
strategy. Via the Ô¨Åve-fold cross-validation [82], the optimal
epoch (model selection) of each fold was determined based
on the validation performance as a ‚Äúfold-by-fold‚Äù manner.

We adapted the SimSiam network [53] as the baseline
method of contrastive learning. Two random augmentations
from the same image were used as training data. In self-
supervised pretraining, 30,000 glomerulus pathologies from

7

Fig. 5: ClassiÔ¨Åcation experiment setting: (a) We evaluate different methods via the Ô¨Åve-fold cross-validation using the in-
house GGS dataset (multi-class). (b) An independent public dataset (binary) is employed to evaluate the trained models directly
as an external validation. (c) The external validation is performed by retraining a binary classiÔ¨Åer using different methods via
the in-house GSS dataset (binary).

web mining were resized to 224 √ó 224 pixels for model
training. For our web-mined glomerular dataset, 70% of the
images‚Äô length-width ratio are within 4:3 or 3:4. Moreover, the
random afÔ¨Åne transformation was employed in the data aug-
mentation, so that the images were resized to different aspect
ratios, rotated with random degrees, and even with shearing
before the downstream learning procedures. Therefore, we
simply resized all images to 224 √ó 224 resolution images. This
strategy has been widely used for large-scale image analysis in
prior arts [83]‚Äì[86]. Two particular augmentation transforms-
random resized crops and color distortions-are applied. In the
classiÔ¨Åer evaluation, only resizing to 224√ó224-pixel is applied
in the augmentation. We used the momentum SGD as the
optimizer. The Weight decay was set to 0.0001. The base
learning rate was lr = 0.05 and the batch size was 64. The
learning rate was lr√óBatchSize/256, which followed a cosine
decay schedule [87].

We used ResNet-50 as the backbone in supervised training.
The model was then trained using the Adam optimizer with a
base learning rate of 1e-4. The optimizer learning rate followed
(linear scaling [88]) lr√óBatchSize/256. We used the focal loss
[89] with Œ≥ = 2.5 for unbalanced classes. Each fold was trained
for 70 epochs, and the epoch with the best balanced accuracy
score on the validation set was used for testing.

To fully estimate the skill of the machine learning model on
unseen data, all the models were trained and tested with Ô¨Åve-
fold cross-validation, where each fold was withheld as testing
data once. The remaining data for each fold was split as 75%
training data and 25% validation data. Furthermore, to avoid
data contamination, all glomeruli from the same patient were
used either for training, validation, or testing.

To apply the self-supervised pre-training networks, we froze
our pretrained ResNet-50 model by adding one extra linear
layer which followed the global average pooling layer. When
Ô¨Ånetuning with the manually annotated glomeruli data, only

the extra linear layer was trained. We used focal loss and the
Adam optimizer to train the linear classiÔ¨Åer with based (initial)
learning rate of lr=30, weight decay=0, momentum=0.9, and
batch size=64 (follows [29]). To evaluate the impact of training
data size, we Ô¨Åne-tuned the classiÔ¨Åer of our self-supervised
learning model and the ImageNet pretrained model on 1, 5,
10, 25 and 100 percentages of annotated training data.

All experiments are performed on the same workstation,

with a NVIDIA Quadro P5000 GPU of 16GB memory.

3) Results: Cross Validation on In-house Dataset. As
shown in Table II, Ô¨Åne-tuning our pretrained SimSiam
(Backbone:ResNet-50) on the same size of dataset achieved
superior results as compared to training from scratch. Inter-
estingly, our model also outperformed ResNet-50 models that
were pretrained on ImageNet. Even Using 10% of all available
labeled data, our self-supervised ResNet50 model achieved the
comparable performance with the fully supervised ResNet-
50 models that used the entire labeled cohort. Moreover, the
computational efÔ¨Åciency was also evaluated. Since contrastive
learning only requires Ô¨Ånetuning on the linear layers, it yielded
less GPU memory (larger batch size) and higher computational
efÔ¨Åciency (Table II). Moreover, our pretrained model also
boosted accuracy upon the ImageNet pretrained ResNet-50.

The confusion matrices are shown in Fig. 6. Our model
achieved comparable performance as compared to the fully su-
pervised models, while only using 10% labeled data. Note that
our approach had superior performance on the two categories
(solidiÔ¨Åed and disappearing) which have smaller numbers of
cases.
External Validation on Public Dataset. For external valida-
tion, as shown in Table IIIa, trained with 5-classes labeled data,
our models showed superior performance with a domain shift.
The contrastive learning model achieved an AUC score of
94.5 when testing directly on the external dataset without any
Ô¨Ånetuning. Even the SimSiam model that previously Ô¨Ånetuned

Inhouse dataDataset 1 (5 class)Normal   O-GGS    S-GGS  D-GGS      Non-GloNormal       GGSDataset 2 (Binary)External Dataset (binary)Normal       GGSExternal dataExperiment 1: Cross-validationTraining dataTesting dataExperiment 2: External validationExperiment 3: External validation(a)(b)(c)8

*Supervised method refers to training a ResNet-50 from scratch

Fig. 6: Comparison between supervised method and our method

TABLE II: Performance of Ô¨Åne-grained GGS classiÔ¨Åcation

Model

Unlabeled data Labeled data Balance acc

F1

Time (s)

ResNet-50
(train from scratch)

ImageNet
(Ô¨Ånetune linear layers)

0

0

SimSiam
(Ô¨Ånetune linear layers)

30k

100%

100%
25%
10%
5%
1%

100%
25%
10%
5%
1%

65.0

62.0
59.6
59.2
58.0
52.3

68.0
66.8
65.1
64.4
59.2

61.7

159.8

51.9
50.5
48.4
46.1
42.1

62.5
60.8
59.7
54.8
52.8

43.7
36.6
29.1
28.7
28.2

42.1
35.2
33.2
29.8
27.8

*ResNet-50: we trained the entire ResNet-50 from scratch with fully supervised learning.
*ImageNet: we only Ô¨Ånetuned the linear layers of an ImageNet pretrained ResNet-50 model.
*SimSiam: we only Ô¨Ånetuned the linear layers of a SimSiam pretrained ResNet-50 model.

*Time: indicates the average computational time per epoch.

Supervised 100% labeled dataOur method 10% labeled dataon 10% of all available labeled data yielded better accuracy
than the fully supervised ResNet-50 models.

In the binary setting (Table. IIIb), the results yielded a
similar trend when compared to the results from the 5-classes
setting. BrieÔ¨Çy, using only 10% the labeled images, our model
outperformed supervised training models that used all labeled
images.

Note that Ô¨Ånetuning the ImageNet pretrained model outper-
formed the training-from-scratch model in external validation,
which is contrary to the results in cross validation. Such
phenomenon might be caused by the domain shift in external
validation. However, our method consistently outperformed
those methods in different scenarios.

B. Glomerular Detection

1) Experimental Design: We employed the CircleNet pre-
trained model [21], [76] as the baseline model. In this study,
we integrated the glomerular detection and classiÔ¨Åcation as
a uniÔ¨Åed framework to enhance the performance of object
detection. BrieÔ¨Çy, we introduced the ‚Äúnon-glomerlar‚Äù class
in the self-supervised ¬ßGlomerular ClassiÔ¨Åcation as a post-
processing module to further Ô¨Ålter out the false positive detec-
tion results. We report AP (average precision), AP50 and AP75
(average precision evaluated at 0.5 and 0.75 IoU threshold
respectively), AP over small (APS), and medium (APM)
objects, which shows the result of CircleNet detection [90].

2) Results: The results of glomerular detection was pre-
sented in Table. IVa and Fig. 7. By introducing the classiÔ¨Åer
as a false-positive Ô¨Ålter, the detection performance in our
Glo-In-One method achieved superior detection performance
compared with original CircleNet method.

C. Glomerular Segmentation

1) Experimental Design: We conducted analyses on two
of
the widely used segmentation backbones (U-Net and
DeepLab v3) on two unique resolutions (512√ó512, 256√ó256).
Since the images from the previous stage are 256√ó256 in
the pipeline, we did experiments respectively on bilinear
interpolation resizing and constant padding strategies. Mean
and standard deviation of Dice similarity coefÔ¨Åcients (DSC)
were the primary statistics used to evaluate segmentation
performance. The hyperparameters for training the U-Net and
DeepLab v3 pipelines were 150 epochs, a batch size of 4
and a learning rate of 1e-4. An Adam Optimizer was used
to adaptively alter the learning rate, with beta values ranging
from 0.9 to 0.999.

2) Results: From the results (Table. IVb), our pipeline
yielded decent DSC values across two backbone methods at
different training scenarios, which is comparable to the prior
arts [70]. Among the benchmark methods, the DeepLab v3
with 512√ó512 image resolution is preferred.

Fig. 8 presents the segmentation performance at the indi-
vidual WSIs level. The results show that the model achieves
consistent performance across different slides.

9

V. DISCUSSION

In this study, we introduced Glo-In-One, an integrated
glomerular quantiÔ¨Åcation open-source software toolkit for
glomerular detection, segmentation, and lesion characteriza-
tion. Only a single command line was required to perform
all quantiÔ¨Åcation tasks as a operating system agnostic Docker
implementation. In this multitask system, we combined several
well validated deep learning models and new self-supervised
learning algorithms to enhance the reliability of the AI system.
The proposed method would potentially be applied to the
kidney transplant patients to achieve a more comprehensive
pre-/post-operational evaluation with glomerulosclerosis char-
acterization across all glomeruli. Moreover, the web image
mining-based learning strategy might improve the diagnosis
of rare pathological phenotypes by integrating the constantly
updated knowledge from the community (e.g., from shared
case studies on social media, new scientiÔ¨Åc publications, and
new books).

Beyond releasing a holistic glomerular quantiÔ¨Åcation tool,
the core technical innovation was the self-supervised glomeru-
lar classiÔ¨Åcation section, where we introduced the con-
trastive learning paradigm of Ô¨Åne grained GSS characterization
via large-scale web image mining.The major focus of our
method is to assess the feasibility and efÔ¨Åcacy of incorpo-
rating the large-scale web mining data into computer-assisted
nephropathological diagnosis to (1) improve the accuracy
of the learning-based glomerulosclerosis characterization on
unbalanced categories, and (2) enhance the generalizability of
the AI models on unseen testing data.

This approach allows neural networks to learn more with
fewer labels, smaller samples, or fewer trials. By taking
advantages of these points, we come up with the idea of
combining self-supervised learning and web image mining.
Advanced detection algorithms and professional biomedical
image database have disabused our worries about quality
control when massively mining web images as training data.
One promising future direction is to integrate self-supervised
learning methods with web image mining in a poor annotation
situation (in which only WSI-wise weak labels are provided)
since our method does not require exhaustive tuning of hyper-
parameters and needs a smaller number of annotations.

In the classiÔ¨Åcation experiment, the hyper-parameter tun-
ning strategy in a cross-validation study is typically a
‚Äúvariance-bias‚Äù tradeoff. For example, as shown in the compre-
hensive study [82], cross-validation without hyper-parameter
tunning yielded a lower variance but a higher bias compared
with cross-validation with fold-by-fold hyper-parameter tun-
ning. Therefore, we further conducted external validations
(using an independent external cohort) to alleviate such con-
cerns in cross-validation based evaluation, as a more rigor
assessment.

From the results, the proposed strategy achieved superior
performance in the task of GGS Ô¨Åne-grained classiÔ¨Åcation,
with fewer human efforts. By deploying our previously de-
veloped compound Ô¨Ågure separation approach, we provided
30,000 web-mined unannotated glomerular images to pretrain
the ResNet classiÔ¨Åcation network via SimSiam contrastive

10

TABLE III: Performance on external validation

(a) Train on 5-classes dataset

(b) Train on binary dataset

Methods

Labeled data AUC

Methods

Labeled data AUC

ResNet-50
(train from scratch)

ImageNet
(Ô¨Ånetune linear layers)

SimSiam
(Ô¨Ånetune linear layers)

100%

91.3

100%

100%
25%
10%
5%
1%

92.4

94.5
93.3
92.6
92.2
89.9

ResNet-50
(train from scratch)

ImageNet
(Ô¨Ånetune linear layers)

SimSiam
(Ô¨Ånetune linear layers)

100%

93.3

100%

100%
25%
10%
5%
1%

93.6

95.2
94.8
94.2
92.2
90.7

*DeÔ¨Ånitions please see Table II

Fig. 7: This Ô¨Ågure presents the WSI-level multi-class circle glomerular detection results, which are visualized by ImageScope.

(a) Detection Results

(b) Segmentation Results

Method

AP

AP50

AP75

APS

CircleNet
Ours

0.621
0.627

0.920
0.951

0.588
0.604

0.554
0.573

*Ours: we used the CircleNet v2 model
with our second-stage classiÔ¨Åer.

APM

0.749
0.758

512√ó512a
512√ó512b
Model
U-Net
0.934 ¬± 0.062
0.940 ¬± 0.029
0.955 ¬± 0.045
0.950 ¬± 0.044
DeepLab v3
*512√ó512a: constant padding from 256√ó256
*512√ó512b: bilinear resized from 256√ó256
*256√ó256: original resolution

256√ó256
0.947 ¬± 0.037
0.945 ¬± 0.047

TABLE IV: (a) For Detection, we report AP (average precision), AP50 and AP75 (average precision evaluated at 0.5 and 0.75
IoU threshold respectively), AP over small (APS), and medium (APM) objects (b) For segmentation, we report mean and
standard deviation of Dice similarity coefÔ¨Åcients (DSC) to evaluate the two backbone methods.

learning. From the results, the GGS Ô¨Åne-grained classiÔ¨Åcation
model achieved superior performance when compared with
baseline methods on both cross validation and external val-
idation. However, the proposed method is still limited in its
performance gain (mostly around 1%). The recent advances
in self-supervised learning have drawn signiÔ¨Åcant attention to-
wards the promising data efÔ¨Åciency and generalization ability.

This approach assesses the feasibility of adapting such learning
strategies to digital pathology with smaller scale annotated
data and larger scale web mined data. One promising future
direction is to further extend the proposed learning framework
to the weakly supervised learning scenarios (in which only
WSI-wise weak labels are provided).
limitations and potential

improvements for our

Several

Original WSIOverlay with AperioImageScope11

REFERENCES

[1] W. E. Hoy, R. N. Douglas-Denton, M. D. Hughson, A. Cass, K. Johnson,
and J. F. Bertram, ‚ÄúA stereological study of glomerular number and
volume: preliminary Ô¨Åndings in a multiracial study of kidneys at
autopsy,‚Äù Kidney International, vol. 63, pp. S31‚ÄìS37, 2003.

[2] P. Kimmelstiel and C. Wilson, ‚ÄúIntercapillary lesions in the glomeruli
of the kidney,‚Äù The American journal of pathology, vol. 12, no. 1, p. 83,
1936.

[3] I. Murray and M. A. Paolini, ‚ÄúHistology, kidney and glomerulus,‚Äù 2020.
[4] R. P. Scott and S. E. Quaggin, ‚ÄúThe cell biology of renal Ô¨Åltration,‚Äù

Journal of cell biology, vol. 209, no. 2, pp. 199‚Äì210, 2015.

[5] B. A. Santo, A. Z. Rosenberg, and P. Sarder, ‚ÄúArtiÔ¨Åcial intelligence
driven next-generation renal histomorphometry,‚Äù Current opinion in
nephrology and hypertension, vol. 29, no. 3, pp. 265‚Äì272, 2020.
[6] G. K. Rangan and G. H. Tesch, ‚ÄúQuantiÔ¨Åcation of renal pathology by
image analysis (methods in renal research),‚Äù Nephrology, vol. 12, no. 6,
pp. 553‚Äì558, 2007.

[7] L. Barisoni, C. C. Nast, J. C. Jennette, J. B. Hodgin, A. M. Herzenberg,
K. V. Lemley, C. M. Conway, J. B. Kopp, M. Kretzler, C. Lienczewski
et al., ‚ÄúDigital pathology evaluation in the multicenter nephrotic syn-
drome study network (neptune),‚Äù Clinical Journal of
the American
Society of Nephrology, vol. 8, no. 8, pp. 1449‚Äì1459, 2013.

[8] C. Zeng, Y. Nan, F. Xu, Q. Lei, F. Li, T. Chen, S. Liang, X. Hou,
B. Lv, D. Liang et al., ‚ÄúIdentiÔ¨Åcation of glomerular lesions and intrinsic
glomerular cell types in kidney diseases via deep learning,‚Äù The Journal
of pathology, vol. 252, no. 1, pp. 53‚Äì64, 2020.

[9] J. Gallego, A. Pedraza, S. Lopez, G. Steiner, L. Gonzalez, A. Laurinavi-
cius, and G. Bueno, ‚ÄúGlomerulus classiÔ¨Åcation and detection based on
convolutional neural networks,‚Äù Journal of Imaging, vol. 4, no. 1, p. 20,
2018.

[10] C. C. Nast, K. V. Lemley, J. B. Hodgin, S. Bagnasco, C. Avila-
Casado, S. M. Hewitt, and L. Barisoni, ‚ÄúMorphology in the digital
age: integrating high-resolution description of structural alterations with
phenotypes and genotypes,‚Äù in Seminars in nephrology, vol. 35, no. 3.
Elsevier, 2015, pp. 266‚Äì278.

[11] M. Khened, A. Kori, H. Rajkumar, G. Krishnamurthi, and B. Srinivasan,
‚ÄúA generalized deep learning framework for whole-slide image segmen-
tation and analysis,‚Äù ScientiÔ¨Åc reports, vol. 11, no. 1, pp. 1‚Äì14, 2021.

[12] J. N. Kather, A. T. Pearson, N. Halama, D. J¬®ager, J. Krause, S. H.
Loosen, A. Marx, P. Boor, F. Tacke, U. P. Neumann et al., ‚ÄúDeep
learning can predict microsatellite instability directly from histology in
gastrointestinal cancer,‚Äù Nature medicine, vol. 25, no. 7, pp. 1054‚Äì1056,
2019.

[13] E. Moen, D. Bannon, T. Kudo, W. Graf, M. Covert, and D. Van Valen,
‚ÄúDeep learning for cellular image analysis,‚Äù Nature methods, vol. 16,
no. 12, pp. 1233‚Äì1246, 2019.

[14] P. Mobadersany, S. YouseÔ¨Å, M. Amgad, D. A. Gutman, J. S. Barnholtz-
Sloan, J. E. V. Vega, D. J. Brat, and L. A. Cooper, ‚ÄúPredicting cancer
outcomes from histology and genomics using convolutional networks,‚Äù
Proceedings of the National Academy of Sciences, vol. 115, no. 13, pp.
E2970‚ÄìE2979, 2018.

[15] A. H. Beck, A. R. Sangoi, S. Leung, R. J. Marinelli, T. O. Nielsen,
M. J. Van De Vijver, R. B. West, M. Van De Rijn, and D. Koller,
‚ÄúSystematic analysis of breast cancer morphology uncovers stromal
features associated with survival,‚Äù Science translational medicine, vol. 3,
no. 108, pp. 108ra113‚Äì108ra113, 2011.

[16] Y. Huo, R. Deng, Q. Liu, A. B. Fogo, and H. Yang, ‚ÄúAi applications in

renal pathology,‚Äù Kidney International, 2021.

[17] Y. Kawazoe, K. Shimamoto, R. Yamaguchi, Y. Shintani-Domoto,
H. Uozaki, M. Fukayama, and K. Ohe, ‚ÄúFaster r-cnn-based glomeru-
lar detection in multistained human whole slide images,‚Äù Journal of
Imaging, vol. 4, no. 7, p. 91, 2018.

[18] M. Temerinac-Ott, G. Forestier, J. Schmitz, M. Hermsen, J. Br¬®asen,
in renal
F. Feuerhake, and C. Wemmert, ‚ÄúDetection of glomeruli
pathology by mutual comparison of multiple staining modalities,‚Äù in
Proceedings of the 10th International Symposium on Image and Signal
Processing and Analysis.

IEEE, 2017, pp. 19‚Äì24.

[19] J. D. Bukowy, A. Dayton, D. Cloutier, A. D. Manis, A. Staruschenko,
J. H. Lombard, L. C. S. Woods, D. A. Beard, and A. W. Cowley,
‚ÄúRegion-based convolutional neural nets for localization of glomeruli
in trichrome-stained whole kidney sections,‚Äù Journal of the American
Society of Nephrology, vol. 29, no. 8, pp. 2081‚Äì2088, 2018.

[20] R. Mar¬¥ee, S. Dallongeville, J.-C. Olivo-Marin, and V. Meas-Yedid, ‚ÄúAn
approach for detection of glomeruli in multisite digital pathology,‚Äù in
2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI).
IEEE, 2016, pp. 1033‚Äì1036.

Fig. 8: This Ô¨Ågure presents the segmentation performance for
glomerulus on external WSIs respectively. The bar plots show
the mean values of Dice Similarity CoefÔ¨Åcients (DSC) while
the error bars represent the standard deviation.

work are as follows. First, integrating with a 3D registration
algorithm would be an avenue for improvement for renal
pathology as sequential cutting is typically involved [91].
With 3D quantiÔ¨Åcation, we can potentially get more precise
quantiÔ¨Åcation of glomeruli, such as the average volume that
represents the patients‚Äô degree of kidney sclerosis. Second,
integrating interactive user quality assurance (QA) interface
might enable more precise results with a ‚Äúhuman-in-the-loop‚Äù
design. Third, from the results, the methods are limited by
around 50% of accuracy on GGS sub-classes classiÔ¨Åcation,
another potential improvement in terms of the performance
could be to build up a more class-balanced Ô¨Åne grained GGS
dataset. The binary classiÔ¨Åcation cohort was used as our
external validation data. Another external validation cohort
with multiple GSS types would lead to a more comprehensive
external validation. However, to our best, such a dataset is not
publicly available to further exam the generalizability of our
multi-class model.

VI. CONCLUSIONS

In this paper, we develop and release a holistic Glo-In-One
open-source toolkit to provide holistic glomerular detection,
segmentation, and lesion characterization. The containerized
machine learning system process gigapixel renal WSIs in a
fully automated manner with a single command line, which is
user-friendly for non-technical users. Our technical contribu-
tion focuses on combining cost-efÔ¨Åcient and large-scale web
image mining with self-supervised algorithms to achieve supe-
rior performance in glomerular detection and Ô¨Åne grained GSS
classiÔ¨Åcation. The results demonstrate that our self-supervised
ResNet50 achieves superior performance as compared with a
standard supervised ResNet-50 using all labeled images.

ACKNOWLEDGMENT

This work was supported by NIH NIDDK DK56942(ABF).

Performance on external WSIsPerformance on external WSIsMean DSC scoresSubject No.[21] H. Yang, R. Deng, Y. Lu, Z. Zhu, Y. Chen, J. T. Roland, L. Lu, B. A.
Landman, A. B. Fogo, and Y. Huo, ‚ÄúCirclenet: Anchor-free detection
with circle representation,‚Äù arXiv preprint arXiv:2006.02474, 2020.
[22] A. H. AbdelhaÔ¨Åz, S. H. Brown, A. Bello, and M. El Nahas, ‚ÄúChronic
kidney disease in older people: physiology, pathology or both?‚Äù Nephron
Clinical Practice, vol. 116, no. 1, pp. c19‚Äìc24, 2010.

[23] A. Greenberg, S. I. Bastacky, A. Iqbal, D. Borochovitz, and J. P.
Johnson, ‚ÄúFocal segmental glomerulosclerosis associated with nephrotic
syndrome in cholesterol atheroembolism: clinicopathological correla-
tions,‚Äù American journal of kidney diseases, vol. 29, no. 3, pp. 334‚Äì344,
1997.

[24] S. K. Lorbach, J. A. Hokamp, J. M. Quimby, and R. E. Cianciolo,
‚ÄúClinicopathologic characteristics, pathology, and prognosis of 77 dogs
with focal segmental glomerulosclerosis,‚Äù Journal of Veterinary Internal
Medicine, vol. 34, no. 5, pp. 1948‚Äì1956, 2020.

[25] J. Tan, Y. Xu, Z. Jiang, G. Pei, Y. Tang, L. Tan, Z. Zhong, P. Tarun, and
W. Qin, ‚ÄúGlobal glomerulosclerosis and segmental glomerulosclerosis
could serve as effective markers for prognosis and treatment of iga
vasculitis with nephritis,‚Äù Frontiers in medicine, vol. 7, p. 704, 2020.

[26] C. Benchimol, ‚ÄúFocal segmental glomerulosclerosis: pathogenesis and
treatment,‚Äù Current opinion in pediatrics, vol. 15, no. 2, pp. 171‚Äì180,
2003.

[27] B. Ginley, J. E. Tomaszewski, R. Yacoub, F. Chen, and P. Sarder,
‚ÄúUnsupervised labeling of glomerular boundaries using gabor Ô¨Ålters and
statistical testing in renal histology,‚Äù Journal of Medical Imaging, vol. 4,
no. 2, p. 021102, 2017.

[28] L. David, J. Ar¬¥us-Pous, J. Karlsson, O. Engkvist, E. J. Bjerrum, T. Kogej,
J. M. Kriegl, B. Beck, and H. Chen, ‚ÄúApplications of deep-learning in
exploiting large-scale and heterogeneous compound data in industrial
pharmaceutical research,‚Äù Frontiers in pharmacology, vol. 10, p. 1303,
2019.

[29] X. Chen and K. He, ‚ÄúExploring simple siamese representation learning,‚Äù

arXiv preprint arXiv:2011.10566, 2020.

[30] T. Yao, C. Qu, Q. Liu, R. Deng, Y. Tian, J. Xu, A. Jha, S. Bao,
M. Zhao, A. B. Fogo, B. A. Landman, C. Chang, H. Yang, and Y. Huo,
‚ÄúCompound Ô¨Ågure separation of biomedical images with side loss,‚Äù
2021.

[31] V. B. Kolachalama, P. Singh, C. Q. Lin, D. Mun, M. E. Belghasem, J. M.
Henderson, J. M. Francis, D. J. Salant, and V. C. Chitalia, ‚ÄúAssociation
of pathological Ô¨Åbrosis with renal survival using deep neural networks,‚Äù
Kidney international reports, vol. 3, no. 2, pp. 464‚Äì475, 2018.

[32] M. Hermsen, T. de Bel, M. Den Boer, E. J. Steenbergen, J. Kers,
S. Florquin, J. J. Roelofs, M. D. Stegall, M. P. Alexander, B. H.
Smith et al., ‚ÄúDeep learning‚Äìbased histopathologic assessment of kidney
tissue,‚Äù Journal of the American Society of Nephrology, vol. 30, no. 10,
pp. 1968‚Äì1979, 2019.

[33] L. Lu, Y. Zheng, G. Carneiro, and L. Yang, ‚ÄúDeep learning and
convolutional neural networks for medical image computing,‚Äù Advances
in computer vision and pattern recognition, vol. 10, pp. 978‚Äì3, 2017.

[34] P. Sarder, B. Ginley, and J. E. Tomaszewski, ‚ÄúAutomated renal
histopathology: Digital extraction and quantiÔ¨Åcation of renal pathology,‚Äù
in Medical Imaging 2016: Digital Pathology, vol. 9791.
International
Society for Optics and Photonics, 2016, p. 97910F.

[35] G. Bueno, M. M. Fernandez-Carrobles, L. Gonzalez-Lopez, and
O. Deniz, ‚ÄúGlomerulosclerosis identiÔ¨Åcation in whole slide images
using semantic segmentation,‚Äù Computer Methods and Programs
in Biomedicine, vol. 184, p. 105273, 2020.
[Online]. Available:
https://www.sciencedirect.com/science/article/pii/S0169260719311381

[36] N. Kumar, R. Gupta, and S. Gupta, ‚ÄúWhole slide imaging (wsi) in
pathology: current perspectives and future directions,‚Äù Journal of Digital
Imaging, vol. 33, pp. 1034‚Äì1040, 2020.

[37] J. N. Marsh, M. K. Matlock, S. Kudose, T.-C. Liu, T. S. Stappenbeck,
J. P. Gaut, and S. J. Swamidass, ‚ÄúDeep learning global glomerulosclero-
sis in transplant kidney frozen sections,‚Äù IEEE transactions on medical
imaging, vol. 37, no. 12, pp. 2718‚Äì2728, 2018.

[38] B. Ginley, K.-Y. Jen, A. Rosenberg, G. M. Rossi, S. Jain, and P. Sarder,
‚ÄúFully automated classiÔ¨Åcation of glomerular lesions in lupus nephritis,‚Äù
in Medical Imaging 2020: Digital Pathology, vol. 11320.
International
Society for Optics and Photonics, 2020, p. 113200Y.

[39] P. Chagas, L. Souza, I. Ara¬¥ujo, N. Aldeman, A. Duarte, M. Angelo,
W. L. Dos-Santos, and L. Oliveira, ‚ÄúClassiÔ¨Åcation of glomerular hy-
percellularity using convolutional features and support vector machine,‚Äù
ArtiÔ¨Åcial intelligence in medicine, vol. 103, p. 101808, 2020.

[40] E. Uchino, K. Suzuki, N. Sato, R. Kojima, Y. Tamada, S. Hiragi,
H. Yokoi, N. Yugami, S. Minamiguchi, H. Haga et al., ‚ÄúClassiÔ¨Åcation of
glomerular pathological Ô¨Åndings using deep learning and nephrologist-ai
collective intelligence approach,‚Äù medRxiv, pp. 2019‚Äì12, 2020.

12

[41] A. Fern¬¥andez, S. Garc¬¥ƒ±a, and F. Herrera, ‚ÄúAddressing the classiÔ¨Åcation
with imbalanced data: open problems and new challenges on class
distribution,‚Äù in International conference on hybrid artiÔ¨Åcial intelligence
systems. Springer, 2011, pp. 1‚Äì10.

[42] G. D. Cascarano, F. S. Debitonto, R. Lemma, A. Brunetti, D. Buon-
giorno, I. De Feudis, A. Guerriero, M. Rossini, F. Pesce, L. Gesu-
aldo et al., ‚ÄúAn innovative neural network framework for glomerulus
classiÔ¨Åcation based on morphological and texture features evaluated in
histological images of kidney biopsy,‚Äù in International Conference on
Intelligent Computing. Springer, 2019, pp. 727‚Äì738.

[43] M. E. M. Pierpont, A. S. Hentges, L. J. Gears, B. Hirsch, and A. Sinaiko,
‚ÄúUnbalanced 4; 6 translocation and progressive renal disease,‚Äù American
journal of medical genetics, vol. 95, no. 3, pp. 275‚Äì280, 2000.
[44] C. Huang, Y. Li, C. C. Loy, and X. Tang, ‚ÄúLearning deep representation
for imbalanced classiÔ¨Åcation,‚Äù in Proceedings of the IEEE conference
on computer vision and pattern recognition, 2016, pp. 5375‚Äì5384.
[45] Q. Zou, S. Xie, Z. Lin, M. Wu, and Y. Ju, ‚ÄúFinding the best classiÔ¨Åcation
threshold in imbalanced classiÔ¨Åcation,‚Äù Big Data Research, vol. 5, pp.
2‚Äì8, 2016.

[46] V. L¬¥opez, A. Fern¬¥andez, J. G. Moreno-Torres, and F. Herrera, ‚ÄúAnalysis
of preprocessing vs. cost-sensitive learning for imbalanced classiÔ¨Åcation.
open problems on intrinsic data characteristics,‚Äù Expert Systems with
Applications, vol. 39, no. 7, pp. 6585‚Äì6608, 2012.

[47] T. Hastie, R. Tibshirani, and J. Friedman, ‚ÄúOverview of supervised
learning,‚Äù in The elements of statistical learning. Springer, 2009, pp.
9‚Äì41.

[48] M. E. Celebi and K. Aydin, Unsupervised learning algorithms.

Springer, 2016.

[49] Z. Wu, Y. Xiong, S. X. Yu, and D. Lin, ‚ÄúUnsupervised feature learning
via non-parametric instance discrimination,‚Äù in Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, 2018, pp.
3733‚Äì3742.

[50] M. Noroozi and P. Favaro, ‚ÄúUnsupervised learning of visual representa-
tions by solving jigsaw puzzles,‚Äù in European conference on computer
vision. Springer, 2016, pp. 69‚Äì84.

[51] C. Zhuang, A. L. Zhai, and D. Yamins, ‚ÄúLocal aggregation for unsuper-
vised learning of visual embeddings,‚Äù in Proceedings of the IEEE/CVF
International Conference on Computer Vision, 2019, pp. 6002‚Äì6012.

[52] R. D. Hjelm, A. Fedorov, S. Lavoie-Marchildon, K. Grewal, P. Bach-
man, A. Trischler, and Y. Bengio, ‚ÄúLearning deep representations
by mutual information estimation and maximization,‚Äù arXiv preprint
arXiv:1808.06670, 2018.

[53] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, ‚ÄúA simple framework
for contrastive learning of visual representations,‚Äù in International
conference on machine learning. PMLR, 2020, pp. 1597‚Äì1607.
[54] H. V. Nguyen and L. Bai, ‚ÄúCosine similarity metric learning for face
veriÔ¨Åcation,‚Äù in Asian conference on computer vision. Springer, 2010,
pp. 709‚Äì720.

[55] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, ‚ÄúMomentum contrast
for unsupervised visual representation learning,‚Äù in Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition,
2020, pp. 9729‚Äì9738.

[56] J.-B. Grill, F. Strub, F. Altch¬¥e, C. Tallec, P. H. Richemond,
E. Buchatskaya, C. Doersch, B. A. Pires, Z. D. Guo, M. G. Azar et al.,
‚ÄúBootstrap your own latent: A new approach to self-supervised learning,‚Äù
arXiv preprint arXiv:2006.07733, 2020.

[57] J. U. Becker, D. Mayerich, M. Padmanabhan, J. Barratt, A. Ernst,
P. Boor, P. A. Cicalese, C. Mohan, H. V. Nguyen, and B. Roysam, ‚ÄúAr-
tiÔ¨Åcial intelligence and machine learning in nephropathology,‚Äù Kidney
International, vol. 98, no. 1, pp. 65‚Äì75, 2020.

[58] G. O. Barros, B. Navarro, A. Duarte, and W. L. Dos-Santos,
‚ÄúPathospotter-k: A computational tool for the automatic identiÔ¨Åcation of
glomerular lesions in histological images of kidneys,‚Äù ScientiÔ¨Åc reports,
vol. 7, no. 1, pp. 1‚Äì8, 2017.

[59] M. Y. Lu, D. F. Williamson, T. Y. Chen, R. J. Chen, M. Barbieri,
and F. Mahmood, ‚ÄúData-efÔ¨Åcient and weakly supervised computational
pathology on whole-slide images,‚Äù Nature Biomedical Engineering,
vol. 5, no. 6, pp. 555‚Äì570, 2021.

[60] G. Bueno, M. M. Fernandez-Carrobles, L. Gonzalez-Lopez, and
O. Deniz, ‚ÄúGlomerulosclerosis identiÔ¨Åcation in whole slide images
using semantic segmentation,‚Äù Computer methods and programs in
biomedicine, vol. 184, p. 105273, 2020.

[61] T. de Bel, M. Hermsen, B. Smeets, L. Hilbrands, J. van der Laak, and
G. Litjens, ‚ÄúAutomatic segmentation of histopathological slides of renal
tissue using deep learning,‚Äù in Medical Imaging 2018: Digital Pathology,
International Society for Optics and Photonics, 2018, p.
vol. 10581.
1058112.

13

[83] A. Krizhevsky, I. Sutskever, and G. E. Hinton, ‚ÄúImagenet classiÔ¨Åcation
with deep convolutional neural networks,‚Äù Advances in neural informa-
tion processing systems, vol. 25, pp. 1097‚Äì1105, 2012.

[84] C. Jayakumari, V. Lavanya, and E. Sumesh, ‚ÄúAutomated diabetic
retinopathy detection and classiÔ¨Åcation using imagenet convolution
neural network using fundus images,‚Äù in 2020 International Conference
on Smart Electronics and Communication (ICOSEC).
IEEE, 2020, pp.
577‚Äì582.

[85] R. EL SALEH, S. BAKHSHI, and N.-A. Amine, ‚ÄúDeep convolutional
neural network for face skin diseases identiÔ¨Åcation,‚Äù in 2019 Fifth Inter-
national Conference on Advances in Biomedical Engineering (ICABME).
IEEE, 2019, pp. 1‚Äì4.

[86] R. Ali, R. C. Hardie, B. N. Narayanan, and S. De Silva, ‚ÄúDeep
learning ensemble methods for skin lesion analysis towards melanoma
detection,‚Äù in 2019 IEEE National Aerospace and electronics conference
(NAECON).

IEEE, 2019, pp. 311‚Äì316.

[87] I. Loshchilov and F. Hutter, ‚ÄúSgdr: Stochastic gradient descent with

warm restarts,‚Äù 2017.

[88] P. Goyal, P. Doll¬¥ar, R. Girshick, P. Noordhuis, L. Wesolowski, A. Kyrola,
A. Tulloch, Y. Jia, and K. He, ‚ÄúAccurate, large minibatch sgd: Training
imagenet in 1 hour,‚Äù arXiv preprint arXiv:1706.02677, 2017.

[89] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Doll¬¥ar, ‚ÄúFocal loss
for dense object detection,‚Äù in Proceedings of the IEEE international
conference on computer vision, 2017, pp. 2980‚Äì2988.

[90] M. Everingham and J. Winn, ‚ÄúThe pascal visual object classes challenge
2012 (voc2012) development kit,‚Äù Pattern Analysis, Statistical Modelling
and Computational Learning, Tech. Rep, vol. 8, p. 5, 2011.

[91] R. Deng, H. Yang, A. Jha, Y. Lu, P. Chu, A. B. Fogo, and Y. Huo,
‚ÄúMap3d: registration based multi-object tracking on 3d serial whole slide
images,‚Äù IEEE Transactions on Medical Imaging, 2021.

[62] N. Altini, G. D. Cascarano, A. Brunetti, I. De Feudis, D. Buongiorno,
M. Rossini, F. Pesce, L. Gesualdo, and V. Bevilacqua, ‚ÄúA deep learning
instance segmentation approach for global glomerulosclerosis assess-
ment in donor kidney biopsies,‚Äù Electronics, vol. 9, no. 11, p. 1768,
2020.

[63] T. Qaiser, Y.-W. Tsang, D. Taniyama, N. Sakamoto, K. Nakane,
D. Epstein, and N. Rajpoot, ‚ÄúFast and accurate tumor segmentation
of histology images using persistent homology and deep convolutional
features,‚Äù Medical image analysis, vol. 55, pp. 1‚Äì14, 2019.

[64] M. Gadermayr, A. Dombrowski, B. Klinkhammer, P. Boor, and D. Mer-
hof, ‚ÄúCnn cascades for segmenting whole slide images of the kidney.
arxiv 2017,‚Äù arXiv preprint arXiv:1708.00251.

[65] N. Bouteldja, B. M. Klinkhammer, R. D. B¬®ulow, P. Droste, S. W.
Otten, S. F. von Stillfried, J. Moellmann, S. M. Sheehan, R. Korstanje,
S. Menzel et al., ‚ÄúDeep learning‚Äìbased segmentation and quantiÔ¨Åcation
in experimental kidney histopathology,‚Äù Journal of the American Society
of Nephrology, vol. 32, no. 1, pp. 52‚Äì68, 2021.

[66] M. Gadermayr, D. Eschweiler, A. Jeevanesan, B. M. Klinkhammer,
P. Boor, and D. Merhof, ‚ÄúSegmenting renal whole slide images virtually
without training data,‚Äù Computers in biology and medicine, vol. 90, pp.
88‚Äì97, 2017.

[67] K. He, G. Gkioxari, P. Doll¬¥ar, and R. Girshick, ‚ÄúMask r-cnn,‚Äù in
Proceedings of the IEEE international conference on computer vision,
2017, pp. 2961‚Äì2969.

[68] G. Cao, W. Song, and Z. Zhao, ‚ÄúGastric cancer diagnosis with mask
r-cnn,‚Äù in 2019 11th International Conference on Intelligent Human-
Machine Systems and Cybernetics (IHMSC), vol. 1.
IEEE, 2019, pp.
60‚Äì63.

[69] G. Lv, K. Wen, Z. Wu, X. Jin, H. An, and J. He, ‚ÄúNuclei r-cnn:
Improve mask r-cnn for nuclei segmentation,‚Äù in 2019 IEEE 2nd
International Conference on Information Communication and Signal
Processing (ICICSP).

IEEE, 2019, pp. 357‚Äì362.

[70] A. Jha, H. Yang, R. Deng, M. E. Kapp, A. B. Fogo, and Y. Huo,
‚ÄúInstance segmentation for whole slide imaging: end-to-end or detect-
then-segment,‚Äù Journal of Medical Imaging, vol. 8, no. 1, p. 014001,
2021.

[71] E. H. Nguyen, H. Yang, R. Deng, Y. Lu, Z. Zhu, J. T. Roland, L. Lu,
B. A. Landman, A. B. Fogo, and Y. Huo, ‚ÄúCircle Representation for
Medical Object Detection,‚Äù IEEE transactions on medical
imaging,
2021.

[72] D. Demner-Fushman, S. Antani, M. Simpson, and G. R. Thoma, ‚ÄúDesign
and development of a multimodal biomedical
information retrieval
system,‚Äù Journal of Computing Science and Engineering, vol. 6, no. 2,
pp. 168‚Äì177, 2012.

[73] Q. Liu, P. C. Louis, Y. Lu, A. Jha, M. Zhao, R. Deng, T. Yao, J. T.
Roland, H. Yang, S. Zhao et al., ‚ÄúSimtriplet: Simple triplet representation
learning with a single gpu,‚Äù arXiv preprint arXiv:2103.05585, 2021.

[74] L.-C. Chen, G. Papandreou, F. Schroff, and H. Adam, ‚ÄúRethinking
atrous convolution for semantic image segmentation,‚Äù arXiv preprint
arXiv:1706.05587, 2017.

[75] A. Bochkovskiy, C.-Y. Wang, and H.-Y. M. Liao, ‚ÄúYolov4: Op-
speed and accuracy of object detection,‚Äù arXiv preprint

timal
arXiv:2004.10934, 2020.

[76] Z. Zhu, Y. Lu, R. Deng, H. Yang, A. B. Fogo, and Y. Huo, ‚ÄúEasierpath:
an open-source tool for human-in-the-loop deep learning of renal pathol-
ogy,‚Äù in Interpretable and Annotation-EfÔ¨Åcient Learning for Medical
Image Computing. Springer, 2020, pp. 214‚Äì222.

[77] G. Bueno, L. Gonzalez-Lopez, M. Garcia-Rojo, A. Laurinavicius, and
O. Deniz, ‚ÄúData for glomeruli characterization in histopathological
images,‚Äù Data in brief, vol. 29, p. 105314, 2020.

[78] P. Refaeilzadeh, L. Tang, and H. Liu, ‚ÄúCross-validation.‚Äù Encyclopedia

of database systems, vol. 5, pp. 532‚Äì538, 2009.

[79] Y. Tang, ‚ÄúDeep learning using linear support vector machines,‚Äù arXiv

preprint arXiv:1306.0239, 2013.

[80] M. Wodzinski,

I. Ciepiela, T. Kuszewski, P. Kedzierawski, and
A. Skalski, ‚ÄúSemi-supervised deep learning-based image registration
method with volume penalty for real-time breast tumor bed localization,‚Äù
Sensors, vol. 21, no. 12, p. 4085, 2021.

[81] V. Perminov, V. Ermakov, and D. Korzun, ‚ÄúEdge analytics for bearing
fault diagnosis based on convolution neural network,‚Äù in Fuzzy Systems
and Data Mining VII.

IOS Press, 2021, pp. 94‚Äì103.

[82] I. Tsamardinos, A. Rakhshani, and V. Lagani, ‚ÄúPerformance-estimation
properties of cross-validation-based protocols with simultaneous hyper-
parameter optimization,‚Äù International Journal on ArtiÔ¨Åcial Intelligence
Tools, vol. 24, no. 05, p. 1540023, 2015.

