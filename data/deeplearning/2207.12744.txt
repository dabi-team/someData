2
2
0
2

l
u
J

6
2

]

V
C
.
s
c
[

1
v
4
4
7
2
1
.
7
0
2
2
:
v
i
X
r
a

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

Distribution Learning Based on Evolutionary Algorithm Assisted
Deep Neural Networks for Imbalanced Image Classiï¬cation

Yudi Zhao1, Kuangrong Hao1,*, Chaochen Gu2, Bing Wei1
1College of Information Sciences and Technology, Donghua University, Shanghai 201620, P. R. China
2Department of Automation, Shanghai Jiao Tong University, Shanghai 200240, P. R. China

To address the trade-off problem of quality-diversity for the generated images in imbalanced classiï¬cation tasks, we research
on over-sampling based methods at the feature level instead of the data level and focus on searching the latent feature space for
optimal distributions. On this basis, we propose an iMproved Estimation Distribution Algorithm based Latent featUre Distribution
Evolution (MEDA LUDE) algorithm, where a joint learning procedure is programmed to make the latent features both optimized
and evolved by the deep neural networks and the evolutionary algorithm, respectively. We explore the effect of the Large-margin
Gaussian Mixture (L-GM) loss function on distribution learning and design a specialized ï¬tness function based on the similarities
among samples to increase diversity. Extensive experiments on benchmark based imbalanced datasets validate the effectiveness of
our proposed algorithm, which can generate images with both quality and diversity. Furthermore, the MEDA LUDE algorithm is
also applied to the industrial ï¬eld and successfully alleviates the imbalanced issue in fabric defect classiï¬cation.

Index Termsâ€”Imbalanced classiï¬cation, quality-diversity, distribution learning, evolutionary algorithm, fabric defect.

I. INTRODUCTION

I MBALANCED problems have always occurred in real-

world collected data, where the high degree of variation
is exhibited in the number of different categories due to
data characteristics, problems in the collection process, or
human factor. Traditional classiï¬cation methods are built on
the premise of the data balance and hence easily confront
a sharp drop in classiï¬cation performance when handling
imbalanced data with highly skewed distributions [1]. Since
imbalanced data is widespread in peopleâ€™s lives and industrial
production, such as credit card fraud recognition, industrial
fault detection, and diagnosis, as well as cancer diagnosis and
treatment, imbalanced classiï¬cation problems have become
challenges in the ï¬elds of machine learning and data mining
[2].

Traditional over-sampling based techniques to address
imbalanced problems mainly synthesize samples randomly
among the minority classes [3]. Random over-sampling (ROS)
[4] is the simplest way to increase the ratio of minority
samples, where the valuable information is not
increased
as the sample count. To improve the generalization ability,
Chawa et al. [5] designed a synthetic minority over-sampling
technique (SMOTE) based on a neighbor strategy among
the minority samples. However, noise could be introduced
to the synthesis process, and the problem of distribution
marginalization probably happens, especially when noisy sam-
ples appear at the boundary of the positive samples and the
negative samples. For this, borderline-SMOTE [6] is further
raised to operate synthesis around the boundaries. He et
al. [7] proposed an adaptive synthetic (ADASYN) sampling
method that adaptively synthesizes minority samples according
to the distribution as well as the learning difï¬culty of the
minority samples. Besides, the majority weighted minority
oversampling technique (MWMOTE) [8] innovatively assigns

*Corresponding author: Kuangrong Hao (email: krhao@dhu.edu.cn)

images. Due to the powerful

different weights to the hard-to-learn minority samples. The
weight is determined by their distances to the nearest majority
samples. However, traditional over-sampling based methods
exist limitations in classiï¬cation tasks when dealing with high-
dimensional
learning ability,
deep learning based over-sampling techniques have shown
superiority in imbalanced problems. Variational autoencoder
(VAE), as a generative model, has strong capacity for image
generation due to its variational inference ability between the
complex data and the low-dimensional latent feature space
[9]. Wan et al. [10] utilized VAE to generate the minority
images and successfully solved the imbalanced problem in
image classiï¬cation tasks. Dai et al. [11] further leveraged
the information from the majority samples based on the VAE,
which achieved great success in the medical ï¬eld. Moreover,
the conditional VAE (CVAE) [12] is a modiï¬cation of VAE to
guide and control the image synthesis process by incorporating
prior constraints.

Even though deep learning based over-sampling models
have made achievements in imbalanced classiï¬cation prob-
lems, the quality and diversity of samples can not always
be guaranteed simultaneously, especially when the existing
samples are limited. To tackle this puzzle, some recent works
explore how to obtain superior quality and diversity trade-off
in generation tasks. Yang et al. [13] improved synthesis quality
by removing detrimental ones based on inï¬‚uence functions and
maximized the diversity by picking out compelling examples
from the generated pool for the application of commonsense
reasoning. Still, both of the selections are based on the
level of samples, which is not so efï¬cient when requiring a
large amount of generative data. Du et al. [14] proposed a
multiconstraint generative adversarial network (MCGAN) to
ensure the similarity, diversity, and correct category of the
synthetic aperture radar (SAR) images in the ï¬eld of automatic
target recognition (ATR), where the diversity is increased by
adding Gaussian noise to the input vector of the generator.

 
 
 
 
 
 
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

2

Similarly, noise perturbation is also employed as well as
inï¬nite generative samples to enhance the discrimination,
which can boost the high-quality and diverse generation [15].
However, noise-based methods are accompanied by random-
ness and are less controllable. In [16], a new quality-diversity
based evolutionary algorithm is applied to GANs to upgrade
the exploration of search space and provide better solutions
for generators and discriminators. Hence, the ï¬nal generators
competitively synthesized high-quality samples. Although this
method can be trained controllably with objectives, it aims
at guiding the evolution of GANs to discover more efï¬cient
models rather than data distribution.

The synthesis of data depends on the generator and its input
vectors sampled from the latent distributions. Meanwhile, it
has proved that the closer the generated distribution is to the
real distribution, the higher the quality and diversity of the
synthesized data achieve [17, 18]. Therefore, in imbalanced
problems, distribution learning is essential for deep learning
based oversampling methods for image generations. However,
existing deep learning based methods are prone to the risk
of overï¬tting, and the learned distribution is likely restricted
within a limited range far from the real distribution when given
training data is imbalanced or even insufï¬cient. This paper
employs an evolutionary algorithm to learn distributions to
alleviate this problem. A similar idea deï¬ned as latent variable
evolution (LVE) is ï¬rst introduced for dictionary attack [19].
This research work adopts the covariance matrix adaptation
evolution strategy (CMA-ES) to evolve the input variables
of GANs for ï¬ngerprint synthesis. However, their objective
is to match the impostors with as many subjects in the real
ï¬ngerprint images as possible during the evaluation of the
recognition system. Besides, LVE is also applied to procedural
content generation (PCG) of video game levels [20, 21, 22].
Volz et al. [20] generated playable Mario levels by applying
CMA-ES to GANs. The same approach is also exploited
to search the latent space for producing DOOM levels with
an excellent grade of novelty and variety [21]. In addition,
Thakkar et al.[22] proposed to merge a multi-population evo-
lutionary algorithm into a multi-channel autoencoder for Lode
Runner level generations and realized the goal of playability
and connectivity. However, these approaches are not applicable
to image generation for imbalanced problems since the ï¬tness
functions are devised according to the desired properties of
different video games rather than objectives like quality or
diversity.

In this paper, we assume that the latent features follow
a multivariate Gaussian mixture (GM) distribution and ap-
ply the estimation of distribution algorithm (EDA) [23] to
evolve the latent feature distribution, which is simultaneously
optimized by deep neural networks with the large-margin
Gaussian Mixture (L-GM) loss for quality-diversity trade-off.
Considering we aimed at optimizing and searching for the
optimal distribution in the latent space while VAEs already
exist a prior probability distribution for latent variables, thus
the autoencoders (AEs) are applied where the input images are
mapped to the feature space by an encoder, and then the latent
features are decoded to the synthesized samples. Meanwhile,
two classiï¬ers, including a latent feature classiï¬er and an im-

age classiï¬er, are employed to control and improve the feature
distribution learning process for better diversity, and train the
generator for better quality. Our contributions are summarized
as follows: (1) A deep neural network based architecture for
imbalanced problems is devised, where an iMproved EDA
(MEDA) is utilized to evolve the latent feature distributions,
and the proposed method can well balance the quality and
diversity of generations. (2) A specialized ï¬tness function is
designed for the MEDA according to the similarities among
samples. The ï¬tness function will guide the search for the
latent variables to enhance the diversity. (3) We exploit the
function of L-GM loss under a more complex assumption,
where the covariance matrix is assumed to be a variable
participating in the optimization of deep neural networks and
the evolution of MEDA instead of being an identity matrix.
(4) Four training phases are innovatively programmed in the
MEDA LUDE algorithm, which can achieve excellent perfor-
mance on benchmark datasets and be successfully applied to
the industrial ï¬eld.

The remainder of the paper is organized as follows: Section
II introduces concepts of EDA and L-GM loss. Detailed
descriptions of our proposed method are given in III. In IV,
experimental results and analysis are displayed. Finally, we
present our conclusions.

II. BACKGROUND

A. Estimation of Distribution Algorithms

Estimation of Distribution Algorithms (EDAs) are a novel
branch of statistical-model-based evolutionary algorithms and
provide a microscopical paradigm where the population
evolves by learning from the probabilistic distribution model
[24]. Although EDAs have developed various implementa-
tions,
the core of them can be summed up as two main
steps [23, 25]: (1) Construct the probabilistic model of the
solution space and select the superior individuals based on the
evaluation. The new explicit probabilistic model can describe
the distribution of the updated solution space. (2) Generate
a new population by sampling randomly from the current
probabilistic model, and then repeat steps (1)-(2) until the
termination criterion is met.

In this paper, we assume that the latent features follow a
multivariate Gaussian mixture model (GMM). Hence, we give
a brief introduction of the basic Gaussian distribution based
EDA [26]. Assume that N represents the population size,
k and Iter are the iterations and the maximum number of
the iterations, respectively. Î· denotes the sampling rate of the
superior population. The general procedure is as follows:

1) Randomly generate N initial solutions as a population,
which is denoted as pop(0) = {x1, x2, Â· Â· Â· , xN }, here
k = 0.

2) Calculate the ï¬tness of each individual in pop(k).
3) Rank the individuals in a descending order based on
ï¬tnesses, and keep the former Î·N individuals as the
superior population spop(k).

4) if k = Iter, terminate the algorithm; Otherwise, con-

tinue step 5).

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

3

5) Calculate the mean and the variance of pop(k)

andspop(k) for each dimension.

6) Update the mean and the variance according to rules

below:

Âµ = Î³Âµnew + (1 âˆ’ Î³)Âµ
new + (1 âˆ’ Î³)Ïƒ2

Ïƒ2 = Î³Ïƒ2

the covariance assumption given above, we assume it to be a
variable that engages in the optimization of deep neural net-
works and the evolution of evolutionary algorithms. Therefore,
the L-GM loss needs to be re-derived, and we should further
adjust the implementations in a more complex situation.

III. METHODOLOGY

where Âµ, Ïƒ2 denote the means and the variances of
pop(k), while Âµnew, Ïƒ2
new represent those of spop(k).
Î³ is the weighting coefï¬cients.

7) Sample from the Gaussian distribution with the current
means and variances, then generate a new population.

8) k := k + 1, and go to step 2).
In our MEDA LUDE algorithm, the basic EDA mentioned
above is improved and adopted to evolve the latent feature
distribution for further quality and diversity enhancement in
data generation.

The proposed MEDA LUDE model consists of an encoder,
a decoder, a latent feature classiï¬er, and an image classiï¬er,
as shown in Fig. 1. The latent features learned from the
encoder are supposed to follow a multivariate GM distribution,
a mixture of K normal distributions, where K represents the
number of categories. To reach the goal of quality-diversity
trade-off in image generation for imbalanced classiï¬cation,
we program a training procedure through four phases based
on the MEDA LUDE architecture, as depicted in Figs. 2-5,
respectively.

B. Large-margin Gaussian Mixture Loss

The L-GM loss is proposed for deep neural networks
in classiï¬cation problems, where the extracted features are
assumed to follow a GM distribution, and each category
belongs to one ingredient [27]. The proposed L-GM loss is
composed of a classiï¬cation loss with large-margin and a
likelihood regularization. The classiï¬cation loss can enhance
the discrimination and improve the generalization capability,
and the likelihood regularization can drive the features to obey
the GM distribution. Assume that Âµk and Î£k are the mean and
covariance of a Gaussian distribution representing class k in
feature space, including total K classes, and xi and zi denotes
the extracted feature and its label of the i âˆ’ th sample. Then
the L-GM loss [27] is deï¬ned as Eq. (1).

Fig. 1. The MEDA LUDE architecture.

A. Phase 1: Pre-training of MEDA LUDE

Lm

GM,i = âˆ’ log

(cid:80)

|Î£zi|âˆ’ 1
k |Î£k|âˆ’ 1
1
2

+ Î»(dzi +

log|Î£zi|)

2 eâˆ’dzi (1+Î±)
2 eâˆ’dk(1+1(k=zi)Î±)

(1)

dk =

1
2

(xi âˆ’ Âµk)T Î£âˆ’1

k (xi âˆ’ Âµk) k âˆˆ [1, K]

(2)

where the ï¬rst term of Eq. (1) is the classiï¬cation loss, and
the second term is the likelihood regularization. Î± is a non-
negative parameter controlling the classiï¬cation margin size
m, and the indicator function 1() equals 1 if k = zi, otherwise
equals 0. Î» is a non-negative weighting coefï¬cient of the
second term.

For simplicity, the authors hypothesize the covariance sat-
isï¬es the hypothesis of the identity matrix, namely Î£k = I.
Hence the L-GM loss is ï¬nally simpliï¬ed as below:

Fig. 2. Phase 1: the parameters of the encoder, the decoder, the latent feature
classiï¬er, the image classiï¬er, and the multivariate GM distributed latent
features all participates in optimization.

Lm

GM,i = âˆ’log

eâˆ’dzi (1+Î±)
k eâˆ’dk(1+1(k=zi)Î±)

(cid:80)

+ Î»dzi

dk =

1
2

(xi âˆ’ Âµk)2

k âˆˆ [1, K]

(3)

(4)

In the proposed MEDA LUDE algorithm, L-GM loss is
adopted to provide the means and covariances of GM distri-
butions with great initial values for MEDA evolving. Unlike

As shown in Fig. 2, the input is composed of the majority
samples Xmaj and the minority samples Xmin. The encoder,
the decoder, and the two classiï¬ers are pre-trained with recon-
struction loss and classiï¬cation loss. Meanwhile, the L-GM
loss is also brought to the total loss, driving the latent features
to follow a multivariate GM distribution automatically and
giving a wise initialization for evolution operations without
prior knowledge.

â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦EncoderDecoderLatent feature classifierImage classifierLatent featuresInputSynthesized imagesğ‘µğğŸ,ğˆğŸğŸğ‘µğğŸ,ğˆğŸğŸğ‘µğğŸ‘,ğˆğŸ‘ğŸğ‘µğğŸ’,ğˆğŸ’ğŸğ‘µğğ‘²,ğˆğ‘²ğŸâ€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦EncoderDecoderLatent feature classifierImage classifierLatent featuresInput:Synthesized imagesâ„’ğ’„ğ’ğ’”ğŸğ’ğ’•ğ’•Classification loss: L-GM loss: â„’ğºğ‘€1ğ‘šâ„’ğ‘Ÿğ‘’ğ‘1Reconstruction loss: Classification loss: â„’ğ’„ğ’ğ’”ğŸğ’Šğ’ğ’ˆğ‘‹ğ‘šğ‘ğ‘—,ğ‘‹ğ‘šğ‘–ğ‘›JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

Different from [27], both the means and covariances of the
multivariate GM distribution are hypothesized to be variables
to be optimized in the MEDA LUDE algorithm. Here the
assumption is given that f eati âˆˆ R1Ã—h is the latent feature
learned from the i âˆ’ th input image, where h is the feature
dimension. Correspondingly, the multivariate mean of class k
has the same dimension, denoted as Âµk âˆˆ R1Ã—h, meanwhile
the covariance matrix Î£k âˆˆ RhÃ—h is hypothesized to be
diagonal, signiï¬ed by Î›k âˆˆ RhÃ—h. The L-GM loss can be
written as:

Lm

GM,i = âˆ’ log

(cid:80)

2 eâˆ’dzi (1+Î±)
2 eâˆ’dk(1+1(k=zi)Î±)

|Î›zi|âˆ’ 1
k |Î›k|âˆ’ 1
1
2

+ Î»(dzi +

log|Î›zi|)

dk =

1
2

(f eati âˆ’ Âµk)T Î›âˆ’1

k (f eati âˆ’ Âµk) k âˆˆ [1, K]

(6)

where the ï¬rst term to the right of the equal sign in Eq. (5)
is the classiï¬cation loss Lcls,i, while the second one is the
likelihood regularization Llkd,i. In Eq. (6), dk calculates the
squared Mahalanobis distance between the i âˆ’ th feature and
the class k.

With the non-ignorable and variable covariances Î›k in
Eq. (6), the formulation needs to be re-derived when cal-
culating the distance D between a batch of features and
the K classes. First, a batch of features are assumed
all
as F EAT = [f eat1; f eat2; . . . ; f eatn] âˆˆ RnÃ—h, where n
is the batch size. The multivariate mean with K classes
is M = [Âµ1; Âµ2; . . . ; ÂµK] âˆˆ RKÃ—h. For convenience, the
diagonal values of Î›k are extracted as a vector Ïƒ2
k =
[Î»k1, Î»k2, . . . , Î»kh] âˆˆ R1Ã—h, hence, the multivariate covari-
K] âˆˆ RKÃ—h. Then the distance D
ance is Î£ = [Ïƒ2
1; Ïƒ2
is derived as follows:

2; . . . ; Ïƒ2

D =

{(F EAT (cid:12) F EAT ) Ã— Î£T

1
2
âˆ’ 2F EAT Ã— (M T (cid:12) Î£T ) + G
ï£¹

ï£®

G =

g(cid:48)
g(cid:48)
...
g(cid:48)

ï£¯
ï£¯
ï£¯
ï£°

ï£º
ï£º
ï£º
ï£»

nÃ—K

g(cid:48) =

hâˆ’1
(cid:88)

j=0

g[j]

g(cid:48) âˆˆ R1Ã—K

g = M T (cid:12) M T (cid:12) Î£T

g âˆˆ RhÃ—K

(7)

(8)

(9)

(10)

4

(12)

ï£¹

ï£º
ï£º
ï£º
ï£»

nÃ—K

ï£®

ï£¯
ï£¯
ï£¯
ï£°

logq
logq
...
logq

Q =

logq = [logq1, logq2, . . . , logqK] âˆˆ R1Ã—K

(13)

where Ones is an n Ã— K matrix of which each element is 1.
label is a one-hot form from the labels of n samples, whose
dimension is n Ã— K.

Based on the logit, the classiï¬cation Lcls of n samples can

be ï¬nally obtained by using cross entropy loss.

(5)

According to the previous assumption about |Î›k|âˆ’ 1
likelihood regularization Llkd can be derived as follows:

2 , the

(14)

(15)

(16)

(17)

(18)

(19)

(20)

Llkd = (D âˆ’ Q) (cid:12) label

Finally, the L-GM loss can be achieved by:

Lm

GM = Lcls + Î»Llkd

Finally, the phase loss Lph1 is deï¬ned by:
Lph1 =Î²rec1 âˆ— Lrec1 + Î²GM1 âˆ— Lm
+ Î²clsimg

+ Î²clsltt

âˆ— Lclsltt

GM1

1

1

1

âˆ— Lclsimg

1

Lrec1 = Lrec1 min + Î¾rec1 âˆ— Lrec1 maj
Lm

GM1 min + Î¾GM1 âˆ— LGM1 maj

= Lm

GM1

Lclsltt

1

Lclsimg

1

= Lclsltt

=Lclsori
Lclssyn

1

1 min + Î¾clsltt
1 min + Î¾clsori
1 min + Î¾clssyn
, and Lclsimg

1

1

âˆ— Lclsltt

1 maj

1 maj

âˆ— Lclsori
âˆ— Lclssyn

1 maj

1

1

1

1

GM1

GM1

, Lclsltt

, and Lclsltt

, and Î²clsimg

where Lrec1, Lm
are the reconstruction
loss, the L-GM loss, the classiï¬cation loss from the latent
features and the images of Phase 1, respectively. Meanwhile,
Î²rec1, Î²GM1 , Î²clsltt
are their corresponding
weighting coefï¬cients. Besides, Lrec1, Lm
are
all composed of the minority part and the majority part, with
respective coefï¬cients Î¾rec1, Î¾GM1 , and Î¾clsltt
to alleviate the
bias caused by imbalanced data. Furthermore, Lclsimg
includes
image
the classiï¬cation loss from both the original
and the synthesized images, namely â€˜Lclsori
âˆ—
Lclsori
1 majâ€™, where
Î¾clsori
are the coefï¬cients for the input images and
the generated images, respectively. When Phase 1 is ï¬nished,
the initial multivariate GM distribution of the latent features
can be obtained and denoted by Minit and Î£init.

1
input
1 min + Î¾clsori

1 majâ€™ and â€˜Lclssyn

1 min + Î¾clssyn

and Î¾clssyn

âˆ— Lclssyn

1

1

1

1

1

1

where â€˜(cid:12)â€™ and â€˜Ã—â€™ denote the Hadamard product and the ma-
trix multiplication, respectively. j represents the row index of
matrix g. The ï¬nal distance Dâ€™s dimension is nÃ—K, recording
the squared Mahalanobis distance between n features and K
classes.

To calculate the classiï¬cation loss Lcls, we assume
2 = qk = elogqk , and the logits logit of n samples

|Î›k|âˆ’ 1
in K class can be calculated by:

logit = âˆ’D (cid:12) (Ones + Î± âˆ— label) + Q

(11)

B. Phase 2: Local Enhancement for Image Synthesis

In Phase 2, we focus on enhancing the ability of the decoder
and the image classiï¬er. As shown in Fig. 3, the latent features
are ï¬rstly produced as the input of the decoder by sampling
from the learned distribution with the mean Minit and the
covariance Î£init. Based on the synthesized images and the real
samples randomly chosen according to the number and labels
of the input, the reconstruction loss Lrec2 and classiï¬cation

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

5

distribution learned from Phase 1 already considers the bias
between the majority and the minority, we ignore the inï¬‚uence
of skewed distribution from the imbalanced data for each loss
in this phase.

D. Phase 4: Evolution of Latent Feature Distribution

The multivariate GM distribution of the latent features is
evolved for better quality and diversity in Phase 4, and the
speciï¬c details are depicted in Fig. 5. The input is formed by
randomly sampling from the current GMM N (Minit, Î£init)
and is ï¬rstly passed through the latent feature classiï¬er. Then
the correctly classiï¬ed ones are kept and denoted by â€˜GM 1â€™,
where the coloured part indicates the correct ones while the
wrong part turns grey. Next, the correct is decoded to the
reconstructed images, denoted as Xsyn, and the images clas-
siï¬ed correctly are reserved and named X quali
syn . To this point,
X quali
is considered to be high-quality images, meaning that
syn
they can be easily identiï¬ed by the human eye or recognized
by an image classiï¬er.

However, the diversity of the generated images can not be
ensured, which may cause an overï¬tting problem for classi-
ï¬ers. A ï¬tness function is designed based on the similarities
among samples to increase the diversity by selecting the
diverse generations. The similarities are calculated by the av-
erage hash algorithm (AHA) [28] between X quali
syn and the real
samples Xreal randomly selected from the imbalanced data:
(1) compute the hash values for all the pairs of samples, with
each pair consisting of one synthesized image and one real
image; (2) compare the hash values to get the similarities; (3)
Sort the similarities and select the corresponding synthesized
samples with the lowest similarities based on selection rate as
superior individuals, named X diver
syn .
To guide the evolution direction to better diversity based on
the high quality, the corresponding latent features of X quali
and X diver
are found and noted by â€˜GM 2â€™ and â€˜Spopâ€™ as
shown in Fig. 5. Compared with the traditional EDAs, the
distribution of the current
latent features is replaced with
that of â€˜GM 2â€™ when evolving to guarantee the quality of
synthesized samples. Simultaneously, â€˜Spopâ€™ contributes to
optimizing the latent feature distribution to be more diverse.
Therefore, the MEDA updates the GM distribution by:

syn

syn

Âµk crt = Î³Âµk quali + (1 âˆ’ Î³)Âµk diver
Ïƒ2
k crt = Î³Ïƒ2

k quali + (1 âˆ’ Î³)Ïƒ2

k diver

(25)

(26)

where Âµk crt and Ïƒ2
k crt calculate the mean and the covariance
of the latest Gaussian distribution for the latent features
in class k. Âµk quali and Ïƒ2
k quali denote the mean and the
covariance of class k in â€˜GM 2â€™, respectively, while Âµk diver
and Ïƒ2
k diver are those of class k in â€˜Spopâ€™. Î³ represents the
weighting coefï¬cients.

Each update is done, the latent features are re-sampled from
the current GM distribution, and the steps above are repeated
until the termination condition is met.

E. Program of Four Phases

Fig. 3. Phase 2: the decoder and the image classiï¬er are locally trained.

Lclsimg
is deï¬ned as:

2

are calculated. Hence, the total loss Lph2 of this phase

Lph2 =Î²rec2 âˆ— Lrec2 + Î²clsimg

2

âˆ— Lclsimg

2

Lrec2 = Lrec2 min + Î¾rec2 âˆ— Lrec2 maj

Lclsimg

2

=Lclsori
Lclssyn

2 min + Î¾clsori
2 min + Î¾clssyn

2

2

âˆ— Lclsori
âˆ— Lclssyn

2 maj

2 maj

(21)

(22)

(23)

2

where Î²rec2 and Î²clsimg
are the corresponding weighting
coefï¬cients. Î¾rec2 is to adjust the weight between the majority
and the minority samples for reconstruction loss. Both the
real samples and the generated images are sent to the image
classiï¬er for calculating the classiï¬cation loss, with Î¾clsori
and
Î¾clssyn
adjusting their weights between the majority and the
2
minority.

2

C. Phase 3: Local Enhancement for Feature Learning

Fig. 4. Phase 3: the encoder and the latent feature classiï¬er are locally trained
in this phase, where the decoder parameters are kept ï¬xed.

The speciï¬c operation of Phase 3 is depicted in Fig. 4.
This phase occurs two kinds of latent features: one is sampled
from the current GMM learned from Phase 1 and treated as
the input of the whole module; another is encoded from the
synthesized images, which are decoded from the input one. To
further optimize the parameters of the encoder and the latent
feature classiï¬er, both the L-GM loss and the classiï¬cation loss
are calculated based on the latter latent features. The total loss
is deï¬ned by:

Lph3 = Î²GM3 âˆ— Lm

GM3

+ Î²clsltt

3

âˆ— Lclsltt

3

(24)

GM3

and Lclsltt

where Lm
are the L-GM loss and the latent
feature classiï¬cation loss in this phase, Î²GM3 and Î²clsltt
are
the corresponding weight coefï¬cients. Since the input dataâ€™s

3

3

DecoderImage classifierâ€¦â€¦â€¦â€¦â€¦â€¦Real samplesâ„’ğ‘Ÿğ‘’ğ‘ğŸReconstruction loss: Classification loss: â„’ğ’„ğ’ğ’”ğŸğ’Šğ’ğ’ˆSynthesized imagesInputEncoderFixed decoderâ€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦Latent feature classifierL-GM loss: â„’ğºğ‘€ğŸ‘ğ‘šâ„’ğ’„ğ’ğ’”ğŸ‘ğ’ğ’•ğ’•Classification loss: Synthesized imagesInputLatent featuresJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

6

Fig. 5. Phase 4: the MEDA evolves the GM distributions of the latent features, where the function f denotes the evolution rule.

Four phases mentioned above are programmed to train the
MEDA LUDE algorithm, and the pseudocode is shown in
Algorithm 1.

In Algorithm 1, the input of the MEDA LUDE is composed
of the majority samples Xmaj and the minority samples Xmin,
namely X = {Xmaj, Xmin}. Their corresponding labels are
denoted as Y = {Ymaj, Ymin}. The model parameters of
the encoder, the decoder, the latent feature classiï¬er, and the
image classiï¬er are signiï¬ed as Î¸en, Î¸de, Î¸cls ltt, and Î¸cls img,
respectively.

IV. EXPERIMENTS

This section evaluates the proposed MEDA LUDE al-
gorithm on the imbalanced datasets
randomly formed
the
from MNIST and CIFAR-10 datasets. Furthermore,
MEDA LUDE is also applied to the industrial ï¬eld and has
achieved signiï¬cant success. The experiments are implemented
with NVIDIA RTX 2080Ti, 64 GB RAM, Intel(R) Xeon(R)
Silver 4114 CPU, Ubuntu 18.04.5 LTS, Pytorch 1.7.0.

Besides, Algorithm 1 makes use of the follow functions in

A. Evaluation on Benchmark-based Imbalanced Datasets

Phase 4:

â€¢ Sample(distribution): sample from â€˜distributionâ€™ to

generate population.

â€¢ Classif y Ltt(ltt, para): classify latent features â€˜lttâ€™ by
latent feature classiï¬er with model parameters â€˜paraâ€™.

â€¢ Select Correct(data, label1, label2):

the cor-
rectly classiï¬ed â€˜dataâ€™ according to the classiï¬cation
results â€˜label1â€™ and the real labels â€˜label2â€™.

select

â€¢ Decode(latentf eature, para): decode â€˜latentf eatureâ€™
to synthesized images by decoder with model parameters
â€˜paraâ€™.

â€¢ Classif y Img(img, para): classify â€˜imgâ€™ by image

classiï¬er with model parameters â€˜paraâ€™.

â€¢ Cal F itness(data1, data2, algorithm): calculate ï¬t-

ness of â€˜data1â€™ based on â€˜data2â€™ by â€˜algorithmâ€™.

â€¢ Evaluate Select(data, f itness): evaluate â€˜dataâ€™ based

on â€˜f itnessâ€™ and select promising solutions.

â€¢ F ind Ltt(data): ï¬nd corresponding latent features of

â€˜dataâ€™.

â€¢ Cal Gaussian(data): give Gaussian distribution of

â€˜dataâ€™.

â€¢ Evolve(mean1, mean2, cov1, cov2): evolve Gaussian
distribution based on â€˜mean1â€™, â€˜mean2â€™, â€˜cov1â€™, â€˜cov2â€™
to the update distribution N (meancrt, covcrt) by:

meancrt = Î³mean1 + (1 âˆ’ Î³)mean2

covcrt = Î³cov1 + (1 âˆ’ Î³)cov2

(27)

(28)

where Î³ is the coefï¬cient in Eq. (25) and Eq. (26).

In Phase 4, labelltt and labelimg denote the real labels of
F EAT4 and Xsyn, respectively.

Two random seeds are set for each benchmark dataset
to allocate the categories of the majority samples and the
minority samples.

For the MNIST dataset, the handwritten digits from 0 to
9 are ï¬rst symbolized with numbers from 0 to 9. Then we
randomly select ï¬ve numbers as the minority classes with
the random seed function in the NumPy library for Python
programming language. The seeds are set to be 0 and 5,
respectively, where the minority classesâ€™ numbers are 2, 8,
4, 9, 1 when the seed is 0, and are 9, 5, 2, 4, 7 when
the seed is 5 accordingly. The two imbalanced datasets built
from the MNIST dataset are both split into the training and
validation sets. The training set contains 50 samples for each
minority class and 5000 examples for each majority class.
The validation set includes 4000 samples uniformly distributed
within ten categories, and the test set is the same as that
of the original MNIST dataset. Hence, the MEDA LUDE is
ï¬nally experimented on two randomly formed datasets with
an imbalanced ratio [29] being 100.

For the CIFAR-10 dataset, the categories of the airplane,
automobile, bird, cat, deer, dog, frog, horse, ship, and truck
are marked with numbers 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9,
accordingly. Here, the random seeds are set to be 1 and 7,
corresponding to the minority classes being bird, truck, frog,
deer, airplane, and ship, dog, airplane, bird, and automobile,
respectively. From the original training set of the CIFAR-10
dataset, 45 and 4500 examples are selected for each minority
class and each majority class, respectively, constituting im-
balanced datasets with an imbalanced ratio of 100 under two
different circumstances. Among the remaining samples of the
training set, 400 samples are chosen randomly for each class

Image classifierDecoderLatent feature classifierâ€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦AHAâ€¦â€¦Spopğ‘µğğŸ_ğ’…ğ’Šğ’—ğ’†ğ’“,ğˆğŸ_ğ’…ğ’Šğ’—ğ’†ğ’“ğŸğ‘µğğŸ_ğ’…ğ’Šğ’—ğ’†ğ’“,ğˆğŸ_ğ’…ğ’Šğ’—ğ’†ğ’“ğŸğ‘µğğŸ‘_ğ’…ğ’Šğ’—ğ’†ğ’“,ğˆğŸ‘_ğ’…ğ’Šğ’—ğ’†ğ’“ğŸğ‘µğğŸ’_ğ’…ğ’Šğ’—ğ’†ğ’“,ğˆğŸ’_ğ’…ğ’Šğ’—ğ’†ğ’“ğŸğ‘µğğ‘²_ğ’…ğ’Šğ’—ğ’†ğ’“,ğˆğ‘²_ğ’…ğ’Šğ’—ğ’†ğ’“ğŸâ€¦ğ‘µğğŸ_ğ’’ğ’–ğ’‚ğ’ğ’Š,ğˆğŸ_ğ’’ğ’–ğ’‚ğ’ğ’ŠğŸğ‘µğğŸ_ğ’’ğ’–ğ’‚ğ’ğ’Š,ğˆğŸ_ğ’’ğ’–ğ’‚ğ’ğ’ŠğŸğ‘µğğŸ‘_ğ’’ğ’–ğ’‚ğ’ğ’Š,ğˆğŸ‘_ğ’’ğ’–ğ’‚ğ’ğ’ŠğŸğ‘µğğŸ’_ğ’’ğ’–ğ’‚ğ’ğ’Š,ğˆğŸ’_ğ’’ğ’–ğ’‚ğ’ğ’ŠğŸğ‘µğğ‘²_ğ’’ğ’–ğ’‚ğ’ğ’Š,ğˆğ‘²_ğ’’ğ’–ğ’‚ğ’ğ’ŠğŸâ€¦ğğ’Œ_ğ’„ğ’“ğ’•,=ğ’‡(ğğ’Œ_ğ’’ğ’–ğ’‚ğ’ğ’Š,,ğğ’Œ_ğ’…ğ’Šğ’—ğ’†ğ’“,)ğˆğ’Œ_ğ’„ğ’“ğ’•ğŸ=ğ’‡(ğˆğ’Œ_ğ’’ğ’–ğ’‚ğ’ğ’ŠğŸğˆğ’Œ_ğ’…ğ’Šğ’—ğ’†ğ’“ğŸ)Real samplesKeep the correctKeep the correctGet the corresponding latent featuresUpdate until terminationInputGM_1â€¦â€¦â€¦â€¦â€¦â€¦Get the corresponding latent featuresEvaluateand selectGM_2Synthesized images ğ‘¿ğ’”ğ’šğ’ğ’’ğ’–ğ’‚ğ’ğ’Šğ‘¿ğ’”ğ’šğ’ğ’…ğ’Šğ’—ğ’†ğ’“â€¦â€¦ğ‘¿ğ’”ğ’šğ’ğ‘¿ğ’“ğ’†ğ’‚ğ’ğ‘µ(ğ‘´ğ’Šğ’ğ’Šğ’•,ğœ®ğ’Šğ’ğ’Šğ’•)JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

7

Algorithm 1. MEDA LUDE training procedure

Input: X = {Xmaj, Xmin},Y = {Ymaj, Ymin}
Output: Î¸de, Mopti, Î£opti

, Lclsltt

1

, and Lclsimg

1

1: /*Phase 1*/
2: while not converged do
3:

for each mini-batch data do
update Î¸en with Lrec1 , Lm
GM1
update Î¸de with Lrec1, Lclsimg
update Î¸cls ltt with Lclsltt
update Î¸cls img with Lclsimg
update M , Î£ with Lm

1

1

1

GM1

end for
9:
10: end while
11: Minit = M , Î£init = Î£

12: for number of training iterations do
13:

/*Phase 2*/
while not converged do

for each mini-batch data do

update Î¸de with Lrec2 , Lclsimg
update Î¸cls img with Lclsimg

2

2

end for
end while

/*Phase 3*/
while not converged do

for each mini-batch data do

update Î¸en with Lm
update Î¸cls ltt with Lclsltt

GM3

, Lclsltt

3

3

end for

4:

5:

6:

7:

8:

14:
15:
16:

17:

18:

19:

20:
21:
22:
23:

24:
25:

26:

27:
28:
29:

30:

31:

32:

33:

34:

35:

36:

37:

38:

39:

40:

end while

/*Phase 4*/
F EAT4 = Sample(N (Minit, Î£init))
while halting condition is not met do

(cid:91)labelltt = Classif y Ltt(F EAT4, Î¸cls ltt)
GM 1 = Select Correct(F EAT4, (cid:91)labelltt, labelltt)

Xsyn = Decode(GM 1, Î¸de)
(cid:91)labelimg = Classif y Img(Xsyn, Î¸cls img)
X quali

syn = Select Correct(Xsyn, (cid:91)labelimg, labelimg)

syn , Xreal, AHA)
syn , f itness)

syn = Evaluate Select(X quali

f itness = Cal F itness(X quali
X diver
GM 2 = F ind Ltt(X quali
syn )
Spop = F ind Ltt(X diver
syn )
N (Âµk quali, Ïƒ2
N (Âµk diver, Ïƒ2
N (Âµk crt, Ïƒ2
Ïƒ2
k qauli, Ïƒ2
Mcrt = [Âµ1 crt; Âµ2 crt . . . ; Âµk crt]
Î£crt = [Ïƒ2
k crt]
F EAT4 = Sample(N (Mcrt, Î£crt))

k qauli) = Cal Gaussian(GM 2)
k diver) = Cal Gaussian(Spop)
k crt) = Evolve(Âµk quali, Âµk diver,
k diver)

2 crt . . . ; Ïƒ2

1 crt; Ïƒ2

41:
end while
42:
43: Mopti = Mcrt
Î£opti = Î£crt
44:
45: end for

46: return Î¸de, Mopti, Î£opti

to form a validation set. The test set is the original one of the
CIFAR-10 dataset.

To validate the effectiveness of our proposed method, all
the methods ï¬rst synthesize samples to construct the balanced
dataset based on the imbalanced training set. Then the ï¬nal
classiï¬er is trained on the balanced training set and tested
to achieve the ï¬nal classiï¬cation performance. The closer the
constructed balanced training dataâ€™s distribution is to the real
dataâ€™s, the better the ï¬nal classiï¬cation performance will be.
The classiï¬cation performance on imbalanced MNIST and
CIFAR-10 datasets are shown in TABLE I and TABLE II,
respectively. In TABLE I, the MEDA LUDE algorithm ob-
tains the optimal results on various indexes under two random
seeds among all the comparative methods, indicating that the
samples generated by our method are superior to its com-
petitors in quality-diversity trade-off and hence contributes to
training the classiï¬er. On the CIFAR-10 dataset, the proposed
MEDA LUDE method shows the competitive classiï¬cation
performance, except that the best value for criterion â€˜AUCâ€™ is
obtained by the CVAE SeTred method when the random seed
is 7. To conclude, the optimization phases we design for the
latent feature distribution and the whole neural networks are
efï¬cacious to trade off the quality and diversity of synthesized

samples.

The generated minority samples for the MNIST dataset
are visualized with t-SNE [30], as depicted in Fig. 6. The
â€˜Originalâ€™ gives the distribution of the real minority data,
the distribution of the minority
and the others represent
samples synthesized by their corresponding method, where
the â€˜MEDA LUDEâ€™ exhibits the generated dataâ€™s distribution
when the random seed is 5. Since ADASYN, SMOTE, and
ROS provide a balanced training set directly, the generated
samples need to be chosen randomly from the minorities of
the balanced set with a certain amount. As Fig. 6 shows, the
distribution of samples synthesized by â€˜ROSâ€™ is a disorder
without distinct boundaries, and the distribution corresponding
to â€˜RMRâ€™ is far from the original distribution. In contrast,
the distributions from â€˜ADASYNâ€™ and â€˜SMOTEâ€™ are relatively
reasonable but appear locally aggregated and integrally sparse.
Compared with â€˜ADASYNâ€™ and â€˜SMOTEâ€™, the minority sam-
ples generated from three generative models, namely â€˜CVAEâ€™,
â€˜CVAE SeTredâ€™, and â€˜MEDA LUDEâ€™, are evenly distributed
for each class, which accord with the original samples better.
Obviously, the distribution learned from â€˜CVAEâ€™ is the most
limited, and the second is that of â€˜CVAE SeTredâ€™. With
the same amount of the minority examples, our proposed

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

8

TABLE I
CLASSIFICATION PERFORMANCE OF THE COMPARATIVE METHODS FOR MNIST

Seed

RMR

ROS

SMOTE

ADASYN CVAE

0
5
0
5
0
5
0
5
0
5
0
5
0
5

93.89
92.28
94.20
93.07
93.89
92.28
99.30
99.14
93.81
92.21
96.49
95.54
0.9932
0.9937

94.63
93.08
94.95
93.81
94.63
93.08
99.41
99.24
94.58
93.05
96.94
96.02
0.9954
0.9946

94.67
94.19
94.94
94.33
94.67
94.19
99.41
99.36
94.60
94.14
96.96
96.70
0.9958
0.9941

95.31
93.48
95.45
93.86
95.31
93.48
99.48
99.27
95.28
93.42
97.35
96.27
0.9936
0.9946

95.37
95.07
95.57
95.35
95.37
95.07
99.48
99.45
95.33
95.05
97.37
97.20
0.9962
0.9953

CVAE
SeTred
95.58
95.44
95.81
95.62
95.58
95.44
99.51
99.49
95.56
95.42
97.50
97.42
0.9961
0.9953

TABLE II
CLASSIFICATION PERFORMANCE OF THE COMPARATIVE METHODS FOR CIFAR10

Seed

RMR

ROS

SMOTE

ADASYN CVAE

1
7
1
7
1
7
1
7
1
7
1
7
1
7

48.78
48.61
60.49
60.52
48.78
48.61
94.31
94.29
41.12
45.52
60.02
62.67
0.8121
0.7889

49.15
49.18
63.02
66.17
49.15
49.18
94.35
94.35
41.72
42.77
60.22
60.01
0.7985
0.7814

50.35
49.43
59.61
64.54
50.35
49.43
94.48
94.38
45.87
43.01
64.02
60.92
0.7972
0.7877

50.94
50.26
62.58
64.34
50.94
50.26
94.55
94.47
44.97
40.94
63.84
57.90
0.8295
0.7914

51.06
51.10
61.35
61.27
51.06
51.10
94.56
94.57
43.12
45.89
61.73
63.86
0.7990
0.8052

CVAE
SeTred
51.36
52.22
61.10
64.17
61.36
52.22
94.60
94.69
46.00
45.46
64.67
62.27
0.8212
0.8129

MEDA
LUDE
95.88
95.49
96.05
95.67
95.88
95.49
99.55
99.49
95.86
95.46
97.67
97.44
0.9966
0.9961

MEDA
LUDE
52.65
52.96
63.42
66.85
52.65
52.96
94.74
94.77
47.04
47.35
64.70
63.94
0.8406
0.8094

Evaluation
Critieria
Accuracy
(%)
Precision
(%)
Recall
(%)
Speciï¬city
(%)
F1
(%)
GM
(%)
AUC

Evaluation
Critieria
Accuracy
(%)
Precision
(%)
Recall
(%)
Speciï¬city
(%)
F1
(%)
GM
(%)
AUC

â€˜MEDA LUDEâ€™ has learned more broad distribution, validat-
ing the better diversity of our synthesized samples indirectly.

balanced data the MEDA LUDE constructs improves a lot.

In addition to the synthesized minority samples, we also
visualize the features output from the last fully connected layer
of the ï¬nal classiï¬er, which is trained on the balanced data
formed by various methods. It should be noted that the visu-
alized features correspond to the inputs of the test set instead
of the training data. The visualizations are depicted in Fig. 7,
where the â€˜Balanced dataâ€™ describes the feature distributions
mapped from the test data by the classiï¬ers trained on the
original balanced training data. Different from the distributions
visualized from the generated samples, the closer the points of
the same class are, and the clearer the clustersâ€™ boundaries of
the different classes appear, the higher probability the samples
are classiï¬ed correctly with. Compared with the â€˜Balanced
dataâ€™, the clusters of the different classes visualized from the
other methods have obvious overlaps, which denotes the place
where samples are classiï¬ed wrongly. Among all of these
synthetic methods, the overlaps of the â€˜MEDA LUDEâ€™ are
relatively less, and the boundaries of different categories are
more apparent. In view of this, our proposed MEDA LUDE
algorithm can generate samples whose distributions are closer
to the real samples than the comparative methods. As a result,
the classiï¬cation performance of the classiï¬er trained on the

B. Industrial Application with Real-world Datasets

The MEDA LUDE algorithm is also applied to the indus-
trial ï¬eld successfully. In the textile production process, fabric
defect classiï¬cation is critical to control the textile quality.
However, during the real-world data acquisition, imbalanced
problems are common due to the factor of production equip-
ment and the characteristics of fabric defects, which sharply
weaken the classiï¬cation performance and signiï¬cantly inï¬‚u-
ence the fabric quality. To solve the imbalanced classiï¬cation
of fabric defects in practical industrial applications, we ï¬rstly
collect and process fabric defect data and then construct fabric
defect datasets: DHU-FD and ALIYUN-FD.

For DHU-FD,

the fabric defect data is collected from
Donghua University (DHU) based on the hardware acquisition
device, including two CCD cameras, a network connector,
lighting facility, computer, operation interface, detection con-
troller, and textile materials. The acquisition device is shown
in Fig. 8, where the right-bottom corner gives examples of
raw fabric textiles labelled as normal and oil stains. The
original DHU textile images are in 1280 âˆ— 1024 pixels. Then
the acquired data is processed with Adobe Photoshop CS6
by intercepting the defected part of uniï¬ed pixels, and each

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

9

t-SNE visualizations of the generated minority samples for MNIST

Fig. 7.

t-SNE visualizations of the features for MNIST dataset

Fig. 6.
dataset

intercepted image only contains one type of defect. These
images are labelled according to the characteristic descriptions
of fabric defects. Finally, the DHU-FD dataset is constructed
with ten classes, and each class contains 100 samples of size
220 âˆ— 220. Types in the sequence of â€˜Normalâ€™, â€˜Mispickâ€™,
â€˜Broken picksâ€™, â€˜Double ï¬‚atâ€™, â€˜Slubâ€™, â€˜Felterâ€™, â€˜Draw-backâ€™,
â€˜Sundriesâ€™, â€˜Broken endâ€™, and â€˜Oil stainsâ€™ are numbered from
0 to 9, respectively. Examples, labels, and numbers for ten
types of fabric defects are given in Fig. 9.

In addition to the DHU data, we also download fabric image
data that is public online in the Tianchi competition sponsored
by Alibaba. The size of the original fabric data is 2560 âˆ— 1920
pixels. After the same operations in processing raw images,
the ALIYUN-FD dataset is constructed, including six types,
with each keeping 1500 samples. Images in the ALIYUN-
FD dataset are in 220 âˆ— 220 pixels. Labels in the order of
Normalâ€™, â€˜Broken endâ€™, â€˜Holeâ€™, â€˜Stainâ€™, â€˜Crackâ€™, and â€˜Felterâ€™
are sequentially numbered from 0 to 5. The speciï¬c details of
ALIYUN-FD examples are shown in Fig. 10.

For both the DHU-FD dataset and the ALIYUN-FD dataset,
two random seeds are set to determine minority classes. For
the DHU-FD dataset, the random seeds are set to 1 and 3
to select ï¬ve classes as the minority categories from all ten
types. The corresponding minority types are â€˜Broken picksâ€™,
â€˜Oil stainsâ€™, â€˜Draw-backâ€™, â€˜Slubâ€™, â€˜Normalâ€™ when the seed is
1, and being â€˜Felterâ€™, â€˜Slubâ€™, â€˜Mispickâ€™, â€˜Broken picksâ€™, â€˜Oil
stainsâ€™ when the seed is 3. In the randomly formed imbalanced

Fig. 8. Hardware acquisition device and raw textile image examples

Fig. 9. Examples and numbers for DHU-FD

Fig. 10. Examples and numbers for ALIYUN-FD

OriginalMEDA_LUDECVAE_SeTredCVAEADASYNSMOTEROSRMRBalanced DataMEDA_LUDECVAE_SeTredCVAEADASYNSMOTEROSRMRCCDCameraLighting FacilityNetwork ConnectorComputerDetectionControllerTextile MaterialsOperation InterfaceOilStainsNormalNormalMispickBrokenpicksDoubleflatSlubFelterDraw-backSundriesBrokenendOilstainsNumber: 0Number: 1Number: 2Number: 3Number: 4Number: 5Number: 6Number: 7Number: 8Number: 9NormalNumber: 0Broken endNumber: 1HoleNumber: 2StainNumber: 3CrackNumber: 4FelterNumber: 5JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

10

DHU-FD dataset, each minority class contains 6 samples,
while each majority class has 60 ones in the training set. The
validation and test sets include 200 images evenly distributed
among ten classes. For the ALIYUN-FD dataset, the random
seeds are 0 and 1. Correspondingly, seed 0 selects â€˜Felterâ€™,
â€˜Holeâ€™, and â€˜Broken endâ€™ as the minority classes, while seed
1 chooses â€˜Holeâ€™, â€˜Broken endâ€™, and â€˜Crackâ€™ as the minority
types. The training set comprises of 270 minority samples and
2700 majority samples, where the imbalance ratio is 10. In the
validation set, 300 images are included in each class, and the
same goes for the test set.

To observe the situation of training the MEDA LUDE
algorithm in large-size images, the training loss curves varying
iterations are plotted for Phase 1, Phase 2, and Phase 3, since
Phases 1-3 are responsible for training models, while Phase
4 aims at evolving latent features. The Adam optimizer is
adopted, and the activation function is ReLU. In Phase 1,
the whole model is ï¬rstly trained, including the encoder, the
decoder, the latent feature classiï¬er, and the image classiï¬er.
Hence the total loss consists of reconstruction loss, L-GM
loss, latent feature classiï¬cation loss, and image classiï¬cation
loss, as depicted in Fig.11. It can be seen that all the losses
in Phase 1 occur rhythmic abrupt changes and ï¬‚uctuations,
which varying learning rates may cause. Nevertheless, all the
losses decrease as the iteration increases until they ï¬nally
converge. Since the convergence of the reconstruction loss is
not apparent when all the losses are included in one picture, the
reconstruction loss is enlarged in the blank space for further
observation, as shown in the red dashed frame in Fig. 11.
It is clear that the reconstruction loss gradually converges
during continuous iterations. In Phase 2, our goal is to train the
decoder and the image classiï¬er. Hence the total loss for Phase
2 is composed of reconstruction loss and image classiï¬cation
loss, as shown in Fig. 12. The image classiï¬cation loss and the
total loss exhibit downward trends on the whole and ï¬nally
converge. Compared with Phase 1, the training process of this
Phase ï¬‚uctuates less and is more stable. The reconstruction
loss is enlarged again in the blank place of this chart for
further study. From the curve in the red dashed square frame,
it is found that the reconstruction loss rises at the beginning,
then decreases, and ï¬nally levels off. This phenomenon is
probably due to the calculation method for the reconstruction
loss. In Phase 1, the reconstruction loss is calculated based
on the input image and the reconstructed image, which is
obtained by decoding the latent feature encoded from the
input image. Different from Phase 1, Phase 2 ï¬rstly samples
from the latent variablesâ€™ distribution trained in Phase 1 and
then decodes the sampling point to get the synthesized image.
Finally, the loss is calculated between the synthesized image
and the real sample, which is randomly chosen. Hence, the
generated images in Phase 2 are not the real reconstructed
images for the input images but the generations from the
latent features. Furthermore, the random sampling points have
more possibilities, leading to the corresponding changes in
generated samples. Therefore, the reconstruction loss exceeds
a relearning process instead of continuing to converge based
on the previous loss. In Phase 3, the MEDA LUDE aims
at training the encoder and the latent feature classiï¬er, and

the total loss includes the L-GM loss and the latent feature
classiï¬cation loss. We can conclude from Fig. 13 that all
the losses decrease stably until ï¬nal convergence. To sum
up, the training process in Phases 1-3 fully showcases the
stability and the robustness of the MEDA LUDE model in
high-dimensional images.

Fig. 11. Losses in Phase 1 for DHU-FD dataset

Fig. 12. Losses in Phase 2 for DHU-FD dataset

Fig. 13. Losses in Phase 3 for DHU-FD dataset

The experimental results in DHU-FD dataset and ALIYUN-
FD dataset are exhibited in TABLE III and TABLE IV,
respectively. In TABLE III, the best accuracies under both the
two random circumstances are achieved by the MEDA LUDE
algorithm, and both of them are far superior to their respective
suboptimal accuracies. Except for the precision of seed 1 and
the AUC of seed 3, the MEDA LUDE algorithm outperforms
all the other comparative methods in various criteria under
two different imbalanced datasets randomly formed, which
validates the effectiveness of the proposed method in handling
the imbalanced problem for fabric defects from DHU. For the
ALIYUN-FD dataset, the proposed MEDA LUDE algorithm
obtains the best results in all the indicators apart from the
index AUC. When the random seed is 0, the most outstanding

02004006008001000Iteration0123456Loss ValueTotal LossLGM LossLtt Classification LossJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

11

TABLE III
CLASSIFICATION PERFORMANCE OF THE COMPARATIVE METHODS FOR DHU-FD

Seed

RMR

ROS

SMOTE

ADASYN CVAE

1
3
1
3
1
3
1
3
1
3
1
3
1
3

63.50
63.50
69.38
69.38
63.50
63.50
95.94
95.94
56.92
56.92
70.63
70.63
0.9444
0.9444

66.00
70.50
75.56
75.98
66.00
70.50
96.22
96.72
62.42
68.93
75.69
81.03
0.9032
0.9625

70.00
71.00
69.36
71.71
70.00
71.00
96.67
96.78
68.59
67.54
80.93
77.34
0.9439
0.9421

69.00
73.00
67.00
75.11
69.00
73.00
96.56
97.00
65.44
71.21
78.21
79.15
0.9375
0.9270

70.00
73.50
78.02
74.29
70.00
73.50
96.67
97.06
67.60
71.41
79.83
79.49
0.9538
0.9352

CVAE
SeTred
71.00
74.00
79.44
75.46
71.00
74.00
96.78
97.11
67.89
72.76
79.21
82.21
0.9560
0.9391

TABLE IV
CLASSIFICATION PERFORMANCE OF THE COMPARATIVE METHODS FOR ALYUN-FD

Seed

RMR

ROS

SMOTE

ADASYN CVAE

0
1
0
1
0
1
0
1
0
1
0
1
0
1

56.72
58.72
66.34
64.83
56.72
58.72
91.34
91.74
51.72
54.56
67.58
69.92
0.8671
0.8714

59.06
58.17
66.35
64.21
59.06
58.17
91.81
91.63
56.19
55.63
70.87
70.63
0.8488
0.8440

59.83
58.50
65.60
65.82
59.83
58.50
91.97
91.70
58.34
56.08
72.49
70.73
0.8418
0.8359

60.11
58.56
64.28
62.79
60.11
58.56
92.02
91.71
57.69
55.56
72.30
70.75
0.8473
0.8380

60.28
58.72
65.47
65.21
60.28
58.72
92.06
91.74
57.61
55.39
72.07
70.43
0.8474
0.8695

CVAE
SeTred
61.00
60.00
66.91
65.20
61.00
60.00
92.20
92.00
58.28
57.39
72.58
72.06
0.8473
0.8389

MEDA
LUDE
74.00
76.00
79.11
79.09
74.00
76.00
97.11
97.33
74.28
73.98
84.13
83.31
0.9603
0.9371

MEDA
LUDE
62.06
60.94
66.94
66.03
62.06
60.94
92.41
92.19
59.54
58.16
73.49
72.59
0.8569
0.8444

Evaluation
Critieria
Accuracy
(%)
Precision
(%)
Recall
(%)
Speciï¬city
(%)
F1
(%)
GM
(%)
AUC

Evaluation
Critieria
Accuracy
(%)
Precision
(%)
Recall
(%)
Speciï¬city
(%)
F1
(%)
GM
(%)
AUC

value for AUC is acquired by RMR, and our methodâ€™s AUC
is second only to RMRâ€™s. However, the accuracy of RMR is
only 56.72%, which is far smaller than ours, and the other
indicators between RMR and the MEDA LUDE method still
exist gaps. When the random seed is set to 1, even though
the MEDA LUDE doesnâ€™t get the best AUC, it still exposes
the excellent classiï¬cation performance in the other criteria.
Since the test set is balanced, according to the classiï¬cation
results presented above, it has proved that the MEDA LUDE
algorithm can be applied successfully to the imbalanced clas-
siï¬cation task for fabric defects but still has room for further
improvement.

V. CONCLUSION
In this paper, a new algorithm called MEDA LUDE is
designed for trading off the quality and the diversity of
generated samples in imbalanced image classiï¬cation tasks.
The proposed method combines deep neural networks and
modiï¬ed EDAs to optimize and evolve latent feature distri-
butions jointly. Besides, the L-GM loss function is introduced
to feature learning under a more complex assumption. The
EDAs are improved to guide the searching space for better
quality and diversity. Classiï¬cation performance on the two
imbalanced datasets constructed from MNIST and CIFAR-
10 datasets and the t-SNE visualizations indicate the efï¬cacy

of our method in generating samples with both the quality
and the diversity. Last, the success of applications in fabric
defect classiï¬cation shows the potential of the MEDA LUDE
algorithm in solving imbalanced problems in the industry.

ACKNOWLEDGMENT

This work was supported in part by the Fundamental
Research Funds for
the Central Universities (2232021A-
10, 2232021D-37), National Natural Science Foundation of
China (61903078), Shanghai Sailing Program (22YF1401300),
Natural Science Foundation of Shanghai
(20ZR1400400,
21ZR1401700), and Chinese Ministry of Education Research
Found on Intelligent Manufacturing (MCM20180703).

REFERENCES

[1] X. Zhang, Y. Zhuang, W. Wang, and W. Pedrycz, â€œTrans-
fer boosting with synthetic instances for class imbalanced
object recognition,â€ IEEE Transactions on Cybernetics,
vol. 48, no. 1, pp. 357â€“370, 2016.

[2] Z. Zhu, Z. Wang, D. Li, Y. Zhu, and W. Du, â€œGeometric
structural ensemble learning for imbalanced problems,â€
IEEE Transactions on Cybernetics, vol. 50, no. 4, pp.
1617â€“1629, 2020.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

12

[3] A. Rosales-PÂ´erez, S. GarcÂ´Ä±a, and F. Herrera, â€œHan-
dling imbalanced classiï¬cation problems with sup-
port vector machines via evolutionary bilevel opti-
mization,â€ IEEE Transactions on Cybernetics, 2022,
doi:10.1109/TCYB.2022.3163974.

[4] A. Liu, J. Ghosh, and C. E. Martin, â€œGenerative oversam-
pling for mining imbalanced datasets.â€ in DMIN, 2007,
pp. 66â€“72.

[5] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P.
Kegelmeyer, â€œSmote: synthetic minority over-sampling
technique,â€ Journal of Artiï¬cial Intelligence Research,
vol. 16, pp. 321â€“357, 2002.

[6] H. Han, W.-Y. Wang, and B.-H. Mao, â€œBorderline-
smote: a new over-sampling method in imbalanced data
sets learning,â€ in International Conference on Intelligent
Computing. Springer, 2005, pp. 878â€“887.

[7] H. He, Y. Bai, E. A. Garcia, and S. Li, â€œAdasyn: Adaptive
synthetic sampling approach for imbalanced learning,â€
in 2008 IEEE International Joint Conference on Neu-
ral Networks (IEEE World Congress on Computational
Intelligence).
[8] S. Barua, M. M.

Islam, X. Yao, and K. Murase,
â€œMwmoteâ€“majority weighted minority oversampling
technique for imbalanced data set learning,â€ IEEE Trans-
actions on Knowledge and Data Engineering, vol. 26,
no. 2, pp. 405â€“425, 2012.

IEEE, 2008, pp. 1322â€“1328.

[9] J. Chen, L. Du, and L. Liao, â€œDiscriminative mixture
variational autoencoder for semisupervised classiï¬ca-
tion,â€ IEEE Transactions on Cybernetics, pp. 1â€“15, 2020.
[10] Z. Wan, Y. Zhang, and H. He, â€œVariational autoencoder
based synthetic data generation for imbalanced learning,â€
in 2017 IEEE Symposium Series on Computational In-
telligence (SSCI).

IEEE, 2017, pp. 1â€“7.

[11] W. Dai, K. Ng, K. Severson, W. Huang, F. Anderson, and
C. Stultz, â€œGenerative oversampling with a contrastive
variational autoencoder,â€ in 2019 IEEE International
Conference on Data Mining (ICDM).
IEEE, 2019, pp.
101â€“109.

[12] J. Lim, S. Ryu, J. W. Kim, and W. Y. Kim, â€œMolec-
ular generative model based on conditional variational
autoencoder for de novo molecular design,â€ Journal of
Cheminformatics, vol. 10, no. 1, pp. 1â€“9, 2018.

[13] Y. Yang, C. Malaviya, J. Fernandez, S. Swayamdipta,
R. L. Bras, J.-P. Wang, C. Bhagavatula, Y. Choi, and
D. Downey, â€œGenerative data augmentation for com-
monsense reasoning,â€ arXiv preprint arXiv:2004.11546,
2020.

[14] S. Du, J. Hong, Y. Wang, and Y. Qi, â€œA high-quality
multicategory sar images generation method with mul-
ticonstraint gan for atr,â€ IEEE Geoscience and Remote
Sensing Letters, vol. 19, pp. 1â€“5, 2022.

[15] C. Yang, Y. Shen, Y. Xu, and B. Zhou, â€œData-efï¬cient
instance generation from instance discrimination,â€ arXiv
preprint arXiv:2106.04566, 2021.

[16] V. Costa, N. LourencÂ¸o, J. Correia, and P. Machado, â€œEx-
ploring the evolution of gans through quality diversity,â€
in Proceedings of the 2020 Genetic and Evolutionary
Computation Conference, 2020, pp. 297â€“305.

[17] D. Alihosseini, E. Montahaei, and M. S. Baghshah,
â€œJointly measuring diversity and quality in text gener-
ation models,â€ in Proceedings of the Workshop on Meth-
ods for Optimizing and Evaluating Neural Language
Generation, 2019, pp. 90â€“98.

[18] J. Li, Y. Lan, J. Guo, and X. Cheng, â€œOn the relation be-
tween quality-diversity evaluation and distribution-ï¬tting
goal in text generation,â€ in International Conference on
Machine Learning. PMLR, 2020, pp. 5905â€“5915.
[19] P. Bontrager, A. Roy, J. Togelius, N. Memon, and
A. Ross, â€œDeepmasterprints: Generating masterprints for
dictionary attacks via latent variable evolution,â€ in 2018
IEEE 9th International Conference on Biometrics The-
ory, Applications and Systems (BTAS).
IEEE, 2018, pp.
1â€“9.

[20] V. Volz, J. Schrum, J. Liu, S. M. Lucas, A. Smith, and
S. Risi, â€œEvolving mario levels in the latent space of
a deep convolutional generative adversarial network,â€ in
Proceedings of the Genetic and Evolutionary Computa-
tion Conference, 2018, pp. 221â€“228.

[21] E. Giacomello, P. L. Lanzi, and D. Loiacono, â€œSearching
the latent space of a generative adversarial network to
generate doom levels,â€ in 2019 IEEE Conference on
Games (CoG).
IEEE, 2019, pp. 1â€“8.

[22] S. Thakkar, C. Cao, L. Wang, T. J. Choi, and J. To-
gelius, â€œAutoencoder and evolutionary algorithm for level
generation in lode runner,â€ in 2019 IEEE Conference on
Games (CoG).
IEEE, 2019, pp. 1â€“4.

[23] S. Zhou and Z. Sun, â€œA survey on estimation of distribu-
tion algorithms,â€ Acta Automatica Sinica, vol. 33, no. 2,
p. 113, 2007.

[24] Q. Yang, W.-N. Chen, Y. Li, C. P. Chen, X.-M. Xu,
and J. Zhang, â€œMultimodal estimation of distribution
algorithms,â€ IEEE Transactions on Cybernetics, vol. 47,
no. 3, pp. 636â€“650, 2016.

[25] Y. Liang, Z. Ren, X. Yao, Z. Feng, A. Chen, and W. Guo,
â€œEnhancing gaussian estimation of distribution algorithm
by exploiting evolution direction with archive,â€ IEEE
Transactions on Cybernetics, vol. 50, no. 1, pp. 140â€“152,
2018.

[26] X. et al., â€œSwarm intelligence optimization based on
estimation of distribution algorithm,â€ Computer And
Modernization, vol. 000, no. 001, pp. 17â€“22, 2017.
[27] W. Wan, Y. Zhong, T. Li, and J. Chen, â€œRethinking
feature distribution for loss functions in image classi-
ï¬cation,â€ in Proceedings of
the IEEE Conference on
Computer Vision and Pattern Recognition, 2018, pp.
9117â€“9126.

[28] L. Weng and B. Preneel, â€œA secure perceptual hash
algorithm for image content authentication,â€ in IFIP
International Conference on Communications and Mul-
timedia Security. Springer, 2011, pp. 108â€“121.

[29] Q. Kang, X. Chen, S. Li, and M. Zhou, â€œA noise-ï¬ltered
under-sampling scheme for imbalanced classiï¬cation,â€
IEEE Transactions on Cybernetics, vol. 47, no. 12, pp.
4263â€“4274, 2016.

[30] L. Van der Maaten and G. Hinton, â€œVisualizing data using
t-sne.â€ Journal of Machine Learning Research, vol. 9,

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

13

no. 11, 2008.

