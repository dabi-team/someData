2
2
0
2

l
u
J

6
2

]

V
C
.
s
c
[

1
v
4
4
7
2
1
.
7
0
2
2
:
v
i
X
r
a

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

Distribution Learning Based on Evolutionary Algorithm Assisted
Deep Neural Networks for Imbalanced Image Classiﬁcation

Yudi Zhao1, Kuangrong Hao1,*, Chaochen Gu2, Bing Wei1
1College of Information Sciences and Technology, Donghua University, Shanghai 201620, P. R. China
2Department of Automation, Shanghai Jiao Tong University, Shanghai 200240, P. R. China

To address the trade-off problem of quality-diversity for the generated images in imbalanced classiﬁcation tasks, we research
on over-sampling based methods at the feature level instead of the data level and focus on searching the latent feature space for
optimal distributions. On this basis, we propose an iMproved Estimation Distribution Algorithm based Latent featUre Distribution
Evolution (MEDA LUDE) algorithm, where a joint learning procedure is programmed to make the latent features both optimized
and evolved by the deep neural networks and the evolutionary algorithm, respectively. We explore the effect of the Large-margin
Gaussian Mixture (L-GM) loss function on distribution learning and design a specialized ﬁtness function based on the similarities
among samples to increase diversity. Extensive experiments on benchmark based imbalanced datasets validate the effectiveness of
our proposed algorithm, which can generate images with both quality and diversity. Furthermore, the MEDA LUDE algorithm is
also applied to the industrial ﬁeld and successfully alleviates the imbalanced issue in fabric defect classiﬁcation.

Index Terms—Imbalanced classiﬁcation, quality-diversity, distribution learning, evolutionary algorithm, fabric defect.

I. INTRODUCTION

I MBALANCED problems have always occurred in real-

world collected data, where the high degree of variation
is exhibited in the number of different categories due to
data characteristics, problems in the collection process, or
human factor. Traditional classiﬁcation methods are built on
the premise of the data balance and hence easily confront
a sharp drop in classiﬁcation performance when handling
imbalanced data with highly skewed distributions [1]. Since
imbalanced data is widespread in people’s lives and industrial
production, such as credit card fraud recognition, industrial
fault detection, and diagnosis, as well as cancer diagnosis and
treatment, imbalanced classiﬁcation problems have become
challenges in the ﬁelds of machine learning and data mining
[2].

Traditional over-sampling based techniques to address
imbalanced problems mainly synthesize samples randomly
among the minority classes [3]. Random over-sampling (ROS)
[4] is the simplest way to increase the ratio of minority
samples, where the valuable information is not
increased
as the sample count. To improve the generalization ability,
Chawa et al. [5] designed a synthetic minority over-sampling
technique (SMOTE) based on a neighbor strategy among
the minority samples. However, noise could be introduced
to the synthesis process, and the problem of distribution
marginalization probably happens, especially when noisy sam-
ples appear at the boundary of the positive samples and the
negative samples. For this, borderline-SMOTE [6] is further
raised to operate synthesis around the boundaries. He et
al. [7] proposed an adaptive synthetic (ADASYN) sampling
method that adaptively synthesizes minority samples according
to the distribution as well as the learning difﬁculty of the
minority samples. Besides, the majority weighted minority
oversampling technique (MWMOTE) [8] innovatively assigns

*Corresponding author: Kuangrong Hao (email: krhao@dhu.edu.cn)

images. Due to the powerful

different weights to the hard-to-learn minority samples. The
weight is determined by their distances to the nearest majority
samples. However, traditional over-sampling based methods
exist limitations in classiﬁcation tasks when dealing with high-
dimensional
learning ability,
deep learning based over-sampling techniques have shown
superiority in imbalanced problems. Variational autoencoder
(VAE), as a generative model, has strong capacity for image
generation due to its variational inference ability between the
complex data and the low-dimensional latent feature space
[9]. Wan et al. [10] utilized VAE to generate the minority
images and successfully solved the imbalanced problem in
image classiﬁcation tasks. Dai et al. [11] further leveraged
the information from the majority samples based on the VAE,
which achieved great success in the medical ﬁeld. Moreover,
the conditional VAE (CVAE) [12] is a modiﬁcation of VAE to
guide and control the image synthesis process by incorporating
prior constraints.

Even though deep learning based over-sampling models
have made achievements in imbalanced classiﬁcation prob-
lems, the quality and diversity of samples can not always
be guaranteed simultaneously, especially when the existing
samples are limited. To tackle this puzzle, some recent works
explore how to obtain superior quality and diversity trade-off
in generation tasks. Yang et al. [13] improved synthesis quality
by removing detrimental ones based on inﬂuence functions and
maximized the diversity by picking out compelling examples
from the generated pool for the application of commonsense
reasoning. Still, both of the selections are based on the
level of samples, which is not so efﬁcient when requiring a
large amount of generative data. Du et al. [14] proposed a
multiconstraint generative adversarial network (MCGAN) to
ensure the similarity, diversity, and correct category of the
synthetic aperture radar (SAR) images in the ﬁeld of automatic
target recognition (ATR), where the diversity is increased by
adding Gaussian noise to the input vector of the generator.

 
 
 
 
 
 
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

2

Similarly, noise perturbation is also employed as well as
inﬁnite generative samples to enhance the discrimination,
which can boost the high-quality and diverse generation [15].
However, noise-based methods are accompanied by random-
ness and are less controllable. In [16], a new quality-diversity
based evolutionary algorithm is applied to GANs to upgrade
the exploration of search space and provide better solutions
for generators and discriminators. Hence, the ﬁnal generators
competitively synthesized high-quality samples. Although this
method can be trained controllably with objectives, it aims
at guiding the evolution of GANs to discover more efﬁcient
models rather than data distribution.

The synthesis of data depends on the generator and its input
vectors sampled from the latent distributions. Meanwhile, it
has proved that the closer the generated distribution is to the
real distribution, the higher the quality and diversity of the
synthesized data achieve [17, 18]. Therefore, in imbalanced
problems, distribution learning is essential for deep learning
based oversampling methods for image generations. However,
existing deep learning based methods are prone to the risk
of overﬁtting, and the learned distribution is likely restricted
within a limited range far from the real distribution when given
training data is imbalanced or even insufﬁcient. This paper
employs an evolutionary algorithm to learn distributions to
alleviate this problem. A similar idea deﬁned as latent variable
evolution (LVE) is ﬁrst introduced for dictionary attack [19].
This research work adopts the covariance matrix adaptation
evolution strategy (CMA-ES) to evolve the input variables
of GANs for ﬁngerprint synthesis. However, their objective
is to match the impostors with as many subjects in the real
ﬁngerprint images as possible during the evaluation of the
recognition system. Besides, LVE is also applied to procedural
content generation (PCG) of video game levels [20, 21, 22].
Volz et al. [20] generated playable Mario levels by applying
CMA-ES to GANs. The same approach is also exploited
to search the latent space for producing DOOM levels with
an excellent grade of novelty and variety [21]. In addition,
Thakkar et al.[22] proposed to merge a multi-population evo-
lutionary algorithm into a multi-channel autoencoder for Lode
Runner level generations and realized the goal of playability
and connectivity. However, these approaches are not applicable
to image generation for imbalanced problems since the ﬁtness
functions are devised according to the desired properties of
different video games rather than objectives like quality or
diversity.

In this paper, we assume that the latent features follow
a multivariate Gaussian mixture (GM) distribution and ap-
ply the estimation of distribution algorithm (EDA) [23] to
evolve the latent feature distribution, which is simultaneously
optimized by deep neural networks with the large-margin
Gaussian Mixture (L-GM) loss for quality-diversity trade-off.
Considering we aimed at optimizing and searching for the
optimal distribution in the latent space while VAEs already
exist a prior probability distribution for latent variables, thus
the autoencoders (AEs) are applied where the input images are
mapped to the feature space by an encoder, and then the latent
features are decoded to the synthesized samples. Meanwhile,
two classiﬁers, including a latent feature classiﬁer and an im-

age classiﬁer, are employed to control and improve the feature
distribution learning process for better diversity, and train the
generator for better quality. Our contributions are summarized
as follows: (1) A deep neural network based architecture for
imbalanced problems is devised, where an iMproved EDA
(MEDA) is utilized to evolve the latent feature distributions,
and the proposed method can well balance the quality and
diversity of generations. (2) A specialized ﬁtness function is
designed for the MEDA according to the similarities among
samples. The ﬁtness function will guide the search for the
latent variables to enhance the diversity. (3) We exploit the
function of L-GM loss under a more complex assumption,
where the covariance matrix is assumed to be a variable
participating in the optimization of deep neural networks and
the evolution of MEDA instead of being an identity matrix.
(4) Four training phases are innovatively programmed in the
MEDA LUDE algorithm, which can achieve excellent perfor-
mance on benchmark datasets and be successfully applied to
the industrial ﬁeld.

The remainder of the paper is organized as follows: Section
II introduces concepts of EDA and L-GM loss. Detailed
descriptions of our proposed method are given in III. In IV,
experimental results and analysis are displayed. Finally, we
present our conclusions.

II. BACKGROUND

A. Estimation of Distribution Algorithms

Estimation of Distribution Algorithms (EDAs) are a novel
branch of statistical-model-based evolutionary algorithms and
provide a microscopical paradigm where the population
evolves by learning from the probabilistic distribution model
[24]. Although EDAs have developed various implementa-
tions,
the core of them can be summed up as two main
steps [23, 25]: (1) Construct the probabilistic model of the
solution space and select the superior individuals based on the
evaluation. The new explicit probabilistic model can describe
the distribution of the updated solution space. (2) Generate
a new population by sampling randomly from the current
probabilistic model, and then repeat steps (1)-(2) until the
termination criterion is met.

In this paper, we assume that the latent features follow a
multivariate Gaussian mixture model (GMM). Hence, we give
a brief introduction of the basic Gaussian distribution based
EDA [26]. Assume that N represents the population size,
k and Iter are the iterations and the maximum number of
the iterations, respectively. η denotes the sampling rate of the
superior population. The general procedure is as follows:

1) Randomly generate N initial solutions as a population,
which is denoted as pop(0) = {x1, x2, · · · , xN }, here
k = 0.

2) Calculate the ﬁtness of each individual in pop(k).
3) Rank the individuals in a descending order based on
ﬁtnesses, and keep the former ηN individuals as the
superior population spop(k).

4) if k = Iter, terminate the algorithm; Otherwise, con-

tinue step 5).

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

3

5) Calculate the mean and the variance of pop(k)

andspop(k) for each dimension.

6) Update the mean and the variance according to rules

below:

µ = γµnew + (1 − γ)µ
new + (1 − γ)σ2

σ2 = γσ2

the covariance assumption given above, we assume it to be a
variable that engages in the optimization of deep neural net-
works and the evolution of evolutionary algorithms. Therefore,
the L-GM loss needs to be re-derived, and we should further
adjust the implementations in a more complex situation.

III. METHODOLOGY

where µ, σ2 denote the means and the variances of
pop(k), while µnew, σ2
new represent those of spop(k).
γ is the weighting coefﬁcients.

7) Sample from the Gaussian distribution with the current
means and variances, then generate a new population.

8) k := k + 1, and go to step 2).
In our MEDA LUDE algorithm, the basic EDA mentioned
above is improved and adopted to evolve the latent feature
distribution for further quality and diversity enhancement in
data generation.

The proposed MEDA LUDE model consists of an encoder,
a decoder, a latent feature classiﬁer, and an image classiﬁer,
as shown in Fig. 1. The latent features learned from the
encoder are supposed to follow a multivariate GM distribution,
a mixture of K normal distributions, where K represents the
number of categories. To reach the goal of quality-diversity
trade-off in image generation for imbalanced classiﬁcation,
we program a training procedure through four phases based
on the MEDA LUDE architecture, as depicted in Figs. 2-5,
respectively.

B. Large-margin Gaussian Mixture Loss

The L-GM loss is proposed for deep neural networks
in classiﬁcation problems, where the extracted features are
assumed to follow a GM distribution, and each category
belongs to one ingredient [27]. The proposed L-GM loss is
composed of a classiﬁcation loss with large-margin and a
likelihood regularization. The classiﬁcation loss can enhance
the discrimination and improve the generalization capability,
and the likelihood regularization can drive the features to obey
the GM distribution. Assume that µk and Σk are the mean and
covariance of a Gaussian distribution representing class k in
feature space, including total K classes, and xi and zi denotes
the extracted feature and its label of the i − th sample. Then
the L-GM loss [27] is deﬁned as Eq. (1).

Fig. 1. The MEDA LUDE architecture.

A. Phase 1: Pre-training of MEDA LUDE

Lm

GM,i = − log

(cid:80)

|Σzi|− 1
k |Σk|− 1
1
2

+ λ(dzi +

log|Σzi|)

2 e−dzi (1+α)
2 e−dk(1+1(k=zi)α)

(1)

dk =

1
2

(xi − µk)T Σ−1

k (xi − µk) k ∈ [1, K]

(2)

where the ﬁrst term of Eq. (1) is the classiﬁcation loss, and
the second term is the likelihood regularization. α is a non-
negative parameter controlling the classiﬁcation margin size
m, and the indicator function 1() equals 1 if k = zi, otherwise
equals 0. λ is a non-negative weighting coefﬁcient of the
second term.

For simplicity, the authors hypothesize the covariance sat-
isﬁes the hypothesis of the identity matrix, namely Σk = I.
Hence the L-GM loss is ﬁnally simpliﬁed as below:

Fig. 2. Phase 1: the parameters of the encoder, the decoder, the latent feature
classiﬁer, the image classiﬁer, and the multivariate GM distributed latent
features all participates in optimization.

Lm

GM,i = −log

e−dzi (1+α)
k e−dk(1+1(k=zi)α)

(cid:80)

+ λdzi

dk =

1
2

(xi − µk)2

k ∈ [1, K]

(3)

(4)

In the proposed MEDA LUDE algorithm, L-GM loss is
adopted to provide the means and covariances of GM distri-
butions with great initial values for MEDA evolving. Unlike

As shown in Fig. 2, the input is composed of the majority
samples Xmaj and the minority samples Xmin. The encoder,
the decoder, and the two classiﬁers are pre-trained with recon-
struction loss and classiﬁcation loss. Meanwhile, the L-GM
loss is also brought to the total loss, driving the latent features
to follow a multivariate GM distribution automatically and
giving a wise initialization for evolution operations without
prior knowledge.

………………………EncoderDecoderLatent feature classifierImage classifierLatent featuresInputSynthesized images𝑵𝝁𝟏,𝝈𝟏𝟐𝑵𝝁𝟐,𝝈𝟐𝟐𝑵𝝁𝟑,𝝈𝟑𝟐𝑵𝝁𝟒,𝝈𝟒𝟐𝑵𝝁𝑲,𝝈𝑲𝟐……………………………EncoderDecoderLatent feature classifierImage classifierLatent featuresInput:Synthesized imagesℒ𝒄𝒍𝒔𝟏𝒍𝒕𝒕Classification loss: L-GM loss: ℒ𝐺𝑀1𝑚ℒ𝑟𝑒𝑐1Reconstruction loss: Classification loss: ℒ𝒄𝒍𝒔𝟏𝒊𝒎𝒈𝑋𝑚𝑎𝑗,𝑋𝑚𝑖𝑛JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

Different from [27], both the means and covariances of the
multivariate GM distribution are hypothesized to be variables
to be optimized in the MEDA LUDE algorithm. Here the
assumption is given that f eati ∈ R1×h is the latent feature
learned from the i − th input image, where h is the feature
dimension. Correspondingly, the multivariate mean of class k
has the same dimension, denoted as µk ∈ R1×h, meanwhile
the covariance matrix Σk ∈ Rh×h is hypothesized to be
diagonal, signiﬁed by Λk ∈ Rh×h. The L-GM loss can be
written as:

Lm

GM,i = − log

(cid:80)

2 e−dzi (1+α)
2 e−dk(1+1(k=zi)α)

|Λzi|− 1
k |Λk|− 1
1
2

+ λ(dzi +

log|Λzi|)

dk =

1
2

(f eati − µk)T Λ−1

k (f eati − µk) k ∈ [1, K]

(6)

where the ﬁrst term to the right of the equal sign in Eq. (5)
is the classiﬁcation loss Lcls,i, while the second one is the
likelihood regularization Llkd,i. In Eq. (6), dk calculates the
squared Mahalanobis distance between the i − th feature and
the class k.

With the non-ignorable and variable covariances Λk in
Eq. (6), the formulation needs to be re-derived when cal-
culating the distance D between a batch of features and
the K classes. First, a batch of features are assumed
all
as F EAT = [f eat1; f eat2; . . . ; f eatn] ∈ Rn×h, where n
is the batch size. The multivariate mean with K classes
is M = [µ1; µ2; . . . ; µK] ∈ RK×h. For convenience, the
diagonal values of Λk are extracted as a vector σ2
k =
[λk1, λk2, . . . , λkh] ∈ R1×h, hence, the multivariate covari-
K] ∈ RK×h. Then the distance D
ance is Σ = [σ2
1; σ2
is derived as follows:

2; . . . ; σ2

D =

{(F EAT (cid:12) F EAT ) × ΣT

1
2
− 2F EAT × (M T (cid:12) ΣT ) + G




G =

g(cid:48)
g(cid:48)
...
g(cid:48)











n×K

g(cid:48) =

h−1
(cid:88)

j=0

g[j]

g(cid:48) ∈ R1×K

g = M T (cid:12) M T (cid:12) ΣT

g ∈ Rh×K

(7)

(8)

(9)

(10)

4

(12)








n×K








logq
logq
...
logq

Q =

logq = [logq1, logq2, . . . , logqK] ∈ R1×K

(13)

where Ones is an n × K matrix of which each element is 1.
label is a one-hot form from the labels of n samples, whose
dimension is n × K.

Based on the logit, the classiﬁcation Lcls of n samples can

be ﬁnally obtained by using cross entropy loss.

(5)

According to the previous assumption about |Λk|− 1
likelihood regularization Llkd can be derived as follows:

2 , the

(14)

(15)

(16)

(17)

(18)

(19)

(20)

Llkd = (D − Q) (cid:12) label

Finally, the L-GM loss can be achieved by:

Lm

GM = Lcls + λLlkd

Finally, the phase loss Lph1 is deﬁned by:
Lph1 =βrec1 ∗ Lrec1 + βGM1 ∗ Lm
+ βclsimg

+ βclsltt

∗ Lclsltt

GM1

1

1

1

∗ Lclsimg

1

Lrec1 = Lrec1 min + ξrec1 ∗ Lrec1 maj
Lm

GM1 min + ξGM1 ∗ LGM1 maj

= Lm

GM1

Lclsltt

1

Lclsimg

1

= Lclsltt

=Lclsori
Lclssyn

1

1 min + ξclsltt
1 min + ξclsori
1 min + ξclssyn
, and Lclsimg

1

1

∗ Lclsltt

1 maj

1 maj

∗ Lclsori
∗ Lclssyn

1 maj

1

1

1

1

GM1

GM1

, Lclsltt

, and Lclsltt

, and βclsimg

where Lrec1, Lm
are the reconstruction
loss, the L-GM loss, the classiﬁcation loss from the latent
features and the images of Phase 1, respectively. Meanwhile,
βrec1, βGM1 , βclsltt
are their corresponding
weighting coefﬁcients. Besides, Lrec1, Lm
are
all composed of the minority part and the majority part, with
respective coefﬁcients ξrec1, ξGM1 , and ξclsltt
to alleviate the
bias caused by imbalanced data. Furthermore, Lclsimg
includes
image
the classiﬁcation loss from both the original
and the synthesized images, namely ‘Lclsori
∗
Lclsori
1 maj’, where
ξclsori
are the coefﬁcients for the input images and
the generated images, respectively. When Phase 1 is ﬁnished,
the initial multivariate GM distribution of the latent features
can be obtained and denoted by Minit and Σinit.

1
input
1 min + ξclsori

1 maj’ and ‘Lclssyn

1 min + ξclssyn

and ξclssyn

∗ Lclssyn

1

1

1

1

1

1

where ‘(cid:12)’ and ‘×’ denote the Hadamard product and the ma-
trix multiplication, respectively. j represents the row index of
matrix g. The ﬁnal distance D’s dimension is n×K, recording
the squared Mahalanobis distance between n features and K
classes.

To calculate the classiﬁcation loss Lcls, we assume
2 = qk = elogqk , and the logits logit of n samples

|Λk|− 1
in K class can be calculated by:

logit = −D (cid:12) (Ones + α ∗ label) + Q

(11)

B. Phase 2: Local Enhancement for Image Synthesis

In Phase 2, we focus on enhancing the ability of the decoder
and the image classiﬁer. As shown in Fig. 3, the latent features
are ﬁrstly produced as the input of the decoder by sampling
from the learned distribution with the mean Minit and the
covariance Σinit. Based on the synthesized images and the real
samples randomly chosen according to the number and labels
of the input, the reconstruction loss Lrec2 and classiﬁcation

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

5

distribution learned from Phase 1 already considers the bias
between the majority and the minority, we ignore the inﬂuence
of skewed distribution from the imbalanced data for each loss
in this phase.

D. Phase 4: Evolution of Latent Feature Distribution

The multivariate GM distribution of the latent features is
evolved for better quality and diversity in Phase 4, and the
speciﬁc details are depicted in Fig. 5. The input is formed by
randomly sampling from the current GMM N (Minit, Σinit)
and is ﬁrstly passed through the latent feature classiﬁer. Then
the correctly classiﬁed ones are kept and denoted by ‘GM 1’,
where the coloured part indicates the correct ones while the
wrong part turns grey. Next, the correct is decoded to the
reconstructed images, denoted as Xsyn, and the images clas-
siﬁed correctly are reserved and named X quali
syn . To this point,
X quali
is considered to be high-quality images, meaning that
syn
they can be easily identiﬁed by the human eye or recognized
by an image classiﬁer.

However, the diversity of the generated images can not be
ensured, which may cause an overﬁtting problem for classi-
ﬁers. A ﬁtness function is designed based on the similarities
among samples to increase the diversity by selecting the
diverse generations. The similarities are calculated by the av-
erage hash algorithm (AHA) [28] between X quali
syn and the real
samples Xreal randomly selected from the imbalanced data:
(1) compute the hash values for all the pairs of samples, with
each pair consisting of one synthesized image and one real
image; (2) compare the hash values to get the similarities; (3)
Sort the similarities and select the corresponding synthesized
samples with the lowest similarities based on selection rate as
superior individuals, named X diver
syn .
To guide the evolution direction to better diversity based on
the high quality, the corresponding latent features of X quali
and X diver
are found and noted by ‘GM 2’ and ‘Spop’ as
shown in Fig. 5. Compared with the traditional EDAs, the
distribution of the current
latent features is replaced with
that of ‘GM 2’ when evolving to guarantee the quality of
synthesized samples. Simultaneously, ‘Spop’ contributes to
optimizing the latent feature distribution to be more diverse.
Therefore, the MEDA updates the GM distribution by:

syn

syn

µk crt = γµk quali + (1 − γ)µk diver
σ2
k crt = γσ2

k quali + (1 − γ)σ2

k diver

(25)

(26)

where µk crt and σ2
k crt calculate the mean and the covariance
of the latest Gaussian distribution for the latent features
in class k. µk quali and σ2
k quali denote the mean and the
covariance of class k in ‘GM 2’, respectively, while µk diver
and σ2
k diver are those of class k in ‘Spop’. γ represents the
weighting coefﬁcients.

Each update is done, the latent features are re-sampled from
the current GM distribution, and the steps above are repeated
until the termination condition is met.

E. Program of Four Phases

Fig. 3. Phase 2: the decoder and the image classiﬁer are locally trained.

Lclsimg
is deﬁned as:

2

are calculated. Hence, the total loss Lph2 of this phase

Lph2 =βrec2 ∗ Lrec2 + βclsimg

2

∗ Lclsimg

2

Lrec2 = Lrec2 min + ξrec2 ∗ Lrec2 maj

Lclsimg

2

=Lclsori
Lclssyn

2 min + ξclsori
2 min + ξclssyn

2

2

∗ Lclsori
∗ Lclssyn

2 maj

2 maj

(21)

(22)

(23)

2

where βrec2 and βclsimg
are the corresponding weighting
coefﬁcients. ξrec2 is to adjust the weight between the majority
and the minority samples for reconstruction loss. Both the
real samples and the generated images are sent to the image
classiﬁer for calculating the classiﬁcation loss, with ξclsori
and
ξclssyn
adjusting their weights between the majority and the
2
minority.

2

C. Phase 3: Local Enhancement for Feature Learning

Fig. 4. Phase 3: the encoder and the latent feature classiﬁer are locally trained
in this phase, where the decoder parameters are kept ﬁxed.

The speciﬁc operation of Phase 3 is depicted in Fig. 4.
This phase occurs two kinds of latent features: one is sampled
from the current GMM learned from Phase 1 and treated as
the input of the whole module; another is encoded from the
synthesized images, which are decoded from the input one. To
further optimize the parameters of the encoder and the latent
feature classiﬁer, both the L-GM loss and the classiﬁcation loss
are calculated based on the latter latent features. The total loss
is deﬁned by:

Lph3 = βGM3 ∗ Lm

GM3

+ βclsltt

3

∗ Lclsltt

3

(24)

GM3

and Lclsltt

where Lm
are the L-GM loss and the latent
feature classiﬁcation loss in this phase, βGM3 and βclsltt
are
the corresponding weight coefﬁcients. Since the input data’s

3

3

DecoderImage classifier………………Real samplesℒ𝑟𝑒𝑐𝟐Reconstruction loss: Classification loss: ℒ𝒄𝒍𝒔𝟐𝒊𝒎𝒈Synthesized imagesInputEncoderFixed decoder………………………Latent feature classifierL-GM loss: ℒ𝐺𝑀𝟑𝑚ℒ𝒄𝒍𝒔𝟑𝒍𝒕𝒕Classification loss: Synthesized imagesInputLatent featuresJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

6

Fig. 5. Phase 4: the MEDA evolves the GM distributions of the latent features, where the function f denotes the evolution rule.

Four phases mentioned above are programmed to train the
MEDA LUDE algorithm, and the pseudocode is shown in
Algorithm 1.

In Algorithm 1, the input of the MEDA LUDE is composed
of the majority samples Xmaj and the minority samples Xmin,
namely X = {Xmaj, Xmin}. Their corresponding labels are
denoted as Y = {Ymaj, Ymin}. The model parameters of
the encoder, the decoder, the latent feature classiﬁer, and the
image classiﬁer are signiﬁed as θen, θde, θcls ltt, and θcls img,
respectively.

IV. EXPERIMENTS

This section evaluates the proposed MEDA LUDE al-
gorithm on the imbalanced datasets
randomly formed
the
from MNIST and CIFAR-10 datasets. Furthermore,
MEDA LUDE is also applied to the industrial ﬁeld and has
achieved signiﬁcant success. The experiments are implemented
with NVIDIA RTX 2080Ti, 64 GB RAM, Intel(R) Xeon(R)
Silver 4114 CPU, Ubuntu 18.04.5 LTS, Pytorch 1.7.0.

Besides, Algorithm 1 makes use of the follow functions in

A. Evaluation on Benchmark-based Imbalanced Datasets

Phase 4:

• Sample(distribution): sample from ‘distribution’ to

generate population.

• Classif y Ltt(ltt, para): classify latent features ‘ltt’ by
latent feature classiﬁer with model parameters ‘para’.

• Select Correct(data, label1, label2):

the cor-
rectly classiﬁed ‘data’ according to the classiﬁcation
results ‘label1’ and the real labels ‘label2’.

select

• Decode(latentf eature, para): decode ‘latentf eature’
to synthesized images by decoder with model parameters
‘para’.

• Classif y Img(img, para): classify ‘img’ by image

classiﬁer with model parameters ‘para’.

• Cal F itness(data1, data2, algorithm): calculate ﬁt-

ness of ‘data1’ based on ‘data2’ by ‘algorithm’.

• Evaluate Select(data, f itness): evaluate ‘data’ based

on ‘f itness’ and select promising solutions.

• F ind Ltt(data): ﬁnd corresponding latent features of

‘data’.

• Cal Gaussian(data): give Gaussian distribution of

‘data’.

• Evolve(mean1, mean2, cov1, cov2): evolve Gaussian
distribution based on ‘mean1’, ‘mean2’, ‘cov1’, ‘cov2’
to the update distribution N (meancrt, covcrt) by:

meancrt = γmean1 + (1 − γ)mean2

covcrt = γcov1 + (1 − γ)cov2

(27)

(28)

where γ is the coefﬁcient in Eq. (25) and Eq. (26).

In Phase 4, labelltt and labelimg denote the real labels of
F EAT4 and Xsyn, respectively.

Two random seeds are set for each benchmark dataset
to allocate the categories of the majority samples and the
minority samples.

For the MNIST dataset, the handwritten digits from 0 to
9 are ﬁrst symbolized with numbers from 0 to 9. Then we
randomly select ﬁve numbers as the minority classes with
the random seed function in the NumPy library for Python
programming language. The seeds are set to be 0 and 5,
respectively, where the minority classes’ numbers are 2, 8,
4, 9, 1 when the seed is 0, and are 9, 5, 2, 4, 7 when
the seed is 5 accordingly. The two imbalanced datasets built
from the MNIST dataset are both split into the training and
validation sets. The training set contains 50 samples for each
minority class and 5000 examples for each majority class.
The validation set includes 4000 samples uniformly distributed
within ten categories, and the test set is the same as that
of the original MNIST dataset. Hence, the MEDA LUDE is
ﬁnally experimented on two randomly formed datasets with
an imbalanced ratio [29] being 100.

For the CIFAR-10 dataset, the categories of the airplane,
automobile, bird, cat, deer, dog, frog, horse, ship, and truck
are marked with numbers 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9,
accordingly. Here, the random seeds are set to be 1 and 7,
corresponding to the minority classes being bird, truck, frog,
deer, airplane, and ship, dog, airplane, bird, and automobile,
respectively. From the original training set of the CIFAR-10
dataset, 45 and 4500 examples are selected for each minority
class and each majority class, respectively, constituting im-
balanced datasets with an imbalanced ratio of 100 under two
different circumstances. Among the remaining samples of the
training set, 400 samples are chosen randomly for each class

Image classifierDecoderLatent feature classifier…………………………………………AHA……Spop𝑵𝝁𝟏_𝒅𝒊𝒗𝒆𝒓,𝝈𝟏_𝒅𝒊𝒗𝒆𝒓𝟐𝑵𝝁𝟐_𝒅𝒊𝒗𝒆𝒓,𝝈𝟐_𝒅𝒊𝒗𝒆𝒓𝟐𝑵𝝁𝟑_𝒅𝒊𝒗𝒆𝒓,𝝈𝟑_𝒅𝒊𝒗𝒆𝒓𝟐𝑵𝝁𝟒_𝒅𝒊𝒗𝒆𝒓,𝝈𝟒_𝒅𝒊𝒗𝒆𝒓𝟐𝑵𝝁𝑲_𝒅𝒊𝒗𝒆𝒓,𝝈𝑲_𝒅𝒊𝒗𝒆𝒓𝟐…𝑵𝝁𝟏_𝒒𝒖𝒂𝒍𝒊,𝝈𝟏_𝒒𝒖𝒂𝒍𝒊𝟐𝑵𝝁𝟐_𝒒𝒖𝒂𝒍𝒊,𝝈𝟐_𝒒𝒖𝒂𝒍𝒊𝟐𝑵𝝁𝟑_𝒒𝒖𝒂𝒍𝒊,𝝈𝟑_𝒒𝒖𝒂𝒍𝒊𝟐𝑵𝝁𝟒_𝒒𝒖𝒂𝒍𝒊,𝝈𝟒_𝒒𝒖𝒂𝒍𝒊𝟐𝑵𝝁𝑲_𝒒𝒖𝒂𝒍𝒊,𝝈𝑲_𝒒𝒖𝒂𝒍𝒊𝟐…𝝁𝒌_𝒄𝒓𝒕,=𝒇(𝝁𝒌_𝒒𝒖𝒂𝒍𝒊,,𝝁𝒌_𝒅𝒊𝒗𝒆𝒓,)𝝈𝒌_𝒄𝒓𝒕𝟐=𝒇(𝝈𝒌_𝒒𝒖𝒂𝒍𝒊𝟐𝝈𝒌_𝒅𝒊𝒗𝒆𝒓𝟐)Real samplesKeep the correctKeep the correctGet the corresponding latent featuresUpdate until terminationInputGM_1………………Get the corresponding latent featuresEvaluateand selectGM_2Synthesized images 𝑿𝒔𝒚𝒏𝒒𝒖𝒂𝒍𝒊𝑿𝒔𝒚𝒏𝒅𝒊𝒗𝒆𝒓……𝑿𝒔𝒚𝒏𝑿𝒓𝒆𝒂𝒍𝑵(𝑴𝒊𝒏𝒊𝒕,𝜮𝒊𝒏𝒊𝒕)JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

7

Algorithm 1. MEDA LUDE training procedure

Input: X = {Xmaj, Xmin},Y = {Ymaj, Ymin}
Output: θde, Mopti, Σopti

, Lclsltt

1

, and Lclsimg

1

1: /*Phase 1*/
2: while not converged do
3:

for each mini-batch data do
update θen with Lrec1 , Lm
GM1
update θde with Lrec1, Lclsimg
update θcls ltt with Lclsltt
update θcls img with Lclsimg
update M , Σ with Lm

1

1

1

GM1

end for
9:
10: end while
11: Minit = M , Σinit = Σ

12: for number of training iterations do
13:

/*Phase 2*/
while not converged do

for each mini-batch data do

update θde with Lrec2 , Lclsimg
update θcls img with Lclsimg

2

2

end for
end while

/*Phase 3*/
while not converged do

for each mini-batch data do

update θen with Lm
update θcls ltt with Lclsltt

GM3

, Lclsltt

3

3

end for

4:

5:

6:

7:

8:

14:
15:
16:

17:

18:

19:

20:
21:
22:
23:

24:
25:

26:

27:
28:
29:

30:

31:

32:

33:

34:

35:

36:

37:

38:

39:

40:

end while

/*Phase 4*/
F EAT4 = Sample(N (Minit, Σinit))
while halting condition is not met do

(cid:91)labelltt = Classif y Ltt(F EAT4, θcls ltt)
GM 1 = Select Correct(F EAT4, (cid:91)labelltt, labelltt)

Xsyn = Decode(GM 1, θde)
(cid:91)labelimg = Classif y Img(Xsyn, θcls img)
X quali

syn = Select Correct(Xsyn, (cid:91)labelimg, labelimg)

syn , Xreal, AHA)
syn , f itness)

syn = Evaluate Select(X quali

f itness = Cal F itness(X quali
X diver
GM 2 = F ind Ltt(X quali
syn )
Spop = F ind Ltt(X diver
syn )
N (µk quali, σ2
N (µk diver, σ2
N (µk crt, σ2
σ2
k qauli, σ2
Mcrt = [µ1 crt; µ2 crt . . . ; µk crt]
Σcrt = [σ2
k crt]
F EAT4 = Sample(N (Mcrt, Σcrt))

k qauli) = Cal Gaussian(GM 2)
k diver) = Cal Gaussian(Spop)
k crt) = Evolve(µk quali, µk diver,
k diver)

2 crt . . . ; σ2

1 crt; σ2

41:
end while
42:
43: Mopti = Mcrt
Σopti = Σcrt
44:
45: end for

46: return θde, Mopti, Σopti

to form a validation set. The test set is the original one of the
CIFAR-10 dataset.

To validate the effectiveness of our proposed method, all
the methods ﬁrst synthesize samples to construct the balanced
dataset based on the imbalanced training set. Then the ﬁnal
classiﬁer is trained on the balanced training set and tested
to achieve the ﬁnal classiﬁcation performance. The closer the
constructed balanced training data’s distribution is to the real
data’s, the better the ﬁnal classiﬁcation performance will be.
The classiﬁcation performance on imbalanced MNIST and
CIFAR-10 datasets are shown in TABLE I and TABLE II,
respectively. In TABLE I, the MEDA LUDE algorithm ob-
tains the optimal results on various indexes under two random
seeds among all the comparative methods, indicating that the
samples generated by our method are superior to its com-
petitors in quality-diversity trade-off and hence contributes to
training the classiﬁer. On the CIFAR-10 dataset, the proposed
MEDA LUDE method shows the competitive classiﬁcation
performance, except that the best value for criterion ‘AUC’ is
obtained by the CVAE SeTred method when the random seed
is 7. To conclude, the optimization phases we design for the
latent feature distribution and the whole neural networks are
efﬁcacious to trade off the quality and diversity of synthesized

samples.

The generated minority samples for the MNIST dataset
are visualized with t-SNE [30], as depicted in Fig. 6. The
‘Original’ gives the distribution of the real minority data,
the distribution of the minority
and the others represent
samples synthesized by their corresponding method, where
the ‘MEDA LUDE’ exhibits the generated data’s distribution
when the random seed is 5. Since ADASYN, SMOTE, and
ROS provide a balanced training set directly, the generated
samples need to be chosen randomly from the minorities of
the balanced set with a certain amount. As Fig. 6 shows, the
distribution of samples synthesized by ‘ROS’ is a disorder
without distinct boundaries, and the distribution corresponding
to ‘RMR’ is far from the original distribution. In contrast,
the distributions from ‘ADASYN’ and ‘SMOTE’ are relatively
reasonable but appear locally aggregated and integrally sparse.
Compared with ‘ADASYN’ and ‘SMOTE’, the minority sam-
ples generated from three generative models, namely ‘CVAE’,
‘CVAE SeTred’, and ‘MEDA LUDE’, are evenly distributed
for each class, which accord with the original samples better.
Obviously, the distribution learned from ‘CVAE’ is the most
limited, and the second is that of ‘CVAE SeTred’. With
the same amount of the minority examples, our proposed

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

8

TABLE I
CLASSIFICATION PERFORMANCE OF THE COMPARATIVE METHODS FOR MNIST

Seed

RMR

ROS

SMOTE

ADASYN CVAE

0
5
0
5
0
5
0
5
0
5
0
5
0
5

93.89
92.28
94.20
93.07
93.89
92.28
99.30
99.14
93.81
92.21
96.49
95.54
0.9932
0.9937

94.63
93.08
94.95
93.81
94.63
93.08
99.41
99.24
94.58
93.05
96.94
96.02
0.9954
0.9946

94.67
94.19
94.94
94.33
94.67
94.19
99.41
99.36
94.60
94.14
96.96
96.70
0.9958
0.9941

95.31
93.48
95.45
93.86
95.31
93.48
99.48
99.27
95.28
93.42
97.35
96.27
0.9936
0.9946

95.37
95.07
95.57
95.35
95.37
95.07
99.48
99.45
95.33
95.05
97.37
97.20
0.9962
0.9953

CVAE
SeTred
95.58
95.44
95.81
95.62
95.58
95.44
99.51
99.49
95.56
95.42
97.50
97.42
0.9961
0.9953

TABLE II
CLASSIFICATION PERFORMANCE OF THE COMPARATIVE METHODS FOR CIFAR10

Seed

RMR

ROS

SMOTE

ADASYN CVAE

1
7
1
7
1
7
1
7
1
7
1
7
1
7

48.78
48.61
60.49
60.52
48.78
48.61
94.31
94.29
41.12
45.52
60.02
62.67
0.8121
0.7889

49.15
49.18
63.02
66.17
49.15
49.18
94.35
94.35
41.72
42.77
60.22
60.01
0.7985
0.7814

50.35
49.43
59.61
64.54
50.35
49.43
94.48
94.38
45.87
43.01
64.02
60.92
0.7972
0.7877

50.94
50.26
62.58
64.34
50.94
50.26
94.55
94.47
44.97
40.94
63.84
57.90
0.8295
0.7914

51.06
51.10
61.35
61.27
51.06
51.10
94.56
94.57
43.12
45.89
61.73
63.86
0.7990
0.8052

CVAE
SeTred
51.36
52.22
61.10
64.17
61.36
52.22
94.60
94.69
46.00
45.46
64.67
62.27
0.8212
0.8129

MEDA
LUDE
95.88
95.49
96.05
95.67
95.88
95.49
99.55
99.49
95.86
95.46
97.67
97.44
0.9966
0.9961

MEDA
LUDE
52.65
52.96
63.42
66.85
52.65
52.96
94.74
94.77
47.04
47.35
64.70
63.94
0.8406
0.8094

Evaluation
Critieria
Accuracy
(%)
Precision
(%)
Recall
(%)
Speciﬁcity
(%)
F1
(%)
GM
(%)
AUC

Evaluation
Critieria
Accuracy
(%)
Precision
(%)
Recall
(%)
Speciﬁcity
(%)
F1
(%)
GM
(%)
AUC

‘MEDA LUDE’ has learned more broad distribution, validat-
ing the better diversity of our synthesized samples indirectly.

balanced data the MEDA LUDE constructs improves a lot.

In addition to the synthesized minority samples, we also
visualize the features output from the last fully connected layer
of the ﬁnal classiﬁer, which is trained on the balanced data
formed by various methods. It should be noted that the visu-
alized features correspond to the inputs of the test set instead
of the training data. The visualizations are depicted in Fig. 7,
where the ‘Balanced data’ describes the feature distributions
mapped from the test data by the classiﬁers trained on the
original balanced training data. Different from the distributions
visualized from the generated samples, the closer the points of
the same class are, and the clearer the clusters’ boundaries of
the different classes appear, the higher probability the samples
are classiﬁed correctly with. Compared with the ‘Balanced
data’, the clusters of the different classes visualized from the
other methods have obvious overlaps, which denotes the place
where samples are classiﬁed wrongly. Among all of these
synthetic methods, the overlaps of the ‘MEDA LUDE’ are
relatively less, and the boundaries of different categories are
more apparent. In view of this, our proposed MEDA LUDE
algorithm can generate samples whose distributions are closer
to the real samples than the comparative methods. As a result,
the classiﬁcation performance of the classiﬁer trained on the

B. Industrial Application with Real-world Datasets

The MEDA LUDE algorithm is also applied to the indus-
trial ﬁeld successfully. In the textile production process, fabric
defect classiﬁcation is critical to control the textile quality.
However, during the real-world data acquisition, imbalanced
problems are common due to the factor of production equip-
ment and the characteristics of fabric defects, which sharply
weaken the classiﬁcation performance and signiﬁcantly inﬂu-
ence the fabric quality. To solve the imbalanced classiﬁcation
of fabric defects in practical industrial applications, we ﬁrstly
collect and process fabric defect data and then construct fabric
defect datasets: DHU-FD and ALIYUN-FD.

For DHU-FD,

the fabric defect data is collected from
Donghua University (DHU) based on the hardware acquisition
device, including two CCD cameras, a network connector,
lighting facility, computer, operation interface, detection con-
troller, and textile materials. The acquisition device is shown
in Fig. 8, where the right-bottom corner gives examples of
raw fabric textiles labelled as normal and oil stains. The
original DHU textile images are in 1280 ∗ 1024 pixels. Then
the acquired data is processed with Adobe Photoshop CS6
by intercepting the defected part of uniﬁed pixels, and each

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

9

t-SNE visualizations of the generated minority samples for MNIST

Fig. 7.

t-SNE visualizations of the features for MNIST dataset

Fig. 6.
dataset

intercepted image only contains one type of defect. These
images are labelled according to the characteristic descriptions
of fabric defects. Finally, the DHU-FD dataset is constructed
with ten classes, and each class contains 100 samples of size
220 ∗ 220. Types in the sequence of ‘Normal’, ‘Mispick’,
‘Broken picks’, ‘Double ﬂat’, ‘Slub’, ‘Felter’, ‘Draw-back’,
‘Sundries’, ‘Broken end’, and ‘Oil stains’ are numbered from
0 to 9, respectively. Examples, labels, and numbers for ten
types of fabric defects are given in Fig. 9.

In addition to the DHU data, we also download fabric image
data that is public online in the Tianchi competition sponsored
by Alibaba. The size of the original fabric data is 2560 ∗ 1920
pixels. After the same operations in processing raw images,
the ALIYUN-FD dataset is constructed, including six types,
with each keeping 1500 samples. Images in the ALIYUN-
FD dataset are in 220 ∗ 220 pixels. Labels in the order of
Normal’, ‘Broken end’, ‘Hole’, ‘Stain’, ‘Crack’, and ‘Felter’
are sequentially numbered from 0 to 5. The speciﬁc details of
ALIYUN-FD examples are shown in Fig. 10.

For both the DHU-FD dataset and the ALIYUN-FD dataset,
two random seeds are set to determine minority classes. For
the DHU-FD dataset, the random seeds are set to 1 and 3
to select ﬁve classes as the minority categories from all ten
types. The corresponding minority types are ‘Broken picks’,
‘Oil stains’, ‘Draw-back’, ‘Slub’, ‘Normal’ when the seed is
1, and being ‘Felter’, ‘Slub’, ‘Mispick’, ‘Broken picks’, ‘Oil
stains’ when the seed is 3. In the randomly formed imbalanced

Fig. 8. Hardware acquisition device and raw textile image examples

Fig. 9. Examples and numbers for DHU-FD

Fig. 10. Examples and numbers for ALIYUN-FD

OriginalMEDA_LUDECVAE_SeTredCVAEADASYNSMOTEROSRMRBalanced DataMEDA_LUDECVAE_SeTredCVAEADASYNSMOTEROSRMRCCDCameraLighting FacilityNetwork ConnectorComputerDetectionControllerTextile MaterialsOperation InterfaceOilStainsNormalNormalMispickBrokenpicksDoubleflatSlubFelterDraw-backSundriesBrokenendOilstainsNumber: 0Number: 1Number: 2Number: 3Number: 4Number: 5Number: 6Number: 7Number: 8Number: 9NormalNumber: 0Broken endNumber: 1HoleNumber: 2StainNumber: 3CrackNumber: 4FelterNumber: 5JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

10

DHU-FD dataset, each minority class contains 6 samples,
while each majority class has 60 ones in the training set. The
validation and test sets include 200 images evenly distributed
among ten classes. For the ALIYUN-FD dataset, the random
seeds are 0 and 1. Correspondingly, seed 0 selects ‘Felter’,
‘Hole’, and ‘Broken end’ as the minority classes, while seed
1 chooses ‘Hole’, ‘Broken end’, and ‘Crack’ as the minority
types. The training set comprises of 270 minority samples and
2700 majority samples, where the imbalance ratio is 10. In the
validation set, 300 images are included in each class, and the
same goes for the test set.

To observe the situation of training the MEDA LUDE
algorithm in large-size images, the training loss curves varying
iterations are plotted for Phase 1, Phase 2, and Phase 3, since
Phases 1-3 are responsible for training models, while Phase
4 aims at evolving latent features. The Adam optimizer is
adopted, and the activation function is ReLU. In Phase 1,
the whole model is ﬁrstly trained, including the encoder, the
decoder, the latent feature classiﬁer, and the image classiﬁer.
Hence the total loss consists of reconstruction loss, L-GM
loss, latent feature classiﬁcation loss, and image classiﬁcation
loss, as depicted in Fig.11. It can be seen that all the losses
in Phase 1 occur rhythmic abrupt changes and ﬂuctuations,
which varying learning rates may cause. Nevertheless, all the
losses decrease as the iteration increases until they ﬁnally
converge. Since the convergence of the reconstruction loss is
not apparent when all the losses are included in one picture, the
reconstruction loss is enlarged in the blank space for further
observation, as shown in the red dashed frame in Fig. 11.
It is clear that the reconstruction loss gradually converges
during continuous iterations. In Phase 2, our goal is to train the
decoder and the image classiﬁer. Hence the total loss for Phase
2 is composed of reconstruction loss and image classiﬁcation
loss, as shown in Fig. 12. The image classiﬁcation loss and the
total loss exhibit downward trends on the whole and ﬁnally
converge. Compared with Phase 1, the training process of this
Phase ﬂuctuates less and is more stable. The reconstruction
loss is enlarged again in the blank place of this chart for
further study. From the curve in the red dashed square frame,
it is found that the reconstruction loss rises at the beginning,
then decreases, and ﬁnally levels off. This phenomenon is
probably due to the calculation method for the reconstruction
loss. In Phase 1, the reconstruction loss is calculated based
on the input image and the reconstructed image, which is
obtained by decoding the latent feature encoded from the
input image. Different from Phase 1, Phase 2 ﬁrstly samples
from the latent variables’ distribution trained in Phase 1 and
then decodes the sampling point to get the synthesized image.
Finally, the loss is calculated between the synthesized image
and the real sample, which is randomly chosen. Hence, the
generated images in Phase 2 are not the real reconstructed
images for the input images but the generations from the
latent features. Furthermore, the random sampling points have
more possibilities, leading to the corresponding changes in
generated samples. Therefore, the reconstruction loss exceeds
a relearning process instead of continuing to converge based
on the previous loss. In Phase 3, the MEDA LUDE aims
at training the encoder and the latent feature classiﬁer, and

the total loss includes the L-GM loss and the latent feature
classiﬁcation loss. We can conclude from Fig. 13 that all
the losses decrease stably until ﬁnal convergence. To sum
up, the training process in Phases 1-3 fully showcases the
stability and the robustness of the MEDA LUDE model in
high-dimensional images.

Fig. 11. Losses in Phase 1 for DHU-FD dataset

Fig. 12. Losses in Phase 2 for DHU-FD dataset

Fig. 13. Losses in Phase 3 for DHU-FD dataset

The experimental results in DHU-FD dataset and ALIYUN-
FD dataset are exhibited in TABLE III and TABLE IV,
respectively. In TABLE III, the best accuracies under both the
two random circumstances are achieved by the MEDA LUDE
algorithm, and both of them are far superior to their respective
suboptimal accuracies. Except for the precision of seed 1 and
the AUC of seed 3, the MEDA LUDE algorithm outperforms
all the other comparative methods in various criteria under
two different imbalanced datasets randomly formed, which
validates the effectiveness of the proposed method in handling
the imbalanced problem for fabric defects from DHU. For the
ALIYUN-FD dataset, the proposed MEDA LUDE algorithm
obtains the best results in all the indicators apart from the
index AUC. When the random seed is 0, the most outstanding

02004006008001000Iteration0123456Loss ValueTotal LossLGM LossLtt Classification LossJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

11

TABLE III
CLASSIFICATION PERFORMANCE OF THE COMPARATIVE METHODS FOR DHU-FD

Seed

RMR

ROS

SMOTE

ADASYN CVAE

1
3
1
3
1
3
1
3
1
3
1
3
1
3

63.50
63.50
69.38
69.38
63.50
63.50
95.94
95.94
56.92
56.92
70.63
70.63
0.9444
0.9444

66.00
70.50
75.56
75.98
66.00
70.50
96.22
96.72
62.42
68.93
75.69
81.03
0.9032
0.9625

70.00
71.00
69.36
71.71
70.00
71.00
96.67
96.78
68.59
67.54
80.93
77.34
0.9439
0.9421

69.00
73.00
67.00
75.11
69.00
73.00
96.56
97.00
65.44
71.21
78.21
79.15
0.9375
0.9270

70.00
73.50
78.02
74.29
70.00
73.50
96.67
97.06
67.60
71.41
79.83
79.49
0.9538
0.9352

CVAE
SeTred
71.00
74.00
79.44
75.46
71.00
74.00
96.78
97.11
67.89
72.76
79.21
82.21
0.9560
0.9391

TABLE IV
CLASSIFICATION PERFORMANCE OF THE COMPARATIVE METHODS FOR ALYUN-FD

Seed

RMR

ROS

SMOTE

ADASYN CVAE

0
1
0
1
0
1
0
1
0
1
0
1
0
1

56.72
58.72
66.34
64.83
56.72
58.72
91.34
91.74
51.72
54.56
67.58
69.92
0.8671
0.8714

59.06
58.17
66.35
64.21
59.06
58.17
91.81
91.63
56.19
55.63
70.87
70.63
0.8488
0.8440

59.83
58.50
65.60
65.82
59.83
58.50
91.97
91.70
58.34
56.08
72.49
70.73
0.8418
0.8359

60.11
58.56
64.28
62.79
60.11
58.56
92.02
91.71
57.69
55.56
72.30
70.75
0.8473
0.8380

60.28
58.72
65.47
65.21
60.28
58.72
92.06
91.74
57.61
55.39
72.07
70.43
0.8474
0.8695

CVAE
SeTred
61.00
60.00
66.91
65.20
61.00
60.00
92.20
92.00
58.28
57.39
72.58
72.06
0.8473
0.8389

MEDA
LUDE
74.00
76.00
79.11
79.09
74.00
76.00
97.11
97.33
74.28
73.98
84.13
83.31
0.9603
0.9371

MEDA
LUDE
62.06
60.94
66.94
66.03
62.06
60.94
92.41
92.19
59.54
58.16
73.49
72.59
0.8569
0.8444

Evaluation
Critieria
Accuracy
(%)
Precision
(%)
Recall
(%)
Speciﬁcity
(%)
F1
(%)
GM
(%)
AUC

Evaluation
Critieria
Accuracy
(%)
Precision
(%)
Recall
(%)
Speciﬁcity
(%)
F1
(%)
GM
(%)
AUC

value for AUC is acquired by RMR, and our method’s AUC
is second only to RMR’s. However, the accuracy of RMR is
only 56.72%, which is far smaller than ours, and the other
indicators between RMR and the MEDA LUDE method still
exist gaps. When the random seed is set to 1, even though
the MEDA LUDE doesn’t get the best AUC, it still exposes
the excellent classiﬁcation performance in the other criteria.
Since the test set is balanced, according to the classiﬁcation
results presented above, it has proved that the MEDA LUDE
algorithm can be applied successfully to the imbalanced clas-
siﬁcation task for fabric defects but still has room for further
improvement.

V. CONCLUSION
In this paper, a new algorithm called MEDA LUDE is
designed for trading off the quality and the diversity of
generated samples in imbalanced image classiﬁcation tasks.
The proposed method combines deep neural networks and
modiﬁed EDAs to optimize and evolve latent feature distri-
butions jointly. Besides, the L-GM loss function is introduced
to feature learning under a more complex assumption. The
EDAs are improved to guide the searching space for better
quality and diversity. Classiﬁcation performance on the two
imbalanced datasets constructed from MNIST and CIFAR-
10 datasets and the t-SNE visualizations indicate the efﬁcacy

of our method in generating samples with both the quality
and the diversity. Last, the success of applications in fabric
defect classiﬁcation shows the potential of the MEDA LUDE
algorithm in solving imbalanced problems in the industry.

ACKNOWLEDGMENT

This work was supported in part by the Fundamental
Research Funds for
the Central Universities (2232021A-
10, 2232021D-37), National Natural Science Foundation of
China (61903078), Shanghai Sailing Program (22YF1401300),
Natural Science Foundation of Shanghai
(20ZR1400400,
21ZR1401700), and Chinese Ministry of Education Research
Found on Intelligent Manufacturing (MCM20180703).

REFERENCES

[1] X. Zhang, Y. Zhuang, W. Wang, and W. Pedrycz, “Trans-
fer boosting with synthetic instances for class imbalanced
object recognition,” IEEE Transactions on Cybernetics,
vol. 48, no. 1, pp. 357–370, 2016.

[2] Z. Zhu, Z. Wang, D. Li, Y. Zhu, and W. Du, “Geometric
structural ensemble learning for imbalanced problems,”
IEEE Transactions on Cybernetics, vol. 50, no. 4, pp.
1617–1629, 2020.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

12

[3] A. Rosales-P´erez, S. Garc´ıa, and F. Herrera, “Han-
dling imbalanced classiﬁcation problems with sup-
port vector machines via evolutionary bilevel opti-
mization,” IEEE Transactions on Cybernetics, 2022,
doi:10.1109/TCYB.2022.3163974.

[4] A. Liu, J. Ghosh, and C. E. Martin, “Generative oversam-
pling for mining imbalanced datasets.” in DMIN, 2007,
pp. 66–72.

[5] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P.
Kegelmeyer, “Smote: synthetic minority over-sampling
technique,” Journal of Artiﬁcial Intelligence Research,
vol. 16, pp. 321–357, 2002.

[6] H. Han, W.-Y. Wang, and B.-H. Mao, “Borderline-
smote: a new over-sampling method in imbalanced data
sets learning,” in International Conference on Intelligent
Computing. Springer, 2005, pp. 878–887.

[7] H. He, Y. Bai, E. A. Garcia, and S. Li, “Adasyn: Adaptive
synthetic sampling approach for imbalanced learning,”
in 2008 IEEE International Joint Conference on Neu-
ral Networks (IEEE World Congress on Computational
Intelligence).
[8] S. Barua, M. M.

Islam, X. Yao, and K. Murase,
“Mwmote–majority weighted minority oversampling
technique for imbalanced data set learning,” IEEE Trans-
actions on Knowledge and Data Engineering, vol. 26,
no. 2, pp. 405–425, 2012.

IEEE, 2008, pp. 1322–1328.

[9] J. Chen, L. Du, and L. Liao, “Discriminative mixture
variational autoencoder for semisupervised classiﬁca-
tion,” IEEE Transactions on Cybernetics, pp. 1–15, 2020.
[10] Z. Wan, Y. Zhang, and H. He, “Variational autoencoder
based synthetic data generation for imbalanced learning,”
in 2017 IEEE Symposium Series on Computational In-
telligence (SSCI).

IEEE, 2017, pp. 1–7.

[11] W. Dai, K. Ng, K. Severson, W. Huang, F. Anderson, and
C. Stultz, “Generative oversampling with a contrastive
variational autoencoder,” in 2019 IEEE International
Conference on Data Mining (ICDM).
IEEE, 2019, pp.
101–109.

[12] J. Lim, S. Ryu, J. W. Kim, and W. Y. Kim, “Molec-
ular generative model based on conditional variational
autoencoder for de novo molecular design,” Journal of
Cheminformatics, vol. 10, no. 1, pp. 1–9, 2018.

[13] Y. Yang, C. Malaviya, J. Fernandez, S. Swayamdipta,
R. L. Bras, J.-P. Wang, C. Bhagavatula, Y. Choi, and
D. Downey, “Generative data augmentation for com-
monsense reasoning,” arXiv preprint arXiv:2004.11546,
2020.

[14] S. Du, J. Hong, Y. Wang, and Y. Qi, “A high-quality
multicategory sar images generation method with mul-
ticonstraint gan for atr,” IEEE Geoscience and Remote
Sensing Letters, vol. 19, pp. 1–5, 2022.

[15] C. Yang, Y. Shen, Y. Xu, and B. Zhou, “Data-efﬁcient
instance generation from instance discrimination,” arXiv
preprint arXiv:2106.04566, 2021.

[16] V. Costa, N. Lourenc¸o, J. Correia, and P. Machado, “Ex-
ploring the evolution of gans through quality diversity,”
in Proceedings of the 2020 Genetic and Evolutionary
Computation Conference, 2020, pp. 297–305.

[17] D. Alihosseini, E. Montahaei, and M. S. Baghshah,
“Jointly measuring diversity and quality in text gener-
ation models,” in Proceedings of the Workshop on Meth-
ods for Optimizing and Evaluating Neural Language
Generation, 2019, pp. 90–98.

[18] J. Li, Y. Lan, J. Guo, and X. Cheng, “On the relation be-
tween quality-diversity evaluation and distribution-ﬁtting
goal in text generation,” in International Conference on
Machine Learning. PMLR, 2020, pp. 5905–5915.
[19] P. Bontrager, A. Roy, J. Togelius, N. Memon, and
A. Ross, “Deepmasterprints: Generating masterprints for
dictionary attacks via latent variable evolution,” in 2018
IEEE 9th International Conference on Biometrics The-
ory, Applications and Systems (BTAS).
IEEE, 2018, pp.
1–9.

[20] V. Volz, J. Schrum, J. Liu, S. M. Lucas, A. Smith, and
S. Risi, “Evolving mario levels in the latent space of
a deep convolutional generative adversarial network,” in
Proceedings of the Genetic and Evolutionary Computa-
tion Conference, 2018, pp. 221–228.

[21] E. Giacomello, P. L. Lanzi, and D. Loiacono, “Searching
the latent space of a generative adversarial network to
generate doom levels,” in 2019 IEEE Conference on
Games (CoG).
IEEE, 2019, pp. 1–8.

[22] S. Thakkar, C. Cao, L. Wang, T. J. Choi, and J. To-
gelius, “Autoencoder and evolutionary algorithm for level
generation in lode runner,” in 2019 IEEE Conference on
Games (CoG).
IEEE, 2019, pp. 1–4.

[23] S. Zhou and Z. Sun, “A survey on estimation of distribu-
tion algorithms,” Acta Automatica Sinica, vol. 33, no. 2,
p. 113, 2007.

[24] Q. Yang, W.-N. Chen, Y. Li, C. P. Chen, X.-M. Xu,
and J. Zhang, “Multimodal estimation of distribution
algorithms,” IEEE Transactions on Cybernetics, vol. 47,
no. 3, pp. 636–650, 2016.

[25] Y. Liang, Z. Ren, X. Yao, Z. Feng, A. Chen, and W. Guo,
“Enhancing gaussian estimation of distribution algorithm
by exploiting evolution direction with archive,” IEEE
Transactions on Cybernetics, vol. 50, no. 1, pp. 140–152,
2018.

[26] X. et al., “Swarm intelligence optimization based on
estimation of distribution algorithm,” Computer And
Modernization, vol. 000, no. 001, pp. 17–22, 2017.
[27] W. Wan, Y. Zhong, T. Li, and J. Chen, “Rethinking
feature distribution for loss functions in image classi-
ﬁcation,” in Proceedings of
the IEEE Conference on
Computer Vision and Pattern Recognition, 2018, pp.
9117–9126.

[28] L. Weng and B. Preneel, “A secure perceptual hash
algorithm for image content authentication,” in IFIP
International Conference on Communications and Mul-
timedia Security. Springer, 2011, pp. 108–121.

[29] Q. Kang, X. Chen, S. Li, and M. Zhou, “A noise-ﬁltered
under-sampling scheme for imbalanced classiﬁcation,”
IEEE Transactions on Cybernetics, vol. 47, no. 12, pp.
4263–4274, 2016.

[30] L. Van der Maaten and G. Hinton, “Visualizing data using
t-sne.” Journal of Machine Learning Research, vol. 9,

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

13

no. 11, 2008.

