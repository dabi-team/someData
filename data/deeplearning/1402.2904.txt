EPIC: Efﬁcient Prediction of IC Manufacturing Hotspots
With a Uniﬁed Meta-Classiﬁcation Formulation
Duo Ding, Bei Yu, Joydeep Ghosh and David Z. Pan
ECE Dept. Univ. of Texas at Austin, Austin, TX 78712
{ding, bei}@cerc.utexas.edu, {ghosh, dpan}@ece.utexas.edu

4
1
0
2

b
e
F
2
1

]

R
A
.
s
c
[

1
v
4
0
9
2
.
2
0
4
1
:
v
i
X
r
a

ABSTRACT
In this paper we present EPIC, an eﬃcient and eﬀective pre-
dictor for IC manufacturing hotspots in deep sub-wavelength
lithography. EPIC proposes a uniﬁed framework to com-
bine diﬀerent hotspot detection methods together, such as
machine learning and pattern matching, using mathemati-
cal programming/optimization. EPIC algorithm has been
tested on a number of industry benchmarks under advanced
manufacturing conditions. It demonstrates so far the best
capability in selectively combining the desirable features of
various hotspot detection methods (3.5-8.2% accuracy im-
provement) as well as signiﬁcant suppression of the detection
noise (e.g., 80% false-alarm reduction). These characteris-
tics make EPIC very suitable for conducting high perfor-
mance physical veriﬁcation and guiding eﬃcient manufac-
turability friendly physical design.

Categories and Subject Descriptors
B.7.2 [Hardware, Integrated Circuit]: Design Aids

Keywords
Design for Manufacturability, Lithography Hotspots, Meta
Classiﬁcation, Machine Learning, Pattern Matching

1.

INTRODUCTION

Due to the widening gap between the continuous scal-
ing of feature-size and the limited lithography capability [1],
the semiconductor industry is critically challenged in both
IC design and manufacturing. To address these challenges,
design-aware manufacturing and manufacturing-friendly de-
sign techniques have been developed to avoid high variability
design patterns (process hotspots) and to ensure high prod-
uct yield at post Silicon stage. During such processes, print-
ing masks are usually re-targeted and optimized through
powerful resolution enhancement techniques (RETs) such
as Sub-Resolution Assist Features, Optical Proximity Cor-
rection, etc. At the same time, various merging lithog-
raphy technologies are under active research and develop-
ment, including Double (Multiple) Patterning lithography,
E-beam lithography and EUV lithography. However, these
technologies still suﬀer from diﬀerent degrees and types of
printing variabilities, therefore layout dependent lithogra-
phy hotspots remain a challenging issue.

To optimize the masks of a design for better printability,
one approach is to ﬁrst locate the lithography hotspots in a
layout, then ﬁx them in a construct-by-correction manner.
Meanwhile in recent years, CAD methodologies have evolved
to incorporate RET models into early design stages (e.g.,
detailed routing) to avoid lithography-unfriendly patterns

This work is supported in part by NSF, SRC, Oracle and NSFC.
Asia and South Paciﬁc Design Automation Conference (ASPDAC),

Jan. 30 – Feb. 2 2012, Sydney, Australia.

in a correct-by-construction manner [2–6]. Consequently,
fast and accurate lithography hotspot detection becomes a
common and critical issue for a wide range of applications
in both design and manufacturing.

However, the quests for such detection methods have been
critically challenged in many aspects: (1) designs are getting
more complex; (2) under the evolving manufacturing condi-
tions, the number of real hotspots is only a very small frac-
tion of the entire design, making it very diﬃcult to achieve
high detection accuracies and low false-alarms simultane-
ously; (3) detections are seriously run-time constrained due
to short turn-around-time, etc.

Current state-of-the-art hotspot detection methods mainly
fall into 3 categories. (1) lithography simulations are very
accurate but CPU intensive.
(2) Machine learning tech-
niques [7–13] with good noise suppression capability are
still in need of further accuracy improvement. (3) Pattern
matching techniques [14–17] that are very good at detect-
ing pre-characterized hotspot patterns lack the capability to
predict never-before-seen hotspots. This is especially prob-
lematic when new types of designs are involved after the
original pattern library is built.

Recently in [18], a hotspot detection ﬂow was proposed
to hybridize the strengths of machine learning models and
pattern matching models. Such a ﬂow feeds data samples to
a pattern matcher ﬁrst, then employs machine learning clas-
siﬁers to further examine the non-hotspot data set produced
by the pattern matcher. It demonstrates good performance
trade-oﬀ between detection accuracies and false-alarms sup-
pression compared to the previous works. However, its ad-
hoc nature can make the performance ﬁne-tuning and opti-
mization processes very costly.

In order to better address the problem, we propose EPIC :
an eﬃcient meta-classiﬁcation formulation (Fig. 1) to com-
bine various hotspot detection techniques into a uniﬁed and
automated framework that selectively adopts their strengths
and suppresses their drawbacks. Based on the theoretical
framework in Order Statistics [19], we propose a new CAD
ﬂow with diﬀerent types of base classiﬁers and optimize the
ﬂow via constrained quadratic programming.

The rest of the paper is organized as follows.

In Sec-
tion 2 we further motivate the meta-classiﬁcation method-
ology and summarize our main contributions. Section 3 de-
tails the overall CAD ﬂow together with an overview of the

Pattern Matching Methods
Good for detecting previously
known types of hotspots

Machine Learning Methods
Good for detecting new/previously
unknown types of hotspots

A New Unified Formulation
Good for detecting all types of hotspots
with advantageous accuracy/false-alarm
(The Meta-Classifier)

Figure 1: A new uniﬁed formulation for combining
various lithography hotspot detection techniques

 
 
 
 
 
 
partial disappearance

jog round-off

contact round-off

(a)

line-end

(b)

Figure 2: Examples of lithography hotspot patterns

meta-classiﬁer construction. Section 4 gives a brief descrip-
tion of several classes of building-block detection techniques,
followed by Section 5, where these techniques are combined
under the meta-classiﬁer with mathematical programming
and optimization techniques. Section 6 presents the results
and analysis. Section 7 concludes the paper.

2. MOTIVATION AND CONTRIBUTIONS

In the previous section we discussed the need for a sys-
tematic and uniﬁed meta-classiﬁcation methodology to se-
lectively combine certain features of multiple hotspot detec-
tion engines. In this section, we use an example to further
motivate such a meta-classiﬁer.

Fig. 2 presents the printed images of 2 local regions from
certain design at 32nm technology node after applying RETs.
We can make several observations from Fig. 2(a) and (b).
First, there are various types of process hotspots, featur-
ing complex patterns related to line-ends, jogs, corners or
contacts, etc. Second, hotspot patterns suﬀer from diﬀerent
amount of manufacturing variation, which is usually mea-
sured by the Edge Placement Error (EPE). Therefore by
setting diﬀerent EPE thresholds, we can classify lithogra-
phy hotspots into multiple categories. This allows us more
eﬃciency to study the manufacturability and yield eﬀects of
each category. We ﬁrst deﬁne lithography hotspots:

Definition 1. Hotspot: A pattern (or part of a pattern)
in an IC design layout that suﬀers excessive EPE/variation
under lithography printing variation at fabrication stage.

The deﬁnition of lithography hotspots is dependent on the
EPE error tolerance of a design. Excessive EPE can lead to
electrical errors (parasitics variation, timing issues, etc.) or
even logic errors (shorts, opens, etc.). To avoid these issues
and assist design sign-oﬀ and manufacturing closure, lithog-
raphy hotspots should be properly predicted and avoided
during early design stages with short turn-around-time. In
this paper, we use the following two targets to quantitatively
calibrate the prediction performance:

Definition 2. Hotspot Accuracy : The rate of correctly
predicted hotspots among the set of actual hotspots.

This rate characterizes the success rate of hotspot prediction
within the set of actual hotspots. We also use Hit to rep-
resent the actual count of correctly predicted hotspots, or
equivalently, the rate of Hotspot Accuracy percentage wise.

Definition 3. Hotspot False-Alarm: The rate of incor-
rectly predicted non-hotspots over the set of actual hotspots.

i

i

i

and xP M

This rate represents the over-shoots of the prediction, i.e.,
the set of non-hotspots predicted incorrectly as hotspots.
We also use Extra to denote the actual count of such a set, or
equivalently, the rate of Hotspot False-Alarm in percentage.
Next we motivate a meta-classiﬁcation ﬂow to concur-
rently optimize Hit and Extra on top of powerful hotspot
prediction methods. During our prediction process, each
fragment geometry in the layout will be processed and an-
alyzed by multiple hotspot detection engines. Suppose we
input pattern i to a machine learning classiﬁer ML and a pat-
tern matcher PM at the same time and the prediction results
are xM L
, respectively. xM L
takes certain value be-
i
tween -1 (non-hotspot) and +1 (hotspot), while xP M
usu-
ally is either -1 (non-hotspot) or +1 (hotspot). Thus the
simpliﬁed meta-classiﬁcation problem becomes the follow-
ing motivational problem:
Given decisions xM L

and xP M
over the same design
pattern i, decide the ﬁnal hotspot target label T meta
to simultaneously maximize Hotspot Accuracy and
minimize Hotspot False-Alarms.
First, it is easy to see that T meta
are (very close to) +1; T meta

and
i
and xM L
xP M
i
i
are (very close to) -1. Second, in the cases when xM L
and
i
xP M
disagree with each other, we introduce the weighting
i
functions f M L(x) and f P M (x) to adjust the weights and
improve detection performance.
T meta
= ̥meta{xM L
i
If we deﬁne T meta
as in Eqn.(1) above, we can pre-calibrate
the weighting functions with accurate lithography simula-
tions as golden targets. Then we can use the calibrated
functions onto new layout fragments by applying Eqn.(1),
where ̥meta is a threshold cut-oﬀ function deﬁned as fol-
lows,

is +1 if both xM L
i

is -1 if both xP M

· f P M (xP M

· f M L(xM L

) + xP M
i

)} (1)

i

i

i

i

i

i

i

i

i

̥meta(x) =

+1 (hotspot),
−1 (nonhotspot),

if x≥θ
if x<θ

(cid:26)

(2)

Such a formulation combines machine learning and pattern
matching techniques meanwhile preserves generality to cover
both cases, as if f M L(x)=1 and f P M (x)=0, then Eqn.(1)
degenerates into a machine learning classiﬁer ML; similarly
for a pattern matcher PM. Therefore the solution to the
above motivational problem lies in the conﬁguration and op-
timization of the weighting functions such that the overall
hotspot prediction performance exceeds each individual pre-
dictor. Built upon such a motivation, this paper proposes
a systematic CAD ﬂow to construct and optimize a meta-
classiﬁer integrating multiple types of powerful hotspot pre-
diction techniques (known as disparate base classiﬁers). Our
key contributions are as follows,

• We propose for the ﬁrst time a uniﬁed meta-classiﬁer
to seamlessly combine the advantages of various hotspot
detection techniques for enhanced accuracy and re-
duced false-alarms.

• We develop high performance hotspot detection en-
gines as base classiﬁers to leverage state-of-the-art ma-
chine learning and pattern matching techniques.

• We employ Quadratic Programming techniques to achieve
eﬃcient conﬁguration and performance optimization of
the meta-classiﬁer.

• We perform exhaustive assessment on the proposed
method using various industry-strength benchmarks
under advanced RET and manufacturing conditions.

Layout Analyzer

Classifier Development/Calibration

Calibration Results

A Set of 
Training Data

Layout 
Fragmentation

Feature 
Feature 
Vectors
Vectors

Machine Learning
Base Classifiers

GDSII
GDSII
Layouts
Layouts

Context 
Processing

Pattern Matching
Base Classifiers

Meta-Classifier

Base Classifiers

Meta-Classifier

Likelihood Functions

Testing Sets of Data
Testing Sets of Data

Post-Silicon 
Measurement/Debugging

Accurate 
Lithography Simulators
(under RET, e.g.OPC, DP)

(a) Phase1: Calibration

Feature Targets 
(hotspots/non-hotspots)

GDSII
GDSII
GDSII
Layouts
Layouts
Layouts

(b) Phase2: Detection

d
d
e
e
i
i
f
f
i
i
t
t
n
n
e
e
d
d

I
I

s
s
t
t
o
o
p
p
s
s
t
t
o
o
H
H

Meta-Classifier
Application

Layout Analyzer

Layout
Fragmentation

Context 
Processing

Figure 3: The overall CAD ﬂow proposed for hotspot detection based on meta-classiﬁcation formulation

3. META-CLASSIFICATION OVERVIEW

deﬁne the following:

3.1 Overall Flow

Fig. 3 shows the overall ﬂow for calibrating and applying
the meta-classiﬁer. It consists of 2 steps, the calibration and
the detection phases. Before going into details, we introduce
the following key components of the proposed ﬂow.

Definition 4. Base Classiﬁer : An individual hotspot clas-
siﬁer that is optimized under certain performance metric,
such as detection accuracy, or false-alarms, or adaptivity to
new unknown designs, etc.

Definition 5. Weighting Function: A function that prop-
erly weights and compensates the prediction result of a base
classiﬁer such that the overall combinations of individual
base classiﬁers can be conﬁgured for better accuracy and
smaller noise.

Definition 6. Meta-Classiﬁer : A classiﬁer that is for-
mulated and optimized via proper combinations of multiple
base classiﬁers under a set of weighting functions to further
enhance hotspot prediction performance.

According to Fig. 3, Phase1 is the calibration stage where
the base classiﬁers and the weighting functions are conﬁg-
ured and optimized using training data sets. This stage
requires the supervision of accurate lithography simulators
or real silicon debugging data. Phase2 is the stage when
the established meta-classiﬁer is applied onto new testing
data sets. This stage operates at very high speed without
accurate lithography simulations.

3.2 Constructing the Meta-Classiﬁer

The construction and optimization of the meta-classiﬁer
are the two key contributions of this paper. In this section
we give an illustrative overview of the proposed methodol-
ogy, leaving detailed analysis to Section 5.

The development of a meta-classiﬁer is illustrated in Fig. 4,
which is mainly divided into 3 levels. For every layout pat-
tern geometry i, certain key hotspot features are extracted
then fed into each base classiﬁer. Base classiﬁers generate
the prediction decisions (xi’s) of pattern i, then the weight of
each classiﬁer’s decision is generated by the weighting func-
tions. The ﬁnal meta-decision is the weighed sum of base
classiﬁers. Generalizing from the motivational example, we

T meta
i

= ̥meta{

x(k)
i

· f (k)(x(k)

i

)}

(3)

N

Xk=1

i

where T meta
is the ﬁnal decision value of pattern i, N is
the total number of base classiﬁers, f (k)(·) is the weighting
function of the kth base classiﬁer, x(k)
is the output from
the kth base classiﬁer when pattern i is the input. ̥meta is
the same as in Eqn.(2).

i

Output meta-decision         for pattern i, where i = 1, 2, … M
(

iT
(

+ +
...

)

)

(

(1)

N

N

f

N

N

N

(

)

)

)

)

(

)

(1)
x
i

(1)
x
i

(
x
i

(
x
i

(1)

f

meta

(
x
i

N

)

)

(
x
i

(1)
x
i

f

(

(1)
x
i

)

f
(

(2)

(2)
x
i

f

(2)
x
i

)

(1)

f

( )
x

(2)

f

( )
x

x

+1
(1)

-1

Decision

ix
Classifier 1

-1

Decision  

x
+1
(2)

ix

Classifier 2

………
Weighing Functions

………

)Nf
(

( )
x

x

Base Classifiers

………

Decision  

-1

+1
)N
(
ix
Classifier N

Feature set 1

Feature set 2

Feature set N

Disparate feature sets
………

Input pattern i, where i = 1, 2, … M

Figure 4: Meta-classiﬁer construction via a combi-
nation of disparate base classiﬁers

By examining the corner cases, we notice that if the weight-
ing function of SVM base classiﬁer f SV M (x) ≡ 1, and
all other base classiﬁers have 0 value weighting functions,
then the meta-classiﬁer degenerates into a SVM base classi-
ﬁer. Therefore by adjusting the weighting functions we can
achieve a performance trade-oﬀ between diﬀerent types of
hotspot detection techniques, such as machine learning and
pattern matching. In the following sections, we will discuss
the development and optimization of each classiﬁer involved
in the proposed ﬂow.

4. CONSTRUCTING BASE CLASSIFIERS

 
 
In this section, we elaborate the base classiﬁers using
machine learning techniques (Artiﬁcial Neural Network and
Support Vector Machine) and pattern matching techniques.

4.1 Artiﬁcial Neural Network Classiﬁers

The ANN base classiﬁer is built via ﬁne tuning [10, 13].
We brieﬂy describe the formulation and our speciﬁc feature
contents as follows.

objective : minimize{

Ep} w.r.t ωij , ωjk

(4)

N

Xp=1

Ep =

1
2

[outp − yp]2

outp = fout{

ωjk · fhid(

V i
p · ωij)}

Xj

Xi

= (outp − yp) · fhid{

V i
p · ωij}

∂Ep
∂ωjk

(5)

(6)

(7)

∂Ep
∂ωij

= (outp − yp) · ωjk · V i

hid)(1 − outj

hid) (8)

Xi
p · (1 + outj

fhid =

2
(1 + e−2x)

− 1,

fin = fout = x

(9)

sign f unc(x) = 


−1 x < 0
0
x = 0
+1 x > 0

(10)

Est ˜p = ̥ann{fout[


ωjk · fhid(

V i
˜p · ωij )]}

(11)

Xj

Xi

An ANN classiﬁer (predictor) works by calculating an out-
come outp for a data sample vector Vp based on established
weights (ωjk) and biases assigned to a neural network struc-
ture, such that the summed square error is minimized ac-
cording to Eqn.(4) and that outp approximates certain tar-
get yp. The models shown here are customized with single
hidden layer of neurons, with transfer functions denoted as
fhid. Inputs Vp to the ANN kernels are the extracted feature
vector samples labeled with values (yp) indicating hotspot
or nonhotspot patterns (these values can be continuous for
variability prediction). We use p to represent feature vector
index with p = 1 to N , V i
p denotes the ith element of vector
Vp, i = 1 to M , where M is the total number of features
for each sample vector. We use fin and fout to represent
input and output layer transfer functions, and index i, j, k
to indicate neuron indices in the input, hidden and output
layer respectively. ̥ann is the threshold adjustment for per-
formance ﬁne-tuning. Once the ANN base classiﬁer is fully
calibrated, we can apply it to estimate Est ˜p according to
Eqn.(11) without using costly lithography simulations.

4.2 Support Vector Machine Classiﬁers

Inside the meta-machine block, we employ a C-class Sup-
port Vector Machine (SVM) classiﬁer ﬁne-tuned based on
[10, 13]. We brief the problem formulation as follows.

objective : minimize{f (α) =

1
2

αT Zα − eT α} w.r.t α

subject

to : 0 ≤ αi ≤ C,

i = 1, ..., n

yT · α = 0

K(Vi, Vj) = exp{γ · kVi − Vj k2}

slope f unc(x) = 


0
x
C

x ≤ 0
0 < x < C
x ≥ C



(12)
(13)

(14)

(15)

(16)

Est ˜p = ̥svm{

αiyiK(V ˜p, Vi) + bias}

(17)

Xi

Given Vi, i=1 to M sample vectors with n number of fea-
tures, with label yi (either hotspot or non-hotspot for 2-class
SVM). e is a vector of all 1’s. C is a pre-set upper bound
to constrain feasible regions for hotspot detection under real
manufacturing conditions. Z is n by n positive semi-deﬁnite
matrix deﬁned as Zij = yiyjK(Vi, Vj), where K(Vi, Vj) is
deﬁned in Eqn.(15) as the kernel function. α is the N ele-
ment weight vector for Vp’s. ̥svm is a threshold function to
adjust and ﬁne-tune the estimation performance of Est ˜p.

The conﬁguration of SVM base classiﬁers is achieved through

performing a set of algorithms over the calibration data Vp’s
to identify the support vectors and weight coeﬃcients that
construct a classiﬁcation hyper-plane with maximized sepa-
ration margin. Once conﬁgured, we apply the SVM model
to evaluate new data samples according to Eqn.(17) without
costly lithography simulations.

4.3 Pattern Matching Classiﬁers

(a)

(b)

(c)

(f)

(d)

(e)
Figure 5: Example patterns in PM base classiﬁers
We explored the current state-of-the-art methods [14–16]
and came up with several major classes (each with hundreds
of speciﬁc hotspot structures) of pattern matching base clas-
siﬁers to cover various types of lithography hotspots, relat-
ing to special line-ends, corners, jogs, contact patterns, etc.
Some example hotspot patterns are illustrated in Fig. 5.
In particular, we have ﬁne-tuned the pattern matchers to
have broader pattern coverage rather than performing ex-
act matching. As a result, the established pattern matchers
demonstrate very good hotspot accuracies onto new data
sets. Obviously, the penalty of such ﬁne-tuning is the con-
sequent high false-alarms. However, as we will see later in
Section 6, the meta-classiﬁer performs well in suppressing
the false-alarms of such a PM base classiﬁer.

5. OPTIMIZING META-CLASSIFICATION
Given the proposed meta-classiﬁer in Fig. 4, in this sec-
tion we ﬁrst analyze the Mean-Square-Error of the meta-
classiﬁer introduced by the errors/noises of the weighting
functions. Then we propose mathematical programming
techniques to optimize the weighting functions to minimize
the detection error.

5.1 Meta-Classiﬁcation Error Analysis

Depicted in Fig. 6 are 2 sets of curves. Assume the black
curves are the optimal weighting functions and the inter-
sected point threshold* is the optimal cutoﬀ value for ̥meta(·)

( )ip

( )
x

( )if

( )
x

( )ie

( )
x

Certain non-optimal
weighing functions

Perfect weighing
functions

( )j

f

( )
x

( )jp

( )
x

( )je

( )
x

s
n
o
i
t
c
n
u
F

i

g
n
h
g
e
W

i

x

-1

threshold*+error

threshold*

+1

Figure 6: An illustration of weighting function error
analysis, assuming two base classiﬁers (N=2)

(this happens under 1:1 importance ratio between hotspot
accuracy improvement and hotspot false-alarm reduction).
Suppose the dotted curves are the sub-optimal weighting
functions for the ith and jth base classiﬁers. In this case,
the derived cut-oﬀ threshold becomes threshold*+error, thus
the meta-classiﬁcation ﬂow has an error:

M SEnoise =

N

{

Xk=1

Zx

N

N

f (k)(x) · x −

p(k)(x) · x}2dx (18)

Xk=1

{[f (k)(x) − p(k)(x)] · x}2dx

(19)

=

Zx

Xk=1

N

=

Zx

Xk=1

{[e(k)(x)] · x}2dx

e(k)(x) = f (k)(x) − p(k)(x)

(20)

(21)

From the analysis above, we observe that the classiﬁcation
error accumulates among all base classiﬁers with a quadratic
index on each term, should noise/error occur in the weight-
ing functions. Therefore, it is critical to ﬁnd the optimal
weighting functions to ensure the meta-classiﬁer ’s noise ro-
bustness. In the following section, we will explore the math-
ematical formulation that optimizes the weighting functions
given certain calibration data.

5.2 Weighting Function Optimization

We ﬁrst deﬁne the meta-classiﬁcation Mean-Square-Error
over the entire calibration data set under the supervision of
accurate lithography simulations:

M SEmeta =

1
M

·

M

N

k

x(k)
i

· p(k)(x(k)

i

) − T litho
i

k2 (22)

Xi=1

Xk=1

where M is the total number of calibration samples and
T litho
is the baseline hotspot characterization result given
i
by accurate lithography simulator. Table 1 details the short-
hand terms used in our mathematical formulation.

To minimize the Mean-Square-Error among the sample
space meanwhile avoid over-ﬁtting of the training data set,
we deﬁne the performance optimization formulation:

T o minimize : M SEmeta + P Cost w.r.t p(k)(x(k)

i

) (23)

P Cost = λ0

(p(k)(x(k)

i

) − const)2

(24)

Xi Xk

where λ0 is a non-negative penalty applied to constrain the
calibration process such that the weighting functions are
bounded within certain proximity of a constant parameter.
This will prevent numerical instability and preserve detec-
tion generality of the weighting functions when applied to

Table 1: Variables and terms in the QP formulation

Terms
N
M
i
k

i

i

x(k)
f (k)(x(k)
p(k)(x(k)
i
L(k)
l

p(l)

k

Θ(·)

α(l)

k (i)

total

L

Q

c

X

meta
T
i

litho
T
i
λ0

Descriptions
Number of the base classiﬁers
Number of meta-machine calibration sample data
Index of each input sample pattern
Index of each base classiﬁer
Prediction result from the base classiﬁer k
given input data sample i
Value of perfect weighting func. f (k)(·) at x(k)

)
) Value of non-perfect weighting func. p(k)(·) at x(k)

i

i

Total quantization levels of base classiﬁer k
Index of each quantization level
Quantized weight value from f (k)(·)

l
at level l of the base classiﬁer k, p

k ∈ [1, L(k)]

The quantization mapping function:
x(k)
i → quantization level index l
Prediction result given by base classiﬁer k at
level l with input sample i (set to 0 if NULL)
i.e., the value to which p(l)

k is to be applied

k

Total number of independent p(l)
A deﬁnite positive matrix ∈ ℜLtotal ×Ltotal
A vector ∈ ℜLtotal ×1
Variable vector for the
quadratic programming formulation, where
k ...p(L(N ))
T ∈ ℜLtotal ×1
X = [p(1)
N
Meta-machine prediction result for input sample i
Prediction baseline for input sample i
by accurate lithography simulator
Parameter to avoid over-ﬁtting/instability

...p(l)

1

]

new testing data. Such proximity is adjustable by varying
λ0.

To assist numerical optimization, we quantized the origi-
nal continuous weighting functions p(1)(x) ∼ p(N)(x), each
into L(k) levels, with each level being a single weight value
denoted as p(l)

k , where l ∈ [1,L(k)].

After the weighting function quantization process, we have

the following modiﬁed formulation:

T o minimize : M SE + P Cost w.r.t p(l)
k

(25)

M SE =

1
M

M

N

k

Xi=1

Xk=1

p(Θ(x(k)

i

k

))

· x(k)

i − T litho

i

k2

(26)

P Cost = λ0

N

L(k)

Xk=1

Xl=1

(p(l)

k − 1)2

(27)

where p(l)
k ’s are the optimization variables (quantized weight
values) for ﬁne-tuning the overall classiﬁcation quality. In
P Cost, we set the constant parameter to 1.0 since it is the
boundary factor of numerical up-scaling and down-scaling.
Due to the P Cost term, each weight variable will be scat-
tered not far away from 1.0 meanwhile be optimized under
predication error minimization objective. This beneﬁts us
in two ways: ﬁrst, avoiding close to zero weights for the cali-
bration data yields better classiﬁcation generality over test-
ing data; second, avoiding large weights can maintain good
balance among hotspot features meanwhile prevent numeric
instability over testing data. For further details of the no-
tations please refer to Table 1.

Finally we can write the following quadratic programming

problem formulation:

f (x) =

1
2

X T QX + cT X

X ≥ lb

(28)

(29)

 
 
lb = [0 0 0 0 0 ... 0]T ∈ ℜL

total ×1

(30)

where X is the optimization variable vector deﬁned as fol-
lows,

X = [p(1)

... p(L(1))

k ... p(L(N ))
where Ltotal is the total number of p(l)

... p(l)

N

1

1

k ’s:

]T ∈ ℜL

total ×1

N

Ltotal =

L(k)

Xk=1

Matrix Q is deﬁned as follows,

(31)

(32)

Q =

β(1)
1 (i)

γ(2,1)
1,1 (i)
.
γ(l,1)
k,1 (i)
γ(L(N ),1)












γ(1,2)
1,1 (i)
. . .
.
.

.

1,k (i) γ(1,L(N ))
γ(1,l)

1,N

(i)

.
β(L(1) )
.

1

(i)

.

.

.
β(l)
k (i)
.

.
.
β(L(N ))

N,1

(i)

(i)
(33)
Vector c is deﬁned as the linear term coeﬃcients vector

N

.

.

Algorithm 1 Meta-Classiﬁer -Calibration
Require: data sample vectors and over-ﬁt penalty λ0

k (i), ω(l)

k (i)

k (i), γ(l)

Initialize Q, c, β(l)
Build Hierarchical MLK-ANN
Build Hierarchical MLK-SVM
Build Pattern Matchers
for All input data samples do

Generate the base classiﬁers
Update Q, c, β(l)

k (i), γ(l)

k (i), ω(l)

k (i)

end for
Formulate Quadratic Programming Problem
if Q not positive deﬁnite then

Increase calibration data volume
Improve hotspot feature quality
Adjust parameter λ0
Consider matrix pre-conditioning

end if
Solve the Quadratic Programming Problem
Optimize the detection threshold function ̥meta(·)
return weighting functions p(l)

k and ̥meta(·)












from the quadratic formulation objective:

c = [ω1

1 (i) · · · ωL(1)

1

(i) · · · ω(l)

k (i) · · · ωL(N )

N

(i) ]T

(34)

where the related terms are deﬁned as follows, and α(l)
k (i) is
an intermediate term to link the base classiﬁer ’s prediction
values with p(l)
k (i) is the x(k)
value that falls into
level l of the quantized weighting function relating to the
base classiﬁer k. Given certain i and k, if there is no output
values corresponding to level l, then α(l)

k , i.e., α(l)

k (i) is set to 0.

i

Algorithm 2 Meta-Classier -Prediction
Require: data sample vectors
Load weighting functions p(l)
Load all base classiﬁers
Generate vector −→xi from base classiﬁers outputs
for Each data vector −→xi do
=̥meta(

k and ̥meta(·)

Calculate T meta

k=1 p(Θ(x(k)

· x(k)
i

N

))

k

i

i

)

end for
P
return Meta-decision {T meta
}

i

β(l)
k (i) =

2
M

[α(l)

k (i)]2 + 2λ0

M

Xi=1
M

γ(n,l)
m,k (i) =

2
M

m (i) · α(l)
α(n)

k (i)

Xi=1

ω(l)

k (i) = −

2
M

M

Xi=1

T litho
i

· α(l)

k (i) − 2λ0

(35)

(36)

(37)

The values and parameters in the above equations are de-
rived properly so that the original problem in Eqn.(23) be-
comes the minimization of a quadratic problem in Eqn.(28).
Once it is solved, we apply the resulting weighting functions
over some calibration data to properly select a threshold
function ̥meta(·) to further balance hotspot accuracy and
hotspot false-alarm. After calibration, the meta-classiﬁer
will be tested over new design layouts based on Eqn.(3).

5.3 Complexity Analysis

Theorem 1: Matrix Q is positive deﬁnite under certain
conditions of λ0 and the formulated quadratic programming
problem has the following properties: (1) it can be solved in
polynomial time complexity; (2) if it has a local minimum,
then this local minimum is also the global minimum.
Proof For notation simplicity, we assume a vector ~X ∈
total ×1 and X ≥ ~0. Let ρi be the coeﬃcient of χi, where
ℜL
χi is the ith element of ~X. Let Ltotal be the total number
of quantization levels among all base classiﬁers. Therefore
we have the following:

~X T Q ~X =

1
M

M

total

L

total

L

X

Xj=i+1

Xi=1

(ρiχi + ρj χj)2 + ∆ (38)

where

∆ = −

Ltotal − 2
M

M

total

L

total

L

i χ2
ρ2

i + λ0

χ2
i

(39)

X

Xi

Xi

We can adjust λ0 to achieve positive ∆ (in practice usually
total −2
M ). Therefore ~X T Q ~X
a λ0 slightly larger than L
M
is always positive given non-zero ~X. Thus Q is a positive
deﬁnite matrix and has no negative eigenvalues under the
speciﬁed condition. Numerical simulations further validate
this proof by showing all positive eigenvalues for matrix Q.
Consequently, the Quadratic Programming problem can be
solved by the ellipsoid method [20] in polynomial time.

P

Since Q is a symmetric positive-deﬁnite matrix, f (·) is
now a convex function. Thus the quadratic program has
a global minimizer if there exists some feasible vector X n
satisfying the constraints and if f (·) is bounded below on
the feasible region (X n ∈ ℜn
+). Therefore in search of a
local minimum, if found, will guarantee the optimal global
minimum.

We solve the quadratic programming problem using a
proper λ0 to optimize the weighting functions during the
calibration phase. Then we use a heuristic approach to
search for the optimal ̥meta(·) function.
In Algorithm 1
and Algorithm 2, we show the details for the calibration
and application of the meta-classiﬁer.

6. SIMULATION AND TESTING

6.1 Benchmarks and Simulation Setups

2

1.5

1

0.5

0

)
0
1
g
o
L
(

e
t
a
r

l

m
r
a
a
−
e
s
a
F

l

−0.5

−1

0.5

PM Classifier Performance 
Trade−off Area

ANN Classifier Area

Table 2: Circuit benchmarks for testing EPIC
Benchmarks
Layout Size um2
Fragment number
Class0a Hotspots number
Class1b Hotspots number
a Class0 hotspots: EPE ≥ 6nm for 32nm process.
b Class1 hotspots: 4.5nm ≤ EPE < 6nm for 32nm process.

CK2
150×150
94.5K
21
134

CK1
100×100
58K
9
61

CK3
800×800
2.5M
122
2.8K

EPIC Meta−Classifier
Performance Boundary

SVM Classifier Boundary Area

0.6

0.7

0.8

0.9

1

Hotspot Detection Accuracy %

Figure 7: Trade-oﬀ capabilities between hotspot accuracy
and false-alarms using various methods on C0 hotspots

To fully evaluate EPIC, we employed a number of train-
ing data sets and 3 new testing circuit benchmarks in 32nm.
These testing circuits include new hotspot patterns that
were not present in the training data. We labeled 2 classes
of ‘real’ lithographic hotspots based on 2 EPE thresholds.
In Table 2, C0 is the class0 hotspot patterns whose printed
images suﬀer from above 6nm of EPE; C1 refers to the pat-
terns whose printed images have EPE from 4.5nm to 6nm.
Further details of the 3 testing benchmarks are in Table 2.
To properly evaluate the proposed methods, we perform ac-
curate lithographic simulations as baseline to identify the
actual hotspots under industry-strength RETs.

In our simulation, EPIC incorporates two types of ma-
chine learning methods based on [10,13] and several pattern
matching techniques based on [14–17]. We implement EPIC
in C++ on 3.2GHz quad-core Linux workstations.

6.2 Result Analysis and Comparison

After the quadratic programming problem is solved, we
properly select the decision threshold function ̥meta(·) us-
ing some calibration data to balance between hotspot accu-
racy and hotspot false-alarm. To illustrate such performance
trade-oﬀ, we test EPIC, ANN and SVM over C0 data with a
set of varying thresholds and plot the results in Fig. 7. We
also plot the performance region of the employed pattern
matchers, which include up to 4 major classes of hotspot
patterns. As we enrich the pattern library gradually with
up to more than hundreds of speciﬁc patterns and struc-
tures, the overall performance becomes a trade-oﬀ between
enhancing detection accuracy and suppressing false-alarms,
especially when there are new unseen types of hotspots in
the testing data.

From Fig. 7 we observe that in the region of above 70%
accuracy, EPIC shows higher hotspot accuracy than other
methods with very similar hotspot false-alarm, it also achieves
lower hotspot false-alarm given similar hotspot accuracy. We
also see that pattern matching methods are not good at
detecting new types of hotspots without obvious penalty
in hotspot false-alarm. In this sense, machine learning can
make pattern matching more robust to predict new/unknown
hotspots, especially when pattern enumeration becomes costly.
Based on Fig. 7, we calculate the following for each method:
Ψ = α · Accuracyhotspot + β · F alse alarmhotspot

(40)

where α (positive) and β (negative) are user deﬁned pa-

Circuits Class

Table 3: Performance of hotspot detection methods
ANN
6
79
52

SVM PM EPIC
7
280
53

9
48
57

7
41
54

C0

Perf.
Hit
Extra
Hit
Extra
Hit
Extra
Hit
Extra
Hit
Extra
Hit
Extra

CK1

CK2

CK3

C1

C0

C1

C0

C1

0.55K 0.33K 1.5K 0.3K

18

17

17

19

120

120

0.2K 0.11K 0.7K 0.1K
125
119
1.2K 0.75K 3.4K 0.65K
105
104
109
1.2K
0.6K 3.9K 0.65K
2.45K 2.5K 2.5K 2.63K
73K 13.5K
24K

16K

112

rameters to quantify the importance ratio between hotspot
accuracy and hotspot false-alarm. In Table 3 and Table 4,
we report the detection result of each method correspond-
ing to the peak of their respective Ψ function. We observe
that EPIC reaches the highest performance over both C0
and C1 categories of hotspots in both hotspot accuracy and
hotspot false-alarm. To be speciﬁc, it improves ANN and
SVM by 3.5-7% in hotspot accuracy and reduces up to 50%
in hotspot false-alarm counts. EPIC also outperforms PM
by 4.5-8.2% in hotspot accuracy and 53-81% in hotspot false-
alarm reduction. This demonstrates very promising poten-
tial of the meta-classiﬁcation ﬂow with respect to weighting
function optimizations. Moreover, EPIC runs at the speed
of around 45 min per mm2 design on a 3.2GHz quad-core
workstation, which is typically hundreds of times faster than
accurate lithography simulator.

In Fig. 8 we give two summary plots on the performance
comparisons of various hotspot prediction methods accord-
ing to (a): hotspot accuracy(Hit rate)/run-time, and (b):
hotspot false-alarm(Extra)/run-time, respectively. Here we
make some further observations.

First, EPIC achieves much enhanced performance in hotspot

prediction accuracy and false-alarms reduction, meanwhile
the extra CPU run-time is only 20-30 minutes per mm2 lay-
out in the worst case (versus pattern matching methods).

Second, in comparing C0 category of hotspots with C1
category, we see EPIC achieves higher Hit rate and lower
False-Alarm ratio (in the unit of X times of real hotspots)
over C1 than C0. In other words, EPIC gives more enhance-
ment in accuracy and false-alarm on C1. This is mostly be-
cause C1 class represents the set of lithography hotspot with

Table 4: Comparison between EPIC and previous
works

C0

C1

Hotspot
Avg. Perf.
EPIC
ANN [10, 13]
SVM [10, 13]
PM [14–17]
Time calibrated in hour/mm2 unit on 3.2GHz quad-core Linux
workstation.

Extra Time Hit
0.72
0.3
0.35
0.2

Extra Time
0.72
0.3
0.35
0.2

Hit
5X
92%
89% 10X
86%
5X
85% 32X

94% 4.8X
88% 8.8X
89% 5.5X
90% 25X

 
 
C0 H it rate C0 run time (hour) C1 H it rate C1 run time (hour)

C0 Extra  ratio

C0 run time (hour)

C1 Extra  ratio

C1 run time (hour)

0.92

0.94

0.89

0.88

0.86

0.89

0.85

0.9

0.87

0.88

0.72

0.72

0.65

0.65

0.3

0.3

0.35

0.35

0.2

0.2

12

10

8

6

4

2

0

10

8.8

32

25

5

4.8

5

5.5

5.2

5.25

0.72

0.72

0.65

0.65

0.3

0.3

0.35

0.35

0.2

0.2

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

EPIC

ANN[10,13]

SVM[10,13]

PM[14-17]

Hybrid[18]

EPIC

ANN[10,13]

SVM[10,13]

PM[14-17]

Hybrid[18]

Figure 8: Overall performance comparison in Hit rate, Extra ratio and run-time over C0 and C1 hotspot data

(a)

(b)

4.5nm to 6.0nm of EPE, while C0 is the set of hotspots with
above 6.0nm EPE values. Under our employed RETs, C0
translates to a set of hotspots that have high variability and
small quantity (a few hundred out of a layout with totally
millions of patterns); whereas C1 is a set of hotspots with
less severe variability and much larger quantity. This is why
sometimes detecting C0 could be slightly harder than C1.
However it also depends on how the trade-oﬀ solution is se-
lected using Ψ based on Fig. 7 to balance between hotspot
accuracy and hotspot false-alarm, e.g., ANN shows a slightly
higher (by 1%) accuracy rate in C0 than C1 category.

An important advantage of EPIC is that it is capable
of high performance hotspot prediction under varying EPE
thresholds and given large scale design layouts. We see
that EPIC exhibits very similar CPU run-time when tar-
geting at diﬀerent categories of hotspot under diﬀerent EPE
thresholds. We have also observed linear run-time complex-
ity when design layout up-scales in area. These properties
make our ﬂow eﬃcient for optimizing large industry designs.
Moreover, EPIC ’s uniﬁed formulation covers the static
hybrid detection ﬂow proposed in [18] as a special case, i.e.,
when weighting function f M LK1(+1) = 0.5 and 0 elsewhere,
f M LK2(+1) = 0.5 and 0 elsewhere, f P M (+1) = 1.0 and 0
elsewhere, θ = 1.0, then EPIC ’s formulation Eqn.(3) will
be equivalent to the hybrid ﬂow in [18]. Here EPIC ’s ad-
vantage lies in the dynamic/automated optimization tech-
niques, thus it can easily reach an optimized solution. Com-
paring with the static hybrid ﬂow over the employed test
cases, EPIC observes around 5.7-6.8% of improvement in
hotspot accuracy and 3.9-8.6% of false-alarm reduction at
a small cost of 10% extra run-time. Depending on designs,
EPIC ’s advantages could be even higher.

7. CONCLUSION

In this paper we examined several diﬀerent types of lithog-
raphy hotspot detection techniques and proposed EPIC, a
new formulation to selectively combine their respective ad-
vantages for further accuracy improvement. Under a meta-
detection ﬂow, we ﬁrst used mathematical programming tech-
niques for systematic performance optimization over a set of
calibration data, then applied the ﬂow onto new testing cases
for further evaluation. EPIC’s accuracy, ﬂexibility and false-
alarm suppression capability show very promising potential
for eﬃcient litho-friendly design.

8. REFERENCES
[1] International Technology Roadmap for Semiconductors. 2011.
[2] Joydeep Mitra, Peng Yu, and David Z. Pan. RADAR:
RET-Aware Detailed Routing using Fast Lithography
Simulation. In Proc. Design Automation Conf., June 2005.
[3] Minsik Cho, Kun Yuan, Yongchan Ban, and David Z. Pan.
ELIAD: Eﬃcient Lithography Aware Detailed Router with

Compact Printability Prediction. In Proc. Design Automation
Conf., June 2008.

[4] Tai-Chen Chen, Guang-Wan Liao, and Yao-Wen Chang.
Predictive Formulae for OPC with Applications to
Lithography-Friendly Routing. In Proc. Design Automation
Conf., June 2008.

[5] David Z. Pan, Minsik Cho, and Kun Yuan. Manufacturability
Aware Routing in Nanometer VLSI. In Foundations and
Trends in Electronic Design Automation, 2010.

[6] Duo Ding, Jhih-Rong Gao, Kun Yuan, and David Z. Pan.

AENEID: A Generic Lithography-Friendly Detailed Router
Based on Post-RET Data Learning and Hotspot Detection. In
Proc. Design Automation Conf., 2011.

[7] Norimasa Nagase, Kouichi Suzuki, Kazuhiko Takahashi,

Masahiko Minemura, Satoshi Yamauchi, and Tomoyuki Okada.
Study of Hotspot Detection using Neural Network Judgement.
In Proc. of SPIE, volume 6607, 07.

[8] Duo Ding, Xiang Wu, Joydeep Ghosh, and David Z. Pan.

Machine Learning based Lithographic Hotspot Detection with
Critical Feature Extraction and Classiﬁcation. In IEEE Int.
Conf. on IC Design Technology, Austin, TX, 2009.
[9] Dragoljub Gagi Drmanac, Frank Liu, and Li-C. Wang.

Predicting Variability in Nanoscale Lithography Processes. In
Proc. Design Automation Conf., San Francisco, CA, 2009.
[10] Duo Ding, J. Andres Torres, Fidor G. Pikus, and David Z. Pan.
High Performance Lithographic Hotspot Detection Using
Hierarchically Reﬁned Machine Learning. In Proc. Asia and
South Paciﬁc Design Automation Conf., 2011.

[11] Jen-Yi Wuu, Fedor G. Pikus, J. Andres Torres, and Malgorzata
Marek-Sadowska. Detecting Context Sensitive Hot Spots in
Standard Cell Libraries. In Proc. of SPIE, 2009.

[12] Jen-Yi Wuu, Fedor G. Pikus, and Malgorzata Marek-Sadowska.

Rapid Layout Pattern Classiﬁcation. In Proc. Asia and South
Paciﬁc Design Automation Conf., 2011.

[13] Duo Ding, J. Andres Torres, and David Z. Pan. High

Performance Lithography Hotspot Detection with Successively
Reﬁned Pattern Identiﬁcations and Machine Learning. In IEEE
Trans. on Computer-Aided Design of Integrated Circuits and
Systems, 2011.

[14] Jingyu Xu, Subarna Sinha, and Charles C. Chiang. Accurate
Detection for Process Hotspots with Vias and Incomplete
Speciﬁcation. In Proc. Int. Conf. on Computer Aided Design,
2007.

[15] Andrew B. Kahng, Chul-Hong Park, and Xu Xu. Fast Dual
Graph based Hotspot Detection. In Proc. of SPIE, volume
6349, 2006.

[16] Hailong Yao, S. Sinha, C. Chiang, X. Hong, and Y. Cai.
Eﬃcient Process Hotspot Detection using Range Pattern
Matching. In Proc. Int. Conf. on Computer Aided Design,
2006.

[17] Ning Ma, Justin Ghan, Sandipan Mishra, Costas Spanos,

Kameshwar Poolla, Norma Rodriguez, and Luigi Capodieci.
Automatic Hotspot Classiﬁcation using Pattern-based
Clustering. In Proc. of SPIE, 2007.

[18] Jen-Yi Wuu, Fedor G. Pikus, and Malgorzata Marek-Sadowska.
Eﬃcient Approach to Early Detection of Lithographic Hotspots
Using Machine Learning Systems and Pattern Matching. In
Proc. of SPIE, 2011.

[19] Kagan Tumer and Joydeep Ghosh. Robust Combining of
Disparate Classiﬁers through Order Statistics. In Pattern
Analysis & Applications, pp. 189-200, 2002.

[20] M. K. Kozlov, S. P. Tarasov, and Leonid G. Khachiyan.

Polynomial Solvability of Convex Quadratic Programming. In
Soviet Mathematics - Doklady 20, pp. 1108-1111, 1979.

