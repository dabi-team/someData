1
2
0
2

r
a

M
0
3

]

V
C
.
s
c
[

1
v
8
7
1
6
1
.
3
0
1
2
:
v
i
X
r
a

Learnable Graph Matching: Incorporating Graph Partitioning with Deep
Feature Learning for Multiple Object Tracking

Jiawei He1,3

Zehao Huang2 Naiyan Wang2

Zhaoxiang Zhang1,3,4

1 Institute of Automation, Chinese Academy of Sciences (CASIA)

2 TuSimple

3 School of Artiﬁcial Intelligence, University of Chinese Academy of Sciences (UCAS)
4 Centre for Artiﬁcial Intelligence and Robotics, HKISI CAS
{hejiawei2019, zhaoxiang.zhang}@ia.ac.cn {zehaohuang18, winsty}@gmail.com

Abstract

Data association across frames is at the core of Mul-
tiple Object Tracking (MOT) task. This problem is usu-
ally solved by a traditional graph-based optimization or di-
rectly learned via deep learning. Despite their popularity,
we ﬁnd some points worth studying in current paradigm:
1) Existing methods mostly ignore the context information
among tracklets and intra-frame detections, which makes
the tracker hard to survive in challenging cases like severe
occlusion. 2) The end-to-end association methods solely
rely on the data ﬁtting power of deep neural networks,
while they hardly utilize the advantage of optimization-
based assignment methods. 3) The graph-based optimiza-
tion methods mostly utilize a separate neural network to
extract features, which brings the inconsistency between
training and inference. Therefore, in this paper we pro-
pose a novel learnable graph matching method to address
these issues. Brieﬂy speaking, we model the relation-
ships between tracklets and the intra-frame detections as
a general undirected graph. Then the association prob-
lem turns into a general graph matching between track-
let graph and detection graph. Furthermore, to make the
optimization end-to-end differentiable, we relax the orig-
inal graph matching into continuous quadratic program-
ming and then incorporate the training of it into a deep
graph network with the help of the implicit function the-
orem. Lastly, our method GMTracker, achieves state-of-
the-art performance on several standard MOT datasets.
Our code will be available at https://github.com/
jiaweihe1996/GMTracker.

1. Introduction

Multiple Object Tracking (MOT) is a fundamental task
that aims at associating the same object across successive
frames in a video clip. A robust and accurate MOT algo-
rithm is indispensable in broad applications, such as au-

Figure 1: An illustration of intra-graph relationship used
in our graph matching formulation. We utilize the second-
order edge-to-edge similarity to model the group activity,
which is more robust under heavy occlusion. Note that not
all vertices in tracklet graph can be matched to the detection
graph because they disappear in the current frame.

tonomous driving and video surveillance. The tracking-by-
detection is currently the dominant paradigm in MOT. This
paradigm consists of two steps: (1) obtaining the bounding
boxes of objects by detection frame by frame; (2) gener-
ating trajectories by associating the same objects between
frames. With the rapid development of deep learning based
object detectors, the ﬁrst step is largely solved by the power-
ful detectors such as [37, 38]. As for the second one, recent
MOT works focus on improving the performance of data
association mainly from the following two aspects: (1) for-
mulating the association problem as a combinatorial graph
partitioning problem and solve it by advanced optimization
techniques [5, 7, 62, 8, 65, 18]; (2) improving the appear-
ance models by the power of deep learning[28, 67, 31, 64].
Although very recently, there are works [77, 53, 8, 65] try-
ing to unify feature learning and data association into an
end-to-end trained neural network, these two directions are

231TrackletsDetections(a) Hungarian Algorithm(b) Graph Matching(c) occlusion case231123 
 
 
 
 
 
almost isolated so that these recent attempts hardly utilize
the progress from the combinatorial graph partitioning.

In the graph view of MOT, each vertex represents a de-
tection bounding box or a tracklet, while the edges are con-
structed between the vertices across different frames to rep-
resent the similarities between them. Then the association
problem can be formulated as a min-cost ﬂow problem [72].
The most popular used method is to construct a bipartite
graph between two frames and adopt Hungarian algorithm
[27] to solve it. This online strategy is widely used in prac-
tice because of its simplicity [7, 64]. Nevertheless, these
methods are not robust to occlusions due to the lack of
history trajectories and long term memory. This problem
is traditionally solved by constructing graph from multiple
frames, and then deriving the best association based on the
optimal solution of this min-cost ﬂow problem [72].

All these existing works focus on ﬁnding the best match-
ing across frames, but ignoring the context within the frame.
In this paper, we argue that the relationship between the ver-
tices within the same frame is also crucial for some chal-
lenging cases in MOT. For example, we can match an oc-
cluded object to the correct tracklet solely by the past re-
lationships with neighborhood objects. Fig. 1 just shows
such an example. Interestingly, these pairwise relationships
within the same frame can be represented as edges in a
general graph. To this end, the popular bipartite match-
ing across frames can be updated to general graph matching
between them. To further integrate this novel assignment
formulation with powerful feature learning, we ﬁrst relax
the original formulation of graph matching [30, 26] to a
quadratic programming, and then derive a differentiable QP
layer based on the KKT conditions and the implicit function
theorem for the graph matching problem, inspired by the
OptNet [2]. Finally, the assignment problem can be learned
in synergy with the features.

Overall, our work has the following contributions:

• Instead of only focusing on the association across
frames, we emphasize the importance of intra-frame
relationships. Particularly, we propose to represent the
relationships as a general graph, and formulate the as-
sociation problem as general graph matching.

• To solve this challenging assignment problem, and
further incorporate it with deep feature learning, we
derive a differentiable quadratic programming layer
based on the continuous relaxation of the problem, and
utilize implicit function theorem and KKT conditions
to derive the gradient w.r.t the input features during
back-propagation.

• We evaluate our proposed GMTracker on the large
scale open benchmark. Our method could remarkably
advance the state-of-the-art performance in terms of
association metric such as IDF1.

2. Related Work

Data association in MOT. The data association step in
tracking-by-detection paradigm is generally solved by prob-
abilistic ﬁlter or combinatorial optimization techniques.
Classical probabilistic approach includes JPDA [3] and
MHT [48]. The advantage of this approach is to keep all the
possible candidates for association, and remain the chance
to recover from failures. Nevertheless, their costs are pro-
hibitive if no approximation is applied [14, 24]. For combi-
natorial optimization, traditional approach include bipartite
matching [7], dynamic programming [13], min-cost ﬂow
[72, 5] and conditional random ﬁeld [66]. Follow-up works
tried to adopt more complex optimization methods [70, 55],
reduce the computational cost [47, 56] or promote an online
setting from them [9, 59].
Deep learning in MOT. Early works of deep learning in
MOT such as [64, 31, 51, 34] mostly focus on learning a
better appearance model for each object. Then by the ad-
vance of object detection and multi-task learning, several
works [6, 40, 76, 73] combine detection and tracking in
the same framework. More recently, several works tried to
bridge the graph optimization and end-to-end deep learn-
ing [21, 8, 65, 34, 18].
[21] adopts Graph Neural Net-
work (GNN) to learn an afﬁnity matrix in a data-driven
way. MPNTrack [8] introduces a message passing network
to learn high-order information between vertices from dif-
ferent frames. [34] constructs two graph networks to model
appearance and motion features, respectively. LifT [18]
proposes a lifted disjoint path formulation for MOT, which
introduces lifted edges to capture long term temporal inter-
actions.
Neighborhood and context information in MOT. Pedes-
trians usually walk in a group, so the motion of them are
highly clustered. Modeling neighborhood and context re-
lationships may provide important clues for the MOT task.
Several early works [50, 19] consider the group model as
a prior in motion model for the crowd scenes.
[68] con-
siders the distance between detections as the neighborhood
relationship during the data association. However, these
hand-crafted priors can be quite limited in complicated
scenes. Recently, many methods [36, 46, 39, 29] learn ap-
pearance and geometric information by passing messages
among neighbors. However, their goal is still to enhance the
appearance features. They do not consider them explicitly
in the association across frames. In this work, we propose to
explicitly consider the neighborhood context in data associ-
ation via differentiable graph matching and use it to guide
the feature learning in an end-to-end manner.
Graph matching and Combinatorial Optimization. Pair-
wise graph matching, or more generally Quadratic Assign-
ment Problem (QAP), has wide applications in various com-
puter vision tasks [58]. Compared with the linear assign-
ment problem that only considers vertex-to-vertex relation-

ship, pairwise graph matching also considers the second-
order edge-to-edge relationship in graphs. The second-
order relationship makes matching more robust. How-
ever, as shown in [15], this problem is an NP-hard prob-
lem. There is no polynomial solver like Hungarian al-
gorithm [27] for the linear assignment problem.
In the
past decades, many works focus on making the problem
tractable by relaxing the original QAP problem [32, 52,
57]. Lagrangian decomposition [54] and factorized graph
matching [75] are two representative ones.

In MOT task, the application of graph matching is very
limited. To the best of our knowledge, [20] is the ﬁrst to for-
mulate the MOT task as a graph matching problem and use
dual L1-normalized tensor power iteration method to solve
it. Different from [20] that directly extracts the features
from an off-the-shelf neural network, we propose to guide
the feature learning by the optimization problem, which can
both enjoy the power of deep feature learning and combina-
torial optimization. This joint training manner of represen-
tation and optimization problem also eliminate the incon-
sistencies between the training and inference.

To incorporate graph matching into deep learning, one
stream of work is to treat the assignment problem as a su-
pervised learning problem directly, and use the data ﬁtting
power of deep learning to learn the projection from input
graphs to output assignment directly [61, 69]. Another
more theoretically rigorous is to relax the problem to a con-
vex optimization problem ﬁrst, and then utilize the KKT
condition and implicit function theorem to derive the gra-
dients w.r.t all variables at the optimal solution [4]. As
shown in [2], the universality and transferability of the lat-
ter approach are much better than the ﬁrst one. Thus, in this
paper, we derive a graph matching layer based on this spirit
to solve the challenging graph matching problem in MOT.

3. Graph Matching Formulation for MOT

In this section, we will formulate the multiple object
tracking problem as a graph matching problem. Instead of
solving the original Quadratic Assignment Problem (QAP),
we relax the graph matching formulation as a convex
quadratic programming (QP) and extend the formulation
from the edge weights to the edge features. The relax-
ation facilitates the differentiable and joint learning of fea-
ture representation and combinatorial optimization.

3.1. Detection and Tracklet Graphs Construction

As an online tracker, we track objects frame by frame. In
1, Dt
frame t, we deﬁne Dt = {Dt
} as the set of
2, · · · , T t
detections in current frame and T t = {T t
} as
nt
the set of tracklets obtained from past frames. nd and nt de-
note the number of detected objects and tracklet candidates.
A detection is represented by a triple Dt
p, t),
where It
p contains the image pixels in the detected area,

2, · · · , Dt
nd
1, T t

p = (It

p, gt

p, yt

p, ht

p, wt

p = (xt
gt
p) is a geometric vector including the
central location and size of the detection bounding box.
Each tracklet contains a series of detected objects with the
same tracklet id. With a bit abuse of notations, the gener-
ation of T t
(id)},
which means we add Dt−1

id ← T t−1
id ∪ {Dt−1
(id) to the tracklet T t−1
id .

id can be represented as T t

i and the tracklet T t

D and vertex j ∈ V t

Then we deﬁne the detection graph in frame t as Gt
D) and the tracklet graph up to the frame t as Gt
D, E t
T ). Each vertex i ∈ V t
T , E t

D =
(V t
T =
(V t
T represents
the detection Dt
j , respectively. The eu =
(i, i(cid:48)) is the edge in E t
D and ev = (j, j(cid:48)) is the edge in E t
T .
Both of these two graphs are complete graphs. Then the
data association in frame t can be formulated as a graph
matching problem between Gt
D and Gt
T . For simplicity, we
will ignore t in the following sections.

3.2. Basic Formulation of Graph Matching

Given the detection graph GD and the tracklet graph GT ,
the graph matching problem is to maximize the similari-
ties between the matched vertices and corresponding edges
connected by these vertices. In the following derivation, we
use the general notation G1 and G2 to obtain a general graph
matching formulation.

As deﬁned in [30], the graph matching problem is a
Quadratic Assignment Problem (QAP) . A practical mathe-
matical form is named Koopmans-Beckmann’s QAP [26]:

maximize
Π

s.t.

J (Π) = tr(A1ΠA2Π(cid:62)) + tr(B(cid:62)Π),

Π1n = 1n, Π(cid:62)1n = 1n,

(1)

where Π ∈ {0, 1}n×n is a permutation matrix that de-
notes the matching between the vertices of two graphs,
A1 ∈ Rn×n, A2 ∈ Rn×n are the weighted adjacency ma-
trices of graph G1 and G2 respectively, and B ∈ Rn×n is
the vertex afﬁnity matrix between G1 and G2. 1n denotes an
n-dimensional vector with all values to be 1.

3.3. Reformulation and Convex Relaxation

For Koopmans-Beckmann’s QAP, as Π is a permutation
matrix, i.e., Π(cid:62)Π = ΠΠ(cid:62) = I. Following [75], Eq. 1 can
be rewritten as

Π∗ = arg min

Π

1
2

||A1Π − ΠA2||2

F − tr(B(cid:62)Π).

(2)

This formulation is more intuitive than that in Eq. 1. For
two vertices i, i(cid:48) ∈ G1 and their corresponding vertices
j, j(cid:48) ∈ G2, the ﬁrst term in Eq. 2 denotes the difference
of the weight of edge (i, i(cid:48)) and (j, j(cid:48)), and the second term
denotes the vertex afﬁnities between i and j. Then the goal
of the optimization is to maximize the vertex afﬁnities be-
tween all matched vertices, and minimize the difference of
edge weights between all matched edges.

It can be proven that the convex hull of the permutation
matrix lies in the space of the doubly-stochastic matrix. So,
as shown in [1], the QAP (Eq. 2) can be relaxed to its tight-
est convex relaxation by only constraining the permutation
matrix Π to be a double stochastic matrix X, formed as the
following QP problem:

X∗ = arg min

X∈D

1
2

||A1X − XA2||2

F − tr(B(cid:62)X),

(3)

where D = {X : X1n = 1n, X(cid:62)1n = 1n, X ≥ 0}.

3.4. From Edge Weights to Edge Features

In the formulation of graph matching above, the element
ai,i(cid:48) in the weighted adjacency matrix A ∈ Rn×n is a scalar
denoting the weight on the edge (i, i(cid:48)). To facilitate the
application in our MOT problem, we expand the relaxed
QP formulation by using an l2-normalized edge feature
hi,i(cid:48) ∈ Rd instead of the scalar-formed edge weight ai,i(cid:48)
in A. We build a weighted adjacency tensor H ∈ Rd×n×n
where H·,i,i(cid:48)
= hi,i(cid:48), i.e., we consider the each dimension of
hi,i(cid:48) as the element ai,i(cid:48) in A and concatenate them along
channel dimension. The H1 and H2 are the weighted ad-
jacency tensors for G1 and G2, respectively. Then the opti-
mization objective in Eq. 2 can be further expanded to con-
sider the l2 distance between two corresponding n-d edge
features other than the scalar differences:

1
2

||Hc

1Π − ΠHc

2||2

F − tr(B(cid:62)Π)

Π∗ = arg min

Π

= arg min

d
(cid:88)

c=1
n
(cid:88)

Π

i=1
− tr(B(cid:62)Π)
n
(cid:88)

= arg min

n
(cid:88)

n
(cid:88)

n
(cid:88)

i(cid:48)=1

j=1

j(cid:48)=1

n
(cid:88)

n
(cid:88)

n
(cid:88)

1
2

1
2

Π

i(cid:48)=1

i=1
j=1
i(cid:48)j(cid:48)) − tr(B(cid:62)Π),

+ π2

j(cid:48)=1

(π2

ij − 2πijπi(cid:48)j(cid:48)h(cid:62)

ii(cid:48)hjj(cid:48)

(4)
where n is the number of vertices in graph G1 and G2, the
subscript i and i(cid:48) are the vertices in graph G1 and j and j(cid:48)
are in graph G2. We reformulate Eq. 4 as:

π∗ = arg min

π(cid:62)((n − 1)2I − M)π − b(cid:62)π,

(5)

π

where π = vec(Π), b = vec(B) and M ∈ Rn2×n2
is the
symmetric quadratic afﬁnity matrix between all the possible
edges in two graphs.

Following the relaxation in Section 3.3, the formulation

Eq. 5 using edge features can be relaxed to a QP:

x∗ = arg min

x(cid:62)((n − 1)2I − M)x − b(cid:62)x,

x∈D(cid:48)

(6)

||hii(cid:48)πij − hjj(cid:48)πi(cid:48)j(cid:48)||2
2

M = (SD ⊗ ST)diag(vec(Me))(TD ⊗ TT)(cid:62),

(8)

Figure 2: An example of the derivation from edge afﬁnity
matrix Me to quadratic afﬁnity matrix M.

(cid:48)

where D
In1, U = I(cid:62)
n2

= {x : Rx = 1, Ux ≤ 1, x ≥ 0, R = 1(cid:62)
n2
⊗ 1n1 }, ⊗ denotes Kronecker product.

⊗

In the implementation, we ﬁrst compute the cosine simi-
larity between the edges in GD and GT to construct the ma-
trix Me ∈ R|ED|×|ET |. The element of the matrix Me is
the cosine similarity between edge features hi,i(cid:48) and hj,j(cid:48)
in two graphs:

Mu,v

e = h(cid:62)

i,i(cid:48)hj,j(cid:48),

(7)

where eu = (i, i(cid:48)) is the edge in GD and ev = (j, j(cid:48)) is the
edge in GT .

And following [71], we map each element of matrix Me

to the symmetric quadratic afﬁnity matrix M:

where diag(·) means constructing a diagonal matrix by
the given vector, SD ∈ {0, 1}|VD|×|ED| and ST ∈
{0, 1}|VT |×|ET |, whose elements are an indicator function:

Is(i, u) :=

(cid:40)
1
0

if i is the start vertex of edge eu,
if i is not the start vertex of edge eu,

(9)

TD ∈ {0, 1}|VD|×|ED| and TT ∈ {0, 1}|VT |×|ET |, whose
elements are another indicator function:

It(i(cid:48), u) :=

(cid:40)

1
0

if i(cid:48) is the end vertex of edge eu,
if i(cid:48) is not the end vertex of edge eu.

(10)
An example of the derivation from Me to M is illustrated
in Fig. 2.

Besides, each element in the vertex afﬁnity matrix B is
the cosine similarities between feature hi on vertex i ∈ VD
and feature hj on vertex j ∈ VT :

Bi,j = h(cid:62)

i hj

(11)

ABCab0.650.400.500.800.500.450.400.650.800.500.450.50001010100010100001001010100010100001010100001001010100010100001001010100ABCABBCCABACBACABBCCABACBACABC0110abba1001abbaababABBCCABACBACabba0.5000.4000000.4500.65000.800000.65000.500000.40000.5000.4500000.8000.500.5000.4000000.4500.65000.800000.65000.500000.40000.5000.4500000.8000.50Figure 3: Overview of our method. We ﬁrst extract features from detections and construct the detection graph using these
features. The tracklet graph construction step is similar to the detection graph, but we average the features in a tracklet.
Then the cross-graph GCN is adopted to enhance the features. The weight wi,j is from the feature similarity and geometric
information. The core of our method is the differentiable graph matching layer built as a QP layer from the formulation in
Eq. 6. The Me and B in the graph matching layer denote the edge afﬁnity matrix from Eq. 7 and the vertex afﬁnity matrix
from Eq. 11 respectively.

4. Graph Matching Network and GMTracker

In this section, we will describe the details of our Graph
Matching Network and our GMTracker. As shown in Fig. 3,
the pipeline of our Graph Matching Network consists of
three parts:
(1) feature encoding in detection and track-
let graphs; (2) feature enhancement by cross-graph Graph
Convolutional Network (GCN) and (3) differentiable graph
matching layer. We will describe these three parts step by
step and show how we integrate them into a tracker (GM-
Tracker) in the following.

4.1. Feature Encoding in Two Graphs

We utilize a pre-trained ReIDentiﬁcation (ReID) net-
work followed by a multi-layer perceptron (MLP) to gen-
erate the appearance feature ai
D for each detection Di. The
appearance feature aj
T of the tracklet Tj is obtained by av-
eraging all the appearance features of detections before.

4.2. Cross-Graph GCN

Similar to [8, 42, 63], we only adopt a GCN module be-
tween the graph GD and graph GT to enhance the feature,
and thus it is called Cross-Graph GCN.

The initial vertex features on detection graph and track-
let graph are the appearance features on the vertices, i.e., let
T . Let h(l)
h(0)
i = ai
j be the feature

D and h(0)

j = aj

and h(l)

i

of vertex i ∈ GD and vertex j ∈ GT in the l-th propagation,
respectively. We deﬁne the aggregation weight coefﬁcient
w(l)
i,j in GCN as the appearance and geometric similarity be-
tween vertex i and vertex j:
i,j = cos(h(l)
w(l)

j ) + IoU(gi, gj)

, h(l)

(12)

i

where cos(·, ·) means the cosine similarity between input
features and IoU(·, ·) denotes the Intersection over Union of
two bounding boxes. For a detection vertex i, gi is the cor-
responding detection bounding box deﬁned in Section 3.1.
As for a tracklet vertex j, we estimate the bounding box
gj in current frame t by Kalman Filter [22] motion model
with a constant velocity. Note that we only consider the
appearance feature similarity in weight wi,j when the cam-
era moves, since the motion model cannot predict reliable
future positions in these complicated scenes.

We use summation as the aggregation function,
i = (cid:80)

i.e.,
j and the vertex features are updated

i,j h(l)
w(l)

j∈GT

m(l)
by:

h(l+1)
i

= MLP(h(l)

i +

(cid:107)h(l)

i (cid:107)2m(l)
i
(cid:107)m(l)
i (cid:107)2

),

(13)

where we adopt message normalization proposed in [33] to
stabilize the training.

We apply l2 normalization to the ﬁnal features after
cross-graph GCN and denote it as hi. Then we use hi as

FeatureExtractorFeatureExtractorDetection GraphDetection Graph ConstructionTracklet GraphTracklet Graph ConstructionCross-graph GCN ModuleGraph Matching LayerDetection GraphTracklet GraphFeatureExtractorMeanMeanFeatureExtractorMatchingScore MapSolveQPGradientsthe feature of vertex i in graph GD, and construct the edge
feature for edge (i, i(cid:48)) with hi,i(cid:48) = l2([hi, hi(cid:48)]), where [·]
denotes concatenation operation. The similar operation is
also applied to the tracklet graph GT . In our implementa-
tion, we only apply GCN once.

4.3. Differentiable Graph Matching Layer

After enhancing the vertex features and constructing the
edge features on graph GD and GT , we meet the core com-
ponent of our method:
the differentiable graph matching
layer. By optimizing the QP in Eq. 6 from quadratic afﬁnity
matrix M and vertex afﬁnity matrix B, we can derive the
optimal matching score vector x and reshape it back to the
shape nd × nt to get the matching score map X.

Since we ﬁnally formulate the graph matching problem
as a QP, we can construct the graph matching module as a
differentiable QP layer in our neural network. Since KKT
conditions are the necessary and sufﬁcient conditions for
the optimal solution x∗ and its dual variables, we could de-
rive the gradient in backward pass of our graph matching
layer based on the KKT conditions and implicit function
theorem, which is inspired by OptNet [2]. Please refer to
the appendix for the detailed derivation of the gradients in
graph matching layer. In our implementation, we adopt the
qpth library [2] to build the graph matching module. In the
inference stage, to reduce the computational cost and ac-
celerate the algorithm, we solve the QP using the CVXPY
library [11] only for forward operation.

For training, we use weighted binary cross entropy Loss:

L =

−1
ndnt

nd(cid:88)

nt(cid:88)

i=1

j=1

kyi,j log(ˆyi,j) + (1 − yi,j) log(1 − ˆyi,j),

(14)
where ˆyi,j denotes the matching score between detection
Di and tracklet Tj, and yi,j is the ground truth indicating
whether the object belongs to the tracklet. k = (nt − 1) is
the weight to balance the loss between positive and nega-
tive samples. Besides, due to our QP formulation of graph
matching, the distribution of matching score map X is rela-
tively smooth. We adopt softmax function with temperature
τ to sharpen the distribution of scores before calculating the
loss:

ˆyi,j = Softmax(xi,j, τ ) =

exi,j /τ
j=1 exi,j /τ

(cid:80)nt

,

(15)

where xi,j is the original matching score in score map X.

4.4. Inference Details

Due to the continuous relaxation, the output of the QP
layer may not be binary. To get a valid assignment, we use
the greedy rounding strategy to generate the ﬁnal permu-
tation matrix from the predicted matching score map, i.e.,
we match the detection with the tracklet with the maximum

score. After matching, like DeepSORT [64], we need to
handle the born and death of tracklets. We ﬁlter out the de-
tection if it meets one of the three criteria: 1) All the appear-
ance similarities between a detection and existing tracklets
are below a threshold σ. 2) It is far away from all tracklets.
We set a threshold κ as the Mahalanobis distance between
the predicted distribution of the tracklet bounding box by
the motion model and the detection bounding box in pixels,
called motion gate. 3) The detection bounding box has no
overlap with any tracklets. Here, besides the Kalman Filter
adopted to estimate the geometric information in Section
4.2, we apply an Enhanced Correlation Coefﬁcient (ECC)
[12] in our motion model additionally to compensate the
camera motion. Besides, we apply the IoU association be-
tween the ﬁltered detections and the unmatched tracklets by
Hungarian algorithm to compensate some incorrect ﬁlter-
ing. Then the remaining detections are considered as a new
tracklet. We delete a tracklet if it has not been updated since
δ frames ago, called max age.

5. Experiments

5.1. Datasets

We carry out all experiments on MOT16 [43] and
MOT17 [43] benchmark. The videos in this benchmark
were taken under various scenes, light conditions and frame
rates. Occlusion, motion blur, camera motion and distant
pedestrians are also crucial problems in this benchmark.
Among all the evaluation metrics, Multiple Object Track-
ing Accuracy (MOTA) [23] and ID F1 Score (IDF1) [49]
are the most general metrics in the MOT task. Since MOTA
is mostly dominated by the detection metrics false posi-
tive and false negative, and our graphing matching method
mainly tries to tackle the associations between detected ob-
jects, we pay more attention to IDF1 than the MOTA metric.

5.2. Implementation Details

Training. Following other MOT methods [8, 18], we adopt
Tracktor [6] to reﬁne the public detections. For the ReID
network used for feature extraction, we use a ResNet50
[16] backbone followed by a global average pooling layer
and a fully connected layer with 512 channels. We fur-
ther normalize the output feature with the l2 normaliza-
tion. We pre-train the ReID network on Market1501 [74],
DukeMTMC [49] and CUHK03 [35] datasets jointly, fol-
lowing the setting of [8]. The parameters of the ReID net-
work will be frozen after pre-training. Then we add two
trainable fully connected layers with 512 channels to get
appearance features. Our implementation is based on Py-
Torch [45] framework. We train our model on an NVIDIA
RTX 2080Ti GPU. Adam [25] optimizer is applied with
β1 = 0.9 and β2 = 0.999. The learning rate is 5×10−5
and weight decay is 10−5. The temperature τ in Eq. 15 is

GM App. Enc. GCN Geo

Inter.

IDF1 ↑ MOTA ↑ MT ↑ ML ↓

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

68.1
70.0
70.2
70.4
70.6
71.5

68.9
71.6
71.7
72.0
72.1
73.0

62.1
62.3
62.2
62.3
62.2
62.3

62.9
64.0
64.0
64.2
63.3
63.8

556
555
555
554
556
555

678
669
666
671
676
672

371
374
374
375
374
375

361
365
364
368
364
361

FP ↓

1923
1735
1744
1741
1748
1741

11440
7095
6816
7701
10888
9579

FN ↓

ID Sw. ↓

124480
124292
124301
124298
124305
124298

112853
113392
113778
112370
111869
111683

1135
1128
1140
1058
1399
1017

723
659
724
627
716
570

Table 1: Ablation studies on different proposed components on MOT17 val set.

Train w/ GM Inference w/ GM IDF1 MOTA

(cid:88)

(cid:88)
(cid:88)

69.5
70.2
71.5

62.1
62.3
62.3

Table 2: Ablation study on the graph matching layer.

10−3.
Inference. Our inference pipeline mostly follows Deep-
SORT [64], except that we use general graphing matching
instead of bipartite matching for association. As in Deep-
SORT, we set the motion gate κ as 9.4877, which is at the
0.95 conﬁdence of the inverse χ2 distribution. The feature
similarity threshold σ is set to 0.6 in the videos taken by the
moving camera, and 0.7 when we use geometric informa-
tion in the cross-graph GCN module for videos taken by the
static camera. The max age δ is 100 frames.
Post-Processing. To compare with other state-of-the-art
ofﬂine methods, we perform a linear interpolation within
the tracklet as post-processing to compensate the missing
detections, following [8, 18]. This effectively reduces the
false negatives introduced by upstream object detection al-
gorithm.

tion (Geo); (iv) the linear interpolation method between the
same object by the time (Inter.).

As shown in Table 1, compared with the DeepSORT
baseline (the ﬁrst row), which associates the detections and
the tracklets by Hungarian Algorithm, the graph matching
method gets a gain of 1.9 IDF1 without interpolation, and a
gain of 2.7 IDF1 and 1.1 MOTA with the linear interpola-
tion. The results show the effectiveness of the second-order
edge-to-edge information.

Appearance feature reﬁnement and GCN improve about
0.6 IDF1 compared to the untrained model. Geometric
information provides about 1.0 additional gain on IDF1,
which highlights the importance of geometric information
in the MOT task. Finally, compared with the baseline, our
method achieves about 3.4 and 0.2 improvements on IDF1
metric and MOTA metric, respectively. With interpolation,
the gain becomes even larger: about 4.1 improvements on
IDF1 and 0.9 on MOTA.

As shown in Table 2, we get the gain of 1.3 and 2.0 IDF1
compared with only removing the graph matching layer in
training stage and in both training and inference stage, re-
spectively. The results demonstrate the effectiveness of our
differentiable graph matching layer and the importance of
training all components in our tracker jointly.

5.3. Ablation Study

5.4. Discussions

We conduct ablation studies of the proposed components
in our method on the MOT17 dataset. Following [8], we
divide the training set into three parts for three-fold cross-
validation, called MOT17 val set, and we conduct the ex-
periments under this setting both in the ablation study sec-
tion and the discussions section. We ablate each component
we propose: (i) graph matching module built as a QP layer
(GM); (ii) MLP trained on MOT dataset to reﬁne the ap-
pearance features (App. Enc.); (iii) the cross-graph GCN
module (GCN) with and without using geometric informa-

In this part, we discuss two main design choices of our
method on MOT17 val set. When we construct the track-
let graph, there are some different intra-tracklet feature ag-
gregation methods. Moreover, how to create and delete a
tracklet is important for an online tracker.
Intra-tracklet feature aggregation. In the tracklet graph
GT , each vertex represents a tracklet. And the vertex fea-
ture aj
T is the aggregation of the appearance features of all
detections in tracklet Tj. Here, we compare several aggre-
gation methods, including mean, moving average and only

Methods

IDF1 MOTA

Methods

Reﬁned Det IDF1 ↑ MOTA ↑ FP ↓

FN ↓ IDS ↓

Last Frame
Moving Average α = 0.5
Moving Average α = 0.8
Mean

69.1
69.9
70.1
70.0

62.3
62.3
62.3
62.3

Table 3: Ablation studies on different intra-tracklet feature
aggregation methods.

Max age (frames)

30

50

80

100

150

Hungarian Algorithm 67.2
68.0

Graph Matching

67.9
69.3

68.1
69.7

68.1
70.0

67.3
70.0

Table 4: The inﬂuence of max age δ on IDF1 .

using the last frame of the tracklet. The results are shown
in Table 3. The IDF1 is 0.9 lower when only using the last
frame of the tracklet. The results also reveal that when we
utilize all the frame information, no matter using the simple
average or the moving average, their impact is not signiﬁ-
cant. To make our method simple and effective, we ﬁnally
use the simple average method to aggregate the appearance
features within a tracklet.
Tracklet death strategies. As for removing a trajectory
from association candidates, our basic strategy is that if the
tracklet has not been associated with any detections in δ
frames, the tracklet will be removed and not be matched any
more. Table 4 shows that larger max age δ, which means
more tracklet candidates, yields better IDF1 score. It shows
the effectiveness of our method from another aspect that
our GMTracker can successfully match the tracklets disap-
peared about ﬁve seconds ago. On the contrary, when the
max age increases to 150 frames, the IDF1 will drop 0.8 us-
ing Hungarian algorithm, which indicates our graph match-
ing can deal with long-term tracklet associations better.

5.5. Comparison with State-of-the-Art Methods

We compare our GMTracker with other state-of-the-art
methods on MOT16 and MOT17 test sets. As shown in
Table 5, when we apply Tracktor [6] to reﬁne the pub-
lic detection, the online GMTracker achieves 63.8 IDF1
on MOT17 and 63.9 IDF1 on MOT16, outperforming the
other online trackers. To compare with CenterTrack [76],
we use the same detctions, called GMT CT, and the IDF1
is 66.9 on MOT17 and 68.6 on MOT16. With the sim-
ple linear interpolation, called GMT simInt in Table 5, we
also outperform the other ofﬂine state-of-the-art trackers on
IDF1. With exactly the same visual inter- and extrapolation
as LifT [18], called GMT VIVE in Table 5, the MOTA is
comparable with LifT. After utilizing the CenterTrack de-
tections and linear interpolation, the GMTCT simInt im-
proves the SOTA on both MOT16 and MOT17 datasets.
In appendix, we report more detailed performance on other

MOT17

GNMOT (O∗) [34]
FAMNet (O) [10]
JBNOT (O∗) [17]
Tracktor++ (O) [6]
Tracktor++v2 (O) [6]
GNNMatch (O) [44]
GSM Tracktor (O) [39]
CTTrackPub (O) [76]
GMTracker(Ours) (O)
GMT CT(Ours) (O)

-
-
-
Tracktor
Tracktor
Tracktor
Tracktor

47.0
48.7
50.8
52.3
55.1
56.1
57.8
CenterTrack 59.6
63.8
CenterTrack 66.9

Tracktor

52.6
TPM [46]
58.1
eTC17 [60]
61.7
MPNTrack [8]
65.2
Lif TsimInt [18]
65.6
LifT [18]
GMT simInt (Ours)
65.9
GMT VIVE (Ours)
65.9
GMTCT simInt (Ours) CenterTrack 68.7

-
-
Tracktor
Tracktor
Tracktor
Tracktor
Tracktor

MOT16

Tracktor++v2 (O) [6]
GNNMatch (O) [44]
GSM Tracktor (O)[39]
GMTracker(Ours) (O)
GMT CT (Ours) (O)

Tracktor
Tracktor
Tracktor
Tracktor

54.9
55.9
58.2
63.9
CenterTrack 68.6

TPM [46]
47.9
eTC [60]
56.1
MPNTrack [8]
61.7
Lif TsimInt [18]
64.1
LifT [18]
64.7
GMT simInt (Ours)
66.2
GMT VIVE (Ours)
66.6
GMTCT simInt (Ours) CenterTrack 70.6

-
-
Tracktor
Tracktor
Tracktor
Tracktor
Tracktor

50.2
52.0
52.6
53.5
56.3
57.0
56.4
61.5
56.2
61.5

54.2
51.9
58.8
58.2
60.5
59.0
60.2
65.0

56.2
56.9
57.0
55.9
62.6

51.3
49.2
58.6
57.5
61.3
59.1
61.1
66.2

29316 246200 5273
14138 253616 3072
31572 232659 3050
12201 248047 2072
8866 235449 1987
12283 228242 1957
14379 230174 1485
14076 200672 2583
8719 236541 1778
14059 200655 2415

13739 242730 1824
36164 232783 2288
17413 213594 1185
16850 217944 1022
14966 206619 1189
20395 209553 1105
13142 209812 1675
18213 177058 2200

2394 76844
3235 74784
4332 73573
2371 77545
5104 62377

2701 85504
8400 83702
4949 70252
4249 72868
4844 65401
6021 68226
3891 66550
6355 54560

617
564
475
531
787

569
606
354
335
389
341
503
701

Table 5: Comparison with state-of-the-art methods on
MOT16 and MOT17 test set. (O) denotes online methods.
(O∗) denotes near-online methods.

metrics, e.g., HOTA [41].

6. Conclusion

In this paper, we propose a novel learnable graph match-
ing method for multiple object tracking task, called GM-
Tracker. Our graph matching method focuses on the re-
lationship between tracklets and detections. Taking the
second-order edge-to-edge similarity into account, our
tracker is more accurate and robust in the MOT task, espe-
cially in crowded videos. To make the graph matching mod-
ule end-to-end differentiable, we relax the QAP formulation
into a convex QP and build a differentiable graph matching
layer in our Graph Matching Network. The experiments
of ablation study and comparison with other state-of-the-art
methods both show the effectiveness of our method.

Acknowledgements
This work was supported in part by the National Key R&D
Program of China(No. 2018YFB1004602), the National
Natural Science Foundation of China (No. 61836014, No.
61773375). The authors would like to thank Roberto Hen-
schel for running their post-processing code for us.

Appendix

A. Gradients of the Graph Matching Layer

As described in Section 4.3 of our main paper, the gra-
dients of the graph matching layer we need for backward
can be derived from the KKT conditions with the help of
the implicit function theorem. Here, we show the details of
deriving the gradients.

For a quadratic programming (QP), the standard formu-

lation is as

IDF1 MOTA MT ML

FP

FN

ID Sw.

Baseline
Ours
Oracle

68.1
71.5
77.2

62.1
62.3
62.6

556
555
545

371
375
368

1923
1741
1730

124480
124298
124287

1135
1017
14

Table A: Comparison between the baseline, our GMTracker
and the Oracle tracker on MOT17 val set.

minimize
x

1
2
subject to G(θ)x ≤ h(θ)

x(cid:62)Q(θ)x + q(θ)(cid:62)x

(A)

A(θ)x = b(θ).

So the Lagrangian is given by

L(x, ν, λ) =

1
2

x(cid:62)Qx + λ(cid:62)(Gx − h) + q(cid:62)x + ν(cid:62)(Ax − b),
(B)

where, ν and λ are the dual variables.
The (x∗, λ∗, ν∗) are the optimal solution if and only if they
satisfy the KKT conditions:

∇xL(x∗, λ∗, ν∗) = 0
Qx∗ + q + A(cid:62)ν∗ + G(cid:62)λ∗ = 0
Ax∗ − b = 0
diag(λ∗)(Gx∗ − h) = 0
Gx∗ − h ≤ 0
λ∗ ≥ 0.

We deﬁne the function

g(x, λ, ν, θ) =





∇xL(x, λ, ν, θ)
diag(λ)λ(cid:62)(G(θ)x − h(θ))
A(θ)x − b(θ)

Figure A: Results on IDF1, FP, FN and ID Switch metrics
under different threshold σ of the feature similarity to create
a new tracklet.

B. Pseudo-code of Our Algorithm

(C)

1, T t

2, · · · , Dt
nd

To make our algorithm clear and easy to understand,
we show the pseudo code of our GMTracker algorithm
in Alg. A. The input of the algorithm is the detection
} and tracklet set T t =
set Dt = {Dt
1, Dt
{T t
2, · · · , T t
}, deﬁned in Section 4.1 of our main pa-
nt
per. And the output is the new tracklet set T t+1 to be asso-
ciated in the next frame. The motion gate κ is 9.4877. The
feature similarity threshold σ is 0.6 in the videos taken by
the moving camera, and 0.7 in the videos taken by the static
camera. The max age δ is 100 frames.



 ,

(D)

and the optimal solution x∗, λ∗, ν∗ satisfy the euqation
g(x∗, λ∗, ν∗, θ) = 0.
According to the implicit function theorem, as proven in [4],
the gradients where the primal variable x and the dual vari-
ables ν and λ are the optimal solution, can be formulated
as

Jθx∗ = −Jxg(x∗, λ∗, ν∗, θ)−1Jθg(x∗, λ∗, ν∗, θ),

(E)

where, Jxg(x∗, λ∗, ν∗, θ) and Jθg(x∗, λ∗, ν∗, θ) are the Ja-
cobian matrices. Each element of them is the partial deriva-
tive of function g with respect to variable x and θ, respec-
tively.

C. Additional Experiments and Analyses

C.1. Comparison with the Oracle Tracker

To explore the upper bound of the association method,
we compare our method with the ground truth association,
called the Oracle tracker. The results on MOT17 val set are
shown in Table A. There is a gap of 5.7 IDF1 and about
1000 ID Switches between our online GMTracker and the
Oracle tracker.

Another observation is that on some metrics, which are
extremely relevant to detection results, like MOTA, FP and
FN, the gaps between the baseline, our method and the Or-

0.50.60.70.8707172IDF1w/ Inter.w/o Inter.0.50.60.70.82500500075001000012500FPw/ Inter.w/o Inter.0.50.60.70.8115000120000125000FNw/ Inter.w/o Inter.0.50.60.70.8800100012001400ID Switchw/ Inter.w/o Inter.acle tracker are relatively small. That is why we mainly
concern with the metrics reﬂecting the association results,
such as IDF1 and ID Switch.

C.2. Discussions

Tracklet born strategies. In our GMTracker, the tracklet
born strategies mostly follow DeepSORT, but we also make
some improvements to make these strategies more suitable
for our approach, as described in Section 4.4 in our main
paper. Among the three criteria to create a new tracklet, we
ﬁnd that the threshold σ is the most sensitive hyperparame-
ter in our method. We conduct experiments with different σ,
and its inﬂuence on IDF1, FP, FN and ID Switch is shown
in Fig. A.

C.3. Detailed Performance

As shown in Table B, the results on more metrics, such as
HOTA, AssA, DetA, LocA, MT, ML are provided for better
comparison.

Algorithm A: GMTracker Algorithm

Input: Dt, T t
Output: T t+1
i ∈ Dt do
for Dt
ai,t
D ← MLPa(ReID(It
h(0)
i ← ai,t
D
j ∈ T t do
for Dk

for T t

i))

(j) ∈ T t
j do
a(j),k
D ← MLPa(ReID(Ik

(j)))

T ← mean(a(j),k
aj,t
D )
h(0)
j ← aj,t
for l ≤ lmax do
for Dt

T

for T t

i

i ∈ Dt do
i ← A({w(l)
m(l)
i ← F(h(l)
h(l+1)
j ∈ T t do
m(l)
j ← A({w(l)
j ← F(h(l)
h(l+1)
i(cid:48) ∈ Dt do

i,j h(l)

| j ∈ GT })
j
, m(l)
i )

i

i,j h(l)
| i ∈ GD})
j , m(l)
j )

, hi(cid:48) ← h(l+1)

i(cid:48)

for Dt

i, Dt

for T t

for Dt

i

hi ← h(l+1)
hi,i(cid:48) ← l2([hi, hi(cid:48)])
i , T t
i(cid:48) ∈ T t do
hj ← h(l+1)
hj,j(cid:48) ← l2([hj, hj(cid:48)])
j ∈ Dt, T t do
i, T t
e ← h(cid:62)
Mu,v
i,i(cid:48)hj,j(cid:48)
Bi,j ← h(cid:62)
i hj

j

, hj(cid:48) ← h(l+1)

j(cid:48)

match ← graph matching(Me, B)
for Dt

j ∈ Dt, T t do
i, T t
if IoU(Dt
i, T t
κ or cos(Dt

j ) ≤ 0 or d(Dt
i, T t
j ) < σ then
delete(match(i, j))

i, T t

j ) >

for Dt

i, T t
if IoU(Dt

j ∈ Dt
i, T t

unmatch, T t
j ) ≥ 0.3 then
matchadd ← Hungarian(IoU(Dt

unmatch do

i, T t

j ))

for Dt

i, T t

j ∈ Dt, T t do

j

if match(i, j) or matchadd(i, j) then
j + {Dt
i}
).update()

T t+1
j ← T t
motion(T t+1
i ∈ Dt
unmatch then
T t+1
new ← {Dt
i}
j .last update > δ then
delete(T t
j )

if Dt

if T t

return T t+1

Methods

Reﬁned Det

IDF1 ↑ HOTA↑ MOTA ↑ MT↑ ML↓ FP ↓

FN ↓

IDS ↓ AssA↑ DetA↑ LocA↑

GNMOT (O∗) [34]
FAMNet (O) [10]
JBNOT (O∗) [17]
Tracktor++ (O) [6]
Tracktor++v2 (O) [6]
GNNMatch (O) [44]
GSM Tracktor (O) [39]
CTTrackPub (O) [76]
GMTracker(Ours) (O)
GMT CT(Ours) (O)

-
-
-
Tracktor
Tracktor
Tracktor
Tracktor
CenterTrack
Tracktor
CenterTrack

TPM [46]
eTC17 [60]
MPNTrack [8]
Lif TsimInt [18]
LifT [18]
GMT simInt (Ours)
GMT VIVE (Ours)
GMTCT simInt (Ours) CenterTrack

-
-
Tracktor
Tracktor
Tracktor
Tracktor
Tracktor

Tracktor++v2 (O) [6]
GNNMatch (O) [44]
GSM Tracktor (O)[39]
GMTracker(Ours) (O)
GMT CT (Ours) (O)

Tracktor
Tracktor
Tracktor
Tracktor
CenterTrack

TPM [46]
eTC [60]
MPNTrack [8]
Lif TsimInt [18]
LifT [18]
GMT simInt (Ours)
GMT VIVE (Ours)
GMTCT simInt (Ours) CenterTrack

-
-
Tracktor
Tracktor
Tracktor
Tracktor
Tracktor

47.0
48.7
50.8
52.3
55.1
56.1
57.8
59.6
63.8
66.9

52.6
58.1
61.7
65.2
65.6
65.9
65.9
68.7

54.9
55.9
58.2
63.9
68.6

47.9
56.1
61.7
64.1
64.7
66.2
66.6
70.6

-
-
41.3
42.1
44.8
45.4
45.7
48.2
49.1
52.0

41.5
44.9
49.0
50.7
51.3
51.1
51.2
54.0

44.6
44.6
45.9
48.9
53.1

36.7
42.0
48.9
49.6
50.8
51.2
51.6
55.2

MOT17

50.2
52.0
52.6
53.5
56.3
57.0
56.4
61.5
56.2
61.5

54.2
51.9
58.8
58.2
60.5
59.0
60.2
65.0

19.3 32.7 29316 246200 5273
19.1 33.4 14138 253616 3072
19.7 35.8 31572 232659 3050
19.5 36.6 12201 248047 2072
21.1 35.3
8866 235449 1987
23.3 34.6 12283 228242 1957
22.2 34.5 14379 230174 1485
26.4 31.9 14076 200672 2583
8719 236541 1778
21.0 35.5
26.3 32.1 14059 200655 2415

22.8 37.5 13739 242730 1824
23.1 35.5 36164 232783 2288
28.8 33.5 17413 213594 1185
28.6 33.6 16850 217944 1022
27.0 33.6 14966 206619 1189
29.0 33.6 20395 209553 1105
26.5 33.2 13142 209812 1675
29.4 31.6 18213 177058 2200

MOT16

56.2
56.9
57.0
55.9
62.6

51.3
49.2
58.6
57.5
61.3
59.1
61.1
66.2

20.7 35.8
22.3 35.3
22.0 34.5
20.3 36.6
26.7 31.0

18.7 40.8
17.3 40.3
27.3 34.0
25.4 34.7
27.0 34.0
27.5 34.4
26.7 33.3
29.6 30.4

2394
3235
4332
2371
5104

2701
8400
4949
4249
4844
6021
3891
6355

76844
74784
73573
77545
62377

85504
83702
70252
72868
65401
68226
66550
54560

617
564
475
531
787

569
606
354
335
389
341
503
701

-
-
39.8
41.7
45.1
45.2
47.0
47.8
53.9
55.1

40.9
47.0
51.1
54.9
54.7
55.1
55.1
56.4

44.6
43.7
46.7
53.7
56.3

34.6
44.5
51.1
53.3
53.1
55.1
55.3
57.8

-
-
43.3
42.9
44.9
45.9
44.9
49.0
44.9
49.4

42.5
43.3
47.3
47.1
48.3
47.6
47.8
52.0

44.8
45.8
45.4
44.6
50.4

39.3
39.9
47.1
46.5
48.9
47.7
48.5
53.1

-
-
80.2
80.9
81.8
81.5
80.9
81.7
81.8
81.8

80.0
79.4
81.5
81.5
81.3
81.2
81.3
81.5

82.0
81.7
81.1
82.1
81.8

79.1
78.8
81.7
81.9
81.4
81.5
81.5
81.5

Table B: Detailed comparison with state-of-the-art methods on MOT16 and MOT17 test set. (O) denotes online methods.
(O∗) denotes near-online methods.

References

[1] Yonathan Aﬂalo, Alexander Bronstein, and Ron Kimmel. On
convex relaxation of graph isomorphism. Proceedings of the
National Academy of Sciences, 112(10):2942–2947, 2015. 4
[2] Brandon Amos and J. Zico Kolter. OptNet: Differentiable
optimization as a layer in neural networks. In ICML, 2017.
2, 3, 6

[3] Yaakov Bar-Shalom, Thomas E Fortmann, and Peter G Ca-

ble. Tracking and data association, 1990. 2

[4] Shane Barratt.

On the differentiability of

the solu-
arXiv preprint

tion to convex optimization problems.
arXiv:1804.05098, 2018. 3, 9

[5] Jerome Berclaz, Francois Fleuret, Engin Turetken, and Pas-
cal Fua. Multiple object tracking using k-shortest paths op-
timization. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence, 33(9):1806–1819, 2011. 1, 2

[6] Philipp Bergmann, Tim Meinhardt, and Laura Leal-Taixe.
Tracking without bells and whistles. In ICCV, 2019. 2, 6, 8,
11

[7] Alex Bewley, Zongyuan Ge, Lionel Ott, Fabio Ramos, and
Ben Upcroft. Simple online and realtime tracking. In ICIP,
2016. 1, 2

[8] Guillem Bras´o and Laura Leal-Taix´e. Learning a neural
In CVPR, 2020. 1, 2,

solver for multiple object tracking.
5, 6, 7, 8, 11

[9] Wongun Choi. Near-online multi-target tracking with aggre-

gated local ﬂow descriptor. In ICCV, 2015. 2

[10] Peng Chu and Haibin Ling. FAMNet: Joint learning of fea-
ture, afﬁnity and multi-dimensional assignment for online
multiple object tracking. In ICCV, 2019. 8, 11

[11] Steven Diamond and Stephen Boyd. CVXPY: A python-
embedded modeling language for convex optimization. The
Journal of Machine Learning Research, 17(1):2909–2913,
2016. 6

[12] Georgios D Evangelidis and Emmanouil Z Psarakis. Para-
metric image alignment using enhanced correlation coefﬁ-
cient maximization. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 30(10):1858–1865, 2008. 6
[13] Francois Fleuret, Jerome Berclaz, Richard Lengagne, and
Pascal Fua. Multicamera people tracking with a probabilistic
occupancy map. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 30(2):267–282, 2007. 2

[14] Seyed Hamid Rezatoﬁghi, Anton Milan, Zhen Zhang, Qin-
feng Shi, Anthony Dick, and Ian Reid. Joint probabilistic
data association revisited. In ICCV, 2015. 2

[15] Juris Hartmanis. Computers and intractability: a guide to

the theory of NP-completeness. 1982. 3

[16] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
In CVPR,

Deep residual learning for image recognition.
2016. 6

[17] Roberto Henschel, Yunzhe Zou, and Bodo Rosenhahn. Mul-
tiple people tracking using body and joint detections.
In
CVPR Workshops, 2019. 8, 11

[18] Andrea Hornakova, Roberto Henschel, Bodo Rosenhahn,
and Paul Swoboda. Lifted disjoint paths with application
in multiple object tracking. In ICML, 2020. 1, 2, 6, 7, 8, 11

[19] Min Hu, Saad Ali, and Mubarak Shah. Detecting global mo-

tion patterns in complex videos. In ICPR, 2008. 2

[20] Weiming Hu, Xinchu Shi, Zongwei Zhou, Junliang Xing,
Haibin Ling, and Stephen Maybank. Dual L1-normalized
context aware tensor power iteration and its applications to
Interna-
multi-object tracking and multi-graph matching.
tional Journal of Computer Vision, 128(2):360–392, 2020.
3

[21] Xiaolong Jiang, Peizhao Li, Yanjing Li, and Xiantong
Zhen. Graph neural based end-to-end data association frame-
arXiv preprint
work for online multiple-object tracking.
arXiv:1907.05315, 2019. 2

[22] Rudolph Emil Kalman. A new approach to linear ﬁltering
and prediction problems. ASME Journal of Basic Engineer-
ing, 82(1):35–45, 1960. 5

[23] Rangachar Kasturi, Dmitry Goldgof,

Padmanabhan
Soundararajan, Vasant Manohar, John Garofolo, Rachel
Bowers, Matthew Boonstra, Valentina Korzhova, and Jing
Zhang. Framework for performance evaluation of face, text,
and vehicle detection and tracking in video: Data, metrics,
IEEE Transactions on Pattern Analysis and
and protocol.
Machine Intelligence, 31(2):319–336, 2008. 6

[24] Chanho Kim, Fuxin Li, Arridhana Ciptadi, and James M
Rehg. Multiple hypothesis tracking revisited. In ICCV, 2015.
2

[25] Diederik P Kingma and Jimmy Ba. Adam: A method for

stochastic optimization. In ICLR, 2014. 6

[26] Tjalling C. Koopmans and Martin Beckmann. Assignment
problems and the location of economic activities. Economet-
rica, 25(1):53–76, 1957. 2, 3

[27] Harold W Kuhn. The Hungarian method for the assignment
problem. Naval research logistics quarterly, 2(1-2):83–97,
1955. 2, 3

[28] Cheng-Hao Kuo and Ram Nevatia. How does person identity

recognition help multi-person tracking? In CVPR, 2011. 1

[29] Long Lan, Dacheng Tao, Chen Gong, Naiyang Guan, and
Zhigang Luo. Online multi-object tracking by quadratic
pseudo-boolean optimization. In IJCAI, 2016. 2

[30] Eugene L. Lawler. The quadratic assignment problem. Man-

agement Science, 9(4):586–599, 1963. 2, 3

[31] Laura Leal-Taix´e, Cristian Canton-Ferrer, and Konrad
Schindler. Learning by tracking: Siamese CNN for robust
target association. In CVPR Workshops, 2016. 1, 2

[32] Marius Leordeanu and Martial Hebert. A spectral technique
for correspondence problems using pairwise constraints. In
ICCV, 2005. 3

[33] Guohao Li, Chenxin Xiong, Ali Thabet, and Bernard
Ghanem. DeeperGCN: All you need to train deeper GCNs.
arXiv preprint arXiv:2006.07739, 2020. 5

[34] Jiahe Li, Xu Gao, and Tingting Jiang. Graph networks for
multiple object tracking. In WACV, pages 719–728, 2020. 2,
8, 11

[35] Wei Li, Rui Zhao, Tong Xiao, and Xiaogang Wang. Deep-
ReID: Deep ﬁlter pairing neural network for person re-
identiﬁcation. In CVPR, 2014. 6

[36] Tianyi Liang, Long Lan, and Zhigang Luo. Enhancing
the association in multi-object tracking via neighbor graph.
arXiv preprint arXiv:2007.00265, 2020. 2

[37] Tsung-Yi Lin, Piotr Doll´ar, Ross Girshick, Kaiming He,
Bharath Hariharan, and Serge Belongie. Feature pyramid
networks for object detection. In CVPR, 2017. 1

[38] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
Piotr Doll´ar. Focal loss for dense object detection. In ICCV,
2017. 1

[39] Qiankun Liu, Qi Chu, Bin Liu, and Nenghai Yu. GSM:
Graph similarity model for multi-object tracking. In IJCAI,
2020. 2, 8, 11

[40] Zhichao Lu, Vivek Rathod, Ronny Votel, and Jonathan
Huang. RetinaTrack: Online single stage joint detection and
tracking. In CVPR, 2020. 2

[41] Jonathon Luiten, Aljosa Osep, Patrick Dendorfer, Philip
H. S. Torr, Andreas Geiger, Laura Leal-Taix´e, and Bastian
Leibe. HOTA: A higher order metric for evaluating multi-
object tracking. International Journal of Computer Vision,
129(2):548–578, 2021. 8

[42] Cong Ma, Yuan Li, Fan Yang, Ziwei Zhang, Yueqing
Zhuang, Huizhu Jia, and Xiaodong Xie. Deep association:
End-to-end graph-based learning for multiple object track-
ing with conv-graph neural network. In ICMR, 2019. 5
[43] Anton Milan, Laura Leal-Taix´e, Ian Reid, Stefan Roth, and
Konrad Schindler. MOT16: A benchmark for multi-object
tracking. arXiv preprint arXiv:1603.00831, 2016. 6

[44] Ioannis Papakis, Abhijit Sarkar, and Anuj Karpatne. GC-
NNMatch: Graph convolutional neural networks for multi-
object tracking via sinkhorn normalization. arXiv preprint
arXiv:2010.00067, 2020. 8, 11

[45] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer,
James Bradbury, Gregory Chanan, Trevor Killeen, Zeming
Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An
imperative style, high-performance deep learning library. In
NeurIPS, 2019. 6

[46] Jinlong Peng, Tao Wang, Weiyao Lin, Jian Wang, John
See, Shilei Wen, and Erui Ding. TPM: Multiple object
tracking with tracklet-plane matching. Pattern Recognition,
107:107480, 2020. 2, 8, 11

[47] Hamed Pirsiavash, Deva Ramanan, and Charless C Fowlkes.
Globally-optimal greedy algorithms for tracking a variable
number of objects. In CVPR, 2011. 2

[48] Donald Reid. An algorithm for tracking multiple targets.
IEEE Transactions on Automatic Control, 24(6):843–854,
1979. 2

[49] Ergys Ristani, Francesco Solera, Roger S. Zou, Rita Cuc-
chiara, and Carlo Tomasi. Performance measures and a data
set for multi-target, multi-camera tracking. In ECCV Work-
shops, 2016. 6

tiple object tracking. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 43(1):104–119, 2019. 1

[54] Paul Swoboda, Carsten Rother, Hassan Abu Alhaija, Dag-
mar Kainmuller, and Bogdan Savchynskyy. A study of La-
grangean decompositions and dual ascent solvers for graph
matching. In CVPR, 2017. 3

[55] Siyu Tang, Bjoern Andres, Miykhaylo Andriluka, and Bernt
Schiele. Subgraph decomposition for multi-target tracking.
In CVPR, 2015. 2

[56] Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, and Bernt
Schiele. Multi-person tracking by multicut and deep match-
ing. In ECCV, 2016. 2

[57] Philip HS Torr. Solving markov random ﬁelds using semi

deﬁnite programming. In AISTATS, 2003. 3

[58] Mario Vento and Pasquale Foggia. Graph matching tech-
In Image Processing: Con-
niques for computer vision.
cepts, Methodologies, Tools, and Applications, pages 381–
421. 2013. 2

[59] Bing Wang, Gang Wang, Kap Luk Chan, and Li Wang.
Tracklet association by online target-speciﬁc metric learning
IEEE Transactions on
and coherent dynamics estimation.
Pattern Analysis and Machine Intelligence, 39(3):589–602,
2016. 2

[60] Gaoang Wang, Yizhou Wang, Haotian Zhang, Renshu Gu,
and Jenq-Neng Hwang. Exploit the connectivity: Multi-
object tracking with trackletnet. In ACM MM, 2019. 8, 11

[61] Runzhong Wang, Junchi Yan, and Xiaokang Yang. Learning
combinatorial embedding networks for deep graph matching.
In ICCV, 2019. 3

[62] Shaofei Wang and Charless C Fowlkes. Learning opti-
mal parameters for multi-target tracking with contextual
International Journal of Computer Vision,
interactions.
122(3):484–501, 2017. 1

[63] Xinshuo Weng, Yongxin Wang, Yunze Man, and Kris Ki-
tani. GNN3DMOT: Graph neural network for 3D multi-
object tracking with 2D-3D multi-feature learning. CVPR,
2020. 5

[64] Nicolai Wojke, Alex Bewley, and Dietrich Paulus. Simple
online and realtime tracking with a deep association metric.
In ICIP, 2017. 1, 2, 6, 7

[65] Yihong Xu, Aljosa Osep, Yutong Ban, Radu Horaud, Laura
Leal-Taix´e, and Xavier Alameda-Pineda. How to train your
deep multi-object tracker. In CVPR, 2020. 1, 2

[66] Bo Yang, Chang Huang, and Ram Nevatia. Learning afﬁni-
ties and dependencies for multi-target tracking using a CRF
model. In CVPR, 2011. 2

[67] Bo Yang and Ram Nevatia. An online learned CRF model

[50] Mikel Rodriguez, Saad Ali, and Takeo Kanade. Tracking in

for multi-target tracking. In CVPR, 2012. 1

unstructured crowded scenes. In ICCV, 2009. 2

[51] Amir Sadeghian, Alexandre Alahi, and Silvio Savarese.
Tracking the untrackable: Learning to track multiple cues
with long-term dependencies. In ICCV, 2017. 2

[52] Christian Schellewald and Christoph Schn¨orr. Probabilistic
In CVPR

subgraph matching based on convex relaxation.
Workshops, 2005. 3

[53] ShiJie Sun, Naveed Akhtar, HuanSheng Song, Ajmal S
Mian, and Mubarak Shah. Deep afﬁnity network for mul-

[68] Ju Hong Yoon, Chang-Ryeol Lee, Ming-Hsuan Yang, and
Kuk-Jin Yoon. Online multi-object tracking via structural
constraint event aggregation. In CVPR, 2016. 2

[69] Tianshu Yu, Runzhong Wang, Junchi Yan, and Baoxin Li.
Learning deep graph matching with channel-independent
embedding and Hungarian attention. In ICLR, 2020. 3
[70] Amir Roshan Zamir, Afshin Dehghan, and Mubarak Shah.
GMCP-Tracker: Global multi-object tracking using general-
ized minimum clique graphs. In ECCV, 2012. 2

[71] Andrei Zanﬁr and Cristian Sminchisescu. Deep learning of

graph matching. In CVPR, 2018. 4

[72] Li Zhang, Yuan Li, and Ramakant Nevatia. Global data as-
sociation for multi-object tracking using network ﬂows. In
CVPR, 2008. 2

[73] Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng,
and Wenyu Liu. FairMOT: On the fairness of detection and
re-identiﬁcation in multiple object tracking. arXiv preprint
arXiv:2004.01888, 2020. 2

[74] Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jing-
dong Wang, and Qi Tian. Scalable person re-identiﬁcation:
A benchmark. In ICCV, 2015. 6

[75] Feng Zhou and Fernando De la Torre. Factorized graph

matching. In CVPR, 2012. 3

[76] Xingyi Zhou, Vladlen Koltun, and Philipp Kr¨ahenb¨uhl.

Tracking objects as points. In ECCV, 2020. 2, 8, 11

[77] Ji Zhu, Hua Yang, Nian Liu, Minyoung Kim, Wenjun Zhang,
and Ming-Hsuan Yang. Online multi-object tracking with
dual matching attention networks. In ECCV, 2018. 1

