Searching for pulsars using image pattern recognition

W. W. Zhu1, A. Berndsen1, E. C. Madsen1, M. Tan1, I. H. Stairs1, A. Brazier 2, P.
Lazarus3, R. Lynch4, P. Scholz4, K. Stovall5,21, S. M. Ransom6, S. Banaszak7, C. M.
Biwer7,19, S. Cohen5, L. P. Dartez5, J. Flanigan7, G. Lunsford5, J. G. Martinez5, A. Mata5,
M. Rohr7, A. Walker7, B. Allen8,7,17, N. D. R. Bhat9,10, S. Bogdanov11, F. Camilo11,13, S.
Chatterjee2, J. M. Cordes2, F. Crawford12, J. S. Deneva 20, G. Desvignes3, R. D.
Ferdman4,14, P. C. C. Freire3, J. W. T. Hessels15,16, F. A. Jenet5, D. L. Kaplan7, V. M.
Kaspi4, B. Knispel8,17, K. J. Lee3, J. van Leeuwen15,16, A. G. Lyne14, M. A. McLaughlin18,
X. Siemens7, L. G. Spitler3, A. Venkataraman13

3
1
0
2

c
e
D
8
1

]

M

I
.
h
p
-
o
r
t
s
a
[

5
v
6
7
7
0
.
9
0
3
1
:
v
i
X
r
a

 
 
 
 
 
 
– 2 –

ABSTRACT

In the modern era of big data, many ﬁelds of astronomy are generating huge
volumes, the analysis of which can sometimes be the limiting factor in research.
Fortunately, powerful data-mining techniques have been developed by computer
scientists, ready to be applied to various ﬁelds. In this paper, we present a novel
artiﬁcial intelligence (AI) program that identiﬁes pulsars from recent surveys

1Department of Physics and Astronomy, 6224 Agricultural Road, University of British Columbia, Van-

couver, BC, V6T 1Z1, Canada; zhuww@phas.ubc.ca, berndsen@phas.ubc.ca

2Astronomy Department, Cornell University, Ithaca, NY 14853, USA
3Max-Planck-Institut f¨ur Radioastronomie, Auf dem H¨ugel 69, D-53121 Bonn, Gemnay

4Department of Physics, McGill University, Montreal, QC H3A 2T8, Canada
5Center for Advanced Radio Astronomy, University of Texas at Brownsville, Brownsville, TX 78520, USA
6NRAO, Charlottesville, VA 22903, USA

7Center for Gravitation, Cosmology and Astrophysics. University of Wisconsin Milwaukee, Milwaukee,

WI 53211 USA

8Max-Planck-Institut f¨ur Gravitationsphysik, D-30176 Hanover, Germany
9International Centre for Radio Astronomy Research, Curtin University, Bentley, WA 6102, Australia

10Centre for Astrophysics & Supercomputing, Swinburne University, Hawthorn, Victoria 3122, Australia
11Columbia Astrophysics Laboratory, Columbia University, New York, NY 10027, USA
12Department of Physics and Astronomy, Franklin and Marshall College, PO Box 3003, Lancaster, PA

17604-3003, USA

13Arecibo Observatory, HC3 Box 53995, Arecibo, PR 00612, USA

14University of Manchester, Jodrell Bank Observatory, Macclesﬁeld, Cheshire SK11 9DL, UK
15ASTRON, the Netherlands Institute for Radio Astronomy, Postbus 2, NL-7900 AA, Dwingeloo, the

Netherlands

16Astronomical Institute ‘Anton Pannekoek,’ University of Amsterdam, Science Park 904, NL-1098 XH

Amsterdam, the Netherlands

17Leibniz Universit¨at Hannover, D-30167 Hannover, Germany
18Department of Physics, West Virginia University Morgantown, WV 26506, USA

19Department of Physics, Syracuse University, NY 13244 USA
20Naval Research Laboratory, 4555 Overlook Ave SW, Washington, DC 20375

21Department of Physics and Astronomy, University of New Mexico, Albuquerque, NM, 87131

– 3 –

∼

using image pattern recognition with deep neural nets—the PICS (Pulsar Image-
based Classiﬁcation System) AI. The AI mimics human experts and distinguishes
pulsars from noise and interference by looking for patterns from candidate plots.
Diﬀerent from other pulsar selection programs which searched for expected pat-
terns, the PICS AI is taught the salient features of diﬀerent pulsars from a set
of human-labeled candidates through machine learning. The training candidates
are collected from the Pulsar Arecibo L-band Feed Array Survey. The informa-
tion from each pulsar candidate is synthesized in four diagnostic plots, which
consist of image data with up to thousands of pixels. The AI takes these data
from each candidate as its input and uses thousands of such candidates to train
9000 neurons. The deep neural networks in this AI system grant it superior
its
ability in recognizing various types of pulsars as well as their harmonic signals.
The trained AI’s performance has been validated with a large set of candidates
from a diﬀerent pulsar survey, the Green Bank North Celestial Cap survey. In
this completely independent test, PICS ranked 264 out of 277 pulsar-related can-
didates, including all 56 previously known pulsars and 208 of their harmonics,
in the top 961 (1%) of 90008 test candidates, missing only 13 harmonics. The
ﬁrst non-pulsar candidate appears at rank 187, following 45 pulsars and 141 har-
monics. In other words, 100% of the pulsars were ranked in the top 1% of all
candidates, while 80% were ranked higher than any noise or interference. The
performance of this system can be improved over time as more training data
are accumulated. This AI system has been integrated into the PALFA survey
pipeline and has discovered six new pulsars to date.

Subject headings: pulsars:general — methods: data analysis — methods:numerical
— techniques: image processing

1.

Introduction

Recent pulsar surveys such as the Pulsar Arecibo L-band Feed Array (PALFA; Cordes et al.

2006; Kaspi 2012; Lazarus 2013) survey and the Green Bank North Celestial Cap (GBNCC;
in prep.) survey are expected to ﬁnd—or are already
Lynch et al. 2013, K. Stovall et al.
ﬁnding—hundreds of new pulsars among many millions of pulsar candidates. However, the
surveys are polluted by radio frequency interference (RFI) that makes it hard to pick out
the pulsars from the candidates produced using simple metrics such as the signal-to-noise
ratio (SNR). Human experts can look at diagnostic plots of the candidates and identify the
pulsars more successfully, but it is impractical to inspect millions of candidates that way.

– 4 –

In this paper, we present an artiﬁcial intelligence (AI) system that emulates human experts
and classiﬁes pulsar candidates using patterns from four standard diagnostic plots—the
pulse proﬁle, time-versus-phase plot, frequency-versus-phase plot, and dispersion-measure
(DM) curve (see Section 2.1 for details). This system was trained with PALFA candidates
classiﬁed by human experts, its parameters were tuned using a cross-validation set of can-
didates, and its ﬁnal performance was compared against a large set of manually identiﬁed
candidates from the GBNCC survey (project code: GBT09C-057). Both the PALFA and
GBNCC candidates are generated using a pipeline that runs the PRESTO1 search software
(Ransom 2001; Ransom et al. 2002), but other pulsar-searching pipelines, such as the one in
the Einstein@Home project (Allen et al. 2013; Knispel et al. 2013), can produce these same
diagnostic plots, so it is possible to apply our AI system to most pulsar surveys with little
modiﬁcation.

In the past, several successful candidate-sifting schemes have been developed for diﬀerent
surveys. Some involve graphical interfaces which allow for the interactive selection of pulsar
candidates based on the pulse period and SNR (Faulkner et al. 2004). Some apply heuristic
scoring algorithms to the candidate diagnostic plots, using statistical tests, curve ﬁtting,
and a graphical interface to visually inspect the distribution of pulsar scores in the scores’
parameter space (Keith et al. 2009). An eﬀective sorting scheme was constructed (Lee 2009;
Lee et al. 2013) using a combination of six carefully designed heuristic scores. One particular
score compares the candidate’s pulse frequency against the frequency distribution drawn from
a large sample of the survey candidates; recognizing that the majority of candidates are RFI,
this single histogram removes a large fraction of the repeatedly observed RFI, especially
harmonics of the 60 Hz interference from the power supply. Eatough et al. (2010) improved
the method of Keith et al. (2009) by applying machine learning (ML) to the heuristic scores.
Instead of inspecting the score distribution by eye, they fed the scores into an artiﬁcial
neural network and trained the network to classify candidates. Bates et al. (2012) expanded
the number of scores used by ﬁtting the candidate’s features with diﬀerent model curves,
and also used a neural network to combine these scores. Another comprehensive score-
based system (Kaspi 2012; Lazarus 2013) was developed and has been used to ﬁnd many
pulsars for the PALFA survey. Most recently, Knispel et al. (2013) designed algorithms that
check for outstanding signals in some of the diagnostic plots by binning the plots with pre-
designed patterns in the shape of vertical lines or area patches, and applied them in the
Einstein@Home project.

Notably, these previous candidate-sifting systems use heuristically-designed functions

1http://www.cv.nrao.edu/

sransom/presto/

∼

– 5 –

which characterize patterns in the diagnostic plots into a set of scores. Such score-based
systems have some advantages. They make good use of the candidate’s properties like period,
DM and computed information like the signiﬁcance of the periodicity and the width/height
of the summed proﬁle. However, such systems often rely on matching candidates with some
pre-designed patterns, such as a Gaussian-like peak. Some of these designed patterns do not
match pulsars with multiple pulse peaks well. When these designed patterns do match the
candidate, they tend to average out the details and small features in the diagnostic plot.
These small features can sometimes be very useful in distinguishing pulsars from RFI. Some
score-based systems select pulsar candidates by drawing the score distributions from known
pulsars. Such systems may be biased against rare types of pulsars, such as pulsars with
wider proﬁles, skewed DM curves or low signal strength.

In contrast, the PICS AI applies image pattern recognition directly to the original diag-
nostic plots, and determines what patterns to match through machine learning. Using the
original diagnostic plots allows the AI to utilize the detailed information in the plots. Using
ML allows us to train the AI with a wide variety of pulsar candidates. A signiﬁcant fraction
of our training candidates are pulsars or their harmonics with weak, broad, or multi-peak
pulse proﬁles (for example, a harmonic signal at 1/2 period of the fundamental would be
a factor of
period would have two
peaks). As a result, the PICS AI is sensitive not only to pulsar candidates but also to their
harmonics. In fact, one of the new pulsars discovered by PICS, PSR J1914+08 (Figure 2),
was identiﬁed from its 6/11, 6/7 and 2/3 harmonics. In this case, the fundamental frequency
was missed by the PALFA pipeline due to RFI. Finally, an important feature of the PICS AI
is that it neglects information such as the candidate’s period, DM and sigma value. Instead,
it focuses on only the details in the normalized diagnostic plots. This feature makes it a
good complement to the score-based systems.

2 broader and 1/√2 weaker and a harmonic at 2

∼

×

This paper introduces a new approach to the candidate-sifting problem using supervised
ML based on image patterns. In Section 2, we describe the candidate plots which contain the
physical features distinguishing them as pulsars, and we detail the data-preparation process
required to adapt these plots as inputs to the ML system. We also describe the structure
of the PICS AI system. In Section 3, we detail the AI’s test performance and results from
classifying GBNCC data. Finally in Section 4, we discuss the results and the AI system’s
unique strengths and features.

– 6 –

2.

Implementation

The diagnostic plot that a human expert relies on to identify a pulsar contains several
important subplots. In order to combine the information from these subplots, we constructed
the PICS AI with a two-layer hierarchy (Figure 1). The ﬁrst layer consists of a group of
ML classiﬁers trained to look at diﬀerent subplots, providing a pool of experts capable of
recognizing pulsar patterns; while the second layer combines the classiﬁcations from ﬁrst
layer to classify the candidate. Each ﬁrst-layer classiﬁer rates how “pulsar-like” a particular
subplot of the candidate is with a number between 0 (not a pulsar) and 1 (a pulsar), giving a
prediction matrix that is the output of the ﬁrst layer. These votes are fed into a second-layer
classiﬁer which learns to properly weight these votes and forms a ﬁnal consensus on how
pulsar-like a candidate is.

In this section we provide a detailed discussion of the PICS AI implementation2, starting

from the most important subplots that the AI uses.

2.1. Four features

Our goal is to train an AI program that mimics human experts. Here we ﬁrst introduce
how the PALFA pipeline ﬁnds pulsar candidates and then discuss which features human
experts look for when identifying promising candidates.

The PALFA survey uses the 7-beam L-band (1.4 GHz) receiver at the Arecibo obser-
vatory. The survey takes 5-minute snapshots of the Galactic plane. In recent observations,
data were taken using the Mock spectrometer, which has a 65.5 µs sampling time and 960 fre-
quency channels covering 322.6 MHz of bandwidth. The data from each beam are analyzed
using a PRESTO-based pulsar-searching pipeline.

Pulsar radio emission is a broadband signal originating from kpc distances. Therefore,
the signal is dispersed by the ionized interstellar medium. This causes the low-frequency
components of a signal to arrive later than the ones at higher frequency. The delay between
the two frequencies ν1 and ν2 is proportional to DM(ν−2
ν−2
2 ) where DM, the dispersion
measure, is the column density of free electrons along the line of sight. This is non-zero and
remains nearly constant for a pulsar. Because of this, the wide-band signals of pulsars need
to be recorded into narrow frequency channels to prevent smearing by dispersion. PRESTO
ﬁrst searches for narrow band or non-dispersed periodic signals in the raw channelized data

1 −

2The AI source code and a trained classiﬁer are accessible on githubhttps://github.com/zhuww/ubc_AI

– 7 –

·

and removes them, since they are likely terrestrial. Then it generates time series for an array
of DM values by adding appropriate time delays to each frequency channel. The range of
cm−3, which easily encompasses the expected Galactic
DM searched is 0 <DM< 5000 pc
interstellar dispersion for all lines of sight in the PALFA survey (Cordes & Lazio 2001) and
also maintains sensitivity to any possible highly-dispersed extragalactic radio sources (e.g.
Lorimer et al. 2007; Thornton et al. 2013, L. Spitler et al. in prep.). After that it searches
for periodic signals in the “de-dispersed” time series using a Fourier Transform and harmonic
summing, and picks out the signiﬁcant periodicity peaks in the power spectrum (see Ransom
2001 for details). For each candidate periodicity, PRESTO folds the de-dispersed time series
into a 3D data cube (time interval, phase and channel frequency) using the period, and
stores the folded data in a pfd format ﬁle together with data descriptors such as the date
and coordinates of the observation. These pfd ﬁles can later be converted to candidate
diagnostic plots using routines in the PRESTO software suite.

Direct inspection of the folded 3D data array is inconvenient, so it is usually projected
into several lower-dimensional plots. The PRESTO routine show pfd is designed to display
the pfd ﬁle as a candidate plot that contains several of these projections. Figure 2 is an
example pulsar candidate plot, with the most important subplots highlighted.

1. Summed proﬁle: One can sum all frequency channels and time intervals to create
a summed intensity-versus-phase pulse proﬁle. Pulse proﬁles of real pulsars are usually
composed of one or several very narrow peaks, though there are some known pulsars with
pulse proﬁles which are broad and/or contain multiple peaks.

2. Time-versus-phase plot: This plot is obtained by summing the data over the
diﬀerent frequency channels, leaving the pulse proﬁle as averaged over subintervals of the
observation. One or more vertical stripes in this plot indicates that a pulsed signal was
observed for the duration of the scan.

3. Frequency-versus-phase plot: Summing the data cube over the diﬀerent time
intervals leaves the frequency-versus-phase plot. The presence of one or more persistent
vertical lines in this subplot, as in the example, indicates a broadband signal during the
pulsed emission, as expected for a pulsar candidate. However, scintillation caused by the
interstellar medium may aﬀect a pulsar’s signal, degrading the signal in some frequency
channels.

4. DM curve: The plotting program searches over a range of DMs around the best
reported value. For each DM trial, it de-disperses the data cube accordingly and calculates
the χ2 of the de-dispersed pulse proﬁle against a horizontal line ﬁt. The DM curve is a plot
of the trial DMs against their corresponding χ2 values. A large χ2 value indicates that the

– 8 –

periodic signal deviates strongly from simple white noise. The DM curve of a real pulsar
will likely peak at a non-zero value unless aﬀected by strong RFI.

These are the four most important features that human experts look at when classifying

candidates, and they are the inputs to our AI system.

2.2. Data preparation

The application of pattern recognition to pulsar candidates is not a trivial task. This is
because the integration time of survey observations may vary, and the number of phase bins
with which the data are folded also changes depending on the period of the candidate. As a
result, the number of data points in the subplots can vary from candidate to candidate. For
ML to work, we need to carefully prepare these data, and make sure the input data blocks
for a particular classiﬁer have identical shape and size.

We extract the key feature plots from the pfd ﬁles. These plots consist of 1D data arrays
(summed proﬁle or DM curve) and 2D data (time/frequency-versus-phase plot). The sizes
of the data arrays vary from candidate to candidate. For example, some candidates have
64 phase bins, while others may have only 32 bins; some candidates have 50 time steps,
while others have 100. This is a result of the search pipeline, which uses fewer phase bins
and more time steps for short period pulsars, and more phase bins with fewer time steps
for long period pulsars—in either case, the number of pulses coherently added in each time
interval is roughly the same. For ML to work on these plots, the features should have the
same size and scale, so we down-sample or interpolate the data to a uniform size: 64 bins for
the summed proﬁle, 64
48 depending on the classiﬁcation algorithm, see Table 1
for details) bins for the time/frequency-versus-phase plot, and 60 bins for the DM curve.
Piecewise linear interpolation was used for the 1D data and spline interpolation3 for the 2D
data. We also normalize the data to zero median and unit variance to remove the absolute
scale of the plots. For the 2D image arrays, normalization is performed line-by-line along
the phase axis, which removes instrumental variations over the course of the observation
and across the observing band, but maintains the variance in signal across the phase—this
should be dominated by the pulsar signal.

64 (or 48

×

×

Once the plots are resized and normalized, we can use them to train a ML system.
However, the thousands of pixels in the 2D plots may slow down the training process for
In this cases the number of internal
the support vector machine (Section 2.3) classiﬁers.

3The 2D interpolation routine in scipy.ndimage.interpolation.map coordinates was used.

– 9 –

parameters requiring training is proportional to the size of the input data, so to speed up
the computation, the image features (time/frequency versus phase plot) are characterized
by a principal component analysis4 (PCA). The PCA algorithm uses a singular value de-
composition to compute a limited set of basis images from the training data. An unknown
candidate’s data, then, has a new representation as the set of eigenvalues resulting from the
projection onto these basis images. In this way, we can compress the image features from
thousands of numbers per candidate to only 24 numbers5, greatly reducing the number of
parameters required in a ﬁt. Figure 3 shows the original 2D images of a pulsar candidate and
their reconstructions from the most signiﬁcant 24 PCA components. One can see that the
PCA reconstructions capture the important features in the images, especially the vertical
stripes. By ﬁltering out the weaker PCA components we also reduce the noise level in the
reconstructed image. Some image classiﬁers trained much faster with PCA-compressed fea-
tures and perform as well as those trained with full-sized images. However, we did not apply
the PCA-compression for the deep-neural-net classiﬁers because they perform signiﬁcantly
better without it.

One last challenge was to prevent the AI from developing any phase-related bias. In
principle, a candidate’s pulse may appear at any phase, but in practice many candidates
peak at phase 0 or 0.5. We found that an earlier version of the AI failed to detect some
good candidates that peaked away from phase 0 or phase 0.5. We resolved this problem by
shifting candidates’ strongest peaks to phase 0.5 before feeding them to the AI. The resulting
AI was tested with candidates of random phase and showed no sign of bias.

In summary, the data-preparation procedure for all candidates fed into the AI system
involves rescaling the data to zero median and unit variance, shifting the peak intensity
to a phase of 0.5, down-sampling or interpolating onto a standardized grid and, optionally,
applying PCA.

2.3. Two-Layer AI: a committee of experts

The ﬁrst layer of PICS (see Figure 1) uses a combination of two ML algorithms on
each of the four subplots, giving eight ratings in total. The set of ML algorithms includes
artiﬁcial neural networks (ANN; see Section 2.4 for detail), convolutional neural networks

4http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html

5The number of singular vectors used in the decomposition is a free parameter in the AI system, but is

ﬁxed by optimizing the performance in cross-validation tests.

– 10 –

(CNN6; see Section 2.5 for detail) and support vector machine (SVM7; an algorithm that
ﬁnds a direction in the parameter space on which the distance between the two classes
of data points are maximized; see Chang & Lin (2011) and Pedregosa et al. (2011) for the
implementation details). The choice of which algorithms to use was determined both by their
individual performance and their beneﬁt to the overall performance. It should be noted that
the combinations were the result of extensive testing, including using other standard ML
algorithms such as decision trees. In the end, PICS uses an ANN with one hidden layer of
logistic units and a radial kernel SVM classiﬁer on each of the 1D subplots (pulse proﬁle,
DM curve), and it uses a CNN and SVM on each of the 2D subplots (pulse interval versus
phase, pulse frequency versus phase).

In the second layer, we combine the scores from the eight ﬁrst-layer classiﬁers using
another ML classiﬁer (Figure 1). Several algorithms are appropriate for this purpose, and
we tested logistic regression (LR), ANN and SVM algorithms. The best performance was
from a simple LR with L2 penalty8, and this option was chosen for the second layer of the
PICS system. The LR algorithm assigns each of the ﬁrst-layer scores (xi) a weight (wi),
computes their weighted sum, and converts this sum to a probability using the logistic
function

P =

1
1 + e− Pi wixi .

(1)

The LR algorithm ﬁnds the best set of wi that minimize the classiﬁcation errors in the
training data.

In order to test how well the classiﬁer can perform on new data, we employ a validation
test. To do this, we ﬁrst split the labelled PALFA data into a training set and a test, or
cross-validation, set. We use the training data to train the classiﬁers and the validation data
to test them. Because the validation data were set aside from the beginning, this test result
is a reliable estimate of the classiﬁer’s performance.

A commonly used performance metric is the F1 score, deﬁned as the harmonic average
of precision p (the ratio of true pulsars to the total number of candidates ranked as a pulsar)
and completeness c (the ratio of ranked true pulsars to the total number of pulsars in the
validation set)

F1 =

2pc
p + c

.

(2)

6https://github.com/aberndsen/NeuralNetwork

7http://scikit-learn.org/stable/modules/svm.html
8A L2 penalty means the algorithm also tries to minimize (Pi w2

i )/C, preventing the weights wi from

growing too large. C is a small control parameter.

– 11 –

The F1 score from validation tests may vary slightly from test to test due to random ﬂuc-
tuations. We run many iterations of training and testing in order to ﬁnd a reliable estimate
of it. Every iteration starts with randomly splitting the labeled data into new groups of
training and test data, so the new test will be diﬀerent from the previous one (See Table 1).

The classiﬁers in both layers of the system all have internal design parameters that
need to be ﬁxed. This is accomplished by a grid search over the possible values of the design
parameters, and is ﬁxed by the set that maximize the F1 score in a validation test. The
optimized parameters of the eight classiﬁers and their test performance on each feature plot
is listed in Table 1. The performance is also depicted in Figure 1, which shows the overall
structure of the PICS system.

Finally, in this particular searching-for-pulsars problem, it might seem that we should
prefer a classiﬁer with higher completeness than precision. In general, maximizing the preci-
sion alone would result in a cautious AI system which would miss a lot of true pulsars, while
maximizing completeness would bring in a lot of false positives. When training the PICS,
we preferred a balanced AI that maximizes F1. This is because we want to improve the AI’s
completeness when we add more varieties of pulsars to the training data and we also want
to improve its precision when we add more RFI candidates, to emphasize on one metric will
hinder our ability to improve the other. When applying the AI in practice, we can adjust its
completeness and precision to our needs by changing the cut on P , the AI probability score.

2.4. The neural networks

In the ﬁrst layer of PICS, we used the ANN for the 1D subplots and the CNN for
the 2D subplots, they are diﬀerent types of neural network.
In this Section, we brieﬂy
introduce some terminology common to the understanding of both these neural networks.
For the detail implementation of LR and SVM please refer to Pedregosa et al. (2011) and
Chang & Lin (2011).

Biologically, a neural network is a collection of neurons connected by synapses, where
individual neurons respond, or “ﬁre”, to diﬀerent inputs. An artiﬁcial neural network is
the computer analog, modelled as a function of many inputs (synapses) to produce a single
output. These functions are often called activation functions h, and typically have ﬁnite
range for classiﬁcation purposes. The most commonly used activation functions are the
logistic (sigmoid) function h(x) = 1/(1 + exp(
x)) and the hyperbolic tangent function
h(x) = tanh(x). The former maps any ﬂoat input to a number between 0 and 1, the latter
maps to a number between

1 and 1.

−

−

– 12 –

·

In the ANN, these neurons are distributed among diﬀerent layers. All neurons in a
single layer l receive the same inputs from the previous layer a(l−1), but weights the signals
with a unique set of parameters (w(l)
for the ith neuron in the lth layer). Thus neurons in the
i
same layer “ﬁre” under diﬀerent circumstances as determined by their weights w(l)
i and bias
bi, h(w(l)
a(l−1) + bi). The weights w(l) connect the outputs of a previous layer in the ANN
i
to the input of the next, serving the role of the synapses in the neural network. A given layer
with N(l) neurons accepting N(l−1) inputs has (N(l) + 1)
N(n−l) weights, or synapses, which
makes the number of synapses in a given network much larger than the number of neurons.
A synapse, however, controls how much weight is given to a single input, so the collection
of synapses forms the pattern which will produce an activation. Since there are so many
synapses in an ANN, there are a lot of patterns that the system can respond to. In practice
the patterns are not known, so the weights are initialized randomly and are determined
through the training process.

×

We train the neural net with manually labeled candidates through back-propagation.
The goal of training is to minimize the diﬀerence between the neural net output and the
human classiﬁcations y (0 for RFI and 1 for pulsar) of the candidates. This diﬀerence, the
prediction error δ(l) = a(l)
y, can be formed for each layer l, and the correction to the
jth weight in the ith neuron ∆(l)
. The exact
functional form depends on the choice of activation function and error function. In practice,
∆(l)
i,j is often averaged over an ensemble of candidates, since training is done in batches for
computational eﬃciency.

i,j is determined as a function of a and δ(l+1)

−

j

2.5. The convolutional neural network

The best individual classiﬁer in the collection of experts is the convolutional neural
network trained on the frequency versus phase plot. This deep, 5-layer network is simi-
lar to LeNet-5 (LeCun et al. 1998), a system proven to be very successful in recognizing
handwritten digits. This CNN also represents the state of the art in machine learning and,
as such, warrants a detailed description of its structure and an explanation of its superior
performance in the candidate-selection process.

The CNN is a powerful pattern recognition system capable of analysing large 2D images
directly without any compression. Therefore, PCA compression, which was necessary for the
SVM image data inputs, was not applied to the inputs of the CNN.

In the ﬁrst layer of the CNN, the input image is fed to groups of neurons with shared
weights. We scan the input image with a sliding window to get a set of sub-images. The

– 13 –

neurons with shared weights each look at one of these sub-images and become active if certain
feature as deﬁned by the shared weights is detected from it. The diﬀerent groups of neurons
are used to detect diﬀerent features. This process can also be viewed as convolving the
input image with a set of small image kernels, or features, and then applying the hyperbolic
tangent activation function to form a set of feature maps. Speciﬁcally, the kth feature map
is given by

hk = tanh (cid:0)(W k

x) + b(cid:1) ,

∗

(3)

where W k is the feature kernel, x is the input image, and b is a bias term. The number of
kernels, k, is a free parameter in the system, and it determines the richness in the represen-
tation of the data. The second layer of the CNN is a max-pooling process. This is a form of
down-sampling which bins the 2D feature maps and chooses the maximum value within each
bin. The main advantage is a reduction in computational complexity in subsequent layers,
though pooling also has the advantage of introducing translation invariance of the feature
W k across the bin (Boureau et al. 2010). These two steps are illustrated in Figure 4.

The output of the max-pooling layer is fed into another convolution layer for feature
detection and yet another max-pooling layer. This output is fed into the ﬁfth and ﬁnal layer,
a traditional, fully-connected ANN. While the previous four layers function to locate small-
scale features across the input images, the ﬁnal layer combines this information to detect
large-scale features and develop a global understanding of the original image.

×

×

48 pixels, convolve them with 20 diﬀerent 16

3 boxes and compresses the convolved image to a size 11

The CNN conﬁgurations for both the time-versus-phase plot and frequency-versus-phase
plot were the same. In the ﬁrst step (Figure 4 left panel), both CNNs take input images down-
16 image kernels, producing 20
sampled to 48
33. The subsequent max-pooling layer (Figure 4 right panel) divides
feature maps of size 33
each map into 3
11 by taking
×
the maximum in each box. The second convolution layer convolves 50 8
8 image kernels
2
shared across the 20 feature maps, resulting in 50 diﬀerent 4
×
max-pooling layer further compresses each feature map to an images of size 2
2. The result
is an array of 50
4 numbers characterizing the local, kernel-sized features of the original
image. The ﬁnal layer is a traditional, fully-connected artiﬁcial neural network consisting of
500 hidden logistic units which take these 200 numbers to compute one ﬁnal score.

×
4 feature maps. A second 2

×

×

×

×

×

There are 8820 artiﬁcial neurons distributed through the ﬁve layers of the CNN including
the ones in the image kernels. All neurons in this network are hyperbolic tangent functions
except the one that forms the ﬁnal output, which is chosen to be a sigmoid function in order
to map onto the classiﬁcation labels 0 and 1. The training of the neural net is to let these
synapses learn and store the patterns distinguishing pulsars from RFI. As an example, the
last layer has 105 weights connecting the 200 outputs of the second last layer to the 500

– 14 –

hidden neurons in the last layer. Each hidden neuron takes, as input, a weighted sum of the
200 outputs of the previous layer. All of the connection parameters are initialized randomly,
and then updated through the process of back-propagation.

The structure of the CNN is determined by the choice of image size, kernel size, number
of kernels, pooling size, and neural network size, these parameters are often called neural
net design or hyper-parameters. The best CNN design, as described above, is determined
through cross-validation tests. The labelled data are randomly shuﬄed and split into a
training set formed from 60% of the candidates and a validation set from the remaining
40%, and a large grid search is performed. For each choice of design parameters the CNN
is trained and the performance is characterized by computing its F1 score (see Section 2.3)
on the validation set. The CNN we used gives F1 = 92% when trained and tested on the
time-versus-phase plots, and F1 = 94% for the frequency-versus-phase plots (Table 1). After
optimizing the CNN design, the ﬁnal AI is trained with all training candidates in order to
maximize its sensitivity. The ﬁnal performance of the PICS system is tested with a set of
completely independent GBNCC data (see Section 3).

This CNN performs well on the frequency-versus-phase plot because a large fraction of
RFI is narrow-band emission. For continuous emission this RFI shows up as a horizontal line,
while burst-like or periodic RFI appears as a small dot. This is opposed to the broadband
pulsed signal of a pulsar, which shows up as a vertical stripe. Since the CNN excels at
detecting small-scale features, it can easily detect this form of RFI. A second reason this
classiﬁer is the best discriminant of pulsars is simply because there is more information in
the 2D plots than the 1D plots. For similar reasons, the algorithm can recognize and reject
burst-like RFI or signals that drift around in phase using the time-versus-phase plot.

This deep neural net is implemented using Theano (Bergstra et al. 2010), a computation
library for python which compiles numerical expressions to run eﬃciently on either CPU or
GPU architectures.

3. Results

We trained the PICS AI system with 3756 labelled PALFA candidates, among them 1659
are pulsars and their harmonics and 2097 are non-pulsars. There are only a few thousand
known pulsar/harmonic candidates in PALFA but millions of non-pulsars. We picked similar
numbers of pulsars and non-pulsars from the PALFA candidate pool as classiﬁed by other
human experts. The pulsar candidates include unique pulsars and also the same pulsar with
diﬀerent beam oﬀsets. To ensure that the AI is sensitive to both pulsars and their harmonics,

– 15 –

40% of the training pulsar candidates are harmonics of known pulsars.

∼

We also manually rated how “pulsar-like” is each of the four subplots for every training
candidate regardless of the candidate’s nature. This is because some RFI candidates may
have a good pulse proﬁle or DM curve, and we want to train the AI to recognize those the
good subplots even when the candidate itself is not a pulsar. The ﬁrst layer classiﬁers are
designed to recognize patterns in individual subplot in the diagnostic plots of the candidates.
Therefore they are trained to predict the “ratings” of the subplots for the training candidates,
not to predict the classiﬁcation of the candidates. In contrast, the second layer (LR) classiﬁer
is designed to predict whether or not a candidate is a pulsar based on the output from the
ﬁrst layer classiﬁers. Thus, it is trained with the classiﬁcations of the candidates, not with
“ratings” of their subplots.

To ensure that the trained classiﬁers can work on new data and to determine their best
initial parameters, we performed standard cross-validation tests (Section 2.5). We shuﬄed
and split the 3756 candidates into two groups, 60% for training and 40% for validating.
Furthermore, we repeated this shuﬄe, split, train and validate procedure 10 times to make
sure their performance on validation data is reliable and repeatable. The individual ﬁrst-
layer classiﬁers score in the range 86–94% F1 (with less than 1% RMS each) on the validation
data (Table 1). The second layer of PICS, a LR algorithm that combines the scores from
ﬁrst-layer classiﬁers to form a consensus vote, scored an average of 96% F1 (8% misses, 1%
false positives) on the validation data.

To further measure the AI’s performance and determine whether it can be generalized to
other surveys, we applied it to a large set of GBNCC candidates that was never seen by the AI
system during training. Like PALFA, the GBNCC survey uses the PRESTO search pipeline
and generates candidates in pfd format, but this survey was conducted using the Robert C.
Byrd Green Bank Telescope (GBT) instead of Arecibo, so the RFI environments of the two
surveys are expected to be diﬀerent; furthermore, GBNCC survey uses the 350 MHz receiver
instead of the 1400 MHz one, thus the DM curves of the GBNCC candidates are expected
to be slightly sharper than that of the PALFA candidates thanks to the more signiﬁcant
dispersion eﬀect in the lower frequency band. We applied the AI to 90008 manually labelled
GBNCC candidates. An initial test showed that the AI can sort all 56 pulsars in this data
set to the top 3.8%, and 68% of the pulsars to the top 0.16%. The ﬁrst RFI appeared in
rank 136, following 29 pulsars and 106 harmonics.

An inspection of the false positive candidates revealed many to be harmonics of the 60 Hz
power signal (see Figure 6 for an example). Table 2 lists the 6 most-populous frequency
ranges in a frequency histogram of all candidates, the majority of these candidates are
likely caused by the 60 Hz power supply. Although these frequencies comprise <1% of the

– 16 –

frequency domain searched by PRESTO, 24519 (roughly 27%) of the candidates fall into
It is standard practice to remove harmonics of 60 Hz for North
these frequency ranges.
American surveys; in spite of these eﬀorts, a signiﬁcant amount of such RFI remains. Using
96.2%) of
the image patterns in the diagnostic plots, our AI was able to reject majority (
this RFI, with the remaining false positives strongly resembling pulsars (see Figure 6 for an
example).

∼

In light of this observation, we adjusted the scores of all candidates using a Bayesian prior
on the pulse frequency f to reduce the score for the false-positive candidates in contaminated
frequency bins:

f ) =

P (p

|

P (p) + [P (f

.

p)] P (r)

(4)

P (p)
r)/P (f

|

|

|

Here P (p) is the probability of being a pulsar as previously scored by PICS, P (r) = 1
P (p),
while P (f
r) and P (f
p) are the probability density functions, or likelihoods, of RFI and pul-
|
|
r) can be well-approximated by sampling the frequency distribution
sars in frequency. P (f
of all test candidates, which is dominated by non-pulsar signals, especially those at 60 Hz and
its harmonics (Table 2). We approximate the prior distribution P (f
p) by median-ﬁltering
r), which removes spikes caused by RFI and leaves a distribution that reﬂects the survey
P (f
f ) < P (p), and the
sensitivity. At the harmonics of 60 Hz P (f
AI score is reduced. Away from the few aﬀected frequency bins (Table 2), P (f
p)
and the AI score is lightly aﬀected, with P (p

p), such that P (p

P (p).

P (f

P (f

≫

f )

r)

r)

−

≃

|

|

|

|

|

|

|

|

≃

The frequencies of the test candidates are binned from 0 Hz to 2000 Hz in steps of
0.5 Hz. Due to the limited bin size, all slow pulsars (f <1 Hz) are binned to the lowest two
bins, along with a lot of RFI. Since the underlying structure of the prior distributions is not
properly resolved in this domain, we did not apply the Bayesian rules to candidates with
f <1 Hz.

Figure 5 shows the distribution of GBNCC test candidates when sorted by P (p

f ), and
summarizes the performance of PICS. After applying the Bayesian rule (Equation (4)), all
56 pulsars and 208 of the 221 harmonics were sorted and placed into the top 961 (1%) of the
90008 candidates by the PICS system. The ﬁrst RFI candidate appeared rank 187, following
45 pulsars and 141 harmonics. The 13 harmonic candidates that were not sifted to the top
are mostly candidates with very low SNR and broad proﬁle.

|

A blind cross-validation test was performed using pulsars and RFI candidates collected
from the PALFA survey but never seen by the AI. We found that the same Bayesian rule
(Equation (4)) that worked for the GBNCC test also clearly reduced the false positive rate in
this cross-validation test. This indicates that the Bayesian rule can be generalized to surveys
other than GBNCC. Caution must be advised, though, since a weak pulsar candidate falling

– 17 –

in an RFI-contaminated frequency bin (Table 2) will be down-weighted by the Bayesian prior
and could be rejected. Fortunately, the chance of this happening is very small, since only a
0.7%, Table 2) are aﬀected signiﬁcantly by the prior. In light of this,
few frequency bins (
the Bayesian-rule RFI rejection is included only as an option in PICS and can be turned oﬀ.

∼

Despite the size and complexity of PICS, candidate classiﬁcation is a fast process be-
cause most of the individual classiﬁers simply apply dot products. The hard part of the
computation was already done during the training phase. It took
45 minutes to classify
0.7 CPU second per
the 90008 GBNCC candidates using a cluster of 24 2.7GHz CPUs,
candidate, though most of the time was spent on disk I/O and not all CPUs were used at
100% capacity. Using the same computer cluster, the AI would be able to classify a million
candidates in several hours.

∼

∼

The PICS AI has been integrated into the PALFA pipeline, such that we can query and
sort candidates using the AI rating on the cyberska.org web platform. With the help of the
AI, we have found many promising candidates over several weeks, six of which have been
conﬁrmed as new PALFA discoveries. Here we list the discovery parameters of these pulsars:

PSR J1914+08 (Figure 2) is a 146.68 ms pulsar with a DM of 289 pc/cm3.

PSR J1938+20 (Figure 7) is a 2.634 ms MSP with a DM of 237 pc/cm3.

PSR J1901+02 is a 885.24 ms pulsar with a DM of 403 pc/cm3.

PSR J1903+04 is a 1151.39 ms pulsar with a DM of 473 pc/cm3

PSR J1930+17 (Figure 8) is a 1609.72 ms pulsar with a DM of 232 pc/cm3

PSR J1854+00 (Figure 9) is a 767.334s pulsar with a DM of 533 pc/cm3

•

•

•

•

•

•

These pulsars are now the subject of on-going timing observations by Arecibo or Jodrell
Bank Observatories.

4. Discussion

PICS scores the candidates with a number between 0 and 1, a higher score corresponding
to a more pulsar-like candidate. When tested with the GBNCC data, the AI placed 100%
of the pulsars and 94% of the harmonics in the top 1% (Figure 5) of ranked candidates. By
rejecting 99% of the candidates, PICS can improve the speed of the candidate classiﬁcation
process for a human expert by a factor of &100. If we combine the AI with other ratings

– 18 –

or scores such as the signal-to-noise ratio, the sorting eﬃciency can be further improved,
making it possible for a few human experts to sift through millions of candidates. Such a
system can be very useful for existing and future pulsar surveys.

In the GBNCC test, PICS AI showed very good performance. However, in the top 1%
of the test candidates, there were still a few pulsars ranked below hundreds of non-pulsars.
These were pulsars with broad pulses and low signal-to-noise ratios, and were surpassed
by some strong RFI signals that also have broad features.
It seems that the PICS AI
could beneﬁt from training with more pulsar/RFI training candidates that have broad pulse
proﬁles.

Despite being limited by the quantity and diversity of the training data, the use of

image-pattern-based machine learning in PICS is a novel idea and has some advantages:

The AI uses an ensemble of ML algorithms, including a deep neural network composed
of many neurons and hidden weights which have the capability to recognize subtle or complex
features. By gathering more human-identiﬁed candidates from surveys, we will be able to
further improve the AI system. Speciﬁcally, if a survey encounters a new kind of RFI that
our system or a method based on analytical heuristics fails to reject, we can improve our AI
by incorporating examples of these RFI into our training data and retrain the system. Future
improvements to PICS include expanding the training set to candidates from both PALFA
and GBNCC surveys, and providing input capability for survey products from other search
software. Rather broadly, by increasing the pool of training candidates, we can improve the
accuracy of the PICS AI.

The PICS AI makes a classiﬁcation based solely on image patterns in the diagnostic
plots. A caveat—and, possibly, feature—is that because these plots are re-binned and nor-
malized to unit variance, the AI ignores the DM, period and pulse amplitude diﬀerences
between diﬀerent candidates. Although this lost information may be useful in some rare
cases (e.g.
ruling out millisecond candidates with high DM based on the DM smearing
timescale), this procedure forces PICS to learn the universal features of pulsars (broadband,
pulsed and dispersed emission) and helps it adapt to other surveys for which sensitivity in
candidate DM, frequency, and signal strength may diﬀer. PICS is also forced to rely less on
information than other score-based systems rely on, making it a good complement to them.

Being trained with many harmonic candidates with weak or multi-peak pulse proﬁles,
the PICS AI is also very good at ﬁnding such candidates. PICS has discovered six new pulsars
since being integrated into the PALFA survey pipeline. PSR J1938+20 was discovered as a
very weak candidate (5.0σ according to the version of PRESTO in the PALFA pipeline at the
time of discovery; Figure 7). This makes it the least signiﬁcant pulsar candidate conﬁrmed

– 19 –

by the PALFA survey. Such a candidate probably would not have been found by a candidate-
sorting method based on the signiﬁcance of the signal. PSR J1914+08 was discovered as a
multi-peaked harmonic, not as a candidate at its fundamental frequency. Other candidate
selection methods that rely on ﬁtting the pulse proﬁle with a single Gaussian curve would
likely down-rate these harmonics. Due to the presence of strong RFI, PSR J1930+17’s
DM curve (Figure 8) is signiﬁcantly skewed to the left. Similarly, PSR J1854+00’s DM
curve appears to be rather shallow and also slightly skewed. It is hard to characterize these
atypical DM curves using simple pre-designed functional forms. But our ML system was
able to recognize these DM patterns based on similar examples in the training data.

A caveat is that the current PICS AI is trained and tested with data from PALFA and
GBNCC survey, both of which have short exposure times of several hundred seconds per
pointing. The pulsar candidates observed by these surveys were rarely aﬀected signiﬁcantly
by scintillation or binary motion. In a survey with signiﬁcantly longer exposure time, scin-
tillation would make the pulsar signal patchy and discontinuous in the 2D subplots, while
binary motion may cause pulsar signals in the time-versus-phase plot to become curved,
indicating acceleration. For surveys and systems exhibiting scintillation and orbital acceler-
ation the AI will need to be retrained with suitable candidates. Alternatively, PICS could
be trained from candidates generated from numerical simulation which include these eﬀects.

Ultimately—and with enough resources—we envision a system that adaptively trains the
AI and re-scores the survey candidates on the ﬂy while human experts are classifying them.
Such an “online” system will ensure portability of the AI when the RFI environment of the
telescope slowly changes over time. Remarkably, owing to the nature of the ML algorithms
employed, this does not require coding new heuristics to characterize any emerging forms
of RFI. One of challenges in implementing an online learning system is that the training
data will be very imbalanced as pulsar surveys tend to ﬁnd a lot more RFI than pulsars.
Lyon et al. (2013) has explored the performance of some existing online ML algorithms
in dealing with imbalanced data streams from pulsar surveys and found promise in these
methods. Whether PICS could be adapted into a successful online learning system will be
explored in future work.

Pulsar research at UBC is supported by NSERC Discovery and Special Research Op-
portunity grants and a Discovery Accelerator Supplement, by CANARIE and by the Canada
Foundation for Innovation. Pulsar research at McGill is supported by an NSERC Discovery
grant and Accelerator Supplement, by the Canada Research Chair program, by the Centre
de Recherche Astrophysique du Qu´ebec, by the Canadian Insitute for Advanced Research,
and by the Lorne Trottier Chair in Astrophysics and Cosmology. This work was also sup-
ported by US National Science Foundation (NSF) grants 1104902, 1104617, and 1105572.

– 20 –

LGS gratefully acknowledges the ﬁnancial support by the European Research Council for
the ERC Starting Grant BEACON under contract no. 279702. The National Radio As-
tronomy Observatory is a facility of the National Science Foundation operated under co-
operative agreement by Associated Universities, Inc. The Arecibo Observatory is operated
by SRI International under a cooperative agreement with the National Science Foundation
(AST-1100968), and in alliance with Ana G. Mndez-Universidad Metropolitana, and the
Universities Space Research Association.

REFERENCES

Allen, B., et al. 2013, ApJ, 773, 91

Bates, S. D., et al. 2012, MNRAS, 427, 1052

Bergstra, J., et al. 2010, in Proceedings of the Python for Scientiﬁc Computing Conference

(SciPy), oral Presentation

Boureau, Y.-L., Ponce, J., & LeCun, Y. 2010, in International Conference on Machine Learn-

ing, 111–118

Chang, C.-C., & Lin, C.-J. 2011, ACM Transactions on Intelligent Systems and Technology,
2, 27:1, software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm

Cordes, J. M., & Lazio, T. J. W. 2001, ApJ, 549, 997

Cordes, J. M., et al. 2006, ApJ, 637, 446

Eatough, R. P., Molkenthin, N., Kramer, M., Noutsos, A., Keith, M. J., Stappers, B. W., &

Lyne, A. G. 2010, MNRAS, 407, 2443

Faulkner, A. J., et al. 2004, MNRAS, 355, 147

Kaspi, V. M. 2012, in American Astronomical Society Meeting Abstracts, Vol. 219, American

Astronomical Society Meeting Abstracts #219, 237.12

Keith, M. J., Eatough, R. P., Lyne, A. G., Kramer, M., Possenti, A., Camilo, F., & Manch-

ester, R. N. 2009, MNRAS, 395, 837

Knispel, B., et al. 2013, ApJ, 774, 93

Lazarus, P. 2013, in IAU Symposium, Vol. 291, IAU Symposium, 35–40

– 21 –

LeCun, Y., Bottou, L., Bengio, Y., & Haﬀner, P. 1998, Proceedings of the IEEE,, 86(11),

2278

Lee, K. J. 2009, PhD thesis, Peking University

Lee, K. J., et al. 2013, MNRAS, 433, 688

Lorimer, D. R., Bailes, M., McLaughlin, M. A., Narkevic, D. J., & Crawford, F. 2007,

Science, 318, 777

Lynch et al. 2013, in IAU Symposium, Vol. 291, IAU Symposium, 41–46

Lyon, R. J., Brooke, J. M., Knowles, J. D., & Stappers, B. W. 2013, astro-ph.IM:1307.8012

Pedregosa, F., et al. 2011, Journal of Machine Learning Research, 12, 2825

Ransom, S. M. 2001, PhD thesis, Harvard University

Ransom, S. M., Eikenberry, S. S., & Middleditch, J. 2002, Astron. J., 124, 1788

Thornton, D., et al. 2013, Science, 341, 53

This preprint was prepared with the AAS LATEX macros v5.2.

– 22 –

F1:96%

Logistic Regression

F1:86-94%

SVM

ANN

SVM

CNN

SVM

CNN

SVM

ANN

1

2

3

4

90% F1, and
Fig. 1.— The ﬁrst layer of classiﬁers learns how to rate each feature to
the second layer learns how to classify candidates based on the output of the ﬁrst layer.
(SVM: support vector machine, NN: Neural Network, LR: logistic regression and adaboost
are machine learning algorithms. See Section 2.3 for the deﬁnition of F1. )

∼

– 23 –

1

2

3

4

Fig. 2.— prepfold diagnostic plot for PICS-discovered pulsar PSR J1914+08. The four key
subplots of the PICS AI system are highlighted: 1. summed pulse proﬁle 2. time-versus-
phase plot 3.
frequency-versus-phase plot 4. DM curve. For subplot 1, 2 and 3 the pulse
phase are wrapped around twice to show two duplicated pulses.

– 24 –

Time vs Phase

Frequency vs Phase

PCA reconstruction

PCA reconstruction

Fig. 3.— Top: The original time-versus-phase and frequency-versus-phase plots from a
pulsar candidate. Bottom: The PCA-reconstructed plots from the top 24 PCA components.

– 25 –

Convolution layer

Max-pooling layer

Features maps

Input for
next layer

max

max

Input image

Features maps

Fig. 4.— A schematic of the ﬁrst two layers in the convolutional neural network. Left:
convolution layer; from bottom up, the input image is convolved with a set of image kernels,
forming feature maps that show the presence of certain features in diﬀerent positions of the
image. right: max-pooling layer; the feature maps are compressed to smaller size by taking
in only the maximum values of adjacent pixels. The PICS CNN consists of two sets of
alternating convolution and max-pooling layers, and a ﬁnal artiﬁcial neural network layer.

5

10

4

10

3

10

2

10

1

10

0

10

s
e
t
a
d
d
n
a
c

i

f
o

r
e
b
m
u
n

overall
pulsars
harmonics

 99%

  1%

0.0

0.2

0.4

0.6

0.8

1.0

AI score

Fig. 5.— The unﬁlled histogram is the distribution of AI scores of 90008 GBNCC candidates.
The ﬁlled histogram is the AI score distribution of known pulsars. The hatched histogram
is that of the harmonics of known pulsars.

 
 
– 26 –

Fig. 6.— An example of a
pulsars in the GBNCC test data.

∼

60 Hz RFI signal that was ranked higher than the weakest four

Fig. 7.— The discovery plot of PSR J1938+20.

– 27 –

Fig. 8.— The discovery plot of PSR J1930+17.

Fig. 9.— The discovery plot of PSR J1854+00.

– 28 –

Table 1. Classiﬁer parameters and test performance.

classiﬁer

feature (sizea )

nodesb

γc

Cd

e

F1

ANN
SVM
CNN
SVM
CNN
SVM
ANN
SVM
LR

summed proﬁle (64)
summed proﬁle (64)

time vs phase (48
×
time vs phase (64
×
frequency vs phase (48
frequency vs phase (64

48)
64)f

48)
64)f

×
×

DM curve (60)
DM curve (60)
layer-one pool (8)

25
–
500
–
500
–
9
–
–

–
0.08
–
0.01
–
0.001
–
0.2
–

2
1
1
1
1
24
10
25
0.1

0.86
0.93
0.92
0.88
0.94
0.88
0.91
0.91
0.96

aThe input features were down-sampled or interpolated to a uniform

size.

bNumber of nodes in the hidden layer of the neural network (NN). For
the CNNs, only the number of nodes of the last hidden layer is listed.
See Section 2.5 for more details.

cγ is the radius parameter for the rbf kernel function used in the SVM.
The traditional SVM can only use linear boundaries to classify data. The
kernel functions enable the SVM to ﬁnd curved boundaries. The rbf-
kernel SVM is considered a more eﬀective classiﬁer than the traditional
SVM.

dThe C parameter controls the regulation in the ANN and the SVM.
Here regulation means that the ANN or SVM tries to minimize a penalty
function while ﬁnding the optimal set of internal parameters wi. The
function is often deﬁned as (P w2
i )/C in order to penalize very large
weights.

eThe average F1 scores of the classiﬁers from 10 independent trials.
In each trial, we randomly shuﬄe our known candidates before splitting
them into training and testing data, after which training is commenced.
The standard deviations of the F1 scores are <0.01.

f PCA compression was applied to prepare 2D image data only for the
64 image into 24 PCA components.

SVM classiﬁers. We compress the 64

×

– 29 –

Table 2. The 60 Hz RFI and its harmonics.

frequency range (Hz)a Countsb Percentagec

18
58
118
139
179
239

−
−
−
−
−
−

19
62
121
140
181
241

2101
12941
4480
2157
1744
1096

2.3%
14.4%
5.0%
2.4%
1.9%
1.2%

aThe 6 most populous frequency ranges in the

histogram of candidates.

bNumber of candidates within the given fre-

quency range.

cPercentage of candidates within the given fre-

quency range.

