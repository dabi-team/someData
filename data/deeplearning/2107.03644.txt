ComFormer: Code Comment Generation via
Transformer and Fusion Method-based Hybrid Code
Representation

Guang Yang†, Xiang Chen†‡∗, Jinxin Cao†, Shuyuan Xu†, Zhanqi Cui‡, Chi Yu†, Ke Liu†
†School of Information Science and Technology, Nantong University, China
†Computer School, Beijing Information Science and Technology University, China
‡Key Laboratory of Safety-Critical Software (Nanjing University of Aeronautics and Astronautics),
Ministry of Industry and Information Technology, China
Email: 1930320014@stmail.ntu.edu.cn, xchencs@ntu.edu.cn, alfred7c@ntu.edu.cn
1113585141@qq.com, czq@bistu.edu.cn, yc struggle@163.com, 806464561@qq.com

Abstract—Developers often write low-quality code comments
due to the lack of programming experience, which can reduce
the efﬁciency of developers’ program comprehension. Therefore,
developers hope that code comment generation tools can be
developed to illustrate the functionality and purpose of the code.
Recently, researchers mainly model this problem as the neural
machine translation problem and tend to use deep learning-based
methods. In this study, we propose a novel method ComFormer
based on Transformer and fusion method-based hybrid code
presentation. Moreover, to alleviate OOV (out-of-vocabulary)
problem and speed up model training, we further utilize the
Byte-BPE algorithm to split identiﬁers and Sim SBT method to
perform AST Traversal. We compare ComFormer with seven
state-of-the-art baselines from code comment generation and
neural machine translation domains. Comparison results show
the competitiveness of ComFormer in terms of three performance
measures. Moreover, we perform a human study to verify that
ComFormer can generate high-quality comments.

Index Terms—Program Comprehension, Code Comment Gen-
eration, Hybrid Code Representation, Transformer, Empirical
Study

I. INTRODUCTION

With the increasing complexity and evolutionary frequency
of software projects, the importance of program comprehen-
sion is also increasing. A recent study by Xia et al. [1] showed
developers spend 59% of their time on program comprehen-
sion on average during software development and mainte-
nance. Therefore, high-quality code comments are critical to
improving the efﬁciency of developers’ program comprehen-
sion [2]. However, developers often write low-quality code
comments or do not write code comments due to the limited
project development budget, lack of programming experience,
or insufﬁcient attention to writing code comments. Although
some tools (such as JavaDoc [3] and Doxygen1) can assist in
generating code comment templates, these tools still unable to
automatically generate content related to the functionality and
purpose of the focused code. If developers manually write code

comments, it will be time-consuming and difﬁcult to guarantee
the quality of the written comments. Moreover, existing code
comments should be updated automatically with the evolution
of the related code [3]. Therefore, it is of great signiﬁcance
to design novel methods that can automatically generate high-
quality comments after analyzing the focused code.

Code comment generation2 is an active research topic in
the current program comprehension research domain. Research
achievements in this research problem can also improve other
software engineering tasks (such as software maintenance,
code search, and code categorization). In the early phase, most
of the studies [6][7][8][9] on code comment generation were
based on template-based methods or information retrieval-
based methods. Recently, most of the studies [10][11][12]
started to follow an encoder-decoder framework and achieved
promising results.

In this study, we propose a novel method ComFormer
via Transformer [13] and fusion method-based hybrid code
representation. Our method considers Transformer since this
deep learning model can achieve better performance than
traditional sequence to sequence models in classical natural
language processing (NLP) tasks (such as neural machine
translation [14][15] and software engineering [16]). Moreover,
our method also utilizes the hybrid code representation to
effectively learn the semantic of the code since this rep-
resentation can extract both lexical-level and syntactic-level
information from the code, respectively. In the hybrid code
representation, we not only consider sequential
tokens of
source code (i.e., lexical level of code) but also utilize AST
(abstract syntax tree) information by our proposed Sim SBT
method (i.e., syntactic level of code). Moreover, we also
consider three different methods to fuse this information.
Finally, to alleviate the OOV (out-of-vocabulary) problem,
we utilize the byte-level Byte-Pair-Encoding algorithm (Byte-
BPE) [17] to split identiﬁers.

∗ Xiang Chen is the corresponding author.
1http://www.doxygen.org

2This challenging research problem is also called source code summariza-

tion in some previous studies [4][5]

1
2
0
2

l
u
J

8

]
E
S
.
s
c
[

1
v
4
4
6
3
0
.
7
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
To evaluate the effectiveness of our proposed method Com-
Former, we conduct experimental studies on a large-scale code
corpus, which contains 485,812 pairs. Each pair includes a
Java method and corresponding code comment. This corpus
was gathered by Hu et al.
[18]. They performed a set
of data cleaning steps to ensure the high quality of this
corpus. Until now, this corpus has been widely used as the
experimental subject in previous code comment generation
studies [18][11][19][20][21][22].

We design empirical studies and perform human studies
to verify the effectiveness of our proposed method. We
ﬁrst compare ComFormer with four state-of-the-art baselines
from code comment generation (i.e., DeepCom [11], Hybrid-
DeepCom [18], Transformer [23], CodePtr [24]) and three
baselines from neural machine translation (i.e., seq2seq mod-
els [25] with/without attention mechanism [26] and GPT-
2 [27]) in terms of three performance measures (i.e., BLEU,
METEOR, and ROUGE-L), which are classical measures in
previous code comment generation studies. Empirical results
show ComFormer can improve the performance when com-
pared with these state-of-the-art baseline methods. Second,
after comparing three fusion methods (i.e., Jointly Encoder,
Shared Encoder, and Single Encoder) to combine code lexical
information and AST syntactic information, we ﬁnd Com-
Former with Single Encoder can achieve the best performance.
Third, We perform a human study to verify the effectiveness of
ComFormer. In our human study, we compare the comments
generated by ComFormer with the comments generated by
Hybrid-DeepCom [18], which has the best performance among
the chosen baselines. The results of our human study also show
the competitiveness of ComFormer.

To our best knowledge, the main contributions of our study

can be summarized as follows:

• We propose a novel code comment generation method
ComFormer based on the Transformer and the fusion
method-based hybrid code representation. Instead of the
copy mechanism, we mitigate the OOV problem through
the Byte-BPE algorithm and vocabulary sharing. Then
we propose a simpliﬁcation version of the SBT algorithm
(i.e., Sim SBT) to traverse the structural information of
the AST, which can speed up model training. Finally, we
consider three different methods for fusing lexical and
syntactical information of the code.

• We evaluate the performance of our proposed method
ComFormer on a large-scale code corpus, which contains
485,812 Java methods and corresponding code comments.
The experimental results show that ComFormer is more
effective than seven state-of-the-art baselines from both
the code comment generation domain and the neural
machine translation domain in terms of three performance
measures. Moreover, we further conduct a human study
to verify the effectiveness of ComFormer.

• We share our source code, trained models, and used code
corpus in the GitHub repository3, which can facilitate

3https://github.com/NTDXYG/ComFormer

the replication of ComFormer and encourage other re-
searchers to make a comparison with ComFormer.
Paper organization. The rest of the paper is organized as
follows. Section II presents the background and related work
of our study. Section III shows the framework of our proposed
method ComFormer and details of key components in Com-
Former. Section IV shows the experiment setup. Section V an-
alyzes our empirical results. Section VI performs a discussion
on our proposed method ComFormer. Section VII discusses
potential threats to the validity of our empirical study. Finally,
Section VIII concludes this paper and shows potential future
directions for our study.

II. RELATED WORK

In the early phase, most studies [6, 7, 8, 9, 28, 29, 30,
31, 32, 33, 34, 35, 36] used template-based or information
retrieval-based methods to generate code comments. Recently,
most of the studies followed deep learning-based methods (i.e.,
encoder-decoder framework) and achieved promising results.
Iyer et al. [10] ﬁrst proposed a method code-NN via an
attention-based neural network. Allamanis et al. [37] proposed
a model in which the encoder uses CNN and attention mecha-
nisms, and the decoder uses GRU. The use of convolution op-
erations helps to detect local time-invariant features and long-
range topical attention features. Zheng et al. [38] proposed a
new attention module called Code Attention, which can utilize
the domain features (such as symbols and identiﬁers) of code
segments. Liang and Zhu [39] used Code-RNN to encode the
source code into the vectors, and then they used Code-GRU
to decode the vectors to code comments.

Hu et al. [11] proposed a method DeepCom by analyzing
abstract syntax trees (ASTs). To better present the structure
of ASTs, they proposed a new structure-based traversal (SBT)
method. Later, Hu et al. [18] further proposed the method
Hybrid-DeepCom. This method mainly made some improve-
ments. For example, the identiﬁers satisfying the camel casing
naming convention are split into multiple words. Recently,
Kang et al. [19] analyzed whether using the pre-trained
word embedding can improve the model performance. They
surprisingly found that using the pre-trained word embedding
based on code2vec [40] or Glove [41] does not necessarily
improve the performance.

Leclair et al. [5] proposed a method ast-attendgru, which
combines words from code and code structure. Leclair et
al. [42] then used a Graph neural network (GNN), which
can effectively analyze the AST structure to generate code
comments. Wan et al. [4] proposed the method Hybrid-DRL
to alleviate the exposure bias problem. They input an AST
structure and sequential content of code segments into a deep
reinforcement learning framework (i.e., actor-critic network).
Then, Wang et al. [20] extended the method Hybrid-DRL.
They used a hierarchical attention network by considering
multiple code features, such as type-augmented ASTs and
program control ﬂows.

Ahmad et al. [23] used the Transformer model to generate
code comments. The Transformer model is a kind of sequence

to sequence model based on multi-head self-attention, which
can effectively capture long-range dependencies. Speciﬁcally,
they proposed to combine self-attention and copy attention
as the attention mechanism of the model and analyzed the
inﬂuence of absolute position and pairwise relationship on the
performance of the code comment generation.

Chen et al. [43] proposed a neural framework, which allows
bidirectional mapping between a code retrieval task and a code
comment generation task. Their proposed framework BVAE
has two Variational AutoEncoders (VAEs): C-VAE for source
code and L-VAE for natural language. Ye et al. [44] exploited
the probabilistic correlation between code comment generation
task and code generation task via dual learning. Wei et al. [22]
also utilized the correlation between code comment generation
task and code generation task and proposed a dual training
framework.

On the other hand, Hu et al. [12] proposed a method TL-
CodeSum, which can utilize API knowledge learned in a
related task to improve the quality of code comments. Zhang
et al. [21] proposed a retrieval-based neural code comment
generation method. This method enhances the model with the
most similar code segments retrieved from the training set
from syntax and semantics aspects. Liu et al. [45] utilized the
knowledge of the call dependency between the source code and
the dependency of codes. Zhou et al. [46] proposed a method
ContextCC, which uses the program analysis to extract context
information (i.e., the methods and their dependency). Haque
et al. [47] modeled the ﬁle context (i.e., other methods in the
same ﬁle) of methods, then they used an attention mechanism
to ﬁnd words and concepts to generate comments.

Different from the previous studies, ComFormer is designed
based on Transformer and fusion method-based hybrid code
presentation. In this study, we investigate three different meth-
ods to fuse lexical-level and syntactic-level code information.
Moreover, we utilize the Byte-BPE algorithm to alleviate the
OOV problem and use the Sim SBT method to reduce the size
of the sequence generated by the original SBT method [11],
which can speed up model training.

III. OUR PROPOSED METHOD COMFORMER

Fig. 1 shows the framework of ComFormer. In this ﬁgure,
we can ﬁnd that ComFormer consists of three parts: data
process part, model part, and comment generation part. Then
we show the details of these three parts.

A. Data Process Part

In ComFormer, we consider a hybrid representation of code.
For this representation, we not only consider sequential tokens
of source code (i.e., lexical level of code) but also utilize AST
structure information (i.e., syntactical level of code).

1) Constructing Source Code Sequence.: We ﬁrst convert
the tokens of code into the sequences. However, many tokens
are identiﬁers (such as the class name, the method name, the
variable name). These identiﬁers are named according to Java’s
naming convention (i.e., camel casing naming convention).
Therefore, most of the identiﬁers are OOV tokens. In our study,

we ﬁrst split these identiﬁers into multiple words, which helps
to alleviate the OOV problem and keep more code information.
For example, the variable name “SegmentCopy” can be split
into two words: ”segment” and ”copy”. The method name
“onDataChanged” can be split into three words: “on”, “data”
and “changed”. The class name “SecureRandom” can be split
into two words: “secure” and “random”. After splitting the
identiﬁers into multiple words, we then convert all the tokens
into lowercase. Finally, we replace the speciﬁc numbers and
strings with “<num >” and “<str >” tags, respectively.

Second, after performing a more detailed manual analysis
on the training set, we ﬁnd that after splitting the words
based only on the camel casing naming convention, there
are still a large number of OOV words in the testing set.
Most of the current studies [23, 24] alleviated this problem
through the copy mechanism by using the pointer network.
In our study, we use the Byte-BPE algorithm [17] to further
divide the token of the code into sub-tokens, then combine the
vocabulary sharing to solve the OOV problem. For example,
we ﬁnd the word ”forgo” exists in the comments of the test
set, which does not appear in the comments of the training
set, nor the corresponding source code. In this case, neither
the camel casing naming split nor the copy mechanism can
solve the problem. However, in the Byte-BPE algorithm, the
word “forgotten” is split into “for”, “go”, “t”, “ten”, so that
in The Decoder, it can decode the comments to produce the
correct word “forgo”.

2) Constructing AST Sequence: We ﬁrst use the javalang
tool4 to convert the Java code into the corresponding AST.
Then we use our proposed Sim SBT method to generate the
traversal sequence of the AST. Since the sequences generated
by the SBT method [11] may contain redundant information
(i.e., many parentheses between type nodes), the sequences
generated by SBT traversal are sometimes longer than the
source code sequences, which makes it more difﬁcult for the
model to learn syntactic information. To alleviate this problem,
we propose a new method Sim SBT, which can better present
the structure of ASTs and keep the sequences unambiguous.
the methods SBT and
results of
Sim SBT are shown in Fig. 2. In this example, the sequence
generated by the original SBT method is too long. Our
proposed method Sim SBT adopts a prior order traversal in
a tree, which has the advantage of reducing the length of
the sequence. We use a code example to show the generated
sequence by using our proposed method Sim SBT in Fig. 3.
In this ﬁgure,
the source code token of the same color
corresponds to the token of the AST syntax type. We can ﬁnd
the AST sequence generated by Sim SBT is slightly shorter
than the source code length, which can effectively reduce the
time of model training.

The AST traversal

B. Model Part

ComFormer follows the Transformer architecture (i.e., the
encoder and the decoder are built using the self-attentive

4https://pypi.org/project/javalang/

Fig. 1. The framework of our proposed method ComFormer

methods at the Encoder.

The Encoder of Transformer does not attempt to compress
the entire source sentence X = (x1, · · · , xn) into a single
context vector z. Instead it produces a sequence of context
vectors Z = (z1, · · · , zn). First, the tokens of the input are
passed through a standard embedding layer. Next, as the model
has no recurrent, it has no idea about the tokens’ order in the
sequence. This problem is solved by using another embed-
ding layer (i.e., positional embedding layer). The positional
embedding layer’s input is not the token itself but the token
position in the sequence. Notice the input starts with <SOS>
(i.e., start of the sequence) token, which is the ﬁrst token in
position 0. The original implementation of Transformer [13]
uses ﬁxed static embeddings and does not learn positional em-
beddings. Recently, positional embeddings have been widely
used in modern Transformer architectures (such as Bert [48]).
Therefore, our study also uses this positional embedding layer.
The encoded word embeddings are then used as the input to
the encoder, which consists of N layers. Each layer contains
two sub-layers: (a) a multi-head attention mechanism and (b)
a feed-forward network.

A multi-head attention mechanism builds upon scaled dot-
product attention, which operates on a query Q, a key K,
and a value V . The original attention calculation uses scaled
dot-product for each representation:

Attention(Q, K, V ) = softmax

(cid:18) QK T
√
dk

(cid:19)

V

(1)

Fig. 2. The AST traversal results of the methods SBT and Sim SBT

Fig. 3. An example of convert an AST to a sequence by using our proposed
method Sim SBT.

mechanism). Moreover, ComFormer considers three methods
for fusing lexical and syntactical information of the code at
the Encoder.

Multi-head attention mechanisms obtain h different repre-
sentations of (Q, K, V ). Then concatenate the results, and
project the concatenation with a feed-forward layer:

1) Encoder Layer: In this section, we ﬁrst introduce Trans-
former’s Encoder and then illustrate three different fusion

headi = Attention

(cid:16)

QW Q

i , KW K
i

, V W V
i

(cid:17)

(2)

MultiHead(Q, K, V ) = Concati (headi) W O

(3)

where Wi and W O are parameter projection matrices that are
learned, and h denotes the number of heads in the multi-head
attention.

The second component of each layer of the Transformer

network is a feed-forward network.

FFN(x) = max (0, xW1 + b1) W2 + b2

(4)

Next, we illustrate three different methods (i.e., Jointly
Encoder, Shared Encoder, and Single Encoder), which can
fuse lexical and syntactical information of the code at the
Encoder. The structure of these fusing methods can be found
in Fig. 4. Speciﬁcally, Jointly Encoder assumes that AST and
source code are two different levels of the input. Therefore,
this method sets up an encoder for the source code sequence
(i.e., Code Encoder) and an encoder for the AST Sequence
(i.e., AST Encoder), respectively. The Linear layer is activated
by the Tanh function to obtain the ﬁnal matrix of contextual
information. Shared Encoders considers the effect of having
two encoders on the model parameters. This method encodes
the source code sequence and the AST Sequence by weight
sharing (i.e., using one encoder). Then it switches the two
output matrices together, adds a Linear layer, and activates it
with the Tanh function to obtain the ﬁnal matrix of contextual
information. Single Encoder ﬁrst splices the source code
sequence and the AST sequence. Then, this method proceeds
through the word embedding in the encoder afterward, which
relies entirely on the positional information encoded in the
model for learning lexical and syntactical information.

it can be found that

2) Decoder Layer: According to the structure of the Trans-
former,
the Decoder is the same as
the Encoder. In the beginning, a position vector Positional
Encoding was added ﬁrst, which is the same as the method
used in the Encoder.

Next is the masked multi-head attention, the mask represents
a mask, which masks certain values so that it has no effect
when the parameters are updated. The decoder implements the
autoregressive model by means of Mask. The sequence mask
is to make the decoder unable to see future information. That
is, for a sequence, at the moment time step is t, our decoded
output should only depend on the output before time t, not
the output after t. So we need to generate an upper triangular
matrix, the values of the upper triangle are all 0. By applying
this matrix to each sequence, the information after t can be
hidden.

Finally, The combined embeddings are passed through the
N decoder layers, along with the encoded source, and the
source and target masks. Notice the rest of the layer structure
is the same as the Encoder in our method.

C. Comment Generation Part

Previous studies [11][12] showed that generating the text
through the maximum probability distribution of the neural
networks often yields a low-quality result. Recently, most

Fig. 4. Structure of three different fusion methods in the Encoder

studies [49][50] resorted to Beam Search [49], which can
achieve high performance on text generation tasks. Therefore,
ComFormer uses the Beam Search algorithm to generate code
comments.

IV. EXPERIMENTAL SETUP

In our empirical study, we want to answer the following

three research questions (RQs):
RQ1: Can our proposed method ComFormer outperform
state-of-the-art baselines for code comment generation in
terms of neural machine translation-based measures?
Motivation. In this RQ, we want to compare the performance
of ComFormer with the state-of-the-art baselines from both the
code comment generation domain and neural machine trans-
lation domain in an automated manner. The main challenge is

how to measure the similarity between the comments written
by developers and the comments generated by ComFormer
and baselines. In this RQ, we consider three performance
measures, which have been used in the previous studies
on neural machine translation [51][52] and code comment
generation [12][4][18].
RQ2: Can hybrid code representation improve the perfor-
mance of our proposed method ComFormer?
Motivation. In this RQ, we want to show the effectiveness of
fusion Method-based hybrid code representation. Therefore,
we want to compare this code representation method with
the methods, which only consider code lexical information.
Moreover, we want to compare the performance of different
methods for fusing code lexical information and code syntac-
tical information. Then we can select the best fusion method
in this study.
RQ3: Can our proposed method ComFormer outperform
state-of-the-art baselines for code comment generation via
human study?
Motivation. Evaluating the effectiveness of our proposed
method in terms of performance measures has the following
disadvantages. First, the quality of the comments written by
developers can not be guaranteed in some cases. Second,
sometimes evaluation based on word similarity is not accu-
rate since two semantic similar code comments may contain
different words. Therefore,
is necessary to evaluate the
it
effectiveness of our proposed method via human study in a
manual way.

A. Code Corpus

In our empirical study, we choose code corpus5 gathered by
Hu et al. [18] as our empirical subjects, since this code corpus
have been widely used in previous studies for code comment
generation [18][11][19][20][21][22].

Table I shows the statistical information for code length,
SBT length, and comment length. For the above code corpus,
20,000 pairs are selected to construct the testing set and the
validation set. Then the remaining 445,812 pairs are used to
construct the training set. This setting is consistent with the
experimental setting in the previous studies (such as Hybrid-
DeepCom [18]), which can guarantee a fair comparison with
the baselines.

TABLE I
STATISTICS OF CODE CORPUS USED IN OUR EMPIRICAL STUDY

Statistics for Code Length

Avg
55.79

Mode Median

11

36

< 100
< 200
< 150
82.75% 92.11% 97.10%

Statistics for Comment Length

Avg
10.25

Mode Median

< 20

< 30

8

9

95.69% 99.99%

< 50
100%

B. Performance Measures

In our study, we use the performance measures from neural
machine translation research to automatically evaluate the
quality between the candidate comments (generated by code
comment generation methods) and the reference comments
(generated by developers). The chosen performance measures
include BLEU, METEOR, and ROUGE-L. These performance
measures have been widely used in previous studies for
code comment generation [12][4][18]. The details of these
performance measures can be found as follows.
BLEU. BLEU (Bilingual Evaluation Understudy) [53] is the
earliest measure used to evaluate the performance of the
neural machine translation models. It is used to compare the
degree of coincidence of n-grams in the candidate text and the
reference text. In practice, N =1∼4 is usually taken, and then
the weighted average is performed. Unigram (N =2) is used
to measure word translation accuracy, and high-order n-gram
is used to measure the ﬂuency of sentence translation.
METEOR. METEOR (Metric for Evaluation of Translation
with Explicit Ordering) [54] is based on BLEU with some
improvements. METEOR is based on the single-precision
weighted harmonic mean and the single word recall rate, and
its purpose is to solve some inherent defects in the BLEU
standard.
ROUGE-L. ROUGE-L (Recall-Oriented Understudy for Gist-
ing Evaluation) [55] calculates the length of the longest com-
mon subsequence between the candidate text and the reference
text. The longer the length, the higher the score.

We utilize the implementations provided by nlg-eval li-
brary6, which can ensure the implementation correctness of
these performance measures.

C. Experimental Settings

Our proposed method ComFormer is implemented with Py-
Torch 1.6.0. In our study, we choose AdamW as the optimizer
and use cross Entropy as the loss function. We set the learning
rate to 0.0005 and set the value of epoch to 30.

All the experiments run on a computer with an Inter(R)
Xeon(R) Silver 4210 CPU and a GeForce RTX3090 GPU with
24 GB memory. The running OS platform is Windows OS.

V. RESULT ANALYSIS

A. Result Analysis for RQ1

RQ1: Can our proposed method ComFormer outperform
state-of-the-art baselines for code comment generation in
terms of neural machine translation-based measures?
Method. In this RQ, we ﬁrst want to compare our proposed
method ComFormer with Hybrid-DeepCom [18]. Hybrid-
DeepCom used the AST traversal method to represent the
code structure information. Then they used the seq2seq model
with the attention mechanism to construct the model. Then,
we also choose other four state-of-the-art code comment
generation methods (i.e., DeepCom [11], CodePtr [24], and
Transformer [23]) as our baselines. Later, we choose three

5This

corpus
EMSE-DeepCom

can be downloaded from https://github.com/xing-hu/

6https://github.com/Maluuba/nlg-eval

TABLE II
THE COMPARISON RESULTS BETWEEN OUR PROPOSED METHOD COMFORMER AND BASELINE METHODS IN TERMS OF BLEU, METEOR AND ROUGE L

METHOD

BLEU 1(%) BLEU 2(%) BLEU 3(%) BLEU 4(%) METEOR(%) ROUGE L(%)

DeepCom
Hybrid-DeepCom
Transformer
CodePtr
Seq2Seq
Seq2Seq with atten
GPT-2

ComFormer without AST
ComFormer with AST

49.023
54.056
55.624
59.506
45.016
46.526
47.915

59.090
62.790

44.140
45.046
46.295
51.107
40.625
41.526
41.253

51.027
55.283

38.265
40.336
41.574
46.386
36.162
37.812
37.593

46.613
51.127

35.216
37.397
38.692
43.371
34.024
35.041
35.301

43.801
48.437

25.183
27.383
29.056
31.382
23.695
24.534
26.887

31.711
34.182

52.175
54.331
55.263
62.761
50.462
51.842
53.398

60.539
63.249

baselines from deep learning-based machine translation mod-
els. The ﬁrst two baselines are traditional seq2seq models [25]
with/without attention mechanism [26]. The last baseline is
GPT-2 [27]). GPT2 only uses the decoder in the Transformer
by large-scale anticipatory learning on tasks (such as machine
translation and text summarization). Finally,
to show the
competitiveness of our fusion method, we also consider a
baseline (i.e., ComFormer without AST), in which the Encoder
only considers the code lexical information. Notice, in this RQ,
ComFormer (i.e., ComFormer with AST) considers the Single
Encoder as the fusion method.

For these chosen baselines, we re-use the experimental
results of three methods (i.e., DeepCom, Hybrid-DeepCom,
and CodePtr) due to the same dataset split setting and re-
implement the remaining baselines.
Results. The comparison results between ComFormer and the
baselines can be found in Table II. Based on Table II, we can
ﬁnd that our proposed method ComFormer can outperform all
of the baselines. In terms of BLEU 1/2/3/4, ComFormer can
at least improve its performance by 6.18%, 9.86%, 12.76%,
14.85% respectively. In terms of METEOR, ComFormer
least. In terms
can improve its performance by 8.20% at
of ROUGE -L, ComFormer can improve its performance by
4.87% at
least. Therefore, ComFormer can achieve better
performance than the baselines in terms of these performance
measures.

In addition, four code examples with different lengths are
selected from the testing set to compare the results generated
by ComFormer and baselines. The comparison results can be
found in Table III. In Case 1, the use of a network of pointers
in CodePtr and the use of BPE splitting with vocabulary
sharing in ComFormer both generate ”cache” words in the
comment, which can demonstrate the effectiveness of our
method in alleviating the OOV problem. We further verify
the competitive nature of our method in Case 2, where the
word “insectwordcategory” does not appear in the source code
and ComFormer still generates the comment correctly, while
Hybrid-DeepCom and CodePtr only generate (cid:104)UNK(cid:105). As we
can ﬁnd from Case 3 and Case 4, although the comments
generated by the baselines are consistent, the comments gen-
erated by ComFormer are better after manual analysis. For

example, the comment generated in Case 3 explains the reason
for doing this separate step, and the comment generated in
Case 4 emphasizes the meaning of the if statement.

Summary for RQ1: Our proposed method Com-
Former can outperform state-of-the-art baselines both
from the code comment generation domain and neural
machine translation domain in terms of three perfor-
mance measures. Besides, the comments generated by
ComFormer can have better quality after analyzing
some cases.

B. Result Analysis for RQ2

RQ2: Can hybrid code representation improve the perfor-
mance of our proposed method ComFormer?
Method. As shown in Fig 4, we consider three different
fusion methods (i.e., Jointly Encoder, Shared Encoder, and
Single Encoder) to combine code lexical information and AST
syntactical information.
Reults. The comparison results are shown in Table IV. First,
we can ﬁnd that using these three fusion methods can achieve
better performance than ComFormer without AST. This means
considering syntactical
information from AST can further
improve the performance of ComFormer. Second, among these
three fusion methods, Single Encoder can achieve the best
performance. This means Single Encoder is best suited for
this task.

Summary for RQ2: Hybrid code representation can
improve the performance of our proposed method
ComFormer, while Single Encoder can achieve the best
performance.

C. Result Analysis for RQ3

RQ3: Can our proposed method ComFormer outperform
state-of-the-art baselines for code comment generation via
human study?

TABLE III
EXAMPLES OF GENERATED COMMENTS BY COMFORMER AND OTHER BASELINES. THESE EXAMPLES COVER BOTH LONG AND SHORT CODE SNIPPETS.

Case ID

Example

private void addCachedLegionMemberEx(LegionMemberEx legionMemberEx) {

this.allCachedLegionMembers.addMemberEx(legionMemberEx);

1

2

3

4

}
Hybrid-DeepCom: this method will add a new legion to this container
Codeptr: convenience method to add new member to cache
ComFormer without AST: add legion member to cache
ComFormer with AST: this method will add a new legion member to the cache
Human Written: this method will add a new legion member to the cache

public SimpleTextCategory(String sName) {

super();
Dictionary = new Dictionary(sName, NUM_);
Dictionary.AddSubStrings = BOOL_;
Dictionary.RemoveSubStrings = BOOL_;
DocumentCount = NUM_;
Name = sName;

}
Hybrid-DeepCom: creates a new instance of (cid:104)UNK(cid:105)
Codeptr: creates a new instance of (cid:104)UNK(cid:105)
ComFormer without AST: creates a new instance of insectcategory given a category name .
ComFormer with AST: creates a new instance of insectwordcategory
Human Written: creates a new instance of insectwordcategory

public void insertNewAddresses(Dao<AddressBook, Integer> addressBookDao,

Dao<AddressItem, Integer> addressItemDao) throws SQLException {
if (this.nonDaoAddresses == null) {

return;

}
addressBookDao.assignEmptyForeignCollection(this, STR_);
for (AddressItem addressItem : nonDaoAddresses) {

addressItem.setAddressBook(this);
addressItemDao.create(addressItem);
addresses.add(addressItem);

}

}
Hybrid-DeepCom: we need to insert a new contacts into the book.
Codeptr: we have separate ormlite doesn t automatically insert ormlite doesn doesn t automatically insert ormlite doesn doesn t automatically .
ComFormer without AST: insert new contact to database
ComFormer with AST: we have to do this separate step because ormlite doesn t automatically insert children
Human Written: we have to do this separate step because ormlite doesn t automatically insert children

public static Class<?> findCommonElementType(Collection collection) {

if (isEmpty(collection)) {

return null;

}
Class<?> candidate = null;
for (Object val : collection) {

if (val != null) {

if (candidate == null) {

candidate = val.getClass();

} else if (candidate != val.getClass()) {

return null;

}

}

}
return candidate;

}
Hybrid-DeepCom: ﬁnds the common element type for a given collection.
Codeptr: ﬁnd the common element of the given collection.
ComFormer without AST: ﬁnd the common element type of the given collection.
ComFormer with AST: ﬁnd the common element type of the given collection if any.
Human Written: ﬁnd the common element type of the given collection if any.

TABLE IV
THE COMPARISON RESULTS BETWEEN THREE DIFFERENT FUSION
METHODS

METHOD

BLEU 4(%) METEOR(%) ROUGE L(%)

ComFormer without AST
Jointly Encoder
Shared Encoder
Single Encoder

43.801
46.301
44.512
48.437

31.711
32.925
32.052
34.182

60.539
63.012
62.105
63.249

Method. In RQ1, the performance comparison is automati-
cally performed in terms of neural machine translation-based
performance measures. To verify the effectiveness of our
proposed methods, we further conduct a human study. We
recruit two master students majoring in computer science,
to perform manual analysis. Since both of these two master
students have rich project development experience, the quality
of our human studies can be guaranteed.

Due to the high cost of manually analyzing all the Java
methods in the testing set, we use a common sampling
method [56] to randomly select at least M IN Java methods
and the generated comments from the testing sets. The value
of M IN can be determined by the following formula:

M IN =

n0
1 + n0−1
size

(5)

(cid:17)

(cid:16)

where n0 depends on the selected conﬁdence level and the
= Z2×0.25
. Z is a conﬁdence level
desired error margin n0
e2
z score and e is the error margin. size is the number of
samples in the testing set. For the ﬁnal manual analysis,
we select M IN examples for the relevant data for the error
margin e = 0.05 at 95% conﬁdence level (i.e., M IN = 377).
For the 377 selected samples, we show the corresponding
source code, the comments generated by ComFormer, and
the comments generated by the method Hybrid-DeepCom to
master students. Notice, these two master students do not
know which method the comment is generated by, which can
guarantee a fair comparison.

Three scores are deﬁned as follows.
• 1 means that there is no connection between the comment
and the code, i.e., the comment does not describe the
function and meaning of the corresponding code. We use
Low to denote this result.

• 2 means that the comment is partially related to the code,
i.e., it describes part of the function and meaning of the
corresponding code. We use Medium to denote this result.
• 3 means that there is a strong connection between the
comment and the code, i.e., the comment correctly de-
scribes the function and meaning of the corresponding
code. We use High to denote this result.

Results. After our human study, we analyze the scoring results
of these two master students. The ﬁnal results are shown
in Table V. First, we can ﬁnd ComFormer can generate
a signiﬁcantly higher proportion of high-quality comments

than Hybrid-DeepCom. Then, ComFormer can generate a
much lower proportion of low-quality comments than Hybrid-
DeepCom. Finally, ComFormer can achieve a higher score
than Hybrid-DeepCom. These results indicate that ComFormer
can signiﬁcantly outperform the baseline Hybrid-DeepCom.

Summary for RQ3: Our proposed ComFormer also
works better than the baseline method on human study.

VI. DISCUSSIONS

In this section, we aim to analyze the impact of codes’
length on the performance of ComFormer and Hybrid-
DeepCom. The ﬁnal results in terms of two performance
measures can be found in Fig. 5. As shown in Fig. 5, the
longer the source code length, the lower the average score
of METEOR and Rouge L. These two methods obtain higher
performance when the coding length is between 15∼50. When
the source code length is short, These two methods can learn
the full semantics of the source code more easily. We found
that the performance ﬂuctuates signiﬁcantly when the number
of tokens in the source code exceeded 125. Because there
are fewer source codes in the corpus, whose length is over
125 and this limits ComFormer’s ability to learn this kind
of code. Overall, ComFormer outperformed Hybrid-DeepCom
regardless of code length.

VII. THREATS TO VALIDITY

In this section, we mainly discuss potential threats to the

validity of our empirical study.
Internal threats. The mainly ﬁrst internal threat is the poten-
tial defects in the implementation of our proposed method.
To alleviate this threat, we ﬁrst check code carefully and
use mature libraries, such as PyTorch and Transformers7. The
second internal threat is the implementation correctness of our
chosen baseline methods. To alleviate this threat, we try our
best to re-implement their approach according to the original
description of these baselines, and our implementation can
achieve similar performance reported in their empirical study.
External threats. The ﬁrst external threat is the choice of the
corpus. To alleviate this threat, we select a corpus, which was
provided by Hu et al. [18]. The reasons can be summarized as
follows. First, Java is the most popular programming language,
and most of the projects are developed by using Java. Second,
the quality of this code corpus has been improved by Hu et al.
by performing data preprocessing. Therefore, this code corpus
has also been used in previous studies on code comment
generation [18][11][19][20][21][22]. In the future, we want to
verify the effectiveness of our proposed method for the corpus
of other programming languages (such as Python, C#) [10].
Construct threats. The construct threat in this study is the
performance measures used to evaluate our proposed method’s

7https://github.com/huggingface/transformers

TABLE V
MANUAL ANALYSIS RESULTS ON COMMENTS GENERATED BY COMFORMER AND HYBRID-DEEPCOM VIA HUMAN STUDY

Student

1

2

Low

Medium

High

Mean

ComFormer Hybrid-DeepCom

ComFormer Hybrid-DeepCom

ComFormer Hybrid-DeepCom

ComFormer Hybrid-DeepCom

2.39%

4.51%

12.20%

10.34%

28.12%

29.90%

35.28%

35.01%

69.49%

65.59%

52.52%

54.65%

2.67

2.61

2.40

2.46

this model evaluation method has not been commonly used
for neural machine translation experiments due to the high
training computational cost.

VIII. CONCLUSION AND FUTURE WORK

High-quality code comments are the key to improve the
program comprehension efﬁciency of developers. Inspired by
the latest research advancements in the ﬁeld of deep learning
and program semantic learning, we propose a novel method
ComFormer via Transformer and fusion Method-based hybrid
code representation for code comment generation. In particu-
lar, we consider the Transformer to automatically translate the
target code to code comment. Moreover, we also use a hybrid
code representation (i.e., capture both lexical information and
syntactic information) to learn the code semantic effectively.
Both empirical studies and human studies verify the effective-
ness of our proposed method ComFormer.

In the future, we ﬁrst want to evaluate the effectiveness
of our proposed method ComFormer by considering other
corpus gathered from other programming languages, such as
Python, C#, and SQL query. Second, we want to use state-of-
the-art deep learning methods to improve the performance of
our proposed method. Finally, we also want to design more
reasonable performance metrics to better evaluate the quality
of code comments generated by ComFormer.

ACKNOWLEDGMENT

This work is supported in part by National Natural Science
Foundation of China (Grant nos. 61702041 and 61202006 ),
The Open Project of Key Laboratory of Safety-Critical Soft-
ware for Nanjing University of Aeronautics and Astronautics,
Ministry of Industry and Information Technology (Grant No.
NJ2020022).

REFERENCES

[1] X. Xia, L. Bao, D. Lo, Z. Xing, A. E. Hassan, and
S. Li, “Measuring program comprehension: A large-scale
ﬁeld study with professionals,” IEEE Transactions on
Software Engineering, vol. 44, no. 10, pp. 951–976,
2017.

[2] H. He, “Understanding source code comments at large-
scale,” in Proceedings of the 2019 27th ACM Joint Meet-
ing on European Software Engineering Conference and
Symposium on the Foundations of Software Engineering,
2019, pp. 1217–1219.

[3] D. Kramer, “Api documentation from source code com-
ments: a case study of javadoc,” in Proceedings of

(a) METEOR scores for different Code lengths

(b) ROUGE L scores for different Code lengths

Fig. 5. Performance comparison between ComFormer and Hybrid-DeepCom
by considering different code length in terms of two performance measures,
here blue line denotes ComFormer and yellow line denotes Hybrid-DeepCom.

performance. To alleviate these threats, we choose three popu-
lar performance measures from the neural machine translation
domain. These measures have also been widely used in previ-
ous code comment generation studies [12][4][18]. Moreover,
we also perform a human study to show the competitiveness
of our proposed method.
Conclusion threats. The conclusion threat in our study is we
do not perform cross-validation in our research. In our study,
the data split on the corpus is consistent with the experimental
setting in the previous study for DeepCom [18]. This can
guarantee a fair comparison with the baselines DeepCom,
Hybrid-DeepCom, and CodePtr (i.e., the model construction
and application on the same training set, validation set, and
testing set). Using cross-validation can comprehensively eval-
uate our proposed method, since different splits may result in
a diverse training set, validation set, and testing set. However,

the 17th annual international conference on Computer
documentation, 1999, pp. 147–153.

[4] Y. Wan, Z. Zhao, M. Yang, G. Xu, H. Ying, J. Wu, and
P. S. Yu, “Improving automatic source code summariza-
tion via deep reinforcement learning,” in Proceedings
of
the 33rd ACM/IEEE International Conference on
Automated Software Engineering, 2018, pp. 397–407.
[5] A. LeClair, S. Jiang, and C. McMillan, “A neural model
for generating natural language summaries of program
subroutines,” in 2019 IEEE/ACM 41st International Con-
ference on Software Engineering (ICSE).
IEEE, 2019,
pp. 795–806.

[6] S. Haiduc, J. Aponte, and A. Marcus, “Supporting pro-
gram comprehension with source code summarization,”
in 2010 acm/ieee 32nd international conference on soft-
ware engineering, vol. 2.

IEEE, 2010, pp. 223–226.

[7] S. Haiduc, J. Aponte, L. Moreno, and A. Marcus, “On
the use of automated text summarization techniques
for summarizing source code,” in 2010 17th Working
Conference on Reverse Engineering.
IEEE, 2010, pp.
35–44.

[8] G. Sridhara, E. Hill, D. Muppaneni, L. Pollock, and
K. Vijay-Shanker, “Towards automatically generating
summary comments for java methods,” in Proceedings
of the IEEE/ACM international conference on Automated
software engineering, 2010, pp. 43–52.

[9] G. Sridhara, L. Pollock, and K. Vijay-Shanker, “Au-
tomatically detecting and describing high level actions
within methods,” in 2011 33rd International Conference
on Software Engineering (ICSE).
IEEE, 2011, pp. 101–
110.

[10] S. Iyer, I. Konstas, A. Cheung, and L. Zettlemoyer,
“Summarizing source code using a neural attention
model,” in Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics (Volume
1: Long Papers), 2016, pp. 2073–2083.

[11] X. Hu, G. Li, X. Xia, D. Lo, and Z. Jin, “Deep code
comment generation,” in 2018 IEEE/ACM 26th Interna-
tional Conference on Program Comprehension (ICPC).
IEEE, 2018, pp. 200–20 010.

[12] X. HU, G. LI, X. XIA, D. LO, S. LU, and Z. JIN,
“Summarizing source code with transferred api knowl-
edge,” in Proceedings of the Twenty-Seventh Interna-
tional Joint Conference on Artiﬁcial Intelli-gence (IJCAI
2018), vol. 19, 2018, pp. 2269–2275.

[13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,
L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin,
“Attention is all you need,” in Advances in neural infor-
mation processing systems, 2017, pp. 5998–6008.
[14] A. Vaswani, S. Bengio, E. Brevdo, F. Chollet, A. N.
Gomez, S. Gouws, L. Jones, Ł. Kaiser, N. Kalchbrenner,
N. Parmar et al., “Tensor2tensor for neural machine
translation,” arXiv preprint arXiv:1803.07416, 2018.
[15] A. Raganato, J. Tiedemann et al., “An analysis of
encoder representations in transformer-based machine
translation,” in Proceedings of the 2018 EMNLP Work-

shop BlackboxNLP: Analyzing and Interpreting Neural
Networks for NLP. The Association for Computational
Linguistics, 2018.

[16] K. Cao, C. Chen, S. Baltes, C. Treude, and X. Chen, “Au-
tomated query reformulation for efﬁcient search based
on query logs from stack overﬂow,” in 2021 IEEE/ACM
43rd International Conference on Software Engineering
(ICSE).

IEEE, 2021, pp. 1273–1285.

[17] C. Wang, K. Cho, and J. Gu, “Neural machine translation
with byte-level subwords,” in Proceedings of the AAAI
Conference on Artiﬁcial Intelligence, vol. 34, no. 05,
2020, pp. 9154–9160.

[18] X. Hu, G. Li, X. Xia, D. Lo, and Z. Jin, “Deep code
comment generation with hybrid lexical and syntactical
information,” Empirical Software Engineering, vol. 25,
no. 3, pp. 2179–2217, 2020.

[19] H. J. Kang, T. F. Bissyand´e, and D. Lo, “Assessing the
generalizability of code2vec token embeddings,” in 2019
34th IEEE/ACM International Conference on Automated
Software Engineering (ASE).

IEEE, 2019, pp. 1–12.

[20] W. Wang, Y. Zhang, Y. Sui, Y. Wan, Z. Zhao, J. Wu,
P. Yu, and G. Xu, “Reinforcement-learning-guided source
code summarization via hierarchical attention,” IEEE
Transactions on Software Engineering, 2020.

[21] J. Zhang, X. Wang, H. Zhang, H. Sun, and X. Liu,
“Retrieval-based neural source code summarization,” in
Proceedings of the 42nd International Conference on
Software Engineering. IEEE, 2020.

[22] B. Wei, G. Li, X. Xia, Z. Fu, and Z. Jin, “Code generation
as a dual task of code summarization,” in Advances in
Neural Information Processing Systems, 2019, pp. 6563–
6573.

[23] W. U. Ahmad, S. Chakraborty, B. Ray, and K.-W. Chang,
“A transformer-based approach for source code summa-
rization,” arXiv preprint arXiv:2005.00653, 2020.
[24] N. Chang-An, G. Ji-Dong, T. Ze, L. Chuan-Yi, Z. Yu,
and L. Bin, “Automatic generation of source code com-
ments model based on pointer-generator network,” 2021,
doi:http://dx.doi.org/10.13328/j.cnki.jos.006270.

[25] I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to
sequence learning with neural networks,” in Advances in
neural information processing systems, 2014, pp. 3104–
3112.

[26] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine
translation by jointly learning to align and translate,” in
3rd International Conference on Learning Representa-
tions, ICLR 2015, 2015.

[27] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei,
and I. Sutskever, “Language models are unsupervised
multitask learners,” OpenAI blog, vol. 1, no. 8, p. 9, 2019.
[28] G. Sridhara, L. Pollock, and K. Vijay-Shanker, “Gener-
ating parameter comments and integrating with method
summaries,” in 2011 IEEE 19th International Conference
on Program Comprehension.

IEEE, 2011, pp. 71–80.

[29] X. Wang, L. Pollock, and K. Vijay-Shanker, “Automati-
cally generating natural language descriptions for object-

related statement sequences,” in 2017 IEEE 24th Inter-
national Conference on Software Analysis, Evolution and
Reengineering (SANER).

IEEE, 2017, pp. 205–216.

[30] P. W. McBurney and C. McMillan, “Automatic source
code summarization of context for java methods,” IEEE
Transactions on Software Engineering, vol. 42, no. 2, pp.
103–119, 2015.

[31] L. Moreno, J. Aponte, G. Sridhara, A. Marcus, L. Pol-
lock, and K. Vijay-Shanker, “Automatic generation of
natural language summaries for java classes,” in 2013
21st International Conference on Program Comprehen-
sion (ICPC).
IEEE, 2013, pp. 23–32.

[32] N. J. Abid, N. Dragan, M. L. Collard, and J. I. Maletic,
“Using stereotypes in the automatic generation of natural
language summaries for c++ methods,” in 2015 IEEE
International Conference on Software Maintenance and
Evolution (ICSME).

IEEE, 2015, pp. 561–565.

[33] B. P. Eddy, J. A. Robinson, N. A. Kraft, and J. C.
Carver, “Evaluating source code summarization tech-
niques: Replication and expansion,” in 2013 21st Interna-
tional Conference on Program Comprehension (ICPC).
IEEE, 2013, pp. 13–22.

[34] P. Rodeghero, C. McMillan, P. W. McBurney, N. Bosch,
and S. D’Mello, “Improving automated source code sum-
marization via an eye-tracking study of programmers,”
in Proceedings of the 36th international conference on
Software engineering, 2014, pp. 390–401.

[35] P. Rodeghero, C. Liu, P. W. McBurney, and C. McMillan,
“An eye-tracking study of java programmers and applica-
tion to source code summarization,” IEEE Transactions
on Software Engineering, vol. 41, no. 11, pp. 1038–1054,
2015.

[36] E. Wong, T. Liu, and L. Tan, “Clocom: Mining exist-
ing source code for automatic comment generation,” in
2015 IEEE 22nd International Conference on Software
Analysis, Evolution, and Reengineering (SANER). IEEE,
2015, pp. 380–389.

[37] M. Allamanis, H. Peng, and C. Sutton, “A convolutional
attention network for extreme summarization of source
code,” in International conference on machine learning,
2016, pp. 2091–2100.

[38] W. Zheng, H.-Y. Zhou, M. Li, and J. Wu, “Code atten-
tion: Translating code to comments by exploiting domain
features,” arXiv preprint arXiv:1709.07642, 2017.
[39] Y. Liang and K. Q. Zhu, “Automatic generation of text
descriptive comments for code blocks,” arXiv preprint
arXiv:1808.06880, 2018.

[40] U. Alon, M. Zilberstein, O. Levy, and E. Yahav,
“code2vec: Learning distributed representations of code,”
Proceedings of the ACM on Programming Languages,
vol. 3, no. POPL, pp. 1–29, 2019.

[41] J. Pennington, R. Socher, and C. D. Manning, “Glove:
Global vectors for word representation,” in Proceedings
of the 2014 conference on empirical methods in natural
language processing (EMNLP), 2014, pp. 1532–1543.

[42] A. LeClair, S. Haque, L. Wu, and C. McMillan, “Im-

proved code summarization via a graph neural network,”
arXiv preprint arXiv:2004.02843, 2020.

[43] Q. Chen and M. Zhou, “A neural framework for re-
trieval and summarization of source code,” in 2018
33rd IEEE/ACM International Conference on Automated
Software Engineering (ASE).
IEEE, 2018, pp. 826–831.
[44] W. Ye, R. Xie, J. Zhang, T. Hu, X. Wang, and S. Zhang,
“Leveraging code generation to improve code retrieval
and summarization via dual learning,” in Proceedings of
The Web Conference 2020, 2020, pp. 2309–2319.
[45] B. Liu, T. Wang, X. Zhang, Q. Fan, G. Yin, and
J. Deng, “A neural-network based code summarization
approach by using source code and its call dependencies,”
in Proceedings of the 11th Asia-Paciﬁc Symposium on
Internetware, 2019, pp. 1–10.

[46] Y. Zhou, X. Yan, W. Yang, T. Chen, and Z. Huang,
“Augmenting java method comments generation with
context information based on neural networks,” Journal
of Systems and Software, vol. 156, pp. 328–340, 2019.

[47] S. Haque, A. LeClair, L. Wu, and C. McMillan, “Im-
proved automatic summarization of subroutines via at-
tention to ﬁle context,” arXiv preprint arXiv:2004.04881,
2020.

[48] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova,
transformers
preprint

“Bert: Pre-training of deep bidirectional
for
language
arXiv:1810.04805, 2018.

understanding,”

arXiv

[49] M. Freitag and Y. Al-Onaizan, “Beam search strate-
gies for neural machine translation,” arXiv preprint
arXiv:1702.01806, 2017.

[50] S. Wiseman and A. M. Rush, “Sequence-to-sequence
learning as beam-search optimization,” arXiv preprint
arXiv:1606.02960, 2016.

[51] C.-Y. Lin and F. J. Och, “Automatic evaluation of ma-
chine translation quality using longest common subse-
quence and skip-bigram statistics,” in Proceedings of the
42nd Annual Meeting of the Association for Computa-
tional Linguistics (ACL-04), 2004, pp. 605–612.

[52] D. Guo, W. Zhou, H. Li, and M. Wang, “Hierarchical
lstm for sign language translation,” in Proceedings of the
AAAI Conference on Artiﬁcial Intelligence, vol. 32, no. 1,
2018.

[53] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, “Bleu: a
method for automatic evaluation of machine translation,”
in Proceedings of the 40th annual meeting of the Associ-
ation for Computational Linguistics, 2002, pp. 311–318.
[54] S. Banerjee and A. Lavie, “Meteor: An automatic metric
for mt evaluation with improved correlation with human
the acl workshop on
judgments,” in Proceedings of
intrinsic and extrinsic evaluation measures for machine
translation and/or summarization, 2005, pp. 65–72.
[55] C.-Y. Lin, “Rouge: A package for automatic evaluation of
summaries,” in Text summarization branches out, 2004,
pp. 74–81.

[56] R. Singh and N. S. Mangat, Elements of survey sampling.
Springer Science & Business Media, 2013, vol. 15.

