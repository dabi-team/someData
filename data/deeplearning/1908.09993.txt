9
1
0
2

g
u
A
7
2

]

V

I
.
s
s
e
e
[

1
v
3
9
9
9
0
.
8
0
9
1
:
v
i
X
r
a

Deep Learning-Based Strategy For Macromolecules
Classiﬁcation with Imbalanced Data from Cellular
Electron Cryotomography

1st Ziqian Luo
International School
Beijing University of Posts and Telecommunications
Beijing, China
luoziqian@bupt.edu.cn

2nd Xiangrui Zeng
Computational Biology Department
Carnegie Mellon University
Pittsburgh, United States
xiangruz@andrew.cmu.edu

3rd Zhipeng Bao
Department of Electronic Engineering
Tsinghua University
Beijing, China
bzp15@mails.tsinghua.edu.cn

4th Min Xu
Computational Biology Department
Carnegie Mellon University
Pittsburgh, United States
mxu1@cs.cmu.edu

Abstract—Deep learning model trained by imbalanced data
may not work satisfactorily since it could be determined by major
classes and thus may ignore the classes with small amount of data.
In this paper, we apply deep learning based imbalanced data clas-
siﬁcation for the ﬁrst time to cellular macromolecular complexes
captured by Cryo-electron tomography (Cryo-ET). We adopt
a range of strategies to cope with imbalanced data, including
data sampling, bagging, boosting, Genetic Programming based
method and. Particularly, inspired from Inception 3D network,
we propose a multi-path CNN model combining focal loss and
mixup on the Cryo-ET dataset to expand the dataset, where
each path had its best performance corresponding to each type
of data and let the network learn the combinations of the paths
to improve the classiﬁcation performance. In addition, extensive
experiments have been conducted to show our proposed method
is ﬂexible enough to cope with different number of classes by
adjusting the number of paths in our multi-path model. To our
knowledge, this work is the ﬁrst application of deep learning
methods of dealing with imbalanced data to the internal tissue
classiﬁcation of cell macromolecular complexes, which opened
up a new path for cell classiﬁcation in the ﬁeld of computational
biology.

I. INTRODUCTION

Biological pathways depend on the function of macro-
molecular complexes, whose structure and spatial organization
to the function and dysfunction of pathways.
are critical
Due to the limitations of data acquisition techniques,
the
native structural information of macromolecular complexes
is extremely difﬁcult to obtain [1]. With the development of
biotechnology, Cryo-electron tomography (Cryo-ET) enables
3D visualization of cellular tissue in near-native state and
sub-molecular resolution [2]–[4], making it a powerful tool
for analyzing macromolecular complexes and their spatial
organization within single cells [5].

Corresponding author: Min Xu

However, it is often observed that the macromolecular com-
plex data collected is imbalanced. The protein concentration
difference can be as large as seven orders of magnitude
[6]. One type of macromolecular complexes may dominate
over other types, resulting in a low accuracy. In fact, the
problem of data imbalance also occurs in most real-world
classiﬁcation problems. The collected data follows a long
tail distribution i.e., data for few object classes is abundant
while data for others is scarce. This phenomenon is termed
the data-imbalanced classiﬁcation problem [7]. Although the
problem of data-imbalanced classiﬁcation occurs frequently
in the computer vision ﬁeld, research work on this topic has
been rare in recent years. Almost all competitive datasets avoid
data-imbalanced during the evaluation and training procedures.
For instance,
the case of the popular image classiﬁcation
datasets (such as CIFAR10/100, ImageNet, Caltech101/256,
and MIT67), efforts have been made by the collectors to ensure
that, either all of the classes have a minimum representation
with sufﬁcient data, or that the experimental protocols are
reshaped to use an equal number of images for all classes
during the training and testing processes [8], [9].

In this paper, we conduct extensive experiments and ex-
plore various methods for dealing with the problem of data-
imbalanced classiﬁcation, such as data sampling, bagging,
boosting, Genetic Programming based method. We rigorously
prove that the above various methods are indeed effective, and
apply them to the classiﬁcation of macromolecular complexes
in single cells, and achieved a competitive classiﬁcation perfor-
mance. In particular, we make the following key contributions:

• We summarize various well-known methods for dealing
with data-imbalanced classiﬁcation problems in order
to improve classiﬁcation performance and further ﬁnd

 
 
 
 
 
 
the best combinations with our own model among the
methods.

• We apply the method of dealing with imbalanced data to
the classiﬁcation of cell macromolecular complexes for
the ﬁrst time.

• We propose a novel method to solve the data-imbalanced
problem, termed as multi-path convolutional neural net-
work (CNN), which signiﬁcantly improves the classiﬁca-
tion performance over traditional methods. Moreover, our
model is ﬂexible enough to cope with different number of
classes by adjusting the number of paths in our multi-path
CNN model.

II. RELATED WORK

A. Cryo-electron tomography (Cryo-ET)

is

Cryo-electron tomography (Cryo-ET)

an imaging
technique used to produce high-resolution (4nm)
three-
dimensional views of samples,
typically biological macro-
molecules in cells [9]. Cryo-ET is a specialized application of
transmission electron cryomicroscopy (CryoTEM) in which
samples are imaged as they are tilted, resulting in a series
of 2D images that can be combined to produce a 3D re-
construction, similar to a CT scan of the human body. In
contrast to other electron tomography techniques, samples are
immobilized in non-crystalline (”vitreous”) ice and imaged
under cryogenic conditions (< 150◦C ), allowing them to
be imaged without dehydration or chemical ﬁxation, which
could otherwise disrupt or distort biological structures [9],
[10]. Cryo-electron tomography (Cryo-ET) [11]–[13] enables
the 3D visualization of structures at close-to-native state and
in sub-molecular resolution within single cells [14]–[17].

B. Inception3D Network

[18] propose a 3D variant of tailored inception network
[19], denoted as Inception3D. Inception network is a recent
successful CNN architecture that has the ability to achieve
competitive performance with relatively low computational
cost [18]. CNN [17] are well-known for extracting features
from a image by using convolutional kernels and pooling
layers to emulates the response of an individual to visual
stimuli. This work [20] is the ﬁrst application of deep learning
for systematic structural discovery of macromolecular com-
plexes among large amount (millions) of structurally highly
heterogeneous particles captured by Cryo-ET. It represents
an important step towards large scale systematic detection
of native structures and spatial organizations of large macro-
molecular complexes inside single cells.

C. Mixup: Data-Dependent Data Augmentation

Large deep neural networks are powerful, but exhibit un-
desirable behaviors such as memorization and sensitivity to
adversarial examples. [21] propose mixup, a simple learning
principle to alleviate these issues. Essentially, mixup trains a
neural network on convex combinations of pairs of examples
and their labels. By doing so, mixup regularizes the neural

network to favor simple linear behavior in-between training
examples, and here is how the mixup training loss is deﬁned:
Eλ∼β(0.1)(cid:96)(λx1 + (1 −
Ex2,y2∼ptrain

L(θ) = Ex1,y1∼ptrain
λ)x2, λy1 + (1 − λ)y2)

D. Focal loss

[22], [49] discover that the extreme foreground-background
class imbalance encountered during training of dense detectors
is the central cause. We propose to address this class imbalance
by reshaping the standard cross entropy loss such that it down-
weights the loss assigned to well-classiﬁed examples. [23]
proposed a novel Focal Loss focuses training on a sparse set of
hard examples and prevents the vast number of easy negatives
from overwhelming the detector during training.

E. Sampling

1) Oversampling: Oversampling method achieves sample
balanced by increasing the number of minority samples in the
classiﬁcation. The most straightforward way is to simply copy
a few samples to form multiple records. However, the disad-
vantage of this method is that if there are few sample features,
it may lead to over-ﬁtting problems. Improved oversampling
method by adding random noise, interference data, or certain
rules to generate new synthetic samples in a few classes, such
as SMOTE algorithm. The process is described about SMOTE
method in Algorithm 1.

Algorithm 1 SMOTE(T, N, K)
Input: Number of minority class Samples T ;
Amount of SMOTE %N ;
Number of nearest neighbors k

Output: (N/100) ∗ T synthetic minority class samples

1: (* If N is less than 100%, randomize the minority
class samples as only a random percent of them will be
SMOTEd.*)

2: if N < 100 then
3:

Randomize the T minority class samples
T = (N/100) ∗ T
N = 100

4:
5:
6: end if
7: N = (int)(N/100) (*The amount of SMOTE is assumed

to be in integral multiples of 100.*)

8: k=Number of nearest neighbors
9: numattrs=Number of attributes
10: Sample[ ][ ]: array for original minority class samples
11: newindex: keeps a count of number of synthetic samples

generated, initialized to 0

12: Synthetic[ ][ ]: array for synthetic samples (*Compute k
nearest neighbors for each minority class sample only.*)

13: for i ← 1 to T do
14:

Compute k nearest neighbors for i, and save the indices

in the nnarray

Populate(N, i, nnarray)

15:
16: end for
17: Populate(N, i, nnarray) (*Function to generate the syn-

thetic samples.*)

18: while N (cid:54)= 0 do
19:
20:
21:
22:

Choose a random number between 1 and k, call it nn.
This step chooses one of the k nearest neighbors of i.
for attr ← 1 to numattrs do

Compute: dif = Sample[nnarray[nn]][attr] - Sam-

ple[i][attr]

23:

24:

∗ dif

Compute: gap = random number between 0 and 1
Synthetic[newindex][attr] = Sample[i][attr] + gap

end for
newindex + +
N = N − 1

25:
26:
27:
28: end while
29: return (* End of Populate. *)

2) Undersampling: Another popular method [24], [46] that
results in having the same number of examples in each class.
However, as opposed to oversampling, examples are removed
randomly from majority classes until all classes have the same
number of examples. While it might not appear intuitive, there
is some evidence that in some situations undersampling can
be preferable to oversampling [25]. A signiﬁcant disadvantage
of this method is that
it discards a portion of available
data. To overcome this shortcoming, some modiﬁcations were
introduced that more carefully select examples to be removed.
E.g. one-sided selection identiﬁes redundant examples close
to the boundary between classes [26]. More general approach
than undersampling is data decontamination that can involve
relabeling of some examples [27].

III. OUR METHOD

A. Overview of our model

With the inspiration from Inception 3D network [28], [44],
[45], we propose a novel model termed as multi-path CNN,
combaning with mixup and focal loss method, which could
signiﬁcantly improve performance on the imbalanced Cryo-
ET data. The overview of our proposed model is as shown in
Figure 1.

B. Mixup on the Cryo-ET dataset

Motivated by [29], [42], [43], we introduce a simple and
data-agnostic data augmentation routine, termed as mixup. In
a nutshell, mixup constructs virtual training examples

˜x = λxi + (1 − λ)xj

˜y = λyi + (1 − λ)yj

where xi,xj are raw input vectors, and yi , yj are one-hot
label encodings (xi, yi) and (xj, yj) are two examples drawn
at random from our training data, and λ ∈ [0, 1]. Therefore,
mixup extends the training distribution by incorporating the
prior knowledge that linear interpolations of feature vectors
should lead to linear interpolations of the associated targets.

Fig. 1. Overview architectures of our model.

C. Multi-path CNN

Many subtomogram data from Cryo-ET are imbalanced due
to their different ratio in the cell. However, there is little
work that had been done to solve the problem of imbalanced
data from Cryo-ET. In this section, we describe detaily our
proposed multi-path CNN model showed in Figure 2, which
will be useful to cope with the imbalanced data from Cryo-ET
with the combination of the related works from Section 2.

Unlike traditional CNN which only has a single path with
serial combinations of convolutional kernels and pooling lay-
ers, our multi-path CNN has multiple parallel combinations
of convolutional kernels and pooling layers, based on the
composition of our imbalanced data. More speciﬁcally, the
number of classes from Cryo-ET equals to the number of
parallel paths in our multi-path CNN model. Each path will try
to learn from the imbalanced Cryo-ET data and become the
best classiﬁer corresponding to a certain type of data before the

note that the implementation of the loss layer combines the
sigmoid operation for computing p with the loss computation,
resulting in greater numerical stability.

F. Evaluation metrics

Evaluation metrics play an important role in assessing the
classiﬁcation performance and guiding the model design. Most
of the traditional methods dealing with the imbalanced data
concentrate on binary classiﬁcation. In binary classiﬁcation
problem, class labels can be divided as positive and negative.
As the confusion matrix shows in Table 1,
true positive
(TP) and true negative (TN) denote the number of positive
and negative samples that are correctly classiﬁed while false
negative (FN) and false positive (FP) denote the number of
positive and negative samples that are wrongly classiﬁed.

Accuracy is the most commonly used metric to evaluate
model performance, however, it is no longer a proper measure
in imbalanced classiﬁcation problem since the minor class has
minimal impact on accuracy compared with the major class.
To solve the problem, a pair of metrics, precision and recall,
have been adopted.

precision =

T P
T P + F P

recall =

T P
T P + F N

Meanwhile, F-Score is used to integrate precision and recall

into a single metric for convenient evaluation of model.

Fβ=(1 + β2) ·

precision · recall
(β2 · precision) + recall

Where β represents the weight between precision and recall.
During our evaluation process, we set β = 1 since we regard
precision and recall has the same weight thus F1-score is
adopted.

However, in multi-class classiﬁcation, we use Macro F1-

Score to evaluate the result.

M acro F1=

F1n

N
(cid:80)
n=1
N

where n represents the number of classiﬁcation and F1n is the
F1 score on nth category.

G-mean is another recognized metric derived from confu-

sion matrix.

G − mean =

(cid:114) T P

+

T N
T N + F P

T P + F N
In multi-class classiﬁcation, we also use Macro G-mean to
evaluate the result, measure the balanced performance of a
learning model.

Fig. 2. Model of multi-path CNN

concatenate layer. The reason about ﬁrstly trying to determine
each single path for each type of data from Cryo-ET is that it
will be easier to ﬁnd a classiﬁer through deep learning that will
behave well in recognizing a single class of data, regardless
of other classes.

In order to ﬁnd the best classiﬁer for a certain type of data
from Cryo-ET, we ﬁrstly carry out a lot of experiments with
serial CNN and ﬁnd its best structure to recognize a single type
from the imbalanced dataset. All paths will be concatenated
together when they are identiﬁed respectively. It
is worth
mentioning that sampling methods have not been used in the
whole process since it may lead to overﬁtting or underﬁtting.
Each single path learns how to do the classiﬁcation job from
the original imbalanced data and whole multi-path CNN learns
how to balance between these paths and make a more precise
decision towards all the types of data from Cryo-ET.

D. Filter Concat

The ﬁnal model obtains the most suitable convolution kernel
on each path, so that the model effect is optimal, and then
combines the best parameters learned by the models on the
four paths, and ﬁnally enters the new pooling layer through
a ﬁlter. The ﬁnal classiﬁcation result is obtained by softmax
through the full connection of the L layer.

E. Focal Loss for imbalanced classiﬁcation

We use an α-balanced variant of the focal loss:

F L(pt) = −αt(1 − pt)γlog(pt)

M acro G − mean=

We adopt this form in our experiments as it yields slightly
improved accuracy over the non-α-balanced form. Finally, we

where n represents the number of classiﬁcation and Gn is the
G-mean on nth category.

Gn

N
(cid:80)
n=1
N

Real positives
Real negatives

pridicted positives
TP
FP
TABLE I
CONFUSION MATRIX FOR BINARY CLASSIFICATION

predicted negatives
FN
TN

Number
Ratio(%)

proteasome d
1043
63.481

ribosome
80
4.869
TABLE II
CLASS RATIO OF CRYO-ET DATASET.

TRiC
125
7.608

proteasome s
386
23.494

(a) proteasome d

(b) ribosome

(c) TRiC

(d) proteasome s

Fig. 3. The 2D visualizations of the 3D macro molecules

IV. EXPERIMENTS

A. Dataset details

Furthermore,

reference-free classiﬁcation and averaging
were tested on a dataset consisting of 125 TCP-1 ring complex
(TRiC) subtomograms, 386 single capped proteasome (protea-
some s) subtomograms, 1043 double capped proteasome (pro-
teasome d) subtomograms, and 80 ribosome subtomograms
extracted from a tomogram of rat neuron with expression of
poly-GA aggregate. All subtomorgams were two times binned
to size 403 (voxel size: 1.368 nm). The tilt angle range was
−50◦ to +70◦.

The four types of macro molecules in our Cryo-ET dataset,
which are proteasome d,
ribosome, TRiC, proteasome s,
whose imbalanced ratio are shown in Table 2. The Figure 3
are the 2D visualizations of the 3D macro molecules.

In order to train and test our multi-path CNN, we shufﬂe
and split our dataset with two parts. There are 1307 samples
in the training set and 327 samples in the testing set.

B. Baseline Methods

1) Bagging:

[30] introduced the concept of bootstrap
aggregating to construct ensembles. It consists in training
different classiﬁers with bootstrapped replicas of the original
training data-set. That is, a new data-set is formed to train each
classiﬁer by randomly drawing (with replacement) instances
from the original data-set (usually, maintaining the original
data-set size). Hence, diversity is obtained with the resampling
procedure by the usage of different data subsets. Finally, when
an unknown instance is presented to each individual classiﬁer,
a majority or weighted vote is used to infer the class [31].

2) Boosting: Boosting (also known as ARCing, adaptive
resampling and combining) was introduced by Schapire in

Classes in Cryo-ET

proteasome d
ribosome
TRiC
proteasome s

path 1

path 2

path 3

path 4

F1
71.7
69.7
72.6
71.2

G-mean
81.2
78.1
81.2
80.4

F1
68.3
74.2
71.7
69.2

G-mean
79.2
82.6
79.8
78.5

F1
69.0
72.3
74.8
72.7

G-mean
78.5
79.4
83.8
81.9

TABLE III
BINARY CLASSIFICATION BY FOUR DIFFERENT PATHS

F1
70.8
71.4
74.1
73.3

G-mean
80.2
77.6
82.4
83.0

Model

Multi-path CNN
Multi-path CNN with boosting
Multi-path CNN with bagging
Multi-path CNN with SMOTE
Multi-path CNN with undersampling
Multi-path CNN with GP
Multi-path CNN with mixup
Multi-path CNN with focal loss
Multi-path CNN with SMOTE + boosting
Multi-path CNN with SMOTE + bagging
Multi-path CNN with SMOTE + GP
Multi-path CNN with mixup+focal loss

Macro F1
68.1
69.3
69.0
69.7
69.1
70.4
70.9
71.1
70.1
71.4
72.6
73.6

Cryo-ET

Macro G-mean
78.1
80.3
79.8
78.6
77.3
78.2
80.2
80.7
78.2
80.2
81.5
84.7

TABLE IV
MULTI-PATH CNN COMBINED WITH DIFFERENT STRATEGIES ON IMBALANCED CRYO-ET

1990 [32]–[34]. Schapire proved that a weak learner (which
is slightly better than random guessing) can be turned into a
strong learner in the sense of probably approximately correct
(PAC) learning framework. AdaBoost [35] is the most repre-
sentative algorithm in this family, it was the ﬁrst applicable
approach of Boosting, and it has been appointed as one of the
top ten data mining algorithms [36].

3) Genetic Programming (GP): GP [37] is an evolutionary
algorithm technique inspired from biological evolution to ﬁnd
computer programs that perform a user-deﬁned task, which
can evolve biased classiﬁers when data sets are unbalanced.
In GP, programs representing different solutions to a problem
are combined with other programs to create new hopefully
better programs; this process is repeated over a number of
generations until a good solution is evolved [38]–[40]. [41]
proposed GP methods utilize the unbalanced data as is in
the learning phase, requiring no prior knowledge about the
problem domain, to evolve classiﬁers with good classiﬁcation
ability on both minority and majority classes.

C. Identiﬁcation of each path in Multi-path CNN

Before carrying out the experiment corresponding to the
whole model in Figure 2, we have carried out lots of exper-
iments to identify each suitable path in the multi-path CNN
model. We name the four paths with path 1, path 2, path 3
and path 4, from left to right in the model in Figure 2. Each
path has the best binary classiﬁcation result on one of the four
classes in Cryo-ET. For example, as shown in Table 3, path 1
behaves best on proteasome d, while path 3 has the best result
on TRiC class. During the experiment in each single path, we
degenerate the multi-class classiﬁcation problem with binary
classiﬁcation, say, the CNN branch in path 1 will only tell
whether the input belongs to proteasome d class and path 3
will only judge whether the input belongs to TRiC class.

D. Multi-path CNN with traditional strategies on imbalanced
dataset

We have done some experiments to combine the multi-path
CNN with recognized and effective strategies like boosting,
bagging, SMOTE, focal loss and mixup method, towards the
imbalanced dataset. The results are shown in Table 4.

Experiments have also been done to compare the multi-
path CNN with traditional classiﬁer, Granular Support Vector
Machine with Repetitive Undersampling(GSVM-RU), [47],
[48]. Besides SVM modeling, GSVM-RU adds another hyper-
parameter G, the number of negative granules. To solve the
problems in multi-class classiﬁcation with binary classiﬁer,
we use the method in Figure 4 to decompose the multi-class
problem into a binary class problem. The experiment results
are shown in Table 5.

Several pairs of experiments have also been done to show
that our model be adjusted to two or three classes classiﬁcation
problem, rather than restricted in four classes classiﬁcation
problem. We conduct GSVM-RU on different number of
classes as baseline for comparison. The results are shown in
the Table 6.

E. Discussion

Cryo-ET has become a powerful tool for 3D visualization
of cellular components in sub-molecular resolution and near-
primary ecology [50]. However, imbalanced classiﬁcation in
cellular tomograms is difﬁcult due to the high complexity of
image content and imaging limitations. In order to complement
the existing method, in this paper, we propose a multi-path
CNN combined with mixup and focal loss strategy which will
have the best classiﬁcation result on the imbalanced data from
Cryo-ET. The above experiment results demonstrate the power
of our approach and they have also indicated that by changing
the number of paths in our multi-path, the model can be

Model

Multi-path CNN with mixup + focal loss
GSVM-RU

Cryo-ET

Macro F1
73.6
69.5

Macro G-mean
84.7
80.3

TABLE V
COMPARISON BETWEEN MULTI-PATH CNN MODEL AND TRADITIONAL METHOD

Model

Four-path CNN with mixup + focal loss
GSVM-RU(based on four classes)
Three-path CNN with mixup + focal loss
GSVM-RU(based on three classes)
Two-path CNN with mixup + focal loss
GSVM-RU(based on two classes)

Macro F1
73.6
69.5
74.3
70.1
76.4
71.2

Cryo-ET

Macro G-mean
84.7
80.3
85.5
81.6
87.2
81.9

TABLE VI
COMPARISON OF DIFFERENT NUMBER OF PATHS IN MULTI-PATH CNN

Fig. 4. Multiclass classiﬁcation achieved by binary classiﬁer

adapted to cope with imbalanced classiﬁcation problems with
different number of classes. The work provides useful steps
for imbalanced classiﬁcation in cell tomography. To the best
of our knowledge, our work is the ﬁrst application of CNN-
based network with focal loss and mixup method in Cryo-ET
data analysis. Our approach is a useful complement to current
technology

V. CONCLUSION

In this paper, we apply the method of dealing with im-
balanced data to the classiﬁcation of cell macromolecular
complexes for the ﬁrst time, which opened up a new path
for cell classiﬁcation in the ﬁeld of computational biology.
In order to solve the imbalanced data problem from Cryo-
ET, we propose a multi-path CNN model combined with
recognized strategies to deal with data imbalance issue like
sampling, bagging and boosting and genetic programming. We
have also made combinations among the methods and with
our model. The multi-path CNN model consists of several
independent paths that behave best in each class respectively.
By adjusting the number of the paths in the model, we
can deal with a more generalized classiﬁcation problem with
different number of classes. Experiments and comparisons

with traditional classiﬁers have shown that the model can work
effectively on the imbalanced data from Cryo-ET. In the future,
we will also consider more issues in the ﬁeld of computer
and bio-related technologies to promote the development of
computational biology.

VI. ACKNOWLEDGEMENT

This work was supported in part by U.S. National Institutes

of Health (NIH) grant P41 GM103712.

REFERENCES

[1] Xu M, Chai X, Muthakana H, et al. Deep learning-based subdivision ap-
proach for large scale macromolecules structure recovery from electron
cryo tomograms[J]. Bioinformatics, 2017, 33(14): i13-i22.

[2] Zeng X, Leung M, Zeev-Ben-Mordehai T, Xu M. A convolutional
autoencoder approach for mining features in cellular electron cryo-
tomograms and weakly supervised coarse segmentation. Journal of
Structural Biology (2017). arXiv:1706.04970.

[3] Liu C, Zeng X, Wang K, et al. Multi-task Learning for Macromolecule
Classiﬁcation, Segmentation and Coarse Structural Recovery in Cryo-
Tomography[J]. arXiv preprint arXiv:1805.06332, 2018.

[4] Wang K W, Zeng X, Liang X, et al. Image-derived generative modeling
of pseudo-macromolecular structures-towards the statistical assessment
of Electron CryoTomography template matching[J]. arXiv preprint
arXiv:1805.04634, 2018.

[5] Zhao Y, Zeng X, Guo Q, et al. An integration of fast alignment and
maximum-likelihood methods for electron subtomogram averaging and
classiﬁcation[J]. arXiv preprint arXiv:1804.01203, 2018.

[33] Barandela R, Rangel E, Snchez J S, et al. Restricted decontamination
for the imbalanced training sample problem[C]. Iberoamerican Congress
on Pattern Recognition. Springer, Berlin, Heidelberg, 2003: 424-431.

[34] Eggermont J, Kok J N, Kosters W A. Genetic programming for data
classiﬁcation: Partitioning the search space[C]. Proceedings of the 2004
ACM symposium on Applied computing. ACM, 2004: 1001-1005.
[35] Abraham J. Wyner, Matthew Olson, et,al. Explaining the Success
of AdaBoost and Random Forests as Interpolating Classiﬁers. arXiv
preprint arXiv:1504.07676, 2017.

[36] Qing-Yan Yin, Jiang-She Zhang, et, al. An Empirical Study on the Per-
formance of Cost-Sensitive Boosting Algorithms with Different Levels
of Class Imbalance. Volume 2013, Article ID 761814, 12 pages.
[37] T. N. Sainath, O. Vinyals, A. Senior, and H. Sak, Convolu- tional,
long short-term memory, fully connected deep neural networks, in IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP). IEEE, 2015, pp. 45804584.

[38] D.Palaz,R.Collobertetal.,Analysis of cnn-based speechrecog- nition sys-

tem using raw speech as input, in Proceedings of Interspeech, 2015.

[39] Tang Y, Zhang Y Q, Chawla N V, et al. SVMs modeling for highly
imbalanced classiﬁcation[J]. IEEE Transactions on Systems, Man, and
Cybernetics, Part B (Cybernetics), 2009, 39(1): 281-288.

[40] Szegedy C, Ioffe S, Vanhoucke V, et al. Inception-v4, inception-resnet
and the impact of residual connections on learning[C]. AAAI. 2017, 4:
12.

[41] Urvesh Bhowanm, Mark Johnston, et al. Reusing Genetic Programming
for Ensemble Selection in Classiﬁcation of Unbalanced Data. IEEE
Transactions on Evolutionary Computation, Volume: 18 Issue: 6, 2014
[42] Galar M, Fernandez A, Barrenechea E, et al. A review on ensembles
for the class imbalance problem: bagging-, boosting-, and hybrid-based
approaches[J]. IEEE Transactions on Systems, Man, and Cybernetics,
Part C (Applications and Reviews), 2012, 42(4): 463-484.

[43] T. DeVries and G. W. Taylor. Dataset augmentation in feature space.

ICLR Workshops, 2017.

[44] Behzad Hasani, et al. Facial Expression Recognition Using Enhanced
Deep 3D Convolutional Neural Networks, IEEE Conference on Com-
puter Vision and Pattern Recognition Workshops, 2017

[45] Christian Szegedy, Vincent Vanhoucke, et al. Rethinking the Inception

Architecture for Computer Vision, CVPR, 2016.

[46] Mayuri S. Shelke, et al. A Review on Imbalanced Data Handling Using
Undersampling and Oversampling Technique, IJRTER, Volume 03, Issue
04; April, 2017

[47] Mateusz Buda, Atsuto Maki, et al. A systematic study of the class
imbalance problem in convolutional neural networks, arXiv preprint
arXiv:1710.05381, 2017

[48] Zhang H, Cisse M, Dauphin Y N, et al. mixup: Beyond empirical risk

minimization[J]. arXiv preprint arXiv:1710.09412, 2017.

[49] Lin T Y, Goyal P, Girshick R, et al. Focal loss for dense object detec-
tion[J]. IEEE transactions on pattern analysis and machine intelligence,
2018.

[50] Guo Q, Lehmer C, Martnez-Snchez A, Rudack T, Beck F, Hartmann
H, Prez-Berlanga M, Frottin F, Hipp MS, Hartl FU, Edbauer D. In situ
structure of neuronal C9orf72 Poly-GA aggregates reveals proteasome
recruitment. Cell. 2018 Feb 8;172(4):696-705.

[6] Beck M, Schmidt A, Malmstroem J, et al. The quantitative proteome of
a human cell line. Molecular Systems Biology, volume 7, pages 549;
November, 2011.

[7] Khan S H, Hayat M, Bennamoun M, et al. Cost-sensitive learning of
deep feature representations from imbalanced data[J]. IEEE transactions
on neural networks and learning systems, 2018, 29(8): 3573-3587.
[8] Lee C Y, Xie S, Gallagher P, et al. Deeply-supervised nets[C]. Artiﬁcial

Intelligence and Statistics. 2015: 562-570.

[9] Gan L, Jensen G J. Electron tomography of cells[J]. Quarterly reviews

of biophysics, 2012, 45(1): 27-56.

[10] Allison Doerr. Cryo-electron tomography. Nature Methods, volume 14,

page 34; December, 2016

[11] Oikonomou C M, Chang Y W, Jensen G J. A new view into prokaryotic
cell biology from electron cryotomography[J]. Nature Reviews Micro-
biology, 2016, 14(4): 205.

[12] Vanhecke D1, Asano S, et al. Cryo-electron tomography: methodology,
developments and biological applications, 2011 Jun;242(3):221-7.
[13] Rossitza N. Irobalieva, Bruno Martins, Ohad Medalia. Cellular structural
biology as revealed by cryo-electron tomography, J Cell Sci 2016 129:
469-476

[14] Lui V, Rigort A, Baumeister W. Cryo-electron tomography: the challenge
of doing structural biology in situ[J]. J Cell Biol, 2013, 202(3): 407-419.
[15] Asano S, Fukuda Y, Beck F, et al. A molecular census of 26S protea-
somes in intact neurons[J]. Science, 2015, 347(6220): 439-442.
[16] Koning RI1, Koster AJ2, Sharp TH3. Advances in cryo-electron tomog-

raphy for biology and medicine. 2018, May;217:82-96.

[17] Murata K, Liu X, Danev R, et al. Zernike phase contrast cryo-electron
microscopy and tomography for structure determination at nanometer
and subnanometer resolutions[J]. Structure, 2010, 18(8): 903-912.
[18] Zhao G, Zhou B, Wang K, Jiang R, Xu M. Respond-CAM: Analyzing
Deep Models for 3D Imaging Data by Visualizations. Medical Im-
age Computing and Computer Assisted Intervention (MICCAI) 2018.
arXiv:1806.00102

[19] Rigort A, Buerlein F J B, Villa E, et al. Focused ion beam microma-
chining of eukaryotic cells for cryoelectron tomography[J]. Proceedings
of the National Academy of Sciences, 2012.

[20] Liu C, Zeng X, Lin R, Liang X, Freyberg Z, Xing E, Xu M. Deep
learning based supervised semantic segmentation of Electron Cryo-
Subtomograms. IEEE International Conference on Image Processing
(ICIP) 2018. arXiv:1802.04087

[21] Ekin D. Cubuk, Barret Zoph, et al. Intriguing Properties of Adversarial

Examples. arXiv preprint, arXiv:1711.02846

[22] Haixiang G, Yijing L, Shang J, et al. Learning from class-imbalanced
data: Review of methods and applications[J]. Expert Systems with
Applications, 2017, 73: 220-239.

[23] Levi G, Hassner T. Age and gender classiﬁcation using convolutional
neural networks[C]. Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition Workshops. 2015: 34-42.

[24] Janowczyk A, Madabhushi A. Deep learning for digital pathology image
analysis: A comprehensive tutorial with selected use cases[J]. Journal
of pathology informatics, 2016, 7.

[25] Jaccard N, Rogers T W, Morton E J, et al. Detection of concealed cars in
complex cargo X-ray imagery using deep learning[J]. Journal of X-ray
Science and Technology, 2017, 25(3): 323-339.

[26] Wang K J, Makond B, Chen K H, et al. A hybrid classiﬁer combining
SMOTE with PSO to estimate 5-year survivability of breast cancer
patients[J]. Applied Soft Computing, 2014, 20: 15-24.

[27] Chawla N V, Bowyer K W, Hall L O, et al. SMOTE: synthetic minority
over-sampling technique[J]. Journal of artiﬁcial intelligence research,
2002, 16: 321-357.

[28] Christian Szegedy, Wei Liu, et al. Going deeper with convolutions.

CVPR, 2015.

[29] Arpit, S. Jastrzebski, Y. Bengio, et al. A closer look at memorization in

deep networks. ICML, 2017.

[30] Shen L, Lin Z, Huang Q. Relay backpropagation for effective learning
of deep convolutional neural networks[C]. European conference on
computer vision. Springer, Cham, 2016: 467-482.

[31] Mikel Galar, Alberto Fernandez, et,al. A Review on Ensembles for
the Class Imbalance Problem: Bagging-, Boosting-, and Hybrid-Based
Approaches, 2011, IEEE TRANSACTIONS ON SYSTEMS, MAN,
AND CYBERNETICSPART C: APPLICATIONS AND REVIEWS
[32] Kubat M, Matwin S. Addressing the curse of imbalanced training sets:

one-sided selection[C]. ICML. 1997, 97: 179-186.

