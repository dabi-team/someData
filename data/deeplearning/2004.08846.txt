BuGL - A Cross-Language Dataset for Bug Localization∗

Sandeep Muvva, A Eashaan Rao, Sridhar Chimalakonda
Research in Intelligent Software & Human Analytics (RISHA) Lab
Indian Institute of Technology Tirupati India
{cs16b017,cs19s501,ch}@iittp.ac.in

0
2
0
2

r
p
A
9
1

]
E
S
.
s
c
[

1
v
6
4
8
8
0
.
4
0
0
2
:
v
i
X
r
a

ABSTRACT
Bug Localization is the process of locating potential error-prone
files or methods from a given bug report and source code. There is
extensive research on bug localization in the literature that focuses
on applying information retrieval techniques or machine learn-
ing/deep learning approaches or both, to detect location of bugs.
The common premise for all approaches is the availability of a good
dataset, which in this case, is the standard benchmark dataset that
comprises of 6 Java projects and in some cases, more than 6 Java
projects. The existing dataset do not comprise projects of other
programming languages, despite of the need to investigate specific
and cross project bug localization. To the best of our knowledge,
we are not aware of any dataset that addresses this concern. In
this paper, we present BuGL, a large-scale cross-language dataset.
BuGL constitutes of more than 10,000 bug reports drawn from open-
source projects written in four programming languages, namely C,
C++, Java, and Python. The dataset consists of information which
includes Bug Reports and Pull-Requests. BuGL aims to unfold new
research opportunities in the area of bug localization.

KEYWORDS
Cross-Language Dataset, Bug Reports, Pull Requests, Bug Localiza-
tion

1 INTRODUCTION
Bug in a software system is an underlying cause of a fault/error
which make the software to deviate from its correct behaviour [21].
Bug Localization task is to locate the bug position in the source
code and is considered as one of the critical activities in software
maintenance cycle. During pre and post-release, many bugs are
identified and reported [21]. Automatically identifying the most
probable source that causes the defect could greatly reduce the
effort of developers in localizing the source of the bug [15]. Bug
description comes in the form of bug reports that majorly contain
natural text [7]. It also accommodates stack traces and code snip-
pets, that provide structured information related to a bug [16]. For
locating the source of the bug using bug reports, two prominent
strategies - Information Retrieval (IR) and Hybrid approach con-
sisting of IR + Machine Learning (ML) + Deep Learning (DL) have
been suggested by researchers.

IR addresses Bug Localization as a "document retrieval problem"
[2]. From the textual information present in the bug report, queries
are fired to fetch top-ranked source files that could possibly contain
bugs. Many IR based techniques and tools exist in the literature
[12, 18, 23, 25]. Lukins et al. [12], created a static LDA model from
the source code that generates n-topics having n-words each. This

∗

BuGL is publicly available along with dataset, documentation and scripts at https:
//github.com/muvvasandeep/BuGL.

model can be queried for bugs that result in a set of files, ranked
based on the probability distribution. The projects used for this
technique are Mozilla, Eclipse, and Rhino. BugLocator, utilizes the
revised Vector Space Model (rVSM) [25] to rank files based on the
textual similarity between source code and bug report, along with
the history of similar bug fixes taken from Eclipse, AspectJ, SWT,
and Zxing. Similar projects have been tested by BLUiR tool, that
employs class names, method names, and bug summaries to rank
files and was observed that these rankings outperform BugLocator
[18]. Some other criteria, such as version history [23] and similar
bug history [19, 23], have been considered, along with bug reports
and source code for bug localization. Certain techniques such as seg-
mentation [20], where source code is bifurcated into segments, and
stack trace, which contains all the data related to invocation calls
till an exception is encountered [16, 20] are studied and leveraged
in bug localization due to the structured information they provide.
Stack-trace analysis and segmentation are complementary to each
other and thus provide a better ranking of files [20]. Despite the
availability of many techniques, current state-of-the-art IR-based
tools are still observed to be unreliable [9].

Hybrid approaches consist of a mixture of methods (IR, ML, and
DL) to reduce the "lexical gap" that exists between source code
and bug reports and provides higher accuracy in bug localization
[15]. Koyuncu et al. [7] have proposed a divide and conquer IR
based approach and also examined the query formulation and its
impacts on the localization performance. They implemented a multi-
classifier approach to compute weights and assign them to the
features extracted from bug reports and source code. A training
dataset which contains exact bug-location pairs has been created
and was passed to the gradient-boosting method to build multiple
classifier model. DNNLOC [8] leverages the features extracted from
textual similarity of a bug report and source code using rVSM. DNN
learns these extracted features and relates them with code tokens
from the source code [8]. DeepLocator [22] uses enhanced CNN for
utilizing full semantic information and bug-fixing history, which
are available in AspectJ, Eclipse, JDT, SWT and Tomcat projects. It
uses revised Term Frequency-Inverse Document Frequency (rTF-
IDuF) to find relevant terms from the bug reports. Word embedding
technique, i.e., word2vec, converts relevant terms from bug reports
and AST from source code into vectors. These vectors are passed
on to CNN, which predicts the localized file for a given bug. In
view of cross-project bug localization, TRANP-CNN [5] extracts
semantic features available from the source project and maps it to
the target project. A system named CAST, which extracts lexical
and semantic information from the bug report and source code,
applies tree-based CNN along with customized AST [11].

A common point for all these techniques is that the projects on
which these techniques are applied are written in Java. AspectJ,
Eclipse, JDT, SWT, Tomcat, Zxing are the most commonly used

 
 
 
 
 
 
projects in bug localization [8, 11, 15, 18–20, 22, 23, 25]. While Rath
et al. have used “IlmSeven” [17] dataset in [16], TRANP-CNN used
dataset containing 3 Java projects - HTTPClient, Jackrabbit, Lucene-
Java [6]. Koyuncu et al. have used the benchmark dataset in bug
localization known as Bench4BL [10] in [7].

Most of the bug localization approaches are applied only on
few Java projects. These projects have bug data from well-known
bug-tracking systems such as Bugzilla1 and JIRA2, and are avail-
able in proper format. However, there are many projects stored on
open source code sharing platforms such as GitHub, where bug
reports are not adequately documented or available. Thus, there
is a need to expand the domain of bug localization with respect to
bug reports availability and to improve the techniques to handle
different projects written in multiple programming languages. This
drive leads us to the creation of "BuGL" dataset. The dataset com-
prises of projects from four different programming languages- C,
C++, Java, and Python. It consists of bug reports along with pull
requests which fixed the issue mentioned in the bug report. BuGL
collectively has more than 10K bugs. The projects chosen here are
different from the ones mentioned in the literature. The purpose
of creating this dataset is to allow researchers to undertake bug
localization challenges which can have various characteristics such
as distinct languages, bug reports, projects, techniques, and so on.
There are few cross-language datasets available in the literature
which provide a myriad of opportunities to understand the devel-
opment process of a software, without being restricted to any par-
ticular programming language. GitHub is one of the largest sources
for open software artifacts, being the source of extraction for many
datasets including BuGL. Public Git Archive [13] and GHTorrent [3]
are some of the large scale open-source code datasets extracted
from GitHub. Software Heritage Graph dataset is the largest "public
archive of software source code that comes along with development
history" [14].

Datasets have been proposed to study various aspects of software
engineering in specific. Gousious et al. have proposed pullreqs
dataset to support the study of pull-based development models
[4]. DupPR has been created by Yu et al. to study duplicate pull
requests [24]. However, to the best of our knowledge, no cross-
language dataset to study bug localization is available, motivating
the creation of “BuGL” dataset.

2 DATASET
2.1 Objectives
Currently, most of the bug localization techniques/tools are de-
veloped based on existing benchmark dataset that consists only
Java projects, which was constructed around 2014. Later in 2018,
Lee et al. [10] created a dataset of 51 projects (5 old subjects and
46 new subjects) and 10,017 bug reports from Java to conduct a
reproducibility study of the performance of IR based bug local-
ization techniques with a large number of subjects. But whether
these techniques/tools work as good as on the datasets constructed
with other programming languages still remains as a question. This
query motivated us to construct BuGL, a dataset of four different
programming languages, namely C, C++, Python, and Java, which

1https://www.bugzilla.org/
2https://www.atlassian.com/software/jira

Figure 1: Methodology for curating the Dataset

could be used as a benchmark dataset for Bug Localization in the
future along with comparative studies with the current benchmark
dataset.

2.2 Methodology for choosing the projects
GitHub is a good source of open source projects. From millions of
public repositories, artifacts such as issues and pull requests are
extracted and used for large-scale studies. GitHub has some features
such as stars, best matches and so on, which infers the number of
developers interested in the project, and thus acts as an index of
popularity [1]. For choosing the primary programming language of
a project, we used GitHub’s linguistic feature. Almost all the GitHub
projects have open and closed issues and pull requests. We include
projects having no less than 500 closed issues and pull requests,
with the intuition that at least 100 issues could be correlated to pull
requests which solved those issues, which, as a result could provide
vital metadata information about bugs.

2.3 Methodology for filtering the bugs
Issues in GitHub repository usually do not have the important
metadata such as files changed while resolving the issues, number
of lines changed in each file, and so on, which play an essential
role in Bug Localization, but, pull requests contain such useful
information. However, a pull request in GitHub need not be a bug
fix, but could be an enhancement, bug, or a feature. Hence, pull
requests cannot be considered as bugs by default. However, some
of the assignees label a pull request with specific keywords such
as bug, feature, and enhancement. But most of the pull requests do
not have such labels. Thus, identifying correlation between pull
requests and issues could fetch required metadata of the issues to
be included in the dataset.

Issues have been correlated with pull requests based on the
description of pull requests and keywords such as fixes, resolves,
and so on, followed by #issue ID. If the assignee merges a pull
request after verification, then the issue is treated as closed. This

2

Figure 2: Metadata of a sample bug

implies that the merging of the pull request has resolved specific
issue with the mentioned issue ID. The metadata from this pull
request can be used for the issue raised in the repository.

2.4 Dataset Creation
Projects present in the dataset are manually curated to carefully in-
clude only those projects that met the criteria mentioned in Section
2.2. Projects were extracted from four different languages- C, C++,
Python, and Java, based on a three-step selection process, presented
below:

• Using GitHub’s linguistic feature, projects were selected by

identifying their primary programming language.
• Projects were sorted based on the number of stars.
• Manual selection of projects based on selection criteria men-

tioned in Section 2.2

Figure 1 summarises the methodology adopted for curating the
dataset. We selected 54 projects consisting of 10,187 bugs, that
included 21 projects from C, 11 from C++, 12 from Python, 10
from Java and downloaded all the selected projects. The aim is to
accumulate at least 2000 issues from multiple projects for each pro-
gramming language. That’s why there are varying project numbers
across these programming languages.

In the next step, we collected metadata of correlated pull re-
quests and issues. We executed a python script and used sele-
nium and chrome driver to scrape the required metadata and then,
stored it in json and xlsx formats. We manually analyzed the
GitHub page for each project and found some common CSS se-
lectors like class name, id, or XPath, which were used to extract
the metadata like issue id, description, and so on. As shown in
the Figure 2, metadata includes issue id, issue summary, issue de-
scription, issue reporting time, issue status, fixed by (id of the
pull request which closes the issue on merging), pull request de-
scription, pull request status, files changed and number of files
changed in each file. For open issues, metadata related to pull re-
quests is empty. Figure 3 summarises the schema of BuGL, there are
4 tables namely Project_Repository, GitHub_Pull_Request,
Metadata_of_Bug and GitHub_Issue. Here GitHub issues are
mapped with GitHub Pull Request as mentioned in Section 2.3.
Metadata for each bug can be found in the table Metadata_of_Bug
having fields such as issue_id, issue_summary, issue_status,
fixed_by and so on.

Figure 3: Database Schema

2.5 Dataset Statistics
Table 1 represents the statistics of BuGL and Table 2 represents
language-wise statistics of BuGL. The final dataset consists of meta-
data and source code of projects having at least 500 pull requests,
and at the minimum 10 issues which have been resolved by pull re-
quests. A .xlsx file (“BuGL details” in the dataset) contains the name
of the repository, number of stars, GitHub link, number of open
and closed issues, number of open and closed pull requests, and
number of bugs. No less than 10 projects from each programming
language are included in the dataset.

Number of projects
Number of closed issues
Average Number of issues
Total number of issues closed by pull requests
Average number of issues closed by pull requests

54
151161
2799
10187
189

Table 1: Statistics of final dataset

3 RESEARCH OPPORTUNITIES
BuGL could be a valuable resource in the area of Software Bugs.
Our dataset has been carefully curated and provides attributes such
as bug reports, pull requests, file changes, and other metadata with
respect to bugs. The unique aspect of this dataset is the diversity
of bugs from different programming languages, which makes it
suitable for a wide range of use cases. The BuGL dataset could
provide several research opportunities and could serve as a standard
dataset for software-bug related studies.

Below we highlight a few research questions and insights that

could be leveraged through BuGL.

3

Language

No. of Projects

C
C++
Python
Java

21
11
12
10

Closed Pull
Requests
51408
37198
32454
47258

Closed
Issues
36617
30227
39760
44557

Open Issues No. of Issues closed by

8608
3607
6767
4210

Pull Requests
2462
2222
2626
2877

Table 2: Programming language wise statistics in BuGL

• Bug Localization: One of the main applications of our
dataset is to facilitate research in locating source of the bug.
It aids in comprehending bugs from the projects written in
several programming languages. BuGL allows researchers to
investigate topics relevant to bug localization such as Finding
similarity between bugs occurring in different programming
languages, Testing if the existing bug-localization techniques
work on BuGL, Studying if change in programming languages
affect bug localization process, Analysing use of bug data on
from projects in one programming language in facilitating bug
localization for projects written in a different programming
language, Variation of bug localization techniques for projects
developed in the open-source and proprietary environments.
We are working towards answering these questions using
the proposed dataset.

• Cross-Project Learning: Another major usage of our dataset
is to answer How effectively learning could take place from the
data present in the source project, for an effective utilization of
it in the target projects. Studies done in this area have been
observed to be scarce, and the data available in BuGL in the
form of pull requests and bug reports can be utilized for
cross-project learning. It is interesting to tackle some ques-
tions such as Possibility of cross-project learning of projects
written in different programming languages in terms of contin-
uous integration, defect prediction, software implementation,
and so on.

• Open source development: The software development
community has embraced open-source philosophy, and it
always serves the researcher to understand many aspects of
Software building process. An exploration of bug reports and
pull-requests triaging process, program comprehension, bug
report quality analysis, software architecture in the context
of bugs, and so on, could be performed using BuGL.

The scope of existing bug localization techniques is limited, as
they worked and compared against a similar kind of projects men-
tioned in Section 1. Hence, these methods might face an overfitting
problem. The projects used in the approaches are well maintained
and documented projects. However, many open-source projects
are lack these features. Tackling these problems is essential, and
the BuGL dataset is one of the first steps to deal with the problems
mentioned above.

4 DISCUSSION
Below, we list out a few scopes of improvement in the dataset along
with key limitations of BuGL:

4

• BuGL represents only a fraction of repositories from GitHub.
However, in future, we plan to extend the dataset with more
curated projects.

• Insufficient description of bug reports and pull requests
makes it hard to categorize bug issues from other issues.
Issues raised in the repository are sometimes are not bugs;
these issues mostly deal with the documentation files or mi-
nor changes in the file name. To mitigate this, we mapped
issues with the pull requests which resolved respective issues.
Changes made in files by a pull request gives us information
on whether the issues reported are related to the bug or not.
• The projects selected from GitHub are based on number
of stars. We applied, Borges and Valente [1] recommenda-
tion while curating projects based on GitHub stars because
popularity of some repositories might be due to their active
promotion in the social media.

• The issues present in projects are sometimes insufficient,
and to train or test a model for bug-localization we need
more issues. With this in mind, we included open issues in
the dataset. It would help to enhance the model and might
be useful for future upgradation of the dataset.

• To extend this dataset, we plan to include repositories from
various domains and programming languages. The aim is to
include a diverse range of bugs that can help to formulate
new sets of bug localization techniques.

• More emphasis will be given towards adding new features
in the dataset for more in-depth analysis of bug reports.
• We are also planning to create an automatic tool that could

deal with duplicate bug reports and pull requests.

5 CONCLUSION
In this paper, we described BuGL, a cross-language dataset con-
sisting of bug reports and pull request information. BuGL consists
of more than 10k bug reports gathered from projects written in 4
different programming languages- C, C++, Java, and Python. We
discussed the methodology used for constructing BuGL along with
its representation. We also talk about the research opportunities
related to this dataset. We hope BuGL creates a strong impact pro-
viding new directions and insights in Bug Localization.

ACKNOLWEDGEMENTS
Even though cross project bug localization is a home-grown project,
we would like to thank ARiSE Group, Robert Bosch Engineering
and Business Solutions Ltd., Bangalore, India for funding some of
our other work in bug localization.

Repositories. 34–37.

[14] Antoine Pietri, Diomidis Spinellis, and Stefano Zacchiroli. 2019. The software
heritage graph dataset: public software development under one roof. In 2019
IEEE/ACM 16th International Conference on Mining Software Repositories (MSR).
IEEE, 138–142.

[15] Sravya Polisetty, Andriy Miranskyy, and Ayşe Başar. 2019. On Usefulness of the
Deep-Learning-Based Bug Localization Models to Practitioners. In Proceedings of
the Fifteenth International Conference on Predictive Models and Data Analytics in
Software Engineering. 16–25.

[16] Michael Rath and Patrick Mäder. 2019. Structured information in bug report
descriptionsâĂŤinfluence on IR-based bug localization and developers. Software
Quality Journal 27, 3 (2019), 1315–1337.

[17] Michael Rath, Patrick Rempel, and Patrick Mäder. 2017. The IlmSeven Dataset.
In 2017 IEEE 25th International Requirements Engineering Conference (RE). IEEE,
516–519.

[18] Ripon K Saha, Matthew Lease, Sarfraz Khurshid, and Dewayne E Perry. 2013.
Improving bug localization using structured information retrieval. In 2013 28th
IEEE/ACM International Conference on Automated Software Engineering (ASE).
IEEE, 345–355.

[19] Shaowei Wang and David Lo. 2014. Version history, similar report, and structure:
Putting them together for improved bug localization. In Proceedings of the 22nd
International Conference on Program Comprehension. 53–63.

[20] Chu-Pan Wong, Yingfei Xiong, Hongyu Zhang, Dan Hao, Lu Zhang, and Hong
Mei. 2014. Boosting bug-report-oriented fault localization with segmentation
and stack-trace analysis. In 2014 IEEE International Conference on Software Main-
tenance and Evolution. IEEE, 181–190.

[21] W Eric Wong, Ruizhi Gao, Yihao Li, Rui Abreu, and Franz Wotawa. 2016. A
survey on software fault localization. IEEE Transactions on Software Engineering
42, 8 (2016), 707–740.

[22] Yan Xiao, Jacky Keung, Qing Mi, and Kwabena E Bennin. 2017.

Improving
bug localization with an enhanced convolutional neural network. In 2017 24th
Asia-Pacific Software Engineering Conference (APSEC). IEEE, 338–347.

[23] Klaus Changsun Youm, June Ahn, Jeongho Kim, and Eunseok Lee. 2015. Bug
localization based on code change histories and bug reports. In 2015 Asia-Pacific
Software Engineering Conference (APSEC). IEEE, 190–197.

[24] Yue Yu, Zhixing Li, Gang Yin, Tao Wang, and Huaimin Wang. 2018. A dataset of
duplicate pull-requests in github. In Proceedings of the 15th International Confer-
ence on Mining Software Repositories. 22–25.

[25] Jian Zhou, Hongyu Zhang, and David Lo. 2012. Where should the bugs be fixed?
more accurate information retrieval-based bug localization based on bug reports.
In 2012 34th International Conference on Software Engineering (ICSE). IEEE, 14–24.

REFERENCES
[1] Hudson Borges and Marco Tulio Valente. 2018. WhatâĂŹs in a GitHub star?
understanding repository starring practices in a social coding platform. Journal
of Systems and Software 146 (2018), 112–129.

[2] Oscar Chaparro, Juan Manuel Florez, and Andrian Marcus. 2019. Using bug
descriptions to reformulate queries during text-retrieval-based bug localization.
Empirical Software Engineering 24, 5 (2019), 2947–3007.

[3] Georgios Gousios. 2013. The GHTorent dataset and tool suite. In 2013 10th
Working Conference on Mining Software Repositories (MSR). IEEE, 233–236.
[4] Georgios Gousios and Andy Zaidman. 2014. A dataset for pull-based develop-
ment research. In Proceedings of the 11th Working Conference on Mining Software
Repositories. 368–371.

[5] Xuan Huo, Ferdian Thung, Ming Li, David Lo, and Shu-Ting Shi. 2019. Deep
transfer bug localization. IEEE Transactions on Software Engineering (2019).
[6] Pavneet Singh Kochhar, Yuan Tian, and David Lo. 2014. Potential biases in bug
localization: Do they matter?. In Proceedings of the 29th ACM/IEEE international
conference on Automated software engineering. 803–814.

[7] Anil Koyuncu, Tegawendé F Bissyandé, Dongsun Kim, Kui Liu, Jacques Klein,
Martin Monperrus, and Yves Le Traon. 2019. D&C: A Divide-and-Conquer
Approach to IR-based Bug Localization. arXiv preprint arXiv:1902.02703 (2019).
[8] An Ngoc Lam, Anh Tuan Nguyen, Hoan Anh Nguyen, and Tien N Nguyen. 2017.
Bug localization with combination of deep learning and information retrieval. In
2017 IEEE/ACM 25th International Conference on Program Comprehension (ICPC).
IEEE, 218–229.

[9] Tien-Duy B Le, Ferdian Thung, and David Lo. 2017. Will this localization tool
be effective for this bug? Mitigating the impact of unreliability of information
retrieval based bug localization tools. Empirical Software Engineering 22, 4 (2017),
2237–2279.

[10] Jaekwon Lee, Dongsun Kim, Tegawendé F Bissyandé, Woosung Jung, and Yves
Le Traon. 2018. Bench4bl: reproducibility study on the performance of ir-based
bug localization. In Proceedings of the 27th ACM SIGSOFT International Symposium
on Software Testing and Analysis. 61–72.

[11] Hongliang Liang, Lu Sun, Meilin Wang, and Yuxing Yang. 2019. Deep Learning
With Customized Abstract Syntax Tree for Bug Localization. IEEE Access 7 (2019),
116309–116320.

[12] Stacy K Lukins, Nicholas A Kraft, and Letha H Etzkorn. 2010. Bug localization
using latent dirichlet allocation. Information and Software Technology 52, 9 (2010),
972–990.

[13] Vadim Markovtsev and Waren Long. 2018. Public Git archive: A big code dataset
for all. In Proceedings of the 15th International Conference on Mining Software

5

