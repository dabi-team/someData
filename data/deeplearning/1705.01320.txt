Formal Veriﬁcation of Piece-Wise Linear
Feed-Forward Neural Networks

R ¨udiger Ehlers
University of Bremen and DFKI GmbH, Bremen, Germany

7
1
0
2

g
u
A
2

]

O
L
.
s
c
[

3
v
0
2
3
1
0
.
5
0
7
1
:
v
i
X
r
a

We present an approach for the veriﬁcation of feed-forward neural networks in which
all nodes have a piece-wise linear activation function. Such networks are often used in
deep learning and have been shown to be hard to verify for modern satisﬁability modulo
theory (SMT) and integer linear programming (ILP) solvers.

The starting point of our approach is the addition of a global linear approximation of the
overall network behavior to the veriﬁcation problem that helps with SMT-like reasoning
over the network behavior. We present a specialized veriﬁcation algorithm that employs
this approximation in a search process in which it infers additional node phases for the
non-linear nodes in the network from partial node phase assignments, similar to unit
propagation in classical SAT solving. We also show how to infer additional conﬂict
clauses and safe node ﬁxtures from the results of the analysis steps performed during
the search. The resulting approach is evaluated on collision avoidance and handwritten
digit recognition case studies.

1 Introduction

Many tasks in computing are prohibitively diﬃcult to formalize and thus hard to get right. A
classical example is the recognition of digits from images. Formalizing what exactly distinguishes
the digit 2 from a 7 is in a way that captures all common handwriting styles is so diﬃcult that this
task is normally left to the computer. A classical approach for doing so is to learn a feed-forward neural
network from pre-classiﬁed example images. Since the advent of deep learning (see, e.g., [Sch15]), the
artiﬁcial intelligence research community has learned a lot about engineering these networks, such
that they nowadays achieve a very good classiﬁcation precision and outperform human classiﬁers
+
on some tasks, such as sketch recognition [YYS
15]. Even safety-critical applications such as obstacle
detection in self-driving cars nowadays employ neural networks.

But if we do not have formal speciﬁcations, how can we assure the safety of such a system? The
classical approach to tackle this problem is to construct safety cases [WK15]. In such a safety case,
we characterize a set of environment conditions under which a certain output is desired and then
test if the learned problem model ensures this output under all considered environment conditions.
In a self-driving car scenario, we can deﬁne an abstract obstacle appearance model all of whose
concretizations should be detected as obstacles. Likewise, in a character recognition application, we
can deﬁne that all images that are close to a given example image (by some given metric) should be
detected as the correct digit. The veriﬁcation of safety cases somewhat deviates from the classical
aim of formal methods to verify correct system behavior in all cases, but the latter is unrealistic due
to the absence of a complete formal speciﬁcation. Yet, having the means to test neural networks

1

 
 
 
 
 
 
on safety cases would help with certiﬁcation and also provides valuable feedback to the system
engineer.

Verifying formal properties of feed-forward neural networks is a challenging task. Pulina and
Tacchella [PT10] present an approach for neurons with non-linear activation functions that only
scales to small networks. In their work, they use networks with 6 nodes, which are far too few for
most practical applications. They combine counterexample-triggered abstraction-reﬁnement with
satisﬁability modulo theory (SMT) solving. Scheibler et al. [SWWB15] consider the bounded model
checking problem for an inverse pendulum control scenario with non-linear system dynamics and a
non-linear neuron activation function, and despite employing the state-of-the-art SMT solver iSAT3
+
[SNM
16] and even extending this solver to deal better with the resulting problem instances, their
experiments show that the resulting veriﬁcation problem is already challenging for neural networks
with 26 nodes.

In deep learning [Sch15], many works use networks whose nodes have piece-wise linear activation
functions. This choice has the advantage that they are more amenable to formal veriﬁcation, for
example using SMT solvers with the theory of linear real arithmetic, without the need to perform
abstract interpretation. In such an approach, the solver chooses the phases of (some of) the nodes,
and then applies a linear-programming-like sub-solver to check if there exist concrete real-valued
inputs to the network such that all nodes have the selected phases. The node phases represent
which part of the piece-wise linear activation functions are used for each node. It has been observed
that the SMT instances stemming from such an encoding are very diﬃcult to solve for modern SMT
solvers, as they need to iterate through many such phase combinations before a problem instance is
+
found to be satisﬁable or unsatisﬁable [KBD
17, PT12]. Due to the practical importance of verifying
piecewise-linear feed-forward neural networks, this observation asks for a specialized approach for
doing so.

Huang et al. [HKWW17] describe such an approach that is based on propagating constraints
through the layers of a network. The constraints encode regions of the input space of each layer all of
whose points lead to the same overall classiﬁcation in the network. Their approach is partially based
on discretization and focusses on robustness testing, i.e., determining the extent to which the input
can be altered without changing the classiﬁcation result. They do not support general veriﬁcation
+
properties. Bastiani et al. [BIL
16] also target robustness testing and deﬁne an abstraction-reﬁnement
constraint solving loop to test a network’s robustness against adversarial pertubations. They also
employ the counter-examples that their approach ﬁnds to learning more robust networks. Katz et
17] provide an alternative approach that allows to check the input/output behavior of a
al. [KBD
neural network with linear and so-called ReLU nodes against convex speciﬁcations. Many modern
network architectures employ these nodes. They present a modiﬁcation of the simplex algorithm for
solving linear programs that can also deal with the constraints imposed by ReLU nodes, and they
show that their approach scales orders of magnitudes better than when applying the SMT solvers
MathSAT or Yices on SMT instances generated from the veriﬁcation problems.

+

Modern neural network architectures, especially those for image recognition, however often
employ another type of neural network node that the approach by Katz et al. does not support:
MaxPool nodes. They are used to determine the strongest signal from their input neurons, and
they are crucial for feature detection in complex machine learning tasks.
In order to support the
veriﬁcation of safety cases for machine learning applications that make use of this node type, it is
thus important to have veriﬁcation approaches that can eﬃciently operate on networks that have
such nodes, without the need to simulate MaxPool nodes by encoding their behavior into a much
larger number of ReLU nodes.

In this paper, we present an approach to verify neural networks with piece-wise linear activation
functions against convex speciﬁcations. The approach supports all node types used in modern
network network architectures that only employ piece-wise linear activation functions (such as
MaxPool and ReLU nodes). The approach is based on combining satisﬁability (SAT) solving and

2

linear programming and employs a novel linear approximation of the overall network behavior.
This approximation allows the approach to quickly rule out large search space parts for the node
phases from being considered during the veriﬁcation process. While the approximation can also
be used as additional constraints in SMT solving and improves the computation times of the SMT
solver, we apply it in a customized solver that uses the elastic ﬁltering algorithm from [CD91] for
minimal infeasible linear constraint set ﬁnding in case of conﬂicts, and combine it with a specialized
procedure for inferring implied node phases. Together, these components lead to much shorter
veriﬁcation times. We apply the approach on two cases studies, namely collision avoidance and
character recognition, and report on experimental results. We also provide the resulting solver
and the complete tool-chain to generate veriﬁable models using the Deep Learning framework
+
Caffe [JSD

14] as open-source software.

2 Preliminaries

Feed-Forward Neural Networks: We consider multi-layer (Perceptron) networks with linear, ReLU,
and MaxPool nodes in this paper. Such networks are formally deﬁned as directed acyclic weighted
graphs G = (V, E, W, B, T), where V is a set of nodes, E ⊂ V × V is a set of edges, W : E → R assigns a
weight to each edge of the network, B : V → R assigns a node bias to each node, and T assigns a type
to each node in the network from a set of available types T ∈ {input, linear, ReLU, MaxPool}. Nodes
without incoming edges are called input nodes, and we assume that T(v) = input for every such node
v. Vertices that have no outgoing edge are also called output nodes.

A feed-forward neural network with n input nodes and m output nodes represents a function
f : Rn → Rm. Given assignments in : {1, . . . , n} → V and out : {1, . . . , m} → V that deﬁne the orders
of the input and output nodes (so that we can feed elements from Rn to the network to obtain an
output from Rm), and some input vector (x1
, . . . , xn) ∈ Rn, we can deﬁne the network’s behavior by
a node value assignment function a : V → R that is deﬁned as follows:
−1(v),
v(cid:48)∈V,(v(cid:48),v)∈E W((v(cid:48), v)) · a(v(cid:48)

• For every node v with T(v) = input, we set a(v) = x j for j = in
• For every node v with T(v) = linear, we set a(v) = (cid:80)
• For every node v with T(v) = ReLU, we set a(v) = max(B(v) + (cid:80)
• For every node v with T(v) = MaxPool, we set a(v) = maxv(cid:48)∈V,(v(cid:48),v)∈E a(v(cid:48)

v(cid:48)∈V,(v(cid:48),v)∈E W((v(cid:48), v)) · a(v(cid:48)

) + B(v).

), 0).

).

, . . . , xn) is deﬁned to be (a(out(1)), . . . , a(out(m))). Note that the weights
Function f ’s output for (x1
of the edges leading to MaxPool nodes and their bias values are not used in the deﬁnition above.
Given a node value assignment function a : V → R, we also simply call a(v) the value of v. If for a
ReLU node v, we have s(v) < 0 for s(v) = B(v) + (cid:80)
), and hence a(v) = 0, we
say that node n is in the ≤ 0 phase, and for s(v) ≥ 0, and hence a(v) ≥ 0, we say that it is in the ≥ 0
phase. If we have s(v) = 0, then it can be in either phase. For a MaxPool node v, we deﬁne it to be in
phase e ∈ E ∩ (V × {v}) if a(v) = a(v(cid:48)
) for e = (v(cid:48), v). If multiple nodes with edges to v have the same
values, then node v can have any of the respective phases.

v(cid:48)∈V,(v(cid:48),v)∈E W((v, v(cid:48)

)) · a(v(cid:48)

Modern neural network architectures are layered, i.e., we have that every path from an input node
to an output node has the same length. For the veriﬁcation techniques given in this paper, it does
however not matter whether the network is layered. Networks can also be used to classify inputs.
In such a case, the network represents a function f (cid:48)
: Rn → {1, . . . , m} (for some numbering of the
classes), and we deﬁne f (cid:48)
(x1

, . . . , xn) = arg maxi∈{1,...,m} yi for (y1

, . . . , ym) = f (x1

, . . . , xn).

We do not discuss here how neural networks are learned, but assume networks to be given with
all their edge weights and node bias values. Frameworks such as Caffe [JSD
14] provide ready-
to-use functionality for learning edge weights and bias values from databases of examples, i.e.,

+

3

, . . . , xn, y1

, . . . , ym) such that we want the network to induce a function f with (x1

, . . . , ym). Likewise, for classiﬁcation problems, the databases consist of tuples (x1

, . . . , xn) =
tuples (x1
, . . . , xn, c) such
(y1
that we want the network to induce a function f (cid:48)
, . . . , xn) = c. When using a neural
network learning tool, the architecture of the network, i.e., everything except for the weights and
the node bias values, is deﬁned up-front, and the framework automatically derives suitable edge
weights and node bias values. There are other node types (such as Softmax nodes) that are often used
during the learning process, but removed before the deployment of the trained network, and hence
do not need to be considered in this work. Also, there are network layer types such as convolutional
layers that have special structures. From a veriﬁcation point of view, these are however just sets of
linear nodes whose edges share some weights, and thus do not have to be treated diﬀerently.

with f (cid:48)

(x1

Satisﬁability Solvers: Satisﬁability (SAT) solvers check if a Boolean formula has a satisfying
assignment. The formula is normally required to be in conjunctive normal form, and thus consists
of clauses that are connected by conjunction. Every clause is a disjuction of one of more literals, which
are Boolean variables or their negation. A SAT solver operates by successively building a valuation
of the Boolean variables and backtracking whenever a conﬂict of the current partial valuation and
a clause has been found. To achieve a better performance, SAT solvers furthermore perform unit
propagation, where the partial assignment is extended by literals that are the only remaining ones
not yet violated by the partial valuation in some clause. Additionally, modern solvers perform
clause learning, where clauses that are implied by the conjunction of some other clauses are lazily
inferred during the search process, and select variables to branch on using a branching heuristic. Most
modern solvers also perform random restarts. For more details on SAT solving, the interested reader
is referred to [FM09].

Linear Programming: Given a set of linear inequalities over real-valued variables and a linear
optimization function (which together are called a linear program), the linear programming problem
is to ﬁnd an assignment to the variables that minimizes the objective function and fulﬁlls all con-
straints. Even though linear programming was shown to have polynomial-time complexity, it has
been observed that in practice [KS08], it is often faster to apply the Simplex algorithm, which is an
exponential-time algorithm.

Satisﬁability Modulo Theory Solving: SAT solvers only support Boolean variables. For problems
that can be naturally represented as a Boolean combination of constraints over other variable types,
Satisﬁability Modulo Theory (SMT) solvers are normally applied instead. An SMT solver combines
a SAT solver with specialized decision procedures for other theories (such as, e.g., the theory of
linear arithmetic over real numbers).

3 Efﬁcient Veriﬁcation of Feed-forward Neural Networks

In this paper, we deal with the following veriﬁcation problem:

: Rn → Rm, and a
Deﬁnition 1 Given a feed-forward neural network G that implements a function f
set of linear constraints ψ over the real-valued variables V = {x1
, . . . , ym}, the neural net (NN)
veriﬁcation problem is to ﬁnd a node value assignment function a for V that fulﬁls ψ over the input and
, . . . , ym), or to conclude that no such node value
, . . . , xn) = (y1
output nodes of G and for which we have f (x1
assignment function exists.

, . . . , xn, y1

The restriction to conjunctions of linear properties in Deﬁnition 1 was done for simplicity. Verifying
arbitrary Boolean combinations of linear properties can be ﬁtted into Deﬁnition 1 by encoding them

4

d

l

c

u

Figure 1: The activation function of a ReLU node, with a linear over-approximation drawn as ﬁlled

area.

into the structure of the network itself, so that an additional output neuron yadd outputs a value ≥ 0
if and only if the property is fulﬁlled. In this case, ψ is then simply yadd

≥ 0.

There are multiple ways to solve the neural network (NN) veriﬁcation problem. The encoding
of an NN veriﬁcation problem to an SMT problem instance is straight-forward, but yields instances
that are diﬃcult to solve even for modern SMT solvers (as the experiments reported on in Section 4
show). As an alternative, we present a new approach that combines 1) linear approximation of the
overall NN behavior, 2) irreducible infeasible subset analysis for linear constraints based on elastic
ﬁltering [CD91], 3) inferring possible safe node phase choices from feasibility checking of partial
node phase valuations, and 4) performing unit-propagation-like reasoning on node phases. We
describe these ideas in this section, and present experimental results on a tool implementing them
in the next section.

Starting point is the combination of a linear programming solver and a satisﬁability solver. We let
the satisﬁability solver guide the search process. It determines the phases of the nodes and maintains
a set of constraints over node phase combinations. On a technical level, we allocate the SAT variables
x(v,≤0) and x(v,≥0) for every ReLU node v, and also reserve variables x(v,e) for every MaxPool node v and
every edge e ending in v. The SAT solver performs unit propagation, clause learning, branching, and
backtracking as usual, but whenever the solver is about to branch, we employ a linear programming
solver to check a linear approximation of the network behavior (under the node phases already
ﬁxed) for feasibility. Whenever a conﬂict is detected, the SAT solver can then learn a conﬂict clause.
Additionally, we infer implied node phases in the search process.

We describe the components of our approach in this section, and show how they are combined at

the end of it.

3.1 Linear Approximation of Neural Network Value Assignment Functions

Let G = (V, E, W, B, T) be a network representing a function f
: Rn → Rm. We want to build a
system of linear constraints using V as the set of variables that closely approximates f , i.e., such that
every node value assignment function a is a correct solution to the linear constraint system, and the
constraints are as tight as possible. The main diﬃculty in building such a constraint system is that
the ReLU and MaxPool nodes do not have linear input-output behavior (until their phases are ﬁxed),
so we have to approximate them linearly.

Figure 1 shows the activation function of a ReLU node, where we denote the weighted sum of the
input signals to the node (and its bias) as variable c. The output of the node is denoted using the
variable d. If we have upper and lower bounds [l, u] of c, then we can approximate the relationship
between c and d by the constraints d ≥ 0, d ≥ c, and d ≤ u·(c−l)
, all of which are linear equations for
u−l
constant u and l. This yields the set of allowed value combinations for c and d drawn as the ﬁlled
area in Figure 1.

Obviously, this approach requires that we know upper and lower bounds on c. However, even
though neural networks are deﬁned as functions from Rn, bounds on the input values are typically

5

known. For example, in image processing networks, we know that the input neurons receive values
from the range [0, 1]. In other networks, it is common to normalize the input values before learning
the network, i.e., to scale them to the same interval or to [−1, 1]. This allows us to use classical interval
arithmetic on the network to obtain basic lower and upper bounds [l, u] on every node’s values.

For the case of MaxPool nodes, we can approximate the behavior of the nodes linearly similarly to
, . . . , ck be the
, . . . , kk be their lower bounds, and d be

the ReLU case, except that we do not need upper bounds for the nodes’ values. Let c1
values of nodes with edges leading to the MaxPool node, l1
the output value of the node. We instantiate the following linear constraints:

(cid:94)

(d ≥ ci) ∧ (c1

+ . . . + ck

≥ d +

i∈{1,...,k}

(cid:88)

i∈{1,...,k}

li − max
i∈{1,...,k}

li)

Note that these are the tightest linear constraints that can be given for the relationship between the
values of the predecessor nodes of a MaxPool node and the node value of the MaxPool node itself.

After a linear program that approximates the behavior of the overall network has been built, we
can use it to make all future approximations even tighter. To achieve this, we add the problem
speciﬁcation ψ as constraints and solve, for every variable v ∈ V, the resulting linear program while
minimizing ﬁrst for the objective functions 1 · v, and then doing the same for the objective function
−1 · v. This yields new tighter lower and upper bounds [l, u] for each node (if the network has any
ReLU nodes), which can be used to obtain a tighter linear program. Including the speciﬁcation in
the process allows us to derive tighter bounds than we would have found without the speciﬁcation.
The whole process can be repeated several times: whenever new upper and lower bounds have been
obtained, they can be used to build a tighter linear network approximation, which in turn allows to
obtain new tighter upper and lower bounds.

3.2 Search process and Infeasible Subset Finding

Given a phase ﬁxture for all ReLU and MaxPool nodes in a network, checking if there exists a node
value assignment function with these phases (and such that the veriﬁcation constraint ψ is fulﬁlled)
can be reduced to a linear programming problem. For this, we extend the linear program built with
the approach from the previous subsection (with V as the variable set for the node values) by the
following constraints:

• For every ≤ 0 phase selected for a ReLU node v, we add the constraints v = 0 and

v)) · v(cid:48) + B(v) ≤ 0.

(cid:80)

(v(cid:48),v)∈E W((v(cid:48),

• For every ≥ 0 phase selected for a ReLU node v, we add the constraint v ≥ (cid:80)

v(cid:48) + B(v).

(v(cid:48),v)∈E W((v(cid:48), v)) ·

• For every phase (v(cid:48), v) selected for a MaxPool node v, we add the constraint v = v(cid:48)

.

If we only have a partial node phase selection, we add these constraints only for the ﬁxed nodes. If
the resulting linear program is infeasible, then we can discard all extensions to the partial valuation
from consideration in the search process. This is done by adding a conﬂict clause that rules out the
Boolean encoding of this partial node phase selection, so that even after restarts of the solver, the
reason for infeasibility is retained.

However, the reasons for conﬂicts often involve relatively few nodes, so shorter conﬂict clauses
can also be learned instead (which makes the search process more eﬃcient). To achieve this, we
employ elastic ﬁltering [CD91].
In this approach, all of the constraints added due to node phase
selection are weakened by slack variables, where there is one slack variable for each node. So, for
(v(cid:48),v)∈E W((v(cid:48), v)) · v(cid:48) + B(v) − sv ≤ 0.
example a constraint
When running the linear programming solver again with the task of minimizing a weighted sum

(v(cid:48),v)∈E W((v(cid:48), v)) · v(cid:48) + B(v) ≤ 0 becomes

(cid:80)

(cid:80)

6

of the slack variables, we get a ranking of the nodes by how much they contributed to the conﬂict,
where some of them did not contribute at all (since their slack variable had a 0 value). We then ﬁx
the slack variable with the highest value to be 0, hence making the corresponding constraints strict,
and repeat the search process until the resulting LP instance becomes infeasible. We then know that
the node phase ﬁxtures that were made strict during this process are together already infeasible,
and build conﬂict clauses that only contain them. We observed that these conﬂict clauses are much
shorter than without applying elastic ﬁltering.

Satisﬁability modulo theory solvers typically employ cheaper procedures to compute minimal
infeasible subsets of linear constraints, such as the one by Duterte and de Moura [DdM06], but the
high number of constraints in the linear approximation of the network behavior that are independent
of node phase selections seems to make the approach less well-suited, as our experiments with the
SMT solver Yices that uses this approach suggest.

3.3 Implied Node Phase Inference during Partial Phase Fixture Checking

In the partial node ﬁxture feasibility checking step from Section 3.2, we employ a linear programming
solver. However, except for the elastic ﬁltering step, we did not employ an optimization function
yet, as it was not needed for checking the feasibility of a partial node ﬁxture.

For the common case that the partial node ﬁxture is feasible (in the linear approximation), we deﬁne
an optimization function that allows us to infer additional infeasible and feasible partial node ﬁxtures
when checking some other partial node ﬁxture for feasibility. The feasible ﬁxtures are cached so that
if it or a partial ﬁxture of it is later evaluated, no linear programming has to be performed. Given a
partial node ﬁxture to the nodes V(cid:48) ⊂ V, we use −1 · (cid:80)
v∈V\V(cid:48),T(v)=MaxPool v as
optimization function. This choice asks the linear programming solver to minimize the error for the
ReLU nodes, i.e, the diﬀerence between a(v) and max(
) + B(v), 0) for every
assignment a computed in the linear approximation of the network behavior and every ReLU-node
v. While this choice only minimizes an approximation of the error sum of the nodes and thus does
not guarantee that the resulting variable valuation denotes a valid node value assignment function,
it often yields assignments in which a substantial number of nodes v have a tight value, i.e., have
a(v) = max(

v(cid:48)∈V,(v(cid:48),v)∈E W((v(cid:48), v)) · a(v(cid:48)

v∈V\V(cid:48),T(v)=ReLU v − 1
10

v(cid:48)∈V,(v(cid:48),v)∈E W((v(cid:48), v)) · a(v(cid:48)

) + B(v), 0).

(cid:80)

(cid:80)

(cid:80)

If tight is the set of nodes with tight values, p is the partial SAT solver variable valuation that
is the (partial) valuation of the SAT variables
is a partial assignment that
to the partial

encodes the phase ﬁxtures for the nodes V(cid:48)
that encodes the phases of the tight nodes, we can then cache that p ∪ p(cid:48)
is feasible in the linear approximation. So when the SAT solver adds literals from p(cid:48)
valuation, there is no need to let the linear programming solver run again.

, and if p(cid:48)

At the same time, the valuation a (in the linear approximation) can be used to derive an additional
clause for the SAT solver. Let unﬁxed be the ReLU nodes whose values are not ﬁxed by p. If for any
node v ∈ unﬁxed, we have a(v) > 0, then we know by the choice of optimization function and the fact
that we performed the analysis in a linear approximation of the network behavior, that some node
in v needs to be in the ≥ 0 phase (under the partial valuation p). Thus, we can learn the additional
v∈V,T(v)=ReLU,((v,≤0)(cid:55)→true)(cid:60)p(v, ≥ 0) for the SAT solver, provided that the values of
clause
the MaxPool nodes are valid, i.e, for all MaxPool nodes v we have a(v) = a(v(cid:48)
) ∈ E.
This last restriction is why we also included the MaxPool nodes in the optimization function above
(but with lower weight).

) for some (v, v(cid:48)

(cid:17)
¬l

∨ (cid:87)

(cid:16)(cid:87)

l∈p

3.4 Detecting Implied Phases

Whenever the SAT solver has ﬁxed a new node phase, the selected phases together may imply other
node phases. Take for example the net excerpt from Figure 2. There are two ReLU nodes, named r1
and r2, and one MaxPool node. Assume that during the initial analysis of the network (Section 3.1),

7

r1

r2

m

Figure 2: An example neural network part, used in Subsection 3.4.

it has been determined that the value of node r1 is between 0.0 and 1.5, and the value of node r2 is
between 0.1 and 2.0. First of all, the SAT solver can unconditionally detect that node r2 is in the ≥ 0
phase. Then, if at some point, the SAT solver decides that node r1 should be in the ≤ 0 phase, this
ﬁxes the value of r1 to 0. Since the ﬂow out of r2 has a lower bound > 0, we can then deduce that
m’s phase should be set to (r2, m).

Similar reasoning can also be performed for ﬂow leading into a node.

If we assume that the
analysis of the initial linear approximation of the network’s node functions yields that the outgoing
ﬂow of m needs to be between 0.5 and 0.7, and the phase of r1 is chosen to be ≤ 0, then this implies
that the phase of r2 must be ≥ 0, as otherwise m would be unable to supply a ﬂow of > 0.

Both cases can be detected without analyzing the linear approximation of the network. Rather,
we can just propagate the lower and upper bounds on the nodes’ outgoing ﬂows through the
network and detect implied phases. Doing so takes time linear in the size of the network, which is
considerably faster than making an LP solver call. This allows the detection of implied phases to
be applied in a way similar to classical unit propagation in SAT solving: whenever a decision has
been made by the solver, we run implied phase detection to extend the partial valuation of the SAT
solver by implied choices (which allows to make the linear approximation tighter for the following
partial node ﬁxture feasibility checks).

3.5 Overview of the Integrated Solver

To conclude this section, let us discuss how the techniques presented in it are combined. Algorithm 1
shows the overall approach.
In the ﬁrst step, upper and lower bounds for all nodes’ values are
computed. The solver then prepares an empty partial valuation to the SAT variables and an empty
list extra in which additional clauses generated by the LP instance analysis steps proposed in this
section are stored. The SAT instance is initialized with clauses that enforce that every ReLU node
and every MaxPool node has exactly one phase selected (using a one-hot encoding).

In the main loop of the algorithm, the ﬁrst step is to perform most steps of SAT solving, such as
unit propagation, conﬂict detection & analysis, and others. We assume that the partial valuation
is always labelled by decision levels so that backtracking can also be performed whenever needed.
Furthermore, additional clauses from extra are mixed to the SAT instance ψ. This is done on a step-
by-step basis, as the additional clauses may trigger unit propagation and even conﬂicts, which need
to be dealt with eagerly. After all clauses from extra have been mixed into ψ, and possibly the partial
valuation p has been extended by implied literals, in line 12, the approach presented in Sect. 3.4 is
applied. If it returns new implied literals (in the form of additional clauses), they are taken care of
by the SAT solving steps in line 11 next. This is because the clauses already in ψ may lead to unit
propagation on the newly inferred literals, which makes sense to check as every additional literal
makes the linear approximation of the network behavior tighter (and can lead to additional implied
literals being detected). Only when all node phases have been inferred, p is checked for feasibility
in the linear approximation (line 14).

There are two diﬀerent outcomes of this check: if the LP instance is infeasible, a new conﬂict clause
is generated, and hence the condition in line 15 is not satisﬁed. The algorithm then continues in line 11
in this case. Otherwise, the branching step of the SAT solver is executed. If p is already a complete

8

Algorithm 1 Top-level view onto the neural network veriﬁcation algorithm.
1: function VerifyNN(V, E, T, B, W)
2:

max) ← ComputeInitialBounds(V, E, T, B, W)
−−→
min, −−→
max) ← ReﬁneBounds(V, E, T, B, W,
max)

−−→
min, −−→
(
−−→
min, −−→
(
p ← ∅, extra ← ∅
ψ ← (cid:86)
ψ ← ψ ∧ (cid:86)
ψ ← ψ ∧ (cid:86)
while ψ has a satisfying assignment do
while extra is non-empty do

v(cid:48)∈V,(v(cid:48),v)∈E xv,(v(cid:48),v)

v∈V,T(v)=MaxPool

v∈V,T(v)=MaxPool,v(cid:48),v(cid:48)(cid:48)∈V,v(cid:48)(cid:44)v(cid:48)(cid:48),(v(cid:48),v)∈E,(v(cid:48)(cid:48),v)∈E(¬xv,(v(cid:48),v)
v∈V,T(v)=ReLU(xv,≤0 ∨ xv,≥0) ∧ (¬xv,≤0 ∨ ¬xv,≥0)

(cid:87)

∨ ¬xv,(v(cid:48)(cid:48),v))

(cid:46) Section 3.1
(cid:46) Section 3.1

Perform unit propagation, conﬂict detection, backtracking, and clause
learning for p on ψ, while moving the clauses from extra to ψ one-by-one.
−−→
min, −−→
max)

(cid:46) Section 3.4

extra ← InferNodePhases(V, E, T, B, W, p,
if extra = ∅ then

−−→
min, −−→
max)

(cid:46) Section 3.2-3.3

extra ← CheckForFeasibility(V, E, T, B, W, p,
if p |= c for all clauses c ∈ extra then

if p is a complete assignment to all variables then

return Satisﬁable

Add a new variable assignment b (cid:55)→ true to p for some variable b in ψ.
if p cannot be extended to a satisfying valuation to ψ then

p = p \ {b (cid:55)→ true} ∪ {b (cid:55)→ false}

return Unsatisﬁable

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

valuation, we know at this point that the instance is satisﬁable, as then the CheckForFeasibility
function just executed operated on an LP problem that is not approximate, but rather captures the
precise behavior of the network. Otherwise, p is extended by a decision to set a variable b to true (for
some variable chosen by the SAT solver’s variable selection heuristics). Whenever this happens, we
employ a plain SAT solver for checking if the partial valuation can be extended to one that satisﬁes
ψ. This not being the case may not be detected by unit propagation in line 11 and hence it makes
sense to do an eager SAT check. In case of conﬂict, the choice of b’s value is inverted, and in any
case, the algorithm continues with the search.

4 Experiments

We implemented the approach presented in the preceding section in a tool called Planet.
It is
written in C++ and bases on the linear programming toolkit GLPK 4.611 and the SAT solver Minisat
2.2.0 [ES03]. While we use GLPK as it is, we modiﬁed the main search procedure of Minisat to
implement Algorithm 1. We repeat the initial approximation tightening process from Section 3.1
−−→
max fall below 1.0. We also abort the process if 5000 node
until the cumulative changes in
approximation updates have been performed (to not spend too much time in the process for very
large nets), provided that for every node, its bounds have been updated at least three times.

−−→
min and

All numerical computations are performed with double precision, and we did not use any com-
pensation for numerical imprecision in the code apart from using a ﬁxed safety margin (cid:15) = 0.0001
for detecting node assignment values a(v) to be greater or smaller than other node assignment values
a(v(cid:48)
), whenever such a comparison
is made in the veriﬁcation algorithm steps described in Sect. 3.2 and Sect. 3.3. Since the neural

), i.e., we actually check if a(v) ≤ a(v(cid:48)

) − (cid:15) to conclude a(v) ≤ a(v(cid:48)

1GNU Linear Programming Kit, http://www.gnu.org/software/glpk/glpk.html

9

+
networks learned using the Caffe [JSD
14] deep learning framework (which we employ for our
experiments in this paper) tend not to degenerate in the node weights, this is suﬃcient for the
experimental evaluation in this paper. Also, we did not observe any diﬀerences in the veriﬁcation
results between the SMT solver Yices [Dut14] on the SMT instances that we computed from the
veriﬁcation problems and the results computed by our tool. The tool is available under the GPLv3
license and can be obtained from https://github.com/progirep/planet along with all scripts &
conﬁguration ﬁles needed to learn the neural networks used in our experiments with the Caffe
framework and to translate them to input ﬁles for our tool.

All computation times given in the following were obtained on a computer with an Intel Core
i5-4200U 1.60 GHz CPU and 8 GB of RAM running an x64 version of GNU/Linux. We do not report
memory usage, as it was always < 1 GB. All tools run with a single computation thread.

4.1 Collision Avoidance

As a ﬁrst example, we consider the problem of predicting collisions between two vehicles that follow
curved paths at diﬀerent speeds. We learned a neural network that processes tuples (x, y, s, d, c1
, c2)
and classiﬁes them into whether they represent a colliding or non-colliding case. In such a tuple,

• the x and y components represent the relative distances of the vehicles in their workspace in

the X- and Y-dimensions,

• the speed of the second vehicle is s,

• the starting direction of the second vehicle is d, and

• the rotation speed values of the two vehicles are c1 and c2.

The data is given in normalized (scaled) form to the neural network learner, so that all tuple
components are between 0 and 1 (or between −1 and 1 for c1 and c2). We wrote a tool that generates
a few random tuples (within some intervals of possible values) along with whether they represent
a colliding or non-colliding case, as determined by simulation. The vehicles are circle-shaped, and
we deﬁned a safety margin and only consider tuples for which either the safety margins around
the vehicles never overlap, or the vehicles themselves collide. So when only the safety margins
overlap, this represents a “don’t care” case for the learner. The tool also visualizes the cases, and
we show two example traces in Figure 3. The tool ensures that the number of colliding cases and
non-colliding ones are the same in the case list given to the neural network learner (by discarding
tuples whenever needed). We generated 3000 tuples in total as input for Planet.

We deﬁned a neural network architecture that consists of 40 linear nodes in the ﬁrst layer, followed
by a layer of MapPool nodes, each having 4 input edges, followed by a layer of 19 ReLU nodes,
and 2 ReLU nodes for the output layer. Since Caffe employs randomization to initialize the node
weights, the accuracy of the computed network is not constant. In 86 out of 100 tries, we were able
to learn a network with an accuracy of 100%, i.e., that classiﬁes all example tuples correctly.

We want to ﬁnd out the safety margin around the tuples, i.e., the highest value of (cid:15) > 0 such that
for every tuple (x, y, s, d, c1
, c2) that is classiﬁed to b ∈ {colliding, notColliding}, we have that all other
± (cid:15), c2 ± (cid:15)) are classiﬁed to b by the network as well. We perform this
tuples (x ± (cid:15), y ± (cid:15), s ± (cid:15), d ± (cid:15), c1
check for the ﬁrst 100 tuples in the list, use bisection search to test this for (cid:15) ∈ [0, 0.05], and abort the
search process if (cid:15) has been determined with a precision of 0.002.

We obtained 500 NN veriﬁcation problem instances from this safety margin exploration process.
Figure 4 shows the distribution of the computation times of our tool on the problem instances, with a
timeout of 1 hour. For comparison, we show the computation times of the SMT solver Yices 2.5.2
and the (I)LP solver Gurobi 7.02 on the problem instances. The SMT solver z3 was observed to
perform much worse than Yices on the veriﬁcation problems, and is thus not shown. The choice

10

Figure 3: Two pairs of vehicle trajectories, where the ﬁrst one is non-colliding, and the second one
is colliding. The lower vehicle starts roughly in north direction, whereas the other one
starts roughly in east direction. The ﬁrst trajectory is non-colliding as the two vehicles pass
through the trajectory intersection point at diﬀerent times.

of these comparison solvers was rooted in the fact that they performed best for verifying networks
+
17]. We also give computation times for Gurobi and Yices after
without MaxPool nodes in [KBD
adding additional linear approximation constraints obtained with the approach in Section 3.1. The
computation times include the time to obtain them with our tool.

It can be observed that the computation times of Gurobi and Yices are too long for practical
veriﬁcation, except if the linear approximation constraints from our approach in this paper are
added to the SMT and ILP instances to help the solvers. While Yices is then still slower than our
approach, Gurobi actually becomes a bit faster in most cases, which is not surprising, given that it is a
highly optimized commercial product that employs many sophisticated heuristics under-the-hood,
whereas we use the less optimized GLPK linear programming framework. Planet spends most time
on LP solving. It should be noted that the solver comparison is slightly skewed, as Yices employs
arbitrary precision arithmetic whereas the other tools do not.

4.2 MNIST Digit Recognition

As a second case study, we consider handwritten digit recognition. This is a classical problem
in machine learning, and the MNIST dataset [LC09] is the most commonly used benchmark for
comparing diﬀerent machine learning approaches. The Caffe framework comes with some example
architectures, and we use a simpliﬁed version of Caﬀe’s version of the lenet network [LBBH98] for
our experiments. The Caffe version diﬀers from the original network in that is has piecewise linear
node activation functions.

Figure 5 (a)-(b) shows some example digits from the MNIST dataset. All images are in gray-scale

and have 28 × 28 pixels. Our simpliﬁed network uses the following layers:

• One input layer with 28 × 28 nodes,

• one convolutional network layer with 3 × 13 × 13 nodes, where every node has 16 incoming

edges,

11

Files

500

450

400

350

300

250

200

150

100

50

0.1

1

5

10

100

600 1200

Time

3600

Figure 4: Cactus plot of the solver time comparison for the 500 vehicle collision benchmarks. Time
is given in seconds (on a log-scale), and the lines, from bottom right to top left, repre-
sent Gurobi without linear approximation (dashed), Yices without linear approximation
(solid), Yices with linear approximation (dotted), Planet (solid), and Gurobi with linear
approximation (solid).

• one pooling layer with 3 × 4 × 4 nodes, where each node has 16 incoming edges,

• one ReLU layer with 8 nodes, and

• one ReLU output layer with 10 nodes

The ReLU layers are fully connected. Overall, the network has 1341 nodes, the search space for the
node phases is of size 163·4·4 · 28 · 210 = 2162, and the network has 9344 edges.

We used this architecture to learn a network from the 100000 training images of the dataset, and
the resulting network has an accuracy of 95.05% on a separate testing dataset. Note that an accuracy
of 100% cannot be expected from any machine learning technique, as the dataset also contains digits
that are even hardly identiﬁable for humans (as shown in Figure 5(b)).

We performed a few tests with the resulting network. First we wanted to see an input image that
, . . . , x28,28) for
is classiﬁed strongly as a 2. More formally, we wanted to obtain an input image (x1,1
which the network outputs a vector (y0, . . . , y9) for which y2 ≥ yi + δ for all i ∈ {0, 1, 3, 4, 5, 6, 7, 8, 9}
for a large value of δ. We found that for values of δ = 20 and δ = 30, such images can be found
in 4 minutes 25 seconds and 32 minutes 35 seconds, respectively. The two images are shown in
Figure 5(c) and Figure 5(d). For δ = 50, no such image can be found (4 minutes 41 seconds of
computation time), but for δ = 35, Planet times out after 4 hours. Gurobi (with the added linear
approximation constraints) could not ﬁnd a solution in this time frame, either.

Then, we are interested in how much noise can be added to images before they are not categorized
correctly anymore. We start with the digit given in Figure 5(a), which is correctly categorized by
the learned network as digit 3. We ask whether there is another image that is categorized as a 4,
but for which each pixel has values that are within an absolute range of ±8% of color intensity of
the original image’s pixels, where we keep the pixels the same that are at most three pixels away
from the boundaries. To determine that this is not the case, planet requires 1 minutes 46.8 seconds.
For a range of ±0.12, planet times out after four hours. The output of planet shows that long

12

‘3’ digit

(a)
MNIST dataset

from the

‘2’ digit

(b)
MNIST dataset

from the

Image classiﬁed as

(c)
digit 2 with δ = 20

(d) Image classiﬁed as
digit 2 with δ = 30

Figure 5: Example digit images from Section 4.2

conﬂict clauses are learned in the process, which suggests that we applied it to a diﬃcult veriﬁcation
problem.

We then considered an error model that captures noise that is likely to occur in practice (e.g., due
to stains on scanned paper). It excludes sharp noise edges such as the ones in Figure 5(d). Instead
of restricting the amplitude of noise, we restrict the noise value diﬀerences in adjacent pixels to be
≤ 0.05 (i.e., 5% of color density). This constraint essentially states that the noise must pass through
a linearized low-pass ﬁlter unmodiﬁed. We still exclude the pixels from the image boundaries from
being modiﬁed. Our tool concludes in 9 minutes 2.4 seconds that the network never misclassiﬁes
the image from Figure 5(a) as a 4 under this noise model. Since the model allows many pixels to
have large deviations, we can see that including a linear noise model can improve the computation
time of planet.

5 Conclusion

In this paper, we presented a new approach for the veriﬁcation of feed-forward neural networks with
piece-wise linear activation functions. Our main idea was to generate a linear approximation of the
overall network behavior that can be added to SMT or ILP instances which encode neural network
veriﬁcation problems, and to use the approximation in a specialized approach that features multiple
additional techniques geared towards neural network veriﬁcation, which are grouped around a SAT
solver for choosing the node phases in the network. We considered two case studies from diﬀerent
application domains. The approach allows arbitrary convex veriﬁcation conditions, and we used
them to deﬁne a noise model for testing the robustness of a network for recognizing handwritten
digits.

We made the approach presented in this paper available as open-source software in the hope that
it fosters the co-development of neural network veriﬁcation tools and neural network architectures
that are easier to verify. While our approach is limited to network types in which all components
have piece-wise linear activation functions, they are often the only ones used in modern network
architectures anyway. But even if more advanced activation functions such as exponential linear units
[CUH15] shall be used in learning, they can still be applied to learn an initial model, which is then
linearly approximated with ReLU nodes and ﬁne-tuned by an additional learning process. The ﬁnal
model is then easier to verify. Such a modiﬁcation of the network architecture during the learning
process is not commonly applied in the artiﬁcial intelligence community yet, but while veriﬁcation
becomes more practical, this may change in the future.

Despite the improvement in neural network veriﬁcation performance reported in this paper, there
is still a lot to be done on the veriﬁcation side: we currently do not employ specialized heuristics

13

for node phase branching selection, and while our approach increases the scalablity of neural
network veriﬁcation substantially, we observed it to still be quite fragile and prone to timeouts for
diﬃcult veriﬁcation properties (as we saw in the MNIST example). Also, we had to simplify the
LeNet architecture for digit recognition in our experiments, as the original net is so large that even
obtaining a lower bound for a single variable in the network (which we do for all network nodes
before starting the actual solution process as explained in Section 3.1) takes more than 30 minutes
otherwise, even though this only means solving a single linear program. While the approach by
Huang et al. [HKWW17] does not suﬀer from this limitation, it cannot handle general veriﬁcation
properties, which we believe to be important. We plan to work on tackling the network size limitation
of the approach presented in this paper in the future.

Acknowledgements

This work was partially funded by the Institutional Strategy of the University of Bremen, funded by
the German Excellence Initiative.

References

+
[BIL

16]

Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis, Aditya V.
Nori, and Antonio Criminisi. Measuring neural net robustness with constraints. In
Annual Conference on Neural Information Processing Systems (NIPS), pages 2613–2621,
2016.

[CD91]

John W. Chinneck and Erik W. Dravnieks. Locating minimal infeasible constraint sets
in linear programs. INFORMS Journal on Computing, 3(2):157–168, 1991.

[CUH15]

Djork-Arn´e Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and accurate deep
network learning by exponential linear units (ELUs). arXiv/CoRR, 1511.07289, 2015.

[DdM06]

Bruno Dutertre and Leonardo Mendonc¸a de Moura. A fast linear-arithmetic solver for
DPLL(T). In 18th International Conference on Computer Aided Veriﬁcation (CAV), pages
81–94, 2006.

[Dut14]

[ES03]

Bruno Dutertre. Yices 2.2. In 26th International Conference on Computer Aided Veriﬁcation
(CAV), pages 737–744. Springer, 2014.

Niklas E´en and Niklas S ¨orensson. An extensible SAT-solver. In 6th International Con-
ference on Theory and Applications of Satisﬁability Testing, (SAT). Selected Revised Papers,
pages 502–518, 2003.

[FM09]

John Franco and John Martin. A History of Satisﬁability, volume 185 of Frontiers in
Artiﬁcial Intelligence and Applications, chapter 1, pages 3–74. IOS Press, February 2009.

[HKWW17] Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. Safety veriﬁcation of
deep neural networks. In 29th International Conference on Computer Aided Veriﬁcation
(CAV). Springer, 2017.

+
[JSD

14]

Yangqing Jia, Evan Shelhamer, Jeﬀ Donahue, Sergey Karayev, Jonathan Long, Ross
Girshick, Sergio Guadarrama, and Trevor Darrell. Caﬀe: Convolutional architecture
for fast feature embedding. arXiv/CoRR, 1408.5093, 2014.

14

+
[KBD

17] Guy Katz, Clark W. Barrett, David L. Dill, Kyle Julian, and Mykel J. Kochenderfer. Relu-
plex: An eﬃcient SMT solver for verifying deep neural networks. In 29th International
Conference on Computer Aided Veriﬁcation (CAV). Springer, 2017.

[KS08]

Daniel Kroening and Ofer Strichman. Decision Procedures – An Algorithmic Point of View.
Springer, 2008.

[LBBH98]

Y. Lecun, L. Bottou, Y. Bengio, and P. Haﬀner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.

[LC09]

Yann Lecun and Corinna Cortes. The MNIST database of handwritten digits, 2009.

[PT10]

[PT12]

[Sch15]

Luca Pulina and Armando Tacchella. An abstraction-reﬁnement approach to veriﬁca-
tion of artiﬁcial neural networks. In 22nd International Conference on Computer Aided
Veriﬁcation (CAV), pages 243–257, 2010.

Luca Pulina and Armando Tacchella. Challenging SMT solvers to verify neural net-
works. AI Commun., 25(2):117–135, 2012.

J ¨urgen Schmidhuber. Deep learning in neural networks: An overview. Neural Networks,
61:85–117, 2015.

+
[SNM

16] Karsten Scheibler, Felix Neubauer, Ahmed Mahdi, Martin Fr¨anzle, Tino Teige, Tom
Bienm ¨uller, Detlef Fehrer, and Bernd Becker. Accurate ICP-based ﬂoating-point rea-
soning. In Formal Methods in Computer-Aided Design (FMCAD), pages 177–184, 2016.

[SWWB15] Karsten Scheibler, Leonore Winterer, Ralf Wimmer, and Bernd Becker. Towards veriﬁ-
cation of artiﬁcial neural networks. In MBMV Workshop 2015, Chemnitz, Germany, pages
30–40, 2015.

[WK15]

+
[YYS

15]

Michael Wagner and Philip Koopman. A philosophy for developing trust in self-driving
cars. In Road Vehicle Automation 2, pages 163–171. Springer International Publishing,
2015.

Qian Yu, Yongxin Yang, Yi-Zhe Song, Tao Xiang, and Timothy M. Hospedales. Sketch-
a-net that beats humans. In British Machine Vision Conference (BMVC), pages 7.1–7.12,
2015.

15

