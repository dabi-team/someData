2
2
0
2

y
a
M
0
3

]
E
M

.
t
a
t
s
[

4
v
6
6
8
8
0
.
2
1
1
2
:
v
i
X
r
a

Detecting Model Misspeciﬁcation in Amortized
Bayesian Inference with Neural Networks

Marvin Schmitt
Cluster of Excellence SimTech
University of Stuttgart, Germany
mail.marvinschmitt@gmail.com

Paul-Christian Bürkner
Cluster of Excellence SimTech
University of Stuttgart, Germany
paul.buerkner@gmail.com

Ullrich Köthe
Computer Vision and Learning Lab, IWR
University of Heidelberg, Germany
ullrich.koethe@iwr.uni-heidelberg.de

Stefan T. Radev
Cluster of Excellence STRUCTURES
University of Heidelberg, Germany
stefan.radev93@gmail.com

Abstract

Recent advances in probabilistic deep learning enable amortized Bayesian infer-
ence in settings where the likelihood function is implicitly deﬁned by a simulation
program. But how faithful is such inference when simulations represent reality
somewhat inaccurately? In this paper, we conceptualize the types of model mis-
speciﬁcation arising in simulation-based inference, systematically investigate the
performance of SNPE-C (APT) and the BayesFlow framework under these misspec-
iﬁcations and devise a “misspeciﬁcation alarm”, namely a statistical test signaling
suspicious inputs. Our main insight is that this test works most reliably on the level
of learnable data summary statistics. Thus, we augment the training objectives
to impose probabilistic structure on our models’ latent summary space, so that
outlying summaries can be detected by maximum mean discrepancy (MMD). We
verify the alarm for various synthetic and real misspeciﬁcations and show that
outlying summary statistics are powerful proxies for posterior inference errors
arising from misspeciﬁed simulations, which cannot be identiﬁed directly because
the true generative process is generally unknown.

1

Introduction

Computer simulations play a fundamental role in many ﬁelds of science. However, ﬁnding simulation
parameters that faithfully reproduce or predict real-world behavior is difﬁcult and usually analytically
intractable. Here, we consider simulation-based inference (SBI) as a general approach to overcome
this difﬁculty. We conduct analyses of the SNPE-C (APT; Greenberg et al., 2019) and BayesFlow
frameworks (Radev et al., 2020a), which utilize deep learning to infer posterior probabilities for the
simulation parameters of interest. Speciﬁcally, we study how amortized simulation-based inference
performs under well-speciﬁed vs. misspeciﬁed simulations (i. e., simulations that do or do not
precisely capture the mechanisms of the real system) and propose a new misspeciﬁcation measure
that reliably detects when the system behavior at test time deviates from the behavior during training.
Detecting such deviations is of crucial importance because mild or sometimes severe mismatch
between simulated and actual behavior occurs almost inevitably in practice. To this end, we develop
a theoretical basis for misspeciﬁcation detection, incorporate it into simulation-based inference
frameworks with learned summary statistics, and investigate it on toy examples and two representative
scientiﬁc tasks in cognitive decision making and disease outbreak dynamics.

Preprint. Under review.

 
 
 
 
 
 
So far, work on deep amortized SBI has mainly focused on ﬁnding network architectures and training
algorithms that achieve the highest performance (Greenberg et al., 2019; Radev et al., 2020a; Durkan
et al., 2020; Lueckmann et al., 2017). In contrast, the consequences of model misspeciﬁcation have
received little attention in the context of amortized SBI. Model misspeciﬁcation occurs when a model
does not fully represent the actual behavior of the modeled system or when it does not completely
account for measurement errors and contamination in the observations serving as inference inputs. In
the context of SBI, this is also referred to as a simulation gap, and we use the terms interchangeably.

Amortized Bayesian methods require simulations to be faithful proxies of reality and might yield
wrong posteriors when presented with observables which are atypical under the assumed model
(cf. Figure 1). Our experiments clearly demonstrate this effect and show how amortized posterior
inference gradually deteriorates as the simulation gap widens. Consequently, amortized SBI methods
must be able to detect simulation gaps and subsequent posterior errors, so that they can warn users
about suspicious outputs (or even decline to make predictions under such circumstances) and guide
model designers in their search for better simulators.

The main purpose of this paper is twofold. First, we conceptualize model misspeciﬁcation in
applications of simulation-based Bayesian inference with neural networks (section 3.1). We then
propose a simple and intuitive way to detect model misspeciﬁcation and posterior inference errors
(posterior errors, for short) arising due to ﬁnite training (section 3.5). See Figure 1 for a conceptual
illustration. Our approach does not modify existing neural architectures and greatly beneﬁts from the
properties of amortized inference. Instead, it acts as a modular and intuitive extension of previous
work on sequential neural density estimators (SNPE-C; Greenberg et al., 2019), invertible neural
networks (INNs; Ardizzone et al., 2018), and the BayesFlow framework (Radev et al., 2020a) towards
a principled simulation-based Bayesian workﬂow. Indeed, the demand for a trustworthy workﬂow in
amortized Bayesian inference increases heavily due to the growing number of applications relying
on amortized simulation-based inference (e.g., Shiono, 2021; Bieringer et al., 2021; Dehning et al.,
2020; Gonçalves et al., 2020). The key contributions of our paper are:

(i) A way to conceptualize different sources of model misspeciﬁcation in amortized Bayesian

inference with neural networks;

(ii) An augmented optimization objective and a criterion to detect model misspeciﬁcation and

posterior errors during inference, regardless of a model’s structure, input, or output;

(iii) A systematic investigation of our detection criterion and its relationship with posterior errors

in a variety of models and misspeciﬁcations.

2 Related work

Neural approaches to amortized simulation-based inference can be categorized as either targeting
the posterior (Radev et al., 2020a; Greenberg et al., 2019), the likelihood (Papamakarios et al., 2019;
Hermans et al., 2020), or both (Wiqvist et al., 2021). We hypothesize that the estimation quality of
these approaches will be, in general, unpredictable, when faced with atypical real-world data.

On the other hand, model misspeciﬁcation has been studied in the context of standard Bayesian
inference and various ideas have been explored (Grünwald et al., 2017; Thomas and Corander, 2019).
For instance, likelihood tempering methods incorporate a modiﬁed likelihood (raised to a power
0 < t < 1) in order to prevent potentially overconﬁdent Bayesian updating (Thomas and Corander,
2019). However, the likelihood in SBI is assumed to be unknown and thus impossible to evaluate
explicitly. Applying likelihood tempering methods to amortized neural likelihoods appears to be
another avenue for future research.

For robust non-amortized ABC samplers, the possibility of utilizing hand-crafted summary statistics
as an important element of misspeciﬁcation analysis has already been explored (Frazier et al., 2020;
Frazier and Drovandi, 2021). Our work parallels these ideas and extends them to the case of
learnable summary statistics in amortized SBI on potentially massive data sets, where ABC becomes
infeasible. Furthermore, we offer a conceptual discussion on the sources of misspeciﬁcations (and
their consequences) arising in SBI and explore the connection between posterior errors and model
misspeciﬁcation as a function of the number of summary statistics. In the ﬁeld of variational Bayes,
recent work has studied the convergence and concentration rates with and without misspeciﬁcation
(Alquier and Ridgway, 2019; Zhang and Gao, 2020). These approaches are not directly transferable

2

Typical generative set

)

(
G

T

x

p(x

)
| M

∼

Latent generative space

hψ
Summary
Network

hψ(x)

fφ
Inference
Network

Correct
Posterior

Incorrect
Posterior

Generative Model

G

Simulation gap

xobs ∼

po(x)

hψ(xobs)

Simulation gap detected

(

) of a complex model

Figure 1: Conceptual overview of our framework as a step towards trustworthy simulation-based
inference with neural density estimators. A summary network hψ transforms the typical generative set
into the typical set of a simple distribution (e. g., Gaussian). Simulation
T
gaps between the model-implied distribution of observables p(x
) and the one implied by reality
po(x) manifest themselves as detectable anomalies, causing posterior errors by the inference network
fφ. These anomalies are ﬂagged by hψ via distribution matching (maximum mean discrepancy).

| M

G

G

to amortized models because they do not naturally provide a practical “misspeciﬁcation alarm”, which
is needed because neural networks remain unchanged after the training phase in SBI.

From the perspective of Bayesian model comparison as classiﬁcation, different outlier detection
techniques appear to be viable for uncovering simulation gaps. For instance, Radev et al. (2021a)
propose to train regularized evidential networks which learn a higher-order distribution over posterior
model probabilities. This way, conclusions about the absolute misﬁt of all models in a set of candidate
models can be drawn. However, this approach is not suitable for parameter estimation and requires a
loss function which does not guarantee a correct approximation of posterior model probabilities.

3 Methods

3.1 Deﬁning model misspeciﬁcation

For the purpose of simulation-based inference, we deﬁne a generative model as a triple
g(θ, ξ), p(ξ

. Such a model generates data points x

=
according to the system

θ), p(θ)

G

|

∈ X

(cid:0)

(cid:1)

x = g(θ, ξ) with ξ

p(ξ

|

∼

θ), θ

∼

p(θ),

(1)

|

∈

where g denotes a (randomized) simulation program, ξ
Ξ is a source of randomness (i. e., noise)
with density function p(ξ
θ), and p(θ) encodes prior knowledge about plausible simulation parame-
Θ. Intuitively, x represents quantities that we can observe and measure in the real-world, θ
ters θ
consists of hidden properties whose role in g we explicitly understand and model, and ξ takes care of
, Ξ, and Θ denote the domain of
nuisance effects that we only treat statistically. The abstract spaces
possible output data (possible worlds), the scope of noise, and the set of admissible model parameters,
respectively. The distinction between hidden properties θ and noise ξ is not entirely clear-cut, but
depends on our modeling goals and may vary across applications. Moreover, our understanding of
the world is constantly evolving, and yesterday’s noise might become tomorrow’s signal.

X

∈

Whenever we employ simulations to investigate some real world phenomenon, a close correspondence
between model and reality is necessary. Unacceptably large discrepancies between the two realms
are known as a simulation gap, and the corresponding model is said to be misspeciﬁed. Model
misspeciﬁcation can arise from any of the three model components in isolation or simultaneously. A
few illustrative examples show what can go wrong in practice:

(i) Misspeciﬁed Simulator.

In a model for the hydraulic conductivity of a medium, the
spatial composition of the material is essential: A simulator relying on the assumption of
homogeneity will wrongly predict the behavior of heterogeneous materials, biasing inference
results in complex and arbitrary ways (Schöniger et al., 2015; Nowak and Guthke, 2016).

3

(ii) Unexpected Contamination. During an ongoing pandemic, data collection may be severely
distorted, for example by noisy measurements, systematic underreporting, and delayed data
transfer (Dehning et al., 2020), to name just a few. An epidemiological model disregarding
these factors in p(ξ
θ) will produce erroneous inferences about key disease parameters,
even if the underlying theory was otherwise a good approximation of the disease dynamics.
(iii) Misspeciﬁed Prior. When the admissible region of the prior p(θ) is speciﬁed too large, –

|

for example, allows negative mass – physically impossible simulations may arise.

Our generative model formulation is equivalent to the standard probabilistic factorization of the
) p(θ
Bayesian joint distribution into likelihood and prior, p(θ, x
), where
| M
M
. This likelihood is
G
) over all possible values of the nuisance

θ,
expresses the prior knowledge and assumptions embodied in the design of

M
obtained by marginalizing the joint distribution p(ξ, x
parameters ξ, that is, over all possible execution paths of the simulation program, for ﬁxed θ:

) = p(x

| M

M

θ,

|

|

p(x

θ,

|

) =

M

(cid:90)Ξ

p(ξ, x

θ,

|

) dξ.

M

(2)

This integral is typically intractable (Cranmer et al., 2020), but we assume that it exists and is
non-degenerate, that is, it deﬁnes a proper density over the constrained manifold (g(θ, ξ), ξ), and
this density can be learned.
Whenever we model a real-world complex system, we assume an unknown (true) generator x = G(
),
·
po(x) and is available to the data analyst only via a
which yields an unknown (true) distribution x
ﬁnite realization (i. e., actually observed data). Then, using the Bayesian formulation, we say that a
generative model

is strictly well-speciﬁed if

∼

G

po(x) = p(x

)
| M

≡

(cid:90)Θ

p(x

θ,

|

) p(θ

M

) dθ

| M

(3)

p(x

∈ X

∈ X

po(x)

. Conversely, a generative model is misspeciﬁed if an observable x
for every x
exists for
which the above equality is violated. Since models necessarily simplify reality, the above criterion
for well-speciﬁed models is often unattainable in practice. We therefore relax the requirement by
quantifying a model’s degree of misspeciﬁcation in terms of the information loss incurred by the
simpliﬁcation: For an acceptable upper bound ϑ on the information loss, a model is well-speciﬁed if
D
< ϑ and misspeciﬁed otherwise. The symbol D denotes a divergence metric
quantifying the “distance” between the data distribution implied by reality and the model-implied
data distribution (the marginal likelihood). Notably, equality in Eq. 3 implies no information loss
) and thus a divergence of zero. A natural choice for D would be a
by modeling po(x) with p(x
| M
-divergences, such as the Kullback-Leibler (KL) divergence. However,
metric from the family of
-divergences requires closed-form densities, and thus po(x)
since the practical computation of
to be analytically tractable, we prefer a probability integral metric, such as the Maximum Mean
Discrepancy (MMD; Gretton et al., 2012). Using the kernel trick, the MMD can be expressed as

)
| M

F

F

||

(cid:3)

(cid:2)

MMD2

po(x)

p(x

)
| M

||

= E po(x)

κ(x, x(cid:48))

+ Ep(x | M)

κ(x, x(cid:48))

2Ex ∼po(x)

x(cid:48)∼p(x | M)

−

κ(x, x(cid:48))

.

(cid:2)

(cid:3)
(4)
Crucially, this metric is practically tractable because it can be efﬁciently estimated via ﬁnite samples
from po(x) and p(x
) is any positive deﬁnite kernel and the
,
). In the above expression, κ(
·
metric equals zero if and only if the two densities are equal (Gretton et al., 2012).

| M

(cid:3)

(cid:2)

(cid:2)

(cid:3)

(cid:3)

(cid:2)

·

We use sums of Gaussian kernels with different widths σi as an established and ﬂexible universal
kernel (Muandet et al., 2017). However, Ardizzone et al. (2018) observe that kernels with heavier
tails may improve performance by yielding more meaningful gradients for outliers. Thus, we repeated
all experiments with a sum of inverse multiquadratic kernels (as proposed by Tolstikhin et al., 2017).
The results are essentially equal to those obtained with sums of Gaussian kernels (cf. Appendix I).

3.2 Architectures for amortized inference

Our proposed method can be applied to any framework that uses learned summary statistics as an
input to a neural posterior approximator. We will exemplarily outline the integration of our method
into the BayesFlow (Radev et al., 2020a) and the SNPE-C (aka APT, Greenberg et al., 2019) methods.

4

BayesFlow The BayesFlow method consists of a summary network hψ and an inference network
fφ which jointly amortize a generative model
. The summary network hψ transforms input data
x of variable size to a ﬁxed-length representation hψ(x). The inference network samples from an
approximate posterior qφ via a conditional invertible neural network (cINN, ?). Together, the two
networks minimize the expected KL divergence between approximate and true simulation posterior,
which reduces to

G

ψ∗, φ∗ = min
ψ,φ

Ep(θ,x | M)

log qφ

θ

hψ(x),

|

−

M

,

(5)

(cid:104)

(cid:0)

(cid:1)(cid:105)

|

x,

M

since the true posterior p(θ
) does not depend on the trainable neural network parameters. We
approximate this expectation via simulations from the generative model
and repeat the process
until convergence. This objective is self-consistent and results in correct amortized inference under
optimal convergence (Radev et al., 2020a). However, simulation-based training takes the expectation
), not the true distribution po(x). Thus, optimal convergence
with respect to the model p(θ, x
does not imply correct posterior inference or faithful prediction in the real world when there is a
simulation gap, that is, when the model

deviates critically from the unknown true generator.

| M

G

G

SNPE-C The SNPE-C method (Greenberg et al., 2019) iteratively transforms a proposal (prior)
) induced by given data set xobs through a
xobs,
distribution ˆp(θ
series of simulation-based training rounds. Typically, the approximate posterior after a given round is
used as the proposal prior for the next round, resulting in a semi-amortized optimization criterion:

) into the posterior p(θ

| M

M

|

ψ∗, φ∗ = min
ψ,φ

Ep(x | θ,M) ˆp(θ | M)

log ˆqφ

θ

x,

|

M

−

(cid:104)

(cid:0)

,
(cid:1)(cid:105)

(6)

| M

where ˆp(θ
) is the current proposal distribution and the approximate posterior ˆqφ
is
represented as a categorical distribution over a discrete set of atomic proposals in order to be tractable
(Greenberg et al., 2019). If we set ˆp(θ
) for all rounds and introduce a jointly trained
summary network hψ(x), then the optimization criterion in Eq. 6 is identical to that of BayesFlow
(Eq. 5) and SNPE-C can perform fully amortized inference. Either way, the ﬁrst round of SNPE-C
always depends only on the simulator outputs, so simulation gaps can be equally problematic.

M
(cid:1)

) = p(θ

| M

| M

x,

θ

(cid:0)

|

3.3 Structured summary statistics

The summary network hψ acts as an interface between the data x and the inference network fφ. Its
role is to learn maximally informative summary vectors of ﬁxed size S from complex and structured
observations (e. g., sets of i.i.d. measurements or multivariate time series). Therefore, the summary
network’s representation hψ(x) is an adequate target to detect simulation gaps.

hψ(x)

Speciﬁcally, we propose to prescribe an S
dimensional multivariate unit Gaussian distribution to
0, I), by minimizing the MMD between summary
the summary space, p
network outputs and random draws from a unit Gaussian distribution. To ensure that the learned
summary vectors comply with the support of the Gaussian density, we introduce a linear (bottleneck)
output layer with S units to the summary network. Thus, a random vector in summary space takes
the form hψ(x) := (s1, . . . , sS)

RS. The extended optimization objective then becomes

| M
(cid:1)

−
(zx

≈ N

(cid:0)

|

∈

ψ∗, φ∗ = argmin

ψ,φ

Ep(θ,x | M)

log qφ

θ

hψ(x),

|

−

M

MMD2

p

hψ(x)

+ γ

·

p

zx

,

||

(7)
(cid:1)(cid:3)
with a hyperparameter γ to control the relative weight of the MMD term. For other frameworks, the
MMD term is added to the optimization objective analogously. Intuitively, this objective encourages
the approximate posterior qφ
to match the true posterior and the summary distribution
p

to match a unit Gaussian. Appendix A discusses the theoretical implications.

hψ(x),

hψ(x)

θ

(cid:0)

(cid:0)

(cid:0)

(cid:2)

|

| M
(cid:1)

(cid:1)(cid:105)

(cid:104)

| M
(cid:1)

(cid:0)

3.4 Detecting model misspeciﬁcation

(cid:0)

M
(cid:1)

Once the simulation-based training phase is completed, we can generate a validation sample
θ(m), x(m)
M
m=1 from our generative model G and pass it through the summary network to obtain a
{
}
M
m=1, where ˜zx = hψ(x) denotes the output of the sum-
sample of latent summary vectors
mary network. The properties of this sample contain important convergence information, which is a
prerequisite for meaningful model comparison later on: If ˜zx is approximately unit Gaussian, we can

˜z(m)
x }

{

5

assume a structured summary space given G. This enables model misspeciﬁcation diagnostics via
distribution checking during inference on real data.

x(n)
obs}

{

N
Let
n=1 be an observed sample, either simulated from a different generative model, or arising
from real-world observations with an unknown generator. Before invoking the inference network,
˜z(n)
N
n=1. We then compare the
we pass this sample through the summary network to obtain
xobs }
M
m=1 with the summary representation at inference time
validation summary distribution
2
˜z(n)
N
(˜zx, ˜zxobs ) (cf. Gretton et al.,
xobs }
{
2012). Importantly, we are not limited to pre-determined sizes of simulated or real-world datasets, as
the MMD estimator is deﬁned for arbitrary M and N .1

˜z(m)
x }
n=1 according to the sample-based MMD estimate (cid:92)MMD
{

{

M
m=1 and

˜z(m)
x }
{

Whenever we estimate the MMD from ﬁnite data, its estimates vary according to a sampling distribu-
tion and we can resort to a sampling-based (frequentist) hypothesis test to determine the probability
of observed MMD values under well-speciﬁed models. We can estimate the MMD sampling dis-
tribution under the null hypothesis (i. e., no simulation gap) from multiple sets of simulations from
˜z(n)
N
n=1, with M large and N equal to the number of real
the generative model,
x }
{
data sets. Based on the estimated sampling distribution, we can obtain a critical MMD value for a
ﬁxed Type I error probability (α) and compare it to the one estimated with the observed data. In
general, a larger α
level corresponds to a more conservative modeling approach: A higher type
I error probability implies that more tests reject the null hypothesis, which corresponds to more
frequent model misspeciﬁcation alarms and a higher chance that incorrect models will be recognised.
Note, that the Type II error probability (β) of this test will generally be high (i. e., the power of
the test will be low) whenever the number of real data sets N is very small. However, we show in
Experiment 2 that even as few as 5 real data sets sufﬁce to achieve β

0 for a complex model.

−

≈

3.5 Posterior inference errors due to misspeciﬁed models

|

x,

M

M

M

) always exists even if

, the correct posterior under the potentially misspeciﬁed model
Given a generative model
is misspeciﬁed for the data x. Obtaining a trustworthy ap-
p(θ
proximation of the correct posterior is the fundamental basis for any follow-up inference (e. g.,
parameter estimation or model comparison) and must be at least an intermediate goal in real world
, the amortized posterior
applications. Assuming optimal convergence under a misspeciﬁed model
), as any transformed x
x,
qφ
arising from po(x) has non-zero density in the latent Gaussian summary space.2 Thus, the inference
for any query x.
network should still be able to obtain the correct pushforward density under
However, optimal convergence can never be achieved after ﬁnite training time, so we need to address
its implications for the validity of amortized simulation-based posterior inference in practice.

still corresponds to the correct posterior p(θ

zx = hψ(x),

M
(cid:1)

M
M

M

θ

(cid:0)

|

|

⊂ X

of the generative model

)
(
G
T
) is close to the entropy E
| M

Given ﬁnite training data, the summary and inference networks will mostly see simulations from the
typical set
, that is, training instances whose self-information
log p(x
. In high dimensional problems, the typical
−
set will comprise a rather small subset of the possible outcome space, determined by a complex
(cid:2)
(Betancourt, 2017). Accordingly, good convergence in
interaction between the components of
) actually follow the approximate Gaussian in
practice may mean that i) only observations from
)
latent summary space and ii) the inference network has only seen enough training examples in
to learn accurate posteriors for observables x

G
log p(x

(
G
).

)
| M

(
G

−

G

T

(cid:3)

T
(
G

∈ T

In contrast, atypical or improbable outcomes occur rarely during simulation-based training and have
negligible effect on the loss in Eq. 7. Consequently, posterior approximation errors for observations
) can be large, simply because the networks have not yet converged in these unusual
outside of
regions, and the highly non-linear mapping of the inference network still deviates considerably from
the true solution. Better training methods might resolve this problem in the future, but for now our
proposed MMD criterion reliably signals low ﬁdelity posterior estimates by quantifying the “distance
from the typical generative set”

) in the structured summary space.

(
G

T

Moreover, we hypothesize and demonstrate empirically in the following experiments that the differ-
ence between the true p(θ
) for misspeciﬁed

) and the approximate posterior qφ(θ

hψ(x),

x,

|

M

1To allow MMD estimation for data sets with single instances (N = 1 or M = 1), we do not use the
unbiased MMD version from Gretton et al. (2012). Singleton data sets are an important use case for our method
in practice, and potential advantages of unbiased estimators do not justify exclusion of such data.

2We assume that we have no hard limits in the prior or simulator in G.

6

(
G

T

|

M

Figure 2: Prior misspeciﬁcation can be detected with a minimal sufﬁcient summary network (S = 2).
Left: Pairplot of 10 000 summary space samples. All prior misspeciﬁcations are distinguishable from
the typical latent generative space (blue).
Right: MMD as a function of µ0 (prior location) and τ0 (scale factor in the mean prior). The
MMD estimate increases as the simulation gap gets more severe. The colored dots correspond to the
respective misspeciﬁed model conﬁguration in the pairplot.

Table 1: Investigated model misspeciﬁcations in Experiment 1. The noise model
3σx to make detection harder.
of a Gaussian and a Beta distribution, rescaled to

±

N is a mixture

M

Prior
Model (MMS)
∗ (No MMS)
µ
µ
P (Prior)
S (Simulator) µ
µ
N (Noise)

M
M
M
M

∼ N
∼ N
∼ N
∼ N

= 0, Σ0 = τ0I), τ0

(µ0 = 0, Σ0 = I)
(µ0 (cid:54)
(µ0 = 0, Σ0 = I)
(µ0 = 0, Σ0 = I)

∈

Likelihood
xk
R+ xk
xk
xk

∼ N
∼ N
∼ N
λ
·
∼

(µ, Σ = I)
(µ, Σ = I)
(µ, Σ = τ I), τ
∈
Beta(2, 5) + (1

R+
λ)

−

(µ, Σ = I)

· N

models increases as a function of MMD and thus also measures the amount of misspeciﬁcation.
Therefore, our MMD criterion serves a dual purpose in practice: It can uncover potential simulation
gaps and, simultaneously, signal errors in posterior estimation.

4 Experiments

4.1 Experiment 1: multivariate normal distribution

Setup. We set the stage by estimating the posterior mean of a D-dimensional conjugate toy multi-
variate normal (MVN) model with a known analytic posterior in order to illustrate our method. The
generative model is deﬁned as

xk

(x

|

∼ N

µ, Σ)

for k = 1, ..., K

with µ

(µ

|

∼ N

µ0, Σ0)

(8)

For ease of visualization, we set D = 2 and simulate data sets of K = 100 observations each. We
use a permutation invariant summary network (Bloem-Reddy and Teh, 2020) with S = 2 output
dimensions, which equal the number of minimal sufﬁcient statistics3 implied by the analytic posterior.
We set the prior to a unit Gaussian and the likelihood covariance Σ to an identity matrix. The model
∗ used for training the networks as well as the types of misspeciﬁcations are outlined in Table 1.
M
We conduct the experiment with BayesFlow as well as SNPE-C, both equipped with our adjusted
optimization objective.4
Results. The BayesFlow network trained to minimize the augmented objective (Eq. 7) exhibits
excellent recovery of the analytic posterior means when no misspeciﬁcation is present (30min training

3Note that the terms “minimal”, “sufﬁcient”, and “overcomplete” refer to the inference task and not to the

data. Thus, S = 2 summary statistics are sufﬁcient to solve the inference task, namely recover two means.
4BayesFlow is available at https://github.com/stefanradev93/BayesFlow (MIT license),
SNPE-C is available in the sbi packge at https://github.com/mackelab/sbi (AGPL-3.0 license).

7

−10010s1−10010s1−10010s2−10010s2−505µ012345τ0(scalefactorofΣ0)drMMD0.51.01.52.02.53.03.5NoMMSPriorlocation:µ0=5Priorscale:τ0=2.5Priorlocationandscale:µ0=5,τ0=2.5(a) Prior misspeciﬁcation: Both summary networks
(minimal and overcomplete) detect increasingly severe
misspeciﬁcation through an elevated rMMD and lead
to a higher posterior error (RMSE) of the inference
network.

(b) Noise and simulator misspeciﬁcation: While the
minimal network exhibits poor detection, its posterior
recovery is not impaired either. The overcomplete
network captures increasingly severe misspeciﬁcation
but suffers from an increased posterior error (RMSE).

Figure 3: Posterior error (RMSE between analytic posterior means µp and approximate posterior
means µˆθ) as a function of model misspeciﬁcation severity, as indexed by the MMD criterion.

time on a CPU). All prior misspeciﬁcations manifest in anomalies in the summary space which are
directly detectable through visual inspection of the 2
dimensional summary space in Figure 2. Note,
that the combined prior misspeciﬁcation (location and scale) exhibits a summary space pattern that
mirrors the location and scale of the respective location and scale misspeciﬁcation. However, based
dimensional summary space, misspeciﬁcations in the ﬁxed parameters of the likelihood (τ )
on the 2
and mixture noise are neither detectable through visual inspection, nor through increased MMD.

−

−

We then investigate the effect of an overcomplete summary space with respect to the inference
task, namely S = 4 summary outputs with an otherwise equal architecture. The overcomplete
summary space captures misspeciﬁcations in the noise and simulator through the MMD criterion (see
Figure B.1b). Furthermore, the induced misspeciﬁcations in the noise distribution and simulator are
visually detectable in the summary space samples (see Figure B.2). The 2
dimensional summary
space fails to capture these misspeciﬁcations (see Figure B.1a).

−

Finally, we compute the error in posterior recovery via RMSE and MMD as a function of misspec-
iﬁcation severity for both BayesFlow networks relying on a minimal (S = 2) or an overcomplete
(S = 4) summary network . Figure 3 illustrates that a larger MMD estimate coincides with a larger
error in posterior estimation across all model misspeciﬁcations for both summary networks. However,
the minimal and overcomplete networks exhibit a drastically different behavior when processing
data with misspeciﬁed noise and simulator (see Figure 3b). While the minimal summary network
cannot detect noise or simulator simulation gaps, its posterior estimation performance is not heavily
impaired either (see Figure 3b). On the other hand, the overcomplete summary network is able to
capture noise and simulator misspeciﬁcations, but also incurs larger posterior inference error.

SNPE-C (APT). Our method successfully detects model misspeciﬁcation in SNPE-C (Greenberg
et al., 2019) with the proposed MMD criterion and a structured summary space (see Appendix C).
The results are largely equivalent to those obtained with BayesFlow. The subtle differences are not
soundly interpretable due to the architectural differences of the two frameworks.

Higher dimensions. We extended the toy model to higher dimensions and a more difﬁcult task
(i. e., recover information beyond ﬁrst moments) in BayesFlow. Appendix D shows that our method
successfully detects simulation gaps for a 5D Gaussian with a fully estimated covariance matrix.

4.2 Experiment 2: COVID-19 modeling

Setup. Compartmental models in epidemiology (CMs) are very popular for inferring relevant disease
parameters, simulating possible outbreak scenarios, and projecting future outcomes (Dehning et al.,
2020). Given the abundance of such models and their increasing complexity, the importance of
detecting simulation gaps for trustworthy inference is two-fold. First, since substantial conclusions
are based on the posterior distributions of model parameters, it is important that these distributions are
formally correct even when models do not capture all relevant real-world factors. Second, given the

8

(01)(52.5)PriorMMS(µ0τ0)0.00.51.0RMSE(µp||µˆθ)minimalovercompletedrMMD0.00.51.01.52.02.53.0(01)(120)NoiseandSimulatorMMS(λτ)0.000.250.500.751.00RMSE(µp||µˆθ)minimalovercompletedrMMD0.00.51.01.52.02.53.0Table 2: Results for different variations of the COVID-19 compartmental model. We report the
median and 95% CI of 100 bootstrap samples of (cid:92)rMMD for each N (see Appendix F for details).

N = 1
3.70 [3.65, 3.79]
3.76 [3.72, 3.80]
3.80 [3.73, 3.83]
3.78 [3.74, 3.83]

Bootstrap (cid:92)rMMD
N = 2
2.61 [2.54, 2.91]
2.86 [2.62, 3.16]
2.81 [2.65, 3.00]
2.81 [2.68, 3.11]

N = 5
1.66 [1.59, 1.84]
2.11 [1.82, 2.50]
2.01 [1.82, 2.19]
2.07 [1.92, 2.41]

Model

∗
M
1
M
2
M
3
M

Power (1

β)

−

N = 1 N = 2 N = 5
—
.958
.804
.690

—
.998
.789
.631

—
1.0
1.0
1.0

≈
≈
≈

dynamic aspect of these models, it is important to detect if an initially well-speciﬁed model becomes
misspeciﬁed at a later time, so the model and its predictions can be amended.

As a ﬁnal real-world example, we thus focus on a high-dimensional CM representing the early months
of the COVID-19 pandemic in Germany (Radev et al., 2021b). Here, we investigate the utility of
our distribution matching method to detect simulation gaps. To achieve this, we train a BayesFlow
setup identical to Radev et al. (2021b) but using our new optimization objective (Eq. 7) to encourage
a structured summary space (24h training time on NVIDIA GTX 1070Ti). We then simulate 1000
∗ and 1000 time-series from three misspeciﬁed models: i) a
time-series from the original model
model
2 without an observation sub-model;
iii) a model

3 without a latent “carrier” compartment (Dehning et al., 2020).

1 without an intervention sub-model; ii) a model

M

M

M

Results. Table 2 shows the MMD between the summary representation of N = 1, 2, 5 bootstrapped
∗.
time series from each model and the summary representation of the 1000 time series from model
M
We also calculate the power (1
Mj∈{1,2,3}
∗ at a
under the sampling distribution estimated from 1 000 samples of the 1 000 time series from
M
type I error probability of α = .05. We observe that the power of the test rapidly increases with more
data sets and the Type II error probability (β) is essentially zero for as few as N = 5 time series (full
power analysis results in Figure H.1).

β) of our hypothesis test for each misspeciﬁed model

−

M

As a next step, we pass the reported data between 1 March and 21 April 2020 (data from Dong et al.,
2020, under CC BY 4.0 license) through the summary network and compute the critical MMD value
for a sampling-based hypothesis test with an α-level of .05 (see Figure F.1). The observed MMD of
the Germany data is below the critical MMD value, leading to the conclusion that the model is not
misspeciﬁed for this time period. Finally, we perform linear dimensionality reduction (PCA) on the
summary space and ﬁnd that the ﬁrst 40 principal components jointly explain 95% of the variance
dimensional summary space outputs. Thus, a 40-dimensional learned summary vector
in the 192
might provide a good approximation of the true (unknown) minimally sufﬁcient summary statistics
and render inference less fragile in the face of potential misspeciﬁcations.

−

5 Discussion

With this work, we approached a fundamental problem in amortized simulation-based Bayesian
inference, namely, capturing posterior errors due to model misspeciﬁcation. We proposed to increase
the networks’ awareness of posterior errors by compressing simulations into a structured latent space
induced by a modiﬁed optimization objective. We then applied the maximum mean discrepancy
(MMD) estimator, equipped with a sampling-based hypothesis test, as a criterion to spotlight discrep-
ancies between model-implied reality and actual observations in latent space. While we focused on
the application to SNPE-C and BayesFlow, the proposed methods can be directly employed in other
frameworks with learned neural summary statistics as well.

Our methods can be extended and modiﬁed in multiple ways. We optimized the latent data space
towards a spherical Gaussian structure. However, our method should work with arbitrary latent data
distributions. For example, heavy-tailed distributions (e. g., α-stable distributions with tunable tail
parameters) might reduce the impact of outliers in latent space. Initial experiments indicate that
such variations can lower posterior errors while still maintaining the ability to detect simulation
gaps. The idea of Frazier et al. (2020) to detect simulation gaps by posterior discrepancies between
differently conﬁgured approximator instances is interesting, and future endeavors might incorporate

9

this into simulation-based inference with neural networks. In addition, considerations on information
geometry and non-Euclidean spaces might guide future research into building more ﬂexible latent
spaces and distance metrics (Arvanitidis et al., 2021).

Our methods are openly available (link redacted during review) and can be seamlessly integrated into
an end-to-end workﬂow for amortized simulation-based inference.

10

References

Alquier, P. and Ridgway, J. (2019). Concentration of tempered posteriors and of their variational

approximations. arXiv:1706.09293 [cs, math, stat]. arXiv: 1706.09293.

Ardizzone, L., Kruse, J., Wirkert, S. J., Rahner, D., Pellegrini, E. W., Klessen, R. S., Maier-Hein, L.,
Rother, C., and Köthe, U. (2018). Analyzing Inverse Problems with Invertible Neural Networks.
CoRR, abs/1808.04730.

Arvanitidis, G., González-Duque, M., Pouplin, A., Kalatzis, D., and Hauberg, S. (2021). Pulling back

information geometry. arXiv preprint arXiv:2106.05367.

Barnard, J., McCulloch, R., and Meng, X.-L. (2000). Modelling Covariance Matrices in Terms of
Standard Deviations and Correlations, with Application To Shrinkage. Statistica Sinica, 10:1281–
1311.

Betancourt, M. (2017). A conceptual introduction to Hamiltonian Monte Carlo. arXiv preprint.

Bieringer, S., Butter, A., Heimel, T., Höche, S., Köthe, U., Plehn, T., and Radev, S. T. (2021).

Measuring QCD Splittings with Invertible Networks. SciPost Physics Proceedings, 10(6).

Bloem-Reddy, B. and Teh, Y. W. (2020). Probabilistic Symmetries and Invariant Neural Networks. J.

Mach. Learn. Res., 21:90–1.

Carpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M.,
Guo, J., Li, P., and Riddell, A. (2017). Stan: A probabilistic programming language. Journal of
statistical software, 76(1).

Cranmer, K., Brehmer, J., and Louppe, G. (2020). The frontier of simulation-based inference.

Proceedings of the National Academy of Sciences, 117(48):30055–30062.

Dehning, J., Zierenberg, J., Spitzner, F. P., Wibral, M., Neto, J. P., Wilczek, M., and Priesemann, V.
(2020). Inferring change points in the spread of COVID-19 reveals the effectiveness of interventions.
Science, 369(6500).

Dong, E., Du, H., and Gardner, L. (2020). An interactive web-based dashboard to track COVID-19 in

real time. The Lancet Infectious Diseases, 20(5):533–534.

Durkan, C., Murray, I., and Papamakarios, G. (2020). On contrastive learning for likelihood-free

inference. In International Conference on Machine Learning, pages 2771–2781. PMLR.

Frazier, D. T. and Drovandi, C. (2021). Robust Approximate Bayesian Inference With Synthetic

Likelihood. Journal of Computational and Graphical Statistics, 30(4):958–976.

Frazier, D. T., Robert, C. P., and Rousseau, J. (2020). Model misspeciﬁcation in approximate Bayesian
computation: consequences and diagnostics. Journal of the Royal Statistical Society: Series B
(Statistical Methodology), 82(2):421–444.

Gonçalves, P. J., Lueckmann, J.-M., Deistler, M., Nonnenmacher, M., Öcal, K., Bassetto, G.,
Chintaluri, C., Podlaski, W. F., Haddad, S. A., Vogels, T. P., et al. (2020). Training deep neural
density estimators to identify mechanistic models of neural dynamics. Elife, 9:e56261.

Greenberg, D., Nonnenmacher, M., and Macke, J. (2019). Automatic posterior transformation for
likelihood-free inference. In International Conference on Machine Learning, pages 2404–2414.
PMLR.

Gretton, A., Borgwardt, K., Rasch, M., Schölkopf, B., and Smola, A. (2012). A Kernel Two-Sample

Test. The Journal of Machine Learning Research, 13:723–773.

Grünwald, P., Van Ommen, T., et al. (2017). Inconsistency of Bayesian inference for misspeciﬁed

linear models, and a proposal for repairing it. Bayesian Analysis, 12(4):1069–1103.

Hermans, J., Begy, V., and Louppe, G. (2020). Likelihood-free mcmc with amortized approximate
ratio estimators. In International Conference on Machine Learning, pages 4239–4248. PMLR.

11

Lueckmann, J.-M., Goncalves, P. J., Bassetto, G., Öcal, K., Nonnenmacher, M., and Macke, J. H.
(2017). Flexible statistical inference for mechanistic models of neural dynamics. Advances in
Neural Information Processing Systems, 30.

Mardia, K., Kent, J., and Bibby, J. (1979). Multivariate analysis. Probability and mathematical

statistics. Acad. Press, London.

Muandet, K., Fukumizu, K., Sriperumbudur, B., and Schölkopf, B. (2017). Kernel Mean Embedding
of Distributions: A Review and Beyond. Foundations and Trends® in Machine Learning, 10(1-
2):1–141.

Murphy, K. (2007). Conjugate Bayesian analysis of the Gaussian distribution.

Nowak, W. and Guthke, A. (2016). Entropy-based experimental design for optimal model discrimina-

tion in the geosciences. Entropy, 18(11):409–434.

Papamakarios, G., Sterratt, D., and Murray, I. (2019). Sequential neural likelihood: Fast likelihood-
free inference with autoregressive ﬂows. In The 22nd International Conference on Artiﬁcial
Intelligence and Statistics, pages 837–848. PMLR.

Radev, S. T., D’Alessandro, M., Mertens, U. K., Voss, A., Köthe, U., and Bürkner, P.-C. (2021a).
Amortized bayesian model comparison with evidential deep learning. IEEE Transactions on
Neural Networks and Learning Systems.

Radev, S. T., Graw, F., Chen, S., Mutters, N. T., Eichel, V. M., Bärnighausen, T., and Köthe, U.
(2021b). OutbreakFlow: Model-based Bayesian inference of disease outbreak dynamics with
invertible neural networks and its application to the COVID-19 pandemics in Germany. PLOS
Computational Biology, 17(10):e1009472.

Radev, S. T., Mertens, U. K., Voss, A., Ardizzone, L., and Köthe, U. (2020a). BayesFlow: Learning
complex stochastic models with invertible neural networks. IEEE Transactions on Neural Networks
and Learning Systems.

Radev, S. T., Voss, A., Wieschen, E. M., and Buerkner, P.-C. (2020b). Amortized Bayesian Inference

for Models of Cognition.

Ratcliff, R. and McKoon, G. (2008). The Diffusion Decision Model: Theory and Data for Two-Choice

Decision Tasks. Neural Computation, 20(4):873–922.

Schöniger, A., Illman, W. A., Wöhling, T., and Nowak, W. (2015). Finding the right balance between
groundwater model complexity and experimental effort via Bayesian model selection. Journal of
Hydrology, 531:96–110.

Shiono, T. (2021). Estimation of agent-based models using Bayesian deep learning approach of

BayesFlow. Journal of Economic Dynamics and Control, 125:104082.

Stan Development Team (2018). The Stan Core Library. Version 2.18.0.

Stine, R. (1989). An Introduction to Bootstrap Methods. Sociological Methods & Research, 18(2-

3):243–291.

Thomas, O. and Corander, J. (2019). Diagnosing model misspeciﬁcation and performing generalized

Bayes’ updates via probabilistic classiﬁers. arXiv preprint arXiv:1912.05810.

Tolstikhin, I., Bousquet, O., Gelly, S., and Schoelkopf, B. (2017). Wasserstein auto-encoders.

Wiqvist, S., Frellsen, J., and Picchini, U. (2021). Sequential Neural Posterior and Likelihood

Approximation. arXiv preprint arXiv:2102.06522.

Zhang, F. and Gao, C. (2020). Convergence rates of variational posterior distributions. The Annals of

Statistics, 48(4).

12

A Theoretical implications of the method

hψ∗ , fφ∗ ,
{
posterior p(θ
p
minimizer of

(cid:0)

Attaining the global minimum of Eq. 7 with an arbitrarily expressive BayesFlow architecture
implies that i) the inference and summary network jointly amortize the correct
M}
x,
) into a unit Gaussian
|
0, I). According to (i), the set of inference network parameters φ∗ is a
zx = hψ∗ (x)

) and ii) the summary network transforms p(x

M
=

| M

(zx

N

|

(cid:1)

φ∗ = argmin

φ

Ep(zx)Ep(θ | zx)

log qφ

θ

zx

,

(9)

−

|

(cid:1)(cid:105)
(cid:104)
(cid:0)
> 0 implies MMD2

(cid:3)

(cid:2)

(cid:3)

(cid:2)

||

||

G

G

p(x

p(x

| M

p(zx)

p(zx)

po(x)

)
| M

po(hψ∗ (x))

(cid:2)
po(hψ∗ (x))

||
). Accordingly, MMD2

while (ii) ensures that MMD2
p(zx)
> 0,
since a deviation of po(hψ∗ (x)) from a unit Gaussian implies that the summary network is no
(cid:3)
longer transforming samples from p(x
> 0 no
longer guarantees that the inference network parameters φ∗ are globally optimal. The preceding
argumentation also motivates our augmented objective, since a divergence of po(hψ(x)) from a unit
Gaussian signalizes a deﬁciency in the assumed generative model
and a need to revise the generative
model. We also hypothesize and show empirically that we can successfully detect simulation gaps in
practice even when convergence of the summary network outputs to a unit Gaussian is not strictly
optimal (e. g., in the presence of correlations, cf. Experiment 2 and Appendix E).
However, the converse will not hold true in general, in other words, MMD2
po(x)
> 0
does not generally imply MMD2
> 0. To show this via a counter-example,
(µ, σ2 = 2), x2
consider the generative model
∼
δ(0) for N = 2 observations and a single-output summary network, S = 1. Then, an optimal
summary network outputs the minimal sufﬁcient summary statistic hψ∗ (x1, x2) = ¯x
(x1 + x2)/2.
Thus, p(x1, x2
(0, 1), since Var(¯x) = Var((x1 +
0, 2) and p(¯x) =
|
x2)/2) = (Var(x1) + Var(x2))/22 = 1, which implies MMD2

po(hψ(x))
||
deﬁned by x1
(cid:2)

|| N
Now, suppose that the real data are actually generated by a different process given by x1
δ(0). Clearly, po(x1, x2) =
1), and x2
∼
po(x)
p(x
p(x1, x2
(0, 1) such that MMD2
above, we ﬁnd that po(¯x) =
(cid:2)
N
fact that the assumed generative model is misspeciﬁed.
(cid:2)

(µ, σ2 =
(cid:3)
∼ N
=
0, 3)
(x2
|
> 0. However, using the same calculations as
= 0, despite the

∼ N
) and so MMD2

(cid:3)
(µ, σ2 = 2), µ

N
p(hψ∗ (x1, x2))

po(hψ∗ (x1, x2))

(µ, σ2 = 3), µ

(cid:2)
∼ N

The above example also shows that learning minimal sufﬁcient summary statistics might not be
optimal for detecting simulation gaps. On the other hand, increasing the output dimensions of the
summary network S would enable the network to learn structurally richer (overcomplete) sufﬁcient
summary statistics. The latter would be invariant to fewer misspeciﬁcations and thus more useful for
uncovering simulation gaps. In the above example, an overcomplete summary network with S = 2
which simply copies and scales the two variables by their corresponding variances is able to detect
the misspeciﬁcation. Next, we describe how to detect simulation gaps during inference using ﬁnite
realizations from

and po.

)
| M

)
| M

(cid:3)
∼ N

(0, 1)

(0, 1)

× N

= 0.

0, 2)

0, 1)

× N

| M

| M

|| N

) =

(x1

(x1

(x2

N

N

≡

||

||

(cid:3)

(cid:2)

(cid:3)

|

|

G

13

(cid:54)
B Multivariate normal distribution: overcomplete summary statistics

Figure B.1 illustrates how prior misspeciﬁcations with respect to the simulator and noise are only
detectable with overcomplete learned summary statistics. Figure B.2 shows the latent summary space
when overcomplete summary statistics (S = 4) are used in Experiment 1 to recover the means of
a 2
dimensional normal distribution. Model misspeciﬁcation with respect to both simulator and
noise is detectable through anomalies in the latent summary space. Note that a network with S = 2
summary statistics and otherwise equivalent architecture could not capture these types of model
misspeciﬁcation.

−

(a) Minimal sufﬁcient statistics: no MMS detection

(b) Overcomplete sufﬁcient statistics: MMS detection
possible

Figure B.1: (cid:92)rMMD as a function of simulator and noise misspeciﬁcation. While the minimal summary
network yields essentially equal MMD estimates across the grid, the overcomplete summary network
captures model misspeciﬁcations in both simulator and noise.

Figure B.2: Pairplot of 10 000 latent summary space samples from the overcomplete summary
network. Both noise (orange) and simulator (pink) misspeciﬁcations are distinguishable from the
typical latent generative space (blue).

14

0.00.20.40.60.81.0λ(noisefraction)05101520τ(scalefactorofΣ)drMMD0.00.51.01.52.02.53.00.00.20.40.60.81.0λ(noisefraction)05101520τ(scalefactorofΣ)drMMD0.00.51.01.52.02.53.0NoMMSSimulatorscale:τ=10Noisefraction:λ=0.5−505s1−505s2−505s3NoMMSSimulator:τ=10Noise:λ=0.5−505s1−505s4−505s2−505s3−505s4C Replication of Experiment 1 with SNPE-C

In the following, we show the results of repeating Experiment 1 with SNPE-C (APT; Greenberg
et al., 2019) instead of BayesFlow for posterior inference. The results with respect to detection of
simulation gaps are largely equivalent to those obtained with the BayesFlow framework.

Figure C.1: In SNPE-C with learned summary statistics, prior misspeciﬁcation can be reliably
detected with a minimal sufﬁcient summary network (S = D = 2) as well.
Left: Pairplot of 10 000 summary space samples. All prior misspeciﬁcations are distinguishable from
the typical latent generative space (blue).
Right: (cid:92)rMMD as a function of µ0 (prior location) and τ0 (scale factor in the mean prior). The
MMD estimate increases as the simulation gap gets more severe. Colored dots correspond to the
misspeciﬁed model conﬁguration in the pairplot.

(a) Minimal sufﬁcient statistics: no MMS detection

(b) Overcomplete sufﬁcient statistics: MMS detection
possible

Figure C.2: SNPE-C, (cid:92)rMMD as a function of simulator and noise misspeciﬁcation. While the
minimal summary network yields essentially equal MMD estimates across the grid, the overcomplete
summary network captures model misspeciﬁcations in both simulator and noise.

15

−10010s1−10010s1−10010s2−10010s2−505µ012345τ0(scalefactorofΣ0)0.51.01.52.02.53.03.5NoMMSPriorlocation:µ0=5Priorscale:τ0=2.5Priorlocationandscale:µ0=5,τ0=2.50.00.20.40.60.81.0λ(noisefraction)05101520τ(scalefactorofΣ)0.00.51.01.52.02.53.00.00.20.40.60.81.0λ(noisefraction)05101520τ(scalefactorofΣ)0.00.51.01.52.02.53.0NoMMSSimulatorscale:τ=10Noisefraction:λ=0.5Figure C.3: SNPE-C, Pairplot of 10 000 latent summary space samples from the overcomplete
summary network. Both noise (orange) and simulator (pink) misspeciﬁcations are distinguishable
from the typical latent generative space (blue).

16

−10−50510s1−10−50510s2−10−50510s3−10010s1−10−50510s4−10010s2−10010s3−10010s4NoMMSPriorlocation:µ0=5Priorscale:τ0=2.5Priorlocationandscale:µ0=5,τ0=2.5D Experiment: multivariate normal distribution, mean and full covariance

recovery

As an extension to Experiment 1, we investigate the fully extended multivariate normal scenario
where the mean and full covariance matrix need to be estimated. The mean vector and covariance
−1 (Barnard
matrix are drawn from a joint prior, namely a normal-inverse-Wishart distribution (N-
µ0, λ0, Ψ0, ν0) implies a hierarchical
et al., 2000)). The normal-inverse-Wishart prior N-
prior. Suppose the covariance matrix

−1(µ, Σ

W

W

|

has an inverse Wishart distribution and the mean vector

Σ

−1(Σ

|

∼ W

Ψ0, ν0)

(10)

|
has a multivariate normal distribution, then the tuple (µ, Σ) has a normal-inverse-Wishart distribution:

∼ N

µ

(µ

µ0,

Σ)

1
λ0

(µ, Σ)
Finally, the likelihood is Gaussian:

N-

W

∼

−1(µ, Σ

|

µ0, λ0, Ψ0, ν0)

xk

(µ, Σ)

for k = 1, . . . , K

∼ N

We apply the BayesFlow method to recover the posterior mean and covariance of a multivariate
normal distribution (MVN). For a D
variate Gaussian with random means and random covariance,
BayesFlow needs to learn 1 + . . . + D covariances and D means. We set the number of summary
statistics to S = 40, equal to twice the sufﬁcient size for the 5
variate Gaussian. For a multi-
variate Gaussian with unknown mean and unknown covariance matrix, the analytic joint posterior
p(µp, Σp

K
k=1) has a closed form, following a normal-inverse Wishart distribution again:

xk

−

−

| {
(µp, Σp

}
xk

| {

K
k=1)
}

∼
µK =

−1(µp, Σp

W

N-
λ0µ0 + K ¯x
λ0 + K

µK, λK, ΨK, νK) with

|

λK = λ0 + K
νK = ν0 + K

K

ΨK = Ψ0 +

(xk

k=1
(cid:88)
The marginal posteriors for µp and Σp then follow as (Murphy, 2007):

¯x)(xk

¯x)T +

−

−

λ0K
λ0 + K

(¯x

µ0)(¯x

µ0)T

−

−

(11)

(12)

(13)

(14)

(15)

µp ∼
Σp

tνK −D−1

µp

µK,

−1(Σp

(cid:16)
|

(cid:12)
ΨK, νK)
(cid:12)
(cid:12)

∼ W

Ψ−1
K

λK(νK

D + 1)

−

(cid:17)

The model
M
are outlined in Table 3.

∗ used for training the networks as well as the types of induced model misspeciﬁcations

Table 3: Investigated model misspeciﬁcations (MMS) for the 5
estimated covariance matrix. A sample from the noise model
a fraction λ
∈
is rescaled to

[0, 1] of the Gaussian data x and replacing it with samples from η
3σx in order to match the data’s scale.

dimensional Gaussian with fully
N is simulated by randomly choosing
Beta(2, 5) which

M

−

∼

±
Model (MMS)
∗ (No MMS)
P (Prior)
S (Simulator)
N (Noise)

M
M
M
M

Prior
µ, Σ
µ, Σ
(cid:1)
µ, Σ
(cid:1)
µ, Σ
(cid:1)
(cid:1)

(cid:0)
(cid:0)
(cid:0)
(cid:0)

Likelihood
xk
= 0, λ0 = 5, Ψ = τ0I, ν = 10) xk
xk
xk

−1(µ0 = 0, λ0 = 5, Ψ = I, ν = 10)
−1(µ0 (cid:54)
−1(µ0 = 0, λ0 = 5, Ψ = I, ν = 10)
−1(µ0 = 0, λ0 = 5, Ψ = I, ν = 10)

(µ, Σ)
(µ, Σ)
tdf(µ, Σ),
λ

∼ N
∼ N
∼
∼

·

N-
N-
N-
N-

W
W
W
W

∼
∼
∼
∼

N>0

df

∈

Beta(2, 5) + (1

λ)

−

· N

(µ, Σ)

In the evaluation, we compare the means of BayesFlow’s predicted posterior samples with the ﬁrst
moment of the respective marginal analytic posterior from Equation 15. We evaluate correlation

17

(a) Prior misspeciﬁcation is detectable

(b) Simulator and noise misspeciﬁcation are detectable

Figure D.1: (cid:92)rMMD as a function of model misspeciﬁcation with respect to the prior (left) as well as
simulator and noise (right). All induced model misspeciﬁcations are detectable through the proposed
detection criterion.

matrices with standard deviations on the diagonal. For the t distributed posterior mean and inverse-
Wishart distributed posterior covariance, we obtain (Mardia et al., 1979):

E(µp) = µK

E(Σp) =

νK

ΨK
D

−

−

1

(16)

The converged BayesFlow network can recover the analytic posterior means as well as standard
deviations and the correlation structure when no model misspeciﬁcation is present. The performance
decreases when model misspeciﬁcation occurs. Since the summary space comprises S = 40
dimensions, visual inspection is no longer feasible. In the following, we inspect the effect of different
degrees of model misspeciﬁcation on the proposed (cid:92)rMMD criterion (see Figure D.1). Both induced
prior misspeciﬁcations are detectable through an increased (cid:92)rMMD. Model misspeciﬁcations through
a heavy-tailed likelihood function (i. e., df = 2 in the context of a Student-t distribution) in the
simulator are detectable as well. Increasing mixture weight λ of the Beta noise variate η leads to
increased MMD values, rendering the investigated noise misspeciﬁcations detectable.

18

−505µ012345τ0(scalefactorofΨ0)drMMD0.51.01.52.02.53.03.50.00.20.40.60.81.0λ(noisefraction)21020simulatordfdrMMD0.00.51.01.52.02.5(a) MVN full: No misspeciﬁcation

(b) MVN full: Prior misspeciﬁcation µ0 = 2, τ0 =
1.5

(c) MVN full: Simulator misspeciﬁcation, df = 2

(d) MVN full: Noise misspeciﬁcation, λ = 0.5

Figure D.2: MVN full covariance: Performance in recovering the means and covariance matrix under
model misspeciﬁcation

19

−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.010µ1−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.016µ2−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.021µ3−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.011µ4−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.009µ50.250.500.751.00Estimated0.20.40.60.81.0TrueNRMSE=0.024σ1−0.50.00.51.0Estimated−0.50.00.51.0TrueNRMSE=0.044cor210.51.01.5Estimated0.51.01.5TrueNRMSE=0.018σ2−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.048cor31−0.50.00.51.0Estimated−0.50.00.51.0TrueNRMSE=0.064cor320.51.0Estimated0.250.500.751.00TrueNRMSE=0.023σ3−10Estimated−1.0−0.50.00.5TrueNRMSE=0.042cor41−1.0−0.50.00.5Estimated−1.0−0.50.00.5TrueNRMSE=0.047cor42−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.044cor430.51.01.52.0Estimated0.51.01.52.0TrueNRMSE=0.010σ4−0.50.00.51.0Estimated−0.50.00.51.0TrueNRMSE=0.046cor51−0.50.00.51.0Estimated−0.50.00.51.0TrueNRMSE=0.069cor52−0.50.00.51.0Estimated−0.50.00.51.0TrueNRMSE=0.036cor53−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.053cor540.51.01.5Estimated0.51.01.5TrueNRMSE=0.022σ5123Estimated1.01.52.02.53.0TrueNRMSE=0.119µ1123Estimated1.01.52.02.53.0TrueNRMSE=0.052µ224Estimated1234TrueNRMSE=0.118µ312Estimated1.01.52.02.5TrueNRMSE=0.181µ41234Estimated1234TrueNRMSE=0.035µ50.751.001.251.50Estimated0.81.01.21.4TrueNRMSE=0.348σ10.00.5Estimated0.00.5TrueNRMSE=0.234cor211.01.52.02.5Estimated1.01.52.02.5TrueNRMSE=0.135σ20.00.51.0Estimated0.00.51.0TrueNRMSE=0.336cor310.00.51.0Estimated0.00.51.0TrueNRMSE=0.213cor321.01.52.0Estimated1.01.52.0TrueNRMSE=0.233σ30.00.51.0Estimated0.00.51.0TrueNRMSE=0.277cor410.00.51.0Estimated0.00.51.0TrueNRMSE=0.244cor420.00.51.01.5Estimated0.00.51.01.5TrueNRMSE=0.341cor430.51.01.5Estimated0.51.01.5TrueNRMSE=0.850σ4−0.50.00.51.0Estimated−0.50.00.51.0TrueNRMSE=0.224cor51−0.50.00.51.0Estimated−0.50.00.51.0TrueNRMSE=0.239cor5201Estimated−0.50.00.51.01.5TrueNRMSE=0.377cor53−0.50.00.51.0Estimated−0.50.00.51.0TrueNRMSE=0.403cor541.01.5Estimated0.751.001.251.501.75TrueNRMSE=0.376σ501Estimated0.00.51.01.5TrueNRMSE=0.040µ1012Estimated0.00.51.01.52.0TrueNRMSE=0.040µ2012Estimated0.00.51.01.52.0TrueNRMSE=0.036µ312Estimated0.51.01.52.0TrueNRMSE=0.045µ4012Estimated0.00.51.01.52.0TrueNRMSE=0.028µ52.55.07.5Estimated2468TrueNRMSE=0.103σ1−101Estimated−1.0−0.50.00.51.0TrueNRMSE=0.110cor21246Estimated246TrueNRMSE=0.110σ2−101Estimated−1.0−0.50.00.51.0TrueNRMSE=0.114cor31−0.50.00.51.0Estimated−0.50.00.51.0TrueNRMSE=0.133cor32246Estimated246TrueNRMSE=0.126σ3−101Estimated−1.0−0.50.00.51.0TrueNRMSE=0.107cor41−101Estimated−1.0−0.50.00.51.0TrueNRMSE=0.113cor42−101Estimated−1.0−0.50.00.51.0TrueNRMSE=0.111cor43510Estimated2.55.07.510.0TrueNRMSE=0.094σ4−10Estimated−1.0−0.50.00.5TrueNRMSE=0.114cor51−101Estimated−1.0−0.50.00.51.0TrueNRMSE=0.132cor52−101Estimated−1.0−0.50.00.51.0TrueNRMSE=0.131cor53−101Estimated−1.0−0.50.00.51.0TrueNRMSE=0.105cor54051015Estimated051015TrueNRMSE=0.095σ5−0.250.000.25Estimated−0.4−0.20.00.2TrueNRMSE=0.017µ1−0.20.00.2Estimated−0.20.00.2TrueNRMSE=0.038µ2−0.20.00.20.4Estimated−0.20.00.20.4TrueNRMSE=0.044µ3−0.20.00.2Estimated−0.20.00.2TrueNRMSE=0.017µ4−0.250.000.250.50Estimated−0.4−0.20.00.20.4TrueNRMSE=0.017µ50.40.60.8Estimated0.40.60.8TrueNRMSE=0.028σ1−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.031cor210.40.60.8Estimated0.40.60.8TrueNRMSE=0.025σ2−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.022cor31−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.048cor320.500.751.001.25Estimated0.40.60.81.01.2TrueNRMSE=0.017σ3−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.028cor41−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.024cor42−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.021cor430.500.751.00Estimated0.40.60.81.01.2TrueNRMSE=0.016σ4−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.026cor51−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.060cor52−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.034cor53−0.50.00.5Estimated−0.50.00.5TrueNRMSE=0.020cor540.500.751.00Estimated0.40.60.81.01.2TrueNRMSE=0.025σ5E Experiment: drift diffusion model

Aims. This experiment aims to i) apply the new optimization objective to a complex model of
decision making; ii) illustrate the effect of dimensionality reduction (principal component analysis);
iii) tackle strategies to determine the required number of learned summary statistics in more complex
applications; iv) compare the posterior estimation of BayesFlow under a misspeciﬁed model with
the estimation provided by the Stan implementation of HMC-MCMC (Carpenter et al., 2017; Stan
Development Team, 2018) as a current gold-standard for Bayesian inference.

Setup. We focus on the drift diffusion model (DDM) – a cognitive model describing reaction times
(RTs) in binary decision tasks (Ratcliff and McKoon, 2008) which is well amenable to amortized
inference (Radev et al., 2020b). The DDM assumes that perceptual information for a choice alternative
accumulates continuously according to a Wiener diffusion process. Thus, the change in information
dxj in experimental condition j follows a random walk with drift and Gaussian noise:

dxj = vdt + ξ√dt with ξ

(0, 1)

∼ N

(17)

Our model implementation assumes ﬁve free parameters θ = (v1, v2, a1, a2, t0) which produce
2-dimensional data stemming from two simulated conditions. The starting point of the evidence
accumulation process is unbiased, xt=0 = a

2 . During training, the parameter priors are:

v1, v2
a1, a2
t0

∼
∼
∼

Γ(5, 0.5)
Γ(5, 0.5)
Γ(5, 0.5)

(18)

−

The summary network is a permutation-invariant network which reduces i. i. d. RT data sets to
10
dimensional vectors. We realize a simulation gap by simulating typically observed contaminants:
fast guesses (e. g., due to inattention), very slow responses (e. g., due to mind wandering), or a
combination of the two. Accordingly, we ﬁrst generate uncontaminated data x∗ from the well-
[0, 1] of the data x∗. Third,
speciﬁed generative model. Second, we randomly choose a fraction λ
we replace this data fraction with contaminants ξo whose distribution depends on the quantiles of the
uncontaminated data5:

∈

Fast guesses:

Slow responses:

ξo
ξo

0.1, Q10(x∗)
Q75(x∗), 10

(cid:1)

(19)

For the comparison with Stan, we simulate 100 uncontaminated DDM data sets and three scenarios
(fast guesses, slow responses, fast and slow combined) with a fraction of λ = 0.1 contaminants.

(cid:1)

∼ U

∼ U

(cid:0)

(cid:0)

Results. During inference, our criterion reliably detects the induced misspeciﬁcations: Increasing
fractions λ of contaminants (fast, slow, and combined) manifest themselves in increasing MMD
N
values (see Figure E.1a). The results of applying PCA to the summary network outputs
n=1
for the well-speciﬁed model (no contamination) are illustrated in Figure E.1b. We observe that the
ﬁrst ﬁve principal components exhibit a large overlap with the true model parameters θ and jointly
account for 85% of the variance in the summary output. Furthermore, the drift rates and decision
thresholds within conditions are entangled (i. e., v1, a1 and v2, a2). This entanglement mimics the
strong posterior correlations observed between these two parameters. In practical applications,
dimensionality reduction might act as a guideline for determining the number of minimally sufﬁcient
summary statistics or parameter redundancies for a given problem.

˜z(n)
xobs }
{

For the comparison with Stan, we juxtapose 4 000 samples from the neural network’s approximate
posterior qφ with 4 000 samples obtained from the Stan sampler after ensuring MCMC convergence
and sufﬁcient sampling efﬁciency for each data set in each simulated scenario (see Figure E.2 for
an illustration). Because Stan is currently considered state-of-the-art for likelihood-based Bayesian

5Qk(x∗) denotes the kth percentile of x∗. The asymmetry in percentiles between fast and slow responses
arises from the inherent positive skewness of reaction time distributions. The ﬁxed upper limit of slow response
contamination is motivated by the maximum number of iterations of the utilized diffusion model simulator.
The contamination procedure is executed separately for each condition and response type. If an experiment
features both fast and slow contamination, the fraction λ is equally split between fast and slow contamination.
The uncontaminated data set is generated once and acts as a baseline for all analyses of an experiment, resulting
in a baseline MMD of 0 since x∗ is unaltered if λ = 0.

20

(a) rMMD estimate by degree of con-
tamination. Dashed lines represent the
respective parameter value in the well-
speciﬁed model without contamination,
namely λslow = λfast = 0.

(b) Correlation between model parameters θ and principal compo-
nents (PCs). The cumulative explained variance ratio w. r. t. the
summary network outputs {˜z(n)
xobs }N

n=1 is denoted as (cid:80) R2.

Figure E.1: Results of the Drift Diffusion Model experiment.

Table 4: Posterior error as the estimated rMMD (median and 95% conﬁdence interval) between
samples from BayesFlow’s approximate posterior qφ and samples from the Stan sampler. The boot-
strapped rMMD values (median and 95% conﬁdence interval) for the summary space representation
of the 100 investigated data sets and 1 000 samples from the uncontaminated model illustrate that
posterior errors are mirrored by anomalies in the neural network’s summary space and thus detectable.

Model (Contamination)
Uncontaminated
Fast contaminants
Slow contaminants
Fast and slow contaminants

Posterior error (cid:92)rMMD Summary space (cid:92)rMMD

0.25 [0.13, 0.56]
2.66 [1.44, 3.40]
0.55 [0.23, 1.01]
1.90 [0.83, 3.18]

0.45 [0.42, 0.52]
2.68 [2.61, 2.74]
1.18 [1.13, 1.26]
2.33 [2.19, 2.43]

inference, we assume the Stan samples are representative of the true posterior and compute the
average rMMD estimate between the BayesFlow and Stan posterior estimates. Under no model
misspeciﬁcation, the posterior samples from BayesFlow and Stan match almost perfectly (see
Figure E.2a). In contrast, the results in Figure E.2b and Table 4 clearly indicate that the amortized
BayesFlow posteriors deteriorate as a result of the induced misspeciﬁcation. Moreover, these
results closely mirror the overall detectability of misspeciﬁcation obtained by matching the summary
representations of 1000 data sets from the uncontaminated process with the representations of the
100 data sets for each of the above scenarios via rMMD (see Table 4).

21

0.000.050.10λslow0.00.10.20.30.40.5λfastdrMMD0123(a) No contamination, the approximate posteriors
between Stan and BayesFlow are essentially equal,
(cid:92)rMMD = 0.034

(b) Slow contamination (λ = 10%), the approxi-
mate posteriors between Stan and BayesFlow differ
by (cid:92)rMMD = 0.854

Figure E.2: Example comparison of the approximate posteriors from Stan and BayesFlow for an
uncontaminated data set (left) as well as the contaminated version of the same data set (right; slow
contamination).

22

1.01.52.02.53.0v1468v223a112345a2123v11.81.9t02.55.07.5v223a124a21.81.9t00.51.01.5v11.01.52.02.5v2234a11.52.02.53.0a20.51.01.5v11.51.61.71.8t012v2234a123a21.61.8t0StanBayesFlowF Details of Experiment 2 (COVID-19 time series)

Bootstrapping procedure

∗ and an
Mobs. Since simulating time series from the compartmental models is time-

In Experiment 2, we estimate a sampling distribution of (cid:92)rMMD between samples from
observational model
consuming, we opt for bootstrapping (Stine, 1989) on 1 000 pre-simulated time series
x(j)
from
obs}
{
x∗(i)
we draw 1 000 samples (with replacement) from
{
x(j)
replacement) from
obs}
{

Mobs. In each bootstrapping iteration,
1, 2, 5
samples (with
}

j=1 and calculate (cid:92)rMMD between the sets of bootstrap samples.

1000
j=1 from
1000
i=1 as well as N

∗ and 1 000 pre-simulated time series

M
x∗(i)
{

1000
i=1
}

∈ {

M

1000

}

Sampling distribution of MMD under the null hypothesis

Figure F.1: Representation of Germany’s COVID-19 time series with respect to the MMD distribution
∗).
under the null hypothesis H0 : po(x) = p(x

| M

23

3.603.653.703.753.803.853.903.95drMMDGermanydataH05%rejectionareaG Performance under model misspeciﬁcation

(a) MVN: no misspeciﬁcation

(b) MVN: Prior misspeciﬁcation µ0 =
5, τ0 = 2.5

(c) MVN: Simulator misspeciﬁcation τ =
10.0

(d) MVN: Noise misspeciﬁcation, λ = 0.5

Figure G.1: Multivariate Normal Distributions: Performance in recovering the means (Experiment
1)

24

−202Estimated−202TrueNRMSE=0.003µ1−202−202NRMSE=0.006µ20510Estimated0.02.55.07.510.012.5TrueNRMSE=0.031µ1051015051015NRMSE=0.078µ2−202Estimated−202TrueNRMSE=0.011µ1−202−202NRMSE=0.015µ2−101Estimated−101TrueNRMSE=0.007µ1−101−101NRMSE=0.008µ2H COVID: detailed power analysis results

(a) M1, N = 1, 1 − β = .998

(b) M1, N = 2, 1 − β = .958

(c) M1, N = 5, 1 − β ≈ 1.0

(d) M2, N = 1, 1 − β = .789

(e) M2, N = 2, 1 − β = .804

(f) M2, N = 5, 1 − β ≈ 1.0

(g) M3, N = 1, 1 − β = .631

(h) M3, N = 2, 1 − β = .690

(i) M3, N = 5, 1 − β ≈ 1.0

Figure H.1: Detailed illustration of the power analysis in Experiment 2.

25

3.603.653.703.753.803.853.90drMMD2.42.62.83.03.23.4drMMD1.61.82.02.22.42.62.8drMMD3.603.653.703.753.803.853.90drMMD2.42.62.83.03.23.4drMMD1.61.82.02.22.42.62.8drMMD3.603.653.703.753.803.853.90drMMD2.42.62.83.03.23.4drMMD1.61.82.02.22.42.62.8drMMDdrMMDunderH0drMMDunderthe(misspeciﬁed)modelTypeI(α)errorTypeII(β)errorI

Inverse multiquadratic kernel

This appendix shows results of Experiment 1 and Experiment 2 when the sum of Gaussian kernels
in the computation of the Maximum Mean Discrepancy (Equation 4) is replaced by a sum of inverse
multiquadratic kernels.

I.1 Inverse multiquadratic kernel in Experiment 1

Figure I.1: Inverse multiquadratic kernel. Prior misspeciﬁcation can be reliably detected with a
minimal sufﬁcient summary network (S = D = 2).
Left: Pairplot of 10 000 summary space samples. All prior misspeciﬁcations are distinguishable from
the typical latent generative space (blue).
Right: (cid:92)rMMD as a function of µ0 (prior location) and τ0 (scale factor in the mean prior). The
(cid:92)rMMD estimate increases as the simulation gap gets more severe. The colored dots correspond to the
respective misspeciﬁed model conﬁguration in the pairplot.

(a) Prior misspeciﬁcation: Both summary networks
(minimal and overcomplete) detect increasingly severe
misspeciﬁcation through an elevated rMMD and lead
to a higher posterior error (RMSE) of the inference
network.

(b) Noise and simulator misspeciﬁcation: While the
minimal network exhibits poor detection, its posterior
recovery is not impaired either. The overcomplete
network captures increasingly severe misspeciﬁcation
but suffers from an increased posterior error (RMSE).

Figure I.2: Inverse multiquadratic kernel. Posterior error (difference between analytic posterior
means µp and the approximate posterior means µˆθ) as a function of model misspeciﬁcation severity,
as indexed by the (cid:92)rMMD criterion.

26

−10010s1−10010s1−10010s2−10010s2−505µ012345τ0(scalefactorofΣ0)drMMD0.51.01.52.02.53.03.5NoMMSPriorlocation:µ0=5Priorscale:τ0=2.5Priorlocationandscale:µ0=5,τ0=2.5(01)(52.5)PriorMMS(µ0τ0)0.00.20.40.60.8RMSE(µp||µˆθ)minimalovercompletedrMMD0.00.51.01.52.02.53.0(01)(120)NoiseandSimulatorMMS(λτ)0.00.20.40.6RMSE(µp||µˆθ)minimalovercompletedrMMD0.00.51.01.52.02.53.0(a) Minimal sufﬁcient statistics: no MMS detection

(b) Overcomplete sufﬁcient statistics: MMS detection
possible

Figure I.3: Inverse multiquadratic kernel. (cid:92)rMMD as a function of simulator and noise misspeciﬁcation.
While the minimal summary network yields essentially equal MMD estimates across the grid, the
overcomplete summary network captures model misspeciﬁcations in both simulator and noise.

Figure I.4: Inverse multiquadratic kernel. Pairplot of 10 000 latent summary space samples from
the overcomplete summary network. Both noise (orange) and simulator (pink) misspeciﬁcations are
distinguishable from the typical latent generative space (blue).

27

0.00.20.40.60.81.0λ(noisefraction)05101520τ(scalefactorofΣ)drMMD0.00.51.01.52.02.53.00.00.20.40.60.81.0λ(noisefraction)05101520τ(scalefactorofΣ)drMMD0.00.51.01.52.02.53.0NoMMSSimulatorscale:τ=10Noisefraction:λ=0.5−505s1−505s2−505s3NoMMSSimulator:τ=10Noise:λ=0.5−505s1−505s4−505s2−505s3−505s4I.2 Inverse multiquadratic kernel in Experiment 2

Table 5: Results for different variations of the COVID-19 compartmental model with an inverse
multiquadratic kernel. We report the median and 95% CI of 100 bootstrap samples of (cid:92)rMMD for
each N (see Appendix F for a detailed description of the procedure).

N = 1
3.63 [3.57, 3.74]
3.71 [3.63, 3.75]
3.75 [3.66, 3.78]
3.72 [3.69, 3.76]

Bootstrap (cid:92)rMMD
N = 2
2.56 [2.50, 2.75]
2.86 [2.59, 3.21]
2.75 [2.61, 2.90]
2.77 [2.66, 3.14]

N = 5
1.68 [1.59, 1.95]
2.14 [1.82, 2.49]
1.90 [1.77, 2.03]
2.17 [2.00, 2.40]

Model

∗
M
1
M
2
M
3
M

Power (1

β)

−

N = 1 N = 2 N = 5
—
.989
.903
.612

—
.996
.691
.334

—
1.0
1.0
1.0

≈
≈
≈

Figure I.5: Inverse multiquadratic kernel. Representation of the Germany COVID-19 time series with
respect to the distribution of (cid:92)rMMD under H0.

28

3.53.63.73.83.9drMMDGermanydataH05%rejectionarea(a) M1, N = 1, 1 − β = .996

(b) M1, N = 2, 1 − β = .989

(c) M1, N = 5, 1 − β ≈ 1.0

(d) M2, N = 1, 1 − β = .691

(e) M2, N = 2, 1 − β = .903

(f) M2, N = 5, 1 − β ≈ 1.0

(g) M3, N = 1, 1 − β = .334

(h) M3, N = 2, 1 − β = .612

(i) M3, N = 5, 1 − β ≈ 1.0

Figure I.6: Inverse multiquadratic kernel. Detailed illustration of the power analysis in Experiment 2

29

3.503.553.603.653.703.753.803.85drMMD2.42.52.62.72.82.93.03.13.2drMMD1.61.82.02.22.4drMMD3.503.553.603.653.703.753.803.85drMMD2.42.52.62.72.82.93.03.13.2drMMD1.61.82.02.22.4drMMD3.503.553.603.653.703.753.803.85drMMD2.42.52.62.72.82.93.03.13.2drMMD1.61.82.02.22.4drMMDdrMMDunderH0drMMDunderthe(misspeciﬁed)modelH0rejectionarea