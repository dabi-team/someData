Deep Ensemble Learning-based Approach to
Real-time Power System State Estimation

Narayan Bhusal*, Raj Mani Shukla**, Mukesh Gautam*, Mohammed Benidris*, and Shamik Sengupta**,
*Department of Electrical and Biomedical Engineering, University of Nevada-Reno, Reno, NV 89557, USA
**Department of Computer Science and Engineering, University of Nevada, Reno, Reno, NV 89557,

1
2
0
2

n
a
J

0
1

]

Y
S
.
s
s
e
e
[

1
v
7
5
4
3
0
.
1
0
1
2
:
v
i
X
r
a

Abstract—Power system state estimation (PSSE) is commonly
formulated as weighted least-square (WLS) algorithm and solved
using iterative methods such as Gauss-Newton methods. However,
iterative methods have become more sensitive to system operating
conditions than ever before due to the deployment of intermittent
renewable energy sources, low carbon technologies (e.g., electric
vehicles), and demand response programs. Appropriate PSSE
approaches are required to avoid pitfalls of the WLS-based PSSE
computations for accurate prediction of operating conditions.
This paper proposes a data-driven real-time PSSE using a deep
ensemble learning algorithm. In the proposed approach, the
ensemble learning setup is formulated with dense residual neural
networks as base-learners and multivariate-linear regressor as
meta-learner. Historical measurements and states are utilised to
train and test the model. The trained model can be used in
real-time to estimate power system states (voltage magnitudes
and phase angles) using real-time measurements. Most of current
data-driven PSSE methods assume the availability of a complete
set of measurements, which may not be the case in real power
system data-acquisition. This paper adopts multivariate linear
regression to forecast system states for instants of missing
measurements to assist the proposed PSSE technique. Case
studies are performed on various IEEE standard benchmark
systems to validate the proposed approach. The results show that
the proposed approach outperforms existing data-driven PSSE
methods techniques.

Index Terms—Deep ensemble learning, multivariate linear
regression, power system state estimation, residual neural net.

NOMENCLATURE

z
x
e
h

H
G
ζ
n
t and ζ δ
ζ v
t

V i
t

δi
t
t and ζ q
ζ p

t

P i
t

measurement vector
state vector
measurement residual vector
nonlinear function, relating state vector to
measurement vector
Jacobian matrix
gain matrix
set of all buses
total number of buses in a power network
set of buses at which voltage magnitude and
phase angle measurements are available at any
instant t, respectively
voltage magnitude measurement at bus i at any
instant t
phase angle measurement at bus i at any instant t
set of buses at which real and reactive power
measurements are available at any instant t,
respectively
real power injection measurement at bus i at any
instant t

t and £q

Qi
t

£
£p

P ii(cid:48)
t

Qii(cid:48)
t

reactive power injection measurement at bus i at
any instant t
total number of branches in a power network
t set of branches at which real and reactive power
ﬂow measurements are available at any instant t,
respectively
real power ﬂow measurement from line i to i(cid:48) at
any instant t
reactive power ﬂow measurement from line i to i(cid:48)
at any instant t

I. INTRODUCTION

is

used

(PSSE)

injections

to
Power System State Estimation
provide real-time database for control and monitoring
systems of power grids and to assist system operators
in making well-informed remedial action decisions
in
case of contingencies. PSSE techniques use power system
measurements like line ﬂows, nodal voltages (magnitude
and phase angle), and nodal
(obtained from
supervisory control and data acquisition (SCADA) system),
to estimate power system states such as voltage magnitudes
and phase angles at system nodes. PSSE is a non-convex
problem generally formulated based on weighted least square
(WLS) methods and solved using iterative methods such
these methods are
as Gauss-Newton methods. However,
sensitive to system operating conditions and uncertainties.
Also,
intermittent
(e.g., photovoltaic and wind
renewable energy sources
low carbon
system-dependent
power generation), power
technologies
(e.g., electric vehicles), and load demand
in modern power grids has led to frequent and sizeable
voltage ﬂuctuations. Furthermore, disparate cyber-attacks
and natural events exacerbate the operation and control of
power systems [1], [2]. The aforementioned unpredictable
behaviour of power grids makes conventional solutions for
PSSE, like WLS-based methods, computationally expensive
and sub-optimal. Therefore,
to develop
computationally efﬁcient and technically feasible alternative
solutions for power system state estimation that address the
above-mentioned uncertainties.

in the deployment of

important

increase

the

is

it

Several model-based methods have been proposed in the
literature to solve the PSSE problem using a number of
statistical criteria. Most commonly used criteria are (a)
maximum likelihood criterion—it maximises the probability
to true values of the
of the estimated states being equal
the
states;
squares of the weighted errors of actual measurements and the

(b) WLS criterion—it minimises the sum of

1

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

 
 
 
 
 
 
estimated measurements; (c) minimum variance criterion—it
minimises the expected value of the sum of squares of
(d)
errors between the true states and estimated states;
least absolute value criterion—it minimises the sum of the
absolute values of the deviations between estimated and
actual measurements [3]–[9]. Other criteria include minimum
mean squared estimator [10], Schweppe Huber generalised
M-estimator, and least-median and least-trimmed square
estimator [11]. However, model-based approaches are sensitive
to initialisation, require several iterations, are computationally
intensive, and produce sub-optimal performance, speciﬁcally
with newly emerging uncertainties and growing system
dynamics.

The development of various machine learning (ML)
approaches has led to the use of big data in potpourri
of complex power system problems, and PSSE is not an
exception [12]–[14]. Data-driven PSSE approaches provide
great ﬂexibility and scalability. They also have the capability to
improve the run-time efﬁciency and accuracy of conventional
state estimation approaches [15].
In [15]–[17], a hybrid
of data-driven and statistical criteria (e.g., WLS and least
absolute value) have been used to estimate power system
states. In the hybrid approach, ML models (neural network
(NN) in [16] and long-short-term-memory (LSTM) in [15])
have been used as a surrogate model
to map available
measurements or historical states in the neighbourhood of the
true latent states. These approximate states have been used as
initialisation for model-based criterion. Numerous model-free
data-driven approaches have also been proposed in literature.
These approaches use historical similar measurements or
simulated measurements and their states for the training,
validation, and testing of the ML models. The trained models
have been used for
real-time state estimation. The ML
approaches such as k-nearest neighbour in [18], LSTM in
[19], physics-inspired unrolled deep neural network (DNN)
[20], auto-associated neural network [21], physics-aware NN
[22], deep recurrent neural network [23], and deep generative
adversary network [24], to name a few, have been used for
PSSE. A comparison between the proposed approaches with
some of these approaches is provided in the case studies.

The aforementioned data-driven approaches provide rich
literature on PSSE and contribute toward the development of
resilient future power grids. However, shallow neural network
models suffer from scalability and computational inefﬁciencies
[25]. Furthermore, due to the stochastic nature of DNN, they
are sensitive to a speciﬁc set of training data, which in turn
results in different predictions—different sets of weights may
be obtained every single time they are trained. In other words,
the stochastic nature of DNN poses high variance and makes
the development of ﬁnal prediction models difﬁcult.

This paper proposes a data-driven real-time PSSE model
using deep ensemble learning method. Actual historical data
(obtained from SCADA) and simulation-derived data (sampled
snapshots using MATPOWER) are utilised to train several
parallel dense Residual Neural Networks (ResNetD). The
ResNetD captures the nonlinear relationship between input
measurements and output states. The output states produced by
base-learner ResNetD are very close to actual states and they

capture various features existing between input measurements
and output states. The multivariate linear regression (MLR)
is used to form the ensemble model for estimating the ﬁnal
power system states (voltage magnitudes and phase angles).
The trained ensemble learning model is used to predict power
system states in real-time. During testing phase, additional
Gaussian noise is added in the data to test the robustness of
the proposed approach against measurement errors. During the
implementation of the proposed data-driven PSSE in real-time,
there may be missing measurements that lead to the failure of
the state estimation. To deal with this problem, we adopted the
MLR to forecast missing states at any instant. The accuracy
and efﬁciency of the proposed method against standard ML
methods is validated through comprehensive case studies on
the IEEE 14, 30, 57, 69, and 118 bus benchmark systems.

The major contributions of this paper toward ML-based

state-of-the-art state estimation are summarised as follows.

• Deep neural networks have the capability to map
nonlinear relationships between the input data and the
output because of their nonlinear nature. They provide
great ﬂexibility and scalability with the system size
and amount of available samples. However, deep neural
networks learn through stochastic training algorithms,
which results in high variation in training parameters of
the model. This may make deep neural networks ﬁnd
different sets of weights every time they are trained
and may produce different results. This work proposes
ensemble learning setup to solve the high variance
problem associated with the state-of-the-art deep learning
based state estimation techniques. Ensemble learning
models train multiple models and combine the output
of those models for the ﬁnal prediction which results in
variance reduction. The ensemble learning model not only
reduces the variance in prediction but also its performance
improves in terms of accuracy and efﬁciency if the
models are selected appropriately.

• Motivated by the capability of recently advanced residual
neural net-work architectures [20], [26]–[30] to map
nonlinear relationships between the input and the output
the ResNetD is developed to capture the
variables,
nonlinear relationship existing in the state estimation
problem. Also, the work presented in [31]–[34] for state
forecasting shows that linear models can appropriately
forecast power system states using historical states.
Therefore,
this paper utilises a number of ResNetD
models as base-learners to predict states that act similar
to historical states used for state forecasting approaches.
However, states predicted by ResNetD are much closer
to actual states due to its capability to map the nonlinear
relationship between input measurements and system
states. MLR maps the relationship between the outputs
of the base-learner modes and the actual states to further
improve the overall performance.

The rest of the paper is organised as follows. Section
II presents details on power system state estimation and
problem formulations. Section III describes the proposed deep
ensemble learning setup for PSSE with an algorithm to deal

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

2

with missing measurements. Section IV examines the proposed
approach through numerical case studies. Section V provides
concluding remarks.

II. PSSE PROBLEM FORMULATION
This section brieﬂy discusses the preliminaries and problem
reproduce rigorous
formulation of PSSE. We will not
derivations of the PSSE problem; rather, we will use the
expressions of the PSSE problem to develop the proposed
approach.

A. Preliminaries of PSSE
Given network conﬁguration and parameters and a set of
measurements, z, the AC state estimation determines system
states as follows [35].

z = h (x) + e,

(1)

where
z = [z1, z2, · · · , zm]: set of measurements
x = [x1, x2, · · · , x2n]: vector of state variables
e = [e1, e2, e3, · · · , em]: vector of measurement residuals
h = [h1(x), h2(x), · · · , hm(x)]: nonlinear
system model) relates state vector to the measurement set.

function (i.e.,

Historical real power system measurements and states are
not easily accessible for training and testing of the proposed
data-driven PSSE. Therefore, WLS with Gauss-Newton
method is used to generate training data. WLS-based
optimisation to determine the estimated state vector, ˆx, can
be expressed as follows.
1
2

(z − h (x))T W (z − h (x)) ,

min J(x) =

(2)

where W is the weight vector developed based on the variance
1, σ2
of the measurement errors (σ2
0
1
σ2
2

2, · · · , σ2
m) represented as,
0
· · ·
· · ·
0
. . .
· · ·

1
σ2
1
0
...
0













W =

...
0

(3)





0
1
σ2
m

The minimum value of the optimisation problem (2) can be
computed using a ﬁrst-order optimality condition as follows.

g(x) =

∂J(x)
∂x

= −H T (x)W [z − h(x)] = 0.

(4)

The state vector ˆx in (4) can be solved as the limit of the
sequence of states, ˆxk, by means of Gauss-Newton recursive
scheme; one step of such recursive scheme can be presented
as follows.

ˆxk+1 = ˆxk + G(ˆxk)−1H T (ˆxk)W [z − h(ˆxk)],

(5)

where H and G are, respectively, Jacobian and Gain matrices
and can be expressed as follows.

H( ˆxk) =

(cid:104) ∂h(x)
∂x

(cid:105)

x=ˆxk

,

G(ˆxk) = H T (ˆxk)W H(ˆxk),
n
1

2

n

2

1

(6)

(7)

, ˆδt
where ˆx = [ ˆVt
, ˆVt
state vector—voltage magnitudes, ˆVt
for the ith bus at time t.

, ...., ˆVt

, ˆδt

, ...., ˆδt
] is the estimated
i
i
, and phase angles, ˆδt
,

B. Problem Statement
The problem of data-driven PSSE is to map the available set
of measurements, zt, to the power system state variables, ˆxt.
This problem can be expressed as follows.

ˆxt = f (zt),

(8)

where the set of measurements can be expressed as follows.

zt =

(cid:104)
{|V i

t |}i∈ζv

t

, {δi

t}i∈ζδ

t

{P i

t }i∈ζp

t

,

{Qi

t}i∈ζq

t

, {P ii(cid:48)

t }(i,i)∈£p

t

, {Qii(cid:48)

t }(i,i)∈£q

t

(cid:105)T

t } and {Qi

t buses; {δi

with {|V i
t |} being voltage magnitude measurements at any
instant t that are available in ζ v
t} is phase
angle measurements at any instant t that are available in ζ δ
t
buses; {P i
t} are real and reactive power injection
measurements at any instant t that are available in ζ p
t and ζ q
t
buses, respectively; and {P ii(cid:48)
t } and {Qii(cid:48)
t } respectively, are
at any instant t
power ﬂow measurements from bus i to i
t , ζ q
t and £q
that are available in £p
t , ζ δ
t )∈ ζ with
ζ = {1, 2, · · · , n} being the set of all buses and (£p
t , £q
t ) ∈ £
with £ is total number of branches in a power network.
The function, f , contains weights (w1, w2, w3,

· · · ,
w2n) that map the relationship between input measurements
and output states. The problem is to ﬁnd the weights,
w1, w2, w3, · · · , w2n,
loss between
predicted and actual states.

that reduce the overall

t lines. (ζ v

t , ζ p

(cid:48)

III. THE PROPOSED PSSE METHOD
In the proposed method, an neural network in the ensemble
learning setup is used. Before proceeding further to describe
the proposed model, the functionality and importance of the
ensemble learning in solving the PSSE problem are explained
as follows.

In ensemble learning, multiple machine learning algorithms
are brought out
together to solve the same prediction or
classiﬁcation problem. Subsequently, results from different
methods are collected and combined. Machine learning (ML)
models in the ensemble learning are called base-learners that
weakly predict a certain parameter. These weak learners are
trained to generate a set of hypotheses and subsequently
combined to produce more accurate results. The base-learners
are combined either in a sequential or parallel manner. The
ﬁnal results are obtained using various techniques including,
but not limited to, majority voting, averaging, and weighted
averaging [36].

Traditional ML models suffer from two disadvantages. First,
given a training data set, it is often not possible to ﬁnd the best
ML algorithm due to their black-box nature. Thus, although
data-driven ML models provide superior results over other
models, this performance cannot be explained [37]. In other
words, regardless of how many times these models are tried
(e.g., in a trial and error fashion), users may not be able to
identify the best model. Second, even if the best algorithm
is identiﬁed, the ML model may not provide the optimal
performance for certain sample data as the search process
of disparate ML algorithms is different. Thus, to compensate
is feasible to combine
for the error of some models,
different learners to get optimal performance. The capability

it

3

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

of ensemble learning lies in the fact that the base learners
are diverse in nature. The diversity can be obtained using
different ML models, different training parameters, different
training data sets, and of course, a combination of all of
them [36], [38]. The added diversity enables the models to
correct errors of some members as different learners make
different errors on the same set of inputs. However, careful
attention is needed while forming the variations in models,
datasets, or training parameters. Selection of inappropriate
base-learner models may worsen the performance if
the
majority of selected base-learners capture similar features and
miss a critical feature even if a few other base-model capture
the critical features. Thus, the combination of carefully chosen
different base-learners reduces the overall prediction error.
Hence, ensemble learning is a powerful method to ensure
accurate generalisation capability in a training process.

The major drawback of the ensemble learning is that, as
compared to a single base learner, the model is redundant and
requires more training. However, neural network training is a
one-time ofﬂine process. Thus, ensemble learners provide a
generalised model, but it requires extra training (that is done
a single time). Since the training process is done only once,
it does not pose a problem when a system operates. In the
operating phase, the execution time is still low (operating
phase execution time for the proposed model is provided in
result section) and better than the mathematical model based
state estimators.

A. Attributions of the Proposed Model
This paper has used a stacking ensemble technique to develop
ensemble learning model for PSSE. In the stacking ensemble
the base-learners are combined in parallel. In
technique,
this technique, heterogeneous weak learners learn on the
training data independently. The independent
learners are
combined using a meta-model that provides output based on
the predictions obtained from weak learners [36]. This paper
uses dense residual neural network (ResNetD) model as a
base learner. Before explaining the functionality of ResNetD,
we describe the development of the proposed ResNetD as a
base-learner.

Many architectures of

the neural network have been
proposed in the literature to map the non-linear relationship
between input and output vectors of a given system. This
includes, but not limited to, classical ML techniques (e.g.,
decision tree and k-nearest neighbours regression), multilayer
perceptron (MLP), CNN,
recurrent neural network (e.g.,
LSTM), and hybrid architectures (e.g., CNN-LSTM and
ResNet). Given the aforementioned advantage of ensemble
learning, we leverage ensemble learning setup for PSSE. To
develop an appropriate model of ensemble learning setup
for PSSE, ML models including MLP, CNN, LSTM, and
ResNet are tested as base learners. A number of
these
models individually and in combination are stacked in parallel
to test
their performance with various meta-learners. ML
models, such as MLP, ResNet, k-nearest neighbours, decision
tree, CNN, and MLR, are tested as meta-learner for the
Individually, dense neural
above-mentioned base-learners.
network-based ResNet (ResNetD) architecture appropriately

maps the non-linear relationship between input measurements
and the output state variables than any other approach for our
problem. Development and testing of ResNetD is motivated
from recently advanced residual neural network architectures
[20], [26]–[30] to map nonlinear relationship between the input
and output variables. Also, with above-mentioned models as
meta-learner, ResNetD has produced better result compared
to other architectures. The results produced by the combined
architecture of ResNetD as base-learners are very close to
true states. Authors of [31]–[34] have demonstrated that linear
models can accurately forecast power system states using
historical states. Since results obtained from ResNetD as
base-learners are similar to historical states (but much close to
actual states than historical states because of the capability of
ResNetD to capture the nonlinear relationship) used for state
forecasting approaches, MLR maps these states even closer
to actual states. Therefore, a number of parallel ResNetD as
base-learners and MLR as meta-learner is taken as ensemble
learning setup for the PSSE problem.

B. Residual Neural Network as a Base Learner Model
Residual Neural Network (ResNet) is a type of artiﬁcial neural
network that builds on a structure known from pyramidal
cells in the cerebral cortex. ResNet is formed by skipping
the connections or by jumping over some layers of the feed
forward neural network. Typical ResNet is formed by skipping
two or three layers that contain batch normalisation and a
non-linear function (rectiﬁed linear unit (ReLU)) in between.
These skipped connections are important in “vanishing” and
“exploding” gradient
issues by reusing activation function
from a previous layer until the adjacent layer learns its weights
[26], [39]. Another advantage of skipping layers is that it
simpliﬁes the network and speeds up learning processes as
fewer layers are used in the training.

Inspired by ResNet architecture proposed in [20], [26]–[30],
a ResNetD is developed as shown in Fig. 1 as a base-learner.
One block of the proposed ResNetD architecture is formed by
merging the regular information ﬂow, the output of previous
blocks’ dense layers, and connecting the input through a dense
layer directly (as shown in Fig. 1 with 2 skip neurons in
the regular information ﬂow). The advantage of this approach
is that
improves the information ﬂow and recovers the
missing features. In this paper, Hubber loss is employed as loss
function because of its robustness against outliers [40]. ReLU
is used as an activation function for the proposed ResNetD.

it

C. The Proposed Deep Ensemble Learning Setup
The proposed model uses stack generalisation of the ensemble
learning to predict power system states. The proposed
architecture employs a number of parallel ResNetD as
base-learner and MLR as meta-learner. Although all of the
six ResNetD models used in this paper have the same
architecture, they act like a diverse set of models because
of the stochasticity involved in the model. Therefore, even
though the models are redundant, their outputs will be different
and the differences in their outputs result in the formation of
appropriate base-learners. The architecture of a base-learner,
ResNetD, is provided in Section III-B. Brief description of
MLR is provided in III-D, as it is well-known technique. Fig. 2

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

4

Fig. 1. Architecture of ResNetD with K = 2, where K denotes number of hidden units W , and Z and X represent the input measurement vector and output
state variable vector, respectively.

shows the basic architecture of the proposed PSSE.

It is assumed in the proposed work that similar operating
patterns to current state exist in the historical dataset. Similar
operating patterns do not always mean the same topology. For
large power systems, change of topology at the local level
may not change the electricity generation or consumption in
the local network. Operating points may still be considered
similar to historical points if the local network is considered
as an aggregated node [18]. For the case of topology change at
a higher level in the bulk power system, where the operating
point may change with the change of topology, the proposed
model has to be trained again with the historical dataset of the
changed topology. For the bulk power system, the immediate
training after the topology change may be computationally
challenging and expensive. The frameworks presented in [41],
[42] work with adaptive learning and could be used for the
case of topology change at a higher level in the bulk power
system. However, further detailed analysis is needed to deem
the applicability of approaches presented in [41], [42] in
our proposed work, which is left as a future work. These
assumptions also exist in most of the ML based state-of-the-art
state estimation approaches. Although it has been shown in
[43]–[45] that the forecasting aided state estimator can address
the lack of measurements, measurement errors, grid topology
and link parameters change, the problem of topology change
in the bulk system that changes the operating point still a
challenge.

time delayed,

For normal conditions,

the measurements are missing or

the proposed state estimation
model can accurately predict power system states. If some
the
of
forecasted states obtained from the proposed state forecasting
approach can be utilised to estimate the missing measurements
as pseudo-measurements. Forecasting-aided state estimation
approach can also deal with measurement errors, network
conﬁguration, sudden changes in the network, and change in
network parameters [43]. For a state estimation approach to
be robust, it must be insensitive to major measurements errors
and network topology changes ( [35] chapter 6). Therefore,
the proposed state estimator is robust against local topology
change,
the missing measurements, and the measurement
errors.

The purpose of the PSSE is to estimate voltage magnitudes
and phase angles at all n buses of a power system at any instant
using measurements obtained from various measurement
devices. In practical power systems, measurements can come
from different measurement devices including PMU and
types and locations
SCADA. Also, different measurement
introduce time synchronisation and time skewness issues

5

It can be seen from Fig. 2,

because of the different latency of the measurements. Several
approaches, for example [46]–[49], have been presented to
deal with this challenge. In this paper, we have assumed
that measurements are synchronised using one of already
available synchronisation approaches. The measurements,
zT = [z1, z2, · · · , zm], obtained from the ﬁeld devices may
consist of real and reactive power ﬂows in different branches,
nodal voltage magnitudes and phase angles, and real and
reactive power injections at various buses of a power network.
in the proposed approach,
m measurements (with m ≥ 2n as the necessary condition
for the system to be observable; observability of a network
depends upon several conditions including type and location
of measurements as well as the network topology, the details
on the system observability condition are provided in chapter
4 of [35]) are used as inputs to the base-learners. Each
of the base-learners computes the state vector independently
(parallel stacking) as an output vector. The output of the
base-learners is provided as input to the meta-learner that
predicts the ﬁnal state vector variable, X, which consists of
n voltage magnitudes and n phase angles for n buses of a
power network. The meta-learner (MLR) maps prediction very
close to actual states. Hereinafter “Stacked ResNetD” is used
to denote this ensemble learning model. Fig. 3 shows the
ﬂowchart of the proposed method.

For the training and testing of the proposed model, the
availability of a complete set of historical measurements and
states is assumed. While at the instant of real-time operation
of the proposed PSSE,
if some of the measurements are
missing or topology are changing, the forecasted states can
be used for the monitoring and control of the power system.
Forecasting aided state estimation helps to deal with errors,
sudden change in the network, and topology and network
parameters change [20], [23], [43]–[45]; therefore, forecasting
missing measurements is important for the completeness of
the data-driven PSSE. Multivariate-linear regression for state
forecasting is described in section III-D to deal with the
problem of missing measurements.

D. Multivariate-linear Regression for State Forecasting
The general assumption of data-driven PSSE approaches is the
availability of complete measurements during real-time state
estimation, which may not be true in real-time data acquisition.
Some of measurements may not be available while performing
state estimation at control centres due to various reasons such
as measurement device failures, unreported outages, denial of
the service attacks, transmission line sags, and transmission
channel failures. Although missing measurement data may

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

W01W1zReLUReLUW0WW12ReLUW1W2W21ReLUW22ReLUW3ReLUWk-12ReLUWkXW31W311)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

Fig. 2. Proposed deep ensemble learning based PSSE. Input vector Zt is the real time measurement vector of size m. The intermediate vectors X 1(cid:48)
· · · X b(cid:48)
are the estimated voltage magnitudes and phase angles from b number of base-learners. The output vector Xt includes n voltage magnitudes and n phase
angles estimate for a power network with n buses.

, X 2(cid:48)

not be frequent
in practical power systems, an algorithm
is needed for missing measurements for the completeness
of the proposed state estimation approach. To deal with
these missing measurements/states, we forecast missing states.
Forecasting of missing states has several advantages because it
compensates for various errors, sudden changes, and topology
and network parameter changes. The advantages of forecasting
missing states or measurements to deal with changes in
network typologies and parameters are provided in [43].
forecasting system states for next hours
Mathematically,
(xt+1) given historical states (xt−h, xt−h+1, ......., xt−1, xt)
can be expressed as follows.

ˆxt+1 = φ(xt−h, xt−h+1, ......., xt−1, xt)
ˆzt+1 = ht+1(ˆxt+1) + et+1

(9)

(10)

It can be seen from (9) that an appropriate mapping function
φ needs to be developed to appropriately forecast next
state. Forecasted states can be used directly as states of
next hours or can be used in (10) as states to generate
the pseudo-measurements of the next hour. The missing
measurements are replaced with the pseudo-measurements
and provided as input
to the proposed state estimator
along with the available measurements. The performance of
the linear and non-linear models are similar for the state
forecasting [31]–[34]. However, nonlinear models come with
added computational time and complexity. Therefore, MLR
is adopted in this work to forecast future states. MLR has
following beneﬁts over the other non-linear models: it is easy
to train; takes much less time for training; and is much easier to
understand. The input to MLR is historical states as explained
above and the output is the states of the next one step (one
hour if the state estimation is done hourly) or more hours (for
multi step forecast). In this work, most recent 24 hours of
the historical time-series states are used as input and output
states of the next hour is forecasted. Analytically, MLR can

6

Fig. 3. Flowchart of the proposed PSSE. Huber loss is the used as loss
function. The proposed work is run for 200 epochs, this number is determined
empirically by looking into the training of ML model error settling around.

Base LearnersPower System State EstimatorXb'X1'X2'Xb'X1'X2'Real-Time Measurements (Zt)z1z2zmz1z2zmEstimated States(Xt)Meta-Learnerx1x2x2nStartSeparate dataset for base-learner modelRecord updated weights and bias of each base learner modelRecord updated weights and bias of each base learner modelUpdate weightsUpdate weightsEvaluate the model using performance metricsEvaluate the model using performance metricsRead power system network data (network topology, load profile, etc. ) Read power system network data (network topology, load profile, etc. ) Generate historical training and testing dataset using WLS and Gauss-Newton methodsGenerate historical training and testing dataset using WLS and Gauss-Newton methodsCompute loss functionCompute loss functionIs predefined number of  epochs reached ?Is predefined number of  epochs reached ?Load base-learner models and combine with MLR to train the compete model Load base-learner models and combine with MLR to train the compete model Ensemble prediction parametersEnsemble prediction parametersEnsemble prediction parametersStopStopSeparate dataset for testingSeparate dataset for testingNoYesLoop for i=1 to b, b is total number of base-learnersLoop for i=1 to b, b is total number of base-learnersInitialise weights and biasInitialise weights and biasInitialise weights and biasSeparate dataset for  meta-learnerSeparate dataset for  meta-learnerSeparate dataset for  meta-learnerbe expressed as follows.

ˆxt+1 = α0 + β0xt + β1xt−1 + ..... + βh−1xt−h+1 + βhxt−h
(11)

where α0 is the intercept and β0 through βh are regression
coefﬁcients for state forecasting.

E. Evaluation Metrics
The proposed work is compared with various state-of-the-art
methods using the following evaluation metrics.

1) Mean Absolute Error (MAE):

M AE =

1
T N

T
(cid:88)

N
(cid:88)

|xi

t − ˆxi
t|

(12)

i=1
2) Root Mean Square Error (RMSE):

t=1

RM SE =

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
T N

T
(cid:88)

N
(cid:88)

t=1

i=1

(xi

t − ˆxi

t)2

(13)

where N = n is the total number of estimated voltage or
phase angle states; T is the total number of test samples; and
t and ˆxi
xi
t represent actual and predicted states, respectively.

IV. NUMERICAL EVALUATION

section validates

This
the proposed approach through
numerical evaluation. Section IV-A describes step-by-step
training and testing data generation. Section IV-B presents
comparisons between the proposed Stacked ResNetD structure
and existing methods including MLP, CNN, and ProxlNet for
PSSE. Section IV-C shows the performance of the proposed
model with Non-Gaussian Noise in the measurements. Section
IV-D shows the capability of proposed PSSE to emulate
generalized maximum-likelihood (GM)-estimator proposed in
[5], [11] for power system state estimation. Finally, section
IV-E shows the performance of the MLR against CNN, LSTM,
and CNN-LSTM for time-series state forecast.

A. Dataset Generation
The performance of
the proposed state estimation is
demonstrated through various case studies on the standard
IEEE benchmark systems: IEEE 14, IEEE 30, IEEE 57, IEEE
69, and IEEE 118-bus systems. As historical measurements
and states of real power systems are not easily accessible
for training the proposed method, training data are generated
using real power load dataset (varying power demands help
capture the dynamics of real power systems) from Global
Energy Forecasting Competition 2012 [50]. Load proﬁle of
zone 1 is taken in this paper. Load proﬁles are normalised
to match the scale of the tested systems. The load time
series dataset is normalised by the peak value as follows. Let
X = x1, x2, · · · , x8760 denote the actual load in the dataset.
The normalised load proﬁle can be determined as follows.

Xprof ile =

x1, x2, ......., x8760
max(x1, x2, ......., x8760)

(14)

To obtain the load demand at each node for each time
instant, actual load demand at each node is multiplied by the
normalised load proﬁle of (14).

Simulations are performed using Power System Simulation
Package (MATPOWER) [51] to generate the data and Python

with Keras and Scikit-learn libraries is used for training and
testing of machine learning models. AC power ﬂow is run
for the entire simulation period of the load data and various
power ﬂow results such as line ﬂows (real and reactive power
ﬂows), nodal voltage magnitudes and phase angles, and nodal
power injections are recorded. Gaussian and non-Gaussian
noises are used to emulate real-world data. While estimating
system states from measurements using WLS method to
generate the training and testing data, measurement standard
errors (0.01, 0.01414, 0.01414, and 0.0122) are used for
voltage magnitudes, phase angles, line power ﬂows, and nodal
power injections, respectively. One of the necessary conditions
for a system to be observable is that the total number of
measurements should be greater than or equal to the total
number of states to be estimated.

taken for

The number of measurements

the 14-bus
system is 64. Although it can be predicted only with
32 measurements (data for this case are provided in the
shared code), 64 measurements are provided because having
redundant measurements have several beneﬁts such as (a)
it improves the performance of the model when there are
suspected measurements; (b) it can obtain better estimate
for the suspected data sets; (c) has capability to estimate
important non-telemetered variables (e.g., transformer taps);
and capability to determine the unknown status of CBs and
to detect topological errors [35]. For the 30-bus system, 110
measurement data points are used;
the proposed methods
can also with work with less number measurements, for
example 80 measurements (data for this case are provided
in the shared code). For 57-, 69-, and 118-bus systems, 216,
210, 562 number of measurements are chosen, respectively.
For this study, the number of measurements are determined
empirically.

As an example of location of measurement devices, the
locations of the 32 measurements for the 14-node system are as
follows: bus real and reactive power injection measurements
are taken from buses [2, 4, 8, 10, 11, 12, 14], i.e., total of
7 × 2 = 14 measurements; voltage magnitude and phase angle
measurements of bus 1; i.e., total of 1 × 2 = 2 measurements;
and real and reactive power ﬂow measurements are taken as
follows (from bus–to bus): 1–2 ,2–3, 2–5, 4–6, 4–7, 6–11,
6–13, 12–13, i.e., 2 × 8 = 16. Locations for the tested systems
are determined empirically and by following a similar location
as that of state estimation work presented in [5], [11].

Measurement

locations of the SCADA system is very
important as the number of measurements and locations have
inﬂuence over the result and observability of the system.
However, determining the optimal number of measurements
and optimal locations of SCADA is outside the scope of this
paper.

B. Results of Stacked ResNetD for PSSE
The m measurements are provided as input and the n voltage
magnitudes and n phase angles are provided as estimated
outputs to train the model which can be performed off-line
for a real power system. The trained model can be used in
real-time to estimate current states of the system with given
current measurements.

7

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

For each of the IEEE 14, 30, 57, and 69 bus test systems,
a total of 39, 444 data points are generated. For the IEEE 118
bus system, a total of 17, 520 data points are generated. From
the total dataset, 40% are utilised for training the base-learners,
36% for training the meta-learner, and the remaining 24% are
used for testing the complete ensemble learning setup. The
point to be noted while training the meta-learner is that it must
be trained with separate data-set than the one used to train
base-learners to avoid the over-ﬁtting. A Gaussian white noise
with signal-to-noise ratio of 50 dB is added to the training data
set. In real-time measurements, errors at any instant may be
different from that of the previous instant of time. To capture
changing measurement errors and check the robustness of the
proposed model against measurement errors, Gaussian white
noises with signal-to-noise ratio of 20 dB are added in the test
data set to alter them more than training data set. Gaussian
noise is considered based on the general convention used
to generate a dataset for data-driven based state estimation.
However, real measurements do not necessarily follow the
Gaussian noise. Speciﬁcally, load does not usually follow a
Gaussian distribution. Advance metering infrastructure can be
used to develop distribution functions for load points. To test
the proposed approach on different distributions and noises,
we have used non-Gaussian noise as well in section IV-C.
The per-unit values of voltage magnitudes are converted to
percent values and the phase angles are converted from radian
to degree for better visualisation.

The proposed Stacked ResNetD for state estimation is
compared with multi-layer-perceptron (MLP), CNN, and
Prox-linear net.

• Multilayer Perceptron (MLP): MLP has a layered
architecture with input, hidden, and output layers. The
normalised input is fed at the input layer. The cardinality
of the input vector determines the number of neurons
in the input layer. There can be multiple hidden layers in
the MLP. The ﬁnal prediction output is obtained from the
output layer. In this work, MLP consisting of 6 hidden
layers with ReLU as activation function and adaptive
moment estimation (Adam) as optimisation function is
used.

• Convolution Neural Networks (CNNs): CNNs are often
used in many applications. The CNNs have a convolution
layer followed by a pooling layer. The CNN and pooling
layers ﬁnd the low level feature of the input vector.
Fully connected layers are added after the convolution
and pooling layers. The CNN architecture is well-suited
for 2-D input. However, it can also be used efﬁciently for
1-D inputs like time-series. One of the beneﬁts of CNN is
that they are easier to train and have a fewer parameters
as compared to the fully connected neural network with
the same number of hidden units. The CNN architecture
is presented to compare it with the proposed approach
which consists sequentially of: two 1-D convolution layer
with 64 ﬁlters and kernel size of 3; one 1-D max pooling
layer with pool size of 3; one 1-D convolution layer with
ﬁlter size of 128 and kernel size of 3; one 1-D global
average pooling layer; two dense layers with 4n units

and ReLU activation function; and a output dense layer
with 2n units and ReLU activation function. CNN model
uses Adam as an optimiser.

• Prox-linear Net

(ProxlNet): Authors of

[20] have
proposed a ProxlNet for real-time PSSE. The ProxlNet
has been formed by skipping the layer that connects the
input directly to the immediate output layer, where each
layer consists of a ﬁxed number of hidden layers. The
ProxlNet architecture used for comparison consists of 2
skip-connection layers with 3 hidden units between each
layer. For the detailed architecture of ProxlNet, refer to
[20].

The aforementioned existing techniques are run 6 times
independently with a batch size of 64 and 200 epochs, and
the minimum values (prediction vary because of the stochastic
nature of the deep learning models) of RMSE and MAE for
all runs are taken for comparison with the proposed Stacked
ResNetD. The batch size of 64 and 200 epochs are determined
empirically. The number of epochs are selected after observing
the training error settling in the machine learning models.
The number of epochs could be different for different models;
however, in this work, we have determined it conservatively.
In other words, during the training phase, some of models may
settle earlier than 200 epochs while others may take around
200 epochs to settle; therefore, the number of epochs is chosen
to be 200. As the training is ofﬂine procedure, the number of
training epochs can be selected based on system requirements.
The structure of ResNetD used as a base-learner is same as
shown in Fig. 1 where three blocks containing 2 skip hidden
units in the regular information ﬂow of each blocks are used.
The number of neurons selected for each input and hidden
layers is the total number of input measurements of a speciﬁc
system; for the output layer, the total neurons equal to total
number of states to be predicted.

As the size of the data is big, we train all 6 parallel
ResNetD base-learners with same dataset and parameters.
Before deciding to train all the base-learners with same set
of training, we also tested the performance of ResNetD as
base-learners by dividing the training data into 6 folds. The
performance of Stacked ResNetD on the test dataset is better
when trained with the entire training dataset for all of the
parallel base-learners than that when trained with 6 fold of
data for 6 parallel ResNetD.

Table I shows comparison of MLP, CNN, ProxlNet, and
proposed Stacked ResNetD models in terms of RMSE and
MAE of voltage magnitude estimation for IEEE 14, 30,
57, 69, and 118 benchmark systems. The values of the
metrics show that the proposed Stacked ResNetD ensemble
learning setup captures the true relationship between input
measurements and the estimated voltage states. The proposed
base-learner has regular information ﬂow, skipping connection,
and direct connection to the input data through dense layer.
All this together solving “vanishing” and “exploding” issues,
improving the regular information ﬂow and recovering missing
features. MLR as meta-learner is further improving the result
toward the actual values.

Table II shows the comparison of MLP, CNN, ProxlNet,
and the proposed Stacked ResNetD in terms of RMSE and

8

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

TABLE I
COMPARISON OF MLP, CNN, PROXLNET, AND PROPOSED STACKED RESNETD IN TERMS OF RMSE AND MAE METRICS FOR VOLTAGE MAGNITUDES
ESTIMATION

Models

MLP
CNN
ProxlNet
Proposed
Stacked ResNetD

IEEE 14 Bus
RMSE
2.4574
2.2262
2.4592
0.2605

MAE
1.8533
1.4926
1.8815
0.1660

IEEE 30 Bus
RMSE
4.1737
4.2576
4.1405
0.4753

MAE
2.9253
2.9005
2.8885
0.2852

IEEE 57 Bus
RMSE
5.1976
5.1595
5.1273
0.4766

MAE
3.5885
3.4571
3.5283
0.2931

IEEE 69 Bus
RMSE
6.8272
6.8614
6.6526
0.6486

MAE
5.3114
5.3225
5.1737
0.4238

IEEE 118 Bus
RMSE
1.8588
1.9343
1.8385
0.1894

MAE
1.3944
1.4635
1.3784
0.1196

TABLE II
COMPARISON OF MLP, CNN, PROXLNET, AND PROPOSED STACKED RESNETD MODELS IN TERMS OF RMSE AND MAE METRICS FOR PHASE ANGLES
ESTIMATION

Models

MLP
CNN
ProxlNet
Proposed
Stacked ResNetD

IEEE 14 Bus
RMSE
0.5496
0.6496
0.5122
0.1102

MAE
0.3533
0.4631
0.3213
0.0733

IEEE 30 Bus
RMSE
1.2202
1.2513
1.1840
0.5472

MAE
0.6854
0.7312
0.6581
0.1873

IEEE 57 Bus
RMSE
1.8197
1.8677
1.7650
0.2978

MAE
1.1970
1.2741
1.1558
0.1581

IEEE 69 Bus
RMSE
2.5232
2.5242
2.4475
0.5417

MAE
1.6724
1.6980
1.6324
0.3156

IEEE 118 Bus
RMSE
1.4351
2.1926
1.3061
0.2104

MAE
1.0852
1.5885
1.0045
0.1272

Fig. 4. Prediction vs actual voltage magnitude and phase angles at bus 10 of
IEEE 14 bus system

Fig. 5. Voltage magnitude and phase prediction vs actual at bus 20 of IEEE
30 bus system

MAE metrics of phase angles estimation for IEEE 14, 30, 57,
69, and 118 benchmark systems. The results obtained by the
proposed approach is closer to actual state values.

The run-time performance of each model is determined over
all the testing dataset and is averaged over each instance.
Table III shows the run-time performance of each model per
instance estimation.

Figures 4, 5, 6, 7, and 8 show the estimated voltage
magnitudes and phase angles of
the proposed Stacked
ResNetD along with the MLP, CNN, and ProxlNet techniques
at different buses of IEEE benchmark systems. These ﬁgures
the states estimated by the proposed Stacked
show that
ResNetD are comparable to the actual states obtained by
the WLS method. The states predicted by ResNetD are very
close to the actual states. The states predicted by ResNetD
as base-learners are linear approximations to actual states.
Therefore, MLR as a meta-learner estimates the states with

low bias.

C. Performance of the Proposed Model with Non-Gaussian

Noise

We have used non-Gaussian noise to test
the proposed
approach on different distributions and noises. To test such
cases, measurement errors are emulated randomly as follows.
A random noise of size 0 − 3% of original power ﬂow
results are generated and inserted in the measurement data.
Separate random errors are generated for each measurement
at every instance and added or subtracted from the original
measurements. In this way, the error size and the disturbed
measurements are changing every instance. Out of total of m
measurements, random errors are added in the ﬁrst 50% and
subtracted from the remaining 50% to make it more practical.
Figures 9– 13 show the performance of MLP, CNN,
ProxlNet, and the proposed Stacked ResNetD in terms
the
of RMSE and MAE metrics. The results show that

9

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

TABLE III
COMPARISON OF MLP, CNN, PROXLNET, AND PROPOSED STACKED RESNETD MODELS IN TERMS OF RUN-TIME PERFORMANCE PER INSTANCE
ESTIMATION WHERE ‘S’ DENOTES SECONDS AND ‘MS’ DENOTES MILLISECONDS.

Models
WLS
GM-Estimator
MLP
CNN
ProxlNet
Proposed
Stacked ResNetD

IEEE 14 Bus
5.566 ms
-
0.0229 ms
0.095 ms
0.0249 ms
0.237 ms

IEEE 30 Bus
0.0196 s
0.2133 s
0.0294 ms
0.1074 ms
0.0347 ms
0.312 ms

IEEE 57 Bus
0.2917 s
1.23 s
0.0512 ms
0.211 ms
0.0535 ms
0.597 ms

IEEE 69 Bus
0.3867 s
-
0.0435 ms
0.196 ms
0.0464 ms
0.591 ms

IEEE 118 Bus
2.22 s
-
0.205 ms
0.53 ms
0.241 ms
2.03 ms

Fig. 6. Prediction vs actual voltage magnitude and phase angles at bus 28 of
IEEE 57 bus system

Fig. 8. Prediction vs actual voltage magnitude and phase angles at bus 59 of
IEEE 118 bus system

Fig. 7. Prediction vs actual voltage magnitude and phase angles at bus 35 of
IEEE 69 bus system

Fig. 9.
Performance of various models on IEEE 14 bus system with
non-Gaussian measurement noise. RMSE V and MAE V are for voltage
magnitudes and RMSE A and MAE A are for phase angles. Score in the
vertical axis denotes voltage in percentage value for RMSE V and MAE V
and phase angle in degree for RMSE A and MAE A.

proposed PSSE can estimate the states accurately even with
non-Gaussian noise.

D. Performance of Proposed PSSE with GM-Estimator
As the main purpose of the proposed work is to develop
that can emulate the physical
a machine learning model

10

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

Fig. 10.
Performance of various models on IEEE 30 bus system with
non-Gaussian measurement noise. RMSE V and MAE V are for voltage
magnitudes and RMSE A and MAE A are for phase angles. Score in the
vertical axis denotes voltage in percentage value for RMSE V and MAE V
and phase angle in degree for RMSE A and MAE A.

Fig. 12.
Performance of various models on IEEE 69 bus system with
non-Gaussian measurement noise. RMSE V and MAE V are for voltage
magnitudes and RMSE A and MAE A are for phase angles. Score in the
vertical axis denotes voltage in percentage value for RMSE V and MAE V
and phase angle in degree for RMSE A and MAE A.

Fig. 11.
Performance of various models on IEEE 57 bus system with
non-Gaussian measurement noise. RMSE V and MAE V are for voltage
magnitudes and RMSE A and MAE A are for phase angles. Score in the
vertical axis denotes voltage in percentage value for RMSE V and MAE V
and phase angle in degree for RMSE A and MAE A.

Fig. 13. Performance of various models on IEEE 118 bus system with
non-Gaussian measurement noise. RMSE V and MAE V are for voltage
magnitudes and RMSE A and MAE A are for phase angles. Score in the
vertical axis denotes voltage in percentage value for RMSE V and MAE V
and phase angle in degree for RMSE A and MAE A.

state estimator models appropriately, we have also tested it
with generalised M-Estimator (GM-Estimator) to demonstrate
the capability of
the proposed method to emulate the
GM-Estimator proposed in [5], [11]. The MATLAB code
for GM-Estimator is obtained from [5], [11]. This case is
tested only on the IEEE 30- and 57-node test systems because
with the MATLAB code provided in [5], [11] for 69 and
118 bus system, GM-estimator state estimation is very time
consuming and difﬁcult to converge with time varying loads.
There can be several ways to reduce the computational burden
of the physical models which is outside the scope of the
proposed work. To test the performance of proposed model
with different number of input measurements, in this case the
number of input measurements are different than that used in
WLS based data generation: 80 measurements are used for 30
bus system, and 216 measurements are used for 57 bus system.

In this case, the dataset are generated using a GM-Estimator.
To incorporate Gaussian and non-Gaussian noise, datasets
are generated with Gaussian noise and non-Gaussian noise
and shufﬂed together and used for training and testing of
the GM-Estimator. As there are 6 base learners in proposed
model, MLP, CNN, and ProxlNet are also run for 6 times
independently and the minimum of each run (prediction vary
because of the stochastic nature of the deep learning models) is
compared with the results of the proposed model. The per-unit
values of voltage magnitudes are converted to percent values
and the phase angles are converted from radian to degree for
better visualisation.

For

the 30-bus system, RMSE for voltage magnitude
estimation with MLP, CNN, ProxlNet, and the proposed
Stacked ResNetD are 0.3815, 0.3984, 0.3518, and 0.2551,
respectively. MAE for voltage magnitude estimation with

11

For

MLP, CNN, ProxlNet, and the proposed Stacked ResNetD are
0.2663, 0.2418, 0.2510, and 0.1353, respectively. Similarly,
for phase angle estimation, RMSE of MLP, CNN, ProxlNet,
and the proposed Stacked ResNetD are 0.1689, 0.2171,
0.1603, and 0.0741, respectively. The phase angle estimation
MAE of MLP, CNN, ProxlNet, and the proposed Stacked
ResNetD are 0.0948, 0.1103, 0.0841, and 0.025, respectively.
the 57-bus system, RMSE for voltage magnitude
estimation of MLP, CNN, ProxlNet, and the proposed Stacked
ResNetD are 1.2161, 2.2138, 1.022, and 0.8897, respectively.
MAE for voltage magnitude estimation of MLP, CNN,
ProxlNet, and the proposed Stacked ResNetD are 0.5714,
0.8481, 0.5545, and 0.3805, respectively. Similarly, for phase
angle, RMSE of MLP, CNN, ProxlNet, and the proposed
Stacked ResNetD are 0.4100, 0.8304, 0.3681, and 0.2986,
respectively. The phase angle estimation MAE of MLP, CNN,
ProxlNet, and the proposed Stacked ResNetD are 0.1638,
0.2216, 0.1644, 0.0918, respectively.

The performance of the proposed model is better than the
other ML models because the proposed model with ResNetD
as base learner can capture the non-linear relationship between
the input measurements and the output states. The MLR
as meta-learner further improves the results because of the
approximate linear relationships between the output of the
different ResNetD models and the actual states. The results
show that the proposed model can accurately emulate the
GM-Estimator.

The run-time performance of machine learning models,

WLS, and GM-Estimator is as shown in Table III.

E. Results of MLR for State Forecasting
When some of the measurements are missing during real-time
operation, usually state forecasting is performed. In this
section, MLR is compared with most common timer-series
forecasting models
such as CNN, LSTM, and hybrid
CNN-LSTM for forecasting of the power system states. Each
of these models is brieﬂy discussed as follows.

• CNN: The CNN used for

the comparison consists
sequentially of: two 1-D convolution layer with kernel
size of 3, 64 ﬁlters and ReLU as activation function;
one 1-D max pooling layer with pool size of 2; one 1-D
convolution layer with 128 ﬁlters and kernel size of 3;
one 1-D global average pooling layer; one single dense
layer with 50 units and activation function of ReLU; and
ﬁnal dense layer with unit size equal to number of states
to be forecasted.

• LSTM: LSTM has

architecture. LSTM
layered
architecture used for the comparison consists sequentially
of: three-layer of LSTM with ReLU activation function
with 4n, 2n, and 2n units, respectively; and two dense
layers with 2n number of units in each layer and ReLU
as activation function.

• CNN-LSTM: The hybrid of CNN and LSTM consists
of CNN networks
followed by LSTM networks.
CNN-LSTM used for the comparison consists of two
layers of 1-D convolution layer with 64 ﬁlters, kernel size
of 3 in each, and ReLU as activation function; one 1-D
max pooling layer with pool size of 2; two LSTM layers

Fig. 14. Prediction vs actual voltage magnitude and phase angles at all buses
of IEEE 14 bus system at instant 500

with 2n number of units with ReLU activation function;
and three dense layers with 2n units with ReLU activation
function in each layer.

Adam is used as an optimiser and mean absolute error is taken
as a loss function for all of the models. All of the CNN, LSTM,
and CNN-LSTM models are run 6 times independently with
batch size of 32 and 200 epochs, and the minimum values of
metrics of all runs are taken for the purpose of comparison.

Out of the available historical data, 40% are used for
training and the remaining 60% are used for testing. For this
time-series forecasting, the last 24 step time series data of
states are utilised to forecast current hour’s state. Although a
state is forecasted only for one step (one hour), the proposed
approach can be used to forecast the states for multiple steps
(two or more hours) with a little modiﬁcation.

Table IV provides comparisons between CNN, LSTM,
CNN-LSTM, and MLR models in terms of RMSE and MAE
metrics forecast of voltage magnitudes for IEEE 14, 30, 57, 69,
and 118 benchmark systems on test datasets. It can be seen
from the table that the performance of MLR is remarkably
better than the other models for all of the tested systems.

Table V presents a comparison between forecast of phase
angles of MLR against LSTM, CNN-LSTM, and CNN on
test data-set of IEEE 14, 30, 57, 69, and 118 bus benchmark
systems in terms of RMSE and MAE metrics. It can be seen
that MLR outperforms all other models for all of the studied
IEEE benchmark systems.

Figures 14, 15, 16, 17, and 18 show the comparison between
CNN, LSTM, CNN-LSTM, and MLR to forecast the power
system states. These ﬁgures show the competitive performance
of MLR for state forecasting.

MLR is mapping the historical states closer to actual states
than any other compared deep learning models. This could be
due to the existence of an approximately linear relationship
between historical power system states.

Although the proposed state forecasting approach can
forecast the current states when all sets of measurements are
available, the states thus obtained are not as close as estimated

12

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

TABLE IV
COMPARISON OF VOLTAGE MAGNITUDE FORECAST OF CNN, LSTM, CNN-LSTM, AND MLR MODELS IN TERMS OF RMSE AND MAE METRICS FOR
STANDARD IEEE 14, 30, 57, 69, AND 118 BENCHMARK SYSTEMS

Models

IEEE 14 Bus
RMSE
0.4174
LSTM
CNN-LSTM 0.4233
0.4218
CNN
0.1241
Proposed
MLR

MAE
0.2927
0.3029
0.3233
0.0845

IEEE 30 Bus
RMSE
0.3351
0.3349
0.3640
0.1509

MAE
0.2397
0.2382
0.2814
0.1044

IEEE 57 Bus
RMSE
0.9008
0.9028
0.6700
0.2115

MAE
0.5772
0.6159
0.5799
0.1417

IEEE 69 Bus
RMSE
0.5312
0.5278
0.4946
0.2529

MAE
0.3554
0.3715
0.3444
0.1955

IEEE 118 Bus
RMSE
0.5271
0.5108
0.4868
0.1919

MAE
0.3751
0.3421
0.3305
0.1420

TABLE V
COMPARISON OF PHASE ANGLES FORECAST OF CNN, LSTM, CNN-LSTM, AND MLR MODELS IN TERMS OF RMSE AND MAE METRICS FOR
STANDARD IEEE 14, 30, 57, 69, AND 118 BENCHMARK SYSTEMS

Models

IEEE 14 Bus
RMSE
0.0337
LSTM
CNN-LSTM 0.0399
0.0686
CNN
0.0037
Proposed
MLR

MAE
0.0263
0.0325
0.0575
0.0025

IEEE 30 Bus
RMSE
0.0399
0.0526
0.0633
0.0036

MAE
0.0318
0.0392
0.0492
0.0025

IEEE 57 Bus
RMSE
0.0853
0.1108
0.0864
0.0094

MAE
0.0647
0.0902
0.0707
0.0067

IEEE 69 Bus
RMSE
0.0601
0.0602
0.0659
0.0015

MAE
0.0516
0.0526
0.0562
0.0010

IEEE 118 Bus
RMSE
0.2182
0.2037
0.2325
0.0460

MAE
0.1594
0.1525
0.1730
0.0343

Fig. 15. Prediction vs actual voltage magnitude and phase angles at all buses
of IEEE 30 bus system at instant 500

Fig. 17. Prediction vs actual voltage magnitude and phase angles at all buses
of IEEE 69 bus system at instant 500

states using the proposed PSSE with the current measurements
(the comparison results are not provided for obviousness and
simplicity of expositions, if interested it can be veriﬁed with
provided source code). Therefore, the state forecasting should
only be used at the instant of missing measurements.

V. CONCLUSIONS
This paper has proposed a data-driven real-time PSSE using a
deep ensemble learning method. The proposed deep ensemble
learning setup was formed by stacking several parallel
ResNetD as base-learners and multivariate-linear regression
as meta-learner. In this work, historical measurements and
states were utilised to train the proposed model for the
estimation of power system states (voltage magnitudes and
phase angles). The trained model was utilised to predict
the states of the power system in real time using real-time
measurements. The data-driven PSSE assumes the availability
of a complete set of measurements; however, some of the

Fig. 16. Prediction vs actual voltage magnitude and phase angles at all buses
of IEEE 57 bus system at instant 500

13

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

[8] L. Fan, Y. Wehbe, Extended kalman ﬁltering based real-time dynamic
state and parameter estimation using pmu data, Electric Power Systems
Research 103 (2013) 168–177.

[9] F. F. Wu, Power system state estimation: a survey, International Journal

of Electrical Power & Energy Systems 12 (2) (1990) 80–87.

[10] H. Bilil, H. Gharavi, Mmse-based analytical estimator for uncertain
power system with limited number of measurements, IEEE Transactions
on Power Systems 33 (5) (2018) 5236–5247.

[11] L. Mili, M. G. Cheniae, N. S. Vichare, P. J. Rousseeuw, Robust state
estimation based on projection statistics [of power systems], IEEE
Transactions on Power Systems 11 (2) (1996) 1118–1127.

[12] B. P. Bhattarai, S. Paudyal, Y. Luo, M. Mohanpurkar, K. Cheung,
R. Tonkoski, R. Hovsapian, K. S. Myers, R. Zhang, P. Zhao, M. Manic,
S. Zhang, X. Zhang, Big data analytics in smart grids: state-of-the-art,
challenges, opportunities, and future directions, IET Smart Grid 2 (2)
(2019) 141–154.

[13] H. Akhavan-Hejazi, H. Mohsenian-Rad, Power systems big data
analytics: An assessment of paradigm shift barriers and prospects,
Energy Reports 4 (2018) 91–100.

[14] B. Dhupia, M. Usha Rani, A. Alameen, The role of big data analytics
in smart grid management,
in: P. Venkata Krishna, M. S. Obaidat
(Eds.), Emerging Research in Data Engineering Systems and Computer
Communications, Springer Singapore, Singapore, 2020, pp. 403–412.

[15] A. S. Zamzam, X. Fu, N. D. Sidiropoulos, Data-driven learning-based
optimization for distribution system state estimation, IEEE Transactions
on Power Systems 34 (6) (2019) 4796–4805.

[16] Z. Cao, Y. Wang, C. Chu, R. Gadh, Scalable distribution systems state
estimation using long short-term memory networks as surrogates, IEEE
Access 8 (2020) 23359–23368.

[17] A. S. Bretas, A. Rossoni, R. D. Trevizan, N. G. Bretas, Distribution
networks nontechnical power loss estimation: A hybrid data-driven
physics model-based framework, Electric Power Systems Research 186
(2020) 106397.

[18] Y. Weng, R. Negi, C. Faloutsos, M. D. Ili´c, Robust data-driven state
estimation for smart grid, IEEE Transactions on Smart Grid 8 (4) (2017)
1956–1967.

[19] F. S. Adi, Y. J. Lee., H. Song, State estimation for dc microgrids using
modiﬁed long short-term memory networks, Applied Science (2020, 10,
3028).

[20] L. Zhang, G. Wang, G. B. Giannakis, Real-time power system state
estimation and forecasting via deep unrolled neural networks, IEEE
Transactions on Signal Processing 67 (15) (2019) 4069–4077.

[21] P. N. P. Barbeiro, J. Krstulovic, H. Teixeira, J. Pereira, F. J. Soares,
J. P. Iria, State estimation in distribution smart grids using autoencoders,
in: 2014 IEEE 8th International Power Engineering and Optimization
Conference (PEOCO2014), Langkawi, Malaysia, 2014, pp. 358–363.

[22] A. S. Zamzam, N. D. Sidiropoulos, Physics-aware neural networks
for distribution system state estimation, IEEE Transactions on Power
Systems (2020, DOI: 10.1109/TPWRS.2020.2988352).

[23] L. Zhang, G. Wang, G. B. Giannakis, Power system state forecasting
via deep recurrent neural networks, in: ICASSP 2019 - 2019 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP), Brighton, United Kingdom, United Kingdom, 2019, pp.
8092–8096.

[24] K. R. Mestav, L. Tong, State estimation in smart distribution systems
with deep generative adversary networks, in: 2019 IEEE International
Conference on Communications, Control, and Computing Technologies
for Smart Grids (SmartGridComm), 2019, pp. 1–6.

[25] T. Poggio, H. Mhaskar, L. Rosasco, B. Miranda, Q. Liao, Why and when
can deep-but not shallow-networks avoid the curse of dimensionality: A
review., Int. J. Autom. Comput. (2017) 503–519.

[26] G. Huang, Z. Liu, L. Van Der Maaten, K. Q. Weinberger,
Densely connected convolutional networks, in: 2017 IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), 2017, pp.
2261–2269.

[27] K. Chen, K. Chen, Q. Wang, Z. He, J. Hu, J. He, Short-term load
forecasting with deep residual networks, IEEE Transactions on Smart
Grid 10 (4) (2019) 3943–3952.

[28] L. Zhao, M. Li, D. Meng, X. Li, Z. Zhang, Y. Zhuang, Z. Tu, J. Wang,
Deep convolutional neural networks with merge-and-run mappings, in:
Proceedings of the 27th International Joint Conference on Artiﬁcial
Intelligence, AAAI Press, 2018, pp. 3170–3176.

[29] M. S. Hanif, M. Bilal, Competitive residual neural network for image

classiﬁcation, ICT Express 6 (1) (2020) 28–37.

[30] X. Zou, Z. Wang, Q. Li, W. Sheng, Integration of residual network and
convolutional neural network along with various activation functions and

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

Fig. 18. Prediction vs actual voltage magnitude and phase angles at all buses
of IEEE 118 bus system at instant 500

real-time measurements may be missing leading to failure in
estimating the states. To deal with missing measurements, this
paper adopted multivariate-linear regression to forecast the
missing states at any instant using historical states. Several
case studies were performed in various IEEE benchmark
systems. Case studies showed that
the proposed approach
outperformed various machine learning techniques.

DECLARATION OF COMPETING INTEREST

None.

ACKNOWLEDGEMENT

This work was supported by the U.S. National Science
Foundation (NSF) under Grant NSF 1847578.

APPENDIX

Source code developed for this project are publicly available
at GithuB.

REFERENCES

[1] N. Bhusal, M. Abdelmalak, M. Kamruzzaman, M. Benidris, Power
system resilience: Current practices, challenges, and future directions,
IEEE Access 8 (2020) 18064–18086.

[2] N. Bhusal, M. Gautam, M. Abdelmalak, M. Benidris, Modeling of
natural disasters and extreme events for power system resilience
enhancement and evaluation methods, in: 2020 International Conference
on Probabilistic Methods Applied to Power Systems (PMAPS), Liege,
Belgium, Belgium, 2020, pp. 1–6.

[3] A. J. Wood, B. F. Wollenberg, G. B. Shebl´e, Power Generation,
Operation, and Control, 3rd Edition, IEEE Wiley, Hoboken, New Jersey,
2014.

[4] A. Abur, M. K. Celik, Least absolute value state estimation with equality
and inequality constraints, IEEE Transactions on Power Systems 8 (2)
(1993) 680–686.

[5] J. Zhao, M. Netto, L. Mili, A robust iterated extended kalman ﬁlter for
power system dynamic state estimation, IEEE Transactions on Power
Systems 32 (4) (2017) 3205–3216.

[6] E. Caro, A. J. Conejo, State estimation via mathematical programming:
IET Generation,

a comparison of different estimation algorithms,
Transmission Distribution 6 (6) (2012) 545–553.

[7] G. Wang, G. B. Giannakis, J. Chen, Robust and scalable power system
state estimation via composite optimization, IEEE Transactions on Smart
Grid 10 (6) (2019) 6137–6147.

14

global pooling for time series classiﬁcation, Neurocomputing 367 (2019)
39–45.

for enhanced cyber-physical smart grid security, IET Smart Grid 3 (4)
(2020) 445–453.

[31] A. S. Debs, R. E. Larson, A dynamic estimator for tracking the state of
a power system, IEEE Transactions on Power Apparatus and Systems
PAS-89 (7) (1970) 1670–1678.

[32] M. Hassanzadeh, C. Y. Evrenoso˘glu, Power system state forecasting
using regression analysis, in: 2012 IEEE Power and Energy Society
General Meeting, San Diego, CA, USA, 2012, pp. 1–6.

[33] M. Hassanzadeh, C. Y. Evrenoso˘glu, L. Mili, A short-term nodal voltage
phasor forecasting method using temporal and spatial correlation, IEEE
Transactions on Power Systems 31 (5) (2016) 3881–3890.

[34] A. M. Leite da Silva, M. B. Do Coutto Filho, J. F. de Queiroz, State
forecasting in electric power systems, IEE Proceedings C - Generation,
Transmission and Distribution 130 (5) (1983) 237–244.

[35] A. Abur, A. G. Exp´osito, Power System State Estimation: Theory and

Implementation, Marcel Dekker, Inc., New York, USA, 2004.

[36] C. Zhang, Y. Ma, Ensemble machine learning: methods and applications,

Springer, 2012.

[37] A. Barredo Arrieta, N. D´ıaz-Rodr´ıguez, J. Del Ser, A. Bennetot,
S. Tabik, A. Barbado, S. Garcia, S. Gil-Lopez, D. Molina, R. Benjamins,
R. Chatila, F. Herrera, Explainable artiﬁcial intelligence (xai): Concepts,
taxonomies, opportunities and challenges
toward responsible ai,
Information Fusion 58 (2020) 82–115.

[38] H. Lappalainen, J. W. Miskin, Ensemble Learning, Springer London,

London, 2000, pp. 75–92.

[39] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image
recognition, in: 2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), Las Vegas, NV, USA, 2016, pp. 770–778.
[40] P. B¨uhlmann, Robust Statistics, Springer New York, New York, NY,

2014, pp. 51–98.

[41] K. Nagaraj, S. Zou, C. Ruben, S. Dhulipala, A. Starke, A. Bretas,
A. Zare, J. McNair, Ensemble corrdet with adaptive statistics for bad
data detection, IET Smart Grid (2020).

[42] C. Ruben, S. Dhulipala, K. Nagaraj, S. Zou, A. Starke, A. Bretas,
A. Zare, J. McNair, Hybrid data-driven physics model-based framework

[43] M. B. Do Coutto Filho, J. C. Stacchini de Souza, Forecasting-aided state
estimation—part i: Panorama, IEEE Transactions on Power Systems
24 (4) (2009) 1667–1677.

[44] X. Ji, Z. Yin, Y. Zhang, M. Wang, X. Zhang, C. Zhang, D. Wang,
Real-time robust forecasting-aided state estimation of power system
based on data-driven models, International Journal of Electrical Power
& Energy Systems 125 (2021) 106412.

[45] W. S. Rosenthal, A. M. Tartakovsky, Z. Huang, Ensemble kalman ﬁlter
for dynamic state estimation of power grids stochastically driven by
time-correlated mechanical input power, IEEE Transactions on Power
Systems 33 (4) (2018) 3701–3710.

[46] M. Kabiri, N. Amjady, A new hybrid state estimation considering
IEEE
different accuracy levels of pmu and scada measurements,
Transactions on Instrumentation and Measurement 68 (9)
(2019)
3078–3089.

[47] G. N. Korres, N. M. Manousakis, State estimation and bad data
processing for systems including pmu and scada measurements, Electric
Power Systems Research 81 (7) (2011) 1514–1524.

[48] Q. Zhang, Y. Chakhchoukh, V. Vittal, G. T. Heydt, N. Logic, S. Sturgill,
Impact of pmu measurement buffer length on state estimation and
its optimization, IEEE Transactions on Power Systems 28 (2) (2013)
1657–1665.

[49] J. Zhao, S. Wang, L. Mili, B. Amidan, R. Huang, Z. Huang, A robust
state estimation framework considering measurement correlations and
imperfect synchronization, IEEE Transactions on Power Systems 33 (4)
(2018) 4604–4613.

[50] T. Hong, P. Pinson, S. Fan, Global energy forecasting competition 2012,

International Journal of Forecasting 30 (2) (2014) 357–363.

[51] R. D. Zimmerman, C. E. Murillo-S´anchez, R. J. Thomas, Matpower:
Steady-state operations, planning, and analysis tools for power systems
research and education, IEEE Transactions on Power Systems 26 (1)
(2011) 12–19.

)
l
a
n
r
u
o
J

r
e
i
v
e
s
l
E
n
a
(

s
m
e
t
s
y
S
y
g
r
e
n
E
d
n
a

r
e
w
o
P
l
a
c
i
r
t
c
e
l
E
f
o

l
a
n
r
u
o
J

l
a
n
o
i
t
a
n
r
e
t
n
I

15

