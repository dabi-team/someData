HARVEY: A Greybox Fuzzer for Smart Contracts

Valentin W¨ustholz
ConsenSys Diligence, Germany
valentin.wustholz@consensys.net

Maria Christakis
MPI-SWS, Germany
maria@mpi-sws.org

9
1
0
2

y
a
M
5
1

]
E
S
.
s
c
[

1
v
4
4
9
6
0
.
5
0
9
1
:
v
i
X
r
a

Abstract—We present HARVEY, an industrial greybox fuzzer
for smart contracts, which are programs managing accounts on
a blockchain.

Greybox fuzzing is a lightweight test-generation approach that
effectively detects bugs and security vulnerabilities. However,
greybox fuzzers randomly mutate program inputs to exercise new
paths; this makes it challenging to cover code that is guarded by
narrow checks, which are satisﬁed by no more than a few input
values. Moreover, most real-world smart contracts transition
through many different states during their lifetime, e.g., for every
bid in an auction. To explore these states and thereby detect
deep vulnerabilities, a greybox fuzzer would need to generate
sequences of contract transactions, e.g., by creating bids from
multiple users, while at the same time keeping the search space
and test suite tractable.

In this experience paper, we explain how HARVEY alleviates
both challenges with two key fuzzing techniques and distill the
main lessons learned. First, HARVEY extends standard greybox
fuzzing with a method for predicting new inputs that are more
likely to cover new paths or reveal vulnerabilities in smart
contracts. Second, it fuzzes transaction sequences in a targeted
and demand-driven way. We have evaluated our approach on
27 real-world contracts. Our experiments show that the under-
lying techniques signiﬁcantly increase HARVEY’s effectiveness in
achieving high coverage and detecting vulnerabilities, in most
cases orders-of-magnitude faster; they also reveal new insights
about contract code.

I. INTRODUCTION

Smart contracts are programs that manage crypto-currency
accounts on a blockchain. Reliability of these programs is of
critical importance since bugs may jeopardize digital assets.
Automatic test generation has shown to be an effective ap-
proach to ﬁnd such vulnerabilities, thereby improving software
quality. In fact, there exists a wide variety of test-generation
tools, ranging from random testing [1], [2], [3], over greybox
fuzzing [4], [5], to dynamic symbolic execution [6], [7].

Random testing [1], [2], [3] and blackbox fuzzing [8], [9]
generate random inputs to a program, run the program with
these inputs, and check for bugs. Despite the practicality
of these techniques, their effectiveness, that is, their ability
to explore new paths, is limited. The search space of valid
program inputs is typically huge, and a random exploration
can only exercise a small fraction of (mostly shallow) paths.
At the other end of the spectrum, dynamic symbolic execu-
tion [6], [7] and whitebox fuzzing [10], [11], [12] repeatedly
run a program, both concretely and symbolically. At runtime,
they collect symbolic constraints on program inputs from
branch statements along the execution path. These constraints
are then appropriately modiﬁed and a constraint solver is

used to generate new inputs, thereby steering execution toward
another path. Although these techniques are very effective in
covering new paths, they cannot be as efﬁcient and scalable
as other test-generation techniques that do not spend any time
on program analysis and constraint solving.

Greybox fuzzing [4], [5] lies in the middle of the spectrum
between performance and effectiveness in discovering new
paths. It does not require program analysis or constraint solv-
ing, but it relies on a lightweight program instrumentation that
allows the fuzzer to tell when an input exercises a new path.
In other words, the instrumentation is useful in computing a
unique identiﬁer for each explored path in the program under
test. American Fuzzy Lop (AFL) [4] is a prominent example
of a state-of-the-art greybox fuzzer that has detected numerous
bugs and security vulnerabilities [13].

In this paper, we present HARVEY, the ﬁrst greybox fuzzer
for smart contracts. We report on our experience in designing
HARVEY, and in particular, focus on how to alleviate two key
challenges we encountered when fuzzing real-world contracts.
Although the challenges are not exclusive to our speciﬁc
application domain, our techniques are shown to be quite
effective for smart contracts and there are important lessons
to be learned from our experiments.

Challenge #1. Despite the fact that greybox fuzzing strikes
a good balance between performance and effectiveness, the
inputs are still randomly mutated, for instance, by ﬂipping
arbitrary bits. As a result, many generated inputs exercise
the same program paths. To address this problem, there have
emerged techniques that direct greybox fuzzing toward low-
frequency paths [14], vulnerable paths [15], deep paths [16],
or speciﬁc sets of program locations [17]. Such techniques
have mostly focused on which seed inputs to prioritize and
which parts of these inputs to mutate.

Challenge #2. Smart contracts may transition through many
different states during their lifetime, for instance, for every
bet in a gambling game. The same holds for any stateful
system that is invoked repeatedly, such as a web service.
Therefore, detecting vulnerabilities in such programs often
requires generating and fuzzing sequences of invocations that
explore the possible states. For instance,
to test a smart
contract that implements a gambling game, a fuzzer would
need to automatically create sequences of bets from multiple
players. However, since the number of possible sequences
grows exponentially with the sequence length, it is difﬁcult
to efﬁciently detect the few sequences that reveal a bug.

Our approach and lessons learned. To alleviate the

 
 
 
 
 
 
ﬁrst challenge, we developed a technique that systematically
predicts new inputs for the program under test with the goal
of increasing the performance and effectiveness of greybox
fuzzing. In contrast to existing work in greybox fuzzing, our
approach suggests concrete input values based on information
from previous executions,
instead of performing arbitrary
mutations. And in contrast to whitebox fuzzing, our input-
prediction mechanism remains particularly lightweight.

Inputs are predicted in a way that aims to direct greybox
fuzzing toward optimal executions, for instance, deﬁned as
executions that ﬂip a branch condition in order to increase
coverage. Our technique is parametric in what constitutes an
optimal execution, and in particular, in what properties such
an execution needs to satisfy.

More speciﬁcally, each program execution is associated with
zero or more cost metrics, which are computed automatically.
A cost metric captures how close the execution is to satisfying
a given property at a given program location. Executions that
minimize a cost metric are considered optimal with respect to
that metric. For example, a cost metric could be deﬁned at each
arithmetic operation in the program such that it is minimized
(i.e., becomes zero) when an execution triggers an arithmetic
overﬂow. Our technique uses the costs that are computed with
cost metrics along executions of the program to iteratively
predict inputs leading to optimal executions.

Our experiments show that HARVEY is extremely successful
in predicting inputs that ﬂip a branch condition even in a single
iteration (success rate of 99%). This suggests a low complexity
of branch conditions in real-world smart contracts.

Although this input-prediction technique is very effective
in practice, it is not sufﬁcient for thoroughly testing a smart
contract and its state space. As a result, HARVEY generates,
executes, and fuzzes sequences of transactions, which invoke
the contract’s functions. Each of these transactions can have
side effects on the contract’s state, which may affect
the
execution of subsequent invocations. To alleviate the second
challenge of exploring the search space of all possible se-
quences, we devised a technique for demand-driven sequence
fuzzing, which avoids generating transaction sequences when
they cannot further increase coverage.

Our experiments show that 74% of bugs in real smart
contracts require generating more than one transaction to be
found. This highlights the need for techniques like ours that are
able to effectively prune the space of transaction sequences.

In total, we evaluate HARVEY on 27 Ethereum smart
contracts. Our fuzzer’s underlying techniques signiﬁcantly
increase its effectiveness in achieving high coverage (by up
to 3x) and detecting vulnerabilities, in most cases orders-of-
magnitude faster.

Contributions. We make the following contributions:

– We present HARVEY, the ﬁrst greybox fuzzer for smart
contracts, which is being used industrially by one of the
largest blockchain-security consulting companies.

– We describe our architecture and two key techniques for
alleviating the important challenges outlined above.

– We evaluate our fuzzer on 27 real-world benchmarks and
demonstrate that the underlying techniques signiﬁcantly
increase its effectiveness.

– We distill the main lessons learned from fuzzing smart-

contract code.

II. BACKGROUND

In this section, we give background on standard greybox

fuzzing and smart contracts.

A. Greybox Fuzzing

Alg. 1 shows how greybox fuzzing works. (The grey boxes
should be ignored for now.) The fuzzer takes as input the
program under test prog and a set of seeds S. It starts by
running the program with the seeds, and during each program
execution, the instrumentation is able to capture the path that
is currently being explored and associate it with a unique
identiﬁer PID (line 1). Note that the PIDs data structure is a
key-value store from a PID to an input that exercises the path
associated with PID. Next, an input is selected for mutation
(line 3), and it is assigned an “energy” value that denotes how
many times it should be fuzzed (line 5).

The input is mutated (line 12), and the program is run with
the new input (line 13). If the program follows a path that has
not been previously explored, the new input is added to the
test suite (lines 14–15). The above process is repeated until
an exploration bound is reached (line 2). The fuzzer returns a
test suite containing one test for each explored path.

B. Smart Contracts

Ethereum [18], [19] is one of the most popular blockchain-
based [20], [21], [22], distributed-computing platforms [23].
It supports two kinds of accounts, user and contract accounts,
both of which store a balance, are owned by a user, and
publicly reside on the blockchain.

In contrast to a user account, a contract account is managed
through code that is associated with it. The contract code
captures agreements between users, for example, to encode
the rules of an auction. A contract account also has persistent
state where the code may store data, such as auction bids.

Contract accounts, their code, and persistent state are called
smart contracts. Programmers may write the code in several
languages, like Solidity or Vyper, all of which compile to the
Ethereum Virtual Machine (EVM) [24] bytecode.

To interact with a contract, users issue transactions that call
its functions, for instance, to bid in an auction, and are required
to pay a fee for transactions to be executed. This fee is called
gas and is roughly proportional to how much code is run.

III. OVERVIEW

We now give an overview of our approach focusing on the

challenges we aim to alleviate.

2

1 function baz(int256 a, int256 b, int256 c)
2

returns (int256) {

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

int256 d = b + c;
minimize(d < 1 ? 1 - d : 0);
minimize(d < 1 ? 0 : d);
if (d < 1) {

minimize(b < 3 ? 3 - b : 0);
minimize(b < 3 ? 0 : b - 2);
if (b < 3) {
return 1;

}
minimize(a == 42 ? 1 : 0);
minimize(a == 42 ? 0 : |a - 42|);
if (a == 42) {
return 2;

}
return 3;

} else {

minimize(c < 42 ? 42 - c : 0);
minimize(c < 42 ? 0 : c - 41);
if (c < 42) {
return 4;

}
return 5;

}

25
26 }

Fig. 1: Example for fuzzing with input prediction.

A. Challenge #1: Random Input Mutations

Fig. 1 shows a constructed smart-contract function baz (in
Solidity) that takes as input three (256-bit) integers a, b, and
c and returns an integer. There are ﬁve paths in this function,
all of which are feasible. Each path is denoted by a unique
return value. (The grey boxes should be ignored for now.)

When running AFL, a state-of-the-art greybox fuzzer, on
(a C version of) function baz, only four out of ﬁve paths
are explored within 12h. During this time, greybox fuzzing
constructs a test suite of four inputs, each of which exploring a
different path. The path with return value 2 remains unexplored
even after the fuzzer generates about 311M different inputs.
All but four of these inputs are discarded as they exercise a
path in baz that has already been covered by a previous test.
The path with return value 2 is not covered because greybox
fuzzers randomly mutate program inputs (line 12 of Alg. 1).
It is generally challenging for fuzzers to generate inputs that
satisfy “narrow checks”, that is, checks that only become true
for very few input values (e.g., line 14 of Fig. 1). In this case,
the probability that the fuzzer will generate value 42 for input
a is 1 out of 2256 for 256-bit integers. Even worse, to cover
the path with return value 2 (line 15), the sum of inputs b and
c also needs to be less than 1 (line 6) and b must be greater
than or equal to 3 (line 9). As a result, several techniques have
been proposed to guide greybox fuzzing to satisfy such narrow
checks, e.g., by selectively applying whitebox fuzzing [25].

Fuzzing with input prediction. In contrast, our technique
for input prediction is more lightweight, without requiring
any program analysis or constraint solving. It does, however,
require additional instrumentation of the program to collect
more information about its structure than standard greybox
fuzzing, thus making fuzzing a lighter shade of grey. This
information captures the distance from an optimal execution
at various points in the program and is then used to predict

inputs that guide exploration toward optimal executions.

Our fuzzer takes as input a program prog and seeds S.
It also requires a partial function fcost that maps execution
states to cost metrics. When execution of prog reaches a state
s, the fuzzer evaluates the cost metric fcost (s). For example,
the grey boxes in Fig. 1 deﬁne a function fcost for baz. Each
minimize statement speciﬁes a cost metric at the execution
state where it is evaluated. Note that fcost constitutes a run-
time instrumentation of prog—we use minimize statements
only for illustration. A compile-time instrumentation would
increase gas usage of the contract and potentially lead to false
positives when detecting out-of-gas errors.

The cost metrics of Fig. 1 deﬁne optimal executions as those
that ﬂip a branch condition. Speciﬁcally, consider an execution
along which variable d evaluates to 0. This execution takes
the then-branch of the ﬁrst if-statement, and the cost metric
deﬁned by the minimize statement on line 4 evaluates to
1. This means that the distance of the current execution from
an execution that exercises the (implicit) else-branch of the
if-statement is 1. Now, consider a second execution that also
takes this then-branch (d evaluates to –1). In this case, the
cost metric on line 4 evaluates to 2, which indicates a greater
distance from an execution that exercises the else-branch.

Based on this information, our input-prediction technique is
able to suggest new inputs that make the execution of baz take
the else-branch of the ﬁrst if-statement and minimize the cost
metric on line 4 (i.e., the cost becomes zero). For instance,
assume that the predicted inputs cause d to evaluate to 7.
Although the cost metric on line 4 is now minimized, the cost
metric on line 5 evaluates to 7, which is the distance of the
current execution from an execution that takes the then-branch.
Similarly, the minimize statements on lines 7–8, 12–13,
and 19–20 of Fig. 1 deﬁne cost metrics that are minimized
when an execution ﬂips a branch condition in a subsequent
if-statement. This instrumentation aims to maximize path cov-
erage, and for this reason, an execution can never minimize all
cost metrics. In fact, the fuzzer has achieved full path coverage
when the generated tests cover all feasible combinations of
branches in the program; that is, when they minimize all
possible combinations of cost metrics.

The fuzzer does not exclusively rely on prediction to gen-
erate program inputs, for instance, when there are not enough
executions from which to make a good prediction. In the above
example, the inputs for the ﬁrst two executions (where d is
0 and –1) are generated by the fuzzer without prediction.
Prediction can only approximate correlations between inputs
and their corresponding costs; therefore, it is possible that
certain predicted inputs do not lead to optimal executions. In
such cases, it is also up to standard fuzzing to generate inputs
that cover any remaining paths.

For the example of Fig. 1, HARVEY explores all ﬁve paths

within 0.27s and after generating only 372 different inputs.

B. Challenge #2: State Space Exploration

Fig. 2 shows a simple contract Foo. The constructor on
line 5 initializes variables x and y, which are stored in the

3

1 contract Foo {
2

int256 private x;
int256 private y;

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22
23 }

constructor () public {

x = 0;
y = 0;

}

function Bar() public returns (int256) {

if (x == 42) {

assert(false);
return 1;

}
return 0;

}

function SetY(int256 ny) public { y = ny; }

function IncX() public { x++; }

function CopyY() public { x = y; }

Fig. 2: Example for demand-driven sequence fuzzing.

persistent state of the contract. In function Bar, the failing
assertion (line 12) denotes a bug. An assertion violation causes
a transaction to be aborted, and as a result, users lose their
gas. Triggering the bug requires a sequence of at least three
transactions, invoking functions SetY(42), CopyY(), and
Bar(). (Note that a transaction may directly invoke up to
one contract function.) The assertion violation may also be
triggered by calling IncX 42 times before invoking Bar.

There are three ways to test this contract with a standard
greybox fuzzer. First, each function could be fuzzed separately
without considering the persistent variables of the contract as
fuzzable inputs. For example, Bar would be executed only
once—it has zero fuzzable inputs. No matter the initial values
of x and y, the fuzzer would only explore one path in Bar.
Second, each function could be fuzzed separately while con-
sidering the persistent variables as fuzzable inputs. The fuzzer
would then try to explore both paths in Bar by generating
values for x and y. A problem with this approach is that the
probability of generating value 42 for x is tiny, as discussed
earlier. More importantly however, this approach might result
in false positives when the persistent state generated by the
fuzzer is not reachable with any sequence of transactions. For
example, the contract would never fail if SetY ensured that
y is never set to 42 and IncX only incremented x up to 41.
the fuzzer could try to explore all paths in all
possible sequences of transactions up to a bounded length.
This, however, means that a path would span all transactions
(instead of a single function). For example, a transaction
invoking Bar and a sequence of two transactions invoking
CopyY and Bar would exercise two different paths in the
contract, even though from the perspective of Bar this is not
the case. With this approach, the number of possible sequences
grows exponentially in their length, and so does the number
of tests in the test suite. The larger the test suite, the more
difﬁcult it becomes to ﬁnd a test that, when fuzzed, leads to
the assertion in Foo, especially within a certain time limit.

Third,

4

We propose a technique for demand-driven sequence
fuzzing that alleviates these limitations. First, it discovers that
the only branch in Foo that requires more than a single
transaction to be covered is the one leading to the assertion
in Bar. Consequently, HARVEY only generates transaction
sequences whose last transaction invokes Bar. Second, our
technique aims to increase path coverage only of the function
that is invoked by this last transaction. In other words, the
goal of any previous transactions is to set up the state, and
path identiﬁers are computed only for the last transaction.
Therefore, reaching the assertion in Bar by ﬁrst calling
SetY(42) and CopyY() or by invoking IncX() 42 times
both result in covering the same path of the contract.

HARVEY triggers the above assertion violation in about 18s.

IV. FUZZING WITH INPUT PREDICTION

In this section, we present the technical details of how we

extend greybox fuzzing with input prediction.

A. Algorithm

The grey boxes in Alg. 1 indicate the key differences. In
addition to the program under test prog and a set of seeds
S, Alg. 1 takes as input a partial function fcost
that, as
explained earlier, maps execution states to cost metrics. The
fuzzer ﬁrst runs the program with the seeds, and during each
program execution, it evaluates the cost metric fcost (s) for
every encountered execution state s in the domain of fcost
(line 1). Like in standard greybox fuzzing, each explored path
is associated with a unique identiﬁer PID. Note, however,
that the PIDs data structure now maps a PID both to an
input that exercises the corresponding path as well as to a
cost vector, which records all costs computed during execution
of the program with this input. Next, an input is selected for
mutation (line 3) and assigned an energy value (line 5).

The input is mutated (line 12), and the program is run with
the new input (line 13). We assume that the new input differs
from the original input (which was selected for mutation on
line 3) by the value of a single input parameter—an assumption
that typically holds for mutation-based greybox fuzzers. As
usual, if the program follows a path that has not been explored,
the new input is added to the test suite (lines 14–15).

On line 17,

the original and the new input are passed
to the prediction component of the fuzzer along with their
cost vectors. This component inspects input and input(cid:48) to
determine the input parameter by which they differ. Based on
the cost vectors, it then suggests a new value for this input
parameter such that one of the cost metrics is minimized. In
case a new input is predicted, the program is tested with this
input, otherwise the original input is mutated (lines 8–10). The
former happens even if the energy of the original input has run
out (line 7) to ensure that we do not waste predicted inputs.
The above process is repeated until an exploration bound is
reached (line 2), and the fuzzer returns a test suite containing
one test for each program path that has been explored.

Example. In Tab. I, we run our algorithm on the example
of Fig. 1 step by step. The ﬁrst column of the table shows

Algorithm 1: Greybox fuzzing with input prediction.
Input: Program prog, Seeds S, Cost function fcost

1 PIDs ← RUNSEEDS(S, prog, fcost )
2 while ¬INTERRUPTED() do
3

input, cost ← PICKINPUT(PIDs)
energy ← 0

4
5 maxEnergy ← ASSIGNENERGY(input)

6

7

8

9

10

11

12

13

14

15

16

17

18

predictedInput ← nil
while energy < maxEnergy ∨ predictedInput (cid:54)= nil do

if predictedInput (cid:54)= nil then
input (cid:48) ← predictedInput
predictedInput ← nil

else

input (cid:48) ← FUZZINPUT(input)

PID (cid:48), cost (cid:48) ← RUN(input (cid:48), prog, fcost )
if ISNEW(PID (cid:48), PIDs) then

PIDs ← ADD(PID (cid:48), input (cid:48), cost (cid:48), PIDs)

if energy < maxEnergy then

predictedInput ← PREDICT(input, cost, input (cid:48), cost (cid:48))

energy ← energy + 1

Output: Test suite INPUTS(PIDs)

an identiﬁer for every generated test, and the second column
shows the path that each test exercises identiﬁed by the
return value of the program. The highlighted boxes in this
column denote paths that are covered for the ﬁrst time, which
means that the corresponding tests are added to the test suite
(lines 14–15 of Alg. 1). The third column shows the test
identiﬁer from which the value of variable input is selected
(line 3 of Alg. 1). Note that, according to the algorithm, input
is selected from tests in the test suite.

The fourth column shows a new input for the program under
test; this input is either a seed or the value of variable input (cid:48) in
the algorithm, which is obtained with input prediction (line 9)
or fuzzing (line 12). Each highlighted box in this column
denotes a predicted value. The ﬁfth column shows the cost
vector that is computed when running the program with the
new input of the fourth column. Note that we show only
non-zero costs and that the subscript of each cost denotes
the line number of the corresponding minimize statement
in Fig. 1. The sixth column shows which costs (if any) are
used to predict a new input, and the last column shows the
current energy value of the algorithm’s input (lines 4 and 18).
For simplicity, we consider maxEnergy of Alg. 1 (line 5)
to always have value 2 in this example. Our implementation,
however, incorporates an existing energy schedule [14].

We assume that the set of seeds S contains only the random
input (a = −1, b = 0, c = −5) (test #1 in Tab. I). This input
is then fuzzed to produce (a = −1, b = −3, c = −5) (test
#2), that is, to produce a new value for input parameter b. Our
algorithm uses the costs computed with metric C7 to predict
a new value for b. (We explain how new values are predicted
in the next subsection.) As a result, test #3 exercises a new
path of the program (the one with return value 3). From the
cost vectors of tests #1 and #3, only the costs computed with
metric C4 may be used to predict another value for b; costs C7
and C8 are already zero in one of the two tests, while metric
C13 is not reached in test #1. Even though the energy of the
original input (from test #1) has run out, the algorithm still

5

TEST

PATH

INPUT
FROM TEST

NEW INPUT
b

c

a

1

2

3

4

5

6

7

8

1

1

3

4

3

2

4

5

–

1

1

1

3

3

4

4

−1

0

−5

−1 −3 −5

−1

−1

7

42

−1

−1

3

6

3

3

6

6

−5

−5

−5

−5

0

42

COSTS

C4 = 6
C7 = 3
C4 = 9
C7 = 6
C4 = 3
C8 = 1
C13 = 43
C5 = 1
C19 = 47
C4 = 3
C8 = 1
C13 = 35
C4 = 3
C8 = 1
C12 = 1
C5 = 6
C19 = 42
C5 = 48
C20 = 1

PREDICTION
COST

ENERGY

–

C7

C4

–

C13

–

C19

–

–

0

1

2

0

1

0

1

Table I: Running Alg. 1 on the example of Fig. 1.

runs the program with the input predicted from the C4 costs
(line 7). This results in covering the path with return value 4.
Next, we select an input from tests #1, #3, or #4 of the test
suite. Let’s assume that the fuzzer picks the input from test #3
and mutates the value of input parameter a. Note that the cost
vectors of tests #3 and #5 differ only with respect to the C13
costs, which are therefore used to predict a new input for a.
The new input exercises a new path of the program (the one
with return value 2). At this point, the cost vectors of tests
#3 and #6 cannot be used for prediction because the costs are
either the same (C4 and C8) or they are already zero in one of
the two tests (C12 and C13). Since no input is predicted and
the energy of the original input (from test #3) has run out, our
algorithm selects another input from the test suite.

This time, let’s assume that the fuzzer picks the input from
test #4 and mutates the value of input parameter c. From the
cost vectors of tests #4 and #7, it randomly selects the C19
costs for predicting a new value for c. The predicted input
exercises the ﬁfth path of the program, thus achieving full
path coverage of function baz by generating only 8 tests.

Note that our algorithm makes several non-systematic
choices, which may be random or based on heuristics, such as
when function PICKINPUT picks an input from the test suite,
when FUZZINPUT selects which input parameter to fuzz, or
when PREDICT decides which costs to use for prediction. For
illustrating how the algorithm works, we made “good” choices
such that all paths are exercised with a small number of tests.
In practice, the fuzzer achieved full path coverage of function
baz with 372 tests, instead of 8, as we discussed in Sect. III-A.

B. Input Prediction

Our algorithm passes to the prediction component the input
vectors input and input (cid:48) and the corresponding cost vectors
cost and cost (cid:48) (line 17 of Alg. 1). The input vectors differ by
the value of a single input parameter, say i0 and i1. Now, let
us assume that the prediction component selects a cost metric
to minimize and that the costs that have been evaluated using
this metric appear as c0 and c1 in the cost vectors. This means
that cost c0 is associated with input value i0, and c1 with i1.
As an example, let us consider tests #3 and #5 from Tab. I.
The input vectors differ by the value of input parameter a, so
i0 = −1 (value of a in test #3) and i1 = 7 (value of a in test

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

#5). The prediction component chooses to make a prediction
based on cost metric C13 since the cost vectors of tests #3 and
#5 differ only with respect to this metric, so c0 = 43 (value
of C13 in test #3) and c1 = 35 (value of C13 in test #5).

Using the two data points (i0, c0) and (i1, c1), the goal is
to ﬁnd a value i such that the corresponding cost is zero. In
other words, our technique aims to ﬁnd a root of the unknown,
but computable, function that relates input parameter a to
cost metric C13. While there is a wide range of root-ﬁnding
algorithms, HARVEY uses the Secant method. Like other
methods, such as Newton’s, the Secant method tries to ﬁnd
a root by performing successive approximations.

Its basic approximation step considers the two data points as
x-y-coordinates on a plane. Our technique then ﬁts a straight
line c(i) = m ∗ i + k through the points, where m is the slope
of the line and k is a constant. To predict the new input value,
it determines the x-coordinate i where the line intersects with
the x-axis (i.e., where the cost is zero).

From the points (−1, 43) and (7, 35) deﬁned by tests #3 and
#5, we compute the line to be c(i) = −i + 42. Now, for the
cost to be zero, the value of parameter a must be 42. Indeed,
when a becomes 42 in test #6, cost metric C13 is minimized.
This basic approximation step is precise if the target cost
metric is indeed linear (or piece-wise linear) with the input
parameter for which we are making a prediction. If not, the
approximation may fail to minimize the cost metric. In such
cases, HARVEY applies the basic step iteratively (as the Secant
method). Our experiments show that one iteration is typically
sufﬁcient for real contracts.

C. Cost Metrics

We now describe the different cost metrics that our fuzzer
aims to minimize: (1) ones that are minimized when execution
ﬂips a branch condition, and (2) ones that are minimized when
execution is able to modify arbitrary memory locations.

Branch conditions. We have already discussed cost metrics
that are minimized when execution ﬂips a branch condition in
the example of Fig. 1. Here, we show how the cost metrics
are automatically derived from the program under test.

For the comparison operators == (eq), < (lt), and <= (le),

we deﬁne the following cost functions:

Ceq (l, r) =

Clt (l, r) =

Cle (l, r) =

1,
0,

l = r
l (cid:54)= r

r − l,
0,

l < r
l ≥ r

(cid:40)

(cid:40)

(cid:40)

Ceq (l, r) =

Clt (l, r) =

0,
|l − r|,

l = r
l (cid:54)= r

0,
l − r + 1,

l < r
l ≥ r

(cid:40)

(cid:40)

(cid:40)

r − l + 1,
0,

l ≤ r
l > r

Cle (l, r) =

0,
l − r,

l ≤ r
l > r

Function Ceq from above is non-zero when a branch condition
l == r holds;
it deﬁnes the cost metric for making this
condition false. On the other hand, function Ceq deﬁnes the
cost metric for making the same branch condition true. The
arguments l and r denote the left and right operands of the
operator. The notation is similar for all other functions.

Based on these cost functions, our instrumentation evaluates
two cost metrics before every branch condition in the program

6

1 contract Wallet {
2

address private owner;
uint[] private bonusCodes;

constructor() public {
owner = msg.sender;
bonusCodes = new uint[](0);

}

function() public payable { }

function PushCode(uint c) public {

bonusCodes.push(c);

}

function PopCode() public {

require(0 <= bonusCodes.length);
bonusCodes.length--;

}

function SetCodeAt(uint idx, uint c) public {

require(idx < bonusCodes.length);
minimize(|&(bonusCodes[idx]) - 0xffcaffee|);
bonusCodes[idx] = c;

}

function Destroy() public {

require(msg.sender == owner);
selfdestruct(msg.sender);

}

30
31 }

Fig. 3: Example of a memory-access vulnerability.

under test. The metrics that are evaluated depend on the
comparison operator used in the branch condition. The cost
functions for other comparison operators, i.e., != (ne), > (gt),
and >= (ge), are easily derived from the functions above, and
our tool supports them. Note that our implementation works
on the bytecode, where logical operators, like && or ||, are
expressed as branch conditions. We, thus, do not deﬁne cost
functions for such operators, but they are also straightforward.
Observe that the inputs of the above cost functions are the
operands of comparison operators, and not program inputs.
This makes the cost functions precise, that is, when a cost
is minimized, the corresponding branch is deﬁnitely ﬂipped.
Approximation can only be introduced when computing the
correlation between a program input and a cost (Sect. IV-B).
Memory accesses. To illustrate the ﬂexibility of our cost
metrics, we now show another instantiation that
targets a
vulnerability speciﬁc to smart contracts. Consider the example
in Fig. 3. (The grey box should be ignored for now.) It is
a simpliﬁed version of code submitted to the Underhanded
Solidity Coding Contest (USCC) in 2017 [26]. The USCC
is a contest to write seemingly harmless Solidity code that,
however, disguises unexpected vulnerabilities.

The contract of Fig. 3 implements a wallet that has an
owner and stores an array (with variable length) of bonus codes
(lines 2–3). The constructor (line 5) initializes the owner to the
caller’s address and the bonus codes to an empty array. The
empty function (line 10) ensures that assets can be payed to the
wallet. The other functions allow bonus codes to be pushed,
popped, or updated. The last function (line 27) must be called
only by the owner and causes the wallet to self-destruct—to

transfer all assets to the owner and destroy itself.

The vulnerability in this code is caused by the precondition
on line 17, which should require the array length to be greater
than zero (not equal) before popping an element. When the
array is empty, the statement on line 18 causes the (unsigned)
array length to underﬂow; this effectively disables the bound-
checks of the array, allowing elements to be stored anywhere
in the persistent state of the contract. Therefore, by setting a
bonus code at a speciﬁc index in the array, an attacker could
overwrite the address of the owner to their own address. Then,
by destroying the wallet, the attacker would transfer all assets
to their account. In a more optimistic scenario, the owner could
be accidentally set to an invalid address, in which case the
assets in the wallet would become inaccessible.

To detect such vulnerabilities, a greybox fuzzer can, for
every assignment to the persistent state of a contract, pick
an arbitrary address and compare it to the target address of
the assignment. When these two addresses happen to be the
same, it is very likely that the assignment may also target
other arbitrary addresses, perhaps as a result of an exploit. A
fuzzer without input prediction, however, is only able to detect
these vulnerabilities by chance, and chances are extremely low
that the target address of an assignment matches an arbitrarily
these are 32 bytes
selected address, especially given that
long. In fact, when disabling HARVEY’s input prediction, the
vulnerability in the code of Fig. 3 is not detected within 12h.
To direct the fuzzer toward executions that could reveal such

vulnerabilities, we deﬁne the following cost function:

Cst (lhsAddr , addr ) = |lhsAddr − addr |

Here, lhsAddr denotes the address of the left-hand side of an
assignment to persistent state (that is, excluding assignments to
local variables) and addr an arbitrary address. Function Cst is
non-zero when lhsAddr and addr are different, and therefore,
optimal executions are those where the assignment writes to
the arbitrary address, potentially revealing a vulnerability.

Our instrumentation evaluates the corresponding cost metric
before every assignment to persistent state in the program
under test. An example is shown on line 23 of Fig. 3. (We use
the & operator to denote the address of bonusCodes[idx],
and we do not show the instrumentation at every assignment
to avoid clutter.) Our fuzzer with input prediction detects the
vulnerability in the contract of Fig. 3 within a few seconds.

Detecting such vulnerabilities based on whether an assign-
ment could target an arbitrary address might generate false
positives when the address is indeed an intended target of
the assignment. However, the probability of this occurring in
practice is extremely low (again due to the address length). We
did not encounter any false positives during our experiments.
In general, deﬁning other cost functions is straightforward
as long as there is an expressible measure for the distance
between a current execution and an optimal one.

V. DEMAND-DRIVEN SEQUENCE FUZZING

Recall from Sect. III-B that HARVEY uses demand-driven
sequence fuzzing to set up the persistent state for testing the

last transaction in the sequence. The goal is to explore new
paths in the function that this transaction invokes, and thus,
detect more bugs. As explained earlier, directly fuzzing the
state, for instance, variables x and y of Fig. 2, might lead
to false positives. Nonetheless, HARVEY uses this aggressive
approach when fuzzing transaction sequences to determine
whether a different persistent state can increase path coverage.
The key idea is to generate longer transaction sequences on
demand. This is achieved by fuzzing a transaction sequence in
two modes: regular, which does not directly fuzz the persistent
state, and aggressive, which is enabled with probability 0.125
and may fuzz the persistent state directly. If HARVEY is able to
increase coverage of the last transaction in the sequence using
the aggressive mode, the corresponding input is discarded
(because it might lead to false positives), but longer sequences
are generated when running in regular mode in the future.

For instance, when fuzzing a transaction that invokes Bar
from Fig. 2, HARVEY temporarily considers x and y as
fuzzable inputs of the function. If this aggressive fuzzing
does not discover any more paths, then HARVEY does not
generate additional transactions before the invocation of Bar.
If, however, the aggressive fuzzing does discover new paths,
our tool generates and fuzzes transaction sequences whose last
transaction calls Bar. That is, longer transaction sequences
are only generated when they might be able to set up the state
before the last transaction such that its coverage is increased.
sequence
SetY(42), CopyY(), and Bar() that reaches the assertion
in about 18s. At this point, the fuzzer stops exploring longer
sequences for contract Foo because aggressively fuzzing the
state cannot further increase the already achieved coverage.

example, HARVEY generates

For our

the

We make two important observations. First, HARVEY is so
quick in ﬁnding the right argument for SetY due to input
prediction. Second, demand-driven sequence fuzzing relies on
path identiﬁers to span no more than a single transaction.
Otherwise, aggressive fuzzing would not be able to determine
if longer sequences may increase coverage of the contract.

Mutation operations. To generate and fuzz sequences of
transactions, HARVEY applies three mutation operations to a
given transaction t: (1) fuzz transaction t, which fuzzes the
inputs of its invocation, (2) insert a new transaction before t,
and (3) replace the transactions before t with another sequence.
HARVEY uses two pools for efﬁciently generating new
transactions or sequences, respectively. These pools store
transactions or sequences that are found both to increase
coverage of the contract under test and to modify the persistent
state in a way that has not been explored before. HARVEY
selects new transactions or sequences from these pools when
applying the second and third mutation operations.

VI. EXPERIMENTAL EVALUATION

In this section, we evaluate HARVEY on real-world smart
contracts. First, we explain the benchmark selection and setup.
We then compare different HARVEY conﬁgurations to assess
the effectiveness of our two fuzzing techniques. At the same
time, we highlight key insights about smart-contract code.

7

BIDs
1
2–3
4–5
6
7
8
9
10–13

Name
ENS
CMSW
GMSW
BAT
CT
ERCF
FBT
HPN
14 MR
15 MT
16
PC
RNTS
17–18
DAO
19
20
VT
USCC1
21
USCC2
22
USCC3
23
USCC4
24
USCC5
25
PW
26
BNK
27

Total

Functions
24
49
49
23
12
19
34
173
25
38
7
49
23
18
4
14
21
7
10
19
44
662

Description

ENS domain name auction
ConsenSys multisig wallet
Gnosis multisig wallet
BAT token (advertising)
ConsenSys token library
ERC Fund (investment fund)
FirstBlood token (e-sports)
Havven payment network

LoSC
1205
503
704
191
200
747
385
3065
1053 MicroRaiden payment service
437 MOD token (supply-chain)
69
749
783
242
57
89
535
164
188
549
649
12564

Payment channel
Request Network token sale
The DAO organization
Valid token (personal data)
USCC’17 entry
USCC’17 (honorable mention)
USCC’17 (3rd place)
USCC’17 (1st place)
USCC’17 (2nd place)
Parity multisig wallet
Bankera token

Table II: Overview of benchmarks.

A. Benchmark Selection

We collected all contracts from 17 GitHub repositories. We
selected the repositories based on two main criteria to obtain
a diverse set of benchmarks. On one hand, we picked popular
projects in the Ethereum community (e.g., the Ethereum Name
Service auction, the ConsenSys wallet, and the MicroRaiden
payment service) and with high popularity on GitHub (4’857
stars in total on 2019-05-07, median 132). Most contracts in
these projects have been reviewed by independent auditors
and are deployed on the Ethereum blockchain, managing
signiﬁcant amounts of crypto-assets on a daily basis. On the
other hand, we also selected repositories from a wide range
of application domains (e.g., auctions, token sales, payment
networks, and wallets) to cover various features of the EVM
and Solidity. We also included contracts that had been hacked
in the past (The DAO and the Parity wallet) and ﬁve contracts
(incl. the four top-ranked entries) from the repository of the
USCC to consider some malicious or buggy contracts.

From each of the selected repositories, we identiﬁed one
or more main contracts that would serve as contracts under
test, resulting in a total of 27 benchmarks. Note that many
repositories contain several contracts (including libraries) to
implement a complex system, such as an auction. Tab. II
gives an overview of all benchmarks and the projects from
which they originate. The ﬁrst column lists the benchmark
IDs and the second the project name. The third and fourth
columns show the number of public functions and the lines of
Solidity source code (LoSC) in each benchmark. The appendix
provides details about the tested changesets.

To select our benchmarks, we followed published guidelines
on evaluating fuzzers [27]. We do not simply scrape contracts
from the blockchain since most are created with no quality
control and many contain duplicates—contracts without assets
or users are essentially dead code. Moreover, good-quality
contracts typically have dependencies (e.g., on libraries or
other contracts) that would likely not be scraped with them.
In terms of size, note that most contracts are a few hundred
lines of code. Nonetheless, they are complex programs, each
least a couple of auditors for weeks. More
occupying at

8

importantly,
their size does not necessarily represent how
difﬁcult it is for a fuzzer to test all paths. For instance, Fig. 1
is very small, but AFL fails to cover all paths within 12h.

B. Experimental Setup

We ran different conﬁgurations of HARVEY and compared

the achieved coverage and required time to detect a bug.

For simplicity, our evaluation focuses on detecting two types
of bugs. First, we detect crashes due to assertion violations
(SWC-110 according to the Smart Contract Weakness Classiﬁ-
cation [28]); in addition to user-provided checks, these include
checked errors, such as division by zero or out-of-bounds array
access, inserted by the compiler. At best, these bugs cause a
transaction to be aborted and waste gas fees. In the worst
case, they prevent legitimate transactions from succeeding,
putting assets at risk. For instance, a user may not be able
to claim an auctioned item due to an out-of-bounds error in
the code that iterates over an array of bidders to determine
the winner. Second, we detect memory-access errors (SWC-
124 [28]) that may allow an attacker to modify the persistent
state of a contract (Fig. 3). In practice, HARVEY covers a wide
range of test oracles1, such as reentrancy and overﬂows.

For bug de-duplication, it uses a simple approach (much
more conservative than AFL): two bugs of the same type are
duplicates if they occur at the same program location.

For each conﬁguration, we performed 24 runs, each with
independent random seeds, an all-zero seed input, and a time
limit of one hour; we report medians unless stated otherwise.
In addition, we performed Wilcoxon-Mann-Whitney U tests to
determine if differences in medians are statistically signiﬁcant
and report the computed p-values.

We used an Intel® Xeon® CPU @ 2.90GHz 36-core

machine with 60GB running Ubuntu 18.04.

C. Results

We assess HARVEY’s effectiveness by evaluating three
research questions. The ﬁrst two focus on our input-prediction
technique and the third on demand-driven sequence fuzzing.
Our baselines implement standard greybox fuzzing within
HARVEY. Since there are no other greybox fuzzers for smart
contracts, we consider these suitable. Related work (e.g.,
[29], [30]) either uses fundamentally different bug-ﬁnding
techniques (like blackbox fuzzing or symbolic execution) or
focuses on detecting different types of bugs. Our evaluation
aims to demonstrate improvements over standard greybox
fuzzing, the beneﬁts of which have been shown independently.
RQ1: Effectiveness of input prediction. To evaluate input
prediction, we compare with a baseline (conﬁguration A),
which only disables prediction. The ﬁrst column of Tab. III
identiﬁes the benchmark, the second the bug, and the third
the bug type according to the SWC (110 stands for assertion
violations and 124 for memory-access errors).

The fourth and ﬁfth columns show the median time (in
secs) after which each unique bug was found by conﬁgurations

1SWC-101, 104, 107, 110, 123, 124, 127

BID
2
2
3
3
4
4
5
5
8
13
13
13
13
15
15
15
15
17
18
18
19
19
19
19
19
19
19
22
22
23
23
24
24
24
24
24
24
24
24
26
27
27
27
27
27
27
27

Bug ID
990d9524
b4f9a3d6
c56e90ab
cb2847d0
306fa4fe
57c85623
51444152
f6ee56cd
c9c0b2f4
341911e4
1cd27b5d
26aee7ba
d7d04622
dec48390
193c72a2
7c3dd9f4
65aa7261
21646ab7
3021c487
ed97030c
e3468a11
b359efbc
9e65397d
4063c80f
49e4a70e
ee609ac1
21f5c23f
f3bf5e12
577a74af
1c8acd5e
fda2cafa
c837a34b
d602954b
863f9452
9774d846
123bf172
a97971ca
9a771b96
dc7bf682
ccf7bc67
f1c8e169
44312719
33c32ef9
d499f535
4fb4fa53
47c60a93
6f92fdea

Median

SWC ID
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-124
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110

TA
22.27
41.59
8.83
13.56
34.47
17.34
11.79
14.85
3600.00
21.27
30.56
20.23
18.42
2823.62
3600.00
3600.00
3600.00
3600.00
9.59
3600.00
7.98
8.63
22.86
20.45
55.38
16.13
23.72
13.13
3600.00
3600.00
3600.00
1.85
3.97
4.76
14.41
238.63
145.79
69.35
3600.00
61.42
112.98
77.18
60.52
3600.00
3600.00
3600.00
3600.00
41.59

TB
0.21
1.27
0.21
0.85
2.62
0.16
0.14
1.14
90.66
4.19
4.60
4.11
4.14
1779.98
17.65
221.12
3600.00
273.17
0.54
3600.00
0.12
0.09
0.47
0.46
2.55
0.71
2.52
0.40
899.60
193.66
218.57
0.04
0.12
0.18
0.43
3.01
4.43
3.62
0.69
1.68
16.26
1.50
1.08
7.36
67.29
141.16
3600.00
2.55

TA/TB
107.35
32.80
42.40
15.95
13.16
106.62
83.23
13.09
39.71
5.07
6.65
4.92
4.45
1.59
204.02
16.28
1.00
13.18
17.68
1.00
64.62
94.28
48.96
44.45
21.70
22.73
9.40
33.05
4.00
18.59
16.47
42.33
34.30
25.96
33.43
79.22
32.90
19.14
5246.66
36.59
6.95
51.36
56.25
489.38
53.50
25.50
1.00
25.96

p
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.362
0.000
0.000
0.338
0.000
0.000
0.917
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.041

A12A
0.00
0.05
0.00
0.04
0.04
0.00
0.00
0.06
0.00
0.05
0.05
0.05
0.06
0.42
0.00
0.04
0.48
0.02
0.03
0.51
0.00
0.01
0.01
0.00
0.05
0.00
0.07
0.07
0.04
0.00
0.00
0.01
0.01
0.04
0.05
0.04
0.05
0.03
0.00
0.01
0.16
0.01
0.07
0.00
0.00
0.02
0.42

A12B
1.00
0.95
1.00
0.96
0.96
1.00
1.00
0.94
1.00
0.95
0.95
0.95
0.94
0.58
1.00
0.96
0.52
0.98
0.97
0.49
1.00
0.99
0.99
1.00
0.95
1.00
0.93
0.93
0.96
1.00
1.00
0.99
0.99
0.96
0.95
0.96
0.95
0.97
1.00
0.99
0.84
0.99
0.93
1.00
1.00
0.98
0.58

Table III: Comparing time-to-bug between conﬁguration
A (w/o input prediction) and B (w/ input prediction).

A and B within the time limit—B differs from A only by
enabling input prediction. Conﬁguration B ﬁnds 43 out of
47 bugs signiﬁcantly faster than A. We report the speed-up
factor in the sixth column and the signiﬁcance level, i.e.,
p-value, in the seventh (we use p < 0.05). As shown in
the table, conﬁguration B is faster than A by a factor of
up to 5’247 (median 25.96). The last two columns compute
the Vargha-Delaney A12 effect sizes [31]. Intuitively, these
show the probability of conﬁguration A being faster than B
and vice versa. Note that, to compute the median time, we
conservatively counted 3’600s for a given run even if the bug
was not found. However, on average, B detects 10 more bugs.
Tab. IV compares A and B with respect to instruction cov-
erage. For 23 out of 27 benchmarks, B achieves signiﬁcantly
higher coverage. The results for path coverage are very similar.

Input prediction is very effective in both detecting
bugs faster and achieving higher coverage.

RQ2: Effectiveness of iterative input prediction. Con-
ﬁguration C differs from B in that it does not iteratively
apply the basic approximation step of the Secant method in
case it fails to minimize a cost metric. For artiﬁcial examples
with non-linear branch conditions (e.g., aˆ4 + aˆ2 ==

BID

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
Median

CA
3868.00
3064.00
2575.00
2791.00
2567.00
1832.00
1524.00
1051.00
2694.00
6833.00
7295.00
2816.00
1585.00
3822.00
3489.00
496.00
1832.00
2766.00
2411.00
1635.00
349.00
919.00
1344.00
687.00
1082.00
1606.00
4232.00
2411.00

CB
3868.00
4005.50
3487.00
3773.00
3501.00
1949.00
1524.00
2205.00
3468.00
7360.50
8716.00
5165.00
4510.00
4655.00
5078.50
496.00
2754.00
2930.00
2611.00
3018.00
434.00
1274.00
2095.00
754.00
1192.00
1606.00
5499.50
3018.00

CB/CA
1.00
1.31
1.35
1.35
1.36
1.06
1.00
2.10
1.29
1.08
1.19
1.83
2.85
1.22
1.46
1.00
1.50
1.06
1.08
1.85
1.24
1.39
1.56
1.10
1.10
1.00
1.30
1.29

p
0.010
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.001
0.000
0.000
0.000

A12A
0.38
0.00
0.00
0.00
0.00
0.00
0.50
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.50
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.22
0.00
0.50
0.00

A12B
0.62
1.00
1.00
1.00
1.00
1.00
0.50
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00
0.50
1.00
1.00
1.00
1.00
1.00
1.00
1.00
0.78
1.00
0.50
1.00

Table IV: Comparing instruction coverage for conﬁgura-
tions A (w/o input prediction) and B (w/ input prediction).

228901770), we were able to show that this conﬁguration is
less efﬁcient than B in ﬁnding bugs. However, for our bench-
marks, there were no signiﬁcant time differences between B
and C for detecting 45 of 47 bugs. Similarly, there were no
signiﬁcant differences in instruction coverage.

During our experiments with C, we measured the success
rate of one-shot cost minimization to range between 97%
and 100% (median 99%). This suggests that complex branch
conditions are not very common in real-world smart contracts.

Even one iteration of the Secant method is extremely
successful in predicting inputs. This suggests that the
vast majority of branch conditions are linear (or piece-
wise linear) with respect to the program inputs.

RQ3: Effectiveness of demand-driven sequence fuzzing.
To evaluate this research question, we compare conﬁguration
A with D, which differs from A by disabling demand-driven
sequence fuzzing. In particular, D tries to eagerly explore all
paths in all possible transaction sequences, where paths span
all transactions. Tab. V shows a comparison between A and D
with respect to time-to-bug for bugs that were found by at least
one conﬁguration. As shown in the table, A is signiﬁcantly
faster than D in detecting 7 out of 35 bugs, with a speed-up
of up to 20x. Note that all 7 bugs require more than a single
transaction to be detected. Instruction coverage is very similar
between A and D (slightly higher for A), but A achieves it
within a fraction of the time for 19 out of 27 benchmarks.

In total, 26 out of 35 bugs require more than one transaction
to be found. This suggests that real contracts need to be
tested with sequences of transactions, and consequently, there
is much to be gained from pruning techniques like ours. Our
experiments with D also conﬁrm that, when paths span all
transactions, the test suite becomes orders-of-magnitude larger.

9

BID
2
2
3
3
4
4
5
5
13
13
13
13
15
18
18
19
19
19
19
19
19
19
22
24
24
24
24
24
24
24
26
27
27
27
27

Bug ID
990d9524
b4f9a3d6
c56e90ab
cb2847d0
306fa4fe
57c85623
51444152
f6ee56cd
341911e4
1cd27b5d
26aee7ba
d7d04622
dec48390
3021c487
ed97030c
e3468a11
b359efbc
9e65397d
4063c80f
49e4a70e
ee609ac1
21f5c23f
f3bf5e12
c837a34b
d602954b
863f9452
9774d846
123bf172
a97971ca
9a771b96
ccf7bc67
f1c8e169
44312719
33c32ef9
47c60a93

Median

SWC ID
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110
SWC-110

TA
22.27
41.59
8.83
13.56
34.47
17.34
11.79
14.85
21.27
30.56
20.23
18.42
2823.62
9.59
3600.00
7.98
8.63
22.86
20.45
55.38
16.13
23.72
13.13
1.85
3.97
4.76
14.41
238.63
145.79
69.35
61.42
112.98
77.18
60.52
3600.00
21.27

TD
15.85
66.31
8.63
12.72
59.90
14.96
12.01
17.69
25.28
28.54
23.12
19.05
3600.00
9.84
3600.00
5.96
8.25
22.06
15.82
55.67
19.45
16.43
9.46
1.98
4.56
4.46
12.72
3600.00
2946.47
1087.31
426.17
504.67
522.75
83.35
3600.00
19.45

TA/TD
1.41
0.63
1.02
1.07
0.58
1.16
0.98
0.84
0.84
1.07
0.87
0.97
0.78
0.97
1.00
1.34
1.05
1.04
1.29
0.99
0.83
1.44
1.39
0.94
0.87
1.07
1.13
0.07
0.05
0.06
0.14
0.22
0.15
0.73
1.00
0.97

p
0.415
0.529
0.643
0.749
0.477
0.942
0.585
0.529
0.749
0.359
0.571
0.942
0.000
0.338
0.028
0.439
0.288
0.781
0.177
0.585
0.877
0.718
0.718
0.673
0.877
0.959
0.845
0.001
0.005
0.010
0.000
0.002
0.018
0.464
0.026

A12A
0.43
0.55
0.46
0.53
0.56
0.49
0.55
0.55
0.53
0.58
0.55
0.51
0.84
0.58
0.65
0.43
0.41
0.52
0.39
0.55
0.51
0.47
0.47
0.54
0.51
0.51
0.48
0.77
0.74
0.72
0.80
0.76
0.70
0.56
0.65

A12D
0.57
0.45
0.54
0.47
0.44
0.51
0.45
0.45
0.47
0.42
0.45
0.49
0.16
0.42
0.35
0.57
0.59
0.48
0.61
0.45
0.49
0.53
0.53
0.46
0.49
0.49
0.52
0.23
0.26
0.28
0.20
0.24
0.30
0.44
0.35

Table V: Comparing time-to-bug between conﬁguration A
(w/ demand-driven sequence fuzzing) and D (w/o demand-
driven sequence fuzzing).

Demand-driven sequence fuzzing is effective in prun-
ing the search space of transaction sequences; as a
result, it detects bugs and achieves coverage faster.
Such techniques are useful since most bugs require
invoking multiple transactions to be revealed.

D. Threats to Validity

External validity. Our results may not generalize to all
smart contracts or program types [32]. However, we evaluated
our technique on a diverse set of contracts from a wide range
of domains. We, thus, believe that our selection signiﬁcantly
helps to ensure generalizability. To further improve external
validity, we also provide the versions of all contracts in
the appendix. Moreover, our comparisons focus on a single
fuzzer—we discuss this below.

Internal validity. Another potential issue has to do with
whether systematic errors are introduced in the setup [32].
When comparing conﬁgurations, we always used the same
seed inputs in order to avoid bias in the exploration.

Construct validity. Construct validity ensures that the eval-
uation measures what it claims. We compare several conﬁgura-
tions of HARVEY, and thus, ensure that any improvements are
exclusively due to techniques enabled in a given conﬁguration.

VII. RELATED WORK

HARVEY is the ﬁrst greybox fuzzer for smart contracts. It
incorporates two key techniques, input prediction and demand-
driven sequence fuzzing, that improve its effectiveness.

Greybox fuzzing. There are several techniques that aim to
direct greybox fuzzing toward certain parts of the search space,

such as low-frequency paths [14], vulnerable paths [15], deep
paths [16], or speciﬁc sets of program locations [17]. There
are also techniques that boost fuzzing by smartly selecting
and mutating inputs [33], [34], [35], or by searching for new
inputs using iterative optimization algorithms, such as gradient
descent [36], with the goal of increasing branch coverage.

In general, input prediction could be used in combination
with these techniques. In comparison, our approach predicts
concrete input values based on two previous executions. To
achieve this, we rely on additional, but still
lightweight,
instrumentation.

Whitebox fuzzing. Whitebox fuzzing is implemented in
many tools, such as EXE [37], jCUTE [38], Pex [39], Bit-
Blaze [40], Apollo [41], S2E [42], and Mayhem [43], and
comes in different ﬂavors, such as probabilistic symbolic
execution [44] or model-based whitebox fuzzing [45].

As discussed earlier, our input-prediction technique does
not rely on any program analysis or constraint solving, and
our instrumentation is more lightweight, for instance, we do
not keep track of a symbolic store and path constraints.

Hybrid fuzzing. Hybrid fuzzers combine fuzzing with other
techniques to join their beneﬁts and achieve better results. For
example, Dowser [46] uses static analysis to identify code re-
gions with potential buffer overﬂows. Similarly, BuzzFuzz [12]
uses taint tracking to discover which input bytes ﬂow to “attack
points”. Hybrid Fuzz Testing [47] ﬁrst runs symbolic execution
to ﬁnd inputs that lead to “frontier nodes” and then applies
fuzzing on these inputs. On the other hand, Driller [25] starts
with fuzzing and uses symbolic execution when it needs help
in generating inputs that satisfy complex checks.

In contrast, input prediction extends greybox fuzzing with-
out relying on static analysis or whitebox fuzzing. HARVEY
could, however, beneﬁt from hybrid-fuzzing approaches.

Optimization in testing. Miller and Spooner [48] were the
ﬁrst to use optimization methods in generating test data, and in
particular, ﬂoating-point inputs. It was not until 1990 that these
ideas were extended by Korel for Pascal programs [49]. Such
optimization methods have recently been picked up again [50],
enhanced, and implemented in various testing tools, such as
FloPSy [51], CORAL [52], EvoSuite [53], AUSTIN [54],
CoverMe [55], and Angora [36]. Most of these tools use ﬁtness
functions to determine the distance from a target and attempt to
minimize them. For instance, Korel uses ﬁtness functions that
are similar to our cost metrics for ﬂipping branch conditions.
The search is typically iterative, e.g., by using hill climbing,
simulated annealing, or genetic algorithms [56], [57], [58].

Our prediction technique is inspired by these approaches but
is applied in the context of greybox fuzzing. When failing to
minimize a cost metric, HARVEY falls back on standard grey-
box fuzzing, which is known for its effectiveness. We show
that input prediction works particularly well in the domain of
smart contracts, where even one iteration is generally enough
for minimizing a cost metric.

Method-call sequence generation. For

testing object-
oriented programs, it is often necessary to generate complex
input objects using sequences of method calls. There are many

10

approaches [59], [60], [61], [3], [62], [63], [64], [65] that
automatically generate such sequences using techniques such
as dynamic inference, static analysis, or evolutionary testing.
In contrast, demand-driven sequence fuzzing only relies on

greybox fuzzing and targets smart contracts.

Program analysis for smart contracts. There exist various
applications of program analysis to smart contracts, such as
symbolic execution, static analysis, and veriﬁcation [30], [66],
[67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77],
[78], [79]. The work most closely related to ours is the
blackbox fuzzer ContractFuzzer [29] and the property-based
testing tool Echidna [80]. In contrast, our technique is the ﬁrst
to apply greybox fuzzing to smart contracts.

VIII. CONCLUSION

We presented HARVEY, an industrial greybox fuzzer for
smart contracts. During its development, we encountered two
key challenges that we alleviate with input prediction and
demand-driven sequence fuzzing. Our experiments show that
both techniques signiﬁcantly improve HARVEY’s effectiveness
and highlight certain insights about contract code.

In future work, we plan to further enhance HARVEY by
leveraging complementary techniques, such as static analysis
and lightweight dynamic symbolic execution.

REFERENCES

[1] K. Claessen and J. Hughes, “QuickCheck: A lightweight tool for random
testing of Haskell programs,” in ICFP. ACM, 2000, pp. 268–279.
[2] C. Csallner and Y. Smaragdakis, “JCrasher: An automatic robustness

tester for Java,” SPE, vol. 34, pp. 1025–1050, 2004.

[3] C. Pacheco, S. K. Lahiri, M. D. Ernst, and T. Ball, “Feedback-directed
IEEE Computer Society, 2007, pp.

random test generation,” in ICSE.
75–84.

[4] “Technical “whitepaper” for AFL,” http://lcamtuf.coredump.cx/aﬂ/

technical details.txt.

[5] “Libfuzzer—A library for coverage-guided fuzz testing,” https://llvm.

org/docs/LibFuzzer.html.

[6] P. Godefroid, N. Klarlund, and K. Sen, “DART: Directed automated

random testing,” in PLDI. ACM, 2005, pp. 213–223.

[7] C. Cadar and D. R. Engler, “Execution generated test cases: How
to make systems code crash itself,” in SPIN, ser. LNCS, vol. 3639.
Springer, 2005, pp. 2–23.

[8] “Peach

Fuzzer
peach-fuzzer/peach-platform/.

Platform,”

https://www.peach.tech/products/

[9] “zzuf—Multi-Purpose Fuzzer,” http://caca.zoy.org/wiki/zzuf.
[10] P. Godefroid, M. Y. Levin, and D. A. Molnar, “Automated whitebox
fuzz testing,” in NDSS. The Internet Society, 2008, pp. 151–166.
[11] C. Cadar, D. Dunbar, and D. R. Engler, “KLEE: Unassisted and auto-
matic generation of high-coverage tests for complex systems programs,”
in OSDI. USENIX, 2008, pp. 209–224.

[12] V. Ganesh, T. Leek, and M. C. Rinard, “Taint-based directed whitebox

fuzzing,” in ICSE.

IEEE Computer Society, 2009, pp. 474–484.

[13] “The AFL vulnerability trophy case,” http://lcamtuf.coredump.cx/aﬂ/

#bugs.

[14] M. B¨ohme, V. Pham, and A. Roychoudhury, “Coverage-based greybox
fuzzing as Markov chain,” in CCS. ACM, 2016, pp. 1032–1043.
[15] S. Rawat, V. Jain, A. Kumar, L. Cojocar, C. Giuffrida, and H. Bos,
“VUzzer: Application-aware evolutionary fuzzing,” in NDSS.
The
Internet Society, 2017, pp. 1–14.

[16] S. Sparks, S. Embleton, R. Cunningham, and C. C. Zou, “Automated
vulnerability analysis: Leveraging control ﬂow for evolutionary input
crafting,” in ACSAC.

IEEE Computer Society, 2007, pp. 477–486.

[17] M. B¨ohme, V. Pham, M. Nguyen, and A. Roychoudhury, “Directed

greybox fuzzing,” in CCS. ACM, 2017, pp. 2329–2344.

[18] “Ethereum white paper,” 2014, https://github.com/ethereum/wiki/wiki/

White-Paper.

[19] “Ethereum,” https://github.com/ethereum.
[20] M. Swan, Blockchain: Blueprint for a New Economy. O’Reilly Media,

2015.

[21] S. Raval, Decentralized Applications: Harnessing Bitcoin’s Blockchain

Technology. O’Reilly Media, 2016.

[22] D. Tapscott and A. Tapscott, Blockchain Revolution: How the Tech-
nology Behind Bitcoin is Changing Money, Business, and the World.
Penguin, 2016.

[23] M. Bartoletti and L. Pompianu, “An empirical analysis of smart con-
tracts: Platforms, applications, and design patterns,” in FC, ser. LNCS,
vol. 10323. Springer, 2017, pp. 494–509.

[24] G. Wood, “Ethereum: A secure decentralised generalised transaction

ledger,” 2014, http://gavwood.com/paper.pdf.

[25] N. Stephens, J. Grosen, C. Salls, A. Dutcher, R. Wang, J. Corbetta,
Y. Shoshitaishvili, C. Kruegel, and G. Vigna, “Driller: Augmenting
fuzzing through selective symbolic execution,” in NDSS. The Internet
Society, 2016.

[26] “Underhanded solidity coding contest,” http://u.solidity.cc/.
[27] G. Klees, A. Ruef, B. Cooper, S. Wei, and M. Hicks, “Evaluating fuzz

testing,” in CCS. ACM, 2018, pp. 2123–2138.

[28] “Smart Contract Weakness Classiﬁcation,” https://smartcontractsecurity.

github.io/SWC-registry.

[29] B. Jiang, Y. Liu, and W. K. Chan, “ContractFuzzer: Fuzzing smart
contracts for vulnerability detection,” in ASE. ACM, 2018, pp. 259–
269.

[30] L. Luu, D. Chu, H. Olickel, P. Saxena, and A. Hobor, “Making smart

contracts smarter,” in CCS. ACM, 2016, pp. 254–269.

[31] A. Vargha and H. D. Delaney, “A critique and improvement of the CL
common language effect size statistics of McGraw and Wong,” JEBS,
vol. 25, pp. 101–132, 2000.

11

[60] T. Xie, D. Marinov, W. Schulte, and D. Notkin, “Symstra: A framework
for generating object-oriented unit tests using symbolic execution,” in
TACAS, ser. LNCS, vol. 3440. Springer, 2005, pp. 365–381.

[61] K. Inkumsah and T. Xie, “Evacon: A framework for integrating evo-
lutionary and concolic testing for object-oriented programs,” in ASE.
ACM, 2007, pp. 425–428.

[62] S. Thummalapenta, T. Xie, N. Tillmann, J. de Halleux, and W. Schulte,
“MSeqGen: Object-oriented unit-test generation via mining source
code,” in ESEC/FSE. ACM, 2009, pp. 193–202.

[63] S. Thummalapenta, T. Xie, N. Tillmann, J. de Halleux, and Z. Su,
“Synthesizing method sequences for high-coverage testing,” in OOPSLA.
ACM, 2011, pp. 189–206.

[64] S. Zhang, D. Saff, Y. Bu, and M. D. Ernst, “Combined static and
dynamic automated test generation,” in ISSTA. ACM, 2011, pp. 353–
363.
[65] P. Garg, F.

Ivanˇci´c, G. Balakrishnan, N. Maeda, and A. Gupta,
“Feedback-directed unit test generation for C/C++ using concolic ex-
ecution,” in ICSE.
IEEE Computer Society/ACM, 2013, pp. 132–141.
[66] K. Bhargavan, A. Delignat-Lavaud, C. Fournet, A. Gollamudi,
G. Gonthier, N. Kobeissi, N. Kulatova, A. Rastogi, T. Sibut-Pinote,
N. Swamy, and S. Zanella-B´eguelin, “Formal veriﬁcation of smart
contracts: Short paper,” in PLAS. ACM, 2016, pp. 91–96.

[67] N. Atzei, M. Bartoletti, and T. Cimoli, “A survey of attacks on Ethereum
smart contracts,” in POST, ser. LNCS, vol. 10204. Springer, 2017, pp.
164–186.

[68] T. Chen, X. Li, X. Luo, and X. Zhang, “Under-optimized smart contracts
IEEE Computer Society, 2017, pp.

devour your money,” in SANER.
442–446.

[69] I. Sergey and A. Hobor, “A concurrent perspective on smart contracts,”

in FC, ser. LNCS, vol. 10323. Springer, 2017, pp. 478–493.

[70] K. Chatterjee, A. K. Goharshady, and Y. Velner, “Quantitative analysis
of smart contracts,” in ESOP, ser. LNCS, vol. 10801. Springer, 2018,
pp. 739–767.

[71] S. Amani, M. B´egel, M. Bortin, and M. Staples, “Towards verifying
Ethereum smart contract bytecode in Isabelle/HOL,” in CPP. ACM,
2018, pp. 66–77.

[72] L. Brent, A. Jurisevic, M. Kong, E. Liu, F. Gauthier, V. Gramoli, R. Holz,
and B. Scholz, “Vandal: A scalable security analysis framework for smart
contracts,” CoRR, vol. abs/1809.03981, 2018.

[73] N. Grech, M. Kong, A. Jurisevic, L. Brent, B. Scholz, and Y. Smarag-
dakis, “MadMax: Surviving out-of-gas conditions in Ethereum smart
contracts,” PACMPL, vol. 2, pp. 116:1–116:27, 2018.

[74] S. Grossman, I. Abraham, G. Golan-Gueta, Y. Michalevsky, N. Rinetzky,
M. Sagiv, and Y. Zohar, “Online detection of effectively callback free
objects with applications to smart contracts,” PACMPL, vol. 2, pp. 48:1–
48:28, 2018.

[75] S. Kalra, S. Goel, M. Dhawan, and S. Sharma, “ZEUS: Analyzing safety

of smart contracts,” in NDSS. The Internet Society, 2018.

[76] I. Nikolic, A. Kolluri, I. Sergey, P. Saxena, and A. Hobor, “Finding the

greedy, prodigal, and suicidal contracts at scale,” pp. 653–663, 2018.

[77] P. Tsankov, A. M. Dan, D. Drachsler-Cohen, A. Gervais, F. B¨unzli, and
M. T. Vechev, “Securify: Practical security analysis of smart contracts,”
in CCS. ACM, 2018, pp. 67–82.

[78] “Manticore,” https://github.com/trailofbits/manticore.
[79] “Mythril,” https://github.com/ConsenSys/mythril-classic.
[80] “Echidna,” https://github.com/trailofbits/echidna.

[32] J. Siegmund, N. Siegmund, and S. Apel, “Views on internal and external
IEEE Computer

validity in empirical software engineering,” in ICSE.
Society, 2015, pp. 9–19.

[33] M. Woo, S. K. Cha, S. Gottlieb, and D. Brumley, “Scheduling black-box

mutational fuzzing,” in CCS. ACM, 2013, pp. 511–522.

[34] A. Rebert, S. K. Cha, T. Avgerinos, J. Foote, D. Warren, G. Grieco,
and D. Brumley, “Optimizing seed selection for fuzzing,” in Security.
USENIX, 2014, pp. 861–875.

[35] S. K. Cha, M. Woo, and D. Brumley, “Program-adaptive mutational

fuzzing,” in SP.

IEEE Computer Society, 2015, pp. 725–741.

[36] P. Chen and H. Chen, “Angora: Efﬁcient fuzzing by principled search,”

in SP.

IEEE Computer Society, 2018, pp. 711–725.

[37] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. Dill, and D. R. Engler,
“EXE: Automatically generating inputs of death,” in CCS. ACM, 2006,
pp. 322–335.

[38] K. Sen and G. Agha, “CUTE and jCUTE: Concolic unit testing and
explicit path model-checking tools,” in CAV, ser. LNCS, vol. 4144.
Springer, 2006, pp. 419–423.

[39] N. Tillmann and J. de Halleux, “Pex—White box test generation for

.NET,” in TAP, ser. LNCS, vol. 4966. Springer, 2008, pp. 134–153.

[40] D. X. Song, D. Brumley, H. Yin, J. Caballero, I. Jager, M. G. Kang,
Z. Liang, J. Newsome, P. Poosankam, and P. Saxena, “BitBlaze: A new
approach to computer security via binary analysis,” in ICISS, ser. LNCS,
vol. 5352. Springer, 2008, pp. 1–25.

[41] S. Artzi, A. Kiezun, J. Dolby, F. Tip, D. Dig, A. M. Paradkar, and M. D.
Ernst, “Finding bugs in web applications using dynamic test generation
and explicit-state model checking,” TSE, vol. 36, pp. 474–494, 2010.

[42] V. Chipounov, V. Kuznetsov, and G. Candea, “S2E: A platform for in-
vivo multi-path analysis of software systems,” in ASPLOS. ACM, 2011,
pp. 265–278.

[43] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley, “Unleashing
IEEE Computer Society, 2012, pp.

Mayhem on binary code,” in SP.
380–394.

[44] J. Geldenhuys, M. B. Dwyer, and W. Visser, “Probabilistic symbolic

execution,” in ISSTA. ACM, 2012, pp. 166–176.

[45] V. Pham, M. B¨ohme, and A. Roychoudhury, “Model-based whitebox
fuzzing for program binaries,” in ASE. ACM, 2016, pp. 543–553.
[46] I. Haller, A. Slowinska, M. Neugschwandtner, and H. Bos, “Dowsing
for overﬂows: A guided fuzzer to ﬁnd buffer boundary violations,” in
Security. USENIX, 2013, pp. 49–64.

[47] B. S. Pak, “Master’s thesis “Hybrid Fuzz Testing: Discovering Software
Bugs via Fuzzing and Symbolic Execution”,” 2012, school of Computer
Science, Carnegie Mellon University, USA.

[48] W. Miller and D. L. Spooner, “Automatic generation of ﬂoating-point

test data,” TSE, vol. 2, pp. 223–226, 1976.

[49] B. Korel, “Automated software test data generation,” TSE, vol. 16, pp.

870–879, 1990.

[50] P. McMinn, “Search-based software test data generation: A survey,”

Softw. Test., Verif. Reliab., vol. 14, pp. 105–156, 2004.

[51] K. Lakhotia, N. Tillmann, M. Harman, and J. de Halleux, “Flopsy—
Search-based ﬂoating point constraint solving for symbolic execution,”
in ICTSS, ser. LNCS, vol. 6435. Springer, 2010, pp. 142–157.
[52] M. Souza, M. Borges, M. d’Amorim, and C. S. Pasareanu, “CORAL:
Solving complex constraints for symbolic PathFinder,” in NFM, ser.
LNCS, vol. 6617. Springer, 2011, pp. 359–374.

[53] G. Fraser and A. Arcuri, “EvoSuite: Automatic test suite generation for

object-oriented software,” in ESEC/FSE. ACM, 2011, pp. 416–419.

[54] K. Lakhotia, M. Harman, and H. Gross, “AUSTIN: An open source
tool for search based software testing of C programs,” IST, vol. 55, pp.
112–125, 2013.

[55] Z. Fu and Z. Su, “Achieving high coverage for ﬂoating-point code via
unconstrained programming,” in PLDI. ACM, 2017, pp. 306–319.
[56] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and
E. Teller, “Equation of state calculations by fast computing machines,”
The Journal of Chemical Physics, vol. 21, pp. 1087–1092, 1953.
[57] S. Kirkpatrick, C. D. Gelatt Jr., and M. P. Vecchi, “Optimization by

simulated annealing,” Science, vol. 220, pp. 671–680, 1983.

[58] R. P. Pargas, M. J. Harrold, and R. Peck, “Test-data generation using
genetic algorithms,” Softw. Test., Verif. Reliab., vol. 9, pp. 263–282,
1999.

[59] P. Tonella, “Evolutionary testing of classes,” in ISSTA. ACM, 2004,

pp. 119–128.

12

All tested smart contracts are open source. Tab. VI provides the changeset IDs and links to their repositories.

APPENDIX

Changeset ID

BIDs
1
2–3
4–5
6
7
8
9
10–13

Name
ENS
5108f51d656f201dc0054e55f5fd000d00ef9ef3
CMSW 2582787a14dd861b51df6f815fab122ff51fb574
GMSW 8ac8ba7effe6c3845719e480defb5f2ecafd2fd4
BAT
CT
ERCF
FBT
HPN
14 MR
15 MT
PC
16
RNTS
17–18
DAO
19
VT
20
USCC1
21
USCC2
22
USCC3
23
USCC4
24
USCC5
25
PW
26
27
BNK

15bebdc0642dac614d56709477c7c31d5c993ae1
1f62e1ba3bf32dc22fe2de94a9ee486d667edef2
c7d025220a1388326b926d8983e47184e249d979
ae71053e0656b0ceba7e229e1d67c09f271191dc
540006e0e2e5ef729482ad8bebcf7eafcd5198c2
527eb90c614ff4178b269d48ea063eb49ee0f254
7009cc95affa5a2a41a013b85903b14602c25b4f
515c1b935ac43afc6bf54fcaff68cf8521595b0b
6c39082eff65b2d3035a89a3f3dd94bde6cca60f
f347c0e177edcfd99d64fe589d236754fa375658
30ede971bb682f245e5be11f544e305ef033a765
3b26643a85d182a9b8f0b6fe8c1153f3bd510a96
3b26643a85d182a9b8f0b6fe8c1153f3bd510a96
3b26643a85d182a9b8f0b6fe8c1153f3bd510a96
3b26643a85d182a9b8f0b6fe8c1153f3bd510a96
3b26643a85d182a9b8f0b6fe8c1153f3bd510a96
657da22245dcfe0fe1cccc58ee8cd86924d65cdd
97f1c3195bc6f4d8b3393016ecf106b42a2b1d97

Repository

https://github.com/ethereum/ens
https://github.com/ConsenSys/MultiSigWallet
https://github.com/gnosis/MultiSigWallet
https://github.com/brave-intl/basic-attention-token-crowdsale
https://github.com/ConsenSys/Tokens
https://github.com/ScJa/ercfund
https://github.com/Firstbloodio/token
https://github.com/Havven/havven
https://github.com/raiden-network/microraiden
https://github.com/modum-io/tokenapp-smartcontract
https://github.com/mattdf/payment-channel
https://github.com/RequestNetwork/RequestTokenSale
https://github.com/slockit/DAO
https://github.com/valid-global/token
https://github.com/Arachnid/uscc
https://github.com/Arachnid/uscc
https://github.com/Arachnid/uscc
https://github.com/Arachnid/uscc
https://github.com/Arachnid/uscc
https://github.com/paritytech/contracts
https://github.com/Bankera-token/BNK-ETH-Contract

Table VI: Smart contract repositories.

13

