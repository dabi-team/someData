Spotting Silent Buffer Overﬂows in Execution Trace through
Graph Neural Network Assisted Data Flow Analysis

Zhilong Wang, Li Yu, Suhang Wang and Peng Liu
College of Information Sciences and Technology
The Pennsylvania State University, USA
zzw169@psu.edu, szw494@psu.edu, luy133@psu.edu, pliu@ist.psu.edu

1
2
0
2

b
e
F
0
2

]

R
C
.
s
c
[

1
v
2
5
4
0
1
.
2
0
1
2
:
v
i
X
r
a

Abstract—A software vulnerability could be exploited without
any visible symptoms. When no source code is available, although
such silent program executions could cause very serious damage,
the general problem of analyzing silent yet harmful executions
is still an open problem. In this work, we propose a graph
neural network (GNN) assisted data ﬂow analysis method for
spotting silent buffer overﬂows in execution traces. The new
method combines a novel graph structure (denoted DFG+) beyond
data-ﬂow graphs, a tool to extract DFG+ from execution traces,
and a modiﬁed Relational Graph Convolutional Network as the
GNN model to be trained. The evaluation results show that
a well-trained model can be used to analyze vulnerabilities in
execution traces (of previously-unseen programs) without support
of any source code. Our model achieves 94.39% accuracy on
the test data, and successfully locates 29 out of 30 real-world
silent buffer overﬂow vulnerabilities. Leveraging deep learning,
the proposed method is, to our best knowledge, the ﬁrst general-
purpose analysis method for silent buffer overﬂows. It is also the
ﬁrst method to spot silent buffer overﬂows in global variables,
stack variables, or heap variables without crossing the boundary
of allocated chunks.

I. INTRODUCTION
A fundamental challenge in cybersecurity is that vulner-
abilities widely exist in all kinds of programs [1] despite
software engineers and security analysts have been spending
lots of efforts to avoid and test them. These vulnerabilities
could be exploited by the attackers and expose a huge threat
to individuals, organizations and governments [2]. Although
researchers have proposed a variety of techniques to automat-
ically discover and analyze software vulnerabilities [3], [4],
[5], [6], almost all existing techniques rely on visible “symp-
toms” (e.g., crashes, failing assertions, and errors found by
integrity checkers). Most vulnerability discovery methods use
such symptoms to distinguish (potentially) harmful program
executions in which a vulnerability is triggered and benign
executions [7], [8], [9].

However, a software vulnerability could be exploited with-
out any visible symptoms, and the corresponding program
executions are often called a “silent” yet harmful execution.
For example, some silent buffer overﬂows, silent Use-After-
Free, and silent information leak could happen given speciﬁc
malicious inputs. All these silent yet harmful program execu-
tions, though not as frequently seen as harmful as executions
carrying visible symptoms, could still be leveraged by attack-
ers to compromise the system [10] and cause serious damage
(e.g., altering program variables, leaking critical information).
When the source code is available, silent yet harmful execu-
tions in principle can be identiﬁed and analyzed. By leveraging
semantic information obtained from source code, researchers
have developed various tools to identify and analyze them [11],

[12], [13]. For example, Konstantin et al. [11] developed
AddressSanitizer to detect memory errors and diagnose root
causes (of silent yet harmful executions) through source code
level instrumentation.

However, in many cases the commercial software and legacy
code targeted by the attacker has no source code available
(to organizations using the software), and it is widely rec-
ognized in the research community that when source code
is not available, analyzing silent yet harmful executions is
an extremely difﬁcult problem. A fundamental challenge in
solving this problem is lack of high-level, semantically rich
information about data structures in the executables [14].
Due to the fundamental challenge, the general problem of
identifying and analyzing silent yet harmful executions is yet
to be solved. In the literature, only a small portion of silent
vulnerabilities can be identiﬁed. For example,
there are a
spectrum of silent buffer overﬂow, but only overﬂow across
the boundary of allocated chunks in heap can be detected by
existing methods [15], [16]. These methods capture the length
of dynamically allocated buffer by hooking the heap allocation
functions. Then they check the integrity of buffer access
by comparing the buffer length and offset of buffer access.
So far, no effective method has been proposed to analyze
silent buffer overﬂows in global variables, stack variables,
or heap variables without crossing the boundary of allocated
chunks. As stated by Dinesh et al. [16], binary disassembly
is insufﬁcient to recover data section layouts and semantic
information lost during compilation. Not surprisingly, silent
vulnerability analysis without source code is still an open
problem and there lacks a general purpose analysis method
for even one main category of silent vulnerabilities.

In this work, we seek to develop a general purpose analysis
method for silent buffer overﬂows, one most important cate-
gory of silent vulnerabilities. The proposed method is based
on a key observation:

Key Observation. In silent yet harmful program executions,
the data ﬂows towards the variables corrupted by silent
buffer overﬂow and the memory space layout of some of the
corrupted variables are inherently different from those of non-
affected variables. It is worth noting that human analysts have
to examine enough data ﬂows and memory layout patterns,
which is usually very time consuming, before they could
leverage this key observation and identify the exact differences
between corrupted and non-affected variables.

In light of this, we propose to leverage Graph Neural
Network [17] to signiﬁcantly reduce manual efforts. In fact,
our method is close to 100% automatic. Our insight is that
critical information about the difference between corrupted
and non-affected variables could be represented by a novel

 
 
 
 
 
 
graph structure. Then Graph Neural Network (GNN) could
learn essential features (from graphs extracted from execution
traces) through representation learning. Then the learned rep-
resentations could enable the GNN model to “analyze” a given
execution trace by classifying the nodes in the graph extracted
from the trace. Finally, the nodes classiﬁed as “vulnerable”
may provide enough information for automatically locating
the address of vulnerable instructions and vulnerable buffers,
respectively.

Speciﬁcally, we design a novel graph data structure to hold
important features obtained from program executions, includ-
ing data ﬂows, variables’ spatial information, and some useful
implicit information ﬂows. During the model training phase,
we utilize a dynamic analyzer based on Intel Pin [18] to build
the newly designed graph automatically from execution traces
(of various programs) and customize AddressSanitizer [11] to
help assign labels to nodes in the graph. A node with label
“vulnerable” corresponds to a corrupted variable resulted from
silent buffer overﬂow. Using the labeled graph as training data,
we design and train a Bi-directional Propagation Relational
Graph Convolutional Network (BRGCN) to perform node clas-
siﬁcation.

After the BRGCN model is well trained and deployed, the
model can be used to analyze vulnerabilities in execution
traces (of previously-unseen programs) without support of any
source code. The experiments show that our model achieves
94.39% accuracy on the balanced test data, and successfully
locates 29 out of 30 real-world vulnerabilities which we obtain
from a public vulnerability database [19], [20]. The evaluation
results show that graph neural network assisted data ﬂow
analysis is an effective general-purpose method in spotting
silent buffer overﬂows when source code in not available.

In summary, we made the following contributions:

• To the best of our knowledge, this work proposes the ﬁrst
graph neural network assisted data ﬂow analysis method
for spotting silent buffer overﬂows in execution traces. It
can analyze a full spectrum of silent buffer overﬂows.
• We designed a new type of graph data structure DFG+
to represent programs’ data ﬂow, variables’ spatial infor-
mation, and implicit information ﬂow, in an integrated
manner.

• We implemented a tool based on Intel Pin to auto-
matically generate DFG+ from program executions and
customized AddressSanitizer to help assign ground truth
labels for nodes in DFG+.

• We modiﬁed the Relational Graph Convolutional Neural
Network (RGCN) [21] by introducing bi-directional rela-
tion types to make it more effective in program analysis.
• We evaluated the effectiveness of the newly designed
DFG+ and the newly designed BRGCN model, and com-
pared with other baseline methods. In our view, the pro-
posed method is neither a “competitor” nor an extension
of existing fuzzing tools. Without source code, existing
fuzzing tools, though very efﬁcient, simply cannot iden-
tify silent buffer overﬂows in global variables, stack vari-
ables, or heap variables without crossing the boundary of
allocated chunks. Hence, comparing the proposed method
and fuzzing tools could result in “comparing apples and
oranges.”

II. BACKGROUND AND RELATED WORK

A. Buffer Overﬂow

For decades buffer overﬂow (BOF) remains as one of
the main security threats plaguing the cyberspace, attributing
to the prevalence of the buffer overﬂow bugs in commod-
ity software and the fundamental difﬁculty to ﬁnd and ﬁx
them. Conventionally, BOF vulnerability refers to a category
of software vulnerabilities which could corrupt the adjacent
memory region due to insufﬁcient bound checking. The buffer
associated with the vulnerability is called vulnerable buffer.
According to the location of vulerable buffer, BOF can be
group into heap, stack, and global BOF. When BOF happens,
it can cause the program to crash by corrupting data/code
pointers (e.g., return address and jump table), or change
program state by altering some non-control-data [10]. In the
paper, we classify wild BOF into three categories according
to its symptoms. A wild BOF means the input is not manually
crafted by analyst, e.g., in exploit generation.

1) Visible Buffer Overﬂow. We call a BOF visible if it
shows visible symptoms, such as program crashing, assertion
failing, or displaying garbled string on the screen.
2) Silent Buffer Overﬂow. Another kind of BOFs happens
without any visible symptoms. For instance, some BOFs that
only corrupt some dead variables (please see the deﬁne of
dead variable in Section V-A), or only corrupt some local
variable in stack, will not crash.
3) Innocent Buffer Overﬂow. A BOF has no effect on the
program if it only overwrites a padding space, which is
inserted by some compilers to the boundary of buffers due
to data alignment speciﬁed by attributes of variable [22] or
language features [23].
In general, visible BOFs are believed to be easily discovered
and analyzed when they happen, attributing to their visible
symptoms. If source code is available, silent BOF can also
be identiﬁed through sanitizer [11] or bound-checking [12].
However, it is extremely challenging to analyze silent BOF
when source code is unavailable, because critical high level
information such as length of buffer and type of variables,
is lost in the binary during the compilation. The literature
review shows that all the existing works [15], [16], [24], [25],
[26] can only identify silent heap BOFs which overﬂow cross
the boundary of allocated memory chunks. The details of
these approaches will be discussed shortly in Section II-D.
Therefore, the general problem of silent BOF analysis is still
an open problem.

It is worth noting that certain BOF vulnerabilities in ex-
ecutiables could display either visible symptom or invisible
symptom in different executions, given different inputs. In
this case if the vulnerability is triggered by one or more
visible executions, the resulted BOF would be a visible BOF,
even though the vulnerability could also be exploited by some
silent executions. Based on this fact, some works in program
testing try to ﬁnd vulnerabilities “shared by” visible BOFs

1 int age, i, total = 0, ages[0x20];
2 for(i = 0; i <= 0x20; i++){
age = receive();
3
if(age == -1) break;
4
ages[i] = age; //overflow when i=0x20
5
total += ages[i];
6
7 }

Code 1: A piece of code with silent buffer overﬂow.

2

and silent BOFs by varying input lengths [7], [9]. However,
this is only feasible when the vulnerability is caused by the
excess length of inputs. And it obviously cannot solve the
general problem of silent BOF analysis. Firstly, many BOF
vulnerabilities only have silent BOF (execution) instances. An
illustrative example 1 is shown in Code 1. In the code, ages is
an integer array of length 20 and i is the index in the for loop
to access ages. We could see there will be a BOF if i equals
0x20 but the program won’t terminate at this point. Secondly,
the length of buffer access does not necessarily depend on the
length of input. It can depend on the length of a portion of
the input, or the value of one or several bytes in the input.
Under these circumstances, it is almost impossible to know
which segment crashes the program.

B. Data Flow Graph

Data ﬂow graph was ﬁrst

introduced in the data ﬂow
machines to describe parallel computation [27]. A data ﬂow
graph is a directed graph, G(N, E), where nodes in N repre-
sent instructions and edges in E represent data dependencies
among the nodes. Data ﬂow graph is widely used in compiler
optimization, such as register allocation, instruction scheduling
and dead code elimination [28]. Although there is no univer-
sally accepted deﬁnition, data ﬂow analysis generally refers to
the process of collecting and deriving information about the
way the variables are deﬁned, used in the program [29].

Data ﬂow graph and analysis are also widely used in
software security to analyze software defects, enforce secure
policies, and so on. Compared with control ﬂow graph, data
ﬂow graph is more informative, which contain semantic infor-
mation of programs.

C. Graph Neural Networks

In recent years, deep neural networks have shown increas-
ingly noticeable success in security domains, such as security-
oriented program analysis [30], [31], [32] and anomaly detec-
tion [33], [34], due to their remarkable representation learning
capabilities [35]. Some representative genres of deep neural
networks are convolutional neural network (CNN), recurrent
neural network (RNN), and graph neural network (GNN).
CNN is developed to capture information from grid data,
whereas RNN is designed to capture sequential information.
Given the nature of our proposed graph data structure DFG+,
GNN is more compelling because of its great ability in
representation learning on graphs.

Convolutional graph neural networks (ConvGNN), among
other GNNs, adopts convolution operations on graphs to
capture local and global structural patterns, through designing
special convolution and readout functions [36]. Standard con-
volutions on images or text embeddings are not applicable to
graphs because graphs have irregular structures, so that special
convolutions have to be designed to work on graph data [17].
Depending on how convolution is performed, existing GNNs
can be classiﬁed into two categorizes,
i.e., spectral-based
convGNN and spatial-based ConvGNN [37].

1) Spectral-based ConvGNN: Spectral-based convolution is
deﬁned based on spectral graph theory [38]. In this framework,
a graph Laplacian is deﬁned and signals on graphs are ﬁltered
using eigen-decomposition of graph Laplacian. The graph

1Note that some compilers may change the layout of variables in stack. In
order to make the example simple, we do not consider variable reorder here.

convolution operators are introduced by deﬁning the graph
Fourier transform. However, despite the solid mathematical
foundations, such approaches suffer from large computational
burden, spatially non-localized issue and generalization prob-
lem. Considering the computation complexity of spectral-
based ConvGNN, we don’t adopt it in our analysis of DFG+.
2) Spatial-based ConvGNN: The main idea of spatial-based
ConvGNN (massage passing GNN) is to generate a node
v’s representation by aggregating its own features xv and
neighbors’ features xu, where u ∈ set of neighbors of v.
Generally, spatial ConvGNN can be deﬁned as:
(cid:33)

(cid:32)

H (l+1) = σ

C (s)H (l)W (l,s)

,

(1)

(cid:88)

s

where H (l) ∈ Rn×dl
is the latent representation of the n nodes
in the l -th layer and dl is number of features. C (s) is the s-
th convolution kernel that deﬁnes how the node features are
propagated to the neighborhood nodes, W (l,s) ∈ Rdl×dl+1
is the trainable weight matrix that maps the dl-dimensional
features into dl+1 dimension, σ is the activation function
such as ReLU [?] and tanh. Equation 1 covers a broad class
of ConvGNN, and different designs of spatial ConvGNN
are distinguished by the their convolution kernel C (s) and
variability induced by W (l,s) in Equation 1.

In each layer, message passing algorithm (neighborhood
aggregation) deﬁned in the Equation 1 aggregates features
from a node’s local neighborhood. Therefore, the node rep-
resentation learned by the a k-layer ConvGNN include not
only the features of itself, but also the features of its k-
hop neighborhoods and the local graph structure [36]. The
node representation learning ability of ConvGNN has been
intensively investigated by recent research [39]. The great
ability of ConvGNNs in modeling graph structured data have
facilitated various domains such as social network mining [40],
[41], knowledge graphs [42], bioinformatics [43] and recently
code similarity comparison [44]. Thus, it has great potential
to adopt ConvGNNs for representation learning on DFG+ to
detect vulnerabilities.

D. Related Works

In this section, we will introduce some works that spot
BOF on the source code and binary level, and discuss their
limitations.

Source Code based Schemes.
The source code based
schemes usually adopt source code analysis to collect semantic
information (e.g., buffer length) and enforce their detection
rules through source code instrumentation. Among several
existing works [11], [12], [13], we choose one representative
scheme – AddressSanitizer (ASAN) – to introduce. Brieﬂy,
ASAN detects spatial bugs by reserving Redzone around
heap, stack, and global objects, detects temporal bugs by
quarantine for heap and stack objects to delay the reuse of
leverages shadow memory to
dead objects. Technically,
mark whether an address in the program space belongs to
Redzone or not, and checks legality of target addresses
before instructions access variables in memory. Despite its
effectiveness to detect all kinds of BOFs in global, stack
and heap, ASAN has two limitations: ﬁrslty, ASAN needs
program’s source code, thereby cannot detect bugs in legacy
code and commercial software. Secondly, it fails to detect non-
linear buffer-overﬂow (an access that jumps over a Redzone).

it

3

TABLE I: Comparison of the related works’ effectiveness to detect buffer overﬂow.

Defence Tools
BOIL
AddressSanitizer
TaintCheck
Memcheck
Fuzzing
Symbolic Execution
The Proposed Method

Require Source Code or Not
No
Yes
No
No
No
No
No

Silent Heap BOF
Partial
Yes
No
Partial
No
No
Yes

Silent Stack BOF
No
Yes
No
No
No
No
Yes

Silent Global BOF
No
Yes
No
No
No
No
Yes

Static Approaches on Binary. Rawat et al. [45] researched
the detection of potential stack-based BOF vulnerability in
binary code. Different from traditional works that usually
deﬁne vulnerability patterns at the syntactic level (e.g., func-
tion name), they considered more features of vulnerabilities
on semantic level and deﬁned the buffer overﬂow inducing
loops (BOIL) to summary the semantic patterns of poten-
tial vulnerable loop. Based on the proposed patterns, they
developed a prototype to identify potential vulnerable loops
from executables. The advantage of their approach is that it
does not need to execute the program and can achieve high
code coverage. However, as pointed out in their paper, their
scheme can only deal with a special case of BOF. We think
it is due to the challenges to summarize all patterns based
on human efforts. In addition, the reported positive functions
in this scheme can only be viewed as potential vulnerable
functions and needs further veriﬁcation, because no concrete
input is available to verify the reported BOF.

Dynamic Approaches on Binary. Dynamic approaches
analyze BOF vulnerabilities by ﬁnding vulnerable execu-
tions. In the binary level, taint analysis (also known as data
ﬂow tracking) is a popular method to debug vulnerabilities.
TaintCheck [46], proposed by James Newsome and Dawn
Song, which locates BOF based on one simple assumption – in
normal data ﬂow, pre-deﬁned taint source, such as user inputs,
environment variables, and network data will not propagate to
pointers. Therefore, their approach can not detect the silent
BOF which does not violate their assumption.

Memcheck [47] is a well-known vulnerability analysis tool
that is implemented based on dynamic binary instrumentation
framework Valgrind [48]. Technically speaking, it obtains the
address and size of buffers in heap by hooking function calls
to heap allocation functions and parsing their parameters and
return values. By comparing the offset of buffer accesses
and the length of allocated buffer in heap, they detect heap
BOF which writes out of allocated heap chunk. As mentioned
in [11], Memcheck and some other tools (Dr. Memory [24],
Purify [25] and Intel Parallel Inspector [26]) that adopt similar
approaches are not capable to ﬁnd out-of-bounds bugs in the
stack (other than beyond the top of the stack frame), global
and in heap if the overwrite does not across the boundary of
allocated chunk.

Fuzzing [7], symbolic execution [49], gradient descent [9]
and hybrid approaches [8] are widely adopted path exploration
method to automatically ﬁnd vulnerable paths in software.
These schemes try to generate input that achieve high cover-
age, and ﬁnd input that can trigger bugs. However, they select
positive inputs based on whether it can crash the program.
In such a case, the silent BOFs are ignored. Recent research
works [15], [16] trying to detect silent vulnerabilities during
Fuzzing suffer from same limitations with the works discussed

in last paragraph.

Table I summary the limitations of related works we men-
tioned above. In conclusion, the general problem of silent BOF
analysis is still an open problem, and it remains a fundamental
challenge to cope with the full spectrum of silent BOF at the
binary level.

III. PROBLEM FORMULATION AND CHALLENGES
In this section, we will formalize the silent BOF analysis

problem and present the challenges to solve it.

A. The Problem and Research Goal

In this example shown in Code 1, an integer array ages
with a ﬁxed length is deﬁned and allocated on the stack. The
loop copies one excess integer to the array and the nearest
variable total in the heap address will be overﬂowed, without
disturbing the normal execution of the program. We name
the out-of-bound access (writing/reading) during execution as
invalid operations or invalid access, deﬁne the instruction
address of the invalid operation as the overﬂow point, name
execution with invalid operation as BOF instance, and a
collection of runtime information as execution trace.

With the above notations, our research goal is to locate the
overﬂow point of silent BOF in an executable by analyzing its
execution trace. To be more speciﬁc, we want to:

1) distinguish BOF instances from normal executions.
2) locate the invalid operations in execution trace and
overﬂow point in an executable.
3) pinpoint each of them separately if there are more than
one overﬂow points in one execution trace.

B. Why is This Problem Hard?

Due to the unavailability of type information in binary, it is
not possible to identify invalid operations by comparing the
offset of buffer reading/writing with length of target buffer.
As shown in Code 2, which is the assembly code generated
from Code 1, the instruction at line 1 allocates memory for

$0x94,%esp
$0x0,-0x10(%ebp)
$0x0,-0x14(%ebp)
target2

<receive>

%eax,-0xc(%ebp)
$0xffffffff,-0xc(%ebp)
target3
-0x10(%ebp),%ebx
-0x94(%ebp,%ebx,4),%eax
%eax,-0x14(%ebp)
$0x1,-0x10(%ebp)

1 sub
2 movl
3 movl
4 jmp
5 target1: call
6 mov
7 cmpl
8 je
9 mov
10 mov
11 add
12 addl
13 target2: cmpl
14 jle
15 target3:

target1

$0x20,-0x10(%ebp)

Code 2: The assemble code compiled from Code 1.

4

variable age, i, total and array ages, and the instructions
at line 2 and line 3 initialize two variables with 0x0. Number
of allocated variables, the type and length of each variable are
unrevealed in variable allocation and initialization instructions.
Therefore, these lost information need to be inferred from the
execution trace. For instance, we could develop heuristic rules
to infer the boundary of buffers by distinguishing the data
ﬂow patterns to access buffers and to access their adjacent
variables.

However, the inferences usually need a lot of domain knowl-
edge associated with instruction set, conventions of compiler,
and features of programming language. Generally, it is unclear
which patterns the silent BOFs follow and which features
exist in execution trace that could be used for analysis. In
fact, designing heuristic rules is very time consuming and
complicated [45] because it requires observing both enough
silent BOF traces and normal execution traces.

IV. APPROACH OVERVIEW

The challenges faced by traditional methods motivate us
to solve the problem through deep neural networks. Although
the complexity of patterns to identify silent BOF is a daunting
challenge for human analysts to develop heuristic rules, it may
not be a challenge for a deep learning algorithm given enough
training data. Accordingly, we propose to spot silent BOF
based on graph neural network assisted data ﬂow analysis.
In this section, we ﬁrst provide several insights based on our
domain knowledge, which motivate us to choose our technical
approach, and these insights will be veriﬁed through several
experiments. Then, we provide an overview of our proposed
approach, and point out the challenges we must address.

A. Insights

1) The Essential Information Need to be Captured for BOF
Analysis: Through dynamic binary instrumentation, lots of
information can be collected along with program’s execution,
such as control ﬂow, data ﬂow, accessed memory, values
of operands for each instruction, and executed instruction
sequence. However, not all these information are useful to
identify silent BOF. If the unnecessary information get in-
cluded in training data, it will introduce noise and reduce the
accuracy of the model. Hence, two questions are raised and
the answers to them are associated with the domain knowledge
related to buffer overﬂow and dynamic program analysis:

Q1. What information should be selected?
Q2. How to design the data structure to hold the data?
Firstly, as discussed in the Section II-A, most silent BOFs
do not violate a valid control ﬂow (by corrupted code pointers),
but they always violate a valid data ﬂow. Therefore, the data
ﬂow is meaningful to be integrated to our training data. A data
ﬂow graph (DFG) is the most popular way to represent pro-
gram’s data ﬂow. Secondly, the spatial information (variable
layout) is useful to diagnose BOF, because BOF is an spatial
error [1]. We will discuss the challenge to represent the spatial
information later on.

Thirdly, some other (implicit) information ﬂow, such as
information ﬂow from a data pointer to its pointed variable,
and information ﬂow from condition variables to branch target,
could be useful to infer whether variables are pointers or
loop control variables. These information could be of great
importance as many BOFs happen due to unsafe the pointer
dereference in a loop.

Fourthly, besides the information ﬂow, information itself,
i.e., the values of variables, could also be useful. In fact,
the value of certain variables like loop control variables
could be very useful to analyze BOF. However, 1) there is
no deterministic relationship between value of loop control
variables and BOFs, and 2) the values of variables can be very
noisy and hard to interpret on the binary level. Therefore, we
decide not to include variable values in our data. Instead we
propose to incorporate some attributes of variables such as
whether a variable is immediate or is copied from the user
input.

Based on the above insights, we leverage a novel graph data
structure to capture the essential information. Since the graph
we build is based on the program’s runtime data ﬂow graph,
together with some spatial information, we call it Data Flow
Graph Plus (DFG+).

2) Model Selection:
Q3. Why is this a node classiﬁcation problem?
With the graph structure and its nodes and edges, graph
analysis tasks can be grouped into three categories [17]: graph
classiﬁcation, node classiﬁcation, and link prediction.

The graph classiﬁcation aims to classify graphs into dif-
ferent types. When it is applied to our DFG+, the problem
becomes classifying whether a program execution contains
silent BOF or not. Since the goal of our work is not only
to identify vulnerable execution, but also to locate the invalid
operations inside the execution, we cannot follow the graph
classiﬁcation task. Link prediction is the problem of inferring
missing relationships between entities (nodes), which also does
not ﬁt our need. Node classiﬁcation, on the other hand, aims
to classify nodes into different categories. If adopted, it could
distinguish vulnerable nodes and benign nodes in graph, and
the vulnerable point in execution trace can be located by
mapping nodes from the graph to program trace. Hence, the
proposed research goals can be achieved by solving a node
classiﬁcation problem.

Q4. Why is graph neural network a promising approach?
Firstly, the graph neural network can learn node features
and graph structure, which is exactly how the DFG+ encodes
data ﬂow information. Secondly, deep learn has shown very
promising result
in some reverse engineering works, such
as [30], [31]. In these works, it has shown superior perfor-
mance compared with traditional methods, which indicates
that it has great learning ability. Compared with other machine
learning algorithms, the deep neural network has following 2
superiority: As stated in [30], there are some attractive features
of neural network, “ﬁrst, neural networks can learn directly
from the original representation with minimal feature engi-
neering” and “second, neural networks can learn end-to-end,
where each of its constituent stages are trained simultaneously
in order to best solve the end goal”.

Q5. Why do we choose relational graph neural network?
Given the DFG+ with multiple types of edges as the training
data, it is natural to adopt the relational graph neural network.
RGCN [21] was originally proposed to represent knowledge
bases with entities and triples as directed labeled multi-graphs.
The entities are treated as nodes and the triples of the form
(subject, predicate, object) are encoded by labeled edges,
which is similar to the data structure in DFG+. There are other
models capable of modeling graph structured data, that we
think not suitable in our case. Graph recurrent neural network
(GRNN) [50] works on dynamic graphs where graphs are

5

Fig. 1: Approach overview.

evolving over time [51]. The GraphSAGE network [52] does
not consider different types of edges in node classiﬁcation. The
Heterogeneous graph neural network [53] aggregates hetero-
geneous attributes or contents associated with nodes, which is
overly complicated for DFG+, where nodes contain relatively
easy-to-encode attributes. Finally, label propagation [54] relies
on a nearest neighbor graph to generate pseudo-labels for
nodes and is often used in semi-supervised learning [55].

B. Overview

Fig.1 provides an overview of our proposed method, which
consists of two major phases. In the training phase, we develop
a runtime analyzer based on Intel Pin to trace program runtime
information and organize it into a graph structure (i.e., DFG+).
In the training samples, locations of invalid operations in
silent BOF execution are obtained through source code instru-
mentation. The invalid operations are reﬂected as vulnerable
labels for nodes in graph. We then train a BRGCN model on
the labeled DFG+ data, for testing in the following phase.
In the testing phase, the trained BRGCN model is used to
predict silent BOF in programs with binary only. The analyzer
will trace program runtime information and construct DFG+
without node label. It also generates maps that mapping each
node from DFG+ to instructions in program and in execution
trace. After labels are predicted for each node in DFG+, the
mapping can help us to locate the invalid operation in silent
BOF.

C. Challenges

Challenge 1: How to apply the model trained on multiple
programs/graphs to a previously-unseen program? Due to the
speciﬁcity of each program, selecting more semantic informa-
tion from program execution inevitably introduce knowledge
related to particular program logic into our dataset, which may
not hold in other programs. These knowledge, if learned by
the model, will hurt model’s generalization ability. As a result,
some previous works [56], [57] on neural network assisted
Fuzzing can only let a model be trained and tested on the
same program. We will discuss how to cope this challenge
shortly when presenting the design of DFG+ and graph neural
network in Section V-A and Section V-D, respectively.

Challenge 2: How to generate labels for DFG+? Generally,
training a high quality model needs a fair amount of training
samples with ground truth. We do not want to manually label
the nodes in DFG+, which requires lots of human efforts.
Hence, we need to develop a tool to label the data samples
automatically. The detail of how data are labeled is presented
in Section V-C1.

Challenge 3: How to represent spatial information in a deep
learning-friendly manner? Adding variable address to the

training data could be the simplest way to include the spatial
information. However, it is hard for the deep learning model
to learn the variable layout from the variable addresses. We
will discuss how we represent the spatial information so that
the deep learning model can quickly capture it in Section V-A.
Challenge 4: How to cope with extremely unbalanced
dataset? Each DFG+ generated from program execution has
more than 200,000 nodes on average, but only a few of them
are vulnerability nodes, which means the dataset is extremely
unbalanced.

V. DESIGN AND IMPLEMENTATION
In this section, we will ﬁrstly introduce the design of DFG+,
technique details of compiler plugin and run-time analyzer,
and how they work together to generate labeled DFG+. Then,
we present the BRGCN and how it helps to spot silent BOFs.

A. DFG+

1) Spatial Information: The trained model should be able to
capture the general information and ignore program-speciﬁc
information, so that the model trained on one set of DFG+
can be applied to the other set. The general information is the
knowledge shared among programs, such as the knowledge to
determine whether two variables are adjacent to each other.
The program-speciﬁc information is the knowledge that only
comes with a speciﬁc program, for example an integer variable
is located at 0x8048000.

information,

To encode spatial

there are two potential
methods: to integrate address of each variable into variable
attributes in data ﬂow graph or to use relations to reﬂect
the adjacency relationships of variables. We did not choose
the ﬁrst method due to two observations: 1) ﬁrst, the spatial
information, such as adjacency of two variable, are speciﬁc
relations between variables, rather than entities or attributes,
which should not be encoded as node features. 2) second,
the value of variable address is always associated with a
concrete execution and will change if a program is com-
piled with different compilers or options, or run in different
system environment (e.g., different heap allocation), or even
at different executions (e.g, different loading address due to
ASLR [58]). Integrating address into data ﬂow graph will
introduce program-speciﬁc information which is not helpful
for the model. Therefore, we instead use relations (edges in a
DFG+) to indicate if two variables are adjacent to each other.
In this way, we can represent the spatial information in a deep
learning-friendly manner.

2) Basic Design: Using the terminology from data ﬂow
analysis [59], a live variable is deﬁned when an instruction
writes value to the variable, and a live variable is used when
an instruction reads the value of the variable. A variable is

6

source codeexecutablessource code instrumentationlabeled DFG+runtime analyzerTrained BRGCNmodel trainingexecutablesunlabeled DFG+labeled DFG+vulnerability inforuntime analyzerTrained BRGCNvulnerability identification Training PhaseTesting Phaselive at a program point p if current value of this variable will
be used in future. A live variable v is dead at program point
q if after program point q the value of v is redeﬁned before it
is used or not will not be used anymore.

Nodes of Graph. A node in DFG+ represents a live variable.
Therefore, multiple nodes will created for a variable if the
variable is deﬁned and redeﬁned along with program execu-
tion. Note that the “variable” in our context not only refers
to variables deﬁned in source code, it can be operands of
any instructions (e.g., the return address on stack, register and
immediate value). According to the attributes of the variable
that a node corresponding to, we group nodes in graph into 4
types:

− Memory Node (m-node) denotes a live variable

stored in memory.

− Register Node (r-node) denotes a live variable

stored in register.

− Immediate Node (i-node) denotes an immediate

operand.

− External Node (e-node) denotes a variable de-
ﬁned by a system call. The e-node is a special type of
nodes for variables associated to external data (e.g., user inputs
and environment variables, and so on). The input data usually
contain dangerous variables, which could result in BOF.

Edges of Graph. We deﬁne 5 classes of directed edges in
DFG+ to reﬂect program’s direct or implicit information ﬂow
and spatial information. Note that each “variable” that appears
in following list is corresponding to a node in graph.

− Data Flow Edge (d-edge) denotes a direct infor-
mation ﬂow from a source variable to a target variable. There
exists a direct information if the value of the source variable
is used to calculate the value of the target variable.

− Adjacency Edge (a-edge) denotes that two vari-
ables are adjacent to each other. The direction of a-edge
denotes relative high or low of two variable addresses.

− Index Edge (i-edge) denotes an implicit infor-
mation ﬂow (implicit data ﬂow). The information ﬂow is
implicit if a pointer or offset a is used to address a variable b
to be read or written.

− Redefine Edge (r-edge) denotes that a live vari-
able is covered by another live variable. The r-edge not only
indicates that these two live variables are in the same address,
but also implicates the order of data ﬂow for this variable.

− Comparison Edge (c-edge) denotes another kind
information ﬂow, which happens when a live
of implicit
variable be compared with another live variable. The values of
their operands will affect the value in eflags register, which
then affect target of a conditional branch.

Fig. 2 shows a DFG+ generated from the execution of a
piece of code in Code 2. The executed instruction sequence
is [1, 2, 3, 4, 13, 14, 5, 6, 7, 8, 9, 10, 11, 12]. Let’s take the several
nodes and edges generated from sub $0x94, %esp, as an
example to demonstrate how the graph is generated. Node 1,
2, and 3 , represent immediate $0x94, source operand %esp,
and the destination operand %esp, respectively. There is a
d-edge and r-edge between 2 and 3 because the old value
in %esp was used to calculate new value for %esp, and live
variable in %esp is redeﬁned. Besides, the a-edge between
node 6 and 8 denotes that live variables in -0x10(%ebp) and
-0x14(%ebp) are adjacent to each other. The i-edge from
node 5 to node 6 denotes that -0x14(%ebp) is used to address

Fig. 2: A DFG+ generated from execution of a piece of code.

variable in -0x10(%ebp). The c-edge from node 6 and 9 to
10 denotes that that the comparison between live variable in
-0x10(%ebp) and immediate number $0x20 determines the
value in %eflags.

Labels of Nodes. There are two types of labels for graphs
nodes: 1) vulnerable label represents that the node is
generated from an invalid operation in silent BOF; 2) benign
label represents that it is generated from normal operation.
3) Reﬂection: Through the noval design, variable type,
information ﬂow and adjacency relationships of variables gath-
ered through program tracing are represented by node features
and graph structure through different types of edges (relations).
From the graph, we can not only clearly see the different graph
structure associated with different type of operations, but also
see the difﬁculty to compare the difference between graph
structures for vulnerable and benign nodes manually through
human efforts. In Section V-D, we will show how Graph
Neural Network capture these features through representation
learning.

Here, we talk about how the design of DFG+ helps to
overcome Challenge 1. The novel design of DFG+ aims to
encode general information and eliminate program-speciﬁc
information in program so that our trained model on some
programs is able to be applied to other programs. Speciﬁ-
cally, variable address, variable value, and opcodes which are
tightly associated with a speciﬁc program, are not included in
DFG+. Instead, we select address agnostic and value agnostic
features – information ﬂow, variable adjacency and general
variable features – from execution trace, and encode them as
different types of edges and node features in DFG+. So that a
model trained on training set can applied to predict labels on
the testing DFG+.

B. Compiler Plugin for Data Labeling

We implement a tool to insert some code to binary through
source code instrumentation, which can automatically distin-
guish vulnerable and benign operations in program execution.
As discussed in the related works, ASAN can detect out-
of-bound memory accesses (i.e., invalid operations) in BOF
execution. Therefore, we leverage ASAN to detect the invalid
vulnerable operations, which helps the graph constructor (to
be discussed in next subsection) to label the nodes. However,
ASAN has four features, which pose 4 problems in our
scenario: 1) ASAN inserts extra instructions before memory
allocation, access and destroy. 2) ASAN inserts Redzone
among variables, which change the adjacency relationships
of variables. 3) ASAN reports memory errors by outputing

7

m-noder-nodee-nodei-noded-edgei-edger-edgec-edgea-edge124365781011121416171819202113232224252691527vulnerable information, then terminate the execution. 4) ASAN
can only detect BOF on function level for function linked
from external libraries. Speciﬁcally, ASAN hooks function call
to library functions, and provides wrapper functions to check
whether BOF happens by analyzing the parameters passed to
these library functions.

The extra instructions inserted by ASAN will introduce
irrelevant information ﬂow and the inserted Redzones break
some a-edges in the constructed DFG+. Besides,
if the
execution terminates at the point of ﬁrst invalid access, the
data ﬂow afterwards will be missing, so we have to modify
ASAN to make it report invalid operations without terminating
the program’s execution. In the following paragraphs, we will
show how we solve these problems.

1) How To Exclude Irrelevant Data Flow from Instructions
Inserted by ASAN?: To deal with the ﬁrst problem, we need to
distinguish program’s original instructions and the instructions
inserted by ASAN. To achieve this goal, we modify the
compiler plugin from ASAN to insert a pair of instructions
(i.e., prefetcht1 and prefetcht2) at the beginning and
end of each piece of code inserted by the ASAN. The pair of
instruction serves as indicators that can be easily distinguished
and skipped when the runtime analyzer builds DFG+ along
with program execution. We adopt prefetch instructions
because prefetch has no side effect to program’s runtime
state and we can easily disable them.

2) How to Restore the Relation of Variable Adjacency?:
To handle the second problem, we leverage the shadow
memory to restore the original relation of variable adjacency.
Speciﬁcally, shadow memory maintained by ASAN’s runtime
environment recorder the location of inserted Redzone in
the address space of target program. The compiler plugin
will save conﬁguration of shadow memory and share it to
the graph constructor. Through these conﬁguration, the graph
constructor can query the shadow memory and restore the
original adjacency relationships of variables. We will discuss
the details of how the adjacency relationships are restored in
Section V-C2.

3) How to Label Nodes Generated from Vulnerable Oper-
ations?: To solve this problem, we let the compiler plugin
to emit prefetcha as indicator before each suspicious in-
struction (that results to out-of-bound read/write). Since ASAN
checks the validity of target address before each suspicious
memory access, and prefetcha will only be executed when
memory errors are detected before it really happens. By
this way, the runtime analysis routine be notiﬁed through
prefetcha and assigns different labels to nodes, accord-
ingly. Thus, we can achieve our goal without terminating the
program execution and introducing any irrelevant data ﬂow.

4) How to Identify Vulnerable Operations in Library Func-
tions?: To solve the last problem, we instrument the necessary
libraries with customized compiler, then link the instrumented
library functions to target program. However, we observe that
the most commonly used library in linux – glibc – cannot be
compiled by LLVM due to some unsupported features, and the
llvm-libc is still in planing phase [60]. Alternatively, we only
instrumented vulnerable functions in glibc, such as scanf
and strcpy. Then, in the runtime library (runtime-rt [61])
of LLVM, we hook calls to these vulnerable functions and
redirect execution to instrumented ones. In such a case, the
vulnerable node in the glibc can be labeled accurately.

CAVEAT. The customized compiler plugin is only used to
help the runtime analyzer to assign labels to vulnerable nodes
in built graph. The runtimer analyzer will assume all other
nodes in graphs as benign nodes. Therefore, there is no need to
instrument other functions without vulnerabilities in libraries.
However, the memory allocation and free functions, such as
malloc and free, are special cases. Even through no BOF
happens in these functions, we still need to instrument these
functions to update the shadow memory.

C. DFG+ Construction based on Runtime Analyzer

The runtime analyzer

is implemented based on Intel
Pin [18], which builds DFG+ along with program’s execution.
Intel Pin provides comprehensive APIs for code inspection
and instrumentation:
the inspection APIs helps to analyze
instructions in binary and the code instrumentation APIs help
to instrument code according to the results of inspection.
The developed runtime analyzer consists of three components:
dynamic code analysis and instrumentation, memory layout
restoration, and graph construction. Fig. 3 demonstrates the
whole workﬂow.

1) Dynamic Code Analysis and Instrumentation: The dy-
namic code instrumentation consists of three phases: code
inspection, code instrumentation and runtime analysis. Before
code instrumentation the analyzer ﬁrstly analyzes instructions
and system calls. Three types of callback functions will be
registered according to the analysis results:

code

information

The
easily

some
uses

ﬂow can
examples:

• Instruction Callback.

be
the
1memory-to-register

structure
understood
of
analysis
given
routine
and
2register-to-register to deﬁne the structures
of information ﬂow in mov 0x8048000, %eax, sub
%eax, %ebx, respectively. Then, callback functions are
registered to instructions according to the types and
structures of information ﬂow as demonstrated in Fig. 3.
• System Call Callback. Some system calls copy
some external data to program space, the variables in
which should be recognized as e-nodes. Call back
functions are registered to these system calls to label
corresponding memory regions at runtime.

• Control Callback. Two callback functions should
be registered to prefetcht1 and prefetcht2 to stop
and resubmit the runtime tracing respectively, so that
inserted pieces of code by ASAN can be skipped. A
callback function should be registered to prefetchta
to receive the signal about invalid operations, and assign
labels to corresponding vulnerable nodes accordingly.
The compiler plugin based on LLVM instruments code
on the intermediate representation (IR) during compilation.
During experiments, we observe that some instructions reside
outside of prefetcht1-prefetcht2 pair in IR level dur-
ing source code instrumentation ﬂoat to position which are
enclosed by prefetcht1-prefetcht2, due to instruction
reordering [62]. In such case, information ﬂow resulting from
the ﬂoated instructions will be lost if we simply stop the
analysis process when execution enters code enclosed by
prefetcht1-prefetcht2.

To solve the problem, we adopt static data ﬂow analysis
to identify the ﬂoated instructions insides the prefetcht1-
prefetcht2 pair based on one heuristic rule: an instruction

8

Fig. 3: Workﬂow of the runtime analyzer to build DFG+ with node labels.

i inside prefetcht1-prefetcht2 pair is a ﬂoated instruc-
tion if there is a data dependency between an instructions j
which is after prefetcht2 and i. Accordingly, we will not
exclude information ﬂow resulting from the ﬂoated instruc-
tions in runtime analyzer. Then, along with program execution,
the callback functions will capture the information ﬂow and
access memory addresses from executed instructions, and send
them to the graph constructor and adjacency relationships
restorer.

2) Adjacency Relationships Restoration: We observe that
there are three kinds of changed adjacency relationships of
variables, requiring different treatments respectively. We will
show these three cases based on Fig. 4, which shows the layout
of a memory fragment before and after instrumentation by
ASAN.

Firstly, case (cid:172) does not need any restoration. For byte(s) in-
side a buffer or variable, the inserted Redzones do not affect
its adjacency relationships, thereby needing no restoration.

Secondly, case (cid:173) needs restoration. For byte(s) on the
boundary of a buffer or variable, its adjacency relationships
get changed because of the inserted Redzone. For example,
the adjacent bytes of i+4 in ML is the byte i+3 and byte i+5.
However, in the ML w/ Redzone, the adjacent bytes for j+12
is byte j+11 and j+13, and the byte j+11 is located in the
Redzone. To restore adjacency relationships for this kind of
byte(s), we ﬁnd the real adjacent bytes by skipping bytes in
Redzone. By skipping Redzone2, the real adjacent byte,

i

i+4

i+12

...

...

var1

buf1

var2

(a) Original memory layout (ML).

j

j+4

j+8

j+12

j+20

j+24

j+28

...

...

i.e., j+7, of byte j+12 can be found.

Thirdly, case (cid:174), which happens in BOF, also needs
restoration. When out-of-bound access happens in a ML w/
Redzone, one or several byte(s) (e.g., x) in Redzone will
be read/written. If the invalid access is mapped to the ML,
the out-of-bound read/write will read/write a byte(s) near
the vulnerable buffer in high address. The following three
steps can help to ﬁnd the corresponding byte(s) in ML w/
Redzone:

1) First, ﬁnding the boundary byte (b) of BOF, which is the
byte near the ﬁrst overﬂow byte(s) in low address.
2) Second, calculating the distance (d) between b and x.
3) Third, ﬁnding byte(s) (y) by shifting d-1 byte from the
b to higher address, while skipping all bytes in Redzone.
After mapping the byte(s) x in Redzone to a byte(s)
y outside of Redzone, the adjacent bytes found through
strategies adopted in case (cid:172), (cid:173), and (cid:174) for y is the restored
adjacent bytes for x. For example, through aforementioned
strategies, we can map byte in j+21 to byte in j+25 and ﬁnd
its real adjacent bytes in j+24 and j+26.

3) Graph Construction: After the information ﬂow are
captured and ﬁltered through callback functions at runtime,
and the adjacency relationships are restored through afore-
mentioned three strategies, it is straightforward to construct
DFG+. We will not cover the details of graph construction.

Supporting Data. Some data, named as supporting data as
shown in Fig. 3, is important not only in the graph construction
phase, but also in vulnerability identiﬁcation phase. For exam-
ple, 1) map that maps a node in DFG+ to the address of its
corresponding variable, 2) map maps a node to the instruction,
which creates the node, and so on. We will show how these
information is used in Section V-E.

CAVEAT. After the model is trained, we no longer need
source code to generate labels, as the model will predict them
for us. The building the unlabeled graphs for binary-only
programs in testing phase as shown in Fig. 1, is much easier.
Since the analyzed programs are not to be instrumented, there
is no need to exclude irrelevant instructions and restore the
adjacency relationships of variables.

red1

var1

red2

buf1

red3

var2

red4

D. Our Graph Neural Network

(b) Memory layout (ML) after code instrumentation (w/ Redzone).

Fig. 4: Comparison between memory layouts with and
without Redzone.

DFG+ is a novel graph data structure to hold variable
attributes, program information ﬂow and variable layout. Gen-
erally, the vulnerable data ﬂow in the execution context and the
variable layout for some variables corrupted by silent buffer

9

......sub $0x94,%espmovl$0x0,-0x10(%ebp)movl$0x0,-0x14(%ebp)jmptarget2target1:call <receive>mov %eax,-0xc(%ebp)cmpl$0xffffffff,-0xc(%ebp)je target3……DFG+mov $0x0, -0x14(%ebp) Callback Fun_mov_r2r_(){……}returnCode Data Space…Shadow Mem…Program SpaceQuery Interfacereturn…Supporting dataDynamic Code Analysis and Instrumentation Adjacency Relationships RestorationGraph ConstructionInformation flowVariable Adjacency…read or writecontrol flowNodes and edgesRestorerAccessed   AddressesConstructoroverﬂow could be different from that of non-affected variables.
In other word, the local graph centered at a vulnerable node
would be slightly different from that of benign node. Thus,
detecting vulnerability is equivalent to node classiﬁcation by
considering the local graph centered at each node. Thus, we
need to design a model that’s able to learn node representa-
tions that capture the local graph structure and neighborhood
information, which facilitates the differentiation of vulnerable
nodes from benign nodes. Thanks to the message passing
mechanism, GNNs are good at learning node representations
by aggregating a node’s neighborhood information. Thus, we
adopt GNNs for DFG+. As DFG+ has different types of nodes
and edges, we propose to adopt RGCN [21] as our basic
model because it is developed for representation learning in
knowledge graph, which also have different types of nodes
and edges.

Essentially, the multiple layer RGCN learns node represen-
tation for a node vx by aggregating features (attributes) of node
vx and its neighbors through message passing. In particular,
for different types of edges/nodes, it use different parameters
during message passing, thus preserving the edge/node type
information. The propagation rule of RGCN in the l-th layer
for calculating the forward-pass update of a node vi is:

h(l+1)
i

= σ





(cid:88)

(cid:88)

r∈R

j∈N r
i

1
ci,r

W (l)

r h(l)

j + W (l)

s h(l)

i



 ,

(2)

where N r
i denotes the set of neighbor indices of node i under
relation r ∈ R and R is a set of relation (edge types). ci,r is
a normalization constant that we set as the count of neighbor
relation r for node i. W (l)
is relation-speciﬁc transformations
r
matrix for relation r, which enables relation-speciﬁc message
passing, thus preserving edge type relationship. To ensure
that the representation of a node at layer l + 1 can also be
informed by the corresponding representation at layer l, a
single self-connection (i.e., W (l)
s ) term is added. All messages
passed along with incoming edges are aggregated through an
element-wise activation function σ(·). W (l)
are the
r
parameters to be learned. By stacking K-layers of RGCN
together, the representation of node vi could capture the K-
hop local graph information centered at node vi.

and W (l)
s

Limitation of RGCN.
Equation 2 is the basic design
of RGCN, which has shown promising result in the early
research [21]. For node classiﬁcation in DFG+, however, the
features of a node x’s outgoing nodes are not used in an
appropriate way. If N r
i is deﬁned as the set of neighbor indices
of node vi under relation r through incoming edge, message
can only pass along in these directions. As a consequence,
node representation learned by the network only aggregates
features from incoming nodes and some important features
from outgoing nodes are lost. For example, if a global variable
is used twice at runtime, its corresponding node x in the
DFG+ will have two outgoing d-edges to node y and z re-
spectively, i.e., y(cid:13) ← x(cid:13) → z(cid:13). In such case, the feature cannot
be propagated from y to z or from z to y through x, which
is undesired because node y could be very useful to classify
node z and vice versa. For nodes without incoming links such
as x in the previous example, no information will propagate
to them and thus we cannot learn good representations.

RGCN with Bi-directional Propagation. One straightfor-
ward solution to the above issues would be ignoring the direc-
tion of the edge, i.e., if the N r
i is deﬁned as the set of neighbor
indices of node i under the relation r through either incoming
edge or outgoing edge, messages will get processed with
the same relation-speciﬁc transformations W (l)
r . However, this
will ignore the difference of incoming and outgoing directions.
From the observations above, we extend the basic design to
a bi-directional propagation for directed graphs. Speciﬁcally,
we adopt two set of parameter for each type of edge:

is used to propagate messages along with the

1) W in
r
direction of directed edge;
2) W out
r
of directed edge;
We deﬁne the propagation rule as:

is used to propagate messages against the direction

h(l+1)
i

= σ





(cid:88)





(cid:88)

r∈R

j∈IN r
i

1
ci,r

W in(l)
r

h(l)
j +

(cid:88)

1
ci,r

W out(l)
r

h(l)
k


 + W (l)

0 h(l)

i

(3)





k∈OU T r
i
i and OUT r

where IN r
i denote the set of incoming neighbors
and outgoing neighbors for node i under the relation r ∈ R,
respectively. The transformations W (l) is applied based on the
type and direction of edge. By designing two sets of weights
for both directions, we make sure that the information of
node y has a chance to propagate to node z and vice versa
(the example shown in the last subsection). In our evaluation,
we will quantitatively evaluate the model represented by
Equation 3 and compare its effectiveness with the basic design
denoted by Equation 2.

Moreover, we deprecate the common one-hot encoding of
IDs for each node as adopted by [21]. Instead, we make the
type of node as the node features, and expect the model to
behave the same regardless of the node order. We will evaluate
its effectiveness in Section VII.

Fig. 5(a) shows the framework of BRGCN, which takes
DFG+ as input and predict the labels for each nodes. DFG+
consists of difference types of nodes and edges, which are
marked with different colors in the ﬁgure. The W and c in
Equation 3 are parameters of the model, which is learned
during the training phase. Initially, node features in DFG+
are embedded and fed into the model as the input of the
ﬁrst layer. Then, layer l computes the update feature (latent
node representation h(l+1)) for each node vi by aggregating
features from its neighbors and itself. The output of the
previous layer become the input to the next layer. Finally, in
the output layer, sof tmax(·) activation is applied to generate
label probabilities.

Fig. 5(b) illustrates message-passing when calculating up-
date feature for a node i in layer l. Features from neighboring
nodes are gathered and then transformed for each relation
type individually, together with different transformation matrix
W s for different types of edges. For example, W out(l)
is the
transformation matrix for outgoing blue edges. The resulting
representations are accumulated and normalized. We choose
ReLU as activation function in our model.

blue

DFG+ is a directed graph G = (V, F, E, R) with nodes
(entities) vi ∈ V have feature fi ∈ F, and edges with (rela-
tions) (vi, r, vj) ∈ E, where r ∈ R is a relation type. In each

10

Fig. 5: Bi-directional Relational Graph Convolutional Network.

), where h(1)

layer l, node features are updated through function deﬁned
in Equation 3. For each node, its old features (h(l)
i ) and its
neighbors’ old features (h(l)
j ) are passed along with the edges
((vi, r, vj) ∈ E ∨ (vj, r, vi) ∈ E), and then aggregated through
a normalized sum ((cid:80)(·)) and an activation function (σ(·)) to
get the updated new features (h(l+1)
i = fi in
the input layer. A n-layer network allows for message passing
across n-hop in the graph. Therefore, the representation of a
nodex learned by a n-layer BRGCN model aggregates node
features from a n-hop subgraph centered on nodex. Besides,
the different sets of weights W d(l)
for different types of edges
r
and sum-aggregation adopted in Equation 3 can help to learn
the graph structures corresponding to information ﬂow and
variable adjacency, respectively. By learning different graph
structures and node features, we believe that the network can
distinguish vulnerable and benign nodes.

i

To train the model, we minimize the following cross-entropy

loss on all labeled nodes:

min
θ

L = −

(cid:88)

G∈G

1
|Y|

(cid:88)

K
(cid:88)

i∈Y

k=1

wk · yik ln h(L)
ik ,

(4)

i

i

where G is a graph in the training set G, Y is the set of
nodes in our training samples. h(L)
is the output of BRGCN
for node i. Note that we used softmax function for the last
layer. Thus h(L)
denotes the predicted class distribution for
node i with h(L)
ik being the probability of node i belonging
to class k, k = {0, 1}. wk is the weight for class k and yik
denotes respective ground truth label for node i. We introduce
wk in our loss function because class distribution in DFG+ is
extremely imbalanced, i.e., the majority of the nodes are nega-
tive nodes (benign nodes), while the positive nodes (vulnerable
nodes) only take up a very small portion. To avoid the majority
class dominate the loss function, we assign larger weight to
0 , W in(l)
positive class. θ = {W (l)
l=1 is the
r
set of the model parameters. After the loss is calculated in
each training epoch, backward propagation computes gradient
of the loss function with respect to the trainable parameters θ,
then parameters are updated to minimize loss.

; r ∈ R}L

, W in(l)
r

Model Parameter Size and Time Complexity. For simplicity
of the analysis, we ﬁrst deﬁne the dimensionality of W in(l)
and W out(l)
∈ Rdl×dl+1,
r
where dl and dl+1 is the dimensionality of the node rep-
resentation in the l-th layer and (l + 1)-th layer, respec-
tively. Since θ = {W (l)
l=1 is the

∈ Rdl×dl+1 and W out(l)

0 , W in(l)

as W in(l)
r

; r ∈ R}L

, W in(l)
r

r

r

r

l=1

(cid:80)

set of parameters for BRGCN, the model parameter size is
O((cid:80)L

r∈R dl · dl+1) = O((cid:80)L

l=1 dl · dl+1 · |R|).

r∈R(|IN r

For the forward pass of BRGCN, the main time complexity
in the l-th layer for node vi is the calculation of Equation 3,
which is O((cid:80)
i |+|OUT r
i |)·dl·dl+1). It is equivalent
to O(Di·dl·dl+1), where Di = (cid:80)
i |+|OUT r
r∈R(|IN r
i |) is the
summation of the in-degree and out-degree of node vi. Thus,
the time complexity of BRGCN for node vi is O(Di ·(cid:80)L
l=1 dl ·
dl+1). Then, the computational cost of BRGCN for a DFG+
graph is O((cid:80)
l=1 dl · dl+1), which is equivalent to
O(|E| (cid:80)L
l=1 dl ·dl+1), where E is the set of edge in DFG+. The
complexity of the backward propagation via gradient descent
is the same as the forward pass. Thus, the total cost in one
iteration is O(|E| (cid:80)L

i Di · (cid:80)L

l=1 dl · dl+1).

E. Vulnerability Identiﬁcation

In this subsection, we demonstrate how the trained model
achieve the goal as proposed in Section III-A. In the training
phase, we leverage source code of vulnerable programs, inputs
that can trigger the vulnerabilities, and the tools that we
present in early subsection to generate labeled DFG+ and
save the corresponding supporting data. Then we train the
model with the generated DFG+ from the vulnerable execution.
Through the forward prorogation (message passing) rules
deﬁned in Equation 3, loss function deﬁned in Equation 4,
and backward prorogation to update the trainable parameters
in the model, we get an effective model which can predict
labels for nodes an given unlabeled DFG+.

In the testing phase we apply the trained model to predict
the labels for unlabeled DFG+ generated from binary-only
software. Through the maps in the supporting data created
by the runtime analyzer, the vulnerable nodes in DFG+ can
be mapped to corresponding instruction addresses in binary
code and execution trace. Since the execution trace contains
the address of memory operands, the address of corrupted
variable can also be identiﬁed. Note that in some cases that
one execution may trigger several silent BOF vulnerabilities,
the vulnerable instructions and corrupted variables can be
identiﬁed separately.
F. Implementation

We implement our system on 32-bit Linux system with Intel
x86 Instruction Set Architecture. The compiler plugin is built
based on the LLVM-5.0.0 and its runtime library is built on
runtime-rt-5.0.0. The plugin and runtime library consists of 82
lines of new code and 2236 lines of new code, respectively,
when comparing with implementation of ASAN. The dynamic

11

DFG+…ReLU…ReLU…Output000100000Hidden Layer(1)Hidden Layer (2)(a) The model overview. (b) Message propagation for one node.binary analyzer and graph constructor are developed on the
Intel Pin 3.10., which consists of 9900 lines of C++ code in
total. The graph model consists of 800 lines of Python code,
and is implemented base on the DGL v0.4.3 [63], an high
performance and salable Python package for deep learning on
graph typed data.

VI. EXPERIMENT AND RESULTS

A. Data Generation and Preprocessing

We select 30 reproducible CVEs as shown in Table II from
a repository of Linux vulnerabilities [64]. We generate three
labeled DFG+ for each CVE, from three different executions:
In the ﬁrst execution, we compile the program by the compiler
plugin and ﬁnd an input to trigger the vulnerability. In the
second execution, we change the input which overﬂow the
buffer with different length. In the third execution, we change
the length of vulnerable buffer in the program’s source code,
recompile it to binary through our compiler plugin, and run
the modiﬁed program again. In all three executions, inputs are
able to trigger the vulnerable without crashing the execution.
Since the length of vulnerable buffer or input can be hardly be
changed in some programs, we ﬁnally get 86 labeled DFG+s
with over 35 millions (35084810) nodes, of which only 6708
nodes are positive.

We observe that the constructed DFG+ vary largely in size
(number of nodes), from a few thousands to a few millions.
It is impossible to ﬁt an entire DFG+ into BRGCN for end-
to-end training, especially for those DFG+ with more than 3
millions of nodes. To alleviate this problem, we propose a
graph cutting algorithm (the detaill of the Algorithm 1 is in
the appendices). In the cutting algorithm, we ﬁrstly cut a big
graph into several small graph by removing edges that connect
different sub-graphs, all the nodes in the sub-graphs is sample
nodes. Secondly, we add n-hop neighbors to each sub-graph
as supporting node, where n is the number of model layers.
When training model on the sub-graphs, both supporting node
and sample nodes are involved in forward propagation whereas
only the sample nodes was considered for calculating loss.

As can be noticed above, the dataset is extremely imbal-
anced – the ratio between positive and negative nodes is
roughly 1/5230. To further reduce the number of negative
nodes, we exclude all the r-node and i-node in sample
nodes because BOF can only overwrite variables in mem-
ory. We also exclude nodes without any incoming d-edge
because the live variables associated with vulnerable nodes
must be written through invalid operation in BOF. After the
exclusion, we are able to reduce the ratio to 1/659. Note that
by excluding we mean we won’t choose them as sample nodes
in sub-graphs. Instead, we select them as supporting nodes if
they are the neighbors of sample nodes to help classify the
sample nodes in sub-graphs. Finally, we further reduce the
number of negative through random sample.

B. Evaluation

We experimented with different number of layers, size of
hidden states, and dropout rates to ﬁnd the best performing
model. Currently BRGCN has 4 layers including an input layer
and an output layer and each layer has hidden states with
dimension 16. 10 sets of parameters (W ) are used for 5 types
for edges (2 sets of parameters for each type).

After we get the best conﬁgurations, we adopt 8-fold cross-
validation to comprehensively evaluate the model. In each

TABLE II: Information and testing results of each CVE cases.

Vulnerability Information

CVE-ID
CVE-2004-0597
CVE-2004-1120
CVE-2004-1255
CVE-2004-1257
CVE-2004-1261
CVE-2004-1262
CVE-2004-1275
CVE-2004-1278
CVE-2004-1279
CVE-2004-1287
CVE-2004-1288
CVE-2004-1289
CVE-2004-1290
CVE-2004-1292
CVE-2004-1293
CVE-2004-1297
CVE-2004-2093
CVE-2004-2167
CVE-2005-0101
CVE-2005-3862
CVE-2005-4807
CVE-2007-1465
CVE-2009-1759
CVE-2009-2286
CVE-2009-5018
CVE-2010-2891
EDB-890
EDB-9264
EDB-14904
EDB-15062

Name
pngslap
proz
2fax
abc2mtex
asp2php
bsb2ppm
html2hdml
jcabc2ps
jpegtoavi
nasm
o3read
pcal
pgn2web
ringtonetools
rtf2latex2e.bin
unrtf
rsync
latex2rtf
newspost
unalz
as-new
dproxy
ctorrent
compface
gif2png
smisubtree
psnup
stftp
fcrackzip
rarcrack

Region
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack
stack

Analysis Result
Detected

(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:55)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)
(cid:51)

round of the cross-validation, we select 75%, 12.5% and
12.5% of 86 graphs as training set, validation set and testing
set. Table III presents the Accuracy, Precision, Recall and
F1 on the test set. Our model achieve 94.39% accuracy and
94.18% F1 score on the sampled dataset. Since we are the ﬁrst
one to analyze the silent vulnerability through deep learning,
we cannot ﬁnd the similar works to compare. However, we
will compare our design with some other potential designs in
next section.

Then, we examine our model’s ability to identify vulnerable
operations in silent BOFs. Since a silent BOF will result in
one or more vulnerable nodes, we can successfully locate
the vulnerable operation as long as one vulnerable node is
identiﬁed. As a result the vulnerabilities detection rate is much
better than the vulnerable node detection rate. Table II shows
the detection results when we map the vulnerable node in
test phase to the executables. Due the limited numbers of
global/heap buffer overﬂow in vulnerability database, we did
not ﬁnd a reproducible one in our evaluation. But we modify
vulnerable stack buffers in several cases displaied in Table II to

TABLE III: The overall performance of our proposed models.

Fold
fold-1
fold-2
fold-3
fold-4
fold-5
fold-6
fold-7
fold-8
Average

Accuracy
0.8871
0.9623
0.9712
0.9072
0.9617
0.9503
0.9359
0.9757
0.9439

Precision
0.9828
1.0000
0.9455
0.9167
0.9657
0.9244
0.8864
0.9537
0.9469

Recall
0.7703
0.9298
1.0000
0.8958
0.9574
0.9821
1.0000
1.0000
0.9419

F1
0.8636
0.9636
0.9719
0.9060
0.9615
0.9523
0.9397
0.9763
0.9418

12

global/heap buffers, ensure the buffer overﬂow corrupted some
adjacent variables, and successfully identify them through our
trained model. In summary, our model successfully identify
and locate 29 vulnerabilities out of 30 CVE traces. The
evaluation result indicate that the vulnerable patterns in data
ﬂow level for stack BOF, global BOF and heap BOF are
similar.

VII. EXPLAINABILITY
When designing DFG+ and BRGCN, we raise several insights
based on our intuitions, in this section we try to explain their
effectiveness through several experiments. Accordingly, we put
forward several evaluation questions: 1) Can sequenced model
such as RNN and LSTM solve the problem through analysis
on the instruction sequence directly? 2) If a homogeneous
graph, rather than a more complex relational graph, is enough
to classify vulnerable nodes in DFG+? 3) Is BRGCN deﬁned in
Equation 3 more effective than RGCN deﬁned in Equation 2?
4) Can BRGCN effectively identify vulnerable nodes in tra-
ditional data ﬂow graphs? 5) Can BRGCN effectively identify
vulnerable nodes in DFG+ with ID as node attributes? 6) Does
BRGCN really beneﬁt from training on multiple graphs?

To answer these questions, we setup 4 groups of experi-
ments. In the ﬁrst group of experiments, we ﬁrstly generate
instruction trace which includes executed instructions and
access memory addresses, secondly split the instruction trace
into ﬁx-length sequence to make them end with memory
access instructions. Thirdly, if the last instruction of a sequence
results in vulnerable operation in silent BOF, we label this
sequence as vulnerable sequence, otherwise we label it as
benign sequence. Fourthly, we sample the same positive sam-
ples and negative samples as that sampled in training BRGCN.
Finally, we adopt an open source implementation of Memory-
Augmented RNN and LSTM [65] to classify execution traces
and the results are reported in Table IV. From the experiment
results, we can easily conclude that RNN and LSTM cannot
help to identify vulnerable operation by analyzing instruction
sequence with access memory addresses.

In the second group of experiments, we adopt ConvGNN
and RGCN and train models on DFG+. In the ConvGNN,
all types of edges are treated homogeneously and processed
with the same weight matrix W . The RGCN adopts different
propagation rules for different edge types, and propagate node
features along with the incoming direction of edges. The
experiment results in Table IV shows that the performance of
BRGCN is better than RGCN, and the performance of RGCN
is better than ConvGNN. This indicates that adopting two sets
of parameters for each type of edge is more effective than one
set of parameter for each type and a single set of parameter
regardless of edge types.

In the third group of experiments, we change the structure
of DFG+. There are two variants: 1) graphs with only program
runtime data ﬂow, and 2) graphs with nodes that are assigned
unique IDs as node attributes. Then, we train BRGCN model
on the two sets of modiﬁed graphs and display their result
in Table IV. From the results we know: 1) the BRGCN
cannot distinguish signiﬁcant difference between local graph
structures of invalid operations and other benign operations in
data ﬂow graph only, the adoption of spatial information and
other implicit information ﬂow plays an important role for the
node classiﬁcation problem and 2) when training a model on
different graphs, the adopting of node IDs as node attributes
is harmful.

TABLE IV: The performance comparison of different neural
networks and graph structures.

Group

1

2

3

4

Setting
RNN
LSTM
ConvGCN
RGCN
BRGCN w/
DF-Only
BRGCN w/
Node-ID
BRGCN w/
One-Program

Accuracy
0.4977
0.4948
0.7914
0.8411

Precision
0.4994
0.4929
0.8105
0.8699

Recall
0.5557
0.5136
0.7619
0.8158

F1
0.5260
0.5030
0.7616
0.8175

0.7001

0.6126

0.7702

0.6793

0.7686

0.7769

0.7466

0.7577

0.5741

0.4839

0.3562

0.4215

In the last group of experiments, we try to train our model
on graphs generated from a single program and test it on
other programs. The evaluation result shows that the model
trained on a single program is signiﬁcantly worse than model
trained on multiple programs. We conclude that by carefully
designing the DFG+, our model can beneﬁt from different
programs/graphs. It indicates common semantic features for
BOF vulnerabilities are shared by different programs.

VIII. LIMITATIONS AND CONCLUSION

Our approach suffers from several limitations. First, al-
though we achieve high detection rate of silent BOFs, there is
considerable false-positive predictions on nodes, meaning that
some benign nodes are falsely classiﬁed as vulnerable nodes.
This is inherent from the extreme imbalance of the number
of positive and negative nodes, which has a ratio as low as
0.0002. We have tried to down-sample the negative nodes and
apply a class-weighted loss function during training, it is still
an issue because any single percentage drop of classiﬁcation
precision would lead to considerable false positive predictions.
Second, although our model can test a graph very quickly (less
than 0.2 seconds on average), there is an overhead in collecting
program runtime data ﬂow and building DFG+. Unless we
can trace program data ﬂow on the ﬂy, it is not practical to
deploy our framework for detecting vulnerabilities in real time
production environment.

In this paper, we design a novel graph data structure
DFG+ to represent the program’s runtime information ﬂow
and variables’ spatial
information. A runtime analyzer is
implemented to construct DFG+ and the AddressSanitizer is
customized to help label the nodes. We further propose BRGCN
to analyze DFG+ and detect vulnerable nodes with 94.39%
accuracy. Through mapping of the vulnerable nodes back to
the execution trace, we are able to locate the vulnerable points
in the program at the binary level. We believe the DFG+ and
the BRGCN proposed in our work have wide applications.
Our proposed scheme could be used in vulnerability analysis
to help locate vulnerable point, in software patch to help
generate patches in the binary, in exploit generation to help
attack vulnerable software, and in software testing to help ﬁnd
software bugs.

Finally, we would like to suggest some future works
that could supplement our approach. Some possible avenues
include applying the GNN-based approach to other silent
vulnerable executions such as detecting buffer overread or on
obfuscated programs.

13

REFERENCES

[1] L. Szekeres, M. Payer, T. Wei, and D. Song, “Sok: Eternal war in
IEEE,

memory,” in 2013 IEEE Symposium on Security and Privacy.
2013, pp. 48–62.

[2] B. Liu, L. Shi, Z. Cai, and M. Li, “Software vulnerability discovery
techniques: A survey,” in 2012 Fourth International Conference on
Multimedia Information Networking and Security, Nov 2012, pp. 152–
156.

[3] J. C. King, “Symbolic execution and program testing,” Commun.
ACM, vol. 19, no. 7, pp. 385–394, Jul. 1976. [Online]. Available:
http://doi.acm.org/10.1145/360248.360252

[4] I. Yun, S. Lee, M. Xu, Y. Jang, and T. Kim, “QSYM : A
practical concolic execution engine tailored for hybrid fuzzing,” in 27th
USENIX Security Symposium (USENIX Security 18). Baltimore, MD:
USENIX Association, Aug. 2018, pp. 745–761. [Online]. Available:
https://www.usenix.org/conference/usenixsecurity18/presentation/yun
[5] J. Xu, D. Mu, P. Chen, X. Xing, P. Wang, and P. Liu, “Credal:
Towards locating a memory corruption vulnerability with your core
the 2016 ACM SIGSAC Conference
dump,” in Proceedings of
on Computer and Communications Security, ser. CCS ’16. New
York, NY, USA: ACM, 2016, pp. 529–540.
[Online]. Available:
http://doi.acm.org/10.1145/2976749.2978340

[6] A. Arora, R. Krishnan, R. Telang, and Y. Yang, “An empirical analysis
of software vendors’ patch release behavior: Impact of vulnerability
disclosure,” Information Systems Research, vol. 21, no. 1, pp. 115–132,
2010. [Online]. Available: https://doi.org/10.1287/isre.1080.0226

[7] M. Zalewski, “American fuzzy lop,” 2014.
[8] I. Yun, S. Lee, M. Xu, Y. Jang, and T. Kim, “QSYM: A Practical
Concolic Execution Engine Tailored for Hybrid Fuzzing,” in Proceedings
of the 27th USENIX Security Symposium (Security), Baltimore, MD,
Aug. 2018.

[9] P. Chen and H. Chen, “Angora: Efﬁcient fuzzing by principled search,”
IEEE, 2018,

in 2018 IEEE Symposium on Security and Privacy (SP).
pp. 711–725.

[10] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer, “Non-Control-
Data Attacks Are Realistic Threats.” in USENIX Security Symposium,
vol. 5, 2005.

[11] K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov, “Address-
sanitizer: A fast address sanity checker,” in Presented as part of the
2012 {USENIX} Annual Technical Conference ({USENIX}{ATC} 12),
2012, pp. 309–318.

[12] R. W. Jones and P. H. Kelly, “Backwards-compatible bounds checking
for arrays and pointers in c programs.” in AADEBUG. Citeseer, 1997,
pp. 13–26.

[13] L. Lam and T. Chiueh, “Checking array bound violation using seg-
mentation hardware,” in 2005 International Conference on Dependable
Systems and Networks (DSN’05), 2005, pp. 388–397.

[14] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino,
A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel, and G. Vigna,
“Sok: (state of) the art of war: Offensive techniques in binary analysis,”
in 2016 IEEE Symposium on Security and Privacy (SP), 2016, pp. 138–
157.

[15] A. Fioraldi, D. C. D’Elia, and L. Querzoni, “Fuzzing binaries for
memory safety errors with qasan,” in 2020 IEEE Secure Development
(SecDev).

IEEE, 2020, pp. 23–30.

[16] S. Dinesh, N. Burow, D. Xu, and M. Payer, “Retrowrite: Statically
instrumenting cots binaries for fuzzing and sanitization,” in 2020 IEEE
Symposium on Security and Privacy (SP).
IEEE, 2020, pp. 1497–1511.
[17] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, “A
comprehensive survey on graph neural networks,” IEEE Transactions
on Neural Networks and Learning Systems, 2020.

[18] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney,
S. Wallace, V. J. Reddi, and K. Hazelwood, “Pin: building customized
program analysis tools with dynamic instrumentation,” Acm sigplan
notices, vol. 40, no. 6, pp. 190–200, 2005.

[19] “Common vulnerabilities and exposures (cve),” https://cve.mitre.org.
[20] “Exploit database (edb),” https://www.exploit-db.com.
[21] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. van den Berg, I. Titov,
and M. Welling, “Modeling relational data with graph convolutional
networks,” 2017.

[22] “Declaring Attributes of Functions,” https://gcc.gnu.org/onlinedocs/

gcc-4.7.2/gcc/Function-Attributes.html, GNU.

[23] “Alignment,”

https://docs.microsoft.com/en-us/cpp/cpp/

alignment-cpp-declarations?view=vs-2019, Microsoft, 2019.

[24] D. Bruening and Q. Zhao, “Practical memory checking with dr. mem-
ory,” in International Symposium on Code Generation and Optimization
(CGO 2011).

IEEE, 2011, pp. 213–223.

[25] B. J. Reed Hastings, “Purify: Fast detection of memory leaks and access
errors,” in In proc. of the winter 1992 usenix conference. Citeseer, 1991.
http://software.intel.com/en-us/

[26] “Intel

Inspector,”

Parallel
intel-parallel-inspector/, Intel.

[27] A. R. Hurson and K. M. Kavi, “Dataﬂow computers: Their history
and future,” Wiley Encyclopedia of Computer Science and Engineering,
2007.

[28] K. Kennedy, A survey of data ﬂow analysis techniques.

IBM Thomas

J. Watson Research Division, 1979.

[29] J. Badlaney, R. Ghatol, and R. Jadhwani, “An introduction to data-ﬂow
testing,” North Carolina State University. Dept. of Computer Science,
Tech. Rep., 2006.

[30] E. C. R. Shin, D. Song, and R. Moazzezi, “Recognizing functions in
binaries with neural networks,” in 24th {USENIX} Security Symposium
({USENIX} Security 15), 2015, pp. 611–626.

[31] Z. L. Chua, S. Shen, P. Saxena, and Z. Liang, “Neural Nets Can Learn
Function Type Signatures from Binaries,” in 26th USENIX Security
Symposium (USENIX Security 17), 2017, pp. 99–116.

[32] W. Guo, D. Mu, X. Xing, M. Du, and D. Song, “{DEEPVSA}:
Facilitating Value-set Analysis with Deep Learning for Postmortem
Program Analysis,” in 28th USENIX Security Symposium (USENIX
Security 19), 2019, pp. 1787–1804.

[33] M. Du, F. Li, G. Zheng, and V. Srikumar, “DeepLog: Anomaly
Detection and Diagnosis from System Logs Through Deep Learning,”
in Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security,
ser. CCS ’17. New York, NY,
[Online]. Available: http:
USA: ACM, 2017, pp. 1285–1298.
//doi.acm.org/10.1145/3133956.3134015

[34] W. Meng, Y. Liu, Y. Zhu, S. Zhang, D. Pei, Y. Liu, Y. Chen, R. Zhang,
S. Tao, P. Sun, and R. Zhou, “Loganomaly: Unsupervised Detection
of Sequential and Quantitative Anomalies in Unstructured Logs,” in
Proceedings of the 28th International Joint Conference on Artiﬁcial
Intelligence, ser.
IJCAI’19. AAAI Press, 2019, pp. 4739–4745.
[Online]. Available: http://dl.acm.org/citation.cfm?id=3367471.3367702
[35] Y. Bengio, A. Courville, and P. Vincent, “Representation learning: A
review and new perspectives,” IEEE transactions on pattern analysis
and machine intelligence, vol. 35, no. 8, pp. 1798–1828, 2013.
[36] Z. Zhang, P. Cui, and W. Zhu, “Deep learning on graphs: A survey,”
IEEE Transactions on Knowledge and Data Engineering, 2020.
[37] M. Balcilar, G. Renton, P. H´eroux, B. Gauzere, S. Adam, and P. Honeine,
“Bridging the gap between spectral and spatial domains in graph neural
networks,” arXiv preprint arXiv:2003.11702, 2020.
[38] F. R. Chung and F. C. Graham, Spectral graph theory.

American

Mathematical Soc., 1997, no. 92.

[39] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, “How powerful are graph

neural networks?” arXiv preprint arXiv:1810.00826, 2018.

[40] J. Qiu, J. Tang, H. Ma, Y. Dong, K. Wang, and J. Tang, “Deepinf:
Social inﬂuence prediction with deep learning,” in Proceedings of the
24th ACM SIGKDD International Conference on Knowledge Discovery
& Data Mining, 2018, pp. 2110–2119.

[41] Q. Tan, N. Liu, and X. Hu, “Deep representation learning for social

network analysis,” Frontiers in Big Data, vol. 2, p. 2, 2019.

[42] H. Wang, F. Zhang, M. Zhang, J. Leskovec, M. Zhao, W. Li, and
Z. Wang, “Knowledge-aware graph neural networks with label smooth-
ness regularization for recommender systems,” in Proceedings of the
25th ACM SIGKDD International Conference on Knowledge Discovery
& Data Mining, 2019, pp. 968–977.

[43] A. Fout, J. Byrd, B. Shariat, and A. Ben-Hur, “Protein interface
prediction using graph convolutional networks,” in Advances in neural
information processing systems, 2017, pp. 6530–6539.

[44] A. Nair, A. Roy, and K. Meinke, “funcgnn: A graph neural network
approach to program similarity,” in Proceedings of the 14th ACM/IEEE
International Symposium on Empirical Software Engineering and Mea-
surement (ESEM), 2020, pp. 1–11.

[45] S. Rawat and L. Mounier, “Finding buffer overﬂow inducing loops in
binary executables,” in 2012 IEEE Sixth International Conference on
Software Security and Reliability.

IEEE, 2012, pp. 177–186.

[46] J. Newsome and D. Song, “Dynamic taint analysis for automatic
detection, analysis, and signaturegeneration of exploits on commodity
software.” in NDSS, vol. 5. Citeseer, 2005, pp. 3–4.

14

APPENDIX A
GRAPH CUT ALGORITHM

Algorithm 1 Graph Cut Algorithm
INPUT: graph G(N , E); number of layer l; number of sub-
graph n;
OUTPUT: a set with m subgraph: C = {Gi | 0 (cid:54) i < n}, and
the IDs of sampled nodes Si in each subgraph Gi;
1: initialize a set of n subgraph: C = {Gi | 0 (cid:54) i < n},

where Gi = (Ni, Ei), Ni = ∅, Ei = ∅;

2: divided nodes in G into m samples: Si | 0 (cid:54) i < n,

n-1
satisfying |Si| (cid:54) (cid:100)|N | /m(cid:101) and ∪
i=0

Si = N

3: for i = n down to 1 do
4: Ni := Si
5:
6:
7:

for e ∈ E do

for j = l down to 1 do

8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21: end for

end if
end for

end for
for e ∈ E do

add e to Ei;

end if
end for

/* src(e), des(e) denotes the source node and
destination node of e */
if src(e) ∈ Ni and des(e) /∈ Ni then

add dst(e) to Ni;

end if
if src(e) /∈ Ni and des(e) ∈ Ni then

add src(e) to Ni

if src(e) ∈ Ni or dst(e) ∈ Ni then

[47] J. Seward and N. Nethercote, “Using valgrind to detect undeﬁned value
errors with bit-precision.” in USENIX Annual Technical Conference,
General Track, 2005, pp. 17–30.

[48] N. Nethercote and J. Seward, “Valgrind: a framework for heavyweight
dynamic binary instrumentation,” ACM Sigplan notices, vol. 42, no. 6,
pp. 89–100, 2007.

[49] N. Stephens, J. Grosen, C. Salls, A. Dutcher, R. Wang, J. Corbetta,
Y. Shoshitaishvili, C. Kruegel, and G. Vigna, “Driller: Augmenting
fuzzing through selective symbolic execution.” in NDSS, vol. 16, no.
2016, 2016, pp. 1–16.

[50] Y. Seo, M. Defferrard, P. Vandergheynst, and X. Bresson, “Structured
sequence modeling with graph convolutional recurrent networks,” in
International Conference on Neural Information Processing. Springer,
2018, pp. 362–373.

[51] E. Hajiramezanali, A. Hasanzadeh, K. Narayanan, N. Dufﬁeld, M. Zhou,
and X. Qian, “Variational graph recurrent neural networks,” in Advances
in neural information processing systems, 2019, pp. 10 701–10 711.
[52] W. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation
learning on large graphs,” in Advances in neural information processing
systems, 2017, pp. 1024–1034.

[53] C. Zhang, D. Song, C. Huang, A. Swami, and N. V. Chawla, “Het-
erogeneous graph neural network,” in Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discovery & Data
Mining, 2019, pp. 793–803.

[54] M. Karasuyama and H. Mamitsuka, “Multiple graph label propagation
by sparse integration,” IEEE transactions on neural networks and
learning systems, vol. 24, no. 12, pp. 1999–2012, 2013.

[55] A. Iscen, G. Tolias, Y. Avrithis, and O. Chum, “Label propagation for
deep semi-supervised learning,” in Proceedings of the IEEE conference
on computer vision and pattern recognition, 2019, pp. 5070–5079.
[56] M. Rajpal, W. Blum, and R. Singh, “Not all bytes are equal: Neural
byte sieve for fuzzing,” arXiv preprint arXiv:1711.04596, 2017.
[57] D. She, K. Pei, D. Epstein, J. Yang, B. Ray, and S. Jana, “Neuzz: Efﬁ-
cient fuzzing with neural program smoothing,” in 2019 IEEE Symposium
on Security and Privacy (SP).

IEEE, 2019, pp. 803–817.

[58] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and
A.-R. Sadeghi, “Just-in-time code reuse: On the effectiveness of ﬁne-
grained address space layout randomization,” in 2013 IEEE Symposium
on Security and Privacy.

IEEE, 2013, pp. 574–588.

[59] U. Khedker, A. Sanyal, and B. Sathe, Data ﬂow analysis: theory and

practice. CRC Press, 2017.

[60] “Memory-augmented recurrent neural networks,” 2019.

[Online].

Available: https://github.com/suzgunmirac/marnns

[61] “”compiler-rt” runtime libraries,” LLVM project, 2020.

[Online].

Available: https://compiler-rt.llvm.org

[62] R. R. Heisch, “Method and system for reordering the instructions of a
computer program to optimize its execution,” Dec. 21 1999, uS Patent
6,006,033.

[63] M. Wang, D. Zheng, Z. Ye, Q. Gan, M. Li, X. Song, J. Zhou, C. Ma,
L. Yu, Y. Gai, T. Xiao, T. He, G. Karypis, J. Li, and Z. Zhang, “Deep
graph library: A graph-centric, highly-performant package for graph
neural networks,” arXiv preprint arXiv:1909.01315, 2019.

[64] D. Mu, “Linuxﬂaw,” 2019. [Online]. Available: https://github.com/

mudongliang/LinuxFlaw

[65] ““llvm-libc” c standard library,” LLVM project, 2020. [Online]. Avail-
able: https://llvm.org/docs/Proposals/LLVMLibC.html#current-status

15

