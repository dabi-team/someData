Optimizing city-scale trafﬁc through modeling
observations of vehicle movements

Fan Yang, Alina Vereshchaka, Bruno Lepri, Wen Dong, member, IEEE

1

1
2
0
2

l
u
J

6
1

]
I
S
.
s
c
[

2
v
3
9
0
5
0
.
6
0
9
1
:
v
i
X
r
a

Abstract—The capability of

trafﬁc-information systems to
sense the movement of millions of users and offer trip plans
through mobile phones has enabled a new way of optimizing city
trafﬁc dynamics, turning transportation big data into insights and
actions in a closed-loop and evaluating this approach in the real
world. Existing research has applied dynamic Bayesian networks
and deep neural networks to make trafﬁc predictions from
ﬂoating car data, utilized dynamic programming and simulation
approaches to identify how people normally travel with dynamic
trafﬁc assignment for policy research, and introduced Markov
decision processes and reinforcement learning to optimally con-
trol trafﬁc signals. However, none of these works utilized ﬂoating
car data to suggest departure times and route choices in order to
optimize city trafﬁc dynamics. In this paper, we present a study
showing that ﬂoating car data can lead to lower average trip
time, higher on-time arrival ratio, and higher Charypar-Nagel
score compared with how people normally travel. The study is
based on optimizing a partially observable discrete-time decision
process and is evaluated in one synthesized scenario, one partly
synthesized scenario, and three real-world scenarios. This study
points to the potential of a “living lab” approach where we learn,
predict, and optimize behaviors in the real world.

I. INTRODUCTION

With 80% of newly sold vehicles in the U.S. able to
communicate vehicle state through a telematics unit, and
57% of the population connected to the Internet by smart
phones, datasets that track vehicles are increasingly available
for transportation and policy researchers to study human
mobility at scale. Such datasets contain rich information —
from how drivers plan their daily activities and trips at the
microscopic level to how road networks respond to transporta-
tion demand at the macroscopic level [1], [2], [3]. Trafﬁc-
information providers such as Google Trafﬁc and INRIX can
play an essential role in city trafﬁc dynamics by suggesting
optimal trip plans according to the observed movements of
millions of vehicles. At the same time, artiﬁcial intelligence
is accelerating workplace transition and the way people travel
at a pace forecasting-based policy research might ultimately
be unable to keep up with. This trend demands a paradigm
that leverages trafﬁc big data to deliver agile, quantiﬁable, and

F. Yang was with the Department of Computer Science and En-
gineering, University at Buffalo, Buffalo, NY, 14260 USA e-mail:
(fyang24@buffalo.edu).

A. Vereshchaka was with the Department of Computer Science and
Engineering, University at Buffalo, Buffalo, NY, 14260 USA e-mail:
(avereshc@buffalo.edu).

B. Lepri is with the Mobile and Social Computing Laboratory, Bruno

Kessler Foundation, 38122 Trento, Italy (e-mail: lepri@fbk.eu).

W. Dong was with the Department of Computer Science and Engi-
neering, University at Buffalo, Buffalo, NY, 14260 USA e-mail: (wen-
dong@buffalo.edu).

Manuscript received Month date, year; Month date, year

scalable solutions to our real-world transportation problems.
Algorithms based on graphical models [4], [5] and neural
networks [6], [7], [8], [9], [10] have been developed to make
trafﬁc predictions from the movement of millions of vehicles,
but none of them utilizes these predictions to optimize complex
city trafﬁc dynamics. Similarly, optimization algorithms have
been developed to identify how people normally travel through
trafﬁc assignment [11], [12], [13], [14] in policy research and
to optimize trafﬁc-light schedules [15], [16], [17], [18], [19],
but none directly connects the observed vehicle trajectories
with suggested driver departure times and route choices in a
closed-loop control to optimize city trafﬁc.

In this paper, we present a simulation study showing that
by transforming the observed probe-vehicle movement data
into trafﬁc predictions and suggestions about optimal departure
times and route choices in closed-loop control, we can achieve
lower average trip time and higher on-time arrival ratio,
and thus a higher Charypar-Nagel score [14], compared with
how people normally travel. To achieve this, we model the
trafﬁc optimization problem as a partially observable Markov
decision process, where the observations are the numbers
of “probe” vehicles at road links and buildings, the future
expected reward to optimize is the Charypar-Nagel scoring
function [14], the control variables are related to departure
times and route choices, and the dynamics are modeled as a
queuing network approximated with a discrete-event model
with neural network components. The simulation study is
conducted using one synthesized scenario [14], one partly
real and partly synthesized scenario [20], and three real-world
scenarios [21], [22].

The uniqueness of this paper is that we combine machine
learning methods and big ﬂoating car data to prototype a
new trafﬁc optimization approach. The variational tracking and
optimal control algorithms that we developed [5], [23], [24] are
complex and less straightforward, so we speciﬁcally develop
a new particle ﬁlter algorithm to track and optimize trafﬁc
by extending our previous work [5], [25]. We also provide a
detailed evaluation of this approach to trafﬁc prediction and
control in synthesized, partly real and partly synthesized, and
real-world scenarios. Our approach not only simulates trafﬁc
jams during rush hours but also predicts from the trajectories
of probe vehicles whether today’s trafﬁc jams will be formed
earlier or last longer than usual, and helps drivers to decide
and plan how to use the road network more efﬁciently.

A use-case diagram in Fig. 1 shows a high-level view of
how the theory in this paper can be deployed in the real world
to track trafﬁc state and optimize trafﬁc dynamics. Floating
vehicle locations from drivers’ navigation apps are aggregated

 
 
 
 
 
 
2

installed at ﬁxed locations to capture speed, ﬂow, and density.
Algorithms include extended Kalman ﬁlter [26],
localized
extended Kalman ﬁlter [27], extended generalized Treiber-
Helbing ﬁlter [28], and particle ﬁlter [29]. More recently,
mobile phones and the Internet of Things have provided
a new way to log the trajectories of millions of vehicles.
These trajectories introduce an unprecedented opportunity to
estimate home and work locations [2], identify trip purposes
and special events [30], model driver behaviors [31], and track
road network dynamics [3], [9]. Algorithms to leverage these
trajectory data include probabilistic Bayesian networks [4],
deep neural networks [6], [7], convolutional neural networks
[8], [9], graph convolutional networks [32], [33], and recurrent
neural networks [10]. Trafﬁc prediction has been used for
model-calibration in policy research, controlling trafﬁc signals,
and informing drivers. However, to the best of our knowledge
the research in this paper is the ﬁrst to optimize trafﬁc by
suggesting optimal departure times and route choices. It is
also new to apply an agent-based [1] discrete-event model to
both predict trafﬁc and visualize how vehicles move in a city-
scale road network in accordance with where probe vehicles
move and how trafﬁc policies change vehicle behavior.

times at

Trafﬁc optimization is conducted for transportation forecast-
ing and trafﬁc control. Transportation forecasting is a four-
step process — trip generation, trip distribution, mode choice,
and trafﬁc assignment — that estimates the future usage
of speciﬁc transportation facilities in order to assist policy
impact [34].
research, such as assessing land-development
Trafﬁc optimization is conducted in the fourth steps through
either mathematical programming [11], [12] or simulation
[13], [35], [14], with the assumption that people select routes
the equilibrium. While
with the minimum travel
optimization is used to identify reasonable routes in trafﬁc
assignment, its usage in this paper is to optimize the overall
utilities of all people in a transportation network in response
trafﬁc prediction based on the observed probe-
to instant
vehicle locations. Our utility to optimize is the Charypar-
Nagel scoring function [14], which entails minimizing not
only travel time but also uncertainty in arrival time, as well as
the impact of trafﬁc ﬂuctuation on planned activity duration.
Various approaches have been applied to optimize trafﬁc-
signal control, including mixed-integer linear programming
[15], model predictive control [16], Q-learning [17], policy
gradient [18], and multi-agent reinforcement learning [19].
Numerous works have used Markov decision processes and
reinforcement learning to optimize other aspects of transporta-
tion, such as the accessibility of taxicabs [36], [37]. While
existing research optimizes transportation dynamics by setting
trafﬁc-light schedules, we optimize by advising drivers about
ideal departure times and route choices.

As city-scale ﬂoating car data is becoming available to the
academia [22], [38], we previously developed a variational so-
lution to the intractable problem in complex-network optimal
control [5], [23], [24]. The essence of the variational solution
is to both ﬁnd optimal trip plans in a tractable surrogate
optimization problem and establish a mathematical guarantee
that the performance of the solution in the original problem
is not worse. In comparison with our previous works, the

Fig. 1. A use-case diagram of trafﬁc monitoring and control with drivers’
navigation apps at high level.

into noisy observations about trafﬁc demands and state (yt
and at−1). These noisy observations are fed into the trafﬁc
prediction algorithm (Algorithm 1, Sec. IV-A) to calculate the
improved trafﬁc state estimation as bt ≈ ˆP (xt|y1:t) using Eq.
10, which in turn uses Eqs. 6, 7, 8, and 9. The improvement
comes from aggregating past observations y1:t, and using a
Bayesian formulation ˆP (xt|y1:t). The improved trafﬁc state
estimation is then fed into the trafﬁc control algorithm (Algo-
rithm 2, Sec. IV-B) to calculate the desired/target trafﬁc ﬂow
as at ∼ P (at|bt) using Eq. 17. The desired trafﬁc ﬂow control
is in the form of what proportions of trafﬁc should be directed
to downstream links/facilities and is used to suggest departure
times and route choices through drivers’ navigation apps. This
improves trafﬁc with better and real-time information bt about
trafﬁc state.

The remainder of this paper is organized as follows. Section
II discusses other research efforts on making predictions and
identifying optimal controls in the road transportation network
from noisy observations. Section III introduces the discrete-
event decision process to deﬁne the problem of optimizing city
trafﬁc dynamics. Section IV details a particle ﬁlter algorithm
that predicts and optimizes trafﬁc from noisy observations.
Section V evaluates the performance of a discrete-event deci-
sion process and particle ﬁlter against other model-based and
model-free methods on synthesized and real-world datasets. In
Section VI we discuss the implications and limitations of our
work and draw some conclusions.

II. RELATED WORKS

In this paper, we apply a discrete-event decision process
[5], [23], [24] to predict complex city trafﬁc dynamics from
the trajectories of probe vehicles and accordingly optimize
that trafﬁc through departure times and route choices. Related
research in intelligent transportation systems falls into two
research streams: trafﬁc prediction and trafﬁc optimization.

Traditionally, trafﬁc prediction was based on trafﬁc cam-
eras, inductive-loop trafﬁc detectors, and similar technologies

focus in this paper is developing conceptually straightforward
algorithms and providing comprehensive evaluation in the
transportation domain.

III. PROBLEM STATEMENT

In this Section, we introduce a discrete-event decision
process (Eq. 2, Sec. III-A) to deﬁne the trafﬁc optimization
problem. In doing so, we specify the utility to optimize, the
states, the events, the observations, and the control variables
(Sec. III-B).

Overall, our purpose is to optimally control transportation
dynamics in order to a) minimize the total travel time, b)
minimize the delay for cars to arrive at their destinations due
to trafﬁc ﬂuctuations, and c) minimize the effect of commuting
on trafﬁc congestion so that people can perform activities at
destinations for an ideal amount of time without incurring
signiﬁcant travel-time increases. Optimal control is achieved
by advising individual drivers about downstream links in
route planning and the time to leave a given location. The
resulting effect is stochastic. The performance indicators of
a transportation network are calculated and estimated by the
states of all
the vehicles and probe vehicles, respectively,
where the probe vehicles account for only a small fraction of
the vehicle population. Optimal control is also computed from
the observed probe-vehicle populations at different locations.
This kind of control is applicable where a trafﬁc-information
provider (such as Google Maps or a trafﬁc authority) provides
trip plans according to the locations reported by a small
number of drivers. We assume discrete-event dynamics, where
the system state consists of numbers of vehicles at road links
and buildings and is driven by elementary events in the form
of an individual vehicle moving from one location to the next.

A. Discrete-Event Model for Inference and Decision Making

Here, we introduce a discrete-event model called the
stochastic kinetic model [39], [40], which captures the dy-
namics of a complex social system driven by a set of events.
A discrete-event model is a versatile model for describing
a wide range of dynamics in various ﬁelds. It has many
other names, including stochastic kinetic model [39], [40],
stochastic Petri net [41], system dynamics model [42], multi-
agent model speciﬁed through a ﬂow chart or a state chart [43],
Markov jump process [44], [45], continuous time Bayesian
network [46], and production rule system [47]. The premise
of introducing a discrete-event simulation model [48], [40],
[43] to specify road network dynamics is that complex system
dynamics can be described by a set of microscopic events
that individually bring only minimal changes but in sequence
induce complex behaviors. Using a discrete-event model, we
specify trafﬁc dynamics in a road network with a set of
stochastic events — a driver starting a trip, moving to the next
road, and ending a trip, for example — and we introduce a
set of control variables to inﬂuence driver choices in response
to the environment.

3

(a) Discrete event process

(b) Discrete event decision process

Fig. 2. Graphical model representations of (2a) a discrete event process
and a (2b) a discrete event decision process. A discrete event model captures
complex system dynamics and speciﬁes a decision-making problem compactly
with a set of events.

Let X(1), · · · , X(M ) denote the individuals belonging to the
M species in the system. A discrete-event process is generated
by a set of events in the form of a production

α(1)
v

X(1) +...+α(M )

v

X(M ) cv→ β(1)

v

X(1) +...+β(M )

v

X(M ).

(1)

t

v

v − α(1)

, . . . , x(M )

v , · · · , β(M )

). Let xt = (x(1)

This production is interpreted as having event rate coefﬁcient
cv (the probability per unit time as time goes to 0). α(1)
v
individuals of species 1, ..., M interact according to event v,
resulting in their removal from the system, and β(1)
individuals
of species 1, ..., M are introduced into the system. Thus, event
v changes the populations by ∆v = (β(1)
v −
α(M )
) be the populations of the
v
t
species in the system at time t. A stochastic kinetic process
initially in state x0 at time t = 0 can be simulated through the
Gillespie algorithm [39] by iteratively (1) sampling the time
τ to the next event according to exponential distribution τ ∼
Exponential(h0(xt, c)), where h0(x, c) = (cid:80)V
v=1 hv(xt, cv) is
the rate of all events and hv(xt, cv) is the rate of event v,
(2) simulating event v according to categorical distribution
v ∼ ( h1
) conditional on event time τ , and (3) updat-
h0
ing the system time t ← t + τ and populations x ← x + ∆v
until the termination condition is satisﬁed. In this algorithm,
event rate hv(xt, cv) is the rate constant cv multiplying a
total of (cid:81)M
different ways for individuals to
interact in the system, assuming homogeneous populations.
Exponential distribution is the maximum entropy distribution
given the rate constant, and consequently it is most likely to
occur in natural reactions [39].

m=1(x(m)

, . . . , hV
h0

)α(m)

t

v

A partially observable discrete-event decision process
(PODEDP) is a partially observable Markov decision process
[49] where the dynamics are deﬁned by a discrete-event
model. Let vt be the event happening at
time t. Let xt
be the state (populations of species or states of individu-
als), and yt the observation about the state at time t. Let
bt = p(xt|yt,t−1,···, at,t−1) = bt(bt−1, yt, at−1) be the belief
state — the probability distribution of the current system
state estimated through observation-action history. Let at be
the control (or action) variables inﬂuencing the event-rate
constants at time t, c(at) = (c1(at), · · · , cV (at)) where the

t-1tHMM 1HMM 2HMM 3Time..................t+1t-1tHMM 1HMM 2Time............t+1action or its distribution is determined by the belief state
at = π(bt; θ) or π = p(at|bt). Further let p(yt|xt) be the
observation model, p(vt+1, xt+1|xt, at) the state transition
model, and R(xt, at) the immediate reward at time t. The
PODEDP problem (Eq. 2) is to maximize the expected future
reward of the discrete-time process deﬁned by the probability
measure p(a0:t, v1:t, x0:t, y1:t) (Eq. 3) by iteratively setting at
from a belief state bt that summarizes the observation-control
history (y1:t−1, a0:t−1), where the indicator function δ(xt+1 ≡
xt + ∆vt+1) is 1 if the current state is xt+1 = xt + ∆vt+1
and 0 otherwise, and 0 < γ < 1 is a discount factor. The
graphical model representations of a discrete-event process and
a discrete-event decision process are given in Fig. 2.
(cid:33)

arg maxa0:∞

Ex0:∞,a0:∞,v0:∞,y0:∞

where
p (a0:T , v1:T , x0:T , y1:T )

γtR(xt, at)

,

(2)

(3)

(cid:32) ∞
(cid:88)

t=0

=p(x0) (cid:81)T −1

t=0 p(at|bt)p(vt+1|xt,at)δ(xt+1≡xt+∆vt+1 )p(yt+1|xt+1),
k τ · hk(xt, at),

(cid:40)

p(vt+1|xt, at; θ) =

1 − (cid:80)
τ · hk(xt, at),

vt+1 = ∅
vt+1 = k

,

hv(x,ck)=cvgv(x) for v=1,··· ,V, and h0(x,c)=

V
(cid:80)
v=1

hv(x,cv).

(4)

(5)

A Markov decision process (MDP) is a framework for mod-
eling decision making in situations where outcomes are partly
random and partly under the control of a decision-maker.
It is used in many ﬁelds, including robotics, manufacturing,
optimal control, game theory, and economics. In recent years,
it has seen increasing applications in intelligent transportation
systems, including trafﬁc-signal control, autonomous driving,
and trafﬁc assignment.

B. Modeling Trafﬁc Dynamics with a Discrete-Event Model

t

In this subsection we deﬁne the trafﬁc optimization problem
in the framework of PODEDP (Eq. 2), specifying the utility,
states, events, observations, and control variables. We consider
the movement of thousands of vehicles in a city-scale trans-
portation network with M locations and V events, for which
the typical length of a control episode is one day discretized
into 1440 steps of one minute each.

, · · · , x(M )

The state xt = (x(1)

, · · · , y(M )

, t) is the number of vehicles
t
at the M locations (road links and buildings) and the current
time t. The observation yt = (y(1)
, t) is the number
t
of probe vehicles at the M locations and current time t,
where the probe vehicles are randomly selected and constitute
10% of the total vehicle population. The action variables at
are the probability of choosing a downstream road link after
completing the current road link, and the event rate coefﬁcient
of leaving or entering buildings. These action variables change
the event rate coefﬁcients to make road usage more efﬁcient.
The reward function R(xt) = (cid:80)
t,travx(m)
emulates the Charypar-Nagel scoring function [14] to reward
locations and penalize
performing the correct activities at
traveling on roads, where β(m)
t,perf are the score
coefﬁcients.

t,trav and β(m)

t + β(m)

t,perfx(m)

m β(m)

t

t

4

Let xttl be the total number of vehicles in the system and
yttl the total number of observed vehicles. The observation
model of observing y(mj )
location j
|x(mj )
conditioned on x(mj )
) =
t
t
(mj )
(mj )
· C yttl−y
C y
t
t
(mj )
(mj )
xttl−x
x
t
t
a-choose-b.

“probe" vehicles at
t
vehicles in total is p(y(mj )
xttl , where C b

a = a!/(b! · (a − b)!) is

/C yttl

t

We implement the state transition model p(vt, xt+1 | xt, at)
using discrete-event dynamics, where there is a single type of
cm1m2→ p·m2. A vehicle p moving from one location
event p·m1
m1 to the next m2 with event rate coefﬁcient cm1m2 changes
the number of vehicles at the two locations to x(m1)
− 1 and
x(m2)
+ 1 respectively. The event rate coefﬁcients cm1m2 (the
t
probability of event per unit time as time goes to 0) of ﬁnishing
the current road link is a function of the numbers of vehicles
per lane per unit length, the maximum ﬂow per lane, the speed
limit, the length of the road link, and the road type (freeway,
arterial road, or local road), implemented with a deep neural
network and trained to best match the queue-network MATSim
trafﬁc dynamics [14]. In this way, we capture a variety of
trafﬁc behaviors involving trafﬁc lights and trafﬁc ﬂow through
a model-free approach.

t

Travel time modeled on a road link using an exponen-
tial random variable with matching average travel time is
approximate. Nevertheless, such a model strikes a balance
between capturing high-ﬁdelity dynamics and being amiable to
gradient-based machine learning algorithms. Because trafﬁc-
state estimation is driven by noisy observations, the inferred
trafﬁc state will be constrained by what
the observations
prescribe and thus will not stray far from the ground truth.
This is different from pure simulation, where an approximate
model can drive the system state to an unrealizable position.
The optimal control from partial observations in this paper is a
closed-loop control, such that any undesirable effect caused by
model inaccuracy and randomness in the dynamics is corrected
in the next time step. This approach is different from open-
loop controls in classic transportation simulators for policy
research.

IV. TRACKING AND OPTIMAL CONTROL

In this section, we describe a particle ﬁlter algorithm that
tracks trafﬁc state (Alg. 1, Sec. IV-A) and implements optimal
control from partial observations (Alg. 2, Sec. IV-B).

A. Tracking with Particle Filter

In this subsection, we derive a particle ﬁlter algorithm to
track vehicles counts (belief state) at different road links and
buildings using the observed probe-vehicle counts at those
locations in order to establish optimal control of transportation
network dynamics. The usage of particle ﬁltering permits
to deal with noisy observations because it aggregates all
information included in the past observations as a probability
distribution of the current trafﬁc state — numbers of vehicles
on the links and locations. We also derive particle smoothing
to back trace the evolution of particles.

Let yt be a noisy observation of system state xt at time
t, and at be the control. A particle ﬁlter (sequential Monte

t and particle indices ik

Carlo method) approximates the posterior probability distribu-
tion of a stochastic process through maintaining a collection
of particles xk
t ∈ {1, · · · , K} to
represent the likely system state xt, where k = 1, · · · , K
and t = 1, · · · , T . Inference with the particle ﬁlter involves
tracking the evolution of a stochastic process by alternating
between particle prediction and updating. In the prediction
step, the particles at the next time step t are sampled ac-
ik
cording to the transition kernel xk
t−1
t−1 ). In
t ∼ p(xt
the updating step,
the particle indices are resampled ac-
cording to the observation likelihood ik
t , yt ∼
t
Categorical (cid:0)p(yt | x1
t )(cid:1). With the resulting par-
ticles and particle indices, we use the empirical probability
1
(xt) to approximate p(xt|y1, . . . , yt−1) and use
k δxk
K
1
k δ
(xt) to approximate p(xt|y1, . . . , yt), where δ is
ik
K
t
t
an indicator function.

t ), ..., p(yt | xK

t , . . . , xK

(cid:80)
(cid:80)

| x1

| x

x

t

t

0 = 1, · · · , iK

0 = x0 and i1

t , at), · · · , xK
t , · · · , xiK

To track a discrete event process initially at state x0 at
time t0 = 0, we initialize particle positions and indices as
0, · · · , xK
x1
0 = K, and alternate
between the following prediction step and updating step.
In the prediction step, we sample particle positions x1
t+1 ∼ p(xt+1|xiK

t+1 ∼
p(xt+1|xi1
, at) at time t+1 from
the particles xi1
at time t. Speciﬁcally, we sample
event vk
t+1 according to how likely it is that different events
will occur conditioned on system state xik
for k = 1, · · · , K
t
t
t+1 = xk
and action at (Eq. 6), and update xk
t + ∆vk
accord-
ingly (Eq. 7). Because the resampled particles are distributed
according to xik
t ∼ p(xt|y1:t, a1:t−1), the sampled particles
are distributed according to xk

t
t

t
t

t+1

t

t

The likelihood of particles xk

t+1) with
respect to the observation yt+1. To avoid particle degeneracy,
we perform a updating step to eliminate particles with low
likelihood and duplicate particles with high likelihood (Eq.8).
After the particle-updating step, all particles are distributed
according to p(xt+1|y1:t+1, a1:t), and all have the same like-
lihood.

t+1 ∼ p(xt+1|y1:t, a1:t).
t+1 are p(yt+1|xk

ik
t
t ,at)
γ

xk

h0 (x

h1(x

ik
t ∼Cat(1−
t

vk
t+1|at,x
ik
t
t +∆vk
t+1, yt+1 ∼ Cat(p(yt+1|x1

t+1=x
t+1|x1:K
ik

t+1

,

,

ik
t
t ,at)
γ

ik
t
t ,at)
hV (x
γ

),

,··· ,

t+1),· · ·, p(yt+1|xK

t+1)).

(6)

(7)

(8)

To derive a particle trajectory from the posterior distribution
of a stochastic kinetic process with respect to observations,
we trace back the events that lead to the particles xik
T for
k = 1, · · · , N :

T

1

1

x0, a0, vjk
where jk

1 , xjk
T = ik

1 , a1, · · · , vjk
T −1 = ijk

T , xjk
T −1, jk

T , jk

T

T

T

T , aT ,

T −2 = i

jk
T −2 , · · · , jk
T −1

(9)
1 = ijk
1 .

2

5

ALGORITHM 1: Particle ﬁltering, smoothing, and
parameter learning for discrete event decision process
Input: Observations y1, · · · , yT and control inputs
a1, · · · , aT of a discrete event decision process (Eq.
3).
Output: Belief state bt ≈ ˆp(xt|y1:t) (Eq. 10) where
particles (vik
t=1:T are sampled from particle
ﬁlter, and particle trajectories (vjk
t , xjk
t=1:T are
sampled from particle smoother.

t )k=1:K

t )k=1:K

t , xik

t

t

t

t

Procedure:

• Initialize x1
• (Filtering) For t = 1, · · · , T and k = 1, · · · , K, sample

0 = 1, · · · , iK

0 = · · · = xN

0 = x0, i1

0 = K.

t and ik
vk

t according to Eq. 6, 7 and 8.
• (Smoothing) Back-track particle trajectory from xik

T
T

according to Eq. 9, for k = 1, · · · , K.

Calibration: Maximize log likelihood log ˆp(y1:T ) (Eq.
11) with gradient ascent.

stochastic process conditioned on observations, where δ is an
indicator function:

ˆp(xt|y1:t) =

1
K

ˆp(y1:T ) =

(cid:89)

t

δ(xik

t

t ≡ xt) K→∞−→ p(xt|y1:t),

(10)

(cid:88)

k

ˆp(yt|y1:t−1) =(cid:81)

t

1
K

(cid:80)
k

p(yt|xk

t )K→∞−→ p(y1:T ), (11)

ˆp(x1:T |y1:T ) = 1

K

(cid:80)
k

δ((x

jk
1:T )≡(x1:T ))K→∞−→ p(x1:T |y1:T ).
1:T

(12)

Overall, we develop a particle-based algorithm to update
the belief state and calibrate the parameters of a discrete event
decision process (Algorithm 1).

B. Optimal Control with Particle Filter

In this subsection, we derive a particle-based algorithm to
identify the optimal control of a complex system from our
estimation of the current system state (belief state), using
the equivalence between the state-value function of a Markov
decision process and the probability of receiving the reward
from a mixture of ﬁnite-time Markov decision processes
[50]. This equivalence enables the translation of the policy-
evaluation and policy-improvement steps in a policy iteration
algorithm into the expectation and maximization steps in an
expectation maximization (EM) algorithm, and the application
of a large variety of approximate inference algorithms for dy-
namic Bayesian networks to solve intractable optimal control
problems. In particular, it is based on the following derivation:

E

∞
(cid:88)

t=0

γtR(at, xt) =

∝

∞
(cid:88)

t=0
∞
(cid:88)

γtE (R(at, xt))

(13)

p(T )

T
(cid:88)

t=0

p(t)E(p(R = 1|at, xt)),

T =0

The particles xi1

t

t , · · · , xiK

form an approximation of the
forward probability p(xt|y1,··· ,t) and likelihood p(y1,··· ,T ).
The ancestral lines of the particles xik
T , where k = 1, · · · , K,
form an approximation of the posterior distribution of the

t
t

T

∞
(cid:88)

where γt ∝

T =0

p(T )p(t)δt≤T , p(R = 1|at, xt) ∝ R(at, xt).

Eq. 13 connects the expected future reward of a Markov
decision process and the probability of receiving a binary

time t,

reward in a mixture of ﬁnite time Markov decision processes
(T, t, ξt, R). This ﬁnite time Markov decision process executes
the same plan as the original Markov decision process up
to a terminal
it generates a state-action trajectory
ξt = x0, a0, · · · , xt, at, and it receives a binary reward with
probability p(R = 1|xt, at) ∝ R(xt, at). In Eq. 13, γt is
a discount factor. Corresponding to the expected discounted
cumulative future reward with γt = γt, we select p(T ) =
(1 − δ)δt and p(t) = (1 − γ
δ )t. Corresponding to the
expected ﬁnite-horizon future reward with γt = δ(t ≤ H),
we select p(T ) = δ(H ≡ T ) and p(t) = 1/(H + 1), where
indicator function δ(T ≡ H) = 1 when T = H and 0
otherwise, and δ(t ≤ H) = 1 when t ≤ H and 0 otherwise.

δ )( γ

To identify optimal control with the EM algorithm in a
discrete event decision process, we maximize the expected
log likelihood ET,t,ξt log p(T, t, ξt, R = 1; θ) by alternately
identifying the typical state-action sequences generated by
a policy that leads to reward (p(T, t, ξt|R = 1; θ)) in the
expectation step (E-step) and tuning the control parameters of
the policy (θ) so that these typical sequences lead to reward
with higher probabilities in the maximization step (M-step).
The EM algorithm is an iterative algorithm that searches for
the parameters to maximize the expected log likelihood over
the posterior probability distribution of the latent variables
conditional on the observations. Here, the likelihood is propor-
tional to the value function, the latent variables are a sequence
of states and actions, and the observations are of whether a
reward is received.

In E-step, we use importance sampling to approximate
the proxy of future expected reward p(R = 1) and the
posterior probability p(xτ , aτ
| R = 1, τ ≤ t) induced
in Eq. 13. Speciﬁcally, we sample T k ∼ p(T ) and ξk ∼
p(ξT |T k) for k = 1, · · · , K, we approximate the prior
distribution p(T, ξT ) with sample distribution ˆp(T, ξT ) =
1
k=1 δ(T k, ξk) ≡ (T, ξT )), and use importance weight
K
(cid:80)T
t ) to approximate the posterior dis-

(cid:80)K
t=0 p(t)p(R = 1|xk

t , ak

tribution, where δ is an indicator function.

(14)

(15)

(16)

T k, ak

0:T k , xk

1:T k ∼

0:T k , vk
T k
(cid:89)

P (T k)b(x0)

p(at|xt; θ)p(vt|at, xt)δ(xt+1 ≡ xt + ∆vt+1)

t=0

E

∞
(cid:80)
t=0

γtR(at,xt)∝p(R=1)≈ 1
K

(cid:80)
k,t

p(t)p(R=1|xk

t ,ak
t )

ˆp(xτ = x, aτ = a|R = 1, τ ≤ t)
k=1 δ(x ≡ xk
τ )δ(a ≡ ak
(cid:80)T
(cid:80)K

(cid:80)K

=

k=1

τ ) (cid:80)T
t=τ p(t)p(R = 1|xk

t=τ p(t)p(R = 1|xk
t , ak
t )

t , ak
t )

.

The posterior probability (Eq. 16) is the fraction of expected
future discounted reward received from xk
τ = a over
the total expected future discounted reward received after τ ,
averaged over sample paths {(T k, ξk) : k}.

τ = x, ak

In M-step, we iteratively maximize the expected log like-
lihood of receiving a reward. The optimal control θ is con-
sequently set such that actions a appears in proportion to the
future rewards.

Eθold log p(ξT , T, R = 1; θ) = · · · + Eπold log p(at, xt|R = 1; θ),

6

⇒ p(a|x; θ) =

(cid:80)
k,τ

δ(xτ ≡x)δ(aτ ≡a)

T k
(cid:80)
t=τ

p(t)p(R=1|xk

t ,ak
t )

δ(xτ ≡x)·

T k
(cid:80)
t=τ

(cid:80)
k,τ

p(t)p(R=1|xk

t ,ak
t )

.

(17)

To summarize, we develop an algorithm 2 to control a
complex system from a discrete event model and noisy ob-
servations.

ALGORITHM 2: Optimal control from belief state
with Particle Filter
Input: Belief state (Eq. 10) of discrete event process
(Eq. 3) at time 0 as particles, {xk
0 : k = 1:K}. Initial
policy θ at time 0.
Output: Optimal action at according to Eq. 17.
Calibration: Improve policy θ through policy iteration.

• E step. For k = 1:K: sample T k, ξk according to Eq. 14
• M step. Upate θ according to Eq. 17.

V. TRACKING AND PLANNING IN CITY-SCALE
TRANSPORTATION NETWORKS

In this section, we benchmark our framework with other
state-of-the-art algorithms on tracking and optimizing the
travel plans in a city-scale transportation network from noisy
observations of network dynamics.

A. Data Description

We evaluate the performance of our framework on ﬁve
datasets of human mobility: (1) SynthTown, (2) Berlin, (3)
Santiago de Chile, (4) Dakar, and (5) NYC Taxicab. We use
as varied data as possible to demonstrate that our proposed
framework is useful in more than a narrow range of cases
and is fair. The different cases indeed show different levels
of uncertainty in trafﬁc state estimation, different travel times,
and different on-time arrival rates. Nevertheless, the proposed
trafﬁc tracking and control algorithms outperforms the state
of the art.

The SynthTown dataset is comprised of a synthesized net-
work of one home location, one work location, and 23 single-
direction road links (Fig. 3) to characterize the trips of 2000
synthesized inhabitants going to work in the morning and
returning home in the afternoon [14]. The prediction problem
is to estimate the vehicle counts at home, at work, and at links
1-23 in the present time, 10 minutes later, and 60 minutes later
from observations of the 200 “probe” inhabitants collected
at link 1 and link 20. The control problem is to maximize
a proxy of the Charypar-Nagel scoring function [14] from
setting control variables according to these observations. We
use this dataset to show the details of tracking and control
results.

The Berlin dataset is comprised of a network of 11 thousand
nodes and 24 thousand single-direction car-only links derived
from OpenStreetMap; and the trips of 9 thousand synthesized
vehicles representing the travel behaviors of three million
inhabitants [20]. To make the problem small enough that
algorithms with bigger time-complexity can run and have
performances compared with our algorithm, we aggregate the

7

The NYC TaxiCab dataset1 is comprised of a network of
7 thousand nodes and 11 thousand single-direction road links
derived from OpenStreetMap and an average of 1 million daily
trips of taxicabs and for-hire vehicles (including Uber, Lyft,
Via and Juno) throughout 2018. Each trip record contains pick-
up and drop-off zones among the 236 zones in New York
City, and pick-up and drop-off data and time, among other
information. The trip records are made publicly accessible
by the New York City Taxi and Limousine Commission (an
agency responsible for licensing and regulating New York
City’s taxi cabs, for-hire vehicles, commuter vans, and para-
transit vehicles). Together with many other open data sets
through the City’s Open Data portal2, TLC’s trip data has
a big impact in making the city street smart. Here, we use
the data to predict the behavior of all taxicabs and for-hire
vehicles from observing a small fraction of them.

B. Tracking Transportation Dynamics

Benchmark algorithms: We ﬁrstly benchmark our frame-
work — stochastic kinetic model with particle ﬁlter (PFSKM)
— against a Deep Neural Network (DNN) [6], [7], a Recur-
rent Neural Network (RNN) [10], and an extended Kalman
ﬁlter (EKF) [26], [27] in the task of continuously tracking
the current and future trafﬁc conditions. DNN represents
the power of a general-purpose non-parametric model. We
build a ﬁve layer Deep Neural Network (DNN): (i) an input
layer accepting the observation history of probe vehicles at
selected locations, (ii) three hidden layers, and (iii) one output
layer generating the inferred distribution of all vehicles at all
locations. RNN exploits the temporal structure that recursively
takes the inferred result from the previous cell as well as the
current observations as input, and output the estimated vehicle
distribution. Both DNN and RNN are trained with 30 days
of synthesized mobility data from MATSim until obtaining
optimum performance. The EKF, instead, assumes a Gaussian
distribution between the time-indexed latent states, and we
implement a standard EKF procedure that alternates between
predicting and updating steps. We trained the DNN and RNN
models with stochastic gradient descent, and trained the EKF
model with expectation maximization.

Evaluation metric: We use two metrics to evaluate the
performance of our model: coefﬁcient of determination (R2)
and mean squared error (MSE). We use R2 to evaluate the
goodness of ﬁt between a time series of the estimated vehicle
counts at a location and the ground truth. Let ft be the
estimated vehicle count at time t, yt the ground truth and ¯y the
average of yt. We deﬁne R2 = 1−(cid:80)
t(yt− ¯yt)2.
A higher R2 indicates a better ﬁt between the estimated time
series and the ground truth, with R2 = 1 indicating a perfect
ﬁt and R2 < 0 a ﬁt worse than using the average. We
use MSE to measure the average squared error difference
between the estimated vehicle counts at all locations at a
time t and the ground truth. A lower MSE represents a
more precise prediction. Let f (i) be the estimated vehicle

t(ft−yt)2/ (cid:80)

1http://nyc.gov/tlcopendata
2https://opendata.cityofnewyork.us/

Fig. 3.
Work, and 23 road links labeled from 1 to 23.

SynthTown road network, which contains 2 facilities, Home and

24 thousand road links into 1539 clusters with a walk-trap
algorithm [51]. The synthesized daily trips have been validated
based on extensive, regularly-conducted travel surveys and
constitute a quality representation of road transport demand.
This data set is the result of a generalizable approach to syn-
thesize individual-level behaviorally-sound trip diaries from
easily accessible input data, since collecting the trip diaries of
real-world people is plagued with privacy issues.

The Santiago de Chile dataset is comprised of a network
of 23 thousand nodes and 38 thousand single-direction car-
only links derived from OpenStreetMap; and the trips of 665
thousand synthesized vehicles representing the travel behaviors
of six million inhabitants in car, walking and public trans-
portation modals [21]. The daily trips in the Santiago de Chile
dataset were initialized from cloning the sequences of activities
(starting time and duration of home, work, school, shopping,
leisure, visit and health) and travel mode of 60 thousand
individuals (from 18 thousand households) from publicly-
accessible travel diaries, and modiﬁed through physical sim-
ulation and a co-evolutionary algorithm (with MATSim) to
maximize the overall utility of the system. The resulting daily
trips are compatible with travel modals’ distributions and ob-
served trafﬁc counts at count stations. This data set represents
the case where we can get travel diaries with ﬁne temporal and
spatial resolution for a signiﬁcant and representative fraction
of a population from publicly-accessible travel diaries.

The Dakar dataset is comprised of a network of 8 thousand
single-direction road links derived from OpenStreetMap and
12 thousand real-world vehicle trips derived from the “Data
for Development (D4D)” data sets based on the Call Detail
Records (CDR) of over 9 million Sonatel customers in Senegal
(out of 15 million total population) through year 2013 [22].
From data set 2, we identify the home and work/school
locations of each user as randomly picked locations from
the most appeared sites during 7am - 7pm and 7pm - 7am
respectively. Then, we sample an activity-trip sequence for
each user to match her/his sequence of mobility records (in
data set 2) from a Markov chain model describing how s/he
performed various activities (home, work, school, shopping,
etc). This data set represents the case where we can get
travel diaries with ﬁne temporal and spatial resolution for a
signiﬁcant and representative fraction of a population through
mobile phones.

8

requires a huge training dataset. PFSKM estimation agrees
with GT, and is closer than DNN and RNN estimations.
This is because PFSKM explicitly leverages problem-speciﬁc
structures such as road topology, while DNN and RNN must
learn them implicitly and gradually. PFSKM is more accurate
than EKF estimation because PFSKM can work with arbitrary
probability distributions while EKF assumes Gaussianity. EKF
and DNN agree well with GT at busy locations (home and
work) but
locations with few people, which
demonstrates that PFSKM better adopts dynamic changes.

less well at

C. Optimal Control in Transportation Dynamics

Benchmark algorithms: In the previous section we have
demonstrated the tracking capability of our framework with
particle ﬁlter. Now, we evaluate our framework for optimizing
trafﬁc against (i) a within-day re-planning baseline algorithm
[52], (ii) a co-evolutionary algorithm implementing open-
loop control [14], and (iii) an advantage actor-critic algorithm
[53] implementing closed-loop control. The baseline algo-
rithm (Baseline) optimizes agents’ expected future rewards
by considering the current trafﬁc situation but not the plans
of other agents. The co-evolutionary algorithm (CoEA) is
the state-of-the-art algorithm for generating the equilibrium
of daily activities and trips in transportation theory [14]. In
CoEA, agents independently explore and exploit their plans
through a genetic operator, then jointly execute and evaluate
this process
their plans in a simulator, and ﬁnally repeat
until an equilibrium is reached [54]. The advantage actor-
critic algorithm (A2C) uses a “critic” to estimate the trafﬁc
situation in terms of an action-value function and an “actor”
which suggests optimal departure times and route choices in
the direction suggested by the critic. We further use advantage
to lower the variance.

the different

Evaluation metric: We use three metrics to evaluate the
different planning algorithms. The ﬁrst is average trip time
in minutes of all vehicles driving from home to work: a
lower average trip time means better trafﬁc. The second is on-
time arrival ratio, which measures the percentage of people
arriving to work on time. Finally, we use expected reward per
vehicle per hour, where higher expected rewards mean better
individual plans and a more efﬁcient transportation network.
Comparing detailed behaviors on SynthTown data: Fig-
locations
ure 7 shows the vehicle counts at
of SynthTown throughout the day after executing different
planning algorithms from the observations of probe vehicles
(10% of the total) at links 1 and 20 only. The x-axis indicates
the hours of the day, the y-axis shows the numbers of vehicles
at different locations (home, work, and road segments marked
on the left), and the baseline (Baseline) serves as the frame
of reference. Note that vehicles applying the policy from our
framework best satisfy the requirements of all individuals.
Indeed, at 9am our framework has the highest number of
people arriving at work on time, followed by within-day re-
planning Baseline, A2C, and CoEAs. Similarly, at 5pm our
framework has the highest number of people arriving back at
home, while under the other three policies most are either still
at work or slowed by congestion on roads. Finally, analyzing

(a) Ground truth

(b) Particle ﬁlter

Fig. 4. Comparing estimated and ground truth trafﬁc densities through two
snapshots taken at the same time (black dots: vehicles in the ground truth;
red dots: vehicles from a particle trajectory; green dots: probe vehicles).

count at
MSE = 1
n

location i and y(i)
(cid:80)n
i=1(y(i) − f (i))2.

the ground truth. We deﬁne

Results’ visualization: One beneﬁt of using a discrete-event
model with particle ﬁlter is that we can qualitatively visualize
how vehicles move in a city-scale road network in accordance
with “probe” vehicle locations, and how trafﬁc policies change
vehicle behavior. Fig. 4 compares the distributions of vehicles
in the ground truth and in a particle trajectory (Eq. 9) using
as an example the Dakar data set through two snapshots taken
at the same time. It can be observed from the ﬁgures that
the vehicle density in ground truth and estimation agree with
each other, and both are proportional to the density of “probe”
vehicles.

Evaluation results: Figure 5 summarizes the MSE and R2
performance statistics of the four models for a vehicle-tracking
task — estimating the numbers of vehicles up to now, with
short-term (10 minutes) and long-term prediction (1 hour) on
all the datasets. The Dakar dataset is simply too large for DNN,
RNN, and EKF, which demonstrates the superior scalability of
PFSKM. PFSKM has the lowest MSE across different times of
day, followed in order by DNN, EKF, and RNN (top row, lower
is better). PFSKM also has the highest R2 across different
locations, followed by DNN, EKF, and RNN (bottom row,
higher is better). PFSKM outperforms RNN and DNN because
it can explicitly leverage problem-speciﬁc structures such as
road topology. PFSKM outperforms EKF because it can work
with arbitrary probability distributions, and sometimes a Gaus-
sian assumption is not a good approximation for real-world
applications. This comparison also points to new developments
in neural network architectures that are either regularized by
event-based structures of a complex system or can learn such
structures explicitly.

Comparing detailed predictions using SynthTown data:
Fig. 6 shows how PFSKM, DNN, RNN, and EKF predict
the number of vehicles at different locations of SynthTown
one hour ahead of time throughout the day from observations
of probe vehicles (10% of the total) at links 1 and 20 only.
The x-axis indicates the hour of the day, the y-axis shows the
number of vehicles at different locations (home, work, and
road segments marked on the left), and the ground truth (GT)
serves as the frame of reference.

All four algorithms perform well, indicating that they all
learn the structure in the dynamics. In fact, there is little
uncertainty about the trafﬁc dynamics at SynthTown if the
number of vehicles on links 1 and 20 can be monitored,
although with noise. RNN underperforms the other three
algorithms because learning the structure of a dynamic system

9

(a) SynthTown MSE

(b) Berlin MSE

(c) Santiago, Darkar, NYC MSE with PFSKM

(d) SynthTown R2

(e) Berlin R2

(f) Santiago, Darkar, NYC R2 with PFSKM

Fig. 5. Performance of PFSKM, DNN, RNN and EKF on SynthTown, Berlin, Dakar, Santiago de Chile and NYC Taxicab datasets using MSE (top, lower
MSE indicates better performance) and R2 (bottom, higher R2 indicates better performance).

Fig. 6. Predicted vehicle counts at home, work, and different road segments
of SynthTown (y-axis, with locations marked on the left) at different hours
of a day (x-axis) from the observations of probe vehicles (10% of the total)
at links 1 and 20 only. Algorithms with a good performance should lead to a
prediction closer to the ground truth (GT).

Fig. 7.
Vehicle counts at home, work, and various road segments of
SynthTown (y-axis, with locations marked on the left) at different hours of
a day (x-axis) after executing different planning and control algorithms from
the observations of probe vehicles (10% of the total) at links 1 and 20 only.
Algorithms with a good performance should lead to lower trip time and higher
on-time arrival ratio.

the ﬁgure horizontally, the people in our framework spend the
least time on roads (links 1, 6, 15, 20, 21, 22, and 23), and
the most time doing useful activities at locations (home and
work).

Comparing summary performance metrics: Table I com-
pares average trip time, on-time arrival ratio, and average unit
reward statistics of the four models using the SynthTown,
Berlin, Dakar, and Santiago de Chile datasets. The Berlin,
Dakar, and Santiago de Chile datasets are too large for the A2C
model to run, demonstrating the superior scalability of our
framework and CoEA. This comparison leads us to the same

conclusion as the detailed comparison on the SynthTown data.
Speciﬁcally, our framework has the lowest average trip time,
the highest on-time arrival ratio, and highest expected reward
among all datasets. The within-day re-planning algorithm
works better than the co-evolutionary algorithm because the
former uses instantaneous trafﬁc information for trip planning
in terms of average trip time, on-time arrival ratio, and the
Charypar-Nagel score. Our algorithm based on solving a
partially observable Markov decision process problem works
better than the within-day re-planning algorithm, because
we speciﬁcally optimize the Charypar-Nagel scoring function

5101520TrackingPredict10Predict60MSEScenarioSantiagoDakarNYC0.000.250.500.751.00TrackingPredict10Predict60R2ScenarioSantiagoDakarNYC02000hGTPFSKMEKFDNNRNN02000w0281010604150132003321045220152368101214161820Hours of dayTABLE I
COMPARING OUR FRAMEWORK, COEA, AND A2C FOR average trip time
IN MINUTES, on-time arrival ratio, AND expected reward PER VEHICLE PER
HOUR. RESULTS ARE OBTAINED USING THE SYNTHTOWN, BERLIN,
DAKAR, AND SANTIAGO DE CHILE DATASETS.

Dataset

Models

Average
trip time

SynthTown

Berlin

Dakar

Santiago

Baseline
Our framework
CoEA
A2C
Baseline
Our framework
CoEA
Baseline
Our framework
CoEA
Baseline
Our framework
CoEA

45.57
31.49
55.47
50.64
39.65
38.38
40.27
29.13
28.12
30.30
36.84
35.36
38.30

On-time
arriving
ratio
0.88
0.89
0.85
0.88
0.72
0.86
0.68
0.86
0.90
0.85
0.81
0.83
0.75

Expected
reward

1.05
2.93
-0.05
0.30
-20.65
-4.83
-54.00
-5.27
0.78
-10.06
-15.33
-7.58
-20.79

through trafﬁc prediction and optimization within POMDP.

VI. CONCLUSIONS AND DISCUSSIONS

The capability to sense the movement of millions of vehicles
through mobile phones and to offer drivers trip plans has
enabled a new way of controlling city trafﬁc dynamics by
turning transportation big data into insights and actions in
a closed-loop. In this paper, we have presented a study
showing that ﬂoating car data can indeed be utilized to offer
optimal departure times and route choices associated with
lower average trip time, higher on-time arrival ratio, and higher
Charypar-Nagel score compared with how people normally
travel, validated both in an agent-based transportation simula-
tor and in the real world. The study is based on optimizing
a partially observable discrete-time decision process and is
evaluated in one synthesized scenario, one partly synthesized
scenario, and three real-world scenarios.

The results show that the framework of turning transporta-
tion big data into insights and actions in the real world is
very much worth further research. For example, while the
study in this paper is based on maximizing the Charypar-
Nagel scoring function, further research is needed to identify
the utilities of people in the real world in the framework of
inverse reinforcement learning [23], [55]. While a particle ﬁlter
seems to be sufﬁcient for trafﬁc-prediction and city trafﬁc
optimization in this study, further research is needed to lower
the variance of Monte Carlo integration [56], [57]. In this
paper we approximated the queuing-network trafﬁc dynamics
of MATSim with a discrete-event process, but further work
to turn transportation simulators into a reinforcement learning
environment [58] will be useful to facilitate this “living lab”
style of research.

REFERENCES

[1] S. An, J. Cui, and L. Li, “Agent-based approach to model commuter
behaviour’s day-to-day dynamics under pre-trip information,” IET Intel-
ligent Transport Systems, vol. 5, no. 1, pp. 70–79, 2011.

[2] K. Kung, K. Greco, S. Sobolevsky, and C. Ratti, “Exploring universal
patterns in human home-work commuting from mobile phone data,”
PloS One, vol. 9, no. 6, p. e96180, 2014.

10

[3] Y. Zheng, Y. Liu, J. Yuan, and X. Xie, “Urban computing with taxicabs,”
in Proceedings of the 13th International Conference on Ubiquitous
Computing (Ubicomp), 2017, pp. 89–98.

[4] E. J. Horvitz, J. Apacible, R. Sarin, and L. Liao, “Prediction, expec-
tation, and surprise: Methods, designs, and study of a deployed trafﬁc
forecasting service,” in Proceedings of the Twenty-First Conference on
Uncertainty in Artiﬁcial Intelligence (UAI2005), 2005, pp. 275–283.
[5] F. Yang, B. Liu, and W. Dong, “Optimal control of complex systems
through variational inference with a discrete event decision process,”
in Proceedings of the 2019 International Conference on Autonomous
Agents & Multiagent Systems.
International Foundation for Au-
tonomous Agents and Multiagent Systems, 2019.

[6] Y. Lv, Y. Duan, W. Kang, Z. Li, and F.-Y. Wang, “Trafﬁc ﬂow
prediction with big data: A deep learning approach.” IEEE Transactions
on Intelligent Transportation Systems, vol. 16, no. 2, pp. 865–873, 2015.
[7] N. G. Polson and V. O. Sokolov, “Deep learning for short-term trafﬁc
ﬂow prediction,” Transportation Research Part C: Emerging Technolo-
gies, vol. 79, pp. 1–17, 2017.

[8] X. Ma, Z. Dai, Z. He, J. Ma, Y. Wang, and Y. Wang, “Learning
trafﬁc as images: a deep convolutional neural network for large-scale
transportation network speed prediction,” Sensors, vol. 17, no. 4, p. 818,
2017.

[9] J. Zhang, Y. Zheng, and D. Qi, “Deep spatio-temporal residual networks

for citywide crowd ﬂows prediction.” in AAAI, 2017, pp. 1655–1661.

[10] Z. Zhao, W. Chen, X. Wu, P. C. Chen, and J. Liu, “Lstm network: a
deep learning approach for short-term trafﬁc forecast,” IET Intelligent
Transport Systems, vol. 11, no. 2, pp. 68–75, 2017.

[11] A. K. Ziliaskopoulos, “A linear programming model for the single des-
tination system optimum dynamic trafﬁc assignment problem,” Trans-
portation science, vol. 34, no. 1, pp. 37–49, 2000.

[12] M. Zolfpour-Arokhlo, A. Selamat, S. Z. M. Hashim, and H. Afkhami,
“Modeling of route planning system based on q value-based dynamic
programming with multi-agent reinforcement learning algorithms,” En-
gineering Applications of Artiﬁcial Intelligence, vol. 29, pp. 163–177,
2014.

[13] L. Smith, R. Beckman, and K. Baggerly, “Transims: Transportation
analysis and simulation system,” Los Alamos National Lab., NM (United
States), Tech. Rep., 1995.

[14] A. Horni, K. Nagel, and K. W. Axhausen, “The multi-agent transport

simulation matsim,” Ubiquity, London, vol. 9, 2016.

[15] S. Timotheou, C. G. Panayiotou, and M. M. Polycarpou, “Distributed
trafﬁc signal control using the cell transmission model via the alternating
direction method of multipliers,” IEEE Transactions on Intelligent
Transportation Systems, vol. 16, no. 2, pp. 919–933, 2015.

[16] S. Lin, B. De Schutter, Y. Xi, and H. Hellendoorn, “Efﬁcient network-
wide model-based predictive control for urban trafﬁc networks,” Trans-
portation Research Part C: Emerging Technologies, vol. 24, pp. 122–
140, 2012.

[17] W. Genders and S. Razavi, “Using a deep reinforcement learning agent
for trafﬁc signal control,” arXiv preprint arXiv:1611.01142, 2016.
[18] N. Casas, “Deep deterministic policy gradient for urban trafﬁc light

control,” arXiv preprint arXiv:1703.09035, 2017.

[19] S. El-Tantawy, B. Abdulhai, and H. Abdelgawad, “Multiagent rein-
learning for integrated network of adaptive trafﬁc signal
forcement
controllers (marlin-atsc): methodology and large-scale application on
downtown toronto,” IEEE Transactions on Intelligent Transportation
Systems, vol. 14, no. 3, pp. 1140–1150, 2013.

[20] D. Ziemke, K. Nagel, and C. Bhat, “Integrating cemdap and matsim to
increase the transferability of transport demand models,” Transportation
Research Record: Journal of the Transportation Research Board, vol.
2493, pp. 117–125, 2015.

[21] B. Kickhöfer, D. Hosse, K. Turner, and A. Tirachini, “Creating an
open matsim scenario from open data: The case of santiago de chile,”
http://www. vsp. tuberline. de/publication: TU Berlin, Transport System
Planning and Transport Telematics, 2016.

[22] Y.-A. de Montjoye, Z. Smoreda, R. Trinquart, C. Ziemlicki, and V. D.
Blondel, “D4d-senegal: the second mobile phone data for development
challenge,” arXiv preprint arXiv:1407.4885, 2014.

[23] F. Yang, A. Vereshchaka, Y. Zhou, C. Chen, and W. Dong, “Variational
adversarial kernel learned imitation learning.” in AAAI, 2020, pp. 6599–
6606.

[24] F. Yang, B. Lepri, and W. Dong, “Optimal control in partially observable
complex social systems,” in Proceedings of
the 19th International
Conference on Autonomous Agents and MultiAgent Systems, 2020, pp.
1557–1565.

[25] F. Yang, A. Vereshchaka, and W. Dong, “Predicting and optimizing city-
scale road trafﬁc dynamics using trajectories of individual vehicles,” in

IEEE,

[49] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction.

11

2018 IEEE International Conference on Big Data (Big Data).
2018, pp. 173–180.

[26] Y. Wang, M. Papageorgiou, and A. Messmer, “Renaissance–a uniﬁed
macroscopic model-based approach to real-time freeway network trafﬁc
surveillance,” Transportation Research Part C: Emerging Technologies,
vol. 14, no. 3, pp. 190–212, 2006.

[27] C. P. van Hinsbergen, T. Schreiter, F. S. Zuurbier, J. Van Lint, and H. J.
Van Zuylen, “Localized extended kalman ﬁlter for scalable real-time
trafﬁc state estimation,” IEEE Transactions on Intelligent Transportation
Systems, vol. 13, no. 1, pp. 385–394, 2012.

[28] J. Van Lint and S. P. Hoogendoorn, “A robust and efﬁcient method for
fusing heterogeneous data from trafﬁc sensors on freeways,” Computer-
Aided Civil and Infrastructure Engineering, vol. 25, no. 8, pp. 596–612,
2010.

[29] X. Xie, H. van Lint, and A. Verbraeck, “A generic data assimilation
framework for vehicle trajectory reconstruction on signalized urban ar-
terials using particle ﬁlters,” Transportation Research Part C: Emerging
Technologies, vol. 92, pp. 364–391, 2018.

[30] F. Calabrese, M. Colonna, P. Lovisolo, D. Parata, and C. Ratti, “Real-
time urban monitoring using cell phones: A case study in rome,” IEEE
Transactions on Intelligent Transportation Systems, vol. 12, no. 1, pp.
141–151, 2011.

[31] J. Ferreira Junior, E. Carvalho, B. Ferreira, C. de Souza, Y. Suhara,
A. Pentland, and G. Pessin, “Driver behavior proﬁling: An investigation
with different smartphone sensors and machine learning,” PloS One,
vol. 12, no. 4, p. e0174959, 2017.

[32] B. Yu, H. Yin, and Z. Zhu, “Spatio-temporal graph convolutional
neural network: A deep learning framework for trafﬁc forecasting,”
Proceedings of the Twenty-Seventh International Joint Conference on
Artiﬁcial Intelligence (IJCAI-18), 2018.

[33] Y. Li, R. Yu, C. Shahabi, and Y. Liu, “Graph convolutional recurrent
neural network: Data-driven trafﬁc forecasting,” The Sixth International
Conference on Learning Representations (ICLR), 2018.

[34] Z. Zhu, C. Xiong, X. Chen, X. He, and L. Zhang, “Integrating meso-
scopic dynamic trafﬁc assignment with agent-based travel behavior mod-
els for cumulative land development impact analysis,” Transportation
Research Part C: Emerging Technologies, vol. 93, pp. 446–462, 2018.
[35] M. E. Ben-Akiva, S. Gao, Z. Wei, and Y. Wen, “A dynamic trafﬁc
assignment model for highly congested urban networks,” Transportation
research part C: emerging technologies, vol. 24, pp. 62–82, 2012.
[36] H. Rong, X. Zhou, C. Yang, Z. Shaﬁq, and A. Liu, “The rich and the
poor: A markov decision process approach to optimizing taxi driver
revenue efﬁciency,” in Proceedings of the 25th ACM International on
Conference on Information and Knowledge Management, 2016, pp.
2329–2334.

[37] X. Yu, S. Gao, X. Hu, and H. Park, “A markov decision process approach
to vacant taxi routing with e-hailing,” Transportation Research Part B:
Methodological, vol. 121, pp. 114–134, 2019.

[38] V. D. Blondel, A. Decuyper, and G. Krings, “A survey of results on
mobile phone datasets analysis,” arXiv preprint arXiv:1502.03406, 2015.
[39] D. T. Gillespie, “Stochastic simulation of chemical kinetics,” Annual

Review of Physical Chemistry, vol. 58, pp. 35–55, 2007.

[40] D. J. Wilkinson, Stochastic modelling for systems biology. CRC press,

2011.

[41] P. J. Goss and J. Peccoud, “Quantitative modeling of stochastic systems
in molecular biology by using stochastic petri nets,” Proceedings of the
National Academy of Sciences, vol. 95, no. 12, pp. 6750–6755, 1998.

[42] J. W. Forrester, Urban dynamics. MIT Press, Cambridge, 1969, vol.

114.

[43] A. Borshchev, The Big Book of Simulation Modeling: Multimethod

Modeling with AnyLogic 6. AnyLogic North America, 2013.

[44] M. Opper and G. Sanguinetti, “Variational inference for markov jump
processes,” in Advances in Neural Information Processing Systems,
2008, pp. 1105–1112.

[45] V. Rao and Y. W. Teh, “Fast mcmc sampling for markov jump processes
and extensions.” Journal of Machine Learning Research, vol. 14, no. 1,
pp. 3295–3320, 2013.

[46] U. Nodelman, C. R. Shelton, and D. Koller, “Continuous time bayesian
networks,” in Proceedings of the Eighteenth conference on Uncertainty
in artiﬁcial intelligence. Morgan Kaufmann Publishers Inc., 2002, pp.
378–387.

[47] A. Newell and H. A. Simon, Human problem solving.

Prentice-Hall

Englewood Cliffs, NJ, 1972, vol. 104.

[48] M. A. Marsan, G. Balbo, G. Conte, S. Donatelli, and G. Franceschinis,
John Wiley & Sons,

Modelling with generalized stochastic Petri nets.
Inc., 1994.

MIT press, 2018.

[50] M. Toussaint, S. Harmeling, and A. Storkey, “Probabilistic inference
for solving (po) mdps,” Institute for Adaptive and Neural Computation,
Tech. Rep., 2006.

[51] P. Pons and M. Latapy, “Computing communities in large networks using
random walks.” J. Graph Algorithms Appl., vol. 10, no. 2, pp. 191–218,
2006.

[52] J. Illenberger, G. Flotterod, and K. Nagel, “Enhancing matsim with
capabilities of within-day re-planning,” in 2007 IEEE Intelligent Trans-
portation Systems Conference.

IEEE, 2007, pp. 94–99.

[53] V. R. Konda and J. N. Tsitsiklis, “Actor-critic algorithms,” in Advances
in neural information processing systems, 2000, pp. 1008–1014.
[54] E. Popovici, A. Bucci, R. P. Wiegand, and E. D. De Jong, “Coevolu-
tionary principles,” in Handbook of natural computing. Springer, 2012,
pp. 987–1033.

[55] F. Yang, A. Vereshchaka, C. Chen, and W. Dong, “Bayesian multi-
type mean ﬁeld multi-agent imitation learning,” Advances in Neural
Information Processing Systems, vol. 33, 2020.

[56] Z. Xu, W. Dong, and S. N. Srihari, “Using social dynamics to make
individual predictions: variational inference with a stochastic kinetic
model,” in Advances in Neural Information Processing Systems, 2016,
pp. 2783–2791.

[57] L. Fang, F. Yang, W. Dong, T. Guan, and C. Qiao, “Expectation prop-
agation with stochastic kinetic model in complex interaction systems,”
in Advances in neural information processing systems, 2017, pp. 2029–
2039.

[58] L. Khaidem, M. Luca, F. Yang, A. Anand, B. Lepri, and W. Dong, “Op-
timizing transportation dynamics at a city-scale using a reinforcement
learning framework,” IEEE Access, vol. 8, pp. 171 528–171 541, 2020.

Fan Yang is a PhD candidate in the Department of
Computer Science and Engineering at the State Uni-
versity of New Your at Buffalo, USA. His research
interests includes reinforcement learning, imitation
learning, modeling, generative models, and proba-
bilistic graphical models.

Alina Vereshchaka is a PhD candidate in the
Department of Computer Science and Engineering
at the State University of New Your at Buffalo,
USA. Her current research interests include deep
reinforcement learning, optimization and multi-agent
modeling in stochastic environments. She has con-
ducted studies in the application areas of optimiza-
tion, transportation and healthcare.

Bruno Lepri received the Ph.D. degree in computer
science from the University of Trento, Italy, in 2009.
From 2010 to 2013, he was a joint Post-Doctoral
Fellow at MIT Media Lab, Boston, MA, USA, and
at Fondazione Bruno Kessler (FBK), Trento, Italy,
where he is currently leading the Mobile and Social
Computing Lab (MobS). He is also the Head of the
Research of Data-Pop Alliance, the ﬁrst thinktank
on Big Data and Development co-created by Har-
vard Humanitarian Initiative, MIT Media Lab, and
Overseas Development Institute.

Wen Dong is an Assistant Professor of Computer
Science and Engineering with a joint appointment
at the Institute of Sustainable Transportation and
Logics at
the State University of New York at
Buffalo. His research focuses on developing machine
learning and signal processing tools to study the
dynamics of large social systems in vivo. He has
a PhD degree from the M.I.T. Media Laboratory.

