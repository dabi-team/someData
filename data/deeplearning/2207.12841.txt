2
2
0
2

p
e
S
6

]

V
C
.
s
c
[

2
v
1
4
8
2
1
.
7
0
2
2
:
v
i
X
r
a

KinePose: A temporally optimized inverse kinematics technique for
6DOF human pose estimation with biomechanical constraints

Kevin Gildea1, Clara Mercadal-Baudart1, Richard Blythman1,2, Aljosa Smolic2, and Ciaran Simms1

1School of Engineering, Trinity College Dublin
2V-SENSE, School of Computer Science & Statistics, Trinity College Dublin

Abstract

Computer vision/deep learning-based 3D human pose estimation methods aim to localize human joints
from images and videos. Pose representation is normally limited to 3D joint positional/translational degrees
of freedom (3DOFs), however, a further three rotational DOFs (6DOFs) are required for many potential
biomechanical applications. Positional DOFs are insufﬁcient to analytically solve for joint rotational DOFs
in a 3D human skeletal model. Therefore, we propose a temporal inverse kinematics (IK) optimization
technique to infer joint orientations throughout a biomechanically informed, and subject-speciﬁc kinematic
chain. For this, we prescribe link directions from a position-based 3D pose estimate. Sequential least
squares quadratic programming is used to solve a minimization problem that involves both frame-based
pose terms, and a temporal term. The solution space is constrained using joint DOFs, and ranges of motion
(ROMs). We generate 3D pose motion sequences to assess the IK approach both for general accuracy, and
accuracy in boundary cases. Our temporal algorithm achieves 6DOF pose estimates with low Mean Per Joint
Angular Separation (MPJAS) errors (3.7°/joint overall, & 1.6°/joint for lower limbs). With frame-by-frame
IK we obtain low errors in the case of bent elbows and knees, however, motion sequences with phases of
extended/straight limbs results in ambiguity in twist angle. With temporal IK, we reduce ambiguity for these
poses, resulting in lower average errors. Code and supplementary material are available1.

Keywords: Human Pose Estimation, Computer Vision, Inverse Kinematics, Motion Capture, Biomechanics

Introduction

1
Human motion capture technologies are
widely used for animation, physiother-
apy, sports biomechanics, ergonomics,
robotics, and augmented/virtual reality.
However, many of these systems currently
involve the use of calibrated multi-sensor
setups, making them prohibitively expen-
sive and unsuitable for potential in-the-
wild applications.
In recent years, a
wide variety of computer vision based 3D
pose estimation methods have been devel-
oped, which present opportunities for a
form of free/low-cost markerless motion-
capture for use on in-the-wild video
footage, e.g., [Dinesh Reddy et al., 2021,
Pavllo et al., 2019].

1https://kevgildea.github.io/KinePose/

Figure 1: KinePose applied to an example case. 3D poses from
[Liu et al., 2020] (multicolor keypoints and gray dashed lines).

 
 
 
 
 
 
State-of-the-art position-based 3D pose estimators are capable of inferring root-relative joint positions
with remarkable accuracy, however, joint/link orientations are often not included, limiting their practical uses.
Approaches that indirectly regress for joint positions through applying joint orientations within a kinematic
chain currently have sub-par performance, and do not allow for user deﬁnition of chain properties, i.e., limb
lengths and joint ranges of motion (ROMs). Therefore, we propose a temporal optimization technique for
mapping/retargeting the motion of an ordered set of 3D joint positions obtained from a pose estimator, to a
user-deﬁned open kinematic chain. The kinematic solution space (see 3.2) is constrained using joint DOFs
and ROMs and limiting joint orientation changes between adjacent frames for temporal consistency (see 3.3).
The proposed approach can be applied as a post-processing technique for position-based 3D pose estimates
(particularly useful for monocular pose estimators), allowing for reﬁnement of 3D poses for a subject-speciﬁc
biomechanical model.

2 State of the Art
Both multi-camera and single-camera (monocular) 3D human pose estimation methods exist. Generally, they
employ a 2D keypoint pose estimator as a backbone and use computer vision/machine learning techniques to
‘lift’ the 2D pose into 3D. A simple calibrated multi-camera technique involves classical algebraic triangulation
of keypoint/joint positions. Many machine learning/regression-based multi-camera pose estimators have also
been developed, which use neural networks trained and tested on widely used motion capture datasets (e.g.
Human3.6M) to regress for both 2D and 3D keypoints directly from images/videos. Regression-based multi-
camera pose estimators have achieved high accuracies of below 2cm Mean Per Joint Position Error (MPJPE)
over a variety of tasks in Human3.6M [Dinesh Reddy et al., 2021, Iskakov et al., 2019]. Considering the in-
herent depth ambiguities, remarkably high accuracy has also been achieved from monocular pose estimators
(in the order of 3-5cm MPJPE) [Dinesh Reddy et al., 2021, Pavllo et al., 2019]. However, position-based pose
representation suffers from several limitations. In particular, joint/link orientations are not included, subject
size estimates are inaccurate, and predicted limb lengths are often quite variable, greatly limiting its practical
uses, e.g., in biomechanics applications. Other regression-based pose estimators address a portion of these lim-
itations through predictions of joint rotations within a kinematic chain [Pavllo et al., 2018, Zhou et al., 2016],
i.e., through forward kinematics (FK) (see 3.1). There are various ways to parameterize these rotations (e.g.,
sequential Euler/Cardan angles, Euler/Screw axis-angle), though unit quaternions are generally preferred as
they overcome singularities associated with operations in (cid:82)3. Orientation-based 3D pose representation allows
for orientation losses to be included, i.e., MPJAS (see 3.3.4). Furthermore, model-based pose estimators allow
for other biomechanical constraints such as joint DOFs. Though orientation-based pose representation is more
physically meaningful than position-based representation, the results are mostly sub-par in terms of MPJPE.
However, these are promising approaches meriting further development. A popular human biomechanics soft-
ware OpenSim contains an IK tool for prescribing joint positions to a biomechanical model, which has recently
been applied to obtain joint orientations from triangulated 2D predictions, i.e., Pose2Sim [Pagnon et al., 2021].
However, many practical applications require a similar tool for 3D pose estimates from a monocular method,
which have characteristics that restrict its application. Namely, subject dimensions are inaccurately scaled
(since there is no context for the size of the subject), and limb lengths are often variable. Therefore, our
approach instead prescribes link directions (see 3.3.2), thus allowing for retargeting of incongruent skeletons.

3 Methods
In this section we give an overview of our IK approach for mapping kinematic chains, i.e., kinematic retargeting.
In 3.1 we describe the process of FK, which is used in parameterization. In 3.2 we describe the indeterminate
nature of the problem. In 3.3, we describe the proposed IK optimization procedure incorporating chain DOFs,
ROMs, and kinematic loss terms.

3.1 Forward kinematics
Kinematic chains can be described as a hierarchical system of links and joints. They are represented by: 1)
the locations and orientations of each of the joints, and 2) the hierarchy of the joints in the system. The
Denavit-Hartenberg (DH) FK convention allows for compact representation and convenient manipulation of

kinematic chains as a series multiplication of 4x4 transformation matrices along the path to the joint. DH-FK
uses a parent-child convention, whereby positions and orientations of child joints are expressed in the parent
coordinate systems, i.e., the position of an arbitrary joint (j) is expressed as a vector in the coordinate system
of its parent joint/body (jparent), i.e., (cid:169)−→
, and the orientation of the joint is expressed as a 3x3 rotation
matrix which speciﬁes the orientation with respect to the parent, i.e., (cid:163)R j , jpar ent (cid:164). For each joint, the parent-child
transformation matrix is then deﬁned in Equation 1. The set of these for an N-joint chain C (with ‘0’ denoting
the global coordinate system) is expressed in Equation 2.

r (cid:170) jpar ent
j , jpar ent

(cid:169)Tj

(cid:170) j , jpar ent =

(cid:34)(cid:163)R j , jpar ent (cid:164)
0 0 0

(cid:169)−→
r (cid:170) jpar ent
j , jpar ent
1

(cid:35)

.

(1)

C = (cid:169){T1}1,0, . . . , {TN}N ,Npar ent (cid:170) .

(2)

To perform kinematic operations on an open chain with branching (e.g., the human body) we need also
use a directed graph (G) specifying its hierarchical structure. We can then perform FK to express joint/body
positions and orientations in the global coordinate system (Equation 3).

(cid:169)Tj

(cid:170) j ,0 = (cid:81)1

i = j {Ti}i ,i par ent

for i on path to root = FK(C ,G).

(3)

The utility of deﬁning a kinematic chain in this manner can be demonstrated if we would like to edit or
reorient our kinematic chain. It makes physical sense to apply the rotation in the local coordinate system, e.g.,
a rotation of the knee is kinematically constrained (due to its DOFs) to occur about a ﬁxed axis deﬁned in the
local coordinate system (usually chosen to be a cardinal axis). Furthermore, performing FK with the inclusion
of a reorientating transformation matrix (cid:169)Tj∆R
(cid:170) j , jpar ent will automatically reorient and reposition all down-chain
joints (Equation 4). The kinematic chain is parameterized in this way.

(cid:169)Tj

(cid:170) j ,0 = (cid:81)1

i = j {Ti}i ,i par ent (cid:169)Tj∆R

(cid:170) j , jpar ent

for i on path to root = FK(C ,G, (cid:169)Tj∆R

(cid:170) j , jpar ent ).

(4)

3.2 Kinematic indeterminacy
In the Supp.Mat.1, we formulate all rotation matrices representing all possible Euler axis-angle combinations
−→
a to point in the same direction as a vector
for mapping/retargeting a vector

−→
b (Equation 5).

(cid:104)

R(cid:98)a→(cid:98)b(cid:105)E AS

=



α,y

α,x

n2

+ (n2

+ n2
nα,x nα,y (1 − cos(Φα)) + nα,z si n(Φα)


nα,x nα,z (1 − cos(Φα)) − nα,y si n(Φα) nα,y nα,z (1 − cos(Φα)) + nα,x si n(Φα)

nα,x nα,y (1 − cos(Φα)) − nα,z si n(Φα) nα,x nα,z (1 − cos(Φα)) + nα,y si n(Φα)
nα,y nα,z (1 − cos(Φα)) − nα,x si n(Φα)

 .
+ n2

α,z )cos(Φα)

α,z )cos(Φα)

+ (n2

+ (n2

+ n2

α,y )cos(Φα)

n2

n2

α,x

α,x

α,y

α,z



(5)

−→
n α and Φα represent the Euler axis-angle solution space (EAS), and α is a continuous angular value
Where
spanning −π to π used to deﬁne unit vectors on the plane symmetrically bisecting the vectors, i.e., candidate
Euler axes for which corresponding Euler angles can be computed.

We can use Equation 5 to analyti-
cally deﬁne the solution space for retar-
geting/mapping one kinematic chain (C)
to an ordered set of 3D positions (P). The
Euler axis-angle solution spaces for all
joints in the chain are computed by com-
bining Equations 4&5. This is visualized
in Figure 2 for a 3-joint serial chain. The
problem has an indeterminate solution (in-
ﬁnite solution space), therefore, optimiza-
tion is needed. Speciﬁcally, the indetermi-
nacy of this problem is due to the ambigu-
ous ‘twist’ angle. The solution space can

Figure 2: Solution space for mapping/retargeting a kinematic chain
to an incongruent hierarchical set of 3D positions.

be somewhat constrained by specifying anatomical joint DOFs and ROMs (see 3.3.1). The problem is compli-
cated in a chain such as the human body with branching, i.e., the mapping process used to generate the solution
space is faced with a dilemma when reorienting branching joints. Therefore, our approach involves IK opti-
(cid:170) j , jpar ent ). In
mization, with parameterization of the reorientation transformation matrix in Equation 4 (i.e., (cid:169)Tj∆R
general terms, since motion sequences involve kinematic indeterminacy our hypothesis is that two metrics can
be used to converge to an optimal solution: 1) a frame-based pose loss term, and 2) a temporal consistency loss
term (see 3.3.2).

Inverse kinematics optimization

3.3
3.3.1 Kinematic chain
Many position-based 3D pose estimators employ a similar chain con-
ﬁguration. We deﬁne a kinematic chain based on this, using common
characteristics to optimize for joint orientations. Joints/bodies are de-
ﬁned to correspond to keypoints, i.e., the mid pelvis (deﬁned as the
root), hips, knees, ankles, mid spine, neck, head, shoulders, elbows,
and ankles. Additional joints are also deﬁned for greater biomechan-
ical ﬁdelity, i.e.
the lower spine, and clavicles (see Figure 3). The
chain has 14 joints for reorientation, and a total of 28 rotational DOFs.
Initially, the kinematic chain is deﬁned in a rest/quiet standing pose,
i.e., we deﬁne a set of transformation matrices (see Equations 2&3) to
describe a human in a relaxed standing pose with their arms by their
sides. Limb/link lengths in the chain are constant and may be user
deﬁned. Changes in pose from rest are implemented using FK and an
additional transformation matrix (see Equation 4). Joint ROMs may
be speciﬁed in the local coordinate system as allowable angle ranges about each cardinal axis of the joint co-
ordinate system, where θ j , φ j , and ψ j correspond to sequential rotations about the local X, Y, and Z axes
respectively (see Figure 3). For assessment, generalized ROM limits are used, however, they can be further
customized. Since there is no 3D keypoint that can be used to directly target the lower spine joint, the lower
and mid spine joints are assigned equally proportioned ROMs which add to the overall ROM of that area of
the spine. Though not without limitations [Baerlocher and Boulic, 2001], Cardan/Euler angles present a conve-
nient and intuitive approach for parameterizing the optimization weights associated with joint rotations within
the kinematic chain, whilst also allowing for speciﬁcation of joint ROMs using bounds to constrain the solu-
tion space. Gimbal lock singularities limit the of use of Cardan/Euler angles for parameterization of human
pose. However, the application of anatomical joint DOFs and ROMs in the form of Cardan/Euler angle ranges
naturally avoids singularities in our formulation by limiting − π
2 (see Supp.Mat.1). However, since
2
the root joint retains a full ROM, we parameterize the root orientation with respect to the global coordinate
−→
n = (cid:169)nx , ny , nz
(cid:170), Φ). Using ROMs throughout the chain
system using the Euler/Screw axis-angle convention (
and bounding the Screw angle in the root joint also overcomes rotation periodicity, i.e., sin x = sin (x + 2π, and
cos x = cos x + 2π.

Figure 3: Kinematic chain parameters.

< φ j < π

3.3.2 Losses
Two frame-based pose error terms are deﬁned, which both minimize the
angular difference in vectors between the 3D pose and the reoriented
kinematic chain. We apply a local pose error term (Equation 6) which
penalizes angular difference in link vector directions (shown in green
in Figure 4), where {(cid:98)r}0
is the normalized vector in the kinematic
chain linking joint j to its parent in the global coordinate system (denoted
by superscript ‘0’) and (cid:169)
is the corresponding normalized vec-
tor on the 3D pose skeleton. Since the kinematic chain includes clavicles
which do not correspond to 3D pose keypoints, and there is no appropri-

(cid:98)p(cid:170)0

j , jpar ent

j , jpar ent

Figure 4: Pose loss vectors.

ate local pose vector to use to constrain the orientations of these joints, we also include a global pose error term
(Equation 7) which considers angular difference in global vectors in the arms of the kinematic chain {(cid:98)r}0
j ,1, i.e.,
stemming from the root joint (shown in orange in Figure 4).
−1({(cid:98)r}0

−1({(cid:98)r}0

(cid:98)p(cid:170)0
· (cid:169)

(cid:176)
(cid:176)
(cid:176)cos

(cid:176)
(cid:176)
(cid:176)cos

−→
p )g l obal

−→
p )l ocal

(cid:98)p(cid:170)0

= 1
N

= 1
A

j , jpar ent

j , jpar ent

(cid:176)
(cid:176)
(cid:176) .

(cid:176)
(cid:176)
(cid:176) .

j ,1)

(6)

(7)

−→
r ,
(

−→
r ,
(

(cid:80)N

(cid:80)A

j =1

j =1

· (cid:169)

j ,1

E(cid:54)

E(cid:54)

)

In cases where there are co-linear sequential links, i.e., when there are fully extended limbs (knees or
elbows), there will be kinematic indeterminacy. Our hypothesis is that appropriately weighted minimization
of joint orientation changes between frames (∆Θ j ) can constrain the solution space toward an optimal solution
with temporal consistency, i.e., optimizing poses across frames with extended and bent limbs (Equation 8) (for
a sequence of poses M frames long).

E∆Θ = 1
M

(cid:80)M

m=1

(cid:110)(cid:80)N

j =1

(cid:176)
(cid:176)∆Θ j

(cid:176)
(cid:176)

(cid:111)

m

,

(8)

− Θm
j

for m = 1, ∆Θ j = (Θm+1

j

− Θm−1
j

)/2 for 1 < m < M, and ∆Θ j = Θm
j

− Θm−1
j

for

where ∆Θ j = Θm+1

j

m = M.

We deﬁne a loss function L f r ame for frame-by-frame IK (Equation 9), and combining Equations 6,7&8
with scalar weighting for the temporal term which competes with the pose error terms, we deﬁne Lt empor al for
temporal IK (Equation 10).
L f r ame = E(cid:54)

(10)

m=1 L f r ame=m + λE∆Θ.

Lt empor al = 1
M

−→
p )g l obal

−→
p )l ocal

+ E(cid:54)

−→
r ,
(

−→
r ,
(

(cid:80)M

(9)

,

3.3.3 Algorithms
A sequential least squares programming procedure is used to solve the minimization problem [Kraft, 1988].
This procedure is commonly used for robust nonlinear programming solutions to kinematic retargeting and IK.
All algorithms take the kinematic chain C in its rest/quiet pose, and a sequence of 3D poses for F frames as
inputs (P). The algorithms output optimized model parameters or joint DOFs (Θ∗) using IK (Equation 11).
These can then be used to specify a sequence of retargeted chains (cid:169)C
∗
∗
1 , . . . , C
F

(cid:170) using Equation 4.

Θ∗ = IK(C ,G, P, Θ0) subject to arg minΘ(L).

(11)
Since convergence of local optimization methods depends on the initial guess (Θ0), we perform a relatively
computationally inexpensive frame-by-frame pre-optimization as input to our temporal optimization, using
L f r ame (Equation 9) as the objective function (Algorithm 1). This addition also speeds up the optimization time
signiﬁcantly.

The temporal algo-
rithm (Algorithm 2) in-
volves blocks, or patches
of M frames (out of a to-
tal of F frames) in which
sequences of poses are
retargeted in tandem with
the inclusion of both pose
and temporal error terms
(Equation 10). Patches
are temporally linked or
‘stitched’ with an additional temporal error term, i.e., the difference in model parameters (E∆Θ) between the
ﬁnal frame of patch i − 1 and the ﬁrst frame of patch i are used in the loss function for patch i (Figure 5).

Figure 5: Overview of the proposed IK approach (patch length M=3).

500 , b) π

200 , and c) π

3.3.4 Assessment
For algorithmic assessment of the IK approaches, we generate twenty-four 30-frame long motion sequences
within joint ROMs for the kinematic chain, with three levels of motion speed, with maximum cardan angle
changes between frames of a) π
70 . The latter corresponding approximately to full movement
within ROMs. Half of the sequences consist of only bent limbs, and the other half have a combination of
prescribed phases of either bent or extended limbs. The motion sequences have been deﬁned such that each
sequence with bent limbs has a corresponding sequence with phases of bent limbs and extended limbs, where
motion in the rest of the skeleton is identical. These phases are: 1) 3 frames extended, 2) 9 frames bent, 3)
6 frames extended, 4) 9 frames bent, 5) 3 frames extended. Generation of motion in this manner allows for
analysis of the effect on accuracy of extended limbs (which results in ambiguity in twist angle) for various IK
implementations. We apply a series of IK algorithms to the resulting joint pose sequences, i.e., with ground truth
joint orientations hidden. We compare Algorithm 1 with and without feeding of optimized model parameters
from previous frames (1a and 1b respectively), and Algorithm 2 with different patch sizes, i.e., 23 (M=3) and 25
(M=5). Computation time on an Intel® Core™ i7-9700 processor is recorded for each implementation. Overall
agreement was assessed using Mean Per Joint Angular Separation (MPJASN ) for all joints that are reoriented
(N=14) across frames, i.e., the average angular difference about the Screw axis between inferred and ground
truth (GT) joint orientations (cid:169)Φj
pr ed ,GT (Equation 12). For comparison, we also calculate MPJAS for each
individual joint.

(cid:170)

MPJASN = 1
F

(cid:80)F

f =1

(cid:110) 1
N

(cid:80)N

j =i

(cid:176)
(cid:169)Φj
(cid:176)
(cid:176)

(cid:170)

pr ed ,GT

(cid:111)

(cid:176)
(cid:176)
(cid:176)

.

f

(12)

An ablation study was performed on a sample of 12 additional motion sequences to determine the optimal
scalar weight for the temporal model (λ) for different motion speeds (λ = 0.3 for speed c, λ = 0.5 for speed b,
and λ = 0.7 for speed a).
4 Results
Table 1 shows a comparison of average angular errors and optimization times for Algorithm 1 with feeding of
weights between frames for initialization (1b), or no feeding (1a), and Algorithm 2 with patches of length 3
(23) or 5 (25) for three levels of motion speed.
Table 1: Accuracy of IK Algorithms 1 and 2. MPJAS14 per frame for three levels of motion speed (fps: Opti-
mization frames per second, E: 14-joint Mean Per Joint Angular Separation (rad/joint)).

Algorithm
1a
1b
23
25

Speed a

Speed b

Speed c

Average

fps
7.44x10−2
9.63x10−2
2.03x10−2
8.94x10−3

E
9.45 x10−2
7.65x10−2
8.28x10−2
7.07x10−2

fps
6.96x10−2
9.28x10−2
2.33x10−2
1.32x10−3

E
9.13 x10−2
7.45x10−2
7.69x10−2
7.40x10−2

fps
7.48x10−2
8.61x10−2
5.74x10−2
3.90x10−2

E
8.12x10−2
5.68x10−2
5.07x10−2
5.13x10−2

fps
7.29x10−2
9.15x10−2
2.74x10−2
1.41x10−2

E
8.90 x10−2
6.93x10−2
7.01x10−2
6.53x10−2

Table 2 shows a comparison of average an-
gular errors for motions with 1) bent limbs only,
or 2) a combination of bent and extended limbs.
Motion sequences with only bent limbs have low
errors for all algorithms, and for sequences with
phases of extended limbs algorithm 1b and both
temporal algorithms have lower errors.

Table 2: MPJAS14 per frame for motion sequences with 1)
only bent limbs, or 2) phases of extended limbs.
Bent limbs only
5.84x10−2
6.05x10−2
5.39x10−2
5.64x10−2

Extended & bent limbs
1.20x10−1
7.80x10−2
8.64x10−2
7.43x10−2

Algorithm
1a
1b
23
25

Figure 6 shows a comparison of average average angular errors for parameterized joints in the chain for
motion sequences with phases of bent and extended limbs. Algorithm 1a produces higher errors in the clavicles
(due to a lack of corresponding keypoints), and shoulders and hips (associated with ambiguity in twist angles).
Results for motion sequences with only bent limbs are provided in the Supp.Mat.1 Furthermore, the relationship
between phases of extended/bent limbs are investigated further for boundary cases.

Figure 6: MPJAS1 by joint and algorithm, for motion sequences with phases of bent and extended limbs.

5 Discussion
MPJAS14 errors are low for all algorithms and motion speeds, ranging from average errors of 8.90x10−2 rad/joint
for algorithm 1a (5.1°), to 6.53x10−2 rad/joint for algorithm 25 (3.7°) (Table 1). Differences observed between
algorithm 1a and 1b highlight the importance of the initialization guess for weights, i.e., feeding weights from
previous frames for initialization in a frame-by-frame optimization reduces time to convergence (Table 1), and
adds a degree of temporal consistency. The results provide a clear justiﬁcation for the temporal model. While
algorithm 1b outperforms 23 on average, temporal algorithm 25 is the best performer across all indicators. The
beneﬁts of the temporal model relate to twist angle ambiguity (Table 2 & Figure 6), and are of particular beneﬁt
for a speciﬁc boundary case involving an initial phase of extended limbs, followed by a phase of bent limbs (see
Supp.Mat.1). Large ﬂuctuations in twist angles are observed for algorithm 1a, whereas, algorithm 1b and both
variations of the temporal algorithm result in lower errors both overall, and in boundary cases. Algorithm 25
achieves the highest accuracy for all motion speeds, and obtains particularly low errors for the lower limbs (hips
& knees), i.e., 2.71x10−2 rad/joint (1.6°) for motion sequences involving phases of extended limbs (Figure 6),
and 1.63x10−3 rad/joint (0.1°) for motion with only bent limbs (see Supp.Mat.1). Temporal implementations
with sufﬁciently large patch sizes are effective for reducing ambiguity in twist angle, which is a key beneﬁt.
Nevertheless, algorithm 1b is suitable for applications requiring faster processing. The temporal scalar weight
should be tuned for both motion speed and video framerate. For fast motion or a low framerate, relative joint
orientation changes between frames will naturally be higher, therefore requiring a lower weighting. Similarly,
for slow motion or high framerate a higher weighting is required.

Due to a lack of relevant keypoints, twist angles of the forearms and neck, and joint reorientations of the
ankles and wrists are currently not included. However, an extension could include these for 3D pose inputs
with more keypoints in the extremities. A large proportion of the errors are associated with those joints in the
chain without corresponding keypoints, i.e., clavicles and lower spine. Parameterization of the lower/mid spine
with equally proportioned rotations in two joints may often not be bioﬁdelic, indeed, this relationship is often
the subject of analyses in biomechanics. These limitations are imposed by the fact that current 3D pose esti-
mators do not include sufﬁcient keypoints. Synthetic generation of motion, as per [Beeson and Ames, 2015],
allows for a detailed assessment of the mathematical procedure including boundary cases of interest. How-
ever, for potential practical applications further testing should include GT activity-speciﬁc motion capture
footage. Furthermore, practical applications rely on the accuracy of the 3D pose estimator used; calibrated
multi-camera pose estimators have higher accuracy, whereas monocular pose estimators are more practically
useful. KinePose is applicable to either multi-camera, or monocular 3D pose estimators with incorrectly scaled
skeletons and variable link lengths.
6 Conclusions
This paper proposes KinePose, a convenient post-processing technique for position-based 3D human pose
estimation methods, to infer joint orientations in a subject-speciﬁc biomechanical model. We demonstrate that
this technique allows for accurate prediction of joint orientations. This technique may be particularly useful
for sports biomechanics, and telehealth applications. Though currently unsuited to real-time applications, we
envisage many potential applications as a post-processing technique for 3D pose estimators.

Acknowledgements
This research was funded under the RSA-Helena Winters Scholarship for Studies in Road Safety.

References

[Baerlocher and Boulic, 2001] Baerlocher, P. and Boulic, R. (2001). Parametrization and Range of Motion of the Ball-

and-Socket Joint. Deformable Avatars, pages 180–190.

[Beeson and Ames, 2015] Beeson, P. and Ames, B. (2015). TRAC-IK: An open-source library for improved solving of

generic inverse kinematics. International Conference on Humanoid Robots, pages 928–935.

[Dinesh Reddy et al., 2021] Dinesh Reddy, N., Guigues, L., Pishchulin, L., Eledath, J., and Narasimhan, S. G. (2021).
TesseTrack: End-to-End Learnable Multi-Person Articulated 3D Pose Tracking. In Conference on Computer Vision
and Pattern Recognition, pages 15190–15200.

[Iskakov et al., 2019] Iskakov, K., Burkov, E., Lempitsky, V., and Malkov, Y. (2019). Learnable Triangulation of Human

Pose. International Conference on Computer Vision, pages 7717–7726.

[Kraft, 1988] Kraft, D. (1988). A software package for sequential quadratic programming. Wiss. Berichtswesen d.

DFVLR.

[Liu et al., 2020] Liu, J., Rojas, J., Li, Y., Liang, Z., Guan, Y., Xi, N., and Zhu, H. (2020). A Graph Attention Spatio-
temporal Convolutional Network for 3D Human Pose Estimation in Video. In International Conference on Robotics
and Automation, pages 3374–3380.

[Pagnon et al., 2021] Pagnon, D., Domalain, M., and Reveret, L. (2021). Pose2Sim: An End-to-End Workﬂow for 3D

Markerless Sports Kinematics—Part 1: Robustness. Sensors 2021, Vol. 21, Page 6530, 21(19):6530.

[Pavllo et al., 2019] Pavllo, D., Feichtenhofer, C., Grangier, D., and Auli, M. (2019). 3D human pose estimation in video
with temporal convolutions and semi-supervised training. In Conference on Computer Vision and Pattern Recognition,
pages 7745–7754.

[Pavllo et al., 2018] Pavllo, D., Grangier, D., and Auli, M. (2018). QuaterNet: A Quaternion-based Recurrent Model for

Human Motion. In British Machine Vision Conference.

[Zhou et al., 2016] Zhou, X., Sun, X., Zhang, W., Liang, S., and Wei, Y. (2016). Deep Kinematic Pose Regression. In

European Conference on Computer Vision, pages 186–201.

