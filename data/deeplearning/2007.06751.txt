SESAME: S
¯
ccelerators with M
¯

oftware deﬁned E
¯
ulti-tenant E
¯

nclaves to S
¯
xecution

A
¯

ecure Inference

0
2
0
2

l
u
J

5
1

]

R
C
.
s
c
[

2
v
1
5
7
6
0
.
7
0
0
2
:
v
i
X
r
a

Sarbartha Banerjee1, Prakash Ramrakhyani2, Shijia Wei1, and Mohit Tiwari1

1University of Texas at Austin
2ARM Research

{sarbartha,shijiawei}@utexas.edu

prakash.ramrakhyani@arm.com tiwari@austin.utexas.edu

ABSTRACT

Hardware-enclaves that target complex CPU designs com-
promise both security and performance. Programs have little
control over micro-architecture, which leads to side-channel
leaks, and then have to be transformed to have worst-case
control- and data-ﬂow behaviors and thus incur considerable
slowdown. We propose to address these security and per-
formance problems by bringing enclaves into the realm of
accelerator-rich architectures.

The key idea is to construct software-deﬁned enclaves
(SDEs) where the protections and slowdown are tied to an
application-deﬁned threat model and tuned by a compiler for
the accelerator’s speciﬁc domain. This vertically integrated
approach requires new hardware data-structures to partition,
clear, and shape the utilization of hardware resources; and a
compiler that instantiates and schedules these data-structures
to create multi-tenant enclaves on accelerators.

We demonstrate our ideas with a comprehensive prototype
– Sesame – that includes modiﬁcations to compiler, ISA, and
microarchitecture to a decoupled access execute (DAE) ac-
celerator framework for deep learning models. Our security
evaluation shows that classiﬁers that could distinguish differ-
ent layers in VGG, ResNet, and AlexNet, fail to do so when
run using Sesame. Our synthesizable hardware prototype (on
a Xilinx Pynq board) demonstrates how the compiler and
micro-architecture enables threat-model-speciﬁc trade-offs
in code size increase ranging from 3-7 % and run-time per-
formance overhead for speciﬁc defenses ranging from 3.96%
to 34.87% (across conﬁdential inputs and models and single
vs. multi-tenant systems).

1.

INTRODUCTION

Hardware-enclaves are key to conﬁdential computing [8]
– where users can push their private data into a box that
is invisible to privileged software, co-resident processes,
and even attackers with physical access to the pins of the
chip [10, 16, 23, 24, 38, 39, 42, 54, 59]. Conﬁdential computing
can provide a trustworthy foundation where users can safely
work with healthcare, ﬁnancial, or business data while organi-
zations can ofﬂoad compliance enforcement [1, 2] to services
that provide hardware root of trust.

Enclaves today however offer a Hobson’s choice. A user
can pick a design like Intel SGX that hardwires a very spe-
ciﬁc threat model for general-purpose CPUs – and pay with
performance-overheads [22, 60] and the risk of side-channel
breaches [18, 43, 62, 64] – or be left with the default unpro-
tected execution inside virtual machines. Crucially, conﬁ-
dential computing is limited to general-purpose cores while
accelerator-rich architectures [19,36] worsen the gap between
non-secure and enclaved execution for important classes of
programs like deep learning and graph computing [27, 28].

In this paper, we propose to bring conﬁdential comput-
ing to domain-speciﬁc secure accelerators, retaining most of
the performance beneﬁts of using an accelerator (compared
to CPUs) and also reducing the attack surface by closing
side-channels. The key insight is to enable software-deﬁned
enclaves – where software can construct enclaves that are cus-
tomized for a speciﬁc threat-model and program domain – in
order to optimize performance without leaking secrets. Threat
models are only known at deployment-time, and hard-wiring
one into hardware means that every conﬁdential program
pays the price of security against threats they may not care
about – for example, the cost of integrity checks or oblivious
main memory accesses in a secure data-center facility, or the
price of obfuscating code when it might be public. Similarly,
general purpose program execution have to be obfuscated as-
suming worst-case control- and data-ﬂows and uncontrolled
micro-architectural side-effects [50, 51] which incurs signif-
icant slowdowns. Software-deﬁned enclaves can tune the
slowdowns from security to scale gracefully with threat mod-
els while driving security and performance optimizations
down from algorithms to bits and gates.

Speciﬁcally, we introduce Sesame, a software-deﬁned en-
clave framework for multi-tenant machine learning infer-
ence accelerators that are tightly coupled to a CPU (e.g.,
Arm Ethos-N NPUs [5, 17]). We focus on decoupled access-
execute (DAE) architectures as an example accelerator that
is popular across deep learning, graph, and other data-driven
domains across cloud and edge devices. Sesame takes deep
learning models such as VGG, ResNet, and AlexNet as in-
put and produces as output an auto-tuned program and a
multi-tenant hardware design that enforces computational
non-interference between security domains. Crucially, a user

1

 
 
 
 
 
 
can express their threat model in terms of (a) the program
model and/or the user inputs being secret, and (b) whether
the attacker’s visibility includes on-chip or off-chip signals.
Sesame translates all concurrent users’ threat models into
a lattice of security labels and ensures computational non-
interference among all labels – (informally) ensuring that
secret inputs/model information from one user does not leak
via on-chip and/or off-chip signals to other users (including
the cloud provider or hardware-owner).

Sesame includes defense mechanisms across the layers of
the accelerator stack. At the synthesizable hardware (RTL)
level, we introduce two new data-structures that the Sesame
compiler can instantiate and tune for the current threat model
and program: (1) private queue that software can partition
based on a schedule – these queues prevent contention-channel
leaks and replace queues that are ubiquitous in hardware de-
signs between pipelined stages and arbiters of shared hard-
ware; (2) trafﬁc shaper that decouples observation channels
– where attackers infer secrets from signals coming out of
a software-deﬁned enclave – from secret variables. While
partitioning and shaping are generic strategies that have been
applied from networking [63] to hardware [68], Sesame’s con-
tribution is to enable compiler/synthesis tools to overlay non-
secure RTL designs with private queues and shapers and re-
use the data movement logic to create ﬂexible enclaves. Fur-
ther, for trafﬁc shapers that can be software-conﬁgured, their
RTL implementation can be far simpler than (e.g.) hardware-
only shapers designed speciﬁcally to obfuscate main memory
trafﬁc [68].

At the compiler level, Sesame’s auto-tuning phase gen-
erates a tiling schedule that maximizes performance while
ensuring that the computation and memory access schedule
has no secret information. The code-generator then annotates
instructions appropriately to obfuscate observation channels
like execution variability and based on the threat model the
driver turns on defenses like private queues and trafﬁc shap-
ing to quash contention and external observation channels.

Enabling a constant-time mode for execution units (like
GEMM and ALU) is the last piece required to construct multi-
tenant enclaves – our prototype system’s baseline GEMM
and ALU units happen to be constant-time already and hence
we do not use this feature.

To summarize, we make the following contributions:

• Sesame introduces software-deﬁned enclaves for domain
speciﬁc accelerators, enabling enclave software to be con-
ﬁdential against co-tenants and infrastructure providers.

• A detailed vulnerability analysis of on-chip accelerators,
highlighting gaps that need defenses in order to construct
a range of accelerator enclaves.

• A cross-layer design including new hardware data-structures
to shape trafﬁc and to share queues (in addition to using
standard base-bound techniques to partition on-chip state);
exposed via ISA extensions to software; that a compiler
uses to generate code for a user-speciﬁed threat model.

• An end-to-end implementation of a deep-learning accelera-
tor (using a baseline VTA [45] system) where Sesame com-
piles and synthesizes six workloads – including ResNet,
VGG, and AlexNet models – to a Xilinx FPGA.

• A security evaluation that shows a classiﬁer that could
distinguish different layers in each model (the ﬁrst step to-
wards reversing models and weights) is foiled by Sesame;
and performance evaluation in terms of code-size, slow-
down, and area cost of Sesame across a range of system
conﬁgurations and threat models. For example, slowdown
varies from 3.96% to 29.2% under increasingly conﬁden-
tial and contention-heavy settings.

We will open source our hardware and compiler contribu-
tions to spur further research into software-deﬁned enclaves
for DAE-applications beyond deep learning.

2. BACKGROUND

2.1 Baseline Secure Platform

Our baseline consists of a user on a client system who
engages one or more services deployed by an infrastructure
provider on a cloud system. The infrastructure provider can
expose accelerator resources in standard units (e.g., smal-
l/medium/large instances on Amazon’s F1 cloud) that the
user’s Sesame compiler can generate code for. Alternatively,
a high level model may be communicated securely to the
cloud which is then compiled in a sandbox to ensure no infor-
mation is leaked. The binary generated is securely transferred
to the provisioning service which copies it into accelerator
memory or uses it as a bitstream to conﬁgure an FPGA.

To program an accelerator, the provisioning service has
to create a trusted channel to establish a root of trust on the
accelerator. This entails the following assumptions about
such a platform:

• The platform provides an attestation service to assure the

client that

– All hardware on the platform is provided by a trusted
manufacturer. This ensures the platform is free from
any hardware trojans with accelerator bitstream hash
checked during secure boot.

– The platform is capable of deploying a trusted exe-
cution environment (TEE). This includes the ability
to isolate an application from the OS, hypervisor and
other privileged/non-privileged software on both the
CPU and main memory. Further, this TEE can be
extended to provide similar isolation guarantees for
the system memory used by the accelerator.

– The ML compiler framework and driver are sourced
from a trusted software provider and can be deployed
to run in a TEE.

Attestation protocols remain the same whether a ‘secure
processor’ implements a RISC CPU (like Aegis [59] or
Sanctum [23]) or an application-speciﬁc accelerator logic.
Attestation enables platform authentication (whose identity
is vouched for by a public-key certiﬁcate authority) on
which the user can execute a workload

• The host platform and the client have the ability to set up a
secure channel to communicate sensitive information
• Conﬁdential data stored in main memory can be protected

using encryption [4, 7, 9].

2

• Any key management systems that handle cryptographic
keys to either set up communication channels or provision
memory encryption for the accelerator are in the trusted
code base.

2.2 Baseline Accelerator Architecture

VTA [45] is a DAE [57] machine built on the TVM [19]
software stack to provide a domain-speciﬁc end-to-end so-
lution to neural network applications. It is built on a Xil-
inx Zynq-7000 series FPGA. Users write their model and
explicitly schedule the computation into a high-level CISC
representation. This is then converted into low-level accel-
erator instructions by a code-generator running in an FPGA
co-processor. The accelerator then uses these instructions
and data to perform inference in the accelerator programmed
in the FPGA.

3. VULNERABILITY ANALYSIS

We systematize the vulnerabilities that a machine-learning-
as-a-service(MLaaS) service may be subject to in Table 1.
Vulnerabilities (1-5) are addressed in our baseline secure
platform model. Vulnerabilities (6-11) correspond to the dig-
ital side channels arising within the accelerator that Sesame
addresses. In this section we take a closer look at these vulner-
abilities and their applicability under different threat model
variants relevant to Sesame.
Memory bandwidth snooping: Modern chips commonly
include high precision memory bandwidth performance coun-
ters for performance debugging purposes. These may also be
used by a cloud provider for ensuring quality of service(QoS)
across multiple tenants using the same platform. However
these performance counters can end up leaking side channel
information. Figure 1a shows the memory trafﬁc of all the
convolution layers of VGG16. Each of the layers utilizes
different amount of memory bandwidth based on tile size
and number of tiles. Figure 1b zooms in on layer 5 which
consists of 32 tiles. The bandwidth trace leaks the number of
tiles and the kernel size of the weight tensor. In Section 8.1,
we demonstrate that a classiﬁer can detect all the boundaries
based on change in trafﬁc shape and bandwidth. Upon suc-
cessful leakage of the structure of the model, the attacker
can craft custom inputs and devise an attack to determine
the weights [32, 47]. Interestingly, this attack can be effected
solely by observing bandwidth variations using performance
counters even when the data and address buses are protected.
To the best of our knowledge, our work is the ﬁrst to make
this observation and design Sesame to defend against such
observation channel attacks (Section 7.1).
Shared dependency queues: The load, compute, and store
units of the DAE accelerator are controlled through depen-
dency queues that are shared among units. An attacker can
corrupt control dependencies of the victim program – e.g., by
triggering execution units before data loading – and violate
read-after-write (RAW) dependencies. Sesame addresses this
through dependency queue partitioning (Section 7.2.1).
Shared access to scratchpads: Shared access to the scratch-
pad can help an attacker read out stale secrets belonging to the
victim by computing on a scratchpad region without loading
any data after a victim’s execution. Sesame uses partitioned
scratchpads, private data zeroization logic, and instruction

(a) Memory bandwidth of layers in vgg16.

(b) Read bandwidth of the 5th layer in vgg16.

Figure 1: Different layers in vgg16 network utilizes different memory
bandwidth, while bursts within each layer show number of tiles.

base/bound check to address this threat (Section 7.2.2).
Shared instruction queues: Shared instruction queues help
the attacker perform cyclic attacks like prime-and-probe by
inserting instructions between victim execution and creating
a covert channel to leak data. Sesame design defends this
threat with private instruction queues (Section 7.3).
Shared access to execution units: Shared instruction units
can lead to cross-tenant contention attacks in a multi-tenant
accelerator. Sesame schedules execution units among differ-
ent tenants based on their program phases.
Variable time GEMM/ALU unit: Since ML weights are
typically sparse, data driven optimizations leading to execu-
tion time variability leaking sensitive model/input data during
spatial sharing. Sesame generates constant time execution
instructions on private data operations (Section 7.4).

Vulnerabilities that require integrity protection (13) and
those that employ the address bus side channel (14) assume
the attacker to have physical access to the system. The
Sesame prototype excludes these vulnerabilities since these
are composable with our case-studies on conﬁdentiality vs.
on-chip attacks (by co-tenants and privileged software) and
are not required in physically secured data-centers. Recent
commercial products include encrypted DRAM without in-
tegrity protection [4, 7, 9] for such use-cases. Nevertheless,
solutions for integrity or address-buses [42, 55, 58, 60] can
be composed with the Sesame prototype by extending the
memory controller while our defenses address vulnerabilities
that arise within the accelerator.

3.1 Sesame threat model variants

Our threat model is deﬁned based on three parameters.
Sesame defenses are conﬁgured based on settings of these
three parameters, which are discussed below:

• Multi-Tenant execution modes: Cloud services deploy
large accelerators capable of hosting multiple ML models
simultaneously. We observe that there can be two modes
of sharing accelerator resources across multiple tenants.

3

050100150200250300End-to-end Trace of VGG16Memory Bandwidth (MBps)Layer 5Total 32 Tiles050100150200Layer 5 in VGG16Memory Bandwidth (MBps)Single TileNo.

Vulnerability

Exploit

1

2

3

4

5

6

7

8

9

10

11

12

13

14

Adversary has access to communication
channel between edge device and cloud

Unauthorized access by privileged pro-
cess on host CPU
Shared access to system memory carve-
out by all tenants on accelerator and their
host processes on CPU
Compiler runs on the host system and
has access to the model
Model execution termination channel ob-
servation
Adversary has access to reading system
memory
Adversary has ability to observe memory
bandwidth characteristics
Shared access to dependency queues in
accelerator
Shared access to instruction queues in
accelerator
Shared access to scratchpad in accelera-
tor
Shared access to execution units in accel-
erator
Variable time GEMM unit execution

Adversary has ability to modify system
memory
Adversary has ability to observe ad-
dresses access patterns on memory bus

Tampering of model/input in ﬂight
when being communicated to the ac-
celerator
Tampering of input/model in memory

Adversary deploys an accelerator task
to access victim’s model parameters /
input
Model privacy compromised

Model parameters may leaked due to
runtime variability
Secret data conﬁdentiality violated

Model topology and layer size leak

Loading corrupt data & performing
computation before data ready
Instruction queue occupation serves
as a covert channel
Reading raw secret data on-chip by
distrustful tenants
Snifﬁng execution output from the ex-
ecution unit pipeline
Model parameters / input data values
leak
Secret model weights & ﬁlter maps
can be tampered
Memory access pattern attacks [32]

Threat Model
PI
PM
(cid:88)
(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

×

×

×

(cid:88)

(cid:88)

(cid:88)

(cid:88)

×

Defences

Remote attestation of cloud system and estab-
lishing a secure channel using TLS

Application isolation using a TEE framework
like Aegis, Sanctum etc.
TEE provides memory isolation between dif-
ferent tenants.

Compiler is attested, made part of the trusted
compute base and runs in a TEE.
Scheduler allocates time slice increments at a
granularity identiﬁed by model provider.
Data encrypted by AES128 or QARMA128

Data independent distribution of memory traf-
ﬁc shape
Partitioned Queues

Partitioned Queues with base & bound check

Base & bound check for each process and
ZEROIZE after secret data becomes dead
Spatial partitioning of GEMM units with pri-
vate operand buffers
Disabling data driven optimizations through
GEMM.C instruction
Data MAC authentication [26, 54, 55]

Invisimem [12], PathORAM [58]

Table 1: Vulnerabilities, exploits and defence mechanisms. Vulnerability 1-5 are addressed in the baseline platform, 6-11 are Sesame contribution
and 12-14 can be composed with Sesame. PM = Private Model, PI = Private Input.

– Temporal Sharing: This corresponds to a scenario
where a single tenant rents entire accelerator for a
given duration. In this mode, the attack surface is
restricted to observation/contention channels outside
of the accelerator during job execution. After the
execution is done attacker can read out secrets by
extracting stale scratchpad data with use-after-free
attacks.

– Spatial Sharing: In this mode multiple mutually dis-
trusting model inference jobs are run concurrently in
a single accelerator. The attacker can observe/contend
for the memory bandwidth channel, shared scratch-
pad, dependency queues, shared buffer and execution
units.

• Private/secret model: This parameter speciﬁes whether
model conﬁdentiality is required and addresses scenarios
where the ML service provider deploys his service on a
third party cloud provider for economies of scale.

• Private/secret user input: This parameter speciﬁes whether

the of user input is conﬁdential.

The threat model column in Table 1 identiﬁes which vul-
nerabilities are relevant with respect to the later two of the
three threat model parameters described above. It may be
noted that vulnerability 8-12 apply to only spatial sharing
mode while all others are applicable to both spatial and tem-
poral sharing modes. Further in the threat model where both
model and input are private the vulnerability list would be
union of the individual lists.

Analog side channels like electromagnetic radiations and
information leakage caused by accelerator power and tem-
perature variations are orthogonal to our system. Denial-of-
Service (DoS) attacks by an attacker which either compro-
mises the accelerator management software or tampers with
the network connected between the CPU and the client or the
accelerator and the CPU is also outside of our threat model.
We also do not protect against DoS attacks of a malicious
kernel executed in the accelerator which leads to contention
in shared resources. The FPGA bitstream hash is checked
during co-processor secure boot and is assumed to be free of
hardware trojans. And runtime reconﬁguration is disabled.

4. SESAME OVERVIEW

This section describes the overall architecture of Sesame to
address new vulnerabilities (shaded blue in Table 1) that arise
when an accelerator is shared by mutually distrusting ten-
ants co-executing on untrusted infrastructure – i.e., to build a
multi-tenant accelerator enclave. These vulnerabilities can
be categorized under information leaks through observation-
only channels (such as memory trafﬁc or scratchpad access
control) and contention-driven (e.g., on-chip queues, scratch-
pad and execution units) channels – closing these with mini-
mal slowdown requires both compiler and hardware support.
In this section, we look at the overall secure accelerator ar-
chitecture and highlight hardware structure that need shaping
and partitioning.

To bootstrap Sesame, a user authenticates the accelerator
hardware and ﬁrmware using remote attestation protocols

4

unit performs the matrix arithmetic and GEMM computa-
tions that form the bulk of deep learning models – Sesame
requires both ALUs and GEMM units to support a constant-
time mode where the execution time is independent of data
value. The compute unit is connected to both load and store
units via dependency queues – Sesame modiﬁes these queues
to be conﬁgurable as private queues. All trafﬁc to memory is
via a Request unit – Sesame adds logic to shape the memory
trace to this unit. The request unit also has load, instruction,
and store queues that a Sesame user can conﬁgure as private
queues in spatial sharing mode.

5. PROGRAMMING MODEL:

5.1

Instruction-set extensions:

We introduce the following instructions to the baseline

architecture:

• LOAD_E <spad_range>,<dram_range>: Load secret data
from DRAM that doesn’t need trafﬁc shaping but still needs
to be decrypted.

• LOAD_S(E) <spad_range>,<dram_range>: Load data
from DRAM with the trafﬁc shaped read channel. Data
decryption needed for the E variant.

• GEMM_C out,<inp1>,<inp2>: This instruction disables

all data-driven optimization of the gemm unit.

• ALU_C <out>,<inp>: This instruction performs constant
time ALU instructions. It prevents leaks through relu and
clipping units. Input can be an immediate value as well.
• ZEROIZE <spad_range>: This instruction is used to ze-
roize a portion of scratchpad address range. This instruc-
tion adds dependency to other instructions that uses con-
ﬂicting regions of scratchpad.

• STORE_E <dram_range>,<spad_range>: Encrypt and

store output from to DRAM.

• STORE_S(E) <dram_range>,<spad_range>: Store data
through a shaped memory write channel. Encryption needed
by the E variant.

5.2 High-level code Pragmas:

Sesame supports application level annotation to identify se-
cret data structures and specify execution mode. The software
deﬁned threat model as mentioned in section 3.1 is propagated
down to generate instructions and accelerator conﬁgurations
through pragmas in high- level code. We describe below the
various pragmas that are used to specify this information.

• allocate_S: This pragma, as illustrated in Figure 3 is an en-
hanced version of the allocate pragma used in the baseline
which allocates scratchpad enables DMA transfer from
DRAM. The _S annotation identiﬁes secret data structures
for the following purposes:

– Data structures thus identiﬁed are stored in encrypted
format in the memory and code generation unit appro-
priately annotates load/store instructions.

– It directs the code generation unit to generate zeroize
instructions at scheduling boundaries to the scratchpad
locations that hold these data structures and computation
results generated from them.

Figure 2: Sesame design: a baseline DAE architecture extended with
private queue partitioning, shaping, and access control blocks.

and a public-key certiﬁcate authority [23]. Users can compile
their models on Sesame using host-side enclaves or remotely
in a machine not exposed to attackers – in both cases, a user
transfers a Sesame binary to the accelerator and triggers exe-
cution until completion or for a ﬁxed duration (if end-to-end
timing channel is within the threat model). The binary along
with the input data is loaded by the secure platform in DRAM
and conﬁguration registers speciﬁc to threat model require-
ments is programmed in accelerator registers.

Sesame hardware comprises of three main primitives. The
ﬁrst component – private queues – secures shared queues
that are used pervasively in hardware micro-architecture to
decouple or pipeline function units. Private queues enable
the accelerator software to partition shared queues across se-
curity domains and prevent information leaks through queue
contention. The second component – a trafﬁc shaper – closes
leaks through all signals that come out an enclave (i.e., obser-
vation channels) by dynamically shaping the attacker-visible
trace to look like a secret-independent distribution. The third
component – secure compilation passes – takes as input pro-
grammer annotations to mark parts of the code and data
as secret and generates accelerator instructions that mini-
mize overheads from obfuscation-related data movement and
cleanup (e.g., zeroing out scratchpads). In addition, Sesame
includes additional logic to partition on-chip scratchpad mem-
ory, implement bound-checks for scratchpad accesses, and
hardware to clear out scratchpad space with dead private
data. The key design principle is that private queues, trafﬁc
shapers, partitioned on-chip memory, and zeroization hard-
ware can be composed arbitrarily. E.g., for small enclaves,
shaping egress signals obviate the need to partition down-
stream queues, while large enclaves may be constructed by
partitioning everywhere on-chip and using shapers exclu-
sively for off-chip trafﬁc.

Figure 2 shows the components in Sesame hardware. The
baseline DAE architecture includes a load unit to load inputs
and weights from memory into the scratchpad – Sesame ex-
tends this with support to zero out memory and place bounds
checks on scratchpad accesses to prevent buffer overﬂow.
The store unit similarly writes back outputs and intermediate
values into memory and includes a scratchpad. The compute

5

Instruction QueueInstruction QueueTraﬃc ShaperDMA EngineInstruction QueueTenant Spad MapMetadata/ConﬁgInputsWeightsBase/Bound CheckerGEMMALU TileExecution Mode Ctlr.DecoderPartitioned Dep QueuePartitioned Dep QueueOutputAccumulatorBase/Bound CheckLoadComputeStoreScratchpadZeroizerScratchpadSchedulerRequest UnitSystem MMUSoC BoundaryZeroizerTenantacceleratorcodeTenantacceleratordataTenantacceleratorconﬁg DRAMSplit Load QueueLoad BuﬀersGEMMGEMMTileALU TileALU TileStore BuﬀersSplit Store QueueRead TraﬃcShapingPartitioningAccess ControlDAE blocksWrite TraﬃcFigure 3: Code generation example for various user-speciﬁed threat model invoking only the required secure hardware widgets

– Computational instructions operating on such structures

are annotated to operate in constant time mode.

– Lastly, for threat scenarios where the trafﬁc shaper has
been enabled, this pragma helps annotate the load/s-
tore instructions that need the bandwidth defenses of
the trafﬁc shaper.

• exec_mode: It informs the driver if the application is
sharing the accelerator with other tenants and need in-
accelerator resource partitioning.

• queue_depth: The driver requests the accelerator sched-
uler to reserve private queues for both instruction and de-
pendency between the DAE components. This prevents
contention attacks by an untrusted tenant co-executing in
the accelerator in spatial sharing mode.

• spad_size: The driver programs the value speciﬁed by
this pragma into tenant-private conﬁguration space. The
scheduler reserves regions of input, weight, accumulator
and output scratchpad based on the size speciﬁed by this
value.

• bandwidth: Memory-mapped registers corresponding to
the trafﬁc shaper are programmed with the constant band-
width speciﬁed by this pragma for both read and write
channels. Trafﬁc generated by LOAD_S or LOAD_SE in-
structions is shaped to this bandwidth speciﬁcation.

5.3 Code transformations

We envision the cloud provider providing entire accelera-
tor(temporal sharing) or part of accelerator(spatial sharing)
to each tenant. Sesame enables users to create enclaves that
are tailored to their threat model. Figure 3 shows how a
user speciﬁes (1) the execution environment to be temporally
shared (single tenant at a time) or spatially shared (by mul-
tiple tenants simultaneously), and (2) whether their model
and/or inputs are private(secret) or public. Sesame then han-
dles (3) accelerator compute execution and (4) tenant tear-
down, clearing out secrets after execution completes. Each of
these stages starts with (a) high level user program descrip-
tion, (b) instruction or conﬁguration metadata generation and
(c) hardware widgets (e.g., queues and shapers) to isolate
computation. Phase 1 creates the execution environment by
enabling private queues and resource requirement. Phase 2

enables user to deﬁne private/public variables to determine
the layer threat model, using which Sesame enables the hard-
ware privacy widgets. Phase 3 performs the constant-time
computation on partitioned execution unit for private vari-
ables and regular execution for public operands. A tiled loop
nest iterates over height,width and channel tiles. Convolu-
tion operation uses the GEMM units while the activation,
pooling,batch normalization uses the ALU units. Finally, the
result is stored back in phase 4 and the scratchpad state is
zeroized to relieve on-chip resources of private data.

6. COMPILER PASSES

Sesame design encompasses enhancing the entire hard-
ware/software stack for domain speciﬁc accelerators to sup-
port the different threat models described in Section 3.1. This
enables a user to get the best-possible performance within the
threat model isolation realm. In this section we discuss how
user speciﬁed security requirements ﬁlter through the various
compiler passes and translate to setting up the required se-
curity constructs on the accelerator either through metadata
for engaging hardware widgets or through instruction genera-
tion. Figure 4 illustrates the various phases involved in this
process which includes: (1) Perform graph transformation
with TVM compiler on ML front and parse security pragmas
and tag private variables information ﬂow tracking for threat
model speciﬁc transformations. (2) Auto-tuning phase per-
form tile-size exploration. (3) Trafﬁc shaping and zeroize
optimization on optimized tiling schedule. (4) Finally, the
metadata after conﬁg validation and code generation phase
ships the binary,data and conﬁg to the driver for deployment.
We describe how speciﬁc compiler phases are adapted to
the work on additional security information speciﬁed above:

• Autotuning tiles: We use AutoTVM [20] framework to
perform optimum tile search using threat model and re-
source constraints before accelerator deployment. Tile
optimization chooses the best conﬁguration for each layer
for the entire model and ensures runtime tenant isolation.
• Resource bill of materials (BOM): Application resource
requirement including memory bandwidth and execution
mode is partially extracted from high-level code. The
scratchpad, private queue and execution tile is extracted

6

Execution Mode DeclarationComputePublic/private variable allocationTeardown#pragma set_mode  spatial#pragma set_queue <queue_depth>#pragma set_spad   <spad_size>#pragma set_bw      <bw>#pragma set_mode  temporalOR#write_conﬁg exec_mode#write_conﬁg queue_depth#write_conﬁg spad_size#write_conﬁg bandwidth- Private Queue- Bandwidth limit- Private alu/gemm- Private scratchpad- Base/bound CheckSpatialExecutionTemporalExecution- Single tenantallocate inpallocate wgtallocate_s inpallocate wgtallocate inpallocate_s wgtallocate_s inpallocate_s wgtLOAD inpLOAD wgtLOAD_E inpLOAD wgtLOAD_S   inpLOAD_SE wgtLOAD_SE inpLOAD_SE wgtPublic InputPublic ModelPrivate InputPublic ModelPublic InputPrivate ModelPrivate InputPrivate Modelconv2D(acc,inp,wgt)Relu(acc,acc)Public InputPublic ModelGEMM acc,inp,wgtMAX acc,acc,0GEMM_C acc,inp,wgtMAX_C acc,acc,0Private Inputand/orPrivate Modelallocate outout=accallocate_s outout=accallocate_s outout=accallocate_s outout=accSTORE outSTORE_E outZEROIZE inpZEROIZE accZEROIZE outSTORE_S outZEROIZE wgtZEROIZE accZEROIZE outSTORE_SE outZEROIZE inpZEROIZE wgtZEROIZE accZEROIZE outPublic InputPublic ModelPrivate InputPublic ModelPublic InputPrivate ModelPrivate InputPrivate ModelRegularloadEncrypted inp loadShaped  memory readShaped  memory readEncrypted  model readEncrypted  model readEncrypted  input readData-dependant time optimizationsConstant time execution modeRegularstoreEncrypted storeZeroize private allocZeroize private allocShape write traﬃcEncrypted storeZeroize private allocShape write traﬃc(1)(2)(3)(4)High-level codeCode generationHW widget(a)(b)(c)Execution PhaseFigure 4: Sesame compiler passes play a key role in state-space explo-
ration shaping and zeroization. Security passes are tightly coupled with
user level threat model deﬁnitions

from the auto-tuning phase. This compiler pass eradicates
illegal resource allocations limiting attackers to create re-
source contention and runtime errors.

• Information ﬂow tracking: Any intermediate results gen-
erated from the sensitive data structures(allocate_S vari-
ables) are marked as private. Scratchpad allocations of
such variables are zeroized before de-allocation. This pass
also ﬂags warning to the user if a particular secret data is
mistakenly marked as public at layer boundaries. Explicit
dataﬂow tracking helps identify kernel schedules and vari-
able liveness durations for precise allocation/zeroization.
• Zeroize optimization: Sesame compiler takes advantage
of explicit kernel scheduling to reuse private scratchpad
regions across different tiles without zeroizing it once at
the layer boundary. This greatly reduces the binary size
and scratchpad zero writes as shown in Figure 8.

• Memory trafﬁc shaper optimizations: The memory traf-
ﬁc shaping is a software-hardware co-design. This pass is
for protecting private ML models.
Burst size equalization with padding: The input and
weight tensors are split into multiple equal-sized bursts.
The tensor edges are padded to make it a multiple of burst
size. Data is laid out such that no burst crosses a DRAM
row-buffer boundary. The padding parameters are embed-
ded in Sesame load instructions similar to VTA. Each burst
is converted to AXI INCR transaction by the DMA engine.
Memory bank conﬂict prevention: Certain tiling conﬁg-
urations of input and weight tensors can cause bank con-
ﬂicts which is reported in autotuning phase by the DMA
engine. Since tiling on channel, height, and width axes
is unique for each convolution layer, data layout trans-
formation is done to ensure streaming data load on the
inner loops and any bank conﬂict loads are rearranged to a
different bank.

• Code generation: Appropriate variants of LOAD/STORE
instructions are generated for DMA transfer between mem-
ory and scratchpad. Compute instructions like GEMM/ALU
instructions are annotated for constant operation to pro-
tect sensitive data structures. ZEROIZE instructions are
generated to leave zero trace after private data execution.
• Conﬁguration generation: Execution conﬁguration is
generated and tenant-private memory mapped registers are
written to invoke threat-model speciﬁc isolation hardware
widgets.

7.

IMPLEMENTATION

Now, we discuss how the proof-of-concept implementation
of memory trafﬁc shaper, the partitioning of various queues,
and the hardware scheduler is implemented to support multi-
tenant enclaves.

7.1 Memory Trafﬁc Shaper

The memory trafﬁc shaper ensures secret-independent data
transfers from the DRAM to accelerator for a secret model
application. It masks secret-dependent read/write bandwidth
variations with a shaped trace with software programmed
bandwidth during the lifetime of secret data computation and
transfer.
Compiler assumptions: The load/store instructions are
already a multiple of burst size and the data load by the driver
ensures no bank conﬂict which are resolved in compiler as
explained in section 6.
Trafﬁc shaper micro-architecture: Figure 5 shows the hard-
ware components of the trafﬁc shaper. A real transaction
queue is ﬁlled with incoming real requests for each tenants.
In order to provide model-size-independent trace, the dma en-
gine always produces ﬁxed-sized transaction bursts. A single
load instruction is split into multiple equal sized bursts by the
DMA engine and each burst is sent on timer_expiry determin-
ing the overall bandwidth. Moreover, to hide the computation
and data dependency at runtime, the trafﬁc generator has
a fake transaction generator to produce transactions to free
memory banks. A real transaction ﬁfo full signal prevents the
load module from generating further memory requests. Same
hardware logic is present for write channel.

The trafﬁc shaper has tenant private conﬁguration registers.
Shaper_en of each tenant(identiﬁed by tenant_id) enables the
fake transaction generator and limits the transaction gener-
ator to produce constant sized transactions. The bandwidth
register programs the timer for each tenant to ensure band-
width QoS and the addr_range enables the fake transaction
generator to generate requests within the memory-mapped
address range to prevent access-control violations.

Figure 5: Memory Trafﬁc Shaper micro-architecture

7.2 Partitioning Resources

In-accelerator partitioning for the following resources is

done for spatial multi-tenancy to deter on-chip attacks:

7.2.1 Dependency queues

The DAE dependency queues are partitioned four ways

7

Graph transformationAutotuningAccelerator MeasurementPragma parsing(conﬁg)•Load/Store annotation•Constant time execution•Zeroize insertionAccelerator RuntimeRuntime DriverExecConﬁgLayer 1Layer 3Layer 2…High-level CodeInference modelPragma parsing(Threat Model) Tensor PaddingConﬁg RegistersDeployBank conﬂict protectionOptimized Tiling ScheduleTraﬃc ShaperZeroize optimizationConﬁg validationInformation ﬂow trackingLayer kCode GenerationConﬁg generationState Space ExplorationLoadModuleLoad 1aLoad 1bLoad 1cLoad 2aLoad 2b…}StallQueueFake Transaction Generatorshaper_enTimertimer_expireemptyDRAMTenant ATenant BTenant CConﬁg Registersmulti-tenantshaper_entenant_idbandwidthaddr_rangeDriverLoad Tenant data/codewith cma driverInput/outputWeightCommandConﬁgBank Conﬂict CheckerBurst SplitterDMA Enginein our implementation to enable multiple tenants. This split
prevents a tenant to corrupt/contend the control dependency
with a co-executing tenant. Tenant ID is used to redirect
queue read/writes to the tenant-private one. The queue depth
comes from conﬁguration register and is validated during
resource BOM compiler phase.

7.2.2

Scratchpad

Sesame has four scratchpads – Weight, Accumulator, Input,
and Output – with capacities listed in Table 2. Each scratch-
pad is split into 16kB regions whose tenant ownership is
maintained in a scheduler scratchmap data structure. Scratch-
pad address base and bound logic checks tenant ownership
from scratchmap before each access keeping tenants isolated.
Zeroizer logic clears private data and tenant ownership at
scratchpad region granularity during teardown.

7.2.3 Execution units

The GEMM and ALU execution units are spatially parti-
tioned into four 8x8 units with private load/store buffers to
eradicate execution unit contention in the multi-tenant sce-
nario. This utility is useful for smaller kernels co-executing
in large accelerators like TPU [36] and cloud accelerator
deployment of Sesame.

7.3 Scheduler

Sesame has a hardware scheduler block consisting of the
instruction queue and data structures keeping track of each
tenant’s resource occupancy and guarantee runtime computa-
tional non-interference. It houses tenant maps for dependency
queues, scratchpad, execution tile and instruction queue pro-
viding complete on-chip separation between multiple tenants.
It also communicates with the driver to launch new tenant and
sets conﬁguration register notifying application teardown.

7.4 Constant time execution units

Sesame ISA supports constant-time execution instructions
(e.g. gemm_c,alu_c) but our PoC implementation only in-
cludes 8-bit DSP implementation of execution units.The per-
formance headroom for such optimizations is limited for
quantized ML inference.

7.5 Private data encryption

To estimate the performance overhead of encryption, Sesame
PoC implementation emulates QARMA128 with a 10ns de-
lay and AES128 [3] with a 20ns delay for every 128-bit
private data access. These delay numbers are taken from
prior work [14].

8. EVALUATION

Sesame proof-of-concept(PoC) implementation is built by
enhancing the VTA [45] hardware baseline with a constant
trafﬁc shaper to mask the memory bus trafﬁc, partitioned
on-chip accelerator resources like dependency queues and
scratchpads for tenant isolation, a zeroization module to clear
private data, an address base/bound logic for access checks
and a hardware scheduler for runtime tenant isolation man-
agement. The prototype runs on a Xilinx Pynq-Z1 board with
a dual-core arm CortexA9 co-processor and an accelerator
prototype in FPGA fabric with speciﬁcations listed in table 2.

Component

Processor
DRAM
FPGA frequency
Accelerator
Weight Scratchpad
Input Scratchpad
Output Scratchpad
Acc Scratchpad
GEMM units
Memory bandwidth

Speciﬁcation

Dual arm CortexA9 @667MHz
512MB DDR3 @ 533MHz
Zynq 7020 @ 100MHz

temporal

spatial

2MB
256KB
256KB
512KB
256
400MB/s

512KB
64KB
64KB
128KB
64
100MB/s

Table 2: System Speciﬁcations with per-tenant temporal and spatial
sharing resource allocation

To simplify the implementation, the resource BOM which
includes trafﬁc shaper bandwidth, datasize of each layer etc.
is extracted manually after compiler autotuning phase and fed
to the runtime driver as command line parameters. The driver
bootstraps the accelerator by creating a conﬁg,code and data
memory-mapped address space as shown in Figure 2. The
conﬁg address space houses live resource availability status
and tenant-private metadata regions for conﬁguration load-
ing. The proof-of-concept implementation supports upto four
tenants. The accelerator driver begins by querying resource
availability registers and schedules a new tenant if adequate
resources are available to prevent over-subscription and cre-
ates a tenant ID. The driver then loads instructions into the
tenant-private instruction region and input/model values into
the data region. After that the driver waits for the results by
polling a conﬁguration register.

In this section, we evaluate the hardware prototype by run-
ning imagenet inference of six trained deep learning networks
taken from MXNET modelzoo [11]. The models are quan-
tized to support 8-bit operation. The image classiﬁcation
models chosen are VGG11, VGG16, AlexNet, ResNet18,
ResNet34, and ResNet50. We ﬁrst assess the security pro-
vided by trafﬁc shaper against memory bandwidth side chan-
nel attacks, followed by instruction binary size and ﬁnally
a performance comparison for all threat models for spatial
and temporal execution modes. The four bars of each plot
is for (1) Public Input Public Model; (2) Private Input Pub-
lic Model;(3) Public Input Private Model; (4) Private Input
Private Model.

8.1 Security Evaluation

8.1.1 Memory trafﬁc shaper

In this section we analyze the effectiveness of Sesame
with the trafﬁc shaping primitive discussed in Section 7.1 to
protect against a memory bandwidth side channel attack from
section 3. To show that bandwidth variations is a problem and
validate the trafﬁc shaper, a bandwidth measurement widget is
synthesized along with the FPGA bitstream. The bandwidth
measurement widget counts the AXI read and write channel
data bytes transferred to report memory bandwidth. Figure 6
shows the memory trafﬁc pattern before and after shaping
collected for the six workloads. Both read/write bandwidth
in unshaped trace is leaky and provides kernel size and layer
boundary information. The ﬁgure shows a single run but each

8

AlexNet VGG11 VGG16 ResNet18 ResNet34 ResNet50 Overall

Execution
time only

SVM w/
(w/o) DWT

MLP w/
(w/o) DWT

CNN w/
(w/o) DWT

1

1

1

1

1

1

1

1

0.958

0.896

0.851

0.824

0.826

1

1

1

1

1

1

1

0.811

0.927

1
(0.986)

1

0.868
(0.849)

0.877
(0.830)

0.949
(0.934)

0.953
(0.934)

Table 4: Layer type classiﬁcation accuracy using unshaped trafﬁc as-
suming perfect layer boundary detection. The ﬁrst row shows the ac-
curacy only using the termination timing of the layers for classiﬁcation.
It serves as a baseline accuracy as long as attacker can identify the layer
boundaries. 2-4th rows show accuracy of 3 classiﬁers using bandwidth
trace with and without frequency domain signal computed from dis-
crete wavelet transform (DWT).

shaper in place, the classiﬁer can detect easy boundaries with
100% precision for AlexNet, VGGs and ResNet18. Note
that for ResNet models, the residual layers are very short,
which makes the boundaries in between them hard to detect
even without trafﬁc shaper. With the trafﬁc shaper in place,
the precision drops down to as low as 0.01% for VGG16.
NA in the table indicates that our modeled attacker fails to
identify every layer boundary in three ResNet models, while
triggering over 10000× false positives (precision < 0.0001).
Layer Type Classiﬁcation. Compared to one feature vec-
tor per kernel in Deepsniffer [31], ﬁne-grained observations
enable attackers to model each layer as a time-series of band-
width information. In addition to memory bandwidth related
features used in DeepSniffer, we include frequency domain
signals(DWT) to capture IFM tile load/store memory band-
width signatures. Our training data constitutes of bandwidth
traces from different potential layer conﬁgurations. we test
victim memory trafﬁc time-series using three classiﬁers: Sup-
port Vector Machine (SVM), Multilayer Perceptron (MLP),
and Convolutional Neural Network (CNN), with and without
frequency domain signals. Similar to [31], SVM and MLP
use one feature vector per layer, while CNN uses a sequence
of feature vectors for classiﬁcation, enabled by ﬁne-grained
observation. Table 4 shows the layer-type classiﬁcation accu-
racy with unshaped trafﬁc data after the layer boundaries are
identiﬁed. The ﬁrst row shows classiﬁcation accuracy merely
using the execution length of each layer. This is a baseline
accuracy for any attacker with the knowledge of the layer
boundaries (execution timing of layers). The 2-4th rows show
accuracy of the three evaluated layer-type classiﬁers. From
execution-time based classiﬁer to bandwidth-based classi-
ﬁers, the accuracy jumps from 84% to 93% on average. From
SVM to CNN, accuracy increases with increasing classiﬁer
complexity. In addition, including frequency domain signals
improves the accuracy as different tile size conﬁgurations
result in different compute/IO ratio.

However, after applying trafﬁc shaping, the classiﬁers are
not able to classify features among different layer types. The
resulting accuracyis similar to the baseline attacker knowing
only the layer termination times. But as the layer boundaries
for the shaped trace is undetectable (Table 3), we conclude
that Sesame seals the memory read/write bandwidth channel.

8.1.2 Partitioned logic

The partitioning and access control hardware is validated

Figure 6: Comparison between real and shaped memory trafﬁc. Top
ﬁgure shows the real read/write trafﬁc of each network while the bot-
tom one plots the shaped trafﬁc.

AlexNet
all
4
1

easy
3
1

VGG11
all
6
1

easy
5
1

VGG16

easy
8
1

all
11
1

ResNet18
all
easy
23
22
0.64
0.69

ResNet34
all
easy
36
24
0.72
0.66

ResNet50
all
easy
52
50
0.33
0.33

precision

recall
precision

0.75
0.03

1
0.03

0.83
0.01

1
0.01

0.73
0.0027

1

1
0.00011 NA NA NA NA NA NA

0.96

0.96

0.67

1

1

recall

0.75

1

0.83

1

0.73

1

NA NA NA NA NA NA

d
e
p
a
h
s
n
U

d
e
p
a
h
S

Table 3: Precision and recall when identifying layer boundaries for
each network. The second row in this table lists the number of the
boundaries between two consecutive layers that are of different types
(easy) and the total number of layer boundaries (all). The precision and
recall are calculated when the attacker detects all boundaries while in-
troducing false positives (if any). NA indicates that the attacker fails to
identify the boundaries while introducing over 10000× false positives.

benchmark is run ﬁfty times and the median is constant for
every sample. Nevertheless, a two stage classiﬁer is designed
to attack both the unshaped and the shaped trace as follows:
Layer Boundary Detector: Prior arts [31, 32] demon-
strated that the read-after-write (RAW) pattern on the address
trace reveals the layer boundaries accurately but bandwidth
variation on read/write channel is used to detect layer bound-
aries. We ﬁrst use the RAW dependency pattern to identify
potential boundaries (the end of each write transaction) on un-
shaped trace. We then compare the memory bandwidth within
a ﬁxed time window before and after the potential boundary.
Statistics like total read/write data, median and peak band-
width, standard deviation as well as frequency domain signals
computed using discrete wavelet transform (DWT) are used.
For shaped trace, since write bus is constantly exercised, the
RAW activity is invisible to the attacker. Instead, we model
an attacker who ofﬂine proﬁles termination timing of all pos-
sible layer conﬁgurations with termination timing protection
turned-off. At run-time, the attacker use a combination of
termination timings to enumerate potential layer boundary
candidates. This helps constrain the maximum false positives.
Similarly, at a boundary candidate, attacker compares the
memory bandwidth channel before and after the candidate
using the same statistics. The different thresholds for this de-
termination allows the attacker to trade-off the aggressiveness
in boundary identiﬁcation vs. triggering false positives.

Table 3 shows the precision and recall numbers for both
unshaped and shaped memory trafﬁc on our evaluation model
suite. The second row in the table shows the total number
of layer boundaries as well as the number of easily identi-
ﬁable boundaries (adjacent layers utilize different memory
bandwidth) from the unshaped trafﬁc. Without the trafﬁc

9

05001000Time in ms050100150200Bandwidth in MB/svgg1101000Time in msvgg160250500Time in msalexnet0200400Time in msresnet180250500Time in msresnet3405001000Time in msresnet5005001000Time in ms050100150200Bandwidth in MB/s010002000Time in ms0500Time in ms0200400Time in ms0500Time in ms05001000Time in msRead trafficWrite trafficﬁrst at RTL level by system verilog tests. Runtime validation
is done by changing a tenant binary in after code generation
to access an unauthorized scratchpad location. The access
was blocked on both read/write channel in BRAM.Moreover,
scratchpad read after tenant teardown returned zero value.

8.2 Compiler Evaluation

8.2.1 Tile optimization performance

Figure 7 illustrates the variability of performance over-
head for the threat model where both input and model are
private. All of the accelerator resource is used for temporal
sharing and 4 tenants equally share accelerator resource in
spatial sharing. Each benchmark is run with 800 different tile
combinations across layers with overhead comparison with
baseline VTA. Tile optimization helps maximum available
resource utilization and the best tile-conﬁgurations change
with resource bom. It results in better utilization of the trafﬁc
shaper bandwidth for private model.

Figure 8: Dynamic instruction count and number of zeroized BRAM
bytes normalized wrt zeroizing every private data for different threat
models

model is public. while a private model needs a read/write traf-
ﬁc shaper and uses load_se/store_se instructions. When
the model is private, public input may be stored unencrypted
in the DRAM and uses load_s as its trafﬁc needs to be
shaped to hide access patterns. When both model and input
are private all read accesses are performed using the load_se
instructions. Internal scratchpad locations holding secret data
are cleared with zeroize instructions which varies based on
the threat model. Each zeroize instruction clears different
amount of scratchpad regions. Even though the number of
zeroize instruction is higher in private input, the latency
is higher in private model as zeroize clears a larger model
scratchpad region.

Figure 7: Performance overhead variation for design space exploration
of tile size conﬁguration

8.2.2 Zeroize Optimization

Figure 8 shows the reduction in the size of scratchpad re-
gions that need to be zeroized over a naive case of zeroizing
all private data held by scratchpad. Kernel scheduling helps
re-utilize private scratchpad regions across multiple tiles that
share the same security level. Only zeroizing regions be-
fore loading public data reduces dynamic zeroize instruction
count by 14% to 18% based on the threat model. Since each
instruction clears variable sized BRAM regions, the right plot
shows the number of BRAM bytes zeroized. There is a reduc-
tion between 8.5% and 16.7% across different threat models.
There is higher reduction in weight secret threat model for
vgg11,vgg16 and alexnet due to larger kernel sizes as com-
pared to the resnets. The private model(bar 2) shows higher
reduction than private input(bar 1) and the private model and
secret threat model(bar 3) plot is closer to the weight reduc-
tion percentage due to higher number of channels in model
weight than the IFM/OFM.

8.2.3 Code Generation Instruction Mix

Figure 9 shows the normalized instruction mix for six
benchmarks for different threat models. Increase in binary
size is solely due to addition of zeroize instructions. Load/-
store instruction variants change with threat model. Load_e
instructions are generated for loading private input when

10

Figure 9: Instruction mix for different threat models

8.3 Performance/FPGA Utilization Results

8.3.1 FPGA Utilization Overhead

Table 5 lists the percentage of FPGA resource used for each
design component. The scheduler uses distributed RAMs to
store tenant ownership of scratchpad partitions and private
queues. The additional conﬁguration registers lead to in-
crease in register and LUT logic. Memory trafﬁc shaper uses
BRAM for tenant-private load/store queues. Distributed ram
is used in DMA engine to partition loads and storing pending
transaction bank information. Glue logic and timer accounts
for the increase in register/LUT. The same queue size in base-
line is split into multiple sections and access control glue
logic accounts for area increase in partitioned resources.

vgg11vgg16alexnetresnet18resnet34resnet500.00.20.40.60.81.0Normalized instruction countLOADLOAD_ELOAD_SLOAD_SEGEMMGEMM_CALUALU_CSTORESTORE_ESTORE_SSTORE_SEZEROIZEComponent Baseline

Scheduler

Logic
LUT

46.97%

Register

19.5%

BRAM

92.14%

Distributed
RAM

11.51%

DSP

100%

9.57%
(1.2x)
11.26%
(1.6x)
1.6%
(1.02x)
10.27%
(1.9x)
0%
(1x)

Memory
Trafﬁc
Shaper
2.56%
(1.05x)
6.24%
(1.3x)
3.22%
(1.04x)
3.3%
(1.29x)
0%
(1x)

Partitioned
Resources

SESAME
Prototype

2.4%
(1.05x)
3.6%
(1.2x)
0%
(0)
0%
(0)
0%
(1x)

61.5%
(1.3x)
40.76%
(2.1x)
96.96%
(1.05x)
23.08%
(2.178x)
100%
(1x)

Table 5: FPGA Component Utilization

8.3.2 Performance Overhead

In this section we study the performance overheads of
providing security against the various threat models in both
temporal and spatial sharing modes v/s a non-secure baseline
for which both model and input are set to be public. Each
of the other three threat models has two bars: one for mem-
ory encryption defense with QARMA-128 block cipher and
the other with AES-128. Private input setting adds zeroize
instruction overhead on the input, accumulator and output
scratchpad with input padding. Private model further adds
overhead due to memory trafﬁc shaper with bandwidth of
400 MB/s, zeroization of weight scratchpad. Figure 10a illus-
trates that for temporal sharing mode performance overheads
range from 3.77% to 25.81% with QARMA128 and 4.92%
to 34.87% with AES128 encryption.

For spatial sharing (Figure 10b), four tenants equally share
all accelerator resources including partitioned scratchpad, pri-
vate queues, execution units and memory trafﬁc bandwidth.
In other words, each inference task is given one fourth the
resources allocated in temporal sharing mode as shown in
Table 2. Thus, with spatial sharing, because the non secure
baseline is already resource constrained, the relative over-
heads for providing security are slightly lower. The overhead
ranges from 3.31% to 12.78% with QARMA128 and 4.86%
to 16.73% with AES128 encryption.The spatial sharing secu-
rity overhead is less for models with larger layers like alexnet
and vgg because limited memory bandwidth in the baseline
is primary bottleneck.

9. RELATED WORK

ML inference accelerators [29, 45, 46, 49, 52, 56] extract
performance using specialized hardware like DAE [57] and
systolic array designs [40] with domain-speciﬁc optimiza-
tions [30]. On the other hand, secure TEEs focus on general-
purpose cores [6, 10, 23, 38, 48] and recently GPUs [33, 65]
and FPGAs [70] (speciﬁcally, on securing the PCIe inter-
face between CPU and GPUs/FPGAs). Sesame is com-
plementary and proposes software-deﬁned enclaves to con-
struct accelerator-TEEs that are tightly coupled on chip with
general-purpose cores.

While partitioning [23, 37, 67] and shaping [68, 69] are
generic strategies that have been extensively studied from
networking to CPU designs, Sesame turns them into hard-
ware/RTL modules – private queues and shapers – to be
synthesized based on the threat model and tuned based on

(a) Temporal Sharing

(b) Spatial Sharing

Figure 10: Performance Overhead of Two Multi-Tenant Scenarios.
Temporal sharing where multiple tenants share the accelerator in a
time-multiplexed manner. Spatial sharing where resources are evenly
shared among four tenants. Overheads are compared to a non-secure
public input public model scenario. Encryption overhead from either
QARMA-128 or AES-128 is added on top of each threat model.

the program phase information. As a result, Sesame’s shaper
unit is simpler than memory-controller shapers [68] because
it relies on software to learn trafﬁc distribution and conﬁgure
it. Sesame is also more secure than Camouﬂage [68] by not
assuming that an attacker is limited to observing only coarse-
grained signals – an on-chip co-tenant or privileged software
can observe Sesame enclave outputs at arbitrary granularity.
A software conﬁgurable Sesame framework is compos-
able with other physical protection units necessary for TEEs
like encryption/integrity blocks [26] and memory access
pattern conﬁdentiality using address encryption [13, 15] or
ORAM [42, 58]. These memory protection schemes can be
exposed to software by extending the Sesame ISA [41]. The
compiler’s auto-tuning framework can be similarly extended
to extract performance by performing state-space exploration
to (e.g.,) take advantage of streaming patterns for integrity
checks.Sesame enables prior work that uses CPU-based TEEs
conﬁdential-ML [34, 35, 61] to use accelerator-TEEs instead.
Beyond hardware-based TEEs, cryptographic approaches
towards privacy in machine learning have also been widely
studied. Homomorphic encryption(HE) and garbled circuits
(GC) based research such as Cryptonets [25], Securenets [21],
SecureML [44], and xonn [53] provide conﬁdentiality guar-
antees for user data without trusting server-side hardware,
but are orders of magnitude slower than non-secure execu-
tion and do not hide the model. Finally, we observe that
protecting against adversarial input attacks (DNNGuard [66])
is orthogonal to our design and threat model.

11

vgg11vgg16alexnetresnet18resnet34resnet50geomean01020304050Performance Overhead in %Private Input Public ModelPublic Input Private ModelPrivate Input Private ModelQARMA 128 encryptionAES-128 encryptionvgg11vgg16alexnetresnet18resnet34resnet50geomean01020304050Performance Overhead in %Private Input Public ModelPublic Input Private ModelPrivate Input Private ModelQARMA 128 encryptionAES-128 encryption10. CONCLUSION

Sesame brings conﬁdential computing to accelerators and
introduces software-deﬁned enclaves – where the slowdown
scales gracefully with the threat model and program phase
regularity. The key innovation is to deﬁne new hardware
modules that replace ubiquitous queues with private queues
and adds trafﬁc-shapers at enclave egress – together, these
modules can form a secure data-plane for accelerators beyond
DAE. While extending Sesame workloads to secure graph
programs are near term tasks, bringing these ideas back into
general-purpose CPUs and incorporating these modules into
hardware veriﬁcation tools would be the longer term wins.
We hope to spur further research into secure and performant
enclaves by sharing our code and benchmark suite with the
research community.

REFERENCES
[1] https://gdpr.eu.

[2] https://oag.ca.gov/privacy/ccpa.

[3] “Aes.” [Online]. Available:

https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.197.pdf

[4] “Amd memory encryption.” [Online]. Available:

https://developer.amd.com/wordpress/media/2013/12/AMD_
Memory_Encryption_Whitepaper_v7-Public.pdf

[5] “Arm ethos-n series processors,” https://developer.arm.com/ip-

products/processors/machine-learning/arm-ethos-n.

[6] “Arm trustzone,”

https://developer.arm.com/ip-products/security-ip/trustzone.

[7] “Aws graviton processor.” [Online]. Available:

https://aws.amazon.com/ec2/graviton/

[8] “Conﬁdential computing consortium,”
https://conﬁdentialcomputing.io/.

[9] “Intel memory encryption technologies speciﬁcation.” [Online].

Available:
https://software.intel.com/sites/default/ﬁles/managed/a5/16/Multi-
Key-Total-Memory-Encryption-Spec.pdf

[10] “Intel software guard extensions,”

https://software.intel.com/en-us/sgx/details.

[11] “Mxnet gluon model zoo.” [Online]. Available:

https://mxnet.incubator.apache.org/api/python/gluon/model_zoo.html

[12] S. Aga and S. Narayanasamy, “Invisimem: Smart memory defenses

for memory bus side channel,” in Proceedings of the 44th Annual
International Symposium on Computer Architecture, ser. ISCA ’17.
ACM, 2017. [Online]. Available:
http://doi.acm.org/10.1145/3079856.3080232

[13] S. Aga and S. Narayanasamy, “InvisiMem: Smart Memory Defenses

for Memory Bus Side Channel.” ACM Press, 2017, pp. 94–106.

[14] R. Avanzi, S. Banik, O. Dunkelman, H. Montaner, P. Ramrakhyani,

F. Regazzoni, and A. Sandberg, “Protecting memory contents on arm
cores,” in Ninth Real World Crypto Symposium, ser. RWC ’20, 2020.
[Online]. Available: https://rwc.iacr.org/2020/slides/Avanzi.pdf

[15] A. Awad, Y. Wang, D. Shands, and Y. Solihin, “ObfusMem: A

Low-Overhead Access Obfuscation for Trusted Memories.” ACM
Press, 2017, pp. 107–119.

[16] F. Brasser, D. Gens, P. Jauernig, A.-R. Sadeghi, and E. Stapf,

“Sanctuary: Arming trustzone with user-space enclaves.” in NDSS,
2019.

[17] I. Bratt and J. Brothers, “Arm’s ﬁrst generation ml processor,” in 30th
IEEE Hot Chips Symposium (HCS), Cupertino, CA, USA, August
19-21, 2018.

IEEE, 2018.

[18] C. Canella, J. Van Bulck, M. Schwarz, M. Lipp, B. Von Berg, P. Ortner,
F. Piessens, D. Evtyushkin, and D. Gruss, “A systematic evaluation of
transient execution attacks and defenses,” in 28th {USENIX} Security
Symposium ({USENIX} Security 19), 2019, pp. 249–266.

[19] T. Chen, T. Moreau, Z. Jiang, H. Shen, E. Q. Yan, L. Wang, Y. Hu,
L. Ceze, C. Guestrin, and A. Krishnamurthy, “Tvm: end-to-end
optimization stack for deep learning,” arXiv preprint
arXiv:1802.04799, pp. 1–15, 2018.

[20] T. Chen, L. Zheng, E. Yan, Z. Jiang, T. Moreau, L. Ceze, C. Guestrin,

and A. Krishnamurthy, “Learning to optimize tensor programs,” in
Advances in Neural Information Processing Systems, 2018, pp.
3389–3400.

[21] X. Chen, J. Ji, L. Yu, C. Luo, and P. Li, “Securenets: Secure inference
of deep neural networks on an untrusted cloud,” in Proceedings of The
10th Asian Conference on Machine Learning, 2018, pp. 646–661.

[22] V. Costan and S. Devadas, “Intel sgx explained.” IACR Cryptology

ePrint Archive, vol. 2016, no. 086, pp. 1–118, 2016.

[23] V. Costan, I. Lebedev, and S. Devadas, “Sanctum: Minimal hardware
extensions for strong software isolation,” in 25th {USENIX} Security
Symposium ({USENIX} Security 16), 2016, pp. 857–874.

[24] C. W. Fletcher, M. v. Dijk, and S. Devadas, “A secure processor

architecture for encrypted computation on untrusted programs,” in
Proceedings of the seventh ACM workshop on Scalable trusted
computing, 2012, pp. 3–8.

[25] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter, M. Naehrig, and
J. Wernsing, “Cryptonets: Applying neural networks to encrypted data
with high throughput and accuracy,” in International Conference on
Machine Learning, 2016, pp. 201–210.

[26] S. Gueron, “Memory encryption for general-purpose processors,”
IEEE Security & Privacy, vol. 14, no. 6, pp. 54–62, 2016.

[27] C.-Y. Gui, L. Zheng, B. He, C. Liu, X.-Y. Chen, X.-F. Liao, and H. Jin,

“A survey on graph processing accelerators: Challenges and
opportunities,” Journal of Computer Science and Technology, vol. 34,
no. 2, pp. 339–371, 2019.

[28] T. J. Ham, L. Wu, N. Sundaram, N. Satish, and M. Martonosi,

“Graphicionado: A high-performance and energy-efﬁcient accelerator
for graph analytics,” in 2016 49th Annual IEEE/ACM International
Symposium on Microarchitecture (MICRO).

IEEE, 2016, pp. 1–13.

[29] S. Han, X. Liu, H. Mao, J. Pu, A. Pedram, M. A. Horowitz, and W. J.
Dally, “Eie: efﬁcient inference engine on compressed deep neural
network,” ACM SIGARCH Computer Architecture News, vol. 44, no. 3,
pp. 243–254, 2016.

[30] S. Han, H. Mao, and W. J. Dally, “Deep compression: Compressing

deep neural networks with pruning, trained quantization and huffman
coding,” arXiv preprint arXiv:1510.00149, 2015.

[31] X. Hu, L. Liang, S. Li, L. Deng, P. Zuo, Y. Ji, X. Xie, Y. Ding, C. Liu,
T. Sherwood, and Y. Xie, “Deepsniffer: A dnn model extraction
framework based on learning architectural hints,” in Proceedings of
the Twenty-Fifth International Conference on Architectural Support
for Programming Languages and Operating Systems, ser. ASPLOS
’20. New York, NY, USA: Association for Computing Machinery,
2020, p. 385–399. [Online]. Available:
https://doi.org/10.1145/3373376.3378460

[32] W. Hua, Z. Zhang, and G. E. Suh, “Reverse engineering convolutional

neural networks through side-channel information leaks,” in
Proceedings of the 55th Annual Design Automation Conference, ser.
DAC ’18. New York, NY, USA: ACM, 2018, pp. 4:1–4:6. [Online].
Available: http://doi.acm.org/10.1145/3195970.3196105

[33] T. Hunt, Z. Jia, V. Miller, A. Szekely, Y. Hu, C. J. Rossbach, and

E. Witchel, “Telekine: Secure computing with cloud gpus,” in 17th
{USENIX} Symposium on Networked Systems Design and
Implementation ({NSDI} 20), 2020, pp. 817–833.

[34] T. Hunt, C. Song, R. Shokri, V. Shmatikov, and E. Witchel, “Chiron:
Privacy-preserving machine learning as a service,” arXiv preprint
arXiv:1803.05961, 2018.

[35] N. Hynes, R. Cheng, and D. Song, “Efﬁcient deep learning on

multi-source private data,” arXiv preprint arXiv:1807.06689, 2018.

[36] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa,
S. Bates, S. Bhatia, N. Boden, A. Borchers et al., “In-datacenter
performance analysis of a tensor processing unit,” in 2017 ACM/IEEE
44th Annual International Symposium on Computer Architecture
(ISCA).

IEEE, 2017, pp. 1–12.

[37] D. Jung, S. Lee, W. Rhee, and J. H. Ahn, “Partitioning compute units
in cnn acceleration for statistical memory trafﬁc shaping,” IEEE
Computer Architecture Letters, vol. 17, no. 1, pp. 72–75, 2017.

12

[38] D. Lee, D. Kohlbrenner, S. Shinde, D. Song, and K. Asanovi´c,
“Keystone: A framework for architecting tees,” arXiv preprint
arXiv:1907.10119, 2019.

[39] D. Lie, C. Thekkath, M. Mitchell, P. Lincoln, D. Boneh, J. Mitchell,

and M. Horowitz, “Architectural support for copy and tamper resistant
software,” Acm Sigplan Notices, vol. 35, no. 11, pp. 168–177, 2000.

[40] R. J. Lipton and D. Lopresti, “A systolic array for rapid string

comparison,” in Proceedings of the Chapel Hill Conference on VLSI.
Chapel Hill NC, 1985, pp. 363–376.

[41] C. Liu, M. Hicks, and E. Shi, “Memory trace oblivious program
execution,” in 2013 IEEE 26th Computer Security Foundations
Symposium.

IEEE, 2013, pp. 51–65.

[42] M. Maas, E. Love, E. Stefanov, M. Tiwari, E. Shi, K. Asanovic,
J. Kubiatowicz, and D. Song, “Phantom: Practical oblivious
computation in a secure processor,” in Proceedings of the 2013 ACM
SIGSAC conference on Computer & communications security. ACM,
2013, pp. 311–324.

[43] M. Minkin, D. Moghimi, M. Lipp, M. Schwarz, J. Van Bulck,

D. Genkin, D. Gruss, B. Sunar, F. Piessens, and Y. Yarom, “Fallout:
Reading kernel writes from user space,” 2019. [Online]. Available:
https://mdsattacks.com/ﬁles/fallout.pdf

[44] P. Mohassel and Y. Zhang, “Secureml: A system for scalable

privacy-preserving machine learning,” in 2017 IEEE Symposium on
Security and Privacy (SP).

IEEE, 2017, pp. 19–38.

[45] T. Moreau, T. Chen, Z. Jiang, L. Ceze, C. Guestrin, and

A. Krishnamurthy, “Vta: An open hardware-software stack for deep
learning,” arXiv preprint arXiv:1807.04188, 2018.

[46] J. F. K. O. M. Papamichael, T. M. M. Liu, D. L. S. A. M. Haselman,
L. A. M. Ghandi, S. H. P. P. A. Sapek, and G. W. L. Woods, “A
conﬁgurable cloud-scale dnn processor for real-time ai,” in
Proceedings of the 45th Annual International Symposium on
Computer Architecture, ser. ISCA ’18, 2018.

[47] A. Parashar, M. Rhu, A. Mukkara, A. Puglielli, R. Venkatesan,

B. Khailany, J. Emer, S. W. Keckler, and W. J. Dally, “Scnn: An
accelerator for compressed-sparse convolutional neural networks,”
ACM SIGARCH Computer Architecture News, vol. 45, no. 2, pp.
27–40, 2017.

[48] T. Peters, R. Lal, S. Varadarajan, P. Pappachan, and D. Kotz,

“Bastion-sgx: Bluetooth and architectural support for trusted i/o on
sgx,” in Proceedings of the 7th International Workshop on Hardware
and Architectural Support for Security and Privacy. ACM, 2018,
p. 3.

[49] J. Qiu, J. Wang, S. Yao, K. Guo, B. Li, E. Zhou, J. Yu, T. Tang, N. Xu,
S. Song et al., “Going deeper with embedded fpga platform for
convolutional neural network,” in Proceedings of the 2016
ACM/SIGDA International Symposium on Field-Programmable Gate
Arrays, 2016, pp. 26–35.

[50] A. Rane, C. Lin, and M. Tiwari, “Raccoon: Closing digital

side-channels through obfuscated execution,” in 24th {USENIX}
Security Symposium ({USENIX} Security 15), 2015, pp. 431–446.

[51] A. Rane, C. Lin, and M. Tiwari, “Secure, precise, and fast

ﬂoating-point operations on x86 processors,” in 25th {USENIX}
Security Symposium ({USENIX} Security 16), 2016, pp. 71–86.

[52] A. Reuther, P. Michaleas, M. Jones, V. Gadepally, S. Samsi, and
J. Kepner, “Survey and benchmarking of machine learning
accelerators,” arXiv preprint arXiv:1908.11348, 2019.

[53] M. S. Riazi, M. Samragh, H. Chen, K. Laine, K. Lauter, and

F. Koushanfar, “Xonn: Xnor-based oblivious deep neural network
inference,” in Proceedings of the 28th USENIX Conference on
Security Symposium, ser. SEC’19. Berkeley, CA, USA: USENIX
Association, 2019, pp. 1501–1518. [Online]. Available:
http://dl.acm.org/citation.cfm?id=3361338.3361442

[54] B. Rogers, S. Chhabra, M. Prvulovic, and Y. Solihin, “Using address
independent seed encryption and bonsai merkle trees to make secure
processors os-and performance-friendly,” in 40th Annual IEEE/ACM
International Symposium on Microarchitecture (MICRO 2007).
IEEE, 2007, pp. 183–196.

[55] G. Saileshwar, P. J. Nair, P. Ramrakhyani, W. Elsasser, J. A. Joao, and

13

M. K. Qureshi, “Morphable counters: Enabling compact integrity trees
for low-overhead secure memories,” in Proceedings of the 51st Annual
IEEE/ACM International Symposium on Microarchitecture, ser.
MICRO-51. Piscataway, NJ, USA: IEEE Press, 2018, pp. 416–427.
[Online]. Available: https://doi.org/10.1109/MICRO.2018.00041

[56] H. Sharma, J. Park, E. Amaro, B. Thwaites, P. Kotha, A. Gupta, J. K.
Kim, A. Mishra, and H. Esmaeilzadeh, “Dnnweaver: From high-level
deep network models to fpga acceleration,” in the Workshop on
Cognitive Architectures, 2016.

[57] J. E. Smith, “Decoupled access/execute computer architectures,” in

ACM SIGARCH Computer Architecture News, vol. 10.
Computer Society Press, 1982, pp. 112–119.

IEEE

[58] E. Stefanov, M. van Dijk, E. Shi, C. Fletcher, L. Ren, X. Yu, and

S. Devadas, “Path oram: An extremely simple oblivious ram protocol,”
in Proceedings of the 2013 ACM SIGSAC Conference on Computer
&#38; Communications Security, ser. CCS ’13. ACM, 2013, pp.
299–310. [Online]. Available:
http://doi.acm.org/10.1145/2508859.2516660

[59] G. E. Suh, D. Clarke, B. Gassend, M. Van Dijk, and S. Devadas,
“Aegis: architecture for tamper-evident and tamper-resistant
processing,” in ACM International Conference on Supercomputing
25th Anniversary Volume, 2003, pp. 357–368.

[60] M. Taassori, A. Shaﬁee, and R. Balasubramonian, “Vault: Reducing

paging overheads in sgx with efﬁcient integrity veriﬁcation structures,”
in Proceedings of the Twenty-Third International Conference on
Architectural Support for Programming Languages and Operating
Systems, ser. ASPLOS ’18. New York, NY, USA: ACM, 2018, pp.
665–678. [Online]. Available:
http://doi.acm.org/10.1145/3173162.3177155

[61] F. Tramer and D. Boneh, “Slalom: Fast, veriﬁable and private

execution of neural networks in trusted hardware,” arXiv preprint
arXiv:1806.03287, 2018.

[62] J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci,

F. Piessens, M. Silberstein, T. F. Wenisch, Y. Yarom, and R. Strackx,
“Foreshadow: Extracting the keys to the Intel SGX kingdom with
transient out-of-order execution,” in Proceedings of the 27th USENIX
Security Symposium. USENIX Association, August 2018.

[63] J. Van Den Hooff, D. Lazar, M. Zaharia, and N. Zeldovich, “Vuvuzela:

Scalable private messaging resistant to trafﬁc analysis,” in
Proceedings of the 25th Symposium on Operating Systems Principles,
2015, pp. 137–152.

[64] S. van Schaik, A. Milburn, S. Österlund, P. Frigo, G. Maisuradze,
K. Razavi, H. Bos, and C. Giuffrida, “RIDL: Rogue in-ﬂight data
load,” in S&P, May 2019.

[65] S. Volos, K. Vaswani, and R. Bruno, “Graviton: trusted execution

environments on gpus,” in 13th {USENIX} Symposium on Operating
Systems Design and Implementation ({OSDI} 18), 2018, pp. 681–696.

[66] X. Wang, R. Hou, B. Zhao, F. Yuan, J. Zhang, D. Meng, and X. Qian,
“Dnnguard: An elastic heterogeneous dnn accelerator architecture
against adversarial attacks,” in Proceedings of the Twenty-Fifth
International Conference on Architectural Support for Programming
Languages and Operating Systems, 2020, pp. 19–34.

[67] Y. Wang, A. Ferraiuolo, D. Zhang, A. C. Myers, and G. E. Suh,
“Secdcp: secure dynamic cache partitioning for efﬁcient timing
channel protection,” in Proceedings of the 53rd Annual Design
Automation Conference, 2016, pp. 1–6.

[68] Y. Zhou, S. Wagh, P. Mittal, and D. Wentzlaff, “Camouﬂage: Memory
trafﬁc shaping to mitigate timing attacks,” in 2017 IEEE International
Symposium on High Performance Computer Architecture (HPCA).
IEEE, 2017, pp. 337–348.

[69] Y. Zhou and D. Wentzlaff, “Mitts: Memory inter-arrival time trafﬁc

shaping,” ACM SIGARCH Computer Architecture News, vol. 44, no. 3,
pp. 532–544, 2016.

[70] J. Zhu, R. Hou, X. Wang, W. Wang, J. Cao, L. Zhao, F. Yuan, P. Li,

Z. Wang, B. Zhao et al., “Enabling privacy-preserving, compute-and
data-intensive computing using heterogeneous trusted execution
environment,” arXiv preprint arXiv:1904.04782, 2019.

