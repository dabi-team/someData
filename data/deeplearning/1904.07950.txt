9
1
0
2

r
p
A
6
1

]

V
C
.
s
c
[

1
v
0
5
9
7
0
.
4
0
9
1
:
v
i
X
r
a

Proceedings of Machine Learning Research 1–15, 2019

Machine Learning for Healthcare

A Comprehensive Study of Alzheimer’s Disease
Classiﬁcation Using Convolutional Neural Networks

Ziqiang Guan
Ritesh Kumar
Yi Ren Fung
Yeahuay Wu
Madalina Fiterau
College of Information and Computer Science
University of Massachusetts Amherst
Amherst, MA, U.S.A.

zguan@cs.umass.edu
riteshkumar@cs.umass.edu
yfung@cs.umass.edu
yeahuaywu@cs.umass.edu
mfiterau@cs.umass.edu

Abstract
A plethora of deep learning models have been developed for the task of Alzheimer’s dis-
ease classiﬁcation from brain MRI scans. Many of these models report high performance,
achieving three-class classiﬁcation accuracy of up to 95%. However, it is common for these
studies to draw performance comparisons between models that are trained on diﬀerent
subsets of a dataset or use varying imaging preprocessing techniques, making it diﬃcult to
objectively assess model performance. Furthermore, many of these works do not provide
details such as hyperparameters, the speciﬁc MRI scans used, or their source code, making
it diﬃcult to replicate their experiments. To address these concerns, we present a com-
prehensive study of some of the deep learning methods and architectures on the full set
of images available from ADNI. We ﬁnd that (1) classiﬁcation using 3D models gives an
improvement of 1% in our setup, at the cost of signiﬁcantly longer training time and more
computation power, (2) with our dataset, pre-training yields minimal (< 0.5%) improve-
ment in model performance, (3) most popular convolutional neural network models yield
similar performance when compared to each other. Lastly, we brieﬂy compare the eﬀects
of two image preprocessing programs: FreeSurfer and Clinica, and ﬁnd that the spatially
normalized and segmented outputs from Clinica increased the accuracy of model prediction
from 63% to 89% when compared to FreeSurfer images.

1. Introduction

Alzheimer’s disease (AD) is a degenerative brain disease and the most common cause of
dementia. It is a burdensome and costly disease that aﬀects 5.5 million people in the United
States. The total value of care provided to AD patients is estimated to be around $250
billion a year (Association et al., 2017).

The symptoms of AD include memory loss, challenges in planning, diﬃculty completing
simple tasks, and decline in other cognitive skills that often lead to a dependency on external
care, which takes a toll on both the family of the individual with AD, as well as society as
a whole.

The disease is characterized by the degeneration of speciﬁc nerve cells, presence of
neuritic plaques outside the neurons, and the accumulation of neuroﬁbillary tangles inside

c(cid:13) 2019 Z. Guan, R. Kumar, Y.R. Fung, Y. Wu & M. Fiterau.

 
 
 
 
 
 
Alzheimer’s Disease Classification Using MRI Scans

the neurons (McKhann et al., 1984), where the latter two proteins lead to cell death by
interfering with various functions of the cell (Association et al., 2017). As a result, brains
of people with advanced AD show inﬂammation, dramatic shrinkage from cell loss, and
widespread debris from dead or dying neurons (Association et al., 2017).

While no cure exists for the disease yet, there is consensus on the need and beneﬁt
for early diagnosis of AD. For example, an overwhelming percentage (80%) of older adults
wish to know as early as possible if they have AD (Dale et al., 2008), and early diagnosis
may help caregivers of AD patients feel more competent in caring for the patients, as well
as increasing the possibility that the caregiver can involve the patient in making medical,
ﬁnancial, legal, and care decisions (de Vugt and Verhey, 2013). Furthermore, Weimer and
Sager (2009) used Monte Carlo cost-beneﬁt analysis to suggest potential social and ﬁnancial
beneﬁts of early detection.

Diagnosis of AD is typically done with a comprehensive evaluation of the patient, which
may include tests of memory, problem solving, and attention, as well as brain scans us-
ing computed tomography (CT), magnetic resonance imaging (MRI), or positron emission
tomography (PET) scans.

Recently, machine learning techniques, speciﬁcally deep learning, show great potential
in aiding the diagnosis of AD using MRI scans. A variety of neural network architectures
have been proposed, some operate on 2D images (Hon and Khan, 2017) (Billones et al.,
2016) (Sarraf et al., 2017), while others operate on 3D MRI scans (Wang et al., 2018)
(Hosseini-Asl et al., 2016) (Payan and Montana, 2015). Because of the relatively small
number of available MRI scans, many proposed architectures (Payan and Montana, 2015)
(Hosseini-Asl et al., 2016) also incorporate an auto-encoder architecture with tied weights
to pre-train the model on a reconstruction task before the classiﬁcation task to prevent
over-ﬁtting on the data.

However, while there is a sizable number of studies on this topic, for people who wish
to utilize a discriminitive MRI feature extractor for other downstream AD-related tasks, it
is still diﬃcult to glean insights that would be helpful for this task. For example, it is not
clear how much performance is gained by using a 3D convolutional neural network (CNN)
to process the MRI, which has a high computation cost, compared to using a simple 2D
model and processing only one slice, or multiple slices of the MRI. It is also not clear how
much pre-training the model helps with raising the performance of the model, as Gupta
et al. (2013), Payan and Montana (2015), Hosseini-Asl et al. (2016) have done. Finally, it
is also not clear how much the various model architectures contribute to the high accuracy
that various authors have claimed in their paper.

In this study, we explore the aforementioned variables one must consider when selecting
a discriminative CNN setup for AD classiﬁcation, 1) the diﬀerence in performance between
using 2D and 3D models; 2) pre-training the model on reconstruction task before training
it on the classiﬁcation task; and 3) the performance gain from using model X versus model
Y.

2. Related Work

The idea of using computers to assist in the diagnosis of AD has been around before the
current wave of enthusiasm for neural networks. Plant et al. (2010) used a feature selection

2

Alzheimer’s Disease Classification Using MRI Scans

algorithm to achieve 92% accuracy in a binary classiﬁcation of AD (Alzheimer’s disease)
versus HC (Healthy Control). Jha et al. (2017) used a dual-tree complex wavelet transform
to extract features (DTCWT) from the MRI scans, performed principle component analysis
(PCA) to reduce the dimension of the extracted features, and a feed-forward neural network
to classify between AD and HC individuals.

Ever since Krizhevsky et al. (2012) won the ImageNet challenge with a seven-layer con-
volutional neural network, surpassing the previous winner by a large margin of 10%, the
computer vision community has mainly shifted from using hand-crafted features with sup-
port vector machines (SVM) or feed-forward neural networks, to large, end-to-end trainable
neural networks with many layers.

Gupta et al. (2013) trained a sparse auto-encoder on both natural images and MRI
images to learn a set of bases or ﬁlters. The ﬁlters were then convolved with the target
MRI to produce a set of features, which were then down-sampled using max-pooling before
fed into a feed-forward network for classiﬁcation. Similarly, Payan and Montana (2015)
trained a sparse auto-encoder on randomly selected patches from the MRI scans to learn the
features. They also used max-pooling to reduce the size of the features before introducing
them into a feed-forward network.

More recently, Hon and Khan (2017) used the image entropy of each slice to decide
which of the slices of the MRI scans to use. They then fed the slice through a pre-trained
2D VGG-16 network (Simonyan and Zisserman, 2014), as well as Inception V4 network
(Szegedy et al., 2015), to obtain the ﬁnal result.

Wang et al. (2018) used DenseNet (Huang et al., 2017) and ensemble methods to classify
the entire 3D MRI scan, leading to a new state-of-the-art three-class (Alzheimer versus Mild
Cognitive Impairment versus Cognitively Normal) classiﬁcation accuracy of 97.19%. Their
study showed that around 2.5% increase in accuracy was attributed to applying ensemble
method, which falls in-line with other studies that employed the method.

3. Methods

In this section, we detail the setup we used for this study, including the acquisition and
preprocessing of the data, and the model architectures we use in our comparison. Figure 1
provides an overview of the various components our study will cover.

3.1. Data Acquisition

For this study, we obtained MRI scans from the Alzheimer’s Disease Neuroimaging Initiative
(ADNI) 1. Speciﬁcally, we are using MRI scans with the description “MPR; GradWarp; B1
Correction; N3”, which we will henceforth refer to as “preprocessed” scans, as well as
the FreeSurfer post-processed MRI scans with the description “FreeSurfer Cross-Sectional
Processing brainmask” in the ADNI database. A total of 3415 “preprocessed” scans and
3177 FreeSurfer post-processed scans were obtained from the website.

1. ADNI Website: http://adni.loni.usc.edu/

3

Alzheimer’s Disease Classification Using MRI Scans

Figure 1: An overview of the pipeline of our experiments. The “preprocessed” MRI scans
from ADNI are processed by Clinica, then used for both 2D and 3D classiﬁcation. The
FreeSurefer scans from ADNI are used directly for 3D classiﬁcation.

3.2. Data Preprocessing

Due to the prominence of extraneous parts of the head that are captured in MRI scans, which
can potentially intorduce noise in the network, most studies use FSL2 and/or Statistical
Parameteric Mapping (SPM)3 for the preprocessing of the MRI scans. FSL provides brain
extraction and tissue segmentation functionality, and SPM realigns, spatially normalizes,
and smoothes the scans.

For our experiments, we used the Clinica software platform4 developed by the ARAMIS
Lab5, which supports FSL, SPM, FreeSurfer, as well as a few other technologies. We are
using the t1-volume pipeline, which is a wrapper of the “segmentation”, “run dartel”, and
“normalize to mni space” routines implemented in SPM.

The inputs to the Clinica pipeline were the “preprocessed” scans from ADNI, and the
outputs of the Clinica pipeline include spatially normalized gray matter, white matter,
and cerebrospinal ﬂuid segmentation maps, as well as a brain extraction output similar to
the FreeSurfer post-processed scans from ADNI’s dataset, with a diﬀerence being that the
Clinica outputs are spatially normalized.

Furthermore, we extract 2D slices from ﬁxed indices for each view of the spatially
normalized brain extraction output. The indices were chosen based on visual prominence of
the hippocampus of the brain. Speciﬁcally, they were the 52nd slice of axial view, the 58th
slice of sagittal view, and the 92nd slice of coronal view. We also experimented with using

2. FSL: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSL
3. SPM: https://www.ﬁl.ion.ucl.ac.uk/spm/
4. Clinica: http://www.clinica.run
5. Aramis Lab: www.aramislab.fr

4

Alzheimer’s Disease Classification Using MRI Scans

(a) The axial, coronal, and sagittal view of the “preprocessed” scans.

(b) The axial, coronal, and sagittal view of the FreeSurfer post-processed scans.

(c) The 52nd axial, 92nd coronal, and 58th sagittal view of the brain extraction outputs
from Clinica, which we used for 2D classiﬁcation.

Figure 2: Slices from “preprocessed” scans, FreeSurfer post-processed scans, and the speciﬁc
slices we use for 2D classiﬁcation.

neighboring slices for classiﬁcation. Figure 2 shows the 2D slices of the brain extraction
output by Clinica.

3.2.1. Demographics

After processing the “preprocessed” scans with Clinica, we obtained 2023 sets of scans.
Table 1 shows the demographics of the FreeSurfer post-processed scans, and Table 2 shows
the demographics of the outputs from the Clinica pipeline. Note that the output from
Clinica had fewer scans because some were lost in the process due to unknown reasons.

5

Alzheimer’s Disease Classification Using MRI Scans

Class

AD
MCI
CN

No. of
subjects
326
219
217

No. of
scans
928
1408
982

Sex

Age

Male Female Mean
74.8
141
185
75.1
78
141
75.6
99
118

Std. Dev
7.3
5.3
7.3

Table 1: Demographics for the FreeSurfer post-processed scans from ADNI’s website.

Class

AD
MCI
CN

No. of
subjects
199
237
169

No. of
scans
586
827
610

Sex

Age

Male Female Mean
75.4
93
106
76.1
93
144
75.4
88
81

Std. Dev
7.3
5.4
7.1

Table 2: Demographics for the output scans of the Clinica pipeline. Note that some of the
scans were lost in the process due to unknown reasons.

3.2.2. Training / Validation / Testing Split

To evaluate the performance of our models, we split the data into a training set, validation
set, and testing set, with a ratio of 6:2:2. We save the model with the lowest validation loss,
and use that to obtain the ﬁnal accuracy on the test set.

Clinica

FreeSurfer

Train
Validation
Test
Train
Validation
Test

AD MCI CN Total
990
330
330
110
330
110
1053
351
351
117
351
117

330
110
110
351
117
117

330
110
110
351
117
117

Table 3: Data distribution between the three classes (AD versus MCI versus CN) and
training, validation, and testing folds for both FreeSurfer post-processed scans and Clinica
outputs.

For each run, we split the data into three classes: (AD, MCI, CN). We then perform
shuﬄing on each of the splits. The ﬁrst N scans of each class are used to create a balanced
dataset, where N is the size of the smallest class. We then split each of the classes into
training, validation, and testing set. See Section .1 in Appendix A for details on the
procedure, and Table 3 for the ﬁnal distribution for both the Clinica and FreeSurfer images.
Many previous works such as Wang et al. (2018), Hosseini-Asl et al. (2016), and Sarraf
et al. (2017), performed ten-fold cross-validation as a way of measuring the performance
of their model. We decided to deviate from this setup because we are not performing

6

Alzheimer’s Disease Classification Using MRI Scans

hyperparameter search, and therefore require an extra set of data for ﬁnal evaluation so we
can use the validation set to guide early-stopping. To compensate for the reduced number
of possible combinations of data that we can train, validate, and test in one run, we utilize
the aforementioned shuﬄing scheme, and run each experiment four to six times to obtain
a good randomized sample over the training, validation, and testing set. All of the 2D
experiments were run six times, but we were only able to run the 3D experiments four
times each due to the signiﬁcantly longer time and greater computation power required.

3.3. 2D Convolutional Neural Network Models

For classifying 2D slices of MRIs, we use an 18-layer residual network (He et al., 2016a), a
16-layer VGG network (Simonyan and Zisserman, 2014), a 121-layer DenseNet (Huang et al.,
2017), and the Inception V3 architecutre (Szegedy et al., 2016). We believe that our selection
of networks is representative of the most popular network architectures currently being used
by the computer vision community, and the designs of many of the more complex networks
we have come across, such as Wang et al. (2018)’s 3D DenseNet, borrow architectural ideas
from these networks.

The models we selected are pre-built models from the PyTorch model zoo, and unless
speciﬁed otherwise, the weights of the models are initialized from weights pre-trained on
the ImageNet dataset. The last layer of each of the models was replaced with a linear layer
that reduced the dimension of the extracted features of the convolutional layers down to
three, each corresponding to one of three classes (AD/MCI/CN).

3.4. 3D Convolutional Neural Network Models

Because there are no pre-built 3D models available, we built a 16-layer (Table 4) and 22-layer
(Table 5) CNN model following the architectural designs of the residual network (He et al.,
2016a). Speciﬁcally, we used the “bottleneck” conﬁguration to reduce the number of ﬁlters
in the inner layer of each residual block (He et al., 2016a), and the “full pre-activation”
layout (He et al., 2016b) for the residual blocks. The layout of each residual block can be
found in Table 6.

3.4.1. Convolutional Autoencoder

Similar to Hosseini-Asl et al. (2016) and Payan and Montana (2015), we added a decoder to
our 22-layer CNN by reversing the weights of the CNN to form an autoencoder. Speciﬁcally,
a simpliﬁed formula for the operation is described in Equation 1, where X is the input
matrix, W is the weight matrix, f is an activation function, Y is a matrix representing the
feature extracted from X, ˆX is a reconstruction of X by the network, and · denotes dot
product.

Y = f (W T · X)
ˆX = f (W · Y )

(1)

7

Alzheimer’s Disease Classification Using MRI Scans

convolution layer
residual block
convolution layer
residual block
convolution layer
residual block
convolution layer
convolution layer
convolution layer
convolution layer
linear layer

In Channel Out Channel Kernel Size
32
32
64
64
128
128
256
512
512
512
3

1
32
32
64
64
128
128
256
512
512
32768

3
—
3
—
32
—
3
3
3
3
—

Stride
1
—
2
—

—
2
2
2
1
—

Table 4: Architecture and hyperparameters for the 16-layer 3D residual network.

convolution layer
residual block
convolution layer
residual block
convolution layer
residual block
convolution layer
residual block
convolution layer
residual block
convolution layer
convolution layer
linear layer

In Channel Out Channel Kernel Size
32
32
64
64
128
128
256
256
512
512
512
512
3

1
32
32
64
64
128
128
256
256
512
512
512
32768

3
—
3
—
3
—
3
—
3
—
3
3
—

Stride
1
—
2
—
2
—
2
—
2
—
2
1
—

Table 5: Architecture and hyperparameters for the 22-layer 3D residual network.

8

Alzheimer’s Disease Classification Using MRI Scans

Batch Norm
ReLU
Convolution Layer
Batch Norm
ReLU
Convolution Layer
Batch Norm
ReLU
Convolution Layer

In Channel Out Channel Kernel Size
—
—
n/2
—
—
n/2
—
—
n

—
—
n
—
—
n/2
—
—
n/2

—
—
1
—
—
3
—
—
1

Stride
—
—
1
—
—
1
—
—
1

Table 6: The layers for the residual block used in our 3D residual network. n is the number
of input channels.

3.5. Optimization Process

3.5.1. Reconstruction Task

To train the convolutional autoencoder on the reconstruction task, we minimize the mean
squared error (MSE), its formulation is shown in Equation 2, where X is the input matrix
(the MRI scan), ˆX is obtained from the formulation shown in Equation 1, n is the number
of MRI scans, and m is the number of features (or voxels) in the scan.

M SE =

1
n

n
(cid:88)

m
(cid:88)

i=1

j=1

(Xij − ˆXij)2

(2)

Following Hosseini-Asl et al. (2016) and Payan and Montana (2015), we apply a sparsity
constraint β to the hidden representation Y , giving us the end-to-end formulation of the
objective for the reconstruction task, shown in Equation 3. We exclude the formulation in
Equation 3 for the weight decay (L2 Regularization) for brevity.

Loss =

1
n

n
(cid:88)

m
(cid:88)

i=1

j=1

(Xij − ˆXij)2 + β ∗ Yij

(3)

3.5.2. Classification Task

For the classiﬁcation task, we minimize the cross-entropy loss between the predicted proba-
bility distribution of the correct label and the ground truth distribution. The objective has
the following formulation, shown in Equation 4, where ˆp is a vector of probability distribu-
tion predicted by the model, l is index of the correct class (e.g. 0 for AD, 1 for MCI, 2 for
CN), and ˆpl and ˆpj are the lth and jth element of ˆp, respectively.

Loss(ˆp, l) = − log(

exp(ˆpl)

(cid:80)#classes
j=1

exp(ˆpj)

)

(4)

9

Alzheimer’s Disease Classification Using MRI Scans

3.5.3. Training

We ran all of our experiments for 100 epochs. The weights that led to the lowest validation
loss were saved and later used to make predictions on the test set. We chose to save the
model with the lowest validation loss instead of the lowest validation accuracy because
the validation loss captures the divergence between the predicted distribution and the true
distribution, whereas accuracy may or may not capture this.

For hardware, hyperparameters, and other information on training, see Section .2 in

Appendix A.

4. Results

4.1. Evaluation Approach

The goal of this study is to answer three queries one may have when deciding among the
numerous proposed architectures as feature extractors for other AD-related downstream
tasks. Speciﬁcally, we are looking to understand the performance gain, if any, from 1)
using a 2D model on a slice of the scan versus 3D model on the entire MRI scan, 2) pre-
training the model on the reconstruction task before training it on the classiﬁcation task,
and 3) diﬀerent choices of models and architectures.

We attempt to provide insight into these three questions by keeping all other variables
constant, such as preprocessing pipelines, variations in data distribution, hyperparameters
for training and testing.

All of the experiments were performed at least four times, and no more than six times,
due to resource constraints. To calculate the reported validation accuracy, we take the
highest validation accuracy that we encounter in every run, and take the mean as the ﬁnal
validation accuracy. For the test accuracy. we simply take the mean of all of the test
accuracy across the runs.

4.2. 2D versus 3D Models

For this comparison, we evaluated the performance of 2D ResNet-18 pre-trained on Im-
ageNet, and our own 3D ResNet-22 pre-trained on extra MRI scans left over from class
balancing (see Section 3.2.2). The 2D ResNet-18 is trained on the coronal slice of the gray
matter map from Clinica, and the 3D ResNet-18 is trained on the entire gray matter map.
From Table 7, we can conclude that there is a performance gain of close to 1% from
utilizing 3D models instead of similar 2D models, which may be desirable if accuracy is
crucial in the target application. However, there is a large cost of going from 2D to 3D,
namely the time required to train the model, and the large amount of GPU memory required
to ﬁt the image and model. See Section .2 in Appendix A for more training information.

Model name
2D gray matter (coronal)
3D gray matter - w/ pre-train

Validation Accuracy Test Accuracy

89.5 ± 1.8%
90.3 ± 1.2%

87.4 ± 2.0%
88.5 ± 1.7%

Table 7: A comparison between 2D ResNet-18 pre-trained on ImageNet and 3D ResNet-22
pre-trained on MRI scans. There is a slight performance advantage with the 3D model.

10

Alzheimer’s Disease Classification Using MRI Scans

4.3. Pre-training versus No Pre-Training

For this comparison, we evaluate the eﬀects of pre-training on the model’s ability to learn
and the ﬁnal accuracy. Table 8 contains the ﬁnal accuracy, where there is little evidence to
suggest that the model is unable to learn without pre-training, or that pre-training leads
to better performance.

Model
gray matter - no pre-train
gray matter - w/ pre-train
gray matter + CSF + white matter - no pre-train
gray matter + CSF + white matter - w/ pre-train

Validation Accuracy Test Accuracy

90.1 ± 1.0%
90.3 ± 1.2%
91.0 ± 0.7%
90.4 ± 0.8%

88.9 ± 2.0%
88.5 ± 1.7%
89.2 ± 1.9%
88.9 ± 2.0%

Table 8: Comparison between models with pre-training versus models without pre-training.
The results show negligible diﬀerence in performance, with a diﬀerence in mean accuracy
of less than < 0.5%.

.

4.4. Model Comparisons

For this comparison, we look at how much impact the model architecture inﬂuences the
performance of the model, by comparing four popular 2D networks. Table 9 shows a com-
parison of the results.

Again, we observe little diﬀerence between the various architectures, suggesting that the

commonly used architectures should be able to perform well on the task.

Model name
ResNet-18 (coronal)
DenseNet121 (coronal)
InceptionNet V3 (coronal)
VGG19 bn (coronal)

Validation Accuracy Test Accuracy

89.2 ± 2.5%
90.0 ± 1.3%
89.1 ± 1.7%
89.1 ± 1.6%

87.5 ± 1.1%
88.8 ± 1.9%
88.6 ± 1.4%
88.1 ± 2.7%

Table 9: Three-class classiﬁcation accuracy of the 2D models.

4.5. FreeSurfer versus Clinica

We performed an additional set of experiments to gain some insight into the diﬀerence
in performance between using FreeSurfer data from the ADNI website, which were skull-
stripped but not spatially normalized, and white matter, gray matter, and cerebrospinal
ﬂuid maps from the Clinica pipeline.

We used the same 3D 16-layer ResNet that we built for both experiments, and found
a signiﬁcant diﬀerence in accuracy between the two sets, highlighting the importance and
advantage of using the Clinica pipeline. See Table 10 for the accuracy comparison.

11

Alzheimer’s Disease Classification Using MRI Scans

Preprocessing Pipeline Validation Accuracy Test Accuracy

FreeSurfer
Clinica

77.2 ± 0%
91.4 ± 1.2%

63.5 ± 0%
89.2 ± 0.4%

Table 10: Comparison between FreeSurfer data, which does not have spatial normalization,
among other preprocessing procedures, and the Clinica output data. Both experiments were
run with our 3D 16-layer ResNet.

5. Discussion

By comparing the various setups, we have come to the conclusion that: (1) there is a
slight improvement of about 1% in performance by using a 3D model over a 2D model,
(2) the advantage of pre-training the model on MRI scans before training it end-to-end for
classiﬁcation was not noticeable, (3) all of the current popular 2D CNN architectures had
similar performance.

For (1), we leave the reader with the caveat that training a 3D model requires signiﬁ-
cantly more time and computation power, and the extra 1% gain in accuracy may not be
worth the cost.

For (2), while we have concluded that pre-training does not aid our model in achieving
higher accuracy, we are not rebutting the previous studies over their claim that pre-training
helped. We have to consider that we have more data available to us, likely enough to a
point where pre-training may no longer be necessary.

For (3), our results suggest that the features of the model, such as densely connected
layers or Inception modules, do not contribute as much to the performance in the task of AD
classiﬁcation as previous studies (Wang et al., 2018)(Hon and Khan, 2017) had suggested.

References

Alzheimer’s Association et al. 2017 alzheimer’s disease facts and ﬁgures. Alzheimer’s &

Dementia, 13(4):325–373, 2017.

Ciprian D Billones, Olivia Jan Louville D Demetria, David Earl D Hostallero, and Pros-
pero C Naval. Demnet: A convolutional neural network for the detection of alzheimer’s
disease and mild cognitive impairment. In 2016 IEEE Region 10 Conference (TENCON),
pages 3724–3727. IEEE, 2016.

William Dale, Joshua Hemmerich, Emily K Hill, Gavin W Hougham, and Greg A Sachs.
What correlates with the intention to be tested for mild cognitive impairment (mci) in
healthy older adults? Alzheimer Disease & Associated Disorders, 22(2):144–152, 2008.

Marjolein E de Vugt and Frans RJ Verhey. The impact of early dementia diagnosis and

intervention on informal caregivers. Progress in neurobiology, 110:54–62, 2013.

Ashish Gupta, Murat Ayhan, and Anthony Maida. Natural image bases to represent neu-
roimaging data. In International conference on machine learning, pages 987–994, 2013.

12

Alzheimer’s Disease Classification Using MRI Scans

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for
image recognition. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 770–778, 2016a.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.

Identity mappings in deep
residual networks. In European conference on computer vision, pages 630–645. Springer,
2016b.

Marcia Hon and Naimul Mefraz Khan. Towards alzheimer’s disease classiﬁcation through
In 2017 IEEE International Conference on Bioinformatics and

transfer learning.
Biomedicine (BIBM), pages 1166–1169. IEEE, 2017.

Ehsan Hosseini-Asl, Georgy Gimel’farb, and Ayman El-Baz. Alzheimer’s disease diag-
arXiv preprint

nostics by a deeply supervised adaptable 3d convolutional network.
arXiv:1607.00556, 2016.

Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely
connected convolutional networks. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pages 4700–4708, 2017.

Rachna Jain, Nikita Jain, Akshay Aggarwal, and D Jude Hemanth. Convolutional neural
network based alzheimers disease classiﬁcation from magnetic resonance brain images.
Cognitive Systems Research, 2019.

Debesh Jha, Ji-In Kim, and Goo-Rak Kwon. Diagnosis of alzheimers disease using dual-tree
complex wavelet transform, pca, and feed-forward neural network. Journal of healthcare
engineering, 2017, 2017.

Alexander Khvostikov, Karim Aderghal, Andrey Krylov, Gwenaelle Catheline, and Jenny
Benois-Pineau. 3d inception-based cnn with smri and md-dti data fusion for alzheimer’s
disease diagnostics. arXiv preprint arXiv:1809.03972, 2018.

Alex Krizhevsky, Ilya Sutskever, and Geoﬀrey E Hinton. Imagenet classiﬁcation with deep
In Advances in neural information processing systems,

convolutional neural networks.
pages 1097–1105, 2012.

Guy McKhann, David Drachman, Marshall Folstein, Robert Katzman, Donald Price, and
Emanuel M Stadlan. Clinical diagnosis of alzheimer’s disease: Report of the nincds-adrda
work group* under the auspices of department of health and human services task force
on alzheimer’s disease. Neurology, 34(7):939–939, 1984.

Adrien Payan and Giovanni Montana. Predicting alzheimer’s disease: a neuroimaging study

with 3d convolutional neural networks. arXiv preprint arXiv:1502.02506, 2015.

Claudia Plant, Stefan J Teipel, Annahita Oswald, Christian B¨ohm, Thomas Meindl, Janaina
Mourao-Miranda, Arun W Bokde, Harald Hampel, and Michael Ewers. Automated de-
tection of brain atrophy patterns based on mri for the prediction of alzheimer’s disease.
Neuroimage, 50(1):162–174, 2010.

13

Alzheimer’s Disease Classification Using MRI Scans

Saman Sarraf, Danielle D DeSouza, John Anderson, Ghassem Toﬁghi, et al. Deepad:
Alzheimer s disease classiﬁcation via deep convolutional neural networks using mri and
fmri. BioRxiv, page 070441, 2017.

Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale

image recognition. arXiv preprint arXiv:1409.1556, 2014.

Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper
with convolutions. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 1–9, 2015.

Christian Szegedy, Vincent Vanhoucke, Sergey Ioﬀe, Jon Shlens, and Zbigniew Wojna.
Rethinking the inception architecture for computer vision. In Proceedings of the IEEE
conference on computer vision and pattern recognition, pages 2818–2826, 2016.

Shuqiang Wang, Hongfei Wang, Yanyan Shen, and Xiangyu Wang. Automatic recognition
of mild cognitive impairment and alzheimers disease using ensemble based 3d densely con-
nected convolutional networks. In 2018 17th IEEE International Conference on Machine
Learning and Applications (ICMLA), pages 517–523. IEEE, 2018.

David L Weimer and Mark A Sager. Early identiﬁcation and treatment of alzheimer’s

disease: social and ﬁscal outcomes. Alzheimer’s & Dementia, 5(3):215–226, 2009.

Appendix A.

.1. Data Splitting Methodology

Suppose we have 20 scans, where 7 are labeled as AD, 5 are labeled as MCI, and 8 are
labeled as CN. We ﬁrst shuﬄe each of the three splits, then take the ﬁrst 5 scans from
each of the class sets, where 5 = min(7, 5, 8), resulting in a ﬁnal dataset size of 15 from the
three classes. We then split each of the three sets into training, validation, and testing sets,
resulting in nine total sets. Lastly, we combine the training, validation, and testing sets
across all three classes to create a ﬁnal training set of 9 scans, validation set of 3 scans, and
testing set of 3 scans.

.2. Additional Training Information

.2.1. Hardware and Training Time

For training the 3D models, we used pairs of NVIDIA Tesla M40 GPUs with 24GB of
memory. We were able to ﬁt two images on each of the GPUs, bringing our maximum
possible batch size to 4. The training time for the experiments ranged from 12-14 hours for
the Clinica preprocessed images, to 24-26 hours for the FreeSurfer images. The signiﬁcantly
longer training time was mostly due to the larger ﬁle size, which led to slow network IO
and longer computation time.

For training the 2D models, we used NVIDIA Titan X GPUs with 12GB of memory. We
used a batch size of 16, which was not dictated by memory limit, but rather by intuition, as

14

Alzheimer’s Disease Classification Using MRI Scans

smaller batch size intuitively leads to better generalization with adaptive learning algorithms
such as Adam. The training time for most 2D models completed within 2 hours.

.2.2. Hyperaparameters

For all of the 3D models, we used Adam optimizer for both the reconstruction task and the
classiﬁcation task. For the reconstruction task, we used a learning rate of 0.001 and weight
decay (also known as L2 regularization) of 0.0001, as well as 0.0003 for β, the sparsity
constraint parameter. For the classiﬁcation task, we use a learning rate of 0.001 and weight
decay (L2 regularization) of 0.0001.

For the 2D models, we used Adam optimizer for the classiﬁcation task, with learning
rate set to 0.001 and weight decay set to 0.01 for ResNet18, and learning rate set to 0.0001
and weight decay set to 0.01 for Inception V3, VGG-16, and DenseNet.

The aforementioned hyperparameters are chosen from past experience, as they generally
work well for Adam. To keep the experiments consistent, no additional hyperparameter
search was performed, with the exception of training Inception V3, VGG-16, and DenseNet,
where we lowered the learning rate from 0.001 to 0.0001 because the models were having
diﬃculty training with the higher learning rate.

Table 13 lists each of the training hyperparameters we used for the diﬀerent models and

tasks.

.3. Tables

Model name
ResNet-18 (coronal)
ResNet-18 (sagittal)
ResNet-18 (axial)
ResNet-18 (coronal) gray matter only
DenseNet121 (coronal)
InceptionNet V3 (coronal)
VGG19 bn (coronal)
Billones et al. (2016)
Hon and Khan (2017) VGG-16
Hon and Khan (2017) Inception V4

Validation Accuracy Test Accuracy No. MRI Data

89.2 ± 2.5%
88.65 ± 1.9%
89.7 ± 3.2%
89.5 ± 1.8%
90.0 ± 1.3%
89.1 ± 1.7%
89.1 ± 1.6%
—
—
—

87.5 ± 1.1%
88.0 ± 2.5%
87.5 ± 2.5%
87.4 ± 2.0%
88.8 ± 1.9%
88.6 ± 1.4%
88.1 ± 2.7%
91.9%
92.3 ± 2.4%
96.25 ± 1.2%

2023
2023
2023
2023
2023
2023
2023
900
200
200

Table 11: Three-class classiﬁcation accuracy of our 2D models, as well as a few other studies
for comparison.

15

Alzheimer’s Disease Classification Using MRI Scans

Model
gray matter - no pre-train
gray matter - w/ pre-train
gray matter + CSF + white matter - no pre-train
gray matter + CSF + white matter - w/ pre-train
Wang et al. (2018) (w/o ensemble)
Hosseini-Asl et al. (2016)
Jain et al. (2019)
Payan and Montana (2015)
Khvostikov et al. (2018) (MRI only)

Val Accuracy Test Accuracy # Subjects
88.9 ± 2.0%
90.1 ± 1.0%
88.5 ± 1.7%
90.3 ± 1.2%
89.2 ± 1.9%
91.0 ± 0.7%
88.9 ± 2.0%
90.4 ± 0.8%
94.7%
—
94.8%
—
95.7%
—
89.4%
—
85.4%
—

605
605
605
605
833
210
150
755
200

Table 12: Three-class classiﬁcation accuracy for our 3D models, as well as a few other
studies for comparison. Our models in this table is the 22-layer residual network, which
was mentioned in Section 3.4.

ResNet-16 (3D)
ResNet-22 (3D)
ResNet-16 (3D)
ResNet-22 (3D)
ResNet-18 (2D)
Inception V3 (2D)
VGG-16 (2D)
DenseNet (2D)

task
R
R
C
C
C
C
C
C

optimizer
Adam
Adam
Adam
Adam
Adam
Adam
Adam
Adam

learning rate weight decay

0.001
0.001
0.001
0.001
0.001
0.0001
0.0001
0.0001

0.0001
0.0001
0.0001
0.0001
0.01
0.01
0.01
0.01

sparsity param
0.0003
0.0003
—
—
—
—
—
—

Table 13: The training hyperparameters used for all of the models. In the task column, R
denotes reconstruction, and C denotes classiﬁcation.

16

