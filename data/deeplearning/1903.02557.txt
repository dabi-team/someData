9
1
0
2

t
c
O
7

]

M

I
.
h
p
-
o
r
t
s
a
[

3
v
7
5
5
2
0
.
3
0
9
1
:
v
i
X
r
a

Draft version October 8, 2019
Typeset using LATEX twocolumn style in AASTeX62

DASH: Deep Learning for the Automated Spectral Classiﬁcation of Supernovae and their Hosts

Daniel Muthukrishna,1, 2, 3 David Parkinson,3, 4, 5 and Brad E. Tucker6, 7, 3

1Institute of Astronomy, University of Cambridge, Madingley Road, Cambridge CB3 0HA, UK
2The Research School of Astronomy and Astrophysics, Australian National University, ACT 2601, Australia
3ARC Centre of Excellence for All-sky Astrophysics (CAASTRO)
4School of Mathematics and Physics, University of Queensland, Brisbane, QLD 4072, Australia
5Korea Astronomy and Space Science Institute, 776, Daedeokdae-ro, Yuseong-gu, Daejeon 34055, Republic of Korea
6Mt Stromlo Observatory, The Research School of Astronomy and Astrophysics, Australian National University, ACT 2601, Australia
7National Centre for the Public Awareness of Science, the Australian National University, Canberra, Australia

Submitted to ApJ

ABSTRACT
We present DASH (Deep Automated Supernova and Host classiﬁer), a novel software package that
automates the classiﬁcation of the type, age, redshift, and host galaxy of supernova spectra. DASH makes
use of a new approach that does not rely on iterative template matching techniques like all previous
software, but instead classiﬁes based on the learned features of each supernova’s type and age. It has
achieved this by employing a deep convolutional neural network to train a matching algorithm. This
approach has enabled DASH to be orders of magnitude faster than previous tools, being able to accurately
classify hundreds or thousands of objects within seconds. We have tested its performance on four years
of data from the Australian Dark Energy Survey (OzDES). The deep learning models were developed
using TensorFlow, and were trained using over 4000 supernova spectra taken from the CfA Supernova
Program and the Berkeley SN Ia Program as used in SNID (Supernova Identiﬁcation software, Blondin
& Tonry 2007). Unlike template matching methods, the trained models are independent of the number
of spectra in the training data, which allows for DASH’s unprecedented speed. We have developed
both a graphical interface for easy visual classiﬁcation and analysis of supernovae, and a Python
library for the autonomous and quick classiﬁcation of several supernova spectra. The speed, accuracy,
user-friendliness, and versatility of DASH presents an advancement to existing spectral classiﬁcation
tools. We have made the code publicly available on GitHub and PyPI (pip install astrodash) to
allow for further contributions and development. The package documentation is available at https:
//astrodash.readthedocs.io.

Keywords: methods: data analysis, machine learning, statistical — supernovae: general — surveys —

techniques: spectroscopic — cosmology: observations

1. INTRODUCTION

Supernovae (SNe) have been pivotal to modern ob-
servational cosmology. The use of Type Ia supernovae
(SNIa) as standard candles have provided some of the
most compelling evidence for the discovery that the ex-
pansion of the universe is accelerating (Riess et al. 1998;
Perlmutter et al. 1999; Schmidt et al. 1998). However,

Corresponding author: Daniel Muthukrishna
daniel.muthukrishna@ast.cam.ac.uk

the nature of dark energy and the value of many cosmo-
logical parameters are still under active consideration
(Zhang et al. 2017; Muthukrishna & Parkinson 2016).
To this end, several large scale surveys including the
Dark Energy Survey (DES) (Dark Energy Survey Col-
laboration et al. 2016), the Supernova Legacy Survey
(SNLS) (Astier et al. 2006), and ESSENCE (Davis et al.
2007) have aimed to increase the total set of supernovae
in order to gain a better understanding of dark energy.
Moreover, in the near future, projects such as the Large
Synoptic Survey Telescope (LSST, LSST Science Col-
laboration et al. 2009) will substantially increase the

 
 
 
 
 
 
2

Muthukrishna et al.

transient catalogue with the expectation to observe or-
ders of magnitude more supernovae than ever before.

The ﬁeld of observational astronomy has reached a
new era of ‘big data’, where we are collecting more data
than humans can possibly process and classify alone.
Machine learning techniques have been a key driver in
tackling these new large-scale problems and many suc-
cessful attempts have been used to solve large data as-
tronomy problems (Ball & Brunner 2010). More re-
cently, however, deep learning has gained a lot of pop-
ularity in the machine learning community for its ac-
curacy, eﬃciency and ﬂexibility. In particular, convolu-
tional neural networks (CNNs) have achieved remark-
able results in a range of diﬀerent applications including
image and speech recognition challenges, outperform-
ing previous approaches (e.g. Krizhevsky et al. (2012);
Razavian et al. (2014); Szegedy et al. (2014)). Only after
the Galaxy Zoo Challenge (Lintott et al. 2008; Dieleman
et al. 2015), however, did it begin to gain a larger in-
terest in the astronomy community (e.g. Cabrera-Vives
et al. (2017); Aniyan & Thorat (2017)).

While machine learning has been applied to photo-
metric supernova classiﬁcation (e.g. M¨oller et al. 2016;
Lochner et al. 2016; Charnock & Moss 2017; Moss 2018;
Narayan et al. 2018; Muthukrishna et al. 2019, in prep.),
few attempts at spectral classiﬁcation of any kind have
been made. While this project was being developed, a
paper by Sasdelli et al. (2016) applied deep learning to
supernova spectra: using it to explore the spectroscopic
diversity in Type-Ia supernovae. Moreover, a recent the-
sis by H´ala (2014) has applied a similar CNN approach
to that described in this paper to the spectral classiﬁ-
cation of quasars, stars and galaxies. Supernovae are
inherently more complicated, however, due to the fact
that they vary with time and have degeneracies in their
type, age and redshift, with often lower signal-to-noise
caused by distortions from their host galaxy.

In fact, there are several factors that make supernova
classiﬁcation a challenging problem. While diﬀerent
types of supernovae are distinguished by the presence of
particular absorption features in their spectra, the prob-
lem of spectral classiﬁcation is made diﬃcult by the fact
that the spectrum changes depending on the number of
days since maximum light it was observed at (deﬁned as
‘age’ in this paper). Each spectrum also has distortions
due to contamination from host galaxy light. Moreover,
the redshift at which the supernova is observed impacts
which spectral features are visible in the observed wave-
length range, and also aﬀects the signal-to-noise ratio
(S/N) which decreases with redshift. Extinction from in-
terstellar dust further impacts the spectra. Subtracting
the continuum from each spectrum can limit this issue

by placing more emphasis on the spectral features in-
stead of the colour information. Finally, issues with the
telescope used to observe the spectrum such as dichroic
jumps being caused by miscalibrations between the two
spectral arms using diﬀerent CCDs, and also telluric fea-
tures from the earth’s atmosphere are further problems
that need to be accounted for when classifying spectra.

1.1. Prior Software

Due to these complications, existing supernova spec-
tral classiﬁers are not able to automate the classiﬁca-
tion process. Currently, the process of classifying super-
novae is very slow and labour-intensive, with the clas-
siﬁcation process for a single supernova taking up to a
few hours with the incessant input of an experienced
astronomer. Surveys like the Australian Dark Energy
Survey (OzDES, Yuan et al. 2015a; Childress et al.
2017) are observing thousands of transient objects which
need to be classiﬁed; and current methods make this an
enormously time-consuming process. SNID (Blondin &
Tonry 2007) and Superfit (Howell et al. 2005) are the
two main spectral classiﬁer software packages used to
classify supernovae. SNID is a fast typing tool written
in Fortran. It makes use of the cross-correlation algo-
rithms of Tonry & Davis (1979) and has been eﬀective
in distinguishing SN subtypes at a range of redshifts.
However, it’s accuracy drops signiﬁcantly when there is
host-galaxy contamination or if the spectra has a low
S/N. In such cases, Superfit acts as a better tool due
to its ability to classify host-contaminated spectra, and
account for extinction, and as such is the primary tool
used by large surveys such as OzDES and SNLS. It’s
main downfall, however, is that it is often very slow
and requires a lot of user-input to constrain priors on
redshift, host, and supernova type. Superfit is writ-
ten in IDL and makes use of a chi-squared minimisation
approach to classify the spectra.
It accounts for the
supernova type, age, host galaxy and extinction in its
minimisation equation, which enable it to be a very ef-
fective tool. However, given the thousands of transient
objects that are being detected by the latest era of su-
pernova surveys, a faster and more autonomous software
is required.

DASH makes use of the techniques used in each of these
In particular, the spectra in DASH are
previous tools.
processed in a very similar method to the log-wavelength
spectra developed by SNID (see section 2.3). Moreover,
the rlap ranking system developed by Blondin & Tonry
(2007) is available in DASH and is used as a test for mis-
classiﬁcations (along with the machine learning scores)
in much the same way as SNID.

DASH

3

All previous spectral tools for classiﬁcation and red-
shifting make use of the Tonry & Davis (1979) cross-
correlation technique (i.e. SNID, MARZ (Hinton et al.
2016), AUTOZ (Baldry et al. 2014), RUNZ) or a chi-squared
minimisation approach (i.e. Superfit). However, using
either of these techniques means that the total compu-
tation time increases linearly with the number of spec-
tra in the dataset. Both SNID and Superfit can only
compare an input spectrum with one other spectrum
at a time, and their accuracy is highly reliant on their
dataset. DASH improves upon this by using the aggre-
gate features of a particular class of supernova instead
of comparing to a single spectrum. DASH is able to learn
from the features of all spectra in a supernova class and
classify on that, instead of comparing to just one spec-
trum at a time like previous tools.

1.2. Overview

We have developed a new supernova spectral clas-
siﬁcation tool, DASH (Deep Automated Supernova and
Host classiﬁer), to quickly and accurately determine the
type, age, redshift, and host galaxy of supernova spec-
tra. We make use of a convolutional neural network
which greatly improves upon many aspects of previous
classiﬁcation tools. In section 2, we detail the datasets
we have collated and the pre-processing techniques that
are uniformly applied to the spectra. In section 3, we
describe the convolutional neural network architecture
that we use. In section 4, we outline the four diﬀerent
trained models that are available in the DASH release,
before describing the algorithms used to redshift and
to warn the user against possible misclassiﬁcations. In
Appendix B, we outline how to use the Python library
and graphical interfaces, as well as detail the platform
requirements and the code development. Finally, in sec-
tion 5, we evaluate the performance of DASH on a vali-
dation set and the recent OzDES data.

2. DATA

Supernovae are the result of either the core-collapse of
massive stars or the thermonuclear disruption of carbon-
oxygen white dwarfs accreting matter from a binary
companion. They are classiﬁed based on the presence
of certain features in their optical spectrum taken near
maximum light instead of their explosion mechanism.
The presence or absence of Hydrogen, Silicon and He-
lium spectral features separate SNe into four broad
types: Type-Ia (SNIa), Type-Ib (SNIb), Type-Ic (SNIc),
and Type-II (SNII). Within each of these, several sub-
types have been deﬁned due to a range of peculiarities
in their spectra. DASH makes use of 17 subtypes deﬁned
by Blondin & Tonry (2007), Modjaz et al. (2016), and
Silverman et al. (2012):

SNIa: Ia-norm, Ia-pec, Ia-91T, Ia-91bg, Ia-csm, Iax

SNIb: Ib-norm, Ib-pec, Ib-n, IIb

SNIc: Ic-norm, Ic-pec, Ic-broad

SNII: IIP, II-pec, IIL, IIn

In order to train the model, it was important that
we collected a wide range of spectra encompassing each
of these subtypes over a range of diﬀerent ages. The
quality of the classiﬁcation model is highly dependent
on the data that it was trained on, and hence, in this
section we detail how the data was collected, outline the
decisions made that led to the ﬁnal dataset, and describe
the systematic pre-processing techniques applied to the
data before it was trained using a deep convolutional
neural network (CNN).

2.1. Description

We collected labelled spectra from three main repos-
itories: the SNID database, the Berkeley Supernovae Ia
Program (BSNIP), and the releases from Liu & Modjaz
in 2014-2016.

2.1.1. SNID Database

The latest version of the SNID database (Templates
2.01) has compiled 3716 spectra from 333 diﬀerent su-
pernovae obtained from 1979 to 2008 (Blondin & Tonry
2007; Blondin et al. 2012). These were collected from
the SUSPECT public archive2, the CfA Supernova
Archive3, and the CfA Supernova Program (Mathe-
son et al. 2008; Blondin et al. 2012). The collected set
were selected to have a high signal-to-noise ratio and
have been cleaned, de-redshifted, continuum-divided,
smoothed and processed onto a log-wavelength scale by
SNID in a process deﬁned by Blondin & Tonry (2007).
The spectra were classed into 14 diﬀerent subtypes: Ia-
norm, Ia-pec, Ia-91T, Ia-91bg, Ia-csm, Ib-norm, Ib-pec,
IIb, Ic-norm, Ic-broad, IIP, II-pec, IIL, IIn. A detailed
description of these subtypes can be found in Blondin
& Tonry (2007).

We removed the supernovae where the date of maxi-
mum light was unknown, and were left with a total of
3618 spectra from 317 diﬀerent SNe. This distribution
comprised of 2724 spectra from 283 SNIa, 223 spectra
from 12 SNIb, 183 spectra from 11 SNIc, and 488 spectra
from 11 SNII.

1 https://people.lam.fr/blondin.stephane/software/snid/index.

html

2 http://bruford.nhn.ou.edu/∼suspect/index1.html
3 http://www.cfa.harvard.edu/supernova/SNarchive.html

4

Muthukrishna et al.

2.1.2. Liu & Modjaz

In 2014-2016, Yuqian Liu and Maryam Modjaz re-
leased a series of papers (Modjaz et al. 2016, 2014;
Liu et al. 2016; Liu & Modjaz 2014) which collected
the largest set of stripped-envelope core-core collapse
supernovae (SNIb and SNIc). The spectral database
was downloaded from their GitHub repository4 and con-
tained 1045 spectra across 96 Type Ib and Ic SNe.
Within this set, Liu & Modjaz (2014) corrected 14 SNe
also included in the SNID Templates 2.0 release, which
had incorrect type or age information. In addition, they
introduced two new subtypes called Ib-n (deﬁned in Pa-
storello et al. 2008) and Ic-pec to better account for
variations in some spectra.

We again removed the supernovae where the date of
maximum light was unknown, and were left with a total
of 571 spectra from 57 SNe. The distribution comprised
of 323 spectra from 27 SNIb, 248 spectra from 30 SNIc,
and zero SNIa or SNII spectra.

2.1.3. BSNIP

In 2012, Silverman et al. (2012) collated 1126 spec-
tra from 277 supernovae as part of the Berkeley SN Ia
Program (BSNIP) in the BSNIP v7.0 release5. Many
of these were, however, also part of the SNID Templates
2.0 set and the Liu & Modjaz updates. After remov-
ing exact duplicates in the BSNIP v7.0 database and
also removing spectra with an unknown date of max-
imum light, we were left with 604 spectra across 133
SNe. This reduced set had 29 new SNe and 114 SNe
that were common to the previously discussed datasets
but included spectra at diﬀerent ages. The distribution
comprised of 564 spectra from 131 SNIa, 40 spectra from
2 SNIc, and zero SNIb or SNII spectra.

The BSNIP release also deﬁned two new subtypes
called Ia-02cx (renamed Iax) and Ia-99aa (deﬁned in
Silverman et al. 2012; Foley et al. 2013). We discussed
these subtypes with the author, Jeﬀrey Silverman, and
he believed that Ia-99aa’s are a subset of the Ia-91T
type, and may not need their own category. Based on
this discussion, and the fact that there were not enough
Ia-99aa spectra to train its own subtype, we reclassiﬁed
the Ia-99aa spectra as Ia-91T SNe.

While duplicate spectra between the datasets were re-
moved, wherever there were discrepancies in the phase
or subtype of a SN, we preferentially selected the Liu
& Modjaz spectra as this dataset was released the

4 https://github.com/nyusngroup/SESNtemple/tree/master/

SNIDtemplates

5 https://people.lam.fr/blondin.stephane/software/snid/index.

html

latest and also purposefully corrected the SNID Tem-
plates 2.0 release. There were a total of six discrep-
ancies in the subtypes of SNe from the BSNIP v7.0
and the SNID Templates 2.0 datasets. The subtypes
from the BSNIP dataset were selected in favour of the
Templates 2.0 dataset because BSNIP intentionally im-
proved upon the SNID dataset. The following changes
were made: sn2002cx, sn2005hk, sn2008A from Tem-
plates 2.0 were changed from Ia-pec to Iax subtypes;
and the sn1995ac, sn2000cn, and sn2004aw from Tem-
plates 2.0 were changed to Ia-91T, Ia-91bg, and Ic-pec
from the norm subtypes, respectively.

2.2. DASH data distribution

Combining the spectra from the SNID Templates 2.0
database, the Liu & Modjaz updates, and the BSNIP
v7.0 release, and removing spectra with unknown ages,
we were left with a total of 4831 unique spectra across
403 unique SNe. The distribution comprised of 3288
spectra from 312 SNIa, 550 spectra from 40 SNIb, 505
spectra from 40 SNIc, and 488 spectra from 11 SNII.

In general, supernovae that are observed several weeks
before or after maximum light are usually very dim, and
their spectra are mostly dominated by host galaxy light.
Thus, we only considered supernovae between the range
of -20 days to +50 days since maximum light. After
removing spectra outside this range, we were left with
3899 spectra from 403 SNe. In order to group the spec-
tra into bins that can be trained on for the machine
learning algorithm, we split the ages into 4-day inter-
vals. Therefore, for each of the 17 supernova subtypes,
there are 18 age bins, leading to a total of 306 diﬀerent
classes to separate all of the spectra. The distribution
of spectra across the supernova subtypes and ages are
illustrated in Figures 1 and 2, respectively. The com-
plete distribution in each type and age classiﬁcation bin
is listed in Appendix A, Figure 7.

2.2.1. Data Augmentation

Figures 1, 2, and 7 illustrate two signiﬁcant problems.
Firstly, there are several bins with zero spectra, mean-
ing that DASH (and previous tools such as Superfit and
SNID) will never be able to classify a spectrum into this
bin. There is no way to ﬁx this problem other than to
observe a wider range of supernovae. In fact, while the
dataset has proven to be suﬃcient for eﬀective classi-
ﬁcation (see section 5), it is expected that if a wider
and deeper range of spectra is added to the training set,
the accuracy - particularly for low-S/N spectra - will
improve.

Secondly, the rarity of some SN types, and the bias of
cosmological surveys to preferentially observe Type-Ia
supernovae near maximum-light over other types mean

DASH

5

the same number of spectra. As an example, if a bin in
the training set had 250 spectra in it, we would repeat
each of those spectra 4 times; and if a bin had 5 spec-
tra, we repeat each of those spectra 200 times; until all
bins have an equal amount of 1000 spectra. However,
instead of simply repeating spectra (which adds no in-
formation to a neural network), we perform three data
augmentation techniques which can magnify the size of
our training set by over 1000 times. The following data
augmentation steps are used:

Adding noise:

The easiest thing to do is to simply add ran-
dom amounts of Gaussian noise to each spectrum
In our case, we add Gaus-
while oversampling.
(µ, σ2) with mean µ = 0 and sigma
sian noise
σ = 0.05(fmax
fmin), where fmax and fmin are
the maximum and minimum ﬂux values in the
spectrum, respectively.

N

−

Figure 1. The fraction of spectra for each subtype in the
ﬁnal dataset. The total distribution separated by subtype
and age is listed in Appendix A, Figure 7.

Figure 2. The distribution of spectra in the ﬁnal dataset
across the diﬀerent age bins.

that there is a large imbalance in the dataset. In SNID
and Superfit, this leads to a ‘type attractor’ (Blondin
& Tonry 2007), whereby low-S/N spectra will preferen-
tially be classiﬁed as SNIa regardless of their actual type,
simply because there are more SNIa spectra to choose
from. Moreover, while this is a large set of supernovae,
in terms of standard machine learning problems, this is
a relatively small dataset. In order to combat both of
these issues, we have made use of an oversampling tech-
nique to greatly diminish the eﬀect of these problems.
The idea of oversampling is to repeat each spectrum in
lowly populated bins until all classiﬁcation bins have

Adding host galaxy spectra:

Second, so that we can also distinguish a super-
nova spectrum which is contaminated by its host
galaxy, we also add on varying amounts of host
galaxy spectra. For each spectrum in the initial
training set, we add a host galaxy spectrum in
varying proportions from 1% to 99%, and also
make use of 11 diﬀerent host types: E, S0, Sa,
Sb, Sc, SB1, SB2, SB3, SB4, SB5, SB6 which are
taken from the BSNIP and Superfit datasets.

Cropping:

We also crop each spectrum by varying amounts,
such that instead of just training on an entire spec-
trum, we train on diﬀerent wavelength segments of
each spectrum. That is, we reduce the wavelength
range of each spectrum by random amounts. As
with all spectra that do not cover the full wave-
length range used in our neural network, we set the
points in the preprocessed and normalised spectra
that do not have data to 0.5 (see Figure 3d for an
example and section 2.3 for more details).

Redshifting:

Finally, for the unknown redshift models (see sec-
tion 4.1) we redshift each spectrum by random
amount from z = 0 to z = 1.

These processes increase the size of our training set
considerably. Since we add on 11 diﬀerent host galaxy
spectra at over 10 diﬀerent fractions, crop each spectrum
at at least 4 diﬀerent wavelength intervals, and add noise
to each spectrum while oversampling by a minimum of
4 times (up to 1000 times depending on the number of

Ia-normIa-csmIa-91bgIa-91TIa-pecIaxIc-broadIc-pecIc-normIb-pecIb-normIbnIIbIInII-pecIIPIIL-20to-18-18to-14-14to-10-10to-6-6to-2-2to22to66to1010to1414to1818to2222to2626to3030to3434to3838to4242to4646to500100200300400500Numberofspectra6

Muthukrishna et al.

10

10

spectra in the bin), we eﬀectively increase our training
4 = 1760 times the initial
4
set by at least 11
training set, but actually over around 100000 times the
initial dataset size, given the amount of oversampling
of lowly populated bins, and random redshifting during
training.

×

×

×

×

In this data augmentation process, we are enabling the
neural network to ﬁnd and train on the common features
among the augmented spectra, allowing it to train only
on the actual features that make up a spectrum instead
of the noise, host light, or wavelength range of each spec-
trum. This signiﬁcantly inhibits the imbalanced dataset
problem, and allows the neural network to train on ac-
tual SN features of a particular classiﬁcation bin rather
than random distortions of a single spectrum.

Ultimately, this technique is very important and ef-
fective, but can’t compete with actually having huge
amounts of real observational data. In future, as more
large scale surveys work to increase the transient cat-
alogue, these CNN problems will be far more powerful
than what can be made with current datasets.

Before augmentation, we split the total set of tran-
sients into two parts: 80% for the training set and 40%
for the testing set. The training set is used to train
the classiﬁer to identify the correct supernovae class,
while the testing set is used to test the performance of
the classiﬁer. We then apply the augmentation detailed
previously to the training set only.

high-frequency noise and cosmic rays. We scale
the amount of smoothing based on the average
wavelength spacing of the spectrum, deﬁned as
λdensity below:

λdensity = (λmax

−

λmin) /N,

(1)

where λmin and λmax are the minimum and max-
imum wavelength of the spectrum, and N is the
number of points in the spectrum. We also deﬁne
the wavelength density of the ﬁnal spectra after
processing as:

wdensity = (w1

w0) /Nw.

−

(2)

The window size of the median ﬁlter is then de-
ﬁned as:

window size =

wdensity
λdensity ×

smooth,

(3)

where smooth is the user-deﬁned amount to scale
the amount of ﬁltering. Most of the spectra used
in the training set have been preprocessed and
smoothed by SNID, and as such we do not add
any further smoothing, and set the window size to
1. Input spectra in DASH have a default smoothing
factor of smooth = 6, but can be altered by a user.
An example of this ﬁltering step is illustrated in
Figure 3a.

2.3. Preprocessing

2. De-redshifting:

Arguably one of the most important aspects in an ef-
fective learning algorithm is the quality of the training
set. As such, a lot of the software eﬀort in this project
has been in ensuring that the data has been processed
in a systematic and uniform way before we train the
matching algorithm. In this section, we outline the pro-
cessing techniques used to prepare the training set and
the input spectra.

Many of the previous classiﬁcation and redshifting
tools (including SNID (Blondin & Tonry 2007), MARZ
(Hinton et al. 2016), and AUTOZ (Baldry et al. 2014))
pre-process their spectra in a similar way before cross-
correlation and template-matching. These methods are
loosely based on the algorithms discussed by Tonry &
Davis (1979). We implement a very similar processing
technique to that used by Blondin & Tonry (2007) in
SNID. Our processing algorithm is applied to both the
training set and any input spectrum. It consists of the
following steps:

1. Low pass median ﬁltering:

The ﬁrst step to processing is to apply a low-pass
median ﬁlter to each spectrum in order to remove

The next stage involves de-redshifting the spec-
trum to its rest frame (illustrated in Figure 3b).
For input spectra, this is an optional stage depend-
ing on which redshift model is used (see section 4).

3. Log-wavelength binning:

In the third step, we bin the spectra onto a log-
wavelength scale with a ﬁxed number of points
(Nw) between w0 and w1. These parameters can
be changed by a user who wishes to re-train the
CNN model. However, the default parameters are
Nw = 1024, w0 = 3500˚A, w1 = 10000˚A, which
covers the optical spectral range at which most
supernova events are observed at, and has enough
points to recover both narrow and broad spectral
features, while not including too many points to
be computationally expensive. These parameters
were further selected to match the default param-
eter values of the SNID data, so that we could di-
rectly use these in our training set.

This step is important for a few reasons. Firstly, it
ensures that each spectrum is a vector of exactly
the same length and at the same wavelengths so

DASH

7

(a)

(c)

(b)

(d)

Figure 3. The spectral pre-processing steps before training using the SNIa DES16C2ma spectrum as an example. (a) The blue
line is the raw data spectrum, while the orange line shows the result after applying a low-pass median ﬁlter with a window size
deﬁned by equation 3 and a smoothing factor of 5. (b) The smoothed spectrum is then de-redshifted to its rest frame based
on the redshift obtained from its host-lines from an external software. This step is not applied in DASH if the redshift-agnostic
model is used. It is also binned into Nw points on a log-wavelength scale. (c) The de-redshifted and smoothed spectrum is
then binned onto a log-wavelength scale as deﬁned in equation 4 (blue line). A 13-point cubic spline interpolation is used to
model the continuum (orange line) before it is divided from the binned spectra to remove any spectral colour information (green
line). (d) The edge-discontinuities on the previous spectrum is smoothed with a cosine-taper (orange line). The ﬂux is then
normalized to values between 0 and 1 (green line).

that vectors from diﬀerent spectra can be easily
compared and trained on. Secondly, it is consis-
tent with the SNID data, and can make redshifting
less computationally expensive (Blondin & Tonry
2007). However, perhaps most important, is that
we can make use of CNN’s natural position in-
variance (Duda et al. 2012) during classiﬁcation.
By using a log-wavelength scale, changes in red-
shift now become linear translations, and so, the
CNN’s natural aﬃnity for being invariant to small
linear translations can be employed to allow clas-
siﬁcations to also be invariant to redshift.

some of the key steps are shown here. First, the
log-wavelength axis, wlog,n, is deﬁned as:

wlog,n = w0 ln en×dwlog ,

(4)

where n is the index of each point in the vector,
and runs from 0 to Nw, and

dwlog = ln(w1/w0)/Nw

(5)

is the size of a logarithmic wavelength bin. The
binned wavelength can then be translated from the
normal wavelength with the following relationship,

binned wave = A ln wlog,n + B

(6)

The log-wavelength binning process follows the
same method outlined in Blondin & Tonry (2007);

where B =
Nw ln w0/ ln(w1/w0) and A =
Nw/ ln(w1/w0). Using this method, the input

−

3000400050006000700080009000Wavelength (Å)864202468Relative FluxRawFiltered3000400050006000700080009000Wavelength (Å)012345Relative FluxDe-redshiftedLog-wavelength binned3000400050006000700080009000Wavelength (Å)012345Relative FluxLog-wavelength binnedContinuumContinuum divided3000400050006000700080009000Wavelength (Å)0.40.20.00.20.40.60.81.0Relative FluxContinuum dividedApodizedNormalised8

Muthukrishna et al.

and training spectra were binned onto this scale.
The binned spectrum is illustrated as the orange
line in Figure 3b. The points in the spectrum that
do not have data in the range w0 to w1 are set to
zero.

306-point one-hot vectors where each entry represents a
diﬀerent classiﬁcation bin so that matrix multiplication
can be more easily used when training. The labelled and
preprocessed data is then passed into the deep learning
model for training.

4. Continuum modelling with spline interpolation:

3. DEEP LEARNING

The fourth step in preparing the spectra involves
dividing the continuum. For galaxy spectra, the
continuum is well deﬁned and is easily removed
using a least-squares polynomial ﬁt. In supernova
spectra, however, the apparent continuum is ill-
deﬁned due to the domination of bound-bound
transitions in the total opacity (Pinto & Eastman
2001). For this reason, a 13-point cubic spline
interpolation is used to model the continuum. 13
points was considered to be suﬃcient to interpo-
late the spectrum. This is illustrated as the orange
line on Figure 3c.

5. Continuum division:

This continuum is then divided from the spectrum
(blue line). This step removes any spectral colour
information (including ﬂux miscalibrations), and
enables the correlation to rely purely on the rela-
tive shape and strength of spectral features in each
spectrum. It also has the advantage of diminishing
the eﬀect of extinction from the remaining spectra.
According to Blondin & Tonry (2007), the loss of
colour information has very little impact on the
redshift and age determination.

6. Apodising the edges:

While the discontinuities at each end of the spec-
trum are limited by the continuum division, fur-
ther discontinuities are removed by apodizing the
spectrum with a cosine bell in the ﬁnal step of
processing. This involves multiplying 5% of each
end of the spectrum by a cosine, to remove sharp
spikes. This is illustrated as the orange line in
Figure 3d. Finally, the spectrum is renormalised
to positive values between 0 and 1 (green line), so
that it is ready for training in the CNN. As neural
networks require regularly sampled data in a ﬁxed
grid, we set the the points in the spectrum that do
not have data in the range w0 to w1 to 0.5.

We then deﬁne two important properties for each pro-
cessed spectrum for the supervised deep learning ap-
proach:
its label and image data. The image data is
composed of the 1024-point vector that corresponds to
the pre-processed normalised ﬂux-values. The labels
correspond to one of the 306 diﬀerent classiﬁcation bins
outlined in section 2.2. We represent these labels as

Deep learning is a branch of machine learning that
has recently gained a lot of popularity for its success in
a range of diﬀerent applications including image, speech,
and language recognition. The age of big data and ad-
vancements in computer hardware have enabled neural
networks to be eﬀective at solving these more compli-
cated problems in reasonable amounts of time.

3.1. Convolutional Neural Networks

Convolutional neural networks are one of the most
popular deep learning architectures, and have been very
successful at benchmark image classiﬁcation problems.
We have employed this architecture by phrasing the
spectral classiﬁcation problem as a one-dimensional im-
age classiﬁcation problem, where ﬂuxes correspond to
pixel intensities. This enables us to use a very similar
method to that which is used to solve the benchmark
MNIST classiﬁcation problem (Li Deng 2012). We have
developed the CNN with TensorFlow’s Python library
due to its convenient high-level library which avoids low-
level details. It makes use of a highly eﬃcient C++ back-
end to do its computations (Abadi et al. 2016).

In a deep neural network, each layer is in the form of
a set of nodes or neurons which represent the data. In
DASH, the ﬁrst input layer is made up of 1024 neurons
representing the ﬂuxes of an input spectrum. Additional
layers of neurons above the original input signal are built
to ensure that each new layer captures a more abstract
representation of the original input layer. Each new hid-
den layer identiﬁes new features by forming non-linear
combinations of the previous layer (Hinton & Salakhut-
dinov 2006; Cybenko 1989). For example, the hidden
layers in DASH represent abstract constructions of the
input ﬂux vector. The ﬁnal output layer will then sim-
ply represent 306 diﬀerent neurons corresponding to the
306 diﬀerent classiﬁcation bins of supernova types and
ages.

The output, ˆyi, of each neuron in a neural network
layer can be expressed as the weighted sum of the con-
nections from the previous layer:

ˆyi =

n
(cid:88)

j=1

Wi,jxj + bi,

(7)

where xj are the diﬀerent inputs to each neuron from the
previous layer, Wi,j are the weights of the corresponding

DASH

9

inputs, bi is a bias that is added to allow some points in
the vector to be more independent of the connections, j
is an integer running from 1 to the number of connected
neurons in a particular layer to sum over the connections
from the previous layer, and i is an integer running from
In the
1 to the number of neurons in the next layer.
simple case, where we simply have a single layered dense
neural network, x is simply the input ﬂux, i runs from
1 to 1024 across the length of the input ﬂux vector, and
j runs from 1 to 306 across the number of classiﬁcation
bins. The weights and biases are free variables that are
computed by TensorFlow during the training process.

In the ﬁnal output layer, the values of ˆy represent the
‘evidence’ tallies for each classiﬁcation bin. In order to
be able to assign probabilities to each of the classiﬁca-
tion bins, we make use of a softmax regression model
in the ﬁnal layer. The softmax regression probabilities,
y, are calculated by applying a softmax function on the
evidence,

y = softmax(ˆy),

where the softmax activation function is deﬁned as

softmax(x)i =

exi

exj

(cid:80)
j

.

(8)

(9)

This function generalises a logistic regression to the
case where it can handle multiple classes. It eﬀectively
normalises the output layer of neurons so that the total
probabilities of all classiﬁcation bins sums to 1. These
softmax probabilities are important in DASH as they are
used to rank the best matching classiﬁcation bins. It’s
important to note that these probabilities only provide
the relative probability of a particular classiﬁcation bin
when compared to the other 306 diﬀerent supernova
types and ages.

Before the training process can begin, we need to spec-
ify a loss function which indicates how accurately the
model’s prediction matches the true class for each input
spectrum. We deﬁne the loss function to be the cross
entropy, HY (y), between the actual classiﬁcation bin, Y ,
and the model’s prediction, y, as:

HY (y) =

306
(cid:88)

−

i=1

Yi log(yi).

(10)

Here, Y is the label of the data which is made up of a
306-point one-hot vector with zeros in all entries except
for one which has a 1 to indicate the true classiﬁcation
bin. On the other hand, y is a 306-point vector where the
sum of all entries add to 1, and ideally for a good model,
the entry with the highest probability would be the same
bin as the entry with a 1 in Y . Hence, the cross-entropy

measures how ineﬃcient the predictions are compared to
the truth. We minimise the cross-entropy using a com-
mon but sophisticated gradient descent optimiser called
the Adam optimiser (Kingma & Ba 2014). We feed in
our training set deﬁned in section 2 in small batches
and train the neural network such that the values for
the weights and biases in each layer are computed to
optimise the model.

Overall, the neural network model consists of six dif-
including two convolutional layers with
ferent layers:
two max-pooling layers between them, one fully con-
nected layer, and a readout layer before the softmax
regression as illustrated in Figure 4. Each convolutional
and fully-connected layer have weights and biases which
are initialised with a small amount of noise to avoid
symmetry-breaking and zero-gradients, and a small pos-
itive bias to avoid ‘dead neurons’, respectively. These
layers use Rectiﬁed Linear Units (ReLU) (Nair & Hin-
ton 2010) as the activation function for each of the neu-
rons in the layers. The max-pooling layers basically just
sub-sample the input ﬂux in a non-linear fashion so as
to reduce the computational complexity (Boureau et al.
2010; Aniyan & Thorat 2017). Following the fully con-
nected layer, we implement dropout regularisation to re-
duce over-ﬁtting during training. Eﬀectively, this means
that the neurons which have very small weight values,
and hence do not strongly interact with other neurons,
are discarded from the network iteratively during train-
ing.

4. TRAINED MODELS

4.1. Models

Using the machine learning architecture deﬁned in sec-
tion 3, we have trained four diﬀerent models which are
available in the DASH release. All of these models use
the same dataset (described in section 2) and follow the
same data augmentation approaches outlined in section
2.2.1, whereby various amounts of host galaxy light are
added to the data. However, they diﬀer in whether they
classify into these hosts, and on whether they calculate
the redshift. They are listed as follows:

1. Known redshift, SN only classiﬁcation

2. Unknown redshift, SN only classiﬁcation

3. Known redshift, SN+host classiﬁcation

4. Unknown redshift, SN+host classiﬁcation

In the majority of supernova spectra, the redshift can
be accurately pre-determined from host galaxy features

10

Muthukrishna et al.

Figure 4. A visual representation of the multilayer convolutional neural network used in DASH. The 1024-point input ﬂux, which
has been processed following the method outlined in Figure 3, is reshaped into a 32 × 32 grid. The ﬁrst convolutional layer
computes 32 features for each 5 × 5 patch on the input. These 32 images are then sub-sampled using a standard max-pooling
layer over 2 × 2 patches of each image, reducing the images sizes to 16 × 16. A second layer of convolution with 64 features for
each 5 × 5 patch is applied to the previous layer before a 2 × 2 max-pooling layer is used to sub-sample the image size down to
8 × 8. The 64 images representing a 64 × 8 × 8 tensor are then ﬂattened down to a 4096-point vector. A fully connected layer
with 1024 neurons to allow processing on the entire image is added. Similar to the convolutional layers, weights and biases are
computed before a readout and softmax regression layer are added to identify the best matching classiﬁcations of the model.
This ﬁnal layer is a 306-point vector, with a score for each supernova type and age bin. Three example classiﬁcation bins have
been listed on the right.

using eﬀective redshifting tools such as MARZ6 (Hinton
et al. 2016). As such, the ‘Known redshift, SN only’
model has been designed with the same CNN architec-
ture illustrated in Figure 4 and ensures that each spec-
trum in the training set has been de-redshifted to its
rest frame (z = 0). During classiﬁcation, the redshift
must be input as a prior by the user so that the input
spectrum can also be de-redshifted to its rest frame.

However, in some supernova spectra, the host galaxy
is too faint compared to the supernova spectrum, and
hence, the redshift cannot be easily determined from
standard redshifting tools. For these cases, we have de-
veloped models which can classify supernovae indepen-
dent of the redshift, and hence do not require a red-
shift prior. The ‘Unknown redshift, SN only’ model
uses the same architecture as the ‘Known redshift,
SN only model’, but diﬀers by adding an extra data-
augmentation step (see section 2.2.1) which involves it-
eratively redshifting each spectrum by varying amounts
before training. This enables the trained model to learn
the features of spectra independent of their redshift, and
hence be able to identify the classiﬁcation bin regardless
of whether the input spectrum is in its rest frame.

Once the best matching classiﬁcation bins have been
identiﬁed, we determine the redshift of each of the top
ranking classiﬁcation bins by making use of a cross-
correlation technique with the input and the training
data from the classiﬁcation bin. This redshifting method
is described in section 4.2.

6 http://samreay.github.io/Marz/

The SN+host classiﬁcation models are designed with
nearly the same architecture as the SN only models, re-
spectively. However, instead of just classifying into the
306 classiﬁcation bins made up of supernova type and
age, we add an extra dimension with 11 host galaxies,
making a total of (11
306) 3366 classiﬁcation bins. In
each of these bins we add varying proportions of a partic-
ular host galaxy spectrum. The 11 host galaxy types we
used are taken from the SNID and BSNIP databases and
follow the Hubble diagram naming convention, listed as
follows: E, S0, Sa, Sb, Sc, SB1, SB2, SB3, SB4, SB5,
SB6. The CNN then trains based on the presence of a
combined supernova and host galaxy.

×

4.2. Redshifting Methods

In the second and fourth models, we iteratively red-
shift each spectrum in the training set by varying
amounts between z = 0 to z = 1 before it is trained
with the the neural network, hence enabling the model
to learn features and classify spectra irrespective of red-
shift. The log-wavelength scale means that redshifts
are now linear translations, and hence, help us to em-
ploy the CNN’s natural position invariance (Duda et al.
2012). Once the model has determined a best matching
classiﬁcation bin, we calculate the redshift using a very
similar cross-correlation technique to that used in SNID
as deﬁned by Blondin & Tonry (2007) and Tonry &
Davis (1979). The preprocessed input spectrum, s(n),
is cross-correlated ((cid:63)) with each training set spectrum,
t(n), in the classiﬁcation bin as follows:

c(n) = s(n) (cid:63) t(n) =

F

(S(k)T (k)) ,

(11)

DASH

11

where n represents the log wavelength indexes, c(n) is
the cross correlation function, S(k) and T (k) represent
the fast Fourier transform of the input spectrum and
a training set spectrum, respectively, and
is the fast
Fourier transform function which enables us to calcu-
late the cross-correlation. An example cross-correlation
function of the spectrum used in Figure 3 and a spec-
trum from the training set is illustrated in Figure 5.

F

Figure 5. An example cross-correlation function of the
DES16C2ma spectrum (Figure 3) with the best matching
spectrum from the training set determined by DASH. The po-
sition of the highest peak is used to determine the redshift
with equation 12. The antisymmetric component, a(n), de-
ﬁned in equation 14 is shown as the orange dashed line, and
the rms of this is illustrated as the horizontal black line. The
height of the correlation peak, h, is the diﬀerence between
the highest value and the antisymmetric rms, σa.

Since the spectra have been processed onto a log wave-
length scale deﬁned in section 2.3, the position of the
peak cross-correlation score enables the redshift to be
computed as

z = eδ×dwlog ,

(12)

where dwlog was deﬁned in equation 5 and δ is the index
value of the peak cross-correlation score in the range
Nw/2 < δ < Nw/2. We calculate the redshift from
−
the cross-correlation of the input spectrum with each
training set spectrum in a particular classiﬁcation bin,
and take the median value of all the redshifts.

The error in the calculated redshift is determined by
simply calculating the standard deviation of the red-
shifts in a particular classiﬁcation bin.

4.3. False Positive Rejection

As outlined in section 3.1, the ranking system used
by DASH only provides a relative measure of how closely

an input spectrum matches a particular classiﬁcation
bin compared to all other classiﬁcation bins. If an in-
put spectrum happens to be a weird spectrum, then this
ranking system will still choose the closest match, which
may lead to false-positive classiﬁcations. To account for
such cases, we have made use of two independent mea-
sures to ﬂag potential misclassiﬁcations. The ﬁrst rejec-
tion test makes use of a similar measure to that used in
SNID called the rlap score, and the second test compares
the top ranking DASH classiﬁcations to ascertain whether
the matches are consistent with each other. This pro-
vides two independent warnings to a user: a ‘low rlap
warning’, and an ‘inconsistent classiﬁcation warning’.
These are seen as a ‘reliability’ label in the DASH in-
terface, which act to inform a user that the automatic
classiﬁcations requires closer human inspection.

4.3.1. Low rlap Warning

In SNID, the rlap scores act as the primary method
of comparing an input spectrum to each of the spec-
tra in the training set: the training set spectrum with
the highest rlap score is considered the best matching
spectrum.

Tonry & Davis (1979) ﬁrst introduced the cross-
correlation height-noise ratio, r, to quantify the sig-
niﬁcance of a cross-correlation peak. It is deﬁned as:

r =

h
√2σa

,

(13)

where h is the height of the cross-correlation shown in
Figure 5, and √2σa is the rms of the antisymmetric
component of c(n). The antisymmetric component is
calculated by assuming that c(n) is the sum of an auto-
correlation of the training set spectrum, t(n) with its
shifted spectrum t(n
δ) and a random function, a(n)
that distorts the correlation peak (Tonry & Davis 1979):

−

c(n) = t(n) (cid:63) t(n

δ) + a(n).

−

(14)

The autocorrelation term will give a peak correlation at
the exact redshift given by the shift, δ, in logarithmic
wavelength units, and will be symmetrical about n = δ.
Assuming that the symmetric and antisymmetric part
of a(n) have approximately the same amplitude and are
uncorrelated, the rms of a(n) is √2 times the rms of its
antisymmetric component (Blondin & Tonry 2007).

While the r score alone is a suﬃcient measure of the
similarity of two spectra if both the training set spec-
trum and input spectra cover a wide wavelength range,
it provides a poor measure if the two spectra do not sig-
niﬁcantly overlap each other in their rest frame. This
overlap can be quantiﬁed as

lap = ln

wa
wb

,

(15)

0.40.30.20.10.00.10.20.30.4zzpeak0.20.00.20.40.6Normalised correlation amplitudeCross-correlation, c(n)Antisymmetric component, a(n)Antisymmetric rms, ah12

Muthukrishna et al.

where wa and wb are the maximum and minimum wave-
lengths at which both spectra overlap each other, re-
spectively. Combining the two scores in the product
rlap = r
lap provides a measurement of the similarity
×
between two spectra.

After cross-correlating an input spectrum with each
training set spectrum in the best matching classiﬁcation
bin, we calculate the average value from each of these
rlap scores. If the average rlap score is small (deﬁned
as rlap < 6), then we output a low reliability ﬂag to the
user to act as a warning that the automatic classiﬁcation
may not be accurate. This enables a user to more closely
inspect the spectra with a low rlap warning. We note
that the rlap scores used in DASH cannot be directly
compared with the scores used in SNID.

4.3.2. Inconsistent Classiﬁcation Warning

The second measure of warning a user about a poten-
tial misclassiﬁcation is to compare the top ranking clas-
siﬁcations provided by DASH. If the top matches are not
in neighbouring classiﬁcation bins, such that the broad
supernova type, or the supernova age are distinctly dif-
ferent from each other in the top few matches, then we
list the classiﬁcation with a warning label. More specif-
ically, we check that the top two matches are the same
broad supernova type, and also check if the age bins of
the top matches are neighbouring each other (i.e. an ex-
ample of neighbouring bins would be ‘2 to 6 days’ and
‘6 to 10 days’). If either of these checks fail, then we
output a warning to signify that there may be a mis-
classiﬁcation.

On the other hand, if the top matching classiﬁcations
are in agreement, such that they represent the same type
of supernova and neighbouring age bins, then we can
actually combine the softmax probabilities together to
provide a higher level of certainty on the classiﬁcation.
For example, in Figure 8, we can combine the top few
classiﬁcations as they are in neighbouring bins, and out-
put the combined probability, as is illustrated in the top
right of the ﬁgure.

5. PERFORMANCE

In this section we detail the performance of the main
Model 1 (see section 4.1) released in DASH. The matching
algorithms are ﬁrst validated against the testing set, and
then it is tested against recent data taken from 3 years
of ATels (Astronomical Telegrams) released by OzDES
(Tucker et al. 2015; Bassett et al. 2015; Lewis et al.
2015; Smith et al. 2015; Davis et al. 2015; Glazebrook
et al. 2015; Pan et al. 2015; Yuan et al. 2015b; Moller
et al. 2016; Sommer et al. 2016; King et al. 2016; O’Neill
et al. 2016a,b; Mudd et al. 2016; Hoormann et al. 2016;

Sharp et al. 2017; Muthukrishna et al. 2017; Calcino
et al. 2018a,b; Macaulay et al. 2018).

5.1. Testing Set

From the total number of spectra described in section
2.1, initially 80% was used for training the deep learning
algorithm, and 20% was left for evaluating the matching
performance. Once we were conﬁdent that the algorithm
was eﬀective, we retrained it using 100% of the data be-
fore testing its performance on the OzDES ATels. While
it is generally not good practice to apply a model that
has not been validated, we decided that in order to be
able to classify into classes that are not well represented
in the training set, it would be more beneﬁcial to use
as much data as we had available. We tested both the
validated model (using just 80% of the data) and the
unvalidated model (using all the available data) on the
OzDES spectra, and found that while the diﬀerence was
marginal, the model using all the data produced results
that more closely matched the OzDES ATels.

The normalised confusion matrix illustrating the clas-
siﬁcation performance on the validation set is illustrated
in Figure 6.

The predicted classes are mostly consistent with
the true classes, with most misclassiﬁcations occurring
within the same broad supernova type. For example,
the Ia-91T misclassiﬁcations were all Ia-norm super-
novae and all Ib-pec SNe were misclassiﬁed as IIb’s.
Similarly, there were some SNIb and SNIc misclassiﬁca-
tions.

5.2. OzDES ATels

To give an indication of how DASH will perform on
noisy host-contaminated spectra from large surveys
based on ﬁbre optics instead of
just long-slit spec-
troscopy, we collected spectra that have been identi-
ﬁed in all OzDES ATels from 2015 to 2017 years, and
have compared whether DASH matches these classiﬁca-
tions. This is listed in Table 2 of Appendix C. In the
OzDES ATELs, objects are often not classiﬁed as pre-
cisely as DASH, whereby the age of the supernova is not
well constrained, and the supernova may be listed with
just a broad type without a speciﬁc subtype, and may
also often be listed with a trailing question mark to
indicate that the classiﬁers were not conﬁdent on the
classiﬁcation. Moreover, it should be noted that these
classiﬁcations were obtained by using data from not just
the spectra, but by also making use of the light curve
information. To this end, the classiﬁcations were com-
pleted by two or three experienced astronomers with the
help of Superfit and SNID, but were not autonomously
classiﬁed like the DASH classiﬁcations.

DASH

13

Figure 6. Normalised confusion matrix of the classiﬁer trained on 80% of the data outlined in section 2.1 and tested on the
remaining 20% of spectra. The colour bar and value in each cell indicate the fraction of each True label that was classiﬁed as the
Predicted Label. The negative colour bar values indicates misclassiﬁcations, while positive corresponds to correct classiﬁcations.

DASH is able to provide a much more speciﬁc classiﬁ-
cation with the age and subtype constrained with useful
probabilities to indicate the conﬁdence of the ﬁt. As a
caveat, we note that objects ﬂagged as Reliable should
be considered strong classiﬁcations even if they have low
probabilities because we can sum the probabilities of the
next few similar classiﬁcations (see section 4.3.2).

Furthermore, the speed of classiﬁcation of DASH is
signiﬁcantly better than previous classiﬁcation tools.
Whereby, we were able to autonomously classify all 212
spectra in under 20 seconds, as opposed to the several
days to weeks taken to originally classify the objects.

DASH was able to classify the entire set of OzDES spec-
tra completely autonomously without any human visual
inspection. It matched the ATel classiﬁcation for 93%
of the spectra, correctly classifying 197 out of the 212
supernovae. These are listed in Table 2 in Appendix C,
and summarised in Table 1. OzDES is primarily a cos-
mological survey, and thus is biased towards following
up SNIa. The OzDES ATels are dominated by type Ia
SNe. Only a small fraction of SNII supernovae are in-

cluded in the ATels (perhaps because these can often be
identiﬁed by the presence of Hydrogen emission lines),
and only three SNIb or SNIc have been included.

All but three of the mismatches were either ﬂagged by
the False Positive Rejection scheme as Unreliable (indi-
cating that the classiﬁcation should be further checked
by a human) or were classiﬁed as a ‘Ic-broad’. In general,
we consider that classiﬁcations into the Ic-broad class
are usually highly host-contaminated spectra, and are
not usually actually Ic-broad type SNe. Two of the other
three misclassﬁications were typed as ‘SNIa?’, indicating
that the ATel classiﬁcations were uncertain. The accu-
racy of the classiﬁcations coupled with the false positive
rejection scheme ultimately enables astronomers to only
need to look at a very small subset of the entire testing
set, with most spectra being classiﬁed autonomously.

5.3. Comparison to previous software

Overall, DASH is a more eﬀective classiﬁcation tool
than previous tools for four important reasons: speed,

Ia-normIa-91TIa-91bgIa-csmIa-02cxIa-pecIb-normIbnIIbIb-pecIc-normIc-broadIc-pecIIPIILIInPredictedlabelIa-normIa-91TIa-91bgIa-csmIa-02cxIa-pecIb-normIbnIIbIb-pecIc-normIc-broadIc-pecIIPIILIInTruelabel0.990.000.010.000.000.000.000.000.000.000.000.000.000.000.000.000.220.780.000.000.000.000.000.000.000.000.000.000.000.000.000.000.080.000.920.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.001.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.001.000.000.000.000.000.000.000.000.000.000.000.000.420.210.000.000.170.210.000.000.000.000.000.000.000.000.000.000.060.000.000.000.030.000.690.000.000.000.090.120.000.000.000.000.000.000.000.000.000.000.001.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.900.000.000.100.000.000.000.000.000.000.000.000.000.000.000.001.000.000.000.000.000.000.000.000.000.000.030.000.000.000.110.000.000.000.770.090.000.000.000.000.060.000.000.000.000.000.000.000.000.000.030.920.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.001.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.001.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.001.000.000.000.000.000.000.000.000.000.000.000.000.000.200.000.000.000.80−1.00−0.75−0.50−0.250.000.250.500.751.0014

Muthukrishna et al.

ATel class # of SNe # of DASH matches

Ia
Ia?
II
II?
Ibc
Ibc?

129
43
28
9
1
2

127
34
25
7
1
2

Table 1. The distribution of the 212 OzDES ATel classiﬁ-
cations released between 2015-2017 is shown in the ﬁrst two
columns. The ‘?’ next to the supernova type was used in the
ATel classiﬁcations to indicate that the authors of the ATel
were not conﬁdent in their classiﬁcation. The third column
lists how many of the objects in each class were also correctly
classiﬁed by DASH.

accuracy, classiﬁcation speciﬁcity, and its installation
and ease of use.

The main improvement of DASH over current tools is
its signiﬁcant speed increase. The primary reason for
the increase in speed is that machine learning does not
iteratively compare with individual spectra, but instead
classiﬁes based on features in the spectrum. Thus, unlike
SNID and Superfit which increase their computation
time linearly with the number of spectra in the training
data, DASH is able to separate the training and testing
stages. The classiﬁcation of a single supernova takes
only a few seconds in DASH, but can take several tens of
minutes in Superfit. Moreover, while SNID is already a
fast program, DASH is even faster, and this is particularly
true when classifying several spectra at once. By making
use of the DASH library functions, a user is able to classify
hundreds or thousands of objects within seconds.

Unlike any other similar software, DASH does not iter-
atively search though and compare an input spectrum
to each training set spectrum. Instead, it learns from
the aggregate set of supernovae in a particular classiﬁ-
cation bin, and trains on the speciﬁc features that make
up a supernova type using a convolutional neural net-
work. The advantage of this is that a classiﬁcation is
always made based on the entire set of spectra within
a particular classiﬁcation bin, rather than a single spec-
trum. This reduces the impact of spectra with incorrect
classiﬁcations or unrepresentative spectra.

Finally, we have made the installation and usage very
simple.
It can be installed without having to worry
about dependencies by making use of the Python Pack-
aging Index. It also enables the simple classiﬁcation of
hundreds of spectra with just two lines of code (see sec-
tion B.3).

Nonetheless, software like Superfit and SNID still
provide independent classiﬁcation measures, and used

in conjunction with DASH, a robust classiﬁcation scheme
can be achieved.

6. CONCLUSIONS

We have developed a novel classiﬁcation tool by us-
ing a contemporary convolutional neural network with
advanced machine learning techniques. We have di-
verged from all similar tools which employ either a cross-
correlation or chi-squared template matching algorithm.
By doing so, we have improved upon previous work to
enable DASH to be orders of magnitude faster than pre-
vious tools, autonomous, more accurate and precise in
its classiﬁcation, and much easier to install and use.

We have collated 4831 supernova spectra from the CfA
Supernova Program, BSNIP, and the stripped-envelope
collection from Liu and Modjaz. Using this as a training
set, we have validated the performance of our classiﬁer
on three years of ATels from OzDES. The results indi-
cate that DASH is well-suited to classify the large number
of spectra soon to be observed by upcoming large scale
spectroscopic surveys, such as DESI (DESI Collabora-
tion et al. 2016) and 4MOST (de Jong et al. 2019).

Furthermore, these surveys will have less biased and
much more complete samples of supernovae that are bet-
ter able to capture the diversity in the non-SNIa popula-
tions. To improve the classiﬁcation performance of DASH
further, we can add this larger and more diverse range
of supernovae to our training set. Unlike previous classi-
ﬁcation tools, increasing the size of the training set does
not decrease the classiﬁcation time. However, the train-
ing of the classiﬁer can be computationally expensive,
and thus it will be most suitable to retrain DASH when-
ever more spectra that encompass a signiﬁcantly deeper
and wider range of spectral classes becomes available.

While this is an expansive set, as future surveys in-
crease the supernova catalogue, we can increase the size
of our training set to retrain and improve the perfor-
mance of DASH even further.

A systematic preprocessing algorithm, and data aug-
mentation techniques have enabled us to train a robust
learning algorithm. The training of four independent
models has further allowed us to classify not only the
supernova type and age, but also its host galaxy and
redshift.

In a beta version of the DASH release, we have included
extra Superluminous Supernova (SLSN) classes as a new
classiﬁcation type, and plan to release this in an upcom-
ing version.

Moreover, while we have primarily developed this tool
for supernova classiﬁcation, there is no signiﬁcant reason
why this approach can’t be extended to other types of

DASH

15

spectra: from diﬀerent types of stars, galaxies, or AGN
in the future.

We have publicly released the software with a graph-
interface and a python library available on pip
ical
and GitHub, and it has already been used in several
published supernova classiﬁcations. Ultimately, the
speed, accuracy, user-friendliness and versatility of DASH
presents an advancement to existing spectral classiﬁca-
tion tools. As such, DASH is a viable alternative or com-
plementary spectral classiﬁer for the transient commu-
nity.

DM was supported by an Australian Government
Research Training Program (RTP) Scholarship and

the Australian Research Council Centre for All-Sky
Astrophysics (CAASTRO), through project number
CE110001020. The models were trained with the Obelix
supercomputer from the School of Mathematics and
Physics at the University of Queensland and the servers
at the Research School of Astronomy and Astrophysics
at the Australian National University.

Software:

AstroPy (Astropy Collaboration et al.
2013), TensorFlow (Abadi et al. 2016), NumPy (van der
Walt et al. 2011), SciPy (Jones et al. 2001–), Qt.

REFERENCES

Abadi, M., Barham, P., Chen, J., et al. 2016, in Proc. 12th

Davis, T. M., M¨ortsell, E., Sollerman, J., et al. 2007, ApJ,

USENIX Conference on Operating Systems Design and

666, 716

Implementation, OSDI’16 (Berkeley, CA, USA: USENIX

Davis, T. M., Kim, A. G., Macualay, E., et al. 2015, The

Association), 265–283

Astronomer’s Telegram, 8367

Aniyan, A. K., & Thorat, K. 2017, ApJS, 230, 20

de Jong, R. S., Agertz, O., Berbel, A. A., et al. 2019, The

Astier, P., Guy, J., Regnault, N., et al. 2006, A&A, 447, 31

Messenger, 175, 3

Astropy Collaboration, Robitaille, T. P., Tollerud, E. J.,

DESI Collaboration, Aghamousa, A., Aguilar, J., et al.

et al. 2013, A&A, 558, A33

Baldry, I. K., Alpaslan, M., Bauer, A. E., et al. 2014,

MNRAS, 441, 2440

Ball, N. M., & Brunner, R. J. 2010, International Journal

of Modern Physics D, 19, 1049

Bassett, B., Kasai, E., Crawford, S., et al. 2015, The

Astronomer’s Telegram, 8164

Blondin, S., & Tonry, J. L. 2007, ApJ, 666, 1024

Blondin, S., Matheson, T., Kirshner, R. P., et al. 2012, AJ,

143, 126

Boureau, Y., Ponce, J., & Lecun, Y. 2010, in ICML 2010 -

Proceedings, 27th International Conference on Machine

Learning, 111–118

Cabrera-Vives, G., Reyes, I., F¨orster, F., Est´evez, P. A., &

Maureira, J.-C. 2017, ApJ, 836, 97

Calcino, J., Davis, T. M., Hoormann, J. K., et al. 2018a,

The Astronomer’s Telegram, 11146

—. 2018b, The Astronomer’s Telegram, 11147

Charnock, T., & Moss, A. 2017, ApJL, 837, L28

Childress, M. J., Lidman, C., Davis, T. M., et al. 2017,

MNRAS, 472, 273

Cybenko, G. 1989, Mathematics of Control, Signals and

Systems, 2, 303. https://doi.org/10.1007/BF02551274

Dark Energy Survey Collaboration, Abbott, T., Abdalla,

2016, arXiv e-prints, arXiv:1611.00036

Dieleman, S., Willett, K. W., & Dambre, J. 2015, MNRAS,

450, 1441

Duda, R. O., Hart, P. E. P. E., & Stork, D. G. 2012,

Pattern classiﬁcation (Wiley), 654

Foley, R. J., Challis, P. J., Chornock, R., et al. 2013, ApJ,

767, 57

Glazebrook, K., Amon, A., Lidman, C., et al. 2015, The

Astronomer’s Telegram, 8413

Guillochon, J., Parrent, J., Kelley, L. Z., & Margutti, R.

2017, ApJ, 835, 64

H´ala, P. 2014, ArXiv e-prints, arXiv:1412.8341

Hinton, G. E., & Salakhutdinov, R. R. 2006, Science, 313,

504

Hinton, S. R., Davis, T. M., Lidman, C., Glazebrook, K., &
Lewis, G. F. 2016, Astronomy and Computing, 15, 61

Hoormann, J. K., Asorey, J., Carollo, D., et al. 2016, The

Astronomer’s Telegram, 9855

Howell, D. A., Sullivan, M., Perrett, K., et al. 2005, ApJ,

634, 1190

Jones, E., Oliphant, T., Peterson, P., et al. 2001–, SciPy:

Open source scientiﬁc tools for Python, ,

King, A., Moller, A., Sommer, N. E., et al. 2016, The

Astronomer’s Telegram, 9570

Kingma, D. P., & Ba, J. 2014, ArXiv e-prints,

F. B., et al. 2016, MNRAS, 460, 1270

arXiv:1412.6980

16

Muthukrishna et al.

Krizhevsky, A., Sutskever, I., & Hinton, G. E. 2012, in

O’Neill, C. R., Moller, A., Sommer, N. E., et al. 2016a, The

Proc. 25th International Conference on Neural
Information Processing Systems - Volume 1, NIPS’12
(USA: Curran Associates Inc.), 1097–1105

Lewis, G. F., Mould, J., Lidman, C., et al. 2015, The

Astronomer’s Telegram, 8167

Li Deng. 2012, IEEE Signal Processing Magazine, 29, 141
Lintott, C. J., Schawinski, K., Slosar, A., et al. 2008,

MNRAS, 389, 1179

Liu, Y., & Modjaz, M. 2014, ArXiv e-prints,

arXiv:1405.1437

Liu, Y.-Q., Modjaz, M., Bianco, F. B., & Graur, O. 2016,

ApJ, 827, 90

Lochner, M., McEwen, J. D., Peiris, H. V., Lahav, O., &

Winter, M. K. 2016, ApJS, 225, 31

Astronomer’s Telegram, 9636

—. 2016b, The Astronomer’s Telegram, 9637

Pan, Y.-C., Foley, R. J., Galbany, L., et al. 2015, The

Astronomer’s Telegram, 8460

Pastorello, A., Quimby, R. M., Smartt, S. J., et al. 2008,

MNRAS, 389, 131

Perlmutter, S., Aldering, G., Goldhaber, G., et al. 1999,

ApJ, 517, 565

Pinto, P. A., & Eastman, R. G. 2001, NewA, 6, 307

Razavian, A. S., Azizpour, H., Sullivan, J., & Carlsson, S.

2014, in Proc. 2014 IEEE Conference on Computer

Vision and Pattern Recognition Workshops, CVPRW ’14

(IEEE Computer Society), 512–519

LSST Science Collaboration, Abell, P. A., Allison, J., et al.

Riess, A. G., Filippenko, A. V., Challis, P., et al. 1998, AJ,

2009, ArXiv e-prints, arXiv:0912.0201

116, 1009

Macaulay, E., Allam, S., Tucker, D., et al. 2018, The

Sasdelli, M., Ishida, E. E. O., Vilalta, R., et al. 2016,

Astronomer’s Telegram, 11148

MNRAS, 461, 2044

Matheson, T., Kirshner, R. P., Challis, P., et al. 2008, AJ,

Schmidt, B. P., Suntzeﬀ, N. B., Phillips, M. M., et al. 1998,

135, 1598

ApJ, 507, 46

Modjaz, M., Liu, Y. Q., Bianco, F. B., & Graur, O. 2016,

Sharp, R., Zhang, B., Sommer, N. E., et al. 2017, The

ApJ, 832, 108

Modjaz, M., Blondin, S., Kirshner, R. P., et al. 2014, AJ,

147, 99

M¨oller, A., Ruhlmann-Kleider, V., Leloup, C., et al. 2016,

JCAP, 12, 008

Moller, A., Tucker, B. E., Yuan, F., et al. 2016, The

Astronomer’s Telegram, 8673

Momcheva, I., & Tollerud, E. 2015, ArXiv e-prints,

arXiv:1507.03989

Moss, A. 2018, ArXiv e-prints, arXiv:1810.06441
Mudd, D., Martini, P., Lewis, G. F., et al. 2016, The

Astronomer’s Telegram, 9742

Astronomer’s Telegram, 9961

Silverman, J. M., Foley, R. J., Filippenko, A. V., et al.

2012, MNRAS, 425, 1789

Smith, M., Sullivan, M., Childress, M., et al. 2015, The

Astronomer’s Telegram, 8176

Sommer, N., Tucker, B. E., Moller, A., et al. 2016, The

Astronomer’s Telegram, 9504

Szegedy, C., Liu, W., Jia, Y., et al. 2014, ArXiv e-prints,

arXiv:1409.4842

Tonry, J., & Davis, M. 1979, AJ, 84, 1511

Tucker, B. E., Sharp, R., Yuan, F., et al. 2015, The

Muthukrishna, D., Narayan, G., Mandel, K. S., Biswas, R.,

Astronomer’s Telegram, 8137

& Hloˇzek, R. 2019, PASP, 131, 118002

van der Walt, S., Colbert, S. C., & Varoquaux, G. 2011,

Muthukrishna, D., & Parkinson, D. 2016, JCAP, 11, 052
Muthukrishna, D., Sharp, R. G., Tucker, B. E., et al. 2017,

Computing in Science and Engineering, 13, 22

Yuan, F., Lidman, C., Davis, T. M., et al. 2015a, MNRAS,

The Astronomer’s Telegram, 10759

Nair, V., & Hinton, G. E. 2010, in Proc. the 27th

International Conference on Machine Learning, ICML’10
(USA: Omnipress), 807–814

Narayan, G., Zaidi, T., Soraisam, M. D., et al. 2018, ApJS,

236, 9

452, 3047

Yuan, F., Tucker, B. E., Lidman, C., et al. 2015b, The

Astronomer’s Telegram, 8464

Zhang, B. R., Childress, M. J., Davis, T. M., et al. 2017,

MNRAS, 471, 2254

DASH

17

APPENDIX

A. DATA DISTRIBUTION

Figure 7. The distribution of the ﬁnal dataset used to train the machine learning model. The number of spectra for each
subtype (rows) and each corresponding age in days since maximum (columns) are listed. The colorbar ranges from 0 to 50
spectra.

DASH is intended to be an easy to use supernova classiﬁcation tool. It has the functionality to quickly classify a single
spectrum, but its main advantage over existing tools lies in its ability to automatically classify hundreds or thousands
of objects in just a few seconds. As such, it is intended to be used for large scale transient surveys, and is currently
being used in the Australian sector of the Dark Energy Survey (OzDES).

B. USAGE

B.1. Platform

We developed DASH (Deep Automatic Supernova and Host classiﬁer) as an oﬄine, cross-platform and standalone
program based in Python. It has been tested to eﬀectively run on most Mac, Linux and Windows distributions, with
stringent testing on Mac Sierra and Ubuntu. We have ensured that the installation process is extremely simple, and
does not require the messiness of worrying about installing dependencies. The easiest way to install DASH is to run
pip install astrodash --upgrade
in the command line, which will automatically install nearly every dependency. This simplicity in installation, and the
fact that it uses Python, which is currently the most popular programming language among astronomers (Momcheva
& Tollerud 2015), is a huge advantage compared to previous supernova classiﬁcation tools.

-20to-18-18to-14-14to-10-10to-6-6to-2-2to22to66to1010to1414to1818to2222to2626to3030to3434to3838to4242to4646to50II-pecIInIILIIPIc-pecIc-broadIc-normIb-pecIIbIbnIb-normIa-pecIaxIa-csmIa-91bgIa-91TIa-norm132322233342321632002004123100030231000000034000000120000181913156838537422000039701043020002004153139272514171611126423901111211615126126146126826002120001500000010414139131318131512964687230000003632311311211111420212616141912106710572500557151117864757661100010147103468311220001001121100110322000102426382423201910101322650018444935182417262321171310810140246176216280271229181156110938681506147280102030405018

Muthukrishna et al.

There are six Python based dependencies used in DASH, which are all automatically updated and installed with
pip. We make signiﬁcant use of Google Brain’s new TensorFlow Python library (Abadi et al. 2016) to develop the
convolutional neural networks, but also make considerable use of NumPy (van der Walt et al. 2011), SciPy (Jones et al.
2001–), AstroPy (Astropy Collaboration et al. 2013), and Qt with PyQt and PyQtgraph for the design of the graphical
user interface. The code-base is open source and publicly available on GitHub7 and is well-documented8.

Two diﬀerent interfaces are available in the DASH package: a graphical interface and a Python library. We detail

these in the following subsections.

B.2.1. Graphical User Interface

B.2. Interfaces

Figure 8. DASH graphical interface. An example classiﬁcation of the OzDES DES16C2ma spectrum (as also illustrated in
Figure 3) is shown. Using the agnostic redshift model, the software predicts that the input spectrum is a Ia-91T supernova at
18 to 22 days past maximum with a 55.6% softmax regression conﬁdence. The input spectrum is plotted in the bottom panel
(green) against one of the example spectra from the training set (red). The cross correlation is plotted in the smaller graph,
with the predicted redshift being z = 0.24. The probabilities of the top six classiﬁcations can be combined, because they are all
consistent with each other, to give a combined softmax regression conﬁdence of 99.92% that the supernova is a SNIa between
10 to 26 days past maximum. Both the rlap and reliable matches ﬂags (see section 4.3 have passed and are written in green
text to indicate that DASH is conﬁdent about the classiﬁcation.

The graphical interface enables users to visually inspect the DASH classiﬁcations while being able to tune various
parameters. It has been designed to be user-friendly, intuitive, and to contain minimal clutter as illustrated in the ex-
ample screenshot in Figure 8. More detailed instructions on the usage have been provided in the online documentation,
but we brieﬂy outline the main components in the following.

On the left panel under the Priors header, the user can make a series of selections which alter the spectrum that
is passed into the classiﬁcation algorithm. The ﬁrst selection enables the user to choose from one of the four models
listed in section 4.1 by selecting a combination of the two check boxes. Next, if the user wishes to avoid bad parts
of the spectrum caused by excessive noise, dichroic jumps or otherwise, the wavelength range of the input spectrum
In the case of very noisy spectra, a smoothing option, which applies a low-pass median ﬁlter at
can be changed.

7 https://github.com/daniel-muthukrishna/astrodash/
8 https://astrodash.readthedocs.io

DASH

19

varying window sizes (as deﬁned in equation 3), has also been provided. Finally, as well as the softmax probabilities
used as a ranking system in DASH, users who are familiar with SNID may also choose to display rlap values which can
act as a second measure of the quality of each classiﬁcation (see section 4.3.1). As cross-correlations are relatively
slow, checking this box will signiﬁcantly increase the total classiﬁcation time. The listed rlap scores are calculated by
averaging the scores from the cross correlation of the input spectrum with each training set spectrum in a particular
classiﬁcation bin.

Once, the priors have been chosen, and the best matching classiﬁcations have been ﬁlled, the right section of the
interface will update to include a few important sections. On the bottom panel, we make use of PyQtgraph to plot
the preprocessed input spectrum against diﬀerent training set spectra. Above this, we also plot the cross-correlation
function against redshift for each spectrum similarly to Figure 5. Under the Best Matches header, the top ranking
classiﬁcation bins are shown with columns for the type, age, host galaxy, softmax probability, redshift, and rlap score.
Depending on the Priors selections and the chosen model, only some of these headers will be displayed. On the
top right, the best matching classiﬁcation will be listed by combining the top ranked classiﬁcations (as detailed in
section 4.3.2). A ﬂag indicating whether the match should be considered reliable or not is also shown based on the
false positive rejections tests outlined in section 4.3. Under the Analyse selection header, a user can choose to plot a
diﬀerent classiﬁcation bin, by selecting the type, age, and host of a supernova. Clicking the arrows will switch between
the diﬀerent spectra in a particular classiﬁcation bin. Finally, the user also has the option to change the fraction of
host galaxy light displayed in the training set spectrum and the redshift of the input to visualise how this aﬀects the
spectral features. By default, a spectrum from the best matching classiﬁcation bin is plotted ﬁrst.

A Python library has also been developed so that several classiﬁcations can be made autonomously without the
requirement of visual inspection. Classiﬁcation of multiple spectra is very simple, requiring only a couple of lines of
code:

B.3. Python Library

import astrodash

classify = astrodash.Classify(filenames, redshifts)
print(classify.list_best_matches())
astrodash.plot_with_gui(indexToPlot=0)

The only inputs required are a list of ﬁlenames containing the spectra which are to be classiﬁed, and an optional list
of corresponding known redshifts. More optional arguments selecting which model should be applied, the amount of
smoothing, and whether rlap scores should be calculated can also be speciﬁed. The details of these optional arguments
are outlined in the documentation. However, it should be noted that with just those two lines of code, several hundreds
of spectra can be classiﬁed automatically and within just a few seconds or minutes, with the best matches being saved
to a human-readable text ﬁle. The ﬁnal line enables the ﬁrst spectral ﬁle in the input list to be plotted and analysed
on the graphical interface.

B.4. Usage with Open Supernova Catalogs
DASH also interfaces with the online Open Supernova Catalog9 (Guillochon et al. 2017). Changing the ﬁlename input
in either interface with something in the format osc-name-age index (e.g. osc-sn2002er-10) will download the spectrum
from the OSC, and classify it.

B.5. Development and Contribution

The DASH source code currently consists of several thousand lines of code across more than 30 Python ﬁles which are
open-source and publicly hosted on a git repository on GitHub at https://github.com/daniel-muthukrishna/astrodash.
GitHub provides issue tracking to keep track of open issues and feature requests. Users are encouraged to report
bugs or issues, and to request new useful features with this issue tracker. Moreover, this project has been developed in
an object oriented fashion, so that diﬀerent code implementations can be relatively easily changed. One such example

9 https://sne.space/

20

Muthukrishna et al.

is the ability to easily change the deep learning architecture by just replacing one Python ﬁle. To this end, as more
advanced neural network architectures become available, the learning algorithm can be improved or replaced.

Furthermore, as more supernova spectra are observed by large scale surveys, the training set should be updated.
In fact, the more spectra that we can train the CNN with, the better the classiﬁcation algorithm will become. To
this end, if any users of the software would like to increase the size of the training set, they should contact us so that
better models can be trained. Alternatively, simply updating the spectra in the training set directory on GitHub and
carefully running the ‘create and save data ﬁles.py’ ﬁle will begin to train a new model. It should be noted, that this
training process may take a signiﬁcant amount of computation time: usually on the order of hours depending on the
computational resources available.

Finally, at the time of writing, the project has just the lead author as the sole active developer of the software.
However, if users of the software would like to implement their own features which may be useful to others, we
encourage them to contact us so that we can add them to the GitHub collaborators.

C. OZDES ATEL CLASSIFICATION COMPARISON

Name

Redshift

DES15X3hp
DES15X3dyu
DES15X3auw
DES15X1bw
DES15E2nk
DES15E2atw
DES15C3fx
DES15S2dye
DES15S1by
DES15C3edd
DES15C2dyj
DES15C2eaz
DES15C2aty
DES15C1atm
DES15X3kqv
DES15E1kwg
DES15X1ith
DES15E1kvp
DES15C3efn
DES15X3iv
DES15X3itc
DES15X3kxu
DES15E1iuh
DES15X2asq
DES15S2ar
DES15C1eat
DES15X1ebs
DES15C3bj
DES15C3axd
DES15C1ebn
DES15C3lvt
DES15E2cwm
DES15S2og
DES15S1cj

0.236
0.425
0.151
0.13
0.308
0.147
0.2
0.26
0.129
0.36
0.395
0.062
0.149
0.207
0.142
0.105
0.16
0.442
0.077
0.018
0.338
0.345
0.105
0.28
0.247
0.45
0.58
0.287
0.42
0.41
0.4
0.291
0.38
0.166

ATel
Classiﬁcation
Ia +3 weeks
Ia max
Ia +2 weeks
Ia +5 weeks
Ia +1 week
Ia +1 week
Ia +3 weeks
Ia +1 week
II post-max
Ia max
Ia +1 week
II max
Ia +2 weeks
Ia +2 weeks
Ia at max
Ia at max
Ia +1 week
Ia At max
Ia +2 weeks
Ia +1 month
Ia +2-5 days post max
Ia At max
II at max
Ia +7 days
Ia? +16 days
Ia? +7 days
Ia? pre-max
II? post-max
Ia? max
Ia? max
Ia? post-max
Ia? +10 days
Ia? post-max
II? post-max

Classiﬁcation
Ia-norm (18 to 22)
Ia-norm (-10 to -6)
Ia-norm (10 to 14)
Ia-91T (42 to 46)
Ia-91T (6 to 10)
Ia-norm (18 to 22)
Ia-csm (10 to 14)
Ia-norm (-2 to 2)
Ic-broad (-6 to -2)
Ia-91T (-2 to 2)
Ia-norm (2 to 6)
IIP (2 to 6)
Ia-norm (18 to 22)
Ia-norm (18 to 22)
Ia-norm (2 to 6)
Ia-norm (-6 to -2)
Ia-norm (6 to 10)
Ia-norm (2 to 6)
Ia-norm (14 to 18)
Ia-norm (46 to 50)
Ia-91T (-2 to 2)
Ia-norm (-2 to 2)
IIP (6 to 10)
Ia-91T (6 to 10)
Ia-norm (10 to 14)
Ia-norm (2 to 6)
Ic-broad (2 to 6)
Ic-broad (-6 to -2)
Ia-pec (2 to 6)
Ic-broad (2 to 6)
Ic-broad (2 to 6)
Ia-91T (10 to 14)
Ia-norm (6 to 10)
IIP (6 to 10)

DASH
Probability Reliability

Match?

0.835
0.938
0.994
0.984
0.947
0.911
0.999
0.953
0.999
0.707
0.955
0.905
0.405
0.59
0.996
0.709
0.905
1.0
0.964
1.0
1.0
0.94
0.918
0.655
0.977
0.612
0.605
0.807
0.997
0.904
0.596
0.964
0.744
0.832

Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)

DASH

21

DES15S1ebd
DES15S2dyb
DES15X3ﬂq
DES15E2kvn
DES15C2lpp
DES15C2lna
DES15X2lxw
DES15X2mei
DES15X3lya
DES15S1mjm
DES15S1lyi
DES15S2mpl
DES15S2mpg
DES15E1neh
DES15X3mpq
DES15X2mpm
DES15X2mku
DES15C1mvy
DES15C1mqf
DES15X3naa
DES15X3nad
DES15X2mzv
DES15X2nkl
DES15C2njv
DES15C1nfb
DES15E2nlz
DES15E1nei
DES15C3mpk
DES15C2oxo
DES15C3orz
DES15C3olc
DES16X1ey
DES16C3ea
DES16E1ah
DES16E1md
DES16C3bq
DES16C3fv
DES16X3jj
DES16X3es
DES16X3hj
DES16X3er
DES16X3km
DES16E2dd
DES16E1de
DES16X2auj
DES16X1ge
DES16C2ma
DES16C2aiy
DES16X3biz
DES16X3aqd

0.408
0.56
0.368
0.208
0.181
0.069
0.197
0.248
0.29
0.26
0.359
0.257
0.186
0.39
0.188
0.235
0.09
0.32
0.111
0.331
0.1
0.313
0.304
0.181
0.13
0.41
0.313
0.182
0.336
0.18
0.067
0.076
0.217
0.149
0.178
0.241
0.322
0.238
0.554
0.308
0.167
0.054
0.075
0.292
0.144
0.25
0.24
0.182
0.24
0.033

Ia? max
Ia? +7 days
Ia? +10 days
Ia? max
II? post-max
II post-max
Ia +1 week
Ia max
Ia max
Ia? +1 week
Ia? +3 weeks
Ia +1 week
Ia max
Ia? max
II +1 month
Ia +2 week
II +1 month
Ia max
Ia +3 weeks
Ia -4 days
II max
Ia max
Ia max
Ia max
Ia max
Ia -5 days
Ia max
Ia +10 days
Ia? +9 days
Ia +5 days
Ia +24 days
SNII post-max
SNIa post-max
SNII post-max
SNIa max
SNIa max
SNIa -6 days
SNII? post-max
SNIa? max
SNIa max
SNIa +2 days
SNII post-max
SNIa +3 days
SNIa? +2 days
Ia max
Ia post-max
Ia post-max
Ia post-max
Ia pre-max
II-P post-max

Ia-91bg (2 to 6)
Ic-broad (-10 to -6)
Ia-91bg (-2 to 2)
Ia-norm (-2 to 2)
Ic-broad (2 to 6)
IIn (10 to 14)
Ia-norm (2 to 6)
Ia-norm (-6 to -2)
Ia-norm (2 to 6)
Ia-norm (2 to 6)
Ia-pec (10 to 14)
Ia-norm (2 to 6)
Ia-91T (2 to 6)
Ic-norm (2 to 6)
IIP (10 to 14)
Ia-pec (10 to 14)
IIP (6 to 10)
Ia-91T (6 to 10)
Ia-norm (14 to 18)
Ia-91T (6 to 10)
IIP (2 to 6)
Ia-91T (6 to 10)
Ia-norm (-2 to 2)
Ia-norm (2 to 6)
Ia-norm (2 to 6)
Ia-norm (-2 to 2)
Ia-norm (2 to 6)
Ia-91T (6 to 10)
Ia-norm (6 to 10)
Ia-91bg (10 to 14)
Ia-norm (18 to 22)
IIn (6 to 10)
Ia-norm (14 to 18)
Ia-norm (26 to 30)
Ia-91T (-2 to 2)
Ia-norm (-2 to 2)
Ia-norm (-10 to -6)
IIL (10 to 14)
Ia-pec (2 to 6)
Ia-91T (-2 to 2)
Ia-91T (-2 to 2)
IIP (6 to 10)
Ia-norm (2 to 6)
Ia-norm (-10 to -6)
Ia-norm (2 to 6)
Ia-norm (22 to 26)
Ia-norm (18 to 22)
Ia-norm (2 to 6)
Ia-norm (-6 to -2)
IIb (-14 to -10)

0.504
0.514
0.5952
0.971
1.0
0.897
0.984
0.527
0.709
0.574
0.602
0.998
0.402
1.0
0.832
0.964
0.999
0.98
0.959
0.724
0.508
0.929
0.797
0.559
0.57
0.789
0.97
1.0
0.69
0.844
1.0
0.818
0.925
0.999
0.982
1.0
0.546
1.0
0.996
0.899
1.0
1.0
0.964
0.568
0.94
0.988
0.658
0.993
0.982
0.961

Unreliable
Reliable
Unreliable
Reliable
Unreliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable

(cid:88)

x
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

22

Muthukrishna et al.

DES16E2aoh
DES16C3bq
DES16E2bht
DES16E2bkg
DES16X2crt
DES16E2cjg
DES16X3cpl
DES16C3at
DES16C1bnt
DES16C2cbv
DES16C1cbg
DES16X2bvf
DES16X2cpn
DES16X2crr
DES16X2bkr
DES16X2ceg
DES16E2cqq
DES16E2clk
DES16E2crb
DES16S1cps
DES16E1ciy
DES16X2dqz
DES16X1der
DES16S2drt
DES16E1eef
DES16E1eae
DES16X1dbx
DES16S2dfm
DES16S2ean
DES16X1dbw
DES16X1drk
DES16E2drd
DES16E2cxw
DES16C3dhv
DES16X3dfk
DES16E1dic
DES16E1dcx
DES16S2ﬀk
DES16X1chc
DES16X1few
DES16X2dzz
DES16C1fgm
DES16S1ﬀb
DES16X3enk
DES16X3eww
DES16C2ege
DES16X3dvb
DES16C3elb
DES17E2ci
DES17E2ce

0.403
0.237
0.392
0.478
0.57
0.48
0.205
0.217
0.351
0.109
0.111
0.135
0.28
0.312
0.159
0.335
0.426
0.367
0.229
0.274
0.174
0.204
0.453
0.331
0.32
0.534
0.345
0.3
0.161
0.336
0.463
0.27
0.293
0.3
0.15
0.207
0.453
0.373
0.043
0.311
0.325
0.361
0.164
0.331
0.445
0.348
0.329
0.429
0.127
0.269

Ia post-max
Ia post-max
SNIa +3 days
SNIa max
SNIa? near-max
SNIa near-max
SNII? near-max
SNII +60 days
SNIa +1 month
SNII near-max
SNII post-max
SNIb post-max
SNIa +1 week
SNIa near-max
SNII post-max
SNIa near-max
SNIa -1 week
SNIa near-max
SNIa near-max
SNIa -1 week
SNIa near-max
SNIb/c? max
SNIa +1 week
SNIa max
SNIa max
SNIa max
SNIa +1 week
SNIa near-max
SNIa pre-max
SNIa +1 week
SNIa near-max
SNIa near-max
SNIa +2 weeks
SNIa near-max
SNIa near-max
SNIa max
SNIa +2 weeks
SNIa? -1 week
SNIa +2 months
SNIa -1 week
SNIa? +2 weeks
SNIa -4 days
SNIa near-max
SNIa? +1 week
SNIa? max
SNIa? +1 month
SNII near-max
SNIa +1 week
SNII post-max
SNIa +3 weeks

Ia-91T (-6 to -2)
Ia-norm (2 to 6)
Ia-norm (-2 to 2)
Ia-norm (-2 to 2)
Ia-norm (-2 to 2)
Ia-91T (-6 to -2)
IIn (-2 to 2)
Ic-broad (2 to 6)
Ia-norm (22 to 26)
IIP (2 to 6)
IIP (-2 to 2)
Ib-norm (14 to 18)
Ia-norm (6 to 10)
Ia-norm (-2 to 2)
IIP (22 to 26)
Ia-norm (6 to 10)
Ia-norm (-2 to 2)
Ia-91T (-2 to 2)
Ia-norm (2 to 6)
Ia-91T (-6 to -2)
Ia-norm (2 to 6)
Ic-norm (-2 to 2)
Ia-norm (2 to 6)
Ia-91T (-10 to -6)
Ia-91T (-2 to 2)
Ia-norm (-2 to 2)
Ia-91T (6 to 10)
Ia-norm (2 to 6)
Ia-norm (-6 to -2)
Ia-91T (6 to 10)
Ia-norm (-2 to 2)
Ia-norm (-2 to 2)
Ia-norm (10 to 14)
Ia-norm (2 to 6)
Ia-norm (2 to 6)
Ia-norm (2 to 6)
Ia-norm (10 to 14)
Ia-91T (-2 to 2)
Ic-norm (34 to 38)
Ia-norm (-6 to -2)
Ia-norm (10 to 14)
Ia-91T (-2 to 2)
Ia-norm (-6 to -2)
Ia-norm (10 to 14)
Ia-norm (-2 to 2)
Ic-norm (10 to 14)
Ic-broad (-10 to -6)
Ic-norm (10 to 14)
IIn (42 to 46)
Ia-norm (18 to 22)

0.864
0.868
0.988
0.599
0.622
0.563
0.991
0.881
0.994
0.822
0.999
0.65
1.0
0.996
0.953
0.709
0.362
0.99
0.998
0.718
0.992
0.993
0.982
0.737
0.582
0.994
0.942
1.0
0.772
1.0
1.0
0.927
0.826
0.999
0.986
0.985
0.928
0.754
0.965
0.946
0.771
0.979
0.552
0.725
0.995
0.999
0.895
0.666
0.764
0.969

Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Unreliable
Reliable
Reliable

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)

x
(cid:88)
(cid:88)

DASH

23

DES17E1by
DES17E2bx
DES17E2bw
DES17E2ar
DES17E2aq
DES17E2b
DES17E2a
DES17X3ct
DES17X3cb
DES17X3ca
DES17X3bd
DES17X3az
DES17C3eg
DES17C3de
DES17E2cc
DES17S2byx
DES17E2bhj
DES17X3bhi
DES17X3btv
DES17S2als
DES17E1byv
DES17E2bro
DES17X1boi
DES17E1bmf
DES17C3biz
DES17E1axa
DES17X1ayb
DES17X1axb
DES17X1aow
DES17X1alj
DES17E2sp
DES17C3dw
DES17X1gd
DES17S2bph
DES17S2bop
DES17E2boo
DES17X2bmp
DES17E2bmb
DES17X2blx
DES17C1azd
DES17X2bﬁ
DES17E2arn
DES17X2alq
DES17X2agh
DES17S2oo
DES17S2lg
DES17X2abj
DES17E1bud
DES17C2bqz
DES17E1bqq

0.287
0.272
0.147
0.513
0.352
0.227
0.295
0.206
0.317
0.198
0.141
0.56
0.117
0.107
0.149
0.31
0.186
0.39
0.407
0.388
0.378
0.223
0.565
0.566
0.23
0.237
0.292
0.139
0.139
0.24
0.312
0.17
0.189
0.362
0.385
0.288
0.466
0.44
0.344
0.338
0.34
0.38
0.38
0.306
0.23
0.339
0.252
0.552
0.61
0.463

SNIa -1 week
SNIa at-max
SNIa +2 weeks
SNIa +10 days
SNIa -1 week
SNIa +1 month
SNIa? +1 month
SNIbc? post-max
SNIa at-max
SNIa? +6 weeks
SNII? post-max
SNIa? +1 week
SNIa +3 weeks
SNII post-max
SNII post-max
SNIa? pre-max
SNII? post-max
SNIa -1 week
SNIa near-max
SNIa +1 month
SNIa pre-max
SNIa -1 week
SNIa near-max
SNIa near-max
SNIa pre-max
SNIa +2 weeks
SNIa +2 weeks
SNII +10 days
SNII post-max
SNIa? +3 weeks
SNIa +1 month
SNII post-max
SNII? post-max
SNIa? near-max
SNIa near-max
SNIa near-max
SNIa? +1 week
SNIa near-max
SNIa max
SNIa max
SNIa pre-max
SNIa +2 weeks
SNIa? +2 weeks
SNIa? +2 weeks
SNII post-max
SNIa? +1 month
SNII? post-max
SNIa? near-max
SNIa? near-max
SNIa max

Ia-norm (-2 to 2)
Ia-91T (-2 to 2)
Ia-norm (10 to 14)
Ia-csm (6 to 10)
Ia-norm (-10 to -6)
Ia-norm (18 to 22)
Ia-norm (22 to 26)
Ib-norm (-6 to -2)
Ia-norm (-2 to 2)
Ia-norm (38 to 42)
IIP (26 to 30)
Ia-91T (6 to 10)
Ia-norm (22 to 26)
IIP (38 to 42)
IIP (18 to 22)
Ia-norm (-10 to -6)
Ib-norm (-6 to -2)
Ia-norm (-6 to -2)
Ia-91T (-6 to -2)
Ia-norm (18 to 22)
Ia-norm (-2 to 2)
Ia-91T (-2 to 2)
Ib-norm (-6 to -2)
Ic-broad (-10 to -6)
Ia-norm (-10 to -6)
Ia-norm (14 to 18)
Ia-91T (6 to 10)
IIP (18 to 22)
IIP (18 to 22)
Ia-norm (22 to 26)
Ia-norm (18 to 22)
IIP (6 to 10)
IIP (6 to 10)
Ia-91T (-2 to 2)
Ia-norm (2 to 6)
Ia-csm (6 to 10)
Ia-norm (2 to 6)
Ia-norm (-2 to 2)
Ia-norm (2 to 6)
Ia-csm (6 to 10)
Ia-norm (-2 to 2)
Ia-pec (2 to 6)
Ia-norm (18 to 22)
Ia-norm (18 to 22)
IIP (34 to 38)
Ia-norm (22 to 26)
IIP (2 to 6)
Ia-norm (-10 to -6)
Ia-norm (-6 to -2)
Ia-norm (-2 to 2)

0.7
0.999
0.998
0.944
0.848
0.518
0.989
0.983
0.981
0.585
0.986
0.397
0.977
0.656
0.985
0.997
1.0
0.922
0.51
0.885
1.0
0.554
0.999
0.98
0.94
0.931
0.702
0.947
0.99
0.946
1.0
1.0
0.651
0.981
0.859
0.858
0.801
0.992
0.64
0.737
0.801
1.0
0.997
0.946
0.861
0.621
0.984
0.998
0.971
0.558

Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Unreliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Unreliable
Unreliable
Reliable
Unreliable
Unreliable
Reliable

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

24

Muthukrishna et al.

DES17S1bof
DES17E1bis
DES17E1beg
DES17S1aya
DES17S1bch
DES17C2acb
DES17C2pf
DES17C2ou
DES17S1lu
DES17C1bql
DES17C3blq
DES17C3bei
DES17C1bat
DES17C3aye
DES17C1ayc
DES17C1ald
DES17S1emx
DES17S2ebs
DES17C3dxw
DES17X1dyt
DES17X2dwm
DES17X1dwi
DES17X1diq
DES17X1cuy
DES17X3dub
DES17E1dgn
DES17C3doq
DES17C1cpv

0.226
0.251
0.222
0.306
0.136
0.35
0.135
0.103
0.084
0.195
0.511
0.103
0.197
0.157
0.435
0.131
0.185
0.304
0.622
0.33
0.3
0.252
0.625
0.55
0.123
0.453
0.32
0.19

SNIa pre-max
SNIa +1 week
SNIa +1 week
SNIa? pre-max
SNIa max
SNIa? +2 weeks
SNII post-max
SNIa +2 months
SNII post-max
SNIa -1 week
SNIa? max
SNII near-max
SNIa +2 weeks
SNII post-max
SNIa +2 weeks
SNIa post-max
SNIa? -1 week
SNIa at max
SNIa? near-max
SNIa -1 week
SNIa near-max
SNIa at max
SNIa? near-max
SNIa? +1 week
SNII near-max
SNIa near-max
SNIa at max
SNIa +1 week

Ia-91T (-6 to -2)
Ia-91T (6 to 10)
Ia-norm (6 to 10)
Ia-csm (-14 to -10)
Ia-norm (2 to 6)
Ia-norm (18 to 22)
II-pec (38 to 42)
Ia-norm (46 to 50)
IIP (38 to 42)
Ia-norm (-6 to -2)
Ic-broad (2 to 6)
IIb (-2 to 2)
Ia-norm (6 to 10)
IIb (-18 to -14)
Ia-91bg (-2 to 2)
Ia-norm (22 to 26)
Ia-91T (-10 to -6)
Ia-norm (-2 to 2)
Ic-norm (2 to 6)
Ia-91T (-6 to -2)
Ia-norm (2 to 6)
Ia-91T (-2 to 2)
Ib-norm (-6 to -2)
Ib-norm (-6 to -2)
IIP (22 to 26)
Ia-norm (-6 to -2)
Ia-91T (-2 to 2)
Ia-norm (6 to 10)

1.0
0.996
0.915
0.985
0.995
0.898
1.0
0.991
0.998
0.761
0.344
0.665
1.0
0.977
0.93
0.822
0.549
0.535
1.0
0.992
1.0
0.593
0.744
0.842
0.696
0.96
0.909
0.992

Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Unreliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Reliable
Unreliable
Unreliable
Unreliable
Reliable
Reliable
Reliable

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

x
(cid:88)
(cid:88)
(cid:88)

x
x
(cid:88)
(cid:88)
(cid:88)
(cid:88)

Table 2. Classiﬁcation of supernovae released in the past 3 years of ATels by OzDES (Tucker et al. 2015; Bassett et al. 2015;
Lewis et al. 2015; Smith et al. 2015; Davis et al. 2015; Glazebrook et al. 2015; Pan et al. 2015; Yuan et al. 2015b; Moller et al.
2016; Sommer et al. 2016; King et al. 2016; O’Neill et al. 2016a,b; Mudd et al. 2016; Hoormann et al. 2016; Sharp et al. 2017;
Muthukrishna et al. 2017; Calcino et al. 2018a,b; Macaulay et al. 2018). The ﬁrst column is the name of the observed object,
the second column is the redshift determined by MARZ. The third column is the classiﬁcation given in the ATel by OzDES. It
details the type and age from maximum. A question mark after the classiﬁcation type indicates that the ATel was not certain
on the classiﬁcation. Most of these ATel classiﬁcations were made by the OzDES team with the help of Superfit or SNID. The
fourth, ﬁfth and sixth columns are the classiﬁcation, softmax regression probability and reliability from DASH, respectively. The
ﬁnal column has a tick if the ATel and DASH agree on the type of the supernova, and a cross if they disagree.

