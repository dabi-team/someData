mPyPl: Python Monadic Pipeline Library for Complex Functional
Data Processing

Dmitry Soshnikov, Microsoft, dmitryso@microsoft.com
Yana Valieva, Microsoft, yana.valieva@microsoft.com

Abstract
In this paper, we present a new Python library called mPyPl, which is intended to simplify complex data
processing tasks using functional approach. This library deﬁnes operations on lazy data streams of named
dictionaries represented as generators (so-called multi-ﬁeld datastreams), and allows enriching those data
streams with more ’ﬁelds’ in the process of data preparation and feature extraction. Thus, most data preparation
tasks can be expressed in the form of neat linear ’pipeline’, similar in syntax to UNIX pipes, or |> functional
composition operator in F#.

We deﬁne basic operations on multi-ﬁeld data streams, which resemble classical monadic operations, and show
similarity of the proposed approach to monads in functional programming. We also show how the library was
used in complex deep learning tasks of event detection in video, and discuss different evaluation strategies that
allow for different compromises in terms of memory and performance.
mPyPl library with some documentation and intro videos are available at http://github.com/shwars/
mPyPl and http://shwars.github.io/mPyPl.

Keywords: Python, Machine Learning, Deep Learning, Data Processing, Functional Programming, Monads

1
2
0
2

n
u
J

6
1

]
L
P
.
s
c
[

1
v
4
6
1
9
0
.
6
0
1
2
:
v
i
X
r
a

1

 
 
 
 
 
 
1. Introduction

It is estimated that in the work of a data scientist, about 80%
is spent on data preparation tasks (CrowdFlower, 2016).
That is why in any data science language and/or framework
many useful tools and libraries exist that simplify the task
of data manipulation.

In many practical machine learning tasks we start with the
ingestion of the original data, and then enrich that data with
some additional features, computing them from the original
source. One common concept that allows doing so is called
dataframe, which is essentially analoguous to a spread-
sheet, with some additional computed columns. In Python,
dataframes are well supported by Pandas (McKinney, 2010).
Also, Pandas supports reading the data source from many
popular formats, such as csv, Excel, etc.

However, when handling large volumes of unstructured or
semi-structured data, for example in video processing tasks,
this approach becomes problematic. First, dataframe typi-
cally needs to ﬁt in memory of one machine, which cannot
be the case in video or even large scale image processing.
Thus, it is essential to be able to load the data on demand,
in the form of batches, yet it is desirable to be able to ex-
press the data pipeline steps in a clean and concise way as
operations on the whole dataset.

The way those tasks are currently handled in deep learning
practice is by creating special classes/adapters for dynamic
loading of data. For example in Keras (Chollet et al., 2015),
there is a concept of ImageDataGenerator, that allows
doing some data augmentation, and can take images on the
ﬂy from a speciﬁed directory. A sample (slightly simpliﬁed)
code to use ImageDataGenerator is presented below:

datagen = ImageDataGenerator(rescale=1./255, ...)

generator = datagen.flow_from_directory(

'data/train', target_size=(150, 150),
batch_size=32, class_mode='binary')

model.fit_generator(generator, ...)

If we want to add some custom augmentation code, or create
generator for handling video streams, or produce pairs of
images for training Siamese networks — we would need
to create our own custom data generator class (maybe by
subclassing existing one). This would immediately require
some familiarity with Keras internals.

The fact that we can modify the functionality of existing data
generator only by subclassing is inherent to object-oriented
design of the Keras library. This can also be said about many
other Python libraries and tools. However, we strongly be-
lieve that for creating data preparation pipelines a func-
tional approach should be used, when required function-
ality is achieved not by subclassing, but by composing to-
gether simpler processing steps in a functional way. This

almost never requires writing custom processing classes or
functions, but rather calling existing combinators with some
small pieces of code written as lambda-expressions.

To simplify writing such data preparation pipelines, we have
created a Python library called mPyPl, based on functional
design and a number of core principles that we will describe
in the following sections.

2. mPyPl Library

Essentially, mPyPl is based on three main ideas:

• using functional programming techniques and lazy

pipelines based on Pipe package (Pallard, 2016)

• using generators that produce streams of named dictio-
naries (instead of atomic values), which ’ﬂow’ through
the pipeline (we call them multi-ﬁeld datastreams)

• using a small number of basic operations (the most
important one being apply) that operate on those ﬁelds,
as well as a number of pre-deﬁned data producers and
sinks, hiding the internal implementation complexity

The main advantage of this approach is the ability to create
pipelines that combine several streams of data together.

2.1. Pipe package

Pipe package allows writing chained computations in the
inﬁx form using | pipeline operator, for example:

from pipe import *
res = (range(10)

| where (lambda x: x%2==0)
| select (lambda x: x*x)
| add )

Here select is another name for a map function, and
where stands for ﬁlter, so this piece of code computes sum
of all even numbers smaller than 10.

Such a way of expressing computations looks very powerful,
for example, we can easily express the logic of preparing a
bunch of images for neural network training, together with
some augmentation1, as shown below:

import mPyPl as mp
images = (

mp.get_files('data',ext='.jpg')
| select(lambda x: cv2.imread(x))
| where(lambda x: x.shape[0]>=1024)
| select(augment)
| select(resize)
| as_list )

1We do not consider augmentation algorithm here, because it is
not important for our discussion, we just assume augment func-
tion does the job, and resize function does additional resizing.

Here we get the list of the image data as a result, but we
have lost all the information about the original ﬁlenames,
and possibly classes of images (if we are solving classi-
ﬁcation problem). Also, if we want the neural network
classiﬁer to use any image metadata, there is no elegant
way to pass it along. We could, theoretically, use tuples to
group several pieces of data together, but in this case all
select functions would look rather ugly, because they
would have to operate only on one piece of info inside the
tuple, while keeping the rest. This brings us to the idea of
passing dictionaries through the pipeline, instead of atomic
values.

2.2. Dictionary generators

In mPyPl, we almost always create pipelines that operate
on named dictionaries, thus several values can be passed
through the pipeline at the same time. We can think of those
named ﬁelds as ’columns’ (if we look at data processing
from Pandas perspective), or as object attributes.

For example, suppose we have a directory with image ﬁles,
and we want to imprint the date of each ﬁle on top of the
image. In this case, it would be useful to construct a data
stream that contains both date/time info, as well as the actual
image content. We can get the stream of ﬁle names using
get_files function, and then create a combined stream
using the following code:

images = (

mp.get_files('images',ext='.jpg')
| mp.as_field('filename')
| mp.apply('filename','image', imread)
| mp.apply('filename','date',

lambda x:str(os.stat(x).st_mtime))

| mp.apply(['image','date'],'result',
lambda x: imprint(x[0],x[1]))

| mp.select_field('result')
| mp.as_list)

Here, the function as_field convert the stream of ﬁle-
names to named multi-ﬁeld stream of dictionaries. apply
takes one or more ﬁelds from the stream and computes an-
other ﬁeld using provided function or lambda-expression.
The function select_field converts named multi-ﬁeld
datastream back to atomic values, taking only one ﬁeld2
from the stream, which results in the generator of image
arrays. At the end we convert this generator to list to store
it in memory for future processing 3

2.3. mdict and lazy evaluations

Standard Python dictionaries could have been used, but
to allow more ﬂexibility in terms of ﬁeld computational

2select field can also extract multiple ﬁelds, in which

case it returns a generator of tuples.

3We could have also converted it to large NumPy array using

as npy.

strategies we introduce special Python class called mdict.
It is essentially a dictionary, but each ﬁeld has an associated
computational strategy:

• Value, which corresponds to eager strategy, and means
that the actual value is stored in the dictionary ﬁeld

• LazyMemoized, which corresponds to lazy evaluation.
Dictionary ﬁeld contains a function to be evaluated
upon ﬁrst request, and then obtained value is stored

• OnDemand. An evaluation function is stored in the
ﬁeld, and it is called every time we need to obtain a
value

We can convert a stream of values into stream of named
ﬁelds using as_field method. A better version of an
example described in section 2.1 can be expressed as:

images = (

mp.get_files('data',ext='.jpg')
| mp.as_field('filename')
| mp.apply('filename','image', imread)
| mp.filter('image',lambda x: x.shape[0]>=1024)
| mp.apply('image','aug_image',augment,

eval_strategy=mp.OnDemand)

| mp.apply('aug_image','output',resize,

eval_strategy=mp.OnDemand)

| mp.as_list)

The most often used function in mPyPl is called apply. It
takes names of input and output ﬁelds, and a function, which
is applied to the input ﬁeld, and the result is stored in the
output ﬁeld. Thus, apply can be considered an analogue
of a computed ﬁeld in Pandas.

Note that in our example we also specify evaluation strategy
for the last two ﬁelds as OnDemand — this is important
for data augmentation to work properly. Eventually during
training we would probably loop over data inﬁnitely, and it
would cause the output ﬁeld to be re-computed each time
we need to get the value, thus each time a new augmentation
would be applied.

Sometimes we might need to use apply with several input
ﬁelds – in this case, we can pass a list of ﬁeld names as a
ﬁrst parameter, and the corresponding processing function
would expect a list of arguments. For example, we can use
the following construction to print a text value over an image
(suppose imprint function expects text as ﬁrst argument
and image as the second):

mp.apply(['text','image'],'out',
lambda x: imprint(x[0],x[1]))

In addition to apply, there are many more useful functions
such as filter, fold, scan (cumulative fold), etc. We
will not describe all those functions in detail here, and refer
you to the documentation available at http://shwars.
github.io/mPyPl.

2.4. Data Sources

So far we have only seen get_files function that returns
a stream of ﬁle names from a given directory. There are
some more generator functions that can obtain data from
common data sources:

We also often need to stratify dataset,
i.e. make
sure there is the same number of samples of each
class. This can be done using stratify_sample, or
stratify_sample_tt (the latter also does stratiﬁca-
tion with respect to train/test split). You can inspect the
number of samples for each class using summary method.

• get_xmlstream_from_dir reads a series of
XML ﬁles from a given directory and returns their con-
tent as named mdict’s. It has many parameters to skip
or ﬂatten certain ﬁelds. One special case of this func-
tion is get_pascal_annotations, which reads
PASCAL VOC annotations for object detection task
(which are essentially XML ﬁles)

• csvsource reads a CSV ﬁle, and returns correspond-
ing stream of mdict’s. Schema is derived from ﬁrst
line in CSV ﬁle

• jsonstream reads a JSON ﬁle, which should be a
list of dictionaries, and returns corresponding mdict
stream

• videosource opens a video ﬁle, and returns its
frames as a sequence (optionally doing some resiz-
ing). Please note that for historic reasons it returns
frames as np-arrays, so you need to call as_field to
convert them to proper named mPyPl stream

• get_datastream is the function most commonly

used for classiﬁcation tasks

Please not that any Python generator can be used as a data
source in mPyPl.

2.5. Classiﬁcation Tasks

Let us consider the latter get_datastream function in
more detail, since it is the basis of doing classiﬁcation with
mPyPl. It expects a base directory, which contains multiple
subdirectories — one per class. It automatically considers
those subdirectories to be class names, numbers the classes
from 0, and returns mdict’s with the ﬁelds filename,
class_no and class_name. If you want to provide
the list of classes and their mapping to class_no val-
ues, you can also pass a dictionary with class_nos and
class_names as classes parameter.

In machine learning, we often need to split the data into
train-test or train-validation-test sets. In mPyPl, it is nor-
mally done by setting a ﬁeld called split. For doing this
split, a very ﬂexible datasplit function can be used,
that can either perform a random split, or save/load split
to a ﬁle, to make sure we are dealing with the same split
each time. Also, sometimes we may want to do split based
on some ﬁlename pattern, which can be achieved by using
datasplit_by_pattern.

2.6. Complete Cats vs. Dogs Example

Let us consider using mPyPl to do complete classiﬁcation
task on images — a classical cats vs. dogs problem de-
scribed in (Chollet, 2016). We will place images of cats
in data/cats directory, and dogs — into data/dogs.
Loading images, resizing them, doing data augmentation
and performing train-test split can be done using one
pipeline as follows:

import mPyPl as mp
import mPyPl.utils.image as mpui
train, test = (

mp.get_datastream('data',ext=".jpg")

| mp.datasplit(split_value=0.2)
| mp.stratify_sample_tt()
| mp.summary()
| mp.apply('filename','orig_image',imread)
| mp.apply('orig_image','transformed_image',

transform.random_transform,
eval_strategy=mp.EvalStrategies.OnDemand)
| mp.apply('transformed_image','scaled_image',

lambda x: mpui.im_resize_pad(x,size=(150,150)),
eval_strategy=mp.EvalStrategies.OnDemand)

| mp.apply('scaled_image', 'image',lambda x:x/255.,

eval_strategy=mp.EvalStrategies.OnDemand)

| mp.make_train_test_split)

For data augmentation we use ImageDataGenerator
from Keras, which can be deﬁned as follows:

from keras.preprocessing.image
import ImageDataGenerator
transform = ImageDataGenerator(

rotation_range=40, width_shift_range=0.2,
height_shift_range=0.2,
shear_range=0.2, zoom_range=0.2,
horizontal_flip=True, fill_mode='nearest')

We will omit deﬁning the actual model architecture here,
but once it is deﬁned, you can train the model using the
following code:

args = { feature_field_name: 'image',

label_field_name: 'class_id',
batch_size: 128 }

hist=model.fit_generator(

train | mp.infshuffle | mp.as_batch(*args),
validation_data=
test | mp.infshuffle | mp.as_batch(*args))

3. mPyPl and Related Work

Now that we have introduced the overall architecture of
mPyPl, let us discuss how it relates to other data processing
approaches that exist. Comparison of mPyPl to related
projects is summarized in Table 1.

3.1. mPyPl and Apache Spark

The most obvious candidate for comparison with mPyPl is
Apache Spark, which also organizes data processing into
functional lazy pipelines. However, the main focus of Spark
is to power distributed computations on clusters, i.e. Spark
pipelines operate on Resilient Distributed Datasets, and are
designed to be effectively distributed. On the other hand,
the main focus of mPyPl is to power local computations,
for which Spark would be an overkill.

In addition to that, the main advantage of mPyPl is to pro-
vide multi-ﬁeld named pipelines, which allows concentrat-
ing all features within one pipeline in a clear and concise
way. This idea, while can probably be implemented on top
of Spark4, is not provided out-of-the-box.

While Spark is a distributed data processing engine, its usage
for deep learning has been mostly limited to embarrassingly
parallel tasks, such as applying deep learning models to data
at scale, or doing hyperparameter optimizations (Databricks,
2019a). While distributed training is somehow supported, it
is mostly through Horovod (Databricks, 2019b) third-party
library. The same approach of using Horovod for distributed
training can be equally well applied to multi-node mPyPl-
powered cluster distributed through Azure Batch (see 6 for
more information on our plans in this area).

3.2. mPyPl and Pandas

We have already mentioned Pandas here, and noted the simi-
larity between apply function and the notion of computed
column in Pandas. Pandas represents data in the form of
dataframes that are stored in memory and indexed, which al-
lows performing many powerful operations on them, such as
pivoting, grouping, ﬂexible masking, etc. However, for deep
learning data preparation tasks, many of those operations
are an overkill, and mostly linear data processing followed
by batching is required. This is exactly the focus of mPyPl,
which provides enough ﬂexibility for deep learning, while
allowing data to be processed in batches in a lazy manner,
without loading everything into memory.

3.3. Other Data Pipeline Concepts

The notion of data processing pipelines exists also in
ML.NET in the form of IDataView interface,
in
Scikit.learn, as well as in Azure ML DataPrep SDK.
While different approaches may have some advantages over
mPyPl in terms of pipeline execution, they are lacking two
main features: ability to deﬁne pipeline with multiple named

4Such an implementation would be quite difﬁcult due to typed
nature of Scala, the language behind Apache Spark. In untyped
dynamic language like Python, where untyped dictionaries are ﬁrst-
class citizens, such an implementation is deﬁnitely more straight-
forward.

ﬁelds, and succinctness of code, achieved through pipe op-
erator overloading.

Most of the mentioned pipeline approaches are closely re-
lated to underlying implementation of the ML engine, be
that ML.NET or Azure ML. For example, IDataView in-
terface has quite complex architecture, which is required
by overall ML platform. The same is true for Azure ML
DataPrep SDK, which allows to deﬁne pipelines for remote
execution on distributed compute. On the contrary, mPyPl
is a very ﬂexible, simple and generic Python tool, which can
be used with multiple deep learning and ML frameworks,
such as Keras, TensorFlow, Scikit learn, etc. We believe
that for many tasks it provides a good compromise between
available data processing features and complexity, while
resulting in very clean, succinct and functional code. While
it is mostly targeting local scenarious, it helps create dis-
tributed processing for massively parallel tasks, as we will
mention below.

4. Why mPyPl Stands for Monadic

A special note should be made on the name of the library,
and why we called it monadic. Strictly speaking, oper-
ations on named multi-ﬁeld data streams do not directly
correspond to the notion of monad, as it is known in func-
tional programming (Wadler, 1992). However, there are
some notable similarities, which we believe are enough to
justify the name.

In functional programming, monads of type T are repre-
sented as some monadic type MT , with two operations
deﬁned: return : T → MT and bind: >>=: Ma →
(f → Mb) → Mb. return simply encapsulates ’normal’
type into monadic type, and bind applies a given function
f (from ’normal’ type to monadic type) to a monadic type,
producing the result as a monadic type.

In our case, we are dealing with data streams of dictionaries
that can encapsulate many ’named’ values at once, thus we
would need to alter the return and bind operations to add
ﬁeld name. To do so, let us introduce some notation.

(cid:74)

(cid:75)

T

a data stream of type T . By Mu we
We will denote by
will denote an mdict with ﬁeld name u, and by Mu,... we
will denote an mdict that contains ﬁeld u and (possibly)
some other ﬁelds. Just writing M would mean any mdict,
no matter which ﬁelds it contains.

We will also use M{u ← x} to denote mdict value with
ﬁeld u equal to x, and we will sometimes use | operator as
reverse-order function application, i.e. x|f ≡ f (x). We
will employ bracket notation for mdict indexing, so that
for example M{u ← x}[u] ≡ x.

Given those deﬁnitions, we can deﬁne the following two
main functions:

mPyPl

Pandas

Apache Spark ML.NET

Azure
Data Prep

ML

Azure
Pipelines

ML

Abstraction

Multi-Field
Datastream
+
Lazy
±
Cluster-ready
Succinct syntax +
Main Focus

single-node
large data deep
learning tasks

Computed Col-
umn
−
−
+
single-node in-
memory tables

RDD

IDataView

DataFlow

Pipeline Step

+
+
±
multi-node
cluster compu-
tations

+
−
−
.NET
projects

+
+
−
pipelines
that
remotely

can run

ML

−
+
−
MLOps steps

Table 1. Comparison of mPyPl to other data processing engines.

• as ﬁeldu :

return

→

T

(cid:74)

(cid:75)

(cid:74)

Mu:T

, which is analogous to
(cid:75)

• >>=u:

Mu:T,...
which is analogous to bind

(cid:74)

(cid:75)

→ (T → Mv,...) →

Mu,v,...

,

(cid:75)

(cid:74)

Here by u, v, . . . we denote ﬁeld names, and u : T means
that ﬁeld name u is assumed to contain values of type T .

Note that bind function >>=f is not directly used in
mPyPl— even though it is deﬁned in the library for inter-
nal usage and called __fnapply. Its direct usage outside
the core mPyPl is discouraged, because it requires some
understanding of library internals. Instead, apply should
be used wherever possible, which is somehow similar in
functionality, i.e.

Mu

|applyu,vf ≡
(cid:75)

(cid:75)
where f (cid:48)(x) = M{u ← x, v ← f (x)}.

(cid:74)

(cid:74)

Mu,...

>>=u f (cid:48)

For brevity, we will also denote
M
(cid:75)

| >=u,v f .

(cid:74)
For those functions, we can observe that the following laws
similar to monadic laws are true:

|applyu,vf as

M
(cid:75)
(cid:74)

• as ﬁeldu

T
(cid:74)
Here, f : T → M.

(cid:75)

>>=u f ≡ mapf

– left identity.

T

(cid:74)

(cid:75)

•

•

Mu,...
(cid:74)
tity

(cid:75)

>>=u as ﬁeldu ≡

Mu,...
(cid:74)

(cid:75)

– right iden-

(cid:75)

>>=u fv >>=v gw ≡

>>=u
Mu,...
(cid:74)
(λu.fv[v] ◦ gw) – associativity. Here we denote by fv
and gw functions that produce mdicts with ﬁelds v
and w, i.e. fv : T → Mv, gw : T (cid:48) → Mw.

Mu,...
(cid:74)

(cid:75)

Associativity property does not look very nice, because
>>= operator that operates on streams of mdicts trans-
lates to normal composition ◦ when being down-lifted to the
function level. This property can be reformulated in terms
of apply in the following way:

Mu,...

| >=u fv| >=v gw (cid:117)

| >=u (fv ◦ gw)

(cid:75)

(cid:74)
The equivalence here is approximate ((cid:117)), because in the
RHS there ﬁeld named v is missing.

(cid:75)

Mu,...
(cid:74)

The latter property turns out to be very useful in practi-
cal computations for simplifying the code, and it can be
re-stated saying that the two following pieces of code are
almost identical:

(source ...

| mp.apply(u,v,f)
| mp.apply(v,w,g)
...)

and

(source ...

| mp.apply(u,w,compose(f,g))
...)

5. Case Study

Initially, creation of mPyPl was motivated by one project
on complex event detection in videos, which we will brieﬂy
describe here. The goal of the project was to be able to detect
events in Formula-E racing videos, such as car collisions.
Source code of the project, together with more detailed
description, can be found in (Yana Valieva, 2019).

Among many methods used for event detection in videos (a
good review can be found in (Kang and Wildes, 2016)), there
are methods that involve considering two streams of data
(Simonyan and Zisserman, 2014) — static frame images,
as well as dynamic properties of image change over time.
Thus, resulting neural network would have quite complex
architecture, taking several streams of data as input.

5.1. Network Architecture and Training

For the experiment, we have collected a dataset of 5-second
video clips with and without collisions from publicly avail-

able sources. The dataset contained around 600 positive and
negative samples. The lack of samples was mostly because
collision events happen to be quite rare during the actual
race.

Due to the relatively small number of samples, we were
focusing on manually engineering some features that would
allow us to minimize possible overﬁtting, and make the
number of parameters smaller. Minimizing overﬁtting also
means getting rid of the original image pixels, and switching
either to CNN embedding domain, or to motion domain
represented by either dense, or focused optical ﬂow (Bruhn
et al., 2005).

In our case, we have considered three main data streams (as
shown in Fig. 1):

• Original frames are processed using VGG-16 embed-
dings, and the resulting vectors are stacked together
into rectangular matrix. This matrix is then fed into
2D or 3D CNN network for pattern detection in the
embedding space.

• Dense Optical Flow ﬁeld is computed between each
pair of frames, the result is converted to polar coor-
dinates and histograms of magnitudes and directions
are computed (we used 200 bins). Those histograms
between each two frames are stored in 125 × 200 × 2
tensor, which is then processed using CNN.

• Focused Optical Flow (see Fig. 3), which is computed
after car detection using RetinaNet(Tsung-Yi Lin,
2017), by tracking features inside detected rectangle.
Focused ﬂow vectors are than transformed in the same
manner as dense ﬂow.

mPyPl allows us to create a single data pipeline contain-
ing all three data streams, which are than passed onto the
neural network. While you can see the complete code in
(Yana Valieva, 2019), the simpliﬁed code below gives the
main idea:

trainstream, valstream = (
mp.get_datastream(data_dir)
# Load video
| mp.apply('filename','video',load_video)
# VGG16 embeddings pipeline
| mp.apply('filename', 'raw_vgg', compute_vgg)
| mp.apply('raw_vgg','vgg', zero_pad)
| mp.delfield('raw_vgg')
# DenseFlow pipeline
| mp.apply('video','raw_dflows', compute_dflow)
| mp.apply('raw_dflows','prep_dflows', zero_pad)
| mp.apply('prep_dflows', 'res_dflows',

normalize_histograms)

| mp.delfield(['raw_dflows', 'prep_dflows'])
# RetinaFlow pipeline
| mp.apply('video', 'raw_rflows', compute_optical)
| mp.apply('raw_rflows', 'gradients', calc_gradients)
| mp.apply('gradients', 'polar', to_polar)
| mp.apply('polar', 'histograms', video_to_hist)
| mp.apply('histograms', 'res_rflows', zero_pad_hist)
| mp.delfield(['video','raw_rflows',

'gradients', 'polar', 'histograms'])

# Split

| mp.make_train_test_split
)

Obtained train and test streams can then be passed onto the
network training function:

flds = ['res_rflows', 'res_vgg', 'res_dflows']
history = model.fit_generator(

trainstream | mp.infshuffle
| mp.as_batch(flds,'class_id',batchsize=32),
validation_data=valstream | mp.infshuffle()
| mp.as_batch(flds,'class_id',batchsize=32),

...)

We want to emphasize the following:

• We use special function delfield here in order to
delete certain ﬁelds from the stream. Without those
functions, loaded videos would stay in memory for the
whole period of training, possibly resulting in out-of-
memory conditions. Using delfield results in the
fact that data stays in memory only during the actual
computations, i.e. during minibatch preparation.

• If we want to store intermediate results on disk, so
that computations can be resumed or performed more
quickly, we can use apply_npy function, which is
the same as apply, but stores the intermediate compu-
tation results on disk. In case those ﬁles are available,
they will be loaded from disk without re-computation.
This turns out to be very useful for optical ﬂow compu-
tations.

• In the code sample above, all features for all videos
would be computed before the actual training takes
place, due to the nature of eager evaluation. If we
want the training to start immediately, loading videos
from disk and computing features only for each mini-
batch, we can specify all computations performed in
apply as LazyMemoized. In the current design on
the library, all ﬁelds that depend on lazy ﬁelds should
also be declared lazy. Also, if lazy evaluation strat-
egy is used, we should not use delfields that make
original ﬁelds unavailable, because lazy computations
depend on them.

5.2. Video Inference

To visually inspect relevance of the model, we wanted to
produce a clip that includes the collision indicator on top of
video, showing the probability of collision predicted by the
model. To do so, we need to take 5 second sliding window
from the video, pre-compute all features, call trained model
to get the result, and then draw the indicator on top of
the current frame. This process can also be handled using
mPyPl data streams:

Figure 1. Three-stream pipeline for complex event detection

Figure 2. Dense Optical Flow Featurization

Figure 3. Focused Optical Flow superimposed on original image

(

)

mp.videosource('input.mp4',video_size=video_size)

| mp.as_field('frame')
| mp.apply_batch('frame','vggx',get_vgg,batch_size=16)
| mp.delay('frame','prev_frame')
| mp.apply(['frame','prev_frame'],'optflow',

compute_optflow)

...
| mp.sliding_window_npy(['frame','vgg',

'optflow','focflow'],size=126)

| mp.apply('frame','midframe',lambda x: x[60])
| mp.apply(['vgg', 'optflow', 'focflow'], predict)
| mp.apply(['midframe','score'],'fframe',imprint)
| mp.select_field('fframe')
| mp.collect_video('output.mp4')

videosource function opens the video ﬁle using
OpenCV and produces stream of frames (a generator). We
then compute all the features in the same way as we did dur-
ing training. Some of the code is omitted here for simplicity.
Please note the usage of delay function to insert previ-

ous frame in the pipeline, allowing us to compute pairwise
optical ﬂow between frames.

To switch from frame sequence to the sequence of 5-second
video intervals we use sliding_window_npy. This
function groups together speciﬁed number of elements into
np-arrays of corresponding size, using the sliding window.
Thus individual frames and optical ﬂow descriptors are auto-
matically converted into 5-second intervals, and the values
are not re-computed for every frame, but are just extracted.

thing to be noted here is

Another
the usage of
apply_batch, which is used to feed several values to-
gether to the VGG-16 network to optimize computations.
It automatically groups together several values, and then
un-groups the result into the data stream.

Finally, we call the model on our 5-second interval features,
and imprint the result onto the middle frame of the video.
All those frames are then grouped together into resulting
video using collect_video sink function.

6. Conclusion and Future Work

In this paper, we have presented Python library called
mPyPl, which allows expressing data manipulation tasks
in the functional way. We have demonstrated similarity of
the proposed architecture to monadic computations, and
have presented a real case where usage of mPyPl simpliﬁed

the training and inference architectures for video process-
ing quite signiﬁcantly. We have also compared our work
to existing data processing approaches such as Pandas and
Apache Spark, and have shown that mPyPl has its own
niche, and it has all the rights to exist.

Our machine learning / data science team in CSE currently
uses mPyPl for almost all of AI/ML related tasks in Python,
including object detection, Siamese network training, etc.
However, there are further improvements that can be imple-
mented.

During heavy data processing, it can be noticed that not
all processor cores are sometimes fully utilized. This is
due to the single-threaded nature of Python, and it happens
when most of the code is purely Pythonic. To overcome this
issue, we are thinking of creating multi-threaded version
of apply that will spread the computation over available
cores.

Another issue is using mPyPl to parallelize computation on
clusters. During data pre-processing, we often need to do
embarrassingly parallelizable computations such as optical
ﬂow computation or object detection on each clip of the
video. This is typically done using Azure Batch service,
however, it requires some hand-made data splitting function-
ality. Using mPyPl, we can just insert mp.batch(k,n)
function into the pipeline to separate every n-th element
with the remainder k, i.e. when computing on n-node clus-
ter we just need to pass the number of node (from 0 to n − 1)
to the computation script. While this functionality already
exists, we are looking for some further way to simplify
cluster computations.

We hope that mPyPl can be useful in a wide range of sce-
narious outside our internal team, and we would welcome
any contributions, issues or comments at the project GitHub
repository: http://github.com/shwars/mPyPl.

Acknowledgements

mPyPl was ﬁrst developed while working on video event
detection project together with Tim Scarfe, whose idea it
was to use Pipe library for data pre-processing. We would
also like to thank him for using the library extensively in
successive projects, and being not only a contributor, but
also the most active advocate of it. We would also like to
thank other members of our team, who contributed ideas
and bug reports, in particular Tess Ferrandez and Claus
Matzinger. We would also like to thank our external col-
laborators, Gianni Rosa Gallina and Clemente Giorio from
DeltaTre Innovation Lab for their valuable feedback.

References

Bruhn, A., Weickert, J., and Schn¨orr, C. (2005). Lu-
cas/kanade meets horn/schunck: Combining local and
global optic ﬂow methods. International Journal of Com-
puter Vision, 61(3):211–231.

Chollet,

F.

(2016).

Building powerful
classiﬁcation models
little
very
using
https://blog.keras.io/building-powerful-
image-classification-models-using-very-
little-data.html.

image
data.

Chollet, F. et al. (2015). Keras. https://keras.io.

CrowdFlower (2016). 2016 data science report.

Databricks (2019a). Deep learning pipelines for apache
https://github.com/databricks/

spark.
spark-deep-learning.

Databricks (2019b). Distributed training with horovod
https://docs.databricks.

on databricks.
com/applications/deep-learning/
distributed-training/index.html.

Kang, S. and Wildes, R. P. (2016). Review of action recog-
nition and detection methods. CoRR, abs/1610.06906.

McKinney, W. (2010). Data structures for statistical com-
puting in python. In van der Walt, S. and Millman, J.,
editors, Proceedings of the 9th Python in Science Confer-
ence, pages 51 – 56.

Pallard, J. (2016). Pipe python package. https://

github.com/JulienPalard/Pipe.

Simonyan, K. and Zisserman, A. (2014). Two-stream convo-
lutional networks for action recognition in videos. In
Ghahramani, Z., Welling, M., Cortes, C., Lawrence,
N. D., and Weinberger, K. Q., editors, Advances in Neu-
ral Information Processing Systems 27, pages 568–576.
Curran Associates, Inc.

Tsung-Yi Lin, Priya Goyal, R. B. G. K. H. P. D. (2017).
Focal loss for dense object detection. In Proceedings of
2017 IEEE International Conference on Computer Vision
(ICCV).

Wadler, P. (1992). Comprehending monads. In Mathemati-

cal Structures in Computer Science, pages 61–78.

Yana Valieva, Dmitry Soshnikov, T. S. (2019). Race
events recognition project. https://github.com/
sulasen/race-events-recognition-1.

