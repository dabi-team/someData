Energy Efficient Placement of ML-Based Services 
in IoT Networks  

Mohammed M. Alenazi, Barzan A. Yosuf, Sanaa H. Mohamed, Member, IEEE, Taisir E. H. El-Gorashi, and Jaafar M. H. 
Elmirghani, Fellow, IEEE 
School of Electrical Engineering 
 University of Leeds, Leeds, United Kingdom 
 {elmmal, b.a.yosuf, s.h.h.mohamed, t.e.h.elgorashi, j.m.h.elmirghani}@leeds.ac.uk 

(IoT) 

Abstract—The  Internet  of  Things 

is  gaining 
momentum in its quest to bridge the gap between the physical 
and the digital world. The main goal of the IoT is the creation of 
smart environments and self-aware things that help to facilitate 
a  variety  of  services  such  as  smart  transport,  climate 
monitoring, e-health, etc. Huge volumes of data are expected to 
be  collected  by  the  connected  sensors/things,  which 
in 
traditional cases are processed centrally by large data centers in 
the  core  network  that  will  inevitably  lead  to  excessive 
transportation  power  consumption  as  well  as  added  latency 
overheads.  Instead,  fog  computing  has  been  proposed  by 
researchers  from  industry  and  academia  to  extend  the 
capability  of  the  cloud  right  to  the  point  where  the  data  is 
collected at the sensing layer. This way, primitive tasks that can 
be hosted in IoT sensors do not need to be sent all the way to the 
cloud for processing. In this paper we propose energy efficient 
embedding of machine learning (ML) models over a cloud-fog 
network  using  a  Mixed  Integer  Linear  Programming  (MILP) 
optimization model. We exploit virtualization in our framework 
to provide service abstraction of Deep Neural Networks (DNN) 
layers that can be composed into a set of VMs interconnected by 
virtual  links.  We  constrain  the  number  of  VMs  that  can  be 
processed  at  the  IoT  layer  and  study  the  impact  on  the 
performance of the cloud fog approach.  

Keywords—  VM  placement,  energy  efficiency,  Internet  of 
Things,  cloud-fog  networks,  MILP,  optimization,  resource 
allocation 

I. 

INTRODUCTION  

Machine  learning  (ML)  models  have  recently  changed  the 
basis  for  most  modern-day  applications  that  include  object 
detection,  natural  language  processing, self-driving  cars,  to 
name a few. As new technologies emerge, the adoption of ML 
based models widens. Studies forecast that billions of devices 
are now connected to the Internet and this figure is anticipated 
to rise further in the future[1]. Internet of Things (IoT) on its 
own is projected to generate five quintillions of data everyday 
day whilst on the other hand driverless cars are reported to 
generate up to 4TB worth of data every single hour of driving 
per day  [2]. Thus, such an amount of data collected makes 
ML  and  Deep  Neural  Networks  (DNNs)  particularly 
attractive  for  deployment  in  the  edge  of  the  network. 
Traditionally, the collected data is transported from the edge 
all  the  way  to  the  centralized cloud  data center  at  the  core 
network.  However,  the  centralized  processing  approach 
introduces several challenges that include privacy, increased 
network power consumption due to the number of hops and 
unacceptable  latency  overheads    [3],  [4].  To  address  the 
aforementioned  challenges, 
fog  computing  has  been 
proposed  in  the  literature  as  a  decentralized  processing 
paradigm  by  exploiting  the  resources  available  across  the 
IoT-Cloud continuum. In most cases, the aggregate resources 
available in the IoT-cloud continuum are overlooked in favor 

of  centralized  processing  using  the  cloud  data  center  [5]. 
Processing,  networking,  and  storage  are  examples  of  such 
resources that can be used to relieve the cloud. Fog allows for 
cloud-based services to be brought closer to the data source, 
facilitating  effective and fast processing [6]. A fog node can 
be  any  device  with  CPU  and  networking  capabilities  [7]. 
Notwithstanding  the  benefits  of  fog  computing,  there  still 
exists a number of obstacles that need to be addressed before 
it can reach its full potential. These include Interoperability, 
fog networking, orchestration and resource provisioning, and 
computation  offloading,  which  are  just  some  of  the  issues. 
We focus on the energy efficient placement of interconnected 
virtual machines (VMs) that are used to abstract DNN layers 
[3]. In this work, we extend our previous contribution in [8] 
by  1)    studying  the  impact  of  a  range  of  the  idle  power 
proportion ratio (IPPR) that is attributed to our application for 
highly shared networking equipment in the access, metro and 
core networks. This can also represent the growth of the given 
application segment considered in the future provided that the 
idle  power  consumption  is  proportional  to  the  size  of  the 
application and 2) paying particular attention to the impact of 
the constraint imposed on the processing capability at the IoT 
layer  such  that  each  IoT  node  can  only  process  a  limited 
number  of  VMs.  This  is  a  practical  constraint  imposed  by 
hardware/software limitations where certain IoT nodes may 
not be able to host certain types of ML models. Also, we build 
on our previous studies in the areas of distributed processing 
[9]–[12], green data center [13]–[22] and core networks [23]–
[28], service embedding and virtualization in IoT [29]–[32], 
machine  learning  and  health  care  systems  [33]-[36]  and 
network coding for core networks [33]–[38]. 

The remainder of this paper is organized as follows: Section 
II describes the proposed cloud fog architecture and the MILP 
optimization  model  for  the  distributed  placement  of  VMs 
representing DNN layers. Section III provides the results and 
discussion  while  Section  IV  provides  the  conclusions  and 
future work. 

II.  THE PROPOSED CLOUD FOG NETWORK 

We assume that the proposed architecture shown in Figure 1 
supports  full  virtualization  at  the  hardware  level,  which 
implies that different VMs can be created and deleted on the 
fly, regardless of the heterogeneity in the specification of the 
hardware  equipment.  We  also  abstract  DNN  workloads  by 
random virtual topologies that are comprised of several VMs 
inter-connected by virtual links for data exchange. Figure 1 
shows  a  cloud  fog  network  with  four  processing  layers, 
namely:  IoT,  Access  Fog  Node  (AFN),  Metro  Fog  Node 
(MFN), and the Cloud. In the Edge Network, we have several  

 
Cloud

Optical 
Switch

Core 
Router

Physical Link

Virtual Link

Edge 
Router

Metro 
Switch

VM Placement

Metro Fog Node 
(MFN)

Access Fog 
Node (AFN)

Abstraction Level

VM1

VM3

VM2

Input 
layer

Output 
layer

Hidden 
layers

k
r
o
w
t
e
N
e
r
o
C

k
r
o
w
t
e
N
o
r
t
e
M

k
r
o
w
t
e
N
s
s
e
c
c
A

k
r
o
w
t
e
N
e
g
d
E

IoT Zone 1

IoT Zone n

IoT Device

ONU AP

Splitter

OLT

WiFi 
Link

Optical 
Link

Ethernet
Link

Figure 1: The Evaluated Cloud Fog over PON Access Network. 

IoT  devices  distributed  in  different  zones  where  they  can 
collect different types of data and perform processing using 
their onboard CPUs. For the access network, we consider a 
Passive  Optical  Network  (PON).  The  single  PON  contains 
several Optical Networking Units (ONUs) that connect with 
the IoT devices via Wi-Fi and aggregate IoT traffic through 
fiber  links  and  a  splitter  towards  an  Optical  Line Terminal 
(OLT) that can be placed at the operator’s exchange office 
[39].  In  the  access  layer,  the  Access  Fog  Node  (AFN) 
containing several servers is connected to the OLT and the 
OLT connects to the metro network through a metro switch. 
The metro switch connects to the core network via multiple 
edge switches. The metro switch is also connected to a Metro 
Fog Node (MFN) which has slightly higher number of servers 
than the AFN due to the number of users it serves. The core 
network is an IP over WDM network, which is comprised of 
a  virtual  and  physical  layer.  In  the  virtual  layer,  IP  routers 
aggregate traffic from the access network and in the physical 
layer,  optical  switches  are  used  to  establish  the connection 
between  the  core  nodes  [40].  In  this  work,  we  consider  a 
single cloud data center that is one hop from the core node 
that aggregates traffic from the metro and access network that 
link the IoT nodes.   

A.  MILP MODEL 
The physical network shown in Figure 1 is modelled as an 
undirected  graph 𝐺 = (𝑁, 𝐿),  where 𝑁 represents  the set  of 
all nodes and 𝐿  the set of links connecting those nodes in the 
topology.  A  virtual  request  is  represented  by  the  directed 
graph  𝐺𝑟 = (𝑅𝑟, 𝐿𝑟) ,  where  𝑅𝑟  is 
the  set  of  VMs 
representing  virtualized  DNN  layers  and  𝐿𝑟  is  the  set  of 
virtual links connecting those VMs. In this subsection, we  

formulate  the  Mixed  Integer  Linear  Programming  model 
(MILP)  that  optimizes  the  placement  of  the  interconnected 
VMs  over  the  proposed  cloud  fog  architecture.  Benefiting 
from our track record in MILP optimization and particularly 
in network virtualization and service embedding in [13], [14], 
respectively,  we  developed  an  optimization  framework  to 
optimally place virtualized DNN functions in the cloud fog 
network.  

B.  NOTATIONS 
Before  introducing  the  optimization  model,  we  define  the 
sets, parameters and variables used:  

Sets: 
𝔻ℂℕ  
𝕄𝔽ℕ 
𝔸𝔽ℕ 
𝕀𝕠𝕋 
𝕀ℕ 

ℙ 

ℝ 
𝕍𝕄𝑟 
ℕ 
ℕ𝑚 

Set of data center node(s). 
Set of MF nodes. 
Set of AF nodes. 
Set of IoT devices. 
Set of IoT nodes generating data for the input 
layer.  
Set of nodes that can process virtual requests, 
where ℙ = 𝔻ℂℕ ∪ 𝕄𝔽ℕ ∪ 𝔸𝔽ℕ ∪ 𝕀𝕠𝕋. 
Set of virtual requests. 
Set of VMs in a virtual request 𝑟 ∈ ℝ.  
Set of all nodes in the CFN architecture.  
Set of neighbor nodes of node m ∈ ℕ. 

Parameters: 
𝑠 𝑎𝑛𝑑 𝑑 

𝑏 𝑎𝑛𝑑 𝑒 

𝑚 𝑎𝑛𝑑 𝑛 

Index  the  source  and  destination  nodes  of  a 
virtual request. 
Index  source  and  destination  of  processing 
nodes hosting VM(s), where  𝑏, 𝑒 ∈ 𝑃, 𝑏 ≠ 𝑒. 
Index the physical links.  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
𝑟 
𝑃𝑠

(𝑛𝑒𝑡) 

𝜋𝑛

𝜖𝑛 

(𝑝𝑟) 

𝜋𝑝

𝑁𝑆𝑝 

𝐸𝑝 
𝛿𝑛 

𝑘 

r = 0. 

r = 1,  if  in  virtual  request  𝑟 ∈ ℝ ,  virtual 
Ps
machine 𝑠 ∈ 𝑉𝑀𝑟 is an input layer, otherwise 
Ps
Idle power consumption of network node 𝑛 ∈
ℕ. 
Energy  per  bit  of  network  node  𝑛 ∈ ℕ,  in 
W/Gb/s. 
Idle  power  consumption  of  a  single  CPU  at 
node 𝑝 ∈ ℙ. 
Maximum  number  of  CPUs  deployed  at 
processing node 𝑝 ∈ ℙ. 
Energy per GFLOP of processing node 𝑝 ∈ ℙ. 
Idle power proportion factor attributed to our 
IoT  application  on  high-capacity  networking 
equipment 𝑛 ∈ 𝑁. 
The number of VMs that can be allocated to a 
single IoT node.   

Variables: 
𝜆𝑏,𝑒 

𝑏,𝑒  
𝜆𝑚,𝑛

𝜆𝑛 

𝛽𝑛 

𝜃𝑝 

Ω𝑝 

𝑁𝑝 

Φ𝑝 

𝑟,𝑠 

𝛿𝑏

∑

𝑏∈ℙ

𝑏∈ℙ

𝑚∈ℕ

∑
∑

𝑒∈ℙ:𝑏≠𝑒

𝑒∈ℙ:𝑏≠𝑒

𝜆𝑛 =

𝑏,𝑒 +
𝜆𝑚,𝑛

𝑛∈ℕ𝑚
∑

Traffic demand between processing node pair 
(𝑏, 𝑒) ∈ ℙ  aggregated  after  all  VSRs  are 
embedded. 
Traffic demand between processing node pair 
(𝑏, 𝑒) ∈ ℙ  aggregated  after  all  VSRs  are 
embedded,  traversing  physical  link  (𝑚, 𝑛) , 
𝑚 ∈ ℕ and 𝑛 ∈ ℕ𝑚. 
Amount of traffic aggregated by network node 
𝑛 ∈ ℕ,  
where 
∑
 ∑
 ∑
∑
𝛽𝑛 = 1, if  network  node  𝑛 ∈ ℕ  is  activated, 
otherwise 𝛽𝑛 = 0. 
Amount  of  traffic  aggregated  by  processing 
node 𝑝 ∈ ℙ. 
Amount of workload in FLOPS, allocated to 
processing node 𝑝 ∈ ℙ. 
Number  of  activated  processing  servers  at 
processing node 𝑝 ∈ ℙ. 
Φ𝑝 = 1 , 
activated, otherwise Φ𝑝 = 0. 
𝑟,𝑠 = 1 ,  if  virtual  machine  𝑠 ∈ 𝑉𝑀𝑟  is 
𝛿𝑏
embedded  for  processing  at  node  b ∈ 𝑃 , 
otherwise 𝛿𝑏

if  processing  node  𝑝 ∈ ℙ  is 

𝑟,𝑠 = 1. 

𝑏,𝑒  
𝜆𝑛,𝑚

𝑚∈ℕ:𝑚≠𝑒

𝑛∈ℕ𝑚

. 

Total power consumption is the sum of two parts: 1) network 
power consumption, 2) processing power consumption. The 
processing  power  consumption  here  includes  switches 
routers and power consumed from servers within those nodes 
to provide (LAN) local area network.  

•  Network Power Consumption (net_pc): 

This is given by: 

∑ 𝜖𝑛. 𝜆𝑛 + ∑ 𝛽𝑛.
𝑛∈ℕ

𝑛∈ℕ

(𝑛𝑒𝑡). 𝛿𝑛
𝜋𝑛

(1) 

The  power  consumption  of  the  networking  equipment 
comprises of power consumption of routers and switches of 
all the nodes in the cloud fog architecture shown in Figure 1. 
The first term calculates the proportional power consumption 

(negligible in this work) and the second term accounts for the 
idle power consumption of the networking equipment.  

•  Processing Power Consumption (proc_pc): 

This is given by: 

∑ 𝐸𝑝. Ω𝑝
𝑝∈ℙ

+ ∑ 𝑁𝑝.
𝑝∈ℙ

(𝑝𝑟)   + ∑ 𝐸𝐿𝑝. 𝜃𝑝
𝜋𝑝

𝑝∈ℙ

(2) 

+  ∑ Φ𝑝. 𝜋𝑝

(𝐿𝐴𝑁). 𝛿𝑛

𝑝∈ℙ

Similarly,  the  first  two  terms  are  the  proportional  and  idle 
power  consumptions  of  processing  servers,  respectively. 
Whilst the third and fourth terms account for the proportional 
and  idle  power  consumption  of  the  LAN  equipment  inside 
server nodes.   

The objective of the model is as follows: 

Minimize: net_pc + proc_pc 

Subject to:  

𝑟,𝑠 = 1

           ∀𝑟 ∈ ℝ, 𝑠 ∈ 𝕍𝕄𝑟: Ps

r ≠ 1 

(3) 

 ∑ 𝛿𝑏
𝑏∈ℙ

Constraint  (3)  ensures  that  VMs  of  all  virtual  requests  are 
embedded, except the input VMs that must be embedded onto 
the preselected IoT acting as the source node.  

∑ ∑ 𝛿𝑏
𝑠∈𝕍𝕄𝑟
𝑏∈𝕀ℕ

𝑟,𝑠 = 1

          ∀𝑟 ∈ ℝ ∶   Ps

r = 1 

(4) 

Constraint (4) ensures that input layers of virtual requests are 
embedded on those IoT nodes acting as source.  

𝑟,𝑠 ≤ 𝑘

∑ ∑ 𝛿𝑏
𝑟∈ℝ
𝑠∈𝕍𝕄𝑟

          ∀𝑏 ∈  𝕀𝕠𝕋 ∶  b ∉ 𝕀𝕀  

(5) 

Constraint (5) restricts the sum of VMs allocated to a single 
IoT node to be less than or equal to the parameter 𝑘.  

∑ 𝜆𝑚,𝑛
𝑛∈ℕ𝑚

𝑏,𝑒 − ∑ 𝜆𝑛,𝑚
𝑛∈ℕ𝑚

𝑏,𝑒 = {

𝜆𝑏,𝑒
−𝜆𝑏,𝑒
0

𝑚 = 𝑠
𝑚 = 𝑑
𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒

(6) 

∀𝑏, 𝑒 ∈ ℙ, 𝑑 ∈ ℙ, 𝑚 ∈ ℕ: 𝑏 ≠ 𝑒. 

Constraint  (4) is the traffic flow conservation constraint that 
preserves the flow of traffic.  

In this paper, due to space limitations, we have only included 
the key parameters, variables, and constraints. The remaining 
constraints  deal  with  traffic  and  CPU  demand  realization, 
binary indicators and capacity constraints.  

RESULTS AND DISCUSSIONS  

III. 
In  our  evaluations,  we  used  the  parameters  in  Table  1  and 
Table  2  for  the  processing  and  networking  devices, 
respectively.    It  is  noteworthy  that,  where  possible,  device 
specifications were collected from manufacturer datasheets, 
however,  we  have  also  made  simple  but  plausible 
assumptions.  For 
instance,  high-capacity  networking 
equipment at the access, metro and core network are highly 
shared  by  many  applications  and  services.  Thus,  we  have 

 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
assumed that only a portion of the idle power which we refer 
to  as  idle  power  proportion  ( 𝛿)  is  attributed  to  our 
application.  The  idle  power  consumption  of  core  network 
devices  is  assumed  to  be  90%  of  the  device’s  peak  power 
consumption.  As  for  lightly  shared  devices  such  as  ONU 
APs, we assume the idle power is 60% of the device’s peak 
power consumption. We also assume the cloud data center is 
a single hop from the aggregating core router and based on 
the topology of the NSFNET, the average distance between 
the  core  nodes  is  509  km  [41].  In  total,  there  are  30  IoT 
devices, uniformly distributed into four IoT zones: IoT Zone 
1 to IoT Zone 4. In each zone, there are five IoT devices that 
are  connected  through  Wi-Fi  links  to  their  corresponding 
ONU AP. In total, we have considered four ONU APs and a 
single OLT device. As for the workloads, we assume that the 
virtual requests are issued by the IoT devices. In this work a 
single IoT device acts as the source node (i.e., the node that 
provides  data  for  the  input  layer).  We  consider  15  virtual 
requests that are all embedded simultaneously on the cloud 
fog  network.  The  number  of  virtual  nodes  (or  VMs)  per 
request  is  assumed  to  be  between  4  –  5  nodes.  The  CPU 
demand per virtual node is randomly distributed between 0.6 
–  10  GFLOPS.  We  assume  that  only  the  input  layer  nodes 
require  negligible  CPU  workload  as  most  of  the  intensive 
tasks are performed by the hidden layers. We have considered 
a linear power consumption profile in the MILP model; hence 
the  proportional  power  consumption  of  networking  is 
negligible  compared  to  the  processing  power consumption. 
The  proportional  power  consumption  is  a  function  of  the 
workload  whilst  the  idle  part  is  consumed  as  soon  as  the 
device is activated. We have assumed that there are enough 
CPU resources at all layers to host all the workloads.  Finally, 
the  MILP  model  is  solved  using  IBM’s commercial  solver 
CPLEX  over  the  University  of  Leeds  high  performance 
computing facilities (ARC3) using 24 cores with 126 GB of 
RAM. 

A.  Single VM Allocation at IoT 
We evaluated the impact of the constraint that only permits 
single VMs to be processed by any IoT device at a given time. 
Our  aim  was  to  represent  a  scenario  in  which,  due  to 
hardware/ software limitations, low power IoT nodes are not 
always capable of processing multiple types of VMs. Figure 
2 shows the total power consumption which is the sum of the 
networking and the processing power consumptions against 
different values of the 𝛿 factor. It can be observed that when 
the 𝛿 factor is low (3%), the model favors the IoT and cloud 
layers  for  processing  the  virtual  requests  due  to  the 
processing  efficiency  of  the  cloud  and  the  low  power 
consumption of the IoT nodes. However, as shown in Figure 
3,  for  cases  where  the   𝛿 is  high  (6%  and  10%),  it  can  be 
observed that the cloud is no longer a favorable choice as it 
loses its merit due to the power consumption of the transport 
network.  This  assumes  that  the  idle  power  of  the  highly 
shared networking equipment grows linearly with the growth 
in  the  IoT  applications  demands.  Interestingly,  despite  the 
ONU  power  consumption  overhead,  the  IoT  is  always  the 
predominant layer in all cases if there is enough processing 
capacity to host all the workloads.    

TABLE I.  

CPU INPUT PARAMETERS  

Devices 

Max(W) 

Idle(W) 

GFLOPS 

IoT CPU 
AFN CPU 

MFN CPU 

Cloud CPU 

7.3 [42] 
37.2 [42] 

37.2 [42] 

298 [42] 

2.56 [42] 
13.8 [42] 

13.8[42] 

58.7 [42] 

13.5 [42] 
34.5 [42] 

34.5 [42] 

428 [42] 

Efficiency 
(W/GFLOPS) 
0.35 
0.67 

0.67 

0.55 

TABLE II.  

NETWORKING INPUT PARAMETERS 

Devices 

Max (W) 

Idle (W) 

ONU Wi-Fi AP 

15 [42] 

9 [42] 

Bitrate  
(Gbps) 
10 [42] 

Efficiency 
(W/Gbps) 
0.6  

OLT 
Metro Router Port 

1940 [42] 
30 [42] 

60 [42] 
27 [42] 

8600 [42] 
40 

Metro Switch 

470 [42] 

423 [42] 

IP/WDM Node 

878 [42] 

790 [42] 

600 

40  

0.22 
0.08 

0.08 

0.14 

3%                            6%                           10% 

Figure 2: Total power consumption under different 
values of 𝛿 when k=1. 

Figure 3: Workload distribution under different values 
of 𝛿 when k=1. 

B.  Multiple VM Allocation at IoT 
In this scenario, we increase the value of the paremer k and 
thus allow multiple VMs to be processed at the IoT layer. In 
Figure 4 and Figure 6, the results show that flexibility in the 
VM  allocation  scheme  substantially  increases  the  power 
savings under all values of 𝛿 by up to 65% compared to the 
single allocation scenario (k=1). In Figure 5, the trends show 
that  the  value  of  𝛿  significantly  influences  the  choice  to 
process VMs at the cloud because of the number of hops it 
takes to get there, hence lower fog layers that are close to the 
source are perfered, despite their processing inefficiency.  As 
can  be  obsereved  in  Figure  5,  when  the  VM  allocation 
constraint  is  relaxed,  the  only  layer  that  is  utilized  for 
processing  is  the  IoT  layer  and  this  only  changes  if  the 
assigned workload exceeds the IoT layer capacity. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3%                           6%                          10% 

Figure 4: Total power consumption under different 
values of 𝛿 when k=2. 

Figure 5: Workload distribution under different values 
of 𝛿 when k=2. 

Figure 6: Total power savings achieved with k=2 
compared to k=1 for different values of 𝛿. 

IV.  CONCLUSIONS  

This  paper  extended  the  work  in  previous  contributions  by 
evaluating the impact of VM allocation flexibly against the 
idle power proportion factor attributed to the considered IoT 
application  in  a  cloud  fog  architecture.  The  results  showed 
substantial  savings  in  the  multiple  VM  allocation  scenario 
compared to the single allocation case due to hosting all the 
workloads on the available IoT nodes. Future work includes 
the design of heuristic algorithms that can solve the problem 
faster compared to the MILP model and evaluating the impact 
of  the  data  rate  between  the  connected  VMs  on  the 
performance of the distributed placement of VMs. 

ACKNOWLEDGMENT 

The first author would like to thank the University of Tabuk 
for funding his PhD scholarship. The authors would like to 
acknowledge  funding  from  the  Engineering  and  Physical 
Sciences  Research  Council 
INTERNET 
(EP/H040536/1),  STAR 
(EP/K016873/1)  and  TOWS 
(EP/S016570/1) projects. All data are provided in full in the 
results section of this paper.  

(EPSRC), 

[1] 

[2] 

[3] 

[4] 

[5] 

[6] 

[7] 

[8] 

[9] 

[10] 

[11] 

[12] 

[13] 

[14] 

[15] 

[16] 

REFERENCES 

pp. 

2020, 

2020, 

912–921, 

Y.  Ashkan  et  al.,  “Jue  Jason  P..  2019,”  All  one  needs  to 
know about fog Comput. Relat. edge Comput. Paradig. A 
Complet. Surv. J. Syst. Archit., vol. 98, pp. 289–330, 2019. 
M.  Kumar,  X.  Zhang,  L.  Liu,  Y.  Wang,  and  W.  Shi, 
“Energy-efficient machine learning on the edges,” Proc. - 
2020 IEEE 34th Int. Parallel Distrib. Process. Symp. Work. 
doi: 
IPDPSW 
10.1109/IPDPSW50202.2020.00153. 
Y. Sahni, J. Cao, S. Zhang, and L. Yang, “Edge Mesh: A 
New  Paradigm  to  Enable  Distributed  Intelligence  in 
Internet of Things,” IEEE Access, vol. 5, pp. 16441–16458, 
2017, doi: 10.1109/ACCESS.2017.2739804. 
B.  R.  Mahmud  R.  Kotagiri  R.,  “Fog  Computing:  A 
Taxonomy,  Survey  and  Future  Directions,”  Springer, 
Singapore., pp. 103–130, 2018, doi: 10.1007/978-981-10-
5861-5_5. 
E. Di Pascale, I. Macaluso, A. Nag, M. Kelly, and L. Doyle, 
“The  Network  As  a  Computer:  A  Framework  for 
Distributed  Computing  over  IoT  Mesh  Networks,”  IEEE 
Internet Things J., vol. 5, no. 3, pp. 2107–2119, 2018, doi: 
10.1109/JIOT.2018.2823978. 
Y.  Ai,  M.  Peng,  and  K.  Zhang,  “Edge  computing 
technologies  for  Internet  of  Things:  a  primer,”  Digit. 
Commun.  Networks,  vol.  4,  no.  2,  pp.  77–86,  2018,  doi: 
https://doi.org/10.1016/j.dcan.2017.07.001. 
S. Sarkar, S. Chatterjee, and S. Misra, “Assessment of the 
Suitability of Fog Computing in the Context of Internet of 
Things,” IEEE Trans. Cloud Comput., vol. 6, no. 1, pp. 46–
59, 2015. 
M. M. Alenazi, B. A. Yosuf, S. H. Mohamed, T. E. H. El-
Gorashi,  and  J.  M.  H.  Elmirghani,  “Energy-Efficient 
Distributed  Machine  Learning  in  Cloud  Fog  Networks,” 
7th IEEE World Forum Internet Things, WF-IoT 2021, pp. 
935–941, 
10.1109/WF-
IoT51360.2021.9595351. 
B.  A.  Yosuf,  M.  Musa,  T.  Elgorashi,  and  J.  Elmirghani, 
“Energy  efficient  distributed  processing  for  IoT,”  IEEE 
Access. 2020. 
S. H. Mohamed, M. B. A. Halim, T. E. H. Elgorashi, and J. 
M.  H.  Elmirghani,  “Fog-Assisted  Caching  Employing 
Solar Renewable Energy and Energy Storage Devices for 
Video  on  Demand  Services,”  IEEE  Access,  vol.  8,  pp. 
115754–115766, 
doi: 
10.1109/ACCESS.2020.3004314. 
Z. T. Al-Azez, A. Q. Lawey, T. E. H. El-Gorashi, and J. M. 
H.  Elmirghani,  “Energy  Efficient  IoT  Virtualization 
Framework  With  Peer 
to  Peer  Networking  and 
Processing,” IEEE Access, vol. 7, pp. 50697–50709, 2019, 
doi: 10.1109/ACCESS.2019.2911117. 
H. A. Alharbi, T. E. H. Elgorashi, and J. M. H. Elmirghani, 
“Energy efficient virtual machines placement over cloud-
fog network architecture,” IEEE Access, vol. 8, pp. 94697–
94718, 2020, doi: 10.1109/ACCESS.2020.2995393. 
A. M. Al-Salim, A. Q. Lawey, T. E. H. El-Gorashi, and J. 
M. H. Elmirghani, “Energy Efficient Big Data Networks: 
Impact of Volume and Variety,” IEEE Trans. Netw. Serv. 
Manag.,  vol.  15,  no.  1,  pp.  458–474,  Mar.  2018,  doi: 
10.1109/TNSM.2017.2787624. 
A. M. Al-Salim, T. E. H. El-Gorashi, A. Q. Lawey, and J. 
M. H. Elmirghani, “Greening big data networks: Velocity 
impact,”  IET  Optoelectron.,  vol.  12,  no.  3,  pp.  126–135, 
Jun. 2018, doi: 10.1049/iet-opt.2016.0165. 
X. Dong, T. El-Gorashi, and J. M. H. Elmirghani, “Green 
IP  over  WDM  networks  with  data  centers,”  J.  Light. 
Technol.,  vol.  29,  no.  12,  pp.  1861–1880,  2011,  doi: 
10.1109/JLT.2011.2148093. 
H. M. M. Ali, T. E. H. El-Gorashi, A. Q. Lawey, and J. M. 

2020, 

2021, 

doi: 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Learning and Big Data Analytics for 6G Networks,” IEEE 
Access,  vol.  8,  pp.  85639–85655,  2020,  doi: 
10.1109/ACCESS.2020.2992555. 

[34]  M.  Hadi,  A.  Lawey,  T.  El-Gorashi,  and  J.  Elmirghani, 
“Using  Machine  Learning  and  Big  Data  Analytics  to 
Prioritize  Outpatients  in  HetNets,”  in  IEEE  INFOCOM 
2019  -  IEEE  Conference  on  Computer  Communications 
Workshops  (INFOCOM  WKSHPS),  2019,  pp.  726–731, 
doi: 10.1109/INFCOMW.2019.8845225. 

7, 

Cellular 

[35]  M. S. Hadi, A. Q. Lawey, T. E. H. El-Gorashi, and J. M. H. 
Elmirghani, 
Networks 
“Patient-Centric 
Optimization  Using  Big  Data  Analytics,”  IEEE  Access, 
doi: 
pp. 
vol. 
10.1109/ACCESS.2019.2910224. 
I. S. B. M. Isa, T. E. H. El-Gorashi, M. O. I. Musa, and J. 
M. H. Elmirghani, “Energy efficient fog-based healthcare 
monitoring  infrastructure,”  IEEE  Access,  vol.  8,  pp. 
doi: 
197828–197852, 
10.1109/ACCESS.2020.3033555. 

49279–49296, 

2019, 

2020, 

[36] 

[37]  M.  Musa,  T.  Elgorashi,  and  J.  Elmirghani,  “Bounds  for 
Energy-Efficient  Survivable  IP  Over  WDM  Networks 
With Network Coding,” J. Opt. Commun. Netw., vol. 10, 
no. 
doi: 
10.1364/JOCN.10.000471. 

471–481,  May 

2018, 

pp. 

5, 

[40] 

[39] 

[38]  M. M. Alenazi, B. A. Yosuf, T. El-Gorashi, and J. M. H. 
Elmirghani,  “Energy  efficient  neural  network  embedding 
in IoT over passive optical networks,” arXiv, pp. 1–6, 2020. 
C.  Gray,  R.  Ayre,  K.  Hinton,  and  R.  S.  Tucker,  “Power 
consumption  of  IoT  access  network  technologies,”  2015 
IEEE  Int.  Conf.  Commun.  Work.,  pp.  2818–2823,  2015, 
doi: 10.1109/ICCW.2015.7247606. 
G. Shen and R. S. Tucker, “Energy-Minimized Design for 
IP Over WDM Networks,” vol. 1, no. 1, pp. 176–186, 2009. 
G.  S.  G.  Shen  and  R.  S.  Tucker,  “Energy-Minimized 
Design for IP Over WDM Networks,” IEEE/OSA J. Opt. 
Commun.  Netw.,  vol.  1,  no.  1,  pp.  176–186,  2009,  doi: 
10.1364/JOCN.1.000176. 
B.  A.  Yosuf,  S.  H.  Mohamed,  M.  Alenazi,  T.  E.  H.  El-
Gorashi,  and  J.  M.  H.  Elmirghani,  “Energy-Efficient  AI 
over a Virtualized Cloud Fog Network.” 2021. 

[42] 

[41] 

pp. 

23, 

[24] 

[23] 

[17] 

[18] 

[19] 

[20] 

[22] 

Dec. 

2018, 

2017, 

5361–5380, 

5395–5405,  Dec. 

(Presentation  Summary),” 

H. Elmirghani, “Future Energy Efficient Data Centers with 
Disaggregated Servers,” J. Light. Technol., vol. 35, no. 24, 
doi: 
pp. 
10.1109/JLT.2017.2767574. 
N.  I.  Osman,  T.  El-Gorashi,  L.  Krug,  and  J.  M.  H. 
Elmirghani, “Energy-efficient future high-definition TV,” 
J.  Light.  Technol.,  vol.  32,  no.  13,  pp.  2364–2381,  Jul. 
2014, doi: 10.1109/JLT.2014.2324634. 
A. Q. Lawey, T. E. H. El-Gorashi, and J. M. H. Elmirghani, 
“BitTorrent  content  distribution  in  optical  networks,”  J. 
Light. Technol., vol. 32, no. 21, pp. 3607–3623, Nov. 2014, 
doi: 10.1109/JLT.2014.2351074. 
A. Q. Lawey, T. E. H. El-Gorashi, and J. M. H. Elmirghani, 
“Distributed  Energy  Efficient  Clouds  over  Core  Optical 
Networks 
in  Advanced 
Photonics  for  Communications,  2014,  p.  PW1B.4,  doi: 
10.1364/PS.2014.PW1B.4. 
J. M. H. Elmirghani et al., “GreenTouch GreenMeter Core 
Network  Energy-Efficiency  Improvement  Measures  and 
Optimization,” J. Opt. Commun. Netw., vol. 10, no. 2, pp. 
A250----A269, Feb. 2018, doi: 10.1364/JOCN.10.00A250. 
[21]  M.  O.  I.  Musa,  T.  E.  H.  El-Gorashi,  and  J.  M.  H. 
Elmirghani,  “Bounds  on  GreenTouch  GreenMeter 
Network  Energy  Efficiency,”  J.  Light.  Technol.,  vol.  36, 
no. 
doi: 
10.1109/JLT.2018.2871602. 
X. Dong, T. E. H. El-Gorashi, and J. H. Elmirghani, “On 
the Energy Efficiency of Physical Topology Design for IP 
Over WDM Networks,” J. Light. Technol., vol. 30, no. 11, 
pp. 1694–1705, Jun. 2012. 
B.  G.  Bathula  M.  Alresheedi  and  J.  M.  H.  Elmirghani, 
“Energy  Efficient  Architectures  for  Optical  Networks,” 
2009. 
B. G. Bathula and J. M. H. Elmirghani, “Energy Efficient 
Optical  Burst  Switched  (OBS)Networks,” 
in  IEEE 
GLOBECOM’09, Honolulu, Hawaii, USA, 2009, pp. 1–6. 
T. E. H. E.-G. X. Dong and J. M. H. Elmirghani, “Green 
optical  orthogonal 
frequency-division  multiplexing 
networks,” IET Optoelectron., vol. 8, no. 137–148, 2014. 
X. Dong, T. El-Gorashi, and J. M. H. Elmirghani, “IP over 
WDM networks employing renewable energy sources,” J. 
Light.  Technol.,  vol.  29,  no.  1,  pp.  3–14,  2011,  doi: 
10.1109/JLT.2010.2086434. 
X.  Dong,  A.  Lawey,  T.  E.  H.  El-Gorashi,  and  J.  M.  H. 
Elmirghani,  “Energy-efficient  core  networks,”  2012,  doi: 
10.1109/ONDM.2012.6210196. 
H. A. Alharbi, T. E. H. Elgorashi, and J. M. H. Elmirghani, 
“Impact  of  the  Net  Neutrality  Repeal  on  Communication 
Networks,” IEEE Access, vol. 8, pp. 59787–59800, 2020, 
doi: 10.1109/ACCESS.2020.2983314. 
L. Nonde, T. E. H. El-Gorashi, and J. M. H. Elmirghani, 
“Energy  Efficient  Virtual  Network  Embedding  for  Cloud 
Networks,”  J.  Light.  Technol.,  vol.  33,  no.  9,  pp.  1828–
1849, 2015, doi: 10.1109/JLT.2014.2380777. 
H. Q. Al-Shammari, A. Q. Lawey, T. E. H. El-Gorashi, and 
J.  M.  H.  Elmirghani,  “Service  Embedding  in  IoT 
Networks,” IEEE Access, vol. 8, pp. 2948–2962, 2020, doi: 
10.1109/ACCESS.2019.2962271. 
A. N. Al-Quzweeni, A. Q. Lawey, T. E. H. Elgorashi, and 
J.  M.  H.  Elmirghani,  “Optimized  Energy  Aware  5G 
Network Function Virtualization,” IEEE Access, vol. 7, pp. 
44939–44958, 
doi: 
10.1109/ACCESS.2019.2907798. 
H. Q. Al-Shammari, A. Q. Lawey, T. E. H. El-Gorashi, and 
J. M. H. Elmirghani, “Resilient Service Embedding in IoT 
Networks,”  IEEE  Access,  vol.  8,  pp.  123571–123584, 
2020, doi: 10.1109/ACCESS.2020.3005936. 

2019, 

[31] 

[26] 

[29] 

[30] 

[32] 

[25] 

[27] 

[28] 

[33]  M. S. Hadi, A. Q. Lawey, T. E. H. El-Gorashi, and J. M. H. 
Elmirghani, “Patient-Centric HetNets Powered by Machine 

 
