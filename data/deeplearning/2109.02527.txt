VulSPG: Vulnerability detection based on slice
property graph representation learning

1st Weining Zheng
Harbin Institute of Technology
Harbin, China
20B903074@stu.hit.edu.cn

2nd Yuan Jiang
Harbin Institute of Technology
Harbin, China
jiangyuan@hit.edu.cn

3rd Xiaohong Su*
Harbin Institute of Technology
Harbin, China
sxh@hit.edu.cn

1
2
0
2

p
e
S
6

]

R
C
.
s
c
[

1
v
7
2
5
2
0
.
9
0
1
2
:
v
i
X
r
a

Abstract—Vulnerability detection is an important issue in
software security. Although various data-driven vulnerability de-
tection methods have been proposed, the task remains challenging
since the diversity and complexity of real-world vulnerable code
in syntax and semantics make it difﬁcult to extract vulnerable fea-
tures with regular deep learning models, especially in analyzing
a large program. Moreover, the fact that real-world vulnerable
information unrelated to
codes contain a lot of redundant
vulnerabilities will further aggravate the above problem. To
mitigate such challenges, we deﬁne a novel code representation
named Slice Property Graph (SPG), and then propose VulSPG,
a new vulnerability detection approach using the improved R-
GCN model with triple attention mechanism to identify potential
vulnerabilities in SPG. Our approach has at least two advantages
over other methods. First, our proposed SPG can reﬂect the
rich semantics and explicit structural information that may be
relevance to vulnerabilities, while eliminating as much irrelevant
information as possible to reduce the complexity of graph.
Second, VulSPG incorporates triple attention mechanism in R-
GCNs to achieve more effective learning of vulnerability patterns
from SPG. We have extensively evaluated VulSPG on two large-
scale datasets with programs from SARD and real-world projects.
Experimental results prove the effectiveness and efﬁciency of
VulSPG.

Index Terms—Security, Vulnerability detection, Program rep-
resentation learning, Deep graph neural network, Program slicing

I. INTRODUCTION

Source code-based vulnerability detection is a classic prob-
lem, in which considerable efforts have been made in the past
decade, such as employing static and dynamic analysis tools to
ﬂag potentially dangerous code as candidate vulnerabilities so
that it can gain special attention [1], [2]. However, many meth-
ods rely on rules manually curated by experts in the security
domain, which usually suffer from low coverage (leading to
false negatives) and high-cost (due to false positives) [3] [4].
Moreover, these methods are not suitable for tracking existing
unknown vulnerabilities on a large scale [5].

Along with the rapid development of artiﬁcial intelligence
and the increasing accessibility of large scale open-source
code repository, many works begin to apply deep learning to
vulnerability detection considering that deep neural networks
can extract features in an automatic way, instead of being
designed by domain experts. For example, Li et al. [6]
proposed a systematic framework SySeVR to represent the
syntax and semantic information pertinent to vulnerabilities, in

which program slicing technique [7] is used to produce smaller
code segments (i.e., some possibly discontinuous but semantic
and vulnerability-related statements), making it applicable for
deep learning networks. Although SySeVR improves the per-
formance of deep learning models in vulnerability detection,
it still has two weaknesses: (1) Code segments generated
by SySeVR can only cover limited types of vulnerabilities,
especially for real-world programs. (2) A sequential neural
work (e.g., LSTM or GRU) is used to encode code segments
in the form of plain texts, which may lose the information
of data and control dependencies among statements in code
segments, and therefore cannot effectively learn the non-
sequential features of graph-based information.

To preserve the complex structral and sementic information
of source code and effectively learn these non-sequential
features of graph-based information, Zhou et al. [8] proposed
a GGNN-based vulnerability detection model Devign, which
ﬁrst integrates syntax and dependency information of source
code into a joint graph representation, and then extracts
vulnerability-relevant features from the composite graph with
the help of GNNs. However, due to the very small proportion
of vulnerable statements in real-world functions, the large
amount of information irrelevant with any vulnerability pat-
terns in the composite graph will hinder the accurate learning
of the vulnerability patterns.

To mitigate the above problems, we deﬁne a novel graph-
and-slice based code representation named Slice Property
Graph (SPG). Compared with other graph-based code rep-
resentations,
it aims to
the proposed SPG differs in that
not only preserve the rich semantics and explicit structural
information that may be relevant to vulnerabilities, but also
eliminate irrelevant information as much as possible to reduce
the complexity of graphs. To this end, based on the four SyVCs
(Syntax-based Vulnerability Candidates) proposed by Li et
al. [6], we ﬁrst add two kinds of new SyVCs to improve
the vulnerability coverage of program slicing. Using these
six kinds of SyVCs as slicing criterion, we use program
slicing technique to extract the slice nodes which might be
relevant to vulnerabilities. Then, we take the data dependency,
control dependency, and function call dependency between
the extracted slice nodes as edges to generate SPG. All
these dependency are extracted from the code property graph
(i.e. CPG) [9] which combines abstract syntax tree (AST)

1

 
 
 
 
 
 
[10], control ﬂow graph (CFG) [11] and program dependency
graph (PDG) [11] into a single data structure. Next, we
propose a new vulnerability detection approach, i.e., VulSPG,
which combines the improved relational graph convolutional
network (R-GCN) [12] model with triple attention mechanism
to identify potential vulnerabilities in SPGs. More concretely,
the R-GCN can perform representation learning on SPGs with
multiple attributes and dependencies, and the triple attention
mechanism helps the detection model focus on vulnerability
features and suppress unimportant ones via learning attention
weight. We evaluated the proposed method on two datasets,
and the experimental results demonstrate that VulSPG can
identify vulnerabilities more accurately than the baselines.

The main contributions of our work are:
• We design a new code representation SPG, which can
encode vulnerable code into a graph data structure and
eliminate as much redundant information that may not
be relevant to vulnerabilities as possible. To improve the
vulnerability coverage of SPG, two new kinds of SyVCs
are added to generate SPGs.

• We propose the R-GCN model with triple attention
mechanism for representation learning of SPG, which can
efﬁciently and accurately capture vulnerability-related
features in SPG for vulnerability detection tasks.

• We

conduct
the

intensive
verify
effectiveness
proposed method through comparative
with
https://github.com/zhengweining1/VulSPG.

other methods. The

evaluation
and

data

is

of VulSPG to
of
the
experiments
at
available

superiority

II. MOTIVATION

A. Motivation for Slice Property Graph

Fig. 1(a) and Fig. 1(b) shows the vulnerable code in the
FFmpeg project that was ﬁxed in revision 486f0b0, which
contains two vulnerabilities: a) Divide By Zero. When the pro-
gram passes the parameter size to the function ff png zallo(),
an error is raised at the statement if(items ≥ UINT MAX /
size) if the attacker sets the value of size to 0. b) Uninitialized
Memory. The function ff png zallo() calls the av malloc() to
request memory without initializing it. Fig. 1(c) shows the
patched code for this vulnerable program.

Fig. 1. Motivation example.

2

From this example, we obtain the following observations:
Observation 1. Vulnerabilities in real-world projects usu-
the
ally span multiple functions or ﬁles. For example,
Uninitialized-Memory vulnerability in Fig. 1 spans the func-
tion ff png zallo() and av malloc(). Therefore, interprocedural
analysis is necessary for detecting vulnerabilities across mul-
tiple functions or even ﬁles, that is, calling relations between
functions should be included in code representation to enable
it to entirely characterize these vulnerabilities.

Observation 2. There are usually a large number of vulnera-
bility independent statements in vulnerable code. For example,
the vulnerable code in Fig. 1 has 70 lines of statements, but
only a few of them are logically and semantically to any
potential vulnerability. The divide-by-zero vulnerability is only
related to the parameter size and the conditional statement
if(items≥UINT MAX/size). The uninitialized-memory vulner-
ability is related to return av malloc(items*size);, ptr = mal-
loc(size);, return ptr;. Taking the vulnerable code shown in
Fig. 1 as example, the composite graph proposed by Devign
[8] can comprehensively characterize the program by merging
AST, CFG, Data ﬂow Graph (DFG) and Natural Code Se-
quence (NCS) into one graph. It contains 171 nodes and 322
edges, but only several nodes and edges are relevant to the
vulnerability.

SySeVR [6] proposed by Li et al. utilizes program slic-
ing technique to generate a set of code statements that
are semantically related to the vulnerability called SeVCs
(Semantic-based Vulnerability Candidates). In fact, SeVCs is
an ordered set of statements which include backward, forward
and interprocedural program slice. Fig. 1(d) shows the SeVC
generated by SySeVR based on the sensitive function malloc()
(a FC-kind SyVC). It provides an entire representation of
the uninitialized-memory vulnerability through interprocedural
slicing, and reduces a large number of statements that are
unrelated to the vulnerability. However, SySeVR leverages
token-based sequential representation, which cannot reﬂect
complex structural information and dependencies in the code.
The need to model the logic and structure of programs in
vulnerability detection tasks has been demonstrated in [8] and
[13]. Furthermore, the SeVCs generated by using 4 types
of slicing criterions can only cover part of the vulnerable
statements in the source code. Taking the SARD dataset
provided by Li et al. themselves as an example, about 93.6% of
all vulnerable codes in the dataset can be covered by SeVCs,
but there are still 890 vulnerable codes that cannot be covered.
To overcome these challenges, we are encouraged to design
a more effective code representation, which needs to satisfy
several conditions. 1) It should contain the calling relations
between functions. 2) It is capable of eliminating redundant
information that may not be relevant to the vulnerability as
much as possible but can cover more vulnerable code. 3) It is
able to characterize the logic and structure of the vulnerable
code with a small yet semantically rich graph. To this end, we
design SPG, a edge-labeled and directed attributed multigraph,
for code representation. The deﬁnition and the generation
process of SPG can be found in section III and section IV-A.

B. Motivation for Using Graph Neural Network

Current popular approaches convert the various represen-
tations of code into a tiled sequence and then use deep
learning models (usually CNNs and RNNs) to learn the code
representation as natural language sequences [14] [15] [16].
However, SPG as a kind of graph data is irregular, each node
in the graph may have a different number of neighboring nodes
and the data samples of each node are not independent of each
other but are related to other nodes, making it hard for general
deep learning algorithms to learn the structural features of
the graph. Hence, to obtain a more accurate characterization
of the vulnerability code, we select Graph Neural Networks
(GNNs) to learn the topology structure and node representation
information directly from the SPG. We choose Relational
Graph Convolutional Networks (R-GCNs) rather than other
graph convolutional networks [17], such as GraphSAGE [18],
Gated graph sequence neural networks (GGNN) [19], to learn
the characteristics of nodes for two reasons. First, the edges
of the SPG are directed, and the directional information of the
edges cannot be properly learned by using non-directed GNN
models. Second, SPG contains multiple relationships between
its nodes, and R-GCN can better exploit these relationships to
learn representations of source code.

C. Motivation for Using the Triple Attention Module

Different syntax elements in the source code are of different
importance for the detection of vulnerabilities. For example,
a statement of type CallExpression related to an API function
call may contain more information about the vulnerability.
Besides, the code structure contains several other independent
dependencies, such as data dependencies, control dependen-
cies and function call dependencies, and the importance of
these dependencies varies from one vulnerability to another.
For example, data dependencies may be more important than
control dependencies in vulnerabilities related to the use of
arrays. Therefore, we introduce an attention mechanism to pay
more attention to the key vulnerability features so that these
features have a greater impact on the classiﬁcation results.
However, there are still some obstacles in applying them to
vulnerability detection. First, the attention mechanism should
ﬁt both the proposed SPG and the GNN model used in this
paper. Second, the attention mechanism needs to be better
adapted to the problem of vulnerability detection.

III. OVERVIEW

As shown in Fig. 2, the proposed VulSPG method contains

four phases:

1) SPG Generating Phase. To generate the corresponding
SPGs of programs, we ﬁrst traverse the program’s AST and
identify key points (or called SyVCs [6]) with special syntactic
features that are likely to trigger any vulnerability. Then,
program slicing technique is applied to ﬁnd the semantically
related nodes (called slice nodes) in PDG to SyVCs. Finally,
the slice nodes are connected, through the data-, control- and
function call-dependency, to form the SPG structures as shown
in Fig. 4. For clarity, the proposed SPGs is deﬁned as follows:

Slice Property Graph (SPG): SPG is a novel code repre-
sentation which merges data dependency graph (DDG), control
dependency graph (CDG) and function call dependency graph
(FCDG) into a joint graph data structure. Formally, a slice
property graph can be denoted as gSP G = (V, E, X, D) where
V is a set of slice nodes, E is a set of directed edges, X is the
set of property values of nodes, and D is the set of property
values of directed edges.

2) Graph Node Embedding Phase. In this phase, we ini-
tialize the feature vector for each node in SPG. Firstly, every
node of SPG described one code statement is lexied into a
sequence of tokens, each of which is then embedding into
a continuous distributed vector via the pre-trained word2vec
model. Secondly, using these vectors as input, the semantic-
feature vectors of the nodes in SPG are obtained by the token-
level attention method in the triple attention mechanism. Next,
the node type information is embedded into the node-type
vector via one-hot encoding, and it is fed into a linear layer by
concatenating it with the semantic-feature vector. The output
result is the initial vector of SPG nodes.

3) Graph Encoding Phase. In this phase, we ﬁrst learn
the hidden states of the nodes of SPG, DDG, CDG, and
FCDG through graph encoding networks, respectively. Then,
the hidden states of the nodes can be used for weighted
summation to calculate the features of SPG and its sub-
graphs including DDG, CDG, and FCDG. The weights can be
obtained through the node-level attention mechanism. Next,
we obtain the feature vector of the subgraph by integrating
all subgraphs through a subgraph-level attention mechanism.
Finally,
the SPG feature vector and the subgraph feature
vectors are concatenated and fed into the classiﬁer network
to train the model.

4) Vulnerability detection phase. In this phase, we use the
model trained in the previous phases to detect whether the
input SPG is vulnerable or not.

IV. METHODOLOGY

A. SPG Generating Phase

In this section, we describe the process of generating the

SPG which can be divided into three steps.

Step 1. The source code is ﬁrst parsed by using open-source
tool joern1 to produce a series of code representations (e.g.,
AST, PDG, CPG), which enable us to analyze the structure of
source code and function calls as well as dependencies in the
program.

Step 2. We search ASTs for SyVCs as a set of slicing cri-
terions through matching some vulnerability candidate syntax
characteristics. The paper uses following six types of SyVCs:
API/Library Function Call (FC), Array Usage (AU), Pointer
Usage (PU), Arithmetic Expression (AE), Function Parameter
(FP) and Function Return statement (FR), where the ﬁrst four
types come from the work of Li et al [6] (please refer their
work for details), and the other two types are proposed in this
paper to improve the coverage of the vulnerability by the SPG.

1https://joern.readthedocs.io/

3

Fig. 2. The processing framework of VulSPG.

Fig. 3 shows an example of matching the FP-kind and FR-kind
syntax characteristics for the vulnerable code given in Fig. 1.
We use this example to illustrate how to match FR-kind and
FP-kind SyVCs.

the set IF SNk(cej) of interprocedural forward slice nodes.
Finally, we merge all the interprocedural forward slice nodes
to obtain the set IF SN (cej) of interprocedural forward slice
nodes.

• The highlighted node in Figure 3(a) matches the FP-kind
syntax characteristic, because it satisﬁes the following
two conditions: 1) its type is “Identiﬁer”, and 2) it has a
parent node of type “Parameter”.

• The highlighted node in Figure 3(b) matches the FR-kind
syntax characteristic, because it satisﬁes the following
two conditions:1) its type is “Identiﬁer”, and 2) it has
a parent node of type “Returnstatement”.

Step 3. Using the SyVCs obtained in step 2 as the slicing
criterion, we traverse the PDG obtained in step 1 to get a
set of statements (called slice nodes) related to each slicing
criterion. Next, we obtain data- and control-dependencies as
well as function calls among slice nodes from CPG. Finally,
the union of all dependency sets and functions calls induces the
proposed SPG, where nodes are slice nodes and directed edges
represent the dependency and call relationships between slice
nodes. The detailed process is shown in Algorithm 1, which
can be divided into four parts:

i

1) Generating the CPG and PDGs (Line 1-5 in Algorithm
1): We ﬁrst generate the CPG gCP G for program P . Then, we
generate a PDG gP DG

for each function fi ∈ P .

2) Extracting the set of forward slice nodes (Line 6-14 in
Algorithm 1): First, using one SyVC cej as a slicing criterion,
we forward traverse gP DG
of function fi to obtain the set
F SN (cej) of forward slice nodes. Then, for each node nk in
F SN (cej), it is considered as caller nodes if it or its child is
of type “CallExpression”. For the corresponding function fl,
we perform forward traverse over the PDG gP DG
to obtain

i

l

i

3) Extracting the set of backward slice nodes (Line
15-23 in Algorithm 1): First, using SyVC cej as slicing
criterion, we backword traverse gP DG
of function fi to obtain
the set BSN (cej) of backward slice nodes. Next, we query
all nodes in gCP G to search a node nz that satisﬁes one
of the following two conditions: 1) nz or its child node
is of type “CallExpression” and calls fi; 2) nz is of type
“ReturnStatement” and belongs to the function fl called by
fi; Finally, we backward traverse the PDG of the correspond-
ing function using nz as a starting node to obtain the set
IBSNz(cej) of interprocedural backward slice nodes and
merge all the interprocedural backward slice nodes to obtain
the set IBSN (cej) of interprocedural backward slice nodes.
4) Generating the SPG (Line 24-33 in Algorithm 1):
First, we merge the sets F SN (cej) and IF SN (cej) obtained
from part 2) and the sets BSN (cej) and IBSN (cej) obtained
from part 3) to generate the set SN (cej) of slice nodes. Next,
we add each control or data dependency edge eq, the source
node src(eq) and the end node end(eq) of eq in gCP G to
SPG gSP G
if src(eq) ∈ SN (ceq) and end(eq) ∈ SN (ceq).
Then, we analyze the calling relationships between functions
according to gCP G and add the function call dependency egdes
to gSP G
. Speciﬁcally, if function f1 calls function f2, we add
j
function call dependency edge with node in f1 which calls
function f2 as the source node and “FunctionDef” node in f2
as the end node.

j

Considering the tradeoff between time cost and perfor-
mance, only one layer depth of call function is considered

4

in our inter-procedural analysis. Taking the vulnerable code
in Fig. 1 as an example, we use the FP-kind SyVC size as
a slicing criterion to generate the SPG shown in Fig. 4. The
yellow nodes which connected by a data dependency edge in
SPG are related to the divide by zero vulnerability, illustrating
that the vulnerability is only related to data dependency. The
blue nodes are related to the uninitialized memory vulnera-
bility. These four nodes are connected in turn by function
call dependency edge, control dependency edge, and data
dependency edge, illustrating the necessity of representing the
vulnerability by these three types of dependencies together.

B. Graph Node Embedding Phrase

Embedding Nodes of SPG: To encode the semantic and
type information of nodes in the SPG, we use the following to
generate the initial embedded vectors of the SPG nodes. For
the semantic information of the nodes, we ﬁrst perform lexical
analysis for each statement and create a vector of lexical tokens
via the pretrained word2vec model. Next, the dependencies
between tokens in each statement are captured using a token-
level attention mechanism to obtain a semantic feature vector
of the SPG node, the detailed procedure of which can be
found in Section IV-D. For the type information of nodes, we
represent the type of each node as a one-hot vector. Since the
semantic feature vector and type feature vector do not belong
to the same semantic space, we concatenate the two vectors
and feed them to a linear layer to ﬁnally obtain the initial
embedded vector of the node. The parameters in the linear
layer can be trained simultaneously with the vulnerability
detection model. Formally, a SPG gSP G(V, E, X, D) is a
directed multigraph with labeled edges. For each node vi ∈ V
in SPG, there is a corresponding xi ∈ X to represent its
feature vector, which is obtained from the semantic feature
vector and the type feature vector through a linear layer, i.e.
xi = Wl(xse
)+bl. Wl and bl are the parameters that can
i
and xtype
be learned in the linear layer, xse
are respectively
i
i
the corresponding semantic feature vector and the type feature
vector of node vi. xi is the corresponding initial embedded
vector of node vi, the symbol || represents the concatenating
operation. For each edge ej ∈ E in SPG, a corresponding

i ||xtype

Algorithm 1 Generating SPGs by SyVCs

Input: A program P = {f1, ..., fη}, a set Y of SyVCs;
Output: The set G of SPGs
1: G ← ∅;
2: Generate a CPG gCP G for P ;
3: for each function fi ∈ P do
4:
5: end for
6: for each cej ∈ Y in gP DG
7:

Generate a PDG gP DG

for fi;

do

i

i

SN (cej ), F SN (cej ), IF SN (cej ), BSN (cej ), IBSN (cej ) ← ∅;

8:
9:
10:

11:

12:
13:
14:
15:
16:
17:

18:

19:

20:

21:
22:
23:
24:

25:
26:

Generate the set F SN (cej ) of forward slice nodes from gP DG
for each node nk ∈ F SN (cej ) do

i

;

if nk or its child node is of type “CallExpression” & nk contains
the function name fl ∈ P called by fi then

Generate the set IF SNk(cej ) of interprocedural forward slice
nodes from gP DG

;

end if
IF SN (cej ) ← IF SN (cej ) ∪ IF SNk(cej );

end for
Generate the set BSN (cej ) of backward slice nodes from gP DG
for each node nz ∈ gCP G do

i

;

if nz or its child node is of type “CallExpression” & nz contains
the name of function fi & nz belongs to the function fm ∈ P
calling fi

then

Generate the set IBSNz(cej ) of interprocedural backward slice
nodes from gP DG
m ;

else if nz is a node of type “ReturnStatement” & nz belongs to
the function fl ∈ P called by fi

then

Generate the set IBSNz(cej ) of interprocedural backward slice
nodes from gP DG

;

l

l

end if
IBSN (cej ) ← IBSN (cej ) ∪ IBSNz(cej );

end for
SN (cej ) ← F SN (cej ) ∪ IF SN (cej ) ∪ BSN (cej ) ∪ IBSN (cej )

for each edge eq ∈ gCP G do

if src(eq) ∈ SN (ceq) & end(eq) ∈ SN (ceq) & eq is
data/control dependency edge then

Add nodes src(eq), end(eq) and edge eq to gSP G

;

j

end if

27:
28:
29:
30:
31:
32: end for
33: Return G;

end for
Add function call dependency edges to gSP G
G ← G ∪ gSP G

j

;

j

dj ∈ D denotes its label, where D contains three types: data-
, control-, and function call-dependency.

Dividing subgraphs of SPG: To better distinguish depen-
dencies in SPG and provide a basis for the attention mecha-
nism based on subgraphs, we divide SPG into three types of
subgraphs according to the dependencies in SPG, including
Control Dependency Graph (CDGSP G), a Data Dependency

Fig. 3. Examples for FP-kind and FR-kind SyVCs

Fig. 4. An example of SPG for the vulnerable code in Fig. 1

5

Graph (DDGSP G) and a Function Call Dependency Graph
(F CDGSP G). If the program does not contain a certain
dependency that causes the subgraph to be empty, it can be
directly treated as a 0-vector of the same dimension.

C. Graph Encoding Network

In this section, we use R-GCN to perform representation
learning on SPG and its subgraphs. A graph data structure
can be denoted as gG(V, E, X, D), where the superscript G ∈
{SP G, CDGSP G, DDGSP G, F CDGSP G} refers to the type
related to the graph g. For each graph, we can use a R-GCN
to learn the hidden state of each node in each layer as follows.

h(l)
i = σ(

(cid:88)

(cid:88)

d∈D

vj ∈N d
i

1
|N d
i |

j W (l−1)
h(l−1)

d

+ h(l−1)

i W (l−1)

0

) (1)

i

and h(l−1)
i

where l < L denotes the l-th layer. h(l)
i ∈ Rz is the hidden
state of the node vi at layer l, and h(l−1)
∈ Rz is the hidden
state of the node vi at the previous layer l − 1, where both
h(l)
are z-dimensional vectors. d ∈ D denotes an
i
edge type that could be one of the dependency relationships
{DAT A, CON T ROL, F U N CT ION CALL}. N d
i denotes
the set of neighboring nodes that point to node vi under
dependency d, i.e., if vj ∈ N d
i , then there must exist an edge
with type d from vj to vi. |N d
i | denotes the number of nodes
∈ Rz×z and W (l−1)
i . Both W (l−1)
in the set N d
∈ Rz×z are
0
weight matrices, but W (l−1)
corresponds to the dependency d
while W (l−1)
has no corresponding dependency. The node
initialization state can be seen as the hidden state in the
network at layer 0, i.e., h(0)
i = xi ∈ Rz. At this stage, the
weight matrix will also turn to be W (0)
d , W (0)
∈ Rz×z.
After performing the aggregation operation on gG with L
layers of R-GCN, we concatenate the hidden states of the
nodes in each layer as the ﬁnal node representation,
i.e.,
i = (h(0)
hG

) ∈ R(L+1)·z.

|| · · · ||h(L)

||h(1)
i

d

d

0

0

i

i

D. The Triple Attention Mechanism

Token-level Attention mechanism: The token-level atten-
tion mechanism is primarily designed to obtain dependency
information between tokens within a statement to help gen-
erate a more accurate semantic vector representation of each
statement node. Speciﬁcally, the tokens in each statement node
are ﬁrst embedded into ﬁxed-dimensional vectors via a pre-
trained word2vec model. Next, we add positional embeddings
to the token vectors to encode the position of the tokens with
repspect to the sequence. Finally, these vectors are fed into
the attention layer to learn the semantic vector representation
of each statement node. The reason for using multi-head
self-attention rather than typical RNNs (GRU, LSTM, et al.)
or CNN is as follows: (1) the self-attention method uses a
large number of parallel operations and is computationally
faster than most of the other techniques mentioned above.
(2) compared to RNN and CNN, the self-attention method
has been shown to be more capable to learn long-range
dependencies among tokens [20].

Formally, let the statement node vi contains m tokens and
Ti = [ti,1, ti,2, · · · , ti,m]T ∈ Rm×c be the semantic matrix
corresponding to vi, where ti,j ∈ Rc denotes the embedding
vector of the j-th token in the statement. Note that
the
positional encodings used in ti,j are calculated in the same way
as taken in [20]. Then, the semantic vector xse
i corresponding
to the node vi can be calculated in (2).

Attention(Q, K, V ) = sof tmax(

QK T
√
c

)V

M utiHead(Q, K, V ) = (head1||head2|| · · · ||heada)
where headp = Attention(QW Q
xse
i = f latten(M utiHead(Ti, Ti, Ti))

p , V W V
p )

p , KW K

(2)

where M utiHead is a multi-head self-attention method that
maps a variable-length sequence of code representations to
another sequence of equal length, which contains the semantic
features of the tokens in the statement. f latten is a function
that ﬂattens the resulting semantic sequence into a one-
dimensional vector for easy computation of node initialization
later (Section IV-B).

Node-level Attention mechanism: We establish the node-
level attention mechanism to obtain the vector representations
of SPG and its three subgraphs, as shown in the right part of
Fig. 2. For the SPG and its subgraphs, we refer to the attention
method in SAGPOOL [21] to calculate the attention score
of each node by taking into account both the characteristics
of the nodes themselves and the topology of the graph. The
calculation equation is as follows:

zG
i = σ(

(cid:88)

(cid:88)

d∈D

vj ∈N d
i

1
|N d
i |

j ΘG
hG

d + hG

i ΘG
0 )

where G ∈ {SP G, CDGSP G, DDGSP G, F CDGSP G}

(3)
where zG
i ∈ R denotes the attention score of the node vi in
the graph gG. ΘG
d ∈ R(L+1)·z and ΘG
0 ∈ R(L+1)·z are both
learnable parameters in the model, ΘG
d corresponds to the
dependency d while ΘG
0 has no corresponding dependency.
The other parameters are the same as those presented in
Section IV-C.
i = sof tmax(zG
aG

i ) =

exp(zG
i )
k∈|VG| exp(zG
k )

(cid:80)

(4)

SG =

(cid:88)

i∈|VG|

αG
i

· hG
i

To avoid loss of information, instead of using the top-
K method to eliminate nodes, we perform the weighted
summation operation over all nodes based on self-attention
values to ensure that each node in the SPG contributes to the
result. Therefore, the feature vector of the graph gG can be
calculated in (4). αG
is the attention weight corresponding
i
to node vG
i , which is obtained by normalizing the attention
scores of all nodes in the graph gG by the softmax function.
VG = {vG
1 , . . . , vG
|VG|} is the set of nodes of the graph
is the attention score corresponding to node vG
gG and zG
i .
i
SG ∈ R(L+1)·z is the feature vector of the graph gG.

i , . . . , vG

Subgraph-level Attention mechanism: After obtaining the
vector representations of the SPG, CDGSP G, DDGSP G and

6

F CDGSP G, we propose the subgraph-level attention mecha-
nism to obtain the feature vector of the combined three types
of subgraphs. In our approach, the attention of a subgraph of
SPG indicates the importance of the subgraph to the SPG,
which can be calculated in (5).
subWrSSP G

rsub = ST
sub ∈ {CDGSP G, DDGSP G, F CDGSP G}
Where sub denotes the type related to the subgraph.
rsub ∈ R and ST
sub ∈ R(L+1)·z represent
the attention
score and the feature vector of the graph sub respectively.
Wr ∈ R(L+1)z×(L+1)z is the matrix of weights to be learned.
SSP G denotes the feature vector of the gSP G. Then,
the
attention weights of the subgraphs are obtained by the softmax
function. Finally, the subgraph feature vectors are lineraly
combined through a weighted sum which is calculated as
follows:

(5)

βsub =

SAS =

(cid:80)
(cid:88)

exp(rsub)
sub exp(rsub)
βsub · Ssub

(6)

Where βsub is the attention weight corresponding to the

graph sub, SAS is the feature vector of all subgraphs.

sub

E. The Classiﬁer Network

At last, we concatenate the SSU B and the SSP G obtained
in Section IV-D, and then feed them directly into the classiﬁer
network for vulnerability detection. To achieve end-to-end
learning, the classiﬁer network in our approach is a single
fully connected layer with softmax outputs. The formula for
the classiﬁer network is (7).

p(y|gSP G) = sof tmax(WCN (SSP G||SAS) + bCN )

(7)

Where y ∈ {0, 1} is the class label, and 1 is a vulner-
able sample, 0 is a non-vulnerable sample. Both WCN ∈
R2(L+1)z×2 and bCN ∈ R2 are the learnable parameters
of the classiﬁer network. p(y|gSP G) is the output of the
classiﬁer network. Finally, we use the widely used cross-
entropy function [22] as a loss function to train the model.

L = −

(cid:88)

(cid:88)

˜p(y|gSP G)log(p(y|gSP G))

gSP G∈T rain

y∈{0,1}

(8)

Where T rain is the training datasets, ˜p(y|gSP G) is the
ground truth, i.e., ˜p(y|gSP G) = 1 if gSP G contains vulner-
abilities and ˜p(y|gSP G) = 0 otherwise.

V. EVALUATION

A. Evaluation Setup

Research Questions: Our evaluation is designed to answer

the following research questions.

RQ1: How effective is VulSPG when compared with state-

of-the-art vulnerability detection methods at slice level?

RQ2: How effective is VulSPG when compared with state-

of-the-art vulnerability detection methods at function level?

RQ3: How effective is SPG in vulnerability detection tasks
when compared with other graph-based code representations?

RQ4: Is our triple attention mechanism beneﬁcial to vulner-

ability detection?

Vulnerability dataset: We conduct comparative experi-
ments on two datasets at the slice level and the function level
to evaluate the beneﬁts of VulSPG. The ﬁrst dataset is provided
by Li et al. [6] and collected from the National Vulnerability
Database (NVD) [23] and the Software Assurance Reference
Dataset (SARD) [24]. There are 15,591 programs in this
dataset, of which 14,000 are from SARD and contain 13,906
vulnerability programs, and the remaining 1,591 programs
from NVD with 874 vulnerability programs. Most of the
programs in this dataset are synthetic, which is not suitable
for evaluating the performance of the model
in practical
applications. In addition,
this dataset contains interference
information (e.g., keyword ”Good” and ”Bad”, etc.), so we
peformed a normalization on source code in this dataset and
used the same normalization method as in [6] for a fair
comparison. The second dataset provided by Zhou et al. [8]
contains real-world programs extracted from two C/C++ open-
source projects(i.e. FFmpeg and QEMU), including 17,549
programs from QEMU, of which 7,479 are vulnerable, and
9,769 programs from FFmpeg, 4,981 of which are vulnerable.
The number of SPGs extracted from these two projects is
shown in Table I.

By introducing two new types of SyVCs (i.e. FP-kind and
FR-kind), the vulnerability coverage of SPGs on two datasets
increased by 3.1% and 10.0%, respectively.

labeling SPG: For SARD programs in the ﬁrst dataset, if
the statement node contains at least one vulnerability in the
generated SPG, it is labeled as 1, otherwise it is 0. Unlike
the SARD programs, the programs from NVD, FFmpeg and
QEMU have no explicit vulnerable lines of code. Therefore,
we can only generate labels for SPGs through the diff ﬁles,
which are divided into three steps. First, for all SPGs generated
by non-vulnerable programs, we label them as 0. Second, for
deleted lines in the diff ﬁle, we treat them as vulnerability
codes. That is, if there is a corresponding deleted line in the
statement nodes of SPG, the SPG will be labeled as 1. Third,
for programs that have no deleted lines in the diff ﬁles but are
vulnerable, we treat its overall structure as vulnerable, that is,
all SPGs generated by these programs are labeled as 1. Finally,
we manually review SPGs labeled as vulnerable by security
experts to ensure proper labeling.

Baseline methods: We select

slice-based approaches

TABLE I
THE NUMBER OF SPGS, VULNERABLE SPGS, NON-VULNERABLE SPGS
FROM THE PROGRAMS OF FFMPEG AND QEMU

#SPGs

SPGs of FFmpeg
#Vul.-
SPGs
8,388
2,874
18,914
6,471
32,238
13,120
13,387
5,866
30,636
12,311
24,510
8,154
128,073 48,796

#Non-
vul.SPGs
5,514
12,443
19,118
7,521
18,325
16,356
79,277

Kind of
SyVCs

FC-kind
AU-kind
PU-kind
AE-kind
FP-kind
FR-kind
Total

7

#SPGs

SPGs of Qemu
#Vul.-
SPGs
1,2258
3,253
7,861
1,623
44,705
12,897
5,677
1,761
39,763
10,492
26,195
5,830
136,459 35,856

#Non-
vul.SPGs
9,005
6,238
31,808
3,916
29,271
20,365
100,603

(VulDeePecker [25] and SySeVR [6]) and graph-based ap-
proaches (Devign [8] and FUNDED [13]) as comparisons to
evaluate the effectiveness of the proposed methods. VulDeeP-
ecker extracts code segments called code gadgets to represent
the programs and then uses BiLSTM to learn the vulnerability
patterns. SySeVR generates the code segments named SeVCs
by extracting four types of SyVCs and then uses BiGRU to
learn the vulnerability patterns. Devign learns vulnerability
patterns from the code composite graphs using GGNN with
the CONV module for vulnerability detection. FUNDED is
similar to Devign, but the proposed representation of the codes
is more complex and contains more syntactic and structural
information and the improved GGNN is veriﬁed to be more
suitable for learning multiple relationships of complex graphs.
Evaluation Conﬁguration: We implement the proposed
GNN-based model with the triple attention mechanism using
Pytorch v1.6 [26] and DGL [27]. Our experiments were run on
a machine with an Intel Core 2.6 GHz CPU and an NVIDIA
2080Ti GPU. Taking into account the computational efﬁciency
of VulSPG and the results of parameter adjustment during
the experiments, we make the following parameter settings.
The dimensionality of initial node vector is 64. In the graph
encoding phase, we set the dimensionality of hidden states as
64, and the number of hidden state layers as 2. Therefore,
the dimensionality of ﬁnal vector of a SPG is 384. We train
our model using the Adam optimizer with a learning rate of
0.001 and 200-epoch patience for early stopping. All baseline
approaches are conﬁgured with the same settings as reported
in their original papers [25] [6] [8] [13].

Evaluation Metrics: We use six widely used metrics to
evaluate the performance of VulSPG and other baseline ap-
proaches. Accuracy (A). The proportion of all
test cases
that are classiﬁed correctly. Precision (P). The proportion of
correctly predicted vulnerability samples to those predicted
to be vulnerable. Recall (R). The proportion of correctly
predicted vulnerability samples to all vulnerable samples.
False-positive rate (FPR). The proportion of false-positive
samples among all non-vulnerable samples. False-negative
rate (FNR). The proportion of false-negative samples among
all vulnerable samples. F1-measure (F1). F1 assesses the
overall effect by considering precision and recall.

B. Evaluation Results

Experiments for answering RQ1: To investigate the an-
swer to Q1, we conducted vulnerability detection experiments
on the ﬁrst dataset at the slice level. For comparison, we
chose three static vulnerability detection tools: checkmark
[28], Flawﬁnder [29], and RATS [30] and two slice-based
methods: VulDeePecker [25] and SySeVR [6]. To reduce the
cost and increase the credibility of the experiment, we use the
experimental results from the original paper [6]. Following
the experimental conﬁgurations in [6], we randomly select
80% of the programs in the ﬁrst dataset as the training set
and the rest 20% as the testing set. Speciﬁcally, we extracted
639,703 SPGs corresponding to the six kinds of SyVCs from

TABLE II
COMPARING OUR APPROACH WITH STATIC VULNERABILITY DETECTION
TOOLS AND STATE-OF-THE-ART SLICE-BASED METHODS AT THE SLICE
LEVEL (METRICS UNIT:%)

Method
Flawﬁnder
RATS
Checkmarx
VulDeePecker
SySeVR-BGRU
Our approach

FPR
21.6
21.5
20.8
2.5
1.4
2

FNR
70.4
85.3
56.8
41.8
5.6
5.3

A
69.8
67.2
72.9
92.2
98.0
97.1

P
22.8
12.8
30.9
78
92.6
93.9

R
29.6
14.7
43.4
58.2
94.4
94.7

F1
25.7
13.7
36.1
66.6
90.5
94.3

12,473 programs to train the VulSPG model, and 158,084
SPGs extracted from 3,118 programs to test the model.

The experimental results are summarized in Table II. First,
all slice-based methods perform better than the static vulner-
ability detection tools. Second, our approach outperforms the
other slice-based methods. VulSPG is 4.9% more accurate and
the F1-measure is 27.7% higher than VulDeePecker. Compared
to SySeVR, VulSPG is still superior in pecision, recall and F1-
measure, although the accuracy is slightly lower. In summary,
VulSPG is more effective than static vulnerability detection
tools and state-of-the-art slice-based approaches on slice-
level vulnerability detection tasks.

Note that for RQ2, RQ3, and RQ4, we focus on performing
experiments on the second dataset. The main reasons are as
follows. First, the second dataset consists of vulnerable codes
from real-world projects, while most of the samples in the
ﬁrst dataset are synthetic codes. Second, the second dataset,
generated on function-level, is more appropriate for comparing
our approach with the state-of-the-art graph-based methods.

Experiments for answering RQ2: This experiment aim to
demonstrate the effectiveness of the VulSPG at the function-
level granularity. Note that SySeVR (4-type) denotes the
baseline method based on four types of SyVCs (FC-kind, AU-
kind, PU-kind, AE-kind) proposed in their original paper, and
SySeVR (6-type) indicates the addition of our proposed two
SyVCs (FR-kind and FP-kind). Referring to the experimental
setup in [8], we randomly divide the samples into two groups
at a ratio of 75%:25%. Unlike other graph-based program
representations, SPGs are generated by using program slicing
technique according to a series of criterions (i.e., SyVCs)
extracted from the program. Therefore, the number of SPGs
generated in the dataset
is much larger than the number
of programs. To make a fair comparison with graph-based
methods Devign and FUNDED, We use the following methods
to detect program vulnerabilities. For each program in the
testing dataset, a program is predicted to be vulnerable if at
least one of its SPGs is predicted to be vulnerable. A program
is predicted to be non-vulnerable if all its SPGs are predicted
to be non-vulnerable. Slice-based methods VulDeePecker and
SySeVR also use the above approach for vulnerability detec-
tion. The experimental results are presented in Table III.

The experimental results indicate that our proposed VulSPG
outperforms other state-of-the-art methods on vulnerability
detection task at the function-level granularity. In the slice-
based approaches, SySeVR performs better than VulDeeP-
ecker. The primary reason is that VulDeePecker only de-

8

TABLE III
COMPARISONS BETWEEN OUR METHOD AND OTHER METHODS ON THE SECOND DATASET AT THE FUNCTION LEVEL

Project

FFmpeg

QEMU

Method
VulDeePecker
SySeVR(4-type)
SySeVR(6-type)
Devign
FUNDED
Our method
VulDeePecker
SySeVR(4-type)
SySeVR(6-type)
Devign
FUNDED
Our method

TP
156
655
743
781
864
947
145
636
770
715
744
1,010

TN
193
650
750
512
397
551
340
1,534
2,030
1,684
1,693
1,749

FP
89
396
415
653
768
614
73
362
350
696
687
631

FN
163
399
409
371
288
205
296
850
890
945
916
650

FPR(%)
31.6
37.9
35.6
56.1
65.9
52.7
17.7
19.0
14.7
29.2
24.7
26.5

FNR(%)
51.1
37.8
35.5
32.2
25.0
17.8
67.1
57.2
53.6
56.9
55.2
39.2

A(%)
58.1
62.1
64.4
55.8
54.4
64.7
56.8
64.2
69.3
59.4
62.8
68.3

P(%)
63.7
62.3
64.2
54.5
52.9
60.7
66.5
63.7
68.8
50.7
55.9
61.6

R(%)
48.9
62.2
64.5
67.8
75.0
82.2
32.9
42.8
46.4
43.1
44.8
60.8

F1(%)
55.3
62.2
64.3
60.4
62.1
69.8
44.0
51.2
55.4
46.6
49.7
61.2

tects vulnerabilities related to insecure library functions, and
thus cannot cover vulnerable programs in the testing dataset
that do not contain insecure functions when generating code
segments. Similarily, SySeVR (6-type) covers more types of
vulnerabilities than SySeVR (4-type) and, thus, has better
performance under the same testing dataset. In the graph-
based approaches, FUNDED slightly outperforms the Devign
in some of the metrics. Although both of them use GGNNs,
FUNDED improves upon GGNN to make it more suitable
for modeling multiple code relationships extracted from the
source code. However, unexpectedly, the graph-based methods
(i.e., Devign and FUNDED) perform worse than the slice-
based methods (e.g., SySeVR (4-type)). The reason is in two
folds: (1) As we detailed in Section II-A, the graph-based
representations of the code used by Devign and FUNDED
contain a lot of nodes that are not relevant to any vulnerability,
which greatly hinders the GGNN to learn effective vulnerable
features. (2) For the FUNDED and Devign methods, the token
embedding within a statement is simply averaged or fed into
the linear layer to obtain initial node representation, which
fails to account for the dependencies between tokens in the
statement nodes. In summary, VulSPG is more effective than
the state-of-the-art slice-based and graph-based methods on
the function-level vulnerability detection task.

Experiments for answering RQ3: In this experiment,
AST, CFG, PDG, and CPG, are selected as the baselines of
program representation. R-GCN and GGNN are selected as
the baselines of vulnerability detection model. In the model
readout phase, we uniformly use the multilayer perceptron
(MLP) for graph-level classiﬁcation to mitigate the impact
of the model on vulnerability detection performance. The
detection results are presented in Table IV.

As shown in Table IV, the experimental results for CFG
and PDG are slightly better than those for AST. In fact,
although AST contains more syntax information than CFG
and PDG, it also contains more nodes and edges that are
not relevant to vulnerabilities. Simlar to AST, although CPG
contains rich information to allow detailed representation of
various types of vulnerability patterns, the large amount of
redundant information unrelated to vulnerabilities it contains
also hinders vulnerability detection, which eventually leads
to its failure to obtain better performance of vulnerability
detection. The proposed SPG combines slicing technique

and graph-based representation to remove a large amount of
redundant information while preserving as much structural
and semantic information about the vulnerability as possible.
Therefore, it achieves the best results in the experiment. The
GGNN model does not perform as well as expected, and we
found that the GGNN model is prone to over-smoothness in the
learning process. GGNN cannot learn the property information
of different
types of directed edges in SPG like R-GCN,
which also explains the performance drop. In summary, our
proposed SPG are more effective than other graph-based
code representations in vulnerability detection.

Experiments for answering RQ4: To demonstrate the
effectiveness of the triple attention mechanism in the Vul-
SPG, we use R-GCN but different readout methods to learn
vulnerability patterns in SPG. Speciﬁcally, We choose MLP
and Conv as baselines, where Conv is the readout method
of Devign that allows more effective feature extraction. Next,
we conduct ablation experiments targeting the triple attention
mechanism. We use the full triple attention mechanism as a
comparison, removing the token-level, the node-level, and the
subgraph-level attention mechanism, respectively. The experi-
mental results are shown in Table V.

The experimental results show that the triple attention mech-
anism improves the graph classiﬁcation performance compared
with the MLP and Conv models. Indeed, focusing on the
structural and semantic features of the code through the at-
tention mechanism is more suitable for vulnerability detection
than collecting all node information equally. In the ablation
experiment, we ﬁnd that removing subgraph-level attention
mechanism has a greater impact on performance, suggesting

TABLE IV
VULNERABILITY DETECTION RESULTS OF DIFFERENT GRAPH-BASED
PROGRAM REPRESENTATIONS (METRICS UNIT:%)

project

FFmpeg

QEMU

represe-
tations
AST
CFG
PDG
CPG
SPG
AST
CFG
PDG
CPG
SPG

RGCN

A
57.6
60.4
60.0
54.5
62.1
57.2
59.3
58.8
57.8
64.5

F1
59.6
59.9
61.2
60.9
64.7
49.3
53.1
54.0
51.6
58.6

GGNN
A
55.8
56.0
57.2
53.5
58.9
57.9
58.3
58.2
57.3
62.9

F1
57.3
59.4
60.0
58.7
61.5
42.8
46.1
47.8
45.7
57.6

9

that subgraph-level attention mechanism is most important
in the triple attention mechanism. The token-level attention
mechanism is used in the process of SPG node embedding,
and from the experimental results, it plays an equally important
role. This indicates that the token-level attention mechanism
extracts dependency information between tokens within a
statement, thus improving the performance of vulnerability
detection. To our surprise, the node-level attention mechanism,
while playing a role, is not as important as we expected. The
above experimental results demonstrates to some extent that
accurate identiﬁcation of vulnerability patterns requires the
ability to consider the combination of semantic, structural, and
contextual information about the vulnerability code.

In summary,

the triple attention mechanism achieves
higher vulnerability detection capability and where token-
level, node-level, subgraph-level attention mechanisms are
all effective.

C. Discussion and Limitation

Inter-procedural analysis In our experiments, the Devign’s
dataset is not provided with a complete program and contains
only function-level code, thus we did not perform the inter-
procedural analysis on this dataset. We ﬁnd that despite the
absence of inter-procedural analysis, VulSPG still performs
well on Devign’s dataset. In addition, using the original same
dataset also allows us to make a fairer comparison with De-
vign. Our future work will consist in verifying the performance
of the inter-procedural analysis in real-world projects.

Bias in the experimental results. In the experiments of
RQ2, the results of our implementation of Devign differ from
those reported in the original paper [8]. This is because in the
experiments we used all the programs in the second dataset
and did not ﬁlter out programs with too many tokens, as in
the original paper. Using the FFmpeg project as an example,
Devign use 6,716 programs when performing the experiments,
while we use all 9,769 programs in the experiments. This leads
to more difﬁcult identiﬁcation of vulnerabilities and worse
experimental results. In addition to using different datasets, it
is difﬁcult to reproduce the code and optimize the experimental
parameters in the same way as the original paper because the
original authors did not open the implemented source code.

Limitations. First, the VulSPG currently focuses on detect-
ing vulnerabilities in the source code of C/C++ programs. We
plan to extend this method to other languages in future work.
Second, although we have added two kinds of SyVCs, there
are still some vulnerability codes that are not covered by our

TABLE V
ABLATION EXPERIMENTS TARGETING THE TRIPLE ATTENTION
MECHANISM (METRICS UNIT:%)

Model
RGCN+MLP
RGCN+Conv
RGCN+token+subgraph
RGCN+token+node
RGCN+node+subgraph
RGCN+triple attention

FFmpeg
A
F1
64.7
62.1
66.5
60.2
67.1
63.4
65.7
63.4
66.1
61.7
69.8
64.7

QEMU
A
64.5
66.3
67.8
67.2
67.5
68.3

F1
58.6
58.5
59.1
57.3
56.8
61.2

generated SPGs. Third, we only consider the most commonly
used vulnerability detection method GGNN as the comparison
of graph coding. We will compare more types of GNN in our
future work.

VI. RELATED WORK
Software vulnerability detection relies on program analysis
techniques, which include static analysis [31], dynamic anal-
ysis [32], and hybrid analysis [33]. Our work builds upon the
foundations of static program analysis techniques.

Classic methods: Early static vulnerability detection meth-
ods are based on rules developed manually by security experts
[34] [3] [4]. However, these methods rely on the knowledge
and experience of experts and it is difﬁcult to develop quality
rules. Symbolic execution [35] [36] mitigates this by analyzing
the control ﬂow of the program, but also suffers from problems
such as path explosion and difﬁculty in resolving constraints.
Machine leaning based methods: Machine learning (ML)
based vulnerability detection methods offer alternative solu-
tions for automated and more efﬁcient vulnerability detec-
tion. Using manually deﬁned features extracted from source
code, such as function/library calls [37], software complexity
metrics [38] [39] [40] and developer activity [41], ML-based
approaches learn potential or abstract vulnerability patterns
by machine learning algorithms. The performance of these
machine learning methods strongly depends on the quality of
the features extracted from the data (i.e. the discriminative and
expressive power of the features) [42].

Deep Learning based methods: DL-based detection meth-
ods are able to extract features of vulnerabilities and automati-
cally learn patterns of vulnerable code, which can signiﬁcantly
reduce time and labor costs as they do not require human-
deﬁned features [1] [43] [44]. We classify the representative
DL-based vulnerability detection methods into slice-based
methods (e.g., VulDeePecker [25] and SySeVR [6] ) and
graph-based methods (e.g., Devign [8] and FUNDED [13]).
Slice-based methods retain only information that may be rel-
evant to the vulnerability, but still treat the code as sequential
tokens and often ignore structure of the code. The graph-based
methods take into account the structure and logic of the code.
However, these code representations also contain too much
redundant information unrelated to the vulnerabilities, which
interferes with the GNN learning the vulnerability patterns
from the vulnerable code.

VII. CONCLUSION
We propose VulSPG, which contains a code representation
called SPG for vulnerability detection tasks, and a vulnera-
bility detection method using R-GCN with a triple attention
mechanism. We evaluate VulSPG on a large-scale slice-level
vulnerability dataset and a function-level real-world dataset,
respectively. The experimental results demonstrate that Vul-
SPG is superior to state-of-the-art approaches.

ACKNOWLEDGMENT
This work was supported by the National Natural Science

Foundation of China (Grant Nos.61672191)

10

REFERENCES

[22] C. M. Bishop, Pattern recognition and machine learning.

springer,

2006.

[23] “Nvd: National vulnerability database,” https://nvd.nist.gov/, 2021.
[24] “Sard: A software assurance reference dataset,” https://samate.nist.gov/

SARD/, 2021.

[25] Z. Li, D. Zou, S. Xu, X. Ou, H. Jin, S. Wang, Z. Deng, and Y. Zhong,
“Vuldeepecker: A deep learning-based system for vulnerability detec-
tion,” arXiv preprint arXiv:1801.01681, 2018.

[26] L. Maxim, G. Hua, C. Geeta, and D. Gisle, “Pytorch proﬁler,” https:

//pytorch.org/, 2021.

[27] M. Wang, D. Zheng, G. Gan, M. Li, Z. Ye et al., “Dgl: Deep graph

library,” https://www.dgl.ai/, 2021.

[28] “checkmarx,” https://www.checkmarx.com/, 2021.
[29] “ﬂawﬁnder,” http://www.dwheeler.com/ﬂawﬁnder/, 2021.
[30] “Rats: Rough audit tool for security,” https://code.google.com/archive/

p/rough-auditing-tool-for-security/, 2021.

[31] M. Pistoia, S. Chandra, S. J. Fink, and E. Yahav, “A survey of static
analysis methods for identifying security vulnerabilities in software
systems,” IBM Systems Journal, vol. 46, no. 2, pp. 265–288, 2007.
[32] P. Godefroid, M. Y. Levin, D. A. Molnar et al., “Automated whitebox

fuzz testing.” in NDSS, vol. 8, 2008, pp. 151–166.

[33] L. K. Shar, L. C. Briand, and H. B. K. Tan, “Web application vulnera-
bility prediction using hybrid program analysis and machine learning,”
IEEE Transactions on dependable and secure computing, vol. 12, no. 6,
pp. 688–707, 2014.

[34] R. Mahmood and Q. H. Mahmoud, “Evaluation of static analysis tools
for ﬁnding vulnerabilities in java and c/c++ source code,” arXiv preprint
arXiv:1805.09040, 2018.

[35] C. Cadar, D. Dunbar, D. R. Engler et al., “Klee: unassisted and automatic
generation of high-coverage tests for complex systems programs.” in
OSDI, vol. 8, 2008, pp. 209–224.

[36] C. Cadar and K. Sen, “Symbolic execution for software testing: three
decades later,” Communications of the ACM, vol. 56, no. 2, pp. 82–90,
2013.

[37] S. Neuhaus, T. Zimmermann, C. Holler, and A. Zeller, “Predicting
vulnerable software components,” in Proceedings of
the 14th ACM
conference on Computer and communications security, 2007, pp. 529–
540.

[38] I. Chowdhury and M. Zulkernine, “Using complexity, coupling, and
cohesion metrics as early indicators of vulnerabilities,” Journal of
Systems Architecture, vol. 57, no. 3, pp. 294–313, 2011.

[39] Y. Shin and L. Williams, “An empirical model

to predict security
vulnerabilities using code complexity metrics,” in Proceedings of the
Second ACM-IEEE international symposium on Empirical software
engineering and measurement, 2008, pp. 315–317.

[40] T. Zimmermann, N. Nagappan, and L. Williams, “Searching for a needle
in a haystack: Predicting security vulnerabilities for windows vista,” in
2010 Third International Conference on Software Testing, Veriﬁcation
and Validation.

IEEE, 2010, pp. 421–428.

[41] Y. Shin, A. Meneely, L. Williams, and J. A. Osborne, “Evaluating
complexity, code churn, and developer activity metrics as indicators of
software vulnerabilities,” IEEE transactions on software engineering,
vol. 37, no. 6, pp. 772–787, 2010.

[42] S. M. Ghaffarian and H. R. Shahriari, “Software vulnerability analysis
and discovery using machine-learning and data-mining techniques: A
survey,” ACM Computing Surveys (CSUR), vol. 50, no. 4, pp. 1–36,
2017.

[43] Z. Shen and S. Chen, “A survey of automatic software vulnerability
detection, program repair, and defect prediction techniques,” Security
and Communication Networks, vol. 2020, 2020.

[44] S. K. Singh and A. Chaturvedi, “Applying deep learning for discovery
and analysis of software vulnerabilities: A brief survey,” Soft Computing:
Theories and Applications, pp. 649–658, 2020.

[1] G. Lin, S. Wen, Q.-L. Han, J. Zhang, and Y. Xiang, “Software vulner-
ability detection using deep neural networks: a survey,” Proceedings of
the IEEE, vol. 108, no. 10, pp. 1825–1848, 2020.

[2] D. Votipka, R. Stevens, E. Redmiles, J. Hu, and M. Mazurek, “Hackers
vs. testers: A comparison of software vulnerability discovery processes,”
in 2018 IEEE Symposium on Security and Privacy (SP).
IEEE, 2018,
pp. 374–391.

[3] D. Engler, D. Y. Chen, S. Hallem, A. Chou, and B. Chelf, “Bugs as
deviant behavior: A general approach to inferring errors in systems
code,” ACM SIGOPS Operating Systems Review, vol. 35, no. 5, pp.
57–72, 2001.

[4] B. Chess and M. Gerschefske, “Rough Auditing Tool for Security,”
https://code.google.com/archive/p/rough-auditing-tool-for-security/,
2019, Mar 18.

[5] Y. Zhou and A. Sharma, “Automated identiﬁcation of security issues
from commit messages and bug reports,” in Proceedings of the 2017
11th joint meeting on foundations of software engineering, 2017, pp.
914–919.

[6] Z. Li, D. Zou, S. Xu, H. Jin, Y. Zhu, and Z. Chen, “Sysevr: A
framework for using deep learning to detect software vulnerabilities,”
IEEE Transactions on Dependable and Secure Computing, 2021.
[7] P. Kilpatrick, D. Crookes, and M. Owens, “Program slicing: A com-
puter aided programming technique,” in Second IEE/BCS Conference:
Software Engineering, 1988 Software Engineering 88.
IET, 1988, pp.
60–64.

[8] Y. Zhou, S. Liu, J. Siow, X. Du, and Y. Liu, “Devign: Effective vulner-
ability identiﬁcation by learning comprehensive program semantics via
graph neural networks,” arXiv preprint arXiv:1909.03496, 2019.
[9] F. Yamaguchi, N. Golde, D. Arp, and K. Rieck, “Modeling and discover-
ing vulnerabilities with code property graphs,” in 2014 IEEE Symposium
on Security and Privacy.

IEEE, 2014, pp. 590–604.

[10] R. E. Noonan, “An algorithm for generating abstract syntax trees,”

Computer Languages, vol. 10, no. 3-4, pp. 225–236, 1985.

[11] J. Ferrante, K. J. Ottenstein, and J. D. Warren, “The program dependence
graph and its use in optimization,” ACM Transactions on Programming
Languages and Systems (TOPLAS), vol. 9, no. 3, pp. 319–349, 1987.

[12] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. Van Den Berg, I. Titov,
and M. Welling, “Modeling relational data with graph convolutional
networks,” in European semantic web conference. Springer, 2018, pp.
593–607.

[13] H. Wang, G. Ye, Z. Tang, S. H. Tan, S. Huang, D. Fang, Y. Feng,
L. Bian, and Z. Wang, “Combining graph-based learning with automated
data collection for code vulnerability detection,” IEEE Transactions on
Information Forensics and Security, 2020.

[14] Y. J. Lee, S.-H. Choi, C. Kim, S.-H. Lim, and K.-W. Park, “Learning
binary code with deep learning to detect software weakness,” in KSII
The 9th International Conference on Internet (ICONI) 2017 Symposium,
2017.

[15] R. Russell, L. Kim, L. Hamilton, T. Lazovich, J. Harer, O. Ozdemir,
P. Ellingwood, and M. McConley, “Automated vulnerability detection
in source code using deep representation learning,” in 2018 17th
IEEE international conference on machine learning and applications
(ICMLA).

IEEE, 2018, pp. 757–762.

[16] M.-j. Choi, S. Jeong, H. Oh, and J. Choo, “End-to-end prediction of
buffer overruns from raw source code via neural memory networks,”
arXiv preprint arXiv:1703.02458, 2017.

[17] D. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre, R. G´omez-
Bombarelli, T. Hirzel, A. Aspuru-Guzik, and R. P. Adams, “Convo-
lutional networks on graphs for learning molecular ﬁngerprints,” arXiv
preprint arXiv:1509.09292, 2015.

[18] W. L. Hamilton, R. Ying, and J. Leskovec, “Inductive representation
learning on large graphs,” arXiv preprint arXiv:1706.02216, 2017.
[19] Y. Li, D. Tarlow, M. Brockschmidt, and R. S. Zemel, “Gated
graph sequence neural networks,” in 4th International Conference on
Learning Representations, ICLR 2016, Conference Track Proceedings,
2016. [Online]. Available: http://arxiv.org/abs/1511.05493

[20] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
L. Kaiser, and I. Polosukhin, “Attention is all you need,” arXiv preprint
arXiv:1706.03762, 2017.

[21] J. Lee, I. Lee, and J. Kang, “Self-attention graph pooling,” in Interna-
tional Conference on Machine Learning. PMLR, 2019, pp. 3734–3743.

11

