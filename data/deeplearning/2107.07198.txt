Graph-Embedded Multi-Agent Learning for Smart
Reconﬁgurable THz MIMO-NOMA Networks

Xiaoxia Xu, Qimei Chen, Member, IEEE, Xidong Mu, Graduate Student Member, IEEE,
Yuanwei Liu, Senior Member, IEEE, and Hao Jiang, Member, IEEE

1

1
2
0
2

t
c
O
5
2

]
P
S
.
s
s
e
e
[

3
v
8
9
1
7
0
.
7
0
1
2
:
v
i
X
r
a

Abstract—With the accelerated development of

immersive
applications and the explosive increment of internet-of-things
(IoT) terminals, 6G would introduce terahertz (THz) massive
multiple-input multiple-output non-orthogonal multiple access
(MIMO-NOMA) technologies to meet the ultra-high-speed data
rate and massive connectivity requirements. Nevertheless, the
unreliability of THz transmissions and the extreme heterogeneity
of device requirements pose critical challenges for practical
applications. To address these challenges, we propose a novel
smart reconﬁgurable THz MIMO-NOMA framework, which can
realize customizable and intelligent communications by ﬂexibly
and coordinately reconﬁguring hybrid beams through the cooper-
ation between access points (APs) and reconﬁgurable intelligent
surfaces (RISs). The optimization problem is formulated as
a decentralized partially-observable Markov decision process
(Dec-POMDP) to maximize the network energy efﬁciency, while
guaranteeing the diversiﬁed users’ performance, via a joint
RIS element selection, coordinated discrete phase-shift control,
and power allocation strategy. To solve the above non-convex,
strongly coupled, and highly complex mixed integer nonlinear
programming (MINLP) problem, we propose a novel multi-
agent deep reinforcement learning (MADRL) algorithm, namely
graph-embedded value-decomposition actor-critic (GE-VDAC), that
embeds the interaction information of agents, and learns a locally
optimal solution through a distributed policy. Numerical results
demonstrate that the proposed algorithm achieves highly cus-
tomized communications and outperforms traditional MADRL
algorithms.

Index Terms—Reconﬁgurable intelligent surface, THz, MIMO-

NOMA, MADRL, distributed optimization.

I. INTRODUCTION

T HE upcoming 6G era confronts a variety of emerg-

ing applications, involving immersive applications such
as ultra-high deﬁnition (UHD) video and virtual
real-
ity/augmented reality (VR/AR), as well as Internet of Things
(IoT) applications like wearable devices and smart homes
[1]. To meet the unprecedented challenges raised by ultra
wide-band communications and massive IoT connectivity,
terahertz (THz) massive multiple-input-multiple-output non-
orthogonal multiple access (MIMO-NOMA) has become an
essential technology for 6G, which can provide 10 Gbps-
order ultra-fast transmission speed and support millions of
connections. Generally, THz MIMO-NOMA systems utilize

X. Xu, Q. Chen, and H. Jiang are with the School of Electronic Information,
Wuhan University, Wuhan 430072, China (e-mail: {xiaoxiaxu, chenqimei,
jh}@whu.edu.cn).

X. Mu is with School of Artiﬁcial Intelligence, Beijing University of Posts

and Telecommunications, Beijing, China. (email: muxidong@bupt.edu.cn).

Y. Liu is with the School of Electronic Engineering and Computer
Science, Queen Mary University of London, London E1 4NS, UK.
(email:yuanwei.liu@qmul.ac.uk).

the large-scale antenna array with hybrid beamforming struc-
ture [2], which can compensate the severe fading over high-
frequency THz bands, and reduce the hardware complexity
and power consumption. In addition, assisted with the MIMO-
NOMA technology [3], [4], highly spatial-correlated users
can be grouped into one cluster and supported by a single
radio frequency (RF) chain, which can signiﬁcantly improve
spectral efﬁciency and connective density [5]. To employ the
massive MIMO-NOMA technology for THz communications,
the authors in [6] proposed an energy-efﬁcient user clustering,
hybrid precoding, and power optimization scheme, where the
blockage probability and unreliability of line-of-sight (LoS)
links have been ignored. Nevertheless, due to the high obscu-
ration susceptibility, the application of THz MIMO-NOMA
network may suffer from serious transmission unreliability and
intermittency resulting from either wall blockage or human-
body blockage effect [7], which may signiﬁcantly degrade the
experiences of unreliability-sensitive 6G immersive applica-
tions.

Fortunately, the newly-emerged reconﬁgurable intelligent
surface (RIS) technology is regarded as a promising way to
overcome the shortcomings in THz MIMO-NOMA communi-
cations [8]–[10]. Speciﬁcally, RISs can dynamically transform
and reshape spatial beams, and thus construct virtual LoS links
between transmitters and receivers to avoid blockage [11].
Meanwhile, a smart radio environment can also be created
to achieve signiﬁcant spectrum/energy efﬁciency improvement
and ﬂexible scheduling [12], [13]. Given the aforementioned
beneﬁts, increasingly research efforts have been devoted to
the RIS-aided MIMO-NOMA networks operating in low fre-
quencies. In [14], the authors proposed a joint passive and
active beamforming method for RIS-aided multiple input sin-
gle output (MISO)-NOMA network, which obtained a locally
optimal solution based on a second-order cone programming
(SOCP)-alternating direction method of multipliers (ADMM)
algorithm. The authors in [15] further studied the joint pas-
sive and active beamforming in RIS-aided MISO-NOMA
networks under both ideal and non-ideal RIS assumptions.
Furthermore, the authors in [16] proposed joint deployment
and beamforming frameworks for RIS-aided MIMO-NOMA
networks based on deep reinforcement learning. However, the
existing methods are inapplicable to 6G THz MIMO-NOMA
communications: 1) The existing MIMO-NOMA mechanisms
are incapable to deal with the extremely heterogenous quality-
of-service (QoS) requirements of 6G users. 2) Compared with
low-frequency MIMO communications, THz MIMO com-
munications face a more prominent transmission unreliabil-

 
 
 
 
 
 
ity problem. 3) Since THz MIMO-NOMA networks usually
have high-dimensional spatial channel information, existing
centralized and iterative optimization algorithms usually lead
to unacceptable high complexity and information exchange
overhead to schedule the complicated THz MIMO-NOMA
scenarios.

Therefore, we aim to propose a novel smart reconﬁgurable
MIMO-NOMA THz framework that can realize customizable
and intelligent indoor communications with high energy efﬁ-
ciency and low complexity based on a machine learning mech-
anism in this work. Here, we consider two types of heteroge-
neous users, namely IoT users and super-fast-experience (SE)
users. Speciﬁcally, SE users, like VR/AR and UHD video, re-
quire ultra-high-speed and reliable immersive communication
experiences, while the densely connected IoT users, like smart
cleaners and smart watches, tolerate sporadic and unreliability-
tolerant trafﬁc transmission. Different from the conventional
systems, we introduce a low-complexity and decentralized
learning-based framework that can jointly design the user
clustering, NOMA decoding, and hybrid beam reconﬁguration
schemes in a cooperative setting with multiple APs and RISs:
1) By adaptively aligning users’ equivalent spatial channels
as well as customizing NOMA decoding orders based on the
QoS requirements, the intra-cluster interference suffered by SE
users can be completely eliminated. 2) We adjust the highly-
directional hybrid beams through the cooperation among APs
and RISs, which can ensure tailored spatial data channels and
mitigate both inter-cluster and inter-AP interference via active
hybrid beamforming and coordinated passive beamforming.
3) To overcome the non-ideal discrete phase-shift control,
we exploit a dynamic RIS element selection structure for the
hybrid beam reconﬁguration, which can ﬂexibly refrain unfa-
vorable and negative reﬂections via an element-wise ON/OFF
control to enhance energy efﬁciency. Overall, the proposed
framework can realize customizable hybrid spatial and power-
domain multiplexing, as well as improving the multi-domain
resource utilization.

Based on the above framework, we propose a long-term
joint RIS element selection, coordinated discrete phase-shift
control, and power allocation learning strategy. The objec-
tive function is formulated to maximize the system energy
efﬁciency as well as satisfying users’ data rate and reli-
ability, which is an NP-hard mixed-integer nonlinear pro-
gramming (MINLP) problem. To efﬁciently solve the non-
convex, strongly coupled, and highly complex MINLP prob-
lem online, we transfer it into a decentralized partially ob-
servable Markov decision process (Dec-POMDP). Thereafter,
we introduce a novel cooperative multi-agent reinforcement
learning (MADRL) method, namely graph-embedded value-
decomposition actor-critic (GE-VDAC), to efﬁciently coordi-
nate multi-AP and multi-RIS in a distributed manner. The
proposed GE-VDAC algorithm can not only improve gen-
learning, but also reduce
eralization ability of multi-agent
information exchange overhead.

The main contributions of this work can be summarized as

follows.

• We propose a novel smart reconﬁgurable THz MIMO-
NOMA framework, which can realize highly customiz-

2

able and intelligent communications to support ultra-wide
bands and ultra-dense connections. The hybrid spatial
beams are smartly and cooperatively reconﬁgured through
multi-AP and multi-RIS coordinations, where dynamic
RIS element selection, on-demand data enhancement,
ﬂexible interference suppression, and efﬁcient hybrid
spatial and power-domain multiplexing are allowed.
• The long-term joint RIS element selection, coordinated
discrete phase-shift control, and power allocation opti-
mization problem is formulated by a Dec-POMDP model.
Under customized user clustering, NOMA decoding, and
sub-connected hybrid beamforming schemes, the Dec-
POMDP model can maximize the expected system energy
efﬁciency while satisfy extremely heterogeneous data rate
and reliability requirements for different users.

• To efﬁciently solve the non-convex, strongly coupled, and
highly complex MINLP problem online, we propose a
novel distributed MADRL algorithm, namely GE-VDAC,
which learns the decomposed local policies by embed-
ding the agents’ interaction information into dimension-
reduced and permutation-invariant features. We show that
the proposed GE-VDAC can not only converge to a locally
optimal solution, but also achieve a better coordination
and generalization with low information exchange over-
head.

• We present numerical results to verify the effective-
ness of the proposed strategy. The proposed GE-VDAC
achieves higher system energy efﬁciency and faster learn-
ing speed than traditional MADRL algorithms. Moreover,
both reliable and ultra-high-speed communications can be
achieved by SE users despite the increment of connected
users.

The rest of this paper is organized as follows. Section II de-
scribes the smart reconﬁgurable THz MIMO-NOMA network.
Section III presents the formulated Dec-POMDP problem, and
Section VI proposes the GE-VDAC based distributed MADRL
algorithm. Numerical results are presented in Section V before
the conclusion in Section VI.

Notation: We denote the imaginary unit by j, and represent
vectors and matrices by lower and upper boldface symbols,
respectively. ∂F
∂x denotes the ﬁrst partial derivative of function
F with respect to x. E [·] represents the statistical expectation.
| · | and (cid:107) · (cid:107) denote the absolute value and the Euclidean norm,
respectively. Moreover, (cid:63) means the permutation operation.
The main notations used throughout this paper is summarized
in Table I.

II. SMART RECONFIGURABLE THZ MIMO-NOMA
FRAMEWORK

As shown in Fig. 1, we consider an indoor downlink massive
MIMO-NOMA THz network that serves densely distributed
SE users and IoT users under multiple pre-installed THz
APs and RISs. Denote the set of M APs and J RISs as
M = {1, 2, ..., M } and J = {1, 2, ..., J}, respectively. By
coordinating and cooperating with neighboring APs and RISs,
S of K m
each AP m serves a set Km
S SE users and a set
Km
U IoT users, which have utterly diversiﬁed QoS

U of K m

TABLE I
MAIN NOTATIONS

Deﬁnitions
number of antennas and RF chains
number of antennas in a subset
analog and digital beamformers at AP m
number of SE and IoT users associated to each AP
user number (set) served by RF chain n of AP m
phase-shift matrix of RIS j
ON/OFF state and phase shift of element l at RIS j

power allocation of user U m
nk and cluster n
equivalent channel from AP i to user U m
nk
direct channel from AP i to user U m
nk
channel from RIS j to user U m
nk
channel from AP i to RIS j
trafﬁc queue and virtual queue of user U m
nk
joint observation, state, and action vectors
vectorized node feature of the u-th type agent i ∈ Iu
vectorized feature of edge (i, i(cid:48))
embedded feature of edge (i, i(cid:48))
hidden and local embedded states of agent i ∈ Iu

n (t))

n (t)

n (t) (Km

Notations
NA, NR
Nsub
Vm, Wm
KS, KU
Km
Θj (t)
ωj
l (t), θj
l (t)
nk(t), P m
pm
him
nk (t)
(cid:101)him
nk (t)
f jm
nk (t)
Gij (t)
qm
nk(t), Y m
nk(t)
Ω(t), s(t), a(t)
ou
i (t)
dii(cid:48) (t)
eii(cid:48) (t)
i (t), (cid:101)zu
zu

i (t)

Fig. 1. The proposed smart reconﬁgurable THz massive MIMO-NOMA
network.

U = ... = KM

S = ... = KM

U = KU. Here, we denote Km = Km

requirements in terms of transmission data rate and reliability.
For simplicity, we assume K 1
S = KS and
K 1
U ∪ Km
S ,
K m = KU + KS, and K = K1 ∪ K2 ∪ ... ∪ KM . To reduce
hardware complexity and energy dissipation, we assume each
user equips with a single antenna and the APs apply the
sub-connected hybrid beamforming structure [17]. Moreover,
each AP is equipped with NA antennas and NR RF chains,
where each RF chain connects to a subset of Nsub antennas
via Nsub phase shifters with Nsub = NA/NR. Deﬁne the
analog and digital beamforming matrixes at each AP m as
Vm ∈ CNA×NR and Wm ∈ CNR×NR. Denote the phase-
shift matrix of each RIS j by Θj. Based on the MIMO-
NOMA technology, the highly spatial-correlated SE and IoT
users can be grouped into one cluster, which is served by a
reconﬁgured beam transmitted from an AP antenna subarray
that is connected with a RF chain. Deﬁne U m
nk as user k
in cluster n under AP m, and Km
n users
in cluster n under AP m. Furthermore, the whole system is
divided into T time slots, indexed by T = {1, 2, ..., T }.

n be the set of K m

In general, we aim to propose a learning-based mechanism
for the smart reconﬁgurable THz MIMO-NOMA network to

3

Fig. 2. Process of the proposed learning-based mechanism.

jointly coordinate both multiple APs and RISs, which has
the ﬂow chart as shown in Fig. 2. Decentralized scheduling
begins after channel estimation, which contains the process
of learning-based decentralized policies and low-complexity
schemes. In the learning-based decentralized policies, we can
determine the dynamic RIS element selection, discrete phase-
shift control, and power allocation with incomplete system
information. Based on the smartly reconﬁgured channels, each
AP can further obtain QoS-based user clustering, customized
NOMA decoding order, and sub-connected hybrid beamformer
using low-complexity schemes. Thereafter, data transmissions
can be performed.

Without loss of generality, we assume each RIS equips
with a low-cost RF chain that can estimate the CSI based
on the semi-passive RIS channel estimation methods [18].
Speciﬁcally, at the beginning of each time slot, APs would
send pilot signals to neighboring users to estimate the direct
channels. Meanwhile, RISs would turn off their reﬂecting
elements to sense the channels, where the indirect channels can
be estimated by processing the received signals. Both direct
and indirect channels can be estimated under compressed
sensing or deep learning methods, which are out of the scope
of this work. For the sake of expression, we ignore the time
slot index t from Section II-A to II-G.

A. RIS Element Selection and Discrete Phase-Shift Control

We suppose that each RIS j consists of L reﬂecting el-
ements, which is controlled by a software-deﬁned RIS con-
troller. Since the continuous phase control is hard to realize in
practice, a ﬁnite-resolution passive phase shifter is utilized for
each reﬂecting element. To save energy consumption as well as
overcoming the non-ideal reﬂecting effect due to the discrete
phase-shift control, we propose to leverage a dynamic RIS
element selection structure during transmissions1. By ﬂexibly
controlling the ON/OFF states and the phase shifts of passive
phase shifters, the dynamic selection structure can prevent
unfavorable reﬂections and achieve higher energy efﬁciency.
Based on the dynamic selection structure, the phase-shift

matrix Θj on RIS j can be given by

Θj = diag

(cid:16)

1ejθj
ωj

1 , ..., ωj

Lejθj

L

(cid:17)

,

(1)

1Note that dynamic RIS element selection requires a complex design for
the RIS array, which might be realized in the near future. In this work, we
assume the reﬂecting elements in RISs can be dynamically turned ON/OFF
by controlling the PIN diodes.

OFF-state RIS elementON-state RIS elementVR/AR userSmart cleanerSmart heaterSmart watchMobile phoneHumidifierVR/AR userTHz AP 1CameraidifUHD videoVR/ARRIS controllerTHz AP 2THRIS controller(cid:540)(cid:20)(cid:20)(cid:20)ClusterCluster(cid:540)(cid:20)(cid:20)(cid:20)ClusterClusterHuman blockageHuman blockageMobile phoneephephonbililhbilhpppphhhhooooonnnnneeeeeDynamic RIS element selection Power allocationDiscrete phase-shift controlLearning-based decentralized policiesQoS-based user clusteringCustomized NOMA decodingSub-connected hybrid BeamformingLow-complexity schemesSmartly recongfigured channelsTime slot t (channel coherence time)Channel estimationData transmission (with incomplete information) (based on reconfigured  channels)Decentralizedschedulingwhere ωj
given by

l denotes the ON/OFF state of the l-th RIS element,

(cid:40)

ωj

l =

1,
0, otherwise.

if reﬂecting element l at RIS j is turned ON,

(2)
The discrete phase shift of a selected element l at RIS j is
l ∈ {0, 1, ..., 2BR−1} and the RIS
determined by an integer βj
resolution bit BR, which can be written as

θj
l ∈ F =

(cid:110)

21−bπβj
l

(cid:12)
(cid:12)βj

(cid:111)
l ∈ {0, 1, ..., 2BR−1}

.

(3)

B. Channel Model

The equivalent channel vector from AP i ∈ M to user U m
nk
nk = [him1
] ∈
nk ∈ C1×Nsub is the equivalent channel from

via multiple RISs is deﬁned as him
C1×NA , where hims
subarray s at AP i to user U m

nk , ..., himNR

nk. Here, him

nk is given by

nk

nk = (cid:101)him
him
nk
(cid:124)(cid:123)(cid:122)(cid:125)
AP-user

+

J
(cid:88)

j=1

f jm
nk ΘjGij
,
(cid:125)
(cid:123)(cid:122)
(cid:124)
AP-RIS-user

(4)

nk ∈ C1×NA , f jm

where (cid:101)him
the direct spatial channels of AP i-user U m
and AP i-RIS j links, respectively.

nk ∈ C1×L, and Gij ∈ CL×NA denote
nk, RIS j-user U m
nk,

We assume LoS paths always exist between the APs and
its neighboring RISs. However, the LoS paths for the AP-user
and RIS-user links may be blocked. Therefore, channel (cid:101)him
nk
can be modeled by

nk = 1im,LoS
(cid:101)him
nNL(cid:88)
(cid:113)

(cid:112)

nk

+

(cid:112)

(cid:113)

NA

Lpath(f, dim,AU

nk

)Υ αH (cid:0)ϕim0

nk

(cid:1)

NA

Lpath(f, dim,AU

nk

)λiml

nk (f )Υ αH (cid:0)ϕiml

nk

(5)

(cid:1) ,

l=1

nk

nk

nk

nk. 1im,LoS

where Υ is the antenna gain, Lpath(f, dim,AU
) is the path
loss determined by the frequency f and the distance dim,AU
between AP i and user U m
∈ {0, 1} indicates
the existence of the LoS path, which is determined by
the LoS probability based on the indoor THz blockage
model [7]. Moreover, nNL signiﬁes the number of NLoS
paths, and λiml
is the reﬂection coefﬁcient for NLoS path
nk
[19]. ϕiml
l
for
nk
the downlink channel between AP i and user U m
nk. Given
AoD ϕ,
the array response vector can be denoted by
(cid:2)1, ..., ejπ[m sin ϕ], ..., ejπ[(NA−1) sin ϕ](cid:3)T
1√
α(ϕ) =
. Ac-
cording to [20], the path loss Lpath(f, d) includes both spread-
ing loss and absorption loss, i.e.,

denotes the angle of departure (AoD)

NA

Lpath(f, d)[dB] = Lspread(f, d)[dB]+Labsorption(f, d)[dB]
(cid:18) c

(cid:19)

= 20 log10

− 10k(f )d log10 e,

4πf d

where k(f ) is the frequency-dependent medium absorption
coefﬁcient, d is the distance, and c is the light speed.

(6)

4

C. User Clustering

In traditional CSI-based massive MIMO-NOMA networks,
the user clustering usually contains a cluster-head selection
(CHS) procedure that chooses cluster head based on channel
conditions, followed by which the remaining users are grouped
with the highest channel-correlated cluster heads [21]. How-
ever, the CSI-based user clustering is inﬂexible to guarantee
the ultra-high data rate and mitigate interference for SE
users. To achieve customizable and intelligent communication
experiences, we extend the traditional CSI-based user cluster-
ing to a QoS-based user clustering. Relying on the smartly
reconﬁgured beams, users’ spatial channels can be ﬂexibly
aligned to achieve adaptive user clustering. Speciﬁcally, we
group multiple IoT users with a single SE user. In this way, we
can ensure multiplexing gain for SE users while enhancing IoT
user connections. In light of this, we assume the number of RF
chains activated at each AP is equal to its serving SE users, i.e.,
NR = KS. Let U m
nk, ∀k > 1,
be the IoT user. The low-complexity user clustering scheme
based on the reconﬁgured channels can be stated as follows.
The SE users are ﬁrstly selected as the cluster heads of
different clusters. Then, we deﬁne the channel spatial corre-
, hmm
lation C (hmm
n1 ) between an ungrouped IoT user k and
k
the cluster head U m
n1 as

n1 represent the SE user, and U m

C (hm

k , hm

n1) =

(cid:12)
(cid:12)
(cid:12)hm
(cid:107)hm

k )H (cid:12)
(cid:12)
n1 (hm
(cid:12)
k (cid:107)(cid:107)hm
n1(cid:107)

.

(7)

Thereafter, multiple IoT users can be non-orthogonally
grouped into the same cluster, where the cluster head achieves
the strongest reconﬁgured channel correlations with them.
The computational complexity of the QoS-based clustering
scheme is O (KUNR). In comparison, the conventional CSI-
based clustering scheme has the computational complexity of
O

NR (KU + KS)2(cid:17)

[21].

(cid:16)

D. Customized NOMA Decoding

Relying on the adaptively aligned channels through RISs,
the NOMA user decoding order in each cluster can be ﬂexibly
customized based on QoS requirements without degrading the
system performance. Exploiting the NOMA successive inter-
ference cancellation (SIC), SE users can subtract signals of
other users within the same cluster, and completely eliminate
intra-cluster interference based on power-domain multiplexing
to realize ultra-high-speed and reliability-guaranteed commu-
nications. To realize this goal, each SE user with the highest
QoS requirements in its cluster would be decoded at last, while
the data signals of K m
n − 1 IoT users in each cluster n would
be decoded ﬁrst.

To ensure the SIC at each IoT users in the same cluster
can be successfully carried out, the NOMA decoding order of
IoT users are rearranged according to equivalent channel gains
as |hm
n |2.
Thereafter, the SE user would sequentially decode the signals
of the former K m
n − 1 IoT users to completely cancel intra-
cluster interference. To successfully cancel interference from

n |2 ≥ ... ≥ |hm

n |2 ≥ |hm

n2Vmwm

n3Vmwm

Vmwm

nKm
n

IoT user U m
following SIC constraint

nk, ∀k > 1, imposed to SE user U m

n1, we have the

n1→nk ≥ γm
γm

nk→nk, ∀k > 1,

(8)

nk for decoding its signal, and γm

where γm
(SINR) of IoT user U m
is the SINR to decode the signal of IoT user U m
n1. We denote 1m,fail
U m
be satisﬁed, i.e., the SE user U m
interference from IoT user U m
intra-cluster interference from IoT user U m
noise at the SE user. In this way, γm
as

n,k→n,k is the signal-to-interference-and-noise ratio
n,1→n,k
nk at SE user
= 0 if the SIC constraint (8) can
n1 can cancel the intra-cluster
nk = 1, and the
nk would be taken as
n,1→n,k can be expressed

nk. Otherwise 1m,fail

nk

n,1→n,k = |hmm
γm

n1 Vmwm

n |2pm

nk ×

(cid:20)(cid:18) k−1
(cid:88)

(cid:88)

pm
nk(cid:48)+

nk(cid:48) pm
1m,fail
nk(cid:48)

(cid:19)

|hmm

n1 Vmwm

n |2 +

k(cid:48)=1

k(cid:48)>k

(cid:12)
(cid:12)hm(cid:48)m
(cid:12)

n1 Vm(cid:48)

wm(cid:48)
n(cid:48)

(cid:12)
2
(cid:12)
(cid:12)

P m(cid:48)
n(cid:48) + σ2

(cid:21)−1

,

(cid:88)

(m(cid:48) ,n(cid:48) )
(cid:54)=(m,n)

(9)

where σ2 is the power spectral density of additional white
Gaussian noise (AWGN), pm
nk is the power allocation coef-
n = (cid:80)Km
nk, and P m
ﬁcient for user U m
nk is the power
consumption of RF chain n at AP m.

k=0 pm

n

(cid:104)

, ..., (cid:98)hmm
NR

, (cid:98)hmm
2

(cid:98)Hmm =
(cid:98)hmm
1
beamforming is calculated as
(cid:99)Wm = (cid:2)
(cid:98)wm
1 , ..., (cid:98)wm
(cid:98)Hmm(cid:17)H (cid:20)
(cid:16)

NR

=

(cid:3)

5

(cid:105)

. Therefore, the ZF digital

(cid:98)Hmm (cid:16)

(cid:98)Hmm(cid:17)H (cid:21)−1

.

(13)

By introducing column power normalizing, the baseband

precoding matrix can be expressed as

wm

n =

n

(cid:98)wm
(cid:98)wm

n (cid:107)2

(cid:107)Vm

.

(14)

F. Transmission Rate
Deﬁne E{sm
nk (sm
with normalized power, and xm
transmitted signal in cluster n. Deﬁne zm
baseband signal received by each SE user U m
be formulated as
n1 = hmm
ym
(cid:124)

nk)H } = 1 as the transmitted symbols
nksm
nk as the
n
k=0
nk as the AWGN. The
n1 after SIC can

n = (cid:80)Km

n1 Vmwm
n(cid:48)

n1sm
n1
(cid:125)

1m,fail
nk

(cid:112)pm

+hmm

(cid:112)pm

(cid:112)pm

nksm

n1 Vmwm
n
(cid:123)(cid:122)
desired signal

(cid:88)

nk

k>1
(cid:123)(cid:122)
residual intra-cluster interference

(cid:124)
wm(cid:48)

n(cid:48) xm(cid:48)
n(cid:48)

(cid:88)

+

n0 Vm(cid:48)
hm(cid:48)m

(m(cid:48),n(cid:48))(cid:54)=(m,n)
(cid:124)

(cid:123)(cid:122)
inter-cluster interference

(cid:125)

.

+ zm
n1
(cid:124)(cid:123)(cid:122)(cid:125)
noise

(cid:125)

(15)

E. Sub-Connected Hybrid Beamforming

Therefore, the SINR of each SE user U m

n1 can be written as

We design the analog beamforming at each AP to increase
effective data gain of each cluster, and design the digital
beamforming for suppressing residual inter-cluster interference
that is not mitigated by RISs based on zero-forcing (ZF).

The analog beamforming matrix with the sub-connected

structure can be formulated as







Vm =

vsub
m11
vsub
m21
...
vsub

mN 1

... vsub
m1N
... vsub
m2N
...
...
... vsub

mN N







=







vsub
m11
0
...
0

0
...
0
...
...
...
... vsub

mN N




,



Nsub

1√

mni = 0 for n (cid:54)= i, and vsub

(10)
mnn ∈ CNsub×1 has
where vsub
an amplitude
. The sub-connected analog beamforming
is designed to improve the effective gains toward cluster
heads that are highly spatial-correlated to the cluster members.
Considering BA-bits quantized phase shifters in each antenna
subarray, the i-th element of the active analog beamforming
vector vsub

mnn is given by [6], [17]

vsub

mnn(i) =

√

1
Nsub

−j

e

mn

2π(cid:36)∗
2BA , i ∈ {1, 2, .., Nsub},

(11)

where (cid:36)∗

mn is the quantized phase calculated by

(cid:36)∗

mn = arg min(cid:36)∈{0,1,...,2BA −1}

j 2π(cid:36)
2BA −

e

(cid:12)
(cid:12)
(cid:12)
(cid:12)

hmm
|hmm

n1 (i)
n1 (i)|

(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(12)
To further suppress the effective inter-cluster interference
that hasn’t been canceled by RISs, we design the ZF digital
n ∈ CNR×1 denote the digital
beamforming as follows. Let wm
beamforming vector for cluster n at AP m. The cluster
nk Vm)T . Denote
center is given as (cid:98)hmm

(hmm

n = 1
Km
n

k∈Km
n

(cid:80)

n1 = |hmm
γm

n1 Vmwm

n |2 pm

n1

(cid:18) (cid:88)

k>1

1m,fail
nk

|hmm

n1 Vmwm

n |2 pm

nk

(cid:88)

+

(m(cid:48),n(cid:48))(cid:54)=(m,n)

(cid:12)
(cid:12)hm(cid:48)m
(cid:12)

n1 Vm(cid:48)

wm(cid:48)
n(cid:48)

2

(cid:12)
(cid:12)
(cid:12)

P m(cid:48)
n(cid:48) + σ2

(cid:19)−1

.

(16)

Moreover, the SINR of IoT users U m

nk, ∀k > 1, can be given

by

nk = |hmm
γm

nk Vmwm

n |2 pm

nk

(cid:18) k−1
(cid:88)

|hmm

nk Vmwm

n |2 pm

nk(cid:48)+

(cid:12)
(cid:12)hm(cid:48)m
(cid:12)

nk Vm(cid:48)

k(cid:48)=1

wm(cid:48)
n(cid:48)

2

(cid:12)
(cid:12)
(cid:12)

pm(cid:48)
n(cid:48) + σ2

(cid:19)−1

.

(cid:88)

(m(cid:48),n(cid:48))(cid:54)=(m,n)

(17)

Hence, the data rate of each user U m

nk at each time slot can

be expressed as

Rm

nk = log2 (1 + γm

nk) , ∀k ∈ K.

(18)

G. Power Consumption

The total power consumption for the proposed networks at
each time slot includes both transmit and circuit power, which
can be formulated as
NR(cid:88)

L
(cid:88)

M
(cid:88)

J
(cid:88)

ξP m

n + KPD + M PAP +

ωj

l PRIS

(cid:0)BR(cid:1) ,

P =

m=1

n=1

j=1

l=1

(19)
where ξ denotes the inefﬁciency of the phase shifter in the
THz network, PD is the circuit power consumption at each

(cid:0)BR(cid:1) denotes hardware energy dissipated at
user, and PRIS
each RIS element depending on the RIS resolution bit BR
[23]. Moreover, PAP is the circuit power consumption at each
AP, which is given by

PAP = PBB + NRPRF + NA (PPS + PA) ,

(20)

where PBB is the baseband power consumption, and PRF, PPS,
and PA denote power consumption of per RF chain, per phase
shifters and per power ampliﬁes, respectively.

Therefore, the network energy efﬁciency η at each time slot

can be formulated as
(cid:80)M

η =

(cid:80)M

m=1

(cid:80)NR
n=1

m=1

(cid:80)Km

(cid:80)N

n=1 ξP m

n +KPD +M PAP +(cid:80)J

n

k=1 log2 (1 + γm
nk)
(cid:80)L
l=1 ωj

j=1

l PRIS (BR)
(21)

6

various QoS requirements in terms of data rate and trans-
mission reliability of users. Therefore, the online objective
function can be formulated as follows

P0 : max
a(t)

lim
T →∞

T
(cid:88)

t=0

E [η(t)] ,

nk(t) ≥ Rm,min
s.t. Rm
Km
n (t)
NR(cid:88)
(cid:88)

nk

, ∀k ∈ K, t ∈ T ,

nk(t) ≤ P max
pm

AP , ∀m ∈ M, t ∈ T ,

(25a)

(25b)

(25c)

.

k=1

n=1
ωj
l (t) ∈ {0, 1}, ∀j ∈ J , 1 ≤ l ≤ L, t ∈ T ,
l (t) ∈ {0, 1, ..., 2BR−1}, ∀j ∈ J , 1 ≤ l ≤ L, t ∈ T ,
βj

(25d)

(25e)

H. Reliability Model

Suppose the THz MIMO-NOMA networks maintain a trafﬁc
buffer queue qm
nk(t) for each user, ∀t ∈ T , which aims to
transmit speciﬁc data volume in a predeﬁned time. At the
beginning of each time slot t, the queue length qm
nk(t) of user
U m

nk can be updated by

nk(t) + [qm

nk(t + 1) = Am
qm
nk(t) is the transmission data rate of (18), Am

where Rm
nk(t)
denotes the trafﬁc arrival column at time slot t following the
poisson distribution, and [x]+ = max{x, 0}.

nk(t) − Rm

nk(t)]+ ,

(22)

To ensure reliable transmission, we should guarantee the
queue stability and keep the outages below a predeﬁned
threshold [22]. The queue stability is ensured by

E [qm

nk(t)] = lim
T →∞

T
(cid:88)

t=1

qm
nk(t) < ∞, ∀k ∈ K.

(23)

Moreover, the outage probability, i.e., the probability that the
nk(t) of device U m
trafﬁc queue length qm
nk exceeds the threshold
qm,max
nk. Therefore, the
nk
reliability conditions can be formulated as

, is limited by a certain threshold (cid:15)m

Pr (qm

nk(t) ≥ qm,max

nk

) ≤ (cid:15)m

nk, ∀k ∈ K.

(24)

III. LYAPUNOV OPTIMIZATION BASED DEC-POMDP
PROBLEM

In this Section, we ﬁrst formulate the constrained Dec-
POMDP problem, and then transfer the constrained Dec-
POMDP problem into a normal Dec-POMDP problem based
on the Lyapunov optimization theory.

A. Constrained Dec-POMDP Model

We aim to dynamically ﬁnd a stationary online policy π,
which can jointly optimize the dynamic RIS element selection,
coordinated discrete phase-shift control, and transmit power
allocation by observing the environment state at each time
slot t. Under the given user clustering, NOMA decoding, and
hybrid beamforming schemes, the joint policy dynamically
maximizes the expected system energy efﬁciency for the smart
reconﬁgurable THz MIMO-NOMA network, while satisfying

(23), (24),

(25f)

nk

where a(t) = [ω(t), α(t), β(t)]. Constraint (25b) ensures
the minimum data rate of each user, (25c) denotes the total
transmit power should be less than the maximum power P max
AP ,
(25d) signiﬁes the binary ON/OFF state of RIS elements,
and constraint (25e) represents the discrete phase-shift control.
Note that the SIC constraint (8) is ignored since it has been
implied in the SINR expression (16) via the indicator 1m,fail
.
This online policy can be modeled as a constrained Markov
Decision Process (MDP). However, solving P0 in a cen-
tralized way is computationally inefﬁcient due to the large-
scale joint state-action space and the heavy overhead of high-
dimensional
information exchange from multiple APs and
RISs to the centralized controller. To tackle P0 in an efﬁcient
and low-complexity manner, we model the long-term energy
efﬁciency optimization problem as a constrained Dec-POMDP.
In detail, the POMDP provides a generalized framework to
describe an MDP with incomplete information, while Dec-
POMDP extends POMDP to the decentralized settings as
P = (I, S, Ω, A, P a
s→s(cid:48), π, r, Γ). Here, I denotes a set of
agents. S, Ω, and A denote the state, observation, and action
spaces. At each slot t, given the true state s(t) ∈ S, each agent
i partially observes a local observation, based on which it can
determine a local action using decentralized policy π. The
joint observation and action vectors of all agents are denoted
by Ω(t) ∈ Ω and a(t) ∈ A, and the decentralized policy
π(a(t)|s(t)) means the probability of taking joint action a(t)
s→s(cid:48) = P(s(cid:48)|s, a) is the
at the joint state s(t). Furthermore, P a
probability of transferring into a new state s(cid:48) by taking action
a at state s. Given the global reward function r (s(t), a(t)) and
the discount factor Γ, the agents can cooperate and coordinate
to maximize the discounted return. In this work, we model
APs and RISs as two types of agents, whose set is denoted as
I = I 0 ∪ I 1. Let I u denote the set of the u-th type agents,
where u = {0, 1} represent APs and RISs respectively. We
specify the formulated Dec-PoMDP as follows.

1) Observation: The joint observation can be expressed as
Ω(t) = (cid:2)Ω0
i (t) is
the local observation of agent i ∈ I u that involves part of the
environment information, given by

J (t)(cid:3), where Ωu

1(t), ..., Ω0

1(t), ..., Ω1

M (t), Ω1

Ω0

i (t) =

(cid:20)(cid:26)

ii(cid:48)

(cid:101)H

(t)

(cid:27)

, qi(t), τ 0

(cid:21)
, ∀i ∈ I 0,
i (t)

(26)

i(cid:48)∈N 0

i ∪{i}

Ω1

i (t) =

(cid:20) (cid:110)

Fim(t)

(cid:111)

(cid:110)

Gmi(t)

,

(cid:111)

m∈N 1
i

m∈N 1
i

, τ 1

i (t)

(cid:21)
, ∀i ∈ I 1,

(cid:105)

(cid:21)

(cid:111)

k∈Km

(t) =

and N 1

(cid:101)hii(cid:48)
nk(t)

nk (t)(cid:9)

(27)
where τ u
i (t) denotes the local action-observation history of
agent i, and N 0
i denotes the neighboring agent
i
sets of RIS i ∈ I 0 and AP i ∈ I 1, respectively. Further-
(cid:20)(cid:110)
more, we deﬁne (cid:101)Hii(cid:48)
and Fim(t) =
(cid:104)(cid:8)f im
in
our settings, the joint observation also represents the true
environment state, i.e., Ω(t) = s(t).
In this work, we

long-term
joint RIS element selection, coordinated discrete phase-
shift control, and power allocation optimization problem.
Therefore, we deﬁne the joint action vector as a(t) =
1(t), ..., a1
[a0
i (t) is the local
action of agent i ∈ I u that can be expressed as

as the vectorized channels. Note that

J (t)], where au

1(t), ..., a0

M (t), a1

2) Action:

consider

k∈Ki(cid:48)

a

7

general MADRL algorithms. To meet the reliability constraints
(29), we construct a virtual queue Y m
nk(t) to model the instan-
taneous deviation of queue length constraints for each user
U m

nk evolves as follows

nk. Here, Y m

nk(t + 1) = [Y m
Y m

nk(t) + (qm

nk(t + 1) − qm,max

nk

nk)]+ ,
(cid:15)m

(30)

12(t), ..., ΞM

nk(t) = [qm

where we initialize Y m

nk(t) = 0 at t = 1, ∀k ∈ K.
nk(t), Y m
(cid:105)
NRKM (t)

Let Ξm
nk(t)], ∀k ∈ K. Deﬁne Ξ(t) =
(cid:104)
Ξ1
11(t), Ξ1
as the combined queue vec-
tor. Then, we introduce the Lyapunov function L(Ξ(t)) =
1
2 Ξ(t)ΞT (t) to measure the satisfaction status of the relia-
bility constraint, which should be maintained under a low
value. Moreover, the one-step Lyapunov drift is deﬁned as
∆L(t) = L(Ξ(t+1))−L(Ξ(t)), which can be upper bounded
by the following Lemma.

Lemma 1. Deﬁne ∆Lm
then ∆Lm

nk(t) can be upper bounded by

nk(t) = L(Ξm

nk(t + 1)) − L(Ξm

nk(t)),

(28)

(cid:40)

au
i (t) =

(cid:104)

pi(t),
∀i ∈ I 0,
(cid:2)ωi(t), βi(t)(cid:3) , ∀i ∈ I 1.
(cid:105)

11(t), pm
pm

Here, pi(t) =
12(t), ..., pm
is the down-
link power allocation vector of AP agent i ∈ I 0, and ωi(t) =
L(t)(cid:3)
L(t)(cid:3) and βi(t) = (cid:2)βi
(cid:2)ωi
denote the dynamic reﬂecting element selection and the dis-
crete phase-shift control of RIS agent i ∈ I 1, respectively.

2(t), ..., ωi

2(t), ..., βi

1(t), ωi

1(t), βi

NRKm
NR

(t)(t)

i (t)|Ωu

3) Decentralized Policy: The joint policy is decom-
posed into multiple decentralized and parallel local policies
i (t)) for each agent i ∈ I u. At each time slot t,
π(au
all the agents take local actions au
i (t) based on the observed
local observations Ωu
i (t) to cooperatively maximize the global
reward.

Reward:

δm(t)

=

n (t)

Rm,min
nk

(t)−Rm

be

the

data

rate
constraint violation. Then, the global reward can be deﬁned
as r (s(t), a(t)) = η(t) − ξδ(t), which maximizes the network
energy efﬁciency as well as satisfying data rate requirements.
Here, δ(t) = (cid:80)M
m=1 δm(t), and ξ is a non-negative parameter
that imposes a penalty for data rate violation. However, due to
the intractable long-term average queue stability and reliability
constraints, it is infeasible to directly use the general MADRL
methods to solve the constrained Dec-POMDP problem [24],
[25]. Hence, we recast the constrained Dec-POMDP into a
standard Dec-POMDP based on the Lyapunov optimization
theory [26].

4) Global
(cid:80)Km
k=1

(cid:80)NR
n=1

(cid:104)

Let
nk(t)

(cid:105)+

B. Equivalently Transferred Dec-POMDP

Based on the Markov’s inequality [27], we can obtain the
) ≤
. Therefore, the reliability constraint (24)

upper bound of the outage probability Pr (qm
E [qm
can be strictly guaranteed by ensuring

nk(t) ≥ qm,max

nk(t)] /qm,max

nk

nk

E [qm

nk(t)] ≤ qm,max

nk

(cid:15)m
nk, ∀k ∈ K.

(29)

∆Lm

nk(t) ≤ C m

nk + Bm

nk(t) +Λm

nk(t) (Am

nk(t) − Rm

nk(t)) , (31)

nk = 2C m,q
)2 + 1

nk + C m,Y

nk
nk(t) = 1

2 (Rm,max
2 (qm
nk(t) + 2qm

is a constant, with C m,q
nk =
nk
nk)2.
)2 and C m,Y
2 (qm,max
nk = 1
(cid:15)m
nk
nk(t))2 + Y m
nk(t) + qm
nk(t) [Am
nk(t)]
nk(t) are ﬁxed values at each time

nk(t) = Y m

nk

where C m
2 (Am,max
1
Moreover, Bm
and Λm
slot.

Proof. See Appendix A.

Based on the Lyapunov optimization,

the original con-
strained Dec-POMDP of maximizing the system energy ef-
ﬁciency while ensuring the long-term reliability constraints
can be transformed into minimising the following drift-minus-
bonus function

∆L(t) − ζη(t) + ξδ(t) ≤

+ Λm

nk(t) (Am

nk(t) − Rm

nk(t))

M
(cid:88)

NR(cid:88)

Km
n (t)
(cid:88)

m=1
n=1
(cid:21)

k=1

(cid:20)
C m

nk + Bm

nk(t)

− ζη(t) + ξδ(t),

(32)

where ζ denotes the positive coefﬁcient
that controls the
tradeoff between energy efﬁciency and transmission reliability,
and the inequality is implied by Lemma 1 and ∆L(t) =
(cid:80)M
nk(t). By ignoring the independent
terms from control variables, P1 can be rearranged as

n (t)
k=1 ∆Lm

(cid:80)NR
n=1

(cid:80)Km

m=1

max
π

lim
T →∞

1
T

T
(cid:88)

t=1



Eπ

ζη(t)−ξδ(t)+

M
(cid:88)

NR(cid:88)

Km
n (t)
(cid:88)



Λm

nk(t)Rm

nk(t)

 ,

m=1

n=1

k=1

s.t. (25c) − (25e).

(33a)

(33b)

To tackle the long-term average constraints (23) and (29),
we apply the virtual queue technique and Lyapunov optimiza-
tion theory [26] to recast the intractable constrained Dec-
POMDP as a normal Dec-POMDP, which can be solved by

Based on (33), the local observation of AP i ∈ I 0 in (26)

can be transformed as

Ω0

i (t) =

(cid:20) (cid:26)

ii(cid:48)

(cid:101)H

(t)

(cid:27)

, Λi(t), τ 0

(cid:21)
, ∀i ∈ I 0,
i (t)

(34)

i(cid:48)∈N 0

i ∪{i}

(cid:104)

(cid:105)
where Λi(t) =
12(t), ..., Λi
. From (33),
the global reward function r (s(t), a(t)) in the equivalent Dec-
POMDP is modiﬁed into

11(t), Λi

n(t)(t)

NRKi

Λi

8

r (s(t), a(t)) = ζη(t)−ξδ(t)+

M
(cid:88)

NR(cid:88)

Km
n (t)
(cid:88)

m=1

n=1

k=1

Λm

nk(t)Rm

nk(t). (35)

IV. GE-VDAC ALGORITHM FOR DISTRIBUTED RIS
CONFIGURATION AND POWER ALLOCATION

A. Review of MADRL Methods

instability,

The standard Dec-POMDP problem can be solved based
on general cooperative MADRL algorithms [28], [29]. By
exploiting the remarkable representation ability of deep neu-
ral network (DNN) for approximating arbitrary non-convex
functions, MADRL algorithms can learn the mapping from
agents’ observations to actions through exploitation and explo-
ration. However, MADRL algorithms commonly suffer partial
observability, environment instability, and credit assignment
problems [28]. To cope with environment
the
multi-actor critic framework based on centralized-training and
distributed-execution (CTDE) design is proposed [29], which
learns distributed policies with a centralized critics. However,
since it utilizes a uniﬁed critic value to compute local policy
gradients, agents cannot fairly learn to contribute for global
optimization, leading to the so-called multiagent credit assign-
ment problem [28], [30], also referred to as indolent agent.
Therefore, the idea of different rewards has been introduced,
which computes the individual reward for each agent
to
evaluate their contributions and motivate coordinations. QMIX
[31] is the widely utilized mechanism that decomposes the
joint state-action value into monotonic individual state-action
functions for different agents. To overcome the monotonicity
limitation of QMIX, QTRAN with higher generalization of
value factorization can be leveraged [32]. Nevertheless, both
QMIX and QTRAN as extensions of the deep Q-learning are
mainly used to deal with the problems with discrete action
spaces. In [33], value-decomposition actor-critic (VDAC) is
introduced to incorporate the value decomposition into the
advantage actor-critic (A2C) framework, which has continuous
action space and higher sample efﬁciency.

In our proposed framework, it’s critical to facilitate coordi-
nation among multiple APs and RISs to mitigate interference,
improve system energy efﬁciency, and guarantee diversiﬁed
QoS requirements. Under the realistic partially observable
environment, although the joint design of RIS conﬁguration
and power allocation has been decomposed into distributed
local policies, information still need to be exchanged among
neighboring agents to achieve fully coordination. However,
considering the high-dimensional CSI information resulting
from the massive MIMO structure, directly exchanging infor-
mation among interacting neighboring agents during each ex-
ecution can cause high communication overhead and latency.
Therefore, the existing MADRL algorithms are still inefﬁcient
to solve the highly coupled Dec-POMDP problem. In this
section, we propose GE-VDAC, a novel MADRL algorithm
that can tackle the multiagent credit assignment as well as the
above problems.

Fig. 3. Procedure of the proposed GE-VDAC algorithm.

B. The Proposed GE-VDAC Framework

GE-VDAC extends the commonly-used CTDE design in
the existing MADRL algorithms, which realizes more efﬁ-
cient cooperative learning by integrating two techniques, i.e.,
graph embedding and different rewards. The interplay among
interacting agents are modeled as a directed communication
graph. Instead of directly exchanging high-dimensional in-
formation, the neighboring agents exchange low-dimensional
embedded features learned by graph embedding, thus requiring
fewer information exchange to achieve efﬁcient coordination
under partially observable environment. Moreover, the graph-
embedded features possess permutation-invariant property. By
learning distributed DRL policies over the graph-embedded
observation space that has reduced dimension and enjoys
permutation-invariant property,
the learning speed and the
generalization ability can be improved.

As shown in Fig. 3,

the GE-VDAC jointly trains three
neural networks, i.e., the distributed graph-embedded actors,
the distributed critics, and the centralized mixing network. For
simplicity, we assume the agents belonging to the same type
u share the neural network parameters of both the distributed

Mini-batch samplesLocal actionLocal obobs.Local actionDistributed executionCentralized trainingReplay bufferMixing networkDistributed criticDistributed criticLocal criticLocal criticLocal criticPolicy gradientDistributed criticDistributed actorDistributed actorGlobal rewardSamples of global rewards and statesPolicy gradientMPGNNLayer2Layer1Local obobs.Local actionGRUDistributed actorLocal obs.MPGNNLayer2Layer1MPGNNLayer2Layer1Embedded featuresEmbedded featuresPolicy gradientGRUGRU.........Local embedded statesGraph embeddingAction generationLocal embedded statesLocal embedded statesCritic gradientCritic gradientCritic gradientGraph embeddingAction generationGraph embeddingAction generationCritic gradientactor πu and critic V u. The distributed graph-embedded actor
contains a semi-distributed graph embedding module learning
graph-embedded features for efﬁcient information exchange,
in conjunction with a fully-distributed action generation mod-
ule that predicts local action based on the local embedded
state attained by the graph embedding module. The graph
embedding module is implemented as message passing graph
neural network (MPGNN) [34], [35]. Moreover, the action
generation module mainly comprises a gated recurrent unit
(GRU) [36], which is a simpliﬁed variant of long-short term
memory (LSTM) that can achieve comparative performance
[37]. Two fully-connected (FC) layers are connected with the
GRU before and after, respectively. On the other hand, the
distributed critic evaluates an individual value of the local
embedded state, which achieves differential reward to judge
each agent’s contribution for global optimization. Meanwhile,
a global mixing network is trained to combine the distributed
critics, which guarantees that equivalent policy improvement
can be achieved based on the value decomposition.

C. Graph-Embedded Actor

1) Graph Modeling: To characterize the interplay among
neighboring agents, we model the THz reconﬁgurable massive
MIMO-NOMA networks as a directed communication graph
G = [I, E, TN, TE], where agents are modeled as two types
of heterogeneous nodes I, and interplay among agents are
modeled as edges E. TN : I → Cdu
N maps a node i to its
i (t). Denote tuple (i, i(cid:48)) as a
N-dimensional node feature ou
du
directed edge from the source node i to the destination node
i(cid:48). TE : E → Cdii(cid:48)
E maps an edge (i, i(cid:48)) to the dii(cid:48)
E -dimensional
edge feature dii(cid:48)(t). Both ou
i (t) and dii(cid:48)(t) are extracted from
the local observation of node i ∈ I u.

The node feature of a AP node i ∈ M contains the spatial
channel information from AP i to its associated users, the
queue information of its associated users, and the local action-
observation history of AP i, deﬁned as
(cid:16)

(cid:17)

(cid:104)
vec

ii
(cid:101)H

(t)

, Λi(t), τ 0

(cid:105)
i (t)

, ∀i ∈ I 0.

o0
i (t) =

(36)

Moreover, the node feature of a RIS node i ∈ I 1 includes the
local action-observation history, i.e., o1

i (t) = τ 1

i (t).

The edge feature dii(cid:48) depicts the interplay effect of agent i

to i(cid:48), which can be mathematically denoted as

dii(cid:48) (t) =
(cid:20)(cid:110)


(cid:16)

(cid:104)

vec
(cid:16)

vec
(cid:18)

(cid:101)Him(t)
(cid:17)

Gii(cid:48)
ii(cid:48)

(t)
(cid:19)

vec

(cid:101)H

(t)




0,

(cid:17)(cid:111)

(cid:21)

m∈N i(cid:48)
1
(cid:16)
Fii(cid:48)

, vec

,

(cid:17)(cid:105)

(t)

i ∈ I 0, i(cid:48) ∈ I 1, and i(cid:48) ∈ N 0
i ,

,

i ∈ I 1, i(cid:48) ∈ I 0, and i(cid:48) ∈ N 1
j ,

,

i, i(cid:48) ∈ I 0, and i(cid:48) ∈ N 0
i ,

otherwise.

(37)

Speciﬁcally, for an AP-RIS link, the edge feature is the spatial
channels from AP i to the users served by neighboring APs
of RIS i(cid:48). For an AP-AP link, the edge feature denotes the
channel from AP i to the users associated with AP i(cid:48). For a
RIS-AP link, the edge feature includes the channels between
RIS i and both AP i(cid:48) and its associated users.

9

To learn the structured representation of

the THz re-
conﬁgurable massive MIMO-NOMA networks, we integrate
MPGNN [35] into the distributed actor/critic networks for
embedding the graph. Therefore, node/edge features of
the directed graph over high-dimensional joint state space
can be embedded into permutation-invariant features over
low-dimensional space. By exchanging the learned low-
dimensional and permutation-invariant embedded features
among neighboring agents, it’s capable to improve general-
ization and enhance coordination among APs and RISs, while
only requiring low information exchange overhead.

2) Graph-Embedded Actor: The graph-embedded actor
(policy) comprises a semi-distributed graph embedding mod-
ule which learns the embedding of the graph, followed by a
distributed action generation module that outputs action by
taking the local embedded sate as inputs. Here, we deﬁne πθG
as the graph embedding sub-policy, and deﬁne πu
, ∀u, as
θA
the action generation sub-policies, which are parameterized as
MPGNNs and GRUs, respectively. Let θu
A denote the
MPGNN and GRU weight parameters shared among agents
i ∈ I u, respectively.

G and θu

We maintain a MPGNN at each distributed node i ∈ I u.
Similar to the multi-layer perceptron (MLP), MPGNN exploits
a layer-wise structure. In each MPGNN layer, each agent ﬁrst
transmits embedded information to its neighbor agents, and
then aggregates embedded information from neighbor agents
and updates its local hidden state.

Deﬁne the edges (i, i(cid:48)) and (i(cid:48), i) as the outbound and
inbound edges of node i. Let N u
i− denote the sets of
neighbor agents that are linked with agent i through outbound
and inbound edges of agent i, respectively. In layer n, each
agent i ∈ I u locally embeds its node feature and the outbound
edge feature dii(cid:48)(t) as

i+ and N u

e(n)
ii(cid:48) (t) = ψ(n)

u

(cid:16)
z(n−1)
ui

(cid:17)

(t), dii(cid:48)(t)

, ∀i(cid:48) ∈ N u

i+, i ∈ I u,

ui

ii(cid:48) (t) to its neighbor agents i(cid:48) ∈ N u

(38)
where z(n−1)
(t) denotes the hidden state of MPGNN layer
n − 1 at agent i ∈ I u, and ψu(·) is the distributed embedding
function. Thereafter, each agent i transmits the outbound
embedded feature e(n)
i+, and
receives the inbound embedded feature e(n)
i(cid:48)i (t) from i(cid:48) ∈ N u
i−.
Thereafter, the received embedded features are aggregated with
a aggregation function φu(·), which is a permutation-invariant
function such as sum(·), mean(·) and max(·). By combining
the local hidden state and the aggregated features using the
combining function Ψu(·), agent i obtains the hidden state
z(n)
ui (t) of layer n as

z(n)
ui (t) = Ψ(n)
u

(cid:18)
z(n−1)
ui

(t), φ(n)

u

(cid:18)(cid:110)

e(n)
i(cid:48)i

(cid:111)

(cid:19)(cid:19)

(t)

, ∀i ∈ I u.

(39)
Combining (38) and (39), the update rule of the n-th MPGNN
layer at node i ∈ I u can be rewritten as

i(cid:48)∈N u
i−

z(n)
ui (t) =
(cid:18)
z(n−1)
ui

Ψ(n)
u

(t), φ(n)

u

(cid:18)(cid:110)

ψ(n)
u

(cid:16)
z(n−1)
ui(cid:48)

(cid:17)(cid:111)

(t), di(cid:48)i(t)

(cid:19)(cid:19)
,

(40)

i(cid:48)∈N u
i−

where z(n)
i ∈ I u, and z(0)

ui (t) = ou

i (t).

ui (t) is the hidden/output state at n-th layer for agent

After the graph embedding module, agent i ∈ I u would
predict local action utilizing GRU based on the output local
embedded state (cid:101)zu
(cid:101)zu
i (t) =

i (t), which is given by

(cid:104)
i (t), z(N )
ou

ui (t)

(41)

(cid:105)

.

The local action au

i (t) for each agent i ∈ I u is sampled
from the action generation sub-policy πu
θA

i (t)).

i (t)|(cid:101)zu

(au

Algorithm 1 Coordinated Multi-AP and Multi-RIS Scheduling
Based on Distributed Graph-Embedded Actors
Input: Distributed actors πu

θ , ∀u ∈ {0, 1}.

nk(t) = 0, Y m

nk(t) = 0, ∀k ∈ K;

1: Initialize t = 1, qm
2: for t = 1, 2, ..., T do
3:
4:

Each agent obtains local observation as (34) and (27);
for each MPGNN layer n ∈ {1, 2, ..., N } do

i+, using (38);

Each agent i ∈ I u calculates local feature embedding
e(n)
ii(cid:48) (t), ∀i(cid:48) ∈ N u
Each agent i ∈ I u aggregates feature embedding
e(n)
i(cid:48)i (t) from neighbor agents i(cid:48) ∈ N u
i−, and update
the hidden state z(n)
ui (t) based on (39);

(au

end for
Each agent i ∈ I u samples local action au
to πu
θA
Each AP m calculates QoS-based user clustering, ob-
tains hybrid beamformer Vm(t) and Wm(t), and de-
cides decoding order of IoT users for each user cluster;

i (t) according

i (t)|(cid:101)zu

i (t));

Observe the global reward r (s(t), a(t)), and calculate
nk(t + 1) and Y m
qm
nk(t + 1) according to (23) and (30);

11: end for
Output: {s(t), (cid:101)z(t), a(t), r (a(t), s(t)) , s(t + 1)}t∈{1,2,...,T }

5:

6:

7:
8:

9:

10:

(au

i (t)|(cid:101)zu

The coordinated scheduling for APs and RISs based on
the distributed graph-embedded actors can be summarized as
Algorithm 1. At each time slot t, APs and RISs exchange
embedded features and obtain their local embedded state (cid:101)zu
i
through MPGNN. Thereafter, each agent i ∈ I u samples
its local action based on the action generation sub-policy
πu
i (t)) of the local actor. By observing the recon-
θA
ﬁgured channels, each AP further decides the user clustering,
hybrid beamforming and IoT user decoding order. In this
way, the customized user clustering, NOMA decoding and
hybrid beamforming schemes are considered as part of the
environment feedback, which would be implicitly learned by
the distributed actors through exploration and exploitation. The
experiences are then joined into the replay memory buffer B
for centralized learning.

3) Policy improvement: Denote the combined parameters
of graph embedding module and action generation module
in the distributed actor (policy) as θu
A]. Here, the
distributed actors θπ = [{θu
π}u∈{0,1}] are trained to maximize
the following performance function:

π = [θu

G, θu

Lπ(θu

π) = Es∼pπ,a∼π [r(s(t), a(t))] ,

(42)

10

where pπ is the joint state transition by following the joint
policy π. Therefore, we calculate policy gradient based on the
advantage function, which is given by

∆θu

π(t) =

(cid:88)

i

∇θu

π

log πu (au

i (t)|ˆsu

i (t)) A (s(t), a(t)) , (43)

where ˆsu
i (t)is the actual input of the graph-embedded actor.
Moreover, A (s(t), a(t)) denotes the temporal difference (TD)
advantage, which is given by

A (s(t), a(t)) = Q(s(t), a(t)) − Vtot(st)

= r(s(t), a(t)) + ΓVtot(st+1) − Vtot(st).

(44)

Here, Vtot(st) and Q(s(t), a(t)) denote the global state value
and the global state-action value, respectively.

D. Value Decomposition

To address credit assignment problem during training, we
rely on the value-decomposition critics [33] to train the
distributed actors, which decomposes the global state value
Vtot(s(t)) into local critics that are combined with a mixing
function f mix as

Vtot(s(t)) =f mix

(cid:18)

s(t), V 0 (cid:0)

1(t)(cid:1) , V 0 (cid:0)
(cid:101)z0

2(t)(cid:1) , ..., V 0 (cid:0)
(cid:101)z0

M (t)(cid:1) ,
(cid:101)z0

V 1 (cid:0)

1(t)(cid:1) , V 1 (cid:0)
(cid:101)z1

2(t)(cid:1) , ..., V 1 (cid:0)
(cid:101)z1

J (t)(cid:1)
(cid:101)z1

(cid:19)
,

(45)

where V u ((cid:101)zu

i (t)) is the local state value for agent i ∈ I u.

Now, we are ready to introduce the following Lemma.

Lemma 2. Any action au
that can improve agent i’s local
i
critic value at local embedded state (cid:101)zu
i will also improve the
global state value Vtot, if the other agents stay at the same
local embedded states taking actions au
−i, and the following
relationship holds

∂Vtot (s(t))
∂V u ((cid:101)zu
i (t))

≥ 0, ∀i ∈ I u, u ∈ {0, 1}.

(46)

Proof. Based on (46), the global reward monotonically in-
crease with V u ((cid:101)zu
i (t)) when the other agents stay at the same
local embedded states taking actions au
−i(t). Therefore, if a
local action au
i (t)), obviously
it can also improve Vtot (s(t)).

i (t) is capable to improve V u ((cid:101)zu

Remark 1. Based on Lemma 2, it’s rational to approximately
decompose the high-complexity global critic into distributed
critics combined by a mixing network with non-negative
thus reducing complexity and
network weight parameters,
achieving difference rewards.

During centralized training, each agent attains a differential
reward V u ((cid:101)zu
i (t)) based on the local graph-embedded features
to evaluate its contribution for global reward improvement,
which can further facilitate agents’ coordination. The weights
of mixing network are generated through separate hypernet-
works [38]. Each hypernetwork takes the joint state and state-
value as input to compute the weights of one layer of the
mixing network [31]. To guarantee that the output weights are

non-negative, the absolute activation function is exploited at
the hypernetworks.

Deﬁne θu

V as the weight parameters of distributed critic V u
θ
that are shared among agents i ∈ I u, and denote µ as the
weights of the mixing network f mix
. The distributed critic and
mixing network are optimized by mini-batch gradient descent
to minimize the following critic loss:

µ

LV (θu
(cid:18)
(cid:20)
s(t),V 0
ˆrt (s(t), a(t)) −f mix
θ

V(t), µ(t)) = [ˆrt (s(t), a(t)) − Vtot (s(t))]2
J (t)(cid:1)
(cid:0)
1(t)(cid:1) ,...,V 1
(cid:0)
(cid:101)z1
(cid:101)z0

=

µ

θ

(cid:19)(cid:21)2
,

(47)

where ˆrt (s(t), a(t)) = (cid:80)n
i=1 Γi−1rt+i + ΓnVtot (st+n) is the
n-step return bootstrapped from the last state, with n upper-
bounded by T . Therefore, the mixing networks can be updated
by

µ ← µ − κµ

∇µLV (θu

V(t), µ(t)) ,

(48)

(cid:88)

t

where κµ is the learning rate for mixing network update.

To reduce complexity, we further share the weight pa-
rameters of non-output layers between distributed critics and
actors for agents of the same type, similar to [33]. Denote
the combined weight parameters of the distributed actors and
G, θu
critics networks as θu = [θu
V]. Therefore, the critic
gradient with respect to θu can be given by

A, θu

∆θu

V(t) = ∇θu LV (θu

V(t), µ(t)) .

(49)

Hence, the update rule of the distributed actor/critic networks
can be derived as

θu ← θu +

(cid:88)

t

(κπ∆θu

π(t) − κV∆θu

V(t)) ,

(50)

where κπ and κV are the learning rate for policy improvement
and critic learning, respectively.

The whole GE-VDAC based MADRL algorithm is summa-

rized in Algorithm 2.

Algorithm 2 GE-VDAC Based MADRL Algorithm

1: Initialize the parameters of distributed actors/critics

θu, ∀u, and the mixing network µ;
2: Initialize the learning rates κµ, κπ, κV;
3: for each training episode do
4:
5:
6:

Initialize replay buffer B = ∅;
for each semi-distributed execution stage do

t∈{1,2,...,T } to replay buffer B;

Execute the semi-distributed multi-AP multi-RIS
scheduling for T steps based on algorithm 1;
Add experiences (cid:8)s(t), (cid:101)z(t), a(t), r (a(t), s(t)) , s(t+
1)(cid:9)
end for
Draw a batch of experiences from buffer B;
Calculate the policy gradient θu
Calculate the critic loss based on (47);
Update mixing network weights µ based on (48);
Calculate the critic gradients ∆θu
V, ∀u, based on (49);
Update distributed graph-embedded actors and critics
based on (50).

π, ∀u, based on (43);

7:

8:
9:
10:
11:
12:

13:
14:

15: end for

11

E. Theoretical Analysis of GE-VDAC

1) Permutation invariance: Firstly, we show that GE-VDAC
has permutation-invariant property, which can lead to better
generalization. Consider a graph G, whose node and edge
features are denoted by O and D. Let ν denote the permutation
operator. Let ν (cid:63) I and ν (cid:63) (O, D) denote the permutation
of nodes (agents) and graph features, respectively. Given two
graphs G and G(cid:48), if their exists a permutation ν satisfying
(O, D) = ν (cid:63)(O(cid:48), D(cid:48)), then G and G(cid:48) are isomorphic, denoted
as G ∼= G(cid:48).

Deﬁnition 1. Given two isomorphic communication graphs
G ∼= G(cid:48) with permutation (O, D) = ν (cid:63) (O(cid:48), D(cid:48)), the dis-
tributed actors/critics are permutation invariant if the output
joint action vector a, a(cid:48) and joint critic vector v, v(cid:48) satisfy

a = ν (cid:63) a(cid:48), v = ν (cid:63) v(cid:48).

(51)

Traditional centralized/multi-agent actor-critic algorithms
usually exchange information directly and utilize neural net-
works such as MLP, convolutional neural network (CNN) and
recurrent neural network (RNN) to learn actor and critic,
which cannot achieve the permutation invariance property.
Despite a sample and all of its agents’ permutations actually
represent the same environments, they would be viewed as
utterly different samples. Since traditional algorithms cannot
adapt to agents’ permutations intelligently, all permutations of
one sample should be fed to train actors and critics, leading
to poor generalization and learning speed. However, by ex-
tending the traditional DRL algorithms, the graph embedding
based distributed actors and critics in GE-VDAC enjoy the
permutation invariance property, as shown below.

Proposition 1. If the aggregation functions φu(·), ∀u, utilized
in (39) and (40) are permutation invariant, the distributed ac-
tors/critics based on GE-VDAC satisfy permutation invariance.

Proof. Considering the update rule of hidden states in (40), if
aggregation functions φu(·), ∀u, are permutation invariant, the
graph embedding features obtained by MPGNN πu
, ∀u, enjoy
θG
permutation invariant property [35], i.e., πu
(ν (cid:63) O, ν (cid:63) D) =
θG
ν (cid:63) (cid:0)πu
(O, D)(cid:1). Given agents’ permutation (O(cid:48), D(cid:48)) =
θG
(ν (cid:63) O, ν (cid:63) D), we have

(zu)(cid:48) = πu
θG

(ν (cid:63) O, ν (cid:63) D) = ν (cid:63) (cid:0)πu
θG

(O, D)(cid:1) = ν (cid:63) zu, ∀u.
(52)
i )(cid:48) = (cid:101)zu
Therefore, we can obtain ((cid:101)zu
ν(i), ∀i, ∀u, which implies
the permutation equivalence of the local embedded states.
Considering the deﬁnition of the local critics, we can achieve
(cid:110)
v(cid:48) = (cid:8)V u

= ν (cid:63) v.

(cid:17)(cid:111)

V u
θ

(cid:16)
(cid:101)zu

ν(i)

(cid:0)((cid:101)zu

i )(cid:48)(cid:1)(cid:9)

θ

i∈(ν(cid:63)I) =

i∈(ν(cid:63)I)

Moreover, since the local actions are sampled from au
πu
θA

(cid:0) · | ((cid:101)zu

ν(i)

(cid:0) · |(cid:101)zu
(cid:0)(au

(cid:1) and (au
i )(cid:48)(cid:1)= πu

i )(cid:48) ∼ πu
θA
(cid:0)au

i )(cid:48) | ((cid:101)zu

ν(i)|(cid:101)zu

i )(cid:48) (cid:1), we have
(cid:1), ∀i ∈ I u, u ∈ {0,1}, (54)

θA
which signiﬁes a(cid:48) = ν (cid:63) a. This ends the proof.

ν(i)

πu
θA

(53)
ν(i) ∼

Based on Proposition 1, the learned distributed actors/critics
in GE-VDAC are insusceptible to the agents’ permutations.

Therefore, GE-VDAC can improve the generalization and the
learning speed in multi-agent cooperative learning.

2) Convergence Guarantee: We also demonstrate that the
proposed GE-VDAC algorithm can achieve the locally optimal
policy. The convergence of the GE-VDAC algorithm can be
theoretically guaranteed with the following theorem.

Theorem 1. The proposed algorithm can converge to a locally
optimal policy for the Dec-POMDP, i.e.,

lim inf
t

(cid:107)∇θπ Lπ(θπ)(cid:107) = 0, w.p.1.

(55)

Proof. See Appendix B.

12

TABLE II
SIMULATION PARAMETERS

Parameters
Frequency
Absorption coeff.
Bandwidth
Antenna gain
Time slots
Inefﬁciency
Maximum power
Baseband power
RF chain power
Phase shifter power
Ampliﬁer power
RIS element power

Values
f = 0.3 THz
k(f ) = 0.0033 m−1
10 GHz
Υ = 20 dBi
T = 40
ξ = 1/0.38
P max
AP = 5 W
PBB = 0.2 W
PRF = 0.16 W
PPS = 0.03 W
PPA = 0.02 W
PRIS = BR × 0.01 W

NN parameters
GNN layers
Local embedding
MLP neurons
Combining function
MPGNN outputs
1st FC layer
GRU neurons
Last FC layer
Learning rates (κµ,
κπ, and κV)

Values
N = 2
SE = 32
Sψ = SΨ = 48
φu = mean(·)
Z = S(2)
S(1)
Z = 48
(cid:0)Su
(cid:1)
in, SGRU
SGRU = 64
(SGRU, action size)

0.0005

3) Complexity Analysis: The computational complexity
of the proposed GE-VDAC algorithm mainly comes from
MPGNNs and GRUs. For each MPGNN, the local embed-
ding function ψ(·) and the combining function Ψ(·) are
parameterized as two-layer MLPs with Sψ and SΨ neu-
the compu-
rons in each MLP layer, respectively. Thus,
tational complexity of local embedding, aggregation, and
combination at agent i ∈ I u in MPGNN layer n can
(cid:16)
(cid:17)(cid:17)
degu
be respectively written as O
,
i+
(cid:16)
O(cid:0)degu
S(n−1)
+SE
, where
Z
Z
(cid:12)
i± = (cid:12)
the outdegree/indegree degu
(cid:12) indicates the number
of outbound/inbound edges of agent i ∈ I u, SE is the
size of the local embedding e(n)
represents the
is initialized as
size of the output vector at
S(0)
N + dii(cid:48)
du
Z =
. Since all the agents can be calculated
in parallel, the computational complexity of the whole N
n=1 C (n)
MPGNN layers is O
max implies the
maximal complexity of agents in MPGNN layer n, i.e.,

S(n−1)
Z
(cid:17)
+SΨS(n)

ii(cid:48) , and S(n)
Z
layer n that

Sψ +SESψ
(cid:17)

, where C (n)

(cid:1), and O

(cid:16)(cid:80)N

(cid:12)N u
i±

i−SE

SΨ

max

(cid:17)

(cid:16)

(cid:16)

(cid:16)

(cid:17)

E

C (n)

max = max
i∈Iu,
u∈{0,1}

(cid:20)
degu

i+Sψ

(cid:16)

N (n−1)
Z

+ SE

(cid:17)

+ degu

i−SE + SΨ

(cid:16)

S(n−1)
Z

+ SE + S(n)

Z

(cid:17) (cid:21)
.

(56)

On the other hand, since the complexity of GRU per weight
and time step is O(1), its computational complexity depends
on the number of GRU weight parameters [39]. For agent
i ∈ I u, the total parameter number of one GRU cell is
3 (Su
N denotes the
size of the GRU input deﬁned in (41), and SGRU is the number
of neurons for each gate in the GRU cell. Based on the above
analyses, the computational complexity of the proposed GE-
VDAC algorithm can be obtained by

in + SGRU) SGRU, where Su

in = S(N )

Z + du

(cid:32) N
(cid:88)

O

(cid:18)

C (n)

max + 3

S(N )
Z + max
u∈{0,1}

du
N + SGRU

(cid:19)

(cid:33)

SGRU

.

n=1

(57)
In comparison, the computational complexity of the tra-
ditional VDAC algorithm [33] (without information interac-
tion) can be obtained by modifying the GRU input size
in the GE-VDAC algo-
and ignoring the MPGNN part
rithm as O (cid:0)3 (cid:2)SVDAC
(cid:1), where SVDAC
=
(cid:16)
N + (cid:80)
du
max i∈Iu ,
is the maximal size of
u∈{0,1}

(cid:3) SGRU
+ SGRU
(cid:17)
dii(cid:48)
E

i(cid:48)∈N u
i+

in

in

the GRU input at all agents. On the other hand, an ad-
vanced VDAC algorithm with direct
information exchange
among agents, denoted as IE-VDAC, has the complexity
of O (cid:0)3 (cid:2)SIE−VDAC
=
N + (cid:80)
du
max i∈Iu ,
u∈{0,1}

(cid:1), where SIE−VDAC
in
(cid:17)
di(cid:48)i
.
E

(cid:3) SGRU
E + (cid:80)
dii(cid:48)

+ SGRU

i(cid:48)∈N u
i−

i(cid:48)∈N u
i+

in
(cid:16)

V. NUMERICAL RESULTS

In this section, we present numerical results to demonstrate
the effectiveness of the proposed smart reconﬁgurable massive
MIMO-NOMA networks. We consider a network with M = 3
APs uniformly deployed on the ceiling of an 8 × 5 m2 indoor
room. Furthermore, we respectively consider J = {1, 2, 4}
RISs mounted on the walls. When J = 1, RIS is deployed
in the middle of one wall. When J ∈ {2, 4}, RISs are
symmetrically and uniformly spaced on walls, respectively.
Each AP m equips NR = 4 RF chains to serve KS = 4
SE users and KU = K m − KS IoT users. For simplicity,
we assume that the numbers of users associated with each
AP are the same. The minimum rate requirements for SE
users and IoT users are 2 Gbit/s and 0.1 Gbit/s, respectively.
We further assume both SE and IoT users arrive the network
under the Poisson distribution with the density of 10 Gbit/s
and 0.2 Gbit/s, respectively. Moreover, the maximum queue
lengths for SE users and IoT users are set as 25 Gbit/s and
10 Gbit/s, and the violation probability is limited by 0.1.
On the other hand, each RIS equips with L = 20 cost-
effective RIS elements with quantization bit BR = {1, 2}. The
LoS probabilities between AP-device and RIS-device links are
calculated according to the human blockage model in [7].
Moreover, the reﬂection coefﬁcient of NLoS path is given by
λ = ρFρR [19], where ρF =

cos ϕin−

√
√

n2

cos ϕin+

r −sin2 ϕin
r −sin2 ϕin

n2

denotes
(cid:17)

(cid:16) 4πf σs cos ϕin
c

2

the Fresnel reﬂection coefﬁcient, and ρR = e− 1
is the Rayleigh roughness factor. ϕin represents the angle
of incidence and reﬂection, nr = 1.922 + 0.0057j means
the refractive index, and σs = 0.05e-3 denotes the standard
deviation of the surface characterizing the material roughness.
Furthermore, the AWGN power spectral density is σ2 = −174
dBm/Hz. The simulation parameters and the neural network
(NN) settings are summarized in Table II. For GE-VDAC, we
empirically learn N = 2 MPGNN layers with local embedding
size SE = 32 and output size S(1)

Z = S(2)

Z = 48.

We compare the proposed GE-VDAC algorithm with the

following three baselines:

13

(a) Convergence of the test reward.

(a) Energy efﬁciency.

(b) Convergence of the energy efﬁciency.

(b) Reliability of SE users.

Fig. 4. Convergence performance comparisons among different algorithms.

Fig. 5. Energy efﬁciency and reliability performance under different algo-
rithms.

• Central

critic:

centralized-critic
the multi-agent
distributed-actor algorithm, which extends the traditional
multi-agent actor-critic algorithm [29]
to the hybrid
discrete and continuous action space.

• VDAC: the fully distributed VDAC algorithm [33] without

information exchange among agents.

• IE-VDAC: the VDAC algorithm with direct Information

Exchange among neighboring agents.

The convergence performance comparisons among different
algorithms are shown in Fig. 4, where all of the agents
are trained for 150000 time steps, and we set K = 24,
NA = 64, b = 1. We can see that the value-decomposition
based algorithms (VDAC, IE-VDAC, GE-VDAC) outperform
central critic algorithm, since the coordination among agents
is enhanced through difference rewards. The fully distributed
VDAC algorithm requires no information exchange overhead
and takes the least training time, but has lower learning speed
and expected reward than both IE-VDAC and GE-VDAC. With
less information exchange overhead than IE-VDAC, GE-VDAC
can achieve the highest expected reward and learning speed,
and the performance gap increases with J, demonstrating its
ability to improve generalization and enhance agents’ coor-

dination. Moreover, since GE-VDAC utilizes the dimension-
reduced embedded features, it has lower complexity than IE-
VDAC and takes less training time, and the time gap is larger
as J increases.

In Fig. 5, we show the energy efﬁciency and reliabil-
ity performance of the smart reconﬁgurable THz MIMO-
NOMA networks under different associated user numbers K.
Here, we further consider conventional THz massive MIMO-
NOMA without the aid of RISs as benchmarks, which utilizes
equal power allocation under channel-based/QoS-based user
clustering and NOMA decoding. We can see that the CSI-
based MIMO-NOMA scheme has the lowest reliability of
SE users, and the performance gap dramatically grows as
the associated users increase. Without the aid of RISs, the
QoS-based MIMO-NOMA scheme can provide higher relia-
bility than CSI-based MIMO-NOMA scheme, but leads to the
lowest energy efﬁciency. However, the proposed algorithms
can achieve the highest global energy efﬁciency, while guar-
anteeing the reliability of SE users. Even when the number
of IoT users increases, the reliability of SE users can be
guaranteed to be larger than 0.94, which veriﬁes that the
proposed reconﬁgurable THz MIMO-NOMA can provide on-

01000200030004000500060007000800014015016017018019020021022023024025001000200030004000500060007000800051015202530354045501518212427303336510152025303540455015182124273033360.40.450.50.550.60.650.70.750.80.850.90.95114

Fig. 6. The relationship between sum rate and power allocation.

(a) Energy efﬁciency.

demand QoS for heterogeneous users with efﬁcient spectral
utilization.

Fig. 6 and Fig. 7 present

the performance of the pro-
posed networks under different number of RISs NA and RIS
quantization bit b. As shown in Fig. 6, when NA and J
increase, the power consumption increases due to the higher
hardware power dissipation. Meanwhile, the sum rate of users
increases with NA but decreases with J, since the spatial
stream interferences become more severe as J growing. In
Fig. 7(a), the energy efﬁciency declines with NA and J based
on the proposed algorithms due to the higher circuit power
dissipation. Compared with 1-bit RISs, 2-bit RISs result in
higher power dissipation to achieve competitive data rate.
Nevertheless, 2-bit RISs can achieve higher energy efﬁciency
when J = 4 and the number of antennas is large, since
they have higher ﬂexibility to suppress the severe spatial
interference. Furthermore, Fig. 7(b) shows the reliability of
SE users increases with NA, J, and b, which demonstrates the
effectiveness of massive MIMO structure and the cooperative
RISs to avoid blockage.

VI. CONCLUSION

In this work, we propose a novel smart reconﬁgurable
THz MIMO-NOMA framework, which empowers customiz-
able and intelligent indoor communications. We ﬁrst propose
speciﬁc schemes of customized user clustering, NOMA de-
coding, and hybrid beamforming. Thereafter, we formulate a
long-term Dec-POMDP problem under a joint dynamic RIS
element selection, coordinated discrete phase-shift control,
and power allocation strategy, which maximizes the network
energy efﬁciency while ensuring heterogenous data rate and
reliability for on-demanded users. To efﬁciently solve the
intractable highly complex MINLP problem, we further de-
velop a decentralized GE-VDAC based MADRL algorithm.
We theoretically demonstrate that the GE-VDAC algorithm
achieves locally optimal convergence and better generaliza-
tion. Numerical results show that the proposed algorithm can
achieve higher energy efﬁciency and faster learning speed
compared to traditional MADRL methods. Furthermore, we

(b) Reliability of SE users.

Fig. 7. System performance under different numbers of AP antennas.

can also obtain highly customized communications through
efﬁcient resource utilization.

APPENDIX A
PROOF OF LEMMA 1

Considering the deﬁnition of qm

nk and

(cid:16)

[x]+(cid:17)2

≤ x2, we

have

1
2

(qm

nk(t + 1))2 ≤
1
2

(qm

nk(t))2 + C m,q

[qm

1
2
nk + qm

≤

nk(t) − Rm

nk(t) + Am

nk(t)]2

nk(t) (Am

nk(t) − Rm

nk(t)) .

Similarly, considering the deﬁnition of Z m

nk, we have

nk(t)2(cid:1)

1
2
(a)
≤

(cid:0)Y m

nk(t + 1)2 − Y m
1
2

(qm

nk(t + 1))2 + C m,Y

nk + Y m

nk(t)qm

nk(t + 1),

(58)

(59)

where (a) is due to qm,max
nk and qm
(cid:15)m
Substituting (58) into (59) and considering the fact that qm

nk(t) are non-negative.
nk(t+

nk

32404856647280200300400500600700015304560753240485664728051015202530354045505560324048566472800.550.60.650.70.750.80.850.90.951nk(t) − Rm

1) = qm
queue, we can obtain

nk(t) + Am

nk(t) due to the nonempty trafﬁc

(cid:0)Y m

1
2
≤ C m,q

nk(t + 1)2 − Y m
nk + C m,Y

nk − (qm

nk(t)2(cid:1)

nk(t) + Y m

nk(t)) Rm

nk(t) + Bm

nk(t).

(60)

Substituting (58) and (60) into ∆Lm
nk(t)2(cid:3) + 1
qm

nk(t + 1)2 − Y m

(cid:2)Y m

2

nk(t) = 1
2

(cid:2)qm

nk(t + 1)2 −

nk(t)2(cid:3) concludes the proof.

APPENDIX B
PROOF OF THE THEOREM 1

For the sake of expression, we ignore the time slot index
t in the following proof. The joint policy can be written
as the product of the graph embedding sub-policy and the
independent action generation sub-policies:

π (a|s) =

(cid:89)

(cid:89)

u

i

πθG ((cid:101)zu

i |O, D) πu
θA

(au

i |(cid:101)zu

i ) .

(61)

Therefore, the policy gradient in (43) can be rewritten as

i |O, D) πu

θA (au

i |(cid:101)zu

i )(cid:1) A (a, s)

gπ = Eπ

(cid:34)

(cid:34)

(cid:88)

(cid:88)

u

i

= Eπ

∇θπ log

∇θπ log (cid:0)πθG ((cid:101)zu
(cid:32)

(cid:89)

(cid:89)

πθG ((cid:101)zu

i |O, D) πu

θA (au

i |(cid:101)zu
i )

u

i

(61)= Eπ [∇θπ log π (a|s) (Q (a, s) − Vtot (s))] ,

(cid:35)

(cid:35)

(cid:33)

A (a, s)

(62)

where θπ = [{θu

A}] is the joint policy parameter vector.
Denoting dπ(s) as the discounted ergodic state distribution,

G} , {θu

we can obtain [33], [40]

∇θπ log π (a|s) Vtot (s)
(cid:88)
dπ(s)Vtot (s) ∇θπ

(cid:88)

log π (a|s)

a

dπ(s)Vtot (s) ∇θπ 1 = 0.

s
(cid:88)

s

=

=

(63)

Substituting (63) into (62), we have

gπ = Eπ [∇θπ log π (a|s) Q (s, a)] ,

(64)

which leads to a standard policy gradient for single-agent
actor-critic algorithm. In [41], it is proven that an actor-critic
based on such gradient can converge to a local maximal
expected return, which satisﬁes (55). This ends the proof.

REFERENCES

[1] M. Giordani, M. Polese, M. Mezzavilla, S. Rangan, and M. Zorzi,
“Toward 6G networks: use cases and technologies,” IEEE Commun. Mag.,
vol. 58, no. 3, pp. 55-61, Mar. 2020.

[2] L. Yan, C. Han, and J. Yuan, “A dynamic array-of-subarrays architecture
and hybrid precoding algorithms for terahertz wireless communications,”
IEEE J. Sel. Areas Commun., vol. 38, no. 9, pp. 2041-2056, Sept. 2020.
[3] Y. Liu, Z. Qin, M. Elkashlan, Z. Ding, A. Nallanathan, and L. Hanzo,
“Nonorthogonal multiple access for 5G and beyond,” Proc. IEEE, vol.
105, no. 12, pp. 2347-2381, Dec. 2017.

[4] Y. Liu, H. Xing, C. Pan, A. Nallanathan, M. Elkashlan, and L. Hanzo,
“Multiple-antenna-assisted non-orthogonal multiple access,” IEEE Wire-
less Commun., vol. 25, no. 2, pp. 17-23, Apr. 2018.

15

[5] M. Zeng, A. Yadav, O. A. Dobre, G. I. Tsiropoulos, and H. V. Poor,
“Capacity comparison between MIMO-NOMA and MIMO-OMA with
multiple users in a cluster,” IEEE J. Sel. Areas Commun., vol. 35, no. 10,
pp. 2413-2424, Oct. 2017.

[6] H. Zhang, H. Zhang, W. Liu, K. Long, J. Dong, and V. C. M. Leung,
“Energy efﬁcient user clustering, hybrid precoding and power optimiza-
tion in terahertz MIMO-NOMA systems,” IEEE J. Sel. Areas Commun.,
vol. 38, no. 9, pp. 2074-2085, Sept. 2020.

[7] Y. Wu, J. Kokkoniemi, C. Han, and M. Juntti, “Interference and coverage
analysis for terahertz networks with indoor blockage effects and line-of-
sight access point association,” IEEE Trans. Wireless Commun., vol. 20,
no. 3, pp. 1472-1486, Mar. 2021.

[8] S. Gong, X. Lu, D. T. Hoang, D. Niyato, L. Shu, D. I. Kim, and Y. C.
Liang, “Toward smart wireless communications via intelligent reﬂecting
surfaces: A contemporary survey,” IEEE Commun. Surveys Tuts., vol. 22,
no. 4, pp. 2283-2314, 4th Quart. 2020.

[9] M. D. Renzo, A. Zappone, M. Debbah, M. Alouini, C. Yuen, J. Rosny, and
S. Tretyakov, “Smart radio environments empowered by reconﬁgurable
intelligent surfaces: How it works, state of research, and the road ahead,”
IEEE J. Sel. Areas Commun., vol. 38, no. 11, pp. 2450-2525, Nov. 2020.
[10] Y. Liu, X. Liu, X. Mu, T. Hou, J. Xu, M. D. Renzo, and N. Al-Dhahir,
“Reconﬁgurable intelligent surfaces: principles and opportunities,” IEEE
Commun. Surveys Tuts., vol. 23, no. 3, pp. 1546-1577, 3rd Quart. 2021.
[11] C. Chaccour, M. Naderi Soorki, W. Saad, M. Bennis, and P. Popovski,
“Risk-based optimization of virtual reality over terahertz reconﬁgurable
intelligent surfaces,” in Proc. IEEE Int. Conf. Commun. (ICC), Jun. 2020,
pp. 1-6.

[12] Y. Liu, X. Mu, X. Liu, M. D. Renzo, Z. Ding, and R. Schober, “Recon-
ﬁgurable intelligent surface (RIS) aided multi-user networks: Interplay
between NOMA and RIS,” 2020, arXiv:2011.13336. [Online]. Available:
https://arxiv.org/abs/2011.13336.

[13] X. Mu, Y. Liu, L. Guo, J. Lin, and N. Al-Dhahir, “Capacity and optimal
resource allocation for IRS-assisted multi-user communication systems,”
IEEE Trans. on Commun., vol. 69, no. 6, pp. 3771-3786, Jun. 2021.
[14] Y. Li, M. Jiang, Q. Zhang, and J. Qin, “Joint beamforming design in
multi-cluster MISO NOMA intelligent reﬂecting surface-aided downlink
communication networks,” 2019, arXiv:1909.06972. [Online]. Available:
http://arxiv.org/abs/1909.06972.

[15] X. Mu, Y. Liu, L. Guo, J. Lin, and N. Al-Dhahir, “Exploiting intelligent
reﬂecting surfaces in NOMA networks: Joint beamforming optimization,”
IEEE Trans. Wireless Commun., vol. 19, no. 10, pp. 688-6898, Oct. 2020.
[16] X. Liu, Y. Liu, Y. Chen, and H. V. Poor, “RIS enhanced massive non-
orthogonal multiple access networks: Deployment and passive beamform-
ing design,” IEEE J. Sel. Areas Commun., vol. 39, no. 4, pp. 1057-1071,
Apr. 2021.

[17] X. Zhu, Z. Wang, L. Dai, and Q. Wang, “Adaptive hybrid precoding
for multiuser massive MIMO,” IEEE Commun. Lett., vol. 20, no. 4, pp.
776-779, Apr. 2016.

[18] Q. Wu, S. Zhang, B. Zheng, C. You, and R. Zhang, “Intelligent reﬂecting
surface-aided wireless communications: A tutorial,” IEEE Trans. on
Commun., vol. 69, no. 5, pp. 3313-3351, May 2021.

[19] R. Piesiewicz, C. Jansen, D. Mittleman, T. Kleine-Ostmann, M. Koch,
and T. Kurner, “Scattering analysis for the modeling of THz commu-
nication systems,” IEEE Trans. Antennas Propag., vol. 55, no. 11, pp.
3002-3009, Nov. 2007.

[20] J. M. Jornet and I. F. Akyildiz, “Channel modeling and capacity analysis
for electromagnetic wireless nanonetworks in the terahertz band,” IEEE
Trans. Wireless Commun., vol. 10, no. 10, pp. 3211-3221, Oct. 2011.
[21] L. Dai, B. Wang, M. Peng, and S. Chen, “Hybrid precoding-based
millimeter-wave massive MIMO-NOMA with simultaneous wireless in-
formation and power transfer,” IEEE J. Sel. Areas Commun., vol. 37, no.
1, pp. 131-141, Jan. 2019.

[22] S. Samarakoon, M. Bennis, W. Saad, and M. Debbah, “Distributed fed-
erated learning for ultra-reliable low-latency vehicular communications,”
IEEE Trans. Commun., vol. 68, no. 2, pp. 1146-1159, Nov. 2019.
[23] C. Huang, A. Zappone, G. C. Alexandropoulos, M. Debbah, and
C. Yuen, “Reconﬁgurable intelligent surfaces for energy efﬁciency in
wireless communication,” IEEE Trans. Wireless Commun., vol. 18, no.
8, pp. 4157-4170, Aug. 2019.

[24] S. Khairy, P. Balaprakash, L. X. Cai, and Y. Cheng, “Constrained deep
reinforcement learning for energy sustainable multi-UAV based random
access IoT networks with NOMA,” IEEE J. Sel. Areas Commun., vol. 39,
no. 4, pp. 1101-1115, Apr. 2021.

[25] W. Wu, P. Yang, W. Zhang, C. Zhou, and S. Shen, “Accuracy-guaranteed
collaborative DNN inference in industrial IoT via deep reinforcement
learning,” IEEE Trans. Ind. Inform., vol. 17, no. 7, pp. 4988-4998, Jul.
2021.

16

[26] M. J. Neely, “Stochastic network optimization with application to com-
munication and queueing systems,” Synthesis Lectures on Communication
Networks, vol. 3, no. 1, pp. 1-211, 2010.

[27] B. K. Ghosh, “Probability inequalities related to Markov’s theorem,”

Amer. Statist., vol. 56, no. 3, pp. 186-190, Aug. 2002.

[28] T. T. Nguyen, N. D. Nguyen, and S. Nahavandi, “Deep reinforcement
learning for multiagent systems: A review of challenges, solutions, and
applications,” IEEE Trans. Cybern., vol. 50, no. 9, pp. 3826-3839, Sept.
2020.

[29] R. Lowe, Y. Wu, A. Tamar, J. Harb, P. Abbeel, and I. Mordatch, “Multi-
agent actor-critic for mixed cooperative-competitive environments,” Proc.
Adv. Neural Inf. Process. Syst., pp. 6379-6390, 2017.

[30] D. H. Wolpert and K. Tumer, “Optimal payoff functions for members

of collectives,” Adv. Complex Syst., vol. 4, pp. 265-279, 2001.

[31] T. Rashid, M. Samvelyan, C. S. De Witt, G. Farquhar, J. Foerster, and
S. Whiteson, “QMIX: Monotonic value function factorisation for deep
multi-agent reinforcement learning,” 2018, arXiv:1803.11485. [Online].
Available: http://arxiv.org/abs/1803.11485.

[32] K. Son, D. Kim, W. J. Kang, D. E. Hostallero, and Y. Yi, “QTRAN:
Learning to factorize with transformation for cooperative multi-agent
reinforcement learning,” 2019, arXiv:1905.05408. [Online]. Available:
http://arxiv.org/abs/1905.05408.

[33] J. Su, S. Adams, and P. A. Beling, “Value-decomposition multi-agent
actor-critics,” Proc. 35th AAAI Conf. Artif. Intell., pp. 11352-11360, 2021.
[34] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, “How powerful are graph
neural networks?” Proc. Int. Conf. Learn. Represent., May 2019. [Online].
Available: https://openreview.net/forum?id=ryGs6iA5Km.

[35] Y. Shen, Y. Shi, J. Zhang, and K. B. Letaief, “Graph neural networks for
scalable tadio tesource management: Architecture design and theoretical
analysis,” IEEE J. Sel. Areas Commun., vol. 39, no. 1, pp. 101-115, Jan.
2021.

[36] K. Cho, B. Van Merri¨enboer, C. Gulcehre, D. Bahdanau, F. Bougares,
H. Schwenk, and Y. Bengio, “Learning phrase representations us-
ing RNN encoder-decoder for statistical machine translation,” 2014,
arXiv:1406.1078. [Online]. Available: http://arxiv.org/abs/1406.1078.
[37] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, “Empirical evalua-
tion of gated recurrent neural networks on sequence modeling,” 2014,
arXiv:1412.3555. [Online]. Available: http://arxiv.org/abs/1412.3555.
[38] D. Ha, A. Dai, and Q. V. Le, “Hypernetworks,” 2016, arXiv:1609.09106.

[Online]. Available: http://arxiv.org/abs/1609.09106.

[39] J. Xie, J. Fang, C. Liu, and X. Li, “Deep learning-based spectrum sensing
in cognitive radio: A CNN-LSTM approach”, IEEE Commun. Lett., vol.
24, no. 10, pp. 2196-2200, Oct. 2020.

[40] R. S. Sutton, D. A. McAllester, S. P. Singh, and Y. Mansour, “Policy
gradient methods for reinforcement learning with function approxima-
tion,” Advances Neural Inform. Processing Syst., Vol. 99, pp. 1057-1063,
Nov. 2000.

[41] V. R. Konda and J. N. Tsitsiklis, “Actor-critic algorithms,” Advances

Neural Inform. Processing Syst., pp. 1008-1014, 2000.

