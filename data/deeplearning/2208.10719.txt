Lexicase Selection at Scale

Li Ding
University of Massachusetts Amherst
liding@umass.edu

Thomas Helmuth
Hamilton College
thelmuth@hamilton.edu

Ryan Boldi
University of Massachusetts Amherst
rbahlousbold@umass.edu

Lee Spector
Amherst College
University of Massachusetts Amherst
lspector@amherst.edu

2
2
0
2

g
u
A
3
2

]
E
N
.
s
c
[

1
v
9
1
7
0
1
.
8
0
2
2
:
v
i
X
r
a

ABSTRACT
Lexicase selection is a semantic-aware parent selection method,
which assesses individual test cases in a randomly-shuffled data
stream. It has demonstrated success in multiple research areas
including genetic programming, genetic algorithms, and more re-
cently symbolic regression and deep learning. One potential draw-
back of lexicase selection and its variants is that the selection pro-
cedure requires evaluating training cases in a single data stream,
making it difficult to handle tasks where the evaluation is compu-
tationally heavy or the dataset is large-scale, e.g., deep learning. In
this work, we investigate how the weighted shuffle methods can
be employed to improve the efficiency of lexicase selection. We
propose a novel method, fast lexicase selection, which incorporates
lexicase selection and weighted shuffle with partial evaluation. Ex-
periments on both classic genetic programming and deep learning
tasks indicate that the proposed method can significantly reduce
the number of evaluation steps needed for lexicase selection to
select an individual, improving its efficiency while maintaining the
performance.

CCS CONCEPTS
• Mathematics of computing → Genetic programming; • Com-
puting methodologies → Machine learning.

KEYWORDS
genetic programming, lexicase selection, parent selection, deep
learning, image classification.

ACM Reference Format:
Li Ding, Ryan Boldi, Thomas Helmuth, and Lee Spector. 2022. Lexicase
Selection at Scale. In Genetic and Evolutionary Computation Conference
Companion (GECCO ’22 Companion), July 9–13, 2022, Boston, MA, USA.
ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3520304.3534026

1 INTRODUCTION
Genetic programming (GP) is a general methodology that has been
widely embraced to tackle various kinds of problems including

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
GECCO ’22 Companion, July 9–13, 2022, Boston, MA, USA
© 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9268-6/22/07. . . $15.00
https://doi.org/10.1145/3520304.3534026

program synthesis, symbolic regression, statistical modeling, and
machine learning. GP evolves programs by applying operations
such as mutation and parent selection, mimicking the natural evo-
lution processes, to the population of programs. Among many
techniques that have been developed to determine the performance
of individuals in parent selection, lexicase selection [13, 26] and
its variants [9, 12, 13, 21] have been demonstrated to have more
promising and robust performance than others [6, 7, 15] in a number
of applications. The key idea of the lexicase selection is to gradually
eliminate candidates by evaluating the population on each case
in a randomly shuffled sequence of data. This procedure has been
shown to bolster the diversity and generality in populations, which
enhance the performance of evolved programs.

Some recent work also shows that lexicase selection can be ap-
plied in rule-based learning systems [1], symbolic regression [20],
machine learning [18, 19], evolutionary robotics [14, 17], and deep
learning [5], helping enhance model performance and generaliza-
tion. Ding and Spector [5] propose gradient lexicase selection, a
variant of lexicase selection that shows promising results on im-
proving the generalization of deep neural networks (DNNs). Despite
these recent successes, one potential drawback of the lexicase selec-
tion algorithm comes to our attention, especially for problems that
involve computationally-heavy programs and large-scale datasets.
Modern computing hardware, such as GPU clusters, have moved to-
wards single-instruction multiple-data (SIMD) architectures. Since
lexicase selection operates in a sequential single-data-stream fash-
ion, it hardly can be optimized with parallel computing to reduce
its running time. For example, in Ding and Spector [5], each lexi-
case selection process involves running inference of a deep neural
network on at most 50,000 training cases per generation, with a
batch size of just 1.

In this work, we aim to explore ways to speed up lexicase selec-
tion while preserving its core behavior of performing sequential
evaluation of training cases for selection. An essential observation
of the lexicase selection algorithm is that the training cases are
considered in randomly-shuffled ordering, with cases earlier in the
ordering receiving more attention than those later in the ordering.
It is straightforward to presume that if the early training cases have
more selection pressure, the selection process may be terminated
earlier with a reduced number of evaluations on training cases.
With this intuition, we revisit the weighted shuffle methods [29]
that shuffle the training cases in a non-uniform manner for lexicase
selection, with the goal of finding a weighted shuffle that does not
negatively affect problem-solving performance but can improve
the average running time of lexicase selection.

 
 
 
 
 
 
GECCO ’22 Companion, July 9–13, 2022, Boston, MA, USA

Ding, et al.

While Troise and Helmuth [29] did extensive experiments and
comparisons of different shuffling methods, a prominent missing
piece is that they only investigate if weighted shuffling has an effect
on the final performance, but not the algorithm running time. There
were two potential reasons: 1) the computation needs for classic
GP problems are usually small, so the common implementation of
lexicase selection assumes that the population has already been
evaluated by all the training cases, in which case the selection
is performed on the error vectors; 2) the weight assignment for
weighted shuffling is based on those error vectors produced by a
complete evaluation. However, when using lexicase selection for
problems with computationally-heavy evaluation process and/or
large-scale datasets, e.g., deep learning problems, it is obvious to see
that such evaluate-then-select paradigm is no longer appropriate
as it will introduce a lot of redundancy in computation.

Our goal is to reduce the number of evaluations needed for se-
lection, in which case only the evaluations that are necessary for
the selection process will be performed. This also means that only
partial evaluation of the training set will be available for assign-
ing weights to each training case for the weighted shuffling. To
solve the above issues, we propose Fast Lexicase Selection: a new
variant of lexicase selection method using weighted shuffle with
partial evaluation. Our method performs evaluation and selection
simultaneously. It can also assign and update weights for shuffling
training cases based on evaluating only a portion of the training
cases. We also extend the idea of our method to other variants of
lexicase selection, e.g., gradient lexicase selection [5], to target on
problems such as deep learning.

For experiments, we test the proposed algorithm on both the
classic GP problems and the benchmark deep learning problem (im-
age classification), where the latter involves large-scale datasets and
heavy computation. Empirical results show that the proposed algo-
rithm has a significant improvement in efficiency with a reduced
number of evaluations, while maintaining similar performance to
the regular lexicase selection.

2 BACKGROUND AND RELATED WORK
2.1 Preliminaries of Lexicase Selection
Lexicase selection considers performance on individual training
cases as opposed to aggregated fitness or accuracy metrics [13, 26].
This has the benefit of including some semantic information about
the performance of the population to potentially help guide search.
Due to the lack of aggregation, lexicase selection tends to select
specialist individuals that trade being somewhat good at all cases
for being elite on a subset of them [10, 11]. This tends to have bene-
ficial effects on behavioral diversity [9, 22], and success rates when
compared to tournament and fitness-proportionate selection [13].
The most recent work [5] using this selection method proposed an
evolutionary framework, gradient lexicase selection, that combines
stochastic gradient descent and lexicase selection to improve the
generalization of deep neural networks.

For every selection event, the training cases are shuffled into
a random order that will be used to select one parent. Using this
random case ordering, lexicase selection filters down the popu-
lation by iteratively removing all individuals that do not exhibit
exactly the best performance on each case, in the order they are

presented. When a single individual remains, it is returned as the
selected parent. If all the cases have been traversed and there are
still individuals in the population, a random individual from the
remaining group is returned.

One potential issue with lexicase selection and its variants in
general, however, is that the selection process operates in a sequen-
tial single-data-stream fashion. In other words, the algorithm’s
time complexity can not be efficiently reduced by using modern
parallel computing architectures. When the training cases for se-
lection are large scale and the evaluation of each training case is
computationally expensive, lexicase selection may have significant
disadvantages when it comes to computation. In this work, our goal
is to improve the running time of lexicase selection while maintain-
ing its core behavior of looking at each individual case instead of
using aggregated fitness metrics.

It is important to note that in lexicase selection, the cases are
shuffled between selection events, so different cases are given dif-
ferent priority over the course of the selection process. In general,
training cases that show up earlier have more impact on the selec-
tion process, since they are responsible for filtering out the most
individuals from the population. It is likely that cases that come at
the end have little to no effect as the selected individual could have
been returned before these cases are ever seen.

2.2 Improving Selection Efficiency
There is a large historical literature surrounding tweaking selec-
tion methods to improve efficiency in GP. Gathercole and Ross [8]
introduce Dynamic Subset Selection, where subsets of the training
data that are harder are sampled and used for selection in tour-
nament selection. Poli and Langdon [23] ran GP backwards, only
evaluating individuals that would eventually be selected to be part
of a tournament selection pool. More recently, Chitty [2] harnesses
the power of parallel computing in order to speed up tournament
selection. These methods have shown great strengths in increasing
the efficiency of selection methods in GP.

More specifically for lexicase selection, de Melo et al. [3] intro-
duced Batch Tournament Selection (BTS), a hybrid of tournament
and lexicase selection, which attempt to incorporate the idea of
lexicase selection into tournament selection to improve both effi-
ciency and quality of solutions. Aenugu and Spector [1] proposed
Batch Lexicase Selection, which is a variant of lexicase selection
that considers batched data during selection events. However, Ding
and Spector [5] find that batch lexicase selection does not perform
as well as lexicase selection on some large-scale problems, such
as image classification. In this work, our method aims to directly
increase the efficiency of lexicase selection, which can be further
extended to the above hybrid methods.

2.3 Weighted Shuffle
Lexicase selection with weighted shuffle [29] is an attempt to
change the way cases are shuffled every selection event. Instead of
uniform random shuffling, weighted shuffling techniques bias the
resultant ordering of cases based on a given metric. In this work, we
will be considering only the weighted and ranked shuffling methods,
with the Number-of-Zeros (easy first) and Number-of-Nonzeros
(hard first) bias metrics.

Lexicase Selection at Scale

GECCO ’22 Companion, July 9–13, 2022, Boston, MA, USA

Weighted shuffle. Weighted shuffle assigns a weight to each
training case based on the chosen bias metric. When selection re-
quires a shuffled list of cases to be built, cases are chosen iteratively
where cases with higher weights have a higher chance of being
selected. This case shuffling technique could be thought of as a
roulette wheel, where cases with a higher weight have a larger slice
of the roulette wheel. Every time we need to pick a case to add to
the list, we update the case probabilities and re-roll the wheel. This
entire process is repeated for every selection event in a generation,
using the same case weights at the beginning.

Ranked shuffle. Ranked shuffle first ranks the cases based on
the chosen bias metric, and sorts the cases using this ranking. Then,
an upper bound is randomly selected between 1 and the number
of training cases, inclusive. The selected case index is then chosen
randomly from 1 to the upper bound, inclusive. The case at this
selected index is added as the first case in the shuffled case list. This
process is repeated for the remaining cases, building up the shuffled
case ordering. Ranked shuffle is likely to place cases with low rank
first in the final case ordering as these low ranks are likely to be
between 1 and the selected upper bound. This method differs from
Weighted shuffle due to it ignoring the magnitude of differences in
weight between cases.

Bias Metrics. The bias metrics used in the weighted shuffle
selection process inform the shuffling method of how to assign
weights to each training case. Past implementations of weighted
shuffle have had access to how every individual in the population
performed on each training case before selection begins. Therefore,
this information can be utilized in the selection process as follows.
The Number-of-Zeros bias metric counts the number of individuals
that achieve zero error on a given training case. Shuffling using this
metric would result in a bias towards easier cases earlier in the case
ordering as easy cases likely have more individuals achieving per-
fect scores on them. The Number-of-Nonzeros bias metric counts
the number of individuals that do not have zero error on a given
training case. This metric would bias the case ordering towards
placing harder cases earlier in the shuffle. For the applications stud-
ied in this work, we propose a general system to update these case
weights without evaluating every individual on every case (as this
process might be computationally intensive when performing large-
scale evolutionary optimization.

While Troise and Helmuth [29] compared these weighted shuf-
fling methods by referring to their solution rates and behavioral
diversity, an empirical study comparing these methods with respect
to efficiency was not performed.

3 METHOD
In this section, we first introduce a new method, weighted shuf-
fle with partial evaluation, that can assign and update weights of
training cases with a partially-observed performance measure. We
then apply this method to lexicase selection and propose two new
variants of the algorithm, fast lexicase selection and fast gradient
lexicase selection, for which the computation cost may be effectively
reduced by having less training cases required to be evaluated.

Algorithm 1: Fast Lexicase Selection for Parent Selection

Data:

• cases - a sequence of all the data samples to be used in

selection with default ordering

• candidates - the entire population of programs
• 𝑊 - a weight vector for all the cases

Result:

• an individual program to be used as a parent
• an updated weight vector 𝑊

shuffled_cases ← Weighted_Shuffle(cases, 𝑊 )
for case in shuffled_cases do

𝑖 ← the index of 𝑐𝑎𝑠𝑒 in cases
results ← evaluate candidates on case
𝑊 [𝑖] ← Bias_Metric(results)
candidates ← the subset of the current candidates
that have exactly best performance on case
if candidates contains only one single candidate then

return candidate, 𝑊

end

end
candidate ← a randomly selected individual in
candidates
return candidate, 𝑊

3.1 Weighted Shuffle with Partial Evaluation
Our goal is to harness the benefit of weighted shuffle to reduce the
number of evaluations needed to be performed on training cases.
In our case study, and the work performed by [29], the weighted
shuffle method requires all the training cases to be evaluated before
the lexicase selection process, which is not actually reducing the
number of individual program evaluations in practice.

The weighted shuffle method scores each training case based on
some bias metric that summarizes the performance of the popula-
tion on that specific case. In this work, we consider the scenario
that not all the training cases are evaluated during selection at each
generation. We propose a novel method, weighted shuffle with
partial evaluation, to handle such a situation.

We begin by initializing a weight vector 𝑊 = [𝑤1, 𝑤2, · · · , 𝑤𝑛]
as the weights assigned to each of the 𝑛 training cases, with some
pre-defined bounds 𝑤𝑖 ∈ [𝑤𝑚𝑖𝑛, 𝑤𝑚𝑎𝑥 ], 𝑖 = 1, 2, · · · , 𝑛. With a
larger value of 𝑤, the training case is more likely to appear earlier
when shuffled.1 The value of 𝑤𝑚𝑖𝑛 and 𝑤𝑚𝑎𝑥 depends on the bias
metrics one choose to use. In general, we assume that 𝑤𝑚𝑖𝑛 > 0
to ensure that easy cases still have possibility to come early in the
ordering.

Since none of the training cases have been evaluated prior to the
selection event, we propose two options for assigning the initial
weights: 1) Default-Min: let 𝑤1 = 𝑤2 = · · · = 𝑤𝑚𝑖𝑛, such that
the unevaluated cases are default to be least likely to appear early
among all the cases; 2) Default-Max: 𝑤1 = 𝑤2 = · · · = 𝑤𝑚𝑎𝑥 ,
meaning the unevaluated cases are most likely to appear early in
the shuffled queue of training cases.

1The shuffling method used in this work is the standard weighted sampling from the
multinomial probability distribution, as defined by the weights. We use the PyTorch
implementation of the function torch.utils.data.WeightedRandomSampler.

GECCO ’22 Companion, July 9–13, 2022, Boston, MA, USA

Ding, et al.

Algorithm 2: Fast Gradient Lexicase Selection for Opti-
mizing Deep Neural Networks

Data:

• data - the whole training dataset in a default order
• candidates - set of 𝑝 instances of the DNN model
• 𝑊 - a weight vector for all the samples in data

Result:

• an optimized DNN model

// K training epochs
set 𝑤𝑚𝑖𝑛 = 1 and 𝑤𝑚𝑎𝑥 = 𝑝 + 1
initialize 𝑊 with 𝑤𝑚𝑖𝑛 (Default-Min) or 𝑤𝑚𝑎𝑥
(Default-Max)
for 𝑒𝑝𝑜𝑐ℎ = 1 : 𝐾 do

subsets ← 𝑝 equal-size subsets obtained through
random sampling from the entire data without
replacement
apply gradient descent and backpropagation to optimize
each of the 𝑝 candidates on each of the 𝑝 subsets
respectively
shuffled_cases ← Weighted_Shuffle(data, 𝑊 )
parent ← None
for case in shuffled_cases do
𝑖 ← the index of 𝑐𝑎𝑠𝑒 in data
results ← evaluate candidates on case
𝑊 [𝑖] ← Bias_Metric(results)
candidates ← the subset of candidates that have
exactly best performance on case
if candidates contains only one single candidate
then

parent ← candidate break

end

end
if parent is None then

parent ← a randomly selected individual in
candidates

end
candidates ← set of 𝑝 instances of the DNN model
copied with the same parameters as parent

end
return parent

For each generation, we first perform weighted shuffle on the
sequence of training cases based on the current weight vector 𝑊 .
Let 𝑝∗ denote the population size and 𝑝 ∈ [0, 𝑝∗] to be the size of
current population (after potential removal of some offspring by the
ongoing selection event). During the selection process, after each
evaluation step on training case 𝑖, we update its assigned weight 𝑤𝑖
according to the performance of the current population, by using
some bias metrics.

3.2 Fast Lexicase Selection
By introducing the proposed weighted shuffle with partial evalua-
tion method into the algorithm pipeline, we propose two variants of
lexicase selection, Fast Lexicase Selection and Fast Gradient Lexicase
Selection.

Fast Lexicase Selection. We propose a general methodology for
parent selection that combines lexicase selection with weighted
shuffle and online weight updating, named Fast lexicase selection.
The algorithm is outlined in Alg. 1.

The key idea of fast lexicase selection is using weighted shuffle
rather than random shuffle to avoid unnecessary evaluation on
training cases that do not result in effective selection of cases. For
example, if all the candidates succeed on an easy training case, it is
more likely that in the next generation they will again all succeed.
Such a case has no selection pressure on the population, and thus
shall be avoided for better efficiency. Especially for lexicase selec-
tion that operates in a single-data-stream fashion, if training cases
with higher selection pressure can be prioritized in the training se-
quence, the computation cost may be effectively reduced by having
less training cases needed to be evaluated for each generation.

Fast Gradient Lexicase Selection. In this work, our goal is to
reduce the runtime of lexicase selection on large-scale computation
problems. To better illustrate this point, we further extend the idea
of fast lexicase selection to the gradient lexicase selection method,
which is a variant of lexicase selection that focuses on optimizing
deep neural networks. An outline of fast gradient lexicase selection
is shown in Alg. 2.

4 EXPERIMENTS ON GP PROBLEMS
In order to compare the efficiency of the above selection methods in
a well established field, we performed GP runs evolving solutions
to two different program synthesis problems. We introduce a new
measure to evaluate the efficiency of said selection strategies and
also verify that the relative success rate results match those found
by Troise and Helmuth [29]. Outlined below is the experimental
setup and the results from these experiments.

4.1 Experimental Setup

Problems. The two problems chosen for this investigation come
from the first General Program Synthesis Benchmark Suite [12].
This benchmark suite contains programming problems that deal
with a range of data types and programming constructs. The two
problems chosen from this benchmark suite are Mirror Image and
Last Index of Zero. Solution programs to Mirror Image receive two
vectors of integers, and return a Boolean indicating whether the
vectors are the reverse of each other. For Last Index of Zero, solutions
must take as input a vector of integers (one of which is a zero), and
return the index of the last zero in the vector. The datasets we used
consist of input and output cases for these problems, as outlined in
the benchmark suite [12].

PushGP. We use the PushGP system to evolve solutions to the
problems described above. PushGP is a GP system that evolves
programs written in the Push programming language [25, 28]. The
Push programming language is a stack-based language that facil-
itates the use of multiple data types and complex programming
paradigms such as iteration and recursion [27]. We used an imple-
mentation of PushGP, Clojush2, that is written in Clojure. Table 1
outlines the system parameters used for the Mirror Image and Last
Index of Zero problems.

2https://github.com/lspector/clojush

Lexicase Selection at Scale

GECCO ’22 Companion, July 9–13, 2022, Boston, MA, USA

Parameter

runs per problem
population size
maximum generations

Genetic Operator

alteration
uniform mutation
uniform close mutation
uniform mutation followed by alternation

Value

50
1000
300

Probability

0.2
0.2
0.3
0.5

Table 1: PushGP system parameters for the Mirror Image
and Last Index of Zero problems. These parameters were
picked as a rule of thumb to better compare to prior work.

Selection Method

Lexicase
Weighted - Num-Nonzeros
Ranked - Num-Nonzeros
Weighted - Num-Zeros
Ranked - Num-Zeros

Success Rate (/50 Runs)

Mirror Image

Last Index of Zero

43
45
46
48
35

20
11
21
2
5

Table 2: Success Rates of GP runs on the Mirror Image and
Last Index of Zero problems, utilizing a variety of selec-
tion techniques. Underlined are the results that were signif-
icantly worse than lexicase selection. No results were signif-
icantly better than lexicase selection across either problem.

Measures. We propose a new measure, the average number of
evaluations, in attempt to measure the efficiency of the various se-
lection methods discussed above. This metric is a rough measure of
the computational effort required to perform the lexicase selection
procedure to select individuals. Instead of using wall-clock times
like explored in previous selection strategy comparisons [3, 8, 23],
we use a measure that provides a hardware-agnostic efficiency com-
parison. We define an evaluation as the act of either computing
the error for an individual (by evaluating the Push program they
produce) on a specific case, or looking up its error on this case from
a different selection. To calculate the number of evaluations for a
single selection event, we add together the number of individuals
remaining after every case is visited. For example, if there are 10
individuals in the population, and 3 remain after visiting the first
case, and 1 remains (and is selected) after visiting the second case,
then the number of evaluations for this selection event is 10+3 = 13.
This metric represents the number of times (in an isolated selection
event) a new individual would have to be evaluated on a new case
from scratch.

It is important to note that the selections we are performing
in our GP runs are not isolated selection events as we can (and
do) reuse evaluations of an individual on a specific training case
from other selection events in the same generation to help increase
performance. This is because it is sometimes the case in lexicase
selection that one individual is evaluated on the same training
case twice or more in a generation during the selection of different
parents. Furthermore, the PushGP implementation we are using
evaluates all individuals on all training cases at the beginning
of every generation, for use in all selection events. Nevertheless,
we believe that measuring the average number of evaluations is
still a meaningful metric that can be broadly used to compare the
efficiency of selection procedures. For different implementations
of PushGP, or uses of lexicase selection outside of GP like those
described in this paper and beyond, this metric can be used as a
much closer correlate of run time. The lower the average number of
evaluations, the more efficient the selection procedure is likely to
be. This measure can also be thought of as how effective the cases
are at filtering down the population size to more computationally
manageable numbers.

To calculate the number of evaluations for a given generation,
we sum together the number of evaluations performed in every
selection event in that generation. For our GP runs, we average
these values across all of the runs that are still active at this gen-
eration. This means that runs finishing early will not deceptively
decrease the number of comparisons occurring during that gener-
ation. Along with this, we will also measure whether the various
weighted shuffling methods in fast lexicase selection are compa-
rable to lexicase selection in terms of success rate. The number of
successes in the following experiments refers to the number of runs
(out of the 50 total) that successfully evolve a solution with perfect
scores on all the held out training cases.

4.2 Results
Table 2 presents the differences in success rate across these selec-
tion methods. None of the weighted or ranked shuffling methods
performed significantly better than lexicase selection. Also, none
of the hard-first metrics performed significantly worse than lexi-
case selection. These findings align with those found by Troise and
Helmuth [29].

Figures 1 and 2 show how the average number of comparisons
per generation are affected by these different selection methods for
the Mirror Image and Last Index of Zero problems, respectively. It is
clear from both of these figures that ranked shuffle with Number-of-
Nonzeros is consistently performing less evaluations per generation
than any of the other methods.

These results show that there are significant improvements in
efficiency when using a method based on weighted shuffling with
a hard-first metric. We also find that using hard-first shuffling
methods have comparable performance (in terms of success rate)
to randomly shuffled lexicase selection in GP. This result leads
us to believe that using weighted shuffle in other applications of
lexicase selection, especially ones with computationally intensive
evaluations, would potentially reduce the overall computational
cost of lexicase selection, while maintaining the numerous benefits
it provides. In order to verify this claim, we repeat the above ex-
periments in a different, more computationally intensive, domain:
image classification with deep neural networks.

GECCO ’22 Companion, July 9–13, 2022, Boston, MA, USA

Ding, et al.

Figure 1: Average number of evaluations performed in a
given active generation over evolutionary time while solv-
ing the Mirror Image problem. The hard first metrics (those
using the Number-of-Nonzeros bias metric) are shown in
red and the easy first metrics (Number-of-Zeros) are shown
in blue. The weighted shuffling technique is presented as
dotted lines, and the ranked shuffling technique is shown
in solid lines. Lexicase selection is shown in black. Ranked
shuffling using the Number-of-Nonzeros bias metric consis-
tently performs less comparisons per generation than all
other shuffling methods, including lexicase selection (ran-
dom shuffling).

5 EXPERIMENTS ON IMAGE

CLASSIFICATION

In this section, we present the experimental results of testing the
proposed fast gradient lexicase selection method on the image
classification problem, which is a popular problem that has been
extensively studied in computer vision and deep learning literature.
We use a common network architecture, VGG [24], and test our
method on a benchmark dataset, CIFAR-10 [16]. The dataset com-
prises of 32 × 32 pixel real-world RGB images of common objects
(50,000 for training, 10,000 for testing).

5.1 Bias Metrics and Weight Assignment
In this experiment, we consider the same two bias metrics as we did
for the GP problems: Number-of-Zeros (Num-Zeros) and Number-
of-Nonzeros (Num-Nonzeros). For the image classification problem,
the model returns a probability distribution of all the classes for
each input case. So, we take the one with largest probability as the
discrete prediction output. The Num-Zeros metric 𝑛𝑧𝑒𝑟𝑜𝑠 counts the
number of individuals in the current population that achieve zero
error, i.e., make the correct prediction, on the given training case
𝑖. We therefore assign the according weight as 𝑊 [𝑖] = 𝑛𝑧𝑒𝑟𝑜𝑠 + 1,
with +1 to avoid zero weights. This metric can be interpreted as
giving easier cases more weight, so they tend to appear earlier in
the sequence of training cases. Alternatively, the Num-Nonzeros
metric 𝑛𝑛𝑜𝑛𝑧𝑒𝑟𝑜𝑠 counts the number of individuals that achieve
non-zero error, which, in this experiment is referred to making a

Figure 2: Average number of evaluations performed in a
given active generation over evolutionary time while solv-
ing the Last Index of Zeros problem.

wrong prediction. This metric, as opposed to 𝑛𝑧𝑒𝑟𝑜𝑠 , gives more
priority to hard cases.

5.2 Implementation Details
We follow the general experiment setups as described in [4, 5].
The network architecture used in this work is VGG [24]. We use a
population size 𝑝 = 4 for both gradient lexicase selection and fast
gradient lexicase selection. We set the total number of epochs as
200(𝑝 + 1).

5.3 Results
We evaluate the proposed fast gradient lexicase selection method
against the original lexicase selection on the image classification
problem. Analyses on both speed and accuracy are presented as
follows.

Speed. First, we compare the number of evaluations performed
among all the design choices of ways to initialize default weight and
bias metrics. The count of evaluations performed in each generation
can be viewed as the theoretical runtime of lexicase selection, under
the assumption that a single evaluation step, e.g., inference of a
DNN on a single input case, takes significantly more time than
other operations such as comparing values.

The raw evaluation counts per generation is shown in Fig. 3. We
can see that in this problem, most of the evaluations happen in
the last few generations. Fast gradient lexicase selection in general
ends up with fewer generations for evolution, and requires fewer
evaluations to be performed in each generation.

To have a better view of the results, we create another view of
Fig. 3 with the last 50 generations of each method, aligned by the
end. We focus on those later generations because early generations
require many fewer evaluations, and thus does not contribute much
to the total runtime. We also perform a moving average of 20 gener-
ations to smooth the values of y-axis. As shown in Fig. 4, we can see
a clear comparison between the methods. The fast gradient lexicase

Lexicase Selection at Scale

GECCO ’22 Companion, July 9–13, 2022, Boston, MA, USA

Figure 3: Comparing number of evaluations of regular gra-
dient lexicase selection and fast gradient lexicase selection
(with different design choices). The plot skips early gener-
ations because most of those generations only require very
few number of evaluations. We can see that the fast gradient
lexicase selection methods in general requires significantly
fewer evaluations than the regular gradient lexicase selec-
tion, and also requires fewer generations.

selection with Default-Max and Num-Nonzeros requires signifi-
cantly fewer evaluations throughout generations. These results
aligns well with our findings for GP, as described in Sec. 4.2

Accuracy. While the results show that fast gradient lexicase
selection is significantly more efficient than the regular method,
we also need to test whether the reduced number of evaluations
has an effect on the performance on the image classification task.
Table 3 shows quantitative results of model performance. We can
see that the performance of all the methods are similar. To statisti-
cally illustrate this, for each of the fast gradient lexicase selection
methods, we perform the one proportion z-test against the regular
gradient lexicase selection.

Let 𝑝 be the accuracy of tested method (fast gradient lexicase
selection) and 𝑝0 be the hypothesized accuracy of the baseline
method (gradient lexicase selection). For the z-test, we use the
following null hypotheses:

𝐻0 : 𝑝 = 𝑝0

and the left-tailed alternative hypothesis:

𝐻1 : 𝑝 < 𝑝0

If the p-value that corresponds to the test statistic is less than the
significance level, we can reject the null hypothesis. From Table 3,
we can see that if we choose the common significance level 0.05,
none of the methods have a p-value less than 0.05. So, we conclude
that the performance of fast gradient lexicase selection (with any
design choice considered in this work) is not significantly different
from the performance of regular gradient lexicase selection.

Figure 4: Comparing number of evaluations of regular gra-
dient lexicase selection and fast gradient lexicase selection,
using the same data as Fig. 3 but on a different view with
the last 50 generations of each method, aligned by the end.
The y-axis is smoothed by applying a moving average over
20 generations. This plot more clearly shows the compar-
ison among methods, that the fast gradient lexicase selec-
tion with Default-Max and Num-Nonzeros being the most
efficient method.

6 DISCUSSION
When using lexicase selection, some cases have a large impact
on how many individuals are filtered out of the selection pool,
while other cases have little to no impact. Additionally, some cases
are synonymous (or nearly synonymous), in that they test similar
inputs and require very similar behavior of individuals to perform
well on. While one synonymous case may filter the selection pool,
consequent cases may have little effect.

Our primary motivation of using weighted shuffle for lexicase
selection is to bias the shuffle such that cases that have more impact
on the filtering of the selection pool more often occur near the start
of the shuffled list of cases. By doing so, the selection pool size will
shrink more rapidly, requiring fewer evaluations during selection.
Before this work, it was an open question whether certain shuffling
techniques or bias metrics would result in more rapid filtering of
the selection pool, and if so, whether they would also have any
effect on problem-solving performance.

Our results, both using PushGP for program synthesis and deep
neural networks for image classification, indicate that weighted
shuffle does have a positive impact on running time while not
negatively affecting problem-solving performance compared to
uniform shuffle. In particular, methods that weight cases that are
more difficult to answer correctly more heavily (Num-Nonzeros)
used the fewest comparisons or evaluations, and therefore better
running time.

More difficult cases are likely passed by fewer individuals in
the population than easier cases. When putting more emphasis on
these cases by having them biased to occur earlier in the weighted

GECCO ’22 Companion, July 9–13, 2022, Boston, MA, USA

Ding, et al.

Table 3: Image classification results. We report the percent-
age accuracy (acc.) for all the methods. For each of the fast
gradient lexicase selection methods, we also report the p-
value of one proportion z-test against the regular gradient
lexicase selection. A p-value greater than the significance
level (0.05) means there is no significance different between
the two methods in performance.

Method

acc.

p-val

Gradient Lexicase Selection
Fast Lexicase - Nonzeros, Default-Max
Fast Lexicase - Nonzeros, Default-Min
Fast Lexicase - Zeros, Default-Max
Fast Lexicase - Zeros, Default-Min

93.34
93.19
92.99
93.29
93.17

-
0.276
0.085
0.421
0.25

shuffle, they likely remove more individuals from the selection
pool, keeping around the smaller group of individuals who perform
better on them. However, this result is not obvious a priori; it might
have been the case that all individuals perform equally poorly on
some difficult cases, meaning that they apply less filtering power on
the selection pool, and that putting easier cases first (or a uniform
shuffle) would produce faster filtering.

Even though biasing easier cases earlier (Num-Zeros) did not
reduce the number of evaluations of gradient lexicase selection
as much biasing harder cases first, it did nevertheless produce
significantly fewer evaluations than uniform shuffle in our deep
learning experiments. While not intuitive, we suppose that both
easier and harder cases may result in increased filtering pressure
compared to average cases. A possible explanation is that the benefit
of weighted shuffling may actually come from the behavior of
focusing on some set of cases (no matter easy or hard ones), which
leads to faster evolution compared to looking at random cases.

We also find that the initialization of case weights is important
to consider when performing fast gradient lexicase selection. When
using a metric that places higher weight on hard cases, it seems
to be beneficial to initialize all the cases to be maximally difficult
with Default-Max. This might be because there is an initial bias
towards looking at cases that have not been seen yet (as these are
set as being hard) and therefore leads to a better initial exploration
of the case space. As we iteratively assign weights (that might be
less than or equal to the max), the probability we select these seen
cases becomes less than that for an unseen (maximally hard) case.
We find that this explanation is also supported by the easy first
metric. When using a shuffling method that places emphasis on easy
cases, such as Number-of-Zeros, initializing cases to be minimally
difficult would place an initial bias towards looking at cases that
have not been considered yet. This might explain why Default-
Max outperforms Default-Min for the Number-of-Nonzeros bias
metric, and the opposite for the Number-of-Zeros metric in our fast
gradient lexicase selection experiments.

7 CONCLUSION AND FUTURE WORK
In this work, we demonstrate the merit of using weighted shuffle
to increase the efficiency of the selection procedure. In order to

overcome the efficiency disadvantage of lexicase selection for large-
scale evolutionary computation, we propose fast lexicase selection,
which is an attempt to combine weighted shuffle and online weight
updating with lexicase selection. The experimental results on clas-
sic GP problems show that there are significant improvements in
efficiency when using the hard-first weighted shuffling methods,
and the performance is still comparable to regular lexicase selection.
We further extend the idea to the gradient lexicase selection
method, which can better demonstrate the enhanced efficiency
of fast lexicase selection in computationally intensive domains.
We test our method on a large-scale image classification problem.
Experimental results show that fast lexicase selection with different
weighting methods outperforms regular lexicase selection in terms
of efficiency, without hindering accuracy. More specifically, the
hard-first metric with the initialization of cases to be maximally
hard gives the best efficiency. We also find that when using the
fast lexicase selection method, initializing cases as being maximally
hard when using a hard-first metric, or minimally hard when using
an easy-first metric seems to be beneficial in decreasing the number
of evaluations needed for every generation.

Through this work, we highlight the importance of using the
information about how the population performs on training cases
in the selection procedure to identify cases with higher selection
pressure, and thus improve the efficiency of the selection procedure.
This is especially important in large scale evolutionary optimization
problems, where each evaluation step might be costly, or the total
number of evaluations might be large. For future work, we look
forward to the exploration of better ways to extract the incremental
information about the relationship between population and training
data, in order to improve the algorithm in terms of both efficiency
and performance.

ACKNOWLEDGMENTS
This work is supported by the National Science Foundation un-
der Grant No. 1617087. Any opinions, findings, and conclusions
expressed in this publication are those of the authors and do not
necessarily reflect the views of the National Science Foundation.

This work was performed in part using high performance com-
puting equipment obtained from the Collaborative R&D Fund man-
aged by the Massachusetts Technology Collaborative.

The authors would like to thank Edward Pantridge and Anil

Saini for their valuable comments and helpful suggestions.

REFERENCES
[1] Sneha Aenugu and Lee Spector. 2019. Lexicase selection in learning classifier
systems. In Proceedings of the Genetic and Evolutionary Computation Conference.
356–364.

[2] Darren Michael Chitty. 2018. Exploiting Tournament Selection for Efficient
Parallel Genetic Programming. In 18th Annual UK Workshop on Computational In-
telligence, UKCI 2018 (AISC, Vol. 840), Ahmad Lotfi, Hamid Bouchachia, Alexander
Gegov, Caroline Langensiepen, and Martin McGinnity (Eds.). Springer, Notting-
ham Trent University, UK, 41–53. https://doi.org/doi:10.1007/978-3-319-97982-
3_4

[3] Vinícius V. de Melo, Danilo Vasconcellos Vargas, and Wolfgang Banzhaf. 2019.
Batch Tournament Selection for Genetic Programming: The Quality of Lexi-
case, the Speed of Tournament. In Proceedings of the Genetic and Evolutionary
Computation Conference (Prague, Czech Republic) (GECCO ’19). Association for
Computing Machinery, New York, NY, USA, 994–1002. https://doi.org/10.1145/
3321707.3321793

[4] Li Ding and Lee Spector. 2021. Evolving neural selection with adaptive regular-
ization. In Proceedings of the Genetic and Evolutionary Computation Conference

Lexicase Selection at Scale

GECCO ’22 Companion, July 9–13, 2022, Boston, MA, USA

Evolvable Machines 3, 1 (2002), 7–40. https://doi.org/10.1023/A:1014538503543
[29] Sarah Anne Troise and Thomas Helmuth. 2018. Lexicase selection with weighted
shuffle. In Genetic Programming Theory and Practice XV. Springer, 89–104.

Companion. 1717–1725.

[5] Li Ding and Lee Spector. 2022. Optimizing Neural Networks with Gradient
Lexicase Selection. In International Conference on Learning Representations. https:
//openreview.net/forum?id=J_2xNmVcY4

[6] Jonathan E Fieldsend and Alberto Moraglio. 2015. Strength through diversity:
Disaggregation and multi-objectivisation approaches for genetic programming.
In Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Compu-
tation. 1031–1038.

[7] Edgar Galvan-Lopez, Brendan Cody-Kenny, Leonardo Trujillo, and Ahmed Kattan.
2013. Using semantics in the selection mechanism in genetic programming:
a simple method for promoting semantic diversity. In 2013 IEEE Congress on
Evolutionary Computation. IEEE, 2972–2979.

[8] Chris Gathercole and Peter Ross. 1994. Dynamic Training Subset Selection for
Supervised Learning in Genetic Programming. In Parallel Problem Solving from
Nature III (LNCS, Vol. 866), Yuval Davidor, Hans-Paul Schwefel, and Reinhard
Männer (Eds.). Springer-Verlag, Jerusalem, 312–321. https://doi.org/doi:10.1007/
3-540-58484-6_275

[9] Thomas Helmuth, Nicholas Freitag McPhee, and Lee Spector. 2016. Lexicase
selection for program synthesis: a diversity analysis. In Genetic Programming
Theory and Practice XIII. Springer, 151–167.

[10] Thomas Helmuth, Edward Pantridge, and Lee Spector. 2019. Lexicase Selection of
Specialists. In Proceedings of the Genetic and Evolutionary Computation Conference
(Prague, Czech Republic) (GECCO ’19). Association for Computing Machinery,
New York, NY, USA, 1030–1038. https://doi.org/10.1145/3321707.3321875
[11] Thomas Helmuth, Edward Pantridge, and Lee Spector. 2020. On the Importance
of Specialists for Lexicase Selection. Genetic Programming and Evolvable Machines
21, 3 (sep 2020), 349–373. https://doi.org/10.1007/s10710-020-09377-2

[12] Thomas Helmuth and Lee Spector. 2015. General program synthesis benchmark
suite. In Proceedings of the 2015 Annual Conference on Genetic and Evolutionary
Computation. 1039–1046.

[13] Thomas Helmuth, Lee Spector, and James Matheson. 2014. Solving uncom-
promising problems with lexicase selection. IEEE Transactions on Evolutionary
Computation 19, 5 (2014), 630–643.

[14] Joost Huizinga and Jeff Clune. 2018. Evolving multimodal robot behavior via many
stepping stones with the combinatorial multi-objective evolutionary algorithm.
arXiv preprint arXiv:1807.03392 (2018).

[15] Krzysztof Krawiec and Paweł Liskowski. 2015. Automatic derivation of search
objectives for test-based genetic programming. In European Conference on Genetic
Programming. Springer, 53–65.

[16] Alex Krizhevsky, Geoffrey Hinton, et al. 2009. Learning multiple layers of features

from tiny images. Tech. Report (2009).

[17] William La Cava and Jason Moore. 2018. Behavioral search drivers and the role
of elitism in soft robotics. In ALIFE 2018: The 2018 Conference on Artificial Life.
MIT Press, 206–213.

[18] William La Cava and Jason H Moore. 2020. Genetic programming approaches
to learning fair classifiers. In Proceedings of the 2020 Genetic and Evolutionary
Computation Conference. 967–975.

[19] William La Cava and Jason H Moore. 2020. Learning feature spaces for regression
with genetic programming. Genetic Programming and Evolvable Machines 21, 3
(2020), 433–467.

[20] William La Cava, Lee Spector, and Kourosh Danai. 2016. Epsilon-lexicase selec-
tion for regression. In Proceedings of the Genetic and Evolutionary Computation
Conference 2016. 741–748.

[21] Pawel Liskowski, Krzysztof Krawiec, Thomas Helmuth, and Lee Spector. 2015.
Comparison of semantic-aware selection methods in genetic programming. In
Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic
and Evolutionary Computation. 1301–1307.

[22] Jared M Moore and Adam Stanton. 2018. Tiebreaks and Diversity: Isolating Effects
in Lexicase Selection. , 590–597 pages. https://doi.org/10.1162/isal_a_00109
[23] Riccardo Poli and William B. Langdon. 2005. Running Genetic Programming
Backward.
In Genetic Programming Theory and Practice III, Tina Yu, Rick L.
Riolo, and Bill Worzel (Eds.). Genetic Programming, Vol. 9. Springer, Ann Arbor,
Chapter 9, 125–140. https://doi.org/doi:10.1007/0-387-28111-8_9

[24] Karen Simonyan and Andrew Zisserman. 2015. Very Deep Convolutional Net-
works for Large-Scale Image Recognition. In International Conference on Learning
Representations.

[25] Lee Spector. 2001. Autoconstructive Evolution: Push, PushGP, and Pushpop.
In PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION
CONFERENCE, GECCO-2001, 137–146. Morgan Kaufmann Publishers, 137–146.
[26] Lee Spector. 2012. Assessment of problem modality by differential performance
of lexicase selection in genetic programming: a preliminary report. In Proceedings
of the 14th annual conference companion on Genetic and evolutionary computation.
401–408.

[27] Lee Spector, Jon Klein, and Maarten Keijzer. 2005. The Push3 execution stack
and the evolution of control. In In Proc. Gen. and Evol. Comp. Conf. ACM Press,
1689–1696.

[28] Lee Spector and Alan Robinson. 2002. Genetic Programming and Autoconstruc-
tive Evolution with the Push Programming Language. Genetic Programming and

