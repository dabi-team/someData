0
2
0
2

n
a
J

4
2

]
E
S
.
s
c
[

1
v
1
0
2
9
0
.
1
0
0
2
:
v
i
X
r
a

Imperial College London

Department of Computing

Comparison of Syntactic and
Semantic Representations of
Programs in Neural
Embeddings

Author:
Austin P. Wright

Supervisor:
Herbert Wiklicky

Submitted in partial fulﬁllment of the requirements for the MSc degree in
Computing (Machine Learning) of Imperial College London

August 2019

1

 
 
 
 
 
 
Abstract

Neural approaches to program synthesis and understanding have proliferated
widely in the last few years; at the same time graph based neural networks
have become a promising new tool. This work aims to be the ﬁrst empirical
study comparing the eﬀectiveness of natural language models and static anal-
ysis graph based models in representing programs in deep learning systems.
It compares graph convolutional networks using diﬀerent graph representa-
tions in the task of program embedding. It shows that the sparsity of control
ﬂow graphs and the implicit aggregation of graph convolutional networks
cause these models to perform worse than naive models. Therefore it con-
cludes that simply augmenting purely linguistic or statistical models with
formal information does not perform well due to the nuanced nature of for-
mal properties introducing more noise than structure for graph convolutional
networks.

Contents

1 Introduction

3

2 Background

5
6
2.1 Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2.1.1 Machine Learning . . . . . . . . . . . . . . . . . . . . .
2.1.2 Multilayer Perceptron . . . . . . . . . . . . . . . . . .
8
2.1.3 Training . . . . . . . . . . . . . . . . . . . . . . . . . . 10
. . . . . . . . . . . . . 11
2.1.4 Convolutional Neural Networks
2.1.5 Autoencoders . . . . . . . . . . . . . . . . . . . . . . . 13
2.1.6 Natural Language Processing . . . . . . . . . . . . . . 14
2.1.7 Graph Convolutions
. . . . . . . . . . . . . . . . . . . 15
2.1.8 Program Analysis . . . . . . . . . . . . . . . . . . . . . 16
. . . . . . . . . . . . . . . . . . . . . . . . 18
2.2.1 History . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.2.2 Classical Formal Program Synthesis . . . . . . . . . . . 20
2.2.3 Neural Program Synthesis . . . . . . . . . . . . . . . . 27
2.3 Similar Work . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

2.2 Program Synthesis

3 Methods

29
3.1 Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.2 Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
. . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.2.1 Dataset
. . . . . . . . . . . . . . . . . . . 33
3.2.2 Feature Engineering
Static Analysis Step . . . . . . . . . . . . . . . . . . . 35
3.2.3
3.2.4 Other Formats
. . . . . . . . . . . . . . . . . . . . . . 38
3.2.5 Neural Architectures . . . . . . . . . . . . . . . . . . . 39
Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . 42

3.3

1

4 Evaluation and Analysis

5 Conclusions and Future Work

46

50

2

Chapter 1

Introduction

Among the oldest goals in computer science has been the problem of program
synthesis, however it has also been among the most elusive. Currently the
most active area of interest in computer science is deep learning, bringing
groundbreaking new results in many problems that were once very diﬃcult.
It is then natural to ask how we may try to apply deep learning to the age
old problem of program synthesis.

The current state of the art in program synthesis goes one of two ways,
either treating programs entirely like natural text in a single sequence and
thus using existing natural language processing techniques, or eschewing deep
learning altogether and using formal methods entirely and treating programs
as purely mathematical objects. One of the more common and useful math-
ematical representations of programs is in various kinds of static analysis
graphs, such as a control ﬂow graph. While in the past these kinds of repre-
sentations have not been compatible with deep learning, recent developments
in geometric deep learning has opened the door to utilizing these graphs in
neural networks. The hope would be that a graph neural network would be
able to have all of the gains of a deep language system, and integrate the
nuance from mathematical analysis and combine this information for better
performance than either of the two other methods alone.

This work is an empirical study on the eﬀectiveness of static analysis
graph based representations when compared to linguistic representations of
computer programs in deep learning systems. While the project proposal was
initially to study deep learning applications in program synthesis, throughout
this process and review it became clear that while there have been certain
conjectures on the eﬀectiveness of graph based representations, no study has

3

been done to show that these kinds of representations outperform other kinds
of models. Towards answering this question of model eﬀectiveness in general
this work considers the speciﬁc case of program embedding, or encoding.
This problem is a useful formulation, as it is both useful in its own right
within a program synthesis framework like CEGIS (see section 2.2), and can
act as a proxy for other kinds of program understanding tasks by forcing a
model to learn to represent the whole program itself. Therefore this work
will analyze the comparative eﬀectiveness of equivalent models using either
purely language based, or formal graph augmented, program representations.

4

Chapter 2

Background

Due to the breadth of topics discussed in this work, and the variance in
expertise of the relevant audience, no background in the relevant ﬁelds of
Deep Learning or Program Analysis are assumed beyond introductory linear
algebra and statistics. This background chapter aims to provide relevant
context and understanding of these ﬁelds required to follow the later analysis;
however it should not be taken as exhaustive or supremely rigorous.

Section 2.1 on Deep Learning will introduce the general machine learning
problem formulation, and introduce the fundamental pillars of how deep
It will then introduce the specialized convolution
learning models work.
and graph convolution structures that are relevant to the models used in
the work. Finally it will introduce some basic natural language processing
as well as static program analysis techniques in order to understand how
programs ﬁt in to these deep learning models. Generally more emphasis
is given to the deep learning portion of the background since bulk of the
methods actually implemented in the work involve deep learning, where as
the program analysis techniques used are rather simple. Overall this should
provide enough background for an undergraduate to get up to speed and
understand the context and content of the work outlined in the following
chapters.

Section 2.2, while not directly relevant to the speciﬁc methods used, in-
cludes a background and history of Program Synthesis techniques. This is
because this work began as an analysis of these deep learning methods in
program synthesis, and the most relevant future works for these technologies
is in that ﬁeld. Therefore this background while not technically relevant,
aims to inform the past and future context where the technologies analyzed

5

are most relevantly applied.

2.1 Deep Learning

2.1.1 Machine Learning

Since Deep Learning is just a special class of models in within the general
framework of machine learning we are ﬁrst going to introduce the funda-
mentals of machine learning. Machine Learning in eﬀect is the synthesis of
statistical modeling which the reader is likely already familiar, with a focus
on computational tools and tractability. There are general deﬁnitions for
this class of algorithms that learn from data such as the Probably Approxi-
mately Correct (PAC) Learning framework [Valiant, 1984]. In essence there
are three main components in machine learning, the data, the model, and
the training algorithm. The fundamental machine learning task is for a given
task, the model uses the training algorithm on the data in order to improve
its performance on said task. The most basic form of machine learning would
be the case of a linear regression, where given a set of points (the data) ﬁnd
the line (linear model) that best matches the trend in the data. This is done

Figure 2.1: Linear Regression

https://en.wikipedia.org/wiki/File:Linear regression.svg

Source:

using the Ordinary Least Squares procedure (training algorithm) in order to
optimize a certain goal, in this case the square error or total distance of the
model line from the data. Often you hear the term objective function, this
term simply represents the metric by which the model is evaluated, which is
essentially part of the training algorithm (this is because much of the time
the objective function used to train a model might actually be diﬀerent that
whatever ﬁnal evaluation metric is used for a model).

6

There are a huge host of problems and types of data used for the machine
learning problem, since it is so general. However broadly these problems can
be broken into supervised learning and unsupervised learning. In a super-
vised learning problem the data is divided into two parts, the input and the
label. In this situation normally a model is trained to predict a label based
on just an input. Supervised learning includes everything from linear regres-
sion (as the model can be viewed as predicting an output/label y value from
a given/input x value), to machine translation (predicting an output french
translation from an input english sentence). This is generally the most com-
mon form of machine learning and performs the best as evaluation is easy
with provided ground truth in the form of labels. However often times this
labeling for the data is not possible or economical. Unsupervised Learning is
learning from data without labels. This includes clustering algorithms that
try and ﬁnd structure in a dataset, or dimensionality reduction like Principle
Component Analysis that tries to represent a high dimensional dataset with
a small set of features. This framework is generally less eﬃcient in the infor-
mation it can extract from a dataset since there is no ground truth provided
other than the data itself, however this class can be very useful in the many
cases where data labeling is simply not an option.

The main goal of most machine learning models is to perform well not
just on a given dataset, but on new unseen data. This is called generalization
and is a very hard problem. Diﬀerent kinds of models have what is called
capacity which essentially means the amount of ﬂexibility the model has in
how ﬁne tuned it is to small patterns in the data (this generally correlates
with the number of learnable parameters in the model). Very low capacity
can lead to underﬁtting where a model might not be able to learn of of the
most important patterns in the data. However if a dataset has a lot of noise
or the capacity of the model is very high, a model could learn false patterns
that are just results of noise that will not generalize, this is called overﬁtting.
Both of these eﬀects hurt the generalization of a model, and so a challenge
in machine learning is ﬁnding the Goldilocks sweet spot for a given problem
between underﬁtting with too low of a capacity and overﬁtting with too high.
Controlling the model capacity is something that is normally done through
methods like regularization which penalize too high of a model capacity, or
other methods that might depend on the speciﬁc model at hand. We also
attempt to measure this generalization phenomena by a technique called
cross-validation which will use a subset of the actual dataset to train, and
then use the held out portion to test the model on. This information can act

7

Figure 2.2: Over and Under Fitting

Source: https://medium.com/greyatom/what-is-underﬁtting-and-
overﬁtting-in-machine-learning-and-how-to-deal-with-it-6803a989c76

as a proxy for true generalization and is often used to tune hyperparameters
or the parameters that are determined before training (things like the size of
the model or attributes of the training algorithm).

Deep Learning ﬁts within this framework as simply a class of models
called Artiﬁcial Neural Networks. Later sections will go into more depth on
how these speciﬁc models work, but they still have the same challenges as
any other model might for machine learning problems. They have fallen into
favor as they have been shown to perform well for a variety of very hard tasks
(most importantly for this work text and language processing), however it is
important to know that deep learning models are not fundamentally diﬀerent
than a linear regression in the overall class of problems they are tryin to solve
and the general kinds of challenges that may arise.

2.1.2 Multilayer Perceptron

The most basic kind of deep learning model is the Deep Feedforward Network
also called a Multilayer Perceptron. However before understanding what a
multilayer perceptron is, perhaps we should ﬁrst cover what a single percep-
tron is. The perceptron is a computational unit that takes inspiration from
the biology of a neuron, in that it has a set of inputs that are combined
and then has what is called an activation which produces a single output.
This is where the similarities with biology and the brain for the most part

8

end, despite all of the hype around deep neural networks. Perceptrons ac-

Figure 2.3: Perceptron Unit

Source: https://towardsdatascience.com/perceptron-the-artiﬁcial-neuron-
4d8c70d5cc8d

tually date back to the earliest days of artiﬁcial intelligence research in the
sixties[Minsky and Papert, 1988]. Speciﬁcally for a given input vector (cid:126)x a
perceptron will take the dot product of (cid:126)x with a weight vector (cid:126)w, which is of
course equivalent to taking a weighted sum of each individual input. Then
this output is passed into what is called an activation function σ. The output
thus of a perception is y = σ( (cid:126)w · (cid:126)x). In the early days this activation func-
tion was a simple threshold, yielding 1 if the input was large enough and 0
otherwise. Later this was adapted to a continuous version called the sigmoid
function, deﬁned as:

σ(x) =

1
1 + e−x

However today many diﬀerent kinds of activation functions are used in-
cluding the hyperbolic tangent and the rectiﬁed linear unit (ReLU). However
regardless of activation function, a single perceptron is not a particularly
powerful model, it essentially is just a linear model with an added function
but cannot learn nonlinear features. The key step in making perceptrons
useful is stacking them together, this puts the deep into deep learning and
the multilayer in multilayer perceptron. By chaining the outputs of per-
ceptrons as the input to another layer of perceptrons, this forms a “hidden
layer” as the inputs are processed to some intermediate value before ﬁnally
being processed into a ﬁnal output (y = σ2( (cid:126)w2 · σ1( (cid:126)w1 · (cid:126)x)). This architecture
with just a single hidden layer actually forms on its own a universal function

9

Figure 2.4: Multilayer Perceptron

Source: https://www.researchgate.net/ﬁgure/A-hypothetical-example-of-
Multilayer-Perceptron-Network ﬁg4 303875065

approximator, where if there are a suﬃcient number of neurons (perceptrons
within a network are often called neurons) in the hidden layer with a non-
linear activation function and a simple linear activation for the ﬁnal output
layer, any function can be modeled by this deep network (by learning the
correct set of weights). However the model is not limited to just one hidden
layer, and empirically it has been shown that generally adding more layers
and making the model “deeper” is more eﬃcient than adding more neurons
to a given layer and making the model “wider”.

2.1.3 Training

However a model with great ability to model functions in theory does not
matter much if there is no way to train it. That is the situation deep feedfor-
ward networks were in for a long time until back-propagation was developed as
a way to train these networks via gradient descent[Rumelhart et al., 1988].
Unlike linear regression where parameters can be solved exactly in closed
form, the nonlinearities generally make the problem of ﬁnding the correct
weights in deep networks non-convex. What that means is that ﬁnding the
correct weights is a much harder problem and involved incrementally improv-
ing the model as opposed to calculating the solution all at once. This is done
by a method called gradient descent (descent because we are normally trying
to minimize some kind of error or loss). For a dataset we can calculate the

10

loss of the model as a function of the weights of the model, L((cid:126)θ). Then in
order to change the weights and improve the loss the gradient (derivative)
is calculated ∇L((cid:126)θ) to ﬁnd out a ﬁrst order approximation of how much the
loss changes by changing each weight. Then each weight is changed by a
small amount in the direction that would improve the loss. Then the process
is repeated many times until an optimum value of the weights is found. This
process does not necessarily guarantee a global optimum, however empiri-
cally if the process is repeated enough times with diﬀerent random starting
values of the weights it has been found that for the most part these local
optima are good. In practice this gradient is only calculated over a small
subset of the data (Stochastic Gradient Descent) and the size of the update
changes as the training process continues (ADAM), in addition to a number
of other small optimizations, however the core concept remains the same.

(cid:16) d

(cid:16) d

dxz(y(x)) =

This technique then comes down to calculating the gradient of the loss in
terms of each parameter. The process by which those values are calculated
is called back-propagation (although it is really just application of the chain
rule). The chain rule states that we can take the derivative of composed
dx y(x)(cid:1)(cid:17)
. Since the output of each layer
functions
is just a function of the previous layers we can use the chain rule to expand
the ∇L((cid:126)θ) term in terms of the output of previous layers, and propagate
that information backwards through the network without having to recom-
pute partial derivatives. This work will not go into the speciﬁcs of how the
mathematics works, but suﬃce to say that this idea, while simple, paved the
way for training deep networks by gradient descent to be at all tractable.

(cid:17)
dy z(y)

· (cid:0) d

2.1.4 Convolutional Neural Networks

Up to this point the network architecture we have discussed have been fully
connected (or dense) feedforward neural networks. However as discussed
previously there is a cost to having many parameters in the model, in terms
of overﬁtting and in terms of training by calculating too many gradients.
Therefore it is often useful to utilize the structure of the data in order to
reduce the number of parameters used in a network. Many kinds of data
contain a degree of locality, such as images and text containing local features.
The most inﬂuential architecture that takes advantage of this, and also the
advancement that took deep learning from an obscure to a behemoth research
ﬁeld is the convolutional layer[Lecun et al., 1998]. The most common use of

11

Figure 2.5: Convolutional Architecture for AlexNet

convolutional layers is in 2D image processing tasks, and while eventually the
application relevant to this work is 1D convolutions over text, the concepts
are still the same. In a convolutional layer a ﬁlter slides over every position on
the input 2D grid (or more precisely slides over every nth position determined
by the stride parameter), and for each position the ﬁlter is dotted with the
input. Since the dot product is in some sense a similarity metric, the output
of the convolution can be construed as the similarity of the local region of the
input image and the ﬁlter for every position of the input. For example a ﬁlter
that has learned an image like a vertical line, when convolved over the input
will show the locations on the input that seem to contain vertical lines. With
many diﬀerent ﬁlters this can be used to extract many diﬀerent local features
from the input that do not depend on the speciﬁc location of the feature.
These layers are then composed to encode increasingly abstract information,
from lines to shapes to layouts, out of an input, until eventually the hidden
state can be passed to a fully connected layer and processed in the same way
as a feed forward network. The key beneﬁts of this are that small constant
size ﬁlters (independent of input size) have many fewer parameters allowing
the model to use many diﬀerent ﬁlters to be composed to extract a variety
of features. At the same time, the translation independence and locality
of the features makes them more robust. This method also learns how to
extract local features directly from the data, where as previous approaches
had involved using expert knowledge to know what features to look for. This
is what made AlexNet[Krizhevsky et al., 2017] kick start the current deep
learning fervor in 2012 when it vastly outperformed other models in an image
recognition competition.

12

Figure 2.6: MNIST Autoencoder

2.1.5 Autoencoders

The structure of problems this work is concerned with is the class of latent
space models. This is where for a given, probably high dimensional, dataset
we assume that there is some other lower dimensional latent space that con-
tains all or most of the relevant information of the data. For instance in
the popular MNIST dataset, images are large 28x28 or 784 dimensional vec-
tors, however for the most part the only useful information can be encoded
in a few dimensions representing the values as well as perhaps a few style
attributes. An autoencoder is a deep network that learns this latent repre-
sentation. The structure of such a network as shown in ﬁgure 2.6 contains
three main components. First there is the encoder network, that transforms
the data to some low dimension state, the state itself at this intermediate
layer then encodes all of the information about the input that the network
can access, ﬁnally there is the decoder network that takes this state and
then tries to rebuild the original input. These models are unsupervised, as
opposed the more standard supervised learning paradigm, because it does
not require separate labels for each datum, but rather uses simply the raw
data itself as labels in order to learn just re represent the data as opposed to
necessarily predict something. However this low dimensional representation
is very useful in itself.

Latent space models can be incredibly useful because of the so called
“curse of dimensionality”, where very high dimensional data makes many
kinds of analysis or visualization simply impossible. Building a low di-
mensional probabilistic representation of a complex dataset helps in under-
standing some of the abstract structure of very complex high dimensional
data. Among these uses is in the ability to easily sample from a low di-
mensional space, and then generate good high dimensional examples from
the original data space.
It allows for optimization and visualization tech-
niques that are impossible for very high dimensional spaces such as Bayesian
Optimization[Frazier, 2018], or for tractable comparisons between data that

13

encodes more meaningful semantic similarity. In particular since the space of
possible programs has a vary high complexity and dimensionality, if a a low
dimensional latent space can be built, there are a huge variety of potential
uses from program synthesis, to encoding program similarity.

2.1.6 Natural Language Processing

Other than computer vision, the most impactful area of application for deep
learning has been natural language processing.
In tasks such as machine
translation and automated question answering deep learning models have
clearly outperformed other kinds of models.

The ﬁrst thing to notice when trying to process text in a machine learning
system is the conversion from the qualitative to the quantitative. For images
this is easy as pixel values are already in a numeric form, however the input of
text needs processing before being able to be thrown into a neural network.
The naive way to input language into a model is to use a simple one-hot
encoding. One-hot vectors are vectors containing all zeros except for a single
value of one at a speciﬁed index. This index is used to represent a single
qualitative category, in this case a word. So a one hot encoding for text
would just require a comprehensive dictionary, and mapping of every word
to its corresponding index. This quickly becomes an issue as vocabularies in
natural language can be very large, and the sparsity of the information for
inputs makes it very diﬃcult to learn patterns from sequences. Therefore
what is commonly used is a word embedding [Mikolov et al., 2013]. A word
embedding trains a separate network on a large corpora of text to predict
context words, input a word in one-hot encoding and it will output a set of
predicted adjacent words. After training this network it then uses the hidden
layer state vector whose dimension is much less than the one-hot vector, as
a dense representation for each word. This process is similar to a more data
rich contextual work level autoencoder. This style of dense representation
has been shown to include a lot of interesting semantic meaning (for instance
the popular example is taking the vector for the work “king”, subtracting
the vector for “man”, and adding the vector for “woman”, will give a vector
closest to the one representing “queen”).

After encoding words into this vector space, natural language processing
(NLP) becomes a task simply involving one dimensional sequences. While the
most state of the art performant methods use a mechanism called Attention[Vaswani et al., 2017][Radford et al., 2019],
one dimensional convolutional models also perform very well and require

14

Figure 2.7: Graph Convolutional Network

substantially fewer computational resources[Bai et al., 2018].
In this work
we will be modeling programing language using these tools for natural lan-
guage, as both are essentially the same as far as NLP tools are concerned. In
particular this work will make use of one dimensional convolutional networks
for processing the text of programs.

2.1.7 Graph Convolutions

While convolutions have proved to be revolutionary for image processing, and
recurrent networks and attention for language; interest has grown for struc-
tures that can achieve similar results for more complicated structures than
grids or sequences, and generalize to and non-euclidean topologies[Bronstein et al., 2017][Scarselli et al., 2009][Wu et al., 2019].
Because of the added complexity of arbitrary graphs, there is not one sin-
gle method that has converged to be the best generalization of convolution
to graph structures. Generally there are spectral methods that take the
whole graph structure, spatial methods that aggregate local information of
nodes based on neighbors, and others such as Graph Attention Network
[Veliˇckovi´c et al., 2017] that use mechanisms like attention from NLP. For
the purposes of this work we will focus on the graph representation learn-
ing work from [Pan et al., 2018] which uses the Graph Convolution concept
from [Kipf and Welling, 2016]. This model uses a graph laplacian to encode
local graph information into successive layers’ nodes. Precisely we have a
graph input deﬁned as a vector of node values X and an adjacency matrix
A. A graph convolutional layer with learnable weights W on the input graph

15

(cid:104)X, A(cid:105) with activation φ is deﬁned

fφ(X, A | W ) = φ( ˜D−1/2 ˜A ˜D−1/2XW )

Where ˜A = A + I to add node self similarity and ˜Dii = (cid:80)

˜Aij for
the local aggregation and then used as ˜D−1/2 as a symmetric normalization
of the transformation. The layer outputs a vector Z which is the same
shape as X, and successive layers need to utilize the same structure matrix
A. However this technique has still been shown in [Pan et al., 2018] to be
able to eﬀectively encode structural information purely in the hidden state
Z. Essentially what the network learns is how to propagate information in
general between connected nodes.

j

2.1.8 Program Analysis

These graph layers are relevant to the program synthesis domain because
programs unlike natural language have a formal graph structure underlying
them. The degree to which these graph structures help in auto-encoding
programs in fact is the key question of this work.

There are essentially two kinds of graph information found in programs,
syntactic and semantic information. Because programs are written in pro-
gramming languages, which are formal languages with a strict grammar, they
have syntactic information in the form of the abstract syntax tree, which is
now encodable into a graph convolutional network. Then there is semantic
information, which sadly in general is an undecidable property thanks to
Rice’s theorem. However there are still static program analysis techniques
that can unveil useful if not fully complete information. The one covered in
this work is control ﬂow analysis.

Programs do not always simply execute in the linear line by line order
that they are written in, instead features like loops and conditionals cause
the program counter to jump around from line to line in a nonlinear fashion.
While we cannot predict the exact path that the program will take, we can
build up a graph the models all of the possible paths a program can take, an
example of code and its corresponding graph can be seen in ﬁgure 2.8. This
graph contains a lot of the overall semantic structure of the program that is
invisible if purely analyzing the text. This graph is constructed depending
on the language, but in general consists of a set of rules, for each kind of

16

Figure 2.8: Example Program and Control Flow Graph

while ( loopCondition ){

if ( ifCondition ){

} else {

foo ();
bar ();

baz ();

}

}

loopCondition

ifCondition

baz

foo

bar

statement how does it potentially alter the ﬂow of the program. For instance
assignments simply pass the program along from the previous to the next
line which would represent a single directed edge to the next line. While
an if statement can send the program to one of two diﬀerent points, and
so two edges are added from the if statement, one to each of the potential
next statements. In such a graph any kind of loop or recursion introduces
a cycle, and the ﬁnal graph is an overestimate of all the possible traces of a
program. This kind of analysis is strictly local and breaks down when outside
procedures are called or if the program modiﬁes the program counter itself,
however in the context of this work we will ignore such programs and assume
all calls halt and bring the program counter back to to location from which
they are called.

Section 2.1 has introduced the basics of deep learning and the classes
of models that will be used in the rest of this work.
It has also shown
how these models might be applied to programs both as bodies of text and
as formal graphs. The section 2.2 on Program Synthesis aims to give a
historical overview of the ﬁeld of program synthesis and place the potential
applications of this work in a greater context. However it is not strictly

17

required to understand the methods of this work and so is more recommended
than required reading.

2.2 Program Synthesis

2.2.1 History

Ever since the early days of Computer Science, Program Synthesis has been
an ambitious goal. After all in a ﬁeld made to automate processes, among
the ﬁrst tasks a computer scientist might think to automate is the work she
is doing, programming. In the summer of 1957 Alonzo Church was among
the ﬁrst to formalize this problem, in his case as building circuits to ful-
ﬁll certain mathematical properties[Church, 1957]. This mathematical and
logical framework for the problem persisted during the early days of artiﬁ-
cial intelligence research, with automata theory approaches and high level
programming languages among the takes on the general problem.

However with the problem being generally considered part of the ﬁeld
of artiﬁcial intelligence, its advancements also fell victim to the AI win-
ters of the seventies and the nineties. After Churches early problem state-
ment the most inﬂuential framework is that of Mana and Waldinger in
1980[Manna and Waldinger, 1980]. The input for this framework is a ﬁrst
order logical formula meant to specify the properties of a function to synthe-
size. Then the system will construct a proof from the formula using such tools
as resolution and induction to build a function that fulﬁlls the speciﬁcation
as correct by construction. This method could only support very small func-
tions, and the programming language generated is comparatively minimal.
However the logical deductive strategy more or less set the direction of the
ﬁeld towards formal logic as the toolset for speciﬁcation and construction.
Logic is a sensible way to frame program synthesis, as is a compact way to
write exactly the properties one might want in a program, as well as coming
with lots of existing techniques for manipulating formulae in a very sound
manner.

However there is a cost to using logical formulae as the underlying tool
for synthesis, as writing out good logical speciﬁcations can sometimes be just
as if not more diﬃcult than the programming we are trying to automate. So
instead of formal speciﬁcations, another approach is to use examples. This
approach of programming by examples is appealing, as anyone regardless of

18

their ability to code or write formulae can simply do examples of a task that
he might want the computer to automate. A popular way to formulate this
approach was that of Inductive Programming. While Mana and Waldinger
introduced a deductive approach, taking a general principle and deducing
the speciﬁc program that fulﬁlled the principle; inductive programming takes
speciﬁc examples and induces a more general program that is consistent with
those examples.

This inductive programming was developed at much the same time as the
ﬁeld of Machine Learning was being deﬁned, and has a very similar struc-
ture. Leslie Valiant in his 1984 paper for Probably Approximately Correct
(PAC) Learning [Valiant, 1984] lays out the primary framework for machine
learning. This approach introduced computational complexity into the prob-
lem, as well as making it a probabilistic model. This would introduce a
split in artiﬁcial intelligence research, as some continued in the formal logi-
cal line, while statistical machine learning developed separately. These two
branches came out of the second AI winter as squarely diﬀerent ﬁelds. Sta-
tistical learning tended to gravitate towards problems in natural language
as opposed to the formal languages of computer programs, while the ﬁeld
of formal methods came out of the turn of the century with newly eﬃcient
algorithms for boolean satisﬁability and later satisﬁability modulo theories
that allowed ﬁrst order logic formulae to be solved much more eﬃciently. As
a result program synthesis generally remained in the logical paradigm, and in
fact in many departments left AI altogether in favor of these formal methods
and programming languages groups.

Then in 2012 when AlexNet[Krizhevsky et al., 2017] kickstarted the deep
learning revolution in statistical machine learning, the ﬁelds began to come
closer together again. Within these well deﬁned logical frameworks, deep
learning models were able to add a heuristic level improvement in solving
strategies, using Neural Guided Search, NeuroSymbolic Synthesis, or Rein-
forcement Learning[Polozov, 2018]. While formal methods remains as the
best performant of program synthesis techniques, further integration of sta-
tistical learning has opened new and exciting areas to explore. This work ﬁts
in that tradition, of deep learning techniques that can be used to potentially
augment existing logical synthesis systems. The following sections will go
into more depth on the workings of existing program synthesis techniques to
give context for application of the deep learning model.

19

Table 2.1: Common Logical Connectives

Symbol (with variable(s))
¬a
a ∧ b
a ∨ b
a → b

Name
Negation
Conjunction
Disjunction
Implication

Meaning
not a
a and b
a or b
if a then b

2.2.2 Classical Formal Program Synthesis

Formal Logic

The basis for program synthesis engines is formal logic. This section will give
a brief introduction to logic, it will somewhat gloss over a lot of the nuances
and intricacies as this section aims to primarily just establish a working
context and vocabulary for the computational tools discussed later on. By
the end of this section if a reader has no background in logic beforehand, she
should be able to read logical sentences and be able to understand what they
mean at an intuitive level rather than a strict formal level.

Boolean logic is a system for reasoning about the truth or falsity of var-
ious kinds of statements expressed as logical formulae. The basic kind of
statement is called a logical proposition, and thus we will begin with propo-
sitional logic. A proposition has two essential components, variables and
connectives. A variable is any symbol that we determine to represent the
truth value of something, for instance whether it is raining which we can
represent in a formula with the symbol r. Connectives combine variables in
such a way that their combination is a logical statement with its own truth
value. For instance we can use the connective and (written as ∧), to write
the statement, that is is both raining (r) and sunny (s) as r ∧ s. This state-
ment has a truth value itself, depending on the values of the variables that it
includes. The set of connectives that are commonly used are shown in Table
2.1. The ﬁnal notational addition are special symbols that represent some-
thing that is always true ((cid:62)) or always false (⊥). A propositional formula
can thus be deﬁned recursively: A propositional formula is either truth ((cid:62)),
false (⊥), a variable, or a connective of formula(e).

For example we can write out the proposition, that if it is raining (r) then

you are wet w or you have an umbrella (u) as:

r → (w ∨ u)

(2.1)

20

This is a valid statement syntactically as it uses the connective → be-
tween the variable r and proposition (w ∨ u) which is a proposition as it is
the connective ∨between variables w and u. We can express the truth of this
statement, depending on the values of the variables in something called a
truth table. This table lays out the semantic meaning behind the syntactic

Table 2.2: Truth Table for Equation 2.1
r w u r → (w ∨ u)
(cid:62) (cid:62) (cid:62)
(cid:62) (cid:62) ⊥
(cid:62) ⊥ ⊥
⊥ (cid:62) (cid:62)
⊥ (cid:62) ⊥
⊥ ⊥ (cid:62)
⊥ ⊥ ⊥

(cid:62)
(cid:62)
⊥
(cid:62)
(cid:62)
(cid:62)
(cid:62)

logical sentence. We can use this underlying interpretation to show equiva-
lences between statements that have the same truth table. This allows us to

Table 2.3: Equivalent Truth Table for Equation 2.1
r w u ¬(r ∧ ¬w ∧ ¬u)
(cid:62) (cid:62) (cid:62)
(cid:62) (cid:62) ⊥
(cid:62) ⊥ ⊥
⊥ (cid:62) (cid:62)
⊥ (cid:62) ⊥
⊥ ⊥ (cid:62)
⊥ ⊥ ⊥

(cid:62)
(cid:62)
⊥
(cid:62)
(cid:62)
(cid:62)
(cid:62)

reason about formulae symbolically using equivalent substitutions (written
≡) such as (p ∨ ¬p) ≡ (cid:62) or ¬(p ∧ q) ≡ ¬p ∨ ¬q and so forth. The truth ta-
ble primitive deﬁnitions for the common connectives are shown in Table 2.4,
these connectives are then composed to form the full set of possible truth
tables and thus logical sentences (in fact you don’t even need all of these
connectives as they can be deﬁned in terms of each other, but this set is
commonly used as primitive).

21

Table 2.4: Truth Tables for Common Connectives
p
q
(cid:62) (cid:62)
(cid:62) ⊥
⊥ (cid:62)
⊥ ⊥

p
q
(cid:62) (cid:62)
(cid:62) ⊥
⊥ (cid:62)
⊥ ⊥

p
q
(cid:62) (cid:62)
(cid:62) ⊥
⊥ (cid:62)
⊥ ⊥

p → q
(cid:62)
(cid:62)
(cid:62)
⊥

p ∧ q
(cid:62)
⊥
⊥
⊥

p ∨ q
(cid:62)
(cid:62)
(cid:62)
⊥

p ¬p
(cid:62) ⊥
⊥ (cid:62)

First Order Logic

In the propositional logic, every object is logical and has a truth table, be it a
variable or proposition, everything is strictly logical. However often times we
want to be able to reason about nonlogical objects, and for that we introduce
a system called First Order Logic. The key addition in ﬁrst order logic
is the introduction of quantiﬁcation over nonlogical variables and boolean
predicates on these variables. A variable that is nonlogical exists over some
domain of discourse, such as the natural numbers, these variables represent
distinct objects in this domain that may have certain characteristics, but
cannot be interpreted as true or false within the formula. In order to reason
about these kinds of objects we deﬁne predicates, which map these abstract
objects to the boolean space of true and false. For instance we can deﬁne the
odd predicate on the natural numbers, so odd(3) is true, while odd(4) is false.
This predicate is deﬁned for any natural number in our discourse so we can
abstract a speciﬁc number by the symbol x which is a non logical variable,
and then odd(x) becomes a logical predicate depending on the value of x,
and since is has a deﬁned boolean value it can be used in logical formulae.

However in this case x is too abstract to reason about on its own, and so
we bind these non logical variables using quantiﬁers. There are two quanti-
ﬁers in ﬁrst order logic: the existential quantiﬁer, read as “there exists” and
written as ∃, and the universal quantiﬁer read as “for all” and written as ∀.
These quantiﬁers bind non logical variables in formulae, and allow predicates
to have determinate truth value. odd(x) on its own depends of the value of x
which is free since it is an arbitrary variable, however when we say ∃x.odd(x),
or “there exists an x such that odd(x) is true” the truth of the statement is
well deﬁned. We just have to ﬁnd any speciﬁc value for the symbol x within
our discourse, for instance 3, that satisﬁes odd(x) to satisfy the statement;
and since we can the statement is true.

This system is clearly very general and powerful, and unsurprisingly this

22

makes reasoning about arbitrary ﬁrst order sentences a very hard problem.
It is a generalization of propositional logic, as we can interpret the logical
variables as predicates with no arguments. However despite it being diﬃcult
in general, its expressiveness makes it useful in many domains.

Satisﬁability

Now let us return to propositional logic so that we can introduce the basic
problem of satisﬁability, this will form the computational basis for tools that
can then be generalized to harder ﬁrst order logic. So consider again sentence
2.1, r → (w ∨ u). Whether the proposition is true depends on the values of
the variables. We can call a speciﬁc set of assignments to the variables
an interpretation or a model. While the statement in general is deﬁned by
the truth table, a speciﬁc interpretation selects a row from that table, and
thus allows the whole proposition to have a single truth value. So under
the interpretation where the atoms {r, u} are true and {w} is false, the
proposition can be said to be true. We can write this out by saying that the
interpretation satisﬁes the formula, since it sets the variables in such a way
as to make the formula true, this is written in our mathematical notation for
a model M and formula φ as:

M |= φ

If a formula has no models that can satisfy it, we say that the formula
is unsatisﬁable, while if any model satisﬁes it we say the formula is valid.
In general what we want is to be able to write formulae and then have a
computer calculate either a satisfying interpretation or determine it is unsat-
isﬁable. In general we know this is a very hard problem, as to check a formula
exhaustively would require checking every row in its truth table, scaling ex-
ponentially with the number of variables. As it turns out this is perhaps the
most well studied problem in computational complexity, and more or less
deﬁnes the class of N P − Complete. However using lots of very complicated
and fancy algorithms and data structures, this problem of SAT is one that
is in theory very diﬃcult, but in practice somewhat tractable. So despite a
huge explosion in the worst case, much of the time for small to medium sized
problems we can solve the boolean satisﬁability problem.

23

Satisﬁability Modulo Theories

Once SAT became a tractable problem in the nineties, the next step in typ-
ical computer science fashion was to use solvers as a backend for a more
expressive language and class of problems. Instead of reasoning over discrete
boolean variables, we want to be able to reason in ﬁrst order logic about
more complicated objects like numbers or eventually programs. So we deﬁne
theories for these domains in ﬁrst order logic, and then use these theories in
formulae to determine satisﬁability, giving the Satisﬁability Modulo Theories
(SMT) problem. While most solvers do not allow quantiﬁers in the actual
formulae they check, the theories used on the backend will involve ﬁrst order
quantiﬁers. This is because in general ﬁrst order logic is not only NP, but
undecidable, and so the full expressiveness of ﬁrst order logic is limited to
certain decidable subsets deﬁning theories which can be solved computation-
ally.

The most basic theory is that of equality and uninterpreted functions,
this is sometimes called the empty theory and is used as a base for other
theories. As the name suggests it introduces the equality symbol (=)to ﬁrst
order logic which acts over nonlogical values.
It also introduces nonlogi-
cal functions, which are called uninterpreted since they have no deﬁnition
other than how they are used (f (x) does not actually calculate some func-
tion f but rather deﬁnes that there is a function f deﬁned over the values for
x). The only requirement for functions is that they are consistent where if
given the same arguments always have the same output, in formal language
for any function f we have ∀x1, ..., xn∀y1, ..., yn.(x1 = y1, ..., xn = yn) →
f (x1, ..., xn) = f (y1, ..., yn). This theory allows syntactic properties in what-
ever universe if being used to be checked. For instance we can check that two
pieces of code should return the same value. In the code in algorithm 2.1, we
can verify that the two functions return the same value using the theory of
equality and uninterpreted functions. We do this by writing a formula that
asks “Is there such a input where the outputs of the two functions diﬀer?”.
This gives the following formula

(input = x) ∧ (input = a)∧
(y = x) ∧ (z = y) ∧ (f oo = mul(z, z))∧
(bar = mul(a, a))∧

¬(bar = f oo)

The formula makes no assumptions over how the ∗ function works, and

24

Algorithm 2.1 Example QF UF

def foo ( x ):

y = x
z = y
return z * z

def bar ( a ):

return a * a

yet only assuming the consistency of the function and SMT solver will quickly
show that this formula is unsatisﬁable as expected, showing that the functions
return the same value for arbitrary inputs.

There are many theories deﬁned for most SMT systems, like linear integer
arithmetic, linear real arithmetic, bitvectos, and more; these clearly are use-
ful in understanding programs in a logical manner and work in very standard
ways, having deﬁnitions for the relevant sets of numbers and operations on
them {+, −, ∗, ≤, etc...}. One of the more interesting theories that is used is
the theory of arrays or the theory of memories, which is clearly vital if we
aim to be able to verify and eventually synthesize programs. This theory
introduces the nonlogical type of an array, which is essentially a mapping of
indices to values. This involves overloading and allowing the equality opera-
tor to be deﬁned for array types, as well as introducing two more nonlogical
symbols, read and write. These deﬁnitions form the axioms of the theory:

1. Writing a value to an index can then be read from that same index as

that value

∀i. read(write(a, i, v)) = v

2. Writing to a diﬀerent index does not change the value at other indices

∀i, j. ¬(i = j) → (read(write(a, i, v), j) = read(a, j))

3. Arrays with the same values at all indices are equal

(∀i. read(a, i) = read(b, i)) → (a = b)

This in conjunction with a suitable numerical theory generally forms enough
of a background to reason about most programs. Solving formulae using

25

Figure 2.9: CEGIS Framework
Synthesizer

No Solution

Trial Program, P

SAT: Counterexample

Formula, Φ

Veriﬁer

UNSAT: P is a solution

these theories generally requires solvers to build speciﬁc tactics for how to
go about solving them. While some theories are harder, this division of
the more complicated ﬁrst order logic going on the side of standard theories
allows SMT solvers to be well optimized for most use cases. Therefore all one
needs to do in order to verify some property of a program is to encode the
actions of the program, be it memory access or arithmetic, into these logical
theories; at which point the SMT solver can check for desired properties. This
on its own is a very useful application of SMT, however we aim to go one
step further and actually synthesize programs that satisfy a given property.

Syntax Guided Synthesis

Now that we have built the background in order to verify properties in pro-
grams, the next step is synthesizing programs that fulﬁll these properties.
The framework we will introduce is called Counter Example Guided Induc-
tive Synthesis (CEGIS) and in particular the problem within that framework
of Syntax Guided Synthesis (SyGuS).

The SMT backend we have developed can be used to formalize a certain
property of a program via a formula, and to verify that the property holds.
Therefore the problem of synthesis is actually just a search problem, over the
space of possible programs. This general paradigm is expressed in the CEGIS
framework. In this framework the only hole left to ﬁll in is the synthesizer,
which has a lot of freedom in how it works. All the synthesizer now has
to do is try as many diﬀerent programs as it likes, and every time it gets
it wrong it can potentially learn from the generated counterexample. The
SyGuS problem adds one additional component of structure to the system,
by stating the the synthesizer can only generate programs that comply with a
speciﬁc grammar. This helps limit the search space from the whole universe
of text to a small set of syntactically correct programs, so the grammar
ensures syntax while SMT solver ensures semantics.

26

While this framework allows for potentially very advanced synthesiz-
ers, however currently the state of the art, as determined by the SyGuS
competition[Padhi, 2019], utilizes essentially a well optimized enumerative
solver, trying programs from the syntax exhaustively. This goes to show both
how hard the problem is, that there is nothing that obviously outperforms a
somewhat naive solution, and that there is still tremendous potential in de-
veloping synthesis tools. The next section will explore exciting new directions
that are being researched that can ﬁt into this overall CEGIS framework.

2.2.3 Neural Program Synthesis

Historically program synthesis has been squarely framed in terms of formal
logic. However recent development in the CEGIS framework has opened
the door for new kinds of approaches to program synthesis that do not in-
volve logic programming or formal methods, as those components are ab-
stracted away by the framework and computed by a separate SMT solver.
This opens the door deep learning researchers to latch themselves onto yet
another branch o computer science. Here there are two popular ways to inte-
grate modern machine learning into this problem. Either building a model to
learn to synthesize programs all on its own, in a reinforcement learning type
setting, or using the immense amount of data generated from trying diﬀerent
programs to build models that can act as heuristics in other synthesizers. The
latter is currently the most successful, and is in use by Microsoft Research and
others and is a very active area of research[Zhang et al., 2018][Lee et al., 2018][Kalyan et al., 2018][Polosukhin and Skidanov, 2018][Feng et al., 2018].

At the same time work has been done in representing the text of programs
in embedded form more suitable for deep learning techniques[Alon et al., 2018].
This work follows that path and aims to build a semantically meaningful en-
coding of program text in a probabilistic latent space. This could ﬁt into
a CEGIS style solver by being able to search a lower dimensional and more
semantically meaningful space of programs.

2.3 Similar Work

There have been a few similar works in program embeddings and it is a
very new and active area of research. In [Wang et al., 2017] embedding is
assisted by semantic information in the form of live program traces, using
recurrent neural networks to encode information from traces. This diﬀers

27

from the goal of this work which is to encode purely statically, however it
does show the value of semantic information in the eﬀectiveness of program
embedding. More recently in 2019 there have been two interesting works
worth comparing to. The SemCluster [Perry et al., 2019] approach clusters
similar algorithms using a more formal approach, classifying code based on
partitions of the input space of the program into equivalence classes. The
code2vec paper[Alon et al., 2018] is the closest to this work, using a neural
model to encode programs into a vector space, using both text and the ab-
stract syntax tree. The primary diﬀerence is ﬁrst in the neural architecture
being used, code2vec uses an attention mechanism while this work uses con-
volutional and graph convolutional layers. The other primary novelty in this
work is it is the ﬁrst the analyze the eﬀectiveness of these models not just on
syntactic graphs, but on static semantic analysis in the form of control ﬂow
diagrams.

28

Chapter 3

Methods

3.1 Goals

Since the impetus for this study is in program synthesis, the goal must be to
study the potential for these diﬀerent models to generate programs. However
full program synthesis tools in this case would add needless complication to
the more restricted study of this work, therefore the program embedding goal
was chosen. The task of embedding involves encoding as much information
about a program text as possible, and then the ability to regenerate a pro-
gram from that information as correctly as possible. This covers the core
competency of program understanding and generation in the program syn-
thesis world, while reducing the need for more complicated frameworks. The
general pipeline will be like in ﬁgure 3.1, where raw code will be processed
then encoded.

Therefore within the framework of embedding there are a few key eval-
uation metrics to use. Firstly there is the actual loss function comparing a
reconstruction and original, in this case the Cross Entropy. There is also the
simple accuracy, the rate at which the reconstruction correctly generates the
same tokens as the original programs. There are also higher level ways to
evaluate the eﬀectiveness of the embedding, such as procedure name com-
parison. This is where programs are embedded anonymously without names,
and then programs close to each-other in the embedding space are compared
to see if they have real semantic similarity, which would be a good sign of
the model embedding meaningful information about the programs.

These comparisons will be done on a few classes of models. Firstly are

29

Figure 3.1: General Embedding Pipeline
Program Text

Preprocessing to Input Representation

Encoder Network

Latent Representation

Decoder Network

Output Reconstructed Representation

Reconstructed Estimated Program Text

the Graph Convolutional Models.
In these models it is easy to compare
static analysis to a control, this is done by using two equally sized graph
convolutional networks, and training one with a control ﬂow graph as the
adjacency matrix, and comparing with a linear control group that uses an
adjacency matrix representing just a linear ﬂow from token to token which is
the same assumption made in normal linguistic models. This allows a truly
apples to apples comparison as the networks will have identical size and
design, and their only diﬀerence will be the degree to which they have been
provided nontrivial analysis graph representations. The hypothesis going in
to this experiment is that models using analysis graphs should signiﬁcantly
outperform naive models. The success or failure of this hypothesis will then
be tested using the above mentioned metrics.

3.2 Design

3.2.1 Dataset

As with all machine learning problems the single most important component
is the data. For this work two diﬀerent datasets utilizing diﬀerent programing
languages were considered, initially the Natural Program Synthesis Dataset
or NAPS[Zavershynskyi et al., 2018], and then a dataset of Java open source

30

code[Alon et al., 2018], [Allamanis et al., 2016]. While the primary insights
of this work used the Java data, both provided useful information and will
be described here.

The NAPS dataset aims to build a large library of ’competitive program-
ming’ solutions in order to provide a basis of ’algorithmic problems’. Com-
petitive programming competitions, in this case from the website codeforces,
emulate programming problems of the kind found in technical interviews.
This involves traversing diﬀerent data structures, dynamic programming,
and the like. This is appealing for the program synthesis space as programs
are small in the number of lines used, and strictly limited in scope consisting
of a single function designed to do a single task. And while the problems
are simple in one aspect, they also have among the most complex semantics,
involving subtle algorithms and techniques, of other program synthesis data.
This should in principle allow models to learn complex fundamentals of algo-
rithmic thinking while being able to remain a set of unique and distant data,
as opposed to natural code with complex interdependencies that does not
generally lend itself to independent and identically distributed code blocks.
This dataset scrapes solutions from speciﬁc codeforces competitions, lim-
iting itself to easy and intermediate level problems. However these compe-
titions allow a variety of programming languages to be used, so in order to
aggregate as much data into the same form as possible, compatible solutions
are converted into a custom domain speciﬁc language called UAST. This
DSL aims to maintain the overall readability of programs while getting rid of
runtimes or compilation steps. It is converted to from the range of languages
found in the codeforces competitions, Java, C++, C#, Pascal, and Python.
The preprocessing done also aims to anonymize the problem speciﬁcations,
and variables are all names simply in order of appearance (var0, var1, etc...
). NAPS currently consists of 16410 training examples and 485 test examples
as split by the original authors.

The NAPS dataset is a very exciting and ambitious new dataset, which
is why it was initially chosen for this work. However ultimately the diﬃculty
associated with the dataset outweighed the gains for the goals fo this project.
Firstly the dataset is somewhat small by many deep learning standards,
and initial explorations found most well performing models to be susceptible
In addition the actual programs, while not
to overﬁtting because of this.
large, are highly nuanced and complex, making the task of learning their
representations very diﬃcult, which made showing diﬀerences between the
diﬀerent models diﬃcult to ascertain. And so since the essential goal of this

31

Project Name

Table 3.1: Open Source Projects Used
Git SHA Description

cassandra

53e370f

Distributed Database

elasticsearch

485915b REST Search Engine

gradle

8263603 Build System

hadoop-common

42a61a4 Map-Reduce Framework

hibernate-orm

e65a883 Object/Relational Mapping

intellij-community d36c0c1

IDE

liferay-portal

39037ca

Portal Framework

presto

4311896 Distributed SQL query engine

spring-framework

826a00a Application Framework

wildﬂy

c324eaa Application Server

work is not to build a state of the art model per se, but rather to make a
strong empirical comparison between equivalent models, it was determined
that a larger and easier dataset would be more appropriate.

Therefore the dataset that was ultimately used is the Java open source
data from [Alon et al., 2018], [Allamanis et al., 2016]. As described in their
paper [Allamanis et al., 2016], 11 open source Java projects from GitHub
were clones. The most popular projects were found by taking the sum of
the z-scores of the number of watchers and forks of each project, using
GHTorrent[Gousios and Spinellis, 2012]. The top 11 projects were chosen
that contained more than 10MB of source code ﬁles each. These projects
have thousands of forks and stars, being widely known among software de-
velopers. The projects along with short descriptions are shown in Table 3.1.
Using this procedure a mature, large, and diverse corpus of real source code
is selected.

While using open source repositories has the beneﬁt of a very large corpus,
there is the cost of having code that is natural, and therefore being formatted
in larger classes and not the small self contained blocks from NAPS. In order
to make the size of each datum for our analysis tractable we then extracted
methods from the raw Java classes and performed our analysis on these

32

processed methods. The exact procedure used to process the methods will
be further explained in section 3.2.2. Despite the diﬃculty in using purely
natural code, there are also beneﬁts in terms of the applicability of the results
of this work. Since the ultimate goal of program synthesis is in generating
not just code, but ideally readable code or human-like code, the ability of
models to represent code not just in a vacuum but in the real applications
that need to be built is a more valuable trait to evaluate. These natural code
methods are also in general much simpler than the complex puzzles found in
NAPS, which means that the models are better able to represent the code
and allowing for a more eﬀective comparison between models.

3.2.2 Feature Engineering

Since the Java data consists of a large directory structure of raw Java ﬁles,
various preprocessing had to be performed in order to extract the features and
representations used in the experiment. This consists of three main phases,
extracting methods from the large library of Java class ﬁles, generating the
sequence of processed tokens used to represent the text of the methods, and
the static analysis phases generating a control ﬂow graph.

Since we are dealing with raw java code from real programmers, there is
some variance in certain style conventions. In order to reduce variance and
make diﬀerent analysis steps easier, the ﬁrst transformation performed on the
code is some automatic formatting through Eclipse. This ensured consistent
use of brackets in all situations where they are optional and other automatic
formatting steps to increase verbosity.

The next step in building a dataset suitable for deep learning models is
extracting the relevant text sequences. As stated before, only methods are
considered as they represent the best atomic units of computation that we
want to represent. This is done by traversing the tree directory structure of
the diﬀerent repositories in the dataset, and for each class parsing the Java
code. The classes do not need to be fully compiled since we do not really
care about running the code, only extracting the relevant components. The
abstract syntax tree is then traversed, where all method declaration nodes
are processed. Then any method that is abstract, or a constructor are ig-
nored. This is because we are trying to consider actual computational blocks,
and obviously abstract methods contain no code and constructors only have
meaning in so far as they instantiate the class, which for the purposes of this
work are ignored, and so constructors are also not useful. This set of method

33

declarations and bodies is then passed to the next processing step.

After extracting the blocks of text that are set to be analyzed, they need
to be converted into a format that is workable within a machine learning
setting. This involves two procedures, ﬁrst is anonymization, and the sec-
ond is numericalization. First is anonymization. Since point of this work is
for the most part concerned with the structure of computer programs, not
variable naming conventions we want to make identiﬁer names anonymous.
Also, since ultimately the full corpus of processed method text needs to be
contained within a ﬁxed sized vocabulary it would be impractical to include
every variable name individually. This also has the eﬀect where the model
does not know the actual name of each method, and therefore allows for eval-
uation criteria involving name prediction and similarity. Therefore identiﬁers
with unique names are replaced in text with the id token. Relationships be-
tween which id tokens refer to the same variable are then saved as well for
potential use in certain models, however this is not strictly necessary for the
techniques explored in this work. The anonymization however is not univer-
sal. A few common variable names that could be useful to diﬀerentiate are
maintained, such as i and j (see ﬁgure 3.2). In addition to variable names,
method names are important to diﬀerentiate. Recursive invocations of the
method being processed (in addition to the actual name in the declaration)
are replaced with the method token, while invocations of other methods are
replaced with the other method token. This process thus transforms the
speciﬁc text of each method into a general and universal vocabulary and for-
mat, and thus allows for patterns within the actual structure of methods to
be learned.

Next is the numericalization process. Since the neural networks require
numeric inputs as opposed to strings the sequence of tokens must be con-
verted to a string of vectors. The ﬁrst step of this process is to develop a
vocabulary for the whole corpus of the dataset. Once the entire set of used
tokens is known, we can represent each token by a unique number being
the index of their location within that vocabulary. That index will then
be converted to a one-hot encoding vector for each token, this makes each
qualitatively diﬀerent token independent from each other without the false
quantitate information of just the raw index number. In most natural lan-
guage processing tasks this process goes one step further and the one-hot
encoded word representation is converted to a dense embedding, however in
this case there are actually not that many diﬀerent tokens that need to be
considered. Due to the anonymization process, the size of the vocabulary

34

is tractably small and thus the network is able to function using the raw
encoding of the tokens. This helps reduce the variance in our results as there
does not need to be a training process to build deep embeddings for each
token, and the only training process in the whole work will be the direct
comparison of models. The full set of 143 tokens in the vocabulary and their
frequencies is shown in table 3.2. This vocabulary includes the expected syn-
tax of java, as well as some of the specially included identiﬁers (like common
type names and variable names), and some common literals (like single digit
integers) and additional terms for other kinds of literals. This completes the
process so that the raw java is converted into sequences of tensors that can
be inputted into deep learning models. The ﬁnal preprocessing step is the
static analysis, being the primary experimental factor in this work.

It is important to note that this process abstracts away a huge amount
In fact the resultant text does not super closely resemble
of information.
useable code, but rather is closer to a boilerplate pseudocode template. Such
a template could still be useful as an intermediary, where formal methods can
ﬁll in speciﬁc identiﬁers and so forth, and the template only includes high
level structural information. Of course this means that the learning task
being trained for is substantially limited, and as is shown later, this does
have a signiﬁcant eﬀect on the result. However this is in fact a necessary evil
of deep learning or pure statistical language model techniques, since these
models require a ﬁxed vocabulary that would require a certain amount of
abstraction no matter what. Therefore this analysis is still meaningful in
so far as it is comparing where and how deep learning models perform when
augmented with formal data. Yet we must still be cognizant of the limitations
of this kind of formulation.

3.2.3 Static Analysis Step

The ﬁnal and most important step in the processing of the input data for
this work is the static analysis step. In ﬁgure 3.3 the preprocessing pipeline
is shown. In it can be seen the two forms of input data that are generated,
the raw code sequence tensors, and the control ﬂow graph adjacency matrix.
Later models will be compared when given inputs of just the code sequence,
or the code sequence with the control ﬂow matrix and the diﬀerence in per-
formance will be analyzed.

The static analysis being performed here is among the most simple, and
making the fewest assumptions about the code as possible. In this analysis

35

Figure 3.2: Vocabulary Frequencies

36

Figure 3.3: Preprocessing Pipeline
Program Text

Parsing

Anonymization and Numericalization

Static Analysis

Tensor Sequence

Control Flow Graph Adjacency Matrix

it is assumed all procedure calls halt and return back to where they were
invoked. The ﬂow of the program is modeled from token to token in order
to match the dimension of the outputted matrix with the token sequence.
While it is very possible to reduce the size of this graph to more basic blocks
without a loss of generality, the formatting gain in this work is more valuable
as it allows a cleaner way to compare the addition or subtraction of this
information within the context of graph neural networks. In this vein there
are a huge number of optimizations and other choices that could have been
made in building this analysis system that were omitted in order to provide
the most basic, comparable, baseline result possible.

Control ﬂow from token to token is modeled through an adjacency matrix
of size n × n where n is the length of the sequence for a given method. Values
of 1 at location i, j represent that there may exist a ﬂow of the program from
token i to token j. Of course since this is a simple analysis and in general
information about whether such a transition will take place is undecidable
this only provides a loose model of the structure of the method. However
since this analysis never uses this graph in any mathematical modeling, but
rather tries to learn patterns statistically from how diﬀerent programs are
structured this is not an issue.

For this analysis there are 7 special tokens which alter the ﬂow from token
to token, if, else, do, while, f or, return, and method. All other tokens are
assumed to simply pass control linearly along to the next token. These other
special tokens however edit the control ﬂow graph (speciﬁc implementation
details for how the sequence is actually processed are in section 3.3). When
encountering an if token there are two edges added. The graph will continue
linearly through the conditional statement, however once reaching the actual
enclosed code block in brackets there are two edges, one continuing ﬂow into

37

the block and one skipping the block entirely and connecting the two brackets
in the adjacency matrix. The else tokens work in much the same way, without
the conditional statement (else if statements are therefore just modeled as
equivalent to if statements). Clearly this is an over-approximation of real
possible paths, since for instance in a simple if...else... combination the graph
makes it possible to traverse without entering either block. However for the
reasons explained earlier, this is not so much of a problem in representing
the overall structure of the method in a way to be learned statistically as
opposed to formally, given the inherent restrictions of static analysis.

The looping tokens of do, while, and f or all act essentially the same in
this analysis. After the condition (at the begging of the loop for while and
f or and at the end of the loop for do) two edges are added to the graph, one
representing continuing on with the rest of the program and one connecting
back to the beginning of the loop, introducing a cycle into the control ﬂow
graph. The other looping mechanism considered in the analysis step is simple
recursion. When encountering the method token, which represents the name
of the current method, an edge is added from the end of the invocation to
the beginning of the sequence. An edge is also added continuing on linearly
with the program. This therefore implies that the recursion is not inﬁnite
and that eventually the call will terminate.

The ﬁnal special token is the return token. When encountering this
token, the ﬂow graph will continue processing up until the next semicolon
for the end of the full return statement, (this allows things like recursive calls
within a return statement), and then add an edge going straight to the end
of the method, and not add any other possible ﬂows.

3.2.4 Other Formats

There are many diﬀerent forms of static analysis that could result in other
interesting graphs for this kind of experiment. This section will discuss some
of those alternatives and why they were not selected.

The most obvious structure that was omitted from this work is the ab-
stract syntax tree. The syntactic information of the AST also ﬁts nicely
within a graph structure, is easy to parse out, seems to be very representative
of the overall code structure, and is used in other works on program embed-
ding (albeit in very diﬀerent ways). There are two main reasons that the AST
was not part of the comparisons in this work: non-matching structure and
redundant information. When parsing a method, the abstract syntax tree

38

will contain nodes not just from the terminal tokens, but also representing
diﬀerent abstract nodes from non-terminals in the grammar. This causes the
structure of the AST graph to not match the raw code sequence. This means
that the technique in this work of Graph Convolutional networks over the
code sequence, with varying adjacency matrices could not work as the resul-
tant graph and matrix for the AST would not ’ﬁt’ for analyzing the raw code.
This would mean for the comparisons in the work either some information
about the size of the AST graph would be available for the control models, or
else the comparison would not be using equivalent data. This complication
did not appear to be worthwhile for this work, as the only information gained
form the AST is syntactic, lacking the semantic analysis information that is
the heart of this comparison. This is to say that the information from the
AST is redundant from what the model could learn just from the raw text.
The other kind of alternative is diﬀerent kinds fo static analysis. Beyond
a control ﬂow graph there are other kinds of graphs that could be gener-
ated statically from source code, from liveness analysis to last-write analysis.
However almost all of these analyses are actually predicated on control ﬂow
information, and control ﬂow information better portrays the large scale
structure of the program. Therefore if control ﬂow provides the best ﬁrst
order approximation of the program among static analysis techniques, and
is required for more advanced analyses, then for the purposes of having the
most clear baseline comparison it is the obvious choice for this work. Other
frameworks may be extended as future work, however for an initial explo-
ration analyzing the eﬀectiveness of this class of techniques, it is better to be
more limited in scope.

3.2.5 Neural Architectures

After the data has been processed to a form acceptable for deep learning mod-
els, these models can be trained. The primary comparison of this work utilizes
the Graph Convolutional Network architecture from [Kipf and Welling, 2016]
which was explained generally in section 2.1.7.

The processed data will be used to train a Graph Convolutional Autoen-
coder. This requires two inputs, the code sequence and adjacency matrix.
The model then encodes these inputs into a smaller dimensional latent space,
and then decodes that space back to produce an output sequence. Because
it is an autoencoder, this output sequence is set to be the same as the input
sequence, thereby measuring how well the latent space can represent and

39

reconstruct the program text. This work compares completely equivalently
speciﬁed Graph Convolutional Autoencoders, with the only diﬀerence being
the adjacency matrix that they are given during training. Figure 3.4 show-
cases the pipeline on how the diﬀerent models are trained. There are three

Figure 3.4: Model Comparison

Program Text

Parsing

Anonymization and Numericalization

Static Analysis

Tensor Sequence

Control Flow Graph Adjacency Matrix

Linear Flow Adjacency Matrix

Identidy Adjacency Matrix

Naive Graph Model

Linear Graph Model

Sequence Graph Model

Tensor Sequence (Reconstruction)

Program Text (Reconstruction)

diﬀerent situations this work will compare within the Graph Convolutional
framework. Those are using the Control Flow or Sequence graph input, using
a linear graph input, and a naive input.

The sequence graph works as described earlier, representing the sequence/ﬂow

of the program from token to token. The linear graph input makes the lin-
guistic assumption of a simple linear sequence of tokens, this is to say the
adjacency matrix given to the model consists just of nodes pointing from each
token to the next in a linear fashion. Finally the naive baseline provides no
graph information whatsoever to the model (which in eﬀect inputs the iden-
tity matrix due to the workings graph convolution [Kipf and Welling, 2016])
which essentially reduces the problem to a very simple token encoding prob-
lem. Therefore using identical models, these three pipelines can test how
useful the additional contextual information provided by the graphs are. The
initial hypothesis being that the sequence graph will perform better than the
linear which will perform better than the naive. This hypothesis will then be

40

Figure 3.5: Example Program and Diﬀerent Graph Inputs

Example Program

Sequence Graph

while ( loopCondition ){

if ( ifCondition ){

} else {

foo ();
bar ();

baz ();

}

}

loopCondition

ifCondition

baz

foo

bar

loopCondition

ifCondition

baz

Linear Graph

loopCondition

foo

bar

ifCondition

baz

foo

bar

Naive Graph

41

tested by training the models through the described pipeline and measuring
and comparing the performance diﬀerence.

3.3

Implementation

This section will now provide a more detailed explanation of the implemen-
tation of the design set above, in addition the full source code can be found
at https://gitlab.doc.ic.ac.uk/aw2318/msc-individual-project/ and is also in-
cluded alongside this report in the project submission. Python was chosen as
the standard environment for deep learning research, and PyTorch was cho-
sen as the deep learning framework. PyTorch was chosen over other frame-
works like Tensorﬂow due to readability, consistency with Imperial College
coursework practice, and available open source implementations. The most
valuable of these reasons is the open source implementations. The Graph
Convolutional Network paper has made their code open source and available
on Github (https://github.com/tkipf/pygcn). By using this code as the basic
units for the Graph Convolutional Autoencoders this work is able to ensure
greater reproducibility, and avoid potential bugs. Algorithm 3.1 shows the
speciﬁc code deﬁning the GraphConvolution layer which is essentially un-
changed from the original paper. Algorithm 3.2 shows the code for the full
autoencoder.

The model expects input data x and adj, each being torch tensors, with
shapes of n × v and n × n respectively where nis the length of the given code
sequence, and v is the size of the vocabulary. This represents the sequence of
one-hot representations of the code, and the adjacency matrix for the graph.
Then depending on the depth parameter, this input is passed through a
number of GraphConvolution layers, where the hidden states have shape
n × h, where h is the hidden size parameter, this represents the hidden state
value for each node. After passing through the encoding layers, the latent
value is generated by passing through a sigmoid activation and producing a
latent variable sequence of size n × l representing the code sequence. Note
through all of these Graph Convolution layers, the same adjacency matrix
is used unchanged, which is the same strategy used in the original work for
deep Graph Convolutional Networks. Then a symmetric process is used in
decoding the latent variable to a reconstructed code sequence tensor. As can
be seen clearly, the model actually is independent of the size of the sequence,
relying on the graph properties to propagate information. This is a beneﬁt

42

Algorithm 3.1 Graph Convolutional Layer

1 class GraphConvolution ( Module ) :
2
3

def __init__ ( self , in_features , out_features ,

bias = True ) :

4
5
6
7

8
9

10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30

super ( GraphConvolution , self ) . __init__ ()
self . in_features = in_features
self . out_features = out_features
self . weight = Parameter ( torch . FloatTensor (

in_features , out_features ) )

if bias :

self . bias = Parameter ( torch . FloatTensor (

out_features ) )

else :

self . register_parameter ( ’ bias ’ , None )

self . reset_parameters ()

def reset_parameters ( self ) :

stdv = 1. / math . sqrt ( self . weight . size (1) )
self . weight . data . uniform_ ( - stdv , stdv )
if self . bias is not None :

self . bias . data . uniform_ ( - stdv , stdv )

def forward ( self , input , adj ) :

support = torch . mm ( input , self . weight )
output = torch . mm ( adj , support )
if self . bias is not None :

return output + self . bias

else :

return output

def __repr__ ( self ) :

return self . __class__ . __name__ + ’(cid:32) ( ’ \

+ str ( self . in_features ) + ’(cid:32) ->(cid:32) ’ \
+ str ( self . out_features ) + ’) ’

43

Algorithm 3.2 Graph Convolutional Autoencoder

1 class GCAE ( nn . Module ) :
2

def __init__ ( self , nfeat , nhid , nlatent , depth

=10) :

3
4
5
6
7

8

9

10

11

12

13
14
15
16
17
18

19
20
21
22
23
24
25
26
27
28
29
30
31

super ( GCAE , self ) . __init__ ()
self . nfeat = nfeat
self . nhid = nhid
self . nlatent = nlatent
self . encoder_gc_init = GraphConvolution (

nfeat , nhid , bias = False )

self . encoder_gc = [ GraphConvolution ( nhid ,

nhid , bias = False ) for _ in range ( depth ) ]

self . encoder_gc_final = GraphConvolution (

nhid , nlatent , bias = False )

self . decoder_gc_init = GraphConvolution (

nlatent , nhid , bias = False )

self . decoder_gc = [ GraphConvolution ( nhid ,

nhid , bias = False ) for _ in range ( depth ) ]

self . decoder_gc_final = GraphConvolution (

nhid , nfeat , bias = False )

def encode ( self , x , adj ) :

x = F . relu ( self . encoder_gc_init (x , adj ) )
for gc in self . encoder_gc :
x = F . relu ( gc (x , adj ) )

z = torch . sigmoid ( self . encoder_gc_final (x ,

adj ) )
return z

def decode ( self , z , adj ) :

x = F . relu ( self . decoder_gc_init (z , adj ) )
for gc in self . decoder_gc :
x = F . relu ( gc (x , adj ) )

x = F . relu ( self . decoder_gc_final (x , adj ) )
return x

def forward ( self , x , adj ) :

z = self . encode (x , adj )
recon = self . decode (z , adj )
return recon

44

meaning there does not need to be any padding and the same network can
be trained directly on the various sized methods in the dataset. However
because of this that means the latent space is also dependently sized, as
opposed to a more standard ﬁxed vector. This will mean that the actual
latent dimension for this experiment to be meaningful will have to be very
small, in order to suﬃciently compress the original sequence and make the
latent representation meaningful and useful.

For the experiment, models were trained with the same procedure and
with the same hyperparameters, varying only the adjacency matrix. A hidden
size of 32, zero additional depth layers, and a latent size of 4 were chosen,
which while small by many deep learning standards were in line with he size
of the dataset and compute resources available, and helped reduce model
size and variance. In particular the latent size of 4 allows for visualization
of program encodings, which is among the goals of the work. The training
procedure utilized a Cross Entropy Loss objective function, which is common
in autoencoders and in this case also frames the autoencoder as a form of
classiﬁcation, classifying the token value for each position. The models were
also regularized using l2 regularization with a value of 10−5, and trained using
Adam optimization[Kingma and Ba, 2014] with a learning rate of 10−3. Each
of the three scenarios of adjacency matrix were trained over the dataset of
13000 methods over 5 epochs. These are very small models by deep learning
standards. This is partially due to time and computational restrictions but
also due to the heavily abstracted and simpliﬁed nature of the task. And so
while it may be possible to achieve more interesting results in future works
using larger networks on a less abstracted problem, this simpliﬁed problem is
still able to show a few key results in the nature of how graph convolutional
networks are able to encode programs and exposes certain limitations even
given the small scale implementation.

45

Chapter 4

Evaluation and Analysis

After running the training procedure described above, Figure 4.1 shows the
training curves for all three models showing both the training loss and accu-
racy (as measured as percent of tokens correctly reconstructed). Table 4.1
shows the same metrics on unseen test data. Table 4.2 shows the resultant re-
constructed text of the diﬀerent models for an unseen test method. As these
results show, performance is substantially worse than expected, and in fact
shows a trend precisely opposite to what is expected. The hypothesis pre-
dicted that the sequence graph result would outperform linear which would
outperform naive graphs. In fact the naive graph vastly outperformed the
other models, and there was little diﬀerence between the sequence and linear
graph models. Therefore this work is forced to reject the initial hypothesis
and come to some explanation of the results. And in the spirit of science, a
negative result is as good as a positive result. The rest of this section will
aim to analyze these results, and understand what exactly happened.

One key component that becomes clear upon analysis is the essential

Table 4.1: Test Metrics and Standard Deviations

Mean Loss

σ

Mean Accuracy

σ

Sequence Graph

0.87364

Linear Graph

0.92246

Naive Graph

0.07852

0.743

0.788

0.146

83.0%

83.5%

98.5%

15.0%

14.8%

2.9%

46

Figure 4.1: Training Curves

Table 4.2: Example Reconstructions

Original Code

method ( int n ) { int id = 1 ; for ( int i = 2 ; i <= n ; i ++ ) { id *= i ; } return id ; }

Sequence Graph method ( id id ) { ; id = ; } } id id , id return return id id id ; id id ) { ) ( { ; } return id ; }

Linear Graph

Naive Graph

method ( id id ) { ; ) ) ) ; id ( id id id ) ) ) ) ) ; id ) id id id id id ; } return id ; }

method ( int :: ) { int id = :: ; for ( int i = :: ; i :: :: ; i ++ ) { id :: i ; } return id ; }

47

similarity between the linear and sequence graph models. When looking
closely at most of the natural code in the dataset it can be seen that the vast
majority of methods are actually just simple imperative executions of small
chunks of code. This makes sense within the object oriented paradigm of Java
where each method aims to do one very limited function. What this means
then is that this speciﬁc kind of static analysis does not actually induce a
suﬃciently large diﬀerence for the vast majority of programs such that these
networks can learn the diﬀerence within a reasonable amount of time over
the size of the data collected. In short, one of the takeaways is that the vast
majority of natural methods do not have very complicated control ﬂows and
therefore models relying on information from control ﬂow graphs for small
segments of object oriented code (which is the vast majority of how real code
is structured) have strong limitations.

Furthermore looking at example reconstructions such as in table 4.2, an-
other pattern becomes clear. The kinds of predictions the poorly performing
models are making are mostly in ’hedging their bets’ and guessing many
common terms in a row to get at least some tokens correct. Part of this can
be attributed to the way this test was conducted, parsing more ﬁnely into
individual tokens more heavily weights much of the minutiae of the program,
and therefore these models learned statistically useful but practically mean-
ingless patterns. This kind of situation may occur when the actual noise of
the input signal is too great, and so the models learn to be more biased.
This is a likely explanation, due to the mechanics of how graph convolu-
tion works. The transformations in Graph Convolutional Networks learn to
propagate information fully locally between connected nodes (including the
augmented self loops). In order for this to work it essentially aggregates all
local connections together within the same weight. What this means is that
in the naive case where only self loops exist the network is able to learn how
each token can be encoded purely based on itself, building what amounts to
a word embedding. However when introducing any linear connections, the
network cannot tell the diﬀerence between an edge connecting the previous
token and the self loop, or even further if there is an additional edge from
the control ﬂow, information propagates in the exact same way. What this
amounts to is anything other than the self loops just introducing noise into
the system, making the network more biased. Furthermore the purely local
nature of these transformations means that the network cannot learn the
global high level structural information that is essentially the only informa-
tion that is maintained through the abstraction preprocessing. This would

48

be ﬁxed in more traditional convolution by adding depth to the network,
however because of the aggregation property this essentially just multiplies
the noise eﬀect when attempted. In addition experiments where the identity
augmentation is removed from the graph convolutional models also produce
substantially worse performance due to the inability to propagate any infor-
mation in the same node from layer to layer making the model nothing more
than trying to predict a token two or three tokens in the future. Essentially
graph convolutional networks perform best under a number of conditions,
namely strong local correlation, node agnostically, and much high density of
connections than are found in control ﬂow graphs. Due to this experiment
lacking those properties, graph convolutions are a poor ﬁt for representing
programs in this way. The naive graph model is able to avoid these issues
by having only the identity connections, and therefore being able to actually
learn a consistent way to encode. However this encoding is not actually that
insightful, as it more or less acts as a pure encoding of each individual to-
ken, containing no information about the program globally. And so while it
performs well it is not very interesting. Essentially the main result of this
analysis is that graph convolutional networks do not encode information from
control ﬂow graphs well and that in the world of program synthesis too much
is lost when trying to abstract away program speciﬁcs to ﬁt within a purely
neural network based model.

49

Chapter 5

Conclusions and Future Work

The primary result of this study is that using the popular notion of Graph
Convolutional Networks, augmentation with control ﬂow graphs have no dis-
cernible gain in program embedding performance, and in fact graph convo-
lutions in general are a poor choice for the task currently when compared to
other results using linguistic models. This has implications in the develop-
ment of geometric deep learning, where it would imply that while existing
local methods are useful in certain applications where the graphs in ques-
tion imply more basic correlation between connected nodes, there is a lack of
methods interpreting nuanced global properties of the graphs. In the ﬁeld of
program synthesis it also implies that more purely linguistic solutions that
can take advantage of more sophisticated models like attention are preferable
to augmentation of less powerful models with formal analysis. And even fur-
ther that the necessary abstractions required in order to ﬁt programs into a
deep learning framework remove too much nuance and thus purely statistical
methods are not likely to be eﬀective in program synthesis. Therefore it also
further supports the use of CEGIS style frameworks for program synthesis,
where the oracle consisting of statistical or deep learning models and the for-
mal veriﬁer are more separated and each task is more individually optimized,
as the relevant information toward those tasks do not substantially overlap.
Finally the most valuable conclusions from such a strong negative result,
given that this is the ﬁrst empirical evaluation of its kind and the many com-
putational limitations and strong abstractions, is the need for replication.
However if these results are replicated, it would certainly have an eﬀect on
the direction of future program synthesis research.

50

Bibliography

[Allamanis et al., 2016] Allamanis, M., Peng, H., and Sutton, C. (2016). A
convolutional attention network for extreme summarization of source code.
In International Conference on Machine Learning (ICML).

[Alon et al., 2018] Alon, U., Zilberstein, M., Levy, O., and Yahav, E. (2018).
code2vec: Learning Distributed Representations of Code. arXiv e-prints,
page arXiv:1803.09473.

[Bai et al., 2018] Bai, S., Zico Kolter, J., and Koltun, V. (2018). An Em-
pirical Evaluation of Generic Convolutional and Recurrent Networks for
Sequence Modeling. arXiv e-prints, page arXiv:1803.01271.

[Bronstein et al., 2017] Bronstein, M. M., Bruna, J., LeCun, Y., Szlam, A.,
and Vandergheynst, P. (2017). Geometric deep learning: Going beyond
euclidean data. IEEE Signal Processing Magazine, 34(4):18–42.

[Church, 1957] Church, A. (1957). Applications of recursive arithmetic to
the problem of circuit synthesis. Summaries of the Summer Institute of
Symbolic Logic, 1:3–50.

[Feng et al., 2018] Feng, Y., Martins, R., Bastani, O., and Dillig, I. (2018).
Program synthesis using conﬂict-driven learning.
In Proceedings of the
39th ACM SIGPLAN Conference on Programming Language Design and
Implementation, PLDI 2018, pages 420–435, New York, NY, USA. ACM.

[Frazier, 2018] Frazier, P. I. (2018). A Tutorial on Bayesian Optimization.

arXiv e-prints, page arXiv:1807.02811.

[Gousios and Spinellis, 2012] Gousios, G. and Spinellis, D. (2012). Ghtor-
rent: Github’s data from a ﬁrehose. In Proceedings of the 9th IEEE Work-

51

ing Conference on Mining Software Repositories, MSR ’12, pages 12–21,
Piscataway, NJ, USA. IEEE Press.

[Kalyan et al., 2018] Kalyan, A., Mohta, A., Polozov, O., Batra, D., Jain, P.,
and Gulwani, S. (2018). Neural-Guided Deductive Search for Real-Time
Program Synthesis from Examples. arXiv e-prints, page arXiv:1804.01186.

[Kingma and Ba, 2014] Kingma, D. P. and Ba, J. (2014). Adam: A Method

for Stochastic Optimization. arXiv e-prints, page arXiv:1412.6980.

[Kipf and Welling, 2016] Kipf, T. N. and Welling, M. (2016).

Semi-
Supervised Classiﬁcation with Graph Convolutional Networks. arXiv e-
prints, page arXiv:1609.02907.

[Krizhevsky et al., 2017] Krizhevsky, A., Sutskever, I., and Hinton, G. E.
(2017). Imagenet classiﬁcation with deep convolutional neural networks.
Commun. ACM, 60(6):84–90.

[Lecun et al., 1998] Lecun, Y., Bottou, L., Bengio, Y., and Haﬀner, P.
(1998). Gradient-based learning applied to document recognition. Pro-
ceedings of the IEEE, 86(11):2278–2324.

[Lee et al., 2018] Lee, W., Heo, K., Alur, R., and Naik, M. (2018). Acceler-
ating search-based program synthesis using learned probabilistic models.
In Proceedings of the 39th ACM SIGPLAN Conference on Programming
Language Design and Implementation, PLDI 2018, pages 436–449, New
York, NY, USA. ACM.

[Manna and Waldinger, 1980] Manna, Z. and Waldinger, R. (1980). A de-
ductive approach to program synthesis. ACM Trans. Program. Lang. Syst.,
2(1):90–121.

[Mikolov et al., 2013] Mikolov, T., Chen, K., Corrado, G., and Dean, J.
(2013). Eﬃcient Estimation of Word Representations in Vector Space.
arXiv e-prints, page arXiv:1301.3781.

[Minsky and Papert, 1988] Minsky, M. L. and Papert, S. A. (1988). Percep-

trons: Expanded Edition. MIT Press, Cambridge, MA, USA.

[Padhi, 2019] Padhi, S. (2019). Sygus-comp 2018 results.

52

[Pan et al., 2018] Pan, S., Hu, R., Long, G., Jiang, J., Yao, L., and Zhang,
C. (2018). Adversarially Regularized Graph Autoencoder for Graph Em-
bedding. arXiv e-prints, page arXiv:1802.04407.

[Perry et al., 2019] Perry, D. M., Kim, D., Samanta, R., and Zhang, X.
(2019). Semcluster: Clustering of imperative programming assignments
based on quantitative semantic features. In Proceedings of the 40th ACM
SIGPLAN Conference on Programming Language Design and Implemen-
tation (PLDI ’19),, page 14.

[Polosukhin and Skidanov, 2018] Polosukhin, I. and Skidanov, A. (2018).
Neural Program Search: Solving Programming Tasks from Description
and Examples. arXiv e-prints, page arXiv:1802.04335.

[Polozov, 2018] Polozov, A.

(2018).

Program synthesis

in 2017-18.

https://alexpolozov.com/blog/program-synthesis-2018/.

[Radford et al., 2019] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D.,
and Sutskever, I. (2019). Language models are unsupervised multitask
learners.

[Rumelhart et al., 1988] Rumelhart, D. E., Hinton, G. E., and Williams,
R. J. (1988). Neurocomputing: Foundations of research. chapter Learning
Representations by Back-propagating Errors, pages 696–699. MIT Press,
Cambridge, MA, USA.

[Scarselli et al., 2009] Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner,
M., and Monfardini, G. (2009). The graph neural network model. IEEE
Transactions on Neural Networks, 20(1):61–80.

[Valiant, 1984] Valiant, L. G. (1984). A theory of the learnable. Commun.

ACM, 27(11):1134–1142.

[Vaswani et al., 2017] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J.,
Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. (2017). Attention
Is All You Need. arXiv e-prints, page arXiv:1706.03762.

[Veliˇckovi´c et al., 2017] Veliˇckovi´c, P., Cucurull, G., Casanova, A., Romero,
A., Li`o, P., and Bengio, Y. (2017). Graph Attention Networks. arXiv
e-prints, page arXiv:1710.10903.

53

[Wang et al., 2017] Wang, K., Singh, R., and Su, Z. (2017). Dynamic
Neural Program Embedding for Program Repair. arXiv e-prints, page
arXiv:1711.07163.

[Wu et al., 2019] Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., and Yu,
P. S. (2019). A Comprehensive Survey on Graph Neural Networks. arXiv
e-prints, page arXiv:1901.00596.

[Zavershynskyi et al., 2018] Zavershynskyi, M., Skidanov, A., and Polo-
sukhin, I. (2018). NAPS: Natural Program Synthesis Dataset. arXiv
e-prints, page arXiv:1807.03168.

[Zhang et al., 2018] Zhang, L., Rosenblatt, G., Fetaya, E., Liao, R., Byrd,
W. E., Might, M., Urtasun, R., and Zemel, R. (2018). Neural Guided
Constraint Logic Programming for Program Synthesis. arXiv e-prints,
page arXiv:1809.02840.

54

