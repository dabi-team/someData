Behavioral Modeling of Persian Instagram Users to detect Bots

Muhammad Bazm , Masoud Asadpour
Faculty of Electrical and Computer Engineering, University of Tehran
Northern Kargar st, Enghelab Square, Tehran, Iran
m.bazm@ut.ac.ir

0
2
0
2

g
u
A
0
1

]
I
S
.
s
c
[

1
v
1
5
9
3
0
.
8
0
0
2
:
v
i
X
r
a

Abstract

Bots are user accounts in social media which are controlled
by computer programs. Similar to many other thing, they are
used for both good and evil purposes. One nefarious use-case
for them is to spread misinformation or biased data in the net-
works. There are many pieces of research being performed
based on social media data and their results validity is ex-
tremely threatened by the harmful data bots spread. Conse-
quently, effective methods and tools are required for detecting
bots and then removing misleading data spread by the bots. In
the present research, a method for detecting Instagram bots is
proposed. There is no data set including samples of Instagram
bots and genuine accounts, thus the current research has be-
gun with gathering such a data set with respect to generality
concerns such that it includes 1,000 data points in each group.
The main approach is supervised machine learning and clas-
sic models are preferred compared to deep neural networks.
The ﬁnal model is evaluated using multiple methods starting
with 10-fold cross-validation. After that, conﬁdence in clas-
siﬁcation studies and is followed by feature importance anal-
ysis and feature behavior against the target probability com-
puted by the model. In the end, an experiment is designed
to measure the models effectiveness in an operational envi-
ronment. Finally, It is strongly concluded that the model per-
forms very well in all evaluation experiments.

Introduction
Before web usages become widespread, there were rather
simple methods for communication among people, includ-
ing letter, telephone, and fax. After this time, tools such as
email and video chat platforms, such as Skype, appeared.
These platforms were only capable of a peer to peer data
transmission which was also limited by acceptable data
types at the beginning of the era.

This generation was obsoleted by Social Networks; a new
platform had brought novel facilities for information shar-
ing and connectivity. The data shared by users were pre-
served and the relationship’s networks were explicitly de-
ﬁned and accessible, thus a large amount of data, represent-
ing people’s activities, was stored. This data is commonly
referred to as The Big Data.

With the big data, new opportunities have appeared for
solving problems with no exact solutions. Most of these
problems were coming from social science creating a new
ﬁeld of study known as Computational Social Science.
Multiple issues are threatening the validity of research re-
sults in this ﬁeld among which data pollution is a major
threat. One of the resources for this problem is an entity
known as Bot1.

Bots are user accounts controlled by a computer program
aimed at gathering or spreading data. Although they might
be used for good purposes, a large number of them are used
for evil goals. Accordingly, providing tools for detecting
such accounts and canceling their effects is extremely re-
quired. In this research, an effective solution is suggested for
this problem which has achieved great scores from multiple
evaluation metrics.

Here, Instagram is the target social media. Recently, it has
become common among people from all around the world.
Persian speaking users have a large community in this media
such that analyzing their data provides valuable answers to
important questions.

Literature Review
Bot detection is a well-known problem in computational so-
cial science. In this section, the most important researches
in this ﬁeld are reviewed. They are divided into three cat-
egories, corresponding to the approach they have adopted.
Each category is described below:

The ﬁrst category includes: (Chu et al. 2012), (Gao et
al. 2015), (Gong, Frank, and Mittal 2014), (Carminati, Fer-
rari, and Viviani 2014), (Danezis and Mittal 2009), (Yu et al.
2008b), (Yu et al. 2008a), (Cross and Jain 1983), (Murphy,
Weiss, and Jordan 2013), (Mohaisen, Yun, and Kim 2010),
(Leskovec et al. 2008), (Viswanath et al. 2010), (Mehrotra,
Sarreddy, and Singh 2016) and (Jia, Wang, and Gong 2017),
(Zhang et al. 2016). In mentioned researches, the main ap-
proach is using network structures; as a result, their job in-
cludes mostly graph-based methods. The major weakness of
this researches is their poor results compared to the last cat-
egory.

Copyright c(cid:13) 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

1Computer Robot

 
 
 
 
 
 
In the second category: researches such as (Jiang et al.
2013), (Yang et al. 2014), (Wang et al. 2013), (Subrahma-
nian et al. 2016) and (Gilani, Kochmar, and Crowcroft 2017)
are found. Their research mostly relies on crowd-sourcing.
Threatening user’s privacy is the most important challenge
in researches in this section.

In the last category researchers such as: (Chu et al. 2012),
(Subrahmanian et al. 2016), (Yang et al. 2014), (Lee, Eoff,
and Caverlee 2011), (Dickerson, Kagan, and Subrahma-
nian 2014), (Davis et al. 2016), (Varol et al. 2017), (Alar-
iﬁ, Alsaleh, and Al-Salman 2016), (Kantepe and Ganiz
2017), (Jia, Wang, and Gong 2017), (Mehrotra, Sarreddy,
and Singh 2016), (Gilani, Kochmar, and Crowcroft 2017),
(Cai, Li, and Zengi 2017) and (Chavoshi, Hamooni, and
Mueen 2016) are included. Above mentioned researches
have adopted a supervised learning approach toward this
problem. Compared to the other categories, researches in
this one have achieved highers scores.

The Data set
There is no data set of bots and genuine accounts except one
which was introduced in (Akyon and Esat Kalfaoglu 2019)
which does not include any Persian user account. As a result,
a new data set suitable for present research’s goals should
have been gathered.

Positive class
Since there was no sample for the Instagram bot, a simpli-
fying assumption was made: Since all harmful bots possess
fake identities, gathering a set of fake accounts, will result
in having a set of Instagram accounts which could be con-
sidered a superset for Instagram bots. The same assumption
has been made before in (Cresci et al. 2017) when preparing
a data set of twitter bots that were used for developing the
famous bot detection tool Botometer in (Varol et al. 2017)
afterwords. Furthermore, to satisfy generalization consider-
ations, ﬁve fake account providers for Instagram were re-
ferred to and 1000 fake accounts where ordered.

Negative class
To have a set of genuine Instagram accounts, data from So-
cial Networks laboratory2 is used. A data set of nearly
all Persian Instagram accounts is gathered in this labora-
tory concerning the user’s privacy. A random sample of size
1000 from this data was taken to represent genuine accounts.
Since most user accounts in each social media belong to real
humans, thus a random sample will provide a set of accounts
including a large portion of genuine accounts.

In this data set, six features are used which are described

in table 1.

Behavioral Modeling
Behavior on Instagram has three forms: 1) to share a post,
2) to comment beneath a post and 3) to like a post or a com-
ment; the three forms are referred to as behavioral proper-
ties. According to Instagram’s structure, tracks of only the

2Faculty of Electrical and Computer Engineering - University

of Tehran

Table 1: Features introduced in the data set.

No Feature name
1
2
3
4
5
6

username length
full name length
biography length
followers count
followings count
Posts creation times

ﬁrst property are accessible when checking a user’s page and
for having the rest, all data of the network is needed which
is not ready here. As a result, only data describing users’
posting behavior could be considered which corresponds to
6th row in table 1. Since the number of posts differs among
users, eight statistical measures are used to create an equal
number of features for all users. Table 2 illustrates names of
above-mentioned measures.

Table 2: Statistical measure used for modeling posts sharing
times.

No
1
2
3
4
5
6
7
8

Statistical Measure
Min
Max
Mean
Median
Std
Skewness
Kurtosis
Entropy

Effectiveness of Behavioral Modeling
To test how effective this form of modeling is, a simple clas-
siﬁer is used, which is Gaussian Naive Bayes in this case,
as a baseline. During two different experiments, one all fea-
tures and then only basic features (all feature minus statis-
tical measures deﬁning behavioral properties) are fed to the
classiﬁer. In each experiment, the classiﬁer is evaluated us-
ing 10-fold cross-validation. To check for the statistical sig-
niﬁcance of the reported results, the above-mentioned ex-
periments are performed 1000 times which results in having
1,000 values for each of the measures per model. In each
iteration (every single experiment of all 1,000), observa-
tions are shufﬂed 100 times to avoid bias. For 10-fold cross-
validation, observations are shufﬂed again which sums up to
101 times random shufﬂing the data. It should be mentioned
that the data is normalized using Z-standardization before
being fed to the model. The ﬁnal results for this evaluation
are represented in table 3. In this table, the mean of all val-
ues for each metric are reported plus or minus two times the
standard deviation.

According to table 3, all measures show improvements
but the recall. Although the recall is decreased when using
all features, the increase in F-1 means that the precision is
increased enough to support the decrease in the recall. Fig-
ures 1 to 4 illustrate distributions for metric values.

Table 3: Behavioral modeling evaluation results.

No Measure
1
Accuracy
Precision
2
3
Recall
F-1
4

Basic Features All features
0.81 +/- 0.01
0.63 +/- 0.03
0.99 +/- 0.00
0.61 +/- 0.05
0.65 +/- 0.02
0.90 +/- 0.08
0.78 +/- 0.01
0.71 +/- 0.03

p-value
0.00
0.00
1.00
0.00

Figure 3: Distribution of recall values for both models. The
darker curve (right) represents the model trained on all fea-
tures and the lighter (left) has only used basic features.

Figure 1: Distribution of accuracy values for both models.
The darker curve (left) represents the model trained on all
features and the lighter (right) has only used basic features.

Figure 4: Distribution of F-1 values for both models. The
darker curve (left) represents the model trained on all fea-
tures and the lighter (right) has only used basic features.

data).

From this experiment, it is clearly understood that behav-
ioral modeling is effective in distinguishing bots and gen-
uine accounts on Instagram, and this result is statistically
signiﬁcant.

Training the candidate models

Features management
In all machine learning studies, the quality of features must
be examined before feeding the data to the model. In the
present research, this job is done in two phases: 1) Calculat-
ing the importance of each feature 2) calculating the corre-
lation between each pair of features.

After the two above-mentioned phases, redundant and
highly correlated features (except one of them), also known
as redundant features, are removed in order to reduce model
complexity and training time. The remaining features are in-
troduced in the table 4.

Finding candidate models
Deep learning models have achieved astonishing results
in the AI community, however, studies such as (Dacrema,

Figure 2: Distribution of precision values for both models.
The darker curve (left) represents the model trained on all
features and the lighter (right) has only used basic features.

Furthermore, the last column, depicts the result of a statis-
tical test evaluating the null hypothesis which says the mea-
sure for both states are equal against the alternative hypoth-
esis saying numbers in the right column are greater than
the left column in a one-tailed test. As is illustrated in the
right-most column, for all measures except the recall, the
null hypothesis is strongly rejected in favor of the alterna-
tive hypothesis. To make certain that the experiment meets
central limit theorem’s criteria:

• Observations for the test are picked randomly.

• Sample size is equal to 40, as a result, it is:

– less that 10% of the population.
– greater that 30 (in order to support skewness in the

Table 4: Remaining features after removing non-related and
redundant features

No Feature name
1
2
3
4
5
6
7

Max
Std
Skewness
Entropy
following count
full name length
biography length

Cremonesi, and Jannach 2019), have shown that in many
cases, ﬁne-tuned classic machine learning algorithms (such
as KNN, etc.) can achieve good performance even compared
to deep learning methods. Furthermore, due to the complex
structure of deep methods, a large amount of training data
is required for them to achieve a high performance, which
is not present in this study. Accordingly, classic machine
learning methods are preferred over deep learning methods
in current research.

Among classic methods, some are selected for further
analysis including KNN, Decision Tree, SVM, Random
Forest, and AdaBoost. This set, includes a spectrum of
classic machine learning methods, from simple to complex.
It is assumed that they can achieve good performance when
using optimal hyperparameters.

Fine-tuning the models
In order to ﬁne-tune the models, a portion of the data should
be taken as the test set. A random sample including 30%
of all observations is selected for this process. A different
sample is used for ﬁne-tuning each model. In this research,
sci-kit learn is used for implementing the solution, as a re-
sult, hyper-parameters names’ are compatible with sci-kit
learn the terminology. Final results in this phase are reported
through tables 5 to 9.

Table 5: Optimal hyper-parameter values for KNN

Value

Name
Algorithm Ball Tree
Leave size
K
Distance
Weights

10
5
Manhattan
Distance

Table 6: Optimal hyper-parameter values for Decision Tree

Name
Criterion
Max depth
Min samples leaf
Min impurity split
Splitter

Value
Gini-index
10
2
3
Random

Table 7: Optimal hyper-parameter values for SVM

Value
Name
C
3
Polynomial
Kernel
degree
5
1.5
coef0
shrinking
True
probabilistic approximations True

Table 8: Optimal hyper-parameter values for Random Forest

Name
Criterion
Max depth
Max features
Min samples split
n estimators

Value
Entropy
None
5
3
20

Table 9: Optimal hyper-parameter values for AdaBoost

Name
Algorithm
Learning rate
n estimators

Value
SAMME
1.0
50

Train and evaluate
When optimal hyper-parameters are determined, ﬁne-tuned
models should be trained with enough data. For each model,
the whole data is shufﬂed, a random sample including 70%
of observations is selected for training models and the rest is
preserved for the test. In addition to test data, the models are
evaluated using 10-fold cross-validation, however, reported
values for all metrics are from cross-validation except for
the area under the ROC curve which is computed using the
test data. In this table, the greatest values are written in bold.
The evaluation results are illustrated in 10.

According to the results, the AdaBoost has achieved the
highest scores. Compared to the baseline model, this model
has achieved a better score in metrics such as accuracy, re-
call, and f-1 but has got a lower score in precision.

AdaBoost further analysis

Classiﬁcation conﬁdence
To examine how conﬁdent the AdaBoost is when it makes
decisions about observations, probabilities of being a bot
computed by the model for the test data are computed.

In this ﬁgure, the curve on the left (the darker) depicts
the distribution of probabilities for being a bot computed for
genuine accounts in the test data. The curve on the right (the
lighter one) shows the same probabilities for genuine ac-
counts in the test data. Ideally, both curves should have been
located away from each other, however, the ﬁgure shows the
opposite. Consequently, it is understood that despite its high
accuracy, the model is not much conﬁdent about the deci-
sions it makes.

The model
KNN
Decision Tree
SVM
Random Forest
AdaBoost

Table 10: Classiﬁcation Results

Accuracy Precision Recall F-1
0.92
0.92
0.92
0.92
0.94
0.93
0.95
0.95
0.95
0.95

0.90
0.91
0.94
0.94
0.95

0.95
0.93
0.94
0.94
0.95

ROC AUC
0.97
0.94
0.96
0.99
0.99

Features’ importance and relations
One way to analyze decisions made by a model is to com-
pute the importance of each feature in the classiﬁcation pro-
cess (recall some features were removed in the feature man-
agement phase, thus Gini importance is computed for re-
maining features by the model). One method for comput-
ing the importance values, is gini importance which is de-
scribed in (Louppe et al. 2013). The Gini importance values
for all features which are used in the data are computed and
reported in ﬁgure 6.

According to this ﬁgure, Max is the most effective fea-
ture in the classiﬁcation process. It is followed by follow-
ing count, standard deviation, entropy and three others.
Among the four most important features, three are behav-
ioral features. This is another proof of the effectiveness of
behavioral features.

The last step toward investigating the AdaBoost is to ana-
lyze relations between every single feature’s values and the
probability of being a bot which is computed by the model.
This is done by using Partial Dependency Plots (PDPs);
these plots are illustrated in ﬁgures 7 to 10. Since the rest
of the features have rather no observable relation with the
probability of being a bot, their corresponding PDPs are not
presented.

Final experiment - I
A ﬁnal experiment is designed to investigate the practical
effectiveness of the AdaBoost. This experiment includes the
following steps:

• A random sample of size 5000 is selected from social net-

works lab’s data

• All observations from the sample are fed to the AdaBoost
and the probability of being a bot is computed for all of
them.

• Observations are sorted in decreasing order of probabili-
ties and 50 ﬁrst accounts were selected for hand-check.

The results of this experiment are brieﬂy illustrated in
table 12 and are comprehensively described here. Among
these ﬁfty accounts:

• Ten were not found. This might have been due to user-

name change and/or account removal.

• Ten accounts were similar to genuine accounts. This ex-
periment is based on observing proﬁle pictures, the sim-
ilarity between the proﬁle picture and other posted pic-
tures, etc. It is clear that in this step, decisions are made
based on the user’s content. Since content-related features

Figure 5: Distributions of probabilities for being a bot com-
puted for the test data.

To quantify the results of this experiment, 95% conﬁdence
intervals are computed for both distributions. To do this, one
sample should be picked from both bots and genuine ac-
counts in the test data. Central limit theorem’s criteria should
be satisﬁed when using conﬁdence intervals, and to do so,
the following conditions must hold for the selected samples.

• The observations must have been selected uniformly at

random.

• Sample’s size must be larger than 30 (this number is most
likely to be enough since neither of the distributions is
highly skewed).

• Sample’s size must be less than 10% of the population.

Information describing the two intervals are provided in

table 11.

Table 11: Conﬁdence interval information
Conﬁdence interval
Class
0.58 +/- 0.016
Bots
0.43 +/- 0.014
Genuine Accounts

Although the conﬁdence intervals reported in table 11
support the idea that the two distributions are close, the thin
marginal errors in both intervals show that they do not over-
lap. This experiment, weakens the idea of overlapping dis-
tributions thus supporting effectiveness of the AdaBoost in
this problem. This phenomenon is believed to be existed due
to the small number of features used for describing the data.

Figure 6: Gini importance for all features which are used in classiﬁcation process.

Figure 7: The relation between values of Max feature and
the probability of being a bot.

Figure 9: The relation between values of std feature and the
probability of being a bot.

Figure 8: The relation between values of Following Count
feature and the probability of being a bot.

Figure 10: The relation between values of Entropy feature
and the probability of being a bot.

are absent in the data set, such a phenomenon is likely to
be observed.

• Thirty accounts looked like genuine accounts. Decisions
in the step, are made on a similar basis as the previous
step. Recalling that content-related features are absent,
this observation shows that behavioral features are in tight
relation with content features.

Table 12: Result of the hand-check for random accounts
Count
10
10
30

Status
Account was not found.
Accounts which look like genuine accounts.
Potential Bots.

Final experiment - II
One way to check the effectiveness of classiﬁcation is to
evaluate the classiﬁer for distinguishing different types of

accounts. To investigate the classiﬁer in this fashion, an ex-
periment was designed. This experiment includes ﬁve iter-
ations. In each iteration, accounts belonging to one of the
visited Instagram service providers are hold out plus an
equal number of genuine accounts altogether as test data,
and the model (AdaBoost with optimum hyper-parameters)
is trained on rest of data. The results of this experiment are
reported in table 13.

Instagram.
Mitham Saki:Developing and maintaining the data cluster
at Social Networks Lab.
Seyed Morteza Ghavami:Developing processes which
maintain the data in the cluste.
Milad Sayadamooz: Developing web services for working
with the data storage cluster.

Table 13: Results of the class by class evaluation
Measures
Itr 5
Accuracy
0.97
Precision
0.97
Recall
0.97
F-1
0.97

Itr 2
0.98
0.98
0.98
0.98

Itr 4
0.95
0.95
0.95
0.95

Itr 3
0.96
0.96
0.96
0.96

Itr 1
0.98
0.98
0.98
0.98

In table 13, each columns includes same values for all
metrics. Although this observation seems strange, it is sim-
ilar to results in table 10 thus the results are reasonable in
this setting.

Furthermore, in all iterations, except for iteration 4, all
metrics’ values are greater than 0.95 which was achieved in
10-fold cross-validation (as reported in table 10). Such an
increase in evaluation metrics might be observed due to the
following reasons:

• Usually, evaluation metrics achieve higher scores with test

data.

• In this experiment, data is re-sampled with replacement to
provide an equal size for both classes. Extra observation
gathered in this way, might have improved classiﬁcation’s
quality.

Results
In this research, a new data set including samples of bots
and genuine Instagram accounts are gathered concerning
generality concerns. Behavioral modeling is introduced as
an effective technique for modeling Instagram users’ data
concerned with the bot detection problem. Classic machine
learning algorithms are used for classiﬁcation and are ﬁne-
tuned to have their performance boosted. It is shown that
ﬁne-tuned classic machine learning models perform well
in the current study. Boosting, as an ensemble method has
proved to be more effective compared to simpler methods.
AdaBoost, which has achieved the best performance among
all studied methods. Creation times of most recent posts
(which is introduced as the Max in the data set) are proved
to be the most important feature in classiﬁcation which has
a negative linear relationship with the probability of being a
bot computed by the classiﬁer.

Acknowledgments
This work would have been much more difﬁcult without
helps from others. People who have had signiﬁcant roles in
this research are mentioned bellow:
Dr Behnam Bahrak: Counsellor on statistical issues.
Abbas Ma’allahi: Developing the crawling system for

References

[Akyon and Esat Kalfaoglu 2019] Akyon, F. C., and Esat
Kalfaoglu, M. 2019. Instagram fake and automated account
In 2019 Innovations in Intelligent Systems and
detection.
Applications Conference (ASYU), 1–7.
[Alariﬁ, Alsaleh, and Al-Salman 2016] Alariﬁ, A.; Alsaleh,
M.; and Al-Salman, A. 2016. Twitter turing test. Inf. Sci.
372(C):332346.
[Cai, Li, and Zengi 2017] Cai, C.; Li, L.; and Zengi, D.
2017. Behavior enhanced deep bot detection in social me-
dia. In 2017 IEEE International Conference on Intelligence
and Security Informatics (ISI), 128–130.
[Carminati, Ferrari, and Viviani 2014] Carminati, B.; Fer-
rari, E.; and Viviani, M. 2014. Security and Trust in Online
Social Networks. Morgan & Claypool Publishers.
N.;
[Chavoshi, Hamooni, and Mueen 2016] Chavoshi,
2016. Debot: Twitter
Hamooni, H.; and Mueen, A.
In 2016 IEEE
bot detection via warped correlation.
16th International Conference on Data Mining (ICDM),
817–822.
[Chu et al. 2012] Chu, Z.; Gianvecchio, S.; Wang, H.; and Ja-
jodia, S. 2012. Detecting automation of twitter accounts:
Are you a human, bot, or cyborg? IEEE Transactions on
Dependable and Secure Computing 9(6):811–824.
[Cresci et al. 2017] Cresci, S.; Di Pietro, R.; Petrocchi, M.;
Spognardi, A.; and Tesconi, M. 2017. The paradigm-shift of
social spambots: Evidence, theories, and tools for the arms
race. In Proceedings of the 26th International Conference
on World Wide Web Companion, WWW 17 Companion,
963972. Republic and Canton of Geneva, CHE: Interna-
tional World Wide Web Conferences Steering Committee.
[Cross and Jain 1983] Cross, G. R., and Jain, A. K. 1983.
Markov random ﬁeld texture models. IEEE Transactions on
Pattern Analysis and Machine Intelligence PAMI-5(1):25–
39.
[Dacrema, Cremonesi, and Jannach 2019] Dacrema, M. F.;
Cremonesi, P.; and Jannach, D. 2019. Are we really mak-
ing much progress? a worrying analysis of recent neural rec-
ommendation approaches. In Proceedings of the 13th ACM
Conference on Recommender Systems, RecSys 19, 101109.
New York, NY, USA: Association for Computing Machin-
ery.
[Danezis and Mittal 2009] Danezis, G., and Mittal, P. 2009.
Sybilinfer: Detecting sybil nodes using social networks.
[Davis et al. 2016] Davis, C. A.; Varol, O.; Ferrara, E.; Flam-
mini, A.; and Menczer, F. 2016. Botornot: A system to

2013.

2nd International Conference on Contemporary Computing
and Informatics (IC3I), 499–504.
[Mohaisen, Yun, and Kim 2010] Mohaisen, A.; Yun, A.; and
Kim, Y. 2010. Measuring the mixing time of social graphs.
In Proceedings of the 10th ACM SIGCOMM Conference on
Internet Measurement, IMC 10, 383389. New York, NY,
USA: Association for Computing Machinery.
[Murphy, Weiss, and Jordan 2013] Murphy, K. P.; Weiss, Y.;
and Jordan, M. I.
Loopy belief propagation
for approximate inference: An empirical study. CoRR
abs/1301.6725.
[Subrahmanian et al. 2016] Subrahmanian, V. S.; Azaria, A.;
Durst, S.; Kagan, V.; Galstyan, A.; Lerman, K.; Zhu, L.; Fer-
rara, E.; Flammini, A.; and Menczer, F. 2016. The darpa
twitter bot challenge. Computer 49(6):38–46.
[Varol et al. 2017] Varol, O.; Ferrara, E.; Davis, C. A.;
Menczer, F.; and Flammini, A. 2017. Online human-bot
interactions: Detection, estimation, and characterization. In
International AAAI Conference on Web and Social Media,
280–289. AAAI.
[Viswanath et al. 2010] Viswanath, B.; Post, A.; Gummadi,
K. P.; and Mislove, A. 2010. An analysis of social network-
based sybil defenses. SIGCOMM Comput. Commun. Rev.
40(4):363374.
[Wang et al. 2013] Wang, G.; Mohanlal, M.; Wilson, C.;
Wang, X.; Metzger, M. J.; Zheng, H.; and Zhao, B. Y. 2013.
Social turing tests: Crowdsourcing sybil detection. ArXiv
abs/1205.3856.
[Yang et al. 2014] Yang, Z.; Wilson, C.; Wang, X.; Gao, T.;
Zhao, B. Y.; and Dai, Y. 2014. Uncovering social network
sybils in the wild. ACM Trans. Knowl. Discov. Data 8(1).
[Yu et al. 2008a] Yu, H.; Gibbons, P. B.; Kaminsky, M.; and
Xiao, F. 2008a. Sybillimit: A near-optimal social network
defense against sybil attacks. In 2008 IEEE Symposium on
Security and Privacy (sp 2008), 3–17.
[Yu et al. 2008b] Yu, H.; Kaminsky, M.; Gibbons, P. B.; and
Flaxman, A. D. 2008b. Sybilguard: Defending against sybil
IEEE/ACM Transactions on
attacks via social networks.
Networking 16(3):576–589.
[Zhang et al. 2016] Zhang, J.; Zhang, R.; Sun, J.; Zhang, Y.;
and Zhang, C. 2016. Truetop: A sybil-resilient system for
user inﬂuence measurement on twitter. IEEE/ACM Transac-
tions on Networking 24(5):2834–2846.

In Proceedings of the 25th Interna-
evaluate social bots.
tional Conference Companion on World Wide Web, WWW
16 Companion, 273274. Republic and Canton of Geneva,
CHE: International World Wide Web Conferences Steering
Committee.
[Dickerson, Kagan, and Subrahmanian 2014] Dickerson,
J. P.; Kagan, V.; and Subrahmanian, V. S. 2014. Using
sentiment
to detect bots on twitter: Are humans more
opinionated than bots? In 2014 IEEE/ACM International
Conference on Advances in Social Networks Analysis and
Mining (ASONAM 2014), 620–627.
[Gao et al. 2015] Gao, P.; Gong, N. Z.; Kulkarni, S. R.;
Thomas, K.; and Mittal, P. 2015. Sybilframe: A defense-in-
depth framework for structure-based sybil detection. ArXiv
abs/1503.02985.
Z.;
[Gilani, Kochmar, and Crowcroft 2017] Gilani,
Kochmar, E.; and Crowcroft, J.
2017. Classiﬁcation
of twitter accounts into automated agents and human
users. In Proceedings of the 2017 IEEE/ACM International
Conference on Advances in Social Networks Analysis and
Mining 2017, ASONAM 17, 489496. New York, NY, USA:
Association for Computing Machinery.
[Gong, Frank, and Mittal 2014] Gong, N. Z.; Frank, M.; and
Mittal, P. 2014. Sybilbelief: A semi-supervised learning
IEEE Trans.
approach for structure-based sybil detection.
Information Forensics and Security 9(6):976–987.
[Jia, Wang, and Gong 2017] Jia, J.; Wang, B.; and Gong,
N. Z. 2017. Random walk based fake account detection
in online social networks. In 2017 47th Annual IEEE/IFIP
International Conference on Dependable Systems and Net-
works (DSN), 273–284.
[Jiang et al. 2013] Jiang, J.; Wilson, C.; Wang, X.; Sha, W.;
Huang, P.; Dai, Y.; and Zhao, B. Y. 2013. Understanding
latent interactions in online social networks. ACM Trans.
Web 7(4).
[Kantepe and Ganiz 2017] Kantepe, M., and Ganiz, M. C.
2017. Preprocessing framework for twitter bot detection.
In 2017 International Conference on Computer Science and
Engineering (UBMK), 630–634.
[Lee, Eoff, and Caverlee 2011] Lee, K.; Eoff, B. D.; and
Caverlee, J. 2011. Seven months with the devils: a long-
term study of content polluters on twitter. In In AAAI Intl
Conference on Weblogs and Social Media (ICWSM.
[Leskovec et al. 2008] Leskovec, J.; Lang, K. J.; Dasgupta,
A.; and Mahoney, M. W. 2008. Community structure in
large networks: Natural cluster sizes and the absence of large
well-deﬁned clusters.
[Louppe et al. 2013] Louppe, G.; Wehenkel, L.; Sutera, A.;
and Geurts, P. 2013. Understanding variable importances
in forests of randomized trees. In Proceedings of the 26th
International Conference on Neural Information Processing
Systems - Volume 1, NIPS13, 431439. Red Hook, NY, USA:
Curran Associates Inc.
A.;
[Mehrotra, Sarreddy, and Singh 2016] Mehrotra,
Sarreddy, M.; and Singh, S.
2016. Detection of fake
twitter followers using graph centrality measures. In 2016

