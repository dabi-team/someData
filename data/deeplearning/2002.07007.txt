0
2
0
2

b
e
F
7
1

]

M
Q
.
o
i
b
-
q
[

1
v
7
0
0
7
0
.
2
0
0
2
:
v
i
X
r
a

The Synthesizability of Molecules Proposed by

Generative Models

Wenhao Gao†,¶ and Connor W. Coley∗,†,‡

†Department of Chemical Engineering, MIT, Cambridge, MA

‡Broad Institute of Harvard and MIT, Cambridge, MA

¶Department of Chemical and Biomolecular Engineering, Johns Hopkins University,

Baltimore, MD

E-mail: ccoley@mit.edu

Abstract

The discovery of functional molecules is an expensive and time-consuming pro-

cess, exempliﬁed by the rising costs of small molecule therapeutic discovery. One class

of techniques of growing interest for early-stage drug discovery is de novo molecu-

lar generation and optimization, catalyzed by the development of new deep learning

approaches. 1 These techniques can suggest novel molecular structures intended to max-

imize a multi-objective function, e.g., suitability as a therapeutic against a particular

target, 2 without relying on brute-force exploration of a chemical space. 3 However, the

utility of these approaches is stymied by ignorance of synthesizability. To highlight

the severity of this issue, we use a data-driven computer-aided synthesis planning pro-

gram 4 to quantify how often molecules proposed by state-of-the-art generative models

cannot be readily synthesized. Our analysis demonstrates that there are several tasks

for which these models generate unrealistic molecular structures despite performing

well on popular quantitative benchmarks. Synthetic complexity heuristics can success-

fully bias generation toward synthetically-tractable chemical space, although doing so

1

 
 
 
 
 
 
necessarily detracts from the primary objective. This analysis suggests that to improve

the utility of these models in real discovery workﬂows, new algorithm development is

warranted.

Introduction

Molecular design is one of the most fundamental challenges in chemical science and en-

gineering. This task is to identify one or more molecules with a speciﬁc set of properties of

interest, such as binding aﬃnity and drug-likeness for drug design. High-throughput virtual

screening (VS) is one widely used strategy to coarsely optimize a molecular structure using

a discretized subspace of the whole chemical space. 5 In VS, we evaluate enumerated can-

didate molecules in terms of their predicted properties of interest and ranked for follow-up

experimental validation. However, because we rarely know a priori where the ideal molecule

will be within the massive design space of chemical space, there is a trend toward using

exceedingly large virtual libraries to increase the likelihood that we will ﬁnd promising can-

didates. Modern virtual libraries may comprise hundreds of millions or billions of candidate

molecules, 3 often generated through combinatorial enumeration of commercially-available

building block compounds. Even billions of compounds, however, represent a tiny fraction

of theoretically-possible, pharmacologically-relevant small molecules, often cited as exceed-

ing 1060 structures. 6 Brute-force virtual screening screening over a chemical space of this size

is clearly computationally intractable.

Recent developments in computer aided drug design (CADD) techniques, especially in

de novo molecular generation and optimization methods, raise the hope of removing this

bottleneck. 1 Generative algorithms are a class of methods that propose molecular structures

in a manner that can be tailored toward a speciﬁc objective. There is a long history of gener-

ative models in chemistry, many based on genetic algorithms 7 and the iterative construction

of molecules from molecular fragments. 8 In the past decade, following on the advent of Vari-

ational Auto-Encoders (VAEs) 9 and Generative Adversarial Networks (GANs), 10 there has

2

been a ﬂood of new deep learning (DL) methods for this task. 11 Many of these methods learn

a mapping from a continuous lower-dimensional real number space to a discrete chemical

space. Jointly trained with a structure-property regression, one can obtain novel chemical

structures conditioned on desired properties. More usefully, combining generative models

with Bayesian optimization (BO), or directly using a heuristic optimization algorithm (e.g.,

a genetic algorithm (GA) or tree search (TS)), we can bias candidate generation toward the

functionality we desire. Deep generative models are trained on a ﬁnite set of molecules to

learn an underlying distribution of chemical space, where interpolation and extrapolation

produce novel chemical structures. Enumerating every candidate molecule is thus unnec-

essary, and applying these models requires linear computational cost to generate multiple

molecular structures once trained. Further, the generative algorithms can explore chemical

space beyond the limited beginning pool and provide novel chemical structures with prefer-

ential intellectual property (IP) positions, whereas molecules in VS are often pre-existing.

In recent years, generative models have been applied to various chemical discovery problems

and have shown promise as a useful tool for the problem of molecular design. 2

However, a practical problem that obstructs the usefulness of generative algorithms is

that proposed molecular structures may be challenging or infeasible to synthesize. In any

realistic discovery scenario, we will need to validate whether a proposed molecule has the

property proﬁle we expect; even if our computational models are infallible, we will need

to manufacture the molecule in order to apply it (e.g., as a therapeutic, as a catalyst, as a

component of a device). Libraries for virtual screening can be constructed from commercially-

available databases. They are often enumerated using well-characterized reaction templates

to try to ensure that enumerated molecules are readily synthesizable. Lyu et al. report an

86% successfully synthesis rate among 51 top-ranking molecules from a library comprising

99 million structures, consistent with the claims of many chemical vendors. 3

The situation is quite diﬀerent in de novo molecular design, especially when using deep

generative methods. We expect (and want) these models to explore molecular structures

3

beyond the ones they have been trained on, so they may propose nonsensical structures

that are unreasonable for pharmaceutical purposes. There have been few studies explicitly

examining this problem, but some anecdotal evidence suggests that compounds are not

easily synthesizable—many structures reported in papers indeed appear absurd. Bjerrum

and Threlfall examined 21 molecules proposed by their recurrent neural network (RNN)

model with Wiley’s ChemPlanner and found a number of possible selectivity issues in the

proposed syntheses, indicating synthetic diﬃculty. 12 Sumita et al. ﬁlter generated molecules

by requiring that they be previously reported with at least one synthetic route in SciFinder,

which removes these models’ ability to propose novel chemical structures. 13 Zhavoronkov

et al. select only 6 molecules from 40 candidates structures based on synthetic accessibility,

even after ﬁltering an initial list of 30,000 structures generated by a deep learning model. 2

Current procedures for quantifying synthesizability are based on (1) structure complex-

ity and similarity or (2) synthetic pathways. The structure-based approach usually involves

constructing a heuristic deﬁnition based on domain expertise or chemical substructure di-

versity 14,15 or designing a model that can be ﬁt to expert scores 16–18 or reaction data. 19,20

This kind of method is widely used due to its ease of implementation and low computational

cost. However, two similar structures with a single functional group transposition can re-

quire substantially diﬀerent synthetic routes (e.g., due to the selectivity of chemical reactions

or availability of speciﬁc building blocks), which makes it challenging to ﬁt a good proxy

score (see Figure S1 and S2 for one example). The most convincing metric might be a direct

scoring from a group of experts on synthetic, medicinal chemistry, which has been used as a

ground truth to train models against. 16–19 To have a group of experts that large enough to

reach a non-biased and stable value is labor-intensive, hard to replicate, and not scalable. 21

The second, more nuanced approach to measuring synthesizability is to explicitly plan

a synthetic pathway and assess its likelihood of experimental validity. Synthetic pathway-

based approaches can incorporate more thorough information about starting materials and

chemical reactions, which enable them to overcome the shortcomings of the structure-based

4

analysis. In this approach, a computer-aided synthesis planning (CASP) program 22 can be

used to perform the retrosynthetic analysis. Using an explicit CASP tool is capable not only

of capturing the high “non-linearity” of synthesizability with respect to chemical structure,

but of recommending actionable synthetic pathways. We see this as a form of interpretability

to verify why the molecule is believed to be synthesizable, with which building blocks, and

in how many steps. Only a handful of studies have used a retrosynthetic planning tool to

analyze synthesizability. 12,23–25 Its practical application in molecular design is not widespread

yet. Therefore, here, we analyze synthesizability of compounds proposed through generative

algorithms using our open-source computer-aided retrosynthesis analysis tool, ASKCOS. 4

We divide our analysis of the synthesizability of molecules generated by de novo genera-

tive algorithms into evaluations of distribution learning and goal-directed generation tasks–

unoptimized and optimized molecules, respectively. Distribution learning models are meant

to interpolate within a chemical space comprised a training set of molecules and generate

new molecules with similar properties. Goal-directed generation instead tries to generate

new molecules that maximize a black-box scoring function. There are an increasing num-

ber of algorithms of these two categories proposed in recent years and a small number of

studies that benchmark these algorithms in terms of their ability to generate novel, optimal

molecules. 26,27

We categorize the approaches one might take to ensure that computationally designed

molecules are able to be synthesized in Figure 1. These represent combinations of (i) a

database of known or enumerated compounds, (ii) an evaluator, which estimates the prop-

erties we are trying to optimize, (iii) a generator function, which can propose new candidate

molecules, (iv) a synthesizability oracle that determines whether it is straightforward to syn-

thesize a given molecule, and/or (v) a heuristic synthesizability estimator that provides a

computationally-inexpensive scalar measure of synthesizability. In this study, we focus on

three major approaches to solving the synthesizability problem: post hoc ﬁltering (Figure 1c),

imposing a priori diﬀerences in training sets (Figure 1d), and heuristic biasing (Figure 1e).

5

Figure 1: Schematic representation of approaches to address the challenge of synthesizability
in molecular optimization: (a) virtual screening can use a ﬁltered database of candidates to
ensure that they are all synthetically accessible; (b) standard molecular generation focuses
on evaluation of properties without regard for synthesizability; (c) a post hoc ﬁlter narrows
down proposed candidates as a separate step from generation; (d) biasing by training set
aims to improve synthesizability by training generative models on synthetically-accessible
compounds; (e) biasing by heuristics uses simple scalar proxies for synthesizability as part
of the objective function; (f) biasing by a CASP oracle runs a full retrosynthetic expansion
for proposed molecules to modify the reward function in a reinforcement learning setting;
and (g) explicit constraints attempt to restrict chemical space to what is accessible using
buyable building blocks and known synthetic transformations.

Results

Synthesizability of common databases according to ASKCOS

We ﬁrst validate that the information returned by ASKCOS is usefully correlated with

synthesizability by analyzing molecules from several standard compound libraries: MOSES, 26

ChEMBL, 28 ZINC, 29 Sheridan et al., 17 and GDB17 30 (see Methods for detailed descriptions

of each data set and the settings used for retrosynthetic analysis, including the evaluation

of commercial availability of building blocks). Figure 2a shows the predicted number of

synthetic steps required to produce a random set of 3000 molecules from each data set. The

6

MOSES data set has the highest rate of perceived synthesizability at 89.8%, consistent with

its focus on small lead molecules and exclusion of compounds with “structural alerts”. Its

parent set, ZINC, has a lower synthesizability rate of 60.8%. The ChEMBL data set has

a higher rate of 68.3%; although it contains larger and more complex structures than does

ZINC, many have been synthesized previously; among those that cannot be synthesized are

natural products that were extracted, not synthesized, and tested for their biological activ-

ity. ChEMBL also contains several directly purchasable compounds, second only to Sheridan

et al.’s data set of 1730 compounds. Unsurprisingly, the exhaustively enumerated data set,

GDB17, has the lowest rate of synthesizability at only 3.5%. We also ﬁnd that the predicted

number of reaction steps is correlated with expert-provided scores (Figure S14). From these

trends and the high success rate of the MOSES database, we conclude that ASKCOS’s ret-

rosynthetic analyses are largely consistent with our expectations of synthesizability and it is

appropriate to use its predictions to benchmark the evaluation of molecular generation.

Agreement between synthesizability heuristics and ASKCOS

We next evaluate the agreement between several heuristic synthesizability scores (length

of SMILES, SA Score, 31 and SCScore 20) and the results of ASKCOS. Because retrosyn-

thetic analysis can be time consuming (tens to hundreds of CPU-seconds), we would prefer

to bias generation by heuristics rather than by a CASP oracle (cf. Figure 1). Figure 2c-e

show the trend of synthesizability of structures in diﬀerent range of SA Score, SCScore, and

SMILES string length. None of them can distinguish the synthesizable and unsynthesizable

compounds perfectly, but all exhibit a decreasing trend as the heuristic score increase. The

trend is clearest for the SA Score, followed by the SMILES length and then the SCScore.

This ordering is quantiﬁed in Figure S3, which shows the area under the receiver operating

characteristic as if these heuristics were being used for binary classiﬁcation. The AUC val-

ues for the three methods in this order are 0.87, 0.69, and 0.61. The slight shoulder around

5.5-6.0 is the contribution from the structurally complex but commercially available com-

7

Figure 2: The synthesizability analysis of common data sets, distribution learning, and
popular heuristics. (a) the number of synthetic steps required to produce random sampled
structures from each data set; (b) the number of synthetic steps required to produce molecules
generated by distribution learning algorithms, trained on either MOSES or ChEMBL; (c-e)
the fraction of synthesizable compounds from each dataset binned by heuristic score and the
number of molecules scored within each bin (excluding GDB).

pounds, highlighting the diﬀerence between synthetic complexity and structural complexity

as discussed in ref. 20.

8

Synthesizability of unoptimized generated molecules

As alluded to above, distribution learning methods are capable of generating “unopti-

mized” molecules that share properties (in aggregate) with the database used for training.

Here, we evaluate methods implemented in the MOSES 26 benchmarking set, which cover di-

verse approaches to the molecular generation problem: a SMILES long short-term memory

(LSTM) model, a variational auto-encoder (VAE), and an adversarial auto-encoder (AAE)

(see Methods). There are more deep learning approaches for molecular generation and op-

timization than can be compared here, 11 so we focus on these top-performing classes of

approaches. In this task, we can use post hoc ﬁltering or training set biasing by separately

training distribution learning models on ChEMBL (less synthesizable) and MOSES (more

synthesizable).

Figure 2b shows the fraction of synthesizable molecules from 300 generated by each

distribution learning method trained on the ChEMBL and MOSES. We observe that the

fraction of synthesizable molecules are comparable to that of the training set, while no

method improves synthesizability relative to its training set. The stark diﬀerence between

results using MOSES and ChEMBL suggests that a priori biasing by training on a “more

synthesizable” data set is a viable approach for distribution learning algorithms. There is

no one method particularly superior than others. The high fraction of synthesizable results

further suggests that post hoc ﬁltering is not necessarily a bad approach (i.e., relatively few

generated molecules would fail a check for synthesizability). Note these results pertain only

to the synthesizability of generated results and do not consider previously evaluated metrics

of novelty, uniqueness and diversity as do Polykovskiy et al.’s analyses. 26

Synthesizability of optimized generated molecules

Our next analyses focus on goal-directed benchmarks, which reﬂect the actual use-case

for generative models. Here, we re-evaluate the methods and objective functions evaluated

by Brown et al.’s Guacamol 27 in terms of their synthesizability. As detailed in the Methods,

9

Figure 3: Dependence of goal-directed optimization performance on heuristic biasing by the
SA Score using ChEMBL as the training database. Each row represents result from one
generative method; each column represents one objective function. In each plot, the green
solid line represents the change of fraction of synthesizable compounds in the top-100 with
the green dashed line as a reference for the synthesizability of the training set (ChEMBL).
Red solid lines represent the change in the objective function value of the top synthesizable
molecule, while the dashed red line represents the change in objective function value of the
top molecule, regardless of its synthesizability. Plots without a solid red line indicates that
no synthesizable structure was obtained in the top 100 molecules; dashed red lines may be
occluded by solid red lines.

this includes three generative algorithms (SMILES LSTM, SMILES GA, and Graph GA)

and 14 multi-property objective functions (MPOs) that convert a molecular structure to a

scalar ﬁtness score. As a baseline method, we include a virtual screening approach, “Best

from Data”, where all candidates from either ChEMBL or MOSES are evaluated to identify

the top performers. In addition to post hoc ﬁltering and training set biasing, we can also bias

generation by modifying the objective function with a heuristic synthesizability score. We

multiply the original objective functions (normalized between 0 and 1) with a quantitative

synthesizability metric (SA Score or SCScore, also normalized between 0 and 1). More

details can be found in Methods section.

We evaluate the eﬀects of heuristic biasing both in terms of the synthesizability of sug-

gested molecules and in terms of the primary objective function value. Figure 3 shows

how these metrics change when biasing with SA Score, initially trained on ChEMBL (Fig-

ure S5 shows additional results using the SCScore/ChEMBL, SA Score/MOSES, and SC-

Score/MOSES). Compared to the synthesizability of starting set (the green dashed lines), we

10

Figure 4: Examples of molecules from goal-directed optimization that were improved by
heuristic biasing. Scores shown are the objective function values that have been normalized
(a,b) cases where no synthesizable compounds were found in the
to the interval [0, 1].
top 100 suggestions without biasing, but at least one was found with either SA Score or
SCScore biasing. (c,d) cases where the top structure found without biasing was perceived
as unsynthesizable and the use of heuristic biasing improved the objective function value of
the top synthesizable structure.

can see the synthesizability varies between diﬀerent methods and objectives. Indeed, the to-

tal fraction of synthesizable compounds in all methods for “hard” objectives without biasing

is 30.2% with ChEMBL and 32.7% with MOSES (see Figure S6 for more details), excluding

the direct sampling from data set. Compared to distribution learning, the goal-directed gen-

eration methods are less sensitive to the starting set of molecular compounds. For several

tasks (Figure S6), very few or no compounds in the top 100 are synthesizable in the absence

11

BH2NNH2NONHIHSHONHNHBBBBSHSOPNHNOONHOHNONNOONHOOHNNHOOOHNHNFFFFFFNNNNONHHNOFFFFNONHSNHHNSNHNFFNOFOONH2NHONHONONONHNOONHOOHOOONFHNNNHNNOClFHNNNHNNOClOHNOONNOONNHNNNOOOa  SMILES GA on Osimertinib MPOd  Graph GA on Deco Hopc  Graph GA on Valsartan SMARTSb  Graph GA on Sitagliptin MPOUnbiasedTop unsynthesizable: 0.881None synthesizable in top 100Biased by SA_ScoreTop synthesizable: 0.837 (-0.044)Biased by SCScoreTop synthesizable: 0.793 (-0.088)UnbiasedTop unsynthesizable: 0.843None synthesizable in top 100Biased by SA_ScoreTop synthesizable: 0.602 (-0.241)Biased by SCScoreTop synthesizable: 0.697 (-0.146)UnbiasedTop unsynthesizable: 0.986UnbiasedTop synthesizable: 0.699 (-0.287)Biased by SA_ScoreTop synthesizable: 0.963 (-0.023)Biased by SCScoreTop synthesizable: 0.596 (-0.390)UnbiasedTop unsynthesizable: 0.938UnbiasedTop synthesizable: 0.938 (-0.000)Biased by SA_ScoreTop synthesizable: 0.991 (+0.053)Biased by SCScoreTop synthesizable: 0.892 (-0.046)of heuristic biasing, particularly when using the genetic algorithms, illustrating the risk of

relying on a post hoc ﬁltering strategy. Examples in Figure 4ab illustrate cases where no

molecule in the top 100 is synthesizable and heuristic biasing is required to generate even

a single feasible candidate. The compounds remaining after ﬁltering for synthesizability, if

any, may have low objective function values.

Most cases in Figure 3 show that the synthesizability of the top 100 compounds after

biasing is quite high, often exceeding the rate for ChEMBL. Generally speaking, the SA Score

performs better than SCScore (Figure S5): the overall synthesizability for hard objectives was

improved from 30.2% to 80.2% or 55.4% when biasing by SA Score or SCScore, respectively,

originally trained on ChEMBL (Table 1). This successful result validates the approach shown

in Figure 1e, but the increased synthesizability comes at the expense of the objective function

value of the top candidate. For some tasks decreases by over 0.2–a signiﬁcant diﬀerence for

these benchmark tasks. However, we note that the value of an in silico objective function is

completely inconsequential if the molecule cannot be made and experimentally tested.

Table 1: Fraction of synthesizable compounds in the top-100 candidates across all goal-
directed optimization tasks and all methods, demonstrating successful heuristic biasing.

ChEMBL

Training database Task diﬃculty Unbiased Biased by SA Score Biased by SCScore
77.9%
55.4%
78.8%
58.0%

trivial
hard
trivial
hard

91.0%
80.2%
92.2%
77.2%

60.1%
30.2%
63.5%
32.7%

MOSES

A fairer comparison can be made between the objective function values of the top syn-

thesizable candidates, i.e., after post hoc ﬁltering. Figure 4cd shows two examples where the

objective of the top-1 candidate decreased, but the value of the top-1 synthesizable candidate

increased. That this is observed in some cases (also see Figure S13) suggests a practical work-

ﬂow for molecular optimization:

if only a few synthesizable candidates (1-10) are desired,

ﬁrst optimize without biasing and ﬁlter unsynthesizable suggestions; if the top synthesizable

candidates are worse than the top unsynthesizable candidates, repeat the optimization while

biasing with the SA score.

12

Discussion of other approaches

As described in Figure 1, there are more ways to improve synthesizability of de novo

molecular generation algorithms. One promising approach is to bias the generation using

a full CASP tool to evaluate synthesizability, instead of a proxy score (Figure 1f). The

advantages are already described above; the disadvantage is the computational expense.

While ASKCOS ﬁnds pathways in a few seconds for some molecules, we spend up to one

minute evaluating each molecule to reduce the number of false negatives.

Benchmarking for molecular optimization, in addition to neglecting synthesizability, has

largely neglected the number of objective function calls and computational expense. When

using genetic algorithms for molecular optimization, we would ﬁrst select high scoring synthe-

sizable compounds as the initial set to propagate from a pool of up to millions of structures

(∼ 106) and then score, at each of hundreds of iterations (∼ 103), hundreds of child com-

pounds (∼ 103). In total, we would require millions or at least hundreds of thousands of

calls to the CASP oracle. Reinforcement-learning-based optimization methods that out-

perform Bayesian optimization when using VAEs require one oracle call per iteration, but

require hundreds of thousands or millions of iterations (e.g., MolDQN reports the use of

200k function calls 32). One study by Korovina et al., who propose a method described in

the next paragraph, highlight several existing methods that all require ≥ 5 thousand evalu-

ations for a single task compared to their 100. Based on the machine learning community’s

broader interest in improving the sample eﬃciency of reinforcement learning algorithms 34

(thus fewer times calling the oracle) and CASP tools becoming faster, the use of an explicit

retrosynthetic planner during optimization may become a computationally viable strategy.

The ﬁnal approach (Figure 1g) is to embed synthesizability constraints in the generation

algorithm itself, i.e., constrain the search space to molecules that can be produced from

available building blocks. As early as 2003, Vinkers et al. describe the iterative optimiza-

tion of molecular structure by selecting building blocks to react with a growing molecular

structure. 35 More recently, Bradshaw et al. 36 propose a model called MoleculeChef that gen-

13

erates a bag of reactants and uses a forward reaction prediction software to obtain the ﬁnal

products. Korovina et al.’s ChemBO similarly treats molecular generation as a random walk

on a directed (synthetic) graph where each node is a molecule, and the parents of this node

are the reagents that produce the child molecule when combined. 33 These techniques are

philosophically aligned with our use of retrosynthetic analysis to evaluate synthesizability–

both try to use our collective knowledge of chemical reactivity to dictate what reactions are

possible–but operate in the forward synthetic direction. This makes them subject to the

same caveats that any CASP tool is subject to: their validity is entirely dependent on the

accuracy of their forward reaction prediction engine, which can use either hand-coded rules

or algorithmically-inferred rules. The greater the number of synthetic steps we allow, the

lower the chances that each reaction will proceed as predicted. As this is essentially how

virtual libraries are constructed, we would expect a similar rate of success (anecdotally, 85%

successful delivery of compounds from a library enumerated with a single synthetic step).

Nevertheless, as the search space is directly constrained by these rules, they may enable a

more eﬃcient exploration of chemical space. We expect such algorithms to rapidly grow in

popularity as the accuracy of reaction prediction tools improves. 37,38

Conclusion

In this paper, we describe an analysis of the synthesizability of de novo generative algo-

rithms. We ﬁrst examined common chemical compound libraries and used ASKCOS to eval-

uate their synthesizability. We next evaluated molecules proposed by distribution learning

and goal-directed generation methods, with and without biasing by heuristic synthesizability

metrics. Distribution learning methods, provided they can learn the chemical distribution

of the training set well, seem to generate molecules that are synthesizable with a similar

frequency to their training set. Goal-directed generation methods have a signiﬁcant risk of

proposing unsynthesizable structures as their top suggestions, particularly using the SMILES

14

GA or Graph GA methods, but occasionally there may be enough high-performing, synthe-

sizable molecules in the top 100 that post hoc ﬁltering (Figure 1c) is a viable strategy. In

other cases, the proposed molecules are so absurd that one immediately recognizes why

benchmarking these methods solely in terms of their objective function value is insuﬃcient

(e.g., Figure S10 and S11). Biasing generation by training set synthesizability (Figure 1d)

works for distribution learning, but does not have a noticeable eﬀect on goal-directed opti-

mization tasks. For some tasks, modifying the objective function with the SA Score leads

to candidates that outperform those obtained through post hoc ﬁltering (Figure 4cd and

Figure S13). This heuristic biasing (Figure 1e) almost always improves the synthesizability

of generated candidates, but necessarily detracts from the main objective function.

We acknowledge that the identiﬁcation of a synthetic pathway by ASKCOS is not a

necessary or suﬃcient condition for synthesizability, nor would the generation of molecular

candidates through forward synthesis prediction be a guarantee that those reactions would

work experimentally. CASP tools for retrosynthesis and forward synthesis are imperfect.

They do not capture our entire knowledge of chemical reactivity and may occasionally pro-

duce overly optimistic suggestions (e.g., with respect to selectivity). Further, the ability

of CASP programs to ﬁnd pathways is sensitive to the precise database of chemicals con-

sidered buyable and the settings one chooses for the retrosynthetic expansion. Even with

an imperfect CASP tool like ASKCOS, however, we can obtain a meaningful analysis of

synthesizability of generated molecules.

Generative models have a tremendous potential to accelerate molecular discovery. As we

improve their ability to propose synthesizable molecules–whether by improving CASP tools

for post hoc ﬁltering, developing new heuristics for synthesizability, eﬃciently sampling a

CASP oracle to bias generation with reinforcement learning, or designing new algorithms

explicitly constrained by predictions of chemical reactivity–their utility and relevance to

practical discovery projects will only increase.

15

Methods

ASKCOS

ASKCOS is an open-source software framework that integrates eﬀorts to generalize

known chemistry to new substrates by learning to apply retrosynthetic transformations,

to identify suitable reaction conditions, and to evaluate whether reactions are likely to

be successful when attempted experimentally. 4,39 Data-driven models within ASKCOS are

trained on millions of reactions from the U.S. Patent and Trademark Oﬃce (USPTO) and

Reaxys databases. The core retrosynthetic capabilities rely on the recursive application of

algorithmically-extracted reaction templates encoded as SMARTS patterns. Expansion is

parallelized using an upper conﬁdence bound tree search as detailed in the original publi-

cation. Importantly, ASKCOS has both programmatic and graphical interfaces to enable

thousands of compounds to be processed without human intervention. The program makes

extensive use of RDKit. 40

While the program oﬀers ﬂexible stopping criteria, we require starting materials to be

commercially available according to a 2018 database of molecules from eMolecules or Sigma

Aldrich with prices no greater than $100 per gram; the full list is available in the ASKCOS

codebase. This is a very strict price limit in the context of drug discovery, so it warrants

two additional comments. First, one could consider most molecules to be “commercially

available”, in that some supplier or contract research organization will agree to produce them

at some cost given suﬃcient lead time. Second, it is straightforward to modify the database

of molecules considered commercially available depending on each user’s price tolerance and

available chemical inventory.

To determine whether a molecule is “synthesizable”, we run a retrosynthetic expansion

using ASKCOS with the following expansion settings: the maximum search depth–longest

linear sequence–is 9, the maximum branching ratio–number of unique precursors to consider

at each disconnection–is 25, the maximum wall time of expansion is 60 seconds, the maximum

16

cumulative probability for target is 0.999, the maximum number of templates to apply is

1000, the maximum price for starting materials is $100/g as described above, the minimum

plausibility of reactions–evaluated by a binary classiﬁer as a “sanity check”–is 0.1. We

terminate the search as soon as a pathway is found, rather than continuing to search for a

more optimal (e.g., shorter, cheaper) pathway. All retrosynthetic analyses were carried out

in an ASKCOS server on a debian virtual machine running on Google Cloud with 8 cores,

52 GB memory, and no other background tasks.

Compound databases

• MOSES 26 is an open database included in the MOSES benchmarking platform that

evaluates distribution learning algorithms for drug discovery. The database of 1.94

million structures represents a subset of the 4.6 million in the ZINC Clean Leads

collection with molar masses of 250-350 g/mol, fewer than 8 rotatable bonds, and a

maximum XLogP of 3.5. Polykovskiy et al. ﬁltered out molecules containing charged

atoms, atoms besides C, N, S, O, F, Cl, Br, and H, cycles longer than 8 atoms, and

molecules containing “structural alerts” from medicinal chemistry ﬁlters and PAINS

ﬁlters.

• ChEMBL 28 is a regularly-updated, open access database containing a large number

of biologically-relevant compounds and associated assays (e.g., binding and ADMET).

In our experiments, we use ChEMBL release 24, which contains 15.2 million activity

measurements for 1.8 million compounds.

• ZINC 41 is an open database of commercially-available (not in-stock) compounds for

virtual screening. ZINC contains over 230 million purchasable compounds in ready-

to-dock, 3D formats. We sampled molecules from ZINC-250k, which is a widely used

subset of ZINC12 41 from G´omez-Bombarelli et al.. 42

• Sheridan et al. 17 refers to a set of 1730 unique and parseable compounds taken from

17

the 2575 unique molecules released by Merck in their paper exploring a crowdsourced

deﬁnition of molecular complexity. These molecules were drawn from various public

and Merck-internal sources as described in the original publication.

• GDB17 30 is an open database containing 166.4 billion enumerated molecules with

up to 17 heavy atoms of C, N, O, S and halogens. The enumeration started from

mathematical graphs to form skeletons, aiming to cover size ranges containing many

drugs and typical for lead compounds. We are sampling from its “Lead-like Set” of 800

thousand compounds with molar masses of 100-350 g/mol, CLogP of 1-3, and without

3- or 4-membered rings.

Molecular generation algorithms

• Random sampler is a baseline approach to molecular generation and optimization that

randomly samples molecules (with replacement) from a “training set” of known com-

pounds.

• Best from data represents the virtual screening approach to molecular optimization,

where all molecules from a “training set” of known compounds are evaluated to identify

the ones with the highest scores.

• LSTM 43 refers to a Long-Short Term Memory 44 neural network that is widely used

in natural language processing. The model is trained in an auto-regressive way to

predict the next character of a simpliﬁed molecular-input line-entry (SMILES) string.

It can be iteratively ﬁne-tuned to optimize molecules toward a speciﬁc objective using

a hill-climbing algorithm. We evaluated the implementation from ref. 27.

• VAE 42 refers to a variational autoencoder architecture that learns to construct a bidi-

rectional mapping between SMILES represented chemical space and a ﬁnite-dimensional

continuous latent space. The architecture is devised to learn a probabilistic generative

18

model as well as its posterior, respectively known as decoder and encoder. The two

parts are trained simultaneously by maximizing the evidence lower bound (ELBO) of

the marginal likelihood, ELBO(φ, θ) = Eqφ(z|x)[log pθ(x|z)] − KL(qφ(z|x)||p(z)), where

φ and θ are diﬀerential parameters and KL is the Kullback–Leibler (KL) divergence.

We evaluated the implementation from ref. 26.

• AAE 45 is another approach to train a SMILES-based encoder-decoder architecture.

Instead of KL regularization, AAE is trained with an adversarial learning regularization

that matches the posterior distribution to a prior distribution. We evaluated the

implementation from ref. 26.

• SMILES GA 46 is a population-based grammar evolution algorithm. We evaluated

Yoshikawa et al.’s model that adopted a “chromosome” with context-free grammar of

SMILES string so that crossover and mutation happens at the level of SMILES tokens.

Each “chromosome” can be decoded to a SMILES string and checked validity using .

We evaluated the implementation from ref. 27.

• Graph GA 47 is another genetic algorithm that represents molecules as graphs, rather

than relying on SMILES strings. The crossovers and mutations are performed by

altering a molecular graph directly, i.e., exchanging substructures and hand-written

substitution rules for mutation. We evaluated the implementation from ref. 27.

Objective functions for optimization

The suite of objective functions we use for goal-directed optimization were taken from

Brown et al.’s benchmarking function sets. 27 Evaluation is divided into “trivial” tasks and

“hard” tasks following the language of the original work. The trivial tasks are named as such

because almost all molecular optimization methods can perform exceedingly well on them

(thus they are not suitable for the assessment of generative models), whereas the hard tasks

19

show greater variation as a function of the method used. However, all of these objective

functions are relatively simple heuristic functions of molecular structure.

The trivial objectives we use include quantitative estimate of drug-likeness (QED); 48 a

central nervous system (CNS) MPO; 49 isomer of C7H8N2O2; and Pioglitazone MPO. The

hard objectives we use include Osimertinib MPO, Fexofenadine MPO, Ranolazine MPO,

Perindopril MPO, Amlodipine MPO, Ranolazine MPO , Sitagliptin MPO, Zaleplon MPO,

Valsartan SMARTS, Scaﬀold Hop and Decorator Hop. Some MPO tasks try to identify

molecules dissimilar to the titular molecule but with similar properties; other MPO tasks

try to identify molecules similar to the titular molecule but with “improved” druglikeness

properties. We didn’t include the benchmarks that measure the similarity to commercial drug

molecules and isomer benchmarks in hard tasks because we think they are less meaningful

for drug discovery purposes. We refer readers to the list of benchmarks in ref. 27 for a full

description of these objectives.

Biasing techniques for molecular generation

• Post hoc ﬁltering is the approach where a CASP tool is used to ﬁlter unsynthesizable

molecules suggested by an unbiased generation. We evaluate this approach by calcu-

lating the fraction of molecules that would pass the ASKCOS ﬁlter and their objective

function values.

• Training set biasing is the approach of starting with a molecule databases that has a

higher fraction of synthesizable compounds as the training set for deep learning meth-

ods or the starting pool for genetic algorithms. In this paper, we use ChEMBL (68.3%

as tested) and MOSES (89.8% as tested) as representative datasets with lower and

higher synthesizabilities, respectively. This approach can be used in both unoptimized

generation and optimized generation.

• Heuristic biasing is the approach of modifying the main objective function to penalize

20

the generation of unsynthesizable compounds. We apply a synthesizability function

multiplier, ranging from 0 to 1, to a pre-normalized objective function (also ranging

from 0 to 1). Speciﬁcally, we use a form of modiﬁed Gaussian and sigmoid function to

rescale the heuristic score x:

Modiﬁer =






1

x < µ

e− (x−µ)2

2σ

x ≥ µ

Modiﬁer = 1 −

1
1 + ea(x−b)

We performed 30 iterations of Tree Parzen Estimator (TPE) Bayesian Optimization

to determine the hyper-parameters for each score. The hyper-parameters aimed to

maximize the fraction of synthesizable suggestions times the average of the objective

function for the top 10 molecules from graph genetic algorithm. We tested the biasing

eﬀect of SA Score, SCScore, and length of SMILES string, but meaningful parameters

could not be obtained for the SMILES string heuristic. The multipliers we use are

shown in Figure S4. This approach can only be used in optimized generation.

– SA Score 31 is a popular heuristic score for quantifying synthesizability. It com-

putes a score using a fragment-contribution approach, where rarer fragments (as

judged by their abundance in the PubChem database) are taken as an indication

of lower synthesizability.

– SCScore 20 is a learned synthetic complexity score computed by as neural network

model trained on reaction data from the Reaxys database. It was designed with

synthesis planning in mind to operate on molecules resembling not just drug-like

products, but intermediates and simpler building blocks as well.

– SMILES length is a very simple heuristic that associates molecules with longer

SMILES strings as an indication of synthetic diﬃculty. The length of a SMILES

21

string correlates closely with the number of heavy atoms in a molecule (i.e., larger

molecules are harder to synthesize), but is further increased by the presence of

formal charges, ring closures, and deﬁned stereochemistry.

Acknowledgement

This work was supported by the Machine Learning for Pharmaceutical Discovery and

Synthesis consortium. We thank Mike Fortunato and Thomas Struble for assisting with

programmatic interfacing of ASKCOS. We also thank Lagnajit Pattanaik and Klavs Jensen

for commenting on the manuscript.

Supporting Information Available

The following ﬁles are available free of charge.

All code and data can be found at https://github.com/wenhao-gao/askcos_synthesizability.

Additional results can be found in the supporting information.

References

(1) Sanchez-Lengeling, B.; Aspuru-Guzik, A. Inverse molecular design using machine learn-

ing:Generative models for matter engineering. Science 2018, 361, 360–365.

(2) Zhavoronkov, A.; Ivanenkov, Y. A.; Aliper, A.; Veselov, M. S.; Aladinskiy, V. A.;

Aladinskaya, A. V.; Terentiev, V. A.; Polykovskiy, D. A.; Kuznetsov, M. D.; Asadu-

laev, A., et al. Deep learning enables rapid identiﬁcation of potent DDR1 kinase in-

hibitors. Nat. Biotechnol. 2019, 37, 1038–1040.

(3) Lyu, J.; Wang, S.; Balius, T. E.; Singh, I.; Levit, A.; Moroz, Y. S.; O’Meara, M. J.;

Che, T.; Algaa, E.; Tolmachova, K.; Tolmachev, A. A.; Shoichet, B. K.; Roth, B. L.;

22

Irwin, J. J. Ultra-large library docking for discovering new chemotypes. Nature 2019,

1.

(4) Coley, C. W.; Thomas, D. A.; Lummiss, J. A.; Jaworski, J. N.; Breen, C. P.; Schultz, V.;

Hart, T.; Fishman, J. S.; Rogers, L.; Gao, H., et al. A robotic platform for ﬂow synthesis

of organic compounds informed by AI planning. Science 2019, 365, eaax1566.

(5) Walters, W. P.; Wang, R. New Trends in Virtual Screening. J. Chem. Inf. Model 2019,

59, 3603–3604.

(6) Virshup, A. M.; Contreras-Garc´ıa, J.; Wipf, P.; Yang, W.; Beratan, D. N. Stochastic

voyages into uncharted chemical space produce a representative library of all possible

drug-like compounds. J. Am. Chem. Soc 2013, 135, 7296–7303.

(7) Lameijer, E.-W.; B¨ack, T.; Kok, J. N.; Ijzerman, A. P. Evolutionary algorithms in drug

design. Natural Computing 2005, 4, 177–243.

(8) Lewis, D. W.; Willock, D. J.; Catlow, C. R. A.; Thomas, J. M.; Hutchings, G. J. De

novo design of structure-directing agents for the synthesis of microporous solids. Nature

1996, 382, 604.

(9) Kingma, D. P.; Welling, M. Auto-encoding variational bayes. arXiv preprint

arXiv:1312.6114 2013,

(10) Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D.; Ozair, S.;

Courville, A.; Bengio, Y. Generative adversarial nets. Advances in Neural Information

Processing Systems. 2014; pp 2672–2680.

(11) Elton, D. C.; Boukouvalas, Z.; Fuge, M. D.; Chung, P. W. Deep learning for molecular

generation and optimization - a review of the state of the art. arXiv:1903.04388 [physics,

stat] 2019, arXiv: 1903.04388.

23

(12) Bjerrum, E. J.; Threlfall, R. Molecular Generation with Recurrent Neural Networks

(RNNs). arXiv:1705.04612 [cs, q-bio] 2017, arXiv: 1705.04612.

(13) Sumita, M.; Yang, X.; Ishihara, S.; Tamura, R.; Tsuda, K. Hunting for Organic

Molecules with Artiﬁcial Intelligence: Molecules Optimized for Desired Excitation En-

ergies. ACS Cent. Sci. 2018, 4, 1126–1133.

(14) Bertz, S. H. The First General Index of Molecular Complexity. J. Am. Chem. Soc.

1981, 103, 3599–3601.

(15) Ertl, P.; Schuﬀenhauer, A. Estimation of Synthetic Accessibility Score of Drug-Like

Molecules Based on Molecular Complexity and Fragment Contributions. J. Chemin-

form. 2009, 1, 8.

(16) Takaoka, Y.; Endo, Y.; Yamanobe, S.; Kakinuma, H.; Okubo, T.; Shimazaki, Y.;

Ota, T.; Sumiya, S.; Yoshikawa, K. Development of a method for evaluating drug-

likeness and ease of synthesis using a data set in which compounds are assigned scores

based on chemists’ intuition. J. Chem. Inf. Model 2003, 43, 1269–1275.

(17) Sheridan, R. P.; Zorn, N.; Sherer, E. C.; Campeau, L.-C.; Chang, C.; Cumming, J.;

Maddess, M. L.; Nantermet, P. G.; Sinz, C. J.; O´Shea, P. D. Modeling a Crowdsourced

Deﬁnition of Molecular Complexity. J. Chem. Inf. Model. 2014, 54, 1604–1616.

(18) Baba, Y.; Isomura, T.; Kashima, H. Wisdom of crowds for synthetic accessibility eval-

uation. J. Mol. Graph. Model. 2018, 80, 217–223.

(19) Li, J.; Eastgate, M. D. Current Complexity: a Tool for Assessing the Complexity of

Organic Molecules. Org. Biomol. Chem. 2015, 13, 7164–7176.

(20) Coley, C. W.; Rogers, L.; Green, W. H.; Jensen, K. F. SCScore: Synthetic complexity

learned from a reaction corpus. J. Chem. Inf. Model 2018, 58, 252–261.

24

(21) Lajiness, M. S.; Maggiora, G. M.; Shanmugasundaram, V. Assessment of the consis-

tency of medicinal chemists in reviewing sets of compounds. J. Med. Chem. 2004, 47,

4891–4896.

(22) Feng, F.; Lai, L.; Pei, J. Computational chemical synthesis analysis and pathway design.

Front. Chem. 2018, 6, 199.

(23) Podolyan, Y.; Walters, M. A.; Karypis, G. Assessing synthetic accessibility of chemical

compounds using machine learning methods. J. Chem. Inf. Model 2010, 50, 979–991.

(24) Huang, Q.; Li, L.-L.; Yang, S.-Y. RASA: a rapid retrosynthesis-based scoring method

for the assessment of synthetic accessibility of drug-like molecules. J. Chem. Inf. Model

2011, 51, 2768–2777.

(25) Bonnet, P. Is chemical synthetic accessibility computationally predictable for drug and

lead-like molecules? A comparative assessment between medicinal and computational

chemists. Eur. J. Med. Chem. 2012, 54, 679–689.

(26) Polykovskiy, D.; Zhebrak, A.; Sanchez-Lengeling, B.; Golovanov, S.; Tatanov, O.;

Belyaev, S.; Kurbanov, R.; Artamonov, A.; Aladinskiy, V.; Veselov, M.; Kadurin, A.;

Nikolenko, S.; Aspuru-Guzik, A.; Zhavoronkov, A. Molecular Sets (MOSES): A Bench-

marking Platform for Molecular Generation Models. arXiv:1811.12823 [cs, stat] 2018,

arXiv: 1811.12823.

(27) Brown, N.; Fiscato, M.; Segler, M. H. S.; Vaucher, A. C. GuacaMol: Benchmarking

Models for De Novo Molecular Design. arXiv:1811.09621 [physics, q-bio] 2018, arXiv:

1811.09621.

(28) Gaulton, A.; Bellis, L. J.; Bento, A. P.; Chambers, J.; Davies, M.; Hersey, A.; Light, Y.;

McGlinchey, S.; Michalovich, D.; Al-Lazikani, B.; Overington, J. P. ChEMBL: a large-

scale bioactivity database for drug discovery. Nucleic Acids Res. 2012, 40, D1100–

D1107.

25

(29) Sterling, T.; Irwin, J. J. ZINC 15 – Ligand Discovery for Everyone. J. Chem. Inf. Model

2015, 55, 2324–2337.

(30) Ruddigkeit, L.; van Deursen, R.; Blum, L. C.; Reymond, J.-L. Enumeration of 166

Billion Organic Small Molecules in the Chemical Universe Database GDB-17. J. Chem.

Inf. Model 2012, 52, 2864–2875.

(31) Ertl, P.; Schuﬀenhauer, A. Estimation of synthetic accessibility score of drug-like

molecules based on molecular complexity and fragment contributions. J. Cheminform.

2009, 1, 8.

(32) Zhou, Z.; Kearnes, S.; Li, L.; Zare, R. N.; Riley, P. Optimization of molecules via deep

reinforcement learning. Scientiﬁc reports 2019, 9, 1–10.

(33) Korovina, K.; Xu, S.; Kandasamy, K.; Neiswanger, W.; Poczos, B.; Schneider, J.;

Xing, E. P. ChemBO: Bayesian Optimization of Small Organic Molecules with Synthe-

sizable Recommendations. arXiv preprint arXiv:1908.01425 2019,

(34) Ortega, P. A.; Wang, J. X.; Rowland, M.; Genewein, T.; Kurth-Nelson, Z.; Pascanu, R.;

Heess, N.; Veness, J.; Pritzel, A.; Sprechmann, P., et al. Meta-learning of sequential

strategies. arXiv preprint arXiv:1905.03030 2019,

(35) Vinkers, H. M.; de Jonge, M. R.; Daeyaert, F. F. D.; Heeres, J.; Koymans, L. M. H.; van

Lenthe, J. H.; Lewi, P. J.; Timmerman, H.; Van Aken, K.; Janssen, P. A. J. SYNOPSIS:

SYNthesize and OPtimize System in Silico. J. Med. Chem. 2003, 46, 2765–2773.

(36) Bradshaw, J.; Paige, B.; Kusner, M. J.; Segler, M. H.; Hern´andez-Lobato, J. M. A

Model to Search for Synthesizable Molecules. arXiv preprint arXiv:1906.05221 2019,

(37) Coley, C. W.; Jin, W.; Rogers, L.; Jamison, T. F.; Jaakkola, T. S.; Green, W. H.; Barzi-

lay, R.; Jensen, K. F. A graph-convolutional neural network model for the prediction

of chemical reactivity. Chem. Sci. 2019, 10, 370–377.

26

(38) Schwaller, P.; Laino, T.; Gaudin, T.; Bolgar, P.; Bekas, C.; Lee, A. A. Molecular

Transformer for Chemical Reaction Prediction and Uncertainty Estimation. 2018,

(39) ASKCOS Software Repository. https://github.com/connorcoley/ASKCOS.

(40) Landrum, G. RDKit: Open-Source Cheminformatics Software. 2016,

(41) Irwin, J. J.; Sterling, T.; Mysinger, M. M.; Bolstad, E. S.; Coleman, R. G. ZINC: a free

tool to discover chemistry for biology. J. Chem. Inf. Model 2012, 52, 1757–1768.

(42) G´omez-Bombarelli, R.; Wei, J. N.; Duvenaud, D.; Hern´andez-Lobato, J. M.; S´anchez-

Lengeling, B.; Sheberla, D.; Aguilera-Iparraguirre, J.; Hirzel, T. D.; Adams, R. P.;

Aspuru-Guzik, A. Automatic chemical design using a data-driven continuous represen-

tation of molecules. ACS Cent. Sci. 2018, 4, 268–276.

(43) Segler, M. H.; Kogej, T.; Tyrchan, C.; Waller, M. P. Generating focused molecule

libraries for drug discovery with recurrent neural networks. ACS Cent. Sci. 2017, 4,

120–131.

(44) Hochreiter, S.; Schmidhuber, J. Long short-term memory. Neural Computation 1997,

9, 1735–1780.

(45) Polykovskiy, D.; Zhebrak, A.; Vetrov, D.; Ivanenkov, Y.; Aladinskiy, V.; Mamoshina, P.;

Bozdaganyan, M.; Aliper, A.; Zhavoronkov, A.; Kadurin, A. Entangled conditional

adversarial autoencoder for de novo drug discovery. Molecular pharmaceutics 2018,

15, 4398–4405.

(46) Yoshikawa, N.; Terayama, K.; Sumita, M.; Homma, T.; Oono, K.; Tsuda, K.

Population-based de novo molecule generation, using grammatical evolution. Chem.

Lett. 2018, 47, 1431–1434.

(47) Jensen, J. H. A graph-based genetic algorithm and generative model/Monte Carlo tree

search for the exploration of chemical space. Chem. Sci. 2019, 10, 3567–3572.

27

(48) Bickerton, G. R.; Paolini, G. V.; Besnard, J.; Muresan, S.; Hopkins, A. L. Quantifying

the chemical beauty of drugs. Nat. Chem. 2012, 4, 90.

(49) Wager, T. T.; Hou, X.; Verhoest, P. R.; Villalobos, A. Central nervous system multipa-

rameter optimization desirability: application in drug discovery. ACS Chem. Neurosci.

2016, 7, 767–775.

28

Supporting Information

The Synthesizability of Molecules Proposed by Generative Models
Wenhao Gao and Connor W. Coley∗

Department of Chemical Engineering, MIT, Cambridge, MA 02139

Broad Institute of Harvard and MIT, Cambridge, MA 02139
Department of Chemical and Biomolecular Engineering, Johns Hopkins University, Baltimore, MD 21218
E-mail: ccoley@mit.edu

Code

All code can be found at https://github.com/wenhao-gao/askcos_synthesizability.

Additional Results

Suitability of heuristic functions for estimating synthesizability

1

Figure S1: Illustration of the diﬃculty of applying heuristics to estimate synthesizability. Ribavirin (left) and its analogue
(right) are structurally very similar, but their syntheses would be substantially diﬀerent due to the inherent reactivity of
ribose to favor substitution at the position leading to ribavirin. The SA Score and SCScore do not reﬂect that the righthand
compound is much harder to access.

2

Figure S2: The synthetic pathway found by ASKCOS for ribavirin (left of Figure S1). By explicitly planning synthetic
routes, ASKCOS easily distinguishes between the two compounds as it cannot identify a synthetic pathway for the righthand
compound.

3

Figure S3: The receiver operating characteristic (ROC) curve obtained when using heuristic estimates of synthetic complexity
for binary classiﬁcation of molecules in the “All but GDB” compound set as synthesizable or unsynthesizable as perceived by
ASKCOS. The area under the curve (AUC) quantiﬁes the visual trends observed in Figure 2c-e. On this compound set, the
SA Score outperforms the SMILES heuristic, which outperforms the SCScore. All three are better than randomly guessing.

4

Full results of heuristics biasing in goal-directed generation

Figure S4: The scaled synthesizability multipliers used for heuristic biasing after optimizing shape parameters (µ and σ) (see
Methods).

5

6
Figure S5: Change of synthesizability and objective function with heuristic biasing. (a) Biasing with SA Score after training
on ChEMBL; (b) biasing with SCScore after training on ChEMBL; (c) biasing with SA Score after training on MOSES;
(d) biasing with SCScore after training on MOSES. Within each panel, each row represents one generative method; each
column represents one objective function. In each plot, the green solid line represents the change of fraction of synthesizable
compounds in the top-100, with the green dashed line as a reference for the synthesizability of the training set (ChEMBL
or MOSES). Red solid lines represent the change in the objective function value of the top synthesizable molecule, while the
dashed red line represents the change in objective function value of the top molecule, regardless of its synthesizability. Plots
without a solid red line indicates that no synthesizable structure was obtained in the top 100 molecules. All plots have a
dashed red line, though it might be occluded by the solid line.

Figure S6: The synthesizable fraction of top-100 candidates proposed during goal-directed optimization for “hard” optimiza-
tion tasks. (left) Without biasing; (middle) with heuristic biasing by SA Score; (right) with heuristic biasing by SCScore.
(top) using ChEMBL for initial training; (botom) using MOSES for initial training. For many tasks, ASKCOS is unable to
identify routes to a large fraction of generated molecules, particularly when using the Graph GA or SMILES GA methods.

Figure S7: The average objective function value of the top-10 synthesizable candidates, identiﬁed through post hoc ﬁltering
of the top-100 candidates proposed during goal-directed optimization for “hard” optimization tasks. (left) Without biasing;
(middle) with heuristic biasing by SA Score; (right) with heuristic biasing by SCScore. (top) using ChEMBL for initial
training; (botom) using MOSES for initial training. White squares with a value of 0.00 indicates that fewer than 10 of the
top 100 molecules were identiﬁed as synthesizable by ASKCOS. The top row showing the Best from Dataset represents a
virtual screening approach.

7

Figure S8: The synthesizable fraction of top-100 candidates proposed during goal-directed optimization for “trivial” opti-
mization tasks. (left) Without biasing; (middle) with heuristic biasing by SA Score; (right) with heuristic biasing by SCScore.
(top) using ChEMBL for initial training; (botom) using MOSES for initial training. Synthesizability is primarily an issue for
the Pioglitazone MPO task.

8

Figure S9: The average objective function value of the top-10 synthesizable candidates, identiﬁed through post hoc ﬁltering of
the top-100 candidates proposed during goal-directed optimization for “trivial” optimization tasks. (left) Without biasing;
(middle) with heuristic biasing by SA Score; (right) with heuristic biasing by SCScore. (top) using ChEMBL for initial
training; (botom) using MOSES for initial training. White squares with a value of 0.00 indicates that fewer than 10 of the
top 100 molecules were identiﬁed as synthesizable by ASKCOS. The top row showing the Best from Dataset represents a
virtual screening approach.

9

Successful cases of heuristic biasing in goal-directed generation

10

(a) SMILES GA / Ranolazine MPO / ChEMBL

(b) Graph GA / Ranolazine MPO / ChEMBL

(c) SMILES GA / Perindopril MPO / ChEMBL

(d) Graph GA / Perindopril MPO / ChEMBL
11
Figure S10: Molecules proposed during goal-directed optimization where there are no synthesizable structures proposed in
the top 100 candidates in the absence of heuristic biasing. Each row represents a particular method, objective function,
and initial training set. From left to right, we draw the best (unsynthesizable) molecule, the best synthesizable molecule
after biasing with the SA Score, and the best synthesizable molecule after biasing with the SCScore. Many of the structures
proposed by the SMILES GA and Graph GA methods are nonsensical and clearly unsynthesizable, despite achieving a high
objective function value.

(a) SMILES GA / Amlodipine MPO / ChEMBL

(b) Graph GA / Sitagliptin MPO / ChEMBL

(c) SMILES GA / Scaﬀold Hop / ChEMBL

(d) SMILES GA / Osimertinib MPO / MOSES
12
Figure S11: Molecules proposed during goal-directed optimization where there are no synthesizable structures proposed in
the top 100 candidates in the absence of heuristic biasing. Each row represents a particular method, objective function,
and initial training set. From left to right, we draw the best (unsynthesizable) molecule, the best synthesizable molecule
after biasing with the SA Score, and the best synthesizable molecule after biasing with the SCScore. Many of the structures
proposed by the SMILES GA and Graph GA methods are nonsensical and clearly unsynthesizable, despite achieving a high
objective function value.

(a) Graph GA / Fexofenadine MPO / MOSES

(b) SMILES GA / Ranolazine MPO / MOSES

(c) Graph GA / Ranolazine MPO / MOSES

(d) SMILES GA / Decoration Hop / MOSES
13
Figure S12: Molecules proposed during goal-directed optimization where there are no synthesizable structures proposed in
the top 100 candidates in the absence of heuristic biasing. Each row represents a particular method, objective function, and
initial training set. From left to right, we draw the best (unsynthesizable) molecule, the best synthesizable molecule after
biasing with the SA Score, and the best synthesizable molecule after biasing with the SCScore.

(a) SMILES LSTM / Sitagliptin MPO / ChEMBL

(b) SMILES LSTM / Ranolazine MPO / MOSES

(c) SMILES LSTM / Sitagliptin MPO / MOSES

(d) SMILES LSTM / Zaleplon MPO / MOSES

Figure S13: Molecules proposed during goal-directed optimization where the main objective function value of the top-1
synthesizable structure is improved by heuristic biasing. Each row represents a particular method, objective function, and
initial training set. From left to right, we draw the best (unsynthesizable) molecule, the best synthesizable molecule, the best
synthesizable molecule after biasing with the SA Score, and the best synthesizable molecule after biasing with the SCScore.
All cases shown here use the SMILES LSTM method.

14

Agreement between ASKCOS results and synthesizability heuristics

Figure S14: Correlation between the length of the ﬁrst synthetic pathway found by ASKCOS and expert scores assigned by
chemists in Sheridan et al.. 17 A length of 0 indicates that the molecule can be found in our database of readily-purchasable
compounds; a length of 11 indicates that no pathway was found with the ﬁxed expansion settings (see Methods).

15

Figure S15: Correlation between the length of the ﬁrst synthetic pathway found by ASKCOS using all compound datasets
and the SA Score 31 heuristic. A length of 0 indicates that the molecule can be found in our database of readily-purchasable
compounds; a length of 11 indicates that no pathway was found with the ﬁxed expansion settings (see Methods).

16

Figure S16: Correlation between the length of the ﬁrst synthetic pathway found by ASKCOS using all compound datasets
and the SCScore 20 heuristic A length of 0 indicates that the molecule can be found in our database of readily-purchasable
compounds; a length of 11 indicates that no pathway was found with the ﬁxed expansion settings (see Methods).

17

Figure S17: Correlation between the length of the ﬁrst synthetic pathway found by ASKCOS using all compound datasets and
the SMILES length heuristic A length of 0 indicates that the molecule can be found in our database of readily-purchasable
compounds; a length of 11 indicates that no pathway was found with the ﬁxed expansion settings (see Methods).

18

Figure S18: Correlation between Sheridan et al.’s meanComplexity 17 and the SA Score; 31 each compound is colored by its
synthesizability according to ASKCOS.

Figure S19: Correlation between Sheridan et al.’s meanComplexity 17 and the SCScore; 20 each compound is colored by its
synthesizability according to ASKCOS.

19

Figure S20: Correlation between Sheridan et al.’s meanComplexity 17 and the SMILES string length; each compound is
colored by its synthesizability according to ASKCOS.

20

