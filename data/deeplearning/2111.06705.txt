A compact butterfly-style silicon photonic-
electronic neural chip for hardware-efficient deep 
learning 

CHENGHAO FENG,1,2,6, JIAQI GU2,6, HANQING ZHU2, ZHOUFENG YING1,3, 
ZHENG ZHAO1,4, DAVID Z. PAN 2,*, RAY T. CHEN2,5,* 
1Microelectronics Research Center, The University of Texas at Austin, Austin, Texas 78758, USA.  
2Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, Texas 
78705, USA. 
3Alpine Optoelectronics, CA, USA. 
4Synopsys Inc., CA, USA. 
5Omega Optics, Inc., 8500 Shoal Creek Blvd., Bldg. 4, Suite 200, Austin, TX 78757, USA. 
6These authors contributed equally. 
*chenrt@austin.utexas.edu, dpan@ece.utexas.edu 

Abstract:  The  optical  neural  network  (ONN)  is  a  promising  hardware  platform  for  next-
generation  neurocomputing  due  to  its  high  parallelism,  low  latency,  and  low  energy 
consumption.  Previous  ONN  architectures  are  mainly  designed  for  general  matrix 
multiplication (GEMM), leading to unnecessarily large area cost and high control complexity. 
Here, we move beyond classical GEMM-based ONNs and propose an optical subspace neural 
network (OSNN) architecture, which trades the universality of weight representation for lower 
optical  component  usage,  area  cost,  and  energy  consumption.  We  devise  a  butterfly-style 
photonic-electronic neural chip to implement our OSNN with up to 7√ó fewer trainable optical 
components  compared  to  GEMM-based  ONNs.  Additionally,  a  hardware-aware  training 
framework is provided to minimize the required device programming precision, lessen the chip 
area, and boost the noise robustness. We experimentally demonstrate the utility of our neural 
chip in practical image recognition tasks, showing that a measured accuracy of 94.16% can be 
achieved in hand-written digit recognition tasks with 3-bit weight programming precision. 

¬© 2022 Optica Publishing Group under the terms of the Optica Publishing Group Open Access Publishing 
Agreement 

1. 

Introduction 

Deep neural networks (DNNs) have demonstrated superior performance in various intelligence 
tasks, such as image recognition, decision making, and language translation [1‚Äì4]. Hardware 
accelerators  capable  of  performing  high-speed,  energy-efficient,  and  parallel  multiply-
accumulate (MAC) operations are in high demand with the rapidly-escalating DNN model size 
and data volume. However, electronic digital hardware accelerators, including but not limited 
to graphical processing units (GPUs), field-programmable gate arrays (FPGAs) [5], and other 
digital  application-specific  integrated  circuits  (ASICs) [6],  are  inevitably  limited  by 
millisecond-level  latency,  high  energy  consumption,  excessive  heat,  and  high  interconnect 
cost [7,8]. In contrast, analog neuromorphic computing represents a paradigm shift in efficient 
DNN acceleration, significantly increasing parallelism and energy efficiency [9,10].  

    The  optical  neural  network  (ONN)  is  a  promising  analog  artificial  intelligence  (AI) 
accelerator that features low latency, wide bandwidth, and high parallelism of light [11‚Äì15]. 
Earlier work has presented a range of high-performance integrated photonic neural networks 
that  implement  multi-layer  perceptrons  (MLPs) [11,16,17] or  convolutional neural  networks 
(CNNs)  [18,19]. The fundamental matrix-vector multiplication (MVM) unit is realized using 
Mach-Zehnder interferometer (MZI) arrays or microring-resonator (MRR) arrays. By tuning 
the phase shifters in MZIs or the transmission of MRRs, these photonic systems are designed 

to  implement  universal  linear  operations  or  general  matrix  multiplication  (GEMM)  with  a 
relatively  high  requirement  in  device  control  precision.  Recent  studies  show  that  the 
construction of DNNs can move beyond conventional GEMM with restricted matrix parameter 
space,  e.g.,  low-rank  NNs [20‚Äì22]  and  structured  NNs [23‚Äì25],  which  shows  not  only 
considerable hardware efficiency improvement but also comparable representability to classical 
GEMM-based  NNs.  We  refer  to  such  NN  architectures  as  subspace  neural  networks.    The 
success of such a design  concept can  be reproduced in ONNs by trading the universality of 
weight  representation  for  higher  hardware  efficiency.  Several  structured  ONNs  have  been 
proposed to reduce the number of optical components, e.g., the fast-Fourier-transform-based 
(FFT-based) ONN [26‚Äì28]. In this work, we further explore this subspace NN design concept 
in  the  optical  domain  and  experimentally  demonstrate  a  novel  butterfly-style  photonic-
electronic neural chip (BPNC) with superior hardware efficiency and compactness.  

    Additionally,  noise-tolerant  ONN  training  currently  still  lacks  an  efficient,  scalable,  and 
physically-evaluated solution.  As is the case with  other  analog computing platforms, ONNs 
will  inevitably  encounter  performance  degradation  or  even  malfunction  due  to  non-ideal 
factors,  e.g.,  process  variations [29,30],  limited  control  precision [31,32],  and  dynamic 
noises [33]. Recently, on-chip training has become an appealing trend towards noise-resilient 
ONNs. Numerous on-chip training algorithms have been proposed to directly optimize optical 
devices with in-situ noise handling [34‚Äì39]. However, prior ONN on-chip training protocols 
suffer  from  algorithmic  inefficiency  and  require  costly  hardware  overhead,  e.g.,  phase 
field 
detection [34],  high-resolution  optical  component  control [35],  or  per-device 
monitoring [34,39].  Therefore,  applying  them  to  practical  ONN  training  is  still  technically 
challenging.  

    In  this  work,  we  propose  an  OSNN  for next-generation hardware-efficient  deep  learning. 
Our  proposed  OSNN  partitions  each  layer‚Äôs  weight  matrix  into  smaller  ùëò √ó ùëò  ( ùëò =4,8) 
submatrices  with  restricted  parameter  space.  Our  architecture  can  achieve  photonic  neural 
computing  with  7 √ó  fewer  trainable  optical  components  compared  to  MZI-based  ONN 
architectures designed for general MVMs [11], resulting in a 3.3√ó smaller footprint and 5.5√ó 
lower latency. The number of trainable optical components can be further reduced by ~70% 
using structured circuit pruning [40] with negligible (<0.2%) task performance loss.  Moreover, 
an  efficient  and  scalable  hardware-aware  training  framework  is  experimentally  deployed  to 
enable ONN training with high noise robustness and low control precision requirement. Our 
OSNN is then experimentally demonstrated on a  4√ó4  BPNC and evaluated  on  the MNIST 
hand-written  digits  classification  task [41]  with  a  measured  accuracy  of  94.16%.  Our 
performance analysis reveals that our OSNN can achieve a computational density of ~225 tera 
(10E+12)  operations  per  second/mm2  (TOPS/mm2)  and  energy  efficiency  of  ~9.5  TOPS/W 
using compact optical devices, e.g., microdisk-based active devices [42]. Our proposed OSNN 
architecture  and  hardware-aware  training  framework  provide  a  synergistic  solution  that 
unleashes the power of optics from a novel co-design perspective and pushes the limits of next-
generation efficient AI. 

2.  Optical subspace neural network 

The proposed OSNN and its training framework are depicted in Fig. 1(a). The mathematical 
representation of one layer in a typical DNN with ùëõ inputs and ùëö outputs is shown in Fig. 1(b), 
along with its hardware implementation shown in Fig. 1(c). Here we partition the ùëö √ó ùëõ weight 
matrix ùëæ into ùëö‚àó √ó ùëõ‚àó submatrices (cid:3419)ùëæ(cid:3036),(cid:3037) ‚àà ‚ÑÇ(cid:3038)√ó(cid:3038)(cid:3423)
. The input vector ùíôùíäùíè is encoded 
as  the  amplitude  of  the  optical  signals  and  will  also  be  partitioned  into ùëõ‚àó segments ùíôùíäùíè =
) .  Thus,  the  MVM  operation  can  be  expressed  using  the  block  matrix 
(ùíôùíäùíè
multiplication formula as follows, 

ùíè‚àó
ùüê , ‚Ä¶ , ùíôùíäùíè

(cid:3036)‚àà[(cid:3041)‚àó],(cid:3037)‚àà[(cid:3040)‚àó]

ùüè , ùíôùíäùíè

                                     ùíôùíêùíñùíï

(cid:4593) = ùëæùíôùíäùíè =

‚éõ
‚éú

‚éû
‚éü

.                                               Eq. (1) 

(cid:3041)‚àó
Œ£(cid:3037)(cid:2880)(cid:2869)
(cid:3041)‚àó
Œ£(cid:3037)(cid:2880)(cid:2869)

(cid:3037)
ùëæ(cid:2869),(cid:3037) ùíô(cid:3036)(cid:3041)
(cid:3037)
ùëæ(cid:2870),(cid:3037) ùíô(cid:3036)(cid:3041)

‚ãÆ

(cid:3041)‚àó
Œ£(cid:3037)(cid:2880)(cid:2869)

‚éù

(cid:3037)
ùëæ(cid:3040)‚àó,(cid:3037) ùíô(cid:3036)(cid:3041)

‚é†

    Each submatrix ùëæ(cid:3036),(cid:3037) can be decomposed as ùëæ(cid:3036),(cid:3037) = ùë©ùúÆ(cid:3036),(cid:3037)ùë∑, where ùë© and ùë∑ are both ùëò √ó ùëò 
unitary  matrices  shown  in  Fig.  1(d),  and ùúÆ(cid:3036),(cid:3037)  is  a ùëò √ó ùëò diagonal  matrix.  Here  we  use  two 
butterfly-style  programmable  photonic  integrated  circuits  (PICs),  namely,  a  butterfly-style 
transform unit (ùë© unit) and a projection unit (ùë∑ unit), to implement the unitary matrices ùë© and 
ùë∑ using  phase  shifters,  directional  couplers,  and  waveguide  crossings,  while  the  diagonal 
matrix unit (ùúÆ unit) is composed with a column of modulators. Fig. 1(d) and Fig. 1(e) show the 
photonic circuit structure of these matrix units when ùëò = 4 and ùëò = 8, respectively.  

One of the key advantages of our OSNN is that the chip footprint and the total number of 
trainable  optical  devices  are  considerably  smaller  than  previous  GEMM-based  MZI-ONN. 
Specifically,  while  an ùëò √ó ùëò MZI  array  consumes ùí™(ùëò(cid:2870)) MZIs,  our ùë© and ùë∑ units  only  use 
ùí™(ùëò log(cid:2870) ùëò) couplers and phase shifters. Besides, instead of having all devices to be trainable, 
only the ùúÆ(cid:3036),(cid:3037) units need to be trained. The ùë© and ùë∑ units will not be modified throughout the 
training and mapping processes after their desired states are accomplished by tuning the phase 
 in an ùëõ-input, 
shifters in them.  As a result, the total number of trainable optical devices is 
ùëö-output layer, significantly reducing the weight loading cost and reprogramming complexity. 

(cid:3040)(cid:3041)

(cid:3038)

Based  on  the  statistical  evaluation [43],  our  butterfly-style ùë©ùúÆùë∑ block  demonstrates  good 
flexibility and matrix expressivity by only using 1/ùëò total trainable components compared to 
MZI arrays (details in Supplementary Note 1). The ùë© and ùë∑ units in OSNN can flexibly support 
a wide range of unitary transforms. For instance, when ùëò = 4, our butterfly unit ùë© itself can 
express  80.2%  arbitrary  unitary  matrices,  and  the ùë©ùúÆùë∑ block  can  realize  64.4%  fidelity  in 
expressing  general  matrices.  As  depicted  in  Fig.  1(d),  several  commonly  used  structured 
matrices  can  be  realized  by  configuring  the  phase  shifters  in ùë© and ùë∑ units.  For  example,  a 
block-circulant matrix can be realized (Fig. 1(d(1)) when the ùë∑ unit performs optical FFT while 
the  B  unit  performs  optical  inverse  FFT  (IFFT) [23].  Furthermore,  our ùë© and ùë∑ units  can 
realize  Hadamard  transformation  (HT),  which  is  a  popular  choice  to  construct  efficient 
DNNs [44].  Detailed proves can be found  in  supplementary Notes 1 and 2.   Figure 1(d(2)) 
shows the matrix pattern when both ùë∑ and ùë© units implement HT. The superior versatility and 
expressivity of our ùë©ùúÆùë∑ units guarantee that our OSNN can have enough learning capability. 

Another  essential  property  of  our  OSNN  is  that  different ùúÆ(cid:3036),(cid:3037) units  can  share  the ùë© and ùë∑ 
units, leading to significant chip area  reduction.  Since all ùëæ(cid:3036),(cid:3037)s are constructed by the same 
ùë©, ùë∑ transforms, ùë© and ùë∑ units can be reused in the optical domain. Here, we rewrite Eq. 1 with 
matrix multiplication‚Äôs distributive and associative properties: 

                   ùíôùíêùíñùíï

(cid:4593) = ùëæùíôùíäùíè =

‚éõ
‚éú

‚éù

(cid:3041)‚àó
Œ£(cid:3037)(cid:2880)(cid:2869)
(cid:3041)‚àó
Œ£(cid:3037)(cid:2880)(cid:2869)

ùë©ùúÆ(cid:2869),(cid:3037)ùë∑ùíô(cid:3037)
ùë©ùúÆ(cid:2870),(cid:3037)ùë∑ùíôùíã

‚ãÆ

(cid:3041)‚àó
Œ£(cid:3037)(cid:2880)(cid:2869)

ùë©ùúÆ(cid:3040)‚àó,(cid:3037)ùë∑ùíôùíã‚é†

‚éû
‚éü

=

(cid:3041)‚àó
ùúÆ(cid:2869),(cid:3037)‚Ñµùíã
ùë©Œ£(cid:3037)(cid:2880)(cid:2869)
(cid:3041)‚àó
ùë©Œ£(cid:3037)(cid:2880)(cid:2869)
ùúÆ(cid:2870),(cid:3037)‚Ñµùíã
‚ãÆ
ùúÆ(cid:3040)‚àó,(cid:3037)‚Ñµùíã‚é†

(cid:3041)‚àó
ùë©Œ£(cid:3037)(cid:2880)(cid:2869)

‚éû
‚éü

‚éõ
‚éú

‚éù

,                              (Eq. 2) 

where ‚Ñµùíã = ùë∑ùíô(cid:3037). By sharing the unitary matrix units, one can implement an MVM operation 
of size ùëö √ó ùëõ with only ùëö/ùëò ùë∑ units and ùëõ/ùëò ùë© units, dramatically reducing the footprint of 
the  OSNN  compared  to  previous  FFT-based  ONN  architecture,  which  requires 
 ùë∑ and ùë© 
units [26].  The mechanism of the optical architecture shown in Fig. 1(b) can then be stated as 
follows:  First,  the  input  optical  signal  ùíôùíäùíè  is  partitioned  into  ùëõ‚àó  segments  ùíô(cid:3037) s  and  then 

(cid:3040)(cid:3041)

(cid:3038)

propagate  through  the ùë∑ units  to  generate ‚Ñµùíãs,  which  will  then  be  distributed  via  a  fanout 
network  to ùëö‚àó √ó ùëõ‚àó diagonal  matrix  units ùúÆ(cid:3036),(cid:3037)s.  After  propagating  through  the ùúÆ(cid:3036),(cid:3037) units,  the 
signals will be combined and fed into each ùë© unit with a combiner network to obtain the MVM 
result.  Finally,  as  with  all  typical  NN  architectures,  a  nonlinear  activation  unit  (ùùà unit)  is 
required to generate the output of the layer ùíôùíêùíñùíï, which has been realized by all-optical non-
linear devices or optoelectronic circuits in previous work [45,46]. In this work, we assume the 
activation functions are realized electronically. We omit details on this and do not consider its 
effects on system performance in our discussion hereinafter. 

 
 
 
 
 
 
 
 
 
 
 
Fig.  1  General  architecture  of  the  optical  subspace  neural  network  (OSNN).  The  hardware-aware  training 
framework is shown in (a). The mathematical representation of one layer in our OSNN is shown in (b), where an ùëö √ó ùëõ 
matrix is partitioned to (cid:3040)(cid:3041)
(cid:3038)(cid:3118)  blocks. The hardware representation of one layer is shown in (c), which consists of ùëõ‚àó = (cid:3041)
(cid:3038)
projection units (ùë∑ units), ùëö‚àó = (cid:3040)
 butterfly-style transform units (ùë© units), ùëö‚àó √ó ùëõ‚àó diagonal matrix units (ùúÆ units). 
(cid:3038)
The fanout network and the combiner network are used to distribute and combine the optical signals to different optical 
paths. By  setting phase  shifters  in  B units and  P  units,  several popular structured ONNs based on  (1)  Fast  Fourier 
transform  and  inverse  Fast  Fourier  transform,  (2)  Hadamard  transform,  or  (3)  other  implementable  transforms  are 
shown in (d). (e) Schematic of 4√ó4 ùë©, ùë∑, and ùúÆ units, respectively, which are the building blocks of a 4-point OSNN. 
(f) Schematic of 8√ó8 ùë©, ùë∑, and ùúÆ units, respectively, which are the building blocks of an 8-point OSNN. To train the 
OSNN, we first perform an on-chip device calibration on our OSNN. The measurement data are learned and modeled 
in  our  hardware-aware  training  flow.  Besides,  other  factors  such  as  the  precision  of  controlling  signals,  limited 
extinction ratio (ER) of input modulators, and other noises are also considered in our training engine to improve the 
accuracy and robustness of our OSNN. 

3.  Hardware-aware training framework 

 
 
 
After  manufacturing,  fabrication  variances  in  optical  components  and  dynamic  noises  will 
introduce  uncertainty  into  the  ONN.  Moreover,  the  numerical  resolution  of  implementable 
weight  matrices  is  limited  by  the  precision  of  electrical  signals  used  to  program  the  ONN. 
Consequently, the task performance will deteriorate. To remedy this robustness issue, we build 
a multi-stage hardware-aware training framework. 

The general procedures of the training framework are summarized in Fig. 1(a). First, the 
OSNN is calibrated on-chip to measure the performance of tunable components and prepare 
the  state  of  the  photonic  chip  to  approach  the  desired  transfer  matrix.  In  reality,  the  actual 
transfer matrix of the photonic neural chip deviates from the designed one due to performance 
variations of the optical components, e.g., the unbalanced splitting ratio of directional couplers. 
Second, to model the non-ideal behavior and predict the response of the real optical neural chip, 
we develop an NN-based differentiable PIC estimator (DPE) using measurement data and AI 
algorithms. Our DPE explicitly models the behavior of the real physical chip during forward 
and  gradient  backpropagation 
that  enables  gradient-based  physical-variation-aware 
optimization. The third step involves determining the DNN parameters and mapping them to 
the electrical control signals using a hardware-aware training and parameter mapping process. 
The DPE is used to efficiently emulate the real chip response to enable variation-aware gradient 
backpropagation. Quantization-aware training with dynamic noise injection techniques is used 
to  improve  the  noise  tolerance  with  limited  device  control  resolution.  Thus,  our  OSNN can 
achieve the performance target despite control precision restrictions and other non-idealities. 
More details of our hardware-aware training framework are shown in Supplementary Note 3. 
Compared  to  prior  on-chip  training  protocols  based  on  derivative-free  optimization 
algorithms [36,47‚Äì49] and gradient approximation using ideal simulation models [50], our AI-
assisted ONN learning shows considerably higher scalability and effectiveness in robust optical 
neural chip training.  

4.  Experiment 

In  this  work,  we  experimentally  demonstrate  the  practicality  of  the  OSNN  on  the  silicon 
photonics platform using a butterfly-style photonic-electronic neural chip (BPNC) capable of 
implementing 4√ó4 ùë©ùúÆùë∑ blocks in our OSNN. The layout of the chip was drawn and verified 
using Synopsys OptoDesigner, while the chip was fabricated by the Advanced Micro Foundry 
(AMF).  The  schematic  of  the  BPNC  is  shown  in  Fig.  2(a),  while  the  close-ups  of  its 
components, such as phase shifters, 50-50 directional couplers, and crossings, are depicted in 
Fig. 2(b). The unitary matrix units ùë©/ùë∑ are marked in red/green in Fig. 2(a). The active phase 
shifters in these regions support enough flexibility to realize different unitary transforms but 
note that they are not optimized as parameters during ONN training. The diagonal matrix unit 
(ùúÆ unit) is built using an array of MZI attenuators for magnitude and phase control [51].  

The  schematic  of  the  testing  setup  is  shown  in  Fig.  3.  Continuous-wave  (CW)  light  of 
different wavelengths is coupled in different input grating couplers separately. There are three 
reasons  to  use  multi-wavelength  inputs  in  our  BPNC:  First,  we  can  use  compact  resonator-
based modulators as input modulators and avoid additional hardware costs for phase control, 
which requires high-speed phase shifters. Second, phase detection at the outputs can be avoided 
using  multi-wavelength  inputs51.  Third,  multi-wavelength  inputs  eliminate  the  phase 
fluctuations of optical signals in off-chip fibers and improve the robustness of OSNN to input 
phase noises, which have been reported in other work53. More details about the weight matrix 
of  the  BPNC  when  we  use multi-wavelength  inputs  are  provided  in  Supplementary  Note  4. 
Using multi-wavelength inputs, our BPNC can express arbitrary non-negative 4√ó4  matrices 
with a surprisingly high fidelity of 92.2% (See Supplementary Note 1). The input modulators 
and phase shifters of the BPNC are programmed by a high-precision multi-channel digital-to-
analog converter (DAC). Off-chip photodetector arrays will collect the output signals, which 
will  subsequently  be  read  using  oscilloscopes  or  analog-to-digital  converters  (ADCs).  A 

microcontroller is used to write electrical signals to the DAC and read the output signals in this 
work.  The  measurement  data  are  processed  by  computers  to  train  and  implement  the  DNN 
model.  It  should  be  noted  that  current  fabrication  and  packaging  technologies  enable  the 
integration  of  electrical  circuits,  photodetectors,  and  the  laser  on  a  single  chip   [52]  with 
potentially much higher compactness,  shorter interconnect paths,  and  higher efficiency.  The 
experimental setup is described in detail in Supplementary Note 5. 

Fig. 2 Schematic of the butterfly-style silicon photonic-electronic neural chip. The micrograph of the neural chip 
is shown in (a). The input optical beams with different wavelengths are shown in different colors. The necessary optical 
components are highlighted in (b). (c) shows the schematic and the normalized transmission curve of an MZI attenuator 
in the diagonal matrix unit (ùúÆ unit). Only the attenuators in ùúÆ are programmed in training.  

Here  we  experimentally  implement  the  multi-stage  hardware-aware  training  flow  on  our 
BPNC. In the calibration stage, the performance of modulators and phase shifters in the BPNC 
are first calibrated individually, such that we can precisely control the state of active devices, 
especially  the  input  modulators  and  the  ùúÆ  matrix  (The  calibration  results  are  detailed  in 
Supplementary Note 6). The second stage is to learn desired device configurations via ONN 
training. We first program the BPNC with representative input signals and phase shifter control 
voltages and collect the corresponding outputs. The above measured input-output pairs are used 
to  train  our  differentiable  PIC  estimator  for  accurate  and  efficient  chip  response  modeling. 
Then, we embed our DPE into our  ONN training procedure  to effectively enable hardware-
aware training. Quantization-aware training and dynamic noise injection techniques are used 
during training to adapt the ONN model to limited phase shifter control resolutions and boost 
the PIC robustness to dynamic system noises.  

In this work, we construct a CNN with our  BPNC  and  benchmark its performance on a 
hand-written digits classification dataset MNIST [41]. We use MVM operations to implement 
CNNs  with  a  widely-applied  tensor  unrolling  method  (im2col) [53],  as  detailed  in 

  
 
Supplementary  Note  7.  Figure  4(a)  illustrates  the  network  structure.  Here,  large-size  tensor 
operations  are  partitioned  into  4√ó4  blocks  and  mapped  onto  our  BPNC.  When  the  voltage 
control resolution is set to 3-bit (8 attenuation levels for each MZI attenuator in the ùúÆ unit), the 
inference accuracy of the CNN reaches 94.16% in our experimental demonstration, comparable 
to  the  simulated  value  of  94.59%.  The  confusion  matrix  depicting  the  prediction  results  is 
shown in Fig. 4(b). Figure 4(c) visualizes tested output images after being convolved by learned 
kernels. Figure 4(d) shows the tested probability distribution of different hand-written digits. 
More testing results are included in Supplementary Note 8, where we evaluate the accuracy of 
OSNN with different control voltage ranges and control resolutions. They will also be discussed 
in the following section. 

Fig. 3 Experimental setup of OSNN. (a) Schematic of our OSNN test flow. The entire MVM is first partitioned into 
multiple  4√ó4  blocks,  and  each  block  is  implemented  optically  on  a  butterfly-style  photonic-electronic  neural  chip 
(BPNC).  (b)  shows  the  wire-bonded  photonic  chip  and  its  starting/ending  electrical  pin  numbers,  while  (c)  is  the 
photography of the chip testing setup. The parameters and the input signals are programmed by a multi-channel digital-
to-analog converter (DAC), while the output signals are read by the oscilloscope. Both the oscilloscope and the DAC 
are controlled by a microcontroller. The MVM results are provided to the computer for data processing in order to train 
and deploy the DNN. 

5.  Discussion  

Footprint.  Our OSNN outperforms SVD-based MZI ONN architectures [47] in the number of 
trainable devices and the footprint. Rather than deploying area-costly MZI arrays, we use basic 
optical components such as directional couplers, phase shifters, and crossings to construct the 
unitary matrix units ùë© and ùë∑. The second reason that leads to our superior compactness is that 
many ùúÆ units share the ùë© and ùë∑ units, which reduces the  chip  area  for implementing unitary 

 
 
transforms. Shown in Fig. 5(a), when the matrix size is 32√ó32, our 8-point OSNN consumes 
~3.6√ó fewer phase shifters and ~4.8√ó fewer directional couplers,  leading  to ~3.3√ó footprint 
reduction compared to SVD-based MZI ONN architectures [47] with the same matrix size and 
optical  component  selection.  Footprints  of  different  ONN  architectures  are  estimated  by 
summing  the  areas  of  their  constituent  optical  components  provided  by  the  same  foundry 
(AMF). See the detailed evaluation of the chip area in Supplementary Note 9. 

(cid:3040)(cid:3041)

(cid:3040)(cid:3041)

pruning strategies. In an ùëõ-input, ùëö-output layer, the 

The chip area or hardware cost of OSNN can be further optimized with structured circuit 
(cid:3038)(cid:3118)  diagonal matrix units can be treated 
as 
(cid:3038)(cid:3118)  parameter groups. When all of the transmission coefficients in one ùúÆ unit are zeros, this 
unit or parameter group is unnecessary and can be omitted in OSNN designs. When training 
the DNN, penalty terms encouraging  higher  sparsity  can be  added to the training objective, 
allowing  for  the  elimination  of  unneeded  ùúÆ  units  while  minimizing  task  performance 
degradation. Our simulation results indicate that more than 70% of neural connections in our 
OSNN  can  be  pruned  with  negligible  (<0.2%)  accuracy  loss  when  implementing  image 
recognition  tasks  such  as  MNIST [41]  or  FashionMNIST [54].  (Results  are  provided  in 
Supplementary Note 9). On these datasets, our pruned OSNN can save around 70% of trainable 
optical components, resulting in ~52% chip area reduction compared to unpruned OSNN. 

Fig. 4 Experimental data of digit recognition with the OSNN. (a) Structure of the CNN, the convolution is realized 
by OSNN with the im2col approach. The first convolutional layer has one input channel and 16 output channels with 
a stride of 2. The subsequent convolutional layer has 16 input/output channels with a stride of 1, and the size of the 
convolutional kernel  is 3√ó3.  After  adaptive average pooling,  we have 5√ó5√ó16=400 hidden  features,  followed by  a 
linear  classifier  with  10  outputs.  (b)  The  confusion  matrix  of  the  trained  OSNN  on  MNIST,  showing  a  measured 
accuracy of 94.16%. (c) Experimental results of convolving two input images with convolution kernels of size 3√ó3 in 
our OSNN. (d) The predicted probability distribution of our OSNN on four selected test digits in the MNIST dataset. 

 
 
 
Computational speed and energy efficiency. Our OSNN utilizes light to implement MVM 
operations,  which  outperforms  electronic  counterparts  in  both  speed  and  energy  efficiency. 
Taking  into  account  the  delay  contributed  by  high-speed  modulators  (10  ps) [42,55], 
photodetectors (10 ps) [56], ADCs (100 ps) [57], and the optical path (43.8 ps), the total delay 
required to implement a 32√ó32 MVM can reach ~164 ps, which corresponds to an operating 
frequency of around 6 GHz . Using the same component library [58], the propagation delay of 
the optical path in our OSNN is 5.5√ó less than that of an MZI-based ONN [47], as depicted in 
Fig. 5(b). The computational speed of OSNN is now constrained by optical-to-electrical (OE) 
or  electrical-to-optical  (EO)  conversion,  but  it  can  be  increased  further  by  using  all-optical 
devices as non-linear activation functions [38] (See Supplementary Note 10). 

    The total power consumption of OSNN for MVM operations is comprised of the power to 
drive the laser/modulators/photodetectors, the power to set the weight matrix, and the power to 
drive the ADCs. Numerous energy-efficient active optical components have been developed in 
recent  years.  For  instance,  the  silicon  microdisk  modulator  achieves  approximately 1  fJ  per 
bit [42]. Maintaining the weight matrix takes less than 2.5 mW per phase shifter in our AMF-
manufactured neural chip, which can be decreased to zero by setting weights with phase change 
materials  or  nano-opto-electro-mechanical  devices [59,60].  Concerning 
the  power 
consumption of ADCs, despite the availability of high-speed ADCs, the power consumption of 
ADCs is significantly higher than that of other components. For example, an 8-bit, 40 GSPS 
ADC consumes 200 mW per channel, while an 8-bit, 10 GSPS ADC consumes 39 mW per 
channel [57]. In addition, the number of trainable devices in our ùëò-point OSNN is only ùí™ (cid:4672)
(cid:4673), 
which saves energy for storing and reconfiguring weights. In comparison to ONN architectures 
designed for general MVM, where the number of programmable devices is around ùí™(ùëöùëõ) [61] 
or ùí™(max(ùëö(cid:2870), ùëõ(cid:2870))) [47], the memory cost of storing and accessing the weight matrix and the 
energy required to reconfigure corresponding active devices are also reduced by ùëò times. This 
feature of OSNN will bring considerable energy efficiency improvement when weights need to 
be  reconfigured  frequently  in  large-scale  DNNs,  where  weight  loading  takes  nontrivial 
hardware cost even with weight-stationary dataflow [62]. 

(cid:3040)(cid:3041)

(cid:3038)

Resolution analysis. Our OSNN is capable of achieving a high accuracy under low-bit control 
of  optical  components.  Prior  ONN  architectures  designed  for  general  MVMs  require  high-
precision  control  of  optical  devices  for  parameter  mapping  to  maintain  accuracy [47]. 
Otherwise, we may encounter severe task performance degradation because of large mapping 
errors [63],  which  will  quickly  accumulate  as  the  size  of  weight  matrices  or  the  number  of 
layers increases. Given that the control precision of some energy-efficient photonic tensor cores 
is only 4 or 5 bits [31], it is necessary to reduce the resolution requirement of ONN architectures 
and enhance the tolerance of quantization errors. In this study, quantization-aware training is 
applied to our OSNN to adopt the limited voltage control precision and mitigate the accuracy 
loss. In experiments, we have shown that ~94% accuracy can be achieved for digit recognition 
when  the  precision  of  the  DACs  for  controlling  the  phase  shifters  is  around  3-bit  (See 
Supplementary Note 8). What is more, low-resolution device control can also lessen the energy 
cost for weight storage, access, and reconfiguration [64]. 

Robustness.  The  robustness  of  our  OSNN  is  guaranteed  by  our  hardware-aware  training 
framework. Our AI-assisted DPE provides accurate variation modeling of static noises, e.g., 
process variations, device calibration errors, thermal crosstalk, and non-ideal extinction ratio 
of modulators. Besides, our noise-injection training algorithm further considers the impacts of 
dynamic  noises,  e.g.,  thermal  noises  from  the  laser  source  and  photodetection  noises.  The 
robustness of our architecture is evaluated by varying the signal-to-noise-ratio (SNR) of the 
inputs and the phase drifts of phase shifters in  MZI attenuators, and our analysis results are 
shown in Fig. 5(c). Thanks to our noise injection techniques, our OSNN maintains greater than 

90% average inference accuracy even when the standard deviation of input noise and phase 
drifts reach 0.1 and 0.2, respectively.  

Fig.  5  Performance  analysis  of  the  OSNN.  (a)  Normalized  area  comparison  and  (b)  normalized  optical  delay 
comparison  between  OSNN  and  MZI-based  ONN11  when  implementing  weight  matrices  of  different  sizes.  (c) 
Robustness  comparison  between  the  hardware-unaware  training  and  our proposed  hardware-aware training,  which 
includes dynamic noise injection techniques. With noise-awareness, our proposed hardware-aware training flow can 
effectively  boost  the  noise  tolerance  of  OSNN  against  various  nonideal  factors,  such  as  input  noses  and  weight-
encoding noises. As a reference, we can achieve 94.41% test accuracy with 3-bit weight programming precision using 
the ideal transfer-matrix-model of the BPNC but will suffer complete malfunction (~10%) when mapped onto the real 
chip due to the huge discrepancy between the simulation model and the manufactured chip. 

    Additionally,  the  robustness  of  our  OSNN  can  be  enhanced  with  more  reliable  optical 
components  and  more  reliable  control  circuits [65].  For  bandwidth-driven  and  robustness-
driven OSNN design, one can directly select broadband MZI with low temperature sensitivity 
as a robust variable optical attenuator (VOA). Less robust but more compact or energy-efficient 
components can also be employed, e.g., ultra-compact MRR modulators with on-chip feedback 
controls and PCM-based modulators with advanced high-endurance materials. 

Scaling and outlook. The performance metrics of the OSNN can be further improved in several 
directions. First, our OSNN is compatible with the majority of the device-level enhancement 
techniques.  For  example,  by  using  smaller  directional  couplers [66],  crossings [67],  and 
VOAs [68], the chip area of the OSNN can be optimized, resulting in a competitive computing 
density of  >200 TOPS/mm2 and energy efficiency of ~9.5 TOPS/W (See Supplementary Note 
13).  Second, massive multiplexing techniques can substantially boost the throughput of our 
architecture. Because all of the optical components in our architecture can be broadband devices, 
wavelength-division multiplexing (WDM) techniques can be applied to our architecture: If ùëò-
wavelength input signals propagate through the chip simultaneously to implement the MVM in 
parallel, the throughput and the computing density can then be improved by (ùëò-1) times over a 

 
single-wavelength OSNN. Furthermore, more circuit structures and optical components can be 
investigated to construct our OSNN. Notably, the BPNC is not the only option to implement 
ùë©ùúÆùë∑ .  For  example,  recent  work  demonstrates  that  multiport  ùëõ -to- ùëõ  directional  couplers, 
multimode interference (MMI) couplers, and diffractive cells can be utilized to build unitary 
matrices [69,70].  They  can  also  be  used  to  build  the ùë© and ùë∑ unit  to  reduce  the  chip  area. 
Finally, faster or more energy efficient EO/OE conversion techniques are demanded to improve 
the  computational  speed  and  energy  efficiency  for  data  movement  between  electrons  and 
photons, which currently restricts the performance of optical computing platforms. 

6.  Conclusion 

We  present  a  hardware-efficient  optical  subspace  neural  network  (OSNN)  architecture  with 
experimental  demonstrations  on  a  silicon  photonic  programmable  butterfly-style  photonic-
electronic  neural  chip  (BPNC).  By  exploring  optical  neurocomputing  beyond  conventional 
GEMMs with restricted weight representability, our OSNN consumes up to 7√ó fewer trainable 
optical  components  than  prior  MZI-based  ONN  architectures  designed  for  GEMMs.  This 
advantage  can  be  further  increased  to  ~23√ó using  structured  circuit  pruning  strategies  with 
negligible accuracy loss. Our proposed hardware-aware training framework efficiently models 
the  behavior  of  the  OSNN  to  help  reduce  control  precision  requirements,  enhance  noise 
robustness, and fully exploit the expressivity in the subspace. The performance of OSNN can 
be  further  improved  with  smaller  optical  components  as  well  as  faster  and  more  efficient 
EO/OE conversion techniques. Our OSNN pushes the limits of scalability and the robustness 
of  ONNs  and  creates  a  new  design  paradigm  for  next-generation  high-performance  AI 
accelerators with improved hardware efficiency. 

Reference 

1.  
2.  

3.  

4.  

5.  

6.  

7.  

8.  
9.  

Y. Lecun, Y. Bengio, and G. Hinton, "Deep learning," Nature 521, 436‚Äì444 (2015). 
A. Krizhevsky, I. Sutskever, and G. E. Hinton, "ImageNet Classification with Deep 
Convolutional Neural Networks," in Advances in Neural Information Processing 
Systems (2012), Vol. 25, pp. 1097‚Äì1105. 
D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. van den Driessche, J. 
Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. 
Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach, K. 
Kavukcuoglu, T. Graepel, and D. Hassabis, "Mastering the game of Go with deep 
neural networks and tree search," Nature 529, 484‚Äì489 (2016). 
T. Morioka, T. Iwata, T. Hori, and T. Kobayashi, "Multiscale recurrent neural 
network based language model," in Interspeech (2010), Vol. 2, pp. 1045‚Äì1048. 
E. Nurvitadhi, G. Venkatesh, J. Sim, D. Marr, R. Huang, J. Gee, H. Ong, Y. T. Liew, 
K. Srivatsan, D. Moss, S. Subhaschandra, and G. Boudoukh, "Can FPGAs Beat GPUs 
in Accelerating Next-Generation Deep Neural Networks?," Proc. 2017 ACM/SIGDA 
Int. Symp. Field-Programmable Gate Arrays (2017). 
Y.-H. Chen, T. Krishna, J. S. Emer, and V. Sze, "Eyeriss: An Energy-Efficient 
Reconfigurable Accelerator for Deep Convolutional Neural Networks," IEEE J. 
Solid-State Circuits 52, 127‚Äì138 (2017). 
R. H. Dennard, F. H. Gaensslen, Hwa-Nien Yu, V. L. Rideout, E. Bassous, and A. R. 
Leblanc, "Design Of Ion-implanted MOSFET‚Äôs with Very Small Physical 
Dimensions," Proc. IEEE 87, 668‚Äì678 (1999). 
M. M. Waldrop, "More Than Moore," Nature 530, 144‚Äì148 (2016). 
C. Li, M. Hu, Y. Li, H. Jiang, N. Ge, E. Montgomery, J. Zhang, W. Song, N. D√°vila, 
C. E. Graves, Z. Li, J. P. Strachan, P. Lin, Z. Wang, M. Barnell, Q. Wu, R. S. 

 
10.  

11.  

12.  

13.  

14.  

15.  

16.  

17.  

18.  

19.  

20.  

21.  

22.  

23.  

24.  

Williams, J. J. Yang, and Q. Xia, "Analogue signal and image processing with large 
memristor crossbars," Nat. Electron. 1, 52‚Äì59 (2018). 
P. Yao, H. Wu, B. Gao, J. Tang, Q. Zhang, and W. Zhang, "Fully hardware-
implemented memristor convolutional neural network," Nature 577, (2020). 
Y. Shen, N. C. Harris, S. Skirlo, M. Prabhu, T. Baehr-Jones, M. Hochberg, X. Sun, S. 
Zhao, H. Larochelle, D. Englund, and M. Soljaƒçiƒá, "Deep learning with coherent 
nanophotonic circuits," Nat. Photonics 11, 441‚Äì446 (2017). 
X. Lin, Y. Rivenson, N. T. Yardimci, M. Veli, Y. Luo, M. Jarrahi, and A. Ozcan, 
"All-optical machine learning using diffractive deep neural networks," Science (80-. 
). 361, 1004‚Äì1008 (2018). 
B. J. Shastri, A. N. Tait, T. F. de Lima, W. H. P. Pernice, H. Bhaskaran, C. D. Wright, 
and P. R. Prucnal, "Photonics for artificial intelligence and neuromorphic 
computing," Nat. Photonics 15, 102‚Äì114 (2020). 
Z. Ying, C. Feng, Z. Zhao, S. Dhar, H. Dalir, J. Gu, Y. Cheng, R. Soref, D. Z. Pan, 
and R. T. Chen, "Electronic-photonic arithmetic logic unit for high-speed 
computing," Nat. Commun. 11, 2154 (2020). 
C. Feng, Z. Ying, Z. Zhao, J. Gu, D. Z. Pan, and R. T. Chen, "Toward High-Speed 
and Energy-Efficient Computing: A WDM-Based Scalable On-Chip Silicon 
Integrated Optical Comparator," Laser Photon. Rev. 15, 2000275 (2021). 
A. N. Tait, T. F. Lima, E. Zhou, A. X. Wu, M. A. Nahmias, B. J. Shastri, and P. R. 
Prucnal, "Neuromorphic photonic networks using silicon photonic weight banks," 
Sci. Rep. 7, 7430 (2017). 
C. Huang, S. Fujisawa, T. F. de Lima, A. N. Tait, E. C. Blow, Y. Tian, S. Bilodeau, 
A. Jha, F. Yaman, H. T. Peng, H. G. Batshon, B. J. Shastri, Y. Inada, T. Wang, and P. 
R. Prucnal, "A silicon photonic‚Äìelectronic neural network for fibre nonlinearity 
compensation," Nat. Electron. 2021 411 4, 837‚Äì844 (2021). 
X. Xu, M. Tan, B. Corcoran, J. Wu, A. Boes, T. G. Nguyen, S. T. Chu, B. E. Little, 
D. G. Hicks, R. Morandotti, A. Mitchell, and D. J. Moss, "11 TOPS photonic 
convolutional accelerator for optical neural networks," Nature 589, 44‚Äì51 (2021). 
J. Feldmann, N. Youngblood, M. Karpov, H. Gehring, X. Li, M. Stappers, M. Le 
Gallo, X. Fu, A. Lukashchuk, A. S. Raja, J. Liu, C. D. Wright, A. Sebastian, T. J. 
Kippenberg, W. H. P. Pernice, and H. Bhaskaran, "Parallel convolutional processing 
using an integrated photonic tensor core," Nature 589, 52‚Äì58 (2021). 
E. L. Denton, W. Zaremba, J. Bruna, Y. LeCun, and R. Fergus, "Exploiting linear 
structure within convolutional networks for efficient evaluation," in Advances in 
Neural Information Processing Systems (2014), pp. 1269‚Äì1277. 
V. Lebedev, Y. Ganin, M. Rakhuba, I. Oseledets, and V. Lempitsky, "Speeding-up 
convolutional neural networks using fine-tuned CP-decomposition," in 3rd 
International Conference on Learning Representations, ICLR 2015 - Conference 
Track Proceedings (International Conference on Learning Representations, ICLR, 
2015). 
C. Tai, T. Xiao, Y. Zhang, X. Wang, and W. E, "Convolutional neural networks with 
low-rank regularization," 4th Int. Conf. Learn. Represent. ICLR 2016 - Conf. Track 
Proc. (2015). 
C. Ding, S. Liao, Y. Wang, Z. Li, N. Liu, Y. Zhuo, C. Wang, X. Qian, Y. Bai, G. 
Yuan, X. Ma, Y. Zhang, J. Tang, Q. Qiu, X. Lin, and B. Yuan, "CIRCNN: 
Accelerating and compressing deep neural networks using block-circulant weight 
matrices," in Proceedings of the Annual International Symposium on 
Microarchitecture, MICRO (ACM, 2017), Vol. Part F1312, pp. 395‚Äì408. 
Z. Li, S. Wang, C. Ding, Q. Qiu, Y. Wang, and Y. Liang, "Efficient recurrent neural 
networks using structured matrices in FPGAS," 6th Int. Conf. Learn. Represent. ICLR 
2018 - Work. Track Proc. 1‚Äì4 (2018). 

25.  

26.  

27.  

J. Gu, Z. Zhao, C. Feng, M. Liu, R. T. Chen, and D. Z. Pan, "Towards Area-Efficient 
Optical Neural Networks: An FFT-based Architecture," in 2020 25th Asia and South 
Pacific Design Automation Conference (ASP-DAC) (IEEE, 2020), Vol. 2020-Janua, 
pp. 476‚Äì481. 
J. Gu, Z. Zhao, C. Feng, M. Liu, R. T. Chen, and D. Z. Pan, "Towards Area-Efficient 
Optical Neural Networks: An FFT-based Architecture," in Proceedings of the Asia 
and South Pacific Design Automation Conference, ASP-DAC (IEEE, 2020), Vol. 
2020-Janua, pp. 476‚Äì481. 
J. Gu, Z. Zhao, C. Feng, Z. Ying, M. Liu, R. T. Chen, and D. Z. Pan, "Toward 
Hardware-Efficient Optical Neural Networks: Beyond FFT Architecture via Joint 
Learnability," IEEE Trans. Comput. Des. Integr. Circuits Syst. 40, 1796‚Äì1809 (2021). 

28.   M. Miscuglio, Z. Hu, S. Li, J. K. George, R. Capanna, H. Dalir, P. M. Bardet, P. 

Gupta, and V. J. Sorger, "Massively parallel amplitude-only Fourier neural network," 
Optica 7, 1812 (2020). 

29.   M. Nikdast, G. Nicolescu, J. Trajkovic, and O. Liboiron-Ladouceur, "Modeling 
fabrication non-uniformity in chip-scale silicon photonic interconnects," in 2016 
Design, Automation Test in Europe Conference Exhibition (DATE) (2016), pp. 115‚Äì
120. 
Y. Zhu, G. L. Zhang, B. Li, X. Yin, C. Zhuo, H. Gu, T.-Y. Ho, and U. Schlichtmann, 
"Countering Variations and Thermal Effects for Accurate Optical Neural Networks," 
in 2020 IEEE/ACM International Conference On Computer Aided Design (ICCAD) 
(2020), pp. 1‚Äì7. 

30.  

31.   M. Miscuglio and V. J. Sorger, "Photonic tensor cores for machine learning," Appl. 

Phys. Rev. 7, 031404 (2020). 
Q. Cheng, J. Kwon, M. Glick, M. Bahadori, L. P. Carloni, and K. Bergman, "Silicon 
Photonics Codesign for Deep Learning," Proc. IEEE 108, 1261‚Äì1282 (2020). 
S. Banerjee, M. Nikdast, and K. Chakrabarty, "Modeling Silicon-Photonic Neural 
Networks under Uncertainties," Proc. -Design, Autom. Test Eur. DATE 2021-Febru, 
98‚Äì101 (2021). 
T. W. Hughes, M. Minkov, Y. Shi, and S. Fan, "Training of photonic neural networks 
through in situ backpropagation and gradient measurement," Optica 5, 864 (2018). 
J. Gu, Z. Zhao, C. Feng, W. Li, R. T. Chen, and D. Z. Pan, "FLOPS: EFficient On-
Chip Learning for OPtical Neural Networks Through Stochastic Zeroth-Order 
Optimization," in 2020 57th ACM/IEEE Design Automation Conference (DAC) 
(IEEE, 2020), Vol. 2020-July, pp. 1‚Äì6. 
J. Gu, C. Feng, W. Li, R. T. Chen, and D. Z. Pan, "Efficient On-Chip Learning for 
Optical Neural Networks Through Power-Aware Sparse Zeroth-Order Optimization," 
in Proceedings of the AAAI Conference on Artificial Intelligence (2020), Vol. 35, pp. 
7583‚Äì7591. 
T. Zhang, J. Wang, Y. Dan, Y. Lanqiu, J. Dai, X. Han, X. Sun, and K. Xu, "Efficient 
training and design of photonic neural network through neuroevolution," Opt. Express 
27, 37150 (2019). 
Q. Bao, H. Zhang, Z. Ni, Y. Wang, L. Polavarapu, Z. Shen, Q. H. Xu, D. Tang, and 
K. P. Loh, "Monolayer graphene as a saturable absorber in a mode-locked laser," 
Nano Res. 4, 297‚Äì307 (2011). 
S. Pai, I. A. D. Williamson, T. W. Hughes, M. Minkov, O. Solgaard, S. Fan, and D. 
A. B. Miller, "Parallel Programming of an Arbitrary Feedforward Photonic Network," 
IEEE J. Sel. Top. Quantum Electron. 26, (2020). 
Y. Wang, W. Wen, B. Liu, D. Chiarulli, and H. H. Li, "Group Scissor: Scaling 
Neuromorphic Computing Design to Large Neural Networks," Proc. - Des. Autom. 
Conf. Part 128280, (2017). 
LECUN and Y., "THE MNIST DATABASE of handwritten digits," 

32.  

33.  

34.  

35.  

36.  

37.  

38.  

39.  

40.  

41.  

42.  

43.  

44.  

45.  

46.  

47.  

48.  

49.  

50.  

51.  

52.  

53.  

54.  

55.  

56.  

57.  

58.  

http://yann.lecun.com/exdb/mnist/ (n.d.). 
E. Timurdogan, C. M. Sorace-Agaskar, J. Sun, E. Shah Hosseini, A. Biberman, and 
M. R. Watts, "An ultralow power athermal silicon modulator," Nat. Commun. 5, 4008 
(2014). 
Y. Tian, Y. Zhao, S. Liu, Q. Li, W. Wang, J. Feng, and J. Guo, "Scalable and 
compact photonic neural chip with low learning-capability-loss," Nanophotonics 11, 
329‚Äì344 (2022). 
R. Zhao, Y. Hu, J. Dotzel, C. De Sa, and Z. Zhang, "Building Efficient Deep Neural 
Networks With Unitary Group Convolutions," in 2019 IEEE/CVF Conference on 
Computer Vision and Pattern Recognition (CVPR) (IEEE, 2019), Vol. 2019-June, pp. 
11295‚Äì11304. 
A. N. Tait, T. Ferreira de Lima, M. A. Nahmias, H. B. Miller, H.-T. Peng, B. J. 
Shastri, and P. R. Prucnal, "Silicon Photonic Modulator Neuron," Phys. Rev. Appl. 
11, 064043 (2019). 
I. Williamson, T. W. Hughes, M. Minkov, B. Bartlett, S. Pai, and S. Fan, 
"Reprogrammable Electro-Optic Nonlinear Activation Functions for Optical Neural 
Networks," IEEE J. Sel. Top. Quantum Electron. 26, (2019). 
Y. Shen, N. C. Harris, S. Skirlo, D. Englund, and M. Soljacic, "Deep learning with 
coherent nanophotonic circuits," in 2017 IEEE Photonics Society Summer Topical 
Meeting Series (SUM) (IEEE, 2017), Vol. 11, pp. 189‚Äì190. 
T. Zhang, J. Wang, Y. Dan, Y. Lanqiu, J. Dai, X. Han, X. Sun, and K. Xu, "Efficient 
training and design of photonic neural network through neuroevolution," Opt. Express 
27, 37150 (2019). 
H. Zhou, Y. Zhao, G. Xu, X. Wang, Z. Tan, J. Dong, and X. Zhang, "Chip-Scale 
Optical Matrix Computation for PageRank Algorithm," IEEE J. Sel. Top. Quantum 
Electron. 26, 1‚Äì10 (2020). 
L. G. Wright, T. Onodera, M. M. Stein, T. Wang, D. T. Schachter, Z. Hu, and P. L. 
McMahon, "Deep physical neural networks trained with backpropagation," Nat. 2022 
6017894 601, 549‚Äì555 (2022). 
D. A. B. Miller, "Analyzing and generating multimode optical fields using self-
configuring networks," Optica 7, 794 (2020). 
A. H. Atabaki, S. Moazeni, F. Pavanello, H. Gevorgyan, J. Notaros, L. Alloatti, M. T. 
Wade, C. Sun, S. A. Kruger, H. Meng, K. Al Qubaisi, I. Wang, B. Zhang, A. Khilo, 
C. V. Baiocco, M. A. Popoviƒá, V. M. Stojanoviƒá, and R. J. Ram, "Integrating 
photonics with silicon nanoelectronics for the next generation of systems on a chip," 
Nature 556, 349‚Äì353 (2018). 
S. Chetlur, C. Woolley, P. Vandermersch, J. Cohen, J. Tran, B. Catanzaro, and E. 
Shelhamer, "cuDNN: Efficient Primitives for Deep Learning," (2014). 
H. Xiao, K. Rasul, and R. Vollgraf, "Fashion-MNIST: a Novel Image Dataset for 
Benchmarking Machine Learning Algorithms," Arxiv (2017). 
E. Timurdogan, Z. Su, R.-J. Shiue, C. V. Poulton, M. J. Byrd, S. Xin, and M. R. 
Watts, "APSUNY Process Design Kit (PDKv3.0): O, C and L Band Silicon Photonics 
Component Libraries on 300mm Wafers," 2019 Opt. Fiber Commun. Conf. Exhib. 1‚Äì
3 (2019). 
L. Vivien, A. Polzer, D. Marris-Morini, J. Osmond, J. M. Hartmann, P. Crozat, E. 
Cassan, C. Kopp, H. Zimmermann, and J. M. F√©d√©li, "Zero-bias 40Gbit/s germanium 
waveguide photodetector on silicon," Opt. Express 20, 1096 (2012). 
"ADC (Analog-to-Digital converters) ‚Äì Alphacore," 
https://www.alphacoreinc.com/adc-analog-to-digital-converters/. 
S. Y. Siew, B. Li, F. Gao, H. Y. Zheng, W. Zhang, P. Guo, S. W. Xie, A. Song, B. 
Dong, L. W. Luo, C. Li, X. Luo, and G. Q. Lo, "Review of Silicon Photonics 
Technology and Platform Development," J. Light. Technol. 39, 4374‚Äì4389 (2021). 

59.   M. Wuttig, H. Bhaskaran, and T. Taubner, "Phase-change materials for non-volatile 

60.  

61.  

62.  

63.  

64.  

photonic applications," Nat. Photonics 11, 465‚Äì476 (2017). 
L. Midolo, A. Schliesser, and A. Fiore, "Nano-opto-electro-mechanical systems," Nat. 
Nanotechnol. 2018 131 13, 11‚Äì18 (2018). 
A. N. Tait, T. F. De Lima, E. Zhou, A. X. Wu, M. A. Nahmias, B. J. Shastri, and P. R. 
Prucnal, "Neuromorphic photonic networks using silicon photonic weight banks," 
Sci. Rep. 7, 7430 (2017). 
Y. H. Chen, J. Emer, and V. Sze, "Eyeriss: A Spatial Architecture for Energy-
Efficient Dataflow for Convolutional Neural Networks," Proc. - 2016 43rd Int. Symp. 
Comput. Archit. ISCA 2016 367‚Äì379 (2016). 
J. Gu, Z. Zhao, C. Feng, H. Zhu, R. T. Chen, and D. Z. Pan, "ROQ: A Noise-Aware 
Quantization Scheme Towards Robust Optical Neural Networks with Low-bit 
Controls," Proc. 2020 Des. Autom. Test Eur. Conf. Exhib. DATE 2020 1586‚Äì1589 
(2020). 
S. Han, X. Liu, H. Mao, J. Pu, A. Pedram, M. A. Horowitz, and W. J. Dally, "EIE: 
Efficient Inference Engine on Compressed Deep Neural Network," 2016 ACM/IEEE 
43rd Annu. Int. Symp. Comput. Archit. 243‚Äì254 (2016). 

67.  

66.  

65.   M. Wade, E. Anderson, S. Ardalan, P. Bhargava, S. Buchbinder, M. L. Davenport, J. 
Fini, H. Lu, C. Li, R. Meade, C. Ramamurthy, M. Rust, F. Sedgwick, V. Stojanovic, 
D. Van Orden, C. Zhang, C. Sun, S. Y. Shumarayev, C. OKeeffe, T. T. Hoang, D. 
Kehlet, R. V. Mahajan, M. T. Guzy, A. Chan, and T. Tran, "TeraPHY: A Chiplet 
Technology for Low-Power, High-Bandwidth In-Package Optical I/O," IEEE Micro 
40, 63‚Äì71 (2020). 
C. Ye and D. Dai, "Ultra-Compact Broadband 2 √ó 2 3 dB Power Splitter Using a 
Subwavelength-Grating-Assisted Asymmetric Directional Coupler," J. Light. 
Technol. 38, 2370‚Äì2375 (2020). 
H.-L. Han, H. Li, X.-P. Zhang, A. Liu, T.-Y. Lin, Z. Chen, H.-B. Lv, M.-H. Lu, X.-P. 
Liu, and Y.-F. Chen, "High performance ultra-compact SOI waveguide crossing," 
Opt. Express 26, 25602 (2018). 
C. Haffner, A. Joerg, M. Doderer, F. Mayor, D. Chelladurai, Y. Fedoryshyn, C. I. 
Roman, M. Mazur, M. Burla, H. J. Lezec, V. A. Aksyuk, and J. Leuthold, "Nano‚Äì
opto-electro-mechanical switches operated at CMOS-level voltages," Science (80-. ). 
366, 860‚Äì864 (2019). 
R. Tanomura, R. Tang, S. Ghosh, T. Tanemura, and Y. Nakano, "Robust Integrated 
Optical Unitary Converter Using Multiport Directional Couplers," J. Light. Technol. 
38, 60‚Äì66 (2020). 
H. H. Zhu, J. Zou, H. Zhang, Y. Z. Shi, S. B. Luo, N. Wang, H. Cai, L. X. Wan, B. 
Wang, X. D. Jiang, J. Thompson, X. S. Luo, X. H. Zhou, L. M. Xiao, W. Huang, L. 
Patrick, M. Gu, L. C. Kwek, and A. Q. Liu, "Space-efficient optical computing with 
an integrated chip diffractive neural network," Nat. Commun. 2022 131 13, 1‚Äì9 
(2022). 

68.  

70.  

69.  

Acknowledgments 

The  authors  acknowledge  support  from  the  Multidisciplinary  University  Research  Initiative 
(MURI) program through the Air Force Office of Scientific Research (AFOSR), monitored by 
Dr. Gernot S. Pomrenke.  

Competing interests  

The authors declare no competing interests. 

Data availability  

 
The data and codes that support the findings of this study are available from the corresponding 
author upon reasonable request.  

 
