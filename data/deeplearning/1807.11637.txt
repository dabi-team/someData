Deep Graph Laplacian Regularization for Robust Denoising of Real Images

Jin Zeng1∗

Jiahao Pang1∗

Wenxiu Sun1

Gene Cheung2

1SenseTime Research
2Department of EECS, York University
{zengjin, pangjiahao, sunwenxiu}@sensetime.com, genec@yorku.ca

9
1
0
2

y
a
M
3

]

V
C
.
s
c
[

3
v
7
3
6
1
1
.
7
0
8
1
:
v
i
X
r
a

Abstract

Recent developments in deep learning have revolution-
ized the paradigm of image restoration. However, its ap-
plications on real image denoising are still limited, due
to its sensitivity to training data and the complex nature
of real image noise.
In this work, we combine the ro-
bustness merit of model-based approaches and the learn-
ing power of data-driven approaches for real image denois-
ing. Speciﬁcally, by integrating graph Laplacian regular-
ization as a trainable module into a deep learning frame-
work, we are less susceptible to overﬁtting than pure CNN-
based approaches, achieving higher robustness to small
datasets and cross-domain denoising. First, a sparse neigh-
borhood graph is built from the output of a convolutional
neural network (CNN). Then the image is restored by solv-
ing an unconstrained quadratic programming problem, us-
ing a corresponding graph Laplacian regularizer as a prior
term. The proposed restoration pipeline is fully differen-
tiable and hence can be end-to-end trained. Experimen-
tal results demonstrate that our work is less prone to over-
ﬁtting given small training data. It is also endowed with
strong cross-domain generalization power, outperforming
the state-of-the-art approaches by a remarkable margin.

1. Introduction

Image denoising is the most fundamental image restora-
tion problem, which has been studied for decades. In or-
der to regularize its ill-posed nature, a large body of works
adopt signal priors. By adopting a certain image model,
one assumes that the original image should induce a small
value for a given model-based signal prior. Representative
priors in the literature include non-local self-similarity [5],
total variation (TV) prior [37], sparsity prior [15], graph
Laplacian regularizer [33], etc. However, these works place
their emphases to the removal of additive white Gaussian
noise (AWGN), which is unrealistic and limits their appli-
cations in practice.
In the real world, image noise stems
from multiple sources, e.g., thermal noise, shot noise, dark

∗Both authors contributed equally to this work. Jiahao Pang is the cor-

responding author.

(a) Noise Clinic.

(b) CDnCNN.
Figure 1. Results of real image denoising. (a) Noise Clinic (model-
based); (b) CDnCNN (data-driven); (c) DeepGLR (proposed). Our
method and CDnCNN are trained for Gaussian denoising.

(c) DeepGLR.

current noise, making it much more sophisticated than the
ideal AWGN.

Recent developments in deep learning have revolution-
ized the aforementioned model-based paradigm in image
restoration. Thanks to the strong learning capacity of
convolutional neural networks (CNN) to capture image
characteristics, CNN-based approaches have achieved the
state-of-the-art performance in Gaussian denoising, e.g.,
[48, 43, 40]. However, the application of deep learning
models on real noise removal remains quite challenging.
Unlike model-based approaches, CNN-based approaches
are data-driven. To learn a CNN for real image noise re-
moval, thousands of real noisy images and their noise-free
versions are necessary to characterize the correspondence
between the corrupted images and the ground-truths [50].
Unfortunately, acquiring the noise-free images is non-trivial
[46, 7], leading to limited amount of training data. In this
case, a purely data-driven approach is prone to overﬁt to
the particular characteristics of the training data. It fails on
test images with statistics different from the training images
[29], e.g., Figure 1b showcases the result of a pure data-
driven approach trained for a different domain.

Differently, model-based denoising approaches rely on
basic assumptions about the original images, which “en-
code” assumed image characteristics. Without the notion of
training, the performance of model-based denoising is gen-
erally more robust than data-driven approaches when fac-
ing the heterogeneity of natural images [13]. However, the
assumed characteristics may not perfectly hold in the real

 
 
 
 
 
 
world, hindering their performance and ﬂexibility in prac-
tice [30], e.g., the denoising result of Figure 1a.

with a focus on graph Laplacian regularization. We also
brieﬂy review a few works on graph learning.

To achieve robust denoising of real images, in this pa-
per we combine the robustness merit of model-based ap-
proaches and the powerful learning capacity of data-driven
approaches. We achieve this goal by incorporating the
graph Laplacian regularizer—a simple yet effective im-
age prior for image restoration tasks—into a deep learning
framework. Speciﬁcally, we train a CNN which takes as
input a real noisy image and outputs a set of feature maps.
Subsequently, a neighborhood graph is built from the out-
put features. The image is then denoised by solving an un-
constrained quadratic programming (QP) problem, assum-
ing that the underlying true image induces a small value of
graph Laplacian regularizer. Figure 1c shows the denoising
result of our approach, one may clearly see its superiority to
the competing methods.

The contributions of our work are as follows:

(i) We are the ﬁrst in literature to incorporate the widely
used graph Laplacian regularizer into deep neural net-
works as a fully-differentiable layer, extracting under-
lying features of the input noisy images and boosting
the performance of the subsequent restoration.

(ii) Our architecture couples the strong graph Laplacian
regularization layer—an adaptive low-pass linear ﬁl-
ter regardless of the training data—with a light-weight
CNN for pre-ﬁltering, making our approach less sus-
ceptible to overﬁtting. Moreover, by constraining the
regularization weight to prevent steep local minimum,
our pipeline is provably numerical stable.

(iii) Experimentation shows that, our approach achieves
robust real noise removal in terms of two perspectives.
Given small amount of training data, our proposal out-
performs CNN-based approaches by avoiding overﬁt-
ting. Secondly, it exhibits strong cross-domain gen-
eralization ability, e.g., our framework training for
Gaussian denoising performs reasonably well on real
image denoising.

We call our proposal deep graph Laplacian regulariza-
tion, or DeepGLR for short. This paper is organized as
follows. Related works are reviewed in Section 2. We
then present our DeepGLR denoising framework combin-
ing CNN and a differentiable graph Laplacian regulariza-
tion layer in Section 3. Section 4 presents the experimenta-
tion and Section 5 concludes our work.

2. Related Works

We ﬁrst review several deep learning models for image
restoration while focusing on image denoising. We then
turn to the review of several representative signal priors,

CNN-based image denoising: CNN-based approaches
were ﬁrst popularized in high-level vision tasks, e.g., classi-
ﬁcation [24] and detection [32], then gradually penetrated
into low-level restoration tasks such as image denoising
[48], super-resolution [12], and non-blind deblurring [47].
To address the problem of Gaussian noise removal with
CNN, Zhang et al. [48] utilize residual learning and batch
normalization to build a deep architecture, which provides
state-of-the-art results. In [21], Jain et al. propose a sim-
ple network for natural image denoising and relate it to
Markov random ﬁeld (MRF) methods. To build a CNN ca-
pable of handling several noise levels, Vemulapalli et al.
[43] employ conditional random ﬁeld (CRF) for regulariza-
tion. Other related works on denoising with CNN includes
[28, 40, 49, 26, 8], etc. Despite their good performance,
these approaches focuses on Gaussian denoising and have
strong dependency on the training data. For effective real
image denoising and enhancing, Chen et al. [7] train a CNN
to directly perform restoration on raw image data. Differ-
ently, our DeepGLR enhances the robustness of the denois-
ing pipeline, so as to achieve effective real noise removal.

Image denoising with signal priors: We hereby review
a few representative works on image denoising using sig-
nal priors. For a more complete review, we refer the read-
ers to [30]. In [5], Buades et al. assume that similar im-
age patches recur non-locally throughout an image. Such a
self-similarity assumption has been adopted in many subse-
quent proposals. One notable method, block-matching 3-D
(BM3D) [10], performs 3-D transform and Wiener ﬁltering
on the grouped similar patches. Elad et al. [15] propose K-
SVD denoising, which seeks sparse representations to de-
scribe noiseless patches with a learned dictionary. A very
recent work [45] extents this notion for real image denois-
ing, though its complexity is too high for practical usage.

Graph Laplacian regularization is a recent popular im-
age prior in the literature, e.g., [33, 16, 17]. Despite its
simplicity, graph Laplacian regularization performs reason-
ably well for many restoration tasks [30]. It assumes that
the original image, denoted as x ∈ Rm, is smooth with re-
spect to an appropriately chosen graph G. Speciﬁcally, it
imposes that the value of xTLx, i.e., the graph Laplacian
regularizer, should be small for the original image x, where
L ∈ Rm×m is the Laplacian matrix of graph G. Typically,
a graph Laplacian regularizer is employed for a quadratic
programming (QP) formulation [33, 20, 27]. Nevertheless,
choosing a proper graph for image restoration remains an
open question. In [16, 27], the authors build their graphs
from the corrupted image with simple ad-hoc rules; while
in [33], Pang et al. derive sophisticated principles for build-
ing graphs under strict conditions. Different from exist-
ing works, our DeepGLR framework constructs neighbor-

hood graphs from the CNN outputs, i.e., our graphs are
built in a data-driven manner, which learns the appropri-
ate graph connectivity for restoration directly. In [38, 4],
the authors also formulate graph Laplacian regularization
in a deep learning pipeline; yet unlike ours, their graph con-
structions are ﬁxed functions, i.e., they are not data-driven.
Learning with graphs: there exist a few works combin-
ing tools of graph theory with data-driven approaches. In
[23, 11] and subsequent works, the authors study the notion
of convolution on graphs, which enables CNNs to be ap-
plied on irregular graph kernels. In [41], Turaga et al. let a
CNN to directly output edge weights for ﬁxed graphs; while
Egilmez et al. [14] learn the graph Laplacian matrices with
a maximum a posteriori (MAP) formulation. Our work also
learns the graph structure. Different from the methodology
of existing works, we build the graphs from the learned fea-
tures of CNN for subsequent regularizations.

3. Deep Graph Laplacian Regularization

We now present our DeepGLR framework integrating
graph Laplacian regularization into CNN for real noise re-
moval. A graph Laplacian regularization layer is composed
of two modules: a graph construction module [33] and a QP
solver [2]. We ﬁrst present the details of graph Laplacian
regularization [33, 16, 20] as an image prior, then introduce
its encapsulation as a layer in a CNN.

3.1. Formulation

We start our illustration with a simple AWGN denois-
ing formulation, which will be extended to take account for
more complex cases (Section 3.3). Consider the following
image corruption model:

y = x + n,

(1)

Here x ∈ Rm is the original image or image patch (in vec-
tor form) with m pixels, while n is an additive Gaussian
noise term and y is the noisy observation. Given an appro-
priate neighborhood graph G with m vertices representing
the pixels, graph Laplacian regularization assumes the orig-
inal image x is smooth with respect to G [39]. Denoting the
edge weight connecting pixels i and j as wij, the adjacency
matrix A of graph G is an m-by-m matrix, whose (i, j)-th
entry is wij. The degree matrix of G is a diagonal matrix D
whose i-th diagonal entry is (cid:80)m
j=1 wij. Then the (combi-
natorial) graph Laplacian matrix L is a positive semideﬁnite
(PSD) matrix given by L = D−A, which induces the graph
Laplacian regularizer xTLx ≥ 0 [39].

To recover x ∈ Rm with graph Laplacian regularization,
one can formulate a maximum a posteriori (MAP) problem
as follows:

x(cid:63) = arg min

x

(cid:107)y − x(cid:107)2

2 + µ · xTLx,

(2)

where the ﬁrst term is a ﬁdelity term (negative log likeli-
hood) computing the difference between the observation y
and the recovered signal x, and the second term is the graph
Laplacian regularizer (negative log signal prior). µ ≥ 0
is a weighting parameter. For effective regularization, one
needs an appropriate graph G reﬂecting the image structure
of ground-truth x. In most works such as [33, 20, 31], it is
derived from the noisy y or a pre-ﬁltered version of y.

For illustration, we deﬁne a matrix-valued function
F(y) : Rm (cid:55)→ Rm×N , where its n-th column is denoted
as fn where fn ∈ Rm, 1 ≤ n ≤ N . Hence, applying F
to observation y maps it to a set of N length-m vectors
{fn}N
n=1. Using the same terminology in [33], the fn’s are
called exemplars. Then the edge weight wij (1 ≤ i, j ≤ m)
is computed by:

(cid:18)

wij = exp

−

dist(i, j)
2(cid:15)2

(cid:19)

,

where

dist(i, j) =

N
(cid:88)

n=1

(fn(i) − fn(j))2.

(3)

(4)

n=1.

Here fn(i) denotes the i-th element of fn.
(4) is the Eu-
clidean distance between pixels i and j in the N -dimension
feature space deﬁned by {fn}N
In practice, the fn’s
should reﬂect the characteristics of the ground-truth image
x for effective restoration. Though different works use dif-
ferent schemes to build a similarity graph G, most of them
differ only in the choice of exemplars F(y) (or the fn’s).
In [27, 22], the authors restrict the graph structure to be a
4-connected grid graph and let dist(i, j) = (y(i) − y(j))2,
which is equivalent to let F(y) = y. In [20], Hu et al. oper-
ate on overlapping patches and let F(y) be the noisy patches
similar to y. Pang et al. [33] interpret the {fn}N
n=1 as sam-
ples on a high-dimensional Riemannian manifold and de-
rive the optimal F under certain assumptions.

3.2. Graph Laplacian Regularization Layer

In contrast to existing works, we deploy graph Lapla-
cian regularization as a layer in a deep learning pipeline, by
implementing the function F with a CNN. In other words,
the corrupted observation y is fed to a CNN (denoted
as CNNF) which outputs N exemplars (or feature maps)
{fn}N

n=1.

Speciﬁcally, we perform denoising on a patch-by-patch
basis, similarly done in [33, 20, 27]. Suppose the observed
noisy image, denoted as Y, is divided into K overlapping
patches {yk}K
k=1. Instead of na¨ıvely feeding each patch to
CNNF individually then performing optimization, we feed
the whole noisy image Y to it, leading to N exemplars im-
ages of the same size as Y, denoted as {Fn}N
n=1. By do-
ing so, for the CNNF with receptive ﬁeld size as r, each
pixel i on Fn is inﬂuenced by all the pixels j on image Y

if j is in the r × r neighborhood of i. As a result, for a
larger receptive ﬁeld r, the exemplar Fn effectively takes
into account more non-local information for denoising, re-
sembling the notion of non-local means (NLM) in the clas-
sic works [5, 10].

n }N

With the exemplar images, we simply divide each of
them, say, Fn, into K overlapping patches f (k)
n ∈ Rm,
1 ≤ k ≤ K. To denoise a patch yk, we build a graph Gk
with its corresponding N exemplars {f (k)
n=1 in the way
described in Section 3.1, leading to the graph Laplacian ma-
trix Lk. Rather than a fully connected graph, we choose
the 8-connected pixel adjacency graph structure, i.e., in the
graph Gk, every pixel i is only connected to its 8 neigh-
boring pixels. Hence, the graph Laplacian Lk is sparse
with ﬁxed sparsity pattern. The graph Laplacian Lk, to-
gether with patch yk, are passed to the QP solver, which
resolves the problem (2) and outputs the denoised patch
k. By equally aggregating the denoised image patches x(cid:63)
x(cid:63)
k
(1 ≤ k ≤ K), we arrive at the denoised image (denoted by
X (cid:63)). From spectral graph theory [9], the graph Laplacian
regularization layer is always an adaptive linear low-pass
ﬁlter, regardless of the training data.

Apart from the aforementioned procedure, for practical
restoration with the graph Laplacian regularization layer,
the following ingredients are also adopted.

(i) Generation of µ: in (2), µ trades off the importance
between the ﬁdelity term and the graph Laplacian reg-
ularizer. To generate the appropriate µ’s for regu-
larization, we build a light-weight CNN (denoted as
CNNµ). Particularly, based on the corrupted image
Y, it produces a set of {µk}K
k=1 corresponding to the
patches {yk}K
k=1.

k=1, in the data term of problem (2).

(ii) Pre-ﬁltering: in many denoising literature (e.g., [30, 6,
34]), it is popular to perform a pre-ﬁltering operation
to the noisy image Y before optimization. We bor-
row this idea and implement a pre-ﬁltering step with
a light-weight CNN (denoted as CNN
(cid:98)Y ). It operates
on image Y and outputs the ﬁltered image (cid:98)Y. Hence,
instead of {yk}K
k=1, we employ the patches of (cid:98)Y, i.e.,
{(cid:98)yk}K
We call

the presented architecture which performs
restoration with a graph Laplacian regularization layer
GLRNet. Figure 2 shows its block diagram, where the graph
Laplacian regularization layer is composed of a graph con-
struction module generating graph Laplacian matrices, and
a QP solver producing denoised patches. The denoised im-
age X (cid:63) is obtained by aggregating the denoised patches.
We see that, to achieve denoising, a noisy image ﬁrst goes
through the pre-ﬁltering network CNN
It is then pro-
cessed by the graph Laplacian regularization layer, a linear
low-pass ﬁlter. As a result, our denoising framework is less

(cid:98)Y .

sensitive to the training data. Moreover, it is less affected by
the chosen structure of CNN
(cid:98)Y , as to be seen in Section 4.2.
Since the graph construction involves only elementary
functions such as exponentials, powers and arithmetic op-
erations, it is differentiable. Furthermore, from [2] the QP
solver is also differentiable with respect to its inputs. Hence,
the graph Laplacian regularization layer is fully differen-
tiable, and our denoising pipeline can be end-to-end trained.
The backward computation of the graph Laplacian regular-
ization layer, including both the graph construction and the
QP solver, is provided in the supplementary material.

3.3. Iterative Filtering

To handle the non-Gaussian property of real image noise,
we cascade T blocks of GLRNet (each block has a graph
Laplacian regularization layer) for effective restoration,
leading to our DeepGLR framework. Suppose each noise
component removed by a GLRNet follows Gaussian dis-
tribution, then the overall noise that is removed forms a
mixture of Gaussian. Ideally, it can approximate any dis-
tribution arbitrarily well [35]. Moreover, classic literature,
e.g., [15, 30, 10], also ﬁlter the noisy image iteratively to
gradually enhance the image quality. Similar to [43], all
the GLRNets in our work have the same structure and share
the same parameters. Figure 3 shows the block diagram of
DeepGLR. In Figure 3 and the following presentation, we
have removed the superscript “(cid:63)” from X (cid:63) for simplicity.

To effectively train the proposed DeepGLR framework,
we adopt a loss penalizing differences between the recov-
ered image and the ground-truth. Given the noisy image Y,
its corresponding ground-truth image X (gt) and the restora-
tion result XT , our loss function is deﬁned as the mean-
square-error (MSE) between X (gt) and XT , i.e.,

(cid:16)

Lres

X (gt), XT

(cid:17)

=

1
HW

H
(cid:88)

W
(cid:88)

(cid:16)

i=1

j=1

X (gt)(i, j)−XT (i, j)

(cid:17)2,

(5)
where H and W are the height and width of the images,
respectively. X (gt)(i, j) is the (i, j)-th pixel of X (gt), the
same for XT (i, j). Note that in our experiments, the restora-
tion loss is only applied to the output of the last cascade XT ,
i.e., only the ﬁnal restoration result is supervised.

For simplicity, we have presented our framework for de-
noising of 1-channel images. To adapt it for denoising of
color images, the ﬁrst layers of the CNNs are changed to
take 3-channel inputs, and CNN
(cid:98)Y should output 3 chan-
nels. Moreover, in the graph Laplacian regularization layer,
the 3 channels share the same graph for utilizing inter-color
correlation; while the QP solver solves for three separate
systems of linear equations then outputs a color image. We
choose to work in the YUV color space. During training,
the loss function of the 3 channels are computed. We then
take the average as the total loss.

Figure 2. Block diagram of the proposed GLRNet which employs a graph Laplacian regularization layer for image denoising.

Figure 3. Block diagram of the overall DeepGLR framework.

3.4. Numerical Stability

We hereby analyze the stability of the proposed GLR
layer which is indispensable for the stability of the entire
framework. Our denoising approach embedding the QP
solver into the processing pipeline have numerical stability
guarantee. Firstly, the problem (2) essentially boils down to
solving a system of linear equations

(I + µL) x(cid:63) = y,

(6)

where I is an identity matrix. It admits a closed-form solu-
tion x(cid:63) = (I + µL)−1 y. Thus, one can interpret x(cid:63) as a ﬁl-
tered version of noisy input y with linear ﬁlter (I + µL)−1.
As a combinatorial graph Laplacian, L is positive semidef-
inite and its smallest eigenvalue is 0 [39]. Therefore, with
µ ≥ 0, the matrix I + µL is always invertible, with the
smallest eigenvalue as λmin = 1. However, the linear sys-
tem becomes unstable for a numerical solver if I + µL has
a large condition number κ—the ratio between the largest
and the smallest eigenvalues λmax/λmin for a normal ma-
trix, assuming an l2-norm [19]. Using eigen-analysis, we
have the following theorem regarding κ.

condition number as κmax where we impose 1 + 2µdmax ≤
κmax, leading to

µ ≤

κmax − 1
2dmax

= µmax.

(8)

Hence, if CNNµ generates a value µ no greater than µmax,
then µ stays unchanged, otherwise it is truncated to µmax.
We empirically set κmax = 250 for both training and testing
to guarantee the stability of our framework.

4. Experimental Results

Extensive experiments are presented in this section. We
ﬁrst describe our adopted CNN architecture and experimen-
tal setup in details then apply our model on real image de-
noising and validate its robustness. First, it provides sat-
isfactory results when trained with very small amount of
data. Moreover, we demonstrate the strong generalization
power of our proposal, which outperforms the state-of-the-
art approaches by a remarkable margin. We use peak signal-
to-noise ratio (PSNR) which computes in logarithmic (dB)
scale as a measurement for objective evaluation.

Theorem 1. The condition number κ of I + µL satisﬁes

4.1. Network Architectures

κ ≤ 1 + 2 µ dmax,

(7)

where dmax is the maximum degree of the vertices in G.

Proof. As discussed, we know λmin = 1. By applying
the Gershgorin circle theorem [42], λmax can be upper-
bounded as follows. First, the i-th Gershgorin disc of L
has radius ri = (cid:80)
j(cid:54)=i |wij| ≤ dmax, and the center of the
disc i for I + µL is 1 + µri. From the Gershgorin circle the-
orem, the eigenvalues of I + µL have to reside in the union
of all Gershgorin discs. Hence, λmax ≤ maxi{1 + 2 µ ri},
leading to κ = λmax ≤ 1 + 2 µ dmax.

Thus, by constraining the value of the weighting param-
eter µ, we can suppress the condition number κ and ensure
a stable denoising ﬁlter. Denote the maximum allowable

Our framework does not limit the choices of network ar-
chitecturesand one has the freedom in designing the speci-
ﬁcations of CNNF, CNNµ and CNN
(cid:98)Y . In our experiment,
we choose the networks shown in Figure 4. Speciﬁcally,

(i) CNNF: To generate exemplars {fn}N

n=1, we adopt
the popular hour-glass structure for CNNF which has
an encoder and a decoder with skip-connections [36].
Similar to [33], we use N = 3 exemplars to build the
graphs.

(ii) CNN

(cid:98)Y : The pre-ﬁltered image (cid:98)Y is simply generated
by a light-weight CNN with 4 convolution layers us-
ing a residual learning structure [18].

(iii) CNNµ: The weighting parameter µ is estimated on a
patch-by-patch basis. Our experiments uses patch size

Figure 4. Network architectures of CNNF, CNN
orange.

(cid:98)Y and CNNµ in the experiments. Data produced by the decoder of CNNF is colored in

Figure 5. The 10 scenes of the RENOIR dataset [3] used for real image denoising.

of 26 × 26 for denoising. Hence, starting from a noisy
patch, it has undergone 4 convolution layers with 2×2
max pooling and 2 fully-connected layers, leading to
the parameter µ.

Except for the last convolution layers of CNNF and CNN
(cid:98)Y ,
and the two deconvolution layers of CNNF, all the rest net-
work layers shown in Figure 4 are followed by a ReLU(·)
activation function. Note that the input image can have dif-
ferent sizes as long as it is a multiple of 4. For illustration,
Figure 4 shows the case when the input is of size 180 × 180.

4.2. Robust Denoising with Small Training Set

To see the robustness of our proposal, we begin with
experimenting DeepGLR with small data.
In this experi-
ment, we employ the RENOIR [3] dataset, which consists
of real low-light noisy images with the corresponding (al-
most) noise-free versions. Speciﬁcally, its subset with 40
scenes collected with a Xiaomi Mi3 smart-phone are used
in our experiments. Since some of the scenes have very low
intensities while some of the given ground-truth images are
still noisy, we remove the scenes whose ground-truths have:
(a) average intensities lower than 0.3 (assuming the inten-
sity ranges from 0 to 1); and (b) estimated PSNRs (provided
by [3]) lower than 36 dB, leading to 10 valid image pairs.
Thumbnails of the images are shown in Figure 5.

We adopt a two-fold cross validation scheme to evalu-
ate the performance of our approach on small dataset. In

each of the two trials, we perform training on one fold—
only ﬁve images—and testing on the other, then measure
the performance by the averaging of the results of both tri-
als. The 10 images are randomly split into two folds and
we repeat such two-fold cross validation process for ﬁve
times then the results are averaged. For objective evalua-
tion, peak signal-to-noise ratio (PSNR) and structural simi-
larity (SSIM) [44] are employed. During the training phase,
the noisy images, accompanied with their noise-free ver-
sions, are fed to the network for training. For both training
and testing, the overlapping patches are of size 26 × 26,
i.e., m = 262 = 676, where neighboring patches are of a
stride 22 apart. We let the batch size be 4 and the model is
trained for 200 epochs. A multi-step learning rate decay
policy, with values [1, 0.5, 0.1, 0.05, 0.01, 0.005] × 10−3,
are used, where the learning rate decreases at the begin-
ning of epochs [2, 5, 20, 50, 150]. We implement the net-
work with TensorFlow [1] on an Nvidia GeForce GTX Ti-
tan X GPU. Note that the QP solver is implemented with the
TensorFlow layer, i.e., matrix solve ls, for solving a
system of linear equations in the least squares sense.

Our DeepGLR is compared with the following ap-
proaches:
(a) CBM3D dedicated for Gaussian noise re-
moval on color image [10]1; (b) MC-WNNM designed for
real image noise removal [46]; (c) Noise clinic [25] also

1For testing with CBM3D, we estimate the equivalent noise variances

using the ground-truth and the noisy images.

(a) Ground-truth

(b) Noisy

(c) CBM3D

(d) MC-WNNM

(e) Noise Clinic

(f) CDnCNN

(h) DeepGLR-FR
Figure 6. Real image noise removal for image 35 of the RENOIR dataset with different approaches.

(i) DeepGLR-PR

(g) GLRNet

(j) DeepGLR

Table 1. Evaluation of different methods for real image denoising. The best results for each metric, except for those tested on the training
set, are highlighted in boldface.

Metric

Noisy

CBM3D MC-WNNM Noise Clinic

CDnCNN (Train)

CDnCNN (Test)

DeepGLR (Train)

DeepGLR (Test)

PSNR
SSIM

20.63
0.3081

26.08
0.6727

26.23
0.6294

27.43
0.6040

34.82
0.8852

32.79
0.8583

34.28
0.8795

32.96
0.8634

Method

designed for real image noise removal; and (d) CDnCNN
[48], a data-driven approach trained with the same dataset
as ours. Evaluation results are shown in Table 1, where
DeepGLR outperforms competing schemes by a range of
0.17–6.88 dB. More visual results are demonstrated in Fig-
ure 6, where competing schemes fail to fully remove the
noise, while DeepGLR is more satisfactory. To see the gap
between training and testing, performance on the training
set is also measured as shown in columns CDnCNN (Train)
and DeepGLR (Train) in Table 1, where CDnCNN excels in
training set but not in testing set indicating a strong overﬁt-
ting. This is because:

(i) Only 5 images are available for training in this experi-
ment, letting CDnCNN strongly overﬁt to the training
data. However, our DeepGLR is less sensitive to the
deﬁciency of the training data.

(ii) While CDnCNN is most suitable for Gaussian noise
removal (as stated in [48]), our DeepGLR adaptively
learns the suitable graphs to low-pass ﬁlter the real
noisy image, which weakens the impact of the com-
plex real noise statistics.

by CDnCNN, the resulting method is called DeepGLR-
PC (“PC” stands for pre-ﬁlter with CDnCNN); (c) CNNF
is removed, and directly use the output of CNN
(cid:98)Y as ex-
this scheme is referred
emplars for graph construction,
to as DeepGLR-FR (“FR” stands for CNNF removed);
(d) GLRNet. Evaluations are provided in Table 2, where
DeepGLR-PC provides similar performance as DeepGLR,
suggesting the GLR layer can perform effective denois-
ing, and adding extra layers to CNNF is of little use.
Moreover, DeepGLR-PC (33.03 dB) can be regarded as
a CDnCNN module (32.79 dB) with GLR as the post-
processing, indicating that GLR boosts CDnCNN’s per-
formance. Apart from DeepGLR-PC, the others provide
less satisfactory results, which is consistent with results
in Figure 6. Without the module for exemplar learning
(DeepGLR-FR), DeepGLR cannot capture the underlying
image structure; without pre-ﬁltering, the GLR layer has
limited effect (DeepGLR-PR); without iterative ﬁltering,
one GLRNet alone cannot fully remove real noise with
complicated statistics. In light of this, DeepGLR stands as
a composite of modules, each playing an irreplaceable role.

4.3. Cross-Domain Generalization

To better understand DeepGLR, we also consider sev-

eral of its variant:
(cid:98)Y
is removed, we call the resulting method DeepGLR-PR
(“PR” stands for pre-ﬁlter removed); (b) CNN
(cid:98)Y is replaced

(a) The pre-ﬁltering network CNN

We hereby evaluate the robustness of our approach in
terms of its cross-domain generalization ability. Speciﬁ-
cally, we evaluate on the RENOIR dataset with DeepGLR
and CDnCNN trained for AWGN blind denoising.

(a) Ground-truth

(e) DeepGLR
(c) Noise Clinic
Figure 7. The proposed DeepGLR trained for AWGN denoising generalizes well to real image denoising.

(d) CDnCNN

(b) Noisy

Table 2. Evaluation of different variants of DeepGLR for real im-
age denoising. The best two results for each metric are highlighted
in boldface.

Metric

DeepGLR

PSNR
SSIM

32.9593
0.8634

DeepGLR
-PR

32.33
0.8534

Variant of DeepGLR
DeepGLR
-PC

DeepGLR
-FR

GLRNet

33.025
0.8637

32.51
0.8552

32.50
0.8599

During training, we adopts the same training dataset as
CDnCNN, i.e., 432 images from BSDS500, and covers the
noise level range σ ∈ [0, 55]. The same network structure,
optimizer and learning rate settings are used for AWGN de-
noising as for real noise removal detailed in Section 4.2.

We ﬁrst evaluate AWGN blind denoising where the re-
sults, in terms of PSNR and SSIM, are shown in Table 3.
The rest 68 images from BSDS500 are adopted for evalua-
tion with noise standard deviations 15, 25, 50 with CBM3D
as the baseline method. DeepGLR has results on par with
CDnCNN, both of them surpasses CBM3D by a large mar-
gin. The results of OGLR [33] are also shown in Table 3.

More importantly, we evaluate the performance of
DeepGLR and CDnCNN on RENOIR dataset to investi-
gate their cross-domain generalization ability. For com-
parison, we include noise clinic [25] designed for real noise
removal as a baseline method. Objective performance, in
terms of PSNR and SSIM, are listed in Table 4. We see that,
DeepGLR has a PSNR performance of 30.10 dB, outper-
forming CDnCNN by 5.74 dB, and noise clinic by 1.87 dB.
Nevertheless, CDnCNN provides better results in Gaussian
noise removal as shown in Table 3. This indicates that
CDnCNN is strongly overﬁtted to the case of Gaussian
noise removal and fails to generalize to real noise, while
DeepGLR provides satisfactory denoising results.

Subjective results demonstrated in Figure 7 show the de-
noising results of two image fragments from the RENOIR
dataset. Noise clinic still has noticable noise unremoved,
and CDnCNN almost preserves most noise. In contrast, our

DeepGLR provides the best visual quality, removing the
noise while preserving the sharp edge details. The strong
domain generalization stems from robust exemplar learning
module in capturing the intrinsic image structure with pres-
ence of complex noise, boosting the denoising performance
through the GLR layer in recovering the clean image.

Table 3. Average PSNR (dB) and SSIM values for Gaussian noise
removal.

Noise

CBM3D

Method (PSNR / SSIM)
OGLR

CDnCNN

DeepGLR

15

25

50

33.49 / 0.9216

33.80 / 0.9268

33.52 / 0.9198

33.65 / 0.9259

30.68 / 0.8675

31.13 / 0.8799

30.79 / 0.8661

31.03 / 0.8797

27.35 / 0.7627

27.91 / 0.7886

27.84 / 0.7755

27.86 / 0.7924

Table 4. Evaluation of cross-domain generalization for real image
denoising. The best results are highlighted in boldface.

Method

Metric

Noisy

Noise Clinic

CDnCNN

DeepGLR

PSNR
SSIM

20.36
0.1823

27.43
0.6040

24.36
0.5206

30.10
0.8028

5. Conclusion

In this work, we incorporate graph Laplacian regulariza-
tion into a deep learning framework for real image noise
removal. Given a corrupted image, it is ﬁrst fed to a CNN,
then neighborhood graphs are constructed from the CNN
outputs on a patch-by-patch basis. The graph construction
and the denoising process is fully differentiable, hence the
overall pipeline can be end-to-end trained. We demonstrate
the robustness of the proposed framework—DeepGLR—
for real noise removal, from two different aspects. Firstly,
it demonstrates higher immunity to overﬁtting while train-
ing with small dataset. Moreover, it manifests strong cross-
domain generalization ability when training and testing data
have different statistics.

References

[1] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean,
M. Devin, S. Ghemawat, G. Irving, M. Isard, et al. Tensor-
ﬂow: A system for large-scale machine learning. In OSDI,
volume 16, pages 265–283, 2016. 6

[2] B. Amos and J. Z. Kolter. OptNet: Differentiable optimiza-
In Proceedings of In-
tion as a layer in neural networks.
ternational Conference on Machine Learning (ICML), pages
136–145. PMLR, 2017. 3, 4

[3] J. Anaya and A. Barbu. Renoir—A dataset for real low-light
noise image reduction. Journal of Visual Communication
and Image Representation, 51:144 – 154, 2018. 6
[4] J. T. Barron and B. Poole. The fast bilateral solver.

In
European Conference on Computer Vision, pages 617–632.
Springer, 2016. 3

[5] A. Buades, B. Coll, and J.-M. Morel. A non-local algorithm
In Proceedings of the IEEE Confer-
for image denoising.
ence on Computer Vision and Pattern Recognition (CVPR),
volume 2, pages 60–65. IEEE, 2005. 1, 2, 4

[6] P. Chatterjee and P. Milanfar. Patch-based near-optimal im-
IEEE Transactions on Image Processing,

age denoising.
21(4):1635–1649, 2012. 4

[7] C. Chen, Q. Chen, J. Xu, and V. Koltun. Learning to see in
the dark. In Proceedings of the IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR), pages 3291–
3300, June 2018. 1, 2

[8] C. Chen, Z. Xiong, X. Tian, and F. Wu. Deep boosting for
image denoising. In The European Conference on Computer
Vision (ECCV), September 2018. 2

[9] F. R. Chung and F. C. Graham. Spectral graph theory. Num-

ber 92. American Mathematical Soc., 1997. 4

[10] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian. Image
denoising by sparse 3-D transform-domain collaborative ﬁl-
tering. IEEE Transactions on image processing, 16(8):2080–
2095, 2007. 2, 4, 6

[11] M. Defferrard, X. Bresson, and P. Vandergheynst. Convolu-
tional neural networks on graphs with fast localized spectral
ﬁltering. In Advances in Neural Information Processing Sys-
tems, pages 3844–3852, 2016. 3

[12] C. Dong, C. C. Loy, K. He, and X. Tang. Learning a
deep convolutional network for image super-resolution. In
European Conference on Computer Vision, pages 184–199.
Springer, 2014. 2

[13] W. Dong, P. Wang, W. Yin, G. Shi, F. Wu, and X. Lu. Denois-
ing prior driven deep neural network for image restoration.
arXiv preprint arXiv:1801.06756, 2018. 1

[14] H. E. Egilmez, E. Pavez, and A. Ortega. Graph learning
from data under Laplacian and structural constraints. IEEE
Journal of Selected Topics in Signal Processing, 11(6):825–
841, 2017. 3

[15] M. Elad and M. Aharon.

Image denoising via sparse and
IEEE
redundant representations over learned dictionaries.
Transactions on Image processing, 15(12):3736–3745, 2006.
1, 2, 4

image and manifold processing. IEEE Transactions on Im-
age Processing, 17(7):1047–1060, 2008. 2, 3

[17] G. Gilboa and S. Osher. Nonlocal linear image regulariza-
tion and supervised segmentation. Multiscale Modeling &
Simulation, 6(2):595–630, 2007. 2

[18] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning
for image recognition. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition (CVPR),
pages 770–778, 2016. 5

[19] R. A. Horn and C. R. Johnson. Matrix analysis. Cambridge

University Press, 1990. 5

[20] W. Hu, G. Cheung, and M. Kazui. Graph-based dequantiza-
tion of block-compressed piecewise smooth images. IEEE
Signal Processing Letters, 23(2):242–246, 2016. 2, 3
[21] V. Jain and S. Seung. Natural image denoising with convo-
lutional networks. In Advances in Neural Information Pro-
cessing Systems, pages 769–776, 2009. 2

[22] A. Kheradmand and P. Milanfar. A general framework for
regularized, similarity-based image restoration. IEEE Trans-
actions on Image Processing, 23(12):5136–5151, 2014. 3

[23] T. N. Kipf and M. Welling. Semi-supervised classiﬁcation
with graph convolutional networks. In International Confer-
ence on Learning Representations (ICLR), 2017. 3

[24] A. Krizhevsky, I. Sutskever, and G. E. Hinton.

Imagenet
classiﬁcation with deep convolutional neural networks.
In
Advances in Neural Information Processing Systems, pages
1097–1105, 2012. 2

[25] M. Lebrun, M. Colom, and J.-M. Morel. The noise clinic:
Image Processing On

A blind image denoising algorithm.
Line, 5:1–54, 2015. 7, 8

[26] S. Lefkimmiatis. Universal denoising networks: A novel
CNN architecture for image denoising. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion (CVPR), pages 3204–3213, 2018. 2

[27] X. Liu, D. Zhai, D. Zhao, G. Zhai, and W. Gao. Progressive
image denoising through hybrid graph Laplacian regulariza-
IEEE Transactions on image
tion: A uniﬁed framework.
processing, 23(4):1491–1503, 2014. 2, 3

[28] X. Mao, C. Shen, and Y.-B. Yang.

Image restoration us-
ing very deep convolutional encoder-decoder networks with
symmetric skip connections. In Advances in Neural Infor-
mation Processing Systems, pages 2802–2810, 2016. 2
[29] M. T. McCann, K. H. Jin, and M. Unser. Convolutional
neural networks for inverse problems in imaging: A review.
IEEE Signal Processing Magazine, 34(6):85–95, 2017. 1
[30] P. Milanfar. A tour of modern image ﬁltering: New insights
IEEE Signal

and methods, both practical and theoretical.
Processing Magazine, 30(1):106–128, 2013. 2, 4

[31] S. Osher, Z. Shi, and W. Zhu. Low dimensional manifold
model for image processing. SIAM Journal on Imaging Sci-
ences, 10(4):1669–1690, 2017. 3

[32] W. Ouyang and X. Wang. Joint deep learning for pedestrian
detection. In Proceedings of the IEEE International Confer-
ence on Computer Vision (ICCV), pages 2056–2063, 2013.
2

[16] A. Elmoataz, O. Lezoray, and S. Bougleux. Nonlocal dis-
crete regularization on weighted graphs: A framework for

[33] J. Pang and G. Cheung. Graph Laplacian regularization for
image denoising: Analysis in the continuous domain. IEEE

[49] K. Zhang, W. Zuo, and L. Zhang. Ffdnet: Toward a fast
and ﬂexible solution for cnn based image denoising. IEEE
Transactions on Image Processing, 2018. 2

[50] F. Zhu, G. Chen, and P.-A. Heng. From noise modeling to
blind image denoising. In Proceedings of the IEEE Confer-
ence on Computer Vision and Pattern Recognition (CVPR),
pages 420–429, 2016. 1

Transactions on Image Processing, 26(4):1770–1785, 2017.
1, 2, 3, 5, 8

[34] J. Pang, G. Cheung, A. Ortega, and O. C. Au. Optimal
graph Laplacian regularization for natural image denoising.
In IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP), pages 2294–2298, 2015. 4
[35] D. Reynolds. Gaussian mixture models. Encyclopedia of

biometrics, pages 827–832, 2015. 4

[36] O. Ronneberger, P. Fischer, and T. Brox. U-Net: Convolu-
tional networks for biomedical image segmentation. In In-
ternational Conference on Medical Image Computing and
Computer-Assisted Intervention, pages 234–241. Springer,
2015. 5

[37] L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear total varia-
tion based noise removal algorithms. Physica D: nonlinear
phenomena, 60(1-4):259–268, 1992. 1

[38] X. Shen, X. Tao, H. Gao, C. Zhou, and J. Jia. Deep automatic
portrait matting. In European Conference on Computer Vi-
sion, pages 92–107. Springer, 2016. 3

[39] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and
P. Vandergheynst. The emerging ﬁeld of signal processing
on graphs: Extending high-dimensional data analysis to net-
works and other irregular domains. IEEE Signal Processing
Magazine, 30(3):83–98, 2013. 3, 5

[40] Y. Tai, J. Yang, X. Liu, and C. Xu. Memnet: A persistent
memory network for image restoration. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 4539–4547, 2017. 1, 2

[41] S. C. Turaga, J. F. Murray, V. Jain, F. Roth, M. Helmstaedter,
K. Briggman, W. Denk, and H. S. Seung. Convolutional net-
works can learn to generate afﬁnity graphs for image seg-
mentation. Neural Computation, 22(2):511–538, 2010. 3
[42] R. S. Varga. Gerˇsgorin and his circles, volume 36. Springer

Science & Business Media, 2010. 5

[43] R. Vemulapalli, O. Tuzel, and M.-Y. Liu. Deep Gaussian
conditional random ﬁeld network: A model-based deep net-
In Proceedings of the
work for discriminative denoising.
IEEE Conference on Computer Vision and Pattern Recog-
nition (CVPR), pages 4801–4809, 2016. 1, 2, 4

[44] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli.
Image quality assessment: From error visibility to struc-
IEEE Transactions on Image Processing,
tural similarity.
13(4):600–612, 2004. 6

[45] J. Xu, L. Zhang, and D. Zhang. A trilateral weighted sparse
coding scheme for real-world image denoising. In European
Conference on Computer Vision (ECCV), September 2018. 2
[46] J. Xu, L. Zhang, D. Zhang, and X. Feng. Multi-channel
weighted nuclear norm minimization for real color image de-
noising. In The IEEE International Conference on Computer
Vision (ICCV), Oct 2017. 1, 7

[47] L. Xu, J. S. Ren, C. Liu, and J. Jia. Deep convolutional neural
In Advances in Neural
network for image deconvolution.
Information Processing Systems, pages 1790–1798, 2014. 2
[48] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang. Be-
yond a Gaussian denoiser: Residual learning of deep CNN
for image denoising. IEEE Transactions on Image Process-
ing, 26(7):3142–3155, 2017. 1, 2, 7

