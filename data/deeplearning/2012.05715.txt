Towards Coinductive Models for Natural Language
Understanding
Bringing together Deep Learning and Deep Semantics

Wlodek Zadrozny1,2,
wzadrozn@uncc.edu
1 College of Computing, University of North Carolina at Charlotte
2 School of Data Science, University of North Carolina at Charlotte

May-November 2020; version 1.0

Abstract

This article contains a proposal to add coinduction to the computational appa-
ratus of natural language understanding. This, we argue, will provide a basis for
more realistic, computationally sound, and scalable models of natural language di-
alogue, syntax and semantics. Given that the bottom up, inductively constructed,
semantic and syntactic structures are brittle, and seemingly incapable of adequately
representing the meaning of longer sentences or realistic dialogues, natural language
understanding is in need of a new foundation. Coinduction, which uses top down
constraints, has been successfully used in the design of operating systems and pro-
gramming languages. Moreover, implicitly it has been present in text mining, machine
translation, and in some attempts to model intensionality and modalities, which pro-
vides evidence that it works. This article shows high level formalizations of some of
such uses.

Since coinduction and induction can coexist, they can provide a common language
and a conceptual model for research in natural language understanding. In particular,
such an opportunity seems to be emerging in research on compositionality. This article
shows several examples of the joint appearance of induction and coinduction in natural
language processing. We argue that the known individual limitations of induction and
coinduction can be overcome in empirical settings by a combination of the the two
methods. We see an open problem in providing a theory of their joint use.

Keywords:
semantics; compositionality; natural language processing; NLP;

coinduction; coalgebra; natural language understanding; deep learning;

0
2
0
2
c
e
D
9

]
L
C
.
s
c
[

1
v
5
1
7
5
0
.
2
1
0
2
:
v
i
X
r
a

1

 
 
 
 
 
 
Contents

1 Introduction and Motivation

1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.1.1 Motivation #1: The conceptual gap between deep neural networks and deep
semantic analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.1.2 Motivation #2: Accuracy gap for long sentences between deep learning and
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

deep semantic models

1.2 Hypothesis

2 What is coinduction? Informally.

. . . . . . . . . . . . .
2.1 Coinductive data, coinductive functions, coinductive proofs
2.2 What are coalgebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Algebras describe constructions . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.2 Coalgebras describe observations . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .

2.3 A few words about related concepts

3 Natural language processing is intuitively coinductive

3.1 Automata as a coalgebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Dialogue: why it matters that interaction is coinductive . . . . . . . . . . . . . . .
3.3 Multimodal interaction coinductively . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.1 Relating process algebras and coinduction . . . . . . . . . . . . . . . . . . .

4 NL understanding: coinduction and induction together

4.1 A motivating example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Recent examples of rules (induction) and neural networks (coinduction) working
together . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Comments and unresolved issues . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5 Not everything should be done via coinduction

5.1 Compositionality is a challenge for neural networks . . . . . . . . . . . . . . . . . .
5.2 Diﬃculties in learning algebra, arithmetic and formal reasoning . . . . . . . . . . .
5.3 Limitations of coinductive view of human cognition . . . . . . . . . . . . . . . . . .

6 Discussion and summary

1 Introduction and Motivation

2
3

3

4
7

8
9
10
10
11
13

14
14
15
16
17

18
18

19
23

24
24
25
26

26

In this article we are proposing to add coinduction 1 to the computational apparatus of
natural language semantics. This, we argue, will provide a basis for a more realistic, com-
putationally sound, and scalable model of natural language understanding. Given that
the bottom up, inductively 2 constructed, semantic structures are brittle, and seemingly
incapable of correctly representing the meanings of longer sentences or realistic dialogues,

1Throughout this article we use the term ‘coinduction’ in its most generic meaning, encompassing also

coalgebra, corecursion, and bisimulation. This terminology will be explained.

2We use the terms ‘induction’ and ‘inductive’ in their logical and mathematical sense, e.g. as in
‘deﬁnition by induction’ or ‘proof by induction,’ and not in the philosophical sense of deriving general
knowledge from speciﬁc cases, as in ‘inductive reasoning.’

2

semantics is in the need of a new foundation. Coinduction, which uses top down con-
straints, has been successfully used in the design of operating systems and programming
languages. Moreover, implicitly it has been present in text mining, machine translation,
and in some attempts to model intensionality and modalities. So, there is scattered evi-
dence it works. Since coinduction and induction can coexist, they can provide a common
language and a conceptual model for research in natural language (NL) understanding.

We elaborate on this proposal in several ways. We motivate it by discussing the
accuracy and conceptual gaps between inductive and coinductive views of NL semantics.
We introduce the coinduction, coalgebras and related concepts focusing on intuitions
and referring the reader to other works for in depth treatments. We show the natural
match between coinduction and several natural language processing (NLP) tasks such
as modeling dialogue and text mining. And we show examples of how induction and
coinduction can jointly improve the process of assigning representations to text.

We argue for the joint use of deep learning and deep semantics in natural language
understanding. Just as the tensor product allows us to jointly explore and use two diﬀerent
but related algebras or vector spaces, we imagine induction and coinduction as jointly
providing a better foundation for NL understanding. Although in the remainder of this
article we try to convey some intuitions about their joint use, the mathematical and
computational requirements for their optimal joint use are not at this point clear to us.

1.1 Motivation

Our motivation to pursue this topic comes from two sources, which we elaborate below.
The ﬁrst one is the diﬀerence in concepts used in deep learning vs. traditional seman-
tics. The second one has to do with the limitations of processing of long sentences using
the traditional semantic representation vs. the relatively successful assignment of much
shallower structures using deep learning. Our proposal to think coinductively about the
latter allows us to incorporate both methodologies within a single conceptual framework.

1.1.1 Motivation #1: The conceptual gap between deep neural networks and

deep semantic analysis

Intuitively there is a gap between using deep neural networks for natural language process-
ing (NLP) and using deep semantic analysis for natural language understanding (NLU). If
we dig deeper into this gap we might observe that their conceptual apparatus is diﬀerent.
Reading the textbooks. This can be perhaps most clearly seen in the new version of
a leading NLP textbook. Looking at Chapter 16 “Logical Representations of Sentence
Meaning”3 we notice it not sharing the vocabulary of the encoder-decoder and embedding
models introduced earlier in the book. This is not a criticism of the book: ﬁrst, this is
work on progress; second, a currently missing section might create a bridge. Our point is
that a bridge is needed.

To reverse the perspective, logical representations do not appear in deep learning
focused NLP books such as Hapke et al. [2019] and Zhang et al. [2020], and NLP doesn’t

3We are using here the manuscript from https://web.stanford.edu/~jurafsky/slp3/, version from

October 16, 2019

3

appear as topic in Goodfellow et al. [2016].

A similar gap can be seen in Bird et al. [2009], where lambda calculus and discourse
representation is avoided in the sections mentioning the applications of logistic regression
and Naive Bayes to NLP, and vice versa.

Even much earlier the problem of bridging the two views of language, one governed
by rules and the other by observations was discussed at length (e.g. Klavans and Resnik
[1996]), but arguably with little impact on the ﬁeld. Somewhat similar sentiment has been
expressed more recently in Manning [2015], commenting on capabilities of deep learning:
“really dramatic gains may only have been possible on true signal processing tasks.”

This article takes the position that such bridge should be formed by creating an
abstraction of both approaches, and not by an ad hoc combination. The value of this
abstraction could lie in informing the theory, i.e. models of meaning, but it could also
be in guiding the process of creation of better tools for human-computer interaction and
natural language understanding.

The historical analogy we might keep in mind is the creation of modern computer
architectures and operating systems (e.g. Auslander et al. [1981]), which introduced new
layers of abstraction (e.g. process streams) and new disciplines (e.g. software engineering).

What about recent research? There was no research article on Google Scholar, as of early
June 2020, mentioning “mathematics of deep learning” and “logical inference,” although
aspects of both are covered in experimental research – “deep learning” + “logical infer-
ence” produces about 800 hits. Thus, combining logical and neural model is an active area
of research. For example, Hudson and Manning [2019] presents a data set for question
answering using both scene graphs modeling of elements present in images and challenging
questions about them. In context of a diﬀerent problem, Zhang et al. [2019] discuss en-
suring factual correctness of summaries, using two models, one logical (to attend to facts)
and one neural (for reducing the size of the document). In our third example, Richardson
et al. [2020] show that neural attention based models such as BERT [Devlin et al., 2018]
can be retrained to master aspects of natural language inference. On the other hand, the
examples we present in Section 5 show that deep neural networks still seem incapable of
deeper reasoning without special purpose architectures, and even modeling elementary
arithmetical operations is a challenge.

1.1.2 Motivation #2: Accuracy gap for long sentences between deep learning

and deep semantic models

There is a gap in the accuracy between deep neural networks and deep semantic analysis,
irrespective of the fact that they try to address diﬀerent aspects of natural language
understanding.

Table 1, viewed through the lenses of the systems’ ability to successfully attend to long
sentences, shows in the left column intuitively ‘successful’ NLP applications; and in the
right the areas where in our view we have seen limited progress in the last 30 years.
Obviously, metrics used by the applications mentioned in the two columns are diﬀerent.
For example, one can argue that computational pragmatics did not exist 30 years ago, and
only recently we have started to see computational, probabilistic models of pragmatics

4

“Automata”
POS Tagging
Text Mining (e.g. Person, Date, ... ) Computational Semantics
Google Search
Gist Translation

Computational Pragmatics
Good Translation

“Structures”
Parsing

Table 1: On the left, one intuitive computational model is that of an automaton, with
data coming as inﬁnite streams (esp. for training). On the right the models are assembled
into structures (often by hand) from previously deﬁned components. The accuracy of the
models on the left is higher. However, the automata-based approach has problems dealing
with task requiring deeper inference.

[Franke and J¨ager, 2016] [Scontras et al., 2017],4, which suggests a big jump. Nevertheless,
the areas on the right do not scale with sentence length. And later, in Sections 2 and 3,
we will argue, from a more abstract perspective, that the diﬀerences between the columns
can be attributed to the diﬀerences in their respective computational models.

Let us discuss long sentences. Prior research in this area shows how parsing accuracy
decreases with the length of the sentence. For example, McDonald and Nivre [2007]
observe fast drop in precision and recall of dependency parsing with the increase of the
dependency length, the distance to the root, and length of sentences. Similar results
appear in Fig.4 of Choi et al. [2015]. Actually the situation might be worse than these
sources suggests. In an analysis of parsing of sentences up to the length of 156, Boullier
and Sagot [2005] entertain a possibility that “(full) parsing of long sentences would be
intractable.” Clearly, deep neural networks improved the accuracy of parsing. However,
even with the attention-based models, Nivre [2020](Fig.4) reports a ∼20% drop in the
labeled attachment scores when the dependency length increases from 1 to 5.

This is clearly a problem, even for linguistically oriented data sets. A recent statistics
given in Borb´ely and Kornai [2019] shows that depending on the language and the corpus
the average sentence length is 19-38 words. However, thousands of sentences in each
corpus are longer than 100 words. The average sentence length in the Penn Treebank is
20.54 words (and the standard deviation of 8.6); in Genesis, 34 words; but, per classic
Yule [1939], in “Biographia Literaria” 10% of sentences are long and have the average
length of about 70 words.

The situation is even more problematic when we switch from general corpora to speciﬁc
ones. In our previous work [Rajshekhar et al., 2016], we discussed the problem of parsing
long sentences in the context of legal text corpora, namely patents. Fig. 1 (op.cit.) shows
the distribution of the lengths of the main patent claim (Claim 1). These claims are
expressed as single long sentences. The sentences of Claim 1 average 150-180, and can
be up to 1400 words long (diﬀerent weekly data introduce the variation). Although the
extreme length is due to legal rules, nevertheless we note that 93% of the claims in this
series are longer than 50 words. This means that any analysis of an average Claim 1 is
likely to be wrong. (In our unreported experiments in 2018 on a handful of claims about

4https://michael-franke.github.io/probLang/

http://www.mit.edu/~tessler/short-courses/

2017-computational-pragmatics/ last retrieved on May 13 2020

5

Figure 1: Distribution of Claim 1 sentences lengths in 4000 patents related to sustainabil-
ity. Note that over 90% of sentences are longer than 50 words. (From Rajshekhar et al.
[2016]).

30 words long, using diﬀerent dependency parsers, we did not get even a single correct
parse).

What about semantic parsing? Semantic representations are diﬃcult to build even for
short sentences, as shown in Fig. 2, from Abzianidze et al. [2020]. All systems submitted
to the competition on the shared task on semantic parsing show a drop in accuracy as the
length of the sentence increases.

6

Figure 2: Semantic representations are diﬃcult to build even for short sentences, as shown
by Abzianidze et al. [2020]. All systems report drop in performance with the sentence
length.

1.2 Hypothesis

Adding coinduction to semantics can provide a foundation for a more realistic, computa-
tionally sound and scalable model of natural language understanding.

We are proposing adding coinduction to the computational apparatus of semantics.
This we argue, will provide a basis for a more realistic, computationally sound and scalable
model of natural language understanding. Given that the bottom up, inductively con-
structed semantic structures are brittle, and seemingly incapable of representing longer
sentences or realistic dialogues, semantics is in the need of a new foundation. Coinduction,
which uses top down constraints, has been successful in the design of operating systems
and programming languages. Moreover, one can argue that implicitly it has been present
in text mining, machine translation and in some attempts to model intensionality (even
though the term itself does not appear in any articles on aclweb.org). In Barwise and
Moss [1996], which is a good introductory textbook, it is used to describe self reference,
paradoxes and modal logics.

So, there is scattered evidence coinduction works. Since coinduction and induction
can coexist, they can provide a common language and conceptual model for research in
NL understanding.

We should mention that one of the ﬁrst theoretical proposals to look at agent interac-
tion as coinduction appeared in Wegner and Goldin [1999], and it included explicit men-
tion of NL dialogue and question answering. Within the following twenty years, as argued
in the present article, the focus of NLP shifted towards coinductive methods5, namely

5This shift occurred without ever mentioning the concept itself. There are literally 12 entries mention-
ing ”deep learning” and ”coinduction”, mostly accidentally, although Elliott [2019] (a formal analysis of
convolutions) is an exception. (As of October 2020).

7

deep learning, with the theoretical justiﬁcation coming from the universal approxima-
tion properties of neural networks. This article summarizes some of these developments
and argues for an explicit introduction of the term ‘coinduction’ to the vocabulary of NLP.

To make the argument, we will focus on the following questions:

1. What is coinduction?

That is, we will discuss coinductive data, coinductive functions, coalgebras and
coinductive proofs (only marginally). See Sections 2 and 3.

2. Do we need it?

We have already started to argue that we do. But we’ll expand on it below in
Sections 4 and 5, where the main point will be the advantages of combining inductive
and coinductive information, and contrast it with the inadequacies of only using a
single approach. The empirical arguments presented there are based on results taken
from the work of other researchers and recast in the language of coinduction.

3. What can be our next steps?

In Section 6 we hypothesize that the practical and theoretical importance of the
joint inductive-coinductive approach to natural language understanding will most
likely be seen in models of compositionality.

2 What is coinduction? Informally.

Although coinduction and coalgebra do not appear in the aclweb.org repository of NLP
articles. We will argue that there is already quite a bit of research in NLU and in semantics
done in the co-inductive style; it just hasn’t been named ‘co-inductive’. We want to argue
the “classical”-style formal semantics can be extended with new problems to bridge the
gap between “coinductive” and “inductive” views of the data.

Before we attempt to answer the question “what is coinduction,” we want to infor-
mally discuss what this speculative paper is about? Namely, in theoretical computer
science we have the concept of co-induction, or coinduction (which is the spelling we will
use).
Induction builds structures bottom up and can be viewed as a reductionist pro-
cess,6 while coinduction provides top down constraints. Our main idea is to base NLU
partly on coinduction, for example to provide better models of dialogue and to address
the problem of parsing and understanding of long sentences. We believe, coinduction can
be incorporated into NL semantics, helped by the fact induction-coinduction relationships
are relatively well investigated in formal logic and theoretical computer science. Empirical
evidence suggests we will be more successful in addressing diﬃcult problems.

Five questions about coinduction we need to answer

• What is coinduction?
6Objects are reduced to their parts.

8

• How might coinduction be applicable to semantics?

• Has coinduction been applied to formal semantics of NL?

• What are the limitations of coinductive view of NLP?

• What kind of problems might be amenable to progress using a joint induction-

coinduction approach?

This exposition will be a bit less formal than in a properly technical article, but
it’s good to start somewhere, and we’ll provide complementary references explaining the
logic(s) of coinduction. As we said earlier, applying coinduction to natural language
processing is an open problem, and this article only intends to show likely places of
intersection between the two ﬁelds.

2.1 Coinductive data, coinductive functions, coinductive proofs

We will use ”coinduction” in the most generic meaning, to mean the three aspects of
coinduction:

• coinductive data

• coinductive functions

• coinductive inference: models and proofs

We will mostly focus on the ﬁrst two bullets. We will not be breaking any new grounds
here, either in having any insights or in arranging the material; we simply will reuse well
known examples. These examples will later be used as formal models for various natural
language phenomena, such as turn taking in modeling NL dialogue (Section 3.2.

To develop computational intuitions about coinduction, we start with two very generic
and known examples from programming, appearing e.g. in Python, Haskell and Prolog.
The examples introduce the concepts of codata, coinductive program, constructor and
destructor, see e.g. Gordon [2017].

Example 1. Coinductive data: two styles of list

Data: The 4-element ﬁnite list L4 = [1, 1, 1, 1] is built by specifying

L4 = cons(1, cons(1, cons(1, cons(1, nil))))

where cons is a list constructor and nil, the empty list, a nullary constructor.

Codata: The inﬁnite list

L1 = [1, 1, 1, 1, ...]

is deﬁned by specifying hd(L1) = 1 and tl(L1) = L1, where hd and tl are destructors.

9

Example 2. Coinductive programs: two styles of addOne

Recursion (ﬁnite lists, step by step):
AddOne(nil) = nil
AddOne(cons(n, l)) = cons(n+1, AddOne(l))

Corecursion (inﬁnite lists with lazy evaluation):

null(AddOne(l))=(l=nil)
hd(AddOne(l))=hd(l)+1
tl(AddOne(l))=AddOne(tl(l))

The recursively deﬁned AddOne maps ﬁnite lists to ﬁnite lists; the corecursively deﬁned

AddOne maps ﬁnite lists to ﬁnite lists and inﬁnite lists to inﬁnite lists.

More generally, recursion deﬁnes a function mapping values from a datatype by invok-
ing itself on the components of the constructors used to build data values. Corecursion
deﬁnes a function mapping to a codatatype by specifying the results of applying destruc-
tors to the results of the function.

2.2 What are coalgebras

We will introduce the concept of coalgebra informally, through a few examples, and we
will mostly follow the exposition from Jacobs [2017], Jacobs [2011] and Rutten [2000]. We
will illustrate the concepts using well known examples from natural language processing
(NLP).

2.2.1 Algebras describe constructions

We are assuming the reader is familiar with the concepts of an algebra. An algebra, for
example, an algebra of sets, a Boolean algebra, a group or a vector space, is deﬁned by
specifying its domain and its operations. Well known examples include set union and set
diﬀerence; conjunction, disjunction and negation for Boolean algebras; multiplication and
inverse for groups; and vector addition for vector spaces. In all these cases, the operations
construct new elements from the elements of the algebra. Pictorially, algebras with a
”carrier” X are maps into X from some type of system or structure or an expression
containing X (shown as a box below).

X ... X c−→ X

10

Figure 3: A grammar can be viewed as an algebra on trees, where two trees can be
combined through adjunction, pictured here, or substitution (not shown). The ﬁgure is
reproduced from Joshi and Rambow [2003], Figure 3.

In NLP, we can view a grammar as an algebra deﬁning how smaller parse trees can
be combined into bigger trees; perhaps this is best shown in the case of tree adjoining
grammars (TAGs), in Fig.3, where the operation of adjunction a of pairs of trees can be
represented as

T rees × T rees

a−→ T rees

or simply a : T rees × T rees −→ T rees. This representation focuses only on types in
the domain and codomain (range) of the function a, and we will see in a moment that
in coinduction, which we will use to represent named entity recognition (NER) in NLP,
we simply reverse the arrow. Notice that this representation tells us nothing about any
constraints that the pair of trees has to satisfy for a being applicable. Such constraints
have to be speciﬁed separately, as they usually are.

2.2.2 Coalgebras describe observations

If we were to create an ”algebraic” view of the standard named entity extraction operation,
we would need to put the box on the other side.

X c−→ X ... X

11

Figure 4: Named entity recognition adds annotations to the text. In this example, the
semantic types organization, .... are added to a fragment of a Wikipedia article. Note
the imperfections. (We used http://corenlp.run/ Stanford CoreNLP 4.0.0, updated
2020-04-16, to obtain these annotations, but such annotations are never perfect).

For example, let us take X = Sentences to consist of lists of words produced by a
sentence ﬁnding algorithm on a corpus of text data. Finding named entities or seman-
tics types in the sentences, e.g. person, city, geopolitical entity, cardinal etc.,
produces new lists of words together with IOB tags, indicating positions of the substring
with speciﬁc properties and these tags, as shown below in formula (1), appear instead of
the ”...” ellipsis.

As shown in Figure 4 and Table 2, ﬁnding entities of interest in this model consists in

adding information to the original, that is creating a table with observations.

Notice we are not constructing new strings, we are observing the text and ﬁnding items
of interest, i.e. named entities, and we are adding annotations to the text. This change
of perspective creates a co-algebraic view of the text. Notice the diﬀerence: sets of trees
were combined into new trees in the previous example; however, for NER we transform
sentences into expressions containing the words of the original sentences and the IOB
annotations.

Replacing the box by the actual types involved in producing the annotations we get,

for the simple case of looking for the person type:

(W ords)<ω ner:city

−−−−−→ (W ords × {I, O, B})<ω

(1)

That is, ner:city takes ﬁnite lists of words and produces ﬁnite lists of words with the
I,O,B labels. The speciﬁcation of a more complex NER task will be more complex, but
our point here is that we are not building new structures but annotating existing entities;
i.e. we are not constructing but observing.

oﬃcially
O

Leland
Stanford
I
B
ORGANIZATION

Junior University
I
I

[12]
O

Table 2: Looking at the details of annotations in Fig.4, the IOB annotations show the
beginning B, inside I and outside O of the entity.

12

Figure 5: Named entity recognition or semantic type recognition adds annotations to the
text. In this example, the semantic type cardinal is added to a fragment of a patent
claim. Note that although “at least one” is annotated properly, “one or more” is not.
(We used http://stanza.run/ to obtain these annotations in June 2020).

Also, as shown in Fig. 5, observations can be incomplete or contain errors. The point
of using coalgebraic (or coinductive) speciﬁcations is to make analysis resilient to errors,
and produce partial useful output.

2.3 A few words about related concepts

Throughout this article we are using the words “coinduction” and “coinductive” in their
widest meaning, because we see it as name for a point of view and a generic computational
approach7. We will also use these terms in a narrower technical sense referring to a
speciﬁcation of how data can be broken down into simpler items or annotations added to
them by observation. There is also another narrower meaning of these words, referring to
a proof technique, which is a “dual” of familiar proofs by induction – we will not concern
ourselves with this speciﬁc sense.

There are a few other related concepts which are mathematically important, but here
we only want to acknowledge their existence, and perhaps provide additional intuitions.
For the readers familiar with logic programming it might be helpful to think in terms

of largest vs. smallest models.

When we give an inductive deﬁnition, we mean the smallest set that satis-
ﬁes the given constraints; everything that’s in the set has some justiﬁcation.
We build the smallest model (i.e.
the smallest ﬁxpoint of the construction).
Coinductive deﬁnitions specify the largest set that is consistent with them.
The construction of a model proceeds by ﬁnding the largest ﬁxpoint consistent
with the speciﬁcations 8.

A question worth asking is: which of the two constructions will be more robust in
real applications? It is our intuition that largest models might tolerate better noise and
novel data, including new expressions and errors in text. Usually, irrelevant things are

7An alternative could be to use the words ”coalgebra” and ”coalgebraic”
8This particular reference might be helpful for the reader struggling with intuitions: https://ask.

metafilter.com/42858/What-the-heck-is-coinduction

13

consistent with speciﬁcation, so with coinductive constructions, we do not have to predict
in advance all possible cases.

For other potentially relevant concepts such as corecursion and bisimulation (which
we are not using in this article), as well as in depth treatment of ﬁxpoints and coinduction,
we would like to refer the reader to Barwise and Moss [1996].

In the next section we will informally introduce process algebras, in the context of

multimodal dialogue, and informally describe their connection to coalgebras.

3 Natural language processing is intuitively coinductive

We saw a moment ago that a formal deﬁnition of named entity recognition, a common
NLP task is coinductive in its form. Now we will go through a list of standard NLP
tasks and talk about them using the jargon of coinduction. The point of this exercise
is twofold: to get used to coinductive deﬁnitions and to show that there is a common
thread to solving natural language processing and understanding problems that require
abandoning the standard inductive, build step-by-step construction of meaning.

3.1 Automata as a coalgebra

Finite state automata are widely used in NLP, as shown in the list and discussion below.
They are naturally described in the language of coalgebras:

c : S → {halt} ∪ (A × S)

(2)

Here, S is a set of states, c is a transition function, and A are outputs (or observables).
Note that this formula does not constrain us to ﬁnite state automata, that is this speciﬁ-
cation is more general.

Examples of ”automata” used in NLP with coinductive representations:

• Any regex

• Chunkers that can operate with limited information; e.g. sentence splitters, phrase

ﬁnders, ”,”-ﬁnders, part of speech taggers, etc.

• Binary neural networks

• RNNs (LSTMs, BERT encoders)

With some modiﬁcation of the above transition function, and making the outputs
A more speciﬁc, along the lines of formula (1), we can intuitively see the coinductive
character of the ﬁrst two items on the list. The other two items are perhaps less intuitive.
However, binary neural networks are ﬁnite state automata (see ˇS´ıma [2020] for a more
in depth recent discussion); recurrent neural networks (RNNs) share the same spirit but
would have more complex deﬁnitions (see e.g. Carlsson and Gabrielsson [2020] for a
mathematical description of feed forward NNs). Actually, Sprunger and Jacobs [2019]
show that learning in artiﬁcial neural networks is coinductive (at least for some types of
RNNs). The above list covers perhaps the majority of techniques used in NLP. Moreover it

14

exempliﬁes the techniques used to address the NLP problems in the left hand side column
of Table 1. However, we want more, that is an argument that coinduction provides a
natural description of several unaddressed problems in language understanding, and in
particular the right hand side of the same table.

3.2 Dialogue: why it matters that interaction is coinductive

A conversation can be viewed as an unbounded sequence of turns modifying the internal
states of the interlocutors. Note that only the exchanged words are observable, but ob-
viously conversations change us. Some conversations are ﬁnite (e.g. hotel reservations),
but some are ”inﬁnite”, for example between members of the same family. Even our
Google searches are better viewed as inﬁnite conversations, where our past interactions
and current states (e.g.
location) together with the query produce a list of results but
also modify the state of the Google search engine (which cannot be observed).

Dialogue coinductively. Natural language dialogue can be described as a very simple
coinductive process consisting of a ﬁnite or inﬁnite collection of utterances, using the
automaton equation (2).

turn: States −→ {halt} ∪ (Who × W ords<ω × States)

(3)

States are not observable and are the internal states of interlocutors, labeled by Who.
Labels and utterances can be observed.

This model is perhaps too simplistic. However it is ﬂexible enough to capture both
recent attention-based neural network models of dialogue ([Budzianowski and Vuli´c, 2019])
and recent challenges to standard views of dialogue in linguistics (Gregoromichelaki et al.
[2020]).

This correspondence deserves a longer discussion. In a ”classical” view of NL dialogue
(e.g. Bird et al. [2009], Chapter 1), each utterance is a sentence or full phrase that can
be assigned linguistic meaning independently of other utterances. This conceptual model
admits exceptions, e.g. fragments that had to be interpreted using other, context driven
mechanisms. A more recent view Gregoromichelaki et al. [2020] postulates a model in
which a single sentence structures can be emerging across participants, and where speaker
and hearer can exchange roles across all syntactic and semantic dependencies:

Ruth: I’m afraid I burned the kitchen ceiling.
Michael: Did you burn
Ruth: myself ? No, fortunately not.

A: Have all the students handed in
B: their term papers?
A: or even any assignments?

Obviously, formula (3) is a good high level model of such exchanges. But it needs
to be augmented to correctly model the linguistic acceptability of the above and the un-
grammatical nature of e.g. any even assignments or?. A general linguistically motivated

15

method of doing so, given by Gregoromichelaki et al. [2020], is based on ”dynamic syntax”,
Kempson et al. [2000]. In a very practical setting of task oriented dialogues, our earlier
work, Zadrozny et al. [2000, 1998], handled similar fragments by ﬁnding most likely seman-
tic representations, derived from an implementation of a construction grammar (Goldberg
[1995], Zadrozny et al. [1994], Zadrozny and Manaster-Ramer [1995]). Thus both theory
and practice seem support this abstraction.

It is our view that for practical applications, and, in particular, to be able to correctly
assign semantic structures to long sentences, as discussed earlier in Section 1.1.2, a com-
bination of coinductive and syntactic constraints is necessary. The exact proportion and
formal role of each is an open issue. It might be the case though that they would have
complementary origins, where the coinductive constraints are learned from observations
using machine learning mechanisms, and the grammatical constraints would come from
human designed formal grammars. We will return to this later in Section 4, providing
examples of coinduction and induction working together and in Section 5 to argue that
not everything should be done by coinduction.

3.3 Multimodal interaction coinductively

A natural extension of spoken dialogue is multimodal dialogue between people, involving
both speech and gesture. More broadly multimodal interaction can involve humans and
machines communicating using speech, handwriting, hand gesture and gaze.

Interestingly, there is already an explicit use of coinduction to account for speech-
gesture interaction Rieser [2017], even though the term ”coinduction” does not appear
there. However, the term “process algebra” is in the title, and the particular version of
process algebra, the ψ-calculi are closely related to coinduction (see below). The cited ar-
ticle argues that to account for split utterances, in the spirit of examples shown in Section
3.2, and to account for the asynchronous multimodal communication and coordination, a
better model is required than “naive compositional” models canonically employed in NL
semantics. Namely, a model in which we have:

— channels on which information (data, agents or procedures) can be sent;
— procedures operating concurrently;
— interfaces enabling communication among processes;
— active and non-active processes;
— communication among agents organized via an i-o-mechanism, and where
— “composition does play a role ﬁnally, when the speech-gesture contact points have

been identiﬁed.”

These are natural postulates in context of multimodal interaction. Semantically, they
signify a transition from a static model of semantics to a dynamic one. This is similar
in spirit to the “dynamic syntax” approach to dialogue mentioned above, except that
concurrency is allowed.

Compositionality plays an important role but needs to be modiﬁed, because gestures
can last over any sequence of words in the sentence, and therefore there is no natural place
for integrating the two modalities. Therefore, description of speech-gesture coordination
cannot be given solely in a naive/static compositional way. Instead, as described in Lawler
et al. [2017], Rieser [2017], speech and gesture processes operate in parallel to create initial

16

Figure 6: Application areas for coalgebras, based on a table in Kurz [2001]. The arrows,
added by us, point to the areas directly applicable to computational linguistics.

representation for the meaning of the gesture and a partial semantic representation of
the speech. Final meaning of the gesture is derived from the constraints present in the
semantic representation of the speech. The latter is combined with the ﬁnal meaning of
the gesture compositionally.

Notice that initially the two channels are observed separately, and annotated. This
should remind us of the {I,O,B} annotations. In other words, we see a productive use of
both compositional/inductive and process algebra/coinductive methods.

Finally, we should mention that one of the ﬁrst theoretical proposals to look at agent
interaction as coinduction appeared in Wegner and Goldin [1999], and it included explicit
mentions of NL dialogue and question answering. Within the following twenty years, as
argued in in this article, the focus of NLP shifted towards coinductive methods, without
ever mentioning the concept.9

3.3.1 Relating process algebras and coinduction

Intuitively, process algebras are connected to coinduction as follows:

— A process algebra, from a very abstract level is a collection of processes, and can

be viewed as a very complex automaton;

— As we have above in Section 3.1, an automaton can be viewed as a coalgebra;
The tutorial Kurz [2001] discusses this relationship in details; see also Ribeiro et al.
[2006] for “a coinductive rephrasal of classic process algebra.” Based on the cited sources,
we can say:

Process algebra (cid:39) Coalgebra (cid:39) Coinduction

9There are literally 12 entries mentioning ”deep learning” and ”coinduction”, mostly accidentally,

although Elliott [2019] (a formal analysis of convolutions) is an exception

17

That is, we can map between the three formalizations, even if such mappings could
involve some subtle points. Informally, the formalisms can be viewed as roughly equiva-
lent. This can also be seen in Figure 6, based on Kurz [2001], showing application areas
of the coalgebra approach (we added the arrows to point to the areas relevant for NLP).

4 NL understanding: coinduction and induction together

The hypothesis we are pursuing in this paper is that coinduction and induction are both
needed for NL understanding. The argument we are making is based on computational
and linguistic intuitions, and on circumstantial evidence. We would view the hypothesis as
experimentally proven if NL models employing both approaches outperform other models
for most tasks. As shown in Section 4.2, indeed there are relatively strong empirical
arguments that this might be the case, although of course our selection of examples is
biased. Before we look at the empirical results, let’s start with a manual analysis to
develop an intuition for their joint use.

4.1 A motivating example

In this section we want to show how coinduction and induction could work together in as-
signing meaning to a poorly formed sentence. This is a ﬁctional example, perhaps beyond
capabilities of real systems. In the subsequent subsection, we will discuss implemented
systems that combine neural and grammatical information.

Example 3. Understanding a sentence from The Corpus of Linguistic Acceptability
(CoLA)10 [Warstadt et al., 2018]. Consider one of the longer sentences from CoLA:

*The younger woman might have been tall and, and the older one deﬁnitely was,

blond.

Let us assume the sentence comes from a dialogue transcript. Dialogue sentences
often have surprising structures.11 Even though marked “ungrammatical” the sentence is
understandable, and parses (perfectly?) with Stanford Stanza v.1.0.0 dependency parser12
[Qi et al., 2020]. However, the parse only has relationships between pairs words, so an
interpretation of the sentence needs to be constructed. The construction story, as we

10https://nyu-mll.github.io/CoLA/
11A well known example is “John thinks bananas.” The sentence is ‘ungrammatical’ without the pre-

ceding “What will Jane have for breakfast?”

12http://stanza.run/

18

are imagining it, would be of coinductive and inductive composition, shown in the steps
1-6 below. We can imagine the following sequence leading to an interpretation. For the
sake of the argument, let us assume the interpretation will be a discourse representation
structure (DRS).13

1. Coinductively we ﬁnd the boundaries of the sentence and sentence chunks.

Note. Pattern matching works well here, e.g. probabilistic automata, or equivalent
hidden Markov models for chunking; another option being a combination of pattern
matching and a neural network Qi et al. [2020].

2. Inductively (CFG) or coinductively (data trained dependency parser), structures

are assigned to the parts and/or the whole.

3. Some predicate(argument) semantics is assigned to the structures using pattern
matching or attributed grammars (e.g. Bird et al. [2009] McCord et al. [2012]. This
produces constraints on a resulting DRS.

Note. The method for assigning the constraints is not important; the point is that
we do not have a full speciﬁcation of semantics, but perhaps we have a partial one.

4. Coinductively (in written text), we ﬁnd the “, phrase,” pattern (or construction)

of a string between two commas.

5. Inductively, we try to apply the ellipsis as a possible meaning frame.

Note: Actually several frames could be applied in parallel, e.g. apposition.

6. Inductively, we see that younger woman:tall and blond is a possible interpreta-

tion. We add it to the DRS (and check its consistency).

The main point of this example is to show the plausibility of using both pattern
recognition (Steps 1, 3 and 4) and inductive steps (2, 5 and 6). Speciﬁcally, the possible
meanings of ellipsis are usually given by a grammar.14

4.2 Recent examples of rules (induction) and neural networks (coinduc-

tion) working together

In this section we present a few selected results in various subdomains of natural language
processing showing superior performance of a combination of inductive and coinductive
methods. We interpret them as supporting our view that induction and coinduction should
both be used in the process of language understanding. Obviously, our selection is biased,

13https://plato.stanford.edu/entries/discourse-representation-theory/
14We also note that the process described above seems roughly consistent with the chunk-and-pass
mechanism postulated by Christiansen and Chater [2016]. In view of that mechanism, the ungrammati-
cality of the sentence could be attributed to the need to backtrack to apply the ellipsis, since the grammar
does not license the ellipsis in the middle of the phrase. An alternative interpretation would give us a
repair, corresponding to The younger woman might have been tall and the older one deﬁnitely was blond
(a less interesting possibility, although more plausible if the sentence was spoken, with commas standing
for pauses).

19

Figure 7: Like earlier, in Fig.2, we see a quick drop in performance with longer sentences,
when dependencies become longer distance. The task is semantic role labeling and this
ﬁgure is taken from the cited paper He et al. [2017].

but the examples are worth noting. In the next section, we discuss examples which seem
to be uniquely hard for NN, but are extremely easily formalized inductively; namely, we
will switch to the world of mathematics.

Example 4. Predicate argument structure. Our ﬁrst example, from He et al. [2017],
is a classical task of semantic role labeling (SRL) which is determining the predicate-
argument structure of a sentence, i.e. “who did what to whom.” The authors also discuss
the impact of using “gold syntax” (hand-annotated text data) and syntactic parsers on
SRL. Their best model uses “gold syntax.”

They observe the following relation between deep learning models and parsers:

Extensive empirical analysis of these gains show that (1) deep models excel at
recovering long-distance dependencies but can still make surprisingly obvious
errors, and (2) there is still room for syntactic parsers to improve these results.

However, and similarly to Fig. 2, they observe a quick drop in performance for longer

argument dependencies. This is shown in Figure 7.

Their result and cited analysis can be viewed as supporting our thesis on the potential
superiority of hybrid models. The cited paper uses a deep learning model (coinductive,
by Section 3.1) and an inductive complement, namely, a syntactic parser for encoding
structure and the raw “gold syntax” (from hand annotated data). When discussing the
role of syntax in SRL, the article also says “there is signiﬁcant room for improvement
given oracle syntax but errors from existing automatic parsers prevent eﬀective use in
SRL.”

This suggests to us that more research is needed on how to eﬀectively combine syntax
and deep learning methods. Although the performance of hybrid methods is superior, the
ground level problem of understanding the structure and meaning of longer sentences has
not been solved. Likely, a solution to this problem will require a subtle interaction be-
tween the knowledge encoded in inductive structures and the statistical patterns encoded

20

Figure 8: Tseo et al. [2020] proposes another hybrid systems combining attention, word
embeddings, context free grammars and several knowledge bases.

in weights of the deep learning model.

Example 5. Information extraction: Our next example also focuses on semantics. A
recent article by Tseo et al. [2020] addresses the problem of extracting criteria for clinical
trials using a novel architecture shown in Fig.8. It combines attention-based conditional
random ﬁelds for named entity recognition (NER), word2vec embedding clustering for
named entity linking (NEL), a context free grammar and a knowledge base. This system
achieves a state of the art performance.

The point of this examples, and the similar ones cited in this article, is to show that in
practice we often beneﬁt from a combination of methods. The other reason is to show that
these are not one-oﬀ examples. Instead, they suggest, there is potential to generalize this
practice using the tools of theoretical computer science, i.e. induction and coinduction.

Example 6. Machine translation: comma analysis for rule-based machine trans-
lation and for patent translation. Even though the two examples we cite below pertain
to machine translation, they also touch upon two topics discussed earlier: the diﬃculty
of parsing long sentences and the complex structure of patents (Section 1.1.2, as well as
Fig.5 in Section 2.2.2).

• Long sentences are not only diﬃcult to parse and interpret, but also diﬃcult to trans-
late. In building an English to Korean machine translation system, Kim [2019] ﬁrst
classiﬁes the usages of commas into nine standard grammatical functions, including
various types of series (e.g. adjectives and conjuctions), parenthetical, appositives
etc. This is done using a support vector machine. The syntactic analysis is then
performed according to the roles of the commas. The result of these preprocessing
steps is improved quality of machine translation.

21

• The second example comes from the domain of Chinese-English patent machine
translation. Li and Zhu [2016] identify commas which separate sub-sentences and
non-sub-sentences, using two methods, one employing word knowledge and formal
rules and the other machine learning. The rule-based method achieves over 93%
accuracy (F1) improves translation accuracy. As in the above examples, diﬀerent
functions of commas are discussed.

Example 7. Parsing coinductively.

There is a tradition in linguistics to view syntax as a set of constraints, for example,
Dalrymple et al. [1993], Frank and Reyle [1995]. This tradition is alive and well in more
recent work, such as Gotham and Haug [2019], who view syntax as constraining possible
semantic interpretations. In a presentation,15 they explain their reasons for viewing syntax
as constraints:

• What the approaches just mentioned (i.e. Minimalism, Montague) have in common
is the view that syntactic structure plus lexical semantics determines interpretation.

• From this it follows that if a sentence is ambiguous, (...), then that ambiguity must

be either lexical or syntactic.

• The Glue approach is that syntax constrains what can combine with what, and

how.

In our view, these points also explain why constraint-driven approaches to semantics
are less brittle. Constraints are not deterministic and they occasionally can be violated;
the violations result in a penalty (i.e. higher value of the loss function), but without
completely breaking of the parsing process. And although, bottom up parsing with a
traditional, context free, grammar can be relatively robust and produce partial parses,
the newer constraint-based parsers work better.

For semantic dependency parsing, a good discussion and details of the constraint-based
approach, used with three diﬀerent dependency parsing formalisms, can be found in Peng
et al. [2017], where constraints are applied to a decoder in a bidirectional LSTM neural
network.

Finally, we note the proposal for a more robust semantic parsing, based on a Type
Theory with Records (TTR) [Cooper, 2005]. Interestingly enough, the lemma constrain(t)
appears 36 times in the follow up work of Dobnik et al. [2012]. And we only need a small
step to make it explicitly coinductive: TTR is based on a stratiﬁed type system, and
is built bottom up to avoid the Russell paradox [Cooper, 2012], but the stratiﬁcation is
already omitted in Larsson [2015] to ease the exposition. We know, from e.g. already cited
Barwise and Moss [1996], that stratiﬁcation can be replaced with constraints; therefore,
purely constraint-based models of TTR should be consistent.

15We are citing almost verbatim from: Glue semantics for Universal Dependencies, Matthew Gotham
and Dag Haug, CLASP seminar, Gothenburg, 8 March 2018. The parentheticals and emphasis are ours.

22

Example 8. Morphology.

Our ﬁnal example of the use of hybrid methods comes from a recent article by Shmid-

man et al. [2020]. To quote:

“The system combines modern neural models with carefully curated declara-
tive linguistic knowledge and comprehensive manually constructed tables and
dictionaries.”

“Our approach (...) uses several bi-LSTM based deep-learning modules for
disambiguating the correct diacritization in context. However, it is also sup-
plemented by comprehensive inﬂection tables and lexicons, when appropriate.”

The problem the paper addresses is adding Hebrew diacritic markers. These markers
are typically omitted in modern Hebrew, but have to be either implicitly understood or
explicitly added to remove ambiguities.

4.3 Comments and unresolved issues

We have presented examples where combinations of methods improves performance on
tasks ranging from semantics to morphology. The inductive parts varied, from facts, such
as ‘gold syntax,’ to tables and rules. The coinductive parts also varied. Clearly, much of
the work described here is driven by experiments. And it seems that with enough eﬀort and
data almost any combination of architecture boxes can made to perform. What is missing,
however, is our understanding: under what constraints, a combination of inductive and
coinductive methods will achieve an optimum performance?

In other words, is there a principled way of building hybrid, inductive/coinductive
or neuro-symbolic architectures? Or, do such combinations of methods simply address
deﬁciencies of speciﬁc neural networks, and with better NN systems, we can remove the
inductive parts? Again we have some anecdotal evidence that not everything should be
done by coinduction, i.e. existing NN architectures show serious deﬁciencies for some
tasks.

The question that arises seems to be: are these examples suggesting something deeper?
In other words, is there a math underlying the practice? — We know a few important
mathematical facts about deep learning, starting with the classical result that neural
networks can approximate any function. More recently, the superiority of deep neural
networks over networks with only one hidden layer has been established (e.g. Telgarsky
[2016]), and complementing it are results about the limitations of feed forward networks
(e.g. Mehrabi et al. [2018]). These three facts suggest to us a technical problem: is there
a formula balancing the inductive and coinductive contributions to understanding?

Perhaps this is the main question raised by the material discussed so far. We would
like to know a formula quantifying the dependence of the accuracy of the neural network
based on three factors: 1. the number of available hard coded facts/values; 2. amounts
of available training data; and 3. diﬃculty of the problem.

Note that there are experimental results in this spirit. For example, Sun et al.
[2017] observe that performance improves logarithmically based on volume of training

23

data, which for some problems might be prohibitive. There is also interest in combin-
ing logic/rules with neural networks (see e.g. Fischer et al. [2019] and the next section).
Recently, there appeared an analysis for a “class of hierarchically local compositional func-
tions” [Poggio et al., 2020], where it is hypothesized “local hierarchical compositionality
is imposed by the wiring of our sensory cortex and, critically, is reﬂected in language.”

However, there are also interesting questions possibly amenable to yes/no answers.
For example, (1) Can a network with certain restriction on the learning function and
parameters (depth, activation etc.) learn ten thousand natural language constructions
of, say, depth-ﬁve from some ﬁxed amount of data? – This could perhaps be assessed
using an artiﬁcial language approach in the spirit of Baroni et al. [2012] and Feinman
and Lake [2020]. An answer would perhaps shed some light on how diﬃcult it is to create
compositional semantics, given we have about ten thousand frequently used English verbs,
each potentially having arguments and adjuncts. (2) Same question, for long “iterative”
sentences with many sub-clauses, such as appearing in patents and legal documents, as
discussed in Section 1.1.2.

Systems improve by learning from interaction, and we have provided argument for
process-based, that is coinductive, approach to NL and multimodal dialogue. Having one
formal view of diﬀerent components of a NL understanding process should be helpful
with integrating them. To us, it seems the best candidate for such formalism is coinduc-
tion/coalgebra.

5 Not everything should be done via coinduction

Given the success of deep learning models, the obvious question is whether “everything
should be done via coinduction”, that is, using deep learning to ﬁnd patterns in text,
and create annotations representing the meaning of text. On the one hand, our common
sense and intuitions contradict the idea of always doing pattern recognition from scratch,
raw data. After all, there are databases of facts, many of them, e.g. ﬁnancial
i.e.
and legal events, have been checked for accuracy. There are terabytes of texts containing
useful information, including vocabulary deﬁnitions, and, ﬁnally, there are formal theories,
created at great cost and eﬀort, in mathematics, physics, biology etc.

Moreover, even though in theory, neural networks can approximate any function with
arbitrary accuracy, in practice they show limitations. We will go over some of them using
a few examples. So, this section can be viewed as complementing the previous one by
adding ‘negative’ examples.

5.1 Compositionality is a challenge for neural networks

As shown in Zadrozny [1994], in theory, any semantics can be encoded in a compositional
fashion, and the encoding method is explicitly coinductive (via bisimulation). However,
in practice, compositionality is a challenge for neural networks. Moreover, the lack of
compositionality is an impediment to progress in NLP and cognitive modeling.

Our ﬁrst set of observations come from M.Baroni’s 2018 CLASP seminar.16 and the

16https://gu-clasp.github.io/static/fe1b398a82e63dd71c99e0668d706b79/1704969_

24

follow up article [Baroni, 2020] His carefully designed experiment, using a simpliﬁed model
of language understanding and trying to model language acquisition and compositionality,
concludes with the following observations:

• (Recurrent) neural networks are remarkably powerful and general (as agnostic “end-

to-end” learners from input-output pairs).

• They can generalize to new inputs that are diﬀerent from those they were trained

on...

• ... but their generalization skills do not display systematic compositionality.

• Thus, they cannot adapt fast to continuous stream of new inputs in domains such

as language, math and, more generally, reasoning.

We can ask why this is the case that RNNs “generalization skills do not display systematic
compositionality”? — An answer perhaps is that it is not their function. Most modern
NN architectures incorporate sophisticated ways of computing correlations. In contrast,
compositionality requires an association of a discrete construction with a speciﬁc meaning
type, e.g. Goldberg [2006] and Cooper et al. [2015], and often access to background knowl-
edge. In the process of understanding, the catalog of constructions is used to decompose
a sentence into meaningful pieces (and the world knowledge helps with disambiguation).
In principle such a catalog of constructions can be learned from data. But the practice
is more complicated. Even in branches of mathematics, where the compositionality is
trivially obvious to a human, neural networks have trouble learning it from data.

Even on relatively simple, strictly compositional data sets, compositionality seems to
elude standard NN architectures. After performing a detailed analysis of latent compo-
sitionality, from several natural points of view, Hupkes et al. [2020] say “high scores do
still not necessarily imply that the trained models fully represent the true underlying
generative system.”

5.2 Diﬃculties in learning algebra, arithmetic and formal reasoning

Algebra and arithmetic: Even with special neural architectures, the performance on
mathematical tasks is limited, and for general purpose NN (even out of the box trans-
formers) it can be really disappointing [Saxton et al., 2019, Hupkes et al., 2020]. Madsen
and Johansen [2020] attribute it to the “lack of inductive bias” in NN:

“Neural networks can approximate complex functions, but they struggle to perform
exact arithmetic operations over real numbers. The lack of inductive bias for arithmetic
operations leaves neural networks without the underlying logic necessary to extrapolate
on tasks such as addition, subtraction, and multiplication.”

The authors then proceed to create a special purpose architecture which provides bet-

ter approximation of the three operations, but leave division as an open problem.

marco-clasp-oct2018-composition.pdf

25

Formal reasoning: Reimann and Schwung [2019] create a special purpose architecture,
“Neural Logic Rule Layers,” to represent arbitrary logic rules in terms of their conjunctive
and disjunctive normal forms. Their experiment shown relatively high accuracy (up to
98% on a limited data set). The authors claim their approach might help create more
explainable neural networks, as well as implement variants of fuzzy logic. Slightly earlier,
Granmo [2018] proposed Tsetlin Machines for a similar task.

While these are interesting experiments, the question we want to ask is whether, from a
practical point of view, hybrid systems, along the lines discussed in Section 4.2, combining
general purpose neural architectures with an inductive component, are better suited for
building applications.

5.3 Limitations of coinductive view of human cognition

Lake et al. [2015] discussed the challenge of generalizing from a small number of exam-
ples, and introduced the Omniglot dataset for one-shot learning. Their progress report
[Lake et al., 2019] concludes that “recent approaches are still far from human-like con-
cept learning on Omniglot, a challenge that requires performing many tasks with a single
model.”

In a related article, Lake et al. [2017] observe that deep neural networks have diﬃculties
with tasks requiring common sense, causality and depth. The article gives an example of
the diﬃculty neural networks have in generalizing in playing computer games by discussing
modiﬁed objectives, such as these:

• Get the lowest possible score;

• Get closest to 100, or any level, without going over;

• Beat your friend, but just barely, not by too much;

• Go as long as you can without dying;

• Die as quickly as you can; and

• Pass each level at the last possible minute.

The limitations of deep neural networks in modeling formal systems and human cogni-
tion suggest that further progress requires better accounts of grounding, compositionality
and causality. To us, as the reader might already expect, it suggests the need for an inter-
play between the formal reasoning (inductive) and the data driven (coinductive) systems
of reasoning.

6 Discussion and summary

This article tries to reconcile two clashing paradigms by observing that a combination of
inductive and coinductive methods produces superior results in many NLP tasks. It casts
the observed empirical results within a common mathematical framework, a framework

26

that has not been used so far in NL understanding, even though it has proven useful in
other branches of computer science. This obviously leads to many questions of practical
and theoretical importance. For example, we can ask how chunking and other cognitive
phenomena ﬁt into this formalized picture. And what about reasoning, generalization and
abduction? However, in our view, the two key and most obvious concerns are:

1. Practical importance: The main question is whether having a common con-
ceptual framework of coinduction + induction leads to better practical results, or
better theoretical models of language understanding?

— We hope so, and this is a reason for writing this article. Perhaps an intuition can
come from another, very diﬀerent context. In the works on the traveling salesman
and related NP-complete problems, it has been observed [Monasson et al., 1999]
“many NP-complete problems occurring in practice contain a mix of tractable and
intractable constraints.” This parallels the examples cited in this article that have
successfully combined inductive and coinductive methods.

2. Theoretical justiﬁcation: We have argued from empirical evidence that a com-
bination of inductive and coinductive methods often produces superior results. Is
there theoretical justiﬁcation supporting these observations? For example, we have
a theory proving that deeper neural networks produce better accuracy per number
of neurons (Section 4.3), if vanishing gradients can be controlled. In the more math-
ematical domain, it has been shown that NP-complete problems mentioned above,
such as the traveling salesman problem’ and the boolean satisﬁability (SAT) exhibit
phase transitions (cf. Cheeseman et al. [1991], Gent and Walsh [1994], Monasson
et al. [1999]). Therefore, we ask whether there are “phase transition” regions be-
tween applicability of inductive and coinductive methods.

Interestingly enough, compositionality might be the key to progress in both issues.
Traditionally, compositional semantics has taken its inspiration from mathematics, and
has been speciﬁed by inductive deﬁnitions. This tradition is very strong in logic, linguistics
and even computational linguistics. However, we see the emergence of compositionality in
neural networks as a very active area of research. As of October 2020, per Google Scholar,
we note about half of all the articles on deep learning and compositionality appeared in
2019 or later. We are seeing this increased interest because compositional systems are
more interpretable, and can incorporate domain knowledge and known causal relation-
ships. But since the world, knowledge and data are always changing, machine learning
has to be part of the picture. We discussed in Section 5 some of the limitations of the
purely data driven attempts to derive compositionality from data, and earlier in Section
4 empirical advantages of combining the two.

Summary: Coinduction is a mathematical and computational tool for specifying con-
straints on program behavior and data.
It is a natural complement to standard (i.e.
bottom up) ways of deﬁning compositional semantics or syntactic correctness. It provides
a principled (formal) view of the current practice in human-computer interaction, pars-
ing, machine translation and others. It covers possible worlds semantics, and, in theory,

27

can encode any semantics. However, coinductive methods have practical limitations, as
partial observations do not resolve all questions about interpretations, even though such
methods are less brittle for longer texts.

In this article, we argued that a combination of inductive (e.g. traditional semantics)
and coinductive (e.g. deep learning) methods is showing practical promise, and both
approaches belong to the same computational paradigm. Perhaps now is the time for an
explicit introduction of the term ‘coinduction’ to the vocabulary of NLP.

Acknowledgments: The impetus for writing up these ideas about the potential of coin-
duction as a theoretical framework for natural language understanding came from a dis-
cussion with CLASP researchers during IWCS 2019 (although coinduction guided some of
my work work on dialogue systems in the second half of 1990s). This article organizes and
expands on the main themes of the CLASP seminar talk given in May of 2020. In partic-
ular, I beneﬁted from personal communications and comments of S. Lappin, L. Moss, N.
Ruozzi, N. Correa, R. Cooper, M. Steedman, and others. Thanks are due to O. Rambow
for permission to reproduce Fig. 3; to the authors of Abzianidze et al. [2020] for Fig. 2;
to the authors of He et al. [2017] for Fig.5; and to the authors of Tseo et al. [2020] for
Fig. 8. Obviously, all the faults of this article are mine.

References

L. Abzianidze, R. van Noord, H. Haagsma, and J. Bos. The ﬁrst shared task on discourse repre-

sentation structure parsing. arXiv preprint arXiv:2005.13399, 2020.

M. A. Auslander, D. C. Larkin, and A. L. Scherr. The evolution of the mvs operating system.

IBM Journal of Research and Development, 25(5):471–482, 1981.

M. Baroni. Linguistic generalization and compositionality in modern artiﬁcial neural networks.

Philosophical Transactions of the Royal Society B, 375(1791):20190307, 2020.

M. Baroni, R. Bernardi, N.-Q. Do, and C.-c. Shan. Entailment above the word level in distribu-
tional semantics. In Proceedings of the 13th Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, pages 23–32. Association for Computational Linguistics,
2012.

J. Barwise and L. Moss. Vicious circles: on the mathematics of non-wellfounded phenomena.

Center for the Study of Language and Information, 1996.

S. Bird, E. Klein, and E. Loper. Natural Language Processing with Python. O’Reilly Media, Inc.,

1st edition, 2009. ISBN 0596516495, 9780596516499.

G. Borb´ely and A. Kornai. Sentence length. arXiv preprint arXiv:1905.09139, 2019.

P. Boullier and B. Sagot. Eﬃcient and robust lfg parsing: Sxlfg.

In Proceedings of the Ninth
International Workshop on Parsing Technology, pages 1–10. Association for Computational
Linguistics, 2005.

P. Budzianowski and I. Vuli´c. Hello, it’s gpt-2–how can i help you? towards the use of pretrained
language models for task-oriented dialogue systems. arXiv preprint arXiv:1907.05774, 2019.

28

G. Carlsson and R. B. Gabrielsson. Topological approaches to deep learning. In Topological Data

Analysis, pages 119–146. Springer, 2020.

P. C. Cheeseman, B. Kanefsky, and W. M. Taylor. Where the really hard problems are. In IJCAI,

volume 91, pages 331–337, 1991.

J. D. Choi, J. Tetreault, and A. Stent.

It depends: Dependency parser comparison using a
web-based evaluation tool. In Proceedings of the 53rd Annual Meeting of the Association for
Computational Linguistics and the 7th International Joint Conference on Natural Language
Processing (Volume 1: Long Papers), pages 387–396, 2015.

M. H. Christiansen and N. Chater. The now-or-never bottleneck: A fundamental constraint on

language. Behavioral and brain sciences, 39, 2016.

R. Cooper. Records and record types in semantic theory. Journal of Logic and Computation, 15

(2):99–112, 2005.

R. Cooper. Type theory and semantics in ﬂux. Handbook of the Philosophy of Science, 14(2012):

271–323, 2012.

R. Cooper, S. Dobnik, S. Lappin, and S. Larsson. Probabilistic type theory and natural language

semantics. In Linguistic Issues in Language Technology, Volume 10, 2015, 2015.

M. Dalrymple, J. Lamping, and V. Saraswat. Lfg semantics via constraints. In Sixth Conference

of the European Chapter of the Association for Computational Linguistics, 1993.

J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training of deep bidirectional

transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.

S. Dobnik, R. Cooper, and S. Larsson. Modelling language, action, and perception in type theory
with records. In International Workshop on Constraint Solving and Language Processing, pages
70–91. Springer, 2012.

C. Elliott.

Generalized convolution and eﬃcient language recognition.

arXiv preprint

arXiv:1903.10677, 2019.

R. Feinman and B. M. Lake. Learning task-general representations with generative neuro-symbolic

modeling. arXiv preprint arXiv:2006.14448, 2020.

M. Fischer, M. Balunovic, D. Drachsler-Cohen, T. Gehr, C. Zhang, and M. Vechev. Dl2: Training
and querying neural networks with logic. In International Conference on Machine Learning,
pages 1931–1941, 2019.

A. Frank and U. Reyle. Principle based semantics for hpsg. In Seventh Conference of the European

Chapter of the Association for Computational Linguistics, 1995.

M. Franke and G. J¨ager. Probabilistic pragmatics, or why bayes’ rule is probably important
for pragmatics. Zeitschrift f¨ur Sprachwissenschaft, 35(1):3 – 44, 2016. URL https://www.
degruyter.com/view/journals/zfsw/35/1/article-p3.xml.

I. P. Gent and T. Walsh. The sat phase transition. In ECAI, volume 94, pages 105–109. PITMAN,

1994.

A. E. Goldberg. Constructions: A construction grammar approach to argument structure. Uni-

versity of Chicago Press, 1995.

29

A. E. Goldberg. Constructions at work: The nature of generalization in language. Oxford Univer-

sity Press on Demand, 2006.

I. Goodfellow, Y. Bengio, and A. Courville. Deep Learning. MIT Press, 2016. http://www.

deeplearningbook.org.

M. Gordon. Corecursion and coinduction: what they are and how they relate to recursion and

induction. 2017.

M. Gotham and D. T. T. Haug. Glue semantics for universal dependencies. 2019.

O.-C. Granmo. The tsetlin machine-a game theoretic bandit driven approach to optimal pattern

recognition with propositional logic. arXiv preprint arXiv:1804.01508, 2018.

E. Gregoromichelaki, R. Kempson, and C. Howes. Actionism in syntax and semantics. CLASP

Papers in Computational Linguistics, page 12, 2020.

H. M. Hapke, H. Lane, and C. Howard. Natural language processing in action. Manning, 2019.

L. He, K. Lee, M. Lewis, and L. Zettlemoyer. Deep semantic role labeling: What works and
what’s next. In Proceedings of the 55th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 473–483, 2017.

D. A. Hudson and C. D. Manning. Gqa: A new dataset for real-world visual reasoning and

compositional question answering. arXiv preprint arXiv:1902.09506, 2019.

D. Hupkes, V. Dankers, M. Mul, and E. Bruni. Compositionality decomposed: How do neural

networks generalise? Journal of Artiﬁcial Intelligence Research, 67:757–795, 2020.

B. Jacobs. Introduction to Coalgebra. Slides at EWSCS 2011: 16th Estonian Winter School in

Computer Science 28 feb.-4 march, Estonia, 2011.

B. Jacobs. Introduction to Coalgebra, volume 59. Cambridge University Press, 2017.

A. Joshi and O. Rambow. A formalism for dependency grammar based on tree adjoining grammar.

In Proceedings of the Conference on Meaning-text Theory, pages 207–216, 2003.

R. Kempson, W. Meyer-Viol, and D. M. Gabbay. Dynamic syntax: The ﬂow of language under-

standing. Wiley-Blackwell, 2000.

S.-D. Kim. Comma analysis and processing for improving translation quality of long sentences in

rule-based english-korean machine translation. In ICAART (2), pages 474–479, 2019.

J. L. Klavans and P. Resnik. The balancing act: combining symbolic and statistical approaches to

language, volume 32. MIT press, 1996.

A. Kurz. Coalgebras and modal logic. ESSLI tutorial, pages 1–100, 2001.

B. M. Lake, R. Salakhutdinov, and J. B. Tenenbaum. Human-level concept learning through

probabilistic program induction. Science, 350(6266):1332–1338, 2015.

B. M. Lake, T. D. Ullman, J. B. Tenenbaum, and S. J. Gershman. Building machines that learn

and think like people. Behavioral and brain sciences, 40, 2017.

B. M. Lake, R. Salakhutdinov, and J. B. Tenenbaum. The omniglot challenge: a 3-year progress

report. Current Opinion in Behavioral Sciences, 29:97–104, 2019.

30

S. Larsson. Formal semantics for perceptual classiﬁcation. Journal of logic and computation, 25

(2):335–369, 2015.

I. Lawler, F. Hahn, and H. Rieser. Gesture meaning needs speech meaning to denote-a case of

speech-gesture meaning interaction. In FADLI@ ESSLLI, pages 42–46, 2017.

H. Li and Y. Zhu. Classifying commas for patent machine translation. In China Workshop on

Machine Translation, pages 91–101. Springer, 2016.

A. Madsen and A. R. Johansen. Neural arithmetic units. arXiv preprint arXiv:2001.05016, 2020.

C. D. Manning. Computational linguistics and deep learning. Computational Linguistics, 41(4):

701–707, 2015.

M. C. McCord, J. W. Murdock, and B. K. Boguraev. Deep parsing in Watson. IBM Journal of

Research and Development, 56(3.4):3–1, 2012.

R. McDonald and J. Nivre. Characterizing the errors of data-driven dependency parsers. 2007.

M. Mehrabi, A. Tchamkerten, and M. I. Youseﬁ. Bounds on the approximation power of feedfor-

ward neural networks. arXiv preprint arXiv:1806.11416, 2018.

R. Monasson, R. Zecchina, S. Kirkpatrick, B. Selman, and L. Troyansky. Determining computa-
tional complexity from characteristic ‘phase transitions’. Nature, 400(6740):133–137, 1999.

J. Nivre. Multilingual dependency parsing from universal dependencies to sesame street.

In
P. Sojka, I. Kopeˇcek, K. Pala, and A. Hor´ak, editors, Text, Speech, and Dialogue, pages 11–29,
Cham, 2020. Springer International Publishing. ISBN 978-3-030-58323-1.

H. Peng, S. Thomson, and N. A. Smith. Deep multitask learning for semantic dependency parsing.

arXiv preprint arXiv:1704.06855, 2017.

T. Poggio, A. Banburski, and Q. Liao. Theoretical issues in deep networks. Proceedings of the

National Academy of Sciences, 2020.

P. Qi, Y. Zhang, Y. Zhang, J. Bolton, and C. D. Manning. Stanza: A python natural language

processing toolkit for many human languages. arXiv preprint arXiv:2003.07082, 2020.

K. Rajshekhar, W. Shalaby, and W. Zadrozny. Analytics in post-grant patent review: Possibilities
and challenges (preliminary report). In Proceedings of the American Society for Engineering
Management 2016 International Annual Conference S. Long, EH. Ng, C. Downing, & B. Nepal
eds, 2016.

J. N. Reimann and A. Schwung. Neural logic rule layers. arXiv preprint arXiv:1907.00878, 2019.

P. R. Ribeiro, M. A. Barbosa, and L. S. Barbosa. Generic process algebra: A programming

challenge. J. UCS, 12(7):922–937, 2006.

K. Richardson, H. Hu, L. S. Moss, and A. Sabharwal. Probing natural language inference models
In Proc. AAAI 2020; see also: arXiv:1909.07521, 2020. doi:

through semantic fragments.
\url{https://doi.org/10.1609/aaai.v34i05.6397}.

H. Rieser. A process algebra account of speech-gesture interaction. revised and updated version.

FADLI 2017, page 67, 2017.

31

J. J. Rutten. Universal coalgebra: a theory of systems. Theoretical computer science, 249(1):3–80,

2000.

D. Saxton, E. Grefenstette, F. Hill, and P. Kohli. Analysing mathematical reasoning abilities of

neural models. arXiv preprint arXiv:1904.01557, 2019.

G. Scontras, M. H. Tessler, and M. Franke. Probabilistic language understanding: An introduction

to the rational speech act framework, 2017.

A. Shmidman, S. Shmidman, M. Koppel, and Y. Goldberg. Nakdan: Professional hebrew dia-

critizer. arXiv preprint arXiv:2005.03312, 2020.

J. ˇS´ıma. Analog neuron hierarchy. Neural Networks, 2020.

D. Sprunger and B. Jacobs. The diﬀerential calculus of causal functions.

arXiv preprint

arXiv:1904.10611, 2019.

C. Sun, A. Shrivastava, S. Singh, and A. Gupta. Revisiting unreasonable eﬀectiveness of data
in deep learning era. In Proceedings of the IEEE international conference on computer vision,
pages 843–852, 2017.

M. Telgarsky. Beneﬁts of depth in neural networks. Journal of Machine Learning Research, 49

(June):1517–1539, 2016.

Y. Tseo, M. Salkola, A. Mohamed, A. Kumar, and F. Abnousi. Information extraction of clinical

trial eligibility criteria. arXiv preprint arXiv:2006.07296, 2020.

A. Warstadt, A. Singh, and S. R. Bowman. Neural network acceptability judgments. arXiv preprint

arXiv:1805.12471, 2018.

P. Wegner and D. Goldin. Coinductive models of ﬁnite computing agents. Electronic Notes in

Theoretical Computer Science, 19:81–101, 1999.

G. U. Yule. On sentence-length as a statistical characteristic of style in prose: With application

to two cases of disputed authorship. Biometrika, 30(3/4):363–390, 1939.

W. Zadrozny. From compositional to systematic semantics. Linguistics and philosophy, 17(4):

329–342, 1994.

W. Zadrozny and A. Manaster-Ramer. The signiﬁcance of constructions. IBM TJ Watson Research

Center, Technical Report, 1995.

W. Zadrozny, M. Szummer, S. Jarecki, D. E. Johnson, and L. Morgenstern. Nl understanding
In Proceedings of the 15th conference on Computational

with a grammar of constructions.
linguistics-Volume 2, pages 1289–1293, 1994.

W. Zadrozny, C. Wolf, N. Kambhatla, and Y. Ye. Conversation machines for transaction process-

ing. Proceedings IAAI-98, 1998.

W. Zadrozny, M. Budzikowska, J. Chai, N. Kambhatla, S. Levesque, and N. Nicolov. Natural
language dialogue for personalized interaction. Communications of the ACM, 43(8):116–120,
2000.

A. Zhang, Z. C. Lipton, M. Li, and A. J. Smola. Dive into Deep Learning, volume 3. 2020.

Y. Zhang, D. Merck, E. B. Tsai, C. D. Manning, and C. P. Langlotz. Optimizing the factual correct-
ness of a summary: A study of summarizing radiology reports. arXiv preprint arXiv:1911.02541,
2019.

32

