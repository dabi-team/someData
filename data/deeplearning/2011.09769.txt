1
2
0
2

p
e
S
9

]

C
O
.
h
t
a
m

[

3
v
9
6
7
9
0
.
1
1
0
2
:
v
i
X
r
a

Data-Driven Robust Optimization
using Unsupervised Deep Learning

Marc Goerigk∗1 and Jannis Kurtz†2

1Network and Data Science Management, University of Siegen, Germany
2Management Science, University of Siegen, Germany

Abstract

Robust optimization has been established as a leading methodology to approach decision
problems under uncertainty. To derive a robust optimization model, a central ingredient is
to identify a suitable model for uncertainty, which is called the uncertainty set. An ongoing
challenge in the recent literature is to derive uncertainty sets from given historical data
that result in solutions that are robust regarding future scenarios.
In this paper we use
an unsupervised deep learning method to learn and extract hidden structures from data,
leading to non-convex uncertainty sets and better robust solutions. We prove that most of
the classical uncertainty classes are special cases of our derived sets and that optimizing
over them is strongly NP-hard. Nevertheless, we show that the trained neural networks can
be integrated into a robust optimization model by formulating the adversarial problem as a
convex quadratic mixed-integer program. This allows us to derive robust solutions through
an iterative scenario generation process. In our computational experiments, we compare this
approach to a similar approach using kernel-based support vector clustering. We ﬁnd that
uncertainty sets derived by the unsupervised deep learning method ﬁnd a better description
of data and lead to robust solutions that outperform the comparison method both with
respect to objective value and feasibility.

Keywords: Robust optimization; data-driven optimization; unsupervised deep learning

1 Introduction

In many real-world optimization problems, many of the observed parameters are uncertain, which
can be due to measurement or rounding errors, or since the true value is ﬁrst revealed in the
future. Examples of uncertain parameters can be future demands, unknown traﬃc situations,
noisy data and many more. Therefore, there is a high demand for optimization models which
can handle the occurring uncertainties. In contrast to stochastic programming, the robust op-
timization approach is used to tackle optimization problems with uncertain parameters by a
worst-case approach and needs no information about the underlying probability distribution of
the uncertain parameters. More precisely, in robust optimization problems we typically want
to ﬁnd a solution which is feasible under all future outcomes of the uncertain parameters and
which is optimal in the worst-case. To this end, the input of robust optimization models is an

∗marc.goerigk@uni-siegen.de, corresponding author, supported by the Deutsche Forschungsgemeinschaft

(DFG) through grant GO 2069/1-1
†jannis.kurtz@uni-siegen.de

1

 
 
 
 
 
 
uncertainty set containing the so-called scenarios. One of the main questions arising in practical
applications is which structure and size the uncertainty set should have.

Initialized by the seminal work of Soyster in 1973 [Soy73], the ﬁeld of robust optimiza-
tion fully emerged in the 1990s and was studied for several classes of uncertainty sets, includ-
ing ﬁnite and convex uncertainty sets [KY96, BTEGN09, ABV09]. For convex uncertainty
sets, the most frequently used sub-classes are polyhedral, conic and ellipsoidal uncertainty
sets [BTN98, BTN99, EGOL98, EGL97]. As a special case of polyhedral uncertainty, the so-
called budgeted uncertainty is a popular uncertainty class due to its simplicity and tractability
[BS04, BS03]. Diﬀerent uncertainty sets and their geometric relationship are studied in [LDF11].
Recently mixed uncertainty sets, combining most of the popular uncertainty classes into one
set, were studied in [DGR20]. Next to the classical robust optimization approach, several less
conservative approaches have been introduced. A survey about the classical and more recent
robust optimization approaches for discrete and convex uncertainty can be found in [BK18].

As mentioned above, one of the main questions for a user applying a robust optimization
model is how to choose the structure and the size of the uncertainty set. In most real-world
situations the user only has a ﬁnite set of observations of the uncertain parameters from the
past, possibly containing corrupted scenarios or outliers. Constructing a ﬁnite uncertainty set
containing all observations can lead to overly pessimistic robust solutions due to outliers and
since no structural properties of the data are exploited. Furthermore, the robust optimization
approach with ﬁnite uncertainty sets is known to be hard to solve, even for easy classical com-
binatorial optimization problems with only two scenarios [KY96]. To tackle the latter problems,
several data-driven robust optimization approaches have been studied. Uncertainty sets can be
constructed by statistical methods using non-parametric estimators to model conﬁdence regions
[AB20], hypothesis tests [BGK18], φ-divergence [YdH13] or statistical learning theory [TR14].
In [HHL17] the authors approximate a high probability region by combinations of classical un-
certainty sets and then use a data-splitting scheme to determine the size of the region.
In
[CH15, NY17] Dirichlet process mixture models are used to construct uncertainty sets which are
given by a union of ellipsoids. Furthermore, in [NY17] computationally tractable uncertainty sets
with a polyhedral structure are constructed and applied to adaptive robust optimization prob-
lems. Polyhedral uncertainty sets incorporating correlations between uncertain parameters are
derived in [NY18] using principal component analysis and kernel smoothing. In the ﬁeld of data-
driven distributional robustness the idea is to construct a distributional ambiguity set around
an empirical distribution, often deﬁned by the Wasserstein metric or φ-divergence, containing all
probability distribution to be considered. The task is to ﬁnd a solution which performs best under
the worst-case distribution in the ambiguity set; see e.g. [EK18, SD21, BSZ19, WKS14, GS10].
In [BTEGN09, BS04, BDHP19] probabilistic performance guarantees of classical and tractable
uncertainty sets were studied, i.e. under the assumption that the uncertain parameters follow
a probability distribution with certain properties, the probability of a robust solution being in-
feasible can be controlled. Interestingly, these performance guarantees even hold for artiﬁcially
constructed probability distributions whose support is not contained in the uncertainty set.

While the goal of most of the latter approaches is the construction of uncertainty or ambiguity
sets leading to good solutions with a probabilistic performance guarantee, another line of research
is concerned with ﬁnding solutions which are feasible for all possible future scenarios, avoiding
probabilistic assumptions on the data. On the one hand, deterministic approaches were developed
to construct a range of uncertainty sets which were applied to the shortest path problem under
real-world traﬃc scenarios of the City of Chicago [CDG19]. In [CCCP21] principal component
analysis is used to derive polyhedral uncertainty sets which are computationally cheaper than
using the convex hull of the observed scenarios. On the other hand, unsupervised machine
learning models were deployed to learn and extract information from data, detect anomalies and

2

to construct uncertainty sets which better describe the structure of the data. Clustering and
supervised machine-learning approaches were used in [GGJ20]. In [SHY17, SY19, SZD+20] the
authors derive a kernel-based support vector clustering model to construct polyhedral uncertainty
sets.

In this work we apply and adapt the unsupervised deep classiﬁcation model developed in
[RVG+18] to construct uncertainty sets which are given by level sets of a norm-function applied
to the output of deep neural networks. Deep learning is widely used to discover and exploit
unknown structure in data [LBH15, Ben12]. Due to the high expressivity of neural networks,
the derived sets have a more complex structure compared to other methods, which can ﬂexibly
be adjusted by varying the architecture of the underlying neural network. Furthermore, the one-
class deep learning method in [RVG+18] succeeded in detecting anomalies in data. The basic
idea of our approach is to train a neural network which can distinguish a true scenario from
a corrupted or unrealistic scenario with high accuracy. The constructed uncertainty set then
contains all scenarios which are classiﬁed by the neural network as true scenarios. By scaling the
radius of our derived set, we can additionally control the conservativeness of the robust solution.
While this work was under review, our method was applied to a real-world reﬁnery planning
problem under uncertainty in [WPS+21]. The results reported in that paper give further evidence
that our method performs well in practice.

Our contributions are as follows:

• We apply the unsupervised deep classiﬁcation model developed in [RVG+18] to create

uncertainty sets for robust optimization problems.

• We show that the constructed sets are given by a ﬁnite union of convex subsets, each of

them having a polyhedral structure intersected with a transformed norm inequality.

• We prove that most of the classical uncertainty classes considered in the literature are
special cases of our derived sets and that optimizing over our set is strongly NP-hard.

• We show that it is possible to optimize over our sets using a mixed-integer programming for-
mulation, which means that the robust optimization problem can be solved by an iterative
scenario generation procedure.

• We test our method on randomly generated data and on realistic traﬃc data and compare
it to the kernel-based support vector clustering sets from [SHY17] and to the convex hull of
the historical data points. Our experiments show that solutions calculated by our method
often outperform both other methods.

2 Preliminaries

2.1 Notation

We deﬁne [k] := {1, . . . , k} for each k ∈ N and RN

+ := (cid:8)x ∈ RN : x ≥ 0(cid:9). The (cid:96)p-norm of a vector
. For a matrix A ∈ Rm×n we denote by ai the i-th
x ∈ RN is deﬁned by (cid:107)x(cid:107)p :=
row and by Aj the j-th column of A. For a vector v ∈ RN we denote by diag(v) the N × N
matrix which has diagonal entries v and zero-entries otherwise. For given matrices W 1, . . . , W L
of appropriate dimensions we deﬁne the product

i∈[N ] xp

(cid:16)(cid:80)

(cid:17) 1

i

p

L
(cid:89)

i=1

W i := W LW L−1 · · · W 1.

3

The identity matrix in dimension n is denoted by En.

2.2 Robust Optimization

Consider the deterministic linear optimization problem

min d(cid:62)x

s.t.

c(cid:62)x ≤ b
x ∈ X

(1)

where d ∈ RN is a given cost vector, X = {x ∈ RN : T x ≤ e} a polyhedron and c ∈ RN , b ∈ R.
Assume that the coeﬃcient parameters of the constraint c(cid:62)x ≤ b are uncertain, i.e. the vector
c is not known precisely. In robust optimization we assume that an uncertainty set U ⊂ RN is
given, which contains all possible realizations of the vector c. The aim is then to calculate an
optimal solution which is feasible for each realization in U , i.e. we want to solve the problem

which is equivalent to the problem

min d(cid:62)x

s.t.

c(cid:62)x ≤ b ∀c ∈ U
x ∈ X

min d(cid:62)x

c(cid:62)x ≤ b

s.t. max
c∈U
x ∈ X.

(2)

(3)

If more than one constraint is uncertain, a similar reformulation can be applied for each such con-
straint. For certain classes of convex uncertainty sets U , replacing maxc∈U c(cid:62)x by its dual formu-
lation, Problem (3) can be transformed to a deterministic problem of a certain class [BTEGN09].
If U is a polyhedral uncertainty set, (3) is equivalent to a linear program, while for ellipsoidal
uncertainty sets it becomes a second-order cone problem.

Alternatively, Problem (2) can be solved by iteratively generating new worst-case scenarios in
U and adding them to the problem. More precisely, we alternately calculate an optimal solution
x∗ ∈ {x ∈ X : maxc∈U (cid:48) c(cid:62)x ≤ b} of Problem (2) for a ﬁnite subset U (cid:48) ⊂ U and afterwards a
worst-case scenario

c∗ ∈ arg max

c(cid:62)x∗

c∈U

(4)

which is then added to U (cid:48) if (c∗)(cid:62)x∗ > b holds. Otherwise, we stop with an optimal solution x∗.
Sometimes the special case of the robust optimization problem is studied where the uncertain

parameters only appear in the objective function, which can be modeled by

min
x∈X

max
c∈U

c(cid:62)x.

(5)

Nevertheless, all results from above also hold for Problem (5). Finally, note that we can equiva-
lently replace U by its convex hull conv (U ) in Problems (2) and (5), since we are optimizing a
linear function over U .

4

2.3 Unsupervised Learning Methods

In this work we consider a subclass of unsupervised learning models, sometimes called anomaly
detection or one-class classiﬁcation. Here the task is to decide whether a given data point is a
normal data point or if it is anomalous. To this end the aim is to train an appropriate model on
a set of unlabeled training data, which is assumed to contain the normal data points, and extract
structural information from this training set to distinguish normal data from anomalous data in
the future. Often the idea behind one-class classiﬁcation models is to ﬁnd a minimal norm-ball
in a certain feature space, such that all anomalous data points are lying outside of the ball. In
the following we summarize two approaches, the ﬁrst based on support vector clustering and the
second using deep neural networks.

Given a set of data points c1, . . . , cm ∈ RN and a mapping φ : RN → RK to a possibly
high-dimensional feature space, the idea of soft margin support vector clustering (SVC) is to
ﬁnd the smallest sphere that encloses most of the training data, which can be done by solving
the problem

min R2 +

m
(cid:88)

ξi

1
N ν

i=1
2 ≤ R2 + ξi
s.t. (cid:107)φ(ci) − ¯c(cid:107)2

i = 1, . . . , m

(6)

¯c ∈ RK, R ≥ 0, ξ ∈ Rm
+ .

Note that the mapping φ(ci) of a data point can lie outside of the sphere around ¯c with radius
R in which case ξi > 0 in an optimal solution. The distance ξi of each point outside of the
sphere is penalized in the objective function and the parameter ν ∈ [0, 1] can be used to adjust
the fraction of data points which will lie outside of the optimal sphere. Problem (6) is a convex
problem and by applying the KKT conditions we obtain its dual problem

min
α

m
(cid:88)

i,j=1

αiαjK(ci, cj) −

m
(cid:88)

i=1

αiK(ci, ci)

s.t.

0 ≤ αi ≤
(cid:88)

1
N ν
αi = 1,

i∈[m]

i ∈ [m]

(7)

where K(·, ·) is a kernel function and K(ci, cj) = φ(ci)(cid:62)φ(cj). If K is a positive deﬁnite kernel,
Problem (7) is a convex quadratic problem and can be solved by classical QP methods [BV04]
or due to its speciﬁc structure by the sequential minimal optimization procedure [ZYX+08].

The main idea in [SHY17] is to construct uncertainty sets

U = (cid:8)c ∈ RN : (cid:107)φ(c) − ¯c(cid:107)2

2 ≤ R2(cid:9) ,

where ¯c and R are given by an optimal solution of (6). The authors apply the kernel

K(u, v) :=

(cid:88)

i∈[m]

li − (cid:107)Q(u − v)(cid:107)1

where Q is a weighting matrix containing covariance information from data and the li are speciﬁed
values which were chosen such that the kernel K is positive deﬁnite. They derive the uncertainty

5

set

Uν = {c ∈ RN : ∃vi ∈ RN ∀i ∈ SV
(cid:88)

αiv(cid:62)

i 1 ≤ min
i(cid:48)∈BSV

(cid:88)

αi(cid:107)Q(ci(cid:48)

− ci)(cid:107)1

(8)

i∈SV
− vi ≤ Q(c − ci) ≤ vi ∀i ∈ SV}

i∈SV

where α is the optimal solution of Problem (7), SV := {i : αi > 0} is the set of support vectors
1
N ν > αi > 0} is the set of boundary support vectors. Geometrically, SV
and BSV := {i :
contains all indices of the data points which lie outside or on the boundary of the sphere, while
BSV contains only the data points on the boundary. Note that the number of variables in the
description of Uν depends on the number of support vectors and therefore grows with increasing
sample size m and decreasing ν.

In [RVG+18] the authors study Problem (6) where φ(c) is replaced by the output of a neural
network for data point c. A neural network is a function fW 1,...,W L : RN → RdL which maps a
data point c ∈ RN to an output vector

fW 1,...,W L(c) = σL (cid:0)W LσL−1 (cid:0)W L−1 . . . σ1 (cid:0)W 1c(cid:1) . . .(cid:1)(cid:1)

where W l ∈ Rdl×dl−1 are the weight matrices, and σl : R → R for each l ∈ [L] are activation
functions which are applied component-wise. The dimension dl is called the width of the l-th layer
with d0 := N . We deﬁne W := (W 1, . . . , W L). The authors present a model called One-Class
Deep Support Vector Data Description (Deep SVDD), which is given by the problem

min
W 1,...,W L

1
m

(cid:88)

i∈[m]

(cid:107)fW 1,...,W L(ci) − ¯c(cid:107)2

2 +

λ
2

(cid:88)

l∈[L]

(cid:107)W l(cid:107)2
F

(9)

(cid:80)

l∈[L] (cid:107)W l(cid:107)2

where ¯c is a given center point, λ ≥ 0 a given control parameter and (cid:107) · (cid:107)F denotes the Frobenius
norm. The term λ
F is a regularizer which leads to smaller weights after training
2
and which can be controlled by the parameter λ. After optimizing Problem (9) the radius R2 > 0
to control the size of the sphere. A new data point c ∈ RN is then classiﬁed as a normal scenario
if (cid:107)fW 1,...,W L(c) − ¯c(cid:107)2 ≤ R. We will use this model in the next section to create uncertainty sets
which can be used for robust optimization problems.

Note that the center point ¯c is ﬁxed and not part of the decision variables. This is because
in the latter, case a trivial optimal solution would be to set all network weights and the center
to 0, provided that the activation functions do not have a bias term, and then all points in RN
would be mapped to the center. In [RVG+18] the authors mention that a good strategy is to set
the center point ¯c to the average of the network representations that result from performing an
initial forwardpass on some training data sample. Another drawback is that bias terms in the
network weights or in the activation functions can lead to useless solutions, since e.g. setting all
weights in the ﬁrst layer matrix W 1 to 0 and the bias vector of the ﬁrst layer to ¯c yields a network
which maps all points in RN to the center and hence does not extract any information from the
data. To tackle this problem in [CRKB20] two regularizers are presented, one based on injecting
random noise via the standard cross-entropy loss, and one which penalizes the minibatch variance
when it becomes too small. By adding one of these regularizers to the loss function in (9) the
mode collapse problem is avoided and bias terms can be used.

6

3 Creating Uncertainty Sets via Unsupervised Deep Learn-

ing

3.1 Deﬁnition and Properties of Uncertainty Sets

In this section we derive non-convex uncertainty sets using level sets of trained neural networks,
which are given as described in Section 2.3. We assume that all activation functions are contin-
uous piecewise aﬃne functions, i.e. they are of the form

σl(w) := αl

iw + γl
i

if βi,l ≤ w ≤ β

i,l

∀i ∈ [kl]

(10)

for all l ∈ [L], where αl
number of intervals and βi,l < β

i,l

i ∈ R are the given slopes, γl

are the bounds of the intervals where β

i are the given y-intercepts, kl ∈ N is the
i,l
= βi+1,l, β1,l = −∞

kl,l

and β
= ∞ for all l ∈ [L]. If all possible data points are contained in a bounded set and if the
neural network is already trained, then we can replace ∞ by a large enough value M > 0. Note
that the ReLU activation function σ(w) = max{w, 0} can be modeled by (10) setting kl = 2,
1,l
αl
1 = 0, αl
= ∞. Other piecewise
aﬃne activation functions as the Hardtanh or the hard sigmoid function can be modeled by (10)
as well. In general, any continuous function could be approximated by these piecewise aﬃne
functions.

2 = 0, β1,l = −∞, β

= 0, β2,l = 0 and β

2 = 1, γl

1 = γl

2,l

For a neural network, trained on the training sample c1, . . . , cm ∈ RN , and given by its
weight matrices W = (W 1, . . . , W L), a center point ¯c ∈ RdL and a radius R > 0, we deﬁne the
uncertainty set

Uf (W, ¯c, R) := {c ∈ RN : (cid:107)fW 1,...,W L(c) − ¯c(cid:107) ≤ R}
for an arbitrary norm (cid:107) · (cid:107). Using the Deep SVDD method deﬁned in (9) to train the neural
network, the natural choice of Uf (W, ¯c, R) would be given by using the Euclidean norm and the
center point ¯c returned by the model. All of the following results hold if we allow bias terms in
the network architecture. In this case each layer is given of the form W iy + bi where bi is the
trained bias term of layer i.

(11)

In the following we deﬁne

A :=






u := (ui,l)l∈[L],i∈[kl] : ui,l ∈ {0, 1}dl ,




ui,l = 1

.



(cid:88)

i∈[kl]

(12)

The idea is that the vectors u encode the activation decisions of all neurons, i.e. ui,l
outcome of the j-th component of layer l lies in the interval [βi,l, β
constraint (cid:80)
vector u ∈ A an activation pattern.

j = 1 if the
) and 0 otherwise. The
i∈[kl] ui,l = 1 ensures that for each neuron exactly one interval is chosen. We call a

i,l

We can now prove the following theorem which shows that the uncertainty set Uf (W, ¯c, R) is
given by a ﬁnite union of convex sets, where each convex set is an intersection of a polyhedron
with a norm constraint. To this end, we deﬁne ˜W 1 = W 1, W L+1 = EdL, where EdL is the
identity matrix in dimension dL, and

˜W l =





l−1
(cid:89)

s=1

W s+1diag(

(cid:88)

i∈[ks]


 W 1

ui,sαs
i )

7

for each l = 2, . . . L + 1. Furthermore, we set ˜γ1 = 0 and






l
(cid:88)

l−1
(cid:89)

W l



(cid:88)

diag(

ui,tαt

i)W t





(cid:88)

ui,s−1γs−1

i

s=2

t=s

i∈[kt]

i∈[ks−1]





˜γl =

for all l = 2, . . . L + 1.

Theorem 1. Given the weight matrices W of a trained neural network, a center point ¯c ∈ RdL
and a radius R > 0, then it holds that

Uf (W, ¯c, R) =

(cid:91)

u∈A

P (W, u, ¯c, R)

(13)

with

P (W, u, ¯c, R) := {c ∈ RN : ˜W lc + ˜γl <

(cid:88)

i,l

ui,lβ

∀l ∈ [L],

i∈[kl]
(cid:88)

˜W lc + ˜γl ≥

ui,lβi,l ∀l ∈ [L],

i∈[kl]
(cid:107) ˜W L+1c + ˜γL+1 − ¯c(cid:107) ≤ R}.

Proof. It is a well-known fact that neural networks with classical piecewise aﬃne activation
functions cluster the data space into polyhedra and apply a diﬀerent aﬃne function on each of
them [RR17, MPCB14, WBB18, RPK+17]. Nevertheless, we will derive our result explicitly for
the more general piecewise aﬃne activation functions in this proof.

Note that for each data point c ∈ RN applied to the neural network, there exists exactly
one activation pattern u ∈ A. Consider a ﬁxed activation pattern u ∈ A, and for a data point
c ∈ Uf (W, ¯c, R) let ˜wl(c) ∈ Rdl be the output of layer l ∈ [L] before applying the activation
function. The data point c has activation pattern u if the conditions

(cid:88)

i∈[kl]

ui,lβi,l ≤ ˜wl(c) <

(cid:88)

i,l

ui,lβ

i∈[kl]

(14)

are true for each l ∈ [L]. The output of layer 1 is given by W 1c. Applying the activation function
componentwise and afterwards applying W 2, the output of layer 2 is given by





˜w2 = W 2

diag(

(cid:88)

ui,1α1

i )W 1c + (

(cid:88)

ui,1γ1
i )



= W 2diag(

(cid:88)

ui,1α1

i )W 1c + W 2(

ui,1γ1
i )

i∈[k1]
(cid:88)

i∈[k1]

i∈[k1]

i∈[k1]

= ˜W 2c + ˜γ2.

Inductively we conclude that the output of layer l ∈ [L] is ˜W lc + ˜γl and together with (14) we
obtain the linear inequalities in P (W, u, ¯c, R). Since the activation function is applied to the
output of the last layer, applying the identity matrix W L+1 afterwards we obtain the output of
the neural network by

fW 1,...,W L(c) = ˜W L+1c + ˜γL+1.
Since for any data point in Uf (W, ¯c, R) the condition (cid:107)fW 1,...,W L (c) − ¯c(cid:107) ≤ R must hold, we
obtain the last constraint in the set P (W, u, ¯c, R) which proves the result.

8

Note that the set P (W, u, ¯c, R) can be unbounded, since if there exists a point ˆc ∈ P (W, u, ¯c, R),
the polyhedron corresponding to the linear constraints has an inﬁnite ray r ∈ RN , and if r is in
the kernel of the matrix ˜W L+1, then each point ˆc+λr for λ ∈ [0, ∞) is contained in P (W, u, ¯c, R).

Estimating the size of A, we ﬁnd the following result.

Corollary 2. The uncertainty set Uf (W, ¯c, R) is the union of at most (d(k − 1))N L convex sets
P (W, u, ¯c, R), where k = maxl∈[L] kl and d := maxl∈[L] dl.

Proof. The idea of the proof is to bound the number of possible regions which arise by the linear
inequalities in the deﬁnition of P (W, u, ¯c, R). It was proved in [RPK+17] that given t hyperplanes
in RN , the number of regions (i.e. the number of connected open sets bounded on some sides by
hyperplanes) is bounded from above by tN . Considering the linear inequalities in P (W, u, ¯c, R),
in the ﬁrst layer we have at most d(k − 1) hyperplanes describing the feasible region, since we
have at most d normal vectors and for each at most k − 1 intervals given by the right hand sides.
Therefore, the number of regions is bounded by (d(k − 1))N . Considering one of the regions, it
has ﬁxed activation pattern for the ﬁrst layer and is then again divided into at most (d(k − 1))N
regions by the hyperplanes of the second layer. Hence, after the second layer we have at most
(d(k − 1))2N possible regions. Inductively we conclude that the number of possible regions given
by the constraints in P (W, u, ¯c, R) is bounded by (d(k − 1))N L.

Note that if every layer has ReLU activation (which is continuous) and we choose the Eu-

clidean norm, then

P (W, u, ¯c, R) := {c ∈ RN | ˜wl

jc ≤ 0 if ul,1
jc ≥ 0 if ul,1

j = 1 and ul,2
j = 0 and ul,2

j = 0 ∀j ∈ [dl], l ∈ [L],
˜wl
j = 1 ∀j ∈ [dl], l ∈ [L],
c(cid:62)( ˜W L+1)(cid:62) ˜W L+1c − 2c(cid:62) ˜W L+1¯c + (cid:107)¯c(cid:107)2 ≤ R2}.

Therefore, applying Theorem 1 and Corollary 2 to the ReLU case, Uf (W, ¯c, R) is the union of
O(dN L) polyhedral cones intersected with the level set of one convex quadratic function.

A direct consequence of Theorem 1 is that in general, the uncertainty set Uf (W, ¯c, R) can
be non-convex and even non-connected. Note that this property is irrelevant when we consider
linear problems, since in this case, it is equivalent to replace the uncertainty set by its convex
hull. This does not hold for multi-stage problems, where our method to construct uncertainty
sets can be applied as well.

Another useful feature is that the size of the uncertainty set Uf (W, ¯c, R) and hence the
conservativeness of the corresponding robust optimization model can be controlled by the radius
R. The radius R can be chosen as the (1 − ε)-quantile of the radii ri = (cid:107)fW 1,...,W L(ci) − ¯c(cid:107)2
of the training data, which results in a corresponding probability guarantee over the empirical
distribution. However, as the resulting solution may be signiﬁcantly more robust than the a
priori guarantee suggests, a more suitable approach is to carry out experiments over a validation
set to determine R, i.e., to choose a value that leads to the best tradeoﬀ between feasibility and
objective value.

Moreover due to the non-convexity of Uf (W, ¯c, R) its robust counterpart (2) cannot be refor-
mulated using classical duality results. Nevertheless, it is possible to optimize over Uf (W, ¯c, R)
in direction x ∈ RN by solving for each u ∈ A the problem

max
c∈P (W,u,¯c,R)

x(cid:62)c

or deciding that it is infeasible. Then the best solution over all sets P (W, u, ¯c, R) is the optimal
solution. Alternatively it is possible to optimize over Uf (W, ¯c, R) by solving a convex quadratic

9

mixed-integer program. A similar idea was already used to model trained neural networks with
ReLU activation in [FJ18] and to train binarized neural networks in [IIC+19, BK20].

Theorem 3. For a given solution x ∈ X and a continuous activation function, the problem

is equivalent to the problem

max
c∈Uf (W,¯c,R)

c(cid:62)x

max x(cid:62)c1

s.t. W lcl <

(cid:88)

i,l

ui,lβ

∀l ∈ [L]

i∈[kl]
(cid:88)

W lcl ≥

ui,lβi,l ∀l ∈ [L]

i∈[kl]
cl+1 = diag(

(cid:88)

ui,lαl

i)W lcl +

(cid:88)

i∈[kl]
ui,l = 1 ∀l ∈ L

(cid:88)

i∈[kl]

ui,lγl

i ∀l ∈ [L]

i∈[kl]
(cid:107)cL+1 − ¯c(cid:107) ≤ R
ui,l ∈ {0, 1}dl
cl ∈ Rdl−1

∀i ∈ [kl], l ∈ [L]

∀l ∈ [L + 1].

(15)

(16)

(17)

(18)

(19)

(20)

(21)

(22)

Proof. The set of feasible variable assignments of the variables ui,l are exactly all possible ac-
tivation patterns in A. The constraints (16)-(17) ensure that the activation pattern given by
the u-variables is true for the data point c1 ∈ RN . Furthermore, the variables cl+1 model the
output of layer l after applying the activation function componentwise. Following the proof of
Theorem 1, the set of feasible solutions c1 ∈ RN of the formulation is equal to Uf (W, ¯c, R).

Note that the quadratic terms in Constraint (18) can be linearized by standard linearization
techniques. Therefore, the problem in Theorem 3 is equivalent to a mixed-integer program with
a convex quadratic constraint if we use the Euclidean norm, or a mixed-integer linear program
if we use the (cid:96)1-norm. Hence, the adversarial Problem (4) can be solved by this formulation
using classical integer programming solvers as CPLEX or Gurobi. Using the iterative constraint
generation procedure (see Section 2), we can then solve the robust problem (2).

We conclude this section by describing an alternative solution method to simplify the ad-
versarial problem (15-22) by avoiding the use of binary variables ui,l. To this end, we apply
all scenarios c1, . . . , cm from the training data to the neural network to calculate the activation
pattern for each of them, i.e. calculating the values of the u-variables for each data point cj
which we denote by ui,l(cj) for all i ∈ [kl], l ∈ [L], j ∈ [m]. These values correspond to those sets
P (W, u, ¯c, R) that contain actual training data. Having determined S := {u(c1), . . . , u(cm)} ⊂ A,
we then solve (15-22) repeatedly for each choice of u ∈ S. This means that we solve possibly
up to m problems (in practice, |S| (cid:28) m), where each problem is given as a quadratic convex
program which can be solved eﬃciently. Furthermore, solving these problems can be easily par-
allelized. This approach to generating adversarial scenarios is used in the following experiments.
However, note that in general, the radius R can be chosen in a way that Uf (W, ¯c, R) does not
contain any of the training data points at all.

10

3.2 Complexity of Robust Optimization

As shown in the previous section, the uncertainty sets constructed via deep one-class learning
have a more complex structure than the classical uncertainty classes considered in the robust
optimization literature, e.g. polyhedral, ellipsoidal or discrete uncertainty. Therefore it is reason-
able to expect that the robust problem is at least as hard to solve as for the classical uncertainty
sets.
In this section we prove that indeed all of the three mentioned uncertainty classes are
special cases of the uncertainty sets constructed in the previous section, and therefore known
NP-hardness results for the classical sets are valid for deep learning uncertainty as well.

Lemma 4. Respectively for each of the following uncertainty sets, there exists a neural network
with at most two layers, given by its weight matrices W 1, W 2 and bias terms b1, b2, a center
point ¯c and a radius R ≥ 0, such that Uf (W, ¯c, R) = Ui, where

(i) U1 = (cid:8)c ∈ RN | (c − a)(cid:62)Σ(c − a) ≤ 1(cid:9), Σ ∈ RN ×N is a symmetric and positive deﬁnite

matrix and a ∈ RN ,

(ii) U2 = (cid:8)c ∈ RN | Ac ≤ b(cid:9) where A ∈ Rp×N , b ∈ Rp,
(iii) U3 = (cid:8)c ∈ {0, 1}N | Ac = b(cid:9) where A ∈ Rp×N , b ∈ Rp.
Proof. Case (i): Calculate the Cholesky decomposition of Σ, i.e. a matrix V ∈ RN ×N such that
V (cid:62)V = Σ which can be done in polynomial time. Deﬁne a neural network with L = 2 layers
and bias term b1 in the ﬁrst layer as follows: set W 1 = En, b1 = −a, W 2 = V , σ1(x) = x and
σ2(x) = x. Furthermore deﬁne ¯c = 0, R = 1 and use the Euclidean norm. Then for a given
data point c ∈ RN the output of the ﬁrst layer is c − a. The output of the second layer is then
V (c − a). Substituting this into the norm constraint we obtain that c ∈ Uf (W, ¯c, R) if and only
if

(cid:107)V (c − a)(cid:107)2 = (c − a)(cid:62)V (cid:62)V (c − a) = (c − a)(cid:62)Σ(c − a) ≤ 1

and hence Uf (W, ¯c, R) = U1.

Case (ii): Deﬁne a neural network with L = 1 layer and bias term b1 as follows: set W 1 = A,
b1 = −b and σ1(x) = max{0, x}. Furthermore deﬁne ¯c = 0, R = 0 and use the Euclidean norm.
Then for data point c ∈ RN the output y ∈ Rp of the ﬁrst layer is the all-zero vector if and only
if c ∈ U2. If c /∈ U2 at least one of the components of y is strictly positive. Since by deﬁnition
c ∈ Uf (W, ¯c, R) if and only if (cid:107)y(cid:107)2 ≤ 0 and therefore y = 0, we have Uf (W, ¯c, R) = U2.

Case (iii): Deﬁne a neural network with L = 1 layer and bias term b1 as follows: set

W 1 =



 ,





b1 =





En
A
A





0
−b
−b + 1

and deﬁne the continuous piecewise aﬃne activation function

σ1(x) =


−x

x
−x + 1

x − 1

if x ≤ 0
if x ∈ [0, 1
2 ]
if x ∈ [ 1
2 , 1]
if x ≥ 1.

Note that σ1(0) = σ1(1) = 0 and σ1(x) > 0 for all x ∈ R \ {0, 1}. Furthermore deﬁne ¯c = 0,
R = 0 and use the Euclidean norm. We have to show Uf (W, ¯c, R) = U3. On the one hand for a
given c ∈ U3 we have Ac − b = 0 and therefore Ac − b + 1 = 1. Furthermore each component ci is

11

either 0 or 1 and therefore by deﬁnition of σ1 the output y of the ﬁrst layer is the all-zero vector
and hence (cid:107)y(cid:107)2 ≤ 0. On the other hand for a given c ∈ Uf (W, ¯c, R) the output of the ﬁrst layer
must be the all-zero vector. Therefore by deﬁnition of σ1 each component of W 1c + b1 must be
either 0 or 1. Hence Enc = c ∈ {0, 1}N , Ac − b ∈ {0, 1}p and Ac − b + 1 ∈ {0, 1}p. The latter
two conditions can only be true at the same time if Ac = b and therefore c ∈ U3.

It is well known that the robust problem with objective uncertainty (5) is already strongly NP-
hard if U is a polyhedron or an ellipsoid and if X = {0, 1}N ; see [BK18]. Therefore by Lemma 4
Problem (5) with uncertainty set Uf (W, ¯c, R) is strongly NP-hard even if X = {0, 1}N . In the
following we prove that even calculating the worst-case scenario is already strongly NP-hard.

Theorem 5. The adversarial problem

max
c∈Uf (W,¯c,R)

c(cid:62)x

is strongly NP-hard.

Proof. We can prove the result by reducing the 3-partition problem, see [GJ90]. Given a set
of weights a1, . . . , a3m and a bound B ∈ N such that (cid:80)3m
2 , the 3-
partition problem asks if there is a partition of the weights into m disjoint sets A1, . . . , Am ⊂ [3m]
such that (cid:80)
ai = B for all j ∈ [m]. Note that due to the weight restrictions any set Aj with
(cid:80)
ai = B contains exactly 3 elements. Hence the problem can be modeled by the constraints

i=1 ai = mB and B

4 < ai < B

i∈Aj

i∈Aj

a(cid:62)xj = B j ∈ [m]
(cid:88)

xj = 1

j∈[m]
xj ∈ {0, 1}3m j ∈ [m].

We can extend this to the optimization problem

max −y
s.t. a(cid:62)xj = B − By

j ∈ [m]

(cid:88)

xj = 1 − 1y

j∈[m]
xj ∈ {0, 1}3m j ∈ [m]
y ∈ {0, 1}.

Note that the latter problem always has a feasible solution since we can set y = 1 and all xj to
the all-zero vector. On the other hand if y = 0 then any feasible solution is a solution of the
3-partition problem. Since we maximize −y we can conclude that the 3-partition instance is a
yes-instance if and only if the optimal value of the latter optimization problem is 0. The latter
optimization problem is of the form

c(cid:62)x

max
c∈U

(cid:110)

c ∈ {0, 1}3m2+1 | Ac = b

with U =
this is an instance of the problem maxc∈Uf (W,¯c,R) c(cid:62)x.

(cid:111)

and x3m2+1 = −1, xi = 0 for all i ∈ [3m2]. By Lemma 4

12

4 Experiments

In the following we conduct two experiments to assess the quality of the robust solutions found
by our approach based on constructing uncertainty sets via deep neural networks (denoted as NN
in the following). To this end, we compare against the related method from [SHY17] presented in
Section 2 which is to construct polyhedra based on support vector clustering with suitable kernel
(denoted as Kernel). We will sometimes write NN or Kernel when referring to the solutions that
were generated by the respective methods.

In the ﬁrst experiment we conduct tests on randomly generated data to gain statistical in-
sights. In the second experiment we conduct an experiment with real traﬃc-data from the City
of Chicago.

All experiments were carried out on a virtual machine running Ubuntu 18.04. and using ten
Intel Xeon CPU E7-2850 processors. Code was implemented in Python, where we solved mathe-
matical programs with Gurobi version 9.0.3 (except for solving the Kernel training problem (7),
where CPLEX version 12.8 was used). To train neural networks, we used the PyTorch implemen-
tation from [RVG+18], which is available online1. Our code and data is made available online2
as well.

4.1 Experiment 1: Random Data Experiments

4.1.1 Setup

In this section we solve two types of robust optimization problems. In the ﬁrst type, the uncertain
parameters only appear in the objective function. We use a simple budget constraint in addition,
which results in optimization problems of the form

min max
c∈U

c(cid:62)x

N
(cid:88)

s.t.

xi = RHSobj

i=1
x ∈ [−1, 1]N .

(Obj)

In the second type of problems, we assume that the uncertain parameters appear in the con-
straints, and solve

max

N
(cid:88)

i=1

xi

s.t. c(cid:62)x ≤ RHSf eas ∀ c ∈ U

x ∈ [−1, 1]N ,

(Feas)

where in both cases, U can be replaced by the uncertainty set generated by Kernel or by NN.
In our experiments, we use problem dimensions N = 10, 20, 40 and set RHSobj = N/2 and
RHSf eas = 50N .

To generate data sets, we use [SHY17] as a starting point and consider three types of data.
The ﬁrst type is multivariate normal distributed (denoted as Gaussian), where we create random
positive deﬁnite covariance matrices using the sklearn Python package. The second type consists
of two such distributions that are created independently; for each data point that is sampled,

1https://github.com/lukasruﬀ/Deep-SVDD-PyTorch
2https://github.com/goerigk/RO-DNN

13

we decide with equal probability whether the ﬁrst or the second distribution is used (denoted as
Mixed Gaussian). For Mixed Gaussian data, we additionally ensure that the mean-points of the
two distributions do not lie in the same quadrant. Finally, the third set is sampled uniformly
from a polyhedron that is constructed in the manner of budgeted uncertainty [BS04]. That is,
scenarios are sampled from sets

U = {c : ci = ci + ciδi,

N
(cid:88)

i=1

δi ≤ Γ}

where the lower and upper bounds ci and ci are chosen randomly and Γ = N
2 (denoted as
Polyhedral ). For a detailed description of the data generation, we refer to our publicly available
code. Figure 1 gives examples for these types of data in two dimensions. White crosses indicate
the training data points. The ﬁrst two ﬁgures show the Gaussian set, the middle two ﬁgures
show the Mixed Gaussian set, and the last two ﬁgures show the Polyhedral set.

For each set, we sample 10,000 test data points. For training, we use diﬀerent sample sizes
m = 250, 500, 1000, where 0.95m data points are sampled from the correct distribution, and
0.05m data points are sampled uniformly in [0, 300]N to simulate outliers which are also included
in Figure 1. For each conﬁguration of m, N , and type (Gaussian, Mixed Gaussian, Polyhedral),
10 data sets are generated (a total of 270).

For NN, we use neural networks with three layers of dimensions N × 50, 50 × 50 and 50 × 50,
respectively, with a ReLU operator after the ﬁrst and second layer. To train the networks, we use
a loss function that aims at minimizing the radius of data points preceding a given (1−ε)% radius
quantile, and maximizing the radius of subsequent data points. More speciﬁcally, to calculate
our loss function, we sort the radii of the m training data points; let rπ(1) ≤ rπ(2) ≤ . . . ≤ rπ(m)
be such a sorting. The loss is then calculated as

k
(cid:88)

i=1

ai · rπ((cid:98)(1−(cid:15))m(cid:99)−i) −

k
(cid:88)

i=1

bi · rπ((cid:98)(1−(cid:15))m(cid:99)+i).

In this experiment, we use k = 5, ai = 5i, bi = i, and (cid:15) = 0.1. This way, we enforce the network
to include those data points where the classiﬁcation conﬁdence is high, and to exclude the others.
Plots on the left of Figure 1 show the radius the neural network associates with each point,
where a white line shows the level set of the 90% radius quantile; i.e., all points within the
white lines are considered as possible scenarios. For the ﬁgures on the right, we show the value
(cid:80)
i 1 with vij = |(Q(c − ci))j|. The white line indicates those points where this value
− ci)(cid:107)1, i.e., points that are considered as possible

i∈SV αiv(cid:62)

i∈SV αi(cid:107)Q(ci(cid:48)

(cid:80)

is less or equal to mini(cid:48)∈BSV
scenarios by Kernel.

4.1.2 Results for Objective Uncertainty

We ﬁrst concentrate on results for problem (Obj), where uncertainty only appears in the objec-
tive. We train Kernel using 1 − ν = 0.1, corresponding to a 90% quantile. For NN, we use a
radius quantile of 90% as well, which makes results comparable since both sets contain the same
amount of training data. Note the radius R could be determined by performing a validation step
testing the corresponding robust solution for a certain set of radii. Note also that training NN
does not necessarily give an optimal network, and repetitions can lead to diﬀerent results. We
train each neural network three times using 1000 epochs and use the network that gives the best
loss value. When measuring training time, we add all three run times together.

We ﬁrst present average training times and solution times in Table 1. All values are in
seconds. For training times, both methods require comparably little eﬀort, with average times

14

(a) Gaussian data, NN set.

(b) Gaussian data, Kernel set.

(c) Mixed Gaussian data, NN set.

(d) Mixed Gaussian data, Kernel set.

(e) Polyhedral data, NN set.

(f) Polyhedral data, Kernel set.

Figure 1: Visual comparison of data sets and uncertainty sets for examples with N = 2.
15

 0 50 100 150 200 250 300 0 50 100 150 200 250 300 0 10 20 30 40 50 60 70 80 90 100 0 50 100 150 200 250 300 0 50 100 150 200 250 300 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0 50 100 150 200 250 300 0 50 100 150 200 250 300 0 10 20 30 40 50 60 70 80 0 50 100 150 200 250 300 0 50 100 150 200 250 300 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 0 50 100 150 200 250 300 0 50 100 150 200 250 300 0 20 40 60 80 100 120 0 50 100 150 200 250 300 0 50 100 150 200 250 300 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8for NN ranging from 7 to 28 seconds, while times for Kernel are in the lower range of 1 to 8
seconds. Training times of both methods primarily depend on the sample size m, with problem
dimension N and the data type having less inﬂuence. Note that NN gives a neural network that
can be used in combination with any radius R, while Kernel needs to be reoptimized for diﬀerent
values of ν. While we keep these values ﬁxed in this experiment, this aﬀects training times if
many quantiles need to be tested.

Train

Solve

n
a
i
s
s
u
a
G

Type N
10
10
10
20
20
20
40
40
40
10
10
10
20
20
20
40
40
40
10
10
10
20
20
20
40
40
40

n
a
i
s
s
u
a
G
d
e
x
i
M

l
a
r
d
e
h
y
l
o
P

m NN Kernel
0.9
2.2
7.9
0.9
2.2
8.1
1.0
2.3
8.0
0.9
2.2
8.0
0.9
2.2
8.0
0.9
2.2
8.0
0.9
2.2
8.0
0.9
2.2
7.8
0.9
2.3
8.0

8.2
16.4
23.7
8.5
11.6
19.6
8.9
19.1
23.7
8.1
15.0
24.9
8.0
12.1
21.0
10.2
20.2
28.6
8.3
14.6
23.7
10.1
13.0
19.1
10.6
14.6
25.7

250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000

NN Kernel
0.1
26.7
0.2
22.9
0.3
34.4
0.3
64.3
0.5
102.9
1.1
120.9
1.2
151.0
2.0
280.8
3.8
596.7
0.1
48.6
0.2
91.4
0.3
88.2
0.3
171.1
0.5
244.8
1.1
295.0
1.2
470.3
2.0
820.9
3.9
1117.2
0.1
31.9
0.2
46.1
0.3
47.1
0.3
58.4
0.5
103.0
1.1
329.9
1.3
236.9
2.1
523.3
3.9
730.8

Table 1: Average solution and training times in seconds for Problem (Obj).

For solution times, diﬀerences between NN and Kernel become more pronounced. While
Kernel only needs to solve a single linear program, our approach needs to generate scenarios
iteratively. Hence, solving NN is orders of magnitude slower than solving Kernel.

With this disadvantage in mind, we now consider the quality of solutions as presented in
Table 2. We show the average of the average out-of-sample objective value and the average
of the 90%-quantile out-of-sample objective value for both robust solutions derived by NN and
Kernel. Recall that the aim is to minimize the objective value. In columns denoted ”Gap”, we
show the relative increase of the average results for Kernel over NN.

We see that NN strongly outperforms Kernel on all combinations of instance type, problem
dimension, and sample size, with respect to both average and quantile performance. In most

16

n
a
i
s
s
u
a
G

Type N
10
10
10
20
20
20
40
40
40
10
10
10
20
20
20
40
40
40
10
10
10
20
20
20
40
40
40

n
a
i
s
s
u
a
G
s
e
x
i
M

l
a
r
d
e
h
y
l
o
P

Avg

NN Kernel Gap
26.8
702.7
34.2
614.7
30.7
536.3
54.6
1402.6
39.3
1409.8
35.7
1396.9
52.7
2770.7
50.8
2897.8
50.2
2875.3
15.3
715.3
8.5
675.6
3.8
666.9
19.2
1437.8
23.6
1413.4
20.2
1363.7
16.6
2808.2
20.7
2905.9
20.8
2874.5
25.7
686.4
18.8
687.5
33.9
692.9
29.1
1424.9
34.4
1462.0
23.0
1469.3
40.7
2879.7
26.8
2969.7
40.7
2924.6

554.1
458.1
410.4
907.1
1011.7
1029.6
1814.1
1921.7
1914.6
620.4
622.5
642.5
1206.5
1143.9
1134.4
2407.6
2408.0
2379.7
546.1
578.7
517.5
1103.6
1087.9
1195.1
2046.2
2341.9
2078.6

90% Quantile

NN Kernel Gap
23.7
725.4
31.2
639.7
27.6
565.3
49.9
1434.7
36.9
1440.1
32.2
1428.2
50.8
2812.5
48.4
2938.9
46.1
2914.2
7.7
742.6
2.0
703.3
0.5
700.3
15.4
1471.3
19.6
1445.7
15.8
1396.9
14.1
2850.6
17.9
2949.5
17.6
2915.6
21.7
721.2
16.0
725.0
28.4
722.0
25.8
1473.2
30.8
1505.0
20.1
1513.9
37.6
2948.6
25.2
3045.3
37.2
2989.5

586.4
487.4
443.2
956.9
1051.6
1080.4
1865.2
1980.9
1994.6
689.5
689.5
696.9
1275.4
1208.9
1206.1
2497.8
2502.7
2478.2
592.7
624.9
562.3
1171.0
1150.6
1260.2
2143.7
2432.7
2178.7

m
250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000
250
500
1000

Table 2: Average objective values of Problem (Obj). Smaller values indicate better performance.

17

cases, even the 90% objective quantile of NN is smaller than the average objective value of
Kernel. Gaps on average objective values range from 26% to 54% for Gaussian data (i.e., the
Kernel solution can be 54% more costly on average when evaluated out-of-sample), from 3% to
23% for Mixed Gaussian data, and from 18% to 40% for Polyhedral data. There is no clear
trend in performance gaps when considering sample size m, but gaps tend to become larger with
increasing problem dimension N , which indicates better scaling capabilities of our method.

Summarizing these ﬁndings, we see that NN solutions require more computational eﬀort to

ﬁnd, but have the beneﬁt of a considerably stronger performance.

4.1.3 Results for Constraint Uncertainty

We now consider the performance when solving problems of type (Feas) with N = 20 and
m = 500. In this experiment, we generate solutions for diﬀerent degrees of robustness (controlled
through parameters ν and R). We consider the cases (1 − ν) ∈ {0.02, 0.04, 0.08, 0.16, 0.32, 0.64},
and use the same quantile values for R.

Each solution is evaluated with respect to its performance in the objective function (cid:80)N
i=1 xi
and with respect to its feasibility. To have a detailed understanding of the latter, we evaluate
c(cid:62)x out-of-sample and consider the 90% quantile of these values, i.e., we calculate how small
RHSf eas can be such that the solution remains feasible in 90% of scenarios. When optimizing,
we use RHSf eas = 50N = 1000. We solve each of the 10 instances of each data type and then
average these performance values for each parameter value ν and R, respectively.

Figure 2 shows the resulting average trade-oﬀ curves for each data type. Each curve consists
of six points, corresponding to the diﬀerent degrees of robustness when calculating solutions.
Points towards the right of the plot have better quality with respect to the objective function.
Points towards the bottom of the plot are more robust, as they remain 90% feasible for smaller
right-hand sides, i.e., plan in more buﬀer in the uncertain constraint. An ideal solution would be
in the bottom right corner, and a reasonable trade-oﬀ curve would go from top right to bottom
left.

(a) Gaussian.

(b) Mixed Gaussian.

(c) Polyhedral.

Figure 2: Robustness vs objective value in Problem (Feas) for N = 20, m = 500. Values to the
bottom right indicate better performance.

Comparing Kernel and NN solutions, we ﬁnd that NN shows a considerably better perfor-
mance being able to produce solutions which at the same time reach larger buﬀers in the uncertain
constraint while simultaneously reaching consistently larger objective values. Furthermore, NN
solutions give a useful trade-oﬀ between robustness and objective value (curves are diagonal from
bottom left to top right), while this is not the case for Kernel solutions. Here, for all three data
sets, solutions calculated with diﬀerent values of ν are dominated by the smallest set Uν with

18

7.07.58.08.59.09.5Objective Value82084086088090092094090% Quantile RHSKernelNN7.07.58.08.59.0Objective Value8008509009501000105090% Quantile RHSKernelNN6.57.07.58.08.5Objective Value78080082084086088090092090% Quantile RHSKernelNN1 − ν = 0.02, which gives both better objective values and better robustness than other values of
ν. This may mean that the corresponding uncertainty sets do not oﬀer protection towards the
relevant scenarios.

4.2 Experiment 2: Real-World Data Experiments

While the results of the ﬁrst experiment demonstrate strong dominance of NN solutions over
Kernel solutions, instances were randomly generated and are thus not necessarily representative
for real-world data. For this reason as a second experiment we solve the shortest path problem
with travel time uncertainty using the travel time data of the City of Chicago that was ﬁrst
collected and used in [CDG19]. Travel times for each arc in the Chicago network were collected
from March to May 2017 through a live traﬃc data interface. The whole network has 1308 arcs
and 538 nodes, but for this experiment, we only use the inner city region containing 189 arcs and
165 nodes. Furthermore, we use scenarios representing weekend travel times. There is a total of
1141 such observations (each observation giving the travel time for every arc in the network), of
which we use 570 for training and 571 for testing.

Due to the way the graph is generated, there exist edges that are completely correlated.
This happens as original travel speed observations were collected on segments that may contain
multiple edges. As the covariance matrix becomes degenerate in this case, small random noise
was added to the travel times to calculate the Kernel sets. As noted below, this eﬀect seems
to have considerable impact on both training and solution times for Kernel. Note that the
covariance matrix is not used in the training process of NN. The neural network we used has
three layers of size 189 × 50, 50 × 50 and 50 × 50, respectively.

Since for the larger data set the kernel method failed to terminate in reasonable time we
restricted the experiment to the city center graph and weekend scenarios. Furthermore, we used
a 95% quantile instead of 90% as in the previous experiment with objective uncertainty, as this
further reduces the size of the optimization model.

Additionally, we include a robust optimization approach where training data is used without
any further modiﬁcation as a discrete uncertainty set which we refer to as Discrete. Note that
since optimize a linear function over the uncertainty set this approach is equivalent to selecting
the convex hull of the training data as uncertainty set. This method was omitted in the pre-
vious experiment since it does not ﬁlter out outliers and thus cannot be expected to perform
competitively.

The robust optimization problem we consider here is to ﬁnd a shortest path over the uncertain
data where the uncertainty is only present in the objective function. We generate ten random
source-sink pairs, where we ensure that at least eight arcs need to be traversed from source to
sink to exclude pairs that are nearby. For each source-sink pair, a robust path is calculated
using Discrete, NN and Kernel. On average after training, Kernel paths take 1497.7 seconds
to compute, while NN paths take 794.8 seconds. The discrete scenario approach takes only 4.4
seconds to be solved on average.

We present results on this experiment in Figures 3-5.

In each ﬁgure, we show the path
computed by Kernel on the left and the path computed by NN on the right for an exemplary
instance.
In the middle, we show the out-of-sample histogram of travel times for all paths,
including Discrete.

We note that classical ﬂow constraints (inﬂow equals outﬂow for each node except source
and sink) correctly model the path problem only if all costs are non-negative. Using the Kernel
approach, we observed that solutions frequently were not connected and included cycles, which
results from uncertainty sets that include negative costs. We modiﬁed the Kernel approach such
that only non-negative arc lengths are contained in the uncertainty set. In two instances (paths

19

(a) Kernel path 01.

(b) Out-of-sample path lengths 01.

(c) NN path 01.

(d) Kernel path 02.

(e) Out-of-sample path lengths 02.

(f) NN path 02.

(g) Kernel path 03.

(h) Out-of-sample path lengths 03.

(i) NN path 03.

(j) Kernel path 04.

(k) Out-of-sample path lengths 04.

(l) NN path 04.

Figure 3: Comparison of paths 1-4 in experiment 3. In Figure 3(b), red line is on top of green
line.

20

41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.617891011cx0102030405060freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6141.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.615678910111213cx020406080freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6141.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.61810121416182022cx01020304050607080freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6141.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.618910111213cx0102030405060freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.61(a) Kernel path 05.

(b) Out-of-sample path lengths 05.

(c) NN path 05.

(d) Kernel path 06.

(e) Out-of-sample path lengths 06.

(f) NN path 06.

(g) Kernel path 07.

(h) Out-of-sample path lengths 07.

(i) NN path 07.

Figure 4: Comparison of paths 5-7 in experiment 3.

21

41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6181012141618cx020406080100120freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6141.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.611012141618cx020406080freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6141.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.618910111213cx010203040506070freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.61(a) Kernel path 08.

(b) Path lengths 08.

(c) NN path 08.

(d) Kernel path 09.

(e) Path lengths 09.

(f) NN path 09.

(g) Kernel path 10.

(h) Path lengths 10.

(i) NN path 10.

Figure 5: Comparison of paths 8-10 in experiment 3. In Figure 5(h), red line is on top of green
line.

22

41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6167891011121314cx01020304050607080freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6141.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.61810121416cx020406080freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6141.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.615678910cx010203040506070freqDiscreteNNKernel41.8641.8741.8741.8841.8841.8941.8941.9041.9041.91-87.65-87.64-87.63-87.62-87.6105 and 09) it can be observed that there still exists a single edge that is traversed twice in an
unnecessary loop. This can only happen if the Kernel approach assumes that such costs are
equal to zero. Apart from these two instances, all paths (both Kernel and NN) seem reasonable
options in the street network. Note that in no case we observe the same path from Kernel and
NN.

Comparing the out-of-sample performance of Kernel and NN, there are ﬁve instances with
mixed results (paths 01, 04, 06, 07, and 10). For these solutions the histograms largely overlap
and paths contain similar edges. In case of paths 01 and 10, Kernel shows better average and
better 95% quantile performance. For paths 04, 06, and 07, this comparison gives NN the
advantage. For the other ﬁve paths (02, 03, 05, 08, and 09), NN has a distinct advantage, clearly
outperforming Kernel.

There is one case (path 03) where Discrete clearly outperforms both Kernel and NN. Apart
from this case, Discrete shows a good overall performance, but can sometimes be worse than
NN, e.g., on paths 02 and 08, which highlights the beneﬁt of generalization through the proposed
machine learning methods when the data is less aﬀected by noise.

To summarize the ﬁndings of the two experiments, we note that (i) when visualized on low-
dimensional data, NN uncertainty sets reasonably capture the shape and size of uncertainty; (ii)
NN uncertainty sets on random, 20-dimensional optimization problems result in signiﬁcantly bet-
ter solutions than what Kernel achieves, irrespective whether we consider objective or constraint
uncertainty, which comes at the cost of higher computational eﬀort; and (iii) using real-world
data, NN becomes more computationally eﬃcient, scaling better in the problem size than Kernel,
but still produces solutions that clearly outperform those produced by Kernel. Finally, (iv) for
relatively noise-free data, the discrete scenario approach can produce solutions of high quality
that are fast to compute.

5 Conclusions

To derive useful robust optimization models, it is central to have a suitable description of the
uncertainty set available. The task of identifying whether a given scenario is similar to observed
data or should be considered as an outlier is related to the task of describing the uncertainty set,
and is a typical problem for which machine learning techniques have been proven to be highly
eﬃcient.

In this paper we combined one-class deep neural networks, to describe the uncertainty set,
with robust optimization models. It turns out that the uncertainty sets created by the one-class
deep neural networks are a ﬁnite union of convex sets, each set being a polyhedron intersected
with a convex norm-constraint. Therefore, our constructed sets have a more complex structure
than other data-driven sets. Indeed we can show that most of the classical uncertainty classes
are special cases of these sets and hence the robust problems is at least as hard as the one for
classical uncertainty sets. Furthermore we could show that optimizing over our sets is strongly
NP-hard. Nevertheless, to solve the robust optimization problem, it is necessary that we can
optimize over the set of scenarios that are classiﬁed as being representative for the historic data
by the neural network. We show that this is possible by formulating the adversarial problem
as a convex quadratic mixed-integer program. By further decomposing this problem using the
historic data, it is even possible to remove the binary variables from the program and solve a
sequence of continuous problems instead.

We tested our method in two experiments, where we compare against a kernel-based support
vector clustering method that is most similar to our approach. Throughout our experiments, we
found encouraging results, observing that the method proposed in this paper often ﬁnds better

23

robust solutions (with respect to both objective value and feasibility) than when applying the
previous method or even discrete uncertainty sets containing the historic data. At the same
time, our method is easy to apply with suitable training and optimization code being readily
available. A drawback is that solution times on randomly generated data are higher than for the
comparison method; here, the development of heuristic solution methods may be beneﬁcial.

Since in the classical linear robust optimization regime the uncertainty set can always be
replaced by its convex hull, the non-convexity (and even non-connectedness) of our uncertainty
set is implicitly reverted and does not have an impact on the performance. Considering two-
stage robust optimization problems, replacing the uncertainty set by its convex hull is not possible
anymore, and therefore extending our method to two-stage robust optimization problems in the
future can lead to larger improvements compared to other uncertainty sets.

References

[AB20]

[ABV09]

Polina Alexeenko and Eilyan Bitar. Nonparametric estimation of uncertainty sets
for robust optimization. arXiv preprint arXiv:2004.03069, 2020.

Hassene Aissi, Cristina Bazgan, and Daniel Vanderpooten. Min-max and min-max
regret versions of combinatorial optimization problems: A survey. European Journal
of Operational Research, 197(2):427–438, 2009.

[BDHP19] Dimitris Bertsimas, Dick Den Hertog, and Jean Pauphilet. Probabilistic guarantees

in robust optimization. Available on Optimization Online, 2019.

[Ben12]

Yoshua Bengio. Deep learning of representations for unsupervised and transfer
learning. In Proceedings of ICML workshop on unsupervised and transfer learning,
pages 17–36. JMLR Workshop and Conference Proceedings, 2012.

[BGK18]

Dimitris Bertsimas, Vishal Gupta, and Nathan Kallus. Data-driven robust opti-
mization. Mathematical Programming, 167(2):235–292, 2018.

[BK18]

[BK20]

[BS03]

[BS04]

Christoph Buchheim and Jannis Kurtz. Robust combinatorial optimization under
convex and discrete cost uncertainty. EURO Journal on Computational Optimiza-
tion, 6(3):211–238, 2018.

Bubacarr Bah and Jannis Kurtz. An integer programming approach to deep neural
networks with binary activation functions. Workshop on Beyond ﬁrst-order methods
in ML systems at the 37th International Conference on Machine Learning, Vienna,
Austria, 2020.

Dimitris Bertsimas and Melvyn Sim. Robust discrete optimization and network
ﬂows. Mathematical Programming, 98(1-3):49–71, 2003.

Dimitris Bertsimas and Melvyn Sim. The price of robustness. Operations Research,
52(1):35–53, 2004.

[BSZ19]

Dimitris Bertsimas, Melvyn Sim, and Meilin Zhang. Adaptive distributionally ro-
bust optimization. Management Science, 65(2):604–618, 2019.

[BTEGN09] Aharon Ben-Tal, Laurent El Ghaoui, and Arkadi Nemirovski. Robust optimization,

volume 28. Princeton University Press, 2009.

24

[BTN98]

[BTN99]

[BV04]

Aharon Ben-Tal and Arkadi Nemirovski. Robust convex optimization. Mathematics
of Operations Research, 23(4):769–805, 1998.

Aharon Ben-Tal and Arkadi Nemirovski. Robust solutions of uncertain linear pro-
grams. Operations Research Letters, 25(1):1–13, 1999.

Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge univer-
sity press, 2004.

[CCCP21] Meysam Cheramin, Richard Li-Yang Chen, Jianqiang Cheng, and Ali Pinar. Data-
driven robust optimization using scenario-induced uncertainty sets. arXiv preprint
arXiv:2107.04977, 2021.

[CDG19]

[CH15]

Andr´e Chassein, Trivikram Dokka, and Marc Goerigk. Algorithms and uncertainty
sets for data-driven robust shortest path problems. European Journal of Operational
Research, 274(2):671–686, 2019.

Trevor Campbell and Jonathan P How. Bayesian nonparametric set construction
for robust optimization. In 2015 American Control Conference (ACC), pages 4216–
4221. IEEE, 2015.

[CRKB20] Penny Chong, Lukas Ruﬀ, Marius Kloft, and Alexander Binder. Simple and eﬀective
prevention of mode collapse in deep one-class classiﬁcation. In 2020 International
Joint Conference on Neural Networks (IJCNN), pages 1–9. IEEE, 2020.

[DGR20]

[EGL97]

Trivikram Dokka, Marc Goerigk, and Rahul Roy. Mixed uncertainty sets for robust
combinatorial optimization. Optimization Letters, 14(6):1323–1337, 2020.

Laurent El Ghaoui and Herv´e Lebret. Robust solutions to least-squares prob-
lems with uncertain data. SIAM Journal on Matrix Analysis and Applications,
18(4):1035–1064, 1997.

[EGOL98]

Laurent El Ghaoui, Francois Oustry, and Herv´e Lebret. Robust solutions to uncer-
tain semideﬁnite programs. SIAM Journal on Optimization, 9(1):33–52, 1998.

[EK18]

[FJ18]

[GGJ20]

[GJ90]

Peyman Mohajerin Esfahani and Daniel Kuhn. Data-driven distributionally robust
optimization using the wasserstein metric: Performance guarantees and tractable
reformulations. Mathematical Programming, 171(1):115–166, 2018.

Matteo Fischetti and Jason Jo. Deep neural networks and mixed integer linear
optimization. Constraints, 23(3):296–309, 2018.

Francis Garuba, Marc Goerigk, and Peter Jacko. A comparison of data-driven
uncertainty sets for robust network design. arXiv preprint arXiv:2003.10507, 2020.

Michael R. Garey and David S. Johnson. Computers and Intractability; A Guide
to the Theory of NP-Completeness. W. H. Freeman & Co., New York, NY, USA,
1990.

[GS10]

Joel Goh and Melvyn Sim. Distributionally robust optimization and its tractable
approximations. Operations research, 58(4-part-1):902–917, 2010.

[HHL17]

L Jeﬀ Hong, Zhiyuan Huang, and Henry Lam. Learning-based robust optimization:
Procedures and statistical guarantees. arXiv preprint arXiv:1704.04342, 2017.

25

[IIC+19]

[KY96]

[LBH15]

[LDF11]

Rodrigo Toro Icarte, Le´on Illanes, Margarita P Castro, Andre A Cire, Sheila A
McIlraith, and J Christopher Beck. Training binarized neural networks using MIP
In International Conference on Principles and Practice of Constraint
and CP.
Programming, pages 401–417. Springer, 2019.

Panos Kouvelis and Gang Yu. Robust Discrete Optimization and Its Applications.
Springer, 1996.

Yann LeCun, Yoshua Bengio, and Geoﬀrey Hinton. Deep learning.
521(7553):436–444, 2015.

nature,

Zukui Li, Ran Ding, and Christodoulos A Floudas. A comparative theoretical
and computational study on robust counterpart optimization: I. robust linear op-
timization and robust mixed integer linear optimization. Industrial & engineering
chemistry research, 50(18):10567–10603, 2011.

[MPCB14] Guido F Montufar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. On the
number of linear regions of deep neural networks. In Advances in Neural Information
Processing Systems, pages 2924–2932, 2014.

[NY17]

[NY18]

Chao Ning and Fengqi You. Data-driven adaptive nested robust optimization: gen-
eral modeling framework and eﬃcient computational algorithm for decision making
under uncertainty. AIChE Journal, 63(9):3790–3817, 2017.

Chao Ning and Fengqi You. Data-driven decision making under uncertainty inte-
grating robust optimization with principal component analysis and kernel smooth-
ing methods. Computers & Chemical Engineering, 112:190–210, 2018.

[RPK+17] Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, and Jascha Sohl-
In International

Dickstein. On the expressive power of deep neural networks.
Conference on Machine Learning, pages 2847–2854. PMLR, 2017.

[RR17]

Blaine Rister and Daniel L Rubin. Piecewise convexity of artiﬁcial neural networks.
Neural Networks, 94:34–45, 2017.

[RVG+18]

Lukas Ruﬀ, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Shoaib Ahmed
Siddiqui, Alexander Binder, Emmanuel M¨uller, and Marius Kloft. Deep one-class
classiﬁcation. In International Conference on Machine Learning, pages 4393–4402,
2018.

[SD21]

Ahmed Saif and Erick Delage. Data-driven distributionally robust capacitated facil-
ity location problem. European Journal of Operational Research, 291(3):995–1007,
2021.

[SHY17]

Chao Shang, Xiaolin Huang, and Fengqi You. Data-driven robust optimization
based on kernel learning. Computers & Chemical Engineering, 106:464–479, 2017.

[Soy73]

[SY19]

Allen L Soyster. Convex programming with set-inclusive constraints and applica-
tions to inexact linear programming. Operations Research, 21(5):1154–1157, 1973.

Chao Shang and Fengqi You. A data-driven robust optimization approach to
scenario-based stochastic model predictive control. Journal of Process Control,
75:24–39, 2019.

26

[SZD+20]

Feifei Shen, Liang Zhao, Wenli Du, Weimin Zhong, and Feng Qian. Large-scale
industrial energy systems optimization under uncertainty: A data-driven robust
optimization approach. Applied Energy, 259:114199, 2020.

[TR14]

Theja Tulabandhula and Cynthia Rudin. Robust optimization using machine learn-
ing for uncertainty sets. arXiv preprint arXiv:1407.1097, 2014.

[WBB18]

Zichao Wang, Randall Balestriero, and Richard Baraniuk. A max-aﬃne spline
perspective of recurrent neural networks. In International Conference on Learning
Representations, 2018.

[WKS14] Wolfram Wiesemann, Daniel Kuhn, and Melvyn Sim. Distributionally robust con-

vex optimization. Operations Research, 62(6):1358–1376, 2014.

[WPS+21] Cong Wang, Xin Peng, Chao Shang, Chen Fan, Liang Zhao, and Weimin Zhong.
A deep learning-based robust optimization approach for reﬁnery planning under
uncertainty. Computers & Chemical Engineering, page 107495, 2021.

[YdH13]

[ZYX+08]

˙Ihsan Yanıko˘glu and Dick den Hertog. Safe approximations of ambiguous chance
constraints using historical data. INFORMS Journal on Computing, 25(4):666–681,
2013.

Zhi-Qiang Zeng, Hong-Bin Yu, Hua-Rong Xu, Yan-Qi Xie, and Ji Gao. Fast training
support vector machines using parallel sequential minimal optimization. In 2008 3rd
international conference on intelligent system and knowledge engineering, volume 1,
pages 997–1001. IEEE, 2008.

27

