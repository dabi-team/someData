1
2
0
2

r
a

M
7
2

]
P
S
.
s
s
e
e
[

2
v
4
4
0
1
1
.
2
0
0
2
:
v
i
X
r
a

©2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including
reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or
reuse of any copyrighted component of this work in other works.

 
 
 
 
 
 
Regression with Deep Learning for Sensor
Performance Optimization

Ruthvik Vaila∗ †, Denver Lloyd†, Kevin Tetz†
∗Boise State University
{ruthvikvaila}@u.boisestate.edu
†ON Semiconductor
{Ruthvik.Vaila, Denver.Lloyd, Kevin.Tetz}@onsemi.com

Abstract—Neural networks with at least two hidden layers
are called deep networks [1]. Recent developments in AI and
computer programming in general has led to development of tools
such as Tensorﬂow, Keras, NumPy etc. making it easier to model
and draw conclusions from data. In this work we re-approach
non-linear regression with deep learning enabled by Keras and
Tensorﬂow. In particular, we use deep learning to parametrize a
non-linear multivariate relationship between inputs and outputs
of an industrial sensor with an intent to optimize the sensor
performance based on selected key metrics.

Index Terms—Deep Learning, Sensor, non-linear regression,

Keras

I. INTRODUCTION

Deep learning has been used in plethora of applications
like autonomous driving, cancer prediction, low power object
recognition etc [2] [3] [4]. In particular, neural networks as
a regression tool have been used in applications like, time
series learning [5], stock prediction [6], pose estimation in
computer vision [7], cost predictions [8] etc. Traditionally,
linear regression with linear or non-linear coefﬁcients has been
used for modeling where real valued outputs are required.
Universal approximation theorem states that a feed forward
neural network with at least one hidden layer can approximate
a continuous function of Rn [9]. Neural networks use stochas-
tic gradient descent (SGD) [10] to achieve an acceptable
local minima that optimizes the output loss function. Many
industrial sensors require ﬁne tuning of the input settings to
attain a desired output. Figure 1 shows that the number of
experiments to be conducted increases by orders of magni-
tude with increase in resolution and number of inputs to a
sensor. In this work, we employed deep learning to model
the relationship between inputs and outputs of a sensor that
were collected at set intervals. Once a satisfactory model was
achieved, we used the model to interpolate the outputs for any
input combinations of the sensor that are within an allowed
range for that input. Using appropriate optimization criteria
we showed that we arrived at an input setting that maximized
or minimized required outputs of the given sensor.

II. BACKGROUND

We used a quadratic cost function on the output layer. Cost,

C is calculated by [1]

y − aL
C , (cid:13)
(cid:13)
2
where y, aL, al(= σ(zl)) are the label vector, the output
layer activation vector, and an activation vector of the lth

(BP1)

2
(cid:13)
(cid:13)

Fig. 1. Resolution indicates number of values a particular setting can assume.

layer respectively. Weights (wl) and biases (bl) are modiﬁed
to decrease C. Error vector on the output layer is given by

δL

= −(y − aL

) ⊙ σ′(zL

)

(BP2)

where σ, zl(= wlzl−1 + bl) represent a chosen activation
function of the neurons and net input to the lth layer respec-
tively. Error vector for internal layers is given by

δl

= ((wl+1)

T δl+1) ⊙ σ′(zl

)

(BP3)

where ⊙ denotes element wise multiplication. Updates to
biases and weights of a layer l are given by

∂C

∂bl = δl
∂wl = δla(l−1)T

∂C

Final weight update equation for layer l is given by

wl

= wl

− η

∂C
∂wl .

similarly, biases of layer l are updated according to

bl

= bl

− η

∂C
∂bl

(BP4)

(BP5)

(BP6)

(BP7)

where η is the learning rate which was set to 0.0005.

III. DATASET

Throughout the paper, we use the sensor data obtained from
ON Semiconductor. Given sensor has seven inputs and three
outputs, six of the inputs are numerical and seventh input is
categorical and can take four possible values. Histograms of
all the numerical inputs and outputs are shown in Figure 2.
Categorical variable is not shown in Figure 2. Each of the
inputs(1 to 4 and 6) assume ﬁve different values therefore we
have a total of 55(3125) possible combinations. For each of
the possible combinations, Input5 was swept from 0 − 49. As
there are four categorical variables, each of the input setting
combinations yields a table (DataFrame) of 50 ∗ 4(= 200)
rows. As there are 3125 possible setting combinations the ﬁnal
dataset contains 3125 ∗ 200(= 625000) rows and each row is
applied as an input to the sensor resulting in three outputs
consisting of Signal, SNR and Output3. Therefore, the input
to the neural network is ∈ R625000×10 and the output is ∈
R625000×3.

TABLE I
CONCERNED SENSOR OF THIS WORK WAS PRESENTED WITH ALL THE
COMBINATIONS OF INPUT1, INPUT2, INPUT3, INPUT4, INPUT6 VALUES
GIVEN IN THE TABLE. FOR EACH OF THE COMBINATION, INPUT5 WAS
SWEPT FROM 0 − 49 OBTAINING A SINGLE SIGNAL [AU] VS SNR [DB]
CURVE. NOTE THAT THE RESOLUTION OF INPUTS FOR WHICH OUTPUTS
WERE RECORDED IS 22, 8, 25, 200 AND 200 FOR INPUTS 1, 2, 3, 4 AND 6
RESPECTIVELY.

Input1
418
441
464
478
510

Input2
112
120
128
136
144

Input3
400
425
450
475
500

Input4
2850
3050
3250
3450
3650

Input6
3200
3400
3600
3600
4000

IV. NEURAL NETWORK

A neural network with three hidden layers, mean squared
error (MSE) cost function and a leaky ReLU activation func-
tion (σ) was chosen. Our network has 10 input and 3 output
neurons which are determined by the dataset. Training was
performed using Keras [11] with Tensorﬂow [12] back end and
Adam was the chosen optimizer . Network’s Keras summary
is given in Figure 3.

A. Data pre-processing

The Signal vs SNR relation of the data from the concerned
sensor is approximately log linear for initial Signal values,
it is shown in the Figure 7. The Signal [AU] column of
the dataframe was log transformed and all
the inputs to
the neural network were normalized by dividing an input
with the maximum value it could assume. Therefore, all the
inputs to the neural network are in between 0 and 1. Outputs
were similarly normalized. All the data were converted to
dataframes using Pandas [13].

B. Modeling

Data were split into training (81% ), validation (9% ) and
testing (10% ). Our network was trained for 100 epochs

Fig. 2. Histogram of all the numerical inputs and outputs.

Fig. 3. Keras sumary of the ﬁnal neural network that was used to model the
data.

and learning rate was reduced by a factor of two for every
consecutive ﬁve epochs if the validation error did not decrease.
Batch size was set to 20 and we report the mean square error
(MSE) to be 4 × 10−5 on the validation set.

C. Prediction and Evaluation

Once the model was trained, training data, testing data and
validation data were passed through the network to obtain the
predictions for the required outputs (SNR[dB], Signal [AU],
Output3). Note that the model/network has not ’seen’ the
testing data directly and validation data was ’seen’ indirectly
in that it was used to optimize for the learning rate. Figure 4
shows the Actual vs Predicted plot for SNR[dB] in testing data
and it is a linear plot indicating that the model was successful
in predicting the SNR[dB] values for unseen data.

[dB] curve. Note that Signal [AU], SNR [dB] and Output3 are
the outputs of the trained neural network. The trained model
was used to predict Signal [AU] vs SNR [dB] plots for a large
number ( ≈ 12 × 106) of interpolated settings combinations
within the domains of all the input settings, to that end we
increased the resolution of the numerical inputs listed in Table
I. Similar to the original dataset, each of the interpolated input
settings combinations also yields a single Signal [AU] vs SNR
[dB] curve. Shown in Figure 7 is a Signal [AU] vs SNR [dB]
curve for a randomly chosen interpolated input settings, green
and blue colors indicate ideal and predicted Signal [AU] vs
SNR [dB] relationships. In this case, Input1, Input2, Input3,
Input4 and Input6 happened to be 418, 112, 400, 2850 and
3200 respectively and the value of Output3 is 2.9365. The
green colored line indicates the ﬁtted line of Signal [AU] with
SNR [dB] for Signal [AU] values that are less than 2 × 103 .

Fig. 4. Actual vs Predicted plot for SNR [dB] in the testing dataset. Goodness
of ﬁt (R2) was found to be 0.990

Figures 5, 6 show Actual vs Predicted plots of Signal [AU],

Output3 for testing datasets.

Fig. 5. Actual vs Predicted plot for Signal [AU] in the testing dataset.
Goodness of ﬁt (R2) was found to be 0.999

Fig. 7. Plot of Signal [AU] vs SNR [dB].

Fig. 6. Actual vs Predicted plot for Output3 in the testing dataset. Goodness
of ﬁt (R2) was found to be 0.999

V. OPTIMIZATION

The goal of the optimization process is to obtain a settings
combination (of Input1, Input2, Input3, Input4 and Input6)
is
that results in a Signal [AU] vs SNR [dB] curve that
closest to the ideal one and minimize the value of Output3.
For the sensor under consideration, the ideal SN R[dB] =
10 log10(pSignal[AU ]). Each of the settings combinations
(of Input1, Input2, Input3, Input4 and Input6) results in a
dataframe of 200 rows because Input6 is swept from 0−49 and
the categorical variable assumes four different categories and
each of these dataframes yields a single Signal [AU] vs SNR

Fig. 8. Zoomed plot of Signal [AU] vs SNR [dB] in the interval ≈ 3 ×
103 − 104 AU from the sensor for a single settings combination. Recorded
prominence (SNR[dB] drop) value for this settings combination was ≈ 5.77
dB.

Blue curve in Figure 7 shows a linear relationship until
Signal [AU] reaches ≈ 3 × 103 AU. Ideally, we expect this
behavior to continue for the rest of the Signal values. A sudden
dip of ≈ 5 dB is noticeable when the Signal [AU] value is in
the range, ≈ 3 × 103 − 104 AU. Since it is highly unlikely to
achieve an ideal performance, we set a few criteria to choose
a particular settings combination that could give the smallest
dip in the SNR value at the interval ≈ 3 × 103 − 104 AU
and a Signal [AU] vs SNR [dB] curve that is closest to the
ideal Signal [AU] vs SNR [dB] curve. The best interpolated
input combination was ﬁltered by applying different criterion
described below. Lower values are preferred for all the criteria.
• MAE between ideal and predicted (criterion 1): Mean
Absolute Error (MAE) was calculated for each of the

input combinations and serial numbers of each of the
dataframes (a single settings combination) was ordered
in an ascending order of the calculated MAEs.

• Prominence of SNR dip (criterion 2): Serial numbers of
each of the dataframes (a single input settings combina-
tion) was ordered in an ascending order of the calculated
dip in SNR [dB] value at ≈ 3 × 103 − 104 AU.

• MAE between ﬁtted line and predicted (criterion 3):
Serial numbers of each of the dataframes (of a single
input settings combination) was ordered in an ascending
order of the calculated for MAE between ﬁtted green line
and predicted blue curve of Figure 7. Green line was ﬁtted
for Signal [AU] vs SNR [dB] upto ≈ 3 × 103 − 104 AU
and extrapolated for the rest of the Signal [AU] values.
• Least value for Output3 (criterion 4): Serial numbers of
each of the dataframes (a single input settings combina-
tion) was ordered in an ascending order of the calculated
Output3 value.

The ﬁrst
the indices
index among the intersection of all
obtained from the above steps gives the optimal input setting
combination with a Signal [DN] vs SNR [dB] curve that meets
all the above criteria. Figure 9 shows the optimized curve.

Fig. 9.
considered.
430, 120, 485, 2900, 3525 respectively.

Plot of Signal [AU] vs SNR [dB] when all
Input3,

Input1,

Input2,

Input4,

the criteria were
Input6 were found to be

TABLE II
CRITERIA VALUES WHEN OPTIMIZED FOR BOTH SNR [DB] AND OUTPUT3.

criterion 1
1167.50

criterion 2
3.9

criterion 3
384.73

criterion 4
2.64

Table II shows the numerical values of different criteria used
in the optimization process. If criterion 4 was excluded from
the optimization criteria (i.e., Signal [AU] vs SNR [dB] curve
not optimized for Output3) then the Signal [AU] vs SNR [dB]
is shown in Figure 10 and corresponding values of criteria are
shown in Table III.

[AU] vs SNR [dB] when criterion 4
Fig. 10.
was ignored.
Input6 were found to be
Input3,
Input1,
426, 112, 495, 3000, 3600 respectively.

Plot of Signal
Input2,

Input4,

TABLE III
CRITERIA VALUES WHEN OPTIMIZED ONLY FOR SNR [DB].

criterion 1
1043.09

criterion 2
3.68

criterion 3
372.75

criterion 4
2.88

Figure 10 was obtained by optimizing for only Signal [AU]
vs SNR [dB] curve. Hence, criterion 4 of the Table III shows
higher value than that of criterion 4 in the Table II.

VI. CONCLUSION

We have shown that deep neural networks can be success-
fully used for black box modeling of industrial sensors and
the obtained model can be used to signiﬁcantly speedup and
improve the sensor performance optimization.

VII. ACKNOWLEDGMENTS

Kevin Tetz proposed the idea and collected the sensor data,
Ruthvik Vaila pre-processed the sensor data and setup the
Machine Learning and Optimization pipelines, Denver Lloyd
assisted in coding and discussions regarding the project. We
thank the management at ON Semiconductor for providing us
an opportunity to publish the work.

REFERENCES

[1] M. A. Nielsen, “Neural Networks and Deep Learning,” Jan 2015.
[2] R. Vaila, J. Chiasson, and V. Saxena, “Feature extraction using spiking
convolutional neural networks,” in Proceedings of
the International
Conference on Neuromorphic Systems, ICONS ’19, (New York, NY,
USA), Association for Computing Machinery, 2019.

[3] R. Vaila, J. Chiasson, and V. Saxena, “Deep convolutional spiking neural

networks for image classiﬁcation,” 2019.

[4] V. Saxena, X. Wu, I. Srivastava, and K. Zhu, “Towards neuromorphic
learning machines using emerging memory devices with brain-like
energy efﬁciency,” Journal of Low Power Electronics and Applications,
vol. 8, no. 4, 2018.

[5] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural

Computation, vol. 9, no. 8, pp. 1735–1780, 1997.

[6] A. N. Refenes, A. Zapranis, and G. Francis, “Stock performance
modeling using neural networks: A comparative study with regression
models,” Neural Networks, vol. 7, no. 2, pp. 375 – 388, 1994.

[7] S. Lathuili`ere, P. Mesejo, X. Alameda-Pineda, and R. Horaud, “A

comprehensive analysis of deep regression,” 2018.

[8] A. E. SMITH and A. K. MASON, “Cost estimation predictive modeling:
Regression versus neural network,” The Engineering Economist, vol. 42,
no. 2, pp. 137–161, 1997.

[9] K. Hornik, M. Stinchcombe, and H. White, “Multilayer feedforward
networks are universal approximators,” Neural Networks, vol. 2, no. 5,
pp. 359 – 366, 1989.

[10] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning
applied to document recognition,” Proceedings of the IEEE, vol. 86,
pp. 2278–2324, Nov 1998.

[11] F. Chollet, Deep Learning with Python. USA: Manning Publications

Co., 1st ed., 2017.

[12] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S.
Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow,
A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur,
J. Levenberg, D. Mane, R. Monga, S. Moore, D. Murray, C. Olah,
M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker,
V. Vanhoucke, V. Vasudevan, F. Viegas, O. Vinyals, P. Warden, M. Wat-
tenberg, M. Wicke, Y. Yu, and X. Zheng, “Tensorﬂow: Large-scale
machine learning on heterogeneous distributed systems,” 2016.

[13] W. McKinney et al., “Data structures for statistical computing in
the 9th Python in Science Conference,

python,” in Proceedings of
vol. 445, pp. 51–56, Austin, TX, 2010.

