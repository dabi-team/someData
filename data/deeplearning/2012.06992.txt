Edge Intelligence for Autonomous Driving in 6G
Wireless System: Design Challenges and Solutions

Bo Yang, Member, IEEE, Xuelin Cao, Kai Xiong, Chau Yuen, Senior Member, IEEE, Yong Liang Guan, Senior
Member, IEEE, Supeng Leng, Member, IEEE, Lijun Qian, Senior Member, IEEE, and Zhu Han, Fellow, IEEE

1

0
2
0
2
c
e
D
3
1

]
I

N
.
s
c
[

1
v
2
9
9
6
0
.
2
1
0
2
:
v
i
X
r
a

Abstract—In a level-5 autonomous driving system, the au-
tonomous driving vehicles (AVs) are expected to sense the
surroundings via analyzing a large amount of data captured
by a variety of onboard sensors in near-real-time. As a result,
enormous computing costs will be introduced to the AVs for
processing the tasks with the deployed machine learning (ML)
model, while the inference accuracy may not be guaranteed.
In this context, the advent of edge intelligence (EI) and sixth-
generation (6G) wireless networking are expected to pave the
way to more reliable and safer autonomous driving by providing
multi-access edge computing (MEC) together with ML to AVs in
close proximity. To realize this goal, we propose a two-tier EI-
empowered autonomous driving framework. In the autonomous-
vehicles tier, the autonomous vehicles are deployed with the
shallow layers by splitting the trained deep neural network
model. In the edge-intelligence tier, an edge server is implemented
with the remaining layers (also deep layers) and an appropriately
trained multi-task learning (MTL) model. In particular, obtaining
the optimal ofﬂoading strategy (including the binary ofﬂoading
decision and the computational resources allocation) can be
formulated as a mixed-integer nonlinear programming (MINLP)
problem, which is solved via MTL in near-real-time with high
accuracy. On another note, an edge-vehicle joint inference is
proposed through neural network segmentation to achieve ef-
ﬁcient online inference with data privacy-preserving and less
communication delay. Experiments demonstrate the effectiveness
of the proposed framework, and open research topics are ﬁnally
listed.

I. INTRODUCTION
Different from the conventional cellular networks, the next-
generation wireless networks, with various labels such as
beyond ﬁfth-generation (B5G) or sixth-generation (6G), are
expected to provide a connection for vehicular networks with
low latency but high reliability ubiquitously via artiﬁcial
intelligence (AI) [1]. To prevent accidents caused by human
driving errors and to carry out emissions reduction, automated
driving systems have been developed by tightly integrating
with promising technologies, such as surround sensing, object
detection and tracking, control decision-making, and wireless
ofﬂoading via multi-access edge computing (MEC) [2], [3].
During the past decades, machine learning (ML), especially
deep learning (DL), has become a promising technology due to
its superiority in extracting inherent features from large-scale
and high-dimensional datasets, which are collected from em-
bedded sensors such as camera sensors, LiDAR sensors, radar
sensors [4]. By feeding the inferred results to the electronic
control unit (ECU) of a vehicle, the AVs can dynamically ad-
just the vehicle’s velocity, brake, and steering according to the
surrounding conditions to achieve autonomous or cooperative
adaptive cruise control (CACC). Nevertheless, the inferring
accuracy usually depends on the input data and capability of

the deployed DL model. For example, the object is difﬁcult
to be identiﬁed via the convolutional neural network (CNN)
model if the input images data is blurry or if the CNN model
has not been sufﬁciently trained [5].

In recent years, Internet-of-Vehicle (IoV) networks undergo
a paradigm shift from connected vehicles to connected in-
telligence. The future of vehicular communications may be a
mashup of dedicated short-range communications (DSRC) and
cellular vehicular-to-everything (C-V2X, also LTE Rel.16+).
Today the ﬁght among vehicular communication standards
is between “802.11p/DSRC” and “C-V2X”
[6]. 802.11p
has the advantage that 5.9 GHz has been approved by the
Department of Transportation and the European Commission,
and the technology is ready for deployment for basic short-
range communications. For “Driver-less V2X”, the situation is
different. Due to the massive data anticipated in MEC, 802.11p
will likely not be sustainable without signiﬁcant amendments
to the current standard. In this context, the innovative aspects
anticipated via C-V2X within B5G/6G will play a key role.

As a promising application, the thriving autonomous driving
has led to an upsurge of MEC and AI, which drives the
prosperity of edge intelligence (EI) for greatly facilitating daily
life [7]–[9]. In this context, EI enables autonomous driving
vehicles (AVs) to sense and react to the surroundings accu-
rately by ofﬂoading the collected data to the powerful edge
server co-located with the base station (BS), as highlighted
in Fig. 1. By deploying EI-based computing service at the
edge server, inference computing of AVs can be achieved with
higher accuracy and lower latency. However, many inherent
issues associated with communication and computing under
limited bandwidth and computation resources, data privacy
and security, present stumbling blocks toward the envisioned
goal of autonomous driving in 6G era. Motivated by the
above-mentioned appealing characteristics, a ﬂurry of research
activities combining 6G with EI in the autonomous driving
system designs has been sparked.

In this vein, this article aims to explore the EI challenges
in autonomous driving, investigate recent contributions and
advances, and then propose solutions. The major contributions
and organization of this article are summarized as follows. We
overview the efforts that have been made on edge intelligence
in vehicular networks and pose the design challenges in
the developed two-
Section II. In Section III, we present
tier EI-empowered autonomous driving framework, which
outperforms the existing works in the following two folds:
1) achieving the intelligent ofﬂoading strategy via multi-
task learning in near-real-time, and 2) achieving the joint
inference with privacy-preserving and less communication

 
 
 
 
 
 
2

Fig. 1: An illustrative scenario of autonomous driving system.

delay through neural network segmentation. In particular, a
multi-task learning model is deployed at the edge server to
infer the optimal ofﬂoading decision of the vehicles and the
computation resource allocation of the edge server with high
accuracy in near-real-time, augmented by a neuron network
segmentation method to achieve efﬁcient online inference
dynamically with privacy-preserving and less latency raised. A
case study is presented to demonstrate the proposed framework
and then evaluated via experiments in Section IV, followed by
listing some critical open research topics and future guidelines
in Section V.

II. WHERE EDGE INTELLIGENCE MEETS AUTONOMOUS
DRIVING: APPLICATIONS AND CHALLENGES

In this section, we list some EI applications in autonomous

driving and discuss the technical challenges raised.

A. Applications of EI in Autonomous Driving

There has been lately increasing research interest in incorpo-
rating AI technology (e.g., ML and DL) into edge computing,
known as EI, which can help achieve efﬁcient computing
and intelligent decision making to keep the roads safe. In
the following, we list some fundamental computation-intensive
applications aided by EI in autonomous driving, such as object
detection, trafﬁc ﬂow prediction, and path planning.

1) Object Detection: Real-time video analytics has been
widely applied in autonomous driving (see Fig. 1), where the
data captured by the cameras and other onboard sensors is
analyzed via the AI techniques. To achieve safe and efﬁcient
driving (e.g., reduce accidents and decrease trafﬁc congestion),
autonomous vehicles should identify the objects timely and
accurately according to the surroundings. However, executing
this kind of delay-sensitive tasks via DL generally requires
high computation resources onboard and incurs high band-
width consumption by uploading the tasks to the remote cloud
centers. To address the issues and make autonomous driving

possible, EI enables the self-driving vehicles to move some of
the video analysis to the edge servers, which are usually near
the data sources and can improve the inference accuracy.

2) Trafﬁc Flow Prediction: With the ever-increasing hu-
man demands on the intelligent transportation system and
the adoption of autonomous vehicles,
timely and accurate
acquisition of trafﬁc ﬂow information will lay out the foun-
dation for many location-related applications, e.g., navigation.
However, massive volumes of environmental data with various
sources will seriously saturate the onboard storage and become
too complex to satisfy the requirements with the traditional
computing techniques and infrastructures [10]. To meet this
challenge, EI represents a trend of “driverless revolution
on big data”. Speciﬁcally, by combining AI with advanced
edge computing techniques, the computation resources can
be expanded to the edge server to achieve state-of-the-art
performance for hierarchical features learning from the high-
dimensional dataset and satisfy real-time requirements of the
time-consuming tasks.

3) Intelligent Decision: Recent years have shown remark-
able attention on intelligent decision in autonomous driving,
e.g., online path planning, which aims to improve road safety
by avoiding collision with the surrounding obstacles, vehicles,
and infrastructure. With feasible path planning, AVs can make
reasonable decisions on the critical maneuvers (such as brak-
ing, turning, and overtaking.) according to the surroundings
by feeding the inferring results into the onboard ECU or
the CACC system. In practice, intelligent decision can be
formulated as an optimized decision-making problem taking
into account the vehicle dynamics, which, however, makes
the decision hardly be achieved in time [10]. Notably, this
becomes a concern increasingly when the B5G/6G paradigm
is taken into account. To meet this concern, EI can be a revolu-
tionary breakthrough by inferring an optimal decision directly
in near-real-time via a well trained DL model deployed at the
edge [11]. Different from the conventional cloud computing-
based methods, e.g., Google Map, with the aid of AI func-

               BSEdge ServerAVAVAVAVAVAV: Autonomous-driving VehicleBS: Base StationVehicle-to-Infrastructure (V2I) communicationsGround-to-ground level transmissionA typical structure of AVtioning on the edge, EI can signiﬁcantly decrease the wireless
communication delay by allowing AVs to upload the collected
data (such as vehicle conditions and surroundings data) to the
edge server. As a result, the AVs may obtain the inferring
results within a limited time, and thus an intelligent, timely,
and reliable decision is prone to be achieved at AVs, especially
when the surrounding conditions change dramatically.

B. Technical Challenges

1) Infeasible Sensing:

In practice, due to the intrinsic
features of the embedded sensors, they usually have restricted
perception capacities, which lead to infeasible sensing of
surroundings. Speciﬁcally, as a primary sensing method, the
main drawback of visual-based object detection is that the
inference performance (e.g., the accuracy of multi-class clas-
siﬁcation) usually relies on the captured images quality. The
image quality can be affected by the surroundings, such as
light conditions, weather conditions, image resolution, and
the distance between camera and object. According to Na-
tional Transportation Safety Board (NTSB) accident report, a
Uber self-driving testing vehicle struck a pedestrian who was
dressed in dark clothing and walked a bicycle across the road
in Arizona at about 9:58 p.m. on March 18, 2018. The bicycle
did not have any side reﬂectors, and the roadway lighting
did not directly illuminate the roadway section. As a result,
the pre-trained deep learning model mistakenly classiﬁed the
pedestrian as an unknown object ﬁrst, then as a vehicle, and
ﬁnally, as a bicycle with varying expectations of the future
travel paths. It is observed from this accident that the decision-
making by a single kind of sensors (e.g., the cameras in
Uber’s testing case) alone has tended to introduce serious
accidents. To avoid this, a promising candidate method is to
fuse alternate sensing modalities for perception, e.g., fusing
from the LiDAR sensors,
the
intelligent trafﬁc lights, and querying the sensors from other
vehicles. This kind of technology is known as sensor fusion,
2) Trade-off between Reliability and Latency: The infer-
ence performance generally includes not only the inference
accuracy but also the inference delay. Since the inference
accuracy of a pre-trained DL model is mainly determined by
the input data quality and the model capability, the inference
accuracy can be degraded due to the “bad quality” data
and shallow neural networks model. Besides, an additional
communication delay is introduced by ofﬂoading the tasks
from the mobile device to a more powerful edge server with
a deeper neural network model. Nevertheless, the channel
dynamics may sometimes disable the ofﬂoading. Even if not,
the introduced delay could be fatal to delay-sensitive appli-
cations. Therefore, there exists a trade-off between inference
accuracy and latency, which makes careful consideration on
the design of edge intelligence inevitable [5]. In order to
achieve a comfortable balance between the reliability and the
latency raised, it becomes necessary to decrease the wireless
transmission delay between the devices and the edge server.
For example, the achievable rate of the wireless link can
be improved via some promising technologies in future 6G
networks, such as mmWave transmission, massive MIMO,

the sensors implemented at

3

and holographic reconﬁgurable intelligent surfaces. On another
note, the data can further be ofﬂoaded to other mobile devices
via the device-to-device links with a shorter distance. In
the considered vehicular networks, the vehicles may directly
ofﬂoad the data to their neighboring vehicles via cellar-V2V
or even PC5 interfaces.

3) Limited Resources: Compared to a large amount of pow-
erful graphics processing units (GPUs) and central processing
unit (CPUs) integrated at the cloud, the edge servers usually
can hardly bear a massive volume of ofﬂoading requests from
the devices due to the constraint of computation, caching, and
power resources on edge servers, and limited communication
bandwidth. In this context, joint optimization of ofﬂoading
decisions and allocation on the limited resources available at
the edge server plays a particularly important role in edge
intelligence.

4) Data Security and Privacy:

In many application do-
mains of edge intelligence, data security and privacy issues
are critical because the mobile devices’ data required to be
processed and inferred might carry much private-sensitive
information that may not want to be captured [12], [13]. Take
autonomous driving as an example, where the AVs capture
a vast amount of images containing privacy information.
Suppose that this kind of information is directly ofﬂoaded to
the edge server to be processed, the user privacy may leak.
In general, this issue may occur in both the model training
and inference. To address this issue, performing simple pro-
cessing (or training) at the device ﬁrst and then uploading the
intermediate features to the edge server become promising.

III. MAIN FUNCTIONALITIES IN AUTONOMOUS DRIVING
EDGE INTELLIGENCE

In this section, we discuss how edge intelligence supports
the key functionalities of autonomous driving and list four
functionality modules, as illustrated in Fig. 2.

A. Data Collection Module

As a fundamental building block in the autonomous driving
system, the data collection module collects the data via the
onboard sensors. In general, the collected data can be roughly
classiﬁed into two categories: sensing data and vehicle status
data. In particular, the sensing data includes the data collected
from the onboard sensors, such as video cameras, LiDAR
sensors, and radar sensors. The vehicle status data usually re-
veals the vehicles’ computation resources, e.g., the CPU/GPU
processing capability, energy power, and storage capabilities.

B. Distributed Learning Module

Distributed learning (e.g., the federated learning) via the
local datasets has gained considerable attention for provid-
ing an EI service for autonomous driving with privacy-
preserving [13]. In particular, distributed learning is operated
at the edge devices based on their collected datasets. Then the
trained local model parameters are uploaded to the edge server
for aggregation. This procedure repeats many times until the
model converges. In this context, AVs can collaboratively

4

Fig. 2: Illustration of the four functionality modules.

train a shared model using real-time generated mobile data.
Although the distributed learning performed by massive edge
devices is sometimes time-consuming due to the limited com-
munication bandwidth, it is envisioned that distributed learning
architectures will still get a considerable boost in autonomous
driving since more advanced communication technologies are
being used under the future B5G/6G networks [1].

C. Ofﬂoading Strategy Decision Module

Ofﬂoading strategy decision making within the critical time
window is crucial for safety achievement
in autonomous
driving networks. Traditionally, ofﬂoading strategy decision
making includes two aspects: ofﬂoading decision and com-
putation resources allocation. The ofﬂoading strategy decision
making can be formulated as an optimization problem with
performance metrics in latency and energy consumption. For
the general self-driving scenarios, ofﬂoading strategy deci-
sion making involves solving a mixed integer programming
problem that is usually NP-hard and difﬁcult to solve via
conventional mathematical techniques near-real-time [3]. One
promising approach is to apply deep learning for solving this
kind of optimization problem by training a deep learning
model to learn the mapping between the problem input pa-
rameters and the optimal solution.

D. Online Inference Module

As the ﬁnal step in the edge learning loop (as shown in
Fig. 2), the driving maneuvers are generated by the online
inference module based on the new input data. On the one
hand, for the local inference mode (i.e., the inference is made
at the vehicles), the inference performance mainly depends
on the vehicle’s computing capability, which is power limited.
On the other hand, introducing edge inference could provide
low-latency services for AVs by feeding the data into the

trained DL model deployed at the edge server. However, edge
inference still faces many challenges, e.g., data privacy and
limited computation capability, which can hardly fully bear
and store the sizeable trained ML model.

IV. TWO-TIER EDGE INTELLIGENCE-EMPOWERED
AUTONOMOUS DRIVING FRAMEWORK

Motivated by the preceding considerations, we materialize
EI-empowered object detection for autonomous driving and
propose in this article a two-tier (including the AV-tier and
the EI-tier) autonomous driving framework with a set of
design guidelines, as shown in Fig. 3. In the following, we
shall discuss speciﬁc components of the proposed framework
and provide a concrete application example to illustrate the
paradigm shift of autonomous driving.

A. Intelligence Ofﬂoading via Multi-task Learning

In the EI-based autonomous driving system, we formulate
the binary ofﬂoading decision-making (i.e., ofﬂoad or not) and
the computational resources allocation (denoting how many
computational resources can be allocated to each vehicle) as
a mixed-integer nonlinear programming (MINLP) problem,
which is generally NP-Hard and challenging to solve. In
particular, some factors (such as the number of vehicles, the
computational capability of vehicles, and the channel condi-
tions.) may vary over time, so the conventional relaxation-
based optimization procedure must be executed repeatedly
on solving the MINLP each time the parameters change.
Therefore, high computational complexity is incurred due to
numerical iterations, and the solutions are often sub-optimal
and would not scale well [11]. This is increasingly concerned
when B5G/6G and IoT paradigms are taken into account [1].
To meet the coming challenges, one promising approach is
to apply deep learning for solving this kind of NP-hard
optimization problem by training a deep learning model to

Sensing data: camera, LiDAR, radar, ...Data CollectionVehicle status: energy, storage, computation ...Learning at vehiclesDistributed LearningAggregation at edgeMathematical-based optimizationOffloading Strategy DecisionMachine learning-based optimizationInference at vehiclesOnline InferenceInference at edgeJoint inferenceSensing / vehicle training dataset Trained modelInference resultsSensing / vehicle Input data Offloading strategy5

Fig. 3: An illustrative two-tier edge intelligence structure for autonomous driving system.

‘learn’ the mapping between the problem input parameters
and the optimal solution. In this paper, we build a multi-
task learning (MTL) based framework to infer the solutions
more efﬁciently with high accuracy, as illustrated in Fig. 3(a).
In particular, a deep neural network model is designed and
trained ofﬂine at the BS to obtain the mapping relationship
from the input parameters to the output solutions. Therefore,
on receiving the ofﬂoading requests from the AVs, the BS can
directly infer the optimal ofﬂoading strategy decision in near-
real-time by performing feedforward calculation via the MTL
model without iterations, as shown in Fig. 3(b).

B. Edge-Vehicle Joint Inference

In the autonomous driving system,

the online inference
local-inference mode,
can be classiﬁed into three modes:
edge inference mode, and joint
inference mode. For the
local inference, the vehicles perform the inference themselves.
The inference performance mainly depends on the available
computational capability (computation resources and storage
space) of the vehicles, which, however, is usually very lim-
ited [5]. For the edge inference, the raw data must be uploaded
to the edge server via the wireless uplink. We note that there
exist
two potential hazards associated with this approach.
One is data privacy due to data fully uploading to the edge
server. The other is that considerable communication delay is
introduced once many vehicles upload their raw data with large
size and quantity via the bandwidth-limited uplink channel.
Motivated by the challenges in the previous two inference
modes, the edge-vehicle joint inference becomes promising by
dividing the trained deep neural network (DNN) model into
two parts: the shallow neural network (SNN) layers at the
vehicle side, and the DNN layers at the edge side. Therefore,
the vehicles only need to upload the intermediate parameters

to the edge server to reduce the end-to-end latency with
joint-inference. In practice, the limited latency gains can be
achieved due to the data ampliﬁcation effect, which indicates
that the size of intermediate output data of the deep neural
networks is larger than that of the input data. In this context,
choosing an appropriate splitting point while avoiding the
data ampliﬁcation effect becomes critical, and thus the size
of uploaded parameters could be far less than the size of raw
data by designing the neural networks model appropriately.

C. Case Study: EI-Assisted Visual Object Detection

In this section, we consider a visual object detection based
autonomous driving system. Due to limited computing re-
sources and a tight energy budget of self-driving vehicles, they
usually need help from the BS to collaboratively process the
delay-sensitive tasks. Since the ofﬂoading strategy decision-
making with minimization of AVs’ energy consumption and
latency can be formulated as an MINLP problem, which is NP-
Hard, we design an MTL-based feedforward neural network
model by learning the end-to-end mapping between the prob-
lem input parameters and the output solutions. Speciﬁcally,
the binary ofﬂoading decision is considered as a multi-class
classiﬁcation problem with the cross-entropy loss, and the
edge server computational resource allocation is considered
as a regression problem with the mean square error (MSE)
loss. During the MTL training, the Adam optimizer is used
to minimize the weighted-sum loss, where χc and χl denote
their weights, respectively. It should be noted that the size
of the appropriately trained MTL model is less than 2 KB,
and thus the edge server has enough storage space to save
the trained MTL model, which can be even cached into the
edge server’s memory in advance to perform the inference
more efﬁciently. With the ofﬂine trained MTL model, the BS

BS    Edge Server Multi-task LearningTask ATask BModel SegmentationEdge-intelligence Tier...DNN LayersAutonomous-vehicles TierAVsEdge Server(1) Intelligent Computation Offloading(2) Edge-Vehicle Joint InferenceOffloading requestsOffloading strategySNN LayersOffloading Strategy PredictionIntermediate featuresLocal InferenceInference resultsEdge Inference(a) The two-tier autonomous driving structure(b) The communication process(1)(2)6

Fig. 4: A case study on the proposed two-tier autonomous driving framework.

can directly infer the ofﬂoading strategy with high accuracy in
near-real-time by performing feedforward calculation without
iterations, as illustrated in step 1) - step 2) in Fig. 4. Therefore,
the proposed MTL-based method “moves” the complexity of
online computation to ofﬂine training, which can be scaled up
across the graphics processing unit (GPU) clusters.

To achieve privacy-preserving and meet the hardware con-
straint of AVs, we investigate it by segmenting a trained
CNN model into the lower-level SNN layers and the higher-
level DNN layers. In particular, the SNN layers and DNN
layers usually contain convolutional
layers, rectiﬁed linear
units layer, polling layer, and fully-connected layers. The
SNN layers are deployed on the resource-constrained vehicles,
usually with limited computation resources and storage space.
All the AVs share the same DNN layers, which are deployed
at
the edge server and can further improve the inference
accuracy by processing the feature maps generated by the
SNN layers. This edge learning setup fulﬁlls the demand for
the timely processing of the video images while taking into
account the practical implementation constraints, e.g., users’
privacy. As illustrated in step 3) - step 4) in Fig. 4, the
lower layers can directly provide sufﬁcient features for the
acceptable object detection performance without ofﬂoading
when the captured images quality is sufﬁciently “good”. On

the contrary, the captured images with “bad” quality would
ofﬂoad the intermediate feature maps to the higher layers at
the edge server to improve inference accuracy. The edge server
then returns the processing results, which help the vehicles
react fast and accurately via the ECUs.

D. Illustrative Results

In this subsection, we ﬁrst evaluate in Fig. 5(a) the impact
of the number of training samples on the inference accuracy of
the MTL model, where χc = χr = 1. The inference accuracy
is deﬁned as the ratio of the number of correct predictions
to the total number of predictions. We generate 4 × 104
data samples by traversing the combinations of the binary
ofﬂoading decision and computational resources allocation
ratio with the exhaustive searching algorithm. In Fig. 5(b), we
compare the accuracy of the proposed MTL model with that
of the conventional spatial branch and bound (sBB) algorithm,
where χc = 0 and χr = 1 when the number of AVs is larger
than 5, and the percentage of training samples in MTL model
is 1. After, we investigate in Fig. 6 the impact of the “bad”
data ratio (denoted as η) on the weighted-sum cost (deﬁned as
the weighted sum of the delay and energy consumption of all
the AVs) using different inference strategies in the autonomous
driving system.

BS    Edge Server SNN layersMulti-task Learning (MTL) Model1) Offloading requests2) Offloading strategy inferred by MTL modelSNN layersDNN layersCaptured ImagesSpeed control, brake control,  direction control...Fast-inference results Intermediate features4) Enhanced-inference results sent to ECUSNN layersSNN layersSNN layersSNN layersAutonomous-vehicles TierEdge-intelligence Tier3) Features offloadingSNN layersEdge-Vehicle Joint InferenceIntelligent Offloading via MTLEdge Inference7

(a)

(b)

Fig. 5: Inference accuracy of the classiﬁcation and the MSE of the regression in the MTL model versus the percentage of training samples is shown in (a),
where the number of AVs is 2. In (b), the number of AVs versus the accuracy achieved by the sBB algorithm and the multi-task learning model is illustrated,
respectively, where the percentage of training samples in multi-task learning model is 1.

using multi-task learning, the time consumption solving the
MINLP is less than one-thousandth of the sBB scheme when
the number of AVs varies from 2 to 8.

Fig. 6 shows that when the “bad” data ratio (denoted
as η) becomes larger (e.g., more captured images are with
low quality), this leads to an increase of the weighted-sum
cost using three inference methods. Speciﬁcally, when η is
relatively small, e.g., η < 0.3, inference at vehicles becomes
more competitive due to the achieved high inference accuracy
without introducing communication delay. As η increases, e.g.,
η ≥ 0.3, the inference given by the SNN layers becomes
worse, which leads to a sudden rise in the weighted-sum cost
due to the introduced penalty. At this time, the advantage of
edge inference is an explicit beneﬁt of exploiting more power-
ful DNN layers to improve inference accuracy via ofﬂoading
the intermediate feature maps.

V. CONCLUSION AND OPEN RESEARCH TOPICS

In this article, we discussed the potential and challenges
of edge intelligence in connected autonomous driving. We
presented a two-tier edge learning-empowered architecture of
wireless computing for AVs and introduced two functionality
designs to make ofﬂoading strategy decision efﬁciently, ensure
data privacy, and improve inference accuracy while meeting
the delay constraint. The effectiveness of the proposed frame-
work was demonstrated via a case study and experiments.

There are some interesting open research topics for EI-based

autonomous driving architecture design.

• Efﬁcient edge learning with limited labeled training data.
Generally, most of the edge learning tasks in the au-
tonomous driving system are based on supervised learn-
ing, which requires complete labeled training datasets.
However, collecting sufﬁcient labeled data with a cor-
rectness guarantee is still a challenge in practice [14].
To facilitate learning on edge with limited labeled data,
we can intuitively take advantage of the historical data
and combine it with real-time collected data. Also, we
can take advantage of semi-supervised learning, transfer

Fig. 6: Bad data ratio (η) versus total weighted-sum cost 0using three
different kinds of inference methods, where the number of AVs is 2,
the transmission power of AVs is 10 W, the CPU frequency of the
AVs and the edge server is 1 GHz and 10 GHz, respectively.

We observe from Fig. 5(a) that the inference accuracy of
binary ofﬂoading decision (i.e., ofﬂoad or not) is low for
the small number of training samples and increases with the
percentage of training samples, whilst the MSE of regression
shows an opposite trend. The reason is that when the training
samples are insufﬁcient, the MTL model can only learn a few
distinguishing features, which can hardly perform inference
accurately. As the number of training samples increases,
the MTL model can further extract more abstract features
enabling the MTL model to learn more about the mapping
between the input parameters and the output solutions of the
formulated MINLP problem. From Fig 5(b), we observe that
the MTL model always outperforms the sBB algorithm in the
inference accuracy, and the gain is improved as the number
of AVs increases. Compared to the sBB algorithm, almost
120% improvement can be achieved by MTL model when
the number of AVs is 8. Notably, the MSE of the MTL model
is even less than half of the sBB algorithm. Moreover, by

0.20.40.60.81Percentage of training samples0.90.951Accuracy0.0150.020.025Mean square error (MSE)Accuracy of classificationMSE of regression2345678Number of AVs00.20.40.60.81AccuracysBB AlgorithmMulti-task Learning00.20.40.60.81Bad data ratio2030405060708090100Total weighted-sum costInference at VehiclesInference at EdgeEdge-Vehicle Joint Inference8

[4] J. Wang, C. Jiang, H. Zhang, Y. Ren, K. C. Chen and L. Hanzo, “Thirty
Years of Machine Learning: The Road to Pareto-Optimal Wireless
Networks,” in IEEE Communications Surveys & Tutorials, vol. 22, no.
3, pp. 1472-1514, thirdquarter 2020.

[5] B. Yang, X. Cao, X. Li, C. Yuen, and L. Qian, “Lessons Learned
from Accident of Autonomous Vehicle Testing: An Edge Learning-aided
Ofﬂoading Framework,” IEEE Wireless Commun. Letters, vol. 9, no. 8,
pp. 1182-1186, Aug. 2020.

[6] K. Xiong, S. Leng, C. Huang, C. Yuen and Y. L. Guan, “Intelligent
Task Ofﬂoading for Heterogeneous V2X Communications,” IEEE Trans.
Intelligent Transportation Syst., pp. 1-13, Aug. 2020.

[7] K. Zhang, Y. Zhu, S. Leng, Y. He, S. Maharjan, and Y. Zhang, “Deep
learning empowered task ofﬂoading for mobile edge computing in urban
informatics,” IEEE Internet of Things J., vol. 6, no. 5, pp. 7635-47, Mar.
2019.

[8] Y. Liu, C. Yang, L. Jiang, S. Xie, and Y. Zhang, “Intelligent edge
computing for IoT-based energy management in smart cities,” IEEE
Network, vol. 33, no. 2, pp. 111-117, Mar. 2019.

[9] Y. Dai, D. Xu, S. Maharjan, G. Qiao, and Y. Zhang, “Artiﬁcial intelli-
gence empowered edge computing and caching for internet of vehicles,”
IEEE Wireless Commun., vol. 26, no. 3, pp. 12-18, Jul. 2019.

[10] W. Xu, Y. Xu, CH Lee, Z. Feng, P. Zhang, and J. Lin, “Data-cognition-
empowered intelligent wireless networks: Data, utilities, cognition brain,
and architecture,” IEEE Wireless Commun., vol. 25, no. 1, pp. 56-63,
Feb. 2018.

[11] B. Yang, X. Cao, J. Bassey, X. Li, and L. Qian, “Computation Ofﬂoading
in Multi-Access Edge Computing: A Multi-Task Learning Approach,”
IEEE Trans. Mob. Comput., pp. 1-1, Apr. 2020.

[12] Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang, “Blockchain
empowered asynchronous federated learning for secure data sharing in
Internet of Vehicles,” IEEE Trans. Veh. Tech., vol. 69, no. 4, Feb. 2020,
pp. 4298-311.

[13] G. Zhu, D. Liu, Y. Du, C. You, J. Zhang, and K. Huang, “Toward an
intelligent edge: wireless communication meets machine learning,” IEEE
Commun. Mag., vol. 58, no. 1, pp. 19-25, Jan. 2020.

[14] J. Zhang, F. Li, F. Ye, and H. Wu, “Autonomous Unknown-Application
Filtering and Labeling for DL-based Trafﬁc Classiﬁer Update,” arXiv
preprint arXiv:2002.06359. Feb. 2020.

[15] K. Xiong, S. Leng, X. Chen, C. Huang, C. Yuen and Y. L. Guan,
“Communication and Computing Resource Optimization for Connected
Autonomous Driving,” IEEE Trans. Veh. Tech., pp. 1-1, Oct. 2020.

learning, or even autonomous learning [14], to yield sig-
niﬁcant training and inference improvements via limited
training data. Furthermore, the sensing deﬁciency caused
by using only video cameras can be ﬁlled up by exploring
the potential of sensor fusion, such as LiDAR sensors,
radar sensors, and even by querying the sensor data from
other vehicles.

• Distributed model training with restricted wireless band-
width. In the autonomous driving system with edge
learning, the training data involved is generally privacy-
sensitive with large size and quantity, e.g., high-deﬁnition
video sequences. By introducing distributed learning
(e.g., federated learning), only the local model param-
eters are uploaded to the edge server to preserve data
privacy. Interestingly, via the federated learning and the
neuron network segmentation, privacy-preserving can be
achieved at the training side and inference side, respec-
tively. Since each AV usually collects unique training
data separately and the data samples are generally non-
independent and identically distributed among the vehi-
cles, the edge server prefers to include more AVs’ local
FL models to generate a converged global model. In this
context, the model parameters exchange between AVs
and servers may result in high communication costs, and
the runtime of each learning iteration is dominated by
the slowest participants, which become a bottleneck for
the autonomous driving system [12]. To mitigate this
issue, more AVs can be allowed to participate in the FL
by sharing their FL models with selected AVs via V2V
communications, using the side-link channel in cellular-
based V2V (C-V2V), DSRC, or even millimeter-wave
transmission [2], [6].

• Vehicle platoon-aided inference. In practice, the vehicles
may sometimes drive out of the coverage of BS, which
will cause considerable inﬂuence on the feasibility of
edge inference. To address this challenge, collaborative
caching and computing among vehicles become a com-
petitive candidate solution [3], [15]. Speciﬁcally,
the
trained DNN model can be divided into multiple parts
the
(called layers), each of which is pre-deployed at
vehicle belonging to the same vehicle platoon. Once a
vehicle leaves the BS’s coverage, this vehicle can still
achieve reasonable inference by routing the intermediate
parameters to other vehicles within the same vehicle
platoon via V2V communications. In this case, the im-
provement of inference accuracy is at the expense of
V2V communication delay, and the impact of the platoon
dynamics needs to be further investigated.

REFERENCES

[1] K. B. Letaief, W. Chen, Y. Shi, J. Zhang, and Y.J.A. Zhang, “The
roadmap to 6G: AI empowered wireless networks,” IEEE Commun.
Mag., vol. 57, no. 8, pp. 84-90, Aug. 2019.

[2] J. Wang, J. Liu, and N. Kato, “Networking and communications in
autonomous driving: A survey,” IEEE Commun. Surveys Tuts., vol. 21,
no. 2, pp. 1243-1274, Second Qtr. 2019.

[3] Y. Dai, D. Xu, S. Maharjan, and Y. Zhang, “Joint computation ofﬂoading
and user association in multi-task mobile edge computing,” IEEE Trans.
Veh. Tech., vol. 67, no. 12, Dec. 2018, pp. 12313-12325.

