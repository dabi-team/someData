1
2
0
2

c
e
D
3

]

O
C

.
t
a
t
s
[

2
v
3
1
9
1
0
.
7
0
1
2
:
v
i
X
r
a

Randomized multilevel Monte Carlo
for embarrassingly parallel inference

Ajay Jasra1, Kody J. H. Law2, Alexander Tarakanov2, and Fangyuan Yu1

1 Computer, Electrical and Mathematical Sciences and Engineering Division, King
Abdullah University of Science and Technology, Thuwal, 23955, KSA.
ajay.jasra@kaust.edu.sa, fangyuan.yu@kaust.edu.sa
2 Department of Mathematics, University of Manchester, Manchester, M13 9PL, UK.
kodylaw@gmail.com, tarakanov517@gmail.com

Abstract. This position paper summarizes a recently developed re-
search program focused on inference in the context of data centric sci-
ence and engineering applications, and forecasts its trajectory forward
over the next decade. Often one endeavours in this context to learn
complex systems in order to make more informed predictions and high
stakes decisions under uncertainty. Some key challenges which must be
met in this context are robustness, generalizability, and interpretability.
The Bayesian framework addresses these three challenges, while bring-
ing with it a fourth, undesirable feature: it is typically far more ex-
pensive than its deterministic counterparts. In the 21st century, and
increasingly over the past decade, a growing number of methods have
emerged which allow one to leverage cheap low-ﬁdelity models in or-
der to precondition algorithms for performing inference with more ex-
pensive models and make Bayesian inference tractable in the context of
high-dimensional and expensive models. Notable examples are multilevel
Monte Carlo (MLMC), multi-index Monte Carlo (MIMC), and their ran-
domized counterparts (rMLMC), which are able to provably achieve a
dimension-independent (including ∞−dimension) canonical complexity
rate with respect to mean squared error (MSE) of 1/MSE. Some paral-
lelizability is typically lost in an inference context, but recently this has
been largely recovered via novel double randomization approaches. Such
an approach delivers independent and identically distributed samples
of quantities of interest which are unbiased with respect to the inﬁnite
resolution target distribution. Over the coming decade, this family of
algorithms has the potential to transform data centric science and engi-
neering, as well as classical machine learning applications such as deep
learning, by scaling up and scaling out fully Bayesian inference.

Keywords: Randomization Methods; Markov chain Monte Carlo; Bayesian
Inference

1

Introduction

The Bayesian framework begins with a statistical model characterizing the causal
relationship between various variables, parameters, and observations. A canoni-

 
 
 
 
 
 
2

Jasra, Law, Yu

cal example in the context of inverse problems is

y ∼ N (Gθ(u), Γθ) ,

u ∼ N (mθ, Cθ) ,

θ ∼ π0 ,

where N (m, C) denotes a Gaussian random variable with mean m and covariance
C, Gθ : U → Rm is the (typically nonlinear) parameter-to-observation map,
θ ∈ Rp is a vector of parameters with π0 some distribution, and the data is
given in the form of observations y [53,54]. Nothing precludes the case where U
is a function space, e.g. leading to a Gaussian process prior above, but to avoid
unnecessary technicalities, assume U = Rd. The objective is to condition the
prior knowledge about (u, θ) with the observed data y and recover a posterior
distribution

p(u, θ|y) =

p(u, θ, y)
p(y)

=

p(y|u, θ)p(u|θ)p(θ)
(cid:82)
U ×Rp p(y|u, θ)p(u|θ)p(θ)dudθ

.

Often in the context above one may settle for a slightly simpler goal of identifying
a point estimate θ∗, e.g. θ∗ = argmaxθp(θ|y) (which we note may require an
intractable integration over U ) and targeting p(u|y, θ∗) instead.

In the context described above, one often only has access to an approximation
of the map Gθ, and potentially an approximation of the domain U , which may
in principle be inﬁnite dimensional. One example is the numerical solution of a
system of diﬀerential equations. Other notable examples include surrogate mod-
els arising from reduced-physics or machine-learning-type approximations [47] or
deep feedforward neural networks [45]. For the sake of concreteness the reader
can keep this model in mind, however it is noted that the framework is much
more general, for example the parameters θ can encode the causal relationship
between latent variables via a graphical model such as a deep belief network or
deep Boltzmann machine [5,43].

A concise statement of the general problem of Bayesian inference is that it
requires exploration of a posterior distribution Π from which one cannot obtain
independent and identically distributed (i.i.d.) samples. Speciﬁcally, the aim is
to compute quantities such as

Πθ(ϕ) :=

(cid:90)

U

ϕ(u)Πθ(du) , ϕ : U → R ,

(1)

where Πθ(du) = πθ(u)νθ(du), νθ(du) is either Lebesgue measure νθ(du) = du,
or one can simulate from it, πθ(u) = γθ(u)/νθ(γθ), and given u one can evaluate
γθ(u) (or at least a non-negative unbiased estimator). Markov chain Monte Carlo
(MCMC) and sequential Monte Carlo (SMC) samplers can be used for this [50].
Considering the example above with U = Rd, we may take ν(du) = du and then

γθ(u) = |Γθ|−1/2|Cθ|−1/2 exp(−

1
2

|Γ −1/2
θ

(y−Gθ(u))|2−

1
2

|C −1/2
θ

(u−mθ)|2) , (2)

where |A| denotes the determinant for a matrix A ∈ Rn. Note we have used a
subscript for θ, as is typical in the statistics literature to denote that everything

rMLMC for inference

3

is conditional on θ, and note that the θ−dependent constants are not necessary
here, per se, but it is customary to deﬁne the un-normalized target as the joint on
(u, y), such that Zθ := νθ(γθ) = p(y|θ). Also note that in (2), u would be referred
to as a latent variable in the statistics and machine learning literature, and so
this setup corresponds to a complex physics-informed (via Gθ) unsupervised
learning model. Labelled data problems like regression and classiﬁcation [44], as
well as semi-supervised learning [40,57], can also be naturally cast in a Bayesian
framework. In fact, if Gθ(u) is point-wise evaluation of u, i.e. Gi
θ(u) = u(xi), for
inputs or covariates xi associated to labels yi, and one allows U to be an inﬁnite-
dimensional (reproducing kernel) Hilbert space, then standard Gaussian process
(GP) regression has this form. In inﬁnite-dimensions there is no Lebesgue density,
so (2) does not make sense, but the marginal likelihood and posterior can both
be computed in closed form thanks to the properties of GP [48]. Alternatively,
if u are the parameters of a deep feedforward neural network [45] fθ(·; u), and
Gi
θ(u) = fθ(xi; u) with Gaussian prior on u, then one has a standard Bayesian
neural network model [45,5].

1.1 The sweet and the bitter of Bayes

Three challenges which are elegantly handled in a Bayesian framework are (a)
robustness, (b) generalizability, and (c) interpretability [1,52]. Uncertainty quan-
tiﬁcation (UQ) has been a topic of great interest in science and engineering
applications over the past decades, due to its ability to provide a more robust
model [17,1]. A model which can extrapolate outside training data coverage is
referred to as generalizable. Notice that via prior knowledge (1) and the phys-
ical model, (2) has this integrated capability by design. Interpretability is the
most heavily loaded word among the three desiderata. Our deﬁnition is that the
model (i) can be easily understood by the user [8], (ii) incorporates all data and
domain knowledge available in a principled way [8,27], and (iii) enables inference
of causal relationships between latent and observed variables [46]. The natural
question is then, “Why in the age of data doesn’t everybody adopt Bayesian
inference for all their learning requirements?”

The major hurdle to widespread adoption of a fully Bayesian treatment of
learning is the computational cost. Except for very special cases, such as GP
regression [48], the solution cannot be obtained in closed form. Point estimates,
Laplace approximations [51], and variational methods [38,6] have therefore taken
center stage, as they can yield acceptable results very quickly in many cases. In
particular, for a strongly convex objective function, gradient descent achieves
exponential convergence to a local minimizer, i.e. MSE ∝ exp(−N ) in N steps.
Such point estimates are still suboptimal from a Bayesian perspective, as they
lack UQ. In terms of computation of (1), Monte Carlo (MC) methods are able to
achieve exact inference in (1) in general [41,50]. In the case of i.i.d. sampling, MC
methods achieve the canonical, dimension-independent convergence rate of MSE
∝ 1/N , for N −sample approximations, without any smoothness assumptions

4

Jasra, Law, Yu

and out-of-the-box3. Quadrature methods [16] and quasi-MC [9] are able to
achieve improvements over MC rates, however the rates depend on the dimension
and the smoothness of the integrand.

A curse of dimensionality can still hamper application of MC methods through
the constant and the cost of simulation, meaning it is rare to achieve canonical
complexity of cost ∝ 1/MSE for non-trivial applications. Usually this is man-
ifested in the form of a penalty in the exponent, so that cost ∝ MSE−a, for
a > 2. A notable exception is MLMC [23,19] and MIMC [22] methods, and their
randomized counterparts rMLMC [49,55] and rMIMC [12], which are able to
achieve dimension-independent canonical complexity for a range of applications.
These estimators are constructed by using a natural telescopic sum identity and
constructing coupled increment estimators of decreasing variance. As an added
bonus, the randomized versions eliminate discretization bias entirely, and deliver
estimates with respect to the limiting inﬁnite-resolution distribution.

In the context of inference problems, i.i.d. sampling is typically not possible
and one must resort to MCMC or SMC [50]. This makes application of (r)MLMC
and (r)MIMC more complex. Over the past decade, there has been an explosion
of interest in applying these methods to inference, e.g. see [25,15,3,26,33] for
examples of MLMC and [31,35] for MIMC. A notable beneﬁt of MC methods is
easy parallelizability, however typically MLMC and MIMC methods for inference
are much more synchronous, or even serial in the case of MCMC. A family of
rMLMC methods have recently been introduced for inference [32,36,24], which
largely recover this lost parallelizability, and deliver i.i.d. samples that are un-
biased with respect to the limiting inﬁnite resolution target distribution in the
inference context. In other words, the expectation of the resulting estimators
are free from any approximation error. The ﬁrst instance of rMLMC for infer-
ence was [10], and the context was diﬀerent to the above work – in particular,
consistent estimators are constructed that are free from discretization bias.

The rest of this paper is focused on these novel parallel rMLMC methods for
inference, which are able to achieve the gold standard of Bayesian posterior in-
ference with canonical complexity rate 1/MSE. In the age of data and increasing
parallelism of supercomputer architecture, these methods are prime candidates
to become a staple, if not the defacto standard, for inference in data-centric sci-
ence and engineering applications. Section 2 describes some technical details of
the methods, Section 3 presents a speciﬁc motivating example Bayesian inverse
problem and some compelling numerical results, and Section 4 concludes with a
call to action and roadmap forward for this exciting research program.

2 Technical Details of the methodology

The technical details of the methodology will be sketched in this section. The
idea is to give an accessible overview and invitation to this exciting methodol-

3 This is the same rate achieved by gradient descent for general non-convex smooth
objective functions. In fact, the success of deep neural networks for learning high-
dimensional functions has been attributed to this dimension-independence in [56].

rMLMC for inference

5

ogy. The interested reader can ﬁnd details in the references cited. With respect
to the previous section, the notation for θ will be suppressed – the concerned
reader should imagine either everything is conditioned on θ or it has been ab-
sorbed into u ← (u, θ). Subsection 2.1 sketches the MLMC idea, and some of the
challenges, strategies for overcoming them, and opportunities in the context of
inference. Subsection 2.2 sketches the rMLMC idea, and some of the challenges,
strategies for overcoming them, and opportunities in the context of inference.
Finally subsection 2.3 brieﬂy sketches MIMC.

2.1 Multilevel Monte Carlo

As mentioned above, for problems requiring approximation, MLMC methods are
able to achieve a huge speedup in comparison to the naive approach of using a
single ﬁxed approximation, and indeed in some cases canonical complexity of
cost ∝ 1/MSE. These methods leverage a range of successive approximations of
increasing cost and accuracy. In a simpliﬁed description, most MLMC theoretical
results rely on underlying assumptions of

(i) a hierarchy of targets Πl, l ≥ 0, of increasing cost, such that Πl → Π as

l → ∞ ;

(ii) a coupling Π l s.t. ∀ A ⊂ U ,

(cid:90)

A×U

Π l(du, du(cid:48)) = Πl(A) ,

and

(cid:90)

U ×A

Π l(du, du(cid:48)) = Πl−1(A);

(iii) the coupling is such that

(cid:90)

|ϕ(u) − ϕ(u(cid:48))|2Π l(du, du(cid:48)) ≤ Chβ
l ,

(3)

and the cost to simulate from Π l is proportional to Ch−ζ
s.t. hl → 0 as l → ∞, and C, β, ζ > 0 independent of l.

l

, for some hl > 0

Now one leverages the telescopic sum

Π(ϕ) =

L
(cid:88)

∆l(ϕ)

+

∞
(cid:88)

∆l(ϕ)

,

l=0
(cid:125)
(cid:123)(cid:122)
(cid:124)
approximation

l=L+1
(cid:124)

(cid:123)(cid:122)
bias

(cid:125)

(4)

where ∆l(ϕ) = Πl(ϕ) − Πl−1(ϕ), Π−1 ≡ 0, by approximating the ﬁrst term,
ΠL(ϕ), using i.i.d. samples from the couplings Π l, l = 0, . . . , L. The second
term is the bias= Π(ϕ) − ΠL(ϕ). This allows one to optimally balance cost with
more samples on coarse/cheap levels, and a decreasing number of samples as l
increases, to construct a multilevel estimator (cid:98)Π(ϕ) that achieves a given mean
square error (MSE),

E( (cid:98)Π(ϕ) − Π(ϕ))2 = variance + bias2 ,

6

Jasra, Law, Yu

(a) Few high ﬁdelity (high-cost)
simulations are combined with
many at low-ﬁdelity (low cost).

(b) MSE vs Cost: MLSMC vs SMC for ellip-
tic PDE, illustrating the large gain in eﬃciency
(smaller Cost for a given MSE). [3]

Fig. 1. Synopsis of MLMC methods: a family of models, including coarse-resolution
approximation of diﬀerential equations, surrogates, etc. (a) can be combined in the
MLMC framework to yield improved complexity cost ∝ 1/MSE (b).

more eﬃciently than a single level method. A schematic is given in Fig. 1(a).

The MLMC estimator is deﬁned as

(cid:98)Y =

L
(cid:88)

l=0

1
Nl

Nl(cid:88)

i=1

Y i
l ,

(5)

l = ϕ(U i

l−1) and (Ul, Ul−1)i ∼ Π l for l ≥ 1, Y i
l ) − ϕ(U i
where Y i
0),
U i
0 ∼ Π0, and L and {Nl}L
l=0 are chosen to balance the bias and variance. In
particular, L ∝ log(MSE) and Nl ∝ h(β+ζ)/2
. In the canonical regime where
l
β > ζ one achieves the canonical complexity of cost ∝ 1/MSE. If β ≤ ζ, there
are penalties. See [19] for details. Note that for the theory above, controlling the
bias requires only α > 0 such that

0 = ϕ(U i

(cid:90)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
ϕ(u) − ϕ(u(cid:48))Π l(du, du(cid:48))
(cid:12)
(cid:12)

≤ Chα
l ,

however it is clear that Jensen’s inequality provides α ≥ β/2, which is suitable
for the purposes of this exposition. There are notable exceptions where one can
achieve α > β/2, e.g. Euler-Maruyama or Milstein simulation of SDE [18], and
this of course provides tighter results.

Note that the assumptions above can be relaxed substantially if one sacriﬁces
a clean theory. In particular, the models Πl need not be deﬁned hierarchically
in terms of a small parameter hl corresponding to “resolution”, as long as hβ
l
and h−ζ
in assumption (iii) above can be replaced with Vl and Cl, respectively,
such that Vl → 0 as Cl → ∞ in some fashion. Indeed in practice one need not
ever consider the limit and can work with a ﬁnite set of models within the same
framework, as is advocated in the related multiﬁdelity literature (see e.g. [47]).

l

Higher fidelitylowerfidelitylowerfidelitylowerfidelityError levelCostlowerfidelitylowerfidelity(cid:19)(cid:18)(cid:22)(cid:19)(cid:19)(cid:17)(cid:19)(cid:19)(cid:22)(cid:19)(cid:20)(cid:17)(cid:19)(cid:230)(cid:19)(cid:22)(cid:19)(cid:230)(cid:19)(cid:17)(cid:19)(cid:230)(cid:18)(cid:22)(cid:19)(cid:230)(cid:18)(cid:17)(cid:46)(cid:52)(cid:38)(cid:9)(cid:2477)(cid:19)(cid:10)(cid:51)(cid:86)(cid:79)(cid:85)(cid:74)(cid:78)(cid:70)(cid:68)(cid:80)(cid:84)(cid:85)(cid:233)(cid:229)(cid:2385)(cid:2410)(cid:30)(cid:17)(cid:2387)(cid:2410)(cid:1099)(cid:230)(cid:18)(cid:2410)(cid:34)(cid:77)(cid:72)(cid:80)(cid:83)(cid:74)(cid:85)(cid:73)(cid:78)(cid:46)(cid:45)(cid:52)(cid:46)(cid:36)(cid:52)(cid:46)(cid:36)COSTMSESMC MLSMC largesmallsmalllargerMLMC for inference

7

MLMC for inference.
In the context of inference, it is rare that one can
achieve i.i.d. samples from couplings Π l. As described in Section 1, one more
often only has access to (unbiased estimates of) the un-normalized target and
must resort to MCMC or SMC. In the canonical regime β > ζ the theory can
proceed in a similar fashion provided one can obtain estimators ˆY N
such that
l
for some C, β > 0 and q = 1, 2

(cid:104) ˆY N

E

l − (Πl(ϕ) − Πl−1(ϕ))

(cid:105)q

≤ C

hβq/2
l
N

.

(6)

In the sub-canonical regime, the situation is slightly more complex.

Achieving such estimates with eﬃcient inverse MC methods has been the
focus of a large body of work. These methods can be classiﬁed according to
3 primary strategies: importance sampling [25,3,2,42,37], coupled algorithms
[15,26,29,21,34], and approximate couplings [30,31,35]. See e.g. [33] for a recent
review. Importance sampling estimators are the simplest, and they proceed by
expressing the desired increment in terms of expectation with respect to one of
the levels. Its applicability is therefore limited to cases where the importance
weights can be calculated or estimated. Coupled algorithms attempt to achieve
the required rates by coupling two single level algorithms targeting the coarse
and ﬁne targets, respectively. These are in some sense the most natural, and
in principle the most general, but it can be deceptively tricky to get them to
work correctly. Approximate coupling is the most straightforward strategy and
can also be quite versatile. In this case, one abandons exactness with respect
to coarse and ﬁne marginals, and aims only to achieve well-behaved weights
associated to a change of measure with respect to an approximate coupling.

2.2 Randomized Multilevel Monte Carlo

Randomized MLMC (rMLMC) is deﬁned similarly to (5) except with a notable
diﬀerence. Deﬁne a categorical distribution p = (p0, p1, . . . ) on Z+ and let
Li ∼ p, and Y i

Li as above. The single term estimator [49] is deﬁned as

Z i =

Y i
Li
pLi

.

(7)

Notice that, as a result of (4),

EZ i =

∞
(cid:88)

l=0

plE

(cid:19)

(cid:18) Y i
l
pl

= Π0(ϕ) +

∞
(cid:88)

l=1

Πl(ϕ) − Πl−1(ϕ) = Π(ϕ) ,

i.e. this estimator is free from discretization bias. The corresponding rMLMC
estimator is given by

(cid:98)Z =

1
N

N
(cid:88)

i=1

Z i =

∞
(cid:88)

l=0

1
N pl

(cid:88)

Y i
l .

i;Li=l

(8)

8

Jasra, Law, Yu

It is easy to see that E#{i; Li = l} = N pl and #{i; Li = l} → N pl as N → ∞,
and the optimal choice level of distribution is analogous to level selection above,
pl ∝ Nl, with Nl as in (5). Despite the inﬁnite sum above, this estimator does
not incur inﬁnite cost for ﬁnite N , because only ﬁnitely many summands are non-
zero. Furthermore, pl → 0, so higher levels are simulated rarely and the expected
cost is also typically ﬁnite. See [49] for further details and other variants.

rMLMC for inference In the inference context, one typically does not have
access to unbiased estimators of YLi, and rather E( ˆY N
l ) (cid:54)= Πl(ϕ) − Πl−1(ϕ). In
the ﬁnite L case, one can get away with this provided (6) holds, however rMLMC
methods rely on this property. In the work [10], SMC is used to construct un-
biased estimators of increments with respect to the un-normalized target (a
well-known yet rather remarkable feature of SMC methods [14]), and subse-
quently a ratio estimator is used for posterior expectations, which are hence
biased (for ﬁnite N ) but consistent (in the limit N → ∞) with respect to the
inﬁnite-resolution (L = ∞) target. Subsequently it has been observed that an-
other inner application of the methodology presented above in Section 2.2 allows
one to transform a consistent estimator into an unbiased estimator [36,32].

In particular, suppose one can couple two estimators ˆY N
l

, with
N (cid:48) > N , that marginally satisfy (6), and such that the resulting estimator
satisﬁes, for q = 1, 2,

and ˆY N (cid:48)

l

E

(cid:104) ˆY N

l − ˆY N (cid:48)

l

(cid:105)q

≤ C

hβq/2
l
N

.

(9)

Introduce inner levels Nk, k ≥ 1, such that Nk → ∞ as k → ∞, and another
categorical distribution p = (p0, p1, . . . ) on Z+. Now let K i ∼ p, Li ∼ p and
simulate ˆY NKi
as above. The resulting doubly-randomized single term
Li
estimator is given by

NKi−1
Li

, ˆY

Z i =

1
pLi pKi

Now, as above,

(cid:16) ˆY NKi

Li − ˆY

NKi−1
Li

(cid:17)

.

(10)

E

(cid:20) 1
pKi

(cid:16) ˆY NKi

l

NKi−1
− ˆY
l

(cid:17)(cid:21)

= Πl(ϕ) − Πl−1(ϕ) ,

and hence EZ i = Π(ϕ). Furthermore, the estimators (10) can be simulated i.i.d.
In other words, the embarrassingly parallel nature of classical MC estimators is
restored, as well as all the classical results relating to i.i.d. random variables,
such as the central limit theorem.

The work [36] leverages such a doubly randomized estimator for online par-
ticle ﬁltering in the framework of [29]. The work [32] uses a so-called coupled
sum variant in the framework of MLSMC samplers [3]. Both of these estimators
suﬀer from the standard limiting MC convergence rate with respect to the inner
randomization, which is sub-canonical. In other words the cost to achieve an
estimator at level K is O(NK) and the error is O(N −1
K ). As a result, it is not

rMLMC for inference

9

possible to achieve ﬁnite variance and ﬁnite cost, and one must settle for ﬁnite
variance and ﬁnite cost with high probability [49]. In practice, one may truncate
the sum at ﬁnite Kmax to ensure ﬁnite cost, and accept the resulting bias.

rMLMCMC An alternative incarnation of the inner randomization can be
used in the context of MCMC, relying on the unbiased MCMC introduced in
[28], which is based on the approach of [20]. In [28] one couples a pair of MCMCs
(Un, U (cid:48)
n) targeting the same distribution Π in such a way that they (i) have the
n+1, (ii) meet in ﬁnite time E(τ ) < ∞,
same distribution at time n, Un
τ = inf{n; Un = U (cid:48)
n}, and (iii) remain identical thereafter. An unbiased estimator
is then obtained via

D∼ U (cid:48)

(cid:98)X = ϕ(Un∗ ) +

= ϕ(Un∗ ) +

∞
(cid:88)

n=n∗+1
τ
(cid:88)

n=n∗+1

ϕ(Un) − ϕ(U (cid:48)
n)

ϕ(Un) − ϕ(U (cid:48)

n) .

It is clear that in expectation the sum telescopes, giving the correct expectation
E (cid:98)X = E(ϕ(U∞)) = Π(ϕ). Such estimators can be simulated i.i.d., which re-
moves the fundamental serial roadblock of MCMC, and the ﬁnite meeting time
ensures ﬁnite cost. Variations of the approach allow similar eﬃciency to a single
MCMC for a single CPU implementation, i.e. without leveraging parallelization.
As above, with parallel processors, the sky is the limit.

In order to apply such technology to the present context, one couples a pair

of coupled chains (Un,l, Un,l−1, U (cid:48)

n,l, U (cid:48)

n,l−1) such that

Un,l, Un,l−1

D∼ U (cid:48)

n+1,l, U (cid:48)

n+1,l−1 ,

yielding a foursome that is capable of delivering ﬁnite-cost unbiased estimators
of Πl(ϕ) − Πl−1(ϕ). Indeed we are also able to achieve estimates of the type in
(6), and therefore (for suitable β) rMLMC estimators with ﬁnite variance and
ﬁnite cost. Note that only the intra-level pairs need to meet and remain faithful.
Ultimately, the i.i.d. estimators have the following form. Simulate Li ∼ p as
described in Section 2.2, and deﬁne Z i = (cid:98)Y i

Li/pLi , where

(cid:98)Y i
l = ϕ(Un∗,l) − ϕ(Un∗,l−1)

τl(cid:88)

+

n=n∗+1

ϕ(Un,l) − ϕ(U (cid:48)

n,l) −

τl−1
(cid:88)

n=n∗+1

(cid:0)ϕ(Un,l−1) − ϕ(U (cid:48)

n,l−1)(cid:1) ,

(11)

with τ(cid:96) = inf{n; Un,(cid:96) = U (cid:48)

n,(cid:96)}, for (cid:96) = l, l − 1. The ﬁnal estimator is

(cid:98)Z =

1
N

N
(cid:88)

i=1

Z i .

(12)

10

Jasra, Law, Yu

2.3 Multi-index Monte Carlo

Recently, the hierarchical telescopic sum identity that MLMC is based upon has
been viewed through the lense of sparse grids, for the case in which there are
multiple continuous spatial, temporal, and/or parametric dimensions of approx-
imation [22]. In other words, there is a hierarchy of targets Πα, where α is a
multi-index, such that Πα → Π as |α| → ∞. Under a more complex set of
assumptions, one can appeal instead to the identity

Π(ϕ) =

(cid:88)

α∈I

∆α(ϕ) +

(cid:88)

α /∈I

∆α(ϕ) ,

I ⊂ Zd

+ ,

where d−fold multi-increments ∆α are used instead, i.e. letting ej ∈ Rd denote
the jth standard basis vector and δjΠα := Πα −Πα−ej , then ∆α := δd ◦· · ·◦δ1Πα
(for any multi-index α(cid:48) with α(cid:48)
i < 0 for some i = 1, . . . , d, Πα(cid:48) := 0). The ﬁrst
term is approximated again using coupled samples and the second is the bias.
Under suitable regularity conditions, this MIMC method yields further huge
speedup to obtain a given level of error [19,22]. Some preliminary work in this
direction has been done recently [31,35]. Forward randomized MIMC (rMIMC)
has recently been done as well [12].

3 Motivating example

3.1 Example of Problem

The following particular problem is presented as an example. This example is
prototypical of a variety of inverse problems involving physical systems in which
noisy/partial observations are made of the solution of an elliptic PDE and one
would like to infer the diﬀusion coeﬃcient. For example, the solution to the
PDE v could represent pressure of a patch of land, subject to some forcing
f (sources/sinks), and the diﬀusion coeﬃcient ˆu(u) then corresponds to the
subsurface permeability [54,53], a highly desirable quantity of interest in the
context of oil recovery. Let D ⊂ Rd with ∂D ∈ C 1 convex and f ∈ L2(D).
Consider the following PDE on D:

−∇ · (ˆu(u)∇v) = f,

on D,

v = 0,

on ∂D ,

where the diﬀusion coeﬃcient has the form

ˆu(x; u) = ¯u +

J
(cid:88)

j=1

ujσjφj(x) ,

(13)

(14)

(15)

Deﬁne u = {uj}J
j=1[−1, 1]. Let v(·; u)
denote the weak solution of (1) for parameter value u. The prior is given by

j=1, and the state space will be X = (cid:81)J

rMLMC for inference

11

uj ∼ U [−1, 1] (the uniform distribution on [−1, 1]) i.i.d. for j = 1, . . . , J. It
will be assumed that φj ∈ C(D), (cid:107)φj(cid:107)∞ ≤ 1, and there is a u∗ > 0 such that
¯u > (cid:80)J
j=1 σj + u∗. Note that under the given assumptions, ˆu(u) > u∗ uniformly
in u. Hence there is a well-deﬁned (weak) solution v(·; u) that is bounded in
L∞(D) and L2(D) uniformly in u, and its gradient is also bounded in L2(D)
uniformly in u [11,13].

Deﬁne the following vector-valued function

G(u) = [(cid:104)g1, v(·; u)(cid:105), . . . , (cid:104)gm, v(·; u)(cid:105)](cid:124),

(16)

where gi ∈ L2(D) for i = 1, . . . , m. We note that pointwise evaluation is also
permissible since u ∈ L∞(D), i.e. gi can be Dirac delta functions, however for
simplicity we restrict the presentation to L2(D). It is assumed that the data take
the form

y = G(u) + ξ,

(17)
where ⊥ denotes independence. The unnormalized density γθ : X → R+ of u for
ﬁxed θ > 0 is given by

ξ ∼ N (0, θ−1 · Im),

ξ ⊥ u ,

γθ(u) = θm/2 exp

(cid:16)

−

θ
2

(cid:107)G(u) − y(cid:107)2(cid:17)

.

(18)

The normalized density is

γθ(u)
Iθ
X γθ(u)du, and the quantity of interest is deﬁned for u ∈ X as

ηθ(u) =

,

where Iθ = (cid:82)

ϕθ(u) := ∇θ log

(cid:16)

(cid:17)

=

γθ(u)

m
2θ

−

1
2

(cid:107)G(u) − y(cid:107)2 .

(19)

To motivation this particular objective function, notice that γθ is chosen
such that the marginal likelihood, or “evidence” for θ, is given by p(y|θ) = Iθ.
Therefore the MLE (λ = 0) or MAP are given as minimizers of − log Iθ +
λR(θ), where R(θ) = − log p(θ). Assuming R(θ) is known in closed form and
diﬀerentiable, then a gradient descent method requires

∇θ log Iθ =

1
Iθ

(cid:90)

X

∇θγθ(u)du =

1
Iθ

(cid:90)

X

(cid:16)

(cid:17)

γθ(u)

γθ(u)du = ηθ(ϕθ(u)) .

∇θ log
(cid:124)

(cid:123)(cid:122)
ϕθ(u)

(cid:125)

(20)
Stochastic gradient descent requires only an unbiased estimator of ηθ(ϕθ(u))
[39], which the presented rMLMC method delivers.

Numerical approximation The ﬁnite element method (FEM) is utilized for
solution of (14) with piecewise multi-linear nodal basis functions. Let d = 1 and
D = [0, 1] for simplicity. Note the approach is easily generalized to d ≥ 1 using
products of such piecewise linear functions described below following standard

12

Jasra, Law, Yu

FEM literature [7]. The PDE problem at resolution level l is solved using FEM
with piecewise linear shape functions on a uniform mesh of width hl = 2−l,
i}2l−1
for l ≥ 0. Thus, on the lth level the ﬁnite-element basis functions are {ψl
deﬁned as (for xi = i · 2−l):

i=1

ψl

i(x) =

(cid:26) (1/hl)[x − (xi − hl)] if x ∈ [xi − hl, xi],
if x ∈ [xi, xi + hl] .

(1/hl)[xi + hl − x]

To solve the PDE, vl(x) = (cid:80)2l−1
each basis element:

i=1 vl

iψl

i(x) is plugged into (1), and projected onto

(cid:68)

∇ ·

−

(cid:16)

ˆu∇

2l−1
(cid:88)

i=1

iψl
vl
i

(cid:69)

(cid:17)

, ψl
j

= (cid:104)f, ψl

j(cid:105),

resulting in the following linear system:

Al(u)vl = f l,

where we introduce the matrix Al(u) with entries Al
i = (cid:104)f, ψl
vectors vl, f l with entries vl

i(cid:105) and f l
Deﬁne Gl(u) = [(cid:104)g1, vl(·; u)(cid:105), . . . , (cid:104)gm, vl(·; u)(cid:105)](cid:124). Denote the corresponding

ij(u) = (cid:104)ˆu∇ψl
i(cid:105), respectively.

i = (cid:104)v, ψl

j(cid:105), and

i, ∇ψl

approximated un-normalized density by

θ(u) = θm/2 exp
γl

(cid:110)

−

θ
2

(cid:107)Gl(u) − y(cid:107)2(cid:111)

,

(21)

and the approximated normalized density by ηl
(cid:82)
X γl

θ(u)du. Furthermore, deﬁne

θ(u) = γl

θ(u)/I l

θ, where I l

θ =

ϕl

θ(u) := ∇θ log

(cid:16)

(cid:17)

γl
θ(u)

=

m
2θ

−

1
2

(cid:107)Gl(u) − y(cid:107)2 .

(22)

It is well-known that under the stated assumptions vl(u) converges to v(u) as
l → ∞ in L2(D) (as does its gradient), uniformly in u [7,11], with the rate hβ/2
,
β = 4. In a forward UQ context, this immediately provides (3) for Lipschitz
functions of v, with β = 4. Furthermore, continuity ensures γl
θ(u) converges
to γθ(u) and ϕl
θ(u) converges to ϕθ(u) uniformly in u as well. See also [4,2]
for further details. This allows one to achieve estimates of the type (6) in the
inference context.

l

3.2 Numerical results

This section is for illustration purposes and reproduces results from [24], specif-
ically Section 4.1.2 and Figure 5. The problem speciﬁed in the previous section
is considered with forcing f (x) = 100x. The prior speciﬁcation of u = (u1, u2)
is taken as J = 2, ¯u = 0.15, σ1 = 1/10, σ2 = 1/40, φ1(t) = sin(πx) and
φ2(t) = cos(2πx). For this particular setting, the solution v is continuous and

rMLMC for inference

13

hence point-wise observations are well-deﬁned. The observation function G(x) in
(16) is chosen as gi(v(u)) = v(0.01+0.02(i−1); u) for i ∈ {1, . . . , m} with m = 50.
The FEM scheme in Section 3.1 is employed with mesh width of l ← l +l0, where
l0 = 3. Using a discretization level of l = 10 to approximate G(x) with Gl(x),
x = (0.6, −0.4) and θ = 1, observations y ∈ Rm are simulated from (17).

The estimators (cid:98)Y i

Li are computed using a reﬂection maximal coupling of pCN
kernels, as described in [24]. The left panel of Figure 2 illustrates that averaging
single term estimators (11) as in (12) yields a consistent estimator that converges
at the canonical Monte Carlo rate of 1/MSE.

Consider now inference for θ in the Bayesian framework, under a prior p(θ)
speciﬁed as a standard Gaussian prior on log θ. A stochastic gradient ascent
algorithm is initialized at θ(0) = 0.1 to compute the maximum a posteriori
probability (MAP) estimator θMAP ∈ arg max p(θ)Iθ, simulated by subtracting
∇θR(θ) from the estimator of (20) given by Z i deﬁned above and in (11). The
right panel of Figure 2 displays convergence of the stochastic iterates to θMAP.
An estimator following [32], of the type in (10), is also shown here, using the
algorithm in [4] instead of coupled MCMC. The plot shows some gains over [32]
when the same learning rates are employed.

Parallel implementation. An example is now presented to illustrate the par-
allel improvement of these methods on multiple cores. These results are borrowed
from [36] for (online) ﬁltering of partially observed diﬀusions. In particular, an
estimator of the form (10) is constructed, in which each ˆY NKi
is a coupled
particle ﬁlter increment estimator at resolution Li and with K i particles, for
i = 1, . . . , N , and these estimators are then averaged as in (12). The parallel
performance is assessed with up to 1000(≤ N ) MPI cores on the KAUST super-
computer Shaheen. A Python notebook that implements the unbiased estimator
both on a single core and multiple cores can be found in the following Github link:
https://github.com/fangyuan-ksgk/Unbiased-Particle-Filter-HPC-.

Li

To demonstrate the parallel scaling power, various numbers of processors
M ∈ {1, 5, 10, 20, 50, 100, 500, 1000} are used, with N = 103M . The serial com-
putation time to obtain the estimator on a single core is recorded, as well as
the parallel computation time on M cores. The parallel speedup is deﬁned as
the ratio of cost for serial implementation and the cost for parallel implementa-
tion, and the parallel eﬃciency is given by the ratio of parallel speedup and the
number of parallel cores M .

The results are shown in Figure 3, which shows almost perfect strong scaling
for up to 1000 MPI cores, for this level of accuracy. It is important to note
that there will be a limitation to the speedup possible, depending upon the
accuracy level. In particular, the total simulation time is limited by the single
most expensive sample required. Therefore, it will not be possible to achieve
MSE∝ ε2 in O(1) time, even with arbitrarily many cores.

14

Jasra, Law, Yu

Fig. 2. Elliptic Bayesian inverse problem of Section 3.2 Left: accuracy (minus MSE)
against number of single term samples N . The samples were simulated in serial on a
laptop, but can all be simulated in parallel. Right: convergence of stochastic gradient
iterates θ(n) to the maximum a posteriori probability estimator θMAP. The learning
rates considered here are αn = α1/n. The red curve corresponds to the unbiased
MLSMC algorithm of [32] for comparison.

123456log2(N)98765log2(MSE)8101214161820log2(cost)161412108642log2(MSE)UBMLMCMC, 1=0.30UBMLMCMC, 1=0.10UBMLMCMC, 1=0.03UBMLSMC, 1=0.30rMLMC for inference

15

Fig. 3. Parallel Speedup and Parallel Eﬃciency against number of MPI cores for the
unbiased particle ﬁlter from [36].

16

Jasra, Law, Yu

4 Conclusion and path forward

This position paper advocates for the widespread adoption of Bayesian meth-
ods for performing inference, especially in the context of complex science and
engineering applications, where high-stakes decisions require robustness, gener-
alizability, and interpretability. Such methods are rapidly gaining momentum
in science and engineering applications, following an explosive interest in UQ,
in concert with the data deluge and emerging fourth paradigm of data-centric
science and engineering. Meanwhile, in the ﬁeld of machine learning and AI
the value of Bayesian methods has been recognized already for several decades.
There it is widely accepted that the Bayesian posterior is the gold standard,
but the community has largely converged on variational approximations or even
point estimators as surrogates, due to complexity limitations.

Here a family of embarrassingly parallel rMLMC simulation methods are
summarized. The methods are designed for performing exact Bayesian inference
in the context where only approximate models are available, which includes
a wide range of problems in physics, biology, ﬁnance, machine learning, and
spatial statistics. Canonical complexity is achieved. Important priorities going
forward are: (i) continued development of novel instances of this powerful class
of algorithms, (ii) adaptation to speciﬁc large scale application contexts across
science, engineering, and AI, and (iii) automation of the methods and the design
of usable software to enable deployment on a large scale and across applications
in science, engineering, and AI, ideally by practitioners and without requiring
an expert.

Acknowledgements. KJHL and AT were supported by The Alan Turing Insti-
tute under the EPSRC grant EP/N510129/1. AJ and FY acknowledge KAUST
baseline support.

References

1. Nathan Baker, Frank Alexander, Timo Bremer, Aric Hagberg, Yannis Kevrekidis,
Habib Najm, Manish Parashar, Abani Patra, James Sethian, Stefan Wild, et al.
Workshop report on basic research needs for scientiﬁc machine learning: Core tech-
nologies for artiﬁcial intelligence. Technical report, USDOE Oﬃce of Science (SC),
Washington, DC (United States), 2019.

2. Alexandros Beskos, Ajay Jasra, Kody J. H. Law, Youssef Marzouk, and Yan Zhou.
Multilevel sequential Monte Carlo with dimension-independent likelihood-informed
proposals. SIAM/ASA Journal on Uncertainty Quantiﬁcation, 6(2):762–786, 2018.
3. Alexandros Beskos, Ajay Jasra, Kody J. H. Law, Raul Tempone, and Yan Zhou.
Multilevel sequential Monte Carlo samplers. Stochastic Processes and their Appli-
cations, 127(5):1417–1440, 2017.

4. Alexandros Beskos, Ajay Jasra, Kody J. H. Law, Raul Tempone, and Yan Zhou.
Multilevel sequential Monte Carlo samplers. Stochastic Processes and their Appli-
cations, 127(5):1417–1440, 2017.

5. Christopher M Bishop. Pattern recognition and machine learning. Springer, 2006.

rMLMC for inference

17

6. David M Blei, Alp Kucukelbir, and Jon D McAuliﬀe. Variational

inference:
Journal of the American statistical Association,

A review for statisticians.
112(518):859–877, 2017.

7. Susanne Brenner and Ridgway Scott. The mathematical theory of ﬁnite element

methods, volume 15. Springer Science & Business Media, 2007.

8. Alan Bundy and etal. Explainable AI: the basics, 2019.
9. Russel E Caﬂisch et al. Monte carlo and quasi-monte carlo methods. Acta numer-

ica, 1998:1–49, 1998.

10. Neil Chada, Jordan Franks, Ajay Jasra, Kody J. H. Law, and Matti Vihola. Un-
biased inference for discretely observed hidden markov model diﬀusions. SIAM
JUQ, to appear, 2020.

11. Philippe G Ciarlet. The ﬁnite element method for elliptic problems. SIAM, 2002.
12. Dan Crisan, Pierre Del Moral, Jeremie Houssineau, and Ajay Jasra. Unbiased
multi-index Monte Carlo. Stochastic Analysis and Applications, 36(2):257–273,
2018.

13. Masoumeh Dashti and Andrew M Stuart. Uncertainty quantiﬁcation and weak ap-
proximation of an elliptic inverse problem. SIAM Journal on Numerical Analysis,
49(6):2524–2542, 2011.

14. Pierre Del Moral. Feynman-Kac formulae. Springer, 2004.
15. Tim J Dodwell, Christian Ketelsen, Robert Scheichl, and Aretha L Teckentrup. A
hierarchical multilevel Markov chain Monte Carlo algorithm with applications to
uncertainty quantiﬁcation in subsurface ﬂow. SIAM/ASA Journal on Uncertainty
Quantiﬁcation, 3(1):1075–1108, 2015.

16. Thomas Gerstner and Michael Griebel. Dimension–adaptive tensor–product

quadrature. Computing, 71(1):65–87, 2003.

17. Roger Ghanem, David Higdon, and Houman Owhadi. Handbook of uncertainty

quantiﬁcation, volume 6. Springer, 2017.

18. Michael B Giles. Multilevel Monte Carlo path simulation. Operations research,

56(3):607–617, 2008.

19. Michael B Giles. Multilevel Monte Carlo methods. Acta Numer., 24:259–328, 2015.
20. Peter W Glynn and Chang-han Rhee. Exact estimation for markov chain equilib-

rium expectations. Journal of Applied Probability, 51(A):377–389, 2014.

21. Alastair Gregory, Colin J Cotter, and Sebastian Reich. Multilevel ensemble trans-
form particle ﬁltering. SIAM Journal on Scientiﬁc Computing, 38(3):A1317–
A1338, 2016.

22. Abdul-Lateef Haji-Ali, Fabio Nobile, and Ra´ul Tempone. Multi-index Monte Carlo:
when sparsity meets sampling. Numerische Mathematik, 132(4):767–806, 2016.
23. Stefan Heinrich. Multilevel Monte Carlo methods. In International Conference on

Large-Scale Scientiﬁc Computing, pages 58–67. Springer, 2001.

24. Jeremy Heng, Ajay Jasra, Kody J. H. Law, and Alexander Tarakanov. On unbiased

estimation for discretized models. arXiv preprint arXiv:2102.12230, 2021.

25. Viet Ha Hoang, Christoph Schwab, and Andrew M Stuart. Complexity anal-
Inverse Problems,

ysis of accelerated MCMC methods for Bayesian inversion.
29(8):085010, 2013.

26. H˚akon Hoel, Kody J. H. Law, and Ra´ul Tempone. Multilevel ensemble Kalman

ﬁltering. SIAM Journal on Numerical Analysis, 54(3):1813–1839, 2016.
27. The Alan Turing Institute. The AI revolution in scientiﬁc research, 2019.
28. Pierre E Jacob, John O’Leary, and Yves F Atchad´e. Unbiased Markov chain Monte
Carlo methods with couplings. Journal of the Royal Statistical Society: Series B
(Statistical Methodology), 82(3):543–600, 2020.

18

Jasra, Law, Yu

29. Ajay Jasra, Kengo Kamatani, Kody J. H. Law, and Yan Zhou. Multilevel particle

ﬁlters. SIAM Journal on Numerical Analysis, 55(6):3068–3096, 2017.

30. Ajay Jasra, Kengo Kamatani, Kody J. H. Law, and Yan Zhou. Bayesian static
parameter estimation for partially observed diﬀusions via multilevel Monte Carlo.
SIAM Journal on Scientiﬁc Computing, 40(2):A887–A902, 2018.

31. Ajay Jasra, Kengo Kamatani, Kody J. H. Law, and Yan Zhou. A multi-index
Markov chain Monte Carlo method. International Journal for Uncertainty Quan-
tiﬁcation, 8(1), 2018.

32. Ajay Jasra, Kody J. H. Law, and Deng Lu. Unbiased estimation of the gradient of
the log-likelihood in inverse problems. Statistics and Computing, 31(3):1–18, 2021.
33. Ajay Jasra, Kody J. H. Law, and Carina Suciu. Advanced multilevel Monte Carlo

methods. International Statistical Review, 88(3):548–579, 2020.

34. Ajay Jasra, Kody J. H. Law, and Yaxian Xu. Markov chain simulation for multilevel

Monte Carlo. Foundations of Data Science, 3:27, 2021.

35. Ajay Jasra, Kody J. H. Law, and Yaxian Xu. Multi-index sequential Monte Carlo
methods for partially observed stochastic partial diﬀerential equations. Interna-
tional Journal for Uncertainty Quantiﬁcation, 11(3), 2021.

36. Ajay Jasra, Kody J. H. Law, and Fangyuan Yu. Unbiased ﬁltering of a class of

partially observed diﬀusions. arXiv preprint arXiv:2002.03747, 2020.

37. Ajay Jasra, Kody J. H. Law, and Yan Zhou. Forward and inverse uncertainty quan-
tiﬁcation using multilevel Monte Carlo algorithms for an elliptic nonlocal equation.
International Journal for Uncertainty Quantiﬁcation, 6(6), 2016.

38. Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul.
An introduction to variational methods for graphical models. Machine learning,
37(2):183–233, 1999.

39. Harold Kushner and G George Yin. Stochastic approximation and recursive algo-
rithms and applications, volume 35. Springer Science & Business Media, 2003.
40. Neil Lawrence and Michael Jordan. Semi-supervised learning via gaussian pro-
cesses. Advances in neural information processing systems, 17:753–760, 2004.
41. Nicholas Metropolis and Stanislaw Ulam. The Monte Carlo method. Journal of

the American statistical association, 44(247):335–341, 1949.

42. Pierre Del Moral, Ajay Jasra, Kody J. H. Law, and Yan Zhou. Multilevel sequential
Monte Carlo samplers for normalizing constants. ACM Transactions on Modeling
and Computer Simulation (TOMACS), 27(3):1–22, 2017.

43. Kevin P Murphy. Machine learning: a probabilistic perspective. MIT press, 2012.
44. R. Neal. Regression and classiﬁcation using Gaussian process priors. Bayesian

statistics, 6:475, 1998.

45. Radford M Neal. Bayesian learning for neural networks, volume 118. Springer

Science & Business Media, 2012.

46. Judea Pearl et al. Causal inference in statistics: An overview. Statistics surveys,

3:96–146, 2009.

47. Benjamin Peherstorfer, Karen Willcox, and Max Gunzburger. Survey of multi-
ﬁdelity methods in uncertainty propagation, inference, and optimization. Siam
Review, 60(3):550–591, 2018.

48. Carl Edward Rasmussen and Christopher KI Williams. Gaussian processes for

machine learning. 2006.

49. Chang-han Rhee and Peter W Glynn. Unbiased estimation with square root con-

vergence for SDE models. Operations Research, 63(5):1026–1043, 2015.

50. Christian Robert and George Casella. A short history of Markov chain Monte
Carlo: Subjective recollections from incomplete data. Statistical Science, pages
102–115, 2011.

rMLMC for inference

19

51. H˚avard Rue, Sara Martino, and Nicolas Chopin. Approximate Bayesian inference
for latent Gaussian models by using integrated nested Laplace approximations.
Journal of the royal statistical society: Series b (statistical methodology), 71(2):319–
392, 2009.

52. Rick Stevens, Valerie Taylor, Jeﬀ Nichols, Arthur Barney Maccabe, Katherine
Yelick, and David Brown. Ai for science. Technical report, Argonne National
Lab.(ANL), Argonne, IL (United States), 2020.

53. Andrew M Stuart.

Inverse problems: a Bayesian perspective. Acta numerica,

19:451–559, 2010.

54. Albert Tarantola. Inverse problem theory and methods for model parameter esti-

mation. SIAM, 2005.

55. Matti Vihola. Unbiased estimators and multilevel Monte Carlo. Operations Re-

search, 66(2):448–462, 2018.

56. E Weinan, Jiequn Han, and Linfeng Zhang.

Integrating machine learning with
physics-based modeling. Arxiv preprint. https://arxiv.org/pdf/2006.02619.pdf,
2020.

57. Xiaojin Zhu, Zoubin Ghahramani, and John D Laﬀerty. Semi-supervised learning
using Gaussian ﬁelds and harmonic functions. In Proceedings of the 20th Interna-
tional conference on Machine learning (ICML-03), pages 912–919, 2003.

