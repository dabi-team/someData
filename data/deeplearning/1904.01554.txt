Learning Algorithms via Neural Logic Networks

Ali Payani 1 Faramarz Fekri 1

9
1
0
2

r
p
A
2

]

G
L
.
s
c
[

1
v
4
5
5
1
0
.
4
0
9
1
:
v
i
X
r
a

Abstract

We propose a novel learning paradigm for Deep
Neural Networks (DNN) by using Boolean logic
algebra. We ﬁrst present the basic differentiable
operators of a Boolean system such as conjunc-
tion, disjunction and exclusive-OR and show how
these elementary operators can be combined in a
simple and meaningful way to form Neural Logic
Networks (NLNs). We examine the effective-
ness of the proposed NLN framework in learning
Boolean functions and discrete-algorithmic tasks.
We demonstrate that, in contrast to the implicit
learning in MLP approach, the proposed neural
logic networks can learn the logical functions ex-
plicitly that can be veriﬁed and interpreted by
human. In particular, we propose a new frame-
work for learning the inductive logic program-
ming (ILP) problems by exploiting the explicit
representational power of NLN. We show the pro-
posed neural ILP solver is capable of feats such as
predicate invention and recursion and can outper-
form the current state of the art neural ILP solvers
using a variety of benchmark tasks such as dec-
imal addition and multiplication, and sorting on
ordered list.

1. Introduction

Deep Neural Networks (DNNs) based on Convolution
Neural Networks (CNNs) and Recurrent Neural Networks
(RNNs) have improved the state of the art in various areas
such as natural language processing (Collobert & Weston,
2008), image and video processing (Krizhevsky et al., 2012),
and Speech recognition (Dahl et al., 2012) just to name a
few. However, while in theory it is known that DNNs and
speciﬁcally RNNs can be Turing complete and capable of
learning any program (Siegelmann & Sontag, 1992), there
has been limited success in using DNNs for learning algo-
rithmic problems. Even a rather simple decimal multipli-

1Department of Electrical and Computer Engineering
to:
Faramarz Fekri

Georgia
Ali Payani <payani@ece.gatech.edu>,
<fekri@ece.gatech.edu>.

Institute of Technology.

Correspondence

cation problem is very difﬁcult to learn just by providing
the model with input/output pairs of examples (Kaiser &
Sutskever, 2015). In particular, MLP based come with some
limitations. These model, in general, do not construct any
explicit and symbolic representation of the algorithm they
learned and the algorithm is implicitly stored in thousands
or even millions of weights, which is typically impossible
to be deciphered and veriﬁed by human agents. Further,
MLP networks are usually suitable for cases where there are
many training examples, and usually do not generalize well
where there only limited training examples. One of the most
successful machine learning approaches that addresses these
shortcomings for learning discrete algorithmic tasks is the
Inductive Logic Programming (ILP). In ILP, explicit rules
and symbolic logical representations can be learned using
only a few training examples and these models are usually
able to generalize well. Further, the explicit symbolic rep-
resentation that is obtained via ILP can be understood and
veriﬁed by human, and can also be used to write programs
in any conventional programming language. Recently there
has been some attempts to bridge the gap between the two
discipline and to use the deep learning methods in solving
the ILP problems. These works usually rely on some forms
of transforming the ILP satisﬁability problem into a differ-
entiable problem which in turn could be solved by gradient
descent algorithms (H¨olldobler et al., 1999; Bader et al.,
2008; Franc¸a et al., 2014; Seraﬁni & Garcez, 2016; Evans
& Grefenstette, 2018).

In this paper we present an alternative approach to the tra-
ditional MLP design for learning Boolean functions and
aim to address some of the shortcoming of the MLP for
learning discrete-algorithmic tasks. Our key idea is to de-
ﬁne a set of differentiable Boolean operators that can be
combined in a multi-layer cascade design like MLP, and
are capable of computing and learning Boolean functions.
Unlike MLP, our proposed model provides explicit symbolic
representation which could be tested and veriﬁed by human.
We further demonstrate that the proposed approach can be
used to transform the ILP into a differentiable problem and
solve it using gradient optimizers more efﬁciently than the
existing neural ILP solvers.

The general idea of representing and learning Boolean func-
tions using neural networks is not new. There is signiﬁcant
body of research from the early days of machine learning

 
 
 
 
 
 
Learning Algorithms via Neural Logic Networks

using neural networks that is focused on the theoretical as-
pects of this problem. Some of special Boolean functions
such as parity-N and XOR has been the subject of special
interest as benchmark tasks for theoretical analysis. Min-
sky and Papert (Minsky & Papert, 2017; Wasserman, 1989)
for example showed the impossibility of representing all
functional dependence and proved this for XOR logic func-
tion while other works demonstrate the possibly of doing
so by adding hidden layers. From the practical standpoint
however, as was suggested by many works (for example
(Steinbach & Kohut, 2002)), any Boolean function can be
learned by a proper multi layer design equipped with proper
activation functions. However, as we will show in following
chapters, there are scenarios where they do not perform well.
Moreover, even if they learn successfully, it is notoriously
difﬁcult to decipher the actual learned Boolean function.

In contrast, in this paper, we propose a new design for the
logical operators (namely Neural Logic Networks (NLN))
by using membership weights without the adjustable bias
terms. The NLN network has an explicit representational
power which separates the proposed models from the previ-
ous works. In this paper, ﬁrst, we introduce general purpose
conjunction, disjunction and the exclusive OR neurons as
the basic elements of the NLN. We would then demonstrate
the properties and characteristics of the proposed model in
three areas :

• Learning Boolean functions efﬁciently : In Section 3,
we demonstrate how the NLN compares to the MLP in
learning Boolean functions.

• Generalization : In Section 4, we compare the gener-
alization performance of NLN and MLP in learning a
message passing decoding algorithm for Low Density
Parity Check Codes (LDPC) over erasure channels.
• Explicit symbolic representation : In Section 5, we
propose a new algorithm for solving ILP problems by
exploiting the explicit representational power of NLN.

2. Neural Logic Layers

2.1. Neural Conjunction and Disjunction Layers

Throughout this paper, we use the extension of the Boolean
values to real values in the range [0, 1] and we use 1 (True)
and 0 (False) representations for the two states of a binary
variable. We also deﬁne the fuzzy unary and dual Boolean
functions of two Boolean variables x and y as:

¯x = 1 − x
(cid:95)

x

y = 1 − (1 − x)(1 − y)

(cid:94)

,

x

y = xy

(1a)

(1b)

This algebraic representation of the Boolean logic allows
us to manipulate the logical expressions via Algebra. Let
xn ∈ {0, 1}n be the input vector in a typical logical neu-
ron. To implement the conjunction function, we would like

xi mi Fc
1
0
0
0
1
0
1
0
1
1
1
1

(a)

xi mi Fd
0
0
0
0
1
0
0
0
1
1
1
1

(b)

Figure 1: Truth table of Fc(·) and Fd(·) functions

to select a subset in xn and apply the fuzzy conjunction
(i.e. multiplication) to the selected elements. One way to
accomplish this is to use a softmax function and select the
elements that belong to the conjunction function similar to
the concept of pointer networks (Vinyals et al., 2015). This
requires knowing the number of items in the subset (i.e. the
number of terms in the conjunction function) in advance.
Moreover, in our experiment we found that the convergence
of model using this approach is very slow for larger input
vectors. Alternatively, we associate a trainable Boolean
membership weight mi to each input elements xi from vec-
tor xn. Further, we deﬁne a Boolean function Fc(xi, mi)
with the truth table as in Fig.1a which is able to include
(exclude) each element in (out of) the conjunction function.
This design ensures the incorporation of each element xi in
the conjunction function only when the corresponding mem-
bership weight is 1. Consequently, the neural conjunction
function can be deﬁned as:

Oconj(x) =

n
(cid:89)

Fc(xi, mi)

i=1
where, Fc(xi, mi) = ximi = 1 − mi(1 − xi) ,

(2)

where Oconj is the output of conjunction neuron. To ensure
the trainable membership weights remain in the range [0, 1]
we use a sigmoid function, i.e. mi = sigmoid(c wi) where
c ≥ 1 is a constant. Similar to perceptron layers, we can
stack m neural conjunction neurons to create a conjunction
layer of size m. This layer has the same complexity as a
typical perceptron layer without incorporating any bias term.
More importantly, this way of implementing the conjunction
layer makes it possible to interpret the learned Boolean func-
tion directly from the values of the membership weights.

The disjunctive neuron can be deﬁned similarly by intro-
ducing membership weights but using the function Fd with
truth table as depicted in Fig.1b. This function ensures an
output 0 from each element when the membership is zero
which correspond to excluding the xi element from the neu-
ron outcome. Therefore, the neural disjunction function can

Learning Algorithms via Neural Logic Networks

Fd(xi, mi) = 1 −

n
(cid:89)

(1 − Fd(xi, mi)) ,

stants (e.g. 1e − 3). Alternatively we can initialize weights
by a normal distribution with negative mean which needs to
be adjusted correctly dependent on the size of the layer.

be expressed as:

Odisj(x) =

n
(cid:89)

i=1

where, Fd(xi, mi) = ximi

i=1

2.3. Neural XOR Layer

(3)

By cascading a conjunction layer with a disjunctive layer,
we can create a multi-layer structure which is able to learn
and represent Boolean functions using the Disjunctive Nor-
mal Form (DNF). Similarly we can construct the Con-
junctive Normal Form (CNF) by cascading the two layers
in the reverse order. The total number of possible logi-
cal functions over a Boolean input vector x ∈ {0, 1}n
is very large (i.e. 22n
). Further, in some cases, a sim-
ple clause in one of those standard forms can lead to
an exponential number of clauses when expressed in the
other form For example, it is easy to verify that converting
(cid:87) xn) to DNF leads
(cid:87) x2) (cid:86)(x3
(x1
to 2 n
2 number of clauses. As such, using only one single
form of Boolean network for learning all possible Boolean
functions is not always the best approach. The general pur-
pose design of the proposed conjunction and disjunction
layers allows us to deﬁne the appropriate Boolean function
suitable for the problem.

(cid:87) x4) (cid:86) · · · (cid:86)(xn−1

2.2. Convergence and Initialization

For a single Boolean layer, it can be easily shown that using
a small enough learning rate, if we have counter examples
in each training batch, they are guaranteed to converge. For
example, by examining the conjunction function in (2), it is
easy to verify that if mi is supposed to be 1, we would need
a training example with xi = 0 and Oconj = 1 to have a
negative gradient necessary for adjusting mi towards 1. This
can be easily veriﬁed considering that ∂Oconj
∝ (xi − 1).
∂mi

The only parameter which we need to adjust for training
these layers is the initial values for the membership weights
mi (or corresponding wi). During the experiments, we real-
ized that while the speed of convergence somewhat depends
on the initial values for the weights, in moderate size prob-
lems, the network is able to ﬁnd the optimal setting and
converges to the desired output. As such, we usually ini-
tialize all the weights randomly using normal distribution
with zero mean. However, in cases where the dimension of
the input vector is very large, this type of initialization may
result in a very slow convergence in the beginning. Due to
the multiplicative design of these layers, when many of the
membership variables have values which are not zero or one,
the gradient can becomes extremely small. To avoid this
situation, we must ensure that most of the membership vari-
ables are almost zero in the beginning. In our experiments
we usually initialize the membership weights by randomly
setting a small subset of inputs to values close to 1 and we
initialize the rest of membership variables to very small con-

Exclusive OR (XOR) is another important Boolean function
which has been the subject of many researches over the
years, especially in the context of parity-N learning problem.
It is easy to verify that expressing XOR of an n-dimensional
input vector in DNF form requires 2n−1 clauses. Although,
it is known that it cannot be implemented using a single
perceptron layer (Minsky & Papert, 2017; Duch, 2006),
it can be implemented, for example, using multilayer per-
ceptron or multiplicative networks combined with small
threshold values and sign function activation (Iyoda et al.,
2003). However, none of these approaches allow for explicit
representation of the learned XOR functions directly. Here
we propose a new algorithm for learning XOR function (or
equivalently the parity-N problem). To form the logical
XOR neuron, we ﬁrst deﬁne k functions of the form:

f1(x) = x1 + x2 + · · · + xk −xk+1 − · · · − xn

f2(x) = x1 + x2 + . . . −xk − · · · − xn−1 + xn
...
...
fk(x) = x1 −x2 − · · · − xk − xk+1 + · · · + xn

...

...

...

(4)
2 (assuming n is even). Then, we deﬁne the

where k = n
XOR function as in Theorem 1.

Theorem 1. Given the set of k functions as deﬁned in (4
we have:

XOR(x) = g1(x)

(cid:94)

g2(x)

(cid:94)

· · ·

(cid:94)

gk(x) ,

(5a)

where, gi(x) =

(cid:40)
0
1

if fi(x) = 0
else

(5b)

Proof. See Appendix A.

Inspired by the Theorem.1, we design our XOR neuron as:

OXOR(x) =

(cid:18)

hs

k
(cid:89)

i=1

(cid:12)
(cid:12)x × (Mi (cid:12) w)T (cid:12)
(cid:12)

(cid:19)

(6)

Here, hs(·) is the hard-sigmoid function, and × and (cid:12)
denote matrix and element-wise multiplication correspond-
ingly. Further, vector Mi ∈ {−1, 1}n is the set of coef-
ﬁcients used in fi(x) and w is the vector of membership
weights. The resulting XOR logical neuron uses only one
weight variable per input element for learning. However,
its complexity is k times higher than the conjunction and
disjunction neurons for an input vector of length n = 2k.

Learning Algorithms via Neural Logic Networks

3. NLN vs MLP

We now compare the performance NLN vs MLP for the task
of learning Boolean functions using two synthetic experi-
ments.

3.1. Learning DNF form

For this experiment, we randomly generate some Boolean
functions over a 10 bits input vectors and a randomly gen-
erated batches of 50 samples as training data. We train
two models; one designed via our proposed DNF network
(with 200 disjunction functions) and another designed by
two layers MLP network with hidden layer of size 1000
and ’relu’ activation and use ’sigmoid’ activation function
for the output layer. We use ADAM optimizer (Kingma
& Ba, 2014) with learning rate of 0.001 for both models
and count the number of errors in 1000 randomly generated
test samples. When we used a Bernoulli distribution with
parameter p = 0.5 (i.e. fair coin toss) for generating the
bits of each training samples, both models quickly converge
and the number of test error drops to zero for both. How-
ever, in many realistic discrete problems, the 0’s and 1’s are
not usually equiprobable. As such, next we use Bernoulli
with parameter p = 0.75. Fig. 2a depicts the comparative
performance of the two models. The proposed DNF model
converges fast and remains at 0 error. On the contrary, the
MLP model continues to generate errors. In our experi-
ments, while the number of errors decreases as training
continues for an hour, the MLP model never fully converges
to the true logical function and occasionally generates some
errors. While for some tasks, this may be a negligible error,
in some logical applications such as the ILP task (in Section.
5), this behavior prevents the model from learning.

3.2. Learning XOR function

Next, we compare the two models for a much more complex
task of learning the XOR logic. We use a multi layer MLP
with ’relu’ as activation functions in the hidden layers and
sigmoid function in the output layer as usual. As for NLN,
we use a single XOR neuron as described in 2.3. For the
small size inputs both models quickly converge. However,
for larger size input vectors (n > 30) the MLP model fails
to converge at all. Fig 2b shows the average bit error over
the number of training samples. The error rate for MLP
was around .5, which indicates it failed to learn the XOR
function. On the contrary, the XOR logic layer was able
to converge and learn the objective in most of the runs.
This is signiﬁcant considering the fact that the number of
parameters in our proposed XOR layer is equal to the input
length, i.e., one membership per input variable.

(a) DNF Task

(b) Xor 50 Task

Figure 2: Comparing MLP vs NLN for learning Boolean
functions

4. Generalization

To evaluate the generalization, we consider learning an iter-
ative decoding algorithm for the LDPC codes. LDPC codes
are linear error correcting codes that are widely used due
to their capacity achieving performance (Richardson et al.,
2001). One popular problem in the coding research is de-
coding these codes over the Binary Erasure Channel (BEC),
where a subset of the bits in the received codeword (from
the channel output) is marked as erased due to the channel
corruption. For BEC, decoding of the received LDPC code-
word can be performed using an iterative Message Passing
(MP) algorithm by enforcing the parity checks in the parity
check matrix. To compare the performance of MLP vs NLN
in learning a discrete-algorithmic task, we use the deep re-
current model that was introduced in (Payani & Fekri, 2018)
to learn the iterative decoding using MLP and NLN.

Simply put, in message passing decoding of LDPC codes,
each iteration involves a forward and backward path. In the
forward path, the content of each check-node is updated via
function F which takes all the connected variable-nodes as
input. In the backward path, the content of each variable-
nodes is then updated via function B which takes the signal
from all the connected check-nodes as input.

To compare the performance of MLP and NLN we design
the forward-backward functions (i.e., F and B) for the
ﬁrst model using MLP architecture (i.e., LDPC-MLP) and
for the second model using NLN (LDPC-NLN). We use
comparable number of parameters in each model (e.g. for
LDPC(3,6) code of length 48 we use hidden dimension
of size 200). In both models, we use randomly generated
codewords for a regular LDPC(3,6) code of length 48 as
training data and set the number of message passing iteration
in training to 3.
In testing phase, we run
the trained models for many more iterations to see how
much each model has generalized and learned the iterative
algorithm.

(tmax = 3).

Fig 3 depicts the performance of two models in terms of
bit error probability (BER). As one may expect, the model
based on MLP converges faster and generates lower BER
for the setup used in training, i.e, t = 3. However, increas-

050k100k150k200k250k300k350k400k450k500kNumber of training samples050100150200250300350400Number of errorsDNF (NLN)MLP0500100015002000250030003500Number of Training Samples00.20.40.60.81Bit Error Rate (BER)Multi-Layers PerceptronXOR Logical LayerLearning Algorithms via Neural Logic Networks

framework rules are usually written as clauses of the form:

H ← B1, B2, . . . , Bm

(7)

where H is called head of the clause and B1, B2, . . . , Bm
is called body of the clause. A clause of this form expresses
that if all the Boolean terms in the body are true, the head
is necessarily true. We assume each of the terms H and
B are made of atoms. Each atom is created by applying
an n-ary Boolean function called predicate to some
constants or variables. A predicate states the relation
between some variables or constants in the logic program.
Throughout this paper we will use small letters for constants
and capital letters (A, B, C, ...) for variables. In most ILP
systems, each predicate can be deﬁned via several clauses of
the form stated in (7) which is equivalent to the DNF logical
form.

Let’s consider
lessThan predicate over natural numbers:

the logic program that deﬁnes

the

lessT han(A, B) ← inc(A, B)

lessT han(A, B) ← lessT han(A, C), inc(C, B)

(8)

and assume that our constants contains the set C =
{0, 1, 2, 3, 4} and the ordering of the natural numbers
are deﬁned using the predicate inc (which deﬁnes in-
crements of 1). The set of background atoms which
describe the known facts about this problem is the set
B = {inc(0, 1), inc(1, 2), inc(2, 3), inc(3, 4)}. We as-
sociate two scalar functions arity(p) and var(p) cor-
responding to the number of input arguments for the
predicate and the number of variables that can be used
in deﬁning predicate. Further, we associate a Boolean
function Fp to each (intensional) predicate which de-
ﬁnes the Boolean function corresponding to the predi-
cate p. In the above example arity(lessT han) = 2 and
var(lessT han) = 3 and the predicate function FlessT han
can be deﬁned over all possible atoms which involve
three variables A,B,C (e.g., it is deﬁned as FlessT han =
inc(A, B) (cid:87)(lessT han(A, C) (cid:86) inc(C, B)) in (8)).

We also distinguish between extensional and intensional
predicates. The former is entirely deﬁned by the ground
facts (eg. inc predicate in the above example), while the
latter is deﬁned using the other predicate function (eg.
the lessT han predicate in the above example) Once we
have the predicate formula (8) which describe our target
predicate, we can use rules of deduction and infer all the
consequences of the program using forward chain
of reasoning, i.e, we apply the target predicate rules to
the constants in the program iteratively. Let Pi be the set of
intensional predicates and X (t) be the set of deduced facts
at time stamp t. We infer the X (T ) where T is the number

Figure 3: LDPC decoding over Erasure Channels

ing the number of iterations in test time not only does not
improve the accuracy for LDPC-MLP, it even degrades the
performance for t > 3. On the other hand, as the num-
ber of iterations increases, the performance of LDPC-NLN
model improves signiﬁcantly. Arguably, there are ways to
improve the performance of MLP in such tasks (e.g, by sig-
niﬁcantly increasing the number of training iterations and
enforcing the network to generate valid outcome at the end
of each iterations by adding some penalty term). However,
the NLN model provides a more natural way for learning
such discrete-algorithmic tasks.

5. Induction Logic Programming via NLN

One of the recent breakthroughs in solving ILP problems
(specially for recusive and algorithmic tasks) is due to works
such as (Cropper & Muggleton, 2015) which led to the
invention of Metagol (Cropper & Muggleton, 2016), the
state of the art ILP solver capable of learning via predi-
cate invention and recursion. Very recently in (Evans and
Grefenstette 2018) the authors proposed a differentiable ILP
(dILP) which also supports those features but using a neural
network framework. While there are some other noticeable
works on neural ILP solvers, we would mainly compare our
proposed model to the Metagol and dILP since the other
alternatives (for instance (H¨olldobler et al., 1999; Bader
et al., 2008; Franc¸a et al., 2014; Seraﬁni & Garcez, 2016))
do not support both of these important features (i.e., recur-
sion and predecate invention) and therefore are not optimal
for solving recursive algorithmic problems.

In this chapter, we introduced a new differentiable ILP
solvers by exploiting the explicit representational power
of our NLN which we believe is a signiﬁcant improvement
over the dILP and is more ﬂexible than Metagol in terms of
the need for an expert input.

For a more complete reference on ILP programming we
refer the reader to (Muggleton & De Raedt, 1994; Dze-
roski, 2007). Here, we give a brief background relevant to
our proposed algorithm using an example problem. Logic
programing is a programming paradigm in which we use
formal logic (and usually ﬁrst-order-logic) to describe rela-
tions between facts and rules of a program domain. In this

024681012Iteration (t)0.080.10.120.140.160.180.2BERMLP DecoderNLN DecoderLearning Algorithms via Neural Logic Networks

of time stamps using the recursive formula:

X (i) =X (i−1) (cid:91)

{ p(a1, . . . , am)|Fp(a1, . . . , an) = T rue,
ak ∈ C, p ∈ Pi, n = var(p), m = arity(p)},

where, X (0) consist of background facts. As an example,
for the logic program lessT han we will have:

{lt(0, 1), lt(1, 2), lt(2, 3), lt(3, 4)}

X (0) = B = {inc(0, 1), inc(1, 2), inc(2, 3), inc(3, 4)}
X (1) = X (0) (cid:91)
X (2) = X (1) (cid:91)
X (3) = X (2) (cid:91)
X (4) = X (3) (cid:91)

{lt(0, 2), lt(1, 3), lt(2, 4)}

{lt(0, 3), lt(1, 4)}

{lt(0, 4)},

where we use lt as shorthand for lessT han. Here, applying
the predicate rules beyond t = 4 does not yield any new
ground atom.

Given the background facts (B) and a set of positive and
negative examples (P and N respectively), The goal of ILP
is that to learn a program (including target predicate and a
number of possible auxiliary predicates) such that it entails
all the positive examples and rejects all the negative ones.
The predicate function deﬁned in (8) is one such solution to
the ILP problem which satisﬁes all the examples.

We use the simple lessT han logic program in above
as an example to explain the basics of the proposed al-
gorithm. Assume we consider a solution for the predi-
cate function Flt containing at most three variables, i.e.
(A, B, C). We deﬁne the function P erm(S, n) to return
all the tuples of length n from the elements of a set
S. For example, P erm({A, B}, 2) would give the set
{(A, A), (A, B), (B, A), (B, B)}. Further, for any predi-
cate p and set of variables V we deﬁne the set T erms(p, V )
as:

T erms(p, V ) = {p(arg)| arg ∈ P erm(V, arity(p) ) }

(9)
For now, if we exclude the use of functions in deﬁning pred-
icates, the set of all the atoms that can be used in deﬁning
target predicate can be expressed as:

InputList(Flt) = T erms(inc, {A, B, C})

(cid:91)

T erms(lt, {A, B, C})

This
{inc(A, A), . . . , inc(C, C), lt(A, A), . . . , lt(C, C)}.

correspond

the

to

is

(10)

(11)

set

Most proposed ILP solvers examine only a very limited
subset of possible combinations to ﬁnd a solution. Metagol
(Cropper & Muggleton, 2016), the state of the art ILP solver

based on meta interpretive learning (Cropper & Muggleton,
2015), employs user-deﬁned meta rules to reduce the set
of possible combinations of terms. This requires an expert
knowledge with regards to the possible forms of the solution,
which is a restrictive approach. Further,this approach may
require many trials to ﬁnd the suitable set of meta rules.

Among the neural ILP solvers, the current state of the art
solver proposed by (Evans & Grefenstette, 2018) limits the
number of possible terms to all the combinations contain-
ing only two atoms which signiﬁcantly reduces the space
of possible solutions and uses a softmax network to ﬁnd
a set of combination corresponding to the answer from all
combinations containing only two atoms. While, in princi-
ple, this limitation can be alleviated by introducing more
and more auxiliary predicates, this approach is not practical
and requires huge amount of memory. The sheer num-
ber of possible combinations that these algorithms need to
consider makes them inviable candidates for larger scale
problems specially when it requires recursion and multiple
steps of forward chain of reasoning. Consequently in (Evans
& Grefenstette, 2018) the experiments were limited to the
predicates with arity of 2

Our key idea is to employ our NLN framework to deﬁne the
predicate functions corresponding to each intensional pred-
icate ( instead of limiting the possible terms using search
trees or considering limited combinations similar to previ-
ous approaches.) This allows for framing the ILP problem
as an end-to-end neural network which can be trained via
typical gradient based optimization techniques. Further, this
would in general eliminate the restrictions for deﬁning the
predicate functions. In particular, in NLN we are not limited
to use the DNF form for deﬁning the predicate and we can
employ any there Boolean network such as a CNF form and
XOR logic to learn the predicate functions.

5.1. NLN based neural ILP Solver

We present our algorithm using the current lessT han ex-
ample. First, we deﬁne the predicate functions for each
intensional predicate (only lt here) using NLN. For exam-
ple, we may use the DNF structure in NLN with a hidden
layer of 4 (four disjunction terms) to deﬁne the Flt.

Next, we deﬁne the valuation vector for each predicate at
time stamp t as Y (t)
p which consists of (fuzzy) Boolean val-
ues of all the ground atoms involving that predicate. For
example the vector Yinc includes the Boolean values for
atoms in {inc(0, 0), inc(0, 1), . . . , inc(4, 4)}. Here we re-
move the t superscripts since the values of atoms from
extensional predicate do not change over time.

Learning Algorithms via Neural Logic Networks

Algorithm 1 Outline of the NLN based neural ILP solver
Result: Y Tmax
target
for t ∈ {1, . . . , Tmax} do

variables mi toward binary values by multiplying the cor-
respond weights wi to some positive constant larger than 1
(e.g. 1.2 in our experiments)

for p ∈ Pi do

for arg ∈ C var(p) do

θ = {arg0/A, arg1/B, arg2/C, . . . }
xi = InputListp|θ
argp = {arg0, . . . , argarity(p)−1}
Yp[argp] ← Yp[argp] (cid:87) Fp(xi)

Algorithm 1 shows the outline of the Tmax steps of forward
chain of reasoning in the proposed ILP solver algorithm.
Here θ deﬁnes a substitution (replacing variables with con-
stants) and InputListp|θ is a fuzzy Boolean vector formed
by gathering the corresponding elements of InputListp
function (after substitution of variables with constants) from
the content of valuation vectors Yp’s. In actual tensorﬂow
implementation (Abadi et al., 2015) we reformulate the
problem in matrix form and before the start of the training
we calculate the content of valuation vectors belong to all
extensional predicates to speed up the training. Also, while
the algorithm is described sequentially, we compute all the
disjunction operations in the inner-most for-loop in paral-
lel in a batch operation since they do not depend on each
other. All the conjunction and disjunction operations in our
algorithm is implemented as deﬁned in (1).
We use the cross-entropy loss between ˆYtarget (the ground
truth provided by the positive and negative examples) and
Y (Tmax)
target which is the output of Algorithm.1.

5.2. Training

We train the model using ADAM (Kingma & Ba, 2014)
optimizer with learning rate of .001 and we initialize mem-
bership weights of the NLN using the approach described
in section 2.2. After the training is completed, a zero cross-
entropy loss indicates that the model has been able to satisfy
all the examples in the positive and negative sets. However,
there can be some terms with membership weights of ’1’
in deﬁning each predicate which are not necessary for the
satisﬁability of the solution. Since there is no gradient at this
point we cannot directly remove those term during gradient
descent algorithm unless we include some penalty terms.
In practice we use a simpler approach. In the ﬁnal stage
of algorithm we remove these terms by a simple satisﬁabil-
ity check, .i.e, if by setting any of membership variables
with value of ’1’ to ’0’ the loss function does not change
we remove that term from the outcome. Further, because
at the end of convergence, the gradient can become small,
to speed up the ﬁnal stage of convergence, when the loss
function is below some threshold, we move the membership

5.3. Benchmark tasks

We tested the proposed algorithm on the 20 symbolic tasks
described in (Evans & Grefenstette, 2018) and the details
of these experiments can be found in Appendices G.1 to
G.20 of that paper. In Table 1 we have listed the percent-
ages of runs for each of the tasks that resulted in correct
solution for the proposed algorithm and compared it to the
baseline methods; dILP and Metagol. Although these are
rather simple tasks, as shown in Table.1, the dlp cannot
always ﬁnd a solution in many of the problems. This can
be due to the fact that the algorithm depends on the initial
weights and therefore many of the simulations may result
in poor performance. Metagol, however is a deterministic
approach and it can either ﬁnd a solution or is unable at all.
In general, if not provided with carefully tuned meta rules,
which deﬁne templates for the axillary and target predicates,
Metagol cannot learn many of the tasks involving recursion
(e.g. Relatedness and Connectedness tasks in Table 1). In
contrast, our proposed model can always ﬁnd the correct
solution for these tasks.
Table 1: NLN solver vs dILP and Metagol in benchmark
tasks

Domain/Task
Arithmetic/Predecessor
Arithmetic/Even
Arithmetic/Even-Odd
Arithmetic/Less than
Arithmetic/Fizz
Arithmetic/Buzz
List/Member
List/Length
Family Tree/Son
Family Tree/GrandParent
Family Tree/Husband
Family Tree/Uncle
Family Tree/Relatedness
Family Tree/Father
Graph/Undirected Edge
Graph/Adjacent to Red
Graph/Two Children
Graph/Graph Colouring
Graph/Connectedness
Graph/Cyclic

dILP Metagol NLN
100
100
100
100
100
100
100
100
49
100
100
100
100
100
10
100
100
35
100
100
100
100
100
93
100
100
100
100
100
97
100
100
100
100
100
70
100
100
0
100
100
100
100
100
100
100
100
51
100
100
95
100
100
95
100
100
0
100
100
0

5.4. Learning Decimal Arithmetic

The 20 tasks in the previous section are rather simple tasks.
For more complex tasks for which the predicate deﬁnition
requires more atoms and the arity of predicates are higher

Learning Algorithms via Neural Logic Networks

than two, methods such as dILP cannot be used. Even
Metagol can only learn such tasks that require recursion
when the appropriate rule templates for the are provided
by an expert. Here, we apply our method to learn more
complex recursive arithmetic tasks. We ﬁrst describe the
addition problem for the natural number domain and then
we use the addition predicate as background knowledge in
second task to learn the multiplication.

5.4.1. ADDITION TASK

We use C = {0, 1, 2, 3, 4, 5} as constants and
is consist of B =
our background knowledges
{zero(0), eq(0, 0), . . . , eq(4, 4), inc(0, 1), . . . , inc(3, 4)},
where inc deﬁnes increment and eq tests for equality. The
target predicate is add(A, B, C) and we allow for use of
two additional variables (i.e., var(add) = 3 + 2 = 5). As
usual, we use a DNF network for learning Fadd. One of the
solutions that our model ﬁnds is:

add(A, B, C) ← zero(B), eq(A, C)

add(A, B, C) ← add(A, D, E), inc(D, B), inc(C, E)

H(X) and t(X) which allow for decomposing a list into
head and tail elements, i.e A = [H(A)|t(A)]. We use ele-
ments of {a, b, c, d} and all the lists made from permutations
of up to three elements as constants in the program. We use
extensional predicates such as gt (greater than), eq (equals)
and lte (less than or equal) to deﬁne ordering between the
elements as part of the background knowledge. We allow
for using two additional variables in deﬁning the predicate
sort(A, B). One of the solution that our model ﬁnds is:

sort(A, B) ← sort(H(A), C), lte(t(C), tA),
eq(H(B), C), eq(tA, tB)

sort(A, B) ← sort(H(A), C), gt(t(C), tA), eq(t(B), t(C)),
eq(H(D), H(C), eq(t(A), t(D), sort(D, H(B))

To the best of our knowledge, learning a recursive solution
like this which involves clauses with 6 atoms and include 4
variables (and their functions) is beyond the power of any
existing neural ILP solver.

5.4.2. MULTIPLICATION TASK

6. Conclusion

Next, we add the learned addition predicate to the back-
ground knowledge of the previous experiment and then try
to learn the mul(A, B, C) predicate. One of the obtained
solutions is:

mul(A, B, C) ← zero(B), zero(C)

mul(A, B, C) ← mul(B, A, C)

mul(A, B, C) ← mul(A, D, E), inc(D, B), plus(E, A, C)

It is worth nothing that to the best of our knowledge, learn-
ing recursive algorithmic tasks like this using only positive
and negative examples and without using any template for
deﬁning viable option (other than assuming DNF form) is
beyond the power of any current ILP solver. Indeed, most
neural ILP solvers are either incapable of learning recursion
or like dlp have limited scope and cannot be used to learn
complex predicates. While, tasks such as decimal and bi-
nary addition and multiplications can be learned with very
sophisticated neural algorithms such as (Kaiser & Sutskever,
2015), they lack the generalization power of ILP and their
performance signiﬁcantly drops when the size of the prob-
lem grows. Furthermore, the learned algorithm is not ex-
plicit in nature and acquired knowledge cannot be transfered
to another problem easily.

5.5. Sorting an ordered list

The sorting tasks is more complex than the previous tasks
since it requires the list semantics. We implement the list
semantic by allowing the use of functions in deﬁning pred-
icates. For a data of type list, we deﬁne two functions

We have introduced NLN as a new paradigm of neural net-
works designed for explicit learning and representation of
Boolean functions. Using various experiments we showed
their effectiveness in learning the logical representations.
Further, we demonstrated their generalization superiority
to the traditional MLP in a discrete iterative algorithmic.
Finally, by proposing a new algorithm for learning ILP prob-
lems we demonstrated the importance of the explicit logical
representation that is achieved using NLN.

A. Proof of Theorem 1.

Proof. First consider that for the case where the number of
(cid:48)1(cid:48)s in x is odd (i.e. XOR(x) = 1), none of the functions
fi(x) can be equal to zero since the sum of odd number of
elements from the set {−1, 1} cannot be zero. Therefore,
the statement in (5a) is true due to (5b). Now consider the
case that XOR(x) is zero. We must show that at least one of
the k functions fi(x) would be equal to zero in this case. Let
Mi ∈ {−1, 1}n be the vector of coefﬁcients for fi(x) and
s be the number of ones in the input vector x. Further, for
any fi, let n(1)
be the number of corresponding
1 and -1 coefﬁcients that matches the positions of elements
of ’1’ in vector x. We notice that the sign of exactly two
elements in Mi and Mi+1 changes when we go from fi(x)
to fi+1(x) and those signs remain unchanged in the next set
of functions. As we have k functions and s ≤ 2k, this would
guarantee that the sign of the coefﬁcients corresponding to
’1’ elements changes exactly once in the set of k functions.
Thus, in one of the functions, let’s say the one corresponding

and n(−1)
i

i

Learning Algorithms via Neural Logic Networks

= n(1)

j = n(−1)
to the jth coefﬁcient vector we would have n(1)
and n(−1)
1 which means fj(x) = −f1(x). Since the
j
difference between each consecutive fi can be zero or ±2,
this guarantees that at some point one of the fi’s (1 ≤ i ≤ j)
should be equal to zero.

1

In the above arguments we assumed n is an even number.
However, if n is an odd number, we can modify it to the
n + 1 problem by appending an extra 0 entry to the input
vector x. Since 0 has no effect on the results of XOR, the
above arguments still hold.

References

Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z.,
Citro, C., Corrado, G. S., Davis, A., Dean, J., Devin, M.,
Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard,
M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Lev-
enberg, J., Man´e, D., Monga, R., Moore, S., Murray, D.,
Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever,
I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan,
V., Vi´egas, F., Vinyals, O., Warden, P., Wattenberg, M.,
Wicke, M., Yu, Y., and Zheng, X. TensorFlow: Large-
scale machine learning on heterogeneous systems, 2015.
URL https://www.tensorflow.org/. Software
available from tensorﬂow.org.

Bader, S., Hitzler, P., and H¨olldobler, S. Connectionist
model generation: A ﬁrst-order approach. Neurocomput-
ing, 71(13-15):2420–2432, 2008.

Collobert, R. and Weston, J. A uniﬁed architecture for natu-
ral language processing: Deep neural networks with mul-
titask learning. In Proceedings of the 25th international
conference on Machine learning, pp. 160–167. ACM,
2008.

Cropper, A. and Muggleton, S. H. Logical minimisation of
meta-rules within meta-interpretive learning. In Inductive
Logic Programming, pp. 62–75. Springer, 2015.

Cropper, A. and Muggleton, S. H. Metagol system.
https://github.com/metagol/metagol, 2016. URL https:
//github.com/metagol/metagol.

Dahl, G. E., Yu, D., Deng, L., and Acero, A. Context-
dependent pre-trained deep neural networks for large-
vocabulary speech recognition. IEEE Transactions on
audio, speech, and language processing, 20(1):30–42,
2012.

Duch, W. K-separability. In International Conference on
Artiﬁcial Neural Networks, pp. 188–197. Springer, 2006.

Dzeroski, S. Inductive logic programming in a nutshell. In-
troduction to Statistical Relational Learning [16], 2007.

Evans, R. and Grefenstette, E. Learning explanatory rules
from noisy data. Journal of Artiﬁcial Intelligence Re-
search, 61:1–64, 2018.

Franc¸a, M. V., Zaverucha, G., and Garcez, A. S. d. Fast rela-
tional learning using bottom clause propositionalization
with artiﬁcial neural networks. Machine learning, 94(1):
81–104, 2014.

H¨olldobler, S., Kalinke, Y., and St¨orr, H.-P. Approximat-
ing the semantics of logic programs by recurrent neural
networks. Applied Intelligence, 11(1):45–58, 1999.

Iyoda, E. M., Nobuhara, H., and Hirota, K. A solution for the
n-bit parity problem using a single translated multiplica-
tive neuron. Neural Processing Letters, 18(3):233–238,
2003.

Kaiser, Ł. and Sutskever, I. Neural gpus learn algorithms.

arXiv preprint arXiv:1511.08228, 2015.

Kingma, D. P. and Ba, J. Adam: A method for stochastic

optimization. CoRR, abs/1412.6980, 2014.

Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet
classiﬁcation with deep convolutional neural networks.
In Advances in neural information processing systems,
pp. 1097–1105, 2012.

Minsky, M. and Papert, S. A. Perceptrons: An introduction

to computational geometry. MIT press, 2017.

Muggleton, S. and De Raedt, L. Inductive logic program-
ming: Theory and methods. The Journal of Logic Pro-
gramming, 19:629–679, 1994.

Payani, A. and Fekri, F. Decoding ldpc codes on binary
erasure channels using deep recurrent neural-logic layers.
In Turbo Codes and Iterative Information Processing
(ISTC), 2018 International Symposium On. IEEE, 2018.

Richardson, T. J., Shokrollahi, M. A., and Urbanke, R. L.
Design of capacity-approaching irregular low-density
parity-check codes. IEEE transactions on information
theory, 47(2):619–637, 2001.

Seraﬁni, L. and Garcez, A. d. Logic tensor networks: Deep
learning and logical reasoning from data and knowledge.
arXiv preprint arXiv:1606.04422, 2016.

Siegelmann, H. T. and Sontag, E. D. On the computational
power of neural nets. In Proceedings of the ﬁfth annual
workshop on Computational learning theory, pp. 440–
449. ACM, 1992.

Steinbach, B. and Kohut, R. Neural networks–a model of
boolean functions. In Boolean Problems, Proceedings of
the 5th International Workshop on Boolean Problems, pp.
223–240, 2002.

Learning Algorithms via Neural Logic Networks

Vinyals, O., Fortunato, M., and Jaitly, N. Pointer networks.
In Advances in Neural Information Processing Systems,
pp. 2692–2700, 2015.

Wasserman, P. D. Neural computing: theory and practice.

Van Nostrand Reinhold Co., 1989.

