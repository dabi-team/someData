1
2
0
2

p
e
S
8

]

R

I
.
s
c
[

2
v
8
6
9
0
0
.
9
0
1
2
:
v
i
X
r
a

Self-supervised Representation Learning for Trip Recommendation

Qiang Gao†* , Wei Wang†, Kunpeng Zhang§, Xin Yang†, Congcong Miao‡
†Southwestern University of Finance and Economics, Chengdu, China.
§University of Maryland, College park.
‡Tsinghua University, Beijing, China.
qianggao@swufe.edu.cn, wangwei1997@smail.swufe.edu.cn, kpzhang@umd.edu, yangxin@swufe.edu.cn,
mccmiao@163.com

Abstract

Trip recommendation is a signiﬁcant and engaging location-
based service that can help new tourists make more cus-
tomized travel plans. It often attempts to suggest a sequence
of points of interest (POIs) for a user who requests a person-
alized travel demand. Conventional methods either leverage
the heuristic algorithms (e.g., dynamic programming) or sta-
tistical analysis (e.g., Markov models) to search or rank a POI
sequence. These procedures may fail to capture the diversity
of human needs and transitional regularities. They even pro-
vide recommendations that deviate from tourists’ real travel
intention when the trip data is sparse. Although recent deep
recursive models (e.g., RNN) are capable of alleviating these
concerns, existing solutions hardly recognize the practical re-
ality, such as the diversity of tourist demands, uncertainties
in the trip generation, and the complex visiting preference.
Inspired by the advance in deep learning, we introduce a
novel self-supervised representation learning framework for
trip recommendation – SelfTrip, aiming at tackling the afore-
mentioned challenges. Speciﬁcally, we propose a two-step
contrastive learning mechanism concerning the POI represen-
tation, as well as trip representation. Furthermore, we present
four trip augmentation methods to capture the visiting uncer-
tainties in trip planning. We evaluate our SelfTrip on four
real-world datasets, and extensive results demonstrate the
promising gain compared with several cutting-edge bench-
marks, e.g., up to 4% and 10% improvements on Osaka re-
garding F1 and pair-F1.

1 Introduction
The ubiquitousness of GPS-integrated mobile devices and
the wide use of location-based services have enabled the
generation of massive volumes of geo-tagged data, which
offers unprecedented opportunities to explore human mov-
ing intentions and correspondingly conduct various down-
stream location-based applications, e.g. POI recommen-
dation (Yu et al. 2020), friend recommendation (Wu et al.
2019), trajectory classiﬁcation (Gao et al. 2017), and trip
to
recommendation (He, Qi, and Ramamohanarao 2019),
name a few. Especially, trip recommendation (a.k.a, itinerary
recommendation) has drawn widespread attention from re-
searchers and practitioners in recent years, aiming at sug-
gesting a sequence of point-of-interests (POIs) while meet-

*Corresponding Author(qianggao@swufe.edu.cn).

Preprint

ing a set of user-provided constraints (e.g., starting and end-
ing points, the number of POIs to be visited). Trip recom-
mendation is signiﬁcantly different from traditional route
planning in that the latter is usually to search for the shortest
or a minimum cost-based route. In contrast, trip recommen-
dation takes more into consideration the diversity and per-
sonalized needs of a POI sequence, which is also not con-
strained by the road network (Wang, Wu, and Zhao 2021).
Therefore, trip recommendation is a more challenging task
in location-based recommendation services.

A conventional solution for trip recommendation is to
employ an orienteering-based method to maximize the
user-speciﬁc query constraints, which is inspired by the
navigation operation. Speciﬁcally it mines and incorpo-
rates prior knowledge extracted from historical trips (e.g.,
the attractiveness of POIs and POI categories) to offer
a sequence of POIs via POI generation (Lim et al. 2015;
Chen, Ong, and Xie 2016; Taylor, Lim, and Chan 2018).
For example, (He, Qi, and Ramamohanarao 2019) uses an
integer linear programming to explore the exact optimal
trips. However, heuristic solutions usually either rely on the
local transitional distribution between POIs or only pursue
the shortest time budget, leading to the failure in respect of
estimating the conditional distribution of human transition
regularity, considering the diversity of human demands, and
exploiting the high-ordered relations. Complement to these,
human mobility actually contains many explicit and implicit
characteristics, e.g, the semantic proximity of POIs and the
spatial-temporal dependencies. In this aspect, another solu-
tion was to leverage deep representation learning methods
to explore the nature of human characteristics, e.g, context-
aware POI embedding (He, Qi, and Ramamohanarao 2019;
Ho and Lim 2021) and recursive trip modeling (Zhou et al.
2020a; Ho and Lim 2021; Gao et al. 2021). Under real
datasets, they have empirically demonstrated superior per-
formance over traditional methods, which inspires us to tap
the charm of deep representation learning to be competent
for trip recommendation.

However, trip recommendation is still facing several chal-
lenges, including: (1) The heterogeneity of user demands:
Due to the diversity of travel plans requested by users, it
is impossible for us to perceive or grasp the needs of all
users. The reality is often that we only observe partial query
records and their corresponding trips. (2) The uncertainty

 
 
 
 
 
 
in trips: Although we can provide tourists with a deﬁnite
travel route according to a given query, it is difﬁcult for us
to understand user’s underlying true travel preference based
on a small amount of available trip data, as well as the het-
erogeneity of individual preferences, which brings the risk
of uncertainty during trip recommendation. (3) The complex
visiting patterns: Due to the data sparsity issue, it is intri-
cate to explore the higher-ordered transitional regularities,
especially the long-term dependencies.

Recent self-supervised learning techniques, e.g., con-
trastive learning, have achieved considerable success for
deep representation learning in natural language process-
ing, computer vision, and recommender systems (Liu et al.
2021). They are capable of discovering implicit supervised
signals together with multiple versions of data augmentation
strategies for promoting representation learning. Motivated
by this, we propose a novel self-supervised framework,
namely SelfTrip (Self-supervised Representation Learning
for Trip Recommendation), to remedy the aforementioned
concerns. In our SelfTrip, we design a novel POI represen-
tation learning module based on contrastive learning, where
a causal random walk strategy is proposed to enrich the di-
versity of query demands. To alleviate the uncertainties in
trip data, we leverage four trip data augmentation methods
to stimulate human travel behaviors, whereafter a contrastive
trip presentation learning module is proposed. Finally, we
model the trip data with a conditional (query-based) recur-
sive module for trip generation, where a destination-enabled
supervised signal regarding the trip destination is incorpo-
rated to constrain POI generation bias. In summary, our
work make the following contributions:

• To the best of our knowledge, SelfTrip is among the ﬁrst
framework to respectively improve the representation of
POI and human mobility with two contrastive learning
schemes.

• We investigate the complex interactions between queries
and potentially visiting POIs on a huge query-based POI
sequence set. Accordingly, the self-supervised POI learn-
ing is proposed to formulate the context-aware POI rep-
resentation.

• We design four data augmentation strategies to mimic
human travel behaviors based on the sparse trip data. In
the sequel, we present a self-supervised trip learning to
enhance the trip inference, where we also incorporate
a destination-enabled supervised signal to constrain the
POI prediction.

• Experimental

results conducted on four

real-world
datasets demonstrate that our SelfTrip signiﬁcantly out-
performs several cutting-edge benchmarks.

where id, lo and la represent the POI id, longitude and lati-
tude, respectively. Formally, a trip is a POI sequence ordered
by check-in time, e.g., < l1, t1 >→< l2, t2 >→ · · · →<
lm, tm >, where < l∗, t∗ > denotes a POI l∗ in a trip was
visited at time t∗.

Deﬁnition 2: Query. In this study, a query q is a quintu-
ple < ls, ts, ld, td, N > that consists of the source POI ls,
starting time ts, the destination POI ld, ending time td, and
the number of POIs N to visit.

Trip Recommendation. Given historical trips T , the
trip recommendation system can return a trip T =
(l1, l2, · · · , lN ) if a tourist provides a query q
:<
ls, ts, ld, td, N >, where ls = l1 and ld = lN . It can be
formally described as follows:

˜T = arg max

θ

P(T |q, T ).

(1)

Contrastive Loss. As a widely used technique in self-
supervised learning, contrastive learning aims to con-
struct positive samples and negative samples based on
the original data, which makes similar samples closer in
the projection space while dissimilar samples are rela-
tively further away. Among which Noise Contrastive Es-
timation (NCE) becomes very popular in various ap-
plications (Oord, Li, and Vinyals 2018; Yan et al. 2021;
Aitchison 2021). Its overall objective is deﬁned as:

JNCE = E





log 


eg(x)
eg(x)⊤ g(x+) +

⊤

g(x+)
j=1 eg(x)⊤g(x

J

P

−
j )









, (2)

where x refers to the ‘anchor’, x+ and x− respectively rep-
resent the positive and negative sample. g and J respectively
denote the learning function (e.g., deep neural networks) and
the number of negative samples.

3 Methodology
We turn to introduce our proposed SelfTrip. First, we present
an overview of the architecture design, whereafter elaborat-
ing the POI learning and trip learning procedures. Finally,
we describe the training details of SelfTrip.

(I)

Contrastive Learning

POI graph

Positive

Negative

Query

Submit

Suggest

Contrastive Learning

Positive

Negative

Augmented POI sequences

GRU

GRU

GRU

GRU

GRU

Trip augmentation

Embedding

(II)

2 Preliminaries
In this section, we introduce basic deﬁnitions and the prob-
lem formulation. We also present the contrastive loss used
later in our SelfTrip.

Deﬁnition 1: Trip. Let L denote a set of POIs and T rep-
resent a set of historical trips. Without loss of generality, we
use a triplet l :< id, lo, la > to represent a POI l ∈ L,

Figure 1: The overview of the SelfTrip framework.

Architecture
As Fig.1 shows, SelfTrip mainly contains two components:
(I) Self-supervised POI Learning aims to embed each POI
into a low-dimensional space. This is an essential action for

trip recommendation, which not only mitigates the prob-
lem of the curse of dimensionality but also is capable of
exploring the semantic relationships between queries and
POIs. (II) Self-supervised Trip Learning ﬁrst formulates
a context-aware query vector, and then randomly selects de-
signed trip augmentation methods to generate variants of an
original trip. Next we present a query-based GRU (Gated
Recurrent Unit) as the basic encoder for contrastive learn-
ing. Besides, we use this encoder as the trip generator in the
formal training process.

Self-supervised POI Learning
The intuitive idea of trip recommendation is to use a query
provided by a user to search out a sequence of POIs, thus
we expect to design such an embedding module that can
preserve interactions between the query and POIs as much
as possible. However, it is not easy to full capture their in-
teractions due to the scale of the training dataset and the
sparsity of query records. To this end, we ﬁrst construct a
POI graph to describe the interactions among POIs. Then
we adopt a simple interaction augmentation strategy to inte-
grate potential geographical preferences of tourists. To ob-
tain more possible queries, we propose a novel query-based
sampling approach to produce more reasonable trips from
the constructed POI graph. In the end, we present a con-
trastive POI learning method to learn possible interactions
between queries and POIs.

Augmented POI graph. To extract query-POI interac-
tions, we transform historical trips into a basic POI graph
Ga(L, E), where E denotes a set of edges reﬂecting the
successive visiting behaviors. To incorporate potential geo-
graphical preferences of tourists, we collect each POI’s geo-
graphical neighbors by setting a distance threshold, and cor-
respondingly building an edge between this POI and all of
its geographical neighbors that are within this threshold. To
constrain the scale of neighbors, we set the distance thresh-
old to 3 km. Finally, we obtain an augmented POI graph
Ga(L, Ea), where E $ Ea.

Causal Random Walks. Before we sample trips from Ga,
we create a transition matrix A to describe the interaction
probability between pairs of POIs (we actually refer to such
two POIs as the source POI and destination POI) accord-
ing to Ga. More speciﬁcally, given any two nodes li and
lj, (li ∈ L, lj ∈ L), the transition probability from li to lj is
calculated by:

P (lj|li) = fij /fi.

(3)

Where fij denotes the frequency of edge li → lj appeared
in Ea, and fi is the frequency of li appeared in Ea. Thus,
we ﬁnally obtain the transition matrix A corresponding to
Ga(L, Ea). Next, we use the causal random walk strategy to
generate a set of POI sequences based on Ga and A. There
exist L POIs in T , thereby we traverse all unique POI pairs
(e.g., < li, lj >) from the graph Ga and obtain a set of query
candidates Q = {< li, lj > |i 6= j, li ∈ L, lj ∈ L}. Actu-
ally, there exist at most |T | queries when and only when the
query of each trip in T is different, meanwhile, we usually
confront |T | ≪ |Q| due to the shortage of training data.

Thus, we use Ga and A to generate M POI sequences cor-
responding to each query candidate in Q, which enables to
alleviate the lack of query records in given trip data.

More speciﬁcally, given a query < li, lj > (< li, lj >∈
Q), we simulate a random walk with a length budget α. Let
ℓκ = (κ ≥ 1) be the κth node in a walk, where we set ℓ0=li.
Correspondingly, node ℓκ is generated by the distribution
P (ℓκ|ℓκ−1), where P (ℓκ|ℓκ−1) ∈ A. Once ℓκ = lj and κ ≤
α, we store the generated POI sequence {ℓ0, ℓ1, · · · , ℓκ} and
proceed to the next walk. If ℓ1 = lj or κ ≥ α, we will drop
the current POI sequence and proceed to the next walk di-
rectly. The reason we set a length budget α is that people
cannot have enough time to take a long trip or it is unreal-
istic to generate a long trip for the tourist to visit. Due to
the constraint of α, the generated POI sequences will have
different lengths, which, to some extent, allows us to cater
to the real scenarios of visiting behaviors. In the end, we
will collect a larger set of POI sequence S, and use it as the
training set for the following POI representation learning.

Contrative POI Learning. We now use the contrastive
learning to train the POI representation for capturing the
potential interactions between queries and POIs. And we
expect to maximize the similarity between a given query
and the POI sampled in the same POI sequence while min-
imizing the similarity between a given query and the POI
sampled from a different sequence. Given a POI sequence
S′ = {l1, l2, · · · , lN } sampled from S, we set up a learnable
matrix v ∈ R|L|×d as the initial POI embeddings, where d
denotes the embedding size. Next, we set l1 as the source
POI and lN as the destination POI, and using a simple av-
eraging operation to formulate a query representation qS′ ,
where qS′ = 1
2 (v′(l1) + v′(lN )) (v′ ∈ R|L|×d refers to
the leanable matrix corresponding to user query). We regard
qS′ as the ‘anchor’ and randomly select a POI l in S′ as the
positive sample while randomly select a POI l′ from another
sequence as the negative sample in which it is associated
with a query that is distinct from qS′ . For simplicity, let qS′
denote the original pair (l1, lN ). Recall Eq.(2), we randomly
sample k − 1 negative samples to cater to the training re-
j ∈ S \ S′}k−1
quirements of contrastive learning, i.e., {l′
.
Therefore, the objective for trip S′ is:

j|l′

1

J(qS′ ) =

(4)

El∈S′\qS′ [s (v(l), qS′ ) − log

k−1

X
j=1

exp(s

v(l′
(cid:0)

j), qS′ ))

,

(cid:3)

where ‘\’ deﬁnes subtraction operation of set and s refers
to the cosine function. Finally, we use the optimal v as the
POI embeddings.

Self-supervised Trip Learning
In this section, we ﬁrst show how to formulate a dense query
representation and trip representation. Then, we present four
trip augmentation strategies for sparse trips and describe
how to train our trip representation with contrastive learning.
In the end, we introduce the training mechanism of SelfTrip.

Query Encoder. To accommodate the input of our Self-
Trip, it is necessary to transform a given query q :<
ls, ts, ld, td, N > into a couple of dense representations.

Hence, we ﬁrst encode the source POI and destination POI in
the query into dense representations. Since we have trained
the POI embeddings v from the above, we can directly use
it to obtain the corresponding dense representations for ls
and ld, whereas they can be deﬁned as v(ls) and v(ld).
Inspired by previous works on time information process-
ing (Gao et al. 2021), an hour-level representation strategy
is adopted to encode ts and td, which splits the day into 24
discrete time intervals and uses simplest one-hot encoding
method to represent the 24 hour-level intervals. For exam-
ple, a tourist whose ending time td can be represented as
u(td) ∈ Rd′

, where d′ is the embedding dimension.
Traditional methods usually use a simple concatenation
operation to mingle those dense representations into an uni-
ﬁed vector to represent the given query q. To capture the
interactions of ls, ts, ld, and td, we design a transformed
operation to obtain a ﬁnal representation for query q:

q = LeakyRelu([v(ld)ku(td)] X([v(ls)ku(ts)]Kq) (5)

+[v(ls)ku(ts)kv(ld)ku(td)]Wq + bq).

′

′

′′

)×d

Where k denotes the concatenation operation, Wq ∈
R2(d+d′
is a learnable matrix, bq ∈ Rd′′
)×d′′
is the bias, and
Kq ∈ R(d+d

is a third-order tensor.

)×(d+d

Trip Encoder. We now introduce how to model a given
query q and its associated trip T by a query-based recur-
rent neural network. That is to say, we aim to incorporate
the query information into the trip representation in a recur-
sive manner. We ﬁrst obtain the context-aware q to repre-
sent the given q. For trip T = {l1, l2, · · · , lN }, we trans-
form each discrete POI to dense representation by looking
up the optimized v, and obtain the basic trip representa-
tion T = {v(l1), v(l2), · · · , v(lN )}. Next, we employ the
query-based GRU to capture the dependencies among the
POIs in T . Taking lτ ∈ T as an example, its hidden state
can be formulated as:

hτ = GRU([v(lτ )kf (q)], hτ −1),

(6)

where f (·) denotes a dense layer. In the end, we can obtain
the hidden state of each POI, i.e., h1, · · · , hN .

Trip Augmentation. As a prerequisite, trip representation
with self-supervised learning needs to set multi-views of real
training trips as the positive samples. Inspired by recent con-
trastive text generation (Yan et al. 2021) and contrastive item
augmentation (Zhou et al. 2020b). We present four strategies
for trip data augmentation which aims to mimic the human
real visiting behaviors. They are:
• POI Mask. It is a simple but realistic strategy. For in-
stance, the tourist Bob would choose some of POIs to
visit although we provide him a longer trip. Thus, we
randomly mask some POIs in a given POI sequence to
generate a new trip.

• Shufﬂing. Although we provide the tourist with a possi-
ble itinerary, he/she may change their visiting plan dur-
ing travelling due to the personal interests. For instance,
SelfTrip provides an itinerary < A, B, C > for tourist
Bob, when Bob prepares to visit B after visiting A, he
may decide to visit C ﬁrst because he considers C more

attractive to him or C is an urgent need. To simulate the
realistic human moving intention, we change the order of
a given sequence of POIs to form a new trip and add it to
our training set.

• Feature Cutoff. Since we use the dense representation to
tackle the discrete POI or trip, the feature cutoff attempts
to erase some feature dimensions to generate an augmen-
tation view of input data. To be speciﬁc, it only applies
to the POI embeddings before we model trip learning.
• Dropout. Dropout is a widely used approach to allevi-
ate the over-ﬁtting issue during neural network model-
ing (Hinton et al. 2012). Hence, we use it to randomly
drop part of values out in each POI embedding by a cer-
tain probability (e.g., the dropout rate is 0.5) and set each
corresponding value to zero.

To accommodate the following contrastive trip learning, we
feed each trip T in T into the augmentation layer and ran-
domly select two strategies for augmentation. For example,
using the augmentation layer to generate two views of T,
denoted as ˆTp and ˆTq.

i }m
i and ˆTq

Contrastive Trip Learning. Notably, using larger mini-
batch is a common method for contrastive learning, we
thus choose m queries {qi}m
i=1 and their corresponding trips
{Ti}m
i=1 from the training set to satisfy the requirement of
mini-batch. Next, we use trip augmentation layer to gen-
i=1 and { ˆTq
erate the augmented trip set { ˆTp
i }m
i=1, where
each Ti is associated with ˆTp
i . Correspondingly, we
can obtain the context-aware query set {qi}m
i=1 by Eq. (5).
As for augmented trips, we use the Trip Encoder to obtain
the hidden states of these trips, and employ the ﬁnal state of
each augmented trip as input of contrastive learning. For in-
stance, we respectively use hp
i to represent the ﬁnal
states of ˆTp
i and ˆTq
i , and use them to represent these two
trips, denoted by ˜Tp
i and ˜Tq
i for consistency. Similarly, we
can formulate the dense representations of other augmented
trips, denoted by { ˜Tp
i=1 and { ˜Tq
i }m
i=1. Now, we can treat
any < ˜Tp
i , ˜Tq
i > as the positive pair, while regarding the
remain (m − 1) pairs as the negative. Thus, the objective
regarding Ti can be deﬁned as:

i and hq

i }m

J(i) = log

exp(s( ˜Tp

i , ˜Tq

exp(s( ˜Tp
m

i , ˜Tq

i ))
j=1,j6=i exp(s( ˜Tp

i )) +

i , ˜Tq

j ))

(7)

P

In practical implementation, we can train the trips {Ti}m
i=1
in a parallel manner by:

L{Ti}m

1 = −

X

I ⊙ log softmax(

˜Tp
1
· · ·
˜Tp
i
· · ·
˜Tp
m









⊤









˜Tq
1
· · ·
˜Tq
i
· · ·
˜Tq
m











) (8)







where I is the identity matrix (denoting the elements in di-
agonal are positive scores while others are negative scores)
and ⊙ denotes the element-wise Hadamard product. In the
end, the overall loss function is:

Lself = −

m×|T |

J(i)

X
i=1

(9)

In the sequel, we will use the warmed-up Query Encoder and
Trip Encoder for the following formal training.

Query

MLP

MLP

q

GRU

GRU

GRU

GRU

GRU

Figure 2: Trip generation with destination-enabled signals

Formal Training
We have used the self-supervised learning to embed each
discrete POI to a low-dimensional vector, where the cor-
relations among the query and POIs are incorporated. And
we also used the self-supervised learning to pre-train model
with contrastive loss. Now we turn towards using the
warmed-up model for supervised trip training. Recall the ob-
jective of Eq.(1), SelfTrip is to generate the trip in a recursive
manner as follows:

˜lτ = GRU([v(lτ −1)kf (q)], hτ −1)Wf + bf ,

(10)

where Wf and bf are the learnable parameters. Traditionally,
we can form the ﬁnal objective as:

Lsup(θ) = −

|T |

X
i=1

log p (Ti | q) ,

(11)

where θ refers to the parameters in SelfTrip. However, trip
recommendation is signiﬁcantly different from traditional
trajectory prediction tasks in that the latter works in a multi-
round next POI generation manner (Zhou et al. 2019). Ac-
tually, we usually neglect a supervised signal that each pre-
dicted POI is also constrained by the destination. Although
such a constraint or interaction is unknown, we attempt to
use a simple neural network (i.e., fully connected neural net-
work) to stimulate such unknown interaction between the
predicted POI and the destination. As Fig. 2 shows, we in-
volve a destination-oriented signal to constrain the trip gen-
eration during the model training process. For a given query
q :< ls, ts, ld, td, N >, we assume that we have obtained a
current hidden state hτ . Then we use a one-layer fully con-
nected neural network to build the relationship between hτ
and the destination by:

˜ld = softmax (hτ W ′ + b′) ,
where W ′ and b′ refer to the learnable parameters. Thus, we
rewrite the Eq.(11) as:

(12)

L(θ, γ) = Lsup(θ) + Ldest(θ, γ) =

(13)

|T |

N

X
1

(log p(lτ | hτ −1, q) + log p′(ld | hτ −1, q)),

X
τ =1

where γ refers to W ′ and b′. Notably, the length N in query
q will be considered as recursive rounds.

4 Evaluation
We conduct experiments on four real-world datasets to
demonstrate the effectiveness of our SelfTrip. In detail, we

ﬁrst introduce the datasets, benchmarking algorithms and
evaluation metrics, followed by the model settings. Then, we
present our results including overall performance compari-
son, the performance of individual module, study of query
and trip augmentation, and parameter sensitivity.

Dataset, Benchmark and Metrics
Datasets. As Table 1 shows, we use four real-world trip
datasets, including Toronto, Osaka, Glasgow, and Edin-
burgh, from Flickr as our experimental data, which have
been widely used in prior studies (Chen, Ong, and Xie
2016; He, Qi, and Ramamohanarao 2019; Gao et al. 2021).
To improve the quality of data, we do some regular
data prepossessing, including ﬁltering out short trajecto-
ries which contain less than three POIs, normalizing the
timestamp into hour-level (i.e., mapping each timestamp
into 24 intervals). Following (Chen, Ong, and Xie 2016;
He, Qi, and Ramamohanarao 2019; Gao et al. 2021), we
also adopt leave-one-out cross validation to evaluate all
methods.

Table 1: Descriptive statistics of datasets
Φ(User)
City
Edinburgh
1,454
Glasgow
601
Osaka
450
Toronto
1,395

Φ(Trajectory)
5,028
2,227
1,115
6,057

Φ(Visits)
33,944
11,434
7,747
39,419

Benchmarks. We compare our SelfTrip with several re-
cently developed representation learning-based methods, in-
cluding:

• Markov (Chen, Ong, and Xie 2016): It is a common and
intuitive method where a POI transition matrix is con-
structed to recommend a trajectory.

• POIRank (Chen, Ong, and Xie 2016): It recommends a
trajectory by ﬁrst ranking POIs via a RankSVM method,
and then connecting them based on their ranking scores.
• Markov-Rank (Chen, Ong, and Xie 2016): It constructs
a POI transition matrix, and recommends a trajectory
based on Markov transitions and POI ranking.

• CATHI (Zhou et al. 2019): It

is a recurrent neural
network-based trajectory planning method in an end-to-
end manner. We leverage an encoder to model the given
query and use the decoder for trip recommendation.

• C-ILP (He, Qi, and Ramamohanarao 2019):

It uses
word2vec-based method to learn context-aware POI rep-
resentation, followed by integer linear programming
(ILP) for trip generation.

• DeepTrip (Gao et al. 2021): It is an end-to-end trip rec-
ommendation method, while using a GAN-style neural
network to approximate the similarity between the query
and the trip.

• NASR+ (Wang, Wu, and Zhao 2021): It is a deep neu-
ral network-based A* algorithm for route planning con-
strained by the road network. Since the check-in data is
not constrained by the road network, we only use its RNN
module enhanced by the attention mechanism for a fair
comparison.

comparison
studies

performance
follow prior

Metrics. For
among
all
methods, we
(Lim et al. 2015;
to use two well-
He, Qi, and Ramamohanarao 2019)
established metrics: (i) F1 score to measure the quality of
a recommended sequence – which is, the harmonic mean
of Precision and Recall of elements in a sequence; (ii)
pairs-F1 score (Chen, Ong, and Xie 2016; Gao et al. 2021),
considers both POI correctness and sequential order by
calculating the F1 score of every pair of POIs, whether
they are adjacent or not in a trajectory. Notably, the values
of both pairs-F1 and F1 are between 0 and 1. The higher
the value, the better the recommended results, e.g., a value
of 1 means that both POIs and their visiting order in the
recommended trajectory are exactly the same as the ground
truth.

Experimental Settings. We reproduce the benchmarks
and implement our SelfTrip in Python while deep learning
methods are accelerated by one NIVDIA RTX 3090 GPU.
As for our SelfTrip, length budget α is 6, the batch size is 8,
the dimensionality of POI is 250, the initial learning rate is
0.1, the hidden size in contrastive trip representation is 256,
and the optimizer is Adam (Kingma and Ba 2014).

tion learning, which allows us to simulate possible human
query demands and trip preference.

Module Performance. To investigate the capability of
POI learning, we compare our self-supervised POI learn-
ing with four popular embedding methods, and they are:
(1) Random refers to the application of random ma-
trix sampled from Gaussian distribution for POI embed-
dings; (2) Deepwalk (Perozzi, Al-Rfou, and Skiena 2014)
uses random walk method to generate the POI sequences
on POI graph, and leverages word2vec to formulate the
POI embeddings; (3) GAE (Kipf and Welling 2016) uti-
lizes the graph autoencoder to generate node (POI) em-
beddings; (4) VGAE (Kipf and Welling 2016) is a variant
of GAE, integrating the variational Bayes mechanism. As
Fig. 3(a) shows, we observe that our method signiﬁcantly
outperforms these four embedding methods, and Deepwalk
achieves the second best. But Deepwalk is worse than Self-
Trip because it only focuses on the surrounding context of
a given POI. Note that we observe similar patterns for other
datasets and omit to report due to the space limitation.

Table 2: Overall performance comparison.
Glasgow

Edinburgh

Osaka

Toronto

Method

F1
0.645
Markov
POIRank
0.700
Markov-Rank 0.659
0.752
CATHI
0.760
C-ILP
0.765
DeepTrip
NASR+
0.755
0.783
SelfTrip

pairs-F1 F1

pairs-F1 F1

pairs-F1 F1

0.417
0.432
0.444
0.731
0.535
0.660
0.734
0.779

0.725
0.768
0.754
0.710
0.852
0.831
0.849
0.855

0.495
0.548
0.545
0.659
0.709
0.782
0.756
0.818

0.697
0.745
0.715
0.756
0.800
0.834
0.811
0.857

0.445
0.511
0.486
0.701
0.611
0.755
0.738
0.851

0.669
0.754
0.723
0.820
0.811
0.808
0.829
0.851

pairs-F1
0.407
0.518
0.512
0.782
0.623
0.748
0.803
0.835

Results
Overall Performance. Table 2 shows the performance
comparison of our SelfTrip with several representative
benchmarks. Note that we use the bold font to highlight the
best performance. Generally, our SelfTrip signiﬁcantly out-
performs all benchmarks across four datasets, with an av-
erage improvement of 2.03%, 6.85% over the best bench-
mark with respect to F1 and pairs-F1, respectively. Among
the benchmarks including Markov, POIRank and Markov-
Rank, the results demonstrate that investigating explicit
knowledge, e.g., the human transition regularity and POI
co-occurrences, do help in understanding human mobility.
However, those methods that either statistically model POI
transitions with Markov chain or learn a ranking of POIs
with traditional machine learning methods (e.g., RankSVM)
cannot automatically explore more complex mobility regu-
larity and handle the data sparsity issue, resulting in an un-
satisfactory performance for trip recommendation. In par-
ticular, they perform worse than these recent deep repre-
sentation learning-based methods, such as DeepTrip and
NASR+. As for SelfTrip, it performs the best, the plausi-
ble reason is that the trip augmentation can address the data
sparsity problem and consider the heterogeneity of user de-
mands during POI embedding and trip representation learn-
ing. Meanwhile, we investigate the inherent interactions be-
tween queries and POIs as the prerequisites for representa-

(a) POI learning.

(b) Trip learning.

Figure 3: Ablation study on Glasgow.

To explore the impact of query encoder, contrastive trip
learning and the destination-enabled supervised signal. We
provide four variants of SelfTrip. The ﬁrst one is a base
model which removes the above three parts and uses a
simple concatenation operation for query encoding, called
SelfTrip-Base;
the second one removes the contrastive
learning component in SelfTrip, namely SelfTrip-CL; the
third one removes the destination-enabled supervised sig-
nal, called SelfTrip-WL, and the last one uses a simple con-
catenation operation for query encoding, called SelfTrip-Q.
As Fig. 3(b) shows, SelfTrip performs the best. We ﬁnd that
these three components do help promote performance gains,
which further indicates that the sparsity of trip data, the po-
tential destination correlation and query context are impor-
tant factors in trip recommendation.

Impact of Augmentation. Query Augmentation. In this
paper, we propose causal random walks to augment the
query records. Whether such a method improves the recom-
mendation performance is still a question, especially when
the user provides a query demand that never appears be-
fore. To answer this question, we re-split each dataset to
new training data (about 80%) and new testing data (about
20%) where queries in testing data do not appear in the train-
ing data. As Table 3 shows, SelfTrip- denotes without using
the augmented queries in SelfTrip. The results demonstrate
that query augmentation signiﬁcantly achieves encouraging
gains, especially for the F1 scores regarding Osaka.

Table 3: Performance comparison.

Edinburgh

Glasgow

Osaka

Toronto

Method

F1

pairs-F1 F1

pairs-F1 F1

pairs-F1 F1

SelfTrip- 0.593
SelfTrip 0.613

0.418
0.408

0.729
0.755

0.489
0.552

0.669
0.694

0.400
0.567

0.665
0.677

pairsF1
0.428
0.426

Trip Augmentation. To evaluate the effect of trip augmen-
tation methods, we empirically show the testing results with
different couples of trip augmentation. As Fig 4 shows, each
cell represents a different couple, where the diagonal means
that we only use a single strategy and ‘None’ means we do
not use any augmentation methods. We observe that single
augmentation method obtains the worse performance while
dropout and POI mask are more efﬁcient in trip augmenta-
tion. Therefore, we will endeavor to choose more efﬁcient
coupling and explore more augmentation methods for data
augmentation in the future.

(a) Osaka.

(b) Glasgow.

Figure 4: F1 score in different trip augmentations
Sensitivity of Hyper-parameters. As Fig 5 shows, we in-
vestigate the sensitivity of some key hyper-parameters, e.g.,
hidden size and the number of negative samples in trip learn-
ing.

(a) Hidden size.
Figure 5: Hyper-parameter tuning on Toronto.

(b) #Negative samples

5 Related Work
Trip Recommendation. Conventionally, one of the com-
mon solutions for trip recommendation is using the simple
heuristic models to understand the transitional patterns of
different POIs. Chen et al. proposed a probabilistic method
by mining the implied information (e.g., transitional matrix)
from historical POIs and trips (Chen, Ong, and Xie 2016).
Gu et al. investigated the attractive routes to make a trip rec-
ommendation considering user experience, where a gravity
model is leveraged to evaluate the rating score of each attrac-
tive route (Gu et al. 2020). In addition to these, other exist-
ing works considered the trip recommendation as a variant
of the orienteering problems (OP), maximizing the collected
scores from the generated path (Taylor, Lim, and Chan
2018; He, Qi, and Ramamohanarao 2019). However, they
are not good at estimating user diverse demands and his-
torical travel preferences with the limit of data scale, re-

sulting in the inability to learn the real distribution of hu-
man travel patterns. Recent researchers used deep represen-
tation learning to explore complex relations from POIs and
trips, such as semantic proximity of POIs and long-term
dependencies in trips (He, Qi, and Ramamohanarao 2019;
Ho and Lim 2021; Gao et al. 2021). He et al. and Ho et
al. adopted the popular POI embedding method for trip
recommendation, modeling the probability distribution of
the co-occurring POIs (He, Qi, and Ramamohanarao 2019;
Ho and Lim 2021). DeepTrip is a regularized latent vari-
able method to understand human travel patterns, leveraging
a trained model for trip recommendation (Gao et al. 2021).
Although the success of deep representation learning, those
methods only relied on historical trips, which still suffer the
sparsity and insufﬁcient representation issues. In contrast,
SelfTrip is a self-supervised framework with data augmenta-
tion that can better alleviate the sparsity of queries and trips.

Self-supervised Representation Learning Recent self-
supervised learning, which has shown excellent perfor-
mance in representation learning, brings a new opportunity
to address the limit of labeled data scale due to its capa-
bility of avoiding the work of tagging large-scale datasets.
And it generally can be categorized into two domains, i.e.,
generative-based and contrastive-based (Wu et al. 2020).
For example, variational Bayesian and adversarial network
attract numerous researchers’ attention since they can self-
train with the whole data without any label information.
Generative-based methods have been widely applied in
mobility-based tasks (Liu et al. 2020; Wang et al. 2019), in-
cluding trip recommendation (Gao et al. 2021). However,
generative-based approaches need to reconstruct accurate lo-
cal details to learn sample features, while the emerging con-
trastive learning focuses on implicit multi-views of samples
and construct an additional contrastive loss to distill inherent
information from the data itself by mutual information max-
imization principle (He et al. 2020; Oord, Li, and Vinyals
2018; Xie et al. 2021). Although the emerging application of
contrastive learning has been widely used in CV and NLP,
our self-supervised learning framework is among the ﬁrst
work to capture implicit supervised signals from both POI-
level and trip-level, which distinguishes from previous stud-
ies.

6 Conclusion and Future Work

In this paper, we present a systematic self-supervised learn-
ing framework to train the POI representation and trip rep-
resentation for trip recommendation, where a novel model
SelfTrip is proposed. We implement a self-supervised learn-
ing with data augmentation including query augmentation
and trip augmentation to capture the inherent interactions
between queries and trips. The empirical results demonstrate
that our SelfTrip achieves the best performance. Besides, our
proposed self-supervised POI learning signiﬁcantly outper-
forms existing widely used embedding methods. In the fu-
ture, we consider incorporating other features (e.g., social
characteristics) to explore human diverse preference.

Taylor, K.; Lim, K. H.; and Chan, J. 2018. Travel itinerary
recommendations with must-see points-of-interest. In Com-
panion Proceedings of the The Web Conference 2018, 1198–
1205.
Wang, J.; Wu, N.; and Zhao, X. 2021.
Personalized
Route Recommendation with Neural Network Enhanced A*
IEEE Transactions on Knowledge and
Search Algorithm.
Data Engineering.
Wang, P.; Fu, Y.; Xiong, H.; and Li, X. 2019. Adversarial
substructured representation learning for mobile user proﬁl-
ing. In Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining, 130–
138.
Wu, J.; Wang, X.; Feng, F.; He, X.; Chen, L.; Lian, J.; and
Xie, X. 2020. Self-supervised Graph Learning for Recom-
mendation. arXiv preprint arXiv:2010.10783.
Wu, Y.; Lian, D.; Jin, S.; and Chen, E. 2019. Graph Convo-
lutional Networks on User Mobility Heterogeneous Graphs
for Social Relationship Inference. In IJCAI, 3898–3904.
Xie, Z.; Liu, C.; Zhang, Y.; Lu, H.; Wang, D.; and Ding, Y.
2021. Adversarial and Contrastive Variational Autoencoder
for Sequential Recommendation. In Proceedings of the Web
Conference 2021, 449–459.
Yan, Y.; Li, R.; Wang, S.; Zhang, F.; Wu, W.; and
Xu, W. 2021. ConSERT: A Contrastive Framework for
Self-Supervised Sentence Representation Transfer. arXiv
preprint arXiv:2105.11741.
Yu, F.; Cui, L.; Guo, W.; Lu, X.; Li, Q.; and Lu, H. 2020. A
category-aware deep model for successive poi recommen-
dation on sparse check-in data. In Proceedings of the web
conference 2020, 1264–1274.
Zhou, F.; Wu, H.; Trajcevski, G.; Khokhar, A.; and Zhang,
K. 2020a. Semi-supervised Trajectory Understanding with
POI Attention for End-to-End Trip Recommendation. ACM
Transactions on Spatial Algorithms and Systems (TSAS),
6(2): 1–25.
Zhou, F.; Yue, X.; Trajcevski, G.; Zhong, T.; and Zhang, K.
2019. Context-aware variational trajectory encoding and hu-
man mobility inference. In The World Wide Web Conference,
3469–3475.
Zhou, K.; Wang, H.; Zhao, W. X.; Zhu, Y.; Wang, S.; Zhang,
F.; Wang, Z.; and Wen, J.-R. 2020b. S3-rec: Self-supervised
learning for sequential recommendation with mutual infor-
mation maximization. In Proceedings of the 29th ACM In-
ternational Conference on Information & Knowledge Man-
agement, 1893–1902.

References
Aitchison, L. 2021. InfoNCE is a variational autoencoder.
arXiv preprint arXiv:2107.02495.
Chen, D.; Ong, C. S.; and Xie, L. 2016. Learning points
and routes to recommend trajectories. In Proceedings of the
25th ACM International on Conference on Information and
Knowledge Management, 2227–2232.
Gao, Q.; Zhou, F.; Zhang, K.; Trajcevski, G.; Luo, X.; and
Zhang, F. 2017. Identifying human mobility via trajectory
embeddings. In IJCAI.
Gao, Q.; Zhou, F.; Zhang, K.; Zhang, F.; and Trajcevski, G.
2021. Adversarial Human Trajectory Learning for Trip Rec-
ommendation. IEEE Transactions on Neural Networks and
Learning Systems.
Gu, J.; Song, C.; Jiang, W.; Wang, X.; and Liu, M. 2020. En-
hancing Personalized Trip Recommendation with Attractive
Routes. In Proceedings of the AAAI Conference on Artiﬁcial
Intelligence, 01, 662–669.
He, J.; Qi, J.; and Ramamohanarao, K. 2019. A joint
In
context-aware embedding for trip recommendations.
2019 IEEE 35th International Conference on Data Engi-
neering (ICDE), 292–303. IEEE.
He, K.; Fan, H.; Wu, Y.; Xie, S.; and Girshick, R. 2020.
Momentum contrast for unsupervised visual representation
learning. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 9729–9738.
Hinton, G. E.; Srivastava, N.; Krizhevsky, A.; Sutskever, I.;
and Salakhutdinov, R. R. 2012. Improving neural networks
arXiv
by preventing co-adaptation of feature detectors.
preprint arXiv:1207.0580.
Ho, N. L.; and Lim, K. H. 2021. User Preferential Tour Rec-
ommendation Based on POI-Embedding Methods. In 26th
International Conference on Intelligent User Interfaces, 46–
48.
Kingma, D. P.; and Ba, J. 2014. Adam: A method for
stochastic optimization. arXiv preprint arXiv:1412.6980.
Kipf, T. N.; and Welling, M. 2016. Variational graph auto-
encoders. arXiv preprint arXiv:1611.07308.
Lim, K. H.; Chan, J.; Leckie, C.; and Karunasekera, S. 2015.
Personalized tour recommendation based on user interests
and points of interest visit durations. In IJCAI.
Liu, X.; Zhang, F.; Hou, Z.; Mian, L.; Wang, Z.; Zhang, J.;
and Tang, J. 2021. Self-supervised learning: Generative or
contrastive. IEEE Transactions on Knowledge and Data En-
gineering.
Liu, Y.; Zhao, K.; Cong, G.; and Bao, Z. 2020. On-
line anomalous trajectory detection with deep generative se-
quence modeling. In 2020 IEEE 36th International Confer-
ence on Data Engineering (ICDE), 949–960. IEEE.
Oord, A. v. d.; Li, Y.; and Vinyals, O. 2018. Representation
learning with contrastive predictive coding. arXiv preprint
arXiv:1807.03748.
Perozzi, B.; Al-Rfou, R.; and Skiena, S. 2014. Deepwalk:
Online learning of social representations. In Proceedings of
the 20th ACM SIGKDD international conference on Knowl-
edge discovery and data mining, 701–710.

