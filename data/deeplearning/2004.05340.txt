DNN-aided Read-voltage Threshold Optimization
for MLC Flash Memory with Finite Block Length

Cheng Wang, Kang Wei, Lingjun Kong, Long Shi, Zhen Mei, Jun Li, and Kui Cai

1

0
2
0
2

r
p
A
1
1

]
T
I
.
s
c
[

1
v
0
4
3
5
0
.
4
0
0
2
:
v
i
X
r
a

Abstract—The error correcting performance of multi-level-
cell (MLC) NAND ﬂash memory is closely related to the block
length of error correcting codes (ECCs) and log-likelihood-ratios
(LLRs) of the read-voltage thresholds. Driven by this issue,
this paper optimizes the read-voltage thresholds for MLC ﬂash
memory to improve the decoding performance of ECCs with
ﬁnite block length. First, through the analysis of channel coding
rate (CCR) and decoding error probability under ﬁnite block
length, we formulate the optimization problem of read-voltage
thresholds to minimize the maximum decoding error probability.
Second, we develop a cross iterative search (CIS) algorithm to
optimize read-voltage thresholds under the perfect knowledge of
ﬂash memory channel. However, it is challenging to analytically
characterize the voltage distribution under the effect of data
retention noise (DRN), since the data retention time (DRT) is
hard to be recorded for ﬂash memory in reality. To address
this problem, we develop a deep neural network (DNN) aided
optimization strategy to optimize the read-voltage thresholds,
where a multi-layer perception (MLP) network is employed to
learn the relationship between voltage distribution and read-
voltage thresholds. Simulation results show that, compared with
the existing schemes,
the proposed DNN-aided read-voltage
threshold optimization strategy with a well-designed LDPC code
can not only improve the program-and-erase (PE) endurance but
also reduce the read latency.

Index Terms—MLC NAND ﬂash memory, read-voltage thresh-

old, ﬁnite block length, LDPC codes, deep neural network.

I. INTRODUCTION

N AND ﬂash memory is widely used over the past decade

due to low power consumption and large storage capac-
ity. The original NAND ﬂash memory cell can only store one
bit with two levels, which is called single-level-cell (SLC).
Using the multi-level-cell (MLC) or triple-level cell (TLC)
technique [1]–[3], the ﬂash memory can store multiple bits
over a single memory cell. However, as the number of levels
in each memory cell
increases, serious scaling challenges
loom up in the NAND ﬂash memory, resulting in a negative
effect on the reliability. These challenges originate from the
characteristics of ﬂash devices that can be seen as several
noise models, such as programming noise (PN), cell-to-cell
interference (CCI), random telegraph noise (RTN), and data
retention noise (DRN) [4].

Among various noises in ﬂash memory, the DRN is caused
by the charge leakage at the ﬂoating-gate of ﬂash memory

C. Wang, K. Wei, and J. Li are with School of Electronic and Optical
Engineering, Nanjing University of Science and Technology, Nanjing, P.
R. China (e-mail:{cheng.wang, kang.wei, jun.li}@njust.edu.cn). L. Kong is
with College of Telecommunication and Information Engineering, Nanjing
University of Posts and Telecommunications, Nanjing, P. R. China (e-mail:
ljkong@njupt.edu.cn) L. Shi, Z. Mei, and K. Cai are with Science and Math
Cluster, Singapore University of Technology and Design, Singapore (e-mail:
slong1007@gmail.com, mei_zhen@outlook.com, cai_kui@sutd.edu.sg). .

cells [5]. The charge leakage starts when a ﬂash memory
cell is programmed. The overall period of this process is
called the data retention time (DRT). As the size of memory
chip decreases, the ﬂoating-gate of a ﬂash memory cell stores
much fewer electrons, which degrades the performance of
ﬂash memory. This is due to the fact that a small amount
of charge leakage has remarkable inﬂuence on the ﬂoating-
gate transistor. Compared with SLC, the MLC technology
intensiﬁes the decoding errors caused by the DRN, as the
reduced interval of write voltage at each storage state distorts
the voltage distribution of ﬂash memory. As a result,
the
increasing number of program-and-erase (PE) cycles and the
DRT limit the operational lifetime of ﬂash memory.

To improve the reliability of ﬂash memory, hard-decision
error correcting codes (ECCs), such as Bose-Chaudhri-
Hocquenghem (BCH) and Reed-Solomon (RS) codes were
employed in ﬂash memory [6], [7]. To enhance the decoding
error performance of ECCs, [8]–[11] proposed the utilization
of soft decision in ﬂash memory. Later on, various soft-
decision decoding algorithms were proposed to achieve de-
sirable error correcting performance. For example, the belief-
propagation (BP) algorithm is one of the probability-based
iterative decoding algorithms with excellent performance [12]–
[15]. It is well known that LDPC codes are decoded with
soft information such as channel log-likelihood-ratios (LLRs).
In order to achieve better error-correcting performance, the
soft-decision decoder demands more reliable and accurate soft
information that can be obtained by the read process [8],
[9], [16]–[18]. For the ﬂash memory channel, the problem of
obtaining soft information can be turned into that of optimizing
the read-voltage thresholds [16].

Driven by this observation, much effort has been put into
the optimization of read-voltage thresholds [8], [9], [16], [19],
[20]. The well-designed read-voltage thresholds can convert
hard information (i.e., voltages of cells) into soft information
(i.e., LLRs), which greatly improve the decoding performance
of ﬂash memory. Initially, ﬂash memory employed the hard-
decision memory sensing that utilizes the hard information
generated by the ﬁxed read-voltage thresholds. However, the
hard-decision method is only effective when the ﬂash memory
noise is small. To prolong the lifetime of ﬂash memory,
the soft read-voltage sensing strategy becomes a prevailing
solution for ﬂash memory. Prior works in [8], [16] introduced
a nonuniform memory sensing strategy to reduce the memory
sensing precision and read latency while maintaining good
error-correction performance. These works obtain the read-
voltage thresholds by utilizing entropy value of each unre-
liable region. Nevertheless, the optimization of read-voltage

 
 
 
 
 
 
thresholds relies on extensive simulations and the memory
sensing level is limited. To solve this dilemma, the work
in [9] developed an adjustable sensing strategy for multiple
reads of the same ﬂash memory cell, which selects the word-
line voltages by maximizing the mutual information (MMI)
between the input and output of the equivalent discrete read
channel.

However, the existing works have the following issues. First,
the aforementioned threshold optimization strategies did not
take into account the block length of ECCs that used in ﬂash
memory [8], [9], [16]. Notably, the block length of ECCs
for emerging memories are usually short due to stringent
requirements on low decoding complexity and read latency. In
practice, there is an signiﬁcant gap between the actual channel
coding rate (CCR) and capacity of the ﬂash memory model
in [16] under ﬁnite block length [21]. Recent research has
unveiled that the ﬂash memory channel after sensing by read-
voltage thresholds can be regarded as a discrete memoryless
channel (DMC) [9]. Several theoretical approaches investi-
gated the threshold optimization in DMC from the perspective
of information theory [22], [23]. Following these theoretical
approaches, we characterize the maximum coding rate in ﬂash
memory as a function of block length and error probability.
Building upon the rate analysis, we optimize the read-voltage
thresholds for ﬂash memory.

Second,

the prior works in [8], [9], [16] designed the
read-voltage thresholds for ﬂash memory assuming perfect
knowledge of PE cycles and DRT. In practice, it is rather
difﬁcult to record DRT. Without the knowledge of PE cycles
and DRT, the following methods were proposed to recover
the soft information of ﬂash memory channel under the effect
of the DRN. A ﬂash correct-and-refresh technique proposed
in [24] read the data stored in ﬂash memory periodically and
utilized the ECCs to perform the decoding and reprogramme
the ﬂash memory. Later on, [25] developed a decision-directed
estimation (DDE) algorithm to remit the DRN by utilizing a
Gaussian mixture model to estimate the voltage distribution
of ﬂash memory. The DDE algorithm ﬁrst compares the input
and output of the decoder to ﬁnd the best-ﬁt parameters of
the Gaussian model, and then utilizes the Gaussian model to
adjust the read-voltage thresholds. Recently, a retention-aware
belief-propagation (RABP) decoding scheme was proposed
to combat
the DRN in MLC ﬂash memory [26]. If the
decoding fails, the RABP algorithm adjusts the input LLRs
based on the decoded bits and performs another round of
decoding. Furthermore, [27] proposed a RABP aided chan-
nel update algorithm to estimate the voltage distribution of
MLC ﬂash memory. It regards voltage distribution of ﬂash
memory as Gaussian distribution and utilizes the decoding
results to update the mean and variance of voltage distribution.
However, the decoding processes in [24]–[27] result in either
large energy consumption or high decoding latency, which
contradicts with practical use of ﬂash memory. In addition,
these methods are applicable only when the DRN is within
a small certain range such that the decoder can still provide
sufﬁcient correct information. In this context, these methods
cannot handle the errors caused by the DRN that exceeds the
correction capability of ECCs.

2

Recently, rapid development of deep learning inspires us to
handle the variation of ﬂash memory channel caused by the
DRN. With an explosive increase in big data, the deep learning
technologies, such as deep neural network (DNN), can distill
the data effectively and extract abstract correlations from
data [28], [29]. For the ﬂash memory, in contrast to the existing
methods that require a round of decoding to obtain the useful
information, the DNN allows the system to train a model off-
line and explore the relationship between the input and output,
and the well-trained DNN model can directly generate the
information from the processed data. These ﬁndings motivate
us to design a DNN-aided read-voltage optimization strategy
that does not rely on the knowledge of DRT.

The primary goal of this paper is to optimize the read-
voltage thresholds in MLC ﬂash memory with ﬁnite ECC
block length. Towards this goal, we ﬁrst formulate the opti-
mization problem of read-voltage thresholds under ﬁnite block
length, and then propose the cross iterative searching (CIS) al-
gorithm and DNN-aided optimization strategy to optimize the
read-voltage thresholds, respectively. The main contributions
of this paper are summarized as follows:

•

•

Read-voltage threshold optimization under ﬁnite block
length—We study the CCR of MLC ﬂash memory under
ﬁnite block length and optimize the read-voltage thresh-
olds with perfect knowledge of PE cycles and DRT.
Under ﬁnite block length, we ﬁrst formulate the read-
voltage optimization problem to maximize the CCR by
minimizing the maximum error probability. Then, we
develop a CIS algorithm to solve this problem. Simulation
results show that, compared with MMI-based quantiza-
tion and entropy-based quantization, the proposed CIS
algorithm can signiﬁcantly improve the lifetime of ﬂash
memory.
DNN-aided read-voltage threshold optimization—We de-
velop a DNN-aided optimization strategy to optimize the
read-voltage thresholds without the knowledge of DRT.
The core of the proposed DNN-aided scheme is to train
a multi-layer perception (MLP) network to learn the
relationship between the voltage distribution (i.e., input of
the MLP) and the read-voltage thresholds (i.e., output of
the MLP). Simulation results show that, compared with
the RBAP decoding scheme, the DNN-aided scheme can
not only improve the PE endurance but also reduce the
read latency.

The remainder of this paper is organized as follows. Sec-
tion II presents the MLC ﬂash memory channel model and
investigates its CCR under ﬁnite block length. Section III
formulates the read-voltage thresholds optimization problem
under ﬁnite block length and proposes the CIS algorithm.
Section IV proposes the DNN-aided optimization strategy.
Section V shows the simulation results. Section VI concludes
this paper.

II. SYSTEM MODEL

A. Channel Model of MLC NAND Flash Memory

Let

denote the storage states of MLC
ﬂash memory. A ﬂash memory cell must be erased before

s0, s1, s2, s3}

=

S

{

programming. Let s0 denote the erased state of an MLC
ﬂash memory cell. With the reference to [16], the voltage
distribution of the cell at state s0 is approximately modeled
as a Gaussian distribution pe(v) =
e ) with mean
µe and standard deviation σe, respectively. In addition, let
s1, s2, and s3 denote the programmed states. Moreover, the
voltages at these programmed states are generated by using
an incremental step-pulse programming technique. Then, the
voltage distribution of the cell at each programmed state
follows a uniform distribution [30]:

(µe, σ2

N

ppsi

(v) =

1/Vp,
0,

(

[Vsi Vp)
v
elsewhere,

∈

i = 1, 2, 3,

(1)

where Vp denotes the programming step voltage and Vsi
denotes the target programmed voltage of si.

The MLC ﬂash memory channel is generally attenuated by
the PN, cell-to-cell interference (CCI), RTN and DRN [16],
[31], [32].

1) Programming Noise: Let npn denote the PN. The voltage
programming process is inﬂuenced by the PN, which can be
approximately modeled as a Gaussian distribution npn(v) =
pn) with zero mean and standard deviation σpn [33]. The
N
programming process does not change the voltage of erased
state, but only effects the voltage distributions of states s1, s2,
s3 [16].

(0, σ2

2) Cell-to-cell Interference: Let nc denote the CCI. As the
major noise source in the MLC ﬂash memory [16], [31], [34],
the CCI results from the scaling down of the ﬂash memory
chip, leading to a voltage shift VC among the cells:

VC =

∆Vjζj,

(2)

j
X
where ∆Vj represents the voltage variation of the j-th inter-
fering cell programmed after the victim cell, and ζj represents
the coupling coefﬁcient between the j-th interfering cell and
the victim cell. The effect of CCI can be estimated and the
pre-distortion/post-compensation technique can be employed
to mitigate the inﬂuence of CCI [32]. However, this technique
cannot eliminate the CCI’s effect on the erased state s0. Let
Vs0 denote the target voltage of the erased state. According
to [16], [32], the voltage distribution of the cell for even-
bit line and odd-bit line at the erased state is modeled by
(˜µeven
two Gaussian distributions, i.e., neven
, σ2
e ) and
e
nodd
e and different
c =
means:

e ), with the same variance σ2

(˜µodd
e

, σ2

N

N

=

c

3

(a)Without DRN

d

1

h

1

d
2

h

d
3

2

d
4

d

5

h

3

d

6

r

1

r

2

r

3

r

4

r

5

r

6

r

7

n
o
i
t
u
b

i
r
t
s
i
D
e
g
a
t
l
o
V

(b)With DRN

s

0

s

0

s

1

s

2

s

3

s

1

s

2

s

3

Voltage

Fig. 1. Voltage distribution and 6-level read quantization of an MLC ﬂash
memory.

(0, σ2

3) Random Telegraph Noise: Let nrtn denote the RTN. The
RTN can be approximately modeled as a Gaussian distribution
rtn) with zero mean and standard deviation
nrtn(v) =
σrtn, where σrtn varies with the number of program-and-
erase (PE) cycles in a power-law form [16]. From [27],
σrtn = 0.00027(NPE)0.64 with NPE being the number of PE
cycles.

N

Fig. 1 (a) illustrates the voltage distribution of an MLC ﬂash

memory cell under the effect of PN, CCI, and RTN.

(µrsi

4) Data Retention Noise: Let nd denote the DRN. The
DRN is approximated as a Gaussian distribution ndi (v) =
are the data-
N
dependent mean and standard deviation, respectively [16],
are time-varying and voltage-
[32]. Both µrsi
dependent:

), i = 0,1,2,3, where µrsi

and σrsi

and σrsi

, σ2
rsi

−
σrsi

µrsi

= log(1 + T )(Vi

V0)[β0(NPE)α0 + β1(NPE)α1 ],

(4a)

,

= 0.4

where T is the DRT, α0, α1, β0, and β1 are constants.

µrsi
(cid:12)
(cid:12)
Finally, the overall voltage distribution functions, calculated
by the convolution integral of initial voltage distribution func-
tions with various noise functions [27], are given by

(4b)

(cid:12)
(cid:12)

psi(v) =

(v−µsi )2
2σsi

e−

1
σsi √2π

, i = 0, 1, 2, 3,

(5)

where

µs0 = Vs0 −
e + σ2
σ2

σs0 =

µrs0

,

rtn + σ2
rs0

,

q
µsˆi = Vsˆi −
pn + σ2
σ2

Vp/2

µsˆi,

−
,ˆi = 1, 2, 3.

rtn + σ2
rsˆi

(6a)

(6b)

(6c)

(6d)

˜µeven
e = Vs0 + Vmean(2Kx + Ky + 2Kxy),

˜µodd
e = Vs0 + Vmean(Ky + Kxy),

(3a)

(3b)

σsˆi =

Vs0 ; ˜µeven

represent the
where Vmean = (Vs0 +Vs3)/2
variances of voltage for the even-bit line and odd-bit line cells,
respectively; Kx, Ky, and Kxy are the coupling coefﬁcients
of the ﬂoating gate in the horizontal, vertical, and diagonal
directions, respectively.

and ˜µodd

−

e

e

q

According to [27], the parameters of MLC ﬂash memory are
set as Vs0 = 1.4, Vs1 = 2.6, Vs1 = 3.2, Vs3 = 3.93, Vp = 0.2,
σe = 0.34, σpn = 0.05, β0 = 0.00001, β1 = 0.00008, α0 =
0.68, and α1 = 0.52, respectively. From (5), the increase of
either NPE or DRT changes the voltage distribution, which

 
4

,

(7)

psi(v)dv

region is calculated by

L(j, k) = log

dj

4

dj

i
dj−1
∈Qk
R
P
psi(v)dv

−

psi (v)dv

dj

dj−1
R

i
∈Qk
P

dj−1
R

i=1
P

where
Based on (7), we can obtain the LLR of each region.

k is the set of states each with the k-th bit being 1.

Q

The choice of read-voltage thresholds determines the LLRs,
thus has great impact on the ECC decoding performance.
Therefore, the goal of this paper is to maximize the read
reliability of MLC ﬂash memory by optimizing the read-
voltage thresholds.

C. CCR for Flash Memory Channel under Finite Block Length

A DMC comprises of an input set, output set, and a
probability transition matrix where the probability distribution
of the output depends only on the input at that time and
is conditionally independent of previous channel inputs or
outputs. Since the read process transforms storage states into
discrete region values, the ﬂash memory channel can be treated
as a DMC.
denote the DMC with transition proba-
Let W :
bilities W (rj
, where input si and output
∈ R
rj correspond to the storage state and quantization region,
respectively. The transition probability function of the voltage
region rj given input si is

S → R
si), si
|

∈ S

, rj

W (rj

|

si) = wrj ,si =

psi (v)dv

dj+1

= Q

dj
Z
µsi
−
σsi (cid:19)

dj

(cid:18)

Q

−

(cid:18)

µsi

dj+1 −
σsi

(cid:19)

,

(8)

where psi(v) is given in (5) and Q(ǫ) =
∞
ǫ
Moreover, the probability of output rj is given by

−t2
2 dt.

e

1
√2π

R

P (rj ) = prj =

psi wrj ,si

rj
X
∈R
Q

=

dj

psi

µsi
−
σsi (cid:19)
From (8) and (9), the mutual information between input si
and output rj is

dj+1 −
σsi

rj
X
∈R

µsi

(cid:19)(cid:21)

(9)

Q

−

(cid:18)

(cid:18)

(cid:20)

.

I (P, W ) =

P (si) W (rj

si
X

rj
∈S X
∈R

=

psiwrj ,si log

si) log

|
wrj ,si
prj

rj
∈S X
∈R
and the unconditional information variance is

si
X

W (rj

si)

|
P (rj )

,

(10)

U (P, W ) =

P (si) W (rj

si
X

rj
∈S X
∈R

=

psiwrj ,si

log

si
X

rj
∈S X
∈R

(cid:18)

si)

log

(cid:18)

|

W (rj

si)

|
P (rj)

2

(cid:19)

2

wrj ,si
prj (cid:19)

−

[I (P, W )]2 .

(11)

1

1

1

0

0

0

0

1

MSB

LSB

MSB
page

LSB
page

Fig. 2. Coding for MLC ﬂash memory.

causes the read errors and degrades the endurance of ﬂash
memory.

B. Read-voltage Quantization

For the MLC ﬂash memory, the relationship among the
block, cell wordline/bitline, and page is briefed as follows [34].
Each memory block contains multiple rows of cells. Each cell
stores K = 2 bits, i.e., the most signiﬁcant bit (MSB) and
least signiﬁcant bit (LSB). To reduce the raw bit error rate,
the Gray coding is used to map the 2 bits in each cell to one
of the storage states. As shown in Fig. 2, the storage states
s0, s1, s2, s3 correspond to the information bits 11, 10, 00, 01,
respectively. The MSBs of all cells on the same wordline are
combined to form an MSB page, and the LSBs of all cells on
the same wordline are combined to form an LSB page.

ECC is used to detect and correct

the raw bit errors
that occur within ﬂash memory. In this paper, we use two
independent length-N ECC to encode the input sequence of
the MSB and LSB pages as XM = (xM,1, xM,2, ...xM,N )
and XL = (xL,1, xL,2, ...xL,N ), respectively. During the write
process in the n-th cell, every K = 2 bits, i.e., (xM,n, xL,n) are
ﬁrst mapped to a storage state. Then, according to the storage
state of a memory cell, the programming operation shifts the
voltage of this cell to a well-designed write-voltage threshold.
During the read process, to transform the voltage value into
soft information (i.e., LLRs) for ECC decoding, the readback
voltages need to be quantized by comparing with precomputed
read thresholds.

D

=

d1, d2, . . . , dJ

Consider a voltage quantization strategy with J-level reads.
The read voltages of memory cells are quantized into J+1
collect J-level read-voltage
regions. Let
collect J+1 output
thresholds, and
regions where rj = [dj , dj+1] with d0 = 0 and dJ+1 = +
.
∞
In addition, the read-voltage thresholds of ﬂash memory cells
< dJ . Fig. 1 illustrates this
yield 0 < d1 < d2 <
, J and
quantization with 6-level read. For j = 1, 2,
, K, the initial LLR of the k-th bit in the j-th
k = 1, 2,

}
r0, r1, . . . , rJ

{
R

· · ·

· · ·

=

{

}

· · ·

As [21] unveiled, for a ﬁnite block length code and DMC,
the achievable CCR with a given error probability ǫ and a code
block length N yields

are used for these two pages. In the view of this independence,
the average maximum error probability for MLC ﬂash memory
over the two pages is given by

5

R(N, ǫ, γ)

I(P, W )

≥

− r
1 is the inverse function of Q(ǫ).

where Q−

U (P, W )
N

Q−

1(ǫ) +

log N
2N

, (12)

where the

T

Q (

ǫmax =

M) + Q (
2
functions of MSB and LSB are denoted by

L)

T

T

,

(17)

III. READ-VOLTAGE THRESHOLD OPTIMIZATION FOR
MLC FLASH MEMORY

In this section, we give the upper bound of decoding error
probability for MLC ﬂash memory channel and formulate
the read-voltage threshold optimization. Unlike conventional
methods such as MMI and entropy-based quantization, our
optimization problem focuses on ﬁnite block length.

A. Error Performance under Finite Block Length

First, we rewrite (12) as

Q−

1(ǫ)

≥ T

(N, ǫ, γ, P, W ),

(13)

where

(N, ǫ, γ, P, W ) =

T

I(P, W )

−

(cid:20)

R(N, ǫ, γ) +

log N
2N

(cid:21) s

N
U (P, W )

.

(14)

For the ﬂash memory, both I and U vary over different P
and W , since P and W depend on the parameters of ﬂash
memory, such as number of PE cycles, DRT and read-voltage
thresholds according to (5) and (8). Thus, the function
in
(14) can also be interpreted as a function with respect to these
parameters:

T

(N, ¯R,

T

D

, E, T ) =

, E, T )

I(

D

(cid:20)

¯R +

−

log N
2N

(cid:21) s

N
, E, T )

U (

D

,

(15)

where ¯R is the code rate of ECCs used in ﬂash memory.

(N, ¯R,

As Q function is monotonically decreasing,
coding error probability is upper bounded by ǫ
≤
. Thus the maximum error probability
Q
D
is ǫmax = Q
. In this context, our goal
, E, T )
is to optimize the read-voltage thresholds by minimizing the
maximum decoding error probability:

(N, ¯R,
(cid:1)

the de-

, E, T )

T
(cid:0)

T
(cid:0)

D

(cid:1)

∗ = arg min

ǫmax,

(16)

D

D

where

D
∗ is the set of optimal read-voltage thresholds.
Due to the write process of MLC ﬂash memory, the MSB
and LSB have different channel conditions [9], [35]. Conse-
quently, the error probabilities of MSB and LSB vary over
different quantization regions. Taking the 6-level read in Fig. 1
for example, the MSB errors often occur in region r4, and
the LSB errors often occur in regions of r2 and r6 [35]. In
addition, according to (8) and (9), the transition probabilities
W of MSB and LSB, denoted by WM and WL, are diverse.
Furthermore, the decoding error probabilities of MSB and
LSB are independent, since independent encoding processes

(18a)

(18b)

(19a)

(19b)

M =

T

L =

T

(cid:20)

(cid:20)

I(P, WM)

¯R +

−

log N
2N

N
U (P, WM)

,

(cid:21) s

I(P, WL)

¯R +

−

log N
2N

N
U (P, WL)

.

(cid:21) s

Overall, we can formulate the optimization problem as

P

: min
s.t.

ǫmax
0 < d1 < d2 <

< dJ .

· · ·

Due to the dimension of

is
D
computationally intractable. In the following, we develop an
efﬁcient method to solve this problem.

, analytical solution of

P

B. Cross Iterative Searching Algorithm

In this part, we utilize genetic algorithm and CIS algorithm
to optimize the read-voltage thresholds in various read-levels.
In the genetic algorithm, the evolution is implemented by
using a set of stochastic genetic operators to mimic the
natural process of reproduction and mutation. Although the
genetic algorithm can solve complex problems, high quality
solutions require massive computations to explore the entire
search space for global optimization [36]. For our problem,
the computation of genetic algorithm dramatically increases
as the dimension of
goes larger. To reduce the complexity,
the cross iterative searching algorithm helps us to ﬁnd local
optimum solution within certain region which saves a lot
of time. Combining the genetic algorithm and cross iterative
searching algorithm, we can escape from local optimum and
obtain near-optimal results.

D

As shown in Algorithm 1, we develop a CIS algorithm to
solve the optimization problem given in (19a). In the read-
voltage threshold optimization, all the read-voltage thresh-
olds are constrained by (19b). Before the iterative searching
the CIS algorithm needs to determine the initial
process,
value of the read-voltage thresholds (see line 1 of Algorithm
1). The well-designed initial value will accelerate the con-
vergence speed and avoid trapping into local optimum. Let
denote a set that collects the read-voltage
H
thresholds under hard decision. We can identify the hard-
decision thresholds by letting

h1, h2, h3}

=

{

ps0(v = h1) = ps1(v = h1),
ps1(v = h2) = ps2(v = h2),
ps2(v = h3) = ps3(v = h3).

(20)

Then, we initialize the J-level read-voltage thresholds as
1, d0
d0
{
j = 2,

, where d0
1, d0

1 = h1 −

j = h1 + (j
h1
1 .

J = h3 + δ, and δ = h3−
J
−

2, . . . , d0
J }
, J
−

δ, d0

· · ·

−

0 =
D
1)δ, for

6

4

5

3

2
Voltage

4

5

0

1

3

2
Voltage

(a)a)(cid:3)Voltage distribution(cid:3)(cid:68)(cid:81)(cid:71)
6-level uniform quantization

(b)(cid:3)Voltage distribution and
6-level nonuniform quantization

Algorithm 1: CIS Algorithm
Input: ǫmax, maximum iterations Imax, stopping criteria

ρ, block length N , code rate ¯R.
.

Output: the read-voltage thresholds

0,
1)

←
ǫ(i
−
max

0;
D
> ρ and i < Imax do

D

1 Initialization: i
2 while
3

ǫ(i)
max

|

|
−
i = i + 1, j = 1;
J do
while j

n
o
i
t
u
b
i
r
t
s
i
D
e
g
a
t
l
o
V

0

1

4

5

6

7

8

j using

≤

Q(

Determine the range of d(i)
j ;
Search for the local optimal d(i)
(d(i)
j , N, ¯R, E, T ));
arg min
d(i)
j
j = j + 1;
Calculate ǫ(i)
(i).

max;

T

9 Output

D

j

over

Lines 2-8 show the iterative searching process. First, the
ranges of read-voltage thresholds are determined in order to
reduce the searching space (see line 5). During the (i + 1)-th
iteration, we search di+1
, where λ is
a well-designed constant (e.g., λ = 0.2 in the simulations).
Second, the thresholds are updated successively, where each
read-voltage threshold is optimized while keeping remaining
read-voltage thresholds ﬁxed (see line 6). Finally, the search-
ing algorithm ends and outputs the optimized read-voltage
thresholds if
< ρ or the maximum number
−
of iterations is reached (see lines 2 and 9).

di
j −

ǫ(i
−
max

ǫ(i)
max

j + λ

λ, di

1)

(cid:3)

(cid:2)

|

|

IV. DNN-AIDED READ-VOLTAGE THRESHOLD
OPTIMIZATION

A. Motivation

Fig. 1 (b) illustrates that the original voltage thresholds
become outdated, since the voltage distribution is changed
under the effect of DRN in MLC ﬂash memory. Without the
precise read-voltage thresholds, we cannot obtain the correct
LLRs in (7) that depend on these thresholds. Finally, due to the
mismatch between new voltage distribution and outdated read-
voltage thresholds, the decoder is unable to decode correctly
based on the incorrect LLRs.

From (5), the voltage distribution mainly depends on the
number of PE cycles and DRT. The number of PE cycles
for the memory block can be recorded in ﬂash memory [27].
Nevertheless, we cannot analytically characterize the voltage
distribution under the effect of DRN, since the DRT is hard
to be recorded. Hence, it is great challenging for existing
technologies to track the voltage distribution under the effect
of DRN. To address this issue, we design a DNN-aided
optimization strategy to optimize the read-voltage thresholds.

B. Data Process

The DNN is a powerful tool to extract deep information
from raw data, which can build the non-linear mapping be-
tween inputs and outputs [28], [29]. However, its learning abil-
ity is limited when the input data lacks valuable information.

0

1

2

4
(c)c)(cid:3)Histogram of 6-le(cid:89)(cid:72)(cid:79)
uniform quantization

3

5

0

2

1

4
(d)(cid:3)Histogram of 6-level
nonuniform quantization

3

5

Fig. 3. 6-level read-voltage quantization for MLC ﬂash memory.

For the ﬂash memory, the input data comes from the read
process. Due to the read errors and limited memory sensing
precision, it is hard to obtain the accurate voltage of each
cell. In the read process, the read-voltage thresholds can be
used to determine the voltage locations over the quantization
regions (i.e., the region where each voltage value falls into)
and transform each location into a speciﬁc LLR of (7).

In this paper, we adopt the nonuniform quantization to
obtain the voltage location information, since the nonuniform
read-voltage quantization shows better error-correction perfor-
mance than uniform under the same number of quantization
levels [8], [9], [16]. As an illustration, Fig. 3 shows that, under
the nonuniform quantization can
the 6-level quantization,
better capture the characteristics of the voltage distribution,
where the histogram is used to count the number of voltage
values that fall into each region. This observation illustrates
that the nonuniform quantization can track the variation of
voltage distribution under the effect of DRN with limited
number of quantization levels. Therefore, by the nonuniform
quantization, the DNN can efﬁciently learn the relationship
between the location information and voltage distribution.

C. Multi-layer Perception Network

To address the mismatch problem between new voltage
distribution and outdated read-voltage thresholds, we propose
a DNN-aided decoding strategy to optimize the read-voltage
thresholds over different DRT. Before delving into the pro-
posed scheme, we brieﬂy introduce the DNN. The MLP is
a feedforward DNN which can extract valuable information
from extremely complex problems. In particular, it utilizes
a supervised learning technique called backpropagation for
training. A typical MLP network consists of at least three
layers and each layer consists of a number of nodes. The
adjacent layers are fully interconnected by weights that are
chosen randomly at the beginning.

 
(cid:80)
(cid:68)
(cid:85)
(cid:74)
(cid:82)
(cid:87)
(cid:86)
(cid:76)
(cid:43)

(cid:86)
(cid:87)
(cid:79)
(cid:88)
(cid:86)
(cid:72)
(cid:53)

(cid:20)

(cid:21)

J

J(cid:14)(cid:20)

(cid:20)

(cid:21)

J(cid:16)(cid:20)

J

(cid:72)
(cid:74)
(cid:68)
(cid:87)
(cid:79)
(cid:82)
(cid:89)
(cid:16)
(cid:71)
(cid:68)
(cid:72)
(cid:53)

(cid:86)
(cid:71)
(cid:79)
(cid:82)
(cid:75)
(cid:86)
(cid:72)
(cid:85)
(cid:75)
(cid:55)

(cid:3)

(cid:44)(cid:81)(cid:83)(cid:88)(cid:87)(cid:3)(cid:47)(cid:68)(cid:92)(cid:72)(cid:85)

(cid:43)(cid:76)(cid:71)(cid:71)(cid:72)(cid:81)(cid:3)(cid:47)(cid:68)(cid:92)(cid:72)(cid:85)(cid:86)

(cid:50)(cid:88)(cid:87)(cid:83)(cid:88)(cid:87)(cid:3)(cid:47)(cid:68)(cid:92)(cid:72)(cid:85)

Fig. 4. The diagram of an MLP network

As shown in Fig. 4, the MLP is composed of input layer,
hidden layers, and output layer. The input layer that owns J +1
nodes receives the input data and forwards it to the hidden
layer. The output layer outputs D = f (W Y + b), where W
and b are the weights and biases of the hidden layer neurons
respectively, and f (
·

) is a non-linear activation function.

For each learning iteration, the MLP receives the input
data (i.e., training set, validation set, or test set) and outputs
some values. Based on the error between the MLP output
and the expected output (i.e., label), the MLP performs a
backpropagation to update the weights of the hidden layers.
By the gradient decent algorithm, the weights are updated by
η ∂E(i)
W (i + 1) = W (i)
∂W (i) , where η is the learning rate and
E(i) is the error at i-th iteration. With the backpropagation,
the DNN can minimize the error between the MLP output and
expected output.

−

D. Training

1) Training Data Generation: The training data of DNN
includes the input data (i.e., histogram results of voltage
values) and expected output data (i.e., read-voltage thresholds
optimized by Algorithm 1). As shown in (5), the voltage
distribution of ﬂash memory channel depends on the number
of PE cycles and DRT. To make the DNN learn the relationship
between input data and expected output data, the training set
must include the voltage values with different numbers of
PE cycles and different DRT. In addition, the training data
is generated within a set of PE cycles
and
a range of DRTs over [0, 106].

4000, 5000, 6000

{

}

TABLE I
DNN HYPER-PARAMETERS

Learning rate

Epoch

Mini-batch size

Initializer

Optimizer

Loss function

10−5

100000

500

Xavier

Adam

MSE

7

Plane
Plane

Plane
Plane

Flash 
Chip

Voltage
write

Voltage
read

Mapping

Threshold 
comparison

LLR table

PE cycles

New
Thresholds

Flash 
Controller

Encoder

LLRs

DNN 

DRAM

m
a
r
g
o
r
P

Decoder

Success

Controller
Processors

First
fail

Second
fail

Error block 
management

Host
Interface

Fig. 5. The architecture of DNN-aided MLC ﬂash memory.

simulations, we employ the mean squared error (MSE) as the
loss function, which deﬁned as

LMSE =

1
J

J

(dj

−

2
ˆdj)

,

(21)

j=1
X
where dj and ˆdj are the expected output and MLP output,
respectively.

3) DNN Parameters: The sizes of input layer and output
layer depend on the read-voltage quantization levels. In the
MLP network, we employ three hidden layers with 512, 256,
128 neurons, respectively. For each hidden layer and output
layer, the activate functions are all Sigmoid Function, i.e.,
S(x) = 1

1+e−x . The hyper-parameters are listed in Table I.

E. DNN-aided Flash Memory

In this subsection, we develop a DNN-aided MLC ﬂash
memory structure as shown in Fig. 5. The DNN is well-trained
with the histogram results and the read-voltage thresholds
optimized by the proposed CIS algorithm. First, the controller
reads the voltage value from the ﬂash memory chip. Second,
the controller converts these voltage values into LLRs. Then,
the decoder uses these LLRs to perform decoding. If the
decoding fails, the DNN is activated and uses the histogram
results to update the read-voltage thresholds. After that, the
decoder receives the updated LLRs and performs decoding
again. If the second decoding fails, the controller records this
block as a bad block.

V. SIMULATION RESULTS

2) Loss Function: The loss function is the measurement of
errors between the MLP output and expected output. In our

In the simulations, we use the sum product algorithm as the
decoding algorithm where the maximum number of decoding

R
C
C

1.95

1.9

1.85

1.8

1.75

1.7

1.65

1.6

1

MMI, 2K-code
Entroy (  = 0.3), 2K-code
CIS, 2K-code
MMI, 4K-code
Entroy (  = 0.3), 4K-code
CIS, 4K-code

2K-code

10-2

10-3

R
E
F

10-4

  Mutual
Information

6-level read

3-level read

Mutual information, 6-level read
Mutual information, 3-level read
CCR, 6-level read, block length=4K
CCR, 6-level read, block length=2K
CCR, 3-level read, block length=4K
CCR, 3-level read, block length=2K

1.5

2

N

PE

 (Flash Memory Endurance)

2.5
104

1.5

N

PE

1.6
 (Flash Memory Endurance)

1.8

1.7

8

4K-code

1.9

2
104

Fig. 6. CCR versus PE cycles under different read-level quantization.

Fig. 7. FER performance of LDPC 2K-QC-code and 4K-QC-code versus
different NPE under 6-level read quantization with Imax = 25.

×

×

×

iterations is Imax. The simulations use three binary LDPC
codes, i.e., 2K-QC-code, 4K-QC-code, and 2K-random-code.
71 base matrix HB
In 4K-QC-code, each entry of a small 7
is replaced by either a circulant shift of a 64
64 identity
64 zero matrix. The block length of this code
matrix or a 64
is 4544 bits and the code rate is set as 0.9. This irregular
code has column-weight of 5 and row-weight of either 50
or 51. The 2K-QC-code is chosen as a QC-LDPC code with
uniform column-weight of 4 and row-weight of either 40 or
41. The code rate of 2K-QC-code are the same as 4K-QC-
code. The 2K-random-code is an irregular LDPC code with
input and output block length (frame size) of 1998 and 1776
bits, respectively. The code-rate is 0.89 and the column-weight
is 4.

MMI, 6-level
Entroy (  = 0.3), 6-level
CIS, 6-level
MMI, 9-level
CIS, 9-level

6-level read

10-1

10-2

R
E
F

10-3

10-4

Fig. 6 plots the CCR under different optimization strategies,
read levels, and block length versus PE cycles. The CCR of
mutual information strategy [9] follows (10), and the CCR of
ﬁnite block length strategy follows (12). First, it is observed
that the loss of CCR enlarges as the block length decreases.
Second, the quantization with larger read-levels contributes
to a higher CCR. This is due to the fact that larger read-
level quantization provides more precise voltage information
especially with high PE cycles.

Fig. 7 plots the frame-error-rate (FER) curves over different
NPE under the proposed CIS algorithm, MMI-based quan-
tization and entropy-based quantization (with the optimized
entropy parameter θ = 0.3 [16]) with 2K-QC-code and 4K-
QC-code, respectively. Consider that the number of PE cycles
ranges over [15000, 19000] and DRT is set to be zero (i.e., T
= 0 that represents the early retention time). It is observed that
the proposed CIS algorithm can endure the largest PE cycles
4,
among all the three methods. For example, at FER = 10−
the MMI-based quantization and entropy-based quantization
with 2K-QC-code can endure around 15100 and 15600 PE
cycles, respectively. In contrast, the proposed CIS algorithm

9-level read

1.5

1.6
N

PE

1.7

1.8

1.9

 (Flash Memory Endurance)

2
104

Fig. 8. FER performance of LDPC 2K-QC-code versus different NPE under
different read-level quantization with Imax = 30.

can extend the endurance limit of PE cycles to 15900.

Fig. 8 compares the FER performance versus different NPE
between the proposed CIS algorithm, MMI-based quantiza-
tion, and entropy-based quantization with 2K-QC-code. It is
observed that the proposed CIS algorithm is superior to both
MMI-based quantization and entropy-based quantization under
both 6-level and 9-level quantization. In addition, higher level
read quantization performance better. For example, at FER
4, the proposed scheme improves the endurance by
= 10−
2100 PE cycles under the 9-level quantization compared with
6-level read. This is due to the fact that, with the higher level
read quantization, more accurate LLRs are fed into the DDN-

9

BP, PE = 4000
BP, PE = 5000
BP, PE = 6000
RABP, PE = 4000
RABP, PE = 5000
RABP, PE = 6000
DNN-aided, PE = 4000
DNN-aided, PE = 5000
DNN-aided, PE = 6000
CIS, PE = 4000
CIS, PE = 5000
CIS, PE = 6000

MMI, 2K-QC-code
Entroy (  = 0.3), 2K-QC-code
CIS, 2K-QC-code
MMI, 2K-random-code
Entroy (  = 0.3), 2K-random-code
CIS, 2K-random-code

2K-QC-code

2K-random-code

100

10-1

10-2

10-3

R
E
F

10-4

10-5

10-6

104

DRT/hours

102

103

104
DRT/hours

105

106

10-2

10-3

R
E
F

10-4

10-5

103

Fig. 9. FER performance of LDPC 2K-QC-code and 2K-random-code versus
different DRT with NPE = 8000 and Imax = 25.

Fig. 10. FER performance of LDPC 2K-random-code under different strate-
gies versus different DRT with NPE = {4000, 5000, 6000} and Imax = 50.

aided decoder. Note that this ﬁgure does not show the FER
of entropy-based 9-level quantization, since the entropy-based
quantization cannot freely choose the read-levels.

Fig. 9 shows the FER curves versus different DRT between
the proposed CIS algorithm, MMI-based quantization, and
entropy-based quantization with 2K-QC-code and 2K-random-
code. Note that all these quantization methods use the perfect
knowledge of DRT and PE cycles. It is observed that the pro-
posed algorithm is superior to other algorithms with different
LDPC codes under the effect of DRN. For example, at FER
4, the proposed algorithm can extend the endurance
= 10−
limit of DRT up to 1000 hours and 2000 hours with 2K-QC-
code and 2K-random-code, respectively.

Fig. 10 plots the FER curves of the BP decoding, the
RABP decoding in [26], the proposed DNN-aided scheme,
and the CIS algorithm. In this ﬁgure, the RABP decoding
utilizes the information generated by the ﬁrst-round BP de-
coding to amend the LLRs and perform the second-round BP
decoding. First, it is observed that the FER of the proposed
DNN scheme approaches that of CIS. Second, the proposed
DNN scheme can signiﬁcantly improve the tolerance of ﬂash
memory against the DRN compared with the BP decoding and
4, the proposed
RABP decoding. For example, at FER = 10−
DNN scheme can extend the endurance of ﬂash memory up
to nearly 30000, 200000, 1000000 hours, while keeping the
NPE ﬁxed at 6000, 5000, 4000, respectively. In addition, the
proposed scheme improves the read latency of ﬂash memory
compared with the RABP decoding. This is due to the fact
that the RABP decoding demands the second-round decoding
to amend the inaccurate results in ﬁrst-round decoding caused
by the DRN. However, the proposed DNN scheme estimates
the read-voltage thresholds every 1000 blocks. Consequently,
there is no need for the proposed scheme to do the second-
round decoding, which reduces the read latency.

VI. CONCLUSIONS

In this paper, we optimized the read-voltage thresholds
for MLC ﬂash memory under ﬁnite block length. First, we
analyzed the ﬂash memory channel under ﬁnite block length
and formulated the threshold optimization problem. Based
on the ﬁnite block length theory, we converted the problem
of maximizing CCR problem into that of minimizing the
maximum decoding error probability. With perfect knowledge
of PE cycles and DRT, we proposed the CIS algorithm
to solve this optimization problem. Furthermore, to address
the intractable LLRs under the effect of DRN in reality,
we proposed the DNN-aided scheme to optimize the read-
voltage thresholds without the knowledge of DRT, where the
nonuniform quantization is employed to generate the voltage
location information as the input to the MLP. The simulation
results demonstrated that the proposed algorithms improve the
PE endurance compared with the existing baseline methods.
In particular, the proposed DNN-aided scheme can reduce the
read latency compared with the RABP decoding scheme.

REFERENCES

[1] K. Kim, “Future memory technology: Challenges and opportunities,” in
Proc. Int. Symp. VLSI Technol. Syst. Appl., San Jose, CA, USA, Apr.
2008, pp. 5–9.

[2] Y. Cai, E. F. Haratsch, O. Mutlu, and K. Mai, “Error patterns in MLC
NAND ﬂash memory: measurement, characterization, and analysis,” in
Proc. DATE, Mar. 2012, pp. 521–526.

[3] H. Lee, J. Shy, Y. Chen, and Y. Ueng, “LDPC coded modulation for
TLC ﬂash memory,” in Proc. IEEE ITW, Kaohsiung, Taiwan, Nov. 2017,
pp. 204–208.

[4] Q. Li, A. Jiang, and E. F. Haratsch, “Noise modeling and capacity
analysis for NAND ﬂash memories,” in Proc. IEEE ISIT, Honolulu,
HI, USA, Jun. 2014, pp. 2262–2266.

[5] Y. Cai, Y. Luo, E. F. Haratsch, K. Mai, and O. Mutlu, “Data retention in
MLC NAND ﬂash memory: characterization, optimization, and recov-
ery,” in Proc. HPCA, Burlingame, CA, USA, Feb. 2015, pp. 551–563.
[6] S. G. Cho, D. Kim, J. Choi, and J. Ha, “Block-wise concatenated BCH
codes for NAND ﬂash memories,” IEEE Trans. Commun., vol. 62, no. 4,
pp. 1164–1177, Apr. 2014.

10

[31] G. Dong, Y. Pan, N. Xie, C. Varanasi, and T. Zhang, “Estimating
information-theoretical NAND ﬂash memory storage capacity and its
implication to memory system design space exploration,” IEEE Trans.
Very Large Scale Integr. (VLSI) Syst., vol. 20, no. 9, pp. 1705–1714,
Sep. 2012.

[32] G. Dong, S. Li, and T. Zhang, “Using data postcompensation and
predistortion to tolerate cell-to-cell interference in MLC NAND ﬂash
memory,” IEEE Trans. Circuits Syst. I, Reg. Papers, vol. 57, no. 10, pp.
2718–2728, Oct. 2010.

[33] K. Takeuchi, T. Tanaka, and H. Nakamura, “A double-level-Vth select
gate array architecture for multilevel NAND ﬂash memories,” IEEE J.
Solid-State Circuits, vol. 31, no. 4, pp. 602–609, Apr. 1996.

[34] Y. Cai, S. Ghose, E. F. Haratsch, Y. Luo, and O. Mutlu, “Error
characterization, mitigation, and recovery in ﬂash-memory-based solid-
state drives,” Proc. IEEE, vol. 105, no. 9, pp. 1666–1704, Sep. 2017.

[35] H. Sun, W. Zhao, M. Lv, G. Dong, N. Zheng, and T. Zhang, “Exploiting
intracell bit-error characteristics to improve min-sum ldpc decoding for
mlc nand ﬂash-based storage in mobile device,” IEEE Trans. Very Large
Scale Integr. (VLSI) Syst., vol. 24, no. 8, pp. 2654–2664, Aug. 2016.

[36] H. Ali, A. Doucet, and D. I. Amshah, “Gsr: A new genetic algorithm
for improving source and channel estimates,” IEEE Trans. Circuits
SystCircuits Syst. I, Reg. Papers, vol. 54, no. 5, pp. 1088–1098, May
2007.

[7] B. Chen, X. Zhang, and Z. Wang, “Error correction for multi-level
NAND ﬂash memory using reed-solomon codes,” in Proc. IEEE SiPS,
Washington, DC, USA, Oct. 2008, pp. 94–99.

[8] G. Dong, N. Xie, and T. Zhang, “On the use of soft-decision error-
correction codes in NAND ﬂash memory,” IEEE Trans. Circuits Syst. I,
Reg. Papers, vol. 58, no. 2, pp. 429–439, Feb. 2011.

[9] J. Wang, K. Vakilinia, T. Y. Chen, T. Courtade, G. Dong, T. Zhang,
H. Shankar, and R. Wesel, “Enhanced precision through multiple reads
for LDPC decoding in ﬂash memories,” IEEE J. Sel. Areas Commun.,
vol. 32, no. 5, pp. 880–891, May 2014.

[10] P. Chen, K. Cai, and S. Zheng, “Rate-adaptive protograph LDPC codes
for multi-level-cell NAND ﬂash memory,” IEEE Commun. Lett., vol. 22,
no. 6, pp. 1112–1115, Jun. 2018.

[11] C. Wang, J. Li, L. Kong, F. Shu, and F. C. M. LAU, “Adaptive 2D
scheduling based nonbinary majority-logic decoding for NAND ﬂash
memory,” IEEE Trans. Circuits Syst. II, Exp. Briefs, Aug. 2019, to be
published.

[12] R. Gallager, “Low-density parity-check codes,” IRE Trans. Inf. Theory,

vol. 8, no. 1, pp. 21–28, Jan. 1963.

[13] H. Xiao and A. H. Banihashemi, “Graph-based message-passing sched-
ules for decoding LDPC codes,” IEEE Trans. Commun., vol. 52, no. 12,
pp. 2098–2105, Dec. 2004.

[14] E. Sharon, S. Litsyn, and J. Goldberger, “Efﬁcient serial message-passing
schedules for LDPC decoding,” IEEE Trans. Inf. Theory, vol. 53, no. 11,
pp. 4076–4091, Nov. 2007.

[15] K. Wei, J. Li, L. Kong, F. Shu, and F. C. M. Lau, “Page-based
dynamic partitioning scheduling for LDPC decoding in MLC NAND
ﬂash memory,” IEEE Trans. Circuits Syst. II, Exp. Briefs, vol. 66, no. 12,
pp. 2082–2086, Feb. 2019.

[16] C. A. Aslam, Y. L. Guan, and K. Cai, “Read and write voltage signal
optimization for multi-level-cell (MLC) NAND ﬂash memory,” IEEE
Trans. Commun., vol. 64, no. 4, pp. 1613–1623, Feb. 2016.

[17] C. A. Aslam, Y. L. Guan, and K. Cai, “Non-binary LDPC code with
multiple memory reads for multi-level-cell (MLC) ﬂash,” in Proc. Int.
Conf. APSIPA, Berkeley, CA ,USA, Dec. 2014, pp. 1–9.

[18] Z. Mei, K. Cai, L. Shi, and X. He, “On channel quantization for
spin-torque transfer magnetic random access memory,” IEEE Trans.
Commun., pp. 7526–7539, Nov. 2019.

[19] B. Peleato, R. Agarwal, J. M. Ciofﬁ, M. Qin, and P. H. Siegel, “Adaptive
read thresholds for NAND ﬂash,” IEEE Trans. Commun., vol. 63, no. 9,
pp. 3069–3081, Sep. 2015.

[20] K. Wei, J. Li, L. Kong, F. Shu, and Y. Li, “Read-voltage optimization
for ﬁnite code length in MLC NAND ﬂash memory,” in Proc. IEEE
ITW, Guangzhou, China, Nov. 2018.

[21] Y. Polyanskiy, H. V. Poor, and S. Verdu, “Channel coding rate in the
ﬁnite blocklength regime,” IEEE Trans. Inf. Theory, vol. 56, no. 5, pp.
2307–2359, May 2010.

[22] B. M. Kurkoski and H. Yagi, “Quantization of binary-input discrete
memoryless channels,” IEEE Trans. Inf. Theory, vol. 60, no. 8, pp. 4544–
4552, Aug. 2014.

[23] F. J. C. Romero and B. M. Kurkoski, “LDPC decoding mappings that
maximize mutual information,” IEEE J. Sel. Areas Commun., vol. 34,
no. 9, pp. 2391–2401, Sep. 2016.

[24] Y. Cai, G. Yalcin, O. Mutlu, E. F. Haratsch, A. Cristal, O. S. Unsal, and
K. Mai, “Flash correct-and-refresh: retention-aware error management
for increased ﬂash memory lifetime,” in Proc. IEEE ICCD, Montreal,
QC, Canada, Sep. 2012, pp. 94–101.

[25] D. H. Lee and W. Sung, “Decision directed estimation of threshold
voltage distribution in NAND ﬂash memory,” IEEE Trans. Signal
Process., vol. 62, no. 4, pp. 919–927, Feb. 2014.

[26] C. A. Aslam, Y. L. Guan, and K. Cai, “Retention-aware belief-
propagation decoding for NAND ﬂash memory,” IEEE Trans. Circuits
Syst. II, Exp. Briefs, vol. 64, no. 6, pp. 725–729, Jun. 2017.

[27] C. A. Aslam, Y. L. Guan, and K. Cai, “Decision-directed retention-
failure recovery with channel update for MLC NAND ﬂash memory,”
IEEE Trans. Circuits Syst. I, Reg. Papers, vol. 65, no. 1, pp. 353–365,
Jan. 2018.

[28] S. Dörner, S. Cammerer, J. Hoydis, and S. T. Brink, “Deep learning
based communication over the air,” IEEE J. Sel. Topics Signal Process.,
vol. 12, no. 1, pp. 132–143, Feb. 2018.

[29] F. Liang, C. Shen, and F. Wu, “An iterative BP-CNN architecture for
channel decoding,” IEEE J. Sel. Topics Signal Process., vol. 12, no. 1,
pp. 144–159, Feb. 2018.

[30] K.-D. Suh et al., “A 3.3 V 32 Mb NAND ﬂash memory with incremental
step pulse programming scheme,” IEEE J. Solid-State Circuits, vol. 30,
no. 11, pp. 1149–1156, Nov. 1995.

