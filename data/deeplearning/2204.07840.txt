1

A Robust and Scalable Attention Guided
Deep Learning Framework for Movement
Quality Assessment

Aditya Kanade1, Mansi Sharma1, Member, IEEE, Manivannan Muniyandi2.

Abstract—Physical rehabilitation programs

fre-
quently begin with a brief stay in the hospital and
continue with home-based rehabilitation. Lack of
feedback on exercise correctness is a signiﬁcant issue
in home-based rehabilitation. Automated movement
quality assessment (MQA) using skeletal movement
data (hereafter referred to as skeletal data) collected
via depth imaging devices can assist with home-based
rehabilitation by providing the necessary quantitative
feedback. This paper aims to use recent advances
in deep learning to address the problem of MQA.
Movement quality score generation is an essential
component of MQA. We propose three novel skeletal
data augmentation schemes. We show that using
the proposed augmentations for generating movement
quality scores result in signiﬁcant performance boosts
over existing methods. Finally, we propose a novel
transformer based architecture for MQA. Four novel
feature extractors are proposed and studied that allow
the transformer network to operate on skeletal data.
We show that adding the attention mechanism in the
design of the proposed feature extractor allows the
transformer network to pay attention to speciﬁc body
parts that make a signiﬁcant contribution towards
executing a movement. We report an improvement
in movement quality score prediction of 12% on
UI-PRMD dataset and 21% on KIMORE dataset
compared to the existing methods.

Index Terms—Movement Quality Assessment, Deep
Learning, Skeletal Data Augmentation, Transformer,
Performance Score Generation, Denoising Autoen-
coder

1The authors are with Department of Electrical Engineering,
Indian Institute of Technology Madras, Chennai, India, 600036.
2The author is with Department of Applied Mechanics, Indian

Institute of Technology Madras, Chennai, India, 600036.

E-mail:

{ee20s086@smail, mansisharma@ee}.iitm.ac.in,

mani@iitm.ac.in

I. INTRODUCTION

Brain stroke is a leading cause of severe long-
term disability. Stroke reduces mobility in more
than half of the survivors, especially senior citizens
(65 years and above). A great effort has been
directed towards improving the quality of life of
stroke survivors with a wide range of technology
[1]. However, only a few medical institutions are
exploiting computer based rehabilitation tools [2].
Literature surveys indicate that more than 90%
of rehabilitation sessions are carried out at home
[3]. The patients either have to self-monitor or
take help from the family members to monitor
progress in the rehabilitation program. Since the
home-based rehabilitation program is completely
voluntary in nature, it often leads to low levels
of patient adherence; resulting in prolonged post
hospitalization recovery [4, 5]. Another issue with
the home-based rehabilitation program is the lack
of corrective feedback on movement quality and
correctness. Some of the technological solutions
available to the patient undergoing home-based re-
habilitation are the robotic assistive systems [6],
virtual reality and gaming interfaces [7], and Kinect
based assistance [8].

In their work, Liao et al. [9] took a step in the di-
rection of automated movement quality assessment
from skeletal data. They proposed a deep learning
framework for quantitative movement assessment;
validated on the UI-PRMD dataset [10]. The ﬁrst
stage of their framework consists of a statistical
model for the exercise generated by training a
mixture of Gaussians on the correct performances of
an exercise. They use the negative log-likelihood of

2
2
0
2

r
p
A
6
1

]

V
C
.
s
c
[

1
v
0
4
8
7
0
.
4
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
the trained model to measure performance quality,
termed the performance metric. A scoring function
is deﬁned, which maps the performance metric val-
ues into movement quality scores in the range [0, 1].
In the second stage, a hierarchical multiscale CNN-
LSTM based architecture is employed to model this
relationship between the movement data and the
score. We list down a few shortcomings of their
framework.

• In the ﬁrst stage of their framework, the au-
thors used an autoencoder to reduce the di-
mensionality of the movement data, which was
used to train the GMM model. Autoencoders
are prone to overﬁtting on the training data;
without requisite regularization, the model will
not learn good and general lower-dimensional
representations [11].

• Long Short Term Memory (LSTM), a recurrent
neural network, is a signiﬁcant building block
in their model. LSTMs have been shown in-
ferior in modeling very long temporal depen-
dencies, they also suffer from poor scalability
and longer training times [12].

In this article, we study advances in deep learning
and propose a more robust and scalable framework
for movement quality assessment, building on the
work done by Liao et al. [9]. The novel contribu-
tions of this paper are:

• Three

novel
skeletal
schemes are proposed.

data

augmentation

• A new training mechanism for the autoen-
coder network is proposed. We show that using
the three proposed skeletal data augmentation
leads to better outcomes in the existing perfor-
mance score generation techniques.

• A novel transformer based architecture is pro-

posed for movement quality assessment.

• Use of CNN based feature extractors is pro-
posed to extract vector representation of tem-
poral window slices, allowing the transformer
network to operate on the skeletal data. We
show that embedding the attention mechanism
into feature extraction can allow the trans-
former network pay attention to speciﬁc body
parts contributing to performance of an exer-
cise.

2

• A comparative study is undertaken to choose
the best feature extractor for the transformer
model.

II. PROPOSED ARCHITECTURE

Towards movement assessment and scoring, we
begin our discussion by acquainting the reader with
skeletal data collected on depth imaging devices
such as Kinect and Vicon optical system. We then
discuss three skeletal data augmentation techniques.
We investigate application of skeletal data aug-
mentation techniques to existing performance score
generation techniques. Finally, a detailed study is
carried out on the proposed Transformer architec-
ture for predicting movement quality scores.

A. Skeletal Data

We consider movement data captured on a depth
imaging system such as the marker-based Vicon
optical
tracker or the markerless Kinect system.
These systems capture the movement data at a
certain frame rate. At every frame,
the system
captures spatial information of several skeletal land-
marks of the human body in 3-dimensional joint
orientation and joint position. We consider joint
orientation data captured by the system for our
experiments due to invariance of the captured data
to varying body structures. Considering an example
system that tracks M skeletal landmarks on a human
subject. Performance of a single repetition by a
human subject of an exercise will generate data
for T frames, joint orientation information for all
the M landmarks will be captured at every frame
by a vector x(i), i ∈ [1...T ] of dimension D, here
D = M × 3. Stacking these vectors for each frame
results in a tensor of X ∈ RT ×D; a representative
of the single repetition.

In our study, we consider two datasets; listed
in Table I. The UI-PRMD dataset was collected
tracker and
using two devices, a Vicon optical
a markerless Kinect tracker. The authors’ Vicon
conﬁguration tracks 39 joint landmarks, whereas
the Kinect-based system tracks 25 joint landmarks.
Both Kinect and Vicon systems track joint position
and orientation. Data for the KIMORE dataset was

TABLE I: Dataset Details

Dataset
UI-PRMD [10]
KIMORE [13]

No. of Participants
10
78

No. of Exercises
10
5

Depth Imaging System
Vicon, Kinect V2
Kinect V2

captured on a Kinect camera. Additionally, perfor-
mances by subjects are evaluated on a scale of
[0, 50] by ﬁve clinicians and are given as part of
the KIMORE dataset.

3

window for the entire duration is another way
to achieve this augmentation.

• Movement Data Masking - Input data mask-
ing is a popular technique of data augmentation
in image classiﬁcation. The skeletal data is
looked at through small windows of size h,
entire movement data within this window is
set to zero with some probability p to achieve
this augmentation.

Fig 1 gives a graphical description of the dis-

B. Skeletal Data Augmentation

cussed skeletal data augmentations.

Human motion displays a broad spectrum of
variability. The data captured on the above-listed
systems will always be limited in their sample size.
Improving the generalization of machine learning
models trained on this limited amount of data is
of prime importance. Augmenting existing datasets
by some form of mathematical manipulation is a
popular method for improving the generalization
capability of machine learning model [14]. We in-
troduce three novel techniques of data augmentation
for skeletal data.

• Variable Pace of Exercise Performance -
The pace of exercise performance is highly
variable. A machine learning model predicting
a movement assessment score should depend
on the movement’s quality and not on the
pace of performance. Increasing or decreasing
the pace of exercise performance on already
recorded movement data can be achieved by
linear interpolation for decreasing the pace
and downsampling for increasing the pace of
performance.

• Joint Occlusion - Joint occlusion is a common
phenomenon while collecting movement data.
The movement data capturing system relies
on skeletal
landmarks to track body move-
ments; complex body movements can result
in the system losing track of the landmarks.
The skeletal data is looked at through small
windows of size h, a small number of joints
(n) are randomly selected, and movement data
recorded for these joints is set to zero within
this window; simulating the condition of joint
occlusion. Repeating movement data captured
for all selected joints at the beginning of each

C. Movement Quality Score Generation

In a real-world home-based physical rehabilita-
tion scenario, a quantitative measure of exercise
performance can enable the patient to gauge their
progress towards functional recovery. Using super-
vised regression, training a deep learning model
for quantitative movement assessment is possible.
However, such a model will require human move-
ment data as input and an assessment score as out-
put. Two ways can generate the assessment scores:
1) human expert-based assessment, 2) statistical
model-based assessment. Each repetition of an exer-
cise performed is scored by a trained clinician on a
predeﬁned scale in the human expert-based assess-
ment. This method, however, presents a challenge
in terms of consistency of movement assessment.
The same motion can receive differing scores from
different experts, reducing the reliability of such a
scoring scheme. However, the statistical modeling
method is different; here, the human bias does not
affect the scoring. The model, however, is limited
by the type of statistical model chosen to capture
information of movement data for an exercise.

Liao et al. [9] proposed using a mixture of
Gaussians to model an exercise. The model was
trained a lower-dimensional projection of the data,
to circumnavigate the curse of dimensionality. Their
exploration found the autoencoder network to work
best for this purpose. The authors explained their
choice using a metric termed as the separation
degree for evaluating performances of various di-
mensionality reduction techniques. The authors ex-
plained the metric as follows “When applied to
the values of the distance metrics, the separation

4

(a)

(b)

(c)

(d)

Fig. 1: Skeletal Data Augmentations - Result of applying the three proposed skeletal data augmentations
is shown here. We consider joint orientation data for six joints for better interpretability. The x-axis
represents the number of timesteps (T) for which the data was recorded, while, the y-axis represents the
orientation angle in degrees. (a) Raw Skeletal Data - Raw joint orientation data captured for six joints.
Joint orientation data is represented in terms of three-dimensional Euler angles for each joint; resulting
in 18 features per frame. (b) Variable Pace of Exercise Performance - The pace of performance is
speeded up by a factor of 25% by downsampling the raw skeletal data. (c) Randomized Joint Occlusion
- The joints from frames are occluded by setting h = 10 and n = 2. (d) Randomized Movement Data
Masking - The raw skeletal data is masked by setting h = 10 and p = 0.2.

degree indicates greater ability of the used metric
to differentiate between correct and incorrect rep-
etitions of an exercise”. Here, by distance metric,
the authors mean the statistical distance between
a sample skeletal data recorded for an exercise
and the trained exercise model. In this paper, we
aim to improve the process of score generation,
precisely the technique used for low dimensional
projection of the movement data, and show the
resulting improvements on the separation degree
metric.

Research indicates that autoencoders tend to
overﬁt the training data [15]. Overﬁtting is prob-
lematic when lower-dimensional projection of the
movement data from the autoencoder network is
used to train the mixture of Gaussians since this
model will only work well on the training data and
will not generalize well. Learning good and gen-
eral representations of the input movement data is
essential. A large corpus of work indicates masked
input modeling as a suitable choice for learning
better representations in autoencoders [16]. The
random masking of the input ensures that a certain
sense of the structure is built into the autoencoder
model, allowing it to recover the original input from
the masked input. We use the three novel skeletal
data augmentation schemes proposed in Section

II-B to train the autoencoder network. The new
autoencoder training mechanism makes it a type of
Denoising Autoencoder [16]. We believe that the
proposed training mechanism aids in the network
learning better latent representations for the input
movement data.

The autoencoder network consists of two com-
ponents: 1) Encoder f (.): A deep neural network
which models the lower dimensional latent repre-
sentation of the input, 2) Decoder g(.): A deep neu-
ral network which projects the lower dimensional
latent representation back into the input space. The
encoder and decoder are jointly trained on the
reconstruction loss Lreconst(.) This loss is deﬁned
as the mean squared error between the reconstructed
output and input at the encoder. A regularization
factor Ω(f) is added to the reconstruction loss. The
regularization is performed using L1 norm of the
encoder weights. This assists the proposed model to
generalize better [17]. Let ∆B = {X 1, X 2, ..., X B}
represent a batch of B episodes of movement data
¯∆B = { ¯X 1, ¯X 2, ..., ¯X B} rep-
for an exercise.
resents the augmented version of the batch. The
neural network is trained using the following loss
function.

Ltotal(∆B) = Lreconst.(∆B; g(f( ¯∆B))) + λ.Ω(f)
(1)

This training mechanism forces the network to
learn the structure of movement data better, as the
network is forced to predict the original movement
data irrespective of the type of augmentation per-
formed.

Fig. 2: Score Generation Model - The dotted red
box highlights the proposed addition of the skeletal
data augmentation in the existing performance score
generation pipeline.

Fig 2 shows a block diagram of the score gener-
ation system in detail. These generated scores will
be used to train the proposed transformer-based
network to predict movement assessment scores.
The quality of the model is evaluated using the
separation degree metric.

D. Transformer Architecture for Rehabilitation As-
sessment

Transformers have been consistently successful
in tasks such as image classiﬁcation, automatic
language processing
speech recognition, natural
[18, 19, 20]. The transformer architecture is scal-
able, and a higher representation capacity can be
obtained by increasing the number of layers in the
architecture [21]. Additionally, parallel execution is
also possible since the transformer architecture is
not recurrent. This architectural difference signiﬁ-
cantly reduces training time and allows for training
on higher amounts of data. Training on more exten-
sive data can pave the way for more complicated
and scalable modeling of human movements as
more movement data becomes available.

Movement data is harder to train on a transformer
directly. For example, data for a single repetition
of an exercise performed for 10 secs, captured on

5

a Vicon system at 90fps will result in a tensor
X of size R900×117. Passing this tensor through a
single attention block of the transformer will cost
9002 operations. Thus, passing the raw movement
data input directly to the transformer does not seem
reasonable. It leads to a quadratic increase in the
number of parameters as the number of attention
blocks increases.

Taking inspiration from the adaptation of the
transformer architecture in the ﬁeld of image clas-
siﬁcation and automatic speech recognition, we
make use of an embedding layer between the raw
movement data and the transformer for tokenizing
the input data. The raw input X ∈ RT ×D is split
into N temporal window slices of size W each, such
that T = W × N , given by the set S, where each
si represents the ith temporal window.

S = (s1, s2, s3, ..., sN ), si ∈ RW ×D

(2)

An embedding layer E projects each temporal win-
dow into a latent subspace Z, where E : si −→
zi, i ∈ 1...N . This operation reduces the dimen-
sionality to RK such that each vector zi is a K
dimensional vector representation of the ith tem-
poral window si. The transformer architecture does
not have a way to capture positional information of
the input tokens by design. We use the technique
described in [12] to add positional information to
the input. Each vector zi is added with a positional
embedding vector pi ∈ RK. The set Zp is the result
of this operation.
Zp = (z1+p1, z2+p2, z3+p3, ..., zN +pN ), zi ∈ RK
(3)
The set Zp is passed on to the lowest encoder
layer of the transformer encoder. Note: we only
use the transformer encoder in our experiment.
The attention map generated at the topmost layer
of the transformer encoder is projected through a
series of dense layers, which ﬁnally predict a score
value for the exercise. The network uses the binary
cross entropy between the predicted and the actual
assessment score to jointly learn the parameters of
the transformer encoder and the embedding layer.
The architecture of this network is shown in Fig
3. We additionally experiment with the structure of
the embedding layer to select the best performing

6

Fig. 4: Attention guided Hierarchical Feature Ex-
tractor

parts. We propose another novel feature extractor
termed the Attention guided Hierarchical Feature
Extractor (HFE-A). This feature extractor consists
of a multi-head attention block after the hierarchical
feature extractor. This block computes a soft mix-
ture of the features extracted by the individual sub-
networks. For our architecture, we use ﬁve heads
in the multi-head attention block. The resulting
computation of the multi-head attention block is
passed through a global max pooling block which
selects the most dominant features. At the end of
this pooling block, the feature vector becomes the
vector representation of the temporal widow slice
of the input movement data.

III. RESULTS AND DISCUSSIONS

A. Movement Quality Score Generation Perfor-
mance

The scores for movement data in UI-PRMD
dataset are generated based on the discussion in
Section II-C. Augmentation schemes discussed in
section II-B are used; augmentations are applied
for every batch. This ensures that the network is
never trained on the original version of the data. At
every iteration, the network sees a modiﬁed version
of data ensuring that overﬁtting doesn’t occur on

Fig. 3: Network Architecture

feature extractor. A comparison between feature
extractors is reported in the results section. We con-
sider four feature extractors for the embedding layer
in our study: 1) MLP Feature Extractor, 2) CNN
Feature Extractor, 3) Hierarchical Feature Extractor
(HFE), and 4) Attention guided Hierarchical Fea-
ture Extractor (HFE-A). The MLP and CNN-based
feature extractors are simple in structure; the former
consists of fully connected neurons layers, while
the latter consists of a stack of one-dimensional
convolutional ﬁlters. The previous body of work has
shown better performance exploiting the hierarchi-
cal structure of the movement data for action recog-
nition [9, 22]. We adopt this structure and propose
a novel feature extractor called the Hierarchical
Feature Extractor (HFE). The feature extractor is
designed to exploit
the spatial characteristics of
human movements by dedicating sub-networks for
processing joint displacements of individual body

the training data. Table II shows the results on
separation degree metric.

We see a signiﬁcant improvement in the sepa-
ration degree metric performance for the proposed
novel training mechanism, with an increase of 1.5
percent in within-subject and a 18 percent increase
in the between-subject category. The autoencoder
model with the novel training mechanism proposed
in Section II-C has to predict the original movement
data irrespective of the augmentation applied at
the input side. The resulting lower dimensional
latent structure that the model discovers is more
general since it displays a certain invariance to the
augmentation applied; since it has to reconstruct this
latent representation back to the original input. A
better representation allows more capacity to dif-
ferentiate between correct and incorrect movements,
leading to greater separation degree, as shown by
the results.

TABLE II: Separation Degree (SD)- shows that
the use of skeletal data augmentations for training
an autoencoder results in better separation between
the correct and incorrect movements.

Within Subject (SD)

Between Subject (SD)

Deep Rehab [9]
0.511
0.376
0.642
0.510
0.585
0.489
0.394
0.617
0.525
0.461
0.510

Proposed
0.518
0.540
0.571
0.352
0.571
0.511
0.478
0.550
0.535
0.497
0.571

Deep Rehab [9]
0.402
0.288
0.404
0.423
0.338
0.428
0.387
0.525
0.414
0.339
0.480

Proposed
0.478
0.444
0.606
0.281
0.499
0.374
0.552
0.597
0.507
0.370
0.552

E1-E10
E1
E2
E3
E4
E5
E6
E7
E8
E9
E10

7

16GB RAM, and an NVIDIA-2080Ti GPU card.
A separate model is trained for each of the ten
exercises in the UI-PRMD dataset. We report the
model performance in terms of the average abso-
lute deviation between the ground truth movement
quality scores and the network prediction; these
values are averaged over ﬁve runs for generating
the results. The network is trained on a 0.8/0.2
train/validation split. The model is trained using the
Adam optimizer, setting the learning rate to 0.0005
[23]. Early stopping is used to avoid overﬁtting the
training data. A patience value of 100 epochs is
set to monitor the validation loss. The network is
trained on binary cross-entropy loss between the
predicted score and the ground truth scores. An
extensive grid search was carried out for selecting
hyperparameters and ﬁne-tuning the transformer
encoder and the embedding layer. Following is a list
of the best conﬁguration we found for the proposed
model.

• Temporal Window (W ) Size - 40
• Feature Vector (zi) Size - 256
• Number of Heads in Transformer Encoder

Block- 4

• Number of Transformer Encoder Blocks - 2
To evaluate the performance of various feature
extractors for the embedding layer, we perform an
ablation study. The results on Deep Squat exercise
(E1) in the UI-PRMD dataset are displayed in Table
III.

Embeddor Type MAE
0.0180
0.0215
0.0200
0.0175

MLP
CNN
HFE
HFE-A

Time per Batch
30ms
30ms
205ms
215ms

B. Transformer Model Performance

The proposed model is trained on the movement
data from the UI-PRMD dataset. The raw joint
orientation data of the skeletal landmarks are used
as input to the proposed network. The scores for
exercises are generated using techniques described
in section II-C. The network is designed to pre-
dict the movement quality score in a supervised
regression setting. The model was implemented on
an HP desktop computer with an i7 processor,

TABLE III: Comparative Study of Feature Ex-
tractors for the Embedding Layer - The study
was carried out on Deep Squat Exercise (E1) from
the UI-PRMD dataset. We report Average Absolute
Deviation for all four types of the proposed feature
extractors. We also report the time taken by each
network per batch.

We see that

the proposed HFE-A works best
between the four proposed feature extractors for
the embedding layer. Fig 5 shows attention map

8

TABLE IV: Average Absolute Deviation on Move-
ment Quality Scores for the UI-PRMD Dataset

Proposed
Model
0.0365
0.0175
0.0321
0.0369
0.0342
0.0321
0.0331
0.0544
0.0379
0.0252
0.0613

Deep
Rehab [9]
0.0415
0.0229
0.0399
0.0441
0.0367
0.0362
0.0414
0.0565
0.0418
0.0283
0.0672

Deep CNN
[9]
0.0456
0.0286
0.0438
0.0394
0.0344
0.0384
0.0424
0.0751
0.0448
0.0364
0.0727

Deep
LSTM [9]
0.0418
0.0230
0.0363
0.0414
0.0350
0.0336
0.0373
0.0598
0.0448
0.0402
0.0668

E1-E10
E1
E2
E3
E4
E5
E6
E7
E8
E9
E10

lists the results of comparative analysis between the
models.

The results demonstrate over 12% improvement
over the current state-of-the-art method and the
baseline models on UI-PRMD dataset. We also
show results on KIMORE dataset, which was col-
lected on the Kinect V2 system. We followed the
same 0.8/0.2 train/validation split for this dataset.
The results of the score predictions are shown in
Table V.

TABLE V: Average Absolute Deviation on Move-
ment Quality Scores for the KIMORE Dataset

Proposed
Model
0.1093
0.0826
0.1624
0.0767
0.1097
0.1153

Deep
Rehab [9]
0.1390
0.1456
0.1429
0.1399
0.1344
0.1326

Deep CNN
[9]
0.1282
0.1346
0.1448
0.1205
0.1192
0.1219

Deep
LSTM [9]
0.1500
0.1257
0.1670
0.1661
0.1442
0.1464

E1-E5
E1
E2
E3
E4
E5

The results demonstrate over 21% improvement
over the current state-of-the-art method and the
baseline models on the KIMORE dataset. Both
these results show superior performance by the
proposed model. At this point, it is important to
note that ﬁnding the right hyperparameters for the
Transformer based architecture is more difﬁcult
than CNN-LSTM based architectures. However, the
increased accuracy, scalability and speed of the
Transformer-based network architecture compen-
the ﬁeld of movement
sates for this. Currently,
assessment lacks a large-scale dataset containing

Fig. 5: Attention Score Map - The ﬁgure shows
the attention map computed by ﬁve heads of the
multi-head attention block for Standing Shoulder
Abduction exercise (E7) in UI-PRMD dataset. Each
row of the ﬁgure indicates mixing coefﬁcients for
vector output from each sub-network. We see that
the network pays attention to upper-body sub-
networks since the exercise is primarily an upper-
body exercise.

it

is important

to note that

generated at the multi-head attention layer of HFE-
A. The attention map was generated by training the
proposed transformer network with HFE-A for the
embedding layer on Standing Shoulder Abduction
(E7) exercise. The exercise is primarily an upper-
body exercise. The results from Fig 5 support our
intuitive assumption that the multi-head attention
block introduced in the design of HFE-A allows
the proposed transformer network to attend spe-
ciﬁc body parts that contribute signiﬁcantly to an
exercise while predicting movement quality score.
Finally,
the simple
MLP based feature extractor also yields comparable
results to HFE-A while being computationally very
efﬁcient. Accordingly, we ﬁnd that both these fea-
ture extractors can be considered based on the trade-
off between accuracy and computational efﬁciency.
We now compare the performance of proposed
transformer model to current state-of-the-art deep
learning models for movement assessment. We are
aware of only one such study which applies deep
learning to the ﬁeld of movement quality assess-
ment; hence we compare our results with two
additional baseline models, Deep CNN and Deep
LSTM. The model parameters and architecture for
the baseline models were selected based on the
details listed in [9] for a fair comparison. Table IV

a large number of diverse examples of various
exercises prescribed for physical rehabilitation. We
believe that the proposed model can aid in scaling to
much larger datasets as a result of the Transformer
based architecture.

IV. CONCLUSION

The aim of this paper was to address the prob-
lem of movement quality assessment using deep
learning. In this paper, we introduced three novel
data augmentation schemes for human skeletal data.
We show that using the proposed augmentation
schemes for performance score generation results
in an improvement of over 18% in between-subject
category and 1.5% in the within-subject category
on the separation degree metric. The enhanced
results are due to more general latent representa-
tions learned by the autoencoder network, allowing
the exercise model better differentiation between
correct and incorrect movements. We further pro-
posed a novel Transformer based architecture for
movement quality assessment and introduced four
novel feature extractors for the embedding layer,
aiding the transformer to operate on the continuous
skeletal data. We compare the performance of the
proposed transformer network on all the proposed
feature extractors and show that the attention guided
hierarchical feature extractor (HFE-A) and the MLP
feature extractor give the best results. We ﬁnally
compare the proposed network against current state-
of-the-art methods and show improvement of over
12% on the UI-PRMD dataset and 21% on the
KIMORE dataset. Improvements in the movement
quality scores are aided with enhanced explain-
ability of the score prediction process due to the
addition of the attention layer.

In this paper, we have explored the technique of
masking and pace manipulation as a way of data
augmentation. However, further research should be
directed towards more augmentation schemes for
skeletal data. Better augmentation schemes can aid
the application of newer techniques such as self-
supervised learning to the ﬁeld of skeletal data. The
attention mechanism in the proposed HFE-A feature
extractor is a beginning towards the application
of attention mechanism in the ﬁeld of movement

9

assessment. Further research needs to be undertaken
for searching for even more powerful ways to apply
the attention mechanism for skeletal data.

ACKNOWLEDGMENT

The scientiﬁc efforts leading to the results re-
ported in this paper have been carried out under the
supervision of Dr. Mansi Sharma while working as
an INSPIRE Hosted Faculty, IIT Madras.

REFERENCES
[1] Y. Chen, K. Abel, J. Janecek, Y. Chen, K. Zheng, and
S. Cramer, “Home-based technologies for stroke reha-
bilitation: A systematic review,” International Journal of
Medical Informatics, vol. 123, 12 2018.

[2] D. Gonz´alez-Ortega, F. D´ıaz-Pernas, M. Mart´ınez-
Zarzuela, and M. Ant´on-Rodr´ıguez, “A kinect-based sys-
tem for cognitive rehabilitation exercises monitoring,”
Computer Methods and Programs in Biomedicine, vol. 113,
no. 2, pp. 620–631, 2014.

[3] R. Komatireddy, “Quality and quantity of rehabilitation
exercises delivered by a 3-d motion controlled camera: A
pilot study,” International Journal of Physical Medicine &
Rehabilitation, vol. 02, 08 2014.

[4] S. Bassett and H. Prapavessis, “Home-based physical
therapy intervention with adherence-enhancing strategies
versus clinic-based management for patients with ankle
sprains,” Physical therapy, vol. 87, pp. 1132–43, 10 2007.
[5] K. Jack, S. M. McLean, J. A. K. Moffett, and E. Gar-
diner, “Barriers to treatment adherence in physiotherapy
outpatient clinics: A systematic review,” Manual Therapy,
vol. 15, pp. 220 – 228, 2010.

[6] S. Guguloth, S. Balasubramanian, and S. Srinivasan, “A
novel robotic device for shoulder rehabilitation,” 07 2018.
[7] L. Gauthier, C. Kane, A. Borstad, N. Strahl, G. Uswatte,
E. Taub, D. Morris, A. Hall, M. Arakelian, and V. Mark,
“Video game rehabilitation for outpatient stroke (vigorous):
Protocol for a multi-center comparative effectiveness trial
of in-home gamiﬁed constraint-induced movement therapy
for rehabilitation of chronic upper extremity hemiparesis,”
BMC Neurology, vol. 17, 06 2017.

[8] A. Dash, A. Yadav, A. Chauhan, and U. Lahiri, “Kinect-
assisted performance-sensitive upper limb exercise plat-
form for post-stroke survivors,” Frontiers in Neuroscience,
vol. 13, 2019.

[9] Y. Liao, A. Vakanski, and M. Xian, “A deep learning
framework for assessing physical rehabilitation exercises,”
IEEE Transactions on Neural Systems and Rehabilitation
Engineering, vol. PP, pp. 1–1, 01 2020.

[10] A. Vakanski, H.-p. Jun, D. Paul, and R. Baker, “A data
set of human body movements for physical rehabilitation
exercises,” Data, vol. 3, no. 1, 2018.

[11] P. Vincent, H. Larochelle, Y. Bengio, and P.-A. Manzagol,
“Extracting and composing robust features with denoising
autoencoders,” pp. 1096–1103, 01 2008.

[12] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones,
A. N. Gomez, L. Kaiser, and I. Polosukhin, “Attention is
all you need,” CoRR, vol. abs/1706.03762, 2017.

10

[13] M. Capecci, M. G. Ceravolo, F. Ferracuti, S. Iarlori,
A. Monteri`u, L. Romeo, and F. Verdini, “The kimore
dataset: Kinematic assessment of movement and clinical
scores for remote monitoring of physical rehabilitation,”
IEEE Transactions on Neural Systems and Rehabilitation
Engineering, vol. 27, pp. 1436–1448, 2019.

[14] L. Perez and J. Wang, “The effectiveness of data augmen-
tation in image classiﬁcation using deep learning,” CoRR,
vol. abs/1712.04621, 2017.

[15] J. Liang and R. Liu, “Stacked denoising autoencoder and
dropout
together to prevent overﬁtting in deep neural
network,” in 2015 8th International Congress on Image
and Signal Processing (CISP), pp. 697–701, 2015.
[16] K. He, X. Chen, S. Xie, Y. Li, P. Doll´ar, and R. B. Girshick,
“Masked autoencoders are scalable vision learners,” CoRR,
vol. abs/2111.06377, 2021.

[17] J. Kukacka, V. Golkov, and D. Cremers, “Regularization for
deep learning: A taxonomy,” CoRR, vol. abs/1710.10686,
2017.

[18] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert:
Pre-training of deep bidirectional transformers for language
understanding,” in NAACL, 2019.

[19] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn,
X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer,
G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby, “An
image is worth 16x16 words: Transformers for image
recognition at scale,” CoRR, vol. abs/2010.11929, 2020.

[20] A. Baevski, H. Zhou, A. Mohamed, and M. Auli, “wav2vec
2.0: A framework for self-supervised learning of speech
representations,” CoRR, vol. abs/2006.11477, 2020.
[21] A. Raganato and J. Tiedemann, “An analysis of encoder
representations in transformer-based machine translation,”
pp. 287–297, 01 2018.

[22] Y. Du, W. Wang, and L. Wang, “Hierarchical recurrent
neural network for skeleton based action recognition,”
pp. 1110–1118, 06 2015.

[23] D. Kingma and J. Ba, “Adam: A method for stochastic
optimization,” International Conference on Learning Rep-
resentations, 12 2014.

