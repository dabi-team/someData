0
2
0
2

n
a
J

3
1

]

G
L
.
s
c
[

3
v
3
2
7
4
0
.
9
0
9
1
:
v
i
X
r
a

Neural Networks for Relational Data

Navdeep Kaur1, Gautam Kunapuli1, Saket Joshi2, Kristian Kersting3, and
Sriraam Natarajan1

1 The University of Texas at Dallas
{Navdeep.Kaur, Gautam.Kunapuli, Sriraam.Natarajan}@utdallas.edu
2 Amazon Inc. {saketjoshi@gmail.com}
3 TU Darmstadt, Germany {kersting@cs.tu-darmstadt.de}

Abstract. While deep networks have been enormously successful over
the last decade, they rely on ﬂat-feature vector representations, which
makes them unsuitable for richly structured domains such as those aris-
ing in applications like social network analysis. Such domains rely on
relational representations to capture complex relationships between en-
tities and their attributes. Thus, we consider the problem of learning neu-
ral networks for relational data. We distinguish ourselves from current
approaches that rely on expert hand-coded rules by learning relational
random-walk-based features to capture local structural interactions and
the resulting network architecture. We further exploit parameter tying
of the network weights of the resulting relational neural network, where
instances of the same type share parameters. Our experimental results
across several standard relational data sets demonstrate the eﬀectiveness
of the proposed approach over multiple neural net baselines as well as
state-of-the-art statistical relational models.

Keywords: neural networks · relational models

1

Introduction

While successful, deep networks have a few important limitations. Apart from
the key issue of interpretability, the other major limitation is the requirement
of a ﬂat inputs (vectors, matrics, tensors), which limits applications to tabu-
lar, propositional representations. On the other hand, symbolic and structured
representations [1, 7, 13, 14, 38] have the advantage of being interpretable, while
also allowing for rich representations that allow for learning and reasoning with
multiple levels of abstraction. This representability allows them to model com-
plex data structures such as graphs far more easily and interpretably than basic
propositional representations. While expressive, these models do not incorporate
or discover latent relationships between features as eﬀectively as deep networks.
Consequently, there has been focus on achieving the dream team of logi-
cal and statistical learning methods such as relational neural networks [19, 42].
While speciﬁc architectures diﬀer, these methods generally employ hand-coded
relational rules or Inductive Logic Programming (ILP, [24]) to identify the do-
main’s structural rules; these rules are then used with the observed data to unroll
and learn a neural network. We improve upon these methods in two speciﬁc ways:

 
 
 
 
 
 
2

N. Kaur et al.

(1) we employ a rule learner that has been recently successful to automatically
extract interpretable rules that are then employed as hidden layer of the neural
network; (2) we exploit the notion of parameter tying from the perspective of
statistical relational learning models that allow multiple instances of the same
rule share the same parameter. These two extensions signiﬁcantly improve the
adaptation of neural networks (NNs) for relational data.

We employ Relational Random Walks [22] to extract relational rules from a
database, which are then used as the ﬁrst layer of the NN. These random walks
have the advantages of being learned from data (instead of time-consumingly
hand-coded), and interpretable (as walks are rules in a database schema). Given
evidence (facts), relational random walks are instantiated (grounded); param-
eter tying ensures that groundings of the same random walk share the same
parameters with far fewer network parameters to be learned during training.

For combining outputs from diﬀerent groundings of the same clause, we em-
ploy combination functions [16, 30]. For instance, given a rule: Professor(P),
Author(P, U), Author(S, U), Student(S), the ana-bob Professor-Student pair
could have coauthored 6 papers, while the cam-dan pair could have coauthored
10 publications (U). Combination functions are a natural way to compare such
relational features arising from rules. Our network handles this in two steps: ﬁrst,
by ensuring that all instances (papers) of a particular Professor − Student pair
share the same weights. Second, by combining predictions from each of these in-
stances (papers) using a combination function. We explore the use of Or, Max
and Average combination functions. Once the network weights are appropriately
constrained by parameter tying and combination functions, they can be learned
using standard techniques such as backpropagation.

We make the following contributions: (1) we learn a NN that can be fully
trained from data and with no signiﬁcant engineering, unlike previous approaches;
(2) we combine the successful paradigms of relational random walks and param-
eter tying from SRL methods; this allows the resulting NN to faithfully model
relational data while being fully learnable; (3) we evaluate the proposed approach
against recent relational NN approaches and demonstrate its eﬃcacy.

2 Related Work

Lifted Relational Neural Networks. Our work is closest to Lifted Relational
Neural Networks (LRNN) [42] due to ˇSourek et al., in terms of the architecture.
LRNN uses expert hand-crafted relational rules as input, which are then instanti-
ated (based on data) and rolled out as a ground network. While at a high-level,
our approach appears similar to the LRNN framework, there are signiﬁcant
diﬀerences. First, while ˇSourek et al., exploit tied parameters across examples
within the same rule, there is no parameter tying across multiple instances; our
model, however, ensures parameter tying of multiple ground instances of the rule
(in our case, a relational random walk). Second, since they adopt a fuzzy notion,
their system supports weighted facts (called ground atoms in logic literature).
We take a more standard approach and our observations are Boolean. Third,

Neural Networks for Relational Data

3

while the previous diﬀerence appears to be limiting in our case, note that this
leads to a reduction in the number of network weight parameters.

ˆSourek et al., have extended their work to learn network structure using
predicate invention [45]; our work learns relational random walks as rules for
the network structure. As we show in our experiments, NNs cannot only easily
handle such large number of such random walks, but can also use them eﬀectively
as a bag of weakly predictive intermediate layers capturing local features. This
allows for learning a more robust model than the induced rules, which take a
more global view of the domain. Another recent approach is due to Kazemi and
Poole [19], who proposed a relational neural network by adding hidden layers to
their Relational Logistic Regression [18] model. A key limitation of their work
is that they are restricted to unary relation predictions, that is, they can only
predict attributes of objects instead of relations between. In contrast, ours is a
more general framework in that can be used to predict relations between objects.
Much of this recent work is closely related to a signiﬁcant body of research
called neural-symbolic integration [12], which aims to combine (arguably) two of
the oldest formalisms in machine learning: symbolic representations with neural
learning architectures. Some of the earliest systems such as KBANN [43] date
back to the early 90s; KBANN also rolls out the network architecture from rules,
though it only supports propositional rules. Current work, including ours, instead
explores relational rules which serve as templates to roll out more complex ar-
chitectures. Other recent approaches such as CILP++ [11] and Deep Relational
Machines [26] incorporate relational information as network layers. However,
such models propositionalize relational data into ﬂat-feature vector and hence,
cannot be seen as truly relational models. A rather distinctive approach in this
vein is due to Hu et al. [15], where two independent networks incorporating rules
and data are trained together. Finally, NNs have also been trained to approxi-
mate ILP clause evaluation [8], perform SLD-resolution in ﬁrst-order logic [21],
and approximate entailment operators in propositional logic [10].

Relational Random Walks. The Path Ranking Algorithm (PRA, [22]) is a
key framework, where a combination of random walks replaces exhaustive search
in order to answer queries. Recently, Das et al. [6] considered random walks
between query entities to perform composition of embeddings of relations on each
walk with recurrent neural networks. DeepWalks [34] performs random walks on
graphs by treating each node as a word, which results in learning embeddings
for each node of graph. Kaur et al. [17] consider relational random walks to
generate count and existential features to train a relational restricted Boltzmann
machine [23]. This feature transformation induces propositionalization that could
potentially result in loss of information, as we show in our experiments.

Tensor Based Models. Recently, several tensor-based models [3,4,31,41,47]
have been proposed to learn embeddings of objects and relations. Such models
have been very eﬀective for large-scale knowledge-base construction. However,
they are computationally expensive as they learn parameters for each object and
relation in the knowledge base. Furthermore, the embedding into some ambient
vector space makes the models more diﬃcult to interpret. Though rule distilla-

4

N. Kaur et al.

tion can yield human-readable rules [48], it is another computationally intensive
post-processing step, which limits the size of the interpreted rules.

Other Models. Several NNs have been utilized with relational databases
schemas [2, 37]. These models diﬀer on how they handle 1-to-N joins, cyclicity,
and indirect relationships between relations. However, they all learn one net-
work per relation, which makes them computationally expensive. In the same
vein, graph-based models take graph structure into consideration during train-
ing. Pham et al. [35] perform collective classiﬁcation via a deep neural network
where connections between adjacent layers are established according to given
graph structure. Niepert et al. [32] proposed an algorithm that prepares the re-
lational data to be directly input to standard convolutional network by assigning
an ordering to enable feature convolution. Scarselli et al. [39] proposed Graph
Neural Networks in which one neural network is installed at each node of the
graph, which is trained by obtaining input from all the incoming edges of graph.
One neural network per node makes the model computationally very expensive
Finally, with the rapid growth of deep learning, relational counterparts of most
of existing connectionist models have been also proposed [33, 40, 46, 49].

3 Neural Networks with Relational Parameter Tying

We ﬁrst introduce some notation for relational logic, which is used for relational
representation, with the domain being represented using constants, variables and
predicates. We adopt the following conventions: (1) constants used to represent
entities in the domain are written in lower-case (e.g., ana, bob); (2) variables and
entity types are capitalized (e.g., Student, Professor); and (3) relations and
predicate symbols between entities and attributes are represented as Q(·, ·). A
grounding is a predicate applied to a tuple of terms (i.e., either a full or partial
instantiation), e.g. AdvisedBy(Student, ana), is a partial instantiation.

Rules are constructed from atoms using logical connectives (∧, ∨) and quan-
tiﬁers (∃, ∀). Due to the use of relational random walks, the relational rules that
we employ are universally conjunctions of the form h ⇐ b1 ∧ . . . ∧ b‘, where
the head h is the target of prediction and the body b1 ∧ . . . ∧ b‘ corresponds
to conditions that make up the rule (that is, each literal bi in the body is a
predicate Q(·, ·)). We do not consider negations in this work.

An example rule could be AdvisedBy(S, P) ⇐ Professor(P) ∧ WorksIn(P, T) ∧

PartOf(T, S) ∧ Student(S). This rules states that if a Student is a part of
the project that the Professor works on, then the Student is advised by that
Professor. The body of the rule is learned as a random walk that starts with
Professor and ends with Student. Such a random walk represents a chain of
relations that could possibly connect a Professor to a Student and is a rela-
tional feature that could help in the prediction. The rule head is the target
that we are interested in predicting. Since these rules are essentially “soft” rules,
we can also associate clauses with weights, i.e., weighted rules: (R, w).

A relational neural network N is a set of M weighted rules describing inter-
j=1. We are given a set of atomic facts F, known

actions in the domain {Rj, wj)}M

Neural Networks for Relational Data

5

to be true (the evidence) and labeled relational training examples {(xi, yi)}‘
i=1.
In general, labels yi can take multiple values corresponding to a multi-class prob-
lem. We seek to learn a relational neural network model N ≡ {Rj, wj)}M
j=1 to
predict a Target relation, given relational examples x, that is: y = Target(x).

Given: Set of instances F, Target relation, relational data set (x, y) ∈ D;
Construct (structure learning): Rj, relational random walk rules (relational
feature describing the network structure of N );
Train (parameter learning): wj, rule weights via gradient descent with rule-
based parameter tying to identify a sparse set of network weights of N

Example. The movie domain contains the entity types (variables) Person(P),
Movie(M) and Genre(G). In addition there are relations (features): Directed(P, M),
ActedIn(P, G) and InGenre(M, G). The domain also has relations for entity res-
olution: SamePerson(P1, P2) and SameGenre(G1, G2). The task is to predict if P1
worked under P2, with the target predicate (label): WorkedUnder(P1, P2).

3.1 Generating Lifted Random Walks

The core component of a neural network model is the architecture, which deter-
mines how the various neurons are connected to each other, and ultimately how
all the input features interact with each other. In a relational neural network, the
architecture is determined by the domain structure, or the set of relational rules
that determines how various relations, entities and attributes interact in the do-
main as shown earlier with the AdvisedBy example. While previous approaches
employed carefully hand-crafted rules, we, instead, use relational random walks
to deﬁne the network architecture and model the local relational structure of
the domain. A similar approach was also used by Kaur et al [17], though the
random walk features were used to instantiate a restricted Boltzmann machine,
which has a far more limited architecture and their work is not lifted since it
instantiates the entire network before learning.

Relational data is often represented using a lifted graph, which deﬁnes the
domain’s schema; in such a representation, a relation Predicate(Type1, Type2)
Predicate
is a predicate edge between two type nodes: Type1
−−−−−−→ Type2. A relational
random walk through a graph is a chain of such edges corresponding to a con-
junction of predicates. For a random walk to be semantically sound, we should
ensure that the input type (argument domain) of the (i + 1)-th predicate is the
same as the output type (argument range) of the i-th predicate.

Example (continued). The body of the rule

ActedIn(P1, G1) ∧ SameGenre(G1, G2) ∧ ActedIn−1(G2, P2)∧
SamePerson(P2, P3) ∧ ActedIn−1(P3, M) ∧ Directed(M, P4)⇒ WorkedUnder(P1, P4)

can be represented graphically as

P1

ActedIn
−−−−−→ G1

SameGenre

−−−−−−−−→ G2

ActedIn−1
−−−−−−−→P2

SamePerson

−−−−−−−−→ P3

ActedIn−1
−−−−−−−→ M Directed

−−−−−−→ P4.

6

N. Kaur et al.

Fig. 1. The relational neural network is unrolled in three stages, ensuring that the
output is a function of facts through two hidden layers: the combining rules layer
(with lifted random walks) and the grounding layer (with instantiated random walks).
Weights are tied between the input and grounding layers based on which fact/feature
ultimately contributes to which rule in the combining rules layer.

This is a lifted random walk between two entities P1 → P4 in the target predi-
cate, WorkedUnder(P1, P4). It is semantically sound as it is possible to chain the
second argument of a predicate to the ﬁrst argument of the succeeding predicate.
This walk also contains an inverse predicate ActedIn−1, which is distinct from
ActedIn (since the argument types are reversed).

We use path-constrained random walks [22] approach to generate M lifted ran-
dom walks Rj, j = 1, . . . , M . These random walks form the backbone of the lifted
neural network, as they are templates for various feature combinations in the
domain. They can also be interpreted as domain rules as they impart localized
structure to the domain model, that is, they provide a qualitative description of
the domain. When these rules, or lifted random walks have weights associated
with them, we are then able to endow the rules with a quantitative inﬂuence on
the target predicate. We now describe a novel approach to network instantiation
using these random-walk-based relational features. A key component of the pro-
posed instantiation is rule-based parameter tying, which reduces the number of
network parameters to be learned signiﬁcantly, while still eﬀectively maintaining
the quantitative inﬂuences as described by the relational random walks.

3.2 Network Instantiation

The relational random walks (Rj) generated in the previous subsection are the
relational features of the lifted relational neural network, N . Our goal is to
unroll and ground the network with several intermediate layers that capture
the relationships expressed by the random walks. A key diﬀerence in network
construction between our proposed work and recent approaches such as that of
ˇSourek et al., [44] is that we do not perform an exhaustive grounding to generate
all possible instances before constructing the network. Instead, we only ground

Neural Networks for Relational Data

7

as needed leading to a much more compact network. We unroll the network in
the following manner (cf. Figure 1).

Output Layer: For the Target, which is also the head h in all the rules Rj,
introduce an output neuron called the target neuron, Ah. With one-hot encod-
ing of the target labels, this architecture can handle multi-class problems. The
target neuron uses the softmax activation function. Without loss of generality,
we describe the rest of the network unrolling assuming a single output neuron.
Combining Rules Layer: The target neuron is connected to M lifted
rule neurons, each corresponding to one of the lifted relational random walks,
(Rj, wj). Each rule Rj is a conjunction of predicates deﬁned by random walks:

1(X, ·) ∧ . . . ∧ Qj
Qj

L(·, Z) ⇒ Target(X, Z), j = 1, . . . , M,

(1)

and corresponds to the lifted rule neuron Aj. This layer of neurons is fully
connected to the output layer to ensure that all the lifted random walks (that
capture the domain structure) inﬂuence the output. The extent of their inﬂuence
is determined by learnable weights, uj between Aj and the output neuron Ah.
In Fig. 1, we see that the rule neuron Aj is connected to the neurons Aji;
these neurons correspond to Nj instantiations of the random-walk Rj. The lifted
rule neuron Aj aims to combine the inﬂuence of the groundings/instantiations
of the random-walk feature Rj that are true in the evidence. Thus, each lifted
rule neuron can also be viewed as a rule combination neuron. The activation
function of a rule combination neuron can be any aggregator or combining rule
[30]. This can include value aggregators such as weighted mean, max0 or
distribution aggregators (if inputs to the this layer are probabilities) such as
Noisy-Or. Many such aggregators can be incorporated into the combining rules
layer with appropriate weights (vji) and activation functions of the rule neurons.
For instance, combining rule instantiations out(Aji) with a weighted mean will
require learning vji, with the nodes using unit functions for activation. The
formulation of this layer is much more general and subsumes the approach of
ˇSourek et al [44], which uses a max combination layer.

Grounding Layer: For each instantiated (ground) random walk Rjθi, i =
1, . . . , Nj, we introduce a ground rule neuron, Aji. This ground rule neuron
represents the i-th instantiation (grounding) of the body of the j-th rule, Rjθi:
1θi ∧ . . . ∧ Qj
Qj
‘θi (cf. eqn 1). The activation function of a ground rule neuron is
a logical AND (∧); it is only activated when all its constituent inputs are true
(that is, only when the entire instantiation is true in the evidence).

This requires all the constituent facts Qj

‘θi to be in the evidence.
Thus, the (j, i)-th ground rule neuron is connected to all the fact neurons that
appear in its corresponding instantiated rule body. A key novelty of our approach
is regarding relational parameter tying: the weights of connections between the
fact and grounding layers are tied by the rule these facts appear in together.
This is described in detail further below.

1θi, . . . , Qj

Input Layer: Each instantiated (grounded) predicate that appears as a part
of an instantiated rule body is a fact, that is Qj
kθi ∈ F. For each such instantiated
fact, we create a fact neuron Af , ensuring that each unique fact in evidence has

8

N. Kaur et al.

Fig. 2. Example: unrolling the network with relational parameter tying.

only one single neuron associated with it. Every example is a collection of facts,
that is, example xi ≡ Fi ⊂ F. Thus, an example is input into the system by
simply activating its constituent facts in the input layer.

Relational Parameter Tying: The most important thing to note about
this construction is that we employ rule-based parameter tying for the weights
between the grounding layer and the input/facts layer. Parameter tying ensures
that instances corresponding to an example all share the same weight wj if they
occur in the same lifted rule Rj. The shared weights wj are propagated through
the network in a bottom-up fashion, ensuring that weights in the succeeding
hidden layers are inﬂuenced by them.

Our approach to parameter tying is in sharp contrast to that of ˇSourek et
al., [44], who learn the weights of the network edges between the output layer
and the combining rules layer. Furthermore, they also use fuzzy facts (weighted
instances), whereas in our case, the facts/instances are Boolean, though their
edge weights are tied. Our approach also diﬀers from that of Kaur et al., [17] who
also use relational random walks. From a parametric standpoint, Kaur et al., used
relational random walks as features for a restricted Boltzmann machine, where
the instance neurons and the rule neurons form a bipartite graph. Thus, the
relational RBM formulation has signiﬁcantly more edges, and commensurately
many more parameters to optimize during learning.

Example (continued, see Fig. 2). Consider two lifted random walks (R1, w1)
and (R2, w2) for the target predicate WorkedUnder(P1, P2)

WorkedUnder(P1, P2) ⇐ActedIn(P1, M) ∧ Directed−1(M, P2),
WorkedUnder(P1, P2) ⇐SamePerson(P1, P3) ∧ ActedIn(P3, M) ∧ Directed−1(M, P2).

Note that while the inverse predicate Directed−1(M, P) is syntactically diﬀerent
from Directed(P, M) (argument order is reversed), they are both semantically
same. The output layer consists of a single neuron Ah corresponding to the bi-
nary target WorkedUnder. The lifted rule layer (also known as combining rules
layer) has two lifted rule nodes A1 corresponding to rule R1 and A2 corresponding
to rule R2. These rule nodes combine inputs corresponding to instantiations that
are true in the evidence. The network is unrolled based on the speciﬁc training

Neural Networks for Relational Data

9

example, for instance: WorkedUnder(Leo, Marty). For this example, the rule R1
has two instantiations that are true in the evidence. Then, we introduce a ground
rule node for each such instantiation:

A11 :ActedIn(Leo, ”TheDeparted”) ∧ Directed−1(”TheDeparted”, Marty),
A12 :ActedIn(Leo, ”TheAviator”) ∧ Directed−1(”TheAviator”, Marty).

The rule R2 has only one instantiation, and consequently only one node:

A21 :SamePerson(Leo, Leonardo) ∧ ActedIn(Leo, ”TheDeparted”)

∧ Directed−1(”TheDeparted”, Marty).

The grounding layer consists of ground rule nodes corresponding to instantia-
tions of rules that are true in the evidence. The edges Aji → Aj have weights vji
that depend on the combining rule implemented in Aj. In this example, the com-
bining rule is average, so we have v11 = v12 = 1
2 and v21 = 1. The input layer
consists of atomics fact in evidence: f ∈ F. The fact nodes ActedIn(Leo, ”TheAviator”)
and Directed−1(”TheAviator”, Marty) appear in the grounding R1θ2 and are
connected to the corresponding ground rule neuron A12. Finally, parameters are
tied on the edges between the facts layer and the grounding layer. This ensures
that all facts that ultimately contribute to a rule are pooled together, which in-
creases the inﬂuence of the rule during weight learning. This, in turn, ensures
that a rule that holds strongly in the evidence gets a higher weight.

Once the network N θ is instantiated, the weights wj and uj can be learned
using standard techniques such as backpropagation. We denote our approach
Neural Networks with Relational Parameter Tying (NNRPT). The tied parame-
ters incorporate the structure captured by the relational features (lifted random
walks), leading to a network with signiﬁcantly fewer weights, while also endow-
ing the it with semantic interpretability regarding the discriminative power of
the relational features. We now demonstrate the importance of parameter tying
and the use of relational random walks as compared to previous frameworks.

4 Experiments

Our empirical evaluation aims to answer the following questions explicitly4: Q1:]
How does NNRPT compare to the state-of-the-art SRL models i.e., what the value
of learning a neural net over standard models? Q2: How does NNRPT compare
to propositionalization models i.e., what is the need for parameterization of
standard neural networks? Q3: How does NNRPT compare to other relational
neural networks in literature?

4 https://github.com/navdeepkjohal/NNRPT

10

N. Kaur et al.

Data Sets: We use ﬁve standard data sets to evaluate our algorithm (see Table
1): Uw-Cse. [38] is a standard data set that consists of predicates and rela-
tions such as Professor, Student, Publication, HasPosition and TaughtBy
etc. The data set contains information from 5 diﬀerent areas of computer science
about professors, students and courses, and the task is to predict the AdvisedBy
relationship between a professor and a student. Imdb was ﬁrst created by Mi-
halkova and Mooney [27] and contains nine predicates such as Gender, Genre,
Movie, and Director. We predict whether an actor has WorkedUnder a direc-
tor. Cora is a citation matching data set modiﬁed by Poon and Domingos [36].
It contains predicates Author, Title, Venue, HasWordAuthor, HasWordTitle,
HasWordVenue, SameAuthor, and SameTitle. The task is to predict if one venue
is SameVenue as another.

Mutagenesis [25] was originally used to predict whether a compound is
mutagenetic or not. It consists of properties of compounds, their constituent
atoms and the type of bond that exists between atoms. We performed rela-
tion prediction of whether an atom is a constituent of a given molecule or
not (MoleAtm(AtomID, MolID)). Sports consists of facts from the sports domain
crawled by the Never-Ending Language Learner (NELL, [5]) including details of
players, sports, individual plays, league information etc. The goal is to predict
which sport a particular team plays.

Table 1. Data sets used in our experiments to answer Q1–Q3. The last column shows
the number of sampled groundings of random walks per example for NNRPT.

Domain
Uw-Cse
Mutagenesis
Cora
Imdb
Sports

Target
advisedBy
MoleAtm
SameVenue
WorkedUnder

90

#Facts #Pos #Neg #RW #Samp/RW
2817
180 2500
29986 1000 2000 100
31086 2331 4662 100
80
200

1000
100
100
-
100

305
200

710
400

914
TeamPlaysSport 7824

Baselines and Experimental Details: To answer Q1, we compare NNRPT with
the more recent and state-of-the-art relational gradient-boosting methods, RDN-
Boost [29], MLN-Boost [20], and relational restricted Boltzmann machines RRBM-
E, RRBM-C [17]. As the random walks chain binary predicates in our model, we
convert unary and ternary predicates into binary predicates for all data sets.
Further, to maintain consistency in experimentation, we use the same resulting
predicates across all our baselines as well. We run RDN-Boost and MLN-Boost with
their default settings and learn 20 trees for each model. Also, we train RRBM-E
and RRBM-C according to the settings recommended in [17].

For NNRPT, we generate random walks by considering each predicate and its
inverse to be two distinct predicates. Also, we avoid loops in the random walks
by enforcing sanity constraints on the random walk generation. We consider 100
random walks for Mutagenesis, Cora, 80 random walks for Imdb, 200 ran-
dom walks for Sports and 2500 random walks for Uw-Cse as suggested by

Neural Networks for Relational Data

11

Table 2. Comparison of diﬀerent learning algorithms based on AUC-ROC and AUC-
PR. NNRPT is comparable or better than standard SRL methods across all data sets.

Data Set Measure

RDN-Boost

MLN-Boost

RRBM-E

RRBM-C

NNRPT

Uw-Cse

Imdb

Cora

Mutag.

Sports

AUC-ROC 0.973±0.014 0.968±0.014 0.975±0.013 0.968±0.011 0.959±0.024
0.931±0.036 0.916±0.035 0.923±0.056 0.924±0.040 0.896±0.063
AUC-PR
AUC-ROC 0.955±0.046 0.944±0.070 1.000±0.000 0.997±0.006 0.984±0.025
AUC-PR
0.863±0.112 0.839±0.169 1.000±0.000 0.992±0.017 0.951±0.082
AUC-ROC 0.895±0.183 0.835±0.035 0.984±0.009 0.867±0.041 0.952±0.043
0.833±0.259 0.799±0.034 0.948±0.042 0.825±0.050 0.899±0.070
AUC-PR
AUC-ROC 0.999±0.000 0.999±0.000 0.999±0.000 0.998±0.001 0.981±0.024
AUC-PR
0.999±0.000 0.999±0.000 0.999±0.000 0.997±0.002 0.970±0.039
AUC-ROC 0.801±0.026 0.806±0.016 0.760±0.016 0.656±0.071 0.780±0.026
0.670±0.028 0.652±0.032 0.634±0.020 0.648±0.085 0.668±0.070
AUC-PR

Kaur et al [17] (see Table 1). Since we use a large number of random walks, ex-
haustive grounding becomes prohibitively expensive. To overcome this, we sample
groundings for each random walk for large data sets. Speciﬁcally, we sample 100
groundings per random walk per example for Cora, Sports, Mutagenesis,
and 1000 groundings per random walk per example for Uw-Cse (see Table 1).
For all experiments, we set the positive to negative example ratio to be 1 : 2
for training, set combination function to be average and perform 5-fold cross
validation. For NNRPT, we set the learning rate to be 0.05, batch size to 1, and
number of epochs to 1. We train our model with L1-regularized AdaGrad [9].
Since these are relational data sets where the data is skewed, AUC-PR and
AUC-ROC are better measures than likelihood and accuracy.

To answer Q2, we generated ﬂat feature vectors by Bottom Clause Proposi-
tionalization (BCP, [11]), according to which one bottom clause is generated for
each example. BCP considers each predicate in the body of the bottom clause as
a unique feature when it propositionalizes bottom clauses to ﬂat feature vector.
We use Progol [28] to generate these bottom clauses. After propositionalization,
we train two connectionist models: a propositionalized restricted Boltzmann ma-
chine (BCP-RBM) and a propositionalized neural network (BCP-NN). The NN has
two hidden layers in our experiments, which makes BCP-NN model a modiﬁed
version of CILP++ [11] that had one hidden layer. The hyper-parameters of
both the models were optimized by line search on validation set.

To answer Q3, we compare our model with Lifted Relational Neural Networks
(LRNN, [44]). To ensure fairness, we perform structure learning by using PROGOL
[28] and input the same clauses to both LRNN and NNRPT. PROGOL learned 4
clauses for Cora, 8 clauses for Imdb, 3 clauses for Sports, 10 clauses for Uw-
Cse and 11 clauses for Mutagenesis in our experiment.

Results: Table 2 compares our NNRPT to MLN-Boost, RDN-Boost, RRBM-E and
RRBM-C to answer Q1. As we see, NNRPT is signiﬁcantly better than RRBM-C for

12

N. Kaur et al.

Table 3. Comparison of NNRPT with propositionalization-based approaches. NNRPT is
signiﬁcantly better on a majority of data sets.

Data Set Measure

BCP-RBM

BCP-NN

NNRPT

Uw-Cse

Imdb

Cora

Mutag.

Sports

AUC-ROC 0.951±0.041 0.868±0.053 0.959±0.024
0.860±0.114 0.869±0.033 0.896±0.063
AUC-PR
AUC-ROC 0.780±0.164 0.540±0.152 0.984±0.025
AUC-PR
0.367±0.139 0.536±0.231 0.951±0.082
AUC-ROC 0.801±0.017 0.670±0.064 0.952±0.043
AUC-PR
0.647±0.050 0.658±0.064 0.899±0.070
AUC-ROC 0.991±0.003 0.945±0.019 0.981±0.024
AUC-PR
0.995±0.001 0.973±0.012 0.970±0.039
AUC-ROC 0.664±0.021 0.543±0.037 0.780±0.026
0.532±0.041 0.499±0.065 0.668±0.070
AUC-PR

Cora and Sports on both AUC-ROC and AUC-PR, and performs comparably
to the other data sets. It also performs better than MLN-Boost, RDN-Boost on
Imdb and Cora data sets, and comparably on other data sets. Similarly, it
performs better than RRBM-E on Sports, both on AUC-ROC and AUC-PR and
comparably on other data sets. Broadly, Q1 can be answered aﬃrmatively in
that NNRPT performs comparably to or better than state-of-the-art SRL models.

Table 3 shows the comparison of NNRPT with two propositionalization models:
BCP-RBM and BCP-NN in order to answer Q2. NNRPT performs better than BCP-RBM
on all the data sets except Mutagenesis, where the two models have similar
performance. NNRPT also performs better than BCP-NN on all data sets. It should
be noted that BCP feature generation sometimes introduces a large positive-to-
negative example skew (for example, in the Imdb data set), which can sometimes
gravely aﬀect the performance of the propositional model, as we observe in Table
3. This emphasizes the need for designing models that can handle relational
data directly and without propositionalization; our proposed model as an eﬀort
in this direction. Q2 can now be answered aﬃrmatively: that NNRPT performs
better than propositionalization models.

Table 4 compares the performance of NNRPT and LRNN when both use clauses
learned by PROGOL [28]. NNRPT performs better on Uw-Cse, Sports evalu-
ated using AUC-PR. This result is especially signiﬁcant because these data sets
are considerably skewed. NNRPT also outperforms LRNN on Cora and Mutage-
nesis. Lastly, NNRPT has comparable performance on Imdb on both AUC-ROC
and AUC-PR. The reason for this big performance gap between the two mod-
els on Cora is likely because LRNN could not build eﬀective models with the
fewer number of clauses (i.e. four) typically learned by PROGOL. In contrast,
even with very few clauses, NNRPT is able to outperform LRNN. This helps us an-
swer Q3, aﬃrmatively, that: NNRPT oﬀers many advantages over state-of-the-art
relational neural networks.

Neural Networks for Relational Data

13

Table 4. Comparison of NNRPT and LRNN on AUC-ROC and AUC-PR on diﬀerent data
sets. Both the models were provided clauses learnt by PROGOL, [28]. NNRPT is capable
of employing rules to improve performance in some data sets.

Model Measure Uw-Cse

Imdb

Cora

Mutagen. Sports

LRNN

NNRPT

AUC-ROC 0.923±0.027 0.995±0.004 0.503±0.003 0.500±0.000 0.741±0.016
AUC-PR 0.826±0.056 0.985±0.013 0.356±0.006 0.335±0.000 0.527±0.036
AUC-ROC 0.700±0.186 0.997±0.007 0.968±0.022 0.532±0.019 0.657±0.014
AUC-PR 0.910±0.072 0.992±0.017 0.943±0.032 0.412±0.032 0.658±0.056

In summary, our experiments clearly show the beneﬁts of parameter tying
as well as the expressivity of relational random walks in tightly integrating with
a neural network model across a wide variety of domains and settings. The key
strengths of NNRPT are that it can (1) eﬃciently incorporate a large number
of relational features, (2) capture local qualitative structure through relational
random walk features, (3) tie feature weights (parameter-tying) in a manner that
captures the global quantitative inﬂuences.

Discussion: A typical convolutional neural network (CNN) is composed of three
layers: convolution, max-pooling and (fully-connected) output layers. NNRPT can
be considered a special instance of a convolutional network in relational domains,
where the fact-grounding layer edges are the equivalent of convolution, combining
rules layer represents pooling, and softmax layer is the fully-connected layer. If
we perform a full and exhaustive grounding of the neural network in NNRPT,
M is the number of lifted random walks (template rules), N is the number of
grounded random walks (instances of a template rule) and |F| is the number of
all facts (atomic instances). The data can be represented as a three-dimensional
tensor B of size M × N × |F|, whose elements are precisely Bijk = Qj
kθi (see
the discussion of the Input Layer in Section 3.2). In addition, if we consider the
rule layer as tensor T = M × 1 × |F|, where parameters are tied across |F|,
then [wm1f ]M
m=1 constitutes the convolving ﬁlter that is repeatedly applied to
each of |F| ground instances. The resulting tensor G = M × N × 1 obtained by
composing G = D ◦ T representing the output of grounded layer passes through
a pooling layer (which is the rule-combination layer, here) to downsample the
data produce a new tensor C = M × 1 × 1. The tensor C, when composed with
the fully-connected non-linear layer F = M × |O| of our model produces tensor
of size 1 × |O| that represents the probability of each class in the output: O.

5 Conclusion and Future Work

We considered the problem of learning neural networks from relational data. Our
proposed architecture was able to exploit parameter tying i.e., diﬀerent instances
of the same rule shared the same parameters inside the same training example.
In addition, we explored the use of relational random walks to create relational
features for training these neural nets. Further experiments on larger data sets

14

N. Kaur et al.

could yield insights into the scalability of this approach. Integration with an
approximate-counting method could potentially reduce the training time. Given
the relation to CNNs, stacking could allow for our method to be deeper. Finally,
understanding the use of such random-walk-based neural network as a function
approximator can allow for eﬃcient and interpretable learning in relational do-
mains with minimal feature engineering.

Acknowledgements: SN, GK & NK gratefully acknowledge AFOSR award
FA9550-18-1-0462. The authors acknowledge the support of Amazon faculty
award. KK acknowledges the support of the RMU project DeCoDeML. Any
opinions, ﬁndings, and conclusion or recommendations expressed in this ma-
terial are those of the authors and do not necessarily reﬂect the view of the
AFOSR, Amazon, DeCoDeML or the US government.

References

1. Bach, S., Broecheler, M., Huang, B., Getoor, L.: Hinge-loss Markov random ﬁelds

and probabilistic soft logic. JMLR (2017)

2. Blockeel, H., Uwents, W.: Using neural networks for relational learning. In: ICML

Workshop (2004)

3. Bordes, A., Glorot, X., Weston, J., Bengio, Y.: Joint learning of words and meaning

representations for open-text semantic parsing. In: AISTATS (2012)

4. Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., Yakhnenko, O.: Translating

embeddings for modeling multi-relational data. In: NeurIPS (2013)

5. Carlson, A., Betteridge, J., Kisiel, B., Settles, B., Hruschka, Jr., E.R., Mitchell,
T.M.: Toward an architecture for never-ending language learning. In: AAAI (2010)
6. Das, R., Neelakantan, A., Belanger, D., McCallum, A.: Chains of reasoning over
entities, relations, and text using recurrent neural networks. In: EACL (2017)
7. De Raedt, L., Kersting, K., Natarajan, S., Poole, D.: Statistical Relational Artiﬁcial
Intelligence: Logic, Probability, and Computation. Morgan & Claypool (2016)
8. DiMaio, F., Shavlik, J.: Learning an approximation to inductive logic programming

clause evaluation. In: ILP (2004)

9. Duchi, J., Hazan, E., Singer, Y.: Adaptive subgradient methods for online learning

and stochastic optimization. JMLR (2011)

10. Evans, R., et al.: Can neural networks understand logical entailment? ICLR (2018)
11. Fran¸ca, M.V.M., Zaverucha, G., d’Avila Garcez, A.S.: Fast relational learning using
bottom clause propositionalization with artiﬁcial neural networks. MLJ (2014)
12. Garcez, A.S.d., Gabbay, D.M., Broda, K.B.: Neural-Symbolic Learning System:

Foundations and Applications. Springer-Verlag (2002)

13. Getoor, L., Friedman, N., Koller, D., Pfeﬀer, A.: Learning probabilistic relational

models. RDM (2001)

14. Getoor, L., Taskar, B.: Introduction to Statistical Relational Learning. MIT Press

(2007)

15. Hu, Z., Ma, X., Liu, Z., Hovy, E.H., Xing, E.P.: Harnessing deep neural networks

with logic rules. In: ACL (2016)

16. Jaeger, M.: Parameter learning for relational bayesian networks. In: ICML (2007)
17. Kaur, N., Kunapuli, G., Khot, T., Kersting, K., Cohen, W., Natarajan, S.: Rela-
tional restricted boltzmann machines: A probabilistic logic learning approach. In:
ILP (2017)

Neural Networks for Relational Data

15

18. Kazemi, S.M., Buchman, D., Kersting, K., Natarajan, S., Poole, D.: Relational

logistic regression. In: KR (2014)

19. Kazemi, S.M., Poole, D.: RelNN: A deep neural model for relational learning. In:

AAAI (2018)

20. Khot, T., Natarajan, S., Kersting, K., Shavlik, J.: Learning Markov logic networks

via functional gradient boosting. In: ICDM (2011)

21. Komendantskaya, E.: First-order deduction in neural networks. In: LATA (2007)
22. Lao, N., Cohen, W.: Relational retrieval using a combination of path-constrained

random walks. JMLR (2010)

23. Larochelle, H., Bengio, Y.: Classiﬁcation using discriminative restricted boltzmann

machines. In: ICML (2008)

24. Lavrac, N., Dˇzeroski, v.: Inductive Logic Programming: Techniques and Applica-

tions. Prentice Hall (1993)

25. Lodhi, H., Muggleton, S.: Is mutagenesis still challenging ? In: ILP (2005)
26. Lodhi, H.: Deep relational machines. In: ICONIP (2013)
27. Mihalkova, L., Mooney, R.: Bottom-up learning of Markov logic network structure.

In: ICML (2007)

28. Muggleton, S.: Inverse entailment and Progol. New Generation Computing (1995)
29. Natarajan, S., Khot, T., Kersting, K., Guttmann, B., Shavlik, J.: Gradient-based
boosting for statistical relational learning: Relational dependency network case.
MLJ (2012)

30. Natarajan, S., Tadepalli, P., Dietterich, T.G., Fern, A.: Learning ﬁrst-order prob-

abilistic models with combining rules. ANN MATH ARTIF INTEL (2008)

31. Nickel, M., Tresp, V., Kriegel, H.P.: A three-way model for collective learning on

multirelational data. In: ICML (2011)

32. Niepert, M., Ahmed, M., Kutzkov, K.: Learning convolutional neural networks for

graphs. In: ICML (2016)

33. Palm, R.B., Paquet, U., Winther, O.: Recurrent relational networks for complex

relational reasoning. In: ICLR (2018)

34. Perozzi, B., Al-Rfou’, R., Skiena, S.: Deepwalk: online learning of social represen-

tations. In: KDD (2014)

35. Pham, T., Tran, T., Phung, D.Q., Venkatesh, S.: Column networks for collective

classiﬁcation. In: AAAI (2016)

36. Poon, H., Domingos, P.: Joint inference in information extraction. In: AAAI (2007)
37. Ramon, J., Raedt, L.D.: Multi instance neural network. In: ICML Workshop (2000)
38. Richardson, M., Domingos, P.: Markov logic networks. MLJ (2006)
39. Scarselli, F., Gori, M., Tsoi, A.C., Hagenbuchner, M., Monfardini, G.: The graph

neural network model. IEEE Transactions on Neural Networks (2009)

40. Schlichtkrull, M., Kipf, T.N., Bloem, P., van den Berg, R., Titov, I., Welling, M.:
Modeling relational data with graph convolutional networks. In: ESWC (2018)
41. Socher, R., Chen, D., Manning, C., Ng, A.: Reasoning with neural tensor networks

for knowledge base completion. In: NeurIPS (2013)

42. ˇSourek, G., Manandhar, S., ˇZelezn´y, F., Schockaert, S., Kuˇzelka, O.: Learning
predictive categories using lifted relational neural networks. In: ILP (2016)

43. Towell, G.G., Shavlik, J.W., Noordewier, M.O.: Reﬁnement of approximate domain

theories by knowledge-based neural networks. In: AAAI (1990)

44. ˇSourek, G., Aschenbrenner, V., ˇZelezny, F., Kuˇzelka, O.: Lifted relational neural

networks. In: NeurIPS Workshop (2015)

45. ˇSourek, G., Svatoˇs, M., ˇZelezn´y, F., Schockaert, S., Kuˇzelka, O.: Stacked structure

learning for lifted relational neural networks. In: ILP (2017)

16

N. Kaur et al.

46. Wang, H., Shi, X., Yeung, D.: Relational stacked denoising autoencoder for tag

recommendation. In: AAAI (2015)

47. Wang, Z., Zhang, J., Feng, J., Chen, Z.: Knowledge graph embedding by translating

on hyperplanes. In: AAAI (2014)

48. Yang, B., Yih, W.T., He, X., Gao, J., Deng, L.: Embedding entitities and relations

for learning and inference in knowledge bases. In: ICLR (2015)

49. Zeng, D., Liu, K., Lai, S., Zhou, G., Zhao, J.: Relation classiﬁcation via convolu-

tional deep neural network. In: COLING (2014)

