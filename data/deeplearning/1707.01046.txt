How Noisy Data Affects Geometric Semantic
Genetic Programming

Luis F. Miranda
Luiz Otavio V. B. Oliveira
luisfmiranda@dcc.ufmg.br
luizvbo@dcc.ufmg.br
Computer Science Department
Universidade Federal de Minas Gerais
Belo Horizonte, Brazil

Joao Francisco B. S. Martins
Gisele L. Pappa
joaofbsm@dcc.ufmg.br
glpappa@dcc.ufmg.br
Computer Science Department
Universidade Federal de Minas Gerais
Belo Horizonte, Brazil

7
1
0
2

l
u
J

4

]
E
N
.
s
c
[

1
v
6
4
0
1
0
.
7
0
7
1
:
v
i
X
r
a

ABSTRACT
Noise is a consequence of acquiring and pre-processing data from
the environment, and shows fluctuations from different sources—
e.g., from sensors, signal processing technology or even human
error. As a machine learning technique, Genetic Programming
(GP) is not immune to this problem, which the field has frequently
addressed. Recently, Geometric Semantic Genetic Programming
(GSGP), a semantic-aware branch of GP, has shown robustness and
high generalization capability. Researchers believe these charac-
teristics may be associated with a lower sensibility to noisy data.
However, there is no systematic study on this matter. This paper per-
forms a deep analysis of the GSGP performance over the presence
of noise. Using 15 synthetic datasets where noise can be controlled,
we added different ratios of noise to the data and compared the
results obtained with those of a canonical GP. The results show that,
as we increase the percentage of noisy instances, the generalization
performance degradation is more pronounced in GSGP than GP.
However, in general, GSGP is more robust to noise than GP in the
presence of up to 10% of noise, and presents no statistical difference
for values higher than that in the test bed.

CCS CONCEPTS
•Computing methodologies → Genetic programming; Super-
vised learning by regression;

KEYWORDS
symbolic regression, geometric semantic genetic programming,
noise impact

ACM Reference format:
Luis F. Miranda, Luiz Otavio V. B. Oliveira, Joao Francisco B. S. Martins,
and Gisele L. Pappa. 2017. How Noisy Data Affects Geometric Semantic
Genetic Programming. In Proceedings of GECCO ’17, Berlin, Germany, July
15-19, 2017, 8 pages.
DOI: http://dx.doi.org/10.1145/3071178.3071300

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
GECCO ’17, Berlin, Germany
© 2017 Copyright held by the owner/author(s). Publication rights licensed to ACM.
978-1-4503-4920-8/17/07. . . $15.00
DOI: http://dx.doi.org/10.1145/3071178.3071300

1 INTRODUCTION
The presence of noise in data is an issue recurrently approached
in the machine learning field. Noisy data can highly influence the
performance of machine learning techniques, leading to overfitting
and poor data generalization [15]. We define noise as anything that
obscures the relationship between the predictor variables and the
target variable of a problem [8]. In classification and regression
problems, noise can be found in the input (predictor) variables, in
the output (target) variable or both, and is usually the result of
non-systematic errors during the process of data generation.

In the context of regression problems, robust regression methods
have been proposed to address noisy data points or outliers1, and
also to deal with other data assumptions most regression methods
do not respect [17], such as the independence between the input
variables. Although not very popular for some time due to its
computational cost, robust regression provide an alternative to deal
with noise. When modeling Genetic Programming (GP) to solve
symbolic regression problems, only a few studies have looked at the
impact of noise on the results of data generalization and overfitting
[2, 6, 9, 20].

Instead, the community has given great focus to the relations
between complexity, overfitting and generalization, and its relation
to bloat and parsimony [7, 23]. These are indeed close-related issues
in GP, but they do not account for problems that are not inherent
to the GP search, but intrinsic to the input data. A few works have
also investigated this matter considering the behavior of the GP
when additive noise is added to the input data [2, 6, 9, 20].

The main objective of this work is not to look at how canonical
GP deals with noise, but rather investigate how GPs that take
semantics into account deal with the problem when compared to
GP. A few papers in the literature have claimed Geometric Semantic
Genetic Programming (GSGP) to be more robust to overfitting—
which can be caused by noisy data points—when compared to
canonical GP techniques [3, 4, 21, 22, 25]. At first, this might be even
counter-intuitive, as the exponential growth of solutions caused
by GSGP might even worsen the effects of overfitting. However,
no systematic study has been performed to assess whether and
in which situations this might be true, and how noisy data points
affect the performance of GSGP.

1We consider that both noisy points and outliers are out of pattern instances that
should be identified. We do not go into the merit of whether a noisy point may be
actually useful to the task and represent an outlier.

 
 
 
 
 
 
GECCO ’17, July 15-19, 2017, Berlin, Germany

Luis F. Miranda et al.

We are particularly interested in noise found in the output vari-
able of symbolic regression problems. This is because GSGP oper-
ates in a semantic space, guided by the vector of outputs defined
by the training set. Hence, noise in the output has a much bigger
impact in the search process in GSGP than noise in the predicted
variables.

In order to investigate the impacts of noise, we systematically
introduced additive noise to a set of 15 artificial datasets from the
literature. We evaluated how increasing noise affected the results
of error of the methods in both the training and test sets, using a
total of 165 versions of the datasets. We also adapted two measures
from the classification literature that capture the noise robustness
of a method, and present results for these measures in the datasets
considered.

In general, our results show that, although GSGP performs bet-
ter in low levels of noise, as we increase the percentage of noisy
instances, the performance of GSGP and GP tend to approximate.

2 GEOMETRIC SEMANTIC GENETIC

PROGRAMMING

Previous GP works have shown that the evolutionary search can
be improved through the inclusion of semantic information [24].
Among them, the Geometric Semantic GP (GSGP) introduces geo-
metric semantic crossover and mutation operators that, acting on
the syntax of the parent programs, produce offspring with known
semantic properties [14].

From the symbolic regression perspective, given a training set
T = {(xi , yi )}n
i=1—where (xi , yi ) ∈ Rd × R (i = 1, 2, . . . , n)—the
semantics of an individual representing a program p, denoted by
s(p), is defined as the vector of outputs it produces when applied to
the set of inputs defined by T , i.e., s(p) = [p(x1), p(x2), . . . , p(xn )].
This definition allows the semantics of any program to be straight-
forwardly represented in a n-dimensional semantic space S, where
n is the size of the training set. Notice that the target output vector
defined by the training set—given by t = [y1, y2, . . . , yn ]—is also
representable in S.

The Geometric Semantic Crossover (GSX) operator combines
two parent individuals, p1 and p2, generating an offspring placed
in the metric segment in S connecting both parents:

GSX (p1, p2) = r · p1 + (1 − r ) · p2 ,
where r is a random real constant in [0, 1] (for fitness function based
on Euclidean distance) or a random real function with codomain
[0, 1] (for fitness function based on Manhattan distance).

(1)

The Geometric Semantic Mutation (GSM) operator, in turn, pro-
duces semantic perturbations to a given individual p, such that its
resulting semantics is placed in a ball with radius ε, proportional
to the mutation step ms, as given by:

GSM(p) = p + ms · (tr1 − tr2) ,

(2)

where tr1 and tr2 are real functions randomly generated.

Figure 1 shows the representation of the geometric semantic
operators in the semantic space with a Manhattan-based fitness
function. The resulting offspring of these operators over the seman-
tics of p1 and p2 are placed in the grey area.

(a)

(b)

Figure 1: Geometric representation of the geometric se-
mantic (a) crossover and (b) mutation operators in two-
dimensional semantic spaces for fitness function based on
Manhattan distance.

3 RELATED WORK
As previously mentioned, the GP community has given a lot of
attention to the relations between complexity, overfitting and gen-
eralization, and their association to bloat and parsimony [7, 23].
This section focuses specifically on works performed to analyze
and minimize the effects of noisy data in GP. In addition, to the
best of our knowledge, so far there are no measures to quantify
the impact of noise in GP-induced models for symbolic regression
problems. Thus, we also present an overview of techniques to mea-
sure the impact of noisy data on the performance of classification
techniques, which we adapted to the regression domain.

3.1 Genetic Programming with Noisy Data
Different strategies have been proposed in symbolic regression to
investigate and minimize the impact of noisy data on the search
performed by GP. On the one hand, one can try to filter out noise
data before performing the regression. On the other hand, one can
improve the methods to simply deal with the problem—a much
more common approach.

Following the first strategy, Sivapragasam et al. [20] use Singular
Spectrum Analysis (SSA) to filter out the noise components before
performing the symbolic regression of a short time series of fort-
night river flow. The experimental study indicates that when the
stochastic (noise) components are removed from short and noisy
time-series, the short-lead forecasts can be improved.

Regarding methods that try to deal with the problem, Borrelli et
al. [2] employ a Pareto multi-objective GP for symbolic regression
of time series with additive and multiplicative noise. The authors
adopt two different configurations employing statistical metrics for
the fitness objectives: (1) the Mean Squared Error (MSE) combined
with the first two momenta and (2) the MSE with the skewness
added to the kurtosis—all the measures computed regarding the de-
sired and evaluated outputs. An experimental analysis considering
time series generated from 50 functions from the literature shows
that, although reducing overfitting and bloat, the multi-objective
approach does not perform well when the noise level is too high.
However, for moderate noise levels, the approach can successfully
discover the trend of the series.

How Noisy Data Affects Geometric Semantic
Genetic Programming

De Falco et al. [6], in turn, present two GP methods guided by
context-free grammars with different fitness functions that take
parsimony and the simplicity of the solutions into account. The
Parsimony-based Fitness Algorithm (PFA) and Solomonoff-based
Fitness Algorithm (SFA) adopt fitness functions based, respectively,
on parsimony ideas and on Solomonoff probability induction con-
cepts. These methods are compared in four datasets generated from
known functions, with five different levels of additive noise. The
experimental analysis indicates that the SFA achieves smaller error
when compared to PFA for all the datasets and levels of noise.

Imada and Ross [9] also present a fitness function, alternative to
functions based on the sum of errors, where the scores are deter-
mined by the sum of the normalized differences between the target
and evaluated values, regarding different statistical features. The
experimental analysis in two datasets with two levels of additive
noise shows that the proposed fitness function outperforms the
fitness based on the sum of errors.

Although the above works handle noise in the symbolic regres-
sion context, there is a lack of studies directed to quantify the
impact of the noise in GP-based regression methods. The next sec-
tion presents measures adopted to quantify the influence of noise
in classification algorithms from the machine learning literature.
In Section 4 we select—and adapt—these metrics to apply to our
regression test bed.

3.2 Quantifying Noise Robustness
When a machine learning method is capable of inducing models
that are not influenced by the presence of noise in data, we say it is
robust to noise—i.e., the more robust a method is to noise, the more
similar are the models it induces from data with and without noise
[19].

Following this premise, works in the classification literature
adopt measures that compare the performance of models induced
in the presence and absence of noise in the dataset, in order to
evaluate the robustness of the learner. Here we introduce three
of these metrics: relative risk bias, relative loss of accuracy and
equalized loss of accuracy.

The Relative Risk Bias (RRB) [11] measures the robustness of an
optimal decision rule—i.e., the Bayesian Decision rule providing
the minimal risk when the training data has no “contaminations”.
S´aez et al. [19] extend the measure to any classifier, given by:

,

R

RRBx % = Rx % − R
where Rx % is the classification error rate obtained by the classifier
in a dataset with noise level given by x% and R is the classification
error rate of the Bayesian Decision rule without noise (this is a
theoretical decision rule, not learned from the data and depends on
the data generating process), which is by definition the minimum
expected error that can be achieved by any decision rule.

(3)

The Relative Loss of Accuracy (RLA) [18], in turn, quantifies the
impact of increasing levels of noise in the accuracy of the classifier
model when compared to the case with no noise. The RLA measure
with level of noise equals to x% is defined by:

RLAx % = A0% − Ax %

A0%

,

(4)

GECCO ’17, July 15-19, 2017, Berlin, Germany

where A0% and Ax % are the accuracies of the classifier with a noise
level of 0% and x%, respectively. RLA is considered more intuitive
than RRB, as methods obtaining high values of accuracy without
noise (A0%) will have a low RLA value.

Finally, the Equalized Loss of Accuracy (ELA) [19] was proposed
as a correction of the RLA inspired by the measure from [11], and
overcomes the limitations of RRB and RLA. The initial performance
(A0%) has a very low influence in the RLA equation, which can
negatively bias the loss of accuracy of methods with high A0%
when compared to methods with low initial accuracy. E.g., let
A0% = A10% = 0.5 be the accuracies of the method α and A(cid:48)
0% = 0.8
and A(cid:48)
10% = 0.75 be the accuracies of the method β. Although
method β has very low loss of accuracy for 10% of noise, the α
classifier has a better RLA10%—equals to 0. The ELA measure is
given by:

ELAx % =

100 − Ax %
A0%

,

(5)

where Ax % and A0% are defined as in Equation 4. ELAx % is equiv-
alent to RLAx % + f (A0%)—see [19] for the derivation—where the
factor f (A0%) = (100 − A0%)/A0% is equivalent to ELA0% and de-
pends only on the initial accuracy A0%. Thus the ELAx % value
of a method is based on its robustness, measured by the RLAx %,
and on the behavior for clean data—i.e., without controlled noise—
measured by ELA0%.

4 METHODOLOGY
This section presents the methodology followed to analyze how
GSGP performs in symbolic regression problems with different
levels of noise when compared to GP. We present the datasets
considered in our study, along with the strategy to incrementally
add noise to the data, and the measures we adopt to assess the
impact of different levels of noise on the performance of GSGP and
GP.

4.1 Test Bed
Since real-world problems have intrinsic noise inserted when the
data is acquired and pre-processed from the environment [15], we
adopt a test bed composed of synthetic data, generated from 15
known functions selected from the list of benchmark candidates
for symbolic regression GP presented in [13]. Table 1 presents the
function set, the sampling strategy adopted to build the dataset,
the input domain, the number of instances and the source from the
literature.

The training and test sets are sampled independently, according
to two strategies presented in Table 1. U [a, b, c] indicates a uniform
random sample of size c drawn from the interval [a, b] and E[a, b, c]
indicates a grid of points evenly spaced with an interval c, from a
to b, inclusive. For the former strategy, we generated five sets of
samples and for the latter, since the procedure is deterministic, we
generated only one sample.

In order to evaluate the impact of noise on GSGP and GP per-
formances, the response variable (desired output) of the training
instances was perturbed by an additive Gaussian noise with zero
mean and unitary standard deviation, applied with probability given
by r . We generated datasets with r varying from 0 to 0.2 with steps

GECCO ’17, July 15-19, 2017, Berlin, Germany

Luis F. Miranda et al.

Table 1: Datasets used in the experiments. Testing and training sets are independent.

Dataset

Objective function

# of variables

Keijzer-1

Keijzer-2

Keijzer-3

Keijzer-4

Keijzer-6

Keijzer-7

Keijzer-8

Keijzer-9

Vladislavleva-1

Vladislavleva-2

Vladislavleva-3

Vladislavleva-4

Vladislavleva-5

Vladislavleva-7

Vladislavleva-8

e −x cos(x ) sin(x )(sin2(x ) cos(x ) − 1)
1
i

i .e ., ln(x +

√

x 2 + 1)

3

0.3 x sin(2π x )
0.3 x sin(2π x )
0.3 x sin(2π x )
x
(cid:205)x
i
ln x
√
x

2

arcsin(x )
e −(x −1)
1.2+(y−2.5)2
e −x x
e −x x

3(cos(x ) sin(x ))(cos(x ) sin2(x ) − 1)
3(cos(x ) sin(x ))(cos(x ) sin2(x ) − 1)(y − 5)

10
5+(x −3)2+(y−3)2+(z−3)2+(v −3)2+(w −3)2

30 (x −1)(z−1)
2(x −10)

y

(x − 3)(y − 3) + 2 sin((x − 4)(y − 4))
−(y−3)
(x −3)

4+(y−3)
3
(y−2)4+10

1

1

1

1

1

1

1

1

2

1

2

5

3

2

2

equal to 0.02, resulting in 11 different levels of noise, in a total of
165 datasets analyzed.

The performance of the methods in the datasets was measured
using the Normalized Root Mean Square Error (NRMSE) [6, 10],
given by2:

RMSE ·

(cid:113) n
n−1

σt

(cid:118)(cid:117)(cid:117)(cid:117)(cid:117)(cid:117)(cid:117)(cid:117)(cid:117)(cid:116)

=

N RMSE =

n
(cid:205)
i=1

(yi − f (xi ))2

n
(cid:205)
i=1

(yi − ¯t)2

,

(6)

where ¯t and σt are, respectively, the mean and standard deviation
of the target output vector t and f is the model (function) induced
by the regression method. NRMSE is equal to 1 when the model
performs equivalently to ¯t and equal to 0 when the model perfectly
fits the data. We used the normalized version of RMSE to be able to
compare results from different levels of noise and datasets in a fair
way, as described in the next section.

4.2 Noise Robustness in Regression
The performance of GSGP and GP in the same datasets with different
levels of noise is assessed by the robustness measures presented
in Section 3.2, namely RLA and ELA, adapted to the regression
domain. Instead of using the accuracy—a performance measure for
classification methods—we adopted the NRMSE.

Notice that the accuracy is defined in [0%, 100%]—or [0, 1]—with
higher values meaning better accuracy and, consequently, smaller
error. Thus, the larger the RLA or ELA measured values, the less
robust is the method to the respective noise level. The NRMSE,
on the other hand, is defined in [0, +∞) and higher values mean
greater error.

In this context, we introduce the Relative Increase in Error (RIE)
and Equalized Increase in Error (EIE) measures as alternatives to

2The presented NRMSE equation regards the training set. However, the formula is
easily extensible to the test set.

Sampling strategy

# of instances

Training

Test

Training

E[−1, 1, 0.1]
E[−2, 2, 0.1]
E[−3, 3, 0.1]
E[0, 10, 0.1]
E[1, 50, 1]
E[1, 100, 1]
E[0, 100, 1]
E[0, 100, 1]

E[−1, 1, 0.001]
E[−2, 2, 0.001]
E[−3, 3, 0.001]
E[0.05, 10.05, 0.1]
E[1, 120, 1]
E[1, 100, 0.1]
E[0, 100, 0.1]
E[0, 100, 0.1]

U [0.3, 4, 100]

E[−0.2, 4.2, 0.1]

E[0.05, 10, 0.1]
x : E[0.05, 10, 0.1]
y : E[0.05, 10.05, 2]
U [0.05, 6.05, 1024]
x : U [0.05, 2, 300]
y : U [1, 2, 300]
z : U [0.05, 2, 300]
U [0.05, 6.05, 300]
U [0.05, 6.05, 50]

E[−0.5, 10.5, 0.05]
x : E[−0.5, 10.5, 0.05]
y : E[−0.5, 10.5, 0.5]
U [−0.25, 6.35, 5000]
x : E[−0.05, 2.1, 0.15]
y : E[0.95, 2.05, 0.1]
z : E[−0.05, 2.1, 0.15]
U [−0.25, 6.35, 1000]
E[−0.25, 6.35, 0.2]

21

41

61

101

50

100

101

100

100

100

600

1024

300

300

50

Test

2001

4001

6001

101

120

991

1001

2025

2025

221

5083

5000

2700

1000

1089

Src.

[10]

[10]

[10]

[10]

[10]

[10]

[10]

[10]

[26]

[26]

[26]

[26]

[26]

[26]

[26]

RLA and ELA, respectively, to quantify the noise robustness in the
regression domain. RIE and EIE are given by Equations 7 and 8,
respectively, where Ex % is the NRMSE obtained by the model in
the dataset with x% of noise, E0% is the NRMSE obtained by the
model in the dataset with no noise, and a plus one term is added to
both denominators in order to avoid division by zero. The higher
the values of both measures, the more sensitive the model is to the
respective noise level.

RI Ex % = Ex % − E0%
1 + E0%
EIEx % = Ex %
1 + E0%

(7)

(8)

Similarly to ELA, we can derive EIE according to Equation 9,
such that EIEx % is equal to RI Ex % plus a term depending only on
the model NRMSE with no noise—given by EIE0%.

EIEx % = Ex %
1 + E0%

= Ex % + E0% − E0%
1 + E0%

= RI Ex % + EIE0%

(9)

5 EXPERIMENTAL ANALYSIS
This section presents the experimental analysis of the performance
of GSGP in symbolic regression problems with noisy data. We com-
pare the results with a canonical GP [1], using the noise robustness
measures introduced in Section 4.2 and the 15 datasets presented in
Table 1 with 11 different noise levels.Given the non-deterministic
nature of GSGP and GP, each experiment was repeated 50 times. As
explained in Section 4.1, we resampled five times the data obtained
randomly by the uniform strategy. In datasets with this sampling
strategy, the experiments were repeated 10 times for each sample,
resulting in a total of 50 repetitions.

Both GP and GSGP were run with a population of 1000 individu-
als evolved for 2000 generations with tournament selection of size
10. The grow method [12] was adopted to generate the random

How Noisy Data Affects Geometric Semantic
Genetic Programming

GECCO ’17, July 15-19, 2017, Berlin, Germany

Table 2: P-values obtained by the statistical analysis of the performances of GP and GSGP. The symbol (cid:7) indicates the null
hypothesis was not discarded and the symbol (cid:78)((cid:72)) indicates that GSGP is statistically better (worse) than GP with 95% confi-
dence.

0.001

0

—
—

(cid:78)

2

0.006
0.003
0.015

(cid:78)
(cid:72)
(cid:78)

4

0.004
0.002
0.021

(cid:78)
(cid:72)
(cid:78)

6

0.015
0.001
0.126

NRMSE
RIE
EIE

8

10

12

14

16

18

20

(cid:78)
(cid:72)
(cid:7)

0.032
0.000
0.300

(cid:78)
(cid:72)
(cid:7)

0.053
0.000
0.381

(cid:7)
(cid:72)
(cid:7)

0.042
0.000
0.402

(cid:78)
(cid:72)
(cid:7)

0.115
0.000
0.467

(cid:7)
(cid:72)
(cid:7)

0.151
0.000
0.381

(cid:7)
(cid:72)
(cid:7)

0.195
0.000
0.598

(cid:7)
(cid:72)
(cid:7)

0.262
0.000
0.885

(cid:7)
(cid:72)
(cid:7)

Training instances affected by noise (%)

functions inside the geometric semantic crossover and mutation op-
erators, and the ramped half-and-half method [12] to generate the
initial population, both with maximum individual depth equals to 6.
The function set included three binary arithmetic operators (+, −, ×)
and the analytic quotient (AQ) [16], an alternative to the arithmetic
division with similar properties, but without discontinuity, given
by:

AQ(a, b) =

√

a
1 + b2

.

(10)

The terminal set comprised the variables of the problem and
constant values uniformly picked from [−1, 1]. The GP method em-
ployed the canonical crossover and mutation operators [12] with
probabilities 0.9 and 0.1, respectively. GSGP employed the geo-
metric semantic crossover for fitness function based on Manhattan
distance and mutation operators, as presented in [5], both with
probability 0.5. The mutation step adopted by the geometric seman-
tic mutation operator was defined as 10% of the standard deviation
of the target vector t given by the training data.

Figure 2 shows how the median training and test NRMSE are
affected when increasing the percentage of noisy instances. Regard-
ing the results for data with no noise, GSGP presents better median
test NRMSE in all but two datasets, Keijzer-6 and Vladislavleva-
5. However, the opposite behavior is observed for noise levels
greater than or equal to 18% in Keijzer-1, 6% in Keijzer-9, 2% in
Vladislavleva-1 and 14% in Vladislavleva-4. Moreover, GSGP test
NRMSE approximates from GP when the noise level increases
in the datasets Keijzer-2, Keijzer-3, Keijzer-4, Keijzer-7, Keijzer-
8, Vladislavleva-2 and Vladislavleva-8. This behavior may indicate
that, although GSGP outperforms GP in low levels of noise in most
of the datasets, its performance deteriorates faster than GP when
the level of noise increases. Notice that in all experiments the me-
dian training NRMSE of the GSGP is smaller than the one obtained
by GP, regardless of the behavior of both methods in the test data,
which may indicate that GSGP has a greater tendency to overfit
noisy data than GP.

Figure 3, in turn, shows the median values for the EIE and RIE
measures presented in Section 4.2, obtained by GSGP and GP meth-
ods for different noise levels considering only the test set. When an-
alyzing RIE values, we verify that GSGP is less robust to noise than
GP for all noise levels in 10 datasets—Keijzer-2, Keijzer-3, Keijzer-
4, Keijzer-6, Keijzer-7, Keijzer-9, Vladislavleva-1, Vladislavleva-2,
Vladislavleva-4 and Vladislavleva-7—and for noise levels greater
than or equal to 4% for Keijzer-1 and Keijzer-8 and 6% in the dataset
Vladislavleva-8.

However, this scenario changes when we look at the values of
EIE. GSGP is more robust than GP in all noise levels in six datasets—
Keijzer-4, Keijzer-7, Keijzer-8, Vladislavleva-2, Vladislavleva-3 and
Vladislavleva-7—and the opposite happens in only two datasets—
Keijzer-6 and Vladislavleva-1. Besides, we can observe that GSGP
obtains smaller EIE values than GP for noise levels smaller than
18% in the datasets Keijzer-1 and Keijzer-3. On the other hand, GP
outperforms GSGP in terms of EIE for noise levels greater than 4% in
the datasets Keijzer-9 and Vladislavleva-4. These analyses indicate
that, overall, GSGP is more robust to noise than GP according to
the EIE measure.

The main reason for these contradicting results lies on what
these measures regard as important to quantify noise robustness.
As presented in Section 3.2, the method performance in the dataset
with no noise has very low influence in the RLA measure—and
consequently in its regression counterpart (RIE). The ELA and EIE,
on the other hand, add a term to their respective equations to
represent the behavior of the model in the data without controlled
noise. As GSGP performs better than GP in the majority of scenarios
when no noise is present, it is natural that EIE considers it more
robust to noise than RIE.

In order to compare the results presented in Figures 2 and 3, we
conducted three paired one-tailed Wilcoxon tests comparing GP and
GSGP under the null hypothesis that their median performance—
measured by their median test NRMSE, RIE and EIE in all datasets—
are equal. The adopted alternative hypotheses differ according to to
the overall results presented in Figures 2 and 3: GSGP outperforms
GP in terms of NRMSE and EIE and GP outperforms GSGP in terms
of RIE. The p-values reported by the tests are presented in Table 2.
Considering a confidence level of 95%, the symbol (cid:7)indicates the
null hypothesis was not discarded and the symbol (cid:78)((cid:72)) indicates
that GSGP is statistically better (worse) than GP. For the NMRSE
measure, GSGP outperforms GP in datasets with 0%, 2%, 4%, 6%,
8% and 12% of noise. However, there are no statistical differences
when the noise level is greater than 12%, which indicates that
GSGP performance approximates from GP. When analyzing the
robustness measures, RIE indicates that GP is more robust than
GSGP in all noise levels. However, the same is not true for the EIE
measure, which indicates GSGP is more robust than GP with low
levels of noise (2% and 4%) and have no significant differences for
noise levels greater than 4%.

6 CONCLUSIONS
This paper presented an analytic study of the impact of noisy data
on the performance of GSGP when compared to GP in symbolic re-
gression problems. The performance of both methods was measured

GECCO ’17, July 15-19, 2017, Berlin, Germany

Luis F. Miranda et al.

(a) Keijzer-1

(b) Keijzer-2

(c) Keijzer-3

(d) Keijzer-4

(e) Keijzer-6

(f) Keijzer-7

(g) Keijzer-8

(h) Keijzer-9

(i) Vladislavleva-1

(j) Vladislavleva-2

(k) Vladislavleva-3

(l) Vladislavleva-4

(m) Vladislavleva-5

(n) Vladislavleva-7

(o) Vladislavleva-8

Figure 2: Median training and test NRSME obtained by GP and GSGP for each dataset.

024681012141618200.00.20.40.60.81.0Median NRMSEGP - TrainingGP - TestGSGP - TrainingGSGP - Test024681012141618200.00.20.40.60.81.01.2024681012141618200.00.20.40.60.81.01.2024681012141618200.00.20.40.60.81.0Median NRMSE024681012141618200.00.20.40.60.81.0024681012141618200.00.10.20.30.4024681012141618200.00.10.20.30.4Median NRMSE024681012141618200.00.10.20.30.40.50.6024681012141618200.00.20.40.60.81.01.21.41.6024681012141618200.00.20.40.60.81.0Median NRMSE024681012141618200.00.20.40.60.81.0024681012141618200.00.20.40.60.81.01.21.402468101214161820Training instances affected by noise (%)0.00.10.20.30.40.50.60.70.8Median NRMSE02468101214161820Training instances affected by noise (%)0.00.10.20.30.40.50.602468101214161820Training instances affected by noise (%)0.00.20.40.60.81.0How Noisy Data Affects Geometric Semantic
Genetic Programming

GECCO ’17, July 15-19, 2017, Berlin, Germany

(a) Keijzer-1

(b) Keijzer-2

(c) Keijzer-3

(d) Keijzer-4

(e) Keijzer-6

(f) Keijzer-7

(g) Keijzer-8

(h) Keijzer-9

(i) Vladislavleva-1

(j) Vladislavleva-2

(k) Vladislavleva-3

(l) Vladislavleva-4

(m) Vladislavleva-5

(n) Vladislavleva-7

(o) Vladislavleva-8

Figure 3: Median test RIE and EIE obtained by GP and GSGP for each dataset.

24681012141618200.00.10.20.30.40.5Median RIE/EIERIE - GPEIE - GPRIE - GSGPEIE - GSGP246810121416182000.20.40.60.8246810121416182000.20.40.624681012141618200.00.10.20.30.40.5Median RIE/EIE246810121416182000.20.40.624681012141618200.00.10.224681012141618200.000.020.040.060.080.10Median RIE/EIE24681012141618200.00.10.20.30.4246810121416182000.20.40.60.81.01.22468101214161820-0.10.00.10.20.30.40.5Median RIE/EIE24681012141618200.00.10.20.30.40.5246810121416182000.20.40.60.81.02468101214161820Training instances affected by noise (%)0.00.10.20.3Median RIE/EIE2468101214161820Training instances affected by noise (%)-0.10.00.10.20.30.42468101214161820Training instances affected by noise (%)-0.10.00.10.20.30.40.5GECCO ’17, July 15-19, 2017, Berlin, Germany

Luis F. Miranda et al.

Programming Needs Better Benchmarks. In Proceedings of the 14th Annual Con-
ference on Genetic and Evolutionary Computation (GECCO ’12). ACM, New York,
NY, USA, 791–798. DOI:http://dx.doi.org/10.1145/2330163.2330273

[14] A. Moraglio, K. Krawiec, and C. G. Johnson. 2012. Geometric Semantic Genetic
Programming. Springer Berlin Heidelberg, Berlin, Heidelberg, 21–31. DOI:
http://dx.doi.org/10.1007/978-3-642-32937-1 3

[15] F. Nettleton, D, A. Orriols-Puig, and A. Fornells. 2010. A study of the effect
of different types of noise on the precision of supervised learning techniques.
Artificial Intelligence Review 33, 4 (2010), 275–306.
J. Ni, R. H. Drieberg, and P. I. Rockett. 2013. The use of an analytic quotient
operator in genetic programming. Evolutionary Computation, IEEE Trans. on 17,
1 (Apr 2013), 146–152.

[16]

[17] Peter J Rousseeuw and Annick M Leroy. 2005. Robust regression and outlier

[18]

[19]

detection. Vol. 589. John wiley & sons.
J. A. S´aez, J. Luengo, and F. Herrera. 2011. Fuzzy rule based classification sys-
tems versus crisp robust learners trained in presence of class noise’s effects: a
case of study. In Intelligent Systems Design and Applications (ISDA), 2011 11th
International Conference on. IEEE, 1229–1234.
J. A. S´aez, J. Luengo, and F. Herrera. 2016. Evaluating the classifier behavior
with noisy data considering performance and robustness: the Equalized Loss of
Accuracy measure. Neurocomputing 176 (2016), 26–35. DOI:http://dx.doi.org/10.
1016/j.neucom.2014.11.086

[20] C. Sivapragasam, P. Vincent, and G. Vasudevan. 2007. Genetic programming
model for forecast of short and noisy data. Hydrological processes 21, 2 (2007),
266–272.

[21] Leonardo Vanneschi. 2014. Improving genetic programming for the prediction
of pharmacokinetic parameters. Memetic Computing 6, 4 (2014), 255–262.
[22] Leonardo Vanneschi, Mauro Castelli, Luca Manzoni, and Sara Silva. 2013. A new
implementation of geometric semantic GP and its application to problems in
pharmacokinetics. In 16th European Conference, EuroGP 2013 (LNCS), Krzysztof
Krawiec, Alberto Moraglio, Ting Hu, A. S¸ima Etaner-Uyar, and Bin Hu (Eds.),
Vol. 7831. Springer Berlin Heidelberg, 205–216.

[23] Leonardo Vanneschi, Mauro Castelli, and Sara Silva. 2010. Measuring Bloat,
Overfitting and Functional Complexity in Genetic Programming. In Proceedings
of the 12th Annual Conference on Genetic and Evolutionary Computation (GECCO
’10). ACM, New York, NY, USA, 877–884. DOI:http://dx.doi.org/10.1145/1830483.
1830643

[24] Leonardo Vanneschi, Mauro Castelli, and Sara Silva. 2014. A survey of semantic
methods in genetic programming. Genetic Programming and Evolvable Machines
15, 2 (2014), 195–214. DOI:http://dx.doi.org/10.1007/s10710-013-9210-0
[25] Leonardo Vanneschi, Sara Silva, Mauro Castelli, and Luca Manzoni. 2014. Geo-
metric Semantic Genetic Programming for Real Life Applications. In Genetic
Programming Theory and Practice XI, Rick Riolo, Jason H. Moore, and Mark
Kotanchek (Eds.). Springer New York, 191–209.

[26] E. J. Vladislavleva, G. F. Smits, and D. Den Hertog. 2009. Order of Nonlinearity
As a Complexity Measure for Models Generated by Symbolic Regression via
Pareto Genetic Programming. Trans. Evol. Comp 13, 2 (April 2009), 333–349.
DOI:http://dx.doi.org/10.1109/TEVC.2008.926486

by the normalized RMSE and two robustness measures adapted
from the classification literature to the regression domain, namely
Relative Increase in Error (RIE) and Equalized Increase in Error
(EIE), in a test bed composed of 15 synthetic datasets, each of them
with 11 different levels of noise equally spaced in [0.00, 0.20].

Results indicated that GP is more robust to all levels of noise than
GSGP when the RIE measure is employed to analyze the outcomes.
However, when the NRMSE or EIE values were analyzed, GSGP
outperformed GP in terms of robustness to lower levels of noise
and presented no significant differences regarding GP in higher
levels of noise. Overall, these outcomes indicate that, although
GSGP performs better than GP in low levels of noise, the methods
tend to perform equivalently for larger levels of noise. Given these
conclusions, potential future developments include investigating
techniques to identify the noisy instances in order to remove them
or minimize their importance during the search.

ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers for
their valuable comments and suggestions. This work was partially
supported by the following Brazilian Research Support Agencies:
CNPq, FAPEMIG, and CAPES.

REFERENCES
[1] W. Banzhaf, P. Nordin, R.E. Keller, and F.D. Francone. 1998. Genetic Programming
— an Introduction: on the Automatic Evolution of Computer Programs and Its
Applications. Morgan Kaufmann Publishers.

[2] A. Borrelli, I. De Falco, A. Della Cioppa, M. Nicodemi, and G. Trautteur. 2006.
Performance of genetic programming to extract the trend in noisy data series.
Physica A: Statistical Mechanics and its Applications 370, 1 (2006), 104–108.
[3] Mauro Castelli, Davide Castaldi, Ilaria Giordani, Sara Silva, Leonardo Vanneschi,
Francesco Archetti, and Daniele Maccagnola. 2013. An efficient implementation
of geometric semantic genetic programming for anticoagulation level prediction
in pharmacogenetics. In 16th Portuguese Conference on Artificial Intelligence, EPIA
2013 (LNCS), Lu´ıs Correia, Lu´ıs Paulo Reis, and Jos´e Cascalho (Eds.), Vol. 8154.
Springer Berlin Heidelberg, 78–89.

[6]

[4] Mauro Castelli, Luca Manzoni, and Leonardo Vanneschi. 2012. An efficient ge-
netic programming system with geometric semantic operators and its application
to human oral bioavailability prediction. arXiv preprint arXiv:1208.2437 (2012).
[5] M. Castelli, S. Silva, and L. Vanneschi. 2015. A C++ framework for geometric
semantic genetic programming. Genetic Prog. and Evolvable Machines 16, 1 (Mar
2015), 73–81.
I. De Falco, A. Della Cioppa, D. Maisto, U. Scafuri, and E. Tarantino. 2007. Parsi-
mony doesn’t mean simplicity: Genetic programming for inductive inference on
noisy data. In Proceedings of the 10th European Conference, EuroGP’07 (LNCS),
M. Ebner, M. O’Neill, A. Ek´art, L. Vanneschi, and A. Esparcia-Alc´azar (Eds.),
Vol. 4445. Springer, 351–360.
Jeannie Fitzgerald and Conor Ryan. 2014. On Size, Complexity and Generalisa-
tion Error in GP. In Proceedings of the 2014 Annual Conference on Genetic and
Evolutionary Computation (GECCO ’14). ACM, New York, NY, USA, 903–910.
DOI:http://dx.doi.org/10.1145/2576768.2598346

[7]

[8] Ray J Hickey. 1996. Noise modelling and evaluating learning from examples.

[9]

Artificial Intelligence 82, 1 (1996), 157–179.
J. H Imada and B. J Ross. 2008. Using feature-based fitness evaluation in sym-
bolic regression with added noise. In Proceedings of the 10th annual conference
companion on Genetic and evolutionary computation. ACM, 2153–2158.
[10] M. Keijzer. 2003. Improving Symbolic Regression with Interval Arithmetic and
Linear Scaling. In 6th European Conference, EuroGP 2003, Conor Ryan, Terence
Soule, Maarten Keijzer, Edward Tsang, Riccardo Poli, and Ernesto Costa (Eds.),
Vol. 2610. Springer Berlin Heidelberg, 70–82. DOI:http://dx.doi.org/10.1007/
3-540-36599-0 7

[11] Yu. Kharin and E. Zhuk. 1994. Robustness in statistical pattern recognition
under “contaminations” of training samples. In Pattern Recognition, 1994. Vol.
2-Conference B: Computer Vision & Image Processing., Proceedings of the 12th IAPR
International. Conference on, Vol. 2. IEEE, 504–506.
J. R. Koza. 1992. Genetic Programming: On the Programming of Computers by
Means of Natural Selection. Vol. 1. MIT Press.
J. McDermott, D. R. White, S. Luke, L. Manzoni, M. Castelli, L. Vanneschi, W.
Jaskowski, K. Krawiec, R. Harper, K. De Jong, and U. O’Reilly. 2012. Genetic

[13]

[12]

