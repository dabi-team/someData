Towards Verified Stochastic Variational Inference for
Probabilistic Programs

9
1
0
2

v
o
N
8
1

]
L
P
.
s
c
[

4
v
7
2
8
8
0
.
7
0
9
1
:
v
i
X
r
a

WONYEOL LEE, School of Computing, KAIST, South Korea
HANGYEOL YU, School of Computing, KAIST, South Korea
XAVIER RIVAL, INRIA Paris and Département d’Informatique of ENS, CNRS/École Normale Supérieure/PSL
University, France
HONGSEOK YANG, School of Computing, KAIST, South Korea

Probabilistic programming is the idea of writing models from statistics and machine learning using program
notations and reasoning about these models using generic inference engines. Recently its combination with
deep learning has been explored intensely, which led to the development of so called deep probabilistic
programming languages, such as Pyro, Edward and ProbTorch. At the core of this development lie inference
engines based on stochastic variational inference algorithms. When asked to find information about the
posterior distribution of a model written in such a language, these algorithms convert this posterior-inference
query into an optimisation problem and solve it approximately by a form of gradient ascent or descent. In
this paper, we analyse one of the most fundamental and versatile variational inference algorithms, called
score estimator or REINFORCE, using tools from denotational semantics and program analysis. We formally
express what this algorithm does on models denoted by programs, and expose implicit assumptions made
by the algorithm on the models. The violation of these assumptions may lead to an undefined optimisation
objective or the loss of convergence guarantee of the optimisation process. We then describe rules for proving
these assumptions, which can be automated by static program analyses. Some of our rules use nontrivial
facts from continuous mathematics, and let us replace requirements about integrals in the assumptions, such
as integrability of functions defined in terms of programs’ denotations, by conditions involving differentia-
tion or boundedness, which are much easier to prove automatically (and manually). Following our general
methodology, we have developed a static program analysis for the Pyro programming language that aims at
discharging the assumption about what we call model-guide support match. Our analysis is applied to the
eight representative model-guide pairs from the Pyro webpage, which include sophisticated neural network
models such as AIR. It finds a bug in one of these cases, reveals a non-standard use of an inference engine in
another, and shows that the assumptions are met in the remaining six cases.

CCS Concepts: • Mathematics of computing → Bayesian computation; Variational methods; • Theory
of computation → Probabilistic computation; Denotational semantics; • Software and its engineer-
ing → Correctness; Automated static analysis; • Computing methodologies → Machine learning;

Additional Key Words and Phrases: probabilistic programming, static analysis, semantics and correctness

ACM Reference Format:
Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang. 2020. Towards Verified Stochastic Variational
Inference for Probabilistic Programs. Proc. ACM Program. Lang. 0, POPL, Article 0 (January 2020), 69 pages.
https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 INTRODUCTION
Probabilistic programming refers to the idea of writing models from statistics and machine learning
using program notations and reasoning about these models using generic inference engines. It has

Authors’ addresses: Wonyeol Lee, School of Computing, KAIST, South Korea, wonyeol@kaist.ac.kr; Hangyeol Yu, School of
Computing, KAIST, South Korea, yhk1344@kaist.ac.kr; Xavier Rival, INRIA Paris and Département d’Informatique of ENS,
CNRS/École Normale Supérieure/PSL University, France, rival@di.ens.fr; Hongseok Yang, School of Computing, KAIST,
South Korea, hongseok.yang@kaist.ac.kr.

2020. 2475-1421/2020/1-ART0 $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

 
 
 
 
 
 
0:2

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

been the subject of active research in machine learning and programming languages, because of its
potential for enabling scientists and engineers to design and explore sophisticated models easily;
when using these languages, they no longer have to worry about developing custom inference
engines for their models, a highly-nontrivial task requiring expertise in statistics and machine
learning. Several practical probabilistic programming languages now exist, and are used for a wide
range of applications [Carpenter et al. 2017; Gehr et al. 2016; Goodman et al. 2008; Gordon et al.
2014; Mansinghka et al. 2014; Minka et al. 2014; Narayanan et al. 2016; Tolpin et al. 2016; Wood
et al. 2014].

In this paper, we consider inference engines that lie at the core of so called deep probabilistic
programming languages, such as Pyro [Bingham et al. 2019], Edward [Tran et al. 2018, 2016]
and ProbTorch [Siddharth et al. 2017]. These languages let their users freely mix deep neural
networks with constructs from probabilistic programming, in particular, those for writing Bayesian
probabilistic models. In so doing, they facilitate the development of probabilistic deep-network
models that may address the problem of measuring the uncertainty in current non-Bayesian deep-
network models; a non-Bayesian model may predict that the price of energy goes up and that of a
house goes down, but it cannot express, for instance, that the model is very confident with the first
prediction but not the second.

The primary inference engines for these deep probabilistic programming languages implement
stochastic (or black-box) variational inference1 algorithms. Converting inference problems into
optimisation problems is the high-level idea of these algorithms.2 When asked to find information
about the posterior distribution of a model written in such a language, these algorithms convert
this question to an optimisation problem and solve the problem approximately by performing
a gradient descent or ascent on the optimisation objective. The algorithms work smoothly with
gradient-based parameter-learning algorithms for deep neural networks, which is why they form
the backbone for deep probabilistic programming languages.

In this paper, we analyse one of the most fundamental and versatile variational inference algo-
rithms, called score estimator or REINFORCE3 [Paisley et al. 2012; Ranganath et al. 2014; Williams
1992; Wingate and Weber 2013], using tools from denotational semantics and program analy-
sis [Cousot and Cousot 1977, 1979, 1992]. We formally express what this algorithm does on models
denoted by probabilistic programs, and expose implicit assumptions made by the algorithm on
the models. The violation of these assumptions can lead to undefined optimisation objective or
the loss of convergence guarantee of the optimisation process. We then describe rules for proving
these assumptions, which can be automated by static program analyses. Some of our rules use
nontrivial facts from continuous mathematics, and let us replace requirements about integrals in the
assumptions, such as integrability of functions defined in terms of programs’ denotations, by the
conditions involving differentiation or boundedness, which are much easier to prove automatically
(and manually) than the original requirements.

Following our general methodology, we have developed a static program analysis for the Pyro
programming language that can discharge one assumption of the inference algorithm about so
called model-guide pairs. In Pyro and other deep probabilistic programming languages, a program

1The term stochastic variational inference (VI) often refers to VI with data subsampling [Hoffman et al. 2013], and our usage
of the term is often called black-box VI [Ranganath et al. 2014] to stress the treatment of a model as a black-box sampler.
2The inference problems in their original forms involve solving summation/integration/counting problems, which are
typically more difficult than optimisation problems. The variational-inference algorithms convert the former problems to
the latter ones, by looking for approximate, not exact, answers to the former.
3REINFORCE [Williams 1992] is an algorithm originally developed for reinforcement learning (RL), but it is commonly used
as a synonym of the score-estimator algorithm. This is because REINFORCE and score estimator use a nearly identical
method for estimating the gradient of an optimisation objective.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:3

denoting a model typically comes with a companion program, called guide, decoder, or inference
network. This companion, which we call guide, helps the inference algorithm to find a good
approximation to what the model ultimately denotes under a given dataset (i.e., the posterior
distribution of the model under the dataset); the algorithm uses the guide to fix the search space of
approximations, and solves an optimisation problem defined on that space. A model and a guide
should satisfy an important correspondence property, which says that they should use the same
sets of random variables, and for any such random variable, if the probability of the variable having
a particular value is zero in the model, it should also be zero in the guide. If the property is violated,
the inference algorithm may attempt to solve an optimisation problem with undefined optimisation
objective and return parameter values that do not make any sense. Our static analysis checks this
correspondence property for Pyro programs. When applied to eight representative model-guide
pairs from the Pyro webpage, which include sophisticated neural network models such as Attend-
Infer-Repeat (AIR), the analysis found a bug in one of these cases, revealed a non-standard use of
the inference algorithm in another, and proved that the property holds in the remaining six cases.
Another motivation for this paper is to demonstrate an opportunity for programming languages
and verification research to have an impact on the advances of machine learning and AI technologies.
One popular question is: what properties should we verify on machine-learning programs? Multiple
answers have been proposed, which led to excellent research results, such as those on robustness
of neural networks [Mirman et al. 2018]. But most of the existing research focuses on the final
outcome of machine learning algorithms, not the process of applying these algorithms. One of
our main objectives is to show that the process often relies on multiple assumptions on models
and finding automatic ways for discharging these assumptions can be another way of making PL
and verification techniques contribute. While our suggested solutions are not complete, they are
intended to show the richness of this type of problems in terms of theory and practice.

We summarise the contributions of the paper:

• We formally express the behaviour of the most fundamental variational inference algorithm on
probabilistic programs using denotational semantics, and identify requirements on program
denotations that are needed for this algorithm to work correctly.

• We describe conditions that imply the identified requirements but are easier to prove. The
sufficiency of the conditions relies on nontrivial results from continuous mathematics. We
sketch a recipe for building program analyses for checking these conditions automatically.
• We present a static analysis for the Pyro language that checks the correspondence requirement
of model-guide pairs. The analysis is based on our recipe, but extends it significantly to address
challenges for dealing with features of the real-world language. Our analysis has successfully
verified 6 representative Pyro model-guide examples, and found a bug in one example.

The proofs of lemmas and theorems of the paper are included in Appendix.

2 VARIATIONAL INFERENCE AND VERIFICATION CHALLENGES BY EXAMPLES
We start by explaining informally the idea of stochastic variational inference (in short SVI), one
fundamental SVI algorithm, and the verification challenges that arise when we use this algorithm.

2.1 Stochastic variational inference
In a probabilistic programming language, we specify a model by a program. The program model()
in Figure 1(a) is an example. It describes a joint probability density p(v, obs) on two real-valued
random variables v and obs. The value of the former is not observed, while the latter is observed
to have the value 0. Finding out the value of v is the objective of writing this model. The joint
density p(v, obs) is expressed in terms of prior p(v) and likelihood p(obs|v) in the program. The

0:4

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

prior p(v) of v is the normal distribution with mean 0 and standard deviation 5, and it expresses
the belief about the possible value of v before any observation. The likelihood p(obs|v) is a normal
distribution whose mean and standard deviation are either (1, 1) or (−2, 1) depending on the sign
of the value of v. The purpose of most inference algorithms is to compute exactly or approximately
the posterior density given a prior and a likelihood. In our example, the posterior p(v |obs=0) is:

p(v |obs=0) =

p(v, obs=0)
∫ dv p(v, obs=0)

= p(v) · p(obs=0|v)
p(obs=0)

.

Intuitively, the posterior expresses an updated belief on v upon observing obs = 0. The dashed blue
and solid orange lines in Figure 1(b) show the prior and posterior densities, respectively. Note that
the density of a positive v in the prior went up in the posterior. This is because when v > 0, the
mean of p(obs|v) is 1, a value closer to the observed value 0 than the alternative −2 for the mean.
SVI algorithms approach the posterior inference problem from the optimisation angle. They
consider a collection of approximating distributions to a target posterior, formulate the problem
of finding a good approximation in the collection as an optimisation problem, and solve the
optimisation problem. The solution becomes the result of those algorithms. In Pyro, the users
specify such a collection by a single parameterised program called guide; the collection can be
generated by instantiating the parameters with different values. The program guide() in Figure 1(a)
is an example. It has a real-valued parameter θ (written as theta in the program), and states that
the probability density qθ (v) of v is the normal distribution with unknown mean θ and standard
deviation 1. The lines 13–17 in the figure show how to apply a standard SVI engine of Pyro (called
Trace_ELBO) to find a good θ . They instruct the engine to solve the following optimisation problem:

argmin
θ

KL(qθ (v)||p(v |obs=0)),

where KL(qθ (v)||p(v |obs=0)) ≜ Eqθ (v)

(cid:20)

log

qθ (v)
p(v |obs=0)

(cid:21)

.

The optimisation objective KL(qθ (v)||p(v |obs=0)) is the KL divergence from qθ (v) to p(v |obs=0),
and measures the similarity between the two densities, having a small value when the densities are
similar. The KL divergence is drawn in Figure 1(c) as a function of θ , and the dotted green line in
Figure 1(b) draws the density qθ at the optimum θ . Note that the mean of this distribution is biased
toward the positive side, which reflects the fact that the property v > 0 has a higher probability
than its negation v ≤ 0 in the posterior distribution.

One of the most fundamental and versatile algorithms for SVI is score estimator (also called RE-
INFORCE). It repeatedly improves θ in two steps. First, it estimates the gradient of the optimisation
objective with samples from the current qθn

:

(cid:12)
∇θ KL(qθ (v)||p(v |obs=0))
(cid:12)
(cid:12)θ =θn

≈

1

N

N
(cid:213)

i=1

(∇θ log qθn (vi )) · log

qθn (vi )
p(vi , obs=0)

where v1, . . . , vN are independent samples from the distribution qθn
θ with the estimated gradient (the specific learning rate 0.01 is chosen to improve readability):

. Then, the algorithm updates

θn+1 ← θn − 0.01 ×

1

N

N
(cid:213)

i=1

(∇θ log qθn (vi )) · log

qθn (vi )
p(vi , obs=0)

.

When the learning rate 0.01 is adjusted according to a known scheme, the algorithm is guaranteed
to converge to a local optimum (in many cases) because its gradient estimate satisfies the following
unbiasedness property (in those cases):

(cid:12)
∇θ KL(qθ (v)||p(v |obs=0))
(cid:12)
(cid:12)θ =θn

= E

(cid:34) 1
N

N
(cid:213)

i=1

(∇θ log qθn (vi )) · log

(cid:35)

qθn (vi )
p(vi , obs=0)

(1)

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:5

1
2
3
4
5
6
7
8
9
10
11

# define model and guide
def model():

v = pyro.sample("v", Normal(0., 5.))
if (v > 0):

pyro.sample("obs", Normal(1., 1.), obs=0.)

else:

pyro.sample("obs", Normal(-2., 1.), obs=0.)

def guide():

theta = pyro.param("theta", 3.)
v = pyro.sample("v", Normal(theta, 1.))

12
13
14
15
16
17
18
19
20
21

# perform stochastic variational inference
svi = SVI(model, guide,

Adam({"lr": 1.0e-2}),
loss=Trace_ELBO())

for step in range(2000):

svi.step()

# print result
print("trained theta =",

pyro.param("theta").item())

(a) Example model-guide pair for stochastic variational inference in Pyro.

(b) Probability densities of the model and the
guide as a function of v ∈ R.

(c) KL divergence from the guide to the model
(plus log p(obs=0)) as a function of θ ∈ R.

Fig. 1. Example of performing stochastic variational inference.

where the expectation is taken over the independent samples v1, . . . , vN from qθn

.

2.2 Verification challenges
We now give two example model-guide pairs that illustrate verification challenges related to SVI.
The first example appears in Figure 2(a). It is the Bayesian regression example from the Pyro
webpage (this example is among the benchmarks used in §8), which solves the problem of finding
a line that interpolates a given set of points in R2.

The problem with this example is that the KL divergence of its model-guide pair, the main
optimisation objective in SVI, is undefined. The model and guide in the figure use the random
variable sigma, but they use different non-zero-probability regions, called supports, for it. In the
model, the support is [0, 10], while that in the guide is R. But the KL divergence from a guide to a
model is defined only if for every random variable, its support in the guide is included in that in the
model. We point out that this support mismatch was found by our static analyser explained in §8.
Figures 2(b) and 2(c) show two attempts to resolve the undefined-KL issue. To fix the issue, we
change the distribution of sigma in the model in (b), and in the guide in (c). These revisions remove
the problem about the support of sigma, but do not eliminate that of the undefined KL. In both (b)
and (c), the KL divergence is ∞. This happens mainly because sigma can be arbitrarily close to 0 in
the guide in both cases, which makes integrand in the definition of the KL divergence diverge to ∞.
An SVI-specific verification challenge related to this example is how to prove the well-definedness
of the KL divergence and more generally the optimisation objective of an SVI algorithm. In §6.2,
we provide a partial answer to the question. We give a condition for ensuring the well-definedness
of the KL divergence. Our condition is more automation-friendly than the definition of KL, because
it does not impose the difficult-to-check integrability requirement present in the definition of KL.

model(prior)model(posterior)guide(optimal)-10-55100.10.20.30.4KL+const-4-2243.03.54.04.50:6

1
2
3

4
5
6
7

1
2
3

4
5
6
7
8
9
10
11

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

def model(...):

...
sigma = pyro.sample("sigma",

Uniform (0., 10.))

...
pyro.sample("obs",

Normal(..., sigma), obs=...)

8
9
10
11
12
13

14

def guide(...):

...
loc = pyro.param("sigma_loc", 1.,

constraint=constraints.positive)

...
sigma = pyro.sample("sigma",

Normal (loc, 0.05))

(a) Bayesian regression example from the Pyro webpage.

def model_r1(...):

...
sigma = pyro.sample("sigma",

Normal (5., 5.))

...
pyro.sample("obs",

Normal(..., abs(sigma)), obs=...)

def guide_r1(...):

# same as guide() in (a)
...

1
2
3
4
5
6
7

8

def model_r2(...):

# same as model() in (a)
...

def guide_r2(...):

...
sigma = pyro.sample("sigma",

Uniform (0., 10.))

(b) The example with a revised model.

(c) The example with a revised guide.

Fig. 2. Example model-guide pairs whose KL divergence is undefined.

The second example appears in Figure 3(a). It uses the same model as in Figure 1(a), but has a
new guide that uses a uniform distribution parameterised by θ ∈ R. For this model-guide pair, the
KL divergence is well-defined for all θ ∈ R, and the optimal θ ∗ minimising the KL is θ ∗ = 1.

However, as shown in Figure 3(b), the gradient of the KL divergence is undefined for θ ∈ {−1, 1},
because the KL divergence is not differentiable at −1 and 1. For all the other θ ∈ R \ {−1, 1}, the KL
divergence and its gradient are both defined, but the score estimator cannot estimate this gradient
in an unbiased manner (i.e., in a way satisfying (1)), thereby losing the convergence guarantee to a
local optimum. The precise calculation is not appropriate in this section, but we just point out that
the expectation of the estimated gradient is always zero for all θ ∈ R \ {−1, 1}, but the true gradient
2 log N(0;1,1)
of the KL is always non-zero for those θ , because it has the form: θ
N(0;−2,1) .
Here N (v; µ, σ ) is the density of the normal distribution with mean µ and standard deviation σ
2πσ ) · exp(−(v − µ)2/(2σ 2))). The mismatch comes from the invalidity
(concretely, N (v; µ, σ ) = 1/(
of one implicit assumption about interchanging integration and gradient in the justification of the
score estimator; see §5 for detail.

25 − 1[−1≤θ ≤1] · 1

√

To sum up, the second example shows that even if the KL divergence is defined, its gradient is
sometimes undefined, and also that even if both the KL divergence and its gradient are defined, the
sample-based estimate of the gradient in a standard SVI algorithm may be biased—this means that
the equation similar to (1) does not hold and an SVI algorithm is no longer guaranteed to converge
to a local optimum. Proving that these failure cases do not arise is another SVI-specific verification
challenge. In §6.3, we give another example of similar flavour, and provide an automation-friendly
condition that ensures the existence of the KL divergence and its gradient as well as the unbiasedness
of the gradient estimate of the score estimator.

We conclude the section by emphasising that the aforementioned issues could have a large
impact on the results of SVI. For instance, running the Bayesian regression example in Figure 2(a)
in Pyro after a small change (0.4 instead of 0.05 in line 14) sometimes results in a crash. Also,
running its revised version in Figure 2(c) leads to the complete failure of an optimiser and produces

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:7

1
2
3
4
5
6
7
8
9
10

11

def model():

v = pyro.sample("v", Normal(0., 5.))
if (v > 0):

pyro.sample("obs", Normal(1., 1.), obs=0.)

else:

pyro.sample("obs", Normal(-2., 1.), obs=0.)

def guide():

theta = pyro.param("theta", 3.)
v = pyro.sample("v",

Uniform (theta-1., theta+1.))

(a) The model from Figure 1(a), and a guide
using a parameterised uniform distribution.

(b) KL divergence from the guide to the model
(plus log p(obs=0)) as a function of θ ∈ R.

Fig. 3. Example model-guide pair for which the gradient of the KL divergence is undefined, or the score
estimator is biased.

meaningless results. These observations strengthen the importance of resolving the verification
challenges presented above.4

3 REVIEW OF MEASURE THEORY AND NOTATIONS
A σ -algebra Σ on a set X is a collection of subsets of X such that (i) X ∈ Σ; (ii) A0 ∪ A1 ∈ Σ and
X \ A0 ∈ Σ for all A0, A1 ∈ Σ; (iii) (cid:208)
n An ∈ Σ when all subsets An are in Σ. An equivalent but
easier-to-remember characterisation is that Σ is closed under boolean operations and countable
union and intersection. We call the pair (X , Σ) of a set and a σ -algebra measurable space, and subsets
in Σ measurable. A function f from a measurable space (X , Σ) to another measurable space (X ′, Σ′)
is measurable if f −1(B) ∈ Σ for all B ∈ Σ′.

An example of measurable space is the n-dimensional Euclidean space Rn with the Borel σ -
algebra B ≜ σ ({(−∞, r1) × · · · × (−∞, rn) (cid:12)
(cid:12) r ∈ Rn }), where σ is the closure operator that converts
a collection of subsets of Rn into the smallest σ -algebra containing the collection. Subsets X of Rn,
such as [0, ∞)n, form measurable spaces with the σ -algebra {X ∩ A | A ∈ B}. Another example is
a set X with the so called discrete σ -algebra on X that consists of all subsets of X .

A measure µ on a measurable space (X , Σ) is a function from Σ to [0, ∞] such that µ(∅) = 0 and µ
satisfies the countable additivity condition: for a countable family of disjoint measurable subsets Bn,

µ

(cid:16) ∞
(cid:216)

n=0

(cid:17) =

Bn

∞
(cid:213)

n=0

µ(Bn).

A well-known example is the Lebesgue measure λn on Rn which maps each measurable subset of
Rn to its volume in the usual sense.5 When µ(X ) ≤ 1, we call µ subprobability measure. If µ(X ) = 1,
we may drop “sub”, and call µ probability measure.

The Lebesgue integral ∫ is a partial operator that maps a measure µ on (X , Σ) and a real-valued
measurable function on the same space (X , Σ) to a real number. It is denoted by ∫
µ(dx) f (x). To
follow the paper, it is enough to know that this integral generalises the usual Riemann integral

4The aforementioned issues do not always cause problems in inference results (e.g., Figures 2(a) and 2(c) mostly give
reasonable results), because the random seeds and the initial values for SVI could be set well so that the probability of SVI
going wrong becomes low. We emphasise, however, that the probability is non-zero.
5The Lebesgue measure λn is the unique measure on Rn that sets the volume of the unit cube (0, 1)n to 1 and is translation
invariant: for all measurable subsets A and r ∈ Rn , λn (A) = λn ({r ′ − r | r ′ ∈ A}).

KL+const-4-20243.54.04.55.00:8

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

from calculus.6 For a measure ν on (X , Σ), if ν (A) = ∫
say that f is the density of ν with respect to µ and call µ reference measure.

µ(dx) (f (x) · 1[x ∈A]) for non-negative f , we

Xi
making all fi ’s measurable: Σ ≜ σ ({ f −1

In the paper, we use a few well-known methods for building measurable spaces.
The first method applies when we are given a set X and a collection of functions { fi
: X →
| i ∈ I } to measurable spaces (Xi , Σi ). The method is to equip X with the smallest σ -algebra Σ
(B) | i ∈ I , B ∈ Σi }).
The second relies on two constructions for sets, i.e., product and disjoint union. Suppose that we
are given measurable spaces (Xi , Σi ) for all i ∈ I . We define a product measurable space that has
(cid:206)

i ∈I Xi as its underlying set and the following product σ -algebra (cid:203)

i ∈I Σi as its σ -algebra:

i

(cid:12)
(cid:12)
(cid:12)

(cid:204)

Σi ≜ σ

(cid:16)(cid:110) (cid:214)

Ai

there is a finite I0 ⊆ I such that (∀j ∈ I \ I0. Aj = X j ) ∧ (∀i ∈ I0. Ai ∈ Σi )

(cid:111)(cid:17)

.

i

i ∈I
The construction of the product σ -algebra can be viewed as a special case of the first method where
we consider the smallest σ -algebra on (cid:206)
i ∈I Xi that makes every projection map to Xi measurable.
When the Xi are disjoint, they can be combined as disjoint union. The underlying set in this case is
(cid:208)

i ∈I Xi , and the σ -algebra is

(cid:202)

i ∈I

Σi ≜ {A | A ∩ Xi ∈ Σi for all i ∈ I }.

When I = {i, j} with i (cid:44) j, we denote the product measurable space by (Xi ×X j , Σi ⊗ Σj ). In addition,
if Xi and X j are disjoint, we write (Xi ∪ X j , Σi ⊕ Σj ) for the disjoint-union measurable space.

The third method builds a measurable space out of measures or a certain type of measures,
such as subprobability measures. For a measurable space (X , Σ), we form a measurable space with
measures. The underlying set Mea(X ) and σ -algebra ΣMea(X ) of the space are defined by

Mea(X ) ≜ {µ | µ is a measure on (X , Σ)},

ΣMea(X ) ≜ σ (cid:0)(cid:8){µ | µ(A) ≤ r } (cid:12)

(cid:12) A ∈ Σ, r ∈ R(cid:9)(cid:1).

The difficult part to grasp is ΣMea(X ). Once again, a good approach for understanding it is to
realise that ΣMea(X ) is the smallest σ -algebra that makes the function µ (cid:55)−→ µ(A) from Mea(X )
to R measurable for all measurable subsets A ∈ Σ. This measurable space gives rise to a variety
of measurable spaces, each having a subset M of Mea(X ) as its underlying set and the induced
σ -algebra ΣM = {A ∩ M | A ∈ ΣMea(X )}. In the paper, we use two such spaces, one induced by the
set Sp(X ) of subprobability measures on X and the other by the set Pr(X ) of probability measures.
A measurable function f from (X , Σ) to (Mea(Y ), ΣMea(Y )) is called kernel. If f (x) is a subprobabil-
ity measure (i.e., f (x) ∈ Sp(Y )) for all x, we say that f is a subprobability kernel. In addition, if f (x)
is a probability measure (i.e., f (x) ∈ Pr(Y )) for all x, we call f probability kernel. A good heuristic is
to view a probability kernel as a random function and a subprobability kernel as a random partial
function. We use well-known facts that a function f : X → Mea(Y ) is a subprobability kernel if
and only if it is a measurable map from (X , Σ) to (Sp(Y ), ΣSp(Y )), and that similarly a function f is a
probability kernel if and only if it is a measurable function from (X , Σ) to (Pr(Y ), ΣPr(Y )).

We use a few popular operators for constructing measures throughout the paper. We say that a
measure µ on a measurable space (X , Σ) is finite if µ(X ) < ∞, and σ -finite if there is a countable
partition of X into measurable subsets Xn’s such that µ(Xn) < ∞ for every n. Given a finite or
countable family of σ -finite measures {µi }i ∈I on measurable spaces (Xi , Σi )’s, the product measure
of µi ’s, denoted (cid:203)
i ∈I Σi ) such that for all measurable

i ∈I µi , is the unique measure on ((cid:206)

i ∈I Xi , (cid:203)

6Another useful fact is that when f is non-negative, ∫
taken with respect to all finite partitions {Ai }i of X into measurable subsets.

µ(dx ) f (x ) = sup (cid:205)

i (inf x ∈Ai f (x )) · µ(Ai ) where the supremum is

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:9

Real constants

c ∈ R
String constants α ∈ Str
Real expressions E ::= c | x | f (E, . . . , E)

Primitive real-valued functions

::= . . .
Primitive string-valued functions д ::= . . .

f

Boolean expressions B ::= true | E < E | B ∧ B | ¬B

String expressions

S ::= α | д(S, . . . , S, E, . . . , E)

Commands C ::= skip | x := E | C; C | if B {C} else {C} | while B {C}

| x := samplenorm(S, E, E) | scorenorm(E, E, E)

subsets Ai of Xi ,

Fig. 4. Grammar of our core language.

(cid:16) (cid:204)

µi

(cid:17) (cid:16) (cid:214)

i ∈I

i ∈I

Ai

(cid:17) = (cid:214)
i ∈I

µi (Ai ).

Given a finite or countable family of measures {µi }i ∈I on disjoint measurable spaces (Xi , Σi )’s, the
sum measure of µi ’s, denoted (cid:201)
i ∈I µi , is the unique measure on ((cid:205)
(cid:16) (cid:202)

i ∈I Σi ) such that

i ∈I Xi , (cid:201)

(cid:17) (cid:16) (cid:216)

µi

i ∈I

i ∈I

Ai

(cid:17) = (cid:213)
i ∈I

µi (Ai ).

Throughout the paper, we take the convention that the set N of natural numbers includes 0. For

all positive integers n, we write [n] to mean the set {1, 2, . . . , n}.

4 SIMPLE PROBABILISTIC PROGRAMMING LANGUAGE
In this section, we describe the syntax and semantics of a simple probabilistic programming
language, which we use to present the theoretical results of the paper. The measure semantics in
§4.2 uses results and observations from [Staton et al. 2016], but the density semantics and the other
materials in §4.3 are new in this work.

4.1 Syntax
We use an extension of the standard while language with primitives for probabilistic programming.
The grammar of the language is given in Figure 4. Variables in the language store real numbers, but
expressions may denote reals, booleans and strings, and they are classified into E, B, S based on these
denoted values. The primitive functions f for reals and д for strings may be usual arithmetic and
string operations, such as multiplication and exponentiation for f and string concatenation for д.
The grammar for C includes the cases for the standard constructs of the while language, such
as assignment, sequencing, conditional statement and loops. In addition, it has two constructs for
probabilistic programming. The first x := samplenorm(S, E1, E2) draws a sample from the normal
distribution with mean E1 and standard deviation E2 and names the sample with the string S.
The next scorenorm(E0, E1, E2) expresses that a sample is drawn from the normal distribution with
mean E1 and standard deviation E2 and the value of this sample is observed to be E0. It lets
the programmers express information about observed data inside programs. Operationally, this
construct can be understood as an instruction for updating a global variable that stores the so called
importance score of the execution. The score quantitatively records how well the random choices
in the current execution match the observations, and the score statement updates this score by
multiplying it with the density at E0 of the appropriate normal distribution.

Consider the following program:

x := samplenorm(“a”, 0.0, 5.0); scorenorm(3.0, x, 1.0).

0:10

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

The program specifies a model with one random variable “a”. Using a relatively flat normal distri-
bution, the program specifies a prior belief that the value of the random variable “a” is likely to be
close to 0.0 and lie between −2 × 5.0 and 2 × 5.0. The next score statement refines this belief with
one data point 3.0, which is a noisy observation of the value of “a” (bound to x). The parameters to
the normal density in the statement express that the noise is relatively small, between −2 × 1.0 and
2 × 1.0. Getting the refined belief, called posterior distribution, is the reason that a data scientist
writes a model like this program. It is done by an inference algorithm of the language.

Permitting only the normal distribution does not limit the type of models expressible in the
language. Every distribution can be obtained by transforming the standard normal distribution.7

4.2 Measure semantics
The denotational semantics of the language just presented is mostly standard, but employs some
twists to address the features for probabilistic programming [Staton et al. 2016].

Here is a short high-level overview of the measure semantics. Our semantics defines multiple
measurable spaces, such as Store and State, that hold mathematical counterparts to the usual actors
in computation, such as program stores (i.e., mappings from variables to values) and states (which
consist of a store and further components). Then, the semantics interprets expressions E, B, S and
commands C as measurable functions of the following types:
⟦B⟧ : Store → B,

⟦C⟧ : State → Sp(State × [0, ∞)).

⟦S⟧ : Store → Str,

⟦E⟧ : Store → R,

Here R is the measurable space of reals with the Borel σ -algebra, and B and Str are discrete
measurable spaces of booleans and strings. Store and State are measurable spaces for stores (i.e., maps
from variables to values) and states which consist of a store and a part for recording information
about sampled random variables. Note that the target measurable space of commands is built
by first taking the product of measurable spaces State and [0, ∞) and then forming a space out
of subprobability measures on State × [0, ∞). This construction indicates that commands denote
probabilistic computations, and the result of each such computation consists of an output state
and a score which expresses how well the computation matches observations expressed with the
score statements in the command C. Some of the possible outcomes of the computation may lead to
non-termination or an error, and these abnormal outcomes are not accounted for by the semantics,
which is why ⟦C⟧(σ ) for a state σ ∈ Σ is a subprobability distribution. The semantics of expressions
is much simpler. It just says that expressions do not involve any probabilistic computations, so that
they denote deterministic measurable functions.

We now explain how this high-level idea gets implemented in our semantics. Let Var be a

countably infinite set of variables. Our semantics uses the following sets:

Stores

s ∈ Store ≜ [Var → R]

(cid:16)which is isomorphic to (cid:214)
x ∈Var

R(cid:17)

Random databases

r ∈ RDB ≜ (cid:216)
K ⊆finStr

[K → R]

(cid:16)which is isomorphic to (cid:216)
K ⊆finStr

(cid:214)

R(cid:17)

α ∈K

States

σ ∈ State ≜ Store × RDB,

where [X → Y ] denotes the set of all functions from X to Y . A state σ consists of a store s and a
random database r . The former fixes the values of variables, and the latter records the name (given
7Here we consider only Borel spaces. Although using only the normal distribution does not affect the expressiveness, it has
an impact on stochastic variational inference to be discussed later, because it requires a guide to use only normal distributions.
But the impact is not significant, because most well-known approaches for creating guides from the machine-learning
literature (such as extensions of variational autoencoder) use normal distributions only, or can be made to do so easily.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:11

⟦skip⟧(σ )(A) ≜ 1[(σ,1)∈A]

⟦x := E⟧(σ )(A) ≜ 1[(σ [x (cid:55)→⟦E⟧σs ],1)∈A]
⟦C0; C1⟧(σ )(A) ≜ ∫ ⟦C0⟧(σ )(d(σ ′, w ′)) ∫ ⟦C1⟧(σ ′)(d(σ ′′, w ′′)) 1[(σ ′′,w ′ ·w ′′)∈A]

⟦if B {C0} else {C1}⟧(σ )(A) ≜ 1[⟦B⟧σs =true] · ⟦C0⟧(σ )(A) + 1[⟦B⟧σs (cid:44)true] · ⟦C1⟧(σ )(A)

⟦while B {C}⟧(σ )(A) ≜ (fix F )(σ )(A)
(cid:0)where F (κ)(σ )(A) ≜ 1[⟦B⟧σs (cid:44)true] · 1[(σ,1)∈A]

+ 1[⟦B⟧σs =true] · ∫ ⟦C⟧(σ )(d(σ ′, w ′)) ∫

κ(σ ′)(d(σ ′′, w ′′)) 1[(σ ′′,w ′ ·w ′′)∈A]

(cid:1)

⟦x := samplenorm(S, E1, E2)⟧(σ )(A) ≜ 1[⟦S ⟧σs (cid:60)dom(σr )] · 1[⟦E2⟧σs ∈(0,∞)]

· ∫ dv (cid:0)N (v; ⟦E1⟧σs , ⟦E2⟧σs ) · 1[((σs [x (cid:55)→v],σr [⟦S ⟧σs (cid:55)→v]),1)∈A]

(cid:1)

⟦scorenorm(E0, E1, E2)⟧(σ )(A) ≜ 1[⟦E2⟧σs ∈(0,∞)] · 1[(σ, N(⟦E0⟧σs ;⟦E1⟧σs,⟦E2⟧σs ))∈A]

Fig. 5. Measure semantics ⟦C⟧ ∈ K of commands C. Here N (v; µ, σ ) is the density of the normal distribution
with mean µ and standard deviation σ .

as a string) and the value of each sampled random variable. The domain of r is the names of all
the sampled random variables. By insisting that r should be a map, the semantics asserts that no
two random variables have the same name. For each state σ , we write σs and σr for its store and
random database components, respectively. Also, for a variable x, a string α and a value v, we write
σ [x (cid:55)→ v] and σ [α (cid:55)→ v] to mean (σs [x (cid:55)→ v], σr ) and (σs , σr [α (cid:55)→ v]).

We equip all of these sets with σ -algebras and turn them to measurable spaces in a standard way.
Note that we constructed the sets from R by repeatedly applying the product and disjoint-union
operators. We equip R with the usual Borel σ -algebra. Then, we parallel each usage of the product
and the disjoint-union operators on sets with that of the corresponding operators on σ -algebras.
This gives the σ -algebras for all the sets defined above. Although absent from the above definition,
the measurable spaces B and Str equipped with discrete σ -algebras are also used in our semantics.
We interpret expressions E, B, S as measurable functions ⟦E⟧ : Store → R, ⟦B⟧ : Store → B,
and ⟦S⟧ : Store → Str, under the assumption that the semantics of primitive real-valued f of
arity n and string-valued д of arity (m, l) are given by measurable functions ⟦f ⟧ : Rn → R and
⟦д⟧ : Strm × Rl → Str. It is standard, and we describe it only for some sample cases of E and S:

⟦x⟧s ≜ s(x),
⟦α⟧s ≜ α,
Lemma 4.1. For all expressions E, B, and S, their semantics ⟦E⟧, ⟦B⟧ and ⟦S⟧ are measurable

⟦д(S0, . . . , Sm−1, E0, . . . , El −1)⟧s ≜ ⟦д⟧(⟦S0⟧s, . . . , ⟦Sm−1⟧s, ⟦E0⟧s, . . . , ⟦El −1⟧s).

⟦f (E0, . . . , En−1)⟧s ≜ ⟦f ⟧(⟦E0⟧s, . . . , ⟦En−1⟧s),

functions from Store to R, B and Str, respectively.

We interpret commands C as measurable functions from State to Sp(State × [0, ∞)), i.e., subprob-
ability kernels from State to State × [0, ∞). Let K be the set of subprobability kernels from State
to State × [0, ∞), and ΣState×[0,∞) be the σ -algebra of the product space State × [0, ∞). We equip K
with the partial order ⊑: for all κ, κ ′ ∈ K, κ ⊑ κ ′ if and only if κ(σ )(A) ≤ κ ′(σ )(A) for all σ ∈ State
and A ∈ ΣState×[0,∞). The next lemma is a minor adaptation of a known result [Kozen 1981].
Lemma 4.2. (K, ⊑) is an ω-complete partial order with the least element ⊥ ≜ (λσ . λA. 0).
The measure semantics of a command C is defined in Figure 5. The interpretation of the loop
is the least fixed point of the function F on the ω-complete partial order K. The function F is
continuous, so the least fixed point is obtained by the ω-limit of the sequence {F n(⊥)}n. In the
definition of F , the argument κ is a sub-probability kernel, and it represents the computation after

0:12

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

the first iteration of the loop. The semantics of the sample statement uses an indicator function to
exclude erroneous executions where the argument S denotes a name already used by some previous
random variable, or the standard deviation ⟦E2⟧σs is not positive. When this check passes, it distils
A to a property on the value of x and computes the probability of the property using the normal
distribution with mean ⟦E1⟧σs and standard deviation ⟦E2⟧σs .

Theorem 4.3. For every command C, its interpretation ⟦C⟧ is well-defined and belongs to K.

4.3 Posterior inference and density semantics
We write a probabilistic program to answer queries about the model and data that it describes.
Among such queries, posterior inference is one of the most important and popular. Let σI = (sI , [])
be the initial state that consists of some fixed store and the empty random database. In our setting,
posterior inference amounts to finding information about the following probability measure Pr(C, ·)
for a command C. For a measurable A ⊆ RDB,

Mea(C, A) ≜

∫

⟦C⟧(σI )(d(σ , w))(w · 1[σ ∈Store×A]), ZC ≜ Mea(C, RDB), Pr(C, A) ≜

Mea(C, A)
ZC

.
(2)

The probability measure Pr(C, ·) is called the posterior distribution of C, and Mea(C, ·) the unnor-
malised posterior distribution of C (in Mea(C, ·) and Pr(C, ·), we elide the dependency on sI to avoid
clutter). Finding information about the former is the goal of most inference engines of existing
probabilistic programming languages. Of course, Pr(C, ·) is not defined when the normalising con-
stant ZC is infinite or zero. The inference engines regard such a case as an error that a programmer
should avoid, and consider only C without those errors.

Most algorithms for posterior inference use the density semantics of commands. They implicitly
pick measures on some measurable spaces used in the semantics. These measures are called
reference measures, and constructed out of Lebesgue and counting measures [Bhat et al. 2012,
2013; Hur et al. 2015]. Then, the algorithms interpret commands as density functions with respect
to these measures. One outcome of this density semantics is that the unnormalised posterior
distribution Mea(C, ·) of a command C has a measurable function f : RDB → [0, ∞) such that
Mea(C, A) = ∫
ρ(dr ) (1[r ∈A] · f (r )), where ρ is a reference measure on RDB. Function f is called
density of Mea(C, ·) with respect to ρ.

In the rest of this subsection, we reformulate the semantics of commands using density functions.

To do this, we need to set up some preliminary definitions.

First, we look at a predicate and an operator for random databases, which are about the possibility

and the very act of merging two databases. For r , r ′ ∈ RDB, define the predicate r #r ′ by:

r #r ′ ⇐⇒ dom(r ) ∩ dom(r ′) = ∅.

When r #r ′, let r ⊎ r ′ be the random database obtained by merging r and r ′:

dom(r ⊎ r ′) ≜ dom(r ) ∪ dom(r ′);

(r ⊎ r ′)(α) ≜ if α ∈ dom(r ) then r (α) else r ′(α).

Lemma 4.4. For every measurable h : RDB × RDB × RDB → R, the function (r , r ′) (cid:55)−→ 1[r #r ′] ×

h(r , r ′, r ⊎ r ′) from RDB × RDB to R is measurable.

Second, we define a reference measure ρ on RDB:
(cid:17)

(cid:16) (cid:204)

ρ(R) ≜ (cid:213)
K ⊆finStr

λ

(R ∩ [K → R]),

α ∈K
where λ is the Lebesgue measure on R. As explained in the preliminary section, the symbol ⊗
here represents the operator for constructing a product measure. In particular, (cid:203)
α ∈K λ refers to

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:13

the product of the |K | copies of the Lebesgue measure λ on R. In the above definition, we view
functions in [K → R] as tuples with |K | real components and measure sets of such functions using
the product measure (cid:203)
α ∈K λ is the nullary-product measure
on {[]}, which assigns 1 to {[]} and 0 to the empty set.

α ∈K λ. When K is the empty set, (cid:203)

The measure ρ computes the size of each measurable subset R ⊆ RDB in three steps. It splits
a given R into groups based on the domains of elements in R. Then, it computes the size of each
group separately, using the product of the Lebesgue measure. Finally, it adds the computed sizes.
The measure ρ is not finite, but it satisfies the σ -finiteness condition,8 the next best property.

Third, we define a partially-ordered set D with certain measurable functions. We say that a
function д : Store × RDB → {⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞)) uses random databases locally or
is local if for all s, s ′ ∈ Store, r , r ′ ∈ RDB, and w ′, p ′ ∈ [0, ∞),

д(s, r ) = (s ′, r ′, w ′, p ′) =⇒ (∃r ′′. r ′#r ′′ ∧ r = r ′ ⊎ r ′′ ∧ д(s, r ′′) = (s ′, [], w ′, p ′))

∧ (∀r ′′′. r #r ′′′ =⇒ д(s, r ⊎ r ′′′) = (s ′, r ′ ⊎ r ′′′, w ′, p ′)).

д : Store × RDB → {⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞))

The condition describes the way that д uses a given random database r , which plays the role of a
bank of random seeds (that д may partially consume as it needs random values). Some part r ′′ of r
may be consumed by д, but the unconsumed part r ′ of r does not change and is returned in the
output. Also, the behaviour of д does not depend on the unconsumed r ′. We define the set D by
D ≜(cid:110)
Here we view {⊥} and [0, ∞) as measurable spaces equipped with discrete and Borel σ -algebras.
Also, we regard Store × RDB and {⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞)) as measurable spaces
constructed by the product and disjoint-union operators on measurable spaces, as explained in §3.
The locality in the definition of D formalises expected behaviours of commands. In fact, as we
will show shortly, it is satisfied by all commands in our density semantics. This property plays an
important role when we establish the connection between the density semantics in this subsection
and the standard measure semantics in §4.2.

(cid:12) д is measurable and local(cid:111)

(3)

(cid:12)
(cid:12)

.

The functions in D are ordered pointwise: for all д, д′ ∈ D,

д ⊑ д′ ⇐⇒ ∀(s, r ) ∈ Store × RDB. (д(s, r ) = ⊥ ∨ д(s, r ) = д′(s, r )).
Lemma 4.5. (D, ⊑) is an ω-complete partial order and has the least element a (cid:55)−→ ⊥. Thus, every

continuous function G on D has a least fixed point (and this least fixed point is unique).

For each д ∈ D, let д‡ be the following lifting to a function on {⊥} ∪(Store ×RDB×[0, ∞)×[0, ∞)):

д‡(⊥) ≜ ⊥,

д‡(s, r, w, p) ≜

(cid:26) ⊥

(s ′, r ′, w × w ′, p × p ′)

if д(s, r ) = ⊥,
if д(s, r ) = (s ′, r ′, w ′, p ′).

This lifting lets us compose two functions in D.

Using these preliminary definitions, we define a density semantics in Figure 6, where a command
C means a function ⟦C⟧
d ∈ D. The notation r \ v in the figure means the removal of the entry v
from the finite map r if v ∈ dom(r ); otherwise, r \ v is just r . The set membership ⟦C⟧
d ∈ D says
that ⟦C⟧
is a local measurable function from Store × RDB to {⊥} ∪ Store × RDB × [0, ∞) × [0, ∞).
d
Thus, the function ⟦C⟧
takes a store s and a random database r as inputs, where the former fixes
d
the values of variables at the start of C and the latter specifies random seeds some of which C may
consume to sample random variables. Given such inputs, the function outputs an updated store
s ′, the part r ′ of r not consumed by C, the total score w ′ expressing how well the execution of C
8The condition lets us use Fubini theorem when showing the well-formedness of the density semantics in this subsection
and relating this semantics with the measure semantics in the previous subsection.

0:14

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

⟦skip⟧
⟦x:=E⟧
⟦C0; C1⟧
⟦if B {C0} else {C1}⟧
⟦while B {C}⟧

d (s, r ) ≜ (s, r , 1, 1)
d (s, r ) ≜ (s[x (cid:55)→ ⟦E⟧s], r , 1, 1)
d (s, r ) ≜ (⟦C1⟧‡
d )(s, r )
d (s, r ) ≜ if (⟦B⟧s = true) then ⟦C0⟧
d (s, r ) ≜ (fix G)(s, r )

◦ ⟦C0⟧

d

d (s, r ) else ⟦C1⟧

d (s, r )

(where G(д)(s, r ) = if (⟦B⟧s (cid:44) true) then (s, r , 1, 1) else (д‡ ◦ ⟦C⟧

d )(s, r ))

⟦x:=samplenorm(S, E1, E2)⟧

d (s, r ) ≜ if (⟦S⟧s (cid:60) dom(r ) ∨ ⟦E2⟧s (cid:60) (0, ∞)) then ⊥

else (s[x (cid:55)→ r (⟦S⟧s)], r \ ⟦S⟧s, 1, N (r (⟦S⟧s); ⟦E1⟧s, ⟦E2⟧s))

⟦scorenorm(E0, E1, E2)⟧

d (s, r ) ≜ if (⟦E2⟧s (cid:60) (0, ∞)) then ⊥ else (s, r , N (⟦E0⟧s; ⟦E1⟧s, ⟦E2⟧s), 1)

Fig. 6. Density semantics ⟦C⟧

d ∈ D of commands C

matches observations, and the probability density p ′ of C at the consumed part of r . If r does not
contain enough random seeds, or the execution of C encounters some runtime error, or it falls into
an infinite loop, then the function returns ⊥.

Lemma 4.6. For every command C, its semantics ⟦C⟧
The density semantics ⟦C⟧
d

is closely related to the measure semantics ⟦C⟧ defined in §4.2. Both
interpretations of C describe the computation of C but from slightly different perspectives. To state
this relationship formally, we need a few notations. For д ∈ D and s ∈ Store, define

d is well-defined and belongs to D.

dens(д, s) : RDB → [0, ∞),

dens(д, s)(r ) ≜

get(д, s) : RDB → Store ∪ {⊥},

get(д, s)(r ) ≜

(cid:26) w ′ × p ′

0

if ∃s ′, w ′, p ′. (д(s, r ) = (s ′, [], w ′, p ′)),
otherwise,

(cid:26) s ′

if ∃s ′, w ′, p ′. (д(s, r ) = (s ′, [], w ′, p ′)),

⊥ otherwise.

Both dens(д, s) and get(д, s) are concerned with random databases r that precisely describe the
randomness needed by the execution of д from s. This is formalised by the use of [] in the definitions.
The function dens(д, s) assigns a score to such an r , and in so doing, it defines a probability density
on RDB with respect to the reference measure ρ. The function get(д, s) computes a store that
the computation of д would result in when started with such an r . We often write dens(C, s) and
get(C, s) to mean dens(⟦C⟧

d , s), respectively.

d , s) and get(⟦C⟧

Lemma 4.7. For all д ∈ D, the following functions from Store × RDB to R and {⊥} ∪ Store are

measurable: (s, r ) (cid:55)−→ dens(д, s)(r ) and (s, r ) (cid:55)−→ get(д, s)(r ).

The next lemma is the main reason that we considered the locality property. It plays a crucial

role in proving Theorem 4.9, the key result of this subsection.

Lemma 4.8. For all non-negative bounded measurable functions h : ({⊥} ∪ Store) × RDB → R,

stores s, and functions д1, д2 ∈ D, we have that

∫

(cid:16)

ρ(dr )

dens(д‡

2 ◦ д1, s)(r ) · h

(cid:16)

get(д‡

2 ◦ д1, s)(r ), r

(cid:17)(cid:17)

∫

=

(cid:16)

ρ(dr1)

dens(д1, s)(r1) · 1[get(д1,s)(r1)(cid:44)⊥]

∫

·

(cid:16)

ρ(dr2)

dens(д2, get(д1, s)(r1))(r2) · 1[r1#r2] · h

(cid:16)

get(д2, get(д1, s)(r1))(r2), r1 ⊎ r2

(cid:17)(cid:17)(cid:17)

.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:15

Assume that ({⊥} ∪ Store) × RDB is ordered as follows: for all (a, r ), (a′, r ′) ∈ ({⊥} ∪ Store) × RDB,
(a, r ) ⊑ (a′, r ′) ⇐⇒ (a = ⊥ ∨ a = a′) ∧ r = r ′.
Theorem 4.9. For all non-negative bounded measurable monotone functions h : ({⊥} ∪ Store) ×

RDB → R and states σ ,
∫

⟦C⟧(σ )(d(σ ′, w ′)) (w ′ ·h(σ ′

s , σ ′

r )) =

∫

(cid:16)

ρ(dr ′)

dens(C, σs )(r ′) · 1[r ′#σr ] ·h(get(C, σs )(r ′), r ′ ⊎ σr )

(cid:17)

.

Corollary 4.10. Mea(C, A) = ∫
Proof. We instantiate Theorem 4.9 with h(a, r ) = 1[r ∈A] and σ = σI . Recall that (σI )s = sI and

ρ(dr ) (1[r ∈A] · dens(C, sI )(r )) for all C and all measurable A.

(σI )r = []. Thus, the conclusion of Theorem 4.9 in this case says that

∫

⟦C⟧(σI , d(σ ′, w ′)) (w ′ · 1[σ ′

r ∈A]) =

=

∫

∫

(cid:16)

(cid:16)

ρ(dr ′)

ρ(dr ′)

dens(C, sI )(r ′) · 1[r ′#(σI )r ] · 1[r ′⊎(σI )r ∈A]

(cid:17)

dens(C, sI )(r ′) · 1[r ′ ∈A]

(cid:17)

.

This gives the equation claimed by the corollary.

□

This corollary says that dens(C, sI ) is the density of the measure Mea(C, ·) with respect to ρ, and
supports our informal claim that ⟦C⟧
d

computes the density of the measure ⟦C⟧.

5 STOCHASTIC VARIATIONAL INFERENCE
In this section, we explain stochastic variational inference (SVI) algorithms using the semantics
that we have developed so far. In particular, we describe the requirements made implicitly by one
fundamental SVI algorithm, which is regarded most permissive by the ML researchers because the
algorithm does not require the differentiability of the density of a given probabilistic model.

We call a command C model if it has a finite nonzero normalising constant:

ZC = Mea(C, RDB) = (cid:16) ∫

⟦C⟧(σI )(d(σ , w)) w

(cid:17)

∈ (0, ∞),

where σI is the initial state. Given a model C, the SVI algorithms attempt to infer a good approx-
imation of C’s posterior distribution Pr(C, ·) defined in (2). They tackle this posterior-inference
problem in two steps.

First, the SVI algorithms fix a collection of approximate distributions. They usually do so by
asking the developer of C to provide a command Dθ parameterised by θ ∈ Rp , which can serve as a
template for approximation distributions. The command Dθ typically has a control-flow structure
similar to that of C, but it is simpler than C: it does not use any score statements, and may replace
complex computation steps of C by simpler ones. In fact, Dθ should satisfy two formal requirements,
which enforce this simplicity. The first is

Mea(Dθ , RDB) = 1

for all θ ∈ Rp,

which means that the normalising constant of Dθ is 1. The second is that Dθ should keep the score
(i.e., the w component) to be 1, i.e.,

⟦Dθ ⟧(σI )(State × ([0, ∞) \ {1})) = 0.
Meeting these requirements is often not too difficult. A common technique is to ensure that Dθ does
not use the score statement and always terminates. Figure 7 gives an example of (C, Dθ ) for simple
Bayesian linear regression with three data points. Note that in this case, Dθ is obtained from C by
deleting the score statements and replacing the arguments 0.0 and 5.0 of normal distributions by

0:16

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

model C ≡ (cid:0)s := samplenorm(“slope”, 0.0, 5.0); i := samplenorm(“intercept”, 0.0, 5.0);
x1 := 1.0; y1 := 2.3; x2 := 2.0; y2 := 4.2; x3 := 3.0; y3 := 6.9;
scorenorm(y1, s · x1 + i, 1.0); scorenorm(y2, s · x2 + i, 1.0); scorenorm(y3, s · x3 + i, 1.0)(cid:1)

guide Dθ ≡ (cid:0)s := samplenorm(“slope”, θ1, exp(θ2)); i := samplenorm(“intercept”, θ3, exp(θ4))(cid:1)

Fig. 7. Example model-guide pair for simple Bayesian linear regression.

parameter θ = (θ1, θ2, θ3, θ4). Following the terminology of Pyro, we call a parameterised command
Dθ guide if it satisfies the two requirements just mentioned.

Second, the SVI algorithms search for a good parameter θ that makes the distribution described
by Dθ close to the posterior of C. Concretely, they formulate an optimisation problem where the
optimisation objective expresses that some form of distance from Dθ ’s distribution to C’s posterior
should be minimised. Then, they solve the problem by a version of gradient descent.

The KL divergence is a standard choice for distance. Let µ, µ ′ be measures on RDB that have

densities д and д′ with respect to the measure ρ. The KL divergence from д to д′ is defined by

KL(д||д′) ≜

∫

ρ(dr )

(cid:18)
д(r ) · log д(r )
д′(r )

(cid:19)

.

(4)

In words, it is the ratio of densities д and д′ averaged according to д. If д = д′, the ratio is always 1,
so that the KL becomes 0. The KL divergence is defined only if the following conditions are met:
• Absolute continuity: д′(r ) = 0 =⇒ д(r ) = 0 for all r ∈ RDB,9 which ensures that the
integrand in (4) is well-defined even when the denominator д′(r ) in (4) takes the value 0;

• Integrability: the integral in (4) has a finite value.
Using our semantics, we can express the KL objective as follows:

argmin

θ ∈Rp KL

(cid:18)

dens(Dθ , sI )

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

dens(C, sI )
ZC

(cid:19)

.

(5)

Recall that dens(Dθ , sI ) and dens(C, sI )/ZC are densities of the probability measures of the command
Dθ and the posterior of C (Corollary 4.10), and they are defined by means of our density semantics
in §4.3. Most SVI engines solve this optimisation problem by a version of gradient descent.

In the paper, we consider one of the most fundamental and versatile SVI algorithms. The algorithm
is called score estimator or REINFORCE, and it works by estimating the gradient of the objective in
(5) using samples and performing the gradient descent with this estimated gradient. More concretely,
the algorithm starts by initialising θ with some value (usually chosen randomly) and updating it
repeatedly by the following procedure:

(i) Sample r1, . . . , rN independently from dens(Dθ , sI )

(ii) θ ← θ − η ×

(cid:32) 1
N

N
(cid:213)

(cid:16)

i=1

∇θ log dens(Dθ , sI )(ri )

(cid:17)

· log dens(Dθ , sI )(ri )
dens(C, sI )(ri )

(cid:33)

Here N and η are hyperparameters to this algorithm, the former determining the number of samples
used to estimate the gradient and the latter, called learning rate, deciding how much the algorithm
should follow the direction of the estimated gradient. Although we do not explain here, sampling
r1, . . . , rN and computing all of dens(Dθ , sI )(ri ), dens(C, sI )(ri ) and ∇θ (log dens(Dθ , sI )(ri )) can be
done by executing Dθ and C multiple times under slightly unusual operational semantics [Yang
2019]. The SVI engines of Pyro and Anglican implement such operational semantics.

9This condition can be relaxed in a more general formulation of the KL divergence stated in terms of the so called Radon-
Nikodym derivative. We do not use the relaxed condition to reduce the amount of materials on measure theory in the paper.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:17

The average over the N terms in the θ -update step is the core of the algorithm. It approximates

the gradient of the optimisation objective in (5):

∇θ KL

(cid:18)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
dens(Dθ , sI )
(cid:12)
(cid:12)

dens(C, sI )
ZC

(cid:19)

≈

1

N

N
(cid:213)

(cid:16)

i=1

∇θ log dens(Dθ , sI )(ri )

(cid:17)

· log dens(Dθ , sI )(ri )
dens(C, sI )(ri )

.

The average satisfies an important property called unbiasedness, summarised by Theorem 5.1.

Theorem 5.1. Let C be a model, Dθ be a guide, and N (cid:44) 0 ∈ N. Define KL(−) : Rp → R≥0 as KLθ
≜ KL(dens(Dθ , sI )||dens(C, sI )/ZC ). Then, KL(−) is well-defined and continuously differentiable with

∇θ KLθ = E(cid:206)

i dens(Dθ ,sI )(ri )

(cid:34) 1
N

N
(cid:213)

(cid:16)

i=1

∇θ log dens(Dθ , sI )(ri )

(cid:17) log dens(Dθ , sI )(ri )
dens(C, sI )(ri )

(cid:35)

(6)

if
(R1) dens(C, sI )(r ) = 0 =⇒ dens(Dθ , sI )(r ) = 0, for all r ∈ RDB and θ ∈ Rp ;
(R2) for all (r , θ, j) ∈ RDB × Rp × [p], the function v (cid:55)−→ dens(Dθ [j:v], sI )(r ) on R is differentiable;
(R3) for all θ ∈ Rp ,

∫

(cid:18)

ρ(dr )

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:19)

< ∞;

(R4) for all (θ, j) ∈ Rp × [p], the function

∫

(cid:18)

ρ(dr )

v (cid:55)−→

dens(Dθ [j:v], sI )(r ) · log

dens(Dθ [j:v], sI )(r )
dens(C, sI )(r )

(cid:19)

on R is continuously differentiable;

(R5) for all θ ∈ Rp ,

∫

∇θ

(cid:18)

ρ(dr )

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:19)

∫

=

(cid:18)

ρ(dr ) ∇θ

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:19)

;

(R6) for all θ ∈ Rp ,

∫

ρ(dr ) ∇θ dens(Dθ , sI )(r ) = ∇θ

∫

ρ(dr ) dens(Dθ , sI )(r ).

Here θ [j : v] denotes a vector in Rp that is the same as θ except that its j-th component is v.

The conclusion of this theorem (Equation (6)) and its proof are well-known [Ranganath et al. 2014],
but the requirements in the theorem (and the continuous differentiability of KLθ in the conclusion)
are rarely stated explicitly in the literature.

The correctness of the algorithm crucially relies on the unbiasedness property in Theorem 5.1.
The property ensures that the algorithm converges to a local minimum with probability 1. Thus, it
is important that the requirements in the theorem are met. In fact, some of the requirements there
are needed even to state the optimisation objective in (5), because without them, the objective does
not exist. In the next section, we describe conditions that imply those requirements and can serve
as target properties of program analysis for probabilistic programs. The latter point is worked out
in detail in §7 and §8 where we discuss program analysis for probabilistic programs and SVI.

0:18

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

6 CONDITIONS FOR STOCHASTIC VARIATIONAL INFERENCE
Ideally we want to have program analysers that discharge the six requirements R1-R6 in Theorem 5.1.
However, except R1 and R2, the requirements are not ready for serving as the targets of static
analysis algorithms. Automatically discharging them based on the first principles (such as the
definition of integrability with respect to a measure) may be possible, but seems less immediate
than doing so using powerful theorems from continuous mathematics.

In this section, we explain conditions that imply the requirements R3-R6 and are more friendly
to program analysis than the requirements themselves. The conditions are given in two boxes (9)
and (10). Throughout the section, we fix a model C and a guide Dθ .

6.1 Assumption
Throughout the section, we assume that the densities of Dθ and C have the following form:

dens(Dθ , sI )(r ) =

M
(cid:213)

i=1

dens(C, sI )(r ) =

M
(cid:213)

i=1

1[r ∈Ai ]

where

(cid:214)

1[r ∈Ai ]

N (cid:0)r (α); µ(i,α )(θ ), σ(i,α )(θ )(cid:1),

(7)

α ∈Ki

(cid:32)

(cid:214)

α ∈Ki

N (cid:0)r (α); µ ′

(i,α )(r ), σ ′

(i,α )(r )(cid:1)

(cid:33)

(cid:169)
(cid:173)
(cid:171)

(cid:214)

j ∈[Ni ]

N (cid:0)c(i, j); µ ′′

(i, j)(r ), σ ′′

(i, j)(r )(cid:1)(cid:170)
(cid:174)
(cid:172)

,

• M, Ni ∈ N \ {0};
• A1, . . . , AM are disjoint measurable subsets of RDB;
• Ki ’s are finite sets of strings such that dom(r ) = Ki for all r ∈ Ai ;
• µ(i,α ) and σ(i,α ) are measurable functions from Rp to R and (0, ∞), respectively;
are measurable functions from [Ki → R] to R;
and µ ′′
• µ ′
are measurable functions from [Ki → R] to (0, ∞);
and σ ′′
• σ ′
• c(i, j) is a real number.

(i,α )

(i,α )

(i, j)

(i, j)

In programming terms, our assumption first implies that both C and Dθ use at most a fixed number
of random variables. That is, the number of random variables they generate must be finite not only
within a single execution but also across all possible executions since the names of all random
variables are found in a finite set (cid:208)M
i=1 Ki . This property is met if the number of steps in every
execution of C and Dθ from σI is bounded by some T and the executions over the same program
path use the same set of random variables. Note that the bound may depend on sI . Such a bound
exists for most probabilistic programs.10 Also, the assumption says that the parameters of normal
distributions in sample statements in Dθ may depend only on θ , but not on other sampled random
variables. This is closely related to a common approach for designing approximate distributions in
variational inference, called mean-field approximation, where the approximate distribution consists
of independent normal random variables.

We use the term “assumption” here, instead of “condition” in the following subsections because
the assumed properties are rather conventional and they are not directly related to the requirements
in Theorem 5.1, at least not as much as the conditions that we will describe next.

10Notable exceptions are models using probabilistic grammars or those from Bayesian nonparametrics.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:19

6.2 Condition for the requirement R3
Note that the integral in the requirement R3 can be written as the sum of two expectations:

(cid:19)

∫

(cid:18)

ρ(dr )

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )
= Edens(Dθ ,sI )(r ) [log dens(Dθ , sI )(r )] − Edens(Dθ ,sI )(r ) [log dens(C, sI )(r )] .
The minus of the first term (i.e., −Edens(Dθ ,sI )(r ) [log dens(Dθ , sI )(r )]) is called the differential
entropy of the density dens(Dθ , sI ). Intuitively, it is large when the density on Rn is close to the
Lebesgue measure, which is regarded to represent the absence of information. The differential
entropy is sometimes undefined [Ghourchian et al. 2017]. Fortunately, a large class of proba-
bility densities (containing many commonly used probability distributions) have well-defined
entropies [Ghourchian et al. 2017; Nair et al. 2006]. Our dens(Dθ , sI ) is one of such fortunate cases.

(8)

Theorem 6.1. Edens(Dθ ,sI )(r ) [| log dens(Dθ , sI )(r )|] < ∞ under our assumption in §6.1.
We remark that a violation of the assumption (7) for Dθ can result in an undefined entropy, as

illustrated by the following examples.

Example 6.2. Consider guides D(i,θ ) defined as follows (i = 1, 2):

D(i,θ ) ≡ (x1 := samplenorm(“a1”, θ1, 1); x2 := samplenorm(“a2”, θ2, Ei [x1]))

where for some n ≥ 1 and c (cid:44) 0 ∈ R,11

E1[x1] ≡ if (x1=0) then 1 else exp(−1/|x1|n),

E2[x1] ≡ exp(exp(c · x

3
1)).

None of dens(D(i,θ ), sI )’s satisfies the assumption (7) because the standard deviation of the normal
distribution for x2 depends on the value of x1. The entropies of dens(D(i,θ ), sI )’s are all undefined:
□
Edens(D(i, θ ),sI )(r )[| log dens(D(i,θ ), sI )(r )|] = ∞ for all i = 1, 2.

Since the first term of (8) is always finite by Theorem 6.1, it is enough to ensure the finiteness of

the second term of (8). For i ∈ [M], define the set of (absolute) affine functions on [Ki → R] as:
(cid:12) f (r ) = c + (cid:213)

(cα · |r (α)|) for some c, cα ∈ R(cid:111)

f ∈ [[Ki → R] → R]

Ai ≜ (cid:110)

(cid:12)
(cid:12)

.

α ∈Ki

Our condition for ensuring the finiteness of the second term is as follows:

For all i ∈ [M], there are f ′, f ′′, l ′, u ′, l ′′, u ′′ ∈ Ai such that

(i,α )(r )| ≤ exp(f ′(r )),
|µ ′
(i, j)(r )| ≤ exp(f ′′(r )),
|µ ′′

exp(l ′(r )) ≤ σ ′
exp(l ′′(r )) ≤ σ ′′

(i,α )(r ) ≤ exp(u ′(r )),
(i, j)(r ) ≤ exp(u ′′(r )),

all four hold for every (α, j, r ) ∈ Ki × [Ni ] × Ai .

(9)

Theorem 6.3. The condition (9) implies Edens(Dθ ,sI )(r ) [| log dens(C, sI )(r )|] < ∞ under our assump-
tion in §6.1. Thus, in that case, it entails the requirement R3 (i.e., the objective in (5) is well-defined).

Our condition in (9) is sufficient but not necessary for the objective in (5) to be defined. However,

its violation is a good warning, as illustrated by our next examples.

11Formally, we should implement E1[x1] as an application of a primitive function f1 to x1 that has the semantics described
by the if-then-else statement here.

0:20

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

Example 6.4. Consider models C1, . . . , C4 and a guide Dθ defined as follows:

Ci ≡ (x1 := samplenorm(“a1”, 0, 1); x2 := samplenorm(“a2”, Ei [x1], 1))
Ci ≡ (x1 := samplenorm(“a1”, 0, 1); x2 := samplenorm(“a2”, 0, Ei [x1]))
Dθ ≡ (x1 := samplenorm(“a1”, θ1, 1); x2 := samplenorm(“a2”, θ2, 1))

for i = 1, 2
for i = 3, 4

where for some n ≥ 1 and c (cid:44) 0 ∈ R,

E1[x1] ≡ if (x1=0) then 0 else

1
x n
1

, E2[x1] ≡ E4[x1] ≡ exp(c·x

3
1), E3[x1] ≡ if (x1=0) then 1 else |x1|n .

Let A = [{“a1”, “a2”} → R]. For r ∈ A, define

1(r ) ≜ if r (“a1”) = 0 then 0 else 1/r (“a1”)n,
µ ′
3(r ) ≜ if r (“a1”) = 0 then 1 else |r (“a1”)|n,
σ ′

2(r ) ≜ exp(c · r (“a1”)3),
µ ′
4(r ) ≜ exp(c · r (“a1”)3).
σ ′

Then, we have that

dens(Ci , sI )(r ) = 1[r ∈A] · N (r (“a1”); 0, 1) · N (r (“a2”); µ ′
i (r ), 1)
dens(Ci , sI )(r ) = 1[r ∈A] · N (r (“a1”); 0, 1) · N (r (“a2”); 0, σ ′
i (r ))
dens(Dθ , sI )(r ) = 1[r ∈A] · N (r (“a1”); θ1, 1) · N (r (“a2”); θ2, 1).
1, µ ′

for i = 1, 2
for i = 3, 4

2, σ ′

3, and σ ′

None of µ ′
1 is not bounded in {r ∈
4 satisfies the condition in (9). The function µ ′
A | −1 ≤ r (“a1”) ≤ 1 ∧ −1 ≤ r (“a2”) ≤ 1}, but every µ ′ satisfying the condition in (9) should be
2 cannot be bounded by any linear exponential
bounded. Also, the cubic exponential growth of µ ′
function on r . The violation of the condition by σ ′
3 and σ ′

4 can be shown similarly.

In fact, the objective in (5) is not defined for all of the four cases. This is because for all i = 1, . . . , 4,
□

Edens(Dθ ,sI )(r ) [| log dens(Ci , sI )(r )|] = ∞.

We now show that the condition in (9) is satisfied by a large class of functions in machine
learning applications, including functions using neural networks. We call a function nn : Rn → R
: Rnj → Rnj+1 and affine functions
an affine-bounded neural network if there exist functions fj
: Rnj → R for all 1 ≤ j ≤ d such that (i) n1 = n and nd +1 = 1; (ii) nn = fd ◦ · · · ◦ f1; and
lj
(iii) ∥ fj (v)∥1 ≤ lj (|v1|, . . . , |vnj |) for all 1 ≤ j ≤ d and v ∈ Rnj , where ∥ · ∥1 denotes the ℓ1-norm.
Note that each component of fj can be, for instance, an affine function, one of commonly used
activation functions (e.g., relu, tanh, sigmoid, softplus), or one of min/max functions (min and max).
Therefore, most of neural networks used in machine learning applications are indeed affine-bounded.
Lemma 6.5 indicates that a wide range of functions satisfy the condition (9).

Lemma 6.5. Pick i ∈ [M] and α ∈ Ki . Let (α1, . . . , α J ) be an enumeration of the elements in Ki , and
r ≜ (r (α1), . . . , r (α J )) ∈ RJ be an enumeration of the values of r ∈ Ai . Consider any affine-bounded
neural network nn : RJ → R, polynomial poly : RJ → R, and c ∈ (0, ∞). Then, the below list of
functions µ ′

(i,α ) on Ai satisfy the condition in (9):

(i,α ) and σ ′
(i,α )(r ) = nn(r ),
µ ′
(i,α )(r ) = |nn(r )| + c,
σ ′
(i,α )(r ) = (|nn(r )| + c)−1,
σ ′

(i,α )(r ) = exp(nn(r )),
µ ′
(i,α )(r ) = exp(nn(r )),
σ ′
(i,α )(r ) = softplus(nn(r )),
σ ′
where softplus(v) ≜ log(1 + exp(v)). Moreover, the same holds for µ ′′
(i, j) and σ ′′
(i, j) as well.

(i,α )(r ) = poly(r ),
µ ′
(i,α )(r ) = |poly(r )| + c,
σ ′
(i,α )(r ) = (|poly(r )| + c)−1,
σ ′

Lemma 6.5 follows from properties about functions having affine-exponential functions as their

upper or lower bounds, summarised by the next lemma:

Lemma 6.6. Assume the setting of Lemma 6.5. Then, we have the following.
• Eq(r ) [exp(l(r ))] < ∞ for every l ∈ Ai and every J -dimensional normal distribution q.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:21

• For some l, l ′ ∈ Ai , |poly(r )| ≤ exp(l(r )) and |nn(r )| ≤ l ′(r ) for all r ∈ Ai .
• For some affine functions l, l ′ : R → R, exp(l(|v |)) ≤ softplus(v) ≤ exp(l ′(|v |)) for all v ∈ R.
• For every l1, l2 ∈ Ai and every ⊙ ∈ {+, −, ×, /, max}, there exists l ∈ Ai such that exp(l1(r )) ⊙

exp(l2(r )) ≤ exp(l(r )) for all r ∈ Ai .

6.3 Condition for the requirements R4-R6
Assume that the model C and the guide Dθ satisfy our assumption and condition in the previous
two subsections. Our condition for the requirements R4-R6 is given below:

For all i ∈ [M], α ∈ Ki , and (θ, j) ∈ Rp × [p],

the function v ∈ R (cid:55)−→ µ(i,α )(θ [j : v]) is continuously differentiable;
the function v ∈ R (cid:55)−→ σ(i,α )(θ [j : v]) is continuously differentiable.

(10)

Theorem 6.7. If both our assumption in §6.1 and the condition (9) hold, then the condition (10)

implies the requirements R4-R6.

The proof of the theorem uses the following nontrivial result [Klenke 2014, Theorem 6.28] about
exchanging differentiation and integration, a consequence of the dominated convergence theorem.

Theorem 6.8. Let V ⊂ R be an open interval, and (X , Σ, µ) be a measure space. Suppose that a
measurable function f : V × X → R satisfies the following conditions: (a) for all v ∈ V , the integral
∫
µ(dx) fv (x) is well-defined; (b) for almost all x ∈ X (w.r.t. µ) and all v ∈ V , the partial derivative
∇v fv (x) with respect to v is well-defined;12 (c) there is a measurable function h : X → R such that
∫
µ(dx) h(x) is well-defined and |∇v fv (x)| ≤ h(x) for all v ∈ V and almost all x ∈ X (w.r.t. µ). Then,

for all v ∈ V , both sides of the below equation are well-defined, and the equality holds:

∫

∇v

µ(dx) fv (x) =

∫

µ(dx) ∇v fv (x).

Note that the theorem ensures not only the validity of interchanging differentiation and integration,
but also the differentiability of ∫
µ(dx) fv (x) (w.r.t. v) and the integrability of ∇v fv (x) over x ∈ X .
Our condition in (10) is sufficient but not necessary for the requirements R4-R6 to hold, in
particular for the objective in (5) to have well-defined partial derivatives in θ . However, its violation
is a good indication of a potential problem. The following example illustrates this point.

Example 6.9. Consider a model C and a guide Dθ defined as follows:

C ≡ x := samplenorm(“a”, 0, 1)

Dθ ≡ x := samplenorm(“a”, 0, E[θ ])

where E[θ ] ≡ relu(θ )+2 and relu(v) ≜ 1[v ≥0]·v. Such E[θ ] can definitely appear in machine learning
applications, once a guide starts to use neural networks with parameters θ . Let A = [{“a”} → R]
and σ (θ ) ≜ relu(θ ) + 2. Then, dens(C, sI )(r ) = 1[r ∈A] · N (r (“a”); 0, 1) and dens(Dθ , sI )(r ) = 1[r ∈A] ·
N (r (“a”); 0, σ (θ )). Note (10) is violated: σ is non-differentiable at θ = 0. A simple calculation shows:

∫

∇θ

(cid:18)

ρ(dr )

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:19)

=

0
((2 + θ )2 − 1)/(2 + θ )
undefined

if θ ∈ (−∞, 0)
if θ ∈ (0, ∞)
if θ = 0.





Hence, the objective in (5) does not have a well-defined partial derivative in θ at θ = 0.

□

12A more popular notation is (∂fv (x ))/(∂v), but we opt for ∇v fv (x ) to avoid clutter.

0:22

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

7 ANALYSIS
In this section, we describe a recipe for building a static analysis that automatically discharges
some of the assumptions and conditions given in §6. The recipe ensures that the constructed static
analyses are sound with respect to the density semantics in §4.3. We illustrate it by describing
four static analyses for verifying the model-guide support match (the requirement R1), the guide-
parameter differentiability (the requirement R2), the condition (9), and the condition (10). The
analysis for the model-guide support match has been developed significantly more for the Pyro
programming language, and applied to analyse realistic examples of the language. This fully-blown
analysis and our experiments will be described in §8.

Throughout this section, we assume that the parameters θ of a guide Dθ are included in Var, and
are only read by Dθ and not accessed by a model C. What we used to call sI will be the part of the
store for variables in Var \ θ , and what we used to write θ will correspond to the other part for θ .

7.1 A generic program analysis framework
Our recipe is for building a static analysis that infers information about the state transformation of
a given command. It is similar to the conventional methodology for building a so called relational
static analysis, which also attempts to find information about the relationship between input and
output states of a given command. However, our recipe diverges from the convention in one
important point: while the abstract states of conventional relational analyses represent relations
on states, we let abstract states directly express sets of concrete state transformers. This departure
from the convention is due to the difficulty of using relations for expressing properties of state
transformers that we desire. For instance, we could not express a set of functions with a certain
type of differentiability using relations.

Recall the domain D in (3), and the notion of admissible subset from domain theory: D0 ⊆ D is

admissible if it contains ⊥ and is closed under taking the limits of ω-chains in D0.
Our recipe assumes an abstraction instance defined by the following items:

• An abstract domain, i.e., a set T ♯ with a designated element ⊥♯.
• A concretisation function, i.e., a function γ : T ♯ → P(D) such that for every t ∈ T ♯, γ (t)
is an admissible subset of D. Note that the concretisation interprets each abstract element
t as a set of concrete transformers in D. The admissibility is imposed to enable the sound
analysis of loops.

γ (ti ) ⊆ γ (widen(t1, t2)) and for every sequence {tn }n ≥1 in T ♯, its widened sequence {t ′
= t ′
defined by t ′

• A widening operator widen : T ♯ × T ♯ → T ♯, such that for all t1, t2 ∈ T ♯ and i ∈ [2],
n }n ≥1,
m+1.
• An abstract conditional operator for every expression E, that is, a function cond(E)♯ : T ♯ ×
T ♯ → T ♯ such that for all t1, t2 ∈ T ♯ and д1, д2 ∈ D, if д1 ∈ γ (t1) and д2 ∈ γ (t2), then
(cid:0)λ(s, r ).(if (⟦E⟧s=true) then д1(s, r ) else д2(s, r ))(cid:1) ∈ γ (cond(E)♯(t1, t2)).

n, tn+1) for n ≥ 1, has an index m such that t ′
m

n+1 ≜ widen(t ′

1 ≜ t1 and t ′

• An abstract composition operator ◦♯ : T ♯ × T ♯ → T ♯ such that for all t1, t2 ∈ T ♯ and

д1, д2 ∈ D, if д1 ∈ γ (t1) and д2 ∈ γ (t2), then д‡

2 ◦ д1 ∈ γ (t2 ◦♯ t1).

• For all expressions E0, E1, E2 and for all variables x, the abstract elements skip♯, update(x, E0)♯,

sample(x, S, E1, E2)♯, and score(E0, E1, E2)♯ ∈ T ♯ such that

⟦skip⟧
⟦x := E0⟧

d ∈ γ (skip♯),
d ∈ γ (update(x, E0)♯),

⟦x := samplenorm(S, E1, E2)⟧
⟦scorenorm(E0, E1, E2)⟧

d ∈ γ (sample(x, S, E1, E2)♯),
d ∈ γ (score(E0, E1, E2)♯).

Given these data, we define the static analysis ⟦C⟧♯ ∈ T ♯ of a command C in Figure 8. Here the

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:23

⟦skip⟧♯ ≜ skip♯

⟦if E {C0} else {C1}⟧♯ ≜ cond(E)♯(⟦C0⟧♯, ⟦C1⟧♯)

⟦x := E⟧♯ ≜ update(x, E)♯
⟦C0; C1⟧♯ ≜ ⟦C1⟧♯ ◦♯ ⟦C0⟧♯

⟦x := samplenorm(S, E1, E2)⟧♯ ≜ sample(x, S, E1, E2)♯
⟦scorenorm(E0, E1, E2)⟧♯ ≜ score(E0, E1, E2)♯

⟦while E {C}⟧♯ ≜ (wfix T ) (where T (t ′) ≜ cond(E)♯(t ′ ◦♯ ⟦C⟧♯, skip♯))

Fig. 8. Abstract semantics ⟦C⟧♯ ∈ T ♯ of commands C

(wfix T ) is the usual widened fixed point tfix of T , which is defined as the first element tm with
tm = tm+1 in the widened sequence (tn)n ≥1 where t1 ≜ ⊥♯ and tn+1 ≜ widen(tn,T (tn)).

Theorem 7.1 (Soundness). For all commands C, we have ⟦C⟧

d ∈ γ (⟦C⟧♯).

In the rest of this section, we instantiate this framework into four static analysis instances. In
each case, we describe the abstract domain, the abstract bottom element, and the concretisation
function. Moreover, in the first two cases, we detail the transfer functions. In the following, for
a tuple (s ′, r ′, w ′, p ′) ∈ Store × RDB × [0, ∞) × [0, ∞), we use the subscripts −s , −r , −w , and −p to
denote its components. For instance, (s ′, r ′, w ′, p ′)s = s ′ and (s ′, r ′, w ′, p ′)r = r ′.

7.2 Analysis for the model-guide match
The first instance analysis finds information about the names of sampled random variables. Such
information can be used for discharging the requirement R1, the correspondence between the
support of a model and that of a guide. The analysis is based on the below abstraction:

T ♯ ≜ {⊥♯, ⊤♯ } ∪ P(Str),

⊥♯ ≜ ⊥♯,

γ (⊥♯) ≜ {λ(s, r ). ⊥},

γ (⊤♯) ≜ D,

γ (K) ≜ (cid:8)д ∈ D (cid:12)

(cid:12) ∀s, r . д(s, r ) (cid:44) ⊥ ∧ (д(s, r ))r = [] =⇒ dom(r ) = K (cid:9),

where [] denotes the empty random database. A typical abstract element in T ♯ is a set of names K,
which represents concrete commands sampling random variables in K. The domain T ♯ contains
⊥♯ and ⊤♯ to express two extreme cases, the set containing only one command that always returns
⊥, and the set of all commands.

Sound abstract operations can be derived from the density semantics and from the abstraction

following the abstract interpretation methodology [Cousot and Cousot 1977]:

widen(⊥♯, S) = widen(S, ⊥♯) = S;
widen(⊤♯, S) = widen(S, ⊤♯) = ⊤♯;
widen(S0, S1) = S0 if S0 = S1, ⊤♯ otherwise for S0, S1 ∈ P(Str);

cond(E)♯ = widen;
◦♯ = widen;

skip♯ = update(x, E0)♯ = ∅;

sample(x, S, E1, E2)♯ = {x };
score(E0, E1, E2)♯ = ∅.

We can use the resulting analysis to discharge the requirement R1. We just need to run it on both
C and Dθ , and check whether ⟦C⟧♯ = ⟦Dθ ⟧♯ = K for some K ∈ P(Str). The positive answer implies
the requirement R1, because all the random variables are drawn from the normal distribution. Our
extension of this analysis for Pyro (§8) does not rely on this exclusive use of the normal distribution,
and tracks information about the type of distribution of each random variable and state properties,
so as to prove the model-guide support match for realistic Pyro programs.

7.3 Analysis for the guide parameter differentiability
The second instance analysis aims at proving the differentiability of the density of a guide Dθ with
respect to its parameters θ . It infers the continuous partial differentiability of multiple functions

0:24

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

with respect to variables in the input state. The analysis is defined by the below abstraction:

T ♯ ≜ P(Var) × P(Var) × P(Var × Var),

⊥♯ ≜ (Var, Var, Var × Var),

γ (X , Y , R) ≜ (cid:8)д ∈ D (cid:12)
(cid:12)

(cid:0)∀x ∈ X . ∀s, r . д(s, r ) (cid:44) ⊥ =⇒ s(x) = (д(s, r ))s (x)(cid:1)
∧(cid:0)∀y ∈ Y . ∀s, r . д(s, r ) (cid:44) ⊥ =⇒ λv ∈ R. dens(д, s[y (cid:55)→ v])(r ) is C1(cid:1)
∧(cid:0)∀(z, u) ∈ R. ∀s, r . д(s, r ) (cid:44) ⊥ =⇒ λv ∈ R. (д(s[z (cid:55)→ v], r ))s (u) is R-valued and C1(cid:1)(cid:9).

By “C1”, we mean that the relevant function is continuously differentiable. Being a R-valued function
in the last part requires that д(s[z (cid:55)→ v], r ) be never ⊥. An (X , Y , R) in T ♯ expresses a property of
a transformer д ∈ D (which can be viewed as semantic command) that д does not change variables
in X , its density is C1 with respect to each variable in Y in the input state, and for each (z, u) ∈ R, it
assigns a real value to u in the output state in a C1 manner with respect to z in the input state.

We now define the abstract operations induced by this abstraction. Given an expression E, we let
V(E) denote the set of variables that occur in E, and we write C1(E) for the set of variables with
respect to which ⟦E⟧ is C1 (based on classical differentiability rules). The definitions below follow
from general principles such as the multivariate chain rule and account for discontinuities induced
by conditions which break differentiability.

widen((X0, Y0, R0), (X1, Y1, R1)) = (X0 ∩ X1, Y0 ∩ Y1, R0 ∩ R1)
cond(E)♯((X0, Y0, R0), (X1, Y1, R1)) = (X0 ∩ X1, (Y0 ∩ Y1) \ V(E),

{(z, u) ∈ R0 ∩ R1 | z (cid:60) V(E) ∨ u ∈ X0 ∩ X1})

◦♯((X0, Y0, R0), (X1, Y1, R1)) = (X0 ∩ X1, {x ∈ Y1 | ∀y ∈ Var. (x, y) ∈ R1 ∧ y ∈ Y0},

{(z, v) | ∀u ∈ Var. (z, u) ∈ R1 ∧ (u, v) ∈ R0})

skip♯ = (Var, Var, Var × Var)

update(x, E)♯ = (Var \ {x }, Var, Var × (Var \ {x }) ∪ {(y, x) | y ∈ C1(E)})

sample(x, S, E1, E2)♯ = (Var \ {x }, C1(E1) \ (V(S) ∪ V(E2)),

(Var \ (V(S) ∪ V(E2))) × Var)
score(E0, E1, E2)♯ = (Var, (C1(E0) ∩ C1(E1)) \ V(E2), (Var \ V(E2)) × Var)

To discharge the differentiability requirement R2, we need to run this analysis on a guide Dθ . If
the Y component of the analysis result contains all the parameters θ (i.e., there exists (X , Y , R) such
that ⟦Dθ ⟧♯ = (X , Y , R) and θ ⊆ Y ), then the requirement R2 is met.

7.4 Analysis for condition (10)
The third analysis extends the second by tracking and checking more properties. Its aim is to prove
the condition (10). Just like the second analysis, it infers information about the continuous partial
differentiability of multiple functions involving the output state and the density. Also, it checks
whether the density of a given command C0 has the form

dens(⟦C0⟧

d , s)(r ) = dens(д, s)(r ) =

M
(cid:213)

i=1

1[r ∈Ai ]

(cid:214)

α ∈Ki

N (cid:0)r (α); µ(i,α )(s), σ(i,α )(s)(cid:1)

(11)

for some finite M, and some Ai , Ki , µ(i,α ) and σ(i,α ), and if so, it tracks properties of the µ(i,α ) and
σ(i,α ). Here is the abstraction for the analysis:

T ♯ ≜ {⊤♯ } ∪ (cid:0)P(Var) × P(Var) × P(Var × Var)(cid:1),

⊥♯ ≜ (Var, Var, Var × Var),

γ (⊤♯) ≜ D,
γ (X , Y , R) ≜ (cid:8)д ∈ D (cid:12)

(cid:12) д has the form (11) ∧ (cid:0)∀x ∈ X . ∀s, r . д(s, r ) (cid:44) ⊥ =⇒ s(x) = (д(s, r ))s (x)(cid:1)

∧(cid:0)∀s, r . д(s, r ) (cid:44) ⊥ =⇒ λv ∈ R. µ(i,α )(s[θj (cid:55)→ v]) is C1 for all i, j, α (cid:1)

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:25

∧(cid:0)∀s, r . д(s, r ) (cid:44) ⊥ =⇒ λv ∈ R. σ(i,α )(s[θj (cid:55)→ v]) is C1 for all i, j, α (cid:1)
∧(cid:0)∀y ∈ Y . ∀s, r . д(s, r ) (cid:44) ⊥ =⇒ λv ∈ R. µ(i,α )(s[y (cid:55)→ v]) is C1 for all i, α (cid:1)
∧(cid:0)∀y ∈ Y . ∀s, r . д(s, r ) (cid:44) ⊥ =⇒ λv ∈ R. σ(i,α )(s[y (cid:55)→ v]) is C1 for all i, α (cid:1)
∧(cid:0)∀(z, u) ∈ R. ∀s, r . д(s, r ) (cid:44) ⊥ =⇒ λv ∈ R. (д(s[z (cid:55)→ v], r ))s (u) is R-valued and C1(cid:1) (cid:9).
The abstract operations are similar to those for the differentiability analysis. Thus, we omit their
definitions. We can use the analysis to prove the condition (10). We just need to run the analysis on
a guide Dθ and check whether ⟦Dθ ⟧♯ is not ⊤♯. If so, the condition holds.

7.5 Analysis for condition (9)
The last instance is a static analysis that aims at proving the condition (9). The analysis checks
whether a given command C0 has a density of the following form:

dens(C0, s)(r ) = dens(д, s)(r ) =
(cid:32)

M
(cid:213)

i=1

(cid:214)

1[r ∈Ai ]

N (cid:0)r (α); µ ′

(i,α )(s, r ), σ ′

(i,α )(s, r )(cid:1)

(cid:214)

N (cid:0)c(i, j); µ ′′

(i, j)(s, r ), σ ′′

α ∈Ki
for some finite M, and some Ai , Ki , Ni , µ ′
, and σ ′′
µ ′
(i,α )
the input variables. The abstraction for the analysis is as follows:

, µ ′′

j ∈[Ni ]

, σ ′

(i,α )

(i,α )

(i, j)

(i, j)

. If so, it tracks whether the
, and σ ′′
and some other functions can be bounded by affine exponentials on

, σ ′

(i,α )

(i, j)

(i, j)

(12)

(i, j)(s, r )(cid:1)(cid:170)
(cid:174)
(cid:172)

(cid:33)

(cid:169)
(cid:173)
(cid:171)
, µ ′′

T ♯ ≜ {⊤♯ } ∪ P(Var) × P(Var) × (Var ⇀ P(Var)),

⊥♯ ≜ (Var, Var, λx ∈Var. ∅),

(cid:12) д has the form (12) ∧ (cid:0)∀x ∈ X . ∀s, r . д(s, r ) (cid:44) ⊥ =⇒ s(x) = (д(s, r ))s (x)(cid:1)

γ (⊤♯) ≜ D,
γ (X , Y , R) ≜ (cid:8)д ∈ D (cid:12)
∧ (cid:0)∀i ∈ [M], α ∈ Ki . ∃ an affine function l from [Y ∪ Ki → R] to R such that for all s, r ,
(i,α )(s, r ), σ ′
∧ (cid:0)∀i ∈ [M], j ∈ [Ni ]. ∃ an affine function l from [Y ∪ Ki → R] to R such that for all s, r ,
(i, j)(s, r ), σ ′′

(i, j)(s, r )−1) ≤ exp(l({|s(x)|}x ∈Y , {|r (β)|}β ∈Ki ))(cid:1)
∧ (cid:0)∀y ∈ dom(R), i ∈ [M]. ∃ an affine function l from [R(y) ∪ Ki → R] to R such that for all s, r ,

(i,α )(s, r )−1) ≤ exp(l({|s(x)|}x ∈Y , {|r (β)|}β ∈Ki ))(cid:1)

д(s, r ) (cid:44) ⊥ =⇒ max(|µ ′′

д(s, r ) (cid:44) ⊥ =⇒ max(|µ ′

(i, j)(s, r )|, σ ′′

(i,α )(s, r )|, σ ′

д(s, r ) (cid:44) ⊥ =⇒ (д(s, r ))s (y) ≤ exp(l({|s(x)|}x ∈R(y), {|r (β)|}β ∈Ki ))(cid:1)(cid:9).

Here we use the notation {|s(x)|}x ∈Y to mean a partial map from variables x in Y to values |s(x)|. The
abstract operations that derive from this abstraction are quite similar to those of the differentiability
analysis, therefore we do not detail them. To verify the condition (9), we run the analysis on a
model C and check whether ⟦C⟧♯ (cid:44) ⊤♯. If the check succeeds, the condition holds.

8 A STATIC ANALYSIS FOR MODEL-GUIDE PAIRS IN PYRO AND ITS EVALUATION
We present a static analysis that can verify the support correspondence for Pyro model-guide pairs.
The analysis extends the first instance of the framework presented in §7. Our presentation focuses
on the most salient aspects of this analysis and experimental results.

8.1 Some features of Pyro programs
Pyro is a probabilistic programming framework based on Python and PyTorch. It supports a wide
spectrum of distributions and neural networks, and features commands for sampling and scoring.
It comes with multiple inference engines, including SVI. We chose Pyro over other probabilistic
programming languages (e.g., Anglican) because unlike most of other languages, in Pyro, SVI

0:26

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

algorithms are considered as main inference engines and neural networks can be used together
with probabilistic programming, which leads to more interesting examples.

In Pyro programs, random-variable names are often created at runtime, for instance by concate-

nating a fixed string with a sequence of dynamically-generated indices.

Example 8.1 (Use of indexed random-variable names). The code excerpt (of a model or guide
program in Pyro) below samples N × M instances of independent random variables, and names
them with “x_1_1”, . . . , “x_N _M”.

for i in range(1,N+1):

for j in range(1,M+1):

val = pyro.sample("x_{}_{}".format(i,j), Normal(m,d))

□

Since Pyro is based on PyTorch and is adapted to implement data-science applications, Pyro
programs heavily use multidimensional arrays, called tensors, and operations over them from
PyTorch, in particular, element-wise operations and broadcasting. More precisely, when a binary
operation (such as addition) is applied to two tensors of identical size, it outputs a new tensor of
the same size where each output element is computed separately from the corresponding input
elements. This principle often makes it possible to parallelise computations. Broadcasting occurs
when a binary operation is applied to two tensors of different dimensions that can somehow
be unified. Intuitively, it introduces and duplicates dimensions to produce tensors of identical
dimensions, so that binary operations can be performed element-wise.

Tensors are also heavily used for sampling, which has several consequences. First, it means
that an analysis targeted at Pyro programs should be able to track information about at least
the dimensions of sampled tensors. Second, the dimensions of sampled tensors are grouped such
that each of these groups has a different property with respect to probabilistic independence of
tensor components. Pyro inference engines exploit this property for optimisation, for instance, via
subsampling, but for this optimisation to be valid, the grouping of dimensions in a model should
match that of a guide. Our analysis tracks information about dimension grouping of sampled tensors
and the use of the Pyro construct called plate, which enables the optimisation just mentioned.

8.2 Abstract domain
We extend our analysis from §7 so that it tracks not just how each part of a given program transforms
states, but also which states can reach at each program point. We need the latter to get information
about random variables with dynamically generated names that is precise enough for our verification
task. To describe states, we rely on an abstract domain that consists of multiple subdomains
(combined by product). Among them, the key part is RDB♯ ≜ [Str ⇀fin {⊤} ∪ (Pfin(Zone♯) × Dist ♯)],
where ⇀fin denotes a finite partial map. Dist ♯ is an abstract domain whose element represents a set
of elementary probability distributions, such as the standard normal distribution. The other Zone♯
is our custom domain for zones, which express higher-dimensional rectangles in Nn.

An element r ♯ ∈ RDB♯ means a set of concrete random databases r for each concrete store s. The
domain of r consists of names that are obtained by concatenating baseline strings α in dom(r ♯)
with index sequences. If r ♯ maps a baseline string α to ⊤, it does not give any information about
index sequence and a probability distribution used for the random variable. Otherwise, the second
component of r ♯ specifies the information about the distribution, and the first component a region
of Nn that contains the index sequences used in the names. The region is described by a finite
subset {Z ♯
n } of Zone♯, which means the disjoint union of the rectangles represented by the
Z ♯
n for the subset. The following
i

. To emphasise this union interpretation, we write Z ♯

1 ∪ . . . ∪ Z ♯

1 , . . . , Z ♯

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:27

table summarises the definitions of our abstract domain, based on Zone♯:

RDB♯ ≜ [Str ⇀fin {⊤} ∪ (Pfin(Zone♯) × Dist ♯)];
m, product of intervals in N;
r ], closed interval specified by bounds;

Z ♯ ≜ I ♯
I ♯ ≜ [B♯
B♯ ≜ c | x + c | x + c = c ′, equality to constant, variable plus constant, or both.

1 × ... × I ♯
l , B♯

A higher-dimensional rectangular zone Z ♯ is described by a finite sequence of intervals I ♯, each
of which is made of two bounds. A bound B♯ may be defined as one or two constraints which
express that this bound is equal to a constant, or to a variable plus a constant, or both. This intuitive
denotation defines a concretisation function γr : RDB♯ → P(State).

Example 8.2. Consider the code of Example 8.1. After i − 1 iterations in the main loop and j
iterations in the last execution of the inner loop, we expect the analysis to come up with the
invariant, [“x” (cid:55)→ ([1, i−1] × [1, M] ∪ [i, i] × [1, j], normal(m, d))]. In turn, at the exit of the main
loop, we expect the analysis to infer the invariant, [“x” (cid:55)→ ([1, i=N ] × [1, j=M], normal(m, d))]. □

In addition to these constraints over random databases, our analyser also uses an abstraction that
maintains typing information and numerical constraints over variables. We do not fully formalise
these constraints as the overall structure of the domain relies on a classical reduced product.

Finally, we describe the combination of the above state abstraction with the abstraction of §7.2.
More precisely, we start with the abstract domain exposed in §7.2 (which we denote by T ♯) and
build a novel abstract domain T ♯
that also satisfies the requirements of §7.1. We let the set of
s
abstract elements be T ♯
s ≜ [RDB♯ → T ♯ × RDB♯]. Intuitively, such an element maps an input
abstract random database into a set of functions together with an over-approximation of their
output, when applied to this abstract input. The concretisation below formalises this: for all ts ∈ T ♯
s ,
γs (ts ) ≜ (cid:110)

д ∈ D

o ) =⇒

i ) = (t, r ♯

(cid:12)
(cid:12)
(cid:12)

∀r ♯

i ∈ RDB♯. ts (r ♯
∃д′ ∈ γ (t). ∀(s, r ) ∈ γr (r ♯

i ). д(s, r ) = д′(s, r ) ∧ (cid:0)д(s, r ) = ⊥ ∨ (д(s, r )s , д(s, r )r ) ∈ γr (r ♯

o )(cid:1)(cid:111)

.

8.3 Computation of loop invariants
Although our static analysis for Pyro requires a state abstraction, its principles and structure
are similar to those of the general analysis shown in §7. In the following, we first describe the
integration of the state abstraction in the analysis of §7.2.

The abstract operations in T ♯
this for the abstract composition ◦♯

s can all be derived by lifting those in T ♯ into functions. We illustrate
s ∈ T ♯
s ,

s . Recall the operator ◦♯ for T ♯ in §7.2. Given ts , t ′

s for T ♯

ts ◦♯

s t ′
s

≜ λr ♯

0 . (t ◦♯ t ′, r ♯

2 ) where (t ′, r ♯

1 ) = t ′

s (r ♯

0 ) and (t, r ♯

2 ) = ts (r ♯
1 )

The other abstract operators over T ♯

s are defined in a similar manner.

As in most static analysis problems, the computation of precise loop invariants requires a carefully
designed widening operator. In the case of zones, the analysis needs to generalise information
about the bounds. We assume r ♯
1 ∈ RDB♯ are abstract random databases, and present the main
steps in the computation of the widening widen(r ♯

0 , r ♯

0 , r ♯
1 ).

(i) For each r ♯
i

1 are the same
except for one component and they represent adjacent high-dimensional rectangles. The

into a single zone when Z ♯

, we fuse zones Z ♯

0 and Z ♯

1 in r ♯
i

0 , Z ♯

0:28

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

following rewriting illustrates this step.

(cid:0)“x” (cid:55)→ (cid:0)[1, i−1] × [1, j=M] ∪ [i, i] × [1, j=M], normal(m, d)(cid:1)(cid:1)

(cid:123) (cid:0)“x” (cid:55)→ (cid:0)[1, i] × [1, j=M], normal(m, d)(cid:1)(cid:1)

(ii) We generalise the intervals of corresponding zones in r ♯

1 using a weak version of
unification on their bounds. The bounds of corresponding intervals in two such zones
survive this step in a weakened form if they share at least one syntactically equal expression.
Otherwise, the bounds are dropped, which causes the introduction of ⊤ into abstract random
databases. The following rewriting instances illustrate this bound generalisation.

0 and r ♯

widen(cid:0)(cid:0)“x” (cid:55)→ (cid:0)[1, i] × [1, j−1=M], normal(m, d)(cid:1)(cid:1), (cid:0)“x” (cid:55)→ (cid:0)[1, i] × [1, j=M], normal(m, d)(cid:1)(cid:1)(cid:1)

= (cid:0)“x” (cid:55)→ (cid:0)[1, i] × [1, M], normal(m, d)(cid:1)(cid:1)

widen(cid:0)(cid:0)“x” (cid:55)→ (cid:0)[1, i] × [1, j−1], normal(m, d)(cid:1)(cid:1), (cid:0)“x” (cid:55)→ (cid:0)[1, i] × [1, j=M], normal(m, d)(cid:1)(cid:1)(cid:1)

= (cid:0)“x” (cid:55)→ ⊤(cid:1)

The analysis also applies standard widening techniques to typing information and numerical
constraints mentioned in §8.2. Finally, a model-guide pair can be verified if and only if their
analyses return equivalent abstract random databases, without any name mapped into ⊤.

8.4 Experimental evaluation
We have implemented a prototype analyser and carried out experiments so as to assess the effec-
tiveness of our analysis to verify the support correspondence for Pyro model-guide pairs.13 More
precisely, we evaluated the following three research questions:

(i) Can our analysis discover incorrect model-guide pairs in realistic probabilistic programs?
(ii) Can the analysis verify correct model-guide pairs despite the complexity of the definition?
(iii) Is the analysis efficient enough so that it can cope with realistic probabilistic programs?

Benchmark programs. We took example programs from the Pyro webpage that can be handled by
standard SVI engines or can be naturally rewritten to be so. Those engines do not use Pyro’s recent
vectorised enumeration-based optimisation (enabled by the option TraceEnum_ELBO), and are run
with the option Trace_ELBO. We made this choice because the optimisation is newly introduced
and whether it is used or not changes the set of random variables used in a Pyro program.

We have applied our analysis to two groups of Pyro programs. The first is the Pyro regression test
suite [Uber AI Labs 2019b], which comprises 66 examples exercising the basic programming patterns
expected in Pyro programs. While each of these is small, they cover many standard patterns of
both correct and incorrect model-guide pairs. Among these, 33 test cases use only TraceEnum_ELBO
and fall outside the scope of our analysis, and 6 of the remaining 33 test cases come with two
subsampling options. Hence, we can consider 39 experiments based on this regression suite.

The second is a collection of examples from the Pyro webpage [Uber AI Labs 2019a]. The webpage
features 18 Pyro examples, among which 9 involve model-guide pairs (other examples use automatic
guide generation, or do not perform SVI at all). Out of these 9 examples, 5 use Trace_ELBO, and
three can be converted naturally into Trace_ELBO versions although they do not use Trace_ELBO.
Thus, 8 Pyro examples fall within the scope of our analysis. These examples correspond to advanced

13Code is available at https://github.com/wonyeol/static-analysis-for-support-match.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:29

Total #

Total dimension

Name Corresponding probabilistic model LoC for plate sample score sample score
170
2

br

θ

csis

lda

Bayesian regression
Inference compilation
Amortised latent Dirichlet allocation
Variational autoencoder (VAE)

27
31
76
91
94
246
349
410

0
0
0
0
0
3
0
2

1
0
5
2
8
2
2
2

10
2
8
2
12
2
4
6

9
10
1
480
2
2
21008
64000 121400
1
1
25600 200704 353600
1 231280 1310720 231280
1 640000 281600 594000
24000 156800 844000
1
20736 160000 6040859
1

vae
sgdef Deep exponential family
Deep Markov model
dmm
ssvae Semi-supervised VAE
air

Attend-infer-repeat

Table 1. Key features of the model-guide pairs from Pyro examples. LoC denotes the lines of code of model
and guide. The columns “Total #” show the number of objects/commands of each type used in model and
guide, and the columns “Total dimension” show the total dimension of tensors in model and guide, either
sampled from sample or used inside score, as well as the dimension of θ in guide.

probabilistic models14 from the machine-learning literature, most of which use sophisticated neural
networks and probabilistic modelling. Table 1 describes the structure of these 8 examples in detail.

Prototype analyser and results. Our analyser is implemented in OCaml, and supports the main
data-structures and operations defined by Python, PyTorch, and Pyro. In particular, it precisely
abstracts the shape of PyTorch tensor objects, the shape transformation information of PyTorch
neural-network-related objects, the automatic broadcasting information of Pyro plate objects, and
the shape of allocated indices for sample names, using the zone abstraction described above. It also
supports common Pyro probability distributions, and can precisely cope with standard Pyro and
PyTorch operations manipulating the Pyro distribution objects and PyTorch tensor objects. While
our prototype supports a wide range of Python, PyTorch, and Pyro features, we point out that we
did not implement a static analysis for the full Python (plus PyTorch and Pyro) language (e.g., no
support for classes, dictionaries, named tuples, and user-defined functions).

The analysis results are summarised in Table 2 and are discussed in detail in the following.

Run-times were measured on an Intel Core i7-7700 machine running Linux Ubuntu 16.04.

Discovery of invalid model-guide pairs. The analysis rejected two Pyro examples, br and lda, as
incorrect due to an invalid model-guide pair. br is the Bayesian regression example discussed in §2.
For br, the analysis discovers that a random variable sigma is sampled from Uniform(0.,10.) in
the model C, but from Normal(..) in the guide Dθ (Figure 2(a)). Since the support of sigma in Dθ
is not a subset of that in C (i.e., R ⊈ [0, 10]), the requirement R1 is violated. Thus, the SVI objective,
KL(Dθ ∥C), is undefined, and br has an invalid model-guide pair.

For lda, the analysis discovers that a random variable doc_topics is sampled from Dirichlet(..)
in the model C, but from Delta(..) in the guide Dθ . Since the reference measures of doc_topics
in C and Dθ are different (the Lebesgue measure vs. the counting measure), KL(Dθ ∥C) cannot be
computed by (4). For this reason, lda has an invalid model-guide pair. Our analyser tracks the
reference measure implicitly by regarding the support of any distribution with Lebesgue mea-
sure, as disjoint from that of any distribution with counting measure (which is sound due to the
aforementioned reason), and this allowed us to discover the issue of lda.

14The models include variational autoencoder (VAE) [Kingma and Welling 2014], semi-supervised VAE [Kingma et al. 2014],
deep exponential family [Ranganath et al. 2015], attend-infer-repeat [Eslami et al. 2016], deep Markov model [Krishnan
et al. 2017], inference compilation [Le et al. 2017], and amortised latent Dirichlet allocation [Srivastava and Sutton 2017].

0:30

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

Category

No plates
Single for-plate
Nested for-plates
Single with-plate
Nested with-plates
Non-nested with-plates
Nested for-plate & with-plate
Total

#Same #Diff #Crash Time
0.001
0.004
0.026
0.001
0.002
0.002
N/A
0.003

9
4
2
5
7
2
0
29

0
0
0
0
2
0
0
2

0
3
2
0
0
0
3
8

br

lda

csis

Name Valid? Time
0.006
0.007
0.014
0.005
0.070
0.536
0.013
4.093

x
o
x
o
o
o
o
o

ssvae

sgdef

vae

dmm

air

(a) Results for Pyro test suite. 39 model-guide pairs are grouped
into 7 categories, based on which type of plate objects are used.
#Same (or #Diff) denotes the number of model-guide pairs for
which the output of our analyser, valid or invalid, is the same as
(or different from) the documented output. #Crash denotes the
number of pairs for which our analyser crashes.

(b) Results for Pyro examples. The col-
umn “Valid?” shows the output of our
analysis, valid or invalid.

Table 2. Analysis results on two benchmark sets. The column “Time” shows the analysis time in seconds;
in (a), it is averaged over those model-guide pairs (in each category) for which our analyser does not crash.

In both cases, the found correctness issues are unknown before and subtle. In particular, it turned
out that lda, though incorrect when viewed as an example of SVI, is a valid implementation, because
it performs not SVI but variational expectation-maximisation (EM) [Neal and Hinton 1998].15 The
lda uses an SVI engine just to solve an optimisation problem in variational EM (not to do SVI), and
uses the Delta distribution to perform a particular realisation of the M-step in variational EM.

Verification of probabilistic programs relying on model-guide pairs. Among the Pyro test suite,
the analysis successfully verifies 31 examples among 39. Interestingly, two of these 31 successful
validations, highlighted in Table 2(a), correspond to cases that were flagged as “invalid model-guide
pairs” in the Pyro git repository. Upon inspection, these two examples turn out to be correct.

On the other hand, 8 examples from the Pyro test suite could not be verified due to the crashes
of the analyser. One of these failures is due to the need to reason more precisely about the content
of a for loop (e.g., using some partitioning techniques), and seven are due to the use of plates with
subsampling, as ranges for for loops. Therefore, these failures could be resolved using existing
static analysis techniques and a more precise handling of the semantics of Python constructions.
Moreover, 6 Pyro examples (among the 8 that we considered) were verified successfully, which
means all correct Pyro examples were verified. Finally, we corrected the two examples that were
rejected due to invalid model-guide pairs, and these two examples were also successfully verified.

Analysis efficiency. The analysis returned within a second on each program in the Pyro test suite,
and on most of the Pyro examples. The slowest analysis was observed on air, which was analysed
within 5 seconds. Most of the Pyro examples sample from and score with distributions of very high
dimension arranged in complex tensors, using nested for and plate’s. While they are not large,
they present a high degree of logical complexity, that is representative of realistic probabilistic
programs. The fact that such programs get analysed within seconds shows that the analysis and the
underlying abstract domain to describe zones, sampled dimensions, and distributions can generalise
predicates quickly so that precise loop invariants can be computed.

15We thank an anonymous reviewer and Eli Bingham for pointing this out and explaining it in detail.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:31

9 RELATED WORK, CONCLUSION AND LIMITATION

Related work. As far as we know, the idea of using SVI for probabilistic programs first appeared
in [Wingate and Weber 2013]. When further insights into how to create generic (sometimes also
called black-box) SVI engines were found [Kucukelbir et al. 2015, 2017; Ranganath et al. 2014], the
idea was tried for realistic probabilistic programming languages, such as Stan [Kucukelbir et al.
2015] and Anglican [van de Meent et al. 2016], resulting in impressive case studies [Kucukelbir
et al. 2015]. The major inference engines for deep probabilistic programming languages [Bingham
et al. 2019; Siddharth et al. 2017; Tran et al. 2018, 2016] are all based on SVI nowadays. However,
we do not know of any prior work that attempts to reveal implicit assumptions made by these SVI
engines and to discharge these assumptions manually or automatically, as we did in this paper.

The correctness of a different type of inference engines based on Monte-Carlo methods has
been the subject of study in the PL community. Such engines have clearly formulated correctness
conditions from Markov chain theory [Geyer 2011; Green 1995; Hastings 1970; Metropolis et al.
1953], such as ergodicity and correct stationarity. Tools from formal semantics have been employed
to show that the inference engines satisfy these conditions [Borgström et al. 2016; Hur et al. 2015;
Kiselyov 2016; Scibior et al. 2018]. While looking at different algorithms, some of these work consider
more expressive languages than what we used in the paper, in particular, those supporting higher-
order functions. One interesting direction is to extend our results to such expressive languages
using the ideas from these works, especially the operational technique in [Borgström et al. 2016]
and the denotational monad-based technique in [Scibior et al. 2018].

The consequence of having random choice in a programming language has been actively investi-
gated by the semantics researchers from the early days [Borgström et al. 2016; Ehrhard et al. 2014;
Heunen et al. 2017; Jones and Plotkin 1989; Kozen 1981; Smolka et al. 2017; Staton 2017; Staton
et al. 2016; Toronto et al. 2015; Vákár et al. 2019]. Our work uses the technique developed in this
endeavour, such as Giry monad and denotational formulation of idealised importance sampling [Sta-
ton et al. 2016]. Also, just as we connected the measure semantics with the density semantics,
[Kozen 1981] and [Borgström et al. 2016] related two semantics with similar flavours, although the
considered languages (with or without continuous distribution and score statements) and the style
of semantics (operational vs denotational) are different. Our density semantics uses a reference
measure built out of Lebesgue measure as in [Bhat et al. 2012, 2013; Hur et al. 2015]. This choice
is found to cause an issue when the score statement is treated not as a scoring mechanism but in
terms of conditional expectation [Wu et al. 2018]. How to resolve this matter is still open.

Static analyses for probabilistic programming languages or languages with probabilistic choice
typically attempt to check probabilistic properties [Chakarov and Sankaranarayanan 2013; Cousot
and Monerau 2012; Monniaux 2000; Wang et al. 2018], or perform posterior inference [Chaganty
et al. 2013; Wang et al. 2018], or find information useful for posterior inference [Nori et al. 2014].
For instance, [Monniaux 2000] defines a probabilistic abstract interpretation framework, which is
applied to estimate the failure probability [Monniaux 2001]. More recently, [Cousot and Monerau
2012] sets up a general framework to design probabilistic abstract interpretations, which lift
conventional static analysis tools to a probabilistic setup, and [Wang et al. 2018] proposes a
framework for analysing probabilistic programs based on hyper-graphs with probabilistic actions
on edges. Our program analyses aim at a different type of verification tasks, namely, proving
the safety requirements imposed by the SVI engines. Static analyses for checking the continuity
properties of programs are proposed in [Chaudhuri et al. 2010]. Some techniques used in those
analyses may help track the kind of smoothness properties considered in this paper precisely.

Conclusion. In this paper, we have set up a semantic model of probabilistic programming lan-
guages that allows to reason about the correctness of subtle optimisation algorithms such as SVI. In

0:32

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

particular, we have identified a set of conditions that guarantee that these algorithms will produce
meaningful results. These conditions simplify the verification of correctness, and open the way
towards the automation of this verification. To evaluate the effectiveness of our framework, we
have completed the design of a static analysis to validate the correspondence assumptions for
the model-guide pairs. Our analysis could verify nontrivial implementations as well as uncover
nontrivial bugs. Such bugs would lead to incorrect results, which would be very difficult to diagnose.

Limitation. We described four static analyses (§7.2-§7.5) for discharging the requirements R1-R6,
and developed one of the four analyses further (§8.2-§8.4) to build a prototype analyser for actual
Pyro programs. Here we clarify the underlying assumptions and limitations of these analyses.

The static analysis for model-guide support match (§7.2) was implemented into our static analyser
for Pyro (§8.4) but with additional extensions (§8.2-§8.3), so that it does not make the assumption
in §6.1; the assumption was introduced mainly to develop analyses for the requirements R3-R6.
Hence, our static analyser handles both continuous and discrete random variables.

On the other hand, other analyses (§7.3-§7.5) are unimplemented and make the assumption in
§6.1. We expect that the assumption can be relaxed, without much difficulty, to permit continuous
or discrete distributions having finite entropy and moments of all degrees, because our proofs of
theorems and lemmas bound various expectations mostly by entropies and moments. It would be
more challenging, however, to relax the assumption to allow distributions not having finite entropy
and moments of all degrees, or models having unboundedly many random variables (of any kind).
In particular, addressing the later limitation might require techniques developed for proving that
probabilistic systems has finite expected execution time.

This paper focuses on a particular optimisation objective (5) for SVI, but we point out that several
other optimisation objectives have been proposed for different inference or learning algorithms,
such as variational EM (e.g., lda in §8.4) and importance weighted autoencoder (IWAE) [Burda et al.
2016]. One interesting research direction is to develop techniques for verifying the well-definedness
of these optimisation objectives.

ACKNOWLEDGMENTS
We thank Fritz Obermeyer and Eli Bingham for explaining the subtleties of Pyro and suggesting us
to try the Pyro regression test suite. Sam Staton, Ohad Kammar and Matthijs Vákár helped us to
understand the semantics of recursion in the probabilistic programming languages better. Lee, Yang
and Yu were supported by the Engineering Research Center Program through the National Research
Foundation of Korea (NRF) funded by the Korean Government MSIT (NRF-2018R1A5A1059921),
and also by Next-Generation Information Computing Development Program through the National
Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT (2017M3C4A7068177).

REFERENCES
Sooraj Bhat, Ashish Agarwal, Richard W. Vuduc, and Alexander G. Gray. 2012. A type theory for probability density

functions. In Principles of Programming Languages (POPL). 545–556.

Sooraj Bhat, Johannes Borgström, Andrew D. Gordon, and Claudio V. Russo. 2013. Deriving Probability Density Functions
from Probabilistic Functional Programs. In Tools and Algorithms for the Construction and Analysis of Systems (TACAS).
508–522.

Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh,
Paul A. Szerlip, Paul Horsfall, and Noah D. Goodman. 2019. Pyro: Deep Universal Probabilistic Programming. Journal of
Machine Learning Research 20, 28 (2019), 1–6.

Johannes Borgström, Ugo Dal Lago, Andrew D. Gordon, and Marcin Szymczak. 2016. A lambda-calculus foundation for

universal probabilistic programming. In International Conference on Functional Programming (ICFP). 33–46.

Yuri Burda, Roger B. Grosse, and Ruslan Salakhutdinov. 2016. Importance Weighted Autoencoders. In International Conference

on Learning Representations (ICLR).

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:33

Bob Carpenter, Andrew Gelman, Matthew Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker,
Jiqiang Guo, Peter Li, and Allen Riddell. 2017. Stan: A Probabilistic Programming Language. Journal of Statistical Software,
Articles 76, 1 (2017), 1–32.

Arun Tejasvi Chaganty, Aditya V. Nori, and Sriram K. Rajamani. 2013. Efficiently Sampling Probabilistic Programs via

Program Analysis. In Artificial Intelligence and Statistics (AISTATS). 153–160.

Aleksandar Chakarov and Sriram Sankaranarayanan. 2013. Probabilistic Program Analysis with Martingales. In Computer

Aided Verification (CAV). 511–526.

Swarat Chaudhuri, Sumit Gulwani, and Roberto Lublinerman. 2010. Continuity analysis of programs. In Principles of

Programming Languages (POPL). 57–70.

Patrick Cousot and Radhia Cousot. 1977. Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs

by Construction or Approximation of Fixpoints. In Principles of Programming Languages (POPL). 238–252.

Patrick Cousot and Radhia Cousot. 1979. Systematic design of program analysis frameworks. In Principles of Programming

Languages (POPL). 269–282.

Patrick Cousot and Radhia Cousot. 1992. Abstract Interpretation Frameworks. Journal of Logic and Computation 2, 4 (1992),

511–547.

Patrick Cousot and Michael Monerau. 2012. Probabilistic Abstract Interpretation. In European Symposium on Programming

(ESOP). 169–193.

Thomas Ehrhard, Christine Tasson, and Michele Pagani. 2014. Probabilistic coherence spaces are fully abstract for proba-

bilistic PCF. In Principles of Programming Languages (POPL). 309–320.

S. M. Ali Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, David Szepesvari, Koray Kavukcuoglu, and Geoffrey E.
Hinton. 2016. Attend, Infer, Repeat: Fast Scene Understanding with Generative Models. In Neural Information Processing
Systems (NIPS). 3233–3241.

Timon Gehr, Sasa Misailovic, and Martin T. Vechev. 2016. PSI: Exact Symbolic Inference for Probabilistic Programs. In

Computer Aided Verification (CAV). 62–83.

Charles J. Geyer. 2011. Introduction to Markov Chain Monte Carlo. In Handbook of Markov Chain Monte Carlo, Steve Brooks,

Andrew Gelman, Galin L. Jones, and Xiao-Li Meng (Eds.). Chapman and Hall/CRC, Chapter 1, 3–48.

Hamid Ghourchian, Amin Gohari, and Arash Amini. 2017. Existence and Continuity of Differential Entropy for a Class of

Distributions. IEEE Communications Letters 21, 7 (2017), 1469–1472.

Noah Goodman, Vikash Mansinghka, Daniel M Roy, Keith Bonawitz, and Joshua B Tenenbaum. 2008. Church: a language

for generative models. In Uncertainty in Artificial Intelligence (UAI). 220–229.

Andrew D. Gordon, Thore Graepel, Nicolas Rolland, Claudio Russo, Johannes Borgstrom, and John Guiver. 2014. Tabular: A

Schema-driven Probabilistic Programming Language. In Principles of Programming Languages (POPL). 321–334.

Peter J. Green. 1995. Reversible jump Markov chain Monte Carlo computation and Bayesian model determination. Biometrika

82, 4 (1995), 711–732.

Wilfred Keith Hastings. 1970. Monte Carlo Sampling Methods Using Markov Chains and Their Applications. Biometrika 57,

1 (1970), 97–109.

Chris Heunen, Ohad Kammar, Sam Staton, and Hongseok Yang. 2017. A convenient category for higher-order probability

theory. In Logic in Computer Science (LICS). 1–12.

Matthew D. Hoffman, David M. Blei, Chong Wang, and John Paisley. 2013. Stochastic Variational Inference. Journal of

Machine Learning Research 14 (2013), 1303–1347.

Chung-Kil Hur, Aditya V. Nori, Sriram K. Rajamani, and Selva Samuel. 2015. A Provably Correct Sampler for Probabilistic

Programs. In Foundation of Software Technology and Theoretical Computer Science (FSTTCS). 475–488.

C. Jones and Gordon D. Plotkin. 1989. A Probabilistic Powerdomain of Evaluations. In Logic in Computer Science (LICS).

186–195.

Diederik P. Kingma, Danilo J. Rezende, Shakir Mohamed, and Max Welling. 2014. Semi-supervised Learning with Deep

Generative Models. In Neural Information Processing Systems (NIPS). 3581–3589.

Diederik P. Kingma and Max Welling. 2014. Auto-Encoding Variational Bayes. In International Conference on Learning

Representations (ICLR).

Oleg Kiselyov. 2016. Probabilistic Programming Language and its Incremental Evaluation. In Asian Symposium on Program-

ming Languages and Systems (APLAS). 357–376.

Achim Klenke. 2014. Probability Theory: A Comprehensive Course (second ed.). Springer-Verlag London.
Dexter Kozen. 1981. Semantics of Probabilistic Programs. J. Comput. System Sci. 22, 3 (1981), 328–350.
Rahul G. Krishnan, Uri Shalit, and David Sontag. 2017. Structured Inference Networks for Nonlinear State Space Models. In

AAAI Conference on Artificial Intelligence (AAAI). 2101–2109.

Alp Kucukelbir, Rajesh Ranganath, Andrew Gelman, and David M. Blei. 2015. Automatic Variational Inference in Stan. In

Neural Information Processing Systems (NIPS). 568–576.

0:34

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

Alp Kucukelbir, Dustin Tran, Rajesh Ranganath, Andrew Gelman, and David M. Blei. 2017. Automatic Differentiation

Variational Inference. Journal of Machine Learning Research 18 (2017), 14:1–14:45.

Tuan Anh Le, Atilim Gunes Baydin, and Frank Wood. 2017. Inference Compilation and Universal Probabilistic Programming.

In Artificial Intelligence and Statistics (AISTATS). 1338–1348.

Vikash K. Mansinghka, Daniel Selsam, and Yura N. Perov. 2014. Venture: a higher-order probabilistic programming platform

with programmable inference. arXiv:1404.0099 (2014).

Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Edward Teller. 1953. Equation

of State Calculations by Fast Computing Machines. The Journal of Chemical Physics 21, 6 (1953), 1087–1092.

T. Minka, J.M. Winn, J.P. Guiver, S. Webster, Y. Zaykov, B. Yangel, A. Spengler, and J. Bronskill. 2014. Infer.NET 2.6. Microsoft

Research Cambridge. http://research.microsoft.com/infernet.

Matthew Mirman, Timon Gehr, and Martin T. Vechev. 2018. Differentiable Abstract Interpretation for Provably Robust

Neural Networks. In International Conference on Machine Learning (ICML). 3575–3583.

David Monniaux. 2000. Abstract Interpretation of Probabilistic Semantics. In Static Analysis Symposium (SAS). 322–339.
David Monniaux. 2001. Backwards Abstract Interpretation of Probabilistic Programs. In European Symposium on Programming

(ESOP). 367–382.

Chandra Nair, Balaji Prabhakar, and Devavrat Shah. 2006. On Entropy for Mixtures of Discrete and Continuous Variables.

arXiv:cs/0607075 (2006).

Praveen Narayanan, Jacques Carette, Wren Romano, Chung-chieh Shan, and Robert Zinkov. 2016. Probabilistic inference by

program transformation in Hakaru (system description). In Functional and Logic Programming (FLOPS). 62–79.

Radford M. Neal and Geoffrey E. Hinton. 1998. A View of the Em Algorithm that Justifies Incremental, Sparse, and other

Variants. In Learning in Graphical Models. 355–368.

Aditya V. Nori, Chung-Kil Hur, Sriram K. Rajamani, and Selva Samuel. 2014. R2: An Efficient MCMC Sampler for Probabilistic

Programs. In AAAI Conference on Artificial Intelligence (AAAI). 2476–2482.

John William Paisley, David M. Blei, and Michael I. Jordan. 2012. Variational Bayesian Inference with Stochastic Search. In

International Conference on Machine Learning (ICML). 1363–1370.

Rajesh Ranganath, Sean Gerrish, and David M. Blei. 2014. Black Box Variational Inference. In Artificial Intelligence and

Statistics (AISTATS). 814–822.

Rajesh Ranganath, Linpeng Tang, Laurent Charlin, and David Blei. 2015. Deep Exponential Families. In Artificial Intelligence

and Statistics (AISTATS). 762–771.

Adam Scibior, Ohad Kammar, Matthijs Vákár, Sam Staton, Hongseok Yang, Yufei Cai, Klaus Ostermann, Sean K. Moss, Chris
Heunen, and Zoubin Ghahramani. 2018. Denotational validation of higher-order Bayesian inference. PACMPL 2, POPL
(2018), 60:1–60:29.

N. Siddharth, Brooks Paige, Jan-Willem van de Meent, Alban Desmaison, Noah D. Goodman, Pushmeet Kohli, Frank Wood,
and Philip Torr. 2017. Learning Disentangled Representations with Semi-Supervised Deep Generative Models. In Neural
Information Processing Systems (NIPS). 5927–5937.

Steffen Smolka, Praveen Kumar, Nate Foster, Dexter Kozen, and Alexandra Silva. 2017. Cantor meets scott: semantic

foundations for probabilistic networks. In Principles of Programming Languages (POPL). 557–571.

Akash Srivastava and Charles A. Sutton. 2017. Autoencoding Variational Inference For Topic Models. In International

Conference on Learning Representations (ICLR).

Sam Staton. 2017. Commutative Semantics for Probabilistic Programming. In European Symposium on Programming (ESOP).

855–879.

Sam Staton, Hongseok Yang, Frank D. Wood, Chris Heunen, and Ohad Kammar. 2016. Semantics for probabilistic pro-
gramming: higher-order functions, continuous distributions, and soft constraints. In Logic in Computer Science (LICS).
525–534.

David Tolpin, Jan-Willem van de Meent, Hongseok Yang, and Frank D. Wood. 2016. Design and Implementation of
Probabilistic Programming Language Anglican. In Implementation and Application of Functional Programming Languages
(IFL). 6:1–6:12.

Neil Toronto, Jay McCarthy, and David Van Horn. 2015. Running Probabilistic Programs Backwards. In European Symposium

on Programming (ESOP). 53–79.

Dustin Tran, Matthew D. Hoffman, Dave Moore, Christopher Suter, Srinivas Vasudevan, and Alexey Radul. 2018. Simple,
Distributed, and Accelerated Probabilistic Programming. In Neural Information Processing Systems (NeurIPS). 7609–7620.
Dustin Tran, Alp Kucukelbir, Adji B. Dieng, Maja R. Rudolph, Dawen Liang, and David M. Blei. 2016. Edward: A library for

probabilistic modeling, inference, and criticism. arXiv:1610.09787 (2016).

Uber AI Labs. 2019a. Pyro examples. http://pyro.ai/examples/. Version used: April 1, 2019.
Uber AI Labs. 2019b. Pyro regression test suite. https://github.com/pyro-ppl/pyro/blob/dev/tests/infer/test_valid_models.py.

Version used: March 1, 2019.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:35

Matthijs Vákár, Ohad Kammar, and Sam Staton. 2019. A domain theory for statistical probabilistic programming. PACMPL

3, POPL (2019), 36:1–36:29.

Jan-Willem van de Meent, Brooks Paige, David Tolpin, and Frank D. Wood. 2016. Black-Box Policy Search with Probabilistic

Programs. In Artificial Intelligence and Statistics (AISTATS). 1195–1204.

Di Wang, Jan Hoffmann, and Thomas W. Reps. 2018. PMAF: an algebraic framework for static analysis of probabilistic

programs. In Programming Language Design and Implementation (PLDI). 513–528.

Ronald J. Williams. 1992. Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning.

Mach. Learn. 8, 3-4 (1992), 229–256.

David Wingate and Theophane Weber. 2013. Automated Variational Inference in Probabilistic Programming. arXiv:1301.1299

(2013).

Frank Wood, Jan Willem van de Meent, and Vikash Mansinghka. 2014. A New Approach to Probabilistic Programming

Inference. In Artificial Intelligence and Statistics (AISTATS). 1024–1032.

Yi Wu, Siddharth Srivastava, Nicholas Hay, Simon Du, and Stuart J. Russell. 2018. Discrete-Continuous Mixtures in
Probabilistic Programming: Generalized Semantics and Inference Algorithms. In International Conference on Machine
Learning (ICML). 5339–5348.

Hongseok Yang. 2019. Implementing Inference Algorithms for Probabilistic Programs. https://github.com/hongseok-yang/
probprog19/blob/master/Lectures/Lecture6/Note6.pdf. Lecture Note of the 2019 Course on Probabilistic Programming at
KAIST.

0:36

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

A PROOFS OF LEMMAS AND THEOREMS IN §4

Lemma 4.1. For all expressions E, B, and S, their semantics ⟦E⟧, ⟦B⟧ and ⟦S⟧ are measurable

functions from Store to R, B and Str, respectively.

Proof. We prove the lemma by structural induction. We present the proof for E only, because
those for B and S are similar. When E is a constant, ⟦E⟧ is a constant function and so it is measurable.
When E is a variable, ⟦x⟧ is a projection of the x component of the given store s. Since Store is given
the product σ -algebra, the projection ⟦x⟧ is measurable. Finally, assume that E is f (E0, . . . , En−1).
Then, by induction hypothesis, the ⟦Ei ⟧ are measurable functions from Store to R. Thus,

λs. (⟦E0⟧s, . . . , ⟦En−1⟧s) : Store → Rn
is measurable. Furthermore, ⟦f ⟧ : Rn → R is measurable. Thus, their composition is measurable as
well. This implies the measurability of ⟦E⟧ because

⟦E⟧ = ⟦f ⟧ ◦ (λs. (⟦E0⟧s, . . . , ⟦En−1⟧s)).

□

Lemma 4.2. (K, ⊑) is an ω-complete partial order with the least element ⊥.

Proof. The fact that ⊑ is a partial order immediately follows from its definition. The least
element is the function λσ . λA. 0. It remains to show the ω-completeness property. Consider an
ω-chain

κ0 ⊑ κ1 ⊑ . . .

Let κ = sup

n κn. We will show that κ is the desired upper bound.

Pick a state σ . Then, κ(σ )(A) is non-negative for all measurable subsets A, and κ(σ )(∅) = 0.
Furthermore, for every countable collection {Aj }j of disjoint measurable subsets of State × [0, ∞),
(cid:16) (cid:216)

(cid:16) (cid:216)

(cid:16) (cid:216)

(cid:17)

κ(σ )

j

(cid:17) = sup

Aj

κn(σ )

(cid:17) = lim

Aj

n

j

(cid:213)

κn(σ )(Aj ) = (cid:213)

κn(σ )

Aj

j

lim
n

κn(σ )(Aj )

j

κn(σ )(Aj ) = (cid:213)

κ(σ )(Aj ).

j

n

= lim
n
= (cid:213)
j

j
sup
n

The exchange between sup and lim in the derivation uses the fact that the sequence involved is
increasing. The third equality follows from the countable additivity of κn(σ ), and the fourth from
the monotone convergence theorem applied to the counting measure on the set of natural numbers.
Finally,

κ(σ )(State × [0, ∞)) = sup
n

κn(σ )(State × [0, ∞)) ≤ 1.

We have just shown that κ(σ ) is a subprobability measure.

To show the measurability of κ, we use the fact that a map f from a measurable space (X , Σ)
to Sp(State × [0, ∞)) is measurable if and only if for all measurable subsets A of State × [0, ∞) and
reals r ∈ R,

f −1 (cid:16)

{µ | µ(A) ≤ r }

∈ Σ.

(cid:17)

Pick a measurable subset A of State × [0, ∞) and a real r ∈ R. Then,

κ−1({µ | µ(A) ≤ r }) = {σ | κ(σ )(A) ≤ r }

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:37

= {σ | sup
n

κn(σ )(A) ≤ r }

= {σ | κn(σ )(A) ≤ r for all n}
= (cid:217)
n
But the intersection at the end of this derivation gives a measurable set because each {σ | κn(σ )(A)}
□
is measurable and the countable intersection preserves measurability.

{σ | κn(σ )(A)}.

Lemma A.1. Let {κn }n be an ω-chain in K. For all non-negative measurable functions h : State ×

[0, ∞) → [0, ∞) and all states σ ,

∫ (cid:16) (cid:196)

(cid:17)

κn

n

(σ )(d(σ ′, w ′)) h(σ ′, w ′) = lim
n

∫

κn(σ )(d(σ ′, w ′)) h(σ ′, w ′).

Proof. We prove it by a simpler version of the so called monotone class theorem. This version
says that in order to show the claimed equality for all non-negative measurable h, it suffices to
show the following properties:

• The claimed equality holds if h is the indicator function λ(σ , w). 1[(σ,w )∈A] for a measurable

subset A of State × [0, ∞).

• If non-negative measurable h1 and h2 satisfy the claimed equality and r1, r2 are non-negative

real numbers, the linear combination r1 · h1 + r2 · h2 also satisfies the equality.

• If {hm }m is a countable family of non-negative measurable functions such that each hm
m hm also satisfies the

satisfies the claimed equality and hm ≤ hm+1 for every m, then sup
claimed equality.

We will show these properties one by one.

Let us start with the proof of the first property. Pick a measurable subset A of State × [0, ∞).

Then,

∫ (cid:16) (cid:196)

(cid:17)

κn

n

(σ )(d(σ ′, w ′)) 1[(σ ′,w ′)∈A] = (cid:16) (cid:196)
∫

n

(cid:17)

κn

(σ )(A) = sup
n

(κn(σ )(A)) = lim
n

(κn(σ )(A))

= lim
n

κn(σ )(d(σ ′, w ′)) 1[(σ ′,w ′)∈A].

The first and the last equalities use the definition of integration, the second the characterisation of
the least upper bound in K, and the third the fact that {κn(σ )(A)}n is increasing.

For the second property, assume that the claimed equality holds for non-negative measurable

functions h1 and h2. Let r1 and r2 be non-negative real numbers. Then,

∫ (cid:16) (cid:196)

(cid:17)

κn

(σ )(d(σ ′, w ′)) (r1h1(σ ′, w ′) + r2h2(σ ′, w ′))

n
∫ (cid:16) (cid:196)

(cid:17)

κn

= r1

(σ )(d(σ ′, w ′)) h1(σ ′, w ′) + r2

∫ (cid:16) (cid:196)

(cid:17)

κn

(σ )(d(σ ′, w ′)) h2(σ ′, w ′)

n

∫

∫

= r1 lim
n
(cid:16)
r1

= lim
n

κn(σ )(d(σ ′, w ′)) h1(σ ′, w ′) + r2 lim
n
∫

κn(σ )(d(σ ′, w ′)) h1(σ ′, w ′) + r2

∫

n
κn(σ )(d(σ ′, w ′)) h2(σ ′, w ′)

κn(σ )(d(σ ′, w ′)) h2(σ ′, w ′)

(cid:17)

∫

= lim
n

κn(σ )(d(σ ′, w ′)) (r1h1(σ ′, w ′) + r2h2(σ ′, w ′)).

0:38

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

The first and the last equalities use the linearity of integration, the second the assumption on h1
and h2, and the third the continuity of constant multiplication and addition.

For the final third property, consider an increasing sequence {hm }m in the property. Then,
(cid:17) =

∫ (cid:16) (cid:196)

∫ (cid:16) (cid:196)

(cid:17)

(cid:16)

(cid:17)

κn

(σ )(d(σ ′, w ′))

(hm(σ ′, w ′))

hm)(σ ′, w ′)

κn

(σ )(d(σ ′, w ′)) sup
m

(sup
m

n

n
∫ (cid:16) (cid:196)

=

(cid:17)

κn

n
∫ (cid:16) (cid:196)

= lim
m

(σ )(d(σ ′, w ′)) lim
m

(hm(σ ′, w ′))

(cid:17)

κn

(σ )(d(σ ′, w ′)) hm(σ ′, w ′)

n

∫

∫

κn(σ )(d(σ ′, w ′)) hm(σ ′, w ′)

κn(σ )(d(σ ′, w ′)) hm(σ ′, w ′).

= lim
m

lim
n

= lim
n

lim
m

The third equality uses the monotone convergence theorem, and the fourth the assumption on the
□
hm.

Theorem 4.3. For every command C, its interpretation ⟦C⟧ is well-defined and it belongs to K.

Proof. We prove the theorem by induction on the structure of C. In the proof, we use concepts

and results from the measure theory that go beyond what we reviewed in §3.

We start with the case C ≡ (x := E). For every σ ∈ State, ⟦x := E⟧(σ ) is the Dirac measure at
(σ [x (cid:55)→ ⟦E⟧σs ], 1). Thus, it suffices to show the measurability of the following function F for every
measurable subset A:

F (σ ) = 1[(σ [x (cid:55)→⟦E⟧σs ],1)∈A].

This holds because the functions

(σ , w) (cid:55)−→ 1[(σ,w )∈A] : State × [0, ∞) → [0, 1],
are both measurable.

σ (cid:55)−→ (σ [x (cid:55)→ ⟦E⟧σs ], 1) : State → State × [0, ∞)

The case C ≡ skip follows from our argument for the previous case C ≡ (x := E), because

⟦skip⟧ = ⟦x := x⟧.

Next we consider sequential composition. Assume that C ≡ (C0; C1). By induction hypothesis,

we know that ⟦C0⟧ and ⟦C1⟧ are subprobability kernels. Then, for all σ and A,

⟦C0; C1⟧(σ )(A) =

≤

∫

∫

⟦C0⟧(σ )(d(σ ′, w ′))

∫

⟦C1⟧(σ ′)(d(σ ′′, w ′′)) 1[(σ ′′,w ′ ·w ′′)∈A]

⟦C0⟧(σ )(d(σ ′, w ′)) ≤ 1.

Furthermore, it is not difficult to show that ⟦C0; C1⟧(σ ) is a measure. The measurability of ⟦C0; C1⟧
follows from three facts. First, it suffices to show that for all measurable subsets A, the function
σ (cid:55)−→ ⟦C0; C1⟧(σ )(d(σ ′, w ′))(A)
is measurable. Second, for every measurable f and every subprobability kernel κ, the function x (cid:55)−→
∫
κ(x)(dy)f (y) is measurable. Second, the functions (σ , w) (cid:55)−→ ⟦C1⟧(σ ) ⊗ δw and ((σ ′′, w ′′), w) (cid:55)−→
(σ ′′, w ′ · w ′′) are measurable. Here δw is the Dirac measure at w and ⊗ is the operator for product
measure.

We move on to the case of C ≡ (if B {C0} else {C1}). We first show that the function ⟦C⟧ is a
well-defined function from State to Sp(State × [0, ∞)), that is, ⟦C⟧(σ ) is a subprobability measure

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:39

for every σ ∈ State. The non-negativity and countable additivity of ⟦C⟧(σ ) follow from the same
properties of ⟦C0⟧(σ ) and ⟦C1⟧(σ ). Also,

⟦C⟧(σ )(A) = ⟦if B {C0} else {C1}⟧(σ )(A)

= 1[⟦B⟧σs =true] · ⟦C0⟧(σ )(A) + 1[⟦B⟧σs (cid:44)true] · ⟦C1⟧(σ )(A)
≤ 1[⟦B⟧σs =true] · 1 + 1[⟦B⟧σs (cid:44)true] · 1 = 1.

It remains to show that ⟦C⟧ is measurable. This boils down to showing that

{σ | 1[⟦B⟧σs =true] · ⟦C0⟧(σ )(A) + 1[⟦B⟧σs (cid:44)true] · ⟦C1⟧(σ )(A) ≤ r }
is measurable for all r ∈ R and measurable subset A of State × [0, ∞). But this follows easily from
the induction hypothesis and the measurability of ⟦B⟧.

The next case is C ≡ (while B {C0}). Recall Lemma 4.2, which says that the set of subprobability
kernels from State to State × [0, ∞), denoted by K, is an ω-cpo when given the pointwise order
⊑. Let F be the function on K used in the semantics of C. That is, for all κ ∈ K, σ ∈ State and
measurable A ⊆ Store × [0, ∞),

F (κ)(σ )(A) ≜ 1[⟦B⟧σs (cid:44)true] · 1[(σ,1)∈A]

+ 1[⟦B⟧σs =true] ·

∫

⟦C0⟧(σ )(d(σ ′, w ′))

∫

κ(σ ′)(d(σ ′′, w ′′)) 1[(σ ′′,w ′ ·w ′′)∈A].

It suffices to show that F is a continuous function on K. The arguments used to handle the if and
sequencing cases show that F (κ) is a subprobability kernel. The monotonicity of F follows from the
fact that the integration is monotone with respect to the measure and its integrand. It remains to
show that F preserves the limits of ω-chains. Consider an ω-chain {κn }n of subprobability kernels
in K. Then, the least upper bound of this ω-chain is κ = (cid:195)
n κn. The following calculation shows
that F preserves this limit.

F (κ)(σ )(A)
= 1[⟦B⟧σs (cid:44)true] · 1[(σ,1)∈A]

+ 1[⟦B⟧σs =true] ·
= 1[⟦B⟧σs (cid:44)true] · 1[(σ,1)∈A]

+ 1[⟦B⟧σs =true] ·

= 1[⟦B⟧σs (cid:44)true] · 1[(σ,1)∈A]

+ 1[⟦B⟧σs =true] ·
= 1[⟦B⟧σs (cid:44)true] · 1[(σ,1)∈A]

∫

∫

∫

⟦C0⟧(σ )(d(σ ′, w ′))

∫

κ(σ ′)(d(σ ′′, w ′′)) 1[(σ ′′,w ′ ·w ′′)∈A]

⟦C0⟧(σ )(d(σ ′, w ′))

∫ (cid:196)

κn(σ ′)(d(σ ′′, w ′′)) 1[(σ ′′,w ′ ·w ′′)∈A]

n

∫

∫

κn(σ ′)(d(σ ′′, w ′′)) 1[(σ ′′,w ′ ·w ′′)∈A]

κn(σ ′)(d(σ ′′, w ′′)) 1[(σ ′′,w ′ ·w ′′)∈A]

⟦C0⟧(σ )(d(σ ′, w ′)) lim
n

∫

+ 1[⟦B⟧σs =true] · lim
n
(cid:16)1[⟦B⟧σs (cid:44)true] · 1[(σ,1)∈A]

⟦C0⟧(σ )(d(σ ′, w ′))

= lim
n

= lim
n

+ 1[⟦B⟧σs =true] ·

∫

⟦C0⟧(σ )(d(σ ′, w ′))

∫

κn(σ ′)(d(σ ′′, w ′′)) 1[(σ ′′,w ′ ·w ′′)∈A]

(cid:17)

F (κn)(σ )(A) = (cid:16) (cid:196)

(cid:17)

F (κn)

(σ )(A).

n

0:40

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

The third equality uses the continuity of integration with respect to the integrating measure and
the non-negative integrand (Lemma A.1), and the fourth equality uses the monotone convergence
theorem.

The next case is C ≡ (x := samplenorm(S, E1, E2)). The requirement that

⟦x := samplenorm(S, E1, E2)⟧(σ )
is a measure for every σ follows immediately from the semantic equation for this sample statement,
which says that ⟦x := samplenorm(S, E1, E2)⟧(σ ) is either the constant-0 measure or the pushforward
of a normal distribution with mean ⟦E1⟧σs and standard deviation ⟦E2⟧σs by some measurable func-
tion. In fact, the following calculation shows that ⟦x := samplenorm(S, E1, E2)⟧ is a subprobability
measure:

⟦x := samplenorm(S, E1, E2)⟧(σ )(A)

∫

= 1[⟦S ⟧σs (cid:60)dom(σr )] · 1[⟦E2⟧σs (cid:60)(0,∞)] ·
≤ 1[⟦S ⟧σs (cid:60)dom(σr )] · 1[⟦E2⟧σs (cid:60)(0,∞)] · 1
≤ 1.

dv (cid:0)N (v; ⟦E1⟧σs , ⟦E2⟧σs ) · 1[((σs [x (cid:55)→v], σr [⟦E2⟧σs (cid:55)→v]),1)∈A]

(cid:1)

Also, since all of N , ⟦S⟧, ⟦E0⟧ and ⟦E1⟧ are measurable,

{σ | ⟦x := samplenorm(S, E1, E2)⟧(σ )(A) ≤ r }
is a measurable subset of State for all A and r . This means that ⟦x := samplenorm(S, E1, E2)⟧ is a
measurable function. From what we have proved, it follows that ⟦x := samplenorm(S, E1, E2)⟧ is a
subprobability kernel as required.

The last case is C ≡ scorenorm(E0, E1, E2). Because of the semantic equation for this score state-
ment, ⟦scorenorm(E0, E1, E2)⟧(σ ) is a measure for all σ . Furthermore, ⟦scorenorm(E0, E1, E2)⟧(σ )(A) is
the product of two indicator functions, and so it is at most 1. That is, ⟦scorenorm(E0, E1, E2)⟧(σ ) is a
subprobability measure. By the semantic equation for the score statement again, the measurability of
the normal density and the measurability of E0, E1 and E2, the set {σ | ⟦scorenorm(E0, E1, E2)⟧(σ )(A) ≤
r } is measurable for all A and r . This measurability implies that ⟦scorenorm(E0, E1, E2)⟧ is a measur-
able function. By putting all these together, we can derive the required fact that ⟦scorenorm(E0, E1, E2)⟧
□
is a subprobability kernel.

Lemma 4.4. For every measurable h : RDB × RDB × RDB → R, the function (r , r ′) (cid:55)−→ 1[r #r ′] ×

h(r , r ′, r ⊎ r ′) from RDB × RDB to R is measurable.

Proof. Let ∗ : RDB × RDB → RDB be the following extension of the partial function ⊎ :

RDB × RDB →partial RDB to a total function:

r ∗ r ′ ≜

(cid:26) r ⊎ r ′
[]

if r #r ′,
otherwise.

Then, for all r , r ′,

1[r #r ′] · h(r , r ′, r ⊎ r ′) = 1[r #r ′] · h(r , r ′, r ∗ r ′).
We will show that (r , r ′) (cid:55)−→ 1[r #r ′] and (r , r ′) (cid:55)−→ r ∗r ′ are measurable. This is enough because the
function on the RHS of the above equation (namely, (r , r ′) (cid:55)−→ 1[r #r ′] · h(r , r ′, r ∗ r ′)) is constructed
by applying pairing, composition and multiplication operators on measurable functions and so it is
measurable.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:41

Pick a real number v ∈ R. We should show that B = {(r, r ′) | 1[r #r ′] ≤ v} is measurable. If
v ≥ 1, the set B is RDB × RDB, and so it is measurable. If v < 0, then B is the empty set, so that it is
measurable as well. If 0 ≤ v < 1, then

{(r , r ′) | 1[r #r ′] ≤ v} = (cid:216)

(cid:216)

[K → R] × [K ′ → R],

K ⊆finStr

K ′ ⊆finStr
K ∩K ′(cid:44)∅

which is measurable because the RHS of the above equation is the countable union of measurable
sets.

Pick a measurable subset A of RDB. We have to prove that B = {(r , r ′) | r ∗r ′ ∈ A} is measurable.

If A = {[]}, then B = {(r , r ′) | 1[r #r ′] ≤ 0.5} ∪ {([], [])}, so that it is measurable. If [] (cid:60) A, then

{(r , r ′) | r ∗ r ′ ∈ A} =

(cid:216)

(cid:216)

K ⊆finStr

K ′ ⊆finStr
K ∩K ′=∅

{(r, r ′) ∈ [K → R] × [K ′ → R] | r ⊎ r ′ ∈ {r ′′ ∈ A | dom(r ′′) = K ∪ K ′}}.

But {r ′′ ∈ A | dom(r ′′) = K ∪ K ′} is measurable, and the set on the RHS of the above equation is
the countable union of measurable sets. Thus, B is measurable in this case as well. The remaining
case is that A contains [] and some other element. We can prove this case by splitting A into {[]}
□
and A \ {[]} and using what we proved in the previous two cases.

Lemma 4.5. (D, ⊑) is an ω-complete partial order and has the least element a (cid:55)−→ ⊥. Thus, every

continuous function G on D has the least fixed point.

Proof. All constant functions from a measurable space to another are measurable. Thus, the
constant function a (cid:55)−→ ⊥ is measurable. It is immediate that this constant function is local and
smaller than any other functions in D.

Let д0 ⊑ д1 ⊑ д2 ⊑ . . . be an ω-chain. We show that the following function is the least upper

bound of the sequence in D: for all s, r ,
(cid:26) ⊥

(cid:16) (cid:196)

(cid:17)

дi

(s, r ) =

i

if дi (s, r ) = ⊥ for all i,
c (cid:44) ⊥ if дi (s, r ) = c (cid:44) ⊥ for some i.

By definition, this function is the least upper bound in D that we are looking for, if it is measurable
and local. To check the locality, suppose that ((cid:195)
i дi )(s, r ) = (s ′, r ′, w ′, p ′). Then, there exists some i
such that дi (s, r ) = (s ′, r ′, w ′, p ′). By the locality of дi , we have that

(∃r ′′. r ′#r ′′ ∧ r = r ′ ⊎ r ′′ ∧ дi (s, r ′′) = (s ′, [], w ′, p ′))

Thus, the definition of (cid:195)
We have just shown that (cid:195)
It remains to show that (cid:195)
measurable set. We prove that ((cid:195)

∧ (∀r ′′. r #r ′′ =⇒ дi (s, r ⊎ r ′′) = (s ′, r ′ ⊎ r ′′, w ′, p ′)).
i дi implies that the above property holds when we replace дi by (cid:195)

i дi is local.
i дi is measurable. Let A ⊆ {⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞)) be a

i дi .

i дi )−1(A) is a measurable set.

• Case A = {⊥}:

(s, r ) ∈

(cid:16) (cid:196)

(cid:17) −1

дi

i

({⊥}) ⇐⇒ дi (s, r ) = ⊥ for all i ⇐⇒ (s, r ) ∈ д−1

i

({⊥}) for all i

⇐⇒ (s, r ) ∈

д−1
i

({⊥}).

(cid:217)

i

0:42

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

The intersection of countably many measurable sets are measurable, and д0, д1, . . . are mea-
surable functions. Hence we get the measurability of ((cid:195)

i дi )−1({⊥}).

• Case ⊥ (cid:60) A:

(s, r ) ∈

(cid:16) (cid:196)

(cid:17) −1

дi

i

(A) ⇐⇒ дi (s, r ) ∈ A for some i ⇐⇒ (s, r ) ∈ д−1

i

(A) for some i

⇐⇒ (s, r ) ∈

д−1
i

(A).

(cid:216)

i

The first equivalence follows from the definition of the order ⊑. The union of measurable
sets are measurable, and д0, д1, . . . are measurable functions. Thus, the desired result follows.

• Case A = {⊥} ∪ A′ with ⊥ (cid:60) A′:

Then A′ is also measurable as {⊥} is and the set subtraction preserves measurability. Moreover
i дi )−1(A′), and the union of countably many measurable
((cid:195)
sets is measurable, and so we can apply the two cases above.

i дi )−1({⊥}) ∪ ((cid:195)

i дi )−1(A) = ((cid:195)

The ω-cpo D permits an operator for composing functions in it. We say that a function
(cid:17)

(cid:16)

{⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞))

→

{⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞))

д : (cid:16)

□

(cid:17)

is local if for all (s, r , w, p), (s ′, r ′, w ′, p ′) ∈ Store × RDB × [0, ∞) × [0, ∞),

д(s, r , w, p) = (s ′, r ′, w ′, p ′) =⇒ (∃r ′′. r ′#r ′′ ∧ r = r ′ ⊎ r ′′ ∧ д(s, r ′′, w, p) = (s ′, [], w ′, p ′))

∧ (∀r ′′. r #r ′′ =⇒ д(s, r ⊎ r ′′, w, p) = (s ′, r ′ ⊎ r ′′, w ′, p ′)).

We say that д is strict if д(⊥) = ⊥. Let
D‡ ≜ (cid:110)

д : (cid:16)

{⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞))

(cid:17)

(cid:16)

→

{⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞))
(cid:12) д is measurable, local and strict(cid:111)

(cid:12)
(cid:12)

.

(cid:17)

Define a partial order ⊑ on D‡ by

д ⊑ д′ ⇐⇒ ∀a ∈ {⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞)). (д(a) = ⊥ ∨ д(a) = д′(a)).

Lemma A.2. (D‡, ⊑) is an ω-complete partial order and has the least element.

Proof. Let
E ≜ (cid:110)

д : (cid:16)

Store × RDB × [0, ∞) × [0, ∞)

(cid:17)

(cid:16)

→

{⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞))
(cid:12) д is measurable and local(cid:111)

(cid:12)
(cid:12)

.

(cid:17)

Essentially by the same argument as the one used in the proof of Lemma 4.5, the set E with the
pointwise order ⊑ is an ω-cpo and has the least element. But (D‡, ⊑) and (E, ⊑) are isomorphic as
□
partially order sets. Thus, (D‡, ⊑) has the property claimed by the lemma.

The following lemma says that the lifting д‡ of д ∈ D in §4.3 is a well-defined function from D

to this new domain.

Lemma A.3. The function д (cid:55)−→ д‡ from D to D‡ is well-defined and continuous.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:43

Proof. We first show that the function is well-defined. Let д ∈ D. Then, д‡(⊥) = ⊥ by the
definition of д‡. The measurability of д‡ follows from the measurability of д, projection, and
multiplication and the fact that both the pairing of measurable functions (into a function to a
product measurable space) and the function composition preserve measurability. The locality of д‡
follows from that of д.

Next, we show the claimed continuity. The monotonicity is an immediate consequence of the
definitions of the −‡ operator and the orders on D and D‡. It remains to show the limit preservation.
Let д0 ⊑ д1 ⊑ д2 ⊑ . . . be an ω-chain in D. Then, by the monotonicity of −‡, {д‡
n }n is also an
ω-chain in D‡. We should show that

(cid:16) (cid:196)

(cid:17) ‡

(a) = (cid:16) (cid:196)

(cid:17)

д‡
n

(a)

дn

n

n

for all a from ({⊥} ∪ Store × RDB × [0, ∞) × [0, ∞)). Pick such an a. If a = ⊥, the required holds
because both sides become ⊥. If a (cid:44) ⊥ but дn(a) = ⊥ for all n, then again both sides of the equality
are ⊥, and so the equality holds. If neither of these two cases hold, there exists n such that дn(a) (cid:44) ⊥
and дn(a) = дm(a) for all m ≥ n. Let (s ′, r ′, w ′, p ′) = дn(a), and (s, r ) = a. Then,

(cid:16) (cid:196)

(cid:17) ‡

(a) = (cid:16)

s ′, r ′, w × w ′, p × p ′(cid:17) = (cid:16) (cid:196)

дn

(cid:17)

д‡
n

(a).

n

n

□

Lemma 4.6. For every command C, its semantics ⟦C⟧

d is well-defined and belongs to D.

is well-defined and measurable proceeds by induction on the

Proof. The proof that ⟦C⟧
d

structure of commands C.
• Case of ⟦skip⟧
d

:

The semantics is clearly well-defined in this case. Note that ⟦skip⟧
is essentially the pairing
d
of the identity function and a constant function. Since both of these functions are measurable
and the pairing preserves measurability, ⟦skip⟧
neither
d
changes nor depends on the r component, it is local.

is measurable. Also, since ⟦skip⟧
d

• Case of ⟦x := E⟧
d

:

The proof is identical to the previous case except that instead of the identity function, we
should use the function (s, r ) (cid:55)−→ (s[x (cid:55)→ ⟦E⟧s], r ), which is measurable because it can be
constructed by composing and pairing three measurable functions, ⟦E⟧, (s, v) (cid:55)−→ s[x (cid:55)→ v],
and projection.

• Case of ⟦if B {C0} else {C1}⟧
d

:

The well-definedness and the locality are immediate consequences of the induction hypothesis
on ⟦C0⟧
. Let A ⊆ {⊥} ∪ Store × RDB × [0, ∞) × [0, ∞) be a measurable set. Then,
d
⟦if B {C0} else {C1}⟧−1

and ⟦C1⟧
d

d (A)
{(s, r ) | ⟦B⟧s = true} ∩ ⟦C0⟧−1

= (cid:16)

d (A)

(cid:16)

(cid:17)

∪

{(s, r ) | ⟦B⟧s (cid:44) true} ∩ ⟦C1⟧−1

d (A)

(cid:17)

.

Moreover, {true} is measurable, and so is its complement. Since ⟦B⟧ is a measurable function,
{(s, r ) | ⟦B⟧s = true} and {(s, r ) | ⟦B⟧s (cid:44) true} are measurable. As a result the above set is
measurable. So, ⟦if B {C0} else {C1}⟧
d
• Case of ⟦C0; C1⟧
:
d
By induction hypothesis, both ⟦C0⟧
are well-defined, local and measurable. This
d
and Lemma A.3 imply that ⟦C1⟧‡
is also local and measurable. The function ⟦C0; C1⟧
is
d
d
nothing but the composition of two well-defined measurable functions ⟦C1⟧‡
, and
d

is well-defined, local and measurable as claimed.

and ⟦C1⟧
d

and ⟦C0⟧
d

0:44

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

so it satisfies the claimed well-definedness and measurability. To see the locality of ⟦C0; C1⟧
d
suppose that

,

◦ ⟦C0⟧
Then, there exist s ′, r ′, w ′, p ′ such that

(⟦C1⟧‡
d

d )(s, r ) = (s ′′, r ′′, w ′′, p ′′).

By the locality of ⟦C0⟧
d

⟦C0⟧

d

d (s, r ) = (s ′, r ′, w ′, p ′) ∧ ⟦C1⟧‡
and ⟦C1⟧‡
d

0 ⊎ r ′ = r ∧ ⟦C0⟧

, there exist r ′
d (s, r ′
0 ⊎ r ′′ = r ′ ∧ ⟦C1⟧‡
d

(s ′, r ′′

r ′
0#r ′ ∧ r ′
∧ r ′′

0 #r ′′ ∧ r ′′
0 . Let r0 ≜ r ′

Note that r ′

0#r ′′

0 ⊎ r ′′

0 . Then,

(s ′, r ′, w ′, p ′) = (s ′′, r ′′, w ′′, p ′′).

0 and r ′′

0 such that

0) = (s ′, [], w ′, p ′)

0 , w ′, p ′) = (s ′′, [], w ′′, p ′′).

d

(s ′, r ′′

◦ ⟦C0⟧

d )(s, r0) = ⟦C1⟧‡

r0#r ′′ ∧ r0 ⊎ r ′′ = r ∧ (⟦C1⟧‡
0 , w ′, p ′) = (s ′′, [], w ′′, p ′′).
d
The first equality from above uses the locality of ⟦C0⟧
. Thus, the first conjunct in the
d
definition of locality holds if we use r0 as a witness in the conjunct. To prove the second
in the definition, consider r1 such that r1#r . Then, r1#r ′. Thus, by the locality of ⟦C0⟧
and
d
⟦C1⟧‡
d
(⟦C1⟧‡
d
• Case of ⟦while B {C}⟧
d

(s ′, r ′ ⊎ r1, w ′, p ′) = (s ′′, r ′′ ⊎ r1, w ′′, p ′′).

d )(s, r ⊎ r1) = ⟦C1⟧‡

, we have

◦ ⟦C0⟧

d

:

Since D is an ω-cpo and has the least element, we simply need to prove that G in the definition
of ⟦while B {C}⟧
is well-defined and continuous so that Kleene’s fixed point theorem applies
d
(Lemma 4.5). By induction hypothesis, ⟦C⟧
is well-defined, local, and measurable. Thus,
d
G is a well-defined function from D to D; the proof that the image of G consists of local
measurable functions is similar to the case of the if statement extended with the argument
with the case of sequencing. Furthermore, G is monotone because both the lifting −‡ and the
function composition are monotone. Thus, G transforms an ω-chain into an ω-chain. Finally,
G preserves the least upper bound of such an ω-chain. This is because both the lifting −‡
and the function composition preserve the least upper bound. We have just shown that G is
well-defined and continuous.

• Case of ⟦x := samplenorm(S, E1, E2)⟧
d

:

The well-definedness and the locality are immediate. To prove the measurability, pick a
measurable subset A of {⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞). Then,

{(s, r ) | ⟦x := samplenorm(S, E1, E2)⟧

d (s, r ) ∈ A} = A0 ∪ A1 ∪ A2 ∩ A3

where

A0 = {(s, r ) | ⊥ ∈ A ∧ ⟦S⟧s (cid:60) dom(r )},
A1 = {(s, r ) | ⊥ ∈ A ∧ ⟦E2⟧s (cid:60) (0, ∞)},
A2 = {(s, r ) | ⟦S⟧s ∈ dom(r ) ∧ ⟦E2⟧s ∈ (0, ∞)},
A3 = A2 ∩ {(s, r ) | (s[x (cid:55)→ r (⟦S⟧s)], r \ ⟦S⟧s, 1, N (r (⟦S⟧s); ⟦E1⟧s, ⟦E2⟧s)) ∈ A}.

We show that all of A0, A1, A2 and A3 are measurable. The measurability of the first three
sets follow from the measurability of the following two sets:

A′

0 ≜ {(s, r ) | ⟦E2⟧s ∈ (0, ∞)}

and A′

1 ≜ {(s, r ) | ⟦S⟧s ∈ dom(r )}.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:45

The set A′
0 is measurable because it is the inverse image of the composition of two measurable
functions (namely, ⟦E1⟧ and projection) to the measurable set (0, ∞). For the measurability
of A′

{(s, r ) | dom(r ) = K } ∩ {(s, r ) | ⟦S⟧s ∈ K }.

1, note that
{(s, r ) | ⟦S⟧s ∈ dom(r )} = (cid:216)
K ⊆finStr

The set on the RHS is measurable, because it is a countable union of the intersection of two
measurable subsets; the measurability of {(s, r ) | dom(r ) = K } comes from the fact that RDB
is built by the disjoint-union construction over [K → R] for all finite K, and the measurability
of {(s, r ) | ⟦S⟧s ∈ K } follows from the measurability of the function ⟦S⟧ and the set K. It
remains to show the measurability of A3. To do so, we note that A3 is the inverse image of a
function constructed by applying measurability-preserving operators on ⟦S⟧, ⟦E1⟧, ⟦E2⟧ and
N , and the application and restriction functions on random databases. Since the first four
are measurable, it is sufficient to show the measurability of the last two, which we spell out
below:

f1 : RDB × Str → R,

f1(r , α) ≜

(cid:26) r (α)
0

if α ∈ dom(r ),
otherwise,

f2 : RDB × Str → RDB,

f2(r , α)(β) ≜

(cid:26) undefined if α = β,

r (β)

otherwise.

For any measurable subset A of R,
f −1
1

(A) = (cid:216)

(cid:216)

(cid:16)

{(r , β) | dom(r ) = K ∧ β = α ∧ α (cid:60) K ∧ 0 ∈ A}

α ∈Str

K ⊆finStr

∪ {(r , β) | dom(r ) = K ∧ β = α ∧ α ∈ K ∧ r (α) ∈ A}

(cid:17)

.

All the explicitly-defined sets on the RHS of this equation are measurable, and the RHS only
uses finite or countable union. Thus, f −1
(A) is measurable. Now consider a measurable subset
1
A′ of RDB. Then,
(A′) = (cid:216)
f −1
2

{(r , β) | β = α ∧ dom(r ) = K ∧ α (cid:60) K ∧ r ∈ A′}

(cid:216)

(cid:16)

α ∈Str

K ⊆finStr

∪ {(r , β) | β = α ∧ dom(r ) = K ∧ α ∈ K ∧ r \ α ∈ A′}

(cid:17)

.

Again all the explicitly-defined sets on the RHS of this equation are measurable, and the RHS
only uses finite or countable union. Thus, f −1
2

(A′) is measurable.

• Case of ⟦scorenorm(E0, E1, E2)⟧
d

:

The well-definedness and the locality are immediate in this case. Pick a measurable set

A ⊆ {⊥} ∪ (Store × RDB × [0, ∞) × [0, ∞)).

Then,

⟦scorenorm(E0, E1, E2)⟧−1

d (A) = {(s, r ) | (s, r , N (⟦E0⟧s; ⟦E1⟧s, ⟦E2⟧s), 1) ∈ A}

∪ {(s, r ) | ⊥ ∈ A ∧ ⟦E2⟧s (cid:60) (0, ∞)}

Both sets in the union here are measurable because all of N , ⟦E0⟧, ⟦E1⟧ and ⟦E2⟧ are mea-
surable and the composition and the pairing operators on functions preserve measurability.
Thus, the union itself is measurable.

□

0:46

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

Lemma 4.7. For all д ∈ D, the following functions from Store × RDB to R and {⊥} ∪ Store are

measurable: (s, r ) (cid:55)−→ dens(д, s)(r ) and (s, r ) (cid:55)−→ get(д, s)(r ).

Proof. We have to show that for every real v ∈ R and measurable subset A ⊆ {⊥} ∪ Store,

B0 ≜ {(s, r ) | dens(д, s)(r ) ≤ v}

and B1 ≜ {(s, r ) | get(д, s)(r ) ∈ A}

are measurable. The set B0 is measurable because

{(s, r ) | dens(д, s)(r ) ≤ v}

= {(s, r ) | д(s, r ) = ⊥ ∧ 0 ≤ v}

∪ {(s, r ) | ∃s ′, r ′, w ′, p ′. д(s, r ) = (s ′, r ′, w ′, p ′) ∧ r ′ (cid:44) [] ∧ 0 ≤ v}
∪ {(s, r ) | ∃s ′, r ′, w ′, p ′. д(s, r ) = (s ′, r ′, w ′, p ′) ∧ r ′ = [] ∧ w ′ · p ′ ≤ v}

and the three sets on the RHS of the equation are all measurable. The measurability of the other B1
follows from a similar argument based on case split. That is,

{(s, r ) | get(д, s)(r ) ∈ A}

= {(s, r ) | д(s, r ) = ⊥ ∧ ⊥ ∈ A}

∪ {(s, r ) | ∃s ′, r ′, w ′, p ′. д(s, r ) = (s ′, r ′, w ′, p ′) ∧ r ′ (cid:44) [] ∧ ⊥ ∈ A}
∪ {(s, r ) | ∃s ′, r ′, w ′, p ′. д(s, r ) = (s ′, r ′, w ′, p ′) ∧ r ′ = [] ∧ s ′ ∈ A}

and all three sets on the RHS of the equation are measurable. Thus, B1 is a measurable subset. □

In the next lemma, we regard {⊥} ∪ Store as a partially-ordered set with the expected order:

a ⊑ b ⇐⇒ a = ⊥ ∨ a = b, for all a, b ∈ {⊥} ∪ Store.

Lemma A.4. Let {дn }n be an ω-chain in D. Then, for all stores s and random databases r , the

sequences {dens(дn, s)(r )}n and {get(дn, s)(r )}n are increasing,

lim
n

dens(дn, s)(r ) = dens

(cid:16) (cid:196)

(cid:17)

(r ),

дn, s

n

and

lim
n

get(дn, s)(r ) = get

(cid:16) (cid:196)

(cid:17)

(r ).

дn, s

n

Proof. Let s be a store, r be a random database, and {дn }n be an ω-chain in D.
We first show that the sequences {dens(дn, s)(r )}n and {get(дn, s)(r )}n are increasing. We do so
by showing the monotonicity of dens(−, s)(r )and get(−, s)(r ). Consider д, д′ ∈ D such that д ⊑ д′.
Then, д(s, r ) = ⊥ or д(s, r ) = д′(s, r ). In the former case, dens(д, s)(r ) = 0 ≤ dens(д′, s)(r ) and
get(д, s)(r ) = ⊥ ⊑ get(д′, s)(r ). In the latter case, dens(д, s)(r ) = dens(д′, s)(r ) and get(д, s)(r ) =
get(д′, s ′)(r ). Thus, dens(−, r )(s) and get(−, r )(s) are monotone.

Next we show that dens(−, s)(r ) and get(−, s)(r ) preserve the limit. By what we have already
shown, the sequence {дn(s, r )}n is monotone. But this sequence is ultimately stable. The sta-
ble value becomes the least upper bound (cid:195)
n дn)(s, r ). Thus,
{dens(дn, s)(r )}n is ultimately stable as well, and its limit is
(cid:16) (cid:196)

n дn(s, r ), which is also equal to ((cid:195)

(cid:17)

lim
n

dens(дn, s)(r ) = dens

дn, s

(r ).

n

By the same reason, {get(дn, s)(r )}n is ultimately stable, and has the limit

lim
n

get(дn, s)(r ) = get

(cid:16) (cid:196)

(cid:17)

(r ).

дn, s

n

□

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:47

Lemma 4.8. For all non-negative bounded measurable functions h : ({⊥} ∪ Store) × RDB → R, stores

s, and functions д1, д2 ∈ D, we have that

∫

(cid:16)

ρ(dr )

dens(д‡

2 ◦ д1, s)(r ) · h

(cid:16)

get(д‡

2 ◦ д1, s)(r ), r

(cid:17)(cid:17)

∫

=

(cid:16)

ρ(dr1)

dens(д1, s)(r1) · 1[get(д1,s)(r1)(cid:44)⊥]

∫

·

(cid:16)

ρ(dr2)

dens(д2, get(д1, s)(r1))(r2) · 1[r1#r2] · h

(cid:16)

get(д2, get(д1, s)(r1))(r2), r1 ⊎ r2

(cid:17)(cid:17)(cid:17)

.

Proof. For д ∈ D and s ∈ Store, let

R1(д, s) : RDB → RDB,
(cid:26) r \ dom(r ′)

R1(д, s)(r ) ≜

[]

if д(s, r ) = (s ′, r ′, w ′, p ′) for some (s ′, r ′, w ′, p ′),
otherwise,

R2(д, s) : RDB → RDB,
(cid:26) r ′
[]

R2(д, s)(r ) ≜

if д(s, r ) = (s ′, r ′, w ′, p ′) for some (s ′, r ′, w ′, p ′),
otherwise.

Here r \ K means the restriction of r to dom(r ) \ K. Both R1(д, s) and R2(д, s) are measurable. The
measurability of the latter is an immediate consequence of the measurability of д. For the former,
we note that for every measurable subset A of RDB with [] (cid:60) A,

R1(д, s)−1(A) = (cid:216)

{r1 ⊎ r2 | r1 ∈ (A ∩ [K1 → R]) ∧ r2 ∈ [K2 → R]}

K1, K2 ⊆finStr
K1∩K2=∅

∩ д−1(s, −)(Store × [K2 → R] × [0, ∞) × [0, ∞)).

The partially applied function д(s, −) is measurable, so that the RHS of this equation is the countable
union of measurable subsets. If A = {[]}, then

R1(д, s)−1(A) = д−1(s, −)({⊥}) ∪

(cid:16)
A ∩ д−1(s, −)(Store × {[]} × [0, ∞) × [0, ∞))

(cid:17)

.

Thus, R1(д, s)−1(A) is measurable. The remaining case is that [] ∈ A. We can be handle this case by
splitting A into {[]} and A \ {[]}, and dealing with the slit cases separately.

For д ∈ D, s ∈ Store, and r ∈ RDB, let consumed(д, s, r ) be the predicate defined by

consumed(д, s, r ) ⇐⇒ ∃s ′, w ′, p ′. (д(s, r ) = (s ′, [], w ′, p ′)).

Then, r (cid:55)−→ 1[consumed(д,s,r )] is a measurable function.

Now we note a few useful equalities about the entities h, s, д1, д2 assumed in the lemma.
First, for all r , if

consumed(д‡

2 ◦ д1, s, r ),

then

r = R1(д1, s)(r ) ⊎ R2(д1, s)(r ),

get(д‡

2 ◦ д1, s)(r ) = get

(cid:16)
д2, get(д1, s)(R1(д1, s)(r ))

(cid:17)

(R2(д1, s)(r )),

dens(д‡

2 ◦ д1, s)(r ) = dens(д1, s)(R1(д1, s)(r )) · dens

(cid:16)
д2, get(д1, s)(R1(д1, s)(r ))

(cid:17)

(R2(д1, s)(r )).

The first equality is just an immediate consequence of the definitions of R1 and R2, and the other
two equalities hold mainly because д1 and д2 are local.

0:48

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

Next, consider the density functions f1 on RDB and f2 on RDB × RDB:

f1 : RDB → [0, ∞),
f2 : RDB × RDB → [0, ∞)

f1(r ) ≜ 1

2 ◦д1,s,r )],
f2(r1, r2) ≜ 1[consumed(д1,s,r1)] · 1[consumed(д2,get(д1,s)(r1),r2)]

[consumed(д‡

· 1[r1#r2].

The densities are taken with respect to ρ and ρ ⊗ ρ, respectively. There is a measurable bijection β
between the supports of f1 and f2, and the pushforward of the measure of f1 by this bijection is the
measure of f2. Concretely, the function β is:

β : RDB → RDB × RDB,

β(r ) =

(cid:40)

(R1(д1, s)(r ), R2(д1, s)(r ))
(rd , rd )

if consumed(д‡
otherwise,

2 ◦ д1, s, r )

where rd ∈ RDB is [“s” (cid:55)→ nil]. Note that β is not a bijection. But the restriction of β to A1 = {r |
f1(r ) > 0} is injective, and its image is A2 = {(r1, r2) | f2(r1, r2) > 0}. These properties follow from
the definitions of consumed, R1 and R2 and the locality of д. The function β is measurable because
R1(д1, s) and R2(д2, s) are measurable functions and {r | consumed(д‡
2 ◦ д1, s, r )} is a measurable
set. It remains to show the measure preservation of β. Pick a measurable subset A′ of A2. We have
to show that

(ρ ⊗ ρ)(A′) = ρ(β −1(A′)).

We calculate the equation as follows:

(ρ ⊗ ρ)(A′) = (ρ ⊗ ρ)

(cid:16) (cid:216)

(cid:16)

A′ ∩

[K1 → R] × [K2 → R]

(cid:17)(cid:17)

K1, K2 ⊆finStr
K1∩K2=∅
(cid:16)(cid:16) (cid:204)

ρv

= (cid:216)

(cid:16) (cid:204)

(cid:17)

⊗

(cid:17) (cid:16)

A′ ∩

(cid:16)

ρv

[K1 → R] × [K2 → R]

(cid:17)(cid:17)

K1, K2 ⊆finStr
K1∩K2=∅

= (cid:216)

K1, K2 ⊆finStr
K1∩K2=∅

α1 ∈K1

α2 ∈K2

(cid:16) (cid:204)

(cid:17) (cid:16)

ρv

α ∈K1∪K2

β −1(A′ ∩ ([K1 → R] × [K2 → R]))

(cid:17)

= (cid:216)

(cid:16)

ρ

β −1(A′ ∩ ([K1 → R] × [K2 → R]))

(cid:17)

K1, K2 ⊆finStr
K1∩K2=∅
β −1 (cid:16) (cid:216)
(cid:16)

= ρ

K1, K2 ⊆finStr
K1∩K2=∅

= ρ(β −1(A′)).

(A′ ∩ ([K1 → R] × [K2 → R]))

(cid:17)(cid:17)

Using what we have shown so far, we calculate the claim of the lemma. In the calculation we
often omit the д1 and s parameters from R1(д1, s)(r ) and R2(д1, s)(r ), and just write R1(r ) and R2(r ).
∫

(cid:16)

ρ(dr )

dens(д‡

2 ◦ д1, s)(r ) · h

get(д‡

2 ◦ д1, s)(r ), r

(cid:16)

(cid:17)(cid:17)

∫

∫

=

=

ρ(dr )

ρ(dr )

(cid:16)1

(cid:16)1

[consumed(д‡

2 ◦д1,s,r )] · dens(д‡

2 ◦ д1, s)(r ) · h(get(д‡

2 ◦ д1, s)(r ), r )

(cid:17)

[consumed(д‡

2 ◦д1,s,r )] · dens(д‡

2 ◦ д1, s)(r ) · 1[get(д1,s)(R1(r1))(cid:44)⊥] · h(get(д‡

2 ◦ д1, s)(r ), r )

(cid:17)

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:49

∫

=

ρ(dr )

(cid:16)1

[consumed(д‡

2 ◦д1,s,r )] · dens(д1, s)(R1(r )) · 1[get(д1,s)(R1(r1))(cid:44)⊥]

· dens(д2, get(д1, s)(R1(r )))(R2(r )) · h(get(д2, get(д1, s)(R1(r )))(R2(r )), R1(r ) ⊎ R2(r ))

(cid:17)

∫

=

∫

ρ(dr1)

ρ(dr2)

(cid:16)1[consumed(д1,s,r1)] · 1[consumed(д2,get(д1,s)(r1),r2)] · 1[r1#r2]

· dens(д1, s)(r1) · 1[get(д1,s)(r1)(cid:44)⊥] · dens(д2, get(д1, s)(r1))(r2)

· h(get(д2, get(д1, s)(r1))(r2), r1 ⊎ r2)

(cid:17)

∫

=

∫

ρ(dr1)

ρ(dr2)

(cid:16)1[r1#r2] · dens(д1, s)(r1) · 1[get(д1,s)(r1)(cid:44)⊥] · dens(д2, get(д1, s)(r1))(r2)

· h(get(д2, get(д1, s)(r1))(r2), r1 ⊎ r2)

(cid:17)

∫

=

(cid:16)

ρ(dr1)

dens(д1, s)(r1) · 1[get(д1,s)(r1)(cid:44)⊥]

∫

·

(cid:16)

ρ(dr2)

dens(д2, get(д1, s)(r1))(r2) · 1[r1#r2] · h

(cid:16)

get(д2, get(д1, s)(r1))(r2), r1 ⊎ r2

(cid:17)(cid:17)(cid:17)

.

□

Theorem 4.9. For all non-negative bounded measurable monotone functions h : ({⊥} ∪ Store) ×

RDB → R and states σ ,
∫

⟦C⟧(σ )(d(σ ′, w ′)) (w ′ ·h(σ ′

s , σ ′

r )) =

∫

(cid:16)

ρ(dr ′)

dens(C, σs )(r ′) · 1[r ′#σr ] ·h(get(C, σs )(r ′), r ′ ⊎ σr )

(cid:17)

.

Proof. We prove the theorem by induction on the structure of C.
When C ≡ skip, we derive the claimed equality as follows:

∫

⟦skip⟧(σ )(d(σ ′, w ′)) (w ′ · h(σ ′

s , σ ′
r ))

= h(σs , σr )

∫

∫

∫

=

=

=

ρ(dr ′)

ρ(dr ′)

ρ(dr ′)

(cid:17)

(cid:16)1[r ′=[]] · 1[[]#σr ] · h(σs , [] ⊎ σr )
(cid:16)1[r ′=[]] · 1[r ′#σr ] · h(σs , r ′ ⊎ σr )
(cid:16)

(cid:17)

dens(skip, σs )(r ′) · 1[r ′#σr ] · h(get(skip, σs )(r ′), r ′ ⊎ σr )

(cid:17)

.

Next we handle the case that C ≡ (x := E).

∫

⟦x := E⟧(σ )(d(σ ′, w ′)) (w ′ · h(σ ′

s , σ ′
r ))

= h(σs [x (cid:55)→ ⟦E⟧σs ], σr )

∫

∫

∫

=

=

=

ρ(dr ′)

ρ(dr ′)

ρ(dr ′)

(cid:16)1[r ′=[]] · 1[[]#σr ] · h(σs [x (cid:55)→ ⟦E⟧σs ], [] ⊎ σr )
(cid:16)1[r ′=[]] · 1[r ′#σr ] · h(σs [x (cid:55)→ ⟦E⟧σs ], r ′ ⊎ σr )
(cid:16)

(cid:17)

(cid:17)

dens(x := E, σs )(r ′) · 1[r ′#σr ] · h(get(x := E, σs )(r ′), r ′ ⊎ σr )

(cid:17)

.

0:50

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

We move on to the case that C ≡ (if B {C0} else {C1}), and prove the desired equality:

∫

⟦if B {C0} else {C1}⟧(σ )(d(σ ′, w ′)) (w ′ · h(σ ′

s , σ ′
r ))

= 1[⟦B⟧σs =true] ·

∫

⟦C0⟧(σ )(d(σ ′, w ′)) (w ′ · h(σ ′
∫

s , σ ′
r ))

+ 1[⟦B⟧σs (cid:44)true] ·

⟦C1⟧(σ )(d(σ ′, w ′)) (w ′ · h(σ ′

s , σ ′
r ))

ρ(dr ′)
∫

= 1[⟦B⟧σs =true] ·

∫

+ 1[⟦B⟧σs (cid:44)true] ·
(cid:16)

∫

=

(cid:16)

dens(C0, σs )(r ′) · 1[r ′#σr ] · h(get(C0, σs )(r ′), r ′ ⊎ σr )

(cid:17)

ρ(dr ′)

(cid:16)

dens(C1, σs )(r ′) · 1[r ′#σr ] · h(get(C1, σs )(r ′), r ′ ⊎ σr )

(cid:17)

ρ(dr ′)

dens(if B {C0} else {C1}, σs )(r ′) · 1[r ′#σr ] · h(get(if B {C0} else {C1}, σs )(r ′), r ′ ⊎ σr )

(cid:17)

.

Now we prove the claimed equality for C ≡ (C0; C1).
∫

⟦C0; C1⟧(σ )(d(σ ′, w ′)) (w ′ · h(σ ′
∫

∫

s , σ ′
r ))

⟦C0⟧(σ )(d(σ ′, w ′))

⟦C1⟧(σ ′)(d(σ ′′, w ′′)) (w ′ · w ′′ · h(σ ′′

s , σ ′′
r ))

=

=

=

=

∫

∫

∫

⟦C0⟧(σ )(d(σ ′, w ′))

⟦C0⟧(σ )(d(σ ′, w ′))

∫

∫

(cid:16)
w ′ ·

(cid:16)
w ′ ·

⟦C1⟧(σ ′)(d(σ ′′, w ′′)) (w ′′ · h(σ ′′

s , σ ′′
r ))

(cid:17)

ρ(dr2) (dens(C1, σ ′

s )(r2) · 1[r2#σ ′

r ] · h(get(C1, σ ′

s )(r2), r2 ⊎ σ ′
r ))

(cid:17)

⟦C0⟧(σ )(d(σ ′, w ′))
∫

(cid:16)
w ′ · 1[σ ′

s (cid:44)⊥] ·

ρ(dr2) (dens(C1, σ ′

s )(r2) · 1[r2#σ ′

r ] · h(get(C1, σ ′

s )(r2), r2 ⊎ σ ′
r ))

(cid:17)

∫

=

(cid:16)

ρ(dr1)

dens(C0, σs )(r1) · 1[r1#σr ]

· 1[get(C0,σs )(r1)(cid:44)⊥] ·

∫

(cid:16)

ρ(dr2)

dens(C1, get(C0, σs )(r1))(r2) · 1[r2#(r1⊎σr )]

· h(get(C1, get(C0, σs )(r1))(r2), r2 ⊎ (r1 ⊎ σr )

(cid:17)(cid:17)

∫

=

(cid:16)

ρ(dr1)

dens(C0, σs )(r1) · 1[get(C0,σs )(r1)(cid:44)⊥]

∫

·

(cid:16)

ρ(dr2)

dens(C1, get(C0, σs )(r1))(r2) · 1[r1#r2] · 1[(r1⊎r2)#σr ]

· h(get(C1, get(C0, σs )(r1))(r2), (r1 ⊎ r2) ⊎ σr )

(cid:17)(cid:17)

∫

=

(cid:16)

ρ(dr )

dens(C0; C1)(r ) · 1[r #σr ] · h

(cid:16)

get(C0; C1)(r ), r ⊎ σr

(cid:17)(cid:17)

.

The third and fifth equalities follow from the induction hypothesis, and the last equality from
Lemma 4.8.

The next case is C ≡ (while B {C0}). Let R ⊆ K × D be the relation defined by
κ [R] д ⇐⇒ for all states σ and non-negative bounded measurable monotone functions h,

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:51

∫

κ(σ )(d(σ ′, w ′)) (w ′ · h(σ ′

s , σ ′
r ))

∫

=

(cid:16)

ρ(dr ′)

dens(д, σs )(r ′) · 1[r ′#σr ] · h

(cid:16)

get(д, σs )(r ′), r ′ ⊎ σr

(cid:17)(cid:17)

.

Note that the least elements from K and D are related by R because they make both sides of the
equality in the definition of R be zero. Furthermore, for all ω-chains {κn }n and {дn }n in K and D,
if κn [R] дn for all n, then

(cid:196)

κn [R]

(cid:196)

дn .

n
This is because for all stores σ and non-negative bounded measurable functions h,

n

∫ (cid:16) (cid:196)

(cid:17)

κn

(σ )(d(σ ′, w ′)) (w ′ · h(σ ′

s , σ ′
r ))

n
∫

= lim
n

κn(σ )(d(σ ′, w ′)) (w ′ · f (σ ′

r ))

∫

ρ(dr ′)

(cid:16)

= lim
n
∫

=

ρ(dr ′) lim
n

∫

=

(cid:16)

ρ(dr ′)

dens

dens(дn, σs )(r ′) · 1[r ′#σr ] · h(get(дn, σs )(r ′), r ′ ⊎ σr )
(cid:16)

dens(дn, σs )(r ′) · 1[r ′#σr ] · h(get(дn, σs )(r ′), r ′ ⊎ σr )
(cid:16) (cid:196)

(cid:16) (cid:196)

(cid:16)

(cid:17)

(cid:17)

дn, σs

(r ′) · 1[r ′#σr ] · h

get

дn, σs

(r ′), r ′ ⊎ σr

(cid:17)(cid:17)

.

(cid:17)

(cid:17)

n

n

The first equation follows from Lemma A.1, and the third from the monotone convergence theorem
and Lemma A.4. The last equality holds because of Lemma A.4 again.

Thus, we can complete the proof of this case if we show one more thing. Let K and G be the
functions on K and D used in the interpretation of the loop (namely, while B {C0}) in the two
semantics. What we have to show is:

Pick κ and д with κ [R] д. Then, for all σ and non-negative bounded measurable h,

κ [R] д =⇒ K(κ) [R] G(д).

∫

(K(κ))(σ )(d(σ ′, w ′)) (w ′ · h(σ ′

s , σ ′
r ))

= 1[⟦B⟧σs (cid:44)true] · h(σs , σr )

+ 1[⟦B⟧σs =true] ·
= 1[⟦B⟧σs (cid:44)true] · h(σs , σr )

∫

⟦C⟧(σ )(d(σ ′, w ′))

∫

κ(σ ′)(d(σ ′′, w ′′)) (w ′ · w ′′ · h(σ ′′

s , σ ′′
r ))

+ 1[⟦B⟧σs =true] ·

∫

⟦C⟧(σ )(d(σ ′, w ′))

∫

(cid:16)
w ′ ·

κ(σ ′)(d(σ ′′, w ′′)) (w ′′ · h(σ ′′

s , σ ′′
r ))

(cid:17)

.

But
∫

=

=

∫

(cid:16)
w ′ ·

⟦C⟧(σ )(d(σ ′, w ′))
∫

⟦C⟧(σ )(d(σ ′, w ′))

(cid:16)
w ′ ·

∫

⟦C⟧(σ )(d(σ ′, w ′))

κ(σ ′)(d(σ ′′, w ′′)) (w ′′ · h(σ ′′
∫

(cid:16)

(cid:17)

s , σ ′′
r ))

ρ(dr ′′)

dens(д, σ ′

s )(r ′′) · 1[r ′′#σ ′

r ] · h(get(д, σ ′

s )(r ′′), r ′′ ⊎ σ ′
r )

(cid:17)(cid:17)

0:52

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

(cid:16)
w ′ · 1[σ ′

s (cid:44)⊥] ·

∫

(cid:16)

ρ(dr ′′)

dens(д, σ ′

s )(r ′′) · 1[r ′′#σ ′

r ] · h(get(д, σ ′

s )(r ′′), r ′′ ⊎ σ ′
r )

(cid:17)(cid:17)

∫

=

(cid:16)

ρ(dr ′)

dens(C, σs )(r ′) · 1[r ′#σr ]
∫

· 1[get(C,σs )(r ′)(cid:44)⊥] ·

ρ(dr ′′)

(cid:16)

dens(д, get(C, σs )(r ′))(r ′′) · 1[r ′′#(r ′⊎σr )]

· h(get(д, get(C, σs ))(r ′′), r ′′ ⊎ (r ′ ⊎ σr ))

(cid:17)(cid:17)

∫

=

(cid:16)

ρ(dr ′)

dens(C, σs )(r ′) ·

∫

(cid:16)

ρ(dr ′′)

dens(д, get(C, σs )(r ′))(r ′′) · 1[r ′#r ′′] · 1[(r ′⊎r ′)#σr ]

· h(get(д, get(C, σs ))(r ′′), (r ′ ⊎ r ′′) ⊎ σr ))

(cid:17)(cid:17)

∫

=

(cid:16)

ρ(dr )

dens(д‡ ◦ ⟦C⟧

d , σs )(r ) · 1[r #σr ] · h(get(д‡ ◦ ⟦C⟧

d , σs )(r ), r ⊎ σr )

(cid:17)

.

The last equality uses Lemma 4.8. Thus, if we continue our calculation that we paused momentarily,
we get

1[⟦B⟧σs (cid:44)true] · h(σs , σr )

+ 1[⟦B⟧σs =true] ·

∫

⟦C⟧(σ )(d(σ ′, w ′))

∫

(cid:16)
w ′ ·

κ(σ ′)(d(σ ′′, w ′′)) (w ′′ · h(σ ′′

s , σ ′′
r ))

(cid:17)

= 1[⟦B⟧σs (cid:44)true] · h(σs , σr )

∫

(cid:16)

ρ(dr )

dens(д‡ ◦ ⟦C⟧

ρ(dr ′)
∫

(cid:16)1[r ′=[]] · 1[[]#σr ] · h(σs , [] ⊎ σr )
(cid:16)

ρ(dr )

dens(д‡ ◦ ⟦C⟧

ρ(dr ′)
∫

(cid:16)1[r ′=[]] · 1[r ′#σr ] · h(σs , r ′ ⊎ σr )
(cid:16)

d , σs )(r ) · 1[r #σr ] · h(get(д‡ ◦ ⟦C⟧
(cid:17)

d , σs )(r ), r ⊎ σr )

d , σs )(r ) · 1[r #σr ] · h(get(д‡ ◦ ⟦C⟧
(cid:17)

d , σs )(r ), r ⊎ σr )

ρ(dr )

dens(д‡ ◦ ⟦C⟧

d , σs )(r ) · 1[r #σr ] · h(get(д‡ ◦ ⟦C⟧

d , σs )(r ), r ⊎ σr )

(cid:17)

(cid:17)

(cid:17)

+ 1[⟦B⟧σs =true] ·
∫

= 1[⟦B⟧σs (cid:44)true] ·

+ 1[⟦B⟧σs =true] ·
∫

= 1[⟦B⟧σs (cid:44)true] ·

+ 1[⟦B⟧σs =true] ·
∫

(cid:16)

=

ρ(dr ′)

dens(G(д), σs )(r ′) · 1[r ′#σr ] · h(get(G(д), σs )(r ′), r ′ ⊎ σr )

(cid:17)

.

Next we handle the case that C ≡ (x := samplenorm(S, E1, E2)).

∫

⟦x := samplenorm(S, E1, E2)⟧(σ )(d(σ ′, w ′)) (w ′ · h(σ ′

s , σ ′
r ))

= 1[⟦S ⟧σs (cid:60)dom(σr )] · 1[⟦E2⟧σs ∈(0,∞)]

∫

·

(cid:16)

dv

N (v; ⟦E1⟧σs , ⟦E2⟧σs ) · h(σs [x (cid:55)→ v], σr [⟦S⟧σs (cid:55)→ v])

(cid:17)

= 1[⟦E2⟧σs ∈(0,∞)]
∫

(cid:16)

·

dv

N (v; ⟦E1⟧σs , ⟦E2⟧σs ) · 1[[⟦S ⟧σs (cid:55)→v]#σr ] · h(σs [x (cid:55)→ v], [⟦S⟧σs (cid:55)→ v] ⊎ σr )

(cid:17)

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:53

= 1[⟦E2⟧σs ∈(0,∞)] ·

∫

ρ(dr ′)

(cid:16)1[dom(r ′)={⟦S ⟧σs }] · N (r ′(⟦S⟧σs ); ⟦E1⟧σs , ⟦E2⟧σs )

· 1[r ′#σr ] · h(σs [x (cid:55)→ r ′(⟦E0⟧σs )], r ′ ⊎ σr )

(cid:17)

∫

=

ρ(dr ′)

(cid:16)1[⟦E2⟧σs ∈(0,∞)] · 1[dom(r ′)={⟦S ⟧σs }] · N (r ′(⟦S⟧σs ); ⟦E1⟧σs , ⟦E2⟧σs )

· 1[r ′#σr ] · h(σs [x (cid:55)→ r ′(⟦E0⟧σs )], r ′ ⊎ σr )

(cid:17)

∫

=

(cid:16)

ρ(dr ′)

dens(x := samplenorm(S, E1, E2), σs )(r ′)

· 1[r ′#σr ] · h(get(x := samplenorm(S, E1, E2), σs )(r ′), r ′ ⊎ σr )

(cid:17)

.

It remains to prove the case that C ≡ scorenorm(E0, E1, E2). Here is our proof for this last case:

∫

⟦scorenorm(E0, E1, E2)⟧(σ )(d(σ ′, w ′)) (w ′ · h(σ ′
s , σ ′
r ))
= 1[⟦E2⟧σs ∈(0,∞)] · N (⟦E0⟧σs ; ⟦E1⟧σs , ⟦E2⟧σs ) · h(σs , σr )

= 1[⟦E2⟧σs ∈(0,∞)] ·

= 1[⟦E2⟧σs ∈(0,∞)] ·

∫

∫

ρ(dr ′)

ρ(dr ′)

(cid:16)1[r ′=[]] · N (⟦E0⟧σs ; ⟦E1⟧σs , ⟦E2⟧σs ) · 1[[]#σr ] · h(σs , [] ⊎ σr )
(cid:16)1[r ′=[]] · N (⟦E0⟧σs ; ⟦E1⟧σs , ⟦E2⟧σs ) · 1[r ′#σr ] · h(σs , r ′ ⊎ σr )

(cid:17)

(cid:17)

∫

=

(cid:16)

ρ(dr ′)

dens(scorenorm(E0, E1, E2), σs )(r ′)

· 1[r ′#σr ] · h(get(scorenorm(E0, E1, E2), σs )(r ′), r ′ ⊎ σr )

(cid:17)

.

□

B PROOF OF THEOREM IN §5

Theorem 5.1. Let C be a model, Dθ be a guide, and N (cid:44) 0 ∈ N. Define KL(−) : Rp → R≥0 as KLθ
≜ KL(dens(Dθ , sI )||dens(C, sI )/ZC ). Then, KL(−) is well-defined and continuously differentiable with

∇θ KLθ = E(cid:206)

i dens(Dθ ,sI )(ri )

(cid:34) 1
N

N
(cid:213)

(cid:16)

i=1

∇θ log dens(Dθ , sI )(ri )

(cid:17) log dens(Dθ , sI )(ri )
dens(C, sI )(ri )

(cid:35)

(6)

if
(R1) dens(C, sI )(r ) = 0 =⇒ dens(Dθ , sI )(r ) = 0, for all r ∈ RDB and θ ∈ Rp ;
(R2) for all (r , θ, j) ∈ RDB × Rp × [p], the function v (cid:55)−→ dens(Dθ [j:v], sI )(r ) on R is differentiable;
(R3) for all θ ∈ Rp ,

∫

(cid:18)

ρ(dr )

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:19)

< ∞;

(R4) for all (θ, j) ∈ Rp × [p], the function

∫

(cid:18)

ρ(dr )

v (cid:55)−→

dens(Dθ [j:v], sI )(r ) · log

dens(Dθ [j:v], sI )(r )
dens(C, sI )(r )

(cid:19)

on R is continuously differentiable;

0:54

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

(cid:18)

(R5) for all θ ∈ Rp ,

∫

∇θ

ρ(dr )

=

(R6) for all θ ∈ Rp ,

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )
∫

(cid:18)

(cid:19)

ρ(dr ) ∇θ

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:19)

;

∫

ρ(dr ) ∇θ dens(Dθ , sI )(r ) = ∇θ

∫

ρ(dr ) dens(Dθ , sI )(r ).

As we explained in the main text already, the theorem (except the continuous differentiability of
KLθ ) is well-known with a well-known proof. We include its proof for completeness and also to
help the reader to see why each of the requirements in the theorem is needed.

Proof. KLθ is well-defined because of the following derivation with R1 and R3:

KLθ = KL

(cid:18)

(cid:12)
(cid:12)
dens(Dθ , sI )
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:19)

dens(C, sI )
ZC

∫

∫

=

=

(cid:18)

(cid:18)

ρ(dr )

ρ(dr )

dens(Dθ , sI )(r ) · log

dens(Dθ , sI )(r ) ·

(cid:18)

(cid:19)(cid:19)

(cid:18) dens(Dθ , sI )(r )
dens(C, sI )(r )/ZC
log ZC + log dens(Dθ , sI )(r )
dens(C, sI )(r )
(cid:19)
dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:19)(cid:19)

.

= log ZC +

∫

(cid:18)

ρ(dr )

It remains to show the continuous differentiability of KLθ and Equation (6). Recall the fact
that for any function f : RN → RM , if all partial derivatives of f exist and are continuous, f is
continuously differentiable. Because of the fact and the linearity of expectation, it suffices to show
that all partial derivatives of KLθ are well-defined and continuous, and

∇θ KLθ = Edens(Dθ ,sI )(r )

(cid:20)(cid:16)

∇θ log dens(Dθ , sI )(r )

(cid:17) log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:21)

.

Here is a well-known derivation of (13):

∇θ KLθ

(cid:18)

= ∇θ

log ZC +

∫

(cid:18)

ρ(dr )

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:19)(cid:19)

∫

= ∇θ

ρ(dr )

(cid:19)

(cid:18)

(cid:18)

(cid:19)

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )
dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )
· log dens(Dθ , sI )(r )
dens(C, sI )(r )
· log dens(Dθ , sI )(r )
dens(C, sI )(r )
(cid:17)

(cid:17)

(cid:16)

(cid:17)

∇θ log dens(Dθ , sI )(r )

∇θ dens(Dθ , sI )(r )

∇θ dens(Dθ , sI )(r )

dens(Dθ , sI )(r ) ·

ρ(dr ) ∇θ

(cid:18) (cid:16)

(cid:18) (cid:16)

ρ(dr )

ρ(dr )

(cid:18)

ρ(dr )

∫

∫

∫

∫

=

=

=

=

(cid:19)

(cid:19)

∫

+

ρ(dr ) ∇θ dens(Dθ , sI )(r )

∫

+ ∇θ

ρ(dr ) dens(Dθ , sI )(r )

(16)

· log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:19)

+ ∇θ 1

(13)

(14)

(15)

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:55

= Edens(Dθ ,sI )(r )

(cid:20)(cid:16)

∇θ log dens(Dθ , sI )(r )

(cid:17)

· log dens(Dθ , sI )(r )
dens(C, sI )(r )

(cid:21)

.

The well-definedness and the continuity of (∇θ KLθ )j for all j ∈ [p] follow from (14) and R4, which
concludes the proof.

Note that R2 is used to guarantee the well-definedness of ∇θ log dens(Dθ , sI )(r ) in (13); R5 and
□

R6 are used in (15) and (16), respectively.

C PROOFS OF EXAMPLES, LEMMA, AND THEOREMS IN §6

Theorem 6.1. Under our assumption in §6.1,

Edens(Dθ ,sI )(r ) [| log dens(Dθ , sI )(r )|] < ∞.

Proof. For i ∈ [M] and r ∈ Ai , define
д(i,θ )(r ) ≜ (cid:214)

α ∈Ki

Then,

N (r (α); µ(i,α )(θ ), σ(i,α )(θ )).

Edens(Dθ ,sI )(r ) [| log dens(Dθ , sI )(r )|]
(cid:32)

∫

=

ρ(dr )

(cid:16) M
(cid:213)

i=1

1[r ∈Ai ] · д(i,θ )(r )

∫

=

ρ(dr )

(cid:32) M
(cid:213)

i=1

1[r ∈Ai ] · д(i,θ )(r ) ·

(cid:33)

(cid:0)1[r ∈Ai ] · д(i,θ )(r )(cid:1)(cid:12)
(cid:12)
(cid:12)
(cid:33)

(cid:17)

(cid:12)
(cid:12)
(cid:12)

·

log

M
(cid:213)

i=1

log д(i,θ )(r )

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

ρ(dr )

(cid:16)1[r ∈Ai ] · д(i,θ )(r ) ·

log д(i,θ )(r )

(cid:17)

(cid:12)
(cid:12)
(cid:12)

∫

ρ(dr )

(cid:16)1[r ∈[Ki →R]] · д(i,θ )(r ) ·

(cid:12)
(cid:12)
(cid:12)

log д(i,θ )(r )

(cid:17)

(cid:12)
(cid:12)
(cid:12)

Eд(i,θ )(r )

(cid:2)| log д(i,θ )(r )|(cid:3)

M
(cid:213)

∫

=

≤

=

i=1
M
(cid:213)

i=1
M
(cid:213)

i=1
< ∞.

The last inequality uses a well-known result that the differential entropy of any multivariate normal
□
distribution is finite.

Example 6.2. Consider guides D(i,θ ) defined as follows (i = 1, 2):

D(i,θ ) ≡ (x1 := samplenorm(“a1”, θ1, 1); x2 := samplenorm(“a2”, θ2, Ei [x1]))

where for some n ≥ 1 and c (cid:44) 0 ∈ R,

E1[x1] ≡ if (x1=0) then 1 else exp(−1/|x1|n),

E2[x1] ≡ exp(exp(c · x

3
1)).

Then, the entropies of dens(D(i,θ ), sI )’s are all undefined.

Proof. We prove that

Edens(D(i,θ ),sI )(r )[| log dens(D(i,θ ), sI )(r )|] = ∞ for all i = 1, 2

0:56

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

by bounding the the expectation as follows.

Edens(D(i, θ ),sI )(r )[| log dens(D(i,θ ), sI )(r )|]

= EN(x1;θ1,1)·N(x2;θ2, Ei [x1]) [| log N (x1; θ1, 1) + log N (x2; θ2, Ei [x1])|]
≥ −EN(x1;θ1,1)·N(x2;θ2, Ei [x1]) [| log N (x1; θ1, 1)|]

+ EN(x1;θ1,1)·N(x2;θ2, Ei [x1]) [| log N (x2; θ2, Ei [x1])|]

Here the two terms in the last equation are bounded as follows.

−EN(x1;θ1,1)·N(x2;θ2, Ei [x1]) [| log N (x1; θ1, 1)|]
(cid:12)
(cid:21)
(cid:12)
(cid:12)
(cid:12)

= −EN(x1;θ1,1)

(x1 − θ1)2

2π −

√

1
2
1
2

(cid:20)(cid:12)
(cid:12)
log
(cid:12)
(cid:12)
(cid:104)log
1
2

√

(cid:105)

2π

−

EN(x1;θ1,1)

(cid:2)(x1 − θ1)2(cid:3)

≥ −EN(x1;θ1,1)

√

2π −

= − log

· 12
EN(x1;θ1,1)·N(x2;θ2, Ei [x1]) [| log N (x2; θ2, Ei [x1])|]

= EN(x1;θ1,1)·N(x2;θ2, Ei [x1])

(cid:20)(cid:12)
(cid:12)
− log
(cid:12)
(cid:12)

√

2π −

≥ −EN(x1;θ1,1)

(cid:104)log

√

(cid:105)

2π

−

1
2

EN(x1;θ1,1)

(cid:20)

(cid:21)

(x2 − θ2)2
2Ei [x1]2 − log Ei [x1]
EN(x2;θ2, Ei [x1])
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:123)(cid:122)
(cid:124)
Ei [x1]2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:2)(x2 − θ2)2(cid:3)
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:125)

(cid:21)

·

1
Ei [x1]2

+ EN(x1;θ1,1) [| log Ei [x1]|]

= − log

√

2π −

1
2

+ EN(x1;θ1,1) [| log Ei [x1]|]

Note that

EN(x1;θ1,1) [| log Ei [x1]|] =

(cid:26) EN(x1;θ1,1)[1[x1(cid:44)0] · 1/|x1|n]

EN(x1;θ1,1)[exp(c · x 3
1)]

(cid:27)

for i = 1
for i = 2

= ∞

because ∫
and σ ∈ R>0. Hence, we obtain the desired result.

1/vn dv = ∞ for any ϵ > 0 and n ≥ 1, and EN(v;µ,σ )[exp(c · v3)] = ∞ for any µ ∈ R
□

[0,ϵ ]

Theorem 6.3. Under our assumption in §6.1, the condition (9) implies

Edens(Dθ ,sI )(r ) [| log dens(C, sI )(r )|] < ∞,
and thus the requirement R3 (i.e., the objective in (5) is well-defined).

Proof. For i ∈ [M], j ∈ [Ni ], α ∈ Ki , and r ∈ Ai , let
N (r (β); µ(i, β )(θ ), σ(i, β )(θ )),

д(i,θ )(r ) ≜ (cid:214)

β ∈Ki

h(i,α )(r ) ≜ N (r (α); µ ′

(i,α )(r ), σ ′

(i,α )(r )),

k(i, j)(r ) ≜ N (c(i, j); µ ′′

(i, j)(r ), σ ′′

(i, j)(r )).

We note that

Eд(i,θ )(r )

(cid:12)log h(i,α )(r )(cid:12)
(cid:2)(cid:12)
(cid:12)

(cid:3) = Eд(i, θ )(r )

√

− log

2π − log σ ′

(i,α )(r ) −

(cid:12)
(cid:12)

(cid:12)

(cid:12)

(cid:12)

(cid:12)

(cid:12)



(cid:16)
r (α) − µ ′
2 (cid:16)

(i,α )(r )
(cid:17) 2

σ ′
(i,α )(r )

(cid:17) 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)









Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:57

√

≤ log

2π + Eд(i,θ )(r )

(cid:104)(cid:12)
log σ ′
(cid:12)
(cid:12)

(i,α )(r )

(cid:105) + Eд(i, θ )(r )

(cid:12)
(cid:12)
(cid:12)

Thus, we can have

if the following two inequalities hold:

Eд(i,θ )(r )

(cid:12)log h(i,α )(r )(cid:12)
(cid:2)(cid:12)
(cid:12)

(cid:3) < ∞









(cid:16)
r (α) − µ ′
2 (cid:16)

(i,α )(r )
(cid:17) 2

σ ′
(i,α )(r )

(cid:17) 2

.









(17)

Eд(i,θ )(r )

(cid:104)(cid:12)
log σ ′
(cid:12)
(cid:12)

(i,α )(r )

(cid:105)

(cid:12)
(cid:12)
(cid:12)

< ∞ and

Eд(i,θ )(r )

< ∞.

(18)

(cid:16)
r (α) − µ ′

(cid:17) 2

(i,α )(r )
(cid:17) 2

(cid:16)
σ ′
(i,α )(r )

















We show that the inequalities are indeed true. By the condition (9) and the parts (a) and (b) of
Lemma 6.6 (full version), there exist functions fi , ui ∈ Ai such that for every r ∈ Ai ,

(cid:12)
log σ ′
(cid:12)
(cid:12)

(i,α )(r )

(cid:12)
(cid:12)
(cid:12)

≤ exp(fi (r ))

and

(cid:16)
r (α) − µ ′

(i,α )(r )
(cid:17) 2

(cid:16)
σ ′
(i,α )(r )

(cid:17) 2

≤ exp(ui (r )).

For every f ∈ Ai , by the part (e) of Lemma 6.6 (full version), we have that

Eд(i,θ )(r ) [exp(f (r ))] < ∞.

The inequalities in (18) follow from the properties in (19) and (20).

By an argument similar to what we have just given, we also have that

Using (17) and (21), we calculate the claim of the theorem:

Eд(i,θ )(r )

(cid:12)log k(i, j)(r )(cid:12)
(cid:2)(cid:12)
(cid:12)

(cid:3) < ∞.

Edens(Dθ ,sI )(r ) [|log dens(C, sI )(r )|]
(cid:32) M
(cid:213)

∫

1[r ∈Ai ] · д(i,θ )(r )

=

ρ(dr ) (cid:169)
(cid:173)
(cid:171)

i=1

∫

=

M
(cid:213)
ρ(dr ) (cid:169)
(cid:173)
(cid:171)

i=1

1[r ∈Ai ] · д(i,θ )(r ) ·

(cid:33)

·

(cid:12)
(cid:12)
(cid:12)
log
(cid:12)
(cid:12)
(cid:12)

M
(cid:213)

i=1

(cid:16)1[r ∈Ai ] ·

(cid:214)

β ∈Ki

h(i, β )(r ) ·

(cid:214)

k(i, j)(r )

h(i, β )(r ) ·

(cid:214)

(cid:17)

k(i, j)(r )

j ∈[Ni ]

log h(i, β )(r ) + (cid:213)

log k(i, j)(r )

1[r ∈Ai ] · д(i,θ )(r ) ·
ρ(dr ) (cid:169)
(cid:173)
(cid:171)
ρ(dr ) (cid:0)1[r ∈Ai ] · д(i,θ )(r ) · (cid:12)

∫

j ∈[Ni ]

(cid:1)

(cid:12)log h(i, β )(r )(cid:12)
(cid:12)

(cid:12)
(cid:12)
log (cid:16) (cid:214)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
β ∈Ki
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

β ∈Ki

(cid:213)

j ∈[Ni ]
(cid:12)
(cid:12)
(cid:12)
(cid:170)
(cid:12)
(cid:174)
(cid:12)
(cid:12)
(cid:172)

(cid:12)
(cid:12)
(cid:12)
(cid:170)
(cid:12)
(cid:174)
(cid:12)
(cid:12)
(cid:172)

M
(cid:213)

(cid:213)

∫

+

ρ(dr ) (cid:0)1[r ∈Ai ] · д(i,θ )(r ) · (cid:12)

(cid:12)log k(i, j)(r )(cid:12)
(cid:12)

(cid:1)

j ∈[Ni ]
∫

ρ(dr ) (cid:0)1[r ∈[Ki →R]] · д(i,θ )(r ) · (cid:12)

(cid:12)log h(i, β )(r )(cid:12)
(cid:12)

(cid:1)

M
(cid:213)

∫

=

i=1

M
(cid:213)

i=1

≤

(cid:213)

β ∈Ki

i=1

≤

M
(cid:213)

(cid:213)

i=1

β ∈Ki

(19)

(20)

(21)

(cid:17)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:170)
(cid:174)
(cid:172)

0:58

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

M
(cid:213)

(cid:213)

∫

+

i=1

j ∈[Ni ]

ρ(dr ) (cid:0)1[r ∈[Ki →R]] · д(i,θ )(r ) · (cid:12)

(cid:12)log k(i, j)(r )(cid:12)
(cid:12)

(cid:1)

M
(cid:213)

(cid:213)

=

β ∈Ki

i=1
< ∞.

Eд(i,θ )(r )

(cid:12)log h(i, β )(r )(cid:12)
(cid:2)(cid:12)
(cid:12)

(cid:3) +

M
(cid:213)

(cid:213)

i=1

j ∈[Ni ]

Eд(i, θ )(r )

(cid:12)log k(i, j)(r )(cid:12)
(cid:2)(cid:12)
(cid:12)

(cid:3)

The last inequality follows from (17) and (21). Finally, the requirement R3 follows from the above
and Theorem 6.1:

∫

ρ(dr )

(cid:12)
dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
(cid:12)
(cid:12)
dens(C, sI )(r )
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ Edens(Dθ ,sI )(r )
< ∞.

(cid:12) log dens(Dθ , sI )(r )(cid:12)
(cid:2)(cid:12)
(cid:12)

(cid:3) + Edens(Dθ ,sI )(r )

(cid:12) log dens(C, sI )(r )(cid:12)
(cid:2)(cid:12)
(cid:12)

(cid:3)

□

Example 6.4. Consider models C1, . . . , C4 and a guide Dθ defined as follows:
Ci ≡ (x1 := samplenorm(“a1”, 0, 1); x2 := samplenorm(“a2”, Ei [x1], 1))
Ci ≡ (x1 := samplenorm(“a1”, 0, 1); x2 := samplenorm(“a2”, 0, Ei [x1]))
Dθ ≡ (x1 := samplenorm(“a1”, θ1, 1); x2 := samplenorm(“a2”, θ2, 1))

for i = 1, 2
for i = 3, 4

where for some n ≥ 1 and c (cid:44) 0 ∈ R,

E1[x1] ≡ if (x1=0) then 0 else 1/x n
1 ,
E3[x1] ≡ if (x1=0) then 1 else |x1|n .

E2[x1] ≡ E4[x1] ≡ exp(c · x

3
1),

Then, the requirement R3 does not hold (i.e., the objective in (5) is undefined) for all i = 1, . . . , 4.

Proof. Since we have

∫

ρ(dr )

(cid:12)
(cid:12)
(cid:12)
(cid:12)

dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(Ci , sI )(r )

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≥ −Edens(Dθ ,sI )(r )[| log dens(Dθ , sI )(r )|]

+ Edens(Dθ ,sI )(r )[| log dens(Ci , sI )(r )|]

Edens(Dθ ,sI )(r )[| log dens(Dθ , sI )(r )|] < ∞,

it suffices to show that

Edens(Dθ ,sI )(r )[| log dens(Ci , sI )(r )|] = ∞ for all i = 1, . . . , 4.

(22)

Case of i = 1, 2: The quantity in (22) is bounded as follows.
Edens(Dθ ,sI )(r )[| log dens(Ci , sI )(r )|]

= EN(x1;θ1,1)·N(x2;θ2,1) [| log N (x1; 0, 1) + log N (x2; Ei [x1], 1)|]
≥ −EN(x1;θ1,1)·N(x2;θ2,1) [| log N (x1; 0, 1)|]

+ EN(x1;θ1,1)·N(x2;θ2,1) [| log N (x2; Ei [x1], 1)|]

Here the two terms in the last equation are bounded as follows.

− EN(x1;θ1,1)·N(x2;θ2,1) [| log N (x1; 0, 1)|]

= −EN(x1;θ,1)

log

√

2π −

(cid:20)(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
2x

2
1

(cid:21)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:59

√

(cid:105)

2π

−

1
2

EN(x1;θ,1)

(cid:3)

(cid:2)x

2
1

≥ −EN(x1;θ,1)

√

= − log

2π −

(1 + θ

2)

(cid:104)log
1
2

EN(x1;θ1,1)·N(x2;θ2,1) [| log N (x2; Ei [x1], 1)|]
1
2

= EN(x1;θ1,1)·N(x2;θ2,1)
√

2π −

− log

(cid:20)(cid:12)
(cid:12)
(cid:12)
(cid:12)

√

≥ −EN(x1;θ1,1)

(cid:105) +

2π

EN(x1;θ1,1)·N(x2;θ2,1)

(cid:2)(cid:12)
(cid:12)x

(x2 − Ei [x1])2

(cid:21)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
2 − 2x2 · Ei [x1] + Ei [x1]2(cid:12)
(cid:12)

2

(cid:3)

√

√

≥ − log

≥ − log

2π −

EN(x2;θ2,1)

(cid:3) +

2
2

1
2

EN(x1;θ1,1)·N(x2;θ2,1)

(cid:12)Ei [x1]2 − 2x2 · Ei [x1](cid:12)
(cid:2)(cid:12)
(cid:12)

(cid:3)

2π −

(1 + θ

2
2 ) +

EN(x1;θ1,1)·N(x2;θ2,1)

(cid:12)Ei [x1]2 − 2x2 · Ei [x1](cid:12)
(cid:2)(cid:12)
(cid:12)

(cid:3)

(cid:104)log
1
2
1
2

1
2
(cid:2)x
1
2

We bound the last term in the last equation as follows, assuming c > 0.
(cid:12)Ei [x1]2 − 2x2 · Ei [x1](cid:12)
(cid:2)(cid:12)
(cid:12)
(cid:2)1[x1 ≥0∧x2 ≤0] · (cid:12)

≥ EN(x1;θ1,1)·N(x2;θ2,1)

EN(x1;θ1,1)·N(x2;θ2,1)

(cid:3)

(cid:12)Ei [x1]2 + (−2x2)
(cid:32)
(cid:32)
(cid:123)(cid:122)
(cid:125)
(cid:124)
≥0

(cid:3)

(cid:12)
(cid:12)

· Ei [x1]
(cid:124)(cid:123)(cid:122)(cid:125)
≥0

≥ EN(x1;θ1,1)·N(x2;θ2,1)
≥ EN(x1;θ1,1)

(cid:2)1[x1 ≥0] · Ei [x1]2(cid:3) · EN(x2;θ2,1)

(cid:2)1[x2 ≤0]

(cid:3)

(cid:2)1[x1 ≥0∧x2 ≤0] · (cid:0)Ei [x1]2 + (−2x2) · Ei [x1](cid:1)(cid:3)

+ EN(x1;θ1,1)

(cid:2)1[x1 ≥0] · Ei [x1](cid:3) · EN(x2;θ2,1)

(cid:2)1[x2 ≤0] · (−2x2)(cid:3)

≥ ∞

for all i = 1, 2

Here the last inequality comes from that the two expectations over x2 are finite while the other two
over x1 are both ∞, because ∫
1/vn dv = ∞ for any ϵ > 0 and n ≥ 1, and EN(v;µ,σ )[exp(c ·v3)] =
∞ for any µ ∈ R and σ ∈ R>0. Note that we can use a similar calculation for the case of c < 0. This
proves the equality in (22).

[0,ϵ ]

Case of i = 3, 4: The proof is similar to the above case, so we omit it. Remark that in the proof,
□

we additionally use the following fact: ∫

| log v | dv < ∞.

[0,1]

Lemma 6.6 (Full Version). Pick i ∈ [M]. Let (α1, . . . , α J ) be an enumeration of the elements in Ki ,

and r ≜ (r (α1), . . . , r (α J )) ∈ RJ for r ∈ Ai .

(a) For every l1, l2 ∈ Ai and every ⊙ ∈ {+, −, ×, /, max}, there exists l ∈ Ai such that

exp(l1(r )) ⊙ exp(l2(r )) ≤ exp(l(r )) for all r ∈ Ai .

(b) For every polynomial poly : RJ → R, there exists l ∈ Ai such that

|poly(r )| ≤ exp(l(r )) for all r ∈ Ai .
In particular, for every l ∈ Ai , there exists l ′ ∈ Ai such that
|l(r )| ≤ exp(l ′(r )) for all r ∈ Ai .

(c) For every affine-bounded neural network nn : RJ → R, there exists l ∈ Ai such that

(d) There exist affine functions l1, l2 : R → R such that

|nn(r )| ≤ l(r ) for all r ∈ Ai .

exp(l1(|v |)) ≤ softplus(v) ≤ exp(l2(|v |)) for all v ∈ R.

0:60

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

(e) For every l ∈ Ai and every J -dimensional normal distribution q,

Eq(r (α1), ...,r (α J )) [exp(l(r ))] < ∞.

Proof of (a). We split the cases.
• Case ⊙ ∈ {×, /}: Take l = l1 ± l2.
• Case ⊙ = max: For m = 1, 2, let

lm(r ) = cm,0 +

J
(cid:213)

j=1

cm, j · |r (αj )|

where cm, j ∈ R. For all r ∈ Ai , we have

max(l1(r ), l2(r )) ≤ max (cid:16)

c1,0 +

J
(cid:213)

j=1

|c1, j | · |r (αj )|, c2,0 +

|c2, j | · |r (αj )|

(cid:17)

≤ l(r ),

J
(cid:213)

j=1

where

l(r ) ≜ max(c1,0, c2,0) +

J
(cid:213)

j=1

max(|c1, j |, |c2, j |) · |r (αj )| ∈ Ai .

Hence, for every r ∈ Ai ,

max(exp(l1(r )), exp(l2(r ))) = exp(max(l1(r ), l2(r ))) ≤ exp(l(r )).

• Case ⊙ ∈ {+, −}: Using the case ⊙ = max, we have the following for some l ∈ Ai :

exp(l1(r )) + exp(l2(r )) ≤ 2 · max(exp(l1(r )), exp(l2(r )))

≤ exp(log 2) · exp(l(r ))
= exp(l(r ) + log 2).

Proof of (b). Let n be an index in {1, . . . , J } such that

poly(r (α1), . . . , r (α J )) = poly ′(r (α1), . . . , r (αn))

for some polynomial poly ′ : Rn → R. We show that there exists l ∈ Ai satisfying

poly ′(r (α1), . . . , r (αn)) ≤ exp(l(r )).

Note that the claim of the lemma follows from this. Our proof is by induction on n.

• Case n = 1: Let v ∈ R and poly ′(v) = (cid:205)D

d =0 cd · vd where cd ∈ R. We use the following fact.

Fact: For every d ∈ N, there exists an affine function ld : R → R such that

|v |d ≤ exp(ld (|v |)) for all v ∈ R.

Proof. Since vd = O(exp(v)) for positive v ∈ R, there exist C1, C2 > 0 such that |v | > C1
implies |v |d < C2 exp(|v |). Since |v |d is continuous, C3 ≜ sup{|v |d |
|v | ≤ C1} satisfies
0 ≤ C3 < ∞. Putting these together, for every v ∈ R,

|v |d ≤ max(C2 exp(|v |), C3)

≤ max(max(C2, 1) · exp(|v |), C3 + 1)
≤ C4 exp(|v |),

where C4 ≜ max(C2, 1) · (C3 + 1) ≥ 1. Thus, ld (v) ≜ (v + log C4) is a desired affine
□
function.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:61

Using the fact, we have

|poly ′(r (α1))| ≤

≤

D
(cid:213)

d =0
D
(cid:213)

d =0

|cd | · |r (α1)|d

|cd | · exp(ld (|r (α1)|)) =

D
(cid:213)

d =0,cd (cid:44)0

exp(l ′

d (r ))

≤ exp(l(r ))

for some l ′

d , l ∈ Ai . The existence of l satisfying the last inequality follows from (a).

• Case n > 1: Let v ∈ Rn, and define v1:n−1 to be the projection of v to its first n − 1 components.

Also, let

poly ′(v) =

D
(cid:213)

d =0

poly ′

d (v1:n−1) · vd

n

where poly ′
d

: Rn−1 → R is a polynomial. Using the induction hypothesis, we have

|poly ′(r (α1), . . . , r (αn))| ≤

≤

D
(cid:213)

d =0
D
(cid:213)

d =0

|poly ′

d (r (α1), . . . , r (αn − 1))| · |r (αn)|d

exp(l ′

d (r )) · exp(ld (|r (αn)|)) =

D
(cid:213)

d =0

exp(l ′′

d (r ))

≤ exp(l(r ))

for some affine functions ld : R → R, and functions l ′
from (a).

d , l ′′

d , l ∈ Ai . The last inequality follows

Proof of (c). By the definition of affine-bounded neural network, there exist functions
f2 : Rn2 → Rn3,

f1 : Rn1 → Rn2,

fd : Rnd → Rnd +1

. . . ,

and affine functions

such that (i) n1 = J and nd +1 = 1; (ii) nn = fd ◦ · · · ◦ f1; and (iii) for all 1 ≤ j ≤ d and v ∈ Rnj ,

l ′
j

: Rnj → R for all 1 ≤ j ≤ d

nj+1
(cid:213)

k =1

| fj (v)k | ≤ l ′

j (|v1|, . . . , |vnj |).

We prove the claim of the lemma by induction on the depth d. For d = 1, the claim follows
immediately from the defining property (iii) of the affine-bounded neural network nn. Assume
: RJ → R such that for all
d > 1. By induction hypothesis, there exist affine functions l1, . . . , lnd
k ∈ {1, . . . , nd } and v ∈ RJ ,

|(fd −1 ◦ · · · ◦ f1)(v)k | ≤ lk (|v1|, . . . , |v J |)
This is because the (fd −1 ◦ · · · ◦ f1)(v)k are affine-bounded neural networks of depth d − 1. Let

l ′
d (v1, . . . , vnd ) = c0 +

nd(cid:213)

k =1

ck · |vk |.

Using what we have proved so far, we calculate:
|nn(v)| = (cid:12)
(cid:12)fd
≤ l ′
d

(cid:0)(fd −1 ◦ · · · ◦ f1)(v)(cid:1)(cid:12)
(cid:12)
(cid:0)|(fd −1 ◦ · · · ◦ f1)(v)1|, . . . , |(fd −1 ◦ · · · ◦ f1)(v)nd |(cid:1)

0:62

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

= c0 +

≤ c0 +

≤ c0 +

nd(cid:213)

k =1
nd(cid:213)

k =1
nd(cid:213)

k =1

ck · |(fd −1 ◦ · · · ◦ f1)(v)k |

|ck | · |(fd −1 ◦ · · · ◦ f1)(v)k |

|ck | · lk

(cid:0)|v1|, . . . , |v J |(cid:1).

Let l(r ) = c0 + (cid:205)nd
k =1 |ck | · lk (|r (α1)|, . . . , |r (α J )|). The function l is essentially the composition of
two affine functions, and so it belongs to Ai . This and the conclusion of the above calculation show
that l is the function in Ai that we look for.
Proof of (d). Since log(1 + v) ≥ v/2 for all v ∈ [0, 1], we have
log(1 + exp(v)) ≥ exp(v)/2 = exp(−|v | − log 2)
log(1 + exp(v)) ≤ log(2 · exp(v)) = |v | + log 2

for all v ∈ (−∞, 0],
for all v ∈ [0, ∞).
Let l1(v) = −v − log 2 and l2(v) = v + log 2. As softplus(−) is increasing, we have
exp(l1(|v |)) ≤ softplus(v) ≤ exp(l2(|v |))

for all v ∈ R.

and

Proof of (e). Let l(r ) = c0 + (cid:205)J
j=1 cj · |r (αj )|, where cj ∈ R. The moment generating function
Gp : RJ → R of a random variable of density p(v) on RJ is defined by Gp (t) ≜ Ep(v) [exp(t · v)]
where t · v is the inner product of t and v. It is well-known that the moment generating functions
are well defined for multivariate normal distributions q(v) on RJ in the lemma, i.e., Gq(t) < ∞ for
all t ∈ RJ . From this fact and that exp(|v |) ≤ exp(v) + exp(−v), it follows that

Eq(r (α1), ...,r (α J )) [exp(l(r ))] = exp(c0) · Eq(r (α1), ...,r (α J ))

exp

(cid:34)

(cid:33)(cid:35)

cj · |r (αj )|

(cid:32) J
(cid:213)

j=1

≤ exp(c0) ·

(cid:213)

(cid:16)

Gq

(−1)k1c1, . . . , (−1)k J c J

(cid:17)

k1, ...,k J ∈ {0,1}

< ∞.

□

The proof of Theorem 6.7 uses two more ingredients: Theorem C.1 which, compared to Theo-
rem 6.8, additionally guarantees the continuity of ∇v
fv dµ by assuming the continuity of ∇v fv ;
and Lemma C.2 which bounds the densities of multiple normal distributions using the density of
a single, fixed normal distribution.

∫

Theorem C.1. Let V ⊂ R be an open interval, and (X , Σ, µ) be a measure space. Suppose that a

measurable function f : V × X → R satisfies the following conditions:

(a) The function v ∈ V (cid:55)−→ ∫
(b) For almost all x ∈ X (w.r.t. µ), the function v ∈ V (cid:55)−→ ∇v fv (x) ∈ R is well-defined, continuous.
(c) There is a measurable function h : X → R such that
µ(dx) h(x) is well-defined and |∇v fv (x)| ≤
h(x) for all v ∈ V and almost all x ∈ X (w.r.t. µ).

µ(dx) fv (x) ∈ R is well-defined.

∫

Then, for all v ∈ V , both sides of the below equation are well-defined, and the equality holds:

Moreover, the function v ∈ V (cid:55)−→ ∇v

µ(dx) fv (x) is continuous.

∫

∇v

µ(dx) fv (x) =
∫

∫

µ(dx) ∇v fv (x).

(23)

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:63

Proof. Theorem 6.8 implies the former part of the conclusion: for all v ∈ V , each side of (23)
is well-defined and the equation (23) holds. To prove the latter part of the conclusion, define
G : V → R and д : V × X → R by

∫

G(v) ≜ ∇v

µ(dx) fv (x) =

∫

µ(dx) д(v, x),

д(v, x) ≜ ∇v fv (x),

and let (vn)n ∈N be any sequence in V such that limn→∞ vn = v∗ ∈ V . Then, it suffices to show that

lim
n→∞

G(vn) = G(v∗).

To apply the dominated convergence theorem, define дn, д∗ : X → R by дn(x) ≜ д(vn, x) and
д∗(x) ≜ д(v∗, x). By (b), the function д(·, x) : V → R is continuous for almost all x ∈ X (w.r.t. µ), so

lim
n→∞

дn(x) = lim
n→∞

д(vn, x) = д(v∗, x) = д∗(x)

for almost all x ∈ X (w.r.t. µ).

By (c), for all n ∈ N, |дn(x)| ≤ h(x) for almost all x ∈ X (w.r.t. µ), and h(x) is integrable (w.r.t. µ).
Therefore, we can apply the dominated convergence theorem to (дn)n ∈N and д∗ with h, which gives:

lim
n→∞

G(vn) = lim
n→∞

∫

µ(dx) дn(x) =

∫

µ(dx) д∗(x) = G(v∗).

□

Lemma C.2. Suppose [µ1, µ2] ⊂ R and [σ1, σ2] ⊂ (0, ∞) Then, there exists c ∈ R such that

for all v ∈ R, µ ∈ [µ1, µ2], and σ ∈ [σ1, σ2].

N (v; µ, σ ) ≤ c · N (v; 0, 2σ2)

Proof. We claim that c = 2σ2
σ1
the claim we need show is that

exp( 1
6σ 2
1

max(µ2

1, µ2

2)) is the desired coefficient. For the constant c,

1
2πσ1
for any v ∈ R, µ ∈ [µ1, µ2], and σ ∈ [σ1, σ2]. Since

(v − µ)2
2σ 2

1
2πσ

exp

√

√

−

≤

(cid:19)

(cid:18)

(cid:18)

exp

√

1
2π σ1

−

v2
8σ 2
2
≥ 1
√

2π σ

+

(cid:19)

2
1, µ

max(µ

1
6σ 2
1
, it suffices to show

2
2)

1
2σ 2
(cid:16)
v −

⇐⇒

⇐⇒

a

⇐=

−

+

v2
1
8σ 2
6σ 2
2
1
2 + σ 2
3σ 2
1
2 + σ 2
3σ 2
1
2 + σ 2
3σ 2
1

µ

µ

(cid:19)

(cid:19)

(cid:18)
av

2 − 2µv + µ

(cid:17) 2

+

µ
a

(cid:18)

(cid:18)

1 −

1 −

1

a
1

a

max(µ

2
1, µ

2
2) ≥ −

(v − µ)2
2σ 2

max(µ

(cid:19)

2
1, µ

2
2)

≥ 0, where a = 1 −

σ 2
4σ 2
2

max(µ

2
1, µ

2
2) ≥ 0

max(µ

2
1, µ

2
2) ≥ 0,

since a = 1 −

σ 2
4σ 2
2

≥

3
4 .

The last inequality holds because

(cid:18)

1 −

(cid:19)

1

a

2 + σ 2
3σ 2
1

µ

max(µ

2
1, µ

2
2) ≥ −

1
3 µ

2 +

1
3

max(µ

2
1, µ

2
2) ≥ 0.

□

Theorem 6.7. If both our assumption in §6.1 and the condition (9) hold, then the condition (10)

implies the requirements R4-R6.

0:64

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

Proof. Before staring the proof, we note that by the condition (10), there is an open interval

V(i,α, j,θ ) ⊆ R for all i ∈ [M], α ∈ Ki , j ∈ [p] and θ ∈ Rp , such that

• V(i,α, j,θ ) contains θj ;
• the function v ∈ R (cid:55)−→ µ(i,α )(θ [j : v]) is continuously differentiable in V(i,α, j,θ );
• the function v ∈ R (cid:55)−→ σ(i,α )(θ [j
inf {σ(i,α )(θ [j : v]) | v ∈ V(i,α, j,θ )} > 0.

: v]) is continuously differentiable in V(i,α, j,θ ), and

Let F1 and F2 be functions from Rp × RDB to R defined as follows: for all θ ∈ Rp and r ∈ RDB,

F1(θ, r ) ≜ dens(Dθ , sI )(r ) · log dens(Dθ , sI )(r )
dens(C, sI )(r )

,

We have to show that for every θ ∈ Rp and j ∈ [p],

F2(θ, r ) ≜ dens(Dθ , sI )(r ).

• the partial derivatives
∫

∇θ j

ρ(dr ) F1(θ, r )

and ∇θ j

∫

ρ(dr ) F2(θ, r )

are well-defined and are continuous functions of θj ∈ R;

• these derivatives commute with integration:
∫

∫

∇θ j

ρ(dr ) F1(θ, r ) =

ρ(dr ) ∇θ j F1(θ, r )

and ∇θ j

∫

ρ(dr ) F2(θ, r ) =

∫

ρ(dr ) ∇θ j F2(θ, r ).

We discharge these proof obligations using Theorem C.1. Pick θ ∗ ∈ Rp and j ∈ [p]. We instantiate

Theorem C.1 twice for F1 and F2 as follows.

• For both cases of F1 and F2, we set V to be an open interval (a, b) such that both a and b are
α ∈Ki V(i,α, j,θ ∗), and (a, b) contains

finite, the closure [a, b] is contained in V(j,θ ∗) ≜ (cid:209)
θ ∗
j

. Note that such an open interval exists because V(j,θ ∗) is open and contains θ ∗
j
• The measurable space (X , Σ) in the theorem is RDB with its σ -algebra in both cases.
• The measure µ is the reference measure ρ on RDB in both cases.
• The measurable function f is instantiated twice for (v, r ) (cid:55)−→ Fi (θ ∗[j : v], r ) with i = 1, 2.
Under this instantiation, the conclusion of Theorem C.1 implies all of the requirements R4-R6.

i ∈[M ]

(cid:209)

.

It remains to show that both instantiations satisfy the three provisos of Theorem C.1 marked (a),
(b) and (c). We tackle the provisos one-by-one. We use the notations in §6.1 without recalling them
explicitly. For i ∈ [M], l ∈ [Ni ], α ∈ Ki , v ∈ R, r ∈ Ai and θ ∈ Rp , let

д(i,α,θ )(v) ≜ N (v; µ(i,α )(θ ), σ(i,α )(θ )),

д(i,θ )(r ) ≜ (cid:214)

д(i, β,θ )(r (β)),

h(i,α )(r ) ≜ N (r (α); µ ′

(i,α )(r ), σ ′

(i,α )(r )),

k(i,l )(r ) ≜ N (c(i,l ); µ ′′

(i,l )(r ), σ ′′

(i,l )(r )),

β ∈Ki

hi (r ) ≜ (cid:214)

h(i, β )(r ),

β ∈Ki
Ni(cid:214)

k(i,m)(r ).

m=1

ki (r ) ≜

Proof of (a). Since we assume the condition 9, Theorem 6.3 ensures that the integral ∫
µ(dr ) F1(θ ∗[j :
v], r ) is well-defined for all v ∈ V . The other integral involving F2 is the integral of the density of
Dθ ∗[j:v]. Since Dθ ∗[j:v] is a guide, the integral is well-defined and has the value 1.
Proof of (b). Note that

F1(θ ∗[j : v], r ) = dens(Dθ ∗[j:v], sI )(r ) · log

dens(Dθ ∗[j:v], sI )(r )
dens(C, sI )(r )

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:65

=

=

=

M
(cid:213)

i=1
M
(cid:213)

i=1
M
(cid:213)

i=1

1[r ∈Ai ] · д(i,θ ∗[j:v])(r ) · log

д(i,θ ∗[j:v])(r )
hi (r ) · ki (r )

1[r ∈Ai ] · д(i,θ ∗[j:v])(r ) · (cid:0)− log(hi (r ) · ki (r )) + log(д(i,θ ∗[j:v])(r ))(cid:1)

1[r ∈Ai ] ·

(cid:214)

α ∈Ki

N (r (α); µ(i,α )(θ ∗[j : v]), σ(i,α )(θ ∗[j : v]))

(cid:32)

·

− log(hi (r ) · ki (r )) + (cid:213)

α ∈Ki

log N (r (α); µ(i,α )(θ ∗[j : v]), σ(i,α )(θ ∗[j : v]))

,

(cid:33)

F2(θ ∗[j : v], r ) = dens(Dθ ∗[j:v], sI )(r )
M
(cid:213)

(cid:214)

=

1[r ∈Ai ] ·

i=1

α ∈Ki

N (r (α); µ(i,α )(θ ∗[j : v]), σ(i,α )(θ ∗[j : v])).

Recall that every r ∈ Ai is a map from Ki to R. The normal density N (v ′; µ ′, σ ′) and its log are
smooth functions on (v ′, µ ′, σ ′) ∈ R × R × (0, ∞). Also, by the condition (10), the functions

v ∈ V(i,α, j,θ ∗) (cid:55)−→ µ(i,α )(θ ∗[j : v])

and

v ∈ V(i,α, j,θ ∗) (cid:55)−→ σ(i,α )(θ ∗[j : v])

are continuously differentiable for all i ∈ [M] and α ∈ Ki . Thus, they are also continuously
differentiable when we restrict their domains to V . One more thing to notice is that neither 1[r ∈Ai ]
nor − log(hi (r ) · ki (r )) depends on v, so that they can be viewed as constant functions on v, which
are obviously smooth. Now note that both v ∈ V (cid:55)−→ F1(θ ∗[j : v], r ) and v ∈ V (cid:55)−→ F2(θ ∗[j : v], r )
are obtained from these smooth or continuously differentiable functions by function composition,
addition and multiplication. Thus, they are continuously differentiable.

Proof of (c). For all i ∈ [M], we will construct measurable function Hi , H ′
i

: Ai → [0, ∞) such that

• both ∫
• for all r ∈ Ai and v ∈ V ,

ρ(dr ) (1[r ∈Ai ] · Hi (r )) and ∫

ρ(dr ) (1[r ∈Ai ] · H ′

i (r )) are well-defined;

(cid:18)
д(i,θ ∗[j:v])(r ) · log

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∇v

д(i,θ ∗[j:v])(r )
hi (r ) · ki (r )

(cid:19)(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ Hi (r );

• for all r ∈ Ai and v ∈ V ,

(cid:12)∇vд(i,θ ∗[j:v])(r )(cid:12)
(cid:12)

(cid:12) ≤ H ′

i (r ).

Once we have such Hi ’s, we can use them to define desired measurable functions H, H ′ : RDB → R
as follows:

H (r ) ≜

M
(cid:213)

i=1

1[r ∈Ai ] · Hi (r )

and H ′(r ) ≜

M
(cid:213)

i=1

1[r ∈Ai ] · H ′

i (r ).

Since both Hi and H ′
i
case for H ′ is similar.

are integrable for all i, so are H and H ′. We prove this only for H below. The

∫

ρ(dr ) |H (r )| ≤

∫

ρ(dr )

M
(cid:213)

i=1

(cid:12)1[r ∈Ai ] · Hi (r )(cid:12)
(cid:12)

(cid:12) =

M
(cid:213)

∫

i=1

ρ(dr ) (cid:12)

(cid:12)1[r ∈Ai ] · Hi (r )(cid:12)

(cid:12) < ∞.

0:66

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

Both Hi and H ′
bound the magnitudes of the partial derivatives involving д(i,θ ∗[j:v]) for every i.
i
Using this, we show that H and H ′ meet the condition about bounding the magnitude of a derivative:

|∇v F1(θ ∗[j : v], r )| =

≤

≤

|∇v F2(θ ∗[j : v], r )| =

≤

≤

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

∇v

M
(cid:213)

i=1
M
(cid:213)

i=1
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

∇v

M
(cid:213)

i=1
M
(cid:213)

1[r ∈Ai ] ·

(cid:16)
д(i,θ ∗[j:v])(r ) ·

(cid:16)

− log(hi (r ) · ki (r )) + log(д(i,θ ∗[j:v])(r ))

M
(cid:213)

i=1

(cid:17)(cid:17)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1[r ∈Ai ] ·

(cid:16)
д(i,θ ∗[j:v])(r ) ·

(cid:16)

∇v

(cid:12)
(cid:12)
(cid:12)

− log(hi (r ) · ki (r )) + log(д(i,θ ∗[j:v])(r ))

(cid:17)(cid:17)(cid:12)
(cid:12)
(cid:12)

1[r ∈Ai ] · Hi (r ) = H (r ),

M
(cid:213)

i=1

(cid:12)
(cid:12)
1[r ∈Ai ] · д(i,θ ∗[j:v])(r )
(cid:12)
(cid:12)
(cid:12)

1[r ∈Ai ] · (cid:12)

(cid:12)∇vд(i,θ ∗[j:v])(r )(cid:12)
(cid:12)

1[r ∈Ai ] · H ′

i (r ) = H ′(r ).

i=1
It remains to construct measurable Hi , H ′
i

i ∈ [M]. Pick i ∈ [M]. Note that

: Ai → R with the required properties for every

(cid:18)
д(i,θ ∗[j:v])(r ) · log

∇v

(cid:19)

д(i,θ ∗[j:v])(r )
hi (r ) · ki (r )

= (cid:0)∇vд(i,θ ∗[j:v])(r )(cid:1) · log

= (cid:0)∇vд(i,θ ∗[j:v])(r )(cid:1) ·

(cid:18)

log

д(i,θ ∗[j:v])(r )
hi (r ) · ki (r )
д(i,θ ∗[j:v])(r )
hi (r ) · ki (r )

(cid:19)

.

+ 1

+ (cid:0)д(i,θ ∗[j:v])(r ) · ∇v log(д(i,θ ∗[j:v])(r ))(cid:1)

We will build Hi and H ′
i
ki (r )| and then combining these bounds. We do so in three steps.

by finding good bounds for |∇vд(i,θ ∗[j:v])(r )|, | log д(i,θ ∗[j:v])(r )| and | log hi (r )·

First, we build functions that bound |∇vд(i,θ ∗[j:v])(r )| and | log д(i,θ ∗[j:v])(r )| over v ∈ V . For every

α ∈ Ki ,

∇v log д(i,α,θ ∗[j:v])(w) = ∇v

− log

(cid:32)

√

2π − log σ(i,α )(θ ∗[j : v]) −

(cid:0)w − µ(i,α )(θ ∗[j : v])(cid:1) 2
2σ(i,α )(θ ∗[j : v])2

(cid:33)

= −

∇vσ(i,α )(θ ∗[j : v])
σ(i,α )(θ ∗[j : v])

= ∇vσ(i,α )(θ ∗[j : v]) ·

−

+

(µ(i,α )(θ ∗[j : v]) − w)∇v µ(i,α )(θ ∗[j : v])
σ(i,α )(θ ∗[j : v])2

(cid:0)w − µ(i,α )(θ ∗[j : v])(cid:1) 2

∇vσ(i,α )(θ ∗[j : v])

σ(i,α )(θ ∗[j : v])3

(cid:0)w − µ(i,α )(θ ∗[j : v])(cid:1) 2

− σ(i,α )(θ ∗[j : v])2

+ ∇v µ(i,α )(θ ∗[j : v]) ·

σ(i,α )(θ ∗[j : v])3

w − µ(i,α )(θ ∗[j : v])
σ(i,α )(θ ∗[j : v])2

.

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:67

Thus, we have

∇vд(i,θ ∗[j:v])(r ) = ∇v

(cid:214)

д(i,α,θ ∗[j:v])(r (α))

α ∈Ki

= (cid:213)
α ∈Ki

∇vд(i,α,θ ∗[j:v])(r (α)) ·

д(i, β,θ ∗[j:v])(r (β))

(cid:214)

β ∈Ki
β (cid:44)α

= (cid:213)
α ∈Ki

д(i,α,θ ∗[j:v])(r (α)) · ∇v log д(i,α,θ ∗[j:v])(r (α)) ·

д(i, β,θ ∗[j:v])(r (β))

(cid:214)

β ∈Ki
β (cid:44)α

= д(i,θ ∗[j:v])(r ) ·

(cid:213)

∇v log д(i,α,θ ∗[j:v])(r (α))

= д(i,θ ∗[j:v])(r ) ·

α ∈Ki

(cid:213)

(cid:32)

α ∈Ki

∇vσ(i,α )(θ ∗[j : v]) ·

+ ∇v µ(i,α )(θ ∗[j : v]) ·

= д(i,θ ∗[j:v])(r ) ·

(cid:213)

2
(cid:213)

α ∈Ki

n=0

G(1,α,n)(v) · r (α)n

(cid:0)r (α) − µ(i,α )(θ ∗[j : v])(cid:1) 2

− σ(i,α )(θ ∗[j : v])2

σ(i,α )(θ ∗[j : v])3

r (α) − µ(i,α )(θ ∗[j : v])
σ(i,α )(θ ∗[j : v])2

(cid:33)

(24)

for some continuous functions G(1,α,n) : V(j,θ ∗) → R that do not depend on r . The continuity of
G(1,α,n) follows from our condition (10). Also,

log д(i,θ ∗[j:v])(r ) = (cid:213)

log д(i,α,θ ∗[j:v])(r (α))

α ∈Ki

= (cid:213)
α ∈Ki

= (cid:213)
α ∈Ki

(cid:32)

√

− log

2π − log σ(i,α )(θ ∗[j : v]) −

(cid:0)r (α) − µ(i,α )(θ ∗[j : v])(cid:1) 2
2σ(i,α )(θ ∗[j : v])2

(cid:33)

2
(cid:213)

n=0

G(2,α,n)(v) · r (α)n

for some continuous functions G(2,α,n) : V(j,θ ∗) → R that do not depend on r . The continuity of
G(2,α,n) follows from the condition (10). Since V ⊂ V(j,θ ∗), the functions G(m,α,n) are all continuous
on the closed (bounded) interval V , where V is the closure of V . Thus, by the extreme value theorem,

Cmax ≜ max
(m,α,n)

sup
v ∈V

|G(m,α,n)(v)| < ∞.

Since the term д(i,θ ∗[j:v])(r ) in (24) still depends on v, we bound it over v ∈ V using Lemma C.2

which is instantiated with

µ1 ≜ min
α ∈Ki
σ1 ≜ min
α ∈Ki

inf
v ∈V
inf
v ∈V

µ(i,α )(θ ∗[j : v])

σ(i,α )(θ ∗[j : v])

µ2 ≜ max
α ∈Ki
σ2 ≜ max
α ∈Ki

sup
v ∈V
sup
v ∈V

µ(i,α )(θ ∗[j : v]),

σ(i,α )(θ ∗[j : v]).

We check that the assumptions of the lemma are satisfied: since V ⊂ V(j,θ ∗) and the functions

v ∈ V(j,θ ∗) (cid:55)→ µ(i,α )(θ ∗[j : v])

and v ∈ V(j,θ ∗) (cid:55)→ σ(i,α )(θ ∗[j : v])

0:68

Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang

are continuous by the condition (10), µm and σm (m = 1, 2) are all finite by the extreme value
theorem; moreover, σ1 is positive by the choice of V(i,α, j,θ ∗). Thus, by Lemma C.2, there exists c ∈ R
such that

д(i,θ ∗[j:v])(r ) = (cid:214)

N (r (α); µ(i,α )(θ ∗[j : v]), σ(i,α )(θ ∗[j : v]))

≤

α ∈Ki
(cid:214)

α ∈Ki

c · N (r (α); 0, 2σ2) = c ′ · д′(r )

for all v ∈ V , where c ′ ≜ c |Ki | and д′(r ) ≜ (cid:206)

N (r (α); 0, 2σ2).

α ∈Ki

Combining what we have proved, we obtain the following bounds: for all v ∈ V ,

(cid:12)∇vд(i,θ ∗[j:v])(r )(cid:12)
(cid:12)

(cid:12) = д(i,θ ∗[j:v])(r ) ·

(cid:213)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
α ∈Ki
2
(cid:213)

2
(cid:213)

n=0

G(1,α,n)(v) · r (α)n

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Cmax · |r (α)n |

≤ c ′ · д′(r ) ·

(cid:213)

n=0
≤ c ′ · д′(r ) · exp(l1(r ))

α ∈Ki

for some l1 ∈ Ai (Lemma 6.6 (a) and (b)),

(cid:12)log д(i,θ ∗[j:v])(r )(cid:12)
(cid:12)

(cid:12) =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

α ∈Ki

(cid:213)

n=0
2
(cid:213)

(cid:213)

2
(cid:213)

G(2,α,n)(v) · r (α)n

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Cmax · |r (α)n | ≤ exp(l1(r )).

α ∈Ki

n=0

Second, we bound | log hi (r ) · ki (r )| by exp(l3(r )) for some l2 ∈ Ai .

| log hi (r ) · ki (r )| ≤

(cid:213)

α ∈Ki

| log h(i,α )(r )| +

Ni(cid:213)

l =1

| log k(i,l )(r )|

= (cid:213)
α ∈Ki

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

√

− log

2π − log σ ′

(i,α )(r ) −

(cid:16)
r (α) − µ ′
2σ ′

(i,α )(r )2

(i,α )(r )

(cid:17) 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

Ni(cid:213)

l =1

(cid:12)
(cid:12)
(cid:12)
− log
(cid:12)
(cid:12)
(cid:12)
(cid:12)

√

2π − log σ ′′

(i,l )(r ) −

(cid:16)
c(i,l ) − µ ′′
2σ ′′

(i,l )(r )2

(i,l )(r )

(cid:17) 2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:17) 2

(cid:170)
(cid:174)
(cid:174)
(cid:172)

(cid:16)
r (α) − µ ′
2σ ′

(i,α )(r )

(i,α )(r )2
(cid:17) 2

(i,l )(r )

(cid:16)
c(i,l ) − µ ′′
2σ ′′

≤ (|Ki | + Ni ) ·

√

2π

(cid:12)
log
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

+ (cid:213)
α ∈Ki

(cid:169)
(cid:173)
(cid:173)
(cid:171)

(cid:12)
log σ ′
(cid:12)
(cid:12)

(i,α )(r )

(cid:12)
(cid:12)
(cid:12)

+

Ni(cid:213)

+

(cid:12)
log σ ′′
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(i,l )(r )
(cid:12)

(cid:170)
(cid:174)
(cid:174)
(cid:172)
for some l2 ∈ Ai (Lemma 6.6 and Condition 9).
by combining the bounds that we got so far. Here are our definitions

(i,l )(r )2

(cid:169)
(cid:173)
(cid:173)
(cid:171)

l =1

+

≤ exp(l2(r ))

Finally, we define Hi and H ′
i

for them:

Hi (r ) ≜ c ′ · д′(r ) · exp(l1(r )) · (exp(l1(r )) + exp(l2(r )) + 1),

Towards Verified Stochastic Variational Inference for Probabilistic Programs

0:69

i (r ) ≜ c ′ · д′(r ) · exp(l1(r )).
H ′

Then, by the choice of l1 and l2, for all r ∈ Ai and v ∈ V ,

(cid:18)
д(i,θ ∗[j:v])(r ) · log

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∇v

д(i,θ ∗[j:v])(r )
hi (r ) · ki (r )

(cid:19)(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ Hi (r )

and

Also, we have

(cid:12)∇vд(i,θ ∗[j:v])(r )(cid:12)
(cid:12)

(cid:12) ≤ H ′

i (r ).

ρ(dr ) (cid:12)

∫

=

ρ(dr )

(cid:12)1[r ∈Ai ] · Hi (r )(cid:12)
(cid:12)
(cid:16)1[r ∈Ai ] · д′(r ) · c ′ · exp(l1(r )) · (exp(l1(r )) + exp(l2(r )) + 1)
(cid:17)
(cid:16)1[r ∈[Ki →R]] · д′(r ) · exp(l3(r ))
N(r (α );0,2σ2) [exp(l3(r ))] < ∞

(Lemma 6.6 (e)),

ρ(dr )

= E(cid:206)

≤

∫

(cid:17)

α ∈Ki

for some l3 ∈ Ai (Lemma 6.6 (a))

∫

and

∫

ρ(dr ) (cid:12)

(cid:12)1[r ∈Ai ] · H ′

∫

∫

=

≤

ρ(dr )

ρ(dr )

i (r )(cid:12)
(cid:12)
(cid:16)1[r ∈Ai ] · д′(r ) · c ′ · exp(l1(r ))
(cid:16)1[r ∈[Ki →A]] · д′(r ) · exp(l4(r ))
N(r (α );0,2σ2) [exp(l4(r ))] < ∞

(cid:17)

= E(cid:206)
We have just shown that Hi and H ′
i

α ∈Ki

(cid:17)

for some l4 ∈ Ai (Lemma 6.6 (a))

(Lemma 6.6 (e)),

are the functions that we are looking for.

□

D PROOF OF THEOREM IN §7
Theorem 7.1 (Soundness). For all commands C, we have ⟦C⟧

d ∈ γ (⟦C⟧♯).

Proof. We prove the theorem by structural induction on C. Every case except the one for the
loop follows from the assumption made for an abstract element in T ♯ or an operator on it that
corresponds to C. The proof of the case of C ≡ (while E {C0}) goes as follows. Let tfix ≜ (wfix T ).
Then, by the assumption on the concretisation, γ (tfix) is an admissible subset of D. Thus, it suffices
to prove that when G is the function in the density semantics of ⟦while E {C0})⟧
, the image of G
d
on γ (tfix) is included in γ (tfix). To do so, pick д ∈ γ (tfix). We have to show that G(д) ∈ γ (tfix). By
the induction hypothesis and the assumption on the abstract composition,

(д‡ ◦ ⟦C0⟧

d ) ∈ γ (tfix ◦♯ ⟦C0⟧♯).

Also, ⟦skip⟧

d ∈ γ (skip♯). Thus,
G(д) = λ(s, r ). if (⟦E⟧s = true) then ⟦skip⟧

d (s, r ) else (д‡ ◦ ⟦C0⟧

d )(s, r )

∈ γ (cond(E)♯(tfix ◦♯ ⟦C0⟧♯, skip♯)) = γ (T (tfix)) = γ (tfix).
The set membership holds because of the assumption on the abstract conditional operator.

□

