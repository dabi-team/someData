2
2
0
2

b
e
F
7

]
I

N
.
s
c
[

1
v
4
2
9
2
0
.
2
0
2
2
:
v
i
X
r
a

3TO: THz-Enabled Throughput and Trajectory
Optimization of UAVs in 6G Networks by Proximal
Policy Optimization Deep Reinforcement Learning

†Sheikh Salman Hassan, †Yu Min Park, †Yan Kyaw Tun, ‡Walid Saad, ††Zhu Han, and †Choong Seon Hong
†Department of Computer Science and Engineering, Kyung Hee University, Yongin, 17104, Republic of Korea
‡Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, VA, 24061, USA
††Department of Electrical and Computer Engineering, University of Houston, Houston, TX 77004-4005, USA
Email: {salman0335, yumin0906, ykyawtun7, cshong}@khu.ac.kr, walids@vt.edu, zhan2@uh.edu.

Abstract—Next-generation networks need to meet ubiquitous
and high data-rate demand. Therefore,
this paper considers
the throughput and trajectory optimization of terahertz (THz)-
enabled unmanned aerial vehicles (UAVs) in the sixth-generation
(6G) communication networks. In the considered scenario, mul-
tiple UAVs must provide on-demand terabits per second (TB/s)
services to an urban area along with existing terrestrial net-
works. However, THz-empowered UAVs pose some new con-
straints, e.g., dynamic THz-channel conditions for ground users
(GUs) association and UAV trajectory optimization to fulﬁll GU’s
throughput demands. Thus, a framework is proposed to address
these challenges, where a joint UAVs-GUs association, transmit
power, and the trajectory optimization problem is studied. The
formulated problem is mixed-integer non-linear programming
(MINLP), which is NP-hard to solve. Consequently, an iterative
algorithm is proposed to solve three sub-problems iteratively, i.e.,
UAVs-GUs association, transmit power, and trajectory optimiza-
tion. Simulation results demonstrate that the proposed algorithm
increased the throughput by up to 10%, 68.9%, and 69.1%
respectively compared to baseline algorithms.

Index Terms—Sixth generation (6G) networking, unmanned
aerial vehicles (UAVs), terahertz (THz) communication, proximal
policy optimization (PPO), deep reinforcement learning (DRL).

I. INTRODUCTION

Wireless communication systems have grown exponentially
in the past several decades due to the need for high-speed data
connections wherever and whenever needed. Therefore, sixth-
generation (6G) networks must be multi-dimensional and capa-
ble of providing ubiquitous and diverse services by integrating
current terrestrial network speciﬁcations with space and air-
based information networks [1]–[3]. 6G networks will likely
be cell-free, which means that users will be able to smoothly
and automatically switch from one network to another to seek
the most appropriate and qualiﬁed communication without the
need for human administration and settings [4].

This work was supported by the National Research Foundation of Ko-
(No. No.
funded by the Korea government
rea (NRF) grant
2020R1A4A1018607) and by the Institute of Information and Communica-
tions Technology Planning and Evaluation (IITP) Grant funded by the Korea
Government (MSIT) (Artiﬁcial Intelligence Innovation Hub) under Grant 2021-
0-02068. *Dr. CS Hong is the corresponding author.

(MSIT)

Furthermore,

the terahertz (THz) band, with frequencies
ranging from 0.1 to 10 THz, is a viable frequency range for the
next generation of ultra-dense wireless networks [5], [6]. The
THz channel can provide rates in the order of terabits per sec-
ond (Tbps) that are suitable to support emerging applications,
including high-quality video streaming, virtual and augmented
reality, and chip-based wireless networks. Moreover, due to
the restricted bandwidth at millimeter-wave (mmW), i.e., 30
gigahertz (GHz) carrier frequencies, it is impossible to reach
Tbps data speeds.

In particular, utilizing THz-enabled unmanned aerial vehicles
(UAVs) communications to offer seamless coverage and provide
high bandwidth to ground users could be an efﬁcient wireless
network integration. Many mobile carriers in the United States
have tested UAV-mounted LTE base stations, including AT&T
and Verizon [7]. Aerial base stations may be attached to UAVs
at low altitudes, making them more cost-effective, quick, and
adaptable than terrestrial communication infrastructures [8].
Also, UAV communications beneﬁt from better line-of-sight
links with ground users due to their high altitudes. However,
there are signiﬁcant problems in terms of deployment, trajectory
design, and network resource optimization when using UAVs
for wireless communications.

To fully exploit the design degrees of freedom for THz-
enabled UAV communications, it is crucial to investigate the
UAV’s mobility and its network resource management in three-
dimensional space. The existing works [9]–[11] consider the
UAVs as aerial base stations. The authors in [9] studied
the problem of minimization of uplink power through user
association in the presence of a single UAV base station. In
[10], the authors investigated the problems of optimal trajectory
design and transmit power optimization to maximize data rate
in the presence of energy harvesting constraints. Similarly, the
authors in [11] studied a three-dimensional (3D) coverage max-
imization problem for UAV networks. Moreover, the authors
in [12] analyzed the coverage probability of UAVs with THz
communication but did not optimize the UAVs’ deployment.
The authors in [13] and [14] investigated the problem of UAV
deployment and transmitting power for THz communication.

 
 
 
 
 
 
However, they used traditional optimization techniques to solve
the proposed problem. Moreover, none of the prior research
takes into account the usage of the THz spectrum for UAVs
with deployment and trajectory optimization.

Hence, to ﬁll the knowledge gap, we investigate the funda-
mental study of optimal UAV trajectory deployment design and
network resource management at THz frequencies. Nonethe-
less, given the signiﬁcant degree of uncertainty in higher
frequency bands such as THz, it is critical to provide addi-
tional degrees of freedom and control in network management.
Therefore, given the ability of UAVs to ﬂy, they are suitable for
providing line-of-sight (LoS) communication links to ground
users (GUs) [15] and [16]. To reap the beneﬁts of deploying
THz-enabled UAVs, it is important to optimize the locations
of the UAVs to offer continuous LoS connections to GUs.
Therefore, to handle the mobility of UAVs in our proposed
dynamic network, we consider deep reinforcement learning-
based UAVs location optimization with a low-complexity algo-
rithm for GU association and transmit power optimization. The
key contributions of our proposed work can be summarized as
follows:

• We propose a THz-enabled UAVs communication network
architecture by considering the quality-of-service (QoS)
parameters for the GUs and the UAV’s optimal trajectory
deployment.

• Our objective is to maximize overall throughput between
the UAVs and the GU by jointly optimizing the operational
UAV’s trajectory deployment and GU association, as well
as minimizing the transmitting power of the UAVs.

• To tackle this optimization problem, we propose an it-
erative algorithm that separates the original optimiza-
tion problem into three subproblems: A GU association
subproblem is handled by balanced K-means clustering
(BKMC), a power control subproblem is solved by suc-
cessive convex approximation (SCA), and a trajectory de-
ployment optimization subproblem is tackled by proximal
policy optimization deep reinforcement
learning (PPO-
DRL) that is solved iteratively.

• Numerical results show that the proposed algorithm can
increase throughput by up to 10%, 68.9%, and 69.1%
respectively when compared to a baseline that optimizes
only transmit power with static UAVs, random transmit
power with static UAVs and optimizes only UAVs trajec-
tories with random transmit power.

The rest of the paper is organized as follows. The system
model and the problem formulation are given in Section II-A
and II-C respectively. Then, the proposed algorithm is presented
in Section III. Section IV describes the implementation and
simulation results, and Section V concludes the paper.

II. SYSTEM MODEL & PROBLEM FORMULATION

A. Network Model

As shown in Fig. 1, we consider a THz-enabled multi-UAV
wireless communication network. This system model consists
of a set K of K UAVs that seek to provide communication

Fig. 1: Illustration of THz-enabled UAVs Network.

services to a set M of M GUs distributed according to
a homogeneous Poisson point process (HPPP). The three-
dimensional (3D) coordinates of UAV k can be represented
as qk(n)=(cid:0)xk(n), yk(n), zk(n)(cid:1), and the two-dimensional (2D)
coordinates of GU m can deﬁned as om(n)=(cid:0)xm(n), ym(n)(cid:1)
respectively.

B. Channel Model & Link Analysis

The presence of this molecular absorption loss distinguishes
the terahertz channel. This loss is produced by molecules in the
air, such as H2O vapor, which each have their own absorption
spectrum, making the wireless channel frequency selective.
Thus, the THz communication channel between UAV k and
GU m can be modeled as follows [13]:

hk,m = d−2

k,me−a(f )dk,m ,

∀k ∈ K, ∀m ∈ M,

(1)
where dk,m = (cid:107)qk − om(cid:107) is the distance between UAV k
and GU m, e−a(f )dk,m represents the channel path-loss due
to the molecular absorption, and a(f ) denotes the molecular
absorption coefﬁcient, which depends on the network operating
frequency (i.e., THz frequency) and the concentration of water
vapor molecules in the air1. To efﬁciently use the network
resources, we consider each UAV to utilize the same frequency
spectrum. Therefore, the network experiences interference from
non-associated UAVs to the GUs in each time slot, which can
be deﬁned as:
(cid:88)
ψk,m(n) =

∀k ∈ K, ∀m ∈ M,

pk(cid:48),m(cid:48) (n)hk(cid:48),m(cid:48) (n),

(cid:88)

∀k(cid:48)(cid:54)=k

∀m(cid:48)(cid:54)=m

(2)
is the transmit power, k(cid:48) is the non-associated
where pk(cid:48),m(cid:48)
UAVs, and m(cid:48) represents the non-associated GUs, respectively.
Therefore,
the signal-to-interference-plus-noise ratio (SINR)
from each UAV k to GU m in each time slot n can be
formulated as:

γk,m(n) =

pk,m(n)h0
ψk,m + αk,mBk,md2

k,meadk,m σ2

,

∀k ∈ K, m ∈ M,

(3)
where h0 is the channel gain at a reference distance d0 = 1m,
pk,m is the transmit power from the UAV k to their associated
GU m, αk,m proportion of the channel bandwidth from the UAV

1Hereinafter, for the sake of simplicity, we will write a instead of a(f ).

k to GU m, Bk,m is the total channel bandwidth, and σ2 is the
additive white Gaussian noise (AWGN) power. The achievable
throughput from UAV k to GU m in each time slot n can be
obtained based on the SINR γk,m as:

Algorithm 1 BKMC for GUs Association

1: Input: the GU locations {om}m∈M, the initial UAV loca-

tions {qk}k∈K.

2: Initialize: Initialize centroid locations C 0 to UAV locations

Rk,m(n) = αk,mBk,m log2 (1 + γk,m) .

(4)

{qk}k∈K.

C. Problem Formulation

Our goal

is to maximize the total

throughput from all
the deployed UAVs while satisfying the QoS and trajectory
constraints of each GU and UAV, respectively, in the network.
Therefore, the throughput maximization problem can be deﬁned
as:

P1: max
α,p,q

Rlo

k (n)

N
(cid:88)

M
(cid:88)

s.t.

(5a)

αk,mRk,m(n) ≥ Rlo

k (n), ∀k ∈ K,

(5b)

m=1

n=1
αk,mRk,m(n) ≥ Rmin, ∀m ∈ M, k ∈ K, n ∈ N ,

(5c)

αk,m ∈ {0, 1} ,

M
(cid:88)

m=1

αk,m = 1, ∀k ∈ K, m ∈ M,

(5d)

(5e)

(5f)

M
(cid:88)

pk,m(n) ≤ P max

k

, ∀k ∈ K, n ∈ N ,

m=1
0 ≤ pk,m(n) ≤ P max
k
2 ≥ D2
(cid:107)qi(n) − qj(n)(cid:107)2

, ∀k ∈ K, n ∈ N ,

min, ∀i (cid:54)= j ∈ K, ∀n ∈ N ,

(5g)

≤ V max, ∀k ∈ K, n ∈ N ,

(cid:107)qk(n + 1) − qk(n)(cid:107)
tmov

(5h)
where (5b) represents the optimization objective, which is the
sum-rate of each UAV at each time slot n. (5c) ensures the QoS
constraint of each user from the associated UAV, (5d) presents
that each GU can be associated with at most one UAV, (5e)
and (5f) ensures the total transmit power of the UAV have to
be less than the maximum transmit power P max
of the UAV,
(5g) guarantees that the distance between UAVs is not as close
as the minimum distance Dmin, and (5h) is the UAVs speed
constraint.

k

III. PROPOSED ALGORITHM

P1 is a MINLP, which is NP-hard and difﬁcult to solve.
Therefore, we will decompose it into three subproblems and
propose an iterative algorithm that is composed of BKMC,
SCA, and PPO-DRL in the following subsections, respectively.

A. Balanced K-means Clustering

Given the initial UAVs’ transmit power p and trajectory qm,
P1 is transformed into P1.1 for optimizing GU association α,
which is integer linear programming. Mathematically, it can be
deﬁned as:

P1:1 max

α

Rlo

k (n)

s.t.

(5b), (5c), and (5d).

(6a)

(6b)

3: t ← 0
4: repeat
5:
6:
7:
8: until the positions of the centroids do not change
9: Output: Optimal user association. α∗

Calculate distances between GUs and UAVs.
Solve an assignment problem by Hungarian algorithm.
Calculate new centroid locations C t+1.

GU association problems, in general, can be solved by K-means
clustering. Although K-means clustering poses an unfairness
issue that can lead to any cluster expanding excessively. Thus,
we propose the use of BKMC, which can calculate the size of
each cluster in advance [17].

We follow the same steps as K-means, while the assignment
phase is different. We deﬁne pre-allocated slots according to the
total number of GU M, instead of choosing the closest UAV k,
each GU m needs to be associated with these slots i.e., M/K
slots per cluster. Assuming that (cid:98)M/K(cid:99) = (cid:100)M/K(cid:101) = M/K,
this will compel all clusters to have the same size. Otherwise,
there will be (M mod K) clusters of size (cid:98)M/K(cid:99), and K−(M
mod K) clusters of size (cid:100)M/K(cid:101). To ﬁnd an assignment that
minimizes mean square error (MSE), we solve an assignment
problem using the Hungarian algorithm [18].

In contrast to a traditional assignment problem with ﬁxed
the weights in this problem vary dynamically af-
weights,
ter each K-means iteration based on the newly determined
centroids. The Hungarian method is then used to obtain the
minimum weight pairing. The update step for choosing new
UAV locations is similar to normal K-means centroids, where
the new location are calculated as the means of each GU
location: qm assigned to each cluster i:

C (t+1)
i

=

1
ni

(cid:88)

oi
m,

(7)

oi

(t)
m∈C
i
where oi
m represents GU m location in cluster i and Ci denotes
the UAV (centroid) location. The edge weight is the distance
between the UAV and GU, which is updated following the
update step in each iteration. The description of BKMC is given
in Algorithm 1.

B. Successive Convex Approximation

Given the optimal GUs association α∗ and UAVs trajectory
qm, P1 is transformed into P1.2a for optimizing transmit
power p, which is non-convex programming. Mathematically,
it can be deﬁned as:

P1.2a: max

p

Rlo

k (n)

(8a)

(8b)
To transform the non-convex objective, we apply SCA, which
is based on the ﬁrst-order Taylor approximation, knowing that

(5b), (5e), and (5f ).

s.t.

this provides the global upper bound for the concave function.
To develop the SCA-based algorithm, we rewrite the log-term
in objective (5a) in the form of the difference of two concave
(D.C.) functions, which can be deﬁned as:

R(p) =

K
(cid:88)

k=1

Rlo

k = log2 (1 + γk,m) = l(p) − h(p),

(9)

where

and

l(p) =

K
(cid:88)

M
(cid:88)

k=1

m=1

log2 (pk,m(n)h0) ,

(10)

h(p) =

K
(cid:88)

M
(cid:88)

k=1

m=1

(cid:16)
ψk,m + Bk,md2

k,m(n)eadk,m σ2(cid:17)

.

log2

(11)

The functions in (10) and (11) are concave, but the difference
between them, captured in (9), is neither convex nor concave.
Therefore, we presented the SCA, which can calculate the
concave lower bound, i.e., the surrogate function for the non-
concave objective given in (9), by providing a feasible solution
p(cid:48) of the problem (5). We design its lower bound with substi-
tuting h(p) by their ﬁrst-order Taylor approximation which can
be deﬁned as:

R(p, p(cid:48)) = l(p) − ˜h((p, p(cid:48))),

(12)

where

˜h((p, p(cid:48))) (cid:44) h(p(cid:48)) − ∇h(p(cid:48))(p − p(cid:48)),
(13)
where (13) is the ﬁrst-order Taylor’s expansion of h(p) near
the given point p(cid:48) in the feasible region of the solution space,
and ∇h(p(cid:48)) denotes the gradient of the h(p) at p(cid:48). The gradient
for UAV k can be given as:

∇kh(p(cid:48)) =

∂h(p(cid:48))
∂p(cid:48)
k
(cid:88)

(cid:88)

=

1
ln2

h0

∀k(cid:48)(cid:54)=k

∀m(cid:48)(cid:54)=m

ψk,m + αk,mBk,md2

k,me−adk,mnσ2

(14)

.

The surrogate function is concave given in (13). Additionally,
we can ﬁnd the upper bound of function h(p) by the ﬁrst-order
Taylor’s expansion as:

h(p) ≤ h(p(cid:48)) + ∇h(p(cid:48))(p − p(cid:48)).
(15)
By analysing (9), (12), and (15), we can deduce the following
observations:

R(p) = l(p) − h(p)

≥ l(p) − {h(p(cid:48)) + ∇h(p(cid:48))(p − p(cid:48))}
≥ l(p) − h(p(cid:48)) − ∇h(p(cid:48))(p − p(cid:48))
= R(p, p(cid:48)).

(16)

where (16) represents that the surrogate function provide the
lower bound of the original function. Therefore, these two
functions are tangent at point p(cid:48),
i.e., R(p, p(cid:48))|p=p(cid:48)=R(p(cid:48)).
Thus, the function in (16) can provide the lower bound for
the original objective function in (5). Therefore, we replace the
non-concave objective in (5) with its surrogate function given
(12). Afterward, we modify the surrogate objective function and
found the convex problem which can be given as:

P1.2b: min

p

− Rlo

k (n)

s.t.

(5b), (5e), and (5f ).

(17a)

(17b)

Algorithm 2 SCA for Transmit Power Optimization (17)

1: Input: pmax

k,m , p0, iteration j = 0, tolerance χ, stopping

criterion e = 1.

2: j ← 0
3: while e ≥ χ do
4:
5:
6:
7:
8: end while
9: Output: Optimal transmit power p∗.

Designed R(p, p(cid:48)) = l(p) − ˜h((p, p(cid:48))) based on (12).
Solve (17) and ﬁnd the pj+1.
Calculate the stopping criterion e = |R(pj+1) − R(pj)|.
Update the iteration counter i.e., j = j + 1.

Hence, problem (17) is convex, and we can solve it using opti-
mization solvers, i.e., CVXPY. We observe that the optimal so-
lution p∗ in each iteration provides the new reference point for
p(cid:48). By updating the value of p(cid:48), we can deﬁne a new surrogate
function and ﬁnd the new approximated convex problem. This
procedure will converge iteratively till the convergence criteria
value χ is met. The details of SCA-approximation are shown
in Algorithm 2. Step 3 represents the convex approximation
and step 4 obtains the successive update based on the newly
obtained solution respectively in Algorithm 2.

C. Proximal Policy Optimization

The UAV trajectory optimization q problem is still non-
convex by giving the optimal user association α∗ and transmit
power p∗. Mathematically, this problem can be deﬁned as:
k (n)

P1.3: max

(18a)

Rlo

q

s.t.

(5b), (5c), (5g), and (5h).

(18b)
To address the challenge of dynamic UAV trajectory optimiza-
tion, we propose a PPO-based DRL. PPO-DRL is based on the
substitution of ﬂexible constraints for hard constraints, which
are seen as penalties. The new, more manageable constraints are
utilized to solve a ﬁrst-order differential problem that approxi-
mates the second-order optimization differential equation. The
Kullback–Leibler (KL) divergence is used to calculate policy
changes at each time step [19]. PPO seeks to compute an update
that minimizes the cost function while keeping the divergence
from the prior policy to a minimum at each time step. Trust
region policy optimization (TRPO) recommends optimizing
surrogate loss and limiting the amount of the update using KL.
The PPO objective implements a method for updating the trust
region that is consistent with stochastic gradient descent (SGD)
and simpliﬁes the algorithm by eliminating the KL penalty
and the necessity for adaptive updates. Thus, PPO offers the
advantages of being simple to apply and having a reduced level
of complexity, which is appropriate for our highly dynamic
environment. The surrogate objective function in TRPO can be
maximized subject to a size limit on the policy update, which
can be described as [20]:

LTRPO(θ) = ˆEt

(cid:20) πθ(at|st)
πold(at|st)

(cid:21)

ˆAt

= ˆEt

(cid:104)

rt(θ) ˆAt

(cid:105)

,

(19)

where πθ is a stochastic policy, ˆAt is an estimator of the advan-
tage function at step t, θold is the vector of policy parameters
before the update, rt(θ) denotes the probability ratio, which can
be deﬁne as:

rt(θ) =

πθ(at|st)
πold(at|st)

,

(20)

(cid:104)

(cid:105)

and ˆEt[...] indicates an expectation of the empirical average
over a ﬁnite batch of samples in the algorithm that alternates
between sampling and optimization. At this point, learning fails
or performance suffers as a result of an excessive rise in the
probability ratio rt(θ), and in the case of TRPO, the problem is
avoided by utilizing KL-Divergence to impose a penalty. How-
ever, TRPO has the drawback of being conceptually difﬁcult to
grasp, and hence difﬁcult to apply. PPO, like TRPO, optimizes
the surrogate objective function via stochastic gradient ascent
(SGA). Thus, PPO used computationally efﬁcient penalties and
avoided unnecessary policy changes by employing a technique
known as the clipped surrogate objective. The clip is a function
that determines the minimum and maximum values of a given
variable. The probability ratio rt(θ) can be trimmed by PPO.
The following is the objective function to which the clipping
is applied:

LPPO(θ) = ˆEt

min(rt(θ) ˆAt, clip(rt(θ), 1 − (cid:15), 1 + (cid:15)) ˆAt)

(21)
where (cid:15) is a hyper parameters. The function in (21) compares
the objectives used in the existing TRPO with the objectives to
which clipping is employed and takes a smaller value.

,

Another feature of the PPO method is that, unlike many
other DRL algorithms, the PPO-Actor-Critic networks contain
a type of parameter sharing, which allows each objective to
be combined into a single goal function and optimized at
the same time. The methods for power allocation mentioned
above are added to the function for computing rewards once
the actor-critic network has been updated and learned. With
this, it was possible to effectively separate power allocation
and UAV trajectory and proceed with optimization. Next, the
state, compensation, and behavior of the agent used in learning
will be described. In learning step t, the state st(n) is deﬁned
as:

(22)
st(n) = {{qk(n)}k∈K, {om}m∈M},
where qk(n) and om(n) denotes UAV k and GU m locations,
respectively, at time slot n. Therefore, agent takes optimal
action through network with all
location information input
without any other information. The action in learning step t
at time slot n is the speed and the moving direction as follow:
(23)
at(n) = {{vk(n), φk(n)}k∈K}.
Speciﬁcally, we
restricted the direction φk(n) between
[−π/3, π/3] to prevent UAVs from turning sharply. Lastly, the
reward in learning step t at time slot n is divided into three and
can be expressed as follows:

rt(n) =






2,

−2,

(cid:80)K

k=1 Rlo

k (n),

if t = max step,
if ∃ i, j ∈ K
s.t. (cid:107)qi(n) − qj(n)(cid:107) < Dmin,
otherwise.

(24)

Algorithm 3 PPO-DRL for UAVs Trajectory Optimization (18)

1: for episode= 1, 2, ..., E do
2:
3:

Initialize randomly each GU’s positions
GUs Association α by Algorithm 1
for actor= 1, 2, ..., A do

4:
5:
6:
7:
8:
9:

10:
11:
12:

for time slot= 1, 2, ..., N do

Run policy πθold in environment
Optimal Power Allocation P by Algorithm 2
Save (sn, an, rn, sn+1) in Trajectory memory

end for
Compute advantage estimates ˆA1, ..., ˆAN

end for
Optimize surrogate LPPO wrt θ, with minibatch from
Trajectory memory
θold ← θ

13:
14: end for
15: Output: The optimal PPO network πθopt

The episode ﬁnishes when learning step t reaches the maximum
step with a reward of 2 and if the distance between UAVs
is as near to the minimum distance then the penalty will be
−2. Otherwise, it receives the total of the minimum data rate
given by each UAV with the proposed power allocation and
GU association algorithm.

The pseudocode for the PPO learning process for UAV
trajectory is depicted in Algorithm 3. We proceed with the
learning of the E number of episodes. The episode begins
by randomly arranging the locations of GUs. Algorithm 1
determines the optimal GU association α∗ based on the location
of the arranged GUs. In subsequent learning, A actors simulta-
neously generate data on the environment. Each actor acts under
prior policy πθold and employs Algorithm 2 to determine optimal
power p∗ and derive rewards from it. Trajectory memory stores
the state, action, reward, and future state of time step n. When
the time step is completed, we calculate the advantage estimates
ˆAn for each time step n. Trajectory memory is used to extract
minibatch, which is then optimized for the target function LPPO.
The learning process is repeated by substituting the updated
parameter θ with the old value θold. As a result, we can obtain
a PPO network πθopt for UAVs trajectory.

D. Algorithms Complexities and Convergences

Based on the deﬁnition mentioned above, the detailed process
of resource allocation via BKMC and SCA is proposed as
shown in Algorithm 2 and Algorithm 3 respectively. The com-
putational complexity of BKMC and SCA is O(K 3) and O(K)
respectively. Moreover, after obtaining the optimal resource
allocation, we execute PPO-DRL as mentioned in Algorithm 3
to get the optimal UAVs trajectories policies and its complexity
is O(Ka2), where a represents the number of actions. It can be
observed that the proposed algorithms converged to the sub-
optimal solutions.

Channel gain at ref. h0=−40 dBm

Value

TABLE I: Simulation Parameters

Parameter
Bandwidth
Noise power σ2=−174 dBm/Hz Max. transmit power
Minimum rate Rmin=0.02 Tbps Absorption coefﬁcient

Value
B=0.1 THz

Parameter

Episodes
Discount factor
Clipping (cid:15)
Epochs
Hidden layers

E=5e + 5
γ =0.99
0.2
3
2

Batch size
Learning rate
Regularizer parameter
Hidden layer’s units
Carrier Frequency

P max=2 W
a(f )=0.005
120
0.0003
λ = 0.95
128
f=1.2 THz [13]

Fig. 3: Achievable rate with benchmarks schemes.

Fig. 2: PPO learning results (reward).

IV. SIMULATION RESULTS

In our network conﬁguration, we consider 3 UAVs and 36
GUs distributed by following homogeneous PPP within a 200 m
× 200 m area in each episode. Moreover, UAVs are assumed
to be hovering at a ﬁxed altitude of zk=20 m. The maximum
speed of the UAVs is 5 m/s. Other parameters are listed in Table
I. All statistical ﬁndings are averaged after several simulation
runs. To assess the performance of our proposed algorithm, we
consider four benchmark algorithms as follows:

• SU with RP: The algorithm which considers static UAVs
(SU) positions with the random power (RP) allocation.
• OU with RP: The algorithm uses the optimal UAVs (OU)

trajectory with the random power (RP) allocation.

• SU with PP: The algorithm assumes the static UAVs (SU)

positions with the proposed power (PP) allocation.

• OU with PP (proposed method): The algorithm considers
the optimal UAV (OU) trajectory with the proposed power
(PP) allocation.

Fig. 2 shows the convergence performance of the cumulative
reward with two power allocation schemes, i.e., optimal and
static. Initially, both schemes provide fewer rewards, but after
the convergence, the proposed schemes provide better results
than the static schemes.

Fig. 3 provides a comparison of the proposed algorithm (OU
with PP) with three benchmarks, i.e., SU with RP, OU with RP,
and SU with PP in terms of the average achievable rate for GUs.

Fig. 4: Achievable rate with UAVs.

It can be observed that OU with PP outperforms the rest of the
three algorithms just after a few time slots.

Moreover, Fig. 4 depicts the average achievable rate of GUs
by varying the number of deployed UAVs in the area. Since
all UAVs need to fulﬁll the QoS of GUs, and therefore, as
the number of GUs increases in the area, network performance
degrades. But, it can be observed that as the number of UAVs
increases, the average performance increases.

The resultant UAV trajectory with the proposed power and
GU allocation algorithm is shown in Fig. 5. It is clear that
the dots represent the GUs, and their clusters are separated
by distinct colors. Each UAV follows the PPO-DRL algorithm
to optimize its trajectory from an initialized location to the
endpoint in time slot n = 1 to n = 25. Each UAV follows a
distinct trajectory while providing optimal network resources
to the GU.

[5] K. M. S. Huq, J. Rodriguez, and I. E. Otung, “3D network modeling
for THz-enabled ultra-fast dense networks: A 6G perspective,” IEEE
Communications Standards Magazine, vol. 5, no. 2, pp. 84–90, June 2021.
[6] C. Chaccour, M. N. Soorki, W. Saad, M. Bennis, and P. Popovski,
“Can Terahertz provide high-rate reliable low latency communications
for wireless VR?” 2021.

[7] M. Mozaffari, W. Saad, M. Bennis, Y.-H. Nam, and M. Debbah, “A
tutorial on UAVs for wireless networks: Applications, challenges, and
open problems,” IEEE Communications Surveys Tutorials, vol. 21, no. 3,
pp. 2334–2360, 2019.

[8] S. S. Hassan, Y. M. Park, and C. S. Hong, “On-Demand MEC empowered
UAV deployment for 6G time-sensitive maritime internet of things,” in
proceedings of the 22nd Asia-Paciﬁc Network Operations and Manage-
ment Symposium (APNOMS), Tainan, Taiwan, Sep. 2021, pp. 386–389.
[9] Z. Yang, C. Pan, M. Shikh-Bahaei, W. Xu, M. Chen, M. Elkashlan,
and A. Nallanathan, “Joint altitude, beamwidth, location, and bandwidth
optimization for UAV-enabled communications,” IEEE Communications
Letters, vol. 22, no. 8, pp. 1716–1719, June 2018.

[10] J.-M. Kang and C.-J. Chun, “Joint trajectory design, Tx power allocation,
and Rx power splitting for UAV-enabled multicasting SWIPT systems,”
IEEE Systems Journal, vol. 14, no. 3, pp. 3740–3743, Jan. 2020.
[11] W. Wang, H. Dai, C. Dong, X. Cheng, X. Wang, P. Yang, G. Chen, and
W. Dou, “Placement of unmanned aerial vehicles for directional coverage
in 3D space,” IEEE/ACM Transactions on Networking, vol. 28, no. 2, pp.
888–901, Mar. 2020.

[12] X. Wang, P. Wang, M. Ding, Z. Lin, F. Lin, B. Vucetic, and L. Hanzo,
“Performance analysis of terahertz unmanned aerial vehicular networks,”
IEEE Transactions on Vehicular Technology, vol. 69, no. 12, pp. 16 330–
16 335, 2020.

[13] L. Xu, M. Chen, M. Chen, Z. Yang, C. Chaccour, W. Saad, and C. S.
location, bandwidth and power optimization for THz-
Hong, “Joint
enabled UAV communications,” IEEE Communications Letters, vol. 25,
no. 6, pp. 1984–1988, Mar. 2021.

[14] Z. Yuan and G.-M. Muntean, “AirSlice: A network slicing framework for
UAV communications,” IEEE Communications Magazine, vol. 58, no. 11,
pp. 62–68, Nov. 2020.

[15] H. Wang, J. Wang, G. Ding, J. Chen, Y. Li, and Z. Han, “Spectrum sharing
planning for full-duplex UAV relaying systems with underlaid D2D
communications,” IEEE Journal on Selected Areas in Communications,
vol. 36, no. 9, pp. 1986–1999, Aug. 2018.

[16] J. Hu, H. Zhang, L. Song, Z. Han, and H. V. Poor, “Reinforcement
learning for a cellular internet of uavs: Protocol design, trajectory control,
and resource management,” IEEE Wireless Communications, vol. 27,
no. 1, pp. 116–123, Mar. 2020.

[17] M. I. Malinen and P. Fr¨anti, “Balanced k-means for clustering,” in
Joint IAPR International Workshops on Statistical Techniques in Pattern
Recognition (SPR) and Structural and Syntactic Pattern Recognition
(SSPR). Springer, 2014, pp. 32–41.

[18] R. Burkard, M. Dell’Amico, and S. Martello, Assignment Problems.
Revised reprint. SIAM - Society of Industrial and Applied Mathematics,
2012, 393 Seiten.

[19] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, “Prox-
imal policy optimization algorithms,” arXiv preprint arXiv:1707.06347,
2017.

[20] J. Schulman, S. Levine, P. Abbeel, M. Jordan, and P. Moritz, “Trust
region policy optimization,” in Proceedings of the 32nd International
Conference on Machine Learning, F. Bach and D. Blei, Eds., vol. 37.
Lille, France: PMLR, 07–09 Jul 2015, pp. 1889–1897.
[Online].
Available: https://proceedings.mlr.press/v37/schulman15.html

Fig. 5: UAVs trajectory obtained by PPO-DRL.

V. CONCLUSIONS

In this article, we have explored THz-enabled UAVs to
facilitate ubiquitous 6G mobile communication networks. The
molecular absorption effect has been explicitly incorporated
in the THz-enabled UAV channel gain model. Then, we have
formulated an optimization problem to optimize the average
throughput of deployed UAVs by enhancing UAV-GU asso-
ciation, transmit power, and trajectories while satisfying the
GU’s demands. To address this problem, we have proposed
an iterative algorithm that separates the original problem into
three subproblems. Firstly, to tackle the UAVs-GUs association
problem, we have employed the BKMC algorithm. To deal with
the optimal transmit power, we have utilized the SCA-based
algorithm. To handle dynamic UAV trajectories optimization,
a PPO-DRL-based algorithm is has been designed, which can
make quick decisions in the given environment owing to its
low complexity. Based on the experience replay and target
networks, the PPO method has efﬁciently learned the optimal
trajectory with fast convergence speed. The simulation results
have shown that our proposed algorithms outperform the other
baselines.

REFERENCES

[1] W. Saad, M. Bennis, and M. Chen, “A vision of 6G wireless systems:
Applications, trends, technologies, and open research problems,” IEEE
Network, vol. 34, no. 3, pp. 134–142, June 2020.

[2] S. S. Hassan, Y. K. Tun, W. Saad, Z. Han, and C. S. Hong, “Blue data
computation maximization in 6G space-air-sea non-terrestrial networks,”
in proceedings of the IEEE Global Communications Conference (GLOBE-
COM), Madrid, Spain, Dec. 2021, pp. 1–6.

[3] S. S. Hassan, D. H. Kim, Y. K. Tun, N. H. Tran, W. Saad, and C. S. Hong,
“Seamless and energy efﬁcient maritime coverage in coordinated 6G
space-air-sea non-terrestrial networks,” arXiv preprint arXiv:2201.08605,
2022.

[4] Z. Zhang, Y. Xiao, Z. Ma, M. Xiao, Z. Ding, X. Lei, G. K. Karagiannidis,
and P. Fan, “6G wireless networks: Vision, requirements, architecture, and
key technologies,” IEEE Vehicular Technology Magazine, vol. 14, no. 3,
pp. 28–41, July 2019.

