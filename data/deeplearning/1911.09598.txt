SUBMITTED FOR REVIEW

1

Deep Learning Based Joint Resource Scheduling
Algorithms for Hybrid MEC Networks

Feibo Jiang, Kezhi Wang, Li Dong, Cunhua Pan, Wei Xu and Kun Yang

9
1
0
2

v
o
N
1
2

]
P
S
.
s
s
e
e
[

1
v
8
9
5
9
0
.
1
1
9
1
:
v
i
X
r
a

Abstract—In this paper, we consider a hybrid mobile edge
computing (H-MEC) platform, which includes ground stations
(GSs), ground vehicles (GVs) and unmanned aerial vehicle
(UAVs), all with mobile edge cloud installed to enable user
equipments (UEs) or Internet of thing (IoT) devices with intensive
computing tasks to ofﬂoad. Our objective is to obtain an online
ofﬂoading algorithm to minimize the energy consumption of
all the UEs, by jointly optimizing the positions of GVs and
UAVs, user association and resource allocation in real-time,
while considering the dynamic environment. To this end, we
propose a hybrid deep learning based online ofﬂoading (H2O)
framework where a large-scale path-loss fuzzy c-means (LSFCM)
algorithm is ﬁrst proposed and used to predict the optimal
positions of GVs and UAVs. Secondly, a fuzzy membership
matrix U-based particle swarm optimization (U-PSO) algorithm
is applied to solve the mixed integer nonlinear programming
(MINLP) problems and generate the sample datasets for the
deep neural network (DNN) where the fuzzy membership matrix
can capture the small-scale fading effects and the information of
mutual interference. Thirdly, a DNN with the scheduling layer is
introduced to provide user association and computing resource
allocation under the practical latency requirement of the tasks
and limited available computing resource of H-MEC. In addition,
different from traditional DNN predictor, we only input one UEs
information to the DNN at one time, which will be suitable for
the scenarios where the number of UE is varying and avoid the
curse of dimensionality in DNN.

I. INTRODUCTION

Computation intensive applications, such as face recogni-
tion, language processing, online gaming, augmented reality
(AR) and virtual reality (VR), have been fast developing and
increasingly outgrowing the limited capabilities of devices [1].
Thanks to the recent advancement of mobile edge computing

This work was supported in part by the National Natural Science Foundation
of China under Grant no. 41604117, 41904127, 41874148, 61620106011,
61572389 and 61871109. This work was also supported in part by the Royal
Academy of Engineering under the Distinguished Visiting Fellowship scheme
(DVFS21819\9\7) and by Scientiﬁc Research Fund of Hunan Provincial
Education Department in China under Grant no. 18A031

Jiang

Feibo

is with Hunan

(jiangfb@hunnu.edu.cn)

Provincial
Key Laboratory of
Intelligent Computing and Language Information
Processing, Hunan Normal University, Changsha, China, Kezhi Wang
is with the department of Computer
(kezhi.wang@northumbria.ac.uk)
Information Sciences, Northumbria University, UK, Li Dong
and
(Dlj2017@hunnu.edu.cn)
is with Key Laboratory of Hunan Province
for New Retail Virtual Reality Technology, Hunan University of Technology
and Business, Changsha, China, Cunhua Pan (Email: c.pan@qmul.ac.uk)
is with School of Electronic Engineering and Computer Science,
Queen Mary University of London, London, E1 4NS, UK, Wei Xu
(wxu@seu.edu.cn) is with NCRL, Southeast University, Nanjing, China, Kun
Yang (kunyang@essex.ac.uk) is with the School of Computer Technology
and Engineering, Changchun Institute of Technology, Changchun, China
and also with the School of Computer Sciences and Electrical Engineering,
University of Essex, CO4 3SQ, Colchester, UK.

Corresponding authors: Kezhi Wang and Kun Yang

(MEC) technology, the gap between the limited amount of
resource in devices and the demands for better experience is
being reduced [2], [3]. With the help of MEC, the UE can
ofﬂoad the intensive computations to the nearby edge servers
to save energy consumption and increase the computational
capacity [4], [5]. However, different from the traditional cloud
in data center, edge cloud may be implemented by the router,
switches, which may have some free computing resource and
are closer to the users. Recently, vehicle and UAV [6] based
MEC has also been proposed. Due to limited amount of the
computing resource in MEC and ﬁnite physical bandwidth
of wireless channels,
task admission control and resource
allocation are normally required, especially in the presence
of a large number of delay-sensitive tasks. The problem is
generally formulated as mixed integer nonlinear programming
(MINLP). To tackle the MINLP problem, branch-and-bound
algorithms [7] and dynamic programming [8] are normally
used to obtain the globally optimal ofﬂoading solution. How-
ever, the search spaces of both methods increase exponentially
with the network size and are computationally prohibitive
for large-scale MEC networks. To reduce the computational
complexity, heuristic local searching methods are proposed.
For instance, [9] proposed a coordinate descent (CD) method
that searches along one binary variable at a time. A similar
heuristic search method for multi-server MEC networks was
studied in [10], which iteratively adjusts binary ofﬂoading
decisions. Another widely adopted heuristic method is through
convex relaxation, e.g., by relaxing integer variables to be
continuous between 0 and 1 [11] or by approximating the
binary constraints with quadratic constraints [12].

Nonetheless, on one hand, the solution quality of reduced-
complexity heuristics is not guaranteed. On the other hand,
both searching-based and convex relaxation methods often
require a large amount of iterations for an algorithm to reach
a satisfying local optimum. Hence, they are unsuitable for
real-time processing in fast changing environment, as the
optimization problem needs to be re-solved once the number
and position of UEs have varied signiﬁcantly.

Recently, some artiﬁcial intelligence methods have emerged
as effective tools for enhancing MECs. In [13], the energy-
efﬁcient computation ofﬂoading management scheme in the
MEC system with small cell networks (SCNs) is proposed,
and a hierarchical genetic algorithm (GA) and particle swarm
optimization (PSO)-based heuristic algorithm are designed to
solve this problem. In [14], a deep learning (DL) algorithm
based on multi-long and short-term memory (LSTM) networks
is proposed to forecast the trafﬁc of small base stations (SBSs),
on the basis of which an ofﬂine mobile data ofﬂoading strategy

 
 
 
 
 
 
SUBMITTED FOR REVIEW

2

obtained through on cross-entropy is presented. In [15], a
conceptor-based echo state network is proposed to predict
content request distribution of users and its mobility pattern
when the network is available. Based on the prediction results,
the optimal positions of UAVs and the content to cache at
UAVs can be obtained. In [16], a distributed deep learning
ofﬂoading algorithm is introduced in MEC networks, where
multiple parallel DNNs are trained separately and applied to
make ofﬂoading decisions cooperatively. In [17], an emerging
deep neural network technique is used in the mobile crowd
sensing (MCS). The proposed technique employs convolu-
tional neural network for feature extraction, and then directs
the sensing and movement of UEs under the guidance of
the distributed multi-agent deep deterministic policy gradient
method. In [18], a deployment strategy for the distributed
multi-layer convolutional neural network is presented. The
strategy divides the convolutional neural network into two
parts: the preprocessing part and the classiﬁcation part. The
preprocessing part is deployed on the edge server for feature
extraction and compression of the image data so as to reduce
the data transmission between the edge server and the cloud
server.

Nonetheless, on one hand, the heuristic computation algo-
rithms have excellent global search ability and high calculation
accuracy, but they need long computing time. On the other
hand,
the supervised learning algorithms have outstanding
prediction and reasoning capabilities, but they require a large
amount of labelled training data.

In this paper, we consider a hybrid mobile edge computing
(H-MEC) platform, where there are ground stations (GSs),
ground vehicles (GVs) and unmanned aerial vehicle (UAVs),
all with edge cloud enhanced, which can enable UEs with
computational intensive tasks to ofﬂoad. We aim to obtain an
online ofﬂoading algorithm to minimize the energy consump-
tion of all the UEs, by jointly optimizing the positions of GVs
and UAVs, user association and resource allocation in real
time, while considering the dynamic environment. Towards
this end, we propose a hybrid deep learning based online
ofﬂoading (H2O) framework to achieve the above targets.
Compared with the existing integer programming and learning
based methods, we have the following novel contributions:

• We ﬁrst introduce a large-scale path-loss fuzzy c-means
(LS-FCM) clustering algorithm to locate the positions of
UAVs and GVs, which has two improvements compared
to the traditional FCM: First, it can ﬁx some cluster
centers denoted as GS positions and not allow them to
participate in the iteration process. Second, it introduces
the large-scale path-loss component to replace distance
in clustering process.

• We then introduce a fuzzy membership matrix U-based
particle swarm optimization (U-PSO) algorithm, which
can solve the task admission and resource allocation prob-
lem with different initial states. This procedure is repeated
until enough samples are collected. PSO can solve the
complex MINLP problems precisely and provide high
quality labeled samples to the DNN for ofﬂine training.
Additionally, a U-based roulette wheel selection strategy
is applied to guide the initial stage of PSO and provide

high quality initialsolution for accelerating convergence
of PSO, where the fuzzy membership matrix can capture
the small-scale fading and the information of mutual
interference.

• The DNN is applied for real-time decision-making. The
training stage is done by the collected samples from U-
PSO, by applying the continuous membership informa-
tion as the input for ofﬂoading action generation and
resource allocation. This hybrid mechanism keeps the
advantages of the PSO in ﬁnding global optimal solutions,
while speeding up the decision-making through DNN.
Besides, to generate an ofﬂoading action, the proposed
H2O framework only needs to input the membership
information of one UE each time. Compared to some
conventional deep learning methods that require to input
the information of all UEs, H2O is computationally
feasible and efﬁcient in large-size networks with different
number of UEs, which is suitable for continually dynamic
scenarios. Moreover, the online new input and output of
the DNN will be collected, recalculated and stored back
to the sample memory database, which is very important
for improving the performance of DNN in real scenarios.
• We further develop an additional scheduling layer of
DNN to check if the constraints are guaranteed. Also,
admission control is conducted in this layer. The H2O
framework is suitable for solving large-scale MINLP
problem in real-time. We ﬁnally evaluate the proposed
H2O framework under extensive numerical studies. The
experiment results of the proposed H2O are compared
with several different kinds of benchmark solutions,
which demonstrates the feasibility and effectiveness of
our framework. The simulation results have also shown
that our solutions have better computational efﬁciency
and accuracy. This can make real-time and optimal design
feasible in the H-MEC networks even in a fast changing
environment.

The remainder of this paper is organized as follows. In
Section II, we describe the system model and problem formu-
lation. We introduce the detailed designs of the H2O algorithm
in Section III. Numerical results are presented in Section IV.
Finally, the paper is concluded in Section V.

II. SYSTEM MODEL AND PROBLEM FORMULATION

Fig. 1 shows our proposed H-MEC networks with several
GSs, GVs and UAVs, all of which have edge server enhanced.
The locations of GSs are assumed to be ﬁxed whereas the
locations of GVs and UAVs can be optimized.

We consider that there are N UEs randomly distributed
in the ground, each of which has a computation task to be
executed. The set of UEs is denoted as N = {1, 2, · · · , N }.
Consider there are J UAVs, K GVs and M GSs, which can
enable the UEs to ofﬂoad the tasks. The sets of UAVs, GVs and
GSs are denoted as J = {1, 2, · · · , J}, K = {1, 2, · · · , K}
and M = {1, 2, · · · , M }, respectively. We use variables aL
i ,
aM EC
to denote the possible places where the UEs can
i,j
execute the tasks, where aL
denote the local
i

and aM EC

i,j

SUBMITTED FOR REVIEW

3

which means that each task must meet the latency requirement.
If this task is executed in UE itself, one has

Fi
f L
i

≤ T req

(7)

is the local executing capacity. Therefore, one can

(cid:88)

j∈{J ,K,M}

aM EC
ij

(

Di
rij

+

Fi
fij

) ≤ T req, ∀i ∈ N . (8)

where f L
i
have

aL
i

Fi
f L
i

+

Also, assume that the computing capacities in the UEs,

UAVs, GVs and GSs are limited as

i ≤ F L

i f L
aL
i,max, ∀i ∈ N
fij ≤ F M EC
j,max , ∀j ∈ {J , K, M}

aM EC
ij

(9)

(cid:88)

i∈N

where F L
i,max is the local computational capability of the i-th
UE, F M EC
j,max is the remote computational capability of the j-th
H-MEC. The power consumption in the i-th UE can be given
by

Fig. 1: The H-MEC network.

executing, and ofﬂoading to the H-MECs (including UAVs,
GVs and GSs), respectively. Then we have the following:

aL
i = {0, 1}, ∀i ∈ N
= {0, 1}, ∀i ∈ N , ∀j ∈ {J , K, M}

aM EC
ij

(1)

P ue

i =

(cid:40)(cid:80)

j∈{J ,K,M} aM EC
P E
i ,

ij

P T
ij ,

if ofﬂoading
if local execution

(10)

i = 0 otherwise, aM EC

where aL
i = 1 means that the i-th UE decides to execute the
task itself, and aL
= 1 means that the
i-th UE decides to ofﬂoad the task to the j-th UAV (when
j ∈ J ), or to the j-th GV (when j ∈ K), or to the j-th GS
(when j ∈ M), and aM EC
= 0 otherwise. It is assumed that
each task can be executed at most one place. Then, we have

ij

ij

i + Σj∈{J ,K,M} aM EC
aL

ij

= 1, ∀i ∈ N .

(2)

Similar to [19], we assume that

the i-th UE has the

computational intensive task Qi to be executed as follows:

Qi = (Fi, Di, T req), ∀i ∈ N

(3)

where Fi describes the total number of the CPU cycles of Qi
to be computed, Di denotes the data size transmitting to the
H-MECs if the ofﬂoading action is decided and T req is the
latency constraint or quality of service (QoS) requirement of
this task. Without loss of generality, in this paper, we consider
that all the tasks have the same time requirement T req. Di and
Fi can be obtained by using the approaches provided in [20].
If the task is selected to ofﬂoad, the execution time of the task
is given by:

T C
ij =

Fi
fij

(4)

where fij is the computation capacity of the j-th H-MEC
providing to the i-th UE. Also, the time to ofﬂoad the data is
given by:

T T r
ij =

Di
rij

(5)

where rij is the ofﬂoading data rate from the i-th UE to the
j-th place. Then, we can have:

ij is the transmitting power from the i-th UE to the
is the execution power in the i-th UE if

where P T
j-th H-MEC and P E
i
UE conducts the task itself and
i = ki(f L
P E

i )vi , ∀i ∈ N

(11)

Assume that

where ki ≥ 0 is the effective switched capacitance and vi ≥ 1
is the positive constant. To match the realistic measurements,
we set ki = 10−27 and vi = 3 [21].
the coordinates of

the j-
the j-th GV and the j-th GS are (xi, yi),
th UAV,
(X U AV
, Y GV
), re-
j
j
spectively. Then, the horizontal distance between the i-th UE
and the j-th UAV is given by

the i-th UE,

), and (X GS

, H U AV
j

, Y U AV
j

), (X GV

, Y GS
j

j

j

RU AV
ij

=

(cid:113)

(X U AV
j

− xi)2 + (Y U AV

j

− yi)2, ∀i ∈ N , ∀j ∈ J .

(12)
If UEs decide to ofﬂoad the task to UAVs, the data rate can

be given as

(cid:32)

rij = Blog2

1 +

(cid:33)

ij hU AV
P T
ij
σ2

, ∀i ∈ N , ∀j ∈ J

(13)

where B is the channel bandwidth, hU AV
nel quality information (CQI), denoted as hU AV

is the chan-
=

ij

ij

αU AV
j

(cid:16)(cid:113)

H U AV 2
j

(cid:17)−2

, αU AV
j

+ RU AV 2
ij
(cid:16)(cid:113)

is the small-scale
(cid:17)−2

H U AV 2
j

+ RU AV 2
ij

fading component,
is the large-
scale path-loss component [22]. Note that we assume that
the users ofﬂoad their tasks to UAV via orthogonal frequency
division multiplexing (OFDM) channels, which means that
there is no interference between each other. Similar to [23],
we assume that horizontal coverage of UAV is constrained by
the following

ij + T C
T T r

ij =

Di
rij

+

Fi
fij

≤ T req

(6)

RU AV
ij

≤ H U AV
j

tanφU AV
j

, ∀i ∈ N , ∀j ∈ J

(14)

SUBMITTED FOR REVIEW

4

where φj can be decided by the angle of antenna in the UAV
[23].

Then, the horizontal distance between the i-th UE and the

j-th GV is

(cid:113)

RGV

ij =

(X GV

j − xi)2 + (Y GV

j − yi)2, ∀i ∈ N , ∀j ∈ K.

(15)
If UEs decide to ofﬂoad to the GVs, the data rate can be

given as:

(cid:32)

rij = Blog2

1 +

(cid:80)

(cid:33)

P T
ij hGV
ij
kjhGV
k∈N k(cid:54)=i P T
kj + σ2
∀i ∈ N , ∀j ∈ K

,

where we assume the UEs share the same channel when they
decide to ofﬂoad to the same GV and there is interference
(cid:0)RGV
between them. hGV
is the small-scale
ij
fading component and (cid:0)RGV
(cid:1)−2
is the large-scale path-loss
component.

ij = αGV

, αGV
j

(cid:1)−2

ij

j

The horizontal distance between the i-th UE and the j-th

GS is as

(cid:113)

RGS

(X GS

ij =

j − xi)2 + (Y GS

j − yi)2, ∀i ∈ N , ∀j ∈ M.
(17)
If UEs decide to ofﬂoad to the GS, the data rate can be

given as

(cid:32)

rij = Blog2

1 +

P T
ij hGS
ij
kjhGS
k∈N k(cid:54)=i P T

(cid:80)

kj + σ2
∀i ∈ N , ∀j ∈ M

(cid:33)

,

(18)

ij = αGS

where hGS
component and (cid:0)RGS
nent.

ij

j

(cid:0)RGS
ij
(cid:1)−2

(cid:1)−2

, αGS
j

is the small-scale fading
is the large-scale path-loss compo-

i , aM EC
ij

Deﬁne the decision variables as A = {aL

}, ∀i ∈ N ,
∀j ∈ {J , K, M}, F = {fi, fij}, ∀i ∈ N , ∀j ∈ {J , K, M},
the location for UAV as W = {X U AV
}, ∀j ∈
J , and the location for GV as G = {X GV
}, ∀j ∈ K.
Then, one can formulate the energy minimization optimization
as

, H U AV
j
, Y GV
j

, Y U AV
j

j

j

P 1 : min

A,F,W,G

(cid:88)

(cid:88)

i∈N

j∈{J ,K,M}

aM EC
ij

P T
ij

Di
rij

+

(cid:88)

i∈N

i P E
aL
i

s.t.

(1), (2), (8), (9), (14).

Fi
f L
i

(19)

One can see that Problem (P 1) is an MINLP problem,
which is hard to solve in general. This is because the admission
decision A is binary while the resource allocation decision
F and locations of UAV W and GV G are continuous.
The major difﬁculty of solving P 1 lies in three aspects: (1)
large-scale mixed integer programming optimization, (2) real-
time decision-making and (3) the dynamic environment. To
circumvent these hurdles, we propose a novel H2O framework
by ﬁrst applying FCM clustering algorithm to get the positions
of GVs and UAVs. Then, DNN is trained ofﬂine by using
the samples obtained from PSO with the global search. After
that, DNN can be applied to make the real time decision,
based on the input of fuzzy membership information, even
in a fast changing environment. The important notations used
throughout this paper are summarized in TABLE I.

(16)

aL
i

aM EC
i,j

TABLE I: Notations used throughout this paper.

Notation

Description

N

The set of UEs

J , K, M The sets of UAVs, GVs and GSs

Local executing indicator

Ofﬂoading indicator

Transmitting power

Local execution power

The transmitting data size

The required number of the CPU cycles

Local executing capacity

Data rate

Channel quality information

The latency constraint

Computation capacity of the j-th H-MEC providing to
the i-th UE

The small-scale fading component

The large-scale path-loss component

Cluster center matrix

Weighting exponent of FCM

The number of clusters

Convergence threshold of FCM

P T
ij

P E
i

Di

Fi

f L
i

rij

hij

T req

fij

αj

R−2
ij

C

τ

c

ε

TF CM

The maximum iteration number of FCM

U

xi

vi

wmax

wmin

pg

P

Fuzzy membership matrix

Position vector of PSO

Velocity vector of PSO

The initial inertia weight of PSO

The ﬁnal inertia weight of PSO

The global best particle

The number of particles

TP SO

The maximum iteration number of PSO

θ

β

r(cid:96)

ui

Nc

Network parameters of DNN

The learning rate of DNN

The (cid:96)-th layer output of DNN

Fuzzy membership information of the i-th UE

The number of constraints

TCN N

The maximum iteration number of CNN

SUBMITTED FOR REVIEW

5

III. THE HYBRID DEEP LEARNING-BASED ONLINE
OFFLOADING FRAMEWORK

A. Algorithm Overview

In this section, we provide a novel algorithm named hybrid
deep learning based online ofﬂoading (H2O) to solve Problem
P 1. The structure of the H2O algorithm is illustrated in
Fig. 2, which is composed of four parts: GV and UAV
location optimization, sample collection, DNN ofﬂine learning
and DNN online decision. The main procedure of the H2O
algorithm is divided into the ofﬂine training phase and the
online optimization phase.

The ofﬂine training phase is carried out in the remote cloud
server with high computational and storage capabilities. We
regard the optimization problem P 1 as the mapping function
from the input system parameters to the output resource alloca-
tion solutions. We use a DDN to ﬁt this mapping function. To
this end, we need to ﬁnd the resource allocation solution under
certain system parameters. In other words, we need samples
to train the DNN. To this end, we provide one algorithm to
solve Problem P 1 to obtain the training samples. In speciﬁc,
we ﬁrst adopt the LS-FCM algorithm in Subsection-B to obtain
the locations of the UAVs and GVs. We then deploy the UAVs
and GVs according to the calculated locations. Then, we pro-
pose a novel U-PSO algorithm in Subsection-C to obtain the
ofﬂoading selection and resource allocation solution based on
the novel fuzzy membership information that can capture the
small-scale channel information and the relative interference
among the UEs. Finally, supervised learning algorithm is used
to train the DNN that can be applied for the scenarios where
the number of UEs is varying.

Then,

the trained DNN can be implemented for online
calculation. In particular, each UE only needs to input its mem-
bership values (detailed in Subsection-C), then the DNN can
output its ofﬂoading choice and computing resource allocation
result. This has much lower computational complexity since
it only needs to perform some simple algebraic calculations
instead of solving the original optimization problem through
high-complexity heuristic algorithms. In addition, during the
online implementation, some results output by the DNN will
be regarded as new samples and be stored in the database at
the cloud. These samples will be used for ofﬂine training and
to update the DNN. This is very important since it can track
the variations of the real scenarios.

In the following, we provide more details of each step of

the H2O algorithm.

B. Location optimization based on LS-FCM

Clustering algorithm is always applied to determine the
locations of UAVs [15], but it cannot be directly used in our
work. First, the positions of GSs are ﬁxed, but the positions
of GVs and UAVs are varying. The conventional clustering
method did not consider the case when some points are
ﬁxed. Second, the iterative process of conventional FCM only
considers the distances between UEs and MECs, and does
not consider CQI between them. To solve these problems,
we propose a novel large-scale path-loss fuzzy c-means (LS-
FCM) algorithm to locate the positions of UAVs and GVs,

which has two advantages: First, it can ﬁx some cluster centers
denoted as GS positions and not allow them to participate in
the iteration process. Second, it introduces the large-scale path-
loss component to replace distance in clustering process.

FCM clustering is a data clustering method in which each
data point belongs to a fuzzy cluster, with a degree speciﬁed
by a membership grade. FCM partitions a collection of n data
point zi into fuzzy clusters. In our study, zi is the i-th data
point which denotes the position (xi, yi) of the i-th UE.

Speciﬁcally, the objective function of LS-FCM is expressed

in the following:

(cid:88)

(cid:88)

G =

(µij)τ d(cid:48)
ij

i∈N

j∈{J ,K,M}

(20)

ij = 1/R−2

where d(cid:48)
ij denotes the large-scale path-loss com-
ponent, µij denotes the fuzzy relationship between the i-
th UE and the j-th MEC. Here, Cj is denoted as the j-th
cluster center which denotes the position of the j-th H-MEC
(including UAVs, GVs and GSs). τ (τ > 1) is a scalar termed
as the weighting exponent that controls the fuzziness of the
resulting clusters. To minimize the criterion G, the centroid Cj
is updated according to Eq. (21), and µij is updated according
to Eq. (22), respectively,

Cj =

(cid:80)
i∈N (µij)τ zi
i∈N (µij)τ , ∀j ∈ {J , K, M},
(cid:80)

and

µij =

1
(cid:16) d(cid:48)
ij
d(cid:48)

ik

,

(cid:17) 2

τ −1

(cid:80)c

k=1

(21)

(22)

where c is the number of clusters.

µij and Cj are calculated iteratively through these two
equations until the FCM algorithm converges. Based on the
solutions of C = [Cj], we can decide the locations of UAVs
and GVs. The reason why we use FCM to locate the position
of UAVs and GVs is that the LS-FCM clustering algorithm
aims at minimizing the total large-scale path loss of all UEs
as seen in Eq. (20), which implicitly reduces the system energy
shown in the objective function of Problem (19).

Finally, a hard classiﬁcation is adopted by assigning each
UE solely to the cluster with the highest µij. In the LS-
FCM, since the GS positions are ﬁxed, some cluster centers
are set to the GS positions in advance and are not allowed
to participate in the iteration process. According to the hard
classiﬁcation, the cluster centers are sorted in a descending
order according to the total required computing resources of
all UEs in this cluster. Then the centers of the cluster are
assigned to GVs and UAVs based on their available computing
the ﬁrst center of the cluster is
resources. For example,
assigned to the H-MEC with the most computing resources,
the last center of the cluster is assigned to the H-MEC with the
least computing resources. Please note that this is not the ﬁnal
computing ofﬂoading solution. This stage just provides a rough
estimation of computing resource needed by all UEs in each
cluster. This LS-FCM just provides the locations for each H-
MEC. Although, some UEs are in one H-MEC’s cluster, these
UEs may not be ofﬂoaded to this H-MEC since the small-
scale fading are not considered in LS-FCM. The ofﬂoading

SUBMITTED FOR REVIEW

6

Fig. 2: The proposed H2O framework.

selection and computing allocation will be studied in the next
subsection.

Several stopping rules can be used in LS-FCM. One is to
terminate the algorithm when the maximum iteration num-
ber TF CM is reached or when the variation of objective
function∆G is less than threshold ε.

The detailed description of LS-FCM algorithm is provided

in Algorithm 1.

Algorithm 1 LS-FCM algorithm
Input: GS positions, UE positions, ε, c, τ , TF CM .
Output: C.

1: Initialize the locations of cluster centers. Calculate µij

according to Eq. (22).

2: Fix some centers of C according to the GS positions.
3: ∆G(1) = 1, G(0) = 0, t = 1.
4: while |∆G(t)| > ε and t < TF CM do
5:

Calculate the remaining cluster centers of matrix C
using Eq. (21).
Calculate the objective function G(t) using Eq. (20).
Update each µij using Eq. (22).

6:
7:
8: ∆G(t) = G(t) − G(t − 1).
9:
10: end while

t = t + 1.

C. Computing ofﬂoading selection and computing resource
allocation based on U-PSO

When the locations of UAV and GV are determined by the
LS-FCM algorithm, we need to optimize the computing of-
ﬂoading decision for each UE and the corresponding allocated
computing resources based on both the large-scale path-loss
and small-scale channel fading information. This topic will be

studied in this subsection. Heuristic algorithms are always used
to solve the complex MINLP problem and obtain high-quality
global solution [13]. However, heuristic algorithms also exhibit
some issues: it takes more calculation time than traditional
gradient descent method when you want to achieve similar
accuracy and the convergence speed decreases considerably
in the later period of evolution. So the heuristic algorithm
is fundamentally infeasible for real-time system optimization
under fast changing environment. In this paper, we propose a
U-PSO, in which we use PSO algorithm to generate samples
for DNN ofﬂine training and then use trained DNN to make
online task admission and resource allocation decision.

PSO is a heuristic computation technique that was originally
proposed by Eberhart and Kennedy [24]. The standard PSO
can be described as follows. Consider a swarm with P
particles, each particle is a candidate solution and it moves
in a bounded p-dimensional search space. The position vector
and velocity vector of the i-th particle are represented as xi =
(xi1, xi2, · · · , xip) and vi = (vi1, vi2, · · · , vip), respectively.
PSO explores the search space by modifying the velocity of
each particle, according to two attractors: the best position
found so far by the particle itself pbi, and the best position
identiﬁed so far by the whole swarm pg. By integrating these
two attractors, the particle behavior can be modeled by using
the following equations:

vid(t + 1) =w(t)vid(t) + ccog · rand1(pbid(t) − xid(t))
+ csoc · rand2(pgd(t) − xid(t))

(23)

xid(t + 1) = xid(t) + vid(t + 1)

(24)

where ccog is the cognitive factor and csoc is the social factor;
rand1 and rand2 are generated randomly between 0 and 1;
pbid(t) is the best position of the i-th particle at iteration t;

SUBMITTED FOR REVIEW

7

pgd(t) is the best particle position among all the particles at
iteration t; d=1,2,,p. w(t) is the inertia weight. Typically, the
inertia weight is set according to [25]:

w(t) = wmax − (wmax − wmin) · t/Tpso

(25)

where wmax is the initial inertia weight, wmin is the ﬁnal
inertia weight, Tpso is the maximum iteration number.

The energy-efﬁcient admission of delay-sensitive tasks is a
complex MINLP problem, using traditional PSO algorithm to
solve this problem has three drawbacks that avoids its direct
application in our considered optimization problem. Firstly,
PSO algorithm often employs continuous real-valued encod-
ings, but the admission decision matrix A is a matrixwith
integer elements equal to 0 or 1; Second, traditional PSO
did not need to check the constraints; Third, traditional PSO
initializes the particle population randomly, and it does not
take advantage of the CQI information. In this regard, we
propose a new U-based particle swarm optimization (U-PSO)
algorithm to solve the MINLP problem efﬁciently.

Firstly, we improve the coding of particle. In our U-PSO

algorithm, the particle can be represented as:

information, so it can output a novel fuzzy membership matrix,
which includes the CQI and interference information for
UEs. The fuzzy membership matrix is very important in our
framework. It can not only be used here for generating the
initial point of the U-PSO algorithm, but also serves as the
input as the DNN discussed in the next subsection.

we deﬁne the novel fuzzy membership matrix U = [uij]
including the small-scale fading and interference information,
then we update the fuzzy membership matrix in the dynam-
ically changing environment. The membership degree uij is
expressed as following:

uij =

1
(cid:16) h(cid:48)
ij
h(cid:48)

ik

,

(cid:17) 2

τ −1

(cid:80)c

k=1

(28)

(cid:16)

(cid:17)

kj

/P T

ij αjR−2
ij

kjαjR−2

γ (cid:80)
k∈N ,k(cid:54)=i P T
where h(cid:48)
ij =
is an
enhanced version of d(cid:48)
ij, which includes the small-scale fading
component αj for the j-th MEC and the referenced interfer-
ence information (cid:80)
kj , ∀j ∈ {K, M}, and
γ is the trade-off factor. The fuzzy membership matrix U
can reﬂect the changes of channel and the interferences of
environment in real time.

k∈N ,k(cid:54)=i P T

kjαjR−2

x =[a1, a2, · · · , ai, · · · , aN , f1, f2, · · · , fi, · · · , fN ]

= [xa, xf ]

(26)

By using the updated dynamic membership information
deﬁned in Eq. (28), we now can obtain the probability of UE
i to select H-MEC j is given by

where ai = 0 means that the i-th UE decides to execute the
task itself, and ai = k means that the i-th UE decides to
ofﬂoad the task to the k-th H-MEC, while k ∈ {1, 2, · · · , J +
K + M }. fi ∈ R means the allocated resource to the i-th UE.
If ai = 0, fi = f L
i . This representation transforms the decision
matrix A and resource allocation matrix F to a tersecoding
for PSO. Then we can round xa part of the particle after each
iteration.

Secondly, we add a constraintcheck step evaluating each
particle. If a particle leads to constraintviolation, we will
assign a large penalty ρ to the ﬁtness value which is set to
be equal to the objective function of (19).

Thirdly, the ﬁnal solution of the U-PSO algorithm mainly
depends on the initial input of the algorithm. Improper se-
lection of the initial point may cause the ﬁnal solution to be
stuck at a locally optimal point with low performance. Hence,
it is critical to select a good initial point. In this paper, we
use U-based roulette wheel selection strategy to provide high-
quality initialsolution for accelerating convergence. However,
to implement the U-based roulette wheel, we need to know
the probability of each UE to select which H-MEC to ofﬂoad.
One intuitive method is to use the parameter µij in (22) after
the LS-FCM algorithm in the above subsection. In speciﬁc,
the probability of the i-th UE to select the j-th H-MEC is
given by

pij =

µij

(cid:80)

.

µik

pij =

uij

(cid:80)

.

uik

k∈{J ,K,M}

(29)

With the probability values, we can now employ the U-
based roulette wheel
to initialize the initial solution. For
example, suppose there are ﬁve H-MECs that UE i can choose
to ofﬂoad (three UAVs, one GV and one GS), in Fig. 3 the
circumference of the roulette wheel is equal to one. UAV1
is the most ﬁt individual and has the largest probability to
be selected, whereas GS and GV are the least ﬁt and have
smaller intervals within the roulette wheel. To select a H-MEC,
a random number is generated in the interval [0,1], and the
H-MEC whose segment spans the random number is selected
and UE i will ofﬂoad its task to this H-MEC. This process
is repeated until all UEs have selected their H-MECs. Then
based on the ofﬂoading decision, the resource of each H-MEC
is allocated evenly to its associated UEs. The process of U-
PSO algorithm is present in Algorithm 2.

The fuzzy membership matrix U which captures small-scale
fading and mutual interference information plays a key role in
our H2O framework. The fuzzy membership matrix U can
not only guide the initialization of U-PSO, but also provide
a concise representation of the relationship between UEs and
H-MECs, which will be a perfect input of DNNs.

(27)

D. Ofﬂine DNN training and online implementation

k∈{J ,K,M}

However, this selection does not capture the instantaneous
small-scale channel information and interference among the
UEs. To resolve this issue, we provide a novel fuzzy mem-
bership matrix based method. It applies the small-scale fading
and interference information to generate dynamic membership

Given the locations of UAVs and GVs, the Problem P 1
can be regarded as an unknown function mapping from the
fuzzy membership matrix U to the optimal task admission
A = [a1, a2, · · · , ai, · · · , aN ] and resource allocation F =
[f1, f2, · · · , fi, · · · , fN ], namely.

F : U ∈ RN ×(J+K+M ) → [A, F] ∈ RN ×2

(30)

SUBMITTED FOR REVIEW

8

TABLE II: activation functions of DNN.

Name

ReLU

tanh

sigmoid

softmax

σ(vi)

Range

max(0, vi)

[0, ∞)

evi −e−vi
evi +e−vi

1
1+e−vi

evi
j e−vi

(cid:80)

(−1, 1)

(0, 1)

(0, 1)

TABLE III: loss functions of DNN

Name

L(p, r)

Fig. 3: Roulette wheel selection strategy.

Algorithm 2 U-PSO algorithm
Input: H-MEC positions, UE positions, P , ρ, wmax, wmin,

Tpso.
Output: pg.
1: Calculate the dynamic fuzzy membership matrix U using

Eq. (28).

2: Initialize the particle population by using the U-based

roulette wheel selection strategy according to U.

3: while t < Tpso do
4:

5:

6:

7:
8:

Calculate the ﬁtness value of each particle using Eq.
(19).
Check the constraints and assign the penalty ρ to the
particle with constraintviolations.
Save the global best particle pg of the swarm.
Save the individual best pbi of each particle.
Update the velocity of each particle using Eq. (23) and
Eq. (25).
Update the position of each particle using Eq. (24).
Round the xa part of each particle.
t = t + 1.

9:
10:
11:
12: end while

where ai = 0 means the i-th UE decides to execute the task
itself, ai = k means the i-th UE decides to ofﬂoad the task to
the k-th H-MEC, while k ∈ {1, 2, · · · , J + K + M }. fi ∈ R
means the allocated resource to the i-th UE. If ai = 0, fi =
f L
i .
Considering that DNN is a universal function approximator,
we use DNN to learn the unknown function mapping. The
DNN with L layers describes a mapping f (r0; θ) ∈ RN0 →
rL ∈ RNL of an input vector r0 ∈ RN0 to an output vector
rL ∈ RNL through L iterative processing steps:

r(cid:96) = f(cid:96)(r(cid:96)−1; θ(cid:96)), (cid:96) = 1, · · · , L
(31)
where r(cid:96) ∈ RN(cid:96) is the output of the (cid:96)-th layer. θ(cid:96) is a set
of parameters of the (cid:96)-th layer. The (cid:96)-th layer is called fully-

MSE
Categorical cross-entropy − (cid:80)

||p − r||2
2

j pj log(rj )

connected if f(cid:96)(r(cid:96)−1; θ(cid:96)) has the form

f(cid:96)(r(cid:96)−1; θ(cid:96)) = σ(W(cid:96)r(cid:96)−1 + b(cid:96))

(32)

where W(cid:96) ∈ RN(cid:96)×N(cid:96)−1 is the weights of the (cid:96)-th layer, b(cid:96) ∈
RN(cid:96) is the thresholds of the (cid:96)-th layer. The set of parameters
for this layer is θ(cid:96) = {W(cid:96), b(cid:96)}. We use θ = {θ1, · · · , θL}
to denote the set of all parameters of the DNN. σ(·) is an
activation function. Some commonly used activation functions
are ReLU, tanh, sigmoid and softmax listed in TABLE II [26].

In order for the DNN to learn the desired input-output map-
ping, it is necessary to tune the parameters θ in a supervised
learning fashion. We deﬁne the loss function L(p(n), r(n)
L ) that
is used to measure the loss between the desired output p(n)
and the actual output r(n)
L . The goal of the training process
is to tune the network parameters θ in order to minimize the
average loss, deﬁned by

L(θ) =

1
Nt

Nt(cid:88)

n=1

L(p(n), r(n)
L )

(33)

where Nt is the number of DNN samples. Several relevant loss
functions are represented in TABLE III [27]. This minimiza-
tion problem can be tackled by (stochastic) gradient descent
methods, i.e. iteratively updating the parameters θ = {W , b}
according to the formulas:

θ(t + 1) = θ(t) − β∇L(θ(t))

(34)

where β is the learning rate, and the gradients are conveniently
estimated based on random subsets of the complete training
set, called mini-batches and leveraging the back-propagation
algorithm [26].

Once the parameters W and b to be used are determined as
a result of the training process, the DNN is conﬁgured and able
to compute task admission and resource allocation directly.
This means that once the small-scale channel information is
changing, the task admission and resource allocation of UEs
are updated by a simple feedforward computing of the DNN
through performing some simple algebraic calculations, in-
stead of solving Problem P 1 through high-complexity heuris-
tic algorithms. This yields a signiﬁcant complexity reduction.

SUBMITTED FOR REVIEW

9

However, there are still two open problems in the design
of DNN model for our system. First, the number of UEs
accessing the network is time-varying, so the size of U is
ever-changing and we cannot obtain a group of uniﬁed samples
with the same dimensionality. Second, the Problem P 1 is a
constrainedoptimization problem, but traditional DNN cannot
guarantee the task constraints. With this regard, we propose a
novel DNN with a scheduling layer. The main improvements
of this new network are listed as follows.

Firstly, to model an efﬁcient DNN for large-scale UEs, we

change function mapping F to F1:

F1 : ui ∈ R(J+K+M ) → [ai, fi] ∈ R2, ∀i ∈ N

(35)

where ui = [ui1, ui2, ..., uic] represents the membership
vector of the i-th UE, ai and fi represents the task admission
value and resource allocation value of the i-th UE, respectively.
ai = 0 means the i-th UE decides to execute the task itself,
ai = k means the i-th UE decides to ofﬂoad the task to the k-
th H-MEC, while k ∈ {1, 2, · · · , J + K + M }, fi ∈ R means
the allocated resource to the i-th UE. If ai = 0, fi = f L
i . This
modiﬁcation has the following beneﬁts. The input dimension
of the DNN only depends on the number of H-MECs and
is not related to the number of UEs. In general, the number
of access points or H-MECs changes much slower than the
number of UEs accessing the network. Hence, our DNN can
be applied in a long time once it has been trained, which is
more practical. Reducing the dimension of input data can also
reduce the training complexity, which is suitable for large-
scale networks with large number of UEs.

Secondly, in order to guarantee task constraints, we propose
a novel DNN structure with a scheduling layer after DNN
training. As shown in Fig. 4, this scheduling layer includes
a constraint layer and a decision layer, the constraint layer
is used to check whether the output ai and fi satisfy the
constraints or not and each node in this layer represents a
constraint check. The output of the j-th node in the constraint
layer can be represented as:

rL+1,j = gj(ai, fi)

(36)

where gj is the j-th constraint check function. If the output
layer of the DNN satisfy theconstraint, the function outputs 1
to the next layer, else outputs 0 to the next layer.

The node in the decision layer is labeled as Π, indicating
that they play the role of a simple multiplier. If the output
layer of the DNN doesnt satisfy all constraints,
the ﬁnal
output rL+2 = 0, which means UE executethe tasklocally
(ai = 0, fi = f L
i ), else the ﬁnal output of the DNN is
rL+2 = rL. The decision layer can be represented as:

rL+2 = rL · ΠNc

j=1rL+1,j

(37)

where Nc is the number of constraints. The detailed pro-
cess of the DNN with the scheduling layer is shown in
Algorithm 3.

The online implementation of the algorithm is as follows.
Once the DNN is trained by the supervised learning method.
Each UE only needs to input its fuzzy membership values into
the DNN, and it will output the resource allocation solution

with some simple algebraic calculations, which is much faster
than the high-complexity heuristic algorithms. Once one new
UE is accessing the network, we need to execute the FCM
algorithm to obtain the new locations of the H-MECs and then
this UE calculates its fuzzy membership values based on the
small-scale channel information and instantaneous interference
power. Then, this UE inputs the calculated membership values
into the trained DNN, and it will output the resource allocation
solution. Hence, our proposed algorithm is very suitable for
dynamic scenarios where the number of UEs is varying, which
is more practical for implementation.

In addition, the feedback mechanism is applied to H2O
framework for online implementation. In practical terms, we
use a differential check method to realize the feedback mecha-
nism. When the new data is inputted to the DNN, we check the
difference between the new data and the existing samples in
the database, which is evaluated by the Euclidean distance. If
there is a big difference between the new data and the existing
samples, the new data will be fed back to the U-PSO and
resolved as a new sample.

Algorithm 3 DNN with a scheduling layer algorithm
Input: U, β, N , TCN N .
Output: θ, rL+2.

Training stage :

1: Randomly initialize network parameters θ.
2: while t < TCN N do
3:

Calculate the feedforward of DNN according to Eqs.
(31)-(32) for all layers.
Calculate the loss function according to Eq. (33).
Update of DNN according to Eq. (34).
t = t + 1.

5:
6:
7: end while
8: Serialize U into a set of ui according to the UE number

4:

N .
Decision stage :

9: while i < N do
10:

11:

12:

Calculate the output ai and fi of the DNN based on
the trained θ according to the input ui.
Check the output of DNN by the constraint
according to Eq. (36).
Calculate the decision output rL+2 by the decision layer
according to Eq. (37).
i = i + 1.

layer

13:
14: end while

IV. SIMULATION RESULTS

In this section, we use simulations to evaluate the perfor-
mance of the proposed H2O algorithm. In all simulations,
we use three UAVs, one GV and one GS. Other parameters
used in the simulations are summarized in TABLE IV, unless
otherwise speciﬁed. The parameters of the LS-FCM method
are chosen as follows: τ = 2, ε = 0.0001, TF CM = 100;
The parameters of the U-PSO method are chosen as follows:
P = 10, ρ = 100, wmax = 0.9, wmin = 0.4, TP SO = 100;
The parameters of the DNN method are chosen as follows:

SUBMITTED FOR REVIEW

10

Fig. 4: DNN with the scheduling layer.

TABLE IV: Simulation parameters

Parameters

Macrocell Radius
GS Coordinate

Bandwidth B
Transmitting Power P T
ij

Input Data Size Di

Assumptions

100m
[50,50]

1MHz

1W

100kB

Required Number of CPU Cycles f L
i
Local Computational Capability F L
Latency Request T req

max

UAV Altitude H U AV

Remote Computational Capability (UAV)

Remote Computational Capability (GV)

Remote Computational Capability (GS)

109 cycles/s

109 cycles/s

2s

20m
1010 cycles/s

1011 cycles/s

1012 cycles/s

β = 0.4, TDN N = 500, the activation function is set to ReLU
and function is set to MSE.

Apart from the proposed task admission algorithm, we also

simulate the following algorithms for comparison purposes.

• Random ofﬂoading (Random):

the task admission is
decided randomly for each UE. If the computational
resources of the allocated H-MEC are insufﬁcient, UE
execute the task locally.

• Greedy ofﬂoading (Greedy): all UEs ofﬂoad the task to
the nearest H-MEC, if the computational resources of the
allocated H-MECs are insufﬁcient, the UEs who need
more computational resources of the H-MECs execute
the task locally.

• Local execution (Local): There is no ofﬂoading. All tasks

are executed locally.

• PSO ofﬂoading (PSO): the task admission is optimized

by the U-PSO method.

All sample vectors in the dataset are split randomly into a

training set and a testing set. 80 percent of the sample vectors
are assigned into the training set, while 20 percent of the
sample vectors are assigned into the testing set. Then cross
validation method [28] is used to evaluate the performance
of DNN. In Fig. 5, we compare the performance of DNN
with different number of hidden nodes in hidden layer, as
the number of hidden layers varies from 1 to 8. With the
increase of hidden layer number, the testing loss of DNN
with 20 hidden nodes and 30 hidden nodes ﬁrst decrease
and then stabilize when the hidden layer number is above 6.
This is because increasing hidden nodes and hidden layers can
enhance the learning ability of DNN and allow the DNN to
learn more information. The DNN with 30 hidden nodes of
each hidden layer achieves the minimum testing loss when the
hidden layer number is above 6. Notice that the testing loss
of DNN with 10 hidden nodes ﬁrst decrease and then increase
when the hidden layer number is above 4. This is dueto the
conceptofoverﬁtting and the DNN cannot improve its learning
ability when the hidden nodes is too less. For this reason, in
the follow simulations, we set the hidden layer number equal
6, the hidden nodes number equal 30.

In Fig. 6, we plot the training loss and testing loss of DNN.
It is clearly seen that the testing loss declines sharply at the
beginning of procedure, then decreases slowly and stabilize
at around 0.07 when t is above 300. Meanwhile, the training
loss gradually decreases and stabilizes at around 0.06, whose
value is less than the testing loss curve. In Fig. 7, we further
study the errordistribution of all samples for the DNN. We
see that 70% of the training errors are less than 0.025 and the
maximum error is less than 0.47. The samesituationapplies to
the error distribution of the testing samples. The simulation
results demonstrate the effectiveness of the proposed DNN
which can quickly converge to an optimal decision model for
our ofﬂoading problem.

In Fig. 8, we compare the performance of DNN trained
by different samples under varying time slots. Before the
evaluation, DNN has been trained with 10000 independent

SUBMITTED FOR REVIEW

11

samples generated from different algorithms (the proposed
PSO, Greedy and Random), and the error curve has converged.
We see that DNN achieves optimal performance with the
samples generated from the proposed PSO (PSO+DNN), and
signiﬁcantly outperforms the DNN with the greedy ofﬂoading
samples (Greedy+DNN) and the random ofﬂoading samples
(Random+DNN). This is because the performance of DNN
depends on the quality of samples. The proposed PSO can
solve the ofﬂoading problem by a heuristic global search and
achieve a high quality global solution, which guarantee the
good performance of DNN from the learning stage.

We then evaluate the performance of 30 independent ran-
dom scenarios for time slots prediction. We see that DNN with
the samples generated from the proposed PSO can achieve
the best performance under all time slots. This is because the
trained DNN has good generalization performance, and can
make the ofﬂoading decision continuously in fast changing
environments.

Fig. 5: The comparison of testing loss of DNN with different
hidden layer number and different hidden nodes number.

Fig. 6: The testing loss and training loss of DNN.

Fig. 7: The training and testing errordistribution of all
samples for the DNN.

Fig. 8: The comparison of average energy consumption of
DNN trained by different samples under varying time slots.

In Fig. 9, we compare the average energy consumption
between the proposed method, PSO, Greedy, Random and
Local, as the number of devices varies from 10 to 100. As
shown in the Fig. 9, the average energy consumptions of
all methods increase gradually while the number of devices
increases. PSO method achieves the lowest average energy
consumption. The proposed method provides almost the same
energy consumption compared as PSO. This is because the
proposed method is a DNN model trained by a set of high
quality global solutions generated by PSO and construct a
nonlinear mapping from UE and MEC information to ofﬂoad-
ing decision. Greedy method saves more energy than Random
method. The energy consumption of Local is highest, since
Local does not admit any devices.

Fig. 10 shows the number of admitted devices (the devices
who decide to ofﬂoad the tasks) achieved by the proposed
method, Greedy, Random and Local, where the number of
devices range from 10 to 100. We can see that the proposed
method admit the most devices for ofﬂoading. Greedy can

SUBMITTED FOR REVIEW

12

admit more devices for ofﬂoading than Random. In contrast,
Local does not admit any device. Fig. 11 shows the number of
admitted devices achieved by the proposed method, Greedy,
Random and Local, where T req ranges from 1s to 3s. We can
see the similar results again, there may be some interesting
conclusions that, for achieving the goal of minimum energy,
the number of admitted devices increases as the number of
devices varies from 10 to 100 or T req varies from 1s to 3s.

Fig. 10: The comparison of average admitted devices as the
number of devices varies from 10 to 100.

Fig. 9: The comparison of average energy consumption as
the number of devices varies from 10 to 100.

Finally, we evaluate the computation time of the proposed
algorithm. The computational complexity of all algorithms
greatly depends on the number of uses. Fig. 12 compares
runtime between the proposed method and PSO. We can see
the proposed method is superior in terms of time efﬁciency. In
particular, it generates an ofﬂoading action in less than 0.03
second when N equals to 100, while PSO takes 80 times
longer CPU time. Overall, trained DNN achieves similar per-
formance as PSO algorithm but requires substantially less CPU
time. This makes real-time ofﬂoading and resource allocation
viable for H-MEC networks in fast changingenvironment.

V. CONCLUSION
In this paper, we have proposed a hybrid deep learning
based online ofﬂoading algorithm, H2O,
to minimize the
sum energy consumption of UEs in a H-MEC network with
binary computation ofﬂoading. The framework includes three
artiﬁcial intelligence algorithms: an LS-FCM method is used
to locate the GVs and UAVs, a U-PSO is used to solve
the MINLP problem and provide high quality samples to
DNN, a DNN with a scheduling layer is applied to make
the task admission and resource allocation decision in real
time. Compared to conventional optimization methods, the
proposed H2O algorithm completely removes the need of
solving MINLP problems in the decision period of DNN.
Simulation results show that H2O achieves similar near-
optimal performance as heuristic methods but reduces the CPU
time by more than several orders of magnitude, making real-
time system optimization feasible for the H-MEC networks in
fast-changing environment.

Fig. 11: The comparison of average admitted devices as T req
varies from 1s to 3s.

REFERENCES

[1] T. Soyata, R. Muraleedharan, C. Funai, M. Kwon, and W. Heinzelman,
“Cloud-vision: Real-time face recognition using a mobile-cloudlet-cloud
acceleration architecture,” in Proc. IEEE Symp. Comput. Commun.
(ISCC), July 2012, pp. 59–66.

[2] W. Zhang, Y. Wen, J. Wu, and H. Li, “Toward a uniﬁed elastic computing
platform for smartphones with cloud support,” IEEE Network, vol. 27,
no. 5, pp. 34–40, Sep. 2013.

[3] X. Lyu, W. Ni, H. Tian, R. P. Liu, X. Wang, G. B. Giannakis, and
A. Paulraj, “Optimal schedule of mobile edge computing for internet
of things using partial information,” IEEE J. Select. Areas Commun.,
vol. 35, no. 11, pp. 2606–2615, Nov 2017.

[4] X. Wang, K. Wang, S. Wu, S. Di, H. Jin, K. Yang, and S. Ou, “Dynamic
resource scheduling in mobile edge cloud with cloud radio access
network,” IEEE Trans. Parallel Distrib. Syst., vol. 29, no. 11, pp. 2429–
2445, Nov 2018.

[5] J. Wang, J. Hu, G. Min, W. Zhan, Q. Ni, and N. Georgalas, “Computation
ofﬂoading in multi-access edge computing using a deep sequential model
based on reinforcement learning,” IEEE Commun. Mag., vol. 57, no. 5,
pp. 64–69, May 2019.

[6] Y. Du, K. Wang, K. Yang, and G. Zhang, “Energy-efﬁcient resource
allocation in uav based mec system for iot devices,” in Proc. IEEE
Glob. Commun. Conf. (GLOBECOM), Dec 2018, pp. 1–6.

SUBMITTED FOR REVIEW

13

[21] A. P. Miettinen and J. K. Nurminen, “Energy efﬁciency of mobile clients
in cloud computing.” HotCloud, vol. 10, no. 4, pp. 4–19, 2010.
[22] X. Chen, “Decentralized computation ofﬂoading game for mobile cloud
computing,” IEEE Trans. Parallel Distrib. Syst., vol. 26, no. 4, pp. 974–
983, April 2015.

[23] H. He, S. Zhang, Y. Zeng, and R. Zhang, “Joint altitude and beamwidth
optimization for uav-enabled multiuser communications,” IEEE Com-
mun. Lett., vol. 22, no. 2, pp. 344–347, Feb 2018.

[24] R. Eberhart and J. Kennedy, “A new optimizer using particle swarm
theory,” in Proc. 6th Int. Symp. Micro Machine and Human Science,
Oct 1995, pp. 39–43.

[25] F. Jiang, Q. Dai, and L. Dong, “An icpso-rbfnn nonlinear inversion for
electrical resistivity imaging,” J. Cent. South Univ., vol. 23, no. 8, pp.
2129–2138, Aug 2016.

[26] J. Schmidhuber, “Deep learning in neural networks: An overview,”

Neural Networks, vol. 61, pp. 85–117, Dec 2015.

[27] T. OShea and J. Hoydis, “An introduction to deep learning for the
physical layer,” IEEE Trans. Cognitive Commun. and Netw., vol. 3, no. 4,
pp. 563–575, Dec 2017.

[28] F. Jiang, L. Dong, and Q. Dai, “Electrical resistivity imaging inversion:
An isﬂa trained kernel principal component wavelet neural network
approach,” Neural Networks, vol. 104, pp. 114–123, Aug 2018.

Fig. 12: The comparison of runtime between PSO and the
proposed method as the number of devices varies from 10 to
100.

[7] Narendra and Fukunaga, “A branch and bound algorithm for feature
subset selection,” IEEE Trans. Comput., vol. C-26, no. 9, pp. 917–922,
Sep. 1977.

[8] D. P. Bertsekas, D. P. Bertsekas, D. P. Bertsekas, and D. P. Bertsekas,
Dynamic programming and optimal control. Athena scientiﬁc Belmont,
MA, 1995, vol. 1, no. 2.

[9] S. Bi and Y. J. Zhang, “Computation rate maximization for wireless
powered mobile-edge computing with binary computation ofﬂoading,”
IEEE Trans. Wireless Commun., vol. 17, no. 6, pp. 4177–4190, June
2018.

[10] T. X. Tran and D. Pompili, “Joint task ofﬂoading and resource allocation
for multi-server mobile-edge computing networks,” IEEE Trans. Veh.
Technol., vol. 68, no. 1, pp. 856–868, Jan 2019.

[11] S. Guo, B. Xiao, Y. Yang, and Y. Yang, “Energy-efﬁcient dynamic
ofﬂoading and resource scheduling in mobile cloud computing,” in Proc.
IEEE Int. Conf. on Comput. Commun.(INFOCOM), April 2016, pp. 1–9.
[12] T. Q. Dinh, J. Tang, Q. D. La, and T. Q. S. Quek, “Ofﬂoading in mobile
edge computing: Task allocation and computational frequency scaling,”
IEEE Trans. Commun., vol. 65, no. 8, pp. 3571–3584, Aug 2017.
[13] F. Guo, H. Zhang, H. Ji, X. Li, and V. C. M. Leung, “An efﬁcient
computation ofﬂoading management scheme in the densely deployed
small cell networks with mobile edge computing,” IEEE/ACM Trans.
Netw., vol. 26, no. 6, pp. 2651–2664, Dec 2018.

[14] H. Jiang, D. Peng, K. Yang, Y. Zeng, and Q. Chen, “Predicted mobile
data ofﬂoading for mobile edge computing systems,” in Proc. Int. Conf.
on Smart Comput. and Commun. Springer, 2018, pp. 153–162.
[15] M. Chen, M. Mozaffari, W. Saad, C. Yin, M. Debbah, and C. S. Hong,
“Caching in the sky: Proactive deployment of cache-enabled unmanned
aerial vehicles for optimized quality-of-experience,” IEEE J. Select.
Areas Commun., vol. 35, no. 5, pp. 1046–1061, May 2017.

[16] L. Huang, X. Feng, A. Feng, Y. Huang,

and L. P. Qian,
“Distributed deep learning-based ofﬂoading for mobile edge computing
networks,” Mobile Netw. Appl., Nov 2018.
[Online]. Available:
https://doi.org/10.1007/s11036-018-1177-x

[17] C. H. Liu, Z. Chen, and Y. Zhan, “Energy-efﬁcient distributed mobile
crowd sensing: A deep learning approach,” IEEE J. Select. Areas
Commun., vol. 37, no. 6, pp. 1262–1276, June 2019.

[18] H. Li, K. Ota, and M. Dong, “Learning iot in edge: Deep learning for
the internet of things with edge computing,” IEEE Network, vol. 32,
no. 1, pp. 96–101, Jan 2018.

[19] K. Wang, K. Yang, and C. S. Magurawalage, “Joint energy minimization
and resource allocation in c-ran with mobile cloud,” IEEE Trans. Cloud
Comput., vol. 6, no. 3, pp. 760–770, July 2018.

[20] L. Yang, J. Cao, S. Tang, T. Li, and A. T. S. Chan, “A framework for
partitioning and execution of data stream applications in mobile cloud
computing,” in Proc. IEEE 5th Int. Conf. Cloud Comput., June 2012,
pp. 794–802.

