0
2
0
2

b
e
F
0
1

]

R
C
.
s
c
[

1
v
4
9
5
3
0
.
2
0
0
2
:
v
i
X
r
a

DROIDETEC: Android Malware Detection and Malicious Code
Localization through Deep Learning

1

Zhuo Ma1, Haoran Ge1, Zhuzhu Wang1, Yang Liu1, Ximeng Liu2

1School of Cyber Engineering, Xidian University, Xian 710071, China
2College of Mathematics and Computer Science, Fuzhou University, China

Android malware detection is a critical step towards building a security credible system. Especially, manual search for the potential
malicious code has plagued program analysts for a long time. In this paper, we propose Droidetec, a deep learning based method
for android malware detection and malicious code localization, to model an application program as a natural language sequence.
Droidetec adopts a novel feature extraction method to derive behavior sequences from Android applications. Based on that, the
bi-directional Long Short Term Memory network is utilized for malware detection. Each unit in the extracted behavior sequence
is inventively represented as a vector, which allows Droidetec to automatically analyze the semantics of sequence segments and
eventually ﬁnd out the malicious code. Experiments with 9616 malicious and 11982 benign programs show that Droidetec reaches
an accuracy of 97.22% and an F1-score of 98.21%. In all, Droidetec has a hit rate of 91% to properly ﬁnd out malicious code
segments.

Index Terms—Android, Malware detection, Malicious code localization, Deep Learning, LSTM, Attention.

I. INTRODUCTION

A NDROID systems have gained increasing popularity in

smart phones and other mobile intelligent terminals in
recent years. Unpleasantly, the accumulation development and
open nature of the platform have also attracted a vast number
of malware developers. According to securelist [1], Kaspersky
detected 230 million unique malicious and potentially un-
wanted objects, along with 870 thousand malicious installation
packages in the third quarter of 2019. A representative series
is Gustuff [2], which phished credentials and automate bank
transactions for over 100 banking applications and 32 cryp-
tocurrency applications. The devastating inﬂuence is difﬁcult
to get quick and effective control, as manual analysis is time
consuming and it places high demands on the experience of
security analysts.

To curb the increasing spread of Android malware, re-
searchers have proposed several solutions for automatic detec-
tion. Most of the existing malware detection methods simply
make a judgement about whether an application is malicious
or not, and some of the methods attach sensitive permissions
and other information to the ﬁnal result. For security analysts,
it lacks direct evidence to support the judgement. To solve
this problem, some detection methods expect to trigger as
many conditions as possible by means of UI (User Interface)
interactions or automatic testing tools like Monkey [5]. Such
methods are able to catch the abnormal behaviors, but it still
takes effort to ﬁnd malicious code for detailed analysis. What’s
worse is that some tricks can easily bypass these methods, such
as the deliberately delayed launch of malicious programs, the
malicious behaviors triggered by some speciﬁc network data
packages or sometimes even a simple login interface. Recently,

This work was supported by the National Natural Science Foundation of
China (Grant No. U1804263, U1764263, 61872283, U1708262), the China
111 Project (No. B16037).

Corresponding author: Z. Ma (email: mazhuo@mail.xidian.edu.cn).

machine learning has been widely researched and used since
there is no need for the user prior knowledge, which makes it
possible to automatically detect malware. Such feature-based
methods indeed provide more accurate detection, while it still
takes a long time for security analysts to conﬁrm where the
malicious code hides. To the best of our knowledge, there
have been only two studies on malicious code localization [7],
[8]. While both of their analyses are only up to the level of
packages, and the localization is likely disturbed by adversarial
mixture. It is currently a challenge to implement accurate and
ﬁne-grained malicious code localization.

Inspired by the work of Zhou et al. [9] which automat-
ically marks the key points of natural language sentences
through the attention mechanism [10], we realized that
it
seems to be a solution for the localization problem. This
work proposes Droidetec, a deep learning based approach for
Android malware detection and malicious code localization.
The source code is a collection of program execution logic,
and is very much like a natural language with massive jump
statements and extra words (produced by developers and code
obfuscation). To this end, Droidetec gives a solution to connect
the instruction bytecode segments before and after the jump
points, and selectively extracts words as behavior sequence
from contextual code. We utilizes an LSTM (Long Short-
Term Memory) network for sequence process which allows
Droidetec to automatically learn a model of malware patterns.
The major contributions of our work can be summarized as
follows:

Sequence feature extraction approach. Instead of search-
ing for independent features, Droidetec implements a depth
ﬁrst invocation traversal on instructions of the bytecode. It
analyzes all of the calling relationships to ﬁgure out a series of
program behaviors. If an application is running, each possible
execution of the application corresponds to a part of the
behavior sequence. Different from a control ﬂow graph, the

 
 
 
 
 
 
deep invocation traversal keeps all of the instructions in their
original order in the same parent node (parent method). For
each program, a complete behavior sequence is extracted as
the feature expression. Through subsequent processing which
turns a behavior sequence into a vector sequence, the feature
sequences (vector sequences) are ﬁnally sent
to the deep
learning model for training and testing.

Automatic malicious code localization. Droidetec utilizes
a weight distribution strategy to calculate the attention value
of the malware behavior sequence, which represents the
contribution of scattered methods to the ﬁnal classiﬁcation.
Sequence fragments with relatively concentrated contribution
values indicate what should be more concerned about in the
entire malware code. Droidetec ultimately grabs these se-
quence fragments and locates to the corresponding decompiled
code, which is regarded as suspected code, along with the
corresponding packages, classes and speciﬁc method calls.
Malicious code localization may be dispensable for common
users, but it provides explanations of the classiﬁcation and
assists analysts in identifying the malicious points in the
shortest time.

Note that our method deals with the opcode, the bytecode
in the APK (Android application package) ﬁles, and the
features we analyze are various API sequences. That means
we discard other instructions except the invoke instructions
that are closely related to program behaviors. Hence whether
an application is obfuscated or not makes no difference in
our case. However, malicious code dynamically loaded from
native shared libraries such as .so (shared object) ﬁles do not
belong to our analysis scope. In addition, Droidetec does not
detail all code related to malicious behaviors. As a complete
malicious behavior from beginning to end may be mixed in
among multiple normal code segments, it is a burden for
users to scan an excess of code. Instead, we select several
code segments which are the most suspicious and provide the
methods that are able to use the code.

The rest of the paper is structured as follows. Section
III presents the architecture along with the methodology of
Droidetec. In Section IV, we evaluate the performance and
limitations of Droidetec with application samples. Section V
reviews related work, and Section VI is a conclusion.

II. PRELIMINARIES

A. Semantic element vectorization

In the program, it is the API invocations that represent
speciﬁc behaviors, while other operation codes play the role of
variable maintenance, logic jump, etc, which are incapable of
directly reﬂecting behavior relevant information. Therefore, we
analyze the instructions of an application program and regard
each API as a semantic element. However, an API expressed as
a character string or a number cannot retain the semantics, as
these independent expressions lack the contextual information
of sequential behaviors.

The Skip-gram model [11] is an efﬁcient method to cap-
ture a large number of precise syntactic and semantic word
relationships, and eventually learn high-quality distributed
vector representations. Past work on NLP (Natural Language

2

Processing) [12]–[14] has achieved good results with Skip-
Gram and its extended models.

In Droidetec, the Skip-Gram model is utilized to map the
API to an n-dimensional space, where n is a variable param-
eter. In a semantic sequence, each unit is a semantic element
and is represented as a vector. Skip-Gram uses each word (wi)
as the input to predict the contextual information(wi−k, ...,
wi−1, wi+1, ..., wi+k), and after training we use the weight
matrix in hidden layers as a lookup table of word vectors. In
our case, we convert each API to a semantic vector, and the
dimension is reduced from the 104 (one-hot vector) to 102.

B. LSTM network

The LSTM (Long Short-Term Memory) network [15]–[17]
is an artiﬁcial RNN (Recurrent Neural Network) architecture
that can process entire sequences of data. Composed of an
input gate, an output gate and a forget gate, the LSTM unit can
maintain the previous information memory. Through extensive
experiments, LSTM networks have demonstrated success in
image captioning, machine translation, sentiment classiﬁcation
and other tasks.

In Droidetec, source APK ﬁles of Android applications are
converted to instruction code and consequently serialization
features. For context-based analysis, we leverage the Bi-LSTM
(Bidirectional LSTM) network to implement a classiﬁcation
model. Since the complete behavior sequence of a program
is attainable, combining the forward and backward analysis
with the bidirectional network model offers a better semantic
information transfer.

C. Attention mechanism

In the serialization features we extract, each portion of
the behavior sequence contributes dissimilarly to the ﬁnal
classiﬁcation result. We desire to ﬁnd out which parts play
the most important role. A feasible solution is to construct
a weight distribution mechanism of serialization features that
quantiﬁes each API in the sequence. Areas with high weight
distribution have a serious possibility to be where malicious
behavior occurs.

In dealing with the regional importance problem, we intro-
duce the attention mechanism. It implements orient perception
and memory access, and actually ﬁgures out the consistency
of the current input and the target state. The earliest and most
successful utilization of attention mechanism is in computer
vision [18], which extracts information from images by adap-
tively selecting several regions and only specially processing
the selected regions. It has been successfully applied in NLP,
especially machine translation [10].

In our case, the attention mechanism contributes to discov-
ering key features that may imply malicious behavior. The cal-
culated attention values expose the suspected segments in the
behavior sequence. Droidetec indicates potentially malicious
code by providing speciﬁc information, including packages,
classes and context, along with the decompiled method code.

3

Fig. 1: Overview of Droidetec

III. MALWARE DETECTION METHOD

A. Overview

In this work, we utilize Bi-LSTM network [15], [16] for
Android malware detection. As shown in Fig.1, Droidetec
consists of ﬁve main stages: the preprocessing, the sequence
generation, the API vectorization, the malware detection and
malicious code localization. Training data for Droidetec are
behavior sequences from malware samples. We ﬁgure out the
jump operations in application programs, and statically extract
the original behavior sequences that may occur in the runtime
of applications. For each original sequence, Droidetec converts
it to a vectorial behavior sequence as a piece of training data.
Droidetec iteratively trains batches of sequences and maintains
the model for malware detection. Through similar process,
the testing stage extracts sequences from extra applications.
Once the detection model determines that an application
belongs to malware, a deeper analysis could be performed for
malicious code localization. The report generated by Droidetec
ultimately provides the suspected code segments, including the
located packages, classes and methods. The rest of this section
details the ﬁve stages.

B. Preprocessing

We ﬁrst describe how to deal with an original Android
application. In the preprocessing stage, our analysis object
is the DEX (Dalvik Executable) ﬁle, a compiled Android
application code ﬁle which contains information on all class
ﬁles for the entire project. This ﬁle format is no trouble to
deal with by means of Android reverse engineering tools such
as Androguard [19].

Decompressed from the APK, the DEX ﬁle is then parsed to
the corresponding instructions, the method set and the API set.
Each instruction consists of opcodes and operation objects, and
we only focus on instructions related to the “invoke-” opcodes.
All of the methods deﬁned in the Dex ﬁle belong to the method
set, which is used in the construction of cross-reference
detailed in Section III-C. The API set contains all of the
invoked APIs, whose names invariably start with “android/”,

“com/android/internal/util/”, “dalvik/”, “java/”, “javax/”,
“org/apache/”, “org/json/”, “org/w3c/dom/”, “org/xml/sax”,
“org/xmlpull/v1/” or “junit/”. In Droidetec, APIs in package
“java/”, “javax/” are outside the scope of analysis as they are
huge in number and not related to device behaviors.

C. Sequence generation.

After preprocessing, Droidetec extract the integrated behav-
ior sequence (API sequence) with the instructions and method
set.

Cross-reference. For each application, we make statistics
to construct the set of all its methods M and combine the
instructions corresponding to deﬁned methods. The cross-
reference of a method mi is expressed as two sets, Rf rom(mi)
and Rto(mi).

Rf rom(mi) = {m|∀m ∈ M, if mi directly invokes m}, (1)
(2)

Rto(mi) = {m|∀m ∈ M, if m directly invokes mi}.

The method’s in-degree ind(m) represents the number of
times the method m is invoked. ind(m) can be acquired by
calculating the size of Rto(m), and the out-degree outd(m)
is similarly deduced. The cross-reference reveals the method
call relation of an application and lay the foundation for the
next step.

Root method. The method call graph of an application can
be extremely complicated in most cases. It is almost impossi-
ble to ﬁnd an entry point from which we can grasp the whole
behavior code. Some code segments are not executed until
the capture of a speciﬁc message or signal such as message
response functions onCreate(), onStart() and onPause() etc.
Thus, we introduce RM , the set of root methods, to analyze
the whole behavior, which is deﬁned as

RM = {m|∀m ∈ M, ind(m) = 0 and outd(m) (cid:54)= 0}.

(3)

The in-degree of a root method is 0 while the out-degree
is non-zero, which indicates a root method is not explicitly
invoked by other methods. A root method is taken as a start
point of a series of behavior code.

API sequence extraction. The depth-ﬁrst invocation traver-
sal is applied to the contextual connection before and after
the invocation point. The extraction process starts with the
instruction traversal corresponding to root methods in RM .
Opcodes ranging from 0x6E to 0x72 and 0x74 to 0x78 which
represent method invocations are selected for the correspond-
ing operation objects (the method calls). The search process
continues recursively to jump to the invoked method and ﬁnd
sequential API calls until the end of the root method. Fig.2
depicts an instance of the sequence extraction, and the ﬁnal
sequence arising from root method b/a() is “... → AP I1 →
AP I2 → ... → AP I5 → AP I6 → ... → AP I7 → AP I8 →
... → AP I9 → ... → AP I3 → AP I4 → ...”.

Fig. 2: API sequence Extraction

Droidetec starts from all of the root methods and repeats
extraction to generate API sequences, which, to avoid con-
fusion, we call subsequences. These subsequences unite into
the complete sequence one by one, which represents the
application sample being parsed. Note that APIs are ordered
inside each subsequence, while there is no explicit connection
between the subsequences, since events are triggered randomly
at application runtime.

D. API vectorization

In the previous process,

the complete API sequence is
generated, where each API is represented by a serial number
that can hardly characterize the difference and correlation
between different behaviors. The numerical representation of
various APIs is equivalent to the high-dimensional one-hot
vector including a single 1 and other 0s. Assuming that 10000
APIs have been found and API android/app/Activity;<init>()
and android/app/Activity;onCreate() is respectively labeled
with number 1 and 2, the one-hot vectors of the two API
can be:

[1

0 0
(cid:124)

· · ·

(cid:123)(cid:122)
9999

0
(cid:125)

] and [0 1

0 0
(cid:124)

· · ·

(cid:123)(cid:122)
9998

].

0
(cid:125)

It can hardly characterize the difference and correlation be-
tween different APIs, nor can it describe the context depen-
dence. The appropriate conversion of one-hot vectors is the
API distributed representation that improves semantic expres-
sion and achieves dimensionality reduction. The converted
sequence turns to a vector delivered to the input layer of the
detection model. Abundant data parsed from the malicious and
benign code are used in multiple rounds of training along with
testing.

4

API distributed representation. Assuming that the total
number of API is l, each API can be expressed as an l-
dimensional one-hot vector asi, the ith API in sequence s.
We utilize an embedding matrix W , just like

W =








(w1)1
(w1)2
...
(w1)l

(w2)1
(w2)2
...
(w2)l

...
...
. . .
...








,

(wv)1
(wv)2
...
(wv)l

to convert the vector and reduce the dimension of asi to v. W
is initialized with random values w to represent the weight of
dense API representation, and each row uniquely corresponds
to an API vector. In this way, a mapping from asi
to its
distributed representation vsi is completed.

vsi = asiW.

(4)

Skip-Gram model is adopted to train the embedding weight
matrix W as it performs well in massive corpus. For each
extracted API sequence, vsi
is the input vector to predict
the contextual vector vs(i−1), vs(i−2), ..., vs(i−n) and vs(i+1),
vs(i+2), ..., vs(i+n). In Skip-Gram, matrix W works as the
hidden layer and become a lookup table of distributed presen-
tation API when trained completely.

E. Malware detection

The converted sequence vsi is used for input data of the
sequence detection model. We adopt the Bi-LSTM network
along with an attention layer as the classiﬁcation model of
Droidetec. As shown in Fig.3, the model consists of 4 layers:
the input layer, the LSTM layer, the attention layer and the
output layer.

Fig. 3: Sequence detection model

Each API sequence consisting of distributed representation
vectors is passed in the input layer. The sequences of different
applications vary in length, and the size of the input layer
is obviously immutable. We take the maximum value L of
all sequence lengths as the size of input layer, and pad the
sequence with v-dimensional zero vectors at the end if the
length is less than L.

……                 ……const/16             v1, 13invoke‐virtual       v0, v1, Landroid/widget/RelativeLayout                             $LayoutParams;‐>addRuleiget‐object          v1, v8, Lb;‐>D Landroid/widget/ProgressBar;invoke‐virtual       v1, v0, Landroid/widget/ProgressBar;                             ‐>setLayoutParamsnew‐instance         v0, Lz;invoke‐virtual       v9, Lcom/izp/views/IZPView;‐>getContext()move‐result‐object   v1invoke‐direct        v0, v1, Lz;‐><init>                             (Landroid/content/Context;)V……                 …………                 ……if‐eqz               v3, +26const/4              v3, 2mul‐int/2addr        v2, v3add‐int/2addr        v1, v2new‐array            v2, v1, [Biput‐object          v2, v0, Lx;‐>a [Binvoke‐virtual       v0, v5, v6, v7, v4, Lx;‐>a([B I I Z)Z……                 …………                 ……check‐cast           v0, Landroid/telephony/TelephonyManager;invoke‐virtual       v0, Landroid/telephony/TelephonyManager;                         ‐>getNetworkOperatorNamemove‐result‐object   v1iput‐object          v1, v5, Lb;‐>s Ljava/lang/String;invoke‐virtual       v0, Landroid/telephony/TelephonyManager;                         ‐>getDeviceId……                 …… Root method：Lb;‐>a(IZPView)V……                 ……const‐string         v1, 'phone'invoke‐virtual       v0, v1, Landroid/content/Context;                             ‐>getSystemServicemove‐result‐object   v0check‐cast           v0, Landroid/telephony/TelephonyManager;invoke‐virtual       v0, Landroid/telephony/TelephonyManager;                         ‐>getNetworkOperatorNamemove‐result‐object   v1……                 ……Method：Lz;‐><init>(Landroid/content/Context;)V……                 ……const‐string         v1, 'wifi'invoke‐virtual       v0, v1, Landroid/content/Context;                             ‐>getSystemServicemove‐result‐object   v0check‐cast           v0, Landroid/net/wifi/WifiManager;invoke‐virtual       v0, Landroid/net/wifi/WifiManager;                         ‐>isWifiEnabled……                 ……invoke‐virtual       v5, Lb;‐>m()Ljava/lang/String;……                 ……Method：Lx;‐>a([B I I Z)Zcheck‐cast           v0, Landroid/net/ConnectivityManager;invoke‐virtual       v0, Landroid/net/Connectivity                         Manager;‐>getActiveNetworkInfomove‐result‐object   v0……                 ……Method：Lb;‐>m()Ljava/lang/StringtaLSTMunitvsiLSTMunithsisihsih[]…vs1vs2…si…softmax….LSTMunitvs(i+1)LSTMuniths(i+1)s(i+1)hs(i+1)hs(i+1).…………Output layerAttention layerLSTM layerInput layer−→
h si =
←−
h si =

−−−−→
LST M (vsi),
←−−−−
LST M (vsi),

i from 1 to l,

i from l to 1.

(5)

(6)

We then utilize LSTM units to keep the contextual infor-
mation of a long API vector sequence. In Eq.5 and 6, forward
input and backward input construct the bidirectional LSTM
network which leads to a more integral description of API
sequences. l represents the length of the API sequence of an
application. We utilize hsi to summarize the information of a
←−
h si.
given API vector vsi by element-wise summing
Not each API contributes equally to the predictive result.
We consequently introduce the attention layer to make weight
assignment to different hsi. It ﬁgures out which hsi we should
focus on and the calculated attention values can be assembled
to summarize the API sequence. The sequence value of an
application is formed by:

−→
h si and

αsi =

tsi = tanh (hsi),
exp (tT
a tsi)
i exp (tT
(cid:88)

(cid:80)

αsihsi.

ss =

a tsi)

,

(7)

(8)

(9)

i

The activation function tanh is used to generate a nonlinear
transformation of hsi. Then the importance weight αsi
is
calculated by a softmax function with tsi and ta. In Eq.8,
ta is a trained parameter vector that represents the state of
the API sequence. Ultimately, the complete sequence of the
sthapplication is expressed as ss, a weighted sum of hsi and
the corresponding importance weight αsi.

The ﬁnal sequence vector s(cid:48) is a high-level representation

of the complete application and is acquired by:

s(cid:48)
s = tanh ss.
In the output layer, the sequence vector s(cid:48) is leveraged in a
softmax classiﬁer to make prediction consequently, which is:

(10)

p = softmax(W (cid:48)s(cid:48)

s + b(cid:48)),

(11)

where W (cid:48) and b(cid:48) are both random initial value for linear
regression which represents weight and bias respectively.

F. Malicious code localization

Existing malware detection methods simply make classiﬁ-
cations about the malicious degree of applications. Although
some of the machine learning based methods have achieved
high accuracy, these methods can not distinguish where the
threat appears. In the case of Droidetec, each application
predicted as malware is optional for further automatic analysis.
Through malicious code localization, the automatic analysis
provides suspected code segments along with relevant details
of this malware, which effectively assists security analysts in
quick discovery of malicious patterns.

In Eq.8, the importance weight of each API in the sequence
is obtained. The methods deﬁned by the application developer
are used as localization units, which can be evaluated by
the weighted sum of the invoked APIs. However, it causes

5

deviation that a method can accumulate to a large sum if
it invokes a lot of APIs with low weight. A deeper method
in the Control Flow Graph (CFG) tends to consist of more
APIs, which results in an overvalued weight sum and the
excessively wide localization of malicious code. Therefore
Droidetec deﬁnes the k-suspect APIs, k APIs with the highest
weights in an API sequence, to reveal which places should we
focus on. The methods directly invoking k-suspect APIs at the
corresponding positions are the possible malicious methods,
and we calculate the suspect scores of these methods with

sus(m) =

k
(cid:88)

i=1

αi · emi,

if the ith suspect API exists in m
else.

(12)

(13)

emi =

(cid:40)

1,
0,

In Eq.12 and Eq.13, αi represents the weight of the ith k-
suspect API. Droidetec sums up the αi if the corresponding
API exists in the suspected method m. The highest n sus(m)
are extracted and represented in the report along with the
decompiled code.

Note that it is meaningless to compare the sus(m) values
in different applications. Inside an application, the sum of the
weight α is 1, which means the average of α in a complex
application is less than that in the simple. Different sus(m)
values can only tell the differences in the suspect degree of
methods within the same application.

IV. EVALUATION

This section focuses on evaluating the classiﬁcation model
and semantic analysis in Droidetec. All of the experiments
have been conducted in a Windows system with an Intel i5 −
7400 CPU. We ﬁrst describe the data set we extracted from
application samples and our data processing.

A. Dataset

The malware samples we used are from AMD (Android
Malware Dataset) [20], [21], a carefully-labeled dataset that
includes comprehensive proﬁle information of malware, and
the benign samples are from Google Play. A total of 21598
application samples including 9616 malicious and 11982 be-
nign programs cover 65732 different APIs. Before training,
we analyzed the usage of each API in the whole program. In
Fig.4, the vertical axis represents a certain API’s frequency of
occurrence while the horizontal axis represents the APIs sorted
by its frequency in total applications from high to low. For the
sake of presentation, only 6000 APIs are selected as the fre-
quency of remaining APIs tends to be 0. The scatter diagrams
respectively represent APIs in benign programs, malicious
programs and all samples. For instance, the points a1(1000,
0.4161), a2(1000, 0.3060) and a3(1000, 0.1687) represent
the same API android/os/AsyncTask;onPreExecute(), which
occurs in 6608 samples (30.6%) including 1622 malicious
programs(16.87%) and 4986 benign programs(41.61%), and
it is the 1000th API of all in order of frequency from large to
small.

6

score and time consumption increase with the dimension.
When the dimension v changes from 200 to 300, the F1-
score increases by 0.238% while the veriﬁcation time has a
36.8% increase, from 0.364s to 0.498s per sequence. In the
case of Droidetec, we leveraged the 200-dimension vector to
express each distributed API vector that guaranteed efﬁciency
and detection rate (97.2% accuracy and 98.2% F1-score).

Besides, we considered the detection performance of
Droidetec with various malware families. It is signiﬁcant for
the model to maintain stable and efﬁcient detection of each
family.

We took 5850 malware from 14 known families and evalu-
ated the detection performance in Fig.6. The overall detection
rate of these malicious programs reaches 96.3%. Especially,
Droidetec effectively detects malware from certain families,
including FakeInst, Fusob and Jisut etc, with a detection rate
of almost 100%. In two families, Dowgin with 270 samples
and AndroRAT with 40 samples, whose detection rates are
respectively 87.8% and 87.5%, the insufﬁcient sample training
leads to unsatisfactory results. In all, Droidetec generally
maintains stable detection capabilities among various malware
families.

2) Comparison with existing methods
In Tab.I, we compare the performance of Droidetec with
the Droid-Sec [22],
the method proposed by Zhao et al.
[23] and two methods based on API usage and requested
permissions using SVM. Zhao’s method uses an ensemble
model based on decision tree and k nearest neighbor classiﬁer
to analyze sensitive API calls. In our experiment, it reaches
a 91.92% accuracy rate and 90.5% F1-score with a 9.48%
false positive rate. Droid-Sec was reproduced with 173 features
(100 permissions, 62 sensitive API functions and 13 dynamic
actions) based on deep belief networks.

Droidetec is superior to both of the two methods in detection
accuracy and error rate. Although Droid-Sec utilizes droidbox
to capture dynamic behaviors, Droidetec has an F1-score
2.87% higher and a false positive rate of 1.58% lower. It
reﬂects that our API sequence based method partially achieves
the effect of dynamic detection.

3) Comparison with Android malware scanners
We then compare the performance of Droidetec with other
Android malware scanners. 6 popular scanners are tested with
the same data set.

Fig. 7 shows the detection rate of Droidetec and mainstream
scanners (Avira, AVG, Kaspersky, McAfee, Symantec and
Avast). Both Avira and Droirtect demonstrate similar detection
capabilities and provide stable detection of a variety of mal-
ware families. Other scanners, despite their good performance
in most of the samples, have a low detection rate in several
families. Especially, some of these scanners present a fairly
high tolerance for adware.

C. Semantic analysis evaluation

SectionIII-F has illuminated that Droidetec scans malicious
code based on an attention-based semantic analysis mech-
anism. This section focuses on the evaluation of semantic
analysis between malicious and benign programs and among
various malware families.

Fig. 4: The frequency of each API in applications

We ﬁltered 43 APIs whose frequency of occurrence are
higher than 75% in malicious, benign and all applications.
lack in
These are regarded as commonly used APIs that
feature tendentiousness, most of which are the basis APIs of
a program such as android/app/Activity;<init>() (called in
91.58% programs, in 94.09% malware and 88.45% benign
programs, the following are simply expressed as the triad
of percentages) and android/app/Activity;onCreate() (90.94%,
fairly common APIs such as an-
92.96%, 88.44%) or
droid/ content/Intent;<init>() (94.89%, 98.06%, 90.94%) and
android/content/Context;getSystemService() (90.8%, 94.74%,
85.88%).

The data set for training and test

includes 21598 API

sequences consisting of the remaining 65689 APIs.

B. Detection evaluation

1) Detection performance
We ﬁrst work over the effects of API vectors on detection

performance.

In SectionIII-D, we have described the distributed represen-
tation of APIs. Each API is expressed as a vector vsi whose
dimension v determines the ability of semantic representation.
Here we ﬁgure out how the dimension v affects the detection
performance. In Fig.5(a), accuracy, precision and recall are
used to describe the detection performance in different dimen-
sions. In general, Droidetec performs better with the increase
of dimension v. The detection accuracy increases with the
dimension, and the precision and recall rates are generally on
the rise. Especially, the recall has remained at around or more
than 98%, which means almost all of the malicious samples
can be identiﬁed in our test.

However, simply increasing the dimension leads to a com-
putational burden. To better display the effect of dimension
changes, we synthetically considered the F1-score and the
veriﬁcation time. The F1-score is the harmonic mean of the
precision and recall and expressed by:

F1-score =

2 × P × R
P + R

,

(14)

where the P and R respectively represent the precision and
recall. It is vividly depicted in Fig.5(b) that both the F1-

01000200030004000500060000.00.20.40.60.81.0 Benign programs Malicious programs All samplesFrequemcySorted API numbera3(1000, 0.1687)a1(1000, 0.4161)a2(1000, 0.3060)7

(a) Detection rate

(b) F1-score and veriﬁcation time

Fig. 5: Detection performance of Droidetec

TABLE I: Detection performance comparison

Method
Droidetec
Droid-Sec [22]
Zhao’s [23]
API usage
Permissions

Accuracy
97.22%
96.50%
91.92%
83.25%
73.11%

F1-score
98.21%
95.34%
90.50%
81.56%
70.71%

FPR
2.11%
3.69%
9.48%
16.71%
26.72%

various program instructions, we depict the distribution of the
API attention.

We ﬁrst studied the distribution of attention values in basis
APIs without the previous ﬁltering work in SectionIV-A. Fig.8
shows the API attention distribution of android/app/Activity;
onCreate()(abbreviated as onCreate()) respectively in benign
and malicious samples. As shown,
the highest frequency
interval is (0, 2×10-5], and more than 50% of its attention
values of fall within the interval (0, 4×10-5] in both samples.
The consistency in size and distribution indicates that these
fairly common APIs, just like onCreate() in the example, are
given the same low level of attention by Droidetec in both
benign and malicious programs. It also shows that the previous
ﬁltering work has little impact on subsequent analysis.

Fig. 6: Detection rate in malware families

Fig. 7: Comparison with Android malware scanners

Fig. 8: API attention distribution of android/app/Activity;
onCreate()

(a) Benign samples

(b) Malicious samples

1) Semantic difference in malicious and benign programs
is known that different APIs contribute variously to
It
the detection result, while the same API can be important
in some programs while less important in others. To verify
that Droidetec can distinguish the semantic differences among

Unlike basis APIs, the APIs that sensitive behavior may in-
volve are treated differently in Droidetec. In Fig.9, we take the
API android/net/wiﬁ/WiﬁInfo;getMacAddress() (abbreviated as
getMacAddress()) as an example. Fig.9(a) details the frequency
of attention values in benign samples while Figs. 9(b) to 9(f)
are the case in 5 malware families. In this case, Droidetec

50-d100-d200-d300-d9092949698100Detection rate (%)Dimension of API vector  Accuracy  Precision  Recall50-d100-d200-d300-d949596979899100  F1-score  TimeDimension of API vectorF1-score(%)0.200.250.300.350.400.450.50Vertification time per sequence (sec)AirpushAndroRATBankBotDowginDroidKungFuFakeInstFusobJisutKuguoMecorMsegRuMMSYoumiZitmoAverage707580859095100Detection rate (%) Overall detection rate  > overall detection rate  < detection rateAviraDroidetecAVGKasperskyMcAfeeSymantecAvast020406080100Detection rate (%)0.00.20.40.60.81.001020304050Frequency (%)Attention value (10-3)0.00.20.40.60.81.001020304050Frequency (%)Attention value (10-3)8

(a) Benign samples

(b) Family Airpush

(c) Family BankBot

(d) Family Dowgin

(e) Family Fusob

(f) Family FakeInst

Fig. 9: API attention distribution of android/net/wiﬁ/WiﬁInfo; getMacAddress()

reﬂects the differences in attention of getMacAddress(). In
benign samples, most of the attention values are less than
2×10-3, while in family FakeInst 30% of attention values
exceed 4.43×10-2. To make it more distinct, Fig. 10 depicts
the frequency distribution curves of attention value in interval
(0, 9×10-3] for benign samples and 5 malware families. The
distribution curves of benign samples and family Airpush are
very close and are mostly in areas with smaller attention
values, while attention in other families tends to be higher. In
addition, from family Airpush to FakeInst, the peak interval
of frequency shifts to higher attention values, which reveals
the semantic difference in malware families. The details are
discussed in the following subsection.

Fig. 10: API attention distribution curves of android/net/wiﬁ/
WiﬁInfo;getMacAddress()

In average, the API attention value of getMacAddress()

(5.542×10-3) is far more than that of onCreate() (1.09×10-4).
Generally, Droidetec concerns more about behavior-related
APIs and places different emphasis on benign samples and
different families.

2) Semantic difference in malware families
We further test Droidetec’s semantic analysis capabilities
in different families. Since the suspected methods in different
malware vary from each other, we employed a uniﬁed expres-
sion for evaluation. As deﬁned in SectionIII-F, the k-suspect
APIs are k APIs with the largest attention values in a certain
program. To describe a set of programs, we ﬁgure out the n
most frequency k-suspect APIs as n-max APIs. The n-max
APIs are good indicators of a program set especially with
similar attributes.

In Tab.II, we make statistics of 5-max API by malware fam-
ilies with k = 200. APIs getLine1Number and getDeviceId of
class android/telephony/TelephonyManager tend to be treated
with more emphasis, no matter which malware family they are
from. These two API calls respectively attempt to obtain the
IMEI (International Mobile Equipment Identity) code and the
local number of the mobile phone.

Besides, each family has its behavioral characteristics. Air-
push is a malware family that aggressively pushes advertis-
ing content to the device’s notiﬁcation bar. In the case of
the Airpush family, Droidetec focuses on setAccuracy and
setCostAllowed, which request Location Provider to provide
location and direction information.

Family BankBot is a banking trojan that embodies stealing
SMS, money transferring, GPS location tracking and so on.
FakeInst malware appears to be installers for normal appli-
cations but sends SMS messages to premium-rate numbers or
services when executed. In both families, 4 of the 5-max APIs

0.00.20.40.60.81.005101520Frequency (%)Attention value (10-2)0.00.20.40.60.81.00510152025Frequency (%)Attention value (10-2)0.00.20.40.60.81.00102030405060Frequency (%)Attention value (10-2)0.00.20.40.60.81.005101520Frequency (%)Attention value (10-2)0.00.20.40.60.81.01.2010203040Frequency (%)Attention value (10-2)0123456705101520Frequency (%)Attention value (10-2)0.0000.0010.0020.0030.0040.0050.0060.0070.0080.009010203040506070Frequency(%)Attention value Famliy Airpush Famliy Bankbot Famliy Dowgin Famliy Fusob Famliy FakeInst Benign samples9

Family

Airpush

BankBot

Dowgin

DroidKungFu

FakeInst

TABLE II: 5-max APIs in malware families

5-max API
android/location/Criteria;setAccuracy
android/location/Criteria;setCostAllowed
android/net/wiﬁ/WiﬁInfo;getMacAddress
android/provider/Settings$Secure;getString
android/telephony/TelephonyManager;getDeviceId
android/telephony/TelephonyManager;getLine1Number
android/telephony/TelephonyManager;getDeviceId
android/telephony/SmsManager;getDefault
android/telephony/SmsMessage;createFromPdu
android/app/admin/DeviceAdminReceiver;onEnabled
android/telephony/TelephonyManager;getDeviceId
android/net/wiﬁ/WiﬁInfo;getMacAddress
android/view/Display;getMetrics
android/telephony/TelephonyManager;getLine1Number
android/content/Context;getClassLoader
android/telephony/TelephonyManager;getDeviceId
android/telephony/TelephonyManager;getLine1Number
android/widget/RelativeLayout;onTrackballEvent
android/widget/RelativeLayout;setPressed
android/net/NetworkInfo;getExtraInfo
android/telephony/SmsManager;getDefault
android/telephony/SmsManager;sendTextMessage
android/telephony/SmsMessage;createFromPdu
android/telephony/TelephonyManager;getLine1Number
android/content/SharedPreferences$Editor;commit

Suspected rate
64.3%
60.2%
60.0%
26.9%
25.5%
54.7%
44.8%
42.2%
38.4%
36.9%
57.2%
45.5%
44.3%
35.1%
22.1%
86.3%
65.0%
56.7%
54.3%
48.3%
82.4%
82.4%
45.3%
44.5%
36.1%

Average weight
0.073
0.018
0.020
0.013
0.019
0.026
0.034
0.204
0.047
0.013
0.028
0.035
0.025
0.026
0.011
0.029
0.035
0.199
0.028
0.061
0.082
0.048
0.028
0.047
0.003

from package android/telephony, and the average attention
weight of android/telephony/SmsManager;getDefault() even
reaches 0.204 in BankBot. These APIs are relative to mobile
phone identiﬁcation and SMS sending, which indicates the
main behavioral characteristics of malware families.

In all, Droidetec changes its focus for different API se-
quences. Moreover, it also shows the distinction in semantic
analysis when deals with various malware families.

D. Automatic malicious code localization

Based on the detection result and semantic attention,
Droidetec eventually generates an analysis report if the pro-
gram under test is detected as malware.

1) An instance of malicious code localization
We ﬁrst take a sample from malware family Zitmo as an
instance to illustrate the analysis report. As shown in Fig.11,
the analysis report contains 3 parts, the brief information, the
summary and the details.

The ﬁrst part offers basic information for this APK, includ-
ing the package name, the requested permissions, the version
of SDK (Software Development Kit) and so on. The summary
explains the ﬁrst k suspected APIs along with their attention
values and the suspected methods, which indicate the corre-
sponding package and class, the parameter type and the return
type. In this instance, several of the top 20 suspected APIs
appear repeatedly. For example, the API sendTextMessage()
appears 4 times with discrepant attention values, for it is
invoked in different segments of behavior sequence. Speciﬁc
information about suspected methods is offered in the detail
part, including the suspected socre (the weighted sum sus(m)
in Eq.12), the possible entry points, the invoked k-suspected
APIs and the decompiled code. Fig.11 selects the suspected
method 2 (onReceive) and 8 (getAdminNumber). The main
malicious point occurs in onReceive, which monitors users’

text messages. The communication with a speciﬁc number
leaks sensitive information, including speciﬁc message content
and source numbers. The program then receives instructions
sent by the speciﬁc number and perform malicious acts. In
the source code of onReceive, the method getAdminNumber is
invoked. This method is also captured by Droidetec as a sus-
pected method where the speciﬁc number “+46769436094” is
exposed.

It should be mentioned that Droidetec can completely
display malicious source code segments no matter they are
obfuscated code or not. For the convenience of explanation,
we select this malware sample with more straightforward class
and method names.

2) Localization evaluation
As described in Sec.III-F, top n methods with the highest
sus(m) scores are selected as possibly malicious methods. A
larger n can cover more potentially malicious methods, but can
also bring a mass of inaccurate localization. To determine an
appropriate n value and evaluate the localization effectiveness,
we deﬁne the hit rate and accuracy that are respectively given
by

hit rate =

Nhit
N

,

accuracy =

(cid:48)
i

(cid:80)N

i=1 n
N × n

.

(15)

(16)

Droidetec is regarded to hit the malware, if one or more
malicious code segments are successfully located. In total N
malicious samples, Nhit pieces of malware are hit. In sample i,
i true malicious methods among n
Droidetec correctly grabs n
suspected methods, and Eq.16 utilizes the accuracy to measure
the localization quality and limit the size of n.

(cid:48)

In Fig.12, we manually inspected 100 pieces of malware
and depict how hit rate and accuracy change with n. Only by
results of the ﬁrst suspected methods (n = 1), we can achieve

10

Fig. 13: Accuracy of single methods

82% hit rate and accuracy. As n increases, hit rate turns
to be higher while accuracy decreases. It is comprehensible
that the more suspected methods we select, the higher the
possibility of catching malicious code becomes. The accuracy
decreases, for suspected methods with lower sus(m) are more
possible to be erroneous judgements. Given that n = 1, and
the mth suspected method is the only localization result, the
accuracy in Eq.16 turns into the single accuracy of method
m. Fig.13 shows the single accuracy from the 1st suspected
method to the 20th, and there is a sharp decline after the 9th
method, which results in the corresponding decline of overall
accuracy in ﬁg.12. Meanwhile, the hit rate no longer increases
when n > 9. In this case, Droidetec offers 9 most suspected
methods by default and achieves 91% hit rate with 65.3%
overall accuracy.

E. Limitation

Droidetec implements malware detection by analyzing the
Dalvik opcode of a program. Hence, libraries linked during
running-time such as .so ﬁles do not belong to our analysis
scope. It is not the case in practice as Droidetec can be easily
combined with other approaches speciﬁc to native shared
libraries detection.

TABLE III: Droidetec time consumption of malware < 10M
in size

Feature extraction
1.263s

Classiﬁcation
0.31s

Report generation Overall
1.682s

0.109s

Time consumption

Feature extraction

Deep invocation traversal
0.89s

Sequence generation
0.033s

Vectorization
0.34s

A limitation of Droidetec is time consumption. Tab.III
indicates the time consumption in all stages of detection when
the malware samples are less than 10M in size. It takes Avira
0.54s per program on average, while Droidetec spends 1.682s
per program to analyse the same samples on the same device.
It is evident that sequence feature extraction takes up most
of the time (75%). As stated in Section I, we aim to propose
a solution that implements a deeper and more efﬁcient static
detection to substitute for the dynamic. Therefore, we have to
take an effort to work out the calling relationship and behavior

Fig. 11: A report instance

Fig. 12: Hit rate and accuracy

Basic information for APKReport summaryLocated malcode(decompiled)05101520828486889092 Hit rate AccuracynHit rate(%)2030405060708090Accuracy(%)05101520020406080Accuracy(%)Suspected method ordinalsequence of a program. Theoretically, we use

T (n) = (navg)d,

(0 < navg << n)

(17)

to measure the time complexity of the feature extraction
process. In Eq. 17, n represents the method amount of a
program, navg is the average number of times a method calls
other methods and d is the average invocation depth. Although
bavg is far less than n, the time complexity is higher than the
O(n) of the common extraction methods [6], [22], [24], [25]
which only require a direct code walk. We have optimized
the time overhead with dynamic planning, which adopts extra
storage space to make the complexity as close as possible to
O(n). While in the worst case (d is large), the time spend
during the deep invocation traversal increases greatly.

V. RELATED WORK

In the past few years, research and experimentation of
Android malware detection methods have been continually
evolving. According to the categorization and analyses of
Arshad et al. [26], we can have an overall view of the cur-
rent Android malware landscape and corresponding detection
methods.

A. Android malware detection

A general detection for Android malware is the permission-
based method [3], [27], [28], which analyses the manifest and
notiﬁes about the over-privileged applications. These methods,
though fast, are difﬁcult to achieve a guaranteed accuracy in
practice. Contemporarily, the classiﬁcation by simple permis-
sions is not appropriate as most Android applications tend to
be functional complexity and request more permissions.

Signature-based approaches [4], [29]–[31] extract features
to create a unique signature for each application. The program
under test will evaluate to malicious if its signature matches
with existing malware families’. For example, AndroSimilar
[29] generates the variable length signature for the application
under test. It measures syntactic ﬁle similarity of the whole
ﬁle instead of just opcodes for faster detection and implements
classiﬁcation based on similarity percentage. Madam [30]
implements a signature-based approach that considers behav-
ioral patterns from known malware misbehaviors. Although
several improvements have been proposed, the signature-based
detection performs unsatisfactorily in dealing with unknown
malware. In most cases, it can be relatively easy for malware
to evade this kind of detection by adding simple obfuscation
methods.

Dynamic analysis [32]–[35] examines the application during
execution. Crowdroid [32] collects the system calls during pro-
gram running time. A clustering algorithm is adopted in iden-
tifying malware and normal programs. TaintDroid proposed by
Enck et al. [33] is a famous dynamic taint tracking framework
labels and tracks sensitive data during a source-sink
that
period. It performs well in information ﬂow tracking and can
effectively avoid privacy leaking. IntelliDroid [34] provides
a generic Android input generator that can produce inputs
speciﬁc to a dynamic analysis tool. It claimed that only a
small number of inputs and a small part of the program

11

execution are needed. Dynamic malware detection tends to
be designed for several certain malicious behaviors and is
time-consuming as the tested application has to keep running
for a long time until anomalies occur. Dynamic detection
can be easily blocked in places where human operations are
necessary. Thus, in most cases, only manual dynamic detection
can be satisfactory. Droidetec can be combined directly with
these dynamic methods. Using Droidetec as preprocessing can
greatly reduce the workload of manual analysis.

B. Combination with machine learning

The development of machine learning has opened up a new
way to malware detection, where machine learning algorithms,
especially several deep learning algorithms, have been applied
to feature process and classiﬁcation [22], [24], [25], [36]–[40].
For instance, Drebin [24] implements an effective and
explainable detection for Android malware that extracts 8
feature sets from the manifest and disassembled code. It
utilizes linear SVM (Support Vector Machines) for this task.
Droid-Sec was proposed by Yuan et al. [22], which extracts
202 features including required permission, sensitive API and
dynamic behavior. The comparison with traditional models
the DBN
such as SVM and C4.5 etc. demonstrates that
(deep belief network) they adopt has the best performance.
Mclaughlin et al. [37] proposed a deep CNN (Convolutional
Neural Network) based detection system that extracts the raw
opcode sequence from a disassembled program as features.
However it only analyzes 218 deﬁned opcodes, most of which
are not behavior related. Invoking related instructions with
different operands such as android/os/SystemClock;sleep(),
android/telephony/TelephonyManager;getSimOperatorName()
and android/net/NetworkInfo;getDetailed() are regarded as
the same feature, which is not reasonable enough.

C. Malicious code localization

There have been two known studies on Android malicious
code localization, which are both based on the CFG. Li et
al. [8] focused on ﬁnding the hooks between carrier and rider
code, and deﬁned two hook types which differ in the way
rider code is triggered: through method calls or the Android
event system. In our case, T ype1,2 are within our detection
scope, since the concept of root method encompasses both
types. Narayanan et al. [7] analyzed the Inter-procedural CFG
and assigned an m-score to quantify the statistical signiﬁcance
of malice operations. The limitation of the two graph-based
methods is that the analysis accuracy will be affected by
incorporating benign subgraph features, while the forget gate
in LSTM helps Droidetec mitigate this negative impact.

Overall, previous machine learning based solutions use
extensive features and only care about achieving outstanding
classiﬁcation results. In our case, Droidetec provides accurate
detection along with the retracing to suspected segments.

VI. CONCLUSION

This paper presents Droidetec, a static and automatic anal-
ysis framework for Android malware detection using a deep

neural network based approach. The feature extraction method
is utilized to traverse all the invocation processes in an orderly
it
manner. Besides, Droidetec goes beyond others in that
provides automatic analysis which indicates the suspected
code segments. That means,
to a certain extent, program
analysts could free themselves from reading complex, obfus-
cated malicious code, and efﬁciently discover the malicious
patterns. In the future, a more accurate method for multi-
classiﬁcation of various malware families will be the focus of
our work. Besides, we are looking for a new way to improve
the malicious code localization in that we will design the range
of code segments instead of reporting the complete decompiled
methods.

REFERENCES

[1] K. Lab, “It threat evolution q3 2019. statistics,” 2019. [Online]. Avail-
able: https://securelist.com/it-threat-evolution-q3-2019-statistics/95269/
[2] Group-IB, “Group-ib uncovers android trojan named gustuff capable
targeting more than 100 global banking apps, cryptocurrency
[Online]. Available: https:

of
and marketplace applications,” 2019.
//www.group-ib.com/media/gustuff/

[3] W. Shin, S. Kiyomoto, K. Fukushima, and T. Tanaka, “Towards formal
analysis of the permission-based security model for android,” in 2009
Fifth International Conference on Wireless and Mobile Communications.
IEEE, 2009, pp. 87–92.

[4] M. Zheng, M. Sun, and J. C. Lui, “Droid analytics: a signature based
analytic system to collect, extract, analyze and associate android mal-
ware,” in 2013 12th IEEE International Conference on Trust, Security
and Privacy in Computing and Communications.
IEEE, 2013, pp. 163–
171.

[5] G. Canfora, E. Medvet, F. Mercaldo, and C. A. Visaggio, “Detecting
android malware using sequences of system calls,” in Proceedings of
the 3rd International Workshop on Software Development Lifecycle for
Mobile. ACM, 2015, pp. 13–20.

[6] K. Xu, Y. Li, R. H. Deng, and K. Chen, “Deepreﬁner: Multi-layer
android malware detection system applying deep neural networks,” in
2018 IEEE European Symposium on Security and Privacy (EuroS P),
April 2018, pp. 473–487.

[7] A. Narayanan, M. Chandramohan, L. Chen, and Y. Liu, “A
multi-view context-aware approach to android malware detection
and malicious code localization,” Empirical Software Engineering,
vol. 23, no. 3, pp. 1222–1274,
[Online]. Available:
https://doi.org/10.1007/s10664-017-9539-8

Jun 2018.

[8] L. Li, D. Li, T. F. Bissyand´e, J. Klein, H. Cai, D. Lo, and Y. Le Traon,
“On locating malicious code in piggybacked android apps,” Journal of
Computer Science and Technology, vol. 32, no. 6, pp. 1108–1124, Nov
2017. [Online]. Available: https://doi.org/10.1007/s11390-017-1786-z

[9] P. Zhou, W. Shi, J. Tian, Z. Qi, B. Li, H. Hao, and B. Xu, “Attention-
based bidirectional long short-term memory networks for relation clas-
siﬁcation,” in ACL, 2016.

[10] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in Advances
in Neural Information Processing Systems, 2017, pp. 5998–6008.
[11] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
“Distributed representations of words and phrases and their composi-
tionality,” in Advances in neural information processing systems, 2013,
pp. 3111–3119.

[12] A. Lazaridou, N. T. Pham, and M. Baroni, “Combining language and
vision with a multimodal skip-gram model,” Computer Science, 2015.
[13] L. De Vine, G. Zuccon, B. Koopman, L. Sitbon, and P. Bruza,
“Medical semantic similarity with a neural
language model,” in
Proceedings of the 23rd ACM International Conference on Conference
on Information and Knowledge Management, ser. CIKM ’14. New
York, NY, USA: ACM, 2014, pp. 1819–1822. [Online]. Available:
http://doi.acm.org/10.1145/2661829.2661974

[14] F. Barbieri, F. Ronzano, and H. Saggion, “What does this emoji mean?

a vector space skip-gram model for twitter emojis.” in LREC, 2016.

[15] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural
Computation, vol. 9, no. 8, pp. 1735–1780, 1997. [Online]. Available:
https://doi.org/10.1162/neco.1997.9.8.1735

12

[16] A. Graves and J. Schmidhuber, “Framewise phoneme classiﬁcation
with bidirectional lstm and other neural network architectures,” Neural
Networks, vol. 18, no. 5-6, pp. 602–610, 2005.

[17] A. Graves, N. Jaitly, and A. R. Mohamed, “Hybrid speech recognition
lstm,” in Automatic Speech Recognition &

with deep bidirectional
Understanding, 2014.

[18] V. Mnih, N. Heess, A. Graves, and k. kavukcuoglu, “Recurrent
models of visual attention,” in Advances in Neural
Information
Processing Systems 27, Z. Ghahramani, M. Welling, C. Cortes, N. D.
Lawrence, and K. Q. Weinberger, Eds. Curran Associates,
Inc.,
2014, pp. 2204–2212. [Online]. Available: http://papers.nips.cc/paper/
5542-recurrent-models-of-visual-attention.pdf

[19] A. Desnos et al., “Androguard,” 2011.
[20] Y. Li, J. Jang, X. Hu, and X. Ou, “Android malware clustering through
malicious payload mining,” in International Symposium on Research in
Attacks, Intrusions, and Defenses. Springer, 2017, pp. 192–214.
[21] F. Wei, Y. Li, S. Roy, X. Ou, and W. Zhou, “Deep ground truth analysis
of current android malware,” in International Conference on Detection
of Intrusions and Malware, and Vulnerability Assessment (DIMVA’17).
Bonn, Germany: Springer, 2017, pp. 252–276.

[22] Z. Yuan, Y. Lu, Z. Wang, and Y. Xue, “Droid-sec: deep learning in
android malware detection,” in ACM SIGCOMM Computer Communi-
cation Review, vol. 44, no. 4. ACM, 2014, pp. 371–372.

[23] C. Zhao, W. Zheng, L. Gong, M. Zhang, and C. Wang, “Quick and
accurate android malware detection based on sensitive apis,” in 2018
IEEE International Conference on Smart Internet of Things (SmartIoT),
Aug 2018, pp. 143–148.

[24] D. Arp, M. Spreitzenbarth, M. Hubner, H. Gascon, K. Rieck, and
C. Siemens, “Drebin: Effective and explainable detection of android
malware in your pocket.” in Ndss, vol. 14, 2014, pp. 23–26.

[25] Z. Ma, H. Ge, Y. Liu, M. Zhao, and J. Ma, “A combination method for
android malware detection based on control ﬂow graphs and machine
learning algorithms,” IEEE Access, vol. 7, pp. 21 235–21 245, 2019.

[26] S. Arshad, M. A. Shah, A. Khan, and M. Ahmed, “Android malware
detection & protection: a survey,” International Journal of Advanced
Computer Science and Applications, vol. 7, no. 2, pp. 463–475, 2016.
[27] A. Utku, I. A. DoGru, and M. A. Akcayol, “Permission based android
malware detection with multilayer perceptron,” in 2018 26th Signal
Processing and Communications Applications Conference (SIU), May
2018, pp. 1–4.

[28] A. Arora, S. K. Peddoju, and M. Conti, “Permpair: Android malware
detection using permission pairs,” IEEE Transactions on Information
Forensics and Security, 2019.

[29] P. Faruki, V. Ganmoor, V. Laxmi, M. S. Gaur, and A. Bharmal,
“Androsimilar: Robust statistical feature signature for android malware
detection,” in Proceedings of
the 6th International Conference
Information and Networks, ser. SIN ’13. New
on Security of
[Online]. Available:
York, NY, USA: ACM, 2013, pp. 152–159.
http://doi.acm.org/10.1145/2523514.2523539

[30] A. Saracino, D. Sgandurra, G. Dini, and F. Martinelli, “Madam: Effective
and efﬁcient behavior-based android malware detection and prevention,”
IEEE Transactions on Dependable and Secure Computing, vol. 15, no. 1,
pp. 83–97, 2016.

[31] Z.-U. Rehman, S. N. Khan, K. Muhammad, J. W. Lee, Z. Lv, S. W.
Baik, P. A. Shah, K. Awan, and I. Mehmood, “Machine learning-assisted
signature and heuristic-based detection of malwares in android devices,”
Computers & Electrical Engineering, vol. 69, pp. 828–841, 2018.
[32] I. Burguera, U. Zurutuza, and S. Nadjm-Tehrani, “Crowdroid: behavior-
based malware detection system for android,” in Proceedings of the 1st
ACM workshop on Security and privacy in smartphones and mobile
devices. ACM, 2011, pp. 15–26.

[33] W. Enck, P. Gilbert, S. Han, V. Tendulkar, B.-G. Chun, L. P. Cox,
J. Jung, P. McDaniel, and A. N. Sheth, “Taintdroid: an information-
ﬂow tracking system for realtime privacy monitoring on smartphones,”
ACM Transactions on Computer Systems (TOCS), vol. 32, no. 2, p. 5,
2014.

[34] M. Y. Wong and D. Lie, “Intellidroid: A targeted input generator for the

dynamic analysis of android malware,” in NDSS, 2016.

[35] P. Feng, J. Ma, C. Sun, X. Xu, and Y. Ma, “A novel dynamic android
malware detection system with ensemble learning,” IEEE Access, vol. 6,
pp. 30 996–31 011, 2018.

[36] S. Hou, A. Saas, L. Chen, and Y. Ye, “Deep4maldroid: A deep learning
framework for android malware detection based on linux kernel system
call graphs,” in 2016 IEEE/WIC/ACM International Conference on Web
Intelligence Workshops (WIW).

IEEE, 2016, pp. 104–111.

[37] N. McLaughlin, J. Martinez del Rincon, B. Kang, S. Yerima, P. Miller,
S. Sezer, Y. Safaei, E. Trickel, Z. Zhao, A. Doup´e et al., “Deep android

13

malware detection,” in Proceedings of the Seventh ACM on Conference
on Data and Application Security and Privacy. ACM, 2017, pp. 301–
308.

[38] J. Li, L. Sun, Q. Yan, Z. Li, W. Srisa-an, and H. Ye, “Signiﬁcant
permission identiﬁcation for machine-learning-based android malware
detection,” IEEE Transactions on Industrial Informatics, vol. 14, no. 7,
pp. 3216–3225, 2018.

[39] T. Kim, B. Kang, M. Rho, S. Sezer, and E. G. Im, “A multimodal deep
learning method for android malware detection using various features,”
IEEE Transactions on Information Forensics and Security, vol. 14, no. 3,
pp. 773–788, March 2019.

[40] X. Chen, C. Li, D. Wang, S. Wen, J. Zhang, S. Nepal, Y. Xiang, and
K. Ren, “Android hiv: A study of repackaging malware for evading
machine-learning detection,” IEEE Transactions on Information Foren-
sics and Security, vol. 15, pp. 987–1001, 2019.

