Development of a VR tool to study pedestrian route and exit choice behaviour in a multi-story building 

YAN FENG1*, DORINE DUIVES1, SERGE HOOGENDOORN1 

1Department of Transport & Planning, Delft University of Technology, 2628 CN, Delft, The Netherlands 

Abstract:  Although  route  and  exit  choice  in  complex  buildings  are  important  aspects  of  pedestrian  behaviour,  studies 
predominantly investigated pedestrian movement in a single level. This paper presents an innovative VR tool that was designed to 

investigate pedestrian route and exit choice in a multi-story building. This tool supports free navigation and collects pedestrian 
walking trajectories, head movements and gaze points automatically. An experiment was conducted to evaluate the VR tool from 

objective  standpoints  (i.e.,  pedestrian  behaviour)  and  subjective  standpoints  (i.e.,  the  feeling  of  presence,  system  usability, 
simulation sickness). The results show that the VR tool allows for accurate collection of pedestrian behavioural data in the complex 

building. Moreover, the results of the questionnaire report high realism of the virtual environment, high immersive feeling, high 
usability, and low simulator sickness. This paper contributes by showcasing an innovative approach of applying VR technologies 

to study pedestrian behaviour in complex and realistic environments.  

Keywords: virtual reality, multi-story building, route choice, exit choice, wayfinding  

1  INTRODUCTION 

While walking in a building, pedestrians constantly choose between a number of routes to reach their destination, which is referred 
to as route choice behaviour [1]. On their way out, pedestrians are furthermore required to choose an exit. This exit choice behaviour 

features the choice of one exit within a set of alternative exits to leave certain places [2]. Many disciplines, such as architecture, 
fire safety engineering, and civil engineering, require a thorough understanding of pedestrian route and exit choice in buildings in 

order to ensure pedestrian safety and design comfortable buildings [3]. 

Traditionally,  field  experiments  have  been  widely  applied  to  investigate  pedestrian  route  and  exit  choice  behaviour.  Field 

experiments collect pedestrian route and exit behaviour data in real-life conditions under uncontrolled (e.g., [4–7]) or controlled 
conditions (e.g., [8–11]). Digital equipment (e.g., camera) is usually used to record pedestrian behaviour in specific situations or 

particular locations. However, it is difficult to control external factors in field experiments under uncontrolled conditions [12]. 
Moreover, the raw data captured during a field experiment cannot be analysed directly, often the data still need to be extracted from 

a video recording afterwards. Consequently, it requires large labour and monetary investments to perform field experiments, while 
the data is often not accurate and reliable enough to perform intricate data analysis. Furthermore, controlled experiments to study 

pedestrian behaviour in risky situations are often restricted by ethical considerations featuring the mental and physical health of 
participants [13]. 

In order to overcome these limitations, researchers have attempted to use Virtual Reality (VR) technologies to study pedestrian 
route and exit choice, especially during evacuations (e.g., [14–18]). Compared to field experiments, VR provides possibilities to 

* Corresponding author: Yan Feng, Email: y.feng@tudelft.nl 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                                 
obtain complete experimental control and collect accurate behavioural data automatically [12]. Moreover, VR allows participants 
to be immersed in dangerous environments without the risk of facing real danger. 

Existing studies have predominantly investigated pedestrian route and exit behaviour in simplified virtual environments, mostly 
a  single  level  of  a  building  and  in  particular  pedestrian  movements  in  the  horizontal  level  have  been  studied  (e.g.,[14,15,19]). 

Moreover, some studies with VR simulators (e.g., desktop-based VR) recorded issues such as lack of natural movements, missing 
details of real-life situations, which might lead to the unrealistic perception of the virtual environment. Consequently, studies that 

use VR to collect comprehensive pedestrian route and exit choice behaviour in immersive, realistic and complex buildings are very 
rare.  

This study aims to develop a VR research tool that addresses these gaps and unlocks the potential of VR technologies for the 
study of pedestrian route and exit choice behaviour in complex multi-story buildings. Maya and Unreal Engine 4 have been used 

to develop this VR tool. This paper details the development process of the VR tool and describes a preliminary experiment using 
this VR tool. The experiment was conducted to demonstrate the ability of this VR tool, and evaluate the usability and realism of 

the developed virtual environment.  

The rest of the paper is organised as follows. Section 2 summarises different methods to collect pedestrian route and exit choice 

data  in  buildings.  Section  3  presents  the  functional  requirements  of  the  VR  research  tool.  Accordingly,  section  4  details  the 
developing process of the VR research tool. Section 5 details the experiment method applying this VR tool. The first results of this 

experiment are discussed in section 6. The paper ends with conclusions and future research. 

2  RELATED WORK 

People need to find their way through buildings while moving from one location to another. This behavioural process may be as 

easy as moving from one room to another or as difficult as trying to escape a building that is on fire [20]. Up to this moment, 
predominantly two experimental methods have been used to study pedestrian route and exit choice behaviour in buildings, namely 

field experiments and VR experiments. This section provides a brief overview of the work featuring these experimental methods 
related to pedestrian route and exit choice behaviour. 

2.1 

Field experiments 

Field experiments have been wildly applied to study pedestrian route and exit behaviour, both in normal and emergency conditions. 

The major advantage of field experiments is that pedestrians walk in a real-life environment and are most likely to behave naturally. 
Often, cameras are used to record the movement and choice behaviour of pedestrians. Pedestrian route and exit choice behaviour 

have been investigated by means of field experiments in schools, universities, theatres, hospitals, tunnels [4–7,21–25]. These studies 
have illustrated that field experiment is a valuable experimental method to study pedestrian movement and choice behaviour.  

However, in these field experiments, the experimental scenarios are generally difficult to control due to the complexity of most 
pedestrian infrastructures and natural variation of human behaviour in such environments [26]. Consequently, it has proven difficult 

to capture detailed data to characterise pedestrian behaviour [27] and challenging to isolate the effect of one explicit variable on 
pedestrian  behaviour  within  a  complex  context.  In  the  examples  where  an  evacuation  was  studied  (e.g.,  Fridolf  et  al.,  2013; 

Heliövaara et al., 2012), the scenarios were not completely realistic due to ethical and financial constraints. Meanwhile, almost all 
studies into pedestrian route and exit behaviour have limited themselves to investigate pedestrian movement in the horizontal levels 

[9], most likely to curb the complexity of the experimental setup. Consequently, literature applying field experiments does not 
capture  the  complexity  and  difficulty  of  pedestrian  movements  in  a  multi-story  building  with  both  horizontal  and  vertical 

movements in a long distance.  

2.2  VR laboratory experiments 

Due to the above-mentioned limitations of field experiments, researchers have explored VR as an innovative experimental approach 

to study pedestrian behaviour. Using VR technologies, it is possible to automatically collect detailed behavioural data in immersive 
environments and analyse precisely how specific controlled factors influence pedestrian behaviour. Another benefit of VR is that 

it can be used to create environments that there are either not likely to encounter in real-life or scenarios which are too dangerous 
to expose a participant due to the health risks, for example, fire, smoke and terrorist attacks.  

2 

Existing research has investigated pedestrian route and exit behaviour in normal conditions or evacuations. This line of research 
is of two types, namely pedestrian’s choice of route and exit (e.g.,[8,16,28–30]) and the impact of external factors on route and exit 

choice (e.g., [17,31–36]).  

These studies illustrated that VR is a safe, engaging and appealing approach to study pedestrian route and exit choice behaviour. 

Moreover, these studies also provided some valuable insights regarding the optimal development and usage of VR technologies for 
pedestrian research. Firstly, the realism level of the virtual environment can impact on the accuracy of the behavioural data [37]. 

Existing  studies  have  predominantly  investigated  simplified  environments,  studies  featuring  pedestrian  route  and  exit  choice 
behaviour in complex buildings are still rare. In order to collect more accurate pedestrian behaviour data, the developed virtual 

environments should represent realistic and complex real-life scenarios. Moreover, it is important to design realistic soundscapes 
to  envelop  the user  in  the  ongoing  situation,  especially  during  emergencies  [38].  Secondly,  to  establish  the  validity  of  the VR 

system, it is important to test whether the results from VR experiments aligns with the actual behaviours of pedestrian in the real 
world. Only a few studies have attempted to validate their results via comparing pedestrian route and exit choice behaviour in VR 

and  real-life  scenarios  (e.g.,  [16,30,39,40]).  Thirdly,  the  literature  suggests  that  more  immersive  virtual  environments  help 
participants behave closely to their behaviour in reality and consequently promise improved validity [41,42]. Compare to desktop 

VR, highly immersive VR systems, such as HMD and CAVE systems can provide more or full immersion for participants with 
more realistic  feelings (e.g., [17,33,36,43–47]). Moreover, VR systems equipped with motion tracking devices (e.g., eye, head 

tracking devices) can more precisely measure visual attention and help researchers to gain a deeper understanding of how pedestrian 
interact with the environment. Lastly, the VR system should be easy to understand, use and interact so that it reduces the possibilities 

for participants experiencing simulation sickness [48,49] 

To  summarise,  although  pedestrian  route  and  exit  choice  behaviour  have  been  widely  studied  in  field  experiments  or  VR 

experiments, few studies have attempted to collect pedestrian behavioural data with both horizontal and vertical movements in 
realistic and complex environments. Pedestrian route and exit choice is affected by the layout of the architectural setting and the 

quality  of  the  environmental  information  [20].  Since  the  complexity  and  difficulty  of  pedestrian  movements  in  complex 
environments are very different [50], findings pertaining to simplified environments cannot be directly  generalised to complex 

buildings. As a result, given the opportunities provided by VR, there is a strong need for VR tools that can create realistic and 
complex scenarios to study pedestrian route and exit choice in multi-story buildings, which includes both vertical and horizontal 

movements.  

3  FUNCTIONAL REQUIREMENTS OF THE VR RESEARCH TOOL 

The aim of the study is to develop a VR tool to study pedestrian route and exit choice behaviour in a multi-story building. Based 

on the aim of the study and review of previous studies pertaining to experimental designs to study pedestrian behaviour, we have 
identified five main requirements for the development of the new VR research tool.  

Firstly, in order to study pedestrian route choices and exit choices across horizontal and vertical levels, the VR tool needs to 
allow  users  to  perform  wayfinding  in  multi-story  buildings.  Thus,  the  virtual  environment  is  required  to  represent  a  complex 

building including multiple floors that are connected by means of staircases. Meanwhile, minimum of two set of route choices on 
both horizontal and vertical level is required.  

Secondly, in order to allow for the validation of the VR tool, the virtual environment should feature a scenario that can be 
reproduced  in  reality,  including  all  its  intricacies.  That  is,  the  visualisation  of  the  geometry,  colour  and  texture  in  the  virtual 

environment should be realistic to represent the real-world experience. Moreover, the general feeling of the environment should be 
similar as well. Thus, the details of the environment (e.g., signage, soundscapes) should be similar to a real-world experience.  

Thirdly, in order to ensure the validity of the VR tool, the interaction between users and the virtual environment should be 
natural so that the participant can behave and react to events (e.g., evacuation) similarly to their real-life behaviour. To achieve the 

most natural response possible, the virtual environment needs to be immersive and interactive. To achieve full immersion, the VR 
tool should integrate natural navigation and realistic soundscapes.  

Fourthly, the VR research tool is particularly designed to perform experiments. Thus, a major requirement of the VR tool is its 
ability to collect pedestrian behaviour data. In particular, the VR tool should be able to track participant’s movements, choice and 

gazing behaviour (e.g., walking trajectory, timestamp, head rotation, gaze point). The VR tool should be able to repeatedly perform 

3 

(almost) identical experiments with varying participants. Therefore, it should support slightly alter of the experimental setup per 
participant, while ensuring an as similar as possible experience. For instance, the viewpoint of participants should be able to be 

adjusted according to their height.  

Lastly, the VR tool should be easy and comfortable to use for the participants and the researcher. This requirement does not 

only relate to the participants’ ability to quickly learn how to use and interact with the VR tool but also the participants’ mental and 
physical load of using the VR tool should not cause simulation sickness. Moreover, also the interface between the researcher and 

the VR environment should be relatively well-balanced in order to ease the operation of VR experiments. 

The following sections address how we achieve the above-mentioned requirements and develop the VR tool. 

4  DEVELOPMENT OF THE VR RESEARCH TOOL 

To provide new opportunities for studying pedestrian route and exit choice in complex buildings, a new VR research tool has been 
developed.  The  development  process  of  this  VR  tool  considers  three  steps,  namely  1)  choice  of  the  virtual  environment,  2) 

construction of the virtual environment and 3) implementation of the interactive elements in the virtual environment. This section 
details the steps one by one.  

4.1 

Virtual environment layout  

The aim is to study pedestrians' horizontal and vertical movement behaviour in complex scenarios which better reflect the actual 

situations people experience. Thus, the experimental environment should ideally be a building with multiple floors that enable 
pedestrians to choose between multiple routes and exit choices. Moreover, in the later stage of this research project, the authors 

aim to validate the results generated from the VR tool. Thus it should be possible to recreate the VR scenario in a real-life setting. 
Consequently, the choice has been made to recreate an existing real-life multi-story building in VR at a very high level of detail. 

In this case, the building of Civil Engineering and Geoscience Faculty of Delft University of Technology has been chosen as 
the real-world benchmark of the virtual environment. This faculty building consists of seven floors; most of which feature two 

parallel running hallways, elevators and staircases that run through all levels of the building. Students mainly occupy the lower two 
floors and the top floor of the faculty building, while the faculty staff have their offices on the second to fifth floors.  

To limit the difficulty of assignment performance in the virtual environment, the three intermediate floors of the building (the 
second, third and fourth floor) are chosen as the experimental area (Figure 1). This is the smallest number of floors required to test 

pedestrian route and exit behaviour featuring both horizontal and vertical levels. The layout of all three floors is quite similar, 
except  for one additional space in between the two corridors on the second floor. That is, each floor has eight small corridors 

connecting the two main corridors. Besides that, each floor has five staircases (green) and five elevators (blue).  

Figure 1: Floorplan of the Faculty of Civil Engineering and Geosciences 

4.2 

Construction of the virtual environment  

The construction of the virtual environment featured two steps, namely the development of a 3D model of the building and the 

creation of the virtual environment. Firstly, the 3D model of the building was developed. Secondly, the virtual environment was 
developed based on the 3D model.  

4 

 
 
The first step was logging the details of the existing building by means of a pre-existing outdated 3D model of the building, site 
visits and photographs taken at the building by the researchers. Afterwards, the building was modelled in 3D using the combined 

information from different sources featuring the main characteristics of the building. The overall geometry for the 3D model was 
created using Maya. Here, three floors were created separately. The fourth floor was first built, and the second and third floors were 

built using the fourth floor as a base model because the main geometry of each floor is quite similar. Lastly, an exit floor was 
developed which connects to the second floor of the building. There were five exits located on the exit floor, namely Exit A, B, C, 

D and E. The main entrance of the building is Exit C. Figure 2 shows an overview of the comprehensive virtual building.  

Figure 2: The overview of the virtual building   

Once the overarching geometry (i.e., the internal layout of the building, walls, escalators, staircases) was finished, additional 
environmental  elements  were  added  to  the 3D  model  to  improve  the  accuracy  of  the  building's  representation  and  increase  its 

realism.  Four  types  of  features  were  identified  by  Weisman  (1981)  as  four  classes  of  environmental  variables  that  influence 
pedestrian route and exit choice behaviour within built environments, namely (a) visual access which provides views that one can 

see other parts of the building from a given location (e.g., glass windows), (b) architectural differentiation, which is the difference 
of objects in the building with respect to size, colour, location, etc. (e.g., chairs, cabinets, tables), (c) signs to provide identification 

or directional information (e.g., evacuation signs, exit signs, room numbers), and (d) plan configuration of the building (e.g., floor 
plan) [9,52]. These types of features were modelled in the virtual building in a way that they, as much as possible, resemble the 

current details in the building and placed in their original position. Figure 3 shows four examples of above-mentioned features that 
were added to the virtual environment. 

The second step was creating the virtual environment. Using the 3D model of the building, the virtual environment was created 
in a game development engine, being Unreal  Engine 4 (UE4). UE4 is an open and widely used game engine developed by Epic 

Games (Epic Games, 2019). The UE4 was chosen for developing the complex virtual environment because it provides all the tools 
required to produce a high-quality virtual environment, and its built-in support for VR development makes it easy to work with VR 

hardware (e.g., HTC Vive and Oculus Rift). Furthermore, UE4 builds game levels which are texture-baked, compiled binaries that 
the game engine can efficiently process when running the game [53]. 

5 

 
 
 
a. glasses window 

b. different chairs and tables 

c. evacuation sign 

d. floor plan 

Figure 3: Samples of four types of features added to the virtual environment  

The 3D model was imported from Maya to UE4 using the FBX file format, which is directly readable by UE4. This static model 

in UE4, was accordingly used to render the virtual environment. Rendering effects include, for instance, textures, shadow, lighting, 
reflection, transparency. Deferred Renderer was selected as the rendering solution for the virtual environment, which is the default 

setting of UE4. Compared to forward rendering, which lighting has to be calculated for each vertex or pixel, deferred renderer is 
able to only run a single fragment shader for each render targets, which optimises complex scenes with a number of lights.  

The colours and textures of objects in the virtual environment resemble those of the objects in the current faculty building as 
much as possible. In the virtual building, the corridors feature a mixture of yellow linoleum, coloured plaster walls (e.g., yellow, 

blue, orange), wooden panelling, rough concrete pillars and walls, and glass walls (Figure 4). Special attention was paid to ensure 
the correct representation of these four materials, given that they severely influence pedestrian’s experience in the corridors and 

visibility of the stairs. Figure 5 shows one example of the final rendering of the virtual environment and the real-world view. 

6 

 
 
 
 
 
Figure 4: Illustration of one corridor in the virtual building 

a. virtual building 

b. real world view 

Figure 5: Screenshots of (a) the virtual building and (b) the real world view  

4.3 

Implementation of interaction elements  

In addition to constructing a realistic virtual environment, the VR tool should support user interaction and provide an immersive 

environment  to  perform  experiments.  Thus  it  is  necessary  to  integrate  navigation,  viewpoint,  trigger,  soundscape,  and  data 
recording. This section details the integration of these elements to the VR research tool using UE4. 

1.  Navigation and locomotion  

In  order  to  enable  free  navigation  in  the  virtual  building,  similar  to  how  pedestrians  move  freely  in  a  real-life  building,  a 

combination  of  open  world  navigation  solution  and  steering  locomotion  was  implemented.  This  combination of  both  solutions 
reduces the change that users would experience motion sickness.  

The open-world solution was achieved via the implementation of Navigation Mesh (NavMesh) in UE4, which defines the area 
users are able to walk in the building in order to explore the virtual environment (Figure 6). The NavMesh was only built within 

the walkable space in corridors, while the spaces of offices, elevators or obstacles (e.g., walls, furniture, objects) were not included. 
This mesh was adopted because of two reasons. First, it protects users from running into walls or other obstacles in the virtual 

building to initiate unrealistic experience. Second, it is on the authors’ assumption that when people are required to evacuate from 
the building, office's doors and elevators would be inaccessible and unreachable. 

Figure 6: One example of implemented Navigation Mesh, indicated by green colour 

Steering  locomotion  provides  continuous  movement  and  rotation  in  virtual  space  using  a  hand  controller.  This  particular 
locomotion method allows for effective exploration and interaction with the virtual environment. In the prototype tests, we also 

found the steering locomotion generate less motion sickness compared to teleportation method. Meanwhile, the lack of continuous 
motion during teleportation might weaken presence and alert users that they are in a virtual environment. 

7 

 
 
 
Through  our  test,  the  maximum  movement  speed  in  the  virtual  environment  has  been  limited  to  140  cm/s  to  ensure  that 
participants in the virtual building have, as much as possible, the same walking pace of the spatial layout as pedestrians have in 

real life (e.g., [54]). Meanwhile, our test showed that the speed limit minimises the motion sickness while participants moving in 
the virtual environment. 

The direction of participant’s movement in the virtual environment is controlled by their head rotations towards the direction 

they want to walk. This solution reduces the sickness as the rotations in the virtual and physical environments are the same.  

2.  Viewpoint and avatar 

In UE4, participants' viewpoints are represented by a camera. Participants view the environment in the first-person perspective. 

Upon starting the simulation, the camera is located at a pre-defined start point. Once tracking is established and the user is on the 
starting position, the viewpoint is automatically calibrated to the actual height of the participant. As such, the user’s vantage point 

in the virtual environment is similar to the user’s 'normal' vantage point in real life. 

Literature suggests pedestrian route and exit choice behaviour is affected by two major physical factors: the layout of the setting 

and  the  quality  of  the  environmental  information  [9].  When  evaluating  the  developed  virtual  environment,  we  were  primarily 
interested in how pedestrians interact with the environment. Thus no other avatars were added in the environment at this stage.  

3.  Trigger 

The virtual environment is designed in a way that participants can perform wayfinding assignments through the building. Thus, 

at various specific locations in the building, triggers were placed in order to present information messages to participants. When 
participants enter theses specific locations in the building, information messages would be triggered. These messages appear on 

the VR glasses screen and present a new (wayfinding) assignment to the participant. The virtual environment contains a sequence 
of different triggers. In case if participants enter one of the triggers' location without finishing the last assignment, the next trigger 

would not be activated.  

4.  Soundscape 

In order to investigate pedestrian route and exit choice behaviour during evacuation, a scenario of evacuation drill was also 
stimulated by means of the VR tool. Thus, a 3D soundscape with realistic alarm sounds was incorporated that is also used during 

official evacuations at the faculty building of Civil Engineering and Geosciences. The alarm sound consists of a female voice that 
repeated the following statement: “Attention, please leave the building using the emergency  exits  as indicated. Do not use the 

elevators.”. 

5.  Data recording 

In order to function as a research tool, the VR tool needs to be able to record specific data points for later analysis. The position 
of  the  participant  inside  the  virtual  environment  is  obtained  via  the  tracking  system.  All  the  parameters  related  to  viewpoint's 

locations, such as positional data (x, y, z), head rotations (yaw, roll, pitch), gaze points, timestamps are recorded in milliseconds. 
All information is saved in separate CSV files per participant, which can be easily interpreted using data analytic toolboxes such 

as Python, R and Matlab. It can also be visualised in the virtual building using the built-in playback system to review what happened 
at a specific location or timestamp. For instance, Figure 7 shows the distribution of one user’s walking trajectories (lines) and gaze 

points (dots) in the virtual building.  

8 

Figure 7: One example of the distribution of walking trajectories and gaze points in the virtual building 

5  EVALUATION EXPERIMENT  

In order to validate and ensure the correct functioning of the VR tool, a VR experiment has been designed and conducted. This 
section details the experimental design, the experimental apparatus adopted for this study, experimental procedure, data collection 

and participant’s characteristics.  

5.1 

Experimental design  

The experiment aims to test and evaluate the VR tool via investigating pedestrian route choice behaviour across 1) a horizontal 

level, 2) a vertical level, 3) a combination of  horizontal and vertical level and 4) route and exit choice during evacuation. In total, 
the  experiment  entails  two  parts.  The  first  part  features  walk-through  assignments,  and  the  second  part  features  an  evacuation 

experiment. Both assignments have no formal time limit. In accordance with the experiment description, participants consider all 
the information provided to them by the virtual environment and walk through the building.  

The first part of the experiment is split into three distinct assignments featuring route choices across a combination of horizontal 
and vertical levels. Firstly, pedestrian route choice behaviour at the horizontal level is investigated. Participants are asked to find 

their way from Room 4.02 to Room 4.99 (Figure 1), which ensures they need to cross from the one main corridor to the other and 
walk the length of the building. Secondly, pedestrian route choice behaviour (including staircase choice) at the vertical level is 

investigated. Participants are asked to find their way from Room 4.99 to Room 2.01. This assignment requires participants to move 
between floors and walk the length of the building. Thirdly, pedestrian route and exit choice in both horizontal and vertical level 

are investigated. Participants are asked to find their way from Room 2.01 to Room 4.64, which forces them to switch floors, main 
corridors and walk through the building.  

The second part of the experiment is to investigate pedestrian route and exit choice during evacuation. Participants are asked to 
evacuate from 4.64 and find an exit on the first floor (the exit floor underneath the second floor). When participants exit on the first 

floor, the experiment ends. 

5.2 

Experiment apparatus 

Especially in a complex or large-scale virtual environment, immersion is one of the major key factors for being able to intuitively 
perceive  all  aspects  of  the  scene  [56].  In this  experiment,  participants  were  immersed  in  the  virtual  environment  via  a  pair  of 

earphone and the HTC Vive system, which consisted of a head-mounted display, one controller and two laser-based base stations. 
The UE4 and the SteamVR were used to run the virtual environment. All experiments were taken in a 3.4m x 2.5m room with a 

2.5m high ceiling, lighted by fluorescent lighting, with no reflective surfaces and no exposure to natural lighting (Figure 8). 

9 

 
Figure 8: A simple illustration of the room setup 

The HMD display has 360-degree head-tracking with a 110-degree field of view. It has two 3.4-inch RGB LCD screens, and 

each provides a resolution of 1080 x 1200 pixels (2160×1200 combined resolution) for 3D effects. It has a refresh rate of 90 Hz. 
Head tracking mechanisms translate movements of the participant’s head into virtual camera movements [56]. Participants used 

one hand controller to move in the environment. Figure 9 shows one participant using the HMD display and one controller during 
the experiment. By simply holding the home pad of the controller, participants can move  forward; by releasing the home pad, 

participants can stop moving. The direction of the movement is controlled by the orientation of the participant’s head.  

Figure 9: One participant was using the HMD display and hand controller during the VR experiment  

HTC Vive provides a room-scale technology that allows the user to freely walk in real-life space and reflects their movement 

in the virtual environment. It is achieved by using tracking equipment, namely the base station (also called lighthouse). The base 
stations accurately track the position and orientation of the headset and the controller and translate this into the virtual environment 

in real-time. The base stations were replaced opposed to each other in the room with a 3.4m x 2.5m tracking area, which enables 
participants to move anywhere and re-orient themselves in any position within the range of the base stations. They were mounted 

on stable tripods at the height of 2.3m from the ground and were connected to each other via the sync cable. Once participants can 
move freely in the pre-defined area, it is necessary to protect them from running into the walls in the room. The measure here is 

showing participants the edge of the area when participants attempt to go beyond the tracking region.  

In  addition  to  the  HTC  Vive  system,  a  pair  of  headphone  was  used  by  the  participants.  The  headphone  provided  audio 

information to the participants and in case isolated the noise from the real-life environment.  

5.3 

Experiment procedure 

The procedure of the VR experiment included the following parts, participants: 1) were introduced about the usage of the HMD 
and procedure of the experiment; 2) were familiarised with the test virtual environment and the HMD device in a simple training 

10 

 
 
scenario; 3) took part in the official experiment; 4) filled in the questionnaire. Underneath, the four parts of the procedure are further 
explained. The VR experiment was approved by the Human Research Ethics Committee of the Delft University of Technology 

(Reference ID 944). 

1.  Introduction.  Before  the  experiment,  we  made  sure  participants  have  normal  sight  or  use  corrective  lenses.  Once  the 

participant  arrived  at  the  experiment  room,  the  procedure  of  the  experiment  was  introduced  to  the  participant  via  a  written 
instruction manual in order to ensure all participants had exactly the same information when entering the virtual environment.  

2. Familiarisation. Participants were invited to wear the headset and headphone to walk through a test environment, which 
features a square area with obstacles randomly located in the area. Signs were added on the wall in the test environment. Participants 

were instructed to walk from A to B to C (Figure 10). This training assignment was used to familiarise the participants with the 
control of the device and discover any tendency of motion sickness. During the assignment, participants needed to perform basic 

movement operations and get acquainted with the system's mode of operation. The familiarisation phase lasted approximately 3 
minutes. Participants who felt sick during this period were allowed to have a break, and after the break, they could decide whether 

to quit or continue the VR experiment. 

Figure 10: A screenshot of the test environment 

3. Performing the assignments. After the familiarisation phase, participants were teleported to the actual virtual building. As 
stated in section 4.1, the start position is Room 4.02 (Figure 1), where participants were instructed to begin the first assignment. 

When participants reached the destination of the assignment, the information showed up to instruct participants to begin the next 
assignment  (Figure  11).  At  the  beginning  of  the  fourth  assignment,  the  evacuation  alarm  sound  was  automatically  triggered, 

followed by a voice message instructing all people to evacuate from the building.  

Figure 11: A screenshot of participant's view during the experiment, showing the current assignment 

4.  Filling  the  questionnaire.  A  questionnaire  was  provided  to  the  participants  directly  after  participants  finished  their 

assignments, which they filled in using a desktop located in the room. The last step of the procedure comprised of the researcher 
ensuring that participants were all right before they were allowed to leave the experimental room. 

11 

 
 
5.4 

Data collection  

The experiment collected two types of data, namely the behavioural data and questionnaire data. Firstly, participant behaviour in 

the virtual environment was recorded. Participant's positions, head rotations, gaze points, timestamp were recorded in milliseconds 
within the UE4. Jointly these collected data captured a rich set of information related to pedestrian route and exit choice behaviour. 

These  data  can  be  translated  into  four  types  of  behavioural  data,  namely  (1)  participant  route  choices,  (2)  the  travel  time  of 
participants during all four assignments, (3) the choice for the specific staircase(s) during each assignment and final exit choice, 

and (4) gaze points of how environmental elements draw the attention of participants.  

Secondly, a questionnaire was designed in order to obtain the personal features and experiences of each participant regarding 

the  virtual  experiment.  The  questionnaire  contained  five  sections:  (1)  participant's  information,  which  included  their  socio-
demographic information and their experience with VR and the experimental building in real-life, (2) the face validity questionnaire, 

which  assessed  the  realism  of  the  virtual  environment,  (3)  the  Simulator  Sickness  Questionnaire  [57],  which  determined  if 
participant's experience sickness throughout the experiment, (4) the System Usability Scale [58], which assessed the usability of 

the applied VR system as a pedestrian simulator, (5) the Presence Questionnaire [59], which measured participant's experience of 
presence in the virtual environment. Here, a comprehensive questionnaire was used to ensure that the authors are able to study the 

validity of the virtual environment and participant’s VR experience in great detail. 

5.5 

Participant’s characteristics  

A total number of 37 participants took part in the VR experiment, and 36 participants finished all assignments. One participant 

asked to take a break during the third assignment and did not finish the whole experiment. Thus, the results discussed underneath 
are based on 36 participants, which included eighteen females and eighteen males. The age of these participants ranged from 17 to 

41  years  (M  =  28.58  years,  SD  =  5.95  years).  Table  1  presents  the  descriptive  statistics  of  the  participants.  It  shows  that  the 
participants  were  generally  familiar  with  computer  gaming  and  not  very  familiar  with  VR.  Moreover,  most  of  the  participants 

received  relatively  high  education.  All  participants  were  volunteers  and  experienced  the  experiment  one  by  one.  None  of  the 
participants complained about sickness during the experiment and all finished the experiment completely.  

Descriptive information 
Highest education level 

Previous experience with VR 

Familiarity  with  any  computer 

gaming 

Table 1: Demographic information of participants. 

Category 
High school or equivalent 
Bachelor degree or equivalent   
Master degree or equivalent 
Doctoral degree or equivalent 
Never 
Seldom 
Sometimes 
Often 
Quite often 
Not at all familiar 
A-little familiar 
Moderately familiar 
Quite-a-bit familiar 
Very familiar 

Number (percentage) 
  5 (13.89%) 
  6 (16.67%) 
19 (52.78%) 
  6 (16.67%) 
11 (30.56%) 
18 (50.00%) 
  6 (16.67%) 
  1 (2.78%) 
  0 (0.00%) 
  7 (19.44%) 
  5 (13.89%) 
  8 (22.22%) 
  7 (19.44%) 
  9 (25.00%) 

6  RESULTS AND DISCUSSION  

The main objective of the VR experiment is to demonstrate the functionality and evaluate the usability of the developed VR research 
tool. This section first illustrates the ability of the VR tool to collect pedestrian behavioural data, namely pedestrian route choice 

and exit choice behaviour, time spent, and point of interests. Next, this section examines the validity, realism and usability of the 
VR tool based on the results of the subjective data collected from the questionnaire (i.e., face validity, the simulation sickness, 

feeling of presence, system usability).  

12 

6.1 

Objective standpoints 

This sub-section presents an analysis of objective behavioural data collected during the VR experiment, including the time spent, 

the route and exit choice and point of interests.  

6.1.1  Time spent on assignments  

One important measurement of pedestrian route and exit choice behaviour is the time spent on the assignments, which provides 

information regarding the ease with which participants navigate through the building. The time spent is defined as the time period 
between the moment in time a participant starts an assignment and the moment in time the participant arrives at the destination.  

On average, participants spent 568.5 seconds (SD = 62.1 s) to finish four assignments. Figure 12 shows the distribution of the 
time spent by the participants on each assignment. On average, the participants spent the most time on assignment two (M = 200.5 

s, SD = 18.5 s), followed by assignment one (M = 160.3 s, SD = 20.1 s), assignment three (M = 140.1 s, SD = 23.8 s), and the least 
time on assignment four (M = 66.2 s, SD = 11.4 s). This is in line with our expectation, as the minimum distance required to travel 

for  each  assignment  also  decreases  in  the  same  order.  Besides  that,  we  see  that  the  time  spent  is  clustered,  in  particular  for 
assignments 2 and 4. This finding suggests that the variation in the walking speed was limited. 

Figure 12: Histograms of the time spent by the participants 

6.1.2  Route and exit choice behaviour  

The walking trajectories of participants are recorded at 10 Hz, which means that we obtain approximately 5600 data points per 

participant  describing  their  movements  throughout  the  four  assignments.  The  trajectories  clearly  reveal  the  route  choices  of 
participants. For instance, Figure 13 shows the trajectory of one participant during all assignments. Here, the colour of the trajectory 

indicates  the  time:  blue  (start)-green-yellow-red  (end).  During  the  third  assignment  (Room  2.01  to  Room  4.64),  there  was  an 
obvious detour on the fourth floor when this participant clearly ‘missed’ the chances to use wider intersections to reach Room 4.64.  

13 

 
Figure 13: Visualisations of one participant's route choice during four assignments 

Hölscher et al. (2007) [60] proposed three distinct strategies for pedestrian route choice in a multi-story building environment. 
Pedestrians use the central point strategy to find their way by frequently visiting well-known parts of the building, even if this 

requires considerable detours. Pedestrians that employ the direction strategy first move to the horizontal position of the destination 
as  directly  as  possible  (irrespective  of  level-changes).  Pedestrians  use  the  floor  strategy  first  find their  way  to  the  floor  of  the 

destination  (irrespective  of  the  horizontal  position of  the  destination).  To  analyse  participants'  route  and  choice  behaviour,  the 
complete set of  walking trajectories was split into four separate sequences pertaining to each assignment. Figure 14 shows the 

walking trajectories of all participants during the first assignment (Room 4.02 to Room 4.99). Two major strategies regarding route 
choice  were  detected. Participants  who  adopted  central  point  strategy  first  went  straight  from  Room  4.02,  then  used  the  wider 

intersections  to  cross  towards  the  other  corridor,  on  which  side  Room  4.99  resides,  and  then  continued  walking  towards  the 
destination.  There  were  also  some  participants that  chose  shortcuts  and  crossed  the  small  intersections between  the  two  major 

corridors. The other main strategy  was direction strategy, participants chose to turn directly to other wider corridor at the first 
interaction and then walked straight down the corridor towards the destination. It is interesting to see, that participants clearly adopt 

different strategies in the virtual environment. 

14 

 
 
Figure 14: Participants' walking trajectories during the first assignment 

After finishing assignment one, participants were instructed to find their way from Room 4.99 to Room 2.01. This assignment 
involved their movement across different floors in the building while both rooms remaining on the same side. Figure 15 shows the 

walking trajectories of all participants during this assignment. It shows that participants predominantly applied the direction and 
floor strategy. Participants who employed the direction strategy stayed on the fourth floor and walked to the direction of Room 

2.01, then went down using one of the staircases. Participants who employed floor strategy initially went down to the second floor 
using the first staircase they encountered nearby Room 4.99, then they subsequently found the target room number within the floor. 

Only one participant chose to go from the fourth floor to the third floor, then to the second floor, a clear deviation from the other 
strategies.  

After the first assignment, participants were clearly more aware of the structure of the building, for instance, rooms were located 
with even and uneven number on different sides. Thus, there was less switching of sides in their route because they were more 

conscious of Room 2.01 is located on the even side of the corridor. Only a few participants chose to stay on the opposite side of 
the building until they reached the last intersection point before their destination. It might because of the disorientation effects 

caused by changing floors [61]. Most participants chose to stay at the side of the building where Room 4.99 and 2.01 were located. 

15 

 
Figure 15: Walking trajectories during the second assignment. 

Figure  16  shows  the  route  trajectories  of  participants  during  the  third  assignment  (Room  2.01  to  Room  4.64).  Participants 
predominantly employed the floor strategy who firstly climbed up the fourth floor using the first staircase they met and accordingly 

kept walking along the side of Room 4.64. Some others used direction strategy and first  moved along the second floor before 
entering the stairs. Although it was the third assignment and some learning effect was recorded, for some participants it was still 

not entirely  clear on which side  of the destination would be. Hence, they adopted the central point strategy,  stuck to the main 
corridor they already knew and took a detour via the other side of the building which is indicated by the green plots opposite Room 

4.64.  

Figure 17, furthermore, shows the aggregation of the trajectories of all participants during the last assignment (evacuate from 

Room 4.64 to an exit). Most of the participants either chose to go down from the right side of Room 4.64 or the left side. Even 
though  five  exits  were  available,  only  the  exits  near  elevator  C  and  D  were  chosen,  which  shows  the  usage  of  the  exits  is 

asymmetrical. This behaviour is in line with other studies look at exit usage [62–64]. Amongst the choices, 18 participants chose 
Exit C and 18 participants chose Exit D. These are the closet two exits for participants. This result is consistent with the studies 

which found that pedestrians were overall more likely to choose the nearest exits and shortest routes [16,29,30,65,66]. Interestingly, 
the split between the two exits is 50% - 50%, which suggests that we see no bias towards the side the participant approached Room 

4.64 from. The results also suggest that participants prefer to use wider corridors among four assignments, which are concordant 
with studies of [35]. 

16 

 
Figure 16: Walking trajectories during the third assignment. 

Figure 17: Walking trajectories during the fourth assignment 

6.1.3  Point of interests in the space 

While performing the assignment, participants kept searching for information using the signs and landmarks on the route towards 

the destination. The collected gaze points data helps to analyse  what objects or information in the virtual environment capture 
participants' attention. By combing the head rotations with route trajectory data, we can investigate how particular elements in 

space influence pedestrian route and exit choice behaviour. For instance, Figure 18 shows the scatter of one individual’s (the same 
participant in Figure 13) gaze points during all four assignments. The directionality of its gaze towards the side of the corridors 

17 

 
 
indicates that the individual's focus has mainly been directed towards room number signs. Figure 19 shows the overall gaze points 
of all participants during four assignments. From this analysis, we can derive that during the first three assignments (Figure 19 a-

c), the main visual attractions in the building are room numbers and fire doors (indicated by the red dots along with the room and 
red vertical lines across the main corridors). During the last evacuation assignment, participants paid more attention to the exit 

signs (Figure 19d), which are indicated by the red dots near the two staircases around Room 4.64. 

Figure 18: Visualisations of one participant's gaze points 

18 

 
a. the first assignment 

b. the second assignment 

c. the third assignment 

d. the fourth assignment 

Figure 19: Visualisations of all participants’ gaze points during four assignments 

6.2 

Subjective standpoints    

This  sub-section  describes  the  results  of  subjective  data  derived  by  means  of  the  questionnaires,  namely  the  face  validity 
questionnaire, the Simulation Sickness questionnaire, the Presence questionnaire and the System Usability Scale questionnaire.  

6.2.1  Face validity  

Face validity refers to the degree of a simulator's realism compare to the real situation. The realism of participants' experience with 

the VR tool was assessed using a five-point Likert scale ranging from 1 (not at all realistic) to 5 (completely realistic). The results 
of the face validity are provided in Table 2. Amongst four elements regarding the realism of the virtual environment, the realism 

of  the  evacuation  alarm  sound  received  the  highest  score  (M  =  4.78),  which  shows  participants  were  highly  engaged  in  the 
assignment and felt the threaten of the emergency situation. The lowest score was assigned to the realism of the movement ability 

(M = 3.8). Participants needed to hold the controller's button while walking in the virtual environment; this might be the reason for 
having a lower score compared to other perspectives. Overall, the average score is 4.07, and three scores (out of four) are above 4, 

19 

 
 
 
 
which indicate that the VR tool has a relatively high degree of realism with respect to the virtual environment and assignment 
design. Thus, these results establish the face validity of the VR tool. 

Table 2: Rating of VR tool realism 

The realism of the VR tool 

The realism of the virtual building 

The realism of the virtual furniture (chairs, doors, etc.) 

The realism of the movement ability 

The realism of the evacuation alarm sound 

6.2.2  Simulation sickness  

Mean 

4.11 

4.19 

3.19 

4.78 

SD 

0.57 

0.58 

0.67 

0.42 

Simulation sickness is generally defined as the discomfort that arises from using simulated environments [67]. When designing a 

VR tool, it is essential to evaluate whether the tool potentially causes simulation sickness. The Simulator Sickness Questionnaire 
[57] determined participant's experience on a set of symptoms (e.g., fatigue, headache) in a 4-point Likert scale, from 0 (none) to 

3  (severe).  It  can  be  summed  to  a  total  symptom  score  as  well  as  grouped  into  three  subscales,  namely  nausea,  oculomotor 
disturbance, and disorientation. The total score is calculated by summing the reported values in each subscale and accordingly 

multiplying the result by 3.74 [68]. The total score of SSQ can range from 0 to 236. For each subscale, the scores are based on the 
reported scores for each symptom and then multiplied by the weight for that particular subscale.  

The total score reflects the severity of the symptomatology of participants using the VR tool and index the troublesomeness of 
a simulator [69]. In the present study, the average total score of simulation sickness questionnaire is 13.61 (SD = 13.20) with up to 

a maximum of sixteen-minute exposure to the virtual environment. The total score is relatively low and only negligible symptoms 
or minimal symptoms were found among all participants according to the categorisation of symptoms [69]. Table 3 presents the 

results of each subscale of SSQ. It shows that the subscale of disorientation received the highest score, followed by Oculomotor 
and Nausea. Although disorientation subscale is related to vestibular disturbances such as dizziness and vertigo, high disorientation 

may be an indicator of having experienced higher levels of virtual presence [70]. The relatively high disorientation score might be 
the result of rotation-induced effects. That is, while participants walking through the virtual environment, they can rotate their head 

side to side, which might cause a response lag. Moreover, the current experiment assignments involved changing floors and some 
turning movements on the stairs in the virtual building, which are key sources of disorientation about one’s heading and position 

in a building. The relation between disorientation and floor changes was also found in [61].  

Table 3: Subscales of SSQ: Means and standard deviations. 

Subscale  
Nausea 
Oculomotor 
Disorientation 

6.2.3  Feeling of presence  

Mean  
  7.95 
13.27 
14.69 

SD 
11.06 
12.07 
18.81 

The  sense  of  presence  reported  by  participants  is  a  key  factor  to  evaluate  the  effectiveness  of  virtual  environments  [59].  The 
Presence Questionnaire (PQ) is a wildly applied questionnaire to measure the degree of participant's feeling of presence in the 

virtual environment. It depends on four subscales, namely Sensory fidelity, Immersion, Involvement and Interface quality [59]. 
Participants use a 7-point scale format to rate 29 questions. 

The total score was counted by summing the reported scores of the 29 items. The average total score for PQ in this study is 
146.17  (SD  =  13.56),  which  indicates  that  the participants  had  a strong  sense  of  presence.  Table 4  shows  the  mean  value  and 

standard  deviations  of  the  four  subscales  in  the  PQ  questionnaire.  The  Immersion  subscale  received  the  highest  score,  which 
confirms that the participants felt a high level of immersion in the designed virtual environment. Meanwhile, the score of Sensory 

fidelity established the accuracy of sensory stimulation. The Involvement score indicates that participants were able to focus their 
attention and energy in the virtual environment. The interface quality score shows that control devices had little distraction from 

participants' assignment performance, and the participants were able to concentrate on the assignments. Furthermore, participants' 
response to Question 8, (i.e., “How much did your experience in the virtual environment seem consistent with your real-world 

20 

experience  ?”,  M  =  5.13,  SD  =  0.96)  indicates  that  the  experiences  in  the  virtual  building  are  consistent  with  the  real-world 
experience.  

Table 4: Subscales of PQ: Means and standard deviations (range from 1 to 7). 

Involvement 

Sensory fidelity 

Immersion 

Interface qualitya 

Mean  
SD  

a Reversed items 

4.84 
0.61 

6.2.4  Usability of the VR tool  

4.94 
0.85 

5.76 
0.49 

4.14 
0.97 

System  Usability  Scale  questionnaire  represents  a  composite  measure  of  the  overall  usability  of  the  simulator  system  [58].  It 

contains questions such as, "I thought the system was easy to use" and "I found the various functions in this system were well 
integrated". Participants rated the ten items of this questionnaire on a 5-point Likert scale (i.e., 1 = strongly disagree, 5 = strongly 

agree). The total score of SUS is calculated by summing the converted responses on ten items and accordingly multiplying the 
result by 2.5. The total score of SUS ranges from 0 to 100.  

The total score of SUS can be translated into adjective ratings for interpreting the results, such as 'worst imaginable', 'poor', 
'OK', 'good', 'excellent', 'best imaginable' [71]. In the present study, the average score of the VR tool is 81.32 (SD = 12.12), which 

suggested 'excellent' usability of the VR simulator. Meanwhile, according to the observation from the researcher, all participants 
were able to easily understand all four assignments and how to use the HMD and controller to interact with the virtual environment.  

7  CONCLUSIONS AND FUTURE RESEARCH 

This study presents a new VR tool that is developed by means of Maya and UE4 which provides substantial benefits for collect 
pedestrian route and exit choice behavioural data in a multi-story complex building. The VR tool supports free movements in all 

directions, allows for the monitoring of pedestrian behaviour throughout a complex building and includes the tracking of walking 
trajectories, gaze points and head movements. The VR tool addresses several limitations with respect to using VR for pedestrian 

behaviour research, such as free movement across horizontal and vertical level, the accurate collection of a wide range of data 
related to pedestrian behaviour. 

This primary experiment aimed to demonstrate the functionality of the VR tool by showcasing participant's time spent, route 
and exit choice and point of interests in the space. Additionally, the realism of participants' experience with the VR tool, simulation 

sickness, the feeling of presence in the virtual environment and the usability of the VR tool were evaluated via questionnaires.  

The results of this study show that this VR tool is able to collect participants’ route and exit choice behavioural data. It shows 

that participants predominantly applied the direction and floor strategy when walking in a multi-story building environment. Under 
evacuation conditions, participants were overall more likely to choose the nearest exits and shortest routes. Analysis of the gaze 

points shows that room numbers, fire doors and exit signs were the major attractors in the building. The questionnaire data showed 
that the VR tool had a high degree of realism and participants experienced a good feeling of presence in the virtual environment. 

Participants also only experienced minimal symptoms during the experiment. Meanwhile, Participants gave the simulator good 
marks on usability. To summarise, the results of this study confirm that this new VR tool is capable of precise collection of data 

pertaining the movement and choice behaviour of pedestrians in a complex multi-story building and the show that the high realism 
of the virtual environment, high immersive feeling, high usability, and low simulator sickness incidence. 

Despite the innovation presented by the VR tool, this study has some limitations and provides implications for future research. 
First, the current applied HMD device only uses head tracking to present participants movements in the environment. In future 

research, applying other sensors, such as eye-tracking and body-tracking, would allow researchers to track pedestrian gaze points 
and  movements  more  precisely.  Second,  although  the  face  validity  shows  the  high  level  of  realism  of  the  developed  virtual 

environment,  further  validation  studies  are  needed  to  determine  whether  the  pedestrian  movement  and  choice  behaviour,  gaze 
points are also similar to pedestrians’ behaviour in real-life. Third, no other agents or socially relevant variables were added at this 

stage because the goal of the current VR tool was to investigate the interaction between pedestrian and environment. One of the 
advantages of VR is the ability to rapidly change the scenario or add other elements to the virtual environment. The researchers of 

this study are continuing to explore the use of VR in other perspectives of pedestrian route and exit choice behaviour, for example, 

21 

 
adding  multiple  users  in  the  environment  simultaneously,  wayfinding  information  or  dynamic  obstacles  and  investigate  their 
influences on pedestrian behaviour.   

ACKNOWLEDGMENTS 

We thank the China Scholarship Council for their financial contribution. This research is also supported by the ALLEGRO project, 

which is financed by the European Research Council (Grant Agreement No. 669792). We also thank Arno Freeke and Arend-Jan 
Krooneman from the VR Zone of the Delft University of Technology for the help with developing the VR tool.  

REFERENCES 

[1] 

A. Schadschneider, W. Klingsch, H. Klüpfel, T. Kretz, C. Rogsch, A. Seyfried, Evacuation Dynamics: Empirical Results, Modeling and Applications, 

Encycl. Complex. Syst. Sci. (2009) 3142–3176. https://doi.org/10.1007/978-0-387-30440-3_187. 

[2] 

C.G. Prato, Route choice modeling: Past, present and future research directions, J. Choice Model. 2 (2009) 65–100. https://doi.org/10.1016/S1755-

5345(13)70005-8. 

[3] 

Y. Feng, D.C. Duives, S.P. Hoogendoorn, Using virtual reality to study pedestrian exit choice behaviour during evacuations, Saf. Sci. 137 (2021) 105158. 

https://doi.org/10.1016/j.ssci.2021.105158. 

[4] 

E.R. Galea, S.J. Deere, C.G. Hopkin, H. Xie, Evacuation response behaviour of occupants in a large theatre during a live performance, Fire Mater. 41 

(2017) 467–492. https://doi.org/10.1002/fam.2424. 

[5] 

S. Heliövaara, J.M. Kuusinen, T. Rinne, T. Korhonen, H. Ehtamo, Pedestrian behavior and exit selection in evacuation of a corridor - An experimental 

study, Saf. Sci. 50 (2012) 221–227. https://doi.org/10.1016/j.ssci.2011.08.020. 

[6] 

M. Kobes, I. Helsloot, B. de Vries, J.G. Post, N. Oberijé, K. Groenewegen, Way finding during fire evacuation; an analysis of unannounced fire drills in a 

hotel at night, Build. Environ. 45 (2010) 537–548. https://doi.org/10.1016/j.buildenv.2009.07.004. 

[7] 

D. Nilsson, A. Johansson, Social influence during the initial phase of a fire evacuation-Analysis of evacuation experiments in a cinema theatre, Fire Saf. J. 

44 (2009) 71–79. https://doi.org/10.1016/j.firesaf.2008.03.008. 

[8] 

Z. Fang, W. Song, J. Zhang, H. Wu, Experiment and modeling of exit-selecting behaviors during a building evacuation, Physica A. 389 (2010) 815–824. 

https://doi.org/10.1016/j.physa.2009.10.019. 

[9] 

C. Hölscher, T. Meilinger, G. Vrachliotis, M. Brösamle, M. Knauff, Finding the Way Inside: Linking Architectural Design Analysis and Cognitive 

Processes, Spat. Cogn. IV. Reason. Action, Interact. 3343 (2005) 1–23. 

[10] 

G.Y. Jeon, J.Y. Kim, W.H. Hong, G. Augenbroe, Evacuation performance of individuals in different visibility conditions, Build. Environ. 46 (2011) 1094–

1103. https://doi.org/10.1016/j.buildenv.2010.11.010. 

[11] 

K.-J. Zhu, Q. Shi, Experimental Study on Choice Behavior of Pedestrians during Building Evacuation, Procedia Eng. 135 (2016) 206–215. 

https://doi.org/10.1016/j.proeng.2016.01.110. 

[12] 

Y. Feng, D. Duives, W. Daamen, S. Hoogendoorn, Data collection methods for studying pedestrian behaviour: A systematic review, Build. Environ. 187 

(2021) 107329. https://doi.org/https://doi.org/10.1016/j.buildenv.2020.107329. 

[13] 

M. Haghani, M. Sarvi, Crowd behaviour and motion: Empirical methods, Transp. Res. Part B Methodol. 107 (2018) 253–294. 

https://doi.org/10.1016/j.trb.2017.06.017. 

[14] 

L. Cao, J. Lin, N. Li, A virtual reality based study of indoor fire evacuation after active or passive spatial exploration, Comput. Human Behav. 90 (2019) 

37–45. https://doi.org/10.1016/j.chb.2018.08.041. 

[15] 

Y. Feng, D.C. Duives, S.P. Hoogendoorn, The impact of guidance information on exit choice behavior during an evacuation – a VR study, in: Traffic 

Granul. Flow 2019, 2019. 

[16] 

M. Kobes, I. Helsloot, B. De Vries, J. Post, Exit choice, (pre-)movement time and (pre-)evacuation behaviour in hotel fire evacuation - Behavioural 

analysis and validation of the use of serious gaming in experimental research, Procedia Eng. 3 (2010) 37–51. https://doi.org/10.1016/j.proeng.2010.07.006. 

[17] 

F. Rebelo, P. Noriega, Indoor Human Wayfinding Performance Using Vertical and Horizontal Signage in Virtual Reality, Hum. Factors Ergon. Manuf. 

Serv. Ind. 24 (2014) 601–615. https://doi.org/10.1002/hfm. 

[18] 

E. Ronchi, K. Fridolf, H. Frantzich, D. Nilsson, A.L. Walter, H. Modig, A tunnel evacuation experiment on movement speed and exit choice in smoke, 

Fire Saf. J. 97 (2018) 126–136. https://doi.org/10.1016/j.firesaf.2017.06.002. 

[19] 

N.W.F. Bode, A.U. Kemloh Wagoum, E.A. Codling, Information use by humans during dynamic route choice in virtual crowd evacuations, R. Soc. Open 

Sci. 2 (2015). https://doi.org/10.1098/rsos.140410. 

[20] 

U. Dogu, F. Erkip, Spatial factors affecting wayfinding and orientation: A case study in a shopping mall, Environ. Behav. 32 (2000) 731–755. 

https://doi.org/10.1177/00139160021972775. 

[21] 

Z. Fang, W. Song, J. Zhang, H. Wu, Experiment and modeling of exit-selecting behaviors during a building evacuation, Physica A. 389 (2010) 815–824. 

https://doi.org/10.1016/j.physa.2009.10.019. 

[22] 

K. Fridolf, E. Ronchi, D. Nilsson, H. Frantzich, Movement speed and exit choice in smoke- filled rail tunnels, Fire Saf. J. 59 (2013) 8–21. 

22 

https://doi.org/10.1016/j.firesaf.2013.03.007. 

[23] 

K.J. Zhu, Q. Shi, Experimental Study on Choice Behavior of Pedestrians during Building Evacuation, Procedia Eng. 135 (2016) 206–215. 

https://doi.org/10.1016/j.proeng.2016.01.110. 
M. Imanishi, T. Sano, Route Choice and Flow Rate in Theatre Evacuation Drills : Analysis of Walking Trajectory Data-set, Fire Technol. 55 (2019) 569–

593. https://doi.org/10.1007/s10694-018-0783-2. 
A. Rahouti, R. Lovreglio, S. Gwynne, P. Jackson, S. Datoussaïd, A. Hunt, Human behaviour during a healthcare facility evacuation drills : Investigation of 

[24] 

[25] 

pre-evacuation and travel phases, Saf. Sci. 129 (2020) 104754. https://doi.org/10.1016/j.ssci.2020.104754. 

[26] 

M. Haghani, Empirical methods in pedestrian, crowd and evacuation dynamics: Part II. Field methods and controversial topics, Saf. Sci. 129 (2020) 

104760. https://doi.org/10.1016/j.ssci.2020.104760. 

[27] 

J.E. Almeida, R.J. Rossetti, J.T.P.N. Jacob, B.M. Faria, A.L. Coelho, Serious games for the human behaviour analysis in emergency evacuation scenarios, 

Cluster Comput. 20 (2017) 707–720. https://doi.org/10.1007/s10586-017-0765-z. 

[28] 

K. Andree, D. Nilsson, J. Eriksson, Evacuation experiments in a virtual reality high-rise building: exit a and waiting time for evacuation elevators, FIRE 

Mater. (2015) 4B. https://doi.org/10.1002/fam. 

[29] 

R.Y. Guo, H.J. Huang, S.C. Wong, Route choice in pedestrian evacuation under conditions of good and zero visibility: Experimental and simulation 

results, Transp. Res. Part B Methodol. 46 (2012) 669–686. https://doi.org/10.1016/j.trb.2012.01.002. 

[30] 

H. Li, J. Zhang, L. Xia, W. Song, N.W.F. Bode, Comparing the route-choice behavior of pedestrians around obstacles in a virtual experiment and a field 

study, Transp. Res. Part C Emerg. Technol. 107 (2019) 120–136. https://doi.org/10.1016/j.trc.2019.08.012. 

[31] 

M. Kinateder, E. Ronchi, D. Gromer, M. Müller, M. Jost, M. Nehfischer, A. Mühlberger, P. Pauli, Social influence on route choice in a virtual reality 

tunnel fire, Transp. Res. Part F Traffic Psychol. Behav. 26 (2014) 116–125. https://doi.org/10.1016/j.trf.2014.06.003. 

[32] 

Q. Li, Y. Gao, L. Chen, Z. Kang, Emergency evacuation with incomplete information in the presence of obstacles, Physica A. 533 (2019) 122068. 

https://doi.org/10.1016/j.physa.2019.122068. 

[33] 

H. Schrom-Feiertag, V. Settgast, S. Seer, Evaluation of indoor guidance systems using eye tracking in an immersive virtual environment, Spat. Cogn. 

Comput. 17 (2017) 163–183. https://doi.org/10.1080/13875868.2016.1228654. 

[34] 

C.-H. Tang, W.-T. Wu, C.-Y. Lin, Using virtual reality to determine how emergency signs facilitate way-finding, Appl. Ergon. 40 (2009) 722–730. 

https://doi.org/10.1016/j.apergo.2008.06.009. 

[35] 

E. Vilar, F. Rebelo, P. Noriega, E. Duarte, C.B. Mayhorn, Effects of competing environmental variables and signage on route-choices in simulated 

everyday and emergency wayfinding situations, Ergonomics. 57 (2014) 511–524. https://doi.org/10.1080/00140139.2014.895054. 
R. Zhu, J. Lin, B. Becerik-gerber, N. Li, Human-building-emergency interactions and their impact on emergency response performance : A review of the 

[36] 

state of the art, Saf. Sci. 127 (2020) 104691. https://doi.org/10.1016/j.ssci.2020.104691. 

[37] 

K.M. Stanney, R.R. Mourant, R.S. Kennedy, Human Factors Issues in Virtual Environments: A Review of the Literature, Presence. 7 (1998) 327–351. 

https://doi.org/10.1162/105474698565767. 

[38] 

C. Li, W. Liang, C. Quigley, Y. Zhao, L.F. Yu, Earthquake Safety Training through Virtual Drills, IEEE Trans. Vis. Comput. Graph. 23 (2017) 1388–

1397. https://doi.org/10.1109/TVCG.2017.2656958. 

[39] 

Y. Feng, D. Duives, W. Daamen, S. Hoogendoorn, Pedestrian exit choice behavior during an evacuation – a comparison study between field and VR 

experiment, in: Transp. Res. Board 98th Annu. Meet. Transporation Res. Board, 2019. 

[40] 

M. Kinateder, W.H. Warren, Social Influence on Evacuation Behavior in Real and Virtual Environments, Front. Robot. AI. 3 (2016) 1–8. 

https://doi.org/10.3389/frobt.2016.00043. 

[41] 

M. Kinateder, E. Ronchi, D. Nilsson, M. Kobes, M. Müller, P. Pauli, A. Mühlberger, Virtual Reality for Fire Evacuation Research, 2 (2014) 313–321. 

https://doi.org/10.15439/2014F94. 
Z. Feng, V. Gonzalez, R. Amor, R. Lovreglio, G. Cabrera-Guerrero, Immersive Virtual Reality Serious Games for Evacuation Training and Research : A 

[42] 

Systematic Literature Review, Comput. Educ. 127 (2018) 252–266. https://doi.org/10.1016/j.compedu.2018.09.002. 

[43] 

D. Bauer, V. Settgast, H. Schrom-Feiertag, A. Millonig, Making the usage of guidance systems in pedestrian infrastructures measurable using the virtual 

environment DAVE, Transp. Res. Part F Traffic Psychol. Behav. 59 (2018) 298–317. https://doi.org/10.1016/j.trf.2018.09.012. 

[44] 

M. Kinateder, W.H. Warren, K.B. Schloss, What color are emergency exit signs? Egress behavior differs from verbal report, Appl. Ergon. 75 (2019) 155–

160. https://doi.org/10.1016/j.apergo.2018.08.010. 

[45] 

M. Kinateder, M. Müller, M. Jost, A. Mühlberger, P. Pauli, Social in fl uence in a virtual tunnel fi re e In fl uence of con fl icting information on 

evacuation behavior *, 45 (2014) 1649–1659. https://doi.org/10.1016/j.apergo.2014.05.014. 

[46] 

H. Li, T. Thrash, C. Hölscher, V.R. Schinazi, The effect of crowdedness on human wayfinding and locomotion in a multi- level virtual shopping mall, J. 

Environ. Psychol. 65 (2019) 101320. https://doi.org/10.1016/j.jenvp.2019.101320. 

[47] 

R. Lovreglio, V. Gonzalez, Z. Feng, R. Amor, M. Spearpoint, J. Thomas, M. Trotter, R. Sacks, Prototyping virtual reality serious games for building 

earthquake preparedness: The Auckland City Hospital case study, Adv. Eng. Informatics. 38 (2018) 670–682. https://doi.org/10.1016/j.aei.2018.08.018. 

[48] 

G. Simpson, L. Johnston, M. Richardson, An investigation of road crossing in a virtual environment, Accid Anal Prev. 35 (2003) 787–796. 

https://doi.org/10.1016/S0001-4575(02)00081-7. 

[49] 

V. Cavallo, A. Dommes, N.T. Dang, F. Vienne, A street-crossing simulator for studying and training pedestrians, Transp. Res. Part F Traffic Psychol. 

23 

Behav. (2016). https://doi.org/10.1016/j.trf.2017.04.012. 

[50] 

K.J. Jeffery, A. Jovalekic, M. Verriotis, R. Hayman, Navigating in a three-dimensional world, Behav. Brain Sci. 36 (2013) 523–587. 

https://doi.org/10.1017/S0140525X12002476. 

[51] 

[52] 

[53] 

[54] 

[55] 

J. Weisman, Evaluating architectural legibility Way-finding in the built environment, Environ. Behav. 13 (1981) 189–204. 

M. Raubal, M. Worboys, A formal model of the process of wayfinding in built environments, in: Int. Conf. Spat. Inf. Theory, 1999: pp. 381–399. 

https://doi.org/10.1007/3-540-48384-5_25. 

D. Arendash, The unreal editor as a web 3D authoring environment, Web3D Symp. Proc. 1 (2004) 119–126. https://doi.org/10.1145/985040.985058. 

K. Fitzpatrick, M.A. Brewer, S. Turner, Another Look at Pedestrian Walking Speed, Transp. Res. Rec. 1982 (2006) 21–29. 

J. Choi, E.R. Galea, W. Hong, Individual Stair Ascent and Descent Walk Speeds Measured in a Korean High-Rise Building, Fire Technol. 50 (2014) 267–

295. https://doi.org/10.1007/s10694-013-0371-4. 

[56] 

T. Hilfert, M. König, Low-cost virtual reality environment for engineering and construction, Vis. Eng. 4 (2016). https://doi.org/10.1186/s40327-015-0031-

5. 

[57] 

R.S. Kennedy, N.E. Lane, K.S. Berbaum, M.G. Lilienthal, Simulator Sickness Questionnaire: An Enhanced Method for Quantifying Simulator Sickness, 

[58] 

[59] 

[60] 

Int. J. Aviat. Psychol. 3 (1993) 203–220. https://doi.org/10.1207/s15327108ijap0303_3. 

J. Brooke, SUS - A quick and dirty usability scale, Usability Eval. Ind. 189 (1996) 4–7. https://doi.org/10.1002/hbm.20701. 

B.G. Witmer, C.J. Jerome, M.J. Singer, The Factor Structure of the Presence Questionnaire, Presence Teleoperators Virtual Environ. 14 (2005) 298–312. 
C. Hölscher, T. Meilinger, G. Vrachliotis, M. Brösamle, M. Knauff, Up the down staircase : Wayfinding strategies in multi-level buildings, J. Environ. 

Psychol. 26 (2007) 284–299. https://doi.org/10.1016/j.jenvp.2006.09.002. 

[61] 

C. Hölscher, S.J. Büchner, T. Meilinger, G. Strube, Map Use and Wayfinding Strategies in a Multi-building Ensemble, in: Int. Conf. Spat. Cogn., 2006: pp. 

365–380. 

[62] 

M. Haghani, M. Sarvi, Pedestrian crowd tactical-level decision making during emergency evacuations, J. Adv. Transp. 50 (2016) 1870–1895. 

https://doi.org/10.1002/atr.1434. 

[63] 

W. Liao, A. Seyfried, J. Zhang, M. Boltes, X. Zheng, Y. Zhao, Experimental study on pedestrian flow through wide bottleneck, Transp. Res. Procedia. 2 

(2014) 26–33. https://doi.org/10.1016/j.trpro.2014.09.005. 

[64] 

D. Duives, H. Mahmassani, Exit Choice Decisions During Pedestrian Evacuations of Buildings, Transp. Res. Rec. J. Transp. Res. Board. 2316 (2012) 84–

94. https://doi.org/10.3141/2316-10. 

[65] 

M. Haghani, M. Sarvi, Human exit choice in crowded built environments: Investigating underlying behavioural differences between normal egress and 

emergency evacuations, Fire Saf. J. 85 (2016) 1–9. https://doi.org/10.1016/j.firesaf.2016.07.003. 

[66] 

W. Liao, A.U.K. Wagoum, N.W.F. Bode, Route choice in pedestrians: Determinants for initial choices and revising decisions, J. R. Soc. Interface. 14 

(2017). https://doi.org/10.1098/rsif.2016.0684. 

[67] 

S. Deb, D.W. Carruth, R. Sween, L. Strawderman, T.M. Garrison, Efficacy of virtual reality in pedestrian safety research, Appl. Ergon. 65 (2017) 449–

460. https://doi.org/10.1016/j.apergo.2017.03.007. 

[68] 

R.S. Kennedy, N.E. Lane, M.G. Lilienthal, K.S. Berbaum, L.J. Hettinger, Profile Analysis of Simulator Sickness Symptoms: Application to Virtual 

Environment Systems, Presence Teleoperators Virtual Environ. 1 (1992) 295–301. https://doi.org/10.1162/pres.1992.1.3.295. 

[69] 

R.S. Kennedy, J.M. Drexler, D.E. Compton, K.M. Stanney, D.S. Lanham, D.L. Harm, Configural scoring of simulator sickness, cybersickness, and space 

adaptation syndrome: Similarities and differences., in: Virtual Adapt. Environ. Appl. Implic. Hum. Perform. Issues., 2003: pp. 247–278. 

https://doi.org/10.1201/9781410608888.ch12. 

[70] 

[71] 

W. Barfield, S. Weghorst, The Sense of Presence within Virtual Environments: A Conceptual Framework., Adv. Hum. Factors Ergon. 19 (1993) 699–704. 
A. Bangor, P. Kortum, J. Miller, Determining What Individual SUS Scores Mean : Adding an Adjective Rating Scale, J. Usability Stud. 4 (2009) 114–123. 

24 

 
 
