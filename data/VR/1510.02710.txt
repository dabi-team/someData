Procams-Based Cybernetics

Kosuke Sato∗

Daisuke Iwai∗

Sei Ikeda∗

Noriko Takemura∗

Osaka University

5
1
0
2

t
c
O
9

]

V
C
.
s
c
[

1
v
0
1
7
2
0
.
0
1
5
1
:
v
i
X
r
a

Figure 1: Accomplishments of procams-based cybernetics research: (a) Palm interface [8], (b) extended hand interface [5], (c) wearable projec-
tion [4], (d) shape deformation interface, (e) deformation visualization, (f) see-through projection and (g) front cover projection for book search
support, (h) shadow interface for browsing graphical information on a tabletop [1], (i) shadow pointing, (j) Extended depth-of-ﬁeld (EDOF) projec-
tor by fast focus sweep, (k) synthetic aperture projection using a single projector and multiple mirrors for EDOF and shadow-less projection, (l)
anywhere touch detection [7], (m) view management of projected annotations [3], (n) radiometric compensation [9], and (o) high dynamic range
3D projection mapping.

1 HIGHLIGHTS

of our procams-based cybernetics project.

Procams-based cybernetics is a unique, emerging research ﬁeld,
which aims at enhancing and supporting our activities by naturally
connecting human and computers/machines as a cooperative inte-
grated system via projector-camera systems (procams). It rests on
various research domains such as virtual/augmented reality, com-
puter vision, computer graphics, projection display, human com-
puter interface, human robot interaction and so on. This laboratory
presentation provides a brief history including recent achievements

2 FOCUS

Procams seamlessly merges computer graphics into real world and
allows us to manipulate them without physically constraining our
heads and bodies while minimizing renovation of our living spaces.
Leveraging this unique property, our research group focuses on in-
vestigating interactive systems to support our daily activities, col-
laborative works, and machine manipulations (Fig. 1).

∗see: http://www.sens.sys.es.osaka-u.ac.jp/

3 STRATEGY

To achieve the goal mentioned above, we develop basic technolo-
gies to overcome the technical limitations of current projection dis-
plays and to achieve robust user manipulation measurement under

 
 
 
 
 
 
dynamic projection illuminations to realize ﬂexible and robust in-
teractive systems.

We use cameras, ranging from normal RGB cameras to near and
far infrared (IR) cameras, to measure user manipulation as well as
scene geometry and reﬂectance properties. For the user measure-
ment, we apply IR cameras to robustly detect user’s touch actions
even under projection-based dynamic illumination.
In particular,
we propose two touch detection techniques; one measures ﬁnger
nail color change by touch action using a near IR camera [7], while
the other measures residual heat of user’s touch on a surface using
a far IR camera. For the scene measurement, we use projectors to
project either spatial binary or uniform color patterns, and capture
the projected results to measure scene depth [6] or reﬂectance prop-
erties. These geometric and photometric information is then used
for radiometric compensation that neutralizes the texture of projec-
tion surface so that desired color is displayed on textured surfaces
[9].

The followings are basic technologies on projection side, which
are developed to change the appearance of real surfaces as freely
as computer graphics do.
In contrast, we realized high dynamic
range projection systems by boosting the contrast of projection sur-
face texture on relatively ﬂat printed paper of E-ink display, on full
color 3D printer output, and on surfaces with dynamic reﬂectance
distributions using photochromic ink that allows us to modulate sur-
face reﬂectance spatiotemporally [2]. We also proposed to extend
the DOF of projector by adopting fast focal sweep technique us-
ing electrically tunable liquid lens. Extended DOF projection was
realized with another approach, synthetic aperture projection, by
which cast shadows could be removed as well. In order to realize
wider ﬁeld of view projection, we proposed pan-tilt projection and
optimized the path of projected image to maximize the spatial res-
olution. For displaying legible text information, we proposed an
optimization method for projected annotation layout [3].

4 UNIQUENESS

Our research activity is unique since it covers from basic technolo-
gies to end-user application systems and lasts for almost 30 years.
It is particularly worth noting that we conducted pioneering and
important works that have signiﬁcantly inﬂuenced subsequent re-
searchers. In 1987, we proposed gray-code pattern projection for
shape measurement in active stereo systems [6]. In 2003, we pro-
posed radiometric compensation technique [9] and wearable projec-
tion system [4]. In 2007, we introduced palm interface where pro-
jector displays graphical information on a user’s palm, with which
she interacts by touching it [8].

5 RECENT ACCOMPLISHMENTS

interactive systems to demonstrate that
We developed several
procams-based cybernetics can support interactions between hu-
man and computer, human and human, and human and machine,
respectively.

For human-computer interaction, we have investigated the fol-
lowing three topics: computing anywhere, shape design support,
and book search support. Aiming at realizing the concept of
computing anywhere, we developed wearable projection system in
which a user can interact with graphical information projected onto
nearby surfaces including her palm by touching it [4, 8]. To sup-
port shape design process, we proposed a system in which a user
can manipulate the shape of a real surface, which is visually de-
formed by projected imagery. The visualization of a real surface
deformation by projection was also proposed. For book search sup-
port, we developed systems that allow users to search for their real
books as they do for digital documents stored in their computers.

For human-human communication, we developed an interactive
tabletop system in which users can browse their private information
by casting their shadows on the tabletop while sharing graphical

Figure 2: Overview of extended hand interface [5].

information in non-shadow areas [1]. We also proposed shadow-
based pointing interface for shared information displayed on a large
screen around 10-feet away from users.

For human-machine interaction, we proposed an extended hand
interface in which a user’s hand is visually extended by projection
so that she can manipulate distant appliances as she touch them [5].
While seating on a chair, the user can use the extended hand to tell
a home service robot a speciﬁc distant object such as a cup that she
wants the robot to bring or a speciﬁc place where the robot should
clean up. We also proposed to enrich the face expression of an
android by projecting high frequency face appearance information
to realize more natural human-robot interaction.

6 FUTURE DIRECTION
In the extended hand research [5] (Fig. 2), we found an interest-
ing phenomena: a user felt the projected hand is her own hand. In
another research, we found that warmth judgement of an touched
object is affected by hand color, which is changed by projection.
These results indicate that we can alter human perception either by
projecting user’s body texture onto real surfaces or by projecting
graphics onto a user’s body. In future, we will focus more on inves-
tigating this issue, which could allow us to develop more ﬂexible
and intuitive systems, with researchers in other domains such as
cognitive science and neuroscience.

REFERENCES

[1] M. Isogawa, D. Iwai, and K. Sato. Making graphical information visible
IEEE Trans. Vis. Comput.

in real shadows on interactive tabletops.
Graphics, 20(9):1293–1302, 2014.

[2] D. Iwai, S. Takeda, N. Hino, and K. Sato. Projection screen reﬂectance
control for high contrast display using photochromic compounds and
uv leds. Opt. Express, 22(11):13492–13506, 2014.

[3] D. Iwai, T. Yabiki, and K. Sato. View management of projected labels
on non-planar and textured surfaces. IEEE Trans. Vis. Comput. Graph-
ics, 19(8):1415–1424, 2013.

[4] T. Karitsuka and K. Sato. A wearable mixed reality with an on-board

projector. In Proc. of IEEE ISMAR, page 321, 2003.

[5] S. Ogawa, K. Okahara, D. Iwai, and K. Sato. A Reachable User Inter-
face by the Graphically Extended Hand. In Proc. of IEEE GCCE, pages
215–216, 2012.

[6] K. Sato and S. Inokuchi. Range-Imaging System Utilizing Nematic
Liquid Crystal Mask. In Proceedings of IEEE International Conference
on Computer Vision (ICCV), pages 657–661, 1987.

[7] N. Sugita, D. Iwai, and K. Sato. Touch Sensing by Image Analysis of

Fingernail. In Proc. of SICE, pages 1520–1525, 2008.

[8] G. Yamamoto and K. Sato. PALMbit: A palm interface with projector-

camera system. In Proc. of Ubicomp, pages 276–279, 2007.

[9] T. Yoshida, C. Horii, and K. Sato. A Virtual Color Reconstruction
In Proc. of VSMM,

System for Real Heritage with Light Projection.
pages 825–831, 2003.

