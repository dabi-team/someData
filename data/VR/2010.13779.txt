0
2
0
2

t
c
O
4
2

]

C
H
.
s
c
[

1
v
9
7
7
3
1
.
0
1
0
2
:
v
i
X
r
a

XR-Ed Framework: Designing Instruction-driven and
Learner-centered Extended Reality Systems for Education

KEXIN YANG, Carnegie Mellon University, USA
XIAOFEI ZHOU, University of Rochester, USA
IULIAN RADU, Harvard University, USA

Recently, the HCI community has seen an increased interest in applying Virtual Reality (VR), Augmented
Reality (AR) and Mixed Reality (MR) into educational settings. Despite many literature reviews, there still
lacks a clear framework that reveals the different design dimensions in educational Extended Reality (XR)
systems. Addressing this gap, we synthesize a broad range of educational XR to propose the XR-Ed framework,
which reveals design space in six dimensions (Physical Accessibility, Scenario, Social Interactivity, Agency,
Virtuality Degree, Assessment). Within each dimension, we contextualize the framework using existing design
cases. Based on the XR-Ed Design framework, we incorporated instructional design approaches to propose
XR-Ins, an instruction-oriented, step-by-step guideline in educational XR instruction design. Jointly, they aim
to support practitioners by revealing implicit design choices, offering design inspirations as well as guide them
to design instructional activities for XR technologies in a more instruction-oriented and learner-centered way.

CCS Concepts: • Human-centered computing → Mixed / augmented reality; Virtual reality; Interac-
tive systems and tools; • Applied computing → Interactive learning environments.

Additional Key Words and Phrases: Extend Reality (XR), Instructional Design, Learning Sciences, Design
Framework

ACM Reference Format:
Kexin Yang, Xiaofei Zhou, and Iulian Radu. 2018. XR-Ed Framework: Designing Instruction-driven and Learner-
centered Extended Reality Systems for Education. 1, 1 (October 2018), 21 pages. https://doi.org/10.1145/1122445.
1122456

1 INTRODUCTION
Virtual technologies can improve students’ academic performance and motivation, e.g. [1–12],
students’ social and collaborative skills [13, 14], and students’ psychomotor and cognitive skills
[15]. Among them Virtual Reality (VR) and Augmented Reality (AR) have long been a popular
design space for educational technology, and recently, Mixed Reality (MR) also increasingly applied
for educational use [10]. These immersive technologies have the potential to increase learner
motivation and engagement [7], promote a full student-centered learning experience [16], support
collaborative and situated learning and enable learners to more concretely and tangibly access
previously physically inaccessible/invisible content [17].

In recent years, multiple literature reviews that explore AR, VR or MR applications in education
emerged, e.g., [1–12], mostly focused on one of the three technologies with specific research

Authors’ addresses: Kexin Yang, kexiny@andrew.cmu.edu, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA,
USA, 15213; Xiaofei Zhou, University of Rochester, 250 Hutchison Rd, Rochester, NY, USA, xzhou50@ur.rochester.edu;
Iulian Radu, Harvard University, 13 Appian Way, Cambridge, MA, USA, iulian_radu@g.harvard.edu.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2018 Association for Computing Machinery.
XXXX-XXXX/2018/10-ART $15.00
https://doi.org/10.1145/1122445.1122456

 
 
 
 
 
 
2

Kexin Yang, Xiaofei Zhou, and Iulian Radu

questions. These immersive technologies have similarity as well as nuanced differences, recent
efforts starting to provide a more comprehensive review across the use of AR, VR, MR educational
applications [5, 6], which encourage us to review on all the different types of extended reality (XR)
[18]. Existing reviews and studies have pointed out that many educational affordances of XR can
be achieved by other multimedia, and in order to maximize its unique educational benefits, the
core of their success lies in integration with effective instructional design.

Though many systematic reviews have been published, there is still a lack of a clear framework
that both reveals different design dimensions existing in XR systems and organizes them in a
learner-centered way. Previous work argued instructional design is more important than other
compelling features of XR technologies, and should be placed at the center of the design process of
educational XR application [8, 9, 17].

In the field of education there has been lots of work done on understanding how to teach properly
(with and without technology). While XR is getting used more in education, many XR practitioners
(e.g. technology designers and developers) may not be intimately familiar with educational theory
and instructional design; so most reviews could have limited use in practice. To reduce the chances
of XR design and development efforts being "hit-and-miss, driven by intuition and ‘common-sense’
extrapolations”, and be more solidly underpinned by research-informed models and frameworks
[19], conceptual support from the perspectives of instructional design and learning theory are
needed, for educational technology practitioner (i.e. researchers, designers) [3, 6, 10, 20], especially
given the fact that many XR practitioners may not be intimately familiar with education.

Therefore, our literature review aims at gaining a new lens in educational XR to answer the
research questions: 1) When designing XR for education, what design dimensions should be
considered by practitioners? 2) What instruction-centered design guidelines and procedures could
practitioners follow when they design educational XR applications? To answer these two research
questions, we reviewed 70 papers in the domain of XR systems for education use, mainly from
recent 5 years.

Our paper contributes the XR-Ed framework, which maps out six design dimensions in the
format of spectrums instantiated with specific XR systems, that XR practitioners could consider
when designing and implementing their own apps. We hope, through making the design space more
transparent, it would help practitioners situate their XR systems on the spectrums when making
design choices and weighing design trade-offs. Based on the framework, we further proposed XR-
Ins design guidelines, a set of instruction-centered XR education technology design guidelines to
facilitate designers and researchers to both make good use of XR design affordances and emphasize
effective instruction/learning experience to design in a more structured way. This guideline was
informed by backward design, a known theoretical approach in instructional design, involving
“Identify desired results”, “Determine acceptable evidence” and “Plan learning experience and
instruction” [21].

2 RELATED WORK

2.1 Distinguishing and defining AR, VR and MR
Virtual Reality (VR) refers to a whole simulated reality built with computer systems using digi-
tal formats to create a realistic immersive experience [7], and can be defined as “hardware and
software systems that seek to perfect an all inclusive, sensory illusion of being present in another
environment” [10]. Augmented Reality (AR) has been defined more diversely [17]. Usually, AR
technologies superpose synthetic elements like 3D objects, multimedia contents or text information
onto real-world images [22]. From the standpoint of experience it affords users, AR can provide
users technology-mediated immersive experiences in which real and virtual worlds are blended, in

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

3

which “a real world context is dynamically overlaid with coherent location or context sensitive
virtual information”. From a technology standpoint, [23] define AR as a form of virtual reality
where the participant’s head-mounted display is transparent, allowing a clear view of the real
world” [23] From the standpoint of features it supports, Azuma defines AR as a system that fulfills
three basic features: a combination of real and virtual worlds, real-time interaction and accurate
3D registration of virtual and real objects. Mixed Reality (MR) came into existence later than AR
and VR, and can be defined as a situation where real world and virtual world objects are presented
together. As situated in the Reality-Virtuality continuum proposed by [23]), mixed reality can
consist of two main ideas: augmented reality (AR) and augmented virtuality (AV), which will be
explained further later in Dimension 5 in the XR-Ed framework.

2.2 Existing Reviews and Framework on XR in Education
Previous reviews generally revealed the trends, advantages, limitations and the vision of educational
VR or AR applications. [2, 4, 12, 17, 24–26]. For example, [3, 8, 11] compared learning outcomes and
benefits in VR versus non-VR [3], AR versus non-AR [11], and different VR-based instruction [8].
[10] took a similar instruction-driven approach in its literature review, with a different target (VR in
higher-ed settings). Some reviews happens in a particular knowledge domain, for example, [1, 9, 27]
investigated how AR technologies support medical professional training [1], science education [27]
and language learning [9].

Existing literature proposed several frameworks for AR, VR or MR in education. [10] proposed
a framework of VR for education, including 14 fine-detailed design elements that practitioners
should consider in the design process, such as realistic surroundings, passive observations, etc.
[17] proposed a framework that identified three viable instructional approaches for AR: in the
design of AR instructional activities or systems, practitioners could choose to emphasize “roles”,
“location” or “task”, each relate to AR affordance (e.g. emphasizing “roles” may increase learners’
sense of presence, immediacy and immersion; while emphasizing “tasks” may potentially enhance
authenticity). For MR, [5] developed a pedagogical framework to evaluate MR use in education
including dimensions of 1) type (AR, VR); 2) operation site (school, home); 3) teaching method
(group, single, partner); 4) level of pervasion (assisting, enhancing, replacing); 5) supervision (1:1,
1:n).

Existing frameworks still have yet to provide a complete flow, (i.e. starting from desired learning
objectives to appropriate assessment results), which our XR-Ins Guideline seeks to address, by
mapping a step-by-step procedure to guide the design of an effective learning experience supported
by XR technologies.

2.3 Learning Theory and Instructional Design Approach
In the domain of education, numerous prior work has identified evidence-based learning sciences
principles to scaffold effective learning. A variety of instructional approaches were adopted the
design of XR learning environments, including game-based learning [28–30], place-based learning
[31, 32], participatory simulations [28, 29, 31], problem-based learning [29, 33], role playing [28],
studio-based pedagogy [32], and jigsaw method [34]. Most prior educational XR reviews focus more
on the classic learning paradigms (e.g. cognitivism, behaviorism, constructivism, connectivism,
experimentalism) [7, 10]. While these learning paradigms provide fundamental knowledge, they
may be too theoretical to prompt immediate actions. Hereby we focus on recent, evidence-based
learning sciences principles, based on the known book by Clark and Mayer on e-Learning design,
to provide inspirations for XR technologies design [35]. Due to space limitation, we included only
principles we consider most important and relevant to the XR design.

4

Kexin Yang, Xiaofei Zhou, and Iulian Radu

(1) Multimedia Principle: Using words and graphics concurrently, rather than text exclusively

can help engage both visual and auditory channels of learners.

(2) Contiguity Principle: Words explaining a concept and its accompanying images should be
presented close to each other (spatial contiguity), and simultaneously (temporal contiguity),
to facilitate learners’ retention and understanding.

(3) Coherence Principle: Irrelevant, extraneous or inapplicable information (audio, visual, words)

should be eliminated, to allow learners to concentrate on critical elements only.

(4) Modality Principle: The way we present information should be dependent on how complex
the information is. (E.g. a complicated process may be more effectively conveyed in a visual
format to reduce learners’ ‘information overload’).

(5) Personalization Principle: Systems that use a conversational voice or tone, rather than formal
authoritative tone, can often be more relatable and engaging, and facilitate learners to process
the knowledge and content.

(6) Signaling (cueing) Principle: E-learning is more effective when cues are added that guide
learners’ attention to relevant elements,or highlight the organization of the materials.

Numerous other books offer insight on how to design e-learning technologies [36], or how to design
effective instruction in a systematic [37–39] way. As for systematic procedure of instructional
design, Understanding by Design (UbD) [21], is a known theoretical approach in this area. In
this broad approach, researchers proposed Backward Design, a three-stage approach practitioners
should follow for learning experience design, that consist of 1) Identify desired results; 2) Determine
acceptable evidence; 3) Plan learning experiences and instruction. We seek to combine these known
approaches in instructional design in the XR-Ins (XR-Instruction) Guideline, to help XR practitioners
adopt an instruction-driven and learner-centered way for XR system design.

3 METHODOLOGY
Our search scanned in three databases, including the ACM Digital library, the dblp computer science
bibliography, and Google Scholar, and used keywords: “XR”, “Virtual Reality”,“VR”, “Augmented
Reality”, “AR” and “Mixed Reality”,“MR” combined with “education”, “learning”, “school”, and
“classroom”. To be included in the review, the paper must be (1) from a peer-reviewed conference
or journal, (2) be written in English, (3) use one of the XR technologies for educational purposes.
The general review method of this paper was inspired by An and Holstein’s review on teaching
augmentation systems, which propose TA framework [40].

Two researchers met weekly to discuss how XR is applied in each paper and review the analysis
results of each paper. During the first round of analysis, two researchers evaluated the study and
XR system design comprehensively, including through extracting the following basic information
to gain initial familiarity. At a meta level, we looked at: 1) study type (and for studies being
experimental, then the independent variables (IV) and dependent variables (DV) were collected), 2)
educational goal, 3) learning sciences theory utilized, 4) research questions asked 5) research result
and contribution, 6) number of users, 7) role of users, 8) age of users, 9) educational settings targeted
(e.g. formal, informal), 10) education domain targeted (e.g. physics, math). From the perspective of
design, we looked at 1) key existing system design components, 2) design recommendation. This
stage of literature review served as helping researchers to get background contexts for the specific
XR applications were designed for and used.

During the second round, researchers paid special attention to how XR technologies were utilized
to facilitate the learning of domain knowledge, by annotating papers on this particular aspect. They
distill higher-level commonality of XR usage from the specific use cases in each paper, and as a result,
came up with common “mechanisms” that signify XR’s common usage in education. The definition

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

5

of “mechanism” draws inspiration from a meta-review [17], and has connotation of the“functions
and affordances of XR in education identified in the paper”. From the initial mechanisms extracted,
researchers took a bottom-up approach to conduct thematic analysis. Specifically, they cluster and
group the similar “mechanism” to more easily see the common higher-level themes that capture the
essence of them. As one concrete example of this process, for instance, while [41–43] target different
domains (i.e. gorillas’ behaviors, state of matter, and asteroid movement/force), this identified a
higher level mechanism that they share is that they all learners to role-play as an object/character
related to the target knowledge, to help learners grasp the “deep structure” of the knowledge [43].
Four rounds of iterative clustering and grouping, they arrived at seven mechanisms in Table. 2 in
appendix.

Finally, by utilizing the list of collected mechanisms, two researchers worked collaboratively
to conduct interpretation sessions, where they cross-check the definition of each mechanism and
if every individual XR application can be mapped back to these extracted mechanisms to check
the validity. Inspired by the presentation of An and Holstein’s TA framework, researchers found
continuum (spectrums) to better capture the rich design space than the categorical mechanisms,
and thus proposed a 6-dimension XR-Ed (XR-Education) framework.

4 XR-ED DESIGN FRAMEWORK
In this section, we present the XR-Ed (XR for Education) framework, consisting of six dimensions
that reveal a rich design space for XR application for educational use. We contextualize each
dimension of the XR-Ed Framework through discussing how they are concretely instantiated in
actual XR systems, and provide brief discussion and reflection for each dimension. We hope to, in
doing so, reveal the key design choices that may normally remain implicit, and help XR practitioners
in their process of designing and building XR applications for educational use.

Fig. 1. The spectrum of D1: Physical Accessibility of Target Learning Content

4.1 D1: Physical Accessibility of Learning Content – How physically/visually

accessible is the target knowledge in a normal life scenario?

The first dimension in the XR-Ed Framework addresses how physically / visually accessible the
content knowledge is in ordinary life scenarios. By “accessible”, we mean if the content to be learned
(e.g. a science phenomena, medical surgery procedure) are normally observable or noticeable.

Instantiate normally inaccessible content. One prominent affordance of XR, is to create
4.1.1
scenarios and learning experiences that are normally inaccessible by learners, or processes that are
hard to capture by human eyes, through various techniques including 3D modeling, simulation
and visualization. For example, Radu and Schneider use AR to design activities where learners can
visualize and interact with dynamic representations of hidden forces (e.g. visualizing electrons,
magnetic fields, light or radio waves), to make challenging concepts visible and accessible to novices
[44]. Similarly, [45] visualizes abstract concepts and invisible science phenomena, to help students
learn thermodynamics (9th-grade science); [46] uses MR, enabling learners to view the virtual

6

Kexin Yang, Xiaofei Zhou, and Iulian Radu

solar system and visualize the process of photosynthesis, that are normally invisible / too slow for
human to capture and observe.

4.1.2 Augment normally accessible content. Contrary to the XR applications that seek to visualize
and allow learners to see or experience normally inaccessible knowledge, some applications (es-
pecially MR and AR) seek to augment the normally accessible content knowledge to be richer or
more engaging. For example, [47] built a MR system that teaches sign language and fingerspelling,
through which learners can watch sign language and fingerspelling motion in three dimensions as
if they are looking at them in the real world. This augment over the traditional media to provide
learners with richer information so as they can grasp the hand gesture better through controlling
the movement and rotation of the 3D model.

4.1.3 Discussion. We argue for XR practitioners to consider XR’s affordances of simulating or visu-
alizing a normally inaccessible or unobservable process, as this may offer a unique, novel learning
experience to learners, which could be otherwise extremely costly or impossible to experience
physically. For example, [25] argued that the main motivation for VR use is it gives the opportunity
to live and experiment situations that “cannot be accessed physically” . They depict four typical
scenarios that XR can afford learners to access the “normally inaccessible”: 1) Time inaccessibility:
e.g. allowing learners to travel in time to experience different historical periods; 2) Physical inac-
cessibility: e.g. exploring the solar system by freely moving around planets; 3) Dangerous situation:
e.g. providing training for firefighters in physically and psychologically stressful situation through
simulation live firefighting; learning gorilla behaviors through interacting with a virtual gorilla
[41]; or using MR to simulates earthquake to teach basic physics [48] 4) Ethic problem: for example,
allowing non-experts to perform surgery. Researches found “turning the invisible visible” could
trigger students’ interests and curiosities in science as well as developing students’ connection
between science learning in classrooms and their lives [7, 31, 45].

Fig. 2. The spectrum of D2: Formal Degree of Learning Scenario

4.2 D2: How formal is the target learning scenario?
The second dimension of the XR-Ed Framework asks how formal the learning scenarios are.
Generally speaking, “formal learning” is pragmatic and organized, and “informal learning” casual,
unstructured, spontaneous and often unintentional. If informal learning comes consciously with a
defined purpose, it becomes “non-formal” [49–51].

4.2.1

Formal learning. :

Formal learning normally refers to educational activities that are structured, goal-oriented and
instructor-led [49–51]. XR has been used to amplify formal learning that happens in the classroom,
targeting knowledge prescribed by national or provincial educational standards [52]. XR used in
formal learning often seeks to augment normal instruction with digital media content, physical or
virtual toolkit or 3D modeling. For example, in a large junior high classroom, [53] uses AR toolkit

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

7

to augment instructions with real-time AR image depicting movements of sun-earth turntables, to
teach earth science (i.e. phenomena of day, night and seasons). In a university classroom, first-year
college students use AR-embedded books which display 3D images upon scanning, to facilitate
geography learning. AR can facilitate formal learning in forms of toolkits, for example, Construct3D
for mathematics and geometry learning (i.e. vector analysis, descriptive geometry, and geometry);
unnamed AR toolkit to teach lever principle (physics)[54].

4.2.2 Non-formal Learning. Non-formal learning normally refers to informal learning that comes
with a defined purpose. It is usually the result of intentional effort, but need not follow a formal
syllabus or be governed by external accreditation and assessment [49–51]. In this sense, educational
XR applications were frequently used to provide a gamified experience, in an effort to better engage
learners to learn formal learning content. Three techniques that we found that were frequently
adopted include 1) Storytelling, 2) Learning by making (doing), 3) Role-play or Participatory
Simulation.

Storytelling. Many educational XR applications operate on the idea of storytelling, to render the
content knowledge more engaging, approachable or easy to understand. For example, to facilitate
math learning, ARMath tells a story that invite children to perform math problems, such as asking
them to figure out how many batteries are needed to turn on the lights on a Christmas tree. Children
then need to solve the math problem to fulfill the story. They found providing a purpose or a story
for children to relate to (e.g. adding coins to a bank to buy a toy car), may better engage them to
solve the math problem. [55]. In a different domain, AR and storytelling is used to support students’
learning of a socio-scientific issue on nuclear energy use and radiation pollution. Students were
asked to imagine their campus being 12km away from the Nuclear Power Plant, and they were
on the first day after the hydrogen gas exploration. These ninth-graders then use AR-embedded
Android tablet computers to collect data of simulated radiation values on their campus. They
found AR can possibly affect learners’ affective attitudes toward real-world issues. Storytelling,
game-based learning and problem-based learning might go hand in hand, many AR games included
problem-solving features in the design [17, 29].

Learning by doing. A great number of XR systems seek to facilitate the process of learning by
making or learning by doing, by bridging and connecting virtual and physical worlds, e.g. [7, 56–58].
Specifically, these systems frequently provide virtual scaffolding, hints and richer information as
learners engage in physical tasks . As one example, AR PhonoBlocks [59] is an app that teaches
rural county students the alphabetic principle of English. The key features are overlaid dynamic
colour cues on 3D physical letters. Specifically, when learners place letters on a surface, the system
can dynamically recognize which letter (pair) has been placed, and color-code the letter (pair)
regularly pronounced together. Additionally, a 3D simulation of relevant pictures were used to
augment the word to be learned to render the learning process more visually engaging (e.g. when
children correctly piece together the word “crab”, a 3D simulation of crab will show up). Similarly,
in CS education, MR systems were used to turn the placement of physical cards/ tiles into runnable
commands, to teach children coding concepts [60, 61]. Similar idea to augment the learning by
doing process with XR virtual content is also used in math education in teaching non-symbolic
math [62].

Role-play and Participatory Simulation. “Participatory simulation” is defined as allowing
“different players to function as interacting components of a dynamic system” and consequently
interactions among students affect the outcomes of the system [17, 31]. In educational XR systems,
they frequently involve learners to play the role of an object/character related to the target knowl-
edge, and is frequently adopted in educational XR activities, e.g.[29, 31, 34, 41–43] These activities
could go hand-in-hand with collaborative learning (e.g. Jigsaw) [29–31, 34]. For example, to teach

8

Kexin Yang, Xiaofei Zhou, and Iulian Radu

children the state of matter, a collaborative MR environment named STEP allows students to play
the role of water particles. The way children move changes the state of the water (e.g. liquid, solid),
thus they need to work collaboratively and coordinate movement to form the target water state
[42]. In another VR system, learners play the role of juvenile gorilla and interact with other virtual
gorillas, to learn about gorilla’s acceptable behaviors, habitat and norms etc. [41]. Research found
role-play and “body-based metaphors” can lead children to better grasp the “deep structure” of the
learning domain. In the cases when the actual experiences/ scenarios are not physically accessible
(i.e. too dangerous, costly or unethical), such role-playing serves as a viable alternative.

Informal learning. Informal learning is normally defined as unplanned, without set-goals
4.2.3
and self-directed, which happen more naturally, sometimes unintended, and usually occurs outside
of a conventional learning setting. As an example, [63] used MR to build interactive artwork that
people can interact with, enjoy and explore in the art museum context. The self-directed learning
in museums is typically considered as informal learning, as it is more exploratory and normally
without clear goal or learning outcome measures. Informal learning also usually concern knowledge
that is “nice to know”, but not necessarily connected with learners certification or degree. One
example is FingAR Puppet that uses AR-enhanced finger puppet to promote 4-6 years old children’s
ability of reasoning about emotional states, communication and divergent thinking [64].

4.2.4 Discussion. Researchers as [10] argued the true potential of VR lies not in better teaching
of declarative knowledge, but in offering opportunities to “learn by doing” which is often very
difficult to implement in traditional lectures. However, we realize for practitioners designing
XR systems, it may be that learning settings are already somewhat predefined. Still, it may be
worth noting that the difference between formal and informal learning are not always clear, nor
are they mutually exclusive. If practitioners are trying to decide whether to choose formal or
informal learning activities, besides considering technologies , several instruction-driven and
learner-centered guiding questions could be helpful to consider, including: 1) Does the learning
outcome need to be measurable? 2) How self-motivated are your target learners? 3) How capable
are your learners of self-directed learning (which informal learning may ask for)? 4) What degree
of gamification is appropriate for target learners (e.g. depending on their age and motivation) and
content knowledge?

Fig. 3. The spectrum of D3: Social Interactivity

4.3 D3: Social Interactivity – How much support for social interaction are there in the

system?

The third dimension concerns the system’s support for social interactivity, broadly defined as the
amount of communication learners have while engaging in the systems. Educational XR systems
can have various degrees of social interactivity built in with different subjects (e.g. agent or human
learners).

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

9

4.3.1 None. Some XR applications have little or no support for social interaction for simplicity.
They may serve more as the purpose of toolkit rather than an interactive learning environment. As
one example, Construct3D is a VR app for mathematics and geometry education, aiming to be a
simple and intuitive 3D construction tool in an immersive virtual environment [56]. XR apps used
in formal learning settings (e.g. classroom) that mainly serve the purpose of supplementing formal
instructions with some 3D visualization or tangible physical objects, may also have little or no
support for social interaction, e.g. [53, 65].

Interact with virtual agent. XR systems that have a virtual agent that learners can interact
4.3.2
with or talk to, can increase the social interactivity that system affords. A virtual agent can guide
learners to progress through the learning activities (i.e. relating to Signaling Principle), provide
context, background knowledge or storyline (i.e. storytelling), to engage learners in the learning
tasks. Such an agent could be human-like or non-human-like (e.g. animal, monster) and normally 1)
have functions of verbal communication, 2) are friendly and non-intimidating (especially if interact
with young children); 3) have a name that target learners could call and relate to; 4) serve to build
connection between the learners and the content, so they may initiate conversation with reference
to the learning materials, and drawing users’ attention as proper. For example, ARMath has Victor,
a friendly virtual “monster” agent to illustrate what daily situations learners are target with to solve
mathematically [55]. In a system to teach non-symbolic math, children are asked to help Dima
(a virtual dinosaur agent), on a ‘magical stone quest’. To that end, the child places objects which
make the stones “gain magical powers” and are asked math questions. Upon the correct answer,
Dima will give congratulatory audio feedback and will ask children to “reconsider your answer” if
incorrect [66].

Interact with other learners. XR (especially AR) can support social learning and collaboration,
4.3.3
through enabling learners to interact with the virtual content while engaging in communication
in the real world [34, 67]. For example, a textbook-based AR social learning game for elementary
school students to practice math together, in two different modes: 1) competitive mode and 2)
collaborative mode, and found learners have higher concentration when they learn with their peers
in the competitive mode. [34] adopted a Jigsaw approach that requires students to complete tasks
together. Jigsaw approach is a known collaborative learning approach where each learner acquire
unique information, and the success of the tasks require each member’s contribution, holding
everyone accountable to solve the problem together.

4.3.4 Discussion. Research evidence of positive effect on learning generally advocates for social
interaction to be built in educational XR systems. The XR systems that give prompt feedback
and promote social interaction can promote better students’ engagement by using immersive
experiences, reducing distractions [7]. In education, immediate feedback is undoubtedly a golden
rule that improves learning. Learners benefit from receiving immediate feedback (e.g. on correctness
of their answers or quality of their performance), as compared to doing tasks without feedback
[68–70]. While we do not argue for every XR system to have high degree of social interact prompt
feedback to support better learning, which sometimes can be achieved through social interaction
with virtual agents or peer learners. In addition, research in e-learning design principles have found
people generally absorb information more effectively when they feel there is ‘human’ element
included, and when content is personalized, conversational and informal. For XR systems that
incorporate virtual agents, it can be beneficial if the agent communicates in a human-like voice
as opposed to a robotic voice, use conversational tone. At the same time of building in social
interactivity, XR practitioners need to balance the risk of over-scripting or over-explaining [71, 72],
potential distraction agents or other learners could bring that might interfere with the learning

10

Kexin Yang, Xiaofei Zhou, and Iulian Radu

tasks, and avoid extraneous information which may result in learners being cognitive overloaded
[17, 73].

Fig. 4. The spectrum of D4: Learner Agency

4.4 D4: Agency - What level of learner agency do system support?
The fourth dimension of the XR-Ed framework asks what level of agency learners have. Agency is
when learners have the “power to act”, and when learning involves the activity and the initiative
of the learners. Higher agency means instead of merely information transmitting to the learners
(passive learners’ role), information can also be transmitted from the learners to affect teachers,
curriculum and systems (active learners’ role) [74, 75]. In XR settings, learner agency can sometimes
go hand in hand with the degree of /textitembodied control that systems support (i.e. the degree
users can /textitbodily and physically interact with the system).

4.4.1 Low learner agency. In these XR applications that promote low learner agency, learners act
as passive recipients of knowledge, and participate in the learning activity in a way of reading,
viewing, or observing, instead of actively manipulating, learning by doing or playing a part of the
XR environment. Examples include in medical education learners view the VR brain images to
learn brain anatomy [76], going through paintings in a museum that displays them in an immersive
virtual reality environment to learn art history [77, 78].

4.4.2 High learner agency. Higher agency could give a more immersive experience, which can
potentially better engage learners in the learning process. Learning activities that seek more learner
input, for example, role-playing, participatory simulation and learning by doing may promote
higher learner agency. Examples include the virtual reality (VR) field trips which invite learners
to role-play as corals to learn about climate change [79], the MR learning environment in which
children role-play as water particles to learn collaboratively the state of the matter [42], and to
improve users’ safety awareness and ability to identify accidents in industrial settings, by allowing
them to move around, pick up and manipulate tools, and explore a full range of physical interaction
[80].

4.4.3 Discussion. While learners could still actively construct knowledge in low-agency, non-
interactive objects and videos in XR should be used judiciously, and practitioners are encouraged
to make the 3D VR content manipulatable and interactive to promote higher learner agency,
as learners may generally expect to learn with higher agency (frequently in form of embodied
control), when using immersive technologies. This was vividly shown by the 2 by 2 randomized
trial conducted by [81], that found in VR settings, the group with higher embodied control (and
intuitively, higher learner agency) learned more content than the passively observing group with
lower embodied control/ learner agency. Yet the different degree of embodiment did not result in a
significant difference in learning content in 2D PC, potentially due to different learners expectations
- they may expect more agency in a VR environment, but are more accustomed to viewing content
passively on PC.

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

11

In XR technologies, while giving learners more agency may encourage students to be active
learners, permitting autonomous exploration, learning by doing which support a constructivist
approach of learning [7, 17, 26], the notion of agency isn’t simply about handing control over to
learners, but involved teachers and technologies designer to create the context that actively involve
learners in the moment.

Fig. 5. The spectrum of D5: Virtuality Degree

4.5 D5: Virtuality Degree: What degree of reality and virtuality exist in the learning

environment?

With the same learning content, designers can still decide how much virtuality the technology is
going to provide in the learning experience. For example, to teach programming concepts along
with computational/critical thinking and problem-solving skills, technology designers’ decisions on
the virtuality degree can lead to different educational systems and learning experiences described
as follows.

4.5.1 Purely virtual environments. Purely virtual learning environments provided by VR have the
unique affordances of immersive technology. [82] designed a Virtual Reality (VR) environment for
‘fun-based’ interactive programming instruction in engineering education courses. The system
utilizes 3D visualization and immersive interaction to enable students’ more complex logic rea-
soning which tends to be one of the challenges in learning programming. In terms of the design
recommendations of virtual learning material, research showed that the contextually embedded
instruction texts can lead to learners’ lower cognitive load and higher self-efficacy, audio is less
cognitively demanding as textual information, but text makes information more available for
learners [83].

4.5.2 Physically-enhanced virtual environments. In a physically-enhanced virtual learning environ-
ment, the main learning contents are still supported by virtual objects and virtual interaction, while
physical objects enable tangible interaction [60] and provide affordance for contextual learning and
scaffolding [55, 84]. By bridging the physical world and virtual world by leveraging AR/MR technol-
ogy, researchers can enable students to physically interact with programming and computational
concepts [60]. In ARMath [55], a mobile AR system, researchers utilize the virtual world on the
screen to visualize abstract concepts, engage students in virtual math situations with vivid avatars,
dialogs for storytelling, and provide different types of scaffolding in time. Meanwhile, physical
objects allow tangible interaction with everyday objects, enact real-life practices.. Compared to
a purely virtual environment, involving physical objects potentially allow educators to tailor the
learning environments to instructional objects in a more accessible and flexible way, such as by
tailoring the physical game board without modifying the AR system development [60].

4.5.3 Virtually-enhanced physical environments . The nuances between virtually-enhanced physical
environments and physically-enhanced virtual world are the amount of virtuality used and whether
or not the main learning contents are presented physically or virtually. In virtually-enhanced

12

Kexin Yang, Xiaofei Zhou, and Iulian Radu

physical learning environments, the physical objects (major learning contents) can be enhanced
by the virtually-presented visual cues, scaffoldings, toolbox [45, 54, 85, 86], which aim to reduce
information overload while students are learning complex knowledge components by providing
immediate feedback, in-time learning supports, handy toolkits. Such designs especially can be
effective to support lower-level students [86], children from rural low socio-economic status (SES)
schools [85] or students with lower self-efficacy [54]. Virtual augmentation can also provide data
visualization to reveal fine details while students are interacting with invisible science phenomena.

Fig. 6. The spectrum of D6: Assessment

4.6 D6: Evaluation of Learning - How seamless are the assessments built in the system?
The sixth dimensions XR-Ed framework looks at how seamless are the assessment of learning
embedded in the XR systems. Assessment is the process of “observing a sample of a student’s
behavior and drawing inferences about the student’s knowledge and abilities” [87]. XR offers
potential for various assessment designs, which, depending on how integrated these assessments
are in the XR systems, roughly include separate pre/post test, paper-and-pencil assessment, and
embedded performance-based assessment.

Separate pre/post test outside of the system: Many educational XR systems have no learner
4.6.1
assessment built in, (e.g. [55, 65, 84]. They rely, rather, on external pre or post tests that assess the
learners. For example, in an AR application for college students’ geography education, students were
assessed by given a 30-item achievement test as pretest and posttest as assessment [65]. Similarly
in [84]’s AR application to learn case grammar, learners were assessed using questionnaire on
their prior knowledge of vocabulary and case grammar (as pre-test), and performed vocabulary
recall test and transfer performance test (as post-test) to assess their knowledge of case grammar .
One design tradeoff is this might be logistically more complicated for learners, but could reduce
the development effort and bypass the technical complexity of implementing assessment in XR
environment.

4.6.2 Paper-and-pencil assessment embedded in the system: Paper-pencil assessments refer to the
traditional way where students provide written responses to items either on paper or on electric
forms. Typically, paper-pencil assessments include questions to answer, topics to address through
paragraph responses, problems to solve, etc. By this, we refer to traditional methods that ask
learners for written responses to demonstrate their knowledge built in the XR systems. This is
less commonly observed than the other categories in our review, but one example is in the context
of learning art history in the museum, children were quizzed on the art knowledge after going
through the VR-enhanced paintings [77]. The “learning activities” and “assessment activities” are
separate, rather than integrated.

4.6.3 Performance-based assessment embedded in the system: Performance-based assessments
refer to students demonstrating their knowledge and skills in a non-written fashion [88, 89].

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

13

They focused on demonstration versus written responses. For example, giving oral presentations,
completing physical assessments in physical education (PE) classes, performing experiments in
a lab, or dissecting activities in anatomy classes fall under this category [87]. Here by embedded
performance-based assessment we mean “assessments that ask students to demonstrate their ability
through interaction with the system”. Instead of pausing from learning activity to take a test,
learning activities can collect user interaction data to assess learners’ learning. One example is, in
a VR game that teaches children about natural selection, users play the VR game by manipulating a
virtual net to catch the correct species of butterflies [81]. Whether the learners caught the required
number of butterflies was a proxy for learners’ mastery of the knowledge. Similarly, in a mixed
reality to teach children non-symbolic math, learners place objects “gain magical powers” and solve
math questions. Their answer will be “evaluated by” virtual dinosaur (Dima), who will also give
immediate corrective feedback [66] When “learning activities” and the “assessment activities” are
not separated but deeply integrated, learners do not need to switch back and forth, and the learning
experience can happen in a smoothie way, as learners are “unconsciously” assessed through the
relatively more enjoyable learning activities.

4.6.4 Discussion. Assessment is an integral part of instruction, as it determines whether or not the
goals of education are being met. Assessment affects decisions about grades, placement, advance-
ment, instructional needs, curriculum, and, in some cases, funding. Assessment inspires education
practitioners to ask hard questions: "Are we teaching what we think we are teaching?" "Are students
learning what they are supposed to be learning?" "Is there a way to teach the subject better?"
Assessment not only helps students see their performance and determine their own understanding,
but also helps teachers to assess and reflect if their instruction meets the desired goal and learning
objectives [21, 90].

Somewhat unintuitively, as prior work noted, a lot of educational XR applications do not measure
learning outcome, but focus their evaluation more on system usability testing [10]. This may be
improved as the domain matures, but researchers note future educational XR applications should
be “more thoroughly evaluated by employing quantitative and qualitative research methods to
assess the students’ increase of knowledge and skills as well as the students’ learning experience”
[10, 91].

5 DISCUSSION

5.1 Summary of Review Result and Current Barriers
Our review included work on Virtual Reality (VR) [47, 56, 77, 81, 83, 92–96], Augmented Reality
(AR) [44, 45, 53–55, 64, 65, 67, 84, 85, 97–100] and Mixed Reality (MR) [42, 43, 46–48, 60–63, 66,
85, 101, 102] for education, which we make explicit effort to include a balanced number of each
category. Work covered in this review a variety of XR systems from the learning standpoint. For
example, for the education setting, the reviewed work span from informal learning [42, 48, 55,
64, 67, 83, 84, 103]to formal learning [45, 46, 53, 54, 65, 85], the target learners age range from
K-12 children [45, 53, 54, 66, 67, 85, 98] to college students in higher ed settings or other adults
[56, 65, 77, 81, 83, 84, 100, 101]; the domain subjects that educational XR systems target in our review
also span from math [55, 56, 67, 101], science (e.g. physics [44, 48, 54, 99], animal science [41]),
programming and coding [60, 61], to language learning [47, 84, 85, 98, 102, 103] and art [63, 77].
The general review method of this paper was inspired by a review on teacher augmentation systems
[40].

Through our review, though immersive technologies hold great potential for education, research
found many technological and usability barriers (such as dizziness and cumbersome devices) (Wu
et al. 2013; Parmaxi and Demetriou 2020; Radianti et al. 2020; Martín-Gutiérrez et al. 2017). Recently,

14

Kexin Yang, Xiaofei Zhou, and Iulian Radu

Radianti et al identified pedagogical issues, such as resistance from schools and teachers, a lack
of clear instruction design guidelines, inflexibility of AR systems for customizing instructional
content; as well as learning issue, such as XR may cause students to be cognitively overloaded,
overwhelmed or confused. As a potential solution, we additionally outlined an instructional design
guideline for helping guide practitioners with instructional design in XR technologies.

5.2 Step-by-step Approach for Designing XR Instructional Activities
Based on the XR-Ed Design Framework, we incorporate known theoretical approaches, Under-
standing by Design and Backward Design, enriched with learning sciences or participatory design
principles, to offer a step-by-step instructional design approach to guide practitioners’ design
process of educational XR instruction.

Step 1: Identify desired results (Identify Learning Goal). For this stage, designers should clearly
5.2.1
identify what they aim to enable students to to know, to understand, and to do [21]. When selecting
learning materials, practitioners should consider materials that are anchored in real world problems
that matter to the learners (Anchored learning) [104].

Step 2: Determine acceptable evidence (Assessment Design). Perhaps unintuitively to most
5.2.2
people, Backward Design suggests that designers should start to plan out what assessment before
planning out instruction. As this approach advocates using desired learning result (end goal) to
guide the design of instruction, (thus the name ‘backward’), this necessitates placing assessment
design prior to instruction design. In this stage, designers should consider if and how the assessment
can be embedded into the XR learning system (D6 in XR-Ed Design Framework). In deciding and
planning out form of assessment, we note some educational principles that could be helpful for
practitioners to keep in mind 1) It is better for students’ learning if they expect an assessment (i.e.
avoid “pop quiz”); 2) a spaced schedule of studying and testing (as opposed to all at once) is usually
better for learning (Spacing Effect); 3) when deciding the difficulty of tests, they should take into
students’ skill level and prior knowledge (Goldilocks Principle) [104].

Step 3: Plan learning experience and instruction (Instruction Activities Design). Having iden-
5.2.3
tified results and assessment methods, it is time to design appropriate instructional activities. In
this step, practitioners could go to D2,D3,D4,D5 in the XR-Ed Design Framework to examine the
design space, look for design inspirations from existing XR systems, and consider the some design
recommendation or tradeoff we noted.

Additionally, some general evidence-based principles that practitioners could consider at this
stage include: 1) consider using stories or example cases, as they tend to be more effective than
didactic facts and abstract principles (Stories and Example Cases)[104]; 2) eliminate extraneous
information on XR media to keep learners attention focused on the most central learning content
(Coherence Principle) [35]; 3) Actively involve academic staff to co-designing instructional activities
with them (e.g. teachers, instructional designers, even students). Co-designing educational technolo-
gies with stakeholders who are to use it in actual daily practice (e.g. classroom teaching) is the most
direct way of gauging what they care about and what kind of systems would be most beneficial
for them in their daily activities [105–107]. Having educational technology more aligned with
stakeholders’ (i.e. teachers) preference, could potentially reduce resistance from school teachers to
adopt XR technologies and maximize learning benefit [10, 107].

6 CONCLUSIONS AND FUTURE WORK
We have introduced XR-Ed Framework, which aims to 1) reveal the underlying, sometimes implicit
design choices in educational XR applications, 2) provide design inspirations for XR designers and

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

15

Step in XR-Ins Guideline

Identify Learning Goal

Dimension to consider in
XR-Ed Framework
D1 - Accessibility

Assessment Design

D6 - Assessment

Instruction Activities Design

D2 - Scenario
D3 - Social Interactivity
D4 - Agency

Example Relevant
Learning Sciences Theories
Anchored learning
Exam Expectation
Spacing Effect
Goldilocks Principle

Stories and Example Cases
Coherence Principle

Table 1. Mapping between different step in XR-Ins Guideline to dimensions in XR-Ed Framework, and example
corresponding educational principles

developers by discussing some design implications and trade-offs, 3) propose a common lens where
future XR researchers can analyze educational XR systems. Additionally, we outlined XR-Ins design
guidelines, a step-by-step instruction-centered design guidelines, [21], each step connecting with
the XR-Ed design Framework, enriched by educational principles. Our generalization of the XR-Ed
framework is not meant to be exhaustive, nor is each design dimension exclusive and separate from
each other. Given the rich design space and numerous XR systems with a wide range of designed
features, it is likely zmore design dimensions, and we welcome researchers to comment, refine and
jointly contribute to comprehend this design space.

While we tried to clearly define each dimension, some of the dimensions coordinate can be
considered non-definitive, and may themselves be better defined in spectrums rather than in
category. For example, there is sometimes ambiguity to classify a given learning scenario into
either formal learning or informal learning in a very definite way (e.g. an educational game in K-12
classroom setting), as these categories may not be mutually exclusive. Thus a more effective way of
visualizing and representing the spectrums (e.g. a three-dimensional one) could be future direction.
In sum, XR-Ed design framework and XR-Ins Design Guideline are jointly proposed to facilitate XR
practitioners (i.e. designers, researchers and developers alike) to identify implicit design choices,
gather design inspirations from existing systems’ design, and ultimately design and implement
more effective learning environment in a more structured, learner-centric way.

REFERENCES

[1] Esther Z Barsom, Maurits Graafland, and Marlies P Schijven. Systematic review on the effectiveness of augmented

reality applications in medical training. Surgical endoscopy, 30(10):4174–4183, 2016.

[2] Peng Chen, Xiaolin Liu, Wei Cheng, and Ronghuai Huang. A review of using augmented reality in education from

2011 to 2016. In Innovations in smart learning, pages 13–18. Springer, 2017.

[3] D Hamilton, J McKechnie, E Edgerton, and C Wilson. Immersive virtual reality as a pedagogical tool in education: a
systematic literature review of quantitative learning outcomes and experimental design. Journal of Computers in
Education, pages 1–32, 2020.

[4] Dorota Kamińska, Tomasz Sapiński, Sławomir Wiak, Toomas Tikk, Rain Eric Haamer, Egils Avots, Ahmed Helmi,
Cagri Ozcinar, and Gholamreza Anbarjafari. Virtual reality and its applications in education: Survey. Information,
10(10):318, 2019.

[5] Christopher Kommetter and Martin Ebner. A pedagogical framework for mixed reality in classrooms based on a
literature review. In EdMedia+ Innovate Learning, pages 901–911. Association for the Advancement of Computing in
Education (AACE), 2019.

[6] Melanie J Maas and Janette M Hughes. Virtual, augmented and mixed reality in k–12 education: a review of the

literature. Technology, Pedagogy and Education, 29(2):231–249, 2020.

[7] Jorge Martín-Gutiérrez, Carlos Efrén Mora, Beatriz Añorbe-Díaz, and Antonio González-Marrero. Virtual technologies
trends in education. EURASIA Journal of Mathematics, Science and Technology Education, 13(2):469–486, 2017.

16

Kexin Yang, Xiaofei Zhou, and Iulian Radu

[8] Zahira Merchant, Ernest T Goetz, Lauren Cifuentes, Wendy Keeney-Kennicutt, and Trina J Davis. Effectiveness
of virtual reality-based instruction on students’ learning outcomes in k-12 and higher education: A meta-analysis.
Computers & Education, 70:29–40, 2014.

[9] Antigoni Parmaxi and Alan A Demetriou. Augmented reality in language learning: A state-of-the-art review of

2014–2019. Journal of Computer Assisted Learning, 2020.

[10] Jaziar Radianti, Tim A Majchrzak, Jennifer Fromm, and Isabell Wohlgenannt. A systematic review of immersive
virtual reality applications for higher education: Design elements, lessons learned, and research agenda. Computers &
Education, 147:103778, 2020.

[11] Iulian Radu. Augmented reality in education: a meta-review and cross-media analysis. Personal and Ubiquitous

Computing, 18(6):1533–1543, 2014.

[12] Rabia M Yilmaz. Educational magic toys developed with augmented reality technology for early childhood education.

Computers in human behavior, 54:240–248, 2016.

[13] Hannes Kaufmann, Karin Steinbügl, Andreas Dünser, and Judith Glück. General training of spatial abilities by
geometry education in augmented reality. Annual Review of CyberTherapy and Telemedicine: A Decade of VR, 3:65–76,
2005.

[14] Jorge Martín-Gutiérrez, José Luís Saorín, Manuel Contero, Mariano Alcañiz, David C Pérez-López, and Mario Ortega.
Design and validation of an augmented book for spatial abilities development in engineering students. Computers &
Graphics, 34(1):77–91, 2010.

[15] Feng Zhou, Henry Duh, and Mark Billinghurst. Trends in augmented reality tracking, interaction and display: A
review of ten years of ismar. 2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality, 2:193–202,
09 2008.

[16] William Winn. Research into practice: Current trends in educational technology research: The study of learning

environments. Educational psychology review, 14(3):331–351, 2002.

[17] Hsin-Kai Wu, Silvia Wen-Yu Lee, Hsin-Yi Chang, and Jyh-Chong Liang. Current status, opportunities and challenges

of augmented reality in education. Computers & education, 62:41–49, 2013.

[18] Steve Mann, Tom Furness, Yu Yuan, Jay Iorio, and Zixin Wang. All reality: Virtual, augmented, mixed (x), mediated

(x, y), and multimediated reality. arXiv preprint arXiv:1804.08386, 2018.

[19] Barney Dalgarno and Mark JW Lee. What are the learning affordances of 3-d virtual environments? British Journal

of Educational Technology, 41(1):10–32, 2010.

[20] Peggy A Ertmer, Anne T Ottenbreit-Leftwich, Olgun Sadik, Emine Sendurur, and Polat Sendurur. Teacher beliefs and

technology integration practices: A critical relationship. Computers & education, 59(2):423–435, 2012.

[21] Grant Wiggins, Grant P Wiggins, and Jay McTighe. Understanding by design. Ascd, 2005.
[22] Min-Chai Hsieh and Hao-Chiang Koong Lin. A conceptual study for augmented reality e-learning system based on

usability evaluation. Communications in Information Science and Management Engineering, 1(8):5–7, 2011.

[23] Paul Milgram, Haruo Takemura, Akira Utsumi, and Fumio Kishino. Augmented reality: A class of displays on
In Telemanipulator and telepresence technologies, volume 2351, pages 282–292.

the reality-virtuality continuum.
International Society for Optics and Photonics, 1995.

[24] Murat Akçayır and Gökçe Akçayır. Advantages and challenges associated with augmented reality for education: A

systematic review of the literature. Educational Research Review, 20:1–11, 2017.

[25] Laura Freina and Michela Ott. A literature review on immersive virtual reality in education: state of the art and
perspectives. In The international scientific conference elearning and software for education, pages 10–1007, 2015.
[26] Juan Garzón, Juan Pavón, and Silvia Baldiris. Systematic review and meta-analysis of augmented reality in educational

settings. Virtual Reality, 23(4):447–459, 2019.

[27] Faruk Arici, Pelin Yildirim, Şeyma Caliklar, and Rabia M Yilmaz. Research trends in the use of augmented reality in

science education: Content and bibliometric mapping analysis. Computers & Education, 142:103647, 2019.

[28] Eric Rosenbaum, Eric Klopfer, and Judy Perry. On location learning: Authentic applied science with networked

augmented realities. Journal of Science Education and Technology, 16(1):31–45, 2007.

[29] Kurt Squire and Eric Klopfer. Augmented reality simulations on handheld computers. The journal of the learning

sciences, 16(3):371–413, 2007.

[30] Kurt D Squire and Mingfong Jan. Mad city mystery: Developing scientific argumentation skills with a place-based
augmented reality game on handheld computers. Journal of science education and technology, 16(1):5–29, 2007.

[31] Eric Klopfer et al. Augmented learning: Research and design of mobile educational games. MIT press, 2008.
[32] James M Mathews. Using a studio-based pedagogy to engage students in the design of mobile-based media. English

Teaching: Practice and Critique, 9(1):87–102, 2010.

[33] Tsung-Yu Liu, Tan-Hsu Tan, and Yu-Ling Chu. Outdoor natural science learning with an rfid-supported immersive

ubiquitous learning environment. Educational Technology & Society, 12:161–175, 10 2009.

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

17

[34] Matt Dunleavy, Chris Dede, and Rebecca Mitchell. Affordances and limitations of immersive participatory augmented
reality simulations for teaching and learning. Journal of science Education and Technology, 18(1):7–22, 2009.
[35] Ruth Clark, Richard Mayer, and Will Thalheimer. E-learning and the science of instruction: Proven guidelines for

consumers and designers of multimedia learning. Performance Improvement, 42, 05 2003.

[36] William Horton. E-learning by design. John Wiley & Sons, 2011.
[37] Michael W Allen and Richard Sites. Leaving ADDIE for SAM: An agile model for developing the best learning experiences.

American Society for Training and Development, 2012.

[38] Megan Torrance. Agile for Instructional Designers: Iterative Project Management to Achieve Results. American Society

for Training and Development, 2019.

[39] Kiersten Ann Yocum. Design creativity: Using Agile principles in instructional design for online learning. PhD thesis,

Capella University, 2015.

[40] Pengcheng An, Kenneth Holstein, Bernice d’Anjou, Berry Eggen, and Saskia Bakker. The ta framework: Designing
real-time teaching augmentation for k-12 classrooms. In Proceedings of the 2020 CHI Conference on Human Factors in
Computing Systems, pages 1–17, 2020.

[41] Don Allison and Larry F Hodges. Virtual reality for education? In Proceedings of the ACM symposium on Virtual

reality software and technology, pages 160–165, 2000.

[42] Danielle Keifert, Christine Lee, Maggie Dahn, Randy Illum, David DeLiema, Noel Enyedy, and Joshua Danish. Agency,
embodiment, & affect during play in a mixed-reality learning environment. In Proceedings of the 2017 Conference on
Interaction Design and Children, pages 268–277, 2017.

[43] Robb Lindgren and J Michael Moshell. Supporting children’s learning with body-based metaphors in a mixed reality
environment. In Proceedings of the 10th International Conference on Interaction Design and Children, pages 177–180,
2011.

[44] Iulian Radu and Bertrand Schneider. What can we learn from augmented reality (ar)? In Proceedings of the 2019 CHI

Conference on Human Factors in Computing Systems, pages 1–12, 2019.

[45] Shiyan Jiang, Xudong Huang, Charles Xie, Shannon Sung, and Rabia Yalcinkaya. Augmented scientific investigation:
support the exploration of invisible" fine details" in science via augmented reality. In Proceedings of the Interaction
Design and Children Conference, pages 349–354, 2020.

[46] Wei Liu, Adrian David Cheok, Charissa Lim Mei-Ling, and Yin-Leng Theng. Mixed reality classroom: learning from
entertainment. In Proceedings of the 2nd international conference on Digital interactive media in entertainment and arts,
pages 65–72, 2007.

[47] Natsuhiko Hirabayashi, Nami Fujikawa, Ryohei Yoshimura, and Yoshinori Fujisawa. Development of learning support
equipment for sign language and fingerspelling by mixed reality. In Proceedings of the 7th ACIS International Conference
on Applied Computing and Information Technology, pages 1–6, 2019.

[48] Nesra Yannier, Kenneth R Koedinger, and Scott E Hudson. Learning from mixed-reality games: Is shaking a tablet as
effective as physical observation? In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing
Systems, pages 1045–1054, 2015.

[49] Danielle Colardyn and Jens Bjornavold. Validation of formal, non-formal and informal learning: Policy and practices

in eu member states. European journal of education, 39(1):69–89, 2004.

[50] Sandhya Devi Coll and Richard K Coll. Formal, informal, non-formal learning & free-choice learning. In Enhancing

Science Learning through Learning Experiences outside School (LEOS), pages 11–24. Brill Sense, 2019.

[51] Alan Rogers. The base of the iceberg: Informal learning and its impact on formal and non-formal learning. Verlag

Barbara Budrich, 2014.

[52] Rick Williams Anahita Ayasoufi and Golbou Makki. Using augmented reality to eliminate common misconceptions for
students in core mechanical engineering courses. In 2019 ASEE Annual Conference & Exposition, number 10.18260/1-
2–33495, Tampa, Florida, June 2019. ASEE Conferences. https://peer.asee.org/33495.

[53] Cheng-ping Chen and Chang-Hwa Wang. Employing augmented-reality-embedded instruction to disperse the
imparities of individual differences in earth science learning. Journal of Science Education and Technology, 24(6):835–
847, 2015.

[54] Changhao Liu, Shuo Wu, Shuming Wu, and Su Cai. An ar-based case study of using textual and collaborative
scaffolding for students with different self-efficacy to learn lever principles. In 2020 6th International Conference of the
Immersive Learning Research Network (iLRN), pages 9–15. IEEE, 2020.

[55] Seokbin Kang, Ekta Shokeen, Virginia L Byrne, Leyla Norooz, Elizabeth Bonsignore, Caro Williams-Pierce, and Jon E
Froehlich. Armath: Augmenting everyday life with math learning. In Proceedings of the 2020 CHI Conference on
Human Factors in Computing Systems, pages 1–15, 2020.

[56] Hannes Kaufmann, Dieter Schmalstieg, and Michael Wagner. Construct3d: a virtual reality application for mathematics

and geometry education. Education and information technologies, 5(4):263–276, 2000.

18

Kexin Yang, Xiaofei Zhou, and Iulian Radu

[57] Lucinda Kerawalla, Rosemary Luckin, Simon Seljeflot, and Adrian Woolard. “making it real”: exploring the potential

of augmented reality for teaching primary school science. Virtual reality, 10(3-4):163–174, 2006.

[58] Nicolas Muller, David Panzoli, Galaup Michel, Pierre Lagarrigue, and Jean-Pierre Jessel. Learning mechanical
engineering in a virtual workshop: A preliminary study on utilisability, utility and acceptability. pages 55–62, 09 2017.
[59] Min Fan, Alissa N Antle, and Shubhra Sarker. From tangible to augmented: Designing a phonoblocks reading system
using everyday technologies. In Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing
Systems, pages 1–6, 2018.

[60] Joonyoung Kim, Sudeep Agarwal, Kristina Marotta, Siwei Li, Jonathan Leo, and Duen Horng Chau. Mixed reality for
learning programming. In Proceedings of the 18th ACM International Conference on Interaction Design and Children,
pages 574–579, 2019.

[61] Ren Sakamoto and Toshikazu Ohshima. Code weaver: A tangible programming learning tool with mixed reality

interface. In SIGGRAPH Asia 2019 Posters, pages 1–2. 2019.

[62] Ceylan Beşevli, Elif Salman, Tilbe Goksun, Hakan Urey, and Oğuzhan Özcan. Mar-t: Designing a projection-based
mixed reality system for nonsymbolic math development of preschoolers: Guided by theories of cognition and
learning. In Proceedings of the 18th ACM International Conference on Interaction Design and Children, pages 280–292,
2019.

[63] David Birchfield, Brandon Mechtley, Sarah Hatton, and Harvey Thornburg. Mixed-reality learning in the art museum

context. In Proceedings of the 16th ACM international conference on Multimedia, pages 965–968, 2008.

[64] Zhen Bai and F Alan. Blackwell, and george coulouris. 2015. exploring expressive augmented reality: The fingar
In Proceedings of the 33rd Annual ACM Conference on Human Factors in

puppet system for social pretend play.
Computing Systems (CHI’15), pages 1035–1044.

[65] Zeynep Turan, Elif Meral, and Ibrahim Fevzi Sahin. The impact of mobile augmented reality in geography education:
achievements, cognitive loads and views of university students. Journal of Geography in Higher Education, 42(3):427–
441, 2018.

[66] Elif Salman, Ceylan Besevli, Tilbe Göksun, Oğuzhan Özcan, and Hakan Urey. Exploring projection based mixed reality
with tangibles for nonsymbolic preschool math education. In Proceedings of the Thirteenth International Conference on
Tangible, Embedded, and Embodied Interaction, pages 205–212, 2019.

[67] Jingya Li, Erik D van der Spek, Xiaoyu Yu, Jun Hu, and Loe Feijs. Exploring an augmented reality social learning
game for elementary school students. In Proceedings of the Interaction Design and Children Conference, pages 508–518,
2020.

[68] Susan Askew. Feedback for learning. Routledge, 2004.
[69] Roberta E Dihoff, Gary M Brosvic, Michael L Epstein, and Michael J Cook. Provision of feedback during preparation
for academic testing: Learning is enhanced by immediate but not delayed feedback. The Psychological Record,
54(2):207–231, 2004.

[70] Michael L Epstein, Amber D Lazarus, Tammy B Calvano, Kelly A Matthews, Rachel A Hendel, Beth B Epstein, and
Gary M Brosvic. Immediate feedback assessment technique promotes learning and corrects inaccurate first responses.
The Psychological Record, 52(2):187–201, 2002.

[71] Shannon M Daniel, Melinda Martin-Beltrán, Megan Madigan Peercy, and Rebecca Silverman. Moving beyond yes or
no: Shifting from over-scaffolding to contingent scaffolding in literacy instruction with emergent bilingual students.
TESOL Journal, 7(2):393–420, 2016.

[72] Pierre Dillenbourg. Over-scripting cscl: The risks of blending collaborative learning with instructional design., 2002.
[73] Shujen L Chang and Kathryn Ley. A learning strategy to compensate for cognitive overload in online learning:

Learner use of printed online materials. Journal of Interactive Online Learning, 5(1):104–117, 2006.

[74] Amelia Hempel-Jorgensen. Learner agency and social justice: what can creative pedagogy contribute to socially just

pedagogies? Pedagogy, Culture & Society, 23(4):531–554, 2015.

[75] Sarah Mercer. Understanding learner agency as a complex dynamic system. System, 39(4):427–436, 2011.
[76] Anthony J Levinson, Bruce Weaver, Sarah Garside, Holly McGinn, and Geoffrey R Norman. Virtual reality and brain

anatomy: a randomised trial of e-learning instructional designs. Medical education, 41(5):495–501, 2007.

[77] Hubert Cecotti, Zachary Day-Scott, Laura Huisinga, and Luis Gordo-Pelaez. Virtual reality for immersive learning
in art history. In 2020 6th International Conference of the Immersive Learning Research Network (iLRN), pages 16–23.
IEEE, 2020.

[78] Diogo Cortiz and Jefferson O Silva. Web and virtual reality as platforms to improve online education experiences. In

2017 10th International Conference on Human System Interactions (HSI), pages 83–87. IEEE, 2017.

[79] David M Markowitz, Rob Laha, Brian P Perone, Roy D Pea, and Jeremy N Bailenson. Immersive virtual reality field

trips facilitate learning about climate change. Frontiers in psychology, 9:2364, 2018.

[80] Daniel W Carruth. Virtual reality for education and workforce training. In 2017 15th International Conference on

Emerging eLearning Technologies and Applications (ICETA), pages 1–6. IEEE, 2017.

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

19

[81] Mina C Johnson-Glenberg, Vanessa Ly, Man Su, Ricardo Nieland Zavala, Hannah Bartolomeo, and Elena Kalina.
Embodied agentic stem education: Effects of 3d vr compared to 2d pc. In 2020 6th International Conference of the
Immersive Learning Research Network (iLRN), pages 24–30. IEEE, 2020.

[82] Magesh Chandramouli, Mohammad Zahraee, and Charles Winer. A fun-learning approach to programming: An
adaptive virtual reality (vr) platform to teach programming to engineering students. In IEEE International Conference
on Electro/Information Technology, pages 581–586. IEEE, 2014.

[83] Sarune Baceviciute, Aske Mottelson, Thomas Terkildsen, and Guido Makransky. Investigating representation of text
and audio in educational vr using learning outcomes and eeg. In Proceedings of the 2020 CHI Conference on Human
Factors in Computing Systems, pages 1–13, 2020.

[84] Fiona Draxler, Audrey Labrie, Albrecht Schmidt, and Lewis L Chuang. Augmented reality to enable users in learning
case grammar from their real-world interactions. In Proceedings of the 2020 CHI Conference on Human Factors in
Computing Systems, pages 1–12, 2020.

[85] Min Fan and Alissa N Antle. An english language learning study with rural chinese children using an augmented

reality app. In Proceedings of the Interaction Design and Children Conference, pages 385–397, 2020.

[86] Jingwan Tang, Yang Zhang, April Luehmann, and Andrew White. Augmented reality improved learning of lower-level

students by empowering their participation in collaborative activities. 2020.

[87] M Hurst. Forms of assessment: Informal, formal, paper-pencil & performance assessments. Psychology, 102, 2015.
[88] Robert L Linn, Eva L Baker, and Stephen B Dunbar. Complex, performance-based assessment: Expectations and

validation criteria. Educational researcher, 20(8):15–21, 1991.

[89] Linda Darling-Hammond. Performance-based assessment and educational equity. Harvard Educational Review,

64(1):5–31, 1994.

[90] Shradha Kanwar. Assessment-an important facet of learning. Literacy Information and Computer Education Journal,

Special, 1(2):916–922, 2012.

[91] María-Blanca Ibáñez and Carlos Delgado-Kloos. Augmented reality for stem learning: A systematic review. Computers

& Education, 123:109–123, 2018.

[92] Rhodora Abadia, James Calvert, and Syed Mohammad Tauseef. Salient features of an effective immersive non-
collaborative virtual reality learning environment. In Proceedings of the 10th International Conference on Education
Technology and Computers, pages 268–278, 2018.

[93] Mirko Gelsomini. An affordable virtual reality learning framework for children with neuro-developmental disorder.
In Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility, pages 343–344,
2016.

[94] Ankit Koirala, Zhiwei Yu, Hillary Schiltz, Amy Van Hecke, Kathleen A Koth, and Zhi Zheng. An exploration of using
virtual reality to assess the sensory abnormalities in children with autism spectrum disorder. In Proceedings of the
18th ACM International Conference on Interaction Design and Children, pages 293–300, 2019.

[95] Julien Saunier, Mukesh Barange, Bernard Blandin, Ronan Querrec, and Joanna Taoum. Designing adaptable virtual

reality learning environments. In Proceedings of the 2016 Virtual Reality International Conference, pages 1–4, 2016.

[96] Chien-wen Shen, Jung-tsung Ho, Ting-Chang Kuo, and Thai Ha Luong. Behavioral intention of using virtual reality
in learning. In Proceedings of the 26th International Conference on World Wide Web Companion, pages 129–137, 2017.
[97] Narges Ashtari, Andrea Bunt, Joanna McGrenere, Michael Nebeling, and Parmit K Chilana. Creating augmented and
virtual reality applications: Current practices, challenges, and opportunities. In Proceedings of the 2020 CHI Conference
on Human Factors in Computing Systems, pages 1–13, 2020.

[98] Victor Cheung, Alissa N Antle, Shubhra Sarker, Min Fan, Jianyu Fan, and Philippe Pasquier. Techniques for augmented-
In Proceedings of the Interaction Design and Children

tangibles on mobile devices for early childhood learning.
Conference, pages 589–601, 2020.

[99] Iulian Radu, Ethan Tu, and Bertrand Schneider. Relationships between body postures and collaborative learning
states in an augmented reality study. In International Conference on Artificial Intelligence in Education, pages 257–262.
Springer, 2020.

[100] Ana Villanueva, Zhengzhe Zhu, Ziyi Liu, Kylie Peppler, Thomas Redick, and Karthik Ramani. Meta-ar-app: An
authoring platform for collaborative augmented reality in stem classrooms. In Proceedings of the 2020 CHI Conference
on Human Factors in Computing Systems, pages 1–14, 2020.

[101] Mina Khan, Fernando Trujano, and Pattie Maes. Mathland: Constructionist mathematical learning in the real world

using immersive mixed reality. In International Conference on Immersive Learning, pages 133–147. Springer, 2018.

[102] Christian David Vazquez, Afika Ayanda Nyati, Alexander Luh, Megan Fu, Takako Aikawa, and Pattie Maes. Serendip-
itous language learning in mixed reality. In Proceedings of the 2017 CHI Conference Extended Abstracts on Human
Factors in Computing Systems, pages 2172–2179, 2017.

[103] Alan Cheng, Lei Yang, and Erik Andersen. Teaching language and culture with a virtual reality game. In Proceedings

of the 2017 CHI Conference on Human Factors in Computing Systems, pages 541–549, 2017.

20

Kexin Yang, Xiaofei Zhou, and Iulian Radu

[104] Arthur C Graesser. Inaugural editorial for journal of educational psychology. 2009.
[105] Jeremy Roschelle, William Penuel, and Nicole Shechtman. Co-design of innovations with teachers: Definition and

dynamics. 2006.

[106] William R Penuel, Jeremy Roschelle, and Nicole Shechtman. Designing formative assessment software with teachers:
An analysis of the co-design process. Research and practice in technology enhanced learning, 2(01):51–74, 2007.
[107] Kenneth Holstein, Bruce M McLaren, and Vincent Aleven. Co-designing a real-time classroom orchestration tool to

support teacher–ai complementarity. Journal of Learning Analytics, 6(2):27–52, 2019.

XR-Ed Framework: Designing Instruction-driven and Learner-centered Extended Reality Systems for Education

21

A APPENDIX

Mechanisms of XR technologies in Education

Use 3D visualization to teach in a clearer or more visually appealing way
Connect physical and virtual world to support learners learning by doing
Augment physical objects to provide richer digital information
Role-play or participatory simulation as part of the target knowledge
Embedding interactive agent in XR to promote Social-Emotional Learning (SEL)
Afford learner control and agency through XR controller, sensors

Table 2. Mechanisms of XR technologies in Education

Example Work
in XR system
[45, 100]
[54, 85, 99]
[84]
[29, 31, 34, 41–43]
[55, 66]
[42, 79, 80]

