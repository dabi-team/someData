4
1
0
2

p
e
S
9
2

]

C
O
.
h
t
a
m

[

2
v
2
3
0
7
.
3
0
4
1
:
v
i
X
r
a

Some comparisons between the Variational
rationality, Habitual domain, and DMCS
approaches

G. C. Bento

A. Soubeyran

September, 28, 2014

The “Habitual domain” (HD) approach and the “Variational rationality”
(VR) approach belong to the same strongly interdisciplinary and very dispersed
area of research: human stability and change dynamics (see Soubeyran, 2009,
2010, for an extended survey), including physiological, physical, psychological
and strategic aspects, in Psychology, Economics, Management Sciences, De-
cision theory, Game theory, Sociology, Philosophy, Artiﬁcial Intelligence,. . . .
These two approaches are complementary. They have strong similarities and
strong diﬀerences. They focus attention on both similar and diﬀerent stay
and change problems, using diﬀerent concepts and diﬀerent mathematical tools.
When they use similar concepts (a lot), they often have diﬀerent meaning. We
can compare them with respect to the problems and topics they consider, the
behavioral principles they use, the concepts they modelize, the mathematical
tools they use, and their results.

1 Problems and topics

The “Habitual domain” (HD) theory. For a survey see Yu, Chen (2010).
Among other points, this approach focus attention on:

A) behavioral habitual domain principles (Yu, 1991, Yu, Chen, 2010);

B) habit formation and the dynamic of activation levels and attention eﬀorts,

following a succession of periods (Chan, Yu, 1985);

C) problem solving, modelized as a given competency set expansion (CSE)
problem within a given period (see Shi, Yu, 1999). It represents the most
developped part of the HD theory, which includes a lot of related papers
using diﬀerent mathematical tools to ﬁnd the optimal expansion set (see
among others, Yu, Zhang, 1990, Li, Yu, 1994, Shi, Yu 1996, Tzeng and
alii, 1998, Li, Chiang, Yu, 2000,. . . );

1

 
 
 
 
 
 
D) innovation dynamics (ID), consider that competency sets are dynamic
and can change over time. It examines a succession of competency set,
expansion problems which refer to decision making with changeable spaces
(DMCS) problems. Innovation dynamics examine also cover-discover (CD)
problems (Larbani,Yu, 2012). A covering problem is a competency set ex-
pansion (CSE) problem. It refers to “how to transform a given competence
set CS* into a set that contains a targeted competence set CS”. Discov-
ering refers to the following problem: “Given a competence set, what is
the best way to make use of it to solve unsolved problems or to create
value? The process under the problem solving or value creation, involves
discovering. A discovering process can be deﬁned as identifying how to
use available tangible and intangible skills, competences, and resources to
solve an unsolved problem or to produce new ideas, concepts, products,
or services that satisfy some newly-emerging needs of people. ....Discover-
ing contributes to reducing the charge level or relieving the pain of some
targeted people” (Larbani,Yu, 2012);

E) Decision making with changeable spaces (DMCS) games with changing

minds (Yu, Larbani, 2009, Larbani, Yu, 2009, 2009b, 2011, 2012).

The “Variational rationality” (VR) approach For an extended presenta-
tion of this model, see Soubeyran (2009, 2010). This approach focuses attention
on a single very general problem: the famous self regulation problem, which in-
volves a lot of many multi-disciplinary aspects in diﬀerent disciplines, employing
diﬀerent terminologies. Among other more speciﬁc topics, it considers:

A’) behavioral stability and change principles;

B’) habit formation and break (HFB) problems at the individual level, as well
as routine formation and break (RFB) problems at the organizational
level;

C’) exploration-exploitation (EEL) learning dynamics;

D’) adaptive self regulation (SR) problems (goal setting, goal striving, goal
revision and goal pursuit) which belong to the general class of decision
making with changeable spaces, moving goals and variable preferences
(DMCSMG) problems. Such self regulation processes modelize the inter-
related dynamics of motivational (desiring and willing), cognitive (percep-
tion and knowledge acquisition) and emotional aspects of human behavior.
Bounded rational satisﬁcing processes represent an important application;

E’) variational games (VG) with self regulating agents (Attouch et al., 2007,
Attouch et al., 2008, Flores-Baz´an, Luc, Soubeyran, 2012, Flam et al.,
2012, Cruz Neto et al., 2013);

F’) application of self regulation problems to variational analysis. Varia-
tional analysis and most of the related algorithms: variational principles

2

(Luc, Soubeyran, 2013) exact and inexact alternating algorithms (At-
touch et al., 2007, Attouch et al., 2008, Attouch et al., 2010), proximal
algorithms with Bregman and quasi distances (Cruz Neto et al., 2010,
Moreno et al., 2012), exact and inexact proximal algorithms on manifolds
(Cruz Neto et al., 2013), multiobjective proximal algorithms (Bento, Cruz
Neto, Soubeyran, 2013), local search inexact proximal algorithms (At-
touch, Soubeyran, 2010), inexact descent methods (Bento and alii, 2013),
equilibrium problems (Bento et al., 2013), and dual equilibrium problems
(Moreno et al., 2012), variational inequalities (Attouch, Soubeyran, 2006,
Luc et al., 2010), trust region methods (Villacorta et al., 2013), Tabu
search algorithms (Martinez-Legaz, Soubeyran, 2007), sequential decision
making (Martinez-Legaz, Soubeyran, 2013) etc, use the same variational
principles as VR. These algorithms may be seen as reduced forms of the
VR self regulation model.

2 Behavioral principles

HD behavioral principles HD theory is based on eight behavioral princi-
ples (Yu, Chen, 2010). Four hypotheses capture the basic workings of the brain:
Circuit pattern hypothesis H1, Unlimited capacity hypothesis H2, Eﬃcient re-
structuring hypothesis H3 and Analogy/Association hypothesis H4. Four other
hypotheses summarize how our mind works: Goal setting and State evaluation
hypothesis H5 (a basic function of our mind), Charge structure and attention
allocation hypothesis H6 (how we allocate our attention to various events), Dis-
charge hypothesis H7 (a least resistance principle that humans use to release
their charges) and the Information internal and external inputs hypothesis H8.

VR behavioral principles VR approach is based on, at least, nine behav-
ioral principles (Soubeyran, 2009, 2010):

K1) agents are bounded rational (Simon, 1955). They do not optimize, except
for simple problems. As soon as a problem is complex, it satisﬁce within
a consideration set. They consider, in each step, only a limited subset of
alternatives related to the behavioral chain: “means and capabilities —>
actions —-> performances —-> goals —-> desires”. This consideration
set changes from one period to the next;

K 2) human activities follow a succession of temporary stays and changes;

K3) in each period, the agent is satisﬁed, or remains unsatisﬁed, relative to

diﬀerent domains of it’s life;

K4) the agent problem, in each step, is to choose one of two alternatives: to

temporary stay or to change (“should I stay, should I go?”);

3

K5) the agent balances, in each step, between advantages and inconvenients to
change or to stay, and more generally, motivation and resistance to change
or to stay. They consider worthwhile temporary stays or changes;

K6) an agent is engaged in a “stop and go” stays and changes course pursuit,
between setting, each period, the same old desired ends and/or new ones,
as well as ﬁnding related feasible means to reach or approach each of them;

K7) an agent is partially able to self regulate this possibly interrupted course
pursuit. He can set goals, strive for them, and revise them (having reached
some goals, to reset the same goals is a possibility);

K8) experience matters and partially determines the current behavioral chain.
Then, almost all things, including preferences, can change. There is a
course pursuit between changing preferences, actions, capabilities and be-
liefs. A current action is chosen on the basis of the current preference.
This changes the current preference which, in turn, changes the choice of
the future action which, in turn. . . ;

K9) Goal pursuit stops when the agent reaches a behavioral trap, which is
worthwhile reaching, starting from the initial position, and where he prefers
to stay than to move again.

Comparisons Circuit pattern hypothesis H1 refers to our resistance to change
concept (repetitions of thoughts, ideas and actions reinforce circuits, making
them diﬃcult to abandon). Unlimited capacity hypothesis H2 states that “prac-
tically, every normal brain has the capacity to encode and store all thoughts,
concepts and messages that one intends to”. Eﬃcient Restructuring hypothesis
H3 states that “encoded thoughts, concepts and messages H1 are organized and
stored systematically as data bases for eﬃcient retrieving. Furthermore, ac-
cording to the dictation of attention they are continuously restructured so that
relevant ones may be retrieved eﬃciently in order to release charges”. Anal-
ogy/Association hypothesis H4 supposes that “the perception of new events,
subjects or ideas can be learned primarily by analogy and/or association with
what is already known. When faced with a new event, subject or idea, the brain
ﬁrst investigates its features and attributes in order to establish a relationship
with what is already known; by analogy and/or association. Once the right
relationship has been established, the whole of the past knowledge (preexist-
ing memory structure) is automatically brought to bear on the interpretation
and understanding of the new event, subject or idea”. The above hypotheses
can be used to derive bounded rationality (Simon, 1955) and to our resistance
to change concept (see K5), where new knowledge and past knowledge are not
mixed immediately. For example, as a lot of experiences on habit formation and
break have shown in Psychology, many attitudes and beliefs temporary resist
to change.

The goal setting and state evaluation hypothesis H5 supposes that “each
one of us has a set of goal functions and for each goal function we have an ideal

4

state or equilibrium point to reach and maintain (goal setting). Continuously,
consciously or subconsciously we monitor, where we are, relative to the ideal
state or equilibrium point (state evaluation). Goal setting and state evaluation
are dynamic, interactive, and are subject to physiological forces, self-suggestion,
external information forces, current data bank (memory) and information pro-
cessing capacity”. The VR approach supposes (see K6) variable ideal states
(moving aspirations and desires) and an adaptive course pursuit between where
we are (uncomfortable moving status quo) and where we want to be (moving
aspirations, or desirable ends).

The charge structures and attention allocation hypothesis H6 supposes that
“each event is related to a set of goal functions. When there is an unfavorable
deviation of the perceived value from the ideal, each goal function will produce
various levels of charge. The totality of the charges by all goal functions is called
the charge structure and it may change dynamically. At any point in time, our
attention will be paid to the event which has the most inﬂuence on our charge
structure”. Discharge hypothesis H7 supposes that “to release charges, we tend
to select the action which yields the lowest remaining charge (the remaining
charge is the resistance to the total discharge), known as the least resistance
principle”. The VR approach agrees with these two hypothesis H6 and H7.
Indeed, this is very similar to the famous “discrepancy reduction” principle in
Psychology. They represent the ﬁrst side of a self regulation process (see K6).
The other side is a “discrepancy production” process (goal setting, goal revision;
goal pursuit).

The information Input hypothesis H8 supposes that “humans have innate
needs to gather external information. Unless attention is paid, external infor-
mation inputs may not be processed”. The VR approach agrees with this, which
can be related to the general concept of consideration sets (see K1).

3 Concepts, variables and parameters

HD concepts. To save space, let us list these concepts with respect to only
three diﬀerent HD problems:

i) Stabilization of an habitual domain problem. Following an inﬁnite se-
quence of periods (a transition, in the parlance of the VR approach), the
agent considers, in each period t, his potential domain at time t, his ac-
tual domain at time t, his activation probability at time t, his reachable
domain at time t, and his attention and activation levels at time t;

ii) Competency set expansion problem. Staying within a given period of time,
deﬁned as a single change in the VR approach (the case of a transition,
where the agent follows an inﬁnite sequence of periods unexamined), the
agent considers: his given competency set as well as his given acquired skill
set, both true or perceived, a given table of costs needed for acquiring a
given skill directly from another given skill, his cost of acquiring a new
skill, a chosen optimal expansion process, decision traps, etc;

5

iii) Decision making in changeable spaces (DMCS) problems. They can be
represented by a time dependent list including, at each time t:
i) a list
of changing or changeable decision elements (a subset of alternatives, a
subsets of criteria, an outcome measured in term of the criteria, and a
preference) and ii) a list of changing or changeable decision environmental
facets (information inputs, an habitual domain, a subset of other involved
decision making agents, and a subset of unknowns). All the elements of
this list can be changed with time.

Innovation problems, like successions of competency set expansion problems
and cover-discover problems, as well as DMCS game problems are very im-
portant problems which, however, will not be examined here since our paper
considers only an agent.

VR concepts. They are relative to the self-regulation problem. More pre-
cisely, given a transition (an inﬁnite sequence of periods), the agent follows a
succession of single temporary stays or changes. Given his current experience
which changes with time, he considers, at each period, using his current change-
able consideration set, his current changeable aspiration gap. That is deﬁned
as the current discrepancy between where he is, the status quo, and where he
wants to be (representing his current changeable aspiration level), his current
changeable goals, which helps to ﬁll a portion of the current aspiration gap, as
well as, to approach his current aspiration level, a future chosen action to be
done, repeating the old action, or doing a new action, the regeneration of old
capabilities to be able to repeat the old action, the deletion of old capabilities
and the acquisition of new capabilities and means to be able to do the new
action, his expected new performance and payoﬀ generated by this action, his
expected costs to be able to stay and his expected costs to be able to change, his
expected advantages to change, inconvenient to change, motivation to change,
resistance to change. The distinction can be made between an ex ante per-
ceived and an ex post realized concept, variable or parameter, etc.. All this
elements can change. Then, worthwhile changes and variational traps are the
keys variational rationality concepts.

The same concepts can be used to examine the functioning of variational
games (for a reduced form, see inertial games, Attouch, Redont, Soubeyran,
2007, Flores-Baz´an, Luc, Soubeyran, 2012). To save space we do not examine
them in this paper which focus on a single agent.

Comparisons.

1) In the parlance of the VR approach, stability and change dynamics con-
sider two dynamics: an intra period dynamic (a single temporary stay or
change made of a succession of elementary stay or change operations) and
an inter periods dynamic (a succession of periods, named a transition).
The Chan, Yu (1985) paper on stable habitual domains examines transi-
tions, while a competency set expansion process (Shi,Yu, 1999) refers to
an inter period dynamic (a single change);

6

2) HD theory examines decision making with changeable spaces (DMCS)
problems, while the VR approach considers decision making with change-
able spaces and moving goals (DMCSMG) problems. However (DMCS)
problems can choose goals as well. VR self regulation processes focus
attention on i) goal setting and goal revision (hence changing aspiration
levels and goals) and ii) goal striving (discrepancy or charge reduction);

3) Main HD choice variables are skills, competency sets, and activation propen-
sities. Main VR choice variables are capabilities, actions and goals where
actions refer to paths of elementary operations.

4) VR and HD payoﬀs are experience dependent in their most general formu-
lations (however, the resolution of the competency set expansion problem,
being mathematically so complex, seems to require the opposite. See, for
example, Shi,Yu, 1996, theorem 5.1, where the expected return function
ER depends only on the elements acquired from Tr\Sk. . . );

5) The two concepts of competency set and capabilities, while having some
similarities, diﬀer. In the HD theory, a competency set is a collection of
resources and skills. For the VR approach a capability is a path of oper-
ations including script and timing, related means (physiological, physical,
cognitive, motivational and emotional, tangible and intangible ingredients,
downstream and upstream tools and machines used to perform these oper-
ations, following the given script); However, both approaches consider, as
alternative formulations, subsets and paths to modelize competency sets
and capabilities.

6) The HD deﬁnition of asymmetric costs for acquiring a new skill directly
from a given skill (see, for example Shi, Yu, 1996), is a particular and
reduced form of the VR deﬁnition of change costs to be able to change,
deﬁned as the cost to acquire, directly or indirectly, the capability to do
a new action, starting from having the capability to repeat an old ac-
tion. They include direct and indirect costs to delete some old elementary
capabilities, which should not be used anymore and pollute. . . , costs to
regenerate some other old capabilities, which will be reused, and costs
to acquire new elementary capabilities. HD costs to acquire a new skill
from an old one are direct costs. They seem to include only acquisitions
costs and they represent the inﬁmum of costs to be able to change (see
Soubeyran, 2009);

7) The VR resistance to change concept (see Soubeyran, 2009, 2010) diﬀers
from the HD resistance to change concept (Larbani,Yu, 2012). For the
HD theory, the discharge hypothesis supposes that “to release charges, we
tend to select the action, which yields the lowest remaining charge (the
remaining charge is the resistance to the total discharge); this is called the
least resistance principle” (Larbani,Yu, 2012). In the VR theory resistance
to change is the disutility of inconvenients to change capabilities.

7

8) In the HD approach, motivation to change is modelized in term of charges
and discharges. The VR concept closest to this will be the utility-disutility
of charges and discharges (as tensions). The VR motivation-resistance to
change balance may be compared to the excitation-inhibition functions
(Chan, Yu,1985);

9) The deﬁnition of traps diﬀers. The HD theory (Larbani,Yu, 2012) says
that a decision maker is in a decision trap at time t, if his competence
set is trapped in some area and cannot expand to fully cover the targeted
competence set. The resolution of challenging problems generally involve
covering and discovering. Discovering requires a target to cover, while the
covering process requires discovering when it falls in a decision trap”. The
VR approach deﬁnes a variational trap with respect to an initial situation
(action, a doing, or a state, some having or being). This type of situation
is worthwhile to reach, starting from this initial situation. However, being
there, not worthwhile to leave. Optima, equilibria, decision traps, habits,
routines, rules and norms represent speciﬁc cases. For game situations,
win-win outcomes are examples of variational traps.

10) The VR approach does not modelize the expansion of the competency
sets. On the contrary, Larbani,Yu (2012) give three HD toolboxes which
show how to expand and enrich the actual and reachable domains and
look into the depth of potential domains:

a) the seven empowerment operators;

b) eight methods for expanding the habitual domain M8. Learning ac-
tively, M9. Projecting from a higher position, M10. Active asso-
ciation, M11. Changing the relevant parameters, M12. Changing
the environment, M13. Brainstorming, M14. Retreating in order to
advance, M15. Praying or meditating (Larbani, Yu, 2012);

c) nine principles of deep knowledge: M16 the deep and down principle,
M17 the alternating principle, M18, the contrasting and complement-
ing principle, M19, the revolving and cycling principle, M20.
the
inner connection principle, M21 the changing and transforming prin-
ciple, M22 the contradiction principle, M23 the cracking and ripping
principle, M24 the void principle (Larbani, Yu, 2012).

4 Rationality of a single agent.

Rationality and the HD theory.
In this paper we consider an isolated
agent. Thus, the comparisons between HD and VR game situations will be
examined elsewhere. HD theory examines three diﬀerent problems and pro-
poses three diﬀerent behavioral models for a single agent, who can be fully or
boundedly rational, depending of the model.

8

i) The stabilization of an habitual domain problem. This situation is mod-
elized by a stabilization of activation propensities model, which repre-
sents a reduced form of the stabilization of an habitual domain problem
(Chan,Yu, 1985). This model is a diﬀerential equation, a variant of the
famous global pattern formation model (Cohen, Grossberg,1983). The au-
thors examine its convergence (weak and strong global stability). In this
case an agent does not optimize. He is boundedly rational;

ii) The competency set expansion problem. In this case the main focus is
on an optimal “Problem solving” approach. More precisely, an agent has
a given problem E to solve. To succeed to solve his problem, he must
own a collection of skills deﬁned as the competency set, Tr(E) (true or
perceived), related to the full resolution of the problem. The agent starts
the resolution equipped with a given competency set, the acquired skill
set Sk (true or perceived), deﬁned as the collection of skills he owns at
the beginning, before starting the resolution. The problem is to ﬁnd an
optimal path of expansion of his competency set, from the initial position
Sk to the ﬁnal position Tr(E), representing a ﬁxed given goal. A lot
of diﬀerent algorithms have been used to ﬁnd the optimal solution for
intermediate and compound skills and asymmetric cost functions (tree
expansion processes, deduction graphs, spanning trees,. . . ; see Li, Chiang,
In this case the agent is fully (substantively) rational; The
Yu, 2000).
opposite case of a bounded rational agent, using a satisﬁcing process to
solve a competency set expansion problem, remains an interesting open
problem in this area of research.

iii) Decision making and optimization in changeable spaces (DMOCS) prob-
lems. In a new setting, Larbani, Yu (2012) used some dedicated optimiza-
tion methods and suggest to search for other new optimizing methods to
solve them. Cover-discover problems belong to this class of new optimiza-
tion problems. However, Larbani, Yu (2012) states that ”the operator
Min in the models (6)-(8) should be understood in the sense of satisfac-
tion, not in the sense of absolute minimum”. They notice (Larbani,Yu,
2012, p 742) that optimization must be understood in term of reducing
the charge level of the decision maker to a satisfactory or acceptable level.
This is in accordance with the satisﬁcing principle (Simon, 1955).

Bounded rationality and the VR approach. VR theory proposes a uniﬁed
model for human behavior, focusing on worthwhile temporary stays and changes,
variational traps, and self regulation processes (goal setting, goal striving, goal
revision, goal pursuit processes). It is well adapted to complex, changing and
high stake decision making problems (see Kunreuther et al., 2002), where agents
cannot be fully rational. In a complex and changing world, full optimization,
at each step, is too costly and even not economizing, because situations (spaces
of feasible means and capabilities, actions, performances, payoﬀs, intermediate
and ﬁnal goals, desires and aspirations) change during each step. Hence, an

9

optimal solution at time t may be irrelevant at time t + 1. An agent tries to
reach, at each step, a moving satisﬁcing level (not a ﬁxed one). In each step,
he considers worthwhile temporary stays or changes, which include, as special
cases, adaptive, satisﬁcing, local, approximate, inexact solutions (and optimal
solutions as limit cases).

5 Behavioral stability issues: “how habits and

routines form and break”.

Diﬀerent mathematical tools for stability issues. The HD theory uses,
at least, three main mathematical tools to examine stability issues (convergence
to a stable and desirable ﬁnal situation) and innovation problems (reaching a
targeted competency set, starting from a given initial one): i) the dynamics of
pattern formation (Grossberg, 1973, 1978, 1980, Cohen, Grossberg, 1983) as the
main tool to examine the dynamic of activation propensities (Chan, Yu, 1985),
ii) mathematical programming and diﬀerent graph methods, to study compe-
tency set formation and innovation problems (see, among many other papers,
Shi,Yu, 1996), iii) Markov chains, to examine the convergence of second order
DMCS games to desirable and stable issues (Yu, Larbani, 2009, Larbani,Yu,
2009, 2011, 2012). In contrast, the VR approach (Soubeyran, 2009, 2010) starts
from variational rationality principles in Behavioral Sciences and oﬀers, as im-
mediate applications, a lot of famous mathematical principles of variational anal-
ysis (Ekeland theorem, Bronsted Lemma, and other equivalent principles,. . . ;
see Flores-Baz´an et al., 2012, Luc, Soubeyran, 2013 ). In turn, it uses a lot of
well known variational algorithms (proximal algorithms, descent methods, vari-
ational inequalities, trust region methods, equilibrium problems,. . . ) in order
to help to reﬁne the VR approach relative to stability and innovative issues, for
isolated and interacting agents (VR games).

While strongly related to the VR approach, competency set expansion prob-
lems do not refer to stability issues, but to innovative issues, while the dynamics
of pattern formation (activation propensities) and second order DMCS games
main focus, are on stability issues. To save space, and since our inexact proximal
algorithm paper chooses, for an application, habit’s and routine’s formation at
the individual and organizational levels (a benchmark stability issue), we will
only compare how the HD and VR approaches solve, in diﬀerent ways, this very
diﬃcult problem of “habits and routines formation and break”. The compar-
ison of the HD and VR approaches relative to DMCS problems, competency
set expansion problems, innovation problems, and second order DMCS games,
will be examined elsewhere. However a preliminary step is done, later, for the
comparison of second order DMCS games and VR games.

Let us compare how the HD theory, using the dynamics of pattern formation
(Grossberg, 1973, 1978, 1980, 1983) and the VR approach modelize and explain
how habit-and-routine form and break on two grounds: i) explain convergence
to a ﬁnal issue, ii) explain why this ﬁnal issue is desirable and stable.

10

Notice that the pattern and the variational rationality methods both involve
a balance principe. Worthwhile changes, balance motivation and resistance to
change while changes in pattern allocations, balance excitation and inhibition
inputs and signals.

HD theories of habit’s and routine’s formation and break. The HD
intuition is the following (Chan, Yu,1985) “. . . the existence of stable HD, based
on a set of hypotheses is described. Roughly, as each human being learns, his
HD grows with time, but at a decreasing rate, because the probability for an
arrival idea to be new with respect to HD, becomes smaller as HD gets larger.
Thus, unless unexpected extraordinary events arrive, HD will reach its stable
state. If extraordinary events do not arrive very often, habitual ways of thinking
and action will prevail most of the time. This observation is the main motiva-
tion to use ’habitual’ as the adjective. More formally, HD theory of habit and
routine formation considers the convergence of the allocations of time and eﬀort
(activities propensities) to diﬀerent activities up to a ﬁnal pattern (an habitual
pattern of time and eﬀort allocations), using a variant of the famous pattern
formation model (Grossberg, 1973, 1978, 1980, 1983). Notice that his model of
progressive pattern formation does not explain why this ﬁnal allocation is de-
sirable and stable. However, as said before, in the contect of DMCS problems,
win-win situations refer to desirable and stable ﬁnal outcomes (Yu, Larbani,
2009, Larbani,Yu, 2009, 2011, 2012).

VR theories of habit’s and routine’s formation and break. The VR
intuition is very diﬀerent. Agents make worthwhile changes and stop to change
when there is no way to be able to consider and make a new worthwhile change.
The convergence may be in ﬁnite or inﬁnite time (see Bento, Soubeyran, 2014,
Flores Bazan, Luc, Soubeyran, 2012; Bento, Cruz Neto, Soares, Soubeyran,
2014). The model explains why, and under which conditions, this ﬁnal issue is
desirable and stable. This is the case when it is a variational trap. Moreover,
the formalized VR theory of habit’s and routine’s formation ﬁts very well (see
below) the main non formalized experimental ﬁndings of the diﬀerent theories
of “how habits and routines form and break”, Psychology as well as in Manage-
ment Sciences, within a bounded rationality approach, and, to some degree, in
Economics, in a perfectly rationality context.

Habit’s formation in Psychology and Economics.

In Psychology
habits represent “learned sequences of acts that have become automatic re-
sponses to speciﬁc cues, and are functional in obtaining certain goals or end
states”; see Verplanken, Aarts (1999). For (Duhigg, 2012), an habit is an au-
tomatized action (mental or physical experience), a more or less ﬁxed way of
thinking, willing, feeling and doing which follows an automatized three steps
pattern: a given trigger which activates the action, a process (or script) that
the action follows, and a reward (beneﬁt or gain). Hence habits are learned
automatic behaviors. Repetition in a similar recurrent context is a necessary
condition for habits to develop. Frequency of past behavior and context sta-

11

bility like internal cues (moods and goals) and external cues ( partners and
external goals) determine habit strength. Habits represent a form of automatic-
ity (Bargh,1994). They are more or less conscious and intentional (wanted, i.e.,
the perception of contexts is more or less goal directed, triggered by goals or by
other cues). They are learned in a progressive way. They can be diﬃcult to con-
trol, hard to form, because they follow a progressive learning process, and more
or less hard to break, given some weak or strong motivation and resistance to
change, as the vestige of past behavior. Then, they can resist to change. Habits
can be good (mentally eﬃcient, saving on deliberation eﬀorts). Habits can also
be bad (addictions, behavioral traps,. . . ).

In Economics agents are perfectly rational and habits are deﬁned as stocks
of past experiences. A current habit is modelized as a stock of past behaviors
which determines the present preference of the agent with respect to present
consumption. In standard models of addictions, see (Becker, 1988), and habit
formation, see (Abel, 1990, Carroll, 2000), preferences have the given current
numerical representation Un = U (cn, hn), where the current state hn represents
a stock of habits, cn stands for current consumption, and n indexes time. The
habit persistence hypothesis implies that instantaneous utility does not only
depend on current consumption, but also on a stock of habits, hn.

Routine’s formation in Management Sciences. In this discipline rou-
tines are deﬁned at the organizational level, as collective patterns of interac-
tions. An enormous literature considers routines as organizational habits in
the context of the stability and change dynamics of organizations. The excel-
lent survey is (Becker, 2004), which lists the main points which characterize
routines as: patterns of interactions, collective activities, mindlessness vs ef-
fortful accomplishments, processes (ways of doing, scripts), context dependent
(embeddedness and speciﬁcity), path dependent, and triggered by related ac-
tors and external cues. Routines have several eﬀects. They favor coordination,
control, truce and stability. They also economize on cognitive resources, store
knowledge, and reduce uncertainty.

Stability issues in VR and N person second order games Although our
proximal algorithm paper considers only an agent and not a game situation, the
VR approach includes the examination of variational games which follow, using
reduced formulations, the VR list of nine principles given above (Attouch et
al., 2007, Attouch et al., 2008, Flores-Baz´an, Luc, Soubeyran, 2012, Flam
et al., 2012, Cruz Neto et al., 2013). Here, the nine VR principles will not
be repeated. However (to save space, this is left to the reader), to allow a
possible more complete comparison of HD and VR stability issues (possible
convergence to some stable ﬁnal situation), let us summarize the content of N
persons second order games (Yu, Larbani, 2009, Larbani,Yu, 2009, 2011, 2012).
They incorporate human psychology in formulating games as people play them,
using the habitual domain theory and the Markov chain theory. A Markov chain
modelizes the evolution of the states of mind of players over time as transition
probabilities over them. States of mind determine the outcomes of the so called

12

two or N -person second-order game. The ﬁnal issues are not Nash equilibria,
but focal mind proﬁles, which are desirable to reach and globally stable solutions
of the game, and win win proﬁles, which are focal and absorbing proﬁles, while
Nash equilibria are not. These games can predict the average number of steps
needed for a game to reach a focal or win-win mind proﬁle where both players
declare victory. Given some hypothesis, the ”possibility theorem” states that
it is always possible to reach a win-win mind proﬁle, restructuring (reframing)
the data of the game, the set of players, the payoﬀ functions, and the set of
strategies of the initial game. In this reframing context, the HD information
input hypothesis H8 plays a major role. In such games, players are not fully
rational. They follow the rule of the HD theory. They refer to DMCS problems,
where the structure of the game can be restructured (it is changeable), and
information inputs help to reach a win win proﬁle. To summarize, in a conﬂict
situation, second order players try to reach a focal proﬁle (which exists) and,
once it is reached, they try to make it stable, as a win win proﬁle.

6 Variational rationality, changeable payoﬀs and
decision sets, and the inexact proximal algo-
rithm

The Variational rationality approach considers the rationality of agents, when
many things change or are changeable, and other things must temporary stay.
Let us summarize our ﬁnding. First, the inexact proximal algorithm (with
relative resistance to change) is a reduced form of the variational rationality
model. Second, it is not a repeated optimizing problem in changeable spaces
as an exact proximal algorithm can be.
In this section, we will show that it
represents a worthwhile to stay and change dynamic. Then, it is an adaptive and
satisﬁcing course pursue problem, with changeable payoﬀs, goals, and decision
spaces.

Exact proximal algorithms as repeated optimization problems with
variable payoﬀs and changeable spaces Let us consider, ﬁrst, exact prox-
imal algorithms which are benchmark cases of their inexact versions. They are
not satisﬁcing models of human behaviors. However, they can be considered as
repeated optimization problems with variable payoﬀs and changeable decision
sets (as worthwhile to change sets, see the Lemma). The fact that they consider
variable payoﬀs has been shown above.

Let X = Rn be an action space, f : X → R ∪ {+∞} a proper, lower semi-
continuous function bounded from below and consider the following problems.

• The ﬁxed payoﬀ and decision set optimization problem (1):

PROBLEM 1 :

inf {f (y), y ∈ X} .

This problem is the substantive (global) rationality minimization problem.

13

• The ﬁxed payoﬀ and ﬁxed decision set exact proximal algorithm

(2)

PROBLEM 2 :

inf (cid:8)f (y) + λkΓ (cid:2)q(xk, y)(cid:3) , y ∈ X(cid:9) ,

where xk ∈ X and λk ∈ R++ are given for each k ∈ N, q : X × X → R+ is
a quasi-distance and Γ : R → R represent the relative resistance to change.
This problem is the exact version of our inexact proximal problem with
relative resistance to change. It is a repeated optimization problem.

• The variable payoﬀs and ﬁxed decision set problem (2’):

PROBLEM 2’ :

inf (cid:8)fEk (y) + ηkΓ (cid:2)q(xk, y)(cid:3) , y ∈ X(cid:9) .

where the variable payoﬀ function is fEk (y) = fEk (y) = v(Ek)f (y)
Equality λk = ηk/v(Ek) shows that this problem is equivalent to Problem
2.
It represents a variable and experience dependent payoﬀ with ﬁxed
decision set problem. It allows to deﬁne a course pursuit problem with
variable preferences.

• Variable payoﬀs and variable decision set problems.

PROBLEM 3 :

inf (cid:8)f (y) + λkΓ (cid:2)q(xk, y)(cid:3) , y ∈ Wλk (xk)(cid:9) ,

where Wλk (xk) = (cid:8)y ∈ X : f (xk) − f (y) ≥ λkΓ (cid:2)q(xk, y)(cid:3)(cid:9),

k=0,1,. . . .

Lemma 1 PROBLEM 1 and PROBLEM 2 are equivalent, i.e.,

argminy∈X (cid:8)f (y) + λkΓ (cid:2)q(xk, y)(cid:3)(cid:9) = argminy∈Wλk (xk) (cid:8)f (y) + λkΓ (cid:2)q(xk, y)(cid:3)(cid:9) .

Proof. Take xk
2 ∈ argminy∈X (cid:8)f (y) + λkΓ (cid:2)q(xk, y)(cid:3)(cid:9). Taking into account
that Γ (cid:2)q(xk, xk)(cid:3) = 0, from the deﬁnition of Wλk (xk), it follows immediately
that xk

2 ∈ Wλk (xk). Now, take

3 ∈ arg min (cid:8)f (y) + λkΓ (cid:2)q(xk, y)(cid:3) , y ∈ Wλk (xk)(cid:9) .
xk

It is easy to see that:

f (xk

3) + λkΓ (cid:2)q(xk, x3)(cid:3)

k

) ≤ f (xk

2) + λkΓ (cid:2)q(xk, xk

2)(cid:3) .

On the other hand, since Wλk (xk) ⊂ X and xk
implies:

3 ∈ Wλk (xk), deﬁnition of xk
2

f (xk

3) + λkΓ (cid:2)q(xk, xk

3)(cid:3) ≥ f (xk

2) + λkΓ (cid:2)q(xk, xk

2)(cid:3) ,

and the result follows.

Remark 2 This lemma show that our inexact proximal algorithm is a change-
able payoﬀ and decision set process which belongs to the class of “Decision
Making and Satisﬁcing (not necessarily Optimizing) Problems in Changeable
Spaces”, where the changeable payoﬀ is Pλk (xk, y) = f (y) + λkΓ (cid:2)q(xk, y)(cid:3) , and
the changeable decision set is the current worthwhile to change set Wλk (xk).

14

Inexact proximal algorithms as adaptive satisﬁcing dynamics with
variable payoﬀs and changeable spaces
If the agent follows an inexact
proximal algorithm, he will choose to perform, each step k, a worthwhile change
y ∈ Wek,ξk (xk) where ξk = λkµk > 0,

f (xk) − f (y) ≥ λkµkΓ (cid:2)q(xk, y)(cid:3) ,

0 < µk ≤ 1.

This inexact proximal algorithm (with relative resistance to change) introduces
a lot of simpliﬁcations, as a reduced form of the variational rationality model.
Among others, it identiﬁes actions x ∈ X to activities x = (x, [x]) where
[x] ∈ [X] refers to a given capability to do an action x. It supposes a strictly
increasing and invertible pleasure (utility) function Ue [Ae] = Ae, and deﬁnes
a relative resistance to change function Γ(Ie) = U −1 [De [Ie]] where pain, i.e,
the disutility of inconvenients to change is De [Ie] = Ie. It considers separable
experience dependent unsatisﬁed need functions fEk (y) = v(Ek)f (y) or separa-
ble payoﬀ (proﬁt) functions gEk(y) = v(Ek)g(y), where Ek = (x1, x2, ..., xk) is
the history of past actions, and the inﬂuence of experience is modelized via
the coeﬃcient v(Ek) > 0. It considers inﬁmum costs to be able to change
C(x, y) = inf (cid:8)C([x] , [y] , ω[x],[y]), ω[x],[y] ∈ Ω([x] , [y])(cid:9) , among all ﬁnite costs
to be able to change C([x] , [y] , ω[x],[y]) < +∞, following a path of change,
ω[x],[y] ∈ Ω([x] , [y], from a given capability [x] to do an action x to a given capa-
bility [y] to do a new action y. This inexact proximal algorithm allows to deﬁne
worthwhile changes xk y y as gEk (y) − gEk (xk) ≥ ηkΓ (cid:2)q(xk, y)(cid:3), where ηk > 0
is an adaptive worthwhile to change satisﬁcing ratio, which can be changed from
period k to period k + 1. If we note λk = ηk/v(Ek),then, a worthwhile change
xk y y is deﬁned as g(y) − g(xk) ≥ λkΓ (cid:2)q(xk, y)(cid:3). In term of separable expe-
rience dependent unsatisﬁed need functions fEk (y) = v(Ek)f (y), a worthwhile
change xk y y ∈ Wek ,ξk (xk) is such that f (xk) − f (y) ≥ λkΓ (cid:2)q(xk, y)(cid:3) .

The topic of our paper is not exact proximal algorithms, but inexact ones.
Inexact proximal algorithms examined in this paper represent adaptive satisﬁc-
ing dynamics (dealing with changeable satisﬁcing levels), variable and experi-
ence dependent preferences and changeable decision sets, which belong to the
class of decision making with changeable spaces and changeable goals problems,
noted DMCSCG problems. Let us show this important point, which helps the
comparison with the Habitual domain theory and DMCS decision making prob-
lems with changeable spaces (Larbani, Yu, 2012). Our VR point of view is the
following. An inexact proximal algorithm is a speciﬁc instance of a VR worth-
while to stay and change dynamics xk+1 ∈ Wek,ξk+1(xk), k ∈ N . This dynamic
is both satisﬁcing and considers changeable goals and decision sets,

i) This dynamic is satisﬁcing because the worthwhile to change condition
generalizes the Simon (1955) deﬁnition in a dynamical context, balancing sat-
isfactions to change with sacriﬁces to change. The moving goal is, each period,
the chosen worthwhile to change satisﬁcing level ξk+1 > 0.

ii) This dynamic is adaptive, and considers changeable decision sets Wek ,ξk+1(xk).

Each period, the agent can chooses how much changes must be worthwhile (the
size of ξk+1) to accept to change. Then, the worthwhile to change set is chosen,
at each period.

15

Local inexact proximal algorithms For each k ∈ N ﬁxed, let X k ⊂ X,
xk ∈ X, λk ∈ R++ and consider the following problem:

PROBLEM 4 :

inf (cid:8)f (y) + λkΓ (cid:2)q(xk, y)(cid:3) , y ∈ X k(cid:9) .

This a variable preference proximal problem with a changeable feasibility space
X k ⊂ X. In Attouch, Soubeyran (2010) it is a changing ball X k = Br(xk) of
constant radius r > 0. We can deﬁne the indicator function IX k and consider
the changeable payoﬀs and decision spaces proximal problem,

inf (cid:8)f (y) + IX k (y) + λkΓ (cid:2)q(xk, y)(cid:3) , y ∈ X(cid:9) .

Bento et al. (2013) have also examined an exact local search multiobjective
proximal problem, where X k is a lower countour set of the multi-objective func-
tion.

Now, let us consider “ﬁxed payoﬀ and variable decision set problems”,

namely,

PROBLEM 5 :

inf (cid:8)f (y), y ∈ Wλk (xk)(cid:9) .

Let us assume that {xk

5} is a generated sequence from the iterative process

5 ∈ argmin (cid:8)f (y), y ∈ Wλk (xk)(cid:9) .
xk

Since xk
change.

5 ∈ Wλk (xk), by deﬁnition, the agent follows, each step, a worthwhile

Lemma 3 Let {xk

2} be a generated sequence from the iterative process

xk
2 ∈ argminy∈X (cid:8)f (y) + λkΓ (cid:2)q(xk, y)(cid:3)(cid:9) ,

such that {f (xk
is a minimizing sequence for PROBLEM 1.

2)} converges to f := inf {f (y), y ∈ X}. Then the sequence {xk
5}

Proof. Take k ∈ N arbitrary. Note that xk
It is easy to see that f (xk
an estimation-majoration f (xk
Now, from the deﬁnition of f , we have

5) ≤ f (xk

2 ∈ Wλk (xk) (see proof of Lemma 2).
2), i.e., each solution of PROBLEM 2 gives
5 ) of PROBLEM 5.

2) to the minimal payoﬀ f (xk

f ≤ f (xk

5) ≤ f (xk

2).

(1)

Therefore, the desired result follows from (1) together the fact of {xk
minimizing sequence for PROBLEM 1.

2} be a

Mathematical stability issues

1) Stability of variational traps. Let λk = ηk/v(Ek) be a stage k prox-
imal ratio, where ηk > 0 is a stage k worthwhile to change ratio, and
v(Ek) > 0 is the experience rate of inﬂuence at stage k. Let λ∗ = η∗/v(E∗)

16

be the limit proximal ratio. It is easy to show that if x∗ ∈ X is a vari-
ational trap, given the proximal ratio λ∗, then, x∗ ∈ X is also a varia-
tional trap, for any higher proximal ratio λ > λ∗. This comes from the
implication: Wλ∗ (x∗) = {x∗} implies Wλ(x∗) ⊂ Wλ∗ (x∗) for λ > λ∗.
Then, Wλ(x∗) = Wλ∗ (x∗) = {x∗} for λ > λ∗. A higher proximal ratio
λ = η/v(E) > λ∗ = η∗/v(E∗) means a higher worthwhile to change ratio
η > η∗ or (and) a lower experience rate of inﬂuence v(E) < v(E∗). It can
also mean higher costs to be able to change parameters and, each period,
a longuer length of the exploitation phase, or a shorter length of the explo-
ration phase (Soubeyran, 2009, 2010). For example, stability issues with
respect to adaptive parameters like λk ≥ λ∞ > 0, where λk represents a
changing preference, resistance to change, costs to be able to change, and
length of the exploitation period relative to the exploration period, will
be examined elsewhere.

2) Stability of worthwhile to change trajectories. For an exact quadratic

proximal problem,

inf {f (y) + λΓ [q(x, y)] , y ∈ X} ,

Γ [q(x, y)] = ky − xk2 ,

this is a well known result. The proximal mapping

X ∋ y 7−→ ϕλ(x) := arg min {f (y) + λΓ [q(x, y)] , y ∈ X} ,

is well deﬁned (recall that f was assumed be bounded from below) and, if
f is convex, it is non expansive, i.e.,

|ϕλ(x′) − ϕλ(x)| ≤ kx′ − xk ,

x, x′ ∈ X,

see, for example, (Attouch, Soubeyran, 2010). For an inexact proximal
algorithm with a non quadratic regularization term and a non convex f ,
this is an open diﬃcult question.

7 Habit’s and Routine’s Formation: Inexact Prox-
imal Processes with Weak Resistance to Change

In this section (see the Arxiv version of our paper, Bento, Soubeyran, 2013), we
detail how our inexact proximal algorithm modelizes habit/routine formation
and break, using the VR resistance to change modelization.

Comparing worthwhile changes and stays processes, inexact proximal
algorithms and habituation-routinization processes. As an application
we will consider habit/routine formation as an inexact proximal algorithm in the
context of weak resistance to change. Because of its strongly interdisciplinary
aspect (Mathematics, Psychology, Economics, Management), to be carefully jus-
tiﬁed, this application needs several steps. This, because we need to compare

17

three diﬀerents processes. First, a general worthwhile change and stay process.
Then, as two speciﬁc instances, an inexact proximal algorithm and an habit-
uation/routinization process. The comparison must consider three aspects; a
dynamical system (which one?), which converges (how?), to an end point (which
one?).

2

• Step.1. At the mathematical level, an exact proximal algorithm repre-
sents a dynamical system, which, each step, minimizes a proximal pay-
oﬀ f + λk (cid:2)q(xk, ·)(cid:3)
over the whole space X. The perturbation term is
2
λk (cid:2)q(xk, y)(cid:3)
, λk > 0, y ∈ X, while the payoﬀ function is f . An inex-
act proximal algorithm represents a dynamical process which, each step,
uses a descent condition and a temporary stopping rule. In both cases,
the problem is to give conditions under which this process converges to a
limit point. Then, an exact or inexact proximal algorithm considers three
points:

i) a dynamical process. It represents the proximal sub-problem which
can be the minimization of the current proximal payoﬀ (for an exact
proximal algorithm), or a descent condition, i.e., a suﬃcient decrease
of the proximal payoﬀ (in the inexact case);

ii) the existence of some end points, which can be, or not, a critical

point, a local, or global minimum of f ;

iii) and the convergence of the process towards an end point. This con-

vergence can be linear, quadratic. . . .

• Step.2. At the behavioral level, in the context of his “Variational rational-
ity approach”, (Soubeyran, 2009, 2010) has examined “worthwhile change
and stay” processes. Such dynamical processes refer to successions of tem-
porary worthwhile changes and worthwhile stays. The end points are vari-
ational traps. The convergence of the process materializes in small steps,
whose length goes to zero. Let us remind that, in this behavioral context,
end points represent traps (reachable, i.e, more or less easy to reach, but
diﬃcult to leave). Worthwhile changes balance, each step, motivation and
resistance to change forces. The motivation force is the utility U [A(x, y)]
of the advantages to change function A(x, y) = f (x) − f (y) where f repre-
sents an unsatisﬁed need to be minimized. The resistance to change force
represents the disutility D [I(x, y)] of the inconvenients to become able to
change I(x, y) = q(x, y), where q(x, y) is a quasi distance. In the context
of this paper, the variational approach considers the relative resistance
to change or aversion to change function Γ [q(x, y)] = U −1 [D [q(x, y)]].
This shows that the perturbation term of an exact or inexact proximal
algorithm is a speciﬁc instance of a relative resistance to change function
Γ [q(x, y)]. (Moreno et al. 2011) have considered the speciﬁc quadratic
case of weak resistance to change, where Γ [q(x, y)] = q(x, y)2. Then, at
the behavioral level, two mains concepts, among others, drive a “worth-
while changes and stays” process: i) the unsatisﬁed need function f (which

18

materializes the motivation to change) and, ii) inertia (the relative resis-
tance to change function Γ [q(x, y)]).

• Step.3. Habit formation/routinization processes. A very short survey has
been given in the previous section Behavioral stability issues: “how habits
and routines form and break”. These processes consider, i) a repetitive
process where an action is repeated again and again in the same recurrent
context, ii) a ﬁnal stage where this action becomes a permanent habit, iii)
the convergent process which describes a slow learning habituation process
where this action, being repeated again and again in the same recurrent
context becomes gradually automatized.

• Step.4. Then, it becomes clear that habituation/routinization processes
are speciﬁc instances of worthwhile change and stay processes. Unsatisﬁed
needs and inertia play a major role.

• Step.5. In our paper we have shown how both exact and inexact prox-
imal algorithms are speciﬁc instances of “worthwhile change and stay”
i) minimization of the current proximal payoﬀ, de-
processes, because:
scent conditions and current stopping rules are special cases of worthwhile
changes and marginal worthwhile stays, ii) critical points, local and global
minimum are speciﬁc representations of variational traps, iii) convergence
of the proximal algorithm shows how proximal worthwhile changes con-
verge, depending of the shape of the payoﬀ function (which can be convex,
lower semicontinuous, or which can satisfy a Kurdyka- Lojasiewicz inequal-
ity,. . . ) and of the shape of the perturbation term (linear, convex,. . . with
respect to distance or quasi distance).

Why resistance to change matters much. The benchmark case of lower
semicontinuous unsatisﬁed need functions f and strong resistance to change
functions Γ [q(x, y)] (where costs to be able to change are higher than a quasi dis-
tance) have been examined by (Soubeyran, 2009, 2010) who considered worth-
while change and stay processes. It has been shown that when a worthwhile
change and stay process converges to a variational trap, this variational formu-
lation oﬀers a model of habit/routine formation which modelizes a permanent
habit/routine as the end point of a convergent path of worthwhile change and
temporary habits, where, for a moment, there is no way to do any other worth-
while change, except repetitions.

The opposite case of weak resistance to change was left open. In the con-
text of an exact proximal algorithm, Moreno et al.(2011) have examined a spe-
ciﬁc case of weak resistance to change, namely the quadratic case Γ [q(x, y)] =
q(x, y)2. However, exact proximal algorithms represent a very speciﬁc case
of worthwhile changes, where, each step, the descent condition is optimal.
This means that, each step, the process minimizes the proximal payoﬀ f +
λkΓ (cid:2)q(xk, ·)(cid:3) on the whole space X. Then, such optimizing worthwhile changes
are not step by step economizing behaviors because they require to explore, each
step, the whole state space, again and again. The present paper considers the

19

generalized weak resistance to change case in the context of an inexact proximal
algorithm instead of an exact one. In both papers the unsatisﬁed need function
f satisﬁes a Kurdyka- Lojasiewicz inequality. How the strength of resistance to
change impacts the speed of habit’s/routine’s formation is, as an application,
the topic of the related paper Bento, Soubeyran (2014).

To summarize, we have compared an inexact generalized proximal algorithm
with a worthwhile change and stay process with respect to three aspects: A)
as a dynamical system, B) with an end point, C) which converges to that end
point. To end this paper, it remains to compare an inexact generalized proximal
algorithm with an habituation and routinization process, as it is described in
Psychology and Management Sciences, using the same three criteria.

Inexact generalized proximal algorithm and habituation/ routiniza-
tion process are dynamical systems.

• Habituation/routinization process. They represents the repetition of
an action of a given kind (some activity related to a given goal), in order
to satisfy a recurrent unsatisﬁed need in a stable context. The repetition
concerns the action and what becomes more and more the same is “the way
of doing it” (the script). This repetition follows a succession of worthwhile
changes and stays. An inexact proximal algorithm represents a step by
step processes, a succession of moves in order to ”decrease enough” some
proximal payoﬀ function. Usually, both dynamical processes are unable
to reach the goal in one step. Each step, the level of satisfaction of the
recurrent need increases, but some unsatisfaction remains.

An habituation process is driven by two balancing forces : a motivation
to change function M [A(x, y)] (an habit/routine must serve us), and a
resistance to change function D [I(x, y)], (habits/routines are hard to form
and hard to break because learning and unlearning are costly). An inexact
proximal algorithm is driven by the two terms f (y) and Γ [q(x, y)] of its
proximal payoﬀ f (y) + λkΓ [q(x, y)] where q(x, y) = C(x, y). This balance
describes the goal-habit interface.

The rationality of an habituation process is to improve by repetition the
way of doing a similar action in the same context. The agent improves with
costs to change. He satisﬁces, doing worthwhile changes, without exploring
too much each step (local consideration and exploration; see Soubeyran,
(2009, 2010) for this important aspect). An inexact proximal algorithm
follows, each step, some descent condition and marginal stopping rule,
without optimizing each step.

The inﬂuence of the past diﬀers from one process to the other. For an
habituation process the impact of the past can be very important (the
past sequence matters much). For an inexact proximal algorithm it is
as if only the last action matters. The inﬂuence of the past is minimal
(it is as if the agent has a short memory). The inﬂuence of the future
seems identical in both cases: myopia seems to be the rule. Only the

20

next future action matters. Agent’s behavior driven by habits/routines
are not forward looking. For more forward looking worthwhile to change
behavior; see Soubeyran, (2009, 2010).

Convergence: see the last paragraph (“why resistance to change
matters much”)

End points. Our inexact proximal algorithm converges to a critical
point, which is not an end point, unless it can be shown that a critical
point is a variational trap (as this is done in our paper). A variational
trap is worthwhile to reach and not worthwhile to leave. An habituation
process ends in a permanent habit/routine which is hard to form and hard
to break. It represents the vestige of a past repeated behavior.

8 Making the assumptions of the proximal algo-

rithms clear in behavioral terms

We have to show how, in Behavioral Sciences, our three proximal algorithms
modelize, at least in a reduced form, how habits form and break.

A ﬁrst step has been given before, in Section 7. This have been done in ﬁve
steps. We have shown that inexact proximal algorithms and habitual processes
are dynamical systems, we have compared their end points, critical points or
variational traps, we have examined how the strength of resistance to change
inﬂuences their abilities to converge, and we have linked resistance to change to
loss aversion, a famous behavioral concept.

A second step is to detail the behavioral content of all the hypothesis which
drive our three proximal algorithms. There are general behavioral hypothesis
which are common to the three proximal algorithms, and speciﬁc hypothesis rel-
ative to each of them. More explicitly, the three algorithms suppose that costs
to be able to change are quasi distances. They consider, each step, worthwhile
and marginally worthwhile changes (descent conditions), and suppose weak re-
sistance to change, as well as a marginal stopping rule. The ﬁrst algorithm is
targeted to converge to a critical point. The second and third algorithms are
targeted to converge to a variational trap.

General behavioral hypothesis

• H.1. Costs to be able to change C are modelized as quasi-distances. For an
agent, costs to be able to change C(x, y) = q(x, y) refer to the inﬁmum of
the costs to be able to change his capabilities, from having the capability
to do an action x, to the capability to do an action y. Then C(x, x) = 0
means that if the agent is able to do an action x,he is able to do this action
at no cost. The condition C(x, y) = 0 ⇐⇒ y = x means that if the agent
is able to move at no cost, then, he can only repeat the same action, if
he is able to do it . The triangle inequality C(x, z) ≤ C(x, y) + C(y, z)
for all x, y, z ∈ X means that, for an agent, the inﬁmum cost to change

21

his capabilities from the initial capability to do an action x to the ﬁnal
capability to do an action z is lower than the inﬁmum cost to change his
capabilities from the initial capability to do action x to the intermediate
capability to do an action y and the inﬁmum cost to change his capabilities
from the intermediate capability to do action y to the ﬁnal capability to do
action z, because the way to change successively from an initial capability
to an intermediate capability and from this intermediate capability to a
ﬁnal capability is an indirect way to change from the initial to the ﬁnal
capability.

• H.2. Unsatisﬁed needs f : Rn → R ∪ {+∞} is a proper lower semicon-
tinuous function. This is a regularity assumption which supposes no free
lunch. The agent cannot reduce his unsatisﬁed need in a given small
amount without changing enough his action (no jump downward are al-
lowed).

• H.3. Advantages to change A(x, y) = f (x) − f (y)

refer to separable
advantages to change functions, linked, when positive, to a decrease in
unsatisﬁed needs.

• H.4. The ratio ξk > 0 modelizes how much a change can be worthwhile
(the adaptive satisﬁcing case). This ratio can change from period to pe-
riod. This means that the agent can adapt with delay or not, each step,
his degree of satisﬁcing. In this paper he adapts with one period delay
(writing ξk > 0 instead of ξk+1 > 0, to ﬁt with a proximal formulation).

• H.5. The utility function U [·] is invertible with U [0] = 0. This is the case
for a strictly increasing utility function, relative to advantages to change
(the usual case).

• Condition (4) supposes that Γ(C) = U −1 [D [C]] is twice diﬀerentiable
with respect to C. It is a regularity condition, relative to the relative
resistance to change function.

• Condition (7) means that the relative resistance to change function is “ﬂat
enough in the small” (in the ”weak enough resistance to change” case).
It supposes that the margnal relative resistance to change must be “lower
enough” with respect to the mean relative resistance to change, at least
for “low enough” costs to be able to change.

• Assumption 3.1 supposes that costs to be able to change are high (low)

enough iﬀ the old and new actions are diﬀerent (similar) enough.

Hypothesis relative to Algorithm 4.1 Algorithm 4.1 supposes three con-
ditions (10), (11), (12). Condition (10) imposes worthwhile changes (a suﬃcient
descent assumption) along the process. Condition (11) deﬁnes subgradients for
the unsatisﬁed needs and costs to be able to change functions. Condition (12)
refers, each step, to a stopping rule, where the norm of the marginal decrease of

22

the unsatisﬁed need is lower than the norm of the marginal relative resistance
to change.

The Kurdyka-Lojasiewicz inequality (Deﬁnition 4.3) refers to a curvature
property of the unsatisﬁed need function, near a critical point. The unsatisﬁed
need must be lower than some increasing function of the marginal unsatisﬁed
need, close to a critical point.

Assumption 3.2 supposes that the marginal relative resistance to change
It is a curvature

function is lower than a power function, near the origin.
property.

Hypothesis relative to Algorithm (9) This algorithm supposes approxi-
mate (almost) worthwhile changes, including, at each step, an error term εk > 0.

Hypothesis relative to Algorithm 4.2 This algorithm supposes three con-
ditions (13), (14), (15). Condition (13) is a modiﬁed worthwhile to change
assumption. Condition (14) deﬁnes subgradients for the unsatisﬁed needs and
costs to be able to change functions. Condition (15) is the stopping rule condi-
tion (12). This algorithm adopts all the hypothesis of Algorithm 4.1.

9 Application to the Formation and Break of

Habits/Routines

The Variational rationality (VR) approach, see Soubeyran (2009, 2010), focus
attention on interdisciplinary stability and change dynamics (habits and rou-
tines, creation and innovation, exploration and exploitation,. . . ), and the self
regulation problem, seen as a stop and go course pursuit between feasible means
and desirable ends mixing, in alternation, discrepancy production (goal setting,
goal revision), discrepancy reduction (goal striving, goal pursuit) and goal dis-
engagement. It rests on two main concepts, worthwhile temporary stays and
changes, variational traps and nine principles. This (VR) approach allows to
recover the main mathematical variational principles, and in turn, it beneﬁts
from almost all variational algorithms for procedural applications, which all, use
some of the main variational rationality principles. The Habitual domain (HD)
theory and (DMCS) approach (see Yu, Chen (2010), for a nice presentation)
and the (DMOCS) Decision making and optimization problems in changeable
spaces (see Larbani, Yu (2012)) refer to three stability and change problems.
They are i) stability issues, using a system of diﬀerential equations, a variant of
the famous pattern formation Cohen-Grossberg model (see Cohen, Grossberg
(1983)), ii) expansion of an initial competency set to be able to solve a given
problem, which requires to acquire a new given competency set, using mathe-
matical programming methods and graphs, iii) DMCS optimization and game
problems, using Markov chains, with applications to innovation cover-discover
problems (see Yu, Larbani (2009) and Larbani, Yu (2009,2011)).

23

1) Habit/routine formation and break problems

The (VR) approach sees habit/routine formation and break as a balance between
motivation and resistance to change, when agents use worthwhile changes; Per-
manent habits refer to variational traps, as the end of a succession of worthwhile
changes. These ﬁndings ﬁt well with Psychology and Management theories of
habits and routines formation and break. For example, in Psychology, habits
form by repetitions, in a rather stable context, which trigger their repetition.
They become gradually more and more automatized behaviors which are inten-
tional (goal directed), more or less conscious and controllable, and economize
cognitive resources.
In this context agents are bounded rational. The (HD)
approach modelizes habit formation as a balance, each step, between excitation
and inhibition forces, which determine, each time, the variation of the allo-
cation of attention and eﬀort (propensities), using, as said before, a variant
of the Cohen-Grossberg system of diﬀerential equations (see Cohen, Grossberg
(1983)).

In the limit, the allocation of attentions and eﬀorts (propensities) converge
to an allocation which represents a stable habitual domain. The (DMOCS)
approach of games deﬁnes limit proﬁles of mind sets as absorbing states of a
Markow chain. In these two contexts agents are bounded rational.

2) Inexact proximal algorithms as repeated satisﬁcing prob-
lems with changeable decision sets

We have shown in Section 3 of this paper that our inexact proximal algorithms
refer to variable and changeable decision sets, payoﬀs, goals (satisﬁcing worth-
while changes) and preference processes. This is the case because worthwhile
to change sets are changeable decision sets which change, each period, with
experience and the choice, each period, of the satisﬁcing worthwhile to change
ratio; see the whole Section 2 and the dynamic of worthwhile (hence satisﬁc-
ing) temporary stays and changes. More precisely Inexact generalized proximal
algorithms are speciﬁc instance of VR worthwhile stay and change adaptive
dynamics. They consider non transitive variable worthwhile to change pref-
erences, see Section 2, which are reference dependent preferences with variable
reference points (variable experience dependent utility/disutility functions, vari-
able payoﬀ functions, variable and non linear resistance to change functions via,
in each case, of the introduction of the separable and variable lambda term).
They can use costs to be able to change which do not satisfy the triangular
inequality; see Bento et al., (2014) and several other references within Bento,
Soubeyran (2014). They are inexact and procedural algorithms on quasi metric
spaces. Then, they modelize bounded rational and more or less myopic agents
who bracket diﬃcult decisions in several steps, contrary to exact proximal al-
gorithms which modelize a repeated optimization problem, and which are not
the topic of our paper. They generalize the Simon satisﬁcing principle to a
dynamical context (repeated and adaptive satisﬁcing). They are anchored to
optimization processes as benchmark cases. They deal with changeable spaces

24

as changeable worthwhile to change sets and also changeable exploration sets;
see Attouch, Soubeyran, (2011), Bento, Cruz Neto, Soubyeran (2014) and con-
sider convergence in ﬁnite time as a central topic; see Bento, Soubeyran (2014)
and Bento et al. (2013). They include psychological aspects (like motivations,
cognitions and inertia) and can easily include emotional aspects.

We point out that the assumptions of inexact proximal algorithms explicit
in behavioral terms have been given in Section 2 of this paper (see the example)
and after each proximal algorithm.

10 References on the VR, HD and DMCS ap-

proaches

References for the Habitual domain theory

1. Yu, P.L, Chen,Y.C.: Dynamic MCDM, habitual domains and competence set
analysis for eﬀective decision making in changeable spaces. Chaper 1. In Trends
in Multiple Criteria Decision Analysis. Matthias Ehrgott Jose Rui Figueira
Salvatore Greco. Springer (2010)

2. Shi, D. S., Yu, P. L.: Optimal expansion of competency sets with intermediate
skills and compound nodes. Journal of Optimization Theory and Applications,
Vol. 102, No.1, pp. 643-657, 1999.

3. Yu, P. L., Zhang, D.: A Foundation for Competence Set Analysis, Mathe-
matical Social Sciences, Vol. 20, pp. 251-299, 1990.

4. Yu, P. L., Zhang, D.: A Marginal Analysis for Competence Set Expansion,
Journal of Optimization Theory and Applications, Vol. 76, pp. 87-109, 1993.

5. Li, H. L., Yu, P. L.: Optimal Competence Set Expansion Using Deduction
Graphs, Journal of Optimization Theory and Applications, Vol. 80, pp. 75-91,
1994.

6. Shi, D. S., Yu, P. L.: Optimal expansion and design of competence set with
asymmetric acquiring costs. Journal of Optimal Theory and Applications, Vol.
88, pp. 643–658, 1996.

7. Li, J. M., Chiang, C. I., Yu, P. L.: Optimal multiple stage expansion of
competence set. European Journal of Operational Research, Vol. 120(3), pp.
511-524, 2000.

8. Yu, P. L.: Habitual Domains. Operations Research, Vol. 39 (6), 869–876,
1991.

25

9. Chan, S. J., Yu, P.L.: Stable Habitual Domains: existence and implications.
Journal of Mathematical Analysis and Applications, Vol. 110 (2) 469-482, 1985.

10. Yu, P. L., Larbani M.: Two-person second-order games, Part 1: formulation
and transition anatomy. Journal of Optimization Theory and Applications,
141(3), 619-639, 2009.

11. Larbani, M., Yu, P.L.: Two-person second-order games, Part II: restructur-
ing operations to reach a win-win proﬁle, Journal of Optimization Theory and
Application, Vol. 141, 641-659, 2009.

12. Larbani, M., Yu, P.L.: n-Person second-order games: A paradigm shift in
game theory, Journal of Optimization Theory and Application, Vol. 149 (3),
447–473, 2011.

13. Larbani M., Yu P.L. Decision Making and Optimization in Changeable
Spaces, a New Paradigm, Journal of Optimization Theory and Application,
Vol. 155 (3), 727-761, 2012.

14. Po L. Yu, Forming Winning Strategies, An Integrated Theory of Habitual
Domains, Springer-Verlag, Berlin, Heidelberg, New York, London, Paris, Tokyo,
1990 (392 pages).

15. Po-Lung Yu, Habitual Domains: Freeing Yourself from the Limits on Your
Life, Highwater Editions, Kansas City, July 1995 (224 pages). (also available in
Chinese and Korean translation)

16. Po-Lung Yu, Habitual Domains and Forming Winning Strategies, NCTU
(National Chiao Tung University) Press, Hsinchu, Taiwan, 2002 (531 pages).

References for the Variational rationality approach

Publications

1) Attouch, H. Soubeyran, A.: (2006) Inertia and reactivity in decision making
as cognitive variational inequalities. Journal of Convex Analysis, 13 (2), 207–224

2) Martinez Legaz, J.E., Soubeyran, A.:
(2007) A Tabu search scheme for
abstract problems, with applications to the computation of ﬁxed points Journal
of Mathematical Analysis and Applications, 338 (1), 620-627

3) Atouch, H., Redont, P., Soubeyran, A.: (2007) A New class of alternat-
ing proximal minimization algorithms with costs- to- move. SIAM Journal on

26

Optimization, 18 (3), 1061-1081

4) Attouch, H., Bolte, J., Redont, P., Soubeyran, A.: (2008) Alternating proxi-
mal algorithms for weakly coupled convex minimization problems. Applications
to dynamical games and PDE’s. Journal of Convex Analysis,15 (3), 485-506

5) Cruz Neto, J. X., Oliveira, P. R., Souza, S. S., Soubeyran, A.: (2010 ) A
Proximal point algorithm with separable Bregman distances for quasiconvex
optimization over the nonnegative orthant. European Journal of Operation
Research, (201) (2), 365-376

6) Luc, D. T., Sarabi, E., Soubeyran, A.: ( 2010) Existence of solutions in varia-
tional relations problems without convexity. Journal of Mathematical Analysis
and Applications, 364 (2), 544-555

7) Attouch, H., Bolte, J., Redont, P., Soubeyran, A.: (2010) Proximal Al-
ternating Minimization and Projection Methods for Nonconvex Problems. An
Approach Based on the Kurdyka- Lojasiewicz Inequality, Mathematics of Op-
erations Research, 35 (2), 438-457

8) Attouch, H., Soubeyran, A.: (2010) Local search proximal algorithms as
decision dynamicswith costs to move, Set-Valued and Variational Analysis, 19
(1), 157-177

9) Moreno, F., Oliveira, P. R., Soubeyran, A.: (2012) A proximal algorithm
with quasi distance. Application to habits formation, Optimization, 61 (12),
1383-1403

10) Flores Bazan, F., Luc, T., Soubeyran, A.: (2012) Maximal elements un-
der reference-dependent preferences with applications to behavioral traps and
games. Journal of Optimization Theory and Applications, 155 (3), 883-901.

11) Godal, O., Flam, S., Soubeyran, A.: ( 2012) Gradient diﬀerences and bilat-
eral barters,1-20, I First http://dx.doi.org/10.1080/02331934.2012.679940

12) Luc, D. T., Soubeyran, A.: (2013) Variable preference relations: Existence
of maximal elements. Journal of Mathematical Economics, 49(4), 251-262

13) Cruz Neto, J. X., Oliveira, P. R., Soares Jr, P. A., Soubeyran, A. (2013)
Learning how to play Nash, potential games and alternating minimization method
for structured non convex problems on Riemannian manifolds. Journal of Con-
vex Analysis, 20(2), 395-438

27

14) Cruz Neto, J. X., Oliveira, P. R., Soares Jr, P. A., Soubeyran, A.: (2013)
Proximal Point Method on Finslerian Manifolds and the “Eﬀort–Accuracy”
Trade-oﬀ. Journal of Optimization Theory and Applications, 1-19.
http://dx.doi.org/10.1007/s10957-013-0483-5

15) Villacorta.K, Oliveira.P, Soubeyran.A. (2013). A Trust-Region Method for
Unconstrained Multiobjective Problems with Applications in Satisﬁcing Pro-
cesses. Journal of Optimization Theory and Applications, 160 (3), 865-889

16) Bento, G. C., Cruz Neto, J. X., Oliveira, P. R., Soubeyran, A.: (2014). The
self regulation problem as an inexact steepest descent method for multicriteria
optimization. European Journal of Operational Research. 235, 494-502

17) Long, N., Soubeyran, A., & Soubeyran, R.(2013). Knowledge Accumulation
within an Organization. Accepted for publication in the International Economic
Review.

18) Bento, G., Cruz Neto, J. X., Soubeyran, A.: (2014) A Proximal Point-Type
Method for Multicriteria Optimization. Set-Valued and Variational Analysis:
theory and applications, v. 22, p. 557-573, 2014.

In revision

19) Bento, G. C., Soubeyran, A.: ( 2014) Generalized Inexact Proximal Algo-
rithms: Habit’s Formation with Resistance to Change, following Worthwhile
Changes. JOTA.

20) Bento, G. C., Cruz Neto, J. X., Soares, P., Soubeyran, A.: (2014) Variational
Rationality and the Equilibrium Problem on Hadamard Manifolds. JOTA

Submitted papers

21) Martinez Legaz, J. E., Soubeyran, A.: (2013) Convergence in sequential
decision making with learning and costs to change, soumis Systems and Control
Letters.

22) Bao, T., Mordukhovich, B., Soubeyran, A.: (2013) Variational Analysis in
Psychological Modelling. JOTA.

23) Bento, G. C., Cruz Neto, J. X., Soares, P., Soubeyran, A.: (2014) Bilevel
equilibrium problems as limits of variational traps. JOTA

28

24) Bao, T., Mordukhovich, B., Soubeyran, A.: (2013) Variational principles,
variational rationality and the Sen capability approach of well being. EJOR.

25) Moreno, F., Oliveira, P. R., Soubeyran, A.:(2013) Dual equilibrium prob-
lems: how a succession of aspiration points converges to an equilibrium. To be
submitted.

ARXIV papers

26) Attouch, H., Soubeyran, A.: (2009) Worthwhile-to-move behaviors as tem-
porary satisﬁcing without too many sacriﬁcing processes.

27) Bao, T., Mordukhovich, B., Soubeyran, A.: (2013) Variational principles in
models of Behavioral Sciences.

28) Bento, G. C., Soubeyran, A.: (2013) Some Comparisons between Variational
rationality, habitual Domain and DMCS approaches.

Pre prints

29) Soubeyran, A.: (2009) Variational rationality, a theory of individual stability
and change: worthwhile and ambidextry behaviors.

30) Soubeyran, A.: (2010) Variational rationality and the unsatisﬁed man: rou-
tines and the course pursuit between aspirations, capabilities and beliefs.

Other references

31) Tversky, A., Kahneman, D.: Loss aversion in riskless choice: a reference
dependent model. Q. J. Econ. 106(4), 1039-1061 (1991)

32) Simon. H.: A behavioral model of rational choice. Q. J. Econ. 69, 99-118
(1955)

33) Kahneman, D., Tversky, A.: Prospect theory: An analysis of decision under
risk. Econometrica 47(2), 263-291 (1979)

34) Abdellaoui, M., Bleichrodt, H., Paraschiv, C.: Loss aversion under prospect
theory: A parameter-free measurement. Manage. Sci. 53(10), 1659-1674 (2007)

35) K¨obberling, V., Wakker, P.: An index of loss aversion. J. Econ. Theory.
122,119–131 (2005)

29

36) Verplanken, B., Aarts, H.: Habit, attitude and planned behaviour: Is habit
an empty construct or an interesting case of goal-directed automaticity? Eur.
Rev. Soc. Psychol. 10, 101–134 (1999)

37) Duhigg, C.: The power of habits. Why we do what we do in life and business.
Random House, New York (2012)

38) Costa, A., Kallick, B.: Habits of mind. A developmental deries. Association
for Supervision and Curriculum Development, Alexandria, VA (2000)

39) Gardner, B.: Habit as automaticity, not frequency. Eur. Health Psychol.
14 (2) 32-36 (2012)

40) Verplanken, B., Wood, W.: Interventions to break and create consumer
habits. J. Public Policy Mark. 25 (1), 90 - 103 (2006)

41) Bargh, J. A.: The four horsemen of automaticity: Awareness, intention,
eﬃciency and control in social cognition. In R.S. Wyer and T.K. Srull (Eds),
Handbook of Social Cognition. Hillsdale, N. J. Erlbaum (1994).

42) Aarts, H., Dijksterhuis, A.: The automatic activation of goal directed be-
haviour: The case of travel habit. J. Environ. Psychol. 20, 75-82 (2000)

43) Verplanken, B., Aarts, H.: Habit, attitude and planned behaviour: Is habit
an empty construct or an interesting case of goal-directed automaticity? Eur.
Rev. Soc. Psychol. 10, 101 – 134 (1999)

44) Lally, P., Van Jaarsveld, C., Potts, H., Wardle, J.: How are habits formed:
Modelling habit formation in the real world. Eur. J. Soc. Psychol. 40(6),
998-1009 (2010)

45) Lewin, K.: Field theory in social sciences. NY: Harper & Row, New York
(1951)

46) Rumelt, R.: Inertia and transformation. Montgomery, Cynthia A., ed.,
Resources in an Evolutionary Perspective: Towards a Synthesis of Evolution-
ary and Resource-Based Approaches to Strategy, Kluwer Academic Publishers,
Norwell, Mass. 101-132 (1995)

47) Li, B.: The reviews and prospects of studies on habits. Psychol. Sci. 35(3)
745-753 ( 2012)

48) Ajzen. I.: The theory of planned behavior. Organ. Behav. Hum. Dec. 50,

30

179-211 (1991)

49) Verplanken, B., Orbell, S.: Reﬂections on past behavior: a self-report index
of habit strength. J. Appl. Soc. Psychol. 33(6), 1313–1330 (2003)

50) Wood, W., Neal, D.: A new look at habits and the habit-goal interface.
Psychol. Rev. 114(4), 843-863 ( 2007)

51) Becker.G, Murphy, K.: A theory of rational addiction. J. Polit. Econ. 96,
675-700 (1988)

52) Abel, A.: Asset prices under habit formation and catching up with the
Joneses. Am. Econ. Rev. 80(2), 38-42 (1990)

53) Carroll, C.: Solving consumption models with multiplicative habits. Econ.
Lett. 68, 67-77 (2000)

54) Wendner, R.: Do habits raise consumption growth? Research in Economics
57, 151–163 (2003)

55) Becker, M.: Organizational routines: a review of the literature. Oxford J.
Econ. & Soc. Sci.- Industrial and Corp. Ch. 13(4), 643-678 (2004)

56) Cohen, M., Grossberg, S.: Absolute stability of global pattern formation and
parallel memory storage by competitive neural networks. IEEE Transactions on
Systems, Man, and Cybernetics, SMC, 13, 815-826 (1983)

57) Grossberg, S.: Contour enhancement, short term memory, and constancies
in reverberating neural network, Stud. Appl. Math. 3 (3) 213-256, (1973)

58) Grossberg, S.: Competition, decision, and consensus, J. Math. Anal. 66,
47-93, (1978)

59) Grossberg, S.: How does a brain build a cognitive code? Psyhal. Rer. 87
(1), 1-51, (1980)

60) Kunreuther, H., Meyer, R., Zeckhauser, R., Slovic, P., Schwartz, B., Schade,
C., Hogarth, R.: High stakes decision making: Normative, descriptive and pre-
scriptive considerations. Marketing Letters, 13 (3), 259-268 (1980)

31

