9
1
0
2

t
c
O
1
1

]

V
C
.
s
c
[

1
v
4
4
9
4
0
.
0
1
9
1
:
v
i
X
r
a

AN AUTOMATIC DIGITAL TERRAIN GENERATION TECHNIQUE
FOR TERRESTRIAL SENSING AND VIRTUAL REALITY
APPLICATIONS

A PREPRINT

Lee Easson
Department of Computer Science and Engineering
University of Nevada, Reno
Reno NV 89557

Alireza Tavakkoli
Department of Computer Science and Engineering
University of Nevada, Reno
Reno NV 89557

Jonathan Greenberg
Department of Natural Resources and Environmental Science
University of Nevada, Reno
Reno NV 89557

October 14, 2019

ABSTRACT

The identiﬁcation and modeling of the terrain from point cloud data is an important component of
Terrestrial Remote Sensing (TRS) applications. The main focus in terrain modeling is capturing
details of complex geological features of landforms. Traditional terrain modeling approaches rely
on the user to exert control over terrain features. However, relying on the user input to manually
develop the digital terrain becomes intractable when considering the amount of data generated by
new remote sensing systems capable of producing massive aerial and ground-based point clouds
from scanned environments. This article provides a novel terrain modeling technique capable of
automatically generating accurate and physically realistic Digital Terrain Models (DTM) from a
variety of point cloud data. The proposed method runs efﬁciently on large-scale point cloud data
with real-time performance over large segments of terrestrial landforms. Moreover, generated digital
models are designed to effectively render within a Virtual Reality (VR) environment in real time. The
paper concludes with an in-depth discussion of possible research directions and outstanding technical
and scientiﬁc challenges to improve the proposed approach.

Keywords Digital Terrain Model · Terrestrial Remote Sensing · Geological Landmass Modeling.

1

Introduction

Terrains are among the most fundamental features in any virtual application simulating a landmass, ranging from
computer games to geological simulations. For example, in an open-world massively multiplayer online role playing
game, large-scale natural environments maybe designed for players to explore, where a vast terrain is usually the ﬁrst
part of the authoring pipeline to be subsequently augmented with props that represent rocks, trees, plants and buildings.
On the other hand, real-world terrain are usually more complex and varied and may include plains, mountain ranges,
and eroded valleys in a single environment. Terrain formation is a combination of long-term and complex geological
events with complicated physical and geological interactions amongst different components comprising the landmass.
In addition, different geological features are dominant at difference range scales. These complexities contribute to many
unsolved challenges in terrain modeling.

One deﬁnition of Digital Terrain Models (DTM), [1], relates to geometrical aspects of the 3D environment acquired
from Laser scanning and is a continuous function mapping a 2D position (x, y) to the terrain elevation z = f (x, y). In

 
 
 
 
 
 
A PREPRINT - OCTOBER 14, 2019

this deﬁnition, the terrain is deﬁned as the boundary between the ground and the air. Yet, there are certain geographical
feature, such as overhangs [2], ground vegetation [3], and large man-made structures, that may render the assumptions
required for this deﬁnition inaccurate [4].

The aforementioned DTM will require utilizing a large amount of data collected by aerial or ground-based Laser
scanning technology. This data is generally combined to produce a collection of points referred to as Point Clouds (PC).
In essence, each point in a point cloud represented a location in the world from which the light emitted from the scanner
is reﬂected back. The massive amount of data within even a small scanned region makes it necessary to represent the
DTM using a more efﬁcient structure.

Several data structures are utilized in the literature that represent DTMs with varied levels of performance [4]. These
structures range from pixel-level representation of the elevation data by quantizing the 2D planimetric locations of the
point clouds to a hybrid approach by interpolating points on the surface of a grid-mesh structure [5]. To improve the
quality of the structure of the DTM, and with the popularity of triangulation techniques in computer graphics, several
Triangulated Irregular Networks (TINs) are proposed with the goal of improving storage efﬁciency of the point cloud
representation of the DTM [6], with recent attempts to improve the performance of the triangulation approaches [7–10].
Most of these methods assume that the terrain is smooth and continuous with a large height difference between
neighbouring points on ground and non-ground objects. Therefore, the performance of these methods often decreases
through wrongly ﬁltering hilly regions and large buildings.

Because of the simplicity and ease of implementation, morphology-based methods [11–14] are mostly used in ground
ﬁltering. However, ﬁnding the correct structuring element size is a problem in these methods. While a small structuring
element is needed for ﬁltering points on vegetation, tree, and cars, a large structuring element should be used for ﬁltering
points on buildings.

In this paper we propose an fast ground ﬁltering approach with an efﬁcient DTM representation capable of preserving
detailed geological features and applicable to both urban and non-urban landmasses. Unlike most other methods that try
to extract ground points via many iterations for DTM generation, the proposed technique extracts all ground points via a
series of atomic operations geared towards preserving geological features and eliminating non-ground points. The main
hypothesis in the proposed method is that non-ground objects produce sharp variations in elevation within a spacial
neighborhood. Hence, we propose using region growing for segmenting non-ground objects. The method is tested on a
number of point cloud data sets obtained the United States Geological Survey. The proposed method is also compared
with the existing methods.

2 The Proposed Approach

Fig. 1 shows an overview of the proposed Point Cloud Filtering and DTM generation pipeline. The proposed architecture
is comprised of three components, i.e., preprocessing stage, map generation module, and terrain generation module,
shown as the vertical tracks. These components in turn process three different data structures in the form of Point
Clouds, Heightmaps, and Landscape mesh.

The ﬁrst stage of the proposed pipeline is the preprocessing step. In this stage the Lidar point cloud data is processed
to represent a gridded topological form. To accomplish this task, we perform the nearest neighbor interpolation in
conjunction with a kernel-based statistical outlier removal to generate the raster grid from the Lidar point cloud. In this
step, the three data structures representing the point cloud data, the spatial matrix of the map data, and the landscape
texture and material data will be established and ready for processing. The texture data is extracted from the point
clouds photometric information, if this information is available. The photometric information will be used to produce a
diffuse map as well as a normal map for the terrain materials.

The second stage in the pipeline is responsible for generating the heightmap data representing a topological formation
of the terrain as well as shader models for rendering a physically realistic view of the material applied on the surface
of the terrain. In this stage, the topological spatial matrix is processed in order to accomplish two tasks. First, the
overall topological and geological statistics of the terrain is learned by employing Singular Value Decomposition (SVD).
Second, the learned statistics of the overall terrain topology is combined with the ﬁrst and second order statistics of the
point cloud data to eliminate the non-terrain objects while preserving details of the geological features of the terrain.

The last step in the pipeline is the terrain generation stage. In this stage, the resolution of the ﬁnal landscape is calculated
from the overall point cloud data. This information is then used to ﬁll the holes introduced in the topological heightmap
as a result of non-terrain object segmentation. Once the overall heightmap of the terrain is established, the terrain mesh
generation process will generate an efﬁcient digital mesh model for the terrain represented at various Level of Detail
(LoD) information. At this stage the shader models for the terrain materials are also computed and applied to render the
terrain.

2

A PREPRINT - OCTOBER 14, 2019

2.1 The Preprocessing Step

Figure 1: The proposed processing pipeline.

The preprocessing stage of the proposed pipeline, shown in Algorithm 1, is responsible for initializing the gridded and
rasterized data structures for the Terrain heightmaps, texture maps, and shader materials.
Algorithm 1: Preprocessing Stage of the DTM Generation Pipeline.
Data: P : Input-Point Cloud. // point Pi = (xi, yi, zi, ri, gi, bi)
Result:
L : Landscape Point Cloud Data File.
T : Landscape Texture.
M : Landscape Layered Material.
begin

L(x, y) ← Stat_Outlier(P, th) // Eq.(1)
for all Pi do

Find Ll(x, y, z) lowest and Lh(x, y, z) highest Lidar Returns Eq.(2)

Set texture Coordinates: begin

T (u, v) = new_T exture(u, v) // coordinate map from Eq.(3)

Set Shader Material: begin

M ← new_M aterial(Dif f (u, v), N orm(u, v))

2.1.1 Statistical Outlier Removal:

The ﬁrst step in cleaning out the input Lidar point-cloud data is to eliminate outliers. Outliers include points introduced
to the point cloud due to noise or small moving objects, such as airplanes, located at drastically different heights than
the terrain, need to be eliminated. In order to perform this task, we ﬁrst build a non-parametric density estimation of the
point cloud in a local spatial neighborhood [15].

Assuming an outlier threshold of th, we eliminate points from the point cloud data whose probability of belonging to
the known distribution from which the Lidar data is generated falls below th. This probability is calculated using the
non-parametric kernel density estimation, below:
1
|Nk(zi)|

σ(pj, pi)
2h2

P (zi|inlier) =

1
σ(cid:112)(2π)

exp

(cid:88)

(1)

−

(cid:18)

(cid:19)

zj ∈Nk(zi)

3

A PREPRINT - OCTOBER 14, 2019

where zi is the height value of the ith point pi in the point cloud data pj at a spatial neighborhood location of Nk ∈ R2.

2.1.2 Top and Bottom Returns:

Once the statistical outliers are eliminated, we will need to determine the most likely ground points. In order to
accomplish this task, we will set two rasterized data structures for the lowest return and the highest return points at a
location (x, y) denoted as Ll(x, y, z) and Lh(x, y, z):

∀Pi

(cid:21)
(cid:20) Ll(x, y, z)
Lh(x, y, z)

=

(cid:34)min
zi
max
zi

(Pi : x = xi&y = yi)
(Pi : x = xi&y = yi)

(cid:35)

(2)

where x ∈ [min(xi), max(xi)] and y ∈ [min(yi), max(yi)].

2.1.3 Shader and Texture Initialization:

In order to render physically realistic materials on the surface of the ﬁnal DTM, we will establish the data structures
T (u, v) and M as the texture map and the landscape material, respectively. First, a mapping between the spatial domain
of the point cloud (x, y) ∈ R2 and the texture-coordinates (u, v) is determined:
(cid:21)
(cid:20)Φu : (xmin, xmax) → (0, 1)
Φv : (ymin, ymax) → (0, 1)

(u, v)T =

(3)

Next, the shader material for the landscape is initialized based on the photogrametric information, if this information is
included in the Lidar point cloud data. Suppose for each point Pi in the point cloud data, the photogrametric information
is given in the form of Ci = (ri, gi, bi) color components. The details about the computation of the diffuse and normal
channels of the landscape material are discussed later in the paper in section 2.3.

2.2 The Heightmap Generation Step

Once the point cloud data is reﬁned during the pre-processing step, it is passed through the heightmap generation stage
of the algorithm to produce a two-dimensional structure maintaining the overall height associated with the terrain
surface. This heightmap object is then utilized to generate a three-dimensional model of the terrain surface as a 3D
mesh object. This section discusses the process of generating the terrain heightmap by removing non-terrain objects
while preserving signiﬁcant geological features.

Algorithm 2: Heightmap Generation Stage of the DTM Pipeline.
Data:
Ll, Lh : Landscape Top and Bottom Point Cloud Data.
P : Point Cloud Data.
Result:
H : Landscape Heightmap Data File.
begin

for all Pi do

ˆL = Ll ∩ Lh // Non-ground overhangs
L = (Ll ∪ Lh) − ˆL // Potential ground points
ˆH ← L.Heights // Eq.(4)
Find ˆg ← S.V.D. ( ˆH) // Eq.(7)
g ← inPaint(ˆg) // Fill holes

Algorithm 2 shows the overall pipeline of generating the terrain surface heightmap. The process starts by taking the
top and bottom point cloud data structures generated from the pre-processing phase to determine the potential ground
points and eliminate the over-hangs. Then a polynomial function with sufﬁcient local variance and smooth global
consistency is ﬁt onto the data to estimate the overall structure of the terrain ground. This is utilized to computer the
ground heightmap values for each point in the landmass.

4

A PREPRINT - OCTOBER 14, 2019

(a)

(b)

(c)

(d)

(e)

(f)

Figure 2: Terrain Modeling Heightmap Generation Step Performed on Idaho Dataset. (a) Original Data with No-terrain
Elements. (b) Dark Areas are Non-Terrain LiDar Returns. (c) Dark Areas are Non-Terrain Geological Features. (d)
Non-Terrain Geological Features are Removed. (e) Non-Terrain Areas are Removed. (f) Final Terrain Heightmap.

2.2.1 Terrain Height Estimation

With the Lowest Ll and the highest Lh LiDar returns from the point cloud data, we start modeling the heightmap of the
terrain. Each point (x, y, z) in a point cloud belongs to one of two classes, i.e., the ground or the non-ground objects.
Both Ll and Lh are quantized in such a way as to represent 2D grids ranging from (xmin, ymin) to (xmax, ymax).

It is trivial to eliminate overhangs (or points covering the ground area) if both the ground position and the overhang
points are visible within the point cloud data. Points within a spatial location R(x, y) are considered to belong to the
non-ground object covering the surface of the ground if they exist in both Ll and Lh structures. Therefore, the ﬁrst
iteration of the heightmap is generate by interpolating the height values of all points in Ll that do not belong to Lh as:

ˆH = h(x, y) =

1
Size(R)

(cid:88)

(x,y,z)∈R

{z|(x, y, z) ∈ L}

(4)

The height of the ground in a landmass may be considered as a low-degree polynomial with the non-ground objects,
e.g. shrubbery, biomass, and man-made structures, disrupting the natural curvature and geological features of the
terrain. Therefore, we postulate that the heightmap of the terrain is a combination of a ground function g(x, y) and an
anomalous function N (x, y):

h(x, y) = g(x, y) + N (x, y)

(5)

where h is a heightmap calculated from raw point cloud data (Fig. 2(a)), g is a low-order polynomial function with high
degrees of smoothness over a large spatial area representing the ground heightmap (Fig. 2(f)), and N represents the
non-ground geological and man-made features shown in Fig. 2(b) and Fig. 2(c).

This formulation represents the terrain heightmap modeling as a novelty detection question [16]. Therefore, we represent
the ground region of the terrain heightmap data g as a polynomial with degree N of the following form:

aibj(xi · yj)

(6)

g(x, y) =

N
(cid:88)

i,j=0

5

A PREPRINT - OCTOBER 14, 2019

Algorithm 3: Mesh Generation and Shader Programming of the DTM Pipeline.
Data:
P : Point Cloud Data
H : Heightmap
Result:
M : Terrain Mesh. H : Terrain Heightmap. T : Terrain Texture. M at : Shader Material.
begin

Mesh.Vert: M.(vertex.x,vertex.y) Φ←− (H.x, H.y) M ← Interpolate[h(Grid(x, y))]
for all Pi do

T ←PC2Texture(P, H) // Generate Texture from Point Cloud

Calculate Terrain Extent
(U, V ) ← Texture Coordinate Mapping
M at ← (Dif f useuv, N ormaluv) // Shader Program

Using the above formulation, and given the heightmap from Eq.(4), we need to solve the linear system of equations
resulting from all (x, y) values of ˆH as follows:




[h(x1, y1) · · · h(xN , yN )]T =

(cid:2)1 x y

· · · xN yN (cid:3)




(7)

a0b0 a1b0
...
...
a0b0 a1b0




· · · aN bN
. . .
· · · aN bN

...

This terrain function may be visualized as the combination of Fig. 2(d) and Fig. 2(e), in which the darker areas represent
non-ground objects encoded as N . These dark areas produce holes in the ground heightmap and are ﬁlled using an
automatic inpainting algorithm similar to [17]. The ﬁnal terrain heightmap is shown in Fig. 2(f).

(a)

(b)

Figure 3: Terrain meshes: (a) Terrain mesh from the original point cloud. (b) Terrain mesh with the proposed heightmap
generation technique.

2.3 The Terrain Modeling Step

Digital Terrain Models are employed in a number of applications ranging from geographical analysis, biomass and
environmental studies, etc. In order for a DTM to be useful for its intended application, it must be generated in such an
efﬁcient manner as to allow for realistic rendering, interactivity, and efﬁcient manipulation. To this end, we propose
the use of the Unreal Engine 4’s Landscapes [18]. Algorithm 3 provides an overview of this stage of the pipeline
responsible for generating the 3D mesh of the terrains as well as shader materials employed for physically realistically
rendering of the terrain.
2.3.1 Terrain Mesh Modeling:

The 3D mesh representing the ground surface is generated by applying a polygonal mesh based on the heightmap
generated from the previous step. In this stage of the algorithm, a 2D grid is generated for each pair of (x, y) coordinates
associated with pixels in the heightmap.

2.3.2 Terrain Texture Modeling:

With the mapping between the heightmap data and the point cloud data established, an interpolation technique is used
to sample the color (or intensity) values from point clouds in a neighborhood that map onto the terrain mesh object.

6

A PREPRINT - OCTOBER 14, 2019

(a)

(b)

(c)

Figure 4: Terrain Texture: (a) Original Sparse Texture. (b) Dense Texture. (c) Modiﬁed Dense Texture.

Fig. 4 shows the resutls of the interpolation steps taken to generate a photorealistic texture for the terrain from the Point
Cloud data.

Figure 5: Final Terrain Model with Shader Parameters Applied.

2.3.3 Terrain Material Modeling:

The material applied to the surface of the terrain mesh is comprised of two main channels, a diffuse channel and a
normal channel. The diffuse channel of the material utilizes the texture coordinates to map the color (or intensity)
values of the terrain texture on the surface of the 3D terrain mesh. The normal channel is computing using a normal
map generation technique [19].

Fig. 5 shows the ﬁnal rendering of the Digital Terrain Model with the material applied. As it can be seen, the quality
of the rendering is quite realistic. Note the various geological features preserved, while the man-made structures or
non-ground objects are effectively removed from the terrain model. The texture applied on the surface of the terrain in
the form of a physically-based material drastically enhances the visualization of the DTM.

3 Experimental Results

This section presents the results of the proposed DTM technique performed on a variety of point cloud data from the
USGS datasets. The ﬁrst set of results (Fig. 6) demonstrates that quality of the modeled DTM compared to the rendering
of the point cloud data. The point cloud data rendered in the Cloud Compare software is shown in Fig. 6(a). The main
issue is the lack of discrimination between points belonging to the ground surface and other structural elements. The
proposed technique has the ability to eliminate the non-terrain elements while preserving signiﬁcant geological features
as evident from Fig. 6(b).

Fig. 7 shows the generated heightmaps (Fig. 7(a)) and the 3D landscape mesh associated with each heightmap (Fig. 7(b).
As seen from the ﬁgures, the proposed DTM mesh objects represent the geological features quite accurately.

7

A PREPRINT - OCTOBER 14, 2019

(a)

(b)

Figure 6: The results of the proposed framework. (a) The original point cloud data rendered in Cloud Compare software.
(b) The 3D landscape DTM generated by the proposed framework and rendered in Unreal Engine 4.

4 Conclusions and Future Work

In this paper we proposed a pipeline for generating Digital Terrain Models (DTM) from a variety of Lidar-based point
cloud datasets. The proposed pipeline automatically generates heightmaps by eliminating non-ground points from the
point cloud and interpolating the surface height values from the remaining points. The texture and materials are also
created to provide photorealistic rendering of the terrain 3D mesh. There are a number of future directions to this work.
Performing semantic segmentation on the 3D point cloud data may add higher level information to the data useful for
effective generation of heightmaps.

References

[1] Naser El-Sheimy, Caterina Valeo, and Ayman Habib. Digital terrain modeling: Acquisition, manipulation and

applications (artech house remote sensing library). Norwood, MA: Artech House, 2005.

[2] Norbert Pfeifer. A subdivision algorithm for smooth 3d terrain models. ISPRS journal of photogrammetry and

remote sensing, 59(3):115–127, 2005.

[3] Erik Næsset. Vertical height errors in digital terrain models derived from airborne laser scanner data in a

boreal-alpine ecotone in norway. Remote Sensing, 7(4):4702–4725, 2015.

[4] Jie Shan and Charles K Toth. Topographic laser ranging and scanning: principles and processing. CRC press,

2018.

[5] Friedrich E Ackermann and Karl Kraus. Grid based digital terrain models. na, 2004.
[6] Peter Axelsson. Dem generation from laser scanner data using adaptive tin models. International archives of

photogrammetry and remote sensing, 33(4):110–117, 2000.

[7] Jixian Zhang and Xiangguo Lin. Filtering airborne lidar data by embedding smoothness-constrained segmentation

in progressive tin densiﬁcation. ISPRS Journal of photogrammetry and remote sensing, 81:44–59, 2013.

[8] Domen Mongus and Borut Žalik. Parameter-free ground ﬁltering of lidar data for automatic dtm generation.

ISPRS Journal of Photogrammetry and Remote Sensing, 67, 2012.

[9] Domen Mongus and Borut Žalik. Computationally efﬁcient method for the generation of a digital terrain model
from airborne lidar data using connected operators. IEEE journal of selected topics in applied earth observations
and remote sensing, 7(1):340–351, 2013.

[10] Abdullah H Özcan and Cem Ünsalan. Lidar data ﬁltering and dtm generation using empirical mode decomposition.
IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 10(1):360–371, 2016.
[11] Andrej Kobler, Norbert Pfeifer, Peter Ogrinc, Ljupˇco Todorovski, Krištof Oštir, and Sašo Džeroski. Repetitive
interpolation: A robust algorithm for dtm generation from aerial laser scanner data in forested terrain. Remote
sensing of environment, 108(1):9–23, 2007.

[12] Thomas J Pingel, Keith C Clarke, and William A McBride. An improved simple morphological ﬁlter for the
terrain classiﬁcation of airborne lidar data. ISPRS Journal of Photogrammetry and Remote Sensing, 77:21–30,
2013.

8

A PREPRINT - OCTOBER 14, 2019

(a)

(b)

Figure 7: Heightmaps (a) and their associated terrains (b) generated by the proposed framework. From top: California
Calaveras-Tuolumne (CA), Washington County (FL), and Oahu (HI), respectively.

[13] Yong Li, Bin Yong, Huayi Wu, Ru An, and Hanwei Xu. An improved top-hat ﬁlter with sloped brim for extracting

ground points from airborne lidar point clouds. Remote sensing, 6(12):12885–12908, 2014.

[14] Domen Mongus, Niko Lukaˇc, and Borut Žalik. Ground and building extraction from lidar data based on
differential morphological proﬁles and locally ﬁtted surfaces. ISPRS Journal of Photogrammetry and Remote
Sensing, 93:145–156, 2014.

[15] Alireza Tavakkoli, Mircea Nicolescu, and George Bebis. Automatic robust background modeling using multivariate
non-parametric kernel density estimation for visual surveillance. In International Symposium on Visual Computing,
pages 363–370. Springer, 2005.

[16] Alireza Tavakkoli. Novelty detection: An approach to foreground detection in videos. In Pattern Recognition.

IntechOpen, 2009.

[17] Nguyen Van Sinh, Tran Manh Ha, and Nguyen Tien Thanh. Filling holes on the surface of 3d point clouds based on
tangent plane of hole boundary points. In Proceedings of the 7th Symposium on Information and Communication
Technology, pages 331–338, 2016.

9

[18] Alireza Tavakkoli. Game development and simulation with Unreal Technology. AK Peters/CRC Press, 2nd edition,

2018.

[19] Gimp. Normal map plugin, 2019.

A PREPRINT - OCTOBER 14, 2019

10

