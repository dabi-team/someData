Facial Electromyography-based Adaptive Virtual
Reality Gaming for Cognitive Training

Lorcan Reidy1, Dennis Chan2, Charles Nduka3 and Hatice Gunes1

0
2
0
2

g
u
A
0
3

]

C
H
.
s
c
[

3
v
3
2
0
5
0
.
5
0
0
2
:
v
i
X
r
a

Abstract— Cognitive training has shown promising results
for delivering improvements in human cognition related to
attention, problem solving, reading comprehension and infor-
mation retrieval. However, two frequently cited problems in
cognitive training literature are a lack of user engagement
with the training programme, and a failure of developed
skills to generalise to daily life. This paper introduces a new
cognitive training (CT) paradigm designed to address these
two limitations by combining the beneﬁts of gamiﬁcation,
virtual reality (VR), and affective adaptation in the develop-
ment of an engaging, ecologically valid, CT task. Additionally,
it incorporates facial electromyography (EMG) as a means
of determining user affect while engaged in the CT task.
This information is then utilised to dynamically adjust the
game’s difﬁculty in real-time as users play, with the aim of
leading them into a state of ﬂow. Affect recognition rates
of 64.1% and 76.2%, for valence and arousal respectively,
were achieved by classifying a DWT-Haar approximation of
the input signal using kNN. The affect-aware VR cognitive
training intervention was then evaluated with a control group
of older adults. The results obtained substantiate the notion
that adaptation techniques can lead to greater feelings of
competence and a more appropriate challenge of the user’s
skills.

I. INTRODUCTION

Cognitive training (CT) has garnered considerable at-
tention due to the promising intervention outcomes it has
provided for improving cognitive skills such as attention,
problem solving, reading comprehension and information
retrieval. Clinician-delivered or computerised CT has been
used for children with attention problems (ADHD) [1] and
engagement in intellectually stimulating lifestyle activities
has been observed to help maintain cognitive function into
later life, via enhancement of cognitive reserve [2]. The
aim of CT therefore is to deliver such beneﬁts to cognition
as a targeted discrete intervention. However, to date, the
numerous studies and CT products, often commercially
marketed as ”brain training” programmes or apps, have
not been found to produce clear evidence of beneﬁt to
cognition [3]. This failure has been attributed to several
factors. The ﬁrst problem (P1) is that of adherence to
the CT programme; with traditional CT programmes often
having attrition rates exceeding 15% [4]. Prior studies

and H. Gunes

1L.

Reidy
Computer

of
Cambridge,
hatice.gunes@cl.cam.ac.uk

Science
U.K.

and

are with
Technology,

the Department
of
lsr29@alumni.cam.ac.uk,

University

2D. Chan is with Institute of Cognitive Neuroscience, University

College London, U.K. dcfchan@doctors.org.uk

3C. Nduka is with Emteq Ltd, U.K. charles@emteq.net

have indicated that participant adherence can decrease with
increasing intervention complexity and intensity [5], [6],
with inhibition due to poor task performance being a strong
predictor for training dropout [7]. These CT programmes
are overly repetitive and fail to address the motivational
deﬁcits often characteristic of older people with memory
difﬁculties [8]. Furthermore, it has been suggested that a VR
format may increase training adherence (when compared
to an on-paper equivalent task) in individuals with Mild
Cognitive Impairment (MCI) and dementia patients [9].
The second problem (P2) is that the skills developed and
the cognitive improvements made during these training
programmes do not transfer to daily life. While the user
might get better at playing the games, there is little ev-
idence that these skills will generalise beyond that [10].
Existing dynamic difﬁculty adjustment (DDA) models have
historically relied on the players performance to infer what
changes in difﬁculty are appropriate. However, Pagulayan
et al. point out that a games evaluation factor ought to be
the affective experience provided by the gameplay, rather
than user performance as in productivity software [11].
Mishra et al. were also of the opinion that the input channel
for closed-loop games should include real-time data from
player interactions and behaviour, rather than just player
performance metrics [12].

The work presented in this paper introduces a novel CT
programme designed to address these two problems, with
an ultimate goal of employing this CT environment for
people with early stages of dementia to support cognitive
training. In keeping with other approaches to CT, a game-
based paradigm is used to enhance participant enjoyment
and thus increase adherence (addressing P1). The use of
VR to create simulated real-world environments within
which the CT game is enacted helps overcome the transfer
problem and facilitate extension of CT-generated gains to
real life activities (addressing P2). Additionally, the design
of the CT task incorporates an active control arm and an
affective feedback loop that enables the dynamic adjustment
of the game’s difﬁculty (DDA), in real-time, based on the
player’s affective state [13] and their in-game performance
(addressing P1). The affective feedback loop is based on
measuring facial electromyography (EMG) signals related
to the nonverbal facial behaviour of the participants, and
training supervised machine learning models with user self-
reported affect labels. The employment of facial EMG is
due to three reasons: (i) other physiological measures such
as the galvanic skin response (GSR) have been reported

 
 
 
 
 
 
to provide extremely noisy signals in gaming where the
user is using a controller and moving around during the
game play [14]; (ii) it is widely acknowledged that the
face is the primary means for communicating affective
and cognitive mental states, including emotions, interest,
agreement, comprehension, concentration and intentions
[15], [16]; and (iii) computer-vision based analysis of facial
expressions, despite its efﬁcacy [17], [18], is not appropriate
in a VR context as the user’s face is mostly occluded by
the head-mounted display.

II. RELATED WORK

A. Cognition, Memory and Affect

The bisection of memory into short-term-memory (STM)
and long-term-memory (LTM), ﬁrst proposed by Hebb [19],
represents the core underlying division imposed in the
taxonomy of cognitive systems. The unitary notion of STM
can be partitioned to recognise a distinct cognitive system,
working memory (WM), that is responsible for temporarily
storing task relevant information available for manipula-
tion. LTM can be divided into procedural (non-conscious)
memory, which underpins skills/habits/conditioning, and
declarative (consciously accessed) memory for storing facts
and events [20]. Declarative memory can be further sepa-
rated into semantic memory (SM), a store of facts about
the world, and episodic memory (EM), the facility for re-
experiencing events in the context in which they originally
occurred [21]. EM is widely considered as a cognitive
competence unique to humans. Unlike SM, it explicitly
encodes spatial, contextual and temporal information.

such

Neurological

attention-
as
disorders
(ADHD) or dementia are
deﬁcit/hyperactivity disorder
associated with memory impairments. Numerous studies
have shown deﬁcits in short-term memory,
long-term
memory and coordination of multiple tasks resulting from
such disorders (e.g. see [22]). Therefore, the VR cognitive
training intervention developed for this work incorporates
both WM and EM training tasks.

WM capacity can be tested through a variety of tasks.
These tasks typically come in the form of a dual-task
paradigm that combines a measure of memory span (a STM
test that involves immediate recollection of an ordered list
of items) with a simultaneous processing task (e.g. see
[23]). It has also been argued that WM reﬂects the ability
to maintain multiple, task-relevant, pieces of information in
the face of distracting irrelevant information [24]. The WM
training task implemented in this work draws on both of
these ideas. A wide variety of methods have been developed
to assess EM capacity, but not all produce consistent results
[25]. For the purpose of this work, the implemented EM
training primarily focuses on spatial memory (SM) tasks,
as they engage the same regions of the brain that EM
requires [26]. SM tasks also proved to be a good ﬁt for
the VR paradigm, where ecologically valid scenarios could
be presented to the user in an engaging manner.

Bennion et al. [27],

in their study of the effect of
emotion on memory, suggest that there is strong evidence to

support the following hypotheses: emotion usually enhances
memory; when it does not, its effect can be understood by
the magnitude of elicited arousal (with arousal beneﬁting
memory up to a point, but
then having a detrimental
inﬂuence); and when emotion facilitates the processing of
information, it also facilitates the retention of that informa-
tion. The general notion that arousal will enhance memory,
up to a point, was reinforced by Yeh et al. in their research
of the effects of negative affect on WM capacity [28]. They
promote the idea of a game that appropriately challenges
users in order to activate their attention, while avoiding
negative emotional responses.

B. Affect and Gaming

Two domains, particularly relevant to this work, have
shown promise in recent literature for the application of
affective computing methods. The ﬁrst is the domain of
cognitive training, which is motivated by the strong re-
lationship between emotions and cognitive performance
[29]. The second is the domain of video games, where the
interaction has been noted as a predominantly emotional
one [30] and therefore susceptible to affective adaptation –
i.e., dynamically changing the gameplay experience based
on affective signals read from the player.

this biological

Affective gaming can be realised through the use of
biofeedback techniques. However, for a game to be con-
sidered affective (and not simply a biofeedback game),
information to propagate
it must exploit
affective feedback [31]. That is, the game is an intelligent
participant
in the biofeedback loop. What distinguishes
affective feedback from biofeedback is that the player is
not deliberately controlling their physiological responses in
order to inﬂuence gameplay.

There are numerous novel possibilities for emotive
twists on conventional gameplay experiences. For example,
Reynolds and Picard developed AffQuake [32], a modiﬁca-
tion to ID Software’s Quake II that incorporated affective
signals to alter gameplay in a variety of ways (e.g. in
StartleQuake, when a player becomes startled, their avatar
also becomes startled and jumps back). Valve Corporation
have also experimented with similar modiﬁcations to their
games: Half-Life 2 and Left 4 Dead 2 [33]. In these
modiﬁcations, the player’s stress level, measured as the
electrical response of their skin, determines the pace of
the
the gameplay. Compared to conventional gameplay,
use of VR in video games induces a greater degree of
engagement and immersion in players. This heightened
immersion, named presence (or the feeling of being there in
the virtual world), has been reported to directly impact the
affective states experienced by the player during gameplay
– i.e., high levels of presence induce more intense and vivid
emotions [34].

C. Therapeutic Applications of Virtual Reality

In a systematic review of computerised cognitive training
literature, Hill et al. concluded that computerised CT is a
viable intervention for enhancing cognition in people with

MCI [35]. Interestingly, they found that for individuals with
dementia, the only clinically meaningful effect sizes were
found in studies that utilised immersive technology such
as VR or the Nintendo Wii [35]. These ﬁndings strongly
support
the idea that greater transference of cognitive
performance to daily life could be achieved through training
on ecologically valid tasks in VR.

Savulich et al. attempted to address the motivational
deﬁcits in older populations with memory impairments
through a novel memory game on an iPad Game Show
which targeted EM as its cognitive process [8]. The game
was designed to have the same motivational properties
typical of computer games (tutorials, stimulating music,
progression, etc.) and employed DDA with in-game per-
formance as a sole input. They conducted a randomised
controlled trial with 42 patients (aged 45 and over) diag-
nosed with amnestic mild cognitive impairment, splitting
the participants evenly into a training and control group.
Their results showed signiﬁcant EM improvements in the
CT group, and suggested that gamiﬁcation enhanced par-
ticipant motivation.

Gamito et al. investigated the effectiveness of VR for
neuropsychological rehabilitation [36] by developing a VR
application for CT which incorporated attention and mem-
ory tasks resembling daily real-world activities. These tasks
targeted WM, visuo-spatial orientation, selective attention,
recognition memory and calculation. The training linearly
increased in difﬁculty throughout the sessions. This was
employed in a study consisting of twenty stroke patients,
with a mean age of 55 years (SD = 13.5), who were
randomly assigned between an intervention and control
group. The results of their study generally supported the
efﬁcacy of VR-based interventions for CT, with signiﬁcant
beneﬁts to memory and attention functions observed in the
intervention group (with the exception that no signiﬁcant
improvement was seen in visual memory).

Optale et al. conducted a 6-month long randomised
controlled pilot study investigating the efﬁcacy of their
VR training intervention in lessening cognitive decline and
improving memory functions [37]. The VR tasks asked
the user to navigate a simple environment and tested their
capacity to recall the route they have taken and their orienta-
tion, with a gradual, linear, increase in the complexity of the
stimuli. They recruited 36 elderly individuals (median age
80 years) with memory impairment and divided them into
an experimental group and an active control group (which
received music therapy sessions). Their results showed that
participants in the experimental group exhibited improve-
ment in general cognitive functioning and verbal memory,
with the most signiﬁcant effects observed in long-term
memory.

Despite their promising results, none of the reviewed
studies utilised affective feedback as part of their VR
intervention, which is the main focus of this work. There
also exist other VR applications for CT (e.g., [38], [39],
[40]), however, these have not yet reached the point of
carrying out studies with their target population.

D. Emotion Sensing from Facial EMG

Computer-vision based analysis of facial nonverbal be-
haviour (facial actions or facial expressions) is not appro-
priate in a VR context as the user’s face will be mostly
occluded by the head-mounted display (HMD). Cohn and
Ekman in [16] provide a detailed review about early studies
that have used surface EMG to measure facial muscle activ-
ity in relation to emotion and the evidence found in terms
of predictive correlation with self- and observer reported
emotion. Therefore, this work utilises facial electromyo-
gram (EMG), recorded from surface electrodes placed over
regions of the user’s face, to measure signals related to the
affective facial behaviour of the participants, using a novel
device, Faceteq [41].

For extracting features from facial EMG, Jerritta et al.
investigated the application of higher order statistics (HOS)
to derive a set of facial EMG features for classifying
Ekman’s six basic emotional states [42]. They used audio-
visual (video clips) stimuli to induce emotional responses
in participants, and employed a kNN classiﬁer with PCA as
a dimensionality reduction technique. Their results showed
that the use of PCA prior to classiﬁcation improved the
classiﬁer’s accuracy, achieving an average classiﬁcation rate
of 69.5% across the six basic emotions (anger, disgust,
fear, happiness, sadness and surprise). Perusquia-Hernandez
et al. [43] investigated the recognition of spontaneous vs.
posed smiles, using spatial and temporal patterns of facial
EMG. Due to the unbalanced nature of the collected data,
they undersampled the majority class to match the minority
class samples (as in [44]). The best classiﬁcation results
for this 2-class problem, obtained using spatial-temporal
features with a Gaussian kernel SVM, range from 85.23%
to 96.43% (across participants), using a 70/30 training/val-
idation data split. Soon et al. developed an application for
speech recognition based on facial EMG. Three participants
were asked to say a series of numeric (spoken in Malay
and English) and command words (spoken in English).
Temporal features were extracted from a DWT-Haar ap-
proximation of the input signal. Four different classiﬁers
were evaluated: Random Forest, Linear Discriminant Anal-
ysis, Naive Bayes and Multilayer Perceptron. Classiﬁcation
results were obtained through a cross-validation scheme
with a 66/34 training/validation data split. Random Forest
provided the best overall performance with temporal fea-
tures achieving 64.7%, 49%, and 41.8% in Malay, English,
and command words respectively.

III. STUDY DESIGN

A. Game Design

Two separate virtual environments were developed, a
virtual supermarket and a virtual multi-room museum (see
Fig. 1 and Fig. 2). These locales provided the setting for
the WM and EM tasks respectively, and were selected to
promote the ecological validity of the intervention, i.e., both
environments are likely to be familiar to the older target
population and, in the case of the supermarket, to reﬂect

a daily activity. The underlying hypothesis was that by
setting the tasks in highly immersive virtual re-creations of
real-world environments and having users perform practical
tasks (e.g. collecting products from a shopping list and in-
teracting with displays in a museum) the acquired cognitive
skills would better generalise to daily life.

In the initial phase of the work, a ﬁxed difﬁculty frame-
work was implemented for both the WM and EM tasks
consisting of three difﬁculty levels (easy, medium and hard).
This was designed with the purpose of eliciting a range of
emotional responses from study participants and, thus, gen-
erating a balanced dataset. These difﬁculty levels differed
in the cognitive load required from the participant (e.g.
shorter/longer shopping lists in the supermarket, less/more
display locations to remember in the museum).

Both tasks employ the same annotation and EMG logging
scheme. EMG data is recorded from when the task starts.
After every 45 seconds of gameplay (a time period arrived
at through pilot tests) the recording is paused and written
out to a log ﬁle (created for that segment). When this
occurs,
the game environment fades to black and the
affective slider (see Fig. ) (implemented in VR to mitigate
gameplay disruption), is displayed to the player. Players
interact with the slider using a VR laser pointer and,
when they are happy with their selection (which should
best describe the average affect experienced by the player
during the preceding 45 seconds of gameplay), press a
conﬁrmation button to append the arousal/valence values
to the associated EMG log. Gameplay and EMG recording
then resumes. This process repeats until the timer runs out.
Putze et al. performed a systematic investigation into the
effects of interrupting the VR experience through a ques-
tionnaire either inside or outside of VR [45]. Their results
showed that administering questionnaires in VR reduces
the Break in Presence without affecting the self-reported
player experience. This motivated our decision to collect
the labels during gameplay. The use of the affective slider
was motivated by its facility for expeditious annotation and
its interpretability. We therefore decided that obtaining these
labels inside VR will better represent the range of emotions
experienced at different points during gameplay (while the
experience is still fresh). Score tracking and a leaderboard
(staples of gamiﬁcation) were also included for both tasks.
A heads-up-display (HUD) was included that enabled
the player to track their current score, time left and other
task speciﬁc information. Together, the inclusion of these
elements was intended to draw the player’s focus away
from the novelty of VR (thereby mitigating the expected
positive bias in the dataset) onto their task performance.
To further associate player performance and emotional
response, audio-visual stimuli were added in response to
correct (bell ringing sound and confetti explosion) and
incorrect (buzzing sound and red X) answers.

1) Working Memory Task: The goal of the WM task
is to ﬁnd a (randomly generated) array of products in a
virtual supermarket (see Fig. 1), placing each product in a
shopping basket. The products are speciﬁed to the player

Fig. 1: The custom virtual supermarket environment, in
which WM tasks were carried out, and player interaction
with this environment.

Fig. 2: The custom, multi-room, virtual museum environ-
ment, in which EM tasks are carried out. More rooms
are unlocked as the difﬁculty level increases. Green arrow
markers indicating which displays are to be remembered
during the encoding phase. Bottom right: visual feedback
for correct answer during the retrieval phase.

at the start of each round through the HUD. Each product
on the shopping list is displayed on the HUD (as an image
and text description) for 1 second, with a 500 ms interval.
Players are challenged to remember remaining items on the
shopping list (stored in WM), while they actively search
for each product. The number of products to be collected
is determined by the difﬁculty level. The medium difﬁculty
tasks users with ﬁnding 7 products, this is intended to be the
most engaging and balanced difﬁculty for most users (based
on Miller’s magic number seven, plus or minus two [46]).
The easy and hard difﬁculties task users with ﬁnding 2 and
12 products respectively. These difﬁculties were designed
to increase the likelihood of inducing negative affect in
users, i.e., calm-negative on easy (bored due to insufﬁcient
challenge) and energetic-negative on hard (frustrated due to
excessive challenge). The speciﬁc number of products for
each difﬁculty level was determined through pilot testing
and feedback. For each correct item collected, 5 points are
added to the player’s score. Collecting an item that was
not on the shopping list reduces the player’s score by 4.
Therefore, while the player is incentivised to carry out the
task quickly, the priority is to ensure that no mistakes are
made. The random generation of shopping lists promotes
the task’s replayability, maintaining the emphasis on short-
term WM (rather than remembering the shopping lists from
previous attempts) on repeated playthroughs.

2) Episodic Memory Task: The EM task takes place in a
multi-room virtual museum environment (see Fig. 2). The

positive (as in [44]). The hypothesis here is based on the
concept of the difﬁculty curve, the idea that, for an optimal
experience, a game’s difﬁculty should progress in a manner
consistent with real-world skill acquisition (easy challenges
during the cognitive stage, moderate challenges during the
associative stage, and more difﬁcult challenges during the
autonomous stage) [48]. By delivering challenges to the
player in a reversed order, it is expected that they will
experience negative affect more frequently (e.g. frustration
early on, and boredom towards the end).

Participants were given a two minute break between
gameplay sessions, allowing them to return to a neutral
affective state. During these breaks, participants were asked
to give an affective label that best summed up that session
(using Russell’s circumplex model [49]). A short informal
interview was conducted, after the EMG data collection and
all other results from the study were recorded, with the
following questions.

• Which of the two environments did you prefer spend-

ing time in?

• Which of the two tasks did you ﬁnd more engaging?
• Did you experience any discomfort during the session
and, if you have prior experience of VR, was the
addition of the Faceteq sensor off-putting in any way?
• To what extent, if any, did the annotation scheme affect

your gameplay experience?

C. Findings

The majority of participants (10/12) expressed a prefer-
ence for the museum environment over the supermarket,
with many responses indicating that the supermarket felt
more mundane as it is an environment they are overly
familiar with in the real world. This may point to a trade-off
between ecological validity and engagement in the choice
of cognitive training environment. Responses were evenly
split when it came to task preference, with many stating
they preferred the EM task as it had more gameplay variety,
while others appreciated the more naturalistic interactions
in the WM task. The response to the Faceteq sensor
was positive. None of the participants indicated that they
experienced any motion sickness or that the sensor was off-
putting. Of the nine participants with prior VR experience,
ﬁve particpants responded that they weren’t aware of the
sensor once they started playing, two participants responded
that they there were aware of the sensor but it had no
signiﬁcant impact on their engagement, and two participants
(self-identiﬁed regular VR users) stated that
the ADC
box attached to the back of the HMD (see Fig. III-B)
served as a counterweight to the front-heavy HTC Vive.
Most participants (7/12) stated that the in-game annotation
scheme was mildly disruptive to the gameplay experience,
while others either found it did not affect their experience
(3/12) or found it very disruptive (2/12).

IV. SYSTEM EVALUATION

This evaluation aims to investigate whether and how
the developed CT environment and the overall system

Fig. 3: Prototype Faceteq sensing HMD foam insert and
how it is placed in the HTC Vive.

core task is divided into two consecutive phases: encoding
(storage of information, such that it can be distinguished
from other distinct pieces of information) and retrieval
(recognition of previously stored information) [47]. In the
encoding phase, players are asked to search for one or more
displays at randomly generated locations in the museum.
Players interact with marked displays in this phase using a
laser pointer. On doing so, the age of the display is shown
to the player. This interaction can take place at a distance,
allowing a greater degree of spatial context to be encoded.
After all the marked displays have been interacted with, the
game transitions to the retrieval phase removing the marked
displays from the museum, and teleporting the player back
to the museum entrance.

In the retrieval phase, players are tasked with placing
a subset of the displays they interacted with during the
encoding phase back in their original positions. The player
uses the laser pointer to indicate where in the environment
(from a selection of highlighted zones) they think it was
located. On completion of the retrieval phase, a short bonus
phase is initiated. Players are shown three displays they
have interacted with and are asked which of them is the
oldest/youngest. This textual (age) recall is not randomised,
and players who can efﬁciently store the information in their
LTM should perform better over repeated sessions.

B. Data Acquisition

After the study procedure and protocol was approved by
Cambridge’s Department of Computer Science and Tech-
nology Ethics Committee, 18 participants (5 female and 13
male, ranging in age from 20 to 37) volunteered to engage
in the EMG data acquisition study, by wearing the HTC
Vive VR headset with Faceteq sensing HMD foam insert
(see Fig. ). 6 of these participants engaged in a preliminary
pilot study, while the data collected from the remaining 12
formed the ﬁnal annotated facial EMG dataset.

The participants were ﬁrst acquainted with the research
goals of the study through an information sheet and ver-
bal
introduction. They were introduced to the meaning
of arousal and valence, and shown the affective slider
annotation scheme (see Fig. III-A). The EMG recording
sessions lasted for 3 minutes and 45 seconds, of which
there were six in total (one per difﬁculty level, for both
the WM and EM tasks). Half of the participants played
through the difﬁculty levels in reverse order (hard-to-easy)
to reduce the likelihood of the collected data being skewed

(with its modules for sensing, feature extraction and affect
recognition) work together.

A. EMG Feature Extraction

1) Pre-processing: Sousa and Tavares noted, in their
review of EMG normalisation methods [50], that the volt-
age potential of surface EMG depends on several factors,
varying between individuals and also over time within an
individual. Baseline normalisation (removal) is a viable
strategy to respond to these issues, having seen use in
numerous studies on a variety of physiological signals (e.g.,
[51]). The user’s baseline was read during the ﬁrst 45
seconds of gameplay as at this point the novelty of VR
had diminished to some extent, and the activities during
the early-game are typically less arousing (e.g. reading
shopping list, and looking at displays).

2) Feature Extraction: After baseline normalisation, the
input signal was processed using DWT [52]. The choice
of mother wavelet for signal approximation was informed
by the work of Phinyomark et al. [53]. They found that,
for the purpose of denoising, coif5, Haar (db1), bior1.1
and rbio1.1 are the most suitable. A preliminary evaluation
with our dataset showed that each of these wavelets resulted
in very similar classiﬁcation improvements (around +5%
to +7% accuracy depending on the classiﬁer). Therefore,
going forward, the presented results are based on the DWT-
Haar approximation of the EMG signal due to its efﬁcient
computation. A signiﬁcant number of studies, in the domain
of facial EMG classiﬁcation, have shown temporal features
to be the most informative [43], [54]–[56]. Based on these
ﬁndings, the time and time-frequency domain features were
extracted from the DWT approximation of the signal. These
are shown in Fig. 4 (see [57] for mathematical deﬁnitions).
Extracting this many features, from eight EMG channels,
results in a high dimensional (8 * 14 = 112) dataset.

3) Feature Selection: Due to the dimensionality of the
dataset, it was considered pertinent to include a feature
selection step prior to classiﬁcation. The strategy employed
here was inspired by the work of Clerico et al. [58],
who utilised the minimal-redundancy-maximal-relevance
criterion (mRMR) [59] to select the best features in an
EMG affective gaming context. mRMR attempts to ﬁnd
optimal features, based on mutual
through
forward selection. The greatest classiﬁcation improvement
was achieved by selecting the best 30 features, identiﬁed
by mRMR (around +3% to +5% accuracy depending on the
classiﬁer). These features were distributed among different
muscle groups with the top 30 ranking made up of 10
features from users’ eyes, 9 from their mouth, 7 from their
eyebrows, and 3 from their corrugator supercilii.

information,

4) Findings: SSC was the most common feature in
the ranking, being extracted from all muscle groups bar
the corrugator supercilii. SSC, extracted from the right
eye sensor, was also computed to be the second most
informative feature in the ranking. This was accompanied
by MMAV1 extracted from the right mouth sensor (1st) and
ZC extracted from the left mouth sensor (3rd), in a top three

Fig. 4: List of time and time-frequency domain features
extracted from the DWT approximation of the signal.

Fig. 5: Classiﬁcation accuracies for kNN, SVM and LDA
for positive valence vs. negative valence and high arousal
vs.
low arousal. Results are obtained using leave-one-
subject-out cross-validation strategy.

that scored signiﬁcantly higher (by a factor of at least 3)
than the remaining 27 features. Interestingly, extracted RMS
features were considered relatively uninformative despite
it being regularly cited as one in facial EMG emotion
recognition research (e.g. [54], [55]). Though deviations
in expected results, such as this, may be attributed to the
fact that physical expressions of affect in peoples’ faces are
likely to be impacted by the VR headset.

B. Affect Classiﬁcation

the original

1) Classiﬁcation: First

(-1 to +1 con-
tinuous) valence/arousal
labels were truncated into one
of four emotion labels: energetic-positive (high valence,
high arousal); calm-positive (high valence, low arousal);
energetic-negative (low valence, high arousal); calm-
negative (low valence,
low arousal). This allows emo-
tion recognition to be framed as a 4-class classiﬁcation
problem. Three classiﬁers, which have been utilised to
varying degrees of success in existing facial EMG literature
[43], [54]–[56], SVMs (with Gaussian kernel); kNN (with
various values for k); and LDA were evaluated using the
(subject-independent) leave-one-subject-out (LOSO) cross-
validation strategy. The best classiﬁcation results for each
classiﬁer can be seen in Fig. 5. The kNN (k = 4) offered
the best arousal classiﬁcation rate (76.2%), and the best

classiﬁcation rate on the combined valence/arousal 4-class
classiﬁcation problem (68.8%). LDA yielded the best va-
lence classiﬁcation rate (64.1%), but fell behind kNN on the
4-class classiﬁcation problem (65.9%). The Gaussian SVM
generally underperformed, though by investigating different
kernels and further tuning hyperparameters, this could be
improved in future work.

2) Findings: The most noticeable discrepancy between
the labels acquired in-game and those acquired post-game,
was a consistently lower annotated value for arousal in
the post-game interview. This manifested as a signiﬁcantly
lower classiﬁcation accuracy for arousal when using the
post-game labels as the four classes (around -15% to -19%
depending on the classiﬁer), while valence classiﬁcation
remained comparable. This suggests that the primary beneﬁt
of acquiring affective labels in-game is a more reliable
estimate of the intensity of emotions. Placing participants
in a reversed difﬁculty group had the desired effect of
inducing negative affect more frequently (resulting in a
more balanced dataset), with that group accounting for
approximately 61% of energetic-negative and 67% of calm-
negative annotations. A notable difference between how
our classiﬁcation results were arrived at compared to those
discussed in similar works (section 3.3), is that these results
were computed using the (subject-independent) leave-one-
subject-out (LOSO) cross-validation strategy.

V. INTERVENTION EVALUATION

The goal of this evaluation was to gather qualitative feed-
back from the target population (older adults) to examine
the potential beneﬁts of utilising affective adaptation for CT
and gather insights for deﬁning future research steps.

A. Affective Feedback Loop Integration

The system integrated here relies on both affect sensing
and player performance as a data point, due to its
exhibited value in existing DDA solutions and to offset
the (classiﬁcation) inaccuracies in the model (i.e. to avoid
ﬁxing what is not broken [61]). The number of difﬁculty
levels in this new adaptive version of the game was
increased from three (easy-medium-hard) to ten (10-point
scale). This allows for more subtle transitions in difﬁculty
to avoid the player becoming overly conscious of the
adaptation (and potentially feeling ‘cheated’ by it [61]).
Every 45 seconds (in place of the annotation interface
from the previous study) the player’s affect is classiﬁed
in real-time based on incoming facial EMG signals. The
following DDA rules, encompassing both player affect and
performance, govern how the difﬁculty is adapted:

[Calm-Negative + :Perfect Score]: Increment difﬁculty by
2;
[Calm-Negative + Imperfect Score] or [Positive Valence +
Perfect Score]: Increment difﬁculty by 1;
[Positive Valence + Imperfect Score]: No change in
difﬁculty;
[Negative Score] or

[Energetic-Negative + Imperfect

Score]: Decrement difﬁculty by 1;
[Energetic-Negative + Negative
difﬁculty by 2.

Score]: Decrement

This rule set was arrived at following a short testing
period with pilot participants. For instance, in the [Calm-
Negative + Perfect Score] case, it is hypothesised that the
player is not enjoying the game as valence is negative,
and is likely bored as they are in a non-energetic state,
and the score is perfect, so the level is increased by two.
Instead, [[Positive Valence + Perfect Score] leads to a
smaller increment of one in order to gradually maximise
the cognitive challenge provided by the game, while min-
imising the risk of disrupting the players engagement (as
indicated by the positive valence score). In the best-case
execution, the adaptation is intended to lead players to a
ﬂow state [62], where they are faced with tasks that they
have a chance of completing through application of their
skills. In addition to being a signiﬁer of high engagement,
being in a state of ﬂow has been shown to improve cognitive
performance [29].

B. Evaluation Study

The protocol for the evaluation study was largely similar
to the previous study, with a few notable exceptions. 6
participants (4 female and 2 male, ranging in age from 60 to
100), with no history of cognitive impairment, volunteered
to engage in this evaluation study. The recruitment of
this older control group was facilitated by the researchers
from The University of Cambridge’s Department of Neuro-
science. None of the participants played video games with
any degree of regularity and only one had prior experience
of VR. Participants started by completing a battery of
standardised cognitive tests [63]–[69] (administered by the
Clinical Neuroscience researchers). This enabled accurate
characterisation of the sample and the investigation of
correlations between the standardised tests and the new VR
paradigm. The time taken to administer these tests averaged
at about 1 hour.

Participants were given an explanation of the task goals
and time to practice in the VR environment prior to starting
the session proper. They played both an adaptive and non-
adaptive (linearly increasing difﬁculty) version of the game
(without being told which version is which), in two, ﬁfteen
minute, gameplay sessions (7 minutes and 30 seconds for
both WM and EM tasks). To mitigate any order effects
bias in the evaluation of the adaptive and non-adaptive
versions, half of the participants played the adaptive version
ﬁrst, while the other half played the non-adaptive version
ﬁrst. Participants’ subjective experience (i.e.
immersion,
engagement, and ﬂow) with the VR training intervention
was evaluated using the in-game and post-game components
of the game experience questionnaire (GEQ) [60].

Each session was concluded with an informal interview
that took place after all other results from the study were
recorded. The contents of this interview was the same as in
the ﬁrst study, with the exception of an additional question

PID
Game Version
Competence
Sensory and Imaginative Immersion
Flow
Tension
Challenge
Negative Affect
Positive Affect

P3

P6

P5

P2

P1

P4
Ad NAd Ad NAd Ad NAd Ad NAd Ad NAd Ad NAd Ad NAd
2.58 1.67
2
3.33 3.17
4
3.17 2.83
3.5
0.83 1.33
2
2.67 3.58
4
0.33 0.75
1.5
2.67 2.42
2.5

1
3
3.5
3.5
4
3
1.5

2.5
3
3
0
3
0
3

2.5
4
3.5
0.5
3
0.5
3.5

2
2
2
2
1
0.5
1.5

3
4
4
0.5
2.5
0
3.5

3
4
3.5
0.5
2
0
3

2
4
2
1.5
3.5
0
2.5

0.5
2
2
2
4
1
2

3
3
3
0
3.5
0
2.5

2
3
3
0.5
4
0
2

2
3
3
0
3
0
3

Mean

TABLE I: In-game GEQ [60] module responses for each participant (P) represented with participant ID (PID), for Adaptive
(Ad) and Non-Adaptive (NAd) versions of the game. Values are on a scale of 0 (not at all) to 4 (extremely), and were
calculated by averaging across their respective components.

PID
Positive
Negative
Tired
R2R

P1
2.4
0.33
1
1

P2
2.6
0
0.5
1

P3
1.4
0
0
0.33

P4
1.6
0
2.5
0.33

P5
2
0
0
0.33

P6 Mean
2.13
2.8
0.11
0.33
0.67
0
0.78
1.66

TABLE II: Post-game GEQ module responses for each
participant (P) on a scale of 0 (not at all) to 4 (extremely),
calculated by averaging across their respective components.
R2R refers to Return to Reality.

on the impact of the in-game affective annotation during the
ﬁrst study. Participation in the study lasted for about 2 hours
and 15 minutes on average (including breaks). Immediately
after playing each version (adaptive/non-adaptive) of the
game, participants reported on their feelings of compe-
tence, sensory and imaginative immersion, ﬂow, tension,
challenge, negative affect, and positive affect by completing
the in-game module of the GEQ. Each of these categories
is represented by a series of sub-components in the ques-
tionnaire, a numeric value is then computed for each by
averaging across their sub-component values. The accu-
mulated responses can be found in Table I. Finally, when
both gameplay sessions were complete,
the participants
ﬁlled out the post-game module of the GEQ [60]. This
gave participants the opportunity to think and reﬂect on
the experience as whole. The accumulated results, similarly
calculated by averaging across their sub-components in the
questionnaire, are provided in Table II.

C. Findings

Looking at Table I, while the response to both versions
of the game can generally be described as positive, there are
a few noteworthy differences. The two standout differences
are the increased feeling of competence and the decreased
feeling of challenge while playing the adaptive version
of the game. The noteworthy increase in competence is
particularly encouraging as it relates to one of the key
deﬁciencies identiﬁed with existing cognitive training in-
terventions, the drop-off in user engagement [10]. In their
research of intrinsic motivation, Deci and Ryan argue that
structures that enable feelings of competence during action
can enhance intrinsic motivation for that action [70]. This
increased feeling of competence, brought about through
affective adaptation, highlights the potential of adaptive
techniques in motivating users to engage with cognitive

training interventions. However, speciﬁc aspects related to
intrinsic motivation were not included in the questionnaires
employed in our studies. For more insightful conclusions on
intrinsic motivation, relevant aspects should be investigated
explicitly in future studies.

While the drop in challenge is not unequivocally positive,
the decrease to a more neutral value in the adaptive version,
along with the slight increase in ﬂow (which describes a
state of high engagement), suggests that participants are
being met with more appropriate challenges that they can
overcome using their skills [62] (potentially explaining the
slight increase in positive affect, and decrease in negative
affect while playing the adaptive version). The largely
positive responses provided for the post-game module of
the GEQ as seen in Table II, in conjunction with those
recorded by the in-game module, are promising indicators
that gamiﬁcation and VR can play a role in increasing
engagement with cognitive interventions in older adults.

Another area of interest for this evaluation was to what
extent the WM and EM tasks, implemented in VR, engaged
the intended cognitive abilities of the participants. This was
examined by looking for correlations between how partici-
pants performed (relative to each other) in the standardised
tests and the VR tasks. Positive correlations, calculated
using Spearman’s rank-order correlation (rho), were found
between the performance rankings of participants in the
VR paradigm and closely related standardized tests. Most
notably, high positive correlations were found between
the Trail Making Test [67], which examines executive
functioning (a superset of WM), and the WM task in VR
(rho=+0.60), and between the 4 Mountains test (a short SM
test) and the EM task in VR (rho=+0.74).

In the post-session interview, all 6 participants stated
their preference for the museum environment (ﬁnding the
supermarket more mundane). The overall consensus was,
however, that the environments they would prefer would
match those in the real-world. 5 participants preferred the
EM task, stating that while they found it
to be more
complex, the greater variety it offered was a motivating
factor for them to return to it and improve. This may point
to task variety being an important factor in maintaining
user engagement in cognitive training. All 6 participants
responded that they felt no motion sickness during the

study. 4 out of the 6 participants indicated that they felt no
facial discomfort, while 2 participants, who wore glasses
throughout the study, felt a bit of pressure on their face
towards the end. This was likely a result of the slightly
thicker face cushion used with the Faceteq prototype.

VI. SUMMARY AND CONCLUSION
This work investigated the development of an affect-
aware VR game for cognitive training using facial EMG
signals for affect classiﬁcation. Classiﬁcation rates of 64.1%
and 76.2%, for valence and arousal respectively, were
achieved through a combination of DWT-Haar ﬁltering,
temporal feature extraction, feature selection, and kNN
classiﬁcation. The promise of DDA in the development of
more engaging cognitive training was substantiated through
a small-scale user study with older adults.

The qualitative feedback garnered over the course of
the study pointed to a notable increase in feelings of
competency and participants being more appropriately
feedback relating to both the
challenged. Participant
adaptive and non-adaptive versions of
the game was
largely positive. This response lends credence to the notion
that gamiﬁcation and VR are viable tools for improving
engagement in cognitive training with older adults. The
ﬁndings here should be qualiﬁed by reiterating an inherent
limitation of the study. Six participants is a small user
group for an evaluation study and should be expanded in
future research to fully determine the veracity of these
ﬁndings.

ACKNOWLEDGEMENTS. This work has been par-
tially supported by the EPSRC (grant ref. EP/R030782/1).

REFERENCES

[1] A. L. Moore, D. M. Carpenter, T. M. Miller, and C. Ledbetter,
“Clinician-delivered cognitive training for children with attention
problems: effects on cognition and behavior from the thinkrx ran-
domized controlled trial,” Neuropsychiatric disease and treatment,
vol. 14, pp. 1671–1683, 2018.

[2] Y. Stern, “Cognitive reserve in ageing and alzheimer’s disease,”

Lancet Neurol., vol. 11, no. 11, pp. 1006–1012, 2012.

[3] G. N.J., V. R.W.M., D. N. M., K. S., M. E., M. G., and R. A.W.S.,
“Computerised cognitive training for preventing dementia in people
with mild cognitive impairment (review),” Cochrane Database of
Systematic Reviews, Issue 3. Art. No.: CD012279., 2019.

[4] T. Wykes, V. Huddy, C. Cellard, S. McGurk, and P. Czobor, “A meta-
analysis of cognitive remediation for schizophrenia: methodology
and effect sizes,” Am. J. Psychiatry, vol. 168, pp. 472–485, 2011.

[5] L. Lam, W. Chan, A. F. T. Leung, and E. Leung, “Would older
adults with mild cognitive impairment adhere to and beneﬁt from
a structured lifestyle activity intervention to enhance cognition?: A
cluster randomized controlled trial,” PLoS One, vol. 10(3), 2015.
[6] N. Coley, T. Ngandu, J. Lehtisalo, H. Soininen, B. Vellas, and
E. Richard, “Adherence to multidomain interventions for dementia
prevention: data from the ﬁnger and mapt trials,” Alzheimers and
Dementia, vol. 15 (6), pp. 729–741, 2019.

[7] D. Arbiv and N. Meiran, “Performance on the antisaccade task
predicts dropout from cognitive training,” Intelligence, vol. 49, pp.
25–31, 2015.

[8] G. Savulich, T. Piercy, J. S. C. Fox, J. Rowe, J. OBrien, and
B. Sahakian, “Cognitive training using a novel memory game on an
ipad in patients with amnestic mild cognitive impairment (amci),”
International Journal of Neuropsychopharmacology, vol. 20 (8), pp.
624–633, 2017.

[9] V. Manera, E. Chapoulie, J. Bourgeois, R. Guerchouche, R. David,
J. Ondrej, G. Drettakis, and P. Robert, “A feasibility study with
image-based rendered virtual reality in patients with mild cognitive
impairment and dementia,” PLoS One, vol. 11 (3), pp. 118–129,
2016.

[10] D. J. Simons, W. R. Boot, N. Charness, S. E. Gathercole, C. F.
Chabris, D. Z. Hambrick, and E. A. Stine-Morrow, “Do brain-
training programs work?” Psychol Sci Public Interest., vol. 17, no. 3,
pp. 103–186, 2016.

[11] R. J. Pagulayan, K. Keeker, D. Wixon, R. L. Romero, and T. Fuller,
“User-centered design in games,” in The human-computer interaction
handbook, 2002, vol. 5, pp. 883–906.

[12] J. Mishra, J. A. Anguera, and A. Gazzaley, “Video games for neuro-

cognitive optimization,” Neuron., vol. 90 (2), pp. 214–218, 2016.

[13] C. Liu, P. Agrawal, N. Sarkar, and S. Chen, “Dynamic difﬁculty
adjustment in computer games through real-time anxiety-based af-
fective feedback,” Int. J. Hum. Comput. Interaction, vol. 25, pp. 506–
529, 2009.

[14] G. A. D., T. L., and G. H., “Measuring affective, physiological
and behavioural differences in solo, competitive and collaborative
games,” in Proc. of Intelligent Technologies for Interactive Entertain-
ment 2016 (INTETAIN), Lecture Notes of the Institute for Computer
Sciences, Social Informatics and Telecommunications Engineering,
P. R., M. JJ., V. R., and D. M., Eds. Cham: Springer, 2016, vol.
178, pp. 184–193.

[15] S. Baron-Cohen, A. Riviere, M. Fukushima, D. French, J. Hadwin,
P. Cross, C. Bryant, and M. Sotillo, “Reading the mind in the face:
A cross-cultural and developmental study,” Visual Cognition, vol. 3,
p. 3959, 1996.

[16] J. F. Cohn and P. Ekman, “Measuring facial action by manual coding,
facial emg, and automatic facial image analysis,” in Handbook of
Methods in Nonverbal Behavior Research, J. A. Harrigan, R. Rosen-
thal, and K. Scherer, Eds. Oxford, UK: Oxford Univ. Press, 2005,
pp. 9 – 64.

[17] E. Sariyanidi, H. Gunes, and A. Cavallaro, “Automatic Analysis of
Facial Affect: A Survey of Registration, Representation, and Recog-
nition,” IEEE Trans. Pattern Analysis and Machine Intelligence, vol.
37 (6), pp. 1113–1133, June 2015.

[18] B. Martinez, M. F. Valstar, B. Jiang, and M. Pantic, “Automatic
analysis of facial actions: A survey,” IEEE Transactions on Affective
Computing, vol. 10, no. 3, pp. 325–347, 2019.

[19] D. Hebb, The Organization of Behavior.

John Wiley and Sons,

New York, 1949.

[20] L. Squire, “Memory systems of the brain: a brief history and current
perspective.” Neurobiol. Learn. Mem, vol. 82, p. 171177, 2004.
[21] E. Tulving, Elements of episodic memory. Oxford University Press,

1983.

[22] A. Baddeley, S. Bressi, S. Sala, R. Logie, and H. Spinnler, “The
decline of working memory in alzheimers disease: a longitudinal
study,” Brain, vol. 114, pp. 2521–2542, 1991.

[23] M. Daneman and P. Carpenter, “Individual differences in working
memory and reading,” Journal of Verbal Learning & Verbal Behav-
ior, vol. 19, no. 4, pp. 450–466, 1980.

[24] R. Engle, S. Tuholski, J. Laughlin, and A. Conway, “Working
memory, short-term memory, and general ﬂuid intelligence: a latent-
variable approach,” Journal of Experimental Psychology: General,
vol. 128, no. 3, pp. 309–331, 1999.

[25] L. Cheke and N. Clayton, “Do different tests of episodic memory
produce consistent results in human adults?” Learning & Memory,
vol. 20, no. 9, pp. 491–498, 2013.

[26] N. Burgess, E. Maguire, and J. OKeefe, “The human hippocampus
and spatial and episodic memory.” Neuron, vol. 35, pp. 625–641,
2002.

[27] K. Bennion, “Oversimpliﬁcation in the study of emotional memory,”
J. Int. Neuropsychological Society, vol. 19, no. 9, pp. 953–961, 2013.
[28] Y. Yeh, “How stress inﬂuences creativity in game-based situations:
Analysis of stress hormones, negative emotions, and working mem-
ory.” Computers & Education, vol. 81, pp. 143–153, 2015.

[29] D. Gabana, L. Tokarchuk, E. Hannon, and H. Gunes, “Effects of
valence and arousal on working memory performance in virtual
reality gaming,” in International Conference on Affective Computing
and Intelligent Interaction, 2017, pp. 36–41.

[30] N. Yee, “Motivations for play in online games,” CyberPsychology &

Behavior, vol. 9, no. 6, pp. 772–775, 2007.

[31] D. Bersak, “Biofeedback using an immersive competitive environ-
ment,” in Online Proceedings of the Designing Ubiquitous Comput-
ing Games Workshop, Ubicomp, 2001.
[32] C. Reynolds and R. Picard, “Affquake,” 2004.
[33] S. Bouchard, F. Bernier, . Boivin, B. Morin, and G. Robillard, “Using
biofeedback while immersed in a stressful videogame increases the
effectiveness of stress management skills in soldiers.” PloS one,
2012.

[34] G. Riva, “Affective interactions using virtual reality: the link between
presence and emotions,” CyberPsychology & Behavior, vol. 10, pp.
45–56, 2007.

[35] N. Hill, L. Mowszowski, S. Naismith, V. Chadwick, M. Valenzuela,
and A. Lampit, “Computerized cognitive training in older adults with
mild cognitive impairment or dementia: a systematic review and
meta-analysis,” Am. J. Psychiatry, vol. 174, no. 94, pp. 329–334,
2017.

[36] P. Gamito, J. Oliveira, C. Coelho, D. Morais, P. Lopes, J. Pacheco,
R. Brito, F. Soares, N. Santos, and A. Barata, “Cognitive training on
stroke patients via virtual reality-based serious games,” Disability
and Rehabilitation, vol. 5, pp. 1–4, 2015.

[37] G. Optale, C. Urgesi, and V. Busato, “Controlling memory im-
pairment in elderly adults using virtual reality memory training: a
randomized controlled pilot study,” Neurorehabilitation and Neural
Repair, vol. 24 (4), pp. 348–357, 2010.

[38] E. Pedroli, S. Serino, M. Stramba-Badiale, and G. Riva, “An inno-
vative virtual reality-based training program for the rehabilitation of
cognitive frail patients,” Pervasive Computing Paradigms for Mental
Health, vol. 207, pp. 62–66, 2018.

[39] G. Doniger, M. Beeri, and A. B.-F. et al., “Virtual reality-based
cognitive-motor training for middle-aged adults at high alzheimers
disease risk: A randomized controlled trial,” Alzheimers and De-
mentia: Translational Research and Clinical Interventions, vol. 4,
pp. 118–129, 2018.

[40] G. Caggianese, A. Chirico, G. D. Pietro, L. Gallo, A. Giordano,
M. Predazzi, and P. Neroni, “Towards a virtual reality cognitive train-
ing system for mild cognitive impairment and alzheimer’s disease
patients,” in Proc. 32nd Int. Conf. Adv. Inf. Netw. Appl. Workshops,
vol. 8, 2018, pp. 663–667.

[41] I. Mavridou, J. T. McGhee, M. Hamedi, M. Fatoorechi, A. Cleal,
E. Ballaguer-Balester, G. Cox, and C. Nduka, “Faceteq interface
demo for emotion expression in vr,” in Proceedings of IEEE Virtual
Reality (VR), 2017, pp. 441–442.

[42] P. Ekman, “An argument for basic emotions,” Cognition and Emo-

tion, vol. 6, pp. 169–200, 1992.

[43] M. Perusqua-Hernndez, M. Hirokawa, and K. Suzuki, “Spontaneous
and posed smile recognition based on spatial and temporal patterns
of facial emg,” in International Conference on Affective Computing
and Intelligent Interaction (ACII), 2017, pp. 537–541.

[44] I. Shumailov and H. Gunes, “Computational analysis of valence and
arousal in virtual reality gaming using lower arm electromyograms,”
in Int. Conf. on Affective Computing and Intelligent Interaction
(ACII), 2017.

[45] S. Putze, D. Alexandrovsky, F. Putze, S. H¨offner, J. D. Smeddinck,
and R. Malaka, “Breaking the experience: Effects of questionnaires
in vr user studies,” in Proceedings of the 2020 CHI Conference on
Human Factors in Computing Systems, ser. CHI 20. New York,
NY, USA: Association for Computing Machinery, 2020, p. 115.
[Online]. Available: https://doi.org/10.1145/3313831.3376144
[46] G. Miller, “The magical number seven, plus or minus two: Some
limits on our capacity for processing information,” Psychological
Review, vol. 63, no. 2, p. 8197, 1956.

[47] W. Wang, B. Subagdja, A.-H. Tan, and J. Starzyk, “Neural modeling
of episodic memory: Encoding retrieval and forgetting,” IEEE Trans.
Neural Netw. Learn. Syst, vol. 23, no. 10, pp. 1574–1586, 2012.

[48] B. Bostan and S. t, “Game challenges and difﬁculty levels: lessons
learned from rpgs,” in International Simulation and Gaming Associ-
ation Conference, 2009.

[49] J. Russell, “A circumplex model of affect.” Journal of Personality

and Social Psychology, vol. 39, pp. 1161–1178, 1980.

[50] A. Sousa and J. Tavares, “Surface electromyographic amplitude
normalization methods: A review.” in Electromyography: New De-
velopments, Procedures and Applications, 2012, pp. 85–102.
[51] M. Zivanovic and M. Gonzlez-Izal, “Simultaneous powerline inter-
ference and baseline wander removal from ecg and emg signals by
sinusoidal modeling,” Medical Engineering and Physics, vol. 35,
no. 10, pp. 1431–1441, 2013.

[52] X. Zhang, Y. Wang, and R. P. Han, “Wavelet transform theory and its
application in emg signal processing,” in Proc. of IEEE International
Conference on Fuzzy Systems and Knowledge Discovery, 2010,
vol. 5, no. 8, pp. 2234–2238.

[53] A. Phinyomark, C. Limsakul, and P. Phukpattaranont, “Optimal
wavelet functions in wavelet denoising for multifunction myoelectric
control,” ECTI Transactions on Electrical Eng., Electronics, and
Communications, vol. 8, no. 1, pp. 43–52, 2010.

[54] S. Jerritta, M. Murugappan, K. Wan, and S. Yaacob, “Emotion
recognition from facial emg signals using higher order statistics and
principal component analysis,” Journal of the Chinese Institute of
Engineers, vol. 37, no. 3, pp. 385–394, 2014.

[55] M. Hamedi, S. Salleh, C. Ting, M. Astaraki, and A. Noor, “Robust
facial expression recognition for muci: A comprehensive neuromus-
cular signal analysis,” IEEE Transactions on Affective Computing,
vol. 9, no. 1, pp. 102–115, 2018.

[56] M. Soon, M. Anuar, M. Abidin, A. Azaman, and N. Noor, “Speech
recognition using facial semg,” in IEEE International Conference on
Signal and Image Processing Applications (ICSIPA), Kuching, 2017,
pp. 1–5.

[57] D. Tkach, H. Huang, and T. Kuiken, “Study of stability of time-
domain features for electromyographic pattern recognition,” Journal
of Neuroengineering and Rehabilitation, vol. 7, no. 1, pp. 1–13,
2010.

[58] A. e. a. Clerico, “Biometrics and classiﬁer fusion to predict the
fun-factor in video gaming,” in IEEE Conference on Computational
Intelligence and Games (CIG), Santorini, 2016, pp. 1–8.

[59] H. Peng, F. Long, and C. Ding, “Feature selection based on mutual
information criteria of max-dependency, max-relevance, and min-
redundancy,” IEEE Transactions on Pattern Analysis and MAchine
Intelligence, vol. 27, no. 8, pp. 1226–1238, 2005.

[60] W. A. Ijsselsteijn, Y. A. W. de Kort, and K. Poels, “The game
experience questionnaire,” Technische Universiteit Eindhoven, 2007.
[61] R. Hunicke, “The case for dynamic difﬁculty adjustment in games,”
in Proc. of ACM SIGCHI Int. Conf. on Advances in computer
entertainment technology, 2005, pp. 429–433.

[62] M. Csikszentmihalyi, Toward a psychology of optimal experience.

Springer, 2014.

[63] D. Mioshi, K. Dawson, J. Mitchell, R. Arnold, and J. Hodges, “The
addenbrookes cognitive examination revised (ace-r): a brief cognitive
test battery for dementia screening,” Int. J. Geriatric Psychiatry,
vol. 21, no. 11, pp. 1078–1085, 2006.

[64] H. Nelson, The National Adult Reading Test. Windsor, England:

NFER-Nelson, 1982.

[65] P. Osterrieth, “Test of copying a complex ﬁgure; contribution to the
study of perception and memory,” Archives de Psychologie, vol. 30,
pp. 206–356, 1944.

[66] H. D. Crockett, “Cued recall and memory disorders in dementia,”
Journal of Clinical and Experimental Neuropsychology, vol. 11,
no. 2, pp. 278–294, 2008.

[67] T. Tombaugh, “Trail making test a and b: normative data stratiﬁed by
age and education,” Arch. Clin. Neuropsychol, vol. 19, pp. 203–214,
2004.

[68] D. Chan, L. Gallaher, K. Moodley, L. Minati, N. Burgess, and
T. Hartley, “The 4 mountains test: a short test of spatial memory
with high sensitivity for the diagnosis of pre-dementia alzheimers
disease.” J. Vis. Exp, 2016.

[69] D. Wechsler, The measurement and appraisal of adult intelligence.

Baltimore, Md: Williams & Wilkens, 1958.

[70] E. Deci and R. Ryan, Intrinsic Motivation and Self-Determination

in Human Behavior. New York: Plenum, 1985.

