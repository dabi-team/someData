1
2
0
2

v
o
N
3

]

A
N
.
h
t
a
m

[

1
v
3
2
5
2
0
.
1
1
1
2
:
v
i
X
r
a

Adding Safety Rules to Surgeon-Authored VR
Training

Ruiliang Gao1, Sergei Kurenov2, Erik W. Black1,3 and J¨org Peters1,3,4

1 University of Florida, Gainesville, FL32611, USA,
2 Roswell Park Comprehensive Cancer Center, Buﬀalo, NY14263, USA
3 Ph.D., Professor
4 corresponding author: jorg.peters@gmail.com
432 Newell Dr, U of Florida, Gainesville, FL, 32611-6120,USA,
(352)382 1200 (fax 1220)

Abstract. .
Introduction Safety criteria in surgical VR training are typically hard-
coded and informally summarized. The Virtual Reality (VR) content
creation interface, TIPS-author, for the Toolkit for Illustration of Proce-
dures in Surgery (TIPS) allows surgeon-educators (SE s) to create laparo-
scopic VR-training modules with force feedback. TIPS-author initializes
anatomy shape and physical properties selected by the SE accessing a
cloud data base of physics-enabled pieces of anatomy.
Methods A new addition to TIPS-author are safety rules that are set
by the SE and are automatically monitored during simulation. Errors
are recorded as visual snapshots for feedback to the trainee. This paper
reports on the implementation and opportunistic evaluation of the snap-
shot mechanism as a trainee feedback mechanism. TIPS was ﬁeld tested
at two surgical conferences, one before and one after adding the snapshot
feature.
Results While other ratings of TIPS remained unchanged for an overall
Likert scale score of 5.24 out of 7 (7 = very useful), the the rating of ‘The
TIPS interface helps learners understand the force necessary to explore
the anatomy’ improved from 5.04 to 5.35 out of 7 after the snapshot
mechanism was added.
Conclusions The ratings indicate the viability of the TIPS open-source
SE-authored surgical training units. Presenting SE-determined proce-
dural missteps via the snapshot mechanism at the end of the training
increases acceptance.

Keywords: laparoscopy; virtual reality; computer simulation; patient-
speciﬁc modeling; patient safety; education, medical; internship and res-
idency

1

Introduction

Teaching laparoscopic surgery under one-on-one supervision in the operating
room (OR) is costly ranging, already a decade ago, from $50–$135 per minute.1

 
 
 
 
 
 
Less supervision is risky: cauterizing too close to a sensitive organ or nicking a
central vein are diﬃcult to repair and may cause the patient unnecessary suf-
fering. Therefore alternative training methods are ethically and ﬁscally prudent.
Mentored self-study curricula, such as Fundamentals of Laparoscopic Surgery
(FLS), oﬀer dexterity training and certiﬁcation on peg-board transfer, cutting
and suturing of physical props as a foundation before working on real patients.2
However, FLS box training can not prepare for the high variability of anatomy
and soft tissue response that actual cases present and provides no automatic
checking of safety criteria.

The additional technical challenge that this work addresses is that entry
must interpret and trigger deployment of monitors for a palette of surgical safety
criteria set by surgeon educators. To explain the challenge, we ﬁrst review soft
tissue simulation and VR trainers in general in Section 1.1, then a customizable
training framework (TIPS, Section 1.2) and then, in Section 1.3, formulate the
speciﬁc challenge and new contributions.

1.1 Soft tissue simulation and VR trainers

The last decade has witnessed progress in soft tissue simulation for a range
of surgical scenarios such as laparoscopic surgery, heart surgery, neurosurgery,
orthopedic and arthroscopic surgery. Early multilayered tissue models for ortho-
pedic trauma surgery were based on 3D mass-spring systems accelerated with
graphics hardware.3 More recently, simulation of cardiac electrophysiology sim-
ulation, pre-operative planning of cryosurgery and per-operative guidance for
laparoscopy use ﬁnite elements in real time in the open source SOFA soft tissue
simulation platform.4 A real-time neurosurgery simulator of skull drilling and
surgical interaction with the brain was proposed in5 and6 report on simulation of
drilling and cutting of the bone using the burr and the motorized oscillating saw
based on the open source iMSTK framework.7 presented a framework for inter-
active outlining of regions for simulation of reconstructive plastic surgery and8
describes a virtual surgical environment for training residents in less invasive
stabilization system surgery used to address fractures of the femur.

Several commercial VR training environments aim to reduce time spent
teaching in the OR by oﬀering training modules with virtual anatomy that can
be probed using force feedback devices. Manual laparoscopic techniques lend
themselves particularly well to simulation that leverage force-feedback devices.
Virtual reality simulators allow trainees to practice decision-making and exe-
cution prior to entering the OR.9, 10 A number of commercial solutions have
sunset during the past 20 years (e.g. Simsurgery), or were merged or bought
up by larger companies (see e.g. SurgicalScience, Simbionics, Mimic). However,
commercial training environments neither capture the broad spectrum of physi-
cal variations encountered in laparoscopic practice, nor prepare learners for less
common interventions.

Building a robust virtual environment is a formidable challenge, leveraging
scientiﬁc advances in collision detection, real-time diﬀerential equation solving,
interactive visual and haptic feedback in a well-engineered interface. Creating

(a) TIPS environment, no hand piece

(b) setup with wired handles

Fig. 1: Physical setup of the TIPS environment: (a) left screen TIPS-simulator;
right screen TIPS-trainee providing instructions and quizzes. Two six degrees-
of-freedom haptic devices provide physical feedback. The haptic setup can be
augmented by (b) laparoscopic tool handles for a training setup with fulcrum,
similar to an FLS box trainer, but wiring is cumbersome and brittle.

or updating VR scenarios is a second hurdle: due to the back-and-forth between
engineers, computer scientists and medical experts, content creation is neither
cheap nor fast and can take months or years; and the result is not easily ad-
justable to create variants, uncommon or specialized scenarios.

1.2 The Toolkit for Illustration of Procedures in Surgery (TIPS)

transmit

The open source Toolkit
for Illustration of proce-
dures in Surgery (TIPS)
addresses the fast proto-
typing challenge of miss-
ing variants of anatomy
and of less common la-
paroscopic procedures. Fig. 1
shows two physical setup
force via
to
small robotic arms. The
TIPS open source envi-
ronment consists of TIPS-
simulator, an interactive
soft-tissue laparoscopic sim-
ulation with force feed-
back,
a
web-based component pro-
viding instruction and ex-
amples to a novice sur-
geon and TIPS-author

(TIPS-trainee,

Fig. 2: Screenshot of TIPS-trainee instructions di-
rectly generated from the TIPS-author entries with
embedded (real and) simulation footage video clips.

(see Section 2.1) that al-
lows the surgeon-educator to specify steps of a minimally invasive procedure in
the ﬁxed format:

The triple ‘action, anatomy, tool’ is used to initialize the geometry and phys-
ical properties of the virtual anatomy. This high-level initialization is possible
thanks to a rich database of simlets. A simlet is a piece of anatomy with its
physical properties, created by content artists. Simlets combine in a Lego-like
fashion.11–13 For example, the cystic duct, cystic artery and the fatty tissue cov-
ering them (each with their unique Young’s modulus etc.), form an anatomy sim-
let. In our implementation, the web-based TIPS-author interface auto-completes
typed items once they are recognized to be in the database and thereby steers
the author towards existing simlets (see Video, Supplemental Digital Content
1). Both the listing of steps and the resulting simulation is peer-reviewed for
completeness and relevance before roll-out to trainees.

An initial study of 34 medical students14 assessed whether the interactive
learning within the prototype TIPS environment has advantages over passive
learning from professional instructional videos.15 The study showed that inter-
active TIPS platform instilled greater conﬁdence in the ability to reproduce the
steps of the procedure (p=0.001) and was preferred by the participants as a
learning tool (p=0.011). Of course conﬁdence is not always positively correlated
with proﬁciency.16

1.3 The missing component and contribution: automatic

initialization and monitoring of safety criteria

The missing component in earlier work is a lack of automatic interpretation of
a ‘safety’ entry in the speciﬁcation of a surgical task. The technical challenge is
that this entry must interpret and trigger deployment of monitors for a palette
of surgical safety criteria set by surgeon educators. Examples are: do not cau-
terize near sensitive organs, limit the force when separating vessels from fatty
tissue, etc. . The challenge addressed in this paper is to provide a generic mech-
anism for meaningful author-controlled yet automatic (unsupervised) surgical
safety feedback to the trainee – and so accommodate current and future not yet
speciﬁed laparoscopic training scenarios.

While on one hand, haptic interactive simulation is no diﬀerent from (a spe-
cialized) computer game, on the other hand the safety criteria can not be hard-
coded a priori as in a game environment – because the surgeon-author sets the
criteria. The challenge then is to insure that (a large class) of surgical safety cri-
teria can be (i) formulated, (ii) automatically translated into measurable events
during VR simulation and (iii) generate both immediate feedback to the trainee
and a meaningful ﬁnal report to be shared with the instructor. Section 2 intro-
duces TIPS. Section 3 reports on the new contributions that

1. allow the surgeon-educator to specify the surgical safety criteria;
2. are automatically monitored within TIPS-simulator;
3. provide immediate feedback to the trainee; and

4. return, in a secure fashion, visual feedback to both the trainee and a summary

message to the instructor as a series of snapshots.

The list of errors and task-completion in the message (4.) record progress:
a repeatedly empty error-report and completed task report indicate proﬁciency
with respect to the training unit. This can be used to trigger the ﬁnal assessment
by the instructor and complete a feedback loop to improve the teaching unit by
setting additional safety criteria or better specifying steps of the procedure.

Fig. 3: TIPS-author deﬁnes the interactive VR training simulation: (1) The au-
thor speciﬁes procedural steps and safety concerns in a ﬁxed format. (2) In-
struction pages are generated from the author’s description. (3) Simlets (pieces
of anatomy and their physical properties) are combined to initialize the scenario
in TIPS-simulator. (4) Trainee achievements and safety violations are screen-
captured in TIPS-simulator for post-review. This is the focus and contribution
of the paper. (5) Completion and errors are reported to the trainee as snapshots
of missteps.

2 Methods

2.1 TIPS-author: a surgical simulation creation environment

TIPS-author enables a surgeon-educator (SE) to improve the specialization, vari-
ety and relevance of laparoscopic VR-training. TIPS-author provides a surgeon-

educator (SE) with an open source environment to create and customize hands-
on, interactive force-feedback laparoscopy training units. Based on the SE’s list-
ing, TIPS-author extracts a set of compatible, computationally eﬃcient simlets
from a database, and generates step-by-step instructions for the web-based TIPS-
trainee interface, quizzes and, as speciﬁed in Section Section 2.2, the monitoring
of surgical errors. The database is generated by a scenario design cycle12 that
separates the roles of author, developer and artist:

- at the developer level, numerical simulation routines are selected or adjusted

and admissible parameter ranges are determined;

- at the artist level, geometric models with collision and physics parameters

(simlets) are created; and

- at the surgeon-author level, simlets are combined and the workspace and

view determined via a interactive webGL interface.

Key to this approach is that it can leverage the vibrant professional open-source
geometric modeling software Blender (http://blender.org,17) and a library of
numerical, geometric and visual algorithms for soft-tissue simulation, SOFA
(http://www.sofa-framework.org,18, 19). Blender and SOFA are combined to gen-
erate hex-meshes on the ﬂy for carvable fatty tissue and thick-shell models of
the stomach. Anatomy and physics are customized via a menu added to Blender
that annotates the .xml ﬁles sent to SOFA for simulation. Combination and
customization are possible due to a small disciplined choice of representation
primitives.

2.2 Adding safety monitoring and feedback to TIPS

Assessment, evaluation and feedback are critical components in the training of
novice surgeons and obeying safety rules is paramount when executing complex
sequences of maneuvers. Physician-training is an experiential process. That is,
learners acquire skill by engaging in supervised patient care. All US physicians-
in-training, including surgical trainees, must demonstrate competency across
a range of knowledge, skills and attitudes prior to graduation.20, 21 Assessing,
evaluating and providing critical feedback and instruction in the workplace is
time intensive and stressful. And it requires an experienced surgeon’s active
participation and expert judgment to provide safe and eﬀective patient care
and a quality learning experience. To ensure that the assessment and evaluation
of surgical trainees is reliable and valid many training programs employ peer-
reviewed evaluative tools such as the objective structured assessment of technical
skills (OSATS) for workplace-based assessment.22

Assessment is also central, but arguably less stressful, in popular computer
games where simple counters monitor progress. Psychometric games claim to
measure mental agility, attention, cognitive speed, spatial aptitude and numeri-
cal processing ability. Increasingly, educational video games incorporate stealth
assessment, ubiquitous, unobtrusive, and real-time assessments that intersect
play, learning, and assessment. Stealth assessments measure knowledge and skill,

then provides learning supports, feedback, instructions, or adapts challenges in
the learning environment (e.g., diﬃculty) to students’ proﬁciency level, maxi-
mizing their learning.23

Existing VR simulators typically report time to completion, task speciﬁc
data such as the number of staples used, and other general counters. TIPS’s
incorporation of SE-established safety criteria makes cases more relevant for the
speciﬁc procedure – but this approach also implies that the criteria cannot be
hard-coded in the simulator ahead of time. Consultation with the clinical experts
identiﬁed general classes of training errors (i–vi):

i Incising or cauterizing at the wrong location.
ii Injuring a nerve by applying too much force (pressure or over-stretching).
iii Leaving foreign objects in the patient’s body (clips, tools).
iv Applying surgical clips incorrectly.
v Removing the wrong (part of) an organ.
vi Suturing at the wrong location.

These surgical errors can be abstracted as: distance to anatomy, force exerted,
location and number of surgical safety clips, and incomplete execution. Initialized
by the ‘safety’ entry in TIPS-author, our solution is to have TIPS-author parse
these safety criteria and append the corresponding safety tags to these simlets
upon export to TIPS-Simulator. TIPS-simulator monitors these data streams
and reports violations both directly and as a sequence of screen-shot images
labeled by error types. Fig. 4 shows screen-shots of four common surgical errors
(corresponding to type i - iv) during laparoscopic cholecystectomy.

In more detail, error class (i) is monitored by TIPS-simulator as a collision
event with an oﬀset distance between the tool listed in the TIPS-authors tuple
of the task and an organ listed in the safety entry.

For example, for cholecystectomy, for the step ‘Explore the triangle of Calot’

(see Fig. 4a) the task tuple reads:

dissect Fatty tissue over the cystic ductus and cystic artery
using Curved Maryland Dissector not too close to Common bile duct.

Here ‘dissect’ is the action, ‘Fatty tissue over
the cystic ductus and cystic artery’ is the anatomy
(specifying a simlet), ‘Curved Maryland Dissec-
tor’ speciﬁes the laparoscopic tool, ‘not too close’
indicates an error of type (i) and ‘Common bile
duct’ is an entry in the anatomy database that
requires monitoring. TIPS-simulator then moni-
tors distance between the cauterizing tool and the
common bile duct. Distance below the oﬀset trig-
gers and registers the error.

Type (ii) errors are monitored in terms of
force feedback returned to the haptic devices. This
safety threshold is customized for veins or arter-
ies with diﬀerent physical properties. Type (iii)

Fig. 5: Excessive force indi-
cated by change of vessel to
red (ﬂashing) color.

⇓

⇓

(a) Wrong incision on common bile
duct.

(b) Overstretching the cystic duct.

⇓

⇓

(c) Clip drops to abdominal wall due
to bile duct cut at the wrong location.

(d) Bile leak due to the lack of vascular
clips on the left side.

Fig. 4: Four types of common surgical errors in laparoscopic cholecystectomy
reported by TIPS-simulator. For immediate feedback the tool tip becomes red
(see ⇓) and the scene brieﬂy freezes (see Video, Supplemental Digital Content
1).

and (iv) errors are detected by a map tracking
the vector of deployed clips on each clip-able ob-
ject to monitor not only the number but also placement of clips. For example,
to prevent bleeding or leaking, two clips should be applied on the part of the
duct or vein that remains inside the body. Type (v) errors are indirectly caught
since they terminate the simulation without generating an ‘achievement’ entry
in the ﬁnal visual report and type (vi) errors are caught by initializing suturable
regions on the object, say the fundus of the gaster during Nissen fundoplication.

Errors (i - iv) alert the trainee by a red ﬂashing (Fig. 4a) instrument tip. A
corresponding screen-shot is saved for later named by time, error type, and error
values.

2.3 Summary feedback as a series of snapshots

Once the procedure completes, typically when the cancerous organ is retrieved
via the surgical pouch, all screen-shots of errors (and small ones for task comple-
tions) are displayed to the trainee as a feedback report. This serves as starting
point for a discussion with the instructor. Proﬁciency with respect to the training
module is equivalent to repeated performance without errors and a complete list
of achievements. The ﬁnal achievement is generically checked by asserting that
the cancerous body is free from the remaining organs and tissues. Similarly, clip
placement requires freeing the vessel and testing that two clips remain within
the body while a third clip ensures integrity of the tissue to be removed. Such
authored criteria provide more valuable feedback than time taken or number of
clips deployed.

Additionally the unique directory of
screen-shots and the ﬁlenames are reported
to the trainee by e-mail and, optionally, to
an account set up for the instructor (see
Fig. 6) to document training progress and de-
cide whether the pattern and number of errors
requires intervention and what errors should
be discussed.

In summary, faced with the complexity of
supporting procedure-speciﬁc proﬁciency as-
sessment, we categorized laparoscopic safety
violations into several generic classes. This en-
ables a simple but eﬀective, implemented and tested strategy to use TIPS-author
safety entries to initialize, monitor and report error events; and to create a record
of progress towards proﬁciency.

Fig. 6: Email reports to trainee
(and the instructor) upon com-
pletion.

3 Results

3.1 Evaluation of TIPS training and feedback

TIPS was demonstrated and experienced by a broad range of medical profes-
sionals at the the American College of Surgeons Clinical Congress 2019 (ACS)
and the Academic Surgical Congress 2020 (ASC). Besides testing the technology
‘in the wild’, the venues allowed the team to conduct a survey of TIPS.

Prior to ﬁeld testing, face, construct and content validity of SE-authored
cholecystectomy and appendectomy TIPS modules had been established by la-
paroscopic surgeons and residents at the Universities of Florida and Buﬀalo.
At the congress ﬁeld tests, after training with the modules, 64 respondents (13
board certiﬁed surgeons, 17 medical residents, 27 medical students and 7 other
medical professionals) rated TIPS across several usability items on a Likert scale
from 1 to 7 (7 = strongly agree, see24). The scale resolution was selected as a
trade-oﬀ between scale complexity and expressiveness. Table 1 lists the outcome
of the four central questions of usability and Fig. 7 breaks down the score on

these four central questions. (Four other questions established medical senior-
ity, familiarity with virtual trainers, and prior experience with laparoscopy). All
questions were selected in consultation with SEs at the authors’ institutions.

TIPS ...
helps understand the force necessary to explore the anatomy
interface does not distract from the surgical task
enhances lap-competency attainment over current methods
is compatible with the current lap training curricula
overall score

standard
deviation
1.46
1.52
1.5
1.43
1.33
Table 1: TIPS with safety rules rated on the four key questions.

mean
rating
5.34
5.02
5.19
5.39
5.24

(a) cumulative

(b) by group

Fig. 7: Breakdown of the average score on the 4 central TIPS evaluation ques-
tions.

3.2 The eﬀect of summative visual feedback via snapshots

When analyzing the data sets from the two conferences, we noticed agreement
of averages between the 13 ACS respondents and the 51 ASC respondents. The
agreement was within .2 on all rating categories except one. The only outlier was
the statement ‘The TIPS interface helps learners understand the force necessary
to explore the anatomy’. Here the rating improved from 5.04 at ACS to 5.35
at ASC. The only change applied to the TIPS software after the ACS survey
and before the ASC survey, was the addition of the visual summary of the
achievements and procedural errors as a series of snapshots. The immediate
feedback by changing the color of a vessel was present in both tests.

4 Discussion

TIPS is a novel authoring environment that allows surgeon-educators to build
customizable VR lap scenarios. The bulk of the survey questions was aimed
to evaluate TIPS as a whole. Ratings collected from medical professionals at
two conference exhibitions indicate the viability of such SE-authored surgical
training. In particular, the high score for ‘enhances lap-competency attainment
over current methods’ speaks to the added value of customized TIPS simulations
over available current methods.

We did not set out to measure the impact of automatic visual summative
feedback on errors presented as screen snapshots. In fact, the immediate feedback
on SE-authored error measurements, a change of color, was present at both ﬁeld
tests. It is therefore noteworthy that presenting trainee errors in visual form
at the end of the training increased acceptance noticeably. Indeed, additional
informal feedback from surgeons and trainees to the question ’what feature of
TIPS do you recall’ endorsed visual feedback via screen shots as both meaningful
and memorable.

References

1. A. Macario, What does one minute of operating room time cost?, J Clin Anesth.
22 (4) (2010) 233–6. doi:10.1016/j.jclinane.2010.02.003.PMID:20522350.
2. Z. B, Brydges, H. S. C. DA., State of the evidence on simulation-based training
for laparoscopic surgery: a systematic review, Ann Surg. 257 (4) (2013) 586–593,
pMID: 23407298. doi:10.1097/SLA.0b013e318288c40b.

3. J. Qin, W.-M. Pang, Y.-P. Chui, T.-T. Wong, P.-A. Heng, A novel modeling frame-
work for multilayered soft tissue deformation in virtual orthopedic surgery, Journal
of medical systems 34 (3) (2010) 261–271.

4. H. Talbot, N. Haouchine, I. Peterlik, J. Dequidt, C. Duriez, H. Delingette, S. Cotin,
Surgery training, planning and guidance using the sofa framework, in: Eurograph-
ics, 2015.

5. G. Echegaray, I. Herrera, I. Aguinaga, C. Buchart, D. Borro, A brain surgery

simulator, IEEE computer Graphics and Applications 34 (3) (2014) 12–18.

6. V. S. Arikatla, M. Tyagi, A. Enquobahrie, T. Nguyen, G. H. Blakey, R. White,
B. Paniagua, High ﬁdelity virtual reality orthognathic surgery simulator, in: Medi-
cal Imaging 2018: Image-Guided Procedures, Robotic Interventions, and Modeling,
Vol. 10576, International Society for Optics and Photonics, 2018, p. 1057612.
7. N. Mitchell, C. Cutting, E. Sifakis, Gridiron: an interactive authoring and cognitive
training foundation for reconstructive plastic surgery procedures, ACM Transac-
tions on Graphics (TOG) 34 (4) (2015) 1–12.

8. J. Cecil, A. Gupta, M. Pirela-Cruz, An advanced simulator for orthopedic surgical
training, International journal of computer assisted radiology and surgery 13 (2)
(2018) 305–319.

9. A. Gallagher, E. Ritter, H. Champion, G. Higgins, M. Fried, G. Moses, C. Smith,
R. Satava, Virtual reality simulation for the operating room: proﬁciency-based
training as a paradigm shift in surgical skills training, An. Surgery 241 (2) (2005)
364–372.

10. L. P. K.S. Gurusamy, R. Aggarwal, B. Davidson, Virtual reality training for surgical
trainees in laparoscopic surgery, The Cochrane Database of Systematic Reviews 1
(2009).

11. Y.-I. Yeo, S. Dindar, G. Sarosi, J. Peters, Enabling surgeons to create simulation-
based teaching modules, in: Medicine Meets Virtual Reality (MMVR) Feb 8-12
2011, Long Beach,CA, Studies in Health Technology and Informatics (SHTI), IOS
Press, Amsterdam, 2011, pp. 1–6.

12. S. Dindar, T. Nguyen, J. Peters, Towards surgeon-authored VR training: the scene-
development cycle, in: Proceedings of Medicine Meets Virtual Reality (MMVR)
April 9-12 2016, L.A. ,CA, Studies in Health Technology and Informatics (SHTI),
IOS Press, Amsterdam, 2016, pp. 1–6.

13. M. Sarov, R. Gao, J. Youngquist, G. Sarosi, S. Kurenov, J. Peters, An authoring
interface for surgeon-authored VR training, International Journal of Computer
Assisted Radiology and Surgery 13 (2018) 1–(1–4)–273.

14. H. Lesch, E. Johnson, J. Cendan, J. Peters, VR simulation leads to enhanced
procedural conﬁdence for surgical trainees, Journal of Surgical Education 77 (1)
(2019) 213–218, nIHMS1680076.

15. N. G. S. of Medicine, A. C. of Surgeons (ACS), A. of Surgical Education (ASE),

Wise-md.
URL http:/www.aquifer.org

16. M. B, Belton, Powell, I. J., The relationship between fundamental movement skill
proﬁciency and physical self-conﬁdence among adolescents, J Sports Sci 35 (17)
(2017) 1709–1714, pMID: 28282760. doi:10.1080/02640414.2016.1235280.

17. B. Foundation, Blender, http://blender.org/ (2015).
18. INRIA, Simulation open framework architecture, http://www.sofa-framework.

org (2015).

19. J. Allard, S. Cotin, F. Faure, P.-J. Bensoussan, F. Poyer, C. Duriez, H. Delingette,
L. Grisoni, Sofa an open source framework for medical simulation, in: Medicine
Meets Virtual Reality (MMVR’15), Long Beach, USA, 2007.

20. S. Yardley, P. W. Teunissen, T. Dornan, Experiential learning: transforming theory

into practice, Medical teacher 34 (2) (2012) 161–164.

21. E. S. Holmboe, Realizing the promise of competency-based medical education,

Academic Medicine 90 (4) (2015) 411–413.

22. J. Martin, G. Regehr, R. Reznick, H. MacRae, J. Murnaghan, C. Hutchison,
M. Brown, Objective structured assessment of technical skill (osats) for surgical
residents, Br J Surg. (1997) 273–8.

23. V. J. Shute, Stealth assessment in computer-based games to support learning,

Computer games and instruction 55 (2) (2011) 503–524.

24. Survey for 2019 American College of Surgeons Clinical Congress and the 2020

Academic Surgical Congress.
URL https://ufl.qualtrics.com/jfe/form/SV_b0WFv9hk3vl44fj

