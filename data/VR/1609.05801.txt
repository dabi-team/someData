Asynchronous Splitting Design for Model Predictive Control∗

L. Ferranti1, Y. Pu2, C. N. Jones2, and T. Keviczky1

6
1
0
2

p
e
S
9
1

]

C
O
.
h
t
a
m

[

1
v
1
0
8
5
0
.
9
0
6
1
:
v
i
X
r
a

Abstract— This paper focuses on the design of an asyn-
chronous dual solver suitable for embedded model predictive
control (MPC) applications. The proposed solver relies on
a state-of-the-art variance reduction (VR) scheme, previously
used in the context of stochastic proximal gradient methods,
and on the alternating minimization algorithm (AMA). The
resultant algorithm, a stochastic AMA with VR, shows geomet-
ric convergence (in the expectation) to a suboptimal solution
of the MPC problem and, compared to other state-of-the-art
dual asynchronous algorithms, allows to tune the probability
of the asynchronous updates to improve the quality of the
estimates. We apply the proposed algorithm to a speciﬁc class
of splitting methods, i.e., the decomposition along the length
of the prediction horizon, and provide preliminary numerical
results on a practical application, the longitudinal control of an
Airbus passenger aircraft.

I. INTRODUCTION

Model Predictive Control (MPC) applications to systems
with fast dynamics are still relatively limited [1], [2]. Ap-
plications in ﬁelds such as automotive and aerospace have
to deal very often with embedded legacy systems. These
systems usually run on certiﬁed (for safety purposes) hard-
ware architectures with limited availability, for example, of
parallel computation units and support a small set of (certi-
ﬁed) mathematical functions. In particular, the availability of
optimization toolboxes suitable for MPC purposes on these
platforms are limited (or nonexistent).

Growing attention has been recently dedicated to the
design of simple ﬁrst-order solvers for MPC ([3], [4], [5],
[6], [7]). These solvers are relatively easy to certify (in
terms of level of suboptimality of the solution), use only
simple algebraic operations, and require little memory. In [5]-
[7], operator-splitting methods, such as the alternating min-
imization method of multipliers (ADMM) [8] and the fast
alternating minimization algorithm (FAMA) [9], have been
used to exploit the MPC problem structure and speed-up
the computation of the solution. These algorithms most of
the time require frequent exchanges of information at given
synchronization points. To reduce the bottlenecks at
the
synchronization points, a solver that can offer more ﬂexibility

*This research is supported by the European Union’s Seventh Frame-
work Programme FP7/2007-2013 under grant agreement n. AAT-2012-
RTD-2314544 (RECONFIGURE), by the TU Delft Space Institute, by the
People Programme (Marie Curie Actions) of the European Union’s Seventh
Framework Programme (FP7/2007-2013) under REA grant agreement n.
607957 (TEMPO) and by the Swiss National Science Foundation under
Grand P2ELP2 165155.

1L. Ferranti and T. Keviczky are with the Delft Center for Systems and
Control, Delft University of Technology, Delft, 2628 CD, The Netherlands,
{l.ferranti,t.keviczky}@tudelft.nl

2Y. Pu and C. N. Jones are with the Laboratoire d’Automatique, ´Ecole
Polytecnique F´ed´erale de Lausanne (EPFL), Lausanne, CH-1015, Switzer-
land, {y.pu,colin.jones}@epfl.ch

in the way the solutions are computed (for example, by
allowing asynchronous updates) would be attractive. In this
work, we are interested in extending the use of splitting
methods, such as AMA, to the asynchronous framework.

Contribution. The contribution of the paper is threefold.
First, we propose a novel algorithm, a stochastic alternat-
ing minimization algorithm with variance reduction (SVR-
AMA), suitable for MPC applications with state and input
constraints. The proposed algorithm operates in the dual
space and combines the advantages of the variance reduction
scheme proposed in [10] for the proximal stochastic gradient
method with the alternating minimization algorithm [11].
The result is that the solution of the MPC problem can be
computed in an asynchronous fashion (i.e., at each iteration,
the algorithm updates a randomly selected subset of the
dual variables instead of the whole set of dual variables)
and the resultant algorithm has geometric convergence (in
the expectation) to the optimal solution. Furthermore, the
proposed algorithm allows the use of a generic probability
distribution for the asynchronous updates. In addition, the
probability distribution can be updated online to improve
the quality of the estimates, as our numerical results show.
Finally, the algorithm relies on simple algebraic operations,
an appealing quality for embedded MPC applications.

Second, we show how we can use SVR-AMA for a
speciﬁc splitting technique, i.e., the decomposition along the
length of the prediction horizon (or time splitting [5]).

Third, we present simulation results on a practical
aerospace application, i.e., the longitudinal control of an
Airbus passenger aircraft [12]. The results show that the
proposed method is more robust when solving ill-conditioned
problems, outperforming synchronous methods in terms of
computation time (measured in terms of number of iterations)
and suboptimality level of the solution.

Related Work. SVR-AMA derives from the application to
the dual problem of the proximal stochastic gradient method
with variance reduction (Prox-SVRG) proposed in [10].

The investigation of asynchronous dual algorithms for
MPC is gaining more attention recently. In [13], for example,
an asynchronous dual algorithm is proposed. Compared
to [13], SVR-AMA allows the use of a generic (i.e., not nec-
essarily uniform) probability distribution and, consequently,
more ﬂexibility in the tuning phase of the algorithm.

The idea of the time splitting has been previously proposed
in [5]. Their work relies on a synchronous ADMM algorithm.
In this context, we reformulate the approach for AMA to
exploit SVR-AMA.

Outline. The paper is structured as follows. Section II
introduces the MPC problem formulation. Section III sum-

 
 
 
 
 
 
marizes AMA and Prox-SVRG. Section IV describes SVR-
AMA and show convergence results. Section V shows how to
reformulate the proposed MPC problem for SVR-AMA using
the time splitting. Section VI presents preliminary numerical
results using an aerospace example. Finally, Section VII
concludes the paper.

Notation. For u ∈ Rn, (cid:107)u(cid:107) = (cid:112)(cid:104)u, u(cid:105) is the Euclidean
norm. Let C be a convex set. Then, PrC(u) is the projection
of u onto C. Let f : D → C be a function. Then, f (cid:63)(y) =
supx(yTx−f (x)) and ∇f (x) are the conjugate function and
the gradient of f (x), respectively. Furthermore, IC(σ) is the
indicator function on the convex set C, which is zero if σ ∈ C
and inﬁnity otherwise. Let A ∈ Rn×m. Then, eigmax(A)
and eigmin(A) are the largest and the smallest (modulus)
denotes that P ∈ Rn×n
eigenvalues of ATA. P ∈ Sn×n
+
is positive deﬁnite. In addition, let x ∈ Rn be a random
variable, E[x] is its expected value. Finally, details on the
notions of strong convexity and Lipschitz continuity used in
the paper can be found in [14].

II. PROBLEM FORMULATION

Consider the discrete linear time-invariant (LTI) system

described by the following equation:

x(k + 1) = Ax(k) + Bu(k),

k = 0, 1, 2, . . .

(1)

Algorithm 1 AMA [11].

Given µ0, T , and τ < σf / eigmax(Hy).
while k = 1, . . . , T do

1a. yk = argminy f (y) + (cid:104)µk−1, −Hyy(cid:105).
1b. zk = argminz g(z) + (cid:104)µk−1, −Hzz(cid:105)+
+ τ
2 (cid:107)d − Hyyk − Hzz(cid:107)2.
2. µk = µk−1 + τ (d − Hyyk − HzzK)

end while

operator-splitting methods (which, for example, usually rely
on parallel hardware architectures)and asynchronicity (which
allows one to perform updates of a randomly selected
subset of variables to reduce the computational effort). The
next section introduces the techniques we rely on to solve
Problem (3), i.e., AMA proposed by [11] and the proximal
stochastic gradient descent method with variance reduction
(Prox-SVRG) proposed by [10].

III. PRELIMINARIES

AMA and Prox-SVRG are the main techniques we rely
on for our design. In the following, Section III-A brieﬂy
describes AMA developed by [11], while Section III-B
describes Prox-SVRG [10].

The state x(k) ∈ Rn and the control input u(k) ∈ Rm are
subject to the following polyhedral constraints:

A. Alternating Minimization Algorithm

Consider the following problem:

Cx(k) + Du(k) ≤ d,

(2)

where C ∈ Rp×n and D ∈ Rp×m. Note that the deﬁnition
of the constraints (2) can include constraints on x(k) only
or on u(k) only. We aim to regulate the state x(k) to the
input u(k) while respecting the
origin using the control
constraints (2). This goal can be translated into the following
model predictive control (MPC) problem:

min
x,u

1
2

N
(cid:88)

t=0

(cid:0)xT

t Qxt + uT

t Rut

(cid:1)

s.t.: xt+1 = Axt + But
Cxt + Dut ≤ d
x0 = xinit,

t = 0, . . . , N − 1

t = 0, . . . , N

(3a)

(3b)

(3c)

(3d)

+

where xt and ut represent the t-step-ahead state and control
predictions, respectively, N indicates the length of the pre-
+ , R ∈ Sm×m
diction horizon, Q ∈ Sn×n
, and xinit is the initial
(measured) state vector. The MPC law implemented in closed
loop is given by the ﬁrst element of the optimal control
sequence obtained by solving Problem (3), i.e., uMPC = u∗
0.
Our goal is to solve Problem (3) in an embedded envi-
ronment. In particular, we assume that explicit MPC [15]
cannot be used due to the problem size and that
the
computational resources are limited, i.e., parallel architec-
tures are not available, memory resources are limited, and
only simple algebraic operations are supported. With this
framework in mind,
in the following, we focus on the
design of a simple solver for Problem (3) that relies on

minimize f (y) + g(z)
subject to Hyy + Hzz = d,

(4a)

(4b)

where f (y) := (cid:80)N

t=0 ft(y) under the following assumptions:
Assumption 1. ft is a strongly convex function and σft
denotes its convexity parameter (t = 0, . . . , N ).

Assumption 2. ft has a Lipschitz continuous gradient with
modulus Lft (t = 0, . . . , N ) and eigmin(Hy) > 0.

Assumption 3. g is a convex function not necessarily
smooth.

Furthermore, recall the following properties of the conju-

gate function f (cid:63):

Lemma 1 (Thm. 4.2.1 [16]). If f is strongly convex with
convexity parameter σf , then f (cid:63) has a Lipschitz continuous
gradient with modulus L(∇f (cid:63)) = σ−1
f .

Lemma 2 (Thm. 4.2.2 [16]). If f is convex and has a
Lipschitz continuous gradient with modulus Lf , then f (cid:63) is
strongly convex with convexity parameter L−1
f .

A state-of-the-art algorithm to solve Problem (4)
is
AMA [11]. AMA operates as a proximal gradient algorithm
(such as, ISTA [17]) on the dual of Problem (4). Speciﬁcally,
given the dual of Problem (4) (under the assumptions above),
described as follows:

maximize
µ∈Rnµ

D(µ) {:= −F (µ) − G(µ)} ,

(5)

where F (µ) := (cid:80)N
t=0 f (cid:63)
dTµ, the following holds:

t (H T
yt

µ) and G(µ) := g(cid:63)(H T

z µ) −

Lemma 3. If Assumptions 1-3 are satisﬁed, F (µ) is strongly
convex with Lipschitz continuous gradient characterized by
Lipschitz constant L(∇F ) := eigmax(Hy)σ−1
f . Furthermore
G(µ) is convex.

Proof. We can use Lemmas 1 and 2 to derive the properties
of F (µ). Convexity of G(µ) follows from the properties of
the conjugate of a convex function and from the fact that
dTµ is a linear function.

AMA updates the dual variables µ ∈ Rpµ as described in
Algorithm 1. In general, AMA uses only simple algebraic
operations (if y and z are unconstrained steps 1a and 1b
can be performed efﬁciently) and does not require advanced
hardware architectures. Nevertheless, the algorithm requires
frequent exchange of information at given synchronization
points (e.g., step 1b requires y computed at step 1a that
can lead to bottlenecks in the computation of the problem
solution). Hence, it would be better to have some ﬂexibility
on the update strategy. Motivated by this observation, the
following section introduces Prox-SVRG used to derive our
proposed asynchronous AMA, as described in Section IV.

B. Stochastic Gradient Method with Variance Reduction

Consider the following primal problem:

minimize
y∈Rny
where F (y) := (cid:80)N
assumptions:

P (y) {:= F (y) + G(y)} ,

(6)

t=0 Ft(y) and G(y) satisfy the following

Assumption 4. F (y) is a strongly convex function with
convexity parameter σF and Lipschitz continuous gradient
characterized by a Lipschitz constant L ≤ (cid:80)N
t=0 Lt, where
Lt are the Lipschitz constants of each Ft(y).

Assumption 5. G(y) is a convex function.

Furthermore, deﬁne the proximal operator as follows:
(cid:26) 1
2

proxτ G(y) := argmin
y∈Rny

(cid:107)y − x(cid:107)2 + τ G(y)

(cid:27)

.

(7)

The main idea behind Prox-SVRG [10] is to eliminate the
dependency of the number of iterations (typical of stochastic
gradient methods) in the deﬁnition of the step size and reduce
the burden in the computation of ∇F (y) (typical of classical
gradient methods). As pointed out in [10], proximal stochas-
tic gradient methods (such as, [18], [19]) suffer of sublinear
convergence (to a suboptimal solution of Problem (6)) given
that the step size decreases at each iteration of the algorithm,
but behave well when N is large. On the other hand, classical
proximal gradient methods require at each iteration of the
algorithm to compute the full gradient of F (y), which can
be an involved operation if N is large, but the step size is
ﬁxed and independent of the number of iterations (leading
to better theoretical convergence properties). Hence, Prox-
SVRG aims to exploit the beneﬁts of the two techniques as
explained below and described in Algorithm 2.

Algorithm 2 Prox-SVRG [10].

Given ˜y0, N , IN := {0, . . . , N } τ , and T .
while s ≤ ¯s do

0a. Set ˜y = ˜ys−1.
0b. Set ˜β = ∇F (˜y).
0c. Set y0 = ˜y.
0d. Set Π := {π0, . . . , πN }.
for k = 1, . . . , T do

1. Pick i ∈ IN randomly according to Π.
2. βk = ˜β + ∇Fi(yk−1)−∇Fi(˜y)
3. yk = proxτ G(yk−1 − τ βk)

πi

end for
4. ˜ys = (cid:80)T

k=1 yk.

end while

Prox-SVRG uses a multistage strategy to gradually reduce
the variance in the estimation of the full gradient ∇F (y)
(without computing the actual full gradient at each iteration).
In particular, the full gradient of F (y) is updated only every
T iterations to reduce the computational effort compared
to the classical gradient methods, and the proximal step
(step 3) uses a modiﬁed direction βk (step 2) that leads
to a smaller variance E(cid:107)βk − ∇F (yk−1)(cid:107)2 compared to
the one obtained using classical stochastic gradient methods
E(cid:107)∇Fi(yk−1) − ∇F (yk−1)(cid:107)2 (i ∈ IN ), where ∇Fi(yk−1)
is used as update direction (refer to [10] for more details).
Furthermore, the random sampling (step 1) is performed on
a probability distribution Π := {π0, . . . , πN } that does not
necessarily have to be uniform, i.e., the algorithm allows
more ﬂexibility in the tuning phase by supporting other
distributions as well, such as Poisson distributions, normal
distributions, etc. Algorithm 2 achieves geometric conver-
gence in the expectation, as stated in the following theorem:

Theorem 1 (Thm. 3.1 in [10]). Suppose Assumptions 4 and 5
hold. Let y∗ = argminy P (y) and LΠ := maxt Lt/πt.
Assume that 0 < τ < 1/(4LΠ) and T is sufﬁciently large so
that:

ρ :=

1
τ σF T (1 − 4τ LΠ)

+

4τ LΠ(T + 1)
T (1 − 4τ LΠ)

< 1.

(8)

Then, for ¯s > 1, Algorithm 2 has geometric convergence in
expectation:

EP (˜y¯s) − P (y∗) ≤ ρ¯s (cid:2)P (˜y0) − P (y∗)(cid:3) .

(9)

Remark 1. The dependency on the probability πt in the
choice of the step size τ can be problematic when using
probability distributions with πt → 0 or when N → ∞
(e.g., the constrained inﬁnite horizon LQR). Nevertheless,
this dependency can be removed in the special case in which
F (y) = (cid:80)N
t=1 Ft(yi), i.e., when the cost is separable in yt.
From the MPC perspective, this is very often the case when
the dual formulation is used, as it is shown in Section V for
the decomposition along the length of the prediction horizon.
Hence, this observation, when the algorithm is used in the
dual framework, can be very beneﬁcial to improve the choice

of the step size and the quality of the MPC solution.

Algorithm 3 SVR-AMA.

IV. STOCHASTIC AMA WITH VARIANCE
REDUCTION

Our goal is to solve Problem (4) in an asynchronous
fashion, i.e. by allowing updates of a randomly selected
subset of the dual variables at each iteration of the solver.
Hence, given that Algorithm 2 cannot be directly applied to
Problem (4), we proceed as explained in Section III-A, i.e.,
we apply Algorithm 2 to the dual of Problem (4). The resul-
tant algorithm (SVR-AMA) is described by Algorithm 3.

Let
Suppose Assumptions
Theorem 2.
µ∗ = argmaxµ D(µ), where D(µ) is the dual cost deﬁned
Π := maxt(πtσf )−1 eigmin(Hy),
in (5). In addition, let L(cid:63)
πt ∈ Π. Assume that 0 < τ < 1/(4L(cid:63)
Π) and T ≥ 1 such
that:

hold.

1-3

ρ :=

Lf
τ T (1 − 4τ L(cid:63)

Π)

+

4τ L(cid:63)
T (1 − 4τ L(cid:63)

Π(T + 1)
Π)

< 1.

(10)

Then, for ¯s > 0, Algorithm 3 has geometric convergence in
expectation:

D(µ∗) − ED(˜µ¯s) ≤ ρ¯s (cid:2)D(µ∗) − D(˜µ0)(cid:3) .

(11)

Proof. If the assumptions of the theorem are satisﬁed, ex-
ploiting a similar argument to the one in Theorem 1 in [9]
for AMA, we can show that Algorithm 3 is equivalent to
applying Algorithm 2 to Problem (5). Consequently, by using
Lemmas 1 and 2, the results follows from Theorem 1.

Remark 2. Note that an acceleration step such as the one used
in FAMA [9] can be added to improve the convergence of
the algorithm. The proof of convergence for the acceleration
is part of our future work, but note that
the simulation
results in Section VI rely on the acceleration step of FAMA,
showing that, in practice, it can be applied to the proposed
algorithm. In addition, note that an acceleration strategy for
Prox-SVRG [10] has been recently proposed in [20] and can
be extended to the dual framework to accelerate Algorithm 3.

V. ASYNCHRONOUS MPC

Our aim is to solve the MPC Problem (3) presented in
Section II using Algorithm 3. Hence, we must show that the
MPC Problem (3) is a particular case of Problem (4).

First, we decompose Problem (3) along the length of
the prediction horizon N into N + 1 smaller subproblems,
according to the time-splitting strategy proposed in [5].
This results is achieved thanks to the introduction of N
consensus variables zt ∈ Rn (t = 1, . . . , N ) used to break
up the dynamic coupling (3b). This decomposition allows to

Given ˜µ0, N , IN := {0, . . . , N }, τ , and T .
while s ≤ ¯s do

0a. Set ˜µ = ˜µs−1, ˜y = ˜ys−1.
0b. Set ˜β = ∇F (˜µ).
0c. Set µ0 = ˜µ.
0d. Set Π := {π0, . . . , πN }.
for k = 1, . . . , T do

1. Pick i ∈ IN randomly according to Π.
2a. yk = argminy fi(y) + (cid:104)µk−1, −Hyiy(cid:105).
2b. zk = argminz g(z) + (cid:104)µk−1, −Hzz(cid:105)+
+ τ

2 (cid:107)d − Hyyk − Hzz(cid:107)2.

3. βk = ˜β + (yk − ˜y)TH T
yi
4. µk = µk−1 − τ (βk + Hzzk − d)

π−1
i

end for
5. ˜µs = 1
T

end while

(cid:80)T

k=1 µk, ˜ys = 1
T

(cid:80)T

k=1 yk.

reformulate Problem (3) as follows:

min
x,u

1
2

N
(cid:88)

(cid:16)

x(t)T
t Qx(t)

t + u(t)T

t Ru(t)

t

(cid:17)

t + Bu(t)

t

t=0
s.t.: zt+1 = Ax(t)
zt+1 = x(t+1)
t+1
t + Du(t)
Cx(t)
x(0)
0 = xinit,

t ≤ d

t = 0, . . . , N − 1

t = 0, . . . , N − 1

t = 0, . . . , N

where the original dynamic coupling (3b) has been replaced
by the consensus constraints (12b) and (12c). Note that we
introduced the superscript t to underline that the xt and ut
are local variables of the subproblems obtained after the time
splitting [5]. Finally, if we introduce N + 1 additional slack
variables σt ∈ Rp to remove the inequality constraints (12d)
and deﬁne C := {σt ∈ Rp | σt ≥ 0}, Problem (12) can be
written as the sum of the following subproblems:

ft (yt) +

p
(cid:88)

IC (σti)

min
yt

s.t.: wt :

i=1
zt = H1yt,
vt+1 : zt+1 = H2yt,

λt :
t := [x(t)T

t

σt = d − Gyt,
u(t)T

where we deﬁne yT
t Qyt, Q :=
diag {Q, R}, G := [C D], H1 := [In 0n×m], H2 := [A B].
Furthermore, for each equality constraint in Problem (13), the
corresponding Lagrange multipliers have been highlighted.

], ft(yt) := yT

t

(cid:80)n

0 . . . yT

N ], f (y) = yTQy =
If we deﬁne yT = [yT
σT
zT
[zT
0 . . . σT
t=0 ft(yt),
N ],
=
diag{Q . . . Q}, g(z) = (cid:80)N
t=0 IC(σt),
=
2 | − GT(cid:3), hT
= (cid:2)H T
2 | − GT(cid:3),
1 H T
= (cid:2)0n | − dT(cid:3),
1 | − GT(cid:3), hT
= (cid:2)H T

= (cid:2)H T

1 . . . zT
N

= hT
dN

d0

y

Q
hT
y0
hT
yN

(12a)

(12b)

(12c)

(12d)

(12e)

(13a)

(13b)

(13c)

(13d)

d = (cid:2)0n 0n | − dT(cid:3),
hT

0
hy

Hy :=

Hz :=

hy0
0
...
0
0
In
0
In
0
0
...
0
0























0
0
0
0
0
In
0

0
0










,

,

. . .

. . .

. . .
. . . hy
0
. . .
0
. . .
0
. . .
0
. . .
0
. . .
. . .
0
. . .
. . .
. . .

In
0

0
0
...
0
hyN
0
Ip
0
0
0
...
0
0










, d :=

0
0
0
0
Ip

0
0

. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .










hd0
hd
...
hd
hdN

0
0
0
0
0














0
0
Ip

Problem (3) can be rewritten as follows:

minimize f (y) + g(z)
Hyy + Hzz = d,

(14a)

(14b)

According to the deﬁnition of Q, f (y) is strongly con-
vex, has a convexity modulus σf
:= eigmin(Q) =
eigmin(blockdiag{Q, R}) = σft, and a Lipschitz constant
Lf := eigmax(Q). In addition, g(z) is a convex function.

1,

For

satisﬁed. Concerning Assumption

f = maxt(eigmax(Hyt)σ−1
ft

the proposed splitting, Assumptions 2 and 3
that
are
L(∇F ) := eigmax(Hy)σ−1
) =
maxt(Lt(∇Ft)) = Lt(∇Ft) ≤ (cid:80)N
t=0 Lt(∇Ft), where the
last equality follows from the fact that we deal with LTI
systems (L0 = L1 = . . . = LN ). Hence, on the dual,
Assumption 4 still holds and, consequently, we can use
SVR-AMA to solve Problem (3).

note

1 λT

N λT

N λT

0 | wT

1 . . . wT

N −1 | wT

The associated SVR-AMA algorithm to solve Prob-
lem (14) is detailed in Algorithm 4. In particular, deﬁning
N −1 vT
µT := [vT
N ], according
to the partitioning of Hy and Hz, F (µ) = f (cid:63)(H T
yµ).
Furthermore, ∇F (w) is the gradient of F at w, ∇F (v)
is the gradient of F at v, and ∇F (λ) is the gradient of F
at λ. Note that the calculation of the gradient step for this
particular splitting is very simple and requires the evaluation
of the product Hyy, that can be performed efﬁciently by
exploiting the structure of the matrix Hy. Finally, note that,
given the structure of F (µ) the probability πt does not affect
the choice of the step size τ , according to Remark 1.

The following complexity upper bound on the primal

sequence can be deﬁned:

Theorem 3. Consider Problem (14). Let {yk} and {µk}
be the sequence of primal and dual variables, respectively,
generated by Algorithm 4. If Assumptions 1-3 are satisﬁed,
z µ) − dTµ, then, the
given ˜µ0 ∈ dom(G), where G := g(cid:63)(H T
following holds:

E(cid:107)˜ys − y∗(cid:107)2 ≤

2
σf

(D(µ∗) − ED( ˜µ)).

(15)

Proof. We summarize the logic of the proof. The inequality

Algorithm 4 SVR-AMA for Problem (14).

˜µ0, N ,

Given
(σf )−1 eigmax(Hy), 0 < τ < 1/(4L(cid:63)), and T .
while s ≤ ¯s do

{0, . . . , N }, L(cid:63)

IN

:=

:=

0a. Set ˜w = ˜ws−1, ˜v = ˜vs−1,
, and ˜y = ˜ys−1.
0b. Set ˜βw = ∇F ( ˜w), ˜βv = ∇F (˜v), and

˜λ = ˜λ

s−1

˜βλ = ∇F (˜λ).

0c. Set w0 = ˜w, v0 = ˜v, and λ0 = ˜λ.
0d. Set Π := {π0, . . . , πN } on IN
for k = 1, . . . , T do

τ (wi + vi)(cid:3).

1. Pick i ∈ IN randomly according to Π.
2a. yk
i = argminy fi(yi) + (cid:104)wi, H1yi(cid:105)+
(cid:104)vi+1, H2yi(cid:105) + (cid:104)λi, −Gyi(cid:105).
i − d − 1
τ λi).
i + H2yi−1 − 1
i −˜yi)TH T
1
πi

2.b σk
2c. zk

3a. βk
wi

i = PrC (Gyk
(cid:2)H1yk
i = 1
2
= ˜βwi + (yk
= ˜βvi + (yi−1−˜yi−1)TH T
= ˜βλi − (yk
i = wi + τ (cid:0)zk
i = vi + τ (cid:0)zk
i = λi + τ (cid:0)βk

πi
i −˜yi)TGT
.
πi
(cid:1).
i − βk
wi
(cid:1).
i − βk
vi
+ d − σk
i
λi

3c. βk
λi
4a. wk
4b. vk
4c. λk

.

(cid:1).

3b. βk
vi

.

2

end for
5. ˜ws = 1
T
s
˜λ
= 1
T

end while

(cid:80)T

(cid:80)T

(cid:80)T

k=1 wk, ˜vs = 1
T
k=1 λk, and ˜ys = 1

T

k=1 vk,
(cid:80)T

k=1 yk .

can be derived by the results of Theorem 5.3 in [7] by
noticing that the primal updates in the inner loop are the same
as AMA. Then, we have to take into account for Algorithm 4
that the primal variables are stochastic variables and that
we must consider their expected values. These observations
combined with the results of Theorem 2 lead to (15).

Remark 3. The initial value of the dual variables ˜µ0 should
be a feasible starting point in order to use the results of
Theorem 5.3. This can be accomplished by noticing the
following. Concerning the ˜λ0
t components of ˜µ0, they must
be in Ct. Concerning the ˜w0
t components of ˜µ0, by
t and ˜v0
providing an initial primal solution satisfying the consensus
constraints (e.g., by using the evolution of the state starting
from xinit under the associated unconstrained LQR control
law ut = KLQRxt), they can be set equal to zero.

The decomposition along the length of the prediction
the size of the
horizon offers several advantages. First,
subproblems (13) is ﬁxed and independent from the length
of the prediction horizon. Second, the resultant subproblems
have improved numerical properties (in terms of condition
number, for example), compared to solving Problem (3).
Third, this decomposition allows one to fully parallelize the
solution of Problem (3), thanks to the introduction of the
consensus variables. In theory, if N + 1 independent workers
are available, the dual update of each subproblem can be

assigned to its dedicated worker that exchanges information
with its neighbors only at dedicated synchronization points
to update the consensus variables, as detailed in [5]. If the
prediction horizon, however, is larger than the number of
available workers the computation of the solution has to be
partially (or fully, if only one worker is available) serialized.
This scenario can be quite common for embedded legacy
control systems, where the serial hardware architecture is
formally veriﬁed and the costs to upgrade to the parallel one
are too high. In this scenario, Algorithm 3 plays a fundamen-
tal role to compute a suboptimal solution of Problem (3).

Algorithm 3 applied to Problem (12) translates into the
possibility of asynchronous updates of the independent sub-
problems. Compared to solving the subprolems in a seri-
alized fashion (i.e., one after the other) in a synchronous
framework, the asynchronous updates lead to less costly (in
terms of computation time) iterations of the algorithm. In
particular, assuming that only one worker is available, at
each inner-loop iteration (steps 1-4 of the algorithm), only
one subproblem is randomly selected for the update. In a
synchronous framework, the update of all the subproblems
would have been required, which can be costly if the length
of the horizon is large.

to

dual

other

Compared

asynchronous

algorithms
(e.g., [13]), Algorithm 3 allows one to tune and adapt
(online) the probability distribution Π. This is particularly
useful, for example, to give priority in the update to those
subproblems whose associated dual variables vary the most
between two iterations of the algorithm, as shown in the
next section.

VI. NUMERICAL EXAMPLE

This section considers the linearized model (at a given
trim condition) of an Airbus passenger aircraft to test the
proposed design. Aerospace applications offer several chal-
lenges for MPC from the computational perspective. First,
these applications usually have strict real-time requirements.
Second, the states have different magnitudes (ranging from
few degrees to thousands of feet) affecting the conditioning
of the MPC problem. Third, some of the open-loop system
eigenvalues are, in general, complex conjugate close to the
imaginary axis. Finally, the problem size is relatively large
and a long prediction horizon is required.

We focus on the longitudinal control of the aircraft. In this
respect, the model we consider has n = 6 states (to describe
the longitudinal dynamics) and m = 4 control actuators.
In particular,
the states associated with the longitudinal
dynamics are pitch rate [deg/sec], roll rate [deg/sec], ground
speed [knots], angle of attack [deg], pitch angle [deg], and
altitude [ft]. Finally, the control surfaces for the longitudinal
dynamics are the four elevators on the tail of the aircraft.

The sampling time of the system is Ts = 0.04 sec and
we consider an horizon length N = 60. The total number
of decision variables is 600. Furthermore, we have 3000
inequality constraints and 600 equality constraints. The goal
of the MPC controller is to regulate the state of the system

Fig. 1: Probability distributions used to test the performance of Algorithm 4
plotted in log10 scale.

to the origin starting from a nonzero initial condition close
to the saturation limits of the system.

We compared the behavior of Algorithm 4 to a syn-
chronous one (a state-of-the-art AMA [11], [9]). The baseline
for the comparison is the trajectory obtained using the MPC
functions of MPT3 [21]. In particular, we are interested
in showing that
the possibility of tuning the probability
distribution that the algorithm offers can lead to signiﬁcant
improvements in terms of performance of the MPC con-
troller, especially when the solver runs for a limited number
of iterations to reach a medium accuracy. In this respect, we
consider four different probability distributions (depicted in
Figure 1): (i) uniform, (ii) Poisson, (iii) generalized Pareto,
and (iv) adaptive. Scenario (iv) is obtained as follows. We
initialize the Π to be the uniform distribution. Then, every
T iterations, we check, for each t = 0, . . . , N whether the
following condition is veriﬁed (cid:107)λT − λT −1(cid:107)2 < 0.01. If the
condition is veriﬁed, πt ← 0.5πt and the probabilities of
its neighbors become πt+1 ← πt+1 + 0.25πt and πt−1 ←
πt−1 + 0.25πt.

To compare the different probability tuning strategies in
practice, we use the same batch size T = 10 < N , step size
τ = 0.9, and number of outer iterations ¯s = 15, 000 for all
the numerical experiments. From the practical point of view,
we noticed that the asynchronous algorithm would allow one
to select a larger step size (compared to the synchronous
algorithm), despite the large condition number of the problem
(κ ≈ 105). The tuning of the parameters is made to compare
with AMA. In particular, we selected the same τ and the
number of iteration of AMA is set to match the number of
iterations of SVR-AMA (¯s = 15, 000 × T /N ). This choice
is made to compare, given the same computation time, the
quality of the solution obtained using the synchronous and
the asynchronous algorithms.

Figures 2 and 4 show the open-loop predictions obtained

0102030405060−2.5−2−1.5−1−0.50NΠ  UniformPoissonPareto[6] L. Ferranti and T. Keviczky, “A Parallel Dual Fast Gradient Method
for MPC Applications”, Proc. of the 54th IEEE CDC, pp. 2406–2413,
2015, DOI:10.1109/CDC.2015.7402568.

[7] Y. Pu, M. N. Zeilinger, and C. N. Jones, “Fast Alternating Minimiza-
tion Algorithm for Model Predictive Control”, Proc. of the 19th IFAC
World Congress, pp. 11980-11986, 2014, DOI:10.3182/20140824-6-
ZA-1003.01432.

[8] S. Boyd et al., “Distributed optimization and statistical learning via
the alternating direction method of multipliers”, Foundations and
Trends R(cid:13) in Machine Learning, vol. 3, no. 1, pp. 1–122, 2011,
DOI:10.1561/2200000016.

[9] T. Goldstein, B. O’Donoghue, S. Setzer, and R. Baraniuk, “Fast Al-
ternating Direction Optimization Methods”, SIAM Journal on Imaging
Sciences, vol. 7, n. 3, pp. 1588–1623, 2014, DOI:10.1137/120896219.
[10] L. Xiao and T. Zhang, “A proximal stochastic gradient method with
progressive variance reduction”, SIAM Journal on Optimization, vol.
24, n. 4, pp. 2057–2075, 2014, DOI:10.1137/140961791.

[11] P. Tseng, “Applications of a splitting algorithm to decomposition
inequalities”, SIAM Jour-
in convex programming and variational
nal on Control and Optimization, vol. 29, n.1, pp. 119–138, 1991,
DOI:10.1137/0329006.

[12] P. Goupil et al, “An overview of the FP7 RECONFIGURE project:
industrial, scientiﬁc and technological objectives”, Proc. of the 9th
IFAC Symposium on SAFEPROCESS, pp 976–981, 2015.

[13] I. Notarnicola and G. Notarstefano, “Randomized dual proximal
gradient for large-scale distributed optimization”, Proc. of the 54th
IEEE CDC, pp. 712–717, 2015, DOI:10.1109/CDC.2015.7402313.

[14] S. Boyd and L. Vandenberghe, “Convex Optimization”, Cambridge

University Press, 2004.

[15] A. Bemporad, M. Morari, V. Dua, E.N. Pistikopoulos, “The explicit
linear quadratic regulator for constrained systems”, Automatica, vol.
38, n. 1, pp. 3–20, 2002, DOI:10.1016/S0005-1098(01)00174-1.
[16] J.-B. Hiriart-Urruty and C. Lemar´echal, “Convex Analysis and Mini-

mization Algorithms”, Springer-Verlag, 1993.

[17] A. Beck and M. Teboulle, “A fast iterative shrinkage-thresholding
algorithm for linear inverse problems”, SIAM Journal on Imaging
Sciences, vol. 2, n. 1, pp. 183–202, 2009, DOI:10.1137/080716542.

[18] Y. Singer, J.C. Duchi, “Efﬁcient learning using forward-backward
splitting”, Proc. of Advances in Neural Information Processing Sys-
tems, pp. 495–503, 2009.

[19] J. Langford, L. Li, T. Zhang, “Sparse online learning via truncated
gradient”, Proc. of Advances in neural information processing systems,
pp. 905–912, 2009.

[20] A. Nitanda, “Stochastic proximal gradient descent with acceleration
techniques”, Proc. of Advances in Neural Information Processing
Systems, vol. 27, pp. 1574–1582, 2014.
al,
Control
the
http://control.ee.ethz.ch/˜mpt.

“Multi-Parametric Toolbox 3.0”, Proc. of
2013,
pp.

[21] M. Herceg et
European

Conference,

502–510,

for the elevator command and the angle of attack using
different probability distributions. As expected, the predic-
tions are suboptimal. Nevertheless, it is interesting to note
that
the results obtained using the adaptive distribution,
given the same number of iterations and step size of the
other setups. The beginning of the horizon is solved with a
higher accuracy, while the tail of the horizon is almost never
updated. This does not affect the closed-loop performance,
as Figures 3 and 5 show. In particular, the behavior obtained
using the adaptive distribution outperforms the other setups,
given the same number of iterations. In particular, compared
to AMA and SVR-AMA with uniform distribution, within
the same number of iterations, SVR-AMA with adaptive
distribution reaches a higher level of suboptimality, which
can be a useful feature if the system has hard real-time
constraints and the number of iterations of the solver allowed
within the sampling time is small.

This simple, but illustrative, example clearly shows the ad-
vantages of tuning the probability distribution of the random
updates, in order to improve the quality of the estimates and
speed up the computation of the MPC problem solution.

VII. CONCLUSIONS

We presented an asynchronous alternating minimization
algorithm with variance reduction scheme suitable for model
predictive control (MPC) applications. As our numerical
example showed, the proposed algorithm outperforms a state-
of-the art solver (the alternating minimization algorithm) in
terms of number of iterations needed to reach a desired
level of suboptimality (i.e., when the solver terminates after
a ﬁxed number of iterations). Furthermore, the possibility
of tuning the probability distribution of the random updates
is an additional beneﬁt for MPC applications. In particular,
compared to other state-of-the-art asynchronous dual solvers
that only performs random updates according to a uniform
distribution, the proposed algorithm allows one to prioritize
the update of the variables at the beginning of the prediction
horizon, leading to improved behavior in closed loop, as our
numerical example showed.

As part of our future work, we aim to extend these
results to different splitting strategies and to formulate its
accelerated version.

REFERENCES

[1] T. Keviczky and G. J. Balas, “Receding horizon control of an F-16
aircraft: a comparative study”, Control Engineering Practice, vol. 12,
n.9, pp. 1023–1033, 2006,DOI:10.1016/j.conengprac.2005.06.003.
[2] D. Hrovat et al, “The development of model predictive control
in automotive industry: A survey”, Proc. of the IEEE Interna-
tional Conference on Control Applications , pp. 295–302, 2012,
DOI:10.1109/CCA.2012.6402735.

[3] S. Richter, C. N. Jones, and M. Morari, “Real-time input-constrained
the 48th IEEE
MPC using fast gradient methods”, Proc. of
CDC held jointly with the 28th CCC, pp. 7387–7393, 2009,
DOI:10.1109/CDC.2009.5400619.

[4] P. Patrinos and A. Bemporad, “An accelerated dual gradient-projection
algorithm for embedded linear model predictive control”, IEEE Trans-
actions on Automatic Control, vol. 59, n. 1, pp. 18–33, 2014, DOI:
10.1109/TAC.2013.2275667.

[5] G. Stathopoulos, T. Keviczky, and Y. Wang, “A hierarchical time-
splitting approach for solving ﬁnite-time optimal control problems”,
Proc. of the ECC, pp. 3089–3094, 2013.

Fig. 2: Control trajectories obtained using different probability distributions
Π in Algorithm 4 in open loop.

Fig. 3: Control trajectories obtained using different probability distributions
Π in Algorithm 4 in closed loop.

Fig. 4: Angle of attack trajectories obtained using different probability
distributions Π in Algorithm 4 in open loop.

Fig. 5: Angle of attack trajectories obtained using different probability
distributions Π in Algorithm 4 in closed loop.

00.20.40.60.811.2t[sec]u1[deg]  AMAUniformPoissonParetoAdaptiveOptimalBound00.20.40.60.811.2t[sec]u1[deg]  AMAUniformPoissonParetoAdaptiveOptimalBound00.511.52−1.5−1−0.500.51t[sec]α[deg]  AMAUniformPoissonParetoAdaptiveOptimal00.511.52−1.5−1−0.500.51t[sec]α[deg]  AMAUniformPoissonParetoAdaptiveOptimal