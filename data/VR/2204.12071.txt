2
2
0
2

p
e
S
2
2

]

C
H
.
s
c
[

3
v
1
7
0
2
1
.
4
0
2
2
:
v
i
X
r
a

Modeling the Noticeability of User-Avatar Movement Inconsistency
for Sense of Body Ownership Intervention

ZHIPENG LI, YU JIANGâˆ—, YIHAO ZHU, RUIJIA CHEN, RUOLIN WANG, YUNTAO WANG,
YUKANG YANâ€ , and YUANCHUN SHI, Tsinghua University, China

64

Fig. 1. A: We investigate the effect of user-avatar movement inconsistency on body ownership; B: We apply angular offsets
to the shoulder and the elbow joints and measure the probability of the user noticing the offset; C: We develop a model that
dynamically calculates a set of applicable offsets given a requirement for noticing probability; D: An rehabilitation application
of creating illusion of motor performance improvement with high body ownership E: A game application of changing physical
effort demand by applying offsets at some expense of body ownership, and F: A target selection application of sacrificing
body ownership for augmenting the userâ€™s input and thus reducing the physical burden.

An avatar mirroring the userâ€™s movement is commonly adopted in Virtual Reality(VR). Maintaining the user-avatar movement
consistency provides the user a sense of body ownership and thus an immersive experience. However, breaking this consistency
can enable new interaction functionalities, such as pseudo haptic feedback [45] or input augmentation [37, 59], at the expense
of immersion. We propose to quantify the probability of users noticing the movement inconsistency while the inconsistency
amplitude is being enlarged, which aims to guide the intervention of the usersâ€™ sense of body ownership in VR. We applied

âˆ—This work was done while Yu Jiang was an intern at Tsinghua University.
â€ Denotes as the corresponding author.

Authorsâ€™ address: Zhipeng Li, lzp20@mails.tsinghua.edu.cn; Yu Jiang; Yihao Zhu; Ruijia Chen; Ruolin Wang; Yuntao Wang; Yukang Yan;
Yuanchun Shi, Tsinghua University, Beijing, China, 100084.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that
copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first
page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy
otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from
permissions@acm.org.
Â© 2022 Association for Computing Machinery.
2474-9567/2022/6-ART64
https://doi.org/10.1145/3534590

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

 
 
 
 
 
 
64:2

â€¢ Li et al.

angular offsets to the avatarâ€™s shoulder and elbow joints and recorded whether the user identified the inconsistency through a
series of three user studies and built a statistical model based on the results. Results show that the noticeability of movement
inconsistency increases roughly quadratically with the enlargement of offsets and the offsets at two joints negatively affect
the probability distributions of each other. Leveraging the model, we implemented a technique that amplifies the userâ€™s arm
movements with unnoticeable offsets and then evaluated implementations with different parameters(offset strength, offset
distribution). Results show that the technique with medium-level and balanced-distributed offsets achieves the best overall
performance. Finally, we demonstrated our modelâ€™s extendability in interventions in the sense of body ownership with three
VR applications including stroke rehabilitation, action game and widget arrangement.

CCS Concepts: â€¢ Human-centered computing â†’ User models; User studies.

Additional Key Words and Phrases: Virtual Reality, visual illusion, user behavior modelling

ACM Reference Format:
Zhipeng Li, Yu Jiang, Yihao Zhu, Ruijia Chen, Ruolin Wang, Yuntao Wang, Yukang Yan, and Yuanchun Shi. 2022. Modeling
the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention. Proc. ACM Interact. Mob.
Wearable Ubiquitous Technol. 6, 2, Article 64 (June 2022), 26 pages. https://doi.org/10.1145/3534590

1

INTRODUCTION

While wearing a Virtual Reality (VR) head-mounted display (HMD), the user cannot see their own body in
the physical world. Instead, they usually embody virtual avatars mirroring their motions from a first-person
perspective. In this manner, they have the sensation that their own body is substituted by the avatar and receive a
strong sense of body ownership [11, 18, 53]. The motion consistency between the user and the avatar is essential
to maintaining immersion in VR. However, breaking the consistency can enable new interactions with powerful
functionalities, including input augmentation [29, 31] and pseudo-haptic feedback such as weight simulation in
VR [45] at the expense of body ownership. Yet, there lacks a thorough understanding of how this cost of body
ownership changes as the movement inconsistencies become more significant, or more fundamentally, how the
noticeability of the inconsistency reacts to the amplitude enlargement. This knowledge can guide interaction
technique implementations to maintain the sense of body ownership to the extent required for an immersive
experience while exploiting movement inconsistency for novel interactions.

We explored arm movement inconsistency as it is one most agile and frequently-used body parts (Fig 1A).
Since movement can be dissected into a series of poses, we start by investigating pose inconsistency, which
can be implemented by applying angular offsets to the arm joints. Instead of directly modeling the effects of
inconsistency on the sense of body ownership, we decide to first investigate on our first research question RQ1:
how strength of arm movement inconsistency affect the probability of it being noticed. We then hope to leverage
this knowledge to provide guidelines on the applicable range of movement inconsistency that be highly useful in
supporting applications with various levels of the sense of body ownership requirements. This, therefore, raises
our second research question RQ2: how to leverage applicable inconsistency in building interaction techniques
with different body ownership requirements?

To answer RQ1, we conducted three user studies to quantify the noticeability of movement inconsistency on
single and both arm joints in various directions. We first investigated varying the strength of offset on single
joint at orthogonal axes separately. Then we explored how offset direction influences the noticeability. Finally we
quantify the offset noticeability for composite two-joint offsets (Fig 1B). The user studies show that inconsistency
noticeability increases roughly quadratically with stronger offsets yet the effect vary across axes, with a 13.31
degree offset strength having an average 50% inconsistency noticing probability, and it remains roughly the same
at different offset directions. Finally, the probability distributions at two joints interacts negatively with each
other.

In answering RQ2, we leveraged the results to construct a statistical model which outputs a set of applicable
composite two-joint offsets given the requirement for noticeability and a arm pose. Based on the model, we

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:3

proposed an example optimization goal of continuous amplification and implemented an interaction technique
leveraging offset-applied movement with a maximum 75% offset noticeability (Fig 1C). To be noted, other than
this example, the model has the potential to support building various applications with different body ownership
requirement and different optimization goals. We evaluated the technique and compared how offset level and
offset distribution between two joints affect the efficiency of task completion and interaction experience. The
results show that the offset could significantly reduce the moving time and distance while a medium-level offset
does not compromise the sense of body ownership. Offset distribution between the shoulder and the elbow doesnâ€™t
affect interaction efficiency, yet a balanced distribution improves interaction experience and helps maintain body
ownership.

To demonstrate the extendability of our model in intervention in the sense of body ownership, we developed
three applications that have different requirements for body ownership. The motivating stroke rehabilitation
application aims to provide a body illusion that requires high body ownership. We thus apply unnoticeable offsets
to the virtual avatarâ€™s movement so that the user perceives a motor performance improvement virtually and
therefore gains stronger engagement [13] (Fig 1D); For the VR action game, which requires less body ownership,
we adjust the level of the offset to change the demand for physical effort from users(Fig 1E); Augmenting input
on tasks such as widget arrangement sacrifices body ownership for augmentation functionalities. We thus apply
strong offsets to amplify the userâ€™s motion to reduce usersâ€™ physical burden (Fig 1F).

This paperâ€™s contributions are three-fold:

â€¢ We thoroughly investigated the statistical relationship between the applied offset and its noticeability on
static poses. Results show that the noticeability rises as the offsets increase in strength with roughly the
same tendency for offsets in different directions. The offsets on the shoulder and elbow interact negatively
with each other.

â€¢ We leveraged the obtained knowledge to build a statistical model which predicts a set of applicable offsets
on the shoulder and the elbow when given a noticeability requirement and a arm pose as inputs. We will
open-source our model upon acceptance of this work.

â€¢ We implemented an input augmentation technique with the model. We evaluated the technique and
developed three applications with different body ownership requirements to demonstrate the extendability
of the model.

2 RELATED WORK
2.1 Body Ownership in VR

The illusion of body ownership refers to a person considering a non-bodily object as part of their own body. One
of the most famous studies is the rubber hand illusion [9], where the user has an illusion that the rubber hand is
part of their body and reacts strongly to any harm done to the rubber hand.

VR can provide an immersive experience of body ownership illusion [30, 53, 54] as well as affecting the userâ€™s
cognition [36], perception [57], emotion [12] and behavior [2]. For instance, Jun et al. [12] investigated whether the
virtual avatarâ€™s facial expression can modulate the userâ€™s emotion with the illusory feeling of full-body ownership
of a virtual avatar. Leveraging motion capture systems [33, 60] researchers reconstruct the userâ€™s physical motion
and render the virtual avatar mirroring the motion to provide a strong sense of body ownership [18, 35, 48, 52, 63].
Since the arm is one of the most flexible and functional body parts, a number of works tried to provide the illusion
of body ownership on a virtual arm [4, 15, 16, 26]. Lorraine et al. [26] investigated how the appearance of a virtual
hand affects the own-body perception and found that a realistic human hand model elicits the strongest illusion.
Ryan et al. [4] investigated the influence of different hand visualizations on body ownership of grasping objects
in VR, and the optimal visualization was to not penetrate the object while grasping, which complies with reality.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:4

â€¢ Li et al.

Most of the previous research focused on the precision of reconstructing and visualizing the userâ€™s real motion
to elicit body ownership illusion. However, research on what precision level is sufficient for providing the illusion
of body ownership and how differences between physical and virtual motions affect the illusion is very limited.
In this paper, we intentionally add motion differences and quantify their influences on the userâ€™s illusion of body
ownership.

2.2 Modifying the Virtual Motion

Instead of reconstructing the motion as precisely as possible, previous research also intentionally broke the
consistency for useful functionalities in VR, including input augmentation, redirect walking, and pseudo-haptic
feedback.

One of the most widespread applications is input augmentation. Researchers leveraged the modified movement
to change the movement speed or the arm length [8, 24, 29, 37, 59]. The Go-Go [37] technique extends the position
of the hand in-depth non-linearly, enabling users to interact with objects beyond reach. The PRISM technique [8]
applied an offset dynamically based on the userâ€™s hand speed to reach distant objects. However, these techniques
prioritize input augmentation and neglect the reduction in body ownership. Li et al. [24] compared four different
motion amplification methods and found that large offsets reduced the feelings of immersion and body ownership.
Ownershift [7] proposed to slowly put the userâ€™s physical hand down while the virtual hand remains high for
interaction. Thus the user could maintain ownership of the virtual hand while with the reduced arm fatigue.
Wentzel et al. [59] proposed to amplify the hand position in-depth with an adaptive function that keeps the userâ€™s
reach within reasonable bounds. Thus it could increase physical comfort while maintaining task performance
and body ownership.

On the other hand, a line of research on redirect walking [41, 42, 55] modifies the perceived forward direction
of users so that they feel like walking straight while actually advancing in circles. This expands a finite space
in reality with infinite virtual space. Rietzler et al. [42] proposed to modify the userâ€™s head rotation to enable
directional changes without any physical turns. Thus the user could always be on an optimal circular path inside
the real world while walking freely inside the virtual world.

Another functionality is the providence of the pseudo-haptic feedback [1, 21, 22, 38, 39]. The offset between the
real and the virtual hand produces the illusion of stiffness while the user is pushing against a virtual object [22].
Pusch et al. [38, 39] used visual hand displacements to create a feeling of wind resistance. It can also be used
to simulate the weight of objects in VR [6, 10, 32, 34, 43, 45]. For instance, Samad et al. [45] leveraged the ease
in moving light objects compared to heavy ones and manipulated the control-display ratio between the userâ€™s
movement and the visualization of the movement to induce an illusory perception of weight.

These techniques show that breaking the movement consistency can enable new interaction functionalities at
the expense of body ownership. However, researchers apply offsets with their own purposes but have limited
understanding of the cost of body ownership, to which extent the users notice the inconsistency. Thus we propose
to quantify the effect of movement inconsistency on the noticeability and finally the sense of body ownership.
We expect the proposed model to serve as a tool for designing and implementation interaction techniques with
different requirements.

3 METHODOLOGY

We term user-avatar movement inconsistency as the differences between the key joint positions of the userâ€™s
physical body and the avatarâ€™s virtual body. To understand how the inconsistency influences the userâ€™s sense of
body ownership, we intentionally add offsets to the avatar body and measure how the possibility of the user
noticing the difference increases as we enlarge the offset. Specifically, we define an offset as noticeable when users
can detect the movement inconsistency and do not perceive the avatarsâ€™ bodies as their own when it is added. In

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:5

this section, we introduce the methodology to quantify the relationship between the movement inconsistency and
the sense of body ownership step by step. Before that, we first formulate the problem and discuss the hypothesis.

3.1 Selecting the Left Shoulder and Elbow for Investigation

Based on existing research, we extend to study the motion modification on more than one key joint. Before being
able to conduct full-body motion modification, which requires controlling a very large number of degrees of
freedom, we decided to investigate adding offsets on limbs composed of several connected key joints as the first
step. We chose the shoulder and the elbow of the left arm to apply offsets. Since the arm is one of the most
agile and frequently-used body parts, we assume that the user will be more sensitive towards the movement
inconsistency of the arm compared to other body parts. We expect the approach on these two key joints to be
applicable and extendable to other body parts, potentially containing more than two joints.

3.2 Defining an Arm Pose

As previous studies explored the effect of scaling the lengths of the upper arm and the forearm on embodiment [29,
59], we focus on how rotational changes at the shoulder joint and the elbow joint affect the sense of body ownership.
We thus employed the spherical polar coordinate system, which defines the position of a point with its distance
to the origin ğ‘Ÿ , its polar angle ğœƒ , and its azimuthal angle ğœ™, instead of the Cartesian coordinate system, which
represents a point in space with a triplet (ğ‘¥, ğ‘¦, ğ‘§). The former releases us from considering the length of the limb.
As shown in Figure 2, we define an arm pose by a pair of angular coordinate (Î¦s, Î˜s) and (Î¦e, Î˜e). The elbow
coordinate is relative to the shoulder joint and the two axes are orthogonal with the upper-arm. We summarize
our parameterization of the upper limb and the according offset in Table 1.

Table 1. Symbols used to represent
the axis angles and offsets.

Position Axis Angle Offset

Shoulder
Shoulder
Elbow
Elbow

ğœ™
ğœƒ
ğœ™
ğœƒ

Î¦ğ‘ 
Î˜ğ‘ 
Î¦ğ‘’
Î˜ğ‘’

ğœ™ğ‘ 
ğœƒğ‘ 
ğœ™ğ‘’
ğœƒğ‘’

Fig. 2. The spherical polar coordinate systems
where we calculate the shoulder and the elbow
joint coordinates. The coordinate system of the
shoulder is relative to the body and that of the
elbow is relative to the upper-arm.

3.3 Hypothesis

In investigating the effect of applying angular offsets on the sense of body ownership, we raise three hypotheses
about the relationship between the interested variables, which were later testified by user studies. The hypotheses
are as follow:

â€¢ H1: The stronger the offsets applied, the more likely users will notice the user-avatar inconsis-
tency. Smaller angular offsets might be unnoticeable, yet larger ones might result in significant and obvious
changes in arm pose (e.g. curving an unbend real arm). We hypothesize that users are more likely to notice
offsets when larger offsets are applied.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:6

â€¢ Li et al.

â€¢ H2: Usersâ€™ sensitivity towards the offsets vary at different directions. Offsets at different directions

could affect how the user observes the arm pose and thus the userâ€™s sensitivity towards offsets.

â€¢ H3: Usersâ€™ sensitivities towards the shoulder and elbow joint offsets are dependent. Since applying
offsets at the shoulder passively affects the elbow position, we assume that shoulder offsets affect the
sensitivity towards offsets at the elbow.

Fig. 3. Left: the participant wears a bodysuit with three markers tracked by the Optitrack motion capture system. He
wears the VR headset and sits on a comfortable chair during the study; Right: the experimental avatar from a third-person
perspective. The virtual avatar mirrors the arm movement of the participant, and a semi-transparent arm is rendered to
indicate the target arm pose.
3.4 Task Design for Noticeability Test

We designed a task to test whether the users lose their sense of body ownership when an offset is applied to the
virtual arm of the avatar at a certain arm pose. During each task, the position of the left shoulder and elbow of
the user is tracked by a marker-based motion capture system. The virtual avatarâ€™s arm is constructed such that it
deviates from the physical arm by a fixed angular offset no matter where the user moves their arm to. Then to
guide the user to perform a target arm pose, we render a semi-transparent virtual arm attached to the avatarâ€™s
body and ask the user to adjust the virtual arm until it overlaps with the semi-transparent arm exactly. After that,
we remove the semi-transparent arm and ask whether participants perceive the virtual arms exactly as their own
arms, as shown in Fig 3. The participants are told to help evaluate the tracking precision of the motion capture
system to avoid them suspecting the existence of offsets. As the output, we counted the number of participants
who identified an offset between their physical arm pose and that of the virtual avatar for each offset. With an
offset, we statistically simulate its offset noticing probability by the percentage of the participants who notice the
inconsistency and leverage such probability as the metric for the strength of the sense of body ownership over
the virtual avatar.

As the tasks test different offsets, directly reapplying the offsets onto the virtual arm results in visual glitches,
which might impair body ownership. To avoid this, we asked users to close their eyes for a short rest while
switching the tasks. The system will play a prompt tone when the switch was done and users open their eyes to
judge if the virtual arms are their own arms. If they recognize the virtual arm poses same as their own arms, they
press button A on the controller held in their right hands and button B otherwise. In a warm-up session before
the experiment, participants perform ten tasks testing all arm poses without offsets, and we orally reminded
them to close their eyes after each task to help them get familiar with the procedure. One of the most frequently
used evaluations of body inconsistency noticeability is questionnaires [3, 7, 14]. However, the questionnaire
is not appropriate in our experiment since users are asked to evaluate the body ownership instantly for every

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:7

combination of pose and offset. Therefore, we adapted a quantitative method to evaluate the body inconsistency
noticeability which is similar to [59].

3.5

Investigating Composite Two-joint Offsets

Considering the extremely large space of adding angular offsets (of different strengths and in different directions)
to two joints in combination, we decide to investigate how the offsets influence body ownership in a bottom-up
flow in four steps.

In the first step, we only added angular offsets to each jointâ€™s two orthogonal directions separately. Without
the complication of different directions, this enabled us to test the strength of the offset with a resolution of 3
degrees in 11 levels. We performed the noticeability tests in each level condition and precisely measured how
offset strength related to the offset noticing probability. Then in the second step, we extended our investigation
to offset directions and tested the directions in the entire space with a resolution of 15 degrees in 24 levels.
Considering the time and effort requirements, we shortened the testing range of offset strength to 12 to 24 degrees
with the same resolution of 3 degrees. Until then, we achieved an overall understanding of how angular offsets
on a single joint affect their noticeability. So in the third step, we looked into the condition of two offsets being
applied on the shoulder and the elbow at the same time. Our goal was to model the relationship between the
noticeability of composite two-joint offsets and the offset noticing probability at each joint. However, the position
of the elbow, as well as the forearm pose, are passively impacted by offsets applied at the shoulder. We thus first
sampled the offsets with the same strength in 8 directions to apply to the shoulder and then tested the offsets of
4 strength levels and in 8 directions to apply to the elbow. We observed how the composite two-joint offsetâ€™s
noticeability differs from that of offset applied only at the elbow to model their relationship further. Then in the
final step, based on the data we collected in the sampled angular offset space, we applied bi-dimensional linear
interpolation to build a statistical model, which can calculate the probability of noticing the offset with a given
composite two-joint offset and a pose.

Fig. 4. The 10 upper left arm poses tested in the following experiments, with the shoulder and elbow joints highlighted as
red balls.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:8

â€¢ Li et al.

3.6

Investigating the Effects of Arm Poses

We consider the arm pose as an extra factor of the userâ€™s sensitivity to noticeability of inconsistency. Through
several pilot tests, we identified that compared to bent arm poses, users were more sensitive towards any offset
applied to either joint when users raised their arms forward. So we also varied the arm poses, characterized by
their jointsâ€™ rotational angles, while adding each angular offset in the studies. Considering our limited capacity of
human labor for data collection and the infeasibility of covering the entire space of human poses, we tested 10
different arm poses. To ensure that the sampled poses are representative, we sampled 6 poses from CMU MoCap
database [20] consisting of motion-captured data of over 2500 motion sequences and over 200000 human poses
with joint positions in real human activities. We added 4 poses to cover the extreme poses at which we believed
the user would have the highest sensitivity. We randomly sampled 50000 frames and clustered them with the
HDBSCAN algorithm [28] using the skeletal distance function given by Shakhnarovich et al. [50]. Given ğ¿ joints
in the pose, the distance between two poses ğ›¼1 and ğ›¼2 can be calculated by

Distance(ğ›¼1, ğ›¼2) = max
1â‰¤ğ‘– â‰¤ğ¿

âˆ‘ï¸

ğ‘‘ âˆˆğ‘¥,ğ‘¦,ğ‘§

(ğ›¼ğ‘–

ğ‘‘,1 âˆ’ ğ›¼ğ‘–

ğ‘‘,2)

(1)

with ğ‘¥, ğ‘¦, ğ‘§ being the locations of the joint. We added raising arm forward, raising arm upward, raising arm to
the side, and putting arm downward as the extreme cases. Fig 4 shows the 10 sample poses with their parameters
listed the supplementary material.

4

INVESTIGATION OF THE TWO-JOINT OFFSET NOTICING PROBABILITY

In this section, we conducted three user studies to confirm whether our hypotheses are correct. Specifically,
we investigated the effect of angular offset on offset noticing probability on two orthogonal axes at a joint,
two-dimensionally at both joints, and on the two joints compositely. All user studies had been approved by our
universityâ€™s IRB board.

4.1 Phase 1: Investigating the Strength of the Offset

We first investigated the effect of offset strength on the offset noticing probability by testing offset values of
different strength on the four axes separately for the sampled 10 poses.

4.1.1 Design. The target poses (Section 3.6) set as a control factor, which sample the space and are representative
of human upper left limb poses. The independent variable is the single axis offset value. The dependent variable is
offset noticing probability which we measure by the metric whether the offset is noticeable with the applied offset
on a pose. The study was conducted based on the procedure described in Section 3.4. We tested offset values
ranging from âˆ’15 to 15 degrees with a 3 degree interval for each of the four axes. Each participant thus evaluated
11offset values Ã— 4axes Ã— 10target poses = 440 tasks in a random order. Each participantâ€™s data collection was
divided into 3 sessions with a five-minute break between sessions to avoid fatigue, lasting around 40 minutes in
total.

4.1.2 Participants. We recruited 12 participants from a local university(6 male, 6 female) with an average age of
21.15 (SD = 1.68). All participants were right-handed. The self-reported familiarity with VR score averages at 3.62
(SD = 1.26) with a 7-point Likert scale from 1 (not at all familiar) to 7 (very familiar).

4.1.3 Apparatus. We developed a VR system to investigate whether an offset on a pose is noticeable, which was
developed in Unity 2019 for the Oculus Quest2 headset powered by an Intel Core i7 CPU and an NVIDIA GeForce
RTX 3080 GPU. The participant performed the experiment in a seated position and wore an adhesive bodysuit
with three Optitrack rigid body trackers tagged at the left shoulder, elbow, and waist. We reconstructed the user

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:9

Fig. 5. The offset noticing probabilities with offset values for the ğœ™ and ğœƒ axes at the shoulder and the elbow joints at Pose 2.
The blue lines show the probabilities at the sampled offset values and the orange curves show the fitted quadratic curves.

movement based on the Optitrack data on a virtual humanoid (male or female) avatar with the userâ€™s viewpoint
coinciding with the avatarâ€™s. An example scene is shown in Fig 3.

4.1.4 Result. For each axis, we plotted the offset noticing probability with offset value for four axes for each
pose. An example based on pose 2 is shown in Fig 5. Please refer to the supplementary material for the complete
result. For each subfigure, the x-axis is the offset value, and the y-axis is the probability of noticing the offset. We
used a quadratic polynomial function to fit the data points with a root mean squared error of 0.034. The figures
demonstrate that the offset noticing probability increases roughly quadratically with stronger offsets.
Also, the effect of offset strength on the offset noticing probability varies on each axis and for each pose. With the
fitted relationship, the offset noticing probability given a single axis offset can thus be interpolated. The quadratic
relationship confirmed the H1.

4.2 Phase 2: Investigating the Direction of the Offset

We then explore how the offset noticing probability is affected by the direction of the offset by testing two-
dimensional offset values.

4.2.1 Design. The control factor and the dependent variable are kept the same with Section 4.1.1 and the
procedure similarly followed Section 3.4. We set the independent variable as two-dimensional offsets at a joint
which applies an offset with a certain value at a direction. We sampled two-dimensional offsets on circles with a
radius ranging from 12 to 24 degrees with a 3 degree interval and with a 15 degree interval between neighboring
points on each circle as shown in Fig 6a. The x-coordinate indicates the offset to be applied at the ğœ™ axis while the
y-coordinate indicates the offset to be applied at the ğœƒ axis. The data range was chosen considering the large data
size in sampling points two-dimensionally and our focus on investigating the offset noticing probability trend,
which we could expect to be significant between 12 to 24 degrees as informed by the result in Phase 1 (Section 4.1).
Given the massive task number that one participant need to finish, we conducted tests at two joints for four poses
to shorten the experiment time and reduce the influence of fatigue. Base on the data collected on these four poses,
we concluded the two-dimensional offset noticing probability distributions and validated the hypothesis. Each
participant thus performed 24 two-dimensional offsets per circle Ã— 5 circles Ã— 2 joints Ã— 4 poses = 960 tasks in a
random order. Each participantâ€™s data collection was divided into 8 sessions with a five-minute break between
sessions to avoid fatigue, lasting around 90 minutes.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:10

â€¢ Li et al.

4.2.2 Participants. We recruited 12 participants including 6 males and 6 females. The participantsâ€™ age ranged
ranged from 20 to 24 (ğ´ğ‘‰ ğº = 21.92, ğ‘†ğ· = 1.57). All participants were right-handed. The self-reported familiarity
score averages at 3.17 (SD = 1.69) with a 7-point Likert scale from 1 (not at all familiar) to 7 (very familiar).

4.2.3 Apparatus. The apparatus remains the same with Section 4.1.3.

4.2.4 Result. We performed the linear interpolation on the collected data points to display heatmaps of offset
noticing probability distributions. Fig 6b shows an example for the shoulder joint and elbow joint probability
distributions for pose 2. Please refer to the supplementary material for the complete result. The x-axis and y-axis
are the ğœ™ and ğœƒ offset values. The color intensity indicates the offset noticing probability with darker color
indicating a lower probability in noticing the offset between visual and the real arm pose. Observe from Fig 6b
that the shape of probability distribution on two-dimensional offsets roughly resembles an oval. Based on this
data we can bi-dimensionally interpolate the offset noticing probability at a joint with a given two-dimensional
joint offset. Similarly, the two-dimensional offset values at a given probability in each quadrant resemble a quarter
oval bounded by the single-axis offset values at the same probability. This visual observation is uniform for two
joints of all four poses we collected data on. With a given probability value, we thus fitted a quarter-oval curve
at each quadrant with a function parameterized by its two single-axis offset values at each joint for each pose.
Based on the fitted relationship, for pose (ğ‘) and at joint ( ğ‘—) the two-dimensional offset (ğ‘¥, ğ‘¦) at a probability of
interest can be characterized by Equation 2 in different quadrants. ğœ™ ğ‘—Â± and ğœƒ ğ‘—Â± represent the positive/negative
single-axis offset values at that probability at the ğœ™ and ğœƒ axes respectively. For pose 2, the root mean square
error was 2.03 for the 90% probability fitted curve, 1.34 for the 70% curve, 1.04 for the 50% curve, 1.03 for the 30%
curve. The quadratic relationship rejected H2 since the offset noticing probabilities in different directions
are roughly the same.

Offsets on joint j of a given probability:

ğ‘¥ 2
ğœ™ 2
jÂ±

+

ğ‘¦2
ğœƒ 2
jÂ±

= 1

(2)

4.3 Phase 3: Investigating the Composite Two-joint Offset Noticing Probability

Since applying offsets at the shoulder passively affects the elbow position, we thus hypothesized that the composite
two-joint offset noting probability is dependent on such probabilities on the shoulder and elbow joints. In this
section, we applied different offsets at the shoulder joint to observe how the probability at the elbow joint
transforms.

4.3.1 Pilot Study. Due to the difficulty of large scale and dense data collection needed to investigate the two-joint
offset noticing probability, we conducted a pilot study to gain more understanding into the transformation to
aid targeted data collection in the formal study. We conducted a pilot study on 2 poses with 4 participants.
We applied two shoulder joint offsets of different directions for each of the two poses. For pose 2, we applied
offsets in the first and the third quadrants diagonally at 45 degrees. Respectively, for pose 2, we applied offsets
in the second and the fourth quadrants. The value of the shoulder offset corresponds to 30% offset noticing
probability. We did noticeable offset tests for the elbow joint at points ranging from 9 to 24 degrees with
a 3 degree interval to explore the transformation. We recruited 4 participants and each of them evaluated
2shoulder offsets Ã— 6elbow offset sampling circles Ã— 24elbow offsets sampled per circle Ã— 2target poses = 576 tasks in
a random order.

The pilot studyâ€™s results are shown in Fig 7. Similar to the previous study, the heat maps made using linear
interpolation between data points represent the offset noticing probability. The yellow stars show that offset
applied at the shoulder joint relative to the origin.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:11

(a)

(b)

Fig. 6. (a) Sample points for the offset noticeable tests: we tested directions 15 degrees apart, and in each direction we
tested points from 12 to 24 degrees with a 3 degree interval. (b)The relationship between two-dimensional offsets and the
probability of noticing the offset at Pose 2. The heatmaps indicate the probability with darker color representing a lower
noticing probability. Two-dimensional offset values with 90%, 70%, 50%, 30% noticing probabilities are shown. In each figure
the black/grey oval indicates the raw offset value while the red oval indicates the fitted offset value at the probability. The
stars in each figure illustrates the single axis offset values at that probability, interpolated from Section 4.

Observe from the heat maps that the two-dimensional offset noticing probability distribution at the elbow
joint shifts in the opposite direction of the shoulder joint offset direction. The shift amount is roughly the same
as the shoulder joint offset amount. Meanwhile, the probability distribution pattern stays roughly the same.

4.3.2 Design. Based on the pilot study results, we conducted an experiment to further investigate the direction
and amount of the elbow probability distribution shift. The control factor and the dependent variable are
kept the same with Section 4.1.1 and the procedure similarly followed Section 3.4. We set the independent
variable as a composite two-joint offset composed of two two-dimensional offsets, one at the shoulder and the
other at the elbow. We sampled eight two-dimensional offsets at the shoulder directionally 45 degrees from
each other starting from the horizontal axis and at values with 30% noticing probability. For each shoulder
offset, we sampled the elbow joint two-dimensional offsets on circles shifted away from the origin opposite
to the direction of the shoulder joint offset and by the amount of the shoulder offset value. The circlesâ€™ radius
range from 9 to 24 degrees with a 3 degree interval and we sampled eight offsets spread evenly on each
circle. We conducted data collection on four poses to validate the hypothesis. Each participant thus evaluated
8shoulder offsets Ã— 4elbow offset sampling circles Ã— 8elbow offsets sampled per circle Ã— 4target poses = 1024 tasks.
Each participantâ€™s data collection was divided into 8 sessions with a five-minute break between sessions to avoid
fatigue, lasting 90 minutes in total.

4.3.3 Participants. We recruited 12 participants including 8 males and 4 females. The participantsâ€™ age ranged
ranged from 19 to 26 (ğ´ğ‘‰ ğº = 21.33, ğ‘†ğ· = 1.28). All participants were right-handed. The self-reported familiarity
score averages at 3.08 (SD = 1.11) with a 7-point Likert scale from 1 (not at all familiar) to 7 (very familiar).

4.3.4 Apparatus. The apparatus remains the same with Section 4.1.3.

4.3.5 Result. Pose two examples of the elbow joint two-dimensional offset noticing probability affected by
shoulder joint offsets of different directions are shown in Fig 8. Refer to the supplementary material for a complete
result. The blue stars are the center of the shifted elbow joint offset noticing probability distribution interpolated

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:12

â€¢ Li et al.

and the yellow stars show the applied shoulder joint offset. From the illustration, we found that the elbow
joint offset oval shifts diagonally from the shoulder offset direction and for the same amount as the shoulder
joint offset. Thus for offsets ğœ™s and ğœƒs applied at the shoulder, the position of the shifted elbow joint probability
distribution is centered at (âˆ’ğœ™s, âˆ’ğœƒs). We thus confirmed H3 since the probability distributions at two joints
negatively and linearly affect each other when predicting the probability of noticing the offset with
a given composite two-joint offset. Therefore, given a composite two-joint offset, we can interpolate its
probability of being noticed by the user.

Fig. 7. The noticing probability distribution of the
composite offset with different shoulder offsets ap-
plied in the pilot study. The yellow stars label the
applied shoulder offset. The darker color represents
the lower noticing probability.

Fig. 8. The noticing probability distributions of the compos-
ite offsets with different shoulder offsets applied at Pose 2.
The heatmaps indicate the probability with darker color rep-
resenting a lower noticing probability. The yellow stars label
the applied shoulder joint offset and the blue stars are the
interpolated elbow probability distribution center. The black
dotted circles outline the task range.

5

IMPLEMENTATION OF THE OFFSET MODEL AND THE MOVEMENT AMPLIFICATION
TECHNIQUE

Based on the results in Section 4, we quantify how the user-avatar movement inconsistency affects the sense of
body ownership. Given an offset and a pose, we are able to interpolate the probability of noticing the offset. We
obtain applicable offsets with a given acceptable offset noticing probability and a pose and adapt it to continuous
movement in this section. Then we adapt it to continuous movement and implement an amplification technique
as an instance of the model.

5.1 Constructing the Model of Applicable Composite Two-joint Offsets

Leveraging the quantified relationship between the offset applied and the offset noticing probability, we construct
a statistical model which outputs a set of applicable composite two-joint offsets given an offset noticing probability
and a pose. With the explored offset noticing probability in Section 4, we build a statistical model to give out the
offsets with a given noticing probability and pose.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:13

Fig. 9. The three-step model of the offset with a given probability and pose. The left interpolates the single axis offsets with
the given probability. The middle shows the two-dimensional offset with noticing probability equal to or less than the given
probability on two joints separately. The right illustrates the composite two-joint offset with noticing probability equal to or
less than the given probability.

Fig 9 outlines the modelâ€™s pipeline. With an acceptable offset noticing probability p, we first interpolate the
single axis offset values at p for all 10 poses and 4 axes based on the findings in Section 4.1. Then for each axis,
we fitted a relationship between the pose and the offset value at that axis based on which we can calculate the
four single axis offset values (Î¦s, Î˜s, Î¦e, and Î˜e) at p for any pose by Equation 3. A, B, C, D, and E are fitted
parameters of the relationship.

Then based on the characterized relationship between four single axis offsets (ğœ™s, ğœƒs, ğœ™e, and ğœƒe) and the
two-dimensional offsets at a given probability for the shoulder and the elbow respectively in Equation 2, we can
interpolate the applicable oval-shaped two-dimensional offset for both joints with offset noticing probability
p. Note that the applicable two-dimensional offsets are any point within the oval shape with offset noticing
probability equal to or less than the required p.

Section 4.3 defines the negative linear relationship between the elbow joint offset noticing probability and
the shoulder joint offset noticing probability. The applicable composite two-joint offset is thus composed of
the applicable shoulder joint offsets at p and the accordingly shifted applicable elbow joint offsets at p with a
determined shoulder offset.

Â± {ğœ™, ğœƒ } {ğ‘ ,ğ‘’ } = ğ´ Ã— Î¦s + ğµ Ã— Î˜s + ğ¶ Ã— Î¦e + ğ· Ã— Î˜e + ğ¸

(3)

Algorithm 1 illustrates the algorithm procedure.

5.2

Implementation of the Dynamic Movement Amplification Technique

With a set of offsets of a specific probability, we could implement various functionalities by choosing different
offsets. In this section, we implemented a dynamic amplification technique to demonstrate the usability and
extendability of the model. Wentzel [59] proposed a guideline for simulating such continuous movement which
states that the modified motion should be continuous and should conform to ergonomics. A continuous movement
can be defined with a series of poses. Sampling poses within the movement and calculating their maximum
offsets is onerous and demanding. Furthermore, based on our model these static posesâ€™ offsets might vary and
do not necessarily adhere to a monotonic relationship. Directly applying the maximum unnoticeable offset

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:14

â€¢ Li et al.

ğ‘ ğ‘–, ğœƒ ğ‘

ğ‘’ğ‘–, ğœƒ ğ‘

ğ‘ ğ‘–, ğœ™ğ‘

Algorithm 1 Calculate the offsets of a specific noticing probability for an arbitrary pose
Input: Given pose(ğ´ğ‘ , ğµğ‘ , ğ´ğ‘’, ğµğ‘’ ), Given noticing probability ğ‘,
Output: A set of offsets of the given probability{(ğ›¼ğ‘
ğ‘’ , ğ›½ğ‘
1: (ğœ™ğ‘

ğ‘  , ğ›½ğ‘
ğ‘’ğ‘– ) â† ğ‘“ (Î¦ğ‘ ğ‘–, Î˜ğ‘ ğ‘–, Î¦ğ‘’ğ‘–, Î˜ğ‘’ğ‘– ) ğ‘– = 1, 2, . . . , 10

2: ğ‘”(Î¦ğ‘ , Î˜ğ‘ , Î¦ğ‘’, Î˜ğ‘’ ) â† ğ‘”(ğœ™ğ‘

ğ‘ ğ‘– is the ğœ™ offset on shoulder joint with
probability ğ‘ on the ğ‘–th sample pose. ğ‘“ (Î¦ğ‘ ğ‘–, Î˜ğ‘ ğ‘–, Î¦ğ‘’ğ‘–, Î˜ğ‘’ğ‘– ) is the quadratic function fitted in Section 4.1 on the
ğ‘–th sample pose(Î¦ğ‘ ğ‘–, Î˜ğ‘ ğ‘–, Î¦ğ‘’ğ‘–, Î˜ğ‘’ğ‘– ).
ğ‘ ğ‘–, ğœ™ğ‘
ğ‘’ğ‘–, ğœƒ ğ‘

âŠ² ğ‘”(Î¦ğ‘ , Î˜ğ‘ , Î¦ğ‘’, Î˜ğ‘’ ) is the function
fitted with Equation 3 which takes in any pose (Î¦ğ‘ , Î˜ğ‘ , Î¦ğ‘’, Î˜ğ‘’ ) and outputs the offset on four axes with the
given probability ğ‘.
ğ‘’ , ğ›½ğ‘

ğ‘’ ) are the four single axis offsets with the given noticing

ğ‘’ğ‘–, Î¦ğ‘ ğ‘–, Î˜ğ‘ ğ‘–, Î¦ğ‘’ğ‘–, Î˜ğ‘’ğ‘– ) ğ‘– = 1, 2, . . . , 10

ğ‘’ ) â† ğ‘”(ğ´ğ‘ , ğµğ‘ , ğ´ğ‘’, ğµğ‘’ ) âŠ² (ğ›¼ğ‘

3: (ğ›¼ğ‘

ğ‘ ğ‘–, ğœƒ ğ‘

ğ‘  , ğ›¼ğ‘

ğ‘  , ğ›½ğ‘

ğ‘’ , ğ›½ğ‘

âŠ² ğœ™ğ‘

ğ‘’ )}

ğ‘  , ğ›½ğ‘

ğ‘  , ğ›¼ğ‘

ğ‘  , ğ›¼ğ‘
probability ğ‘ on the given pose (ğ´ğ‘ , ğµğ‘ , ğ´ğ‘’, ğµğ‘’ ).

4: ğ¹ (ğ›¼ğ‘ , ğ›½ğ‘  ) = ğ‘ƒ {(ğ›¼ğ‘ , ğ›½ğ‘  )â€™s noticing probability is equal to or less than p} â† â„(ğ›¼ğ‘

ğ‘  , ğ›½ğ‘
ğ‘  )

âŠ² ğ¹ (ğ›¼ğ‘ , ğ›½ğ‘  ) is the

noticing probability distribution of the elbow offset. â„ is the function defined by Equation 2.

5: ğ‘†ğ‘  = {(ğ›¼ğ‘ , ğ›½ğ‘  )|ğ¹ (ğ›¼ğ‘ , ğ›½ğ‘  ) â‰¤ 2ğ‘} âŠ² ğ‘†ğ‘  is a set of shoulder offsets (ğœ™ğ‘  , ğœƒğ‘  ) whose noticing probabilities (ğ›¼ğ‘ , ğ›½ğ‘  ) are

equal to or less than twice of the given probability ğ‘.

6: ğ¹ (ğ›¼ğ‘’, ğ›½ğ‘’ ) = ğ‘ƒ {(ğ›¼ğ‘’, ğ›½ğ‘’ )â€™s noticing probability is equal to or less than p} â† â„(ğ›¼ğ‘’, ğ›½ğ‘’ )

âŠ² ğ¹ (ğ›¼ğ‘’, ğ›½ğ‘’ ) is the

noticing probability distribution of the elbow offset. â„ is the function defined by Equation 2.

7: ğ‘†ğ‘’ = {(ğ›¼ğ‘’, ğ›½ğ‘’ )|ğ¹ (ğ›¼ğ‘’, ğ›½ğ‘’ ) â‰¤ 2ğ‘} âŠ² ğ‘†ğ‘’ is a set of elbow offsets (ğœ™ğ‘’ , ğœƒğ‘’ ) whose noticing probabilities (ğ›¼ğ‘ , ğ›½ğ‘  ) are

equal to or less than twice of the given probability ğ‘.

8: ğ¹ (ğ›¼ğ‘ , ğ›½ğ‘ , ğ›¼ğ‘’, ğ›½ğ‘’ ) = ğ‘ƒ {(ğ›¼ğ‘ , ğ›½ğ‘ , ğ›¼ğ‘’, ğ›½ğ‘’ )â€™s noticing probability is equal to or less than p} â† ğ‘˜ (ğ›¼ğ‘ , ğ›½ğ‘ , ğ›¼ğ‘’, ğ›½ğ‘’ )

âŠ²
ğ¹ (ğ›¼ğ‘ , ğ›½ğ‘ , ğ›¼ğ‘’, ğ›½ğ‘’ ) is the noticing probability distribution of the composite two-joint offset (ğ›¼ğ‘ , ğ›½ğ‘ , ğ›¼ğ‘’, ğ›½ğ‘’ ). ğ‘˜ is
the negative linear function based on Section 4.3 results.

9: ğ‘† = {(ğ›¼ğ‘ , ğ›½ğ‘ , ğ›¼ğ‘’, ğ›½ğ‘’ )|ğ¹ (ğ›¼ğ‘ , ğ›½ğ‘ , ğ›¼ğ‘’, ğ›½ğ‘’ ) â‰¤ ğ‘, (ğ›¼ğ‘ , ğ›½ğ‘  ) âˆˆ ğ‘†ğ‘ , (ğ›¼ğ‘’, ğ›½ğ‘’ ) âˆˆ ğ‘†ğ‘’ } âŠ² ğ‘† contains the composite offsets whose

noticing probabilities are equal to or less than ğ‘.

at each pose would result in incoherent virtual movements due to varying maximum unnoticeable offset of
these poses. There are different solutions to simulate continuous movement smoothly and naturally based on
varying optimization goals. We thus propose one such goal to continuously amplify movements and implement
an interaction technique that amplifies the movement at the direction of the movement relative to the body. It
involves finding an extreme pose based on the userâ€™s intentions-the extreme pose can be the target pose if a
target exists or simply a directional extreme pose. The intended results are: offset increments linearly as the
user moves towards the extreme pose; the maximum offset determined by the user defined maximum noticing
probability is applied when the user reaches the extreme pose.

Here we describe in detail how we interpolate the four single axis offsets to be applied at any moment during
the movement. Since we found that users could be less sensitive to the dynamic movement offsets, we adopted a
75% offset noticing probability to determine the maximum offset. Parameterize the extreme pose by Î¦S, Î˜S, Î¦E,
and Î˜E. At any given moment the current pose can be defined by Î¦s, Î˜s, Î¦e, and Î˜e. Given the extreme pose, we
first obtain its two-dimensional shoulder joint maximum applicable offset. Since our technique applies offset
along the direction of the pose, we interpolate the maximum extreme pose shoulder offset ğœ™ğ‘
ğ‘† at the pose
shoulderâ€™s direction which implies Equation 4. We define the shoulder joint offset to be applied at the current pose
linearly such that for each axis we have current offset
extreme angle . We can thus calculate the offsets to be applied
at ğœ™ and ğœƒ axis from equation 5. From this we can deduct equation 6. This confirms that the two-dimensional
offset we applied at the shoulder conforms with the current shoulderâ€™s direction relative to the origin.

current angle = extreme offset

ğ‘† and ğœƒğ‘

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:15

Î¦S
Î˜S

=

ğœ™ğ‘
S
ğœƒğ‘
S
Ã— ğœ™ğ‘
S

ğœ™s =

, ğœƒs =

Ã— ğœƒğ‘
S

Î¦s
Î¦S
Î¦s
Î¦S
Î˜s
Î˜S

Î˜s
Î˜S
Ã— Î¦S
Ã— Î˜S

(4)

(5)

Î¦s
Î¦S
Î˜s
Î˜S
With the determined shoulder joint offset, we can use the model to obtain the applicable elbow joint offsets.
The above steps can then be repeated to choose the applicable elbow joint offset. Fig 10 shows an example of
movement amplification by our technique. The left shows the amplified movement as the user raises his arm
upwards and the right illustrates the programmed tracking of the physical and virtual arm movement paths.

Ã— ğœ™ğ‘
S
Ã— ğœƒğ‘
S

Î¦s
Î˜s

ğœ™s
ğœƒs

(6)

=

=

=

Fig. 10. The physical and virtual arms are shown in black and grey respectively. The shoulder and elbow paths are illustrated
by dotted lines. The offset increases when the physical arm is raising.

6 EVALUATING THE AMPLIFICATION TECHNIQUE

In Section 5.2, we implemented an interaction technique that amplifies the userâ€™s arm movements by adding
dynamic unnoticeable angular offsets to their shoulder and elbow. To validate that technique achieves the design
goal and evaluate the user performance, we conduct a comparison experiment with the task of performing
different arm poses in VR. We compared five implementations of the proposed techniques with the difference in
two key parameters (offset strength, offset distribution). We calculated task completion time, physical, and RULA
score [27] as the quantitative metrics and collected the participantsâ€™ subjective feedback in post-experiment
questionnaires. Results showed that adding offsets significantly reduced physical efforts, a strength of medium
level helped participants maintain body ownership, and a balanced offset on two joints was generally favored by
the participants.
6.1 Task

The task for the participant was to control the virtual avatarâ€™s arm with their own arm movements to perform
the target arm poses. We rendered a virtual avatar whose viewpoint coincides with that of the users in VR. The
avatarâ€™s arm moved as the userâ€™s physical arm, whose shoulder, elbow, and hand position was tracked with a
motion capture system. In four of the five test conditions, we added dynamic angular offsets calculated with
the proposed model to the shoulder and the elbow of the virtual avatar while the arm was moving. To indicate
the target pose, we rendered two blue balls in mid-air, showing the target positions of the elbow and the wrist
joint positions, respectively. The participants needed to overlap the two balls with the elbow and the wrist of

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:16

â€¢ Li et al.

the virtual avatar. Visual feedback of turning the balls to the color green was provided when the participant
managed to overlap them with the correct joints. Time duration of 0.5 seconds keeps the target pose triggered
the completion of the task. In between the tasks, the participant reset their arm poses to naturally lay down on
the side. We asked the participants to keep the remaining part of the body still while changing the arm pose
during the tasks. Similar to Section 3.6, we used the HDBSCAN cluster algorithm on the CMU MoCap dataset to
sample 40 target poses. Considering the fatigue might affect the results, participants do not need to repeat the
same pose in one condition. Each participant thus completed 5conditions Ã— 40poses = 200 tasks. We used a latin
square to counterbalance the order of condition and the tasks were randomized.
6.2 Design

We used a within-subject factorial design with the independent variables of offset strength (no, medium, strong) and
offset distribution (shoulder, shoulder and elbow, elbow). Offset strength was to test whether adding unnoticeable
offsets (no V.S. medium) can improve user performance and maintain body ownership at the same time, and the
trade-off of increasing the performance gain and losing body ownership (medium V.S. strong). We controlled the
offset strength with the predicted noticeability of the offsets at the extreme arm pose (90, 90, 90, 90), in which
the participant should be the most sensitive about the offset. We set the noticing probability to be 75% and 100%
for the medium and strong levels, respectively. Note that as predicted by the proposed model, we expected the
offsets at the strong level to be possibly noticed by the participants. Offset Distribution was to compared adding
composite two-joint offsets to the naive conditions when it degrades to adding one-joint offsets to either the
shoulder or the elbow. Specifically, we scaled its shoulder offset by ğ›¿s and its elbow offset by ğ›¿e = 1 âˆ’ ğ›¿s.

Table 2. Offset strength and offset distribution parameters for the conditions.

Condition Noticing probability ğ›¿shoulder
N/A
0%
0.5
75%
0
75%
1
75%
0.5
100%

N
MB
ME
MS
HB

ğ›¿elbow
N/A
0.5
1
0
0.5

Description

No offset
Medium level, balanced offset
Medium level, only elbow offset
Medium level, only shoulder offset
High level, balanced offset

As shown in Table 2, we compared five implementations in total. In comparing conditions N, MB, and HB, we
investigated the level of offset strength; while in comparing conditions MB, ME, and MS, we investigated the
distribution of offset at two joints. We measured the completion time, Rapid Upper Limb Assessment(RULA)
score [27], the virtual and physical path length for the elbow and wrist as quantitative metrics for task performance.
Task completion time is the time taken by the participant to reach the target arm pose from the reset pose.
RULA score measures the ergonomic difficulty of a pose. It is an objective metric which can be calculated with
the shoulder and elbow angles. A pose can be graded with a series of rules, for instance, if the upper arm puts
downward, the RULA score will plus one, while if the upper arm raises upward, the RULA score will plus four. A
lower RULA score indicates a lower physical effort and a more comfortable pose. The virtual path length refers
to the ratio of the avatar movement path length to the linear distance between the initial and the target pose.
Similarly, physical path length refers to the userâ€™s real movement path length to target distance ratio. Then after
each condition session, each participant was asked to fill a survey to report their sense of comfort, ease of reach,
sense of control, and body ownership based on a 7-point Likert scale (1: strongly disagree, 4:neutral, 7: strongly
agree). All user studies had been approved by our universityâ€™s IRB board.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:17

6.3 Apparatus and participants

We developed an experimental platform with Unity 2021 for Oculus Quest 2 headset. The interface showed the
virtual avatar as well as the blue balls indicating the target arm pose. We captured the participantâ€™s movement
with Optitrack and applied our dynamic amplification technique on the virtual arm. Then the modified movement
data was sent to the headset and was rendered to the user at 30 FPS. The systemâ€™s hardware and setup remained
the same with Section 4.1.3.

Given that the most related works [7, 25] conducted their evaluation studies with 12 users, we recruited 12
participants for the evaluation. All of them had not participated in our previous experiments and were right-
handed. The participants aged from 19 to 22 (ğ´ğ‘‰ ğº = 20.25, ğ‘†ğ· = 0.63), including 5 females and 7 males. Half of
the participants had at least moderate experience with virtual reality. The average self-reported virtual reality
familiarity was 2.58 (1: Not familiar at all; 7: Very familiar).
6.4 Results

We conducted the Bartlettâ€™s test and validated that the assumption of sphericity had not been violated on
the metrics of the task completion time( ğœ’ 2 = 2.09, ğ‘ > 0.05), RULA score( ğœ’ 2 = 0.14, ğ‘ > 0.05), physical
elbow( ğœ’ 2 = 8.78, ğ‘ > 0.05), physical wrist( ğœ’ 2 = 7.93, ğ‘ > 0.05). Therefore, we conducted repeated measures
ANOVA tests on these metrics. If any independent variable had significant effects(ğ‘ < 0.05), we used Bonferroni-
corrected post hoc T-tests for pairwise comparisons since we compared multiple pairs of data. Since the subjective
scores were discrete and ordinal, they were analyzed using Friedman tests with a series of Wilcoxon signed-rank
post hoc tests. We performed our data analysis using scipy [49]. We compare conditions N, MB, HB, and MB, ME,
MS to study the effect of offset strength and offset distribution respectively.

RM-ANOVA tests showed significant differences on task completion time (ğ¹4,44 = 31.94, ğ‘ < 0.05, ğœ‚2 = 0.74),
RULA score(ğ¹4,44 = 16.59, ğ‘ < 0.05, ğœ‚2 = 0.60), physical moving distance of elbow(ğ¹4,44 = 10.03, ğ‘ < 0.05, ğœ‚2 =
0.60), and physical moving distance of wrist(ğ¹4,44 = 7.48, ğ‘ < 0.05, ğœ‚2 = 0.51). We confirmed that the virtual
path lengths of all participants had no significant differences to ensure that they followed the same target path in
all conditions and the offset would not result in extra movements.

Fig. 11. Quantitative results of the three techniques with different offset strength parameters.

6.4.1 Effects of offset strength. Adding offsets significantly reduced task completion time. Pair-wise comparisons
showed significant differences on task completion time between the following pairs: N (ğ´ğ‘‰ ğº = 5.02, ğ‘†ğ· = 0.13)
and MB (ğ´ğ‘‰ ğº = 4.83, ğ‘†ğ· = 0.14, ğ‘¡ (11) = 2.88, ğ‘ < 0.05, ğ‘‘ = 1.29), MB (ğ´ğ‘‰ ğº = 4.83, ğ‘†ğ· = 0.14) and
HB (ğ´ğ‘‰ ğº = 4.35, ğ‘†ğ· = 0.16, ğ‘¡ (11) = 7.42, ğ‘ < 0.05, ğ‘‘ = 2.94), N (ğ´ğ‘‰ ğº = 5.02, ğ‘†ğ· = 0.13) and HB
(ğ´ğ‘‰ ğº = 4.35, ğ‘†ğ· = 0.16, ğ‘¡ (11) = 12.56, ğ‘ < 0.05, ğ‘‘ = 4.21).

Adding offsets reduced the physical effort and made movement ergonomically easier. Pair-wise comparisons
showed significant differences on the RULA score between N (ğ´ğ‘‰ ğº = 5.08, ğ‘†ğ· = 0.04) and MB (ğ´ğ‘‰ ğº =

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:18

â€¢ Li et al.

4.98, ğ‘†ğ· = 0.04, ğ‘¡ (11) = 6.29, ğ‘ < 0.05, ğ‘‘ = 2.57), N (ğ´ğ‘‰ ğº = 5.08, ğ‘†ğ· = 0.04) and HB (ğ´ğ‘‰ ğº = 4.97, ğ‘†ğ· =
0.05, ğ‘¡ (11) = 5.78, ğ‘ < 0.05, ğ‘‘ = 2.36).

Adding offsets effectively reduced the physical moving distance, making the tasks less physically demanding. The
effect of larger offsets on decreasing physical path length was significant on both elbow. Pair-wise comparisons
showed significant differences on physical path length between all pairs: elbow N (ğ´ğ‘‰ ğº = 1.22, ğ‘†ğ· = 0.02)
and MB (ğ´ğ‘‰ ğº = 1.19, ğ‘†ğ· = 0.03, ğ‘¡ (11) = 3.17, ğ‘ < 0.05, ğ‘‘ = 1.03), MB (ğ´ğ‘‰ ğº = 1.19, ğ‘†ğ· = 0.03) and
HB (ğ´ğ‘‰ ğº = 1.14, ğ‘†ğ· = 0.02, ğ‘¡ (11) = 3.18, ğ‘ < 0.05, ğ‘‘ = 1.73), N (ğ´ğ‘‰ ğº = 1.22, ğ‘†ğ· = 0.02) and HB
(ğ´ğ‘‰ ğº = 1.14, ğ‘†ğ· = 0.02, ğ‘¡ (11) = 3.51, ğ‘ < 0.05, ğ‘‘ = 3.43); wrist N (ğ´ğ‘‰ ğº = 1.24, ğ‘†ğ· = 0.03) and MB
(ğ´ğ‘‰ ğº = 1.15, ğ‘†ğ· = 0.03, ğ‘¡ (11) = 2.23, ğ‘ < 0.05, ğ‘‘ = 1.54), MB (ğ´ğ‘‰ ğº = 1.15, ğ‘†ğ· = 0.03) and HB (ğ´ğ‘‰ ğº =
1.10, ğ‘†ğ· = 0.03, ğ‘¡ (11) = 3.16, ğ‘ < 0.05, ğ‘‘ = 1.29), N (ğ´ğ‘‰ ğº = 1.24, ğ‘†ğ· = 0.03) and HB (ğ´ğ‘‰ ğº = 1.10, ğ‘†ğ· =
0.03, ğ‘¡ (11) = 4.75, ğ‘ < 0.05, ğ‘‘ = 2.32)

Fig. 12. Qualitative results of the three techniques of different offset strength parameters.

Strong offsets reduced the comfort and body ownership. The Wilcoxon signed-rank test results show that comfort,
sense of control, and body ownership is only reduced with significance when offsets of strong strength were
applied. For the comfort metric, large offsets reduced comfort as N (ğ´ğ‘‰ ğº = 5.53, ğ‘†ğ· = 0.50) was significantly
higher than HB (ğ´ğ‘‰ ğº = 4.80, ğ‘†ğ· = 1.05, ğ‘ = 2.09, ğ‘ < 0.05). Body ownership was reduced significantly in
HB (ğ´ğ‘‰ ğº = 4.07, ğ‘†ğ· = 1.06) compared to N (ğ´ğ‘‰ ğº = 5.40, ğ‘†ğ· = 0.61) and MB(ğ´ğ‘‰ ğº = 5.27, ğ‘†ğ· = 0.68): N
and HB (ğ‘ = 2.83, ğ‘ < 0.05), MB and HB (ğ‘ = 2.77, ğ‘ < 0.05). Users found it hard to control the virtual arm
with a strong offset. Sense of control is reduced significantly in HB (ğ´ğ‘‰ ğº = 4.73, ğ‘†ğ· = 1.06) compared to both
N (ğ´ğ‘‰ ğº = 5.73, ğ‘†ğ· = 0.77) and MB (ğ´ğ‘‰ ğº = 6.04, ğ‘†ğ· = 0.82): N and HB (ğ‘ = 2.76, ğ‘ < 0.05), MB and HB
(ğ‘ = 2.82, ğ‘ < 0.05). Users felt easier to move and reach with added offsets. Ease of reach improved for both MB
(ğ´ğ‘‰ ğº = 5.40, ğ‘†ğ· = 0.95) and HB (ğ´ğ‘‰ ğº = 5.47, ğ‘†ğ· = 0.88) compared to N (ğ´ğ‘‰ ğº = 4.40, ğ‘†ğ· = 0.71) with
significance: N and HB (ğ‘ = âˆ’2.97, ğ‘ < 0.05), N and MB (ğ‘ = âˆ’2.64, ğ‘ < 0.05). This implies the applying offset
made reaching tasks easier yet such effect isnâ€™t raised when higher level offset is applied.

The quantitative result demonstrates that only a strong offset reduced the ergonomic difficulty of the tasks.
With an increasing level of offsets applied, users take less time and move less to achieve ergonomically easier
tasks. The qualitative result also supported that the ease of reach improves with offsets and supplemented that
usersâ€™ comfort, sense of control, and body ownership are only compromised with significance when a high-level
offset is applied. This reflects that virtual tasks can be made easier, more efficient, and more accessible without
compromising body ownership illusion by applying a medium level of offsets.

6.4.2 Effects of offset distribution. The balanced distribution of offset reduced the physical effort most. Pair-wise
comparisons showed significant differences only on RULA score. RULA score is the highest with unbalanced
offset when only the elbow has offset applied as ME (ğ´ğ‘‰ ğº = 5.08, ğ‘†ğ· = 0.06) is significantly higher than both

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:19

Fig. 13. Quantitative results of the three techniques of different offset strength parameters.

MB (ğ´ğ‘‰ ğº = 4.98, ğ‘†ğ· = 0.04, ğ‘¡ (11) = âˆ’5.05, ğ‘ < 0.05, ğ‘‘ = 1.97) and MS (ğ´ğ‘‰ ğº = 4.97, ğ‘†ğ· = 0.06, ğ‘¡ (11) =
4.72, ğ‘ < 0.05, ğ‘‘ = 1.83). This implies that compared to shoulder offset, elbow offset adds more to ergonomic
unease. None other condition or metric is significant.

Fig. 14. Qualitative results of the three techniques of different offset strength parameters.

Unbalanced distribution of offset made the user feel hard to control and reach. For the ease of reach metric, MB
(ğ´ğ‘‰ ğº = 5.40, ğ‘†ğ· = 0.95) is higher than both ME (ğ´ğ‘‰ ğº = 4.80, ğ‘†ğ· = 1.33) and MS (ğ´ğ‘‰ ğº = 4.07, ğ‘†ğ· = 1.29)
with significance: MB and ME (ğ‘ = 2.08, ğ‘ < 0.01), MB and MS (ğ‘ = 2.87, ğ‘ < 0.01). Similarly, applying balanced
offset achieves the best sense of control for users as MB (ğ´ğ‘‰ ğº = 6.04, ğ‘†ğ· = 0.82) significantly outperforms both
ME (ğ´ğ‘‰ ğº = 4.67, ğ‘†ğ· = 1.30) and MS (ğ´ğ‘‰ ğº = 4.07, ğ‘†ğ· = 1.12): MB and ME (ğ‘ = 2.92, ğ‘ < 0.01), MB and MS
(ğ‘ = 4, 01, ğ‘ < 0.01).

The balanced distribution of offset made the virtual movement more natural. The body ownership subjective
rating is the highest for balanced offset while within two unbalanced offset distribution, applying elbow offset has
higher body ownership. MB (ğ´ğ‘‰ ğº = 5.27, ğ‘†ğ· = 0.68) scores higher than ME (ğ´ğ‘‰ ğº = 4.42, ğ‘†ğ· = 1.02) which
outperforms MS (ğ´ğ‘‰ ğº = 3.63, ğ‘†ğ· = 0.88): MB and ME (ğ‘ = 2.69, ğ‘ < 0.01), ME and MS (ğ‘ = 2.15, ğ‘ < 0.05),
MB and MS (ğ‘ = 3.31, ğ‘ < 0.01). Several participants reported that they felt the virtual arm not part of their
body since the unbalanced offset made the virtual arm movement unnatural and thus hurt the body ownership.
The quantitative result demonstrates that the completion time and physical movement path ratio for both
joints are unaffected by offset distribution. On the other hand, the RULA score indicates that the task is more
ergonomically difficult when the offset is only applied at the elbow. This implies that while offset distribution
doesnâ€™t affect the efficiency of the task completion in VR, offset unevenly applied on the elbow is less effective in
making the tasks ergonomically easier thus more comfortable to achieve. Usersâ€™ subjective preferences for offset

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:20

â€¢ Li et al.

distribution, however, are more significant. Balanced distribution helps improve ease of reach, sense of control,
and the sense of body ownership. Furthermore, body ownership is reduced the most with an unbalanced offset
applied only at the shoulder. Comfort is unaffected by offset distribution.
7 APPLICATIONS

To demonstrate our modelâ€™s potential in leveraging the trade-off between functionality and body ownership
illusion, we developed three applications with different functionality versus body ownership needs.
7.1 Motivating VR Stroke Rehabilitation

Therapeutically appropriate rehabilitation is crucial to post-surgery motor function recovery for stroke pa-
tients [17, 46, 47, 56]. We propose to provide virtual motor performance improvement to motivate patients and
thus to boost engagement[13, 19, 40] in rehabilitation exercises. In order to enable the patients to embody the
virtual avatar, VR rehabilitation has a high requirement for body ownership. We thus developed a stroke VR
rehabilitation system that motivates the patients through subtle motion amplification. In a living room environ-
ment, the patient is instructed to perform stroke rehabilitation poses (abduction-adduction, internal-external
rotation, elbow flexion-extension, and forearm pronation-supination) by coinciding the mid-air balls which outline
the shoulder and the elbow joint trajectories. During this process, the virtual left arm position can be subtly
amplified as compared to the real physical arm by applying a small offset. In perceiving a motor performance
improvement virtually, the patient gains stronger engagement and will likely to be motivated and spend more
effort in rehabilitation.
7.2 Manipulating Physical Effort Demand in VR Action Games

With the model we propose motion modification as a new dimension in manipulating usersâ€™ physical effort
demand [61, 62] in VR games and therefore simulating a virtual avatarâ€™s stamina level. Specifically, the physical
effort demand can be lowered by motion amplification and increased by motion reduction. We thus designed a
first-person VR action game inspired by VR games Beat Saber [44] and Oh Shape [51]. The players need to pose
their left arm to coincide with the target pose, represented by mid-air coins, and to avoid colliding with the devil
bats. Example scenes of the game are shown in Fig 15. The playerâ€™s motion is amplified with a medium-level
offset, so the virtual arm moves quicker. Similarly the virtual arm moves slower when the same level of offset is
applied opposite to the moving direction.
7.3 Widget Arrangement in VR

Movement in a large space has been unpopular in VR both due to long term fatigue induced by large movements,
or limited physical movement space. Input augmentation techniques can help transform small-scale and close-to-
body movements in the real world to large-scale and more dramatic virtual motions. Such functionality oftentimes
comes at the expense of body ownership illusion. We developed an demonstration for widget arrangement tasks [5]
based on our model with high functionality requirements yet relatively low body ownership requirement. In
a typical work/study scenario, when the user is sitting at a desk and has limited space in the real world, users
can reach distant positions with shortened moving distance, less time, and less physical energy with amplified
movements.
8 DISCUSSION

In this paper, we have thoroughly investigated the effects of user-avatar movement inconsistency on its notice-
ability. We constructed a model that predicts a set of applicable offsets to an arm pose for a required noticing
probability. With this model, we implemented an interaction technique that amplifies the userâ€™s arm movement
without letting them notice the offsets. We developed three example applications to demonstrate the extendability
of the proposed method. In this section we discuss the limitations of our work and suggest new opportunities for
future work.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:21

(a)

(b)

(c)

Fig. 15. The illustration of three applications. (a) Motivating stroke rehabilitation: The mid-air balls guide the userâ€™s arm for
rehabilitation. (b) Changing physical effort demand in VR action games: The mid-aid balls illustrates the target pose. The
level of offset applied onto the arm can be adjusted to change the gameâ€™s demand for physical effort. (c) Input augmentation
for widget arrangement: Users can amplify their arm movement to different extents by applying varying levels of offsets.

8.1 Effects of Avatarâ€™s Appearance on Body Ownership

In this paper, we used the default humanoid avatar in Unity 2021 to study how the offset affects body ownership.
Since the avatarâ€™s appearance could affect body ownership [11, 18, 63], we fixed the avatar to avoid the effects of
this confounding factor. Since the changes in the avatarâ€™s appearance have reduced the sense of body ownership,
the user might be more sensitive to the motion offset. However, we acknowledge the potential of modifying the
avatarâ€™s appearance and the motion at the same time to provide interaction functionalities and to keep the body
ownership as well, which will be important future work of this paper.

8.2 Applying Offsets beyond Angular Rotations on Shoulder and Elbow

The offsets we studied in this paper are the angular rotation offsets applied on the shoulder and the elbow joints.
We acknowledge that there are offsets of other types that can also be applied to modify the movements. Existing
research [29, 37, 59] has explored stretching the arm without a length restriction to enable reaching the space far
away. We expect the research approach that we adopted in this study can also be applicable to the investigation
of other offsets, including length and the combined usage of length and rotation offsets.

On the other hand, we did not investigate the noticeability of hand and finger movement inconsistency in this
paper, considering the relatively limited influence imposed by hand and finger to the entire arm pose. However,
as one of the most frequently used organs, hand and finger could play an important role in the influences of
user-avatar movement inconsistency in VR. Though we did not involve hand and finger in our study, we expect
that the research flow in our study can be adopted to hand movement inconsistency, finger, and composite
inconsistency in the future.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:22

â€¢ Li et al.

8.3 Calculate the Noticing Probability for a Given Offset and Pose

In Section 5.2, we constructed a model which took in a given probability and arm pose and predicted a set of
applicable offsets. This provides convenience for application developers with an explicit requirement on the
noticeability of the movement inconsistency, and the model automatically calculates the applicable offsets for
them to adopt. However, we could also construct the model reversely as calculating the noticing probability of the
movement inconsistency given a pair of offsets to apply on the shoulder and the elbow joints. With the collected
noticing probability distributions of the offset strength on 10 poses, the model can interpolate the offset strength
and the arm pose to calculate the probability for a given pose and offset. This could help other researchers or
engineers who would like to know how many users could notice the offset in their projects or research.

8.4 Human Adaptation to the Offset

Though we gave out a model to tell the noticeability of a certain offset and pose, users might adapt to the offset if it
continuously exists. This could change the noticeability to the offset which indicate that our model might add the
adaptation as a parameter. After our user studies, we divided every userâ€™s data into four groups in chronological
order. Then we conducted repeated measures ANOVA tests with the variables of chronological order on the
number of users reported that they noticed the offset after checking the sphericity had not been violated. The
results showed that the task order did not significantly affect the noticing times (ğ¹3,31 = 1.83, ğ‘ > 0.05) which
indicated that users did not adapt to the offset in 90 minutes experiment. However, if long term offset was applied,
users could be less sensitive to the offset since they believed that some modified movements were consistent
with physical movements and became more acceptive to larger offsets.
8.5 Limitation and Future Work

We decided to limit our investigation to the upper left limb as it is one of the most agile and frequently-used body
parts and with the consideration of the human labor cost in data collection. However, we expect our approach
to be applicable to similar investigations for other limbs and body parts to construct the offset model. This has
considerable potentials in future applications in maintaining whole-body immersion while enabling body-scale
interaction functionalities and thus will be further explored in future work.

In Section 4 and Section 6, we conducted four user studies with 12 participants for each, which results in 48
participants in total. Considering the long experiment time (around 90 minutes), heavy physical load of task, it is
hard to conduct studies with massive users, especially during the COVID-19 pandemic. We conducted repeated
measures ANOVA tests with the variables of user on the proportion of noticing the offset for the same set of poses
and offsets and the results showed that user did not significantly affect the noticing probability (ğ‘ > 0.05) which
indicated that these usersâ€™ data were similar and thus the 12 usersâ€™ data are appropriate to construct a statistical
model. We constructed the model based on 36 usersâ€™ data that we collected in the three phases in Section 4
and evaluated it with 12 users in the evaluation study. We recognize that our modelâ€™s prediction accuracy is
constricted by the number of participants and the accuracy could be better with more participants. The evaluation
results were promising which indicate that the model constructed with relatively small data worked well. We
will repeat the studies with more users and validate our conclusions and model in the future.

In the evaluation in Section 6, we compared three offset distributions between the shoulder and the elbow
joints to study how offset distribution affects interaction efficiency and experience in Section 6 and found that
balanced offsets were optimal for immersion. We chose three representative distributions (ğ›¿ğ‘  - ğ›¿ğ‘  : 1 - 0, 0.5 - 0.5, 0
- 1) and three strength level(none, medium, and high). We only tested three conditions for each of the two factors
cause we were not sure whether these two factors would significantly affect the performances. Therefore we
conducted an elementary explorative experiment and we would test more levels, for instance, offset distribution
of (0.75 - 0.25) or (0.25 - 0.75). We recognised that the evaluation of distributions can be extended to identify other
optimal offset strength and distribution.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:23

We investigated the movement inconsistencyâ€™s noticeability from the first-person point of view in this paper.
However, existing research found that users could observe their motions with more clarity with a third-person
point of view [23, 58] in VR. We expect the trend of body ownership degradation with increased offset differs
from that of the first-person point of view and is worth investigating.

9 CONCLUSION

This paper explores how the strength of user-avatar movement inconsistency affects its noticeability and finally
the sense of body ownership in VR. In approaching this, we investigated the effect of applying angular offsets to
the left armâ€™s shoulder and elbow on body ownership by the probability of noticing the existence of the offset. We
conducted three user studies to quantify the effect of offset on the offset noticing probability. With this quantified
effect, we can predict the probability of noticing the offset with a given composite two-joint offset at various pose.
Leveraging this knowledge, we then constructed a statistical model which outputs a set of applicable composite
two-joint offsets given an offset noticing probability and an arm pose. We adapted our model to construct dynamic
movement with a maximum 75% offset noticeability to support an interaction technique optimizing movement
amplification. We evaluated the technique, and the results show that the offset could significantly reduce the
moving time and distance while a medium-level offset does not compromise the sense of body ownership. We
demonstrated the extendability and usability of the proposed model in three applications with different body
ownership requirements. Finally, we discussed other factors that affected body ownership as possible future work
and recognized the limitations.

ACKNOWLEDGMENTS

This work is supported by the Natural Science Foundation of China under Grant No.6213000120, 62002198,
Tsinghua University Initiative Scientific Research Program, the China Postdoctoral Science Foundation un-
der Grant No.2021M691788, Key Research Projects of the Foundation Strengthening Program under Grant
No. 2020JCJQZD01412, the Natural Science Foundation of China under Grant No. 62132010, Beijing Key Lab
of Networked Multimedia, and the Institute for Guo Qiang and Institute for Artifcial Intelligence, Tsinghua
University.

REFERENCES

[1] Mahdi Azmandian, Mark Hancock, Hrvoje Benko, Eyal Ofek, and Andrew D. Wilson. 2016. Haptic Retargeting: Dynamic Repurposing
of Passive Haptics for Enhanced Virtual Reality Experiences. In Proceedings of the 2016 CHI Conference on Human Factors in Computing
Systems, San Jose, CA, USA, May 7-12, 2016, Jofish Kaye, Allison Druin, Cliff Lampe, Dan Morris, and Juan Pablo Hourcade (Eds.). ACM,
1968â€“1979. https://doi.org/10.1145/2858036.2858226

[2] Domna Banakou and Mel Slater. 2014. Body ownership causes illusory self-attribution of speaking and influences subsequent real

speaking. Proceedings of the National Academy of Sciences 111, 49 (2014), 17678â€“17683.

[3] Matthew Botvinick and Jonathan Cohen. 1998. Rubber hands â€˜feelâ€™touch that eyes see. Nature 391, 6669 (1998), 756â€“756.
[4] Ryan Canales, Aline Normoyle, Yu Sun, Yuting Ye, Massimiliano Di Luca, and Sophie JÃ¶rg. 2019. Virtual Grasping Feedback and
Virtual Hand Ownership. In ACM Symposium on Applied Perception 2019, SAP 2018, Barcelona, Spain, September 19-20, 2019, SolÃ¨ne
Neyret, Elena Kokkinara, Mar GonzÃ¡lez-Franco, Ludovic Hoyet, Douglas W. Cunningham, and Justyna Swidrak (Eds.). ACM, 4:1â€“4:9.
https://doi.org/10.1145/3343036.3343132

[5] Yifei Cheng, Yukang Yan, Xin Yi, Yuanchun Shi, and David Lindlbauer. 2021. SemanticAdapt: Optimization-Based Adaptation of
Mixed Reality Layouts Leveraging Virtual-Physical Semantic Connections. In The 34th Annual ACM Symposium on User Interface
Software and Technology (Virtual Event, USA) (UIST â€™21). Association for Computing Machinery, New York, NY, USA, 282â€“297. https:
//doi.org/10.1145/3472749.3474750

[6] L. Dominjon, A. Lecuyer, J.-M. Burkhardt, P. Richard, and S. Richir. 2005. Influence of control/display ratio on the perception of mass of
manipulated objects in virtual environments. In IEEE Proceedings. VR 2005. Virtual Reality, 2005. 19â€“25. https://doi.org/10.1109/VR.2005.
1492749

[7] Tiare M. Feuchtner and JÃ¶rg MÃ¼ller. 2018. Ownershift: Facilitating Overhead Interaction in Virtual Reality with an Ownership-Preserving
Hand Space Shift. In The 31st Annual ACM Symposium on User Interface Software and Technology, UIST 2018, Berlin, Germany, October

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:24

â€¢ Li et al.

14-17, 2018, Patrick Baudisch, Albrecht Schmidt, and Andy Wilson (Eds.). ACM, 31â€“43. https://doi.org/10.1145/3242587.3242594
[8] Scott Frees, G. Drew Kessler, and Edwin Kay. 2007. PRISM interaction for enhancing control in immersive virtual environments. ACM

Trans. Comput. Hum. Interact. 14, 1 (2007), 2. https://doi.org/10.1145/1229855.1229857

[9] Arvid Guterstam, Valeria I Petkova, and H Henrik Ehrsson. 2011. The illusion of owning a third arm. PloS one 6, 2 (2011), e17208.
[10] David Antonio GÃ³mez JÃ¡uregui, Ferran Argelaguet, Anne-HÃ©lÃ¨ne Olivier, Maud Marchal, Franck Multon, and Anatole LÃ©cuyer. 2014.
Toward "Pseudo-Haptic Avatars": Modifying the Visual Animation of Self-Avatar Can Simulate the Perception of Weight Lifting. IEEE
Trans. Vis. Comput. Graph. 20, 4 (2014), 654â€“661. https://doi.org/10.1109/TVCG.2014.45

[11] Dongsik Jo, Kangsoo Kim, Gregory F. Welch, Woojin Jeon, Yongwan Kim, Ki-Hong Kim, and Gerard Jounghyun Kim. 2017. The impact
of avatar-owner visual similarity on body ownership in immersive virtual reality. In Proceedings of the 23rd ACM Symposium on Virtual
Reality Software and Technology, VRST 2017, Gothenburg, Sweden, November 8-10, 2017, Morten Fjeld, Marco Fratarcangeli, Daniel SjÃ¶lie,
Oliver G. Staadt, and Jonas Unger (Eds.). ACM, 77:1â€“77:2. https://doi.org/10.1145/3139131.3141214

[12] Joohee Jun, Myeongul Jung, So-Yeon Kim, and Kwanguk Kim. 2018. Full-body ownership illusion can change our emotion. In Proceedings

of the 2018 CHI Conference on Human Factors in Computing Systems. 1â€“11.

[13] Hee-Tae Jung, Taiwoo Park, Narges Mahyar, Sungji Park, Taekyeong Ryu, Yangsoo Kim, and Sunghoon Ivan Lee. 2020. Rehabilitation
Games in Real-World Clinical Settings: Practices, Challenges, and Opportunities. ACM Trans. Comput. Hum. Interact. 27, 6 (2020),
41:1â€“41:43. https://doi.org/10.1145/3418197

[14] Andreas Kalckert and H Henrik Ehrsson. 2014. The moving rubber hand illusion revisited: Comparing movements and visuotactile

stimulation to induce illusory ownership. Consciousness and cognition 26 (2014), 117â€“132.

[15] M. Ke and H. Bernhard. 2013. The virtual-hand illusion: effects of impact and threat on perceived ownership and affective resonance.

Frontiers in Psychology 4 (2013).

[16] M. Ke and B. Hommel. 2015. The role of agency for perceived ownership in the virtual hand illusion. Consciousness and Cognition 36

(2015), 277â€“288.

[17] Michael P Kilgard and Michael M Merzenich. 1998. Cortical map reorganization enabled by nucleus basalis activity. Science 279, 5357

(1998), 1714â€“1718.

[18] Konstantina Kilteni, Jean-Marie Normand, Maria V Sanchez-Vives, and Mel Slater. 2012. Extending body space in immersive virtual

reality: a very long arm illusion. PloS one 7, 7 (2012), e40867.

[19] Gert Kwakkel. 2006. Impact of intensity of practice after stroke: issues for consideration. Disability and rehabilitation 28, 13-14 (2006),

823â€“830.

[20] CMU Graphics Lab. 2021. CMU Graphics Lab Motion Capture Database. http://mocap.cs.cmu.edu/. Online; accessed 9 September 2021.
[21] Anatole LÃ©cuyer. 2009. Simulating Haptic Feedback Using Vision: A Survey of Research and Applications of Pseudo-Haptic Feedback.

Presence Teleoperators Virtual Environ. 18, 1 (2009), 39â€“53. https://doi.org/10.1162/pres.18.1.39

[22] Anatole LÃ©cuyer, Sabine Coquillart, Abderrahmane Kheddar, Paul Richard, and Philippe Coiffet. 2000. Pseudo-Haptic Feedback: Can
Isometric Input Devices Simulate Force Feedback?. In Virtual Reality 2000 Conference, VRâ€™00, New Brunswick, New Jersey, USA, March
18-22, 2000, Proceedings. IEEE Computer Society, 83â€“90. https://doi.org/10.1109/VR.2000.840369

[23] Juyoung Lee, Myungho Lee, Gerard Jounghyun Kim, and Jae-In Hwang. 2020. Effects of Virtual Gait Visualization in Walk-in-Place on
Body Ownership and Presence. In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, CHI 2020,
Honolulu, HI, USA, April 25-30, 2020, Regina Bernhaupt, Florian â€™Floydâ€™ Mueller, David Verweij, Josh Andres, Joanna McGrenere, Andy
Cockburn, Ignacio Avellino, Alix Goguey, Pernille BjÃ¸n, Shengdong Zhao, Briane Paul Samson, and Rafal Kocielnik (Eds.). ACM, 1â€“7.
https://doi.org/10.1145/3334480.3382867

[24] Jialei Li, Isaac Cho, and Zachary Wartell. 2018. Evaluation of Cursor Offset on 3D Selection in VR. In Proceedings of the Symposium on
Spatial User Interaction, SUI 2018, Berlin, Germany, October 13-14, 2018. ACM, 120â€“129. https://doi.org/10.1145/3267782.3267797
[25] Zhen Li, Joannes Chan, Joshua Walton, Hrvoje Benko, Daniel Wigdor, and Michael Glueck. 2021. Armstrong: An Empirical Examination
of Pointing at Non-Dominant Arm-Anchored UIs in Virtual Reality. In CHI â€™21: CHI Conference on Human Factors in Computing Systems,
Virtual Event / Yokohama, Japan, May 8-13, 2021, Yoshifumi Kitamura, Aaron Quigley, Katherine Isbister, Takeo Igarashi, Pernille BjÃ¸rn,
and Steven Mark Drucker (Eds.). ACM, 123:1â€“123:14. https://doi.org/10.1145/3411764.3445064

[26] Lorraine Lin and Sophie JÃ¶rg. 2016. Need a hand?: how appearance affects the virtual hand illusion. In Proceedings of the ACM
Symposium on Applied Perception, SAP 2016, Anaheim, California, USA, July 22-23, 2016, Eakta Jain and Sophie JÃ¶rg (Eds.). ACM, 69â€“76.
https://doi.org/10.1145/2931002.2931006

[27] L McAtamney and E Nigel Corlett. 1993. RULA: a survey method for the investigation of work-related upper limb disorders. Applied

ergonomics 24, 2 (April 1993), 91â€“9.

[28] Leland McInnes, John Healy, and Steve Astels. 2017. hdbscan: Hierarchical density based clustering. J. Open Source Softw. 2, 11 (2017),

205. https://doi.org/10.21105/joss.00205

[29] Jess McIntosh, Hubert Dariusz Zajac, Andreea Nicoleta Stefan, Joanna BergstrÃ¶m, and Kasper HornbÃ¦k. 2020. Iteratively Adapting
Avatars using Task-Integrated Optimisation. In Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology.
709â€“721.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

Modeling the Noticeability of User-Avatar Movement Inconsistency for Sense of Body Ownership Intervention â€¢

64:25

[30] S. Mel. 2009. Inducing illusory ownership of a virtual body. Frontiers in Neuroscience 3, 2 (2009).
[31] Roberto A. Montano Murillo, Sriram Subramanian, and Diego MartÃ­nez Plasencia. 2017. Erg-O: Ergonomic Optimization of Immersive
Virtual Environments. In Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology, UIST 2017,
Quebec City, QC, Canada, October 22 - 25, 2017, Krzysztof Gajos, Jennifer Mankoff, and Chris Harrison (Eds.). ACM, 759â€“771. https:
//doi.org/10.1145/3126594.3126605

[32] Kumiyo Nakakoji, Yasuhiro Yamamoto, and Yasuharu Koike. 2010. Toward Principles for Visual Interaction Design for Communicating

Weight by using Pseudo-Haptic Feedback.

[33] Optitrack. 2021. Optitrack Motion Capture System. https://optitrack.com/. Online; accessed 9 September 2021.
[34] K. L. Palmerius, D. Johansson, G HÃ¶st, and K SchÃ¶nborn. 2014. An Analysis of the Influence of a Pseudo-haptic Cue on the Haptic

Perception of Weight. In Springer Berlin Heidelberg.

[35] Xueni Pan and Mel Slater. 2011. Confronting a moral dilemma in virtual reality: a pilot study. In Proceedings of the 2011 British Computer
Society Conference on Human-Computer Interaction, BCS-HCI 2011, Newcastle-upon-Tyne, UK, July 4-8, 2011, Linda Little and Lynne M.
Coventry (Eds.). ACM, 46â€“51. http://dl.acm.org/citation.cfm?id=2305326

[36] Tabitha C Peck, Sofia Seinfeld, Salvatore M Aglioti, and Mel Slater. 2013. Putting yourself in the skin of a black avatar reduces implicit

racial bias. Consciousness and cognition 22, 3 (2013), 779â€“787.

[37] Ivan Poupyrev, Mark Billinghurst, Suzanne Weghorst, and Tadao Ichikawa. 1996. The Go-Go Interaction Technique: Non-Linear
Mapping for Direct Manipulation in VR. In Proceedings of the 9th Annual ACM Symposium on User Interface Software and Technology,
UIST 1996, Seattle, WA, USA, November 6-8, 1996, David Kurlander, Marc H. Brown, and Ramana Rao (Eds.). ACM, 79â€“80. https:
//doi.org/10.1145/237091.237102

[38] Andreas Pusch, Olivier Martin, and Sabine Coquillart. 2008. HEMP-Hand-Displacement-Based Pseudo-Haptics: A Study of a Force Field
Application. In IEEE Symposium on 3D User Interfaces, 3DUI 2008, Reno, Nevada, USA, 8-9 March, 2008. IEEE Computer Society, 59â€“66.
https://doi.org/10.1109/3DUI.2008.4476593

[39] Andreas Pusch, Olivier Martin, and Sabine Coquillart. 2009. HEMP - hand-displacement-based pseudo-haptics: A study of a force field
application and a behavioural analysis. Int. J. Hum. Comput. Stud. 67, 3 (2009), 256â€“268. https://doi.org/10.1016/j.ijhcs.2008.09.015
[40] Mary Vining Radomski. 2011. More than good intentions: Advancing adherence to therapy recommendations. American Journal of

Occupational Therapy 65, 4 (2011), 471â€“477.

[41] Sharif Razzaque, Zachariah Kohn, and Mary C. Whitton. 2001. Redirected Walking. In 22nd Annual Conference of the European
Association for Computer Graphics, Eurographics 2001 - Short Presentations, Manchester, UK, September 3-7, 2001, Jonathan C. Roberts
(Ed.). Eurographics Association. https://doi.org/10.2312/egs.20011036

[42] Michael Rietzler, Martin Deubzer, Thomas Dreja, and Enrico Rukzio. 2020. Telewalk: Towards Free and Endless Walking in Room-Scale

Virtual Reality. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1â€“9.

[43] Michael Rietzler, Florian Geiselhart, Jan Gugenheimer, and Enrico Rukzio. 2018. Breaking the Tracking: Enabling Weight Perception
using Perceivable Tracking Offsets. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, CHI 2018,
Montreal, QC, Canada, April 21-26, 2018, Regan L. Mandryk, Mark Hancock, Mark Perry, and Anna L. Cox (Eds.). ACM, 128. https:
//doi.org/10.1145/3173574.3173702

[44] Beat Saber. 2021. Beat Saber - VR rhythm game. https://beatsaber.com. Online; accessed 9 September 2021.
[45] Majed Samad, Elia Gatti, Anne Hermes, Hrvoje Benko, and Cesare Parise. 2019. Pseudo-Haptic Weight: Changing the Perceived Weight
of Virtual Objects By Manipulating Control-Display Ratio. In Proceedings of the 2019 CHI Conference on Human Factors in Computing
Systems, CHI 2019, Glasgow, Scotland, UK, May 04-09, 2019, Stephen A. Brewster, Geraldine Fitzpatrick, Anna L. Cox, and Vassilis Kostakos
(Eds.). ACM, 320. https://doi.org/10.1145/3290605.3300550

[46] Krishnankutty Sathian, Laurel J Buxbaum, Leonardo G Cohen, John W Krakauer, Catherine E Lang, Maurizio Corbetta, and Susan M
Fitzpatrick. 2011. Neurological principles and rehabilitation of action disorders: common clinical deficits. Neurorehabilitation and neural
repair 25, 5_suppl (2011), 21Sâ€“32S.

[47] Lumy Sawaki, Andrew J Butler, Xiaoyan Leng, Peter A Wassenaar, Yousef M Mohammad, Sarah Blanton, K Sathian, Deborah S Nichols-
Larsen, Steven L Wolf, David C Good, et al. 2008. Constraint-induced movement therapy results in increased motor map area in subjects
3 to 9 months after stroke. Neurorehabilitation and neural repair 22, 5 (2008), 505â€“513.

[48] Valentin Schwind, Pascal Knierim, Lewis Chuang, and Niels Henze. 2017. " Whereâ€™s Pinky?" The Effects of a Reduced Number of Fingers

in Virtual Reality. In Proceedings of the Annual Symposium on Computer-Human Interaction in Play. 507â€“515.

[49] SciPy. 2021. SciPy. https://www.scipy.org/. Online; accessed 9 September 2021.
[50] Gregory Shakhnarovich. 2005. Learning task-specific similarity. Ph. D. Dissertation. Massachusetts Institute of Technology, Cambridge,

MA, USA. http://hdl.handle.net/1721.1/36138

[51] Oh Shape. 2021. Oh Shape. https://store.steampowered.com/app/1098100/OhShape/. Online; accessed 9 September 2021.
[52] M. Slater, A. Antley, A. Davison, D. Swapp, C. Guger, C. Barker, N. Pistrang, and M. V. Sanchez-Vives. 2006. A Virtual Reprise of the

Stanley Milgram Obedience Experiments. PLOS ONE 1 (2006), e39.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

64:26

â€¢ Li et al.

[53] Mel Slater, Bernhard Spanlang, Maria V Sanchez-Vives, and Olaf Blanke. 2010. First person experience of body transfer in virtual reality.

PloS one 5, 5 (2010), e10564.

[54] M. Slater, B. Spanlang, M. V. Sanchez-Vives, and O. Blanke. 2014. First Person Experience of Body Transfer in Virtual Reality. (2014).
[55] Frank Steinicke, Gerd Bruder, Jason Jerald, Harald Frenz, and Markus Lappe. 2010. Estimation of Detection Thresholds for Redirected

Walking Techniques. IEEE Trans. Vis. Comput. Graph. 16, 1 (2010), 17â€“27. https://doi.org/10.1109/TVCG.2009.62

[56] Robert W Teasell and Lalit Kalra. 2005. Whatâ€™s new in stroke rehabilitation: back to basics. Stroke 36, 2 (2005), 215â€“217.
[57] BjÃ¶rn Van Der Hoort, Arvid Guterstam, and H Henrik Ehrsson. 2011. Being Barbie: the size of oneâ€™s own body determines the perceived

size of the world. PloS one 6, 5 (2011), e20195.

[58] Albert H. van der Veer, Adrian J. T. Alsmith, Matthew R. Longo, Hong Yu Wong, Daniel Diers, Matthias Bues, Anna P. Giron, and
Betty J. Mohler. 2019. The Influence of the Viewpoint in a Self-Avatar on Body Part and Self-Localization. In ACM Symposium on Applied
Perception 2019, SAP 2018, Barcelona, Spain, September 19-20, 2019, SolÃ¨ne Neyret, Elena Kokkinara, Mar GonzÃ¡lez-Franco, Ludovic Hoyet,
Douglas W. Cunningham, and Justyna Swidrak (Eds.). ACM, 3:1â€“3:11. https://doi.org/10.1145/3343036.3343124

[59] Johann Wentzel, Greg dâ€™Eon, and Daniel Vogel. 2020. Improving virtual reality ergonomics through reach-bounded non-linear input

amplification. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. 1â€“12.
[60] Xsens. 2021. Xsens 3D Motion Tracking. https://www.xsens.com/. Online; accessed 9 September 2021.
[61] Yukang Yan, Chun Yu, Xiaojuan Ma, Shuai Huang, Hasan Iqbal, and Yuanchun Shi. 2018. Eyes-Free Target Acquisition in Interaction
Space around the Body for Virtual Reality. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (Montreal
QC, Canada) (CHI â€™18). Association for Computing Machinery, New York, NY, USA, 1â€“13. https://doi.org/10.1145/3173574.3173616

[62] Yukang Yan, Chun Yu, Xin Yi, and Yuanchun Shi. 2018. HeadGesture: Hands-Free Input Approach Leveraging Head Movements for HMD
Devices. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 2, 4, Article 198 (dec 2018), 23 pages. https://doi.org/10.1145/3287076
[63] Nick Yee and Jeremy Bailenson. 2007. The Proteus effect: The effect of transformed self-representation on behavior. Human communication

research 33, 3 (2007), 271â€“290.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 6, No. 2, Article 64. Publication date: June 2022.

