To appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

Towards Sneaking as a Playful Input Modality for Virtual Environments

Sebastian Cmentowski*
High Performance Computing Group
University of Duisburg-Essen

Andrey Krekhov†
High Performance Computing Group
University of Duisburg-Essen

Andr ´e Zenner‡
Saarland University & DFKI
Saarland Informatics Campus

Daniel Kucharski
High Performance Computing Group
University of Duisburg-Essen

Jens Kr ¨uger §
High Performance Computing Group
University of Duisburg-Essen

1
2
0
2

b
e
F
0
1

]

C
H
.
s
c
[

2
v
4
2
0
2
0
.
2
0
1
2
:
v
i
X
r
a

Figure 1: We explore the potential of sneaking as a novel input modality for immersive virtual environments. In addition to hiding
visually, players also must pay attention to their own gait to avoid detection.

ABSTRACT

Using virtual reality setups, users can fade out of their surroundings
and dive fully into a thrilling and appealing virtual environment. The
success of such immersive experiences depends heavily on natural
and engaging interactions with the virtual world. As developers
tend to focus on intuitive hand controls, other aspects of the broad
range of full-body capabilities are easily left vacant. One repeatedly
overlooked input modality is the user’s gait. Even though users
may walk physically to explore the environment, it usually does
not matter how they move. However, gait-based interactions, using
the variety of information contained in human gait, could offer
interesting beneﬁts for immersive experiences. For instance, stealth
VR-games could proﬁt from this additional range of interaction
ﬁdelity in the form of a sneaking-based input modality.

In our work, we explore the potential of sneaking as a playful
input modality for virtual environments. Therefore, we discuss possi-
ble sneaking-based gameplay mechanisms and develop three techni-
cal approaches, including precise foot-tracking and two abstraction
levels. Our evaluation reveals the potential of sneaking-based inter-

*e-mail: sebastian.cmentowski@uni-due.de
†e-mail: andrey.krekhov@uni-due.de
‡e-mail: andre.zenner@dfki.de
§e-mail: jens.krueger@uni-due.de

actions in IVEs, offering unique challenges and thrilling gameplay.
For these interactions, precise tracking of individual footsteps is
unnecessary, as a more abstract approach focusing on the players’
intention offers the same experience while providing better compre-
hensible feedback. Based on these ﬁndings, we discuss the broader
potential and individual strengths of our gait-centered interactions.

Index Terms: Human-centered computing—Virtual reality; Soft-
ware and its engineering—Interactive games

1 INTRODUCTION

Imagine being a spy inﬁltrating a secret base, sneaking past pa-
trolling guards, stealing the conﬁdential information, and leaving —
unseen. This plot reads like a typical mission of any stealth game.
While such games already deliver an intense experience when con-
sumed on a ﬂat-screen, virtual reality (VR) setups provide the unique
potential of boosting tension and involvement even further. Players
may fully dive into the character’s role and experience the plot them-
selves. Nevertheless, existing stealth VR-games often fail to reach
this enormous potential. Most of the available titles, such as Espire
1: VR Operative [12], do not offer a fully fetched sneaking mech-
anism. Instead, players have to use virtual locomotion techniques
and activate a binary sneak mode using hardware buttons. While
enemies may visually detect the players, one of the central aspects
of sneaking is left vacant: being quiet.

In the real world, every step we take emits noise. Apart from
revealing our position and speed, these walking sounds also expose
a broad range of personal information, including gender [36], emo-

1

 
 
 
 
 
 
To appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

tional state [15], or posture [43]. Still, we usually tend to ignore
them in our everyday life. Things change when the situation requires
secrecy and discretion. Sneaking needs both – staying out of sight
and adopting the own gait to minimize walking sounds. On the other
hand, one can also attract attention by producing sounds intention-
ally, i.e., through stomping. This range of interaction ﬁdelity, which
is still missing in today’s VR games, could greatly beneﬁt immersive
VR experiences.

Our research closes this gap by assessing the potential of sneaking
as a novel input modality for immersive virtual environments (IVEs).
Therefore, we split our work into three consecutive parts: We start
by developing the technical basis for capturing the users’ sneaking
behavior. In this process, we provide insights into our exploratory
design process that covered a range of different technical approaches,
e.g., using microphones or marker-based tracking, as well as various
abstraction levels. We also discuss the reasoning behind our ﬁnal
selection of three fundamentally different implementations.

In the second part of this work, we develop possible interactions
and gameplay elements utilizing our stealth mechanisms. Combining
sneaking with other time- or body-based tasks allows us to modify
the overall task difﬁculty and provide varied challenges. In the ﬁnal
step, we compare our three sneaking mechanisms in a between-
subject study, using the developed interaction concepts. Our context
is an immersive stealth VR-game, where the subjects take the role
of a secret agent, stealing conﬁdential information (see Figure 1).

Our results reveal the great potential of sneaking as an input
modality for IVEs, providing high presence and enjoyment levels.
The body-based mechanisms offer unique challenges and thrilling
gameplay. Comparing the different technical approaches, we found
that precise tracking of individual footsteps is unnecessary for the
particular use-case. Instead, a more abstract approach focusing on
the players’ intention offers the same experience while providing
better comprehensible feedback. In turn, accurate footstep tracking
could be used for a variety of other use-cases, e.g., for training simu-
lations providing individual gait-related feedback. These ﬁndings
form the basis for further research on other gait-related interaction
concepts.

2 RELATED WORK

In this section, we cover the related research relevant to this work.
We start by brieﬂy covering the basic concepts linked to playing
games in VR — immersion, presence, and cybersickness. Next,
we provide a concise summary of VR locomotion research, as our
topic is closely linked to this area. Lastly, we discuss the latest
advancements enriching IVEs with novel sensations or a greater
input ﬁdelity, focusing primarily on gait-related approaches.

Modern head-mounted displays (HMDs), such as the Oculus
Quest 2 [13], replace the users’ real surroundings with a realistic
representation of the virtual world.
In this context, researchers
usually call the technical quality of the used hardware immersion [5,
8, 50] and the perceptual effect of being in the IVE presence [18,
51]. The latter is of particular interest for this work and can be
measured using various approaches [10, 24, 37]. Apart from the
positive experience of diving into a fully immersive environment,
VR also bears the risk of causing cybersickness [19, 35]. In this case,
a mismatch between the human vision and the vestibular system
causes symptoms ranging from headaches to vomiting.

Especially poorly suited locomotion techniques bear the risk of
quickly inducing high levels of discomfort [16]. Thus, recent work
has mostly focused on using natural locomotion approaches, such
as real walking [47], to counter this threat. These efforts center
around the concept of extending the walking range by augmenting
real movements [4, 7, 26], changing perspectives [2, 9, 32], or sub-
consciously avoiding real obstacles [46]. Among these approaches,
the walking-in-place concept is of particular interest as it derives
the users’ anticipated motion from in-place steps [52]. While being

superior to gamepad locomotion, early implementations did not feel
as natural as real walking [61]. Thus, later research [14, 56, 68] has
focused on improving the matching, e.g., by using the biomechanics
of human gait [65]. Since our work connects only loosely to VR
locomotion research, we point to Boletsis et al. [6] and Krekhov et
al. [34] for a more detailed overview of the current state of the art.
Recently, a particular focus in VR research has been placed on
enhancing the users’ perception of the virtual world. These efforts
mostly focus on adding additional sensations exceeding the visual
and audio components of currently available headsets. Examples in-
clude haptic surface feedback [66], weight-shifting controllers [69],
or olfactory systems [40]. Instead of adding novel sensations, other
projects used the existing capabilities to manipulate the users’ im-
pression of the virtual world. In this context, a special focus was
placed on the effects of displaying virtual avatars in various shapes
and appearances [38]. For instance, altering the users’ avatar can
not only evoke the impression of changing age [3], race [30, 44], or
even species [33] but also impact mental health, like in the case of
eating disorders [45]. Speciﬁcally related to our particular research
interest, Pan and Steed [42] focused on the inﬂuence of virtual legs
and feet on presence and embodiment.

Apart from enriching the users’ interactions and sensations in
general, a growing body of research has focused on improving the
movement through virtual scenarios. A compelling and realistic
walking experience requires a profound knowledge of the biome-
chanical fundamentals of human gait. The upright bipedal progres-
sion characterizing human locomotion is commonly deﬁned as a
periodic movement of the two lower limbs. The underlying pattern,
i.e., the gait cycle [25], consists of two phases: the swing phase,
where the foot is in the air, and the stance phase, where the foot
has contact with the ground [29]. The latter phase is subdivided
into four stages [23, 39]: heel strike, forefoot contact, midstance,
and heel off. The interplay of alternating swing and stance phases
leads to forward propulsion. Individual differences, such as gender,
age, posture, or walking speed, signiﬁcantly inﬂuence the particular
gait [31, 58], and it was shown that listeners could deduce these
characteristics solely from the emitted walking sounds [63]. Also,
research mainly differentiates between two primary types of gait:
walking and running [11, 21]. Apart from the velocity, the main
difference is the ﬂight phase while running, i.e., no foot is touch-
ing the ground. Thus, we consider sneaking a subtype of walking,
characterized by a more careful foot placement.

In the last decades, foot-based interactions have been of ongoing
interest to the research community [62]. For virtual scenarios, most
of the work has focused on more realistic walking experiences. The
Real-Walk approach by Son et al. [53] simulates various surfaces
by altering the viscosity of a shoe-like apparatus. Similarly, King
et al. [57] combined visual with tactile vibrations to improve the
realism of walking in VR. Strohmeier et al. [54] presented their
bARefoot prototype capable of generating virtual walking surfaces
through motion-coupled vibrations. Our work — exploring sneaking
as an input modality — adds to the research dealing with the auditive
aspect of walking. This research area is mostly centered around
synthesizing or modifying the users’ footstep sounds as part of the
overall soundscape. For instance, Tajadura et al. [55] showed that
modiﬁed walking sounds alter the self-perception. Also, Kern et
al. [28] reported the positive effects of synchronized step sounds on
presence and realism. For a broader view on the interplay between
synthesized footstep sounds and immersive soundscapes, we point
to the extensive work by the Medialogy Department at Aalborg
University Copenhagen [41, 49, 59]. The closest related work in this
ﬁeld is the VRSneaky approach by Hoppe et al. [20]. The authors
use shoe-attached trackers to play gait-aware walking sounds in
a stealthy IVE to provoke a gait-change and achieve an increased
presence. While these works underline the importance of plausible
soundscapes, including synchronized walking sounds, our work

2

To appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

concentrates on the potential of the users’ sneaking behavior as a
novel input modality.

3 DEVELOPING THE SNEAKING MECHANISMS
While past research has already dealt with capturing the users’ walk-
ing behavior and using this information in virtual environments,
these approaches mainly aimed to achieve a realistic soundscape.
In contrast, our mechanism should translate the users’ gait into a
discrete state, i.e., differentiating between walking and sneaking.
This processed information would form the basis for our novel
input modality. From the very start of our design process, we de-
cided to start from scratch and refrain from using any auditory
walking feedback with our mechanism. Existing research, such as
VRSneaky [20], have already demonstrated the beneﬁts of precisely
synchronized footstep sounds for presence and gait awareness. We
wanted to focus entirely on the interactional aspect and determine
the necessary tracking ﬁdelity needed for a plausible sneaking mech-
anism.

Based on this goal, we determined three main requirements for
the target implementation. Firstly, the mechanism must be able to
differentiate between the two states walking and sneaking. We do not
distinguish between walking and stomping, as both share the same
source, i.e., stepping with normal force, and the same effect, i.e.,
attracting attention. Secondly, the used tracking mechanism must
deliver robust signals to determine the active state independent of
the users’ physiologies, walking behavior, and other environmental
factors, i.e., ground, footwear, or noise. Finally, the chosen tracking
method must not impede the users’ movement in the real world in
any way. This constraint also applies to hardware that might alter or
diminish the ﬁne-graded foot movement necessary for sneaking.

Considering these prerequisites, we started by capturing the real
step sounds emitted by the users. Therefore, we attached Bluetooth
microphones to the users’ ankles and used the transmitted audio vol-
ume to extract the users’ gait. This approach is the exact realization
of the abstract idea behind our work. The lightweight microphones
guarantee an easy setup that is not intervening with the actual game-
play. However, external interferences and individual differences
between users are only partially removable by ﬁltering. Eager to ﬁnd
a better alternative, we experimented with various other approaches.
In particular, we shifted our focus from measuring the exact sounds
to detecting the foot motions during sneaking.

Compared to other alternatives, such as force-sensing resistors,
our ﬁnal implementation uses the existent precise VR tracking envi-
ronment and only requires a pair of HTC Vive trackers attached to
the users’ feet. This setup does not inﬂuence the individual sneaking
movement and provides seamless and quick integration with the
overall VR system. As with every sensor device, minor tracking
errors and inaccuracies might occur from time to time. Also, us-
ing the trackers’ exact positions to determine the foot’s touchdown
would require precise calibration as every users’ feet are different.
However, we found that these issues are avoidable by rethinking
the deﬁnition of silent footsteps. When a foot is placed on the ﬂoor,
the ground slows its speed to zero. The faster a foot is slammed
down, the more noise is produced. Thus, the step sounds are directly
dependent on the decrease in velocity.

Plotting the decrease in velocity over time reveals the users’ gait.

Note that we isolate the deceleration alone:

d(v,t) =




∆ v
∆t

0

if ∆ v ≤ 0

otherwise

The resulting peaks correspond to when the users place their foot
on the ﬂoor. These measured values vary only minimally across
different users, making it possible to determine global thresholds
for different types of gait (see Figure 2). While this approach is
immune to typical noise sources, such as random foot movements

Figure 2: Plotted deceleration values (in m/s2) for a typical player. The
average peaks for sneaking, walking, and running activities (from left
to right) vary only minimally across different users, providing robust
thresholds for the different types of gait.

or physiological differences, we noticed that minor tracking errors
might still trigger an unexpected peak. We solved this impediment
by adding a small sliding window to eliminate single erroneous
frames. After all, this tracker-based approach has a minimal impact
on the movement and provides a reliable and precise tracking of the
users’ gait.

During the design process of our ﬁrst implementation, we learned
that it might be beneﬁcial to use a more abstract approach instead
of measuring walking sounds directly. The result stays the same:
we can detect whether users are walking or sneaking. Next, we
asked ourselves: Do we even need to track individual steps? When
testing our early prototypes, all test users shared one similarity when
sneaking: they walked slowly. While it would certainly be possible
to sneak quietly without sacriﬁcing much of the original walking
speed, we usually measured a signiﬁcant decrease in general velocity
during our trials. It seems that this observation is tightly associated
with the users’ expectations. Thus, we designed our second approach
to measure the overall walking speed using the horizontal velocity of
the HMD. The threshold, determining whether users sneak or walk,
was chosen based on the tracking data of our pre-tests. Like the ﬁrst
tracker-based mechanism, we added a sliding window to account for
tracking issues and the head’s micro-movements. Apart from that,
both approaches work almost identical.

The main difference between our two implementations is the loss
of tracking ﬁdelity. Only the ﬁrst technique can detect the actual gait,
whereas the second mechanism relies on an implicit observation.
Nonetheless, both approaches are body-based interactions and are
compatible with natural walking, which is generally seen as the best
locomotion technique for virtual environments [61]. In contrast,
existing stealth VR-games are geared to sneaking mechanisms of
established non-VR games. These games tend to use a binary stealth
mode that is triggered using a hardware button. Players are slowed
down and become harder to detect by the NPCs. Of course, this
approach requires a virtual locomotion technique to control the
player’s position and movement. While not entirely comparable
to our walking-oriented mechanisms, we decided to add gamepad-
based sneaking as a third baseline implementation. This approach
uses a continuous joystick movement and introduces a dedicated
button triggering the sneaking mode. While sneaking, users are
limited to a lower velocity that does not attract attention. It is worth
noting that this mode is optional, as users might use the joystick
carefully enough to achieve the same effect.

Altogether, our design and implementation phase leaves us with

three different approaches to detect sneaking:

• Tracker: ankle-attached trackers measure the foot’s deceleration
• HMD: HMD’s movement is used as a proxy for the users’ speed
• Gamepad: joystick locomotion and button-controlled sneak mode

3

01020304050SneakingWalkingRunningTo appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

Figure 3: Overview of a typical level of our testbed game, including all important elements: the target tablet (A), the enemy guard (B), obstacles
providing cover (C), and the teleporter serving as entry and exit (D).

4 DESIGNING SNEAKING-BASED INTERACTIONS

Apart from developing the technical basis for measuring the users’
gait, it is crucial to design gameplay elements and interactions that
utilize the novel input channel. On the surface, our sneaking mech-
anism appears to be a simple binary differentiation: If the players
walk carefully enough, everything is ﬁne. Otherwise, they are de-
tected.

In this regard, sneaking is very similar to hiding visually from
enemies. Both mechanisms build on top of the normal locomotion
in the virtual scenario. However, they differ in the underlying chal-
lenge. Hiding behind obstacles and avoiding a direct line of sight
is a complex body-based task. Players must pay attention to the
positioning of all body parts, i.e., not letting a limb peek out of
the coverage. On the other hand, sneaking does not constrain the
players’ position but requires careful movement. Thus, hiding is
challenging the where to move and sneaking the how to move. Both
mechanisms are often used in conjunction to increase the overall
difﬁculty.

Besides this famous coalescence, sneaking might be combined
with other interaction patterns to obtain interesting challenges and
vary the degree of difﬁculty. We subdivide these patterns into two
groups: reinforcing and contradicting elements. A task is called
reinforcing if it intensiﬁes the players’ attention on their movement.
Typical examples include stepping over obstacles or crouching be-
hind barriers. These tasks add an additional movement challenge
forcing the players to focus even more on every step. Conversely,
contradicting gameplay elements split the players’ attention between
the newly emerged challenge and the active sneaking task. For in-
stance, getting past patrolling guards requires spatial understanding
and precise timing, while players still must avoid getting heard.

Finally, the switch between quiet sneaking and loud walking itself
is another potential gameplay element. A common feature found
in almost every stealth game is the capability of producing sound
on purpose. Whistling or stomping may attract attention and lure
enemies to desired spots. In essence, this interaction combines the
known gameplay elements. Stomping is another type of reinforcing
action, as it requires stopping sneaking for one single step. Next
follows a typical contradicting time-based task, e.g., guards investi-
gating the noise’s source. Thus, we consider such composite features
to be more complex than their primary counterparts.

Table 1: Gameplay overview of our testbed stealth game. In each of
the ten consecutive levels, we add one additional gameplay concept.

Level Description

Gameplay Concept

01
02
03
04

05
06
07

08
09

10

steal the tablet

sneak
avoid the guard’s sight

guard is outside of the room
guard is outside, tablet is hidden search the tablet
guard is facing the wall
guard is observing the obvious
path
guard is turning regularly
guard patrols along a ﬁxed path analyze the patrol
guard patrols through the entire
room
dynamic obstacles provide cover combine multiple timings
lasers block the path at breast
height
guard stands behind a counter

time the own movements

move while crouching

crouch past obstacles

keep moving

5 EVALUATION

We conducted a study to evaluate our three proposed sneaking tech-
niques using a between-subject design. We were primarily interested
in the general acceptance of our mechanisms and the differences in
enjoyment, presence, tension, difﬁculty, and necessary effort. There-
fore, we designed a VR stealth game that consisted of multiple short
levels, each focusing on one of the introduced interactions.

5.1 Research Questions and Hypotheses

The study’s main goal is to explore the differences between the three
implementations Tracker, HMD, and Gamepad. In this context, we
refer to both of our two proposed approaches, HMD and Tracker, as
full-body movement-based interactions. We hypothesize that these
techniques, resembling real sneaking, beneﬁt the perceived presence.
Additionally, such gait-based interactions force the players to pay
attention to every step they take. Consequently, we expect a signif-
icantly higher physical effort compared to the Gamepad controls.
Also, we assume an overall increase in task complexity. Despite
these difﬁculties, we do not expect a lower success rate. Instead,
the novel challenges are likely to increase the players’ tension and
enjoyment. All in all, our hypotheses are as following:

4

To appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

Table 2: Mean scores, standard deviations, and one-way ANOVA values of the Presence Questionnaire (PQ), the Intrinsic Motivation Inventory
(IMI), the Player Experience Inventory (PXI), the NASA Task Load Index (NASA-TLX), and the Simulator Sickness Questionnaire (SSQ).

Tracker (N = 15)

HMD (N = 15)

Gamepad (N = 15)

F(2,42)

η 2

p

PQ (scale: 0 - 6)
Realism
Possibility to Act
Interface Quality
Possibility to Examine
Performance
Total

IMI (scale: 0 - 6)

Interest/Enjoyment
Pressure/Tension

PXI (scale: 0 - 6)
Challenge

NASA-TLX (scale: 0 - 99)
Physical Demand
Mental Demand

SSQ (scale: 0 - 3)

Nausea
Oculomotor
Disorientation

4.98 (0.63)
4.92 (0.71)
5.16 (1.13)
4.89 (0.88)
4.90 (0.76)
4.97 (0.52)

5.37 (0.46)
3.07 (0.73)

5.03 (0.68)
4.78 (0.55)
5.02 (1.16)
4.80 (0.81)
4.70 (1.11)
4.98 (0.56)

5.20 (0.76)
2.85 (0.59)

4.02 (0.91)
4.83 (0.69)
5.18 (0.64)
4.47 (0.96)
4.57 (1.02)
4.46 (0.66)

5.15 (0.53)
2.27 (0.64)

5.11 (0.85)

4.98 (0.90)

3.73 (1.18)

65.00 (15.81)
53.33 (24.62)

24.80 (23.31)
20.21 (22.68)
22.27 (24.57)

36.00 (23.92)
45.00 (25.00)

9.54 (13.00)
13.82 (9.92)
7.42 (12.74)

25.00 (17.428)
46.33 (21.08)

41.98 (46.71)
33.37 (29.35)
44.54 (46.53)

8.695
0.161
0.106
0.947
0.444
3.897

0.557
5.985

8.929

17.069
0.538

5.007
3.137
5.770

0.293
0.008
0.005
0.043
0.021
0.157

0.026
0.185

.001 **
.852
.900
.396
.644
.028 *

.577
.005 **

0.000

.001 **

0.448
0.025

.000 **
.588

0.163
0.126
0.203

.015 *
.062
.009 *
*p < .05, ** p < .01

• H1: In comparison to the Gamepad condition, the Tracker and
HMD approaches signiﬁcantly increase the perceived presence.
• H2: The full-body conditions require a signiﬁcantly higher phys-

ical effort compared to the Gamepad controls.

• H3: The Tracker and HMD conditions signiﬁcantly increase task

difﬁculty but not the success rate.

• H4: Movement-based sneaking signiﬁcantly boosts players’ en-

joyment and tension compared to the Gamepad approach.

Apart from these four hypotheses, we are also interested in how the
players perceive the different sneaking techniques: Are the controls
easy to learn and usable? How do the techniques compare to real
sneaking? Finally, we want to use the insights from the hypotheses,
logged gameplay data, and participants’ feedback to compare our
two proposed approaches against each other. We summarize both
aspects into two additional research questions:

• RQ1: How do players assess their particular sneaking technique

regarding usability, learnability, and realism?

• RQ2: Are there notable differences between the two proposed

walking-based approaches HMD and Tracker?

5.2 Scenario
We realized the stealth game, used for comparing the different sneak-
ing techniques, with the Unity game engine [60]. The setting is
futuristic and highly technological, including teleports and patrolling
robots (see Figure 3). The players take the role of a spy who must
steal a tablet with conﬁdential information hidden somewhere in
the level. Since two of our sneaking mechanisms rely on natural
walking, we restricted the virtual environment’s size to match our
real play area’s boundaries, i.e., 16 m2. Each of the ten consecutive
levels is structured similarly: The players enter the room using a
teleporter, which serves as a loading screen. While obstacles, e.g.,
crates, walls, or laser barriers, differ each time, at least two elements
are found in every level: the target tablet and a sentinel robot.

This guard is the main antagonist in the game. If players fail to
sneak while walking through the level, they attract attention to their
position, causing the robot to investigate the noise’s source. If the
robot detects the players visually, a bar indicating the alertness level
begins to ﬁll. Similar to other games, only the HMD’s position is

used to determine visibility. Players who fail to interrupt the robot’s
line of sight will be caught and must restart the level. Therefore,
players must do their best to stay unseen and unheard. In the case of
detection, the environment offers various corners and blinds that help
the players hide and wait for the guard to stop searching. Addition-
ally, we provide a holographic noise indicator attached to the hand,
informing the players whether they are sneaking quietly enough. As
only one condition involves positional foot tracking, we refrain from
visualizing feet or body to assure comparability. Also, prior research
already covered the effects of displaying virtual limbs [42].

While walking through the level and locating the tablet, the play-
ers have to overcome various challenges and obstacles. These are
designed carefully to introduce new gameplay concepts one at a
time. In the beginning, players only need to sneak to avoid the guard,
who is looking out of a window. Subsequently, we add the guard’s
lookout, time-based patrols, dynamic obstacles, and crouching ac-
tivities. A complete list of the mechanisms used in each of the ten
levels is depicted in Table 1. After retrieving the tablet, the players
must return quietly to their starting point. They are then teleported
back to a waiting room where they start the next level.

5.3 Procedure and Applied Measures

We conducted a between-subject study splitting the participants ran-
domly into three groups, each using one of the proposed sneaking
techniques. In the beginning, we considered a within-subject design
to collect qualitative feedback comparing the different implemen-
tations. However, the necessary repetition of gameplay elements
paired with the general similarity between the sneaking approaches
would have led to unwanted sequence effects.

We executed the study in our VR lab using an HTC Vive Pro
Wireless setup [22]. On average, the study took 45 minutes. At
ﬁrst, the participants were informed about the overall process and
completed a general questionnaire assessing gender, age, gaming
behavior, and prior VR experience. We also administered the Immer-
sive Tendencies Questionnaire (ITQ) [67] to determine the ability to
get immersed in ﬁction. At last, we introduced the participants to
the VR hardware and assisted them in putting on the hardware.

The participants started the game in a waiting room, where they
were introduced to the controls needed to complete the levels. While
there was no guard present in the waiting room, the subjects could

5

To appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

Table 3: Mean scores, standard deviations, and one-way ANOVA values of the custom questions (CQ).

Question Item

CQ1 The sneaking felt realistic.
CQ2 The sneaking did not feel right.
CQ3 The sneaking technique was intuitive.
CQ4 I had to make an effort to sneak.
CQ5 The sneaking was too difﬁcult.
CQ6 I felt very active while playing.
CQ7 I would have preferred another sneaking

technique.

Tracker

5.20 (1.01)
1.80 (2.04)
4.67 (1.50)
4.20 (1.47)
2.00 (1.69)
5.33 (0.72)
1.80 (1.78)

CQ8 I would have liked to play more levels.
CQ9 I would like to play more

5.27 (1.33)
5.13 (1.25)

sneaking-based VR games in the future.

HMD

Gamepad

F(2,42)

4.53 (1.30)
1.93 (2.15)
4.67 (1.18)
3.07 (1.62)
1.27 (1.16)
5.00 (0.85)
0.73 (1.22)

5.07 (0.88)
4.87 (1.36)

3.67 (1.50)
1.60 (1.55)
5.60 (0.63)
1.00 (0.93)
0.20 (0.41)
3.73 (1.91)
1.80 (1.52)

4.53 (2.10)
4.20 (1.42)

5.361
0.113
3.251
27.759
12.257
25.886
2.445

0.928
2.026

η 2

0.203
0.005
0.134
0.499
0.286
0.238
0.104

0.042
0.088

p

.008 **
.893
.049 *
.000 **
.000 **
.019 **
.099

.403
.145

*p < .05, ** p < .01

use their holographic noise indicator to test the particular sneaking
technique. We did not limit this introductory phase, which usually
only took one to two minutes. After getting used to the controls, the
subjects entered the ﬁrst level by stepping on the teleporting device
and returned to the waiting room between every level. We logged
the relevant statistics, such as the overall playtime or the number of
detections, to analyze the players’ performance.

After completing the ﬁnal level, the subjects removed the HMD
and ﬁlled out a series of questionnaires regarding their experience.
For administering the feeling of presence, we used the Presence
Questionnaire (PQ) [10, 67] focussing on interaction-related pres-
ence. It contains ﬁve subdimensions, each rated on a 7-point Likert
scale (coded 0 - 6): realism, possibility to act, quality of interface,
possibility to examine, and self-evaluation of performance. We also
included the challenge construct of the Player Experience Inventory
(PXI) [1] and two subscales of the Intrinsic Motivation Inventory
(IMI) [48]: interest/enjoyment and pressure/tension (coded 0 - 6).

For assessing the mental and physical effort, we used the NASA
Task Load Index (NASA-TLX) questionnaire [17]. The two chosen
subscales mental demand and physical demand are rated on a 100-
point scale with 5-point steps (coded 0-99). Finally, we also included
the Simulator Sickness Questionnaire (SSQ) [27] with its three sub-
scales nausea, oculumotor, and disorientation. While we expected
to ﬁnd certain differences in cybersickness, these should relate to
the different locomotion techniques, i.e., walking and gamepad, and
not to the sneaking mechanism itself. The questionnaires were ac-
companied by a set of custom questions (coded 0 - 6) to gain further
insights into the participants’ experiences with the sneaking mecha-
nisms (see Table 3). We ﬁnished the study by allowing the subjects
to share their opinions in a semi-structured interview.

6 RESULTS

In total, 45 persons (19 female, 26 male) participated in our study
with a mean age of 24.64 (SD=3.13). Most of the subjects played
digital games a few times a month (93%) and had already used VR
systems before (78%). However, only a minority of 11% reported
using VR regularly. All participants were randomly split into three
study conditions. We did not ﬁnd any signiﬁcant discrepancies be-
tween these groups regarding age, gender, prior VR experience, or
immersive tendencies (all p > .05). As we searched for differences
between the three independent groups, we performed one-way anal-
yses of variances (ANOVA) for all measures. Therefore, we ensured
normal distribution with Kolmogorov-Smirnov and homogeneity of
variances using Levene’s tests. In cases where the data did not meet
the latter requirement, we used Welch’s ANOVA instead. Depending
on Levene’s test results, we chose either Tukey’s or Games-Howell
tests for posthoc comparisons. For legibility reasons, we only re-
port signiﬁcant differences between the conditions, including all
necessary information to ensure reproducibility [64].

6.1 Questionnaires

We assumed that the walking-based implementations lead to higher
enjoyment and tension levels. Table 2 depicts the resulting scores
of the interest/enjoyment and pressure/tension subscales of the IMI.
Only the difference in experienced tension is signiﬁcant, accord-
ing to the ANOVA (p = .005). Posthoc comparisons indicate that
the Gamepad condition elicited signiﬁcantly less tension than the
Tracker condition (p = .005; 95% CI[−1.382, −0.218]) and the
HMD condition (p = .048; 95% CI[−1.169, −0.005]).

Moreover, we compared the perceived presence between the three
study conditions using the PQ questionnaire. As shown in Table 2,
only the measure for experienced realism and the total presence score
indicate a signiﬁcant difference. For perceived realism, the posthoc
tests show that the conditions Gamepad and Tracker (p = .003; 95%
CI[−1.626, −0.298]), as well as Gamepad and HMD (p = .002;
95% CI[−1.673, −0.346]) differed signiﬁcantly. Regarding the total
presence, only the difference between Gamepad and HMD (p =
.050; 95% CI[−1.037, −0.001]) is signiﬁcant.

Further, we wanted to assure that potential cybersickness induced
by locomotion would not impede our study. The results of the
SSQ are listed in Table 2. The values for the Gamepad condi-
tion are signiﬁcantly higher than for the HMD condition (nausea:
p = .018; 95% CI[4.882, 59.990], disorientation: p = .023; 95%
CI[4.999, 69.241]). We presume that this difference is related to
the used locomotion technique rather than the sneaking mechanism.
Most importantly, the values across all groups are low compared to
Kennedy et al.’s reference values [27], thus not indicating signiﬁcant
problems with cybersickness in any of the three conditions.

To test our hypotheses, we also assessed individual subscales of
the NASA-TLX and PXI. The resulting means and standard devia-
tions are listed in Table 2. The perceived challenge, according to the
PXI, differed signiﬁcantly across the conditions. The posthoc tests
indicate that the Tracker (p = .001; 95% CI[0.504, 2.252]) and HMD
(p = .004; 95% CI[0.371, 2.118]) conditions provided a greater chal-
lenge than the Gamepad controls. For the NASA-TLX, only the
physical demand subscale reveals a notable difference: the Tracker
condition required a substantially higher physical effort than the two
other groups (Gamepad: p < .001; 95% CI[24.961, 55.039], HMD:
p = .002; 95% CI[10.525, 47.475]).

6.2 Custom Questions and Logging Data

To better understand the participants’ expectations and experiences,
we also assessed several custom questions. These questions cov-
ered three aspects: realism, usability, and liking. Table 3 lists the
means, standard deviations, and ANOVA results. In particular, the
performed one-way ANOVA reveals notable disparities for ﬁve of
the ten custom questions. For CQ1, posthoc tests indicate that the
Tracker mechanism felt more realistic than the Gamepad approach

6

To appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

guard would hear every loud step immediately”(P5). It seems that
most participants did not notice the inferior tracking ﬁdelity.

H2: The full-body conditions require a signiﬁcantly higher
physical effort compared to the Gamepad controls.
One potential difﬁculty introduced by our proposed mechanisms
is the additional physical demand. The requirement of cautiously
placing every foot increases the necessary physical effort for the
Tracker condition signiﬁcantly. While the values for the HMD con-
dition were also higher than for the Gamepad group, this difference
was not signiﬁcant. Also, VR experiences do not necessarily suffer
from demanding full-body interactions. In contrast, several par-
ticipants appreciated the novel challenge as it forced them ”to be
fully aware of the own body”(P34). Especially the tracker-based
approach caused the subjects to feel very active (CQ6) and was
sometimes as demanding as an ”exergame”(P1).

H3: The Tracker and HMD conditions signiﬁcantly increase
task difﬁculty but not the success rate.
The result from the assessed PXI subscale indicates that our two
proposed approaches increased the game’s challenge signiﬁcantly.
Since both mechanisms are movement-based, players had to stay
cautious and canny even in stressful situations. This conﬂict was
especially noticeable when players got detected and had to outsmart
the guard to avoid failing the level. Several participants reacted
hectically, which sabotaged their goal and usually forced them to
restart the level. As a consequence, the players progressed more
slowly and carefully. While the subjects’ cautious behavior increased
the overall playtime, it had no notable effects on the success rate or
enjoyment. Since developers typically seek this kind of behavior in
stealth games, we consider our approaches’ increased challenge to
beneﬁt the intended genre.

H4: Movement-based sneaking signiﬁcantly boosts players’ en-
joyment and tension compared to the Gamepad approach.
The study’s results conﬁrmed our fourth hypothesis only partially.
Regarding the participants’ enjoyment, we did not ﬁnd any notable
difference between the three groups. Nevertheless, the high scores of
the IMI subscale indicate an overall pleasant experience. Especially
in the groups using real walking, players sometimes described the
gameplay as ”if you were a secret agent in a blockbuster movie”(P9).
Additionally, the tension subscale revealed that our two proposed
techniques elicited a signiﬁcantly higher tension than the gamepad
controls. While there is no considerable difference between the
more accurate tracker-based mechanism and the more abstracted
HMD approach, the results still underline the general advantage of
body-based sneaking. These outcomes are also reﬂected in the oral
feedback: ”it is extremely thrilling to play hide-and-seek with the
guard after already being detected”(P22).

RQ1: How do players assess their particular sneaking tech-
nique regarding usability, learnability, and realism?
In general, most participants learned to use the particular sneak-
ing technique very quickly. The concepts behind each mechanism
were understood intuitively (CQ3) and did not require additional
assistance from the study coordinators. Especially the visual noise
indicator, attached to the players’ hand, was mentioned as a major
aid as it helped to ”gain a feeling for the own loudness”(P14). Af-
ter the ﬁrst levels, the participants mostly ”learned the acceptable
threshold by heart”(P10) and reduced their use of the display.

Since all three sneaking techniques work differently, the players’
difﬁculties and problems varied as well. Some of the subjects using
the gamepad approach reported being challenged by pressing multi-
ple buttons simultaneously, e.g., taking the tablet while sneaking. In
particular, participants with no prior VR experience tended to utter
this concern. In the other groups, players had to pay more attention
to their movement. Later levels increased this challenge by adding
obstacles requiring precise timing or crouching. As this hurdle is

Figure 4: Results from the data logged during the play sessions
(means and standard errors). From left to right: The difference in
playtime for all study groups in seconds; The average number of
audible detections by the NPC guard; The average number of level
restarts caused by the players being caught.

(p = .006; 95% CI[0.392, 2.674]). Even though the ANOVA sug-
gests a signiﬁcant difference for CQ3, posthoc testing could not
conﬁrm this assumption.
the Gamepad condition required a sub-
Concerning CQ4,
stantially lower effort
to sneak than the other two groups
(Tracker: p < .001; 95% CI[−4.324, −2.077], HMD: p = .001;
95% CI[−3.278, −0.855]). Further, the posthoc test reveals a no-
table difference between the Gamepad condition and the Tracker
(p = .003; 95% CI[−2.962, −0.638]) and HMD (p = .010; 95%
CI[−1.882, −0.251]) conditions for CQ5. For CQ6, only the dif-
ference between Gamepad and Tracker conditions is signiﬁcant
(p = .019; 95% CI[−2.945, −0.255]).

Finally, we also analyzed the data logged during the play ses-
sions: the total playtime, the number of detections by the guard,
and the number of level restarts (see Figure 4). Among those,
only the playtime differs signiﬁcantly across the groups. Com-
pared to the Gamepad condition, subjects in the HMD group
played 23% longer (F(2, 26.33) = 9.410; p = .014; η 2 = 0.327;
95% CI[29.808, 293.276]), and participants using the Tracker ap-
proach played even 50% longer (F(2, 26.33) = 9.410; p = .002;
η 2 = 0.327; 95% CI[129.543, 580.650]). However, this discrep-
ancy was not caused by substantial differences in detections or level
restarts.

7 DISCUSSION
Regardless of the used sneaking technique, the majority of players
enjoyed participating in our study. Subjects explicitly mentioned the
potential of sneaking-based interactions for immersive experiences.
According to their feedback, this type of gameplay conforms to the
key advantage of VR by allowing to ”become someone completely
different — like a master spy”(P29). Most subjects wanted to play
more levels (CQ8) and were interested in other sneaking-based VR
games (CQ9). But how do the different implementations compare?
Where are the individual strengths and weaknesses? Our four hy-
potheses and two research questions cover the various aspects of
player experience and usability necessary to answer these questions.

H1: In comparison to the Gamepad condition, the Tracker and
HMD approaches signiﬁcantly increase the perceived presence.
The results from the PQ indicate that the subjects experienced high
levels of presence across all three conditions. However, the two
movement-based techniques both scored higher regarding experi-
enced realism. This ﬁnding supports our primary research goal of
creating a natural and realistic sneaking experience for IVEs. In-
terestingly, the HMD condition got even minimal higher values for
realism and total presence than the precise tracker-based approach.
Players in the HMD group even reported having the feeling that ”the

7

7.077.879.600369GamepadHMDTrackerAverageRestartsofLevels21.3325.9327.200102030GamepadHMDTrackerAverageDetections701862105604008001200GamepadHMDTrackerAveragePlaytimeinSecondsTo appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

primarily relevant for the tracker-based approach, subjects in this
group had signiﬁcantly more problems (CQ5). However, it is worth
noting that only very few players reported being overstrained (CQ5)
or preferring a different technique (CQ7).

Apart from usability and learnability, we were also interested in
the realism of our proposed techniques. How do they compare to real
sneaking? In general, players tend to adapt to simpliﬁcations and ab-
stractions in gameplay elements and usually ignore implausibilities
for the sake of a coherent game experience. Therefore, it does not
surprise that the participants mostly rejected CQ2. However, ask-
ing them personally, subjects articulated more diversiﬁed feedback.
Especially the binary sneak mode of the Gamepad condition ”did
not feel like sneaking but cheating. I stopped using it and controlled
my speed manually”(P3). For the tracker-based sneaking, players
liked that ”every step is relevant. I could even stomp to attract atten-
tion on purpose”(P28). This feedback is reﬂected in the signiﬁcant
difference regarding the realism of the sneaking technique (CQ1).

RQ2: Are there notable differences between the two proposed
walking-based approaches HMD and Tracker?
Our proposed implementations ﬁt their intended purpose and pro-
vide valuable beneﬁts. Compared to established controls, these ap-
proaches can increase the perceived presence, tension, and challenge
without causing frustration or exhaustion. However, generally speak-
ing, both proposed techniques performed very similarly, despite the
differences in tracking precision. While the accurate tracker-based
approach offers some advantages over the HMD abstraction, e.g.,
more realism and physical activity, these did not signiﬁcantly impact
the player experience. In contrast, the feedback for the Tracker con-
dition was more ambiguous than the overall positive HMD feedback.
The oral feedback points towards the most likely reason: with
the hardware trackers, players must pay attention to every single
step they take. In contrast, the HMD approach focuses on the play-
ers’ intentions. Precisely speaking, the mechanism is based on the
assumption that sneaking players walk slowly. Despite being un-
aware of the actual implementations, players intuitively understood
this concept. The HMD approach delivers a comparable experience
to precise tracking while requiring less attention and being more
forgiving. Therefore, it might ﬁt the players’ expectations better.

Furthermore, the HMD implementation relies only on standard
hardware and does not require any additional tracking devices. Con-
sidering both properties, we conclude that the HMD-based approach
is most suited for consumer-oriented experiences, i.e., VR stealth
games. In contrast, the hardware trackers can guarantee far more
precise footstep tracking necessary for enhanced realism and addi-
tional gait-based interactions that are not possible with the HMD
abstraction, e.g., stomping. The technique also builds upon Vive’s
marker-based tracking and is therefore easily applicable to every
VR scenario. These beneﬁts make our approach valuable for other
use-cases as well. For instance, accurate footstep tracking is useful
for a variety of physical activities such as dancing or in speciﬁc
simulation or training applications.

8 LIMITATIONS
In our study, we compared our two movement-based approaches
against the commonly used gamepad controls. This decision was
motivated by the observation that current stealth VR-games tend
to rely on button-controlled sneak modes and joystick locomotion.
Nevertheless, the chosen study setup raises the question of whether
our ﬁndings may instead originate from this difference in locomotion
techniques. While we indeed attribute a notable inﬂuence to the
particular navigation method, the overall low levels of cybersickness
paired with the similar enjoyment levels indicate a comparable user
experience across the groups.

Further, we focussed entirely on the fundamental sneaking mech-
anism, comprising a simple binary differentiation between walking
and sneaking. Consequently, more complex interaction patterns,

such as the introduced stomping concept, were not included in the
study scenario. Especially stomping is an interesting concept, as it
introduces an additional degree of input ﬁdelity, namely exceeding
the sneaking-threshold deliberately. However, such interactions are
not easily realizable for the Gamepad and HMD approaches without
adding additional buttons. Since this step would have introduced
an additional variable for our study, we decided to test the basic
sneaking concept in isolation.

Finally, we decided against any avatar visualization except for the
players’ hands. This decision was mainly motivated by the differ-
ences in tracked devices: Only one condition featured positional feet
tracking. Therefore, displaying virtual feet would have introduced
an additional variable to our study. Instead, we point to the exist-
ing work on virtual avatars as the underlying effects were already
extensively covered. Similarly, we decided to base our detection
algorithms solely on the visibility of the HMD. Thereby, we assured
comparability and avoided frustration caused by peeking limbs. Nev-
ertheless, using the players’ fully tracked and visualized bodies for
the detection mechanism might signiﬁcantly inﬂuence the players’
behavior and the measured effects.

9 CONCLUSION AND FUTURE WORK

Virtual reality games provide the unique opportunity to slip into
the role of the own favorite character and experience a thrilling
adventure ﬁrst-handed. One of these stories may involve a top-secret
agent on his almost impossible mission to save the world. Therefore,
the agent must inﬁltrate a restricted area and secure conﬁdential ﬁles.
While players can already encounter similar plots in available VR
games, these often lack to convey a satisfying stealth experience. In
most cases, players only need to stay out of sight of the probably deaf
guards. Stepsounds rarely have any inﬂuence on the gameplay. This
simpliﬁcation does not use the full interaction ﬁdelity of sneaking
activities and limits the achievable scope of realism.

With our work, we have explored the potential of sneaking as
a novel input modality for such IVEs. Therefore, we developed
two gait-oriented mechanisms to capture the users’ gait. The ﬁrst
measured the feet’s deceleration, while the second used the average
HMD speed as a proxy. We then compared the two approaches
against the established gamepad controls. Our study’s results re-
vealed three interesting takeaways:

1. The experiments conﬁrmed that players generally appreciated

sneaking-based gameplay elements.

2. Our proposed implementations increased the perceived pres-
ence, tension, challenge, and physical activities without over-
charging or exhausting the players.

3. Both approaches performed very similarly, despite the differ-
ences in tracking ﬁdelity and degree of abstraction. In most
cases, it is not necessary to capture exact foot movements, as
the HMD-based implementation provides a similar experience.

In our future research, we will concentrate on further use-cases of
the proposed interaction concepts. In particular, our tracker-based
mechanism opens interesting research directions. It enables pre-
cise detection of the users’ steps, which could be used for other
movement-intense activities, such as dancing. While we mainly
focused on differentiating walking and sneaking, our tracking mech-
anism was also capable of detecting stomping and jumping move-
ments. In the future, we want to extend this concept to identify
more types of gait. Especially training simulations could proﬁt from
this capability to provide individual gait-understanding feedback.
Finally, we aim to combine the proposed gait-based sneaking with
additional channels, namely synchronized audio feedback, voice
detection, haptic feedback, and full-body tracking, to achieve a fully
lifelike sneaking experience.

8

To appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

REFERENCES

[1] V. V. Abeele, K. Spiel, L. Nacke, D. Johnson, and K. Gerling. Devel-
opment and validation of the player experience inventory: A scale to
measure player experiences at the level of functional and psychosocial
International Journal of Human-Computer Studies,
consequences.
135:102370, 2020.

[2] P. Abtahi, M. Gonzalez-Franco, E. Ofek, and A. Steed. I’m a giant:
Walking in large virtual environments at high speed gains. In Proceed-
ings of the 2019 CHI Conference on Human Factors in Computing
Systems, p. 522. ACM, 2019.

[3] D. Banakou, R. Groten, and M. Slater. Illusory ownership of a vir-
tual child body causes overestimation of object sizes and implicit
attitude changes. Proceedings of the National Academy of Sciences,
110(31):12846–12851, 2013.

[4] J. Bhandari, S. Tregillus, and E. Folmer. Legomotion: Scalable
walking-based virtual locomotion. In Proceedings of the 23rd ACM
Symposium on Virtual Reality Software and Technology, VRST ’17,
pp. 18:1–18:8. ACM, New York, NY, USA, 2017. doi: 10.1145/3139131
.3139133

[5] F. Biocca and B. Delaney. Communication in the age of virtual reality.
chap. Immersive Virtual Reality Technology, pp. 57–124. L. Erlbaum
Associates Inc., Hillsdale, NJ, USA, 1995.

[6] C. Boletsis. The new era of virtual reality locomotion: A systematic
literature review of techniques and a proposed typology. Multimodal
Technologies and Interaction, 1(4):24, 2017.

[7] B. Bolte, F. Steinicke, and G. Bruder. The jumper metaphor: an effec-
tive navigation technique for immersive display setups. In Proceedings
of Virtual Reality International Conference, 2011.

[8] P. Cairns, A. Cox, and A. I. Nordin.

Immersion in digital games:
review of gaming experience research. Handbook of digital games, pp.
337–361, 2014.

[9] S. Cmentowski, A. Krekhov, and J. Kr¨uger. Outstanding: A multi-
perspective travel approach for virtual reality games. In Proceedings
of the Annual Symposium on Computer-Human Interaction in Play, pp.
287–299, 2019.

[10] U. Q. Cyberpsychology Lab. Presence questionnaire: Revised by the

uqo cyberpsychology lab, 2004.

[11] F. J. Diedrich and W. H. Warren Jr. Why change gaits? dynamics of
the walk-run transition. Journal of Experimental Psychology: Human
Perception and Performance, 21(1):183, 1995.

[12] Digital Lode. Espire 1: VR Operative. Game [SteamVR], November

2019. Tripwire Interactive LLC.

[13] L. Facebook Technologies. Oculus Quest 2. Website, 2020. Retrieved
October 15, 2020 from https://www.oculus.com/quest-2/.
[14] J. Feasel, M. C. Whitton, and J. D. Wendt. Llcm-wip: Low-latency,
continuous-motion walking-in-place. In 2008 IEEE Symposium on 3D
User Interfaces, pp. 97–104. IEEE, 2008.

[15] B. Giordano and R. Bresin. Walking and playing: What’s the origin of
emotional expressiveness in music. In Proc. Int. Conf. Music Perception
and Cognition, 2006.

[16] M. J. Habgood, D. Wilson, D. Moore, and S. Alapont. Hci lessons
from playstation vr. In Extended Abstracts Publication of the Annual
Symposium on Computer-Human Interaction in Play, CHI PLAY ’17
Extended Abstracts, pp. 125–135. ACM, New York, NY, USA, 2017.
doi: 10.1145/3130859.3131437

[17] S. G. Hart and L. E. Staveland. Development of nasa-tlx (task load
index): Results of empirical and theoretical research. In Advances in
psychology, vol. 52, pp. 139–183. Elsevier, 1988.

[18] C. Heeter. Being there: The subjective experience of presence. Pres-
ence: Teleoperators & Virtual Environments, 1(2):262–271, 1992.
[19] L. J. Hettinger and G. E. Riccio. Visually induced motion sickness in
virtual environments. Presence: Teleoperators & Virtual Environments,
1(3):306–310, 1992.

[20] M. Hoppe, J. Karolus, F. Dietz, P. W. Wo´zniak, A. Schmidt, and T.-K.
Machulla. Vrsneaky: Increasing presence in vr through gait-aware
auditory feedback. In Proceedings of the 2019 CHI Conference on
Human Factors in Computing Systems, pp. 1–9, 2019.

[21] A. Hreljac, R. T. Imamura, R. F. Escamilla, and W. B. Edwards. When
does a gait transition occur during human locomotion? Journal of
sports science & medicine, 6(1):36, 2007.

[22] HTC Corporation. HTC Vive Pro. Website, 2020. Retrieved October
26, 2020 from https://www.vive.com/eu/product/vive-pro/.
[23] B. Huang, M. Chen, W. Ye, and Y. Xu. Intelligent shoes for human
identiﬁcation. In 2006 IEEE International Conference on Robotics and
Biomimetics, pp. 601–606. IEEE, 2006.

[24] W. A. IJsselsteijn, H. de Ridder, J. Freeman, and S. E. Avons. Presence:
concept, determinants, and measurement. vol. 3959, pp. 520–529,
2000. doi: 10.1117/12.387188

[25] V. T. Inman, H. J. Ralston, and F. Todd. Human walking. Williams &

Wilkins, 1981.

[26] V. Interrante, B. Ries, and L. Anderson. Seven league boots: A new
metaphor for augmented locomotion through moderately large scale
immersive virtual environments. In 3D User Interfaces, 2007. 3DUI’07.
IEEE Symposium on. IEEE, 2007.

[27] R. S. Kennedy, N. E. Lane, K. S. Berbaum, and M. G. Lilienthal.
Simulator sickness questionnaire: An enhanced method for quantifying
simulator sickness. The international journal of aviation psychology,
3(3):203–220, 1993.

[28] A. C. Kern and W. Ellermeier. Audio in vr: Effects of a soundscape and
movement-triggered step sounds on presence. Frontiers in Robotics
and AI, 2020.

[29] A. Kharb, V. Saini, Y. Jain, and S. Dhiman. A review of gait cycle
and its parameters. IJCEM International Journal of Computational
Engineering & Management, 13:78–83, 2011.

[30] K. Kilteni, I. Bergstrom, and M. Slater. Drumming in immersive
virtual reality: the body shapes the way we play. IEEE transactions on
visualization and computer graphics, 19(4):597–605, 2013.

[31] S.-u. Ko, S. Stenholm, and L. Ferrucci. Characteristic gait patterns
in older adults with obesity—results from the baltimore longitudinal
study of aging. Journal of biomechanics, 43(6):1104–1110, 2010.
[32] A. Krekhov, S. Cmentowski, , K. Emmerich, M. Masuch, and J. Kr¨uger.
Gullivr: A walking-oriented technique for navigation in virtual reality
games based on virtual body resizing. In Proceedings of the Annual
Symposium on Computer-Human Interaction in Play, CHI PLAY ’18.
ACM, New York, NY, USA, 2018. to appear.

[33] A. Krekhov, S. Cmentowski, K. Emmerich, and J. Kr¨uger. Beyond
human: Animals as an escape from stereotype avatars in virtual reality
games. In Proceedings of the Annual Symposium on Computer-Human
Interaction in Play, pp. 439–451, 2019.

[34] A. Krekhov and K. Emmerich. Player locomotion in virtual reality
games. In The Digital Gaming Handbook, pp. 313–330. CRC Press,
2020.

[35] J. J. LaViola Jr. A discussion of cybersickness in virtual environments.

ACM SIGCHI Bulletin, 32(1):47–56, 2000.

[36] X. Li, R. J. Logan, and R. E. Pastore. Perception of acoustic source
characteristics: Walking sounds. The Journal of the Acoustical Society
of America, 90(6):3036–3049, 1991.

[37] M. Lombard and T. Ditton. At the heart of it all: The concept of
presence. Journal of Computer-Mediated Communication, 3(2):0–0,
1997.

[38] J.-L. Lugrin, M. Ertl, P. Krop, R. Kl¨upfel, S. Stierstorfer, B. Weisz,
M. R¨uck, J. Schmitt, N. Schmidt, and M. E. Latoschik. Any “body”
there? avatar visibility effects in a virtual reality game. In 2018 IEEE
Conference on Virtual Reality and 3D User Interfaces (VR), pp. 17–24.
IEEE, 2018.

[39] R. E. Morley, E. J. Richter, J. W. Klaesner, K. S. Maluf, and M. J.
Mueller. In-shoe multisensory data acquisition system. IEEE Transac-
tions on Biomedical Engineering, 48(7):815–820, 2001.

[40] T. Nakamoto, T. Hirasawa, and Y. Hanyu. Virtual environment with
smell using wearable olfactory display and computational ﬂuid dynam-
ics simulation. In 2020 IEEE Conference on Virtual Reality and 3D
User Interfaces (VR), pp. 713–720. IEEE, 2020.

[41] R. Nordahl, L. Turchet, and S. Seraﬁn. Sound synthesis and evaluation
of interactive footsteps and environmental sounds rendering for virtual
reality applications. IEEE transactions on visualization and computer
graphics, 17(9):1234–1244, 2011.

[42] Y. Pan and A. Steed. How foot tracking matters: The impact of an
animated self-avatar on interaction, embodiment and presence in shared
virtual environments. Frontiers in Robotics and AI, 6:104, 2019.
[43] R. E. Pastore, J. D. Flint, J. R. Gaston, and M. J. Solomon. Auditory

9

To appear in 2021 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).

event perception: The source—perception loop for posture in human
gait. Perception & psychophysics, 70(1):13–29, 2008.

[44] T. C. Peck, S. Seinfeld, S. M. Aglioti, and M. Slater. Putting yourself
in the skin of a black avatar reduces implicit racial bias. Consciousness
and cognition, 22(3):779–787, 2013.

[45] C. Perpi˜n´a, C. Botella, R. Ba˜nos, H. Marco, M. Alca˜niz, and S. Quero.
Body image and virtual reality in eating disorders: Is exposure to
virtual reality more effective than the classical body image treatment?
CyberPsychology & Behavior, 2(2):149–155, 1999.

[46] S. Razzaque, Z. Kohn, and M. C. Whitton. Redirected walking. In
Proceedings of EUROGRAPHICS, vol. 9, pp. 105–106. Citeseer, 2001.
[47] R. A. Ruddle and S. Lessels. The beneﬁts of using a walking interface
to navigate virtual environments. ACM Transactions on Computer-
Human Interaction (TOCHI), 16(1):5, 2009.

[48] R. M. Ryan and E. L. Deci. Self-determination theory and the fa-
cilitation of intrinsic motivation, social development, and well-being.
American psychologist, 55(1):68, 2000.

[49] S. Seraﬁn, L. Turchet, and R. Nordahl. Extraction of ground reaction
forces for real-time synthesis of walking sounds. Proc. Audiomostly,
2009.

[50] W. R. Sherman and A. B. Craig. Understanding virtual reality: Inter-

face, application, and design. Elsevier, 2002.

[51] M. Slater. A note on presence terminology. Presence connect, 3(3):1–5,

2003.

[52] M. Slater, A. Steed, and M. Usoh. The virtual treadmill: A naturalistic
metaphor for navigation in immersive virtual environments. In Virtual
environments’ 95, pp. 135–148. Springer, 1995.

[53] H. Son, H. Gil, S. Byeon, S.-Y. Kim, and J. R. Kim. Realwalk: Feeling
ground surfaces while walking in virtual reality. In Extended Abstracts
of the 2018 CHI Conference on Human Factors in Computing Systems,
pp. 1–4, 2018.

[54] P. Strohmeier, S. G¨ung¨or, L. Herres, D. Gudea, B. Fruchard, and
J. Steimle. barefoot: Generating virtual materials using motion coupled
vibration in shoes. In Proceedings of the 33rd Annual ACM Symposium
on User Interface Software and Technology, pp. 579–593, 2020.
[55] A. Tajadura-Jim´enez, M. Basia, O. Deroy, M. Fairhurst, N. Marquardt,
and N. Bianchi-Berthouze. As light as your footsteps: altering walking
sounds to change perceived body weight, emotional state and gait. In
Proceedings of the 33rd annual ACM conference on human factors in
computing systems, pp. 2943–2952, 2015.

[56] J. N. Templeman, P. S. Denbrook, and L. E. Sibert. Virtual locomotion:
Walking in place through virtual environments. Presence, 8(6):598–
617, 1999.

[57] L. Terziman, M. Marchal, F. Multon, B. Arnaldi, and A. L´ecuyer. The
king-kong effects: Improving sensation of walking in vr with visual
and tactile vibrations at each step. In 2012 IEEE Symposium on 3D
User Interfaces (3DUI), pp. 19–26. IEEE, 2012.

[58] N. F. Troje. Retrieving information from human movement patterns.
Understanding events: How humans see, represent, and act on events,
1:308–334, 2008.

[59] L. Turchet, R. Nordahl, and S. Seraﬁn. Examining the role of context
in the recognition of walking sounds. In Proc. of Sound and Music
Computing Conference, 2010.

[60] Unity Technologies. Unity. Website, 2020. Retrieved October 26,

2020 from https://unity.com/.

[61] M. Usoh, K. Arthur, M. C. Whitton, R. Bastos, A. Steed, M. Slater,
and F. P. Brooks Jr. Walking¿ walking-in-place¿ ﬂying, in virtual envi-
ronments. In Proceedings of the 26th annual conference on Computer
graphics and interactive techniques, pp. 359–364. ACM Press/Addison-
Wesley Publishing Co., 1999.

[62] E. Velloso, D. Schmidt, J. Alexander, H. Gellersen, and A. Bulling. The
feet in human–computer interaction: A survey of foot-based interaction.
ACM Computing Surveys (CSUR), 48(2):1–35, 2015.

[63] Y. Visell, F. Fontana, B. L. Giordano, R. Nordahl, S. Seraﬁn, and
R. Bresin. Sound design and perception in walking interactions. Inter-
national Journal of Human-Computer Studies, 67(11):947–959, 2009.
[64] J. B. Vornhagen, A. Tyack, and E. D. Mekler. Statistical signiﬁcance
testing at chi play: Challenges and opportunities for more transparency.
In Proceedings of the Annual Symposium on Computer-Human Inter-
action in Play, pp. 4–18, 2020.

[65] J. D. Wendt, M. C. Whitton, and F. P. Brooks. Gud wip: Gait-
understanding-driven walking-in-place. In 2010 IEEE Virtual Reality
Conference (VR), pp. 51–58. IEEE, 2010.

[66] E. Whitmire, H. Benko, C. Holz, E. Ofek, and M. Sinclair. Haptic
revolver: Touch, shear, texture, and shape rendering on a reconﬁgurable
virtual reality controller. In Proceedings of the 2018 CHI Conference
on Human Factors in Computing Systems, pp. 1–12, 2018.

[67] B. G. Witmer and M. J. Singer. Measuring presence in virtual environ-
ments: A presence questionnaire. Presence, 7(3):225–240, 1998.
[68] L. Yan, R. Allison, and S. Rushton. New simple virtual walking
method-walking on the spot. In Proceedings of the IPT Symposium, pp.
1–7, 2004.

[69] A. Zenner and A. Kr¨uger. Drag: on: A virtual reality controller provid-
ing haptic feedback based on drag and weight shift. In Proceedings of
the 2019 CHI Conference on Human Factors in Computing Systems,
pp. 1–12, 2019.

10

