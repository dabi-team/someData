Federated Echo State Learning for Minimizing Breaks in

Presence in Wireless Virtual Reality Networks

1

Mingzhe Chen, Omid Semiari, Member, IEEE, Walid Saad, Fellow, IEEE,

Xuanlin Liu, Changchuan Yin, Senior Member, IEEE,

9
1
0
2

p
e
S
3
1

]
T
I
.
s
c
[

2
v
2
0
2
1
0
.
2
1
8
1
:
v
i
X
r
a

Abstract

In this paper, the problem of enhancing the virtual reality (VR) experience for wireless users is

investigated by minimizing the occurrence of breaks in presence (BIP) that can detach the users from

their virtual world. To measure the BIP for wireless VR users, a novel model that jointly considers

the VR application type, transmission delay, VR video quality, and users’ awareness of the virtual

environment is proposed. In the developed model, the base stations (BSs) transmit VR videos to the

wireless VR users using directional transmission links so as to provide high data rates for the VR users,

thus, reducing the number of BIP for each user. Since the body movements of a VR user may result

in a blockage of its wireless link, the location and orientation of VR users must also be considered

when minimizing BIP. The BIP minimization problem is formulated as an optimization problem which

jointly considers the predictions of users’ locations, orientations, and their BS association. To predict the

orientation and locations of VR users, a distributed learning algorithm based on the machine learning

framework of deep (ESNs) is proposed. The proposed algorithm uses concept from federated learning to

enable multiple BSs to locally train their deep ESNs using their collected data and cooperatively build

a learning model to predict the entire users’ locations and orientations. Using these predictions, the

user association policy that minimizes BIP is derived. Simulation results demonstrate that the developed

algorithm reduces the users’ BIP by up to 16% and 26%, respectively, compared to centralized ESN

and deep learning algorithms.

M. Chen, X. Liu, and C. Yin are with the Beijing Key Laboratory of Network System Architecture and Convergence, Beijing

University of Posts and Telecommunications, Beijing, 100876, China, Emails: xuanlin.liu@bupt.edu.cn, ccyin@ieee.org.

M. Chen is also with the Chinese University of Hong Kong, Shenzhen, 518172, China, and with the Department of Electrical

Engineering, Princeton University, Princeton, NJ, 08544, USA, Email: mingzhec@princeton.edu.

O. Semiari is with the Department of Electrical and Computer Engineering, University of Colorado Colorado Springs, Colorado

Springs, CO, 80918, USA, Email: osemiari@uccs.edu.

W. Saad is with the Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg,

VA, 24060, USA, Email: walids@vt.edu.

A preliminary version of this work was published in the IEEE GLOBECOM conference [1].

 
 
 
 
 
 
I. INTRODUCTION

2

Deploying virtual reality (VR) applications over wireless networks is an essential stepping

stone towards ﬂexible deployment of pervasive VR applications [2]. However, to enable a seam-

less and immersive wireless VR experience, it is necessary to introduce novel wireless networking

solutions that can meet stringent quality-of-service (QoS) requirements of VR applications [3].

In wireless VR, any sudden drops in the data rate or increase in the delay can negatively

impact the users’ VR experience (e.g., due to interruptions in VR video streams). Due to such

an interruption in the virtual world, VR users will experience breaks in presence (BIP) events

that can be detrimental to their immersive VR experience. While the ﬁfth-generation (5G) new

radio supports operation at high frequency bands as well as ﬂexible frame structure to minimize

latency, the performance of communication links at high frequencies is highly prone to blockage.

That is, if an object blocks the wireless link between the BS and a VR user, the data rate can

drop signiﬁcantly and lead to a BIP. In addition to wireless factors such as delay and data rate,

behavioral metrics related to each VR user such as the user’s awareness can also induce BIP.

Awareness is deﬁned as each wireless VR user’s perceptions and actions in its individual VR

environment. Therefore, to minimize the BIP of VR users, it is necessary to jointly consider all

of the wireless environment and user-speciﬁc metrics that cause BIP, such as link blockage, user

location, user orientation, user association, and user awareness.

Recently, several works have studied a number of problems related to wireless VR networks

[4]–[11]. The work in [4] developed a multipath cooperative route scheme to enable VR wireless

transmissions. In [5], the authors develop a framework for mobile VR delivery by leveraging the

caching and computing capabilities of mobile VR devices. The authors in [6] study the problem

of supporting visual and haptic perceptions over wireless cellular networks. A communications-

constrained mobile edge computing framework is proposed in [7] to reduce wireless resource

consumption. The work in [8] proposes a concrete measure for the delay perception of VR

users. The authors in [9] present a scheme of proactive computing and high-frequency, millimeter

wave (mmWave) [12] transmission for wireless VR networks. In [10], the authors design several

experiments for quantifying the performance of tile-based 360◦ video streaming over a real

cellular network. Our previous work in [11] studied the problems of resource allocation and 360◦

content transmission. However, most of these existing works do not provide a comprehensive

3

BIP model that accounts for the transmission delay, the quality of VR videos, VR application

type, and user awareness. Moreover, the prior art in [4]–[11] does not jointly consider the impact

of the users’ body movements when using mmWave communications.

To address this challenge, machine learning techniques can be used to predict the users’

movements and proactively determine the user associations that can minimize BIP. However,

in prior works on machine learning for user movement predictions [13]–[17], the data for each

user’s movement must be collected by its associated BS. However, in real mobile VR scenarios,

users will move and change their association and the data related to their movement is dispersed

across multiple BSs. In such scenarios, the BSs may not be able to continuously share collected

user data among each other, due to the high overhead of data transmission. Moreover, sending

all the information to a centralized processing server will cause very large delays that cannot be

tolerated by VR applications. Thus, centralized machine learning algorithms such as in [13]–[17]

will not be useful to predict real-time movements of the VR users. To this end, a distributed

learning framework that can be trained by the collected data at each BS is needed.

Recently, a number of existing works such as in [18]–[21] studied important problems related

to the implementation of distributed learning over wireless networks. While interesting, these

prior works [18]–[21] that focus on the optimization of the performance of distributed learning

algorithms such as federated learning do not consider the use of distributed learning to optimize

the performance of wireless networks. In particular, these existing works [18]–[21] do not

consider the use of distributed learning algorithms to predict users’ orientations and locations to

reduce the BIP of wireless VR users. Note that, in [1], we have studied the use of a single-layer

echo state network (ESN) model with federated learning for orientation and location predictions.

However, the federated learning algorithm of [1] cannot be used to analyze a large dataset.

Meanwhile, the work in [1] does not analyze the prediction accuracy or memory capacity of the

introduced learning algorithm.

The key contribution of this work is to develop a novel framework for minimizing BIP within

VR applications that operate over wireless networks. To our best knowledge, this paper is the

ﬁrst to analyze how a wireless network with distributed learning can minimize BIP for VR users

and enhance their virtual world experience. The key contributions therefore include:

• For wireless VR users, we mathematically model a new BIP metric that jointly considers

VR application type, the delay of VR video and tracking information transmission, VR

4

video quality, and the users’ awareness.

• To minimize the BIP of wireless VR users, we develop a federated ESN [22] learning

algorithm that enables BSs to locally train their machine learning algorithms using the

data collected from the users’ locations and orientations. Then, the BSs can cooperatively

build a learning model by sharing their trained models to predict the users’ locations and

orientations. Based on these predictions, we perform fundamental analysis to ﬁnd an efﬁcient

user association for each VR user that minimizes the BIP.

• To analyze the prediction accuracy of the federated ESN learning algorithm, we study

the memory capacity of federated ESNs. The memory capacity characterizes the ability

of the ESN model to record historical locations and orientations of each VR user. As the

memory capacity increases, the prediction accuracy will improve. Since the BSs determine

the user association based on these predictions, better prediction accuracy will lead to a

more effective user association scheme that will minimize the number of BIP. The analytical

results show that the memory capacity of ESNs depends on the number of neurons in each

ESN model and the values of matrices that are used to generate the ESN model.

• Simulation results demonstrate that our proposed algorithm can achieve signiﬁcant improve-

ments in the statistics of BIP that occur within a wireless VR network.

The rest of this paper is organized as follows. The problem formulation is presented in Section

II. The federated ESN learning algorithm for the predictions is proposed in Section III. In Section

IV, the memory capacity of various ESN models are analyzed. The user association is found in

Section V. In Section VI, simulation results are presented and conclusions are drawn in Section

VII.

II. SYSTEM MODEL AND PROBLEM FORMULATION

Consider a cellular network that consists of a set B of B BSs that service a set U of U VR

users. In this model, BSs act as VR controllers that can collect the tracking information related

to the users’ movements via VR sensors and use the collected data to generate the VR videos for

their associated users, as shown in Fig. 1. In particular, the uplink is used to transmit tracking

information such as users’ locations and orientations from the VR devices to the BSs, while

the downlink is used to transmit VR videos from BSs to VR users. For user association, the

VR users can associate with different BSs for uplink and downlink data transmissions. Different

5

Fig. 1.

The architecture of a wireless VR network. In this architecture, the Sub-6 GHz uplink is used to transmit tracking

information and the mmWave downlink is used to transmit VR videos.

from prior works such as in [3], [5]–[11] that assume the VR users to be static, we consider a

practical scenario in which the locations and orientations of the VR users will impact the VR

application performance.

A. Transmission Model

We consider both uplink and downlink transmission links between BSs and VR users. The VR

users can operate at both mmWave and sub-6 GHz frequencies [23]–[25]. The VR videos are

transmitted from BSs to VR users over the 28 GHz band. Meanwhile, the tracking information

is transmitted from VR devices to their associated BSs over a sub-6 GHz frequency band. This

is due to the fact that sub-6 GHz frequencies with limited bandwidth cannot support the large

data rates required for VR video transmissions. However, it can provide reliable communications

for sending small data sized users’ tracking information.

1) Uplink Transmissions of User Tracking Information: Let (xit, yit) be the Cartesian co-

ordinates for the location of user i at time t and S be the data size of each user’s tracking

information, including location and orientation. S depends on the VR system (i.e., HTC Vive

[26] or Oculus [27]). The data rate for transmitting the tracking information from VR user i to

BS j is given by:



ij (xit, yit) = F ULlog2
cUL


1 +

(cid:80)
k∈Ui

Pugijd−β
Pugkjd−β

ij (xit, yit)
kj (xkt, ykt)+ρ2




,

(1)

mmWaveSub-6 GHz6

where F UL is the bandwidth of each subcarrier, U UL

j

is the number of VR users associated with

BS j over uplink, Ui is the set of VR users that use the same subcarriers with user i, Pu is the

transmit power of each VR user (assumed equal for all users), gij is the Rayleigh channel gain,
dij is the distance between VR user i and BS j at time t, and ρ2 is the noise power.

2) Downlink VR Video Transmission: In the downlink, antenna arrays are deployed at BSs to

perform directional beamforming over the mmWave frequency band. For simplicity, a sectored

antenna model [28] is used to approximate the actual array beam patterns. This simpliﬁed antenna

model consists of four parameters: the half-power beamwidth φ, the boresight direction θ, the

antenna gain of the mainlobe Q, and the antenna gain of the sidelobe q. Let ϕij be the phase

from BS j to VR user i. The antenna gain of the transmission link from BS j to user i is:

Gij =






Q, if |ϕij − θj| (cid:54) φ
2 ,
q, if |ϕij − θj| > φ
2 .

(2)

Since the VR device is located in front of the VR user’s head, the mmWave link will be

blocked, if the user rotates. Let χit be the orientation of user i at time t and ϑ be the maximum

angle using which BS j can directly transmit VR videos to a user without any human body

blockage. φ(cid:48)

ij denotes the phase from user i to BS j. For user i, the blockage effect, bi (χit),

caused by its own body can be given by:



bi (χit) =

1, if (cid:12)
0, if (cid:12)

(cid:12)ϕ(cid:48)
(cid:12)ϕ(cid:48)

ij − χit
ij − χit

(cid:12)
(cid:12) (cid:54) ϑ,
(cid:12)
(cid:12) > ϑ.

(3)



We assume that each VR user’s body constitutes a single blockage area and nijt represents the

number of VR users located between user i and BS j at time t. If there are no users located

between user i and BS j that block the mmWave link, i.e., (bi (χit) + nij = 0, then, as shown

in Fig. 2(a)), the communication link between user i and BS j is line-of-sight (LoS). If the

mmWave link between user i and BS j is blocked by the user i’s own body (as shown in Fig.

2(b), bi (χit) = 1) or blocked by other users located between user i and BS j (as shown in Fig.

2(c), +nij > 0), then the communication link between user i and BS j is said to be non-line-

of-sight (NLoS). From (3), we can see that bi (χit) and nij can be directly determined by the

users’ orientations and locations.

Considering path loss and shadowing effects, the path loss for a LoS link and a NLoS link

(4)

(5)

(cid:18) d0fc4π
ν
(cid:18) d0fc4π
ν

(cid:19)

7

(a) LoS links.

(b) NLoS links caused by the user’s

(c) NLoS links caused by other user’s body.

own body.

Fig. 2. VR video transmission over LoS/NLoS links

between VR user i and BS j in dB will be given by [28]:

hLoS
ij

(xit, yit) = 20 log

(cid:19)

+ 10(cid:36)LoS log (dij (xit, yit)) + µσLoS,

hNLoS
ij

(xit, yit) = 20 log

+ 10(cid:36)NLoS log (dij (xit, yit)) + µσNLoS,

where 20 log (cid:0) d0fc4π

(cid:1) is the free space path loss. Here, d0 represents the reference distance, fc is
the carrier frequency and ν is the light speed. (cid:36)LoS and (cid:36)NLoS represent the path loss exponents

ν

for the LoS and NLoS links, respectively. µσLoS and µσNLoS represent Gaussian random variables
with zero mean, respectively. σLoS and σNLoS represent the standard deviations for LoS and NLoS

links in dB, respectively. The downlink data rate of VR video transmission from BS j to user i

is given by:

cDL
ij (xit, yit, bi (χit) , nij) =






(cid:18)

F DLlog2

(cid:18)

F DLlog2

1 + PBGij
ij /10
hLoS
10
1 + PBGij
ij /10
hNLoS
10

ρ2

(cid:19)

, if bi (χit) + nij = 0,

(cid:19)

(6)

, if bi (χit) + nij > 0,

ρ2

where F DL is the bandwidth allocated to each user and PB is the transmit power of each BS j

which is assumed to be equal for all BSs. Since the downlink uses mmWave links, we assume

that, due to directivity, interference in (6) can be neglected, as done in [29].

B. Break in Presence Model

In a VR application, the notion of a BIP represents an event that leads the VR users to realize

that they are in a ﬁctitious, virtual environment, thus ruining their immersive experience. In

other words, a BIP event transitions a user from the immersive virtual world to the real world

[30]. For wired VR, BIP can be caused by various factors such as hitting the walls/ceiling, loss

of tracking with the device, tripping on wire cords, or talking to another person from the real

LoS linkNLoS linkNLoS linkworld [30]. For wireless VR, BIP can be also caused by the delay of VR video and tracking

information transmission, the quality of the VR videos received by the VR users, and inaccurate

tracking information received by BSs.

8

mission and the quality of the VR videos. We ﬁrst deﬁne a vector li,t

To model such BIP, we jointly consider the delay of VR video and tracking information trans-
ij (xit, yit, bi (χit) , nij)(cid:1) =
[li1,t, . . . , liNL,t] that represents a VR video that user i received at time t with lik,t ∈ {0, 1}.
lik,t = 0 indicates that pixel k is not successfully received by user i, and lik,t = 1, otherwise. We
also deﬁne a vector mi,t (GA) = [mi1,t, . . . , miNL,t]T that represents the weight of the importance
of each pixel constructing a VR video, where mik,t ∈ [0, 1] and GA represents a VR application

(cid:0)cDL

such as an immersive VR game or a VR video. mik,t = 1 indicates that pixel k is one of the most

important elements for the generation of GA. The value of mik,t depends on the compression

used for the VR video. In each VR application GA, a number of pixels can be compressed at

the BS and recovered by the user and, hence, these pixels are not important. However, the pixels

that cannot be compressed by the BS are important and must be transmitted to the VR users.

Therefore, each pixel will have different importance and mik,t ∈ [0, 1]. Then, the BIP of VR

user i caused by the wireless transmission will be given by:

ωit

(cid:0)xit, yit, χit, aUL

i,t , aDL
i,t

(cid:1) =

1(cid:40)

A

cUL
ij (xit,yit)

aUL
ij,t

+

D(li,t(aDL
ik,t
cDL
aDL
ik (xit,yit,bi(χit),nik)
ik,t

ik (xit,yit,bi(χit),nik)))
cDL

>γD ∨ li,t(aDL

ik,tcDL

ik (xit,yit,bi(χit),nik))mi,t(GA)<γQ

(cid:41). (7)

where 1{x} = 1 if x is true, and otherwise, we have 1{x} = 0. 1{x} ∨ 1{y} = 1 as y or x is true,
(cid:3) is a vector that represents user i’s uplink
1{x} ∨ 1{y} = 0, otherwise. aUL
(cid:3) is a vector that
i,t = (cid:2)aDL
i1,t, . . . , aDL
association with aUL
iB,t
aDL
ik,t = 1. γD and γQ represent
the target delay and video quality requirements, respectively. In (7), A represents the data size of

i,t = (cid:2)aUL
i1,t, . . . , aUL
iB,t
ik,t = 1. Similarly, aDL
aUL

represents user i’s downlink association with aDL

ik,t ∈ {0, 1} and (cid:80)

ik,t ∈ {0, 1} and (cid:80)

k∈B

k∈B

the tracking information,

A

from user i to BS j, D (li,t (cDL
ik (xit,yit,bi(χit),nik)))
D(li,t(cDL
cDL
ik (xit,yit,bi(χit),nik)

ij (xit,yit) represents the time used for tracking information transmission
cUL
ik (xit, yit, bi (χit) , nik))) represents the data size of a VR video, and
represents the transmission latency for sending the tracking information
(cid:1). (7)

(cid:0)xit, yit, χit, aUL

i,t , aDL
i,t

from BS k to user i. For simplicity, hereinafter, ωit is referred as ωit

shows that if the delay of VR video and tracking information transmission exceeds the target

delay threshold allowed by VR systems or the quality of the VR video cannot meet the video

requirement, users will experience a BIP (ωit=1). From (7), we can also see that, the BIP of user

9

i caused by wireless transmission depends on user i’s location, orientation, VR applications, and

user association. (7) captures the BIP caused by wireless networking factors such as transmission

delay and video quality. Next, we deﬁne a BIP model that jointly considers wireless transmission,

the VR application type, and the users’ awareness. The BIP of user i can be given by [31]:

Pi

(cid:0)xit, yit, GA, χit, aUL

i,t , aDL
i,t

(cid:1) =

1
T

T
(cid:88)

t=1

(cid:0)GA + ωit + GAωit + (cid:15)i + (cid:15)GA|i + (cid:15)B

(cid:1) ,

(8)

where (cid:15)i

is user i’s awareness, (cid:15)GA|i

is the joint effect caused by user i’s awareness and

VR application GA, and (cid:15)B is a random effect. (cid:15)i, (cid:15)GA|i, and (cid:15)B follow a Gaussian distri-
i , σ2
bution [31] with zero mean and variances σ2

B, respectively. In (8), the value
(cid:1) quantiﬁes the average number of BIP that user i can identify

of Pi

(cid:0)xit, yit, GA, χit, aUL

i,t , aDL
i,t

GA|i, and σ2

during a period. From (8), we can see that, as the VR application for user i changes, the BIP

value will change. For example, a given user watching VR videos will experience fewer BIP

compared to a user engaged in an immersive ﬁrst-person shooting game. This is due to the fact

that in an immersive game environment, users are fully engaged with the virtual environment, as

opposed to some VR applications that require the user to only watch VR videos. In (8), we can

also see that the BIP depend on the users’ awareness. This means that different users will have

different actions and perceptions when they interact with the virtual environment and, hence,

different VR users may experience different levels of BIP.

C. Problem Formulation

From (8), we can see that the BIP of each user depends on this user’s location, orientation,

and selected BSs. By using an effective learning algorithm to predict the users’ locations and

orientations, the BSs can proactively determine the users’ association to improve the downlink

and uplink data rates and minimize BIP for each VR user. The BIP minimization problem is:

min
aUL
i,t,aDL
i,t

(cid:88)

i∈U

Pi

(cid:0)ˆxit, ˆyit, GA, ˆχit, aUL

i,t , aDL
i,t

(cid:1)

s. t.

Uj (cid:54) V,

∀j ∈ B,

ij,t, aDL
aUL

ij,t ∈ {0, 1} , ∀i ∈ U, ∀j ∈ B,
ij,t = 1, (cid:80)
aUL

aDL
ij,t = 1,

∀i ∈ U,

(cid:80)
j∈B

j∈B

(9)

(9a)

(9b)

(9c)

10

where ˆxit, ˆyit, and ˆχit are the predicted locations and orientation of user i at time t, which depend

on the actual historical locations and orientation of user i. Uj is the number of VR users associated

with BS j over downlink and V is the maximum number of users that can be associated with each

BS. (9b) and (9c) show that each user can associate with only one uplink BS and one downlink

BS. From (9), we can see that the BIP of each user will depend on the user association as well as

the users’ locations and orientations. Meanwhile, the user association depends on the locations

and orientations of the VR users. If the BSs perform the user association without knowledge of

the locations and orientations of the users, the body blockage between the user-BS transmission

links can potentially be signiﬁcant, thus increasing the BIP of each user. Therefore, the BSs

must use historical information related to the users’ locations and orientations to determine

the user association. As the users’ locations and orientations will continuously change as time

elapses, BSs must proactively determine the user association to reduce the BIP of VR users.

In consequence, it is necessary to introduce a machine learning algorithm to predict the users’

locations and orientations in order to determine the user association and minimize BIP of VR

users. In the model deﬁned in Section II, the user association changes as the users’ location and

orientation vary with time. Consequently, each BS that connects to a given VR user can only

collect partial information about this user’s locations and orientation. However, a BS cannot rely

on partial information to predict each user’s location and orientation. Moreover, since a given

VR user will change its association, the data pertaining to this VR user’s movement will be

located at multiple BSs. Hence, traditional centralized learning algorithms that are implemented

by a given BS cannot predict the entire VR user’s locations and orientations without knowing

the user’s data collected by other BSs. To overcome the challenges mentioned previously, we

introduce a distributed federated learning framework that can predict the location and orientation

of each VR user as the training data related to each user’s locations and orientations is located

at multiple BSs.

III. FEDERATED ECHO STATE LEARNING FOR PREDICTIONS OF THE USERS’ LOCATION

AND ORIENTATION

Federated learning is a decentralized learning algorithm [32] that can operate by using training

datasets that are distributed across multiple devices (e.g., BSs). For our system, one key advantage

of federated learning is that it can allow multiple BSs to locally train their local learning model

11

using their collected data and cooperatively build a learning model by sharing their locally

trained models. Compared to existing federated learning algorithms [33] that use matrices to

record the users’ behavior and cannot analyze the correlation of the users’ behavior data, we

propose an ESN-based federated learning algorithm that can use an ESN to efﬁciently analyze

the data related to the users’ location and orientation. The proposed algorithm enables the BSs to

collaboratively generate a global ESN model to predict the whole set of locations and orientations

for each user without transmitting the collected data to other BSs. However, if the BSs use

the centralized learning algorithms for the orientation and location predictions, the BSs must

use the data collected from all BSs to train the algorithm. ESNs have two unique advantages:

simple training process and the ability to analyze time-dependent data [22]. Since the data

that is related to the orientation and locations of the users is time-dependent and the users’

orientation and locations will change frequently, we must use ESNs that can efﬁciently analyze

time-dependent data and converge quickly to obtain the prediction results on time and determine

the user association. Next, we ﬁrst introduce the components of the federated ESN learning

model. Then, we explain the entire procedure of using our federated ESN learning algorithm to

predict the users’ locations and orientation.

A. Components of Federated ESN Learning Algorithm

A federated ESN learning algorithm consists of ﬁve components: a) agents, b) input, c) output,

and d) local ESN model, which are speciﬁed as follows:

• Agent: In our system, we need to deﬁne an individual federated ESN learning algorithm

to predict the location and orientation of each VR user. Meanwhile, each user’s individual

federated ESN learning algorithm must be implemented by all BSs that have been associated

with this user. Each BS j must implement U learning algorithms to predict the locations

and orientations of all users.

• Input: The input of the federated ESN learning algorithm that is implemented by BS j for the
predictions of each VR user i is deﬁned by a vector υij = [υij,1, · · · , υij,T ]T that represents

the information related to user i’s location and orientation where υij,t = [ξij1,t, . . . , ξijNx,t]

represents user i’s information related to location and orientation at time t. This information

includes user i’s locations, orientations, and VR applications. Nx is the number of properties

that constitute a vector υij,t. The input of the proposed algorithm will be combined with

12

Fig. 3. Architectures of deep ESN models.

(a) a series ESN model

(b) a parallel ESN model

the ESN model to predict users’ orientation and locations. BSs will use these predictions

to determine user associations.

• Output: For each user i, the output of the federated ESN learning algorithm at BS j is
(cid:3) of user i’s locations and orientations where ˆyijt+k =
a vector yij,t = (cid:2)ˆyijt+1, . . . , ˆyijt+Y
[ˆxit+k, ˆyit+k, ˆχit+k] with ˆxit+k and ˆyit+k being the predicted location coordinates of user i

at time t + k and ˆχit+k being the estimated orientation of user i at t + k. Y is the number

of future time slots that a federated ESN learning algorithm can predict. The predictions of

the locations and orientations can be used to determine the user’s association.

• Local ESN model: For each BS j, a local ESN model is used to build the relationship

between the input of all BSs and the predictions of the users’ location and orientation, as
j ∈ RNW ×T ,
shown in Fig. 4. The local ESN model consists of the input weight matrix W in
j ∈ RY ×(NW +T ). The
recurrent matrix W j ∈ RNW ×NW , and the output weight matrix W out
j and W j are generated randomly. However, the output weight matrix W out
values of W in
j

need to be trained according to the inputs of all BSs.

We introduce three ESN models: single ESN model, series ESN model, and parallel ESN

model. In the single ESN model, an ESN is directly connected to the input and output.

Moreover, as shown in Fig. 3, series and parallel ESN models connect single ESN models

in series and parallel, respectively. Each ESN model has its own advantage for our problem.

In particular, a single ESN model can converge faster than a series ESN model and a parallel

ESN model. A parallel ESN model has a larger memory capacity than a series ESN model.

Input of ESNSeries ESN ModelOutput of ESNInput of ESNParallel ESN ModelOutput of ESN13

Fig. 4. The implementation of the ESN based federated learning. Here, the data is located at the BSs and the learning model

W out
j

that is trained by each BS’s collected data is the local model.

A series ESN model can decrease the prediction errors in the training process.

B. ESN Based Federated Learning Algorithm for Users’ Location and Orientation Predictions

Next, we explain the entire procedure of training the proposed ESN-based federated learning

algorithm. Our purpose of training ESN is to ﬁnd an optimal output weight matrix in order to

accurately predict the users’ locations and orientations, as shown in Fig. 4.

To introduce the training process, we ﬁrst explain the state of the neurons in ESN. The neuron

states of the proposed algorithm implemented by BS j for the predictions of user i are:

Based on the states of neurons and the inputs, the ESN can estimate the output, which is:

µj,t = W jµj,t−1 + W in

j υij,t.

ˆyij,t = W out
j,t





υij,t

µj,t



 .

(10)

(11)

From (11), we can see that, in order to enable an ESN to predict the users’ locations and

orientations, we only need to adjust the value of the output weight matrix. However, each BS

can collect only partial data for each user and, hence, we need to use a distributed learning

algorithm to train the ESNs. To introduce the distributed learning algorithm, we ﬁrst deﬁne two

matrices which are given by:


H j =













υij,1 µj,1
...
υij,T µj,T

and Ej = [eij,1, . . . , eij,T ] ,

(12)

Implement ESN to train W4outImplement ESN to train W3outImplement ESN to train W2outImplement ESN to train W1outCollected dataAfter training,  =W2out=W3out=W4out14

where eij,t is the desired locations and orientations of each VR user, given the ESN input υij,t.

Then, the training purpose can be given as follows:

min
W out

1
2

(cid:32) B
(cid:88)

j=1

(cid:13)
(cid:13)W outH T

j − Ej

(cid:13)
2
(cid:13)

(cid:33)

+

λ
2

(cid:107)W out(cid:107).

(13)

(13) is used to ﬁnd the optimal global output weight matrix W out according to which the BSs

can predict the entire users’ locations and orientations without the knowledge of the users’ data

collected by other BSs. From (13), we can see that, each BS j needs to adjust its output weight
and ﬁnd the optimal output weight matrix W out. After the learning step, we have
matrix W out
j
j = W out, which means that when the learning algorithm converges, the local model of each
W out
for the augmented

BS will converge to the global model.. A standard update policy of W out
j

Lagrangian problem in (13) is given by [34]:

W out

j,t+1 = ς −1 (cid:2)I − H T

j

(cid:0)ςI + H jH T

j

(cid:1) H T

j

(cid:3) (cid:0)H T

j Ej − nj,t + ςW out
t

(cid:1) ,

(14)

where ς is the learning rate and W out
of each BS needs to ﬁnd. From (14), we can see that W out
generated at BS j. W out
the users’ data collected by BS j. W out

j,t+1 is the output weight matrix that is
j,t+1 can only be used to predict partial locations and orientations given
j,t+1 is different from the output weight matrices of other

is the optimal output weight matrix that the ESN model

t

BSs. The optimal output weight matrix is given by:

W out

t+1 =

Bς ˆW

out
t+1 + B ˆnt

λ + ςB

,

where ˆW

out

t+1 and ˆnout

t+1 can be calculated as follows:

ˆW

out
t+1 =

1
B

B
(cid:88)

j=1

W out

j,t+1, ˆnt =

1
B

B
(cid:88)

j=1

nj,t.

(15)

(16)

From (14) to (16), we can see that the global output weight matrix W out is based on (15) and
(16) while the local output weight matrix W out
j
between the output weight matrix W out
W out

t+1 that the ESN model of each BS needs to converge, which is given by:

j,t+1 of each BS j and the optimal output weight matrix

In (14), nj,t is the deviation

is based on (14).

nj,t+1 = nj,t + γ (cid:0)W out

j,t+1 − W out
t+1

(cid:1) .

(17)

W out

t+1 is the global optimal output weight matrix that can be used to predict the entire locations
t+1, each BS can predict the entire

and orientations of a given user. This means that using W out

Algorithm 1 Federated ESN learning algorithm for location and orientation predictions
Input: Training data set (local), υij.

Initialization: Each BS j generates the ESN model for each user including W in

j (local), W j (global), and W out
j

(local).

15

1: Obtain the matrices H j and Ej based on (10).

2: for time t do

3:

4:

5:

6:

7:

8:

Compute W out
j,t+1 using (14).
out
Calculate ˆW
t+1 and ˆnout

t based on (16).

Calculate W out

t+1 based on (15).

Compute nj,t+1 based on (17).

Compute (cid:107)rj,t+1(cid:107) and (cid:107)sj,t(cid:107).

If (cid:107)rj,t+1(cid:107) (cid:54) γA or (cid:107)sj,t(cid:107) (cid:54) γA, the algorithm converges.

9: end for

user’s locations and orientations as the BS only collects partial data related to the user’s locations
and orientations. As time elapses, W out

t+1. In consequence, all of
BSs can predict the entire locations and orientations of each user. To measure the convergence,
we deﬁne two vectors which can be given by rj,t = W out
t−1. As
(cid:107)rj,t+1(cid:107) (cid:54) γA or (cid:107)sj,t(cid:107) (cid:54) γA, the proposed algorithm converges. γA is determined by the BSs.

j,t+1 will ﬁnally converge to W out

and sj,t = W out

j,t − W out
t

t − W out

Since the minimization function in (13) is a convex function, the BSs are guaranteed to ﬁnd an
optimal output weight matrix that satisfy (cid:107)rj,t+1(cid:107) (cid:54) γA or (cid:107)sj,t(cid:107) (cid:54) γA. As γA increases, the

accuracy of the predictions and the number of iterations decrease. Therefore, BSs need to jointly

account for the time used for training ESN and the prediction accuracy to determine the value

of γA. In fact, the ESN As the learning algorithm converges, each BS can use its own ESN to

predict the entire location and orientation of each VR user. According to these predictions, BSs

can determine the user association to minimize the BIP of VR users. Algorithm 1 summarizes

the entire process of using ESN based federated learning algorithm for the predictions of the
users’ locations and orientations. From Algorithm 1, we can see that W in
parameters which means that each BS j will generate its own W in

j and W out
j
a global parameter which means that all of the BSs will have the same W j.

. However, W j is

j and W out
j

are local

IV. MEMORY CAPACITY ANALYSIS

To improve the prediction accuracy of the proposed algorithm, we analyze the memory capacity

of the proposed ESN model. The memory capacity quantiﬁes the ability of each ESN to record

16

the historical locations and orientations of each VR user. As the memory capacity of the ESNs

increases, the ESNs can record more historical data related to users’ locations and use this

information to achieve better prediction1 for the users’ locations and orientations. The analysis

of the ESN memory capacity will be used for the choice of the ESN models for the predictions

of the users’ locations and orientations. Next, we derive closed-form expressions of the memory

capacity of the three ESN models that we described in Section III, namely, the single ESN model,

the parallel ESN model, and the series ESN model. Note that, our previous work [35] analyzed

the memory capacity for a centralized parallel ESN model. In contrast, here, we analyze the

memory capacity for three ESN models used for federated learning.

We assume that the input of each ESN model at time t is mt and the output of each ESN

model is zt. Then, the memory capacity of each ESN model is given by [36]:

M =

∞
(cid:88)

k=1

Cov2(mt−k, zt)
Var(mt)Var(zt)

,

(18)

where Cov and Var represent the covariance and variance operators, respectively. In (18), Cov2(mt−k,zt)
Var(mt−k)Var(zt)

captures the correlation between the ESN input mt−k at time t−k and the ESN output zt at time t.
Cov2(mt−k,zt)
Var(mt−k)Var(zt) = 1 indicates that mt−k and zt are related which means that the output zt includes
the information of mt−k and, hence, the ESN can record input mt−k at time t. Cov2(mt−k,zt)
Var(mt)Var(zt) = 0
indicates that mt−k and zt are unrelated, which means that zt does not include any information

related to mt−k and, hence, the ESN cannot record mt−k. In consequence, M represents the total

number of historical input data that each ESN can record. The recurrent matrix W in each ESN

model is given by:

W l =










0

0

· · · w

w 0
. . .

0

0

0

0

0

0

0

w 0










,

(19)

and the input weight matrix is given by W in = (cid:2)win

1 , . . . , win
NW

(cid:3)T

. We also deﬁne a matrix that

1Here, as the size of the recorded data increases, the ESNs can use more historical data to build a relationship between

historical orientations and locations, and future orientations and locations. Hence, the ESN prediction accuracy improves.

will be used to derive the memory capacity of the ESNs, which can be given by:

V =










win
1
win
2
...
win

NW

win

NW
win
1
...

win

NW −1










.

· · · win
2
· · · win
3
...
· · · win
1

· · ·

17

(20)

Based on the above deﬁnitions, we can invoke our result from [36, Theorem 2] to derive the

memory capacity of single ESN model, which can be given as follows.

Corollary 1 (Single ESN model). Given the recurrent matrix W and the input matrix W in that

guarantees the matrix V regular, the memory capacity of the single ESN model is:

M = NW − 1 + w2NW .

(21)

(cid:104)

µt (µt)T(cid:105)

Proof. Given the input stream vector m...t = [m1, . . . , mt−1, mt], we can calculate the activa-
tions µj,t using (10). The output weight matrix of the ESN model can be given by W out =
R−1pk, where R = E
represents the covariance matrix with µt = [µ1,t, . . . , µNW ,t]
(cid:1) is
and pk = E [µtmt−k]. Assume that win
NW −1, . . . , win
NW ...1 by k positions to the right. We have W out = (1 −
an operator that rotates vector win
), where A = V TΓ 2V with Γ = diag (cid:0)1, w, . . . , wNW −1(cid:1). Based
w2NW )wkA−1rotk(win
on W out, we can the covariance of the output with the k-slot delayed input, which is given
by Cov(zt, mt−k) = (1 − w2NW )w2kσ2ζk. We can also obtain Var(zt) = E [ztzt] = (1 −
w2NW )w2kσ2ζk. Since Var(mt) = σ2, we have M = (cid:80)∞
Cov2(mt−k,zt)
Var(mt)Var(zt) = NW − 1 + w2NW .

NW ...1 = (cid:2)win

(cid:3) and rotk

(cid:0)win

, win

NW ...1

1...NW

k=1

NW

1

From Corollary 1, we can see that the memory capacity of the single ESN model depends

on the number of neurons and values of the recurrent matrix. Corollary 1 also shows that the

memory capacity of the single ESN model will not exceed NW . That means the single ESN

model based federated learning algorithm can only record NW locations or orientations.

Next, we derive the memory capacity of the parallel ESN model, which can be given by the

following theorem.

Theorem 1 (Parallel ESN). Given a parallel ESN model during which L ESN models are
parallel connected with each other, each ESN model’s input weight matrix W in that guarantees

the matrix V regular and recurrent matrix W , then the memory capacity of each parallel ESN

18

can be given by:

Proof. See Appendix A.

M = NW − 1 + w2NW .

(22)

Theorem 1 shows that the memory capacity of a parallel ESN model is similar to the memory

capacity of a single ESN. Hence, adding multiple ESN models will not increase the memory

capacity. This is due to the fact that, in a parallel ESN model, there is no connection among

the ESNs, as shown in Fig. 3(b). Therefore, the input of the parallel ESN model will separately

connect to each single ESN and, hence, the parallel ESN models do not need to use more

neurons to record the input data compared to the single ESN model. Theorem 1 also shows that

the memory capacity of a parallel ESN depends on the number of neurons in each ESN model

and the values of the recurrent weight matrix of each ESN model. Accordingly, we can increase

the value of output weight matrix and the number of neurons in each ESN model to increase

the memory capacity of the parallel ESN models. As the memory capacity of the parallel ESN

models increases, BSs can record more users’ data to predict the users’ locations and orientations

accurately. Next, we derive the memory capacity of the series ESN model.

Theorem 2 (Series ESN model). Given a series ESN model during which L ESN models are

series connected with each other, a recurrent matrix W of each ESN model, and each ESN
model’s input weight matrix W in that guarantees the matrix V regular, the memory capacity of

each series ESN model is:

Proof. See Appendix B.

M = (cid:0)1 − w2NW (cid:1)L−1 (cid:0)NW − 1 + w2NW (cid:1) .

(23)

From Theorem 2, we can see that the memory capacity of each series ESN model is smaller

than the memory capacity of a single ESN or a series ESN. Theorem 2 also shows that the

memory capacity of each series ESN model decreases as the number of ESN models L increases.

Thus, it would be better to use a single ESN model or a parallel ESN model to predict the users’

locations and orientations.

19

Theorems 1 and 2 derive the memory capacities of the parallel ESN model and the series

ESN model with single input. Next, we formulate the memory capacity of a single ESN model

given multiple inputs, which is given by the following theorem.

Theorem 3 (Multi-input single ESN). Consider a single ESN with a recurrent matrix W , input
vector mt = [m1t, . . . , mKt], the input weight matrix W in that guarantees the matrix V regular,

the memory capacity of each single ESN is

(cid:32)

M =

(cid:80)K

k=1

(cid:80)K

(cid:80)K

l=1 σ2
l
n=1 ρknσkσn

(cid:33)2

(cid:0)NW − 1 + w2NW (cid:1) ,

(24)

where ρkn represents the correlation coefﬁcient between input mkt and mnt.

Proof. See Appendix C.

From Theorem 3, we can observe that the correlation among input elements in vector mt will

affect the memory capacity of each ESN model. In particular, as the correlation of the input data

increases, the memory capacity of the ESN model increases. This is because the ESN can use

more input data to predict the users’ locations and orientations, hence improving the predictions

accuracy. Therefore, it would be better to jointly predict the users’ locations and orientations.

Theorems 1-3 allow each BS to determine its ESN model, the number of neurons NW in

each ESN model, and the values of the recurrent matrix W as the size of the data collected by

each BS changes. A parallel ESN model has a larger memory capacity compared with the series

ESN model and is more stable than the single ESN model, and, hence, a parallel ESN model

can record more historical data to predict the users’ orientations and locations so as to improve

the prediction accuracy. As the prediction accuracy is improved, the BSs can determine the user

association more accurately. Hence, the BIP of the users can be minimized. Therefore, we use

the parallel ESN model in our proposed algorithm.

V. USER ASSOCIATION FOR VR USERS

Based on the analysis presented in Sections III and IV, each BS can predict the users’ locations

and orientations. Next, we explain how to use these predictions to ﬁnd the user association for

each VR user. Given the predictions of the locations and orientations, the BIP minimization

problem in (9) can be rewritten as follows:

min
aUL
i,t,aDL
i,t

(cid:88)

i∈U

Pi

(cid:0)ˆxit, ˆyit, GA, ˆχit, aUL

i,t , aDL
i,t

(cid:1) .

20

(25)

We use the reinforcement learning algorithm given in [37] to ﬁnd a sub-optimal solution of the

problem in (25). In the reinforcement learning algorithm given in [37], the actions are the user

association schemes, the states are the strategies of other BSs, and the output is the estimated BIP.

Hence, this reinforcement learning algorithm can learn the VR users state and exploit different

actions to adapt the user association according to the predictions of the users’ locations and

orientations. After the learning step, each BS will ﬁnd a sub-optimal user association to service

the VR users. To simplify the learning process and improve the convergence speed, we ﬁrst select

the uplink user association scheme. This is because as the uplink user association is determined,

the BSs that the users can associate in downlink will be determined, as follows:

Proposition 1. Given the predicted location and orientation of user i at time t as well as the

uplink user association aUL

i∗,t, the downlink cell association for a VR user i is:

ik,t = 1(cid:40) D(li,t(aDL
aDL

ik (ˆxit,ˆyit,bi( ˆχit),nik)))
cDL

ik,t
cDL
ik (ˆxit,ˆyit,bi( ˆχit),nik)

aDL
ik,t

(cid:41)∧1

(cid:54)γD−

A
cUL
i∗ (ˆxit,ˆyit)

aUL
i∗,t

{li,t(aDL

ik,tcDL

ik (ˆxit,ˆyit,bi( ˆχit),nik))mi,t(GA)(cid:62)γQ},

(26)

where aDL

ik,t is the downlink user association obtained in (26). cUL

i∗ (xit, yit) is the uplink data rate

of user i.

Proof. For downlink user association, each VR user i needs to ﬁnd a BS that can guarantee

the transmission delay and VR video quality. Since we have determined the user associa-

A
i∗,tcUL
aUL
delay requirement of user i, i.e.,

tion over uplink, the maximum time used for VR video transmission can be given by γD −
i∗ (ˆxit,ˆyit) . Consequently, user i needs to connect with a BS that can satisfy the transmission
i∗ (ˆxit,ˆyit) . Moreover,
user i needs to associate with a BS that can meet the requirement of VR video quality, i.e.,
ik (ˆxit, ˆyit, bi ( ˆχit) , nik)(cid:1) mi,t (GA) (cid:62) γQ. Thus, if BS k can satisfy the conditions:
ik (ˆxit,ˆyit,bi( ˆχit),nik)))
mi,t (GA) (cid:62)

D(li,t(aDL
ik,tcDL
aDL

ik (ˆxit,ˆyit,bi( ˆχit),nik)))

ik,tcDL
ik,tcDL

ik (ˆxit,ˆyit,bi( ˆχit),nik)

A
i∗,tcUL
aUL

ik (ˆxit, ˆyit, bi ( ˆχit) , nik)

(cid:54) γD −

(cid:54) γD −

ik,tcDL
aDL

ik,tcDL

i∗ (ˆxit,ˆyit) and li,t
γQ, user i can associate with it. This completes the proof.

ik (ˆxit,ˆyit,bi( ˆχit),nik)

(cid:0)aDL
li,t
D(li,t(aDL
ik,tcDL
aDL

A
i∗,tcUL
aUL

(cid:16)

(cid:17)

From Proposition 1, we can see that the user association of each user i depends on user i’s

location and orientation. Proposition 1 shows that, for each user i, the uplink user association will

21

TABLE I

SYSTEM PARAMETERS

Parameter
PB
PU
σ
F UL
F DL
NW
β
M
m
φ

Parameter
d0
fc
c

Value
30 dBm
10 dBm
-94 dBm
10 Mbit (cid:36)LoS, (cid:36)NLoS
µσLoS , µσNLoS
10 Mbit
GA
30
γD
2
γQ
15 dB
2
σi
0.7 dB
30◦
A

Value
5 m
28 GHz
3 × 108 m/s
2, 2.4
5.3, 5.27
11
10 ms
0.8
0.193
50 kbits

Parameter Value

Y
T
γ
λ
w
L
V
ϑ
σ2
GA|i
2
σB

10
5
0.5
0.005
0.98
3
10
2
0.151
0.05

affect the downlink user association. This is due to the fact that the VR system has determined the

total transmission delay of each user. As a result, when the uplink user association is determined,

the uplink transmission delay and the requirement of the downlink transmission delay will be

determined.

VI. SIMULATION RESULTS AND ANALYSIS

For our simulations, we consider a circular area with radius r = 500 m, U = 20 wireless

VR users, and B = 5 BSs distributed uniformly. To simulate blockage, each user is considered

as a two-dimensional point. For simplicity, we ignore the altitudes of the BSs and the height

of the users. If blockage points are located between a user and its BS, the communication link

will be considered to be NLoS. Real data traces for locations are collected from 50 students

at the Beijing University of Posts and Telecommunications. The locations of each student is

collected every hour during 9:00 am – 9:00 pm. For orientation data collection, we searched 25

videos related to a ﬁrst-person shooter game from youTube. Then, we input these VR videos

to HTC Vive devices. The HTC Vive deveploper system can directly measure the movement of

the VR videos using HTC Vive devices. We arbitrarily combine one user’s locations with one

orientation for each VR user. In simulations, a parallel ESN model2 is used for the proposed

algorithm due to its stability and large memory capacity. The other system parameters are listed

in Table I. For comparison purposes, we consider the deep learning algorithm in [15] and the

ESN algorithm in [16], as two baseline schemes. The deep learning algorithm in [15] is a deep

autoencoder that consists of multiple layers of restricted Boltznann machines. The centralized

2The code can be found in https://github.com/lasisal/deepESN.

22

(a)

(b)

(c)

Fig. 5. Predictions of the VR users’ orientations and locations as time elapses.

(a)

(b)

(c)

Fig. 6. Predictions of the VR users’ orientations and locations as time elapses.

ESN-based learning algorithm in [16] is essentially a single layer ESN algorithm. The input

and output of the centralized ESN and deep learning algorithms are similar to the proposed

algorithm. However, for the deep learning algorithm and the centralized ESN algorithm, each

BS can use only its collected data to train the learning model. Both the centralized and deep

learning algorithms are trained in an ofﬂine manner. All statistical results are averaged over a

large number of independent runs.

Figs. 5 and 6 show the predictions of the VR users’ locations and orientations as time elapses.

To simplify the model training, the collected data related to locations and orientations are mapped

to [−0.5, 0.5]. The orientation and location of each user are, respectively, mapped by the function
(cid:19)

χit
360◦ − 0.5 and
proposed algorithm can predict the users’ locations and orientations more accurately than the

× ˆyit. From Figs. 5 and 6, we observe that the

− 0.5 where z =

(cid:18)ˆxit+ˆyit(cid:80)

z
zmax

n=1

n

centralized ESN and deep learning algorithms. Figs. 6(b) and 6(c) also show that the prediction

error mainly occurs at time slot 8 to 12. This is due to the fact that the proposed algorithm can

build a learning model that predicts the entire locations and orientations of each user. In particular,

101214161820Time (hour)-0.4-0.200.20.40.6The locations of a given userReal locationsLocations predicted by the proposed algorithm101214161820Time (hour)-0.4-0.200.20.40.6The locations of a given userReal locationsLocations predicted by the centralized ESN101214161820Time (hour)-0.4-0.200.20.40.6The locations of a given userReal locationsLocations predicted by the deep learning24681012Time slot-0.500.5The orientations of a given userReal orientationsOrientations predicted by the proposed algorithm24681012Time slot-0.500.5The orientations of a given userReal orientationsOrientations predicted by the centralized ESN24681012Time slot-0.500.5The orientations of a given userReal orientationsOrientations predicted by the deep learning23

Fig. 7. Total BIP experienced by VR users as the number of BSs varies.

(a)

(b)

the output weight matrices of all ESN algorithms implemented by each BS will converge to a

common matrix. Hence, BSs can predict the entire locations and orientations of each VR user.

Fig. 7 shows how the total BIP of all VR users changes as the number of BSs varies. From

Fig. 7, we can see that, as the number of BSs increases, the total BIP of all VR users decreases.

That is because as the number of BSs increases, the VR users have more connection options.

Hence, the blockage caused by human bodies will be less severe, thereby improving the data

rates of VR users. Fig. 7(a) also shows that the proposed algorithm can achieve up to 16%

and 26% reduction in the number of BIP, respectively, compared to centralized ESN algorithm

and deep learning algorithm for a network with 9 BSs. These gains stem from the fact that the

centralized ESN and deep learning algorithms can partially predict the locations and orientation

of each VR user as they rely only on the local data collected by a BS. In contrast, the proposed

algorithm facilitates cooperation among BSs to build a learning model that can predict the entire

users’ locations and orientations. Fig. 7(b) shows that the proposed algorithm using a parallel

ESN model can achieve up to 8% and 14% gains in terms of the total BIP of all users compared

to the proposed algorithm with a single ESN model and with a series model. Clearly, compared

to a single ESN, using a parallel ESN model can increase the stability of the proposed algorithm.

Meanwhile, the memory capacity of a parallel model is larger than a series ESN model thus

improving the prediction accuracy and reducing BIP for users.

In Fig. 8, we show how the total BIP of all VR users changes with the number of VR users.

This ﬁgure shows that, with more VR users, the total BIP of all VR users increases rapidly due

123456789Number of BSs250300350400Total BIPs of all VR usersFederated ESN learning algorithmCentralized ESN algorithmDeep learning algorithm13579Number of BSs260280300320340360380400420Total BIPs of all VR usersThe proposed algorithm using a parallel ESN modelThe proposed algorithm using a single ESN modelThe proposed algorithm using a series ESN model24

Fig. 8. Total BIP of all VR users as the number of VR users varies.

Fig. 9. CDFs of the BIP resulting from the different algorithms.

to an increase in the uplink delay, as the sub-6 GHz bandwidth is shared by more users. Fig.

8 also shows that the gap between the proposed algorithm and the centralized ESN algorithm

decreases as more VR users are present in the network.. Clearly, with more VR users, it becomes

more probable that a user located between a given VR user and its associated BS blocks the

mmWave link. Thus, as the number of users increases, more VR users will receive their VR

videos over NLoS links and, the total BIP signiﬁcantly increases.

In Fig. 9, we show the CDF for the VR users’ BIP for all three algorithms. Fig. 9 shows that

the BIP of almost 98% of users resulting from the considered algorithms will be larger than 10.

1020304050Number of VR users300350400450Total BIPs of all VR usersFederated ESN learning algorithmCentralized ESN algorithmDeep learning algorithm1 5 101520253040Number of BIPs 00.20.40.60.81CDFFederated ESN learningCentralized ESN algorithmDeep learning algorithm25

Fig. 10. Normalized root mean square error of the predictions as the number of neurons varies.

This is due to the fact that the BIP will also be caused by other factors such as VR applications

and user’s awareness. In Fig. 9, we can also see that the proposed algorithm improves the CDF

of up to 38% and 71% gains at a BIP of 25 compared to the centralized ESN and deep learning

algorithms, respectively. These gains stem from the fact the ESNs are effective at analyzing

the time related location and orientation data and, hence, they can accurately predict the users’

locations and orientations.

Fig. 10 shows how the normalized root mean square error (NRMSE) of the predictions changes

as the number of neurons in each ESN model varies. In this ﬁgure, the NRMSE of the predictions
is given by (cid:13)

(cid:13)
(cid:13). From Fig. 10, we can see that, with more neurons, the NRMSE of

(cid:13)ˆyij,t − eij,t

the predictions resulting from all of the considered ESN models decreases. This is because, as

the number of neurons increases, each ESN model can record more historical data related to the

users’ locations and orientations. Fig. 10 also shows that the parallel model can achieve up to

37.5% and 90% gains in terms of NRMSE compared to the series model for the ESN models

have 30 neurons. This is due to the fact that the prediction errors of a parallel ESN model is

averaged over multiple outputs, thus, improving the prediction accuracy.

Fig. 11 shows how the total BIP of all VR users changes as the number of BSs varies. In

this ﬁgure, all of the considered algorithms used the reinforcement learning algorithm given in

[31] to solve the problem in (25). In the algorithm without the knowledge of the locations and

orientations, the users are randomly associated with the BSs. From Fig. 11, we can see that the

1015202530Number of neurons0.050.10.150.20.250.30.350.40.45NRMSE of the predictionsParallel ESN modelSeries ESN model Single ESN model26

Fig. 11. Total BIP of all VR users as the number of BSs varies.

proposed algorithm yields 23% fewer BIP compared to the algorithm without the knowledge of

the locations and orientations. This is due to the fact that the proposed algorithm uses federated

ESN algorithm to predict the users’ orientations and locations to optimize the user association

and reduce the BIP of the users. From Fig. 11, we can also see that, a gap exists between the

proposed algorithm and the algorithm with the perfect knowledge of the users’ orientations and

locations. This gap stems from the prediction inaccuracy caused by the proposed algorithm.

VII. CONCLUSION

In this paper, we have developed a novel framework for minimizing BIP within VR applications

that operate over wireless networks. To this end, we have developed a BIP model that jointly

considers the VR applications, transmission delay, VR video quality, and the user’s awareness.

We have then formulated an optimization problem that seeks to minimize the BIP of VR users

by predicting users’ locations and orientations, as well as determining the user association. To

solve this problem, we have developed a novel federated learning algorithm based on echo state

networks. The proposed federated ESN algorithm enables the BSs to train their ESN with their

locally collected data and share these models to build a global learning model that can predict

the entire locations and orientations of each VR user. To improve the prediction accuracy of

the proposed algorithm, we derive a closed-form expression of the memory capacity for ESNs

to determine the number of neurons in each ESN model and the values of the recurrent weight

3456789Number of BSs200250300350400450500Total BIPs of all VR usersFederated ESN learning algorithmPerfect knowledge of locations and orientationsWithout knowledge of locations and orientations27

matrix. Using these predictions, each BS can determine the user association in both uplink and

downlink. Simulation results have shown that, when compared to the centralized ESN and deep

learning algorithms, the proposed approach achieves signiﬁcant performance gains of BIP.

A. Proof of Theorem 1

APPENDIX

Given the input stream vector m...t = [m1, . . . , mt−1, mt], the activations µj,t in (10) of the

reservoir neuron in ESN model l at time t can be given by:

µ(l)
j1,t = win

1,lmt + wwin

NW ,lmt−1 + w2win

NW −1,lmt−2 + · · · + wNW −1win

2,lmt−(NW −1)

+ wNW win

1,lmt−NW + wNW +1win

NW ,lmt−(NW +1) + · · · + w2NW −1win

2,lmt−(2NW −1) + w2NW win

1,lmt−2NW

+ w2NW +1win

NW ,lmt−(2NW +1) + · · · ,

...

(27)

µ(l)
jNW ,t = win

NW ,lmt + wwin

NW −1,lmt−1 + w2win

NW −2,lmt−2 + · · · + wNW −1win

1,lmt−(NW −1)

+ wNW win

NW ,lmt−NW + wNW +1win

NW −1,lmt−(NW +1) + · · · + w2NW win

NW ,lmt−2NW

+ w2NW +1win

NW −1,lmt−(2NW +1) + · · · ,

where w is an element of the recurrent matrix W which is assumed to be equal for all of the

ESN models. The output weight matrix of each ESN model l can be given by

where Rl = E
(cid:104)
µ(l)

and pk,l = E

(cid:20)

µ(l)
t

(cid:16)
µ(l)
t
(cid:105)

W out

l = Rl

−1pk,l,

(cid:17)T(cid:21)

represents the covariance matrix with µ(l)

t =

(cid:104)

1,t , . . . , µ(l)
µ(1)

NW ,t

(cid:105)

t mt−k

. The element Rl,12 in Rl can be calculated as follows

Rl,12 =E

(cid:104)
2,tµ(l)
µ(l)

1,t

(cid:105)

= E[win

1,lwin

2,lm2

t + w2win

NW ,lwin

1,lm2

t−1 + · · · + w2(NW −1)win

2,lwin

3,lm2

t−(NW −1)

+ w2NW win

1,lwin

2,lm2

t−NW

+ · · · + w2(2NW −1)win

2,lwin

3,lm2

t−(2NW −1) + w4NW win

1,lwin

2,lm2

t−2NW

+ · · · ]

=σ2(win

1,lwin

2,l + w2win

NW ,lwin

1,l + · · · + w2(NW −1)win

2,lwin

3,l + w2NW win

1,lwin

2,l + w2(NW +1)win

NW ,lwin

1,l + · · ·

+ w2(2NW −1)win

2,lwin

3,l + w4NW win

1,lwin

2,l + · · · )

∞
(cid:88)

w2NW j (cid:16)

=σ2

win

1,lwin

2,l + w2win

NW ,lwin

1,l + · · · + w2(NW −1)win

2,lwin
3,l

j=0
σ2
1 − w2NW

=

(cid:0)rot1

(cid:0)win

NW ...1,l

(cid:1)(cid:1)T

Γ 2rot2(win

NW ...1,l),

(cid:17)

(28)

where σ2 is the variance of the input signal mt. win

NW ...1,l = (cid:2)win

NW ,l, win

NW −1,l, . . . , win

1,l

28

(cid:3) and

rotk

(cid:0)win

NW ...1,l
example, rot1

(cid:1) denote an operator that rotates vector win
(cid:0)win

NW ...1,l by k place to the right. For
(cid:3). Γ = diag (cid:0)1, w, . . . , wNW −1(cid:1). The element

(cid:1) = (cid:2)win

1,l, win

NW ,l, . . . , win

NW ...1,l

2,l

Rl,ij can be given by:

Rl,ij =

σ2

Thus, Rl =

1−w2NW V T
element pk1,l is given by:

σ2
1 − w2NW
σ2

(roti(win

NW ...1,l))TΓ 2rotj(win

NW ...1,l).

(29)

l Γ 2V l =

1−w2NW Al where Al = V T

l Γ 2V l. Similarly, based on (28),

pk1,l =E

(cid:104)

µ(l)
1,tmt−k

(cid:105)

= σ2wkwin

(NW −k+1)mod NW ,l.

We assume that win
matrix of each ESN model l is W out

0,l = win

NW ,l. Hence, pk,l = σ2wkrotk

l = (1 − w2NW )wkA−1

(cid:0)win
1...NW ,l
l rotk(win

1...NW ,l).

(30)
(cid:1) . Then, the output weight

The output of each ESN model l at time t can be given by zl,t = (µ(l)
1...NW ,l) and zt = (cid:80)L

l = (1 −
l=1 zl,t. Then, the covariance of the output with

t )TW out

t )TA−1

w2NW )wk(µ(l)

l rotk(win
the k-slot delayed input can be calculated by:

Cov(zt, mt−k) =

L
(cid:88)

l=1

(1 − w2NW )wkCov

(cid:18)(cid:16)

(cid:17)T

µ(l)
t

, mt−k

(cid:19)

A−1

l rotk(win

1...NW ,l)

=L(1 − w2NW )w2kσ2 (cid:0)rotk(win

1...NW ,l)(cid:1)T A−1

l rotk(win

1...NW ,l)

(31)

(a)
=L(1 − w2NW )w2kσ2ζk,

where (a) is obtained from the fact that ζk = (cid:0)rotk(win
of the output can be given by:

1...NW ,l)(cid:1)T A−1

l rotk(win

1...NW ,l). The variance

Var(zt) =E

(cid:34) L
(cid:88)

L
(cid:88)

zl,t

l=1

p=1

(cid:35)

(cid:32)

zp,t

−

(cid:34) L
(cid:88)

E

l=1

(cid:35)(cid:33)2

zl,t

=

L
(cid:88)

L
(cid:88)

l=1

p=1

E [zl,tzp,t] .

(32)

Since E [zp,tzl,t] = (1 − w2NW )w2kσ2ζk, we have Var(zt) = L2(1 − w2NW )w2kσ2ζk.

The memory capacity of the parallel ESN model can be given by

M =

∞
(cid:88)

k=1

Cov2(mt−k, zt)
Var(mt)V ar(zt)

=

1
L

∞
(cid:88)

k=0

Cov(mt−k, zt)
σ2

−

Cov(mt, zt)
Lσ2

29

L
(cid:88)

l=1

L
(cid:88)

l=1

L
(cid:88)

l=1

=

=

=

=

=

=

1
L

1
L

1
L

1
L

1
L

1
L

∞
(cid:88)

L
(cid:88)

k=0

l=1

(1 − w2NW )w2kζk −

(1 − w2NW )

∞
(cid:88)

w2kζk −

1
L

1
L

L
(cid:88)

(1 − w2NW )ζ0

l=1

L
(cid:88)

l=1

(1 − w2NW )ζ0

k=0
(cid:34)NW −1
(cid:88)

(1 − w2NW )

(1 − w2NW )

k=0
(cid:32)NW −1
(cid:88)

k=0

(cid:33) (cid:32) ∞
(cid:88)

(cid:33)

w2NW k

−

w2kζk

1
L

L
(cid:88)

l=1

(1 − w2NW )ζ0

k=0
(cid:33)

(a)
=

1
L

L
(cid:88)

(cid:32)NW −1
(cid:88)

l=1

k=1

(cid:33)

w2kζk + w2NW ζ0

w2kζk − (1 − w2NW )ζ0

w2kζk + w2NW ζNW

=

(cid:33)

1
L

L
(cid:88)

(cid:32)NW(cid:88)

l=1

k=1

(cid:33)

w2kζk

(b)
= NW − 1 + w2NW ,

L
(cid:88)

(cid:32)NW −1
(cid:88)

l=1

L
(cid:88)

k=0
(cid:32)NW −1
(cid:88)

l=1

k=1

w2kζk +

(cid:35)

w2kζk + . . .

−

2NW −1
(cid:88)

k=NW

1
L

L
(cid:88)

l=1

(1 − w2NW )ζ0

(33)

where (a) is obtained from the fact that ζ0 = ζNW and (b) stems from the fact that w2k
as k = 1, . . . , NW − 1 and w2NW ζNW = w2NW . This completes the proof.

l ζk = 1

B. Proof of Theorem 2

Let m...t = [m1, . . . , mt−1, mt] be the input steam vector and z(l)

t be the output of ESN model

l. Next, we derive the memory capacity of a series ESN model using an enumeration method.
First, according to (27)-(32), we have Cov(z(1)
of the ﬁrst ESN model, z(1)
(cid:0)1 − w2NW (cid:1)2 w2kζkσ2. Similarly, we can obtain that Cov(z(3)
Therefore, we can conclude that Cov(z(L)
memory capacity of a series ESN can be given by (cid:80)∞

, mt−k) =
, mt−k) = (cid:0)1 − w2NW (cid:1)3 w2kζkσ2.
, mt−k) = (cid:0)1 − w2NW (cid:1)L w2kζk. Based on (34), the
(cid:0)1 − w2NW (cid:1)L w2kζk − (cid:0)1 − w2NW (cid:1)L ζ0.

, which is the input of the second ESN model, then Cov(z(2)

, mt−k) = (1 − w2NW )w2kσ2ζk. Given the output

t

t

t

t

t

k=0

30

(34)

(35)

(36)

Then, the memory capacity of a series ESN is

M =

∞
(cid:88)

k=0

(cid:0)1 − w2NW (cid:1)L

w2kζk − (cid:0)1 − w2NW (cid:1)L

ζ0 = (cid:0)1 − w2NW (cid:1)L

∞
(cid:88)

k=0

w2kζk − (cid:0)1 − w2NW (cid:1)L

ζ0

= (cid:0)1 − w2NW (cid:1)L

(cid:34)NW −1
(cid:88)

w2kζk +

(cid:35)

w2kζk + . . .

− (cid:0)1 − w2NW (cid:1)L

ζ0

2NW −1
(cid:88)

k=NW

k=0
(cid:32)NW −1
(cid:88)

(cid:33) (cid:32) ∞
(cid:88)

(cid:33)

w2NW k

w2kζk

− (cid:0)1 − w2NW (cid:1)L

ζ0

= (cid:0)1 − w2NW (cid:1)L

= (cid:0)1 − w2NW (cid:1)L

k=0
(cid:32) (cid:80)NW −1
k=0

(cid:0)w2kζk

1 − w2NW

k=0
(cid:1)L

−

(cid:33)

ζ0 − ζ0w2NW
1 − w2NW

(cid:16)

=

1 − w2NW
l

(cid:17)L−1 (cid:0)NW − 1 + w2NW (cid:1) .

This completes the proof.

C. Proof of Theorem 3

The memory capacity of a single ESN with multiple inputs is derived using an enumeration

method. Consider K = 2, then the input stream will be m...t = [m...1t, m...2t] where m...kt =

mk1 . . . mkt−2mkt−1mkt. Based on the proof of Theorems 1 and 2, R can be given by:

R =

1 + 2ρ12σ1σ2 + σ2
σ2
2
1 − w2NW

V TΓ 2V =

1 + 2ρ12σ1σ2 + σ2
σ2
2
1 − w2NW

A,

and pk = wk (σ2

2) rotk (V 1...N ). Then the output weight matrix can be given by:

1 + σ2
W out = (cid:0)1 − w2NW (cid:1) wk

1 + σ2
σ2
2
1 + 2ρ12σ1σ2 + σ2
σ2
2

A−1rotk (V 1...N ) .

The output at time t is

zt = (mt)T W out = (cid:0)1 − w2NW (cid:1) wk

1 + σ2
σ2
2
1 + 2ρ12σ1σ2 + σ2
σ2
2

(mt)T A−1rotk (V 1...N ) .

(37)

The covariance of the output at time t and t − k can be given by:
Cov (zt, mt−k) = (cid:0)1 − w2NW (cid:1) wk

Cov

(cid:16)

(µt)T , mt−k

(cid:17)

× A−1rotk (V 1...N )

1 + σ2
σ2
2
1 + 2ρ12σ1σ2 + σ2
σ2
2
2)2

= (cid:0)1 − w2NW (cid:1) w2k

(σ2

1 + σ2
1 + 2ρ12σ1σ2 + σ2
σ2
2

ζk.

Based on (32), Var (zt) = Cov (zt, mt−k) . Then, the memory capacity can be given by

M =

∞
(cid:88)

k=0

Cov2 (zt, mt−k)
Var (mt−k) Var (zt)

−

Cov2 (zt, mt)
Var (mt) Var (zt)

=

∞
(cid:88)

k=0

Cov (zt, mt−k)
1 + 2ρ12σ1σ2 + σ2
σ2
2

−

Cov (zt, mt)
1 + 2ρ12σ1σ2 + σ2
σ2
2

(cid:18)

=

(cid:18)

=

1 + σ2
σ2
2
1 + 2ρ12σ1σ2 + σ2
σ2
2

(cid:19)2

× (cid:0)1 − w2NW (cid:1)

NW −1
(cid:88)

k=0

w2kζk

∞
(cid:88)

j=0

r2NW j − (cid:0)1 − w2NW (cid:1)

1 + σ2
σ2
2
1 + 2ρ12σ1σ2 + σ2
σ2
2

(cid:19)2 NW −1
(cid:88)

k=0

w2kζk − (1 − w2NW ) =

(cid:18)

1 + σ2
σ2
2
1 + 2ρ12σ1σ2 + σ2
σ2
2

(cid:19)2

(cid:0)NW − 1 + w2NW (cid:1) .

(38)

31

Similarly, we can formulate the memory capacity of the single ESN with input vector mt =
(cid:17)2 (cid:0)NW − 1 + w2NW (cid:1) .
In consequence, the memory capacity of a single ESN with input vector mt = [m1t, . . . , mKt]

1+σ2
σ2
1+2ρ12σ1σ2+2ρ13σ1σ3+2ρ23σ2σ3+σ2
σ2

[m1t, m2t, m3t], which is given by

2+σ2
3

2+σ2
3

(cid:16)

can be given by

(cid:16)

(cid:80)K
(cid:80)K

l=1 σ2
l
n=1 ρknσkσn

(cid:80)K

k=1

(cid:17)2 (cid:0)NW − 1 + w2NW (cid:1). This completes the proof.

REFERENCES

[1] M. Chen, O. Semiari, W. Saad, X. Liu, and C. Yin, “Minimization of breaks in presence in wireless VR networks: An

ESN-based federated learning approach,” in Proc. of IEEE Global Communications Conference (GLOBECOM), Waikoloa,

HI, USA, December 2019.

[2] W. Saad, M. Bennis, and M. Chen, “A vision of 6G wireless systems: Applications, trends, technologies, and open research

problems,” IEEE Network, to appear, 2019.

[3] E. Ba¸stu˘g, M. Bennis, M. Médard, and M. Debbah, “Towards interconnected virtual reality: Opportunities, challenges and

enablers,” IEEE Communications Magazine, vol. 55, no. 6, pp. 110–117, Jan. 2017.

[4] X. Ge, L. Pan, Q. Li, G. Mao, and S. Tu, “Multipath cooperative communications networks for augmented and virtual

reality transmission,” IEEE Transactions on Multimedia, vol. 19, no. 10, pp. 2345–2358, Oct 2017.

[5] Y. Sun, Z. Chen, M. Tao, and H. Liu, “Communication, computing and caching for mobile VR delivery: Modeling and

trade-off,” arXiv preprint arXiv:1804.10335, April 2018.

[6] J. Park and M. Bennis, “URLLC-eMBB slicing to support VR multimodal perceptions over wireless cellular systems,”

available online: arxiv.org/abs/1805.00142, May 2018.

[7] X. Yang, Z. Chen, K. Li, Y. Sun, N. Liu, W. Xie, and Y. Zhao, “Communication-constrained mobile edge computing

systems for wireless virtual reality: Scheduling and tradeoff,” IEEE Access, vol. 6, pp. 16665–16677, March 2018.

[8] A. Taleb Zadeh Kasgari, W. Saad, and M. Debbah, “Human-in-the-loop wireless communications: Machine learning and

brain-aware resource management,” IEEE Transactions on Communications, to appear, 2019.

[9] M. S. Elbamby, C. Perfecto, M. Bennis, and K. Doppler, “Edge computing meets millimeter-wave enabled VR: Paving

the way to cutting the cord,” in Proc. of IEEE Wireless Communications and Networking Conference, Barcelona, Spain,

April 2018.

[10] W. C. Lo, C. L. Fan, S. C. Yen, and C. H. Hsu, “Performance measurements of 360 video streaming to head-mounted

displays over live 4G cellular networks,” in Proc. of Asia-Paciﬁc Network Operations and Management Symposium, Seoul,

South Korea, Sept 2017.

[11] M. Chen, W. Saad, and C. Yin, “Virtual reality over wireless networks: Quality-of-service model and learning-based

resource management,” IEEE Transactions on Communications, vol. 66, no. 11, pp. 5621–5635, Nov. 2018.

[12] O. Semiari, W. Saad, M. Bennis, and M. Debbah, “Integrated millimeter wave and sub-6 GHz wireless networks: A

roadmap for joint mobile broadband and ultra-reliable low-latency communications,” IEEE Wireless Communications, vol.

26, no. 2, pp. 109–115, April 2019.

[13] J. Yin, L. Li, H. Zhang, X. Li, A. Gao, and Z. Han, “A prediction-based coordination caching scheme for content centric

networking,” in Proc. of Wireless and Optical Communication Conference, Hualien, Taiwan, April 2018.

[14] L. Yao, A. Chen, J. Deng, J. Wang, and G. Wu, “A cooperative caching scheme based on mobility prediction in vehicular

content centric networks,” IEEE Transactions on Vehicular Technology, vol. 67, no. 6, pp. 5435–5444, June 2018.

[15] N. T. Nguyen, Y. Wang, H. Li, X. Liu, and Z. Han, “Extracting typical users’ moving patterns using deep learning,” in

Proc. of IEEE Global Communications Conference, Anaheim, CA, USA, Dec 2012.

32

[16] M. Chen, M. Mozaffari, W. Saad, C. Yin, M. Debbah, and C. S. Hong, “Caching in the sky: Proactive deployment

of cache-enabled unmanned aerial vehicles for optimized quality-of-experience,” IEEE Journal on Selected Areas on

Communications (JSAC), vol. 35, no. 5, pp. 1046–1061, May 2017.

[17] O. Esraﬁlian, R. Gangula, and D. Gesbert,

“Learning to communicate in UAV-aided wireless networks: Map-based

approaches,” IEEE Internet of Things Journal, to appear, 2018.

[18] K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov, C. Kiddon, J. Konecny, S. Mazzocchi, H. B.

McMahan, T. V. Overveldt, D. Petrou, D. Ramage, and J. Roselander, “Towards federated learning at scale: System design,”

arXiv preprint arXiv:1902.01046, 2019.

[19] J. Koneˇcn`y, H. B. McMahan, D. Ramage, and P. Richtárik, “Federated optimization: Distributed machine learning for

on-device intelligence,” arXiv preprint arXiv:1610.02527, 2016.

[20] J. Koneˇcn`y, B. McMahan, and D. Ramage, “Federated optimization: Distributed optimization beyond the datacenter,”

arXiv preprint arXiv:1511.03575, 2015.

[21] S. Samarakoon, M. Bennis, W. Saady, and M. Debbah, “Distributed federated learning for ultra-reliable low-latency

vehicular communications,” arXiv preprint arXiv:1807.08127, 2018.

[22] M. Chen, U. Challita, W. Saad, C. Yin, and M. Debbah, “Artiﬁcial neural networks-based machine learning for wireless

networks: A tutorial,” IEEE Communications Surveys Tutorials, to appear, 2019.

[23] O. Semiari, W. Saad, and M. Bennis, “Joint millimeter wave and microwave resources allocation in cellular networks with

dual-mode base stations,” IEEE Transactions on Wireless Communications, vol. 16, no. 7, pp. 4802–4816, July 2017.

[24] Q. Li, M. Yu, A. Pandharipande, X. Ge, J. Zhang, and J. Zhang, “Performance of virtual full-duplex relaying on cooperative

multi-path relay channels,” IEEE Transactions on Wireless Communications, vol. 15, no. 5, pp. 3628–3642, May 2016.

[25] Q. Li, M. Yu, A. Pandharipande, and X. Ge, “Outage analysis of co-operative two-path relay channels,” IEEE Transactions

on Wireless Communications, vol. 15, no. 5, pp. 3157–3169, May 2016.

[26] HTC, “HTC vive,” https://www.vive.com/us/.

[27] Oculus, “Mobile VR media overview,” https://www.oculus.com/.

[28] O. Semiari, W. Saad, M. Bennis, and Z. Dawy, “Inter-operator resource management for millimeter wave multi-hop

backhaul networks,” IEEE Transactions on Wireless Communications, vol. 16, no. 8, pp. 5258–5272, Aug 2017.

[29] K. Venugopal, M. C. Valenti, and R. W. Heath, “Device-to-device millimeter wave communications: Interference, coverage,

rate, and ﬁnite topologies,” IEEE Transactions on Wireless Communications, vol. 15, no. 9, pp. 6175–6188, Sep. 2016.

[30] J. Jerald, The VR book: Human-centered design for virtual reality, Morgan & Claypool, Sept. 2015.

[31] J. Chung, H. J. Yoon, and H. J. Gardner, “Analysis of break in presence during game play using a linear mixed model,”

ETRI journal, vol. 32, no. 5, pp. 687–694, Oct. 2010.

[32] M. M. Amiri and D. Gunduz, “Computation scheduling for distributed machine learning with straggling workers,” arXiv

preprint arXiv:1810.09992, Oct. 2018.

[33] V. Smith, C. K. Chiang, M. Sanjabi, and A. S. Talwalkar, “Federated multi-task learning,” in Proc. of Advances in Neural

Information Processing Systems, Long beach, CA,USA, Dec. 2017.

[34] S. Scardapane, D. Wang, and M. Panella, “A decentralized training algorithm for echo state networks in distributed big

data applications,” Neural Networks, vol. 78, pp. 65–74, June 2016.

[35] X. Liu, M. Chen, C. Yin, and W. Saad, “Analysis of memory capacity for deep echo state networks,” in Proc. of IEEE

International Conference on Machine Learning and Applications (ICMLA), Orlando, FL, USA, Dec 2018.

[36] M. Chen, W. Saad, C. Yin, and M. Debbah, “Echo state networks for proactive caching in cloud-based radio access

networks with mobile users,” IEEE Transactions on Wireless Communications, vol. 16, no. 6, pp. 3520–3535, June 2017.

[37] M. Bennis and D. Niyato, “A Q-learning based approach to interference avoidance in self-organized femtocell networks,”

in Proc. of IEEE Global Communications Conference Workshops, Miami, FL, USA, Dec 2010.

