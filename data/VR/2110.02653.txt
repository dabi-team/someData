Proactive Scheduling and Caching for Wireless VR
Viewport Streaming
Mostafa Abdelrahman∗, Mohammed Elbamby† and Vilho R¨ais¨anen†
∗Aalto University, Espoo, Finland mostafa.abdelrahman@aalto.ﬁ
†Nokia Bell Labs, Espoo, Finland {mohammed.elbamby, vilho.raisanen}@nokia-bell-labs.com

1
2
0
2

t
c
O
6

]
I

N
.
s
c
[

1
v
3
5
6
2
0
.
0
1
1
2
:
v
i
X
r
a

Abstract—Virtual Reality (VR) applications require high data
rate for a high-quality immersive experience,
in addition to
low latency to avoid dizziness and motion sickness. One of the
key wireless VR challenges is providing seamless connectivity
and meeting the stringent latency and bandwidth requirements.
This work proposes a proactive wireless VR system that utilizes
information about the user’s future orientation for proactive
scheduling and caching. This is achieved by leveraging deep
neural networks to predict users’ orientation trained on a real
dataset. The 360° scene is then partitioned using an overlapping
viewports scheme so that only portions of the scene covered by
the users’ perceptive ﬁeld-of-view are streamed. Furthermore,
to minimize the backhaul latency, popular viewports are cached
at the edge cloud based on spatial popularity proﬁles. Through
extensive simulations, we show that the proposed system provides
signiﬁcant latency and throughput performance improvement,
especially in ﬂuctuating channels and heavy load conditions. The
proactive scheduling enabled by the combination of machine
learning prediction and the proposed viewport scheme reduces
the mean latency by more than 80% while achieving successful
delivery rate close to 100%.

Index Terms—Virtual Reality (VR) streaming, 360° videos,
Head Movement Prediction, Viewport, Recurrent Neural Net-
works (RNN), Mobile Networks

I. INTRODUCTION

Over the last decade, virtual reality (VR) has seen signiﬁ-
cant advancements to improve the rendering capabilities and
provide a more immersive experience [1]. This has gained a
lot of attention from businesses and consumers and paved the
way for use cases such as interactive video games and 360°
videos [2]. However, many if not all, of today’s high-end VR
headsets require a wired connection to a powerful computer
to provide intensive rendering computation and user tracking.
The setup cost for a powerful PC and the reduced mobility
due to wired connections are amongst the main barriers to
mainstream adoption of such headsets. On the other hand,
some existing mid-range headsets provide better movement
ﬂexibility by utilizing local on-device computational power.
These headsets however provide limited capabilities and also
dissipate heat as the load increases, which is not favorable as
the head-mounted display (HMD) is close to the eyes.

An alternative approach is to rely on wireless connectivity
to cloud servers to carry out the heavy rendering while the
VR headset acts as a thin client. Remote centralized clouds
will induce high network and communication latency, which
is not suitable due to the latency sensitivity of VR applications.
Studies [3], [4] have shown that a latency of more than 15ms
in VR can lead to motion sickness. Increased latency also
breaks the immersion of the VR experience. Moreover, VR
applications have high bandwidth requirements as content is

projected inside a sphere and transmitting the entire 360°
view at each time frame is often not feasible on a wireless
connection. Fortunately, only a limited region of the sphere
is within users’ ﬁeld-of-view (FoV). Still, high bandwidth is
required to transmit only the FoV. The study in [2] estimated
a required bit rate of 1 Gbps for a 150x120° FoV. Therefore,
wireless VR headsets can provide a better experience, but
various optimizations need to be implemented to reduce the
latency and not restrict VR to simple and low-resolution
applications.

Streaming only the active FoV of a 360° video requires
having prior knowledge about the users’ FoV of the individual
frames. Much work has been done to predict
the users’
FoV for future frames. Prediction methods can be classi-
ﬁed into trajectory-based, content-based and hybrid methods.
Trajectory-based methods utilize historical head movements to
extrapolate future orientation. For example, the authors in [5]
developed a neural network regression model to predict the
user’s viewport based on the roll, pitch and yaw trajectories.
In [6], spectral clustering was used to cluster trajectories and
an individual trajectory is extrapolated based on the cluster
average. The work in [7] used a linear regressor to predict an
individual user future point, the prediction is then amended
via a K nearest neighbor election method of nearest users.
However, trajectory-based methods can suffer from huge drops
in accuracy for large prediction horizons (> 2 seconds).
Content-based methods, such as in [8] and [9], extract saliency
features from the video frame to predict future regions of
interest. As for hybrid methods, the saliency features and
trajectory information are combined. Examples are the studies
in [10] and [11].

From wireless streaming perspective, recent works have
investigated incorporating machine learning (ML) prediction
into optimizing streaming quality in wireless networks. For
example,
the studies in [12], [13] use FoV prediction to
determine relevant tiles to improve bandwidth consumption,
whereas in [14], a transmission scheme incorporating both
multicast and unicast
is proposed to maximize bandwidth
efﬁciency. The work of [15] used a recurrent neural network to
directly predict future FoV tiles of the 360° frame, and the pre-
diction is used to implement a proactive multicast transmission
scheme in a multi-user scenario. Similarly, other works have
focused on viewport-based streaming methods in which pre-
partitioned and rendered portions of video frames are streamed
to users. For instance, [5] used two deep neural networks
to predict the viewpoint center and the possible deviation in
the viewport center prediction, both predictions are used to

 
 
 
 
 
 
calculate and adaptive viewport size that contains the FoV
with high probability. Joint optimizing of VR transmission and
caching is studied in [16]. However, ML is used for network
management optimization but not for VR FoV prediction.

This paper proposes proactive wireless VR streaming
method. The proposed method predicts user’s future viewport
and subsequently assigns wireless resources to users and
caches popular viewports in a proactive manner such that
stringent low latency requirements are met. More concretely,
the contributions of the paper are summarized as follows:

i.e.,

• The method uses a deep neural network that processes
the time series of orientations to predict users’ orientation for
various time horizons to minimize latency as users navigate
the virtual environment.
• The 360° scene sphere is partitioned into small segments,
called viewports, and only the relevant segments are fetched.
Viewport-based rendering is shown to provide robustness
against non-perfect predictions,
less powerful models
could be used without signiﬁcant reduction in overall perfor-
mance.
• Viewport-based rendering also enables ofﬂine analysis and
caching of popular video viewports in edge clouds based on
spatial popularity proﬁles, resulting in improved bandwidth
usage, reduced backhaul latency and fewer quality transitions.
• The performance of the proposed approach is demonstrated
using extensive simulations. It is shown that the proposed
machine learning method achieves a mean angular error less
than 15° for a prediction horizon up to 30 frames. Proac-
tive network scheduling combined with overlapping viewport
scheme are shown to not only reduce the mean latency by
more than 80% but also to achieve a success delivery rate
close to 100%, particularly in ﬂuctuating channels. Caching
of popular viewports at the edge cloud is shown to improve
the 99-percentile delay by an additional 10%.

Th rest of this paper is organized as follows. The overall
model and architecture of our proposed system is presented in
Section II. The implementation of machine learning prediction
and network optimization components are then described in
Section III. The experimental setup and analysis of the results
are detailed in Section IV. Finally, conclusions are drawn in
the last Section.

II. SYSTEM MODEL

Consider an indoor VR arcade with dimensions l × w and
a set of users U, uniformly distributed throughout the arcade,
each equipped with millimeter wave (mmWave) HMDs. Each
user chooses to watch a 360° video v from the available
video catalog V. The network consists of multiple mmWave
small base stations (SBS) B at ﬁxed locations distributed
around the arcade. These SBSs are connected to an edge
cloud server equipped with a cache storage. While the user
is watching a particular video, the user location and 3DoF
pose are continuously tracked, uploaded and mapped into a
set of candidate viewports to be streamed back to the users.
An illustration of the network model is shown in Fig. 1.

Fig. 1: Illustration of network architecture for indoor VR
arcade with mmWave SBSs and edge cloud computing.

A. Edge Architecture Model

Due to the limited computational power and storage capacity
of the HMDs, content is rendered in the remote cloud server
and transmitted to the edge cloud with backhaul delay TBH .
The content is then transmitted via the SBSs to the users within
the indoor arcade with over-the-air (OTA) latency TOT A. To
minimize the backhaul latency, content is cached at the edge
cloud. Because of limited edge storage capacity, only the most
popular viewports are cached. For any video in the catalog,
not all viewports are equally likely to be requested by users.
Furthermore, the popularity changes with the content of the
video i.e., a viewport popularity is a function of current frame
index. Hence, the spatial popularity proﬁle of any video is
deﬁned as a ranking of the viewports within a frame.

B. Network Model

In mmWave communications, transmissions are challenging
due to sensitivity to blockage and high path loss in non-line-
of-sight (NLOS) conditions [17], [18]. Hence, mmWave can
achieve higher bandwidth over a smaller denser area and it
is well suited for the proposed VR arcade. We employ a
probabilistic model that weights both line-of-sight (LOS) and
NLOS path losses with the probability of LOS between a user
u and base station b. The path loss (cid:96)ub can be written as:

(cid:96)ub(d) = pt(d)(cid:96)LOS

ub (d) + (1 − pt(d))(cid:96)NLOS

ub

(d)

(1)

where pt(d) is the LOS probability, (cid:96)LOS
are the
ub
LOS and NLOS path loss respectively and d is the distance
in meters between the SBS and the user.

and (cid:96)NLOS

ub

For a user u, SBS b and transmit power pb, the Signal to

Interference and Noise Ratio (SINR) is calculated as:

SINRbu(t) =

pbGbu

c (t)Gbu
Rx(t)Gbu
Iu(t) + BWbN0

T x(t)

(2)

c (t), Gbu

Rx(t), Gbu

where Gbu
T x(t) are the channel, receive and
transmit antenna gains between user u and SBS b, respectively
BWb is the bandwidth for SBS b, N0 is the noise power
spectral density and Iu(t) is the interference at time instant t.

III. PROPOSED APPROACH

Because of the low latency requirements of VR applications,
we propose a joint prediction, matching and caching scheme.
First, we utilize machine learning to predict users’ head
orientations for future frames. Subsequently, the orientations
are mapped into viewports that can be pre-rendered and
proactively streamed to the user. Finally, users are matched
to SBSs and popular viewports are cached.

A. Pose Prediction

Let Pt denote the vectors of the 3DoF pose at time t
represented as a quaternion q = w + xˆi + yˆj + zˆk and let
TH be the prediction horizon. Also, let Pt−tp:t = {Pi}t
i=t−tp
be a sequence of the 3DoF poses between time t − tp and
time t. At each time step t, given Pt−tp:t we predict the user
pose ˆpt+tH at time t + TH such that the distance between the
ground truth future pose and the predicted pose is minimized.
The orientation prediction task can be formulated as a
sequence modeling problem, in which Recurrent neural net-
work (RNN) can tackle efﬁciently. In this work, we utilize
Gated Recurrent Units (GRUs) since they have been shown
to perform well for smaller datasets [19]. For a time horizon
TH and history window TP , the model input X ∈ RN ×Tp×D,
where N is the number of users and D is the dimension of
the input vector, equals 4 for quaternions, is fed into a GRU
unit with 128 hidden cells followed another GRU unit of the
same size and the output is fed into a linear layer.

The model output is y ∈ RN ×D, where yi is the prediction
for the ith user at time t + TH in the future and is trained
to minimize the root-mean-square error (RMSE). However,
care should be taken when comparing quaternions because, for
instance, the distance between q and −q is 2q even though they
represent the same orientation. Hence, in this work, we mea-
sure the angular distance between two quaternions using the
angle of rotation θ ∈ [0, π] needed to transform one orientation
into the other and it is calculated as θ = 2 × cos−1(|ˆq0 · ˆq1|),
where ˆq is the normalized quaternion, q1 · q2 is the dot product
and | · | is the absolute function.

B. Viewport Streaming

We deﬁne a viewport-based streaming scheme in which
viewports are ﬁxed and overlapping regions that cover the
entire sphere. The size and location of each viewport can be
conﬁgured based on the capabilities of the rendering server
with the constraint that any user’s FoV must lie entirely in at
least one viewport. Because the viewport size is larger than the
users’ FoV, which typically only accounts for approximately
1/6 of the entire sphere, this allows the system to tolerate the
inaccuracies of the machine learning prediction (see Fig. 2)
so that for small error values, the predicted orientation is
still mapped to a correct viewport that contains the actual
orientation.

A user’s FoV may also lie entirely in multiple viewports at
the same time. This offers two main advantages. First, since
the viewports are predeﬁned, they can be easily pre-rendered
and cached at the edge cloud, improving the overall system

Fig. 2: The larger size of the viewport allows the system to
tolerate the inaccuracies in predicting the users’ orientation.
Illustration adopted from [14].

performance. Second, since the viewports are overlapping, the
system can have multiple candidate viewports to choose for a
given FoV. The choice of the candidate viewport is controlled
by a policy to achieve a certain objective. For instance, one
policy is to select the minimum number of viewports that cover
a set of users and transmit these via multicast. Another policy
would be to select the most popular viewports that can be
available in the edge cloud cache.

C. Users-SBS Matching and Scheduling

The assignment of users to SBS and scheduling of frames
can be formulated as a matching game between the SBS and
users with active requests, each aiming to minimize latency.
This process is repeated at each time instant, hence, a matching
procedure is applied to prioritize users based on their requests
and the network load.

Let U = {u1, u2, ..., un} be the set of users and B =
{b1, b2, ...., bm} be the set of SBS. A matching S is a set
of ordered pairs from the set of all ordered pairs U × B such
that each member of U and B appears at most once in any pair
in S. Furthermore, each member in U and B has a preference
list that ranks members of the opposite set, for example, a
user u is said to prefer b to b(cid:48) if u ranks b higher than b(cid:48)
in u preference list. A pair (u, b) is blocking with respect
to a matching S if (u, b) does not belong to S and each of
u and b ranks the other higher than their partner in S. A
matching that contains no blocking pairs is a stable matching.
Gale and Shapely [20] proved that each matching problem has
a stable matching. They introduced the Deferred Acceptance
(DA) Algorithm which is guaranteed to ﬁnd a stable matching
in polynomial time, with O(n2) worst case runtime.

In this work, the user-SBS preference is chosen to minimize
latency, which can be approximated as the ratio between the
required rate (bits) and the actual service rate (bits/s). In
the considered video streaming scenario, the required rate is
constant as users are requesting ﬁxed sized viewports. Fur-
thermore, only the estimated service rate can be known before
transmission since interference cannot be calculated a priori.
Hence, the latency is inversely propositional to the estimated
service rate. Hence, we consider the user-SBS preference for
a user u and SBS b as:

Prefub(t) = BWb log2(1 + SINRbu(t))

(3)

Algorithm 1 Scheduling between SBSs and Users
Stage I - Ready-to-schedule users

Let vpprediction(t) to be the predicted viewport received at time t.
Let vpreal-time(t) to be the actual viewport received at time t.
for user u ∈ U do

Append vpprediction(t) to user queue with deadline t + TH .
if vpreal-time(t) (cid:54)= vpprediction(t − TH ) then

Append vpreal-time(t) to user queue with deadline t.

end if

end for
U (cid:48) ← {u ∈ U | queue is non empty}
State II - Matching and scheduling

(cid:46) eligible set of users

For each user u ∈ U (cid:48) and SBS b ∈ B, calculate Prefub(t).
Initialize the subset of unmatched users SU ⊆ U (cid:48) so that initially |SU | =
|U (cid:48)|.
Initialize the subset of unmatched SBSs SB ⊆ B so that initially |SB| =
|B|.
For each user u ∈ U (cid:48), initialize the subset of proposal candidates Pu ⊆ B
so that initially |Pu| = |B|.
while |SU | (cid:54)= ∅ and ∀u∈U (cid:48) |Pu| (cid:54)= ∅ do

Pick a random user u ∈ SU such that Pu is not empty.
Let b be the highest-ranked SBS in Pu.
if b ∈ SB then

(cid:46) b is free

Match b and u and remove them from SU and SB respectively.

else

if Prefu(cid:48)b(t) > Prefub(t) then
Refuse proposal from u.
Remove b from Pu.

(cid:46) b is matched with another user u(cid:48)
(cid:46) b ranks u(cid:48) higher than u

(cid:46) b is no longer a candidate for u

else

Unmatch b from u(cid:48) and add u(cid:48) back to SU
Match b and u and remove u from SU

end if

end if
end while
For each user u ∈ UM , sort user queue in descending order of deadline.

where SINRbu is calculated as deﬁned in Eq. 2 with the
interference estimated using an exponential moving average
ˆIu and instantaneous interference ˜Iu at time instant t − 1 with
a learning parameter β. The instantaneous interference ˜Iu(t)
on a user u due to currently transmitting active users is given
by:

˜Iu(t) =

(cid:88)

b∈B(cid:48)

pbGbu

T x(t)

Rx(t)Gbu
(cid:96)ub(t)

(4)

where B(cid:48) is the set of interfering base stations and (cid:96)ub is the
path loss, the interference is then estimated as Iu:
Iu(t) = β ˜Iu(t − 1) + (1 − β) ˆIu(t − 1)

(5)

Only users with non-empty queues enter the matching
procedure. For a network with B SBSs and U users, at each
transmission instant, at most B users can have an active
transmission. Once a stable matching is reached, the network
prioritizes each user queue according to their deadlines. Each
user queue can contain either or all of (1) predicted viewports,
with their deadlines being after the time horizon TH . (2)
sensory-based viewports, with real-time deadline. The latter
are admitted to into the queues in case of a false positive
prediction. This process is performed by the scheduler and is
outlined in Algorithm 1.

D. Caching

In order to estimate the spatial popularity proﬁle of any
video, we analyze the historical viewing data to rank the
viewports and deﬁne the popularity of viewport vpf at frame
index f as the ratio of the users that requested viewport vpf
to the total number of users. The K most popular viewports
at each frame index are then cached at the edge cloud. This
number K is dependent on the storage capacity available at the
edge cloud and the viewport conﬁguration used, for example
a viewport in a 3x3 conﬁguration is 1.5 larger than a viewport
in a 5x5 conﬁguration.

IV. SIMULATION RESULTS

In this section, we evaluate the performance of the proposed
system on a public dataset collected from 59 users watching
seven 360° videos, each about 60 seconds long [21].

A. Machine Learning Training & Evaluation

A separate model is trained for each video and the training
and validation sets contain 80% and 20% of the traces respec-
tively. The models were trained using the Adam optimizer with
no weight decay and (β1 = 0.9, β2 = 0.999) for the running
averages coefﬁcients. The models were trained for 100 epochs
and a batch size of 32. This process is repeated using K-fold
cross validation (K = 5).

The models had a different performance proﬁle among
the different videos in the dataset. Overall, there is a rising
linear trend in error versus time horizon with the lowest error
achieved in ‘Rollercoaster‘ followed by ‘Rhino‘ and ‘Venice‘
whereas ‘Timelapse‘ had the highest error, as shown in Fig. 3.
The actual and predicted users’ orientations are then mapped
to the equivalent viewports to be used in the network simu-
lations. In this work, we consider the 3x3 and 5x5 viewport
conﬁguration as they provide a good trade-off between the
required storage space and overall viewport size.

B. Network Simulations

We consider a square VR arcade with 100m side length.
SBSs are located at the 4 corners of the arcade and users
are uniformly distributed throughout the arcade. The pathloss

Fig. 3: Aggregated Model performance for different videos for
time step = 10 frames.

                  W L P H  K R U L ] R Q      0 H D Q  $ Q J X O D U  ' L V W D Q F H  °  9 L G H R ' L Y L Q J ( O H S K D Q W 3 D U L V 5 K L Q R 5 R O O H U F R D V W H U 7 L P H O D S V H 9 H Q L F Hmodel follows the probabilistic model deﬁned in Section II-B
and values are chosen according to 3GPP standard [22].
The pathloss (cid:96)ub(d) is recalculated every 100ms during the
simulation with LOS probability p(d) calculated as:




p(d) =

1.0
exp(− d−5
70.8 )
211.7 ) × 0.54
Table I provides the set of default parameter values used

d ≤ 5m
5m < d ≤ 49
d > 49m

exp(− d−49

(6)



for the simulations.

TABLE I: Simulation Parameters.

Parameter
Simulation time
Transmission slot duration
Bandwidth
mmWave Band
Rx beamwidth
Tx beamwidth
Noise spectral density
SBS transmit power
Users per video
Catalog size
Time step window
Prediction horizon
Frame duration
Backhaul latency
Cache size

Value
30 s
0.25 ms
0.85 GHz
28 GHz
45°
90°
-174 dBm/Hz
24 dBm
12
[3, 4, 5, 6] videos
10 frames
[5, 10, 15, 20, 25 ,30] frames
33 ms
3 ms
2 viewports per video frame

The following 4 schemes are considered for comparison:

• ML: Requests are proactively scheduled.
• ML (cache): Requests are proactively scheduled and pop-
ular viewports are cached at the edge cloud.
• NML: Requests are scheduled in real-time.
• NML (cache): Requests are scheduled in real-time and
popular viewports are cached at the edge cloud.

The performance of each scheme is evaluated through
average, and 99th percentile delay. Furthermore, transition
quality percentage, deﬁned as the ratio of times HD frame
delivery failed and HMD had to downgrade to a lower quality
frame or interpolate previous frames to the total number of
frames, and the HD delivery rate and measured. The metrics
are averaged over all users.

a) Impact of Network Load: The effect of the network
load is analyzed by simulating the network under an increasing
number of users and videos. Fig. 4 shows that the proposed
schemes achieve lower latency and maintain close to 100% HD
rate up to 60 users. Furthermore, caching helps signiﬁcantly
reduce the rising slope of the 99th percentile delay, this is
observed in the different schemes, with more prominence in
non-ML schemes. Intuitively, for real-time requests, fetching
content from the remote cloud is on the critical path and any
speedup in fetching improves the overall latency. However, in
ML schemes and with the use of proactive scheduling, fetching
content is no longer on the critical path as the network has
TH frames to deliver the content.

b) Impact of Prediction Horizon: A longer prediction
horizon TH allows the scheduler more leeway in scheduling
future frames, however, the prediction error monotonically

increases with the prediction horizon, as discussed in Section
IV-A, resulting in more data to be transmitted in real-time.
Hence, the baseline methods remain constant as they do not
proactive schedule frames whereas in the proposed methods
the delay is affected by (1) the network load and ability to meet
the current demand and (2) the prediction error causing misses
and for frames to be scheduled in real-time. Fig. 5 shows the
performance using 72 users for a 3x3 viewport conﬁguration.
In this heavily loaded scenario, the delay exhibits a U-shaped
performance where the delay initially decreases due to having
more scheduling time, then increases again due to high miss
rate and the need to schedule more frames in real-time.

As such, even with non-perfect predictions,

the use of
proactive scheduling has signiﬁcantly improved the latency
and delivery rate. Proactive scheduling is especially useful in
ﬂuctuating channels; by transmitting viewports a few frames
in advance, a transient drop in users’ rate budget would not
result in an outage.

V. CONCLUSION
This paper has presented a solution for proactive VR
viewport streaming in wireless network. The proposed solution
minimizes latency and meets the high bandwidth and low
latency constraints by combining user orientation prediction,
caching, and proactive delivery of user’s own viewport of the
360° video frame. Machine learning model based on recurrent
neural networks has been developed and has been shown to
predict user orientation at a future time horizon based on
previous motion history. Subsequently, Deferred Acceptance
matching algorithm has then been used to match users and base
stations with the preferences deﬁned to minimize estimated
latency. The combination of prediction and matching for
proactive streaming is shown to signiﬁcantly minimize latency
and maximize delivery rate. Caching has been leveraged to
store popular video viewports in edge servers close to users
which is shown to minimize the latency, especially in real-time
requests.

REFERENCES

[1] S. Mandal, “Brief introduction of virtual reality & its challenges,”
International Journal of Scientiﬁc & Engineering Research, vol. 4, no. 4,
pp. 304–309, 2013.

[2] M. S. Elbamby, C. Perfecto, M. Bennis, and K. Doppler, “Toward low-
latency and ultra-reliable virtual reality,” IEEE Network, vol. 32, no. 2,
pp. 78–84, 2018.

[3] M. C. Potter, B. Wyble, C. E. Hagmann, and E. S. McCourt, “Detecting
meaning in RSVP at 13 ms per picture,” Attention, Perception, &
Psychophysics, vol. 76, no. 2, pp. 270–279, 2014.

[4] R. Albert, A. Patney, D. Luebke, and J. Kim, “Latency requirements
for foveated rendering in virtual reality,” ACM Transactions on Applied
Perception (TAP), vol. 14, no. 4, pp. 1–13, 2017.

[5] Y. Bao, H. Wu, T. Zhang, A. A. Ramli, and X. Liu, “Shooting a moving
target: Motion-prediction-based transmission for 360-degree videos,” in
2016 IEEE International Conference on Big Data (Big Data), 2016, pp.
1161–1170.

[6] S. Petrangeli, G. Simon, and V. Swaminathan, “Trajectory-based view-
port prediction for 360-degree virtual reality videos,” in 2018 IEEE
International Conference on Artiﬁcial Intelligence and Virtual Reality
(AIVR).

IEEE, 2018, pp. 157–160.

[7] Y. Ban, L. Xie, Z. Xu, X. Zhang, Z. Guo, and Y. Wang, “Cub360:
Exploiting cross-users behaviors for viewport prediction in 360 video
adaptive streaming,” in 2018 IEEE International Conference on Multi-
media and Expo (ICME).

IEEE, 2018, pp. 1–6.

(a)

(b)

(c)

(d)

Fig. 4: (a) Average delay, (b) 99th percentile delay, (c) HD delivery rate and (d) Quality transition versus the number of users
(with a ﬁxed number of 12 users per video) in a 5x5 viewport conﬁguration with TH = 10.

(a)

(b)

(c)

(d)

Fig. 5: (a) Average delay, (b) 99th percentile delay, (c) HD delivery rate and (d) Quality transition versus the prediction horizon
(in frames) in a 3x3 viewport conﬁguration for 72 users.

[8] M. Xu, Y. Song, J. Wang, M. Qiao, L. Huo, and Z. Wang, “Predicting
head movement in panoramic video: A deep reinforcement learning
approach,” IEEE transactions on pattern analysis and machine intel-
ligence, vol. 41, no. 11, pp. 2693–2708, 2018.

[9] C. Li, W. Zhang, Y. Liu, and Y. Wang, “Very long term ﬁeld of view
prediction for 360-degree video streaming,” in 2019 IEEE Conference
on Multimedia Information Processing and Retrieval (MIPR).
IEEE,
2019, pp. 297–302.

[10] M. F. R. Rond´on, L. Sassatelli, R. A. Pardo, and F. Precioso, “Track:
a multi-modal deep architecture for head motion prediction in 360°
videos,” in 2020 IEEE International Conference on Image Processing
(ICIP).

IEEE, 2020, pp. 2586–2590.

[11] A. Nguyen, Z. Yan, and K. Nahrstedt, “Your attention is unique:
Detecting 360-degree video saliency in head-mounted display for head
movement prediction,” in Proceedings of the 26th ACM international
conference on Multimedia, 2018, pp. 1190–1198.

[12] F. Qian, B. Han, Q. Xiao, and V. Gopalakrishnan, “Flare: Practical
viewport-adaptive 360-degree video streaming for mobile devices,” in
Proceedings of the 24th Annual International Conference on Mobile
Computing and Networking, 2018, pp. 99–114.

[13] F. Qian, L. Ji, B. Han, and V. Gopalakrishnan, “Optimizing 360 video
delivery over cellular networks,” in Proceedings of the 5th Workshop
on All Things Cellular: Operations, Applications and Challenges, 2016,
pp. 1–6.

[14] Y. Bao, T. Zhang, A. Pande, H. Wu, and X. Liu, “Motion-prediction-
based multicast for 360-degree video transmissions,” in 2017 14th
Annual IEEE International Conference on Sensing, Communication, and
Networking (SECON).
IEEE, 2017, pp. 1–9.

[15] C. Perfecto, M. S. Elbamby, J. Del Ser, and M. Bennis, “Taming
the latency in multi-user VR 360°: A QoE-aware deep learning-aided
multicast framework,” IEEE Transactions on Communications, vol. 68,
no. 4, pp. 2491–2508, 2020.

[16] M. Chen, W. Saad, and C. Yin, “Echo-liquid state deep learning for 360°
content transmission and caching in wireless vr networks with cellular-
connected uavs,” IEEE Transactions on Communications, vol. 67, no. 9,
pp. 6386–6400, 2019.

[17] Y. Niu, Y. Li, D. Jin, L. Su, and A. V. Vasilakos, “A survey of millimeter
wave communications (mmWave) for 5g: opportunities and challenges,”
Wireless networks, vol. 21, no. 8, pp. 2657–2676, 2015.

[18] L. Wei, R. Q. Hu, Y. Qian, and G. Wu, “Key elements to enable mil-
limeter wave communications for 5g wireless systems,” IEEE Wireless
Communications, vol. 21, no. 6, pp. 136–143, 2014.

[19] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, “Empirical evaluation of
gated recurrent neural networks on sequence modeling,” arXiv preprint
arXiv:1412.3555, 2014.

[20] D. Gale and L. S. Shapley, “College admissions and the stability of
marriage,” The American Mathematical Monthly, vol. 69, no. 1, pp. 9–
15, 1962.

[21] X. Corbillon, F. De Simone, and G. Simon, “360-degree video head
movement dataset,” in Proceedings of the 8th ACM on Multimedia
Systems Conference, ser. MMSys’17. ACM, 2017, pp. 199–204.
[22] 3GPP, “3rd generation partnership project; technical speciﬁcation group
radio access network; study on channel model for frequencies from 0.5
to 100 GHz,” Tech. Rep. 38.901 version 16.1.0 Release 16, 12 2020.

