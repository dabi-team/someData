Proactive Scheduling and Caching for Wireless VR
Viewport Streaming
Mostafa Abdelrahmanâˆ—, Mohammed Elbambyâ€  and Vilho RÂ¨aisÂ¨anenâ€ 
âˆ—Aalto University, Espoo, Finland mostafa.abdelrahman@aalto.ï¬
â€ Nokia Bell Labs, Espoo, Finland {mohammed.elbamby, vilho.raisanen}@nokia-bell-labs.com

1
2
0
2

t
c
O
6

]
I

N
.
s
c
[

1
v
3
5
6
2
0
.
0
1
1
2
:
v
i
X
r
a

Abstractâ€”Virtual Reality (VR) applications require high data
rate for a high-quality immersive experience,
in addition to
low latency to avoid dizziness and motion sickness. One of the
key wireless VR challenges is providing seamless connectivity
and meeting the stringent latency and bandwidth requirements.
This work proposes a proactive wireless VR system that utilizes
information about the userâ€™s future orientation for proactive
scheduling and caching. This is achieved by leveraging deep
neural networks to predict usersâ€™ orientation trained on a real
dataset. The 360Â° scene is then partitioned using an overlapping
viewports scheme so that only portions of the scene covered by
the usersâ€™ perceptive ï¬eld-of-view are streamed. Furthermore,
to minimize the backhaul latency, popular viewports are cached
at the edge cloud based on spatial popularity proï¬les. Through
extensive simulations, we show that the proposed system provides
signiï¬cant latency and throughput performance improvement,
especially in ï¬‚uctuating channels and heavy load conditions. The
proactive scheduling enabled by the combination of machine
learning prediction and the proposed viewport scheme reduces
the mean latency by more than 80% while achieving successful
delivery rate close to 100%.

Index Termsâ€”Virtual Reality (VR) streaming, 360Â° videos,
Head Movement Prediction, Viewport, Recurrent Neural Net-
works (RNN), Mobile Networks

I. INTRODUCTION

Over the last decade, virtual reality (VR) has seen signiï¬-
cant advancements to improve the rendering capabilities and
provide a more immersive experience [1]. This has gained a
lot of attention from businesses and consumers and paved the
way for use cases such as interactive video games and 360Â°
videos [2]. However, many if not all, of todayâ€™s high-end VR
headsets require a wired connection to a powerful computer
to provide intensive rendering computation and user tracking.
The setup cost for a powerful PC and the reduced mobility
due to wired connections are amongst the main barriers to
mainstream adoption of such headsets. On the other hand,
some existing mid-range headsets provide better movement
ï¬‚exibility by utilizing local on-device computational power.
These headsets however provide limited capabilities and also
dissipate heat as the load increases, which is not favorable as
the head-mounted display (HMD) is close to the eyes.

An alternative approach is to rely on wireless connectivity
to cloud servers to carry out the heavy rendering while the
VR headset acts as a thin client. Remote centralized clouds
will induce high network and communication latency, which
is not suitable due to the latency sensitivity of VR applications.
Studies [3], [4] have shown that a latency of more than 15ms
in VR can lead to motion sickness. Increased latency also
breaks the immersion of the VR experience. Moreover, VR
applications have high bandwidth requirements as content is

projected inside a sphere and transmitting the entire 360Â°
view at each time frame is often not feasible on a wireless
connection. Fortunately, only a limited region of the sphere
is within usersâ€™ ï¬eld-of-view (FoV). Still, high bandwidth is
required to transmit only the FoV. The study in [2] estimated
a required bit rate of 1 Gbps for a 150x120Â° FoV. Therefore,
wireless VR headsets can provide a better experience, but
various optimizations need to be implemented to reduce the
latency and not restrict VR to simple and low-resolution
applications.

Streaming only the active FoV of a 360Â° video requires
having prior knowledge about the usersâ€™ FoV of the individual
frames. Much work has been done to predict
the usersâ€™
FoV for future frames. Prediction methods can be classi-
ï¬ed into trajectory-based, content-based and hybrid methods.
Trajectory-based methods utilize historical head movements to
extrapolate future orientation. For example, the authors in [5]
developed a neural network regression model to predict the
userâ€™s viewport based on the roll, pitch and yaw trajectories.
In [6], spectral clustering was used to cluster trajectories and
an individual trajectory is extrapolated based on the cluster
average. The work in [7] used a linear regressor to predict an
individual user future point, the prediction is then amended
via a K nearest neighbor election method of nearest users.
However, trajectory-based methods can suffer from huge drops
in accuracy for large prediction horizons (> 2 seconds).
Content-based methods, such as in [8] and [9], extract saliency
features from the video frame to predict future regions of
interest. As for hybrid methods, the saliency features and
trajectory information are combined. Examples are the studies
in [10] and [11].

From wireless streaming perspective, recent works have
investigated incorporating machine learning (ML) prediction
into optimizing streaming quality in wireless networks. For
example,
the studies in [12], [13] use FoV prediction to
determine relevant tiles to improve bandwidth consumption,
whereas in [14], a transmission scheme incorporating both
multicast and unicast
is proposed to maximize bandwidth
efï¬ciency. The work of [15] used a recurrent neural network to
directly predict future FoV tiles of the 360Â° frame, and the pre-
diction is used to implement a proactive multicast transmission
scheme in a multi-user scenario. Similarly, other works have
focused on viewport-based streaming methods in which pre-
partitioned and rendered portions of video frames are streamed
to users. For instance, [5] used two deep neural networks
to predict the viewpoint center and the possible deviation in
the viewport center prediction, both predictions are used to

 
 
 
 
 
 
calculate and adaptive viewport size that contains the FoV
with high probability. Joint optimizing of VR transmission and
caching is studied in [16]. However, ML is used for network
management optimization but not for VR FoV prediction.

This paper proposes proactive wireless VR streaming
method. The proposed method predicts userâ€™s future viewport
and subsequently assigns wireless resources to users and
caches popular viewports in a proactive manner such that
stringent low latency requirements are met. More concretely,
the contributions of the paper are summarized as follows:

i.e.,

â€¢ The method uses a deep neural network that processes
the time series of orientations to predict usersâ€™ orientation for
various time horizons to minimize latency as users navigate
the virtual environment.
â€¢ The 360Â° scene sphere is partitioned into small segments,
called viewports, and only the relevant segments are fetched.
Viewport-based rendering is shown to provide robustness
against non-perfect predictions,
less powerful models
could be used without signiï¬cant reduction in overall perfor-
mance.
â€¢ Viewport-based rendering also enables ofï¬‚ine analysis and
caching of popular video viewports in edge clouds based on
spatial popularity proï¬les, resulting in improved bandwidth
usage, reduced backhaul latency and fewer quality transitions.
â€¢ The performance of the proposed approach is demonstrated
using extensive simulations. It is shown that the proposed
machine learning method achieves a mean angular error less
than 15Â° for a prediction horizon up to 30 frames. Proac-
tive network scheduling combined with overlapping viewport
scheme are shown to not only reduce the mean latency by
more than 80% but also to achieve a success delivery rate
close to 100%, particularly in ï¬‚uctuating channels. Caching
of popular viewports at the edge cloud is shown to improve
the 99-percentile delay by an additional 10%.

Th rest of this paper is organized as follows. The overall
model and architecture of our proposed system is presented in
Section II. The implementation of machine learning prediction
and network optimization components are then described in
Section III. The experimental setup and analysis of the results
are detailed in Section IV. Finally, conclusions are drawn in
the last Section.

II. SYSTEM MODEL

Consider an indoor VR arcade with dimensions l Ã— w and
a set of users U, uniformly distributed throughout the arcade,
each equipped with millimeter wave (mmWave) HMDs. Each
user chooses to watch a 360Â° video v from the available
video catalog V. The network consists of multiple mmWave
small base stations (SBS) B at ï¬xed locations distributed
around the arcade. These SBSs are connected to an edge
cloud server equipped with a cache storage. While the user
is watching a particular video, the user location and 3DoF
pose are continuously tracked, uploaded and mapped into a
set of candidate viewports to be streamed back to the users.
An illustration of the network model is shown in Fig. 1.

Fig. 1: Illustration of network architecture for indoor VR
arcade with mmWave SBSs and edge cloud computing.

A. Edge Architecture Model

Due to the limited computational power and storage capacity
of the HMDs, content is rendered in the remote cloud server
and transmitted to the edge cloud with backhaul delay TBH .
The content is then transmitted via the SBSs to the users within
the indoor arcade with over-the-air (OTA) latency TOT A. To
minimize the backhaul latency, content is cached at the edge
cloud. Because of limited edge storage capacity, only the most
popular viewports are cached. For any video in the catalog,
not all viewports are equally likely to be requested by users.
Furthermore, the popularity changes with the content of the
video i.e., a viewport popularity is a function of current frame
index. Hence, the spatial popularity proï¬le of any video is
deï¬ned as a ranking of the viewports within a frame.

B. Network Model

In mmWave communications, transmissions are challenging
due to sensitivity to blockage and high path loss in non-line-
of-sight (NLOS) conditions [17], [18]. Hence, mmWave can
achieve higher bandwidth over a smaller denser area and it
is well suited for the proposed VR arcade. We employ a
probabilistic model that weights both line-of-sight (LOS) and
NLOS path losses with the probability of LOS between a user
u and base station b. The path loss (cid:96)ub can be written as:

(cid:96)ub(d) = pt(d)(cid:96)LOS

ub (d) + (1 âˆ’ pt(d))(cid:96)NLOS

ub

(d)

(1)

where pt(d) is the LOS probability, (cid:96)LOS
are the
ub
LOS and NLOS path loss respectively and d is the distance
in meters between the SBS and the user.

and (cid:96)NLOS

ub

For a user u, SBS b and transmit power pb, the Signal to

Interference and Noise Ratio (SINR) is calculated as:

SINRbu(t) =

pbGbu

c (t)Gbu
Rx(t)Gbu
Iu(t) + BWbN0

T x(t)

(2)

c (t), Gbu

Rx(t), Gbu

where Gbu
T x(t) are the channel, receive and
transmit antenna gains between user u and SBS b, respectively
BWb is the bandwidth for SBS b, N0 is the noise power
spectral density and Iu(t) is the interference at time instant t.

III. PROPOSED APPROACH

Because of the low latency requirements of VR applications,
we propose a joint prediction, matching and caching scheme.
First, we utilize machine learning to predict usersâ€™ head
orientations for future frames. Subsequently, the orientations
are mapped into viewports that can be pre-rendered and
proactively streamed to the user. Finally, users are matched
to SBSs and popular viewports are cached.

A. Pose Prediction

Let Pt denote the vectors of the 3DoF pose at time t
represented as a quaternion q = w + xË†i + yË†j + zË†k and let
TH be the prediction horizon. Also, let Ptâˆ’tp:t = {Pi}t
i=tâˆ’tp
be a sequence of the 3DoF poses between time t âˆ’ tp and
time t. At each time step t, given Ptâˆ’tp:t we predict the user
pose Ë†pt+tH at time t + TH such that the distance between the
ground truth future pose and the predicted pose is minimized.
The orientation prediction task can be formulated as a
sequence modeling problem, in which Recurrent neural net-
work (RNN) can tackle efï¬ciently. In this work, we utilize
Gated Recurrent Units (GRUs) since they have been shown
to perform well for smaller datasets [19]. For a time horizon
TH and history window TP , the model input X âˆˆ RN Ã—TpÃ—D,
where N is the number of users and D is the dimension of
the input vector, equals 4 for quaternions, is fed into a GRU
unit with 128 hidden cells followed another GRU unit of the
same size and the output is fed into a linear layer.

The model output is y âˆˆ RN Ã—D, where yi is the prediction
for the ith user at time t + TH in the future and is trained
to minimize the root-mean-square error (RMSE). However,
care should be taken when comparing quaternions because, for
instance, the distance between q and âˆ’q is 2q even though they
represent the same orientation. Hence, in this work, we mea-
sure the angular distance between two quaternions using the
angle of rotation Î¸ âˆˆ [0, Ï€] needed to transform one orientation
into the other and it is calculated as Î¸ = 2 Ã— cosâˆ’1(|Ë†q0 Â· Ë†q1|),
where Ë†q is the normalized quaternion, q1 Â· q2 is the dot product
and | Â· | is the absolute function.

B. Viewport Streaming

We deï¬ne a viewport-based streaming scheme in which
viewports are ï¬xed and overlapping regions that cover the
entire sphere. The size and location of each viewport can be
conï¬gured based on the capabilities of the rendering server
with the constraint that any userâ€™s FoV must lie entirely in at
least one viewport. Because the viewport size is larger than the
usersâ€™ FoV, which typically only accounts for approximately
1/6 of the entire sphere, this allows the system to tolerate the
inaccuracies of the machine learning prediction (see Fig. 2)
so that for small error values, the predicted orientation is
still mapped to a correct viewport that contains the actual
orientation.

A userâ€™s FoV may also lie entirely in multiple viewports at
the same time. This offers two main advantages. First, since
the viewports are predeï¬ned, they can be easily pre-rendered
and cached at the edge cloud, improving the overall system

Fig. 2: The larger size of the viewport allows the system to
tolerate the inaccuracies in predicting the usersâ€™ orientation.
Illustration adopted from [14].

performance. Second, since the viewports are overlapping, the
system can have multiple candidate viewports to choose for a
given FoV. The choice of the candidate viewport is controlled
by a policy to achieve a certain objective. For instance, one
policy is to select the minimum number of viewports that cover
a set of users and transmit these via multicast. Another policy
would be to select the most popular viewports that can be
available in the edge cloud cache.

C. Users-SBS Matching and Scheduling

The assignment of users to SBS and scheduling of frames
can be formulated as a matching game between the SBS and
users with active requests, each aiming to minimize latency.
This process is repeated at each time instant, hence, a matching
procedure is applied to prioritize users based on their requests
and the network load.

Let U = {u1, u2, ..., un} be the set of users and B =
{b1, b2, ...., bm} be the set of SBS. A matching S is a set
of ordered pairs from the set of all ordered pairs U Ã— B such
that each member of U and B appears at most once in any pair
in S. Furthermore, each member in U and B has a preference
list that ranks members of the opposite set, for example, a
user u is said to prefer b to b(cid:48) if u ranks b higher than b(cid:48)
in u preference list. A pair (u, b) is blocking with respect
to a matching S if (u, b) does not belong to S and each of
u and b ranks the other higher than their partner in S. A
matching that contains no blocking pairs is a stable matching.
Gale and Shapely [20] proved that each matching problem has
a stable matching. They introduced the Deferred Acceptance
(DA) Algorithm which is guaranteed to ï¬nd a stable matching
in polynomial time, with O(n2) worst case runtime.

In this work, the user-SBS preference is chosen to minimize
latency, which can be approximated as the ratio between the
required rate (bits) and the actual service rate (bits/s). In
the considered video streaming scenario, the required rate is
constant as users are requesting ï¬xed sized viewports. Fur-
thermore, only the estimated service rate can be known before
transmission since interference cannot be calculated a priori.
Hence, the latency is inversely propositional to the estimated
service rate. Hence, we consider the user-SBS preference for
a user u and SBS b as:

Prefub(t) = BWb log2(1 + SINRbu(t))

(3)

Algorithm 1 Scheduling between SBSs and Users
Stage I - Ready-to-schedule users

Let vpprediction(t) to be the predicted viewport received at time t.
Let vpreal-time(t) to be the actual viewport received at time t.
for user u âˆˆ U do

Append vpprediction(t) to user queue with deadline t + TH .
if vpreal-time(t) (cid:54)= vpprediction(t âˆ’ TH ) then

Append vpreal-time(t) to user queue with deadline t.

end if

end for
U (cid:48) â† {u âˆˆ U | queue is non empty}
State II - Matching and scheduling

(cid:46) eligible set of users

For each user u âˆˆ U (cid:48) and SBS b âˆˆ B, calculate Prefub(t).
Initialize the subset of unmatched users SU âŠ† U (cid:48) so that initially |SU | =
|U (cid:48)|.
Initialize the subset of unmatched SBSs SB âŠ† B so that initially |SB| =
|B|.
For each user u âˆˆ U (cid:48), initialize the subset of proposal candidates Pu âŠ† B
so that initially |Pu| = |B|.
while |SU | (cid:54)= âˆ… and âˆ€uâˆˆU (cid:48) |Pu| (cid:54)= âˆ… do

Pick a random user u âˆˆ SU such that Pu is not empty.
Let b be the highest-ranked SBS in Pu.
if b âˆˆ SB then

(cid:46) b is free

Match b and u and remove them from SU and SB respectively.

else

if Prefu(cid:48)b(t) > Prefub(t) then
Refuse proposal from u.
Remove b from Pu.

(cid:46) b is matched with another user u(cid:48)
(cid:46) b ranks u(cid:48) higher than u

(cid:46) b is no longer a candidate for u

else

Unmatch b from u(cid:48) and add u(cid:48) back to SU
Match b and u and remove u from SU

end if

end if
end while
For each user u âˆˆ UM , sort user queue in descending order of deadline.

where SINRbu is calculated as deï¬ned in Eq. 2 with the
interference estimated using an exponential moving average
Ë†Iu and instantaneous interference ËœIu at time instant t âˆ’ 1 with
a learning parameter Î². The instantaneous interference ËœIu(t)
on a user u due to currently transmitting active users is given
by:

ËœIu(t) =

(cid:88)

bâˆˆB(cid:48)

pbGbu

T x(t)

Rx(t)Gbu
(cid:96)ub(t)

(4)

where B(cid:48) is the set of interfering base stations and (cid:96)ub is the
path loss, the interference is then estimated as Iu:
Iu(t) = Î² ËœIu(t âˆ’ 1) + (1 âˆ’ Î²) Ë†Iu(t âˆ’ 1)

(5)

Only users with non-empty queues enter the matching
procedure. For a network with B SBSs and U users, at each
transmission instant, at most B users can have an active
transmission. Once a stable matching is reached, the network
prioritizes each user queue according to their deadlines. Each
user queue can contain either or all of (1) predicted viewports,
with their deadlines being after the time horizon TH . (2)
sensory-based viewports, with real-time deadline. The latter
are admitted to into the queues in case of a false positive
prediction. This process is performed by the scheduler and is
outlined in Algorithm 1.

D. Caching

In order to estimate the spatial popularity proï¬le of any
video, we analyze the historical viewing data to rank the
viewports and deï¬ne the popularity of viewport vpf at frame
index f as the ratio of the users that requested viewport vpf
to the total number of users. The K most popular viewports
at each frame index are then cached at the edge cloud. This
number K is dependent on the storage capacity available at the
edge cloud and the viewport conï¬guration used, for example
a viewport in a 3x3 conï¬guration is 1.5 larger than a viewport
in a 5x5 conï¬guration.

IV. SIMULATION RESULTS

In this section, we evaluate the performance of the proposed
system on a public dataset collected from 59 users watching
seven 360Â° videos, each about 60 seconds long [21].

A. Machine Learning Training & Evaluation

A separate model is trained for each video and the training
and validation sets contain 80% and 20% of the traces respec-
tively. The models were trained using the Adam optimizer with
no weight decay and (Î²1 = 0.9, Î²2 = 0.999) for the running
averages coefï¬cients. The models were trained for 100 epochs
and a batch size of 32. This process is repeated using K-fold
cross validation (K = 5).

The models had a different performance proï¬le among
the different videos in the dataset. Overall, there is a rising
linear trend in error versus time horizon with the lowest error
achieved in â€˜Rollercoasterâ€˜ followed by â€˜Rhinoâ€˜ and â€˜Veniceâ€˜
whereas â€˜Timelapseâ€˜ had the highest error, as shown in Fig. 3.
The actual and predicted usersâ€™ orientations are then mapped
to the equivalent viewports to be used in the network simu-
lations. In this work, we consider the 3x3 and 5x5 viewport
conï¬guration as they provide a good trade-off between the
required storage space and overall viewport size.

B. Network Simulations

We consider a square VR arcade with 100m side length.
SBSs are located at the 4 corners of the arcade and users
are uniformly distributed throughout the arcade. The pathloss

Fig. 3: Aggregated Model performance for different videos for
time step = 10 frames.

                  W L P H  K R U L ] R Q      0 H D Q  $ Q J X O D U  ' L V W D Q F H  Â°  9 L G H R ' L Y L Q J ( O H S K D Q W 3 D U L V 5 K L Q R 5 R O O H U F R D V W H U 7 L P H O D S V H 9 H Q L F Hmodel follows the probabilistic model deï¬ned in Section II-B
and values are chosen according to 3GPP standard [22].
The pathloss (cid:96)ub(d) is recalculated every 100ms during the
simulation with LOS probability p(d) calculated as:

ï£±
ï£²

p(d) =

1.0
exp(âˆ’ dâˆ’5
70.8 )
211.7 ) Ã— 0.54
Table I provides the set of default parameter values used

d â‰¤ 5m
5m < d â‰¤ 49
d > 49m

exp(âˆ’ dâˆ’49

(6)

ï£³

for the simulations.

TABLE I: Simulation Parameters.

Parameter
Simulation time
Transmission slot duration
Bandwidth
mmWave Band
Rx beamwidth
Tx beamwidth
Noise spectral density
SBS transmit power
Users per video
Catalog size
Time step window
Prediction horizon
Frame duration
Backhaul latency
Cache size

Value
30 s
0.25 ms
0.85 GHz
28 GHz
45Â°
90Â°
-174 dBm/Hz
24 dBm
12
[3, 4, 5, 6] videos
10 frames
[5, 10, 15, 20, 25 ,30] frames
33 ms
3 ms
2 viewports per video frame

The following 4 schemes are considered for comparison:

â€¢ ML: Requests are proactively scheduled.
â€¢ ML (cache): Requests are proactively scheduled and pop-
ular viewports are cached at the edge cloud.
â€¢ NML: Requests are scheduled in real-time.
â€¢ NML (cache): Requests are scheduled in real-time and
popular viewports are cached at the edge cloud.

The performance of each scheme is evaluated through
average, and 99th percentile delay. Furthermore, transition
quality percentage, deï¬ned as the ratio of times HD frame
delivery failed and HMD had to downgrade to a lower quality
frame or interpolate previous frames to the total number of
frames, and the HD delivery rate and measured. The metrics
are averaged over all users.

a) Impact of Network Load: The effect of the network
load is analyzed by simulating the network under an increasing
number of users and videos. Fig. 4 shows that the proposed
schemes achieve lower latency and maintain close to 100% HD
rate up to 60 users. Furthermore, caching helps signiï¬cantly
reduce the rising slope of the 99th percentile delay, this is
observed in the different schemes, with more prominence in
non-ML schemes. Intuitively, for real-time requests, fetching
content from the remote cloud is on the critical path and any
speedup in fetching improves the overall latency. However, in
ML schemes and with the use of proactive scheduling, fetching
content is no longer on the critical path as the network has
TH frames to deliver the content.

b) Impact of Prediction Horizon: A longer prediction
horizon TH allows the scheduler more leeway in scheduling
future frames, however, the prediction error monotonically

increases with the prediction horizon, as discussed in Section
IV-A, resulting in more data to be transmitted in real-time.
Hence, the baseline methods remain constant as they do not
proactive schedule frames whereas in the proposed methods
the delay is affected by (1) the network load and ability to meet
the current demand and (2) the prediction error causing misses
and for frames to be scheduled in real-time. Fig. 5 shows the
performance using 72 users for a 3x3 viewport conï¬guration.
In this heavily loaded scenario, the delay exhibits a U-shaped
performance where the delay initially decreases due to having
more scheduling time, then increases again due to high miss
rate and the need to schedule more frames in real-time.

As such, even with non-perfect predictions,

the use of
proactive scheduling has signiï¬cantly improved the latency
and delivery rate. Proactive scheduling is especially useful in
ï¬‚uctuating channels; by transmitting viewports a few frames
in advance, a transient drop in usersâ€™ rate budget would not
result in an outage.

V. CONCLUSION
This paper has presented a solution for proactive VR
viewport streaming in wireless network. The proposed solution
minimizes latency and meets the high bandwidth and low
latency constraints by combining user orientation prediction,
caching, and proactive delivery of userâ€™s own viewport of the
360Â° video frame. Machine learning model based on recurrent
neural networks has been developed and has been shown to
predict user orientation at a future time horizon based on
previous motion history. Subsequently, Deferred Acceptance
matching algorithm has then been used to match users and base
stations with the preferences deï¬ned to minimize estimated
latency. The combination of prediction and matching for
proactive streaming is shown to signiï¬cantly minimize latency
and maximize delivery rate. Caching has been leveraged to
store popular video viewports in edge servers close to users
which is shown to minimize the latency, especially in real-time
requests.

REFERENCES

[1] S. Mandal, â€œBrief introduction of virtual reality & its challenges,â€
International Journal of Scientiï¬c & Engineering Research, vol. 4, no. 4,
pp. 304â€“309, 2013.

[2] M. S. Elbamby, C. Perfecto, M. Bennis, and K. Doppler, â€œToward low-
latency and ultra-reliable virtual reality,â€ IEEE Network, vol. 32, no. 2,
pp. 78â€“84, 2018.

[3] M. C. Potter, B. Wyble, C. E. Hagmann, and E. S. McCourt, â€œDetecting
meaning in RSVP at 13 ms per picture,â€ Attention, Perception, &
Psychophysics, vol. 76, no. 2, pp. 270â€“279, 2014.

[4] R. Albert, A. Patney, D. Luebke, and J. Kim, â€œLatency requirements
for foveated rendering in virtual reality,â€ ACM Transactions on Applied
Perception (TAP), vol. 14, no. 4, pp. 1â€“13, 2017.

[5] Y. Bao, H. Wu, T. Zhang, A. A. Ramli, and X. Liu, â€œShooting a moving
target: Motion-prediction-based transmission for 360-degree videos,â€ in
2016 IEEE International Conference on Big Data (Big Data), 2016, pp.
1161â€“1170.

[6] S. Petrangeli, G. Simon, and V. Swaminathan, â€œTrajectory-based view-
port prediction for 360-degree virtual reality videos,â€ in 2018 IEEE
International Conference on Artiï¬cial Intelligence and Virtual Reality
(AIVR).

IEEE, 2018, pp. 157â€“160.

[7] Y. Ban, L. Xie, Z. Xu, X. Zhang, Z. Guo, and Y. Wang, â€œCub360:
Exploiting cross-users behaviors for viewport prediction in 360 video
adaptive streaming,â€ in 2018 IEEE International Conference on Multi-
media and Expo (ICME).

IEEE, 2018, pp. 1â€“6.

(a)

(b)

(c)

(d)

Fig. 4: (a) Average delay, (b) 99th percentile delay, (c) HD delivery rate and (d) Quality transition versus the number of users
(with a ï¬xed number of 12 users per video) in a 5x5 viewport conï¬guration with TH = 10.

(a)

(b)

(c)

(d)

Fig. 5: (a) Average delay, (b) 99th percentile delay, (c) HD delivery rate and (d) Quality transition versus the prediction horizon
(in frames) in a 3x3 viewport conï¬guration for 72 users.

[8] M. Xu, Y. Song, J. Wang, M. Qiao, L. Huo, and Z. Wang, â€œPredicting
head movement in panoramic video: A deep reinforcement learning
approach,â€ IEEE transactions on pattern analysis and machine intel-
ligence, vol. 41, no. 11, pp. 2693â€“2708, 2018.

[9] C. Li, W. Zhang, Y. Liu, and Y. Wang, â€œVery long term ï¬eld of view
prediction for 360-degree video streaming,â€ in 2019 IEEE Conference
on Multimedia Information Processing and Retrieval (MIPR).
IEEE,
2019, pp. 297â€“302.

[10] M. F. R. RondÂ´on, L. Sassatelli, R. A. Pardo, and F. Precioso, â€œTrack:
a multi-modal deep architecture for head motion prediction in 360Â°
videos,â€ in 2020 IEEE International Conference on Image Processing
(ICIP).

IEEE, 2020, pp. 2586â€“2590.

[11] A. Nguyen, Z. Yan, and K. Nahrstedt, â€œYour attention is unique:
Detecting 360-degree video saliency in head-mounted display for head
movement prediction,â€ in Proceedings of the 26th ACM international
conference on Multimedia, 2018, pp. 1190â€“1198.

[12] F. Qian, B. Han, Q. Xiao, and V. Gopalakrishnan, â€œFlare: Practical
viewport-adaptive 360-degree video streaming for mobile devices,â€ in
Proceedings of the 24th Annual International Conference on Mobile
Computing and Networking, 2018, pp. 99â€“114.

[13] F. Qian, L. Ji, B. Han, and V. Gopalakrishnan, â€œOptimizing 360 video
delivery over cellular networks,â€ in Proceedings of the 5th Workshop
on All Things Cellular: Operations, Applications and Challenges, 2016,
pp. 1â€“6.

[14] Y. Bao, T. Zhang, A. Pande, H. Wu, and X. Liu, â€œMotion-prediction-
based multicast for 360-degree video transmissions,â€ in 2017 14th
Annual IEEE International Conference on Sensing, Communication, and
Networking (SECON).
IEEE, 2017, pp. 1â€“9.

[15] C. Perfecto, M. S. Elbamby, J. Del Ser, and M. Bennis, â€œTaming
the latency in multi-user VR 360Â°: A QoE-aware deep learning-aided
multicast framework,â€ IEEE Transactions on Communications, vol. 68,
no. 4, pp. 2491â€“2508, 2020.

[16] M. Chen, W. Saad, and C. Yin, â€œEcho-liquid state deep learning for 360Â°
content transmission and caching in wireless vr networks with cellular-
connected uavs,â€ IEEE Transactions on Communications, vol. 67, no. 9,
pp. 6386â€“6400, 2019.

[17] Y. Niu, Y. Li, D. Jin, L. Su, and A. V. Vasilakos, â€œA survey of millimeter
wave communications (mmWave) for 5g: opportunities and challenges,â€
Wireless networks, vol. 21, no. 8, pp. 2657â€“2676, 2015.

[18] L. Wei, R. Q. Hu, Y. Qian, and G. Wu, â€œKey elements to enable mil-
limeter wave communications for 5g wireless systems,â€ IEEE Wireless
Communications, vol. 21, no. 6, pp. 136â€“143, 2014.

[19] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, â€œEmpirical evaluation of
gated recurrent neural networks on sequence modeling,â€ arXiv preprint
arXiv:1412.3555, 2014.

[20] D. Gale and L. S. Shapley, â€œCollege admissions and the stability of
marriage,â€ The American Mathematical Monthly, vol. 69, no. 1, pp. 9â€“
15, 1962.

[21] X. Corbillon, F. De Simone, and G. Simon, â€œ360-degree video head
movement dataset,â€ in Proceedings of the 8th ACM on Multimedia
Systems Conference, ser. MMSysâ€™17. ACM, 2017, pp. 199â€“204.
[22] 3GPP, â€œ3rd generation partnership project; technical speciï¬cation group
radio access network; study on channel model for frequencies from 0.5
to 100 GHz,â€ Tech. Rep. 38.901 version 16.1.0 Release 16, 12 2020.

