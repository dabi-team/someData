2
2
0
2

n
u
J

1

]
I

N
.
s
c
[

1
v
7
1
3
0
0
.
6
0
2
2
:
v
i
X
r
a

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

1

Temporal Characterization of VR Trafﬁc for
Network Slicing Requirement Deﬁnition

Federico Chiariotti, Member, IEEE, Matteo Drago, Student Member, IEEE,
Paolo Testolina, Student Member, IEEE, Mattia Lecci, Student Member, IEEE,
Andrea Zanella, Senior Member, IEEE, and Michele Zorzi, Fellow, IEEE

Abstract—Over the past few years, the concept of VR has attracted increasing interest thanks to its extensive industrial and
commercial applications. Currently, the 3D models of the virtual scenes are generally stored in the VR visor itself, which operates as a
standalone device. However, applications that entail multi-party interactions will likely require the scene to be processed by an external
server and then streamed to the visors. However, the stringent Quality of Service (QoS) constraints imposed by VR’s interactive nature
require Network Slicing (NS) solutions, for which proﬁling the trafﬁc generated by the VR application is crucial. To this end, we collected
more than 4 hours of traces in a real setup and analyzed their temporal correlation. More speciﬁcally, we focused on the CBR encoding
mode, which should generate more predictable trafﬁc streams. From the collected data, we then distilled two prediction models for
future frame size, which can be instrumental in the design of dynamic resource allocation algorithms. Our results show that even the
state-of-the-art H.264 CBR mode can have signiﬁcant ﬂuctuations, which can impact the NS optimization. We then exploited the
proposed models to dynamically determine the Service Level Agreement (SLA) parameters in an NS scenario, providing service with
the required QoS while minimizing resource usage.

Index Terms—Virtual Reality, Extended Reality, Trafﬁc Modeling, Network Slicing, Resource Provisioning

(cid:70)

1 INTRODUCTION

O VER the past few years, the rapid technological de-

velopment of Head Mounted Devices (HMDs) and
the strong push towards the virtual world caused by the
COVID-19 pandemic led to an explosion of the eXtended
Reality (XR) market, which includes technologies such as
Virtual Reality (VR), Augmented Reality (AR), and Mixed
Reality (MR). Recent studies estimate hundreds of millions
of users of these technologies in a time span of just 3
years [1], requiring millions of new devices to be developed,
produced, and shipped around the world for a business in
the order of billions of dollars [2].

While the latest news on the metaverse seem to indi-
cate that the fastest growth will be in the entertainment
and social media industries, XR is expected to make an
impact in a wide variety of scenarios [3], [4]. Interactive
design, marketing, healthcare, and employee training are
just a few of the proposed use cases, but industrial remote
control in manufacturing and agriculture might have the
largest impact, allowing human operators to remotely con-
trol machines in risky, hard to reach or unsafe environments,
through a fully interactive virtual framework.

•

Federico Chiariotti (corresponding author, email: fchi@es.aau.dk) is with
the Department of Electronic Systems, Aalborg University, 9220 Aal-
borg, Denmark. Matteo Drago (dragomat@dei.unipd.it), Paolo Testolina
(testolina@dei.unipd.it), Mattia Lecci (leccimat@dei.unipd.it), Andrea
Zanella (zanella@dei.unipd.it), and Michele Zorzi (zorzi@dei.unipd.it) are
with the Department of Information Engineering, University of Padova,
35131 Padua, Italy.

• This work was partially supported by the National Institute of Standards
and Technology (NIST) under award no. 60NANB21D127 and by the In-
tellIoT project under the H2020 framework grant no. 957218. The work of
Mattia Lecci and Paolo Testolina was supported by Fondazione CaRiPaRo
under grant “Dottorati di Ricerca” 2018 and 2019, respectively.

A common characteristic of all these new applications
is their interactive nature: users do not passively receive
the information or stream a video, but need to manipulate
the environment while maintaining an illusion of presence
that requires the application to operate under very strict
end-to-end delay constraints [5], [6]. In particular, safety-
critical and industrial applications will have even stricter
constraints, as the consequences of network impairments
can be signiﬁcantly more serious. Cybersickness is another
important issue, as a delay over 20 ms between movements
and visual and auditory feedback can cause disorientation
and dizziness [1], [7].

In order to fulﬁll these stringent latency requirements
over a wireless connection, the application and the network
need to cooperate. The Network Slicing (NS) paradigm [8]
allows 5G and Beyond networks to reserve resources to a
given stream, deﬁning Quality of Service (QoS) targets. Most
works in this area, however, focus on relatively predictable
applications. In this setting, the need for predictability in
the XR trafﬁc becomes extremely important, leading to a
resurgence of quasi-Constant Bit Rate (CBR) encoders, which
are not used in non-interactive streaming due to their lower
picture quality stability. While some efforts have been de-
voted by prominent standard bodies on this topic [5], [6],
the current availability of trafﬁc models for XR is scarce.
Furthermore, to the best of our knowledge, no detailed anal-
ysis of the temporal statistics of quasi-CBR video streams can
be found in the literature, making existing slicing schemes
rely on uncertain foundations. This makes the deﬁnition
of a Service Level Agreement (SLA) for XR trafﬁc more
complex: most NS solutions assume that each application’s
demand in terms of required throughput and latency is
known, but such a characterization can be difﬁcult in case

 
 
 
 
 
 
THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

2

of streams with variable frame size, requiring signiﬁcant
overprovisioning.

However, even CBR encoders are not perfect, and the in-
terplay between the video content and the movements and
actions of the users may cause signiﬁcant ﬂuctuations. In
this work, we analyze the trafﬁc from a real VR application
using the Periodic-Intra Refresh mode of the H.264 codec,
which results in relatively small differences in the frame
sizes. Modeling these imperfections, and consequently pre-
dicting the size of future frames in advance, can be ex-
tremely signiﬁcant in the allocation of network resources,
particularly if some critical QoS metrics have to be reached.
For example, this is the case for Cloud XR, a new trend
pursued by some major players in the telecommunications
industry that moves the processing and rendering steps of
the XR content from the user to the Cloud, making the
QoS requirements even more critical [9], [10]. This increases
the need for a dynamic SLA that can allow an NS system
to provide low-latency service to XR applications without
wasting too many resources: as we mentioned above, a
static deﬁnition of the required throughput would require
signiﬁcant overprovisioning, while a temporal model of the
XR trafﬁc stream could allow to predict the future needs of
the application, tailoring the QoS requirements in the SLA
to what will actually be needed.

Hence, in this paper we address the problem of pro-
viding a realistic stochastic characterization of a VR traf-
ﬁc source, so as to allow for a dynamic provisioning of
bandwidth resources for VR users to satisfy the latency con-
straints. Our analysis can also be applied to the downlink
part of generic XR trafﬁc.

Building upon our previous works [11], [12], in which we
collected more than 4 hours of live sessions and performed
in this paper we take the
basic trafﬁc characterization,
analysis one step further by modeling the size of VR frames
in the stream as a correlated time series that is then used to
derive an adaptive and predictive SLA. The contributions of
this paper are the following:

• We propose two parametric regression models to
predict the size of future frames, and show that
these models can be generalized to other traces and
even different applications with limited regression
performance loss;

• We analyze the residual error of these predictors,
providing a full statistical model of future frame
sizes;

• We show that the prediction can be successfully used
for efﬁcient resource allocation in an NS scenario;
• We consider different NS modes, including per-user
or application-level slicing, and compare the perfor-
mance of different schemes in terms of the trade-off
between resource utilization and latency.

A partial version of this work was presented in [13]. This
work signiﬁcantly extends it by exploring the statistical
analysis of frame sizes at a deeper level, including the
characterization of the residual error of the predictors, and
expanding on the SLA deﬁnition, including the use case
with multiple VR users. All our traces, as well as the analysis

and simulation code, are publicly available.1

The rest of the paper is structured as follows. Sec. 2 will
discuss the current state of the art on XR modeling, and
our experimental setup is brieﬂy presented in Sec. 3. Our
analysis is reported in Sec. 4, while Sec. 5 illustrates how
our analysis can be leveraged for a simple NS use case by
designing predictive resource allocation mechanisms and
testing their performance in a simple simulation scenario.
Finally, Sec. 7 draws conclusions and presents some avenues
for future work.

2 STATE OF THE ART

Despite a steady scientiﬁc interest in VR since the 1990s [14],
relatively little work has been done to characterize the
details of this type of trafﬁc. We can distinguish four main
areas of research: the reduction of the Motion-To-Photon
(MTP) latency, the modeling and characterization of XR
trafﬁc, the use of trafﬁc models in NS, and the scheduling
and resource management of XR data streams.

2.1 Motion-To-Photon latency and VR sickness

The MTP latency is deﬁned as the time difference between
the beginning of a movement of the user’s head and the
instant when the image that corresponds to the user motion
is shown on the HMD screen. This phenomenon is one of
the main factors causing sickness when experiencing XR
content, the main symptoms being discomfort, nausea, cold
sweating, eye fatigue, and disorientation.

From a research point of view, a lot of effort has been
devoted to avoiding such episodes in the ﬁrst place, and
the IEEE issued a dedicated standard in 2021 [15], which
addressed the content design, sickness assessment and mea-
surement, and the network requirements that may inﬂuence
the MTP latency as the three main areas to consider in order
to reduce or control bad user experience.

First of all, measuring the MTP latency represents a
challenge per se. The architecture described in [16], which
consists of a control PC, a head position model-based rotary
platform, a pixel luminance change detector which converts
the change in the display into a voltage value, and a digital
oscilloscope to show such voltage information, is used as
reference in [15]. Speciﬁcally, after a movement of the rotary
platform is generated by the control PC, the MTP latency
is measured as the time difference between the platform’s
movement and the corresponding change of the voltage
value given by the oscilloscope.

To obtain a robust estimate of the MTP latency, a precise
head tracking algorithm is of the utmost importance. The
authors of [17] presented a 6 Degrees of Freedom (6DoF),
optical head tracking instrument with a declared motion-to-
pose latency (i.e., the time between a change in the users
pose and the tracker actually detecting the movement) of
about 28 µs, at a sample rate of 50 kHz. In their work,
they also showed that the difference between the tracker’s
pose output and the user’s true pose is proportional to pose
velocity, tracker sampling rate, tracking latency, and noise.
Moreover, the authors of [18] showed that latency jitter

1. Code

repository:

https://github.com/signetlabdei/vr-trace-

analysis

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

3

artifacts already occur with a low system load by injecting
artiﬁcial latency in a VR simulation. Even though their
hypothesis included the tracking algorithm of the speciﬁc
HMD as the possible cause of such jitter spikes, they did
not prove it empirically.

Both rotational and translational MTP latencies were
estimated in [19] by calculating the phase shift between
the captured signals of the physical motion of the HMD
and a motion-dependent gradient stimulus rendered on
the display. They were able to conclude that rapid head
movements may elicit stronger disorientation to users in
VR environments than slower head movements do. Even
though the measurements were carried out with an Oculus
Rift DK2, the proposed methodology is general and can be
applied to other HMDs as well. The authors of [20] also
measured the MTP latency with different workloads (deter-
mined by the complexity of the scene to render), ﬁnding
that it can span from a minimum of 45 ms to a maximum of
155 ms. In general, the network requirements deﬁned by the
standard [15] are way more stringent: approximately 5 ms
for the wireless transmission and 20 ms in total for the MTP
latency, with a jitter strictly lower than 5 ms.

2.2 XR Trafﬁc Characterization

XR trafﬁc modeling is closely related to 2D video content,
and, even more so, to live, interactive applications such
as video conferencing and gaming. However, most of the
work on the subject has considered the customary encoding
schemes for pre-recorded video streaming, i.e., the Variable
Bit Rate (VBR) encoding based on either the H.264 or the
H.265 standard [21]. VBR can provide a stable visual quality,
improving the user’s Quality of Experience (QoE), but is
also subject to signiﬁcant jitter due to the large frame size
ﬂuctuations. Transmitting VBR videos with low latency can
then be a signiﬁcant challenge even over channels with
constant capacity [22]. On the other hand, CBR encoding
sacriﬁces some visual quality stability to obtain an encoded
video stream with a stable transmission rate [23]. Although
the higher predictability of the encoded output makes CBR
encoding attractive for interactive video and XR content, it
is still relatively unexplored in the relevant literature.

A topic related to XR trafﬁc is video game streaming, also
called Cloud gaming. Games run on remote servers and the
scenes are streamed directly to the users without the need
for client-side computation. The stringent requirements of
gaming applications, especially in terms of latency, and the
need to address them with optimized protocols and new
transmission strategies, have led to an increased interest in
their characterization.

The authors of [24] carried out an extensive measure-
ment campaign in Google Stadia, a popular Cloud gaming
platform, giving an overview of its inner working. They
studied the distributions of downlink trafﬁc, packet size
and inter-packet time under multiple settings, including
different resolutions, video codecs, and network conditions.
On the other hand, in [25], [26] direct comparisons were
made between different Cloud gaming platforms, mostly
focusing only on the bit rate of the video stream, without
including latencies or user experience.

A more comprehensive Cloud gaming testbed, including
automated trace acquisition over Ethernet, WiFi, and LTE,

was presented in [27]. Automating the acquisitions surely
gives an advantage in terms of reproducibility and speed
of the experiments, but the unpredictability of the users’
actions in gaming scenarios (and, more importantly, in XR)
is the real challenge that the network has to face, limiting
the usefulness of the results. These works represent a good
starting point for the collection and modeling of VR trafﬁc,
as it is reasonable to assume that most of these Cloud
gaming companies will start providing VR services soon.
However, most works still focused on simple applications,
such as interactive data visualization [28], and do not pro-
vide much insight on more complex scenarios. There is an
extensive literature on immersive video streaming [29], but
it has been mostly focused on passive applications in which
the user is only a viewer, with different QoE and encoding
considerations. A recent document by the 3GPP [30] also
provided a simple model for XR trafﬁc, which however does
not consider temporal or video content aspects, and is thus
usable for general feasibility studies, but not for ﬁne-grained
optimization.

2.3 Prediction-Based Slicing

The use of trafﬁc prediction in NS is a concept that was ﬁrst
explored in [31]: as slicing requires precise SLAs to provide
QoS to different services, but most practical applications
are VBR, characterizing the trafﬁc and predicting future
requests is a way to allocate resources in a foresighted
manner, performing resource allocation on a short timescale
and admission control on a longer one. If we consider
wider networks with massive numbers of users, the daily,
weekly, and seasonal cycles of network usage can also be
exploited to allocate resources more effectively [32]. This
work, however, will focus on shorter-term predictions over
a limited number of XR ﬂows. Other works such as [33]
have also explored the possibility of exploiting longer-term
trends for a rough resource allocation, while using a short-
term scheduler for ﬁne-grained optimization.

In particular, the use of Auto-Regressive Moving Av-
erage (ARMA) models has been explored in [34] as a po-
tential application-agnostic prediction method to perform
resource allocation: as the orchestrator knows the state of
the packet buffer for each slice, it can perform the mov-
ing average and allocate resources accordingly. However,
ARMA models require a certain number of past samples,
and this approach cannot discriminate between different
applications: consequently, the initial performance will be
lower when compared to an application-aware model that
takes knowledge of the trafﬁc source into account. In order
to capture the behavior of more complex trafﬁc sources, it is
also possible to replace the ARMA model with a Long Short-
Term Memory (LSTM) deep neural network [35], which
can generalize to non-linear and longer-term patterns. Deep
reinforcement learning [36] is another alternative, as it can
implicitly learn even complex application behaviors and
take them into account when slicing.

Another recent idea is to combine NS with video bit
rate adaptation: if we consider QoE as a ﬂexible metric over
which we can compromise in high trafﬁc conditions, a cross-
layer approach allows the orchestrator to dictate the video
bit rate for the next few frames [37], limiting the demands

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

4

of the interactive video ﬂow to what the network is able to
support. This approach is complementary to the prediction-
based one, as these bit rate changes need to be relatively
infrequent to avoid annoying the user, and such a system
would operate over a longer timescale: while the prediction
and allocation of resources is usually performed over tens
or hundreds of milliseconds, video bit rate adaptation spans
multiple seconds, and the two approaches can be integrated.

2.4 XR Resource Management

Although the management of XR ﬂows is a relatively new
problem, a few works have already discussed efﬁcient
schemes for providing QoS to these applications. For ex-
ample, in [38], [39] game-theoretic approaches are proposed
to tackle the optimization of multi-user VR streaming over
a small cell, with the help of machine learning. The authors
of [40] analyze the scheduling problem from the perspective
of Mobile Edge Cloud (MEC), proposing scheduling strate-
gies and analyzing communication, computing, and caching
trade-offs. While the models proposed for the network
architectures considered in these works are extremely com-
plex, there is no comparison with real-world VR streaming.
To the best of our knowledge, our previous works, which
proposed a simple architecture for collecting trafﬁc traces
from VR games [11] and a simple generative model for the
frame size [12], were the ﬁrst to use real VR trafﬁc traces.
This paper extends our previous works by characterizing
the temporal behavior of the VR traces and drawing novel
conclusions for NS optimization.

3 VR STREAMING ARCHITECTURE
In this section, we describe the architecture of our VR
streaming acquisition and give some perspective on the
full end-to-end setup. To further understand what are the
steps that most inﬂuence the VR performance, it is useful
to describe a common end-to-end VR architecture. First,
we can start from the collection and processing of tracking
information, delegated to the HMD. Then, this information
is sent to a remote server to compose the viewport, i.e.,
what is actually shown to the user. This process includes
the rendering of the scene, the video encoding providing a
more robust transmission towards the mobile device, and
possibly some additional information, e.g., the direction in
which the rendered frame is supposed to be displayed.
After receiving and decoding the video stream together with
all the additional meta-information, the HMD generates
the images to display at the occurring screen refresh rate.
These steps need to be accomplished with minimal delay to
guarantee adequate QoE.

Our experimental setup consisted of a desktop computer
equipped with an NVIDIA GeForce RTX 2080 Ti graphics
card acting as the rendering server, and an iPhone XS
enclosed in a VR cardboard acting as the HMD. VR applica-
tions were thus run on the rendering server and streamed to
the headset using the RiftCat 2.0 application (on the server),
and VRidge 2.7.7 (on the phone).2

The application uses hardware-accelerated H.264 encod-
ing via Nvidia Encoder (NVENC) as long as a compatible

2. https://riftcat.com/vridge

graphics card is available to the system. RiftCat’s developers
disclosed that Periodic Intra-Refresh is used, a setting pro-
vided by the encoder that allows each frame to be roughly
the same size, making the stream almost CBR and thus
easier to handle from a network perspective. It does so by
replacing key frames with waves of refreshed intra-coded
blocks, i.e., blocks without any dependence on other frames,
effectively spreading a key frame over multiple frames.
Image quality is balanced with resilience to packet loss
by setting the intraRefreshPeriod, a parameter that
determines the period after which an intra refresh happens
again, and the intraRefreshCnt parameter, which sets
the number of frames over which the intra refresh hap-
pens [41]. If we consider a 30 Frames per Second (FPS)
video, a value of 30 for the intraRefreshPeriod would
ensure that the frame is fully recovered every second. On the
other hand, choosing small values of intraRefreshCnt
leads to a quicker refresh but lower quality.

Detailed information about the video encoder is fun-
damental for our work, since different encoders typically
behave differently, especially when analyzing the temporal
behavior of the encoded source. Still, we believe that our
work offers network researchers a peek into the intricacies
of this topic, showing some key results on how a VR trafﬁc
ﬂow can be analyzed for resource provisioning.

Different freely available games and applications were
used to acquire our dataset, including Minecraft, Virus Pop-
per, and Google Earth VR. Further details on the acquisition
setup and our traces can be found in [12]. In the following,
we will mostly concentrate on one trace acquired using
the Virus Popper application, but the methodology holds
throughout the dataset, and can be easily replicated for any
of the other traces.

4 VIDEO TRACE ANALYSIS

By analyzing the acquired traces, we determined that the
application used User Datagram Protocol (UDP) over IPv4.
It also used an additional application-layer protocol header
of variable size, which we decoded to determine the types
of the exchanged packets. More speciﬁcally, synchroniza-
tion and acknowledgment packets were exchanged in both
directions, while the Uplink (UL) stream from the HMD
to the rendering server also contained frequent and rela-
tively small head-tracking information packets. Naturally,
the Downlink (DL) stream also had regular video frame
packet bursts.

Fig. 1 is a visual representation of a short period of
bidirectional VR streaming, showing the main data streams
in both DL and UL. As the ﬁgure clearly shows, most of
the trafﬁc is concentrated in DL and consists of packet
bursts encoding video frames. Video frame fragments were
consistently found to be 1320 B long in all acquired traces,
with a data size (the UDP payload) of 1278 B.

First, we considered the head tracking packets in the UL,
which were all 192 B long. The distribution of the inter-
packet interval ∆u is shown in Fig. 2: tracking packets are
relatively frequent, with a median interval of about 7 ms,
but the distribution has a long tail. This suggests that head-
tracking packets are usually sent at regular intervals, but
some are transmitted adaptively if there were signiﬁcant

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

5

Video Frame (DL)

Frame Feedback (DL)

Frame Feedback (UL)

Head Tracking (UL)

1 500

1 000

500

]
B
[

e
z
i
s

t
e
k
c
a
P

0

0

1 500

1 000

500

0

10.6

10.8

11

11.2

10

20

30

40

50

60

70

80

90

100

Time [ms]

Fig. 1: Portion of trafﬁc trace from Virus Popper (50 Mb/s, 30 FPS). In this trace, each video frame burst consists in about
130–140 individual fragments.

1

0.8

0.6

0.4

0.2

F
D
C

l
a
c
i
r
i
p
m
E

0
10−1

S = 1

S = 5

S = 30

S = 120

S = 300

Ideal CBR

F
D
C

l
a
c
i
r
i
p
m
E

1

0.8

0.6

0.4

0.2

0

100

101

∆u (ms)

102

103

0

10

20

30

40

50

Rate (Mb/s)

Fig. 2: Head tracking packet inter-arrival time.

Fig. 3: Rate distribution for different MA window sizes S
[number of frames].

headset movements that can affect the video rendering on
the HMD. As we did not manage to decode the content of
the tracking packets, a deeper analysis of their relation to
head movements is left as future work.

By decoding the application protocol, we managed to
identify frame boundaries and sort out the video data
frames from metadata and control information. We can then
consider the size of individual frames in a video trace.
We note that non-video packets have a low impact on the
total streaming data rate. Considering this, as well as the
strong dependence of metadata on the application setup, we
decided to focus mostly on the video frame data, discarding
all other packets from our analysis. Our results can then be
applied to any VR application using the same encoder.

The encoder uses the H.264 Periodic Intra-Refresh com-
pression scheme to reduce the variation between frame
sizes, so we do not expect a multimodal distribution, as
would be the case for a classical keyframe-based encoding.
As we mentioned above, encoding VR trafﬁc as CBR offers a
signiﬁcant advantage for the network optimization, because
frames of constant size make it possible for NS schemes to
provide a guaranteed latency without wasting resources.

However, CBR encoding is not perfect, and frames may
still have variable size, although the average rate almost
perfectly matches the required one. We can use a simple
Moving Average (MA) ﬁlter with a rectangular window S
to examine the behavior of the trafﬁc on longer timescales,
which is useful if resource allocation is performed at a
slower pace. Naturally, allocating resources every S frames

leads to a larger jitter between frames, but it can also im-
prove the resource allocation efﬁciency, as size ﬂuctuations
tend to average out over multiple frames.

In order to measure this effect, we consider the Virus
Popper trace, with a required rate R = 30 Mb/s and a
ϕ = 60 FPS refresh rate. We only measure the video traf-
ﬁc, without packet headers and redundancy added by the
application, which results in an average rate of 29.76 Mb/s.
Fig. 3 shows the empirical Cumulative Distribution Func-
tion (CDF) of the rate, considering different values of the
MA window sizes. If we consider each frame individually,
there is a signiﬁcant variation in the rate, which gradually
reduces as we increase the number of frames over which the
rate is measured.

However, providing reliable service will require a signif-
icant overhead even if we relax the slicing time: Fig. 4 shows
the overﬂow rate, i.e., the difference between the actual rate
and the expected 30 Mb/s CBR rate, as a function of the
MA window sizes. The plot shows the standard deviation,
as well as the 95th and 99th percentile overﬂow rates. If our
aim is to provide 99% reliability, we need to overprovision
by more than 8 Mb/s (i.e., almost 30% of the CBR rate)
even if we consider a timescale of 100 ms for resource
allocation, i.e., 6 frames. Even averaging over periods of
multiple seconds leads to worst-case rates almost 4 Mb/s
higher than the target, probably because of highly dynamic
content in the video. Interestingly, the overﬂow standard
deviation is approximately constant if the MA window

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

6

0

1

2

3

4

5

0

200

400

600

800

1 000

Window (s)

Lag (ms)

)
s
/
b
M

(

e
t
a
R
w
o
ﬂ
r
e
v
O

10

5

0

Standard deviation

95th percentile overﬂow

99th percentile overﬂow

)
s
(

e
m
T

i

0
60
120
180
240
300
360
420
480
540

1
0.75
0.50
0.25
0
−0.25
−0.50
−0.75
−1

0

50

100

150

200

250

300

0

5

10 15 20 25 30 35 40 45 50 55 60

MA window size S (frames)

Lag (frames)

Fig. 4: Overﬂow rate for a target CBR of 30 Mb/s.

Fig. 6: Rolling windowed ∆F autocorrelation for Virus
Popper (30 Mb/s, 60 FPS). The windows were 600 frames
(10 s) long, with a time shift of 60 frames (1 s).

Lag (ms)

4.1 Frame Size Prediction

200

400

600

800

Autocorr. of F (t)

Autocorr. of ∆F (t)

0

1

n
o
i
t
a
l
e
r
r
o
c
o
t
u
A

0.5

0

−0.5

0

10

20

30

40

50

Lag (frames)

Fig. 5: Video frame size autocorrelation for Virus Popper
(30 Mb/s, 60 FPS).

is longer than 50 frames, while the higher percentiles of
the overﬂow continue to decay: this suggests that higher
throughput periods tend to be shorter and more frequent,
while there are longer periods of time with a bit rate below
the average. Fig. 3 also hints at a skew in the distribution, as
the left tail of the frame size empirical CDF is much longer.

Finally, we can analyze the autocorrelation of the frame
size sequence F (t), to identify patterns in how the se-
quence changes. Fig. 5 shows the autocorrelation of F (t)
and ∆F (t) = F (t) − F (t − 1). While F (t) has a strong
long-term autocorrelation, due to the constant component,
the ∆F (t) sequence has a strong negative autocorrelation
between one frame and the next, while almost all longer
time differences fall within the ±0.05 range. This means that
the encoder tends to balance out ﬂuctuations between one
frame and the next, such that a frame that is bigger than the
previous one tends to be followed by a smaller one again.
We can check that this holds throughout the whole video
by computing a rolling window autocorrelation, shown in
Fig. 6 for ∆F (t). In this case, the plot clearly shows that
there are no strong long-term correlations in any part of
the video. The frame difference sequence has a noticeable
and consistent autocorrelation only with lags 1, 3, and 5,
conﬁrming the result from Fig. 5.

Let us consider the average size of future frames in the time
interval [t, t + T ), given by

FT (t) =

1
T

T −1
(cid:88)

F (t + i).

(1)

i=0
We denote by ˆFT (t, τ ) an estimate of FT (t + τ ), τ > 0, i.e.,
considering a look-ahead of τ frames. We focus on linear
predictors based on the last N ≥ 0 samples, so that

ˆFT (t, τ ) = θ0 +

N
(cid:88)

j=1

θjF (t − j + 1),

(2)

where θ = [θ0, . . . , θN ] is a weight vector, which determines
the accuracy of the estimate. If N = 0, the estimate is just
given by the parameter θ0, and does not consider any past
frames. The difference between actual and estimated value
is captured by the error term w(t, τ, T ) = FT (t + τ ) −
ˆFT (t, τ ), which will be denoted just as w in the following,
for ease of writing. We can then consider two regression
methods to determine the value of the parameter vector θ:

• Ordinary Least Squares (OLS) linear regression: least
squares regression was independently developed by
Gauss and Legendre in the 19th century [42], and is
the most classic form of regression. In this case, the
objective is to minimize the (cid:96)2 norm of the sequence
w. OLS regression can be useful in determining the
average behavior of the underlying stochastic pro-
cess, giving easily interpretable results on the quality
of the prediction and the dynamics of the frame size
over time;

• Quantile regression [43]:

this technique estimates
ˆFT (t, τ ) so that the probability that it is higher than
the real value, is not larger than ps. This has obvious
implications for network resource provisioning: as
we are interested in providing enough resources
to send a frame within the required latency with
probability ps, estimating the corresponding quantile
might be the best way to get the required quality.

We also used Robust linear regression [44] to verify that the
OLS prediction was not too sensitive to outliers. We consid-
ered a robust method using Huber’s T norm instead of the

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

7

N = 0

N = 1

N = 2

N = 4

N = 6

F
D
C
C

F
D
C
C

100

10−1

10−2

10−3

100

10−1

10−2

10−3

F
D
C
C

100

10−1

10−2

10−3

−20 −10

0

10

20

30

40

−20 −10

0

10

20

30

40

Residual error w (kB)

Residual error w (kB)

(a) OLS regression, T = 1.

(b) Quantile regression (ps = 0.95), T = 1.

F
D
C
C

100

10−1

10−2

10−3

−20 −10

0

10

20

30

40

−20 −10

0

10

20

30

40

Residual error w (kB)

Residual error w (kB)

(c) OLS regression, T = 6.

(d) Quantile regression (ps = 0.95), T = 6.

Fig. 7: Complementary CDF of the error w with τ = 1 and different values of N and T .

(cid:96)2 norm: the two norms have the same quadratic behavior
if the error is smaller than a threshold δ, but Huber’s T
increases linearly for larger values. Setting the threshold to
δ =
, we found that the results matched exactly those
of the OLS model, suggesting that outliers are not playing
a relevant role in this case and thus letting us discard this
model.

E[|F |]
4

In this section, we will show results for both the OLS
and the quantile regression models. As we stated above,
while the results from OLS are more immediate, quantile
regression is useful when focusing on scheduling network
resources for a VR stream, which requires a model of the tail
of the frame size distribution to provide latency guarantees.
We can now examine the results of the regression analy-
sis for the Virus Popper trace, considering a rate of 30 Mb/s
and 60 FPS. We focus on this video trace as the standard
example in the paper, but other traces, even at different
bit rates and frame rates, exhibit a similar behavior. Fig. 7
shows the complementary CDF of the residual error w,
considering τ = 1 and two different values of the averaging
interval T . The ﬁrst thing we can notice is that the error
distribution has a slightly different shape for the OLS and
quantile regression models, indicating that the difference in
the two models is not simply a shift in the value of the
intercept θ0, but instead the two predictions are inherently
different. We can also notice that there is some beneﬁt
from having a longer memory, although increasing N yields
diminishing returns in terms of increased accuracy. Finally,
we can conﬁrm that the reliable transmission of this VR
content will require signiﬁcant overprovisioning, even when
using prediction: for T = 1 the 95th percentile error of the
OLS prediction is approximately 15 kB higher than the mean
with any of the models, i.e., about 25% of the average frame
size (which is 62.5 kB for this trace). In fact, this is close to
the difference between the average predictions of the OLS
and the quantile models.

This difference is about halved for T = 6, due to the

fact that computing the average over multiple frames allows
errors to compensate and cancel each other out. However,
provisioning over multiple frames means that only the
average amount of resources will be assigned to the stream,
which will cause larger frames to have a higher latency, thus
causing additional queuing delay to subsequent frames.
Since the frame cannot be properly shown on screen until it
is fully received, this translates to a higher jitter and reduces
the QoE perceived by the user, making a lower value of T
preferable.

Another fundamental component in evaluating the qual-
ity of a predictor is the autocorrelation of the residual error
w: if the autocorrelation between subsequent samples of the
residual error is high, the model did not capture some effect,
usually due to an insufﬁcient memory, i.e., too low a value
of N . Fig. 8 shows the autocorrelation of w for different
values of N : it is easy to see that models with N < 4,
and particularly with N = 0 and N = 1, do not have
enough memory to capture the frame size dynamics. This is
more evident in quantile regression, which shows a higher
autocorrelation for these models.

Finally, we can examine the effect of N and τ on the
quality of the prediction by looking at Fig. 9, which shows
the standard deviation of the residual error w as a function
of these two parameters with T = 1. The ﬁgure clearly
shows that increasing the memory of the model improves
the prediction, but gives diminishing returns, as the differ-
ence between N = 6 and N = 10 is minimal. Furthermore,
we see an expected increase of the error if τ increases, but
this is not monotonic for N < 3: this might be due to the
autocorrelation we observed in the w sequence, as N < 3
is not sufﬁcient to fully represent the state of the stochastic
process, resulting in suboptimal predictions.

4.2 Residual Error Characterization
We can then analyze the residual error w in more detail: as
Fig. 10 shows, we attempted to ﬁt the residual error on the

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

8

N = 0

N = 1

N = 2

N = 4

N = 6

Lag (ms)

Lag (ms)

0

100

200

300

0

100

200

300

1

0.5

0

n
o
i
t
a
l
e
r
r
o
c
o
t
u
A

n
o
i
t
a
l
e
r
r
o
c
o
t
u
A

1

0.5

0

0

5

10

15

20

0

5

10

15

20

Lag (frames)

(a) OLS regression.

Lag (frames)

(b) Quantile regression (ps = 0.95).

Fig. 8: Autocorrelation of the residual error w for next-frame prediction (T = 1, τ = 1) for different values of N .

OLS

Quantile

the shape parameter b is then given in [45] by:

10

8

6

4

2

τ

10

8

6

4

2

τ

0

5

N

10

0

10

5

N

10.5

10

9.5

9

8.5

)
B
k
(

w
σ

Fig. 9: Heatmap of the residual error standard deviation
(measured in kB) as a function of N and τ , with T = 1.

0.1

8 · 10−2

6 · 10−2

4 · 10−2

2 · 10−2

F
D
P

0

−40

Data

Gaussian

Student T

Cauchy

Laplace

−20

0

20

40

Residual error w (kB)

ˆb =

1
N

N
(cid:88)

|xi − ˆµ|.

(4)

i=1
The instantaneous value ˆbT (t, τ ) can then be determined
from the model. As we are considering a regression model,
in which previous frame sizes affect the distribution of
future frames, we can simply perform an OLS regression on
the absolute value of the residual error |w| to ﬁnd ˆbT (t, τ ).
We can then represent the future frame size as a value
ˆFT (t, τ ) given by the prediction plus a noise term w, whose
distribution is Laplace( ˆFT (t, τ ), ˆbT (t, τ )). Interestingly, if
we adopt this model, we have the complete distribution
of the frame size, making it extremely easy to derive the
quantile values for any desired point and considerably
reducing the computational impact with respect to multiple
quantile regressions. The quantile function P −1(ps|T, τ, t) is
given by:
P −1(ps|T, τ, t) = ˆFT (t, τ ) + ˆbT (t, τ ) log(min(2ps, 2 − 2ps)).
(5)

Fig. 10: Residual error after OLS prediction for Virus Popper
(30 Mb/s, 60 FPS), with T = 1, τ = 1, and N = 6.

frame size to various common bilateral distributions, and
the maximum likelihood ﬁt was given by the Laplace(µ, b)
distribution, whose Probability Density Function (PDF) is
given by:

pw(x; µ, b) =

e− |x−µ|

b

,

1
2b

(3)

where µ is the location parameter and b is the shape param-
eter. The same result held for all other traces in the dataset,
leading us to infer that this distribution depends on some
inherent property of the encoder and the way it generates
frames, instead of speciﬁc features in the video content.

If we consider the residual error of the OLS regression
method, the best estimate of the parameter µ is ˆµ = 0, as
having a non zero-mean residual error would imply a bias
in the OLS estimator. The maximum likelihood estimator of

4.3 Model Generalization

In the above, we studied how well regression models can
predict future frame sizes ˆFT (t, τ ), but we always found
the parameter vector θ based on the same video trace. In
the following, we study how prediction models perform
when the regression is performed over multiple traces, with
different bit rates and types of content. This has signiﬁcant
advantages, as ﬁnding a predictor for each speciﬁc video
content requires acquiring traces for each content and qual-
ity level, while generalizing the predictor would allow for
simpler deployment.

We consider N = 6 and τ = 1, as we determined that
N = 6 is sufﬁcient to capture the dynamics of the model.
In order to directly compare traces with different bit rates
R and frame rates ϕ, we normalize the video traces by the
expected frame size ϕ−1R, obtaining a normalized param-
eter vector ˜θ, which, given the linearity of our models, can
be converted back to the original parameter vector in (1) as
θ = R ˜θ
ϕ . By normalizing our frame sizes, we can train and
use our models on multiple traces with different values of
R and ϕ. We then consider three generalized models:

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

9

General model

Content-dependent model

Content- and rate-dependent model

Video content

Video content

Minecraft

Cities

Tour

Virus popper

Minecraft

Cities

Tour

Virus popper

r
o
r
r
e

e
v
i
t
a
l
e
R

0.5

0.25

0

−0.25

−0.5

−0.75

−1

r
o
r
r
e

e
v
i
t
a
l
e
R

0.5

0.25

0

−0.25

−0.5

−0.75

−1

r
o
r
r
e

e
v
i
t
a
l
e
R

0.5

0.25

0

−0.25

−0.5

−0.75

−1

10

30

50

20

40

10

30

50

20

40

10

30

50

20

40

10

30

50

20

40

Rate (Mb/s)

Rate (Mb/s)

(a) OLS regression, T = 1.

(b) Quantile regression (ps = 0.95), T = 1.

Video content

Video content

Minecraft

Cities

Tour

Virus popper

Minecraft

Cities

Tour

Virus popper

r
o
r
r
e

e
v
i
t
a
l
e
R

0.5

0.25

0

−0.25

−0.5

−0.75

−1

10

30

50

20

40

10

30

50

20

40

10

30

50

20

40

10

30

50

20

40

Rate (Mb/s)

Rate (Mb/s)

(c) OLS regression, T = 6.

(d) Quantile regression (ps = 0.95), T = 6.

Fig. 11: Boxplot of the relative residual error ϕw
grouped by video content, and each group of boxplots shows the error at different bit rates for that video content.

R for different levels of generalization with N = 6 and τ = 1. The traces are

1) A general model (GM), which computes θ using the
whole dataset, with different frame rates, bit rates,
and video content types;

2) A content-dependent model (CM), which computes θ
using a single type of content (e.g., the Virus Popper
game), but with different bit rates and frame rates;
3) A content- and rate-dependent model (CRM), which
derives the parameter vector on a per-content, frame
rate, and bit rate basis, i.e., a single trace.

Given that different values of R and ϕ can have different
scales of errors which can be difﬁcult to compare directly, in
Fig. 11 we show the error normalized to the expected frame
size R/ϕ. As the ﬁgure shows, the model can generalize
quite well: the performance of CM is almost always similar
to that obtained by CRM, making generalization across
different bit rates and frame rates possible for the same
video content. On the other hand, GM performs slightly
worse, and has a large error in the Minecraft trace with
R = 40 Mb/s: it is possible that this trace involves different
dynamics in the content or head movements, leading to
sharp differences even with other traces with the same type
of content. On the other hand, GM has similar performance
to CM and CRM with the OLS predictor, but shows a less
consistent behavior for the quantile regressor. For example,
the Minecraft trace with R = 40 Mb/s shows very different
performance between the three models and different values
of T . Furthermore, the Virus Popper trace seems to have a

smaller tail, as GM is more conservative than the models
based only on that video content.

As we can see, using the quantile model leads to a
prediction between 25% and 40% higher than the average,
skewing the error distribution. We should also further high-
light that averaging over multiple frames can also signiﬁ-
cantly reduce the error across almost all traces.

5 PREDICTIVE NETWORK SLICING

In this section, we consider an NS use case for the models
we developed in Sec. 4. We assume that a number M of
VR clients are assigned to a high-priority slice, with the
objective of allowing each frame to be delivered before the
generation of the next one, i.e., maintaining a latency below
1/60th of a second. Provisioning the time and frequency
resources for VR is a critical component of Beyond 5G
networks, and guaranteeing limited latency while reducing
the impact on other users is an important application of our
model. Each client m then has a different bit rate Rm and,
potentially, a different application, but we assume that the
clients all share the same frame rate ϕ. Furthermore, each
client m has a different spectral efﬁciency ηm, depending
on its connection’s Signal-to-Noise Ratio (SNR): users closer
to the base station will have a stronger signal, and conse-
quently, a higher transmission efﬁciency.

With a small loss of generality, we assume that clients are
synchronized, i.e., frames are generated at the same time.

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

10

The orchestration can be adapted relatively easily to the
more general case, but the notation would be much more
cumbersome, and we maintain this simplifying assumption
for the sake of readability. We can then assume that the
network slicing orchestrator is equipped with the general
frame size distribution model from Sec. 4.3, and can estimate
the frame size distribution for arbitrary values of T and
τ for each client m. We consider an orchestrator that can
make decisions on the resource allocation only at times
t = kS, k ∈ Z, i.e., every S frames or, conversely, every
∆t = S
ϕ ms. In the following, we consider queued bits from
earlier frames in the slicing as well. At time t = kS, we
consider that the previous slice might have been unable to
send all the data in time, leaving in the queue qm(t) bits that
have to be sent in the following frame intervals.

5.1 Motion-To-Photon Latency

We can now analyze the MTP latency by dividing it into 6
components, which are shown in Fig. 12:

1) The movement of the user needs to be recorded
and transmitted. For simplicity, we can assume head
tracking packets to be transmitted at a constant in-
terval ∆u; in this case, the time between the motion
and its transmission is τm ∼ U(0, ∆u).

2) The head tracking packet needs to be transmitted
to the Cloud VR server. Considering that the uplink
trafﬁc is very light, as the packet is small, we can
assume that it only incurs a constant propagation
delay τp. We can also assume that ∆u includes the
uplink transmission time to the Base Station (BS),
simplifying the model. In general, the transmission
time from the HMD to the BS should be extremely
low.

3) The head tracking data is received by the Cloud
server, which then needs to produce a frame. The
frame generation delay is τf ∼ U(0, ϕ−1).

4) The server needs to generate, render, and encode the
frame. We denote this delay as τr, and assume that
it is constant across short periods of time.

5) The frame is transmitted to the BS through a series
of ﬁber optic links. As the capacity of ﬁber optic
links is much higher than the Radio Access Network
(RAN)’s, we can assume this to take only the prop-
agation time τp.

6) The frame is transmitted from the BS to the HMD.
This component depends on both the frame size and
the downlink bandwidth allocated to its slice by the
orchestrator.

2)

If we set a maximum allowed MTP latency Tmax, we can
then derive a condition on the minimum bandwidth B(k)
to be assigned to the n-th customer in the k-th interval of
time:

B(k) ≥

F (k)
η (Tmax − τm − 2τp − τf − τr)

.

(6)

where η is the spectral efﬁciency, known to the BS. However,
τm and τf are random variables, so we can set a stricter
condition that guarantees that the latency requirement is

HMD

τm

BS

Cloud

τp

τp

τf
τr

ϕ−1

T (k)

∆u

F (k)
C(k)

Fig. 12: Schematic of the components of the MTP latency.

met in the worst case by substituting their maximum values,
i.e., ∆u and ϕ−1, respectively. We hence obtain

B(k) ≥

F (k)
η (Tmax − ∆u − 2τp − ϕ−1 − τr)

.

(7)

For the sake of readability, we denote the maximum time
allowed for the RAN transmission to fulﬁll the MTP latency
requirement as Ttx, i.e.,

Ttx = Tmax − ∆u − 2τp − ϕ−1 − τr.

(8)

Finally, to ensure the stability of the queue at the BS, the
average allocated bit rate, ηE[B(k)], must be larger than the
mean offered trafﬁc, i.e.,

ηE[B(k)] > ϕE[F (k)].

(9)

5.2 Slicing schemes

We can then deﬁne four ways of allocating resources to the
VR users:

1)

Individual FDMA (IF): each individual VR user is
allocated to a different slice that it can fully exploit,
and each slice has a constant bandwidth over the
next S frames. The bandwidth is then given by:

B(m)
IF

(kS + (cid:96)) =

m (ps|S, 1, kS) + qm(t)
P −1
ηmTtx

S

,

(10)

with (cid:96) ∈ {1, . . . , S}. The scheme uses Frequency Di-
vision Multiple Access (FDMA), as the bandwidth
B is constant over the whole slicing interval. In
order to avoid instability, the qm(t) queued bits need
to be considered in the slicing, but they are spread
out over the S frames in the slicing period, so as to
avoid excessive overprovisioning.
Individual OFDMA (IO): in this case, each user is still
assigned to their own individual slice, but there is a
ﬁner-grained control over the assignment of band-
width resources, allowing frame-by-frame control
of the bandwidth assignment by using Orthogonal
Frequency Division Multiple Access (OFDMA). In
this case, the queued bits can be handled in the ﬁrst
frame:

B(m)

IO (kS + 1) =

P −1

m (ps|1, 1, kS) + qm(t)
ηmTtx

.

(11)

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

11

In all subsequent frames, i.e., for (cid:96) ∈ {2, . . . , S}, the
bandwidth assignment B(m)
IF
P −1

(t) is then given by:

B(m)

IO (kS + (cid:96)) =

m (ps|1, (cid:96), kS)
ηmTtx

.

In the ﬁrst frame, the queues need to be ﬂushed
before new data can be transmitted:
1,...,M (ps|1, 1, kS) + (cid:80)M
P −1

m=1 qm(t)

(12)

BAF(kS + 1) =

ηmTtx

3) Aggregated FDMA (AF): while the two schemes de-
scribed above give each user a slice of their own,
this scheme performs FDMA, so it maintains a
constant bandwidth throughout, but considers a
single slice for the VR service. This allows users
with larger than expected frames to exploit the
bandwidth left unused by others with smaller than
expected frames, but requires another, more ﬁne-
grained scheduler to divide the resources among
users, which we will describe below. If we con-
sider an oracle prediction, the required bandwidth
B∗(kS) to deliver all the generated data is given by:
S + (cid:80)S

M
(cid:88)

qm(t)

(cid:96)=1 F (m)(kS + (cid:96))
ηmTtx

.

(13)

B∗(kS) =

m=1

We can split the required bandwidth in two compo-
nents:

B∗(kS) = B∗

q (kS) + B∗

f (kS),

where we have:

B∗

q (kS) =

B∗

f (kS) =

M
(cid:88)

m=1
M
(cid:88)

;

qm(t)
SηmTtx
S
(cid:88)

F (m)(kS + (cid:96))
ηmTtx

m=1

(cid:96)=1

(14)

(15)

.

(16)

While B∗
q (kS) is a deterministic, known value, as
it only depends on the amount of queued bytes
for each user, the bandwidth B∗
f (kS) required to
transmit future frames is unknown, as the size
of these frames is stochastic. The distribution of
B∗
f (kS) is given by the convolution of M S Laplace
distributions, and the details of its computation are
given in the Appendix. If we denote the quantile
function of this distribution as P −1
1,...,M (ps|S, 1, t),
we get, with (cid:96) ∈ {1, . . . , S}:

BAF(kS + (cid:96)) =

1,...,M (ps|S, 1, kS) + (cid:80)M
P −1

m=1

qm(t)
S

.

ηmTtx

(17)
We assume that users are synchronized, so that
frames arrive approximately at the same time: this
results in a need-based scheduler delivering the
frames from all users approximately at the same
time, allocating more bandwidth to users with a
larger frame (or a lower spectral efﬁciency). This is
a slight simpliﬁcation, but we can easily adapt the
mechanism for the asynchronous case with limited
loss of performance. The choice of a need-based
scheduler leaves the decision of setting user rates to
ﬂow admission, serving users equitably once they
access the system.

4) Aggregated OFDMA (AO): as we did for the individ-
ual slicing, we can also create aggregated slices with
a ﬁner-grained control of the bandwidth allocation.

.

(18)

(19)

For (cid:96) ∈ {2, . . . , S}, we then have:

BAO(kS + (cid:96)) =

P −1

1,...,M (ps|1, (cid:96), kS)
ηmTtx

.

Naturally, if there is only one user, i.e., M = 1, the
AF and AO slicing schemes are the same as the IF and
IO, respectively. In the same way, the FDMA and OFDMA
slicing schemes are equivalent if S = 1, as the allocation
is performed over the shortest possible unit of time, i.e., a
single frame period. All slicing schemes ensure the stability
of the queue by considering qm(t) in the bandwidth alloca-
tion, inherently ensuring that the condition in (9) is met. The
calculation of the aggregated trafﬁc distribution is given in
the Appendix.

6 SIMULATION RESULTS
In the following, we run a simulation on a system imple-
menting the slicing schemes we described in the previous
section, analyzing the two fundamental Key Performance
Indicators (KPIs) of the system: the MTP latency and the
bandwidth B reserved to the VR users. Ideally, a system
should be able to maintain the MTP latency below the
required threshold while limiting the required bandwidth.
The main parameters of the scenario are listed in Table 1,
and will be used in all simulations, unless stated otherwise.
We chose Tmax = 50 ms, which is consistent with the
relevant literature, though looser than in the IEEE standard:
as the application we used for the measuring has ∆u = 7 ms
(on average) and ϕ = 60 FPS, even an instantaneous
transmission would incur an MTP latency over 20 ms in the
worst case. The stricter deadline set by the IEEE standard
is then impossible to reach with the considered application,
and we chose a looser but still realistic deadline, leaving the
fulﬁllment of the more demanding one to future work with
more powerful XR applications.

We also considered τp = 5 ms and τr = 5 ms, consid-
ering a powerful Cloud VR server located relatively close
to the user. The ﬁnal parameters are close to the 3GPP rec-
ommendation [30], which recommends a rate R = 30 Mb/s
and ϕ = 60 FPS, although our DL latency budget is slightly
looser, as the BS has 11.3 ms to stream each frame, while
3GPP speciﬁes 10 ms as the target.

6.1 Single User

We can now examine the simulation results for a single user.
As we remarked in the previous section, the IO scheme can
reduce the jitter by having a more ﬁne-grained prediction,
as each frame will be allocated enough resources to be
transmitted with probability ps. On the other hand, the IF
scheme has a rougher prediction, with consequently higher
jitter, but will waste fewer network resources, as it can allow
larger frames to be compensated by smaller ones before
and after them. Both models are realistic, as they work
under different assumptions: in the ﬁrst case, the resources

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

12

∆t (ms)

∆t (ms)

0

50

100

150

0

50

100

150

IO

IF

)
s

m

(

T

60

55

50

45

40

)
s

m

(

y
c
n
e
t
a
L

56

54

52

50

48

46

)
z
H
M

(

B

12

11

10

9

1

2

3

4

5

6

7

8

9

10

1

2

3

4

5

6

7

8

9

10

S (frames)

(a) Latency.

S (frames)

(b) Assigned bandwidth.

Fig. 13: Boxplot of slicing performance for IF and IO for a single user.

IF, av.

IO, av.

IF, 95%

IO, 95%

IF, 99%

IO, 99%

)
z
H
M

(

B

15
14
13
12
11
10
9

0.9

0.92

0.94

0.96

0.98

1

0.9

0.92

0.94

0.96

0.98

1

ps

(a) Latency.

ps

(b) Assigned bandwidth.

Fig. 14: Average and worst-case percentiles of the latency and assigned bandwidth of a single user as a function of the
quantile ps.

that are allocated for each frame need to be over both
time and frequency, while the second case gives the slice
a constant bandwidth over the slicing interval, which is the
most common slicing model in the literature.

We can then look at the slicing schemes’ performance as
a function of S, setting ps = 0.95 and N = 6: Fig. 13 shows
boxplots of the latency and assigned bandwidth for IF and
IO. Fig. 13a clearly shows that, while the slicing granularity
has a limited effect on IO, the lower precision of IF means
that the longer the slicing interval, the higher the average
latency, and the worst-case latency, represented by the upper
whisker of the boxplots, increases even more. On the other
hand, as Fig. 13b shows, the bandwidth required by IF
decreases as S grows, while the average bandwidth required
by the IO algorithm remains roughly constant irrespective
of the value of S, but always higher than the bandwidth
used by IF.

TABLE 1: Basic scenario parameters.

Parameter

Value

Tmax
∆u
τp
τr
ps
S
N
τ
R
ϕ
Video content

50 ms
7 ms
5 ms
5 ms
0.95
6 frames
6 frames
1 frame
30 Mb/s
60 FPS
Virus Popper

This behavior is to be expected, as the errors in frame
prediction can compensate over a longer window, but comes
at the cost of a higher latency. Naturally, the choice between
the two models depends not only on the desired point in
the trade-off between QoS and resource efﬁciency, but also
on the capabilities of the underlying system: state-of-the-art
slicing frameworks often consider a period ∆t = 100 ms,
which would correspond to S = 6 frames, and the gran-
ularity of the slicing over time and frequency will dictate
whether IO is even an option.

It is also possible to simply increase the value of C(t),
e.g., by increasing ps, in the IF scheme to match the IO
performance in terms of latency, but IF will always be less
efﬁcient for the same latency target. Fig. 14 shows the slicing
performance as a function of the value of ps. Naturally, a
higher ps means a more conservative prediction of getting
larger frames, which reduces the latency but increases the
bandwidth requirements. The closer we get to 1, the more
increasing ps affects the latency, with a correspondingly
larger increase in the bandwidth that is reserved to the VR
ﬂow. We can also notice that IF requires a much higher
value of ps to get the same performance as IO in terms
of latency. A sensible example is to target a latency of one
inter-frame interval, i.e., ϕ−1 = 16.67 ms (the dashed line
in Fig. 14a), with a probability of 0.95 (the pink lines in
Fig. 14). We notice that to meet this requirement, a value of
ps ≥ 0.96 has to be chosen for the IO scheme, but the same
requirement can only be fulﬁlled if ps ≥ 0.99 using IF. This
corresponds to an average assigned bandwidth of at least
7.5 MHz for IO, but 7.64 MHz for IF. While the difference is

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

13

IF

IO

AF

AO

)
s

m

(

T

60

55

50

45

40

14

12

)
z
H
M

(

BM

10

8

1

2

3

4

5

6

7

8

9

10

1

2

3

4

5

6

7

8

9

10

M (users)

(a) Latency.

M (users)

(b) Assigned bandwidth per user.

Fig. 15: Boxplot of the latency and per-user bandwidth as a function of the number of users.

IF

IO

AF

AO

50

45

)
s

m

(

T

)
z
H
M

(

m
B

30

20

10

0

1

2

3

4

5

6

1

2

3

4

5

6

User m

(a) Latency.

User m

(b) Assigned bandwidth.

Fig. 16: Boxplot of the latency and bandwidth for each user.

not very signiﬁcant, and the IF scheme can be used without
a big performance loss, choosing the correct value of ps to
compensate for the slicing scheme’s optimism is not simple,
particularly in more complex network scenarios, while it is
relatively straightforward for IO.

6.2 Multiple Users

We can now consider a more complex scenario, in which
multiple VR users are served by the same BS. The ﬁrst
thing we need to understand is the impact of an increased
number of users on the latency and allocation of resources.
In this case, we will set up a scenario in which all users
have the same spectral efﬁciency η = 5 b/s/Hz, and stream
the same content (i.e., the Virus popper trace at 60 FPS and
30 Mb/s), although starting with a random offset. This is
to ensure that the scenario is as uniform as possible, and
the only variable is the number M of users in the system.
Furthermore, as we stated in Sec. 5.2, we assume that all VR
users are synchronized, i.e., frames from all users come at
the same time: this is a slight simpliﬁcation, which does not
have a signiﬁcant effect on performance.

Fig. 15 shows the latency and assigned bandwidth for
the scenario: if we look at the latency boxplot in Fig. 15a,
we can note that the average latency for the two aggregated
schemes increases with M , but the higher percentiles actu-
ally decrease as M increases: this is because, as aggregating
more users leads to errors in the frame size prediction com-
pensating each other, the resource allocation can be more
precise, aiming at satisfying the ϕ−1 latency requirement,
but not trying to go far below that. As the number of users
grows, the distribution of the latency will tend towards
deterministically achieving ϕ−1 with limited jitter. This is
a signiﬁcant advantage with respect to individual slicing,

which is compounded by the lower resource use, as Fig. 15b
shows: as the number of users increases, the bandwidth
allocated to each user remains the same for individual
slicing schemes, while the aggregate schemes can reduce the
total amount of resources. As for the latency, this is because
independent variations in the frame size compensate each
other, leading to a lower overall uncertainty on the total
frame size and a better resource provisioning. Finally, as
for the single user case, using OFDMA can slightly reduce
the latency, overshooting the deadline less often, but at the
cost of a higher resource utilization: the same error compen-
sation effect that we mentioned across different users can
be exploited over different frames, at the cost of a higher
latency violation probability.

We then analyze the per-user results more in depth by
considering a scenario with M = 6 users, whose detailed
parameters are given in Table 2: each user has a different
video bit rate Rm and a different spectral efﬁciency, but
they have a common frame rate ϕ and are synchronized. As
we did above, we consider a predictive slicing orchestrator
using the general model obtained by performing the regres-
sion over all traces. The videos also have a random offsets,
so even users with the same content have independent

TABLE 2: Multi-user scenario parameters.

User m

VR content

Rm (Mb/s)

ηm (b/s/Hz)

¯Bm(M Hz)

1
2
3
4
5
6

Virus Popper
Cities
Minecraft
Tour
Minecraft
Virus Popper

10
20
30
40
50
40

1.5
2.5
3
3.5
5.5
4

6.67
8
10
11.43
9.09
10

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

14

IF, av.
AF, 95%

IO, av.
AO, 95%

AF, av.
IF, 99%

AO, av.
IO, 99%

IF, 95%
AF, 99%

IO, 95%
AO, 99%

)
s

m

(

T

)
z
H
M

(

BM

60

55

50

45

30

20

10

)
s

m

(

T

60

55

50

45

0.9

0.92

0.94

0.96

0.98

1

0.9

0.92

0.94

0.96

0.98

1

ps

ps

(a) Latency (IF and IO).

(b) Latency (AF and AO).

)
z
H
M

(

BM

30

20

10

0.9

0.92

0.94

0.96

0.98

1

0.9

0.92

0.94

0.96

0.98

1

ps

ps

(c) Assigned bandwidth (IF and IO).

(d) Assigned bandwidth (AF and AO).

Fig. 17: Average and worst-case percentiles of the latency and assigned bandwidth as a function of the quantile ps.

)
z
H
M

(

BM

18

16

14

12

IF

IO

AF

AO

)
z
H
M

(

BM

20

18

16

14

47

48

49

50

51

52

50

52

54

56

58

99th perc. T (ms)

(a) 95th percentile.

99th perc. T (ms)

(b) 99th percentile.

Fig. 18: Pareto curves for the performance of the slicing schemes.

traces. Fig. 16 shows the latency and assigned bandwidth for
the 6 users, presenting some interesting patterns. As Fig. 16a
shows, the latency for all users is the same when using
the aggregated slicing schemes: this is an effect of using a
need-based scheduler when allocating resources inside the
slice. On the other hand, latency is different when using
individual slicing, with users 5 and 6 having a lower latency
violation probability. On the other hand, the bandwidth
assigned to each user, shown in Fig. 16b, is similar for all
schemes, with the aggregated ones having a slightly lower
resource utilization. This is due to the fact that the average
required bandwidth ¯Bm = Rm
, whose value for each user is
ηm
given in Table 2, is the main factor in assigning bandwidth
resources, both with individual and aggregated schemes: we
can easily see that users 1, 2, and 5, who have the lowest
values of ¯Bm, are also assigned the least bandwidth by the
slicing schemes. Interestingly, user 5 is actually the one with
the lowest bandwidth, although users 1 and 2 have lower
values of ¯Bm: this is due to the higher relative variations in
the video traces at lower bit rates, as can be easily seen from
Fig. 11, so that in order to meet the ps = 0.95 requirement,
the slicing schemes have to overprovision more for those
users.

We can also look at the performance as a function of ps
in the scenario given in Table 2, as we did for the single-
user case. The results are shown in Fig. 17: it is easy to see
that aggregated schemes manage to maintain a much lower
latency in the worst case with a lower total bandwidth, as
the individual schemes have either a latency higher than
the 50 ms threshold (for lower values of ps) or a far higher
resource utilization (for higher values of ps). Interestingly,
the performance difference between FDMA and OFDMA is
negligible for the aggregated schemes: the prediction errors
of a user are effectively compensated by the other users,
enhancing the overall performance.

We can further analyze the performance difference be-
tween the schemes by plotting their Pareto curves. Pareto
curves are useful to show two-dimensional performance
metrics which need to be traded against one another: the
curve includes all points at the edge of the achievable
performance region, i.e., points for which it is impossible
to improve one metric without making the other worse.
In our case, the two metrics are the MTP latency and the
bandwidth: ideally, we would like both to be as low as
possible, and the Pareto curve is another way of showing
the trade-off we discussed above.

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

15

If we deﬁne the performance of a slicing scheme g in
terms of latency and bandwidth as qg(ps) = (T, B), we can
say that ps dominates p(cid:48)
s where ps has
a better performance for both metrics, i.e.,

s, and we write ps (cid:31) p(cid:48)

T (g, ps) < T (g, p(cid:48)

s) ∧ B(g, ps) < B(g, p(cid:48)

s).

(20)

We can then deﬁne the Pareto curve Pg as the set of points
that are not dominated by any other point:

Pg (cid:44) {qg(ps), ∀ps | (cid:64)p(cid:48)

s : p(cid:48)

s (cid:31) ps} .

(21)

Fig. 18 shows the Pareto curves for the 4 schemes, consider-
ing ps ∈ [0.9, 0.995]. The two plots show the performance in
terms of the average assigned bandwidth per user and the
95th and 99th percentiles of latency, and conﬁrm our anal-
ysis: the aggregated schemes can signiﬁcantly outperform
the individual ones, with a bandwidth reduction of more
than 10% to obtain the same latency performance at the
95th percentile and more than 20% at the 99th percentile.
We can also note that, while the difference between IF
and IO is relatively small for the 95th percentile, it grows
for the 99th percentile, as taking the worst case highlights
the limits of the FDMA approach. On the other hand, the
difference between AF and AO is negligible. In addition
to signiﬁcantly improving the performance, choosing an
aggregated scheme is also computationally simpler, as the
slicing algorithm will only need to allocate resources to a
single VR slice and not to each individual user.

7 CONCLUSIONS

This work aims at closing a gap in the literature on trafﬁc
source modeling: there are several analyses for passive
streaming, both 2D and in immersive setups with Head
Mounted Devices (HMDs), and some for live gaming trafﬁc
in 2D, but none for interactive VR with strict latency require-
ments and quasi-CBR encoding. We analyzed live captures
from a setup we devised, publishing both the dataset and
the code for the analysis, and presented the performance
of two regression models. The ﬁrst part of our discussion
analyzes the prediction models, determining the necessary
memory in the linear regression, the residual distribution,
and the correctness of the linear model. The prediction
models are simple and ﬂexible, as they generalize extremely
well across different traces and bit rate settings: this means
that a shared pre-trained model can be used with good
performance across different video content types and bit
rate levels.

We then showed a simple Network Slicing (NS) scenario,
which highlights the importance of the trade-off between
resource efﬁciency and QoE. This is a ﬁrst step towards fully
designing an NS system able to satisfy the stringent QoS re-
quirements of XR applications also in critical scenarios, e.g.,
in industrial settings, in which the consequences of network
failures are not only discomfort and nausea for the user,
but also signiﬁcant delays in production and even safety
hazards. The results we obtained show a signiﬁcant trade-
off between resource efﬁciency and MTP latency guarantees,
which can be improved signiﬁcantly if multiple VR users
are put together in the same slice, sharing Radio Access
Network (RAN) resources using a fair scheduler.

There are several additional analyses and opportunities
for future work, that can be divided in two main directions.
The ﬁrst potential avenue of research is a wider charac-
terization, with different encoding parameters and even
different encoders, and considering different applications,
going beyond simple VR games to include the industrial and
commercial use cases we mentioned above, and a wider set
of subjects. The traces should also integrate a record of the
head movements of the users, as they correspond to shifts
in the point of view of the VR headset and are expected to
be strongly correlated with frame size changes.

The other challenge is to actually design slicing schemes
and scheduling algorithms able to take into account the na-
ture of the trafﬁc and accommodate it, efﬁciently exploiting
the prediction and adapting to the peculiarities of different
communication technologies or even multiple independent
links. The use of packet-level coding to protect the stream
from link failures and deep fading events, can be promising
avenues to design a solid framework to support XR in
mission-critical scenarios. The study of these techniques at
all levels of the communication stack, simulating connection
impairments in repeatable conditions through a full-stack
network simulator, is our ﬁrst priority in the ongoing work
on this subject.

APPENDIX

Aggregated trafﬁc distribution

Given that the frame size distribution for a single user is
known and well deﬁned, we can derive the distribution
of the total required bandwidth B∗
f (k) for the M users in
closed form. In the following, we will consider the case in
which S = 1, but the calculation can be trivially extended to
the case with S > 1. Speciﬁcally, the bandwidth required
to deliver the next frame for all the M users is deﬁned
in Eq. (16) as a weighted sum of Laplace random variable:

B∗

f (k) =

M
(cid:88)

m=1

m F (m)(k).
η−1

(22)

In the following, we omit the index k for the sake of read-
ability. The user spectral efﬁciencies η−1
m are constant scalars
which result in a scaling of the frame size distribution, i.e.,

Bm = η−1

m F (m) ∼ Laplace (αm, βm) ,
and βm = bm
ηm

where αm = µm
. The distribution of the
ηm
sum of independent random variables is obtained as the
convolution of the corresponding PDFs, denoted by pm(x).
In the Laplace transform domain, this translates to a product
of the transforms of the densities. Given that the Laplace
transform L[·] of the Laplace distribution is

(23)

L [pm(x)] (s) =L

(cid:18) 1
2βm

e− |x−αm|

βm , s

(cid:19)

ms2 ,
the transform of the PDF p(x) of the sum B∗

=e−αms

1
1 − β2

f (k) is

L [p(x)] (s) = e

−s

M
(cid:80)
m=1

αm

M
(cid:89)

m=1

1
1 − β2

ms2 .

(24)

(25)

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

16

In the case when the poles have multiplicity equal to 1,
the product can be represented with its partial function
decomposition as

L [p(x)] (s) =e

−s

M
(cid:80)
m=1

αm

M
(cid:89)

−s

M
(cid:80)
m=1

αm

=e

m=1

M
(cid:88)

m=1

1
1 − β2

ms2

γm
1 − β2

ms2 ,

(26)

where Res(gh,k, ·) is the residue of the function
gh,k(s) = (cid:0)1 − β2

hs2(cid:1)k−1

f (s),

(32)

Res

and can be computed as
(cid:0)gh,k, β2
1
(ph − k)!

(cid:1) =
(cid:34)

dph−k
d(s2)ph−k

=

h

(cid:0)1 − β2

hs2(cid:1)ph f (s)

(cid:35)

(33)

.

s2=β2
h

where the values of γm can be obtained through the residue
(or Heaviside cover-up) method, and are equal to

REFERENCES

γm =

(cid:81)

β2(M −1)
m
n(cid:54)=m (β2

m − β2
n)

.

(27)

Thanks to the additive and the shift property of the Laplace
transform, we get the PDF of

(cid:32)

p

x −

M
(cid:88)

m=1

(cid:33)

(cid:32)

αm

=L−1 [L [p(x)] (s)]

x −

(cid:33)

αm

M
(cid:88)

m=1

=

M
(cid:88)

m=1

β2(M −1)−1
m
2 (cid:81)
n(cid:54)=m (β2

e− |x|
m − β2
n)

βm

.

(28)

We can then use this result to directly compute the quantile
function P −1
1,...,M (ps|1, 1, k). Extending the result to larger
values of S and multiple frames, we can simply plug in the
function to obtain the AF and AO slicing schemes.

The above calculation is correct in the case of simple
poles. We can then brieﬂy discuss the more general case of
repeated poles. Repeated poles can be present in Eq. (25)
if the distributions of the bandwidth required by different
users have the same shape parameter β (i.e., the ratio
between the shape parameter bm and the user spectral
efﬁciency ηm), regardless of the mean α. This may be the
case when the same or similar applications are streamed
to multiple, possibly static users in the same room, e.g., in
the case of a VR arena. Thus, the distribution of the frame
sizes, determined by the application, and the spectral efﬁ-
ciencies, determined by the propagation environment, may
be the same for different users. Namely, we can consider
the most general case when there are P ≤ M unique poles
{β1, β2, . . . , βP } of order {p1, p2, . . . , pP }, (cid:80)P
i=1 pi = M ,
i.e., the users are grouped in P clusters with similar β
values.

In this case, the partial fraction representation is more
involved than that in Eq. (26). Taking into account the
repeated poles, the product in Eq. (26) can be rewritten as

M
(cid:89)

m=1

1
1 − β2

ms2 =

P
(cid:89)

i=1

1
i s2)pi ,
(1 − β2

and can thus be decomposed as

P
(cid:89)

i=1

1
i s2)pi =
(1 − β2

P
(cid:88)

ph
(cid:88)

h=1

k=1

γh,k
hs2)k = f (s).
(1 − β2

(29)

(30)

Several methods exist for determining the γ vector. The
residue method offers a general solution:
(cid:1) ,

(cid:0)gh,k, β2

γh,k = Res

(31)

h

[1] Huawei Technologies Co., “Empowering consumer-focused im-
mersive VR and AR experiences with mobile broadband,” Huawei
Technologies Co., White Paper, 2016, accessed on May 2022.
[Online]. Available:
https://www.huawei.com/en/industry-
insights/outlook/mobile-broadband/insights-reports/vr-and-ar
[2] ——, “AR insight and application practice,” Huawei Technologies
Co., White Paper, 2021, accessed on May 2022. [Online]. Available:
https://carrier.huawei.com/∼/media/CNBGV2/download/
bws2021/ar-insight-and-application-practice-white-paper-en.pdf
[3] Oculus Business, “Virtual reality – Set to enter the business
mainstream,” Oculus Business, White paper, Sep. 2020, accessed
on May 2022. [Online]. Available: https://go.facebookinc.com/
security-whitepaper.html

[4] Qualcomm Technologies,

of

2020,

future

accessed

“The mobile

eX-
tended Reality (XR),” Qualcomm Technologies, Presentation,
Nov.
[Online]. Avail-
on May
able: https://www.qualcomm.com/media/documents/ﬁles/the-
mobile-future-of-extended-reality-xr.pdf
3GPP, “Extended Reality (XR) in 5G,” 3GPP, Technical Report (TR)
26.928, Dec. 2020.
ITU-T, “Requirements for mobile edge computing enabled content
delivery networks,” ITU, Report F.743.10, Nov. 2019.

2022.

[5]

[6]

[7] H. G. Kim, W. J. Baddar, H.-T. Lim, H. Jeong, and Y. M. Ro,
“Measurement of exceptional motion in VR video contents for
VR sickness assessment using deep convolutional autoencoder,” in
ACM Symposium on Virtual Reality Software and Technology (VRST),
Gothenburg, Sweden, Nov. 2017.

[8] A. A. Barakabitze, A. Ahmad, R. Mijumbi, and A. Hines, “5G
network slicing using SDN and NFV: A survey of taxonomy,
architectures and future challenges,” Computer Networks, vol. 167,
p. 106984, Feb. 2020.

[9] Nokia, “Cloud gaming and 5G – Realizing the opportunity,”
Nokia, White Paper, 2020. [Online]. Available: https://onestore.
nokia.com/asset/207843

[10] Huawei, “Preparing for a Cloud AR/VR future,” Huawei,
White Paper, 2017, accessed on May 2022.
[Online]. Avail-
able: https://www-ﬁle.huawei.com/-/media/corporate/pdf/x-
lab/cloud vr ar white paper en.pdf?la=en

[11] M. Lecci, A. Zanella, and M. Zorzi, “An ns-3 implementation of
a bursty trafﬁc framework for virtual reality sources,” in ACM
Workshop on ns-3 (WNS3), Virtual Conference, US, Jun. 2021.
[12] M. Lecci, M. Drago, A. Zanella, and M. Zorzi, “An open frame-
work for analyzing and modeling XR network trafﬁc,” IEEE
Access, vol. 9, pp. 129 782–129 795, Sept. 2021.

[13] M. Lecci, F. Chiariotti, M. Drago, A. Zanella, and M. Zorzi, “Tem-
poral characterization of XR trafﬁc with application to predictive
network slicing,” in IEEE International Symposium on a World of
Wireless, Mobile and Multimedia Networks (WoWMoM), Belfast, UK,
Jun. 2022.

[14] J. Latta and D. Oberg, “A conceptual virtual reality model,” IEEE
Computer Graphics and Applications, vol. 14, no. 1, pp. 23–29, Jan.
1994.

[15] “IEEE Standard for Head-Mounted Display (HMD)-Based Virtual
Reality(VR) Sickness Reduction Technology,” IEEE Std 3079-2020,
pp. 1–74, 2021.

[16] M.-W. Seo, S.-W. Choi, S.-L. Lee, E.-Y. Oh, J.-S. Baek, and S.-J.
Kang, “Photosensor-based latency measurement system for head-
mounted displays,” Sensors, vol. 17, no. 5, May 2017.

[17] A. Blate, M. Whitton, M. Singh, G. Welch, A. State, T. Whitted,
and H. Fuchs, “Implementation and evaluation of a 50 kHz, 28µs
motion-to-pose latency head tracking instrument,” IEEE Transac-
tions on Visualization and Computer Graphics, vol. 25, no. 5, pp. 1970–
1980, May 2019.

THIS PAPER HAS BEEN SUBMITTED TO IEEE TRANSACTIONS ON MOBILE COMPUTING. COPYRIGHT MAY CHANGE WITHOUT NOTICE.

17

[39] M. Chen, W. Saad, C. Yin, and M. Debbah, “Data correlation-aware
resource management in wireless Virtual Reality (VR): An echo
state transfer learning approach,” IEEE Trans. on Communications,
vol. 67, no. 6, pp. 4267–4280, Jun. 2019.

[40] X. Yang, Z. Chen, K. Li, Y. Sun, N. Liu, W. Xie, and Y. Zhao,
“Communication-constrained mobile edge computing systems for
wireless virtual reality: Scheduling and tradeoff,” IEEE Access,
vol. 6, pp. 16 665–16 677, Mar. 2018.

[41] Nvidia, “Video Codec SDK Documentation,” 2021.

[Online].
https://docs.nvidia.com/video-technologies/video-

Available:
codec-sdk/nvenc-video-encoder-api-prog-guide/

[42] S. M. Stigler, “Gauss and the invention of least squares,” The

Annals of Statistics, pp. 465–474, May 1981.

[43] R. Koenker and G. Bassett Jr, “Regression quantiles,” Econometrica:

journal of the Econometric Society, pp. 33–50, Jan. 1978.

[44] C. Yu and W. Yao, “Robust linear regression: A review and com-
parison,” Communications in Statistics-Simulation and Computation,
vol. 46, no. 8, pp. 6261–6282, Sep. 2017.

[45] R. M. Norton, “The double exponential distribution: Using cal-
culus to ﬁnd a maximum likelihood estimator,” The American
Statistician, vol. 38, no. 2, pp. 135–136, May 1984.

[18] J.-P. Stauffert, F. Niebling, and M. E. Latoschik, “Simultaneous run-
time measurement of motion-to-photon latency and latency jitter,”
in IEEE Conference on Virtual Reality and 3D User Interfaces (VR),
Mar. 2020, pp. 636–644.

[19] J. Zhao, R. S. Allison, M. Vinnikov, and S. Jennings, “Estimating
the motion-to-photon latency in head mounted displays,” in IEEE
Virtual Reality (VR), Los Angeles, California, Mar. 2017, pp. 313–
314.

[20] S.-W. Choi, S. Lee, M.-W. Seo, and S.-J. Kang, “Time sequential
motion-to-photon latency measurement system for virtual reality
head-mounted displays,” Electronics, vol. 7, no. 9, Sept. 2018.
[21] S. Tanwir and H. Perros, “A survey of VBR video trafﬁc models,”
IEEE Communications Surveys & Tutorials, vol. 15, no. 4, pp. 1778–
1802, Jan. 2013.

[22] S. Liew and D.-Y. Tse, “A control-theoretic approach to adapting
VBR compressed video for transport over a CBR communications
channel,” IEEE/ACM Transactions on Networking, vol. 6, no. 1, pp.
42–55, Feb. 1998.

[23] N. Mohsenian, R. Rajagopalan, and C. A. Gonzales, “Single-pass
constant- and variable-bit-rate MPEG-2 video compression,” IBM
J. Res. Dev, vol. 43, no. 4, pp. 489–509, Jul. 1999.

[24] M. Carrascosa and B. Bellalta, “Cloud-gaming: Analysis of
Google Stadia trafﬁc,” in arXiv, Sep. 2020. [Online]. Available:
https://arxiv.org/pdf/2009.09786.pdf

[25] A. Di Domenico, G. Perna, M. Trevisan, L. Vassio, and D. Gior-
dano, “A network analysis on Cloud Gaming: Stadia, GeForce
Now and PSNow,” Network, vol. 1, no. 3, pp. 247–260, Oct. 2021.

[26] P. Graff, X. Marchal, T. Cholez, S. Tufﬁn, B. Mathieu, and O. Festor,
“An analysis of Cloud Gaming platforms behavior under different
network constraints,” in International Conference on Network and
Service Management (CNSM), Virtual Conference, Oct. 2021.
[27] O. S. Pe ˜naherrera-Pulla, C. Baena, S. Fortes, E. Baena, and R. Barco,
“Measuring Key Quality Indicators in Cloud Gaming: Framework
and assessment over wireless networks,” Sensors, vol. 21, no. 4,
Feb. 2021.

[28] B. Hentschel, M. Wolter, and T. Kuhlen, “Virtual Reality-based
multi-view visualization of time-dependent simulation data,” in
IEEE Virtual Reality Conference, Lafayette, LA, USA, Mar. 2009, pp.
253–254.

[29] F. Chiariotti, “A survey on 360-degree video: Coding, quality of
experience and streaming,” Computer Communications, vol. 177, pp.
133–155, Sep. 2021.

[30] 3GPP, “Study on XR (Extended Reality) Evaluations for NR,”

3GPP, Technical Report (TR) 38.838, Dec. 2021.

[31] V. Sciancalepore, K. Samdanis, X. Costa-Perez, D. Bega, M. Gra-
maglia, and A. Banchs, “Mobile trafﬁc forecasting for maximizing
5G network slicing resource utilization,” in IEEE Conference on
Computer Communications (INFOCOM), Atlanta, GA, USA, Apr.
2017.

[32] C. Marquez, M. Gramaglia, M. Fiore, A. Banchs, and X. Costa-
Perez, “Resource sharing efﬁciency in network slicing,” IEEE
Transactions on Network and Service Management, vol. 16, no. 3, pp.
909–923, Jun. 2019.

[33] H. Jiang, T. Wang, and S. Wang, “Multi-scale hierarchical resource
management for wireless network virtualization,” IEEE Transac-
tions on Cognitive Communications and Networking, vol. 4, no. 4, pp.
919–928, Oct. 2018.

[34] L. Tang, X. He, X. Yang, Y. Wei, X. Wang, and Q. Chen, “ARMA-
prediction-based online adaptive dynamic resource allocation in
wireless virtualized network,” IEEE Access, vol. 7, pp. 130 438–
130 450, Sep. 2019.

[35] C. Gutterman, E. Grinshpun, S. Sharma, and G. Zussman, “RAN
resource usage prediction for a 5G slice broker,” in International
Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc),
Catania, Italy, Jul. 2019, pp. 231–240.

[36] N. Van Huynh, D. T. Hoang, D. N. Nguyen, and E. Dutkiewicz,
“Real-time network slicing with uncertain demand: A deep learn-
ing approach,” in IEEE International Conference on Communications
(ICC), Shanghai, China, May 2019, pp. 1–6.

[37] A. Arfaoui, R. El-Azouzi, M. Haddad, and E. Sabir, “Flexible
network slicing assisted 5G for video streaming with effective and
efﬁcient isolation,” in IEEE International Teletrafﬁc Congress (ITC
32), Osaka, Japan, Sep. 2020, pp. 156–164.

[38] M. Chen, W. Saad, and C. Yin, “Virtual Reality over wireless
networks: Quality-of-Service model and learning-based resource
management,” IEEE Transactions on Communications, vol. 66, no. 11,
pp. 5621–5635, Nov. 2018.

