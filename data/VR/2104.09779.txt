Privacy-aware VR streaming

Xing Wei and Chenyang Yang
School of Electronics and Information Engineering, Beihang University, Beijing 100191, China
Email: {weixing, cyyang}@buaa.edu.cn

1

1
2
0
2

r
p
A
0
2

]

M
M

.
s
c
[

1
v
9
7
7
9
0
.
4
0
1
2
:
v
i
X
r
a

Abstract—Proactive tile-based virtual reality (VR) video
tracking data of a user to
streaming employs the current
predict future requested tiles, then renders and delivers the
predicted tiles to be requested before playback. The quality
of experience (QoE) depends on the overall performance of
prediction, computing (i.e., rendering) and communication. All
prior works neglect that users may have privacy requirement,
i.e., not all the current tracking data are allowed to be uploaded.
In this paper, we investigate the privacy-aware VR streaming.
We ﬁrst establish a dataset that collects the privacy requirement
of 66 users among 18 panoramic videos. The dataset shows that
the privacy requirements of 360◦ videos are heterogeneous. Only
41% of the total watched videos have no privacy requirement.
Based on these ﬁndings, we formulate the privacy requirement
as the degree of privacy (DoP), and investigate the impact of DoP
on the proactive VR streaming. First, we ﬁnd that with DoP, the
length of the observation window and prediction window of a
tile predictor should be variable. Then, we jointly optimize the
durations for computing and transmitting the selected tiles as
well as the computing and communication capability, aimed at
maximizing the QoE given arbitrary predictor and conﬁgured
resources. From the obtained optimal closed-form solution, we
ﬁnd a resource-saturated region where DoP has no impact on
the QoE and a resource-unsaturated region where the two-fold
impacts of DoP are contradictory. On the one hand, the increase
of DoP will degrade the prediction performance and thus degrade
the QoE. On the other hand, the increase of DoP will improve the
capability of computing and communication and thus improve the
QoE. Simulation results using two predictors and a real dataset
validate the analysis and demonstrate the overall impact of DoP
on the QoE.

Index Terms—360◦ video streaming, privacy datasets, privacy-

aware VR, degree of privacy

I. INTRODUCTION

Wireless virtual reality (VR) can provide a seamless and
immersive experience to users. As the main type of VR
services , 360◦ video has the following unique features. First,
360◦ video usually has 360◦ ×180◦ panoramic view with ultra
high resolution (e.g., binocular 16K [1]). Second, the range of
angles of a 360◦ video that humans can see at arbitrary time
is only a small portion of the full panoramic view (e.g., 110◦
×90◦), which is called ﬁeld of view (FoV). More importantly,
the stalls or black holes during watching 360◦ video will cause
physiological discomfort, e.g., dizziness, which degrades the
quality of experience (QoE) and thus should be avoid.

To stream such video with QoE guarantee, proactive VR
video streaming is proposed [2], [3], which divides a full
panoramic view segment into small tiles in spatial domain.
Before the playback of the segment, the tiles to be most likely
requested in the segment are ﬁrst predicted using the user
behavior-related data in an observation window, which are then
computed (i.e., rendered) and ﬁnally delivered to the user.

While proactive VR video streaming is being intensive
investigated in academia and industry, all the research neglects
the willingness of users. Are users willing to share their
behavior-related data while watching VR videos?

Recent work shows that with less than 5 minutes tracking
data while watching VR videos, simple prediction algorithm
random forest can correctly identify 95% of users among all
the 511 users [4]. This reveals that behavior-related data can
be used to dig personal information. As the development of the
technology, one may be able to dig more personal information
than beyond imagination.

With this consideration, it is reasonable to consider privacy
protection in VR video streaming. Then, many fundamental
problems arise: How to deﬁne the privacy requirement for
VR video streaming? How to design privacy-aware VR video
streaming? What is the impact of privacy requirement on the
system?

In this paper, we strive to answer these questions. The main

contributions can be summarized as follows.

• We establish the ﬁrst privacy requirement dataset, from
which we verify that users have heterogeneous privacy
requirements.

• Based on the dataset, we deﬁne the degree of privacy
(DoP) as the ratio of a video trace that a user requires
not to disclose user behavior-related data.

• Based on the deﬁned privacy requirement, we design a
privacy-aware VR video streaming system. We ﬁnd a
predictor with variable length of input and output is more
suitable for privacy requirement. Then, we optimize the
durations and the capability for rendering and transmit-
ting to maximize the QoE.

• From the obtained optimal solution, we ﬁnd a resource-
saturated region where DoP has no impact and a resource-
unsaturated region where DoP has contradictory impacts
on the QoE. The increase of DoP on the one hand
improves the capability of computing and communication
and thus improve the QoE. On the other hand, it degrades
the prediction performance and thus degrades the QoE.
The overall impact depends on which factor dominates
the QoE.

• Simulation with two predictors on a real dataset veriﬁes
the analysis and shows that the impact of DoP on QoE
also depends on other inﬂuence factors, e.g., the robust-
ness of a predictor to the variation of DoP and assigned
resources. The heterogeneous DoP calls for a predictor
that has strong robustness to the variation of DoP.

 
 
 
 
 
 
2

II. PRIVACY INVESTIGATION WHEN WATCHING 360◦
VIDEOS

In this section, we investigate the privacy requirement of
users when watching 360◦ videos. To this end, we ﬁrst collect
a dataset that contains the privacy requirement when watching
360◦ videos, then analyze the obtained data.

To obtain the real privacy requirement when a user requests
a 360◦ video, the experiment is carefully designed to mimic
a real 360◦ video-on-demand (VoD) procedure.

A. Dataset Establishment

The dataset includes the privacy requirement of 66 viewers
when requesting three among 18 panoramic videos, called
“Privacy 360◦ video dataset”. The age of viewers ranges from
18 to 38, most viewers are in their early twenties, and 40.9%
of them are female. The collection procedure is as follows.

First, we select 18 panoramic videos and one demo video
from Bilibili1 and Internet. Unlike other experiments that
cutting videos into the video sequence [5] or removing the
audio track [6], we remain the complete videos in order to
construct a real library of 360◦ videos. As shown in Table I, the
content of these videos is diverse and covers the representative
category of panoramic videos.

Before the video requests start, viewers are guided to wear
the HMD of an HTC Vive Pro, seat on a swivel chair, and
interact using a handheld controller. They can turn around
freely, such that all panoramic regions are accessible. Then
they are guided to watch a demo video, which helps them
to adapt to the virtual reality environment. When viewers
have acclimatized themselves to the VR environment,
the
video requests start, viewers can freely choose three panoramic
videos they prefer. Unlike other experiments where viewers
are forced to watch all the videos [5]–[7], the free choice
mechanism avoids viewers to watch the videos they dislike,
thus the obtained privacy requirement of videos can be more
close to reality. After watching the 360◦ videos, they are asked
to ﬁll out a questionnaire, as shown in Table II.

B. Results analysis

We collect 3×66 = 198 privacy requirements, the statistical
result is shown in Figure 1. Only 81
198 = 41% of the total
video requests has no privacy requirement, i.e., privacy re-
quirement equals to 0. Furthermore, from Figure 2, users have
heterogeneous privacy requirement of 360◦ videos. From these
results we can ﬁnd that privacy requirements are necessary
to be considered in proactive VR video streaming system.
Therefore, in the following, we consider the privacy-aware VR
video streaming system and investigate the impact of privacy
requirement on the system.

III. SYSTEM MODEL

Consider a tile-based proactive VR video streaming system
with an multi-access edge computing (MEC) server co-located
with a base station (BS) that serves K users. The MEC

1https://www.bilibili.com/

Fig. 1: Privacy requirement and corresponding ratio

Fig. 2: Heterogeneous privacy requirements among users and
videos

server equips with powerful computing units for rendering and
training predictors, and can access a VR video library, which
can be realized by local caching or high speed backhaul hence
the delay from the Internet to the MEC server can be omitted.
Each user requests 360◦ videos from the library according
to their own time schedule and interests hence the requests
are asynchronous, which then can be decoupled into multiple
individual requests. In the sequel, without loss of generality,
we consider arbitrary one request for vth video from the kth
user for analysis.

The playback duration of VR video is TVR. Each VR video
consists of L segments in temporal domain, and each segment
consists of M tiles in spatial domain. The playback duration of
each tile equals to the playback duration of a segment, denoted
by Tseg [2], [8].

Each user is equipped with a HMD, which can measure
user behavior-related data2, send the recorded data to the MEC

2The current useful user behavior-related data for prediction include sensor-
related data, (i.e., the head movement orientation tracking [2], [9] and eye
tracking data [6], [10] from the HMD sensors) and content-related data (i.e.,
the images in historical FoVs [5], [6], temporal-spatial saliency [11], [12],
and audio track information [13]). While our framework is applicable for
prediction using one or multiple types of data, we take the head movement
trace as an example for easy exposition.

0%20%40%60%80%100%Privacy requirement020406080100Number of video requestsLake baikalWingsuit flyingVideo0%20%40%60%80%100%Privacy requirement12th user21th user43th user55th user3

TABLE I: Description of 19 panoramic videos

Category
Demo

Landscape

Micro ﬁlm

Sports

Human landscape

Natural landscape

Science ﬁction

Horror
Cartoon

First perspective

Third perspective

Life sharing

Work of art

Videos of game

First perspective interaction

Video
Guide Dog
Venice carnival
Street concert
Just Dance
Lake baikal
Africa safari
Help
King Kong
The Conjuring 2
Father and daughter
Wingsuit ﬂying
Val Thorens Ski
Basketball
Travel dream imagine
Dreams of Dali
Zero-gravity in dreams
Assassin’s Creed
WannaOne’s girlfriend
Surrounded by Korean girls

Link
www.bilibili.com/video/BV1gK411P7iB
www.bilibili.com/video/BV1hp4y1k79k
pan.baidu.com/s/190xMAwwy 0EcLRl-kgRvSw, password:Stre
pan.baidu.com/s/12raF1sPQNzrzbMPdKxVpuA, password:Just
www.bilibili.com/video/BV1b54y1C7W9
pan.baidu.com/s/1YaPjPyBSzbcAxjkt3pkooA, password:Afri
www.bilibili.com/video/BV1Wt4y1i7iH
www.bilibili.com/video/BV13f4y1q7CL
www.bilibili.com/video/BV1Ua411w7Ut
www.bilibili.com/video/BV1q5411576u
www.bilibili.com/video/BV1a64y1T7a4
pan.baidu.com/s/1HWyYfRmt35eiVrLNqkV9Jw, password:ValT
pan.baidu.com/s/1mgNIzkOjghli3Lw3hRa8QA, password:Bask
pan.baidu.com/s/1tZVqbb1Z1sgy6XrncCEDuw, password:Trav
www.bilibili.com/video/BV14D4y1d7Gp
www.bilibili.com/video/BV1ap4y1Y7YU
www.bilibili.com/video/BV1QA411j7hw
www.bilibili.com/video/BV1Bv41167dM
www.bilibili.com/video/BV1cV411y7oR

TABLE II: Questionnaire

Please ﬁll out the privacy requirement of the three videos (0∼100%). 1. ﬁrst video:

, 2. second video:

, 3. third video:

Explanation: (a) From the viewing orientations trace of a video one can recover the image in FoVs that you choose to see.
(b) Privacy requirement is the percentage of the trace that you are not willing to share with others.
(c) Three examples of privacy requirement: 0: Share the complete trace to communication operator or online video content
platform, 100%: Not share any part of the traces. 50%: Share half length to the operator and platform, keep half by yourself.

server, and pre-buffer segments.

A. Degree of Privacy

To reﬂect

the privacy requirement when watching 360◦
videos, we deﬁne the degree of privacy as the percentage of
the “private duration” among the playback duration of a 360◦
video, i.e.,

ρ (cid:44) T p
VR
TVR

∈ [0, 100%]

(1)

where T p
VR is the total private duration in the VR video for
an arbitrary user, wherein the user requires not to disclose
any user behavior-related data. When ρ = 0, the user allows
to share all the data during watching the VR video. When
ρ = 100%, the user forbids to release any data during the
whole playback procedure. The DoP of the kth user when
requesting the vth video can be expressed as ρk,v.

The total available duration where the user behavior-related
data is accessible by the MEC server is T a
VR =
(1 − ρ) · TVR. In order to maximally utilize the available data
with duration T a
VR for predicting tile requests in each segment,
we assume the duration T a
VR is equally allocated among all the
segments. Then, for each segment, the duration of the available
data used for prediction, i.e., the observation window, is

VR = TVR − T p

tobw(ρ) =

T a
VR
L

= (1 − ρ) ·

TVR
L

= (1 − ρ) · Tseg

(2)

Then, the private duration in each segment is

tpv(ρ) = Tseg − tobw(ρ) = ρTseg

Fig. 3: Streaming the ﬁrst four segments of a VR video, ρ > 0.

B. Privacy-aware Streaming Procedure

When a user requests a VR video with DoP ρ > 0, the
MEC server ﬁrst streams the initial (l0 − 1)th segments in a
passive streaming mode [14]. When the MEC server collects
the user behaviour-related data (e.g., the head movement trace)
in an observation windows with duration tobw(ρ), the tiles to
be played in the l0th segment with duration Tpdw = Tseg
can be predicted. Then, proactive streaming for the l0th
segment begins, subsequent segments are predicted, rendered,
and transmitted one after another, as shown in Figure 3. In the

Playback PassiveProactiveInitial delaytHead movement trace1RenderingTransmitting 2343344Prediction and tile selectionTile selectioncpttcomtpdwsegTTcc()Tobw()tpv()t4

ﬁgure, l0 = 3.

Speciﬁcally, at
the end of the observation window for
tile request probabilities or the ﬁxation
the ﬁrst segment,
sequences of FoVs in the third (i.e., the l0th) segment can
be predicted.3 Based on the probabilities (or the ﬁxation
sequences) and the number of tiles that can be streamed,
the tiles to be streamed can be determined (to be explained
in Section IV-C). Then, the selected tiles are rendered with
duration tcpt and the sequence of FoVs can be generated, and
ﬁnally the rendered tiles are transmitted with duration tcom,
which should be ﬁnished before the start time of playback for
the predicted segment. The total duration for computing and
communication is

Tcc(ρ) = Tpv(ρ) + Tseg = (1 + ρ)Tseg

which begins from the end of the observation window and
terminates at the playback time of the predicted segment. The
durations for computing and transmitting satisfy

tcom(ρ) + tcpt(ρ) = (1 + ρ)Tseg

which depends on ρ, and thereby are functions of ρ.

C. Computing and Transmission Model

The computing resource of MEC for rendering a VR video
can be assigned by allocating graphics processing unit (GPU)
and compute uniﬁed device architecture cores [15], [16]. The
conﬁgured computing resource for rendering a video from the
request of the kth user is denoted as Fcpt,k (in ﬂoating-point
operations per second, FLOPS). Then, the number of bits that
can be rendered per second, referred to as the computing rate,
is

Ccpt,k (cid:44) Fcpt,k
µr
where µr is the required ﬂoating-point operations (FLOPs) for
rendering one bit of FoV in FLOPs/bit [16].

(in bit/s),

The BS serves K single-antenna users using zero-forcing
beamforming with Nt antennas. The instantaneous data rate
at the ith time slot within the duration tcom for the kth user
is

C i

com,k(Bk, pk) = Bk log2

1 +

(cid:32)

k |˜hi
pkd−α
σ2

k|2

(cid:33)

,

(cid:44) (hi

k)H wi

where Bk is the conﬁgured bandwidth for the kth user,
˜hi
k is the equivalent channel gain, pk and wi
k
k
are respectively the transmit power and beamforming vector
k ∈ CNt are respectively the distance
for the kth user, dk and hi
and the small scale channel vector from the BS to the kth user,
α is the path-loss exponent, σ2 is the noise power, and (·)H
denotes conjugate transpose.

We consider indoor users as in the literature, where the
distances of users, dk, usually change slightly [5], [8], [17] and
hence are assumed ﬁxed. Due to the head movement and the
variation of the environment, small-scale channels are time-
varying, which are assumed as remaining constant in each

3Predicting the second segment may be useless. For example, when ρ = 0,
there is no time for proactively rendering and transmitting the second segment.

time slot with duration ∆T and changing independently with
identical distribution among time slots. With the proactive
transmission, the rendered tiles (i.e., sequences of FoVs) in
a segment should be transmitted with duration tcom(ρ). The
number of bits transmitted with tcom(ρ) can be expressed as
C com,k(Bk, pk) · tcom(ρ), where
Ns(cid:88)
C com,k(Bk, pk) (cid:44) 1
Ns

com,k(Bk, pk) · ∆T

i=1
is the time average transmission rate, and Ns is the number
of time slots in tcom. Since future channels are unknown
when making the optimization, we use ensemble-average rate
Eh{Ccom,k(Bk, pk)} [18] to approximate the time-average
rate C com,k(Bk, pk), where Eh{·} is the expectation over h,
which can be very accurate when Ns or Nt is large [16].

C i

We can observe that

the ensemble-average transmission
rate Eh{Ccom,k(Bk, pk)} can be conﬁgured by allocating
bandwidth Bk and transmission power pk. In the sequel,
we consider arbitrary one user and use Ccom and Ccpt to
replace Eh{Ccom,k(Bk, pk)} and Ccpt for notional simplicity.
Besides, we refer the transmission rate and computing rate as
“Resource rates”.

IV. PROBLEM FORMULATION

A. Performance Metric of Tile Prediction

Average segment degree of overlap (average-DoO) has been
used to measure the prediction performance for a VR video
[16]. It indicates the average overlap of the predicted tiles
and the requested tiles among all the proactively streamed
segments , which is deﬁned as
L
(cid:88)

1
L − l0 + 1

l=l0

qT
l · el(tobw)
(cid:107)ql(cid:107)1

D(tobw) (cid:44)

∈ [0, 100%]

where ql (cid:44) [ql,1, ..., ql,M ]T denotes the ground-truth of
the tile requests for the lth segment with ql,m ∈ {0, 1},
el(tobw) (cid:44) [el,1(tobw), ..., el,M (tobw)]T denotes the predicted
tile requests for the segment with el,m(tobw) ∈ {0, 1}, (·)T
denotes transpose of a vector, and (cid:107) · (cid:107)1 denotes the (cid:96)1 norm
of a vector. When the mth tile in the lth segment is truly
requested, ql,m = 1, otherwise ql,m = 0. When the tile is
predicted to be requested, el,m(tobw) = 1, otherwise it is zero.
the number of predicted tiles (cid:107)el (tobw) (cid:107)1
in-
creases, average-DoO will be nondecreasing. We consider
(cid:107)el (tobw) (cid:107)1 = Nfov with Nfov < M , where Nfov is the number
of tiles within a FoV. A larger value of average-DoO indicates
a better prediction.

If

As the veriﬁed Assumption 1 in [16] states, a predictor can
be more accurate with a longer observation window. Therefore,
average-DoO is a monotonically increasing function of tobw.
When consider DoP, tobw becomes a monotonically decreasing
function of ρ, as shown in (2). Then, average-DoO becomes
a monotonically decreasing function of ρ as
∂D
∂ρ

D(ρ) (cid:44) DoO (tobw(ρ)) ,

< 0

(3)

From here on we omit the intermediate variable tobw, all the
prior functions of tobw are expressed as the functions of ρ,
e.g., el(tobw) can be expressed as el(ρ).

B. Computing and Communication Capability

To reﬂect the ratio of tiles in a segment that can be rendered
and transmitted within assigned durations for transmission and
computing, deﬁne the capability of computing and communi-
cation(CC) tasks as

Ccc (cid:44) N (ρ)
M

∈ [0, 1],

(4)

where

N (ρ) (cid:44) min

(cid:26) Ccomtcom(ρ)
scom

,

Ccpttcpt(ρ)
scpt

(cid:27)

, M

is the number of tiles that can be computed in tcpt and
transmitted in tcom, scom = pxw · pxh · b · rf · Tseg/γc [1]
is the number of bits in each tile for transmission, scpt =
pxw · pxh · b · rf · Tseg is the number of bits in a tile for
rendering, pxw and pxh are the pixels in wide and high of a
tile, b is the number of bits per pixel relevant to color depth
[1], rf is the frame rate, and γc is the compression ratio.

C. Determine the streamed tiles

When the CC capability (N (ρ)) is determined, the streamed
tiles can be selected by either one of the following schemes.
(a) When the predicted parameter is the probabilities of the
tile requests [11], the ﬁrst N (ρ) tiles with largest probabilities
are selected. (b) When the predicted parameter is the ﬁxation
sequence of FoVs [2], [19], N (ρ) can be ﬁrst transformed into
the size of an ellipse, then the selected tiles is the tiles within
the ellipse [20].

D. Metric of Quality of Experience

For proactive tile-based streaming,

the motion-to-photon
latency can be zero if the constraint tcom(ρ)+tcpt(ρ) = Tcc(ρ)
can be satisﬁed. Yet black holes will appear if the requested
tiles cannot be streamed before playback. For arbitrary given
predictor, DoP ρ, and the number of selected tiles N (ρ), we
consider the following QoE metric

QoE (cid:44)

1
L − l0 + 1

L
(cid:88)

l=l0

qT
l · el(ρ)
(cid:107)ql(cid:107)1

,

(5)

which is the percentage of the correctly streamed tiles that
can be computed and delivered among all the requested tiles,
where (cid:107)el (ρ) (cid:107)1 = N (ρ) = Ccc(ρ) · M . We can observe
that the QoE depends on the average-DoO and CC capability,
which can be expressed as

QoE = Q (D (ρ) , Ccc(ρ)) ∈ [0, 100%]

(6)

When all the requested tiles in a VR video are proactively
computed and delivered before playback, the value of the QoE
is 100%. When Ccc(ρ) is increased, more tiles can be rendered
and transmitted, then more requested tiles can be satisﬁed.
Therefore, we have the following remark:

Remark 1: Q (D (ρ) , Ccc(ρ)) is a monotonically nonde-

creasing function of Ccc(ρ).

V. PRIVACY-AWARE PREDICTION: VARIABLE LENGTH OF
INPUT AND OUTPUT

5

i.e., ρ > 0,

Without consideration of privacy,

to train the predictor
and predict requested tiles, the durations of observation and
prediction windows are ﬁxed [19]. However, when users have
the durations of these
privacy requirement,
windows should be variable. The reasons are two-folds. (1)
The durations of prediction window in training and inference
are different, as shown in Figure 4a. To train a predictor and
learn the mapping from data in Tobw(ρ) of the lth segment
to the tile request probabilities of the (l+2)th segment, the
prediction window in the (l+2)th segment should be Tseg.
However, the accessible data in the (l+2)th segment used as
labels is with duration Tobw(ρ). Therefore, the duration of
prediction window for training becomes T train
pdw(ρ) = Tobw(ρ).
When predicting the tiles, the predictor needs to infer the tile
requests in a whole segment, i.e., the prediction window for
inference should be T infr
pdw = Tseg. (2) In training procedure,
the durations of observation and prediction windows among
different users and videos may be variable, as shown in 4b
and 4c. This is because users may have heterogeneous privacy
requirements.

To handle the variable length of observation and prediction
windows caused by privacy requirement, a predictor with
dimensional scalability of input and output could be more
suitable, e.g., the sequence-to-sequence framework [21].

(a) Prediction window for training and testing.

(b) Training using the data of k1th user for vth video, ρk1,v = 50%.

(c) Training using the data of k2th user for vth video, ρk2,v = 80%.

Fig. 4: Observation and prediction windows for training and
inference

Prediction window for trainingObservation windowHead movement tracePrediction window for inferenceobw()Tpdwobw()()trainTTSegment indexll+1l+2pdwseginfrTTPrediction window for trainingObservation windowHead movement trace1obw,()kvT11pdw,obw,()()trainkvkvTTPrediction window for trainingObservation windowHead movement trace2obw,()kvT22pdw,obw,()()trainkvkvTT6

VI. DOP: CONTRADICTORY EFFECTS FOR QOE

In this section, we investigate how DoP affects the QoE.
To this end, we ﬁrst optimize durations for communication
and computing as well as the CC capability to maximize
the QoE. From the obtained closed-form solution, we ﬁnd a
resource-saturated and a resource-unsaturated regions. Then
we investigate how the DoP affects average-DoO and CC
capability in the two regions, respectively. Finally, we discuss
the overall impact of DoP on the QoE.

A. Joint Optimization of the Durations and Capability for
Computing and Communication

Given arbitrary computing rate Ccpt, transmission rate Ccom
and DoP ρ, we ﬁnd the optimal durations for communication
and computing as well as the CC capability to achieve maxi-
mized QoE, i.e.,

P0 :

max
tcom(ρ),tcpt(ρ),Ccc(ρ)

Q (D (ρ) , Ccc(ρ))

s.t. Ccc(ρ) =

min

(cid:110) Ccomtcom(ρ)
scom

, Ccpttcpt(ρ)
scpt

, M

M

(cid:111)

,

tcom(ρ) + tcpt(ρ) = (1 + ρ)Tseg,

Problem P0 is a functional optimization problem, where the
optimal solution as a function of Ccom, Ccpt, and ρ needs to
obtained. To emphasize the impact of ρ, we do not explicitly
express tcom(ρ), tcpt(ρ), and Ccc(ρ) as functions of Ccom and
Ccpt. As derived in the supplementary material, the solution
of P0 is,

cc ) achieves (1 + ρ)Tseg = T M

tiles T M
cc . This indicates that all the tiles can be computed
and transmitted, i.e., C ∗
cc(ρ) = 1, as shown in (8c). Besides,
since all tiles can be streamed when the conﬁgured resource
rates (reﬂected by 1/T M
cc , further
increasing the resource rates is useless for improving the
maximized CC capability C ∗
cc(ρ). That is to say, the resource
rates are saturated in this region. We refer to this region as
“Resource-saturated region”.
When (1 + ρ)Tseg < T M

cc , the duration for computing and
transmitting the selected tiles is less than the required duration
for computing and transmitting all the tiles. This indicates
that not all the tiles can be computed and transmitted. In this
region, increasing the resource rates (i.e., 1/T M
cc ) can always
increase the percentage of rendered and transmitted tiles, i.e.,
cc(ρ) = (1+ρ)Tseg
C ∗
. We refer to this region as “Resource-
unsaturated region”.

T M
cc

In the resource-saturated region, C ∗

cc(ρ) = 1, all tiles can be
streamed before playback, then QoE = 100%. In this region,
DoP has no impact on the QoE. In the following, we discuss
the impact of DoP in the resource-unsaturated region.

C. Contradictory Role in the Resource-Unsaturated Region

1) Improve the Maximized CC Capability: The maximized
CC capability indicates the maximal percentage of streamed
the tiles with duration Tcc(ρ), which can
tiles among all
be regarded as “completed amount” of CC tasks with given
resource rates and time. We can rewrite the maximized CC
capability in the resource-unsaturated region from (8c) as
follows:

t∗
com(ρ) =






Ccptscom(1+ρ)Tseg
Ccomscpt+Ccptscom
(cid:104) scomM
Ccom

,
, (1 + ρ)Tseg − scptM
Ccpt

(cid:105)

(1 + ρ)Tseg ≤ T M
cc ,
, (1 + ρ)Tseg ≥ T M
cc ,

t∗
cpt(ρ) =






Ccptscom(1+ρ)Tseg
Ccomscpt+Ccptscom
(cid:104) scptM
Ccpt

,
, (1 + ρ)Tseg − scomM
Ccom

(1 + ρ)Tseg ≤ T M
cc ,
, (1 + ρ)Tseg ≥ T M
cc ,

(cid:105)

(8a)

C ∗

cc(ρ) =

(cid:40) (1+ρ)Tseg

T M
cc

1,

,

(1 + ρ)Tseg ≤ T M
cc ,
(1 + ρ)Tseg ≥ T M
cc ,

(8b)

(8c)

where T M
tiles in a segment with expression

cc is the duration to deliver and compute all the M

T M
cc

(cid:44) scomM
Ccom

+

scptM
Ccpt

.

(9)

The value of 1/T M
of Ccom and Ccpt, which can reﬂect the resource rates.

cc monotonically increases with the increase

B. Resource-saturated and Resource-Unsaturated Regions

In the following, we show that the system may operate in a
resource-saturated or a resource-unsaturated region. From (8)
we can ﬁnd that the optimal solution can be divided into two
regions with a boundary line (1 + ρ)Tseg = T M
cc .

When (1 + ρ)Tseg ≥ T M

cc , the duration for computing and
transmitting the streamed tiles, i.e., (1+ρ)Tseg, is no less than
the required duration for computing and transmitting all the

C ∗

cc(ρ) =

1/T M
cc
(cid:124) (cid:123)(cid:122) (cid:125)
resource rates gain

· (1 + ρ)Tseg
(cid:123)(cid:122)
(cid:125)
(cid:124)
duration gain

,

term corresponds to a resource rates gain. The
The ﬁrst
second term corresponds to a duration gain, which comes
from the fact that the increase of ρ increases the duration for
computing and communication Tcc(ρ). We can observe that the
increase of ρ can be equivalently transformed into the increase
of resource rates for improving the CC capability. Besides,
from (9) we can ﬁnd that either increasing the transmission rate
Ccom or the computing rate Ccpt can provide resource rates
gain. This indicates that different combinations of computing
and transmission rates can achieve the same resource rates
gain.

To visualize the impact of ρ in the two regions in term
of CC capability, in Figure 5 we provide values of C ∗
cc(ρ)
obtained from (8c). Speciﬁcally, consider the point “P” in the
resource-unsaturated region. To achieve the resource-saturated
region, we can see that increasing the DoP by 0.7 is equivalent
to increasing 1/T M

cc by 0.27.

2) Degrade the Average-DoO: From (3), we can see that
the increase of DoP decreases the duration for observation and
then degrades the average-DoO.

3) Overall Impact: In the resource-unsaturated region, the
impact of DoP is complicated. On the one hand, it improves
the CC capability. On the other hand, it degrades the average-
DoO. Generality speaking, the overall impact depends on if
the QoE is dominated by the increment of CC capability or
the reduction of average-DoO.

7

our tests, the average number of tiles in a FoV is Nfov = 33.
To gain useful insight, we assume that all users have identical
DoP requirement for all videos, ranging from 0 to 80%. Given
DoP and 1/T M
cc , the maximized CC capability C ∗
cc(ρ) can be
obtained from (8c). Then, given C ∗
cc(ρ) and predicted time
series of positions, the streamed tiles can be determined by
scheme (b) in Section IV-C. Finally, QoE is ﬁrst calculated
from (5), then averaged over the testing set.

In Figure 6, we show the average QoE achieved by two
predictors versus DoP and the assigned resource rates. We can
observe that the impact of DoP in the resource-unsaturated
region depends on the predictor and the assigned resource
rates. For the no-motion predictor, as shown in Figure
6a, regardless of the assigned resource rates, the increase
of DoP slightly improves the QoE. For the tailored
position-only predictor, as shown in Figure 6b, when
assign high resource rates, the impact of DoP is not obvious,
when assign less resource rates, the impact of DoP is more
complicated.

To further understand how the ﬁnal QoE is affected by the
DoP and why the impact also depends on the predictor in the
resource-unsaturated region, we consider one case when the
resource rates 1/T M
cc = 0.17 as an example, to investigate how
the CC capability C ∗
cc(ρ), average-DoO D(ρ), and average
QoE is effected by DoP ρ. As shown in Figure 7. For the
no-motion predictor, we observe that the increase of DoP
increases the maximized CC capability C ∗
cc(ρ) and degrades
the average-DoO D(ρ). Since the degradation of average-DoO
is relative small, the QoE is dominated by the increase of CC
capability. For the tailored position-only predictor,
the variation of average-DoO is relative high, then the QoE is
dominated by the variation of average-DoO. Besides, we can
ﬁnd that for different predictors, the sensitivity of average-
DoO in terms of DoP is different. When a predictor is more
sensitive, e.g., tailored position-only predictor, the
QoE is more likely dominated by the average-DoO. When
a predictor is more robust to the variation of DoP, e.g., the
no-motion predictor, the QoE is more likely dominated by
the variation of CC capability. This is the reason why the
impact of DoP also depends on the predictor. In practice, the
DoP are heterogeneous rather than identical. This calls for
predictors that have strong robustness to the variation of DoP.

VIII. CONCLUSION

In this paper, we investigated the impact of privacy on
the VR video streaming system. We ﬁrst collected a privacy
dataset, veriﬁed that users indeed have privacy requirements.
Then, we employed duration optimization and analysis of the
obtained closed-form solution as tools, to ﬁnd the relation
between DoP and QoE. When DoP is considered, a predictor
with variable length of input and output is more suitable.
We found a resource-saturated region where DoP has no
impact and a resource-unsaturated region where DoP has
contradictory impact on the QoE. The increase of DoP on
the one hand improves the CC capability, on the other hand,
impact depends
it degrades the average-DoO. The overall
on which factor the QoE is dominated. Simulation with two

Fig. 5: Resource-saturated and resource-unsaturated regions.

VII. SIMULATION AND NUMERICAL RESULTS

In this section, we show the overall impact of DoP on QoE

via simulation and numerical results.

First we consider the prediction task on a real dataset
[5], where 300 traces of head movement positions from 30
users4 watching 10 VR videos are used for training and
testing predictors. The ratio of training and testing sets is 8:2.
We use two predictors, position-only and no-motion
predictors, which achieve the state-of-the-art accuracy in the
dataset, according to tests in [22]. The position-only
predictor employs a sequence-to-sequence LSTM-based ar-
chitecture, which only exploits the time series of past head
movement positions as input, to predict the time series of
future positions [22]. Note that the predictor does not consider
the time required for computing and communication as well as
the degree of privacy. To reserve time for computing and com-
munication and satisfying the DoP requirement, we tailor the
predictor as follows. Set the distance between the observation
and prediction windows as Tcc(ρ), set the durations of ob-
servation window, prediction window for training, prediction
window for inference (i.e., testing) as Tobw(ρ), Tobw(ρ), Tseg,
respectively, as shown in Figure 4a. We refer to the predictor as
tailored position-only predictor. Other details and
hyper-parameters of the tailored predictor is the same as the
position-only predictor [22]. The no-motion predictor
assumes no head movement and simply uses the last position
in the observation window as the predicted time series of future
positions [22].

Since one value of 1/T M

cc can represent various combina-
tions of computing and transmission rates, we directly set the
range of 1/T M
cc to reﬂect the variation of resources rates. The
procedure to obtain the mapping from the conﬁgured resources
to 1/T M
cc can be found in the supplementary material, for the
interested readers.

The playback duration of a segment is set as Tseg = 1 s [23].
The total number of tiles is M = 200 [5]. The size of FoVs
are modeled by 100◦ × 100◦ circles [22], [24]. According to

4The original dataset contains the traces of 50 users. According to the
analysis in [19], [22], the traces of the ﬁrst 20 users may have some mistakes,
thus we only use the traces of the other 30 users.

8

(a) No-motion predictor

(a) No-motion predictor

(b) Tailored position-only predictor

(b) Tailored position-only predictor

Fig. 6: Average QoE v.s. resource rates and DoP

Fig. 7: Average QoE, CC capability, and DoO v.s. DoP,
1/T M

cc = 0.17.

predictors validated the analysis and showed that the impact
of DoP on QoE can also be effected by other inﬂuence factors,
e.g., the robustness of a predictor to the variation of DoP and
the assigned resource rates.

REFERENCES

[1] iLab. Cloud VR network solution whitepaper. Technical report, Huawei

Technologies CO., LTD., 2018.

[2] Feng Qian, Lusheng Ji, Bo Han, and Vijay Gopalakrishnan. Optimizing
the
360 video delivery over cellular networks.
5th Workshop on All Things Cellular: Operations, Applications and
Challenges, ATC ’16, page 1–6, New York, NY, USA, 2016. Association
for Computing Machinery.

In Proceedings of

[3] Mohammad Hosseini and Viswanathan Swaminathan. Adaptive 360
VR video streaming: Divide and conquer. In 2016 IEEE International
Symposium on Multimedia (ISM), pages 107–110, 2016.

[4] Mark Roman Miller, Fernanda Herrera, Hanseul Jun, James A Landay,
and Jeremy N Bailenson. Personal identiﬁability of user tracking data
during observation of 360-degree VR video. Scientiﬁc Reports, 10(1):1–
10, 2020.

[5] Wen-Chih Lo, Ching-Ling Fan, Jean Lee, Chun-Ying Huang, Kuan-Ta
Chen, and Cheng-Hsin Hsu. 360° video viewing dataset in head-mounted
virtual reality. In Proceedings of the 8th ACM on Multimedia Systems
Conference, MMSys’17, page 211–216, New York, NY, USA, 2017.
Association for Computing Machinery.

[6] Mai Xu, Yuhang Song, Jianyi Wang, MingLang Qiao, Liangyu Huo,
and Zulin Wang. Predicting head movement in panoramic video: A
IEEE transactions on pattern
deep reinforcement learning approach.
analysis and machine intelligence, 41(11):2693–2708, Nov 2019.

[7] Xavier Corbillon, Francesca De Simone, and Gwendal Simon. 360-
degree video head movement dataset. In Proceedings of the 8th ACM
on Multimedia Systems Conference, MMSys’17, page 199–204, New
York, NY, USA, 2017. Association for Computing Machinery.

[8] Ching-Ling Fan, Wen-Chih Lo, Yu-Tung Pai, and Cheng-Hsin Hsu. A
survey on 360° video streaming: Acquisition, transmission, and display.
ACM Comput. Surv., 52(4), August 2019.

[9] Chenge Li, Weixi Zhang, Yong Liu, and Yao Wang. Very long term
In 2019
ﬁeld of view prediction for 360-degree video streaming.
IEEE Conference on Multimedia Information Processing and Retrieval
(MIPR), pages 297–302. IEEE, 2019.

[10] Precision eye tracking, 2021.

https://enterprise.vive.com/us/product/

vive-pro-eye/.

[11] C. Fan, S. Yen, C. Huang, and C. Hsu. Optimizing ﬁxation prediction
using recurrent neural networks for 360◦ video streaming in head-
mounted virtual reality. IEEE Trans. Multimedia, 22(3):744–759, March
2020.

[12] Yanyu Xu, Yanbing Dong, Junru Wu, Zhengzhong Sun, Zhiru Shi, Jingyi
Yu, and Shenghua Gao. Gaze prediction in dynamic 360 immersive
In proceedings of the IEEE Conference on Computer Vision
videos.
and Pattern Recognition, pages 5333–5342, 2018.

[13] Fang-Yi Chao, Cagri Ozcinar, Chen Wang, Emin Zerman, Lu Zhang,
Wassim Hamidouche, Olivier Deforges, and Aljosa Smolic. Audio-
visual perception of omnidirectional video for virtual reality applica-
tions. In 2020 IEEE International Conference on Multimedia & Expo
Workshops (ICMEW), pages 1–6, 2020.

[14] 3GPP. Extended reality (XR) in 5G, 2020. 3GPP TR 26.928 version

16.0.0 release 16.

[15] NVIDIA. NVIDIA CloudXR cuts the cord for VR, raises the bar for

020%40%60%80%0.10.150.20.250.360%65%70%75%80%85%020%40%60%80%0.10.150.20.250.345%50%55%60%65%70%75%80%9

AR. https://blogs.nvidia.com/blog/2020/05/14/cloudxr-sdk.

[16] Xing Wei, Chenyang Yang, and Shengqian Han. Prediction, communi-
cation, and computing duration optimization for VR video streaming.
IEEE Transactions on Communications, 69(3):1947–1959, 2021.
[17] C. Perfecto, M. S. Elbamby, J. Del Ser, and M. Bennis. Taming
the latency in multi-user VR 360°: A QoE-aware deep learning-aided
multicast framework. IEEE Trans. Commun., 68(4):2491–2508, 2020.
[18] Dilip Bethanabhotla, Giuseppe Caire, and Michael J Neely. Adaptive
video streaming for wireless networks with multiple users and helpers.
IEEE Transactions on Communications, 63(1):268–285, 2014.

[19] Miguel Fabi´an Romero Rond´on, Lucile Sassatelli, Ram´on Aparicio-
Pardo, and Fr´ed´eric Precioso. A uniﬁed evaluation framework for head
motion prediction methods in 360° videos. In Proceedings of the 11th
ACM Multimedia Systems Conference, MMSys ’20, page 279–284, New
York, NY, USA, 2020. Association for Computing Machinery.

[20] Junni Zou, Chenglin Li, Chengming Liu, Qin Yang, Hongkai Xiong,
and Eckehard Steinbach. Probabilistic tile visibility-based server-side
rate adaptation for adaptive 360-degree video streaming. IEEE Journal
of Selected Topics in Signal Processing, 14(1):161–176, 2020.

[21] Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. Sequence to sequence

learning with neural networks. arXiv 1409.3215v3, 2014.

[22] Miguel Romero.

Analysis of head motion prediction in virtual
reality. https://gitlab.com/miguelfromeror/head-motion-prediction/tree/
master/, 2020.

[23] Anahita Mahzari, Afshin Taghavi Nasrabadi, Aliehsan Samiei, and Ravi
Prakash. FoV-aware edge caching for adaptive 360◦ video streaming. In
Proceedings of the 26th ACM International Conference on Multimedia,
MM ’18, page 173–181, New York, NY, USA, 2018. Association for
Computing Machinery.

[24] Ching-Ling Fan, Jean Lee, Wen-Chih Lo, Chun-Ying Huang, Kuan-
Ta Chen, and Cheng-Hsin Hsu. Fixation prediction for 360◦ video
streaming in head-mounted virtual reality. In Proceedings of the 27th
Workshop on Network and Operating Systems Support for Digital Audio
and Video, NOSSDAV’17, page 67–72, New York, NY, USA, 2017.
Association for Computing Machinery.

