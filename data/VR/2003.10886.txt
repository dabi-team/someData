Assessment of Empathy in an Affective VR 
Environment using EEG Signals 

Maryam Alimardani 1*, Annabella Hermans 1 and Angelica M. Tinga 1, 2 

1  Department of Cognitive Science and Artificial Intelligence, Tilburg University, The Netherlands 
2  Department of Human Factors in Vehicle Automation, Institute for Road Safety Research, The Netherlands 

*  Correspondence: m.alimardani@uvt.nl 

Abstract:  With  the  advancements  in  social  robotics  and  virtual  avatars,  it  becomes  increasingly 
important that these agents adapt their behavior to the mood, feelings and personality of their users. 
One  such  aspect of  the  user  is  empathy.  Whereas many  studies measure  empathy  through  offline 
measures  that  are  collected  after  empathic  stimulation  (e.g.  post-hoc  questionnaires),  the  current 
study  aimed  to  measure  empathy  online,  using  brain  activity  collected  during  the  experience. 
Participants  watched  an  affective  360°  video  of  a  child  experiencing  domestic  violence  in  a  virtual 
reality  headset  while  their EEG signals were recorded. Results showed  a  significant  attenuation  of 
alpha, theta and delta asymmetry in the frontal and central areas of the brain. Moreover, a significant 
relationship between participants’ empathy scores and their frontal alpha asymmetry at baseline was 
found. These results demonstrate specific brain activity alterations when participants are exposed to 
an affective virtual reality environment, with the level of empathy as a personality trait being visible 
in  brain  activity  during  a  baseline  measurement.  These  findings  suggest  the  potential  of  EEG 
measurements for development of passive brain-computer interfaces that assess the user’s affective 
responses  in  real-time  and  consequently  adapt  the  behavior  of  socially  intelligent  agents  for  a 
personalized interaction. 

Keywords: Empathy; Affective computing; Brain activity; EEG asymmetry; Human-agent interaction 
(HAI); Virtual reality (VR), Passive brain-computer interface (BCI) 

1. Introduction 

We  are  currently  in  an  era  of  rapid  technological  advancements,  which  characterizes  itself  by 
technologies  that  merge  the  physical,  psychological  and  digital  spheres  [1].  New  technologies  are 
rapidly  arising  in  the  fields  of  artificial  intelligence,  robotics,  and  virtual  reality  (VR)  impacting  all 
disciplines and industries. With the emerging focus on human-centered innovation, more attention is 
directed  towards  socially  attentive  and  adaptive  agents  [2].  Future  robots  and  virtual  avatars  are 
expected to collaborate with humans in different social scenes and to display realistic, human-like and 
intelligent  behavior.  In  order  to  facilitate  social  interaction  between  humans  and  agents,  it  is  thus 
necessary for agents to ‘understand’ their user. This could be achieved by gaining an insight into the 
user’s affective state during the interaction, computing how the user is feeling, what mood s/he is in 
and how s/he is responding to an emotional situation. In the present study, the term affective state will 
be used when referring to emotion and mood-related causes.  

In  the  field  of  psychology,  affective state  has  been  found  to  have  an  influence on  our  memory, 
assessment,  judgement,  opinion,  expectations  and more  behavior-related factors  [3].  With the  use  of 

 
 
 
 
 
 
affective  computing  it  is  possible  to  capture  information  about  the  user’s  affective  state,  which  is 
considered to be essential for better communication.  

Conventional  approaches  have  estimated  the  affect  of  the  user  using  offline  measures  that  are 
collected  after  the  experience,  such  as  post-hoc  subjective  questionnaires  [4].  More  recently,  affect-
related information has been acquired online using facial and vocal recognition and eye-tracking data 
that are collected during the affective experience [5, 6]. There are also methods that estimate affective 
states online based on the user’s motor behavior, for instance, in the form of mouse and keyboard usage 
[7]. Moreover, recent trends show an increased interest toward physiological signals and bio-indices of 
affect captured by such measures as galvanic skin response, heart rate and facial muscle activity [8, 9] 
and brain activity measurements [10, 11]. The advantage of using physiological measurements is that 
wearable  sensors  can  record rich  and  precise  data  without  interruption,  with  no control  of the  user. 
Particularly  with  brain  activity  measurements,  previous  research  has  shown  that  real-time  systems 
such as passive brain-computer interfaces (BCIs) can extract mental and emotional states from the user 
and employ this information to either adapt the interface or provide feedback to the user to improve 
performance [12, 13]. Similarly, with the passive and continuous neurophysiological input from these 
BCIs, agents can adapt their behavior based on the human's affective state and enhance engagement 
during  the  interaction.  Thus,  it  is  important  to  first  identify  neuro-correlates  of  specific  affective 
responses extracted from online recordings as a benchmark for development of passive BCIs.   

In  addition  to  the  user’s  affective  state,  estimating  a  user’s  personality  traits  can  also  improve 
human-agent interaction (HAI). One example of a personality trait that could influence an individual’s 
behavior  in social  interactions  is  empathy.  Empathy  is  defined  as  having  a  similar  affective  state  as 
another person as a result of the perception of the other person’s situation [14]. There are two types of 
empathy,  1) trait  empathy,  a  person’s  overall  level  of empathy,  and  2)  state  empathy,  the  empathic 
concern towards a person or stimulus at a particular moment. Through empathy people can share their 
emotions and create a better understanding about the way of thinking of others. Both trait and state 
empathy  can  be  divided  into  two  different  systems  with  different  neural  underpinnings,  affective 
(emotional) empathy and cognitive empathy [15]. For example, one instance of affective (emotional) 
empathy  is  the  feeling  of  personal  discomfort  in  response  to  another  person’s  suffering.  Cognitive 
empathy refers to the ability to understand the cognitive perspective and the state of mind of another 
individual. In the current study, we focus on trait empathy and affective empathy.  

Previous brain imaging studies have investigated the neural basis of empathy in the brain. A large-
scale  lesion  study  with  123  participants  suffering  from  a  neurodegenerative  disease  used  structural 
MRI  brain  volume  measurements and  found  empathic  concern to  be regulated  in  the  right anterior 
temporal and medial frontal regions of the brain [16]. Another lesion study demonstrated that patients 
with brain damage in the prefrontal area of the brain, especially in the right ventromedial cortex, were 
significantly impaired in empathy compared to patients with posterior lesions and healthy participants 
[17]. This suggests that empathy is regulated mainly in the frontal and temporal brain regions in the 
right hemisphere.  

Researchers have also conducted studies measuring empathy in the brain with EEG. EEG has an 
advantage  for  HAI  because  the  brain  activity  measurement  could  be  seamless,  unobtrusive  and  be 
integrated  and  embedded  in  devices  such  as  VR  headsets.  In  most  of  EEG  research  investigating 
empathy, a painful stimulus is utilized to evoke empathy towards another person being in pain. For 
instance, by showing participants images of a hand in a painful situation or in a neutral situation, Mu 
et al. [18] found increased theta synchronization and increased alpha desynchronization in respectively 
the  frontal/central  and  the  central/parietal  brain  regions.  Even  when  participants  were  told  that  a 
patient suffering from a neurological deficit would experience pain from a non-painful stimulus and 
vice versa, power in the alpha band was still found to be suppressed particularly in the frontocentral 
regions  for the  non-painful  stimuli  that  were supposedly  painful  for  the  patient  [19]. A comparable 
study on  brain  responses  to  the  pain  of  others  used  an  immersive CAVE  (CAVE Automatic  Virtual 
Environment)  environment  to  display  a  virtual  avatar,  which  was  either  sitting  on  a  chair,  moving 
normally or moving and expressing pain. Participants showed greater alpha suppression in the central 

and temporal brain area for the avatar that was expressing pain versus the avatar that was just moving 
or was sitting still (neutral). Therefore, alpha suppression could not be explained by movements, but 
was due to the pain expressions of the avatar [20].  

Other studies analyzed EEG power by comparing power in frequency bands over the two cerebral 
hemispheres  of  one  individual  [21].  Most  often,  this  is  done  by  computing  the  power  difference 
between  the  left  and  right  hemispheres.  An  advantage  of  this  method  is  that  it  counterbalances 
individual  differences  such  as  skull  thickness.  In  the  context  of  emotion,  a  large  body  of  literature 
examined EEG alpha power in the frontal area of the brain, which is generally associated with a state 
of  mind  that  is  awake  but  relaxed  [22, 23].  Since  the  alpha  band  is  found  to  be  inhibitory,  a  greater 
cortical activation is equivalent to a decrease in alpha power [21]. A difference in alpha power between 
the  two  hemispheres  (asymmetry)  in  the  frontal  area  was  found  to  be  involved  in  emotion  and 
motivation [24]. Very generally stated, a larger left frontal asymmetry is related to positive affect and a 
larger right frontal asymmetry is related to negative affect.  

Tullett  et  al.  [24]  hypothesized  that  empathy  is  linked  to right  frontal  EEG  asymmetry  because 
empathy evokes a feeling of personal distress as a consequence of sharing the pain or sorrow of other 
people. They recorded EEG signals while participants were viewing images of charity organizations 
and  collected  self-reported  sadness,  personal  distress,  perspective  taking  and  empathic  concern 
towards the images. Results showed a positive correlation between right frontal alpha asymmetry and 
empathic  concern,  mediated  by  feelings  of  sadness.  However,  in  the  parietal  brain  area,  a  reversed 
correlation was found with the right parietal asymmetry being negatively correlated to empathy. This 
could  indicate that the right-sided asymmetry  is  limited  to the  frontal region  of  the  brain. This  also 
corresponds with the lesion studies discussed before.  

The current study was similar to that of Tullett et al. [24] but instead of using still images of charity 
organizations, an immersive 360° VR video of the same nature was used to induce empathic concern. 
The reason for this selection of stimuli was two-fold; 1) the VR video was presented in a head-mounted 
display  and  therefore  any  possible  visual  distraction  from  the  environment  was  avoided,  2)  it  was 
speculated that the immersive VR experience was associated with a higher sense of presence during 
stimulus  presentation  and  hence  would  make  the  empathic  responses  more  pronounced  [25]. 
Moreover, in the previous work, empathy was investigated as an affective state, whereas the current 
study included empathy as a personality trait, measured by a questionnaire at the baseline.  

Two research questions are central to the current paper. First, whether an empathy-inducing VR 
video influences brain activity measurements, and second, whether there is a correlation between the 
self-reported level of empathy (personality trait) and the EEG asymmetry in the presence and absence 
of empathy-inducing stimuli. Based on the research discussed above, we expected to find effects in the 
frontal and central areas of the brain, specifically in the asymmetry of the alpha band. We also expected 
empathic  participants  to  have  a  stronger  EEG  response  to  the  stimulus  versus  less  empathic 
participants [26]. 

2. Materials and Methods 

2.1. Participants 

Fifty-two university students (33 female, age M = 20.3, SD = 2.3) were recruited and received 1.5 
course credit for their participation. Participants were included if they were native Dutch speakers and 
if they reported no current cardiovascular or neurological disorder. The study was approved by the 
Research Ethics Committee of Tilburg School of Humanities and Digital Sciences. 

2.2. Materials and apparatus 

To  measure  brain  activity,  the  B-Alert  X10  Electroencephalogram  was  used  including  nine 
channels  covering  the  frontal,  central  and  parietal  areas  of  the  brain  following  the  10/20  system  of 
electrode placement (F3, Fz, F4, C3, Cz, C4, P3, POz and P4). In addition, two sensors were placed on 

 
the mastoid bones behind both ears as reference electrodes to cancel the noise from the data. The EEG 
signals  were  recorded  continuously  throughout  the  experiment  at  256  samples  per  second  by  the 
software  program  Acqknowledge  4.4  (BIOPAC  Systems  Inc.)  running  on  a  computer  dedicated  to 
collecting the  EEG data. Care  was  taken  to  keep  the scalp-electrode  impedance  below  40  kΩ  for all 
electrode sites using conductive gel. 

The self-reported level of empathy was measured using the Toronto Empathy Questionnaire [27] 
with  a 7-point  Likert  scale.  This questionnaire  consists  of sixteen  empathy-related questions  such  as 
“when someone else is feeling excited, I tend to get excited too” or “it upsets me to see someone being 
treated disrespectfully.”  

The stimuli were displayed in VR using the HTC-Vive headset (resolution: 1080 x 1200 pixels per 

eye; refresh rate: 90 Hz, field of view: 110 degrees). 

2.3. Stimuli 

For this experiment, two 360 degrees VR videos were used. The first video was used to make the 
participant familiar with VR environments removing a VR novelty effect. This video [28] (2.18 minutes) 
contained several sceneries of the world in a 360 degrees view. The second video [29] (4.43 minutes), 
which  was  used  to  induce  empathy,  was  produced  by  the charity organization ‘Terre des Hommes’ 
and illustrated the life of a Kenyan girl who was being abused as a domestic slave. The video contained 
five scenes in which the girl did housework as a slave, was scolded and punished for her mistakes, and 
even got sexually abused by the father of the family.  

2.4. Procedure 

The experiment was conducted in a silent research lab on campus. The participants sat down in a 
comfortable chair in front of a computer screen and received an explanation about the nature of the 
experiment. After signing the informed consent form, participants filled out the empathy questionnaire 
and additional demographic questions using Qualtrics [30]. Next, the EEG sensors were placed on the 
participants’ head and the collection of EEG data began. The VR headset was then placed over the EEG 
sensor  strap  and  the  stimuli  were  presented.  The  setup  of  the  EEG  device  together  with  the  head 
mounted display is shown in Figure 1.  

The experiment consisted of four phases all administered in the VR headset: 1) Familiarization, 2) 
Pre-baseline (Pre-b), 3) VR experience (VRX) and 4) Post-baseline (Post-b). In the Familiarization phase 
participants  first  explored  the  VR  environment  with  the  familiarization  video.  In  the  Pre-b  phase, 
participants were asked to look at a fixation cross for 3 minutes while their baseline EEG was being 
recorded. In the VRX phase, participants watched the empathy-inducing video and EEG signals were 
obtained. Finally, in the Post-b phase, another 3 minutes of baseline EEG was collected. Participants 
were instructed to sit as still as possible to avoid noise in the EEG signals but were allowed to move 
their head and look around the VR environment. Once the experiment was finished, all sensors and the 
VR headset were removed and participants were debriefed. 

2.5. Data analysis 

The FieldTrip-lite [31] EEG processing toolbox (version 31-08-2018) in MATLAB 9.4 (R2018a) was 
used  to  process  all  EEG  data.  First,  the  quality  of  the  EEG  data  was  visually  inspected  for  each 
individual participant by three researchers using the quality check reports provided by FieldTrip. In 
this way noisy data files were removed from further analysis.  

The remaining EEG recordings were bandpass filtered between 0.5 and 50 Hz to remove all high 
and low frequency components. Then the data was segmented into the three phases, Pre-b, VRX and 
Post-b. The Familiarization phase was excluded from the data analysis because it was only meant for 
training purposes. 

Figure 1. Experimental setup; the participant is watching an affective 360° video in a VR headset while 
EEG signals are recorded. 

The remaining EEG recordings were bandpass filtered between 0.5 and 50 Hz to remove all high 
and low frequency components. Then the data was segmented into the three phases, Pre-b, VRX and 
Post-b. The Familiarization phase was excluded from the data analysis because it was only meant for 
training  purposes.  A  Fast  Fourier  Transform  was  applied  to  the  EEG  segments  to  compute  power 
spectra and the mean power was obtained for five frequency bands: Delta (0.5 - 3.9), Theta (4 - 7.9), 
Alpha  (8  -  12.9), Beta  (13  -  27.9)  and  Gamma  (28 -  50).  For  every  participant,  an  array  of  mean  EEG 
powers  was  constructed  for  all  nine  electrodes,  in  five  frequency  bands  during  three  phases.  The 
asymmetry  powers  were  then  computed  by  subtracting  the  left  channel  from  the  right  channel  in 
frontal, central and parietal areas (i.e. F4 – F3, C4 – C3, and P4 – P3) for each frequency band in each 
phase.  

The  data  was  further  analyzed  in  R  [32].  Since  the  EEG  asymmetry  data  was  not  normally 
distributed, non-parametric Kruskall-Wallis tests were used to test if there was a significant main effect 
between  the  three  phases. This was  tested  in  the  three  brain  areas  and  for  all  five  frequency  bands. 
Pairwise-comparisons  were carried  out  using Wilcoxon  signed-rank tests  in those cases  where  main 
effects were found.  

As  for  the  empathy  questionnaire,  first  participants’  answers  to  the  7-point  Likert  scale  were 
numerically converted, where never = 0, almost never = 1, rarely = 2, sometimes = 3, often = 4, very often 
= 5 and always = 6. From the total of 16 questions, half had to be reverse-coded because higher scores 
indicated less empathy. Next, the sum of scores from all 16 questions was computed and assigned as 
the total empathy score.  

In order to identify the relationship between EEG measurements and subjective responses from 
the  participants,  a  regression  analysis  was  performed  on  asymmetry  powers  and  empathy  scores. 
Before performing regression analyses, Cook’s distance was used to find the influential observations, 
where the following formula determined the cutoff threshold for the outliers: 4/N. This was computed 
for the Pre-b phase to investigate whether a relationship existed before being exposed to the stimulus. 
It  was  also  computed  for  the  VRX  phase  to  investigate  the  relationship  while  the  participants  were 
watching the immersive VR video. Moreover, the difference between the Pre-b and the VRX phase was 
computed  to  investigate  whether  participants  with  a  higher  empathy  score  showed  stronger  brain 
activity responses to the VR video compared to participants with a lower empathy score. 

 
 
 
 
 
3. Results 

After the experimental phase, six participants were excluded due to not correctly following the 
procedure of the experiment, such as speaking during the video, or technical issues in the experimental 
procedure. Based on the quality check of the EEG data, another six participants were excluded from 
the analysis. The data from the remaining 40 participants (14 male, 26 female, age M = 20.53, SD = 2.14) 
were used for further analysis. Figure 2 visualizes the acquired asymmetry powers over the 5 frequency 
bands in the frontal (Figure 2a), central (Figure 2b) and parietal (Figure 2c) areas of the brain in each 
phase of the experiment. 

The main effects for the differences between the Pre-b, VRX and Post-b phases were computed for 
all frequency bands in all brain areas, shown in Table 1. In the frontal brain area, a significant change 
in the theta and alpha asymmetry was found over the three phases. In the central brain area a significant 
change in delta and theta asymmetry was found, whereas in the parietal area of the brain, no significant 
changes were found in any of the frequency bands. Effect-size was computed using the Phi coefficient 
(φ), which is the square root of Chi-Squared (χ2) divided by the number of observations (√(χ2/n)). The 
effect-size  is  considered  large  when  it  is  .5  or  higher,  which  was  solely  the  case  for  frontal  alpha 
asymmetry power (φ = .66). Since in all measurements, the number of observations n was equivalent, 
the value of Chi-Squared in Table 1 is representative for comparison of effect-sizes between different 
locations and frequency bands.  

To investigate in which specific phases (Pre-b, VRX and Post-b) effects occurred, a post-hoc test 
was conducted on the alpha and theta band in the frontal area and for the delta and theta band in the 
central area (Table 2) 

(a)

(b)

* p < .05 
** p < .01

Figure 2. Average asymmetry values for five frequency bands in (a) frontal, (b) central, and (c) 
parietal areas. Error bars represent the standard error of the mean. 

(c)

 
TABLE 1. Results of the Kruskall-Wallis tests testing the difference 

between the three experimental phases for each brain area and frequency 

band (significant findings marked in bold). 

Frequency 

Frontal area 

Central area 

Parietal area 

band 

Delta 

Theta 

Alpha 

Beta 

Gamma 

X2(2) 

0.542 

9.512 

1.222 

0.553 

p 

.762 

.009 

.543 

.758 

17.175 

<.001 

X2(2) 

8.320 

9.348 

5.948 

0.805 

1.136 

p 

.016 

.009 

.051 

.669 

.567 

X2(2) 

4.644 

2.625 

3.363 

1.715 

0.285 

p 

.098 

.269 

.186 

.424 

.867 

Fig. 3.  Frontal  asymmetry  values  for  five  frequency  bands.  *  p  <  .05,  
** p < .01. Error bars represent the standard error of the mean.  

p 

p 

p 

X2(2) 

X2(2) 

X2(2) 

Frontal 

Central 

Frontal area 

Central area 

Parietal area 

Brain area  Freq. band 

(delta  and 

Pre-b vs. 
VRX (p) 

.068 
.001 
.049 
.034 

Theta 
Alpha 
Delta 
Theta 

.009 
<.001 
.021 
.011 

Theta 
Alpha 
Delta 
Theta 

4.644 
2.625 
3.363 
1.715 
0.285 

8.320 
9.348 
5.948 
0.805 
1.136 

.762 
.009 
<.001 
.543 
.758 

0.542 
9.512 
Freq. 
17.175 
1.222 
band 
0.553 

Delta 
Theta 
Brain 
Alpha 
Beta 
area 
Gamma 

VR vs. 
VRX vs.
Post-b (p) 
.009 
<.001 
.021 
.011 

Pre-b vs. 
Post- b (p) 
.214 
.407 
.413 
.470 

.098 
.269 
Pre-b vs. 
.186 
.424 
Post- b 
.867 
(p) 
.214 
.407 
.413 
.470 

Table 1. Results of the Kruskall-Wallis tests testing the difference between the three experimental 
phases for each brain area and frequency band (significant p-values marked in bold). 

Table 2. Results of the pairwise comparisons between the three experimental phases using Wilcoxon 
rank sum test (significant p-values marked in bold). 

In  the  frontal  brain  area,  a  significant  change  in  the 
theta and alpha asymmetry was found over the three phases. 
In  the  central  brain  area  a  significant  change  in  delta  and 
theta  asymmetry  was  found, whereas in the parietal area of 
the  brain,  no  significant  changes  were  found  in  any  of  the 
frequency  bands.  Effect-size  was  computed  using  the  Phi 
TABLE 1. Results of the Kruskall-Wallis tests testing the difference 
coefficient,  which  is  the  square  root  of  Chi-Square  divided 
between the three experimental phases for each brain area and frequency 
band (significant findings marked in bold). 
by  the  number  of  observations  (√(X2/n)).  Because  in  all 
Frequency 
measurements,  the  number  of  observations  was  equivalent, 
band 
the  Chi-Square  value  is  representative  for  the  effect-size. 
TABLE 2. Results of the pairwise comparisons between the three 
The  effect-size  is  considered  large  when  it  is  .5  or  higher, 
experimental phases using Wilcoxon rank sum test (significant 
.016 
which  was  solely  the  case  for  frontal  alpha  asymmetry 
findings marked in bold) 
.009 
power  (φ  =  .66).  To  investigate  in  which  specific  phases 
VR vs. 
.051 
(Pre-b,  VRX  and  Post-b)  effects  occurred,  a  post-hoc  test 
.669 
Post-b (p) 
was  conducted  on  the  alpha  and  theta  band  in  the  frontal 
.567 
area  and  for  the  delta  and  theta  band  in  the  central  area 
Frontal 
In  the  frontal  brain  area,  a  significant  change  in  the 
(Table 2). 
theta and alpha asymmetry was found over the three phases. 
Central 
In  the  central  brain  area  a  significant  change  in  delta  and 
TABLE 2. Results of the pairwise comparisons between the three 
theta  asymmetry  was  found, whereas in the parietal area of 
experimental phases using Wilcoxon rank sum test (significant findings 
the  brain,  no  significant  changes  were  found  in  any  of  the 
marked in bold) 
In  the  frontal  (theta  and  alpha  bands)  and 
frequency  bands.  Effect-size  was  computed  using  the  Phi 
Pre-b vs. 
theta  bands)  brain  areas, 
central 
coefficient,  which  is  the  square  root  of  Chi-Square  divided 
VRX (p) 
significant changes were found from the Pre-b to the 
by  the  number  of  observations  (√(X2/n)).  Because  in  all 
.068 
VRX phase and from the VRX phase to the Post-b. 
measurements,  the  number  of  observations  was  equivalent, 
.001 
the  Chi-Square  value  is  representative  for  the  effect-size. 
The  only  exception  was  in  the  theta  asymmetry  in 
.049 
The  effect-size  is  considered  large  when  it  is  .5  or  higher, 
the  frontal  area  of  the  brain  where  a  significant 
.034 
which  was  solely  the  case  for  frontal  alpha  asymmetry 
change  was only  found  from  the  VRX phase  to  the 
power  (φ  =  .66).  To  investigate  in  which  specific  phases 
In  the  frontal  (theta  and  alpha  bands)  and  central 
Post-b.  
(Pre-b,  VRX  and  Post-b)  effects  occurred,  a  post-hoc  test 
(delta and theta bands) brain areas, significant changes were 
Regression  analyses  were  next  conducted 
was  conducted  on  the  alpha  and  theta  band  in  the  frontal 
found from the Pre-b to the VRX phase and from the VRX 
frontal  alpha  asymmetry  powers 
for 
only 
In the frontal (theta and alpha bands) and central (delta and theta bands) brain areas, significant 
area  and  for  the  delta  and  theta  band  in  the  central  area 
phase  to  the  Post-b.  The  only  exception  was  in  the  theta 
because  of  the  greatest  effect-size.  For  the  Pre-b 
changes were found from the Pre-b to the VRX phase and from the VRX phase to the Post-b. The only 
(Table 2). 
asymmetry  in  the  frontal  area  of  the  brain  where  a 
and  the  VRX  phases,  the  frontal  alpha  asymmetry 
exception was in the theta asymmetry in the frontal area of the brain where a significant change was 
significant  change  was  only  found  from  the  VRX  phase  to 
powers  were  tested  for  a linear regression with  the 
only found from the VRX phase to the Post-b.  
the Post-b.  
TABLE 2. Results of the pairwise comparisons between the three 
empathy  scores.  Also,  the  difference  between  the 
Regression analyses were next conducted only for the frontal alpha asymmetry powers as this was 
Regression analyses were next conducted only for the 
experimental phases using Wilcoxon rank sum test (significant findings 
VRX and the Pre-b was computed and tested for a 
the only significant effect with a large effect size. For the Pre-b and the VRX phases, the frontal alpha 
marked in bold) 
frontal  alpha  asymmetry  powers  because  of  the  greatest 
linear  regression  with  the  empathy  scores.  After 
asymmetry  powers  were  tested  for  a  linear regression  with the  empathy  scores.  Also, the  difference 
Pre-b vs. 
effect-size.  For  the  Pre-b  and  the  VRX  phases,  the  frontal 
VRX (p) 
cook’s  distance  detection,  respectively  38,  39  and 
between the VRX and the Pre-b (VRX – Pre-b) was computed and tested for a linear regression with the 
alpha asymmetry powers were tested for a  linear regression 
.068 
37 participants remained for the analysis of the Pre-
empathy scores. After Cook’s distance detection, respectively 38, 39 and 37 participants remained for 
with  the  empathy  scores.  Also,  the  difference  between  the 
.001 
the analysis of the Pre-b, VRX and VRX – Pre-b phases. The statistical results of the linear regression 
b,  VRX  and  VRX  –  Pre-b  phases.  The  statistical 
VRX  and  the  Pre-b  was  computed  and  tested  for  a  linear 
.049 
analyses are shown in Table 3. Only in the Pre-b phase, a significant relationship was found between 
regression  with  the  empathy  scores.  After  Cook’s  distance 
results of  the  linear regression analyses are  shown 
.034 
detection,  respectively  38,  39  and  37  participants  remained 
empathy and frontal alpha asymmetry, as shown in Figure 3. 
in Table 3. 
for the analysis of the Pre-b, VRX and VRX – Pre-b phases. 
In  the  frontal  (theta  and  alpha  bands)  and  central 
The  statistical  results  of  the  linear  regression  analyses  are 
TABLE 3. Results of the regression analyses testing the relationship 
(delta and theta bands) brain areas, significant changes were 
between  the  frontal  alpha  asymmetry  in  each  experimental  phase 
shown in Table 3. 
found from the Pre-b to the VRX phase and from the VRX 
and empathy (significant findings marked in bold). 
phase  to  the  Post-b.  The  only  exception  was  in  the  theta 
asymmetry  in  the  frontal  area  of  the  brain  where  a 
Phases 
β 
significant  change  was  only  found  from  the  VRX  phase  to 
-5.687 
Pre-b 
the Post-b.  
-0.401 
VRX 
Regression analyses were next conducted only for the 
2.502 
VRX – Pre-b 
frontal  alpha  asymmetry  powers  because  of  the  greatest 
In  the  Pre-b  phase,  a  significant  relationship 
effect-size.  For  the  Pre-b  and  the  VRX  phases,  the  frontal 
was  found  between  empathy  and  frontal  alpha 
alpha asymmetry powers were tested for a  linear regression 
asymmetry, as shown in Fig. 6.  
with  the  empathy  scores.  Also,  the  difference  between  the 
VRX  and  the  Pre-b  was  computed  and  tested  for  a  linear 
regression  with  the  empathy  scores.  After  Cook’s  distance 
detection,  respectively  38,  39  and  37  participants  remained 
for the analysis of the Pre-b, VRX and VRX – Pre-b phases. 
The  statistical  results  of  the  linear  regression  analyses  are 
shown in Table 3. 

Table 3. Results of the regression analyses testing the relationship between the frontal alpha 
asymmetry in each experimental phase and empathy (significant findings marked in bold). 

Pre-b vs. 
Post- b (p) 
.214 
.407 
.413 
.470 

VR vs. 
Post-b (p) 
.009 
<.001 
.021 
.011 

4.64
4 
2.62
5 
3.36
3 
1.71
5 
0.28
5 

T(df) 
-2.619(36) 
-0.242(37) 
1.152(35) 

b 
67.507 
66.954 
68.888 

Theta 
Alpha 
Delta 
Theta 

p 
.013 
.810 
.257 

Brain area  Freq. band 

Parietal area 

the 

Central 

Frontal 

X2(2) 

.867 

.098 

.269 

Fig. 3.  Frontal  asymmetry  values  for  five  frequency  bands.  *  p  <  .05,  
** p < .01. Error bars represent the standard error of the mean.  

Fig. 4.  Central  asymmetry  values  for  five  frequency  bands.  *  p  <  .05,  
** p < .01. Error bars represent the standard error of the mean. 

Fig. 5.  Parietal asymmetry values for five frequency bands. Error 

bars represent the standard error of the mean. 

The main effects for the differences between the Pre-b, 

VRX and Post-b phases were computed for all frequency 
bands in all brain areas, shown in Table 1.  

Delta 

0.542 

.762 

8.320 

.016 

TABLE 1. Results of the Kruskall-Wallis tests testing the difference 
between the three experimental phases for each brain area and frequency 
band (significant findings marked in bold).  

Frequency 

Frontal area 

Central area 

Fig. 4.  Central  asymmetry  values  for  five  frequency  bands.  *  p  <  .05,  
** p < .01. Error bars represent the standard error of the mean. 
X2(2) 
p 

p 

band 

X2(2) 

p 

Theta 

9.512 

.009 

Alpha 

17.17

<.00

5 

1 

Beta 

1.222 

.543 

9.348 
Fig. 5.  Parietal  asymmetry  values  for  five  frequency  bands.  *  p  <  .05,  
** p < .01. Error bars represent the standard error of the mean 
5.948 

.186 

.051 

.009 

The main effects for the differences between the Pre-b, 

VRX and Post-b phases were computed for all frequency 
.424 
bands in all brain areas, shown in Table 1.  

0.805 

.669 

Gamma 

0.553 

.758 

1.136 

.567 

In  the  frontal  brain  area,  a  significant  change 
in  the  theta  and  alpha  asymmetry  was  found  over 
the  three  phases.  In  the  central  brain  area  a 
significant change in delta and theta asymmetry was 
found, whereas in the parietal area of the brain, no 
significant  changes  were  found  in  any  of  the 
frequency  bands.  Effect-size  was  computed  using 
the  Phi  coefficient,  which  is  the square  root of  Chi-
Square  divided  by  the  number  of  observations 
The main effects for the differences between the Pre-b, 
(√(X2/n)).  Because  in  all  measurements,  the  number 
VRX and Post-b phases were computed for all frequency 
of  observations  was  equivalent,  the  Chi-Square 
bands in all brain areas, shown in Table 1.  
value  is  representative  for  the  effect-size.  The 
effect-size  is  considered  large  when  it  is  .5  or 
higher,  which  was  solely  the  case  for  frontal  alpha 

** p < .01. Error bars represent the standard error of the mean 

Fig. 5.  Parietal  asymmetry  values  for  five  frequency  bands.  *  p  <  .05,  

Deleted: * p < .05, ↵
** p < .01. 

Commented [AH5]: Added 

asymmetry power (φ = .66). To investigate in which 

specific  phases  (Pre-b,  VRX  and  Post-b)  effects 

occurred,  a  post-hoc  test  was  conducted  on  the 

alpha and theta band in the frontal area and for the 

delta and theta band in the central area (Table 2). 

Fig. 6.  Linear regression model of the empathy score and the frontal 

alpha asymmetry, p < .05 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
     Figure 3. Linear regression model of the empathy score and the frontal alpha asymmetry, p < .05. 

4. Discussion 

The  aim  of  this  study  was  to  assess  affective  empathy  in  participants  through  EEG  as  online 
physiological measure in order to contribute to the enhancement of human-agent interaction. Empathy 
was elicited by showing participants an affective VR video about child exploitation. Before, during and 
after showing the VR video, participants’ brain activity was measured using EEG sensors.  

Findings  showed  that  overall  EEG  asymmetry,  defined  as  the  difference  in  EEG  spectral  band 
power  between  right  and  left  hemispheres,  decreased  when  participants  were  experiencing  the  VR 
video,  and  increased  after  the  video.  This  indicates  that  on  average  brain  activity  shifts  due  to  the 
stimulus, in almost all frequency bands and in all brain areas. Significant transitions in the theta and 
alpha asymmetry were found in the frontal brain area. Also, in the central area, significant asymmetry 
changes were found in the lower frequency bands; delta and theta. The parietal area did not show any 
significant asymmetry transitions.  

In the frontal brain region, the alpha asymmetry power shifted from a positive value to a negative 
value indicating a change of activity over hemispheres during the VR experience. The alpha wave is 
inhibitory, which means that a negative alpha asymmetry during the VR phase was caused by a greater 
cortical activation in the right hemisphere. This is consistent with previous literature that indicated that 
empathy is found to be in the right frontal brain area [15, 16, 23].  

Further  analyses  showed  a  significant  correlation  between  the  frontal  alpha  asymmetry  and 
empathy  during  the  baseline  phase.  The  frontal  alpha  asymmetry  ranged  from  negative  values  for 
higher empathy scores to positive values for lower empathy scores. This demonstrates that participants 
with a higher score on empathy scale showed relatively larger cortical activity in the right hemisphere 
and  participants  with  a  lower  empathy  score  had  a  relatively  larger  cortical  activity  in  the  left 
hemisphere  during  the  Pre-b  measurement.  This  result  indicates  that  there  is  a  cortical  difference 
between people with different personality characteristics with regards to empathy, even when they are 
not exposed to the stimulus yet. Similar results were shown in previous research of Tullett et al. [24] 
where larger right frontal activity was found to be a predictor for empathic concern. This also supports 
lesion studies discussed earlier, that claim empathy as a trait is related to right frontal regions [15, 16].  
We  expected  that  participants  with  a  relatively  higher  empathy  score  would  have  been  more 
influenced  by  the  empathy-inducing  immersive video  and  hence  showed  a  larger transition  in  their 
brain asymmetry from the Pre-b phase to the VRX phase compared to the participants with a relatively 
lower  empathy  score.  However,  our  results  did  not  support  this  hypothesis.  Even  though  the 
asymmetry powers changed significantly in some frequency bands in the frontal and central areas of 
the  brain,  the  regression  analysis  did  not  find  a  significant  relationship  between  this  change  and 
participants’ empathy scores. One possible explanation could be that participants did not respond to 

 
 
the immersive video in the same way and hence the changes in the their brain activity differed based 
on the level of presence they felt in the environment [33]. Future research should look at the correlations 
between  sense  of  presence  in  VR  and  changes  in  asymmetry  powers  that  participants  exhibited  in 
different brain regions. Another possibility is that since the empathy scores were normally distributed 
in  a  limited  range  (obtained  score  range  49/86,  min/max  score  0/96),  there  was  not  enough  variety 
within  the  participants  to  find  a  relationship  with  the  brain  asymmetry  alterations.  This  could  be 
investigated  in  future  research  by  examining  participants  that  exhibit  a  very  low  level  of  empathy, 
which could be due to cortical impairments, versus participants that score extremely high on empathy 
questionnaire.  

A possible limitation of the employed analysis in this study is the effect of ocular artifacts in the 
EEG signals. Although it is a common practice in neuroscientific research to correct eye blinks artifacts 
in EEG signals through regression-based techniques or independent component analysis (ICA) [34], we 
did not perform such artifact rejection in our pre-processing. The reason for this was two-fold; 1) we 
were  interested  in  identifying  EEG  features  that  could  be  detected  by  real-time  BCI  systems  in  the 
future.  Automatic  detection  and  filtering  of  eye  artifacts  during  recording  is  not  computationally 
efficient for BCIs [35] and therefore most passive BCI algorithms rely on temporally observable changes 
in unprocessed EEG signals. In this case, we collected pre- and post-baselines with open eyes and we 
compared those segments with the VR viewing condition in which the eyes were open, 2) based on the 
findings of the past research, we were particularly interested in brain activity patterns in the frontal 
area of the brain. Eye artifact removal, either performed manually as in ICA or by automatic-selection 
algorithms,  can  largely  affect  frontal  EEG data and  lead  to  information  loss.  In  order to  avoid  such 
possible  information  loss  at  the  frontal  sites,  we  decided  to  limit  the  pre-processing  to  bandpass 
filtering of high and low frequency components.  

Another limitation of this study is generalizability of our findings to different age groups. Previous 
studies  have  shown that age  has a  significant  impact on  EEG  measures  such  as  spectral  power  and 
coherence  [36-38].  In  this  experiment,  we  recruited  our  participants  from  a  homogenous  age  group 
(around  20  years  old)  in  order  to  minimize the  effect of  individual differences  on  the  EEG features. 
Future research should replicate this study with other age groups including middle-aged and elderly 
to investigate the general conformity of our results. 

An important question regarding our findings is that whether the lateralization of cortical activity 
during the VR experience is a signature of empathic response and not simply an arousal response to 
stress.  In  this  study,  we  focused  on affective  (emotional)  empathy,  which  is  the  emotional response 
towards  another  person’s  suffering  (here  an  African  child  being  exploited)  and  inherently  involves 
personal distress  and  sadness  as  a result  of  empathic concern  [15,  24].  Images of charity  campaigns 
have been used in past studies [24] and similar results have been reported for frontal asymmetry as an 
objective indicator of emotions and approach-withdrawal responses [39-41]. Overall, literature shows 
that positive emotions such as happiness, pleasantness and interest that are representative of approach 
or motivational effect are accompanied by increased left frontal activity in alpha band, whereas fear, 
disgust,  anger  and  sadness,  which  are  associated  with  withdrawal,  lead  to  increased  right  frontal 
activity  [24,  39].  Our  study  provides  consistent  findings  where  empathic  concern  during  the  VR 
viewing led to a withdrawal effect and subsequent shift of activation in alpha band from the left to right 
hemisphere.  Future research  should  further  evaluate whether  this  empathic  emotional  response  can 
also promote a change of behavior (e.g. taking action to help). 

Lastly,  future  research  should  examine  the  effect  of  different  media  usage  and  degrees  of 
immersion to induce empathy. In this research, we used an immersive 360° video together with a VR 
headset  in  order  to  dissociate  the  participants  from  the  experimental  room  and  induce  a  sense  of 
presence as if they were in the same location of the African girl [33]. Past research has shown that a 
greater  immersion  results  into  a  higher  sense  of  presence,  which  is  in  correlation  with  stronger 
emotional experience in an affective VR environment [42]. The active viewing of the VR environment 
in  our  experiments,  in  which  participants  could  move  their  head  and  watch different  corners of the 
room, was a novel aspect compared to the experimental setup of previous studies where participants 

only passively watched a video or a series of images on a computer screen (e.g. [15], [24]). Yet, an even 
higher sense of presence could be achieved by using a VR environment in which users are provided 
with the ability to interact with the environment and manipulate objects. It is, however, noteworthy 
that 360° videos are the most widely used and cost-effective way of presenting VR to people and have 
been used in past research as visual stimuli as well [43].  

What  do  our  findings  mean  for  the  development  of  future  interactive  technologies?  With 
developments  in  artificial  intelligence,  social  robotics,  VR  and  serious  gaming,  the  use  of  socially 
intelligent  agents  that  take  into  account  user  responses  becomes  increasingly  important.  Whereas 
agents such as Microsoft’s paperclip ‘Clippy’ [44] did not care too much about the wellbeing of its user, 
agents such as the intelligent tutoring system AutoTutor [45] took into account individual differences 
in  the  verbal  input.  An  affective  version  of  AutoTutor  considered  the  cognitive  state  of  the  user  by 
adjusting the pedagogical state of its expressions on the user’s affect [46]. Today’s agents can take the 
interaction with the user even a step further by considering empathy. With the availability of sensing 
technologies and AI algorithms that measure and predict physiological and cognitive responses of the 
user [38], the next generation of agents is likely to become more interactive and show more empathy 
with the user.  

Another potential application of our findings is in the development of neurofeedback approaches 
and brain-computer interfaces that will help patients who have limited empathic understanding due 
to neurological disorders. This has been tested in the past in form of an interactive narrative paradigm 
where  subjects  supported  a  virtual  character  by  means  of  their  brain  activity  [47]  or  in  forensic 
psychiatry, where BCI-based empathy training in VR is suggested for the improvement of criminals’ 
emotional responses and suppression of their violent behavior [48].    

We  expect  that  applying  EEG  in  combination  with  interactive  technology  will  become  more 
feasible and common in the future due to technological advancements. For example, EEG sensors will 
become more comfortable for the user and less costly. Wireless and portable EEG systems are already 
available  which  offer  increased  mobility  during  data  collection.  Also,  software  tools  are  being 
developed that aid in processing and classifying EEG signals. Our work shows that such commercial 
EEG systems together with software tools for data analysis provide sufficient resources to obtain neural 
indicators of affective experiences in VR. This can set an example for other researchers in the field of 
human-technology interaction to similarly employ these applications for evaluation and optimization 
of  their  interaction  protocol.  Future  VR  systems  could  also  include  EEG  sensors  embedded  in  the 
headset and have the computational capacity to extract a user’s neural changes in real-time and adapt 
the VR environment to the user’s needs. The current study has taken a step toward identifying such 
EEG features that represent empathic state changes and empathy as a personality trait. 

In  future  studies,  other  personality  traits  than  empathy  could  be  investigated  in  relation  to 
particular brain activity patterns. Knowledge about these traits in relation to EEG measurements could 
help human-agent interaction become more efficient and more adaptive, enhancing the communication 
and behavior of the agent towards the user. 

5. Conclusions 

This study evaluated the neurophysiological underpinnings of an empathic experience induced 
by  an  affective  VR  environment.  We  collected  EEG  signals  before,  during  and  after  participants 
watched  a  video  of  child  exploitation  in  a  head-mounted  display.  Our  results  showed  significant 
decreases  in  alpha,  theta  and  delta  asymmetry  in  the  frontal  and  central  brain  regions  during  the 
affective  VR  experience.  Furthermore,  a  significant  relationship  was  found  between  empathy  as  a 
personality trait and frontal alpha asymmetry at the pre-baseline indicting that participants with higher 
empathy scores generally exhibited more cortical activation in the right hemisphere. These findings are 
useful in the field of wearable sensors and human-technology interaction, where a user’s traits and real-
time  affective  responses  can  be  detected  by  artificial  agents  and  hence  improve  their  interactive 
behavior.      

 
Author Contributions: conceptualization, M.A.; methodology and experiment design, all authors; data acquisition 
and analysis, A.H.; writing—original draft preparation, A.H.; writing—review and editing, all authors. 

Funding: This research was partially funded by the European Union, OP Zuid, the Ministry of Economic Affairs, 
the  Province  of  Noord-Brabant  and  the  municipalities  of  Tilburg  and  Gilze  Rijen  (PROJ-00076).  The  usual 
exculpations apply. 

Acknowledgments: We would like to thank Dylan Tjon who helped with the data collection.  

Conflicts of Interest: The authors declare no conflict of interest. 

References 

1. 

Li, G.; Hou,  Y.;  Wu, A.  Fourth  Industrial  Revolution:  technological  drivers,  impacts  and coping methods. 
Chinese Geographical Science 2017, 27(4), pp. 626-637. 

2.  Goodrich,  M.A.;  Schultz,  A.C.  Human–robot  interaction:  a  survey.  Foundations  and  Trends®  in  Human–

Computer Interaction 2008, 1(3), pp. 203-275. 

3.  Derbaix,  C.;  Pecheux,  C.  Mood  and  children:  Proposition  of  a  measurement  scale.  Journal  of  Economic 

Psychology 1999, 20(5), pp. 571-591. 

4.  Wiles,  J.A.;  Cornwell,  T.B.  A  review  of  methods  utilized  in  measuring  affect,  feelings,  and  emotion  in 

advertising. Current Issues and Research in Advertising 1991, 13(1-2), pp. 241-275. 

5.  Meng, H.; Bianchi-Berthouze, N. Affective state level recognition in naturalistic facial and vocal expressions. 

IEEE Transactions on Cybernetics 2013, 44(3), pp. 315-328. 

6.  Zeng,  Z.;  Tu,  J.;  Pianfetti,  B.M.;  Huang,  T.S.  Audio–visual  affective  expression  recognition  through 

multistream fused HMM. IEEE Transactions on multimedia 2008, 10(4), pp. 570-577. 

7.  Zimmermann, P.; Guttormsen, S.; Danuser, B.; Gomez, P. Affective computing—a rationale for measuring 
mood with mouse and keyboard. International journal of occupational safety and ergonomics 2003, 9(4), pp. 539-
551. 

8.  Kulic, D.; Croft, E. A. Affective state estimation for human–robot interaction. IEEE Transactions on Robotics 

9. 

2007, 23(5), pp. 991-1000. 
Fridlund, A.J.; Schwartz, G.E; Fowler, S.C. Pattern recognition of self-reported emotional state from multiple-
site facial EMG activity during affective imagery. Psychophysiology 1984, 21(6), pp. 622-637. 
Jia, X.; Li, K.; Li, X; Zhang, A. A novel semi-supervised deep learning framework for affective state recognition 
on eeg signals. In 2014 IEEE International Conference on Bioinformatics and Bioengineering 2014, pp. 30-37. IEEE. 
11.  Vul,  E.;  Harris,  C.;  Winkielman,  P.;  Pashler,  H.  Puzzlingly  high  correlations  in  fMRI  studies  of  emotion, 

10. 

personality, and social cognition. Perspectives on psychological science 2009, 4(3), pp. 274-290. 

12.  Aricò, P.; Borghini, G.; Di Flumeri, G.; Sciaraffa; N., Babiloni, F. Passive BCI beyond the lab: current trends 

and future directions. Physiological measurement 2018, 39(8), 08TR02. 

13.  Zander,  T.  O.;  Kothe,  C.  Towards  passive  brain–computer  interfaces:  applying  brain–computer  interface 

technology to human–machine systems in general. Journal of neural engineering 2011, 8(2), 025005. 

14.  Preston,  S.D.;  De Waal,  F.B.  Empathy:  Its  ultimate  and proximate  bases.  Behavioral and  brain  sciences  2002, 

25(1), pp. 1-20. 

15.  Shamay-Tsoory, S.G.; Aharon-Peretz, J.; Perry, D. Two systems for empathy: a double dissociation between 
emotional and cognitive empathy in inferior frontal gyrus versus ventromedial prefrontal lesions. Brain 2009, 
132(3), pp. 617-627. 

16.  Rankin,  K.P.;  Gorno-Tempini,  M.L.;  Allison,  S.C.;  Stanley,  C.M.;  Glenn,  S.;  Weiner,  M.W.;  Miller,  B.L. 

Structural anatomy of empathy in neurodegenerative disease. Brain 2006, 129(11), pp. 2945-2956. 

17.  Shamay-Tsoory,  S.G.;  Tomer,  R.;  Berger,  B.D.;  Aharon-Peretz,  J.  Characterization  of  empathy  deficits 
following prefrontal brain damage: the role of the right ventromedial prefrontal cortex. Journal of cognitive 
neuroscience 2003, 15(3), pp. 324-337. 

18.  Mu, Y.; Fan, Y.; Mao, L.; Han, S. Event-related theta and alpha oscillations mediate empathy for pain. Brain 

research 2008, 1234, pp. 128-136. 

 
19.  Perry, A.; Bentin, S.; Bartal, I.B.A.; Lamm, C.; Decety, J. “Feeling” the pain of those who are different from us: 
Modulation of EEG in the mu/alpha range. Cognitive, Affective, & Behavioral Neuroscience 2010, 10(4), pp. 493-
504. 
Joyal, C.C.; Neveu, S.M.; Boukhalfi, T.; Jackson, P.L.; Renaud, P. Suppression of sensorimotor alpha power 
associated with pain expressed by an avatar: A preliminary EEG study. Frontiers in human neuroscience 2018, 
12. 

20. 

21.  Coan, J.A.; Allen, J.J. Frontal EEG asymmetry as a moderator and mediator of emotion. Biological psychology 

2004, 67(1-2), pp. 7-50. 

22.  Sutton, S.K.; Davidson, R.J. Prefrontal brain asymmetry: A biological substrate of the behavioral approach 

and inhibition systems. Psychological science 1997, 8(3), pp. 204-210. 

23.  Light, S.N.; Coan, J.A.; Zahn-Waxler, C.; Frye, C.; Goldsmith, H.H.; Davidson, R.J. Empathy is associated with 
dynamic change in prefrontal brain electrical activity during positive emotion in children. Child development 
2009, 80(4), pp. 1210-1231. 

24.  Tullett,  A.M.; Harmon-Jones,  E;  Inzlicht, M.  Right frontal  cortical  asymmetry  predicts  empathic  reactions: 
Support for a link between withdrawal motivation and empathy. Psychophysiology 2012, 49(8), pp. 1145-1153. 
25.  Bachen,  C.M.;  Hernández-Ramos,  P.;  Raphael,  C.;  Waldron,  A.  How  do  presence,  flow,  and  character 
identification affect players’ empathy and interest in learning from a serious computer game?. Computers in 
Human Behavior 2016, 64, pp. 77-87. 

26.  Gale, A.;  Edwards,  J.;  Morris,  P.;  Moore,  R.; Forrester,  D.  Extraversion–introversion,  neuroticism–stability, 
and EEG indicators of positive and negative empathic mood. Personality and Individual Differences 2001, 30(3), 
pp. 449-461. 

27.  Spreng, R.N.; McKinnon, M.C.; Mar, R.A.; Levine, B. The Toronto Empathy Questionnaire: Scale development 
and  initial  validation  of  a  factor-analytic  solution  to  multiple  empathy  measures.  Journal  of  personality 
assessment 2009, 91(1), pp. 62-71. 

28.  VR Gorilla. (2016, May 27) Most beautiful sceneries of the world - Part 1 (360 VR Video) [Video file]. Retrieved 

from https://www.youtube.com/watch?v=ZS8aG415A8c 

29.  Terre des Hommes Nederland (2015, June 2) Terre des Hommes VR experience ENG [Video file]. Retrieved from 

https://www.youtube.com/watch?v=WjNbfhE4onA&t=31s 

30.  Schwarz,  N.;  Sciences,  B.;  Review,  I.;  Arbor,  A.;  Info,  B.  M.  Qualtrics  Survey  Software  Qualtrics  Survey 

Software. Info, 2012. 

31.  Oostenveld, R.; Fries, P.; Maris, E.; Schoffelen, J.M. FieldTrip: open source software for advanced analysis of 
MEG, EEG, and invasive electrophysiological data. Computational intelligence and neuroscience 2011, p.1. 

32.  Team, R.C. R: A language and environment for statistical computing 2013. 
33.  Tjon, D.; Tinga, A.; Alimardani, M.; Louwerse, M. M. Brain Activity Reflects Sense of Presence in 360° Video 
for Virtual Reality. In Proceedings of the 28th International Conference on Information Systems Development 2019. 
(to appear) 

34.  Di Flumeri, G.; Aricó, P.; Borghini, G.; Colosimo, A.; Babiloni, F. A new regression-based method for the eye 
blinks artifacts correction in the EEG signal, without using any EOG channel. In 2016 38th Annual International 
Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) 2016, August. pp. 3187-3190. IEEE. 
35. 
Jiang, X.; Bian, G. B.; Tian, Z. Removal of artifacts from EEG signals: a review. Sensors 2019, 19(5), p. 987.  
36.  Gaál, Z. A.; Boha, R.; Stam, C. J.; Molnár, M. Age-dependent features of EEG-reactivity—Spectral, complexity, 

and network characteristics. Neuroscience letters 2010, 479(1), pp. 79-84. 

37.  Kober, S. E.; Reichert, J. L.; Neuper, C.; Wood, G. Interactive effects of age and gender on EEG power and 
coherence during a short-term memory task in middle-aged adults. Neurobiology of aging 2016, 40, pp. 127-
137. 

38.  Tinga, A.M.; de Back, T.T.; Louwerse, M.M. Non-invasive neurophysiological measures of learning: A meta-

analysis. Neuroscience & Biobehavioral Reviews 2019. 

39.  Davidson,  R. J.;  Ekman,  P.;  Saron,  C.  D.;  Senulis, J. A.;  Friesen, W.  V. Approach-withdrawal and cerebral 
asymmetry: emotional expression and brain physiology I. Journal of personality and social psychology 1990, 58(2), 
pp. 330-341. 

40.  Coan, J. A.; Allen, J. J. Frontal EEG asymmetry as a moderator and mediator of emotion. Biological psychology 

2004, 67(1-2), pp. 7-50. 

41.  Di Flumeri, G.; Aricò, P.; Borghini, G.; Sciaraffa, N.; Maglione, A. G.; Rossi, D.; Modica, E.; Trettel, A.; Babiloni, 
F.;  Colosimo,  A.;  Herrero,  M.  T.  EEG-based  approach-withdrawal  index  for  the  pleasantness  evaluation 
during taste experience in realistic settings. In 2017 39th annual international conference of the IEEE engineering 
in medicine and biology society (EMBC) 2017, July. pp. 3228-3231. IEEE. 

42.  Diemer, J.; Alpers, G. W.; Peperkorn, H. M.; Shiban, Y.; Mühlberger, A. The impact of perception and presence 

on emotional reactions: a review of research in virtual reality. Frontiers in psychology 2015, 6, 26. 

43.  Bindman, S. W.; Castaneda, L. M.; Scanlon, M.; Cechony, A. Am I a Bunny? The Impact of High and Low 
Immersion Platforms and Viewers' Perceptions of Role on Presence, Narrative Engagement, and Empathy 
during an Animated 360 Video. In Proceedings of the 2018 CHI conference on human factors in computing systems 
2018, April. p. 457. ACM. 

44.  Veletsianos, G. Cognitive and affective benefits of an animated pedagogical agent: Considering contextual 

relevance and aesthetics. Journal of Educational Computing Research 2007, 36(4), pp. 373-377. 

45.  Graesser, A.C.; Lu, S.; Jackson, G.T.; Mitchell, H.H.; Ventura, M.; Olney, A.; Louwerse, M.M., AutoTutor: A 
tutor with dialogue in natural language. Behavior Research Methods, Instruments, & Computers 2004, 36(2), pp. 
180-192. 

46.  D'mello,  S.;  Graesser,  A.  AutoTutor  and  affective  AutoTutor:  Learning  by  talking  with  cognitively  and 
emotionally  intelligent  computers  that  talk  back.  ACM  Transactions  on  Interactive  Intelligent  Systems  (TiiS) 
2012, 2(4), p. 23. 

47.  Gilroy, S.W.; Porteous, J.; Charles, F.; Cavazza, M.; Soreq, E.; Raz, G.; Ikar, L.; Or-Borichov, A.; Ben-Arie, U.; 
Klovatch, I.; Hendler, T. A Brain-Computer Interface to a Plan-Based Narrative. In IJCAI 2013, August. pp. 
1997-2005. 

48.  Benbouriche,  M.;  Nolet,  K.;  Trottier,  D.;  Renaud,  P.;  Virtual  reality  applications  in  forensic  psychiatry.  In 

Proceedings of the 2014 Virtual Reality International Conference 2014, April. p. 7. ACM. 

 
