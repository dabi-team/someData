2
2
0
2

g
u
A
3
2

]

C
H
.
s
c
[

1
v
0
7
1
1
1
.
8
0
2
2
:
v
i
X
r
a

“It’s Just Part of Me:” Understanding Avatar Diversity and
Self-presentation of People with Disabilities in Social Virtual
Reality

Kexin Zhang
University of Wisconsin-Madison
Madison, Wisconsin, USA
kzhang284@wisc.edu

Elmira Deldari
Univ. of Maryland, Baltimore County
Baltimore County, Maryland, USA
edeldar1@umbc.edu

Zhicong Lu
City University of Hong Kong
Kowloon, Hong Kong, China
zhicong.lu@cityu.edu.hk

Yaxing Yao
Univ. of Maryland, Baltimore County
Baltimore County, Maryland, USA
yaxingyao@umbc.edu

Yuhang Zhao
University of Wisconsin-Madison
Madison, Wisconsin, USA
yuhang.zhao@cs.wisc.edu

ABSTRACT
In social Virtual Reality (VR), users are embodied in avatars and
interact with other users in a face-to-face manner using avatars as
the medium. With the advent of social VR, people with disabilities
(PWD) have shown an increasing presence on this new social me-
dia. With their unique disability identity, it is not clear how PWD
perceive their avatars and whether and how they prefer to disclose
their disability when presenting themselves in social VR. We fill this
gap by exploring PWD’s avatar perception and disability disclosure
preferences in social VR. Our study involved two steps. We first con-
ducted a systematic review of fifteen popular social VR applications
to evaluate their avatar diversity and accessibility support. We then
conducted an in-depth interview study with 19 participants who
had different disabilities to understand their avatar experiences.
Our research revealed a number of disability disclosure preferences
and strategies adopted by PWD (e.g., reflect selective disabilities,
present a capable self). We also identified several challenges faced
by PWD during their avatar customization process. We discuss the
design implications to promote avatar accessibility and diversity
for future social VR platforms.

CCS CONCEPTS
• Human-centered computing → Virtual reality; Accessibil-
ity technologies.

KEYWORDS
Social VR, avatar, self-perception, disability disclosure, visual im-
pairments, d/Deaf and heard of hearing

ACM Reference Format:
Kexin Zhang, Elmira Deldari, Zhicong Lu, Yaxing Yao, and Yuhang Zhao.
2022. “It’s Just Part of Me:” Understanding Avatar Diversity and Self-presentation

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ASSETS ’22, October 23–26, 2022, Athens, Greece
© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9258-7/22/10. . . $15.00
https://doi.org/10.1145/3517428.3544829

of People with Disabilities in Social Virtual Reality. In The 24th International
ACM SIGACCESS Conference on Computers and Accessibility (ASSETS ’22),
October 23–26, 2022, Athens, Greece. ACM, New York, NY, USA, 16 pages.
https://doi.org/10.1145/3517428.3544829

1 INTRODUCTION
With the rising popularity of virtual reality (VR), social VR is be-
coming the mainstream of the online social eco-system. Social VR
refers to VR platforms where people communicate and socialize in
the form of avatars [26]. One iconic characteristic of social VR is the
embodied “face-to-face” interaction from a first-person perspective
through avatars. By customizing their avatars, users can craft and
maintain any characters they prefer in a virtual world.

Due to the deep embodiment of a user with their avatars, to
some degree, a customized avatar can be considered as a proxy
of the user themselves [56]. A myriad of research has explored
how people use avatars to shape their self-images in virtual social
spaces, including both PC-based virtual worlds [41] and the more
immersive social VR [25, 26]. Research has found that while many
people designed their avatars to reflect their physical appearance
in the real world [57], some people leveraged the opportunity to
experiment with different aspects of their personalities [18, 24]
and even explored completely different identities [81]. However,
most prior works focused on the self-presentation preferences of
people without disabilities. People with disabilities (PWD), given
their unique disability identity, may have different perceptions and
preferences when constructing self-images via avatars in social VR.
Research on PWD’s self-presentation in social VR is in its in-
fancy. On traditional social media platforms, PWD have a strong
presence and use various strategies to construct their online images
as others do [72, 85]. Unlike people with typical abilities, disabil-
ity disclosure is a unique perspective that PWD need to consider
during self-presentation. Many PWD are cautious about disclos-
ing their disability-related vulnerabilities, and some intentionally
hide their disability to avoid potential risks, such as loss of job
opportunities [90] and cyber-bullying [46]. In contrast, some proac-
tively disclose their disabilities, especially on dating platforms, to
build trust and filter potential partners [65]. Unlike the 2D text-
or image-based social media, social VR provides a more embod-
ied and immersive experience via avatars, which can potentially

 
 
 
 
 
 
ASSETS ’22, October 23–26, 2022, Athens, Greece

Zhang et al.

change PWD’s self-presentation preferences and their willingness
to disclose their disabilities. To promote safe and inclusive social
VR experiences for PWD, the accessibility and VR communities are
in need of a thorough understanding of PWD’s avatar perceptions
and disability disclosure preferences on the emerging social VR
platforms.

Our research aims to fill the gap by investigating how PWD de-
sign and use their avatars for disability disclosure and self-presentation
in social VR. Given that social VR is an emerging but premature
medium that lacks sufficient accessibility support, we also explore
the status quo of avatar diversity and accessibility on commercial
social VR platforms to reveal the barriers faced by PWD in the
avatar customization process. Specifically, we aim to answer the
following research questions:

• RQ1: Whether and how is avatar diversity supported on the

mainstream commercial social VR platforms?

• RQ2: Whether and how do PWD disclose their disabilities

when presenting themselves via avatars?

• RQ3: What challenges do PWD face during the avatar design

and creation process?

To answer these research questions, we first systematically re-
viewed 15 commercial social VR applications to understand what
avatar features are supported for disability representation. We then
conducted in-depth semi-structured interviews with eight visually
impaired people, nine d/Deaf and hard of hearing people, and two
people with multiple disabilities to explore their avatar perceptions
and customization experiences in the social VR context. Our find-
ings revealed a spectrum of disability disclosure strategies adopted
by PWD for self-presentation, from accurately disclosing one’s dis-
ability, to selectively presenting a particular aspect of the disability,
presenting the changes in one’s ability, to hiding one’s disability to
construct a different self. Our study highlighted the lack of avatar
diversity for disability representation and emphasized PWD’s needs
to flexibly control their disability disclosure in different social con-
texts. We also identified the avatar accessibility barriers faced by
PWD and suggested design implications.

This paper makes three contributions. First, to the best of our
knowledge, this is the first research that investigates social VR
avatar diversity and self-presentation from the lens of disability.
Second, our research presents rich and in-depth data to uncover
PWD’s different disability disclosure strategies and preferences.
Third, design implications are derived to inspire a more accessible
and inclusive avatar experience for PWD in social VR.

2 RELATED WORK
2.1 Self-presentation in Virtual Worlds
Self-presentation, also known as impression management, refers
to the ways that a person “conveys an impression to others which
is in his interests to convey” [30]. Via self-presentation, people
can selectively craft, present, and maintain specific facets of their
identities based on different audiences and social settings [1, 22,
43, 63]. A myriad of research has explored how people manage
their identities on social media (e.g., Facebook, Twitter), revealing
the complexity of self-presentation from various aspects, such as
beautified real self on anonymous social platforms [29, 87, 88],

multiple online identities for different audience groups [17], and
the stereotypical representation of genders [3].

With the advances in computer graphic technology and hard-
ware support, social media expands from 2D to 3D avatar-based
systems [25]. Instead of using text and images to construct self-
image, people can directly create and personalize an avatar as their
virtual representation and manage the impression from others via
the avatar. Many researchers explored users’ digital representations
via avatars in PC-based virtual worlds, including both the game
worlds (e.g., World of Warcraft [21]) and the social worlds (e.g., Sec-
ond Life [48]). In the virtual game worlds where a limited number
of pre-defined avatars were provided, many users tended to select
avatars that stood out, followed a trend [18], or served the role they
planned to play in the game [27]. In contrast, social worlds gave
users more flexibility to design their own avatars, for example, by
adjusting and customizing different body features (e.g., hair, eyes,
skin color). Without restrictions from the game theme, many users
chose to create avatars that resembled themselves in the real world
[18, 71, 82]. For example, Ducheneaut et al. [18] explored users’
avatar customization across three virtual worlds (i.e., Maple Story,
World of Warcraft, and Second Life), and found that more users
preferred reproducing some of their physical characteristics in the
social virtual worlds than in the game worlds. Koles et al. [44] also
showed that the majority of users in Second Life tended to use
their physical selves as the starting point to create their virtual
representation.

With the high flexibility in avatar customization, people also
have the freedom to create avatars that are different from their
physical appearances, thus better shaping their online identities.
As a result, some people used avatars to experiment with different
aspects of their personalities [42, 78, 79]. For example, Kafai et
al. [42] surveyed 438 tween players in a virtual social community
named Whyville and found that most tweens did not construct
their avatar appearances based on their real selves. Instead, they
designed avatars to achieve recognition from others or to reveal
specific aspects of their “real” selves, including those they desired
but could not present in real life. Via avatar creation, users can even
create and explore a completely different identity, such as an avatar
with a different gender [37] or a different race [62], which may help
them discover their true selves and increase their self-esteem [5].
Most prior work on avatar perception focused on the majority
group. Limited attention has been paid to the self-presentation
and identity disclosure of the under-representative user groups,
especially people with disabilities.

2.2 Self-disclosure by People with Disabilities

in Virtual Worlds

Different from self-presentation where people can construct and
present any images that they prefer to the audience, self-disclosure
refers to the act of revealing any messages about oneself to others
[14, 29, 31]. While self-disclosure is involved in self-presentation
strategies to help build closer relationships [70], it also poses po-
tential risks of exposing one’s vulnerabilities, especially to the
unknown or anonymous audience online [53]. Prior research has

Avatar Diversity and the Self-presentation of People with Disabilities in Social VR

ASSETS ’22, October 23–26, 2022, Athens, Greece

explored the online self-disclosure experiences of various under-
representative groups, such as racial minority [36, 49, 50] and gen-
der minority [9, 11, 20, 60]. In this section, however, we focus on
the work for people with disabilities (PWD).

Disability disclosure has always been an important topic for
PWD even before social media platforms emerged [38, 64, 68, 80].
Prior research focused primarily on the physical working context,
showing that disability disclosure could potentially assure appro-
priate workplace accommodations and increase workplace diver-
sity and inclusiveness for PWD [80]. However, it may also lead
to negative employment consequences for PWD, such as lowered
supervisor expectations, isolation from colleagues, and increased
possibility of termination [38, 64]. Because of these, in working or
daily living contexts, disability disclosure is highly contextualized,
and influenced by many factors such as employers, managers, and
workplace climate [64, 80].

The advent of online social platforms (e.g., social media, social
virtual worlds) affords new forms of social interactions and activi-
ties, along with new social relationships. These online platforms
bring PWD more opportunities to interact with others and get ac-
cess to resources and communities [74, 76]. For example, Boellstorff
[6] built “Ethnographia”, a virtual island in Second Life, to investi-
gate how digital spaces influenced PWD’s experiences and found
that building virtual worlds enhanced PWD’s sense of ability and
helped them reconstruct identities. With these online social plat-
forms, PWD were able to manage their disability disclosure, thus
achieving a “levelling ground” where they could be treated on their
merits as a person without being shadowed by their disabilities
[7]. However, disability disclosure in online communities can also
bring risks to PWD [69, 74]. For example, Ringland [69] conducted
a 200-hour observation in Autcraft, an online community for chil-
dren with autism, and found that the autistic identity in virtual
worlds could be both a source of empowerment and a source of
harassment and violence.

Researchers have explored PWD’s self-disclosure strategies and
preferences in different online communities [6, 28, 40, 65, 69]. For
example, Porter et al. surveyed 91 adults with and without disabil-
ities to understand the needs for disability disclosure on online
dating platforms. They found a higher expectation of the disclosure
of visible disabilities than invisible disabilities [65]. By designing a
movement-based virtual game for young people using wheelchair
and exploring their avatar preferences, Gerling et al. found that
while 6 out of 8 participants depicted wheelchairs as indispensable
parts of their self-images, only two participants were willing to use
avatars with mobility disabilities in the game [28]. Recently, Davis
and Stanovsek conducted a 3-year ethnography study to explore
how PWD customize their avatars in Second Life and found that
many participants used non-human avatars to free themselves from
their visible disabilities [16].

Compared to the conventional social media and virtual worlds,
the emerging social VR brings unique embodied experiences, which
may potentially affect PWD’s willingness of disability disclosure.
However, little work has investigated the influence of social VR on
PWD’s self-presentation and disability disclosure preferences.

2.3 Avatars Design and Self-presentation in

Embodied Social VR

In recent years, social VR has gained increasing attention. Unlike
the PC-based virtual worlds where users see avatars on a 2D screen
and can only control the avatars via a keyboard and a mouse, social
VR incorporates full-body tracking, providing a more embodied
first-person avatar experience as well as richer and more immer-
sive social interactions [25]. As a result, social VR provides new
affordances for avatar design and interaction [34, 45, 59, 83]. For
instance, Kolesnichenko et al. [45] interviewed industry experts
who work for different commercial social VR platforms and uncov-
ered the current avatar design practices from different aspects, such
as locomotion, avatar aesthetics, and avatar’s relation to one’s vir-
tual identity. Menon [59] also researched the relationship between
avatar customization and embodiment in a virtual job interview
context, highlighting the needs for basic avatar customization.

Some research specifically focused on avatar-based self-presentation

in social VR and how it affected users’ behaviors and interactions
[25, 26, 55]. For example, Freeman et al. [25] interviewed 30 people
about their avatar perception and social interaction experiences
in social VR. They found that most people considered the avatars
to be themselves and strived to make their avatars similar to their
physical appearances. This research also revealed how avatar gen-
ders and race affected people’s experience. For example, female
avatars received better first impression and nicer treatment but
also led to more harassment, and non-white avatars could bring
certain social stigma. Moreover, Maloney and Freeman [55] studied
how and why people disclose their information in social VR. They
argued that creating avatars that look like one’s physical self can
disclose important personal information such as gender, race, and
appearance. While this helped build close connection with others,
it can potentially lead to privacy risks.

With more realistic avatars and more embodied interactions,
social VR can also affect PWD’s self-presentation and disability dis-
closure preferences. Some researchers have noticed the importance
of this research direction. Boellstorff [6] emphasized the importance
of distinguishing “virtual world” and “virtual reality” for under-
standing PWD’s avatar experience. Mott et al. [61] also stressed
the needs for supporting more diverse avatar representations for
PWD in social VR. However, to our knowledge, no research has
thoroughly explored PWD’s avatar design experiences in the em-
bodied social VR. Our research contributes to this line of research
by developing a deep understanding of the current avatar diver-
sity practices, as well as PWD’s self-presentation challenges and
strategies in social VR.

3 STUDY I: APPLICATION REVIEW: AVATAR
DIVERSITY ON COMMERCIAL SOCIAL VR
PLATFORMS

The goal of this study is to build a comprehensive understanding of
the avatar diversity and accessibility practices on current commer-
cial social VR platforms (RQ1). Specifically, we aim to uncover 1) the
general avatar design practices: what types of avatars are supported
and how users can select or customize an avatar on different social
VR platforms; 2) avatar diversity support: what avatar features are
provided to enable disability disclosure for PWD; and 3) avatar

ASSETS ’22, October 23–26, 2022, Athens, Greece

Zhang et al.

accessibility: what accessibility features are provided for PWD to
perceive, use, and customize avatars.

3.1 Method
We conducted a systematic review of fifteen popular commercial
social VR applications. To determine which social VR applications
to review, we conducted an exhaustive search on three mainstream
VR application stores, including Oculus, Viveport, and Steam. Our
search focused on applications available in the United States in
November and December 2021. We first searched the keyword “so-
cial” in these stores and identified a total of 133 VR applications:
47 from Oculus, 54 from Viveport, and 50 from Steam (18 apps
were available across multiple stores). To further narrow down
the scope, we filtered the applications by checking the application
descriptions and only focused on the applications whose descrip-
tions clearly indicated a social or collaborative nature.Finally, we
excluded VR applications that showed an intense gaming nature
(e.g., sports, shooting games), which can distract users from socializ-
ing, such as EchoVR, StarTrek: Bridge Crew, and SpaceteamVR. We
also consulted other related work and online articles about popular
social VR applications to ensure not missing any mainstream social
VR platforms [2, 52, 86]. This process resulted in fifteen social VR
applications with strong social nature, including Rec Room, VR-
Chat, Horizon Worlds, vTime XR, AltspaceVR, Bigscreen, Alcove,
Half + Half, Horizon Venues, Villa, Arthur, ENGAGE, Multiverse,
PokestarVR, and Spatial (details can be found in Table 2 in Appen-
dix).

Two researchers on the team reviewed all applications indepen-
dently. We adopted a depth-first traverse strategy, clicking all avail-
able buttons and menu items in the avatar customization process.
During the review, researchers video-recorded and took notes of
all avatar options and the interaction process. The two researchers
then discussed their results to ensure the reliability of the review.
Following the same strategy, we reviewed the general setting in
each social VR application to examine what accessibility features
were supported. Any accessibility features that could influence or
be applied to the avatar selection and customization process were
documented. All applications were reviewed with Oculus Quest 2.

3.2 Review Results
3.2.1 Avatar Creation Methods. We identified four ways to cre-
ate and customize avatars in social VR: (1) Full Avatar Selection: se-
lecting from a set of pre-determined avatars provided by the system,
(2) Avatar Feature Customization: customizing different components
of a human avatar (e.g., eyes, hair styles), (3) Photo-based Avatar
Generation: uploading a photo to the system and generating a cor-
responding avatar automatically, and (4) Third-party Avatar Import:
designing an avatar using a third-party platform and uploading it
to the social VR application.

Most social VR platforms (12 out of 15) supported Avatar Feature
Customization, allowing users to customize the avatar’s physical
features (e.g., skin tone, body shape, eyes), clothing (e.g., outfits,
accessories), or both. Three platforms (VRChat, Half+Half, and Mul-
tiverse) employed the Full Avatar Selection model. Notably, VRChat
offered a set of 80 pre-defined avatars for users to select and sup-
ported various avatar types, including both humanoid avatars and

non-humanoid avatars, such as cartoons, robotic figures, animals,
and objects. VRChat was also the only platform that enabled users
to design and import their own avatars from third-party platforms.
Additionally, three platforms (Villa, Arthur, and Spatial) employed
Photo-based Avatar Generation. Table 2 in Appendix listed the
avatar customization methods supported by different platforms.

Beyond individual applications, the Oculus system provided its
own avatar system (i.e., Meta Avatars) that employed the Avatar
Feature Customization model. When first logged in to an Oculus
device, users were automatically directed to Horizon Home1 to
customize their avatars for the whole VR system. Three platforms–
Horizon Worlds, Horizon Venues, Alcove–directly adopted the Meta
Avatars, so that a user could continue using the same avatar from
the Oculus system.

Our review of the avatar customization process confirmed the
results from Kolesnichenko et al.’s work [45] and further extended
the scope to more widely-used social VR applications.

3.2.2 Avatar Realism. Most social VR platforms provided only
humanoid avatars. We investigated the avatar realism by examining
the completeness of the humanoid avatars. We found that only
three platforms–VRChat, vTime XR, and ENGAGE–provided full
body avatars, including head, neck, torso, arms, hands, legs, and
feet. All other 12 platforms focused on rendering the upper body
of the avatars, presenting at least the avatars’ head and hands.
Specifically, five platforms did not show the avatars’ arms but only
presented flowing hands; avatars in Rec Room and Bigscreen did
not have necks; and Villa’s avatars did not even have a torso. In
terms of avatar rendering details, except for Rec Room, all social
VR platforms we reviewed rendered avatar fingers and tracked the
users’ finger movement via the VR controllers. Table 2 in Appendix
provides details of the avatar realism on all platforms.

3.2.3 Disability Representation in Avatars. Our review uncov-
ered the limited avatar diversity support for PWD. We found that
most commercial social VR platforms did not offer any disability-
related avatar features. Meta Avatars was the only avatar system
that provided hearing device features for people who are d/Deaf
or hard of hearing. Two types of hearing devices were supported:
cochlear implants and hearing aids. A user can put the hearing de-
vice on the avatar via three options: left ear only, right ear only, and
both ears (Fig 1A). This feature was provided under the category of
“Clothing.” However, no other assistive devices or disabilities were
supported. Additionally, we found some “near disability-related”
features that may be used to indicate a disability. Specifically, Bige-
screen provided an eye patch feature under “Glasses” category,
which users can add onto their avatars to present their visual im-
pairments or eye injuries. However, we acknowledge that this fea-
ture might be designed as an eye decoration (e.g., to imitate a pirate)
instead of a disability feature.

Besides disabilities, some applications allowed users to customize
wrinkles and face lines on avatars to reflect age and represent older
adults. For example, Meta Avatars provided five levels of face lines
with different depth and number of wrinkles on avatar’s face to

1A virtual home in Oculus Quest 2, which functions like the homepage of 2D platforms
and enables certain social activities [66].

Avatar Diversity and the Self-presentation of People with Disabilities in Social VR

ASSETS ’22, October 23–26, 2022, Athens, Greece

demonstrate different ages. vTime XR offered four sagging levels
for avatars’ facial skin to present age (Fig 1B).

Figure 1: Avatar Diversity: A. Hearing devices in Meta
Avatars; B. Sagging facial skin in vTime XR Avatar.

3.2.4 Accessibility Features for Avatar Customization. The
accessibility features on social VR platforms were limited. While
some platforms supported standard accessibility features that were
commonly used on computer and smartphone interfaces (e.g., mag-
nification, color correction), no features were designed specifically
for avatar customization. Specially, AltspaceVR allowed users to
adjust the scale of the avatar interface. The Oculus system also
provided visual augmentations (i.e., color correction, text size ad-
justment) that can be applied to any applications on Oculus devices.
Moreover, most social VR platforms allowed adjustment to the
audio and haptic feedback, which could be helpful for PWD.

By reviewing mainstream social VR platforms, we developed a
comprehensive understanding of the current practices of the avatar
design, diversity, and accessibility. The results of this study inspired
and served as a solid grounding for our following interview study
(Study II). First, the review identified existing disability features
for avatars and the social VR platforms that supported such fea-
tures, which enabled us to better understand participants’ social VR
experiences and disability disclosure choices in an in-depth inter-
view. Second, the limited disability features (i.e., hearing aids, eye
patches) identified in this study helped us narrow down the focus
to participants who were visually impaired and deaf or hard of
hearing, since they were the only disability groups that had avatar
representations in social VR.

4 STUDY II: INTERVIEWS:

SELF-PRESENTATION OF PEOPLE WITH
DISABILITIES VIA AVATARS

In this study, we investigated how PWD design and craft their
avatars to disclose their disabilities and present themselves in social
VR (RQ2) as well as their challenges and needs during the avatar
creation and customization process (RQ3).

4.1 Method
We conducted semi-structured interviews with 19 PWD via Zoom
in February and March 2022. The study was approved by the Insti-
tutional Review Board (IRB).

4.1.1 Participants. Our recruitment focused on two types of sen-
sory disabilities, (1) d/Deaf or Hard of Hearings (DHH) people and
(2) visually impaired (VI) people, since they are common and visible

disabilities (or disabilities that can be indicated by visible assis-
tive technologies). Both disabilities can be easily noticed in the
real world and thus can be reflected via avatar design. For exam-
ple, blind people may use a white cane, and d/Deaf people may
wear hearing aids or may sign. We recruited 19 participants (11
female, 7 male, and 1 transgender). Their ages ranged from 20 to 58
(𝑚𝑒𝑎𝑛 = 33, 𝑆𝐷 = 11.57). Among the participants, eight had visual
impairments (V-P1 to V-P8), nine were DHH (H-P1 to H-P9), and
two had multiple disabilities (M-P1, M-P2). M-P1 was both blind
and DHH, while M-P2 was blind and had a prosthetic leg. Table 1
shows participants’ detailed information.

We spread our recruitment information via (1) the mailing lists
of non-profit disability organizations, such as the National Feder-
ation of the Blind and National Association of the Deaf, and (2)
mainstream social media platforms, such as Facebook groups, Twit-
ter, and Instagram. Interested participants could fill in a screening
survey with their age, disability conditions, and general avatar ex-
periences. Participants were eligible if they were over 18 and had
visual impairments or were d/Deaf or hard of hearing. We limited
the recruitment to individuals who spoke English. If selected to
participate, participants were asked to sign a consent form prior
to the interview. Upon completion, participants received $15 as
compensation.

Interview protocol. The interview included three phases. The
4.1.2
first phase focused on participants’ background information, in-
cluding demographics (age and gender), self-reported disability, and
experiences with VR and social VR.

The second phase focused on participants’ self-presentation and
disability disclosure via avatars. We first asked participants to send
photos of their avatars or screen share their avatars with us to
demonstrate their avatar design. We asked about how they de-
signed their avatars, why they customized their avatars in this
way, and whether their avatars involved any features to disclose
their disabilities. If the participants disclosed their disabilities via
their avatars, we further asked how they disclosed their disabilities,
why they wanted to do so, and their experience in social VR after
they disclosed disabilities via avatars. If participants’ avatars did
not indicate their disabilities, we asked about their willingness of
disclosing their disabilities via avatars and the reason. Additionally,
we asked participants whether and how they had disclosed their
disabilities through any other means or on any other online social
platforms and the rationales. Participants also discussed whether
and how they wanted the social VR platforms to support disability
representations via avatars.

The last phase of the interview focused on avatar creation acces-
sibility. We asked about participants’ experiences, difficulties, and
strategies when creating and customizing avatars and the types
of assistance they needed to complete the avatar creation process.
We also asked about their suggestions for a more accessible avatar
experience.

4.1.3 Data recording and analysis . Upon participants’ consent,
all 19 interviews were recorded and auto-transcribed by Zoom.
Participants had the option to turn off their cameras during the
interview, although it was not required. Two researchers manually
cleaned all transcripts by checking the recorded interviews.

ASSETS ’22, October 23–26, 2022, Athens, Greece

Zhang et al.

We conducted thematic analysis [8, 13] to identify repetitive
patterns and themes in the interviews. First, we manually organized
all qualitative data in an Excel sheet and selected five representative
transcripts (2 DHH participants, 2 VI participants, and 1 participant
with multiple disabilities) as samples. Three researchers coded all
samples independently at the sentence level with open coding.
Then, they discussed and reconciled their codes to resolve any
differences, and developed an initial codebook upon agreement.
Next, two researchers divided the rest of the transcripts based on the
participants’ disabilities. Specifically, one researcher analyzed all
VI participants’ data (including the two participants with multiple
disabilities) and the other researcher analyzed all DHH participants’
data. During this process, the two researchers regularly checked
each other’s codes and discussed as needed to ensure consistency.
New codes were added to the codebook based on the agreement
between the two researchers. In the meantime, the third research
oversaw all these activities to ensure a high-level agreement. The
final codebook contained over 120 codes. We categorized all the
codes into high-level themes using affinity diagram and achieved
twenty themes.

4.2 Findings
4.2.1 Experience with Avatars and Social VR Platforms. Six-
teen out of 19 participants had social VR experiences. In general, we
found that DHH participants had a richer experience with social VR
avatars than VI participants. Except for H-P3, all DHH participants
had used social VR multiple times. Five DHH participants were
frequent users with experiences of more than a year. In contrast, VI
participants had limited social VR experience, with most of them
only trying it a few times. Three VI participants did not have so-
cial VR experience, but they used avatars on conventional social
media, such as Snapchat Bitmoji and Meta Avatars for Instagram.
Several VI participants mentioned that they attempted to customize
their avatars on social VR several times but were blocked when
setting up an account. We report the accessibility challenges faced
by participants in Section 4.2.5.

The two most commonly used social VR platforms by our par-
ticipants were VRChat (7 participants) and Rec Room (5). Most
participants used social VR via head-mounted VR devices and the
most commonly used devices were Oculus Quest, Oculus Rift, and
Valve Index. However, three participants (H-P1, V-P2, V-P6) pre-
ferred using desktop-based social VR due to the accessibility issues
of VR devices.

Participants used social VR for multiple reasons. Most partici-
pants used social VR to communicate with friends (7 participants)
and play games (6). H-P4 specifically wanted to know other DHH
people and connect with DHH community in social VR. Six par-
ticipants used social platforms for professional purposes, such as
hosting VR meetups (H-P1), promoting rights for PWDs as accessi-
bility activists (H-P1), and using social VR as an education platform
(e.g., M-P1, V-P7, H-P4). Notably, three participants (H-P4, H-P6,
H-P8) used social VR for American Sign Language (ASL) educa-
tion. They learned or taught ASL in a VRChat community called
“Helping Hands” [84], which was a community for DHH people
to communicate via sign language (see details about ASL in VR in
Section 4.2.4).

4.2.2 Disability Disclosure via Avatars. Our study indicated
that disability disclosure via avatars was an essential strategy of
self-presentation for PWD. We identified participants’ different
disability disclosure preferences in social VR.

Reflect one’s physical self. The majority of our participants
(17 out of 19) designed avatars to reflect their physical appearances
in real life, including both facial features and outfits. Some partici-
pants even hoped to craft the fine details (e.g., makeup, accessories)
of the avatars to show their daily styles, habits, and values in real
life.

As part of their physical appearance, eight participants (e.g.,
H-P3, H-P7, V-P1) expressed their willingness to disclose their
disability via their avatars since they believed that the disability “is
part of me” (H-P3). As H-P7 indicated, “I have [a cochlear implant]
on [my avatar] all the time really, just because that’s what I do in real
life. I like my avatar to represent me as realistic as possible or as close
to [myself], so if I have a cochlear implant I’m not ashamed of it.” Two
participants (M-P1, H-P8) specifically emphasized that when they
disclosed their disabilities on social platforms, they never aimed
to highlight their disability since the disability was just like other
physical features, such as hairstyle, skin color, and gender. As M-P1
stated, “Because that’s who I am. I don’t see any reason to not disclose
[my disability]. It’s a part of who I am. And I wouldn’t like try to
pretend that I was a different race or try to pretend that I was not
female cisgender kind of person, so I wouldn’t pretend that I didn’t
have a disability.”

Interestingly, although most participants wanted their avatars to
reflect their physical selves as much as possible, H-P2 did not want
the details to be completely the same: “I just tried to make it look
kind of like me, but not too much like me, because it’s kind of creepy
when they look like twins. [The avatars] don’t ever look completely
like you, especially the hair, you cannot replicate someone’s hair [with
the current VR technology].” With the limitation of current avatar
realism and the Uncanny Valley effect2 , she discussed the boundary
between the physical self in real life and the virtual image presented
by avatars in the virtual world: “I don’t want [avatars] to be too much
like me, because it’s not real life. Don’t try to make it be real life when
it’s not like [real life].”

Reflect one’s physical self with selective disabilities. Un-
like most participants who preferred disclosing their disabilities
entirely, M-P1 selectively disclosed her disability. M-P1 experienced
both visual and hearing loss, and she decided which disability to
disclose based on the visibility of the disabilities. She used both a
white cane and hearing aids in the real life. However, she would
only add a white cane to her avatar to signify her visual impair-
ments but not disclose her hearing loss. This is because hearing
aids were not visible to people in the real world in most cases. Inter-
estingly, M-P1’s consideration of disability visibility was to fulfill
the expectation of the audience, specifically people who knew her
in real life. As she explained,

“I do use hearing aids, but I don’t think that they are visible partic-
ularly... so I was like, well I am not going to add a hearing aid, because
a lot of people probably don’t even know that I use [hearing aids],
because I don’t think they’re that visible, whereas people would know

2Uncanny Valley effect refers to viewer’s increased eerie feelings when an entity looks
highly human-like [35].

Avatar Diversity and the Self-presentation of People with Disabilities in Social VR

ASSETS ’22, October 23–26, 2022, Athens, Greece

Table 1: Participants’ demographics and social VR experiences. * indicates avatar platforms demonstrated by our participants.

ID

Age/
Sex

Self-reported Disability

Assistive Tech Used

Social VR
Experience

Social VR Platforms Used

H-P1

52/F

Profound deaf since birth

Cochlear implant

12 months

VRChat, AltspaceVR, Spatial, Mozilla Hubs, Rec
Room, Meta Avatars*

H-P2

H-P3

20/F

20/F

Severe deaf in left ear

Hearing aid

Multiple times

A social VR game, Snapchat*

25% hearing loss in right ear

Hearing aid

Tried once

VR Exhibition at a museum, Snapchat*, Meta
Avatars*, Sims*, Memoji*

H-P4

23/Trans Moderate hearing loss

H-P5

29/F

Moderate hearing loss

Hearing aids

Hearing aids

24 months

VRChat*

Multiple times

VRChat, Rec Room, Snapchat*, Meta Avatars*,
Roblox*

H-P6

25/M

Profound deaf

N/A

12 months

VRChat*, SteamVR

H-P7

30/M

Profound deaf

Cochlear implant

12 months

VRChat, Rec Room*, Lost Horizon, Meta
Avatars*

H-P8

25/M

Deaf

H-P9

29/F

80% hearing loss

Hearing aids

Hearing aids

White cane

N/A

N/A

24 months

VRChat*, SteamVR

Multiple times

A social VR app to play games with others,
Snapchat*

Few times

2 months

24 months

Horizon Series, Meta Avatars*

Cardboard, Meta Avatars*

BeanVR, Snapchat*

White cane, guide dog Multiple times

VRChat, Rec Room, Oculus Venues, Xbox*

Blind

Residual vision in one eye

Loss of side vision

Blind

Only have vision in one eye

White cane, guide dog

Blind

Blind

White cane

White cane

N/A

N/A

Snapchat*

Twitter avatar*

Multiple times

A social VR app with educational purpose, sev-
eral social VR games, Meta Avatars*

peripheral vision loss

White cane, guide dog

N/A

Meta Avatars*

Blind since birth; hearing dis-
ability since recently

Hearing aids, white
cane, guide dog

Few months

A social VR app for education, Meta Avatars*

V-P1

V-P2

V-P3

V-P4

V-P5

V-P6

V-P7

28/M

31/F

26/M

38/M

32/F

25/F

49/F

V-P8

M-P1

53/F

58/F

M-P2

38/M

Blind; has a prosthetic leg

White cane

Multiple times

Rec Room*

that I use a cane. I was trying to make [my avatar] look like me, and
I think that if I had hearing aids, a lot of people would be like, why
do you have hearing aids, so why did you do that.”

Moreover, M-P1’s experience with different disabilities also influ-
enced her choice of disability disclosure. She preferred to disclose
only the “dominant disability” that can represent her most: “I have
had the hearing disability for a lot less time than the [blindness], I
mean I’ve been blind all my life, so pretty like used to [blindness].
I think that maybe if I had grown up hard of hearing or deaf that
would be more important to represent for me.”

Reflect changes of the physical self. Notably, participants
who experienced acquired and progressive disabilities mentioned
that they wanted to use their avatars to reflect their physical changes
and inform people about their current abilities. For example, H-P2,
who suddenly experienced one-side hearing loss at the age of 20,
emphasized her need to inform people of her current hearing ability
via her avatar: “Because people don’t know [my acquired disability],
especially when [my hearing loss] happens so suddenly to me. Liter-
ally people are like ‘Oh, you can still hear out with one ear, you’re
just fine.’ But it’s like, I have no ability to locate a noise. When there’s
any sort of background noise, I can’t hear anything that you say. The
whole world is just like quieter. People don’t realize that.”

they were as capable as people without disabilities in accomplish-
ing tasks. However, participants employed divergent strategies to
present their capabilities.

Four participants (H-P4, V-P3, V-P4, M-P2) chose to hide their
disabilities in avatars, so that their disabilities would not bias others
and overshadow their capability in social interactions. For example,
V-P3, who played multiplayer games in BeanVR, preferred not to
disclos his visual disability, because he was afraid of being judged
as a weak player. As V-P3 described, “Sometimes there are challenges,
when you are trying to make friends, people may like disregard your
friend request because [your] visual impairment. Sometimes you have
to keep it a secret. I was like looking for teammate on BeanVR, so that
you can join a game, nobody wanted to be my teammates at the end
because maybe my weakness.”

Reversely, some participants (V-P1,V-P5) crafted their avatars
to show their disabilities and used them as a way to prove their
capability and independence in using this new technology. As V-
P1 said: “I see that avatar can be a symbol of hope, a symbol of I
can do this. For me, disability is not the end. I like to overcome my
disability and show others that I can overcome it. I’ve thought of ways
to overcome every obstacle. So, by [customizing my avatars], [I show
that] every person with disability can become independent.”

Present a capable self. Uniquely for PWD, some participants
wanted to present a capable self via avatars, demonstrating that

Present a professional self for disability education and
awareness. Nine participants (4 DHH and 4 VI participants, and

ASSETS ’22, October 23–26, 2022, Athens, Greece

Zhang et al.

M-P1) disclosed their disabilities to trigger conversations and edu-
cate the public about disability and equity. As H-P7 expressed, “I
think if people notice [the disability feature of my avatar], it can spark
an interesting discussion about oh look they’re wearing a cochlear
implant, what is that.” H-P1 further emphasized the importance of
educating people about DHH people: “Avatars [with disabilities]
were kind of cool, because that’s me educating people that deafness is
a spectrum, we don’t offer in buckets.”

V-P7 shared her disability to advocate for social justice. As V-P7
said, “Part of the reason [of disclosing my disability] is that, I am an
advocate for social justice and all marginalized communities, and so
I want people to know that I am an ally, and I am here to support
and work for equitable opportunities for all individuals regardless of
what their different diversity might be, and so having my disability
out there on social media gives people a little more insight into me as
a person.”

Disclose disability selectively based on social contexts. Some

participants decided whether to disclose their disabilities based on
specific social circumstances. Seven participants (three DHH and
four VI participants) considered the audience. Some preferred dis-
closing their disabilities only to the audience who they knew in
real life. For example, H-P1 did not want to disclose her disability
to random strangers in social VR: “I think the only situation I can
think of where I may not disclose is when there are other strangers,
too many strangers. In a setting where you can just show up, and a
stranger can come run after you, I would not want to [disclose my
disability].”

V-P2 emphasized that disability was her privacy. She would not
share information about her disability on every occasion. Instead,
she would assess the situation and audience, then make the decision
accordingly. As she indicated, “Well, in general, I am a private person.
I don’t like too many people knowing about my disability, because
they haven’t been through what I’ve been through, they judge before
they even know. I am a really sensitive person, so somebody says that
to me may not be hurtful to them, [but hurtful to me].”

Present a different self that is not defined by disability.
While the majority of participants were willing to disclose their
disabilities via avatars, three participants (H-P4, V-P4, and M-P2)
held the opposite attitudes. H-P4 preferred not disclosing her dis-
ability at all because she did not want her disability to become her
representative identity and to overshadow her personality when
socializing with others: “I don’t like to disclose [my disability], be-
cause I don’t want that to be the initial impression that people have,
that this person is deaf. I just don’t feel a need to say anything unless
I have to. Because it might just be a personal thing, and I just don’t
want that to be characteristically associated. It’s not a bad thing. But
I’ve been that way (not disclosing disability unless necessary) all my
life, not just in VR.”

Moreover, some participants (H-P4, V-P4, and M-P2) viewed
social VR as a world where they can express themselves freely
and explore an ideal self that was different from the real world. As
V-P4 said, “Because I feel like in virtual reality, your disability really
shouldn’t matter because it’s virtual reality. And virtual reality you’re
not hampered or hindered or shouldn’t be any way. So my case of
blindness, plus a prosthetic leg, should not hold me back in virtual
reality.”

4.2.3 Avatar Customization for Disability Disclosure. While
most participants indicated a strong desire to be able to show their
disabilities via avatar design, they experienced various difficulties
in practicing disability disclosure via avatars. In this section, we
reveal participants’ challenges in disability disclosure via avatars,
the strategies they adopted, and their desired features to support
disability representation.

Challenges in disclosing disability via avatars. We identi-
fied four main challenges that participants encountered when dis-
closing disability via avatars.

First, almost all participants (18 out of 19) complained about the
lack of disability representations in avatar design. Seven partici-
pants mentioned not knowing or not being able to find any avatar
features that represent disabilities on the social platforms they used.
While some platforms support limited disability features (e.g., hear-
ing aids and cochlear implants in Meta Avatars), the choices and
customization options were limited. For example, H-P2 mentioned
that Snapchat only provided hearing aids for avatars, but people
who used cochlear implants did not want to use them to represent
their disabilities. Due to the lack of disability features, V-P5 used
regular avatar decorations (i.e., sunglasses) to present her low vi-
sion. However, it cannot clearly signify her disability since people
without disabilities also use it. As V-P5 said, “My avatar has sun-
glasses [since I’m light sensitive], but this doesn’t really make sense
because anybody can wear sunglasses. I honestly do wish that there is
more representation of people with disabilities.”

V-P4 further emphasized the importance of avatar diversity for
disabilities by comparing it to other minority groups, “I think it’s a
very good idea to have [disability-related] features, I might even use
them. Everyone’s talking about diversity and it’s all about race and
gender. But one common thing that gets left out is disability. I think
that you should have the option to represent, whether you want to use
that or not it’s up to you, but it never hurts to have.”

Second, current disability signifiers for avatars were not always
compatible with other avatar features. For example, H-P1 tried to
put a cochlear implant on her avatar but ended up not using it since
it was blocked by the avatar’s hair: “The [Meta Avatars] do have a
cochlear implant you can add. But you can’t see it, because my hair
kind of covered it. I tried to spare [the hair] in a pony tail to see if
you could see the cochlear implants. But you couldn’t, so I put it back
down.”

Moreover, the unrealistic size of the virtual hearing devices also
prevented participants from applying them to their avatars. H-P5
explained her experience in Roblox: “The hearing aids are larger
than the character, so if you try to put them on, it’s seriously like
trying to put Barbie clothes on like a Little Tikes doll. They’re just
wrong, they’re just floating.”

Methods of disclosing disabilities via avatars. Participants
mostly disclosed their disabilities by accessorizing their avatars with
the assistive devices they used in real life. Three DHH participants
added cochlear implants or hearing aids to their avatars (H-P1 and
H-P7 on Meta Avatars, H-P3 on Snapchat). For VI participants, there
were no avatar features designed to represent visual impairments
on current social VR platforms. Two VI participants (V-P2 and V-
P5) thus put dark glasses on their avatars to signify their visual
impairments. “My avatar has sunglasses because when I go out, I

Avatar Diversity and the Self-presentation of People with Disabilities in Social VR

ASSETS ’22, October 23–26, 2022, Athens, Greece

always have sunglasses with me, because I’m light sensitive. So that
is why my avatar is wearing sunglasses.” (V-P5).

Moreover, P-H6 added an ID badge and a mini-status to his
avatars to indicate his disability. As he described, “You can make
your own ID badge to explain that you’re Deaf or/and Hard of Hearing
and have it on your avatar so you can let anyone read it and learn
about you. And plus I have a little mini status that would show above
my avatar head [if you enabled it in the menu], it’ll say ‘I’m Deaf
:D.”’ (Fig. 2A)

Figure 2: A. H-P6’s mini-status in VRChat; B. H-P6’s sign
avatar with black-outlined hands and ID Badge

Alternative approaches to disclosing disabilities. Besides
avatars, participants (nine VI and seven DHH participants) used
other methods, such as bio, posts, photos, emoji, and YouTube
videos, to present their disabilities on social media.

Compared to the 2D social platforms, we found that many par-
ticipants (six DHH and two VI) were more willing to disclose their
disabilities via 3D avatars in social VR. The embodied experience
made participants feel more comfortable disclosing their disabili-
ties. In contrast, some participants (H-P4, H-P5) felt that expressing
their disabilities in a less embodied way (e.g., via text on social
media) was highlighting their disabilities rather than representing
themselves. As H-P5 noted, “The hearing aids are physical reality
for me, so I just have them on [my avatar]. I wouldn’t want to put
it in text. I wouldn’t want it to be [highlighted]. While [the hearing
aid] is visible it feels more subtle [than disclosing my disability in
text].” Meanwhile, some participants felt that the visual presenta-
tion of avatars was more noticeable than in other mediums. For
example, H-P2 claimed that avatar would be "the first thing" that
people see, and H-P7 added that “it’s the easiest way of [disclosing
my disability]. I don’t think I would put it in like text information
like oh I’m deaf. Because I think most of the time well, probably no
one reads it.”

In addition, H-P7 considered social VR to be a safer place to
disclose disability since he could easily move away from toxic con-
versations. As he indicated, “the freedom of moving around [with
avatars] makes you get the power to walk away [from offensive com-
ments], you have a bit of control that you wouldn’t have in social
media.”

However, some VI participants preferred using text-based meth-
ods to disclose their disabilities other than avatars since avatars
were visual and not accessible. For instance, V-P7 wrote posts or ar-
ticles to reveal her disability to the public. Five VI participants also

used emojis (e.g.,
) in their posts to present their disabilities.
For instance, M-P1 utilized disability-related emojis in her everyday
communications. As she mentioned, “Well, I didn’t create [the emoji],
but I like that [they] are already on the iPhone. There is a person with
a white cane or whatever. I have used those before to represent me, if
I’m writing something, posting a message, or something.”

Desired Disability Representations in Avatar Design. Par-
ticipants suggested various ways to facilitate disability represen-
tation in avatars. Most participants hoped that avatar interfaces
could include more assistive devices for PWD (e.g., prosthetic limbs,
wheelchairs, white cane). While some platforms already provided
hearing aids and cochlear implants, DHH participants wanted more
options that present different details. For example, they wanted
hearing aids with different colors, brands, and wearing methods
(e.g., one side and both sides), so that users can freely choose their
preferred appearance of assistive devices and feel more realistic.
For VI participants, two main desired features were the white cane
and guide dog, which were commonly used by VI people in real
life. Beyond simply incorporating assistive devices, participants
also expressed the need to communicate their personalities through
the assistive devices they used. Two participants (V-P1 and V-P6)
desired to decorate their avatars’ canes. As V-P6 explained, “[The
cane] not only ties in with my disability, but like my person-hood as
well around and through that disability.” Moreover, M-P1 who used
Braille wished to have jewelry with Braille on it, which represented
“her culture as a person with a disability.”

Besides accessories, H-P1 emphasized the need for a customiz-
able avatar body to accurately reflect PWD’s physical appearance,
including their disabilities. She used the Helen Keller doll as an
example, “When the Helen Keller doll came out, Haben Girma, who’s
a very famous blind person, was not happy with that because [the
doll’s] eyes were proportional. They were the same. But Helen Keller in
real life, her eyes are not. I mean, even Haben’s eyes are not perfectly
proportioned. So maybe that would be something worth improving,
is to give people the ability to customize the eyes differently. Some
people may want to be as accurate as possible.”

However, one participant (H-P8) did not support providing dis-
ability features for avatars. He was concerned that these features
could be abused by people without disabilities and suggested ver-
ifying the authenticity of one’s disability before a user achieves
access to these features. As he described, “From my experience in
VRChat, there are a lot of people who have faked disabilities. Do not
trust anyone even your new online friends that you have met recently.
I don’t think it’s necessary to show any disabilities on the avatars.
People have to show proof that they truly have disabilities. For exam-
ple, I won’t hold back and sign fast as possible to fake deaf people.
They will suddenly show their ugly true colors.”

4.2.4 Specialized avatars and VR-ASL for the Deaf commu-
nity. Notably, three people in the Deaf community3 (H-P4, H-P6,
H-P8) reported using specialized avatars to sign in social VR, specif-
ically in VRChat (Fig. 2B). All three participants were members
of the “Helping Hands” community in VRChat, where they were
either learning or teaching American Sign Language (ASL). Instead
of typical ASL, they used VR-ASL, a simplified version of ASL in

3The Deaf community “views themselves as a unique cultural and linguistic minority
who use sign language as their primary language” [12].

ASSETS ’22, October 23–26, 2022, Athens, Greece

Zhang et al.

VR (Fig. 3). We report participants’ experiences with the specialized
avatars and VR-ASL.

VR-ASL. ASL in real life involved rich movements of fingers,
body gestures, and facial expressions. However, not all signs can
be recognized in VR due to its limited tracking capabilities. Thus,
Deaf users simplified or adjusted some signs so that they could be
captured by the current VR controllers, which resulted in VR-ASL
(Fig. 3A). It is worth noting that all three participants who used
VR-ASL adopted the Valve Index Knuckles Controllers, which can
capture more hand gestures and finger movements than other VR
controllers [39].

Specialized sign avatars. To enable people to better perceive
the signs, participants used specialized sign avatars in VRChat. The
sign avatars had three unique characteristics. First, their hands
usually had a high contrast skin color to the avatars’ clothes, which
increased the visibility of the hand gestures. As H-P4 mentioned,
“Oftentimes, people who use sign language, if their [avatar] skin is
white, it’s easier to see and contrast [with dark shirts color], so that
helps people visually understand what you’re saying.” Second, many
sign avatars had black outlined hands to further enhance their visi-
bility (Fig. 2B). Last, sign avatars were re-programmed to support
richer gestures, so that users can conduct more sophisticated signs
in social VR (see the creation of specialized avatars in Section 4.2.4).
For example, H-P4’s avatar can perform the hand gesture that sig-
nified the letter “y” in ASL (Fig. 3B), while with the same controller
input, typical avatars would only pose a “rock and roll” gesture (Fig.
3C) that did not represent any sign letters.

Creation of specialized sign avatars. Participants used dif-
ferent ways to acquire, create, and customize sign avatars. H-P4
usually imported the publicly available avatars in VRChat into
Unity and re-programmed them to support more hand gestures.
H-P4 explained the detailed process of her avatar augmentation
in Unity: “I was using custom animations, and I was able to modify
the controller inputs to play animations, like I might be able to do ‘e’
hand or flat ‘o’ hand, otherwise you won’t be able to have it. Here
is a little chart with all the different combinations you can do (Fig.
4A), and I was able to modify the game to which I can have access to
even more [gestures] with the combination.” H-P8 also modified the
avatars in VRChat, but he asked his friends to do it for him due to
technical barriers (see Section 4.2.5).

Instead of creating his own avatars, as a teacher who taught
VR-ASL in Helping Hands, H-P6 received his avatars as a gift from
“A9,” a professional creator of sign avatars. A9 owned a warehouse
in VRChat, showcasing all the sign avatars he created for VR-ASL
(Fig. 3D). Members in Helping Hands can choose sign avatars from
his warehouse.

Unique disability disclosure via sign avatars. All three par-
ticipants who used VR-ASL preferred not using any hearing devices
on their avatars, because these assistive devices can not distinguish
Deaf people from deaf or hard of hearings people. Instead, the best
way to present the Deaf culture was to sign via their avatars. As
such, the sign avatars and the use of VR-ASL became a unique way
of disability disclosure for Deaf people. As H-P6 explained, “I can
convey and gesture [my disability] to anyone I meet, ‘Sorry, me deaf,
me sign’ and they get the gist just fine anyway.”

4.2.5 Avatar Creation and Accessibility. Avatar creation and
customization posed barriers to some participants, especially those
with visual impairments. We describe the different challenges DHH
and VI participants faced.

Barriers to DHH people. For DHH participants, the avatar
customization interface in social VR was accessible and easy to use.
Six DHH participants reflected that they did not encounter any
difficulties because all avatar features and customization steps were
visual and rarely involved any audio information.

However, the major challenge occurred when creating the spe-
cialized sign avatars with third-party platforms since it required
programming skills (Section 4.2.4). Both H-P4 and H-P8 reported
experiencing technical issues and highlighted the lack of support
in solving the issues. As H-P4 emphasized, “Oh so many times, you
don’t even want to believe, it’s always difficult because when the issue
is about avatar creation, as of now is that there isn’t a lot of resources
about it. There isn’t a lot of tutorials that are either very relevant or
high quality for creating avatars. So that has a lot to be progressed.
That’s like my biggest issue. I don’t know how to do something.”

Although some third-party platforms offered tutorials for avatar
customization, most tutorials focused on audio instructions and
were not accessible to DHH users. As H-P6 complained, “I think
there were some visual examples and others, which was very helpful
to learn about, but for most of it was about audio stuff which I, un-
fortunately, can’t hear them. I feel like they haven’t thought this out
very well.”

Barriers to VI people. Unlike DHH participants, VI partici-
pants faced more significant challenges when creating avatars and
using VR platforms in general. Without the support of a screen
reader, VR was not accessible at all to blind users. For example,
M-P2 purchased an Oculus Quest but decided to abandon it due
to accessibility issues. As he explained, “I have tried, the Oculus
Quest, totally inaccessible, because it does not speak. I see it has no
screen reading functionality in it. Because I have absolutely no use
for this thing unless Meta includes screen reading technology and
text-to-speech technology in this. Still, it’s sitting in my closet in its
original box, it’s never even been opened.”

For low vision participants, similar to Zhao et al.’s results [89],
we found that information readability was a big challenge. The text
on some avatar interfaces was too small. Moreover, some interfaces
appeared at a fixed distance, preventing users from getting close
to see. As V-P4 said, “For avatar creation, they’ll use that sort of flat
screen style interface, but then the texts are not large enough, well
then you either guess, or you just don’t interact with it. So that’s where
the problem is.”

Avatar creation on social media. Compared to VR, avatar
creation on conventional social media was more accessible to VI
participants since participants can access the interface with their
phone or computer that incorporated a screen reader. Seven VI
participants had experience creating avatars on social media, such
as Instagram and SnapChat. However, VI participants still faced
various challenges.

The biggest issue was the lack of sufficient descriptions across the
whole avatar design process. When designing avatars, participants
(e.g., V-P1, V-P7) had difficulty understanding each avatar feature,
tracking their design progress, and confirming the final outcome.
Without suitable descriptions and notifications, the avatars created

Avatar Diversity and the Self-presentation of People with Disabilities in Social VR

ASSETS ’22, October 23–26, 2022, Athens, Greece

Figure 3: A. Signing the alphabet using ASL vs. VR-ASL; B. H-P4’s avatar signing “y” hand; C. the “Rock and Roll” gesture; D.
Warehouse with sign avatars created by “A9”.

Figure 4: Creation of specialized sign avatars: A. Oculus Hand Chart; B. Unity interface in modifying hand gestures

by VI participants (e.g., V-P7, V-P8) did not match their desired
avatar appearances. As V-P7 indicated, “Meta has a little bit of
description, but not everything has a description. So the first [avatar]
I made, [my friends] said it was terrible, didn’t look anything like me.
I didn’t choose the right face, I didn’t choose the right color skin tone.
People told me the outfit I chose was ugly. I didn’t get a lot of positive
feedback.” Since participants could not see and confirm the final
look of their avatars, they did not build strong connections with
the avatars, thus not caring much about their avatars: “When I was
designing [my avatar], I did have to have my daughter help. It wasn’t
very accessible and so really it doesn’t mean a lot to me because I’m
not completely invested in it, because I can’t confirm that I like it”
(V-P7).

Moreover, the avatar customization interfaces usually offered a
long list of options, which was difficult for VI users to navigate with
screen readers. As V-P6 said, “I think there were so many buttons to
flick through, for example, I would choose my hair color and it will
be like 60 of them. Those processes [pose] accessibility hazards. I am
good with technology, but I think that someone who was not so good
with technology would get really overwhelmed with that.”

5 DISCUSSION
Our research has contributed the first exploration of avatar diver-
sity and PWD’s self-presentation in social VR. We answer the three
research questions proposed in the Introduction. Firstly, our sys-
tematic review in Study I highlighted the lack of disability represen-
tation in avatar design on the mainstream social VR platforms. Only
the Meta Avatars (and the platforms that adopted the Meta Avatars)
provided disability-related features, but the features were restricted
to DHH people (RQ1). Secondly, our in-depth interviews in Study
II indicated that PWD employed a spectrum of self-presentation
strategies via avatars in social VR (see details in Section 5.1), and
the majority of them showed strong preferences in disclosing their
disabilities via avatars by adding the assistive tools they used in real
life (RQ2). We also uncovered the major differences between DHH
and VI participants in avatar perception (Section 5.2). Lastly, the
avatar creation and customization process posed barriers to PWD,
especially for VI participants (RQ3). In this section, we discuss the
unique self-presentation strategies of PWD from the lens of disabil-
ity disclosure, the avatar perception differences between DHH and
VI users, and the design considerations we derive to inspire more
accessible and inclusive avatar design.

ASSETS ’22, October 23–26, 2022, Athens, Greece

Zhang et al.

5.1 Disability Disclosure via Avatars in Social

5.2 Avatar Perception of People with Different

VR

Disabilities

Our research identified some similar self-presentation patterns
observed in people without disabilities. We confirmed that most
people regarded the embodied avatars as themselves and designed
avatars to reflect their physical selves [25], and people may want
their avatars to reveal a different self in online games other than
their physical selves [42].

Beyond the insights from prior research, our research uncovered
PWD’s unique avatar perceptions and self-presentation strategies
in social VR. We found that PWD managed their disability dis-
closure to craft their self-images in social VR. Instead of a binary
switch between disclosing and not disclosing [16], PWD adopted
a spectrum of strategies to determine to what extent and from
what aspect they would like to disclose their disability to shape
their avatar figures. Some participants saw disability as part of
their physical selves and wanted to reflect their disability as accu-
rately as possible; some selectively disclosed a certain aspect of
their disabilities (e.g., the more visible disability, or the disability
with stronger personal attachment) to signify their major disability
identity; and some participants with acquired or progressive dis-
abilities employed avatars as a nuanced way to indicate their ability
changes. Moreover, PWD disclosed their disabilities via avatars
to convey certain signals to the audience. For example, some par-
ticipants designed avatars with disability features to demonstrate
their capability and independence, while some participants used
their avatars to increase disability awareness and advocate for di-
versity and equity. These patterns demonstrated the importance
of disability disclosure for PWD in self-presentation, suggesting
the necessity of granting PWD sufficient flexibility to control their
disability disclosure in the avatar creation process.

Our research also highlighted PWD’s different disability disclo-
sure preferences from other online social platforms (e.g., social
media, virtual worlds). While avatars were also supported in some
2D/desktop-based social platforms (e.g., Instagram, Second Life),
PWD generally did not feel attached to their avatars due to the lack
of embodiment, and many tended to hide their disabilities by using
non-human avatars [16, 75]. In contrast, our study suggested that
the embodied nature of social VR enabled people to build strong
attachment with their avatars, making them more willing to reflect
their disabilities in their avatars. Some participants (H-P4, H-P5)
mentioned that they did not want to disclose their disabilities on
social media since it felt like “showing off” their disabilities, but
displaying their disabilities via avatars in social VR were more nat-
ural. The support of embodied interaction further enhanced PWD’s
engagement and attachment. Our Deaf participants can thus com-
municate with their preferred manner in real life—ASL, and they
even created VR-ASL to accommodate to the limited capability of
current VR technology. Our findings echoed the Embodied Social
Presence Theory [58] that the embodied avatars and the shared vir-
tual space and activities can affect user perception and bring them
to a higher engagement level, and further expanded this theory by
providing evidences from the disability perspective.

Our findings uncovered DHH and VI people’s different avatar ex-
perience and perception. Given the visual-driven nature of current
VR technology, it is not surprising that VI people face tremen-
dously more challenges than DHH people when designing and
using avatars. Our study showed that DHH users had much more
substantive avatar experiences than VI users. DHH users already
started forming communities in social VR (e.g.,“Helping Hands”),
whereas the majority of VI participants only tried social VR for
a few times. Due to the distinct avatar experiences, DHH and VI
people perceived avatars differently. Since VI users cannot see or
even imagine the appearances of their avatars, they had weak at-
tachment with their avatars and some ended up not caring about
their avatars at all in social VR. As V-P4 said, “[Avatar design] really
is just for fun, I mean it’s just kind of seeing what types of appear-
ances, or what types of features that the avatars have. I really don’t
necessarily care about avatars all that much.” In contrast, DHH peo-
ple showed stronger attachment with their avatars and spent more
effort customizing, specializing, and even re-programming their
avatars for better self-presentation and communication.

While this research focused only on DHH and VI users, our
findings indicated that people with different disabilities may have
different avatar perception and self-presentation preferences. For
example, compared to people who have visible disabilities (e.g., a
person with an amputation) or who use apparent assistive tech-
nologies (e.g., a VI person who has a cane), people with invisible
conditions and using invisible assistive technologies (e.g., a person
who experiences chronic pain and uses a trigger tracker) may be
more reluctant to disclose their disabilities in social VR. Future
research should consider other disabilities and explore different
factors that may affect people’s disability disclosure decisions, such
as visibility of disability and visibility of assistive technology [23].

5.3 Design Implications for Avatar Diversity

and Accessibility

5.3.1 Avatar Diversity. We drew three design implications to
promote disability representations for avatars.

Offer more assistive device representations. Most partici-
pants saw their assistive devices as the key signifier of their disabili-
ties and preferred adding these devices to their avatars for disability
representation. Participants suggested various commonly-used as-
sistive technologies that can represent their disabilities, including
a white cane and guide dog for VI people, cochlear implants and
hearing devices for DHH people, and prosthetic limbs, wheelchair,
and walking aids for people with motor disabilities. Besides the
basic assistive technology representations, participants wanted to
further personalize their virtual assistive devices to reflect their
aesthetics and personalities, for example, customizing the color and
the brand. Adding these features in the mainstream avatar systems
would empower PWD to express and present themselves freely and
equally in social VR. Designers should involve PWD throughout
the whole avatar design process to ensure the suitability of the
disability representations.

Support representations for people with invisible disabili-
ties. Compared to visible disabilities, some invisible disabilities

Avatar Diversity and the Self-presentation of People with Disabilities in Social VR

ASSETS ’22, October 23–26, 2022, Athens, Greece

could not be easily expressed, especially when no apparent assis-
tive technologies are used to signify the disability. In our study,
participants suggested using accessories, such as a necklace with
Brailles or an arm badge with their community logo, to present
their disabilities. We suggest that designers should consider using
these indirect mediums, such as outfits with disability signifiers
(e.g., a T-Shirt with the Autism Awareness Puzzle logo), to enable
people with invisible disabilities to better manage their disability
visibility in social VR.

Guarantee appropriate use of diversity features. Adding
more avatar diversity features may also pose potential risks. Our
participants indicated their concerns on the inappropriate usage of
these features by people without disabilities. The abuse of diversity
features can lead to cyber-bullying and increase the misconception
of disability from the public. One participant (H-P8) further sug-
gested conducting strict verification on the authenticity of one’s
disability before they can access the diversity features. How to
guarantee the proper use of the diversity features is a vital issue
that should be considered by the commercial social VR platforms
from both the design and the policy perspectives. Researchers and
designers should investigate how to set up suitable rules to support
interaction freedom without marginalizing and harming vulnerable
populations on these new and emerging social platforms.

5.3.2 Avatar Accessibility. Our findings highlighted the difficul-
ties faced by VI and DHH people when designing avatars. This
echoed the general VR accessibility issues revealed by prior re-
search [10, 47, 61, 89], and also expanded the problems from a new
avatar creation perspective. We drew three design implications to
enhance avatar accessibility.

Combine avatar automation with fine-grained customiza-
tion. Avatar creation is not accessible to VI participants due to
its heavily visual-driven nature and the complex steps to navigate.
Our blind participants usually needed external human assistance
in customizing their avatars. Instead of crafting the avatars from
scratch, some participants suggested automating the avatar genera-
tion process (M-P1, V-P5): the avatar system should automatically
generate a baseline avatar based on the user’s photo, and allow
the user to adjust details based on their preferences. While not
new, this feature is supported by very limited number of social VR
platforms. In our application review (Study I), only three out of 15
commercial social VR platforms support avatar automation. We
suggest that designers should consider enabling multiple avatar
creation methods—both auto generation and manual adjustment—
to enhance the accessibility of avatar creation and customisation
for people with diverse abilities.

Convey avatar design outcomes for VI users. VI users rely
on alternative text to perceive graphic information. Our research
highlighted the lack of and the need for alternative text and screen
reader support for avatars in social VR. While the avatar design
system for conventional social media (e.g., Facebook, SnapChat)
could be accessed by VI users via alternative text and embedded
screen readers, participants reported challenges in understanding
their customization progress and final outcomes, which led to their
emotional detachment from the avatars. Artificial intelligence (AI)
technology could be considered to recognize the avatars and gener-
ate semantic confirmations about the holistic avatar customization

outcomes, such as whether the avatar looks like the user. However,
this could be technically and ethically challenging since catego-
rizing and recognizing human facial features is difficult in both
technology [15, 67, 73] and sociology fields [19, 33]. For example,
an algorithm may mis-recognize particular avatar or user faces and
report inappropriate results. Moreover, how to suitably label and
describe human appearance, especially the marginalized groups, is
another important question to consider [4, 33, 40]. Besides refining
the algorithms and datasets from the computer vision perspective
[77], HCI solutions could also be adopted, for example, indicating
the potential inaccuracy of the recognized results to users [54, 91],
or leveraging human-AI collaboration to achieve more reliable re-
sults [32, 51].

Add closed caption for all audio information. Although
the avatar creation and customization process was visual-driven,
adding closed caption would still be valuable, especially for DHH
users. We believe that with proper caption positioning, closed cap-
tion will have an significantly positive impact on the social VR
ecosystem.

6 LIMITATIONS AND FUTURE WORK
In this paper, we studied the avatar experience and perception of
PWD on social VR platforms. We focused on two disability groups—
DHH and VI people. Future work should take into account more
diverse types of disabilities to get a more comprehensive under-
standing of PWD’s disability disclosure preferences, especially for
people with invisible disabilities. Moreover, our application review
study (Study I) focused on the Oculus Quest 2 platform. Although
social VR applications mostly support the same avatar design and
accessibility features across VR devices, we acknowledge that dif-
ferent VR devices may offer their own system-level avatars (e.g.,
Oculus offers the Meta Avatars), which may bring nuances to the
review results. Thus, other mainstream VR devices should also be
considered to achieve a more comprehensive results. Finally, future
work may complement our qualitative findings with quantitative
analysis to investigate what factors may impact PWD’s disability
disclosure behaviors, such as gender, age, and disability visibility.

ACKNOWLEDGMENTS
We thank the National Federation of the Blind for helping us recruit
for our study, as well as the anonymous participants that provided
their perspective.

REFERENCES
[1] Dominic Abrams and Michael A Hogg. 2004. Metatheory: Lessons from social

identity research. Personality and social psychology review 8, 2 (2004), 98–106.

[2] Alvirmin. 2021.

7 Best Social Networking Apps in VR for Oculus Quest
2. https://allvirtualreality.com/review/best-social-networking-apps-vr-oculus-
quest.html last accessed 5 July 2022.

[3] Jane Bailey, Valerie Steeves, Jacquelyn Burkell, and Priscilla Regan. 2013. Negoti-
ating with gender stereotypes on social networking sites: From “bicycle face” to
Facebook. Journal of Communication Inquiry 37, 2 (2013), 91–112.

[4] Cynthia L Bennett, Cole Gleason, Morgan Klaus Scheuerman, Jeffrey P Bigham,
Anhong Guo, and Alexandra To. 2021. “It’s Complicated”: Negotiating Accessibil-
ity and (Mis) Representation in Image Descriptions of Race, Gender, and Disability.
In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems.
1–19.

[5] Katherine Bessière, A Fleming Seay, and Sara Kiesler. 2007. The ideal elf: Identity
exploration in World of Warcraft. Cyberpsychology & behavior 10, 4 (2007),
530–535.

ASSETS ’22, October 23–26, 2022, Athens, Greece

Zhang et al.

[6] Tom Boellstorff. 2019. The Ability of Place: Digital Topographies of the Virtual
Human on Ethnographia Island. Current Anthropology 61 (08 2019), S109–S122.
[7] Natilene Bowker and Keith Tuffin. 2002. Disability discourses for online identities.

Disability & Society 17, 3 (2002), 327–344.

[8] Virginia Braun and Victoria Clarke. 2006. Using thematic analysis in psychology.

Qualitative research in psychology 3, 2 (2006), 77–101.

[9] Justin Buss, Hayden Le, and Oliver L Haimson. 2022.

Transgender
identity management across social media platforms. Media, Culture &
Society 44, 1 (2022), 22–38.
https://doi.org/10.1177/01634437211027106
arXiv:https://doi.org/10.1177/01634437211027106

[10] Diane Carr. 2010. Constructing disability in online worlds: conceptualising
disability in online research. London Review of Education (03 2010), 51–61.
[11] Justine Cassell. 1998. Chess for girls?: Feminism and computer games. (1998).
[12] National Deaf Center. 2021. The Deaf Community: An Introduction.
[13] Victoria Clarke, Virginia Braun, and Nikki Hayfield. 2015. Thematic analysis.
Qualitative psychology: A practical guide to research methods 222 (2015), 248.
[14] Paul C Cozby. 1973. Effects of density, activity, and personality on environmental

preferences. Journal of Research in Personality 7, 1 (1973), 45–60.

[15] Chirag Dalvi, Manish Rathod, Shruti Patil, Shilpa Gite, and Ketan Kotecha. 2021.
A Survey of AI-Based Facial Emotion Recognition: Features, ML & DL Techniques,
Age-Wise Datasets and Future Directions. IEEE Access 9 (2021), 165806–165840.
[16] Donna Z Davis and Shelby Stanovsek. 2021. The machine as an extension of the
body: When identity, immersion, and interactive design serve as both resource
and limitation for the disabled. Human-Machine Communication 2 (2021), 121–
135.

[17] Joan Morris DiMicco and David R Millen. 2007. Identity management: multiple
presentations of self in facebook. In Proceedings of the 2007 international ACM
conference on Supporting group work. 383–386.

[18] Nicolas Ducheneaut, Ming-Hui Wen, Nicholas Yee, and Greg Wadley. 2009. Body
and mind: a study of avatar personalization in three virtual worlds. In Proceedings
of the SIGCHI conference on human factors in computing systems. 1151–1160.
[19] Yarrow Dunham, Elena V. Stepanova, Ron Dotsch, and Alexander Todorov. 2015.
The development of race-based perceptual categorization: skin color dominates
early category judgments. Developmental Science 18, 3 (2015), 469–483.

[20] Allison Eden, Erin Maloney, and Nicholas David Bowman. 2010. Gender attribu-
tion in online video games. Journal of Media Psychology: Theories, Methods, and
Applications 22, 3 (2010), 114.

[21] Blizzard Entertainment. 2021. World of Warcraft. https://worldofwarcraft.com/

en-us/ last accessed 5 July 2022.

[22] Shelly D Farnham and Elizabeth F Churchill. 2011. Faceted identity, faceted lives:
social and technical issues with being yourself online. In Proceedings of the ACM
2011 conference on Computer supported cooperative work. 359–368.

[23] Heather A. Faucett, Kate E. Ringland, Amanda L. L. Cullen, and Gillian R. Hayes.
2017. (In)Visibility in Disability and Assistive Technology. 10, 4 (2017), 17 pages.
[24] Katrina Fong and Raymond A Mar. 2015. What does my avatar say about me?
Inferring personality from avatars. Personality and Social Psychology Bulletin 41,
2 (2015), 237–249.

[25] Guo Freeman and Divine Maloney. 2021. Body, avatar, and me: The presentation
and perception of self in social virtual reality. Proceedings of the ACM on Human-
Computer Interaction 4, CSCW3 (2021), 1–27.

[26] Guo Freeman, Samaneh Zamanifard, Divine Maloney, and Alexandra Adkins.
2020. My body, my avatar: How people perceive their avatars in social virtual
reality. In Extended Abstracts of the 2020 CHI Conference on Human Factors in
Computing Systems. 1–8.

[27] James Paul Gee. 2003. What video games have to teach us about learning and

literacy. Computers in entertainment (CIE) 1, 1 (2003), 20–20.

[28] Kathrin Gerling, Kieran Hicks, Michael Kalyn, Adam Evans, and Conor Linehan.
2016. Designing Movement-Based Play With Young People Using Powered
Wheelchairs. In Proceedings of the 2016 CHI Conference on Human Factors in
Computing Systems. 4447–4458.

[29] Jennifer L Gibbs, Nicole B Ellison, and Rebecca D Heino. 2006. Self-presentation
in online personals: The role of anticipated future interaction, self-disclosure,
and perceived success in Internet dating. Communication research 33, 2 (2006),
152–177.

[30] Erving Goffman. 1959. The presentation of self in everyday life. Bantam Doubleday

Dell Publishing group.

[31] Kathryn Greene, Valerian J Derlega, and Alicia Mathews. 2006. Self-disclosure
in personal relationships. The Cambridge handbook of personal relationships 409
(2006), 427.

[32] Anhong Guo, Anuraag Jain, Shomiron Ghose, Gierad Laput, Chris Harrison, and
Jeffrey P Bigham. 2018. Crowd-ai camera sensing in the real world. Proceedings of
the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2, 3 (2018),
1–20.

[33] Margot Hanley, Solon Barocas, Karen Levy, Shiri Azenkot, and Helen Nissenbaum.
2021. Computer Vision and Conflicting Values: Describing People with Auto-
mated Alt Text. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics,
and Society. 543–554.

[34] Daniel Hepperle, Christian Felix Purps, Jonas Deuchler, and Matthias Wölfel.
2021. Aspects of visual avatar appearance: self-representation, display type, and
uncanny valley. The Visual Computer (2021), 1–18.

[35] Daniel Hepperle, Hannah Ödell, and Matthias Wölfel. 2020. Differences in
the Uncanny Valley between Head-Mounted Displays and Monitors. In 2020
International Conference on Cyberworlds (CW). 41–48. https://doi.org/10.1109/
CW49994.2020.00014

[36] Tanner Higgin. 2009. Blackless fantasy: The disappearance of race in massively
multiplayer online role-playing games. Games and Culture 4, 1 (2009), 3–26.
[37] Zaheer Hussain and Mark D Griffiths. 2008. Gender swapping and socializing
in cyberspace: An exploratory study. CyberPsychology & Behavior 11, 1 (2008),
47–53.

[38] Nora F Huvelle, Milton Budoff, and Deidre Arnholz. 1984. To tell or not to
tell: Disability disclosure and the job interview. Journal of Visual Impairment &
Blindness 78, 6 (1984), 241–244.

[39] VALVE INDEX. 2022. Controllers. https://www.valvesoftware.com/en/index/

controllers last accessed 11 April 2022.

[40] Emory James Edwards, Kyle Lewis Polster, Isabel Tuason, Emily Blank, Michael
Gilbert, and Stacy Branham. 2021. "That’s in the Eye of the Beholder": Layers of
Interpretation in Image Descriptions for Fictional Representations of People with
Disabilities. In The 23rd International ACM SIGACCESS Conference on Computers
and Accessibility (ASSETS ’21). Article 19, 14 pages.

[41] Yasmin B Kafai, Deborah A Fields, and Melissa Cook. 2007. Your second selves:
avatar designs and identity play in a teen virtual world. In Proceedings of DIGRA,
Vol. 2007.

[42] Yasmin B Kafai, Deborah A Fields, and Melissa S Cook. 2010. Your second selves:

Player-designed avatars. Games and culture 5, 1 (2010), 23–42.

[43] Sanjay Kairam, Mike Brzozowski, David Huffaker, and Ed Chi. 2012. Talking in
circles: selective sharing in google+. In Proceedings of the SIGCHI conference on
human factors in computing systems. 1065–1074.

[44] Bernadett Koles and Peter Nagy. 2012. Who is portrayed in Second Life: Dr. Jekyll
or Mr. Hyde? The extent of congruence between real life and virtual identity.
Journal For Virtual Worlds Research 5, 1 (2012).

[45] Anya Kolesnichenko, Joshua McVeigh-Schultz, and Katherine Isbister. 2019. Un-
derstanding emerging design practices for avatar systems in the commercial
social vr ecology. In Proceedings of the 2019 on Designing Interactive Systems
Conference. 241–252.

[46] Robin M Kowalski, Chad A Morgan, Kelan Drake-Lavelle, and Brooke Allison.
2016. Cyberbullying among college students with disabilities. Computers in
Human Behavior 57 (2016), 416–427.

[47] Rachel L. Franz, Sasa Junuzovic, and Martez Mott. 2021. Nearmi: A Framework
for Designing Point of Interest Techniques for VR Users with Limited Mobility. In
The 23rd International ACM SIGACCESS Conference on Computers and Accessibility.
1–14.

[48] Linden Lab. 2013. 10 Years of Second Life. https://www.lindenlab.com/releases/

infographic-10-years-of-second-life last accessed 4 Feb 2022.

[49] Jong-Eun Roselyn Lee. 2014. Does virtual diversity matter?: Effects of avatar-
based diversity representation on willingness to express offline racial identity
and avatar customization. Computers in Human Behavior 36 (2014), 190–197.

[50] Jong-Eun Roselyn Lee and Sung Gwan Park. 2011. “Whose second life is this?”
How avatar-based racial cues shape ethno-racial minorities’ perception of virtual
worlds. Cyberpsychology, Behavior, and Social Networking 14, 11 (2011), 637–642.
[51] Sooyeon Lee, Rui Yu, Jingyi Xie, Syed Masum Billah, and John M Carroll. 2022.
Opportunities for human-AI collaboration in remote sighted assistance. In 27th
International Conference on Intelligent User Interfaces. 63–78.

[52] Qiaoxi Liu and Anthony Steed. 2021. Social Virtual Reality Platform Comparison
and Evaluation Using a Guided Group Walkthrough Method. Frontiers In Virtual
Reality (2021), 1–15.

[53] Xiao Ma, Jeff Hancock, and Mor Naaman. 2016. Anonymity, Intimacy and Self-
Disclosure in Social Media. In Proceedings of the 2016 CHI Conference on Human
Factors in Computing Systems (San Jose, California, USA) (CHI ’16). Association
for Computing Machinery, New York, NY, USA, 3857–3869. https://doi.org/10.
1145/2858036.2858414

[54] Haley MacLeod, Cynthia L Bennett, Meredith Ringel Morris, and Edward Cutrell.
2017. Understanding blind people’s experiences with computer-generated cap-
tions of social media images. In Proceedings of the 2017 CHI Conference on Human
Factors in Computing Systems. 5988–5999.

[55] Divine Maloney, Samaneh Zamanifard, and Guo Freeman. 2020. Anonymity
vs. familiarity: Self-disclosure and privacy in social virtual reality. In 26th ACM
Symposium on Virtual Reality Software and Technology. 1–9.

[56] Tony Manninen and Tomi Kujanpää. 2007. The value of virtual assets: the role of
game characters in MMOGs. International Journal of Business Science & Applied
Management (IJBSAM) 2, 1 (2007), 21–33.

[57] Rosa Mikeal Martey and Mia Consalvo. 2011. Performing the looking-glass self:
Avatar appearance and group identity in Second Life. Popular Communication 9,
3 (2011), 165–180.

Avatar Diversity and the Self-presentation of People with Disabilities in Social VR

ASSETS ’22, October 23–26, 2022, Athens, Greece

Computing Systems. 3133–3142.

[86] XRTODAY. 2022. The Best Social Apps in VR. https://www.xrtoday.com/virtual-

reality/the-best-social-apps-in-vr/ last accessed 5 July 2022.

[87] Jennifer Yurchisin, Kittichai Watchravesringkan, and Deborah Brown McCabe.
2005. An exploration of identity re-creation in the context of internet dating.
Social Behavior and Personality: an international journal 33, 8 (2005), 735–750.

[88] Shanyang Zhao, Sherri Grasmuck, and Jason Martin. 2008. Identity construction
on Facebook: Digital empowerment in anchored relationships. Computers in
human behavior 24, 5 (2008), 1816–1836.

[89] Yuhang Zhao, Edward Cutrell, Christian Holz, Meredith Ringel Morris, Eyal Ofek,
and Andrew D Wilson. 2019. SeeingVR: A set of tools to make virtual reality more
accessible to people with low vision. In Proceedings of the 2019 CHI conference on
human factors in computing systems. 1–14.

[90] Yuhang Zhao, Shaomei Wu, Lindsay Reynolds, and Shiri Azenkot. 2017. The effect
of computer-generated descriptions on photo-sharing experiences of people with
visual impairments. Proceedings of the ACM on Human-Computer Interaction 1,
CSCW (2017), 1–22.

[91] Yuhang Zhao, Shaomei Wu, Lindsay Reynolds, and Shiri Azenkot. 2018. A face
recognition application for people with visual impairments: Understanding use
beyond the lab. In Proceedings of the 2018 CHI Conference on Human Factors in
Computing Systems. 1–14.

A APPENDIX

[58] Brian E. Mennecke, Janea L. Triplett, Lesya M. Hassall, and Zayira Jordan Conde.
2010. Embodied Social Presence Theory. In 2010 43rd Hawaii International Con-
ference on System Sciences. 1–10.

[59] Akash Menon. 2021. The Role of Avatar Creation and Embodied Presence in

Virtual Reality Job Interviews.

[60] Helen Morgan, Amanda O’donovan, Renita Almeida, Ashleigh Lin, and Yael
Perry. 2020. The Role of the Avatar in Gaming for Trans and Gender Diverse
Young People. International journal of environmental research and public health
17, 22 (2020), 8617.

[61] Martez Mott, Edward Cutrell, Mar Gonzalez Franco, Christian Holz, Eyal Ofek,
Richard Stoakley, and Meredith Ringel Morris. 2019. Accessible by Design: An
Opportunity for Virtual Reality. In 2019 IEEE International Symposium on Mixed
and Augmented Reality Adjunct (ISMAR-Adjunct). 451–454.

[62] Lisa Nakamura. 1995. Race in/for cyberspace: Identity tourism and racial passing

on the Internet. Works and Days 13, 1-2 (1995), 181–193.

[63] Carman Neustaedter and Elena Fedorovskaya. 2009. Presenting Identity in a Vir-
tual World through Avatar Appearances. In Proceedings of Graphics Interface 2009
(Kelowna, British Columbia, Canada) (GI ’09). Canadian Information Processing
Society, CAN, 183–190.

[64] Veronica Pearson, Frances Ip, Heidi Hui, Nelson Yip, et al. 2003. To tell or not to
tell; disability disclosure and job application outcomes. Journal of Rehabilitation
69, 4 (2003), 35.

[65] John R Porter, Kiley Sobel, Sarah E Fox, Cynthia L Bennett, and Julie A Kientz.
2017. Filtered out: Disability disclosure practices in online dating communities.
Proceedings of the ACM on Human-Computer interaction 1, CSCW (2017), 1–13.
[66] Mark Rabkin. 2021. Connect 2021 Recap: Horizon Home, the future of work, presence
platforms, and more. https://www.oculus.com/blog/connect-2021-recap-horizon-
home-the-future-of-work-presence-platform-and-more/ last accessed 13 April
2022.

[67] Inioluwa Deborah Raji, Timnit Gebru, Margaret Mitchell, Joy Buolamwini, Joon-
seok Lee, and Emily Denton. 2020. Saving Face: Investigating the Ethical Concerns
of Facial Recognition Auditing. Association for Computing Machinery, New York,
NY, USA, 145–151. https://doi.org/10.1145/3375627.3375820

[68] Sheila Riddell and Elisabet Weedon. 2014. Disabled students in higher education:
Discourses of disability and the negotiation of identity. International Journal of
Educational Research 63 (2014), 38–46.

[69] Kathryn E Ringland. 2019. “Autsome”: Fostering an Autistic Identity in an Online

Minecraft Community for Youth with Autism. (2019), 142–143.

[70] Ann E Schlosser. 2020. Self-disclosure versus self-presentation on social media.
Current Opinion in Psychology 31 (2020), 1–6. https://doi.org/10.1016/j.copsyc.
2019.06.025 Privacy and Disclosure, Online and in Social Interactions.

[71] Zicodas Serapis. 2008. Coming of age in second life: an anthropologist explores

the virtually human.

[72] Carmit-Noa Shpigelman and Carol J Gill. 2014. Facebook use by persons with
disabilities. Journal of Computer-Mediated Communication 19, 3 (2014), 610–624.
[73] Luke Stark. 2019. Facial Recognition is the Plutonium of AI. XRDS 25, 3 (apr

2019), 50–55.

[74] Karen Stendal. 2012. How do People with Disability Use and Experience Virtual
Worlds and ICT: A Literature Review. Journal of Virtual Worlds Research (05
2012), 1–17.

[75] Karen Stendal, Judith Molka-Danielsen, Bjørn Munkvold, and Susan Balandin.
2012. Virtual worlds and people with lifelong disability: Exploring the relationship
with virtual self and others. ECIS (01 2012), 156–179.

[76] Stephanie Stewart, Terri S. Hansen, and Timothy A. Carey. 2010. Opportunities
for People with Disabilities in the Virtual World of Second Life. Rehabilitation
Nursing Journal 35 (2010), 254–259.

[77] Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf. 2014. DeepFace:
Closing the Gap to Human-Level Performance in Face Verification. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
[78] Sherry Turkle. 1999. Life on the Screen: Identity in the Age of the Internet. The

Psychohistory Review 27, 2 (1999), 113.

[79] Sherry Turkle. 2005. The second self: Computers and the human spirit. Mit Press.
[80] Sarah Von Schrader, Valerie Malzer, and Susanne Bruyère. 2014. Perspectives
on disability disclosure: the importance of employer practices and workplace
climate. Employee Responsibilities and Rights Journal 26, 4 (2014), 237–255.
[81] Zach Waggoner. 2009. My avatar, my self: Identity in video role-playing games.

McFarland.

[82] Paul Wallace and James Maryott. 2009. The impact of avatar self-representation
on collaboration in virtual worlds. Innovate: Journal of Online Education 5, 5
(2009).

[83] Thomas Waltemate, Dominik Gall, Daniel Roth, Mario Botsch, and Marc Erich
Latoschik. 2018. The impact of avatar personalization and immersion on vir-
tual body ownership, presence, and emotional response. IEEE transactions on
visualization and computer graphics 24, 4 (2018), 1643–1652.

[84] VRChat Legends Wiki. 2022. Helping Hands. https://vrchat-legends.fandom.

com/wiki/Helping_Hands last accessed 9 April 2022.

[85] Shaomei Wu and Lada A Adamic. 2014. Visually impaired users on an online
social network. In Proceedings of the SIGCHI Conference on Human Factors in

ASSETS ’22, October 23–26, 2022, Athens, Greece

Zhang et al.

VR Platforms

Avatar type

Avatar Customization

Avatar Realism

Disability Representation

Rec Room

VRChat

Horizon Worlds

vTime XR

AltspaceVR

Bigscreen

Alcove

Half+Half

Horizon Venues

Villa

Arthur

ENGAGE

Multiverse

PokerStars VR

Spatial

N/A

Any uploaded 3rd-party disability features

Hearing aids; cochlear implants

N/A

N/A

Eye patch

Hearing aids; cochlear implants

N/A

Hearing aids; cochlear implants

N/A

N/A

N/A

N/A

Hearing aids; cochlear implants

N/A

Table 2: Overview of social VR platforms and their avatar creation options. Description of the icons: humanoid avatar=
robot avatar= , cartoon avatar= , animal avatar= , object avatar=
upper body, arm hand, leg= , partial body avatar includes head, upper body, arm, hand =
floating upper body without arm = , floating hand= , floating fingerless hand =
customization = , photo-based avatar generation =

,
, abstract avatar= , full body avatar includes head,
,
, full avatar selection = , avatar feature

, floating head without neck=

, third-party avatar import =

