Will Metaverse be NextG Internet? Vision, Hype, and Reality

Ruizhi Cheng, Nan Wu, Songqing Chen, and Bo Han
George Mason University
Email: {rcheng4,nwu5,sqchen,bohan}@gmu.edu

2
2
0
2

n
a
J

0
3

]
I

N
.
s
c
[

1
v
4
9
8
2
1
.
1
0
2
2
:
v
i
X
r
a

Abstract—Metaverse, with the combination of the
preﬁx “meta” (meaning transcending) and the word
“universe”, has been deemed as the next-generation
(NextG) Internet. It aims to create a shared virtual
space that connects all virtual worlds via the Inter-
net, where users, represented as digital avatars, can
communicate and collaborate as if they are in the
physical world. Nevertheless, there is still no uniﬁed
deﬁnition of the Metaverse. This article ﬁrst presents
our vision of what the key requirements of Metaverse
should be and reviews what has been heavily advocated
by the industry and the positions of various high-tech
companies. It then brieﬂy introduces existing social
virtual reality (VR) platforms that can be viewed as
early prototypes of Metaverse and conducts a reality
check by diving into the network operation and per-
formance of two representative platforms, Workrooms
from Meta and AltspaceVR from Microsoft. Finally,
it concludes by discussing several opportunities and
future directions for further innovation.

I. Introduction

Although the term Metaverse has been around for al-
most 30 years since it was coined by Neal Stephenson in
his 1992 science ﬁction novel Snow Crash, we are still in
the early stage of actually building the Metaverse, which
envisions an immersive successor to the Internet. The
development of Metaverse has gone through several stages.
Retrospectively, the text-based interactive games, such as
MUD (multi-user dungeon) that emerged in the late 1970s,
could be viewed as the earliest prototypes of Metaverse,
even before the term was literally introduced. They deﬁne
a multiplayer virtual world with role playing, interact-
ive ﬁction, and online chat. The second phase happened
during the postmillennial decade with the development of
commercial virtual worlds such as Second Life1. It then
embraced fully 3D virtual worlds such as OpenSimulator2,
which is largely compatible with Second Life.

In the current stage, with the ﬂourishing of 5G and
mobile immersive computing [5], there has been a surge of
research & development on the Metaverse in both industry
and academia. We have now entered an open development
phase of the Metaverse, which is widely considered as a col-
lection of 3D virtual worlds connected via the Internet [4]
and enabled by various immersive technologies such as
augmented reality (AR), virtual reality (VR), and mixed
reality (MR) [13], which are often collectively referred to
as extended reality (XR). While there is still no uniﬁed

1https://secondlife.com/ (accessed on 30-January-2022)
2http://opensimulator.org/ (accessed on 30-January-2022)

Figure 1: Elements of the Metaverse and their interaction with
the physical world.

deﬁnition of the Metaverse, it is broadly deemed as the
next-generation (NextG) Internet.

Figure 1 illustrates the basic elements in the Metaverse
and how they interact with the physical world. In general,
users with XR devices access the Metaverse and particip-
ate in its various social events, whose smooth execution
is enabled by techniques such as 5G and HCI (human-
computer interaction). Users are free to create their own
content via 3D modeling to decorate social events in the
Metaverse. The content can be traded using non-fungible
token (NFT) through a decentralized blockchain. Physical
objects can be presented in the Metaverse as digital twins
that are generated via 3D modeling and consumed with
XR devices assisted by artiﬁcial intelligence (AI).

In this article, we present our vision of the Metaverse
by discussing its key technical requirements (Section II).
We then review recent advances in the industry and in-
troduce the advocates of various key players (Section III).
After that, we provide an overview of existing social VR
platforms, the early prototype of Metaverse that combines
online social networks and VR technologies, and compare
their unique features (Section IV). We then conduct a
ﬁrst-of-its-kind reality check to understand the networking
protocol usage and system performance of two represent-

Real-worldCurrency3D Modeling Real-worldObjectsMetaversePhysicalWorldNon-fungible  TokenSocialEvents  User-generatedContentDigital TwinsXR DevicesBlockchainXR5G, HCIAIXRDecorateTrade 
 
 
 
 
 
mmWave, from 24 to 39 GHz). Low-band 5G is used
for extensive coverage and is ideal
for deployment in
rural areas. Mid-band 5G has been commonly deployed in
metropolitan areas. High-band 5G can reach a maximum
throughput of, in theory, 10-20 Gbps. However, it works
in only a small radius, and thus is more useful in urban
areas and crowded locations (e.g., shopping malls).
• AR/VR/MR augment or supplant our view of the world,
and are a key to the success of Metaverse [11]. VR makes
people fully immersed in the virtual world, and social
VR is widely considered an important component of the
Metaverse. AR enables digital twins in the Metaverse
to be overlaid on physical objects in a perceptible way,
eﬀectively connecting the Metaverse with the physical
world. MR allows users to interact with virtual objects, by
creating more connections and collaborative relationships
among the physical world, virtual space, and users [13].
• Edge Computing is a computing paradigm that moves
computation and data storage closer to users. The advant-
ageous performance of edge computing in reducing latency
for XR has made it an important backbone for building
the Metaverse. Several telecom carriers have undertaken
a project called HoloVerse to test the best 5G edge
network infrastructure for eﬃcient deployment of services
in the Metaverse6. Meanwhile, Niantic, the producer of
P ok´emonGo, has joined forces with telecom carriers to
explore how 5G edge computing can enhance the quality
of experience (QoE) for AR games7.
• Blockchain ensures the security of data records and
generates trust without requiring trusted third parties. It
is closely related to user-generated content (UGC) such as
digital assets that can greatly enrich the Metaverse [12].
For example, NFT, which is used for trading in the
Metaverse, is a data unit on the blockchain. Deﬁning the
ownership of UGC in the Metaverse is a practical chal-
lenge, as digital assets can be copied and reproduced. NFT
provides an eﬀective way to prove that UGC is unique and
non-fungible (i.e., non-interchangeable). It enables owners
of digital content to sell/trade their property via smart
contracts in the decentralized crypto space (e.g., using
cryptocurrencies),
• Machine Learning, especially deep learning (DL),
is
an important branch of artiﬁcial intelligence (AI) that
enables machines to learn from massive amounts of data.
Undoubtedly, the Metaverse will generate huge amounts
of complex data, providing rich opportunities for DL. For
example, we can use digital twins in the Metaverse for
intelligent healthcare. Laaki et al. [8] designed a prototype
for remote surgery using digital twins of patients. Surgical
operations on the digital twin will be repeated on the
patient using a robotic arm assisted by DL.
focuses on the interaction between users and
• HCI
computers. Given that the ﬁnal stage of the Metaverse

6https://yhoo.it/3AD6dsu (accessed on 30-January-2022)
7https://bit.ly/3L1Uj0r (accessed on 30-January-2022)

Figure 2: Enabling Technologies of the Metaverse.

ative platforms, Meta’s Horizon Workrooms3 (referred to
as Workrooms) and Microsoft’s AltspaceVR4 (Section V).
Finally, we discuss the technical challenges, opportunities,
and directions for future research activities (Section VI)
and conclude this article.

II. Defining Metaverse

Existing Deﬁnitions and Enabling Technologies.
Metaverse has been viewed as a new type of online social
network, and arguably NextG Internet. It would be the
convergence of digital second life (to “escape” to) and vir-
tual reality (for exploration), mimicking user interaction
in the real world. A narrow deﬁnition of Metaverse is thus
a universal virtual world focusing on social interaction,
which connects multiple 3D virtual environments via the
Internet (i.e., a network of virtual worlds [4]). We envision
that the Metaverse should evolve to seamlessly integrate
the physical world and the virtual space, for example, via
digital twin and digital economies (e.g., cryptocurrencies).
Objects in the physical world can interact with the
Metaverse. They can generate their digital twins through
3D modeling and keep their digital twins presenting the
same state as what is happening in the real world. Con-
versely, after the digital twin is manipulated/processed in
the Metaverse, its physical-world state will be changed
accordingly. For example, BMW has used Omniverse5
from Nvidia to construct a fully functional digital twin of
its automobile factory, reducing manufacturing costs and
increasing productivity.

While there is no consensus on the deﬁnition, as shown
in Figure 2, it is commonly agreed that the Metaverse is
built on and integrates technologies such as 5G, XR, edge
computing, blockchain, machine learning (ML), and HCI.
• 5G provides a faster, lower latency, more scalable net-
work than 4G. According to the frequency bands, 5G
can be divided into low-band (below 1 GHz), mid-band
(between 1 and 6 GHz), and high-band (millimeter-wave,

3https://www.oculus.com/workrooms/ (accessed on 30-January-

2022)

4https://altvr.com/ (accessed on 30-January-2022)
5https://www.nvidia.com/en-us/omniverse/ (accessed on 30-

January-2022)

5GEdge Computing Blockchain MLHCIEnabling TechnologiesAR VR MRMetaversewill interconnect the physical world and digital twins, it
is, therefore, necessary to enable users to interact with
digital twins in real-time and in multiple ways. The most
important problem to be addressed is user input. The
key limitation of existing input devices (e.g., mice and
keyboards) is that they cannot free the users’ hands
and accurately reﬂect their body movements. Recently,
researchers have begun to study freehand manipulation
that allows more intuitive and concrete interaction in the
Metaverse. These techniques often rely on computer vision
and brain-computer interfaces.

Our Vision. Next, we present our vision of the Meta-
verse by illustrating three key requirements on scalability,
accessibility, and security, privacy, and legal issues.

Requirement #1: Scalability. With the Internet trans-
itioning to the Metaverse, we expect the ﬁrst practical
challenge faced by any Metaverse platform is the scalab-
ility issue. As our preliminary investigation in Section V
shows, currently Workrooms, an early prototype of the
Metaverse, can hardly scale up to tens of participants.
When more participants access Workrooms, the corres-
ponding uploading and downloading demand increases
proportionally. The platform, either serving just as a relay
or performing further content processing in the middle,
will quickly become a bottleneck.

As can be expected, the bandwidth requirement of
Metaverse could be huge. On one hand, compared to tra-
ditional 2D videos, the bandwidth for transmitting up to
16K 360-degree panorama [15] or 3D volumetric content [6]
to XR headsets could be high. On the other hand, the
Metaverse is full of social elements, which further increases
the bandwidth requirement. Currently, the U.S. Federal
Communications Commission (FCC) deﬁnes the standard
broadband service as 25 Mbps in downlink and 3 Mbps
in uplink [9]. Therefore, it is of the utmost importance
to guarantee the scalability of Metaverse by leveraging
advanced networking techniques.

Requirement #2: Accessibility. Today’s Internet access
does not need speciﬁc devices. For the Metaverse, however,
users are required to wear headsets for better interaction
in the virtual world. It greatly limits the accessibility of
the Metaverse, mainly due to the inconvenience of such
access. We envision that in the future, new “interfacing”
devices should be developed for accessing the Metaverse
without wearing any additional device, and glasses or con-
tact lenses would replace the cumbersome headsets [11].
Moreover, interaction techniques, other than just display
would need to be in place so that users can not only see
in the virtual world, but also feel, smell, taste, etc., like
what we do in the physical world [4].

Besides the interfacing devices of the Metaverse, another
potential obstacle is network accessibility. The average 25
Mbps downlink bandwidth in the U.S. [9] is far from the
demand of even a rudimentary Metaverse – the band-
width requirement would go up with more and more user-

Figure 3: Current development of the Metaverse in industry.

generated content and assets in the Metaverse. Yet another
issue related to accessibility is the interoperability across
diﬀerent implementations of the Metaverse, especially
when users move from one platform to another. The user
experience should be seamless without any interruption.

Requirement #3: Security, Privacy, and Legal Issues.
Similar to online social networks, in the Metaverse, there
will be security and privacy issues, such as attacks on
user authentication and impersonation [2]. Moreover, there
will be new types of challenges, for example, securing
the NFT, which involves the physical world when users
buy and trade assets. Moreover, online harassment can be
exacerbated in the immersive environment of Metaverse
by features including free avatar movements and enhanced
feelings of presence and embodiment [1]. Furthermore,
given that the Metaverse assets (content) are user gener-
ated, there will be copyright issues. The protection of con-
tent ownership, the detection of copyright infringement,
and the licensing of such content have not been well laid
out. Considering that there will be multiple Metaverse
platforms, transferring users’ assets from one to another
is a practical issue to be addressed. Such portability and
interoperability demand not only standardizations from
the industry but also legal enforcement.

III. Industry Trends

In this section, we brieﬂy introduce the current devel-
opment of Metaverse in the industry, which is summarized
in Figure 3.

Many high-tech companies have joined the Metaverse
arena. Meta is conceivably the most notable among all
that have invested in this space. In September 2019, Meta
(named Facebook then) announced Facebook Horizon, a
VR social platform. In July 2021, Facebook announced the
transition into a Metaverse company within ﬁve years. To
echo this vision, in October 2021, Facebook changed its

MetaverseAppleNvidiaMetaEpic GamesMicrosoftRobloxname to Meta. Meta considers VR as the foundation to
build the Metaverse. Its VR headset, Oculus Quest 2, has
sold over 10 million units, making it the state-of-the-art
and best-selling VR device.

Nvidia announced a plan to create the ﬁrst virtual
collaboration and simulation platform called Omniverse
in August 2021. This platform can be used to connect 3D
worlds into a shared virtual universe and create digital
twins, simulating real-world buildings and factories. Omni-
verse has three key components. The ﬁrst one is Omniverse
Nucleus, a database engine that allows multiple users to
connect and create a scene together. The second one is
the rendering and animation engine to simulate the virtual
world. The third one is Nvidia CloudXR for streaming XR
content to client devices. Meanwhile, Omniverse integrates
AI to train digital twins in the Metaverse.

Epic Games, a video game company famous for its
Unreal game engine, announced a $1 billion investment to
build the Metaverse. In its most popular game, Fortnite,
which is regarded as a prototype of Metaverse, users can
create their avatars, buy digital items, and enjoy movies
and concerts. Roblox is another company in this arena.
As the largest UGC game platform, players in Roblox
can create their own games and virtual worlds. They can
buy, sell, and create virtual items that can be used to
decorate their avatars. However, Roblox mainly targets
game players and provides limited XR support.

Although most companies embrace the Metaverse’s con-
cepts and vision, cautions and doubts also emerge. While
both Apple and Microsoft have virtual space applications8,
they consider that seamlessly connecting the Metaverse
and the physical world is a key to its success, if not more
important than the Metaverse itself. They believe that
the purpose of creating the virtual space is just to enable
people to improve productivity and reduce production
costs in the physical world.

IV. Social VR Platforms

Since social VR is a major component of Metaverse,
we provide an overview of several commercial social VR
platforms, highlighting their key features and diﬀerences.
Social VR, regarded as the future of social media, allows
users to interact with each other as avatars in the virtual
world, communicating and collaborating as if they are
in the physical world. With the global outbreak of the
COVID-19 pandemic, many people around the world have
to stay at home and lack social interactions, leading to
a surging demand for novel applications of social media.
Thus, predictably, the demand for social VR will continue
to grow, as it not only satisﬁes people’s social needs but
also gives them a sense of spatial presence.
Key Features. After an extensive survey, we focus on
the eight most popular social VR platforms, VRChat9,

8Apple acquired a VR company, Spaces, in 2020, and Microsoft

acquired a social VR platform called AltspaceVR back in 2017.
9https://hello.vrchat.com/ (accessed on 30-January-2022)

Platforms

VRChat
Rec Room
AltspaceVR
Mozilla Hubs
Anyland
Cluster
Bigscreen
Workrooms
Table I: Comparison of popular social VR platforms.

Smartphone
(cid:55)
(cid:51)
(cid:55)
–
(cid:55)
(cid:51)
(cid:55)
(cid:55)

Browser
(cid:55)
(cid:55)
(cid:55)
(cid:51)
(cid:55)
(cid:55)
(cid:55)
(cid:51)

Open
Source
(cid:55)
(cid:55)
(cid:55)
(cid:51)
(cid:55)
(cid:55)
(cid:55)
(cid:55)

PC
App
(cid:51)
(cid:51)
(cid:51)
(cid:55)
(cid:51)
(cid:51)
(cid:51)
(cid:55)

Rec Room10, AltspaceVR, Mozilla Hubs11, Anyland12,
Cluster13, Bigscreen14, and Workrooms. As a ﬁrst step, we
examine them from the following perspectives: i) Whether
they are accessible from Web browsers? ii) Do they sup-
port smartphones? iii) Do they have PC applications? and
iv) Are they open-source?

Table I presents a summary of these platforms. We ﬁnd
that most platforms currently have limited support for
smartphones and browser-based user access. Only Moz-
illa Hubs and Workrooms oﬀer browser-access options,
while only Rec Room and Cluster provide smartphone
applications for both Android and iOS. While Mozilla
Hubs supports browser-based access on both PC and
mobile devices, Workrooms enables browser access on PC
only. Furthermore, although most platforms have their PC
applications for Windows, only AltspaceVR and Cluster
have both Windows and macOS applications. Meanwhile,
Mozilla Hubs and Workrooms do not have PC applica-
tions, and thus users can use them through only browsers
on PC. Finally, Mozilla Hubs is the only open-source social
VR platform among them.

User Experience. We experiment with the above plat-
forms and highlight their advantages in terms of QoE.
• VRChat: Users can build their own games in the virtual
world. It allows an impressive amount of customization
(e.g., users can upload any 3D model as the avatar).
• Rec Room: It enables cross-play between diﬀerent users
with VR headsets, PCs, and smartphones. The interaction
between users with diﬀerent devices is smooth.
• AltspaceVR: The ambient lighting of the virtual scene
matches the shadows, making the lighting of the scene
realistic. There are many environments and events initi-
ated from all over the world, with a rich social element.
• Mozilla Hubs: Users can customize their applications
with its source code and deploy their own servers. They
can use Hubs through browsers without downloading any
application, which is lightweight and convenient.
• Anyland: It is a “sandbox universe”, where users can
build anything (even the avatar) they need using tools that
exist in the physical world.

10https://recroom.com/ (accessed on 30-January-2022)
11https://hubs.mozilla.com/ (accessed on 30-January-2022)
12https://altvr.com/ (accessed on 30-January-2022)
13https://cluster.co/ (accessed on 30-January-2022)
14https://www.bigscreenvr.com/ (accessed on 30-January-2022)

of headset users, indicating that the current design of
Workrooms may face scalability issues (Figure 5b).
• Workrooms does not consider situations not requiring
server involvement, but simply lets the server process and
forward all users’ data, resulting in unnecessary commu-
nication overhead (Figure 5c).

We perform the same experiments on AltspaceVR to
understand the diﬀerences between the two platforms. We
conduct a series of experiments with a 3-minute duration.
We use a Macbook Pro as the WiFi access point, which is
connected to a high-speed home network via Ethernet for
Internet access. We capture and analyze network traﬃc
using the Wireshark packet analyzer15. We conduct most
experiments with two users, U1 and U2, both using Oculus
Quest 2 to access Workrooms and AltspaceVR.

Network Protocol Analysis. We ﬁrst compare the net-
work protocols employed by Workrooms and AltspaceVR.
Besides headsets, we use Google Chrome to access Work-
rooms and the Windows application to access AltspaceVR
from a PC. We ﬁnd that users’ devices communicate with
two servers in both Workrooms and AltspaceVR. Figure 4
summarizes the process of establishing connections and
exchanging data between the clients and the servers in
Workrooms (top) and AltspaceVR (bottom).

In Workrooms, the connection with Server I starts dur-
ing the loading period (i.e., when the loading progress bar
is displayed). All data exchanges are over User Datagram
Protocol (UDP). We have proven that this ﬂow transmits
virtual content [3] and refer it to virtual content (VC)
ﬂow. The connection with Server II starts when users
enter the meeting room. The headset and browser clients
have a slightly diﬀerent way of establishing connections
with Server II. First, they both establish a Transmission
Control Protocol (TCP) connection with Server II, while
using Session Traversal Utilities for NAT (STUN) protocol
to traverse network address translator (NAT) gateways.
The headset and Server II then transfer 1-3 Transport
Layer Security (TLS, a secure communication protocol
over TCP) packets to each other. However, the browser
client does not transmit any additional TCP packets, but
establishes a Datagram Transport Layer Security (DTLS,
a secure communication protocol over UDP) connection
with Server II. Finally, both browser and headset clients
use Real-time Transport Protocol (RTP) and RTP Control
Protocol (RTCP) to exchange multimedia content with
Server II. We refer to this ﬂow as multimedia (MM) ﬂow.
In AltspaceVR, however, the client-server connections
work in a diﬀerent way. First, the client downloads 10-
20MB data from Server I using the Hypertext Transfer
Protocol Secure (HTTPS) protocol, when the client screen
displays “downloading world content”. Only users who join
the event for the ﬁrst time need to download the data.
Then, the client downloads 300-500KB data from Server

15https://www.wireshark.org/ (accessed on 30-January-2022)

Figure 4: The process of establishing connections and exchan-
ging data between the clients and the servers for Workrooms
(top) and AltspaceVR (bottom).

• Cluster: It bears a large capacity for public events, with
up to 500 people participating in a four-hour event at the
same time, and allows people to organize events for free.
• Bigscreen: Users can play PC games in the virtual world
and watch together videos (e.g., Netﬂix and YouTube)
played on PCs in a private or public room.
• Workrooms: It supports physical keyboards, which are
much more convenient than the virtual ones manipulated
by a controller. Moreover, users can write using the con-
troller as a pen by ﬂipping it around.

V. Case Studies

In this section, we conduct a reality check of the
Metaverse by comparing the network operation and per-
formance of Workrooms and AltspaceVR. In our previous
work [3], we have dissected how Workrooms works. Our
key ﬁndings are as follows:
• Workrooms primarily employs two servers to commu-
nicate with its clients, one is for delivering virtual content
and the other is for streaming/exchanging audio and video
data, as shown in Figure 4 (top).
• With two headset users in Workrooms, each user’s
downlink throughput is about 2–3 Mbps and the up-
link throughput is ∼0.6 Mbps (Figure 5a). However, the
downlink throughput linearly increases with the number

Server IServer IIBrowser UserHeadset User Stage I for browser andheadset users: Server Iloads background andkeeps exchangingvirtual content via UDP.Stage II for headset users:Users set up a connectionwith server II via TLS (over TCP) and STUN.Stage II for browser users:Users set up a connectionwith server II via TCP, DTLS(over UDP), and STUN.3UDPTLS STUN TCP DTLS STUN RTP RTCPRTP RTCP12UDPStage III for browser andheadset users: Userskeep exchanging multimediacontent with server II viaRTP and RTCP.Server IServer IIPC UserStage I: Both users setup HTTPS (over TCP)connection with Server I,then load mainenvironment and worldcontent of the event fromServer I via HTTPS.Stage II: Both userskeep exchanginguser-related content(e.g., audio) withServer II via UDP.HTTPSHTTPSUDPUDP12Headset User(a) Throughput (Workrooms)

(b) Scalability (Workrooms)

(c) Audio Data (Workrooms)

(d) Throughput (AltspaceVR)

(e) Scalability (AltspaceVR)

(f) Audio Data (AltspaceVR)

Figure 5: Comparison of throughput, scalability, audio data between Workrooms and AltspaceVR. a) and d) bitrate of
UDP ﬂow in Workrooms and Altspace VR; b) and e) bitrate of the VC ﬂow (no change for MM ﬂow) in Workrooms
and UDP ﬂow in AltspaceVR, three additional users join at 50, 100, and 150 s respectively; c) and f) comparison of
audio data for U1’s uplink and U2’s downlink in Workrooms and AltspaceVR (both users mute from 100 to 150 s).

I via another HTTPS connection, when the client screen
displays “loading main environment”.

The connection with Server II starts when users ﬁnish
loading. All data exchanges are over UDP. Since this
UDP ﬂow is the only ﬂow after users enter the event, we
speculate it is for user-related content. Through further
analysis, we ﬁnd that this UDP ﬂow follows a custom
protocol. The fourth byte of the UDP payload is used to
distinguish the data type, such as audio data.

Network Performance. Next, we compare the two plat-
forms based on key ﬁndings of Workrooms. Figure 5d
shows the throughput (i.e., bitrate) of the UDP ﬂow in
AltspaceVR. We ﬁnd that since users have downloaded the
event content before entering the event, the throughput
(less than 0.06 Mbps) after that is much smaller than
Workrooms. Figure 5e shows the throughput of the UDP
ﬂows in AltspaceVR, where we let three other headset
users join the experiment at 50, 100, and 150 s, respect-
ively. We ﬁnd that AltspaceVR also faces scalability issues,
with the downlink bitrate increasing almost linearly every
time a new user joins (∼0.03Mbps). However, its increase
is much smaller than Workrooms (∼0.5Mbps).

Figures 5c and 5f show the comparison of the audio
data for U1’s uplink and U2’s downlink. In Workrooms,
we observe that the bitrate on the downlink of U1 ex-
actly matches that of the uplink of U2, and vice versa
(Figure 5c). This indicates that the server simply forwards
one user’s audio data to others without further processing.
However, in AltspaceVR, the uplink audio data of one user
does not exactly match the downlink audio data of another
user, indicating that the server processes the audio data
before forwarding it (Figure 5f). Also, most of the time,

the downlink throughput of a user is lower than the uplink
throughput of the other user, which indicates that the
server may optimize the audio data uploaded by users.

To summarize, by comparing Workrooms and Alt-

spaceVR, we have the following ﬁndings.
• AltspaceVR requires users to download event data in
advance, and transfers only user-related data after that,
requiring less bandwidth consumption than Workrooms.
• Both platforms face scalability issues, although Alt-
spaceVR does not cause signiﬁcant bandwidth consump-
tion (∼0.18 Mbps for downlink with ﬁve users).
• Unlike Workrooms, AltspaceVR processes the data up-
loaded by users before forwarding it, reducing the size of
data received by other users.

VI. Discussion

In this section, we discuss the technical challenges of
building the Metaverse and point out opportunities for
further innovation.

First, the operation of Metaverse will generate a large
amount of data, such as metadata created by sensors, a
shared virtual space for social activities of users, and the
transmission of high-resolution video streams, requiring
huge network bandwidth. However, the existing 5G tech-
nology may not be suﬃcient to support the Metaverse.
Although 5G can reach a maximum throughput of, in
theory, 10-20 Gbps, considering the scalability demand,
the bandwidth requirement of Metaverse may exceed what
5G can oﬀer. To this end, a potential solution is peer-to-
peer (P2P) communication techniques. As a result, user
devices have to combine the content received from multiple
parties and then render the virtual world accordingly.

50100150200Time (s)0123Bitrate (Mbps)UplinkDownlink50100150200Time (s)012Bitrate (Mbps)UplinkDownlink50100150200Time (s)0.000.010.020.03Bitrate (Mbps)UplinkDownlink50100150200Time (s)0.000.020.040.06Bitrate (Mbps)UplinkDownlink50100150200Time (s)0.000.050.100.15Bitrate (Mbps)UplinkDownlink50100150200Time (s)0.000.010.020.03Bitrate (Mbps)UplinkDownlinkSecond, network latency is critical to the user exper-
ience. Given that users may access the Metaverse from
diﬀerent parts of the world, ensuring low latency when
users are across geographically distributed regions is a
practical challenge. Meanwhile, sensors in the Metaverse,
such as those on XR headsets and haptic devices, require
latency as low as tens of milliseconds to maintain an
immersive user experience [14]. Similar to the motion-
to-photon latency in VR, in the Metaverse the latency
between the motion of a user and its reﬂection perceived
by others is a key metric to optimize. Remote rendering [7]
of virtual content at the network edge is a promising
direction for reducing the above latency.

Third, the security and privacy issues in the Metaverse
deserve our attention. Although commercial social VR
platforms employ secure communication protocols (e.g.,
TLS and DTLS) to protect transmitted data, as veriﬁed
in our measurement study, the Metaverse may still lead
to many security concerns, such as users’ identiﬁcation
information. Since it requires users to access with headsets,
they often need to identify themselves with biometric in-
formation, which could be a target of security attacks [10].
Digital twins in the Metaverse also need our protection.
There will be a large number of complex ML models for
supporting digital twins, which in turn inﬂuence objects in
the physical world. If these models are attacked, there will
be unpredictable eﬀects in the physical world. Moreover,
user-worn headsets will continuously collect personal in-
formation (e.g., biometric information and user behavior)
to improve the QoE, which results in privacy concerns.
Storing biometric data and digital twins of the Metaverse
in the blockchain is a possible direction [12].

Finally, as the Metaverse becomes commonplace in our
daily lives, user addiction will be a crucial issue. People
may rely on the Metaverse to escape from the real world,
just as described in the novel Snow Crash. Recent surveys
show that 51% of U.S. adults use social media at a higher
rate during the COVID-19 pandemic16. Beyond better
regulation and guidance, how to eﬀectively address this
issue is still an open problem.

VII. Conclusion

While Metaverse has been deemed as the NextG In-
ternet, much of the discussion,
in both industry and
academia, has focused on its potential. In this article, after
reviewing the existing deﬁnitions of Metaverse and its en-
abling technologies, we present our vision by discussing the
technical requirements of Metaverse. We then introduce
the current hype in industry and existing social VR plat-
forms that can be viewed as early prototypes of Metaverse.
By measuring and comparing two representative social
VR platforms, Workrooms and AltspaceVR, we point
out the technical challenges and opportunities for future
development. Given its multidisciplinary nature [11], we

16https://bit.ly/3q8neXW (accessed on 30-January-2022)

hope to see more initiatives emerging from not only the
networking research community, but also other related
disciplines such as social sciences, economics, computer
graphics, AR/VR/MR, HCI, security, and privacy.

References

[1] L. Blackwell, N. Ellison, N. Elliott-Deﬂo, and R. Schwartz.
Harassment in Social Virtual Reality: Challenges for Platform
Governance. Proceedings of the ACM on Human-Computer
Interaction, 3:1–25, 2019.

[2] P. Casey, I. Baggili, and A. Yarramreddy.

Immersive Virtual
Reality Attacks and the Human Joystick. IEEE Transactions
on Dependable and Secure Computing, 18(2):550–562, 2019.
[3] R. Cheng, N. Wu, S. Chen, and B. Han. Reality Check of
Metaverse: A First Look at Commercial Social Virtual Reality
Platforms. In Proceedings of IEEE Workshop for Building the
Foundations of the Metaverse (Metabuild), co-located with IEEE
Conference on Virtual Reality and 3D User Interfaces (VR),
2022.

[4] J. D. N. Dionisio, W. G. B. III, and R. Gilbert. 3D Virtual
worlds and the metaverse: Current status and future possibilit-
ies. ACM Computing Surveys, 45(3):34:1–34:38, 2013.

[5] B. Han. Mobile Immersive Computing: Research Challenges and
the Road Ahead. IEEE Communications Magazine, 57(10):112–
118, 2019.

[6] B. Han, Y. Liu, and F. Qian. ViVo: Visibility-Aware Mo-
bile Volumetric Video Streaming.
In Proceedings of ACM
International Conference on Mobile Computing and Networking
(MobiCom), 2020.

[7] D. Koller, M. Turitzin, M. Levoy, M. Tarini, G. Croccia,
P. Cignoni, and R. Scopigno. Protected Interactive 3D Graph-
ics Via Remote Rendering. ACM Transactions on Graphics,
23(3):695–703, 2004.

[8] H. Laaki, Y. Miche, and K. Tammi. Prototyping a Digital
Twin for Real Time Remote Control Over Mobile Networks:
Application of Remote Surgery. IEEE Access, 7:20325–20336,
2019.

[9] K. MacMillan, T. Mangla, J. Saxon, and N. Feamster. Measur-
ing the Performance and Network Utilization of Popular Video
Conferencing Applications. In Proceedings of ACM SIGCOMM
Conference on Internet Measurement (IMC), 2021.

[10] F. Mathis, J. H. Williamson, K. Vaniea, and M. Khamis. Fast
and Secure Authentication in Virtual Reality Using Coordin-
ated 3D Manipulation and Pointing. ACM Transactions on
Computer-Human Interaction, 28(1):1–44, 2021.

[11] S.-M. Park and Y.-G. Kim. A Metaverse: Taxonomy, Com-
IEEE Access,

ponents, Applications, and Open Challenges.
10:4209–4251, 2022.

[12] B. Ryskeldiev, Y. Ochiai, M. Cohen, and J. Herder. Distributed
Metaverse: Creating Decentralized Blockchain-based Model for
Peer-to-peer Sharing of Virtual Spaces for Mixed Reality Ap-
plications. In Proceedings of Augmented Human International
Conference (AH), 2018.

[13] M. Speicher, B. D. Hall, and M. Nebeling. What is Mixed
Reality? In Proceedings of Conference on Human Factors in
Computing Systems (CHI), 2019.

[14] W. Zhang, B. Han, and P. Hui. SEAR: Scaling Experiences
In Proceedings of IEEE
in Multi-user Augmented Reality.
Conference on Virtual Reality and 3D User Interfaces (VR),
2022.

[15] W. Zhang, F. Qian, B. Han, and P. Hui. DeepVista: 16K
Panoramic Cinema on Your Mobile Device. In Proceedings of
International Conference on World Wide Web (WWW), 2021.

