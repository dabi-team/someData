Effects of Virtual Acoustics on Dynamic Auditory Distance Perception

Atul Rungta Nicholas Rewkowski Roberta Klatzky Ming Lin Dinesh Manocha

7
1
0
2

r
p
A
0
2

]

D
S
.
s
c
[

1
v
8
0
0
6
0
.
4
0
7
1
:
v
i
X
r
a

Figure 1: Effects of reverberation on acoustic distance perception in dynamic environments. (a) our training setup in a real-world environment
with a user being trained; (b) a blindfolded subject taking the study (inset) and the reverberation pattern shown in different colors; (c) the
subject moving along a path and experiencing dynamic reverberation. Our study shows that accurate ray-tracing-based reverberation produces
a consistently higher perception of distance compared to a commonly-used approximate technique based on a parametric reverberation ﬁlter.

ABSTRACT

Sound propagation encompasses various acoustic phenomena in-
cluding reverberation. Current virtual acoustic methods, ranging
from parametric ﬁlters to physically-accurate solvers, can simu-
late reverberation with varying degrees of ﬁdelity. We investigate
the effects of reverberant sounds generated using different prop-
agation algorithms on acoustic distance perception, i.e. how far
away humans perceive a sound source. In particular, we evaluate
two classes of methods for real-time sound propagation in dynamic
scenes based on parametric ﬁlters and ray tracing. Our study shows
that the more accurate method shows less distance compression as
compared to the approximate, ﬁlter-based method. This suggests
that accurate reverberation in VR results in a better reproduction
of acoustic distances. We also quantify the levels of distance com-
pression introduced by different propagation methods in a virtual
environment.

1 INTRODUCTION

Realistic sound effects can increase the sense of presence or immer-
sion in virtual environments. In fact, some researchers and devel-
opers consider spatial audio and sound rendering as VR’s second
sense1. Recent hardware developments in virtual reality have re-
sulted in renewed interest in the development of fast techniques to
generate plausible or realistic sounds on commodity hardware.

Sound in virtual environments has received less attention than
visual rendering and effects. Over the last decade, many new al-
gorithms have been proposed for sound propagation and render-
ing. However, there is relatively less investigation on evaluating
the perceptual effectiveness of these methods in virtual environ-
ments [17, 24, 33].

One of the most important acoustic effects is reverberation,
which corresponds to the sound reaching the listener after a large
number of successive temporally dense reﬂections with decaying
amplitudes. Reverberation is known to have multiple perceptual

1https://www.youtube.com/watch?v=Na4DYI-WjlI

effects on humans, including auditory distance perception, environ-
ment size estimation, degraded localization, and degraded speech
clarity [30].

Some of the widely used techniques for virtual acoustics are
based on artiﬁcial reverberation ﬁlters. The ﬁrst set of such algo-
rithms were proposed in the early 1960s, and they have been reg-
ularly used for music production, games, and VR. These methods
low runtime overhead and most game and VR engines use such
ﬁlters to generate propagation or reverberation effects. Recent ad-
vancements in computing power and algorithmic methods have re-
sulted in physically-accurate techniques for simulating reverbera-
tion at interactive rates based on ray tracing [26], wave-based meth-
ods [20], and ray-wave coupling [32]. However, some of these ac-
curate techniques [20, 32] have a considerably higher precomputa-
tion or runtime overhead as compared to artiﬁcial ﬁlters. An open
issue is whether the increase in the physical accuracy of sound prop-
agation leads to an increase in perceptual differentiation.

In this paper, we evaluate and quantify the relative beneﬁts of dif-
ferent propagation methods for auditory distance perception in VR.
In general, distances tend to be under-estimated or under-perceived
in virtual environments and this can have considerable impact on
the resulting simulation or training applications [8]. Distance per-
ception has been actively studied with respect to visual and aural
cues. In particular, it is known that distance perception in vision, as
assessed by direct walking, is accurate to more than 20 meters [18].
Auditory distance perception, in contrast to visual cues, is compres-
sive [19]. In reverberant environments, there is less compression in
terms of auditory distance perception [14]. One of the most impor-
tant distance cues is the loudness of the sound and this cue can be
estimated more accurately when the energy ratio of the direct and
reverberant sound is available. Some of the earlier work on audi-
tory distance perception was based on setting up physical environ-
ments, using appropriate sound sources, and performing the stud-
ies. However, prior studies of auditory distance perception have
been affected by the issues that arise in terms of controlling and
quantifying the actual sound stimulus to the ears of the users in a
physical scene. In contrast, virtual acoustic techniques can provide
more ﬂexibility and less expensive solutions in terms of evaluating
auditory distance perception [6]. In that regard, the recent devel-
opments in interactive and physically-accurate sound propagation

 
 
 
 
 
 
methods can provide unique capabilities for performing novel ex-
periments using virtual acoustics.
Main Results: We evaluate the impact of different reverberation
algorithms on auditory distance perception in virtual environments.
Our main focus is to evaluate the distance compression character-
istics of approximate vs. accurate interactive reverberation algo-
rithms. The objective is to determine if increase in physical ac-
curacy leads to an increase in perceptual differentiation. In terms
of approximate reverberation, we use a parametric Schroeder ﬁl-
ter [30] and perform dynamic calibration to improve its perfor-
mance in terms of reverberation effects. The accurate propagation
effects are computed using a fast acoustic ray-tracer that can per-
form 50 − 100 orders of specular and diffuse reﬂections at inter-
active rates to compute dynamic late reverberation on a multi-core
PC [26]. As the source or the receiver moves, the reverberation is
recomputed and used for auralization.

A key issue in the use of parametric ﬁlter is tuning of various pa-
rameters and that can change the reverberation. In order to tune
these ﬁlters for distance perception, we present a dynamic cali-
bration algorithm that uses the RT60 (reverberation time) and DRR
(direct-to-reverberant ratio) parameters. These two parameters are
computed from the impulse response based on the accurate ray trac-
ing algorithm. The Schroeder ﬁlter was appropriately scaled and
spliced on the early part of the impulse response, starting at the ap-
proximate onset time of reverberation to match the RT60 and DRR
of the ray-traced impulse response. In this way, our calibration al-
gorithm tends to compute the best tuned ﬁlter for auditory distance
perception.

We conducted two separate studies to test auditory distance per-
ception in virtual environments. The ﬁrst study (static scene) is
used to evaluate the effects of two reverberation methods in two
rectangular-shaped rooms of different sizes for sources that were
close to the listener, i.e., between 1m − 5m. The source and listener
were at static locations. The second study (dynamic scenes) stud-
ied the effects of two reverberation methods in a large rectangular-
shaped room for sources that were far away from the listener, i.e.
between 10m − 40m. Furthermore, the listener in this study was
moving in the environment, and thereby the reverberation effects
perceived by the listener change. We analyze the results from these
studies and observed the following results in VR:

• Auditory distance perception shows substantial compression
in virtual environments and can be well-represented using a
power-function. Our power functions are similar to those re-
ported by Zahorik [33], though the exponents are different.

• In case of a static scene, a well-tuned or calibrated parametric
reverberation ﬁlter can exhibit similar compression and per-
ceived distance as the ray-traced reverberation method. The
ﬁlter parameters, RT60 and DRR, were matched to ray-traced
generated impulse response parameters. This study indicates
that in case of a static environment, only the DRR is sufﬁcient
for a consistent and similar result.

• In case of dynamic scenes, a well-tuned or calibrated para-
metric reverberation ﬁlter shows similar compression charac-
teristics as the accurate ray tracing method. However, the
perceived distance is consistently higher for the ray tracing
method. This ﬁnding indicates that matching the DRRs of two
method is not sufﬁcient for distance perception in dynamic
scenes. Instead, the full impulse response for the given source
and listener positions also plays an important role in terms
acoustic distance estimation. This result suggests that accu-
rate reverberation methods can lead to better reproduction of
acoustic distances.

The rest of the paper is organized as follows. In Section 2, we give
a brief overview of prior work in acoustic simulation and auditory

distance perception. In Section 3, we discuss the calibration method
used to match the ﬁlter to the impulse response. We describe our
study for the static scene in Section 4 and present the experiment
for the dynamic scene in Section 5. Section 6 analyzes the results.

2 RELATED WORK AND BACKGROUND
In this section, we give a brief overview of sound propagation,
including the computation of impulse responses and reverbera-
tion. We also review many techniques for generating reverbera-
tion based on precomputed ﬁlters, geometric propagation and wave-
based propagation.

2.1 Acoustic Impulse Response and Reverberation
The acoustic impulse response ﬁlter refers to how an environment
behaves when provided with an impulse for a given source and
listener position in the environment. In particular, it captures the
acoustic signature of an environment and gives us an idea of how a
source would sound in that particular source-listener position con-
ﬁguration. In the real-world, acoustic impulse response measure-
ments are widely used to characterize the acoustic characteriza-
tion of an environment [16]. The impulse response can be used
to study the acoustic characteristics of an environment and derive
important acoustic metrics such as RT60 (reverberation time), DRR
(direct-to-reverberant energy ratio), C80 (clarity), D50 (deﬁnition),
G (strength), Onset (onset delay), dir (onset direction), etc.

Reverberation: Reverberation is the acoustic phenomenon of re-
peated sound reﬂections in an environment. Reverberation lends
large environments a characteristic impression of spaciousness, and
plays a crucial role in the acoustic design of buildings, concert halls,
etc. The two key characteristics for measuring this property are re-
verberation time (RT60) and the direct-to-reverberant ratio (DRR).
RT60 is deﬁned as the time it takes for the sound in the environ-
ment to decay by 60 dB. RT60 is one of the most important param-
eters in room and architectural acoustics and provides an approxi-
mation of how long the reverberation effects will last in a given en-
vironment. For example, the recommended reverberation time for a
classroom is 0.4 − 0.6 seconds and is about 1.8 − 2.2 seconds for a
concert hall. Empirically, RT60 is computed using the well-known
Sabine’s equation:

RT60 ≈ 0.1611sm−1 V
Sa

,

(1)

where V is the volume of the space, S is the total surface area, and a
is the average absorption coefﬁcient of the surfaces. This formula-
tion doesn’t require the exact impulse response of the environment
and is mostly used to estimate to the actual RT60 in simple, rect-
angular rooms. The more accurate way of computing the RT60 is
based on reverse cumulative trapezoidal integration to compute the
decay of the impulse response and then use a linear least-squares ﬁt
to compute the slope of the decay from 0 dB to −60 dB [16].

The DRR is another well-known metric related to reverberation,
and is formulated based on the energy ratio between the energy of
the sound coming directly from the source and its reﬂections. Given
the acoustic impulse response, the DRR can be estimated from the
impulse responses by evaluating the onset and decay characteristics.
Mathematically, DRR can be expressed as:

DRR = 10log10(

X(T0 −C : T0 +C)2
X(T0 +C + 1 : Tn)2 ),

(2)

where X is the approximated integral of the impulse response, T0
is the time of the direct impulse, Tn is the time of the last impulse,
and C = 2.5ms [34]. Some recent work on human hearing has
predicted that DRR can also provide absolute distance information,
especially in reverberant environments [34].

2.2 Sound Propagation

2.3 Acoustic Distance Perception

At a broad level, sound propagation deals with modeling how sound
waves reﬂect, scatter, and diffract around obstacles as they travel
through an environment. These techniques are used to measure the
impulse response, which is composed of the direct sound, early re-
ﬂections, and reverberation. The early reﬂections correspond to the
sound reaching the listener after a small number of reﬂections and
are used to localize the sound source(s). Sound propagation has
been an active area of research in computational acoustics and vir-
tual environments for many decades. At a broad level, prior prop-
agation methods can be classiﬁed into: use of parametric ﬁlters,
geometric propagation, and wave-based propagation.

2.2.1 Parametric Filters

Some of the simplest algorithms to model reverberation are based
on parametric or artiﬁcial reverberation ﬁlters [13] that capture the
statistics of reverberant decay using a small set of parameters. The
three main categories are delay networks, convolution-based algo-
rithms, and physical room models [30]. These are widely used in
games and virtual environments because of their low runtime over-
head. Typically the designer or artists divide a large scene into dif-
ferent reverberation zones or regions and compute separate ﬁlters
for each region. Moreover, different ﬁlters are interpolated at run-
time to generate smooth acoustic responses. Many techniques have
been proposed to automatically compute the reverberation parame-
ters [4, 3].

2.2.2 Geometric Acoustic Methods

These algorithms are based on ray tracing and its variants (e.g.,
beam tracing or frustum) and assume that the sound travels along
linear rays. Different techniques have been proposed to compute
specular and diffuse reﬂections [15, 1, 31]. They work well for
high frequency sources, though some approximate techniques have
also been proposed to approximate low-frequency effects such as
edge diffraction. Over the last decade, many faster algorithms for
interactive ray tracing have been proposed to accelerate sound prop-
agation and these methods can exploit the parallel capabilities of
current multi-core CPUs and GPUs. Earlier, interactive ray tracing
algorithms were limited to compute only the early reﬂections [9, 28]
in dynamic scenes, while late reverberation was estimated using
statistical approximation or precomputation methods [2]. Recently,
interactive techniques have been proposed to compute higher order
specular and diffuse reﬂections using ray tracing [27, 26]. These
algorithms are able to compute 50 − 100 orders of reﬂections in dy-
namic scenes at interactive rates on a multi-core desktop PC by ex-
ploiting the coherence of the sound ﬁeld and performing backward
ray tracing. This enables us to accurately compute early reﬂections
as well as dynamic late reverberation effects. In this paper, one of
our goals is to evaluate the psycho-acoustic characteristics of these
dynamic late reverberation algorithms for auditory distance percep-
tion.

2.2.3 Wave-based Simulation

The wave-based algorithms numerically solve the acoustic wave
equation and compute the sound pressure ﬁeld and impulse re-
sponses. Recently, many precomputation techniques have been
proposed for interactive applications [29, 22, 20, 32]. As com-
pared to geometric methods, these algorithms are able to accurately
model low frequency effects, but the time complexity increases as
the fourth power of the frequency. As a result, they are only prac-
tical for low to medium range frequencies (e.g., less than 1 or 2
KHz). Furthermore, they are limited to static scenes due to the high
precomputation overhead.

There is considerable work in perception and VR literature on dis-
tance perception based on visual and/or aural cues [8]. This in-
cludes work in VR on spatial perception with visual displays, au-
diovisual environments, and auditory displays [21, 25, 23, 12]. In-
terestingly, distance compression was observed in all such virtual
environments. Other work includes the study of auditory percep-
tion in the presence of visual information [7].

In terms of acoustic cues, most of the earlier research was on
directional aspects of auditory localization [33]. Over the last few
decades, there is considerable work on auditory distance percep-
tion as well as use of virtual acoustic techniques [6]. This includes
evaluation of how well can humans estimate the stationary sound
sources. Most of these studies suggest that listeners systematically
underestimate distances to faraway sound sources.

3 CALIBRATING FILTER PARAMETERS

In this section, we present the details of the Schroeder ﬁlter used
to generate reverberation effects. We also describe our dynamic
calibration algorithm adjusts some parameters of this ﬁlter.

3.1 Schroeder Filter

We use the Schroeder ﬁlter as an approximation method to com-
pute reverberation. This ﬁlter is one of the oldest, most commonly
used digital reverberation algorithms. It is easy to set up and cus-
tomize to produce plausible reverberation characteristics in an en-
vironment. An artiﬁcial reverberator must have a ﬂat frequency
response and should be able to produce the desired density of re-
ﬂections. The Schroeder ﬁlter uses a parallel bank of comb ﬁlters
connected to a series of all-pass ﬁlters, as shown in Figure 2. The
comb ﬁlters generate a repeated version of the input signals, while
the all-pass ﬁlters keeps the frequency gain of the input as constant.
The parallel-bank of comb ﬁlters combined with a series of all-pass
ﬁlters serves as a means to control the ﬁnal output sound with a
greater resolution. The overall speciﬁcation of the Schroeder ﬁlter
is controlled by different parameters, such as:
Room size: This parameter speciﬁes size of the room for which
reverberation is being generated. Larger rooms tend to have longer
reverb times.
Pre-delay: This parameter speciﬁes the time it takes sound to reﬂect
once.
Damping: It speciﬁes the amount of attenuation applied to the high-
frequency content of the sound.
Wet Gain: This parameter speciﬁes the amount of energy contained
by the reverberation relative to the direct sound.
Dry Gain: It speciﬁes the amount of energy contained by the direc-
tion sound relative to the reverberation.

Figure 2: Schroeder reverberation ﬁlter: We highlight various com-
ponents used in the design of such a ﬁlter. The comb ﬁlters produce
reﬂections of the input sound, while the all-pass ﬁlters control the
reverberator’s wet and dry mix.

3.2 Calibration of Impulse Responses

The performance and reverberation effects computed in an environ-
ment are governed by the different parameters used in the Schroeder

ﬁlter formation. Since we are comparing two methods of reverber-
ation, we need to make sure that early part of the impulse response
for the two methods is exactly the same in our experiments. As a re-
sult, two versions of the impulse responses were computed for each
source, listener position - the ﬁrst one is the full impulse response
computed using the ray tracer [26] and the second one without the
reverberant tail that contains only the early part of the impulse re-
sponse as shown in Figure 3(a) & (b). We compute the RT60 and
DRR using the full impulse response, and adjust the parameters of
the Schroeder ﬁlter till these parameters match.

Algorithm 1 Impulse Response Calibration
1: procedure IRC(FullIR, EarlyIR)
2:

[RT Full
60

computed using ray tracing

, DRRFull] ← GetParameters(FullIR) / FullIR is

3:
4:
5:
6:
7:
8:
9:
10:

11:

12:
13:
14:

15:

MaxNumberO f Iterations ← M
OnsetTimes ← t f irstsample + [t1..tn]
Scaling ← [s1..sn]
RF ← SchroederFilter()
while i ≤ MaxNumberO f Iterations do

for time in OnsetTimes do
for scale in Scaling do

SyntheticIR ← EarlyIR(time) + RF ∗ scale
[RT Synthetic
60

, DRRSynthetic]

GetParameters(SyntheticIR)
end for

Figure 3:
(a) The full impulse response computed using the ray-
tracer; (b) The early part of the impulse response computed us-
ing the ray tracer (using a different time scale); (c) The output of a
generic Schroeder-reverberator; (d) The calibrated Schroeder ﬁlter
with matching RT60 and DRR values as those of (a)

←

end for
if RT Synthetic
60
DRRFull ≤ εDRR then

− RT Full

60 ≤ εRT60 and DRRSynthetic −

MatchedIR ← SyntheticIR / i.e. RT60 and DRR

match with those of ray tracer

end if
i ← i + 1

16:
17:
18:
19:
20: end procedure

end while
return MatchedIR

the details of

Algorithm 1 gives

calibration scheme.
SchroederFilter is a generic Schroeder reverberation genera-
tor that produces a series of repeated, decaying impulses. The
GetParameters function computes the RT60 and DRR, as described
in the previous section. The OnsetTimes deﬁnes a linear space
of reverberation onset times. Typically, late reverberation starts
around t f irstsample = 80ms [10] from the ﬁrst impulse, so this space
deﬁnes a time domain from t f irstsample + t1 to t f irstsample + tn. This
linear space is used to determine the time at which the synthetic
(Schroeder ﬁlter) reverberation is added to the early part of the
impulse response. The Scaling, on the other hand, determines
the space of multipliers that scales the synthetic reverberation
computation. For each pair {time, scale}, the synthesized impulse
response is constructed and its RT60 and DRR are evaluated.
If
these values match the RT60 and DRR of the full impulse response,
based on the just-noticeable difference (JND) of the respective
parameters(εRT60 , εDRR), it corresponds to a considered a calibrated,
matched impulse response.

4 EXPERIMENT 1: STATIC LISTENER IN A REVERBERANT

ENVIRONMENT

In this section, we give an overview of the static scene used in our
evaluation. This study is based on a static sound source and a static
listener.

4.1 Participants
Twelve subjects took part in the study with informed consent. The
ages ranged from 20 to 31 (mean = 25.2 and SD = 2.7). It include

Figure 4: The two rooms used for the experiments. The red dots
show the 7 randomly generated azimuths where the sources were
kept. The numbers 1..7 indicate the distances at uniformly sampled
points between [1m-5m] from the listener for both rooms. The sub-
jects were placed 1m away from the wall.

one female and eleven males. All subjects reported normal hearing.

4.2 Apparatus
The set up consisted of a Dell T7600 workstation and the sound
was delivered via a pair of Beyerdynamic DT990 PRO headphones.
The subjects were blindfolded for the study. The software to com-
pute the RT60 and DRR is based on open-source MATLAB code
[11]. The calibration and auralization were performed using in-
house software, also written in MATLAB.

4.3 Stimuli
The stimuli consisted of a pre-recorded sound of a human male
voice. The voice was played in two highly-reverberant virtual
rooms of dimensions 9.5m × 9.5m × 3m and 13m × 13m × 3m. The
subjects were placed 1m away from one of the walls of both the
rooms, as shown in Fig 4. The listener’s head-orientation was
ﬁxed to look in the forward direction. Seven omnidirectional sound
sources were placed in the azimuthal plane of the listener at dis-
tances of 1.0m, 1.7m, 2.3m, 3m, 3.7m, 4.3m, and 5.0m at a constant
height of 1.7m. This was performed assuming the standard lis-
tener’s height of 1.7m in the virtual environment. The azimuthal
angles for these 7 source positions were pre-selected randomly: 3
positions between [-20◦ -45◦] and 4 positions between [20◦ 45◦]
relative to the zero straight ahead, and kept the same throughout the
study for all the subjects. Sound was rendered by constructing two

impulse responses per source using the two reverberation methods
- Schroeder reverberation ﬁlter and interactive ray tracing using the
calibration scheme described above. The impulse responses were
then convolved with the sound signal for auralization. The source
sound power was 78dB.

4.4 Design & Procedure

The environments were created to emulate a highly-reverberant
room, similar to what a painted indoor room with no windows
would sound. The calibration algorithm described above was used
to match the RT60 and DRR of the two reverberation methods, i.e.,
the Schroeder ﬁlter and interactive ray tracing. This was a within-
subject study and all of the subjects experienced the acoustic ef-
fects from both methods of reverberation for all seven sources in
the two rooms. The subjects were blindfolded, and the sound was
delivered through headphones. This way we can accurately evalu-
ate the acoustic effects. In the absence of variable head-orientation,
a generic HRTF-ﬁlter-based spatialization was used, as the evalua-
tions only involved sources in the azimuthal plane. All the distance
estimates were in meters.

Before starting the experiment, the subjects were given an idea
of the size of meter by showing them a meter-long strip of tape.
After that, they were blindfolded and four sound clips were played:
1m away at 30◦ to the left, 1m away at 30◦ to the right, 5m away
at 30◦ to the left, and 5m away at 30◦ to the right. The subjects
were familiarized that these are the kind of sounds they should ex-
pect, without giving them the actual distances associated with these
clips. The clips were rendered using the interactive ray tracing al-
gorithm. The subjects were asked to rate the distances in meters on
a scale of 1m − 10m. The same metric was used in the subsequent
experimental trials.

This was a within-subject study, and each subject rated the com-
plete set of 7 source positions within two rooms. The order of the
sound ﬁles was randomized before starting a block of trials, and
three such blocks were conducted, giving a total of 42 evaluations
per subject (7 source positions × 2 rooms × 3 blocks). The sub-
ject’s head orientation was kept ﬁxed, and the sound clip for each
source position was played in a loop, until the listener responses.
The subjects were allowed to take breaks. The experiment took an
average of ﬁfteen minutes per subject. No fatigue was reported.

4.5 Results

A 4-way ANOVA on block, distance, room, and reverberation
method shows signiﬁcant effects for distance (F(6, 66) = 56.46, p
< 0.01) and room(F(1, 11) = 12.52, p < 0.01), but none for the
reverberation method or block. The two-way interaction between
distance and room also shows signiﬁcance (F(6, 66) = 11.23, p <
0.01). This indicates that the room size has an effect on the per-
ception of distance despite the distances being the same in the two
rooms (Figure 5). On the other hand, the reverberation method
doesn’t seem to affect the distance estimate. This can be explained
if we take into account the fact that distance perception is a func-
tion of the DRR and since the DRRs were matched closely, in a
static scene, the distance perception is similar. Moreover, the big-
ger room also has higher DRR values compared to the smaller
one. The two reverberation methods did not noticeably affect the
perception of distance in either of the rooms. There is a signif-
icant two-way interaction between method and block, however,
F(2, 22) = 4.4, p = .024. The pattern of this effect is modestly
greater distance estimate in Block 1 for the ray tracing algorithm
(mean 5.6m) relative to the Schroeder ﬁlter (mean 4.9m). As this
effect was absent in subsequent blocks, the effect size was small.
No further block effects were observed.

The results indicate that our method is sensitive to both distance
and moderating effects (i.e., room size) for a static environment
with sources relatively near to the listener. The absence of con-

Figure 5: The average values as judged by the subjects in the two
rooms for the two reverberation methods in the static scene. Fs-
mall (blue), Rsmall (red), Flarge (green), Rlarge (purple) represent
small room with ﬁlter, small room with ray tracing, large room with
ﬁlter, and large room with ray-tracing, respectively. The effect of the
reverberation method (approximate vs. accurate) is null on the per-
ception of distance, which is to be expected in a static scene where
listeners would tend to use just the DRR and intensity for the dis-
tance estimation. Due to our calibration routine, we ensured that the
DRR of the Schroeder ﬁlter matched that of the interactive ray tracing
method. These results suggest that auditory distance perception in
static scenes is mainly governed by the DRRs.

sistent effects of reverberation method over the present distances,
together with the indication that larger rooms would increase per-
ceived distance, motivated us to perform a second experiment with
two changes: First, the room size was increased to a much larger
value, 45m, allowing an expanded range of simulated distances.
Second, dynamic cues to auditory distance perception, based on
listener’s movement, were added. The purpose was to determine if
accurate reverberation would expand perceived distance under these
conditions.

Figure 6: The room used for the experiment. The path marked in
red is the walking path along which the subject walks. The sound
sources are perpendicular to the walking path kept at increasing dis-
tances from it. The labels 1-7 show the different distances sampled
uniformly from the range [10-40]m

5 EXPERIMENT 2: MOVING LISTENER IN A REVERBERANT

ENVIRONMENT

In this section, we present the study results in the dynamic scene.
In this scenario, the listener moves and the movement results in
dynamic reverberation effects.

5.1 Participants

5.4.2 Method

Seventeen participants took part in the study with informed consent.
Their ages ranged from 19 to 47 (mean = 25.9 and SD = 7.4. Four
females, thirteen males). The participants were recruited from the
students and staff at the university. All participants reported normal
hearing.

5.2 Apparatus

The set up consisted of a Dell T7600 workstation and the sound was
delivered via a pair of Beyerdynamic DT990 PRO headphones. The
subjects were blindfolded for the study. The software to compute
the RT60 and DRR was based on open-source MATLAB code [11].
The calibration and auralization were done using in-house software,
also written in MATLAB.

5.3 Stimuli

The source was a pre-recorded, broadband sound of human clap-
ping. The virtual environment consisted of a rectangular room
45m × 10m × 3m with highly reﬂective walls to create a highly-
reverberant environment with an eight meter walking path as shown
in Figure 6. Seven omnidirectional sound sources were kept at in-
creasing distances from the center of the path starting from 10m up
to 40m in increments of 5m. The sources were all kept at the same
height of 1.7m from the ﬂoor. This value was chosen, assuming a
standard listener height of 1.7m in the virtual environment. Sound
was rendered by constructing two impulse responses per source and
using the two reverberation methods - Schroeder ﬁlter and interac-
tive ray tracing - and convolving them with the source signal. The
source sound power was 78dB. The details on how the impulse re-
sponses were generated are described below.

5.4 Design & Procedure

A rectangular room was chosen as it provides the ‘best-case’ sce-
nario for the reverberation ﬁlter. The environment was created to
emulate a highly-reverberant environment similar to a painted, con-
crete room with no windows. As mentioned in Section 2, the DRR
is one of the main parameters in distance perception. In order to
make sure we’re comparing the underlying methods and not the spe-
ciﬁc parameters, we ensured that the RT60 and the DRR are same for
both reverberation methods.

5.4.1 Training

Before the participants started the experiments, they completed a
training task. The training part of the experiment took place in a
real-world setting. An 8m long walking path was constructed and
the sound sources were placed at 3m and 6 from the center of the
walking path, starting with 3m. The participants were blindfolded
before being led into the room so as to not give them an idea of
the room dimensions. The dry (without reverberation) sound clip
was played from a Harmon/Kardon HK 195 desktop speaker. The
participants were asked to point at the sound source with their right
hand and keep pointing at the source as they walked along the 8m
path. Since the participants were blindfolded, they were helped
by the test administrators as they walked down the path. Once they
reached the end of the path, the participants were asked to give their
best evaluation (in meters) as to how far they thought the sound
source to be when it seemed closest to them. The training task was
then repeated with the source moved to 6m. The subjects were told
the actual distances at the end of the training. The training exercise
was not meant to be an exact replica of the experiment as it was not
possible to construct a physical room with the same kind of rever-
berance, as the one in the virtual environment. Instead, the training
was meant to give the participants a feeling as to what to expect and
how to make judgements. Please refer to the supplementary video
on how the training was performed.

This was a within-subject study and all the participants experienced
both methods of reverberation. The walking in the virtual environ-
ment was not controlled by the participants; instead, the 81 im-
pulse responses per source were sampled such that each impulse
response contributed to 0.1m of the total 8m for a human travel-
ing at the average speed of 1.39 m/s. The contributions from each
of these 81 impulse responses/sources were spliced together (with
interpolation) to create a sound ﬁle for each source. This sound
ﬁle was played to the participants and they were asked to give the
same estimate as they performed in the training, i.e., the perceived
distance (in meters) of the sound when it seemed to be the closest
to them. The impulse responses were spatialized using a generic
HRTF-ﬁlter. The participant’s head orientation was ﬁxed and they
were always looking straight ahead. Each participant rated the com-
plete set of 7 source positions × 2 reverberation methods with the
order of the sources randomized for each block, giving a total of
42 (7 source positions × 2 methods × 3 blocks) judgements. The
total time for the experiment, including the training, took around
15 minutes. The participants were allowed to take breaks between
blocks, as required. No fatigue was reported.

5.5 Results

A 3-way ANOVA on block, distance, and reverberation method
shows the signiﬁcant effects of method (F(1, 16) = 15.29, p <
0.01) and distance (F(6, 96) = 29.12, p < 0.01). All two-way inter-
actions (block-distance, block-method, distance-method) failed to
show signiﬁcance indicating that the reverberation method and dis-
tance effects are independent. This ﬁnding indicates that the shape
of distance compression is statistically the same for both the rever-
beration methods and the ray tracing algorithm exhibits an overall
tendency to give longer distances.

The null effect of block indicates that we should average over
blocks in presenting data and that averaging does not obfuscate any
trends in data - it only makes the data cleaner.

6 ANALYSIS

In this section, we analyze the results of our studied performed in
the static and dynamic scenes. Acoustic distance perception is a
complex phenomenon, and few studies have characterized its ef-
fect in virtual environments. Nevertheless, acoustic distance per-
ception forms an important component of immersion in virtual en-
vironments and helps provide additional cues to the perception of
the soundscape.

6.1 Data Fitting

Zahorik [33] performed a comprehensive study of acoustic distance
perception in virtual environments that assesses the weights as-
signed to the principal cues. To analyze the data, [33] ﬁtted a power
function of the form:

Dr = kda
r ,

(3)

where Dr is the perceived distance, k is a constant, a is the power-
function exponent that determines the function’s rate of growth or
decay, and dr is the actual source distance.

Zahorik’s data [33] found that perceived distance was a power
function of the simulated distance with the power parameter aver-
aging 0.39. A value less than 1.0 means that perceived distance was
highly compressive. The mutiplicative parameter was 1.3, which
would result in over-estimation of very low distance values. There
was also substantial variability in the reported judgments across
the individuals, particularly for distances > 1m. The tendency to
compress perceived distance was consistent across the source sig-
nal type or direction, but relative weighting of cues did vary with
these factors.

In our present data, the power function ﬁt on the data generated

the following functions:

and

Daccurate

r

= 1.56d0.58

r

,

D f ilter
r

= 1.08d0.66

r

.

(4)

(5)

accurate is 0.94 while the R2

The R2
f ilter is 0.99; thus both functions
account well for the observed variability in the mean perceived dis-
tance. The exponents exceed by ∼50% the average value found by
Zahorik [33] for a stationary listener.

Figure 7: The power function ﬁt of the distance data for the Schroeder
ﬁlter (in blue, bottom curve) and interactive ray tracing (in red,
top curve) algorithms. This plot suggests that the compression of
perceived distance relative to simulated distance was comparable
across both methods of generating reverberation. The distance per-
ceived with accurate ray tracing algorithm exceeds that obtained with
the ﬁlter method by essentially a constant amount.

The similarity of the power-function exponent for the two rever-
beration methods conﬁrms the lack of interaction between physi-
cal distance and method in the ANOVA, which indicates that the
compression of perceived distance relative to simulated distance
was comparable across both methods of generating reverberation.
The effect of the greater multiplicative parameter for the accurate
method is to move the responses closer to the true values for all dis-
tances measured in our study and any measured beyond this range
of 10m – 40m. Any over-estimation resulting from a multiplicative
parameter > 1.0 would be expected for much smaller distances.
The statistically conﬁrmed result is that across the range of values
examined here, the distance perceived with accurate ray tracing al-
gorithm exceeds that obtained with the ﬁlter method by essentially
a constant amount.

The degree of compression observed here with virtual sound
must be evaluated relative to the compressive perception found in
reverberatory environments with real sound.
If we take the data
from [14] to provide a standard, linear compression of 0.7 is to be
expected with verbal report. The linear ﬁts to the present data were
reasonable for ﬁlter and accurate (values of R2
accurate,
respectively), and the corresponding slopes were 0.24 and 0.23. In
this context, we can estimate the additional compression due to sim-
ulation as a multiplicative factor on the order of 1
3 giving us a good
idea what to expect in terms of perceived distance when using vir-
tual acoustics.

f ilter and R2

6.2 Discussion
The results in the static scene seem to suggest that matching the
DRRs of the approximate method based on Schroeder ﬁlter to that
of ray tracing method may provide the same level of accuracy in
terms distance perception. However, in case of dynamic scenes that

is not sufﬁcient and the accurate ray-tracing algorithm results in
better distance estimates.
Interestingly, in most applications, the
parameters of the Schroeder ﬁlter are tuned by an artist or by us-
ing some presets for a set of different environments. It is not clear
whether those methods can ensure that the DRRs of the Schroeder
ﬁlter would match those computed using the accurate ray-tracing
method. Our Algorithm 1 provides an automatic mechanism to
compute Schroeder ﬁlter with little manual efforts. Moreover, the
reverberation ﬁlters are mostly designed for rectangular rooms, and
are based on Sabines Equation. It is not clear whether they will pro-
vide the same level of reverberation effects or distance estimates for
non-rectangular rooms.

7 CONCLUSIONS, LIMITATIONS, AND FUTURE WORK
In this paper, we studied the impact of different sound propagation
algorithms on auditory distance perception. In particular, we com-
pared the performance of approximate techniques based on para-
metric ﬁlters with accurate techniques based on interactive ray trac-
ing in static and dynamic scenes. Our study shows that although the
compression characteristics of two methods are similar, the more
accurate propagation method results in less distance compression
in VR, especially in dynamics scenes with a moving listener. This
ﬁnding suggests that accurate reverberation effects in a VR sys-
tem can be perceptually useful for different applications. This work
has some limitations. The geometric acoustic methods are accurate
at high frequencies, and it would be useful to combine them with
wave-based methods for low frequencies. Besides sound intensity
and DRR, there are many cues other that may affect auditory dis-
tance perception, including the at-the-ear spectrum due to the sound
absorbing properties of the air and binaural differences [34], and
it would be useful to evaluate them as part of future work. We
would also like to extend our evaluation to environments with mov-
ing sound sources, dynamic obstacles, nonrectangular scenes, and
varying the level of reverberation. It would be useful to combine
our results with other cues (e.g., visual perception). Ultimately, we
hope to develop good VR systems with multi-modal capabilities
(including sound), where researchers from other ﬁelds (e.g., psy-
chology) can evaluate different hypothesis.

REFERENCES

[1] J. B. Allen and D. A. Berkley. Image method for efﬁciently simulat-
ing small-room acoustics. The Journal of the Acoustical Society of
America, 65(4):943–950, April 1979.

[2] L. Antani, A. Chandak, L. Savioja, and D. Manocha. Interactive sound
propagation using compact acoustic transfer operators. ACM Trans.
Graphics, 31(1):7:1–7:12, 2012.

[3] L. Antani and D. Manocha. Aural proxies and directionally-varying
reverberation for interactive sound propagation in virtual environ-
ments. Visualization and Computer Graphics, IEEE Transactions on,
19(4):567–575, 2013.

[4] R. S. Bailey and B. Brumitt. Method and system for automatically
generating world environment reverberation from game geometry.
U.S. Patent Application 20100008513, 2010.

[5] S. Boustila, D. Bechmann, and A. Capobianco. Evaluation of factors
affecting distance perception in immersive virtual environments dur-
ing virtual visits of houses. In Proceedings of the 27th Conference on
L’Interaction Homme-Machine, IHM ’15, pages 8:1–8:10, New York,
NY, USA, 2015. ACM.

[6] A. W. Bronkhorst and T. Houtgast. Auditory distance perception in

rooms. Nature, 397(6719):517–520, 1999.

[7] E. R. Calcagno, E. L. Abreg´u, M. C. Egu´ıa, and R. Vergara. The role
of vision in auditory distance perception. Perception, 41(2):175–192,
2012.

[8] D. J. Finnegan, E. O’Neill, and M. J. Proulx. Compensating for dis-
tance compression in audiovisual virtual environments using incon-
gruence. In Proceedings of the 2016 CHI Conference on Human Fac-
tors in Computing Systems, CHI ’16, pages 200–212, New York, NY,
USA, 2016. ACM.

[9] T. Funkhouser, I. Carlbom, G. Elko, G. Pingali, M. Sondhi, and
J. West. A beam tracing approach to acoustic modeling for interac-
tive virtual environments. In Proc. of ACM SIGGRAPH, pages 21–32,
1998.

[10] T. Hidaka, Y. Yamada, and T. Nakagawa. A new deﬁnition of bound-
ary point between early reﬂections and late reverberation in room
Journal of the Acoustical Society of America,
impulse responses.
122(1):326–332, 2007.

Transactions on Visualization and Computer Graphics, 18:1797–
1810, 2012.

[29] N. Tsingos, C. Dachsbacher, S. Lefebvre, and M. Dellepiane. Instant
sound scattering. In Proceedings of the Eurographics Symposium on
Rendering, pages 111–120, 2007.

[30] V. Valimaki, J. D. Parker, L. Savioja, J. O. Smith, and J. S. Abel. Fifty
years of artiﬁcial reverberation. Trans. Audio, Speech and Lang. Proc.,
20(5):1421–1448, July 2012.

Hummersone.
information

[11] C.
tic
calculator.
mathworks.com/matlabcentral/fileexchange/
42566-impulse-response-acoustic-information-calculator.

acous-
https://www.

[31] M. Vorl¨ander. Simulation of the transient and steady-state sound prop-
agation in rooms using a new combined ray-tracing/image-source al-
gorithm. The Journal of the Acoustical Society of America, 86(1):172–
178, 1989.

response

Impulse

[32] H. Yeh, R. Mehra, Z. Ren, L. Antani, D. Manocha, and M. Lin.
Wave-ray coupling for interactive sound propagation in large complex
scenes. ACM Trans. Graph., 32(6):165:1–165:11, 2013.

[33] P. Zahorik. Assessing auditory distance perception using virtual
the Acoustical Society of America,

The Journal of

acoustics.
111(4):1832–1846, 2002.

[34] P. Zahorik. Direct-to-reverberant energy ratio sensitivity. The Journal
of the Acoustical Society of America, 112(5):2110–2117, 2002.

[12] V. Interrante, B. Ries, and L. Anderson. Distance perception in im-
mersive virtual environments, revisited. In IEEE Virtual Reality Con-
ference (VR 2006), pages 3–10. IEEE, 2006.

[13] J.-M. Jot and A. Chaigne. Digital delay networks for designing artiﬁ-

cial reverberators. In AES Convention, 1991.

[14] R. L. Klatzky, Y. Lippa, J. M. Loomis, and R. G. Golledge. Encoding,
learning, and spatial updating of multiple object locations speciﬁed by
3-d sound, spatial language, and vision. Experimental Brain Research,
149(1):48–61, 2003.

[15] A. Krokstad, S. Strom, and S. Sorsdal. Calculating the acoustical room
response by the use of a ray tracing technique. Journal of Sound and
Vibration, 8(1):118–125, July 1968.

[16] H. Kuttruff. Acoustics: An Introduction. Taylor and Francis, New

York, 2007.

[17] P. Larsson, D. Vastfjall, and M. Kleiner. Better presence and perfor-
mance in virtual environments by improved binaural sound rendering.
In Audio Engineering Society Conference: 22nd International Confer-
ence: Virtual, Synthetic, and Entertainment Audio. Audio Engineering
Society, 2002.

[18] J. M. Loomis and J. M. Knapp. Visual perception of egocentric dis-
tance in real and virtual environments. Virtual and adaptive environ-
ments, 11:21–46, 2003.

[19] J. M. Loomis, Y. Lippa, R. L. Klatzky, and R. G. Golledge. Spatial up-
dating of locations speciﬁed by 3-d sound and spatial language. Jour-
nal of Experimental Psychology: Learning, Memory, and Cognition,
28(2):335, 2002.

[20] R. Mehra, N. Raghuvanshi, L. Antani, A. Chandak, S. Curtis, and
D. Manocha. Wave-based sound propagation in large open scenes
using an equivalent source formulation. ACM Trans. on Graphics,
32(2):19:1–19:13, 2013.

[21] J. Meng, J. J. Rieser, and B. Bodenheimer. Distance estimation in
virtual environments using bisection. In Proceedings of the 3rd Sym-
posium on Applied Perception in Graphics and Visualization, APGV
’06, pages 146–146, New York, NY, USA, 2006. ACM.

[22] N. Raghuvanshi, J. Snyder, R. Mehra, M. Lin, and N. Govindaraju.
Precomputed wave simualtion for real-time sound propagation of dy-
namic sources in complex scenes. ACM Trans. on Graphics (Proc. of
ACM SIGGRAPH), 29(3), 2010.

[23] M. R´ebillat, X. Boutillon, ´E. Corteel, and B. F. Katz. Audio, visual,
and audio-visual egocentric distance perception by moving subjects
in virtual environments. ACM Transactions on Applied Perception
(TAP), 9(4):19, 2012.

[24] A. Rungta, S. Rust, N. Morales, R. Klatzky, M. Lin, and D. Manocha.
Psychoacoustic characterization of propagation effects in virtual envi-
ronments. ACM Transactions on Applied Perception (TAP), 13(4):21,
2016.

[25] C. S. Sahm, S. H. Creem-Regehr, W. B. Thompson, and P. Willem-
sen. Throwing versus walking as indicators of distance perception in
similar real and virtual environments. ACM Transactions on Applied
Perception (TAP), 2(1):35–45, 2005.

[26] C. Schissler and D. Manocha. Interactive sound propagation and ren-
dering for large multi-source scenes. ACM Transactions on Graphics
(TOG), 36(1):2, 2016.

[27] C. Schissler, R. Mehra, and D. Manocha. High-order diffraction and
diffuse reﬂections for interactive sound propagation in large environ-
ments. ACM Transactions on Graphics (TOG), 33(4):39, 2014.
[28] M. Taylor, A. Chandak, Q. Mo, C. Lauterbach, C. Schissler, and
D. Manocha. Guided multiview ray tracing for fast auralization. IEEE

