Image-based underwater 3D reconstruction for 
Cultural Heritage: from image collection to 3D. 
Critical steps and considerations 

Dimitrios Skarlatos 1†  & Panagiotis Agrafiotis 1,2† 

1 Cyprus University of Technology, Civil Engineering and Geomatics Dept., Lab of 
Photogrammetric Vision 2-8 Saripolou str., 3036, Limassol, Cyprus; 
dimitrios.skarlatos@cut.ac.cy, panagiotis.agrafioti@cut.ac.cy 

2 National Technical University of Athens, School of Rural and Surveying Engineering, 
Department of Topography, Zografou Campus, 9 Heroon Polytechniou str., 15780, Athens, 
Greece; pagraf@central.ntua.gr  

† Authors contributed equally to this work 

Abstract     Underwater Cultural Heritage (CH) sites are widely spread; from ruins 
in coastlines up to shipwrecks in deep. The documentation and preservation of this 
heritage is an obligation of the mankind, dictated also by the international treaties 
like the Convention on the Protection of the Underwater Cultural Heritage which 
fosters  the  use  of  “non-destructive  techniques  and  survey  methods  in  preference 
over  the  recovery  of  objects”.  However,  submerged  CH  lacks  in  protection  and 
monitoring in regards to the land CH and nowadays recording and documenting, for 
digital preservation as well as dissemination through VR to wide public, is of most 
importance. At the same time, it is most difficult to document it, due to inherent 
restrictions posed by the environment. In order to create high detailed textured 3D 
models, optical sensors and photogrammetric techniques seems to be the best solu-
tion. This chapter discusses critical aspects of all phases of image based underwater 
3D reconstruction process, from data acquisition and data preparation using colour 
restoration and colour enhancement algorithms to Structure from Motion (SfM) and 
Multi-View Stereo (MVS) techniques to produce an accurate, precise and complete 
3D model for a number of applications. 

Introduction 

Image-based underwater 3D reconstruction is a key tool for 3D record, map and 
model  submerged  heritage providing  the 3D  relief  and  the  valuable  visual  infor-
mation  together.  In  this  context,  they  represent  an  effective  tool  for  research, 

documentation,  monitoring  and  more  recently  public  diffusion  and  awareness  of 
UCH  assets,  through  for  example,  virtual  reality  headsets,  serious  games,  etc. 
[1][2][3]. They can serve also as a tool for the assessment of the state of preservation 
of the submerged heritage and its threats, natural or manmade. Depending on the 
archaeological needs and on the environmental conditions such as depth or water 
turbidity, sensors, techniques and methods may need to be used differently or may 
even be not suitable at all [4]. 

Despite the relative low cost of the image-based methods in relation to others, 
they  present  a  major  drawback;  optical  properties  and  illumination  conditions  of 
water severely affect underwater imagery and data acquisition process. Colours are 
lost as the depth increases, resulting in a green-blue image effect due to light ab-
sorption,  which  mainly  influences  red  wavelength.  Therefore,  red  channel  histo-
gram has fewer values compared to green and blue. Water also absorbs light energy 
and scatters optical rays creating blurred images, reducing the exploitable visibility 
to a few meters.  

Moreover, refraction causes additional issues on the processing of the underwa-
ter imagery. In the literature, two different approaches are reported for dealing with 
the  refraction  effect,  when  the  camera  is  completely  submerged;  the  first  one  is 
based on the geometric interpretation for light propagation through various media 
(e.g. air – housing device – water) and the other on the application of suitable cor-
rections, in order to compensate for the refraction. Some researchers use a pinhole 
camera for the estimation  of the refraction parameters,  while others calibrate the 
cameras with the help of an object of known dimensions, which is put underwater 
in situ [5]. Nowadays, self-calibration is widely applied for the camera-housing sys-
tem, as it is assumed that refraction effects are compensated by the interior orienta-
tion parameters [6]. 

In this chapter, a brief reference to the state of the art in underwater 3D recon-
struction of CH is followed by an analysis of the implications caused by the under-
water environment to the Structure from Motion and Dense Image Matching tech-
niques. Camera calibration, underwater network establishment and data acquisition 
issues  are  also  discussed.  Moreover,  the  need  and use  of  image  processing  tech-
niques in the underwater 3D reconstruction along with best practices, is discussed.  

State of the art in underwater image-based 3D reconstruction 
for Cultural Heritage 

Underwater photogrammetry for seabed mapping has a long history, with initial 
systematic experiments dating back to the sixties [7]. With its versatility, low cost 
equipment and lately the high degree of automation as its main advantages, be-
came the most widely used technique in underwater CH 3D reconstruction nowa-
days, with first report of underwater Structure from Motion application reported 

 
 
 
 
in [8]. Since shallow and deep waters impose different constraints, which influence 
the  recording  process,  there are plenty applications reported  in literature  about 
underwater Cultural Heritage 3D reconstruction. In [4] a wide overview of the state 
of the art on the field is being reported. However, in the following paragraphs, some 
of  the  more  interesting  and  recent  works  found  in  the  literature  are  presented  in 
respect to the data acquisition methodology; divers or robotics platforms. 

Diver based data for underwater 3D reconstruction 

An early report mapping amphorae discovered in a sunken ship off the shore of 
Syria can be found in [9], where a digital orthophoto mosaic was generated. During 
the years that followed, sensors and cameras technology advancement together with 
the affordable waterproof housings and the availability of educational and low-cost 
commercial software for close range photogrammetry facilitated the spread of the 
image-based underwater 3D reconstruction. 

During the recent years, a large number of published studies reports applications 
of  photogrammetry  and  computer  vision  for  underwater  CH  documentation  for 
depths within the limits of most recreational diving certifications. Bruno et al. in 
[10], report over the documentation of an archaeological site in the Baiae underwa-
ter park, during experimental conservation operations. McCarthy and Benjamin in 
[11] discuss the 3D results from trials in Scotland and Denmark at depths of up to 
30 m. Yamafune et al. in [12] present a methodology to record and reconstruct the 
wooden structures of a 19th century shipwreck in southern Brazil and of a 16th cen-
tury shipwreck in Croatia. In [13] a case study of application of photogrammetric 
techniques for archaeological field documentation record in course of underwater 
excavations of the Phanagorian shipwreck is reported. In [14] a survey and 3D rep-
resentation  of  two  Roman  shipwrecks  using  integrated  surveying  techniques  for 
documentation  of  underwater  sites  is  described.  In  [15]  and  [16]  one  of  the  first 
systematic approaches on the continuous 3D documentation of an underwater CH 
asset during the excavation process is reported. The site studied there is the classical 
shipwreck of Mazotos lying at 45m depth, thus beyond recreational diving certifi-
cations. 

More recently, Abdelaziz and Elsayed [17] documented the archaeological site 
of the lighthouse of Alexandria situated at a varying depth of 2 to 9 metres. Until 
2016, only 7200m2 of the 13000 m2  of the submerged site, were covered. Bruno et 
al. in [18] presented an interesting approach for studying and monitoring the preser-
vation  state  of  an  underwater  archaeological  site,  by  combining  the  quantitative 
measurements coming from optical and acoustic surveys with the study of biologi-
cal  colonization  and  bio-erosion  phenomena  affecting  ancient  artefacts.  In  [19] 
some methods for underwater documentation were presented and their advantages 
and disadvantages reported. Authors in [20] reported on the complementarity be-
tween in situ studies and photogrammetry by presenting the feedback from a roman 
shipwreck in Caesarea, Israel. 

 
Most of the aforementioned approaches use the commercially available software 
application Agisoft Photoscan©  . There are few reports in the literature using open 
source  software  for  such  applications  ([8][15][21])  where,  for  the  reconstruction 
process, the Bundler software [22] was used to orient the images and retrieve the 
camera calibration parameters. The successive DIM step was then performed using 
the  PMVS  (Patch-based  Multi-View  Stereo)  software  [23].  For  documenting  a 
semi-submerged  archaeological  structure,  Menna  et  al.  in  [24]  adopted  a  photo-
grammetric method, initially developed for marine engineering applications. In this 
method, two separate photogrammetric surveys are carried out, one in air above the 
water level and one underwater. Then, through several special rigid targets, that are 
partially immersed, rigid transformations are computed to combine the two separate 
surveys in a unique reference system. 

Autonomous Underwater Vehicle (AUV) and Remotely Operated 
Vehicle (ROV) based data for image-based underwater 3D 
reconstruction 

Image data acquisition carried out by scuba divers impose depth limit and several 
safety related constraints; limited bottom time and nitrogen narcosis (deeper than 
30m) may lead to several consecutive dives by several divers for the same data ac-
quisition campaign, thus increasing risks and complicating logistics. To overcome 
the  aforementioned  shortcomings,  robotic  platforms  like  AUVs  and  ROVs  have 
been adopted, especially in cases where larger areas must be covered or access is 
dangerous and depth prohibiting. However, while in shallow waters the use of these 
platforms may be an option over divers, exceeding the recreational diving limits on 
depth and limiting bottom time, reduces choices. Provided that the ROV and AUV 
systems  can  perform  data  acquisition  needed for  image-based  3D  reconstruction 
purposes, they  seem  to be  a  safe choice to reduce or completely  abandon  use of 
divers,  especially in depths more than 30m where the use of artificial  lighting is 
necessary. However, when it comes to real world applications, small ROVs are dif-
ficult to handle, especially  in areas  with  strong currents, they  are prone  to water 
leaks and have limited operational time while larger and more reliable ROVs are 
expensive,  requiring  specialized  boats  and personnel for their  operation,  thus  in-
creasing the cost. 

Captured data by these systems in image-based 3D reconstruction applications 
for CH consist mainly of optical data, but other sensors may also be on board, es-
pecially when larger ROVs and AUVs are employed. Typically, the imagery taken 
from an AUV or ROV system is acquired by following the principles of aerial pho-
togrammetry.  Captured  data  are  processed  using  an  SfM  and  MVS  pipeline  
[25][26][27][28]. Additionally  to the SfM MVS  processing,  the extracted feature 
points are matched and tracked into overlapping stereo-image pairs. This resulting 
information is then integrated with additional navigation sensor data such as a depth 

 
 
 
sensor, a velocity sensor and data from the Inertial Navigation System (INS) in or-
der to implement a SLAM algorithm and compute the trajectory of the platform. 
This estimated trajectory and the 3D points resulting from the SfM-MVS processing 
are then used to reconstruct a global feature map of the underwater scene. This step 
is of high importance when it comes to submerged CH mapping since it enables the 
AUV or ROV pilot to be aware of the area covered and thus the completeness of 
the delivered 3D reconstruction. 

In the literature, many studies describe similar approaches. Johnson-Roberson et 
al. in [29] adopted an AUV and a diver-controlled stereo imaging platform (for very 
shallow water) in order to document the submerged Bronze Age city at Pavlopetri, 
Greece. Bingham et al., in [30] developed techniques for large-area 3D reconstruc-
tion of a 4th c. B.C. shipwreck site off the Greek island of Chios in the north eastern 
Aegean Sea using an UAV. Mahon et al., in [26] presented a vision-based under-
water mapping system for archaeological use in the same area. Another interesting 
approach is presented by Bosch et al. in  [31] where an omnidirectional underwater 
camera mounted on an AUV was used for a mapping a shipwreck. In [32] an ap-
proach based on photogrammetry for surveying the Roman shipwreck Cap Bénat 4, 
at  a  depth of  328m using  an ROV  is  presented.  The Visual Odometry  technique 
presented there provides real time results, sufficient for piloting the ROV from the 
surface vessel and ensures a millimetric precision on the final 3D results. Finally, 
in the work presented in [33], bathymetric maps of underwater archaeological sites 
in water depths between 50m and 400m and different turbidity conditions were gen-
erated using an ROV equipped with optical cameras, laser and a multibeam sonar. 
Expected results over the comparison of the three different sensors indicated that in 
every case the laser and multibeam results were consistent while in stereo imaging 
the  point density was highly dependent on scene texture, which  is  high turbidity 
environments may render photogrammetric approaches useless. 

The  aforementioned  studies  highlight  that  underwater  image-based  3D  recon-
struction is a tool that has been accepted and applied by many disciplines and ex-
perts. Even though this facilitates faster mapping of submerged cultural heritage, 
with impressive results, implementation of those techniques by non-experts or ig-
noring the difficulties addressed in this chapter, underlies the danger of producing 
non-accurate and unreliable results. 

Implications to bundle adjustment and Structure from Motion. 

Any given set of images of a specific object, captured from different viewpoints, 
must undergo bundle adjustment as part of the 3D reconstruction process. This task 
can be described as the simultaneous estimation of camera positions so that the bun-
dles of rays from the images intersect in 3D spaces, both in common points and in 
control points, i.e, points with known coordinates in the reference system of choice. 
At any given photogrammetric project, the Bundle Adjustment (BA) is the critical 
task where all gross and systematic errors are to be detected, estimated and finally 

 
eliminated at a great extent. Remaining systematic errors will affect the final results, 
particularly the 3D reconstruction, in an unpredictable way. Moreover, these errors 
will remain undetectable, unless check points are utilised, as a mean to quantify the 
remaining errors. Camera's interior orientation is a potential systematic error source 
and as such, BA can be employed to resolve camera's (or cameras') geometry. This 
process is known as self-calibration.  

Despite that BA was a well-established process in photogrammetry, the last dec-
ade this process is being replaced from Structure from Motion (SfM), which is a 
more generic process than BA and in fact includes robust BA as the last step. How-
ever,  it  differs  significantly  from  conventional  photogrammetry,  where  a  priori 
knowledge for camera used, initial approximations of camera stations, and a set of 
control points is required. In fact, camera geometry and camera positions and ori-
entation  are  solved  automatically  without  the  need  to  specify  any  a  priori 
knowledge. These are estimated simultaneously using a highly redundant, iterative 
bundle  adjustment  procedure,  based  on  a  database  of  features  automatically  ex-
tracted from a set of multiple overlapping images [34]. The SfM approach is most 
suited to sets of images with a high degree of overlap that capture full three-dimen-
sional structure of the scene viewed from many different positions, or as the name 
suggests, images derived from a moving sensor [35]. 

In essence SfM is more generic, as it includes both the automated task of feature 
points detection, descriptions and matching, followed by robust SBA [36]. Several 
variations  exist,  each  one  with  its  own  characteristics,  strengths  and  weaknesses 
[37].  The  most  critical  task  of  the  process  is  feature  detection,  description  and 
matching, as blunders are unavoidable in this phase. Poor detection and matching 
might  lead  to  incomplete  alignment,  erroneous  alignment  of  few  images  or  total 
failure of the alignment. In all cases, some blunders will remain to the final solution, 
even after robust SBA and will affect final 3D reconstruction. It is advised that these 
errors are manually, or semi automatically selected and removed during the align-
ment phase.  

In a similar way, underwater 3D reconstruction employing SfM, enjoys speed, 
ease of use and versatility but suffers the same limitations and shortcomings. In fact, 
due to particularities of the environment, there are several reasons for the SfM to 
fail.  

Many problems have been reported that tend to be particularly profound in the 
underwater environment, posing either hard limitations or shortcomings, which if 
properly addressed may be overcome. Shortcomings may be divided in two catego-
ries; environmental and computational, with the former ones need to be addressed 
during the acquisition phase and the latter ones being able to address during pro-
cessing.  

Environmental shortcomings affect acquisition process, including control point 
network establishment, stability and coordinate system definition. The deeper the 
site the more the shortcomings. Depth, increases the colour absorption, decreases 
light, reduces bottom time and enhances nitrogen narcosis effects. All these prob-
lems must be dealt during the acquisition phase, with proper planning and dive lo-
gistics. Some problems, such as  camera calibration, colour aberration, vignetting 

 
 
 
etc, can be dealt at some extend with dome lens housings and prime camera lenses. 
Remaining environmental problems effects, may also be dealt computationally, pro-
vided they are not severe. 

Camera calibration 

The obvious consideration  on underwater  photogrammetry is camera calibration, 
which although a trivial task in air, underwater implementation is not. Two media 
photogrammetry is governed by law’s of physics, and therefore, collinearity equa-
tion may be modified and used for underwater camera calibration. Several authors 
have investigated the influence of flat or dome port in underwater photogrammetry, 
both in terms of geometry, and colour ([38][39][24]). The use of dome port, in the-
ory completely removes refraction if the projection centre is positioned at the centre 
of  the  dome  [39], but  in  general  case,  this  is  very  difficult  to  achieve unless  the 
camera and housing are being manufactured as a uniform body. Deviations below 
1 cm from the concision of the two centres might be ignored, or absorbed by the 
central and tangential distortion parameters of the camera calibration model [40]. In 
case the camera is misaligned to the dome or a flat port is being used, the conven-
tional distortion model will not suffice and a full physical model must be adopted 
[39]  such  as  in  [41]  or  [42], taking  into  consideration  the  glass  thickness.  Other 
researchers perform calibration on air and then compile parameters in underwater 
environment [43].  
Chromatic aberration (Fig. 1), is severe in underwater environment and may result 
in several pixels deformation [24]. Although it seems as an irrelevant radiometric 
problem, it can affect image geometric properties during both calibration and 3D 
reconstruction, in several ways. For example, calibration channel (colour) and 3D 
reconstruction channel (colour), should be compatible (the same), otherwise defor-
mations  will  occur.  Therefore,  good  practice  on  underwater  SfM,  is  selecting  a 
channel to work with, both during alignment and 3D reconstruction phase, while for 
texturing the full colour images maybe used, instead of the single channel ones. Post 
processing to amend chromatic aberration could be applied but analysis of the actual 
image-point  correction  due  to  refraction  shows  that  for  close-range  imaging,  the 
actual aberration is depth dependent, and three dimensional problem ([39]4344). 
Light absorption and vignetting affects are also significant, especially in wide angle 
lenses, but the they are bounded to radiometry  without  any geometric extension. 
Using underwater strobes is effective in small distances, and even then, the effect is 
not uniform (Fig. 1). Light absorption also affects clarity and crispness of images, 
hence deteriorating the performance of feature detectors. Backscattering, caused by 
floating particles and false strobe positioning, render photos useless by feature de-
tectors (Fig. 2) Hence, these effects might influence texturing or orthoimage pro-
duction. Underwater photography is a difficult task, governed by many issues, and 
must be mastered before performing photogrammetric documentation of a cultural 
site.  

 
Fig. 1. Samples of underwater chromatic vignetting (left) and chromatic aberration in detail (right), 
where the colour shift of a white line is demonstrated. 

Fig. 2. Typical sample of backscattering effect, if lights are not positioned correctly. Such mild 
effects can be processed correctly from SfM, but when more profound, the results are unexpected. 

Network of control points establishment and solving. 

Georeferencing of CH sites is a standard process in land sites, but underwater is a 
difficult task at depths more than 3m. Up to such depths, use of large poles allows 
surfacing of GPS receiver and correct geolocalization of a rather limited number of 
points, as the process is time consuming. In larger depths, use of buoys is not rec-
ommended as currents and waves do not allow vertical lines to the surface. Availa-
ble  systems  for  exact  geolocalization  of  underwater  sites,  such  as  long  baseline 
acoustic positioning system, may provide accuracy of up to few centimetres, but the 
cost  of  the  system  is  so  high  that  cannot  be  sustainable,  only  for  archaeological 
purposes. Most sites are documented in local reference systems, as establishing a 
reference system is necessary if site is to be revisited for monitoring or due to mul-
tiple excavation periods. 

 
 
 
 
 
 
 
 
 
Even so, establishing an underwater network of control points, is not a trivial task. 
Selecting position of control points (design), fixation of control points, measure-
ment  acquisition,  become difficult  to perform,  the deeper the site is [6]. Limited 
bottom  time,  low  visibility  and  poor  communication  underwater  are  challenging 
conditions, which render many land practices completely useless. The prevailing 
measuring methods in underwater CH documentation are tape measurements and 
photogrammetry,  with  the  latter  having  a  true  advantage  in  terms  of  acquisition 
speed [6], as a whole site may be measured within a single dive, where tape meas-
urements require several dives, complicating dive logistics and overall planning of 
the expedition. 
Even so, computational aspects on solving the network should also be considered, 
since vertical reference in not given, like in land CH sites. Buoys suffer from cur-
rents and cannot provide true vertical reference, inverted hoses with air inside, may 
transfer depth  from point to  point  and provide relative depth differences, but not 
absolute  depth,  and  dive  computers  are  accurate  to  10cm  and  very  unreliable  as 
reading differs from day to day and from brand to brand. By using photogrammetry 
and a free network bundle adjustment, one may take advantage and relate several 
dive computer depth readings into a single solution and therefore provide vertical 
reference to a site. In a similar way when using only tape measurements for trilat-
eration adjustment, depth readings remain unrelated measurements as the inherent 
unreliable vertical solution of trilateration, cannot take advantage of them in a ho-
listic adjustment solution. In [6]  authors, based on  realistic assumptions, demon-
strated  that  when  using  photogrammetric  measurements  for  free  network  adjust-
ment, to assign coordinates in the control points, the average σXY error is 0.02m and 
the  average  σZ  error,  is  0.02m.  Similar  values,  when  using  trilateration  and  tape 
measurements,  are  σXY 0.06m  and  the  average  σZ  error,  is  0.64m.  Nevertheless, 
they point out that different  assumptions over  network might change results, alt-
hough photogrammetric measurements will always be more precise. 

Colour processing of underwater images 

Despite the relative low cost of the image-based methods in relation to others, 
they present a major drawback in underwater environment; optical properties and 
illumination conditions of water severely affect underwater imagery. Colours are 
lost as the depth increases, resulting in a green-blue image due to light absorption, 
which affects mainly red wavelength. Therefore, red channel histogram has fewer 
values compared to green and blue. Water also  absorbs  light  energy and  scatters 
optical rays creating blurred images.  

 
Caustics effect 

Even though the above phenomena affect RGB imagery in every depth, when it 
comes to shallow waters (less than 10m depth), caustics, the complex physical phe-
nomena resulting from the projection of light rays being reflected or refracted by a 
curved surface (Fig. 3), seems to be the main factor degrading image quality for all 
passive optical sensors [46]. Unlike deep water photogrammetric approaches, where 
midday might be the best time for data capturing due to brighter illumination con-
ditions, when it comes to shallow waters, the object to be surveyed needs strong 
artificial illumination, or images taken under overcast conditions, or with the sun 
low on the horizon, in order to avoid lighting artefacts on the seabed [46].  

 
 
 
 
Fig. 3. Caustics of various patterns and density are present in the underwater imagery on shallow 
depths 

If not avoided during the acquisition phase, caustics and illumination effects will 
affect image matching algorithms and are the main cause for dissimilarities in the 
generated textures and orthoimages, if these are the final results. In addition, caus-
tics effects throw off most of the image matching algorithms, leading to less accu-
rate matches  [46]. 

In the literature, only a few techniques have been proposed for the removal of 
caustics from images and video in the context of image enhancement. Trabes et al., 
in [47] propose a technique which involves tuning a filter for sunlight-deflickering 
of dynamically changing underwater scenes. A different approach was proposed in 
[48] where a mathematical solution was presented involving the calculation of the 
temporal median between images within a sequence. The same authors later extend 
their work in [49] and propose an online sunflicker removal method which treats 
caustics as a dynamic texture. As reported in the paper this only works if the seabed 
or bottom surface is flat. In [50] authors propose a method based on analysing by a 
non-linear algorithm a number of consecutive frames in order to preserve consistent 
image  components  while  filtering  out  fluctuations.  Finally,  Forbes  et  al.,  in  [51] 
proposed a solution based on two small and easily trainable CNNs (Convolutional 
Neural Networks). This proposed solution was evaluated in terms of keypoint de-
tection, image matching and 3D reconstruction performance in [46].  

 
 
Despite the innovative and complex aforementioned techniques, addressing caustic 
effect removal with procedural methods requires that strong assumptions are made 
on the many varying parameters involved e.g. scene rigidity, camera motion, etc 45.  

Underwater image restoration and underwater image 
enhancement 

During the last decades, the  acquisition of correct or at least realistic as possible 
underwater colour imagery became a very challenging, as well  as promising,  re-
search field which affects the image-based 3D  reconstruction and mapping tech-
niques [52]. To address these issues, two different approaches for underwater image 
processing are implemented according to their description in literature. The first one 
is image restoration. It is a strict method that is attempting to restore true colours 
and correct the image using suitable models, which parameterize adverse effects, 
such as contrast degradation and backscattering, using image formation process and 
environmental factors, with respect to depth ([53][54][55][56][57]). The second one 
uses image enhancement techniques that are based on qualitative criteria, such as 
contrast and histogram matching [58][59]. Image enhancement techniques do not 
consider the image formation process and do not require environmental factors to 
be known a priori [52][60]. In  both approaches, recent advances in machine and 
deep learning facilitated the implementation of new improved techniques [61] for 
underwater image processing however, due to the lack of sufficient and effective 
training data, the performance of deep learning-based underwater image enhance-
ment algorithms do not match in many cases the success of recent deep learning-
based high-level and low-level vision problems [61]. 

Pre-processing or post-processing the underwater imagery 

Having developed various underwater image colour restoration and colour en-
hancement techniques, experts in underwater image-based 3D reconstruction faced 
the challenge of exploiting them and integrate them into the reconstruction steps. 
This integration is usually tackled with two different approaches; the first one fo-
cuses on the enhancement of the original underwater imagery before the 3D recon-
struction in order to restore the underwater images and potentially improve the qual-
ity of the generated 3D point cloud. This approach in some cases of non-turbid water 
[52][60] proved to be unnecessary and time-consuming, while in high-turbidity wa-
ter it seems to have been effective enough [62]. The second approach suggests that, 
in good visibility conditions, the colour correction of the produced textures or or-
thoimages is sufficient and time efficient [52][60].  

Recently, a combination of the above was proposed in [63]. There, an investiga-
tion as to whether and how the pre-processing of the underwater imagery using five 

 
 
 
implemented  image  enhancement  algorithms  affects  the  3D  reconstruction  using 
automated SfM-MVS software is performed. This work follows and completes the 
work of presented in [52] and [60].  

Image with no artificial light 

Image with artificial light 

Histo-
gram of 
the 
original 
image 

Original 

ACE 

CLAHE 

Lab 

NLD 

SP 

Fig. 4. Example images without artificial light (left column) at a depth of 34.5m captured by an 
ROV and with artificial light (right column) at a depth of 45m (Credits:  Photogrammetric Vision 
Lab. of Cyprus University of Technology for the left column and MARELab, University of Cy-
prus, for the images of the right column) 

Specifically, each one of the presented algorithms in this article is evaluated ac-
cording to its performance in improving the results of the 3D reconstruction using 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
specific metrics over the reconstructed scenes of the five different datasets of sub-
merged Cultural Heritage. To this end underwater imagery ensuring different envi-
ronmental conditions (i.e., turbidity etc.), depth, and complexity was used. Results 
suggest that the 3D reconstructions were not significantly improved by the applied 
methods,  probably  the  minor  improvement  obtainable  with  the  LAB  colour  en-
hancement  algorithm  [64]  could  not  justify  the  effort  to pre-process  hundreds  or 
thousands of images are required for larger models.  

In the case of an underwater 3D reconstruction, the tool presented in [63] can be 
employed to try different combinations of methods and quickly verify if the recon-
struction process can be improved somehow. However, as can be observed in Fig. 
4, if no artificial light is present from a depth and below, images cannot be improved 
due to severe lack of the red channel, and most of the image enhancement methods 
fail. 

A  strategy  that  is  suggested  is  to  pre-process  the  images  with  the  LAB  [64] 
method trying to produce a more accurate and dense 3D reconstruction and, after-
wards, to enhance the original images with  another method such as  ACE [65] to 
achieve a textured model more faithful to reality. Employing this tool for the en-
hancement of the underwater images ensures to minimize the pre-processing effort 
and  enables  the  underwater  community  to  quickly  verify  the  performance of  the 
different methods on their own datasets. 

Conclusions 

This chapter discussed critical aspects of all phases of image-based underwater 
3D reconstruction process, from data acquisition and data preparation using image 
processing  techniques  to  Structure  from  Motion  (SfM)  and  Multi-View  Stereo 
(MVS) techniques to produce an accurate, precise and complete 3D representation 
of the submerged heritage for a number of applications. It is straightforward that 
image-based 3D modelling of CH underwater sites offers the best performance to 
cost ratio. It is affordable, easy and fast, while offers excellent 3D spatial resolution 
and important visual information. However, it heavily depends on visibility, which 
renders the method inadequate for turbid waters. Quality of final results depend on 
many factors and are highly variable, depending on environmental conditions and 
data acquisition experience.  The most important of these parameters is the camera 
to object distance reducing the field of view of a single image, minimizing the dis-
tance from the object and rendering full object coverage a challenge for any diver 
or ROV operator. Therefore, current bottleneck of what seems a flawless 3D recon-
struction  and  texturing  technique  for  VR  applications,  are illumination  problems 
colour variations, processing power imitations, experience over data acquisition and 
reference system definition.  

 
 
 
 
Acknowledgements 

Part of the work presented here conducted in the context of the iMARECULTURE 
project  (Advanced  VR,  iMmersive  Serious  Games  and  Augmented  REality  asn-
Tools to Raise Awareness and Access to European Underwater CULTURal herit-
agE, Digital Heritage) that has received funding from the European Union’s Hori-
zon 2020 research and innovation programme under grant agreement No 727153. 
Authors would like also to thank M.A.RE Lab from University of Cyprus and the 
lead archaeologist Prof. S. Demesticha for providing data from several underwater 
sites, and moreover challenging the authors to overcome problems and shortcom-
ings of the 3D documentation process in underwater CH.  

References 

[1].  Skarlatos, D., Agrafiotis, P., Balogh, T., Bruno, F., Castro, F., Petriaggi, B. D., ... & 
Kikillos,  F.  (2016).  Project  iMARECULTURE:  advanced  VR,  iMmersive  serious 
games and augmented REality as tools to raise awareness and access to European un-
derwater CULTURal heritagE. In Euro-Mediterranean Conference: 805-813. Springer, 
Cham.  

[2].  Bruno, F., Lagudi, A., Muzzupappa, M., Lupia, M., Cario, G., Barbieri, L., ... & Saggi-
omo,  R.  (2016).  Project  VISAS:  Virtual  and  Augmented  Exploitation  of Submerged 
Archaeological  Sites‐Overview  and  First  Results. Marine  Technology  Society  Jour-
nal, 50(4): 119-129.  

[3].  Liarokapis, F., Kouřil, P., Agrafiotis, P., Demesticha, S., Chmelík, J., and Skarlatos, D. 
(2017)  3D  MODELLING  AND  MAPPING  FOR  VIRTUAL  EXPLORATION  OF 
UNDERWATER ARCHAEOLOGY ASSETS, Int. Arch. Photogramm. Remote Sens. 
Spatial  Inf.  Sci.,  XLII-2/W3,  425-431,  https://doi.org/10.5194/isprs-archives-XLII-2-
W3-425-2017, 2017.  

[4].  Menna, F., Agrafiotis, P., Georgopoulos, A. (2018). State of the art and applications in 
archaeological underwater 3D  recording and mapping.  Journal of  Cultural  Heritage, 
33, 231-248. 

[5].  Georgopoulos, A. and Agrafiotis, P., (2012) Documentation of a submerged monument 
using improved two media techniques," 18th International Conference on Virtual Sys-
tems and Multimedia, Milan, 2012, 173-180. doi: 10.1109/VSMM.2012.6365922 
[6].  Skarlatos,  D.,  Menna,  F.,  Nocerino,  E.,  and  Agrafiotis,  P.  (2019)  PRECISION 
POTENTIAL  OF  UNDERWATER  NETWORKS  FOR  ARCHAEOLOGICAL 
EXCAVATION  THROUGH  TRILATERATION  AND  PHOTOGRAMMETRY,  Int. 
Arch.  Photogramm.  Remote  Sens.  Spatial  Inf.  Sci.,  XLII-2/W10,  175-180, 
https://doi.org/10.5194/isprs-archives-XLII-2-W10-175-2019, 2019 

[7].  Rebikoff,  D. I. (1966). Mosaic And  Strip Scanning Photogrammetry Of Large Areas 
Underwater  Regardless  Of  Transparency  Limitations.  In Underwater  Photo  Optics 
I (Vol. 7, pp. 105-115). International Society for Optics and Photonics.  

[8].  Skarlatos, D., Agapiou, A., Rova, M. (2010) Photogrammetric support on an underwater 
archaeological excavation site: The  Mazotos shipwreck case.  Euromed 2010, Digital 
Heritage, 8-11 November, Lemesos, 2010. EuroMed2010, 3rd International Conference 
dedicated on Digital Heritage, Arcaeolingua, 14-20 

 
[9].  Murai, S., Kakiuchi, H., Hano, K., Tsuboi, K., Tanabe, S. (1988) Computer Generated 
Mosaic of Underwater Photographs of Ancient Amphorae, Offshore the Syria, Int. Arch. 
Photogrammetry Remote Sensing Spat. Info. Sci. XXVII (Part B5). 

[10]. Bruno, F., Gallo, A., De Filippo, F., Muzzupappa, M., Petriaggi, B. D., & Caputo, P. 
(2013). 3D documentation and monitoring of the experimental cleaning operations in 
the underwater  archaeological  site  of  Baia  (Italy).  In 2013  Digital  Heritage  Interna-
tional Congress (DigitalHeritage) (Vol. 1, pp. 105-112). IEEE. 

[11]. McCarthy, J., & Benjamin, J. (2014). Multi-image photogrammetry for underwater ar-
chaeological  site recording: an accessible, diver-based approach. Journal of maritime 
archaeology, 9(1), 95-114.  

[12]. Yamafune, K., Torres, R., & Castro, F. (2017). Multi-image photogrammetry to record 
and  reconstruct  underwater  shipwreck  sites. Journal  of  Archaeological  Method  and 
Theory, 24(3), 703-725.  

[13]. Zhukovsky, M.  O.,  Kuznetsov, V.  D.,  & Olkhovsky,  S.  V. (2013). Photogrammetric 
techniques for 3-D underwater  record  of the  antique  time ship  from  Phanagoria. Int. 
Arch. Photogramm. Remote Sens. Spat. Inf. Sci, 40, 717-721.  

[14]. Balletti, C., Beltrame, C., Costa, E., Guerra, F., & Vernier, P. (2016). 3D reconstruction 
of marble shipwreck cargoes based on underwater multi-image photogrammetry. Digi-
tal Applications in Archaeology and Cultural Heritage, 3(1), 1-8.  

[15]. Skarlatos, D., Demestiha, S., & Kiparissi, S. (2012). An ‘open’method for 3D modelling 
and mapping in underwater archaeological  sites. International Journal of Heritage in 
the digital era, 1(1), 1-24.  

[16]. Demesticha, S., Skarlatos, D., & Neophytou, A. (2014). The 4th-century BC shipwreck 
at Mazotos, Cyprus: new techniques and methodologies in the 3D mapping of shipwreck 
excavations. Journal 
DOI: 
of 
http://dx.doi.org/10.1179/0093469014Z.00000000077 

Archaeology, 39(2), 

134-150. 

Field 

[17]. Abdelaziz,  M.  and  Elsayed,  M.  (2019)  UNDERWATER  PHOTOGRAMMETRY 
DIGITAL  SURFACE  MODEL  (DSM)  OF  THE  SUBMERGED  SITE  OF  THE 
ANCIENT LIGHTHOUSE NEAR QAITBAY FORT IN ALEXANDRIA, EGYPT, Int. 
Arch.  Photogramm.  Remote  Sens.  Spatial 
Inf.  Sci.,  XLII-2/W10,  1-8, 
https://doi.org/10.5194/isprs-archives-XLII-2-W10-1-2019, 2019. 

[18]. Bruno, F., Lagudi, A., Collina, M., Medaglia, S., Davidde Petriaggi, B., Petriaggi, R., 
Ricci, S., and Sacco Perasso, C. (2019) DOCUMENTATION AND MONITORING OF 
UNDERWATER  ARCHAEOLOGICAL 
IMAGING 
TECHNIQUES:  THE  CASE  STUDY  OF  THE  “NYMPHAEUM  OF  PUNTA 
EPITAFFIO” (BAIAE, NAPLES), Int. Arch. Photogramm. Remote Sens. Spatial Inf. 
Sci., XLII-2/W10, 53-59, https://doi.org/10.5194/isprs-archives-XLII-2-W10-53-2019, 
2019. 

SITES  USING 

3D 

[19]. Costa, E. (2019) THE PROGRESS OF SURVEY TECHNIQUES IN UNDERWATER 
SITES:  THE  CASE  STUDY  OF  CAPE  STOBA  SHIPWRECK,  Int.  Arch.  Photo-
gramm. Remote Sens. Spatial Inf. Sci., XLII-2/W10, 69-75, https://doi.org/10.5194/is-
prs-archives-XLII-2-W10-69-2019, 2019. 

AND 

SITU STUDIES 

[20]. Derenne,  B.,  Nantet,  E.,  Verly,  G.,  and  Boone,  M.  (2019)  COMPLEMENTARITY 
PHOTOGRAMMETRY: 
BETWEEN IN 
METHODOLOGICAL  FEEDBACK  FROM  A  ROMAN  SHIPWRECK 
IN 
CAESAREA, ISRAEL, Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-
2/W10, 77-83, https://doi.org/10.5194/isprs-archives-XLII-2-W10-77-2019, 2019. 
[21]. Bruno, F., Lagudi, A., Gallo, A., Muzzupappa, M., Davidde Petriaggi, B., and Passaro, 
S.:  3D  DOCUMENTATION  OF  ARCHEOLOGICAL  REMAINS 
IN  THE 
UNDERWATER PARK OF BAIAE, Int. Arch. Photogramm. Remote Sens. Spatial Inf. 
Sci., XL-5/W5, 41-46, https://doi.org/10.5194/isprsarchives-XL-5-W5-41-2015, 2015.  
[22]. Snavely, N., Seitz, S. M., & Szeliski, R. (2008). Modeling the world from internet photo 

collections. International journal of computer vision, 80(2), 189-210.  

 
 
 
[23]. Y. Furukawa, J. Ponce (2010)  Accurate, dense, and robust multi-view stereopsis. Pat-

tern analysis and machine intelligence, IEEE Trans. 32 (8) 1362–1376 

[24]. Menna, F., Nocerino, E., & Remondino, F. (2018). Photogrammetric modelling of sub-
merged structures: influence of underwater environment and lens ports on three-dimen-
sional (3D) measurements. In In latest developments in reality-based 3D surveying and 
modelling (pp. 279-303). MDPI Basel, Switzerland.  

[25]. Johnson‐Roberson, M., Pizarro, O., Williams, S. B., & Mahon, I. (2010). Generation 
and visualization of large‐scale three‐dimensional reconstructions from underwater ro-
botic surveys. Journal of Field Robotics, 27(1), 21-51 

[26]. Mahon, I., Williams, S. B., Pizarro, O., & Johnson-Roberson, M. (2008). Efficient view-
based SLAM using visual loop closures. IEEE Transactions on Robotics, 24(5), 1002-
1014.  

[27]. Ludvigsen, M., Eustice, R., & Singh, H. (2006). Photogrammetric models for marine 

archaeology. In OCEANS 2006 (pp. 1-6). IEEE.  

[28]. Bryson, M., Johnson-Roberson, M., Pizarro, O., & Williams, S. B. (2013). Colour-con-
sistent structure-from-motion models using underwater imagery. Robotics: Science and 
Systems VIII, 33. 

[29]. Johnson‐Roberson, M., Bryson, M., Friedman, A., Pizarro, O., Troni, G., Ozog, P., & 
Henderson, J. C. (2017). High‐resolution underwater robotic vision‐based mapping and 
three‐dimensional  reconstruction  for  archaeology. Journal  of  Field  Robotics, 34(4), 
625-643.  

[30]. Bingham, B., Foley, B., Singh, H., Camilli, R., Delaporta, K., Eustice, R., ... & Sakel-
lariou, D. (2010). Robotic tools for deep water archaeology: Surveying an ancient ship-
wreck with an autonomous underwater vehicle. Journal of Field Robotics, 27(6), 702-
717.  

[31]. Bosch, J., Ridao, P., Ribas, D., & Gracias, N. (2015). Creating 360 underwater virtual 
tours  using  an omnidirectional  camera  integrated  in an  AUV.  In OCEANS  2015-Ge-
nova (pp. 1-7). IEEE.  

[32]. Drap, P., Seinturier, J., Hijazi, B., Merad, D., Boi, J. M., Chemisky, B., ... & Long, L. 
(2015). The ROV 3D Project: Deep-sea underwater survey using photogrammetry: Ap-
plications  for  underwater archaeology. Journal  on  Computing and  Cultural  Heritage 
(JOCCH), 8(4), 21.  

[33]. C.  Roman,  G.  Inglis,  J.  Rutter  (2010)  Application  of  structured  light  imaging  for 
highresolution mapping of underwater archaeological sites, in: In OCEANS 2010 IEEE-
Sydney. IEEE, pp. 1–9. 

[34]. Snavely, N., Garg, R., Seitz, S. M., &amp; Szeliski, R. (2008). Finding paths through 
the  world's  photos.  ACM  SIGGRAPH  2008  papers  on  -  SIGGRAPH 
'08. 
doi:10.1145/1399504.1360614 

[35]. Westoby,  M.,  Brasington, J.,  Glasser, N.,  Hambrey,  M.,  &amp;  Reynolds, J.  (2012). 
‘Structure-from-Motion’ photogrammetry: A low-cost, effective tool for geoscience ap-
plications. Geomorphology, 179, 300–314. doi:10.1016/j.geomorph.2012.08.021 
[36]. Lourakis,  M.  I.  A.,  &amp;  Argyros,  A.  A.  (2009).  Sparse  Bundle  Adjustment.  ACM 

Transactions on Mathematical Software, 36(1), 1–30. doi:10.1145/1486525.1486527 

[37]. Snavely, N., Seitz, S. M., &amp; Szeliski, R. (2006). Photo tourism. ACM SIGGRAPH 

2006 Papers on   - SIGGRAPH '06. doi:10.1145/1179352.1141964 

[38]. Shortis, M., (2019) Camera Calibration Techniques for Accurate Measurement Under-
water, in 3D Recording and Interpretation for Maritime Archaeology, Ed., McCarthy, 
J. K., Benjamin, J., Winton, T., van Duivenvoorde, W. Springer International Publish-
ing, pp, 11-27. 

[39]. Sedlazeck, A., and Koch, R. (2012). Perspective and Non-perspective Camera Models 
in Underwater Imaging -- Overview and Error Analysis. @ book Perspective and Non-
perspective Camera  Models  in Underwater Imaging -- Overview and Error Analysis, 
Ed. Dellaert, F., Frahm, J-M., Pollefeys, M., Leal-Taix, L., Rosenhahn, B. Springer Ber-
lin Heidelberg. pp:212-242 

 
[40]. Kunz, C., Singh, H. (2008). Hemispherical  refraction and camera calibration in under-

water vision. In: OCEANS 2008. pp.1-7 

[41]. Treibitz, T., Schechner,  Y., Singh, H.  (2008) Flat refractive geometry. In: Proc. IEEE 

Conference on Computer Vision and Pattern Recognition CVPR 2008, pp. 1-8 

[42]. Constantinou,  C.,  Loizou,  S.,  G.,  Georgiades,  G.,  Potyagaylo,  S.,  Skarlatos,  D. 
(2014). Adaptive  Calibration  of  an  Underwater  Robot  Vision  System  based  on  Hemi-
spherical Optics. Oceanic Engineering Society - IEEE AUV 2014, Autonomous Under-
water Vehicles 2014, 6-9 Oct., Oxford, Mississippi, US 

[43]. Lavest, J., M., Rives, J., Lapreste, J., T., 2000. Underwatr camera calibration. In: ECCV 
’00: roceedings of the 6th European Conference on Computer Vision-Part II. Pp. 654-668 
[44]. Shortis, M. (2015) Calibration techniques for accurate measurements by underwater cam-

eras. Sensors 15(12), pp. 30810-30826 

[45]. Telem,  G.,  Filin,  S.  (2010)  Photogrammetric  modeling  of  underwater  environments. 

ISPRS Journal of photogrammetry and remote sensing, 65(5), pp. 433-444. 

[46]. Agrafiotis, P., Skarlatos, D., Forbes, T., Poullis, C., Skamantzari, M., and Georgopou-
los,  A.  (2018)  UNDERWATER  PHOTOGRAMMETRY  IN  VERY  SHALLOW 
WATERS: MAIN CHALLENGES AND CAUSTICS EFFECT REMOVAL, Int. Arch. 
Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2, 15-22, https://doi.org/10.5194/is-
prs-archives-XLII-2-15-2018, 2018. 

[47]. Trabes,  E.,  and  Jordan,  M.A.  (2015)  Self-tuning  of  a  sunlight-deflickering  filter  for 
moving  scenes  underwater,  Information  Processing  and  Control  (RPIC),  2015  XVI 
Workshop on. IEEE, 2015.   

[48]. Gracias, N., Negahdaripour, S., Neumann, L., Prados, R., & Garcia, R. (2008). A motion 
compensated filtering approach to remove sunlight flicker in shallow water images. In 
OCEANS 2008 (pp. 1-7). IEEE. 

[49]. Shihavuddin, A. S. M., Gracias, N., & Garcia, R. (2012) Online Sunflicker Removal us-

ing Dynamic Texture Prediction. In VISAPP (1) (pp. 161-167). 

[50]. Schechner,  Y.  Y.,  &  Karpel,  N.  (2004)  Attenuating  natural  flicker  patterns.  In 
OCEANS'04. MTTS/IEEE TECHNO-OCEAN'04 (Vol. 3, pp. 1262-1268). IEEE. 
[51]. Forbes, T., Goldsmith, M., Mudur, S., & Poullis, C. (2018). DeepCaustics: classification 
and removal of caustics from underwater imagery. IEEE Journal of Oceanic Engineer-
ing. 

[52]. Agrafiotis,  P.,  Drakonakis,  G.  I.,  Georgopoulos,  A.,  and  Skarlatos,  D.  (2017)  THE 
EFFECT  OF  UNDERWATER 
3D 
RECONSTRUCTION  AND  ORTHOIMAGERY,  Int.  Arch.  Photogramm.  Remote 
Sens. Spatial Inf. Sci., XLII-2/W3, 25-31, https://doi.org/10.5194/isprs-archives-XLII-
2-W3-25-2017, 2017.  

IMAGERY  RADIOMETRY  ON 

[53]. Hou, W., Weidemann, A. D., Gray, D. J., & Fournier, G. R. (2007) Imagery-derived 
modulation  transfer function  and  its  applications for  underwater imaging.  In  Optical 
Engineering+ Applications (pp. 669622-669622). International Society for Optics and 
Photonics. 

[54]. Treibitz, T., & Schechner, Y. Y. (2009) Active polarization descattering. IEEE transac-

tions on pattern analysis and machine intelligence, 31(3), 385-399. 

[55]. Akkaynak, D., & Treibitz, T. (2018). A revised underwater image formation model. In 
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 
6723-6732). 

[56]. Berman,  D., Treibitz, T.,  &  Avidan,  S.  (2018). Single  Image Dehazing  Using Haze-

Lines. IEEE transactions on pattern analysis and machine intelligence. 

[57]. Akkaynak, D., & Treibitz, T. (2019). Sea-Thru: A Method for Removing Water From 
Underwater Images. In Proceedings of the IEEE Conference on Computer Vision and 
Pattern Recognition (pp. 1682-1691). 

[58]. Ghani,  A.  S.  A.,  &  Isa,  N.  A.  M.  (2014).  Underwater  image  quality  enhancement 
through composition  of  dual-intensity images and Rayleigh-stretching.  SpringerPlus, 
3(1), 757. 

 
 
 
[59]. Mangeruga, M., Cozza, M., & Bruno, F. (2018). Evaluation of underwater image en-
hancement algorithms under different environmental conditions. Journal of Marine Sci-
ence and Engineering, 6(1), 10. 

[60]. Agrafiotis, P., Drakonakis, G. I., Skarlatos, D., & Georgopoulos, A. (2018). Underwater 
Image Enhancement before Three-Dimensional (3D) Reconstruction and  Orthoimage 
Production Steps: Is It Worth. Latest Developments in Reality-Based 3D Surveying and 
Modelling;  Remondino,  F.,  Georgopoulos,  A.,  González-Aguilera,  D.,  Agrafiotis,  P., 
Eds. 

[61]. Li, C., Guo, C., Ren, W., Cong, R., Hou, J., Kwong, S., & Tao, D. (2019). An underwa-
image  enhancement  benchmark  dataset  and  beyond.  arXiv  preprint 

ter 
arXiv:1901.05495 

[62]. Mahiddine, A.; Seinturier, J.; Boï, D.P.J.; Drap, P.; Merad, D.; Long, L. (2012) Under-
water image preprocessing for automated photogrammetry in high turbidity water: An 
application on the Arles-Rhone XIII roman wreck in the Rhodano river, France. In Pro-
ceedings of the 2012 18th International Conference on Virtual Systems and Multimedia, 
Milan, Italy, 2–5 September 2012; pp. 189–194. 

[63]. Mangeruga, M., Bruno, F., Cozza, M., Agrafiotis, P., & Skarlatos, D. (2018). Guidelines 
for underwater image enhancement based on benchmarking of different methods. Re-
mote Sensing, 10(10), 1652. 

[64]. Bianco, G., Muzzupappa, M., Bruno, F., Garcia, R., and Neumann, L.: A NEW COLOR 
CORRECTION METHOD FOR UNDERWATER IMAGING, Int. Arch. Photogramm. 
Remote Sens. Spatial Inf. Sci., XL-5/W5, 25-32, https://doi.org/10.5194/isprsarchives-
XL-5-W5-25-2015, 2015.  

[65]. Getreuer,  P.  (2012).  Automatic  color  enhancement  (ACE)  and  its  fast  implementa-

tion. Image Processing On Line, 2, 266-277. 

 
