1

Digital Twin Network: Opportunities and Challenges
Paul Almasan∗, Miquel Ferriol-Galm´es∗, Jordi Paillisse∗, Jos´e Su´arez-Varela∗,
Diego Perino†, Diego L´opez†, Antonio Agustin Pastor Perales†, Paul Harvey‡, Laurent Ciavaglia‡,
Leon Wong‡, Vishnu Ram§, Shihan Xiao¶, Xiang Shi¶, Xiangle Cheng¶,
Albert Cabellos-Aparicio∗, Pere Barlet-Ros∗
∗Barcelona Neural Networking Center, Universitat Polit`ecnica de Catalunya
†Telef´onica Research ‡Rakuten Mobile §Independent Researcher ¶Huawei Technologies Co.,Ltd.

2
2
0
2

n
a
J

7

]
I

N
.
s
c
[

2
v
4
4
1
1
0
.
1
0
2
2
:
v
i
X
r
a

Abstract—The proliferation of emergent network ap-
plications (e.g., AR/VR, telesurgery, real-time communi-
cations) is increasing the difﬁculty of managing mod-
ern communication networks. These applications typically
have stringent requirements (e.g., ultra-low deterministic
latency), making it more difﬁcult for network operators
to manage their network resources efﬁciently. In this
article, we propose the Digital Twin Network (DTN) as a
key enabler for efﬁcient network management in modern
networks. We describe the general architecture of the DTN
and argue that recent trends in Machine Learning (ML)
enable building a DTN that efﬁciently and accurately mim-
ics real-world networks. In addition, we explore the main
ML technologies that enable developing the components
of the DTN architecture. Finally, we describe the open
challenges that the research community has to address in
the upcoming years in order to enable the deployment of
the DTN in real-world scenarios.

Index Terms—Digital Twin Network, Network Model,

Machine Learning

I. INTRODUCTION

In the last years, the digital transformation of both
society and industry has led to the emergence of novel
network applications. These applications have com-
plex requirements that cannot be easily met by tra-
ditional network management solutions, such as net-
work over-provisioning or admission control. For ex-
ample, novel forms of communication (e.g., AR/VR,
holographic telepresence) require ultra-low determinis-
tic latency, while recent industrial developments (e.g.,
to ever-changing
Vehicular Networks) need to adapt
network topologies in real-time. At the same time, the
number of connected devices is growing rapidly, making
modern networks’ behaviour highly dynamic and hetero-
geneous. As a result, modern communication networks
have become very complex and costly to manage.

This work has been submitted to the IEEE for possible publication.
Copyright may be transferred without notice, after which this version
may no longer be accessible.

Other industry sectors have recently adopted the Dig-
ital Twin (DT) paradigm [1] to model complex and
dynamic systems. A DT can be understood as a virtual
model of a physical object, system, or phenomenon that
is represented in the digital world. The main advantage
of a DT is that
it can accurately model a complex
system without interacting with it, which would oth-
erwise be costly in the physical world. DT examples
include enabling smart manufacturing in Industry 4.0
[2], improving the performance and design of complex
engineering products (e.g., engine design ) or modelling
physical interactions [3].

This article makes the case for the Digital Twin
Network (DTN) as a key enabler of efﬁcient control and
management of modern real-world networks. Speciﬁ-
cally, a DTN allows network operators to design network
optimization solutions, perform troubleshooting, what-if
analysis, or plan network upgrades taking into account
the network’s expected user growth. Since the interaction
with the DTN does not require access to the real network,
the aforementioned processes can be carried out in real-
time, without jeopardizing the physical network.

In addition, we argue that

the latest advances in
Machine Learning (ML) make it possible to build a
DTN. In particular, recent ML proposals have shown
the huge capabilities of modern ML technologies for
modeling complex systems. For example, Alphafold uses
ML to predict protein structures in 3D [4]. In computer
networks, ML has been successfully used to model path
delays [5], schedule jobs in data processing clusters [6],
and optimize trafﬁc in data-centers [7], among others.

in the digital world. Then,

Figure 1 shows a general overview of the DTN. First,
the digital representation of the physical network is
built
the network opera-
tor interacts with the DTN in real-time. The DTN is
built using already existing ML techniques, making its
execution fast and lightweight compared to traditional
network simulation technologies (see later). This allows
the network operator to immediately obtain accurate
performance metrics of the network while evaluating

 
 
 
 
 
 
2

Fig. 1: General Overview

different network conﬁgurations on the DTN.

C. Network Planning

There is a growing interest in the netwroking com-
munity in building a DTN. In particular, Standard De-
velopment Organizations (SDO), such as the IETF or
the ITU, have started to work on the deﬁnition of a
DTN [8]. While their work focuses on deﬁning the main
concepts and interfaces of a DTN, in this article we focus
on the technologies and research challenges involved
in implementing a ML-based DTN, complementing the
work of SDOs.

II. APPLICATIONS OF THE DIGITAL TWIN NETWORK
A. Troubleshooting

There are many factors that cause network failures
(e.g., invalid network conﬁgurations, unexpected proto-
col interactions). Debugging modern networks is com-
plex and time consuming. Currently, troubleshooting is
typically done by human experts with years of experi-
ence using networking tools.

Network operators can leverage a DTN to reproduce
previous network failures, in order to ﬁnd the source
of service disruptions. Speciﬁcally, network operators
can replicate past network failure scenarios and analyze
their impact on network performance, making it easier to
ﬁnd speciﬁc conﬁguration errors. In addition, the DTN
helps in ﬁnding more robust network conﬁgurations that
prevent service disruptions in the future.

B. What-if analysis

The DTN is a unique tool to perform what-if analysis,
where the impact of potential scenarios and conﬁg-
urations are safely analyzed using the DTN. In this
context, the DTN acts as a safe sandbox where different
conﬁgurations are applied to the DTN to understand
their impact on the network. What-if analysis helps
operators detect network misconﬁgurations, bottleneck
links, observe network performance in case of disasters
(e.g., link failures), or predict future network behaviours
under different events without any impact on the real
network.

The size and trafﬁc of networks has doubled every
year [9]. To accommodate this growth in users and
network applications, networks need periodical upgrades.
For example, ISPs might be willing to increase certain
link capacities or add new connections to alleviate the
burden on the existing infrastructure. This is typically
a cumbersome process that relies on expert knowledge.
Furthermore, modern networks are becoming larger and
more complex, thus exacerbating the difﬁculty of exist-
ing solutions to scale to larger networks [10].

The DTN models large infrastructures and produces
accurate and fast performance estimates. Hence, it can
help in estimating when an existing network will run
out of resources, assuming a given growth in users. In
addition, its performance estimates are useful to plan the
optimal upgrade that can cope with such growth. In short,
network operators can leverage the DTN to make better
planning decisions and anticipate network upgrades.

D. Network Anomaly Detection

Since the DTN models the behavior of a real-world
network, network operators have access to an estimation
of the expected network behaviour. When the real-world
network behaviour deviates from the DTN’s behavior, it
can act as an indicator of an anomaly in the real-world
network. Such anomalies can appear at different places
in a network (e.g., core, edge, IoT), and different data
sources can be used to detect such anomalies.

E. Education and Training

As discussed before, the DTN can be understood as a
safe playground where misconﬁgurations don’t affect the
real-world system performance. In this context, the DTN
can play an important role in improving the education
and certiﬁcation process of network professionals. For
example, the DTN can be used in cybersecurity scenarios
to evaluate the effects of network attacks and possible
counter-measures.

Network OperatorINTERACTIONDigital WorldPhysical World3

Fig. 2: Digital Twin Network Architecture.

Fig. 3: Network optimization process using the Digital
Twin Network.

III. ARCHITECTURE

The DTN is a data-driven paradigm that leverages
network-related data to build a digital representation of
a network. The source of this data is typically from real-
world networks, dedicated network testbeds, or network
simulation tools. The data might be diverse in nature, but
has to deﬁne the network environment or phenomena that
the network operator wants to mimic.

Once the data is gathered, the next step is to build
the DTN model. Advances in Deep Learning (DL) tech-
nologies showed great modeling capabilities in complex
network scenarios [5]–[7]. We argue that DL techniques
can be leveraged to extract knowledge from the gathered
data and build the DTN of a network.

Figure 2 presents the reference architecture of the
DTN. The central component of the architecture is
the DT, which fundamentally incorporates a network
model that mimics the physical network. This model
takes as input a set of network-related information and
produces a set of performance metrics. In addition,
some applications (e.g., Trafﬁc Engineering) can use a
network optimizer to ﬁnd the best solutions to different
optimization problems.

A. Digital Twin Network Model

The DTN can be seen as a black-box that contains the
ML-based network model. This box takes as input some
parameters (e.g., trafﬁc, topology, routing, scheduling
policies) and outputs some network-related performance
metrics (e.g., utilization, delay, packet drops). The inputs
and outputs are problem and context dependent.

The network operator can change the values of the
input parameters and observe the resulting performance
metrics of the DTN in real-time. This is done without the
need of running expensive simulations or instrumenting
the real-world network. Since the DTN is a faithful copy
of the real-world network, the operator can test any input
values, even if these values might cause network service

disruptions. This is because the DTN is executed in a
safe environment isolated from the real-world network.
The output performance metrics of the DTN can be
of multiple types (e.g., time-series, per-link prediction,
global metric values), which are deﬁned according to the
needs of the network operator.

B. Network Optimizer

The DTN is combined with a network optimizer
to operate a network efﬁciently. Figure 3 summarizes
this process. The optimizer is in charge of searching
for the best network conﬁguration (step 2) that fulﬁlls
the requirements speciﬁed by a network operator (e.g.,
minimize the maximum link utilization). Such objectives
can be expressed using a declarative language. If the
performance metrics from the DTN indicate that the so-
lution is not good enough (step 3), the network optimizer
continues the search until the stopping condition is met.
The best solution found so far is applied directly to
the real-world network (step 4). To reduce the DTN’s
uncertainty, the network conﬁgurations can be evalu-
ated using lightweight simulation/emulation tools (e.g.,
Mininet) before being applied to the real infrastructure.
Notice that the optimization process can be closed-loop,
where human intervention is not necessarily required.

C. Training the Digital Twin

Training the DTN model requires building a dataset
that contains relevant information of the network. The
DTN’s accuracy highly depends on the quality of the
data, requiring the training dataset to contain a repre-
sentative set of the network behaviour to model. For
example, if the goal is to model the delay of network
ﬂows, then the dataset has to include a wide range of
network scenarios and its impact on the delay. This
means including different routing conﬁgurations, topolo-
gies, scheduling and trafﬁc loads. Likewise, the dataset
has to include events that negatively impact the delay,

Time (s)TrafficNETWORKCONFIGURATIONNetwork ApplicationsOptimizationNetwork PlanningWhat-If?TroubleshootingNETWORK INFRASTRUCTUREDigital TwinTime (s)DelayLink IDUtilizationAnomalyUpgrade LinkCapacityNETWORK METRICSXYNetwork OperatorNetwork Optimizer (e.g., DRL, CP, ILP)Network IntentApply optimal configuration New network configuration (e.g., routing)Network performance metrics (e.g., delay, link utilization)1New network event (e.g., link failure)NETWORK INFRASTRUCTUREDigital Twin2345such as link and interface failures, misconﬁgurations,
highly congested scenarios, etc.

Another important aspect to consider is, where do we
obtain this dataset? Fundamentally, the dataset can be
obtained from real-world networks (i.e., using the real-
world network events) or from non-production dedicated
network infrastructures (i.e., using pre-deﬁned network
events). In other words,
the training dataset can be
generated at the customer network or at a dedicated
testbed not in production.

However, generating such training sets in production
networks is impractical. As we have mentioned,
the
dataset must contain -among other data- failures, miscon-
ﬁgurations and congested scenarios. Nevertheless, this is
not acceptable in a production network, because it can
cause service interruptions. As a result, we envision that
the training dataset will be produced in a non-production
dedicated network infrastructure, such as a testbed. In
the testbed, the network can be conﬁgured with different
trafﬁc proﬁles, failures, misconﬁgurations and errors, as
well as a wide range of valid conﬁgurations without
disrupting users.

We must note that online telemetry should not be
confused with generating the training dataset in a testbed.
Online telemetry is deﬁned as how information from
various data sources is collected using a set of semi-
automated processes. Online telemetry from production
networks can be used to expand the training dataset.
However, the generation of data using not in production
testbeds is still required.

The main challenge of generating the dataset using
dedicated networks is that the DTN has been trained in
a speciﬁc testbed, but when deployed it has to operate
in a previously unseen customer network. Hence, the
DTN has to operate in scenarios that are not speciﬁcally
included in the training set. As an example, the topology
and trafﬁc proﬁle of the customer network might be
different from the ones seen during training in the
testbed. In the AI domain, the capability of a ML-based
model to operate in unseen scenarios is referred to as
generalization.

IV. ENABLING TECHNOLOGIES

A. Digital Twin Network Model

Recent works explored the feasibility of applying DL
techniques to model computer networks. Earlier works
proposed solutions based on traditional Neural Network
(NN) architectures (e.g., Multilayer Perceptron, Recur-
rent NN) for network modeling. Unfortunately, these
solutions yielded poor performance, because classical
NN architectures experience difﬁculties when modeling

4

Fig. 4: Performance comparison of a GNN based model
(RouteNet*), MLP, and RNN for end-to-end path delay
prediction for unseen topologies.

complex relational relationships (e.g., between routing,
topology and end-to-end path delays). In addition, real-
world network topologies can change over time due to
external factors (e.g., link failures), and traditional ML-
based solutions are not able to adapt to such topological
(relational) changes.

Graph Neural Networks (GNN) have been proposed
by the ML community to model relational-structured
information [11]. GNNs are a family of DL models
that capture graph dependencies using a message pass-
ing algorithm between a graph’s entities (e.g., nodes,
edges). Since computer networks are fundamentally rep-
resented as graphs, GNNs offer unique advantages for
network modeling when compared to traditional NN
architectures. In the last years, GNNs have demonstrated
outstanding performance when solving network-related
problems [5]–[7]. We argue that GNNs are a central
technology that enables the construction of scalable
network models that can generalize to different network
topologies, conﬁgurations, and trafﬁc distributions.

Figure 4 shows the results of a motivating experi-
ment to predict end-to-end path delays using different
types of neural networks: a Multi-Layer Perceptron
(MLP), a Recurrent Neural Network (RNN), and a
GNN (RouteNet*), based on the original RouteNet [5].
These results demonstrate that GNNs are able to provide
accurate estimates even in networks not seen during
training. Note that the GNN-based method signiﬁcantly
outperforms the other types of NN architectures.

B. Network Optimizer

A network optimizer can leverage a DTN to solve
several networking problems (e.g., Trafﬁc Engineering).
Speciﬁcally, it can use the DTN to obtain immediate
network performance estimations during an optimization
process. However, the network optimizer must be able

to adapt to the real network’s dynamics. For example,
real-world physical links break due to external factors,
or network users can have different behaviour patterns
that cause difﬁcult-to-predict spikes in the utilization
of network resources. Thus, it is important to adapt to
such changes and to automate the network optimization
process in complex scenarios.

Traditional optimization solutions, such as Constraint
Programming (CP) or
Integer Linear Programming
(ILP), start the optimization process from scratch upon
a change in the optimization scenario. This is inef-
ﬁcient because the knowledge learned from previous
optimization scenarios (e.g., past trafﬁc distribution) is
not transferred to the new scenario (e.g., new trafﬁc
distribution). Deep Reinforcement Learning (DRL) is a
key technology that offers fast operation and can efﬁ-
ciently operate in complex scenarios. DRL differs from
traditional optimization solutions because it leverages
the knowledge learned in past optimizations. DRL has
been applied to network optimization scenarios, showing
outstanding performance [10], [12]. Recent work com-
bining Multi Agent Reinforcement Learning with GNNs
showed that the cost of the optimization process scales
almost linearly with the size of the network topology
[12].

The high complexity of network optimization prob-
lems can make the DRL algorithm reach sub-optimal
solutions. For example, in Trafﬁc Engineering the num-
ber of different routing conﬁgurations that minimize a
network metric under a threshold (e.g., minimize the
maximum link utilization) can be difﬁcult to ﬁnd. Several
works started combining DRL with traditional optimiza-
tion methods (e.g., CP) to improve DRL’s performance
in two different ways. First,
traditional optimization
methods can be used to teach the DRL agent good
actions, helping the agent converge faster to a solution.
Second, methods like CP or Local Search can be applied
after the DRL optimization process to improve DRL’s
solution. The latter explores the neighbourhood of the
DRL’s solution space to ﬁnd a better alternative.

V. OPEN RESEARCH CHALLENGES

A. Generalization

The DTN should be able to perform well on different
or unseen network scenarios. Generalization is important
because training a DTN model is not immediate, and
it is unfeasible training it after every network change
(e.g., link failure). Since these changes occur very fast
(e.g., in vehicular networks), it is not possible to start the
training process again. In addition, modern networks are
large, making it difﬁcult to replicate them on a testbed,

5

or time consuming to simulate them in order to gather
the necessary data to train the DTN model. Therefore,
with generalization capabilities it would be possible to
train the DTN model in smaller network instances, and
deploy it on larger real-world networks without losing
signiﬁcant performance.

B. Flow-based operation

It is necessary to understand the network trafﬁc at a
ﬂow granularity to accurately model a network. However,
networks have a large number of ﬂows which raises scal-
ability issues for ML-based methods [13]. Some network
systems tackle the scalability issue using sampling or
aggregation techniques instead of trying to model each
individual ﬂow. This enables the network operator to tune
the sampling granularity to deﬁne how representative the
samples are going to be. However, most of the ﬂows
are short ﬂows that could be imperceptible to the ﬂow
sampling algorithm. Therefore, building ﬂow-based ML
models that can operate at ﬂow granularity and at short
time scales is a relevant research challenge.

C. Operation in large scenarios

The efﬁcient operation of large scale networks raises a
scalability challenge for the DTN. In such situations, the
performance and inference cost should grow at a similar
rate as the network size (i.e., larger topologies require
larger DTN models, which have higher inference costs).
In addition, the training process should also scale well
with the network as larger scenarios are inherently more
complex, and thus, they require more training time. If a
DTN is applied on a larger network and its performance
degrades, or it takes more time to execute or to train,
the advantages with respect to traditional simulations are
lost.

Operating in large network scenarios implies training
a DTN model for large scenarios. However,
this is
unfeasible as it requires building large and expensive
testbeds or executing time-consuming simulations. Re-
cent works that apply ML techniques to networking
leverage different techniques to enable scalability. One
of them is problem reduction, which reduces the original
problem to a smaller instance of the same problem. As
an example, graph clustering techniques can be used to
reduce the network topology to a smaller version.

D. Explainability

As mentioned previously, NNs are typically seen as a
black-box. This hinders the deployment of NN-based so-
lutions in real-world network scenarios because network

operators struggle to interpret the predictions made by
the NN. Recently, the ML community started to investi-
gate how to understand and interpret better DL models.
Network operators can leverage the knowledge extracted
from the DL trained models to identify potential issues
or design better solutions. However, the tools to interpret
NN-based systems should be easy to use and friendly for
non-ML experts, like network engineers. The networking
community is already investigating methods to interpret
NNs [14].

E. Uncertainty estimation

When a NN is evaluated, it is difﬁcult to obtain a con-
ﬁdence interval of the predicted values. This is important
because the NN can produce overconﬁdent predictions
about the values or actions (e.g., in DRL), making it
difﬁcult for network operators to trust NN-based so-
lutions, and to adopt them in real-world deployments.
Such limitation is important as network operators usually
seek robust and reliable methods to solve networking
problems. To enable the deployment of NNs in real-
world applications it is necessary to ﬁnd a method to
assess the conﬁdence of the values predicted by the
NN. Recent works are trying to solve this problem by
substituting the weights from a NN by distributions [15].

F. Data collection and storage

In a networking context, the collection and processing
of data is challenging and expensive. Data is only
valuable if it is meaningful, which is typically achieved
by using a common data format or labelling. However, in
real-world networks data comes from different sources
and has different formats. Thus,
the data collection
process has to aggregate or transform the original data
to a common representation, which is decoupled from
the data source. This requires using common telemetry
systems to gather relevant network-related data.

One of the limitations of gathering network related
data is that it can require an extremely large amount of
storage. For example, in production scale data-centers
(with the order of thousands of servers) the majority of
ﬂows are short ﬂows, i.e. ﬂows that have a very short
life [13]. Storing the data of all ﬂows can take hundreds
of GB [13], which can become unfeasible to store and
to process. This calls for the research community to ﬁnd
a method to reduce the size of the data and to study
network compression techniques.

VI. CONCLUSION
In this article we introduced the DTN paradigm. We
argued that the DTN enables the design and develop-
ment of efﬁcient network management tools for modern

6

networks. Recent advances in ML enable building a
DTN that is able to mimic the behaviour of a real-
world network. We believe that existing ML techniques
allow the networking industry to build market-ready
DTNs. While there are still some open challenges to
be addressed for a full-scale DTN deployment in real
networks, we encourage the networking community to
explore solutions to these challenges.

ACKNOWLEDGMENT

This publication is part of the Spanish I+D+i project
TRAINER-A (ref. PID2020-118011GB-C21), funded by
MCIN/AEI/10.13039/501100011033. This work is also
partially funded by the Catalan Institution for Research
and Advanced Studies (ICREA) and the Secretariat for
Universities and Research of the Ministry of Business
and Knowledge of the Government of Catalonia and the
European Social Fund.

REFERENCES

[1] F. Tao, H. Zhang, A. Liu, and A. Y. C. Nee, “Digital twin
in industry: State-of-the-art,” IEEE Trans. on Indust. Inform.,
vol. 15, no. 4, pp. 2405–2415, 2019.

[2] Q. Qi and F. Tao, “Digital twin and big data towards smart
manufacturing and industry 4.0: 360 degree comparison,” IEEE
Access, vol. 6, pp. 3585–3593, 2018.

[3] M. Glatt, C. Sinnwell, L. Yi, S. Donohoe, B. Ravani, and J. C.
Aurich, “Modeling and implementation of a digital twin of
material ﬂows based on physics simulation,” Jour. of Manuf.
Syst., vol. 58, pp. 231–245, 2021.

[4] A. W. Senior, R. Evans, J. Jumper, J. Kirkpatrick, L. Sifre,
T. Green, C. Qin, A. ˇZ´ıdek, A. W. Nelson, A. Bridgland et al.,
“Improved protein structure prediction using potentials from
deep learning,” Nature, vol. 577, no. 7792, pp. 706–710, 2020.
[5] K. Rusek, J. Su´arez-Varela, P. Almasan, P. Barlet-Ros, and
A. Cabellos-Aparicio, “Routenet: Leveraging graph neural net-
works for network modeling and optimization in sdn,” IEEE
JSAC, vol. 38, no. 10, pp. 2260–2270, 2020.

[6] H. Mao, M. Schwarzkopf, S. B. Venkatakrishnan, Z. Meng,
and M. Alizadeh, “Learning scheduling algorithms for data
processing clusters,” in Proc. of the ACM Special Interest Group
on Data Comm., ser. SIGCOMM ’19, New York, USA, 2019,
p. 270–288.

[7] L. Chen, J. Lingys, K. Chen, and F. Liu, “Auto: Scaling deep
reinforcement
learning for datacenter-scale automatic trafﬁc
optimization,” in Proc. of the ACM Special Interest Group on
Data Comm., ser. SIGCOMM ’18, New York, USA, 2018, p.
191–205.

[8] C. Zhou, H. Yang, X. Duan, D. Lopez, A. Pastor,
and C.
“Digital
Jacquenet,
Q. Wu, M. Boucadair,
and Reference Architecture,”
Twin Network: Concepts
draft-zhou-nmrg-digitaltwin-network-
IETF,
concepts-05, Oct.
22,
2021). [Online]. Available: https://datatracker.ietf.org/doc/html/
draft-zhou-nmrg-digitaltwin-network-concepts-05

Internet-Draft

on Nov.

(Accessed

2021,

[9] A. Ellis, N. M. Suibhne, D. Saad, and D. Payne, “Communica-
tion networks beyond the capacity crunch,” Phil. Trans. R. Soc.
A, 2016.

[10] H. Zhu, V. Gupta, S. S. Ahuja, Y. Tian, Y. Zhang, and X. Jin,
“Network planning with deep reinforcement learning,” in Proc.
of the ACM SIGCOMM Conf., ser. SIGCOMM ’21. New York,
USA: ACM, 2021, p. 258–271.

[11] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and
G. Monfardini, “The graph neural network model,” IEEE Trans.
on Neural Netw., vol. 20, no. 1, pp. 61–80, 2009.

[12] G. Bern´ardez, J. Su´arez-Varela, A. L´opez, B. Wu, S. Xiao,
X. Cheng, P. Barlet-Ros, and A. Cabellos-Aparicio, “Is machine
learning ready for trafﬁc engineering optimization?” in 2021
IEEE 29th International Conference on Network Protocols
(ICNP), 2021, pp. 1–11.

[13] T. Benson, A. Akella, and D. A. Maltz, “Network trafﬁc
characteristics of data centers in the wild,” in Proc. of the ACM
SIGCOMM Conf. on Internet Measur., ser. IMC ’10, New York,
USA, 2010, p. 267–280.

[14] Z. Meng, M. Wang, J. Bai, M. Xu, H. Mao, and H. Hu,
“Interpreting deep learning-based networking systems,” in Proc.
of the ACM Special Interest Group on Data Comm. on the App.,
Tech., Arch. and Prot. for Computer Comm., ser. SIGCOMM
’20, New York, USA, 2020, p. 154–171.

[15] C. Blundell, J. Cornebise, K. Kavukcuoglu, and D. Wierstra,
“Weight uncertainty in neural network,” in Proc. of the 32nd
Int’l. Conf. on Machine Learning.
PMLR, 2015, pp. 1613–
1622.

7

Antonio Agustin Pastor Perales works as an expert in Telef´onica
I+D for global technical areas where he is involved in network and
security innovation activities.

Paul Harvey is the research lead and co-founder of the Rakuten
Mobile Innovation Studio.

Laurent Ciavaglia is a researcher at Rakuten Mobile and Co-Chair of
the Network Management Research Group at the Internet Engineering
Task Force.

Leon Wong is the Industry Research Collaboration Lead and Re-
search Engineering Lead for Research & Innovation Lab in Rakuten
Mobile.

Paul Almasan is a PhD candidate at the Barcelona Neural Network-
ing Center, Universitat Polit`ecnica de Catalunya.

Vishnu Ram is an independent researcher with more than two
decades in the telecom industry.

Miquel Ferriol-Galm´es is a PhD candidate at the Barcelona Neural
Networking Center, Universitat Polit`ecnica de Catalunya.

Shihan Xiao received his PhD degree at Tsinghua University in
2017 and is currently a technical expert of Network AI at Huawei
Technologies.

Jordi Paillisse is a postdoctoral researcher at the Barcelona Neural
Networking Center, Universitat Polit`ecnica de Catalunya.

Xiang Shi is a senior engineer at the Network Technology Laboratory
of Huawei Technologies.

Jos´e Su´arez-Varela is a postdoctoral researcher at the Barcelona
Neural Networking Center, Universitat Polit`ecnica de Catalunya.

Xiangle Cheng is a research fellow working on NetAI technologies
at Huawei.

Diego Perino is the Director of Telef´onica Research, a team of
researchers and technical experts in the areas of Artiﬁcial Intelligence,
Networks and Systems, Security and Privacy and Human computer
Interaction.

Albert Cabellos-Aparicio is a professor at Universitat Polit`ecnica de
Catalunya and director at the Barcelona Neural Networking Center.

Diego L´opez is a senior technology expert at Telefonica I+D, Chair
of ETSI NFV and PDL ISGs.

Pere Barlet-Ros is a professor at Universitat Polit`ecnica de Catalunya
and scientiﬁc director at the Barcelona Neural Networking Center.

