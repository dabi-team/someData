2
2
0
2

r
p
A
6
1

]

C
H
.
s
c
[

2
v
1
2
1
7
0
.
4
0
2
2
:
v
i
X
r
a

Facing the Illusion and Reality of Safety in Social VR

Qingxiao Zheng
School of Information Sciences
University of Illinois at Urbana-Champaign, USA
qzheng14@illinois.edu

Lingqing Wang
Department of Industrial Engineering
Tsinghua University, China
wanglq19@mails.tsinghua.edu.cn

Tue Ngoc Do
Department of Computer Science
University of Illinois at Urbana-Champaign, USA
tuedo2@illinois.edu

Yun Huang
School of Information Sciences
University of Illinois at Urbana-Champaign, USA
yunhuang@illinois.edu

Abstract
The ethical design of social Virtual Reality (VR) is not a new
topic, but “safety” concerns of using social VR are escalated
to a diﬀerent level given the heat of the Metaverse. For exam-
ple, it was reported that nearly half of the female-identifying
VR participants have had at least one instance of virtual sex-
ual harassment. Feeling safe is a basic human right — in
any place, regardless in real or virtual spaces. In this paper,
we are seeking to understand the discrepancy between user
concerns and designs in protecting users’ safety in social VR
applications. We study safety concerns on social VR experi-
ence ﬁrst by analyzing Twitter posts, and then synthesize
practices on safety protection adopted by four mainstream
social VR platforms. We argue that future research and plat-
forms should explore the design of social VR with boundary-
awareness.

CCS Concepts: • Software and its engineering → Soft-
ware safety; • Social and professional topics → Codes of
ethics; Censorship; • Human-centered computing → Vir-
tual reality.

Keywords: Metaverse, virtual reality, safety, social VR, bound-
ary

ACM Reference Format:
Qingxiao Zheng, Tue Ngoc Do, Lingqing Wang, and Yun Huang.
2022. Facing the Illusion and Reality of Safety in Social VR. In CHI
Conference on Human Factors in Computing Systems (CHI ’22), April
29-May 5, 2022, New Orleans, LA, USA. ACM, New York, NY, USA,
5 pages.

Permission to make digital or hard copies of part or all of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. Copyrights for third-
party components of this work must be honored. For all other uses, contact
the owner/author(s).
CHI EA ’22, Proceedings of the 1st Workshop on Novel Challenges of Safety,
Security and Privacy in Extended Reality, April 29-May 5, 2022, New Orleans,
LA, USA
© 2022 Copyright held by the owner/author(s).

1 Introduction
The 3D virtual world, or metaverse [7], is broadly deﬁned to
be the recent ﬂush of technologies including and related to
Virtual Reality (VR) and Augmented Reality (AR), consisting
of permanent virtual worlds that persist when we log oﬀ.
This new dimension of user interaction is likely to spark
new social norms and cultural behaviors.

However, attention has been drawn towards the safety, or
lack of, features currently existing in commercial VR spaces.
For example, a recent news report [2] asserted that virtual
worlds lack adequate safety precautions; reporting on a group
of researchers who recorded a social transgression (e.g. raci-
sm or sexual harassment) on average once per seven min-
utes, and often with minors present. Heavy criticism has
been raised on some VR front runners, for focusing on growth
at the expense of safety and privacy [5, 6, 12].

Furthermore, considerations of the immersive facet of vir-
tual reality have led some to explore new avenues of on-
line attacks. In comparison to traditional social medias, in
which a user has the physical barrier of a screen held at arms
length, psychological attacks within these spaces are poten-
tially more traumatic [2, 3, 16]. There seems to be less bound-
aries in VR that can rule and determine what are reasonable,
psychologically safe and permissible ways for other people
to behave around self and how self will respond when some-
one steps outside those limits. To this end, we are trying to
explore the following questions:

RQ1: What safety concerns are emerging in social VR plat-

forms?

RQ2: What mechanisms do mainstream social VR products

use to protect user safety?

2 Related Social VR Research
Social VR has been deﬁned as “a growing set of multi-user
applications that enable people to interact with one another
in virtual space through VR headmounted displays” [11]. To-
day’s social VR applications are similar to “collaborative vir-
tual environments” studied in the late 1990s and early 2000s,
which applied virtual reality to support multiple user inter-
actions [4].

 
 
 
 
 
 
CHI EA ’22, Proceedings of the 1st Workshop on Novel Challenges of Safety, Security and Privacy in Extended Reality, April 29-May 5, 2022, New Orleans,
Zheng, et al.
LA, USA

There are a set of works mapping social VR landscape and
design research by proposing a taxonomy of social VR appli-
cation design ecology [15, 21]. Some work specially investi-
gated codes of ethics in the virtual worlds [1, 8, 13]. Some
studied social VR from human factor perspective. For exam-
ple, one study investigated how violations of interpersonal
space can cause discomfort in real-world situations [19], and
another work learned how users shape pro-social behavior
in VR [14].

New questions have arisen from the embodied and spa-
tialized experiences that immersive presence in VR aﬀords
in recent years. Harassment in social VR, for instance, has
proven particularly fraught, with the eﬀects of abuse magni-
ﬁed by embodied presence [15]. However, to the best of our
knowledge, research related to safety mechanisms applied
in social VR is still very limited.

3 Method
We conducted an exploratory study. The seed ﬁndings will
be expanded with a more comprehensive investigation in
the future.

3.1 Scraping Social Media Posts

To answer RQ1, we used the Tweepy and PRAW Python
packages to scrape recent three months’ content from Twit-
ter and Reddit, respectively. These social media platforms
were chosen due to their more public natures and author
familiarity. We used search queries of social VR synonyms
(e.g., social VR, social virtual reality, virtual reality, virtual
worlds) and names of commercial social VR applications [21].
We ended up with 18,274 data entries and proceeded by man-
ually reviewing all tweets and comments after ﬁltering by
keywords. Using a thematic analysis approach [18], we syn-
thesized major concerns and discussion topics of social me-
dia posts related to social VR.

3.2 Investigating Mainstream Social VR Platforms
To answer RQ2, we investigated 14 existing social VR com-
mercial applications previously summarized [10, 21]. Based
on number of downloads in across VR app stores of Oculus
Store1, Steam VR2, and Sidequest 3, we chose four social VR
apps. They are Rec Room4, which allows users to manipu-
late a variety of objects and engage with mini-games with
other users; VRChat5, which is known for non-normative so-
cial interactions and performative memes; Horizon Worlds6,
which allows users to explore virtual worlds and engage in
content consumption and creation; and AltspaceVR7, which

1https://www.oculus.com/experiences/quest
2https://store.steampowered.com/vr
3https://sidequestvr.com/all-apps
4https://recroom.com
5https://hello.vrchat.com/
6https://www.oculus.com/horizon-worlds
7https://altvr.com

is used for live, virtual events, empowering artists, brands,
and businesses. One researcher experienced these social VR
apps using an Oculus Quest 2 headset and triggered the
safety mechanisms built within to examine these apps’ safety
protection protocols. Then, one co-author summarized the
observations of the safety mechanisms applied by the apps.
Additionally, co-authors analyzed the relationship between
safety-related design features and the kinds of social inter-
actions they may support or constrain, by reviewing their
experiences of onboarding, exploration, and play.

4 Preliminary Takeaways
4.1 Safety Concerns about Social VR (RQ1)

4.1.1 Safety of Minors. A key concern mentioned by mul-
tiple users across platforms were the existence of minors
in these VR environments. Although users seemed to be
split on whether to blame parents or developers for negli-
gence, users unanimously expressed that minors did not be-
long on the platform, as their safety could not be guaranteed.
The underlying reasoning was the perceived accessibility of
dangerous/unﬁtting material. For example, one Twitter user
made an analogy to the physical world "There’s a beneﬁt to
the physical distance between the average house and the Vegas
strip. Harder for your kids to just wander over there."

Virtual reality has attracted many young users with chat
rooms and popular games, such as Roblox. But whether it
can adequately protect children is a major concern. Many
users of Horizon Worlds have reported that Facebook, now
Meta, does not suﬃciently enforce the age restriction, which
leads to worries for minors’ safety and a negative adult user
experience. These problems have been widely discussed and
addressed on social media. However, some platforms in vir-
tual reality spaces still lag behind common concerns, lack-
ing pre-existing methods such as parental controls and guard-

rails for young users, to the frustrations of some commu-
nity members.

4.1.2 Distrust of Corporations. Another concern is dis-
trust. Speciﬁcally, regarding the track record of Meta, there
seemed to be some pushback with Reddit users feeling un-
comfortable plugging in at all. One Reddit user remarked
"I can assure you I will not be using it [Oculus]...Zuckerberg
has revealed over and over he doesn’t [care (replaced word for
polite language)] about safety or privacy."

There also seems to be a disdain for Meta’s current moder-
ation systems. Regarding sexual harassment and abusive
behavior, one commentor expresses in regards to a block-
ing feature (at the time unimplemented), "I would not be sur-
prised if Facebook empowers users even in this minor way. You
know they aren’t gonna bother banning creeps."

In December 2021, a beta tester of Horizon Worlds wrote
about being virtually groped by another user, creating quite

CHI EA ’22, Proceedings of the 1st Workshop on Novel Challenges of Safety, Security and Privacy in Extended Reality, April 29-May 5, 2022, New Orleans,
LA, USA
Facing the Illusion and Reality of Safety in Social VR

a stir. After that, while VR platforms are claiming to de-
velop diﬀerent tools and improve their accessibility to pro-
tect users, more harassment cases are reported. Sexual ha-
rassment exists in all kinds of digital spaces. However, the
immersive, multi-sensory and ‘realistic’ nature of VR trig-
gers stronger emotional responses, thus even worse reper-
cussions for users in such circumstances.

4.1.3 Humiliating Behaviors. Currently, the public seems
to largely rehash many known concerns with other social
media without considering the additional dimension and com-
plications a virtual reality can bring. For example, regarding
a now-famous incident of a woman being groped while in
VR, some commentors were dismissive of her experiences,
suggesting that woman just "turn it oﬀ", and falsely equaliz-
ing the experience with milder internet norms such as teabag-
ging (the act of repeatedly crouching). As more incidents
were logged with these technologies and social space, and
new norms and cultures are yet established, it remains to
be seen where public opinions start to lean in terms of user
safety in the virtual worlds.

4.1.4 Integration with the Reality. Many users have been
discussing that Social VR platforms might blur the boundary
between reality and the virtual world. Despite users’ wor-
ries that the VR world may lead to addiction easily, causing
more serious isolation from real-world and cognitive prob-
lems. It also raises concerns when integrating into the real
world. For example, there are several news reports on the
physical injury in the real-world caused by body movement
in the virtual world, when users immerse themselves in the
playing.

Some other emerging issues have also caught public atten-
tion. One is the sleeping phenomenon. Widely discussed
on YouTube channels, there is a unique phenomenon that
users regularly sleep on virtual platforms despite all the in-
conveniences in real world. For example, the headset might
hinder head movement while sleeping, and the cable might
tie around users’ neck. Reasons for sleeping in a social VR
platform vary from social satisfaction when sleeping with
friends to avoiding the real-world noisy environment. Though
users make the trade-oﬀ to do so, they are generally not
clear about the potential consequence.

Another emerging issue is phantom touch, or more broadly
speaking, phantom sense, which means users feel the sen-
sation as if they are their avatars, without any haptic tech-
nology. One Reddit user wrote "when someone headpats me
(well, my avatar, but to me, they’re the same thing... ) it gives
me a tingly feeling on my head ..." There are many explana-
tions and guides to help users develop phantom touch in
Reddit and other discussion forums. Some users claim they
naturally gain phantom sense, and other provides various
methods to trick the mind into that. For example, one user
in the Steam community recommended asking a friend to
pet users’ face in VR, suggesting that "area most sensitive

for most people is the small part between the upper lips and
the bottom of the nose - especially to the left and right of the
center." While this phenomenon is not clear, it adds exciting
layers to user experience in virtual world. Many users are
trying to practice and keep the feelings of phantom touches
in VR. However, many users also express their worries about
whether they can still diﬀerentiate between reality and the
virtual environment. After all, having a bad experience for
the avatars, like being shoved or stabbed, might not be fun.
In summary, we found that safety concerns on social me-
dia include "intensiﬁed old concerns in the new world." Ha-
rassment and abusive behaviors, distrust of user privacy,
content appropriateness for children etc., have long been
discussed in previous social platforms. And now, they exac-
erbate users’ concerns because of the double-edged, more
authentic experience that social VR platforms promise to
provide, which would also bring more real lousy experience
at the same time.

Also, some "new concerns in the new world" have recently
become salient, such as problems caused by the separation
of body and mind in real and virtual worlds, and emerging
issues like sleeping phenomenon and phantom sense. How
work and lifestyles would be reshaped, and what that might
impact user psychological and physical safety are not yet
addressed extensively.

4.2 Designs Features for User Safety (RQ2)

In a prior work, we advocate raising "boundary-awareness"
when designing AI-based interactive systems to support hu-
man-human interaction [20]. When reviewing safety mech-
anisms adopted by main stream social VR platforms, we iden-
tiﬁed six major social boundary settings, four safety protec-
tion mechanisms, and community protocols.

4.2.1 Setting Social Boundaries. We found six bound-
ary related design practices to keep users comfortable with
social distance when hanging out in social VR.

(1) Intimacy Proxemic. Hall’s personal space theory de-
scribes that there are four zones in personal space [9]. Re-
cently, Horizon Worlds released the personal boundary fea-
ture with a default setting making users feel like an almost
4-foot distance between their avatar and others. Similarly,
Rec Room has an adjustable "personal space bubble," an in-
visible space that allows users to control how close other
players interact with their avatars from close, medium, to
large. We also found a similar function in AltspaceVR.

(2) Intimacy Rank. When playing VRchat, users’ trust
feeds into a "trust rank" with several levels, i.e., trusted user,
known user, user, new user, visitor, and nuisance.

(3) Social Spaces. Rec Room has a dorm room, user-created

rooms, and clubs. The dorm room is a completely private
space. Room owners of user-created rooms and clubs are
fully responsible for ensuring their rooms do not devolve
into a toxic mess, even if they are going on vacations in the

CHI EA ’22, Proceedings of the 1st Workshop on Novel Challenges of Safety, Security and Privacy in Extended Reality, April 29-May 5, 2022, New Orleans,
Zheng, et al.
LA, USA

real world. We found that local expectations are set for con-
duct in public spaces. For example, it must be private if a
club involves sexual themes.

(4) Image Control. Users can adjust both their own avatars’

identities, such as gender, race, and voice, and select to hide
or show speciﬁc users’ avatars. For example, in VRchat, when
a user encounters a user that, despite their higher Trust
Rank, is wearing an avatar they feel uncomfortable, they
can choose "hide avatar" in their social panel.

(5) Trust System. Users can adjust control settings to
maintain desirable social boundaries with others. For exam-
ple, VRChat trust and safety system can keep users safe from
nuisance by adjusting microphones, screen-space shaders,
loud sounds, or visually noisy or malicious particle eﬀects.
(6) User Demographics. Age limits are set in social VR.
For example, Rec Room enables a junior account managed
by an account owned by the parent or guardian for players
under 13 years of age, which come with safety features to
prevent children from disclosing their identiﬁable informa-
tion in the virtual world. It also allows age-based matchmak-
ing to recommend players close to their age range.

4.2.2 Quick Reactions When Boundaries are Crossed.
Diﬀerent safety self-protection mechanisms were designed
to allow users to react accordingly when their social bound-
aries are violated in the virtual world, ranging from reac-
tions and safe zones to safety reports.

Safety Reactions. Simple communication gestures and
shortcuts allowed quick-action remediation in challenging
situations. For example, Rec Room’s ’talk to the hand’ and
pointing gestures can instantly trigger users’ comfort and
moderation menu, allowing users to mute, block, vote kick,
and report the player. These simple mechanisms enable users
to report a hurting experience instantly without interrupt-
ing or degrading their experience.

Safe Mode. VRchat has a shortcut called "safe mode," which
can immediately disable all features on all users around. Hori-
zon worlds oﬀer a one-touch button that can quickly re-
move users from a situation. Similarly, AltspaceVR has a
"title screen" feature, which immediately drops users back
into the command center, removing their avatars from the
previous space and scene.

Safety Reports. Users can report users, rooms or event
places that violate codes of conduct or ask for extra support.

4.2.3 Consent and Codes of Conduct. All applications
have informed Consent before using entering the applica-
tion. The informed consent contents regarding health and
safety warnings range from the immersive eﬀects on users’
psychological status, a notice of risky content during social
interactions, and user privacy. Some applications, for exam-
ple, Rec Room, also require users to ﬁnish a tutorial of codes
of conduct in the virtual environment; these codes were in-
troduced to newcomers and repeated displayed to members
of the communities.

5 Opportunities for Future Research
Initial results reveal many old safety concerns in the new
virtual world (e.g., user trust, abusive language and behav-
ior, threats to minors) which current design features have
addressed. However, some new issues, such as the "phan-
tom sense," are not considered by any reviewed social VR
apps. There are many novel safety facets of this emerging
design space of social VR. Below, we propose some topics to
explore.

5.1 Re-deﬁning User Safety in Social VR

Do we need to redeﬁne safety in social VR? VR has many
shared characteristics with our experiences in real life. Be-
cause players can disguise themselves into another human,
animal, or object and use transportation behaviors, they may
have diﬀerent social boundaries and appropriateness deﬁni-
tions than as usual. Due to its nascent stage and creative for-
mats, it is yet to investigate the social norms being applied
in the new world. One approach is distinguishing universal
rules and consequences for real-world and virtual-world vi-
olations and harassment.

5.2 Boundary-Awareness for Safter Social Systems

Boundary-aware design is an emerging and under-explored
research area[20]. Our ﬁndings on social VR safety mech-
anisms demonstrate the dynamics of boundary considera-
tions in social systems. Studying how these systems con-
sider various social boundaries and the interactions occur-
ring at diﬀerent levels of boundaries, may add value to the
human-human interactions through these social technolo-
gies. For example, building granular controls on diﬀerent
boundary levels (e.g., on information sharing, emotional bou-

ndaries, diﬀerentiating reality and virtual, persona building,
to name a few) may help foster safety in social VR spaces. Re-
searchers can also develop a boundary-aware framework to
support the design process and evaluations with such aware-
ness.

5.3 Values of Platforms, Creators, and Users
Building safe and responsible VR ecology will have a com-
petitive edge in the virtual world. For platforms, toolkits
providers that have the autonomy to limit content creators’
production capabilities may easily restrict creators’ devel-
opment capabilities by restraining risky developer support.
Creators, such as those in the Decentraland, a ﬁrst-ever plat-
form to create, explore, and trade land in the virtual world
owned by its users, have high autonomy in the "fully de-
centralized world." Platforms can hardly control the content
created. For users, we found community consensuses and
discussions regarding safety in social VR are not fully de-
veloped, perhaps due to its novelty. One possible approach

CHI EA ’22, Proceedings of the 1st Workshop on Novel Challenges of Safety, Security and Privacy in Extended Reality, April 29-May 5, 2022, New Orleans,
LA, USA
Facing the Illusion and Reality of Safety in Social VR

violent incident in an immersive virtual environment. PloS one 8, 1
(2013), e52766.

[18] Gareth Terry, Nikki Hayﬁeld, Victoria Clarke, and Virginia Braun.
2017. Thematic analysis. The SAGE handbook of qualitative research
in psychology 2 (2017), 17–37.

[19] Laurie M Wilcox, Robert S Allison, Samuel Elfassy, and Cynthia Gre-
lik. 2006. Personal space in virtual reality. ACM Transactions on Ap-
plied Perception (TAP) 3, 4 (2006), 412–428.

[20] Qingxiao Zheng, Yiliu Tang, Yiren Liu, Weizi Liu, and Yun Huang.
2022. UX Research on Conversational Human-AI Interaction: A
arXiv preprint
Literature Review of the ACM Digital Library.
arXiv:2202.09895 (2022).

[21] Douglas Zytko, Ryan Handley, Bert Guerra, and Rukkmini Goli. 2022.
A Taxonomy of Social VR Design. arXiv preprint arXiv:2201.02253
(2022).

perhaps can be community-based safety reports, where by-
standers can intervene and stop a violent attack by one per-
son on another [17]. A shared understanding is needed and
we posit that more future studies could uncover more fruit-
ful understandings.

References
[1] Devon Adams, Alseny Bah, Catherine Barwulor, Nureli Musaby,
Kadeem Pitkin, and Elissa M Redmiles. 2018. Ethics emerging: the
story of privacy and security perceptions in virtual reality. In Four-
teenth Symposium on Usable Privacy and Security (SOUPS 2018). 427–
442.

[2] Maura Barrett and Forte Douglas. 2019. Metaverse virtual worlds lack

adequate safety precautions.

[3] Tanya Basuarchive. 2021. The metaverse has a groping problem al-

ready.

[4] Barbara Becker and Gloria Mark. 1998. Social conventions in collab-
orative virtual environments. In Proceedings of Collaborative Virtual
Environments. 17–19.

[5] Lindsay Blackwell, Nicole Ellison, Natasha Elliott-Deﬂo, and Raz
Schwartz. 2019. Harassment in social VR: Implications for design. In
2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR).
IEEE, 854–855.

[6] Ellysse Dick. 2021. Balancing User Privacy and Innovation in Aug-
mented and Virtual Reality. Technical Report. Information Technol-
ogy and Innovation Foundation.

[7] John David N Dionisio, William G Burns III, and Richard Gilbert. 2013.
3D virtual worlds and the metaverse: Current status and future possi-
bilities. ACM Computing Surveys (CSUR) 45, 3 (2013), 1–38.

[8] Colin M Gray and Shruthi Sai Chivukula. 2019. Ethical mediation
in UX practice. In Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems. 1–11.

[9] Edward T Hall, Ray L Birdwhistell, Bernhard Bock, Paul Bohannan,
A Richard Diebold Jr, Marshall Durbin, Munro S Edmonson, JL Fischer,
Dell Hymes, Solon T Kimball, et al. 1968. Proxemics [and comments
and replies]. Current anthropology 9, 2/3 (1968), 83–108.

[10] Marcel Jonas, Steven Said, Daniel Yu, Chris Aiello, Nicholas Furlo, and
Douglas Zytko. 2019. Towards a taxonomy of social vr application
design. In Extended Abstracts of the Annual Symposium on Computer-
Human Interaction in Play Companion Extended Abstracts. 437–444.

[11] Anya Kolesnichenko, Joshua McVeigh-Schultz, and Katherine Isbister.
2019. Understanding emerging design practices for avatar systems in
the commercial social vr ecology. In Proceedings of the 2019 on Design-
ing Interactive Systems Conference. 241–252.

[12] Fade Lorne. 2021. What Is Virtual Reality, And How Can It Be Used In

The Workplace?

[13] Michael Madary and Thomas K Metzinger. 2016. Real virtuality: a
code of ethical conduct. Recommendations for good scientiﬁc practice
and the consumers of VR-technology. Frontiers in Robotics and AI 3
(2016), 3.

[14] Joshua McVeigh-Schultz, Anya Kolesnichenko, and Katherine Isbister.
2019. Shaping pro-social interaction in VR: an emerging design frame-
work. In Proceedings of the 2019 CHI Conference on Human Factors in
Computing Systems. 1–12.

[15] Joshua McVeigh-Schultz, Elena Márquez Segura, Nick Merrill, and
Katherine Isbister. 2018. What’s It Mean to" Be Social" in VR? Map-
ping the Social VR Design Ecology. In Proceedings of the 2018 ACM
Conference Companion Publication on Designing Interactive Systems.
289–294.

[16] Frenkel Sheera and Browning Kellen. 2021. The Metaverse’s Dark Side:

Here Come Harassment and Assaults.

[17] Mel Slater, Aitor Rovira, Richard Southern, David Swapp, Jian J Zhang,
Claire Campbell, and Mark Levine. 2013. Bystander responses to a

