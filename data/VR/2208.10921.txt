JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

1

AI and 6G into the Metaverse: Fundamentals,
Challenges and Future Research Trends

Muhammad Zawish, Student Member, IEEE, Fayaz Ali Dharejo, Student Member, IEEE,
Sunder Ali Khowaja, Senior Member, IEEE, Kapal Dev, Senior Member, IEEE, Steven Davy, Member, IEEE,
Nawab Muhammad Faseeh Qureshi, Senior Member, IEEE, Paolo Bellavista, Senior Member, IEEE

2
2
0
2

p
e
S
4
2

]
I

A
.
s
c
[

2
v
1
2
9
0
1
.
8
0
2
2
:
v
i
X
r
a

Abstract—Since Facebook was renamed Meta, a lot of atten-
tion, debate, and exploration have intensiﬁed about what the
Metaverse is, how it works, and the possible ways to exploit it. It
is anticipated that Metaverse will be a continuum of rapidly
emerging technologies, usecases, capabilities, and experiences
that will make it up for the next evolution of the Internet. Several
researchers have already surveyed the literature on artiﬁcial
intelligence (AI) and wireless communications in realizing the
Metaverse. However, due to the rapid emergence and continuous
evolution of technologies, there is a need for a comprehensive and
in-depth survey of the role of AI, 6G, and the nexus of both in re-
alizing the immersive experiences of Metaverse. Therefore, in this
survey, we ﬁrst introduce the background and ongoing progress
in augmented reality (AR), virtual reality (VR), mixed reality
(MR) and spatial computing, followed by the technical aspects of
AI and 6G. Then, we survey the role of AI in the Metaverse by re-
viewing the state-of-the-art in deep learning, computer vision, and
Edge AI to extract the requirements of 6G in Metaverse. Next, we
investigate the promising services of B5G/6G towards Metaverse,
followed by identifying the role of AI in 6G networks and 6G
networks for AI in support of Metaverse applications, and the
need for sustainability in Metaverse. Finally, we enlist the existing
and potential applications, usecases, and projects to highlight the
importance of progress in the Metaverse. Moreover, in order to
provide potential research directions to researchers, we underline
the challenges, research gaps, and lessons learned identiﬁed from
the literature review of the aforementioned technologies.

Index Terms—Metaverse, 5G, 6G, AI, cloud and edge

computing, AR/VR/XR, spatial computing

I. INTRODUCTION

I N 2021, Metaverse started inﬂuencing the real-world due

to: i) pandemic lifestyle, and ii) the announcements of
Meta, Amazon, Apple, Netﬂix, and Google (MAANG) to
release Metaverse-related features and projects for their users.
Since then, Metaverse has sought sheer attention from both
academia and industry. At the current point in time, the Meta-
verse can be generally viewed as a pool of extended reality
(XR)1 spaces in which humans and their digital counterparts

M. Zawish and S. Davy are with Walton Institute for Information and
Communication Systems Science, South East Technological University,
Ireland, E-mails: {muhammad.zawish, steven.davy}@waltoninstitute.ie

F.A Dharejo is with CNIC, University of Chinese Academy of Sciences,

Beijing, 100190, China. E-mail: fayazdharejo@cnic.cn

S.A. Khowaja is with Faculty of Engineering and Technology, University

of Sindh, Jamshoro, Pakistan. E-mail: sandar.ali@usindh.edu.pk

K. Dev is associated with the Department of Computer science, Munster
Intelligent Systems,

Technological University,
University of Johannesburg, South Africa. E-mail: kapal.dev@ieee.org

Ireland and Institute of

N. M. F. Qureshi is associated with the Department of Computer Education,

Sungkyunkwan University, Seoul, South Korea. E-mail: faseeh@skku.edu

Paolo Bellavista is associated with the Department of Computer
Science and Engineering, University of Bologna, 40136 Bologna, Italy.
E-mail:paolo.bellavista@unibo.it

1Note that important acronyms are deﬁned in Table. I

interact in a fully immersive manner [1]–[4]. According to a
recent survey2, the majority of technology experts believe that
by 2040 the Metaverse will be more reﬁned and seamless in
its operation so that people around the world will be able to
fully engage in its full immersion capabilities as an integral
part of their daily lives. In essence, Metaverse is anticipated
to integrate all essential aspects of cyberspace or the world
wide web, such as B5G/6G, cloud and edge computing, social
media, online gaming, augmented reality (AR), virtual reality
(VR), cryptocurrencies, and artiﬁcial intelligence (AI)/machine
learning (ML)/deep learning (DL) platforms and applications,
to allow users to interact virtually [1], [5]–[8].

Some of the early stage applications of Metaverse, namely
Roblox3, VRChat4, Zepeto5 or Second Life6 have been
allowing users to live in “different” or simulated lives, such
as making friends and socializing with new avatars. These
platforms have incorporated AR, VR and MR as a few
elements of the Metaverse. The VR technology replaces the
real world around users with a computer-generated digital
scene using various software and communication devices, such
as a head-mounted display (HMD). While in AR, the virtual
world is seamlessly connected with the real world in order to
create new interactive experiences. Finally, MR emerges as the
combination of AR and VR and their underlying technologies.
It is also noteworthy to mention that the popularity of these
technologies has led to the universal availability of AR
and VR equipment at reasonable prices while continually
improving the quality of experience (QoE) for their users [9].
However, in order to achieve the processing power and
communication speed that are required by VR services to
deliver smooth and immersive experiences, most HMDs still
require the users to be tethered to a PC or gaming console.
The only device to break free from this cable constraint is
Meta’s Oculus Quest 27. Over the next few years, a number
improvements will be made to visual content and the
of
untethered experience of mobile devices as processors get
faster and wireless communication technologies to become
latency-free. In particular, with the existence of 5G, there will
be a proliferation of devices connected to the network, which
will have a profound impact on the growth of Metaverse [10].
5G has enabled real-time communication and information
exchange among all of the connected devices with its low
latency. It is evident that 5G offers faster speeds than 4G, but

2https://www.pewresearch.org/internet/2022/06/30/the-Metaverse-in-2040/
3https://www.roblox.com/
4https://hello.vrchat.com/
5https://zepeto.me/
6https://secondlife.com/
7https://store.facebook.com/ie/quest/products/quest-2/

 
 
 
 
 
 
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

2

such applications

inconsiderable for

most importantly, it offers a variety of other beneﬁts that go
beyond speed alone [11]. Speciﬁcally, Metaverse developers
will be able to beneﬁt from 5G’s low latency by creating
applications that can transmit 360◦ content in near real-time.
Metaverse will also proliferate the trend of human-
centric/data-centric intelligent systems. This trend poses a
number of constraints on existing 5G communication systems,
making them less efﬁcient and unreliable. For example,
considering the 0.1ms delay requirements of haptic-based
Metaverse applications such as teleportation or teleoperations,
5G can only provide the air interface latency of <1ms, which
[12]–[15].
becomes
Moreover, according to Cisco [16], mobile data trafﬁc has
grown 17-fold over the past ﬁve years and is expected to
continue to grow. In particular, as of 2022, the 5G trafﬁc will
comprise 12% of the total mobile trafﬁc in the world. 5G
networks were designed to be able to cover large areas of the
spectrum, such as millimeter-waves (up to 300 GHz), and as a
result, can handle large quantities of wireless trafﬁc [17]–[20].
Since Metaverse will bring several applications that may re-
quire data rates that are higher than Tbps, which is not likely to
be the case with mmWave systems, such as holographic telep-
resence (HT), haptic sensory communications, brain-computer
interface (BCI), and XR [21]–[23]. As a result, researchers
have resorted to exploring the Terahertz (THz) frequency band
(0.1-10 THz) in order to achieve the objectives of Tbps data
rates. 6G communication system is expected to provide 1Tbps
of data rates, operating at 3Thz of bandwidth in order to
support data-intensive applications such as online gaming, live
streaming of high deﬁnition videos, the transmission of holo-
graphic content, and real-time avatar interactions [24]–[27].
6G will also provide ubiquitous coverage and ultra-low latency
(less than 1ms) as well as support around 100 km/hour mobil-
ity by integrating the space-air-ground-sea networks [28]–[30].
Nevertheless, Metaverse applications such as virtual edu-
cation and training, precise navigation and localization, im-
mersive gaming, and remote healthcare applications would
all be enabled by AI and 6G, making the Metaverse more
successful. In particular, state-of-the-art in computer vision can
be utilized to provide animated 3D human models or realistic
animated faces, and even for the creation of holograms [31]–
[33]. However, the key challenge in utilizing the 3D content
for Metaverse services lies in the scalability of the existing
infrastructure. Therefore, the rise of Metaverse makes it crucial
to develop the key tools and infrastructure to enable Metaverse
developers to build better and more scalable 3D/AR/VR ex-
periences, regardless of platforms or purposes. In principle,
researchers need to take a leap from the supervised learning
paradigm of AI and resort to diversiﬁed learning strategies
such as reinforcement learning and self-supervised learning
in order to scale in a Metaverse environment. Moreover, the
edge computing capabilities of 6G networks can be combined
with the AI to provide edge intelligence, hence reducing the
network delays and privacy issues for enhanced QoE in Meta-
verse [34]. Motivated by the existing technologies and foreseen
challenges, we survey the state-of-the-art in AI and 6G in the
context of Metaverse to answer the following question: how
to provide a better and sustainable Metaverse experience by
leveraging the ongoing progress in AI, 6G, and the nexus of
both? In the following subsections, we review the related sur-
veys and outline the contribution and structure of this survey.

TABLE I
LIST OF IMPORTANT ACRONYMS

Acronym

Deﬁnition

ICT
AI
6G
B5G
KPI
NIB
SDN
NFV
O-RAN
3GPP
AI
LTE
CPS
DT
IIoT
UAVs
mMIMO
THz and mmWave
RIS
IoT
mLLMTC
UmMTC
eRLLC
eMBB
MEC
HCI
HT
GPUs
HMD
FoV
FPS
SAGSIN
QoS and QoE
GBs and GHz
HDR
AIInfra
AIInt
AICont
AIVWorld
AIART-E
SocialAI
PersonalizedAI
GPT
GauGAN
GPT
ML
DL
FL
RSI
NLP
FCC
HEMTs
AR
VR
XR

Information and Communications Technology
Artiﬁcial Intelligence
Sixth-Generation
Beyond 5G
Key Performance Indicator
Network-in-Box
Software-deﬁned Networking
Network Functions Virtualization
Open Radio Access Networks
3rd Generation Partnership Project
Artiﬁcial Intelligence
Long Term Evolution
Cyber-Physical Systems
Digital Twin
Industrial Internet-of-Things
Unmanned Aerial Vehicles
Massive Multiple-Input and Multiple-Output
Terahertz and Millimeter Wave
Reﬂecting Intelligent Surfaces
Internet of Things
Massive Low Latency Machine Type Communication
Ultra-massive Machine Type Communication
Extremely Reliable and Low Latency Communications
Enhanced Mobile Broadband
Multi-access Edge Computing
Hyper-computer Interface
Holographic Telepresence
Graphical Processing Units
Head-mounted Display
Field of View
Frames per second
Space-air-ground-sea Integrated Network
Quality-of-Services and Quality-of-Experiences
Gigabytes and Gigahertz
High Dynamic Range
AI-based Infrastructure
AI-based Interfaces
AI-based Smart Contracts
AI-based virtual worlds
AI-based Art for economic enrichment
Improved social network experience with AI
AI for personalized immersive experience
Generative Pre-Trained Transformer
Paul Gauguin Generative Adversarial Networks
Generative Pre-trained Transformer
Machine Learning
Deep Learning
Federated Learning
Real Super Intelligence
Natural Language Processing
Federal Communications Commission
High-electron-Mobility Transistors
Augmented Reality
Virtual Reality
Extended Reality

A. Related surveys

technology,

the potential

In this subsection, we review the state-of-the-art surveys
conducted on several technologies in the context of Metaverse.
Recently, there has been many surveys and research studies
conducted to investigate
its
implementation, applications, and future research directions
[1]–[4], [6], [10], [30], [35]–[42]. For example, Yang et al.,
[35] investigate the integrated role of AI and Blockchain for
the Metaverse environments. In particular, authors in [35]
propose that Metaverse is a 3D virtual reality platform that
covers all aspects of social and economic activities and allows
everyone to participate in these activities in a safe and free
environment that transcends the limitations of our real world
by making use of AI and blockchain technology. Similarly, [2]
surveys the security and privacy concerns for Metaverse users
and proposes potential directions to provide secure services to
Metaverse users. On the other hand, researchers in [3], [36],
[37] investigate the role of AI in the Metaverse. In particular,
[3] surveys the existing state-of-the-art in AI, computer vision,
and deep learning in the context of Metaverse, while [36] and
[37] explore the role of edge intelligence and 6G-powered edge

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

3

TABLE II
SUMMARY AND CATEGORIZATION OF THE REVIEWED STUDIES CONCERNING METAVERSE

g
n
i
t
u
p
m
o
C

l
a
i
t
a
p
S

,

R
X

,

R
V

,

R
A

L

M

(cid:51)

(cid:51)

L

L

(cid:51)

L

(cid:51)

L

(cid:51)

L

(cid:51)

(cid:51)

(cid:51)

e
r
u
t
c
e
t
i
h
c
r
A

e
s
r
e
v
a
t
e

M
d
e
r
e
y
a
L

(cid:55)

(cid:55)

(cid:55)

(cid:51)

(cid:55)

L

(cid:55)

L

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

M

L

s
r
e
b
m
u
N

e
c
n
e
r
e
f
e
R

[35]

[36]

[37]

[10]

[1]

[38]

[39]

[40]

[41]

[30]

[6]

[42]

[2]

[3]

[4]

s

m
g
i
d
a
r
a
P

g
n
i
n
r
a
e
L

d
n
a

n
o
i
s
i
V

r
e
t
u
p
m
o
C

(cid:51)

L

(cid:51)

M

L

L

(cid:55)

L

(cid:51)

L

L

L

M

(cid:51)

(cid:51)

z
H
T

,
e
v
a

W
m
m

,

C
E
M

,

G
6
/
G
5

(cid:55)

(cid:51)

L

(cid:51)

(cid:51)

(cid:51)

L

(cid:51)

L

M

L

L

L

M

(cid:55)

s
k
r
o
w
t
e
N
G
6

r
o
f

I
A

(cid:55)

(cid:55)

(cid:51)

M

(cid:55)

L

(cid:55)

L

(cid:51)

L

(cid:55)

I
A

r
o
f

s
k
r
o
w
t
e
n
G
6

(cid:55)

(cid:55)

L

(cid:51)

(cid:51)

(cid:51)

L

(cid:51)

L

(cid:51)

(cid:55)

M

M

(cid:55)

L

(cid:55)

(cid:55)

L

(cid:55)

y
t
i
l
i
b
a
n
i
a
t
s
u
S

M

L

L

L

L

(cid:55)

L

(cid:55)

L

(cid:55)

L

(cid:55)

M

M

L

s
o
m
e
D
&

s
t
c
e
j
o
r
P

,
s
k
r
o
w
e
m
a
r
F

(cid:55)

L

M

L

L

L

L

(cid:55)

M

(cid:55)

(cid:51)

(cid:55)

(cid:51)

L

(cid:51)

s
e
s
a
c
e
s
U

d
n
a

s
n
o
i
t
a
c
i
l
p
p
A

(cid:55)

(cid:51)

(cid:51)

L

M

M

(cid:51)

M

(cid:51)

(cid:55)

L

(cid:55)

(cid:51)

(cid:51)

M

d
e
n
r
a
e
L

s
n
o
s
s
e
L
&

,
s
n
o
i
t
c
e
r
i
D

h
c
r
a
e
s
e
R

,
s
e
g
n
e
l
l
a
h
C

M

(cid:51)

M

(cid:51)

L

M

(cid:51)

L

M

(cid:51)

(cid:51)

(cid:55)

(cid:51)

(cid:51)

M

Authors & Year

Yang et al.,
2022
Wang et al.,
2022
Huynh et al.,
2022
Lim et al.,
2022
Khan et al.,
2022
Chang et al.,
2022
Jagatheesaperumal et al.,
2022
Dhelim et al.,
2022
Park et al.,
2022
Tang et al.,
2022
Gadekallu et al.,
2022
Mozumder et al.,
2022
Ning et al.,
2021
Lee et al.,
2021
Lee et al.,
2021

Our Article

—

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

Remarks
(Relevance with Metaverse)

Integration of Blockchain and AI for Metaverse

Security and Privacy for Metaverse

Artiﬁcial Intelligence for Metaverse

Edge Intelligence for Metaverse

Wireless Architectures for Metaverse

6G-powered Edge AI for Metaverse

XR and IoE for Education in Metaverse

Mobile Edge Computing for Metaverse

User interactions, Implementations, and Applications in Metaverse

URLLC, Digital Twins, and SAGSIN for Metaverse

Blockchain Technology for Metaverse

Technology Roadmap for Healthcare in Metaverse

Social Value and Technology convergence in Metaverse

Technological Ecosystem for Metaverse

Digital Artworks for Metaverse
This survey investigates the underlying technologies of AI and 6G, such as advancements in computer vision,
learning paradigms, and wireless communication technologies in the context of Metaverse.
The joint role of AI and 6G in obtaining ubiquitous intelligence, tactile feedbacks,
and self-optimising capabilities for Metaverse is explored.
The sustainability aspect of Metaverse followed by the applications, usecases, and on-going projects is given
Lastly, numerous open issues, future directions, and lessons learned are enlightened for
potential researchers and developers of Metaverse applications and services.

(cid:51) High Coverage

M Medium Coverage

L

Low Coverage

(cid:55)

Absent/Unavailable

AI for Metaverse, respectively. In contrast, authors in [1], [30],
[39], [40] scrutinize the wireless communication architectures
and technologies in support of Metaverse. For instance, [30]
reviews the advancements in ultra reliable and low latency
twins, and SAGSIN for
communication (uRLLC), digital
providing ubiquitous intelligence in Metaverse, while [40]
and [39] provides the overview of Mobile Edge Computing
(MEC) and Internet of Everything (IoE)
for Metaverse.
Different from above studies, authors in [2]–[4], [41], [42]
provide the overview of societal, economical, technological,
and digital value in Metaverse applications. In Table II, we
compare and contrast
the above-discussed state-of-the-art
with this article in terms of different aspects of Metaverse.

B. Contribution and Structure of this survey

It

is clear from the above discussion that some of the
existing surveys have focused on very narrow perspectives
technologies, while others have
of AI, 6G, and relevant
investigated the role of the Metaverse in terms of societal,
economic, and digital value. As opposed to them, in this
review, we provide the following key contributions:
• We describe the underlying components of Metaverse, i.e.,
VR, MR, AR, and Spatial computing. The fundamentals of

the aforementioned technologies are presented to provide
readers with an understanding of technical aspects and
state-of-the-art, leading to a fully immersive Metaverse.
• We present an extensive review of the state-of-the-art in
AI and examine the role of AI in realizing the Metaverse
with an aim to extract communication requirements for
6G in Metaverse. Essentially, we deﬁne the role of AI
in the layered architecture of Metaverse, followed by the
learning
state-of-the-art
paradigms and Edge AI for Metaverse.

in computer vision applications,

• We explain the role of B5G/6G in realizing Metaverse by
ﬁrstly answering the following key questions: i) is B5G/6G
need of an hour? and ii) what services B5G/6G can bring
to Metaverse? Next, we review the state-of-the-art for
immersive experiences and holographic telepresence over
wireless by exclusively considering the role of 5G-NR,
URLLC, mmWave, MEC, THzComms, and their interplay.
• We also consider the integrated role of AI and 6G towards
realization of the Metaverse. In principle, we examine
the potential of AI for 6G networks and 6G networks
for AI
in support of Metaverse. Next, we investigate
the
the sustainability of Metaverse in the context of
followed by the potential
aforementioned technologies,

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

4

applications and usecases and ongoing projects. Lastly, we
present the challenges and future research directions along
with the lessons learned from this survey.

the article is organized as follows. Section
The rest of
II
includes the background and technical aspects of all
relevant technologies, including AI, 6G, VR, MR, AR, and
Spatial computing. Section III presents the role of AI in the
Metaverse, while Section IV covers the role of B5G/6G in the
Metaverse. Section V highlights the integrated role of AI and
6G in the context of Metaverse, followed by the sustainability
perspective of Metaverse in Section VI. Applications and
followed by the
Usecases are explored in Section VII,
description of projects in Section VIII. Challenges and future
research directions are entailed in Section IX, while Section
X presents the lessons learned from this survey. Finally,
Section XI concludes the survey. In Figure 1, we present our
paper’s complete pictorial structure.

II. AI AND 6G
FOR METAVERSE: BACKGROUND AND TECHNICAL ASPECTS
This section of the article will provide a detailed account
of the background on the metaverse from the point of view
of technical analysis. The term “Metaverse” is a combination
of the preﬁx “meta” (meaning “beyond”) and the sufﬁx
“verse” (short for “universe”). As a result,
it refers to a
universe beyond the physical world. This “universe beyond”
alludes to a computer-generated environment
instead of
metaphysical or mystical notions of domains beyond the
physical reality [43]. Metaverses are fully immersive three-
dimensional digital environments, as opposed to cyberspace,
which refers to all online spaces. We provide a critical
evaluation of AI and the Metaverse in this section and some
essential prerequisites for understanding the Metaverse 6G
prospects [44]. This comprehensive overview will cover the
fundamental algorithms, terminology, and current and future
product applications. We take a brief introduction to AI, which
constructed a sophisticated black-box for high-level tasks such
as detection and classiﬁcation. The Metaverse role is then
conducted to investigate what the Metaverse requires of AI
key stakeholders for more trustworthy communications [45].

A. The background of AI for Metaverse

This secction explain the background of metaverse. The
metaverse incorporates numerous technologies such as 3D
animation, VR, AR, spatial computing, blockchain, and many
more hot technologies [46], [47]. It is the next technological
future from a socioeconomic standpoint. Many enterprises
have already devoted signiﬁcant
resources to Metaverse
initiatives to give new digital services to the globe and be
the ﬁrst to deliver metaverse landscapes. Why do we say
metaverse is the hottest
technological and socioeconomic
topic right now? Take the example of Facebook, which
changed its name to Meta from Facebook, demonstrating that
the metaverse will be the next big mainstream technology
for industries. The future of Internet in metaverse will be a
large-scaled, resilient, dynamic, and platform for socializing,
trading,
transferring data, and entertaining people in real-
time. Hitherto, a lot of effort was made on Web1 and Web2
[48]. Web1 was guided on browsing plain online pages,
whereas Web2 explained how to connect to social platforms

within controlled ecosystems. In the metaverse, NFTs will
take the place of digital ownership in an open, decentralized
environment [49]. This will enable people to link digitally with
the rest of the world and generate a healthy economy in which
people can execute any work that can be performed in the
physical world. Much has been said about the Internet and its
future, but it is vital to distinguish between the metaverse and
Web3. Web3 is about applying advanced digital services, but
instead of being controlled by large technology corporations
as in Web2,
these services will be created and governed
by the community, returning to the ethos of Web1, when
the Internet’s value was generated by users at the network’s
edge, predominantly in a forward mode. Virtual worlds,
massive scalability, persistence, synchronicity, a functional
economy, openness and decentralization,
interoperability,
and so on should all be included in a Metaverse platform
[45]. The metaverse begins to make artiﬁcial
intelligence
(AI) more ubiquitous in reality, which will power numerous
metaverse technology layers such as spatial computing, artist
scaffolding, and new emerging types of storytelling. We have
seen that AI is advancing at a comparable level, such as
transformers;
transformers are neural networks that allow
machines to interact with natural language, and the graph
below shows the exponential expansion of deep learning
transformers [50] [51]. In Figure 2, we show how Growth of
Deep Leaning Transformers from 2018 to 2021.

Consider the following transformers: the Generative Pre-
trained Transformer (GPT) dealt with 110 million parameters;
the newest Google Brain transformer dealt with over 1 trillion
parameters. GPT-4 will most
likely have far more. This
suggests that
the volume of DNN networks will continue
to grow in the future. With the advancement of neural
networks, AI has already achieved a lot of success in voice
recognition in Alexa, Tesla’s autonomous driving system,
Google image recognition, and a few algorithms that elicit
reactions from social media and deep fakes; however, all of
these applications are just basic in comparison to AI’s future
applications [50] [52]. The Metaverse is not in the future; it
is a transformation from being to becoming.

it

the

contains

shared virtual

The Metaverse is where the physical and digital worlds
intersect;
environment,
AR glasses, headgear devices, and Oculus VR headsets.
These can be accessed over the Internet via smartphones and
wristband technology. People will play, learn, create, shop, and
communicate with friends in a virtual, online world. Today, the
Metaverse is emerging as metaphysics, or, as we might say, the
transformation of the universe. In the past two years, we have
seen that with the covid epidemic, digital technologies shift
their waves quickly, and it has been in the past as well. The
1980s saw the rise of computers, the 1990s saw the rise of the
Internet, the 2000s saw the rise of mobile Internet, the 2010s
saw the rise of AI/ML/DL/Data alaytics [53], and the 2020s
saw the rise of true AI/Trans-AI/Meta-AI. The Metaverse,
transverse, or omniverse could be the next wave. The waves
are now merging, such as the Internet on PCs, the Internet on
mobile devices, and AI/ML on the mobile Internet. The Meta-
verse will demand the Internet, mobile devices, and REAL AI.
A Metaverse contains simulated AR, VR, MR [54]–[60], a 3D
World Wide Web, and other forms of digital twins, including
digital humans as intelligent avatars. Metaverse will function
as a real-time digital environment containing all feasible

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

5

Fig. 1. Structure of this survey

entities, occurrences, activities, and interactions. Currently,
trillions of dollars are being invested in Metaverse projects
like AI-driven digital reality to offer a digital infrastructure
that can accommodate all of its social media networks,
e-commerce, and big tech oligopoly [61]. We risk creating a
Matrix-like Metaverse of digitized humans and superintelligent

agents as a virtual world where young people can transcend
the meaningless reality of the real world in which they live.
The Metaverse is a virtual reality that integrates all essential
aspects of cyberspace or the world wide web, such as cloud
and edge computing, social media, online gaming, augmented
reality (AR), virtual reality (VR) [54], [55], cryptocurrencies

This Survey  Chapter I:  Introduction  Backgrounds, Concepts, Benefits, Challenges and Motivations Chapter II: AI and 6G for Metaverse: Background and Technical AspectsA. The background of AI for MetaverseChapter III: Role of AI in MetaverseA. Learning Paradigms for MetaverseChapter IV: Role of B5G/6G in MetaverseA. B5G/6G need of an HourChapter V: Nexus of AI and 6G for MetaverseA. 6G-driven Pervasive AI for Metaverse Chapter VI: Sustainable MetaverseA. Virtual Resources in MetaverseChapter VII: Applications and UsecasesA. What Are the Use Cases of the MetaverseChapter VIII: ProjectsA. Decentraland              Chapter IX: Challenges and Future Research DirectionsA. Role of AI in MetaverseChapter X: Lessons LearnedA. Art and Immersive ExperienceChapter XI: ConclusionB. Spatial Computing D. AR/VR/MR Deployments on 5G/6GC. Background of B5G/6GB. Computer Vision in MetaverseC. Edge AI for MetaverseB. What B5G/6G brings to Metaverse?D. Holographic Telepresence in MetaverseC. Immersive Experiences over WirelessB. AI and 6G for Tactile Internet in MetaverseC. AI-led Autonomous 6G Networks for MetaverseB. Travelling through MetaverseC. Digital Twins and MetaverseD. Penetrating psychological barriers through MetaverseE. Social Sustainability with MetaverseB. UscasesC. Benefits of MetaverseD. Metaverse Market: State of the ArtB. OculusC. Enjin                       D. SilksE. HighstreetF. MetaheroG. XR initiative            H. SilksB. Role of B5G/6G in MetaverseC.Integrated Role of AI and 6G in Metaverse D. Sustainable MetaverseB. Circular EconomyC. Sustainability in MetaverseD. Layered Security in MetaverseJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

6

intelligence information, evolve, and continue to perpetuate.
With AI, DL, and ML, the Metaverse can achieve Real Super
it can function as
Intelligence (RSI), demonstrating that
advanced man-machine intelligence. The Metaverse will be
enabled, ﬁlled, and sustained by the most sophisticated man-
machine intellect, the RSI, rather than the narrow and weak AI
and ML [63]. It will power all seven Metaverse technological
layers, including spatial computing, creator scaffolding, and
new and complex types of narrative. We envision the role of
DL and ML in the Metaverse in the broader context.

1) Deep learning in Metaverse: Deep learning algorithms
(DL) have gained signiﬁcant popularity due to their accuracy
and efﬁciency in a variety of computer vision applications,
such as extracting 2D human pose information from RGB
camera data [64]–[66] or 3D human pose information from
RGB-D sensor data [67]–[69]. Among SoTA 2D pose tracking
approaches in the Metaverse, OpenPose [65] has been widely
used by scientists to track user postures in various virtual
contexts, such as VR [56], [57], AR [58]–[60], and Metaverse
[70]. Furthermore, 3D pose tracking, FingerTrack [69], has
a great potential for XR applications and the Metaverse
in tracking and the hand position estimation approach. As
we have seen, multi-person tracking is more complex than
single-person tracking; yet,
the tracking algorithm must
count the number of users and their positions and classify
them [64]. The Metaverse environment mandates using both
single-person and multi-person body posture monitoring
techniques. The algorithms designed must be resilient and
efﬁcient to ensure strong connections between the Metaverse,
the physical world, and people.

B. Spatial Computing

Spatial computing is the digitalization of machine, human,
and object activities and the locations in which they occur
to facilitate and improve actions and interactions. Spatial
computing is the seamless integration of three technologies:
augmented reality (AR), virtual reality (VR), and mixed reality
(MR) in a three-dimensional world [71] [72]. This technology
can digitally revolutionize how industrial organizations opti-
mize operations for front-line workers in factories, work areas,
and logistics. Spatial computing technology is analogous to the
commonwealth of the physical and digital worlds. This means
that almost all people no longer interact with computers in
the fashion that an impartial observer should; conversely, they
choose to encounter what it is really like to be in the digital
domain by associating with elements that only reside in it. In
contrast to traditional computing, which is predominantly two-
dimensional, spatial computing allows users to think out of the
box and communicate with gadgets from above the screen.
The innumerable devices are already on the marketplace for
spatial computing. Here are a few examples: VR Headsets,
AR Glasses, and Hybrid Gear are all examples of cutting-
edge technology [73]. Whereas VR headsets enable visitors to
explore being a part of a virtual universe, AR Glasses allow in-
dividuals to go greater depth into the digital space, and Hybrid
Gear combines VR, AR, and MR technology. Since the user
may fully integrate their senses, this program enables them to
enjoy a cinematic experience. In the past, gamers adopted VR
headsets to interact with video game items and avatars. Their
application has recently expanded to encompass additional

Fig. 2. Growth of Deep Learning Transformers from 2018 to 2021

Fig. 3. Application and infrastructure-level machine learning and deep
learning techniques for 6G.

[62], and AI/ML/DL platforms [53] and applications, to allow
users to interact virtually. Everything we use anyway, such as
video conferencing, games, email, mixed reality, e-commerce,
social media, and Netﬂix/YT live-streaming, are all part of the
Metaverse. For many MMOG gamers, the Metaverse, deﬁned
as the Internet ﬁlled with mixed, virtual, and augmented
worlds, is more real than any physical reality. It is as real
as its technological solutions, which include social media,
virtual virtual world games, extended reality, simulation and
modeling, human-computer interaction, digital twin, machine
learning and reasoning, data analytics, computer vision, edge
and cloud computing, and mobile networks, all of which are
powered by true AI Metaverse technology. Using machine
learning and deep learning, we have demonstrated the detailed
involvement of the metaverse in 6G technologies in Figure 3.
Building the Metaverse as a Global AI Platform: Based
on the data presented above, it is evident that the Metaverse
will prevail in the coming years due to its immense potential
for success as a global AI computing system. Breakthroughs
in the Metaverse are expected in the future,
including
several
technological developments, protocols, companies,
and scientiﬁc points of view. To advance in the Metaverse
context, one must establish Metaverse infrastructures and then
create a set of standard rules and protocols to load valuable

1000105.01000.01.0Jun-2018Dec-2018Jun-2019Dec-2019Jun-2020Dec-2020Jun-2021Jun-2021Deep Learning Transformer GrowthGPTGoogle BertLarge  GPT-3NVEDIA Megatron  LM Microsoft Turing NLG GPT-2GoogleBrain GPT-4Number of parameters  ×109Transformation with Period 2018 to 2021AI-6G at Metaverse  End to End Communication Devices Dependencies Synergy Management  Machine Learning  Unsubstantiated learning Supervised  learning Unsupervised  learning Semi-Supervised  learning Reinforcement  learning Clustering Load Balancing  User Inference   6G wireless Communication System  Security  Network Capacity   Latency   Throughput   Power Allocation   Energy Efficiency    Deep Learning  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

7

Fig. 4. Metaverse refers to tranformation of physical reality into the digital realm, so it could be a mix of physical reality and digital realm such as AR,
VR, and MR.

applications such as training and modeling. AR Glasses are
gadgets that project data and visuals and are particularly ben-
eﬁcial in industrial workplaces. Google Glass and Microsoft
HoloLens are two special AR glasses on the market right
now. FellReal’s multi-sensory mask is an excellent example
of such technology. While such merchandise is still in the
works, major tech corporations like Samsung, Google, Apple,
and Microsoft invest in startups to create cutting-edge hybrid
tools and equipment. By showing how the physical world will
be transformed into the digital world via the rise of Metaverse,
we demonstrate in Figure 4 how technologies such as enabling
technologies will play a signiﬁcant role. The ultimate advan-
tage of spatial computing is the ability to interact with digital
objects. It provides extra privileges that we could only dream
of aeons ago but are now a “spatial” reality [74].

1) Virtual Reality (VR): Virtual

reality is deﬁned as
computer technologies to construct space that can be explored
in 360◦ (VR). Unlike traditional technologies, virtual reality
(VR) plunges the user in a virtual world to give an interactive
experience [75]. It has been revealed that virtual reality has
the most conspicuous characteristics of completely synthetic
vistas. Commercial VR removes
real-world vision and
provides video to each eye, allowing for depth of view [76].
It is a virtual environment in which the user is fully immersed
and is interacting with real items via interactive techniques
via the Internet. This technology is augmented with head

and body tracking to link the virtual environment to the user
is viewing. Furthermore, VR is described as the “farthest
end from reality in the Reality-Virtuality Horizon” [77]. In a
VR environment, users can produce their own content, such
as VR painting,
to devote their complete attention to the
virtual worlds, which are distinct from the real environments
[78]. Interacting with virtual entities in a virtual space can
in discovering user accessibility, such as changing
assist
the scene’s shape and adding new tasks. The collaboration
between multiple users in virtual space can therefore occur
in real-time, which aligns with well-deﬁned requirements
for virtual environments, including a sense of location, time,
and availability, gestures,
texts, and voice communication,
and information sharing [79]. Furthermore, Virtual Reality
expands democratization and permits more humans to engage
with digitization. For example, Google’s Tilt Brush5 enables
customers to create unique artworks using VR goggles.
The link between new and classic arts technologies is not
unidirectional;
they can live harmoniously. When
contemplating the Metaverse, users should locate themselves
in their own shared spaces while interacting with the physical
analogue, such as AR and MR. The goal of the Metaverse
is to create multiple shared spaces in which to undertake
concurrent activities among existing objects, avatars, and their
relationships, for example, Object-to-object, object-to-avatar,
and avatar-to-avatar interactions. To represent the events of

instead,

•Scenereconstruction•Objectdetection•Eventdetection•Videotracking•Objectrecognition•3Dposeestimation•Motionestimation•Visualservoing•3Dscenemodeling•ImagerestorationComputer VisionsInternet of Things•Wearable•EdgeComputing•Cloudcomputing•BlockChain•Drones•NFC•Smartfarming•SmartCity•E-Govern.•Intelligentsensing•BelkinWeMo•Canary5G/B5G/6G•MBRLLC•mURLLC.•HCS.•MPS.•PervasiveAI•BlockchianandDLS.•CRAS.•UAV/Satellitecommunication•Quantumcommunication•AssistiveTechnology•AmbientBackscater•Autonomousvehicles•Decentralizedbusiness•Machinelearning•Deeplearning•Machinevision•NLP•AutomationandRobotics•Reinforcementlearning•SuperviseandunsupervisedlearningArtificial Intelligence •AugmentedReality(AR)•VirtualReality(VR)•MixedReality•XRandBCIequipment.•Audio-VisualTechnology.•AR/VRheadsets•spatialunderstanding•Optimizedesignandoperations•Superrobust,flexible,responsive•Modes:Worldspacevs.Userspacevs.ObjectanchoringSpatial Computing Physical WorldEnabling Technologies Digital World (Metaverse) JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

8

Fig. 5. Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR), explored in depth.

the virtual spaces, all users who participate in the virtual
environment must synchronize [80]. However, synchronizing
dynamic events at scale is a large problem because unlimited
users can simultaneously together act on virtual objects and
interact with one other without reasonable latency, which
might be detrimental to users. VR in the Metaverse seems
to be a more advancing technology that may be deployed for
various purposes, such as classrooms, to help teach a subject
or topic by allowing students to ’experience’ the knowledge.

2) Augmented Reality (AR): Digital visual elements, music,
or other sensory stimuli are used in augmented reality (AR)
to enhance the physical world. Commercial apps and mobile
computing companies are embracing it. Augmented reality

(AR) goes beyond virtual worlds to improve our physical
surroundings through different experiences. Audio, images,
taste, and touch are all possible perceptual input channels
for computer-generated virtual elements [81]–[83]. Digital
toppings are projected on top of our physical environments
using the ﬁrst generation of AR system frameworks. Users’
participation with digital entities has been studied extensively
is worth noting that digital entities are
in AR so far. It
superimposed on top of the user’s physical surroundings,
allowing users to perform many actions at once, similar to VR.
Interactions with such digital entities in AR are difﬁcult and
intended to connect people between the physical world and the
Metaverse [83]. The majority of science ﬁction ﬁlms use urban

Virtual or Computer simulated environment  Fully immersive senses controlled by systemBlock of real environment-RequiresHeadset or handheld controllerHigh quality displaySignificant $Examples: VR headset Oculus Rift (3D, 360 Degree views)RisksDepersonalizationCyber/motion sicknessAccidents (eg., tripping, hitting celling fans)Uses: medical, training, education, entertainmentUsers do no aware about real-worldReal and Virtual contents do not interact Users do not interact with real and virtual world in real-timeVirtual and real-time World environment.RequiresLower quality displayLess cost verse VRSignificant $Examples:  APPs(i.e., Pokémon Go), pop out 3D emails, holograms, Google glass, 3D video games, Microsoft HoloLensRisksLack of focus or impaired perceptionSecurity and privacyStress/overloadUses: marketing, tourism, design, navigation, education, entertainmentActive or passivePersonal vs. collectiveUsers aware about real-world Real and Virtual contents do not interact Users interact with real and virtual world in real-timeReal and Virtual WorldCombines VR and ARMore complex and nuanced apps (eg., high-spec sensors scan a user’s environment and recreate for haptic interfacing).RequiresHeadset  EquipmentSignificant $Examples: Microsoft HoloLens, holograms-RisksSee VR, ARUses: engineering, education, architectures, military, business, manufacturing Users aware about real-world Real and Virtual contents interact Users interact with real and virtual world in real-timeIt uses Audio-Visual Technology.Enables us to perceive 3D digital contentsuch as AR/VR headsetsIt allows us to interact naturally with 3D digital content (such as voice control, eye tracking, hand/body tracking and haptics)Few applications of spatial technologies PTC envisions within the industrial workplaceEnable seamless interactionsClose the loop on performance managementImprove machines’ spatial understandingOptimize design and operationsVirtual Reality (VR)Mixed Reality (MR)Augmented Reality (AR)Spatial Computing JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

9

and peri-urban concepts to present intuitive AR user interfaces
[54]. Like, Voodoo Dolls offered a freehand technique in
which the user can select and work with virtual content using
squeeze motions. Later, HOMER proposed a method [84] that
provides ray-casting from the user’s virtual hand, displays
item selections, and is ﬁnally deceived. Furthermore, AR will
play an important part in our daily lives, such as gaming,
annotating directions in new regions, and locating objects
based on user surroundings [85]. As a result, we can anticipate
that the AR in Metaverse will integrate urban environments,
and digital entities will appear in visible and tangible ways
on top of various physical things in metropolitan places. We
can conclude that AR will facilitate communication between
the physical and virtual worlds in the Metaverse. However,
mapping virtual objects with regard to their corresponding
position in the real environment needs a signiﬁcant amount
of effort for simple actions such as detection and tracking
[86]–[88]. As the ﬁrst research prototype of augmented reality
outdoors, Traveling Machine is considered groundbreaking. A
head-mounted display containing map navigation information
and a GPS device are included in the prototype. Using a
pointer and touch surface, users interact with AR maps [89]. A
recent AR headset, however, has shown great advancements,
particularly in mobility. AR headsets can receive video
and auditory feedback, but other senses remain untapped,
including smell and haptics [90]. Interestingly, AR headsets
are not the only way to view Metaverse content. AR patches,
as well as digital entities from the Metaverse, can be supplied
via a variety of devices, including but not limited to AR
headsets [54], [55], hand-held tablet devices [91], overhead
projectors [92], and tabletops [93], Pico (portable) projectors
[94], and so on. Matter of fact, in terms of switching user
attention and occupying users’ hands, AR headsets have
an advantage over other tactics. The ﬁnest aspect of this
technique is that users must shift their focus between physical
environments and digital material on other sorts of AR
gadgets. AR headsets also allow users to visualize [74], [95],
and the user’s hands will not be burdened by tangible items
functioning as processing elements. These advantages make
AR headsets more immersive in the Metaverse via AR lenses.
Augmented reality continues to evolve and spread across a
wide range of applications.

3) Mixed Reality (MR): A mixed reality (MR) environment
is one in which physical and digital items coexist and interact
in real time in a physical and virtual world. In other words, we
can say that MR is a hybrid of AR and VR technologies [96],
and we will go over the role of MR in the Metaverse further.
There is no formal deﬁnition of MR, but it is imperative to
have a name that describes the alternate reality that exists
between the two poles of AR and VR. While reading the
previous literature, we came across several descriptions of MR,
including a “traditional” notion of MR in Continuum [96], MR
as a generic term for AR [97], MR as a type of liaison [98],
MR as a combo of AR and VR [99], MR as a synchronisation
of environments [93], and a “greater” version of AR [100].
MR is a combination of AR and VR that allows users to
interact with virtual elements in physical environments,
according to the scientiﬁc community. Nowadays, mobile
AR is the most popular mixed reality service on social
media. Mix reality events are created by AR ﬁlters on
Instagram. Microsoft Windows Mixed Reality combines all

user experiences to create holographic portrayals of people,
3D models, and their real environment. In comparison, as seen
in existing applications [90], AR typically shows information
layered on physical locations without regard for compatibility.
Due to the massive aforementioned characteristics of MR, it
is regarded a more powerful version of AR, with collective
linkages to physical spatial, user interaction, and virtual
entities [90],
[101]–[103]. Humans, computers, and the
surroundings can interact naturally and immersively with
mixed reality. The world of computer vision, graphics,
display technologies,
input methods, and cloud computing
has changed dramatically. Sensor and processing power
breakthroughs are resulting in novel computer perceptions of
surroundings based on innovative input modalities. A person’s
body position in the physical world, objects,
surfaces,
lighting and sound, object
and boundaries, environmental
classiﬁcation, and geographical locations can all be captured
via environmental inputs.

C. Background of B5G/6G

To fully utilize the Metaverse, we must have smooth outdoor
mobility enabled by cellular networks such as the 5G and 6G
networks. With the advent of 6G technology, 5G has been
ruled out, but it is still being rolled out to replace the aging
4G standard [104]. As shown in the Table III below, we have
laid out different ways in which enabling technologies play a
key role from 1G to 6G. 6G networks are being developed and
are projected to be speedier, with increased capacity and fewer
latency [105]. It can be seen that 6G networks will encompass
a wide range of capabilities, as well as current mobile applica-
tions such as VR/AR, AI, and the IoT. Mobile network opera-
tors are also predicted to use ﬂexible distributed approaches for
6G, including local spectrum licensing, bandwidth allocation,
and connectivity sharing. Mobile edge computing, short-packet
communication, and blockchain technology would be respon-
sible for all of this. As evidence suggests that new wireless
technologies are released regularly after every ten years, it may
be anticipated that 6 will be in use by 2030. In the future, more
designs and protocols will be launched in 6G. Users will con-
tinue to use more IoT, mobile devices, and similarly use a lot
of data at increasing rates as 6G evolves, indicating the more
theoretical aspects of 6G are predicted to emerge [30], [38].
1) 5G evolution: Although 6G is replacing 5G [106],
however, 5G technologies are still required. Wireless telecom-
munication industries continue to rely on 4G for consumer use,
and 5G is attempting to replace the outdated technology, albeit
gradually, with most deployments taking place in tightly pop-
ulated regions. In 2009, the 4G/LTE [107] standard was intro-
duced, which proved to be a game-changer for mobile devices
by increasing data speed and letting users watch HD movies,
play online games, and exchange enormous amounts of data
at speeds of up to 33 Mbps. 5G [106] outperforms 4G by
using microwave and mmWave technology to boost its speed
to roughly 900 Mbps or more. Faster speeds and capacity are
comparable to commercial broadband providers, offering more
uses beyond streaming media. IoT and edge computing will
have real-time sensing capabilities, which means they will
obtain data instantaneously by leveraging the cloud. In the
healthcare profession, such as medical services, instantaneous
knowledge from patients is required for diagnosis and treat-

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

10

TABLE III
ROLE OF KEY ENABLING TECHNOLOGIES FROM PRE-4G TO 6G

Generations

Pre 4G

4G

5G

6G

Advantages

•

Improve voice clarity

• The network uses the analog signal (1G)
• Consume less battery power
• Data and voice signals are
digitally encrypted
• Fixed and variable data rates
• Asymmetric data rates (3G)

• High speed
• Tight network security
• High usability: anytime, anywhere
and any with technology
• Support for multimedia
services low transmission cost
• Low cost per bit

• Greater speed in the transmissions
• A lower latency
• Greater capacity of remote execution
• A greater number of connected devices
• Possibility of implementing virtual networks
• Your PCs can be controlled by handsets

Disadvantages

• Poor voice quality
• Large phone size
• Poor battery life
• Complex data, such as videos,
could not be handled by the system
• Different handsets are required
• Too little bandwidth
• Consumption of energy is high
• Spectrum license cost
• High expenses of 3G phones
• 3G compatible handset
• Connection rate

Applications

• Voice calling
• SMS

• The battery uses is more
• Hard to implement
• Need complected hardware

•

It required the use of 4G technology

• It is still costly to build a
next-generation network
• The network has more problems
has security issues

• Old devices are unable to handle 5G,
so they must be replaced by new ones
• A costly process
• Developing infrastructure
requires a high price tag
• There is yet to be a resolution to the
privacy and security issues

• HD movies
• Video conferences
• Telephony

•
IoT, Wearable, Smart manufacturing
• Edge computing, Smart farming, AI

• Assistive Technology

•

Immersive AR/VR, Advanced AI

• Autonomous vehicles,
Decentralized business
• A greater number of connected devices
• 6G has a high data rate (Tb/sec)
and a short latency (sub-ms).

• Text messages,Picture messages and MMS
• Wireless voice telephony,
Mobile Internet access, Fixed wireless
Internet access, Video calls, Mobile TV

•

• Text messages, Picture messages and MMS
• Wireless voice telephony,
Mobile Internet access,
Fixed wireless

•

Internet access, Video calls, Mobile TV

• Amended mobile web access,
IP telephony, Gaming Services
• Video conferences
• High deﬁnition mobile TV,
Video conferencing, 3D television

• Amended mobile web access,
IP telephony,
Gaming Services
• Video conferences
• High deﬁnition mobile TV,
Video conferencing, 3D television

• FDMA
• TDMA
• CDMA
• W-CDMA
• GSM, EDGE, UMTS, DECT
• WiMax, CDMA 2000

• ADVANCED LTE, WirelessMAN-Advanced,
IEEE 802.16m, Three-GPP Long Term Evolutions
• WiMAX (IEEE 802.16e) for mobile devices
• China’s TD-LTE network
• The UMB (formerly the EV-DO Rev. C)
• Flash-OFDM

• eMBB
• uRLLC
• mMTC

• eMBB
• uRLLC
• mMTC

• Smartphones
• Sensors
• Drones

• AI-assisted intelligent
connectivity • Depth connection
• The term “holographic connection”
refers to the use of AR/VR to
provide continuous coverage
anywhere
• A ubiquitous connection that
spans space, air, ground, and sea
• By removing time, space and
workﬂow barriers, 6G will transform
the health-care industry

• Multi-connection architecture
and cell-less architecture
are used in 6G. In a cell-less
deployment, UEs are not
connected to a single cell,
but to the RAN. Network
architecture needs to be redesigned
• As part of its
communication, 6G uses visible
light frequencies; therefore,
its drawbacks could be considered
to be those of 6G wireless technology
It is challenging to design communication

protocol stacks for network and
terminal types of equipment

•

• AI-assisted intelligent connectivity
• Depth connection
• The term “holographic connection”
refers to the use of AR/VR to
provide continuous coverage anywhere
• A ubiquitous connection that spans
space, air, ground, and sea
• By removing time, space and
workﬂow barriers, 6G will transform
the health-care industry

• MBRLLC
• mURLLC
• HCS
• MPS

• MBRLLC
• mURLLC
• HCS
• MPS

• MBRLLC
• Sensors and
DLT devices CRAS
• XR and BCI equipment
• Smart implants

2.4 Kbps to 2 Mbps

33.88 Mbps

40 to 1100 Mbps

Up to 1 Tbps

20 to 100 ms

100-1000 ms

10 ms

20-30 ms

5 ms

100 ns

< 1 ms

10 ns

Architecture

Wide Area Network

Hybrid Network

• Denser sub 6 GHz small cells
with umbrella macro base stations
• < 100 m tiny and dense mmWave cells

• High-frequency cell-free smart
surfaces powered by mmWave
tiny cells that can be accessed
by mobile and ﬁxed devices

ment, which can only be accomplished with faster computa-
tions; therefore, 5G has applications in retail and industry. The
list is virtually endless, but we will not see 5G’s entire poten-
tial until the advanced technology is implemented globally.

2) 6G and Internet of Everything: As already mentioned,
6G [105] is still in development and is too early to have
functionality.
accurate information on its technology or
We anticipate that
the telecommunications industry will
use dynamic, decentralized marketing strategies with local
spectrum licensing/sharing and infrastructure sharing in 5G.
6G is fully integrated with Internet-based systems that enable
speedy communication between users, gadgets, automobiles

it

and the surrounding environment [108]. As a result,
is
possible to estimate when we will transition from the Internet
of Things (IoT) to the Internet of Everything (IoET), which
6G could theoretically deliver. The existing ﬁbers can provide
up to 1 Gbps; however, the researchers believe that a 6G
network could provide thousands of times quicker than optical
ﬁbres. The Federal Communications Commission (FCC) has
opened the door to 6G speeds in 2019, enabling ﬁrms to
experiment with terahertz waves in the 95-GHz to 3 THz
spectrum. 5G, on the other hand, uses a low band as low as 24
GHz to 40 GHz, such as mmWave and microwave technology.

Application

Types

Application Types

Device Types

Rate
Requirements

Rate
End-to-End
Delay Requirement

Rate Processing
Delay

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

11

TABLE IV
STATE-OF-THE-ART ON AR/VR/MR IMPLEMENTATIONS IN VARIOUS INDUSTRY VERTICALS ENVISIONED BY 5G AND 6G TECHNOLOGY.

Reference

Years

[111]

[112]

[113]

[114]

[115]

[116]

[38]

2019

2020

2020

2020

2020

2020

2022

Aims and Objectives
IoT and AR/VR are being used in modern industries
to demonstrate how they can survive
Observing how VR, AR, and AR have been
integrated to beneﬁt companies and industries.
To see how blockchain can be
integrated with mobile devices and AR/VR
An observation of blockchain’s convergence with 5G and 6G.
networks for the development of immutable, distributed and smart applications
5G network problems countered by AI

Demonstration of authentication and key protocols for 5G and 6G networks

A metaverse system based on 6G edge intelligence was investigated

[1]

2022

A metaverse vision towards enabling 6G wireless development is presented

Contribution
Analyze the beneﬁts and challenges
of integrating AR with blockchain.
The system has the potential to eliminate
the need for third parties.
The efﬁciency of VR combined
with blockchain technology and augmented reality

Limitation
A hypothetical scenario is considered
rather than a reality scenario

Taxonomy Parameters

BC based AR/VR/MR

There are limited use cases in the scenario

BC based AR/VR/MR

AR is not taken into account

BC based AR/VR/MR

Practical overview and solution of AR/VR

Does not address existing problems with 5G networks

5G/6G enabled AR/VR/MR

Taxonomy for 5G networks at a high level
In blochain applications, various stats
are observed in various situations
The organic integration of edge AI
and metaverse enabled by 6G
Identifying key enablers, such as interactive experience
technologies, avatars, and digital twins and their potential
beneﬁts for wireless systems and mobile services

AI and 5G problems are not discussed

5G/6G enabled AR/VR/MR

Threats to security are not discussed

5G/6G enabled AR/VR/MR

Edge node computing power distribution is imbalanced.

5G/6G enabled AR/VR/MR

Wireless systems that self-conﬁgure only

6G enabled AR/VR/MR

they would be subject

Although terahertz waves could enhance 6G speeds to 1
Tbps,
to the same restrictions as
5G. Using N-Polar gallium nitride high-electron-mobility
researchers from the University of
transistors (HEMTs),
California, Santa Barbara have created a device to speed
up the 6G development process. These HEMETs feature a
junction between two materials with differing bandgaps that
work as a channel instead of the common doped region found
in MOSFETS, allowing the device to operate at signiﬁcantly
higher frequencies (140 to 230 THz), as required by 6G
[109]. As time passes, new advancements in 6G emerge. Last
year, researchers from Singapore’s Nanyang Technological
University and Japan’s Osaka University produced a device
for terahertz waves that could be used for 6G [110]. Engineers
designed millimeter wave products for G-bands that function
in terahertz waves this year. A few tools can help 6G become
a reality and progress beyond the research phase. It may
take the time that 6G becomes increasingly widespread in
real-time applications to roll out 5G progressively.

D. AR/VR/MR Deployments on 5G/6G Networks

Although AR/VR technology has existed for a couple of
years, its scale adoption depends on 5G/6G technology and
edge computing. In order to enable the use cases, 5G/6G
must bring ultra-low latency and high bandwidth. As a result
of private 5G/6G solutions, many industrial and enterprise
customers can carry out mission-critical processes with the
capabilities necessary to accomplish this. While public 5G/6G
networks do not extend adequate coverage, do not deliver a
particular ability to the required level, or are deemed to be
unreliable, private 5G/6G networks provide the capabilities
required for mission-critical applications.

The metaverse proves to have huge potential when it
comes to securing the AR/VR/MR space in the future. It is
designed to allow its users to build a full-featured virtual world
governed by a set of rules without the involvement of platform
developers or the risk of being exposed to their risks. The
second beneﬁt of BC is that it allows copyright protection to
be applied to the content as a user may record it. Finally, BC
can enhance the popularity of VR by merging the market for
cryptocurrencies with VR, resulting in increased proﬁtability
due to the merger. There are several aspects of AR/VR/MR
that could beneﬁt from the use of 6G that are outlined below.
is possible to
• With the advent of 6G networks,
communicate at THz in the submillimetre range with
extremely low latency. As part of 6G, virtualized service
sets simplify holographic communication over physical
boundaries and enhance management capabilities. As a

it

result, 3D imagery can be experienced in real-time (XR)
in conjunction with autonomous driving, etc.

• For data security in AR/VR applications, it is essential to
ensure trusted decentralization among multiple nodes to
ensure massive data-sharing.

• The fast display and processing of images and videos
required by AR/VR assets requires that the data be stored
and exchanged through a local central server due to the
amount of memory and processing required limitations.

applications AR [97],

• Since AR/VR-oriented

[99],
[100] consume a great deal of data and bandwidth; the
central server could become overloaded due to multiple
asynchronous communications among the AR/VR devices.
• For military and battleﬁeld applications that use AR/VR
devices, Blockchain improves cybersecurity through sharing
sensitive data, law enforcement, and public safety.

• By creating a user-deﬁned marketplace for storing and
in the

uploading AR content, Metaverse can assist
commercialization of AR devices.

• In addition to assisting users and developers in downloading
and uploading content, communication can also facilitate the
development of new applications and set up marketplaces
and storefronts for AR/VR/MR devices to make them more
commercially viable.

A summary of recent papers incorporating AR/VR/MR
[97], [99], [100] into 5G/6G networks can be found in
the Table IV.The adoption of AR and VR at scale has yet
to become mainstream. 5G and edge computing can now
overcome some of these challenges. We explore speciﬁc use
cases and real-life applications in sections VII.

III. ROLE OF AI IN METAVERSE

In this section, we present the AI pyramid for Metaverse
technology, followed by methods related to different learning
paradigms, computer vision, and Edge AI. This subsection
also serves as a basis for discussing sustainable metaverse
in Section VI. Post Facebook’s name change to Meta, the
rejuvenation of the Metaverse ﬁeld has been the talk of the
research community. Another reason for inclined interest
towards the Metaverse is its impact on socioeconomic and
technological aspects, such as combining 3D animation, virtual
reality, blockchain, non-fungible tokens, digital economy, and
many others. The non-fungible tokens (NFTs) created a lot of
hype that explained the role of blockchain in the context of the
Metaverse, however, this section will mainly focus on the role
of AI in the said technology. Recently, an article was surfaced,
which explained the concept of the Metaverse in the context

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

12

Fig. 6. Layered Architecture of Metaverse by Jon Radoff. The labels on the right side are original layers deﬁned in ”Building the Metaverse”, while the
labels on the left side exhibit equivalent mapping in the context of AI.

of value chain 8. The article summarized the Metaverse as the
(real-time activity-based Internet) and proposed an abstract
layered architecture for the same. We use the seven-layered
Metaverse architecture as a reference to explain the role of
AI, as shown in Figure 6. We brieﬂy explain the areas and
deﬁne the equivalent AI mapped role in the layered schema to
understand the diversity and advancements that AI brings to
the ﬁeld of Metaverse. This correspondent has already been
performed by David Pereira 9, but this study further elaborates
on the use of AI in each layer, accordingly. We explain each
of the corresponding layers in a bottom-up approach.

AIInfra: It

is apparent

that with increasing popularity,
a large number of users will opt
to use the services
associated with Metaverse. In this regard, the infrastructure
should be capable of accommodating massive machine-type
communication (mMTC) devices along with the support for
executing AI-based models. Furthermore, it should be noted
that the infrastructure is the base for the services being offered
at stacked layers, therefore, the support for temporary storage

8https://medium.com/building-the-Metaverse/the-Metaverse-and-artiﬁcial-

intelligence-ai-577343895411

9https://towardsdatascience.com/how-ai-will-shape-the-Metaverse-

4ea7ae20c99

of data or support for cloud connectivity is also necessary.
For instance, 5G/6G networks already allow support for AI
devices and operations. Similarly, Microelectromechanical
(MEMs) devices enable the wearables to perform automatic
sensing and data collection, and Graphic Processing Units
(GPUs) enable the device to perform faster computations.
Together,
the
necessary infrastructure to perform decision-level operations
and allow the Metaverse services to operate in a seamless
manner, hence the name, AI-based Infrastructure (AIInfra).

the AI-based devices

(AIDev) provides

AIInt: Metaverse services heavily rely on user experiences
and, to make them satisfactory, design of user interface is the
initial step. Although the design of interactive and intuitive
user interfaces helps improve social interactions, it can be a
hindrance to some of the users that include disabled, introvert,
and specially challenged people. To make the interface acces-
sible in general, AI methods can be extensively used (AIInt).
For instance, usage of computer vision approaches for visually
challenged users, or generating automated voice from text for
visually impaired ones, design of social avatars for friendly
interaction in virtual world, brain computer interface for spe-
cially challenged users, and so forth. AI-based methods can not
only be used for enabling the user-experience in terms of in-

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

13

Fig. 7. AI in Avatar and Environment Design for Metaverse: Image courtesy: https://spatial.io/

terface design for some users, but also can be used to improve
the accessibility and interaction with the interfaces, in general.
AICont: Decentralization has been extensively achieved
through smart contracts and blockchain based methods,
however, Metaverse emphasizes on democratization along
with the decentralization. Decentralization allows users and
creators to protect ownership and exchange entitlements and
assets easily in the digital space; however, it does not ensure
disintermediation from corporations, ﬁnancial institutions, and
investors. For instance, let us consider the Adidas NFT case,
which was dropped in December 2021 with a constraint that
purchases were limited to 2 persons. The NFT was sold out in
less than 1 second because a single user purchased 330 of them
in a single transaction. This was accomplished by modifying
smart contracts, which proves
the democratization
cannot be achieved by just using conventional contracts.
Democratization refers to the equal opportunity for all users,

that

thus snatching away the power from big corporations. In this
regard, AI can be used to detect modiﬁcations and anomalies
concerning smart contracts, hence the name AI-based smart
contracts (AICont). Furthermore, AICont can leverage the
information acquired from AIInt and infrastructure to detect
non-democratic activities for preventing such kind of incidents
in blockchain transactions.

AIVWorld: The creation of virtual environments is of vital
importance in Metaverse, and making it believably realistic
is one of the research challenges to solve. Some examples of
digital worlds are NVIDIA’s Omniverse10 and Spatial IO11.
These platforms provide a set of components to simulate the
real-world objects and create unique digital worlds in quite an
impressive manner. The use of AI is extensive in creating this

10https://developer.nvidia.com/nvidia-omniverse-platform
11https://spatial.io

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

14

Fig. 8.

Images generated with Botto, GauGAN2 and DALL-E

set of components as the process needs to be autonomous,
realistic, and visually pleasing (AIVWorld). These virtual
worlds can be used for variety of applications such as building
massive worlds, creating simulation environments for robots
and autonomous vehicles, simulating voice-based commands
in the digital world, and so forth. AI will be responsible
for not only creating realistic digital worlds, but also testing
automation within the Metaverse. Some snapshots from
Spatial IO virtual environment are shown in Figure 712.

AIART-E: Non-fungible tokens (NFTs) have proven to be
a stepping stone in Metaverse from an economic perspective.
Although, NFTs are generated by the artists, but AI can be
used to generate unique art as well. Considering the expansion
of AI usage among noncoders (thanks to GPT-3 and similar
models), the users will be able to generate their own NFTs.
The advances in natural
language processing (NLP) have
allowed AI to generate art for economic enrichment (AIART-
E) in the digital space. Unique stories can be generated using
models such as GPT-3 [117], [118], while realistic unique art
can be generated from a single line of text using DALL-E
[119], [120] and GauGAN2 [121]. There are also community-
driven platforms governed by autonomous artists that build
algorithms to create arts. One of such community-driven
platforms is Botto13. Some creations from Botto, GauGAN2,
and DALL-E are shown in Figure 814 [119], [121].

that

SocialAI: The core motivation behind Metaverse is to
create an interactive environment
improves the social
network experience. However, with current social networking
platforms, there is a lot of abuse, hate, and serious concerns
in terms of safety and inclusion for children and minorities.
Such constraints can contribute to the depowering of digital
personalization and self-knowledge, which are the things that
Metaverse stands for. The use of artiﬁcial intelligence can
be leveraged to improve the experience of social networks

12https://spatial.io/
13https://botto.com/
14https://botto.com/

(social AI). The techniques can be used for the machine
learning observability, focus more on Explainable AI that
can avoid bias, compute content relevance with respect to
the minority groups belonging to different ethnicity, culture,
geography and language, and detect hate and abusive speech.
PersonalizedAI: The ﬁnal layer in Metaverse pyramid is
the hyper-personalization in terms of experience. In terms
of AI usage, the former layers leverage the techniques to
achieve goals that ultimately contribute to enhance the user’s
performance. However,
the experience enhancement was
applied in a general manner. In this layer, the goal is to
provide the user with a personalized experience that is speciﬁc
to each user in the Metaverse. For instance, adjust the gaming
models with respect to users’ emotions or mental well-being,
or apply personalization by considering the users’ disabilities.
Personalized AI can be explored in different ways for a
variety of applications such as education, healthcare, gaming,
socialization, sports, and others using real-time analytics.

A. Learning Paradigms for Metaverse

Over the years, applications in Metaverse such as robotics,
embodiement, virtual reality, augmented reality, digital ren-
dering, and more saw remarkable progress through supervised
learning techniques [122]. However, the supervised learning
strategy tends to make the Metaverse application task depen-
dent, as it is highly based on human supervision. Although,
diversiﬁed learning strategies such as reinforcement learning
[123], self-supervised learning [26], and more have been
proposed to make the Metaverse application task independent,
its still a work in progress. The Meta AI research group is
exploring the self-supervised paradigm, speciﬁcally in the do-
main of text and speech, to make advances in task-independent
learning networks. Recently, Meta AI research released the
data2vec model which is presented as a uniﬁed solution for
the speech, vision, and natural language processing task while
leveraging multiple modalities [124]. Currently, Meta AI is
working towards more uniﬁed models that could leverage

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

15

multiple modalities while helping in reading lips and under-
standing the speech semantics to make leaps of progress in
digital reality. While Meta is exploring the self-supervised
paradigm, its rival Google’s DeepMind has stuck with super-
vised learning and uses massive amounts of data from VRChat
to train a digital agent on how to interact with humans in a
simpliﬁed environment. In 2018 alone, 16 million hours of VR
data was generated. Google DeepMind used 20,000 hours of
VRChat data to train a digital agent to learn ground language
while interacting with humans15. The study showed that the
digital agent becomes curious and autonomous with such a
training strategy. According to the experiments, the DeepMind
suggested that it could pave the way for understanding how
the Metaverse could be equipped with life like intelligence.

B. Computer vision for Metaverse

In the ﬁeld of computer vision, Metaverse has gained the
most progress, as researchers can replicate human-like avatars
or hologoraphic images of loved ones in the digital world.
William Shatner who played Captain James T. Kirk of the
starship Enterprise in vintage star trek television series is one
of the most beloved actors. An AI startup StoryFile16 acquired
hours of William Shatner’s footage while answering questions
using volumetric cameras. The footage was acquired with a
green screen so that William Shatner’s image can be easily
segmented, and a proprietary model Conversa was used to
associate answers with the asked questions. Currently, the
startup built a lifelike videobot of the aforementioned actor.
Although, the startup used green screen, there are many deep
learning based semantic segmentation methods that does not
need a green screen to get a person segmented in even a
complex scene, such as FCN [125], UPerNet [126], BiSeNet
[127], FPN [128], SFNet [129], SegFormer [130], FaPN
[131], CondNet [132], and Lawin [133].

There are further many projects in development that can
be considered as a technological leap towards Metaverse. For
instance, companies are working on the hologram of holocaust
survivors. It is an innovative medium to keep stories from
the past alive using artiﬁcial intelligence17. A socially distant
santaclaus 18 and avatars of the loved ones. Recently, Microsoft
[134] registered a patent for an AI system that could help an
individual interact with a dead loved one through its 3D digital
version. Similarly, Replika AI19 is also trying to address
mental well-being and loneliness through a digital avatar.
Apart from people, researchers are also trying to build a digital
system for animals. Researchers from Ubisoft china have pro-
posed a rendering keyframe animation method, i.e. ZooBuilder
[135] for animals by using OpenPose method [136] for ex-
tracting 2D joint coordinates and 2D-3D human pose estimator
[137] to track the temporal relationships between connected
joints. With the emergence of Metaverse, many Internet-based
tools now use computer vision techniques to provide animated

15https://www.youtube.com/watch?v=b-fvsi9YIP4
16https://storyﬁle.com
17https://www.cbsnews.com/news/artiﬁcial-intelligence-holocaust-

remembrance-60-minutes-2020-04-03/

18https://edition.cnn.com/2020/12/15/health/children-social-distance-with-

santa-wellness/index.html
19https://replika.ai

3D human models or realistic animated faces, some of them
include Kinetix20, Mixamo21, and StyleGAN2 [138].

C. Edge AI for Metaverse

The use of Edge AI would be quite crucial for realizing
Metaverse, as it is highly dependent on low latency and high
throughput to meet the needs of user experience. The ﬁfth
generation (5G) networks meet the user experience demands
to some extended, i.e., maximum data rate of 10 Gbps and
delay of less than 10 milliseconds, but as per the estimations
and forecasts, the delay needs to be lower and the peak data
rate needs to be higher in order to sustain user experiences in
Metaverse. Thanks to the use of AI techniques in combination
with edge computing, the foundation to develop emerging
mission-critical applications is laid [139]. Several deep learn-
ing, soft computing, and machine learning techniques have
been proposed to achieve uRLLC, be it active user detection
[140], resource allocation [141], scheduling problems [142],
and power-management problems [21], accordingly. Recently,
AI has also been exploited for mobility prediction, trafﬁc
estimation, channel prediction, and spectrum management for
maintaining uRLLC. For instance, SCGNet [143] and MCNet
[144] were introduced to enhance the spectrum utilization
efﬁciency while demodulating the receiver’s signal accurately.
In [145] a combination of CNN and LSTM was introduced to
predict the channel state information for improving robustness
in practical 5G systems. The study [146] proposed a 3D
trafﬁc by
convolutional networks for
leverage long and short term spatial patterns from the trafﬁc
data. In summary, Edge AI techniques are very crucial in
achieving low latency with high throughput that acts like a
support system for high class integrated services in Metaverse.

forecasting cellular

D. 6G: A requirement for AI-based Metaverse

The services associated with Metaverse rendered by AI
require the infrastructure to be scalable, services to be light-
ning fast which require low latency, reliability through stable
connection, and security. Although the current generation of
communication system, i.e. LTE and 5G, provide some of the
basis to realize Metaverse its still far away from large-scale
implementation due to the aforementioned characteristics.
Since the metaverse needs to support atleast thousands if not
millions of remote devices that need to process and transmit
huge amounts of data, the latency will be the core issue for
current network environment as it is considered to be the
bottleneck for adaptation of wide array of applications [147].
Some haptic and spatial AI applications require latency of less
than 1ms while the transfer rate of more than 1 Mbps [140].
The ﬁfth generation communication system alleviate this
problem to some extent but as the Metaverse grows, which is
assumed to be the case, a stable and faster new generation of
mobile communication will be deﬁnitely required [148].
As discussed in previous subsections, large language models
will play a key role in understanding user preferences and
generating customized and unique environments.
In this
regard, the training of such models require computing power
and a stable connection [149]. However, researchers have

20https://www.kinetix.tech/
21https://www.mixamo.com/

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

16

TABLE V
DELAYS AND BANDWIDTH REQUIREMENT FOR EACH OF THE LAYER IN METAVERSE PYRAMID

Layer
AIINFRA
AIINT
AICONT
AIVWORLD
AIART-E

SocialAI

PersonalizedAI

Delay (ms)
1.167
3.5
500
3.5
3.5

1.167

150

AIT (ms)
2.86
3500
4500
8000
10000
1.25 (Text) /
2000 (Image)
19200

AIT-EUE (ms)
-
5800
-
19300
24400
1.37 (Text) /
3400 (Image)
48800

TBR
-
1062 Gbps
500 Kbps
63.70 Gbps
10.62 Gbps

TBR-C
-
530 Mbps
500 Kbps
210 Mbps
35 Mbps

500 Kbps

128 Kbps

238.89 Gbps

796 Mbps

shown that the current iteration of network environment is
not suitable for training large language models, rather it
works better with small-scale ones, and one of the reasons for
such failure is the lack of stable connection [150]. Therefore,
in order to realize the metaverse with its full potential, the
communication network needs to play an effective part along
with the AI methods, respectively.

We analyzed several studies [148], [151]–[154]for require-
ment gathering concerning delays and bandwidth with respect
to each layer in Metaverse pyramid shown in 6 and report
the ﬁgures in V. The requirement is gathered with respect to
delay, average inference time (AIT), average inference time
with enhanced user experience (AIT-EUE), transmission bit
rate (TBR), and transmission bit rate with compression (TBR-
C), respectively. The AIT-EUE refers to the data enhancement
techniques for enhancing user experience, for instance, image
denoising, image super resolution, and more. The AIT-EUE
mainly depends upon the image resolution (assuming that
Metaverse mainly deals with imaging technologies). The
relationship with the inference time is simple, higher the
resolution, higher the inference time. The reported values
are in terms of average and also hypothetical, as Metaverse
and 6G are not realized to a larger extent. For AICONT, we
considered the average transaction speed of cryptocurrencies
that are fastest, such as Algorand and EOS. The values
for average transaction speed for the cryptocurrencies and
related information are obtained using Statista22 and Algorand
Blog23, while the information regarding NFTs are obtained
using Chainalysis24. The requirement suggests that the current
iteration of communication system (5G) will not be able to
meet most of the requirements, thus, the realization of Meta-
verse is closely tied with the emergence of sixth generation
communication system which promises to have lesser delays,
latency, and higher transmission bit rates, accordingly.

IV. ROLE OF B5G/6G IN METAVERSE

This section outlines the importance of B5G/6G services
towards Metaverse in subsections IV-A and IV-B, followed
by a comprehensive review of the state-of-the-art wireless
communication technologies for immersive experiences in
subsections IV-C and IV-D.

22https://www.statista.com/statistics/944355/cryptocurrency-transaction-

speed/

23https://www.algorand.com/resources/blog/role-of-transaction-ﬁnality-

speed-in-nft-minting

24https://blog.chainalysis.com/reports/chainalysis-web3-report-preview-

nfts/

A. Is B5G/6G Need of an Hour?

It

telecommuting,

telecomputing,
telepresence, avatar

is anticipated that Metaverse will be grounded on
large-scale wireless cellular network technologies for the
teleporting,
of
purpose
teleoperating,
interactions, and data
mobility. The interactive and immersive experiences inside
Metaverse will require very high data rates and low latency
while transmitting high-resolution content. 5G networks could
deliver data rates of up to <10GBs by exploiting the mmWave
(30-300 GHz) spectrum [17]. This frequency and data rate
remained successful
in fulﬁlling the uplink and downlink
throughput requirements of several multimedia applications
ranging from live streaming to connected and autonomous
vehicles. However, Metaverse is likely to interconnect a
wide range of such services potentially involving holographic
communication and real-time haptics, requiring milliseconds
the bandwidth
of motion-to-photon latency. Consequently,
and throughput requirements for delivering such services will
be 103x more compared to the existing 5G-based cellular
systems [20]. Therefore, 5G and pre-5G networks will not
support the Metaverse for the following key reasons:
1) Proliferation of devices: Metaverse is expected to drive
the growth of mobile and other IoT devices signiﬁcantly.
Thus, the connection density of 5G and pre-5G networks
will not be able to accommodate the increasing number
of devices.

immersive

2) Multi-sensory communications: Apparently, Metaverse
services with multisensory
will
bring
communications
challenges
to existing 5G QoS and QoE classes. Thus, 5G and
pre-5G wireless systems will fail to provide a seamless
experience to multiple immersive services such as avatar
interactions or teleoperations in parallel.

that will pose

stringent

3) Complex and ultra-massive connectivity: Metaverse
is envisioned to build on proliﬁc heterogeneous devices
distributed in a highly dynamic, complex and ultra-massive
network. In such a scenario, the existing 5G and pre-5G
services catalog will not offer a reliable solution since
those services are often designed for static and predeﬁned
optimization challenges.

4) Decentralized services: Decentralized intelligence will be
a cornerstone in Metaverse driven heterogeneous multi-
machine, multi-technology, multi-user, multi-application,
and multi-device environments. Although 5G architecture
can support the AI services on the network’s decentralized
edge,
the edge intelligence required by Metaverse is
beyond the original goals of current 5G networks. The
transmission rate offered by 5G can not guarantee the
resilient edge AI because AI models will need to be subtle

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

17

and highly dynamic while serving on the edge or other
devices in Metaverse.
Pre-5G networks successfully supported the deployment of
AR among retail applications, educational services, the gaming
arena, and Google Maps [155]. VR/AR devices such as Google
Glass25, Toshiba dynaEdge26, Microsoft hololens 227, etc., and
mobile applications such as IKEA Place28, Pokemon Go29,
etc., have widely beneﬁted from pre-5G networks. These apps
and devices were not only self-sufﬁcient but also leveraged
Internet access via pre-5G access methods. Studies show
that VR/AR users gained adequate experience via 4G LTE
networks [156]. However, such networks are insufﬁcient to
meet Metaverse users’ expectations. Metaverse will bring in
next-generation multimedia such as real-time haptic feedback,
high dynamic range (HDR), and stereoscopic video formats.
The estimated data rate required to render a stereoscopic HDR
360◦ video of 8K resolution with 90 frames per second (FPS)
is 200Mbps [155]. In addition, the holographic avatars will be
rendered as a physical presence for remote users in Metaverse.
The rendering of holographic avatars will be witnessed in
situations where a doctor will be required to perform remote
surgery, an engineer to troubleshoot
in a remote factory,
and a farmer to look after the grass and animals in remote
geographic locations. Apart from typical graphical properties
(e.g., resolution, depth, texture, or color), the holographs will
be organized from various postures to ensure consistency in
angles, frames, and slopes relative to the avatar. If an avatar
is rendered in tiles of 4” x 4” dimensions, then an avatar
with a 6’ x 20” human size will require a transmission rate of
4.32 Tb/s [157]. According to a Third Generation Partnership
Project (3GPP) analysis on the communication aspect of
healthcare services, a remote AR-based surgery can operate on
approximately <1ms of E2E latency and 12 Gbps of transmis-
sion rate considering an HDR 10bits stream of 4K resolution
with 120fps [158]. Metaverse is envisioned to deal with longer
durations of remote surgeries, operations, and other clinical
trials. To offer immersive experiences in Metaverse, additional
synchronization will be required apart from high data rates
to ensure seamless transmission of multisensory content
delivery and user experience. Such requirements are beyond
the offerings of pre-B5G/6G systems, and non-3GPP access
including Wi-Fi, will be impractical due to the
networks,
performance benchmarks and handover issues occurring from
mobility [159]. Thereby, B5G/6G plays its role in recognizing
the demands mentioned above. In the subsequent section, we
will entail the enabling technologies offered by B5G/6G.

B. What B5G/6G Brings to Metaverse?

Since Metaverse is coined to be the next

in
it will encompass multisensory
multimedia after VR/AR,
network
holographic
and
as
such
communications. Soon users will undermine the QoE delivered
by VR/AR and demand new lifelike multimedia experiences,
not−real−enough VR/AR experiences.
unlike

services

frontier

today’s

haptic

25https://www.google.com/glass/start/
26https://us.dynabook.com/smartglasses/products/index.html
27https://www.microsoft.com/en-us/hololens/
28https://www.ikea.com/au/en/customer-service/mobile-apps/say-hej-to-

ikea-place-pub1f8af050

29https://pokemongolive.com/en/

Metaverse applications involving avatar interactions aided
with novel communication modalities such as avatar−to−avatar
(A2A), avatar−to−human (A2H), and human−to−avatar (H2A)
will drive the majority of the Internet trafﬁc by 2030 [160].
Thereby, the services provided by B5G/6G have a crucial
role in realizing the lifelike experiences in Metaverse.

1) 5G Services Towards Metaverse: 5G networks offer
three prime categories of services listed by the International
Telecommunication Union (ITU)30: uRLLC, mMTC, and
eMBB to handle the requirements of extremely low latency,
enormous content transmission and high computations. eMBB
trafﬁc requires a gigabit/s level of the transmission rate. At
the same time, uRLLC expects high reliability of 99.999%
with ultra-low-latency of 0.25 ∼ 0.30 ms/packet, and mMTC
requires highly dense connectivity with signiﬁcant energy
efﬁciency. However, uRLLC can only provide a data rate
of up to 10 Mbps which might ﬁt in a few applications of
VR/AR. In contrast, eMBB can be suitable for delivering
ultra-high throughput in order to meet the requirements of
Metaverse users accessing multisensory content ranging from
teleoperations to holoconferences to telesurgeries with 3D 4K
resolutions31. In addition, it can offer the minimum guaranteed
delivery of 100 Mbps to users. Therefore, eMBB can play a
crucial role in Metaverse’s gaming and entertainment paradigm
by providing mobile users with 100-200 Mbps downlink with
a peak threshold of 250 Mbps and latency of <100ms [161].
An evolution of VR technologies can be seen in Figure
9. From basic VR video streaming to interconnected VR to
a fully wireless interconnected VR, a series of stages can
be seen [20]. However, unlike conventional video streaming,
wireless streaming in Metaverse may require transmitting
enormous omnidirectional visual content with a latency of
<20ms. The success of such an immersive virtual experience
is highly reliable on a smooth transmission mechanism of
ultra-high-resolution visual content along with a highly subtle
tactile feedback in downlink networks. As discussed in section
IV-A, it is obvious to rely on the B5G wireless technologies
the immersive virtual applications. Therefore,
to support
mmWave has progressed towards standardization by 3GPP in
B5G wireless systems [19]. Simultaneously, researchers have
also explored the potential of mmWave mobile networks in
realizing the wireless bandwidth requirements of VR appli-
cations. According to [20], mmWave is able to successfully
deliver high data rates with low-latency transmission for
several VR applications. Similarly, the mMTC service can
support dense mobile connectivity of up to 1 million devices
per square kilometer which is approximately 10x greater than
4G LTE networks. A study by the European 5G Observatory32
reported the data obtained from 180 trials to assess the capacity
of 5G in a dense urban area of Finland. The mMTC service
was able to deliver a realistic data rate of 700 Mbps to 1
Gbps by accommodating a reasonable user density. Based on
the overall analysis, 5G service equipped users’ devices with
average data rates of 1-4.5 Gbps with a delay of <5ms [162].
Since a few Metaverse applications will require a data rate
ranging from 100 Mbps to a few Gbps with 99% reliability and
a delay of <5ms, 5G networks may fulﬁll these requirements

30https://www.itu.int
31https://www.5g-eve.eu/
32http://5gobservatory.eu/5g-trial/major-european-5g-trials-and-pilots/

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

18

Fig. 9. Evaluation of VR experiences: a) VR over wired connectivity, b) VR over interconnected network, and c) VR over fully wireless connectivity [20]

the recent

efﬁciently. Apart from that, Metaverse users will utilize the
diverse features of mobile systems ranging from display and
sensing capabilities to near-user computing resources [58].
In addition,
innovations in vision and tracking
technologies such as depth, 360◦ resolution and precision have
supported the idea of user’s interactions with the surroundings.
These capabilities are not
limited to smartphones; many
devices such as ﬁtness watches, smart TVs, game consoles,
and autonomous vehicles also possess these features. These
devices can leverage the services of 5G with single-digit la-
tency, high throughputs (i.e., 10x > 4G), ﬁve-nines of network
reliability and dense network coverage (i.e.,> 10-100x) [163].
In 2021, 5G smartphones entered the commercialization phase
and were expected to spread in the global market within
the next few years [164]. The growth of these devices with
seamless connectivity will certainly form the basis of several
immersive services such as tele-classrooms,
tele-surgeries,
and teleoperations. Nevertheless, to deliver such services with
a sufﬁcient QoE requires very high data rates within a range
of 1 Gb/s to 1 Tb/s which can be supported by B5G cellular
and underlying transmission networks [165].

2) 6G Services Towards Metaverse: 6G networks are
envisaged to provide ubiquitous intelligence with abundant
compute power and high-speed wireless data ﬁdelity over the
air, space, and sea as shown in Figure 11. 6G services have
been deﬁned in terms of the real-time mesh of physical and
cyber worlds, with a ﬁne-grained focus on the interactions
among physical, digital, and biological
(human-centered)
worlds [166], [167]. An immersive merger of cyber and
physical space is likely to bring new platforms in the
shape of embodied Internet, providing 6G based Metaverse
applications and other cyber-physical systems (CPS). 6G will
exquisitely enhance user experience in the Metaverse since its
services are primarily human-centric instead of data-centric.
Consequently, Metaverse users and the associated processes,
user equipment, and the network will be holistically integrated

to provide a plethora of immersive applications.

Moreover, 6G networks will empower edge intelligence
through on-device machine/deep learning and distributed AI
that will transform the “connectedness with intelligence” for
not only human-centric but also machine-centric applications
[168]. In Metaverse, 6G will enable neural and haptic sensory
communications with an integrated holographic reinforcement
[38]. 6G will also fulﬁll
the requirement of Internet-of-
everything by featuring the network-in-box management and
virtualized services that will motivate the massive multiple
access points to shape a distributed (cell-less) multiple-input
and multiple-output (MIMO) system [169]. In contrast to 5G
systems, 6G supports terahertz frequency bands and is liable to
provide 1 Tbps of data rate with an E2E delay of 0.1ms [170].
It also supports extremely reliable low latency communications
(eRLLC)-based services along with a reliability rate of
99.9999999%. In principle, Metaverse users can achieve high
QoE by leveraging the following 6G services: support for
multi-dimensional holograms, ultra-massive data-transmission
rates to support HDR 360◦ multimedia with 4K/8K resolution,
extreme low-latency and high precision for haptics required in
3D-printing, telepresence, immersive multi-user gaming, and
responsive digital twins in industry 5.0. Furthermore, these 6G
services will be underpinned by AI, such as federated learning,
split computing, and distributed deep reinforcement learning
to reduce network congestion and improve the user QoE [25].
In summary, 6G will surpass the previous generations
by catalyzing the wireless revolution from “connectivity”
to “connectivity with intelligence” with the following key
emerging services and utilities:

• High data rates: The usage scenarios under ultra mobile
broadband (uMBB) will exploit signiﬁcantly higher data
rates as compared to the ones in 5G eMBB services.

• Dense connectivity: The ultra-massive machine-type com-
munication (uMTC) scenario will empower use cases where
a relatively higher and massive number of connections in a

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

19

certain space will be required simultaneously as compared
to the ones provided in 5G-mMTC services.

• High reliability and precision: The services under
require a
ultra-high precision communication (uHPC)
very high degree of precision,
reliability and accurate
positioning, making them suitable for mission-critical
applications as opposed to 5G-URLLC services. These
services ensure stringent service level guarantees can be
enforced independently or in part with each other.

• Air-to-ground connectivity: The services under extended
3-dimensional coverage (e3DC) will be able to exploit the
in-space non-terrestrial satellite communications by utilizing
the ground-based terrestrial mobile networks. The realm of
in-space networks includes drones, high-altitude platform
stations,
to provide multi-dimensional
coverage across the globe.

and air-borne

• Communication meets computation: The proliferation
of emerging smart devices will urge the need for an
autonomous and distributed computing framework to
facilitate key technologies such as split computing and
federated learning. 6G will
facilitate the computation-
centric communication that will ensure the required QoS
provisioning by trading off the communication resources
in order to achieve sufﬁcient computational accuracy.

• Context-driven communications: The 6G network context,
such as network architecture and bandwidth, will navigate
the provisioning of 6G uMBB services to the users. It
will signiﬁcantly beneﬁt the Metaverse applications since
the physical context, such as the user’s location, mobility
and social connections, will be highly dynamic, eventually
leveraging the agile and adaptive service provisioning of
6G networks.

• Event-driven communications: 6G networks will ensure
the orderly provisioning of uHPC services based on certain
characteristics of emergency or disaster events. The highly
dynamic spatio-temporal attributes of users and devices,
network trafﬁc and infrastructure will play a key role in
resource allocation in 6G-uHPC application scenarios.
Apart from the above services and their usage scenarios, 6G
can also offer a hybrid of these services to meet the extreme
demand for new performance metrics in the Metaverse that
are unlikely to be achieved by 5G and pre-5G networks.
For instance, an application can leverage the combination of
uMBB and uHPC, subject to the fulﬁllment of requirements
of both services simultaneously. Similarly, uMTC and uHPC
can be combined for a certain application if the needs of both
services can be met simultaneously [108].

C. Immersive Experiences over Wireless

thus

Immersive experiences are facilitated through virtual
worlds, where the users experience a fully immersive
environment,
creating a meta-world that projects
the real-world scenarios. State-of-the-art VR applications
are embedded with a dynamic streaming framework that
automatically adapts the bitrate of the XR content according
to the network bandwidth and user’s geolocation [171].
Although the 5G legacy has remained capable of providing
rudimentary XR support, scaling the adoption of XR devices
and applications over wireless networks requires new research
and engineering directions. Recently, 5G and beyond has

mmWave

paced further in boosting the XR performance by introducing
various heterogeneous improvements in not only XR-speciﬁc
entities but also service-related advancements. Table VII
shows several studies that investigated the role of state-of-
the-art B5G/6G technologies for immersive experiences.
this end,

for Wirless VR: Towards
the
3GPP is involved in standardization activities for mmWave
communications in B5G/6G systems [168]. In the meantime,
academia is also exploring the potential of mmWave mobile
networks
to support wireless VR streaming over high
bandwidth [22]. The use of mmWave communications
enables high transmission rates and low delay transmissions
so that wireless VR applications can be seamlessly supported.
In addition,
the abundance of wireless bandwidth can
further alleviate the scarcity of transmission rates through
mmWave communications. Researchers generally consider
60 GHz mmWave wireless technologies since it is the only
standardized mmWave wireless technology that has been
identiﬁed so far based on the IEEE 802.11ad [172]. For
example, authors in [173] explore the potential of a 60GHz
wireless channel
to simultaneously process the large-scale
multimedia content delivery in distributed VR platforms.

MEC for Wireless VR: Another challenge in supporting
VR experiences is that the videos must also remap pixels from
a viewing sphere to a 2D viewport in order to distinguish their
content form from traditional videos. The rendering process
involves complex matrix mult-add operations and is extremely
computationally intensive. Hence, the power consumption of
virtual reality videos is signiﬁcantly higher than other forms
of video [174]. As a result, this will bring great challenges to
the ubiquitous applications of wireless VR, as the continuous
rendering of viewports will lead to exhaustion of battery and
will eventually shorten the battery life. To address this chal-
lenge, various scenarios of MEC and caching have emerged as
promising solutions to support wireless VR [165]. The deploy-
ment of MEC and caching paradigms at the mobile network
edge can enable some computation tasks to be handled by in-
network computing capacity. Additionally, some popular VR
content and computational outputs can be cached to reduce the
amount of repetitive computation and transmission. For exam-
ple, in the article [175], the theoretical architecture of a hybrid
mobile computing system is presented concurrently that com-
bines the processing abilities of cloud servers, MEC servers
and end devices along with the caching capabilities of MEC
servers. Similarly, according to [169], VR tasks can be divided
into several sub-components, and part of the sub-component
can be cached using the mobile device’s caching mechanism.
mmWave meets MEC for Transmission Efﬁciency in
Wireless VR: Furthermore, several studies have indicated
that introducing FOV into 360◦ video will reduce up to 80%
of the bandwidth requirements compared to delivering 360◦
video, hence lowering the overall necessary transmission data
rate [177], [178]. For example, authors in [179] analyze the
tradeoff between homogeneous and heterogeneous FOVs for
a MEC-based mobile VR delivery model regarding computa-
tions and caching tasks. In addition, several methods have been
proposed that take advantage of the FOV of users, for instance,
introducing FOV prediction [180] and segregating different
types of VR frames and multicasting them [181]. Based on
the above discussion, it is apparent that more schemes can
be developed if mmWave communication is combined with

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

20

for indoor service delivery. For instance, Liu et al. propose
a deep reinforcement learning (DRL)-based strategy to efﬁ-
ciently maintain the long-term QoE in THz-based immersive
systems [186]. Speciﬁcally, authors have studied a joint use
of THz and RIS to create a VR network in an indoor scenario
with an aim to enhance downlink transmission. To achieve the
aim, the authors utilize the current and historical viewpoints
of VR users obtained from real VR datasets to train a gated
recurrent unit (GRU) model for predicting the dynamic view-
point preference of VR users. Table VII shows several studies
that investigated the THz channels for immersive experiences.

D. Holographic Telepresence in Metaverse

Metaverse users would be able to see high-quality,
representations of people using
three-dimensional digital
Holograms and without wearing HMD. Future networks (i.e.,
B5G/6G) will be able to support extremely low latencies and
ultra-high data rates with high reliability in order to underpin
the holographic communication that will facilitate Metaverse
users to fully immerse in gadget-free communication [22].
For example, a 6G network with 0.1ms of latency supported
by an ultra-high bandwidth of Tbps can be leveraged for
HT [187]. In order to evaluate HT applications, there should
be seamless and quality connections between users, which
requires an extremely low-latency data transmission rate and
massive low latency. A number of factors affect the required
data rates, such as the method used to construct a hologram,
the type of display and the number of images that need to
be synchronized. For example, a typical hologram based on
the point cloud techniques requires 0.5–2 Gb/s, whereas a
large-sized hologram may require up to a few Tb/s [188]. The
transmission of such holograms may be underpinned by using
data compression techniques, but even then, holograms are
likely to require vast amounts of bandwidth. Therefore, latency
and reliability become two critical key performance indicators
(KPIs) for HT. Within Metaverse, HT will be able to launch a
number of human-type communications, including telesurgery,
immersive education, teleoperations, and the Internet of Skills
(IoS) [189]. Due to HT’s high sensitivity to latency, these
applications have strict requirements for round-trip delay.
Thus, it is important that the communication link for these
applications be ultra-reliable to avoid packet losses which may
lead to disastrous events. To overcome that, mobile B5G/6G
networks have been considering URLLC as one of the new ap-
plication scenarios to support the above applications [190]. It
is expected that with 5G New Radio, the radio access networks
(RANs) can achieve a 1 ms delay with 10-5-10-7 packet loss
probability. This includes 0.5 ms uplink transmission and 0.5
ms downlink transmission [191]. In addition to that, 6G can
provide URLLC with 1 Tbps of data rate and E2E delay of
0.1ms using THz frequency bands to support HT in Metaverse.

V. NEXUS OF AI AND 6G FOR METAVERSE
This section outlines the interplay of B5G/6G and AI
towards Metaverse. In subsections V-A, we discuss the role
of 6G in realising the pervasive and ubiquitous AI services
that are discussed in section III for Metaverse environments.
Subsection V-B explains the role of AI in making autonomous
6G network infrastructures for Metaverse, followed by the

Fig. 10. Transmission of a panoramic virtual reality video (PVRV) stream
using mmWave and sub-6GHz link on a MEC framework [176].

MEC-based FOV mechanisms. For instance, Liu et al. use
mmWave and sub-6GHz link to transmit a panoramic virtual
reality video (PVRV) stream by encoding the viewport and
rendering the standby tiles according to different quality levels
[176], as shown in Figure 10. Similarly, Gputa et al. present
A multiple-layer streaming scheme in which the base layer is
encoded and transmitted via Wi-Fi [182]. In contrast, a number
of enhancement layers are transmitted via the mmWave access
point. Therefore, a fusion of mmWave and MEC-based FOV
schemes can reduce bandwidth requirements while reducing
the transmission delay when compared with 360◦ videos.

Immersive ﬁdelity with THz communication: Metaverse
will use 360◦ videos and MAR applications to bring immer-
siveness, as well as AI-driven applications with ubiquitous in-
tegration. Due to this, vast amounts of data will be exchanged;
hence the demand for radio frequency bandwidth spectrum
will surge rapidly. The existing mmWave technology cannot
satisfy this demand. Consequently, switching to the terahertz
and sub-terahertz bands would be imperative. THz communi-
cations are able to deliver ultra-high throughput and low la-
tency by supporting data-intensive applications such as VR/XR
over wireless personal area networks [27]. Several studies have
leveraged the unique beneﬁts of THz to be implemented with
6G for immersive experiences. In a study by Du et al., authors
examined the problem of providing a high-quality immersive
VR video service [183]. In particular, the authors exploit the
THz channel with MEC integration to optimize the immersive
VR rendering, power management, and ofﬂoading viewports
while satisfying the QoE constraints. Similarly, Chen et al.,
[184] investigated an immersive application involving VR
users transmitting 360◦ images to a backend server. They
formulated a problem to maximize the users’ successful
transmission probability by optimizing the downlink image
transmission and the rotation of the surrounding images. Their
proposed optimization problem involves a transfer learning ap-
proach consisting of liquid state machines to enhance the con-
vergence speed by transferring the learned transmission into a
new one. Despite the promising QoS delivery by the THz com-
munication system, it still has signiﬁcant propagation losses
and water-molecule absorption losses due to high transmission
frequency [185]. For this reason, THz has remained effective

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

21

TABLE VI
SUMMARISING THE ROLE OF STATE-OF-THE-ART B5G/6G TECHNOLOGIES IN THE CONTEXT OF METAVERSE.

Reference

B5G/6G Services

HMDs, mobile edge, and cloud computing

eMBB, mMTC, URLLC, and IIoT

Application scenario
AR-based tele-maintenance using a
cloud-based and serviced oriented system
AR/VR and digital twin based
industrial manufacturing

Authors & Year
Mourtzis et al.,
2017
Cheng et al.,
2018
Erol et al.,
2018
Ren et al.,
2020
Pengnoo et al.,
2020
Zhou et al.,
2021
Liu et al.,
2021
Fantacci et al.,
2021
Ng et al.,
2021
Ren et al.,
2022
Zhang et al.,
2022
Ghoshal et al.,
2022
Van et al.,
2022
Bhattacharya et al.,
2022
Kang et al.,
2022

[192]

[193]

[194]

[195]

[24]

[196]

[186]

[27]

[197]

[198]

[199]

[18]

[200]

[5]

[201]

edge caching, edge mining, computational ofﬂoading

AR/VR access pattern in virtual tourism

D2D communication, cloud computing,
on-device computing, and computational ofﬂoading

digital twins, THz links, and metasurface reﬂectors

MEC, 5G antennas, computational handoff, RNI, and gNB/ng-eNB

MEC, THz network, RIS, and federated learning

HRLLC, THz channels, SNC, and edge computing

edge intelligence, uniﬁed resource allocation, and VSPs

edge node localisation, service migration, load balancing, distributed edge AI

edge caching, computational ofﬂoading, decentralised computing

mmWave, cloud computing, uplink data ofﬂoading

MEC, URLLC, digital twins, and edge caching

TI, URLLC, H2M control, blockchain, xAI, and decentralised computing

MEC, federated learning, IIoT, blockchain, and AoI

Edge-assisted multi-user cooperative environment
for mobile web AR applications
Improving transmission links for potential
data-intensive applications in Metaverse
Improving QoE for MAR based gaming such as
collaborative assembly of a virtual object
Empowering immersive VR experiences using
prediction, rendering, and transmission of 360◦ content
Improving QoS for edge-assisted VR experiences
by minimizing the E2E transmission delay
Improving QoS in educational applications of Metaverse
by optimising resource allocation on users’ demands
Orchestration of distributed edge services
for location-based mobile AR systems
Scaling object recognition services for
seamless mobile AR experiences
Realising cloud-based multi-user AR experiences
with 5G mmWave
Improving QoE of digital twins in Metaverse by jointly
optimising the computing, communication, and storage resources
Improving quality and precision of tele-surgeries
for patients, virtual hospitals, and doctors in Metaverse
Empowering immersive Metaverse experiences through
user-deﬁned privacy-preserving incentive schemes

joint role of AI and 6G for tactile and immersive experiences
in subsections V-C.

A. 6G-driven Pervasive AI for Metaverse

Metaverse is envisioned to be extending people’s life by
allowing them to live, work, and play seamlessly for unlimited
durations. This can only be realized if the Metaverse has a
strong relationship with “ubiquitous connectivity with intelli-
gence,” i.e., B5G/6G, AI, and space-air-ground-sea integrated
network (SAGSIN) as shown in Figure 11. In essence, 6G
will support pervasive intelligence by reducing the potential
latency of virtual experiences and will allow developers to
develop better virtual experiences in the Metaverse where
millions of concurrent users can share an immersive 3D space
with each other. In such cases, the location of sender and
receiver might be remote; thus, the challenge is to support
dense connections (e.g., 107 users/km2), where multiple users
can transmit and receive 360◦ video content or real-time
human-like holographs in parallel [28], [30]. Such a sheer
amount of data ﬁdelity will require ultra-high bandwidth with
heterogeneous hardware for hosting AI services discussed in
section III, requiring extremely low-latency communications
for transferring model parameters or performing AI inferences.
Since 5G’s rollout, the ﬁrst set of promising technologies
along with architectural evaluation were polar codes, massive
MIMO, mmWave, and MEC. These unique 5G services were
able to support AR/VR applications by providing ubiquitous
connectivity. AR/VR users leveraged 5G-eMBB service to
achieve <100ms latency with a throughput of 100-200Mbps
[29]. Several experiments were carried out further to evaluate
5G’s performance in realistic mobile environments. For exam-
ple, the 5G-PPP (The 5G Infrastructure Public Private Partner-
ship, 2018)33 consortium reported a data rate of approximately
3Gbps having 2ms of latency on their Bari-Matera installation

it

thus,

in Italy34. This experiment was carried out with the combina-
tion of 5G services with LTE technology35. Another experi-
ment provides data from around 180 trials and investigations
conducted by the European 5G Observatory. In this scenario,
the trials were conducted for a number of weeks in urban areas
of Finland, therefore possibly with a reasonable density of
users, and results suggest that the most realistic data rate was
approximately ranged from 700 Mbps to 1 Gbps. According
to the ﬁnal experiment results, users’ devices realized 1 to 4.5
Gbps in average data rates, with less than 5 ms latency. It has
widely been acknowledged that AR/VR applications require
latency lower than 5ms, with average throughput between 100
Mbps to a few Gbps, and reliability of at least 99%, meaning
that 5G performance is sufﬁcient to support these needs [11].
Metaverse is supposed to be accessible from anywhere
at any time;
is presumed that 5G networks will
fail to provide coverage in some parts of the globe, such
remote areas, oceans, mountains, deep forests, and
as
airspace. This shortcoming of 5G can be overcome by 6G,
which is expected to provide ubiquitous global coverage
as shown in Figure 11. As part of 6G systems, data
collection, transportation, and utilization will take place in
real-time and anywhere at any given time, hence, catalyzing
immersive applications and services for Metaverse. 6G will
particularly emphasize ubiquitous AI, bringing artiﬁcial
general intelligence into every aspect of Metaverse through
a hyper-ﬂexible architecture. On top of that, a 6G network
will be well
several Metaverse applications
involving deep learning because it can generate a great
deal of data and perform computation and storage at
the
In summary, 6G networks can not
network edge [34].
only host personalized AI services but also cater to the
needs of dense user connectivity with low-latency-high-
reliability communications. For instance, a case study by

suited for

33https://5g-ppp.eu/5g-trials-2/

34https://www.fastweb.it/fastweb-plus/digital-magazine/5g-matera-fastweb/
35http://www.barimatera5g.it/

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

22

Fig. 11. An illustration of a large-scale SAGSIN in Realizing Metaverse.

Adeogun et al. entails a framework involving a short-range
wireless isochronous real
time (WIRT) environment for a
6G communication system. Authors developed a WIRT in-X
sub-network with roundtrip communication latency lesser
than 0.1ms with an outage probability < 10−6 [217]. A
multi-GHz spectrum for enhancing spatial service availability
is considered part of a dense IoT scenario with up to two
devices per m2. Based on their results, it can be observed that
cycle times are 10x shorter than the latency target achieved
i.e., <0.1ms [217]. Therefore,
via 5G radio technology,
Metaverse services involving novel communication modalities
such as A2A, A2H, and H2A can leverage great beneﬁts from
6G. We present a clear taxonomy of state-of-the-art for 5G/6G
wireless-empowered immersive experiences in Figure 12.

B. AI-led Autonomous 6G Networks for Metaverse

The success of the Metaverse experience will highly rely
on the seamless and sustainable integration of physical space
into virtual 3D space. Modern technologies (i.e., XR, AI,
and 6G) can contribute to the interconnected Metaverse by
ensuring interoperable coherence between the Metaverse and
the physical world (e.g., physical objects in the real world are
compatible with virtual objects in the Metaverse) [1]. In this
regard, a minor disconnect between Metaverse and the physical
world can cause only a mere disturbance to the users; however,
as the prevalence and utility of Metaverse increases, such a
disconnect in immersion may leave a long-lasting impact on
the life-critical applications of Metaverse. Therefore, a com-
munication system for Metaverse must be capable of providing
a stress-free and extremely reliable experience for sheer users.

1) Self-X Networks: Based on the

above-discussed
Metaverse requirements in subsection IV-A, it is critical for
6G networks to have an intelligent and autonomous adjustment
capability in order to meet various performance requirements,
such as full coverage sensing, ultra-low latency, and ultra-high
reliability, and persistent security [218]. At present, there is
difﬁculty in dynamically adapting to the continual changes
in user needs and network environments that alter
the
operating paradigms of today’s networks, which mainly rely
on rule-based algorithms as their core. A further constraint
is the inability to effectively accumulate the QoE of network
operations, which in turn prevents continuous improvement
in the capabilities of the network [219]. In other words, it is
not currently possible for networks to self-evolve under the
existing operating procedures. Thereby, whenever there is a
need to upgrade or improve something, much human expertise
and effort are needed. As 6G networks grow in geography and
complexity, manual intervention is unacceptable and unreliable
for the networks to operate at such a scale. Therefore, to
overcome this hurdle, european telecommunications standards
institute (ETSI) recently initiated 2 groups, i.e., zero-touch
(ZSM)36 and experiential networked
service management
intelligence (ENI)37, having focused on the use of ML and
DL to manage and orchestrate the resources of a network in a
fully automated way. The key objective of ZSM and ENI is to
add the component of “intelligence” into every block of future
networks in order to realize intelligent and self-evolution

36https://www.etsi.org/committee/zsm
37https://www.etsi.org/committee/ENI

GEO Satellite MEO Satellite LEO Satellite Sea Networks  Air Networks  Space Networks  Terrestrial Networks  Core Network Metaverse Environment   Mobile Edge Computing Metaverse ConnectivityD2D Link  Small Cell BS  JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

23

AR/VR Task Ofﬂoading

Decentralized and/or
Distributed AR/VR/XR

Wireless Networks
for Immersive
Applications

Tactile and/or Haptic Feedback

Intelligent Sensing

Huynh et al., 2022 [200]

Jiang et al., 2021 [216]

Lin et al., 2021 [215]

Chen et al., 2020 [214]

De. 2022 [213]

Chen et al., 2022 [212]

Guo et al., 2020 [211]

Sartipi et al., 2019 [210]

Minopoulos et al., 2022 [209]

Kusuma et al., 2021 [208]

Gupta et al., 2021 [207]

Zhang et al., 2018 [206]

Han et al., 2022 [205]

Sugimoto. 2020 [204]

Kim and Yun. 2020 [203]

Alam et al., 2019 [202]

Fig. 12. Taxonomy for the classiﬁcation of literature on 5G/6G Wireless-empowered Immersive AR/VR Applications.

abilities within the 6G-and-beyond networks [220].

2) AI

for Networks: The inception of Metaverse will
exceptionally pose new challenges for 6G networks that will
require support
from AI, particularly deep reinforcement
learning, and deep federated learning as shown in Figure 13.
In the traditional sense, the Metaverse is not like a digital twin,
which is a virtual representation serving as the equivalent
to a physical object [159]. In essence, Metaverse will offer
possibilities for scenario creation that differ from reality and
allow them to be run at their own time and with their own
rules, requiring dynamic support from 6G and AI nexus. As
such, several researchers have already explored the use of
AI for supporting 6G networks in challenging environments.
For example, the dutch double auction mechanism and DRL
were combined in [221] to improve transaction efﬁciency in
the Metaverse. The ability to make intelligent decisions based
on RL is a key enabler for the development of 6G networks
for Metaverse, especially those with strict QoS requirements.
Metaverse
from RL optimization
techniques if they are well designed because they enable the
ability of self-healing, self-optimizing, and self-organizing
for the 6G networks. For instance, Tariq et al. propose a
DRL-driven approach for proactive resource management and
intelligent service provisioning in 6G networks for a digital-
twin application [14]. However, this approach can suffer from

can beneﬁt

services

a signiﬁcant deﬁciency in the performance of AI models.
Particularly, for a highly distributed Metaverse application
where users are only supposed to interact continuously for
the purpose of AI model training without accessing the other
user’s data due to strict security restrictions as shown in Figure
13. To retain the performance of such AI models, recently
Kang et al. proposed an architecture for a decentralized
Metaverse application based on federated learning integrated
with blockchain [201]. Based on their architecture, the local
AI model can be optimized by horizontal cooperation of
multiple end nodes (edge devices), which eventually retain
the performance of AI models over time. Hence,
the use
of AI to optimize the network architecture and improve the
performance of 6G networks is therefore proving to be a
promising means of enhancing the Metaverse experience. In
Figure 14, we present a clear taxonomy of state-of-the-art for
AI-driven immersive experiences over wireless.

C. AI and 6G for Tactile Internet in Metaverse

In the Metaverse, the tactile Internet will dominate haptic
communication for mission-critical virtual services with touch
and actuation in real-time while facilitating timeliness of infor-
mation delivery for intelligent and interconnected meta-worlds.
TI is expected to underpin human-to-human and human-to-
machine interactions in a way that the time duration between

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

24

mentioned in section IV-A, its design objectives were not cus-
tomized to the TI’s speciﬁc features and requirements. In re-
sponse to the shortcomings of 5G, both industry and academia
have gathered a great deal of interest in next-generation 6G
systems, which are expected to support a variety of immersive
applications from multi-sensory communication to XR [226].
Apart from that, TI lays out a sheer amount of opportunities
to leverage AI, particularly deep learning to segregate the
perception of humans from the overwhelming transmission
delays which are usually experienced in wide area networks
(WANs) [227]. AI can certainly play a key role in fulﬁlling
the 1ms latency requirements using these networks. Although
communication-based enabling technologies can overcome
the end-to-end latency challenge, their efﬁciency can not go
beyond the scope of 150km due to their dependency on the
speed of light. Therefore, deep learning-based predictions can
be widely utilized to achieve 1ms latency by ruling out the
150km constraint on these networking technologies [191].

VI. SUSTAINABLE METAVERSE
This section outlines the sustainability issues in the Meta-
verse with respect to virtual resources, virtual travel, digital
twins, psychological barriers, and social sustainability, respec-
tively. The issue of sustainability is at the helm of affairs when
discussed business strategies concerning climate change. It is
inevitable for the organizations to not think of a sustainable
and efﬁcient way for conducting business to make a positive
impact on climate change. Although the concept of sustain-
ability is not new, however, it needs to be evolved with respect
to the innovation, changing times, and work style, accordingly.
the concerns
about carbon emissions and energy consumption were also
raised as the commerce of Metaverse is solely based on
cryptocurrencies. However, it has been highlighted by several
studies that the Metaverse holds potential for reducing carbon
reductions through virtual interactions, replacing physical with
digital goods, and digital twins, respectively. Furthermore, it
has also been suggested that Metaverse, through immersive
experience, can help overcome behavioral hurdles concerning
climate change.

With the announcement of Metaverse,

Most of the studies use sustainability in the context of
environment, however, sustainability should also be addressed
from social point of view. Metaverse can help in enhancing
social sustainability by bringing equity,
inclusiveness, and
accessibility on the table. It
is the responsibility of the
businesses and all stackholders involved to develop strategies
and utilize Metaverse for improving both the environmental
and social sustainability, respectively. This section brieﬂy
discusses the correlation between sustainability and Metaverse
with the use of Digital-Twins and Industry 5.0. The topics
covered in this subsection are summarized in ﬁgure 15.

A. Virtual Resources in Metaverse

The core assumption and intuition of Metaverse being
sustainable lies in the fact that it can use virtual and digital
alternatives as a substitute for real-world experiences and
physical goods. It is assumed that the virtual experiences and
digital products will be carbon-efﬁcient and less resource-
intensive in comparison to their counterparts. A paradigm
in terms of budget allocation from consumers have
shift

Fig. 13. FL architecture and distributed training procedure in Metaverse.

actions and feedback should be much lower than the physical
world reaction times [12]. For this reason, it is necessary that
the TI has a 1ms delay due to the nature of the haptic signals
and how humans perceive them. There is, however, a limit to
the latency that can be supported by pre-5G networks, which
is approximately 25ms [13]. Therefore, B5G/6G networks
are anticipated to outperform previous generations in terms
of performance by providing a sustainable infrastructure that
will ultimately realize the TI for immersive services. 5G can
aid in TI realization for Metaverse by addressing the key
communication and computation challenges leveraging the
following 3 important enabling technologies: edge computing,
network functions virtualization (NFV), and software-deﬁned
networking (SDN) [222]. These enabling technologies can be
combined in order to provide sophisticated solutions for the
network architecture. For instance, researchers in [223], [224]
explore how SDN can be leveraged efﬁciently for the edge
computing based 5G networks. In another study by Aijaz et
al. [15], authors investigate how edge computing, SDN, and
NFV can be utilized to create a novel, sustainable and general-
purpose 5G architecture to realize TI applications. In essence,
their approach is motivated by the virtualization concept of
NFVs, which can dynamically instantiate an end-to-end 5G
network according to the user’s applications’ requirements.
Therefore, it can be observed that bringing computing capabil-
ities closer to the user equipment and using SDN to control it
centrally (i.e., limiting intermediate nodes) can foster latency
reduction through edge computing and SDN [224], [225]. It
is also important to stress that the TI should not be limited
to the context of 5G, as discussed above in relation to the
Tactile Internet and 5G, but that it should take a broader
position than that. Many research efforts are underway that
aim to achieve the TI over other technologies (e.g., wireless
communication with sub-GHz technology, wireless local area
network (WLAN) and wireless body area network (WBAN),
and combinations of technologies similar to these). Despite
5G’s potential to enable URLLC applications in general, as

Edge ServerSelection & Configuration 1Local UpdatingAggregationModel Feedback4Model UpdatingModel/Knowledge Transfer63253636G RAN16G RAN2Edge Server25224445Cloud Data Centers665EducationShopping Social Networks Tele Surgery1111542JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

25

AI for Immersive
Wireless
Applications

Computing and Caching

Resource Allocation

Network Slicing
and/or Automation

3D Networking and/or
Ubiquitous Coverage

Cai et al., 2022 [240]

Chien et al., 2020 [239]

Dang et al., 2019 [238]

Erol-Kantarci et al., 2018 [194]

Han et al., 2022 [205]

Du et al., 2022 [237]

Yang et al., 2020 [236]

Chen et al., 2018 [235]

Liu et al., 2022 [234]

Sohaib et al., 2021 [233]

Xu et al., 2021 [232]

Kasgari et al., 2018 [231]

Tang et al., 2022 [30]

Zhang et al., 2020 [230]

El saer et al., 2020 [229]

Chen et al., 2019 [228]

Fig. 14. Taxonomy for the classiﬁcation of literature on AI-empowered Immersive Wireless Experiences.

already been noticed that shows positive signs for a signiﬁcant
sustainability impact. For
instance, Denim trade globally
consumes 4.7 billion m3 of water while emitting 16.0
metric tons of carbon dioxide equivalent (MTCO2e) [241].
If consumers opt for a digital denim for their avatars instead
of buying the physical one, it can save substantial amount of
water and carbon emissions. According to a study from EY
Future Consumer Index38 21% of Metaverse consumers intend
to buy digital items for their avatars in future rather than
investing in physical items. The study [241] suggested that the
transition to virtual denim from physical one can reduce the
CO2 emissions by 10% which is equivalent to annual water
consumption and annual emissions of around 350K internal
combustion of automobiles in America [242], [243]. Consid-
ering that a digital transformation from a single product could
impact the resource and carbon efﬁciencies in a signiﬁcant
way,
the Metaverse is a potential
candidate to achieve the required environmental sustainability.

it can be assumed that

B. Travelling through Metaverse

Globally, air travel contributes to 2.5% of CO2 emissions
but it was cut in half due to the COVID19 pandemic [244].

38https://www.ey.com/en gl/consumer-products-retail/future-consumer-

index-moving-out-of-brands-reach

One of the earliest applications of Metaverse was to conduct
a virtual meeting with a realistic VR experience. Recently,
virtual concerts (Metaverse-based concerts) was organized
which was attended by thousands of people in a virtual world
[245] that indicates that both the business and recreational
travel can be replaced by Metaverse to a certain degree.
Furthermore, with such an immersive experience, companies
and businesses can promote the work-from-home culture to
cut CO2 emissions. Although, physical collaboration and
personal presence is important and recreating a live gathering
would not be as real in Metaverse as it is in physical world,
we assume that
the Metaverse is not here to completely
replace it. Rather it can be considered as an effective tool to
reduce complexity and expense of discretionary trips while
maintaining environmental sustainability.

C. Digital Twins and Metaverse

Digital twins is the biproduct of emerging technologies such
as AI, IoT, and augment and virtual reality. With the satellite
generated data, digital twin can transform the real-world enti-
tites into virtual representations, hence propelling sustainabil-
ity with respect to individuals, manufacturing assets, supply
chains, and so forth. Currently, there are many applications
streamlined that use digital twins to improve the environmental
sustainability. For instance, European space agency is working

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

26

Fig. 15. Summarization of Sustainable Metaverse

towards a system that can represent Earth’s digital twin to
study human activities and its impact on the climate. The
simulation model will then be used for making policies to
ensure the improvement in environmental sustainability. Sim-
ilarly, using digital twin for supply chain and manufacturing
can improve the optimization for logistics, traceability, energy,
processes and material inputs, accordingly. Many industries
have already started to adapt digital twin in order to reduce en-
ergy and scrap usage that contribute directly to environmental
sustainability [246]. Digital twins have also been widely used
for medical records, modeling data from wearable sensors and
forecast individual’s health with respect to air pollution and air
quality [247]. However, the digital twins have achieved best
environmental sustainability in the ﬁeld of building operations
that could help in improving space utilization by 25%, human
productivity is increased by 20%, maintenance and operational
efﬁciency has been improved by 35%, and lastly carbon emis-
sion for a building can be reduced by around 50%, respectively
[248]–[250]. In recent interviews, Michael Jansen the CEO of
Cityzenith (that is involved in making smart and sustainable
cities throughout
the world) has argued that urban digital
twins and real-world Metaverse are synonymous and therefore,
Metaverse would help in dealing with multisystem simulation
and visualization of buildings and environment in digital space.

D. Penetrating psychological barriers through Metaverse

It has been suggested by many studies that environmental
sustainability and climate change are highly correlated.
Companies and industries might have the power to slow down
the carbon emissions, however, the masses or general public
can be equally held responsible for using the items that are
not ecological friendly. Although, past years have recorded
around two billion social media posts that address the climate
conditions but a recent study showed that the general public
bases their idea of climate change with respect to normal
weather, therefore, their perception is quite short-term, i.e.,
the affect that started to come in play since 2 - 8 years [251].

The use of Metaverse for providing immersive experience and
simulation of climate change can tap into consciousness of
general public to spur the action towards usage of eco-friendly
products, hence, reducing the carbon emission footprint. The
relationship of virtual reality and climate change psychology
has been carried out and addressed in a recent study by
Marowitz [252] to compel
the general public for opting
proenvironmental actions, respectively.

E. Social Sustainability with Metaverse

Most of the sustainability issues are centered towards
its environmental aspect, however, Metaverse addresses
the unsustainable social aspects of
the physical world
and coalesce social rights such as diversity, accessibility,
and equity within its ecosystem. The same was recently
highlighted by the Chief Diversity Ofﬁcer, Maxine Williams
by her statement “Diverse people shouldn’t just participate in
the Metaverse as consumers; they should be its architects and
builders as well”39. Recently, a bloomberg report [253] also
highlighted this issue concerning CryptoPunk NFTs stating
that
the digital avatar prices varied based on skin color,
gender, and race, accordingly. Companies like OvalEdge40
have identiﬁed the problem as unconcious bias which is
quite similar to the ones associated with AI models. The
company suggest to use metrics and comprehensive set of
targel goals for the data scientist
to reduce the bias and
increase accessibility in Web3. Furthermore, stakeholders,
investors, regulators,
civil society organizations, academia,
and businesses need to collaborate on this matter to make the
Metaverse more democratized instead only decentralized.

F. Sustainable communication and connectivity

The ﬁfth generation communication system was created
with a lot of hype and ambition to bring ubiquitous

39https://tech.fb.com/ideas/2022/02/being-intentional-about-diversity-

equity-and-inclusion-in-the-Metaverse/

40https://www.ovaledge.com/

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

27

connectivity to the users. In recent Mobile World Congress
(MWC), vice president of distributed edge at VMware quoted
that “5G is another phone in hands that is no different from
LTE and 4G. The sixth generation communication system is
about putting the focus back on humanity and sustainability”41.
The discussions on 6G always
starts conversation in
accordance to human, economic, and societal development.
Furthermore, 6G emphasizes more on democratization instead
of decentralization which is one of
the major concerns
with Metaverse and its coarse to sustainability. The sixth
generation system is also being developed for achieving
less
sustainability goals through better resource efﬁciency,
energy consumption, and less power requirement, accordingly.
One of the driving forces for 6G advancement was the COVID-
19 pandemic that made researchers and people realize about
putting more emphasis on economic and societal needs of the
broadband network instead of looking for nice presentation
of devices and better performance. The 6G and metaverse
are a good match for sustainable due to its characteristics of
democratization and keeping human in the loop while breaking
temporal and spatial barriers for multi-person communication.

VII. APPLICATIONS AND USECASES

A. What Are the Use Cases of the Metaverse

1) Metaverse and Physical wold: How Do They Interact:
To understand the different uses of the Metaverse, one must
ﬁrst know what it is. Users can interact with varying spaces as
their digital avatar in the Metaverse, an immersive 3D virtual
world. Metaverse users can move around different areas as
their digital avatars, just like they do in the real world. Users
can also create, share, or trade experiences and assets using
the Metaverse [254]. Recently, the proverbial Metaverse was
rumored worldwide, and people are taking a great deal of
interest in its use cases. Many companies, such as Facebook,
noticed it unveiled Meta as the brand name of their parent
company at the Facebook Connect event in late October 2021.
Social media giant Biggie has recently launched Metaverse
tools for developers as well. There are three components to
it, including a Headset, Presence Platform, and developers’
AI toolkit. The interaction of VR/AR objects with users
can be programmed. Similarly, Microsoft has invested in
Metaverse to create an environment that fosters collaboration
with Microsoft Mesh. Almost all major
tech companies
have jumped aboard the Metaverse bandwagon, doubling the
demand for Metaverse use cases.

B. Usecases

Having a basic understanding of the Metaverse and why it is
gaining popularity, you must be looking forward to discovering
its use cases. Since the Metaverse is cutting-edge technology,
many people wonder, “What are the beneﬁts of a Metaverse?”
In what ways will you use the Metaverse to your advantage?
What roles will digital reality play in the real world? From
identity veriﬁcation to payments, the world around us has be-
come more and more digital [255]. In turn, a digital world like
the Metaverse makes it possible for individuals and businesses
to change how they view and use technology. Below are some
examples of how the Metaverse could be used [1], [256].

41https://www.trendingtopics.eu/how-will-6g-and-the-metaverse-change-

the-world/

1) Unlocking Marketing Prospects: A possible use case for
Metaverse would be the possibility of unlocking new market-
ing opportunities [36]. People can interact with digital avatars
to do many things in the virtual world. Furthermore, people
engage in the Metaverse’s socializing, leisure, and learning
activities. Marketers could take advantage of exclusive market-
ing opportunities in different virtual worlds in the Metaverse.
Marketers have already taken advantage of in-business oppor-
tunities in the Metaverse. Such as Anzu, which uses ads to
track real-time views in gaming environments across mobile
and console platforms. Also included in this list are brands
like Paramount and WarnerMedia. In the Metaverse, the ads
are reminiscent of real-life, and they are intertwined with the
gameplay, where the ads can be found at the right places. For
instance, billboard ads or characters wearing branded clothing
offer promising brand exposure. Metaverse games have proved
how Metaverse can open up new marketing prospects [257].
2) Blockchain Use Cases: Blockchain applications could
provide advanced technology as the most prominent use
case in the Metaverse [6]. Decentralizing the Metaverse
through the adoption of large-scale Metaverse across various
industries
the large-scale
Metaverse. Blockchains enable the development of dApps and
NFTs, power cryptocurrencies, and function as a distributed
ledger for recording peer-to-peer transactions. Blockchain
technology offers several beneﬁts for engaging the NFT
marketplaces fostering new and realistic avenues [258]. Users
can communicate with other users and share more interactive
Metaverses in the NFT marketplaces. Users can interact
with NFTs to make informed purchasing decisions via the
Metaverse. Metaverse blockchain application cases include
the promotion of new NFTs or the development of a shared
virtual area. The blockchain-based games trend has attracted
a great deal of traction. Players in NFT or blockchain games
can gain various in-game collectibles to exchange with other
players or on external marketplaces. The Metaverse can
power Blockchain-based online gaming [42].

foundation for

is a powerful

3) Virtual Tourism: Virtual tourism is another promising
use case of the Metaverse [259], [260]. The development of ad-
vanced technologies has led to the point where one can enjoy
traveling without physically reaching the destination. There
is a big difference between experiencing such destinations in
person and watching them on video. The Metaverse could be
used to create immersive digital environments through virtual
reality (VR) [56], [57], and augmented reality (AR) [58]–
[60]. You may stir your audience’s imagination by merging
immersive digital reality with real content. As a result, people
can experience their environment as physically present. The
possibility for widespread adoption and acknowledgment of
VR tourism is a possible mainstream use case. There is an
increasing amount of 360◦ video content on video streaming
platforms such as YouTube and other content hosting services.
A serious drawback of using Metaverse for virtual tourism
is its limited freedom, as you can notice with the use cases.
Tourism destinations are not ﬂexible enough to allow people
to move around since they can only be viewed recorded.

4) Web Real-time Communication: A Metaverse can
also facilitate real-time communication in web experiences,
based on the search for blockchain use cases in a [48]. A
real-time communication initiative for mobile applications
and web browsers is known as real-time web communication.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

28

One of the most intriguing applications is the Metaverse to
transform traditional audio and visual communication. You
can transfer information between clients through real-time
web communication without requiring an intermediary server.
Thanks to peer-to-peer communication in the Metaverse
[261],
could
become possible. In addition to providing a platform for
designing new web communication standards, the Metaverse
technology offers an intriguing application case. Web real-time
communication can also be combined with numerous media
streams, which is important for constructing virtual worlds.

communication

browsers

between

direct

5) Virtual Ofﬁce and Learning Spaces: Remote working
grew as a result of a global pandemic. The pandemic exposed
professionals from various sectors to Skype calls, Microsoft
Teams, and Zoom meetings. Remote professionals were able
to communicate virtually with these tools [262]. Metaverses
offer many possibilities for developing virtual ofﬁce spaces
or learning environments [263], [264]. Working or learning
together in the Metaverse is possible if you feel like you are
in the same room. Virtuworx, for example, has created virtual
ofﬁce spaces by leveraging Metaverse use cases. With its
hybrid of virtual and mixed reality environments, the company
offers a meaningful and productive work environment. Team
members can access various functions such as events, ofﬁces,
conferences, virtual training, and trade exhibitions by using
a completely conﬁgurable solution. Metaverse beneﬁts are
found in the education sector as well. Minecraft and Second
Life have been used to improve student learning experiences
in universities. Students in architecture and medicine may
also beneﬁt from VR simulations in the Metaverse.

C. Beneﬁts of Metaverse

It is equally important to know the beneﬁts of the Metaverse
after understanding its use cases. In the different examples
of how a Metaverse might be used, an impression can be
gained of its potential advantages [3], [261]. As technology
advanced, it answered many uncertainties like who would
have imagined that people could make video calls over long
distances to share data in seconds. If someone wondered about
the beneﬁts of the Metaverse in the past, you might not have
found many answers, but at the moment, they seem evident to
everyone. However, virtual spaces and digital communication
avenues are used by millions of people worldwide to socialize
remotely. Beyond adding real-world capabilities to virtual
worlds, Metaverse has several beneﬁts for the digital world.
Here are a few of the Metaverse technology’s key advantages.
1) Innovation in Healthcare: To understand how healthcare
sectors ﬁt
into the Metaverse, we need to examine their
promising beneﬁts. For example, the Metaverse provides a
unique opportunity for patients to interact with healthcare
professionals regardless of their geographic location [265].
Healthcare professionals can interact with patients in virtual
worlds in real-time through the Metaverse.
In addition,
medical students can engage in engaging and comprehensive
learning experiences through virtual reality simulation in the
Metaverse [266].

2) Metaverse and Exciting New Games: The Metaverse
will play a crucial
role in gaming applications through
play-to-earn models, which enable developers, publishers,
and users to reap economic rewards from gaming experiences

[257], [267]. On different online marketplaces, gamers can,
for
the
instance, create and trade in-game assets. Thus,
beneﬁts of decentralization inherent in blockchain combined
with Metaverse can revolutionize gaming.

3) Completely New Economy: One of the most prominent
assumptions about
the Metaverse is the possibility of a
creator economy. Trading assets across different spaces is
made possible by the Metaverse [268], [269]. On another
platform in the Metaverse, you can sell an NFT you created
in a Metaverse game. A great deal of economic growth can
be attributed to DeFi, NFTs, and blockchain games.

D. Metaverse Market: State of the Art

Without reﬂecting on the state of the current Metaverse,
many people are intrigued by the question, “is the Metaverse
the next Internet?” What number of projects are currently
being developed? Is the Metaverse attracting attention from
big names? Take Facebook, for example. Can we expect
other tech giants to pay attention? There must be multiple
organizations, creators, and developers creating the Metaverse,
no matter who owns it. Metaverse adoption will also be
mainly determined by its names. These are some of the top
companies that have begun to develop a Metaverse [270].

1) Facebook: Many tech enthusiasts have viewed Face-
book’s Metaverse announcement as a PR stunt. It is crucial to
consider how a tech giant like Facebook can help create a more
promising market for the Metaverse. Furthermore, Facebook
has almost all of its resources to develop the Metaverse,
from infrastructure to human interaction to discovery [271].
The online networking behemoth has a massive advertising
engine, Oculus headsets, and a burgeoning creator economy.
2) Epic Games: Epic Games, a well-known game
in the
production studio, competes
Metaverse’s future. Epic Games co-founder Tim Sweeney
outlined a vision for the Metaverse a few years ago, and now
the ﬁrm has the appropriate platform for it to thrive. Epic
Games can potentially grow Metaverse growth with 1 billion
dollar in funding from Sony in the future [272].

for high positions

future. Microsoft

3) Icrosoft: Microsoft’s efforts to develop the Metaverse
cannot be ignored under any circumstance. The involvement
of companies like Microsoft assuages concerns about
the
is constructing Microsoft
Metaverse’s
Mesh, a business-focused Metaverse [273]. Users would
be able to connect to Microsoft products through a digital
environment seamlessly. Using Microsoft Mesh, users can
leverage Windows, Teams, and other services through VR.
4) Decentraland: Decentraland is an example of
the
resiliency of the Metaverse market. Metaverse is one of
the ﬁrst pioneering products that explicitly mentions the
Metaverse. Users can trade in virtual real estate and create
NFTs on Decentraland, developed in 2017. A recent auction
in Decentraland featured virtual real estate worth more than
2 million [274], [275]. This means Decentraland is likely to
become one of the top names in the Metaverse of the future.
Microservices and blockchain technologies are also included,
along with edge computing and AI agents.

VIII. PROJECTS
An interconnected network of 3D virtual worlds is one way
to deﬁne the concept deﬁnition of the Metaverse. Through a

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

29

TABLE VII
ONGOING METAVERSE PROJECTS

Project Title

Decentraland

Oculus (Meta Quest)

Enjin

Silks

University of Miami
- XR initiative
MirageXR
Highstreet

Metahero

Project sub-title
Virtual advertisement for content,
goods and services
Meta’s Metaverse platform -
VR equipment, experiences and games
NFTs for everyone
Horse racing and bidding in
Metaverse through NFTs

Project Length

2015 - ongoing

2014 - ongoing

2009 - ongoing

Upcoming (2022 - 2023)

Project URL

https://decentraland.org/

https://store.facebook.com/quest/

https://enjin.io/

https://silks.io

Multiple XR and Metaverse based projects

2018 - ongoing

https://xr.miami.edu/projects/index.html

Learn through holograms
Metaverse shopping and product showcases
3D scanning of humans to create their
own NFT avatars for Metaverse

2021- ongoing
2021 - ongoing

2021 - ongoing

https://wekit-ecs.com/team
https://www.highstreet.market/

https://metahero.io/

virtual reality headset, users enter these worlds, navigating the
Metaverse with their eye movements, feedback controls, and
voice instructions. The user is submerged by the headgear,
producing a phenomenon called presence, which is achieved
by simulating the genuine physical experience of being
present. But before the Metaverse is widely and universally
adopted, there are obstacles to be resolved. The virtual aspect
of this environment is a signiﬁcant obstacle. Although a VR
headset is often required for entry into the Metaverse, this is
not the only need. It is expected that the Metaverse industry
will overcome these challenges as there is a tremendous
growth in the sales of headsets supporting Metaverse concepts.
There are many players entering into the Metaverse
universe in the recent years. The few signiﬁcant ongoing
Metaverse projects are shown in Table VII.

A. Decentraland

a

is

Decentraland

decentralized

blockchain-based
Metaverse. Decentraland focuses on creating, exhibiting,
and selling real-world and NFT assets. Decentraland is
governed by a Decentralized Autonomous Organization
(DAO), which owns the necessary smart contracts based on
which Decentraland operates. Users can vote using the DAO
system to inﬂuence the various aspects of the Metaverse.
The assets can be bought using multiple currencies, such
as polygon and ethereum, while the parcels of land on the
Metaverse can be purchased only using ethereum.

Major brands such as Samsung, Atari, and Adidas have
bought plots of land in Decentraland and established their
products’ showcases. The various brands in the Decentraland
perform live events and immersive experiences. For example,
Samsung recently hosted a live event of their Galaxy S22
unveiling in the Decentraland.

B. Oculus

C. Enjin

Enjin is a marketplace and platform that deal with the
creation of NFTs for Metaverses. The Enjin provides Software
Development Kits (SDKs) that support these activities. Enjin
works with two different types of currencies - Enjin token
and Enjin coin. Furthermore, they provide integration support
to integrate the trading of the created NFTs inside your
Metaverse applications. Examples of Metaverses running
on Enjin platform are AlterVerse, MotoBloq and Dvision
Network. Enjin also actively funds Metaverse projects and
such projects can apply for funding through their website.

D. Silks

Silks, a game platform for the Metaverse, mimics the
thoroughbred horse racing industry in real life with the use
of a blockchain-enabled Metaverse. A play-to-earn gaming
economy powers the Silks Metaverse, enabling people to own
racehorses and horse farms while earning tokens via skillful
games and contributions to the Silks ecosystem. The users will
be able to purchase, gather, exchange, and interact with digital
assets that reﬂect genuine thoroughbred racehorses. Users will
also be able to buy, build, and maintain horse farms, other real
estates, and interactive digital assets. The project is underde-
velopment and is expected to be fully functional by 2023.

E. XR initiative

XR initiative is a initiative from Miami University to
explore use cases of XR and VR and their interoperability.
The XR initiative is signiﬁcant since it focuses on non-gaming
domains such as education and healthcare. Though the XR
initiative is not a complete Metaverse of its own, the various
projects provide a possible look into the utility and usecases
of Metaverse in the future. The projects part of this initiative
include anesthesia training for nurses and technological
training for persons suffering from autism spectrum disorder.

Oculus is the online platform that holds the experiences and
games accessed through Meta’s VR headset platform (Quest).
Though it is not a Metaverse of its own, it provides a variety
of backgrounds and games that can be experienced through
the headset. The signiﬁcance of Oculus is that it serves as
the ground for Meta’s future planned expansion into the
Metaverse concepts. Hence, it is vital to closely monitor the
developments in Oculus even though it is not a Metaverse yet.

F. MirageXR

MirageXR enables educators and developers to create
unique holographic training programs, enhancing workplace
efﬁciency, enabling data analysis to evaluate performance,
and assisting industrial organizations in saving money on
training expenses. The app’s core is technology-enhanced
learning, which helps users go beyond simply remembering

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

30

and comprehending the content of learning exercises by
actually performing the action themselves.

The project’s authoring and performance analytics capa-
bilities allow AR course designers to update activities, gauge
engagement quickly, and assist
learners in analyzing their
actions by recording practice sessions to enhance practice.

G. Highstreet

A Metaverse with a focus on business. Web browsers
can be used to access the market. The Metaverse promises
to interact with famous people who will
possibilities
introduce their brands on the Highstreet. There are face-to-
face interactions available in the Highstreet Metaverse. The
Highstreet is home to a unique cryptocurrency lounge where
customers may exchange digital currency in a virtual reality
setting. Every item sold on Highstreet is displayed to the
customer in both digital and physical forms, connected via
a product token. In addition to being able to wear a pair of
shoes the user purchases in the real world, they may also be
added to their avatar’s wardrobe in the Metaverse.

H. Metahero

The Metahero project employs NFT smart contracts and 3D
scanning technologies to enable the development of unique
meta avatars and meta-objects. Metahero’s
fundamental
technology is 3D scanning, which examines physical objects
to gather information about their appearance and digitally
depict them. Wolf Studio and Metahero have a partnership for
3D scanning. The concept of Metahero is to scan the user’s
body using 3D scanning machines and then create realistic
NFTs. These NFTs will be utilized as the users’ avatars
inside the Metaverse. The project is in the development stage,
where the users can sign up to be notiﬁed if a scanner is
available near their location.

IX. CHALLENGES AND FUTURE RESEARCH DIRECTIONS
This section discuss and enlist the foreseeable challenges
and future research trends concerning the role of AI, B5G/6G,
and their interplay in Metaverse.

A. Role of AI in Metaverse

This

subsection highlights

foreseeable challenges and

future directions concerning the role of AI in Metaverse.

1) Integration with Emerging Technologies: It is apparent
from the growth of Metaverse that more and more users
will explore and adapt to the aforementioned technology. In
order to handle scalablility, Metaverse needs to integrate with
emerging technologies such as 5G/6G, Industry 5.0, Internet of
Aerial and Ground Vehicles, and so forth. The repercussions or
issues that may arise from such integration are yet to be seen
but we can assume that the heterogeneity, bandwidth manage-
ment, energy efﬁciency, and security would be a few of them.
2) Unique Immersive Experience: Metaverse is knwon for
realistic and immersive experience in digital world. However,
the users will demand
as the marketplace gets saturated,
for unique aspects such as new digital
landscapes, more
interactive spaces, experiences based on reality, and real-time
emotion mapping in digital world. Few of the aforementioned
issues can be handled by large language models and methods

like Dall-E, but these models and methods are not publicly
accessible. Furthermore, the usage of these models cannot
be handled by hand-held devices, therefore, the challenge of
designing platforms that could provide mutual services and
solutions will be in dire need.

3) Democratization: From the review of seminal works,
it has been revealed that the Metaverse is far from being
democratized at this point. With the growing and diverse users,
Metaverse will have to opt for democratization in order to
maintain sustainability. Researchers have suggested to use AI-
based smart contracts to detect anomalies, but that is yet to be
achieved, and the outcomes are yet to be realized. AI is itself
subjected to biases, therefore, humans in the loop for making
the process of democratization bias free needs to be integrated.
4) Intellectual Property Preservation: Metaverse has
been mainly introduced as an extension of our reality. This
extension brings forth the businesses challenges that exist in
the real-world such as brand protection, copyright issues, theft
of intellectual property and more. Due to being in a digital
space, the counterfeiting in Metaverse would be much easier,
and reproducibility of the trademarks in the form of virtual
images or NFTs would be much cheaper. The challenges for
this category are not only related to AI, but also the law
enforcement agencies and intellectual ﬁling ofﬁces. Further-
more, methods needs to be devised to confront anonymity
in the Metaverse as it will hinder the most for content and
brand owners to enforce their intellectual property rights.

B. Role of B5G/6G in Metaverse

This subsection highlights foreseeable challenges and future

directions concerning the role of B5G/6G in Metaverse.

1) Massive, Highly dynamic, and Complex Metaverse: It
is beyond question that Metaverse will be build on top of the
highly dynamic, massively dense, and exceptionally complex
mobile networks. These networks will be composed of ultra-
large scale and inherently heterogeneous equipments. There
are, however, many features that are ﬁxed in the architecture
of current wireless networks, and the optimization tasks are
thus deﬁned to address particular challenges and services that
have been identiﬁed and deﬁned in advance [276], [277].
Consequently, the existing process of manually optimizing
and conﬁguring networks is not suitable for the Metaverse.
Further, the original 5G service classes will be challenged by
new immersive experiences such XR gaming, teleoperations,
and holographic telepresense that will become available soon
in the context of Metaverse [278]. Therefore, future mobile
networks have to simultaneously deliver high transmission
rates, high reliability, and low latency in order to effectively
provide aforementioned Metaverse services.

2) Zero-touch Management for Metaverse: Future wireless
networks for Metaverse will not rely on manual interventions
to avoid any minacious possibilities. Hence, ZTM will play
a useful role by controlling, monitoring, and conﬁguring
the tasks for massive networks to attain a fully independent
closed-loop automation by alleviating any opportunities of
In current wireless networks,
human intervention [218].
ZTM has been enabled for speciﬁc 5G/6G usage scenarios
[220]. However, Metaverse will expose diverse requirements
application. Hence
occurring from heterogeneous user
the
it demands for a universal ZTM strategy to meet
requirements of several verticals in Metaverse.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

31

C. Integrated Role of AI and 6G in Metaverse

This

subsection highlights

foreseeable challenges and
future directions concerning the integrated role of AI and 6G
in Metaverse.

1) 6G-enabled Edge AI in Metaverse: It is anticipated that
Metaverse will bring a complete shift of AI from cloud to
the network edge, hence achieving on-device intelligence for
Metaverse services. Edge AI can certainly beneﬁt Metaverse
in achieving low latency response while ensuring privacy of
the user’s data [38], [283], [284]. However, the ofﬂoading of
Metaverse services will pose severe challenges for the existing
wireless networks. For instance, Metaverse users based in
remote regions with poor Internet connectivity might face a
disconnect due to high latency. For mission-critical applica-
tions, this latency can potentially lead to worse consequences.
Hence, modern communication systems can leverage 6G-
uMBB services to support Metaverse applications on the end
devices [285]. Edge caching can also be explored to further
reduce the transmission latency. Furthermore, Metaverse will
enable collection of sheer amount of hetrogenous data (due to
diverse users/services), hence edge devices can leverage the
federated learning to perform model training locally without
violating any privacy laws as shown in Figure 13.

2) AI-based Network Automation for Metaverse:

In a
Metaverse composed of heterogeneous users and services,
the network automation will be of key importance for
delivering seamless QoE to users. AI has to play a vital
role in enabling self-adaptive capabilities in 6G networks.
Recently, AI-based frameworks have been widely used for
empowering automation in 6G networks by allowing them
to self-allocate, self-conﬁgure and self-optimise the network
equipment and resources [219]. However, as anticipated
in Metaverse, these abilities can be hindered by following
challenges when leveraging AI:
• Lack of labeled training data to update the AI model given

the changing context

• The complexity of underlying deep learning models to be

ported on resource-constrained devices

• The limitation in availability of hardware to support new

and emerging intelligent services for Metaverse
To address the aforementioned challenges,

the possible
research directions would be to adapt self-supervision learning
techniques for training AI models, and distributing the AI
models in the end-edge-cloud continuum to alleviate the
computational load on end/edge devices.

3) Energy efﬁcient AI and 6G for Metaverse: Energy
efﬁciency will
remain amongst key KPIs for Metaverse
developers when proposing AI and 6G driven solutions. Based
on the integrated role of AI and 6G, as discussed in section
V, it can be said that both will be highly utilized for delivery
of immersive services in Metaverse while tackling the density
and mobility of users. However, in order to meet the Metaverse
requirements for ubiquitous intelligence from anywhere at
anytime, 6G networks will require abundant resources and
the resources
their maintenance [250]. While some of
might be highly leveraged,
the others will rather remain
redundant or unutilized most of the time, hence consuming
the equivalent energy. To address this, network resources
should be either adaptive or designed speciﬁcally according
to the energy requirements of a certain Metaverse application

Fig. 16. Some KPIs and requirements for evaluating the immersiveness in
a Metaverse environment [281].

3) Space-air-ground-sea coverage for Metaverse: The
space-air-ground-sea integrated communication network will
empower Metaverse in two folds:
• Non-terrestrial networks will provide ubiquitious wireless

access to users from anywhere at anytime [279].

• Terrestrial networks will support Metaverse users to hop
freely among space-air-ground-sea intergrated networks for
an uninterrupted immersive experience [30], [280].
However, the highly frequent ﬁdelity of momentous data
among space-air-ground-sea can cause signiﬁcant delays
requiring massive bandwith and overwhelming backhaul
resources [170]. Thus,
it becomes imperative to explore
new SAGSIN architectures and simulation platforms to
underpin the diverse and extensive services and applications
of Metaverse. Further, reliability could be compromised in
existing SAGSIN architectures due to highly mobile nature of
satellites which may eventually cause disruption to Metaverse
applications. Hence, novel reliability evaluation metrics are
needed to be designed for future services of Metaverse, as
proposed by researchers in [281]. Figure 16 shows some of
the requirements for seamless meta-immersion and indicators
to evaluate the performance of services.

4) Tactile Feedback in Metaverse: It has been discussed
IV-D and V-C that certain applications of
in sections
Metaverse, such as robotic surgery, avatar-to-avatar interaction,
teleoperations, and telepresence need to rely on every tiny bits
of tactile information occuring from the interaction between
physical and meta environment in order to function normally.
Although IEEE introduced a standard for tactile Internet
(IEEE P1918.1) to normalize such activities, however, the
requirements of tactile feedback are ultra-low latency such as
in milliseconds [222]. The existing 5G-URLLC usecases are
expected to meet these requirements. Irrespective of that, the
tactile Internet poses a number of potential research challenges
that have yet to be fully addressed, particularly in the context
of Metaverse. For example, efﬁcient
routing and MAC
protocols for delivering tactile information can be proposed
for Metaverse usecases [282]. In addition to that, intelligent
and adaptive network trafﬁc management can be explored
for delivering multi-sensory audio-visual tactile information
over wireless networks. Lastly, the computing capabilities can
be accelerated for immersive services by apply compression
techniques as pro-processors for tactile information.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

32

[218], [220]. Moreover, since most of the intelligence will
be hosted locally, it will consume relatively higher energy
than cloud-based intelligence, and will eventually cause the
batteries to drain faster. In such cases, the end devices should
be capable of harvesting energy from their surroundings in
order to remain self-sufﬁcient [286]. Apart from that, modern
AI models require signiﬁcant energy for their execution due
to their nature of being highly parameterised. Therefore, a
potential research direction would be to either remove the
redundant parameters from AI models by trading the accuracy
or adaptively ofﬂoad the models to edge or cloud based on
the intermittent energy available on the devices.

D. Sustainable Metaverse

This subsection highlights the foreseeable challenges and

future directions concerning sustainable Metaverse.

to the environment

1) Climate Change: Although the Metaverse has the
potential to reduce carbon emissions, substantially through
the virtual interactions and digital presence, but it can also
be harmful
if used improperly. For
instance, with the emergence of Metaverse, there would be
a need to powerup data centers, thus the companies adopting
to hyperscale data centers
Metaverse would need to shift
for meeting energy demands. Furthermore, most of
the
ecommerse associated with Metaverse is performed through
NFTs and blockchain based processes which is an energy
intensive process. Metaverse would need to move towards
proof-of-stake where the transactions are concerned as they
are less energy intensive. Furthermore, AI can be used to
optimize the efﬁciency gains while proof-of-stake transactions
are performed to further lower the energy consumption.

2) Digital Divide: Studies have suggested that certain
part of societies have better access to technology, therefore,
the introduction to new technology in the market foster
homogeneity instead of diversity. For instance, statista reported
that Western Europe and North America makes up almost 90
percent of the VR set sales42. Very recently, PR Newswire
suggested that North America will be the epicenter of
Metaverse growth in next four years43. In order for Metaverse
to be compliant with sustainable development goals, it needs to
move forward towards equitable distribution of the technology,
thus, lowering the digital divide in the digital world.

3) Resentment and Division: Currently, the Metaverse is
considered to be an extension of our reality or a digital space
which is not dependent on the current mental state. However,
continuous exposure and overuse of the Metaverse can create
societal implications such as creating a parallel reality that
affects the mental state and well-being of an individual. In
it needs to undergo
order to make Metaverse sustainable,
governance and audit, so that an individual’s mental state
should not be overwhelmed and the individual’s perception
of digital world, i.e. Metaverse should be disjoint from its
physical state, accordingly.

42https://www.statista.com/statistics/685774/ar-vr-headset-sales-share-by-

region-worldwide/

43https://www.prnewswire.com/news-releases/Metaverse-market-38-
of-growth-to-originate-from-north-america–information-by-device-vr-
and-ar-devices-and-computing-devices-and-geography–forecast-till-2026-
301531082.html

4) Security and Privacy: The Metaverse not only collects
two-dimensional Internet data but also the three dimensional
serious
if
environment data, which,
implications in the physical world. Furthermore, the Metaverse
enables the users to create their multiple personalities which
can elevate the challenge of security and privacy to manifold.
The use of AI and blockchain for not only managing person-
alities, identities but also that governance, data ownership,
authentication and transactions needs to be undertaken.

leaked can have

X. LESSONS LEARNED

Based on the systematic review and tutorial like information
lessons and

the practical

presented in previous sections,
recommendations are as follows:

let

and

1) Art

Immersive Experience: A continuous
advancement has been recorded in the ﬁeld of AI,
it
be in the form of self-supervised learning, explainable AI,
generative adversarial networks, variational autoencoders,
transformers, or large-language models [118], [119], [121].
All of the aforementioned methods have been used in some
capacity or another to make the visualization of images/frames
better and unique. Recently, large-language models such as
Dall-E2 [120] has taken the Internet by storm with the
creation of realistic images via language understanding. It
will help not only with the creation of scintillating art but
also unique visual experience for the users.

in order

2) Circular Economy: In simple words, circular economy
is all for producing waste and circulating materials and
products
to preserve nature. Although many
companies have move towards eco-friendly products but the
impact is not substantial. We have discussed as to how the
travel reduces CO2 emissions. In 2017 alone, the conference
and exhibition industry was estimated to be 2.5 trillion dollars
of worth, which requires substantial travel. Metaverse can help
reduce the air travel by making the exhibition and conference
industry digital/virtual, which will not only help in achieving
sustainable development goals but will also help in cost
savings for both the parties, hence a more circular approach
[287]. Similarly, a game could be designed that can motivate
the consumers for not using plastic items and using recycled
products for minting a fraction of a coin (mining approach).
3) Sustainability in Metaverse: It has been suggested by
researchers as well as industry personnel
that Metaverse
can help in improving overall sustainability [288]. It can be
the motivation for users to opt for digital clothing, virtual
concerts, virtual meetings, and so forth. If used the right
way, achieving sustainability through Metaverse would be
inevitable. However, it could be used otherwise to disrupt
the sustainability goals, therefore, regulations, guidelines and
laws needs to be made and enforced for making the Metaverse
a savior. Furthermore, the use of digital twins has already
proven to be a positive way towards sustainability. In addition,
the Metaverse also need to work on social sustainability so
that the virtual system could achieve democratization instead
of only moving towards decentralization.

4) Layered Security in Metaverse: Metaverse is without
a doubt a game changer but with the increasing number of
users, it will also be a nightmare for security personnel. It is
estimated that cyber crimes would increase manifold as the

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

33

Metaverse move toward commercialization. For instance, a
successful business deal can turn to a disaster if the avatar
(person) is impersonating someone else. Therefore, a layered
security will be essential
to secure the data as well as
AI methods in Metaverse. Emerging technologies such as
Federated learning, Private AI, and Blockchain along with
encryption and privacy-preservation methods would be used
to maintain security in Metaverse ecosystem [289], [290].

of

systems

5) Wireless

of wireless
on

communication
improvement

Interactivity in Metaverse: The previous
have
generations
concentrated mostly
connectivity.
However, the future generations of mobile terrestrial systems
will be blending connectivity with virtual and physical space,
as well as ubiquitous intelligence. There is a potential for the
wireless interactivity, which is made possible through future
to play an important role in
communication technologies,
the establishment of links between cyberspace and physical
space, as well as among humans. THz communication will
be particularly useful for ultra high data rate communications
within short distances that have absolutely zero error rates,
as well as high data rates [24], [26], [27]. Moreover, in the
near future, AI will have a huge impact on the future of 6G-
powered wireless communications by becoming both native
and ubiquitous, which will enable all the components of 6G to
be intelligent and user-friendly. As the Metaverse grows, 6G
is also likely to be dominated by an increase in interactivity,
which will be one of its key fundamentals [291]. 6G-based
interactivity will provide Metaverse users with multi-sensory
experiences that are immersive and tactile, hence enriching
their daily lives and enhancing their quality of life.

It

6) Diverse Service Requirements in Metaverse:

is
possible that the mobile networks will not be utilized to their
full potential due to the diverse and sometimes conﬂicting
requirements of the various Metaverse services and applica-
tions. In such cases, 6G networks allow slicing of the network
into multiple virtual and standalone logical networks while
sharing a same physical
infrastructure [190], [292]. Thus,
each network slice can be customised to serve a Metaverse
application in an efﬁcient way by taking care of the energy
efﬁciency, latency, dense connectivity, mobility, and bandwith.
A key feature of 6G networks will be the provisioning of
network slices in a dynamic manner [187]. Rather than
categorizing Metaverse applications into eMBB, mMTC, and
URLLC as in the traditional networks, 6G networks will be
capable of providing dynamic types of service depending on
the network trafﬁc and the user requirements.

7) Self-sufﬁcient

Infrastructure in Metaverse: Existing
communication and computing infrastructures are limited in
terms of scaling the services and applications according to
dynamic requirements. As an example, Facebook space (a
VR-based social network), is only able to handle a maximum
of three people to socialise in the environment it provides.
Metaverse will bring many essential use cases for which this is
inefﬁcient, including virtual classrooms, holoconferences and
events, and virtual tourism [3], [293]–[295]. With the advent
of decentralised intelligence, multi-access edge computing,
microservices, and reinforcement learning techniques, a ray
of optimism shines through the way for such immersive
applications [10], [34], [40], [195]. A Metaverse environment
supported by 6G networks will be made more responsive
by automating the wireless networks with advanced deep

learning methods.
In particular, 6G combined with the
incredible capabilities of
learning has the
reinforcement
to truly transform the existing infrastrcture and
potential
making them suitable for Metaverse environments. Moreover,
implementing AI as a native function of the network will
enable 6G to become the ﬁrst-generation network to promote
self-optimized and automated
large-scale deployment of
networks [21], [296]. As a result of the latest advances in
aforementioned technologies, practices, and methods,
the
future wireless networks will be able to co-exist according to
their state and achieve the goals set for them.

XI. CONCLUSION

This

survey paper provides a comprehensive review
on the role of AI and 6G in realising the immersive
In particular, we investigated
experiences of Metaverse.
several underlying technologies of AI and 6G, such as
advancements in computer vision, learning paradigms, and
wireless communication technologies
in the context of
Metaverse. Besides that, we explore the joint role of AI
and 6G technologies in obtaining ubiquitous intelligence,
tactile feedbacks, and self-optimising capabilities for several
Metaverse services ranging from holographic telepresence to
remote surgeries. Next, we highlight the sustainable aspect of
Metaverse services followed by the applications, usecases, and
on-going projects. Lastly, we enlighten numerous open issues,
future directions, and lessons learned for potential researchers
and developers of Metaverse applications and services.

REFERENCES

[1] L. U. Khan, Z. Han, D. Niyato, E. Hossain, and C. S. Hong,
“Metaverse for wireless systems: Vision, enablers, architecture, and
future directions,” arXiv preprint arXiv:2207.00413, 2022.

[2] H. Ning, H. Wang, Y. Lin, W. Wang, S. Dhelim, F. Farha, J. Ding,
the state-of-the-
technologies, applications, and challenges,” arXiv preprint

and M. Daneshmand, “A survey on metaverse:
art,
arXiv:2111.09673, 2021.

[3] L.-H. Lee, T. Braud, P. Zhou, L. Wang, D. Xu, Z. Lin, A. Kumar,
C. Bermejo, and P. Hui, “All one needs to know about metaverse: A
complete survey on technological singularity, virtual ecosystem, and
research agenda,” arXiv preprint arXiv:2110.05352, 2021.

[4] L.-H. Lee, Z. Lin, R. Hu, Z. Gong, A. Kumar, T. Li, S. Li, and P. Hui,
“When creators meet the metaverse: A survey on computational arts,”
arXiv preprint arXiv:2111.13486, 2021.

[5] P. Bhattacharya, M. S. Obaidat, D. Savaliya, S. Sanghavi, S. Tanwar,
and B. Sadaun, “Metaverse assisted telesurgery in healthcare 5.0: An
interplay of blockchain and explainable ai,” in 2022 International
Conference on Computer, Information and Telecommunication Systems
(CITS).

IEEE, 2022, pp. 1–5.

[6] T. R. Gadekallu, T. Huynh-The, W. Wang, G. Yenduri, P. Ranaweera,
Q.-V. Pham, D. B. da Costa, and M. Liyanage, “Blockchain for the
metaverse: A review,” arXiv preprint arXiv:2203.09738, 2022.

[7] L. Cao, “Decentralized ai: Edge intelligence and smart blockchain,
metaverse, web3, and desci,” IEEE Intelligent Systems, vol. 37, no. 3,
pp. 6–19, 2022.

[8] I. A. Ilyina, E. A. Eltikova, K. A. Uvarova, and S. D. Chelysheva,
“Metaverse-death to ofﬂine communication or empowerment of
interaction?” in 2022 Communication Strategies in Digital Society
Seminar (ComSDS).
IEEE, 2022, pp. 117–119.

[9] N. Vretos, P. Daras, S. Asteriadis, E. Hortal, E. Ghaleb, E. Spyrou,
H. C. Leligou, P. Karkazis, P. Trakadas, and K. Assimakopoulos,
“Exploiting sensing devices availability in ar/vr deployments to foster
engagement,” Virtual Reality, vol. 23, no. 4, pp. 399–410, 2019.
[10] W. Y. B. Lim, Z. Xiong, D. Niyato, X. Cao, C. Miao, S. Sun, and
Q. Yang, “Realizing the metaverse with edge intelligence: A match
made in heaven,” arXiv preprint arXiv:2201.01634, 2022.

[11] M. Torres Vega, C. Liaskos, S. Abadal, E. Papapetrou, A. Jain,
B. Mouhouche, G. Kalem, S. Erg¨ut, M. Mach, T. Sabol et al.,
“Immersive interconnected virtual and augmented reality: A 5g and iot
perspective,” Journal of Network and Systems Management, vol. 28,
no. 4, pp. 796–826, 2020.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

34

[12] M. Al Ja’afreh, H. Adharni, and A. El Saddik, “Experimental qos
optimization for haptic communication over
tactile internet,” in
2018 IEEE International Symposium on Haptic, Audio and Visual
Environments and Games (HAVE).

IEEE, 2018, pp. 1–6.

[13] K. Polachan, J. Pal, C. Singh, and T. Prabhakar, “Assessing quality
of control in tactile cyber-physical systems,” IEEE Transactions on
Network and Service Management, 2022.

[14] M. Tariq, F. Naeem, and H. V. Poor, “Toward experience-driven trafﬁc
management and orchestration in digital-twin-enabled 6g networks,”
arXiv preprint arXiv:2201.04259, 2022.

[15] A. Aijaz, M. Dohler, A. H. Aghvami, V. Friderikos, and M. Frodigh,
“Realizing the tactile internet: Haptic communications over next
generation 5g cellular networks,” IEEE Wireless Communications,
vol. 24, no. 2, pp. 82–89, 2016.

[16] T. Barnett, S. Jain, U. Andra, and T. Khurana, “Cisco visual networking
index (vni) complete forecast update, 2017–2022,” Americas/EMEAR
Cisco Knowledge Network (CKN) Presentation, pp. 1–30, 2018.
[17] N. Ana-Maria, M. Alexandru, and P. E. Cristian, “Study of millimeter
waves in 5g,” in 2021 IEEE International Black Sea Conference on
Communications and Networking (BlackSeaCom).
IEEE, 2021, pp.
1–4.

[18] M. Ghoshal, P. Dash, Z. Kong, Q. Xu, Y. C. Hu, D. Koutsonikolas,
and Y. Li, “Can 5g mmwave support multi-user ar?” in International
Conference on Passive and Active Network Measurement.
Springer,
2022, pp. 180–196.

[19] W. Roh, J.-Y. Seol, J. Park, B. Lee, J. Lee, Y. Kim, J. Cho, K. Cheun,
and F. Aryanfar, “Millimeter-wave beamforming as an enabling
technology for 5g cellular communications: Theoretical feasibility and
prototype results,” IEEE communications magazine, vol. 52, no. 2, pp.
106–113, 2014.

[20] P. Lin, Q. Song, F. R. Yu, D. Wang, A. Jamalipour, and L. Guo,
“Wireless virtual reality in beyond 5g systems with the internet of
intelligence,” IEEE Wireless Communications, vol. 28, no. 2, pp.
70–77, 2021.

[21] B. Gu, X. Zhang, Z. Lin, and M. Alazab, “Deep multiagent
reinforcement-learning-based resource
internet of
controllable things,” IEEE Internet of Things Journal, vol. 8, no. 5,
pp. 3066–3074, 2021.

allocation for

[22] M. Maier, A. Ebrahimzadeh, A. Beniiche, and S. Rostami, “The art of
6g (tao 6g): how to wire society 5.0,” Journal of Optical Communica-
tions and Networking, vol. 14, no. 2, pp. A101–A112, 2022.

[23] D. M. Hilty, K. Randhawa, M. M. Maheu, A. J. McKean, R. Pantera,
M. C. Mishkind, A. Rizzo et al., “A review of telepresence, virtual
reality, and augmented reality applied to clinical care,” Journal of
Technology in Behavioral Science, vol. 5, no. 2, pp. 178–205, 2020.

[24] M. Pengnoo, M. T. Barros, L. Wuttisittikulkij, B. Butler, A. Davy,
and S. Balasubramaniam, “Digital
twin for metasurface reﬂector
management in 6g terahertz communications,” IEEE access, vol. 8,
pp. 114 580–114 596, 2020.

[25] M. Adhikari and A. Hazra, “6g-enabled ultra-reliable low-latency
communication in edge networks,” IEEE Communications Standards
Magazine, vol. 6, no. 1, pp. 67–74, 2022.

[26] X. Liu, F. Zhang, Z. Hou, L. Mian, Z. Wang, J. Zhang, and
J. Tang, “Self-supervised learning: Generative or contrastive,” IEEE
Transactions on Knowledge and Data Engineering, vol. Early Access,
pp. 1–8, 2021.

[27] R. Fantacci and B. Picano, “Edge-based virtual

reality over 6g

terahertz channels,” IEEE Network, vol. 35, no. 5, pp. 28–33, 2021.

[28] U. K. Chude-Okonkwo, B. S. Paul, and A. A. Vasilakos, “Enabling
precision medicine via contemporary and future communication
technologies: A survey,” IEEE Access, 2022.

[29] K. Chakrabarti, “Deep learning based ofﬂoading for mobile augmented
reality application in 6g,” Computers and Electrical Engineering,
vol. 95, p. 107381, 2021.

[30] F. Tang, X. Chen, M. Zhao, and N. Kato, “The roadmap of
the metaverse,” IEEE

communication and networking in 6g for
Wireless Communications, 2022.

[31] A. Aggarwal, M. Mittal, and G. Battineni, “Generative adversarial
theory and applications,” International
network: An overview of
Journal of Information Management Data Insights, vol. 1, no. 1, p.
100004, 2021.

[32] X. Huang, J. Twycross, and F. Wild, “A process for the semi-
automated generation of life-sized, interactive 3d character models
for holographic projection,” in 2019 International Conference on 3D
Immersion (IC3D).

IEEE, 2019, pp. 1–8.
[33] Z. Li, L. Chen, C. Liu, F. Zhang, Z. Li, Y. Gao, Y. Ha, C. Xu,
S. Quan, and Y. Xu, “Animated 3d human avatars from a single image
with gan-based texture inference,” Computers & Graphics, vol. 95,
pp. 81–91, 2021.

[34] L. Lov´en, T. Lepp¨anen, E. Peltonen,

J. Partala, E. Harjula,
P. Porambage, M. Ylianttila, and J. Riekki, “Edgeai: A vision for
distributed, edge-native artiﬁcial intelligence in future 6g networks,”
The 1st 6G wireless summit, pp. 1–2, 2019.

[35] Q. Yang, Y. Zhao, H. Huang, Z. Xiong, J. Kang, and Z. Zheng,
“Fusing blockchain and ai with metaverse: A survey,” IEEE Open
Journal of the Computer Society, 2022.

[36] Y. Wang, Z. Su, N. Zhang, D. Liu, R. Xing, T. H. Luan, and X. Shen,
“A survey on metaverse: Fundamentals, security, and privacy,” arXiv
preprint arXiv:2203.02662, 2022.

[37] T. Huynh-The, Q.-V. Pham, X.-Q. Pham, T. T. Nguyen, Z. Han, and
D.-S. Kim, “Artiﬁcial intelligence for the metaverse: A survey,” arXiv
preprint arXiv:2202.10336, 2022.

[38] L. Chang, Z. Zhang, P. Li, S. Xi, W. Guo, Y. Shen, Z. Xiong,
J. Kang, D. Niyato, X. Qiao et al., “6g-enabled edge ai for metaverse:
Challenges, methods, and future research directions,” arXiv preprint
arXiv:2204.06192, 2022.

[39] S. K. Jagatheesaperumal, K. Ahmad, A. Al-Fuqaha, and J. Qadir,
“Advancing education through extended reality and internet of
everything enabled metaverses: Applications, challenges, and open
issues,” arXiv preprint arXiv:2207.01512, 2022.

[40] S. Dhelim, T. Kechadi, L. Chen, N. Aung, H. Ning, and L. Atzori,
“Edge-enabled metaverse: The convergence of metaverse and mobile
edge computing,” arXiv preprint arXiv:2205.02764, 2022.

[41] S.-M. Park and Y.-G. Kim, “A metaverse: Taxonomy, components,
applications, and open challenges,” Ieee Access, vol. 10, pp. 4209–
4251, 2022.

[42] M. A. I. Mozumder, M. M. Sheeraz, A. Athar, S. Aich, and H.-C.
Kim, “Overview: technology roadmap of the future trend of metaverse
based on iot, blockchain, ai technique, and medical domain metaverse
activity,” in 2022 24th International Conference on Advanced
Communication Technology (ICACT).

coinbase

“How
metaverse,”

[43] Coinbase,
the
how-coinbase-thinks-about-the-metaverse-16d8070f4841, 2021.
[44] J. Huang, P. Sun, and W. Zhang, “Analysis of the future prospects for
the metaverse,” in 2022 7th International Conference on Financial
Innovation and Economic Development (ICFIED 2022).
Atlantis
Press, 2022, pp. 1899–1904.
“How

about
https://blog.coinbase.com/

[45] D.

Pereira,

ai

IEEE, 2022, pp. 256–261.
thinks

will

the
https://towardsdatascience.com/

shape

metaverse,”
how-ai-will-shape-the-metaverse-4ea7ae20c99, 2021.

[46] K. MacCallum and D. Parsons, “Teacher perspectives on mobile
augmented reality: The potential of metaverse for learning,” in World
Conference on Mobile and Contextual Learning, 2019, pp. 21–28.

[47] M. Sparkes, “What is a metaverse,” 2021.
[48] N. Kshetri, “Web 3.0 and the metaverse shaping organizations’ brand
and product strategies,” IT Professional, vol. 24, no. 02, pp. 11–15,
2022.

[49] K. Valaskova, V. Machova, and E. Lewis, “Virtual marketplace
dynamics data, spatial analytics, and customer engagement tools in
a real-time interoperable decentralized metaverse,” Linguistic and
Philosophical Investigations, vol. 21, pp. 105–120, 2022.

[50] J.

Radoff,

“The

gence,”
the-metaverse-and-artiﬁcial-intelligence-ai-577343895411, 2021.

metaverse

intelli-
https://medium.com/building-the-metaverse/

artiﬁcial

and

[51] ——,

“The

metaverse

value-chain,”

https://medium.com/

building-the-metaverse/the-metaverse-value-chain-afcf9e09e3a7,
2021.

[52] J.

Radof,

“9

megatrends
meta-
shaping
https://medium.com/building-the-metaverse/

verse,”
9-megatrends-shaping-the-metaverse-93b91c159375, May 2021.
[53] K. Aggarwal, M. M. Mijwil, A.-H. Al-Mistarehi, S. Alomari, M. G¨ok,
A. M. Z. Alaabdin, S. H. Abdulrhman et al., “Has the future started?
the current growth of artiﬁcial intelligence, machine learning, and
deep learning,” Iraqi Journal for Computer Science and Mathematics,
vol. 3, no. 1, pp. 115–123, 2022.

the

[54] L. Lik-Hang and H. Pan, “Interaction methods for smart glasses,”

ACM Comput. Surv, vol. 1, no. 0, 2017.

[55] L. H. Lee, K. Y. Lam, Y. P. Yau, T. Braud, and P. Hui, “Hibey:
Hide the keyboard in augmented reality,” in 2019 IEEE International
Conference on Pervasive Computing and Communications (PerCom.
IEEE, 2019, pp. 1–10.

[56] X.-Y. Huang, M.-S. Tsai, and C.-C. Huang, “3d virtual-reality
interaction system,” in 2019 IEEE International Conference on
Consumer Electronics-Taiwan (ICCE-TW).

IEEE, 2019, pp. 1–2.

[57] E. D’Antonio, J. Taborri, E. Palermo, S. Rossi, and F. Patane, “A
markerless system for gait analysis based on openpose library,” in 2020
Instrumentation and Measurement Technology
IEEE International
Conference (I2MTC).

IEEE, 2020, pp. 1–6.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

35

[58] R. Bajireanu, J. A. Pereira, R. J. Veiga, J. D. Sardo, P. J. Cardoso,
R. Lam, and J. M. Rodrigues, “Mobile human shape superimposition:
an initial approach using openpose,” International Journal of
Computers, vol. 4, 2019.

[59] C. Nuzzi, S. Ghidini, R. Pagani, S. Pasinetti, G. Coffetti, and
G. Sansoni, “Hands-free: a robot augmented reality teleoperation
system,” in 2020 17th International Conference on Ubiquitous Robots
(UR).

IEEE, 2020, pp. 617–624.

[60] X. Wang, Y. Wang, Y. Shi, W. Zhang, and Q. Zheng, “Avatarmeeting:
An augmented reality remote interaction system with personalized
avatars,” in Proceedings of the 28th ACM International Conference
on Multimedia, 2020, pp. 4533–4535.

[61] V. Ponnusamy, A. Vasuki, J. C. Clement, and P. Eswaran, “Ai-
driven information and communication technologies, services, and
applications for next-generation healthcare system,” Smart Systems for
Industrial Applications, pp. 1–32, 2022.

[62] A. Phillip, J. S. Chan, and S. Peiris, “A new look at cryptocurrencies,”

Economics Letters, vol. 163, pp. 6–9, 2018.

[63] H. Zhu, “Metaaid: A ﬂexible framework for developing metaverse
technology and human editing,” arXiv preprint

applications via ai
arXiv:2204.01614, 2022.

[64] Q. Dang, J. Yin, B. Wang, and W. Zheng, “Deep learning based 2d
human pose estimation: A survey,” Tsinghua Science and Technology,
vol. 24, no. 6, pp. 663–676, 2019.

[65] Z. Cao, T. Simon, S.-E. Wei, and Y. Sheikh, “Realtime multi-person
2d pose estimation using part afﬁnity ﬁelds,” in Proceedings of the
IEEE conference on computer vision and pattern recognition, 2017,
pp. 7291–7299.

[66] H.-S. Fang, S. Xie, Y.-W. Tai, and C. Lu, “Rmpe: Regional multi-
person pose estimation,” in Proceedings of the IEEE international
conference on computer vision, 2017, pp. 2334–2343.

[67] D. Mehta, S. Sridhar, O. Sotnychenko, H. Rhodin, M. Shaﬁei, H.-P.
Seidel, W. Xu, D. Casas, and C. Theobalt, “Vnect: Real-time 3d
human pose estimation with a single rgb camera,” Acm transactions
on graphics (tog), vol. 36, no. 4, pp. 1–14, 2017.

[68] T. B. Moeslund and E. Granum, “A survey of computer vision-based
human motion capture,” Computer vision and image understanding,
vol. 81, no. 3, pp. 231–268, 2001.

[69] F. Hu, P. He, S. Xu, Y. Li, and C. Zhang, “Fingertrak: Continuous
3d hand pose tracking by deep learning hand silhouettes captured
by miniature thermal cameras on wrist,” Proceedings of the ACM on
Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 4,
no. 2, pp. 1–24, 2020.

[70] Y.-j. Shin, H.-j. Lee, J.-h. Kim, D.-y. Kwon, S.-a. Lee, Y.-j. Choo, J.-
h. Park, J.-h. Jung, H.-s. Lee, and J.-h. Kim, “Non-face-to-face online
home training application study using deep learning-based image pro-
cessing technique and standard exercise program,” The Journal of the
Convergence on Culture Technology, vol. 7, no. 3, pp. 577–582, 2021.
[71] “What is spatial computing? a short deﬁnition of spatial computing,”
https://www.techslang.com/deﬁnition/what-is-spatial-computing/.

[72] Coinbase,

“Spatial

computing,”

https://www.ptc.com/en/

industry-insights/spatial-computing.

[73] S. Shekhar, S. K. Feiner, and W. G. Aref, “Spatial computing,”
Communications of the ACM, vol. 59, no. 1, pp. 72–81, 2015.
[74] T. Zhang, Y.-T. Li, and J. P. Wachs, “The effect of embodied
interaction in visual-spatial navigation,” ACM Transactions on
Interactive Intelligent Systems (TiiS), vol. 7, no. 1, pp. 1–36, 2016.

[75] J. Bardi, “What

is virtual

reality? [deﬁnition and examples,”

https://www.marxentlabs.com/what-is-virtual-reality/, 2020.

[76] J. W. Kelly, L. A. Cherep, A. F. Lim, T. Doty, and S. B. Gilber,
“Who are virtual reality headset owners? a survey and comparison of
headset owners and non-owners,” in 2021 IEEE Virtual Reality and
3D User Interfaces (VR).

IEEE, 2021, pp. 687–694.

[77] P. Milgram, H. Takemura, A. Utsumi, and F. Kishino, “Augmented
reality: A class of displays on the reality-virtuality continuum,”
in Telemanipulator and telepresence
technologies, vol. 2351.
International Society for Optics and Photonics, 1995, pp. 282–292.

[78] M. Speicher, B. D. Hall, and M. Nebeling, “What is mixed reality?”
the 2019 CHI conference on human factors in

in Proceedings of
computing systems, 2019, pp. 1–15.

[79] M. Zyda, Networked virtual environments: design and implementation.

Addison-Wesley, 1999.

[80] H. Liu, M. Bowman, and F. Chang, “Survey of state melding in virtual
worlds,” ACM Computing Surveys (CSUR), vol. 44, no. 4, pp. 1–25,
2012.

[81] T. Narumi, S. Nishizaka, T. Kajinami, T. Tanikawa, and M. Hirose,
“Augmented reality ﬂavors: gustatory display based on edible marker
and cross-modal interaction,” in Proceedings of the SIGCHI conference
on human factors in computing systems, 2011, pp. 93–102.

[82] D. Schmalstieg and T. Hollerer, Augmented reality: principles and

practice. Addison-Wesley Professional, 2016.

[83] E. Kruijff, J. J. LaViola, and I. POUPYREV, “3d user interfaces:

theory and practice,” 2004.

[84] J. S. Pierce and R. Pausch, “Comparing voodoo dolls and homer:
feedback in virtual environments,”
the SIGCHI Conference on Human Factors in

exploring the importance of
in Proceedings of
Computing Systems, 2002, pp. 105–112.

[85] L.-H. Lee, T. Braud, S. Hosio, and P. Hui, “Towards augmented reality
driven human-city interaction: Current research on mobile headsets
and future challenges,” ACM Computing Surveys (CSUR), vol. 54,
no. 8, pp. 1–38, 2021.

[86] T. Langlotz, S. Mooslechner, S. Zollmann, C. Degendorfer,
G. Reitmayr, and D. Schmalstieg, “Sketching up the world:
in
situ authoring for mobile augmented reality,” Personal and ubiquitous
computing, vol. 16, no. 6, pp. 623–630, 2012.

[87] T. Langlotz, C. Degendorfer, A. Mulloni, G. Schall, G. Reitmayr, and
D. Schmalstieg, “Robust detection and tracking of annotations for
outdoor augmented reality browsing,” Computers & graphics, vol. 35,
no. 4, pp. 831–840, 2011.

[88] B. MacIntyre, E. M. Coelho, and S. J. Julier, “Estimating and adapting
to registration errors in augmented reality systems,” in Proceedings
IEEE Virtual Reality 2002.

IEEE, 2002, pp. 73–80.

[89] S. Feiner, B. MacIntyre, T. H¨ollerer, and A. Webster, “A touring
machine: Prototyping 3d mobile augmented reality systems for
exploring the urban environment,” Personal Technologies, vol. 1,
no. 4, pp. 208–217, 1997.

[90] L.-H. Lee and P. Hui, “Interaction methods for smart glasses: A

survey,” IEEE access, vol. 6, pp. 28 712–28 732, 2018.

[91] P. Wacker, A. Wagner, S. Voelker, and J. Borchers, “Heatmaps,
shadows, bubbles, rays: Comparing mid-air pen position visualizations
in handheld ar,” in Proceedings of
the 2020 CHI Conference on
Human Factors in Computing Systems, 2020, pp. 1–11.

[92] C. Xie, Y. Kameda, K. Suzuki, and I. Kitahara, “Large scale interactive
ar display based on a projector-camera system,” in Proceedings of the
2016 Symposium on Spatial User Interaction, 2016, pp. 179–179.
[93] J. S. Roo, R. Gervais, J. Frey, and M. Hachet, “Inner garden:
Connecting inner states to a mixed reality sandbox for mindfulness,”
in Proceedings of the 2017 CHI Conference on Human Factors in
Computing Systems, 2017, pp. 1459–1470.

[94] J. Hartmann, Y.-T. Yeh, and D. Vogel, “Aar: Augmenting a wearable
augmented reality display with an actuated head-mounted projector,”
in Proceedings of the 33rd Annual ACM Symposium on User Interface
Software and Technology, 2020, pp. 445–458.

[95] I. Chaturvedi, F. H. Bijarbooneh, T. Braud, and P. Hui, “Peripheral
vision: a new killer app for smart glasses,” in Proceedings of the 24th
International Conference on Intelligent User Interfaces, 2019, pp.
625–636.

[96] P. Milgram and F. Kishino, “A taxonomy of mixed reality visual
displays,” IEICE TRANSACTIONS on Information and Systems,
vol. 77, no. 12, pp. 1321–1329, 1994.

[97] P. Lopes, S. You, A. Ion, and P. Baudisch, “Adding force feedback
to mixed reality experiences and games using electrical muscle
stimulation,” in Proceedings of the 2018 chi conference on human
factors in computing systems, 2018, pp. 1–13.

[98] D. Reilly, A. Echenique, A. Wu, A. Tang, and W. K. Edwards,
“Mapping out work in a mixed reality project room,” in Proceedings
of the 33rd Annual ACM Conference on Human Factors in Computing
Systems, 2015, pp. 887–896.

[99] M. Ohta, S. Nagano, H. Niwa, and K. Yamashita, “Mixed-reality store

on the other side of a tablet.” in ISMAR, 2015, pp. 192–193.
[100] Y.-T. Yue, Y.-L. Yang, G. Ren, and W. Wang, “Scenectrl: Mixed
reality enhancement via efﬁcient scene editing,” in Proceedings of
the 30th annual ACM symposium on user interface software and
technology, 2017, pp. 427–436.

[101] L.-H. Lee, T. Braud, S. Hosio, and P. Hui, “Towards augmented
reality-driven human-city interaction: Current research and future
challenges,” arXiv preprint arXiv:2007.09207, 2020.

[102] L. Malinverni, J. Maya, M.-M. Schaper, and N. Pares, “The world-as-
support: Embodied exploration, understanding and meaning-making
of the augmented world,” in Proceedings of the 2017 CHI Conference
on Human Factors in Computing Systems, 2017, pp. 5132–5144.
[103] A. L. Gardony, R. W. Lindeman, and T. T. Bruny´e, “Eye-tracking for
human-centered mixed reality: promises and challenges,” in Optical
Architectures for Displays and Sensing in Augmented, Virtual, and
Mixed Reality (AR, VR, MR), vol. 11310. SPIE, 2020, pp. 230–247.
[104] U. Gustavsson, P. Frenger, C. Fager, T. Eriksson, H. Zirath,
F. Dielacher, C. Studer, A. P¨arssinen, R. Correia, J. N. Matos et al.,
“Implementation challenges and opportunities in beyond-5g and 6g
communication,” IEEE Journal of Microwaves, vol. 1, no. 1, pp.
86–100, 2021.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

36

[105] M. Giordani, M. Polese, M. Mezzavilla, S. Rangan, and M. Zorzi,
IEEE

“Toward
Communications Magazine, vol. 58, no. 3, pp. 55–61, 2020.

networks: Use

technologies,”

cases

and

6g

[106] S. K. Rao and R. Prasad, “Impact of 5g technologies on industry 4.0,”
Wireless personal communications, vol. 100, no. 1, pp. 145–159, 2018.
[107] S. Glisic and J.-P. Makela, “Advanced wireless networks: 4g
technologies,” in 2006 IEEE Ninth International Symposium on Spread
Spectrum Techniques and Applications.

IEEE, 2006, pp. 442–446.

[108] W. Saad, M. Bennis, and M. Chen, “A vision of 6g wireless systems:
Applications, trends, technologies, and open research problems,” IEEE
network, vol. 34, no. 3, pp. 134–142, 2019.

[109] P. Shrestha, M. Guidry, B. Romanczyk, N. Hatui, C. Wurm, A. Krishna,
S. S. Pasayat, R. R. Karnaty, S. Keller, J. F. Buckwalter et al., “High
linearity and high gain performance of n-polar gan mis-hemt at 30
ghz,” IEEE Electron Device Letters, vol. 41, no. 5, pp. 681–684, 2020.
6g,
how fast will
[Online]. Available:

and T. Lacoma. What
is

it
https://www.digitaltrends.com/mobile/what-is-6g/

is
coming?

[110] A. Boxall

and when

be,

it

[111] T. M. Fernandez-Carames and P. Fraga-Lamas, “A review on the
application of blockchain to the next generation of cybersecure industry
4.0 smart factories,” Ieee Access, vol. 7, pp. 45 201–45 218, 2019.

[112] A. Cannavo and F. Lamberti, “How blockchain, virtual

reality,
and augmented reality are converging, and why,” IEEE Consumer
Electronics Magazine, vol. 10, no. 5, pp. 6–13, 2020.

[113] A. M. French, M. Risius, and J. P. Shim, “The interaction of virtual
reality, blockchain, and 5g new radio: Disrupting business and society,”
Communications of the Association for Information Systems, vol. 46,
no. 1, p. 25, 2020.

[114] D. C. Nguyen, P. N. Pathirana, M. Ding, and A. Seneviratne,
“Blockchain for 5g and beyond networks: A state of the art survey,”
Journal of Network and Computer Applications, vol. 166, p. 102693,
2020.

[115] A. El Azzaoui, S. K. Singh, Y. Pan, and J. H. Park, “Block5gintell:
Blockchain for ai-enabled 5g networks,” IEEE Access, vol. 8, pp.
145 918–145 935, 2020.

[116] Z. Haddad, M. M. Fouda, M. Mahmoud, and M. Abdallah,
2020
“Blockchain-based
IEEE International Conference on Informatics, IoT, and Enabling
Technologies (ICIoT).

IEEE, 2020, pp. 189–194.

authentication

networks,”

for

5g

in

[117] L. Floridi and M. Chiriatti, “Gpt-3: Its nature, scope,

limits, and

consequences,” Minds and Machines, vol. 30, pp. 681–694, 2020.

[118] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,
A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal,
A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh,
D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin,
S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford,
I. Sutskever, and D. Amodei, “Language models are few shot learners,”
in 33rd Advances in Neural Information Processing Systems (NeurIPS),
2020, pp. 1–25. [Online]. Available: https://proceedings.neurips.cc/
paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html

[119] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal,
G. Sastry, A. Askell, P. Mishkin,
J. Clark, G. Krueger, and
I. Sutskever, “Learning transferable visual models from natural
language supervision,” in 38th International Conference on Machine
Learning (ICML), 2021, pp. 8748–8763.
[Online]. Available:
http://proceedings.mlr.press/v139/radford21a

[120] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. Voss, A. Radford, M. Chen,
and I. Sutskever, “Zero-shot text-to-image generation,” in 38th Interna-
tional Conference on Machine Learning (ICML), 2021, pp. 8821–8831.
[Online]. Available: https://proceedings.mlr.press/v139/ramesh21a.html
[121] T. Park, M.-Y. Liu, T.-C. Wang, and J.-Y. Zhu, “Gaugan: Semantic
image synthesis with spatially adaptive normalization,” in ACM
SIGGRAPH 2019 Real-Time Live, 2019, pp. 1–1.
[122] C. M. BISHOP, Pattern recognition and machine

learning.

SPRINGER-VERLAG NEW YORK, 2016.

[123] V. Francois-Lavet, P. Henderson, I. Riashat, M. G. Bellemare, and
J. Pineau, An introduction to Deep Reinforcement Learning. Now
Foundations and Trends, 2018.

[124] A. Baevski, W.-N. Hsu, Q. Xu, A. Babu, J. Gu, and M. Auli,
framework for self-supervised learning in

“data2vec: A general
speech, vision, and language,” arXiV, preprint, pp. 1–13, 2022.
[125] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks
for semantic segmentation,” IEEE Transations on Pattern Analysis
and Machine Intelligence, vol. 39, no. 4, pp. 640–651, 2017.
[126] T. Xiao, Y. Liu, B. Zhou, Y. Jiang, and J. Sun, “Uniﬁed perceptual
scene understanding,” in European Conference on

parsing for
Computer Vision, 2018, pp. 432–448.

[128] A. kirillov, R. Girshick, K. He, and P. Dollar, “Panoptic feature pyramid
networks,” in Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), 2019, pp. 6399–6408.

[129] X. Li, A. You, Z. Zhu, H. Zhao, M. Yang, K. Yang, S. Tan, and
Y. Tong, “Semantic ﬂow for fast and accurate scene parsing,” in
European Conference on Computer Vision, 2020, pp. 775–793.
[130] E. Xie, W. Wang, Z. Yu, A. Anandkumar, J. M. Alvarez, and P. Luo,
“Segformer: Simple and efﬁcient design for semantic segmenattion
Information
with transformers,” in 35th Conference on Neural
Processing Systems (NeurIPS), 2021, pp. 1–14.

[131] S. Huang, Z. Lu, R. Cheng, and C. He, “Fapn: Feature aligned pyramid
network for dense image prediction,” in Proceedings of the IEEE Inter-
national Conference on Computer Vision (ICCV), 2021, pp. 864–873.
[132] C. Yu, Y. Shao, C. Gao, and N. Sang, “Condnet: Conditional classiﬁer
for scene segmentation,” IEEE Signal Processing Letters, vol. 28, pp.
758–762, 2021.

[133] H. Yan, C. Zhang, and M. Wu, “Lawin transformer: Improving
semantic segmentation transfoermer with multiscale representations
via large window attention,” arXiv, pp. 1–11, 2022.

[134] D. I. Abramson and J. Johnson, “Creating a conversational chatbot of

a speciﬁc person,” Dec 2020.

[135] A. S. Fangbemi, Y. F. Lu, M. Y. Xu, X. W. Luo, A. Rolland, and
C. Raissi, “Zoobuilder: 2d and 3d pose estimation for quadrupeds
using synthetic data,” ACM Siggraph, vol. 39, pp. 1–2, 2020.
[136] Z. Cao, G. Hidalgo, T. Simon, S.-E. Wei, and Y. Sheikh, “Openpose:
Realtime multiperson 2d pose estimation using part afﬁnity ﬁelds,”
IEEE Transactions on Pattern Analysis and Machine Intelligence,
vol. 43, pp. 172–186, 2021.

[137] M. R. I. Hossain and J. J. Little, “Exploiting temporal information
for 3d human pose estimation,” in European Conference on Computer
Vision (ECCV), 2018, pp. 69–86.

[138] T. Karras, S. Laine, M. Aittala, J. Hellsten, and J. Lehtinen, “Analyzing
and improving the image quality of stylegan,” in Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2020, pp. 8110–8119.

[139] C. She, C. Sun, Z. Gu, Y. Li, C. Yang, H. Poor, Vincent, and B. Vucetic,
“A tutorial on ultrareliable and low-latency communications in 6g:
Integrating domain knowledge into deep learning,” Proceedings of the
IEEE, vol. 109, no. 3, pp. 204–246, 2021.

[140] K. Dev, S. A. Khowaja, P. K. Sharma, B. S. Chowdhry, S. Tanwar, and
G. Fortino, “Ddi: A novel architecture for joint active user detection
and iot device identiﬁcation in grant-free noma systems of 6g and
beyond networks,” IEEE Internet of Things Journal, vol. 9, no. 4, pp.
2906–2917, 2022.

[141] C. She, R. Dong, Z. Gu, Y. Li, W. Hardjawana, C. Yang, L. Song,
and B. Vucetic, “Deep learning for ultra-reliable and low-latency
communication in 6g neworks,” IEEE Network, vol. 34, no. 5, pp.
219–225, 2020.

[142] M. Alsenwi, N. H. Tran, M. Bennis, S. R. Pandey, A. K. Bairagi,
and C. S. a. Hong, “Intelligence resource slicing for embb and urllc
coexistence in 5g and beyond: A deep reinforcement learning based
approach,” IEEE Transactions on Wireless Communications, vol. 20,
no. 7, pp. 4585–4600, 2021.

[143] G. B. Tunze, T. Huynh-The, J.-M. Lee, and D.-S. Kim, “Sparsely
connected cnn for efﬁcient automatic modulation recognition,”
IEEE Transactions on Vehicular Technology, vol. 69, no. 12, pp.
15 557–15 568, 2020.

[144] T. Huynh-The, C.-H. Hua, Q.-V. Pham, and D.-S. Kim, “Mcnet: An
efﬁcient cnn architecture for robust automation modulation classiﬁca-
tion,” IEEE Communication Letters, vol. 24, no. 4, pp. 811–815, 2020.
[145] C. Luo, J. Ji, Q. Wang, X. Chen, and P. Li, “Channel state information
prediction for 5g wireless communications: A deep learning approach,”
IEEE Transactions on Network Science and Engineering, vol. 7, no. 1,
pp. 227–236, 2020.

[146] S. Guo, Y. Lin, S. Li, Z. Chen, and H. Wang, “Deep spatial-temporal
3d convolutional neural networks for trafﬁc data forecasting,” IEEE
Transactions on Intelligent Transportation Systems, vol. 20, no. 10,
pp. 3913–3926, 2019.

[147] X. Wang, Y. Han, V. C. M. Leung, D. Niyato, X. Yan, and X. Chen,
“Convergence of edge computing and deep learning: A comprehensive
survey,” IEEE Communication Surveys and Tutorials, vol. 22, no. 2,
pp. 869–904, 2020.

[148] S. A. Khowaja, K. Dev, P. Khuwaja, Q.-V. Pham, N. M. F. Qureshi,
P. Bellavista, and M. Magarini, “Iifnet: A fusion-based intelligent
service for noisy preamble detection in 6g,” IEEE Network, vol. 36,
no. 3, pp. 48–54, 2022.

[127] C. Yu, J. Wang, C. Peng, C. Gao, G. Yu, and N. Sang, “Bisenet:
Bilateral segmentation network for real-time semantic segmentation,”
in European Conference on Computer Vision, 2018, pp. 334–349.

[149] S. A. Khowaja, K. Dev, P. Khuwaja, and P. Bellavista, “Toward
energy-efﬁcient distributed federated learning for 6g networks,” IEEE
Wireless Communications, vol. 28, no. 6, pp. 34–40, 2021.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

37

[150] Z. Li, S. Zhuang, S. Guo, D. Zhuo, H. Zhang, D. Song, and I. Stoica,
“Terapipe: Token-level pipeline parallelism for training large-scale
language models,” Proceedings of Machine Learning Research, vol.
139, pp. 6543–6552, 2021.

[151] S. A. Khowaja, A. G. Prabono, F. Setiawan, B. N. Yahya, and S.-L.
Lee, “Contextual activity based healthcare internet of things, services,
and people (hiotsp): An architectural
framework for healthcare
monitoring using wearable sensors,” Computer Networks, vol. 145,
pp. 190–206, 2018.

[152] P. Khuwaja, S. A. Khowaja, and K. Dev, “Adversarial

learning
networks for ﬁntech applications using heterogeneous data sources,”
IEEE Internet of Things Journal, vol. Early Access, pp. 1–8, 2021.

[153] D. G. Morin, P. Perez, and A. G. Armada, “Toward the distributed
implementation of immersive augmented reality architectures on 5g
networks,” IEEE Communications Magazine, vol. 60, no. 2, pp. 46–52,
2022.

[154] F. Hu, Y. Deng, W. Saad, M. Bennis, and A. H. Aghvami, “Cellular-
connected wireless virtual
reality: Requirements, challenges, and
solutions,” IEEE Communications Magazine, vol. 58, no. 5, pp.
105–111, 2020.

[155] Y. Siriwardhana, P. Porambage, M. Liyanage, and M. Ylianttila, “A
survey on mobile augmented reality with 5g mobile edge computing:
architectures, applications, and technical aspects,” IEEE Communica-
tions Surveys & Tutorials, vol. 23, no. 2, pp. 1160–1192, 2021.
[156] S. Sukhmani, M. Sadeghi, M. Erol-Kantarci, and A. El Saddik, “Edge
caching and computing in 5g for mobile ar/vr and tactile internet,”
IEEE MultiMedia, vol. 26, no. 1, pp. 21–30, 2018.

[157] R. Li, “Network 2030: Market drivers and prospects,” in Proc. 1st
International Telecommunication Union Workshop on Network, vol.
2030, 2018.

[158] D. Gotsch, X. Zhang, T. Merritt, and R. Vertegaal, “Telehuman2: A
cylindrical light ﬁeld teleconferencing system for life-size 3d human
telepresence.” in CHI, vol. 18, 2018, p. 552.

[159] B. Yang, Z. Yu, J. Lan, R. Zhang, J. Zhou, and W. Hong, “Digital
beamforming-based massive mimo transceiver for 5g millimeter-wave
communications,” IEEE Transactions on Microwave Theory and
Techniques, vol. 66, no. 7, pp. 3403–3418, 2018.

[160] A. Yastrebova, R. Kirichek, Y. Koucheryavy, A. Borodin,
and A. Koucheryavy, “Future networks 2030: Architecture &
requirements,” in 2018 10th International Congress on Ultra Modern
Telecommunications and Control Systems and Workshops (ICUMT).
IEEE, 2018, pp. 1–8.

[161] M. Erel- ¨Ozc¸evik and B. Canberk, “Road to 5g reduced-latency: A soft-
ware deﬁned handover model for embb services,” IEEE Transactions
on Vehicular Technology, vol. 68, no. 8, pp. 8133–8144, 2019.
[162] M. Zhang, M. Polese, M. Mezzavilla, J. Zhu, S. Rangan, S. Panwar,
and M. Zorzi, “Will tcp work in mmwave 5g cellular networks?”
IEEE Communications Magazine, vol. 57, no. 1, pp. 65–71, 2019.

[163] D. Milovanovic, Z. Bojkovic, M. Indoonundon, and T. P. Fowdur, “5g
low-latency communication in virtual reality services: Performance
requirements and promising solutions,” WSEAS Transactions on
Communications, vol. 20, pp. 77–81, 2021.

[164] W. Chen, J. Montojo, J. Lee, M. Shaﬁ, and Y. Kim, “The standardiza-
tion of 5g-advanced in 3gpp,” IEEE Communications Magazine, 2022.
[165] C. Yeh, G. Do Jo, Y.-J. Ko, and H. K. Chung, “Perspectives on 6g

wireless communications,” ICT Express, 2022.

[166] H. Viswanathan and P. E. Mogensen, “Communications in the 6g era,”

IEEE Access, vol. 8, pp. 57 063–57 074, 2020.

[167] N. DOCOMO, “White paper: 5g evolution and 6g (version 3.0),” NTT

DOCOMO White Paper, 2021.

[168] Z. Zhang, Y. Xiao, Z. Ma, M. Xiao, Z. Ding, X. Lei, G. K.
Karagiannidis, and P. Fan, “6g wireless networks: Vision, requirements,
architecture, and key technologies,” IEEE Vehicular Technology
Magazine, vol. 14, no. 3, pp. 28–41, 2019.

[169] X. Yang, Z. Chen, K. Li, Y. Sun, N. Liu, W. Xie, and Y. Zhao,
“Communication-constrained mobile edge computing systems for
wireless virtual reality: Scheduling and tradeoff,” IEEE Access, vol. 6,
pp. 16 665–16 677, 2018.

[170] C. Chaccour, M. N. Soorki, W. Saad, M. Bennis, P. Popovski, and
M. Debbah, “Seven deﬁning features of
terahertz (thz) wireless
systems: A fellowship of communication and sensing,” IEEE Com-
munications Surveys & Tutorials, vol. 24, no. 2, pp. 967–993, 2022.

[171] V. Petrov, M. Gapeyenko, S. Paris, A. Marcano, and K. I. Pedersen,
“Extended reality (xr) over 5g and 5g-advanced new radio: Standardiza-
tion, applications, and trends,” arXiv preprint arXiv:2203.02242, 2022.
[172] J. Kim, S.-C. Kwon, and G. Choi, “Performance of video streaming
in infrastructure-to-vehicle telematic platforms with 60-ghz radiation
and ieee 802.11 ad baseband,” IEEE Transactions on Vehicular
Technology, vol. 65, no. 12, pp. 10 111–10 115, 2016.

[173] J. Kim, J.-J. Lee, and W. Lee, “Strategic control of 60 ghz millimeter-
wave high-speed wireless links for distributed virtual reality platforms,”
Mobile Information Systems, vol. 2017, 2017.

[174] Y. Leng, C.-C. Chen, Q. Sun, J. Huang, and Y. Zhu, “Energy-efﬁcient
video processing for virtual reality,” in Proceedings of
the 46th
International Symposium on Computer Architecture, 2019, pp. 91–103.
[175] X. Yang, Z. Fei, J. Zheng, N. Zhang, and A. Anpalagan, “Joint
multi-user computation ofﬂoading and data caching for hybrid mobile
cloud/edge computing,” IEEE Transactions on Vehicular Technology,
vol. 68, no. 11, pp. 11 018–11 030, 2019.

[176] Y. Liu, J. Liu, A. Argyriou, and S. Ci, “Mec-assisted panoramic
vr video streaming over millimeter wave mobile networks,” IEEE
Transactions on Multimedia, vol. 21, no. 5, pp. 1302–1316, 2018.

[177] F. Qian, L. Ji, B. Han, and V. Gopalakrishnan, “Optimizing 360 video
delivery over cellular networks,” in Proceedings of the 5th Workshop
on All Things Cellular: Operations, Applications and Challenges,
2016, pp. 1–6.

[178] S. Mangiante, G. Klas, A. Navon, Z. GuanHua, J. Ran, and M. D.
Silva, “Vr is on the edge: How to deliver 360 videos in mobile
networks,” in Proceedings of the Workshop on Virtual Reality and
Augmented Reality Network, 2017, pp. 30–35.

[179] Y. Sun, Z. Chen, M. Tao, and H. Liu, “Communications, caching, and
computing for mobile virtual reality: Modeling and tradeoff,” IEEE
Transactions on Communications, vol. 67, no. 11, pp. 7573–7586,
2019.

[180] L. Zhao, Y. Cui, C. Guo, and Z. Liu, “Optimal streaming of 360 vr
videos with perfect, imperfect and unknown fov viewing probabilities,”
in GLOBECOM 2020-2020 IEEE Global Communications Conference.
IEEE, 2020, pp. 1–6.

[181] K. Long, Y. Cui, C. Ye, and Z. Liu, “Optimal wireless streaming of
multi-quality 360 vr video by exploiting natural, relative smoothness-
enabled, and transcoding-enabled multicast opportunities,” IEEE
Transactions on Multimedia, vol. 23, pp. 3670–3683, 2020.

[182] S. Gupta, J. Chakareski, and P. Popovski, “Millimeter wave meets
edge computing for mobile vr with high-ﬁdelity 8k scalable 360
video,” in 2019 IEEE 21st International Workshop on Multimedia
Signal Processing (MMSP).

IEEE, 2019, pp. 1–6.

[183] J. Du, F. R. Yu, G. Lu, J. Wang, J. Jiang, and X. Chu, “Mec-assisted
immersive vr video streaming over terahertz wireless networks: A
learning approach,” IEEE Internet of Things
deep reinforcement
Journal, vol. 7, no. 10, pp. 9517–9529, 2020.

[184] M. Chen, W. Saad, and C. Yin, “Liquid state based transfer learning for
360 image transmission in wireless vr networks,” in ICC 2019-2019
IEEE International Conference on Communications (ICC).
IEEE,
2019, pp. 1–6.

[185] C. Han and Y. Chen,

“Propagation modeling for wireless
in the terahertz band,” IEEE Communications

communications
Magazine, vol. 56, no. 6, pp. 96–101, 2018.

[186] X. Liu, Y. Deng, C. Han, and M. Di Renzo, “Learning-based
prediction, rendering and transmission for interactive virtual reality in
ris-assisted terahertz networks,” IEEE Journal on Selected Areas in
Communications, vol. 40, no. 2, pp. 710–724, 2021.

[187] M. Z. Chowdhury, M. Shahjalal, S. Ahmed, and Y. M. Jang,
“6g wireless communication systems: Applications,
requirements,
technologies, challenges, and research directions,” IEEE Open Journal
of the Communications Society, vol. 1, pp. 957–975, 2020.

[188] C. De Alwis, A. Kalla, Q.-V. Pham, P. Kumar, K. Dev, W.-J. Hwang,
and M. Liyanage, “Survey on 6g frontiers: Trends, applications,
requirements, technologies and future research,” IEEE Open Journal
of the Communications Society, vol. 2, pp. 836–886, 2021.

[189] J. Park, S. Samarakoon, H. Shiri, M. K. Abdel-Aziz, T. Nishio,
A. Elgabli, and M. Bennis, “Extreme urllc: Vision, challenges, and
key enablers,” arXiv preprint arXiv:2001.09683, 2020.

[190] J. Wallace and A. Valdivia, “A high-performance 5g/6g infrastructure
for augmented, virtual, and extended reality,” in 2021 International
Conference on Computational Science and Computational Intelligence
(CSCI).

IEEE, 2021, pp. 1291–1296.

[191] X. Li, W. Feng, J. Wang, Y. Chen, N. Ge, and C.-X. Wang, “Enabling
5g on the ocean: A hybrid satellite-uav-terrestrial network solution,”
IEEE Wireless Communications, vol. 27, no. 6, pp. 116–121, 2020.

[192] D. Mourtzis, V. Zogopoulos, and E. Vlachou, “Augmented reality
application to support remote maintenance as a service in the robotics
industry,” Procedia Cirp, vol. 63, pp. 46–51, 2017.
[193] J. Cheng, W. Chen, F. Tao, and C.-L. Lin, “Industrial
towards smart manufacturing,” Journal of

environment
Information Integration, vol. 10, pp. 10–19, 2018.

iot
in 5g
Industrial

[194] M. Erol-Kantarci and S. Sukhmani, “Caching and computing at the
edge for mobile augmented reality and virtual reality (ar/vr) in 5g,”
Ad Hoc Networks, pp. 169–177, 2018.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

38

[195] P. Ren, X. Qiao, Y. Huang, L. Liu, C. Pu, S. Dustdar, and J.-L. Chen,
“Edge ar x5: An edge-assisted multi-user collaborative framework for
mobile web augmented reality in 5g and beyond,” IEEE Transactions
on Cloud Computing, 2020.

[196] P. Zhou, B. Finley, X. Li, S. Tarkoma, J. Kangasharju, M. Ammar, and
P. Hui, “5g mec computation handoff for mobile augmented reality,”
arXiv preprint arXiv:2101.00256, 2021.

[197] W. C. Ng, W. Y. B. Lim, J. S. Ng, Z. Xiong, D. Niyato, and C. Miao,
“Uniﬁed resource allocation framework for the edge intelligence-
enabled metaverse,” arXiv preprint arXiv:2110.14325, 2021.

[198] P. Ren, L. Liu, X. Qiao, and J. Chen, “Distributed edge system
orchestration for web-based mobile augmented reality services,” IEEE
Transactions on Services Computing, no. 01, pp. 1–15, 2022.
[199] W. Zhang, B. Han, and P. Hui, “Sear: Scaling experiences in multi-user
augmented reality,” IEEE Transactions on Visualization and Computer
Graphics, vol. 28, no. 5, pp. 1982–1992, 2022.

[200] D. Van Huynh, S. R. Khosravirad, A. Masaracchia, O. A. Dobre, and
T. Q. Duong, “Edge intelligence-based ultra-reliable and low-latency
communications for digital twin-enabled metaverse,” IEEE Wireless
Communications Letters, 2022.

[201] J. Kang, D. Ye, J. Nie, J. Xiao, X. Deng, S. Wang, Z. Xiong, R. Yu,
and D. Niyato, “Blockchain-based federated learning for industrial
Incentive scheme with optimal aoi,” arXiv preprint
metaverses:
arXiv:2206.07384, 2022.

[202] M. F. Alam, S. Katsikas, and S. Hadjiefthymiades, “An intelligent and
modular sensing system for augmented reality application,” in 2015
9th International Conference on Sensing Technology (ICST).
IEEE,
2015, pp. 850–855.

[203] S. Kim and J.-H. Yun, “Motion-aware interplay between wigig and wiﬁ

for wireless virtual reality,” Sensors, vol. 20, no. 23, p. 6782, 2020.

[204] M. Sugimoto, “Cloud xr (extended reality: Virtual reality, augmented
reality, mixed reality) and 5g mobile communication system for
medical image-guided holographic surgery and telemedicine,” in Mul-
tidisciplinary Computational Anatomy. Springer, 2022, pp. 381–387.
[205] Y. Han, D. Niyato, C. Leung, C. Miao, and D. I. Kim, “A dynamic
resource allocation framework for synchronizing metaverse with iot
service and data,” in ICC 2022-IEEE International Conference on
Communications.
IEEE, 2022, pp. 1196–1201.

[206] Q. Zhang, J. Liu, and G. Zhao, “Towards 5g enabled tactile robotic

telesurgery,” arXiv preprint arXiv:1803.03586, 2018.

[207] R. Gupta, S. Tanwar, S. Tyagi, and N. Kumar, “Tactile-internet-based
telesurgery system for healthcare 4.0: An architecture,
research
challenges, and future directions,” IEEE Network, vol. 33, no. 6, pp.
22–29, 2019.

[208] H. M. Kusuma, V. K. Shukla, and S. Gupta, “Enabling vr/ar and
tactile through 5g network,” in 2021 International Conference on
Communication information and Computing Technology (ICCICT).
IEEE, 2021, pp. 1–6.

[209] G. Minopoulos, K. E. Psannis, S. Goudos, S. Nikolaidis, G. Kokkonis,
and Y. Ishibashi, “Efﬁcient integration of xr with haptic feedback
and 5g networks,” in 2021 IEEE 9th International Conference on
Information, Communication and Networks (ICICN).
IEEE, 2021,
pp. 240–244.

[210] K. Sartipi, R. C. DuToit, C. B. Cobar, and S. I. Roumeliotis, “Decen-
tralized visual-inertial localization and mapping on mobile devices for
augmented reality,” in 2019 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS).
IEEE, 2019, pp. 2145–2152.
[211] F. Guo, F. R. Yu, H. Zhang, H. Ji, V. C. Leung, and X. Li, “An
adaptive wireless virtual reality framework in future wireless networks:
A distributed learning approach,” IEEE Transactions on Vehicular
Technology, vol. 69, no. 8, pp. 8514–8528, 2020.

[212] D. Chen, L. J. Xie, B. Kim, L. Wang, C. S. Hong, L.-C. Wang,
and Z. Han, “Federated learning based mobile edge computing for
augmented reality applications,” in 2020 international conference on
computing, networking and communications (ICNC).
IEEE, 2020,
pp. 767–773.

[213] D. De, “Fedlens: federated learning-based privacy-preserving mobile
crowdsensing for virtual tourism,” Innovations in Systems and Software
Engineering, pp. 1–14, 2022.

[214] X. Chen and G. Liu, “Joint optimization of task ofﬂoading and resource
allocation via deep reinforcement learning for augmented reality in
mobile edge network,” in 2020 IEEE International Conference on
Edge Computing (EDGE).

IEEE, 2020, pp. 76–82.

[215] P. Lin, Q. Song, F. R. Yu, D. Wang, and L. Guo, “Task ofﬂoading for
wireless vr-enabled medical treatment with blockchain security using
collective reinforcement learning,” IEEE Internet of Things Journal,
vol. 8, no. 21, pp. 15 749–15 761, 2021.

[216] Y. Jiang, J. Kang, D. Niyato, X. Ge, Z. Xiong, and C. Miao,
“Reliable coded distributed computing for metaverse services:
Coalition formation and incentive mechanism design,” arXiv preprint
arXiv:2111.10548, 2021.

[217] R. Adeogun, G. Berardinelli, P. E. Mogensen, I. Rodriguez, and
M. Razzaghpour, “Towards 6g in-x subnetworks with sub-millisecond
communication cycles and extreme reliability,” IEEE Access, vol. 8,
pp. 110 172–110 188, 2020.

[218] C. Benzaid and T. Taleb, “Ai-driven zero touch network and service
management in 5g and beyond: Challenges and research directions,”
IEEE Network, vol. 34, no. 2, pp. 186–194, 2020.

[219] A. Rizwan, M. Jaber, F. Filali, A. Imran, and A. Abu-Dayya, “A
zero-touch network service management approach using ai-enabled
cdr analysis,” IEEE Access, vol. 9, pp. 157 699–157 714, 2021.
[220] B.-M. Andrus, S. A. Sasu, T. Szyrkowiec, A. Autenrieth, M. Chamania,
J. K. Fischer, and S. Rasp, “Zero-touch provisioning of distributed
video analytics in a software-deﬁned metro-haul network with p4
processing,” in Optical Fiber Communication Conference.
Optica
Publishing Group, 2019, pp. M3Z–10.

[221] M. Xu, D. Niyato, J. Kang, Z. Xiong, C. Miao, and D. I. Kim,
“Wireless edge-empowered metaverse: A learning-based incentive
mechanism for virtual reality,” arXiv preprint arXiv:2111.03776, 2021.
[222] A. Aijaz, Z. Dawy, N. Pappas, M. Simsek, S. Oteafy, and O. Holland,
“Toward a tactile internet reference architecture: Vision and progress
of the ieee p1918. 1 standard,” arXiv preprint arXiv:1807.11915, 2018.
[223] A. C. Baktir, A. Ozgovde, and C. Ersoy, “How can edge computing
beneﬁt from software-deﬁned networking: A survey, use cases, and
future directions,” IEEE Communications Surveys & Tutorials, vol. 19,
no. 4, pp. 2359–2391, 2017.

[224] W. Raﬁque, L. Qi, I. Yaqoob, M. Imran, R. U. Rasool, and W. Dou,
“Complementing iot services through software deﬁned networking and
edge computing: A comprehensive survey,” IEEE Communications
Surveys & Tutorials, vol. 22, no. 3, pp. 1761–1804, 2020.

[225] S. K. Sharma, I. Woungang, A. Anpalagan, and S. Chatzinotas, “To-
ward tactile internet in beyond 5g era: recent advances, current issues,
and future directions,” Ieee Access, vol. 8, pp. 56 948–56 991, 2020.

[226] C. Zhang, G. He, Y. Chen, P. Zhu, and S. Dou, “Challenges and
road ahead for wireless networks to serve immersive human centric
applications,” in 2020 IEEE 92nd Vehicular Technology Conference
(VTC2020-Fall).

IEEE, 2020, pp. 1–5.

[227] M. Maier and A. Ebrahimzadeh, “Towards immersive tactile internet
experiences: Low-latency ﬁwi enhanced mobile networks with edge
intelligence,” Journal of Optical Communications and Networking,
vol. 11, no. 4, pp. B10–B25, 2019.

[228] M. Chen, W. Saad, and C. Yin, “Deep learning for 360 content trans-
mission in uav-enabled virtual reality,” in ICC 2019-2019 IEEE Inter-
national Conference on Communications (ICC).
IEEE, 2019, pp. 1–6.
[229] A. El Saer, C. Stentoumis, I. Kalisperakis, L. Grammatikopoulos,
P. Nomikou, and O. Vlasopoulos, “3d reconstruction and mesh
optimization of underwater spaces for virtual reality,” The International
Archives of Photogrammetry, Remote Sensing and Spatial Information
Sciences, vol. 43, pp. 949–956, 2020.

[230] J. Zhang and F. Wu, “A method of ofﬂine reinforcement learning
virtual reality satellite attitude control based on generative adversarial
network,” Wireless Communications and Mobile Computing, vol.
2021, 2021.

[231] A. T. Z. Kasgari and W. Saad, “Stochastic optimization and control
framework for 5g network slicing with effective isolation,” in 2018
52nd Annual Conference on Information Sciences and Systems (CISS).
IEEE, 2018, pp. 1–6.

[232] K. Xu, “Electrical automation teaching based on vr virtual reality
technology,” in 2021 2nd Asia-Paciﬁc Conference on Image Processing,
Electronics and Computers, 2021, pp. 925–928.

[233] R. M. Sohaib, O. Onireti, Y. Sambo, and M. A. Imran, “Network
slicing for beyond 5g systems: An overview of the smart port use
case,” Electronics, vol. 10, no. 9, p. 1090, 2021.

[234] Y.-J. Liu, H. Du, D. Niyato, G. Feng, J. Kang, and Z. Xiong,
“Slicing4meta: An intelligent
integration framework with multi-
dimensional network resources for metaverse-as-a-service in web 3.0,”
arXiv preprint arXiv:2208.06081, 2022.
[235] M. Chen, W. Saad, and C. Yin, “Virtual

reality over wireless
networks: Quality-of-service model and learning-based resource
management,” IEEE Transactions on Communications, vol. 66, no. 11,
pp. 5621–5635, 2018.

[236] Y. Yang, L. Feng, C. Zhang, Q. Ou, and W. Li, “Resource allocation
for virtual
sharing based on 5g d2d multicast
communication,” EURASIP Journal on Wireless Communications and
Networking, vol. 2020, no. 1, pp. 1–12, 2020.

reality content

[237] H. Du, J. Liu, D. Niyato, J. Kang, Z. Xiong, J. Zhang, and D. I. Kim,
“Attention-aware resource allocation and qoe analysis for metaverse
xurllc services,” arXiv preprint arXiv:2208.05438, 2022.

[238] T. Dang and M. Peng, “Joint radio communication, caching, and
computing design for mobile virtual reality delivery in fog radio
access networks,” IEEE Journal on Selected Areas in Communications,
vol. 37, no. 7, pp. 1594–1607, 2019.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

39

[239] W.-C. Chien, H.-Y. Weng, and C.-F. Lai, “Q-learning based
collaborative cache allocation in mobile edge computing,” Future
generation computer systems, vol. 102, pp. 603–610, 2020.

[240] Y. Cai, J. Llorca, A. M. Tulino, and A. F. Molisch, “Joint compute-
for online data-intensive service

caching-communication control
delivery,” arXiv preprint arXiv:2205.01944, 2022.

[241] M. Zhao, Y. Zhou, J. Meng, H. Zheng, Y. Cai, Y. Shan, D. Guan,
and Z. Yang, “Virtual carbon and water ﬂows embodied in global
fashion trade - a case study of denim products,” Journal of Cleaner
Production, vol. 303, p. 127080, 2021.

[242] U. E. P. Agency. Greenhouse gas emissions from a typical passenger
https://www.epa.gov/greenvehicles/

vehicle.
greenhouse-gas-emissions-typical-passenger-vehicle

[Online]. Available:

[243] W. F. Network. National water

footprint.

[Online]. Available:

https://waterfootprint.org/en/water-footprint/national-water-footprint/

[244] C. Nugent. Airlines’ emissions halved during the pandemic. can the in-
dustry preserve some of those gains as travel rebounds. [Online]. Avail-
able: https://time.com/6048871/pandemic-airlines-carbon-emissions/

[245] M. Rasmussen. Touring the musical metaverse: Virtual concerts are
here to stay. [Online]. Available: https://www.virtualhumans.org/article/
touring-the-musical-metaverse-virtual-concerts-are-here-to-stay
[246] S. S. Kamble, A. Gunasekaran, H. Parekh, V. Mani, A. Belhadi,
and R. Sharma, “Digital twin for sustainable manufacturing supply
chains: Current
trends, future perspectives, and an implementation
framework,” Technological Forecasting and Social Change, vol. 176,
p. 121448, 2022.

[247] H. S. Govindasamy, R. Jayaraman, B. Taspinar, D. Lehner, and
M. Wimmer, “Air quality management: An exemplar for model-driven
twin engineering,” in ACM/IEEE International Conference
digital
on Model Driven Engineering Languages and Systems Companion
(MODEL-C), 2021, pp. 229–232.

[248] G. P. Lydon, S. Caranovic, I. Hischier, and A. Schlueter, “Coupled
simulation of thermally active building systems to support a digital
twin,” Energy and Buildings, vol. 202, p. 109298, 2021.

[249] S. M. E. Sepasgozar, “Differentiating digital twin from digital shadow:
Elucidating a paradigm shift to expedite a smart, sustainable built
environment,” Buildings, vol. 11, no. 4, p. 151, 2021.

[250] L. Zhao, H. Zhang, Q. Wang, and H. Wang, “Digital-twin-based
evaluation of nearly zero-energy building for existing buildings based
on scan-to-bim,” Advances in Civil Engineering, vol. 2021, no.
6638897, pp. 1–11, 2021.

[251] F. C. Moore, N. Obradovich, F. Lehner, and P. Baylis, “Rapidly
declining remarkability of temperature anomalies may obscure public
perception of climate change,” Proceedings of the National Academy
of Sciences, vol. 116, no. 11, pp. 4905–4910, 2019.

[252] D. M. Markowitz and J. N. Bailenson, “Virtual reality and the
psychology of climate change,” Current Opinion in Psychology,
vol. 42, pp. 60–65, 2021.

[253] M.

[254] J.

A.

Gardner.

Egkolfopoulou
all
not

in
the
[Online].
https://www.bloomberg.com/news/features/2021-12-06/

metaverse,
Available:
cryptopunk-nft-prices-suggest-a-diversity-problem-in-the-metaverse
metaverse

and
identities

[Online].
https://medium.com/building-the-metaverse/

Even
equal.

value-chain.

Available:
the-metaverse-value-chain-afcf9e09e3a7

Radoff.

created

The

are

[255] H. Duan, J. Li, S. Fan, Z. Lin, X. Wu, and W. Cai, “Metaverse for social
good: A university campus prototype,” in Proceedings of the 29th
ACM International Conference on Multimedia, 2021, pp. 153–161.

[256] H. Du, B. Ma, D. Niyato, and J. Kang, “Rethinking quality of
experience for metaverse services: A consumer-based economics
perspective,” arXiv preprint arXiv:2208.01076, 2022.

[257] K. J. Nevelsteen, “Virtual world, deﬁned from a technological perspec-
tive and applied to video games, mixed reality, and the metaverse,”
Computer Animation and Virtual Worlds, vol. 29, no. 1, p. e1752, 2018.
[258] L. V. Kiong, Metaverse Made Easy: A Beginner’s Guide to the
Metaverse: Everything you need to know about Metaverse, NFT and
GameFi. Liew Voon Kiong, 2022.

[259] D. Gursoy, S. Malodia, and A. Dhir, “The metaverse in the hospitality
and tourism industry: An overview of current
trends and future
research directions,” Journal of Hospitality Marketing & Management,
pp. 1–8, 2022.

[260] T. Um, H. Kim, H. Kim, J. Lee, C. Koo, and N. Chung, “Travel incheon
as a metaverse: Smart tourism cities development case in korea,” in
ENTER22 e-Tourism Conference. Springer, Cham, 2022, pp. 226–231.
[261] B. Ryskeldiev, Y. Ochiai, M. Cohen, and J. Herder, “Distributed meta-
verse: creating decentralized blockchain-based model for peer-to-peer
sharing of virtual spaces for mixed reality applications,” in Proceedings
of the 9th augmented human international conference, 2018, pp. 1–3.
[262] D. Bennett, “Remote workforce, virtual team tasks, and employee
engagement tools in a real-time interoperable decentralized metaverse.”

Psychosociological Issues in Human Resource Management, vol. 10,
no. 1, 2022.

[263] G. H. Popescu, C. F. Ciurl˘au, C. I. Stan et al., “Virtual workplaces in the
metaverse: Immersive remote collaboration tools, behavioral predictive
analytics, and extended reality technologies.” Psychosociological
Issues in Human Resource Management, vol. 10, no. 1, 2022.
[264] P. Ludlow and M. Wallace, The Second Life Herald: The virtual
tabloid that witnessed the dawn of the metaverse. MIT press, 2007.
the metaverse change health

[265] J. Thomason, “Metahealth-how will

care?” Journal of Metaverse, vol. 1, no. 1, pp. 13–16, 2021.

[266] T. F. Tan, Y. Li, J. S. Lim, D. V. Gunasekeran, Z. L. Teo,
W. Y. Ng, and D. S. Ting, “Metaverse and virtual health care in
ophthalmology: Opportunities and challenges,” The Asia-Paciﬁc
Journal of Ophthalmology, vol. 11, no. 3, pp. 237–246, 2022.
[267] D. Shin, “The actualization of meta affordances: Conceptualizing
affordance actualization in the metaverse games,” Computers in
Human Behavior, vol. 133, p. 107292, 2022.

[268] S. Hamilton, “Deep learning computer vision algorithms, customer
engagement
tools, and virtual marketplace dynamics data in the
metaverse economy.” Journal of Self-Governance & Management
Economics, vol. 10, no. 2, 2022.

[269] S. Mackenzie, “Criminology towards the metaverse: Cryptocurrency
scams, grey economy and the technosocial,” The British Journal of
Criminology, 2022.

[270] S. Mystakidis, “Metaverse,” Encyclopedia, vol. 2, no. 1, pp. 486–497,

2022.

[271] P. Fernandez, “Facebook, meta, the metaverse and libraries,” Library

Hi Tech News, 2022.

[272] J. Kim, “Advertising in the metaverse: Research agenda,” Journal of

Interactive Advertising, vol. 21, no. 3, pp. 141–144, 2021.

[273] R. Cheng, N. Wu, S. Chen, and B. Han, “Will metaverse be nextg inter-
net? vision, hype, and reality,” arXiv preprint arXiv:2201.12894, 2022.
[274] D. Vidal-Tom´as, “The new crypto niche: Nfts, play-to-earn, and
metaverse tokens,” Finance Research Letters, p. 102742, 2022.
[275] L. Ante, “Non-fungible token (nft) markets on the ethereum
blockchain: Temporal development, cointegration and interrelations,”
Available at SSRN 3904683, 2021.

[276] H. Fourati, R. Maaloul, L. Chaari, and M. Jmaiel, “Comprehensive
survey on self-organizing cellular network approaches applied to 5g
networks,” Computer Networks, vol. 199, p. 108435, 2021.

[277] S. Vittal et al., “Self optimizing network slicing in 5g for slice isolation
and high availability,” in 2021 17th International Conference on
Network and Service Management (CNSM).
IEEE, 2021, pp. 125–131.
[278] Z. Nadir, T. Taleb, H. Flinck, O. Bouachir, and M. Bagaa, “Immersive
services over 5g and beyond mobile systems,” IEEE Network, vol. 35,
no. 6, pp. 299–306, 2021.

[279] F. Rinaldi, H.-L. Maattanen, J. Torsner, S. Pizzi, S. Andreev, A. Iera,
Y. Koucheryavy, and G. Araniti, “Non-terrestrial networks in 5g &
beyond: A survey,” IEEE access, vol. 8, pp. 165 178–165 200, 2020.

[280] B. Lin, J. Duan, M. Han, and L. X. Cai, “Next generation marine

wireless communication networks,” pp. 1–143, 2022.

[281] H. Du, D. Niyato, J. Kang, D. I. Kim, and C. Miao, “Optimal
targeted advertising strategy for secure wireless edge metaverse,”
arXiv preprint arXiv:2111.00511, 2021.

[282] S. Ghafoor, N. Boujnah, M. H. Rehmani, and A. Davy, “Mac protocols
for terahertz communication: A comprehensive survey,” IEEE Commu-
nications Surveys & Tutorials, vol. 22, no. 4, pp. 2236–2282, 2020.

[283] M. Zawish, N. Ashraf, R.

I. Ansari, S. Davy, H. K. Qureshi,
N. Aslam, and S. A. Hassan, “Towards on-device ai and blockchain
for 6g enabled agricultural supply-chain management,” arXiv preprint
arXiv:2203.06465, 2022.

[284] M. Zawish, S. Davy, and L. Abraham, “Complexity-driven cnn
ai,” arXiv preprint

resource-constrained edge

compression for
arXiv:2208.12816, 2022.

[285] B. Han, W. Jiang, M. A. Habibi, and H. D. Schotten, “An abstracted
survey on 6g: Drivers, requirements, efforts, and enablers,” arXiv
preprint arXiv:2101.01062, 2021.

[286] T. Chen, M. Zhao, Q. Shi, Z. Yang, H. Liu, L. Sun, J. Ouyang,
and C. Lee, “Novel augmented reality interface using a self-powered
triboelectric based virtual reality 3d-control sensor,” Nano Energy,
vol. 51, pp. 162–172, 2018.

[287] M. Eshghie, L. Quan, G. A. Kasche, F. Jacobson, C. Bassi, and
C. Artho, “Circlechain: Tokenizing products with a role-based scheme
for a circular economy,” arXiv preprint arXiv:2205.11212, 2022.
[288] M. Deveci, A. R. Mishra, I. Gokasar, P. Rani, D. Pamucar, and
E. Ozcan, “A decision support system for assessing and prioritizing
sustainable urban transportation in metaverse,” IEEE Transactions on
Fuzzy Systems, vol. Early Access, pp. 1–10, 2022.

[289] S. A. Khowaja, K. Dev, N. M. F. Qureshi, P. Khuwaja, and L. Foschini,
“Toward industrial private ai: A two-tier framework for data and

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021

40

model security,” IEEE Wireless Communications, vol. 29, no. 2, pp.
76–83, 2022.

[290] S. A. Khowaja, I. H. Lee, K. Dev, M. A. Jarwar, and N. M. F. Qureshi,
“Get your foes fooled: Proximal gradient split learning for defense
against model inversion attacks on iomt data,” IEEE Transactions on
Network Science and Engineering, vol. Early Access, pp. 1–10, 2022.
[291] Y. Zhang, X. Ma, J. Zhang, M. S. Hossain, G. Muhammad, and
S. U. Amin, “Edge intelligence in the cognitive internet of things:
Improving sensitivity and interactivity,” IEEE Network, vol. 33, no. 3,
pp. 58–64, 2019.

[292] L. U. Khan, I. Yaqoob, N. H. Tran, Z. Han, and C. S. Hong, “Network
slicing: Recent advances, taxonomy, requirements, and open research
challenges,” IEEE Access, vol. 8, pp. 36 009–36 028, 2020.

[293] H. Lee, D. Woo, and S. Yu, “Virtual reality metaverse system sup-
plementing remote education methods: Based on aircraft maintenance
simulation,” Applied Sciences, vol. 12, no. 5, p. 2667, 2022.

[294] S. Tayal, K. Rajagopal, and V. Mahajan, “Virtual

reality based
metaverse of gamiﬁcation,” in 2022 6th International Conference on
Computing Methodologies and Communication (ICCMC).
IEEE,
2022, pp. 1597–1604.

[295] B. Kye, N. Han, E. Kim, Y. Park, and S. Jo, “Educational applications
of metaverse: possibilities and limitations,” Journal of Educational
Evaluation for Health Professions, vol. 18, 2021.

[296] J. Wu, R. Li, X. An, C. Peng, Z. Liu, J. Crowcroft, and H. Zhang,
“Toward native artiﬁcial intelligence in 6g networks: System design,
architectures, and paradigms,” arXiv preprint arXiv:2103.02823, 2021.

