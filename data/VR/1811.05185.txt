0
2
0
2

y
a
M
5

]

M
M

.
s
c
[

2
v
5
8
1
5
0
.
1
1
8
1
:
v
i
X
r
a

SPHERICAL CLUSTERING OF USERS NAVIGATING 360◦ CONTENT

Silvia Rossi⋆

Francesca De Simone†

Pascal Frossard‡

Laura Toni ⋆

⋆ Department of Electronic & Electrical Engineering, UCL, London (UK)
† DIS, Centrum Wiskunde & Informatica, The Netherlands
‡ LTS4, ´Ecole Polytechnique F´ed´erale de Lausanne (EPFL), Switzerland
E-mails: {s.rossi, l.toni}@ucl.ac.uk, F.De.Simone@cwi.nl, pascal.frossard@epfl.ch

ABSTRACT

In Virtual Reality (VR) applications, understanding how users ex-
plore the visual content is important in order to optimize content
creation and distribution, develop user-centric services, or even to
detect disorders in medical applications. In this paper, we propose a
graph-based method to identify clusters of users who are attending
the same portion of spherical content, within one frame or a series
of frames. With respect to other clustering methods, the proposed
solution takes into account the spherical geometry of the content and
correctly identiﬁes clusters that group viewers who actually display
the same portion of spherical content. Results, carried out by using
a set of publicly available VR user navigation patterns, show that the
proposed method identiﬁes more meaningful clusters, i.e., clusters
of users who are consistently attending the same portion of spherical
content, with respect to other methods.

Index Terms— Virtual Reality, 360◦ video, user behaviour anal-

ysis, data clustering

1. INTRODUCTION

Virtual Reality (VR) systems are expected to become wide spread
in a near future, with applications in a variety of ﬁelds, ranging
from entertainment to e-healthcare. These systems involve omni-
directional (i.e., 360◦) videos, which are visual signals deﬁned on a
virtual sphere, depicting the 360◦ surrounding scene. The viewer,
virtually positioned at the centre of the sphere, can navigate the
scene with three Degrees-Of-Freedoms (3-DOF), i.e., yaw, pitch and
roll, by rotating his head and changing his viewing direction. This
interactive navigation is typically enabled by a head-mounted dis-
play (HMD), which renders at each instant in time only the portion
of the spherical content attended by the user, i.e., the viewport.

Understanding how users explore the VR content is important in
order to optimize content creation [1] and distribution [2–6], develop
user-centric services [7,8], and even for medical applications that use
VR to study psychiatric disorders [9]. In the last few years, many
studies have appeared collecting and analysing the navigation pat-
terns of users watching VR content [6, 8, 10–16]. Most studies build
content-dependent saliency maps as main outcome of their analysis,
which compute the most probable region of the sphere attended by
the viewers, based on their head or eye movements [6, 10, 17–19].
Some studies also provide additional quantitative analysis based on
metrics, such as the average angular velocity, frequency of ﬁxa-
tion, and mean exploration angles [8, 13]. Models to predict future

saliency maps have also been proposed [20–22]. Nevertheless, none
of these studies performs clustering of the navigation patterns, i.e.,
none provides quantitative data indicating how many groups of users
consistently share the same behaviour over time, by attending a sig-
niﬁcantly overlapping portion of the 360◦ content. This information
can be useful in order to improve the accuracy and robustness of
algorithms predicting users navigation patterns. A proper cluster-
ing could also be useful to reﬁne user-centric distribution strategies,
where for example different groups of users might be served with
high quality content in the different portions of the sphere that will
be more likely attended by the viewers.

To the best of our knowledge, studies identifying clusters for
omnidirectional content delivery have appeared only recently [23,
24]. User clustering is employed to identify the number of Region
of Interests (RoIs) over time and to perform long-term prediction,
associating to each user the future trajectory of the cluster that user
belong to. In [23], the viewport center, i.e., the viewing direction
of each user at each instant in time, is considered as a point on the
equirectangular planar representation of the spherical content. These
points on the plane are then clustered based on their Euclidean dis-
tance, which unfortunately ignores the actual spherical geometry of
the navigation domain. Conversely, in [24] each user navigation
pattern is modelled as independent trajectories in roll, pitch, and
yaw angles, and spectral clustering is then applied. While it is ef-
ﬁcient in discovering general trends of users’ navigation, this clus-
tering methodology might fail to identify clusters that are consistent
in terms of actual overlap between viewports displayed by differ-
ent users. It means that users in the same cluster do not necessarily
consume the same portion of content. At the same time, this consis-
tency needs to be guaranteed for clustering methods to be used for
prediction purposes or for implementing accurate user-based deliv-
ery strategies.

The goal of this paper is to propose a novel clustering strategy
able to detect meaningful clusters in the spherical domain. We con-
sider as meaningful cluster a set of users attending the same portion
of spherical content at a given time instant or over a series of frames.
This implies that the overlap between the viewports of all users in a
cluster must be substantial. With this goal in mind, ﬁrst we deﬁne
a metric to quantify the geometric overlap between two viewports
on the sphere (Section II). Then, we use this metric to build a graph
whose nodes are the centers of the viewports associated to differ-
ent users. Two nodes are connected only if the two corresponding
viewports have a signiﬁcant overlap (Section III). Finally, we pro-
pose a clustering method based on the Bron-Kerbosch (BK) algo-
rithm [25] to identify clusters that are cliques, i.e., sub-graphs of
inter-connected nodes (Section III). Results demonstrate the con-

 
 
 
 
 
 
sistency of the proposed clustering method in identifying clusters
where the overlap between the portions of the spherical surface cor-
responding to different viewports is higher than in state-of-the-art
clustering (Section IV). In summary, the main contribution of this
paper is to propose a clustering algorithm that i) considers the spher-
ical geometry of the data, ii) identiﬁes clusters in which there is a
consistent and signiﬁcant geometric overlap between the portions of
spherical surface corresponding to viewports attended by different
users (by imposing that clusters are cliques), iii) can be applied to
a single frame or to a series of frames. This is a useful new tool to
improve the accuracy of user’s navigation prediction algorithms and
user-dependent VR content delivery strategies, such as those pro-
posed in [23, 24].

2. GEODESIC DISTANCE AS PROXY OF VIEWPORT
OVERLAP

Our goal is to identify clusters of users who are displaying the same
portion of spherical content within a frame or over a series of con-
secutive frames. We derive a similarity metric that reliably quantiﬁes
how similar the portions attended by two users are. More speciﬁ-
cally, each user attends a portion of the spherical surface. This is the
projection on the spherical surface of a plane tangent to the sphere
(i.e., viewport) in the point that identiﬁes the user’s viewing direc-
tion (center of the viewport)1. The overlap between the viewports
attended by two users at an instant in time is a clear indicator of how
similar users are with respect to their displayed viewports. For ex-
ample, an overlap equal to the area of the viewport corresponds to
two users attending exactly the same portion of visual content. The
geometric overlap could be analytically computed, knowing the ro-
tation associated to each user head’s position (i.e., roll, pitch, and
yaw) and the horizontal and vertical ﬁelds of view that deﬁne the
viewport. However, this is non trivial. Thus, we propose the simple
and straightforward solution of using the geodesic distance between
two viewport centres as a proxy for the viewport overlap.

By geodesic distance we denote the length of the shortest arc
connecting the viewport centers on the sphere. Such distance is
clearly an approximation of the actual area overlap: it does not ac-
count for the three degrees of freedom of the user’s head rotation,
which deﬁne the exact viewport. As a result, viewports whose cen-
ters have the same geodesic distance could correspond to a different
viewport overlap (example in Figure 1). Nevertheless, the smaller
the distance between viewport centers, the smaller the approxima-
tion error with geodesic distance. As an example, Figure 2 shows
the pairwise geodesic distance (in blue) and the pairwise area over-
lap (in red) between the viewport attended by one user and those
of 58 other users, for a frame of a video sequence, extracted from
the public dataset proposed in [13]. The correlation between the
two metrics is evident: if the overlap is high, the geodesic distance
between the two viewport centres is low. Particularly, a viewport
area overlap larger than 75% of the viewport area corresponds to a
geodesic distance smaller than 3π/4. We are therefore interested in
identifying a threshold value below which the geodesic distance is a
robust proxy of the viewports overlap.

To empirically deﬁne this threshold, we built the Receiver Op-
erating Characteristic (ROC) curve as follows. We assume that two
users are attending the same portion of content if their viewports
overlap by at least Oth of the total viewport area. We then deﬁne
a threshold value for the geodesic distance Gth such that users are

1Without loss of generalization, we consider a scenario in which the view-

ports of all users have the same horizontal and vertical ﬁeld of view.

(a) 87% overlap

(b) 58% overlap

Fig. 1. Viewports (in green and blue) with π/10 centre distance. (a)
viewports are aligned with an overlap of 87%, (b) one viewport is
rotated by π/2 resulting an overlap of 58%.

/10
/8

3* /4

/2

/4

e
c
n
a
t
s
d

i

i

c
s
e
d
o
e
g

Pairwise geodesic distance

Pairwise area overlap

5

10

15

20

25

30
users

35

40

45

50

55

100

75

50

25

0

p
a
l
r
e
v
o

t
r
o
p
w
e
v
%

i

Fig. 2. Comparison between pairwise geodesic distance and view-
port overlap in one frame of video Rollercoaster from [13].

neighbours if their geodesic distance is below threshold. Anytime
users are neighbors but their overlap is less than Oth, we experience
a false positive. Conversely, a true positive is experienced if users
that are neighbors also experience an overlap equal or higher than
Oth. Equipped with these deﬁnitions, we can compute the ROC by
considering all the videos and user’ navigation patterns included in
the dataset described in [13]. Figure 3 shows the curve obtained in
our scenario with Oth = 80%. On the x axis of the ROC curve there
is the False Positive Rate (FPR) i.e., probability to have a wrong
classiﬁcation over the number of actual negative events. This rate
should be as small as possible. On the contrary, the True Positive
Rate (TPR) on the y axis represents the probability to correctly clas-
sify an event. The best value of geodesic distance is π/10 since
it corresponds to a TPR value equal to 1, which in our application
means a sure identiﬁcation of viewports with an overlap of at least
80% based on the geodesic distance between their centers. There-
fore, in the following we assume Gth = π/10 as a suitable thresh-
old to robustly approximate the area overlap between two viewports
by means of the geodesic distance between their centers.

3. CLIQUE-BASED CLUSTERING ALGORITHM

We now describe the proposed clustering algorithm, aimed at iden-
tifying clusters of users having a common viewport overlap. We
model the evolution of users’ viewports over a time-window T , i.e.,
a series of consecutive frames, as a set of graphs {Gt}T
t=1. Each
unweighted and undirected graph Gt = {V, Et, Wt} represents the
set of users2 viewports at a particular instant t, where V and Et de-

2Without loss of generality, we assume that the set of users does not
change over time. This covers also cases in which users’ devices are not
synchronized in the acquisition time, as users’ positions are usually interpo-
lated to create a synchronized dataset.

 
 
 
1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

e

t

a
r
e
v
i
t
i
s
o
p
e
u
r
T

0

0

0.1

0.2

0.3

0.4
0.6
0.5
False positive rate

0.7

0.8

0.9

1

0

/50
2* /25
3* /50
2* /25
/10
3* /25
7* /25
4* /25
9* /50
/5

11* /50
6* /25
13* /50
7* /25
3* /10
8* /25
17* /50
9* /25
19* /50
2* /5
21* /50
11* /25
23* /50
12* /25

/2

Fig. 3. ROC curve to evaluate optimal Gth considering all video in
database [13] and Oth = 80% .

note the node and edge sets of Gt. Each node in V corresponds to
a user interacting with the 360◦ content. Each edge in Et connects
neighbouring nodes, where two nodes are neighbours if the geodesic
distance between the viewport centers associated to the users repre-
sented by the nodes is lower than Gt, as deﬁned in Section II. The
binary matrix Wt is the adjacency matrix of Gt, with wt(i, j) = 1
if the geodesic distance between the two viewport centres of users i
and j at time t is below a threshold. More formally:

wt(i, j) =

if g(i, j) ≤ Gth

0,
1, otherwise

(

(1)

where g(i, j) is the geodesic distance between the viewport centres
of users i and j and Gth is thresholding value, discussed in Section
II. Note that the clique-based clustering algorithm that we present in
the following gets in input binary adjacency matrices. Hence, Wt is
binary.

T
t=1, we are interested in
Looking at the graphs over time {Gt}
clustering users based on their trajectories within a time window T .
Similarly to other clusters of trajectories [26], we derive an afﬁnity
matrix A that will be the input to our clustering algorithm, with

T

a(i, j) = ID

wt(i, j)

(2)

t=1
X

!

where ID(x) = 1 if x ≥ τ and 0 otherwise. This means that in the
ﬁnal graph two nodes, representing two users, are neighbours, i.e.,
connected by an edge, only if the corresponding viewports have a
signiﬁcant overlap in D instants over T . In the case of τ = T , we
obtain a(i, j) = IT
t Wt, and users’ viewport
centers need to be always at a distance below threshold Gt. This
(cid:1)
condition is however too constraining, therefore we introduce the
threshold value τ .

t wt(i, j)

(cid:0)P

Q

=

The goal of our clustering algorithm is to identify groups of
users that are consistently attending the same portion of the spheri-
cal surface. To ensure that all users belonging to a cluster are attend-
ing the same area, they all need to be neighbors (i.e., a(i, j) = 1
for all pairs of users i and j in the cluster). Therefore, we propose
a clique-based clustering. In graph theory, a set of nodes all con-
nected to each other is called a clique. A clique perfectly matches
with the deﬁnition of cluster needed in our application, which iden-
tiﬁes a set of users all having signiﬁcant pairwise viewport overlaps,
thus attending a common portion of video. We consider the Bron-
Kerbosch (BK) algorithm [25] to ﬁnd all maximal cliques present
in our graph (i.e., the most populated sub-graphs forming cliques).
However, maximal cliques identiﬁed by the BK algorithm can inter-
sect, i.e., one user can belong to more than one clique. Conversely,

Fig. 4. Graphical example of the proposed clique clustering.

t Wt), QQQ = [{∅}, . . . , {∅}]

Algorithm 1 Clique-Based Clustering
T
t=1, D
{Gt}

Input:
Output: K, QQQ = [Q1, ..., QK]
i = 1, A(1) = ID(
Init:
repeat

P

⋆

= arg maxl |Cl|

CCC = [C1, ..., CL] ← KB(A(i))
l
Qi = Cl⋆
A(i+1) = A(i)(CCC \ Cl⋆)
i ← i + 1

until A(i) is not empty;
K = i − 1

we are interested in identifying disjoint sets3.Hence, our clustering
method consists of iterations of BK instances, as depicted in Fig-
ure 4. We initialize the clustering method by evaluating the afﬁnity
matrix from Eq. (2). Then, we perform the following steps (Algo-
rithm 1):

1. Maximal cliques in the graph are detected by the BK algo-

rithm.

2. Among the resulting cliques, only the most populated one
(i.e., the one with the highest cardinality) is kept as a clus-
ter.

3. A new afﬁnity matrix is built, eliminating the entries corre-
sponding to the elements of the cluster identiﬁed in Step 2.

These three steps are repeated until all nodes are assigned to clusters.
It is worth mentioning that this iterative selection does not guaran-
tee optimal clusters (i.e., clusters with maximal joint overlap among
the viewports of users belonging to a cluster). However, i) it im-
poses viewport overlap among users within a cluster, ii) it identiﬁes
highly populated clusters, which can be translated in reliable trajec-
tories/behaviours shared among users.

4. EXPERIMENTAL RESULTS

The proposed clustering algorithm is compared to state-of-the-art so-
lutions, namely the Louvain method [27], the K-means clustering
[28] and the clustering of VR trajectories proposed in [24] (labelled
“SC”). We use the geodesic distance between viewport centers as
distance metric in all algorithms. Moreover, in the K-means cluster-
ing, the number of clusters K is imposed as the value achieved by
the Louvain method (labelled “K-means 1”), as well as the K value
obtained from our proposed clustering (labelled “K-means 2”). The
proposed implementations have been made publicly available 4. We

3Clusters should be disjoint for most content-delivery applications. For
example, if clusters are used for prediction, each user must belong only to
one cluster.

4https://github.com/LASP-UCL/spherical-clustering-in-VR-content.

 
 
 
s
0
3
~

.
r
F
s
0
4
~

.
r
F
s
0
5
~

.
r
F

K
Mean Overlap Cl.(% user >3)
Main cl. overlap (% users)
K
Mean Overlap Cl.(% users >3)
Main cl. overlap (% users)
K
Mean Overlap Cl.(% users >3)
Main cl. overlap (% users)

Louvain method
10
38.90 % (84.75 %)
26.70% (44.10%)
8
35.60% (89.83%)
24.20% (45.80%)
8
48.20% (89.80%)
46.40%(30.50 %)

ROLLERCOASTER

Clique Clustering
15
62.50 % (76.30 %)
58.60% (30.50%)
15
65.75% (76.30%)
58.33% (35.60%)
12
65.70% (86.45%)
59.90% (57.70%)

K-Means 1
10
53.95 % (93.20 %)
48.30% (19% )
8
44.38% (100%)
0% (30.50%)
8
43.50% (98.30%)
0% (22.40%)

TIMELAPSE

K-Means 2
15
48.10 % (94.90 %)
0% (20.70% )
15
47.65% (84.75%)
0% (15.25%)
12
55.30% (96.60%)
0% (15.25%)

Clique Clustering
Louvain
13
24
46 % (89.70%)
72.35% (56.90%)
32.90% (20.70%)
69% (12.10% )
18
27
47.65 % (75.90%)
72.95 % (77.60%)
51.80% (20.70%)
63.70% (17.24%)
18
29
71.40% (51.70%)
49.12 % (77.60%)
30.60 (22.40%)% 70.80% (25.90%)

K-Means 1
13
45.90% (96.50 %)
15% (19% )
18
60.27% (96.55%)
47.50% (20.70%)
18
48.36 % (87.90%)
37% (24.15%)

K-Means 2
24
51.50% (50%)
23.50% (13.80%)
27
65.90% (84.50%)
33.60% (8.60%)
29
55.90 % (55.17%)
62.71% (17.24%)

Table 1. Clustering analysis of users in three selected frames from Rollercoaster (ﬁrst half) and Timelapse (second half). In brackets, the
percentage of covered population.

test these algorithms on two 1-minute long video sequences (Roller-
coaster and Timelapse), which have been watched by 59 users whose
navigation paths are publicly available [13]. Rollercoaster has one
main RoI (i.e., the rail) while in Timelapse, there are many fast mov-
ing objects (e.g., buildings, people) along the equator line.

Frame-based Clustering. First, we consider frame-based clus-
tering, in which users are identiﬁed by their viewport centers at one
given frame. Table 1 reports results in terms of number of clusters
(K), mean viewport overlap computed within each cluster composed
by at least three users, and viewport overlap within the most pop-
ulated cluster, that we refer to as the main cluster. The viewport
overlap within a cluster is the joint overlap across all users’ view-
ports in the cluster. The mean overlap is computed by averaging the
viewport overlap of all clusters with at least three users identiﬁed at a
given frame. In Table 1, we also provide the percentage of users cov-
ered by clusters. The proposed algorithm always ensures the highest
viewport overlap (on average always over 50%) with respect to the
other methods. This is due to the implicit constraint that is imposed
by the clique-based detection of the clusters. This constraint leads
to the identiﬁcation of clusters that are populated and yet meaning-
ful (i.e., with large viewport overlap among users). For example, in
Rollercoaster at frame 40s, our algorithm identiﬁes a main cluster
grouping 35% of the population with a viewport overlap of 58.33%.
This is much higher than the overlap of 24.20% (0%) in the main
cluster identiﬁed by the Louvain (K-means) method. Beyond the
accuracy, another important parameter is the percentage of the pop-
ulation that is covered by clusters with a signiﬁcant number of users.
These clusters are the most useful ones to allow predictions. For
instance in Timelapse at frame 50s, our method identiﬁes a large
number of clusters (29), which also includes single users clusters.
Nevertheless, half of the population (51.70%) belongs to clusters
with more than 3 users with high value of joint overlap (71.40%).

Trajectory-based clustering.

Second, we test the proposed
algorithm over a time-window with T = 3s and τ = 1.8s. In this
case we compare the proposed solution with algorithm SC [24]. The
algorithm SC is applied to trajectories spanning the entire video, as
in [24], as well as consecutive time windows of 3s. We also con-
sider the case of SC in which the number of clusters K is not eval-
uated from their afﬁnity matrixbut it is imposed as the K obtained
from our solution. We label this clustering (“SC - K given”). Fig-
ure 5 shows results in terms of overlap among viewports clustered
together in both Rollercoster (a) and Timelapse (b). In more details,
all users are clustered over consecutive time-windows of T seconds
each. Then, for each frame the viewport overlap among all users
within one cluster is evaluated and averaged across clusters. The
mean overlap (solid line) and the variance (shaded area) is ﬁnally
depicted in the ﬁgure. Moreover, the mean value of joint overlap in
clusters with more than three users across the entire video is showed
in the legend. Our solution outperforms SC in terms of mean over-
lap but also in terms of variance. The latter shows the stability of

s
P
V
n
o

i
t
c
e
s
r
e

t

n

i

l
l

a
r
e
v
O
%

100

90

80

70

60

50

40

30

20

10

0

s
P
V
n
o
i
t
c
e
s
r
e
t
n

i

l
l

a
r
e
v
O
%

100

90

80

70

60

50

40

30

20

10

0

Clique clustering  (66.96 %)
SC - T = 3s 
(8.20 %)
SC - entire video  (24.81%)
(48.05%)
SC - K given 

5

10

15

20

25

30
sec

35

40

45

50

55

(a) Rollercoaster video - T = 3 s.

Clique clustering  (72.22%)
(3.24%)
SC - T = 3s 
SC - entire video  (2.45%)
SC - K given 

(26.43%)

5

10

15

20

25

30
sec

35

40

45

50

55

(b) Timelapse video - T = 3 s.

Fig. 5. Mean and variance of the joint overlap across clusters over
time. In the legend, the mean value of joint viewport overlap of clus-
ters with more than three users performed across the entire video.

our clustering method ensuring for each cluster a consistent overlap
over time. Finally, the performance gain is signiﬁcant also in terms
of overlap in the most populated clusters (value provided in the leg-
end).

5. CONCLUSIONS

In this paper, we proposed a novel graph-based clustering strategy
able to detect meaningful clusters, i.e., group of users consuming the
same portion of a virtual reality spherical content. First, we derived
a geodesic distance threshold value to reﬂect the similarity among
users and then we built a clique-based clustering based on this met-
ric. Results on a set of publicly available VR user navigation patterns
show that the proposed method identiﬁes more meaningful clusters
with respect to other state-of-the-art clustering methods. The as-
sociated code has been made publicly available for future compar-
isons. Future works will focus on the application of our method in
the framework of adaptive streaming of VR videos and for the pre-
diction of user navigation patterns.

 
 
 
 
 
 
head rotations watching 360 videos on an HMD,” in Proceed-
ings of the 9th ACM Multimedia Systems Conference (MMSys),
2018.

[16] A. Singla, S. Fremerey, W. Robitza, P. Lebreton, and A. Raake,
“Comparison of Subjective Quality Evaluation for HEVC En-
coded Omnidirectional Videos at Different Bit-rates for UHD
and FHD Resolution,” in Proceedings of the ACM Conference
on Multimedia (MM) Thematic Workshops, 2017.

[17] A. Duchowski and G. Marmitt, Modeling Visual Attention in
VR: Measuring the Accuracy of Predicted Scanpaths, Ph.D.
thesis, 2002.

[18] E. J. David, J. Guti´errez, A. Coutrot, M. Da Silva, and
P. Le Callet, “A Dataset of Head and Eye Movements for 360◦
Videos,” in Proceedings of the 9th ACM Multimedia Systems
Conference (MMSys), 2018.

[19] Y. Rai, P. Le Callet, and P. Guillotel, “Which saliency weight-
ing for omni directional image quality assessment?,” in In-
ternational Conference on Quality of Multimedia Experience
(QoMEX), May 2017.

[20] I. Bogdanova, A. Bur, and H. Hugli, “Visual Attention on the
Sphere,” IEEE Transactions on Image Processing, vol. 17, no.
11, Nov 2008.

[21] I. Bogdanova, A. Bur, H. H¨ugli, and P. Farine, “Dynamic visual
attention on the sphere,” Computer Vision and Image Under-
standing, vol. 114, no. 1, 2010.

[22] M. Xu, J. Song, Y.and Wang, M. Qiao, L. Huo, and Z. Wang,
“Modeling Attention in Panoramic Video: A Deep Reinforce-
ment Learning Approach,” arXiv preprint arXiv:1710.10755,
2017.

[23] L. Xie, X. Zhang, and Z. Guo, “CLS: A Cross-user Learning
based System for Improving QoE in 360-degree Video Adap-
tive Streaming,” in ACM Multimedia Conference on Multime-
dia Conference (MM), 2018.

[24] S. Petrangeli, G. Simon, and V/ Swaminathan, “Trajectory-
Based Viewport Prediction for 360-Degree Virtual Reality
Videos,” in IEEE conference on Artiﬁcial Intelligence and Vir-
tual Reality (AIVR), 2018.

[25] C. Bron and J. Kerbosch, “Algorithm 457: ﬁnding all cliques
of an undirected graph,” Communications of the ACM, vol. 16,
no. 9, 1973.

[26] S. Atev, G. Miller, and N. P. Papanikolopoulos, “Clustering of
vehicle trajectories,” IEEE Transactions on Intelligent Trans-
portation Systems, vol. 11, 2010.

[27] V. D. Blondel, J. Guillaume, and E. Lambiotte, R.and Lefebvre,
“Fast unfolding of communities in large networks,” Journal of
statistical mechanics: theory and experiment, , no. 10, 2008.

[28] J. Hartigan and M. Wong, “Algorithm as 136: A k-means clus-
tering algorithm,” Journal of the Royal Statistical Society, vol.
28, 1979.

6. REFERENCES

[1] A. Serrano, V. Sitzmann,

J. Ruiz-Borau, G. Wetzstein,
D. Gutierrez, and B. Masia, “Movie editing and cognitive event
segmentation in virtual reality video,” vol. 36, 2017.

[2] S. Rossi and L. Toni, “Navigation-Aware Adaptive Stream-
ing Strategies for Omnidirectional Video,” in IEEE 19th Inter-
national Workshop on Multimedia Signal Processing (MMSP),
2017.

[3] X. Corbillon, G. Simon, A. Devlic, and J. Chakareski,
“Viewport-adaptive navigable 360-degree video delivery,” in
IEEE International Conference on Communications (ICC),
2017.

[4] S. Petrangeli, V. Swaminathan, M. Hosseini, and F. De Turck,
“An HTTP/2-Based Adaptive Streaming Framework for 360
Virtual Reality Videos,” in Proceedings of the 2017 ACM on
Multimedia Conference, 2017.

[5] C. Fan, J. Lee, C. Lo, W.and Huang, K. Chen, and Cheng-H.
H., “Fixation Prediction for 360 Video Streaming in Head-
Mounted Virtual Reality,” in Proceedings of the 27th Workshop
on Network and Operating Systems Support for Digital Audio
and Video. ACM, 2017.

[6] M. Yu, H. Lakshman, and B. Girod, “A Framework to Evalu-
ate Omnidirectional Video Coding Schemes,” in IEEE Interna-
tional Symposium on Mixed and Augmented Reality (ISMAR),
2015.

[7] M. Broeck, F. Kawsar, and J. F. Sch¨oning, “It’s all around
you: Exploring 360-degree video viewing experiences on mo-
bile devices,” in Proceedings of the 2017 ACM on Multimedia
Conference (MM), 2017.

[8] V. Sitzmann, A. Serrano, A. Pavel, M. Agrawala, D. Gutierrez,
B. Masia, and G. Wetzstein, “Saliency in VR: How Do People
Explore Virtual Environments?,” vol. 24, no. 4, April 2018.

[9] K. Srivastava, RC Das, and S Chaudhury, “Virtual reality ap-
plications in mental health: Challenges and perspectives,” In-
dustrial psychiatry journal, vol. 23, 2014.

[10] E. Upenik and T. Ebrahimi,

“A simple method to obtain
visual attention data in head mounted virtual reality,”
in
IEEE International Conference on Multimedia Expo Work-
shops (ICMEW), July 2017.

[11] B. Hu, I. Johnson-Bey, M. Sharma, and E. Niebur,

“Head
movements during visual exploration of natural images in vir-
tual reality,” in IEEE 51st Annual Conference on Information
Sciences and Systems (CISS), 2017.

[12] C. Wu, Z. Tan, Z. Wang, and S. Yang, “A Dataset for Explor-
ing User Behaviors in VR Spherical Video Streaming,” in Pro-
ceedings of the 8th ACM on Multimedia Systems Conference
(MMSys), 2017.

[13] X. Corbillon, F. De Simone, and G. Simon, “360-degree video
head movement dataset,” in Proceedings of the 8th ACM on
Multimedia Systems Conference (MMSys), 2017.

[14] C. Lo, W.and Fan, J. Lee, C. Huang, K. Chen, and C. Hsu,
“360 Video Viewing Dataset in Head-Mounted Virtual Real-
ity,” in Proceedings of the 8th ACM on Multimedia Systems
Conference (MMSys), 2017.

[15] S. Fremerey, A. Singla, K. Meseberg, and A. Raake, “AV-
track360: an open dataset and software recording people’s

