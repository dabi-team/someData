Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized
SGD with Sample-induced Topology

Yan Huang 1 Ying Sun 2 Zehan Zhu 1 Changzhi Yan 1 Jinming Xu 1

2
2
0
2

l
u
J

8

]

C
O
.
h
t
a
m

[

1
v
0
3
7
3
0
.
7
0
2
2
:
v
i
X
r
a

Abstract

We develop a general framework unifying several
gradient-based stochastic optimization methods
for empirical risk minimization problems both in
centralized and distributed scenarios. The frame-
work hinges on the introduction of an augmented
graph consisting of nodes modeling the samples
and edges modeling both the inter-device com-
munication and intra-device stochastic gradient
computation. By designing properly the topol-
ogy of the augmented graph, we are able to re-
cover as special cases the renowned Local-SGD
and DSGD algorithms, and provide a uniﬁed per-
spective for variance-reduction (VR) and gradient-
tracking (GT) methods such as SAGA, Local-
SVRG and GT-SAGA. We also provide a uniﬁed
convergence analysis for smooth and (strongly)
convex objectives relying on a proper structured
Lyapunov function, and the obtained rate can re-
cover the best known results for many existing
algorithms. The rate results further reveal that
VR and GT methods can effectively eliminate
data heterogeneity within and across devices, re-
spectively, enabling the exact convergence of the
algorithm to the optimal solution. Numerical ex-
periments conﬁrm the ﬁndings in this paper.

1. Introduction

With the increasing popularity of large-scale machine
learning, distributed stochastic optimization methods have
sparked considerable interest to improve learning efﬁciency
in both academia and industry (Lian et al., 2017; Boyd
et al., 2011). In contrast to the typical centralized/parameter-
server architecture (Dean et al., 2012; Lian et al., 2015;

1College of Control Science and Engineering, Zhejiang Uni-
versity, Hangzhou, China 2School of Electrical Engineering and
Computer Science, The Pennsylvania State University, PA 16802,
USA. Correspondence to: Jinming Xu <jimmyxu@zju.edu.cn>.

Proceedings of the 39 th International Conference on Machine
Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy-
right 2022 by the author(s).

Stich, 2019) where a center node coordinates the entire op-
timization process, which usually becomes the bottleneck,
distributed structure has its unique advantage in improving
computation and communication efﬁciency (Nedi´c et al.,
2018). Besides, since the data is locally maintained by each
node, data privacy can be well preserved for data-sensitive
application domains (Li et al., 2019).

We consider the prototypical empirical risk minimization
problem collaboratively solved by a set of agents over a
communication network. The overall objective of the agents
is to seek an optimal solution x∗ ∈ Rd that solves the
following ﬁnite-sum problem:

f (x) =

min
x∈Rd




fi(x) :=

1
n

n
(cid:88)

i=1

1
m

m
(cid:88)

j=1

f (x, ξi,j)
(cid:124)
(cid:125)
(cid:123)(cid:122)
fij (x)




,

(1)

where fi : Rd → R is the local private loss function acces-
sible only by the associated node i ∈ N := {1, 2, · · · , n},
and {ξi,j}m
j=1 denote the data samples locally stored at node
i ∈ N and {fij} denote the corresponding loss functions.

Problem (1) has been extensively studied over the last
decade and enormous distributed algorithms, e.g., Nedic and
Ozdaglar (2009); Nedic et al. (2010); Lobel and Ozdaglar
(2011); Yuan et al. (2016); Pu et al. (2020), have been pro-
posed to solve this problem. The readers are referred to the
recent survey paper (Nedi´c et al., 2018) and the references
therein. Among these algorithms, the distributed gradient
decent (DGD) algorithm (Nedic and Ozdaglar, 2009) is a
simple yet effective method. However, it suffers from steady-
state error when employing constant stepsizes due to the
fact that the ﬁxed point of DGD is inherently not consensual
(Yuan et al., 2016). To bridge the gap between centralized
gradient decent and DGD, a gradient-tracking scheme is
introduced to overcome the above issue (Xu et al., 2015;
Di Lorenzo and Scutari, 2016; Nedic et al., 2017; Qu and Li,
2017), which introduces an auxiliary variable to estimate
the full gradient ∇f (the sum of local gradients) leveraging
dynamic average consensus (Zhu and Mart´ınez, 2010) so
as to make the ﬁxed point consensual. The introduction of
gradient tracking scheme allow us to effectively account
for the heterogeneity among local data sets (also known as
external variance among data distribution of nodes).

 
 
 
 
 
 
Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Variance-reduced (VR) and local methods. All of the
above-mentioned algorithms are deterministic and require
evaluating the local full gradient ∇fi at each iteration, lead-
ing to high computational complexity (Hong et al., 2017).
A natural way to reduce the computational complexity is to
use stochastic gradients to approximate the local full gra-
dient. To this end, a vast number of distributed stochastic
optimization algorithms are proposed for the problem (1),
such as DSGD (Ram et al., 2009), D-PSGD (Lian et al.,
2017) and SGP (Assran et al., 2019), and just to name a few.
These stochastic optimization algorithms work quite well in
practice but usually require diminishing stepsizes to atten-
uate the variance of the stochastic gradient, a.k.a. internal
(sample) variance. An effective solution to this is to employ
the idea of variance-reduction and learn the local full gra-
dient ∇fi iteratively, as did in SVRG (Johnson and Zhang,
2013), SAGA (Defazio et al., 2014), L-SVRG (Hofmann
et al., 2015; Qian et al., 2021) and SARAH (Nguyen et al.,
2017) to eliminate the internal variance, yielding faster con-
vergence such as D-SAGA (Calauzenes and Roux, 2017).
To avoid high communication burden among nodes, one
may trade computation with communication by performing
several local gradient steps between two consecutive com-
munication steps, which leads to communication-efﬁcient
algorithms, such as Local-SGD (Khaled et al., 2020) and
Local-SVRG (Gorbunov et al., 2021); or employing peri-
odic global averaging (PGA) for speeding up consensus,
such as Gossip-PGA (Chen et al., 2021).

Gradient-tracking-based (GT) stochastic methods. The
gradient-tracking scheme have been also recently incorpo-
rated into various stochastic optimization algorithms as a key
step to eliminate the external variance. For example, DSGT
(Pu and Nedi´c, 2020) and DSA (Mokhtari and Ribeiro,
2016) can achieve higher accuracy than that of DSGD by
removing the bias due to the heterogeneity among local data
sets. Nevertheless, gradient-tracking, by its nature, is still
unable to eliminate the data sample variance. This naturally
leads to the integration of variance-reduction methods with
the gradient-tracking scheme. For instance, Sun et al. (2020)
employ a scheme with both gradient-tracking and variance-
reduction to solve a smooth (probably non-convex) problem
and show that it converges to a stationary point sublinearly.
Li et al. (2021) proposed a similar algorithm with a nested
loop structure for the sake of improving its overall com-
plexity. Xin et al. (2020) and Jiang et al. (2022) consider
a similar GT-VR framework and obtain a linear rate for
strongly convex problems and O (1/k) rate for non-convex
setting, respectively. Similar attempts have been recently
made towards composite optimization problems (Ye et al.,
2020). There are also many other efforts made to solve Prob-
lem (1), such as those based on approximate Newton-type
methods (Li et al., 2020) and acceleration schemes (Scaman
et al., 2017; Hendrikx et al., 2021).

Uniﬁed framework for ﬁrst-order stochastic optimiza-
tion algorithms. There have been some efforts made to
unify the aforementioned algorithms. In particular, Hu et al.
(2017) unify several variance-reduction methods by estab-
lishing the intrinsic connection between stochastic optimiza-
tion methods and dynamic jump systems. Wang and Joshi
(2021) consider to use a time-varying mixing matrix to
model Cooperative SGD which can recover several existing
non-variance-reduced methods. Building on this, Koloskova
et al. (2020) propose a uniﬁed framework for Decentral-
ized (Gossip) SGD by employing changing topology and
multiple local updates. To incorporate variance-reduction
methods, Gorbunov et al. (2020) study a general framework
that can account for variance-reduction, importance sam-
pling, mini-batch sampling, leading to a uniﬁed theory of
variance reduced and non-variance-reduced SGD methods.
The authors also extend this framework to cover Local-SGD
and variance-reduced SGD methods, which recovers the
rate in (Koloskova et al., 2020). However, to the best of our
knowledge, there is no such a framework for distributed ﬁrst-
order stochastic optimization algorithms that can recover
all the above-mentioned VR-, GT-, Local- and PGA-based
methods both in centralized and decentralized settings.

1.1. Our Contribution

In this work, we develop a new uniﬁed framework based on
the introduction of an augmented graph whose nodes model
the data samples. Leveraging a proper sampling strategy on
the augmented graph, this framework allows us to recover
many existing algorithms as well as their corresponding
best known rates. In contrast to the existing frameworks as
mentioned above, the proposed framework not only contain
them as special cases but also enable us to easily design new
efﬁcient algorithms with guaranteed rates, especially those
employing gradient-tracking scheme, yielding a broader
range of methods to be incorporated. The main contributions
of this paper are summarized as follows:

• New uniﬁed framework for algorithm design and
analysis. The proposed framework unify various
gradient-based stochastic optimization methods both
in centralized and distributed scenarios. With proper
sampling strategies on the augmented graph, we can
easily recover these VR-, GT-, Local- and PGA-based
methods, as well as their proper combinations (see Ta-
ble 1). Besides, this framework also provides a new
unifying perspective for GT- and VR-based schemes,
which are otherwise two separate approaches before,
and show an equivalence of Local-SGD, Gossip-PGA
and DSDG in terms of iteration complexity once their
expected topology connectivity is same.

• Recovering various existing algorithms along with
the best known rates. A uniﬁed convergence analysis

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

is provided, which relies on a proper Lyapunov func-
tion for smooth and (strongly) convex objectives. The
obtained rates either recover the existing best known
rates or are new for certain algorithms under our set-
tings, including SAGA, Local-SGD, DSGD, Local-
SVRG and GT-SAGA (see Table 1). These rates also
show the clear dependence of the convergence perfor-
mance on the above-mentioned schemes, such as GT,
VR, Local update, and PGA. The theoretical results
further reveal that VR- and GT-based methods are usu-
ally needed to achieve exact convergence in scenarios
where data heterogeneity is a key concern.

• New efﬁcient algorithms with provable rates. Our
framework allows us to easily come up with new ef-
ﬁcient algorithms with proper design of the sampling
strategy on the augmented graph and provides the corre-
sponding rate guarantee as well, such as Local-SAGA,
PGA-SAGA, PGA-GT-SAGA, which are not formally
analyzed before (see Table 1). Moreover, the proposed
framework provides more ﬂexibility in design of net-
work topology which can be of multi-layer structure in
certain scenarios for communication efﬁciency.

2. Problem Formulation

We consider solving Problem (1) over a peer-to-peer net-
work, modeled as an augmented directed graph (digraph)
G = (V, E) where V := {1, 2, ..., M } with M = nm
denotes the set of nodes modeling the data samples and
E ⊆ V × V denotes the set of edges consisting of ordered
pairs (i, j) modeling the virtual/actual communication link
from j to i. We then make the following blanket assump-
tions on the cost functions of problem (1).
Assumption 1. Each fi : Rd → R is µ-strongly convex
and L-smooth, i.e., for any x, x(cid:48) ∈ Rd

(cid:104)∇fi (x) − ∇fi (x(cid:48)) , x − x(cid:48)(cid:105) (cid:62) µ (cid:107)x − x(cid:48)(cid:107)2 ,

(2)

(cid:107)∇fi (x) − ∇fi (x(cid:48))(cid:107) (cid:54) L (cid:107)x − x(cid:48)(cid:107) .
Assumption 2. (Bounded data heterogeneity at optimum)
Let x∗ ∈ arg minx f (x). For each fij : Rd → R, i ∈
[n], j ∈ [m], there exist positive constants σ∗, ζ ∗ such that

(3)

1
M

n
(cid:88)

m
(cid:88)

(cid:107)∇fij (x∗) − ∇fi (x∗)(cid:107)2 (cid:54) σ∗,

i=1

j=1
1
n

n
(cid:88)

i=1

(cid:107)∇fi (x∗)(cid:107)2 (cid:54) ζ ∗.

(4)

(5)

Remark 1. The parameter σ∗, ζ ∗ are deﬁned to measure
the local gradient sampling variance and data heterogeneity
across devices, respectively. Notice that we do not require
the data heterogeneity be bounded uniformly for all x but
only at the optimum x∗, which is weaker than the previous
works such as (Lian et al., 2017; Wang and Joshi, 2021).

Assumption 3. (Averaged smoothness) For all i ∈ [n] and
∀x, x(cid:48) ∈ Rd, we have

1
m

m
(cid:88)

j=1

(cid:107)∇fij (x) − ∇fij (x(cid:48))(cid:107)2

(6)

(cid:54) 2L (fi (x) − fi (x(cid:48)) − (cid:104)∇fi (x(cid:48)) , x − x(cid:48)(cid:105)) .

Assumption 3 is automatically satisﬁed if we assume that
each fij is convex and L-smooth.

3. Sample-wise Push-Pull Framework

In this section, we introduce the sample-wise Push-Pull
framework for the ﬁnite-sum problem (1). To this end, we
use an augmented graph G with a two-level structure as
depicted in Figure 1 to illustrate the key ideas.

Figure 1. A two-level augmented graph for n = 6 and m = 4.
The graph GV on the left refers to a fully connected underlying
graph within one device, and the solid arrows represent the local
stochastic gradient computation for updating parameters. The
graph G = GW ⊗ GV on the right represents the augmented graph
induced by the samples locally stored at all the devices.

We ﬁrst model each device as a super-node connected by
the actual communication network GW . Then, we replace
each device i with a virtual fully connected graph GV whose
nodes model the samples ξi,j, yielding an augmented graph
G = GW ⊗ GV . As we will show shortly, implementation of
stochastic optimization algorithms can be deemed as recur-
sively sampling the edges of G, which consists in: i) locally
updating the parameter of sample node j in device i using
the gradient of fil when the edge (j, l) ∈ GV associated
with device i; ii) performing an actual communication step
between devices i and s when the edge (i, s) ∈ GW .

As a convention in decentralized optimization, we associate
each node in G a local variable xi ∈ Rd that serves as a
copy of the global variable x. Besides, each node i also
maintains an auxiliary variable yi ∈ Rd that estimates the
full gradient ∇f (x). For brevity, we use X, Y ∈ RM ×d to
denote matrices stacking the xi’s and yi’s, respectively:

X := [x1, x2, · · · , xM ]T , Y := [y1, y2, · · · , yM ]T .

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Accordingly, the collective gradient vectors of all local ob-
jective functions at X is denoted as

∇F (X) := [∇f1 (x1) , · · · , ∇fM (xM )]T .

Now, we are ready to introduce our algorithmic framework,
termed sample-wise Push-Pull (SPP), for Problem (1):

Xk+1 = RkXk − αΓkYk,
Yk+1 = CkYk + ∇F (Xk+1) − ∇F (Xk) ,

(7a)

(7b)

where α is a constant step-size, and Rk, Ck ∈ RM ×M
are time-varying weight matrices (to be properly designed)
for reaching consensus (pull operation) among nodes and
tracking the overall average gradient (push operation), re-
spectively; Γk ∈ RM ×M is a random sampling matrix for
selecting edges of the augmented graph.

In what follows, we explain the role of the above three key
parameters of Γk, Rk and Ck over an augment graph with
the two-level structure as shown in Figure 1.

Sampling on augmented graph.
In our proposed SPP
framework, both the processes of actual communication
among devices and local stochastic gradient computation for
updating parameters can be regarded as selecting a subset of
nodes from the augmented graph G = GW ⊗ GV . In particu-
lar, each device i elects its samples (nodes in GV ) participat-
ing in the update at iteration k, indicated by a binary-valued
vector ei,k ∈ {0, 1}m×1: the j-th element ej
i,k is set to be
one if the ξij is selected and zero otherwise. The concate-
n,k]T ∈ RM then indicates
nated vector ek = [eT
the identities of all the samples in the network selected at
iteration k. Denote by bk the number of selected samples
of each device at iteration k, i.e., bk = 1T
mei,k, ∀i ∈ [n].
Inherited from the weight matrix of G at iteration k, which
is Wk ⊗ 11T , the sampling matrix becomes:

1,k , · · · , eT

Γk := Λk+1

(cid:0)Wk ⊗ 11T (cid:1) Λk
bk

,

(8)

where Λk = diag (ek) denotes the elected samples at it-
eration k who will send messages to the nodes picked by
Λk+1. Indeed, Γk models the virtual/actual message passing
among sample node from iteration k to k + 1.

Then, we consider the following sampling strategy, which
is commonly used for many distributed learning problems.
Assumption 4. For all k (cid:62) 0, each device i ∈ [n] indepen-
dently and uniformly selects bk data samples from its local
datasets at random without replacement.

Intra and inter consensus guarantee. The main purpose
of the weight matrix Rk is to ensure consensus of estimates
within and across devices, which is designed as follows:

Rk := IM − Λk+1 + Γk,

(9)

where the term IM − Λk+1 represents that the parameters
kept at the nodes that are not sampled remain unchanged
at iteration k + 1. The term Γk, as deﬁned in (8), denotes
the message passing from samples ξk to ξk+1 over the aug-
mented graph, and only samples in ξk+1 perform update.
Note that in such design, Rk is row-stochastic. There are in-
deed two consensus processes involved in the above process:
1) consensus within each device, which is guaranteed by the
fully connectivity of GV , meaning that the latest parameters
can be always sent to the current sample node; 2) consensus
across devices, which is ensured by the proper design of
weight matrix Wk that has been incorporated in Λk.

Accurate full-gradient estimation for tackling data het-
erogeneity. In order to obtain an accurate estimate on gra-
dient descent direction, variance-reduction and gradient-
tracking methods are widely used to eliminate the variance
of the stochastic gradient within and across the devices, re-
spectively. In the proposed framework, we properly design
the doubly-stochastic weight matrix Ck corresponding to
the augmented graph GW ⊗ GV as

Ck := Gk ⊗ Vk.

(10)

Since Ck is doubly-stochastic, we have by induction,

1T
M
M

Yk =

1T
M
M

∇F (Xk) , ∀k (cid:62) 0,

(11)

which enables all the nodes to track the full gradient ∇f (x).
In fact, it will become clear that Gk ∈ Rn×n is meant
for gradient-tracking across devices while Vk ∈ Rm×m is
dedicated to variance-reduction within device.

Thus, we can properly choose these above weight matrices
Γk, Rk, Ck to recover existing algorithms with or without
GT and VR operations. We use A (Γk, Rk, Ck) to denote
algorithms generated from the proposed SPP framework.
For ease of presentation, we will use the above same setting
for Γk, Rk and Ck throughout the paper.

Remark 2. In contrast to the existing frameworks, our
proposed SPP framework provides a more general prospec-
tive for algorithm design based on sampling of an aug-
mented graph, i.e., we allow for adopting various consensus
schemes, gradient estimation methods and their combina-
tions by different choices of the three key matrices Rk, Ck
and Γk. Our framework covers several recently proposed
frameworks, such as Local-SGD (Gorbunov et al., 2021),
Cooperative SGD (Wang and Joshi, 2021), Decentralized
(Gossip) SGD (Koloskova et al., 2020). Indeed, none of
these works consider both gradient-tracking and variance-
reduction with changing topology and local updates. Be-
sides, the proposed framework has the potential to recover
Multi-Level Local-SGD (Castiglia et al., 2020) by properly
designing a topology of hierarchical structures.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

4. Existing Algorithms as Special Cases and

Beyond

In this section, we show how the proposed SPP framework
can, indeed, recover a large number of existing algorithms
as special cases. To this end, we introduce a projection
matrix Sk ∈ Rn×M , which is deﬁned as

update with a certain probability, it can be also recovered
by SPP with the following stochastic matrix Vk varies as:

(cid:40)

Vk = Im,
Vk = Jm,

w.p. 1 − p,

bk = b,
bk = m, w.p. p.

(17)

Then, we obtain the recovered L-SVRG algorithm by Sk,

Sk := (cid:0)In ⊗ 1T

m

(cid:1) Λk
bk

,

(12)

that can reduce the dimension of the general SPP algorithm
from M (number of samples) to n (number of physical
devices), yielding an algorithm that can be implemented
efﬁciently on actual devices with new updating variables:

ˆXk := SkXk,

ˆYk := SkYk.

(13)

Now, we will use the cases of SAGA/L-SVRG (n = 1), and
GT-SAGA (n > 1) to illustrate the equivalence between the
recovered algorithm and the general SPP algorithm. More
details on the recovery of various existing algorithms can
be found in Appendix A.

Recovering SAGA/L-SVRG. Under the proposed SPP
framework, we choose the parameters (Γk, Rk, Ck) as de-
ﬁned in (8), (9) and (10) for SAGA with:

Wk = Gk = 1, Vk = Jm, ∀k (cid:62) 1.

(14)

We denote by sk the mini-batch of randomly selected b ∈
[1, m] sample nodes at iteration k, then we can derive the
recursion of decision variable:

ˆxk+1 = ˆxk − αˆyk,

(15)

(cid:16) ˆXk, ˆYk

(cid:17)

where (ˆxk, ˆyk) is an instance of
with n = 1.
Then, by noticing that only the randomly selected sam-
ple nodes performs update, i.e, xs,k+1 = ˆxk+1, ∀s ∈
sk+1, while the other sample nodes remain unchanged, i.e.,
xj,k+1 = xj,k, ∀j /∈ sk+1, we can derive the recursion of
full-gradient estimation variable:

ˆyk+1 =

=

1T
m
m
1
m

m
(cid:88)

j=1
(cid:88)

+

1
b

∇F (Xk) + Sk+1 (∇F (Xk+1) − ∇F (Xk))

∇fj (xj,k)

(∇fs (ˆxk+1) − ∇fs (xs,k)),

s∈sk+1

(16)

ˆxk+1 = ˆxk − αˆyk,

ˆyk+1 =

1
m

m
(cid:88)

j=1

∇fj

(cid:0)xj,tk+1

(cid:1)

+

1
bk+1

(cid:88)

s∈sk+1

(cid:0)∇fs (ˆxk+1) − ∇fs

(cid:0)xs,tk+1

(cid:1)(cid:1),

(18)
where tk+1 < k + 1 denotes the latest iteration before k + 1
performing full gradient update, i.e., btk+1 = m.

Recovering GT-SAGA.
In contrast to the centralized set-
ting, there exists extra data heterogeneity among devices
(n > 1). Gradient tracking methods are proposed to fur-
ther eliminating the global data heterogeneity. We recover
GT-SAGA (Xin et al., 2020) by choosing (Γk, Rk, Ck) as
deﬁned in (8), (9) and (10) with:

Wk = Gk = W, Vk = Jm, ∀k (cid:62) 1.

(19)

Then, multiplying both sides of (7) with Sk+1 and using the
fact that Sk+1Rk = Sk+1Γk = WkSk (c.f., Lemma (1)),
we can obtain a reduced algorithm as follows:
(cid:16) ˆXk − α ˆYk

ˆXk+1 = W
ˆYk+1 = W SkYk + Sk+1 (∇F (Xk+1) − ∇F (Xk))

(cid:17)

,

= W ˆYk −

(cid:18)

In ⊗

(cid:19)

1T
m
m

(∇F (Xk+1) − ∇F (Xk)) .

(20)
Further, noticing that ∇F (Xk) resembles the gradient table
of all samples at iteration k, GT-SAGA is thus recovered
under the proposed SPP framework. See Appendix A for
more detailed recovery of various other algorithms.

New efﬁcient algorithms.
It should be noted that our pro-
posed SPP framework can further recover a large family of
algorithms by proper combination of existing algorithms,
such as Local-SVRG, Gossip-PGA. In so doing, we can
easily design some new efﬁcient algorithms that have not
been formally proposed before with provable rates, such as
Local-SAGA, PGA-SAGA, PGA-GT-SAGA (see Table 1).

The above procedures imply that ∇F (Xk) actually plays
the role of gradient table (Defazio et al., 2014). Thus, the
original SAGA is recovered.

Different from SAGA, L-SVRG, (Qian et al., 2021) reduces
the stochastic gradient variance by performing full gradient

5. Convergence Analysis

In this section, we provide a uniﬁed convergence analy-
sis of the proposed SPP framework for both strongly con-
vex and general convex cases. To this end, we ﬁrst deﬁne

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Table 1. Topology design and complexity comparison for the algorithms that can be recovered and analysed by our SPP framework
under strongly convex setting. The choices of Wk (consensus), Vk (variance-reduction) and Gk (gradient-tracking) are presented with
corresponding values of (ρW , r, p, q). Notice that “Wk = 1” implies centralized scenario with only one device. “ ˜O” implies that the
log 1
ε factor is omitted when the sub-linear terms are dominant. The mark “*” implies that the best-known rate is recovered by our
convergence analysis under the same settings; “†” denotes that the obtained rate is new under our settings.

Algorithm
SAGA
(Defazio et al., 2014) *
L-SVRG
(Qian et al., 2021) *
Local-SGD
(Khaled et al., 2020) *
DSGD
(Lian et al., 2017) *
Gossip-PGA

(Chen et al., 2021)

Local-SAGA
(New)

Local-SVRG
(Gorbunov et al., 2021) †

D-SAGA
(Calauzenes and Roux, 2017)†

PGA-SAGA

(New)

GT-SAGA
(Xin et al., 2020) †

PGA-GT-SAGA

(New)

Wk

1

1

Vk

Jm

{Im, Jm}

{In, Jn}

W

{W, Jn}

Im

Im

Im

{In, Jn}

Jm

{In, Jn}

{Im, Jm}

W

{W, Jn}

W

{W, Jn}

Jm

Jm

Jm

Jm

Gk

1

1

In

In

In

In

In

In

In

(ρW , r, p, q)
(cid:8)0, 1, 1, b

(cid:9)

m

{0, 1, p, 1}

{1, r, 0, 0}

{ρW , 0, 0, 0}

(cid:8)1, r, 1, b

m

(cid:9)

{1, r, p, 1}

(cid:8)ρW , 0, 1, b

m

(cid:9)

(cid:8)ρW , r, 1, b

m

(cid:9)

W (cid:8)ρW , 0, 1, b

m

(cid:9)

Wk

(cid:8)ρW , r, p, b

m

(cid:9)

Obtained Complexity ( ˜O(·))

Results

(cid:17)

(cid:16) L

b

µ + m
(cid:17)
(cid:16) L

µ + 1

p

log 1
ε

log 1
ε

L

µr + σ∗

nbµ2ε +

(cid:113) (1−r)L
µ3rε

L

µ(1−ρW ) + σ∗

nbµ2ε +

(cid:114)

ρW L
µ3(1−ρW )ε

(cid:1)

(cid:0) ζ∗

b

r + σ∗
(cid:16) ζ∗

(cid:17)

+ σ∗
b

1−ρW

(cid:16) ζ∗

1−ρr,W

(cid:17)

+ σ∗
b

{ρW , r, 0, 0}

L
µ(1−ρr,W )

+ σ∗

nbµ2ε +

(cid:114) ρr,W L

µ3(1−ρr,W )ε
(cid:113) (1−r)Lζ∗

µ3r2ε

(cid:113) (1−r)Lζ∗

µ3r2ε

L

µr + m

b +

L

µr + 1

p +

L

µ(1−ρW ) + m

b +

L
µ(1−ρr,W )

+ m

b +

(cid:113) ρW Lζ∗

µ3(1−ρW )2ε
(cid:114) ρr,W Lζ∗

µ3(1−ρr,W )2

ε

(cid:16)

L

µ(1−ρW )2 + m

b

(cid:17)

log 1
ε

(cid:18)

L

µ(1−ρr,W )2 + m

b

(cid:19)

log 1
ε

Cor. 2

Cor. 2

Cor. 1

Cor. 1

Cor. 1

Cor. 2

Cor. 2

Cor. 2

Cor. 2

Cor. 3

Cor. 3

p := P (Vk = Jm) as the probability of performing local
variance-reduction; q := E [bk/m|Vk = Jm] the expected
ratio of batch-size while performing variance-reduction;
r := P (Wk = Jn) the probability of adopting global av-
eraging. In order to characterize the algorithm to be in-
corporated into the proposed framework, we also need to
specify the non-negative matrices Wk, Gk, Vk which corre-
spond to mixing, gradient-tracking and variance-reduction,
respectively, as given by the following assumption.

Assumption 5. The non-negative matrices Wk, Gk, Vk are
independently and randomly chosen as

Wk ∈ {W, Jn} , Gk ∈ {In, Wk} , Vk ∈ {Im, Jm} ,

for all k (cid:62) 0, and Wk is doubly stochastic, i.e., 1T
1T
n , Wk1n = 1n, and satisﬁes

n Wk =

ρr,W := E

(cid:104)

(cid:107)Wk − Jn(cid:107)2
2

(cid:105)

= (1 − r) ρW < 1,

(21)

where ρW := (cid:107)W − Jn(cid:107)2
2.
Remark 3. Assumption 5 does not require a contraction
property of Wk at each iteration but in the sense of expecta-
tion. For instance, Wk in Local-SGD can be randomly or pe-
riodically chosen from {In, Jn}, or simply set as Wk = W
with ρW < 1 for k (cid:62) 0 in DSGD (c.f., Appendix A).

Main results. For convergence analysis, we deﬁne the
average variables of Xk and Yk as follows:

¯xk :=

1T
n
n

SkXk,

¯yk :=

1T
n
n

SkYk.

(22)

Then, we are ready to establish the convergence rates of SPP
for smooth and strongly convex objective functions under
both centralized and distributed settings. To this end, we
ﬁrst construct a general Lyapunov function consisting of
several error terms as follows:

Tk+1 := c0(cid:107)¯xk+1 − x∗(cid:107)2
(cid:125)
(cid:124)

(cid:123)(cid:122)
optimal gap

+ c1

(cid:13)
ˆXk+1 − 1n ¯xk+1
(cid:13)
(cid:13)
(cid:123)(cid:122)
(cid:124)
consensus error

(cid:13)
2
(cid:13)
(cid:13)
(cid:125)

+ c2(cid:107)∇F (Xtk ) − ∇F (1M x∗)(cid:107)2
(cid:125)

(cid:123)(cid:122)
delayed VR error

(cid:124)

+ c3(cid:107)∇F (Xk) − ∇F (1M x∗)(cid:107)2
(cid:125)

(cid:124)

+ c4

(cid:123)(cid:122)
VR error
(cid:13)
(cid:13)
2
ˆYk+1 − 1n ¯yk+1
(cid:13)
(cid:13)
,
(cid:13)
(cid:13)
(cid:125)
(cid:123)(cid:122)
(cid:124)
GT error

(23)

where c0, c1, c2, c3, c4 (cid:62) 0 are constants to be properly
determined (see Appendix B for more details). Note that the

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

vanishing of the Lyapunov function implies the attainment
of the optimum for strongly convex objective functions.

Now, we proceed to present our main results1 for algorithms
A (Γk, Rk, Ck) under different parameter settings and we
summarize their complexity in Table 1 for comparison.
Theorem 1. Consider algorithms A (·, ·, Ck ≡ IM ) gener-
ated from the SPP framework with a constant batch-size of
b. Suppose Assumption 1-5 hold and µ > 0. Let

c0 = 1, c1 = (1 − r)

8αL (4αL + 1)
n (1 − ρr,W )

, c2 = c3 = c4 = 0

and the step-size satisfy

(cid:26)

α = min

O

(cid:19)

(cid:18) 1
L

, O

(cid:18) 1 − ρr,W
√
ρr,W

L

(cid:19)(cid:27)

.

(24)

Then, we have for all k (cid:62) 0
(cid:18)

(cid:26)

E [Tk+1] (cid:54)

1 − min

αµ,

(cid:27)(cid:19)

1 − ρr,W
8
(cid:18) 4ζ ∗

1 − ρr,W

E [Tk] +

2α2σ∗
nb

+

(cid:19)

.

σ∗
b

+ (1 − r)

16α3Lρr,W
1 − ρr,W

(25)
Remark 4. Theorem 1 yields a known tightest convergence
rate as Koloskova et al. (2020) for a class of decentral-
ized optimization algorithms without adopting VR or GT
schemes, i.e., Local-SGD, DSGD (see Table. 1).
Corollary 1. Under the conditions in Theorem 1, there
exists a suitable upper-bound of step-size α (refer to supple-
mentary) such that E [TK] (cid:54) ε after at most the following
number of iterations K:

(cid:18)

K (cid:62) O

L
µ (1 − ρr,W )
(cid:115)

log

(cid:19)

E [T0]
ε

ρr,W L
µ3 (1 − ρr,W ) ε

(cid:32)

+ O

σ∗
nµ2ε

+

(cid:18)

ζ ∗
1 − ρr,W

+

σ∗
b

(cid:19)(cid:33)

.

(26)

Then, we provide the convergence analysis for algorithms
that adopt VR schemes, such as Local-SVRG, Local-SAGA
(new) and D-SAGA, in order to eliminate the internal vari-
ance σ∗ due to gradient sampling.
Theorem 2. Consider algorithms A (·, ·, Ck ≡ In ⊗ Vk)
generated from the SPP framework with p > 0. Suppose
Assumption 1-5 hold and µ > 0. Let

c0 = 1, c1 =

20Lα
n (1 − ρr,W )

, c2 =

5α2
M p

, c3 =

16α2
M q

, c4 = 0

and the step-size satisfy

α = O

(cid:18) 1 − ρr,W
L

(cid:19)

.

(27)

1All proofs can be found in Appendix C

Then, we have for all k (cid:62) 0
(cid:26)

(cid:18)

E [Tk+1] (cid:54)

1 − min

αµ,

pq
2

,

1 − ρr,W
8

(cid:27)(cid:19)

E [Tk]

+

80α3Lρr,W
(1 − ρr,W )2 ζ ∗.

(28)
Corollary 2. Under the conditions in Theorem 2, there
exists a suitable upper-bound of step-size α (refer to sup-
plementary) such that we have E [TK] (cid:54) ε after at most the
number of iterations K:

K (cid:62) O

(cid:18)(cid:18) 1
pq

+

(cid:32)(cid:115)

+ O

L
µ (1 − ρr,W )
(cid:33)

ρr,W Lζ ∗
(1 − ρr,W )2 µ3ε

(cid:19)

log

(cid:19)

E [T0]
ε

.

(29)

Finally, we provide the convergence analysis for algorithms
adopting both VR and GT schemes, such as GT-SAGA and
PGA-GT-SAGA (new) which are capable of removing both
the internal (σ∗) and external variance (ζ ∗) induced by the
data heterogeneity within and across devices.
Theorem 3. Consider algorithms A (·, ·, Ck = Wk ⊗ Jm)
generated from the SPP framework. Suppose Assumption
1-5 hold and µ > 0. Let

c0 = 1, c1 =

1 − ρr,W
nρr,W (1 + ρr,W )

, c2 = 0,

c3 =

20α2

M q (1 − ρr,W )2 , c4 =

8α2
n (1 − ρr,W )

and the step-size satisfy

α = O

(cid:32)

(1 − ρr,W )2
L

(cid:33)

.

(30)

Then, we have for all k (cid:62) 0
(cid:26)
(cid:18)

E [Tk+1] (cid:54)

1 − min

αµ,

q
2

,

1 − ρr,W
8

(cid:27)(cid:19)

E [Tk] .

(31)
Corollary 3. Under the same conditions in Theorem 3, we
have E [TK] (cid:54) ε after at most the number of iterations K:

(cid:32)(cid:32)

K (cid:62) O

L
µ (1 − ρr,W )2 +

1
q

(cid:33)

(cid:33)

log

E [T0]
ε

.

(32)

Remark 5. It follows from the above theorems that one can
always effectively remove the data heterogeneity within and
across devices by properly choosing VR and GT schemes,
respectively. Besides, the above results also establish a clear
dependency of the complexity on the parameters related to
network, cost functions and algorithm design.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Remark 6. In Table 1, we provide the complexity results for
several well known existing and some new algorithms for
smooth and strongly convex objectives under our proposed
SPP framework. With proper choices of Wk, Vk and Gk,
the complexity induced by Theorem 1 yields a best-known
convergence rate for Local-SGD and DSGD , i.e., matching
the results in (Koloskova et al., 2020). We also recover the
complexity results of SAGA and L-SVRG in the centralized
scenario from Theorem 2; Besides, we enhance the result of
GT-SAGA (Xin et al., 2020) in that the dependency on the
condition number of objectives is improved from (L/µ)2 to
L/µ (c.f., Th. 3) in our slightly stronger settings. We also
provide several new algorithms with provable rates, such as
Local-SAGA, PGA-SAGA and PGA-GT-SAGA, which have
not been formally proposed and analyzed yet.

For general convex cases (µ = 0), we provide the obtained
complexity of the algorithms that can be recovered and anal-
ysed by the SPP framework in Table 2. In particular, we
can also recover the best-known sub-linear rates of SAGA,
L-SVRG, DSGD and Local-SGD. Moreover, we establish
the sublinear rate of GT-SAGA in general convex settings,
which is not yet considered in Xin et al. (2020) (c.f., Theo-
rem 4-6). All proofs can be found in Appendix D.

6. Experimental Results

In this section, we report some experiments to verify the the-
oretical ﬁndings for the proposed framework under different
settings of data heterogeneity and topology2.

Experiment settings. We train a regularized logistic re-
gression classiﬁer on both CIFAR-10 and Fashion-MNIST
(F-MNIST) datasets over a network of n nodes each of
which locally stores m data samples, which reads:

f (x) :=

min
x∈Rd

1
n

n
(cid:88)

i=1

1
m

m
(cid:88)

j=1

(cid:32)

(cid:96) (x, ξij) +
(cid:123)(cid:122)
(cid:124)
fij

(cid:33)

λ
2

(cid:107)x(cid:107)2
(cid:125)

(33)

with the cross-entropy loss (cid:96) deﬁned as:

(cid:96) (x, ξij) := −

10
(cid:88)

c=1

ij log (cid:0)1 + exp (cid:0)−xT θi,j
φc

(cid:1)(cid:1)−1

, (34)

where λ = 0.001 is the regularization parameter, θi,j ∈ Rd
and φc
ij ∈ {−1, 1} is the feature vector and the label of
class c ∈ [10] associated with sample ξij, respectively. The
datasets and parameters we used are summarized in Table 3
with r = 0.05 for certain algorithms with global averaging.

Data heterogeneity. We consider datasets with unbalanced
label distribution, which is an important type of data het-
erogeneity for classiﬁcation problems in distributed settings

2More experimental results can be found in Appendix E.

(Hsieh et al., 2020), and control the level of data hetero-
geneity through an arithmetic sequence with a difference of
h to allocate training samples of each class (c.f., Eq. (106,
107) in Appendix E). Fig. 2 plots the testing accuracy of
the algorithms to be compared under different settings of
heterogeneous label distributions: i) independent and identi-
cally (label) distributed (IID) datasets on the top row, i.e.,
h = 0; ii) non-IID datasets with h = 124 on the middle
row; iii) A highly unbalanced label distribution denoted by
h = hmax on the bottom row (c.f., Table 6). It follows from
Fig. 2 that, when the labels are evenly distributed (top row),
the VR-based algorithms (such as SAGA, D-SAGA, Local-
SAGA, denoted in solid lines) outperform the others without
VR schemes. Furthermore, when the level of data hetero-
geneity increases (middle and bottom rows), GT-SAGA and
PGA-GT-SAGA that adopt GT schemes can maintain rel-
atively high testing accuracy while those without GT will
degrade dramatically, especially for those that also do not
employ VR schemes, which implies that GT-based meth-
ods are more robust against the data heterogeneity. The
above experimental results verify the effectiveness of adopt-
ing VR and GT schemes in scenarios where datasets are
heterogeneous, which corroborates the Theorem 1-3.

Figure 2. Performance comparison of DSGD, Local-SGD, Gossip-
PGA, D-SAGA, Local-SAGA, PGA-SAGA, GT-SAGA and PGA-
GT-SAGA on directed ring graph with n = 8 under different
settings of data heterogeneity.

Topology dependence. To verify the dependency of the
impact of data heterogeneity on the performance against
the connectivity of the topology, we conduct several exper-
iments (with a ﬁxed value of h = 20) on different graphs:
directed ring with n = 8, ρW ≈ 0.92 ; exponential graph

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Table 2. Topology design and complexity comparison for the algorithms that can be recovered and analysed by our SPP framework
under convex settings (µ = 0). The choices of Wk (consensus), Vk (variance-reduction) and Gk (gradient-tracking) are presented with
corresponding values of (ρW , r, p, q). Notice that “Wk = 1” implies centralized scenario with only one device. The mark “*” implies
that the best-known rate is recovered by our analysis under the same settings; “†” denotes that the obtained rate is new under our settings;
O(·) hides the initial error (cid:107)x0 − x∗(cid:107)2.

Algorithm
SAGA
(Defazio et al., 2014) *
L-SVRG
(Qian et al., 2021) *
Local-SGD
(Khaled et al., 2020) *
DSGD
(Lian et al., 2017) *
Gossip-PGA

(Chen et al., 2021)

Local-SAGA
(New)

Local-SVRG
(Gorbunov et al., 2021) †

D-SAGA
(Calauzenes and Roux, 2017)†

PGA-SAGA

(New)

GT-SAGA
(Xin et al., 2020) †

PGA-GT-SAGA

(New)

Wk

1

1

Vk

Jm

{Im, Jm}

{In, Jn}

W

{W, Jn}

Im

Im

Im

{In, Jn}

Jm

{In, Jn}

{Im, Jm}

W

{W, Jn}

W

{W, Jn}

Jm

Jm

Jm

Jm

Gk

1

1

In

In

In

In

In

In

In

(ρW , r, p, q)
(cid:8)0, 1, 1, b

(cid:9)

m

{0, 1, p, 1}

{1, r, 0, 0}

{ρW , 0, 0, 0}

(cid:8)1, r, 1, b

m

(cid:9)

{1, r, p, 1}

(cid:8)ρW , r, 1, b

m

(cid:9)

(cid:8)ρW , r, 1, b

m

(cid:9)

W (cid:8)ρW , 0, 1, b

m

(cid:9)

Wk

(cid:8)ρW , r, p, b

m

(cid:9)

Obtained Complexity (O(·))

Results

mL
bε

L
pε

(cid:113) (1−r)L
r

L

rε + σ∗

nbε2 + 1
ε3/2

(cid:0) ζ∗

r + σ∗

b

(cid:1)

L

(1−ρW )ε + σ∗

nbε2 + 1
ε3/2

(cid:114)

ρW L
1−ρW

(cid:16) ζ∗

1−ρW

(cid:17)

+ σ∗
b

{ρW , r, 0, 0}

L
(1−ρr,W )ε

+ σ∗

nbε2 + 1
ε3/2

(cid:114)

ρr,W L
1−ρr,W

(cid:16) ζ∗

1−ρr,W

(cid:17)

+ σ∗
b

mL
brε +

(1−r)Lζ∗
brε3/2

√

m

√

L
rpε +

mL

b(1−ρW )ε +

(1−r)Lζ∗
rpε3/2
√

ρW Lζ∗
m
b(1−ρW )ε3/2

mL
b(1−ρr,W )ε

+

√

ρr,W Lζ∗
m
b(1−ρr,W )ε3/2

mL
b(1−ρW )2ε

mL
b(1−ρr,W )2

ε

Cor. 5

Cor. 5

Cor. 4

Cor. 4

Cor. 4

Cor. 5

Cor. 5

Cor. 5

Cor. 5

Cor. 6

Cor. 6

Table 3. Summary of the experimental setup.

7. Conclusions

Dataset

Node (n)

#Train

#Test

BS (n × b)

SS (α)

F-MNIST

{8, 50}

60000

10000

CIFAR-10

{8, 50}

50000

10000

200

400

0.05

0.008

BS: Batch-size; SS: Step-size.

with n = 50, ρW ≈ 0.99 for DSGD, D-SAGA and GT-
SAGA, respectively, whose testing accuracy results are plot-
ted in Fig. 3. It follows from Fig. 3 that the performance
of both DSGD and D-SAGA will be degraded when the
connectivity of the graph becomes worse while GT-SAGA
maintains relatively high testing accuracy since it removes
data heterogeneity ζ ∗ by employing GT-schemes.

Figure 3. Performance comparison of DSGD, D-SAGA, and GT-
SAGA on graphs with n = 8, 50.

This paper develops a new uniﬁed framework for ﬁrst-order
stochastic gradient methods both in centralized and dis-
tributed scenarios. The proposed framework is able to re-
cover many existing stochastic algorithms along with their
corresponding rates. It also enable us to easily design new
efﬁcient algorithms by proper design of sampling strategies
on the augmented graph. This framework is especially suit-
able for scenarios where data heterogeneity is a key concern.
Since the framework heavily depends on the underlying
augmented graph, it is of great interest and importance to
design a proper augmented graph and sampling strategy to
account for different important scenarios.

Acknowledgements

The work of Huang, Zhu, Yan, and Xu has been supported in
parts by National Natural Science Foundation of China un-
der Grants 62003302, 62088101, 61922058 and 62173225;
and in parts by the Key Laboratory of Collaborative Sensing
and Autonomous Unmanned Systems of Zhejiang Province.
The work of Sun has been supported by the Ofﬁce of Naval
Research, under the grant N00014-21-1-2673.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

References

Assran, M., Loizou, N., Ballas, N., and Rabbat, M. (2019).
Stochastic gradient push for distributed deep learning. In
International Conference on Machine Learning, pages
344–353. PMLR.

Boyd, S., Parikh, N., and Chu, E. (2011). Distributed op-
timization and statistical learning via the alternating di-
rection method of multipliers. Now Publishers Inc.

Calauzenes, C. and Roux, N. L. (2017). Distributed SAGA:
Maintaining linear convergence rate with limited commu-
nication. arXiv preprint arXiv:1705.10405.

Castiglia, T., Das, A., and Patterson, S. (2020). Multi-level
local SGD: Distributed SGD for heterogeneous hierarchi-
cal networks. In International Conference on Learning
Representations.

Chen, Y., Yuan, K., Zhang, Y., Pan, P., Xu, Y., and Yin, W.
(2021). Accelerating gossip SGD with periodic global av-
eraging. In International Conference on Machine Learn-
ing, pages 1791–1802. PMLR.

Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Mao,
M., Ranzato, M., Senior, A., Tucker, P., Yang, K., et al.
(2012). Large scale distributed deep networks. Advances
in neural information processing systems, 25.

Defazio, A., Bach, F., and Lacoste-Julien, S. (2014). SAGA:
A fast incremental gradient method with support for non-
strongly convex composite objectives. In Advances in
neural information processing systems, pages 1646–1654.

Di Lorenzo, P. and Scutari, G. (2016). Next: In-network
nonconvex optimization. IEEE Transactions on Signal
and Information Processing over Networks, 2(2):120–
136.

Gorbunov, E., Hanzely, F., and Richt´arik, P. (2020). A
uniﬁed theory of SGD: Variance reduction, sampling,
In International
quantization and coordinate descent.
Conference on Artiﬁcial Intelligence and Statistics, pages
680–690. PMLR.

Gorbunov, E., Hanzely, F., and Richt´arik, P. (2021). Lo-
cal SGD: Uniﬁed theory and new efﬁcient methods. In
International Conference on Artiﬁcial Intelligence and
Statistics, pages 3556–3564. PMLR.

Gut, A. (2005). Probability: A Graduate Course. New York,

NY : Springer Science+Business Media, Inc.

Hofmann, T., Lucchi, A., Lacoste-Julien, S., and
McWilliams, B. (2015). Variance reduced stochastic
gradient descent with neighbors. In Proceedings of the
28th International Conference on Neural Information
Processing Systems-Volume 2, pages 2305–2313.

Hong, M., Hajinezhad, D., and Zhao, M.-M. (2017). Prox-
PDA: The proximal primal-dual algorithm for fast dis-
tributed nonconvex optimization and learning over net-
works. In International Conference on Machine Learning,
pages 1529–1538. PMLR.

Hsieh, K., Phanishayee, A., Mutlu, O., and Gibbons, P.
(2020). The non-iid data quagmire of decentralized ma-
chine learning. In International Conference on Machine
Learning, pages 4387–4398. PMLR.

Hu, B., Seiler, P., and Rantzer, A. (2017). A uniﬁed analysis
of stochastic optimization methods using jump system
theory and quadratic constraints. In Conference on Learn-
ing Theory, pages 1157–1189. PMLR.

Jiang, X., Zeng, X., Sun, J., and Chen, J. (2022). Distributed
stochastic gradient tracking algorithm with variance re-
duction for non-convex optimization. IEEE Transactions
on Neural Networks and Learning Systems.

Johnson, R. and Zhang, T. (2013). Accelerating stochastic
gradient descent using predictive variance reduction. Ad-
vances in neural information processing systems, 26:315–
323.

Khaled, A., Mishchenko, K., and Richt´arik, P. (2020).
Tighter theory for local SGD on identical and hetero-
geneous data. In International Conference on Artiﬁcial
Intelligence and Statistics, pages 4519–4529. PMLR.

Koloskova, A., Loizou, N., Boreiri, S., Jaggi, M., and
Stich, S. (2020). A uniﬁed theory of decentralized SGD
with changing topology and local updates. In Interna-
tional Conference on Machine Learning, pages 5381–
5393. PMLR.

Li, B., Cen, S., Chen, Y., and Chi, Y.

(2020).
Communication-efﬁcient distributed optimization in net-
works with gradient tracking and variance reduction. In
International Conference on Artiﬁcial Intelligence and
Statistics, pages 1662–1672. PMLR.

Li, B., Li, Z., and Chi, Y. (2021).

DESTRESS:
Computation-optimal and communication-efﬁcient de-
centralized nonconvex ﬁnite-sum optimization. arXiv
preprint arXiv:2110.01165.

Hendrikx, H., Bach, F., and Massoulie, L. (2021). An opti-
mal algorithm for decentralized ﬁnite-sum optimization.
SIAM Journal on Optimization, 31(4):2753–2783.

Li, X., Huang, K., Yang, W., Wang, S., and Zhang, Z. (2019).
On the convergence of FedAvg on non-iid data. In Inter-
national Conference on Learning Representations.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Lian, X., Huang, Y., Li, Y., and Liu, J. (2015). Asyn-
chronous parallel stochastic gradient for nonconvex op-
timization. Advances in Neural Information Processing
Systems, 28.

Lian, X., Zhang, C., Zhang, H., Hsieh, C.-J., Zhang, W., and
Liu, J. (2017). Can decentralized algorithms outperform
centralized algorithms? a case study for decentralized
parallel stochastic gradient descent. Advances in Neural
Information Processing Systems, 30.

Lobel, I. and Ozdaglar, A. (2011). Distributed subgradient
methods for convex optimization over random networks.
IEEE Trans. Autom. Control, 56(6):1291–1306.

Mokhtari, A. and Ribeiro, A. (2016). DSA: Decentralized
double stochastic averaging gradient algorithm. The Jour-
nal of Machine Learning Research, 17(1):2165–2199.

Nedi´c, A., Olshevsky, A., and Rabbat, M. G. (2018). Net-
work topology and communication-computation tradeoffs
in decentralized optimization. Proceedings of the IEEE,
106(5):953–976.

Nedic, A., Olshevsky, A., and Shi, W. (2017). Achieving
geometric convergence for distributed optimization over
time-varying graphs. SIAM Journal on Optimization,
27(4):2597–2633.

Nedic, A. and Ozdaglar, A. (2009). Distributed subgradi-
ent methods for multi-agent optimization. IEEE Trans.
Autom. Control, 54(1):48–61.

Nedic, A., Ozdaglar, A., and Parrilo, P. A. (2010). Con-
strained consensus and optimization in multi-agent net-
IEEE Transactions on Automatic Control,
works.
55(4):922–938.

Nesterov, Y. (2003). Introductory lectures on convex opti-
mization: A basic course, volume 87. Springer Science
& Business Media.

Nguyen, L. M., Liu, J., Scheinberg, K., and Tak´aˇc, M.
(2017). SARAH: A novel method for machine learning
problems using stochastic recursive gradient. In Proceed-
ings of the 34th International Conference on Machine
Learning, pages 2613–2621.

Qu, G. and Li, N. (2017). Harnessing smoothness to ac-
celerate distributed optimization. IEEE Transactions on
Control of Network Systems, 5(3):1245–1260.

Ram, S. S., Nedi´c, A., and Veeravalli, V. V. (2009). Asyn-
chronous gossip algorithms for stochastic optimization.
In Proceedings of the 48h IEEE Conference on Decision
and Control (CDC) held jointly with 2009 28th Chinese
Control Conference, pages 3581–3586. IEEE.

Scaman, K., Bach, F., Bubeck, S., Lee, Y. T., and Massouli´e,
L. (2017). Optimal algorithms for smooth and strongly
convex distributed optimization in networks. In interna-
tional conference on machine learning, pages 3027–3036.
PMLR.

Stich, S. U. (2019). Local SGD converges fast and commu-
nicates little. In ICLR 2019-International Conference on
Learning Representations, number CONF.

Sun, H., Lu, S., and Hong, M. (2020). Improving the sam-
ple and communication complexity for decentralized non-
convex optimization: Joint gradient estimation and track-
ing. In International Conference on Machine Learning,
pages 9217–9228. PMLR.

Wang, J. and Joshi, G. (2021). Cooperative SGD: A uniﬁed
framework for the design and analysis of local-update
SGD algorithms. Journal of Machine Learning Research,
22(213):1–50.

Xin, R., Khan, U. A., and Kar, S. (2020). Variance-reduced
decentralized stochastic optimization with accelerated
convergence. IEEE Transactions on Signal Processing,
68:6255–6271.

Xu, J., Zhu, S., Soh, Y. C., and Xie, L. (2015). Augmented
distributed gradient methods for multi-agent optimization
under uncoordinated constant stepsizes. In Proceedings
of the 54th IEEE Conference on Decision and Control,
pages 2055–2060.

Ye, H., Xiong, W., and Zhang, T. (2020).

PMGT-
VR: A decentralized proximal-gradient algorithmic
arXiv preprint
framework with variance reduction.
arXiv:2012.15010.

Pu, S. and Nedi´c, A. (2020). Distributed stochastic gradient
tracking methods. Mathematical Programming, pages
1–49.

Yuan, K., Ling, Q., and Yin, W. (2016). On the convergence
of decentralized gradient descent. SIAM J. on Optim.,
26(3):1835–1854.

Pu, S., Shi, W., Xu, J., and Nedic, A. (2020). Push-pull
gradient methods for distributed optimization in networks.
IEEE Transactions on Automatic Control.

Qian, X., Qu, Z., and Richt´arik, P. (2021). L-SVRG and
L-Katyusha with arbitrary sampling. Journal of Machine
Learning Research, 22(112):1–47.

Zhu, M. and Mart´ınez, S. (2010). Discrete-time dynamic

average consensus. Automatica, 46(2):322–329.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Appendix

Contents

1

Introduction

1.1 Our Contribution

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

2 Problem Formulation

3 Sample-wise Push-Pull Framework

4 Existing Algorithms as Special Cases and Beyond

5 Convergence Analysis

6 Experimental Results

7 Conclusions

A Recovering Existing Algorithms

A.1 Recovering (centralized) SAGA, L-SVRG and SARAH .

A.2 Recovering Local-SAGA, D-SAGA and PGA-SAGA .

A.3 Recovering Local-SVRG and D-SVRG .

A.4 Recovering GT-SAGA .

.

.

.

.

.

.

.

.

.

B Technical Preliminaries

B.1 Supporting Lemmas .

.

.

.

.

.

.

.

B.2 The Recursion of Optimality Gap .

B.3 The Recursion of Consensus Error

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

B.4 The Recursion of Variance Reduction Error .

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

B.5 The Recursion of Delayed Variance Reduction Error

B.6 The Recursion of Gradient Tracking Error

.

.

.

.

.

C Proofs in Section 5

C.1 Proof of Theorem 1 .

C.2 Proof of Corollary 1 .

C.3 Proof of Theorem 2 .

C.4 Proof of Corollary 2 .

C.5 Proof of Theorem 3 .

C.6 Proof of Corollary 3 .

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

D Sub-linear Convergence Analysis for Convex Problems

E Additional Experiments

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

1

2

3

3

5

5

8

9

13

14

15

15

16

16

17

21

22

24

25

25

26

27

27

28

29

30

30

31

34

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

A. Recovering Existing Algorithms

In this section, we show that most of existing algorithms can be recovered by the proposed SPP framework. To this end, we
ﬁrst recall our proposed SPP framework (7) as follows:

Xk+1 = RkXk − αΓkYk,
Yk+1 = CkYk + ∇F (Xk+1) − ∇F (Xk) ,

where

Γk = Λk+1

(cid:0)Wk ⊗ 11T (cid:1) Λk
bk

, Rk = IM − Λk+1 + Γk, Ck = Gk ⊗ Vk.

Note that the matrices Rk is row-stochastic and Ck is doubly-stochastic such that we have by induction

Also, let us recall the notions with dimension mentioned in the main text:

1T
M
M

Yk =

1T
M
M

∇F (Xk) , ∀k ≥ 0.

xi,k ∈ Rd ∀i,
yi,k ∈ Rd ∀i,

Xk := [x1,k, x2,k, · · · , xM,k]T ∈ RM ×d,
Yk := [y1,k, y2,k, · · · , yM,k]T ∈ RM ×d,
∇F (Xk) := [∇f1 (x1,k) , · · · , ∇fM (xM,k)]T ∈ RM ×d,
ˆXk := SkXk = (cid:2)ˆxT
∈ Rn×d,
1,k, ˆxT
ˆYk := SkYk = (cid:2)ˆyT
1,k, ˆyT
1T
1T
n
n
n
n
1T
1T
n
n
n
n
x∗ := argmin

2,k, · · · , ˆxT
2,k, · · · , ˆyT
n,k

SkXk ∈ R1×d,

SkYk ∈ R1×d,

f (x) ∈ R1×d.

∈ Rn×d,

n,k
(cid:3)T

ˆXk =

ˆYk =

¯xk :=

¯yk :=

(cid:3)T

(35)

x

Now, we show that how each algorithm mentioned in this paper can be recovered with particular choices of (Γk, Rk, Ck)
as well as the projection matrix Sk := (cid:0)In ⊗ 1T
(c.f., Eq. (12)).
The following lemma related to Kronecker product is crucial in recovering these algorithms.
Lemma 1. Suppose Assumption 4 holds. Then we have for all k (cid:62) 0,

(cid:1) Λk
bk

m

Proof. Since Λk (IM − Λk) = 0 according to the deﬁnition of Λk, we have Sk+1Rk = Sk+1Γk. Further, we obtain that

Sk+1Rk = Sk+1Γk = WkSk.

(36)

Sk+1Rk = Sk+1Γk =

(cid:18)

(cid:0)In ⊗ 1T

m

. . .







=

1
bkbk+1

mΛi
1T

k+1

(cid:19)






· · ·

· · ·

(37)

(cid:1) Λk+1
bk+1


(cid:19) (cid:18)

(cid:0)Wk ⊗ 11T (cid:1) Λk
bk
· · · w1j,k11T Λj
k

...

· · · wnj,k11T Λj
k










. . .

· · ·


 = Wk

(cid:0)In ⊗ 1T

m

· · ·

(cid:1) Λk
bk

,

=

1
bk

which completes the proof.






· · · w1j,k1T
...
· · · wnj,k1T

mΛj

k

mΛj

k

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

A.1. Recovering (centralized) SAGA, L-SVRG and SARAH

To recover the algorithms with VR schemes, we set the matrices (Γk, Rk, Ck) as follows:

Γk = Λk+111T Λk
bk

, Rk = Im − Λk+1 + Λk+111T Λk
bk

, Ck = Vk.

For SAGA. The matrices Wk, Gk and Vk are set as follows (c.f., Section 4 for more details for these matrices):

Wk = Gk = 1, Vk = Jm, k (cid:62) 1.

(38)

We denote by sk the set of randomly selected sample nodes at iteration k with constant mini-batch size b ∈ [1, m]. Then,
multiplying Sk+1 for both sides of (7) and invoking Lemma 1, we can derive the following recursions:

ˆxk+1 = Sk+1 (RkXk − αΓkYk) = ˆxk − αˆyk,
ˆyk+1 = Sk+1 (JmYk + ∇F (Xk+1) − ∇F (Xtk ))

∇F (Xk) + Sk+1 (∇F (Xk+1) − ∇F (Xk))

(39)

=

=

1T
m
m
1
m

m
(cid:88)

j=1

∇fj (xj,k) +

1
b

(cid:88)

s∈sk+1

(∇fs (ˆxk+1) − ∇fs (xs,k)),

where (ˆxk, ˆyk) is the speciﬁc instance of
with n = 1, and s ∈ sk+1 represents the index of sample randomly
picked at iteration k + 1. It is worth noting that only the picked sample nodes in s ∈ sk+1 performs updates at each iteration.
As a result, the collective gradient vector ∇F (Xk) keeps the historical gradients of all samples, resembling the role of the
table storing the gradients in the original SAGA algorithm (Defazio et al., 2014).

(cid:16) ˆXk, ˆYk

(cid:17)

For L-SVRG. The matrix Vk corresponding to variance reduction and batch-size bk vary as:

(cid:40)

Vk = Im,
Vk = Jm,

w.p. 1 − p

bk = b,
bk = m, w.p. p

,

which indicates that the algorithm performs full gradient update with probability p. Then, by Lemma 1 and Lemma 5, we
derive the recursions of the recovered L-SVRG algorithm with the projection matrix Sk+1:

ˆxk+1 = Sk+1 (RkXk − αΓkYk) = ˆxk − αˆyk,
ˆyk+1 = Sk+1 (VkYk + ∇F (Xk+1) − ∇F (Xk))

=

1
m

m
(cid:88)

j=1

∇fj

(cid:0)xj,tk+1

(cid:1) +

1
bk+1

(cid:88)

s∈sk+1

(cid:0)∇fs (ˆxk+1) − ∇fs

(cid:0)xs,tk+1

(cid:1)(cid:1),

(40)

where tk+1 < k + 1 denotes the latest iteration before k + 1 performing the full gradient update, i.e., btk+1 = m, and
xj,tk+1 = ˆxtk+1, ∀j ∈ [m]. The original L-SVRG algorithm (Qian et al., 2021) is thus recovered.

For SARAH. As with SAGA and L-SVRG, we can verify that SARAH can be also recovered from the SPP framework by
setting:

Vk = Jm,

bk =

(cid:40)

w.p. 1 − p

b,
m, w.p. p

,

(41)

which indicates that SARAH always performs variance reduction (since Vk = Jm) while using dynamic sampling strategy.
Therefore, we can obtain the original SARAH algorithm (Nguyen et al., 2017) by the projection matrix Sk, which shares the
same recursions of SAGA in (39) while intermittently performing full gradient update. It can be further revealed from Table
4 that SARAH is, indeed, a mixing of SAGA and L-SVRG.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Table 4. A uniﬁed perspective for SAGA, L-SVRG and SARAH under SPP framework

Algorithms
bk
Vk

SAGA L-SVRG SARAH
{b, m}
{b, m}
Jm
{Im, Jm}

b
Jm

A.2. Recovering Local-SAGA, D-SAGA and PGA-SAGA

We choose the parameters (Γk, Rk, Ck) as follow:

Γk = Λk+1

(cid:0)Wk ⊗ 11T (cid:1) Λk
bk

, Rk = IM − Λk+1 + Λk+1

(cid:0)Wk ⊗ 11T (cid:1) Λk
bk

, Ck = (In ⊗ Vk) .

For Local-SAGA. We set Gk = In, Vn = Jm, and the mixing matrix Wk corresponding to the actual communication
topology varies as:

(cid:40)

Wk =

In, w.p. 1 − r
Jn, w.p.

r

.

From Lemma 1, we derive the following recursion of the recovered Local-SAGA algorithm:

ˆXk+1 = Sk+1 (RkXk − αΓkYk) = Wk
ˆYk+1 = Sk+1 (((In ⊗ Jm) Yk + ∇F (Xk+1) − ∇F (Xk)))

,

(cid:16) ˆXk − α ˆYk

(cid:17)

(cid:18)

=

In ⊗

(cid:19)

1T
m
m

∇F (Xk) + Sk+1 (∇F (Xk+1) − ∇F (Xk)) .

(42)

Then, by noticing that the decision variables Xk+1 and Xk are only different at the rows corresponding to samples at
iteration k + 1, we have

Sk+1 (∇F (Xk+1) − ∇F (Xk)) =

In ⊗

(cid:18)

(cid:19)

1T
m
m

(∇F (Xk+1) − ∇F (Xk)) ,

which implies

ˆYk+1 =

(cid:18)

In ⊗

(cid:19)

1T
m
m

∇F (Xk) .

By doing so, we get the recovered Local-SAGA algorithm:

ˆXk+1 = Wk

(cid:18)

ˆXk − α

(cid:18)

In ⊗

(cid:19)

1T
m
m

(cid:19)

∇F (Xk)

,

(43)

(44)

(45)

which indicates that each device performs SAGA over their local datasets, and carry out global communication at a
probability of r to reach consensus .

For D-SAGA and PGA-SAGA. Similar to Local-SAGA, the only difference between them are the mixing matrix Wk, in
speciﬁc, we can recover D-SAGA by choosing Wk = W for k (cid:62) 0, and PGA-SAGA by choosing Wk varying as:

(cid:40)

Wk =

W, w.p.
Jn, w.p.

1 − r
r

.

(46)

A.3. Recovering Local-SVRG and D-SVRG

For Local-SVRG. The matrix Wk corresponding to the actual communication topology, and Vk corresponding to variance
reduction vary as:

(cid:40)

Wk =

In, w.p. 1 − r
Jn, w.p.

r

,

(cid:40)

Vk = Im,
Vk = Jm,

w.p. 1 − p

bk = b,
bk = m, w.p. p

,

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

which indicates that each device performs full gradient update with probability p (L-SVRG) over their local datasets, and
global communication to reach consensus with probability r.

Then, similar to Local-SAGA, we can drive the recursions of the recovered Local-SVRG algorithm with Sk+1:

ˆXk+1 = Sk+1 (RkXk − αΓkYk) = Wk

(cid:16) ˆXk − α ˆYk

(cid:17)

,

ˆYk+1 = (cid:0)In ⊗ 1T
(cid:18)

m

=

In ⊗

(cid:1) Λk+1
bk+1
(cid:19)
∇F (cid:0)Xtk+1

1T
m
m

((In ⊗ Vk) Yk + ∇F (Xk+1) − ∇F (Xk))

(47)

(cid:18)

(cid:1) +

In ⊗

(cid:19)

1T
m
m

(cid:0)∇F (Xk+1) − ∇F (cid:0)Xtk+1

(cid:1)(cid:1) .

Noticing that tk+1 < k + 1 denotes the iteration before k + 1 performing full gradient update, which thus recovers the
original Local-SVRG algorithm (Gorbunov et al., 2021).

For D-SVRG. Similar to Local-SVRG, it is straightforward to recover D-SVRG by choosing the mixing matrix Wk = W
for k (cid:62) 0.

A.4. Recovering GT-SAGA

We choose the parameters (Γk, Rk, Ck) as follow:

Γk = Λk+1

(cid:0)Wk ⊗ 11T (cid:1) Λk
bk

, Rk = IM − Λk+1 + Λk+1

(cid:0)Wk ⊗ 11T (cid:1) Λk
bk

, Ck = (Wk ⊗ Vk) ,

which indicates performing both gradient tracking and variance reduction. Then, using Lemma 1, we can derive the
recursions of the recovered GT-SAGA algorithm:

ˆXk+1 = Sk+1 (RkXk − αΓkYk) = Wk

(cid:16) ˆXk − α ˆYk

(cid:17)

,

ˆYk+1 = (cid:0)In ⊗ 1T

m

(cid:18)

= Wk

In ⊗

(cid:1) Λk+1
bk+1
(cid:19)
1T
m
m

((Wk ⊗ Jm) Yk + ∇F (Xk+1) − ∇F (Xk))

Yk + Sk+1∇F (Xk+1) − Sk+1∇F (Xk)

(48)

= Wk ˆYk −

(cid:18)

In ⊗

(cid:19)

1T
m
m

(cid:18)

∇F (Xk+1) −

In ⊗

(cid:19)

1T
m
m

∇F (Xk) ,

where in the last equality we have used the following facts:

(cid:18)

In ⊗

(cid:19)

1T
m
m

(cid:18)

Yk =

In ⊗

(cid:19)

1T
m
m

ΛkYk = ˆYk,

Sk+1 (∇F (Xk+1) − ∇F (Xk) ) =

In ⊗

(cid:18)

(cid:19)

1T
m
m

(∇F (Xk+1) − ∇F (Xk)) .

Noticing that ∇F (Xk), indeed, plays the role of the table of SAGA storing the historical gradients, we thus recover the
original GT-SAGA algorithm (Xin et al., 2020).

New efﬁcient algorithms. It should be noted that we can further design various new algorithms by properly choosing the
matrices Wk, Gk and Vk to obtain suitable performance for different scenarios.

B. Technical Preliminaries

The key idea of the proofs for the main results in Section 5 is based on the proper design of the following Lyapunov function
as deﬁned in (23), which we recall here:

Tk+1 := c0 (cid:107)¯xk+1 − x∗(cid:107)2 + c1

(cid:13)
ˆXk+1 − 1n ¯xk+1
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ c2 (cid:107)∇F (Xtk ) − ∇F (1M x∗)(cid:107)2 + c3 (cid:107)∇F (Xk) − ∇F (1M x∗)(cid:107)2 + c4

(cid:13)
ˆYk − 1n ¯yk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

,

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

where c0, c1, c2, c3, c4 (cid:62) 0 are parameters to be properly determined. In particular, the above Lyapunov function consists of
the following ﬁve error terms in the sense of expectation:

• Optimality gap: E

(cid:104)

(cid:107)¯xk − x∗(cid:107)2(cid:105)

;

• Consensus error across proxy nodes: E

(cid:20)(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

2(cid:21)
;

(cid:13)
(cid:13)
(cid:13)

• Delayed variance-reduction error: E

(cid:104)

(cid:107)∇F (Xtk ) − ∇F (1M x∗)(cid:107)2(cid:105)
;

• Variance-reduction error : E

(cid:104)

(cid:107)∇F (Xk) − ∇F (1M x∗)(cid:107)2(cid:105)

;

• Gradient tracking error: E

(cid:20)(cid:13)
ˆYk − 1n ¯yk
(cid:13)
(cid:13)

2(cid:21)
.

(cid:13)
(cid:13)
(cid:13)

Proof Sketch: To obtain the main results, we ﬁrst need to establish the evolution of each of the above error terms denoted as
ek (c.f., Lemma 9-14) to come up with a recursive dynamics: ek+1 (cid:54) Aek + b. Then, by properly choosing a non-negative
non-zero coefﬁcient vector c := [c0, · · · , c4]T such that we have cT A (cid:54) (cid:37)cT with (cid:37) < 1, we are able us to obtain the
convergence results as stated in Theorem (Corollary) 1-3 for smooth and strongly convex objectives (µ > 0). Similar
procedures can be applied to obtain the sub-linear rates for general convex cases (µ = 0).

Before proceeding to the main proofs, we ﬁrst introduce some lemmas that will be crucial in the subsequent analysis.
Besides, we denote by Fk the σ-algebra generated by {Λ0, R0, C0, · · · , Λk−1, Rk−1, Ck−1}, and deﬁne E [·|Fk] as the
conditional expectation given Fk. We also recall the following deﬁnitions:

ρW := (cid:107)W − Jn(cid:107)2

2 , r := P (Wk = Jn) , p := P (Vk = Jm) , q := E [bk/m|Vk = Jm] ,

where ρW denotes the spectral gap of the ﬁxed mixing matrix W ; r represents the probability of adopting global averaging;
p represents the probability of performing local variance reduction (i.e., updating the gradient table kept by each device); q
represents the expected batch-size of samples while performing variance reduction.

B.1. Supporting Lemmas

In this section, we ﬁrst provide some lemmas that will be used in the subsequent analysis.
Lemma 2. (Nesterov, 2003) Suppose Assumption 1 hold. Then, for any x, x(cid:48) ∈ Rd, we have

(cid:107)∇fi (x) − ∇fi (x(cid:48))(cid:107)2 (cid:54) 2L (fi (x) − fi (x(cid:48)) − (cid:104)∇fi (x(cid:48)) , x − x(cid:48)(cid:105)) .

(49)

Lemma 3. Let x ∈ Rn be a random vector and A ∈ Rn×n be a random matrix. Then, if A is independent on x, we have

(cid:104)

(cid:107)Ax(cid:107)2(cid:105)

E

= E (cid:2)xT AT Ax(cid:3) = E (cid:2)xT E (cid:2)AT A|x(cid:3) x(cid:3) (cid:54) ρ (cid:0)E (cid:2)AT A(cid:3)(cid:1) E

(cid:107)x(cid:107)2(cid:105)
(cid:104)

.

The above lemma follows directly from the smoothing lemma (Gut, 2005) and thus its proof is omitted.
Lemma 4. Suppose Assumption 4 hold. Then, we have for all k (cid:62) 0,

and

(cid:104)

ρ(E

(Sk)T Sk

(cid:105)
) (cid:54) 1
m

,

(cid:32)

ρ

E

(cid:34)(cid:18) 1T
n
n

(cid:19)T (cid:18) 1T
n
n

Sk

Sk

(cid:19)(cid:35)(cid:33)

(cid:54) 1
M

,

where ρ(·) denotes the spectral radius of a matrix.

(50)

(51)

(52)

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Proof. Under Assumption 4, we know that each node i performs independent identically distributed mini-batch sampling
without replacement from ﬁnite m data samples locally. Therefore, by Lemma 3, we have

(cid:104)

E

(Sk)T Sk

(cid:105)

= E

= E

(cid:34)

(cid:34)

1
(bk)2

1
(bk)2

(cid:32)

= E

(cid:20) Λk
bk
C bk−1
m−1
C bk
m
(cid:18)

(cid:18) bk
m

(cid:0)In ⊗ 1m1T

m

(cid:21)

(cid:1) Λk
bk

IM +

C bk−2
m−2
C bk
m
(cid:19)

1 −

bk − 1
m − 1

IM +

bk (bk − 1)
m (m − 1)

(cid:0)In ⊗ 1m1T

m

(cid:1)

(cid:19)(cid:35)

,

(cid:0)In ⊗ (cid:0)1m1T

m − Im

(cid:1)(cid:1)

(cid:33)(cid:35)

where C bk

m denote the number of bk combinations from the set [m]. Then, using Gershgorin circle theorem, we have

(cid:104)

(cid:16)

E

ρ

(Sk)T Sk

(cid:105)(cid:17)

(cid:54) 1
m

,

and

(cid:32)

ρ

E

(cid:34)(cid:18) 1T
n
n

(cid:19)T (cid:18) 1T
n
n

Sk

Sk

(cid:19)(cid:35)(cid:33)

(cid:54) ρ

(cid:18) 1n1T
n2

n

(cid:19)

(cid:104)

(cid:16)

E

ρ

(Sk)T Sk

(cid:105)(cid:17)

=

1
M

,

which completes the proof.

Lemma 5. Suppose Ck = IM hold for k > tk. Then, we have by induction that

Yk = Ctk Ytk + ∇F (Xk) − ∇F (Xtk ) .

(53)

The above lemma shows that there will be a delay in the recursion of Yk when the estimation on the full gradient is not
adopted at each iteration (i.e., Ck = IM ), such as SVRG and L-SVRG algorithms.
Lemma 6. Under the proposed SPP framework, we have for k > 0

Xk+1 = (IM − Λk+1) Xk + Λk+1

(cid:16) ˆXk+1 ⊗ 1m

(cid:17)

,

and

∇F (Xk) = (IM − Λk) ∇F (Xk−1) + Λk∇F

(cid:16) ˆXk ⊗ 1m

(cid:17)

.

(54)

(55)

Proof. By (8), (9), we have

Xk+1 = (IM − Λk+1) Xk + Λk+1

(cid:0)Wk ⊗ 11T (cid:1) Λk
bk

(Xk − αYk)

= (IM − Λk+1) Xk + Λk+1 (Wk ⊗ 1m) (cid:0)In ⊗ 1T

m

= (IM − Λk+1) Xk + Λk+1

(cid:16) ˆXk+1 ⊗ 1m

(cid:17)

,

(cid:1) Λk
bk

(Xk − αYk)

where in the second equality we have used the property of Kronecker product that (A ⊗ B) (C ⊗ D) = AC ⊗ BD. In what
follows, by noticing that Λk∇F (Xk) represents selecting the rows of ∇F (Xk) corresponding to the randomly selected
samples at iteration k by Λk, we have

∇F (Xk) = ∇F

(cid:16)

(IM − Λk) Xk−1 + Λk

(cid:16) ˆXk ⊗ 1m

(cid:17)(cid:17)

= (IM − Λk + Λk) ∇F
(cid:17)

(cid:16) ˆXk ⊗ 1m

= Λk∇F

+ (IM − Λk) ∇F (Xk−1) ,

(cid:16)

(IM − Λk) Xk−1 + Λk

(cid:16) ˆXk ⊗ 1m

(cid:17)(cid:17)

which completes the proof.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Lemma 6 illustrates the update rule of decision variables over the augmented graph, that is, only the sampled nodes (samples)
perform update, while other nodes that are not sampled remain unchanged.
Lemma 7. Suppose Assumption 4 and 5 hold. Then we have for all k > 0

where

E [¯yk|Fk] = r∇f (¯xk) + (1 − r) gk,

gk =

1T
M
M

(cid:16) ˆXk ⊗ 1m

(cid:17)

,

∇F

and r = P (Wk = Jm) denotes the probability of performing global averaging at each iteration.

Proof. By the deﬁnition of ¯yk in (22), we have ¯yk = 1T

n

n SkYk, and

E [¯yk|Fk]

(7b)
= E

Sk (Ck−1Yk−1 + ∇F (Xk) − ∇F (Xk−1)) |Fk

(cid:21)

(cid:20) 1T
n
n
(cid:20)(cid:18) 1T
M
M
(cid:20)(cid:18) 1T
M
M

(11)
= E

=E

Yk−1 +

= E

(cid:20) 1T
n
n

Sk∇F (Xk) |Fk

,

(cid:21)

1T
n
n

Sk∇F (Xk) −

(cid:19)

(cid:21)

Sk∇F (Xk−1)

|Fk

1T
n
n

∇F (Xk−1) +

1T
n
n

Sk∇F (Xk) −

(cid:19)

(cid:21)

∇F (Xk−1)

|Fk

1T
M
M

(56)

(57)

(58)

where in the second equality we have used the fact that E
is doubly-stochastic. Then, by the Eq. (55) in Lemma 6, we obtain
(cid:16) ˆXk ⊗ 1m

E [¯yk|Fk] = E

n Sk

∇F

Λk

Sk

(cid:16)

(cid:104)

n

(cid:17)

+ (IM − Λk) Xk−1

(cid:17)(cid:105)

(cid:21)

|Fk

(cid:104) 1T

(cid:105)

= 1T

n
n

(cid:16)

In ⊗ 1T

m
m

(cid:17)

= 1T

M

M due to Assumption 4 and Ck−1

(cid:20) 1T
n
n
(cid:20) 1T
n
n
(cid:20) 1T
n
n

= E

= E

(cid:104)

Sk

Λk∇F

(cid:16) ˆXk ⊗ 1m

(cid:17)

(cid:105)
+ (IM − Λk) ∇F (Xk−1)

|Fk

(cid:21)

(59)

(cid:16) ˆXk ⊗ 1m

(cid:17)

(cid:21)

|Fk

,

Sk∇F

where in the last equality we have used the fact that Λk (IM − Λk) = 0. Therefore, by the law of total probability, we obtain
(cid:21)

(cid:21)

Sk∇F

(cid:16) ˆXk ⊗ 1m

(cid:17)

|Fk, Wk = Jn

+ (1 − r) E

Sk∇F

(cid:16) ˆXk ⊗ 1m

(cid:17)

|Fk, Wk = W

E [¯yk|Fk] = rE

(cid:20) 1T
n
n

(cid:20) 1T
n
n

= r∇f (¯xk) + (1 − r)

1T
M
M

(cid:16) ˆXk ⊗ 1m

(cid:17)

,

∇F

which completes the proof.

Lemma 7 shows that the expectation of ¯yk is a linear combination of the full gradient evaluated at the averaged decision
variable and that evaluated at the decision variable of proxy nodes.

In the next lemma, we deﬁne an error term σk (resembling internal variance) which can be bounded by the variance reduction
errors, and establish the upper bounds under three particular settings discussed in the main text.
Lemma 8. Suppose Assumption 1-5 hold. Denote

σk := nE

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

1T
n
n

Sk∇F (1M x∗) +

1T
n
n

SkCtk Ytk −

1T
n
n

(cid:13)
2
(cid:13)
Sk∇F (Xtk ) − ∇f (x∗)
(cid:13)
(cid:13)

(cid:35)

|Fk

,

(60)

where tk < k represents the latest iteration before k that Ctk (cid:54)= IM . Then we have, for all k > 0, if we choose Ck ≡ IM
and bk = b,
σk (cid:54) σ∗
b

(61)

,

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

else if Ck = In ⊗ Vk with p > 0 holds,
σk (cid:54) 1 − p
M
p
M

+

(cid:104)

E

E

(cid:104)(cid:13)
(cid:13)∇F (cid:0)Xtk−1

(cid:1) − ∇F (1M x∗)(cid:13)
2
(cid:13)

(cid:105)

|Fk, Vk−1 = Im
(cid:105)

(cid:107)∇F (Xk−1) − ∇F (1M x∗)(cid:107)2 |Fk, Vk−1 = Jm

else if Ck = Wk ⊗ Jm holds,

σk (cid:54) 1
M

E

(cid:104)
(cid:107)∇F (Xk−1) − ∇F (1M x∗)(cid:107)2 |Fk

(cid:105)

.

,

(62)

(63)

Proof. By the deﬁnition of σk and tk, for Ck ≡ IM in the ﬁrst case, which implies tk = 0, we obtain by noticing
Y0 = ∇F (X0) and bk = b that

σk =

E

1
n

=

1
n

n
(cid:88)

i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

E




(cid:34)(cid:13)
(cid:13)
n Sk∇F (1M x∗) − 1T
1T
(cid:13)
n
(cid:13)


(cid:18)

In ⊗

1T
m
m

(cid:19)

(cid:13)
2
(cid:13)
∇F (1M x∗)
(cid:13)
(cid:13)

(cid:35)

|Fk

1
bk

(cid:88)

j∈ξi,k

(∇fij (x∗) − ∇fi (x∗))






|Fk

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:54) 1
n

n
(cid:88)

E

i=1





1
b2
k

(cid:88)

j∈ξi,k

(cid:107)∇fij (x∗) − ∇fi (x∗)(cid:107)2|Fk


 (cid:54) σ∗
b

,

where we used the fact that E [∇fij (x∗) − ∇fi (x∗)] = 0, j ∈ ξi.

For the case that Ck = In ⊗ Vk with p > 0, recalling that Ck is column-stochastic, then we have

σk = nE

(cid:18)(cid:18)

In ⊗

(cid:19)

1T
m
m

∇F (Xtk ) − Sk∇F (Xtk ) + Sk∇F (1M x∗) −

(cid:18)

In ⊗

(cid:19)

1T
m
m

∇F (1M x∗)

=

1
n

E

In ⊗

(cid:19)

1T
m
m

∇F (Xtk ) − Sk∇F (Xtk ) + Sk∇F (1M x∗) −

(cid:18)

In ⊗

1T
m
m

(cid:19)

(cid:13)
2
(cid:13)
∇F (1M x∗)
(cid:13)
(cid:13)

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:35)

|Fk

,

1T
n
n

(cid:18)

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(64)

(cid:35)

|Fk

where in the second equality we used E [Sk] = In ⊗ 1T
(cid:107)X(cid:107)2(cid:105)
(cid:104)
E

(cid:107)X − E [X](cid:107)2(cid:105)

, we get

(cid:54) E

(cid:104)

(65)
m induced by Assumption 4. Furthermore, noticing the fact that

m

E

σk (cid:54) 1
n
(cid:54) 1 − p
M
(cid:104)
p
E
M

+

(cid:104)
(cid:107)Sk∇F (Xtk ) − Sk∇F (1M x∗)(cid:107)2 |Fk

(cid:105)

E

(cid:104)(cid:13)
(cid:13)∇F (cid:0)Xtk−1

(cid:1) − ∇F (1M x∗)(cid:13)
2
(cid:13)

|Fk, Vk−1 = Im

(cid:105)

(66)

(cid:107)∇F (Xk−1) − ∇F (1M x∗)(cid:107)2 |Fk, Vk−1 = Jm

(cid:105)

,

where in the last inequality we have used the law of total probability.

For Ck = Wk ⊗ Jm in the third case, we have p = 1 and

σk (cid:54) 1
M

E

(cid:104)
(cid:107)∇F (Xk−1) − ∇F (1M x∗)(cid:107)2 |Fk

(cid:105)

.

which completes the proof.

Lemma 8 shows that the error term σk is related to the optimization error when the variance-reduction methods are adopted
(see Lemma 12 and 13), otherwise, there will be a ﬁxed upper bound on σk as deﬁned in Assumption 2.

Now we are going to bound each error term in the Lyapunov function (23) and then combine them together to obtain a
recursion of the constructed Lyapunov function with proper choice of c0 − c4.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

B.2. The Recursion of Optimality Gap

Lemma 9. Suppose Assumption 1-5 hold. Then, we have for all k > 0,

E

(cid:104)
(cid:107)¯xk+1 − x∗(cid:107)2 |Fk

(cid:105)

(cid:54) (1 − αµ) (cid:107)¯xk − x∗(cid:107)2 − (cid:0)2α − 8α2L(cid:1) (f (¯xk) − f (x∗))

+ (1 − r)

(cid:0)4α2L2 + αL(cid:1)
n

(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+

2α2σk
n

.

(67)

Proof. Using (22), we have

which implies that

¯xk+1 = ¯xk − α¯yk,

(cid:107)¯xk+1 − x∗(cid:107)2 = (cid:107)¯xk − x∗(cid:107)2 − 2α (cid:104)¯yk, ¯xk − x∗(cid:105) + (cid:107)¯yk(cid:107)2 .

Then by lemma 6 and 7, we get

(cid:104)

E

(cid:107)¯xk+1 − x∗(cid:107)2 |Fk

(cid:105)

(cid:54) (cid:107)¯xk − x∗(cid:107)2 − 2αE [(cid:104)¯yk, ¯xk − x∗(cid:105) |Fk] + α2E

(cid:104)
(cid:107)¯yk(cid:107)2 |Fk

(cid:105)

= (cid:107)¯xk − x∗(cid:107)2 − 2α (cid:104)r∇f (¯xk) + (1 − r) gk, ¯xk − x∗(cid:105) + α2E

(cid:104)
(cid:107)¯yk(cid:107)2 |Fk

(cid:105)

(a)
(cid:54) (1 − αµr) (cid:107)¯xk − x∗(cid:107)2 − 2αr (f (¯xk) − f (x∗)) − 2α (1 − r) (cid:104)gk, ¯xk − x∗(cid:105) + α2E

(cid:104)

(cid:107)¯yk(cid:107)2 |Fk

(cid:105)

(b)
(cid:54) (1 − αµ) (cid:107)¯xk − x∗(cid:107)2 − 2α (f (¯xk) − f (x∗)) +

αL (1 − r)
n

(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ α2E

(cid:104)

(cid:107)¯yk(cid:107)2 |Fk

(cid:105)

,

where in the inequality (a) we have used the fact that f is µ-strongly convex:

−2α (cid:104)r∇f (¯xk) , ¯xk − x∗(cid:105) (cid:54) −2rα (f (¯xk) − f (x∗)) − rαµ (cid:107)¯xk − x∗(cid:107)2 ,

and for the inequality (b), noticing that ˆXk := SkXk =
µ-strongly convex and L-smooth, we have:

− 2α(1 − r) (cid:104)gk, ¯xk − x∗(cid:105)

(cid:104)
1,k, ˆxT
ˆxT

2,k, · · · , ˆxT

n,k

(cid:105)T

∈ Rn×d, and the fact that each fi is

= −2α (1 − r)

= −2α (1 − r)

= −2α (1 − r)

1
n

(cid:28) 1T
n
n
n
(cid:88)

1
n

i=1
n
(cid:88)

i=1

(cid:18)

In ⊗

(cid:19)

1T
m
m

(cid:16) ˆXk ⊗ 1m

(cid:17)

∇F

, ¯xk − x∗

(cid:29)

(cid:104)∇fi (ˆxi,k) , ¯xk − x∗(cid:105)

((cid:104)∇fi (ˆxi,k) , ˆxi,k − x∗(cid:105) + (cid:104)∇fi (ˆxi,k) , ¯xk − ˆxi,k(cid:105))

(cid:54) 2α (1 − r)

+ 2α (1 − r)

1
n

1
n

n
(cid:88)

(cid:16)

fi (x∗) − fi (ˆxi,k) −

i=1
n
(cid:88)

i=1

(cid:18)

fi (ˆxi,k) − fi (¯xk) +

(cid:107)ˆxi,k − x∗(cid:107)2(cid:17)

(cid:19)

(cid:107)ˆxi,k − ¯xk(cid:107)2

µ
2

L
2

= −2α (1 − r) [f (¯xk) − f (x∗)] − αµ (1 − r) (cid:107)¯xk − x∗(cid:107) +

αL (1 − r)
n

(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Further, we can bound the last term in the inequality (b) (note that ∇f (x∗) = 0)

E (cid:107)¯yk − ∇f (x∗) |Fk(cid:107)2
1T
n
n

(22)
= E

Sk∇F (Xk) +

1T
n
n

SkCk−1Yk−1 −

1T
n
n

Sk∇F (Xk−1) − ∇f (x∗)

(cid:35)

|Fk

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

1T
n
n

1T
n
n

(cid:13)
2
(cid:13)
Sk [∇F (Xk) − ∇F (1M ¯xk) + ∇F (1M ¯xk) − ∇F (1M x∗)]
(cid:13)
(cid:13)

(cid:35)

|Fk

Sk∇F (1M x∗) +

1T
n
n

SkCtk Ytk −

1T
n
n

(cid:13)
2
(cid:13)
Sk∇F (Xtk ) − ∇f (x∗)
(cid:13)
(cid:13)

|Fk

(cid:35)

(cid:125)

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

1T
n
n

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

1T
n
n

Sk (∇F (Xk) − ∇F (1M ¯xk))

|Fk

(cid:123)(cid:122)
:=σk/n
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:123)(cid:122)
S1

(cid:35)

(cid:125)

Sk (∇F (1M ¯xk) − ∇F (1M x∗))

(cid:123)(cid:122)
S2

(cid:35)

|Fk

+

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

2σk
n

.

(cid:125)

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:54) 2E

+ 2E

(cid:124)

(cid:54) 4E

(cid:124)

+ 4E

(cid:124)

In what follows, under Assumption 3, we bound the terms S1 and S2 respectively. For S1, we have

E

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(54)
= E

1T
n
n
(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:54) 1
n

n
(cid:88)

i=1

Sk (∇F (Xk) − ∇F (1M ¯xk))

(cid:35)

|Fk

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

1T
n
n

1
m

(cid:16)

∇F

(cid:16) ˆXk ⊗ 1m

(cid:17)

Sk

− ∇F (1M ¯xk)

(cid:35)

|Fk

(cid:17)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

m
(cid:88)

j=1

(cid:107)∇fij (ˆxi,k) − ∇fij (¯xk)(cid:107)2

(6)

(cid:54) L2
n

(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

,

and for S2, we have

E

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

1T
n
n

(cid:13)
2
(cid:13)
Sk (∇F (1M ¯xk) − ∇F (1M x∗))
(cid:13)
(cid:13)

(cid:35)

|Fk

(cid:54) 1
n

n
(cid:88)

i=1

1
m

m
(cid:88)

j=1

(cid:107)∇fij (¯xk) − ∇fij (x∗)(cid:107)2

(6)
(cid:54) 2L (f (¯xk) − f (x∗)) .

Then, combining (68), (69) and (70), we get

E (cid:107)¯yk − ∇f (x∗) |Fk(cid:107)2 (cid:54) 4 (1 − r)

L2
n

ρW

(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ 8L (f (¯xk) − f (x∗)) +

2σk
n

.

which completes the proof.

B.3. The Recursion of Consensus Error

For simplicity, we ﬁrst recall the following notations:

(68)

(69)

(70)

(71)

r = P (Wk = Jm) ,

ρr,W = (1 − r) ρW ,

ρW = (cid:107)W − Jn(cid:107)2 .

Then, we bound the consensus error for two types of algorithms respectively. In particular, the results for the algorithms
adopting only variance-reduction schemes are provided in Lemma 10 while the results for those adopting both variance-
reduction and gradient-tracking schemes are given in Lemma 11.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Lemma 10. Suppose Assumption 1-5 hold. Then, if we set Ck = In ⊗ Vk, we have for all k > 0

(cid:21)

(cid:13)
2
(cid:13)
(cid:13)

|Fk

E

(cid:20)(cid:13)
ˆXk+1 − 1n ¯xk+1
(cid:13)
(cid:13)
(cid:18) 1 + ρr,W
2

+

(cid:54)

4α2L2ρr,W (1 + ρr,W )
1 − ρr,W

(cid:19) (cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

+

8nα2Lρr,W (1 + ρr,W )
1 − ρr,W

(f (¯xk) − f (x∗)) + α2ρr,W

(cid:13)
2
(cid:13)
(cid:13)
(cid:18) 4nζ ∗

1 − ρr,W

(cid:19)

+ nσk

.

Proof. First of all, recalling the deﬁnition of ˆXk in (13), ¯xk in (22) and ρr,W := (1 − r) ρW , we have

(cid:105)

− 1n (¯xk − α¯yk)

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk, Wk = W

(cid:21)

|Fk

(cid:13)
2
(cid:13)
(cid:13)
(cid:104) ˆXk − α ˆYk

E

(cid:20)(cid:13)
ˆXk+1 − 1n ¯xk+1
(cid:13)
(cid:13)

= (1 − r) E

+ rE

(cid:20)(cid:13)
(cid:13)
(cid:13)W

= (1 − r) E

(cid:20)(cid:13)
(cid:13)
(cid:13)Wk
(cid:104) ˆXk − α ˆYk
(cid:20)(cid:13)
(cid:13)
(cid:13)W

(cid:54) (1 − r) (cid:107)W − Jn(cid:107)2
2

(cid:105)

− 1n (¯xk − α¯yk)

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk, Wk = Jn

− 1n (¯xk − α¯yk)

(cid:105)

(cid:104) ˆXk − α ˆYk
(cid:20)(cid:13)
(cid:16) ˆXk − 1n ¯xk
(cid:13)
(cid:13)

E

(cid:17)

− αSkYk

(cid:21)

|Fk

.

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

(cid:13)
2
(cid:13)
(cid:13)

|Fk

= ρr,W E

(cid:20)(cid:13)
(cid:16) ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:17)

− αSkYk

(cid:21)

|Fk

.

(cid:13)
2
(cid:13)
(cid:13)

Then, by Lemma 5, we get

E

(cid:20)(cid:13)
ˆXk+1 − 1n ¯xk+1
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk

(72)

(73)

(cid:54) ρr,W E

(c)
(cid:54) ρr,W E

+ α2ρr,W E

− αSk (Ctk Ytk + ∇F (Xk) − ∇F (Xtk ))

(cid:17)

(cid:20)(cid:13)
(cid:16) ˆXk − 1n ¯xk
(cid:13)
(cid:13)
(cid:34)(cid:13)
(cid:16) ˆXk − 1n ¯xk
(cid:13)
(cid:13)
(cid:13)
(cid:34)(cid:13)
(cid:13)
Sk (Ctk Ytk − ∇F (Xtk )) + Sk∇F (1M x∗) −
(cid:13)
(cid:13)

− α

(cid:18)

(cid:17)

Sk∇F (Xk) − Sk∇F (1M x∗) +

(cid:21)

(cid:13)
2
(cid:13)
(cid:13)

|Fk

(cid:18)

In ⊗

(cid:19)

1T
m

∇F (1M x∗)

(cid:19)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)

(cid:35)

|Fk

(cid:18)

In ⊗

1T
m

(cid:19)

(cid:13)
2
(cid:13)
∇F (1M x∗)
(cid:13)
(cid:13)

|Fk

(cid:35)

(cid:125)

(74)

(cid:124)

(d)
(cid:54) ρr,W (1 + β)

(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ 2α2ρr,W

+ 2α2ρr,W

(cid:18)

1 +

(cid:19)

1
β

nζ ∗ + α2ρr,W nσk,

(cid:123)(cid:122)
:=nσk
(cid:19) (cid:16)
1
β

(cid:18)

1 +

(cid:104)

E

(cid:107)Sk∇F (Xk) − Sk∇F (1M x∗)(cid:107)2 |Fk

(cid:105)(cid:17)

where tk < k denotes the latest iteration before k that Vtk = Jm, and thus Ctk = In ⊗ Jm. Besides, in the inequality (c)
we have used the fact that E
, and in the inequality (d) we have used Young inequality with
parameter β = 1−ρr,W
2ρr,W
(cid:104)

(cid:107)X − E [X](cid:107)2(cid:105)
. Furthermore, noticing that

(cid:107)X(cid:107)2(cid:105)
(cid:104)

(cid:54) E

(cid:104)

(cid:105)

E

(cid:107)Sk∇F (Xk) − Sk∇F (1M x∗)(cid:107)2 |Fk

(cid:104)
(cid:107)Sk∇F (Xk) − Sk∇F (1M ¯xk) + Sk∇F (1M ¯xk) − Sk∇F (1M x∗)(cid:107)2 |Fk

(cid:105)

(75)

= E
(cid:54) 2L2 (cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ 4nL (f (¯xk) − f (x∗)) ,

we thus complete the proof of the lemma.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Lemma 11. Suppose Assumption 1-5 hold. Then, if we set Ck = Wk ⊗ Jm, we have for all k > 0

E

(cid:20)(cid:13)
ˆXk+1 − 1n ¯xk+1
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk

(cid:54) ρr,W

(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+

α2ρr,W (1 + ρr,W )
1 − ρr,W

E

(cid:20)(cid:13)
ˆYk − 1n ¯yk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk

.

(76)

Proof. Recalling the deﬁnition of ˆXk in (13) and ¯xk in (22), we have

E

(cid:20)(cid:13)
ˆXk+1 − 1n ¯xk+1
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk

= (1 − r) E

(cid:20)(cid:13)
(cid:13)
(cid:13)(Wk − Jn)

(cid:16) ˆXk − 1n ¯xk

(cid:17)

− α (W − Jn)

(cid:54) ρW (1 − r) (1 + β)

(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ α2ρW (1 − r)

(cid:21)

|Fk

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

(cid:16) ˆYk − 1n ¯yk
(cid:20)(cid:13)
(cid:19)
ˆYk − 1n ¯yk
(cid:13)
(cid:13)

1 +

E

1
β

(cid:18)

(77)

(cid:21)

|Fk

,

(cid:13)
2
(cid:13)
(cid:13)

where in the last inequality we have used Young inequality. Setting β = 1−ρr,W
2ρr,W

completes the proof.

B.4. The Recursion of Variance Reduction Error

In the following lemma, we show that the VR error will be decaying when the variance-reduction methods such as SAGA,
L-SVRG, are adopted. For ease of presentation, we recall the notions as follows:

q := ρ (E [Λk+1|Vk = Jm]) ,

r := P (Wk = Jn) .

Lemma 12. Suppose Assumption 1-5 hold. Then, we have for all k > 0

(cid:104)

E [∇F (Xk) − ∇F (1M x∗) |Fk, Vk−1 = Jm]
(cid:54) (1 − q) E
+ 2 (1 − r) mqL2 (cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ 4M qL (f (¯xk) − f (x∗)) .

(cid:107)[∇F (Xk−1) − ∇F (1M x∗)](cid:107)2 |Fk, Vk−1 = Jm

(cid:105)

(78)

Proof. Using Lemma 5, we have

∇F (Xk) = (IM − Λk) ∇F (Xk−1) + Λk∇F

(cid:16) ˆXk ⊗ 1m

(cid:17)

.

Then, we further obtain

(cid:104)

E

(cid:107)∇F (Xk) − ∇F (1M x∗)(cid:107)2 |Fk, Vk−1 = Jm

(cid:105)

|Fk, Vk−1 = Jm

(cid:21)

= E

= E

+ E

(cid:16) ˆXk ⊗ 1m

(cid:20)(cid:13)
(cid:13)
(cid:13)(IM − Λk) ∇F (Xk−1) + Λk∇F
(cid:104)(cid:13)
(cid:13) (IM − Λk) [∇F (Xk−1) − ∇F (1M x∗)] (cid:13)
2
(cid:13)
(cid:20)(cid:13)
(cid:17)
(cid:13)
(cid:13)Λk

(cid:16) ˆXk ⊗ 1m

− ∇F (1M x∗)

(cid:104)
∇F

(cid:105)(cid:13)
2
(cid:13)
(cid:13)

(cid:17)

(cid:13)
2
− ∇F (1M x∗)
(cid:13)
(cid:13)
(cid:105)

|Fk, Vk−1 = Jm

|Fk, Vk−1 = Jm

(cid:21)

(cid:105)

(69),(70)

(cid:54) (1 − q) E

(cid:104)

+ 2 (1 − r) mqL2E

(cid:107)∇F (Xk−1) − ∇F (1M x∗)(cid:107)2 |Fk, Vk−1 = Jm
(cid:20)(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

|Fk, Vk−1 = Jm

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

+ 4M qL (f (¯xk) − f (x∗)) .

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

B.5. The Recursion of Delayed Variance Reduction Error

When the variance-reduction methods with random local loops, such as L-SVRG, are adopted, an additional delay error
term will appear and should be dealt with properly for convergence analysis.

Lemma 13. Suppose Assumption 1-5 hold. Then, we have for all k > 0,

(cid:105)

(cid:104)

E

(cid:107)∇F (Xtk ) − ∇F (1M x∗)(cid:107)2 |Fk
(cid:104)(cid:13)
(cid:13)∇F (cid:0)Xtk−1

(cid:54) (1 − p) E
(cid:104)
(cid:107)[∇F (Xk−1) − ∇F (1M x∗)](cid:107)2 |Fk, Vk−1 = Jm

(cid:1) − ∇F (1M x∗)(cid:13)
2
(cid:13)

+ pE

(cid:105)

.

|Fk, Vk−1 = Im

(cid:105)

(79)

The proof for the above lemma is straightforward leveraging the deﬁnition of tk as well as the conditional expectation on the
choices of Vk − 1, which is thus omitted.

B.6. The Recursion of Gradient Tracking Error

The following lemma shows that the error caused by the data heterogeneity across devices is decaying with iteration when
gradient-tracking schemes are adopted.

Lemma 14. Suppose Assumption 1-5 hold, if we set Ck = Wk ⊗ Jm, then for all k > 0

(cid:21)

(cid:13)
2
(cid:13)
(cid:13)

|Fk

E

+

(cid:20)(cid:13)
ˆYk+1 − 1n ¯yk+1
(cid:13)
(cid:13)
(cid:18) 1 + ρr,W
2
4 (1 + ρr,W ) L2
1 − ρr,W
2 (1 + ρr,W )
m (1 − ρr,W )
4n (1 + ρr,W )
1 − ρr,W

(cid:18)

(cid:54)

+

+

+

8α2L2ρr,W (1 + ρr,W )
1 − ρr,W

(cid:19)

E

(cid:104)
(cid:107)Yk − 1M ¯yk(cid:107)2 |Fk

(cid:105)

(cid:0)4 + (1 − r) q + 4 (1 − r) α2L2(cid:1) (cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)
(cid:19)

1 − q +

4α2L2
n

E

(cid:104)
(cid:107)∇F (Xk−1) − ∇F (1M x∗)(cid:107)2

(cid:105)

2 |Fk

(cid:0)8α2L3 + 4L + 2qL(cid:1) (f (¯xk) − f (x∗)) .

(cid:13)
2
(cid:13)
(cid:13)

(80)

Proof. Recalling the deﬁnition of ˆYk in (13) and ¯yk in (22), we have

E

(cid:20)(cid:13)
ˆYk+1 − 1n ¯yk+1
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk

Wk ˆYk + Sk+1 (∇F (Xk+1) − ∇F (Xk))

(cid:21)

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

|Fk

= E

(cid:16)

(cid:20)(cid:13)
(cid:13)
(cid:13)(In − Jn)
(cid:20)(cid:13)
ˆYk − 1n ¯yk
(cid:13)
(cid:13)

E

(cid:54) 1 + ρr,W
2

(cid:21)

|Fk

+

(cid:13)
2
(cid:13)
(cid:13)

1 + ρr,W
1 − ρr,W

E

(cid:104)
(cid:107)Sk+1 (∇F (Xk+1) − ∇F (Xk))(cid:107)2 |Fk

(cid:105)

,

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

where we have used the Young inequality. Then, we ﬁrst bound the last term:

E

(cid:104)
(cid:107)Sk+1 (∇F (Xk+1) − ∇F (Xk))(cid:107)2 |Fk

(cid:105)

(cid:104)

= E

(cid:54) 2E

+

2
m

E

(cid:54) 4L2E

(cid:17)

(cid:16)

∇F

(cid:16) ˆXk+1 ⊗ 1m

(cid:107)Sk+1∇F (Xk+1) − Sk+1∇F (1M x∗) + Sk+1∇F (1M x∗) − Sk+1∇F (Xk)(cid:107)2 |Fk
(cid:20)(cid:13)
(cid:16) ˆXk ⊗ 1m
(cid:13)
(cid:13)Sk+1
(cid:104)
(cid:107)∇F (Xk) − ∇F (1M x∗)(cid:107)2 |Fk
(cid:20)(cid:13)
(cid:20)(cid:13)
ˆXk+1 − ˆXk
(cid:13)
(cid:13)
(cid:13)Sk+1∇F
(cid:13)

(cid:13)
2
− Sk+1∇F (1M x∗)
(cid:13)
(cid:13)

(cid:16) ˆXk ⊗ 1m

(cid:16) ˆXk ⊗ 1m

− ∇F (1M x∗)

+ 4E

+ ∇F

− ∇F

(cid:13)
2
(cid:13)
(cid:13)

|Fk

|Fk

(cid:17)

(cid:17)

(cid:17)

(cid:21)

(cid:105)

(cid:21)

(cid:105)

(cid:21)

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

|Fk

(cid:124)

(cid:123)(cid:122)
S3

(cid:125)

(cid:124)

E

(cid:104)
(cid:107)∇F (Xk) − ∇F (1M x∗)(cid:107)2 |Fk

(cid:105)

,

+

2
m

(cid:123)(cid:122)
S4

(cid:125)

In what follows, we further bound the terms of S3 and S4, respectively. For S3, we have

E

(cid:20)(cid:13)
ˆXk+1 − ˆXk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk

(cid:21)

(cid:13)
2
(cid:13)
(cid:13)

|Fk

= E

(cid:54) E

= E

(cid:21)

(cid:20)(cid:13)
(cid:13)Wk ˆXk − ˆXk − αWk ˆYk
(cid:13)
(cid:20)(cid:13)
(cid:13)Wk ˆXk − ˆXk
(cid:13)
(cid:20)(cid:13)
(cid:13)
2
(cid:13)Wk ˆXk − ˆXk
(cid:13)
(cid:13)
(cid:13)
(cid:105)
(cid:107)¯yk(cid:107)2 |Fk

− 2α

(cid:13)
2
(cid:13)
(cid:13)

|Fk

|Fk

(cid:21)

(cid:104)

+ nα2E

+ α2E

+ α2E

(cid:20)(cid:13)
(cid:13)Wk ˆYk − 1n ¯yk + 1n ¯yk
(cid:13)
(cid:20)(cid:13)
(cid:21)
(cid:13)Wk ˆYk − 1n ¯yk
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

|Fk

(cid:21)

|Fk

− 2α

(cid:13)
2
(cid:13)
(cid:13)

(cid:68)
Wk ˆXk − ˆXk, Wk ˆYk

(cid:69)

(cid:68)
Wk ˆXk − ˆXk, Wk ˆYk − 1n ¯yk

(cid:69)

(cid:54) 2E [(cid:107)Wk − In(cid:107)]2
2

(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ 2α2ρr,W E

(cid:20)(cid:13)
ˆYk − 1n ¯yk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk

+ nα2E

(cid:104)

(cid:107)¯yk(cid:107)2 |Fk

(cid:105)

.

Then, for S4, recalling the relations in (69) and (70), we have

E

(cid:20)(cid:13)
(cid:13)
(cid:13)Sk+1∇F
(cid:20)(cid:13)
(cid:13)
(cid:13)Sk+1
(cid:20)(cid:13)
(cid:13)
(cid:13)Sk+1

(cid:54) 2E

= E

(cid:16) ˆXk ⊗ 1m

(cid:17)

− Sk+1∇F (1M x∗)

(cid:21)

(cid:13)
2
(cid:13)
(cid:13)

|Fk

(cid:16)

(cid:16) ˆXk ⊗ 1m

(cid:17)

∇F

− ∇F (1M ¯xk) + ∇F (1M ¯xk) − ∇F (1M x∗)

(cid:21)

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

|Fk

(cid:16)

∇F

(cid:16) ˆXk ⊗ 1m

(cid:17)

− ∇F (1M ¯xk)

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

(cid:21)

|Fk

+ 2E

(cid:104)
(cid:107)Sk+1 (∇F (1M ¯xk) − ∇F (1M x∗))(cid:107)2 |Fk

(cid:105)

(cid:54)2L2 (cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

+ 4nL (f (¯xk) − f (x∗)) .

Combining all these inequalities above, together with the inequality of E

(cid:104)
(cid:107)¯yk(cid:107)2 |Fk

(cid:105)

in (68), we complete the proof.

Remark 7. It follows from 14, together with Lemma 10 with Lemma 11, that the error caused by the data heterogeneity
across devices is decaying when gradient-tracking methods are adopted, otherwise the heterogeneity constant ζ ∗ as deﬁned
in Assumption 2 will not be eliminated.

C. Proofs in Section 5

In this section, we provide the proofs of Theorem 1-3, followed by the corresponding Corollary 1-3 for the strongly convex
and smooth objectives.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

C.1. Proof of Theorem 1

Proof. For algorithms A (·, ·, Ck ≡ IM ), recalling the following parameter settings of Lyapunov function (23)

c0 = 1, c1 =

8 (1 − r) αL (4αL + 1)
n (1 − ρr,W )

, c2 = c3 = c4 = 0,

and using Lemma 8, 9, 10, we can derive by properly rearranging terms that

E [Tk+1] = c0E

(cid:107)¯xk+1 − x∗(cid:107)2(cid:105)
(cid:104)

+ c1E

(cid:20)(cid:13)
ˆXk+1 − 1n ¯xk+1
(cid:13)
(cid:13)

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

(cid:54) (1 − αµ) c0E

(cid:104)
(cid:107)¯xk − x∗(cid:107)2
2

(cid:105)

(cid:18)

+

1 −

1 − ρr,W
8

(cid:19)

E

(cid:20)(cid:13)
ˆXk − 1n ˆxk
(cid:13)
(cid:13)

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

(cid:32)

+

(1 − r)

(cid:124)

(cid:32)

+

(1 − r)

64α3L2 (4αL + 1) ρr,W (1 + ρr,W )
(1 − ρr,W )2
(cid:123)(cid:122)
e1

(cid:0)4α2L2 + αL(cid:1)
n

− (1 − r)

8αL (4αL + 1)
n (1 − ρr,W )

1 − ρr,W
8

− (cid:0)2α − 8α2L(cid:1)

(cid:33)

E [f (¯xk) − f (x∗)]

(81)

(cid:125)

(cid:33)

E

(cid:125)

(cid:20)(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

(cid:124)

+

2α2σ∗
nb

(cid:123)(cid:122)
e2

+ (1 − r)

8α3L (4αL + 1) ρr,W
(1 − ρr,W )

(cid:18) 4ζ ∗

1 − ρr,W

+

(cid:19)

.

σ∗
b

It can be thus veriﬁed that if the step-size satisﬁes

(cid:40)

α (cid:54) min

1
5L

,

1 − ρr,W
4L(cid:112)ρr,W (1 + ρr,W )

,

1 − ρr,W
12L(cid:112)2ρr,W (1 + ρr,W )

(cid:41)

(cid:26)

= min

O

(cid:19)

(cid:18) 1
L

, O

(cid:18) 1 − ρr,W
√
ρr,W

L

(cid:19)(cid:27)

,

(82)

then the coefﬁcient e0, e1 (cid:54) 0, and we thus have

E [Tk+1] (cid:54)

(cid:18)

(cid:26)

1 − min

αµ,

(cid:27)(cid:19)

1 − ρr,W
8

E [Tk] +

2α2σ∗
nb

+ (1 − r)

16α3Lρr,W
1 − ρr,W

(cid:18) 4ζ ∗

1 − ρr,W

+

(cid:19)

,

σ∗
b

which completes the proof.

C.2. Proof of Corollary 1

Proof. According to Theorem 1, we have

E [Tk] (cid:54)

(cid:18)

(cid:26)

1 − min

αµ, 1 −

(cid:27)(cid:19)k

1 − ρr,W
8

E [T0] +

min

1

(cid:110)

αµ, 1−ρr,W

8

(cid:0)α2D1 + α3D2

(cid:1) ,

(cid:111)

(83)

where

D1 =

2σ∗
nb

, D2 = (1 − r)

8Lρr,W (4αL + 1)
1 − ρr,W

(cid:18) 4ζ ∗

1 − ρr,W

+

(cid:19)

.

σ∗
b

Let γ denote the resulting upper bound on step size α in (82), and give another extra upper bound as follow:

α (cid:54) min




γ,



(cid:16)

ln

max

(cid:111)(cid:17)

, µ3K3
D2

(cid:110)
2, µ2K2
D1
µK






,

(84)

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Then, we consider two possible situations. First, if γ (cid:54) ln

(cid:16)

(cid:110)

max

2,min

(cid:110) µ2K2
D1

, µ3K3
D2

(cid:111)(cid:111)(cid:17)

holds, then we let α = γ, and obtain

E [Tk] (cid:54)

(cid:18)

(cid:18)

1 − min

γµ,

(cid:19)(cid:19)K

1 − ρr,W
8

E [T0] +

µK

1

(cid:16)

min

γµ, 1−ρr,W

8

(cid:0)γ2D1 + γ3D2

(cid:1)

(cid:17)

(cid:18)

(cid:18)

(cid:54) exp

(cid:54) exp

(cid:18)

− min

γµ,

(cid:18)

− min

γµ,

1 − ρr,W
8

1 − ρr,W
8

(cid:19)

(cid:19)

K

E [T0] +

1

(cid:16)

min

γµ, 1−ρr,W

8

(cid:0)γ2D1 + γ3D2

(cid:1)

(cid:17)

(cid:19)

(cid:19)

K

+

D1
µ2K

+

D2
µ3K 2 +

D1
(1 − ρr,W ) µ2K 2 +

D2
(1 − ρr,W ) µ3K 3 .

(85)

To get E [TK] (cid:54) ε, we have
(cid:32)(cid:18) 1
γµ

K (cid:62) O

+

1
1 − ρr,W

(cid:19)

log

E [V0]
ε

+

σ∗
nbµ2ε

+

(cid:115)

ρr,W L
µ3 (1 − ρr,W ) ε

(cid:18) 4ζ ∗

1 − ρr,W

+

σ∗
b

(cid:19)(cid:33)

(cid:62)

1
1 − ρr,W

.

(86)

Second, if

(cid:110)

γ, 1−ρr,W

8µ

(cid:16)

(cid:111)

(cid:62) ln

and then obtain

(cid:110)

max

2,min

(cid:110) µ2K2
D1

(cid:111)(cid:111)(cid:17)

, µ3K3
D2

holds, we set

µK

α =

(cid:16)

ln

max

(cid:110)

2, min

(cid:110) µ2K2
D1

, µ3K3
D2

(cid:111)(cid:111)(cid:17)

µK

,

E [TK] (cid:54) (1 − αµ)K E [T0] +
(cid:16)

(cid:110)



ln

max

2, min

1
µ
(cid:110) µ2K2
D1

(cid:1)

(cid:0)γD1 + γ2D2
(cid:111)(cid:111)(cid:17)

, µ3K3
D2

= exp

−

= O

(cid:18) D1
µ2K

+

D2
µ3K 2

(cid:19)

.

µK



µK

 +

1
µ

(cid:0)γD1 + γ2D2

(cid:1)

In all, substituting the value of γ and hiding the constants, we have E [TK] (cid:54) ε after at most the following number of
iterations:

(cid:32)(cid:18)

K (cid:62) O

L
µ (1 − ρr,W )

(cid:19)

log

E [T0]
ε

+

σ∗
nbµ2ε

+

(cid:115)

ρr,W L
µ3 (1 − ρr,W ) ε

(cid:18) 4ζ ∗

1 − ρr,W

(cid:19)(cid:33)

.

+

σ∗
b

which completes the proof.

C.3. Proof of Theorem 2

Proof. In order to obtain the convergence rate, we choose the following parameters for the Lyapunov function:

c0 = 1, c1 =

20Lα
n (1 − ρr,W )

, c2 =

5α2
M p

, c3 =

16α2
M q

, c4 = 0.

(87)

Then, using Lemma 8, 9, 10, 12 and 13, if

which implies

1 + ρr,W
2

+

4α2L2ρr,W (1 + ρr,W )
1 − ρr,W

(cid:54) 3 + ρr,W
4

,

α (cid:54)

1 − ρr,W
4L(cid:112)ρr,W (1 + ρr,W )

,

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

we can derive the recursion of Lyapunov function as follows:

E [Tk+1] = E

(cid:104)
(cid:107)¯xk+1 − x∗(cid:107)2
2

(cid:105)

+ c1E

(cid:20)(cid:13)
ˆXk+1 − 1n ¯xk+1
(cid:13)
(cid:13)

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

+ c2E
(cid:32)

(cid:54)

(cid:124)

(cid:32)

(cid:104)
(cid:107)∇F (Xtk ) − ∇F (1M x∗)(cid:107)2

2

(cid:105)

+ c3E [∇F (Xk) − ∇F (1M x∗)]

160α3L2ρr,W (1 + ρr,W )
(1 − ρr,W )2

− (cid:0)2α − 72α2L(cid:1)

(cid:33)

E [f (¯xk) − f (x∗)]

(cid:123)(cid:122)
e1
(cid:0)4α2L2 + αL(cid:1)
n

(cid:125)

+ (1 − r)

32α2L2
n

−

5Lα
2n

+

(1 − r)

(cid:20)(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

(cid:33)

E

(cid:125)

(cid:124)
(cid:18) 2α2
n

(cid:124)
(cid:18) 2α2
n

(cid:124)

+

+

1 − p
M

+

(cid:123)(cid:122)
e2
20α3Lρr,W
(1 − ρr,W )
(cid:123)(cid:122)
e3

1 − p
M

p
M

+

20α3Lρr,W
(1 − ρr,W )
(cid:123)(cid:122)
e4

p
M

+

(cid:18)

+ (1 − αµ) E

(cid:104)
(cid:107)¯xk − x∗(cid:107)2
2

(cid:105)

+

1 −

(cid:19)

−

5α2
2M

E

(cid:104)(cid:13)
(cid:13)∇F (cid:0)Xtk−1

(cid:1) − ∇F (1M x∗)(cid:13)
2
(cid:13)
2

(cid:105)

(cid:125)

5α2
M

−

8α2
M

(cid:19)

E

(cid:104)

(cid:107)[∇F (Xk−1) − ∇F (1M x∗)](cid:107)2
2

(cid:105)

(cid:125)

(cid:19)

1 − ρr,W
8

(cid:20)(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

c1E

(cid:105)

(cid:16)

(cid:16)

+

+

1 −

1 −

(cid:17)

(cid:17)

p
2
q
2

c2E

(cid:104)(cid:13)
(cid:13)∇F (cid:0)Xtk−1

(cid:1) − ∇F (1M x∗)(cid:13)
2
(cid:13)
2

(cid:104)

c3E

(cid:107)[∇F (Xk) − ∇F (1M x∗)](cid:107)2
2

(cid:105)

+

80α3Lρr,W
(1 − ρr,W )2 ζ ∗.

It can be veriﬁed that if the step-size satisﬁes:

(cid:40)

α (cid:54) min

1
64L

,

1 − ρr,W
40L

,

1 − ρr,W
16L(cid:112)ρr,W (1 + ρr,W )

(cid:41)

= O

(cid:18) 1 − ρr,W
L

(cid:19)

,

(88)

then we have e1, e2, e3, e4 (cid:54) 0, and

E [Tk+1] (cid:54)

(cid:18)

(cid:26)

1 − min

αµ,

pq
2

,

1 − ρr,W
8

(cid:27)(cid:19)

E [Tk] +

80α3Lρr,W
(1 − ρr,W )2 ζ ∗,

which completes the proof.

C.4. Proof of Corollary 2

Proof. Similar to the proof of Corollary 1, let γ denote the resulting upper bound on step size α in (88), and give another
extra upper bound as follow:

α (cid:54) min

ln






γ,

(cid:16)

max

(cid:110)
2, µ3K2
D1

(cid:111)(cid:17)

µK






,

(89)

(cid:111)(cid:17)

or

(cid:16)

max

(cid:110)

2, µ3K2
D1
µK

where D1 = 80Lρr,W

(1−ρr,W )2 ζ ∗. Then, for a constant iteration K such that either γ (cid:54) ln
(cid:110)
2, µ3K2
D1

max

(cid:111)(cid:17)

ln

(cid:16)

µK

(cid:54) min

(cid:26) 1 − ρr,W
8µ

,

pq
2µ

(cid:27)

,

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Then, substituting the value of γ and hiding the logarithmic factors and constants, we have E [TK] (cid:54) ε after at most the
following number of iterations

K (cid:62) O

(cid:18)(cid:18) 1
pq

+

L
µ (1 − ρr,W )

(cid:19)

log

(cid:19)

E [T0]
ε

+ O

(cid:32)(cid:115)

ρr,W Lζ ∗
(1 − ρr,W )2 µ3ε

(cid:33)

,

which completes the proof.

C.5. Proof of Theorem 3

Proof. For algorithms A (·, ·, Ck = Wk ⊗ Jm), recalling the following parameter settings of Lyapunov function (23)

c0 = 1, c1 =

1 − ρr,W
nρr,W (1 + ρr,W )

, c2 = 0, c3 =

20α2

M q (1 − ρr,W )2 , c4 =

8α2
n (1 − ρr,W )

and using Lemma 8, 9, 11, 12, 14, we have

E [Tk+1] (cid:54)

(cid:18)

(cid:26)

1 − min

αµ,

q
2

,

1 − ρr,W
8

(cid:27)(cid:19)

E [Tk]

+ e1E [f (¯xk) − f (x∗)] + e2E

(cid:20)(cid:13)
ˆXk − 1n ¯xk
(cid:13)
(cid:13)

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

+ e3E

(cid:107)∇F (Xk−1) − ∇F (1M x∗)(cid:107)2(cid:105)
(cid:104)

+ e4E

(cid:20)(cid:13)
ˆYk − 1n ¯yk
(cid:13)
(cid:13)

2(cid:21)

(cid:13)
(cid:13)
(cid:13)

,

where

e1 =

e2 =

32α2L (1 + ρr,W )
(1 − ρr,W )2
32α2L2 (1 + ρr,W )
n (1 − ρr,W )2

(cid:0)8α2L2 + 4 + 2q(cid:1) +

80α2L

(1 − ρr,W )2 − (cid:0)2α − 8α2L(cid:1) ,

(cid:0)4 + (1 − r) q + 4 (1 − r) α2L2(cid:1) + (1 − r)

80α2L2
n (1 − ρr,W )2

+ (1 − r)

(cid:0)4α2L2 + αL(cid:1)
n
16α2 (1 + ρr,W )
M (1 − ρr,W )2
α2
8α2
8n
n

= 0.

−

(cid:18)

e3 =

e4 =

−

(1 − ρr,W )2
4nρr,W (1 + ρr,W )
(cid:19)

,

1 − q +

4α2L2
n

+

2α2
M

−

20α2
2M (1 − ρr,W )2 ,

It can be veriﬁed that if the step-size satisﬁes:

(cid:40)

α (cid:54) min

1
8L

,

1 − ρr,W
4L(cid:112)2ρr,W (1 + ρr,W )

,

(1 − ρr,W )2
528L

(cid:41)

(cid:32)

= O

(1 − ρr,W )2
L

(cid:33)

,

then all the coefﬁcients satisfy e1, e2, e3, e4 (cid:54) 0, which further leads to

E [Tk+1] (cid:54)

(cid:18)

(cid:26)

1 − min

αµ,

q
2

,

1 − ρr,W
8

(cid:27)(cid:19)

E [Tk] .

We thus complete the proof.

C.6. Proof of Corollary 3

Proof. By Theorem 3, we have

E [Tk] (cid:54) max

(cid:26)

1 − αµ,

q
2

,

1 − ρr,W
8

(cid:27)k

E [T0] ,

(90)

(91)

(92)

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

where

α = O

(cid:32)

(1 − ρr,W )2
L

(cid:33)

,

then similar to the proof of Corollary 1, we have E [TK] (cid:54) ε after at most the following number of iterations:

(cid:32)(cid:32)

K (cid:62) O

L
µ (1 − ρr,W )2 +

1
q

(cid:33)

log

(cid:33)

.

E [T0]
ε

D. Sub-linear Convergence Analysis for Convex Problems

In this section, we give the corresponding sub-linear convergence rate in section 5 for smooth and convex (µ = 0) objectives,
the proofs are also based on the Lyapunov function (23).
Theorem 4. Consider algorithms belonging to A (·, ·, Ck ≡ IM ). Suppose Assumption 1-5 hold and µ = 0. Let

c0 = 1, c1 = (1 − r)

8L (4αL + 1)
n (1 − ρr,W )

, c2 = c3 = c4 = 0

and the step-size satisfy

(cid:40)

α (cid:54) min

1
5L

,

(1 − ρr,W )
24L(cid:112)ρr,W (1 + ρr,W )

(cid:41)

(cid:26)

= min

O

(cid:19)

(cid:18) 1
L

, O

(cid:18) 1 − ρr,W
√
ρr,W

L

(cid:19)(cid:27)

,

then we have for all k > 0

1
K

K−1
(cid:88)

k=0

E [f (¯xk) − f (x∗)] (cid:54) 5 (cid:107)¯x0 − x∗(cid:107)2

αK

+

10ασ∗
nb

+ (1 − r)

72α2Lρr,W
n (1 − ρr,W )

(cid:18) 4nζ ∗

1 − ρr,W

+

(cid:19)

.

nσ∗
b

Proof. According to the proof of Theorem 1 and noticing µ = 0, we further let the step size satisﬁes

(93)

(94)

α (cid:54)

(1 − ρr,W )
24L(cid:112)ρr,W (1 + ρr,W )

,

which implies that

(cid:0)2α − 8α2L(cid:1) − (1 − r)

64α3L2 (4αL + 1) ρr,W (1 + ρr,W )
(1 − ρr,W )2

(cid:62) (cid:0)α − 4α2L(cid:1) .

Combining the upper bound of step-size in (82), then we have
(cid:0)α − 4α2L(cid:1) (f (ˆxk) − f (x∗))
2α2σ∗
nb

(cid:54) E [Tk] − E [Tk+1] +

+ (1 − r)

8αL (4αL + 1)
n (1 − ρr,W )

Then, summing over k from 0 to K − 1, we further obtain

1
K

K−1
(cid:88)

k=1

(f (¯xk) − f (x∗))

α2ρr,W

(cid:18) 4nζ ∗

1 − ρr,W

+

(cid:19)

.

nσ∗
b

(95)

(cid:54)

E [T0]
α (1 − 4αL) K
(cid:54) 5 (cid:107)¯x0 − x∗(cid:107)2
αK

+

which completes the proof.

+

2ασ∗
nb (1 − 4αL)

+ (1 − r)

10ασ∗
nb

+ (1 − r)

72α2Lρr,W
n (1 − ρr,W )

8α2L (4αL + 1) ρr,W
n (1 − ρr,W ) (1 − 4αL)
nσ∗
b

(cid:18) 4nζ ∗

1 − ρr,W

+

(cid:19)

,

(cid:18) 4nζ ∗

1 − ρr,W

(cid:19)

+

nσ∗
b

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Corollary 4. Under the same conditions in Theorem 4, suppose the step-size satisfy

(cid:26)

γ,

√

α (cid:54)

1
H1K

,

√
3

1
H2K

(cid:27)

,

where γ denotes the resulting upper bound on α in (93) and

H1 =

σ∗

nb (cid:107)x0 − x∗(cid:107)2 , H2 =

72Lρr,W (1 − r)
(1 − ρr,W ) (cid:107)x0 − x∗(cid:107)2

(cid:18) 4ζ ∗

1 − ρr,W

+

(cid:19)

.

σ∗
b

Then, we have

after at most the following iterations:

1
K

K−1
(cid:88)

k=0

E [f (¯xk) − f (x∗)] (cid:54) ε

(cid:32)

K (cid:62) O

1
γε

+

σ∗
nbε2 +

1
ε3/2

(cid:115)

ρr,W L (bζ ∗ + (1 − ρr,W ) σ∗)
b (1 − ρr,W )2

(cid:33)

(cid:107)¯x0 − x∗(cid:107)2 .

(96)

Proof. According to the obtained sub-linear rate in Theorem 4 and the upper bound on α, we have three cases:

γ (cid:54)

(cid:26) 1
√

H1K

,

√
3

1
H2K

(cid:27)

,

√

1
H1K

(cid:26)

(cid:54)

γ,

√
3

(cid:27)

,

1
H2K

√
3

1
H2K

(cid:26)

(cid:54)

γ,

√

(cid:27)

.

1
H1K

Then, we can obtain

1
K

(cid:54)

K−1
(cid:88)

k=0

min

+ (1 − r)

E [f (¯xk) − f (x∗)]

(cid:110)

5 (cid:107)¯x0 − x∗(cid:107)2
1
γ,
H2K

1√

3√

,

H1K
72Lρr,W
n (1 − ρr,W )

+

(cid:111)

K
(cid:18) 4nζ ∗

1 − ρr,W

10σ∗
nb

√

1
H1K

(cid:19)

+

nσ∗
b

√
3

1
H2K

(cid:54) ε.

Plugging H1 and H2 into the above inequality and merging the similar terms, we obtain the complexity in (96).

Theorem 5. Consider algorithms A (·, ·, Ck = In ⊗ Vk) with p > 0. Suppose Assumption 1-5 hold and µ = 0. Let

c0 = 1, c1 =

20Lα
n (1 − ρr,W )

, c2 =

5α2
M p

, c3 =

16α2
M q

, c4 = 0

and the step-size satisfy

(cid:40)

α (cid:54) min

1
64L

,

1 − ρr,W
40L

,

1 − ρr,W
32L(cid:112)ρr,W (1 + ρr,W )

(cid:41)

= O

(cid:18) 1 − ρr,W
L

(cid:19)

.

Then, we have

1
K

K−1
(cid:88)

k=1

(f (¯xk) − f (x∗)) (cid:54)

E [T0]
αK

+

80α2Lρr,W
(1 − ρr,W )2 ζ ∗.

Proof. According to the proof of Theorem 2 and noticing µ = 0, let the step size satisfy

which implies that

α (cid:54)

1 − ρr,W
32L(cid:112)ρr,W (1 + ρr,W )

,

160α3L2ρr,W (1 + ρr,W )
n (1 − ρr,W )2

(cid:62) (cid:0)α − 36α2L(cid:1) .

(97)

(98)

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Combining the upper bound of step-size in (88), then we get

(cid:0)α − 36α2L(cid:1) (f (¯xk) − f (x∗)) (cid:54) E [Tk] − E [Tk+1] +

80α3Lρr,W
(1 − ρr,W )2 ζ ∗.

(99)

Summing over k from 0 to K − 1, we have

1
K

K−1
(cid:88)

k=1

where

(f (¯xk) − f (x∗)) (cid:54)

E [T0]
α (1 − 36αL) K

+

80α2Lρr,W

(1 − 36αL) (1 − ρr,W )2 ζ ∗ (cid:54)

E [T0]
αK

+

80α2Lρr,W
(1 − ρr,W )2 ζ ∗

(100)

T0 = (cid:107)x0 − x∗(cid:107)2 + O

(cid:19)

(cid:18) α2
pq

(cid:107)∇f (x0) − ∇f (x∗)(cid:107)2

(cid:54) E

(cid:104)

(cid:107)x0 − x∗(cid:107)2(cid:105)

+ O

(cid:19)

(cid:18) α2
pq

L2 (cid:107)x0 − x∗(cid:107)2 = O

(cid:19)

(cid:18) 1
pq

(cid:107)x0 − x∗(cid:107)2 .

Corollary 5. Under the same conditions in Theorem 5, suppose that the step-size

α (cid:54) min

(cid:26)

γ,

√

(cid:27)

,

1
H1K

where γ is the resulting upper bound of α in (97) and

Then, we have

after at most the following iterations:

H1 =

80Lρr,W pq
(1 − ρr,W )2 (cid:107)x0 − x∗(cid:107)2 ζ ∗.

1
K

K−1
(cid:88)

k=0

E [f (¯xk) − f (x∗)] (cid:54) ε

(cid:32)

K (cid:62) O

1
γpqε

+

1
pqε3/2

(cid:115)

(cid:33)

ρr,W Lζ ∗
(1 − ρr,W )2

(cid:107)x0 − x∗(cid:107)2 .

Proof of Corollary 5 is similar to the proof of Corollary 4 and thus omitted.

Theorem 6. Consider the algorithms A (·, ·, Ck = Wk ⊗ Jm). Suppose Assumption 1-5 hold and µ = 0. Let

c0 = 1, c1 =

1 − ρr,W
nρr,W (1 + ρr,W )

, c2 = 0, c3 =

20α2

M q (1 − ρr,W )2 , c4 =

8α2
n (1 − ρr,W )

and the step-size satisfy

(cid:40)

α (cid:54) min

1
8L

,

1 − ρr,W
4L(cid:112)2ρr,W (1 + ρr,W )

,

(1 − ρr,W )2
1056L

(cid:41)

(cid:32)

= O

(1 − ρr,W )2
L

(cid:33)

.

Then, we have

1
K

K−1
(cid:88)

k=0

E [f (¯xk) − f (x∗)] (cid:54)

(cid:16)

2α

(1 − ρW )2 −

(1 − ρW )2
640 + 10 (1 − ρW )2(cid:17)
(cid:16)

(cid:17)

αL

K

E [T0] .

(101)

(102)

(103)

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Proof. According to the proof of Theorem 2 and noticing µ = 0, let the step size satisfy

α (cid:54) (1 − 4αL) (1 − ρr,W )2

1056L

,

which implies that

32α2L (1 + ρr,W )
(1 − ρr,W )2

(cid:0)8α2L2 + 4 + 2q(cid:1) +

80α2L
(1 − ρr,W )2

(cid:54) (cid:0)α − 4α2L(cid:1) .

Combining the upper bound of step-size in (91), then we get

(cid:0)α − 4α2L(cid:1) (f (¯xk) − f (x∗)) (cid:54) E [Tk] − E [Tk+1] .

Summing over k from 0 to K − 1, we have

1
K

K−1
(cid:88)

k=0

(f (¯xk) − f (x∗)) (cid:54)

E [T0]
(1 − αL) αK

,

where

E [T0] = (cid:107)x0 − x∗(cid:107)2 + O

(cid:32)

(cid:33)

(cid:107)∇F (1M x0)(cid:107)2

α2
M q (1 − ρr,W )2
(cid:33)

= (cid:107)x0 − x∗(cid:107)2 + O

(cid:32)

α2L2
q (1 − ρr,W )2

(cid:107)x0 − x∗(cid:107)2 = O

Corollary 6. Under the conditions same in Theorem 6, we have

after at most the following iterations:

1
K

K−1
(cid:88)

k=0

E [f (¯xk) − f (x∗)] (cid:54) ε

K (cid:62) O

(cid:19)

(cid:18) 1
γqε

(cid:107)x0 − x∗(cid:107)2 .

(cid:107)x0 − x∗(cid:107)2

(cid:19)

.

(cid:18) 1
q

(104)

(105)

Proof of Corollary 6 is similar to the proof of Corollary 4 and thus omitted.

E. Additional Experiments

Table 5. Summary of the experimental setup.

Dataset
F-MNIST
CIFAR-10

Node (n)
{8, 20, 50}
{8, 20, 50}

# Train
60000
50000

# Test Dimension
10000
10000

784
3072

BS (n × b)
200
400

SS (α)
0.05
0.008

λ

0.001
0.001

In this section, we further verify our theoretical ﬁndings by several extra experiments. The experiment setting is recalled
here. We train a regularized logistic regression classiﬁer on both CIFAR-10 and Fashion-MNIST (F-MNIST) datasets over a
network of n nodes each of which locally stores m data samples, as deﬁned in (33) and (34):

with the cross-entropy loss (cid:96):

f (x) :=

min
x∈Rd

1
n

n
(cid:88)

i=1

1
m

m
(cid:88)

j=1

(cid:32)

(cid:96) (x, ξij) +
(cid:123)(cid:122)
(cid:124)
fij

λ
2

(cid:33)
,

(cid:107)x(cid:107)2
(cid:125)

(cid:96) (x, ξij) := −

10
(cid:88)

ij log (cid:0)1 + exp (cid:0)−xT θi,j
φc

(cid:1)(cid:1)−1

,

where λ is a regularization parameter, ξij represents the j-th sample of node i with feature vector θi,j ∈ Rd and label
φc
ij ∈ {−1, 1} of class c. The datasets and parameters we used are summarized in Table 5 with r = 0.05 for corresponding
algorithms. All the algorithms are executed on a server with 8 GPUs (NVIDIA RTX 2080Ti).

c=1

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Table 6. Unbalanced label distribution of training samples with h = 20 for CIFAR-10.

Label

Node

1
2
3
4
5
6
7
8

1

2

3

4

5

6

7

8

9

10

555
575
595
615
635
655
675
695

575
595
615
635
655
675
695
555

595
615
635
655
675
695
555
575

615
635
655
675
695
555
575
595

635
655
675
695
555
575
595
615

655
675
695
555
575
595
615
635

675
695
555
575
595
615
635
655

695
555
575
595
615
635
655
675

625
625
625
625
625
625
625
625

625
625
625
625
625
625
625
625

Table 7. A highly unbalanced label distribution of training samples denoted by h = hmax for CIFAR-10.

Label

Node

1
2
3
4
5
6
7
8

1

2

3

4

5

6

7

8

9

10

1000
1000
1000
1000
1000
0
0
0

0
1000
1000
1000
1000
1000
0
0

0
0
1000
1000
1000
1000
1000
0

0
0
0
1000
1000
1000
1000
1000

1000
0
0
0
1000
1000
1000
1000

1000
1000
0
0
0
1000
1000
1000

1000
1000
1000
0
0
0
1000
1000

1000
1000
1000
1000
0
0
0
1000

625
625
625
625
625
625
625
625

625
625
625
625
625
625
625
625

Heterogeneously split dataset. In order to generate different levels of data heterogeneity among devices, we split the
samples of 10 classes into n = {8, 20, 50} nodes with different label distributions for both Fashion-MNIST and CIFAR-10
datasets. In particular, we denote by mi,c the number of samples of class c ∈ [10] allocated to node i ∈ [n], then we generate
the unbalanced label distribution through cyclic arithmetic sequences with a difference of h, i.e, for the case n = 8, we have

mi,c =

(cid:40)

m0 + h(i + c − 2), ∀i, c ∈ [n]
M
10n , ∀i ∈ [n] , c /∈ [n]

,

s.t.,

n
(cid:88)

i=1

mi,c =

M
10

,

10
(cid:88)

c=1

mi,c =

M
n

,

(106)

where M denotes the total number of samples to be allocated, m0 denotes the initial term of the arithmetic sequence, and h
is the difference between the consecutive terms which we used to represent the level of data heterogeneity. We also consider
the cases n = 20, 50 which are larger than the number of classes, then the label distribution {mi,c} is generated as follow:

mi,c = m0 + h((i + c − 2) %10), ∀i ∈ [n] , c ∈ [10] ,

s.t.,

n
(cid:88)

i=1

mi,c =

M
10

,

10
(cid:88)

c=1

mi,c =

M
n

,

(107)

where % denotes the remainder operator. Intuitively, the larger the value of h, the more heterogeneous the local datasets will
be. For example, let n = 8, h = 20 and m0 = 555, we get the allocation strategy of training samples on CIFAR-10 dataset
by (106) in Table 6. Furthermore, we also design a highly unbalanced label distribution of CIFAR-10 denoted by hmax in
Table 7 (can be adapted to F-MNIST), which indicates that each node only has samples of 7 classes while other classes of
samples are inaccessible. As a result, it is very difﬁcult to learn a global model for 10-class image classiﬁcation task in a
distributed manner (c.f. Fig. 2).

Topology dependence. We provide more experiments to verify the topology dependence of different algorithms, as we
reported in the theoretical results in the main text. We compare various algorithms that can be recovered in the proposed
SPP framework on heterogeneously split datasets (h = 20) over graphs: i) directed ring with n = 8; ii) directed ring
with n = 20; iii) geometric graph with n = 50. The results are summarized in Fig. 4. It follows from the ﬁgure that the
algorithms adopting VR and/or GT schemes (solid lines) outperform the others both in terms of testing accuracy and training
loss, especially on the graph with worse connectivity (i.e., n = 50, ρW ≈ 0.99), which veriﬁes the dependency of the
performance of the algorithms on the sampling variance, data heterogeneity, and the connectivity of the graph.

Tackling Data Heterogeneity: A New Uniﬁed Framework for Decentralized SGD

Figure 4. Performance comparison of DSGD, Local-SGD, Gossip-PGA, D-SAGA, Local-SAGA, PGA-SAGA and GT-SAGA over three
graphs: i) directed ring with n = 8 (ﬁrst column); ii) directed ring with n = 20 (second column); iii) geometric graph with n = 50 (third
column). The sub-ﬁgures on the ﬁrst two rows plot the training loss and testing accuracy of the algorithms on Fashion-MNIST dataset,
respectively, and the sub-ﬁgures on the last two rows plot the training loss and testing accuracy on CIFAR-10 dataset.

