1
2
0
2

r
p
A
5

]

C
H
.
s
c
[

2
v
5
8
2
1
0
.
1
0
1
2
:
v
i
X
r
a

All Factors Should Matter! Reference Checklist
for Describing Research Conditions in Pursuit of
Comparable IVR Experiments(cid:63)

Kinga H. Skorupska1,2[0000−0002−9005−0348], Daniel Cnotkowski3,
Julia Paluch1[0000−0002−7657−7856], Rafa(cid:32)l Mas(cid:32)lyk1[0000−0003−1180−2159],
Anna Jaskulska4[0000−0002−2539−3934], Monika Kornacka2[0000−0003−2737−9236],
and Wies(cid:32)law Kope´c1,2[0000−0001−9132−4171]

1 Polish-Japanese Academy of Information Technology
skorupska@pja.edu.pl
2 SWPS University of Social Sciences and Humanities
3 National Information Processing Institute
4 KOBO Association

Abstract. A signiﬁcant problem with immersive virtual reality (IVR)
experiments is the ability to compare research conditions. VR kits and
IVR environments are complex and diverse but researchers from diﬀer-
ent ﬁelds, e.g. ICT, psychology, or marketing, often neglect to describe
them with a level of detail suﬃcient to situate their research on the IVR
landscape. Careful reporting of these conditions may increase the ap-
plicability of research results and their impact on the shared body of
knowledge on HCI and IVR. Based on literature review, our experience,
practice and a synthesis of key IVR factors, in this article we present a
reference checklist for describing research conditions of IVR experiments.
Including these in publications will contribute to the comparability of
IVR research and help other researchers decide to what extent reported
results are relevant to their own research goals. The compiled checklist is
a ready-to-use reference tool and takes into account key hardware, soft-
ware and human factors as well as diverse factors connected to visual,
audio, tactile, and other aspects of interaction.

Keywords: VR · Empirical Studies in HCI · Research practices.

1

Introduction

VR has a long history of development on the reality-virtuality continuuum [17]
which may include any system that makes use of artiﬁcial elements to create a
virtual experience, from the Sensorama machine of 1956, through 3D graphics
on a single ﬂat screen or immersive CAVE environments (Figure 1) to modern
Head Mounted Displays (HMDs).

Consumer solutions were deemed mature enough to conduct scientiﬁc exper-
iments as of 2016 [2] and have made it possible to perform immersive virtual

(cid:63) Supported by KOBO Association and XR Lab at PJAIT.

 
 
 
 
 
 
2

Skorupska et al.

Fig. 1. An Immersive Virtual Reality CAVE, where the IVR experience can be shared
with others and the ”hamster wheel” can simulate covering large distances in VR.

reality (IVR) studies on a budget. This created an illusion that the experiments
conducted with IVR are easily comparable. For example, Buschet al. conclude
“virtual environments can be an alternative to real environments for user experi-
ence studies, when a high presence is achieved.” [7] and as such, they can be used
to simulate real experiences. The excitement of human subjects experiments in
IVR environments in some cases overshadowed the human, environmental and
technological factors which go hand in hand for creating speciﬁc research con-
ditions. Researchers often omit or ignore some of these factors or at least ne-
glect to mention them in their publications, when it comes to IVR experiments.
Such omissions have a lasting eﬀect on the quality of reporting, and the conclu-
sions others can draw based on them. Andujar and Brunet [1] list issues with
VR experiment validation related to ”lack of background on experimentation,
psychology and psychophysics, time-consuming nature of human-subject exper-
iments, and the diﬃculties to fulﬁll all requirements (double-blind experiments,
informed consent, representative users, representative datasets/models/tasks, re-
producibility)”. These issues are in part related to the knowledge of IVR experi-
menters who have to exhibit interdisciplinary competence and take into account
both human and technological factors. Andujar and Brunet also noticed that the
performance of participants of VR experiments may be related to hardware fac-
tors. Continuous development in the ﬁeld of dimensional tracking, high ﬁdelity
displays, wireless transmission of data and motion controls, has brought many
improvements over each new generation of previous VR hardware. Some aspects
may even be hard to compare across diﬀerent HMD versions, not only manufac-
turers, as the speciﬁcity of each of them is reﬂected in the quality of experience
they oﬀer. This fast development pace of IVR solutions may cause older research
to become obsolete - old Oculus or ﬁrst Vive HMDs oﬀered an inferior experience

All Factors Should Matter!

3

to their newest counterparts, but are leaps ahead of Google Cardboard. Thus,
the validity of conclusions is connected to the speciﬁc setup, participants’ psy-
chological features (eg. executive function and attention) and domain. This all
contributed to the signiﬁcant problem with IVR experiments which is related to
the ability to compare research conditions and, in consequence, the applicability
of research results and their contribution to the shared body of knowledge on
human factors and IVR. This is a very important limitation which is diﬃcult to
overcome, but it can be mitigated.

There are multiple guidelines on good research practices in the European
Code of Conduct for Research Integrity5, but such documents are written in
broad strokes and do not cover the speciﬁcs of each subﬁeld, especially one as
complex as the IVR landscape now. Within it, there is diverse research being con-
ducted from case studies of creating interactive VR archaeological exhibits [4],
to making low-cost VR videos to provide higher level of comfort to pre-surgery
patients [18] or coping with stress and regulating emotions [14]. Researchers ex-
plore various aspects of VR, such as the feeling of presence, connected to minute
details like realistic light, sounds or movements [15]; the sense of agency [3], or
even attitudes towards entering and exiting VR environments [12].

This problem is also directly related to the ”reproducibility crisis”, one of the
driving forces of the open science movement. In psychology research, in response
to some of these problems, checklists, such as the one created by Liao et al.[16],
started to appear. Software engineering also saw its share of checklists, as in the
review by Wieringa [21]. The same is needed in the area of IVR experiments,
which has its own speciﬁcity.

Therefore, we have decided to draft an IVR checklist that may guide re-

searchers to report their research in a more comprehensive way.

2 What Factors Matter and Why

First of all, Virtual Reality is a very broad concept, and it is important to dis-
tinguish Immersive Virtual Reality (IVR), usually entered with a head mounted
display (HMD), from Virtual Reality (VR) simulated on a traditional computer
screen, or in a massive VR installation like CAREN (Figure 2).

Grouping insights from these areas together is a somewhat common mistake

of novice practitioners caused by the common shorthand of VR for IVR.

Hardware importance can be also seen in a study [8] which compared video-
conferencing via Skype and VR-mediated communication in ﬁnancial services
based on surveys ﬁlled out by participants after their two meetings, which were
randomly held ﬁrst either in VR, or via Skype. VR communication achieved
signiﬁcantly higher presence and closeness (to the other person) scores, however,
participants rated Skype higher, possibly due to the VR gear being uncomfort-
able to wear.

5 The code was developed by ALLEA - the European Federation of Academies of
Sciences and Humanities and more on this can be found here: https://allea.org/code-
of-conduct/

4

Skorupska et al.

Fig. 2. The CAREN system - is a large scale immersive installation with a movement
sensitive balance platform and a set of diagnostic tools to track body movement.

So, even within IVR proper, entered with a HMD, there exist multiple dif-

ferences which rely on plethora of other factors:

– Head mounted display: while most of the time HMD’s speciﬁcation is pub-
licly available, when it is not, these properties should be reported: per eye
or combined resolution, native refresh rate, ﬁeld of view (horizontal and ver-
tical), display’s pixels per inch, display’s technology, lenses, eye tracking,
recommended user’s IPD or IPD range, HMD’s weight, tracking system.
– Controllers: their model information is necessary to assess the ease of use.
– Graphics processing unit: Even simple VR applications can give very poor
experience if GPU’s performance is not suﬃcient to display graphics on two
or even three (with on screen reproduction) high resolution screens within
target frame rate (e.g. Varjo, Valve Index, Pimax, HTC Vive Pro)6

– Central processing unit: VR applications tend to be GPU intensive due to
combined resolution that needs to be rendered, CPU performance might be
a limiting factor when we incorporate various media streaming methods or
wireless HMD solutions (e.g. HTC Vive, HTC Vive Pro).

– Media storage: due to asset loading, it can negatively impact research that

relies on e.g. high resolution textures coupled with movement.

– Audio accessories: features like active noise cancellation are absent even in
high-end VR solutions, so use of external audio solutions should be reported.
– Cable management systems and extensions: these should be reported as
hardware or software when talking about play space area, especially in re-
gards to room scale VR environments.
If wireless solution was used, information about latency should be provided.

6 In our research we observed that dynamic IVR experiences tend to be more immer-
sive with higher refresh rates, which are not critical for non-dynamic HQ IVREs.

All Factors Should Matter!

5

– External accessories and modiﬁcations: Most HMD accessories and modiﬁ-

cations alter the factors making up the user experience.

While other PC components are important when conﬁguring systems, their
importance from research perspective is little to none as long as complete sys-
tems behave as expected. Given that: motherboard chipset, RAM speed, cable
extension properties etc, do not need to be reported unless they were in some
way the subject of experiment.

Software plays an important role in creating coherent experiences and exper-
iments and key aﬀecting solutions should be reported, even if setup reproduction
may not be possible:

– Framework used: Software like Steam VR, Oculus VR app, proprietary

frameworks. These can change HMDs’ and controller capabilities.

– GPU drivers: GPU’s are one of the most important pieces in hardware setup
for IVR. Diﬀerent versions can cause a performance boost or instability.
– Application engine: Application engine decision is largely based on compat-
ibility, features and team experience. It is important to measure overall per-
formance within our application, to allow for better reproducibility without
need for code publication.

– Boundary system: Most VR frameworks oﬀer some kind of boundary sys-
tem, with various levels of customization. Those settings should be noted,
especially when exploring immersion-related aspects.

– User calibration: With ambiguity regarding if users experience content prop-
erly, a set of actions should be taken into consideration when ﬁtting equip-
ment to participants. HMD ﬁtting, IPD adjustments, eye tracking calibration
are important from experiment validity perspective. Proper vision and com-
fort validation processes should not only be incorporated into experiments,
but also reported if unusual or innovative steps were taken.

Environment design is another critical factor impacting user experience and
immersion. While environment reproduction might be impossible in derivative
works, or when the environment was co-designed in participatory studies [13], it
is important convey enough detail to encourage other researchers to refer to our
work, or to become a source of inspiration for them. Suﬃcient reporting should
include:

– Environment type: Type of environment used - with its features and content

- is the most important information.

– Interactions: While subset of possible meaningful interactions is deﬁned by
environment type and hardware used, it is crucial to describe the subset used
in as much detail as possible. Haptic feedback presence and design should
be also included in interaction description as it can be highly impactful for
certain user groups [11]. Naturally environment interactivity can be close to
none in e.g. 360 videos.

6

Skorupska et al.

– Locomotion system: If used one of most important and troublesome aspect
of bigger than physical space environments. There is plethora of locomotion
techniques to choose from [5], not including in-house solutions. Not only we
should describe how locomotion was solved but also what complementary
systems supported it, such as screen dimming, ﬁeld of view reductions etc.
– Avatar: Usage of certain styles of avatars can increase virtual body owner-
ship and greatly impact immersion. Avatar style, body parts’ tracking and
simulation, and customization options necessitate a detailed description. [20]
– Control scheme: Control scheme in conjunction with controllers and interac-
tions can make up very unique experiences within identical environments.
– Graphic ﬁdelity: Graphic ﬁdelity can impact immersion and overall presence,
even to the point of increasing emotional response to environments [10]. Its
aspects such as graphical style used, content resolution or model complexity
should be described, or visually best presented in research description.

– Sound design: Use of proper sound technology and mixing can lead to more

immersive environments and achievement of higher presence. [19]

– Ethical factors: The ethical factors [6] conveyed by the environment feel
(architectural style, presence of minorities, age groups etc) and interaction
design choices (what you can do with items) may be subject to unconscious
biases and impact the experience for diﬀerent groups of users.

Finally, there is a wide array of possible factors related to participants.
For example, a comparative study on obedience in VR-mediated communica-
tion [9] in which 51 participants were divided into two groups (VR and RR)
to solve problems and encouraged to change their answers by the researcher
who was with them shows that in the VR setting the participants were more
susceptible to manipulation. This eﬀect appears despite the VR avatar of the
researcher having limited emotive capacity. However, the study did not account
for the participants’ familiarity and the perceived presence felt in VR. So there
may have been interference caused by lack of experience with VR. Therefore,
recruitment strategies and screening for IVR experiments and human factors
are critical. Participants can vary considerably, not only in age, socio-economic
circumstances, executive and attentional functioning, emotional reactivity but
also in how receptive and experienced they are with IVR.

Some studies show diﬀerences in behaviors in Virtual Reality and Real Real-
ity, which can be explained by the extent to which the VR scenarios imitate the
RR. Even more diﬀerences are found comparing results of one IVR study with
another with a diﬀerent setup. Without a reference to a detailed checklist of fac-
tors aﬀecting these experiments conclusions from one study may not be relevant
to other studies as the quality of the IVR experience may diﬀer signiﬁcantly.

3 Reference Checklist

Based on literature review, our experience, practice and a synthesis of key IVR
factors we present a reference checklist for describing research conditions of IVR
experiments.

All Factors Should Matter!

7

In creating this preliminary checklist we propose a structured way to present
IVR papers to include, at least, the following core factors aﬀecting the VR
experience and the results:

1. HARDWARE

(cid:3) VR HMD and controllers used
(cid:3) Information about GPU, CPU, Media storage
(cid:3) Audio sources and inputs (external microphones, headphones with ANC)
(cid:3) Wire extensions, cable management systems, wireless solutions (ceiling

mounted cables, wireless adapters)

(cid:3) Non-standard HMD and controller qualities (lens mods, prescription)
(cid:3) Accessories used and modiﬁcations (silicone grips, foam replacement)

2. SOFTWARE

(cid:3) Framework used: Steam VR, Oculus VR or other
(cid:3) GPU drivers’ versions
(cid:3) Application engine
(cid:3) Boundary system and customization
(cid:3) User calibration

3. ENVIRONMENT DESIGN

(cid:3) Environment type
(cid:3) Types of interactions
(cid:3) Locomotion solutions
(cid:3) Avatar look and features
(cid:3) Control scheme
(cid:3) Graphic ﬁdelity and style illustrated with example assets
(cid:3) Sound design
(cid:3) Ethical factors and other unique features.

4. PARTICIPANTS

(cid:3) Recruitment procedures, ethics and informed consent
(cid:3) Prior IVR experience and any training received
(cid:3) Participant age group and socioeconomic status
(cid:3) Exclusions (e.g. participants leaving or ﬁnishing early)
(cid:3) Glasses/hearing aids
(cid:3) VR sickness inducing predispositions (e.g. travel sickness)
(cid:3) General attitude towards VR
(cid:3) Momentary mood
(cid:3) Use of physiological measures of emotional activation (skin conductance)

5. DISTRACTIONS

(cid:3) Obstacles and problems encountered
(cid:3) Waiting times and mean calibration time per participant
(cid:3) Other people present during the experiment (e.g. “spotter”)
(cid:3) Environmental factors such as wind, smells, temperature and sounds

8

Skorupska et al.

4 Conclusions

Relevance of conducted research to other research is of key importance for build-
ing a solid foundation of knowledge. For this reason we are excited to present
this preliminary checklist that takes into account the speciﬁcity of IVR experi-
ments. We hope that this list will be ﬁeld-tested and expanded according to the
diverse experience of the IVR research community. It is our goal to initiate the
discussion which would result in a more standardized and comprehensive way of
describing IVR experiments, so that researchers with all levels of experience and
from very diﬀerent disciplines can more easily situate the research conditions of
each reported IVR experiment on the IVR landscape.

5 Acknowledgments

We would like to thank Kobo Association and all transdisciplinary experts in-
volved with the HASE research initiative (Human Aspects in Science and En-
gineering) including XR Lab at PJAIT, VR Lab at IP PAS, EC Lab at SWPS
University and LIT of the NIPI.

References

1. Andujar, C., Brunet, P.: A Critical Analysis of Human-Subject Experiments in Vir-
tual Reality and 3D User Interfaces, pp. 79–90. Springer International Publishing,
Cham (2015)

2. Anthes, C., Garc´ıa-Hern´andez, R.J., Wiedemann, M., Kranzlm¨uller, D.: State of
the art of virtual reality technology. In: 2016 IEEE Aerospace Conference. pp. 1–19
(March 2016). https://doi.org/10.1109/AERO.2016.7500674

3. Argelaguet, F., Hoyet, L., Trico, M., Lecuyer, A.: The role of interaction in virtual
embodiment: Eﬀects of the virtual hand representation. In: 2016 IEEE Virtual
Reality (VR). pp. 3–10 (March 2016). https://doi.org/10.1109/VR.2016.7504682
4. Barbieri, L., Bruno, F., Muzzupappa, M.: User-centered design of a vir-
International Journal on
tual
Interactive Design and Manufacturing (IJIDeM) 12(2), 561–571 (6 2018).
https://doi.org/10.1007/s12008-017-0414-z

for archaeological museums.

reality exhibit

5. Boletsis, C.: The new era of virtual reality locomotion: A systematic literature
review of techniques and a proposed typology. Multimodal Technologies and Inter-
action 1(4) (2017). https://doi.org/10.3390/mti1040024

6. Brey, P.: The
ality. Ethics
https://doi.org/10.1023/A:1010069907461

ethics

and

of

Information Technology

representation

and

action

in

virtual

1(1),

5–14

(Mar

re-
1999).

7. Busch, M., Lorenz, M., Tscheligi, M., Hochleitner, C., Schulz, T.: Being there
for real – presence in real and virtual environments and its relation to usability.
In: Proceedings of the NordiCHI 2014: The 8th Nordic Conference on Human-
Computer Interaction: Fun, Fast, Foundational (10 2014)

8. Campbell, A., Holz, T., Cosgrove, J., Harlick, M., O’Sullivan, T.: Uses of Virtual
Reality for Communication in Financial Services: A Case Study on Comparing Dif-
ferent Telepresence Interfaces: Virtual Reality Compared to Video Conferencing,
pp. 463–481 (01 2020)

All Factors Should Matter!

9

9. Dzardanova, E., Kasapakis, V., Gavalas, D., Sylaiou, S.: Exploring aspects of
obedience in vr-mediated communication. In: 2019 Eleventh International Con-
ference on Quality of Multimedia Experience (QoMEX). pp. 1–3 (June 2019).
https://doi.org/10.1109/QoMEX.2019.8743196

10. Hvass, J., Larsen, O., Vendelbo, K., Nilsson, N., Nordahl, R., Seraﬁn, S.: Visual
realism and presence in a virtual reality game. In: 2017 3DTV Conference: The
True Vision (3DTV-CON). pp. 1–4 (2017)

11. H˚akonsson, Jakob: Haptic-enhanced presence in vr: Exploring the importance of
haptic feedback in virtual environments to achieve presence (Jan 2018), http:
//muep.mau.se/handle/2043/25952

12. Knibbe, J., Schjerlund, J., Petraeus, M., Hornbæk, K.: The dream is collapsing:
The experience of exiting vr. In: Proceedings of the 2018 CHI Conference on Human
Factors in Computing Systems. pp. 483:1–483:13. CHI ’18, ACM, New York, NY,
USA (2018). https://doi.org/10.1145/3173574.3174057

13. Kope´c, W., Wichrowski, M., Kalinowski, K., Jaskulska, A., Skorupska, K.,
Cnotkowski, D., Tyszka, J., Popieluch, A., Voitenkova, A., Mas(cid:32)lyk, R., Gago, P.,
Krzywicki, M., Kornacka, M., Biele, C., Kobyli´nski, P., Kowalski, J., Abramczuk,
K., Zdrodowska, A., Pochwatko, G., Mo˙zaryn, J., Marasek, K.: Vr with older adults:
Participatory design of a virtual atm training simulation. IFAC-PapersOnLine
52(19), 277–281 (2019). https://doi.org/10.1016/j.ifacol.2019.12.110

14. Kornacka, M., Douilliez, C.: Steer away from rumination? the impact of repetitive
negative thinking on attentional disengagement. International Journal of Psychol-
ogy 51, 632 (2016)

15. Lee, M., Kim, K., Daher, S., Raij, A., Schubert, R., Bailenson, J., Welch, G.:
The wobbly table: Increased social presence via subtle incidental movement of a
real-virtual table (03 2016)

16. Liao, Y., Skelton, K., Dunton, G., Bruening, M.: A Systematic Review of Methods
and Procedures Used in Ecological Momentary Assessments of Diet and Physical
Activity Research in Youth: An Adapted STROBE Checklist for Reporting EMA
Studies (CREMAS). Journal of Medical Internet Research 18(6), e151 (Jun 2016).
https://doi.org/10.2196/jmir.4954, http://www.jmir.org/2016/6/e151/

17. Milgram, P., Takemura, H., Utsumi, A., Kishino, F.: Augmented reality: A class
of displays on the reality-virtuality continuum. Telemanipulator and Telepresence
Technologies 2351 (01 1994). https://doi.org/10.1117/12.197321

18. O’Sullivan, B., Alam, F., Matava, C.T.: Creating low-cost 360-degree virtual reality

videos for hospitals: A technical paper on the dos and don’ts (2018)

19. Poeschl, S., Wall, K., Doering, N.: Integration of spatial sound in immersive virtual
environments an experimental study on eﬀects of spatial sound on presence. In:
2013 IEEE Virtual Reality (VR). pp. 129–130 (2013)

20. Waltemate, T., Gall, D., Roth, D., Botsch, M., Latoschik, M.: The Impact of
Avatar Personalization and Immersion on Virtual Body Ownership, Presence, and
Emotional Response. IEEE Transactions on Visualization and Computer Graphics
PP, 1–1 (2018). https://doi.org/10.1109/TVCG.2018.2794629

21. Wieringa, R., Condori-Fernandez, N., Daneva, M., Mutschler, B., Pastor, O.:
Lessons learned from evaluating a checklist for reporting experimental and ob-
servational research. In: Proceedings of the ACM-IEEE international symposium
on Empirical software engineering and measurement - ESEM ’12. p. 157. ACM
Press, Lund, Sweden (2012). https://doi.org/10.1145/2372251.2372279, http://
dl.acm.org/citation.cfm?doid=2372251.2372279

