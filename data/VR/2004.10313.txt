Keep It Real: a Window to Real Reality in Virtual Reality

Baihan Lin
Computational Visual Inference Lab, Columbia University, New York, NY 10027, USA
Department of Applied Mathematics, University of Washington, Seattle, WA 98195, USA
baihan.lin@columbia.edu

0
2
0
2

v
o
N
2
1

]

C
H
.
s
c
[

3
v
3
1
3
0
1
.
4
0
0
2
:
v
i
X
r
a

Abstract

This paper proposed a new interaction paradigm in
the virtual reality (VR) environments, which con-
sists of a virtual mirror or window projected onto
a virtual surface, representing the correct perspec-
tive geometry of a mirror or window reﬂecting the
real world. This technique can be applied to various
videos, live streaming apps, augmented and virtual
reality settings to provide an interactive and immer-
sive user experience. To support such a perspective-
accurate representation, we implemented computer
vision algorithms for feature detection and corre-
spondence matching. To constrain the solutions,
we incorporated an automatically tuning scaling
factor upon the homography transform matrix such
that each image frame follows a smooth transition
with the user in sight. The system is a real-time
rendering framework where users can engage their
real-life presence with the virtual space. 1

Figure 1: Projective geometry problem for the perspective mirror.

1 Introduction
Traditional VR technologies usually emphasize creating an
entirely immersive environment, visual inputs of the real re-
alities are usually discouraged [Burdea and Coiffet, 2003;
Bowman and McMahan, 2007]. Studies have attempted to
introduce virtual mirrors to facilitate embodiment [Spanlang
et al., 2014], rehabilitation [Sato et al., 2010] and education
[Blum et al., 2012], but almost all of them reﬂects the virtual
space (e.g.
the body of the avatar in the virtual room). We
demonstrated in our system, however, that the introduction
of such a virtual window or mirror reﬂecting the real world
can bridge the two realities in a surprisingly beneﬁcial syn-
ergy: (1) introducing a virtual window or mirror which the
user could activate or deactivate any time could encourage the
user to actively attend to and seamlessly receive real-world
feedbacks where virtual rendering was challenging; (2) pro-
jecting a geometrically accurate representation of users’ im-
age and reality into a movie could create an illusion that the
user is presently sharing the same universe with the virtual
characters – breaking the fourth wall.

1The data and code to reproduce the video application can be

downloaded at https://github.com/doerlbh/V2R

Figure 2: Examples of the perspective mirrors in augmented reality.

2 Projective Geometry

As in Figure 1, the projective geometry problem is outlined
as follows: the user is the observer O who has a reﬂection of
a virtual mirror image at O(cid:48) from a window or mirror on a vir-
tual plane (e.g. a virtual wall); camera C with unknown dis-
tances covers the user in its ﬁeld angle, and we wish to solve
the perspective transform (the homography), from the camera
view plane, (i) to the virtual camera view plane by the mir-
ror, (ii) to the virtual plane where the mirror is located, and
eventually (iii) to the image space where the observer sees.
Solving (iii) is straightforward [Coxeter, 2003], but solving
(i) and (iii) is nontrivial since depth estimation in a video and
the camera at the same time is an innately chanllenging prob-
lem. In another word, there is not a unique homography for
the projection of the mirror image, but a ray of solutions for
each point. We tackled the issue by introducing an additional
scaling factor to constrain the homography according to each
pairs of image frame. The scheme follows Figure 1.

 
 
 
 
 
 
Figure 3: Procedures to create a real-world window or perspective mirror in the virtual environments (videos, stream apps, AR and VR).

3 Virtual-to-Real (V2R) Mirrors or Windows

The V2R framework involves two main components: pattern
matching (where to put our windows) and image warping.

The pattern matching problem is deﬁned as a feature detec-
tion plus classiﬁcation problem (in case of multiple windows
or mirrors). Since we would like to apply it to real-time cam-
era feed (as in AR and VR), there are two major difﬁculties:
(1) a short response time requires the model to slim and fast;
(2) noisy, blurring and shaking image frame in the video due
to hand-held motion. Neural networks tend to be slower so
we resort to the signal processing methods (such as ﬁltering)
to speed up the computation. For demonstration purpose, we
chose the classical cross-shaped black-white circle as mark-
ers to benchmark our methods, and obtained robust perfor-
mance with template matching, Harris and Hough operators
[Brunelli, 2009] after applying Guassian and median ﬁlters.

Figure 3 summarizes the steps involved in the image warp-
ing: ﬁrst, rectify the camera feed with respect to the virtual
space; then, crop the image given a proper camera ﬁeld angle;
and ﬁnally project it the image space given the computed ho-
mography. This framework turns out to be fairly robust and
ﬂexible to apply to a wide range of applications. For instance,
we can introduce a V2R mirror into a movie in every scene
where a target painting appears, as in the example of the TV
series “Friends”. In VR, we can also make the postboard a
V2R window whenever a button on the control bar is pressed.

Figure 2 conﬁrmed the validity of our method: for instance,
in the rightmost case, the virtual perspective is clearly looking
down from above, and the warped image is indeed as if the
observer was looking down and can only see from the mirror
the bottom half of the body. V2R can be applied in real-
time in a timely fashion (more example videos and images
can accessed at https://github.com/doerlbh/V2R).

As an important concept of AI, the sense of presence can
effectively engage the interaction between the human with the
virtual agents in virtual environments. V2R aims to create
such a synergy by bridging the two spaces seamlessly.

4 The Demonstration System
V2R provides extensive entertainment capacities and interac-
tive possibilities, such as activating and deactivating the win-
dow given certain features or user commands (in VR), expe-
riencing the thrilling emotion of being in the same room with
the serial killer in a blockbuster horror movie only a mirror re-
ﬂection away (in movies), blending your face with an ancient
guru master through the secret portal of a crystal ball (in AR),
priming customers to buy a product by projecting users’ real
world objects into a commercial (in online streaming ad). In
the demonstration, we will provide a pool of interesting short
videos, where the mirror location detection have been prop-
erly trained and tuned, such that the user can see themselves
instantly within these movie clips (e.g. as in Figure 2).

5 Ongoing and Future Directions
Exciting next steps involve developing a wide spectrum of
interactions around V2R and accompany intelligent modules
such as gesture recognition (imagine creating a virtual win-
dow to the real world by drawing a square in the air with
your hands), video conference with virtual windows to mul-
tiple camera feeds (literally as if in the same room), real-
time rendering of virtual objects given the real-world camera
feed (bring an apple from the real life to the virtual space)
etc.. Another direction is to improve the projective geome-
try: these mirrors and windows projected from single-camera
2d images are currently pseudo-representations of what one
should see from the exact computed point of view in the real
world, as the single-camera setup make it hard to perform a
3d reconstruction. A useful extension of V2R is to introduce
multiple cameras, such that the camera depth can be prop-
erly estimated along with a 3d projection of the details that
could be revealed but hidden in 2d representation (e.g. an
occlusion). Another useful extension is to introduce visuo-
tactile and visuo-motor feedbacks [Berger et al., 2020] into
this blended setting, which can potentially change periper-
sonal space in VR. These improvements should illicit highly
interactive user experience and engage more users and re-
search into the ﬁeld of intelligent virtual reality interactions.

References
[Berger et al., 2020] Christopher Berger, Baihan Lin, Bigna
Lenggenhager, Jaron Lanier, and Mar Gonzalez-Franco.
Follow Your Nose: Extended Arm Reach After Pinocchio
Illusion in Virtual Reality. under review, 2020.

[Blum et al., 2012] Tobias Blum, Valerie Kleeberger,
Christoph Bichlmeier, and Nassir Navab. mirracle: An
augmented reality magic mirror system for anatomy
In 2012 IEEE Virtual Reality Workshops
education.
(VRW), pages 115–116. IEEE, 2012.

[Bowman and McMahan, 2007] Doug A Bowman

and
Ryan P McMahan. Virtual reality: how much immersion
is enough? Computer, 40(7):36–43, 2007.

[Brunelli, 2009] Roberto Brunelli. Template matching tech-
niques in computer vision: theory and practice. John Wi-
ley & Sons, 2009.

[Burdea and Coiffet, 2003] Grigore C Burdea and Philippe
Coiffet. Virtual reality technology. John Wiley & Sons,
2003.

[Coxeter, 2003] Harold Scott Macdonald Coxeter. Projective
geometry. Springer Science & Business Media, 2003.
[Sato et al., 2010] Kenji Sato, Satoshi Fukumori, Takashi
Matsusaki, Tomoko Maruo, Shinichi Ishikawa, Hiroyuki
Nishie, Ken Takata, Hiroaki Mizuhara, Satoshi Mizobuchi,
Hideki Nakatsuka, et al. Nonimmersive virtual reality mir-
ror visual feedback therapy and its application for the treat-
ment of complex regional pain syndrome: an open-label
pilot study. Pain medicine, 11(4):622–629, 2010.

[Spanlang et al., 2014] Bernhard Spanlang, Jean-Marie Nor-
mand, David Borland, Konstantina Kilteni, Elias Gi-
annopoulos, Ausi`as Pom´es, Mar Gonz´alez-Franco, Daniel
Perez-Marcos, Jorge Arroyo-Palacios, Xavi Navarro Mun-
cunill, et al. How to build an embodiment lab: achieving
body representation illusions in virtual reality. Frontiers in
Robotics and AI, 1:9, 2014.

