2
2
0
2

r
a

M
7
2

]
I

N
.
s
c
[

2
v
7
7
2
2
1
.
2
0
1
2
:
v
i
X
r
a

1

Meta-Reinforcement Learning for Reliable

Communication in THz/VLC Wireless VR Networks

Yining Wang, Student Member, IEEE, Mingzhe Chen, Member, IEEE,

Zhaohui Yang, Member, IEEE, Walid Saad, Fellow, IEEE, Tao Luo, Senior Member, IEEE,

Shuguang Cui, Fellow, IEEE, and H. Vincent Poor, Life Fellow, IEEE

Abstract

In this paper, the problem of enhancing the quality of virtual reality (VR) services is studied for an

indoor terahertz (THz)/visible light communication (VLC) wireless network. In the studied model, small

base stations (SBSs) transmit high-quality VR images to VR users over THz bands and light-emitting

diodes (LEDs) provide accurate indoor positioning services for them using VLC. Here, VR users move

in real time and their movement patterns change over time according to their applications, where both

THz and VLC links can be blocked by the bodies of VR users. To control the energy consumption of

the studied THz/VLC wireless VR network, VLC access points (VAPs) must be selectively turned on

so as to ensure accurate and extensive positioning for VR users. Based on the user positions, each SBS

must generate corresponding VR images and establish THz links without body blockage to transmit

Y. Wang and T. Luo are with the Beijing Laboratory of Advanced Information Network, Beijing University of Posts and

Telecommunications, Beijing, 100876, China, (e-mail: wyy0206@bupt.edu.cn; tluo@bupt.edu.cn).

M. Chen and H. V. Poor are with the Department of Electrical and Computer Engineering, Princeton University, Princeton,

NJ, 08544, USA, (e-mail: mingzhec@princeton.edu; poor@princeton.edu).

Z. Yang is with the Department of Electronic and Electrical Engineering, University College London, WC1E 6BT London,

UK, (e-mail: zhaohui.yang@ucl.ac.uk).

W. Saad is with the Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Arlington,

VA, 22203, USA, (e-mail: walids@vt.edu).

S. Cui is currently with the School of Science and Engineering (SSE) and Future Network of Intelligence Institute (FNii), the

Chinese University of Hong Kong, and Shenzhen Research Institute of Big Data, Shenzhen, China, 518172; he is also afﬁliated

with Peng Cheng Laboratory, Shenzhen, China, 518066 (e-mail: shuguangcui@cuhk.edu.cn).

This work was supported in part by the National Natural Science Foundation of China under Grant 62171047, in part by

the US National Science Foundation under Grant CNS-1909372, in part by the National Key R&D Program of China with

grant No. 2018YFB1800800, in part by the Basic Research Project No. HZQB-KCZYZ-2021067 of Hetao Shenzhen-HK S&T

Cooperation Zone, in part by Shenzhen Outstanding Talents Training Fund 202002, in part by Guangdong Research Projects

No. 2017ZT07X152 and No. 2019CX01X104, and in part by BUPT Excellent Ph.D. Students Foundation (CX2020210).

A preliminary version of this work [1] is published in the Proceedings of the 2021 IEEE International Conference on

Communications.

 
 
 
 
 
 
2

the VR content. The problem is formulated as an optimization problem whose goal is to maximize the

average number of successfully served VR users by selecting the appropriate VAPs to be turned on and

controlling the user association with SBSs. To solve this problem, a policy gradient-based reinforcement

learning (RL) algorithm that adopts a meta-learning approach is proposed. The proposed meta policy

gradient (MPG) algorithm enables the trained policy to quickly adapt to new user movement patterns.

In order to solve the problem of maximizing the average number of successfully served users for VR

scenarios with a large number of users, a dual method based MPG algorithm (D-MPG) with a low

complexity is proposed. Simulation results demonstrate that, compared to a baseline trust region policy

optimization algorithm (TRPO), the proposed MPG and D-MPG algorithms yield up to 26.8% and

21.9% improvement in the average number of successfully served users as well as 81.2% and 87.5%

gains in the convergence speed, respectively.

Index Terms

Wireless virtual reality, terahertz (THz), visible light communications (VLC), indoor positioning,

meta-learning, reinforcement learning (RL), reliability.

I. INTRODUCTION

Deploying virtual reality (VR) applications over wireless networks provides new opportunities

for VR to offer seamless user experience [2]. However, the scarce bandwidth of sub-6 GHz limits

the ability of wireless networks to satisfy the stringent quality-of-service (QoS) requirements

of VR applications in terms of delivering high data rates, low latency, and high reliability.

A promising solution is to integrate VR services over high frequency bands with abundant

bandwidth, such as terahertz (THz) and millimeter wave (mmWave) frequencies. Currently, 5G

supports millimeter wave (mmWave) frequency bands to provide basic wireless VR services.

However, as discussed by industry in [3], in order to support ultimate VR services that must

integrate vision with perception, an uncompressed bit rate of up to 2 Tbit/s is strictly required.

Hence, it is necessary to study the use of frequency bands beyond mmWave for future wireless

networks. In addition, although the use of beamforming enables mmWave beams to focus on a

small area, interference between neighboring users is still difﬁcult to control in a dense room.

Therefore, THz frequencies are viewed as a natural candidate to provide unprecedentedly high

data rate for VR content transmission due to the large available bandwidth. Moreover, THz

bands can achieve very narrow pencil beamforming (narrower than mmWave) that spatially aligns

narrow THz beams to VR users and, hence signiﬁcantly reducing the interference [4]. However,

3

THz frequencies are highly prone to blockage and their transmission distance is short [5]. In

indoor VR scenarios, although short distances enable high-rate VR image transmission at THz

frequencies, the mobile users’ bodies may lead to dynamic blockages over the THz links, thus

negatively affecting the immersive VR experience. In addition, to ensure a seamless interaction

between the users and the virtual world, it is necessary to accurately locate VR users in real time

for VR image generation and transmission. Therefore, deploying THz-enabled wireless networks

to offer high-reliability VR services faces many challenges such as user positioning, reduction

of link blockage, user association, and reliability assurance.

Recently, several works such as in [5]–[12] studied a number of problems related to wireless

VR networks. In [6], the authors studied the use of both edge fog computing and caching to

satisfy the low latency requirement of VR users. The authors in [7] proposed a novel mobile

edge computing-based mobile VR delivery framework that can cache the ﬁeld of views (FOVs)

of 360◦ VR images. The work in [8] studied the problem of resource management in wireless

VR networks to minimize the VR interaction latency. However, the works in [6]–[8] sacriﬁced

the quality of delivered VR videos (e.g., by reducing the resolution of VR videos or only

displaying the FOV of 360◦ VR images) to meet the low latency constraints. This challenge can

be addressed by using high frequency bands (e.g., mmWave and THz) with abundant bandwidth

to transmit high-quality VR images. The authors in [9] investigated the use of the mmWave

bands to maximize the quality of the delivered video chunks in a wireless VR network. In

[10], the authors introduced a multi-connectivity (MC)-enabled mmWave network for providing

low-latency VR services. The work in [11] studied the use of mmWave bands to meet the high

bandwidth requirements of panoramic VR video streaming. However, the works in [9]–[11] did

not study how to use mmWave and high frequency bands to provide reliable VR services in a

dense VR scenario. In [5], the authors studied the use of THz bands to provide VR services in a

dense VR network. The authors in [12] studied the use of THz-based reconﬁgurable intelligent

surfaces (RISs) to serve VR users in a wireless network. However, the works in [5] and [9]–[12]

did not consider the mobility of users that can signiﬁcantly affect VR network performance,

particularly for THz-enabled wireless VR networks whose transmission links can be blocked by

mobile users. Moreover, all of the existing works in [5]–[12] ignored the requirement of accurate

user localization that is needed to generate users’ VR images. Therefore, in a THz-enabled VR

system, it is necessary to consider the time-varying user positions that are used to generate VR

4

images and avoid dynamic blockages of THz links.

A number of existing works such as in [13]–[15] studied the problem of positioning applied in

a VR system. In [13], the authors used machine learning (ML) algorithms to predict the locations

and orientation of VR users. However, the position prediction accuracy of ML algorithms depends

on the training data and cannot adapt to different users’ movement patterns. The authors in

[14] studied the use of ultrawideband signals and ultrasonic waves to achieve decimeter-level

VR user positioning, respectively. The work in [15] proposed a mobile laser scanning (MLS)

positioning system for indoor VR applications. Although the positioning accuracy of an MLS

system can reach the centimeter-level accuracy, such a laser system is expensive. Moreover, the

existing works in [14] and [15] require equipping VR systems with additional positioning devices,

thus increasing energy consumption and deployment costs. The work in [16] showed that THz

has the potential for indoor positioning. However, since THz bands require very narrow pencil

beamforming in dense indoor VR scenarios, one can only passively adjust the beam direction or

user association after the user moves, which can detach the users from their virtual world. Visible

light communication (VLC) based on light-emitting diodes (LEDs) can provide an alternative

and accurate positioning service [17]. In [18]–[21], the authors proved that using three LEDs that

are in the line of sight (LoS) of the receiver can provide a centimeter-level three-dimensional

(3-D) position. However, none of these works in [18]–[21] considered the dynamic selection

of LEDs according to the user mobility so as to provide inclusive positioning services while

ensuring acceptable brightness in a multi-user VR scenario. To this end, we propose to use a

THz/VLC-enabled wireless VR network that jointly considers the VLC access points (VAPs)

selection and user association in order to provide reliable positioning and high data rate VR

content transmission services for VR users.

The main contribution of this work is, thus, a novel framework that jointly uses VLC and THz

to service VR users. In particular, we study a dynamic THz/VLC-enabled VR network that can

accurately locate VR users in real time using VLC and build THz links to transmit high-quality

VR images based on the users’ positions. In the studied network, only a subset of the VAPs can

be turned on to locate VR users due to the users’ limited tolerance for brightness. Based on the

obtained user positions, each small base station (SBS) must determine the user association to

generate corresponding VR images and build THz links to avoid blockages caused by the user

bodies. The problem is formulated as a reliability maximization problem that jointly considers

5

the VAP selection, user association with THz SBSs, and time varying users’ movement patterns.

The reliability of VR networks is deﬁned as the average number of successfully served VR users.

To solve this problem, we propose a meta-policy gradient (MPG) algorithm to ﬁnd the locally

optimal policy for VAP selection and user association. Compared to traditional reinforcement

learning (RL) algorithms that can only be trained for a ﬁxed environment in which each user has

a ﬁxed movement pattern, the proposed algorithm enables the trained policy to quickly adapt to

new users’ movement patterns. To reduce the computational complexity of the MPG algorithm,

we propose a dual method based MPG algorithm that uses dual method to assist the MPG

algorithm to determine user association based on the selected VAPs. Simulation results show

that, compared to a baseline trust region policy optimization algorithm (TRPO), the proposed

MPG algorithm and the dual method based MPG algorithm yield a performance improvement

of about 26.8% and 21.9% in terms of the average number of successfully served users as well

as about 81.2% and 87.5% gains in the convergence speed, respectively. Simulation results also

show that the proposed dual method based MPG algorithm achieves up to 88.7% reduction in

the training time compared to the MPG algorithm. To the best of our knowledge, this paper is

the ﬁrst to study the joint use of THz and VLC for reliability maximization while considering

dynamic VR users’ movement patterns.

The rest of this paper is organized as follows. The system model and the problem formulation

are described in Section II. The use of MPG algorithm for VAP selection and user association

is introduced in Section III. The dual method based MPG algorithm is presented in Section IV.

In Section V, the numerical results are presented and discussed. Finally, conclusions are drawn

in Section VI.

II. SYSTEM MODEL AND PROBLEM FORMULATION

Consider an indoor wireless network that consists of a set B of B SBSs and a set V of V VAPs.

All the VAPs and SBSs are managed by a central controller. The SBSs are evenly distributed in

an indoor area G to serve a set U of U VR users over THz frequencies, as shown in Fig. 1. In the

studied model, accurate locations of the users are required by the SBSs so as to build LoS THz

links and generate the VR images requested by users [7]. Each VAP provides accurate indoor

positioning and tracking services for VR users using VLC. Here, we consider dual-mode user

equipments (UEs) that are able to access both THz and VLC bands. In the studied multi-user

VR network, at each time slot t, each SBS can only serve one user with a narrow beam while

6

Fig. 1: Illustration of the considered THz/VLC-enabled wireless VR network.

each VAP can locate all the users that are not blocked in its FOV. To control the system energy

consumption, the central controller selects a group of VAPs at the beginning of each time slot to

locate VR users. Here, not all users can be accurately localized due to the user body blockage

over the VLC links [22]. Hence, based on the obtained user positions, the central controller

determines the SBSs associated with the successfully localized users, and then SBSs transmit

the corresponding VR images to those users using wireless THz links. In our model, each time

period n consists of T time slots. A successful transmission implies that the request of a given

VR user is successfully completed within a time period.

A. User Blockage Model

In the studied model, the LoS links (VLC or THz links) between user j and a transmitter (a

VAP or an SBS) can be blocked by other VR users’ bodies [5]. For a given a user j located at
vn
j,t = (xn
j,t, yn
deﬁne a binary variable bn

j,t) at time slot t in time period n and a transmitter k located at (xk, yk, Z), we
kj,t that indicates whether LoS links exist between user j and transmitter

j,t, zn

k, as follows:

kj,t = 1(cid:40)
bn

{γ(xk,yk,Z)+(1−γ)(xn

j,t,yn

j,t,zn

j,t)|0<γ<1}∩ (cid:83)

Dn

m,t=∅

m(cid:54)=j∈U

(cid:41),

(1)

where (cid:8)γ(xk, yk, Z) + (1−γ)(xn
j,t)|0 < γ < 1(cid:9) is the set of all points in the LoS trans-
mission link between transmitter k and user j, Dn
m,t} is the
space occupied by the body of user m at time slot t in time period n and 1{x} = 1 as x is

m,t, z)|0 (cid:54) z (cid:54) zn

m,t = {(xn

m,t, yn

j,t, yn

j,t, zn

true, 1{x} = 0, otherwise. Equation (1) indicates that the LoS link between transmitter k and

user j at time slot t exists only if none of the other users (m (cid:54)= j ∈ U) blocks the transmission

7

link, as shown in Fig. 1. In (1), bn

j is blocked at time slot t in period n; otherwise, we have bn

kj,t = 0 implies that the link between transmitter k and user
kj,t = 1. Here, we assume that the

positions of the VR users remain unchanged during each time slot t.

B. VLC Indoor Positioning

We assume that the three-dimensional (3D) location vn

determined by three VAPs from three different orientations [17], where xn

j,t) of each user j is
j,t are the
j,t is the height of user j. Here, we consider the use of
only three VAPs to localize each user since using more VAPs may increases the complexity of

coordinates of user j in the room, and zn

j,t and yn

j,t = (xn

j,t, yn

j,t, zn

the positioning algorithm [18] and the energy consumption for user localization.

At each time slot t in time period n, a set Ln

t = {l1, l2, l3} of three VAPs is turned on to
broadcast their location information to users. We assume that no optical ﬁlter and concentrator

will be used. The LoS channel gain of the VLC link between VAP lk and user j will be given

by [23]




Gn

lkj,t =


lk j,t)2 cosm(φn

lkj,t, 0 (cid:54) ψn
An
others,
0,

lkj,t

(cid:54) Ψ 1

2

and bn

lkj,t = 1,

(2)

where An

lkj,t = (m+1)ρ

2π(dn

distance between VAP lk and user j, Ψ 1

2

lkj,t)cosM (ψn

lkj,t) with ρ being the detector area, dn
being the receiver FOV semi-angle, φn

being the angle of irradiance and incidence, respectively, m = − ln 2/ ln(cos(Φ 1

lkj,t being the
lkj,t and ψn
lkj,t
)) and M =

2

− ln 2/ ln(cos(Ψ 1
2

)) being Lambertian parameters that depend on the half-power angle Φ 1

2

of

VAP and the receiver FOV semi-angle Ψ 1

2

, respectively. From (2), we see that user j can receive

the location information sent by VAP lk at time slot t only when the following conditions are

satisﬁed: a) VAP lk is in the FOV of user j, and b) the VLC link between VAP lk and user

j is LoS (i.e. bn

lkj,t = 1). When user j receives the location information of three VAPs, it can
accurately calculate its location. Here, we ignore the centimeter-level positioning error since the

VLC based localization is accurate enough for building THz links, generating VR images, and

user blockage analysis [18]–[20]. Then, the set of VAPs available for providing the positioning

service to user j can be given by
(cid:110)

Ln

j,t =

lk

(cid:12)
(cid:12)0 (cid:54) ψn
(cid:12)

lkj,t

(cid:54) Ψ 1

2

, bn

lkj,t = 1, lk ∈ Ln

t

(cid:111)

,

(3)

where Ψ 1

2

is the receiver FOV semi-angle.

Based on three different incidence angles and the corresponding VAP locations, each user j

can calculate its own location vn

j,t at time slot t in period n using a triangulation algorithm [20].

8

Then, the positioning state of user j at time slot t in period n will be

j,t(Ln
pn

t ) =






1, |Ln

0, |Ln

j,t| = 3,
j,t| < 3,

(4)

where |Ln

j,t| represents the number of VAPs that can serve user j.

Once the position of user j is successfully calculated at time slot t in period n (i.e. pn

t ) =
1), user j transmits its own location to the central controller and requests the corresponding

j,t(Ln

VR image. Here, we do not consider the time that each user transmits its position information

transmission to the central controller, since the location information of each user only consists

of three scalars and since this location information is transmitted over THz frequencies that have

abundant bandwidth. Based on the obtained user positions, the central controller can determine

the user-SBS association and, then, the SBSs can generate corresponding VR images and serve

the associated users over THz band.

C. Transmission Model

We assume that a time division multiple access (TDMA) technique is adopted for each SBS.

Due to the extremely narrow pencil beamforming (narrower than mmWave) for THz [4], we

assume that each user can only be associated with one SBS and each SBS can only serve one

user at each time slot. In time period n, let un

i and user j at time slot t, i.e., un

ij,t ∈ {0, 1} be the index of the link between SBS
ij,t = 1 implies that user j is associated with SBS i; otherwise,

we have un

ij,t = 0. Then, we have

0 (cid:54)

B
(cid:88)

i=1

un
ij,t

(cid:54) 1, ∀j ∈ U, 0 (cid:54)

U
(cid:88)

j=1

un
ij,t

(cid:54) 1, ∀i ∈ B.

(5)

Since VR users move in real time, at different time periods, the VR users must be served by SBSs

deployed in different locations to avoid blockages of the THz links and to meet the transmission

delay constraints. In the considered network, a time period consists of T time slots. Each user

only needs to successfully receive the requested VR image within a single time slot in each time

period to ensure an immersive VR experience. Hence, the handovers between different SBSs

can be completed during the time slots in which the SBSs do not transmit the VR images over

THz links [24].

9

In the studied model, we assume that each THz SBS and each user will be equipped with

one directional antenna used to form a 3D THz beam. One 3D THz beam is approximated

by a 3D pyramidal-plus-sphere sectored antenna model [25]. In particular, the pyramidal zone

accounts for the main lobe of the antenna beam while the sphere accounts for the side lobes

of the antenna beam, as shown in Fig. 1. At each time slot t, each SBS adjusts the direction

of main lobe towards its associated user so as to guarantee beam alignment. Hence, we only

consider the transmit gain of the main lobe of each SBS, given by [25]

GT =

4π
(ιT + 1)ΩT

,

(6)

where ιT is the ratio of the power concentrated along the side lobes to the power concentrated

along the main lobe of a transmit antenna and ΩT = 4 arcsin

with ϕT
H
V being the horizontal and vertical beamwidths of the transmit antennas, respectively. The

and ϕT

tan

tan

(cid:16)

(cid:17)

(cid:16) ϕT
H
2

(cid:17)(cid:17)

(cid:16) ϕT
V
2

receive gain of the directional antenna of each user will be

GR =

4π
(ιR + 1)ΩR

,

(7)

where ιR is the power ratio between the side lobes and the main lobe of a receive antenna

and ΩR = 4 arcsin

V being the horizontal and vertical
beamwidths of the receive antennas, respectively. Due to the abundant bandwidth at THz fre-

H and ϕR

with ϕR

tan

tan

(cid:16)

(cid:17)

(cid:16) ϕR
H
2

(cid:17)(cid:17)

(cid:16) ϕR
V
2

quencies, we allocate orthogonal THz bands for each SBS to ensure that no inter-cell interference

occurs. In the studied model, since the transmission delay is limited within the time duration ∆t

of a time slot and ∆t is in milliseconds, we assume that the users are static during transmission.

Hence, we can reasonably ignore the Doppler effect in the considered transmission model. At

time slot t in period n, given an SBS i ∈ B located at (xi, yi, Z) and its associated user j ∈ U

located at (xn

j,t, yn

j,t, zn

j,t), the path loss of the THz link between SBS i and user j can be given

by [5]

where rn

ij,t =

(cid:113)

gn
ij,t =






(cid:17)2

(cid:16) c
4πf rn

ij,t

0,

δ(rn

ij,t = 1,

ij,t), bn
bn
ij,t = 0,

(8)

j, c is the speed of light, f is the operating frequency, and δ(rn

(xi − xn

j,t)2 + (yi − yn

j,t)2 + (Z − zn

j,t)2 is the distance between SBS i and user
ij,t) ≈ e(−K(f )rn
ij,t) represents

the transmittance of the medium following the Beer-Lambert law with K(f ) being the overall

absorption coefﬁcient of the medium at THz frequency f [26]. In (8), bn

ij,t is a binary variable
that indicates whether a LoS link exists between SBS i and user j at time slot t in period n.

Given the location of user j, bn

ij,t can be obtained using (1). The total noise power at each UE

j that is generated by thermal agitation of electrons and molecular absorption is [26]

I n
j,t = I0 +

(cid:33)2

(cid:32)

c
4πf rn
lj,t

(cid:88)

P

l∈B

(cid:0)1 − δ(rn

lj,t)(cid:1),

(9)

where P is the transmit power of each SBS, I0 = KBTe represents the Johnson-Nyquist noise

10

generated by thermal agitation of electrons in conductors with KB and Te being Boltzmann
lj,t)(cid:1) is the
constant and the temperature in Kelvin, respectively, and (cid:80)
sum of molecular absorption noise caused by the transmit power of any SBS l ∈ B. The data

(cid:17)2(cid:0)1 − δ(rn

(cid:16) c
4πf rn

l∈B

P

lj,t

rate of VR image transmission from SBS i to its associated user j at time slot t in period n will

then be

C n

ij,t(un

ij,t) = un

ij,tW log2

(cid:18)

1 +

P gn

ij,tGTGR

(cid:19)

I n
j,t

.

(10)

where W is the bandwidth of the THz band.

Given the data size S of the VR image requested by user j at time slot t in period n, the

transmission delay will be

j,t(un
dn

j,t) =

B
(cid:80)
i=1

S

,

(11)

C n

ij,t(un

ij,t)

where un

j,t = [un

Bj,t]. Note that the data size S of a VR image only depends on the
image resolution which remains unchanged during service. Since the user position will change

2j,t, · · · , un

1j,t, un

at the next time slot, the VR image requested by user j can be successfully transmitted only

when the transmission delay is within the time duration ∆t of a time slot t. Then, in time period

n, the transmission state of user j at time slot t can be expressed as

hn
j,t(un

j,t) =






j,t) (cid:54) ∆t,

1, dn

j,t(un
0, otherwise.

(12)

From (12), we can see that, whether the requested VR image of user j is successfully transmitted

at time slot t or not depends on the user’s locations, user association, and blockages between

SBS i and user j.

D. Reliability Model

As mentioned earlier, in our model, the reliability of the THz/VLC-enabled wireless VR

network refers to the average number of successfully served VR users. At each time slot t, a

successfully served user j must satisfy two conditions: a) user j is successfully localized and b)

the VR image requested by user j is transmitted within ∆t. In order to enable a seamless and

immersive wireless VR experience, we assume that the waiting delay is limited to a time period

that consists of T time slots. In other words, each user should be successfully served at least

once in a time period. Therefore, in time period n, the service state of user j until time slot t

11

based on the selected Ln

t and un
t , un

j,t will be
j,t(Ln

j,t) = (cid:0)pn

wn

j,t(Ln

t )hn

j,t(un

j,t)(cid:1) ∨ wn

j,t−1(Ln

t−1, un

j,t−1).

(13)

where t = 2, 3, · · · , T and ∨ represents the logical “or” operation. The newly served users at

time slot t will be

W n

t (Ln

t,un

j,t) = {j|wn

j,t(Ln

t,un

j,t) = 1, wn

j,t−1(Ln

t−1,un

j,t−1) = 0}.

Then, the number of successfully served users in each time period n can be given by

Rn(Ln

:T , un

j,:T ) =

T
(cid:88)

(cid:12)
(cid:12)W n

t (Ln

t,un

j,t)(cid:12)
(cid:12),

(14)

(15)

where Ln

t=1
j,1, · · · , un
j,T }. From (15)-(13) we can see that, once
a VR user is successfully served at least once in T time slots, the seamless VR experience of

T } and un

j,:T = {un

1 , · · · , Ln

:T = {Ln

this user can be guaranteed. Therefore, the maximum waiting delay for each VR user is T time

slots.

E. Problem Formulation

Given the deﬁned system model, our goal is to effectively select the subset of VAPs to provide

accurate positioning services and, then, determine the user-SBS association based on the obtained

user positions so as to maximize the reliability of the studied VR network. Then, the reliability

maximization problem is formulated as follows:
:T , un
Rn(Ln
N

max
t ,un
Ln
j,t

N
(cid:88)

j,:T )

,

n=1

s.t.

|Ln

t | = 3,

0 (cid:54)

0 (cid:54)

B
(cid:88)

i=1

U
(cid:88)

j=1

un
ij,t

(cid:54) 1, ∀j ∈ U,

un
ij,t

(cid:54) 1, ∀i ∈ B,

un
ij,t ∈ {0, 1}, ∀i ∈ B, ∀j ∈ U,

(16)

(16a)

(16b)

(16c)

(16d)

where N is the total number of all time periods. Constraint (16a) captures the fact that only three

VAPs are selected at each time slot to provide positioning service. Constraints (16b), (16c), and

12

(16d) indicate that each user can only be associated with one SBS and each SBS can only serve

one user at each time slot. From (16), we can see that the reliability depends on the selected VAPs

and the user association with SBSs. Meanwhile, the VAP selection and the user-SBS association

depend on the positions of the VR users. However, the users’ positions continuously change as

time elapses. Therefore, real-time user positions are needed by the central controller so as to

generate corresponding VR images and build THz links without blockages. Moreover, due to the

time-varying nature of VR applications, the users’ movement pattern varies over different time

periods [27]. Here, we deﬁne a position transition matrix M n as the users’ movement pattern

the user moving from vn

during time period n, in which each element M n
j,t,vn
vn

j,t) is the probability of
j,t+1. Note that the studied THz/VLC-enabled VR network has no
knowledge of the users’ movement patterns. Due to the non-convexity and the unpredictability of

j,t to vn

j,t+1|vn

= P (vn

j,t+1

the users’ movement patterns, (16) cannot be solved by the traditional optimization algorithms,

such as dynamic programming or nonlinear programming. Moreover, traditional RL algorithms,

such as Q-learning [28] or deep Q-network [12], can only solve optimization problems in static

and known environments, and, thus, they are also not suitable to solve the problem in (16).

Hence, we propose a RL algorithm based on a meta-learning framework to sensitively adapt to

dynamic users’ movement patterns so as to determine the VAP selection and the user association

in advance. We next introduce a meta-reinforcement learning algorithm to proactively determine

the VAP selection and the user association.

III. META-LEARNING FOR VAP SELECTION AND USER ASSOCIATION

Next, we introduce a policy gradient-based RL algorithm [29] using meta-learning framework

[30], called meta policy gradient (MPG), that can effectively solve problem (16). Traditional

policy gradient algorithms can only determine the VAP selection and user association in a ﬁxed

environment (i.e., the ﬁxed users’ movement patterns). Meta-learning is a novel learning approach

that can integrate the prior reliability-enhancing experience with information collected from the

new users’ movement patterns, thus training a rapidly adaptive learning model. Therefore, the

proposed MPG can obtain the VAP selection and user association policies that can be quickly

updated to adapt to new users’ movement patterns using only a few further training steps.

Compared with the meta-trained value decomposition-based RL algorithm [31] that uses each

agent’s local observation of the environment to estimate the rewards resulting from the actions, the

13

proposed MPG algorithm enables the agent to directly obtain the reward of a chosen action from

the global environment. Hence, the proposed MPG algorithm can effectively ﬁnd a better action

that results in a higher reliability compared to the RL algorithm in [31]. The VAP selection aims

to obtain the positions of as many users as possible under the limitation of energy consumption.

Then, the user-SBS association is determined based on the user positions in a way to avoid

blockages of THz links and meet the transmission delay constraints. Next, we ﬁrst introduce the

components of the MPG algorithm for VAP selection and user association. Then, we explain the

entire procedure of using our MPG algorithm to select VAPs and determine the user association

with SBSs.

A. Components of MPG

An MPG algorithm consists of six components: a) agent, b) actions, c) states, d) policy, e)

reward, and f) tasks, which are speciﬁed as follows:

• Agent: Our agent is a central controller that can obtain the user positions and simultaneously

control the VAPs and the SBSs.

• Actions: The action of the agent at each time slot t in period n is a vector an

2,t,
U,t] that jointly considers the VAP selection and the user association. The action space

t = [Ln

· · · , un

1,t, un

t , un

A is the set of all optional actions.

• States: The state at time slot t in time period n is deﬁned as sn

t , wn
t ] that consists of:
U,t], where vn
j,t−1 and the movement
pattern M n in time period n, which is unknown to the central controller and 2) the service

t = [vn
j,t depends on vn

1) the user position vn

1,t, · · · , vn

t = [vn

state vector wn

t = [wn

1,t, · · · , wn

U,t] that implies each user whether has been successfully

served until time slot t. The state space S is the set of all possible states.

• Policy: The policy is the probability of the agent choosing each action at a given state. The

MPG algorithm uses a deep neural network parameterized by θ to map the input state to

the output action. Then, the policy can be expressed as πθ(sn

t−1). Based
on the policy πθ, an execution process in a time period n can be deﬁned as a trajectory

t ) = P (an

t−1, an

t |sn

τ n = {sn

0 , an

1 , · · · , sn

T−1, an

T }.

• Reward: The beneﬁt of choosing action an

t )|. Therefore, the reward
t ∈ τ n. Note that the
reward function is equivalent to the number of successfully served users deﬁned in (15),

t at state sn
t−1 is |W n
T
(cid:80)
t (an
|W n
t=1

of a trajectory during a time period n is F n(τ n) =

t (an
t )|, ∀an

14

that is F n(τ n) = Rn(Ln
to optimize is the average reward function of all time periods ¯F (τ n) = 1
N

j,:T ). The objective function of problem (16) that the agent aims

:T , un

N
(cid:80)
n=1

F n(τ n) =

1
N

N
(cid:80)
n=1

Rn(Ln

:T , un

j,:T ).

• Tasks : We use a task T n to refer to the reliability maximization problem max
an
t

F n(τ n) in

each time period n. A task is thus deﬁned as T n = {M n, F n(τ n)}. For each task T n, the

trajectory τ n and the corresponding reward F n(τ n) are affected by the users’ movement

pattern M n that is unknown to the agent. However, the policy πθ is shared by all tasks.

Therefore, the agent must ﬁnd the effective policy that can quickly adapt to new users’

movement patterns.

B. MPG for Optimization of Reliability

Next, we introduce the entire procedure of training the proposed MPG algorithm. Our purpose

from training MPG is to ﬁnd the optimal policy that maximizes the reliability of the THz/VLC-

enabled wireless VR network over different time periods. The MPG algorithm enables the trained

policy to quickly adapt to the time-varying users’ movement patterns. The intuition behind the

proposed MPG is that some of its parameters are task-sensitive while other parameters are

broadly applicable to all tasks. Therefore, the training process of MPG has two steps: 1) task

learning step and 2) meta-learning step. The task learning step enables the MPG to execute the

policy gradient on task-sensitive parameters so as to make rapid progress on each new task.

The meta-learning step aims to ﬁnd the broadly applicable parameters that can improve the

performance of all tasks. The proposed MPG model is trained ofﬂine, which means that the

MPG model is trained by the trajectories and the corresponding rewards sampled in historical

tasks. Using the historical trajectories and rewards, the MPG model can learn the distribution

of the tasks and thus quickly adapt to a new task. In particular, the trained fast-adaptive MPG

model only requires a few iterations of the task learning step to learn the new users’ movement

pattern so as to solve the new task. Hence, the proposed algorithm can maximize the reliability

of the studied VR network in each speciﬁc new time period. Speciﬁcally, the task learning step

and meta-learning step can be given as follows:

1) Task learning step: For each task T n, the agent ﬁrst collects K trajectories based on a given

policy πθ. The set of collected trajectories of task T n is Dn = {τ n
where τ n

K},
k is the trajectory k of task T n. To evaluate the policy πθ for maximizing the

k , · · · , τ n

1 , · · · , τ n

reliability of the VR network, we deﬁne the expected reward of the trajectories in Dn as

¯J n(θ) =

(cid:88)

Pθ(τ n)F n(τ n),

τ n∈Dn

(17)

15

T
(cid:81)
t=1

where Pθ(τ n) = P (sn
0 )
state sn

πθ(sn
t−1 transitioning to state sn

t−1, an
t ) is the probability of
t after taking action an
t , which depends on the movement
pattern M n. The goal of optimizing the policy πθ for each task T n is to maximize the

t ). P (sn

t )P (sn

t−1, an

t−1, an

t |sn

t |sn

number of successfully served users in time period n, that is

For each task T n, the policy πθ is updated using the standard gradient ascent method

¯J n(θ).

max
θ

(18)

where α is the learning rate that is equal for all tasks and the policy gradient is

˜θn = θ + α∇θ

¯J n(θ),

∇θ

¯J n(θ) =

K
(cid:88)

k=1

Pθ(τ n

k )F n(θ)∇ log Pθ(τ n

k ),

(19)

(20)

K
(cid:88)

k=1

F n(θ)∇ log Pθ(τ n

k ),

K
(cid:88)

T
(cid:88)

F n(θ)∇ log πθ(sn

t−1, an

t ).

≈

=

1
K

1
K

k=1

t=1

Finally, the agent collects K (cid:48) trajectories for each task T n using the corresponding updated
policy π ˜θn. Each trajectory set D(cid:48)n = {τ (cid:48)n
K(cid:48)} is used to optimize the broadly
applicable parameters in the next meta-learning step so as to increase the average number

1 , · · · , τ (cid:48)n

of successfully served user for all tasks.

2) Meta-learning step: The agent ﬁrst computes the expected rewards ¯J n( ˜θn) of each trajec-
tory set D(cid:48)n based on the each updated policy ˜θn. To solve the reliability maximization

problem (16), we only need to solve the following optimization problem

max
θ

1
N

N
(cid:88)

n=1

¯J n( ˜θn).

Substituting (19) into (21), we have
1
N

max
θ

N
(cid:88)

n=1

¯J n(θ + α∇θ

¯J n(θ)).

(21)

(22)

Then, to improve the average number of successfully served users for all tasks, the policy

πθ is updated by

θ ← θ +

β
N

∇θ

N
(cid:88)

n=1

¯J n(θ + α∇θ

¯J n(θ)),

(23)

16

Algorithm 1 MPG algorithm for VAP selection and user association.
1: Input: The set of VAPs V, the set of SBSs B, the user positions vn
2: Initialize: θ is initially generated randomly, wn

0 , and the transition matrix M n.

0 = [0, · · · , 0], task learning rate α, meta-learning rate β, and the number

of iterations E.

3: for i = 1 → E do

4:

5:

6:

7:

8:

9:

10:

11:

for all task T n do

1 , · · · , τ n

Collect K trajectories Dn = {τ n
Compute ∇θ ¯J n(θ) using Dn based on (20).
Compute parameters ˜θn of the adapted policy based on (19).
Collect K (cid:48) trajectories D(cid:48)n = {τ (cid:48)n

k , · · · , τ n

1 , · · · , τ (cid:48)n

K(cid:48) } using π ˜θn .

K } using πθ.

end for
Compute ¯J n( ˜θn) using each D(cid:48)n.

Update the parameters of the policy based on (23).

12: end for

where β is the learning rate for meta-learning. Here, note that the meta-learning step is
performed over the parameters θ instead of the parameters ˜θn updated in the previous task

learning step.

By iteratively running the task learning and the meta-learning step, a locally optimal policy for

determining the VAP selection and user association under different users’ movement patterns

can be obtained. The speciﬁc training process of the proposed MPG algorithm is summarized

in Algorithm 1.

The optimization problem (16) is solved once the locally optimal policy of the proposed MPG

model that used to determine the VAP selection and user association is obtained. Since the meta-

learning step tends to optimize the broadly applicable parameters for all tasks, the proposed MPG

algorithm enables the trained policy to quickly adapt to new tasks. Once the fast-adaptive VAP

selection and user association policy is trained, the central controller can quickly ﬁnd the locally

optimal policy in new time periods. In particular, for a new task with new users’ movement

pattern, using the trained policy as initialization, the central controller can further optimize the

policy for the new task by only executing a few iterations. Hence, the proposed meta learning

based algorithms can signiﬁcantly reduce the training overhead in actual VR scenarios.

C. Complexity and Overhead of MPG

Next, we analyze the computational complexity of the proposed MPG algorithm for VAP

selection and user association optimization. The complexity of the MPG algorithm depends

on the number of the policy parameter θ, which depends on the size of action space A and

the size of state space S [32]. The action space A is a set of all possible VAP selections

and user associations. The number of optional combinations of three VAPs from V VAPs is

17

V ! max(U,B)!

will be

V = V !

3!(V −3)!(max(U,B)−min(U,B))! . The state space S consists of continuous user locations vn

C 3
U and the number of SBSs B, which is Amin(U,B)

3!(V −3)!. The number of possible user-SBS association depends on the number of users
(max(U,B)−min(U,B))! . Hence, the size of A
t as
t . To ensure the ﬁnite state space,
t . In particular, the considered indoor space G is
divided into G small grids and the position of the user in each grid is represented by the center

we discretize the continuous user positions vn

t and newly served users W n

well as discrete service state wn

max(U,B) =

max(U,B)!

of the grid. The size of service state space wn
t

is U . Then, the size of state space S is GU .

Therefore, the computational complexity of the proposed MPG algorithm can be given as

(cid:40)

O

GU

V ! max(U, B)!
3!(V −3)! (max(U, B)−min(U, B))!

L−1
(cid:89)

l=2

Hl

(cid:41)

(cid:40)

=O

U V 3

max(U, B)!
(max(U, B)−min(U, B))!

(cid:41)

Hl

,

L−1
(cid:89)

l=2

(24)

where Hl is the number of the neurons in layer l of the deep neural network used to train the pol-

icy. From (24) we can see that, due to the combinatorial user associations (i.e.,

max(U,B)!
(max(U,B)−min(U,B))! ),
the complexity of the MPG algorithm becomes unacceptably large as the number of users U

increases. To this end, we proposed a dual method based MPG (D-MPG) solution in which

an action only determines VAP selection. Given the VAP selection, the user association can be

determined by dual method thus reducing the size of action space of the original MPG algorithm.

Here, we need to note that the MPG and D-MPG algorithms have their own advantages and

drawbacks. MPG can converge to a local optimal solution but D-MPG cannot. However, D-MPG

has a faster convergence compared to the MPG. Therefore, one must select the solutions (MPG

or D-MPG) based on the implementation requirements such as training time or performance.

Next, we introduce the D-MPG algorithm.

IV. DUAL METHOD BASED META-LEARNING

The components of the D-MPG algorithm are deﬁned as follows:

• Agent: The agent of the D-MPG is also the central controller.

• Actions: The action of the agent at each time slot t in period n consider the subset of VAPs

to select, which is a(cid:48)n

t = Ln

t . The action space is A(cid:48).

18

• States: The state at time slot t in time period n is sn

t ] and the state space is S.
t depends on the user association.
The determination of user association using dual method will be speciﬁed in Section IV-A.

t , the service state vector wn

Given the VAP selection a(cid:48)n

t = [vn

t , wn

• Policy: The policy πθ(cid:48)(sn

t ) is used to build the relationship between the input state
and output action, where θ(cid:48) is the parameter of the deep neural network used to learn the

t−1, an

policy. The trajectory during a time period n based on the policy πθ(cid:48) can be given as

τ n = {sn

0 , a(cid:48)n

1 , · · · , sn

T−1, a(cid:48)n

T }.

• Reward: The reward of a trajectory in time period n is F n(τ n) =

T
(cid:80)
t=1

(cid:12)
(cid:12)W n

t (a(cid:48)n

j,t)(cid:12)
t , u∗n

(cid:12) =

:T , u∗n

t ∈ τ n, where u∗n

Rn(Ln
action a(cid:48)n
¯F (τ n) = 1
N

j,:T ), ∀a(cid:48)n
j,t is the optimal user association based on the chosen
t . The average reward function of all time periods that the agent aims to optimize is
j,:T ), which is also the objective function of the
reliability maximization problem (16). Here, we see that, to maximize the average reward
function ¯F (τ n), we need to determine the optimal user association u∗n

F n(τ n) = 1
N

j,t at each time slot t.

:T , u∗n

N
(cid:80)
n=1

N
(cid:80)
n=1

Rn(Ln

• Tasks : Task T n is the reliability maximization problem in each time period n.

From the above deﬁnitions, we can see that the only difference between the MPG algorithm

and the D-MPG algorithm is action. In particular, an action of the original MPG jointly deter-

mines VAP selection and user association while an action of the D-MPG determines only VAP

selection. Therefore, the D-MPG can signiﬁcantly decrease the action space thus improving

training complexity and convergence speed. Next, we will specify the dual method for user-SBS

association optimization.

A. Optimization of User-SBS Association and Reliability

Once VAPs are selected, the user-SBS association can be determined based on the user

positions to avoid blockages of THz links and meet the transmission delay constraints by solving

the optimization problem deﬁned in (16). Substituting (15) into (16), the user-SBS association

and reliability maximization problem with ﬁxed VAP selection Ln

t can be expressed as

max
un
j,t

s.t.

N
(cid:88)

T
(cid:88)

n=1

t=1

|W n

t (a(cid:48)n

t , un

j,t)|,

B
(cid:88)

i=1

U
(cid:88)

j=1

un
ij,t

(cid:54) 1, ∀j ∈ U n
t ,

un
ij,t

(cid:54) 1, ∀i ∈ B,

ij,t ∈ {0, 1}, ∀i ∈ B, ∀j ∈ U n
un
t .

19

(25)

(25a)

(25b)

(25c)

From (14), we can see that users can experience immersive VR services as long as each one

of them is successfully served once in each time period. This means that serving a VR user

multiple times in a period cannot improve the reliability of the studied VR network. Therefore,

a problem equivalent to (25) is

max
un
j,t

N
(cid:88)

T
(cid:88)

n=1

t=1

|W n

t (a(cid:48)n

t , un

j,t)|,

s.t.

(25a) − (25c),

T
(cid:88)

B
(cid:88)

t=1

i=1

un
ij,t

(cid:54) 1, ∀j ∈ U n
t ,

(26)

(26a)

(26b)

where (26b) indicates that each VR user can be served at most once in a time period. Based on

(26b), the newly served user at each time slot deﬁned in (14) can be simpliﬁed to

W n

t (a(cid:48)n

t,un

j,t(a(cid:48)n

j,t)= {j|wn
(26b)
==== {j|wn

t,un

j,t) = 1, wn

j,t−1(a(cid:48)n

t−1,un

j,t−1) = 0},

t,un

j,t) = 1}.

j,t(a(cid:48)n
j,t−1(a(cid:48)n

This is because wn

j,t(a(cid:48)n

t,un

j,t) = 1 and wn

t−1,un

j,t−1) = 0 must always be satisﬁed simultane-

ously with the additional service constraint (26b). Then, substituting (13) into (27), we have

|W n

t (a(cid:48)n

t,un

j,t)| = (cid:12)

j,t(a(cid:48)n

t,un

j,t) = 1}(cid:12)
(cid:12) ,

(cid:12){j|wn
U
(cid:88)

(cid:0)(pn

=

j,t(a(cid:48)n

t)hn

j,t(un

j,t))∨wn

j,t−1(a(cid:48)n

t−1, un

j,t−1)(cid:1),

j=1

(26b)
====

U
(cid:88)

j=1

j,t(a(cid:48)n
pn

t )hn

j,t(un

j,t).

(27)

(28)

20

Here, due to (26b), the service state wn

we have (pn
user at each time slot t given the selected VAPs a(cid:48)n
t

j,t−1) = 0 at time slot t − 1 must be satisﬁed if
j,t)) = 1 at time slot t. Hence, (28) that represents the number of served
is obtained.

j,t−1(Ln

j,t(a(cid:48)n

t−1,un

j,t(un

t)hn

Since optimizing the user association in each time period n is independent, problem (26)

can be decoupled into multiple subproblems. In addition, due to the binary variable un

j,t, the
optimization problem in (26) is hard to solve. Hence, we temporarily adopt the fractional user

association relaxation, where association variable un

proved in [23], although the feasible region of un

j,t can take on any real value in [0, 1]. As
j,t is relaxed to be continuous, the optimal
solution of the relaxed problem also meets the integer constraint. Therefore, the relaxation does

not cause any loss of optimality to the ﬁnal solution of problem (26). Then, for each time period

n, the reliability maximization subproblem can be formulated as follows:

max
un
j,t

s.t.

T
(cid:88)

U
(cid:88)

t=1

j=1

j,t(a(cid:48)n
pn

t )hn

j,t(un

j,t),

B
(cid:88)

i=1
U (cid:48)
(cid:88)

j=1

un
ij,t

(cid:54) 1, ∀j ∈ U (cid:48)n
t ,

un
ij,t

(cid:54) 1, ∀i ∈ B,

T
(cid:88)

B
(cid:88)

t=1

i=1

un
ij,t

(cid:54) 1, ∀j ∈ U (cid:48)n
t ,

ij,t ∈ [0, 1], ∀i ∈ B, ∀j ∈ U (cid:48)n
un
t ,

ij,t = 0, ∀i ∈ B, ∀j ∈ U n
un

t \U (cid:48)n
t ,

(29)

(29a)

(29b)

(29c)

(29d)

(29e)

j,t(a(cid:48)n

where U (cid:48)n

t = {j|pn

set of VAPs Ln

t ) = 1} represents the set of users that are successfully localized by the
t . Note
j,t is relaxed. Here, we ignore the
blockages of THz links caused by the users that are not successfully localized by the set of

t at time slot t in time period n and U (cid:48) is the number of users in U (cid:48)n

that problem (29) becomes convex after the binary variable un

VAPs Ln

t (i.e., j ∈ U n

t \U (cid:48)n
t ).

Due to constraint (29c), all time slots are coupled in problem (29). To simplify problem (29),

we use the dual method to decouple problem (29) into multiple subproblems. The dual problem

of (29) can be given by

max
un
j,t

T
(cid:88)

U
(cid:88)

t=1

j=1

j,t(a(cid:48)n
pn

t )hn

j,t(un

j,t)+

U
(cid:88)

j=1

(cid:32)

λj

1 −

(cid:33)

un
ij,t

T
(cid:88)

B
(cid:88)

t=1

i=1

B
(cid:88)

s.t.

un
ij,t

(cid:54) 1, ∀j ∈ U (cid:48)n
t ,

i=1
(cid:88)

j∈U (cid:48)n
t

un
ij,t

(cid:54) 1, ∀i ∈ B,

ij,t ∈ {0, 1}, ∀i ∈ B, ∀j ∈ U (cid:48)n
un
t ,

ij,t = 0, ∀i ∈ B, ∀j /∈ U (cid:48)n
un
t ,

21

(30)

(30a)

(30b)

(30c)

(30d)

where λj is the dual variable associated with constraint (29c). According to [33], there is no gap

between convex problem (29) and its dual problem (30). Hence, the solution of problem (30) is

the same as the solution of problem (29) and is also the solution of the original problem (26).

Since both the objective function and constraints in (30) can be decoupled, the reliability

maximization subproblem at time slot t in period n can be given by
(cid:33)

(cid:32)

max
un
j,t

s.t.

U
(cid:88)

j,t(a(cid:48)n
pn

t )hn

j,t(un

j,t) − λj

B
(cid:88)

j=1

B
(cid:88)

un
ij,t

(cid:54) 1, ∀j ∈ U (cid:48)n
t ,

i=1

i=1
(cid:88)

j∈U (cid:48)n
t

un
ij,t

(cid:54) 1, ∀i ∈ B,

ij,t ∈ {0, 1}, ∀i ∈ B, ∀j ∈ U (cid:48)n
un
t ,

ij,t = 0, ∀i ∈ B, ∀j /∈ U (cid:48)n
un
t ,

un
ij,t

,

(31)

(31a)

(31b)

(31c)

(31d)

which can be solved by the Hungarian algorithm [34]. The dual variable λj can be updated by

using the gradient method [33]. The update procedure is given by

(cid:34)

(cid:32)

λj =

λj − φ

1 −

T
(cid:88)

B
(cid:88)

(cid:33)(cid:35)

un
ij,t

,

∀j ∈ U,

(32)

i=1
where φ > 0 is a dynamically chosen step-size sequence and [x]+ = max{x, 0}. The speciﬁc

t=1

process of using the proposed D-MPG algorithm to determine the VAP selection and user

association is summarized in Algorithm 2.

Once the user-SBS association is determined based on the user positions measured by the

selected VAPs, the states and reward of the D-MPG algorithm can be obtained. Then, the D-MPG

Algorithm 2 Dual method based algorithm for VAP selection and user association.
1: Input: The set of VAPs V, the set of SBSs B, the user positions vn
2: Initialize: θ(cid:48) is initially generated randomly, wn

0 , and the transition matrix M n.

0 = [0, · · · , 0], task learning rate α, meta-learning rate β, the number of

iterations E, the dual variable λj, and step size φ.

3: for i = 1 → E do

22

4:

5:

6:

7:

8:

9:

for all task T n do

for all time slot t do
Choose a(cid:48)n
Determine un

t using πθ(cid:48) .

j,t based on the solution of (25) using the dual method.

end for
Collect K trajectories Dn = {τ n

1 , · · · , τ n

k , · · · , τ n

K }.

10:

11:

end for
Update the parameters θ(cid:48) of the policy as done in Algorithm 1.

12: end for

algorithm can train the VAP selection policy ofﬂine using the trajectories and the corresponding

rewards sampled in historical tasks according to the training process deﬁned in Section III-B.

Here, we need to point out that the users that are not successfully localized may block the THz

links that are established according to the user association obtained by the D-MPG algorithm thus

damaging the reliability of the THz/VLC-enabled VR network. This is because, at each time slot,

the user association optimization problem (25) can only consider the users who is successfully
localized using the selected VAPs a(cid:48)n

t . However, compared to the original MPG algorithm, the
proposed D-MPG algorithm can control the tradeoff between algorithm processing time or space

and reliability gain achieved by the algorithm.

B. Complexity and Overhead of the Proposed Algorithms

The complexity of the D-MPG algorithm lies in training the policy for VAP selection and

optimizing the user association by the dual method. The complexity for training the VAP selection

policy depends on the size of action space A(cid:48) and the size of state space S. Since an action of

the proposed D-MPG algorithm only determines VAP selection, the size of A(cid:48) is C 3

3!(V −3)!.
As analyzed in Section III-C, the size of S is still GU . Given the VAP selection, the complexity

V = V !

of optimizing user association lies in solving the dual problem of user association optimization

problem using Hungarian algorithm whose worst-case complexity is U 2B. To determine the user

association for N time slot in a time period, the complexity is N U 2B. Therefore, the complexity

23

of the D-MPG algorithm can be given as

(cid:40)

O

GV !U
3!(V − 3)!

L−1
(cid:89)

l=2

(cid:41)

(cid:40)

Hl + N U 2B

= O

U V 3

L−1
(cid:89)

l=2

(cid:41)

Hl + N U 2B

.

(33)

Compared with (24), the complexity of solving the proposed reliability maximization problem

is signiﬁcantly reduced.

The proposed MPG and D-MPG models are trained ofﬂine, which means that the models are

trained during the idle time of the central controller using the trajectories and the corresponding

rewards sampled in historical tasks. Hence, we ignored the time and energy consumption of the

training process of the proposed algorithms. In actual VR applications, we ﬁrst train the proposed

model ofﬂine. The trained model is considered as an initialization model for new learning tasks

and can be directly implemented without training. Meanwhile, when implementing a new task,

the proposed meta learning algorithm can further improve its pre-trained initialization model to

achieve better reliability of the studied network using a small number of iterations.

V. SIMULATION RESULTS AND ANALYSIS

For our simulations, a 6 m × 6 m square room is considered with D = 7 VAPs and B = 7

SBSs evenly distributed at a ﬁxed hight of Z = 3 m. U = 20 wireless VR users are initially

randomly distributed in the room and move according to users’ movement patterns M n generated

based on a given distribution in each time period n. For comparison purposes, we consider the

trust region policy optimization algorithm (TRPO) as the baseline scheme. TRPO is a widely

used RL algorithm that has been proven to always converge to the optimal or local optimal

solution in a static environment [35]. All statistical results are averaged over a large number of

independent runs. Other parameters are listed in Table I [25], [26].

Fig. 2 shows how the reliability of a THz/VLC-enabled VR network changes as the number

of iterations of the MPG algorithm varies. Here, a VR scenario with 8 users is considered for the

proposed MPG algorithm due to the huge computational overhead. The MPG model is trained

for N = 20 tasks and N = 50 tasks to obtain a fast-adaptive policy for VAP selection and user

association, respectively. In Fig. 2, we can see that the proposed MPG algorithm can converge

and effectively solve the reliability maximization problem (16). This is due to the fact that the

proposed MPG algorithm can analyze the distribution of the dynamic users’ movement patterns

so as to update the policy to increase the average number of the successfully served users for all

24

TABLE I: System parameters

Parameters

Ψ 1
2
f

ιT

ϕT
H
ϕR
H

Value

60◦

1.05 THz

0.1

10◦

33◦

Parameters

P

S

ιR

ϕT
V
ϕR
V

Value

5 dBm

20 Mbit

0.1

10◦

33◦

KBTe

−174 dBm/Hz

K(f )

0.07512 m−1

K

α

50

0.1

K (cid:48)

β

10

0.01

Fig. 2: The reliability of the THz/VLC-enabled VR network as the number of iterations of the

MPG algorithm varies.

tasks. Fig. 2 also shows that the training process of N = 20 tasks is more stable and converges

faster than the training process of N = 50 tasks. This is because fewer tasks are more likely to

ﬁnd update gradients that work for most of the tasks in the meta-learning step.

Fig. 3 shows the convergence of the D-MPG algorithm in a network with 20 users. In Fig. 3

we can also see that, using the D-MPG algorithm, N = 20 tasks require approximately 30% the

number of iterations needed to reach convergence compared for the case with N = 50 tasks.

This is because the D-MPG algorithm needs to analyze the users’ movement patterns of all tasks

so as to train the locally optimal VAP selection policy.

Fig. 4 shows the training reliability for eight VR users resulting from all of the considered

RL algorithms. In Fig. 4, we can see that, compared with the baseline TRPO algorithm that

0200400600800Number of MPG iterations345678Training reliability for eight usersN=20N=5025

Fig. 3: The convergence of the D-MPG algorithm in a network with 20 users.

Fig. 4: The training process of all considered RL algorithms.

cannot converge in presence of dynamic users’ movement patterns, the proposed MPG and D-

MPG algorithm can reach convergence after approximately 400 and 200 iterations, respectively.

Meanwhile, compared to the TRPO algorithm, the proposed MPG algorithm and D-MPG algo-

rithm can achieve 33.3% and 29.8% gains in terms of reliability that is averaged over the last

400 iterations. This stems from the fact that the proposed MPG and D-MPG algorithms can

build a relationship between the dynamic users’ movement patterns by meta-learning step. Fig.

4 also shows that the reliability of the studied VR network achieved by the MPG algorithm is

2.7% higher than the reliability achieved by the D-MPG algorithm. This is because the MPG

algorithm determines the user-SBS associations based on the learned users’ movement patterns

and hence, it optimizes user-SBS association while considering all VR user locations. However,

0100200300400Number of DMPG iterations101214161820Training reliability for twenty usersN=20N=500200400600800Number of iterations345678Training reliability for eight usersMPGD-MPGTRPO26

Fig. 5: The training time of the proposed MPG algorithm and DMPG algorithm.

the D-MPG algorithm optimizes the user-SBS associations for the successfully localized users

without considering the users that are not successfully localized. Fig. 4 also shows that, compared

with the MPG algorithm, the D-MPG algorithm converges faster. This is due to the fact that the

policy of the D-MPG algorithm only needs to learn how to select VAPs, while the policy of the

MPG algorithm needs to learn how to determine the VAP selection and the user association.

In Fig. 5, we show how the training time of the proposed MPG algorithm and D-MPG

algorithm will change as the number of users varies. From Fig. 5 we can see that the D-MPG

algorithm for 8 users can yield up to 88.7% reduction in terms of training time compared with the

MPG algorithm. This gain stems from the fact that the use of the dual method to determine the

user association can signiﬁcantly reduce the computational complexity of the D-MPG algorithm.

In Fig. 5, we can also ﬁnd that, as the number of VR users increases, the training time of

the D-MPG algorithm increases. This is because the complexity of the D-MPG algorithm is a

function of the number of VR users as analyzed in Section IV-B.

Fig. 6 shows how the average reliability per user changes as the number of users varies. In

Fig. 6, the number of users varies from 4 to 8 for the MPG algorithm and the baseline TRPO

algorithm and the number of users varies from 4 to 20 for the D-MPG algorithm. From Fig. 6

we can see that the average reliability per user of all the considered algorithms decreases as the

number of users increases. This is due to the fact that, as the number of users in a given area

increases, the probability of each user blocking the VLC or THz links increases. In addition, B

SBSs can serve a limited number of users in T time slots (at most BT users), hence the average

reliability per user should decrease as the number of users increases. Fig. 6 also shows that the

0100200300400500600700Time of training (minutes)4681012141618Training reliability8 users using MPG8 users using D-MPG12 users using D-MPG16 users using D-MPG20 users using D-MPG200 iterations400 iterations27

Fig. 6: The average reliability per user as the number of users varies.

Fig. 7: The success rate of the user positioning as the number of users varies.

proposed MPG algorithm and D-MPG algorithm can respectively yield up to 17.1% and 14.5%

improvements in terms of the average reliability per user compared to the TRPO algorithm.

This is because the proposed MPG and D-MPG algorithms can analyze and quickly adapt the

dynamic users’ movement patterns so as to determine the VAP selection and user association that

can maximize the reliability of the studied VR network. In Fig. 6 we can also observe that, even

in a dense environment (36 m2 with 20 users), the proposed D-MPG algorithm can guarantee an

average reliability per user of more than 0.9. This indicates that the studied THz/VLC network

can provide reliable wireless VR services using the proposed algorithms.

Fig. 7 shows how the number of users that can be successfully localized changes as the total

number of users varies. In Fig. 7, a round-robin scheduling policy for VAP selection is considered

28

Fig. 8: The average reliability per user as the number of SBSs varies (V = 7).

as a baseline. From Fig. 7, we can see that the success rate of user positioning decreases as

the number of users increases. This is due to the fact that, as the number of users in a given

area increases, the probability of the VLC links being blocked by other users increases. Fig. 7

also shows that the proposed MPG algorithm and D-MPG algorithm can respectively yield up

to 5.6% and 23.9% improvements in terms of the success rate of the user positioning compared

to the baseline. The reason is that the proposed algorithms can analyze the users’ movement

patterns and thus optimizing the VAP selection policy to avoid blockages over VLC links.

Fig. 8 shows how the average reliability per user changes as the number of SBSs varies in

a room with 7 VAPs. From this ﬁgure, we observe that, as the number of SBSs increases, the

average reliability per user of all algorithms increases since more SBSs can increase the access

probability of VR users. Fig. 8 also shows that the MPG and D-MPG algorithms can achieve up to

26.8% and 21.9% gains in terms of average reliability per user compared to the TRPO algorithm,

respectively. Meanwhile, in Fig. 8, as the number of SBSs increases, the average reliability per

user resulting from the proposed algorithms increases more signiﬁcantly than that of the TRPO

algorithm. This is due to the fact that the proposed algorithms determine the actions based on

the analysis of the users’ movement patterns, thus enabling the SBSs to cooperatively provide

services to VR users. In consequence, the reliability of the THz/VLC-enabled VR network is

signiﬁcantly improved using the proposed algorithms.

Fig. 9 shows how the average reliability per user changes as the number of VAPs varies

in a room with 7 SBSs. From Fig. 9, we can see that, as the number of VAPs increases, the

average reliability per user of all algorithms increases. The reason is that, as the number of

3456789Number of SBSs0.600.650.700.750.800.850.900.95Average reliability per userMPGD-MPGTRPO29

Fig. 9: The average reliability per user as the number of SBSs varies (B = 7).

Fig. 10: Test adaptability on new tasks.

VAPs increases, the central controller has more VAP options for localization so as to avoid

blockages of VLC links. Fig. 9 also shows that the MPG and D-MPG algorithms can achieve

up to 29.7% and 21.2% gains in terms of average reliability per user compared to the TRPO

algorithm, respectively. This is due to the fact the proposed algorithms can adapt to the dynamic

users’ movement patterns and select the appropriate VAPs for user localization.

Fig. 10 shows the adaptability of all the trained models testing for new tasks. In Fig. 10, the

line and shadow are the mean and standard deviation computed over 5 random generated new

tasks and all the models trained by old tasks are used as the initial models for the new tasks.

From Fig. 10, we observe that, for new tasks, the proposed MPG and D-MPG algorithms achieve

better performance at the beginning of the test process than the TRPO model. This is because the

policies trained by our proposed algorithms learned the knowledge useful for all tasks. Fig. 10

345678Number of VAPs0.650.700.750.800.850.900.95Average reliability per userMPGD-MPGTRPO30

Fig. 11: Visualization of using MPG algorithm for a VR scenario with eight users.

Fig. 12: Visualization of using D-MPG algorithm for a VR scenario with sixteen users.

also shows that the trained MPG and D-MPG models require approximately 30 and 20 iterations

of further training to reach convergence for a new task, respectively, which are 81.2% and 87.5%

less than the trained TRPO algorithm that requires about 160 iterations to reach convergence

for a new task. Meanwhile, compared with the training process in Fig. 4, the test process of

the MPG algorithm and D-MPG algorithm yield up to 88% and 86.7% reductions in terms of

the number of iterations to reach convergence, respectively. This demonstrates that the proposed

MPG and D-MPG algorithms ﬁnd the locally optimal policies that can quickly adapt to new

tasks with new users’ movement patterns. In Fig. 10, we can also see that the proposed MPG

algorithm and D-MPG algorithm achieves up to 13.2% and 10.3% gains in terms of the reliability

compared with the TRPO algorithm, respectively. This is because the alternative iteration of the

task learning step and the meta-learning step can ﬁnd the broadly applicable parameters that can

improve the performance of all tasks.

In Figs. 11 and 12, we show examples of how the proposed MPG and D-MPG algorithms can

optimize the reliability of the THz/VLC-enabled VR network, respectively. In the examples, 7

31

VAPs and 7 SBSs are deployed in a 6 m × 6 m square room to serve VR users. From Figs. 11

and 12, we can see that the VAP selection and the user association determined by the proposed

algorithms can effectively serve the VR users during a time period and guarantee the network

reliability. This is because that the MPG and D-MPG algorithms have already learned the users’

movement pattern during the sampling time period. Moreover, the proposed algorithms aim to

serve as many unserved users as possible so as to maximize the reward function. Fig. 11 shows

the VAP selection and the user-SBS association which result in the maximum reliability of

randomly distributed 8 users. In Figs. 11(b) and 11(c) we can see that the unsuccessful THz

transmission using the MPG algorithm is caused by the fact that the served user is not successfully

localized and thus cannot establish a THz link. Fig. 12 shows the VAP selection and the user-

SBS association obtained by the D-MPG algorithm that can serve 16 users randomly distributed

in the considered room. From Fig. 12(c), we can see that a user who cannot be localized blocks

the THz link established according to the D-MPG algorithm. In Fig. 12 we can also see that,

compared with the user association determined by the MPG algorithm that all the SBSs need to

serve users at each time slot as shown in Fig. 11, the D-MPG algorithm only uses the necessary

SBSs to provide transmission services to the unsuccessfully served users. This is due to the

fact that the D-MPG algorithm uses Hungarian algorithm to solve the dual problem of the user

association optimization problem for those successfully localized users.

VI. CONCLUSION

In this paper, we have developed a novel framework for maximizing reliability of THz/VLC-

enabled wireless VR networks. To this end, we have formulated an optimization problem that

jointly considers the user mobility, blockages of both THz and VLC links, VAP selection, and

user association. To solve this problem, we have developed a novel MPG algorithm based

on meta-learning framework, which can effectively ﬁnd the policy of VAP selection and user

association for maximizing reliability. The proposed MPG algorithm enables the trained policy

to quickly adapt to new users’ movement patterns. Then, a D-MPG algorithm is proposed that

use dual method to assist the MPG algorithm to determine user association so as to reduce the

computational complexity of the MPG algorithm. Simulation results have shown that, compared

with the traditional RL algorithm, the proposed algorithms can achieve better performance and

faster convergence speed. Simulation results also show that the proposed D-MPG algorithm can

32

achieve the tradeoff between the algorithm processing time and the reliability gain. In our future

works, the use of massive MIMO and the handover overhead can be considered. Meanwhile, the

accuracy of the VLC-based indoor positioning and the deployment layout of VAPs and SBSs can

be optimized to further improve the reliability of the studied VR network. We can also consider

the co-existence between VR users and cellular mobile users.

REFERENCES

[1] Y. Wang, M. Chen, Z. Yang, W. Saad, T. Luo, S. Cui, and H. V. Poor, “Meta-reinforcement learning for immersive virtual
reality over THz/VLC wireless networks,” in Proc. IEEE International Conference on Communications, Quebec, Canada,
June 2021.

[2] F. Hu, Y. Deng, W. Saad, M. Bennis, and A. H. Aghvami, “Cellular-connected wireless virtual reality: Requirements,

challenges, and solutions,” IEEE Communications Magazine, vol. 58, no. 5, pp. 105–111, May 2020.

[3] Huawei Technologies Co., Ltd., “Huawei iLab VR technology white paper. Cloud VR bearer networks,” 2017, Available:
https://www-ﬁle.huawei.com/-/media/corporate/pdf/ilab/cloud vr oriented bearer network white paper en v2.pdf.
[4] H. Zhang, H. Zhang, W. Liu, K. Long, J. Dong, and V. C. M. Leung, “Energy efﬁcient user clustering, hybrid precoding
and power optimization in terahertz MIMO-NOMA systems,” IEEE Journal on Selected Areas in Communications, vol.
38, no. 9, pp. 2074–2085, Sept. 2020.

[5] C. Chaccour, M. N. Soorki, W. Saad, M. Bennis, and P. Popovski, “Can terahertz provide high-rate reliable low latency

communications for wireless VR?,” 2020, Available: https://arxiv.org/abs/2005.00536.

[6] T. Dang and M. Peng, “Joint radio communication, caching, and computing design for mobile virtual reality delivery in
fog radio access networks,” IEEE Journal on Selected Areas in Communications, vol. 37, no. 7, pp. 1594–1607, July 2019.
[7] Y. Sun, Z. Chen, M. Tao, and H. Liu, “Communications, caching, and computing for mobile virtual reality: Modeling and

tradeoff,” IEEE Transactions on Communications, vol. 67, no. 11, pp. 7573–7586, Nov. 2019.

[8] X. Liu, X. Li, and Y. Deng, “Learning-based prediction and proactive uplink retransmission for wireless virtual reality

network,” IEEE Transactions on Vehicular Technology, vol. 70, no. 10, pp. 10723–10734, Oct. 2021.

[9] C. Perfecto, M. S. Elbamby, J. D. Ser, and M. Bennis, “Taming the latency in multi-user VR 360◦: A QoE-aware deep
learning-aided multicast framework,” IEEE Transactions on Communications, vol. 68, no. 4, pp. 2491–2508, April 2020.
[10] M. S. Elbamby, C. Perfecto, M. Bennis, and K. Doppler, “Toward low-latency and ultra-reliable virtual reality,” IEEE

Network, vol. 32, no. 2, pp. 78–84, April 2018.

[11] Y. Liu, J. Liu, A. Argyriou, and S. Ci, “MEC-assisted panoramic VR video streaming over millimeter wave mobile

networks,” IEEE Transactions on Multimedia, vol. 21, no. 5, pp. 1302–1316, May 2019.

[12] C. Chaccour, M. N. Soorki, W. Saad, M. Bennis, and P. Popovski, “Risk-based optimization of virtual reality over terahertz
reconﬁgurable intelligent surfaces,” in Proc. IEEE International Conference on Communications, Dublin, Ireland, June
2020, pp. 1–6.

[13] M. Chen, O. Semiari, W. Saad, X. Liu, and C. Yin, “Federated echo state learning for minimizing breaks in presence in
wireless virtual reality networks,” IEEE Transactions on Wireless Communications, vol. 19, no. 1, pp. 177–191, Jan. 2020.
[14] M. Kok, J. D. Hol, and T. B. Sch¨on, “Indoor positioning using ultrawideband and inertial measurements,” IEEE Transactions

on Vehicular Technology, vol. 64, no. 4, pp. 1293–1303, April 2015.

[15] W. Liu, Z. Li, S. Sun, R. Malekian, Z. Ma, and W. Li, “Improving positioning accuracy of the mobile laser scanning in
GPS-denied environments: An experimental case study,” IEEE Sensors Journal, vol. 19, no. 22, pp. 10753–10763, Nov.
2019.

[16] S. Fan, Y. Wu, C. Han, and X. Wang, “SIABR: A structured intra-attention bidirectional recurrent deep learning method
for ultra-accurate terahertz indoor localization,” IEEE Journal on Selected Areas in Communications, vol. 39, no. 7, pp.
2226–2240, July 2021.

[17] Y. Zhuang, L. Hua, L. Qi, J. Yang, P. Cao, Y. Cao, Y. Wu, J. Thompson, and H. Haas, “A survey of positioning systems
using visible LED lights,” IEEE Communications Surveys & Tutorials, vol. 20, no. 3, pp. 1963–1988, Feb. 2018.
[18] H. Li, H. Huang, Y. Xu, Z. Wei, S. Yuan, P. Lin, H. Wu, W. Lei, J. Fang, and Z. Chen, “A fast and high-accuracy real-time
visible light positioning system based on single LED lamp with a beacon,” IEEE Photonics Journal, vol. 12, no. 6, pp.
1–12, Dec. 2020.

[19] J. Xu, C. Gong, and Z. Xu, “Experimental indoor visible light positioning systems with centimeter accuracy based on a

commercial smartphone camera,” IEEE Photonics Journal, vol. 10, no. 6, pp. 1–17, Dec. 2018.

[20] Y. Wu, X. Liu, W. Guan, B. Chen, X. Chen, and C. Xie, “High-speed 3D indoor localization system based on visible
light communication using differential evolution algorithm,” Optics Communications, vol. 424, pp. 177–189, Oct. 2018.
[21] A. S¸ ahin, Y. S. Ero˘glu, ˙I. G¨uvenc¸, N. Pala, and M. Y¨uksel, “Hybrid 3-D localization for visible light communication

systems,” Journal of Lightwave Technology, vol. 33, no. 22, pp. 4589–4599, Nov. 2015.

33

[22] Y. Yang, Z. Zeng, J. Cheng, C. Guo, and C. Feng, “A relay-assisted OFDM system for VLC uplink transmission,” IEEE

Transactions on Communications, vol. 67, no. 9, pp. 6268–6281, Sep. 2019.

[23] Y. Wang, M. Chen, Z. Yang, T. Luo, and W. Saad, “Deep learning for optimal deployment of UAVs with visible light

communications,” IEEE Transactions on Wireless Communications, vol. 19, no. 11, pp. 7049–7063, Nov. 2020.

[24] M. F. ¨Ozkoc¸, A. Koutsaftis, R. Kumar, P. Liu, and S. S. Panwar, “The impact of multi-connectivity and handover constraints
on millimeter wave and terahertz cellular networks,” IEEE Journal on Selected Areas in Communications, vol. 39, no. 6,
pp. 1833–1853, June 2021.

[25] C. Lin and G. Y. Li, “Adaptive beamforming with resource allocation for distance-aware multi-user indoor terahertz

communications,” IEEE Transactions on Communications, vol. 63, no. 8, pp. 2985–2995, Aug. 2015.

[26] V. Petrov, D. Moltchanov, and Y. Koucheryavy, “Interference and SINR in dense terahertz networks,” in Proc. IEEE

Vehicular Technology Conference, Boston, MA, Sept. 2015, pp. 1–5.

[27] X. Wang, L. Duan, and R. Zhang, “User-initiated data plan trading via a personal hotspot market,” IEEE Transactions on

Wireless Communications, vol. 15, no. 11, pp. 7885–7898, Nov. 2016.

[28] S. Wang, M. Chen, X. Liu, C. Yin, S. Cui, and H. V. Poor, “A machine learning approach for task and resource allocation

in mobile edge computing based networks,” IEEE Internet of Things Journal, vol. 8, no. 3, pp. 1358–1372, Feb. 2021.

[29] P. S. Thomas and E. Brunskill, “Policy gradient methods for reinforcement learning with function approximation and

action-dependent baselines,” 2017, Available: https://arxiv.org/abs/1706.06643.

[30] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for fast adaptation of deep networks,” 2017, Available:

https://arxiv.org/abs/1703.03400.

[31] Y. Hu, M. Chen, W. Saad, H. V. Poor, and S. Cui, “Distributed multi-agent meta learning for trajectory design in wireless
drone networks,” IEEE Journal on Selected Areas in Communications, vol. 39, no. 10, pp. 3177–3192, Oct. 2021.
[32] M. Chen, D. G¨und¨uz, K. Huang, W. Saad, M. Bennis, A. V. Feljan, and H. V. Poor, “Distributed learning in wireless
networks: Recent progress and future challenges,” IEEE Journal on Selected Areas in Communications, vol. 39, no. 12,
pp. 3579–3605, Dec. 2021.

[33] Dimitri P Bertsekas, Convex Optimization Theory, Athena Scientiﬁc Belmont, 2009.
[34] M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint learning and communications framework for federated
learning over wireless networks,” IEEE Transactions on Wireless Communications, vol. 20, no. 1, pp. 269–283, Jan. 2021.
[35] J. Schulman, S. Levine, P.Moritz, M. Jordan, and P. Abbeel, “Trust region policy optimization,” in Proc. International

Conference on Machine Learning, Lille, France, July 2015, pp. 1889–1897.

