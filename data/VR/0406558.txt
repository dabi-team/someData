Astronomy&Astrophysicsmanuscript no. msrev2
(DOI: will be inserted by hand later)

November 17, 2018

4
0
0
2

n
u
J

4
2

1
v
8
5
5
6
0
4
0
/
h
p
-
o
r
t
s
a
:
v
i
X
r
a

QSO size ratios from multiband monitoring of

a microlensing high–magniﬁcation event

L. J. Goicoechea1, V. Shalyapin1,2,3, J. Gonz´alez–Cadelo1, A. Oscoz4

1 Departamento

de F´ısica Moderna, Universidad

de Cantabria, Avda.

de

Los Castros

s/n, E–39005 Santander, Spain;

e-mail: goicol@unican.es,

juan.gonzalezc@alumnos.unican.es
2 Institute of Radio Astronomy, NAS of Ukraine, 4 Krasnoznamennaya St., 61002,

Kharkov, Ukraine
3 O. Ya. Usikov Institute of Radiophysics and Electronics, NAS of Ukraine, 12 Academician

Proskura St., 61085, Kharkov, Ukraine; e-mail: vshal@ire.kharkov.ua
4 Instituto de Astrof´ısica de Canarias, C/ V´ıa L´actea s/n, E–38200 La Laguna, Spain;

e-mail: aoscoz@ll.iac.es

Submitted: January 2004

Abstract. We introduce a new scheme to study the nature of the central engine in a lensed

QSO. The compact emission regions could have different sizes in different optical wave-

lengths, and our framework permits to obtain the source size ratios when a microlensing spe-

cial high–magniﬁcation event (e.g., a caustic crossing event, a two–dimensional maximum

crossing event and so on) is produced in one of the QSO components. To infer the source

size ratios, only cross–correlations between the brightness records in different optical bands

are required. While the deconvolution method leads to a richer information (1D intrinsic lu-

minosity proﬁles), the new approach is free of the technical problems with complex inver-

sion procedures. Using simulations related to recent V R data of Q2237+0305A, we discuss

the ability of the scheme in the determination of the visible–to–red ratio q = RV /RR.

We conclude that extremely accurate ﬂuxes (with a few µJy uncertainties, or equivalently,
a few milli–magnitudes errors) can lead to ∼ 10% measurements of q. Taking into ac-
count the errors in the ﬂuxes of Q2237+0305A from a normal ground–based telescope, ∼
10 µJy (∼ 10 mmag), it must be possible the achievement of smaller errors from the cur-

rent superb–telescopes, and thus, an accurate determination of q. Obviously, to measure

the visible–to–red ratio, the light curves cannot be contaminated by an intrinsic event or

an important high–frequency intrinsic signal, i.e., exceeding the µJy (mmag) level. For an

arbitrary lensed QSO, we ﬁnally remark that the framework seems to work better with very

fast microlensing events.

 
 
 
 
2

L. J. Goicoechea et al.: QSO size ratios

Key words. Gravitational lensing – Galaxies: nuclei – Quasars: general – Quasars:

Q2237+0305

1. Introduction

In an optical component of a lensed quasar, we might see large ﬂux variations as a result of grav-

itational microlensing. Some high–magniﬁcation events (HMEs) occur when the compact source

crosses fold caustics. In caustic crossing events (CCEs), the folds are assumed to be straight lines,

or more properly, the source radius and the source path are assumed to be small compared to the

caustic curvature radius. This approach is realistic for short trajectories of sufﬁciently compact

sources. However, for long paths in parallel to fold caustics or broad–line regions crossing folds,

the curvature effects can be important (e.g., Fluke & Webster 1999). We also note that the ac-

tual magniﬁcation maps contain assorted caustics, so the curvature radii of the smallest folds are

probably equal or less than the source radius, and obviously, our approach is not valid in this

”dwarf” caustic case. The CCEs are prominent variations belonging to a wider family of special

high-magniﬁcation events (SHMEs). The SHMEs are related to high–magniﬁcation regions in

which the non–uniform ampliﬁcation law, A(X, Y ), veriﬁes that A(kX, kY ) = f (k)A(X, Y ),

with k,f (k) > 0.

Grieger, Kayser & Refsdal (1988) suggested one important test on the nature of the compact

source, which is based on the analysis of the observed light curve during an individual CCE. They

showed that the one–dimensional intrinsic luminosity proﬁle can be retrieved from the brightness

record of a CCE. Other physical quantities can also be determined from observed CCEs (Grieger

et al. 1988), but at present, it is not possible to fulﬁl all the observational requirements. In the

nineties, the Grieger et al.’s original idea (deconvolution of the one–dimensional proﬁle from an

observed CCE) was developed by Grieger, Kayser & Schramm (1991), Agol & Krolik (1999),

and Mineshige & Yonehara (1999), and currently, there are projects to apply it.

This paper deals with a different realistic test on the compact source structure: from the

multiband monitoring of an individual SHME, one may measure the source size ratios, which

inform about the nature of the emitter. In the past, some authors have also done multiband stud-

ies of quasar microlensing (e.g., Rauch & Blandford 1991; Wambsganss & Paczy´nski 1991;

Jaroszy´nski et al. 1992; Yonehara et al. 1998; Yonehara el al. 1999). Here, we introduce a novel

methodology to determine source size ratios in a direct and model–independent way. A hypo-

thetical U BV RI monitoring could lead to a very complete set of ratios, e.g., RU /RB, RB/RV ,

RV /RR and RR/RI, while records in only two optical bands may be used to infer one ra-

tio. From observed events in QSO 2237+0305 that were associated with CCEs (i.e., a kind

of SHMEs), previous works discussed the size of the V R sources (e.g., Wyithe et al. 2000;

Shalyapin 2001; Yonehara 2001, Shalyapin et al. 2002), so indirect and model–dependent esti-

mates of q = RV /RR are available for that quasar. Shalyapin et al. (2002) reported indirect mea-

Send offprint requests to: L. J. Goicoechea

L. J. Goicoechea et al.: QSO size ratios

3

surements of q for several circularly symmetric source models, but unfortunately, the constraints

on q are usually weak (with large uncertainties) and depend on the assumed source model. If we

only consider the results corresponding to the best source models (power–law with the smallest

power index and accretion disk by Shakura & Sunyaev 1973), then it is derived a global interval

0.41

q

≤

≤

1.26 (using 1σ conﬁdence limits). Therefore, for QSO 2237+0305 and other lensed

quasars, we need a new tool to obtain an accurate and robust estimation of q or another different

ratio.

In Section 2 we present the new test. The method is robust, since it works with an arbitrary

source model. Only similarity between the compact sources (corresponding to different optical

ﬁlters) is required. More properly, the two–dimensional intensity distribution is arbitrary, but as

usual, it is stationary. Therefore, while several popular scenarios are included in the methodology,

e.g., a face–on standard disk or an inclined standard disk, we cannot discuss some scenarios,

e.g., unstable or anisotropic (rotating) disks. In order to apply the test, we must focus on an

observed SHME. Our method is only valid for the standard magniﬁcation close to a fold caustic

and some non–standard ampliﬁcation laws. In Section 2 we comment on a few non–standard

behaviours leading to SHMEs. The techniques for obtaining the best value of q as well as the

criteria to measure the visible–to–red ratio are introduced in Section 3. Several details of the

techniques are cumbersome and they are described in Appendix A. In Section 3, we also use

synthetic light curves to test the power of the framework. The synthetic records are not arbitrary

ones, but records related to the V –band and R–band GLITP (Gravitational Lensing International

Time Project) microlensing peaks in the ﬂux of Q2237+0305A (Alcalde et al. 2002; see also

the corresponding OGLE event in Wo´zniak et al. 2000). Finally, in Section 4 we summarize and

discuss our results.

2. The method: basic ideas

We concentrate on a component of a multiple (gravitationally lensed) quasar. In a given opti-

cal band, if the mass of the lens galaxy is mainly due to main sequence stars, white dwarfs,

black holes and so on, gravitational microlensing high–magniﬁcation ﬂuctuations are expected

at different epochs. The compact source travels a magniﬁcation map in the source plane, which

contains a caustic network with folds and cusps (e.g., Schneider, Ehlers & Falco 1992). In a

high–magniﬁcation region, the radiation ﬂux of the QSO component has two contributions: (a)

a constant term (F0) due to the extended source and a possible uniform magniﬁcation of the

compact source, and (b) a variable contribution caused by the non–uniform magniﬁcation of the

compact source, which is responsible for a prominent event.

We take two Cartesian coordinate frames: ﬁrst, a source frame (x,y) in which the origin coin-

cides with the compact source peak (the point with maximum intensity). The surface brightness

distribution of the compact source is traced by the law I(x, y) = I0B(x/R, y/R), where B is an

arbitrary function that veriﬁes B(0, 0) = 1 and 0

B < 1 at (x,y)

= (0,0), R is the characteris-

≤

6
4

L. J. Goicoechea et al.: QSO size ratios

tic length of the intensity distribution and I0 is the maximum intensity. Second, a magniﬁcation

frame (X,Y ), so the non–uniform magniﬁcation is A(X, Y ). At t = t0, the magniﬁcation pattern

frame coincides with the source frame. However, the origin of the magniﬁcation frame and the

high–magniﬁcation region as a whole have an effective transverse motion, and we can split up

the effective velocity in two parts: the motion parallel to the x-axis, Vk, and the motion perpen-

dicular to that axis, V⊥. The random stellar motions in the lens galaxy are implicitly neglected

during the high–magniﬁcation event. At a time t, the global ﬂux is given by

F (t) = F0 +

ǫI0
D2

s Z Z

A[x

Vk(t

−

−

t0), y

−

V⊥(t

−

t0)]B(x/R, y/R)dxdy,

(1)

where ǫ is the dust extinction factor, which ranges from 0 (complete extinction) to 1 (no ex-

tinction), and Ds is the angular diameter distance to the source. Using normalized coordinates

ξ = x/R and η = y/R, one ﬁnds

F (t) = F0 +

ǫI0R2
D2

s Z Z

R[ξ

A
{

−

Vk(t

−

t0)/R], R[η

V⊥(t

−

−

t0)/R]

}

B(ξ, η)dξdη.

(2)

On the other hand, we adopt a magniﬁcation law that is characterized by the property

A(kX, kY ) = f (k)A(X, Y ),

(3)

where k is an arbitrary positive constant and f (k) is another positive constant related to k. From

Eqs. (2–3), a ﬂux of the QSO component is inferred

F (t) = F0 +

ǫI0R2f (R)
D2
s

J

Vk(t

−
R

t0)

,

V⊥(t

−
R

t0)

.

(cid:21)

(4)

(cid:20)
τ, η

−

ω)B(ξ, η)dξdη.

−

The J function is given by J[τ, ω] =

A(ξ

We remark two important issues. The ﬁrst point deals with the high–magniﬁcation regions

R R

that are consistent with the property (3), and consequently, are related to SHMEs. The magniﬁ-

cation law near a cusp caustic does not verify Eq. (3) (e.g., Schneider & Weiss 1992; Zakharov

1995). However, in the surroundings of a fold caustic, the behaviour of the non–uniform ampli-

ﬁcation is A(X, Y ) = aC H(X)/√X. Here, H(X) is the Heaviside step function (e.g., Chang

& Refsdal 1979; Schneider & Weiss 1987). It is evident that the previous standard ampliﬁcation

veriﬁes Eq. (3), so the CCEs are included in our framework. Other non–uniform laws also agree

with that equation. For example, the non–uniform magniﬁcations around an one–dimensional
maximum (αX 2) and a two–dimensional maximum (αX 2 + βXY + γY 2) are characterized by
f (k) = k2. The relation between the non–standard behaviours and real regions in magniﬁca-

tion patterns merits more attention. The source model is another important issue. With respect to

this topic, we note that the two–dimensional intensity distribution can have circular symmetry,

elliptical symmetry or a more complex structure, but it cannot evolve with time.

We consider a set of compact sources that are associated with a set of optical ﬁlters, so all

sources have the same shape and peak. They only differ in their lengths and peak intensities.

Although this hypothesis of similarity is useful to link different sources corresponding to dif-

ferent ﬁlters, it could be false in a real situation. However, the similarity between sources is

L. J. Goicoechea et al.: QSO size ratios

5

consistent with the standard face–on accretion disk (e.g., Shalyapin et al. 2002; Kochanek 2004).

During a SHME, in a ﬁrst optical band (number 1), the theoretical light curve depends on the

background ﬂux F01, the dust extinction ǫ1, the maximum intensity I01 and the length R1 (see

Eq. 4). In a similar way, in a second optical band (number 2), one has the parameters F02, ǫ2, I02

and R2. We can directly compare the ﬂux in the 1-band at the time t with the ﬂux in the 2-band

at the time t′, when both times are linked from the relationship

Alternatively, Eq. (5) can be rewritten as

t

t0

−
R1

t′

=

t0

−
R2

.

t′ = r21t + (1

r21)t0,

−

(5)

(6)

where r21 = R2/R1 is the source size ratio, and t′ is obtained through a dilation (r21t) and a

delay (t0

−

so

r21t0). At the time t′, the 2-band ﬂux fulﬁls

D2

s [F2(t′)
ǫ2I02R2

−
2f (R2)

F02]

= J

(cid:20)

Vk(t

−
R1

t0)

,

V⊥(t

−
R1

t0)

,

(cid:21)

constants

The
ǫ1I01R2

1f (R1)

a

/

and
ǫ2I02R2

2f (R2)

> 0, respectively.

F1(t) = a + bF2(t′).

b

are

given

by

a

=

F01

F02b

and

b

−

(7)

(8)

=

(cid:2)

Eqs. (6) and (8) show that it is viable a cross-correlation between an observed light curve in

(cid:3)

(cid:2)

(cid:3)

the ﬁrst band and a brightness record in the second band, which could lead to the measurement

of four involved parameters (a, b, t0, r21). We note that this new test about the source size ratio is

different to the determination of the time delay between two components of a lensed quasar. In

the time delay estimation, using light curves in magnitudes, we only have two free parameters:

one offset and one delay. However, in the new problem, there are an offset, an ampliﬁcation, a

characteristic epoch and a dilation factor, and just the dilation factor (r21) is the relevant param-

eter. On the other hand, although the estimation of the source size ratio is possible, in practice,

the observed light curves are not continuous functions of the time and they are measured with

ﬁnite accuracy. These observational problems (discontinuous sampling and photometric errors)

may make difﬁcult the source size ratio estimation. Moreover, the detection of a clean SHME

is not so easy, even if a true special event is taken place. For example, the observed event could

be contaminated by intrinsic variability. Finally, we remember that the optical ﬁlters 1 and 2 are

arbitrary ones, so we can apply the method to any pair of ﬁlters. From a multiband monitoring

of a SHME, one may get a very rich information. In Section 3, using simulations associated with

recent V R data of Q2237+0305A, we discuss the feasibility of accurate estimates of q = rV R

from the new test.

3. Determination of the visible–to–red ratio from the method

In the optical continuum, QSO 2237+0305 (Einstein Cross) is a gravitational mirage that consists

of four components (A-D) round the nucleus of the deﬂector (lens galaxy). Irwin et al. (1989)

6

L. J. Goicoechea et al.: QSO size ratios

discovered microlensing variability in that system, and after such a fascinating discovery, several

groups did an important effort to monitor its components (e.g., Corrigan et al. 1991; Østensen et

al. 1996; Vakulik et al. 1997; Wo´zniak et al. 2000; Alcalde et al. 2002; Schmidt et al. 2002). In

recent dates, the OGLE collaboration presented the ﬁrst detailed light curves of Q2237+0305A–

D in the V band, which showed two clear high–magniﬁcation events between days (in JD–

2450000) 1200 and 1800: one in the A component and another one in the C component (Wo´zniak

et al. 2000). The GLITP collaboration also reported excellent V –band and R–band records of the

four QSO components, which are complementary to the OGLE data (Alcalde et al. 2002). The

GLITP monitoring (from day 1450 to day 1575) permitted to accurately trace the behaviour

around the maximum of the ﬂuctuation in the A component, so that the OGLE–GLITP event in

Q2237+0305A is by far the best observed high–magniﬁcation variation in the Einstein Cross. We

call OGLE–GLITP/Q2237+0305A event to the peak between days 1400 and 1600.

If we have V R observations of a SHME in a QSO component, we may robustly mea-

sure the parameter q = RV /RR. Eqs. (6) and (8) are rewritten as t′ = qt + (1
FR(t) = a + bFV (t′), respectively, and it might be possible to infer the visible–to–red ratio

q)t0 and

−

from a comparison between the V –band record and the R–band one. While the measurement

would be robust because it would not depend on particular (stationary) source models, the dis-

continuous sampling and the photometric uncertainties could be obstacles to get an estimation

of q. First, we present some techniques for obtaining the best value of q. The criteria to measure

the ratio are also quoted. Second, in order to test the power of the framework, it is applied to

synthetic light curves (simulations) related to the GLITP/Q2237+0305A data. The inﬂuence of

several observational parameters is analyzed in detail.

3.1. Best value and measurement of the source size ratio RV /RR

As a ﬁrst method to infer the best value of q (or equivalently, the best ratio), we use a usual
χ2 minimization. As a second estimator, we use the dispersion, which is also popular between

people working on discrete time series. Thinking of the measurement of time delays, Pelt and

collaborators (Pelt et al. 1994, 1996) developed this statistical technique. During the last decade,
the D2 minimization was successfully applied in the time delay estimation of several lens sys-

tems, so the method is able to ﬁnd delays in gravitational mirages. Unfortunately, the original

version of the estimator is not useful in our problem (see comments in the last paragraph of

section 2), and therefore, we must slightly modify the original scheme by Pelt et al. Finally, we
take a variant of the minimum dispersion method, which is called ǫ2 minimization. All the three

techniques are described in Appendix A. In the Appendix we comment on the main details of

the minimization techniques, including the way to transform the four dimensional estimators into
three dimensional (χ2) or two dimensional (D2 and ǫ2) ones.

For a given estimator of q, we follow two different approaches. In the ﬁrst framework, we

make one repetition of the experiment by adding a random quantity to each original ﬂux in the

L. J. Goicoechea et al.: QSO size ratios

7

light curves. The random quantities are realizations of normal distributions around zero, with

standard deviations equal to the errors of the ﬂuxes. We can make a large number of repetitions,

and thus, obtain a large number of q values. The true value will be included in the whole distribu-

tion of measured ratios. This ﬁrst procedure is called NORMAL. In the second approach, we use

a bootstrap procedure (BOOTSTRAP). The repetitions are generated by bootstrap resampling

of residuals from the original light curves smoothed by a ﬁlter. In section 3.3 (see below), each

original light curve is smoothed by a minimum (3–point) ﬁlter, and the results seem to be stable

with respect to the choice of any reasonable smoothing ﬁlter. The smoothed curves are assumed

to be rough reconstructions of the underlying signals, and thus, the residuals are taken as errors,

which may be resampled to infer a bootstrap simulation. Each bootstrap simulation of both the

V –band and R–band records is considered as one repetition of the original experiment. All our

q distributions include 300 ratios. For each distribution, we study the feasibility of an accurate

determination of q. The source size ratio is only measured when the true value of q is included

in the q range for the dominant feature. In that case, after the cleaning of the distribution, we

compute the centre of the main structure (central value) and the standard error (about 70% con-

ﬁdence interval). To measure the ratio, we properly clean the distribution of values of q, i.e., it is

dropped the signal out of the dominant structure and its wings.

In order to clarify the difference between some expressions, we comment them all together.

First, the term ”true value” refers to the true value of a physical parameter. In a real experiment,

the true value is unknown and we want to estimate it. However, in a synthetic experiment, the as-

tronomer controls the involved physics and chooses the true value. Second, the term ”best value”

(or ”best solution”) refers to the direct estimation of a physical quantity from an experiment and
a technique (χ2 minimization, minimum dispersion method or minimum modiﬁed dispersion

method). Third, after the direct estimation, we make repetitions (NORMAL or BOOTSTRAP)

of the experiment, obtain a best value from each repetition, and study the distribution of best

values. The distribution may include ”peaks” for some values of the physical parameter, and

sometimes a ”dominant peak” may appear. In a favourable situation, the true value, the best

value and the central value for the dominant structure would be nearby each others.

3.2. Synthetic light curves

To study the ability of our scheme, we make synthetic V R light curves and apply the formalism

to the simulations (see section 3.3). The GLITP observations of Q2237+0305A are used as a

reference data set, which contains 49 ﬂuxes in the R band and 52 ﬂuxes in the V band. The

observations were made with the 2.56 m Nordic Optical Telescope (NOT) at Canary Islands

(Spain). By pure chance, the component was monitored from day 1450 to day 1575 (in JD–

2450000), just during a microlensing peak (Alcalde et al. 2002). In each optical ﬁlter, to compute

a typical error in the ﬂuxes, the GLITP collaboration used the mean of the absolute differences

between adjacent days. Errors of σR = 0.017 mJy and σV = 0.010 mJy were derived from that

8

L. J. Goicoechea et al.: QSO size ratios

Fig. 1. GLITP (black symbols) and SYNa (blue and red symbols) V R light curves. The GLITP

ﬂuxes correspond to observations of Q2237+0305A, whereas the SYNa ﬂuxes are synthetic data.

In the simulations (SYNa), we take noise processes and sampling consistent with the GLITP

photometric errors and dates.

procedure. We note that our R–band calibration is made in an arbitrary way, so our R–band

ﬂuxes disagree with those in the GLITP Web site. However, the inappropriate calibration is not

a problem, because the q estimates do not depend on the calibration of the V R light curves. The

amplitudes of the observed features are about 10 times the photometric uncertainties.

Going into details, each underlying signal is generated through the Eq. (13) in Shalyapin et al.

(2002). Therefore, a circularly symmetric source model and a caustic crossing are involved. We

use a p = 3/2 power–law intensity proﬁle. The source size ratio and the time of caustic crossing

by the common center of the sources are taken as q = 0.8 and t0 = 1483, respectively. Moreover,

the ﬁnal ﬂuxes are normally distributed around the underlying ones, so the observational random

noise is characterized by a normal standard deviation. Except for a family of experiments (those

incorporating extremely accurate ﬂuxes), the error bar is computed from the GLITP criterion (the

L. J. Goicoechea et al.: QSO size ratios

9

Fig. 2. GLITP (black symbols) and SYNd (blue and red symbols) V R light curves. The simula-

tions (SYNd) have a homogeneous sampling.

mean of the absolute differences between adjacent ﬂuxes), and it is close to the normal standard

deviation. All the simulated V R records have time coverage and ﬂux variations consistent with

the GLITP V R records for Q2237+0305A. In the ﬁrst synthetic experiments, the ﬂux errors and

sampling properties agree with the GLITP photometric uncertainties and sampling. The sampling

properties are modiﬁed in a second kind of experiments, whereas homogeneously distributed and

very accurate ﬂuxes are produced in the last experiments.

Firstly, it is considered the SYNa data set. In Figure 1 we have drawn together the observed

(GLITP) light curves and the SYNa ones. The black symbols represent the observations, while

the blue and red symbols represent the simulations. In SYNa, the standard deviations of the

observational noise processes are assumed to be 0.017 mJy (R–band) and 0.010 mJy (V –band),

i.e., in agreement with the GLITP uncertainties. The SYNa sampling also coincides with the

GLITP distribution of dates. Indeed, in Fig. 1 we can see synthetic data very similar to the GLITP

ones. Besides of this ﬁrst GLITP–like data set, we generate two more GLITP–like experiments.

10

L. J. Goicoechea et al.: QSO size ratios

Fig. 3. GLITP (black symbols) and SYNe (blue and red symbols) V R light curves. The new

synthetic records (SYNe) have a quasi–continuous sampling of one photometric measurement

per day.

They are called SYNb and SYNc simulations, and the observations and simulations are again

similar in all the details.

An interesting issue is the inﬂuence of some observational aspects on the determination of q,

e.g., the sampling. Therefore, in a second kind of simulations, we exclusively modify the sam-

pling properties. The sampling of the light curves has two main properties: rate and homogeneity.

From a ground–based telescope, a sampling rate of one frame each two or three days is excellent.

This very good rate is used to generate the ﬁrst kind of simulations (GLITP–like simulations).

The sampling quality also depends on the homogeneity in the dates. For example, the GLITP–

like light curves have important gaps. In the SYNd experiment (see Figure 2), we only improve

the sampling homogeneity. There are 50 ﬂuxes in each optical band (blue and red symbols in Fig.

2), but their time distributions are highly homogeneous. In another experiment (SYNe) we con-

L. J. Goicoechea et al.: QSO size ratios

11

Fig. 4. GLITP (black symbols) and SYNf (blue and red symbols) data sets. The simulations

(SYNf) have a homogeneous sampling and ﬂux errors two times less than the GLITP ones.

sider a quasi–continuous sampling of one photometric measurement per day. The GLITP records

(black symbols) and the SYNe light curves (blue and red symbols) are showed in Figure 3.

From a third kind of experiments, we can also test the inﬂuence of the ﬂux uncertainties.

The SYNf V R light curves are generated with normal standard deviations (observational noise

processes) of 0.008 mJy (R–band) and 0.005 mJy (V –band). To produce these synthetic light

curves, the sampling rate is assumed to be the GLITP one, the dates are homogeneously dis-

tributed along the time coverage, and the ﬂux errors are lowered by a factor of 2. In Figure 4, the

black symbols represent the GLITP data, and the blue and red symbols represent the SYNf data.

Both data sets (observations and simulations) are similar in some details. However, apart from

the sampling homogeneity, it is clear in Fig. 4 that the simulated errors are half the GLITP ones.

The SYNg light curves are characterized by normal standard deviations of 1.7 µJy (R–band)

and 1 µJy (V –band), i.e., with respect to the GLITP–like curves, the uncertainties are lowered

by a factor of 10. In Figure 5, we show the two synthetic curves. The accuracy is impressive,

12

L. J. Goicoechea et al.: QSO size ratios

Fig. 5. GLITP (black symbols) and SYNg (blue and red symbols) data sets. The simulations

(SYNg) have a homogeneous sampling and uncertainties 10 times less than the GLITP errors.

and each error bar has a size similar to the point size. In the SYNg experiment, the error bars

are not inferred from the usual criterion (the mean of the absolute differences between adjacent

ﬂuxes), but they are chosen to be the normal standard deviations. The hypothetical observer can-

not measure a ﬂux uncertainty (in a given optical band) from the scatter of ﬂuxes, because the

error is clearly smaller than the true day–to–day variability. We assume that the observer uses a

non–biased criterion. Moreover, we also use 10 additional experiments similar to SYNf and 10

additional data sets similar to SYNg.

Although our study is mainly based on 27 data sets, we have produced and analyzed about

100 synthetic experiments (”SYN”). The names and properties of the seven basic experiments

(see here above) are listed in Table 1.

L. J. Goicoechea et al.: QSO size ratios

13

Name

Sampling rate (data/week) Homogeneity

V –band noise (µJy) R–band noise (µJy)

SYNa

SYNb

SYNc

SYNd

SYNe

SYNf

SYNg

∼ 3

∼ 3

∼ 3

∼ 3

7

∼ 3

∼ 3

No

No

No

Yes

Yes

Yes

Yes

10

10

10

10

10

5

1

Table 1. Basic synthetic experiments.

17

17

17

17

17

8

1.7

Fig. 6. Distributions of q based on NORMAL and BOOTSTRAP repetitions of the SYNa ex-

periment. To derive the BOOTSTRAP repetitions, we use curves smoothed from a 3–point ﬁlter

(a time window of about 5 days). Dashed lines represent the NORMAL distributions and solid
lines trace the BOOTSTRAP histograms. Top panel: minimum χ2 method (α = 2.5 days). Bottom

panel: minimum dispersion method (δ = 2.5 days).

14

L. J. Goicoechea et al.: QSO size ratios

Fig. 7. Distributions of q from NORMAL and BOOTSTRAP repetitions of the SYNb experiment

(GLITP–like simulations). In the BOOTSTRAP procedure, it is used a 3–point ﬁlter (a time

window of about 5 days). As remarked in the caption under Fig. 2, dashed lines and solid lines
represent the NORMAL and BOOTSTRAP distributions, respectively. Top panel: χ2 (α = 2.5
days). Bottom panel: D2 (δ = 2.5 days).

3.3. Results

Using the experiments in Table 1 together with the scheme in section 3.1 and Appendix A, it

might be analyzed the feasibility of an accurate estimate of the source size ratio. We consider a

large rectangle in the (t0,q) plane: 1450

t0

≤

≤

1550 and 0.5

q

≤

≤

1.5, which includes the true

values of t0 (1483) and q (0.8).

3.3.1. Light curves similar to the GLITP observations

As we have about 50 V R data in a period of 125 days (4 months), the typical separation between

adjacent dates is of 2.5 days. Therefore, 2–3 days seems a good range for both the bin semiwidth

L. J. Goicoechea et al.: QSO size ratios

15

Fig. 8. Histograms based on repetitions of the SYNc experiment (GLITP–like simulations). We

present NORMAL (dashed lines) and BOOTSTRAP (solid lines) distributions. We use a 3–point
ﬁlter in the BOOTSTRAP scheme. Top panel: χ2 (α = 2.5 days). Bottom panel: D2 (δ = 2.5

days).

(α) and the decorrelation length (δ). From the SYNa data set, taking α = 2.5 days, the χ2 mini-

mization leads to a best value of q = 1.5 (t0 = 1498), whereas from NORMAL and BOOTSTRAP
repetitions and the minimum χ2 method, we derive the distributions of q values that appears in

Figure 6 (top panel). In order to make the BOOTSTRAP repetitions, we use a 3–point ﬁlter.

The NORMAL (dashed lines) and BOOTSTRAP (solid lines) distributions are consistent each

other. There are dominant peaks at the q = 1.5 edge, secondary features around q = 0.9 and zero

probabilities along the q < 0.85 interval. The ratios q > 1 are mainly derived from a relatively

small number of RV pairs (in general, N < 40, and sometimes, N

25). Another alternative

∼

technique is the minimum dispersion method. When it is applied to the SYNa data (using δ =
2.5 days), the best value is q = 1.5 (t0 = 1523). The new best solution for q is equal to the χ2

best solution for that relevant parameter, and both of them are far from the true value. From

16

L. J. Goicoechea et al.: QSO size ratios

Fig. 9. NORMAL (dashed lines) and BOOTSTRAP (solid lines) histograms associated with rep-

etitions of the GLITP experiment. We show the results from a study with high time resolution: α

= δ = 2.5 days and a 3–point ﬁlter.

NORMAL and BOOTSTRAP repetitions (using a 3–point ﬁlter) and D2 minimization, new dis-

tributions are inferred and showed in Fig. 6 (bottom panel). The new NORMAL (dashed lines)

and BOOTSTRAP (solid lines) histograms are very enhanced at the edges. Now, there is not any

structure close to q = 0.8. Most the ratios q

0.5 are associated with negative ampliﬁcations
1.5 too. The D2 results are even worse than the results from the χ2

∼

(b < 0), and some ratios q

∼

minimization.

Through the SYNb data, the χ2 best solution is q = 0.98 (t0 = 1456), and the results from
the χ2 minimization and the repetitions (NORMAL and BOOTSTRAP using a 3–point ﬁlter) are

presented in Figure 7 (top panel). In all ﬁgures, dashed lines trace NORMAL distributions and

solid lines describe BOOTSTRAP results. Regarding the distributions in the top panel of Fig.

7, the new histograms are more homogeneous. However, there is zero probability at q < 0.85,

and the ratios q > 1 are usually inferred from N < 40 (in some cases, N

25). Sometimes,

∼

L. J. Goicoechea et al.: QSO size ratios

17

Fig. 10. NORMAL (dashed lines) and BOOTSTRAP (solid lines) histograms associated with

repetitions of the SYNd experiment. We show the results from the analysis with α = δ = 2.5 days

and a 3–point ﬁlter.

we simultaneously obtain a value of q larger than one and a negative ampliﬁcation. On the other
hand, the D2 best solution is q = 1.5 (t0 = 1536). From the minimum dispersion method, we

deduce the histograms in Fig. 7 (bottom panel). We remark that there are no repetitions leading

to the value q = 0.8 (true ratio), and some extreme values of q (q

0.5 or 1.5) are related to

∼

negative ampliﬁcations.

Using the SYNc data and α = δ = 2.5 days, the χ2 and D2 best solutions are q = 0.85 (t0 =

1535) and q = 0.52 (t0 = 1548), respectively. The NORMAL and BOOTSTRAP (3–point ﬁlter)

histograms are plotted in Figure 8. We note that the results from the SYNc light curves are not

very different to the results by means of the SYNa and SYNb data sets. To sum up, with the

three experiments (associated with three hypothetical observatories), the distributions from the
minimum χ2 technique are not bell–shaped and centered on a ratio near the true value (top panels

of Figs. 6–8). Instead of that good behaviour, we obtain rare distributions, which are characterized

18

L. J. Goicoechea et al.: QSO size ratios

Fig. 11. NORMAL (dashed lines) and BOOTSTRAP (solid lines) histograms associated with

repetitions of the SYNe experiment. We work with very high time resolution: α = δ = 1.2 days

and a 3–point ﬁlter.

by the absence of ratios at q < 0.85 and the presence of artifacts in the range 0.85–1.5. The false

signals in the 0.85

q

≤

≤

1.5 interval can be distributed in different ways, but curious structures

around q = 0.9 are always present. These artifacts are secondary features in the top panel of Fig.

6, prominent features in the top panel of Fig. 7 and dominant structures in Fig. 8 (top panel).
In the histograms from the D2 minimization (bottom panels of Figs. 6–8), there are dominant

peaks at the edges and negligible signals around the true value (q = 0.8). Here as in other parts
of the paper, we do not show the results from the ǫ2 minimization (see sections 3.1 and A.3),
because the minimum ǫ2 method works better than the D2 minimization, but a little worse than
the minimum χ2 method. As a global conclusion, using our framework and GLITP–like data

sets, we cannot measure the visible–to–red ratio.

Although the simulations consistent with the GLITP observations indicate the non-viability

of a measurement of q, we compare the best values and distributions from the simulations and the

L. J. Goicoechea et al.: QSO size ratios

19

Fig. 12. NORMAL (dashed lines) and BOOTSTRAP (solid lines) histograms associated with

repetitions of the SYNf experiment.

results from the GLITP data. Using the GLITP brightness records, we ﬁnd that the χ2 (α = 2.5
days) best solution is q = 0.91 (t0 = 1546). We also derive the q distributions (χ2) in Figure 9 (top

panel). The ratios q > 1 are usually derived through < 40 RV pairs, and in some cases, only

25

∼

RV pairs are used. A slight correlation between large ratios (q > 1) and negative ampliﬁcations

(b < 0) is another property of the results from the NORMAL and BOOTSTRAP (3–point ﬁlter)

repetitions. There are no signals at q < 0.85. However, the 0.85–1.5 range includes extended
signals and dominant features around q = 0.9. Apart from the χ2 minimization, the D2 (δ =

2.5 days) best solution is q = 0.5 (t0 = 1540, b < 0). In Fig. 9 (bottom panel), we show the

corresponding q histograms. The ratios q

∼

0.5 are mainly associated with b < 0, and sometimes,

b < 0 for q > 1. Moreover, the distributions are enhanced at the edges. Taking into account the

knowledge from the GLITP–like simulations (see here above), all the structures in Fig. 9 could
be false features. Even the dominant features in the signals from the minimum χ2 method may

be due to the limitations of the framework for the GLITP data set.

20

L. J. Goicoechea et al.: QSO size ratios

Fig. 13. NORMAL (dashed lines) and BOOTSTRAP (solid lines) histograms associated with

repetitions of the SYNg experiment.

3.3.2. Sampling properties

From the SYNd data set (see Table 1) and the techniques, we try to measure the ratio q. Using
α = 2.5 days, the χ2 best solution is q = 1.24 (t0 = 1481). In addition to this best value, the q
distributions from the χ2 minimization and 300 repetitions (NORMAL and BOOTSTRAP) are

depicted in Figure 10 (top panel). In the BOOTSTRAP procedure, as usual, it is used a 3–point

ﬁlter. The histograms in the top panel of Fig. 10 are clearly different to the distributions in the

top panels of Figs. 6–8. In the new signals, we see dominant structures at q < 0.7 and do not

see the artifacts around q = 0.9, which suggests the existence of a relation between the gaps in

the GLITP–like curves and the trends in the top panels of Figs. 6–8. In any case, the fraction of

ratios in the 0.7–0.9 interval (i.e., the probability that the true value will fall within the 0.7

q

0.9 range) is very small. Therefore, as P (0.7

q

≤

≤

0.9)

≤

basically obtain false signals. From the minimum dispersion method, we infer a best ratio of 1.5

≤
10% and the true value is q = 0.8, we

≤

L. J. Goicoechea et al.: QSO size ratios

21

(t0 = 1525) and deduce the histograms in the bottom panel of Fig. 10. There are dominant peaks

at the q = 1.5 edge and very small probabilities at q < 1.2. We remark that the improvement in

the sampling homogeneity is not sufﬁcient, since the new best values and q distributions do not

permit to estimate the visible–to–red ratio.

By means of either a large collaboration including several observatories around the world or

a space telescope, in each optical band, we can get a quasi–continuous sampling of one frame per

day. This ”ideal” sampling is assumed in the SYNe experiment. The time resolution is roughly

increased by a factor of 2, so 1.2 days is a reasonable choice for both the bin semiwidth (α) and
the decorrelation length (δ). The χ2 minimization leads to a very promising best value for both

the ratio and the time of caustic crossing: q = 0.79 and t0 = 1484. However, the distributions of

q values have not a behaviour as good as expected. In Figure 11 (top panel), the NORMAL and
BOOTSTRAP histograms (χ2) appear. Around q = 0.8, there are prominent peaks with relatively

small probabilities of P (0.7

q

≤

≤

0.9)

≈

23–24%. These signiﬁcant features are not dominant

structures, but structures surrounded by other similar features. As a result of the existence of
several similar features, a fair measurement of q cannot be attained. When the minimum D2

method is applied to the SYNe data, the best value is q = 1.48 (t0 = 1510). From NORMAL
and BOOTSTRAP repetitions and D2 minimization, we infer disappointing distributions of q

(see the bottom panel of Fig. 11). It becomes apparent the absence of a signiﬁcant feature in
the surroundings of q = 0.8 (true value), and of course, the histograms (D2) are strongly biased.

Finally, we conclude that our framework does not work in a proper way, even with a substantial

improvement in the sampling properties.

3.3.3. Flux errors

In the SYNf experiment, the ﬂux errors are lowered in a factor 2 (see Table 1 and Fig. 4). From the
χ2 minimization, taking α = 2.5 days, the best ratio is q = 0.73 (t0 = 1489). Using the minimum
χ2 technique with the usual time resolution (α = 2.5 days and 3–point ﬁlter in BOOTSTRAP

repetitions), we obtain two q distributions that are depicted in Figure 12 (top panel). In the top

panel of Fig. 12, we see encouraging BOOTSTRAP results. From the BOOTSTRAP repetitions,

a dominant peak around q = 0.76 appears. This central value (0.76) is in good agreement with

the best ratio (0.73), and moreover, the true ratio (0.8) is included in the q range for the dominant

feature. The NORMAL results are worse than the BOOTSTRAP results, because the NORMAL

main spike is placed at the q = 0.5 edge. Using the BOOTSTRAP histogram, we can derive the

ﬁrst estimate of the source size ratio. Following the procedure that is described in section 3.1, q =

0.76

±

0.05. To obtain the measurement, we ignore the signal at q < 0.6 and q > 0.9. However,

unfortunately, the possibility of

∼

3–10% measurements of the source size ratio is not supported

by other experiments similar to the SYNf one. For example, from ten new synthetic experiments
and the χ2 minimization, only three best ratios are included in the promising 0.65

0.85

q

≤

≤

interval. In ﬁve cases, the best ratio is of about 0.5, whereas in two cases, the best value is close

22

L. J. Goicoechea et al.: QSO size ratios

to 1.4. Therefore, if we consider ten hypothetical observers measuring the source size ratio each
of them (via χ2/BOOTSTRAP), several best estimates and distributions of q will be in serious

disagreement with the true ratio. Although some particular observers are successful, most ob-
servers fail in the determination of q. Through the SYNf–like experiments, we also derive χ2

min

values in the interval 0.25–0.60. These results suggest that we deal with seven biased ”superﬁts”,

which are not related to the true physical scenario. The observational noise and discontinuous

sampling are the cause of the superb correlations between the V ﬂuxes and the R ones. From

the minimum dispersion method, taking δ = 2.5 days, the best ratio is q = 1.15 (t0 = 1523). The
NORMAL and BOOTSTRAP repetitions lead to poor histograms. These D2 histograms appear

in Fig. 12 (bottom panel). In spite of the small peak in the surroundings of the true value, it is

apparent that the distributions are biased. From the NORMAL and BOOTSTRAP distributions
of q (D2), a false ratio exceeding the critical value (q = 1) is strongly favoured. If we compare

the results in Fig. 12 and the distributions in Fig. 10 (from a data set with similar sampling and

larger errors), it is clear that the decrease of the ﬂux errors leads to a global improvement. With

smaller errors, we ﬁnd stronger signals in the proximity of the true ratio.

As the photometric errors seem to have a signiﬁcant inﬂuence on the q distributions, ﬁnally,

we explore the ability of the methodology with extremely accurate photometric data. For this
ﬁnal effort, the SYNg data set is a suitable tool. For the SYNg data, the χ2 minimization gives a

best solution: q = 0.79 (t0 = 1484), while for the NORMAL and BOOTSTRAP repetitions, the

technique also works well. In Figure 13 (top panel), the corresponding distributions are plotted.

We see dominant structures around q = 0.80 (NORMAL and BOOTSTRAP central value). With

the q resolution in the top panel of Fig. 13, the main features have not a nice shape, but they
contain most the best solutions. Our χ2/NORMAL&BOOTSTRAP measurement is of q = 0.80

0.08 (ignoring the signal at q < 0.65 and q > 0.95). From ten monitorings similar to the
±
SYNg experiment and the minimum χ2 method, we get convincing results: nine best ratios are

within the 0.70

q

≤

≤

0.92 interval, and only one best ratio has a biased value of q = 0.52. Even

in this last case (q = 0.52), the NORMAL and BOOTSTRAP histograms have relatively good

behaviours. The NORMAL distribution shows a dominant spike close to 0.5, which contains

about 50% of the best ratios. However, the rest of ratios (about 50%) are mainly placed in the

0.65

q

≤

≤

0.95 range. In the BOOTSTRAP distribution, there is also an extended feature within

q

the 0.65

0.95 range, which includes about 70% of the ratios. The highest spike at q

∼
0.5 only contains about 30% of the ratios. In other words, the hypothetical observer would ﬁnd

≤

≤

doubtful results, since there are evidences for two different values: q

∼
0.8 (true ratio). Apart from this troublesome situation, any possible observer has a very high

∼

0.5 (artifact) and q

probability (about ninety per cent) of measuring a fair and accurate visible–to–red ratio (
measurement). For the nine SYNg–like experiments leading to non–biased values of q, the χ2
min interval and all is ok. However, χ2
varies from 0.95–1.20, i.e., we infer a reasonable χ2

∼

min

min

10%

= 0.6 from the SYNg–like experiment associated with a strange value of q. The strange ratio is
related to a very small χ2 (”superﬁt”), and both (χ2

min and q) are due to the noise and sampling.

L. J. Goicoechea et al.: QSO size ratios

23

From the minimum D2, the best ratio is q = 0.80 (t0 = 1484). This is the only case in which
both the χ2 and D2 best estimates are nearby each other and the true value. New D2 histograms

appear in Fig. 13 (bottom panel). The two distributions in the bottom panel of Fig. 13 are really

rare. We see the true signal inside the 0.65

0.95 interval and other features at q > 1. The
q
≤
1.1–1.4 range. Why are the D2 histograms so rare?.
main structures are related to ratios in the
From the 10 synthetic data sets similar to the SYNg one and the minimum D2 method, we infer

≤

∼

surprising results: two ratios exceeding the critical value (i.e., larger than 1) and eight ratios larger

than 0.74 and smaller than 0.91. This independent q distribution (based on real repetitions, i.e.,

using the true underlaying signal) indicates that the NORMAL and BOOTSTRAP procedures
may be unsuitable with extremely accurate light curves and the D2 minimization. Finally, we

note that future monitoring projects from modern ground–based or space telescopes can lead to

10% measurements of the visible–to–red ratio. To be successful in the accurate determination

∼
of q, a reasonable sampling and a few µJy uncertainties are required.

4. Summary and discussion

We present a new framework to analyze the structure of the optical compact source of a lensed

QSO. When a microlensing high–magniﬁcation event (HME) is produced in one of the QSO

components, assuming that the compact emission regions have different sizes in different wave-

lengths, the multiband light curves of the HME can be used to measure the source size ratios

(e.g., Wambsganss & Paczy´nski 1991). In this paper, we deal with a kind of HMEs: the special

high–magniﬁcation events (SHMEs). This family includes the well–known caustic crossing as

well as other situations, e.g., the two–dimensional maximum crossing. Our method has the ad-

vantage that ﬁnds the source size ratios in a direct and model–independent (stationary source

model) way and without complex computation procedures. From the brightness records of a

caustic crossing event (CCE), the deconvolution technique leads to a richer information, because

the method enables to retrieve the one–dimensional intrinsic luminosity proﬁles (e.g., Grieger,

Kayser & Schramm 1991). However, the determination of the 1D intrinsic luminosity proﬁles is

not a fair and simple task, and the problem is related to complex inversion procedures. To infer a

source size ratio, we propose a straightforward cross–correlation between the records in the two

optical bands, so our procedure has some resemblance to the classical time delay measurement.

In order to measure the visible–to–red ratio (q = RV /RR), we also introduce several suitable

tools, which can be applied to derive another ratio (RU /RB, RB/RV , ...).

The power of the new scheme is tested from synthetic light curves that are related to the V –

band and R–band GLITP microlensing peaks in the ﬂux of Q2237+0305A (Alcalde et al. 2002).

Very recently, assuming that the GLITP/Q2237+0305A ﬂuctuations are due to a CCE, Shalyapin

et al. (2002) and Goicoechea et al. (2003) analyzed the nature and size of the optical compact

source, as well as the central mass and accretion rate associated with the favoured model (stan-

dard accretion disk). In this work, the GLITP/Q2237+0305A records are also associated with

24

L. J. Goicoechea et al.: QSO size ratios

a CCE (for a discussion on the origin of the GLITP/Q2237+0305A data set, see here below).

To generate synthetic datasets, we take underlying signals in agreement with the GLITP obser-
vations (reduced χ2 values close to 1). They correspond to p = 3/2 power–law source proﬁles

crossing a fold caustic, so the source size ratio is taken as q = 0.8 (see Tables 1–3 in Shalyapin

et al. 2002). Once an underlying signal is made, we add observational random noise, which is

characterized by a normal standard deviation. This random noise must incorporate the pure ob-

servational uncertainty and the day–to–day intrinsic variability. We remark that the scheme is

based on a stationary source model, and thus, the underlying signal cannot include any intrinsic

variation. While in some synthetic experiments, the ﬂux errors and sampling properties agree

with the GLITP photometric uncertainties and sampling, in other experiments, the inﬂuence of

the sampling properties and ﬂux errors is studied in detail. We ﬁnd that GLITP–like datasets are

not suitable for measuring the visible–to–red ratio. Even with a dramatic improvement in the

sampling, our framework does not lead to convincing results. However, if the ﬂux uncertainties

are signiﬁcantly lowered, the scheme works in an accurate way. From V R light curves with a few

µJy uncertainties, we can infer

∼

10% measurements of q. Assuming the NOT uncertainties for

Q2237+0305A (of about 10 µJy) as mainly due to pure observational noise, it would be viable

to achieve smaller errors using the current superb–telescopes (the best ground–based telescopes

or the Hubble Space Telescope). Therefore, there are no technological obstacles to get accurate

estimates of the visible–to–red ratio for QSO 2237+0305. The possible presence of very rapid

intrinsic variability with relatively large amplitude would be the only serious obstacle. Using the
χ2 minimization, one can obtain an accurate value of q in two ways: either from only one mon-

itoring and standard techniques to infer the error in q, or from the best solutions corresponding

to several datasets of different observatories. However, using the minimum dispersion method,

the standard repetitions of an individual experiment do not seem to lead to good results, and
one must focus on the best solutions from different experiments. In general, the χ2 minimization
works better than the minimum dispersion method, and the ǫ2 minimization is a technique with

intermediate quality.

Sampling and ﬂux errors aside, other factors may determine the ability of the methodology.

For example, the time coverage of the SHME. We only test microlensing peaks lasting

100

∼

days, but longer and larger variations could lead to an accurate determination of the ratio, without

need for improving the uncertainties. Nevertheless, it is hard to imagine a long period of about

1 year in which the source QSO does not vary. From a long–timescale monitoring, we would

observe a dirty SHME, i.e., true microlensing ﬂuctuations that are contaminated by some intrinsic

variation. Moreover, it may be difﬁcult to detect a pure SHME, since a long–timescale event

may include variability from either several features in the magniﬁcation pattern or random stellar

motions in the deﬂector. Another possibility is the determination of q from very fast microlensing

events. For a given level of noise, some probes indicate that the fastest underlaying signals enable

the best measurements of the ratio. Therefore, faster events in Q2237+0305A as well as very fast

L. J. Goicoechea et al.: QSO size ratios

25

events in another component of that system or other lensed QSO would represent more favourable

situations.

Before to reliably apply the scheme, a key point is to conﬁrm that the observed records are

very probably related to a clean and pure SHME. This task is not so easy, and currently, even the

origin of the GLITP/Q2237+0305A ﬂuctuations is not a totally clear matter. The global ﬂat shape

for the V R GLITP light curves of Q2237+0305D (the faintest component of the system) indicates

the absence of a global intrinsic variation. Therefore, the GLITP/Q2237+0305A peaks seem to be

clean microlensing ﬂuctuations. On the other hand, the V –band and R–band GLITP light curves

of Q2237+0305A trace the regions around the maxima of the V R ﬂuctuations. As the peaks are

highly asymmetric and correspond to a prominent event (observations by the OGLE team), they

were associated with a CCE (a kind of SHME) since were discovered. The CCE hypothesis led

to very reasonable results for the source structure (Shalyapin et al. 2002; Goicoechea et al. 2003)

, which are an a posteriori support for the initial hypothesis. But do they really correspond to a

pure CCE?. Kochanek (2004) studied the source trajectories that agree with the whole V –band

OGLE light curves for Q2237+0305A–D. His results for the origin of the prominent event in
the A component are a bit disappointing, because the best trajectories in terms of χ2 cross over

simple folds, but other relatively good trajectories pass through complex magniﬁcation zones (see

Figs. 12–16 in Kochanek 2004). However, several issues suggest that the Kochanek’s conclusions

about the nature of the microlensing event are preliminary ones. First, the conclusions were

based on a joint study of the four components A–D during a long period. Second, it was used an

enlargement of the formal errors, so the pair of best trajectories on the magniﬁcation patterns for
Q2237+0305A have excessively small values of χ2 (χ2
of good paths are characterized by ∆χ2 = χ2

−
15. In the circumstances, the use

187, Ndof = 290), and the rest

−
of smaller uncertainties does not seem unrealistic. Moreover, the new uncertainties could lead to
∆χ2 > (2Ndof )1/2. Third, in order to obtain statistical conclusions, the total number of good

0 = 186

χ2
0

14

≥

−

trajectories is clearly small. At present, the University of Cantabria group is carrying out a deep

study about the origin of the OGLE–GLITP/Q2237+0305A event.

Acknowledgements. We thank R. Gil–Merino for a careful reading of the manuscript and suggestions. We

also thank C. S. Kochanek for comments on the origin of the OGLE–GLITP/Q2237+0305A event, and F.

Almeida and F. de Sande (Depto. Estadistica, I.O. y Computacion, Universidad de La Laguna) for valuable

aid in the four–dimensional minimization of the dispersion, which was used to test the two–dimensional

one. The authors would like to thank the anonymous referee for comments on the overall structure of the

paper. This work was supported by Universidad de Cantabria funds and the Spanish Department for Science

and Technology grant AYA2001-1647-C02.

References

Agol, E., & Krolik, J. 1999, ApJ, 524, 49

Alcalde, D., Mediavilla, E., Moreau, O., et al. 2002, ApJ, 572, 729

Chang, K., & Refsdal, S. 1979, Nat, 282, 561

26

L. J. Goicoechea et al.: QSO size ratios

Corrigan, R. T., Irwin, M. J., Arnaud, J., et al. 1991, AJ, 102, 34

Fluke, C. J., & Webster, R. L. 1999, MNRAS, 302, 68

Goicoechea, L. J., Alcalde, D., Mediavilla, E., & Mu˜noz, J.A. 2003, A&A, 397, 517

Grieger, B., Kayser, R., & Refsdal, S. 1988, A&A, 194, 54

Grieger, B., Kayser, R., & Schramm, T. 1991, A&A, 252, 508

Irwin, M. J., Webster, R. L., Hewett, P. C., et al. 1989, AJ, 98, 1989

Jaroszy´nski, M., Wambsganss, J., & Paczy´nski, B. 1992, ApJ, 396, L65

Kochanek, C. S. 2004, ApJ, 605, 58

Mineshige, S., & Yonehara, A. 1999, PASJ, 51, 497

Østensen, R., Refsdal, S., Stabell, R., et al. 1996, A&A, 309, 59

Pelt, J., Hoff, W., Kayser, R., Refsdal, S., & Schramm, T. 1994, A&A, 256, 775

Pelt, J., Kayser, R., Refsdal, S., & Schramm, T. 1996, A&A, 305, 97

Rauch, K. P., & Blandford, R. D. 1991, ApJ, 381, L39

Schmidt, R. W., Kundi´c, T., Pen, U.–L., et al. 2002, A&A, 392, 773

Schneider, P., Ehlers, J., & Falco, E. E. 1992, Gravitational Lenses (Berlin: Springer)

Schneider, P., & Weiss, A. 1987, A&A, 171, 49

Schneider, P., & Weiss, A. 1992, A&A, 260, 1

Shakura, N. I., & Sunyaev, R. A. 1973, A&A, 24, 337

Shalyapin, V. N. 2001, AstL, 27, 150

Shalyapin, V. N., Goicoechea, L.J., Alcalde, D., Mediavilla, E., Mu˜noz, J.A., & Gil-Merino, R. 2002, ApJ,

579, 127

Vakulik, V. G., Dudinov, V. N., Zheleznyak, A. P., et al. 1997, Astron.Nachr., 318, 73

Wambsganss, J., & Paczy´nski, B. 1991, AJ, 102, 864

Wo´zniak, P. R., Udalski, A., Szyma´nski M., et al. 2000, ApJ, 540, L65

Wyithe, J. S. B., Webster, R. L., Turner, E. L., & Mortlock, D. J. 2000, MNRAS, 315, 62

Yonehara, A. 2001, ApJ, 548, L127

Yonehara, A., Mineshige, S., Fukue, J., Umemura, M., & Turner, E.L. 1999, A&A, 343, 41

Yonehara, A., Mineshige, S., Manmoto, T., Fukue, J., Umemura, M., & Turner, E. L. 1998, ApJ, 501, L41

(erratum 511, L65)

Zakharov, A. F. 1995, A&A, 293, 1

Appendix A: Minimization techniques

A.1. χ2 minimization

The whole data set includes the observed ﬂuxes in the R band, FR(ti), i = 1, 2, ..., NR, with

i = qti + (1

common uncertainties σR, and the observed ﬂuxes in the V band, FV (tj), j = 1, 2, ..., NV , with
observational errors σV . The R–band ﬂux at time ti, FR(ti), is compared to the ﬂux a+bFV (t′
q)t0. In general, the dilated and delayed time t′
where t′

i),
i does not coincide with
i) by averaging the V –band ﬂuxes
i with a semiwidth α. To average, it is appropriate the use of weights
i and the dates tj in the bin. For given

any epoch in the V band, and we estimate the value of FV (t′
within the bin centered on t′

depending on the separation between the central time t′

−

L. J. Goicoechea et al.: QSO size ratios

27

values of q and t0, the number of possible [FR(ti),FV (t′
some V –band bins may be empty. The χ2 estimator is given by

i)] pairs is less or equal to NR, since

2

χ

(a, b, t0, q) =

N

[FR(ti)
a
−
−
R + b2σ2
σ2

V i

bFV (t′

i)]2

N

1

4

−

i=1
X
NR), FV (t′

,

(A.1)

where N is the number of RV pairs (N

≤

selection factors Sij are

i) = [

j SijFV (tj )]/

j Sij, the weight–

P

P

t′
i −
α

|

1

−

tj|

,

if

0,

if

Sij = 


t ′
i −
t ′
i −

|

|

tj

tj

α,

| ≤

> α,

|

and the uncertainties in the ﬂuxes FV (t′

i) are



σ2
V i =

ijσ2
j S2
j Sij )2 .

V

(
P

(A.2)

(A.3)

P
In principle, the χ2 estimator is a function of four parameters (a, b, t0, q). However, as the

parameter a is entered in Eq. (A.1) in a simple way, it is possible to obtain an analytical constraint
a = a(b, t0, q) from the minimization condition ∂χ2/∂a = 0. One ﬁnds a = P

bQ, where

−

P =

N

"

i=1
X

N

and

FRi
R + b2σ2
σ2

V i #

/

1
R + b2σ2
σ2

V i #

,

N

"

i=1
X

N

Q =

FV i
R + b2σ2
σ2

/

1
R + b2σ2
σ2

.

V i #
Thus, we search for the minimum of χ2 in a 3D parameter space, i.e., we minimize the function
χ2 = χ2[a(b, t0, q), b, t0, q].

i=1
X

i=1
X

V i #

"

"

(A.4)

(A.5)

A.2. Minimum dispersion method

Our R–band data are modelled as FRi = s(ti) + ǫR(ti). Here, s and ǫR denote the true R–

band signal and the unknown R–band errors, respectively. In a consistent way (see Eqs. 6 and

8), the V –band data should be modelled as FV j =

s[tj/q + (1

{

1/q)t0]

a

}

−

−

/b + ǫV (tj).

These two series are combined into one for every ﬁxed value of an offset a, an ampliﬁcation b, a

characteristic time t0 and a dilation factor q. In the combined serie, NR data are the FRi values at
times ti, whereas the rest of data (NV ) are the a + bFV j values at dates t′

1/q)t0.

j = tj/q + (1

−

Each combined curve includes NR + NV ﬂuxes and times. The dispersion of the combined curve

is

2

D

(a, b, t0, q) =

NR
i=1

NV

j=1 Sij Wij (FRi −

a

bFV j)2

,

−

NR
i=1

NV
j=1 SijWij

P

P

where Sij are weight–selection factors deﬁned by
P

P

t′
j|

,

|

ti −
δ

1

−

if

0,

if

ti

ti

|

|

−

−

Sij = 




δ,

t ′
j | ≤
t ′
j |

> δ,

(A.6)

(A.7)

28

L. J. Goicoechea et al.: QSO size ratios

and Wij = 1/(σ2
V ) are the statistical weights. We note that all the (i,j) pairs have equal
statistical weight, and in this special case, the Wij factors do not play a role in the D2 estimator.

R + b2σ2

The main difference between the old problem (estimation of the best time delay) and the new one

(estimation of the best source size ratio) lies in the dilation factor that is absent in delay studies.

In the minimization process, one can also reduce the dimension of the parameter space (see

the end of section A.1). We search for the minimum dispersion in a 2D parameter space, since

there are analytical constraints a = a(t0, q) and b = b(t0, q). These constraints are inferred from
the system of equations: ∂D2/∂a = ∂D2/∂b = 0. In a straightforward way, the system leads to

a = P

−

bQ and b = (X

P Q)/(S

−

−

Q2), being

P =

SijFRi/

Sij,

i
X

j
X

i
X

j
X

Q =

SijFV j/

Sij ,

i
X

j
X

i
X

j
X

S =

SijF 2

V j/

Sij ,

i
X

j
X

i
X

j
X

X =

Sij FRiFV j/

Sij.

i
X

j
X

i
X

j
X

(A.8)

(A.9)

(A.10)

(A.11)

A.3. Minimum modiﬁed dispersion method

We also propose a modiﬁed dispersion. The basic difference lies in the fact that we do not use
the usual terms (FRi −
The new estimator has an expression

bFV j)2, but the normalized ones (FRi −

bFV j)2/(σ2

R + b2σ2

V ).

−

−

a

a

ǫ2(a, b, t0, q) =

NR
i=1

P

P

NV

j=1 SijWij (FRi −
NV
j=1 Sij

NR
i=1

bFV j)2

a

−

.

(A.12)

The ǫ2 estimator depends on four parameters: a, b, t0 and q, but we can use some constraints and
P
simplify the 4D minimization process. From ∂ǫ2/∂a = 0, it is inferred the relationship

P

a =

i

P

P

j Sij(FRi −
j Sij

i

bFV j)

.

(A.13)

P
If we denote the averages of the light curves as

P

P =

SijFRi/

Sij , Q =

SijFV j/

Sij,

(A.14)

i
X
then the expression for the parameter a takes the simple appearance

j
X

j
X

i
X

j
X

i
X

i
X

j
X

−
Using ∂ǫ2/∂b = 0, it is derived a second interesting constraint. The new constraint can be written

a = P

bQ.

(A.15)

as

Sij(FRi −

a

−

bFV j)

(cid:0)

i
X

j
X

bσ2

V FRi + σ2

RFV j

= 0.

(cid:1)

(A.16)

L. J. Goicoechea et al.: QSO size ratios

29

In order to simplify the expression (A.16), we introduce the deviations of the ﬂuxes from the

averages. Thus,

δFRi = FRi −

P, δFV j = FV j −

Q.

(A.17)

From Eqs. (A.15), (A.16) and (A.17), we ﬁnally obtain

2

2
σ
V

b

−

i
X

j
X

SijFRiδFV j + b

2
σ
V





i
X

j
X

Sij FRiδFRi −

2
R

σ

σ2
R

i
X

j
X

i
X

j
X

+

SijFV jδFV j


Sij FV jδFRi = 0.

(A.18)

Now it is clear that one can work in a 2D parameter space. For a given pair (t0,q), through Eqs.
(A.15) and (A.18), we can straightway derive the solutions (a,b) that minimize the ǫ2 estimator.

