1

Learning-based Prediction, Rendering and
Transmission for Interactive Virtual Reality in
RIS-Assisted Terahertz Networks

Xiaonan Liu, Student Member, IEEE, Yansha Deng, Member, IEEE, Chong Han, Member, IEEE,
and Marco Di Renzo, Fellow, IEEE

1
2
0
2

l
u
J

7
2

]
P
S
.
s
s
e
e
[

1
v
3
4
9
2
1
.
7
0
1
2
:
v
i
X
r
a

Abstract—The quality of experience (QoE) requirements of
wireless Virtual Reality (VR) can only be satisﬁed with high
data rate, high reliability, and low VR interaction latency. This
high data rate over short transmission distances may be achieved
via abundant bandwidth in the terahertz (THz) band. However,
THz waves suffer from severe signal attenuation, which may
be compensated by the reconﬁgurable intelligent surface (RIS)
technology with programmable reﬂecting elements. Meanwhile,
the low VR interaction latency may be achieved with the mobile
edge computing (MEC) network architecture due to its high
computation capability. Motivated by these considerations,
in
this paper, we propose a MEC-enabled and RIS-assisted THz
VR network in an indoor scenario, by taking into account the
uplink viewpoint prediction and position transmission, MEC
rendering, and downlink transmission. We propose two methods,
which are referred to as centralized online Gated Recurrent
Unit (GRU) and distributed Federated Averaging (FedAvg), to
predict the viewpoints of VR users. In the uplink, an algorithm
that integrates online Long-short Term Memory (LSTM) and
Convolutional Neural Networks (CNN) is deployed to predict the
locations and the line-of-sight and non-line-of-sight statuses of
the VR users over time. In the downlink, we further develop
a constrained deep reinforcement learning algorithm to select
the optimal phase shifts of the RIS under latency constraints.
Simulation results show that our proposed learning architecture
achieves near-optimal QoE as that of the genie-aided benchmark
algorithm, and about two times improvement in QoE compared
to the random phase shift selection scheme.

Index Terms—Terahertz transmission, reconﬁgurable intelli-
gent surface, constrained deep reinforcement learning, convolu-
tional neural network, virtual reality.

I. INTRODUCTION

Wireless virtual reality (VR) can be a potential solution
in breaking geographical boundaries, providing the VR users
with a sense of total presence and immersion under VR
interaction latency, and may unleash plenty of novel VR
applications [1]. To achieve this vision, we still face unique
challenges, including how to support real-time VR interaction
under low interaction latency (in the order of tens of mil-
liseconds), high resolution 360 degree VR video transmission
under high data rates, seamless connectivity for moving VR

X. Liu and Y. Deng are with the Department of Engineering, King’s
(e-mail:{xiaonan.liu, yan-

College London, London, WC2R 2LS, U.K.
sha.deng}@kcl.ac.uk). (Corresponding author: Yansha Deng).

C. Han is with Terahertz Wireless Communications (TWC) Laboratory,

Shanghai Jiao Tong University, China. (e-mail:{chong.han}@sjtu.edu.cn).

M. Di Renzo is with Universit´e Paris-Saclay, CNRS, CentraleSup´elec,
Laboratoire des Signaux et Syst`emes, 3 Rue Joliot-Curie, 91192 Gif-sur-
Yvette, France. (marco.di-renzo@universite-paris-saclay.fr)

users even under unstable wireless channels, and satisfy the
asymmetric and coupled uplink and downlink requirements
[2].

To address the above challenges, terahertz (THz) commu-
nication can be a promising enabler for high rate, high relia-
bility, and low VR interaction latency [3]. However, the THz
transmission suffers from severe propagation attenuation and
water-molecular absorption loss because of its high frequency,
which limits the propagation distance [4]. That is the reason
why the THz communication system is usually deployed in
an indoor scenario. Note that the indoor environment can be
complex with physical obstacles, such as walls and furniture,
which may block the line-of-sight (LoS) communication links
[5], [6].

To address the severe path attenuation of THz and sup-
port transmission for users in non-line-of-sight (NLoS) areas,
reconﬁgurable intelligent surface (RIS) can be an effective
approach to create a second virtual LoS path and enhance the
coverage [7]–[11]. The RIS is a planar surface that consists of
a number of small-unit reﬂectors, and is equipped with a low-
cost sensor and controlled with a simple processor. Each re-
ﬂecting element of the RIS can reﬂect incident electromagnetic
waves independently with an adjustable phase shift. Through
deploying the RIS in the THz network and smartly adjusting
the phase shift of all the elements, the THz signals between
the transmitters and receivers can be reconﬁgured ﬂexibly to
support the THz transmission for the users in NLoS areas
[12]–[14].

It is important to note that the VR interaction latency, which
is composed of the uplink transmission latency, the rendering
latency, and the downlink transmission latency, is also one
of the key requirements in VR service. Violating the VR
interaction latency constraint can lead to motion sickness and
discomfort [2]. Rendering real-time high quality VR videos
via a computing unit with high processing capabilities can be
a potential solution to reduce the VR interaction latency. To do
so, mobile edge computing (MEC) can be introduced to shift
the heavy VR video computation load from the VR device to
the MEC server [15].

Motivated by the above, in this paper, we focus on opti-
mizing the QoE of VR users in a MEC-enabled and RIS-
assisted THz VR network in an indoor scenario, and we
develop a novel learning strategy to efﬁciently optimize the
long-term QoE in THz VR systems. The main contributions
are summarized as follows:

 
 
 
 
 
 
• We propose a MEC-enabled and RIS-assisted THz VR
network in an indoor scenario, taking into account the
uplink transmission, MEC rendering, and downlink VR
video transmission.

• In the uplink, we use a two-ray uplink transmission to
deliver the actual viewpoints or learning models to the
MEC. Based on the historical and current viewpoint of
the VR user from real VR datasets [16], we propose
two methods, which are referred to as the centralized
online Gated Recurrent Unit (GRU) algorithm and the
distributed Federated Averaging (FedAvg) algorithm, to
predict the dynamical viewpoint preference of the VR
users over time. By doing so, the predicted ﬁeld of view
(FoV) can be rendered and transmitted in advance, with
the aim to reduce the VR interaction latency.

• We also propose an algorithm that integrates online Long-
Short Term Memory (LSTM) and Convolutional Neural
Networks (CNN) to predict the new positions of the VR
users based on their historical positions delivered via the
uplink, which are then used to predict the LoS or the
NLoS status of the VR users.

• With the predicted viewpoint and the LoS/NLoS status
of each VR user as the inputs, we propose a constrained
Deep Reinforcement Learning (C-DRL) algorithm to
optimize the long-term QoE of VR users under VR
interaction latency constraints, by selecting the optimal
phase shifts of the RIS reﬂecting elements. Through com-
parison with non-learning-based methods, we show that
our proposed ensemble learning architecture with GRU,
LSTM, CNN, and C-DRL achieves near optimal QoE
similar to that offered by an exhaustive-search algorithm,
and enhances of about two times the QoE compared to
the random phase shift selection scheme.

The rest of this paper is organized as follows. Section II
presents the related works. The system model and problem
formulation are proposed in Section III. The learning algo-
rithms for THz VR systems are presented in Section IV. The
simulation results and conclusions are described in Section V
and Section VI, respectively.

II. RELATED WORKS

In this section, related works on THz VR systems, RIS-
assisted THz networks, and MEC-enabled wireless VR net-
works are brieﬂy introduced in the following three subsections.
1) Wireless VR/AR system in THz: In [17]–[20], the re-
liability, transmission rate, viewpoint rendering, and energy
consumption of a THz VR/AR system were investigated.
Speciﬁcally, in [17], the reliability of VR services in the THz
band was studied, and the theoretical analysis of the end-to-end
(E2E) delay was performed. In [18], a risk-based framework
was proposed to optimize the rate and reliability of THz-band
for VR applications. In [19], through jointly optimizing the
viewport rendering ofﬂoading and downlink transmit power
control, the long-term energy consumption of a THz wireless
access-based MEC system for high quality immersive VR
video services was minimized. In [20], the age of information
(AoI) of AR services in a THz cellular network with RISs was

2

studied, and the cumulative distribution function (CDF) of the
AoI was derived for two different scheduling policies, which
are the last come ﬁrst served (LCFS) queues and the ﬁrst come
ﬁrst served (FCFS) queues. However, in [17], [18], and [20],
the authors mainly focused on the theoretical analysis of the
reliability and E2E delay of the THz VR/AR. In [19], the
authors mainly optimized the long-term energy consumption
via deep reinforcement learning, rather than the QoE and VR
interaction latency, without the consideration of RIS.

2) RIS-assisted THz network: In [21]–[29], the sum rate
maximization problem in RIS-assisted THz network was in-
vestigated. Speciﬁcally, in [21], based on channel estimation,
a deep neural network (DNN) was proposed to select the
optimal phase shift conﬁgurations to maximize the sum rate in
the RIS-assisted THz multiple-input multiple-output (MIMO)
system. In [22], through optimizing the beamforming vector
of the transmitter and reﬂection coefﬁcients matrix of the
RIS, the coverage probability in indoor THz communication
scenarios was improved, and a low complexity phase shift
search scheme was used to achieve near-optimal coverage
performance. In [23], energy-efﬁcient designs for both the
transmit power allocation and the phase shifts of the RIS sub-
ject to downlink multi-user communication were developed.
In [24], the downlink of an RIS-empowered multiple-input
single-output (MISO) communication system was considered,
where the alternating least squares and vector approximate
message passing methods were used to estimate channels
between the base station (BS) and the RIS, as well as the
channels between the RIS and users. In [25], RIS-assisted
secure wireless communications were investigated, and the
successive convex approximation-based algorithm was used
to solve the transmit covariance matrix optimization problem,
which maximized the secrecy rate. In [26],
the network
architecture and spectrum access of AI-enabled Internet of
Things in 5G and 6G networks were proposed. In [27], a
comprehensive roadmap outlining the seven deﬁning features
of THz wireless systems that guarantee a successful deploy-
ment in future wireless generations was proposed. In [28] and
[29], a novel hybrid beamforming scheme for multi-hop RIS-
assisted communication networks was proposed to improve the
coverage range of THz networks. Nevertheless, in [21]–[29],
the authors mainly optimized the phase shift and beamforming
vector to maximize the sum rate of RIS-assisted THz networks
using a DNN or non-learning based approaches.

3) MEC-enabled wireless VR network: In [30] and [31],
a joint caching and computing optimization problem was
formulated to minimize the average transmission rate and
maximize the average tolerant delay, respectively. In [32],
through effectively exploiting the characteristics of multi-
quality tiled 360 VR videos and computation resources, the
optimal wireless streaming of a multi-quality tiled 360 VR
video to multiple users in wireless networks was investigated
to decrease the energy consumption. In [33], a decoupled
learning strategy was developed to optimize the real-time VR
video streaming in wireless networks, by taking into account
the FoV prediction and rendering MEC association. Through
the design of centralized/distributed deep reinforcement learn-
ing algorithms to select proper MECs to render and transmit

3

Fig. 1. Wireless VR system in THz network.

predicted VR video frames, the QoE was enhanced and the
VR interaction latency was reduced. However, the authors of
[30]–[32] mainly used convex optimization to optimize the
wireless VR network, which can not guarantee the long-term
QoE of the VR users. The authors of [33] only considered the
MEC association problem without using real VR datasets.

III. SYSTEM MODEL AND PROBLEM FORMULATION

We consider an indoor scenario, where an RIS that com-
prises N reﬂecting elements is deployed to assist the uplink
and downlink transmission between a MEC and K VR VR
users, as shown in Fig. 1. The MEC operating over THz
frequency is equipped with M antennas1 and each VR user
is equipped with a single antenna, respectively. The indoor
scenario is assumed to be a square with length W of each side.
The RIS is connected to a smart controller that communicates
with the MEC via a wired link for cooperative transmission
and information exchange, such as channel state information
(CSI), and phase shifts control of all reﬂecting elements [34].
Due to the substantial path loss in THz transmission, we only
consider the THz signal reﬂected by the RIS for the ﬁrst time
and ignore the signals that are reﬂected for twice or more
times following [35].

A. VR User Mobility

We present a mobility model based on the VR user move-
ments in the indoor VR scenario, which is the so-called virtual
reality mobility model (VRMM) [36]. The VRMM includes
the following parameters: start location, destination location,
speed, and moving direction. We assume that there are four
directions for the VR user to select, namely, up, down, left,
and right. We split the indoor area into W × W grids. When
the VR user is at the start location, it sets its destination
location, speed, and moving direction, and transmits its current
location at each time slot to the MEC server through uplink

1Physically, the MEC and SBS are co-located in one location.

Fig. 2.

Illustration of THz network in the presence of obstacles.

transmission. Note that the location of the VR user for the
next time slot is determined by the location of the current
time slot rather than the locations in previous time slots, so
that the mobility of the VR user in the indoor area follows the
Markov property. When the VR user arrives at the destination
location, it sets a new destination location and moves forward
to it with a given speed.

B. Indoor Blockage

Due to the severe signal attenuation and narrow wave spread
in THz frequencies, the THz transmission is very sensitive to
the presence of obstacles [37]. When the VR users are moving
in an indoor scenario, the blockage between the MEC and the
kth VR user can be caused by an obstacle and the other VR
users with higher heights that are located near to the kth VR
user. For simplicity, we map the 3D indoor scenario into a 2D
image. In Fig. 2, when VR users are behind the obstacle, they
are directly blocked by the obstacle. As shown in Fig. 3, we
assume that the height of the MEC is hA, the height of the
VR user 2 is hB (hB < hA), the height of the VR user 1
is hU (hU < hB), the distance between the VR user 2 with
height hB and the MEC is l, and the distance between the VR
user 1 with height hU and the MEC is x.

Deﬁnition 1: When the MEC server, the VR user 2, and
the VR user 1 are located in the same line in the 2D plane,
the VR user 1 will be blocked by the VR user 2 if its distance
in the 2D plane is less than (hA−hU )l
hA−hB

.

Proof. According to Fig. 3, the coordinates of the MEC, the
VR user 2, and the VR user 1 in the 2D plane are denoted
as (0, hA), (l, hB), and (x, hU ), respectively. Applying slope-
intercept equation, we can calculate the line equation across
the point (0, hA) and (l, hB) as

y =

hB − hA
l

x + hA.

(1)

For y = hU , x is computed as (hA−hU )l
. Thus, the distance
hA−hB
between the VR user 2 and the VR user 1 is computed as
(hB −hU )l
hA−hB
Due to the blockage caused by the obstacles, such as pillars,
walls, or other VR users, the THz transmission between the

.

RISRISMECMECRIS ControllerRIS ControllerObstacleVR UserOptical FiberDesired SignalOptical FiberDesired SignalOptical FiberDesired SignalBlockedNLoSNLoSLoSMECRISObstacleNLoS AreaNLoS Area4

symbol of the kth VR user, and is set as discrete ran-
dom variable with zero mean and unit variance, gup
k (t) ∈
CN ×1 is the channel matrix between the kth VR user and
the RIS, Gup(t) ∈ CM ×N is the channel matrix between
the RIS and the MEC, and nup
k (t) is the additive white
Gaussian noise of the kth VR user with zero mean and
k variance. Meanwhile, (cid:80)KVR
i (t)xup
k (t)hup
ˆσ2
i (t) and
(cid:80)KVR
k (t)Gup(t)Θup(t)gup
i=1,i(cid:54)=k uH
i (t) are the interfer-
ences from the LoS and NLoS links of other VR users,
respectively. Let θ = [θ1, ..., θN ] denote the selected phase
shift set of N reﬂection elements, where θn ∈ [0, 2π] denotes
the phase shift of the nth reﬂecting element of the RIS, which
can be carefully adjusted by an RIS controller. Here, the
reﬂection coefﬁcients matrix Θup(t) is presented as

i=1,i(cid:54)=k uH
i (t)xup

Θup(t) = diag(ejθup

1 (t), ..., ejθup

N (t)).

(3)

For practical implementation, we assume that the phase shift
of each element of the RIS can only take a ﬁnite number
of discrete values. We set b as the number of bits used to
indicate the number of phase shift levels ˆL, where ˆL = 2b.
For simplicity, we assume that such discrete phase-shift values
can be obtained by uniformly quantizing the interval [0, 2π).
Thus, the set of discrete phase shift values at each element is
given by

F = {0, (cid:52)θ, ..., ( ˆL − 1)(cid:52)θ},

(4)

where (cid:52)θ = 2π/ ˆL [35]. Now, the uplink transmission rate of
the kth VR user at the tth time slot is calculated as
k (t) + Gup(t)Θup(t)gup
k (t)(hup

k (t))|2

|uH

Rup

k (t)=log2

I+

Iup
k (t) + ˆσ2

kIM

(cid:12)
(cid:12)
(cid:12)
(cid:12)

,

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(5)

where IM is the identity matrix, and

KVR
(cid:88)

Iup
k (t)=

i=1,i(cid:54)=k

|uH

k (t)(hup

i (t) + Gup(t)Θup(t)gup

i (t))|2.

(6)

According to (5), the uplink transmission rate of the VR user
in the LoS area is determined by both the LoS and NLoS links.
The uplink transmission rate of the kth VR user in the NLoS
area is only affected by the NLoS link, and uH
k (t) = 0.

k (t)hup

D. VR Viewpoint Prediction

By predicting the viewpoint preference of the VR user with
centralized online GRU algorithm or distributed FedAvg algo-
rithm, the corresponding FoV can be rendered and transmitted
in advance in order to decrease the VR interaction latency.
When the VR user watches the VR video frames, the viewpoint
is determined by three degrees of freedom, which are X, Y ,
and Z axes. Thus, predicting the viewpoint of the VR user
can be converted to predicting the X, Y , and Z angles. We
consider a sliding window to predict the viewpoint of the VR
user in continuous time slots. The future viewpoint of the
VR user can be predicted according to the current and past
rotation statuses. To guarantee the prediction accuracy, we use
the online GRU algorithm to predict the viewpoint of the VR
user at each time slot. Speciﬁcally, we use Mean Square Error

Fig. 3. Illustration of a single THz transmission link in the presence of blocker
via other VR user with higher height.

MEC server and the VR users can be enhanced by the RIS,
where each passive reﬂecting element can change the phase
shift of the THz wave [22]. In our model, we deﬁne the MEC-
VR user link as the line-of-sight (LoS) link, and the MEC-
RIS-VR user link as non-LoS (NLoS) link. It is important to
note that through obtaining the current and historical locations
and LoS/NLoS statuses of the VR users, the MEC server can
predict the LoS/NLoS statuses of the VR users at each time
slot.

C. THz Uplink Transmission

At the start of each time slot, the VR user transmits its actual
viewpoint and location to the MEC via uplink transmission.
Because of the mobility of the VR user, it may enter the LoS
or NLoS region. To guarantee the reliability of the uplink
transmission, we consider a two-ray uplink transmission. One
ray is the LoS link, and the other is the NLoS link. For the
VR user in the LoS region, the received signals include the
ones from LoS and NLoS links. While for the VR user in the
NLoS region, the received signal only includes the signal from
the NLoS link. For the kth VR user, the transmitted two-ray
signals through the uplink transmission at the tth time slot are
denoted as

k (t)+

k (t)xup
k (t)hup
yup
k (t) =uH
k (t)Gup(t)Θup(t)gup
uH
KVR
(cid:88)

k (t)hup
uH

i (t)xup

i (t)+

k (t)xup

k (t)+

(2)

i=1,i(cid:54)=k

KVR
(cid:88)

k (t)Gup(t)Θup(t)gup
uH

i (t)xup

i (t) + nup

k (t),

i=1,i(cid:54)=k

k (t) ∈ C1×M is the beamforming vector of the
where uH
the tth time slot, which can be denoted
kth VR user at
k (t)
k (t)(cid:107) [38]. In (2), hup(t) ∈ CM ×1
as
is the channel vector between the MEC and the kth VR
k (t) is the transmitted data
user at

hup
k (t)+Gup(t)Θup(t)gup
k (t)+Gup(t)Θup(t)gup
(cid:107)hup

the tth time slot, xup

hAxhBhUBlocking humansNon-blocking humansLoS pathVR User 1MEChAxhBhUBlocking humansNon-blocking humansLoS pathVR User 1MEClVR User 2(MSE) as the cost function in each training step to update the
parameters of the online GRU model, which is calculated as

MSEk

t =

1
K VR

KVR
(cid:88)

k=1

( ˆV k

t − V k

t )2,

(7)

t , Y k

t , Z k

t , ˆY k

t , ˆZ k

t = (X k

t = ( ˆX k

where ˆV k
t ) and V k
t ) are the
predicted and actual viewpoint of the kth VR user at the tth
time slot, respectively. At the (t − 1)th time slot, the MEC or
the VR device will predict the viewpoint ˆV k
t of the kth VR
user for the tth time slot. Then, the kth VR user will transmit
its actual viewpoint V k
t or the learning model to the MEC
via uplink transmission. By comparing it with the predicted
viewpoint, the parameters of the online GRU algorithm are
updated, which can further improve the prediction accuracy.

E. MEC Rendering

When the VR users enjoy the VR video frames, the cor-
responding portion of the sphere is rendered at the MEC
based on the predicted viewpoint. Through equirectangular
projection (ERP) mapping [39], a stitched 2D image with RGB
color model is rendered into the required FoV. We assume that
the resolution of the FoV is Np × Nv, and the size of each
pixel is 8 bits. The size of the FoV in RGB model is calculated
as

C = 3 × 8 × Np × Nv × V,

(8)

where 3 represents the red, green, and blue color in RGB
model, and V = 2 is the number of viewpoints for two eyes.
We assume that the execution ability of the GPU of the MEC is
FMEC, and the number of cycles required for processing one
bit of input data in the MEC is fMEC. The MEC rendering
latency is calculated as

Trender =

fMECC
FMEC

.

(9)

From (9), we can obtain that the rendering latency for all VR
users is the same.

F. THz Downlink Transmission

In the THz downlink transmission, it is possible that VR
users may be blocked by the obstacles or VR users with higher
heights, as shown in Fig. 2 and Fig. 3. For the VR users that
are not blocked by obstacles and other VR users, the MEC
directly performs transmission in LoS channel, otherwise, it
is served by NLoS channel aided by the RIS [40]–[42].

We consider a multi-input single-output (MISO) THz chan-
nel. We use the sets VLoS and VNLoS to denote the LoS and
NLoS VR user groups, respectively. For the kth VR user in
the LoS group, the received signal from the MEC at the tth
time slot is denoted as

yLoS
k

(t) = hH
k (t)vLoS
(t)xLoS
k
k
(cid:88)
hH
k (t)vLoS
i

(t)+
(t)xLoS
i

(t)+

i(cid:54)=k,i∈VLoS
(cid:88)
hH
k (t)vNLoS
j

j∈VNLoS

(t)xNLoS
j

(t) + nk(t),

(10)

5

j

j

k

k

(t) can be denoted as

(t) ∈ CM ×1 and vNLoS

where hk(t) ∈ CM ×1 is the channel vector between the MEC
and the kth VR user, vLoS
(t) ∈
CM ×1 are the beamforming vectors of the kth VR user in
the LoS group, and the jth VR user in the NLoS group,
hk(t)
respectively. In (10), vLoS
(cid:107)hk(t)(cid:107) , and
xLoS
(t) and xNLoS
(t) indicate the transmitted data symbol
k
for the kth VR user in the LoS group and the jth VR
user in the NLoS group, respectively, and are deﬁned as
discrete random variable with zero mean and unit variance.
We assume that xLoS
(t) are independent from
each other. Meanwhile, (cid:80)
hH
k (t)vLoS
(t) and
(cid:80)
hH
k (t)vNLoS
(t) are the interference from
j
the MEC. In addition, nk(t) ∼ CN (0, σ2
kIM ) is the additive
white Gaussian noise at the kth VR user in the LoS group.
The transmission rate between the MEC and the kth VR user
in the LoS group at the tth time slot is expressed as

(t) and xNLoS

(t)xNLoS
j

(t)xLoS
i

i(cid:54)=k,i∈VLoS

j∈VNLoS

k

j

i

(cid:32)

RLoS
k

(t) = log2

1 +

(cid:33)

(t)|2

|hH

k (t)vLoS
ILoS
k

(t) + σ2
k

k

,

(11)

where

ILoS
k

(cid:88)

(t)=

|hH
i∈VLoS,i(cid:54)=k

k (t)vLoS
i

(t)|2 +

(cid:88)

|hH

k (t)vNLoS
j

(t)|2.

(12)

j∈VNLoS

For the VR users in the NLoS group, the signal between
the MEC and the bth VR user at the tth time slot is presented
as

yNLoS
b

b (t)Θdown(t)Gdown(t)vNLoS
(t) = gH
b (t)Θdown(t)Gdown(t)vNLoS
gH

b

j

(cid:88)

j(cid:54)=b,j∈VNLoS

(t)xNLoS
b
(t)xNLoS
j

(t)+

(t) + nb(t),

(13)

where Gdown(t) ∈ CN ×M is the channel matrix between the
MEC and the RIS, gb(t) ∈ CN ×1 is the channel matrix
(t) ∈ CM ×1 is
between the RIS and the bth VR user, vNLoS
the precoding matrix for the bth VR user in the NLoS group,
which can be written as Gdown(t)H Θdown(t)gk(t)
(t)
is the transmitted data for the bth VR user, Θdown(t) is the
reﬂection coefﬁcients matrix of the RIS. Note that Θdown(t)
is written as

(cid:107)Gdown(t)H Θdown(t)gk(t)(cid:107) , xNLoS

b

b

Θdown(t) = diag(ejθdown

1

(t), ..., ejθdown

N (t)),

(14)

is

the

and nb(t)
the bth VR user with zero mean and σ2
(cid:80)

additive white Gaussian noise of
k variance.
b (t)Θdown(t)Gdown(t)vNLoS
gH
(t) is the
interference from the RIS. Then, the downlink transmission
rate of the bth VR user in the NLoS group is written as

(t)xNLoS
j

j(cid:54)=b,j∈VNLoS

j

(cid:32)

RNLoS
b

(t) = log2

1 +

|gH

b (t)Θdown(t)Gdown(t)vNLoS

b

INLoS
b

(t) + σ2
b

(cid:33)

(t)|2

,

(15)

where

INLoS
b

(t) =

(cid:88)

|gH

b (t)Θdown(t)Gdown(t)vNLoS

j

(t)|2.

(16)

j(cid:54)=b,j∈VNLoS

6

For the NLoS transmission, the THz channels between the

MEC and the RIS are denoted as

Gup(t) = ηGNLoS
f,dM−I

(t)aNLoS
φMEC

(t)aNLoS
φRIS

(t)H ,

(21)

and

Gdown(t) = ηGNLoS
f,dM−I

(t)aNLoS
φRIS

(t)aNLoS
φMEC

(t)H ,

(22)

where η is the path-loss compensation factor written as
√

2

πf GRISN

η =

c

.

(23)

In (23), N is the number of elements on the RIS, and GRIS
is the RIS element gain. The channel function GNLoS
(t) is
f,dM−I
written as

GNLoS
f,dM−I

(t) =

c
4πf dM−I

τ (f )dM−I
2

e−

e−j2πf δNLoS,M-I(t),

(24)

where dM−I is the distance between the MEC and the RIS,
δNLoS,M-I(t) = dM−I
is the time-of-arrival of the NLoS propa-
gation between the MEC and the RIS. The normalized antenna
array response vectors aNLoS
(t) of
φRIS
the MEC are written as

(t) of the RIS and aNLoS
φMEC

c

aNLoS
φRIS

(t) =

1
√
N

[1, ej 2π

λ sin (φRIS), ..., ej 2π

λ (N −1) sin (φRIS)]H ,

(25)

and

aNLoS
k,φMEC

(t)=

1
√
M

[1, ej 2π

λ sin (φMEC), ..., ej 2π

λ (M −1) sin (φMEC)]H,

(26)
respectively. In (25) and (26), φRIS and φMEC are AoD or
AoA, repectively. The THz channel between the RIS and the
bth VR user is given by

˜gb(t) = gNLoS
(t)aNLoS
f,db
φb
b (t), gb(t)}, the channel function gNLoS
f,db

(t),

(27)

(t)

where ˜gb(t) = {gup
is written as

gNLoS
f,db

(t) =

c
4πf db

e− τ (f )db

2

e−j2πf δNLoS,b(t),

(28)

db is the distance between the RIS and the bth VR user, and
aNLoS
φb

(t) is written as

aNLoS
φb

(t) =

1
√
N

[1, ej 2π

λ sin (φb), ..., ej 2π

λ (N −1) sin (φb)]H .

(29)

H. Quality of Experience Model

The QoE of the wireless VR video frame streaming can
be inﬂuenced by several factors, including video quality, VR
interaction latency, and smoothness of the VR video frame
[44]. The success of the uplink transmission will further affect
the prediction of the viewpoint and the status of LoS or NLoS
of the VR user. We use unit-impulse function ˆδk(t) to denote
the success of the viewpoint prediction, which is expressed as

ˆδk(t) =

(cid:40)

t = V k
t ;

if ˆV k
1,
0, otherwise.

(30)

where ˆV k
t ) and V k
t ) are the
predicted and actual viewpoint of the kth VR user at the tth

t = ( ˆX k

t = (X k

t , ˆZ k

t , ˆY k

t , Z k

t , Y k

Fig. 4.

Illustration of THz channel model in the presence of obstacles.

G. THz Channel Model

The THz channel model in the presence of obstacles is
shown in Fig. 4. In THz communication, the power of the
scattering component is generally much lower than that of
LoS component. Thus, we ignore the scattering component,
and the LoS channel is expressed as

˜hk(t) = hLoS
f,dk

(t)aLoS
k,φk

(t),

(17)

where ˜hk(t) = {hup
function
hLoS(f, dk) consists of a spreading loss function and a molec-
ular absorption loss function, which is presented as

k (t), hk(t)}, LoS channel

hLoS
f,dk

(t) =

c
4πf dk

e− τ (f )dk

2

e−j2πf δLoS,k(t),

(18)

where c is the speed of light. Assuming that the RIS can be
installed on the wall or ceiling of the indoor scenario with
height H, the location of the reﬂecting unit can be presented
as LRIS = [XRIS, YRIS, HRIS]. The location of the MEC can
be denoted as LMEC = [XMEC, YMEC, HMEC]. The location
of the kth VR user can be written as Lk = [Xk, Yk, Hk]. The
distance between the MEC and the kth VR user is denoted as
dk, which is calculated as
dk = (cid:112)(XMEC − Xk)2 + (YMEC − Yk)2 + (HMEC − Hk)2,
(19)
f is the carrier frequency, and δLoS,k(t) = dk
is the time-of-
c
arrival of the LoS propagation of the kth VR user. τ (f ) is
the frequency-dependent medium absorption coefﬁcient that
depends on the molecular composition of the transmission
medium, namely, the type and concentration of molecules
found in the channel as deﬁned in [43]. In addition, aLoS
(t)
k,φk
is the normalized antenna array response vector at the MEC
with M antenna elements, which is written as

aLoS
k,φk

(t) =

1
√
M

[1, ej 2π

λ sin (φk), ..., ej 2π

λ (M −1) sin (φk)]H ,

(20)
where M is the number of antennas equipped in the MEC, λ is
the wavelength, and φk denotes the angles of departure/arrival
(AoD/AoA).

MECRISObstacleMECRISObstacleMECRISObstacleLoS SignalNLoS SignalΘ BlockedVR user with low heightVR user with high heightPhase Shift Matrixrd1d2t = V k

t , ˆδk(t) = 1,
time slot, respectively. In (30), if ˆV k
otherwise, ˆδk(t) = 0. According to [45] and [46], the QoE
of the kth VR user at the tth time slot is denoted as
QoEk(t) = ˆδk(t)(q(Rk(t))−|q(Rk(t))−q(Rk(t−1))|), (31)
where q(Rk(t)) is the VR video transmission quality metrics.
Here, due to [46], q(Rk(t)) is presented as
(cid:19)

q(Rk(t)) = log

,

(32)

(t)

(cid:18) Rdown
k
Rdown
th

th

where Rdown
is the downlink transmission threshold, and
|q(Rk(t))−q(Rk(t−1))| is the transmission quality variation,
which indicates the magnitude of the changes in the transmis-
sion quality from the (t − 1)th time slot to the tth time slot.
Note that the QoE model in (31) guarantees the seamless,
continuous, smoothness and uninterrupted experience of the
VR user.

I. Optimization Problem

To ensure that the requested FoV is rendered and transmitted
within the VR interaction latency, we aim to maximize the
long-term QoE of the RIS-aided THz transmission system by
optimizing the phase shift of the RIS reﬂecting element under
VR interaction latency constraint. At the tth time slot, the
VR interaction latency TVR consists of Tuplink, Trender, and
Tdownlink [2], which is written as

TVR(t) = Tuplink(t) + Trender(t) + Tdownlink(t),

(33)

where Tuplink(t) is the uplink transmission latency, and
Trender(t) is the MEC rendering latency. For the centralized
online GRU, the size of the uplink data is small, and the
uplink transmission latency is negligible. It is important to
the size of FoV does not change for different
know that
viewpoints,
the rendering latency remains the same.
thus,
the VR interaction constraint condition can be
Therefore,
converted to downlink transmission latency constraint. The
proposed THz VR system aims at maximizing the long-term
total QoE under the downlink transmission latency constraint
in continuous time slots with respect to the policy π that maps
the current state information St to the probabilities of selecting
possible actions in At. We formulate the optimization as

max
π(At|St)

∞
(cid:88)

K
(cid:88)

γi−tQoEk(i),

k=1

i=t
s.t. T k
downlink(i) ≤ T downlink

th

(34)

(35)

,

where γ ∈ [0, 1) is the discount factor which determines the
weight of the future QoE, and γ = 0 means that the agent
only considers the immediate reward. In (35), T k
downlink(t) is
the downlink transmission latency of the kth VR user at the tth
time slot, and T downlink
is the downlink transmission latency
constraint. Note that (35) guarantees the VR interaction latency
in each time slot under the VR interaction latency constraint.
the mobility of the VR user is
Markovian in continuous time slots,
the dynamics of the
THz VR system is a Partially Observable Markov Decision
Process (POMDP) problem, which is generally intractable.

Due to the fact

that

th

7

Here, the partial observation refers to that the MEC server
can only know the previous viewpoints and locations of the
VR users in the environment, while it is unable to know all
the information of the environment, including, but not limited
to, the channel conditions, and the viewpoint in the current
time slot. Meanwhile, the selected policy also needs to satisfy
the VR interaction threshold constraint. Thus, the problem
in (34) is a constrained MDP (C-MDP) problem that can be
transformed into the following form

min
ω≥0,µ≥0

max
π

∞
(cid:88)

K
(cid:88)

i=t

k=1

γi−tQoEk(i)−ω(T downlink

th

−T k

downlink(i)),

(36)
where ω is the Lagrangian multiplier, and π is the policy.
Due to the fact that the number of combinations of the phase
shift increases exponentially with the number of phase shift
levels of the RIS, the problem in (36) is the generalization
of large dimension C-MDP. To address this issue, we deploy
constrained deep reinforcement learning (C-DRL) to solve this
problem in (36) in Section IV.

Fig. 5. Learning strategy for MEC-enabled and RIS-assisted THz VR
networks.

IV. LEARNING ALGORITHMS FOR THZ VR SYSTEM

The deep neural network is one of the most popular non-
linear approximation functions, and C-DRL can effectively
solve C-MDP problem [47]. To solve the optimization problem
in (36), we propose a novel learning architecture based on
online GRU, online LSTM, CNN, and C-DRL, as shown in
Fig. 5. In particular, the online GRU and online LSTM are
integrated with CNN to predict the viewpoint preference and
LoS or NLoS status of each VR user in continuous time slots,
respectively. Using this information as inputs, the C-DRL is
deployed to select an optimal reﬂection coefﬁcient matrix for
THz downlink transmission.

[Vt-T0+1,…,Vt-1 ,Vt ]GRURelu[Lt-T0+1,…,Lt-1 ,Lt ]LSTMSoftmax[Lt-T0+1,…,Lt-1 ,Lt ]LSTMSoftmaxC-DRLCNNNetwork EnvironmentNetwork EnvironmentLoS/NLoSViewpoint Predictor LoS/NLoS PredictorError Loss ∆V Update GRU using loss ∆V Update LSTM using loss ∆L Error Loss ∆L Action At+1Reward Rt+1VtVt+1LtNew Observation Ot+1Lt+1 [Vt-T0+1,…,Vt-1 ,Vt ]GRURelu[Lt-T0+1,…,Lt-1 ,Lt ]LSTMSoftmaxC-DRLCNNNetwork EnvironmentLoS/NLoSViewpoint Predictor LoS/NLoS PredictorError Loss ∆V Update GRU using loss ∆V Update LSTM using loss ∆L Error Loss ∆L Action At+1Reward Rt+1VtVt+1LtNew Observation Ot+1Lt+1 Predicted LocationPredicted ViewpointActual LocationActual ViewpointA. Viewpoint Prediction

We use the centralized online GRU and distributed FedAvg
to predict the viewpoints of the VR users over time. The input
of the learning model is the actual viewpoints of the previous
time slots, and the output is the predicted viewpoint of the VR
user for the next time slot. For the centralized online GRU,
the VR user directly transmits its actual viewpoint to the MEC
through uplink transmission at each time slot, and then the
viewpoint is predicted based on the current and previous time
slots. The centralized online GRU for viewpoint prediction has
already been introduced in Section IV of [48] in detail.

For the federated learning among distributed VR devices,
each VR user predicts the viewpoint in its VR device in
continuous time slots based on the online GRU algorithm.
At each time slot, the updated learning model of each VR
user is delivered to the MEC for model aggregation via uplink
transmission, and the model aggregation at the MEC at the tth
time slot can be denoted as

¯θGRU
t =

K
(cid:88)

k=1

pkθGRU

k,t , and pk =

nk
n

,

(37)

where pk is the percentage of the number of data samples
of the kth device in the total number of data samples, nk
is the number of data samples of the kth VR user, and n
is the total number of data samples, which is calculated as
n = (cid:80)K
k=1 nk. Then, the aggregated model is transmitted to
each VR user through downlink transmission to predict the
viewpoint, and the predicted viewpoint is delivered to the MEC
for VR video frame rendering. Due to the fact that the size of
the learning model is much larger than that of the viewpoint,
the VR interaction latency may be increased.

B. LoS and NLoS Prediction

When VR users move in the indoor scenario following the
VRMM mobility model, they may be blocked by the VR users
with higher height or the obstacle. To predict the LoS or
NLoS status of each VR user in continuous time slots, we ﬁrst
employ an RNN model based on LSTM to predict the position
of the VR user [49]. Then, we map the indoor scenario into
a 2D image, label the positions of the MEC, the VR users,
and the obstacles with different colors, and deploy the CNN
to predict the LoS or NLoS status of each VR user.

t , O2

t , Y k

t , H k

t , ..., OK

1) Long-short Term Memory: To capture the dynamics in
mobility of the VR user for the (t + 1)th time slot, both
of the most recent observation Ot = {O1
t } and
the previous observations Ht = {Ot−To+1, ..., Ot−2, Ot−1}
given a memory window To are required, where Ok
t =
[X k
t ] is the actual location of the kth VR user at the
tth time slot. In the VRMM, we assume that there are four
moving directions, which are up, down, left and right, and can
be denoted as Du, Dd, Dl, and Dr, respectively. To detect the
the moving direction of the VR user over time, an RNN model
with parameters θRNN, and a LSTM architecture in particular,
is leveraged, where θRNN consists of both the LSTM internal
parameters and weights of each layer.

t = Lk

The online LSTM layer has multiple standard LSTM units
and receives current and previous observations at each time

8

slot via the two-ray uplink transmission, and is connected to
an output layer, which consists of a Softmax non-linearity
activation function with four output values. The four out-
the predicted probabilities P{Dt =
put values represent
{Du, Dd, Dl, Dr}|[O1
t , ..., OK
t ], θRNN} of the moving di-
rections for the tth time slot with historical observations
[O1

t , O2
To update the model parameter θRNN, a standard Stochastic
Gradient Descent (SGD) [50] via BackPropagation Through
Time (BPTT) [51] is used. At the (t + 1)th time slot, the
parameters θRNN are updated as

t , ..., OK
t ].

t , O2

t+1 = θRNN
θRNN

t − λRNN∇LRNN(θRNN

t

),

(38)

where λRNN ∈ (0, 1] is the learning rate, ∇LRNN(θRNN
the gradient of the loss function LRNN(θRNN
RNN predictor. Here, LRNN(θRNN
the cross-entropy loss as

) is
t
) to train the
) is obtained by averaging

t

t

(θRNN) = −

t
(cid:88)

log
t(cid:48) =t−Tb+1

LRNN
t

where

(cid:16)
P{Dt(cid:48) = ˆD|Ot

(cid:48)
t(cid:48) −T0

(cid:17)
, θRNN}

, (39)

ˆD={Du, Dd, Dl, Dr}, Ot

(cid:48)
t(cid:48) −T0

= [Ot(cid:48) −T0+1, ..., Ot(cid:48) −1, Ot(cid:48) ],

(40)

and Tb is the randomly selected mini-batch size.

By predicting the moving direction of each VR user, the
MEC is able to know the position of the VR user in the next
time slot in advance.

2) Convolutional Neural Network: Based on the predicted
positions of VR users, the MEC, obstacles, and the VR users
with different heights are labeled with different colors, and
mapped into a 2D image to be the input of the CNN. The
CNN predicts the LoS/NLoS status of each VR user based on
the input 2D image.

Fig. 6. Proposed CNN to classify the LoS or NLoS status of VR users.

The CNN is a multi-layer network evolved from the tra-
ditional neural network. The CNN mainly includes the input
layer, convolution layer, pooling layer, fully-connected layer,
and output layer. It is used for feature extraction and mapping
through fast training, and possesses high classiﬁcation and
prediction accuracy. We assume that the proposed CNN model
consists of one data input layer, Nc convolution layers, Np
pooling layers, Nf fully-connected layers, and one output
layer. Meanwhile, it is assumed that the size of the input image
is N0 × N0. The detailed description of each layer in the CNN
is introduced as follows:

(a) Data Input Layer: The MEC, obstacles, VR user with
higher height, and VR user with lower height are denoted
by different colors in the 2D image. The preprocessed im-
ages are used as the input data of the convolution network,

Input21 × 21L1:Feature map64@21×21L2:Feature map64@21×21L3:Sub sampling64@11×11L4:FC layer64@11×11 to 128L5:Output128 to 2SoftmaxFully ConnectedConvolutionsConvolutionsMax Poolingand the initial feature extraction is obtained via principal
component analysis (PCA) [52], which is usually used for
feature extraction. Meanwhile, the images are projected into
the characteristic subspace of N0 × N0 × 3, where 3 presents
the color of the image is in RGB mode. Therefore, the learning
efﬁciency and computational complexity of the CNN can be
decreased by reducing the image dimensionality.

(b) Convolution Layer: The characteristics of the input
image is extracted by a randomly initialized ﬁlter. It is possible
that the input image has various characteristics, thus, multiple
ﬁlters are used to extract all features in the original image.
Zero padding is also used for each convolution layer to keep
the size of the features extracted from the input image as
N0 × N0.

(c) Pooling Layer: It plays an important role in sub-sampling
via using the features extracted from the convolution layers.
The time complexity can be decreased in the next convolution
layer or fully-connected layer by reducing the number of op-
erations in sub-sampling. The Max-pooling method is usually
deployed to extract the largest value in the sliding window for
the sub-sampling among all the methods used in the pooling
layer.

(d) Fully-connected Layer: The features extracted by the
convolution and pooling layer are inserted into the neural
network. A softmax layer that is often used for the clas-
siﬁcations of multiple classes is employed at
the end of
the fully-connected layer. Meanwhile, the classiﬁcation result
corresponds to a probability that the sum of the probabilities
of all classes is equal to 1, and the class with the highest
probability is the estimated label for the corresponding input
image.

For example, the proposed CNN to classify the LoS or
NLoS statuses of VR users is shown in Fig. 6, which is also
used for the simulations in Section V. In Fig. 6, a 21 × 21
image goes through two convolution layers with 64 ﬁlters,
and one max-pooling layer. The kernel size and pooling size
are 2 × 2. Then, the extracted features pass through a fully-
connected layer with 128 ﬁlters. The activation function in
the convolution layer and fully-connected layer is the ReLu
function. After passing through the fully-connected layer, the
softmax layer is used to determine the LoS or NLoS status
corresponding to the input image. Note that Adam Optimizer
is also employed while training the proposed CNN model [53].

C. Downlink RIS Conﬁguration

The main purpose of Reinforcement Learning (RL) is to
select proper reﬂection coefﬁcient matrix Θ given in (14) of
the RIS for THz downlink transmission for the VR users in
the NLoS area. While for the uplink transmission at the (t +
1)th time slot, it directly uses the selected Θ at the tth time
slot. This is because the downlink transmission requires a high
data rate for the FoV with high resolution, whereas the uplink
transmission only transmits the actual position and viewpoint
or the learning model of the VR user (e.g., the size of the
uplink data is much smaller than that of the FoV). Through
a series of action strategies, the MEC is able to transmit the
selected Θ to the RIS via wired connection, interact with the

9

environment, and obtain rewards based on its actions, which
can help improve the action strategy. With enough number of
iterations, the MEC is able to learn the optimal policy that
maximizes the long-term reward.

We use S ∈ S, A ∈ A, and R ∈ Re to denote the state,
action and reward from their corresponding sets, respectively.
The purpose of the RL algorithm is to ﬁnd an optimal policy
π to maximize the long-term reward for A = π(S). The
optimization function can be formulated as < S, A, R >, and
the detailed descriptions of the state, action, and reward of the
optimization problem in (34) are introduced as follows.

• State: At the tth time slot, the network state is denoted

as

St = (Lt, It, (cid:100)QoEt−1) ∈ S,

(41)

t

t

},

t , L2
with Lt = {L1
It = {I 1
t , I 2
(cid:100)QoEt−1 = {QoE1

t , ..., LKVR
t , ..., I KVR
}
t−1, ..., QoEKVR
t−1, QoE2
where Lt is the set containing the positions of all VR
users at the tth time slot, where Lk
t , H k
t ],
I k
t = {1, 0} is the predicted LoS or NLoS status of the
kth VR user for the tth time slot, where 1 represents
LoS, 0 represents NLoS, and QoEk
t−1 is the QoE value
calculated by (31) of the kth VR user for the (t − 1)th
time slot.

t = [X k

t , Y k

t−1 },

• Action: The action space is written as

At = { (cid:101)Θt} ∈ A,

(42)

with (cid:101)Θt = {Θ1

t , Θ2

t , ..., Θ

ˆLN
t },

where (cid:101)Θt is the set that includes all the possible reﬂection
coefﬁcient matrix given the number of reﬂection elements
N of the RIS and the number of phase shift levels ˆL, with
Θi

t given in (14).

• Reward: The immediate reward Rt is designed as

Rt(St, At) =

KVR(cid:88)

k=1

QoEk
t .

(43)

The performance of the selected action is determined by
the position and LoS/NLoS status of the VR user, which can
further inﬂuence the long-term QoE of the THz VR system.
Therefore, we use the observed position, the LoS/NLoS status,
and the QoE of the VR user as observation, and use the QoE
as a reward. According to the observed environmental state
St at the tth time slot, the MEC selects speciﬁc action At
from the set A and obtains reward Rt. Then, the discounted
accumulation of the long-term reward is denoted as

Q(S, π) =

∞
(cid:88)

i=t

(γ)i−tRi(Si, Ai),

(44)

where γ ∈ [0, 1) is the discount factor.

When the number of reﬂection elements and phase shift
levels is small, the RL algorithm can efﬁciently obtain the
optimal policy. However, when a large number of reﬂection
elements and phase shift levels exist, e.g. 1050 ( ˆL = 10,
N = 50),
the state and action spaces will be increased

proportionally, which will not only occupy plenty of com-
putation memory of the MEC, but also inevitably result in
massive computation latency and degraded performance of
the RL algorithm. To address this issue, deep learning is
introduced to RL, namely, deep reinforcement learning (DRL),
through interaction with the environment, DRL can directly
control the behavior of the MEC, and solve complex decision-
making problems. Meanwhile, the policy should not violate the
VR interaction latency threshold. Thus, we use a constrained
deep Q network (C-DQN) to solve the optimization problem,
which indirectly optimizes the policy by optimizing the value
function while satisfying the downlink latency constraint.

Fig. 7. The C-DRL diagram of the THz transmission scheme.

As shown in Fig. 7, C-DQN is a value-based DRL al-
gorithm, it combines a neural network with Q-learning and
optimizes the state-action value function through a deep neural
network (DNN). The C-DQN uses a neural network to store
state and action information Qπ(S, A). It also applies the
experience replay to train the learning model, and experiences
in the experience replay are partially selected to learn to
improve the learning efﬁciency of the neural network and
break the correlation among the training samples. In addition,
the distribution of the training samples can be smoothed via
averaging the selected samples, which can further avoid the
training divergence.

The objective of C-DQN is to ﬁnd the optimal policy
π(cid:63), and obtain optimal state-action value Q(cid:63)(S, A), which is
expressed as

π(cid:63)(S) = arg max

A

Q(cid:63)(S, A).

(45)

In the proposed optimization problem, C-DQN should satisfy
the VR downlink transmission latency constraint. Thus, the
state-action value is calculated as

Q(S, A) = R + γCDQN max

A(cid:48)

Q(S

(cid:48)

(cid:48)

, A

) − µC down,

(46)

(cid:48)

(cid:48)

is the next state, A

where S
is the next action, and γCDQN is
the discount factor, which determines the balance between the
current state-action value and future state-action value. In (46),

C down is the downlink transmission cost due to the constraint
in (35) at each time slot, which is calculated as

10

C down = T downlink

th

−

(cid:80)KVR

k=1 T k
K VR

downlink

,

(47)

th

where K VR is the number of the VR users, T k
downlink(t) is the
downlink transmission latency of the kth VR user at the tth
time slot, and T downlink
is the downlink transmission latency
constraint. According to (46), the Q evaluation network in
C-DQN is used to estimate Q(S, A). Note that the target Q
network does not change in each time slot and is updated after
several time slots. To update the evaluation state-action value,
Bellman Equation is applied, which is denoted as

Qe(S, A) = (1 − αCDQN)Qe(S, A) + αCDQNQtar(S, A), (48)

where Qe and Qtar are the output of Q evaluation and target
network, respectively. In (48), αCDQN is the learning rate. The
loss function is calculated as (Qtar − Qe), which is used to
update the weights of the Q evaluation network. We can obtain
the optimal policy and Q value when the C-DRL converges.
Our detailed C-DRL algorithm is presented in Algorithm 1.

D. Computational Complexity Analysis of Learning Algo-
rithms

i ˆn2

i=1 ˆm2

For the computation complexity of the RNN based on the
GRU and LSTM architecture, it is computed as O( (cid:101)m(cid:101)n log (cid:101)n),
where (cid:101)m is the number of layers, and (cid:101)n is the number of units
per learning layer. The computation complexity of the CNN
is written as O((cid:80)LCNN
i cincout), where ˆm is the length
of the output feature map of the Convolution kernel, ˆn is the
length of the Convolution kernel, cin is the number of the
input channels, cout is the number of the output channels, and
LCNN is the number of CNN layers [54]. The computational
complexity of the C-DRL algorithm is given by O( ¯m¯n log ¯n).
Here, ¯m is the number of layers, and ¯n is the number of units
per learning layer [55].

To compare with the C-DRL algorithm, we use an exhaus-
tive algorithm to select the optimal phase shift of the RIS, and
the computational complexity of the exhaustive algorithm is
denoted as O( ˆLN ) [22], where ˆL and N are the number of
phase shift levels and the number of reﬂecting elements of the
RIS, respectively.

V. SIMULATION RESULTS

In this section, we examine the effectiveness of our proposed
learning architecture in Fig. 5. The simulation parameters are
summarized in Table I.

A. Viewpoint Prediction

The VR dataset obtained from [16] includes 16 clips of VR
videos with 153 VR users, and 969 data samples of the motion
in three dimensions, pitch, yaw, and roll, namely, X, Y and Z
viewing angles. The viewpoint ranges of X, Y and Z angles
are (-50◦, 50◦), (-150◦, 150◦) and (-50◦, 50◦), respectively.
According to [56], the motion of the VR user has strong short-
term auto-correlations in all three dimensions. Due to the fact

EnvironmentEvaluation QNetworkLossFunctionTarget QNetworkExperience ReplayCost Function    SGD tar Reset       11

TABLE I
SIMULATION PARAMETERS OF THZ VR NETWORK

Indoor scenario size
Location of MEC
Height of VR user
Location of obstacle (Y axis)
Center Location of RIS
THz center frequency
FoV resolution
Number of cycles processing one bit fMEC
Downlink transmission latency
LSTM memory size
RNN learning rate
Number of C-DRL layer
C-DRL Learning rate αCDQN

20 m × 20 m × 3 m
[0, 0, 3 m]
[1.2 m, 1.8 m]
[8 m, 12 m]
[10 m, 20 m, 3 m]
300 GHz
4k
1000 Cycles/bit
12 ms
10
0.005
2
0.05

Number of MEC
Number of VR users
Location of obstacle (X axis)
Height of obstacle (Z axis)
Speed of Light
Number of phase shift elements
MEC execution ability FMEC
Number of antennas of MEC
White Gaussian noise σ2
Minibatch size
Discount Factor γ
Number of C-DRL units of each layer
Time slots

1
5
[4 m, 8 m], [12 m, 16 m]
3 m
3 × 108 m/s
20
5 GHz
30
−110 dBm
64
0.9
128
300

Algorithm 1 C-DRL to select the optimal phase shifts of the
RIS in THz transmission

1: Initialize replay memory G, discount factor γCDQN ∈

[0, 1), and learning rate αCDQN ∈ (0, 1].

2: Initialize state-action value function Q(S, A), the param-
eters of evaluation Q network and target Q network.

3: for Iteration = 1,...,I do
4:
5:

Input the network state S.
for t = 1,...,T do

6:

7:

8:

9:

10:

11:

12:
13:
14:
15:

16:
17:
18:

Q(St, A).

Use (cid:15)-greedy algorithm to select a random action At
from the action space A.
Otherwise, select At = max
A∈A
The MEC performs downlink transmission according
to the selected action At.
The MEC observes reward Rt, new state St+1 and
calculates the cost according to (47).
Store transition (St, At, Rt, C down
memory G.
Sample
random
(Sj, Aj, Rj, C down
G.
if j + 1 is terminal then
= Rj.

transitions
from replay memory

, St+1) in replay

minibatch

, Sj+1)

of

j

t

ytarget
j
else

= Rj+1 + γ max

ytarget
j
end if
Update evaluation Q network.
Update the Lagrangian multiplier with

Q(Sj+1, A).

A

ω = ω + αCDQN

1
|G|

|G|
(cid:88)

i=1

C down
i

,

(49)

where |G| is the size of the replay memory.
Update target Q network periodically.

19:
20:
21: end for

end for

that auto-correlations are much stronger than the correlation
between these three dimensions, the angles in each direction
can be trained independently and separately. In addition, the
range of Y angle distribution is much larger than that of X and
Z. Therefore, for simplicity, we use online GRU to predict the

Fig. 8. Average prediction error of centralized online GRU and distributed
FedAvg algorithms in continuous time slots.

Y angle of VR users in this section, however, our algorithms
can also be used for the prediction of X and Z angles. In the
simulation, we use the viewpoint samples of the historical ten
time slots (1 second) to predict the viewpoint of the next time
slot (0.1 seconds).

Fig. 8 plots the average prediction error of the centralized
online GRU and distributed FedAvg algorithms in continuous
time slots. In the Genie-aided scheme, the learning algorithms
are trained with the known correct actual viewpoint of each
VR user by the MEC at each time slot. In the Error-free
there are no transmission errors in
Transmission scheme,
the uplink and downlink transmission. We can see that the
performance of the centralized online GRU is better than that
of the FedAvg. This is because the FedAvg depends on the
local data of each VR user while minimizing the loss function,
and this biases the learning model to be ﬁt for the speciﬁc
VR user [57], whereas the centralized online GRU can learn
from global data of all VR users, so that the learning model
can be appropriated for all VR users. It is also noted that at
the beginning, there are large ﬂuctuations in the performance
of the learning algorithms. This is because the parameters
in the learning algorithms should be modiﬁed to capture
the viewpoint preference of the VR user. In addition, more
simulation results of viewpoint prediction have already been
described in Section V of [48] in detail.

050100150200250Time Slot05101520Average Prediction Error (%)Centralized Online GRU, Genie-aidedFedAvg, Error-free Transmission12

(a)

(b)

Fig. 9. (a) Loss of LSTM for VR user mobility prediction of each epoch. (b)
Prediction error of LSTM algorithm via different number of moving periods.

(a)

(b)

Fig. 10.
(a) Loss of CNN for LoS or NLoS prediction of each VR user of
each epoch. (b) Prediction accuracy of CNN algorithm via different number
of VR users.

B. LoS and NLoS Prediction

During the LoS and NLoS prediction, the algorithm that
integrates online LSTM and CNN is deployed to predict the
mobility of VR users and judge the LoS/NLoS status of the VR
user in continuous time slots. We ﬁrst use Python to simulate
the mobility of VR users in the indoor scenario, and label the
moving direction based on the corresponding mobility data.
Then, we use the created mobility dataset to train parameters
of the LSTM, which can be further used for the online mobility
prediction. Fig. 9 (a) plots the loss of the LSTM of each epoch.
It is seen that the LSTM converges after 60 epochs. Fig. 9 (b)
plots the prediction error of the LSTM via different number of
moving periods. It is noted that when we use the mobility data
of the previous 10 time slots to predict the mobility direction
for the next time slot, we can obtain the minimum prediction
error [48].

Fig. 10 (a) plots the loss of CNN for LoS or NLoS
prediction of each VR user of each epoch. It is obtained that
the CNN converges after 150 epochs. Fig. 10 (b) plots the
prediction accuracy of CNN via different number of VR users.
We observe that the prediction accuracy is about 95% when
the number of VR users is smaller than 15, but decreases with
the increasing number of VR users. This can be explained by
the fact that when more VR users exist in the indoor scenario,
the features of the input 2D image become more complex, and
make it difﬁcult for CNN to extract the features with the given
structure, which reduces the prediction accuracy.

C. RIS Conﬁguration of THz Transmission

For the downlink THz transmission, we deploy C-DRL to
select the proper phase shift of the RIS to reﬂect the THz

Fig. 11. Reward of the MEC-enabled and RIS-assisted THz VR network of
each time slot via C-DRL.

signals for the VR users in the NLoS area. For simplicity,
we use “w/ Pred” to present “with prediction”. In the Genie-
aided scheme, the online learning algorithms are trained with
known correct actual viewpoint and position of each VR user
at each time slot, which is the upper bound of the online
learning algorithm and can hardly be achieved in the practical
wireless VR systems. To compare with the proposed learning
architecture, an exhaustive algorithm is deployed to select the
optimal phase shift of the RIS in downlink transmission at
each time slot.

Fig. 11 plots the reward of the MEC-enabled and RIS-
assisted THz VR network of each time slot via C-DRL. It can
be seen that the C-DRL converges after 50 epochs. Fig. 12
plots the average QoE and the average VR interaction latency
of the MEC-enabled and RIS-assisted THz VR network of
each time slot via C-DRL with the uplink viewpoint and
LoS/NLoS prediction via GRU compared to that via the
exhaustive algorithm, respectively. It is observed that at the
beginning 150 time slots, the average QoE of C-DRL with
prediction scheme is worse than that of the C-DRL with
Genie-aided scheme, and both schemes do not violate the VR
interaction latency after convergence. This is because in the
Genie-aided scheme, the online learning algorithms are di-
rectly trained with known correct actual viewpoint and position
of each VR user, so that they are capable of better capturing
historical trends of viewpoint preference and mobility of the
VR user, which can further improve the prediction accuracy.
Interestingly, we notice that after 150 time slots, the gap
between the C-DRL with prediction scheme and the exhaustive
with prediction scheme is small. This is due to the experience
replay mechanism and randomly sampling in C-DRL, which
uses the training samples efﬁciently and smooth the training
the
distribution over the previous behaviours. Importantly,
performance of all the learning-based and exhaustive schemes
substantially outperforms the conventional non-learning based
scheme, where the reﬂection coefﬁcients matrix of the RIS
is randomly selected. From Fig. 12, we also notice that the
performance of the centralized C-DRL with the Genie-aided

020406080100Epoch0.000.050.100.150.20LossLSTM24681012Number of Periodic Moving010203040506070Prediction Error (%)LSTM050100150200Epoch0.2300.2350.2400.2450.250LossCNN51015202530Number of VR User020406080100Prediction Accuracy (%)CNN050100150200250300Epochs−101234567RewardC-DRL13

(a)

(b)

Fig. 12.
(a) Average QoE of the MEC-enabled and RIS-assisted THz VR network of each time slot via C-DRL with viewpoint and LoS/NLoS prediction.
(b) Average VR interaction latency of the MEC-enabled and RIS-assisted THz VR network of each time slot via C-DRL with viewpoint and LoS/NLoS
prediction, where the VR interaction latency constraint is 20 ms.

(a)

(b)

(a) Average QoE of the MEC-enabled and RIS-assisted THz VR network via C-DRL with viewpoint and LoS/NLoS prediction with increasing
Fig. 13.
number of VR users. (b) Average VR interaction latency of the MEC-enabled and RIS-assisted THz VR network via C-DRL with viewpoint and LoS/NLoS
prediction with increasing number of VR users, where the VR interaction latency constraint is 20 ms.

scheme is better than that of the scheme with FedAvg. This
is because in the FedAvg, the learning model needs to be
uploaded via uplink transmission for model aggregation, and
then the updated global model needs to be transmitted to
all VR users through downlink transmission for viewpoint
prediction, which leads to extra transmission latency.

Fig. 13 plots the average QoE and VR interaction latency
of the MEC-enabled and RIS-assisted THz VR network via
C-DRL with viewpoint and LoS/NLoS prediction versus the
number of VR users compared to that via the exhaustive
algorithm, respectively. With the increasing number of VR
users, the average QoE of VR users decreases as shown in Fig.
13 (a), whereas the average VR interaction latency increases
as shown in Fig. 13 (b). This is due to the fact that with

increasing number of VR users, the interference among the
THz transmission increases. When the number of the VR
user is larger than 15, the gap between the C-DRL and the
exhaustive algorithm becomes larger, and the VR interaction
latency constraints are violated with increasing number of VR
users. This is because the LoS/NLoS prediction accuracy via
CNN decreases, which further affects the action selected by
the C-DRL.

Fig. 14 plots the average QoE and the average VR inter-
action latency of the MEC-enabled and RIS-assisted THz VR
network via C-DRL with viewpoint and LoS/NLoS prediction
versus the number of reﬂecting elements of the RIS compared
to that via the exhaustive algorithm, respectively. With increas-
ing number of reﬂecting elements of the RIS, the average QoE

050100150200250300Time Slot0.250.500.751.001.251.501.752.00Average QoEExhaustive, Genie-aidedExhaustive, w/PredC-DRL, Genie-aidedC-DRL, FedAvg, Error-free TransmissionC-DRL, w/PredRandom, Genie-aidedRandom, w/Pred050100150200250300Time Slot1520253035404550Average VR Interaction Latency (ms)Exhaustive, Genie-aidedExhaustive, w/PredC-DRL, Genie-aidedC-DRL, FedAvg, Error-free TransmissionC-DRL, w/PredRandom, Genie-aidedRandom, w/Pred51015202530Number of VR Users0.250.500.751.001.251.501.752.00Average QoEExhaustive, Genie-aidedExhaustive, w/PredC-DRL, Genie-aidedC-DRL, w/PredRandom, Genie-aidedRandom, w/Pred51015202530Number of VR Users152025303540Average VR Interaction Latency (ms)Exhaustive, Genie-aidedExhaustive, w/PredC-DRL, Genie-aidedC-DRL, w/PredRandom, Genie-aidedRandom, w/Pred14

(a)

(b)

Fig. 14.
(a) Average QoE of the MEC-enabled and RIS-assisted THz VR network via C-DRL with viewpoint and LoS/NLoS prediction with increasing
number of reﬂecting elements of the RIS. (b) Average VR interaction latency of the MEC-enabled and RIS-assisted THz VR network via C-DRL with
viewpoint and LoS/NLoS prediction with increasing number of reﬂecting elements of the RIS, where the VR interaction latency constraint is 20 ms.

of VR users increases as shown in Fig. 14 (a), whereas the
average VR interaction latency decreases as shown in Fig.
14 (b). This is because as the number of reﬂecting elements
increases, the THz channel gain reﬂected by the RIS increases
[41], which further increases the THz transmission rate for the
VR users in the NLoS area. In addition, the VR interaction
latency of the non-learning schemes is not inﬂuenced by the
predicted LoS/NLoS status via CNN.

VI. CONCLUSIONS
In this paper, a MEC-enabled and RIS-assisted THz VR
network was developed to maximize the long-term QoE of
real-time interactive VR video streaming in an indoor scenario
under VR interaction latency constraints. Speciﬁcally, in the
uplink, a centralized online GRU algorithm and distributed
FedAvg were used to predict the viewpoints of the VR users
over time, to determine the corresponding FoV to be rendered
at the MEC. An algorithm that integrates online LSTM and
CNN was also designed to predict the locations of the VR
users and determine the LoS or NLoS statuses in advance.
Then, a C-DRL algorithm was developed to select the optimal
phase shifts of the reﬂecting elements of the RIS to compen-
sate for the NLoS loss in THz transmission. Simulation results
have shown that our proposed ensemble learning architecture
with online GRU, online LSTM, CNN, and C-DRL algorithms
substantially improved the long-term QoE, while satisfying the
VR interaction latency constraint, and the QoE performance of
our proposed learning architecture was near-optimal compared
to the exhaustive algorithm.

REFERENCES

[1] E. Bastug, M. Bennis, M. Medard, , and M. Debbah, “Toward intercon-
nected virtual reality: Opportunities, challenges, and enablers,” IEEE
Commun. Mag., vol. 55, no. 6, pp. 110 – 117, Jun. 2017.

[2] F. Hu, Y. Deng, W. Saad, M. Bennis, and A. H. Aghvami, “Cellular-
connected wireless virtual reality: Requirements, challenges, and solu-
tions,” IEEE Commun. Mag., vol. 58, no. 5, pp. 105 – 111, May 2020.

[3] I. F. Akyildiz, J. M. Jornet, and C. Han, “Teranets: ultra-broadband
communication networks in the terahertz band,” IEEE Commun. Mag.,
vol. 21, no. 4, pp. 130 – 135, Aug. 2014.

[4] C. Han and Y. Chen, “Propagation modeling for wireless communica-
tions in the terahertz band,” IEEE Commun. Mag., vol. 56, no. 6, pp.
96 – 101, Jun. 2018.

[5] J. Federici and L. Moeller, “Review of terahertz and subterahertz wire-
less communications,” J. Appl. Phys., vol. 107, pp. 111 101–1–111 101–
22, 2010.

[6] V. Petrov, A. Pyattaev, D. Moltchanov, and Y. Koucheryavy, “Terahertz
band communications: Applications, research challenges, and standard-
ization activities,” 2016 8th International Congress on Ultra Modern
Telecommunications and Control Systems and Workshops (ICUMT), pp.
183–190, 2016.

[7] E. Basar, M. D. Renzo, J. D. Rosny, M. Debbah, M. S. Alouini, and
R. Zhang, “Wireless communications through reconﬁgurable intelligent
surfaces,” IEEE Access, vol. 7, pp. 116 753 – 116 773, Aug. 2019.
[8] M. D. Renzo et al., “Smart radio environments empowered by recon-
ﬁgurable AI meta-surfaces: An idea whose time has come,” EURASIP
J. Wireless Commun. Netw, May 2019.

[9] M. D. Renzo, K. Nltontin et al., “Reconﬁgurable intelligent surfaces vs.
relaying: Differences, similarities, and performance comparison,” IEEE
Open J. Commun. Soc., vol. 1, pp. 798 – 807, Jun. 2020.

[10] M. D. Renzo et al., “Smart radio environments empowered by recon-
ﬁgurable intelligent surfaces: How it works, state of research, and the
road ahead,” IEEE J. Sel. Areas Commun., vol. 38, no. 11, pp. 2450 –
2525, Nov. 2020.

[11] G. Zhou, C. Pan, H. Ren, K. Wang, M. Elkashlan, and M. D. Renzo,
“Stochastic learning-based robust beamforming design for RIS-aided
millimeter-wave systems in the presence of random blockages,” IEEE
Trans. Veh. Technol., vol. 70, no. 1, pp. 1057 – 1061, Jan. 2021.
[12] Q. Wu, S. Zhang, B. Zheng, C. You, and R. Zhang, “Intelligent reﬂecting
surface aided wireless communications: A tutorial,” arxiv:2007.02759,
2020.

[13] C. Huang et al., “Holographic MIMO surfaces for 6G wireless networks:
Opportunities, challenges, and trends,” IEEE Wireless Comm., vol. 27,
no. 5, pp. 118 – 125, Oct. 2020.

[14] Z. Wan, Z. Gao, F. Gao, M. D. Renzo, and M. S. Alouini, “Terahertz
massive MIMO with holographic reconﬁgurable intelligent surfaces,”
arxiv: 2009.10963, 2020.

[15] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey
on mobile edge computing: The communication perspective,” IEEE
Commun. Survey Tuts., vol. 19, no. 4, p. 2322–2358, 4th Quart. 2017.

[16] www.dropbox.com/sh/78ff9djp3v2nv8x/AAACwzDFYwYJzIMrTs8jgM09a.
[17] C. Chaccour, M. N. Soorki, W. Saad, M. Bennis, and P. Popovski,
“Can terahertz provide high-rate reliable low latency communications
for wireless VR?” arxiv:2005.00536, 2020.

51015202530Number of Reflecting Elements of the IRS0.81.01.21.41.61.82.0Average QoEExhaustive, Genie-aidedExhaustive, w/PredC-DRL, Genie-aidedC-DRL, w/PredRandom, Genie-aidedRandom, w/Pred51015202530Number of Reflecting Elements of the IRS15.017.520.022.525.027.530.032.5Average VR Interaction Latency (ms)Exhaustive, Genie-aidedExhaustive, w/PredC-DRL, Genie-aidedC-DRL, w/PredRandom, Genie-aidedRandom, w/Pred15

[40] C. Huang, R. Mo, and C. Yuen, “Reconﬁgurable intelligent surface
assisted multiuser miso systems exploiting deep reinforcement learning,”
IEEE J. Sel. Areas Commun., vol. 38, no. 8, pp. 1839 – 1850, Aug. 2020.
[41] K. Feng, Q. Wang, X. Li, and C. K. Wen, “Deep reinforcement learning
based intelligent reﬂecting surface optimization for miso communication
systems,” IEEE Wireless Commun. Lett., vol. 9, no. 5, pp. 745 – 749,
May 2020.

[42] B. Ning, Z. Chen, W. Chen, and Y. Du, “Channel estimation and trans-
mission for intelligent reﬂecting surface assisted thz communications,”
arxiv:1911.04719, 2020.

[43] C. Han, A. O. Bicen, and I. F. Akyildiz, “Multi-ray channel modeling
and wideband characterization for wireless communications in the
terahertz band,” IEEE Trans. Wireless Commun., vol. 14, no. 5, pp. 2402
– 2412, May 2015.

[44] “3rd generation partnership project; Technical speciﬁcation group ser-
vices and system aspects; Extended reality (XR) in 5G,” 3GPP TR
26.928, Feb. 2020.

[45] X. Yin, A. Jindal, V. Sekar, and B. Sinopoli, “A control-theoretic
approach for dynamic adaptive video streaming over HTTP,” Proc. 2015
ACM Conf. on Special Interest Group on Data Commun., p. 325 – 338,
Aug. 2015.

[46] H. Mao, R. Netravali, and M. Alizadeh, “Neural adaptive video stream-
ing with pensieve,” Proc. Conf. of the ACM Special Interest Group on
Data Commun., p. 197 – 210, Aug. 2017.

[47] Q. Liang, F. Que, and E. Modiano, “Accelerated primal-dual policy
optimization for safe reinforcement learning,” arxiv:1802.06480, 2018.
[48] X. Liu, X. Li, and Y. Deng, “Learning-based prediction and
reality (VR) network,”

uplink retransmission for wireless virtual
arxiv:2012.12725, 2020.

[49] Z. Lin, “Recurrent neural network models of human mobility,” Ph.D.
disserration, Dept. Civil Environ. Eng., Univ. California, Berkeley,
Berkeley, CA, USA, 2018.

[50] S. Ruder, “An overview of gradient descent optimization algorithms,”

arXiv:1609.04747, 2016.

[51] P. J. Werbos, “Backpropagation through time: what it does and how to
do it,” Proceedings of the IEEE, vol. 78, no. 10, pp. 1550 – 1560, Oct.
1990.

[52] M. Turk and A. P. Pentland, “Face recognition using eigenfaces,” In
Proc. IEEE Conf. Computer Vision and Pattern Recognition, 1991.
[53] D. P. Kingma and B. Jimmy, “Adam: A method for stochastic optimiza-

tion,” arxiv:1412.6980, 2014.

[54] L. O. Chua, CNN: A Paradigm for Complexity.

Singapore: World

Scientiﬁc, 1998.

[55] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction

to Algorithms. Cambridge, USA: The MIT Press, 2009.

[56] Y. Bao, H. Wu, T. Zhang, A. A. Ramli, and X. Liu, “Shooting a moving
target: Motion-prediction-based transmission for 360-degree videos,” in
Proc. IEEE Int. Conf. Big Data, pp. 1161 – 1170, 2017.

[57] M. Mohri, G. Sivek, and A. T. Suresh, “Agnostic federated learning,”

arxiv:1902.00146, 2019.

[18] C. Chaccour et al., “Risk-based optimization of virtual reality over

terahertz reconﬁgurable intelligent surfaces,” arxiv:2002.09052, 2020.

[19] J. Du, F. R. Yu, G. Lu, J. Wang, J. Jiang, and X. Chu, “MEC-assisted
immersive VR video streaming over terahertz wireless networks: A deep
reinforcement learning approach,” IEEE Internet Things J., vol. 7, no. 10,
pp. 9517 – 9529, Oct. 2020.

[20] C. Chaccour and W. Saad, “On the ruin of age of

informa-
tion in augmented reality over wireless terahertz (THz) networks,”
arxiv:2008.09959, 2020.

[21] X. Ma, Z. Chen, W. Chen, Z. Li, Y. Chi, C. Han, and S. Li, “Joint
channel estimation and data rate maximization for intelligent reﬂecting
surface assisted terahertz MIMO communication systems,” IEEE Access,
vol. 8, pp. 99 565 – 99 581, May 2020.

[22] X. Ma, Z. Chen, W. Chen, Y. Chi, Z. Li, C. Han, and Q. Wen, “Intelligent
reﬂecting surface enhanced indoor terahertz communication systems,”
Nano Commun. Netw., vol. 24, May 2020.

[23] C. Huang, A. Zappone, G. C. Alexanddropoulos, C. Yuen, M. Debbah,
and C. Yuen, “Reconﬁgurable intelligent surfaces for energy efﬁciency
in wireless communication,” IEEE Trans. Wireless Commun., vol. 18,
no. 8, pp. 4157 – 4170, Aug. 2019.

[24] L. Wei, C. Huang, G. C. Alexanddropoulos, C. Yuen, Z. Zhang, and
M. Debbah, “Channel estimation for RIS-empowered multi-user MISO
wireless communications,” IEEE Trans. Commun., vol. 69, no. 6, pp.
4144 – 4157, Jun. 2021.

[25] W. Jiang, Y. Zhang, J. Wu, W. Feng, and Y. Jin, “Intelligent reﬂecting
surface assisted secure wireless communications with multiple-transmit
and multiple-receive antennas,” IEEE Access, vol. 8, no. 1, pp. 86 659–
86 673, May 2020.

[26] H. Song, J. Bai, Y. Yi, J. Wu, and L. Liu, “Artiﬁcial intelligence enabled
internet of things: Network architecture and spectrum access,” IEEE
Comput. Intell. Mag., vol. 15, no. 1, pp. 44 – 51, Feb. 2020.

[27] C. Chaccour, M. N. Soorki, W. Saad, M. Bennis, P. Popovski, and
M. Debbah, “Seven deﬁning features of terahertz (THz) wireless sys-
tems: A fellowship of communication and sensing,” arxiv:2102.07668,
2021.

[28] C. Huang, Z. Yang, G. C. Alexandropoulos, K. Xiong, L. Wei, C. Yuen,
and Z. Zhang, “Hybrid beamforming for RIS-empowered multi-hop
terahertz communications: A DRL-based method,” arxiv:2009.09380,
2020.

[29] C. Huang, Z. Yang, G. C. Alexandropoulos, K. Xiong, L. Wei, C. Yuen,
Z. Zhang, and M. Debbah, “Multi-hop RIS-empowered terahertz com-
munications: A DRL-based hybrid beamforming design,” IEEE J. Sel.
Areas Commun., vol. 39, no. 6, pp. 1663 – 1677, Jun. 2021.

[30] Y. Sun, Z. Chen, M. Tao, and H. Liu, “Communications, caching, and
computing for mobile virtual reality: Modeling and tradeoff,” IEEE
Trans. Comm., vol. 67, no. 11, pp. 7573 – 7586, Nov. 2019.

[31] T. Dang and M. Peng, “Joint radio communication, caching, and
computing design for mobile virtual reality delivery in fog radio access
networks,” IEEE J. Sel. Areas Commun., vol. 37, no. 7, p. 1594 – 1607,
Jul. 2019.

[32] K. Long, Y. Cui, C. Ye, and Z. Liu, “Optimal wireless streaming of
multi-quality 360 VR video by exploiting natural, relative smoothness-
enabled and transcoding-enabled multicast opportunities,” IEEE Trans.
Multimedia, p. 1 – 1, Oct. 2019.

[33] X. Liu and Y. Deng, “Learning-based prediction, rendering and as-
sociation optimization for MEC-enabled wireless virtual reality (VR)
network,” arxiv:2005.08332, 2020.

[34] Q. Wu and R. Zhang, “Towards smart and reconﬁgurable environment:
Intelligent reﬂecting surface aided wireless network,” IEEE Commun.
Mag., vol. 58, no. 1, pp. 106 – 112, Jan. 2020.

[35] Q. Wu et al., “Beamforming optimization for wireless network
reﬂecting surface with discrete phase shifts,”

aided by intelligent
arxiv:1906.03165, 2020.

[36] Z. Yu, B. Gong, and X. He, “Virtual reality mobility model for wireless
ad hoc networks,” J. Syst. Eng. Electron., vol. 19, no. 4, pp. 819 – 826,
Aug. 2008.

[37] Y. Wu, J. Kokkoniemi, C. Han, and M. Juntti, “Interference and coverage
analysis for terahertz networks with indoor blockage effects and line-
of-sight access point association,” IEEE Trans. Wireless Commun., to
appear, 2021.

[38] Q. Wu and R. Zhang, “Intelligent reﬂecting surface enhanced wireless
network via joint active and passive beamforming,” IEEE Trans. Wireless
Commun., vol. 18, no. 11, pp. 5394 – 5409, Nov. 2019.

[39] “5G; 3GPP virtual reality proﬁles for streaming applications,” ETSI TS

126 118, Apr. 2019.

