Emotion-robust EEG Classiﬁcation for
Motor-imagery

Abdul Moeed
Technical University of Munich
Munich, Germany
abd.moeed@tum.de

0
2
0
2

y
a
M
3
2

]
P
S
.
s
s
e
e
[

1
v
3
2
5
3
1
.
5
0
0
2
:
v
i
X
r
a

Abstract—Developments in Brain Computer Interfaces (BCIs)
are empowering those with severe physical afﬂictions through
their use in assistive systems. Common methods of achieving this
is via Motor-Imagery (MI), which maps brain signals to code for
certain commands. Electroencephalogram (EEG) is preferred for
recording brain signal data on account of it being non-invasive.
Despite their potential utility, MI-BCI systems are yet conﬁned to
research labs. A major cause for this is lack of robustness of such
systems. As hypothesized by two teams during Cybathlon 2016,
a particular source of the system’s vulnerability is the sharp
change in the subject’s state of emotional arousal. This work
aims towards making MI-BCI systems resilient to such emotional
perturbations. To do so, subjects are exposed to high and low
arousal-inducing virtual reality (VR) environments before record-
ing EEG data. The advent of COVID-19 compelled us to modify
our methodology. Instead of training machine learning algorithms
to classify emotional arousal, we opt for classifying subjects
that serve as proxy for each state. Additionally, MI models are
trained for each subject instead of each arousal state. As training
subjects to use MI-BCI can be an arduous and time-consuming
process, reducing this variability and increasing robustness can
considerably accelerate the acceptance and adoption of assistive
technologies powered by BCI.

I. INTRODUCTION
Biological systems, such as humans, use electrical signals
as the medium of communication between their control centers
(brains) and motor organs (arms, legs). While this is taken for
granted by most people, those with severe physical impair-
ments, such as quadriplegia, experience the breakdown of this
communication system rendering them unable to perform the
most basic physical movements. Modern technologies, such
as BCIs, have attempted to ameliorate this through the use
of brain signals as commands for assistive systems [39]. MI,
a common paradigm for BCI control, requires the subject to
simulate or imagine movement of the limbs on account of there
being discernible differences in brain signals when moving
different limbs [1]. Due to it being non-invasive and cost-
effective, EEG is the method of choice for collecting data for
such systems [1].

One of the many recent developments in the application
of EEG-driven BCIs is the Cybathlon competition held every
four years under the auspices of Eidgenssische Technische
Hochschule Zrich (ETH Zurich) [45]. The competition in-
volves physically challenged individuals completing routine
tasks via assistive systems. One such task – the BCI race
– has the participants (called pilots) control a virtual game
character via brain signals only. Competing teams, who may

hail from either academia or industry, are responsible for
creating BCI systems and training their respective pilots. The
goal of the Cybathlon is to push the state-of-the-art in BCI
assistive systems, and accelerate its adoption in everyday lives
of those who need it most.

For

the 2020 edition of Cybathlon, a team from the
Technische Universitt Mnchen (TUM) called ”CyberTUM” is
amongst the competitors in the BCI race challenge. In order
to achieve high scores in the competition, a major part of
BCI development is the focus on robustness of the system i.e.
minimizing the variability of the system for different sessions
and environments. Lack of robustness, in fact, is an established
concern in almost all BCI systems. Possible causes of the
problem include nonstationarity of EEG signals (variance for
the same subject) [59] [56]. An additional cause, as noted
by participating teams in Cybathlon 2016, is the change in
the subject’s emotional state. During the race, As expected,
a public event such as the BCI race, the pilots’ stress stress
levels increased. This is to be expected as a public event such
as the BCI race can heighten stress. This change in the pilots’
emotional state caused their respective BCI systems to perform
sub-optimally.

The objective of this work is to mitigate this concern and
develop MI systems that are robust to perturbations in the
subject’s emotional state, speciﬁcally to emotional arousal.
In order to achieve this, we develop VR environments to
induce high and low arousal in the subject before recording MI
data. VR environments have been previously used along with
EEG to prompt changes in emotional arousal [5]. Additionally,
they have been used together with MI for treating Parkinson’s
disease [32]. To our knowledge, this is the ﬁrst work where
VR environments are used to increase robustness of MI-BCI
systems. Subsequently, learning algorithms are trained, not
only for MI but also for different arousal states. The idea is
that during the BCI race, we ﬁrst detect the pilot’s emotional
state of arousal, and choose the appropriate MI classiﬁer. Due
to COVID-19, many steps in the above mentioned outline had
to be modiﬁed, the details of which are present as follows.

II. RELATED WORK

A. Cybathlon 2016

The inaugural Cybathlon competition was held in 2016.
After the competition, the competing teams published their
methods for training the participants, amongst which were

 
 
 
 
 
 
Alternative descriptions, such as the ’vector model’ [7], do
not veer off sharply from the circumplex model; they too base
emotional classiﬁcation on both valence and arousal. Hence
the circumplex model was used as the paradigm of emotional
analysis for the duration of the project.

C. Arousal, EEG and Motor Imagery

States of high and low arousal can be inferred from EEG
signals [41]. This has been previously used to train learning
systems for distinguishing between various arousal states [34].
EEG bands pertinent to different states of arousal are alpha (8-
14 Hz) – related to a relaxed yet awakened state – and gamma
(36-44 Hz) – a pattern associated with increased arousal and
attention. The theta pattern (4-8 Hz), correlated with lethargy
and sleepiness, is also useful for differentiating arousal.

With regards to motor imagery (MI), the most relevant EEG
bands have been shown to be alpha (8-14 Hz) and beta (14-30
Hz) [15], the latter of which is associated with high degrees
of cognitive activity [41].

Motor imagery data refers to data produced when the subject
simulates limb movement. As movement of different limbs is
sufﬁciently distinguishable, this can be used to perform control
for various other tasks [37]. To record EEG data for motor
imagery, the 10-20 international system of electrode placement
is used 2. Due to the cross-lateral nature of limb control in
the human brain, movement of the right arm is recorded most
faithfully by C3 and that of the left arm by C4 [15].

Fig. 2: 10-20 International system of EEG electrode place-
ment. Electrodes C3 and C4 are most relevant for MI activity.
Figure courtesy of [47].

III. METHODOLOGY

A. Virtual Reality Environments

Traditional methods of inducing stress include the Sing-a-
song stress test (SSST) [8] and the Trier social stress test
(TSST) [20], while meditation has been shown to induce
relaxation [49] [29]. Emulating such environments faithfully
in VR is sufﬁciently challenging, and may not be the most
productive way to use VR to induce high/low emotional
arousal.

Previously, VR exposure therapy has been explored to alle-
viate various psychological disorders [24]. One such example

Fig. 1: The circumplex model of emotional classiﬁcation.
Figure courtesy of [19].

Brain Tweakers (EPFL) [39] and Mirage91 (Graz University of
Technology). One of the pilots of the former performed well in
the qualiﬁers but poorly in the ﬁnal, prompting the authors to
cite psychological factors such as stress as the possible cause
for the drop. A similar course of events was observed for the
pilot of Mirage91, who after achieving an average runtime of
120 s in the days leading up to the Cybathlon, dropped to 196
s during the competition. The authors indicated that the pilot
was showing signs of nervousness on competition day, with
a heart beat of 132 beats per minute (bpm) prior to the race
[51].

The authors’ hypothesis regarding the drop in their pilots’
performances is supported by existing BCI literature [9] [28]
[16] [18]. Further support comes from evidence in affective
science: It has been theorized that any event
that causes
an increase in emotional arousal can affect perception and
memory in a manner which causes the retention of high-
priority information and disregard of low-priority information
[31].

B. Emotional Valence and Arousal

Emotions are deﬁned as complex psychological states, with
three constituents: subjective experience, physiological and
behavioral response [17]. Following early attempts [60], more
rigorous descriptions of emotions were made, the most widely
accepted of which being the ’circumplex model’ [48]. It
proposes that all emotions can be described as a combina-
tion of two properties: valence and arousal. These can be
thought as orthogonal axes in two-dimensions. Neurologically,
it entails that any emotional state is a result of two distinct
and independent neural sub-systems [42]. Figure 1 provides
a visual representation of the circumplex model. As can be
seen, emotions such as ’excited’ are high on both the arousal
and valence axes, while ’gloomy’ is low in both arousal and
valence.

of Technology. The dataset has been used previously in the
BCI Competition IV [53]. EEG data is collected for 9 subjects
doing a binary motor-imagery task (moving right and left hand
on cue). The data is sampled at a frequency of 250 Hz with 3
EEG and 3 EOG channels. For our experiments, we use data
from two subjects, B05 and B04, whom we refer to as subject
1 and 2 respectively henceforth.

C. Subject Classiﬁcation as Proxy for Arousal Classiﬁcation

As mentioned, we were unable to obtain our own EEG
arousal data. To train the classiﬁers, we alternatively modiﬁed
the experiment. Instead of using data with high/low arousal
emotional states as labels, we used different subjects as proxies
for such states, making it a cross-subject classiﬁcation task
[13] [46]. As EEG signals demonstrate signiﬁcant variance
between subjects, we can consider the data coming from
subject A as that belonging to the emotional state of high
arousal, and data from subject B as belonging to low arousal.
With this approach, we can continue to train a classiﬁer that
would approximate the performance of one that is trained on
actual arousal data, assuming the emotional states in this actual
data are informative.

D. Experimental Design

The original scheme was to:
1) Develop VR environments in line with existing literature
that are known to induce stress (high arousal) and
relaxation (low arousal) in subjects.

2) Use electrodermal activity (EDA) activity to validate
the efﬁcacy of VR environments. EDA is a wide-used
measure for emotional arousal, as skin conductance rises
with rise in arousal [10].

3) Record MI data alternating between states of low and
high arousal for each session. Start with 60s of inducing
high arousal via the ”Height” environment, then record
MI data for 45s. Repeat the same with ”Forest” environ-
ment for relaxed state. Repeat this process for each trial.
The MI data was to be recorded by using the common
paradigm of showing the participant a cue on screen
(typically left or right arrow) which would prompt them
to imagine as if they were moving their left or right hand
[44] [40] [27].

4) Train an arousal classiﬁer. The aim of this classiﬁer is
to indicate the emotional state (high or low arousal) of
the subject.

5) Train separate MI classiﬁers for each emotional state.
The goal is to optimize for accuracy, even if different
types of pre-processing and classiﬁer types were re-
quired for each state, unlike the arousal classiﬁer which
necessitates the same pre-processing steps.

6) During deployment, ﬁrst classify the emotional state
using the arousal classiﬁer, and based on its result,
choose the appropriate MI classiﬁer.

As mentioned previously, due to numerous factors, many steps
in the above formulation had to be either abandoned (2 and

Fig. 3: Virtual reality environments for inducing arousal in
subjects. On top is ’Height’ designed to induce high arousal
by placing the subject on the edge of a skyscraper. Below is
’Relaxation’ intended to lower arousal via a natural, calming
setting.

is using a VR height challenge – placing the subject on
higher ground in a virtual environment [14]. Not only does the
challenge induce high emotional arousal in test subjects, but
the control subjects – the ones who are not acrophobic – also
exhibit the same physiological responses as the test group i.e.
increased heart rate and skin conductance level [14]. Similarly,
VR environments, particularly those with natural scenery e.g. a
forest, have shown efﬁcacy in reducing stress [2] [3]. We thus
developed two VR environments: one where the subject was
placed on top of a skyscraper, called ’Height’ while the second
in a relaxing forest called ’Relaxation.’ The environments were
created using Unity 3D1.

B. Dataset

As this project was part of the CyberTUM team’s partic-
ipation in Cybathlon 2020, the original idea was to collect
real data with the actual pilots who will be competing in the
even proper. At the beginning of this work, however, no ethics
approval had been acquired to run any experiments on the
pilots. This was not detrimental to the project as a proof-
of-concept could still be arrived at by collecting EEG data
from volunteers within the CyberTUM team. The COVID-19
pandemic obstructed our means of collecting such data.

In the absence of our own motor-imagery and arousal data,
we opted for the Graz 2b data set [25]. It belongs to a family
of BCI datasets collected by the BCI Lab at Graz University

1https://unity.com/

3) or modiﬁed (4 and 5). The revised scheme, replaced steps
4-6 with the following:

1) Train a cross-subject classiﬁer replacing the arousal
classiﬁer. The task of this classiﬁer is to take EEG as
input from any of the two subjects, and classify the input
as belonging to either subject 1 or 2. As the classiﬁer is
agnostic to the subject, the same pre-processing had to
be done for each subject’s data.

2) Train separate MI classiﬁers for each subject instead of

training for each emotional state.

3) At test time, sample a run of a few data points (5 in our
experiments), feeding them to the cross-subject classi-
ﬁer. Based on its mode (most frequent classiﬁcation),
select the appropriate MI classiﬁer.

E. Learning algorithms

We experimented with a multitude of machine learning

algorithms which are brieﬂy described as follows.

a) Logistic regression: Logistic regression is a modiﬁca-
tion of linear regression for a binary classiﬁcation task [21].
It predicts the probability of a class given the input, by ﬁrst
learning a weighted linear combination of input features and
applying a logistic function to the result.

(a) Plotting ICA with EOG channels. A visual depiction of the ﬁrst
component (in red) of ICA being correlated with EOG.

1

(1)

y =

1 + e−a where a = θ0 + θ1.x1 + θ2.x2
b) Linear discriminant analysis: LDA attempts to maxi-
mize inter-class variance while minimizing intra-class variance
[4] in the data. This results in a clustering of the data where
it is easily separable. It is widely used in MI BCI [58] [58].
c) Naive Bayes: A probabilistic classiﬁer, naive bayes
uses bayes’ law to calculate the posterior probability of an
event (class) given the prior and likelihood [33]. The posterior
can then be updated with new evidence. It assumes that the
features are independent, hence the term naive in its name.

P (y|x) =

P (y).P (x|y)
P (x)

(b) Plotting ICA components against each other. The peak in the ﬁrst
component (blue) evidently due to an eye-blink.

(2)

d) Ensemble model: This is implemented as a voting
classiﬁer in gumpy. It uses a mix of classiﬁers such as nearest-
neighbor, LDA and support vector machines (SVM) and uses
the majority vote as the classiﬁcation output. As such,
it
necessarily either equals or outperforms both Naive Bayes and
LDA as it uses them in the ensemble.

A. Artifact Removal

IV. RESULTS

The data for subject 1 and 2 contained 324 and 399 trials
(attempts at moving right or left hand) respectively. The
standard approach to train MI classiﬁers is to analyze data and
remove existing artifacts before extracting features from the
data [55]. We ﬁrst applied a Butterworth bandpass ﬁlter [11] to
extract frequencies within the range 2-60 Hz. We then analyze
the data for artifacts. A common source of artifacts in MI data
is noise from electrodes located in the forehead’s proximity.
This is in fact data collected from the Electrooculography

Fig. 4: Artifact analysis using ICA for subject 1.

(EOG) channels which detect movements such as eye blinks,
which may show up in the MI data. Such noise can be
detected by ﬁrst performing independent component analysis
(ICA) – widely used in EEG preprocessing [30] – which tries
to decompose a signal into constituent component under the
assumption of statistical independence. We then see which of
the resultant components correlates most with EOG channels,
and ﬁlter it out [57]. An example of ICA on subject 1 can
be seen in ﬁgure 4. We ﬁlter out the ﬁrst component which
seems to be picking up an eye blink. ICA on subject 2 did not
improve the results.

B. Feature Extraction

Several methods were attempted to extract features. In
principle, feature extraction in BCI takes two forms: frequency
band selection and channel selection (also known as spatial

(a) PCA visualization of subject 1’s feature vector.

(b) PCA visualization of subject 2’s feature vector.

Fig. 5: Dimensionality reduction using PCA for feature space visualization of both subjects. Subject 2’s features are more
informative for the motor-imagery task compared to subject 1 which is also reﬂected in the training accuracy. Right hand
movements are labeled red while left hand movements are blue.

ﬁltering). In regards to the former, we’ve previously mentioned
in II-C that alpha and beta bands have been shown to be most
related to MI activity. Accordingly, we use these frequency
bands as our features. In the same section we observed that
channels C3 and C4 are the most relevant for MI, which we
can use directly without any spatial ﬁltering. For this, instead
of using raw alpha and beta patterns, we opt for logarithmic
sub-band powers of said patterns (see gumpy documentation2).
Each spectrum is divided into four sub-bands. An alternative
approach for feature extraction in MI classiﬁcation has been
the use of the ”common spatial pattern (CSP)” algorithm
[22]. It tries to ﬁnd optimal variances of subcomponents of
a signal [43] with respect to a given task. In our experiments,
however, CSP performed poorly compared to logarithmic sub-
band power of alpha and beta bands. The results when CSP
was applied have thus been omitted from the report, but
could be reproduced in the notebook (see section IX-A). A
visualization of the features using PCA for both subjects can
be seen in ﬁgure 5. As can be observed, the features for
subject 2 are more conducive to discrimination of MI. This is
also veriﬁed in the training results, where every classiﬁcation
algorithm achieved higher accuracy for subject 2 compared to
subject 1.

C. Training

As mentioned previously, we train two types of classiﬁers:
MI per subject classiﬁer and cross-subject classiﬁer. The entire
training procedure is visually depicted in ﬁgure 6. After doing
feature extraction, we ﬁrst train an MI classiﬁer for each
subject with labels 0 and 1 (left and right hand movement
respectively). Subsequently, we combine data of both subjects,
labelling it 0 and 1 (subject 1 and subject 2 respectively) and
train the cross-subject classiﬁer. All classiﬁers described in
III-E are trained in each case, the results of which can be
seen in table I.

a) MI classiﬁcation: The data for each subject was
divided into an 80-20 split (training-test). The features were
also standardized by rescaling to zero mean and unit standard
deviation. Results for both subjects were satisfactory, although
subject 1’s data was harder to train on compared to subject 2.

2http://gumpy.org/

Fig. 6: Training scheme for both classiﬁers. MI classiﬁers are
trained separately for each subject (labels corresponding to
right and left hand) while Cross-subject classiﬁer trained on
features of both subjects.

This can be observed by looking at the ranges of training ac-
curacy for both subjects [55.84-70.12 vs. 91.25-95]%. Subject
2’s classiﬁers achieved both a higher average accuracy as well
as lower variance. LDA performed best for subject 1, while
logistic regression achieved best results for subject 2.

b) Cross-subject

classiﬁcation: Training for

cross-
subject classiﬁers followed the same procedure of feature
extraction with the only difference being a re-labeling of the
samples from limb movements to source subject. Once again,
we split the data into 80-20 (train-test) portions, though this
time the data is the combined samples from both subjects. For
testing the classiﬁers, we split the test set further into sections
containing ﬁve samples (trials) each. For each section, we take
the mode (most frequent prediction) of the classiﬁer which is
considered the ﬁnal result. For example, if our test data has
50 samples from each subject, we portion it into 20 sections
(each subject with 10 sections). We then feed each section

0110000011111011MI Labels, Subject 1Cross-Subject LabelsMI Labels, Subject 2Features, Subject 2Features, Subject 1Cross-SubjectClassiﬁerMI Classiﬁer,Subject 1MI Classiﬁer,Subject 2to the classiﬁer and take the majority score for that section
as the classiﬁer’s prediction. As can be seen, the ensemble
model outperforms the rest of the algorithms by a considerable
margin. In addition to this, we also created t-SNE embeddings
of the features with 2 and 3 dimensions [26]. The results were
not up to par and have thus been left out here (they can be
reproduced via the notebook discussed in IX-A). More details
can be found in V.

TABLE I: Summary of results. Accuracy scores for MI (both
subjects) as well as cross-subject (X-sub) using various clas-
siﬁers. Best results in bold

Task

MI-sub 1
MI-sub 2
X-sub

Logistic Regression
67.53%
95%
58.65%

Classiﬁer
LDA
70.12%
91.25%
59.38%

Naive Bayes
55.84%
91.25%
59.38%

Ensemble
70.12%
93.75%
68.75%

V. DISCUSSION

The results indicate that assuming different emotional states
impart sufﬁcient differences in EEG data, we can train classi-
ﬁers that perform well above chance. Signiﬁcant differences in
the EEG signals between both subjects were observed during
feature extraction and classiﬁcation. This is not an uncommon
phenomenon and has been documented in the literature [41].
Blankertz et. al show that after testing on 80 subjects, the
average classiﬁer accuracy of a binary task was 74.4% with
a spread of 16.5% [6]. Our ﬁndings buttress this as the
best models for subject 1 and 2 achieved 75.38% and 95%
accuracy respectively. This variability generally chalked up
to differences in the subjects’ abilities for implicit learning
[23], performance in early neurofeedback sessions [35] and
attention spans [12].

According to Tangermann et. al, the best results on data set
2b were achieved using ﬁlter-bank CSP as a pre-processing
step followed by a naive bayes classiﬁer during Competition
IV [53]. In our testing, however, vanilla CSP for feature ex-
traction was sub-optimal. Naive bayes was also found trailing
behind other classiﬁers as seen in table I. We thus observe
that vanilla CSP is not as performant as log band-power in
our experiments, while we did not perform any experiments
with ﬁlter-bank CSP.

In regards to cross-subject classiﬁcation, appreciable results
have been achieved by using ICA for feature extraction [54]
combined with a nearest-neighbor (NN) classiﬁer. We verify
the efﬁcacy of ICA as a pre-processing step for feature
extraction. Other approaches have shown PCA as an effective
step for dimensionality reduction [38]. While we could not
conﬁrm this with PCA, using the more modern dimension-
ality reduction technique of t-SNE performed poorly in our
experiments (tested using target dimensions 2 and 3). There
is, however, recent evidence that using t-SNE in tandem with
common dictionary learning may yield good results [36].

A. Limitations and Future Outlook

A primary limitation of this work is the lack of testing
on actual subjects. While the system ensures acceptable per-
formance on an existing dataset, we can not conclude much
about its usefulness in the real-world. To make such assertions
with a certain degree of conﬁdence, we need to evaluate how
quickly we can switch between various MI classiﬁers based on
the predictions of the emotion (cross-subject) classiﬁer. This
is also true for calibration time at the start of each session;
while we use ﬁve trials during testing and get well above-
chance results, comprehensive and systematic veriﬁcation of
the system is in order if it is to be of any practical use.

In addition to alpha patterns, gamma bands are correlated
with increased arousal [41], which may have carried a strong
supervision signal for the classiﬁer. Had we acquired EEG
data for aroused and relaxed states of a subject, an emphasis
on gamma bands would have been warranted. As such, in
the present case, as we did not have data corresponding to
high and low arousal, gamma patterns were assumed not to
be informative.

Future work may also look at training classiﬁers for more
than two subjects. While two subjects sufﬁce for the purposes
of this study, as the original
task was the discrimination
between two emotional states of arousal, it may be worth
exploring how the cross-subject classiﬁer would scale to addi-
tional classes. This may be interpreted as having to classify not
only emotional arousal but also valence (positive or negative)
which may have important ethical implications.

Most of the classiﬁers used in this project are classic
algorithms, and were chosen for their still prevailing use in
MI BCI. However, future work may also incorporate modern
approaches such as deep neural networks for MI classiﬁcation
[52]. Deep learning could also be used to formulate our
problem as that of multi-task learning for both arousal and
MI classiﬁcation [50]. In this manner we can replace training
multiple classiﬁers with a single one which both classiﬁes
emotional arousal as well as motor imagery.

VI. INTERDISCIPLINARY WORK

The nature of this project necessitated the undertaking of a
multi-disciplinary approach, from understanding and system-
atizing human emotional arousal to developing algorithms for
distinguishing both emotional states as well as motor function
via EEG. Thus, this work borrows, incorporates and synthe-
sizes elements from a number of disciplines including psy-
chology (emotional arousal), neuroscience (EEG and motor-
imagery), computer graphics (virtual reality environments)
and artiﬁcial intelligence (machine learning for classiﬁcation).
Broadly, we can categorize psychology and neuroscience as
brain sciences and computer graphics and artiﬁcial intelligence
under the umbrella of informatics. Each of the two disciplines
contributed unique methods and insights without which the
project may not have come to fruition. The most valuable
insight was the difﬁculty in training accurate machine learning
algorithms for EEG. Although machine learning has become
the dominant paradigm for classiﬁcation tasks, this project

demonstrates that pre-processing of data (via techniques such
as ICA and log power-band) is at least as important to the
success of the system as the classiﬁer (the results for other
feature extractors can be reproduced in the provided note-
book), and even after pre-processing, we have no guarantees
of robust performance. Another key insight was the extent to
which EEG patterns vary between different people, pointing
to the difﬁculty of transfer learning in this domain.

VII. CONCLUSION

A major hurdle in the widespread and practical use of
assistive systems based on MI-BCI is lack of reliability. While
this can have many origins, an important source as identiﬁed
by two Cybathlon teams in 2016 was related to shifts in the
subject’s state of emotional arousal. In this work, we present
an end-to-end framework for inducing high/low arousal in
subjects, collecting EEG data and train learning algorithms
for robust MI classiﬁcation. While COVID-19 enforced certain
constraints on data acquisition, we were still able to develop
a proof-of-concept for how emotion-robust MI-BCI systems
could be trained. Our results indicate that if the training signal
contains sufﬁcient information i.e. each emotional state has
a distinct enough EEG signature, we can successfully train
systems that are robust to variance in emotional arousal. A
thorough study, however, needs to be conducted to determine
the practicality of such a system with respect to variables such
as classiﬁer switching times and calibration periods.

VIII. ACKNOWLEDGMENTS

This project could not have been possible without the aid
of Nicholas Berberich who provided constant and quality
guidance on overall methodology, feature extraction and algo-
rithms. Also worth gratitude are Matthijs Pals for his support in
regards to MI data preprocessing and Svea Meyer for helping
in the initial phase of the project as well as with explaining
EEG terminology.

REFERENCES

[1] Reza Abiri, Soheil Borhani, Eric W Sellers, Yang Jiang, and Xiaopeng
Zhao. A comprehensive review of eeg-based brain–computer interface
paradigms. Journal of neural engineering, 16(1):011001, 2019.

[2] Allison P Anderson, Michael D Mayer, Abigail M Fellows, Devin R
Cowan, Mark T Hegel, and Jay C Buckey. Relaxation with immersive
natural scenes presented using virtual reality. Aerospace medicine and
human performance, 88(6):520–526, 2017.

[3] Matilda Annerstedt, Peter J¨onsson, Mattias Wallerg˚ard, Gerd Johansson,
Bj¨orn Karlson, Patrik Grahn, ˚Ase Marie Hansen, and Peter W¨ahrborg.
Inducing physiological stress recovery with sounds of nature in a virtual
reality forestresults from a pilot study. Physiology & behavior, 118:240–
250, 2013.

[4] Suresh Balakrishnama and Aravind Ganapathiraju. Linear discriminant
analysis-a brief tutorial. Institute for Signal and information Processing,
18:1–8, 1998.

[5] Thomas Baumgartner, Lilian Valko, Michaela Esslen, and Lutz J¨ancke.
Neural correlate of spatial presence in an arousing and noninteractive
virtual reality: an eeg and psychophysiology study. CyberPsychology &
Behavior, 9(1):30–45, 2006.

[6] Benjamin Blankertz, Claudia Sannelli, Sebastian Halder, Eva M. Ham-
mer, Andrea Kbler, Klaus-Robert Mller, Gabriel Curio, and Thorsten
Dickhaus. Neurophysiological predictor of smr-based bci performance.
NeuroImage, 51(4):1303 – 1309, 2010.

[7] Margaret M. Bradley, Mark K. Greenwald, Mark C. Petry, and Peter J.
Lang. Remembering pictures: pleasure and arousal in memory. Journal
of experimental psychology. Learning, memory, and cognition, 18 2:379–
90, 1992.

[8] Anne-Marie Brouwer and Maarten A Hogervorst. A new paradigm
to induce mental stress: the sing-a-song stress test (ssst). Frontiers in
neuroscience, 8:224, 2014.

[9] Ujwal Chaudhary, Niels Birbaumer, and Ander Ramos-Murguialday.
Brain–computer interfaces for communication and rehabilitation. Nature
Reviews Neurology, 12(9):513, 2016.

[10] Hugo D Critchley. Electrodermal responses: what happens in the brain.

The Neuroscientist, 8(2):132–142, 2002.

[11] SS Daud and R Sudirman.

Butterworth bandpass and stationary
wavelet transform ﬁlter comparison for electroencephalography signal.
In 2015 6th international conference on intelligent systems, modelling
and simulation, pages 123–126. IEEE, 2015.

[12] I Daum, B Rockstroh, N Birbaumer, T Elbert, A Canavan, and
W Lutzenberger. Behavioural treatment of slow cortical potentials in
intractable epilepsy: neuropsychological predictors of outcome. Journal
of Neurology, Neurosurgery & Psychiatry, 56(1):94–97, 1993.

[13] Marcos Del Pozo-Banos, Jes´us B Alonso, Jaime R Ticay-Rivas, and
identiﬁcation: A

Carlos M Travieso. Electroencephalogram subject
review. Expert Systems with Applications, 41(15):6537–6554, 2014.
[14] Julia Diemer, Nora Lohkamp, Andreas M¨uhlberger, and Peter Zwanzger.
Fear and physiological arousal during a virtual height challengeeffects
in patients with acrophobia and healthy controls. Journal of anxiety
disorders, 37:30–39, 2016.

[15] Bernhard Graimann, Brendan Z Allison, and Gert Pfurtscheller.
Brain-computer interfaces: Revolutionizing human-computer interac-
tion. Springer Science & Business Media, 2010.

[16] Eva Maria Hammer, Sebastian Halder, Benjamin Blankertz, Claudia
Sannelli, Thorsten Dickhaus, Sonja Kleih, Klaus-Robert M¨uller, and
Andrea K¨ubler.
Psychological predictors of smr-bci performance.
Biological psychology, 89(1):80–86, 2012.

[17] H. Hockenbury. Discovering Psychology. Worth Publishers, Incorpo-

rated, 2000.

[18] Camille Jeunet, Emilie Jahanpour, and Fabien Lotte. Why standard
brain-computer interface (bci) training protocols should be changed: an
experimental study. Journal of neural engineering, 13(3):036024, 2016.
[19] Hye-Rin Kim, Henry Kang, and In-Kwon Lee. Image recoloring with
valence-arousal emotion model. Comput. Graph. Forum, 35:209–216,
2016.

[20] Clemens Kirschbaum, Karl-Martin Pirke, and Dirk H Hellhammer. The
trier social stress test–a tool for investigating psychobiological stress
responses in a laboratory setting. Neuropsychobiology, 28(1-2):76–81,
1993.

[21] David G Kleinbaum, K Dietz, M Gail, Mitchel Klein, and Mitchell

Klein. Logistic regression. Springer, 2002.

[22] Z. J. Koles, Michael S. Lazar, and S Z Zhou. Spatial patterns underlying
population differences in the background eeg. Brain Topography, 2:275–
284, 2005.

[23] Irene Daum Marcus Schugens Niels Birbaumer Boris Kotchoubey,
Stephan Haisst. Learning and self-regulation of slow cortical potentials
in older adults. Experimental aging research, 26(1):15–35, 2000.
[24] Merel Krijn, Paul MG Emmelkamp, Ragnar P Olafsson, and Roeline
Biemond. Virtual reality exposure therapy of anxiety disorders: A
review. Clinical psychology review, 24(3):259–281, 2004.

[25] R Leeb, C Brunner, G M¨uller-Putz, A Schl¨ogl, and G Pfurtscheller.
Bci competition 2008–graz data set b. Graz University of Technology,
Austria, pages 1–6, 2008.

[26] Ming-ai Li, Xin-yong Luo, and Jin-fu Yang. Extracting the nonlinear
features of motor imagery eeg using parametric t-sne. Neurocomput.,
218(C):371381, December 2016.

[27] Yi-Hung Liu, Shiuan Huang, and Yi-De Huang. Motor imagery
eeg classiﬁcation for patients with amyotrophic lateral sclerosis using
fractal dimension and ﬁshers criterion-based channel selection. Sensors,
17(7):1557, 2017.

[28] Fabien Lotte, Florian Larrue, and Christian M¨uhl. Flaws in current
human training protocols for spontaneous brain-computer interfaces:
lessons learned from instructional design. Frontiers in human neuro-
science, 7:568, 2013.

[29] Anna-Lena Lumma, Bethany E Kok, and Tania Singer.

Is meditation
always relaxing? investigating heart rate, heart rate variability, experi-

enced effort and likeability during training of three types of meditation.
International Journal of Psychophysiology, 97(1):38–45, 2015.

[30] Scott Makeig, Anthony J. Bell, Tzyy-Ping Jung, and Terrence J. Se-
Independent component analysis of electroencephalographic
jnowski.
In Proceedings of the 8th International Conference on Neural
data.
Information Processing Systems, NIPS95, page 145151, Cambridge,
MA, USA, 1995. MIT Press.

[31] M Mather and MR Sutherland. The selective effects of emotional arousal

on memory. Psychol. Sci. Agenda, 2012.

[32] Anat Mirelman, Inbal Maidan, and Judith E Deutsch. Virtual reality
and motor imagery: promising tools for assessment and therapy in
parkinson’s disease. Movement Disorders, 28(11):1597–1608, 2013.
[33] Kevin P Murphy et al. Naive bayes classiﬁers. University of British

Columbia, 18:60, 2006.
[34] Tam´as Nagy, David Tellez,

´Ad´am Div´ak, Emma L´og´o, M´at´e K¨oles,
and Bal´azs H´amornik. Predicting arousal with machine learning of eeg
signals. In 2014 5th IEEE Conference on Cognitive Infocommunications
(CogInfoCom), pages 137–140. IEEE, 2014.

[35] N Neumann and N Birbaumer. Predictors of successful self control dur-
ing brain-computer communication. Journal of Neurology, Neurosurgery
& Psychiatry, 74(8):1117–1121, 2003.

[36] Takashi Nishimoto, Hiroshi Higashi, Hiroshi Morioka, and Shin Ishii.
Eeg-based personal identiﬁcation method using unsupervised feature
extraction and its robustness against intra-subject variability. Journal
of Neural Engineering, 17(2):026007, 2020.

[37] Natasha Padﬁeld, Jaime Zabalza, Huimin Zhao, Valentin Masero, and
Eeg-based brain-computer interfaces using motor-

Jinchang Ren.
imagery: Techniques and challenges. Sensors, 19(6):1423, 2019.
[38] Ramaswamy Palaniappan and Danilo P Mandic. Energy of brain poten-
tials evoked during visual stimulus: A new biometric? In International
Conference on Artiﬁcial Neural Networks, pages 735–740. Springer,
2005.

[39] Serafeim Perdikis, Luca Tonin, Sareh Saeedi, Christoph Schneider, and
Jos´e del R Mill´an. The cybathlon bci race: Successful longitudinal mu-
tual learning with two tetraplegic users. PLoS biology, 16(5):e2003787,
2018.

[40] Gert Pfurtscheller, Ch Neuper, Doris Flotzinger, and Martin Pregen-
zer. Eeg-based discrimination between imagination of right and left
hand movement. Electroencephalography and clinical Neurophysiology,
103(6):642–651, 1997.

[41] Diego A Pizzagalli et al. Electroencephalography and high-density
electrophysiological source localization. Handbook of psychophysiology,
3:56–84, 2007.

[42] Jonathan Posner, James A Russell, and Bradley S Peterson.

The
circumplex model of affect: An integrative approach to affective neu-
roscience, cognitive development, and psychopathology. Development
and psychopathology, 17(3):715–734, 2005.

[43] H. Ramoser, J. Muller-Gerking, and G. Pfurtscheller. Optimal spatial
IEEE
ﬁltering of single trial eeg during imagined hand movement.
Transactions on Rehabilitation Engineering, 8(4):441–446, 2000.
[44] Herbert Ramoser, Johannes Muller-Gerking, and Gert Pfurtscheller. Op-
timal spatial ﬁltering of single trial eeg during imagined hand movement.
IEEE transactions on rehabilitation engineering, 8(4):441–446, 2000.

[45] Robert Riener and Linda J Seward. Cybathlon 2016.

In 2014 IEEE
International Conference on Systems, Man, and Cybernetics (SMC),
pages 2792–2794. IEEE, 2014.

[46] Mouad Riyad, Mohammed Khalil, and Abdellah Adib. Cross-subject eeg
signal classiﬁcation with deep neural networks applied to motor imagery.
In International Conference on Mobile, Secure, and Programmable
Networking, pages 124–139. Springer, 2019.

[47] Gonzalo M Rojas, Carolina Alvarez, Carlos E Montoya, Mar´ıa de la
Iglesia-Vay´a, Jaime E Cisternas, and Marcelo G´alvez. Study of resting-
state functional connectivity networks using eeg electrodes position as
seed. Frontiers in neuroscience, 12:235, 2018.

[48] James A Russell. A circumplex model of affect. Journal of personality

and social psychology, 39(6):1161, 1980.

[49] Peter Sedlmeier, Juliane Eberth, Marcus Schwarz, Doreen Zimmermann,
Frederik Haarig, Sonia Jaeger, and Sonja Kunze. The psycholog-
ical effects of meditation: a meta-analysis. Psychological bulletin,
138(6):1139, 2012.

[50] Y. Song, D. Wang, K. Yue, N. Zheng, and Z. M. Shen. Eeg-based
In 2019
motor imagery classiﬁcation with deep multi-task learning.
International Joint Conference on Neural Networks (IJCNN), pages 1–
8, 2019.

[51] Karina Statthaler, Andreas Schwarz, David Steyrl, Reinmar Kobler,
Maria Katharina H¨oller, Julia Brandstetter, Lea Hehenberger, Marvin
Bigga, and Gernot M¨uller-Putz. Cybathlon experiences of the graz bci
racing team mirage91 in the brain-computer interface discipline. Journal
of neuroengineering and rehabilitation, 14(1):129, 2017.

[52] Yousef Rezaei Tabar and Ugur Halici. A novel deep learning approach
for classiﬁcation of EEG motor imagery signals. Journal of Neural
Engineering, 14(1):016003, nov 2016.

[53] Michael Tangermann, Klaus-Robert M¨uller, Ad Aertsen, Niels Bir-
baumer, Christoph Braun, Clemens Brunner, Robert Leeb, Carsten
Mehring, Kai J Miller, Gernot Mueller-Putz, et al. Review of the bci
competition iv. Frontiers in neuroscience, 6:55, 2012.

Selecting relevant eeg signal

identiﬁcation problem using ica and neural network.

[54] Preecha Tangkraingkij, Chidchanok Lursinsap, Siripun Sanguansintukul,
locations for
and Tayard Desudchit.
In
personal
2009 Eighth IEEE/ACIS International Conference on Computer and
Information Science, pages 616–621. IEEE, 2009.
[55] Jose Antonio Urig¨uen and Bego˜na Garcia-Zapirain.

Eeg artifact
removalstate-of-the-art and guidelines. Journal of neural engineering,
12(3):031001, 2015.

[56] Carmen Vidaurre and Benjamin Blankertz. Towards a cure for bci

illiteracy. Brain topography, 23(2):194–198, 2010.

[57] G. Wang, C. Teng, K. Li, Z. Zhang, and X. Yan. The removal of eog
artifacts from eeg signals using independent component analysis and
multivariate empirical mode decomposition. IEEE Journal of Biomedical
and Health Informatics, 20(5):1301–1308, 2016.

[58] Yijun Wang, Shangkai Gao, and Xiaornog Gao. Common spatial pattern
method for channel selelction in motor imagery based brain-computer
In 2005 IEEE Engineering in Medicine and Biology 27th
interface.
Annual Conference, pages 5392–5395. IEEE, 2006.

[59] Jonathan R Wolpaw, Niels Birbaumer, Dennis J McFarland, Gert
Pfurtscheller, and Theresa M Vaughan. Brain–computer interfaces for
communication and control. Clinical neurophysiology, 113(6):767–791,
2002.

[60] Wilhelm Max Wundt and Charles Hubbard Judd. Outlines of psychology,

volume 1. Scholarly Press, 1897.

IX. APPENDICES

A. Documentation

The VR environments developed for this project can be

found on the following Google Drive links:

• Forest VR - https://tinyurl.com/y79dxk87
• Height VR - https://tinyurl.com/yaqrmveu

and

The environments were created using Unity version 2018.4.14f
with the post-processing stack enabled. All code written for
this project pertaining to training can be found on LRZ Gitlab
using the following link: https://gitlab.lrz.de/cybertum/eeg-
https://github.com/Abdul-Moeed/eeg-
classiﬁcation
classiﬁcation. The Jupyter notebook titled ’Classiﬁer Demo’
contains the crux of the code; the rest of the scripts were
created for testing tools and techniques. To reproduce ICA
plots, run ’classiﬁer.py’. The data used in this project can be
found at http://www.bbci.de/competition/iv/ under ’Data sets
2b’. Further information on reproducibility can be found in
the repository’s README.

B. Methodological Reﬂections

1) What would you do differently next time in your ex-
perimental/technical setup? A major challenge, com-
pounded by COVID-19, was the collection of arousal
data. We were originally planning to use the Biopac sys-
tem (BIOPAC Systems, Inc., Goleta, California, United
States) for measuring skin conductance. The procedure

is involved and somewhat cumbersome, and could have
been substituted with a heart rate sensor. Heart rate
measurement is also an indicator of emotional arousal
levels, and has the added beneﬁt of being present in
a smart watch. This would have made data acquisition
simpler. Another important step would have been to test
the efﬁcacy of VR environments in inducing high/low
arousal
in systematic trials under control. Although
there already exists evidence that VR has been known
to impart such states,
to observe its effect on EEG
data would have been desirable. Finally, while classic
machine learning is still widely used in MI classiﬁcation,
we observed, at least in subject 1’s case, the difﬁculty
in training a robust classiﬁer. Perhaps opting for deep
learning, which has shown increased performance in
other domains such as computer vision and natural
language processing, may have been promising.
2) What went really good/easier than expected?

The
creation of VR environments was surprisingly simple
due to vast community support for Unity 3D. Integrating
VR controls in the environments was slightly more
involved but went rather smoothly. Regarding training:
Besides feature extraction, training the classiﬁers was
fairly straightforward. This was in part due to previous
experience working with machine learning and in part
because of easy-to-use implementations of common al-
gorithms in existing libraries.

3) What kinds of skills would you need to learn in your
studies to do such a project even better (machine
learning, statistics, psychology, neuroscience)? Taking
a course on BCI prior to working on this project would
have substantially accelerated development. Trying to
get familiarized with methods and terminology of the
ﬁeld was a major part of the project, but it also entailed
allocating time for such self-study which could have
been dedicated to development had prior knowledge in
this domain been acquired. Thus a course on neurofeed-
back and BCI would have made the project better.
4) If you tried out an approach which you later on aban-
doned, you can report this here as well. Give reasons
why you decided not to pursue this approach. During
the training of MI classiﬁers, initially I used data from
certain sessions for each subject. This yielded scores
with high variance, even for the same subject for dif-
ferent sessions. I abandoned this by taking data from
all sessions for each subject and using that for training
instead.

