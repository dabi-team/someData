1
2
0
2

n
u
J

5
1

]
T
I
.
s
c
[

1
v
5
6
1
8
0
.
6
0
1
2
:
v
i
X
r
a

1

QoE Driven VR 360◦ Video Massive MIMO

Transmission

Long Teng, Guangtao Zhai, Senior Member, IEEE, Yongpeng Wu, Senior Member, IEEE,

Xiongkuo Min, Member, IEEE, Wenjun Zhang, Fellow, IEEE, Zhi Ding, Fellow, IEEE, and

Chengshan Xiao, Fellow, IEEE

Abstract

Massive multiple-input and multiple-output (MIMO) enables ultra-high throughput and low latency
for tile-based adaptive virtual reality (VR) 360◦ video transmission in wireless network. In this paper,

we consider a massive MIMO system where multiple users in a single-cell theater watch an identical
VR 360◦ video. Based on tile prediction, base station (BS) deliveries the tiles in predicted ﬁeld of view

(FoV) to users. By introducing practical supplementary transmission for missing tiles and unacceptable

VR sickness, we propose the ﬁrst stable transmission scheme for VR video. we formulate an integer

non-linear programming (INLP) problem to maximize users’ average quality of experience (QoE) score.

Moreover, we derive the achievable spectral efﬁciency (SE) expression of predictive tile groups and the

approximately achievable SE expression of missing tile groups, respectively. Analytically, the overall

throughput is related to the number of tile groups and the length of pilot sequences. By exploiting

the relationship between the structure of viewport tiles and SE expression, we propose a multi-lattice

multi-stream grouping method aimed at improving the overall throughput for VR video transmission.

Moreover, we analyze the relationship between QoE objective and number of predictive tile. We transform

the original INLP problem into an integer linear programming problem by setting the predictive tiles

groups as some constants. With variable relaxation and recovery, we obtain the optimal average QoE.

Extensive simulation results validate that the proposed algorithm effectively improves QoE.

Index Terms

L. Teng, G. Zhai, Y. Wu, X. Min, and W. Zhang are with the Institute of Image Communication and Information
Processing, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: tenglong@sjtu.edu.en; zhaiguangtao@sjtu.edu.cn;
yongpeng.wu@sjtu.edu.cn; minxiongkuo@sjtu.edu.cn; zhangwenjun@sjtu.edu.cn). (Corresponding authors: G. Zhai and Y. Wu.)

Z. Ding is with the Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA 95616

USA (e-mail: zding@ucdavis.edu).

C. Xiao is with the Department of Electrical and Computer Engineering, Lehigh University, Bethlehem, PA 18015 USA

(e-mail: xiaoc@lehigh.edu).

 
 
 
 
 
 
2

Tile-based adaptive VR 360◦ video, ﬁeld of view (FoV), tolerant latency, tile grouping, massive

MIMO, quality of experience (QoE), linear programming

I. INTRODUCTION

The recent explosive growth of smart devices and multimedia services strongly motivate the develop-

ment of new technology to deliver virtual reality (VR) 360◦ video across wireless networks. The ultra-high

resolution, high representation, panoramic scene, and multi-stimuli of VR provide a unique immersive

experience, allowing users to interact within an alternative world. Unlike traditional video, panoramic

scene of VR 360◦ video is captured by omnidirectional cameras. While watching VR videos, users may

freely adjust orientation to retrieve expected immersive scene as part of VR user interaction with support

from interactive sensors [1].

As discussed in [2], transmitting VR 360◦ video, characterized by ultra-high data rate and low latency,

presents critical challenges to wireless networking. Recent works have focused on compressing the

required data payload in the area of VR 360◦ video processing. For example, VR 360◦ video is projected

into a speciﬁc 2-D plane with multiple slices, and encoded with a established rule [3]. Generally, delivering

all slices is unnecessary considering that the ﬁeld of view (FoV) is limited. Transmitting only desired slices

is able to decrease the data size to effectively relieve network load [4]. Despite such efforts, transmitting

ultra-high resolution VR video in real-time remains unrealistic under limited wireless bandwidth and

throughput. Long transmission latency can cause human VR sickness. An alternative proposal is to apply

content buffering or caching [5], [6] in wireless edge or device in advance. To this end, content prediction

is necessary. Buffering predicted contents in devices before playback and adjusting the sequence of

encoded segments to reduce response latency are likely to lessen the impact of random head movement

[7] and the VR sickness caused by stall [2].

Content prediction techniques in VR mainly include saliency prediction and quality assessment. Saliency

[8] can describe the importance of different visual contents and can be used to obtain the scope of the

most visually appealing areas automatically. Quality assessment has also been widely used to analyze VR

360◦ video content. For example, [9] proposes a blind image quality assessment model based on multi-

channel convolutional neural network (CNN) architectures to accumulate the objective quality scores of

the VR 360◦ video, which can help derive the probable slices of interest. The success of CNN in slice

prediction for VR 360◦ image [10] and VR 360◦ video [4], [11] conﬁrms the capability of learning based

approach according to the user behaviors in predicting the “exact scope”. In fact, we leverage the result of

exact scope in next model and formulation. In particular, [12] utilizes gaze-aware streaming to limit the

provisioning of high video quality to areas near users’ ﬁxations, without quality loss in user perception.

3

Omnidirectional video coding is also an important element in VR. High efﬁciency video coding

(HEVC) [13] is standardized collaboratively by a joint video exploration team (JVET) of ITU-T VCEG

and ISO/IEC MPEG organizations, and the joint exploration model beyond HEVC developed by JVET

provides a well-performing encoder with manageable complexity, with potential to improve the coding

efﬁciency signiﬁcantly. In terms of sphere-to-plane coding on head mounted display (HMD), the work in

[14] shows that equirectangular format saves 8.3% bit rate trafﬁc. Considering the equirectangular format

of VR 360◦ video, tile-based projection (TBP) [11], [15]–[17], which splits the high resolution video

into several tiles, effectively reduces the transmitted data with low distortion according to the viewport

of user [3]. TBP is widely used in the projection process of VR video and exhibits strong advantages in

multicast application [18]1. Hence, in this work we apply the TBP with reasonable tile size to transmit

VR 360◦ video in wireless network.

Most existing VR 360◦ video transmission schemes explore the optimization algorithms in a certain

wireless network. With optimal transmission time and power allocation, [20] searches the multicast

opportunity to respectively minimize the average transmission energy for the given video quality and

maximize the video quality for the given energy budget in a time division multiple access (TDMA)

system. Based on the concept in [20], work in [21] exploits user transcoding and transcode-playback

mode aimed to maximize the multicast opportunity with the consideration of smoothness requirement in

a TDMA system. [22] deﬁnes a performance metric for perfect, imperfect and unknown FoV probability

distributions, and maximize the performance metric in a multi-carrier system.

In VR video transmission, the quality of experience (QoE) is paramount. Factors restricting QoE of

VR video have been extensively investigated in [7], [17], [23]–[26]. Most previous works adopt mean

opinion score based on subjective quality evaluation. Summarizing the works of [7], [17], [23]–[26],

there are three major factors of VR quality that should be investigated in wireless applications. The ﬁrst

is the overall tile quality perceived by multiple users, which relates to the network capacity. The second

is the uncomfortable visual perception caused by quality differences among tiles. The third is the stall

time caused by low transmission rate or data retransmission. Thus, we consider these three major factors

in the QoE model. Note that the stall time longer than tolerant latency is a major cause for VR sickness.

To the best of our knowledge, the performance of existing wireless transmission methods of VR 360◦

video has been less than satisfactory. The major obstacle is the poor tile quality caused by the low link

throughput. Moreover, current works focusing on VR video transmission in wireless networks [11], [18],

[23], [27] generally assume that the exact FoV can be predicted infallibly from machine learning and only

1Compared with unicast, multicast can substantially improve the overall achievable throughput [19].

4

transmit the predictied FoV. In addition, existing works, e.g., [20]–[22] try to search the exact FoV through

the viewing probability distribution, which leads to inaccurate results or requires many more tiles for

transmission. In practice, for the reason of exceptional head movement caused by multi-stimuli [24], e.g.,

when user is watching a scene with multi-stimuli like racing and roller coaster, the FoV is difﬁcult to be

predicted reliably and a much larger scope of tiles must be considered. In short, existing VR transmission

works have not systematically considered the real supplementary transmission for missing tiles, which

is likely to cause unacceptable latency, and perceptual difference due to spatial quality variance. These

shortcomings present challenges to user QoE of VR delivered over wireless network.

Massive multiple-input and multiple-output (MIMO) [28], can overcome effects of uncorrelated noise

and fast fading and deliver multiple streams to their respective users simultaneously. Base stations (BSs)

equipped with large-scale antenna arrays can effectively exploit the estimated channel matrix [29] to

provide high sum-rate [30] and signal quality [31]. Thus, massive MIMO has the potential to wirelessly

achieve the VR need for high-throughput and low access latency [32]. Moreover, the multiple tiles, treated

as multiple streams, can be easily transmitted to users simultaneously by taking advantage of the massive

MIMO systems. Integrating massive MIMO within VR video transmission has strong potential to improve

the QoE. Surprisingly, there has been very few existing efforts in this direction.

Existing works in [20]–[22] have proven that grouping and multicast can efﬁciently improve network

throughput. However, the multicast [20]–[22] is uni-stream multicast in TDMA. Moreover, there has

been no prior work that systematically combines the multi-stream multicast massive MIMO and VR

360◦ video transmission in the QoE optimization. Motivated by the need for supplementary transmission

for missing tiles and the potential offered by massive MIMO, we consider a practical and innovative

scenario involving QoE driven transmission of VR 360◦ video in multi-user massive MIMO wireless

networks. In this multicast setting, multiple users in a single-cell massive MIMO systems are engaged

in the same VR 360◦ video. Our goal is to implement the tile grouping and determine the quantity of

predictive tiles for maximizing the average QoE. Speciﬁcally, the main contributions of this paper are

summarized as follows:

•

•

We investigate the QoE driven VR 360◦ video transmission in multi-user massive MIMO systems,

and systematically combine multi-stream multicast massive MIMO and VR 360◦ video transmission

in the QoE optimization. According to the real supplementary transmission for missing tiles and the

unacceptable VR sickness, we propose a practical and stable transmission scheme. We formulate

the average QoE objective of watching an identical VR 360◦ video.

We derive a closed-form expression of the achievable spectral efﬁciency (SE) of predictive tile

groups and the approximately achievable SE of missing tile groups under the maximum ratio

5

transmission (MRT) and zero-forcing (ZF) precoding schemes, and allocate precoding power to

guarantee consistent delivery rate of each stream based on max-min fairness (MMF).

•

•

We analyze the relationship between SE and viewport tiles, and prove the existence of an optimal

multi-stream grouping based on rectangular viewport. We further propose a multi-lattice multi-stream

grouping (MLMSG) method to reduce the transmitted groups and pilot sequences during multicast.

We adopt a variable number of predictive tiles. By setting the number of predictive tile groups as

some constants, the original integer non-linear programming (INLP) problem is transformed into an

integer linear programming (ILP) problem to optimize the ﬁnal average QoE through relaxation and

recovery. Extensive simulations demonstrate that the proposed algorithm effectively improves VR

360◦ video QoE at low complexity.

The remainder of this paper is organized as follows. We present the system model and problem

formulation in Section II. Section III derives the achievable SE of each group tile in massive MIMO

system. And we propose the MLMSG in Section IV. In Section V, we maximize the average QoE by

turning the non-linear problem into a linear problem. Simulation results are presented in Section VI to

evaluate the performance of our proposed algorithm. We ﬁnally conclude our paper in Section VII.

Notations: Lower case, boldface lower case, and boldface upper case letters denote scalars, vectors,

and matrices, respectively; IN denotes the identity matrix of size N . x ∼

(0, Σ) indicates that x is a

CN

circularly symmetric complex Gaussian vector with zero mean and covariance matrix Σ. The superscripts

)H stand for the transpose, conjugate, and conjugate-transpose of a matrix, respectively.
)T , (
)∗, and (
(
·
·
·
We use E

x
⌋
|
|
stand for the smallest integer larger than or equals to x and the largest integer smaller than or equals to

to denote ensemble expectation and

to represent cardinality of a set x.

x
⌈

x
⌊

and

{·}

⌉

x, respectively.

II. SYSTEM MODEL AND PROBLEM FORMULATION

In this section, we introduce the system model which contains the tile-based adaptive regime in

VR video processing and the considered deployment scenario in wireless network. Then the problem

formulation maximizing the average QoE is presented.

A. Tile-Based Adaptive Regime

VR 360◦ video captured and stitched by omnidirectional camera has a spherical shape in the original

format. For a watching user, the scene within viewport is displayed in the HMD, and user can turn their

head and eyes to track the interesting contents as illustrated in Fig. 1(a). Utilizing the typical tilling

approach [3], the whole spherical streaming is projected into an equirectangular format with multiple

6

sized tiles as shown in Fig. 1(b), which can be encoded according to a set of quality levels. It is noted that

the equator of VR sphere is projected into the horizontally intermediate line of equirectangular. Denote

the coordinate origin as O, the horizontal coordinate set as

, and the vertical coordinate set as

, then

V

H

the tile index in the equirectangular can be represented by ζ(x, y), x

, y

∈ H

∈ V

. Without moving head,

FoV covering 150◦ horizontally and 120◦ vertically including eyes movement is recommended in [2].

Accordingly, the tiles contained FoV are encoded in high quality and the remaining ones can be encoded

in basic low-quality or abandoned to improve the QoE under limited network capacity. Simultaneously,

HMD sensors can feel user movement and activities, and can provide helpful information to predict the

desired tiles and implement tile-based adaption.

y

yaw

x
pitch

z

roll

Middle
line

Roll

Equator

Tiles

(a) Head rotation direction

(b) Equirectangular
format

format and FoV

Fig. 1.

(a) Head rotation model; and (b) equirectangular projection based on tiling approach.

B. Deployment Scenario

We consider an open VR theater with seats arranged in multiple cycles in a single-cell, where each user

wears a single-antenna HMD and seats on a rotatable but ﬁxed chair. There are K active users indexed

by set

=

1,
{

K

, K

}

· · ·

and the transmission bandwidth is W . The scenario is illustrated in Fig. 2,

where the BS equipped with N antennas locates in the center to serve the K active users simultaneously

in the time division duplexing (TDD) mode. The powers of HMD and BS are denoted as Pu and Pd,

respectively. In the scenario, the radii of inner cycle and outer cycle are r1 and r2, respectively.

Assume a block-fading channel model which remains invariant in each coherence interval T , where

T is the product of the coherence bandwidth CB and coherence time CT . Further, the duration of

exceptional head movement is relative small compared with the coherence time such that Doppler

frequency offsets can be negligible. In the system, we consider uncorrelated Rayleigh fading channel

7

responses, and denote hk as the channel response of user k, i.e., hk

(0, ψkIN ), where ψk is the

∼ CN

large-scale fading coefﬁcient. Note that practical channels might have spatially correlated fading or line of

sight components, but theoretical studies and practical measurements carried out in real massive MIMO

propagation environments have shown that SE can be predicted using uncorrelated fading models [33].

Moreover, this channel model enables us to present novel insights into VR 360◦ video massive MIMO

transmission.

Within each coherence interval, we focus on uplink pilot transmission and downlink data transmission.

During uplink pilot transmission, users send uplink pilots to enable BS to estimate their respective uplink

channels. The pilots in classic unicast massive MIMO system are orthogonal. Applying the concept of

co-pilot proposed in [19], the users assigned to receive the same tile would share a pilot in each multicast

stream. It is therefore reasonable to assume that the pilots of different streams are orthogonal. Taking

advantage of reciprocity between uplink and downlink channels in TDD, the BS performs downlink

precoding based on the estimated channels and deliveries the tile.

Fig. 2. Multiple users experiencing VR 360◦ video in a massive MIMO cell.

The FoV can move arbitrarily by rotation in the directions of pitch, yaw, and roll. Denote the angle

between the middle line of viewport and equator as θ, which is inﬂuenced by the rotation in the direction

of roll. We illustrate the relationship between θ and roll direction in Fig. 1(b). It was shown in [34] that

a large proportion of ﬁxation distributes near the equator, and the authors of [11] stated that rotation in

the direction of roll is negligible compared with the other two directions. Hence, we mainly focus on

θ = 0 where predictive FoV tiles are rectangle in shape. Further, the number of tiles different between

the FoV and the exact scope is directly and positively correlated to the distribution area of multi-stimuli

around a certain viewport [4]. Over 80% prediction accuracy can be obtained by machining learning [4],

[35]. Thus the exact scope that can be predicted is consequently a little larger than the FoV. In addition,

the structural similarity proposed in [36] recommends that the predictive tiles reside in the middle of the

8

exact scope. We apply this concept in tile buffering. For clarity, we illustrate the case in Fig. 3. Without

fully accurate prediction, BS transmits desired missing tiles, i.e., the tiles within exact scope outside

the predictive set, to supplementally meet user needs. The BS has completely cached the original VR

360◦ video and the HMD has ability of buffering and computing. The BS leverages the existing CNN

prediction model to calculate the prospective viewports of each user, and transmits the corresponding

data to HMDs in advance. Having received the transmitted data, the HMD selectively arranges the tiles,

stitches 2-dimensional (2D) tiles into 3-dimensional (3D) FoV, renders and displays the expected scenes.

Exact scope tiles

Predictive FoV

Fig. 3. Representations of predictive FoV and exact scope.

Like traditional video, VR 360◦ video has similar frame structure and frame size. Based on char-

acteristics of tile prediction, time interval of predictive tiles2 should be scheduled reasonably to avoid

non-real-time transmission or excessive overhead on computing time and energy. Further, time interval

of missing tiles should be short to reduce the stall time. In this work we set T1 and T2 as the time

intervals of predictive tiles and missing tiles, respectively. All tiles in each interval time include three

parts, i.e., the predictive tiles within T1, denoted as Z0, the missing tiles within T2, denoted as Z1, and
the subsequent missing tiles within T1 −
Without being content speciﬁc, quality level of each tile strictly relates to the set of encoding rates. We

T2, denoted as Z2. Note the transmission order: Z0, Z1, and Z2.

denote the encoding rates of predictive tile and missing tile as ηp, and ηm, respectively, which belong

to encoding rate set

=

R1,
{

R

· · ·

, Rd,

, RD

. For public VR theater, VR sickness due to stalling is
}

· · ·

unacceptable. Thus, there is an upper bound of tolerable stall time Ty. In addition, assuming user fairness,

we make the following assumptions.

Assumption 1:

1) The encoding rates of predictive tiles and missing tiles for every user are the same;

2Note that the time interval of predictive tiles is also the corresponding playback time.

2) The numbers of predictively transmitted tiles of each frame are the same for each user, denoted as

9

N k

p = Np,

k

∀

∈ K

each user, denoted by N k

m = Nm,

k

∀

.

∈ K

; thus the expected numbers of missing tiles of each frame are also the same for

C. Problem Formulation

In this paper, we maximize the average QoE of VR 360◦ video transmission in massive MIMO systems

by joint consideration among Np, Nm, ηp, and ηm.

Denote functions χ(Np, Z0), χ(Nm, Z1), and χ(Nm, Z2) as the transmission latencies of transmitting

Z0, Z1, and Z2, respectively, where the size of Z0, Z1, and Z2 are T1ηp, T2ηm, and (T1 −
respectively. To avoid VR sickness caused by stall,

T2)ηm,

χ(Nm, Z1)

Ty.

≤

(1)

In addition, during the current playback time T1, the transmission of last Z2 will occupy the current

transmission time for current Z0. For clarity, we illustrate the scheme in Fig. 4. The ﬁrst Z2 and the

Fig. 4. Stable transmission scheme for Z0, Z1, and Z2.

second Z0 should be delivered within T1, to maintain transmission model stability. Under the identical

prediction model and smooth short interval T1, the number of missing tiles between two adjacent time

intervals are approximately the same. For this reason, we can reasonably assume that Z0 and Z2 in the

same interval time should be delivered within T1. In other words, we require

χ(Np, Z0) + χ(Nm, Z2)

T1.

≤

(2)

The prediction error is relatively small based on the existing prediction model. Hence, the number of

missing tiles is smaller than the number of tiles hit by prediction. Based on the visual perception and

joint consideration between χ(Np, Z0) and χ(Nm, Z1), we set

ηm

ηp.

≤

10

(3)

The QoE in [26] is formulated by the weighted average of video quality minus the weighted spatial

video quality. Generally, the distortion of each tile depends on the encoding rate while the spatial video

quality can be determined by Nm

(ηp

·

−

ηm). As the number of hit tiles is greater than that of missing

tiles, the encoding rate of predictive tiles is the quality of major tiles, which is near the average video

quality. Thus, the average mean squared error and the spatial quality variance can be controlled by ηp and

Nm

(ηp

·

−

ηm) jointly through weight adjustment. A QoE score is intuitively formulated as the encoding

rate of predictive tiles subtracting the perceptual difference, a penalty factor. Based on Assumption 1, we

can assess QoE in a video frame within T1. Hence, the optimization objective is formulated as

(P0) max
ηp,ηm

s.t.

K

αkηp

1
K

Xk=1
(1), (2), (3)

βkNm

(ηp

·

−

ηm)

−

ηm, ηp

R1,

∈ {

, Rd,

, RD

}

· · ·

· · ·

(4)

where for user k, we assign weights αk and βk for the encoding rate of predictive tiles and the encoding

rate difference (ηp

−

ηm), respectively. Particularly, based on human visual system and saliency inﬂuence

in [10], [34], larger saliency degree in VR FoV carries out larger visual impact, especially in the case of

perceptual difference. Thus, αk and βk are positively related to saliency degree, especially for βk.

Problem analysis: In the multi-user massive MIMO systems, variables Np, Nm, and transmission mode

jointly determine χ(Np, Z0), χ(Nm, Z1), and χ(Nm, Z2), which further decide the average QoE score.

The existing basic transmission mode, e.g., uni-stream multicast in [20], which counts indices of tiles

for all active users and transmits each tile by uni-stream multicast, is unable to meet the needs of VR

360◦ video transmission. Thus, optimizing the transmission mode for VR 360◦ video in massive MIMO

systems is necessary. Normally, optimized transmission mode in massive MIMO systems is related to

the tile grouping method of multiple tiles, which aims to maximize the overall network throughput.

Under a certain transmission mode, integer ηm in constraint (1) is linear with integer Nm, whereas

integers ηp and ηm in constraint (2) are linear with respect to integers Np and Nm. Furthermore, Nm(ηp

−
ηm. Hence, the problem (P0) is a high complexity INLP problem.

ηm) is a product of integers Nm and ηp

−

Solving this INLP problem directly would be impractical for real-time transmission. Hence, we consider

low complexity alternatives by jointly considering transmission mode, variables Np and Nm.

11

To solve problem (P0) efﬁciently and approximately, we ﬁrst derive the achievable spectral efﬁciency

to establish a basic foundation to optimize tile grouping. We then examine the relationship between Np

and Nm, as well as the product Nm(ηp

ηm) to efﬁciently optimize the QoE.

−

III. ACHIEVABLE SPECTRAL EFFICIENCIES IN TILE TRANSMISSION

In this section, we analyze the SE of VR video by the major linear MRT and ZF precoding in massive

MIMO systems. In massive MIMO systems, the tile transmission is either unicast or multicast, and the

transmitted data are either uni-stream or multi-stream. We focus on the multi-stream multicast in the VR

video transmission process. We index the multiple groups formed by all transmitted tiles of each frame

by the index set

=

1,
{

G

· · ·

, g,

, and the multiple streams in each group queue for transmission.
, G
}

· · ·

We indicate the indices of users requesting tile in group g by a signal matrix Jg with F rows and B
columns, where the (f, b)-th entry Jg(f, b) represents the index of the b-th user that requests the f -th tile
, F , to represent the set of users in the f -th row of Jg.
stream in group g. We further use גg,f , f = 1,

· · ·

A. Channel Estimation

We deﬁne a pilot matrix Φg = √σg

, φg,f ,
, composed by σg mutually orthogonal
σg-length pilot sequences, where φg,f is a pilot sequence for each user in גg,f . The received uplink signal
at the BS is

, φg,F

φg,1,

· · ·

· · ·

(cid:3)

(cid:2)

Yg = HgΦg + Ng

(5)

where matrix Hg is formed by entries Hg(f, b). Each entry Hg(f, b) represents the channel response of
user Jg(f, b), and Ng

σg is the normalized additive noise matrix with entries Ng(t, s) ∼

(0, 1).

CN

×

CN

∈

Thus, we have

F

B

Yg =

σgquHg(i, b)φT

g,i + Ng

p
where qu is the normalized uplink power. We can obtain the received sequence from Yg via

i=1
X

Xb=1

yg,f = Ygφ∗g,f =

B

Xb=1

p

σgquHg(f, b) + ng,f

where ng,f

∼ CN

(0, IN ) is normalized additive noise vector corresponding to the users in גg,f . According

to the MMSE estimation proposed in [37], BS can estimate the channel response Hg(f, b) as follows

˜Hg(f, b) =

1 +

√σgquΨg(f, b)

B

B
t=1 σgquΨg(f, t)  

t=1
X

P

σgquΨg(f, b)Hg(f, t) + ng,f

p

(8)

!

(6)

(7)

where Ψg(f, b) is the large-scale fading coefﬁcient of Jg(f, b), and ˜Hg(f, b)
Ug(f, b) = σgqu(Ψg(f,b))2
1+
for גg,f , to be

t=1 σgquΨg(f,t)
B
t=1 √σgquHg(f, b) and we have

P

B

. Due to the linear combination, we estimate hg,f , the channel response

12

(0, Ug(f, b)IN ) with

∼ CN

P
˜hg,f =

1 +
P

B
t=1 σgquΨg(f, t)

B

B
t=1 σgquΨg(f, t)  

where ˜hg,f

∼ CN

P
(0, µg,f IN ) with µg,f =

(
P
1+

σgquΨg(f, b)Hg(f, t) + ng,f

p

t=1
X
t=1 σgquΨg(f,b))2
t=1 σgquΨg(f,t)

B

B

. Thus, we have

P

˜Hg(f, b) =

√σgquΨg(f, b)
B
t=1 σgquΨg(f, t)

˜hg,f .

!

(9)

(10)

Note that unicast has the same derivation, and the difference is that

P

B
t=1 σgquΨg(f, t) in (8)-(10) is

equal to σgquΨg(f, b).

P

B. Achievable Spectral Efﬁciency in Downlink Transmission

The received sequence of users in group g is

rg = HH

g Bgsg + Ng

(11)

where sg = [sg,1,

, sg,f ,

· · ·

· · ·

, sg,F ]H represents the transmitted sequence of data symbols and Bg =

, bg,F ] is the precoding matrix of group g in the system. Hence, the received signal of user

[bg,1,
· · ·
Jg(f, b) is

rg(f, b) = Hg(f, b)HBgsg + Ng(f, b).

1) MRT Precoding: The precoding vector for the tile to גg,f is

bMRT

g,f =

qd
g,f
N µg,f

s

˜hg,f

(12)

(13)

where qd

g,f is the downlink power of the precoding vector for גg,f . The received signal of user Jg(f, b)

is

rMRT
g

(f, b) = Hg(f, b)HbMRT

g,f sg,f +

Hg(f, b)HbMRT

g,i sg,i + Ng(f, b).

(14)

F

Hence, the signal-to-interference-plus-noise-ratio (SINR) of user Jg(f, b) is

=f
Xi=1,i

ΩMRT
g

(f, b) =

E

Hg(f, b)H bMRT
g,f

2

1

−

E

(cid:12)
(cid:12)
(cid:12)

n

n
Hg(f, b)HbMRT
g,f

(cid:12)
(cid:12)
(cid:12)

2

+

F
i=1

E

o(cid:12)
(cid:12)
(cid:12)

P

Hg(i, b)H bMRT
g,i

o(cid:12)
(cid:12)
(cid:12)
(cid:26)(cid:12)
(cid:12)
(cid:12)

(15)

.

2

(cid:27)

(cid:12)
(cid:12)
(cid:12)

6
Based on the derivation in [33], ΩMRT

g

(f, b) is

ΩMRT
g

(f, b) =

N qd
g,f Ug(f, b)
1 + Ψg(f, b)P

where P is the total normalized downlink power. And the corresponding SE is

ΓMRT
g

(f, b) = (1

σg
T

−

)log2(1 + ΩMRT

g

(f, b)).

2) ZF Precoding: The precoding vector for tile gf is

bZF

g,f =

(N

q

−

σg)qd

g,f µg,f ˜Hg

˜HH
g

˜Hg

1

−

eg,f

(cid:16)

(cid:17)

where eg,f is the f -th column of a identity matrix Iσg . The received signal is

rZF
g =

F

i=1
X

sg,iHH

g bZF

g,i + Ng.

13

(16)

(17)

(18)

(19)

˜Hg and a diagonal

−

g −
, √σgquΨg(F,B)

w=1 σgquΨg(F,w)

B

P

F

rZF
g =

sg,i

i=1
X

(cid:16)

By replacing HH

g with Z ˜HH

ˆHH

g , where ˆHg and Z are the estimation error Hg

matrix

√σgquΨg(1,1)
i=1 σgquΨg(1,i) ,

B

P

h

· · ·

based on (10), respectively, rZF
g

i

turns to be

Z ˜HH

g bZF

g,i −

ˆHH

g bZF
g,i

+ Ng.

(cid:17)

(20)

In (20), matrix ˆHg is formed by entries ˆHg(f, b), where entry ˆHg(f, b) is the estimation error of channel
response for Jg(f, b). ˜HH
σg)qd

g,f µg,f eg,i according to (18); thus, we have

g,i is equal to

g bZF

(N

rZF
g (f, b) =

q

(N

−

−

q
g,f µg,f σgquΨg(f, b)

σg)qd
B
t=1 σgquΨg(f, t)

sg,f

−

F

i=1
X

ˆHg(f, b)H bZF

g,isg,i + Ng(f, b).

(21)

Based on the derivation in [33], the SINR of user JZF

P

g (f, b) is

ΩZF

g (f, b) =

And the corresponding SE is

(N

σg) qd
−
1 + P (Ψg(f, b)

g,f Ug(f, b)

.

Ug(f, b))

−

ΓZF

g (f, b) = (1

σg
T

−

)log2(1 + ΩZF

g (f, b)).

(22)

(23)

Note that uni-stream transmission has the same derivation, and the difference is that Bg and sg in (11)

are a single vector and a one-dimensional data symbol, respectively.

C. Max-Min Fairness

In a multi-stream group, the common performance metric is MMF, where we want to maximize the

14

minimal SINR among the streams. For MRT, the target is maxqd
AMRT
g

g,f , where
(f, b) = (N Ug(f, b))/(1 + Ψg(f, b)P ), is the (f, b)-th entry of a power coefﬁcient matrix Ag. For

minAMRT

g,f

g

g

(f,b) AMRT

(f, b)qd

the user set גg,f , we extract the minimal value in the set
the minimal power coefﬁcient aMRT

AMRT
(f, 1),
g
g,f = P
g,f , yielding the solution qd
aMRT
g,f
Ug(f, b))P ], and we also extract their
g,f Ug(f, b)/ [1 + (Ψg(f, b)

, AMRT
g
F
t=1

. Likewise, the power

(f, b), AMRT

· · ·
/

(f, B)

coefﬁcient AZF

g (f, b) is (N

σg) qd

1
aMRT
g,t

P

as

(cid:8)

(cid:9)

g

minimal value as the minimal power coefﬁcient aZF

−

−
g,f , yielding the solution qd

g,f = P
aZF
g,f

/

F
t=1

1
aZF
g,t

.

Hence, the SINRs of each stream in group g by either MRT precoding or ZF precoding are the

P

same, which are denoted as ΩMRT

g,ǫ = log2(1 + P/

F
t=1

1
aMRT
g,t

) and ΩZF

g,ǫ = log2(1 + P/

F
t=1

1
aZF
g,t

),

respectively. The achievable SEs of each stream in group g are also the same, which are denoted as

P

P

ΓMRT

g,ǫ = (1

−

σg/T )ΩMRT

g,ǫ and ΓZF

g,ǫ = (1

σg/T )ΩZF

g,ǫ, respectively. Note that the rule for predictive groups

−

is also applicable to missing groups, and we denote the missing group set as

= [1,

, j,

· · ·

· · ·

J

, J].

IV. MULTI-STREAM GROUPING BASED ON VIEWPORT

In this section, we try to search the optimal multi-stream grouping in VR video massive MIMO

systems, the SE of which is derived in Section III. According to the equations (17) and (23), we have

that decreasing the group number G and the length of pilot sequence σg is the key to maximize the

systems throughput. We analyze both the characteristics and constraints of multi-streaming group, and

proposed a multi-stream grouping method based on multiple viewports. Note that the predictive tiles can

be obtained; thus we ﬁrstly analyze the predictive tiles.

A. Multi-Stream Group Based on Viewport Tiles

According to the assumption that the number of predictive tiles among users is the same, multiple

users may have the same viewport in HMDs simultaneously. Note that the number of different viewports

among users relates to the difference of users’ favors. We treat these users, who have the same viewport in

HMDs, as one entity. The number of entities is equal to the number of different viewports. To make clear

the relationship between users and tiles for taking advantage of multicast, we classify the all transmitted

tiles of K users into L viewports, and index the viewport set as

=

1,

{

L

· · ·

, l,

· · ·

, L

}

3. Each viewport

has its corresponding viewport tiles and viewport users.

3Turning users into viewport set, we can ignore the speciﬁc unicast and multicast.

15

In a multi-stream group g, we use pg(l, f ) as an indicator of whether the users of viewport l retrieve

the f -th tile stream. Those users with viewpoint l that can retrieve tile f in group g are associated with

indicator pg(l, f )=1; otherwise, pg(l, f )= 0. The users of one viewport can only reliably receive no more

than one tile simultaneously; thus, we have

pg(l, f1) + pg(l, f2)

0

≤

1,

≤

= f2.

f1 6

(24)

Note that there is no restriction among the tiles in one group according to equation (24). Selecting two

tiles belonging to viewport l as two streams into group g, those users with viewport l can only receive

one of two tiles once and retrieve the other in a new group. It causes an increase in the number of

transmitted groups, which leads to the performance degradation. To solve it, each tile stream in a group

belongs to a distinct viewport. To search the optimal grouping method, we extend the conception of (24).

A tile f in group g that belongs to a viewport l is associated with indicator dg(l, f ) = 1; otherwise,

dg(l, f ) = 0. Thus we can write

dg(l, f1) + dg(l, f2)

0

≤

1,

≤

= f2.

f1 6

(25)

Note that constraint (24) is a basic condition for stable transmission and constraint (25) is a necessary

condition for the optimal grouping. Further, selecting more viewports into a group, which slightly increases

the length of pilot sequence, can reduce the group number G. Empirically, the inﬂuence from the increased

length of pilot sequence is relatively smaller than that from the reduced group number4. Also, reducing

the length of pilot sequence under the minimum group number is necessary.

For a certain tile f , it belongs to one viewport or multiple viewports. To distinguish the two tile

types, we deﬁne the former as isolated tile (IT), and the latter as coexisting tile (CT). To clarify the

relationship between tile and viewport, we analyse a simple viewport set

only belonging to l1 and l2 as ξ(l1, l2), the CTs of l3 as ξ(

removing l2 from (

l3) as ξ(

l3 −

l2), respectively. And they follow

P

=

l1, l2, l3}
l3), the ITs of l3 as ξ(l3), and the CTs

. Denote the CTs

L

{

P

P

ξ(l1, l2, l3)

ξ

⊆

l3

ξ(l1, l3)

ξ(l2, l3)

ξ

ξ

⊆

⊆

(cid:16)X
l3 −
l3 −

(cid:17)
l2

(cid:17)

.

l1

(cid:17)

(cid:16)X

(cid:16)X






(26)

l2) as Π(l1, l2),

l3 −

(l3), and

A

Further, we denote the number of CTs ξ(l1, l2), ITs ξ(l3), and CTs ξ(

4The worst case is basic grouping method which has the maximum group number and the minimum length of pilot sequence.

P

Π(

l3 −

P

l2), respectively. Then, we have

Π(l1, l3) + Π(l2, l3) + Π(l1, l2, l3) = Np

(l3)

Π

−

− A

l3 −

l1 −

l2

.

(cid:17)

(cid:16)X

16

(27)

Based on the distribution of viewport tiles in the HMD scene, we deﬁne the viewport that has no IT as

coexisting viewport (CV) and that has at least one IT as isolated viewport (IV).

Fig. 5. An example of viewports relation in multi-stream groups.

For clarity, we utilize an example illustrated in Fig. 5 to elaborate the relation of multiple viewports.

Each rectangular viewport has 4 tiles in the length and 3 tiles in the width, and we denote its formate

as 4

×

3. We also draw the relationship among viewports in the tile region and illustrate the relationship

of equations (25) and (26) by the graph. After selecting tile ξ(l1) into multi-stream group g, tile ξ(l1, l2)

is unable to join in group g. Further, selecting tile ξ(l1) and tile ξ(

l2) into multi-stream group g,

l3 −

each tile of viewport l2 is unable to join in group g. Normally, CVs always connect with other viewports

P

and are unable to be selected alone, and IVs are the opposite. Note that the goal is to select all viewport

tiles into minimal groups under constraint (25). Hence, the focus of tile selection mainly locates on the

combination between CVs.

After selecting a viewport tile into a group, the rest viewport tiles form a new graph. And the new

selection in another group is processed based on the new graph. The process continues until there is no

tile left.

B. Optimal Multi-Stream Grouping Based on Rectangular Viewport

In order to facilitate the following description, we make two deﬁnitions as follows:

Deﬁnition 1: Combing multiple tiles to form a multi-stream group is deﬁned as combination, and the

operation symbol is deﬁned as

.

S

17

Deﬁnition 2: The group containing all viewports is a complete group, denoted as Υ.

The optimal result in each selection process is picking out all viewports in the graph and form a

complete group. When selecting a viewport tile into a group, whether the other viewports satisfy constraint

(25) is unknown. Moreover, the combination basis for every viewport is unknown, and there is no

algorithm to guarantee a complete group in each selection process. To analytically search the optimal

complete groups, we ﬁrstly propose the following proposition:

Proposition 1: Under constraint (25), combination of rectangular viewports with identical shape h

v

×

has the minimal complete group number Gre = h

·

v, and the combination of tile ζ(x, y) satisﬁes

V −y

H−x

⌊

v ⌋

⌊

h ⌋

[j=
−⌊
and V = max

where H = max

x
{
Proof: See Appendix A.

}

[i=
−⌊

x

h ⌋

y

v ⌋
y
{

.

}

ζ(x + i

·

h, y + j

·

def
= Υ

v)

(28)

Remark 1: Proposition 1 ﬁrstly reveals the combination relation among all rectangular viewports in

the combination problem. Secondly, Proposition 1 represents that rectangular viewports with identical

shapes have the minimal complete group number. Applying the maximum served users in each group

and non-repeated tile stream in all groups is able to make the most of multi-stream ability and minimize

the length of pilot sequences in massive MIMO systems. It greatly improves the throughput and reduces

delay in VR 360◦ video transmission. Thirdly, Gre = h

v well reﬂects the relation between transmitted

·

group size and viewport format size.

C. MLMSG on Non-Rectangular Viewport

In the proposed transmission model, the transmitted viewport contains not only the predictive FoV tiles,

but also other tiles in the exact scope. Thus, sometimes the shape of transmitted viewport to each user is

non-rectangular. Note that the non-rectangular viewports have no minimum complete group number under

constraint (25), even though the shape of each viewport is identical. Based on the Proposition 1, we can

try to structure a rectangular tile entity, i.e., decomposing the non-rectangular viewport l into rectangular

tile lattice λl and the other rest tiles δl

5. Then,

= Np. Note that the larger lattice can achieve

|
smaller total length of pilot sequences for likely increasing the ratio of CTs to all tiles. Thus, the shape

|

λl
|

+

δl
|

of each rectangular tile lattice is the largest shape within all non-rectangular viewports. For rectangular

tile lattice λl, Section IV-B gives the optimal multi-stream grouping. By iterative decomposition, we can

5Compared with λl, δl is relative small and the combination of δl is only subject to the basic constraint (24).

decompose the rest tiles δl into multiple types of rectangular tile lattices according to the shape of every

δl. To meet the tile combination requirement, the quantity of each type of rectangular tile lattices for

each viewport is the same. For clarity, we describe the process with an illustration given in Fig. 6.

18

(a) Decomposition of non-rectangular viewport l1

(b) Decomposition of non-rectangular viewport l2

Fig. 6. Decomposition of non-rectangular viewports accordingly to their shapes.

In Fig. 6, the tiles in the red dashed line boxes are tile lattices. The ﬁrst largest tile lattice is the

central 4

×

3 tile entity. Then, in their rest tiles, there is a lattice including two tiles with identical shapes.

Last, the rest one-tile entity forms an one-tile lattice. Hence, we can decompose both non-rectangular

viewports l1 and l2 into one central 4

3 rectangular tile lattice, one 2

1 rectangular tile lattice, and

×

×

two 1

×

1 rectangular tile lattices, respectively.

Note that the combination in each tile lattice set is independent and the equation (28) is still applicable

for each type of tile lattice set. Hence, the total group number Gre is equal to Np

6 , and the stream

number in each group is determined. The complexity of the combination of the non-rectangular viewports

is linear with Np, namely,

O

the complexity is

(Nm).

O

(Np). Note that the MLMSG is also suitable for missing viewport tiles, and

V. AVERAGE QOE MAXIMIZATION

The traditional retrieving method only fetches and buffers the predictive FoV tiles, which ignores the

missing tiles. The missing tiles do appear in the practical scenario, which causes QoE degradation and

even unacceptable VR sickness. In this section, we jointly consider the predictive transmission and the

supplementary transmission for missing tiles, and explore the effect of Np on the average maximum QoE.

Without fully accurate prediction, prediction error occurs and is closely related to exceptional motion

[7], which is caused by the multi-stimuli in HMDs. Researchers in [24] leverage realism loss and

6When the N k

to max{N k

p }.

p is different for different users, the decomposition method is still applicable, and the group number Gre is equal

reconstruction loss to predict the intensity of exception motion of fragment frames, which can provide

experimental evidence on the exact scope. Hence, the size of exact scope tiles is a function of the stimuli,

which can be obtained based on the previous prediction model. Generally, we assume that the request

probability of each tile in the exact scope is equal. Thus, the expected number of missing tiles Nm is

19

Nm =

M

(cid:24)

Np

S

·

−
S

(cid:25)

where M and S are the tiles number of FoV format and exact scope format, respectively.

According to the expression of achievable SE and multi-stream grouping,

G = Np




J = Nm.

(29)

(30)

Hence, Np is also an optimization variable that determines G and J. Thus, we reformulate problem (P0)
into problem (P1)



(P1)

max
ηp,ηm,Np

1
K

K

Xk=1

αkηp

−

βkNm(ηp

ηm)

−

s.t.

(3), (4), (29), (30)

T2)ηm
(T1 −
vj

T1

≤

T1ηp
vg

+

J

j=1
X

T2ηm

vj ≤

Ty

G

g=1
X
J

j=1
X

(31)

(32)

where vg and vj are the transmission rates of predictive group g and missing group j, respectively. Note

that vg = W

·

Γg,ǫ is achieved in the predictive transmission but vj is unavailable without knowning

speciﬁc tile and user.

To solve the unknown vj and meet the tolerant latency constraint, vj is suggested to be a valid value,

which is little bit smaller than the actual value. For simplicity, the missing groups reuse the deﬁnition

of predictive groups, i.e., Jj, Jj(f, b), גj,f , Ψj(f, b), Uj(f, b), and Aj(f, b) have similar meanings to
Jg, Jg(f, b), גg,f , Ψg(f, b), Ug(f, b), and Ag(f, b), respectively. The differences are that group indices

g turn to be j for missing group j.

In terms of transmission rate in j-th missing group by MRT precoding, the SINR of each stream is

20

(33)

(cid:21)

the same and we formulate it as

ΩMRT

j,ǫ =

F
i=1

P

P

1

minb∈גj,i (AMRT

j

(i,b))

F
i=1

P

=

=

P

1

minb∈גj,i (cid:20)

(1+PB

t=1

F
i=1 maxb
∈

גj,i

(1+

P

(cid:20)

P

j (i,b)P ) (cid:21)

j (i,b))2
j (i,t))(1+Ψ

N σj qu (Ψ
σj qu Ψ
N P
t=1 σjquΨj(i,t))(1+Ψj(i,b)P )

B

σjqu(Ψj(i,b))2

where

1+Ψj(i,b)P
σgqu(Ψj(i,b))2 decreases monotonously as Ψj(i, b) increases. In the worst case, the minimal large-

scale fading coefﬁcient in each stream is the same as the minimal one of the total users. Hence,

ΩMRT

j,ǫ ≥

N P

F
i=1 1 +

·

σjquΨ2
min
1+ΨminP
B
t=1 σjquΨj(i, t)

= N P

σj quΨ2
min
1+ΨminP
σj + σjquΨall

·

= N P

quΨ2
min
1+ΨminP
1 + quΨall

·

(34)

where Ψall =

F
i=1

P

cients. Denote the right term in (34) as ΩMRT
P

P

j,min, j

P

B
t=1 Ψj(i, t), and Ψmin is the minimal value of the user large-scale fading coefﬁ-
, which has no association with the length of pilot

∈ J

sequence and group tile index.

Likewise, we formulate the SINR of j-th group by ZF precoding as

P

1

minb∈גj,i (AZF

j (i,b))

ΩZF

j,ǫ =

F
i=1

P

=

=

P

1

F
i=1

P

minb∈גj,i (cid:20)

F
i=1 maxb
∈

גj,i

P

(N −σj )·U
j (i,b)−U

j (i,b)
j (i,b))P (cid:21)

1+(Ψ
P
1+(Ψj(i,b)
Uj (i,b))P
−
Uj(i,b)
σj )
(N
·

−

h

(35)

i

where 1+Ψj(i,b)P
Uj(i,b)

decreases monotonously as Ψj(i, b) increases. The worst case is that the minimal

large-scale fading coefﬁcient in each stream is Ψmin. Similarly,

ΩZF

j,ǫ ≥

minP
(N
1 + quΨall + (1 + quΨall) ΨminP

σj) quΨ2

−

σjquΨ2

minP

−

(36)

where the right term is denoted as ΩZF

j,min. The approximate errors in MRT precoding and ZF precoding

are extremely small, which are revealed in Section VI.

We denote the minimum SEs of group j in MRT precoding and ZF precoding by ΓMRT

j,min = (1

1 + ΩMRT
j,min

σj/T )log2
−
is unknown. In the worst case, the tile lattices in the multi-stream grouping are all 1

σj/T )log2

j,min = (1

, respectively. Further, σj,

j,min

(cid:17)

(cid:17)

(cid:16)

and ΓZF

1 + ΩZF

j

(cid:16)

∈ J
1 tile lattices;
j,min. Hence, the results vj of problem (P1) in MRT precoding
ΓZF
j,min, respectively. Note that the

j,min and vZF
ΓMRT

j = W

= W

×

∀

·

·

j,min and ΓZF
thus σj is equal to L in ΓMRT
and ZF precoding approximate to vMRT

j

approximation is also able to be applied to predictive tile groups.

By analysing, ηp and ηm in constraints (31) have linear relationship and are also linear with Np, and

−
,

21

ηm in (32) is linear with Nm, whereas the product of Nm and (ηp

ηm) makes the optimization objective

−

nonlinear. To make it linear, the general method is to set Nm or (ηp

ηm) as a constant. Np, the set of

−

which is

M,
{

· · ·

, S

}

, decides Nm, the cardinality of which is much smaller than that of (ηp

ηm). Thus,

−

we set Np as a constant from M to S, and respectively denote ηp(Np) and ηm(Np) as the encoding rates.

The ﬁnal QoE score of the optimization objective is the maximal value among the calculated results.

Note that the two discrete variables ηp and ηm make each calculation non-convex. Based on the general

linear programming method, we relax discrete variables into continuous variables and recover them from
[R1, RD], and problem (P1)

the optimization solution. Hence, with ﬁxed Np, we relax ηp(Np), ηm(Np)
in the calculation turns to be an ILP problem (P2):

∈

(P2)

max
ηp(Np),ηm(Np)

1
K

K

Xk=1

αkηp(Np)

−

βkNm [ηp(Np)

ηm(Np)]

−

s.t.

(3), (29), (30), (31), (32)

ηp(Np), ηm(Np)

[R1,

∈

· · ·

, Rd,

· · ·

, RD]

(37)

which can be efﬁciently solved through the convex optimization toolbox [38]. In the ﬁxed Np calculation,

we obtain the optimization solutions ηp(Np, 1) and ηm(Np, 1), which locate in intervals

R1

dNp

, R1

dNp +1

and

R2

dNp

, R2

dNp +1

i
, respectively. According to the two-dimensional linear programming, the closest

h

h

i

two-dimensional integer point is only relevant to ηp(Np, 1), which is illustrated in Fig. 7 for clarity.
Thus, the two variables recovery starts from variable ηp(Np, 1), which is either R1

or R1

dNp

dNp +1. For

Recovery line

Fig. 7. The recovery policy of two-dimensional integer point.

and R1

ﬁxed R1

dNp
them by R3

dNp +1, we respectively obtain the optimal encoding rates of missing tiles and indicate
dNp +1) to indicate their
) and
QoE scores, respectively. Hence, we easily obtain the recovery policy and QoE score in the ﬁxed Np

dNp +1, and we use

dNp +1, R4

(Np, R1

(Np, R1

and R4

, R3

dNp

dNp

dNp

Q

Q

calculation as follows

Np = max

Q

n

Therefore, the optimal QoE is

(Np, R1

dNp

Q

, R3

dNp

),

(Np, R1

dNp +1, R4

dNp +1)

Q

o

22

.

(38)

Therefore, we accordingly obtain the optimal Np, ηp, and ηm. In addition, the linear programming makes

op = max

Q

S,

{Q

,

M

Q

.
}

· · ·

(39)

the complexity as (S

M )

O

−

(K), which is a low value.

VI. SIMULATION RESULTS

In the section, we run simulation in Matlab to verify the performance of MLMSG and the joint

consideration between predictive tiles and missing tiles in QoE driven VR 360◦ video massive MIMO

transmission.

A. Simulation Setup

We consider VR transmission in a single cell where the radii r1 and r2 are 45 meters and 40 meters,

respectively. The number of users K and antennas N are 100 and 128, respectively. We model the large-

scale fading coefﬁcient for user k as ψk = c/τ κ

κ = 3.76 is the pass-loss exponent, and c = 10−

k , where τk is the distance between user k and the BS,
3.5 is a constant [33]. We set the transmission bandwidth

W as 100 MHz at a carrier frequency of 2 GHz. The coherence bandwidth and coherence time are

200 kHz and 1 ms, respectively, which contribute to the coherence interval of 200 symbols. We set the

noise power spectral density, HMD power Pu, and total downlink power Pd as σ2 =

174 dBm/Hz,

−

0.1 Watts, and 10 Watts, respectively. Thus, the normalized uplink power and total downlink power are

qu = Pu/(W

·

σ2) and P = Pd/(W

σ2), respectively.

·

Given that the prediction accuracy decreases sharply as the interval time T1 increases, T1 is usually

set at 200 ms for high prediction accuracy [35], [39]. Further, we consider a moderate T2 to balance

transmission time with computing time and rendering time. Thus, we set the time interval of the predictive

tiles and the missing tiles to T1 = 200 ms and T2 = 90 ms, respectively. The authors [2] recommend the

tolerant latency of VR sickness to be Ty = 10 ms. In the simulation, the equirectangular format of VR

360◦ video by tilling projection is 12

12, and FoV format is 5

×

×

4. The prediction accuracy is about

90% for T1 = 200 ms [35], and the exact scope is a litter larger than the FoV. Thus, we consider three

reasonable exact scope formats: 6

4, 5

5, and 6

5. Further, we deﬁne the interval of encoding rate of

×
each tile as 105 bps. As for the weights of the major tiles quality and the perceptual difference, we adopt

×

×

the concept in [26] and consider a moderate variation. Thus, set αk = [1.9, 2.1], βk = [ ¯β
where ¯β =

. For clarity, we summarize our simulation parameters in Table I.
, 1
}

0.1, 0.2,
{

· · ·

23

0.02, ¯β +0.02],

−

TABLE I
SIMULATION PARAMETERS

Parameter Value

Parameter

N
T
T2
αk
r1
σ2
κ
Pu
W
FoV format

128
200
90 ms

[1.9,2.1]
40
-174 dBm/Hz
3.76

0.1 W
100 MHz

5

4

×

K
T1
Ty
¯β
r2
c
τk
Pd
Equirectangular format
Encoding rate interval

, 1
}

Value

100
200 ms
10 ms

· · ·

3.5

0.1,
{
45
10−
[r1, r2]
10 W

12
12
×
105 bps

B. Performance Evaluations and Comparisons

In this subsection, we show the performance of the proposed MLMSG and adjustment of value Np

in QoE driven VR 360◦ video massive MIMO transmission. To the best of our knowledge, there has

been no previous work proposing a complete system for VR 360◦ video massive MIMO transmission.

The basic grouping (BG) mode derived from uni-stream multicast in [20], is to count the indices of all

users’ tiles and transmitting each tile by uni-stream multicast. And the previous works on VR 360◦ video

transmission ﬁx value Np as the FoV size M . Hence, we evaluate and compare the proposed methods

in two parts: MLMSG and BG, with variable Np (VN) and ﬁxed Np = M (FN), respectively.

To evaluate the approximate processing of vj described in Section V, we illustrate the actual value and

approximate value versus Nm in Fig. 8. We select the exact scope format to be 6

5; thus the expected

×

number of missing tile groups J = Nm can change from 1 to 7. In Fig. 8(a), the approximate SINR is

extremely close to the actual SINR, and the approximate error is about 0.2%. The approximate SINR

and actual SINR by ZF precoding are little larger than those by MRT precoding, respectively. In Fig.

8(b), the average actual SE increases with Np. The reason is that some tile lattices contain more CTs

such that the total pilot sequences turn smaller. The approximation error between the worst approximate

SE and the actual SE in missing groups is small and the largest approximation error is 3.5%, which is

feasible for performance guarantee.

To evaluate and compare MLMSG and BG, we leverage the transmission delay caused by transmit-

ting one bit of each tile on unit bandwidth, and denote it as ρ, which is unrelated to the encoding

1.024

1.023

1.022

1.021

1.02

1.019

Actual SINRMRT
Approximate SINRMRT
Actual SINRZF
Approximate SINRZF

1.018

1

2

3

4
Value of N

m

5

6

7

24

1

s
p
u
o
r
g

0.99

i

g
n
s
s
m

i

l
l

a

g
n
o
m
a
E
S
e
g
a
r
e
v
A

0.98

0.97

0.96

0.95

1

Actual SEMRT
Approximate SEMRT
Actual SEZF
Approximate SEZF

2

3

4
Value of N

m

5

6

7

s
p
u
o
r
g
g
n
s
s
m

i

i

l
l

a

g
n
o
m
a
R
N
S
e
g
a
r
e
v
A

I

(a) Average SINR versus Nm

(b) Average SE versus Nm

Fig. 8. The comparison between approximate value and actual value.

rate. By MLMSG method, we obtain the approximate value of vj in advance. But the unknown value
B
t=1 σjquΨj(f, t) and the variable value J make value vj in BG method ﬂuctuates over a wide range,
which makes it hard to estimate the approximate value of vj. Thus, we mainly calculate the value of
P

predictive tiles, ρ =

to the FoV format 5

P
×

G
g=1 1/Γg,ǫ, which well reﬂects the performances of MLMSG and BG. According
4 and three considered exact scope formats, we present the results of ρ with

predictive tile formats of 5

4, 6

4, 5

5, and 6

5 in Table II. For this scenario, MRT and ZF have

×
similar behaviors. The value ρ of MLMSG is much smaller than that of BG in all four tile formats, and

×

×

×

the reduction is about 23 percent. Compared with BG, the difference is that MLMSG makes the most

of the multi-stream ability in MIMO systems and the tile-grouping to reduce group number and length

of pilot sequences. It validates that utilizing the multi-stream ability of massive MIMO systems and the

optimal multi-stream grouping can greatly improve the throughput and reduce delay in VR 360◦ video

transmission.

TABLE II
EXPERIMENTAL RESULTS (ρ)

Transmission mode

MLMSGMRT

BGMRT

MLMSGZF

BGZF

5

4

×

6

4

×

5

5

×

5

6

×

19.7507

23.8946

24.5218

29.6776

26.2308

31.0087

31.7641

37.4574

19.7411

23.8876

24.5080

29.6666

26.1884

30.985

31.7241

37.4193

To analyze the performance of average QoE score, we mainly evaluate and compare the combination

of MLMSG and VN (MLMSG+VN), the combination of MLMSG and FN (MLMSG+FN), and the

combination of BG and FN (BG+FN). Fig. 9 presents the average QoE scores of MLMSG+VN,

 
 
 
 
 
 
 
 
 
 
25

MLMSG+FN, and BG+FN. The horizontal axis is the value of ¯β and the vertical axis is the average QoE
score. We restate that higher saliency of multiple stimuli leads to higher ¯β for user experience. Normally,
the average QoE scores of all three methods descend as ¯β increases. Beneﬁting from the high throughput,

MLMSG can signiﬁcantly improve the QoE score compared with BG. And MLMSG+VN has a better
performance than MLMSG+FN when ¯β turns larger. For VN, BS adjusts the encoding rate of predictive

tiles to reduce the value of penalty factor while the major tiles quality descends. For FN, the penalty

factor increases rapidly without adjustment, which leads to the rapid descent of the ﬁnal QoE score.

When the exact scope turns larger, the QoE scores of three algorithms turn smaller for more transmitted

tiles and lower encoding rate. Further, the results shows that the difference between MLMSG+VN and

MLMSG+FN in Fig. 9(a) and Fig. 9(b) is detectable, though difference between 24 and 25 is little small.
It demonstrates that width and height have a little inﬂuence on QoE performance. Also, the value of ¯β,

which distinguishes MLMSG+VN and MLMSG+FN, turns smaller for the larger exact scope format.
5 and moderate ¯β, which are closer to the real multi-stimuli VR

For the exact scope with format 6

×

video, the average QoE score of MLMSG+VN maintains an acceptable level but that of MLMSG+FN
decreases sharply as ¯β increases. It validates that VN aimed at real supplementary transmission of missing

tiles can improve and guarantee the QoE score.

100

90

80

70

60

50

40

e
r
o
c
s
E
o
Q
e
g
a
r
e
v
A

30

0.1

100

90

80

70

60

50

40

e
r
o
c
s
E
o
Q
e
g
a
r
e
v
A

30

0.1

MLMSGMRT+VN (6 4)
MLMSGMRT+FN (6 4)
BGMRT+FN (6 4)
MLMSGZF+VN (6 4)
MLMSGZF+FN (6 4)
BGZF+FN (6 4)

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

MLMSGMRT+VN (5 5)
MLMSGMRT+FN (5 5)
BGMRT+FN (5 5)
MLMSGZF+VN (5 5)
MLMSGZF+FN (5 5)
BGZF+FN (5 5)

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

100

90

80

70

60

50

40

30

e
r
o
c
s
E
o
Q
e
g
a
r
e
v
A

MLMSGMRT+VN (6 5)
MLMSGMRT+FN (6 5)
BGMRT+FN (6 5)
MLMSGZF+VN (6 5)
MLMSGZF+FN (6 5)
BGZF+FN (6 5)

20

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

(a) Exact scope format 6×4

(b) Exact scope format 5×5

(c) Exact scope format 6×5

Fig. 9. Average QoE score versus value of ¯β for different algorithms in three different exact scope formats.

VII. CONCLUSIONS AND FUTURE WORK

In this paper, we have investigated the problem of maximizing the average QoE in VR 360◦ video

massive MIMO transmission. Based on the investigations of the previous works, we considered a practical

scenario, and proposed a stable transmission scheme according to the supplementary transmission for

missing tiles and unacceptable VR sickness. The integer variables and their relation make the average

QoE objective be formulated as an INLP probelm. Leveraging the derived expression of the achievable

SE of each tile group, we proposed the MLMSG+VN algorithm, and turned the INLP problem into an

 
 
 
 
 
 
26

ILP problem by ﬁxing the quantity of predictive tiles. With variables relaxation and recovery, we ﬁnally

achieve the optimal average QoE. Simulation results suggest that our proposed MLMSG+VN algorithm,

with pretty low complexity, improves and guarantees VR 360◦ video QoE. Further, the large improvement

validates that the massive MIMO systems with the characteristics of the high overall throughput and the

multi-stream ability are very suitable for VR 360◦ video transmission.

In addition, 360◦ VR motion sickness, a sensory mismatch between the vestibular system and the

visual system, is another challenging issue. The desired scene in the FoV and interactive virtual world

should be presented immediately and satisfactorily during user motion, which demands high-rate network

links. Given the low latency and high transmission rate of massive MIMO, adapting our method to head

motion to improve user experience is an important future direction.

APPENDIX A

PROOF OF PROPOSITION 1

To prove Proposition 1, we start with two canonical cases of connection among three h(h = 4)

×
v(v = 3) viewports. One case is the maximum viewport connection (MVC) in the horizontal direction

as illustrated in Fig. 10(a), and another is the MVC in the vertical direction as shown in Fig. 10(b).

(a) Horizontal MVC case

(b) Vertical MVC case

Fig. 10. Two basic cases of three 4 × 3 viewports.

In both cases, viewport l2 is CV while viewports l1 and l3 are IVs. The number of ITs of viewport l3

is

(l3) = h

v

·

−

A

Π(l2, l3)

−

Π(l1, l2, l3)

(40)

where

Then, we have

Π(l2, l3) = h

v

·

− A

(l2)

−

Π(l1, l2)

−

Π(l1, l2, l3).

With the same derivation, we have

Π(l1, l2) =

(l3).

A

Π(l2, l3) =

(l1).

A

27

(41)

(42)

(43)

Hence, there are enough tiles ξ(l3) and ξ(l1) to respectively combine with all CTs ξ(l1, l2) and all

CTs ξ(l2, l3) to form complete groups. In the three-viewport basic cases, we can easily determine the

combination relation to form complete group. Further, the combination of tiles indices is related to the

size of h and v. Analytically, in the three-viewport horizontal MVC case, for an arbitrary tile ζ(x, y), x

∈
h, y), and combination among them can form

, y

, there exists either tile ζ(x + h, y) or tile ζ(x

∈ V

H
a complete group in deﬁnition, namely,

−

ζ(x, y)

∪

ζ(x + h, y)

ζ(x

∪

−

h, y)

def
= Υ.

(44)

When ζ(x + h, y) or ζ(x

−

h, y) in (44) is nonexistent, we can ignore the combination with ζ(x + h, y)

or ζ(x

−

h, y), which has no effect on the combination equation. Likewise, in the three-viewport vertical

MVC case, for an arbitrary tile ζ(x, y), x

, y

∈ H

∈ V

, there exists either tile ζ(x, y +v) or tile ζ(x, y

and

ζ(x, y)

∪

ζ(x, y + v)

ζ(x, y

∪

−

def
= Υ.

v)

v),

−

(45)

The combination of tile indexes in (44) and (45) enables these three-viewport tiles to form complete

groups with number Gre = h

v.

·

When viewport l1 and l3 have a connection with other viewports (there are more than three viewports

in the graph), (42) and (43) respectively expand to

Π(l1, l2) =




Π(l2, l3) =

A

A

(l3) + Π(

(l1) + Π(

X

l3 −
l1 −

l1 −
l2 −

l2)

l3).

(46)

Note that the combination of tile indices among viewports l1, l2, and l3 remains unchanged.



X

We deﬁne the rectangular graph, which has both horizontal MVC and vertical MVC, as full MVC

(FMVC) graph. For clarity, we illustrate a 6

5 FMVC graph with 4

×

×

3 viewport tiles in Fig. 11.

Note that we can divide the FMVC graph into multiple overlapped MVC graphs and vertical MVC

28

Fig. 11. 6 × 5 FMVC graph with 4 × 3 viewport tiles, and also the FMVC graph of the example in Fig. 5.

graphs, and the combination characteristics remain unchanged7. Based on the unchanged characteristics,

the combination approach is suitable for a H(H > h)

V (V > v) FMVC graph. And the combination

×

of indexes of tile ζ(x, y) is

V −y

H−x

⌊

v ⌋

⌊

h ⌋

y

[j=
−⌊

x

[i=
−⌊

ζ(x + i

h, y + j

v).

·

·

(47)

v ⌋
Each combined group is a complete group, and the group number is Gre = h

h ⌋

v.

·

Note that any rectangular viewport graph has its FMVC graph according to the minimal and maximal

coordinates. Hence, we easily can achieve any multi-rectangular-viewport graph through its FMVC graph,

and the approach is only deleting the nonexistent viewport tiles from the FMVC graph. Further, the

combination of indices of tiles remains unchanged, which is the same as (47), and the group number is

also Gre = h

·

v. The only difference is that H = max

x
{

, V = max
}

y
{

. Thus, Proposition 1 is proved.
}

REFERENCES

[1] M. T. Hossan, M. Z. Chowdhury, M. Shahjalal, and Y. M. Jang, “Human bond communication with head-mounted displays:

Scope, challenges, solutions, and applications,” IEEE Commun. Mag., vol. 57, no. 2, pp. 26–32, 2019.

[2] E. Bastug, M. Bennis, M. Medard, and M. Debbah, “Toward interconnected virtual reality: Opportunities, challenges, and

enablers,” IEEE Commun. Mag., vol. 55, no. 6, pp. 110–117, 2017.

[3] Z. Chen, Y. Li, and Y. Zhang, “Recent advances in omnidirectional video coding for virtual reality: Projection and

evaluation,” Signal Processing, vol. 146, pp. 66 – 78, 2018.

7Non-rectangular viewport does not have the characteristics.

29

[4] M. Xu, Y. Song, J. Wang, M. Qiao, L. Huo, and Z. Wang, “Predicting head movement in panoramic video: A deep

reinforcement learning approach,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 41, no. 11, pp. 2693–2708, 2019.

[5] Y. Sun, Z. Chen, M. Tao, and H. Liu, “Communications, caching, and computing for mobile virtual reality: Modeling and

tradeoff,” IEEE Trans. Commun., vol. 67, no. 11, pp. 7573–7586, 2019.

[6] T. Dang and M. Peng, “Joint radio communication, caching, and computing design for mobile virtual reality delivery in

fog radio access networks,” IEEE J. Sel. Areas Commun., vol. 37, no. 7, pp. 1594–1607, 2019.

[7] H. Hu, Z. Xu, X. Zhang, and Z. Guo, “Optimal viewport-adaptive 360-degree video streaming against random head

movement,” in Proc. IEEE Int. Conf. Commun. (ICC), 2019, pp. 1–6.

[8] O. Le Meur, P. Le Callet, D. Barba, and D. Thoreau, “A coherent computational approach to model bottom-up visual

attention,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 28, no. 5, pp. 802–817, 2006.

[9] W. Sun, X. Min, G. Zhai, K. Gu, H. Duan, and S. Ma, “MC360IQA: A multi-channel CNN for blind 360-degree image

quality assessment,” IEEE J. Sel. Topics Signal Process., vol. 14, no. 1, pp. 64–77, 2020.

[10] Y. Zhu, G. Zhai, X. Min, and J. Zhou, “The prediction of saliency map for head and eye movements in 360 degree images,”

IEEE Trans. Multimedia, vol. 22, no. 9, pp. 2331–2344, 2020.

[11] J. Zou, C. Li, C. Liu, Q. Yang, H. Xiong, and E. Steinbach, “Probabilistic tile visibility-based server-side rate adaptation

for adaptive 360-degree video streaming,” IEEE J. Sel. Topics Signal Process., vol. 14, no. 1, pp. 161–176, 2020.

[12] P. Lungaro, R. Sj¨oberg, A. J. F. Valero, A. Mittal, and K. Tollmar, “Gaze-aware streaming solutions for the next generation

of mobile VR experiences,” IEEE Trans. Vis. Comput. Graphics, vol. 24, no. 4, pp. 1535–1544, 2018.

[13] G. J. Sullivan, J. Ohm, W. Han, and T. Wiegand, “Overview of the high efﬁciency video coding (HEVC) standard,” IEEE

Trans. Circuits Syst. Video Technol., vol. 22, no. 12, pp. 1649–1668, 2012.

[14] M. Yu, H. Lakshman, and B. Girod, “A framework to evaluate omnidirectional video coding schemes,” in Proc. IEEE Int.

Symp. Mixed Augmented Reality, 2015, pp. 31–36.

[15] J. Feng, Y. Wu, G. Zhai, N. Liu, and W. Zhang, “An algorithm for transmitting VR video based on adaptive modulation,”

in Proc. IEEE/CIC Int. Conf. Commun. China (ICCC), 2019, pp. 443–448.

[16] Z. Liu, S. Ishihara, Y. Cui, Y. Ji, and Y. Tanaka, “JET: Joint source and channel coding for error resilient virtual reality

video wireless transmission,” Signal Processing, vol. 147, pp. 154 – 162, 2018.

[17] J. Li, R. Feng, Z. Liu, W. Sun, and Q. Li, “Modeling QoE of virtual reality video transmission over wireless networks,”

in Proc. IEEE Global Commun. Conf. (GLOBECOM), 2018, pp. 1–7.

[18] K. Long, C. Ye, Y. Cui, and Z. Liu, “Optimal multi-quality multicast for 360 virtual reality video,” in Proc. IEEE Global

Commun. Conf. (GLOBECOM), 2018, pp. 1–6.

[19] H. Yang, T. L. Marzetta, and A. Ashikhmin, “Multicast performance of large-scale antenna systems,” in Proc. IEEE 14th

Workshop Signal Process. Adv. Wireless Commun. (SPAWC), 2013, pp. 604–608.

[20] C. Guo, Y. Cui, and Z. Liu, “Optimal multicast of tiled 360 VR video,” IEEE Wireless Commun. Letters, vol. 8, no. 1,

pp. 145–148, 2019.

[21] K. Long, Y. Cui, C. Ye, and Z. Liu, “Optimal wireless streaming of multi-quality 360 VR video by exploiting natural,

relative smoothness-enabled and transcoding-enabled multicast opportunities,” IEEE Trans. Multimedia, pp. 1–1, 2020.

[22] L. Zhao, Y. Cui, C. Guo, and Z. Liu, “Optimal streaming of 360 VR videos with perfect, imperfect and unknown fov

viewing probabilities,” in Proc. IEEE Global Commun. Conf. (GLOBECOM), 2020, pp. 1–6.

[23] Z. Fei, F. Wang, J. Wang, and X. Xie, “QoE evaluation methods for 360-degree VR video transmission,” IEEE J. Sel.

Topics Signal Process., vol. 14, no. 1, pp. 78–88, 2020.

30

[24] H. G. Kim, H. Lim, S. Lee, and Y. M. Ro, “VRSA Net: VR Sickness Assessment Considering Exceptional Motion for

360◦ VR Video,” IEEE Trans. Image Process., vol. 28, no. 4, pp. 1646–1660, 2019.

[25] T. Zhao, Q. Liu, and C. W. Chen, “QoE in video transmission: A user experience-driven strategy,” IEEE Commun. Surveys

Tuts., vol. 19, no. 1, pp. 285–302, 2017.

[26] J. Fu, X. Chen, Z. Zhang, S. Wu, and Z. Chen, “360SRL: A sequential reinforcement learning approach for ABr tile-based

360 video streaming,” in Proc. IEEE International Conference on Multimedia and Expo (ICME), 2019, pp. 290–295.
[27] C. Perfecto, M. S. Elbamby, J. D. Ser, and M. Bennis, “Taming the latency in multi-user VR 360◦: A QoE-aware deep

learning-aided multicast framework,” IEEE Trans. Commun., vol. 68, no. 4, pp. 2491–2508, 2020.

[28] T. L. Marzetta, “Noncooperative cellular wireless with unlimited numbers of base station antennas,” IEEE Trans. Wireless

Commun., vol. 9, no. 11, pp. 3590–3600, 2010.

[29] A. Adhikary, J. Nam, J. Ahn, and G. Caire, “Joint spatial division and multiplexing—the large-scale array regime,” IEEE

Trans. Inf. Theory, vol. 59, no. 10, pp. 6441–6463, 2013.

[30] C. Sun, X. Gao, S. Jin, M. Matthaiou, Z. Ding, and C. Xiao, “Beam division multiple access transmission for massive

MIMO communications,” IEEE Trans. Commun., vol. 63, no. 6, pp. 2170–2184, 2015.

[31] L. Sanguinetti, E. Bj¨ornson, and J. Hoydis, “Toward massive MIMO 2.0: Understanding spatial correlation, interference

suppression, and pilot contamination,” IEEE Transactions on Communications, vol. 68, no. 1, pp. 232–257, 2020.

[32] Y. Polyanskiy, H. V. Poor, and S. Verdu, “Channel coding rate in the ﬁnite blocklength regime,” IEEE Trans. Inf. Theory,

vol. 56, no. 5, pp. 2307–2359, 2010.

[33] M. Sadeghi, E. Bj¨ornson, E. G. Larsson, C. Yuen, and T. Marzetta, “Joint unicast and multi-group multicast transmission

in massive MIMO systems,” IEEE Trans. Wireless Commun., vol. 17, no. 10, pp. 6375–6388, 2018.

[34] V. Sitzmann, A. Serrano, A. Pavel, M. Agrawala, D. Gutierrez, B. Masia, and G. Wetzstein, “Saliency in VR: How do

people explore virtual environments?” IEEE Trans.Visu. Comput. Graphics, vol. 24, no. 4, pp. 1633–1642, 2018.

[35] F. Qian, B. Han, Q. Xiao, and V. Gopalakrishnan, “Flare: Practical viewport-adaptive 360-degree video streaming for mobile

devices,” in Proc. ACM Mobicom, ser. MobiCom ’18. New York, NY, USA: Association for Computing Machinery, 2018,

p. 99–114.

[36] Zhou Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, “Image quality assessment: from error visibility to structural

similarity,” IEEE Trans. Image Process., vol. 13, no. 4, pp. 600–612, 2004.

[37] S. M. Kay, Fundamentals of statistical signal processing, ser. Prentice Hall signal processing series. Upper Saddle River,

NJ: Prentice Hall PTR, 1993.

[38] M. Grant and S. Boyd, “CVX: Matlab software for disciplined convex programming, version 2.1,” Mar. 2014.

[39] X. Hou, S. Dey, J. Zhang, and M. Budagavi, “Predictive adaptive streaming to enable mobile 360-degree and VR

experiences,” IEEE Trans. Multimedia, vol. 23, pp. 716–731, 2021.

