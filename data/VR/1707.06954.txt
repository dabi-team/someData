The lives and death-throes of massive stars
Proceedings IAU Symposium No. 329, 2017
J.J. Eldridge, L. Xiao, L.A.S. McClelland
& J.C. Bray, eds.

c(cid:13) 2017 International Astronomical Union
DOI: 00.0000/X000000000000000X

360-degree videos: a new visualization
technique for astrophysical simulations

Christopher M. P. Russell1
1X-ray Astrophysics Laboratory, NASA/Goddard Space Flight Center,
Greenbelt, MD 20771, USA (NASA Postdoctoral Program Fellow, administered by USRA)
email: crussell@udel.edu

Abstract. 360-degree videos are a new type of movie that renders over all 4π steradian. Video
sharing sites such as YouTube now allow this unique content to be shared via virtual reality
(VR) goggles, hand-held smartphones/tablets, and computers. Creating 360◦ videos from astro-
physical simulations is not only a new way to view these simulations as you are immersed in
them, but is also a way to create engaging content for outreach to the public. We present what
we believe is the ﬁrst 360◦ video of an astrophysical simulation: a hydrodynamics calculation
of the central parsec of the Galactic centre. We also describe how to create such movies, and
brieﬂy comment on what new science can be extracted from astrophysical simulations using
360◦ videos.

Keywords. hydrodynamics, Galaxy: centre

1. Introduction

360◦ videos are a new type of video that displays over all 4π steradian. Spurred by the
development of 360◦ cameras to capture 360◦ content, it is now possible to share these
videos via sites like YouTube and Facebook, thus increasing their reach.

A natural application of this technology to astrophysics is to create 360◦ videos of sim-
ulations. As opposed to traditional movies, which typically view the simulation domain
from outside the simulation volume, or which move through the simulation domain but
only render each frame in a predetermined direction, 360◦ videos immerse the viewers
in the simulation and allow the viewers to choose where to look. The three methods for
viewing 360◦ videos are on a computer, with a hand-held smartphone or tablet, or in
VR goggles. For each method, you click and drag the video on the screen, pan the phone
around, or simply look in diﬀerent directions, respectively, to change the viewing orienta-
tion. The VR goggles are by far the most immersive experience, but using a smartphone
or computer makes these movies accessible to a much larger audience.

The 360◦ videos described here are not speciﬁcally VR content, in which the user puts
on a VR headset plugged into a computer and can walk around to move through the
simulation volume; the image in the goggles is then rendered in real time based on the
user’s position and viewing orientation. On the other hand, sharable 360◦ videos have a
predeﬁned camera location chosen by the creator (just like with traditional movies), but
the viewers choose where they look.

In this paper, we ﬁrst describe how to create 360◦ videos from astrophysical simula-
tions, then present what we believe is the ﬁrst such video shared online, which shows the
distribution of material expelled by Wolf-Rayet stars in the Galactic centre, and ﬁnally
discuss potential scientiﬁc applications of 360◦ videos.

1

7
1
0
2

l
u
J

1
2

]

M

I
.
h
p
-
o
r
t
s
a
[

1
v
4
5
9
6
0
.
7
0
7
1
:
v
i
X
r
a

 
 
 
 
 
 
2

Christopher M. P. Russell

2. Constructing a 360-degree video

The ﬁrst step is to create a movie where the x- and y-axes are the azimuthal and polar
axes, respectively. Naturally, the x-axis should range from 0◦ to 360◦, and the y-axis
from 0◦ to 180◦, so the aspect ratio is 2-to-1 for the recommended square pixels. Fig. 1
shows a frame from the video presented here.

This is the most challenging step since most visualization software generates images
where the x- and y-axes correspond to linear dimensions, not angular dimensions. For our
video, we modiﬁed the smoothed particle hydrodynamics (SPH) visualization program
Splash (Price 2007) to render pixels across the full azimuthal and polar ranges at the
desired angular width. Once the images are created, the next step is to create a movie
with a 2-to-1 aspect ratio using video creation software; we use ffmpeg.

The second step is to add metadata to the movie ﬁle that states that it is a 360◦
video ﬁle. As we put our videos on YouTube, we followed the instructions here https:
//support.google.com/youtube/answer/6178631, which involves downloading a pro-
gram called “Spatial Media Metadata Injector.” Importing the video, which must be in
*.mov or *.mp4 format, to this program adds the necessary metadata.

The ﬁnal step is to upload the video to YouTube. Besides the aforementioned metadata,
nothing special needs to be done to get the video into 360◦ format. However, the usual
YouTube tools to modify videos will overwrite this information, so they can not be used.
Therefore, the initial ﬁle into which the metadata is injected must be the ﬁnal form.
Once uploaded, the 360◦ video is available for the world to see.

At present, the maximum resolution for a 360◦ video shared via YouTube is 2160s
through the app and 4320s via a computer. The ‘s’ designation stands for ‘spherical,’
and the number preceding it is the number of polar pixels; e.g., 2160s is 4320 azimuthal
pixels by 2160 polar pixels. The human eye with 20/20 vision can resolve ∼1(cid:48), or ∼10800s,
so the maximum resolution for 360◦ videos is ∼20-40% of what humans can see.

3. 360-degree video of the Galactic centre

Cuadra et al. (2008, 2015) constructed numerical simulations of the 30 Wolf-Rayet
(WR) stars and their winds orbiting Sgr A∗ within the central parsec of our galaxy.
Starting from the stellar locations 1100 yr ago, the WRs orbit Sgr A∗ while ejecting
their stellar wind material. The central parsec quickly ﬁlls up with an ambient medium,
into which the newly ejected wind material plows, causing wind-blown bubbles from
the slow-moving stars and bow shocks around the fast-moving WRs. The intent was to
study the time-dependent accretion history of material onto Sgr A∗ (the WR winds are
the dominant mass-injection source in the region), but was also successful in explaining
the thermal X-ray emission resolved with Chandra (Russell et al. 2017).

We created a 360◦ video from an updated hydrodynamic simulation of these 30 WR
stars and their winds by rendering column density from the position of the centre of the
simulation, i.e. at the location of Sgr A∗. The link to the video is https://youtu.be/
pK59iu4cNRM †. Fig. 2 shows the snapshot of Fig. 1 viewed in 360◦ format. Note that the
distortion evident in Fig. 1, which is due to the image being polar vs. azimuthal angle
and the viewing region being near the bottom of the plot, is gone when viewed in the
360◦ format of Fig. 2.

† Alternatively, it might be better, particularly if viewing on a smartphone or VR goggles,
to go to CMPR’s YouTube channel – either http://tinyurl.com/cmpr360video, or search for
“Christopher Russell astronomy” in the app – and select the video “Galactic Center Column
Density.”

360-degree videos of astrophysical simulations

3

Figure 1. A single frame used to make the 360◦ video of the column density viewed from the
exact centre of our galaxy. The x-axis goes from 0-360◦ in azimuthal, while the y-axis is 0-180◦
in polar. Adding the metadata tells YouTube to warp this into a sphere when viewing the movie.

Figure 2. A screenshot of the movie when viewed from inside VR goggles.

To our knowledge, a shorter version of this video, published to YouTube on 15 Nov.
2016, is the ﬁrst 360◦ video of an astrophysical simulation ever created and shared. (This
video was published 10 days later.)

4. Future work

We are currently studying which science insights can be obtained from viewing simula-
tions in this 360◦ manner. For example, we have produced a new movie with 10× higher
time sampling (https://youtu.be/BWiBIol7gzQ). This aﬀords a clear view of the in-
spiraling and stretching of clumps as they plummet towards Sgr A∗. Additionally, a 360◦
movie of the colliding wind binary η Carinae shows when the primary wind completely en-
gulfs the secondary star around periastron passage (https://youtu.be/RzF6u0on_tw).
More applications will certainly be developed in the future.

References
Cuadra, J., Nayakshin, S., and Martins, F. 2008, MNRAS, 383, 458
Cuadra, J., Nayakshin, S., and Wang, Q. D. 2015, MNRAS, 450, 277
Price, D. J. 2007, PASA, 24, 159
Russell, C.M.P., Wang, Q.D., & Cuadra, J. 2017, MNRAS, 464, 4958

