Cellular-Connected Wireless Virtual Reality:
Requirements, Challenges, and Solutions

Fenghe Hu, Student Member, IEEE, Yansha Deng, Member, IEEE, Walid Saad, Fellow, IEEE, Mehdi Bennis,
Senior Member, IEEE, and A. Hamid Aghvami, Fellow, IEEE

1

0
2
0
2

r
a

M
3
1

]
P
S
.
s
s
e
e
[

2
v
7
8
2
6
0
.
1
0
0
2
:
v
i
X
r
a

Abstract—Cellular-connected wireless connectivity provides
new opportunities for virtual reality (VR) to offer seamless user
experience from anywhere at anytime. To realize this vision, the
quality-of-service (QoS) for wireless VR needs to be carefully
deﬁned to reﬂect human perception requirements. In this paper,
we ﬁrst identify the primary drivers of VR systems, in terms of
applications and use cases. We then map the human perception
requirements to corresponding QoS requirements for four phases
of VR technology development. To shed light on how to provide
short/long-range mobility for VR services, we further list four
main use cases for cellular-connected wireless VR and identify
their unique research challenges along with their corresponding
enabling technologies and solutions in 5G systems and beyond.
Last but not least, we present a case study to demonstrate
the effectiveness of our proposed solution and the unique QoS
performance requirements of VR transmission compared with
that of traditional video service in cellular networks.

I. INTRODUCTION

Virtual reality (VR) will revolutionize the human interac-
tions between humans and their world by connecting people
across global communities within highly interactive virtual
components or worlds that transcend geographical boundaries.
This vision has inspired the commercial release of various
hardware devices, open-access standards, and APIs by various
global enterprises, including ARKit from Apple, HoloLens
from Microsoft, Oculus series from Facebook, and Vive series
from HTC. Indeed, it is anticipated that the global VR market
size will reach $80.7 billion by 2024, stemming from a diverse
set of VR services and devices that are expected to stimulate
our human senses with realistic feedback.

Virtual reality (VR) is a transformative service designed to
build a synthetic virtual environment to mimic the real world
and, subsequently,
immerse participants in highly realistic
virtual worlds. VR will in fact provide innovative ways for
users to interact with their world for various purposes such as
personal entertainment and social interactions. Indeed, VR will
have a very rich application domain ranging from automotive
video streaming, social sharing at crowded venues, and 6
degree-of-freedom content streaming, to remote control/tactile
the poor user experience provided
Internet [1]. However,

F. Hu, Y. Deng, and A. H. Aghvami are with the Department of Informatics,
King’s College London, London WC2R 2LS, UK (E-mail: fenghe.hu, yan-
sha.deng, hamid.aghvami@kcl.ac.uk).(Corresponding author: Yansha Deng.)
M. Bennis is with Centre for Wireless Communications, University of Oulu,

Finland, (Email: bennis@ee.oulu.ﬁ).

W. Saad is with Wireless@VT, Bradley Department of Electrical and
Computer Engineering, Virginia Tech, Blacksburg, VA, USA,
(Email:
walids@vt.edu). This research was supported by the U.S. National Science
Foundation under Grant CNS-1836802.

by traditional computer-supported VR headsets or all-in-one
headsets (e.g., Oculus Go) limits the imagination and virtual
world potential for what is possible with VR (as shown in
Table. I).

One of the main barriers facing the mass marketization
of these VR applications is the restricted mobility of wired
VR devices and the lack of real-time high-quality content
support of the all-in-one VR devices. To overcome these
limitations, one can support VR devices with wireless cellular
connectivity that can provide ubiquitous user experiences from
anytime and anywhere and can potentially unleash a plethora
of novel VR applications. While cellular-connected VR has
a very promising potential, it is imperative to address many
unique challenges that are not faced in wired VR systems
and conventional wireless video streaming systems. Such
challenges include providing seamless service over unstable
wireless channels, solving handover issues when VR users
are mobile, managing the asymmetric and coupled trafﬁc in
the uplink and downlink, and providing real-time VR content
service [2]–[4]. With the growing interest in wireless VR
[5]–[7], there is a need for a concrete vision on how one
can integrate wireless VR services over cellular networks.
Although some recent articles such as [5]–[7] have attempted
to discuss these challenges, they failed to provide quantitative
quality-of-service (QoS) requirements from human perceptions
and cellular-connected VR use cases perspectives. In [7], we
have provided a new deﬁnition, called quality-of-physical-
experience, which jointly considers the physical fact of human
itself and network QoS. Meanwhile, in [8], we have introduced
the concept of breaks-in-presence to capture the QoS of
wireless VR.

The main contribution of this paper is a comprehensive
study of the unique challenges and potential solutions for
cellular-connected wireless VR networks. From the perspec-
tive of satisfying human perceptions, we ﬁrst deﬁne human
perceptions of VR services which are then mapped to unique
QoS requirements for immersive VR in Section II. In par-
ticular, we categorize the development of VR QoS into four
phases with their corresponding QoS requirements as well
as VR device parameters. Then, we introduce the four use
cases of VR deﬁned by Qualcomm and their speciﬁc VR QoS
requirements for cellular-connected VR and we identify the
challenges in meeting these QoS requirements, while outlining
promising solutions in Section III. We then conclude with a
practical simulation to capture the challenge of supporting
cellular-connected VR with the current state-of-art cellular
network in Section IV.

 
 
 
 
 
 
TABLE I
CURRENT MR/VR HEADSETS TECHNICAL PARAMETERS

Devices

Hololens 2
Vive
Pimax 8K
Odyssey
Oculus Rift
Playstation VR
Vive Pro Eye

FoV
(diagonal)
52°
110°
150°
110°
110°
100°
110°

PPD

47
11
14
14
11
11
14

Resolution
(single-eye)
/
1080×1200
3840×2160
1440×1600
1080×1200
960×1080
1440×1600

Refresh
Rate
/
90 Hz
80 Hz
/
90 Hz
120 Hz
90 Hz

II. VR SERVICE REQUIREMENT

In order to deﬁne the VR QoS requirements of cellular-
connected VR devices, the service requirements for a fully im-
mersive virtual experience will be ﬁrst discussed based on the
human perception requirements, given that the performance
of VR services is highly determined by the users’ quality-of-
physical-experience (QoPE) [7]. Then, the QoS requirements
for four VR phases pertaining to the evolution of VR devices
will be detailed.

A. Human Perception

In VR applications, human perceptions can be evaluated
based on resolution, ﬁeld-of-view (FoV), refresh rate, and
VR interaction latency. These factors will impact the QoS
requirement needed for having an immersive VR experience in
different applications and for various users. Human perception
can vary between individuals depending on a variety of human
factors that include age, health, and occupation, among others.
In the following, we provide the average human perception
values for a typical, healthy young person between 12 and 18
years old.

1) Resolution: The minimum VR resolution can be de-
termined by the maximum acuity of human eyes. For an
environment with a ﬁne black line on an illuminated white
background, the maximum acuity corresponds to a minimum
resolvable feature or gap of 0.3~1 arc-minutes, a minimum de-
tectable object of 0.5 arc-second, a minimum visible position
shift of 5 arc-second, and a minimum identiﬁable object of
40~60 arc-second. In this case, an image resolution with more
than 720 pixel-per-degree (PPD) is required to fully satisfy the
human eye’s requirement. For a non-ideal environment with
relatively low disparity scenes, a VR resolution with more than
60 PPD is needed to fully satisfy the human eye’s requirement
[3]. However, as shown in Table I, existing commercial VR
headsets can only achieve a maximum of 14 PPD resolution,
leading to the so-called “screen door effect”, in which the ﬁne
lines separating pixels become visible.

2) Field-of-View: The area of vision in the human eye at a
speciﬁc time is known as the ﬁeld-of-view (FoV) shown in [9,
Fig. 4.1], which speciﬁes a 210°×150° (i.e., diagonal 200°)
FoV requirement. The FoV can be further divided into several
regions with different resolution requirements. The central
vision zone is the most sensitive zone with 60° around the
center. Meanwhile, peripheral vision zone is a less sensitive
zone with 30° around the central vision, and the monocular

2

vision zone is the rest of the vision. Usually, the central
vision zone has the highest resolution requirement, and the
monocular vision has the lowest resolution requirement [5,
Fig. 2]. Note that existing commercial VR headsets can only
achieve a maximum 150° of FoV as shown in Table I.

3) Refresh Rate: The refresh rate is the number of frames
per second shown by the display. A higher refresh rate leads
to more continuity in the motion. A low refresh rate can
cause motion blur. Depending on either the visual acuity or
the motion continuity, lower bounds of the refresh rate can
be obtained. To ensure the motion continuity from human
perceptions, the minimum refresh rate for a computer-rendered
video is 120 Hz [5]. To ensure the movement is presented
pixel by pixel continuously while moving at a speed of 30
degree/second speed on a 60 PPD resolution monitor, the
minimum refresh rate can be very stringent and as strict as
1800 Hz [3]. Note that existing commercial VR headsets can
only achieve a maximum 120 Hz refresh rate as shown in Table
I.

4) VR Interaction Latency: The VR interaction latency is
one of the key requirement in VR service and is deﬁned as
the time starting from the user’s movement to the time where
the virtual environment responds to the user’s movements.
For non-VR application, the interaction latency cannot exceed
100 ms for action like pressing the key [3]; for VR application,
the VR interaction latency should be less than 20 ms to
avoid motion sickness and discomfort. The VR interaction
latency is also signiﬁcantly impacted by the human brain and
perception [7]. To cater to different requirements of human
and applications, it is common to deﬁne the minimum VR
interaction latency as 10 ms [5].

B. Mapping Human Perception Requirements to QoS

Given the limits of human perceptions, we can map them to
concrete VR QoS requirements, such as data rate, error rate,
and communication delay.

1) Data Rate: To satisfy the human perception require-
ments with 60 PPD minimum resolution and 120 Hz minimum
refresh rate, the minimum downlink data rate will be around
50.39 Gbps for 360 degrees VR transmission under a 20:1
compression rate as shown in Table. II. Note that, with a higher
compression rate, the data rate requirement can be reduced by
sacriﬁcing the VR interaction latency using more processing
resources. The data rate of uplink motion information is
around 100-150 kbps, which is negligible compared to the
downlink video streaming [2].

2) VR Interaction Latency: The 10 ms minimum VR inter-
action latency requirement is not restricted to the communi-
cation delay, but it also includes the rendering delay and the
video coding/decoding latency. Meeting this unique VR delay
requirement will, in turn, lead to a very stringent constraint
on the wireless communication latency which must now be
much smaller than 10 ms. As an example, the VR test on
a Huawei 5G network with cloud service [10] showed that
the communication latency accounts for 17.9 ms out of the
82.2 ms VR interaction latency, as shown in Fig. 1. Even with
prediction, only one-third of the target VR interaction latency

3

TABLE II
QOS REQUIREMENTS FOR VR PHASES

Requirement

Pre-VR

Entry-Level VR

Advanced VR

Human
Perception

Experience Duration

Video Resolution

less than 20
minutes

3840×1920
(Full-view 4K
Video)

less than 20
minutes

7680×3840
(Full-view 8K
Video)

less than an hour

/

11520×5760
(Full-view 12K
Video)

21600×10800
(Full-view
Video)

Ultimate VR

more than an
hour

23040×11520
(Full view 24K
Video)

Single-eye Resolution

1080×1080

1920×1920

3840×3840

9000×8100

9600×9600

Field-of-View (Single-eye)

100×100

110×110

120×120

150×135

150×150

Bit per Color (RGB)

Refresh Rate

Pixel per Degree

8

60

10

8

90

17

10

120

32

/

120

60

12

200

64

Service
Require-
ment

Uncompressed Bit Rate
(Progressive 1:1)*

Transmitting Bit Rate
(Low-latency
Compression 20:1)

Transmitting Bit Rate
(Lossy Compression
300:1)

Typical Round Trip
Time (RTT)

Typical Packet Loss

10.62 Gbps

63.70 Gbps

238.89 Gbps

1007.77 Gbps

1911.03 Gbps

530 Mbps

35 Mbps

10 ms

10−6

3.18 Gbps
(Full-view) 796
Mbps (FoV)

210 Mbps
(Full-view) 53
Mbps (FoV)

11.94 Gbps
(Full-view) 5.31
Gbps (FoV)

796 Mbps
(Full-view) 354
Mbps (FoV)

50.39 Gbps
(Full-view) 31.49
Gbps (FoV)

95.55 Gbps
(Full-view) 66.36
Gbps (FoV)

3.36 Gbps
(Full-View) 2.10
Gbps

6.37 Gbps
(Full-view) 4.42
Gbps (FoV)

10 ms

10−6

5 ms

10−6

10 ms

10−6

5 ms

10−6

* Progressive Data rate = (3×Bit per Color) × (Pixel per Degree×Field-of-view (Full-view or Single-eye)) × Refresh Rate / Compression ratio

is available for wireless transmission, which further strains the
resources of the cellular network. Under such stringent latency
constraints, few additional milliseconds in the communication
latency can have a signiﬁcant inﬂuence on the VR QoS.

3) Error Rate: VR devices support two major types of
trafﬁc: motion information and VR stream data. The motion
information requires zero error. As the visual environment is
constructed based on the real-time user’s motion and location
information, an error in motion information can require an
additional processing delay in order to regenerate the error
pixels [8]. Thus, it is desirable to maintain the error rate of VR
stream data below 10−6 to avoid lost, degraded, or damaged
frames detectable by a human. Even with a lower error rate,
the VR frame error may propagate and be visible over many
consecutive frames.

C. Mapping VR Phases to Quality-of-Service

Fig. 1. Decomposition of end-to-end VR interaction latency in Huawei 5G
Test with cloud server [10].

Huawei has deﬁned four evolved VR phases with different
VR device technical speciﬁcations: Pre-VR, Entry-level VR,
Advanced VR, and Ultimate VR phase [4]. Each phase deﬁnes
a new level of VR device technical speciﬁcation, which
is primarily related to the development of the VR device.
Based on these speciﬁcations, we can calculate the service
requirement at each phase as shown in Table II. Clearly, the
current commercial VR devices in Table I fall in the pre-
VR and Entry-level VR phases, and the service requirement
governed by human perceptions lies between the Advanced
VR and the Ultimate VR phases.

III. USE CASES, CHALLENGES, AND POTENTIAL
SOLUTIONS

Based on the VR requirements of Section II, we identify
several key characteristics of VR trafﬁc that makes it different
from conventional video trafﬁc:

• VR applications require a seamless low delay high ca-
pacity guarantee service for real-time rendering and VR
interaction latency;

16.9       ms5.4 ms6ms11.9ms16.8ms13.9msMoon trackingRenderingVideo/Audio EncodeFrame TransmissionVideo/Audio DecodeAdjustmentCloud/Edge ServerBase SaonsUser0 msPredictorIf the Predicon is Correct4

Fig. 2. Cellular-connected wireless VR use cases, challenges, and potential solutions in 5G [1]. The data rate and latency values are suggested in the report
which is based on the existing commercial VR devices in Entry-level VR phase as shown in Table II.

• VR content changes following the real-time users’ mo-

tion;

• The uplink and downlink data rate requirements are
asymmetric and coupled as they are both correlated to
the end-to-end VR performance.

The aforementioned unique characteristics of VR services
bring forward new research challenges for existing wireless
networks. For outdoor VR applications, LTE has been tested
in [2] under various mobility and signal strength conditions,
and it is shown to support around 15 Mbps trafﬁc with 10 −
30 ms network delay, which does not even reach the pre-VR
phase requirement in Table II. It is anticipated that 5G systems
will deliver much higher data rates than LTE and, hence, it
can better support ubiquitous connectivity for VR services.
It is reported in [11] that the minimum downlink and uplink
targets for 5G will be more than 50 Mbps everywhere, and
the maximum downlink data rate at the user can be up to 1
Gbps, which only reaches the data rate requirements of the
Advanced VR in Table II.

By quantifying the capacity, latency, and reliability require-
ments for cellular-connected VR services, a recent technical
report from [1] has classiﬁed cellular-connected VR applica-
tions into four main use cases, which are automotive video
streaming (VR-AVS), social sharing at crowded venues (VR-
SS), 6 degree-of-freedom content streaming (VR-DoF), and
remote control/tactile Internet (VR-RC), as shown in Fig.
2. In the following, these four use cases with their service
requirements are described followed by their key challenges
and potential solutions.

A. Automotive Video Streaming

The automotive video streaming (VR-AVS) use case will
allow commuters to enjoy live VR video streaming in high-
speed trains and cars, which leads to technical challenges
pertaining to supporting uniform and seamless connectivity
with 100 Mbps data rate (Early-level VR phase) for high-
mobility VR users using cellular networks. Next, we list
potential solutions to cope with cellular network challenges
brought by high mobility.

1) Dual Connectivity: Dual connectivity, which allows
multiple base stations (BSs) to transmit and receive data
simultaneously to and from VR-AVS users, provides new
opportunities for maintaining seamless VR service. Dual con-
nectivity has been introduced as an important feature in LTE-
Advanced (Rel-10/11) as well as part of 5G Multilink. For
delay and resource sensitive VR applications, dual connectivity
can reduce the service glitch caused by resource shortage,
blockage, handover failure, and poor cell-edge performance.
For instance, a VR-AVS video can be split between two
BSs via drastically different bands for uplink and downlink
communications for more efﬁcient and robust transmission
via inter-cell resource aggregation. As a result, part of the
video can be received if errors occur over one of the links.
Speciﬁcally, a sub-6 GHz band with decent coverage can be
suitable for uplink motion information (small packets), and
the millimeter-wave (mmWave) band that provides high data
rates can be used for downlink VR video trafﬁc. However, for
users with high mobility in VR-AVS use case, the association,
energy, and resource allocation are the major problems for dual
connectivity. The backhaul network also requires to re-route
the required trafﬁc following the movement of VR users.

2) Coordinated Multipoint Transmission and Reception:
Under the aforementioned conditions, coordinated multipoint
transmission (CoMP), can be a suitable solution for addressing
the challenge related to possible ﬂuctuations in the data rates
due to blockage (under mobility), by serving VR-AVS users
using multiple BSs (multiple-path) over the same spectrum
at the same time. Note that CoMP has been listed as a key
feature in LTE-Advanced and 5G because of its ability to
support delay-sensitive wireless applications [12]. For VR
applications,
the downlink data rates can be improved to
continuously meet the QoS needs of the VR users and the
uplink motion information can be jointly processed for higher
reliability to ensure accurate motion tracking.

B. Remote Control and Tactile Internet

The remote control and tactile internet

(VR-RC) use
case pertains to applications that involve a remote control
of cellular-connected unmanned-aerial-vehicles (UAVs) and

robots over very long distances using VR. In this use case,
the main challenge is how to support seamless connectivity
with ultra-low end-to-end latency (e.g., within 5 ms latency).
Similar to other delay sensitive applications, such as vehicular
networks, the existing solutions for delay reduction include
caching, network slicing and edge computing etc.

In the latency-sensitive VR-RC use case, motion predic-
tion using machine learning can largely beneﬁt the VR user
experience at multiple levels. For instance, the prediction of
users’ motion allows pre-fetching the FoV of the users, as
shown in Fig. 1. However, it is important to note that the
system needs to be able to tolerate prediction inaccuracy and
to re-generate the correct content within the delay threshold
[8]. It is also important to ensure the generalization of these
prediction algorithms and enable transfer learning for other
scenarios and applications. Second, motion prediction on the
users’ movement and location can be also beneﬁcial for the
quick association of VR users and remotely-controlled robots.
Recall that VR services that use high-frequency bands are
highly vulnerable to blockage due to obstacles. It is possible
to proactively associate users by predicting the orientation
and mobility patterns of VR users with known environment
information. In this way, sudden drops in the control link’s
QoS caused by blockage can be reduced.

C. The 6 Degree-of-freedom Content Streaming

The 6 degree-of-freedom (VR-DoF) content streaming use
case will allow users to intuitively interact with a high quality
immersive virtual world while moving freely inside the virtual
environment. This use case requires meeting unique challenges
related to supporting high data rates (400 − 600 Mbps, Ad-
vanced VR stage), and low latency (5 − 20 ms) with accurate
positioning of the VR user. These challenges can be addressed
using the following solutions.

1) High Frequency Transmission: In VR-DoF, the immer-
sive experience of VR user must be supported through high-
resolution video transmission, imposing stringent bandwidth
requirements. The desire for higher video compression rate
and lower compression latency calls for additional radio re-
sources. As shown in Table II, the Ultimate VR phase with
a 20:1 compression rate under ultra-low latency constraints
requires more than 100 Gbps throughput. In this context,
high-frequency transmission like mmWave (30 − 300 GHz)
and terahertz (THz) (100 GHz–10 THz) communication are
promising technologies to deliver VR-DoF content for wear-
able VR devices due to their high bandwidth availability and
small form factor [13]. Using the aforementioned technologies,
Vive has already implemented a wireless adapter for delivering
such service via a mmWave connection from two access points
within a small open room.

However, the main drawback of high-frequency communi-
cation is that it is unreliable and cannot maintain a high data
rate over non-line-of-sight (NLoS) channels. This is because
the penetration loss increases with increasing the frequency for
most solid materials. In fact, even the human body can block
the signal and cause glitches in the data stream. Overcoming
including the use
this challenge requires new techniques,

5

of a reﬂector for re-establishing line-of-sight connectivity,
proactive mobility management, dynamic frame structure, and
integration of mmWave with sub-6 GHz frequencies [8], [14].
2) Edge Computing: VR-DoF content streaming VR appli-
cations will require effective computing to execute tasks such
as rendering the VR environment, processing user motions,
and computing data in the virtual environment. To maintain
a low computing delay and avoid end-to-end transmission
latency to a remote cloud, it is desirable to rely on edge com-
puting techniques in which video rendering and computations
are executed at edge devices that include BSs, edge servers, or
even the VR devices themselves. Determining where (cloud or
edge) and how to perform computing tasks for VR purposes
is therefore an important challenge. Performing computations
at the level of the VR devices can signiﬁcantly reduce the
transmission latency. However, the limited computing capacity
of end-user VR devices can lead to higher computing latency.
As such, it is of interest to study how one can distribute
computing tasks to different edge devices. Overcoming these
challenges requires research across computing and communi-
cation domains. For instance, in [8], the author have developed
several video transmission and caching schemes that take into
account both the processing and transmission aspects of VR
networking. In the commercial area the overall latency with
state-of-the-art image processing and networking for VR was
analyzed in [4] and by Google Stadia which promises to
achieve 100 ms end-to-end edge/cloud gaming experience.

D. Social Sharing at Crowded Venues

The social sharing at crowded venues (VR-SS) use case will
allow a large group of users to share a VR experience in a
public area, such as a bar or stadium. The main challenges
facing the VR-SS use case include the need to support high
uplink/downlink data rates with 12.5 Tbps/km2 in each direc-
tion and the need to integrate diverse VR applications with
different service requirements [1]. It is a critical challenge for
the cellular network to support a broad range of bandwidth-
consuming and latency-critical VR services with various QoS
requirements.

To guarantee a target perceptual resolution, massive MIMO
can be employed to exploit spatial diversity and provide the
multi-gigabit data rates required by static and mobile VR-
SS users over large coverage areas. The large antenna array
of massive MIMO systems will also provide more angle-of-
arrival information, which beneﬁts the positioning the system
in VR. Although many prior research has already shown that
massive MIMO is effective to provide cellular connectivity,
there is still a need for enhancing the stringent VR QoS
requirement, especially for ultra-dense device connectivity in
VR-SS use case. Beyond increasing the number of antennas
within a limited space, it is also important to look for an
economically viable approach to serve a large public crowd.
For an indoor VR-SS environment with dense VR users
in an ofﬁce building, holographic massive MIMO using a
large intelligent surface can potentially be used to overcome
unfavourable propagation conditions or to enrich the channel
by introducing multi-paths, through integrating an uncountable
and inﬁnite number of antennas into a limited surface area.

IV. CASE STUDY

In light of the aforementioned VR challenges, it is necessary
to identify the joint high reliability, low latency, as well as
high data rate requirements for all four cellular-connected VR
use cases. More importantly, there is a fundamental difference
between a traditional video service (even a 360° video) and a
VR-DoF streaming service due to the new human perception
requirements in VR that we discussed in Section II. While
a streamed 3DoF video (i.e., 360° video) content can tolerate
unstable QoS via a jitter buffer, the rendering of 6DoF content
calls for real-time transmission with low interaction latency
[1].

To compare the rate-reliability-latency performance between
VR-DoF streaming and traditional video streaming in cellular
networks, we examine the percentage of successfully deliv-
ered bitplanes within a 7 ms constraint between traditional
video transmission and VR video transmission in the same
wireless mmWave network setting. To separate the 10 ms
delay constraint into uplink and downlink, we have distributed
the values of the delay constraint according to the proportion
of downlink delay in the context of the round-trip delay
ratio in Fig. 1, which is 7 ms. Both types of video are
transmitted following a MPEG video coding scheme, which
separates a video stream into bitplanes, each of which being
of size 1, 578 bits, calculated based on a 768 Mbps bit rate
requirements for the Advanced phase in Table II. Then, we
apply dual connectivity (with two mmWave links) for VR-
DoF streaming to show the need for new technologies to
deliver such service, where the second-closest base station acts
as the ﬁxed second base station, which transmits the same
data simultaneously in another mmWave band. In this regard,
we conduct a VR-DoF use case study with Nu randomly
distributed viewers using the 2D map of King’s College
London within a simulation environment with three BSs (with
ﬁxed locations at ME London, Strand Building, and Somerset
House). For the wireless connection, we use a classical 3GPP
mmWave channel model [15] operating at 28 GHz taking into
account the penetration loss and the indoor path loss through
real building walls in King’s College London. We also consider
two types of schedulers at the BSs, namely proportional fair
(PF) or round-robin (RR) scheduler following their implement
in NS-3.

To measure the rate-reliability-latency tradeoff, in Fig. 3,
we plot
the percentage of successfully delivered bitplanes
within a 7 ms downlink delay constraint versus the number
of users for VR streaming and traditional video during within
a transmission time of 5 minutes. As expected, this metric
for both trafﬁc types decreases with increasing the number of
users to a larger cell load and higher interference. Surprisingly,
the performance of the two schedulers with the same type
of trafﬁc are similar due to the relatively low downlink
trafﬁc load. We also notice that the cellular network failed
to support VR streaming effectively in the rate-reliability-
latency space, as can be seen from a much lower percentage
of successfully delivered bitplanes within 7 ms constraint
compared with traditional video streaming. This is because
the uncertainty of the channel conditions in mmWave networks

6

Fig. 3. The percentage of successful delivered bitplanes with a delay
constraint of 7 ms for VR and traditional videos.

result in performance degradation, that is unbearable for VR
user experience. Importantly, it is also shown that our proposed
solution – dual connectivity – can largely combat the unstable
wireless channel by connecting a VR device with two BSs
simultaneously to provide enhanced performance. This case
study clearly highlights the need for providing seamless VR
connectivity within rate-reliability-latency space by using new
approaches such as dual connectivity.

V. CONCLUSION
In this paper, we have envisioned a new paradigm for
integrating VR into wireless cellular networks for providing
seamless immersive VR applications from anywhere at any
time. From a VR user perspective, we have ﬁrst deﬁned
the QoS requirements for four wireless VR technological
phases based on human perception requirements. We have then
presented four use cases and corresponding potential solutions
for cellular-connected VR communication by quantifying their
speciﬁc QoS requirements and potential trade-off. Importantly,
the case study has demonstrated that a cellular mmWave
network can potentially support the VR streaming with new
QoS requirement via the help of dual connectivity, and
identiﬁed the unique QoS requirements of VR transmission
compared with that of traditional video service. This work
serves to inspire research to customize optimization solutions
for cellular-connected VR use cases with technologies like
motion prediction, massive MIMO, and edge computing.

REFERENCES

[1] Qualcomm, “VR and AR pushing connectivity limits,” Qualcomm
2019-
[Online]. Available: https://www.qualcomm.com/invention/

Inc., Tech. Rep.,

Technologies.
12-19).
extended-reality/virtual-reality

(Accessed

2018

on

[2] Z. Tan, Y. Li, Q. Li, Z. Zhang, Z. Li, and S. Lu, “Supporting mobile
VR in LTE networks: How close are we?” in Proc. ACM Meas. Anal.
Comput. Syst., vol. 2, no. 1, pp. 1–31, March 2018.

[3] E. Cuervo, K. Chintalapudi, and M. Kotaru, “Creating the perfect illusion
: What will it take to create life-like virtual reality headsets?” Proc. 19th
Int. Work. Mob. Comput. Syst. Appl., pp. 7–12, February 2018, NY,
USA.

[4] Huawei-iLab, “Cloud VR,” Tech. Rep., 2017 (Accessed on 2019-12-19).
https://www-ﬁle.huawei.com/-/media/corporate/

[Online]. Available:
pdf/ilab/cloud vr oriented bearer network white paper en v2.pdf

051015202530354045Number of users (Nu)70%75%80%85%90%95%100%Percentage of successfully deliveredbitplaneswithin7msconstrainVR traffic with PF schedulerVR traffic with RR schedulerVideo traffic with PF schedulerVideo traffic with RR schedulerVR traffic with RR scheduler and dual-connectivityVR traffic with PF scheduler and dual-connectivity7

[5] E. Bastug, M. Bennis, M. Medard, and M. Debbah, “Toward intercon-
nected virtual reality: Opportunities, challenges, and enablers,” IEEE
Commun. Mag., vol. 55, no. 6, pp. 110–117, August 2017.

[6] M. S. Elbamby, C. Perfecto, M. Bennis, and K. Doppler, “Toward low-
latency and ultra-reliable virtual reality,” IEEE Netw., vol. 32, no. 2, pp.
78–84, January 2018.

[7] W. Saad, M. Bennis, and M. Chen, “A Vision of 6G Wireless Systems:
Applications, Trends, Technologies, and Open Research Problems,”
IEEE Netw., 2020. [Online]. Available: http://arxiv.org/abs/1902.10265
[8] M. Chen, W. Saad, and C. Yin, “Virtual reality over wireless networks:
Quality-of-service model and learning-based resource management,”
IEEE Trans. Commun., vol. 66, no. 11, pp. 5621–5635, June 2018.
[9] 3GPP, “Virtual reality (VR) media services over 3GPP (3GPP TR 26.918

version 15.2.0 release 15),” 3GPP, Tech. Rep., 2018.

[10] W. Zhang, “Cloud X: New services in 5G era,” Huawei, Tech. Rep.,
2018 (Accessed on 2019-12-19). [Online]. Available: https://www.gsma.
com/futurenetworks/wp-content/uploads/2019/03/Huawei-5G-PDF.pdf

[11] R. El Hattachi

and J. Erfanian,

“NGMN 5G white paper,”
NGMN Alliance, Tech. Rep., Feb. 2015 (Accessed on 2019-12-
[Online]. Available: https://www.ngmn.org/wp-content/uploads/
19).
NGMN 5G White Paper V1 0 01.pdf

[12] 3GPP, “3GPP TR 36.819: Coordinated multi-point operation for LTE

physical layer aspects(release 11),” 3GPP, Tech. Rep., 2013.

[13] C. Chaccour, R. Amer, B. Zhou, and W. Saad, “On the reliability of
wireless virtual reality at Terahertz (THz) frequencies,” in Proc. of
10th IFIP International Conference on New Technologies, Mobility and
Security (NTMS), Canary Islands, Spain, June 2019.

[14] O. Semiari, W. Saad, M. Bennis, and M. Debbah, “Integrated millimeter
wave and sub-6 GHz wireless networks: A roadmap for joint mobile
broadband and ultra-reliable low-latency communications,” IEEE Wirel.
Commun., vol. 26, no. 2, pp. 109–115, February 2018.

[15] 3GPP, “Study on channel model for frequency spectrum above 6 GHz
(3GPP TR 38.900 version 14.3.1 release 14),” 3GPP, Tech. Rep., 2017.

Fenghe Hu is currently a PhD student in the center of telecommunication
research, King’s College London.

Yansha Deng is currently a Lecturer (Assistant Professor) with the Depart-
ment of Informatics, Kings College London. Her research interests include
molecular communication, Internet of Things, and 5G wireless networks.

Walid Saad is a Professor at the Department of Electrical and Computer
Engineering at Virginia Tech. His research interests include wireless networks,
machine learning, game theory, cybersecurity, unmanned aerial vehicles, and
cyber-physical systems.

Mehdi Bennis is an Associate Professor at the Centre for Wireless Communi-
cations, University of Oulu, Finland. His main research interests are in radio
resource management, game theory and machine learning in 5G/6G networks.

Hamid Aghvami joined the academic staff at Kings College London in 1984.
In 1993 was promoted Professor in Telecommunications Engineering. He is
the founder of the Centre for Telecommunications Research at Kings.

