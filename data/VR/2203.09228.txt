2
2
0
2

r
p
A
8
2

]

C
H
.
s
c
[

3
v
8
2
2
9
0
.
3
0
2
2
:
v
i
X
r
a

Re-shaping Post-COVID-19 Teaching and Learning:
A Blueprint of Virtual-Physical Blended Classrooms
in the Metaverse Era

Yuyang Wang∗
Hong Kong University of Science and Technology (Guangzhou)
Hong Kong University of Science and Technology

Lik-Hang Lee†
Korea Advanced Institute of Science and Technology

Tristan Braud‡
Hong Kong University of Science and Technology

Pan Hui§
Hong Kong University of Science and Technology (Guangzhou)
Hong Kong University of Science and Technology

Abstract—During the COVID-19 pandemic, most countries
have experienced some form of remote education through video
conferencing software platforms. However, these software plat-
forms fail to reduce immersion and replicate the classroom
experience. The currently emerging Metaverse addresses many
of such limitations by offering blended physical-digital environ-
ments. This paper aims to assess how the Metaverse can support
and improve e-learning. We ﬁrst survey the latest applications
of blended environments in education and highlight the primary
challenges and opportunities. Accordingly, we derive our pro-
posal for a virtual-physical blended classroom conﬁguration that
brings students and teachers into a shared educational Metaverse.
We focus on the system architecture of the Metaverse classroom
to achieve real-time synchronization of a large number of par-
ticipants and activities across physical (mixed reality classrooms)
and virtual (remote VR platform) learning spaces. Our proposal
attempts to transform the traditional physical classroom into
virtual-physical cyberspace as a new social network of learners
and educators connected at an unprecedented scale.

Index Terms—Human-computer interaction, VR/AR, Distance

learning, Metaverse, E-learning

I. INTRODUCTION

Under the complex and changing global political and
economic situation and the global pandemic, individual ac-
tivities and production methods face increasing challenges.
For example, lectures have moved to online via Zoom or MS
Teams to maintain social distancing. However, the current
online educational content is mainly based on ﬂat 2D display,
which lacks immersion and engagement compared to tradi-
tional teaching in a physical classroom. Students feel hardly
focused on the remote lecture. In this situation, the Metaverse
appears as a meaningful solution by integrating state-of-the-art
technologies such as virtual reality (VR) and augmented reality
(AR), artiﬁcial intelligence and cloud computing [1] to make
educational activities to more attractive.

∗e-mail:yuyangwang@ust.hk
†e-mail:likhang.lee@kaist.ac.kr
‡e-mail:braudt@ust.hk
§e-mail:panhui@ust.hk

Motivations. The next generation of education, i.e., teaching
and learning, should include diversiﬁed yet customized learning
content and context, increased student interaction and creativity,
boosted motivation and engagement [2]. Unfortunately, existing
teaching facilities and tools fail to offer these features. This
work examines existing teaching and learning modalities
and proposes a novel teaching system to promote learning
experience and performance in the Metaverse era. In this
context, we ﬁrst present a mini-survey on digital education
platforms, including computer-mediated learning and teaching
via online conferencing tools and VR/AR-based teaching. We
highlight the pros and cons of these teaching modalities. For
instance, Zoom enables synchronous teaching but lacks students
engagement [3]. On the other hand, VR/AR provides more en-
gaging teaching activities thanks to 3D visualization technology
in semi-immersive or fully immersive environments. However,
it requires a high-quality and robust network for synchronizing
graphical data [4]. Therefore, we put forward a virtual-physical
blended classroom, with the ambition of migrating physical
classrooms and remote educational activities to the uniﬁed yet
immersive cyberspace, known as the Metaverse. Our proposed
Metaverse classroom contains two physical classrooms at
two university campuses and one digital classroom hosted
in the edge-cloud synchronized computing devices. The digital
classroom enables users (i.e., learners and educators) to appear
at a physical lecture from their home campus, in which the
digital twins of such users, as avatars, can interact with users
from other campuses.

Review methodology. First, we search in Google Scholar for
the terms “VR education” and “AR education”, and additional
keywords including “application” and “challenge” and ﬁnd
that related publications spread among several journals and
conferences. Second, we choose papers mainly from celebrated
publishers: ACM, IEEE, Springer, Elsevier and Taylor &
Francis. Third, we favour the paper with top citations and
from the ﬁeld of education and VR/AR. Finally, if no proper
references can be found in the former steps, we expand our
search domain in Google Scholar with other keywords such as

 
 
 
 
 
 
“VR/AR applications” and ﬁlter by investigating the relevance to
the educational ﬁeld. This mini-survey illustrates the paradigm
shift in teaching and learning in the post-COVID-19 period.
The classroom moves from computer-mediated learning or
VR/AR-based applications to a fully virtual-physical blended
one.

Contributions. This paper’s contributions are twofold, as
follows. First, we review the latest development of remote learn-
ing and interactive medium like VR/AR. Second, we propose
the Metaverse classroom containing two physical classrooms
and one cloud-based virtual classroom, and the architecture
about how to implement the system. We accordingly pinpoint
the grand challenges of establishing the proposed Metaverse
classroom.

II. RECENT EDUCATION LANDSCAPE

The recent development of VR/AR provides evidence that
immersive elements are no longer a myth in learning context [5].
We highlight some important works related to computer-
mediated education and relevant studies of VR/AR, as presented
in Figure 1.

teaching tools has posed a threat

Computer-mediated Education. Since the outbreak of
COVID-19, the lack of high-quality learning materials and
to traditional
efﬁcient
classroom-based education. Learning remotely through a video
conferencing system has provided an opportunity to maintain
lecturing and communicating activities. However, the human-
computer interaction (HCI) community also identiﬁed some
challenges arising from remote teaching [3]. For instance,
students may ﬁnd it challenging to pay continuous attention be-
cause of multitasking and unexpected interruption. They tend to
experience decreased learning efﬁcacy as live streaming learn-
ing costs a longer time and reduced engagement/collaboration
because the learning environment changes from a community-
based public area supported by various university facilities to
a private space with limited resources. Researchers proposed
several solutions to mitigate the deﬁciency or weakness for both
teachers and students during the live streaming course, e.g.,
establishing the voice-based conversational agents to engage
natural interaction [13], assigning learning tasks to learners
and improving motivational beliefs [14], boosting explanation
quality and presentation skills [15].

Durham University developed a multi-touch and multi-user
desk to boost children’s mathematical skills in a collaborative
and interactive way [16]. Pupils can work together to solve prob-
lems and answer questions through some inventive solutions.
Compared to traditional paper-based activities, the multi-touch
table can improve mathematical ﬂexibility and ﬂuency and
promote higher levels of active student engagement.

VR in Education. VR integrates ﬁve essential components:
3D perspective, dynamic rendering, closed-loop interaction,
ego-referenced perspective and enhanced sensory feedback [17].
Thanks to rising computing power and the easy access to many
affordable head-mounted displays (HMDs), VR has proved to
be helpful in various applications such as surgical operations,
psychotherapy and STEM education [18].

The lack of opportunities for practical and hands-on manip-
ulation of objects in the real world is linked to the fact that
children are usually poor at intuitive physics [19]. Therefore,
Brelsford [19] designed a physics simulator to give students a
better intuition about the physical process inside an immersive
environment. One group of students was given a pendulum
in controllable length and three balls in varied mass in this
simulator. These students can manipulate gravity, mass, location
of the balls, air drag, friction, period of the pendulum, force,
motion, and starting force of the pendulum to carry out
experiments for an hour. Another control group of students
was given a lecture in the physical classroom on the same
material. An exam was assigned four weeks after the test.
The results indicated that those who had learned through the
virtual laboratory revealed better retention than those from the
lecture-based learning group.

Similarly, Yalow and Snow [20] reported that offering learn-
ers instructional material in spatial-graphical format, instead
of verbal words, will improve their immediate comprehension
of the material. Therefore, many studies have investigated
the beneﬁts of learning in virtual environments. Rega and
Fink [21] performed a pioneer study that designed a novel
approach to pandemic preparedness and response based on
immersive simulation. The authors developed a semester-
long course in simulated environments for students in Master
of Public Health (MPH). Students are grouped to represent
different country health departments during the whole semester,
and they can gain incident command training and acquire
audio lectures and learning materials related to the imminent
pandemic. Despite learning in virtual environments, students
still considered this training paradigm more groundbreaking,
fascinating and educative. Such work provides us with another
solution to combat the current COVID-19 global pandemic [22].
In addition, VR has made signiﬁcant contributions to other
educational cases, e.g., controlling the real chemistry lab
by interacting with a virtual lab [10] and teaching physical
geography through spherical video-based VR immersion [11].
VR can be promising for education and training, but
challenges still exist [23]. First, VR is generally regarded
as a game for entertainment and relaxation. Learners pay more
attention to winning in the game, but they are not fully engaged
to acquire knowledge and improve critical thinking skills,
far from the teaching objective. Second, VR is not perfect
from a psychological point of view. For example, the older
lectures may prefer the classical teaching approach instead of
the digital one compared to younger students. Longstanding
immersion in locomotion-dominated VR applications will cause
discomfort and sickness symptoms (e.g., nausea, dizziness and
disorientation) individually among users, which will weaken
users’ willingness for using VR devices [24]. Third,
the
educational institution will share the high cost of design and
creating the VR resources towards different teaching objectives,
and the library department lacks interoperability standards or
optimal practices for adopting these VR contents, leading to
difﬁculties to share resources among different institutions and
pointless duplicated work [25].

Fig. 1: Examples of different digital teaching and learning approaches through computer-aided tools and VR/AR technologies.
(a) Star trek room to boost children’s mathematical abilities with on one desktop [6]; (b) Teaching via online conferencing
tools [3]; (c) Providing additional information during sport training [7]; (d) Collaborative learning via ARQuest [8]; (e) Digital
content representation of teaching material [9]; (f) Controlling the real lab inside the VR [10]; (g) Teaching physical geography
with video-based VR [11]; (h) Construction of a virtual campus at CUHK SZ [12].

AR in Education. AR is a 3D technology that boosts the
user’s perception of the physical work by adding a contextual
layer of information [26], and it has become a favoured topic
in educational research in the last decade [27]. The popularity
of AR technology is because it does not require expensive
hardware and complicated equipment such as HMDs. AR can
be achieved with low-cost handheld devices such as mobile
phones and tablets, enabling AR-based educational settings
to be available for most learners. Among many learner types,
K-12 students (primary and secondary students) are the most
preferred learners because the outstanding visualization features
of AR hold the key to students whose learning performance
relies mainly on seeing, hearing or other ways to sense at this
age [28].

There are many examples of the successful applications
of AR in education. Gardeli and Vosinakis [8] designed the
ARQuest application through a collaborative mobile AR game
for improving problem-solving and computational skills of
primary school students through a gamiﬁed activity, which
demonstrates the application of AR system in classroom-based
interventions. ARQuest supports multi-user interaction, and
students can collaborate with high engagement and motivation
to solve challenging problems, despite the small screen size.
This work can be regarded as a 3D version of the above-
mentioned 2D Star trek classroom [16]. The AR application
can beneﬁt learners in sports education and training to learn
sports skills, provide additional hints and feedback, stimulate
practice, and introduce new rules for creating new sports [7].
However, a broad application of AR in education is still
facing some challenges. The most blamed challenge is usability
because most AR educational settings are difﬁcult for students
to use [28]. For example, students might ﬁnd it challenging to
use the AR application and perform interactive activities with-
out well-designed interfaces, leading to worse effectiveness [29].
In addition, previous work revealed that the group of learners
with AR devices required signiﬁcantly longer training time
compared with those without using AR equipment, which might

be due to the novelty of the AR technology and users were not
familiar with the learning approach [30]. Another issue is that
the AR learning environment may increase learners’ cognitive
workload because of the excessive materials and complicated
tasks [31]. Some technical issues can also weaken learners’
expectations of AR technology. For example, location-based
AR applications rely heavily on the GPS signal to determine
the position and orientation, while low sensitivity in trigger
recognition frequently appears as an issue [31].

III. A VISION OF METAVERSE CLASSROOMS

Traditional teaching activities depend on verbal and nonver-
bal interactions between teachers and students to formulate
and enrich cultural norms, behaviors, practices, and beliefs,
but meeting on an online platform interrupts such a process
and changes individuals‘ communication habits [32]. On the
other hand, current VR/AR education allows 3D visualization
but fails to provide remote access. Therefore, we expect to
overcome the defects of current education methods and there-
fore propose the virtual-physical blended Metaverse classroom,
which can boost student engagement via more sense of presence,
improve learning efﬁciency via 3D visualization, and create
supportive connection tools via immersive interaction during
and after class meetings. The Metavese classroom room can
take advantage of the online and VR/AR education, therefore
avoiding some disadvantages of each.

Greenan [32] argued that social presence and self-disclosure
are two crucial aspects of virtual education. Garrison et al. [33]
explained the social presence as socio-emotional support and
interaction and the individual’s ability to project themselves
socially and emotionally with their entire personality through
a communication tool, which will be impacted by conversions,
activities, collaboration, familiarity and motivation among
participants. On the other hand, during virtual education,
self-disclosure could lower the feeling of unreliability and
ambiguity during communication and promote intimacy and
positive relationships [32], which reduce the mental distance

(c)(a)(b)(d)(e)(f)(g)(h)between individuals and increase trust between teachers and
students [34]. Thus, with the increasing popularity of AR
and VR education applications (section II), establishing the
Metaverse classroom can promote the aforementioned beneﬁts
at scale.

A. Towards the Metaverse classroom

Due to the global pandemic, it is limited for teachers and
students access to classrooms and laboratories. Online confer-
encing tools enable continuity of education, making lectures
and tutorials available virtually to anyone. Coincidentally, the
pandemic shed light on the feasibility of e-learning in long
duration and hence the user acceptability to the e-learning
at scale. However, engagement is an essential component
of education, and passive learning via video conferencing
fails to reinforce the engagement among class participants.
One way to tackle this challenge, highlighted during the
COVID-19 pandemic, is to introduce interactive and real-time
elements to educators and learners. The advanced development
of VR/AR is characterized by immersive visual stimuli and
real-time tracking. Also, the related hardware and multimedia
technologies can support
the Metaverse as an affordable
learning platform for learners and educators on the globe.
With such an unprecedented opportunity, we can employ the
Metaverse as a new social platform for both learners and
educators, as nowadays VR/AR devices are getting mature,
which serve as an efﬁcient tool for teaching and learning.

We propose an educational platform that supports the
teaching and learning experience with the Metaverse, with the
following features: (i) learning assessment in the Metaverse for
the courses, (ii) interaction with presentations in the Metaverse,
and (iii) teaching experience with augmentation that beneﬁts
from visualizing knowledge and from 3D virtual entities.
The platform aims to bring more engaging and interactive
tutorials and mixed learning. Remarkably, the virtual-physical
blended classroom in the Metaverse makes the educators and
learners situated in intuitive yet user-context (to both learners
and educators) environments. Thus, the Metaverse classroom
provides effective communication media among participants
from various campuses. At the same time, the changeover
in such a virtual-physical environment brings new values
to the class participants, in terms of learning effectiveness,
senses of (virtual) presences, interactive learning experience,
etc. Although such a Metaverse classroom can connect to
numerous possible usage scenarios, we speciﬁcally highlight
several class participants’ interactions, as follows.

Gamiﬁed Learning and Task-based Modules. Promoting
gamiﬁcation is obvious, which facilitates active class dynamics
by designing digital “breakouts" for teams of students or letting
students collaborate to create their own.

Learner Collaborations. Challenging students to work in
teams to solve a riddle or puzzle or bring the surreal scenes, i.e.,
augmented and virtual realities, to the classroom. Additionally,
incorporating a 360-degree video scene.

Learner-driven Activities. Empowering students to create
“choose your own adventure"-style stories or presentations to

share their contents (learning outcomes, opinions, a speech,
etc.) with the Metaverse community.

Saving Instructors’ Time. With unlimited possibilities for
creating experiences and new features being added continuously,
instructors would become more willing to spend their time
on designing new curricula, creating diversiﬁed and even
personalized activities for the sake of improving their students’
skills and knowledge.

Access to Limited/restricted Equipment. As people can
access the Metaverse classroom anytime and anywhere, the
virtual-physical presence of class participants could achieve
ubiquitous learning yet real-time access to the lab resource
(e.g., a virtual
twin) as well as other
limited/restricted resources (e.g., testing Uranium in the Meta-
verse).

lab as the digital

Fig. 2: The MR Metaverse classroom allows students, instruc-
tors, and speakers located physically in HKUST GZ campus,
HKUST CWB campus, or online to interact within the same
activity (lecture, tutorial, seminar). Through MR, the virtual
classroom enables users to attend a physical lecture on their
home campus, while users from other campus and online users
are represented through avatars.

We consider the Metaverse classroom consists of both
physical and virtual classrooms. As shown in Figure 2, learners
and instructors are situated in classrooms spreading over
multiple campuses, while the virtual classroom bridge the
physical class participants together. The physical participants
of one location can meet the virtual participants and the physical
participants of other locations. We outline the above concept
with a unit case. The participants are situated in two physical

classrooms and one virtual classroom spreading over two
campuses (Hong Kong Clear Water Bay, CWB and Guangzhou,
GZ) in the following paragraphs. These three classrooms are
synchronized so that the intervention of a participant in any
of these classrooms will be visible to the attendants in the
other two classrooms through his or her avatar representation
(i.e., the digital twins of class participants). It is important to
note that the number of physical classrooms is expandable, i.e.,
more than two physical classrooms can access the Metaverse
classroom.

Physical Metaverse Classroom in HKUST GZ and CWB
Campuses. These two classrooms are linked together through
a mixed reality (MR) Metaverse platform that enables classes
to be shared between the two campuses. Each classroom is
equipped with a set of sensors to track the participants and
replicate their presence through digital avatars on another
campus’ classroom(s). These digital avatars are displayed in
MR through projectors or headsets. As such, it is possible to
seamlessly conduct a wide range of activities, ranging from
talks and lectures to group projects involving students and staff
from both campuses.

Digital Metaverse Classroom Online in VR. A signiﬁcant
portion of class attendants can access the learning context
remotely, i.e., without any physical presence, which is similar
to nowadays situation of remote learning via Zoom. Nonethe-
less, the remote participants can virtually meet the physical
participants from HKUST GZ and CWB campuses. These
users perhaps are either HKUST students who cannot attend
the physical lecture due to unexpected circumstances (sickness,
travel restriction, etc.) or learners outside of HKUST who
audit the course. These users can connect to a third, fully
virtual classroom through a VR headset or their computers.
The HKUST students’ presence can be represented through
digital avatars displayed in both MR classrooms, while guest
avatars enable outside users to participate in the class (e.g.,
guest speakers). For instance, students from KAIST, represented
by avatars, can meet HKUST students in the Metaverse Digital
Classroom, as well as other remote class participants from MIT
and Cambridge (the lower half in Figure 2).

B. Architecture of the Metaverse classroom

Following the unit case in previous paragraphs, Figure 3
depicts the system architecture for replicating physical partici-
pants situated in the physical classroom (Classrooms 1 and 2),
who can interact with remote participants in virtual cyberspace.
The participants in the physical classroom 1 wear MR headsets
that can track their locations and other features, such as facial
expressions. Meanwhile, the physical classroom is equipped
with non-intrusive sensors that can estimate the exact pose of
the participants. The data from the headsets and the classroom
sensors are transmitted through WiFi (headset) or wired network
(sensors) to the edge server that aggregates the data to estimate
the pose and facial expression of the participants.

The server then generates the avatar and their interaction
traces accordingly, and packages them via the real-time
transmission link to both the edge server of Classroom 2

Fig. 3: General system architecture to handle synchronization
between two MR Metaverse classrooms and a VR Metaverse
classroom.

and the cloud server of the VR classroom. The edge server
in Classroom 2 identiﬁes the vacant seats to display virtual
avatars in the MR classroom. Upon the reception of the digital
information, it corrects the pose to match the new position
of the avatar and generates the scene to display to the users
through the lens of their MR headsets. Similarly, the cloud
server arranges the avatars of all users within an entirely virtual
VR classroom and transmits the results back to the remote
users. Both classrooms can rely on their own independent WiFi
infrastructure to accelerate the data transmission between the
headsets and the edge servers and minimize the end-to-end
latency for replicating the participants’ poses and expressions
as digital avatars on the other Metaverse classrooms, whether
MR or VR.

C. Challenges for developing the Metaverse classroom

The Metaverse classroom will be a more student-centered,
collaborative and innovative platform for educational activities.
Despite being a promising teaching platform, the proposed
architecture must be meticulously investigated and designed
to minimize some side effects and maximize its potential.
Some challenges need addressing during the implementation for
keeping the learning engagement and efﬁciency, and creating
teaching aids inside the Metaverse classroom. The overcome
of these troubles will also help us solve issues (e.g., usability,
cybersickness, and high cost) inherited from VR/AR technology
because most problems arise from interaction and content
design, systems and networking stability.

User Interactivity and Perception. Learners and educators
are the key actors in the Metaverse classroom. Maintaining
the bandwidth of user interactivity, regardless of output and
inputs, is crucial to user retention. Nonetheless, ﬁrst, the
user inputs on mobile MR and VR headsets are far from
satisfaction, resulting in low throughput rates in general [35],
which could hinder the users’ expression, i.e., converting
one’s intentions into resultant outcomes in virtual-physical
blended environments. Additionally, current input methods of
headsets are primarily speech recognition and simple hand
gestures [36]. As a result, users can only deal with enriched

educational contents/contexts at a degraded quality. On the
other hand, the output channels, known as feedback cues, are
limited, albeit the headsets can sufﬁciently provide visuals
of digital entities. However, such displays’ limited Field-of-
View (FOV) potentially deteriorates communication efﬁcacy
among users in the Metaverse classroom [37]. Speciﬁcally,
partial view of body gestures, heavily relying on constant
visual attention, due to limited FOV, can lead to distorted
communication outcomes. Thus, multi-modal feedback cues
(e.g., haptics) become necessary to maintain the granularity of
user communication. Additionally, haptic feedback is essential
to delivering high levels of presence and realism, but current
networking constraints create delayed feedback and damage
user experiences [38]. More importantly, presence and realism
can inﬂuence the sense of “being together” in the Metaverse
classroom.

Navigation and Cybersickness. Navigation is the most
fundamental interaction and is the primary task when users
move inside the 3D virtual environment. For example, students
need to move from one position to another and adapt their
viewpoint
in the virtual classroom to communicate with
their learning peers. In physical environments, humans can
navigate easily and gain consistent multisensory feedback from
through from visual, proprioceptive and vestibular systems.
In contrast, in immersive virtual environments, they cannot
walk naturally due to the limitation of Metaverse devices
and small workspace. They have to be constrained into a
limited physical space, implying impossible matches between
actual and virtual walking, and thus leading to unnatural
sensory feedback. According to the sensory conﬂict theory [39],
the mismatched visual and vestibular information will lead
users to experience cybersickness with symptoms, such as
fatigue, headache, nausea, disorientation, etc. As there exists a
signiﬁcant correlation between the sickness level and user
discomfort [40], failure in mitigating cybersickness would
threaten the success and acceptance of the Metaverse classroom.
Several technical settings are responsible for the occurrence
of cybersickness, such as latency, FOV,
low frame rates,
inappropriate adjustment of navigation parameters [41]. As
the user susceptibility to cybersickness is individually different,
the Metaverse classroom would consider to ease the severity of
cybersickness by involving individual factors such as gender,
gaming experience, age, ethnic origin, etc [42].

Systems and Networking. Developing such a classroom
raises signiﬁcant challenges in synchronization. The MR
environment requires transmitting large amounts of data to
ﬁnely synchronize the users’ actions. Although these data
account for less trafﬁc than live video streaming, users’ actions
need to be synchronized in real-time to enable seamless
interaction. As such, latency is a primary challenge. In highly
interactive applications, users start to notice latency above
100 ms. Besides, a latency below 100 ms still affects user
performance despite less noticeable [43]. Latency will therefore
be a primary concern in such a classroom. Another major
challenge lies in sharing the real-time course with thousands
of remote users scattered worldwide. Although some works

strive to address massively multi-users systems [44], they
do not address the stringent latency that may happen when
users located either far away, or on a poorly interconnected
network ( due to peering agreements or ﬁrewalls) present a
round-trip latency in the order of the hundreds of milliseconds.
Most gaming platforms solve this issue by setting up regional
servers. Another major concern is the ﬁne rendering of the
digital avatars of physical participants. Owing to the pervasive
sensing capabilities of the physical MR classroom, it will
be possible to rebuild highly accurate representations of the
physical participants as sophisticated avatars. However, these
avatars may be too complex to render with WebGL and
lightweight VR headsets. As such, it may be necessary to
leverage servers (cloud and edge) to pre-render some elements
of the digital scene. One solution would be to render a low-
quality version of the models on-device and merge the rendered
frame with high-quality frames rendered in the cloud [45].
Finally, many courses may rely on video transmission, whether
of the instructor, digital artefacts (e.g., slides), or physical
objects in the classroom (e.g., whiteboard). These video frames
need to be transmitted in real-time to match both the avatars’
actions and the related audio transmission. Maximizing video
quality while minimizing latency to an imperceptible level
has been a challenge in the cloud gaming community, and
leveraging joint source coding and forward error correction at
the application level are promising solutions [46].

Content Democratization and Privacy. The Metaverse
encourages participants to contribute content in the virtual-
physical blended cyberspace [47]. Furthermore, regardless
of learners and educators, class participants in the proposed
classroom are expected to contribute learning content in various
educational contexts. NFTs and well-design economics models
are the keys to the sustainability of user contributions that
expect credits and rewards. Finally, as the newly created
content will remain in the classroom cyberspace, we have
to consider the appropriateness of content overlays under the
privacy-preserving perspective [48]. Improper augmentation of
contents in the Metaverse can pose privacy threats and perhaps
risks of copyright infringement.

IV. CONCLUSION

The pandemic catalyzes the emergence of immersive environ-
ments that potentially impact how we work, play, and even learn
and teach. We foresee that the Metaverse classroom will bring
more learner-centric, collaborative, and innovative elements to
the future classroom. Our work serves as a groundwork for
the digital transformation of learning and teaching, from sole
digital medium to virtual-physical blended one. Despite the
Metaverse classroom being a promising learning platform for
students, extra efforts are required to meticulously investigate
system performance and user-centric evaluation and collect
valuable feedback from actual trials, i.e., teaching activities.
Therefore, we call for joint research efforts to actualize the
Metaverse classroom, and particularly, we have to address
several challenging aspects including user-centric, system and
networking issues.

REFERENCES

[1] L.-H. Lee, T. Braud et al., “All one needs to know about metaverse:
A complete survey on technological singularity, virtual ecosystem, and
research agenda,” arXiv:2110.05352, 2021.

[2] “The expanding role of immersive media in education,” Proc. of the 14th
IADIS Inter. Conf. e-Learning 2020, EL 2020 - Part of the 14th Multi
Conf. on MCCSIS 2020, pp. 191–194, 2020.

[3] Z. Chen et al., “Learning from home: A mixed-methods analysis of live
streaming based remote education experience in chinese colleges during
the covid-19 pandemic,” in Proc. of the 2021 CHI Conf. on Human
Factors in Comp. Sys., ser. CHI ’21. NY, USA: ACM, 2021.

[4] Y. Zhang et al., “Virtual reality applications for the built environment:
Research trends and opportunities,” Automation in Construction, vol.
118, p. 103311, 2020.

[5] N. Elmqaddem, “Augmented Reality and Virtual Reality in Education.
Myth or Reality?” International J. of Emerging Technologies in Learning
(iJET), vol. 14, no. 03, p. 234, feb 2019.

[6] “Star

trek
desks,”

classroom:
Durham

school
News,
https://www.dur.ac.uk/news/newsitem/?itemno=15991.

University

Nov

the

next

generation

of
2012,

[7] P. Soltani and A. H. Morice, “Augmented reality tools for sports education
and training,” Computers & Education, vol. 155, p. 103923, 2020.
[8] A. Gardeli and S. Vosinakis, “ARQuest: A tangible augmented reality
approach to developing computational thinking skills,” 2019 11th Inter.
Conf. on Virtual Worlds and Games for Serious Applications, VS-Games
2019 - Proc., p. 1DUUMY, 2019.

[9] Y. M. Tang, K. M. Au, H. C. Lau, G. T. Ho, and C. H. Wu, “Evaluating
the effectiveness of learning design with mixed reality (MR) in higher
education,” Virtual Reality, vol. 24, no. 4, pp. 797–807, 2020.

[10] Y. Lu, Y. Xu, and X. Zhu, “Designing and Implementing V R2E2C, a
Virtual Reality Remote Education for Experimental Chemistry System,”
Journal of Chemical Education, vol. 98, no. 8, pp. 2720–2725, aug 2021.
[11] M. S. Y. Jong, C. C. Tsai, H. Xie, and F. Kwan-Kit Wong, “Integrating
interactive learner-immersed video-based virtual reality into learning
and teaching of physical geography,” British Journal of Educational
Technology, 2020.

[12] H. Duan, J. Li, S. Fan, Z. Lin, X. Wu, and W. Cai, “Metaverse for Social
Good: A University Campus Prototype,” in Proceedings of the 29th ACM
International Conference on Multimedia. New York, NY, USA: ACM,
oct 2021, pp. 153–161.

[13] R. Winkler et al., Sara, the Lecturer: Improving Learning in Online
Education with a Scaffolding-Based Conversational Agent. NY, USA:
ACM, 2020, p. 1–14.

[14] S. Zhang and Q. Liu, “Investigating the relationships among teachers’ mo-
tivational beliefs, motivational regulation, and their learning engagement
in online professional learning communities,” Computers & Education,
vol. 134, pp. 145–155, 2019.

[15] A. Shoufan, “What motivates university students to like or dislike
an educational online video? a sentimental framework,” Computers &
education, vol. 134, pp. 132–144, 2019.

[16] S. Higgins et al., “Multi-touch tables and collaborative learning,” British
J. of Educational Technology, vol. 43, no. 6, pp. 1041–1054, 2012.
[17] C. D. Wickens, “Virtual reality and education,” IEEE International

Conference on Systems, Man and Cybernetics, 1992.

[18] C. P. Fabris et al., “Virtual reality in higher education,” Inter. J. of
Innovation in Science and Mathematics Education, vol. 27, no. 8, pp.
69–80, 2019.

[19] J. W. Brelsford, “Physics Education in a Virtual Environment,” Proc. of
the Human Factors and Ergonomics Society Annual Meeting, vol. 37,
no. 18, pp. 1286–1290, oct 1993.

[20] E. Yalow and R. E. Snow, “Individual differences in learning from verbal
and ﬁgural materials.” Stanford Univ Calif School of Education, Tech.
Rep., 1980.

[21] P. P. Rega and B. N. Fink, “Immersive simulation education: a novel
approach to pandemic preparedness and response,” Public Health Nursing,
vol. 31, no. 2, pp. 167–174, 2014.

[22] M. Lieux et al., “Online conferencing software in radiology: Recent
trends and utility,” Clinical Imaging, vol. 76, pp. 116–122, 2021.
[23] D. Velev and P. Zlateva, “Virtual Reality Challenges in Education and
Training,” International J. of Learning, vol. 3, no. 1, pp. 33–37, 2017.
[24] Y. Wang et al., “Development of a speed protector to optimize user
experience in 3D virtual environments,” Inter. J. of Human-Computer
Studies, vol. 147, p. 102578, dec 2021.

[25] M. Cook et al., “Challenges and strategies for educational virtual reality:
Results of an expert-led forum on 3D/VR technologies across academic
institutions,” Information Technology and Libraries, vol. 38, no. 4, pp.
25–48, 2019.

[26] R. T. Azuma, “A survey of augmented reality,” Presence: teleoperators

& virtual environments, vol. 6, no. 4, pp. 355–385, 1997.

[27] M.-B. Ibáñez and C. Delgado-Kloos, “Augmented reality for STEM
learning: A systematic review,” Computers & Education, vol. 123, pp.
109–123, aug 2018.

[28] M. Akçayır and G. Akçayır, “Advantages and challenges associated with
augmented reality for education: A systematic review of the literature,”
Educational Research Review, vol. 20, pp. 1–11, 2017.

[29] J. A. Munoz-Cristobal et al., “Supporting teacher orchestration in
ubiquitous learning environments: A study in primary education,” IEEE
Trans. on Learning Technologies, vol. 8, no. 1, pp. 83–97, 2014.
[30] N. Gavish et al., “Evaluating virtual reality and augmented reality training
for industrial maintenance and assembly tasks,” Interactive Learning
Environments, vol. 23, no. 6, pp. 778–798, 2015.

[31] K.-H. Cheng and C.-C. Tsai, “Affordances of augmented reality in science
learning: Suggestions for future research,” J. of science education and
technology, vol. 22, no. 4, pp. 449–462, 2013.

[32] K. A. Greenan, “The Inﬂuence of Virtual Education on Classroom
Culture,” Frontiers in Communication, vol. 6, no. March, pp. 10–13, mar
2021.

[33] D. R. Garrison, T. Anderson, and W. Archer, “Critical inquiry in a text-
based environment: Computer conferencing in higher education,” The
internet and higher education, vol. 2, no. 2-3, pp. 87–105, 1999.
[34] H. Song, J. Kim, and N. Park, “I know my professor: Teacher self-
disclosure in online education and a mediating role of social presence,”
Inter. J. of Human–Computer Interaction, vol. 35, no. 6, pp. 448–455,
2019.

[35] L.-H. Lee et al., “Towards augmented reality driven human-city interac-
tion: Current research on mobile headsets and future challenges,” ACM
Computing Surveys (CSUR), vol. 54, pp. 1 – 38, 2022.

[36] ——, “Ubipoint: towards non-intrusive mid-air interaction for hardware
constrained smart glasses,” Proc. of the 11th ACM Multimedia Sys. Conf.,
2020.

[37] ——, “From seen to unseen: Designing keyboard-less interfaces for text
entry on the constrained screen real estate of augmented reality headsets,”
Pervasive Mob. Comput., vol. 64, p. 101148, 2020.

[38] C. Bermejo et al., “Exploring button designs for mid-air interaction
in virtual reality: A hexa-metric evaluation of key representations and
multi-modal cues,” Proc. of the ACM on Human-Computer Interaction,
vol. 5, pp. 1 – 26, 2021.

[39] C. M. Oman, “Motion sickness: a synthesis and evaluation of the sensory
conﬂict theory,” Canadian J. of physiology and pharmacology, vol. 68,
no. 2, pp. 294–303, 1990.

[40] A. Somrak et al., “Estimating vr sickness and user experience using
different hmd technologies: An evaluation study,” Future Generation
Comp. Sys., vol. 94, pp. 302–316, 2019.

[41] J.-R. Chardonnet, M. A. Mirzaei, and F. Merienne, “Inﬂuence of
navigation parameters on cybersickness in virtual reality,” Virtual Reality,
vol. 25, no. 3, pp. 565–574, 2021.

[42] Y. Wang et al., “Using Fuzzy Logic to Involve Individual Differences
for Predicting Cybersickness during VR Navigation,” in 2021 IEEE VR.
Lisbon, Portugal: IEEE, mar 2021, pp. 373–381.

[43] M. Claypool and K. Claypool, “Latency and player actions in online

games,” Commun. ACM, 2006.

[44] J. Donkervliet, A. Trivedi, and A. Iosup, “Towards supporting millions of
users in modiﬁable virtual environments by redesigning {Minecraft-Like}
games as serverless systems,” in 12th USENIX Workshop on Hot Topics
in Cloud Computing (HotCloud 20), 2020.

[45] K. Lee et al., “Outatime: Using speculation to enable low-latency
continuous interaction for mobile cloud gaming,” in Proceedings of the
13th Annual International Conference on Mobile Systems, Applications,
and Services, 2015.

[46] A. Alhilal et al., “Nebula: Reliable low-latency video transmission for

mobile cloud gaming,” arXiv:2201.07738, 2022.

[47] L.-H. Lee et al., “When creators meet the metaverse: A survey on

computational arts,” ArXiv, vol. abs/2111.13486, 2021.

[48] A. Kumar et al., “Theophany: Multimodal speech augmentation in
instantaneous privacy channels,” Proc. of the 29th ACM Inter. Conf.
on Multimedia, 2021.

