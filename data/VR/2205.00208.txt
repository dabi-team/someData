JOURNAL OF

1

Security and Privacy in Virtual Reality -
A Literature Survey

Alberto Giaretta

2
2
0
2

y
a
M
0
2

]

R
C
.
s
c
[

2
v
8
0
2
0
0
.
5
0
2
2
:
v
i
X
r
a

Abstract—Virtual Reality (VR) is a multibillionaire market
that keeps growing, year after year. As VR is becoming prevalent
in households and small businesses,
it is critical to address
the effects that this technology might have on the privacy and
security of its users. In this paper, we explore the state-of-the-
art in VR privacy and security, we categorise potential issues
and threats, and we analyse causes and effects of the identiﬁed
threats. Besides, we focus on the research previously conducted
in the ﬁeld of authentication in VR, as it stands as the most
investigated area in the topic. We also provide an overview of
other interesting uses of VR in the ﬁeld of cybersecurity, such
as the use of VR to teach cybersecurity or evaluate the usability
of security solutions.

Index Terms—Virtual Reality, VR, privacy, security, cyberse-

curity, authentication

I. INTRODUCTION

that enables realistic physical

E Xtended Reality (XR) is a paradigm that refers to dif-

ferent types of human-machine interaction within real
and virtual environments, enabled by computer technology
and wearable devices. Under the umbrella of XR, Virtual
Reality (VR) is a computer-generated simulation of a 3D
environment
interactions by
means of technology and wearable devices. The popularity of
VR has grown steadily over the years; according to Oberlo [1],
the number of US consumers that used VR went from 16%
in 2019 to 19% in 2020. Of those users, shows a report
from eMarketer [2], 52.1 million people use VR technology
at least once per month. Furthermore, the growth is expected
to continue in the near future. By 2028, the compound annual
growth rate of the VR market is expected to reach 18% [3],
according to statistics by Grand View Research. In terms of
market value, Valuates Reports [4] projects that the global VR
market size will reach US$ 26860 million by 2027, from US$
7719.6 million in 2020.

By design, VR is capable of collecting a large amount of
non-verbal information, such as users’ movements, biometrics,
and usage patterns. As shown in Figure 1, VR devices are
equipped with different sensors that collect both explicit
input and non-verbal information, which is used by the VR
engine to model the virtual world according to the user’s
actions. As noted by Bailenson [5], non-verbal information
is uniquely telling and can be used for different goals, from
tailoring advertisements, to determining if users are low or
high performers. Hours of personal use, paired with unclear
policies regarding data handling and learning algorithms, could

A. Giaretta is with the Department of Science and Technology, Centre
for Applied Autonomous Sensor Systems, ¨Orebro University, ¨Orebro 70281,
Sweden e-mail: alberto.giaretta@oru.se

Manuscript received April 29, 2022; revised April 29, 2022.

allow companies to estimate users’ preferences and infer their
characteristic behaviour. Taking into account the consistent and
considerable growth of VR, alongside its pervasive nature, it is
of paramount importance to evaluate any privacy and security
concern that could arise. In this paper, we provide a literature
survey on VR threats and issues, in terms of privacy and
security, with the aim of highlighting what has been done and
what is still open for research.

Within the umbrella term XR, besides VR, exist other types
of extended reality. Namely, Augmented Reality (AR) and
Mixed Reality (MR). In AR, virtual objects are added to the
real environment for enriching it;a notable example is pointing
a smartphone to an art piece and getting information about the
piece itself. MR is a combination of VR and AR, where the
interactions do not happen exclusively in the virtual space nor
in the real one, but in a hybrid fashion. AR and MR exhibit
their own set of challenges and issues, in terms of security
and privacy, which are not necessarily similar to those found
in VR. In 2014, Roesner et al. [6] conducted a survey on AR
security and privacy concerns, while King et al.[7] focused
speciﬁcally on the privacy issues of AR applications. Regard-
ing MR, De Guzman et al. [8] conducted an exhaustive survey
on the security and privacy issues that affect it. However, to
our knowledge, a comprehensive survey on the security and
privacy aspects of VR is lacking. In this paper, we aim to ﬁll
this gap, providing four main contributions:

• An overview of privacy issues that affect VR, organised

by typology and causes;

• An analysis of threats to VR security, categorised in
traditional attacks that also affect VR, such as denial
of service (DoS), and attacks speciﬁc for VR, such as
dizziness inducing ones;

• An in-depth exploration on the research done on authen-

tication aspects in VR;

• An overview of other uses of VR in the ﬁeld of cybersecu-
rity and physical security, such as teaching cybersecurity
concepts or evaluating the usability of security solutions.

A. Outline

This paper is organised as follows. In Section II, we discuss
issues and threats to privacy within the VR domain. Similarly,
in Section III we discuss the threats to the security of VR
and we dedicate Section IV to the topic of authentication for
VR. In Section V we discuss different uses of VR within
the cybersecurity domain, such as teaching security concepts,
training physical security, and evaluating the usability of
security processes. Finally, in Section VI we provide some
ﬁnal remarks and provide our conclusions.

 
 
 
 
 
 
JOURNAL OF

2

Fig. 1. The Virtual Reality (VR) paradigm. Users perceive the VR environment using head-mounted displays (HMDs) and interact with it via controllers or
more advanced techniques, such as ﬁnger tracking sensors. Every device is equipped with various sensors to provide useful information to the VR engine,
which creates the virtual world and modiﬁes it according to the input received from the user.

II. PRIVACY ISSUES IN VR

the
VR technology raises a number of concerns about
privacy of its users. In this section, we provide an overview
threats to privacy in the context of VR,
of the different
following the structure shown in Figure 2. In 2018, Adams
et al. [9] identiﬁed to which extent users and developers are
concerned about privacy in VR. They conducted interviews
with 20 participants, 10 users and 10 developers, showing that
6 users and 6 developers raised concerns on the data collection
practises, while 7 participants out of 20 expressed general
mistrust in headset producers. The authors also highlighted
that developers show consideration for users’ privacy, but that
there is a marked disconnection between general concerns and
concerns about their own products. One of the interviewees
expressed concern for the perception capabilities of the VR
sensors and cameras. As shown by Kreylos [10], Oculus Rift
sensors are regular webcams, equipped with a ﬁrmware and a
physical ﬁlter that allow infrared light to pass, while removing
visible light. However, Kreylos showed that it is possible to
operate software manipulations and extract realistic pictures
from the Oculus camera, even though it is meant to perceive
only the infrared spectrum.

O’Brolch´ain et al. [11] discuss the privacy concerns that
derive from the combination of VR and social networks.
They divide threats to privacy and privacy issues into three
categories:

• Associational privacy, in particular the ability to include
and exclude people from certain events or the global vil-
lage, in which everyone could potentially learn important
and trivial matters about others;

• Informational privacy, in particular the increased vulner-

ability of data or its misuse;

• Physical privacy, in particular the prevalence of recording
devices or the unintended revelation of physical informa-

tion (such as physical reactions to ads and the loss of
anonymity).

Although this categorisation focuses on the threats arising
from the combination of VR and social networks, it applies
equally well to general privacy threats to VR. In addition
to privacy issues, the authors note that when privacy cannot
be ensured, the autonomy of individuals (i.e., their ability to
form independent opinions, plans, and goals) is also at stake,
because autonomy is intertwined with privacy. Human beings
need privacy to think through their problems, make mistakes,
and explore different possibilities. Without the guarantee of
privacy, users might experience a decrease in autonomy or
even lose it.

A. Threats to Associational Privacy

In 2016, Nwaneri [12] noted that Facebook has a track
record of experimenting with its users (e.g., showing that
removing negative or positive news from feeds affected their
mood). They also noted that the Oculus policies were phrased
in such a way that it would allow Facebook to conduct similar
experiments. The risk to users’ privacy would be even higher
than the ones found in social networks, given the kind of data
gathered by VR systems. In particular, Nwaneri argues that the
policy statement regarding collecting ”information about [the
users’] physical movements and dimensions when [they] use a
virtual reality headset” could facilitate discrimination and mass
surveillance. According to the author, failing to address these
points could lead companies to face serious consequences,
such as accusations of violating state privacy and wiretapping
laws. On a side note, Nwaneri highlights that the long-term
effects of immersive sensory experience granted by VR are
still unknown. VR environments might cause safety risks in
their users, such as seizures, post-traumatic stress disorder, or
interference with childhood mental development. Therefore,

VRRealityOperates UsingCreatesUserControllerHand TrackingVR EngineVirtual CatVirtual BallVirtual BoxActs OnOutputs ToCreatesCreatesOperates UsingOperates UsingHead-mounteddisplayEquippedWithEquippedWithSensorsCreatesVirtual CharacterJOURNAL OF

3

Fig. 2. Privacy issues in VR. In purple the three main categories, further speciﬁed in subcategories and speciﬁc concerns.

it is in the best interest of VR companies to push for clear
policies and legislation that regulate their business.

Tromp et al. [13] elaborated more on the issues of com-
bining social networks and VR, to produce multi-user social
VR environments. Among various psychological risks, which
fall outside the scope of our work, the authors list privacy.
Head-mounted displays (HMDs), due to the sensors they are
equipped with, record detailed user’s physical and psycholog-
ical responses to stimuli. These responses could be analyzed
automatically and used for targeting users with tailored adver-
tising, a method known as neuromarketing. In their work, they
provided some recommendations to different actors involved
with VR applications, such as users, parents, software and
hardware companies, regulatory institutions, and researchers.
For example, it is still unclear whether VR addiction exhibits
similar characteristics to internet use addiction. Therefore,
psychologists should establish if the same treatments can be
used and VR users should be aware that doctors may not yet
know how to treat such addiction.

B. Threats to Informational Privacy

Regarding the legislative issues, Lake [14] highlights that
the current US legal framework for online identity misappro-
priation does not adequately protect VR users. In particular,

the author notes that the combination of different laws leaves
plaintiffs without any party to sue: anonymity laws make it
impossible to sue the identity appropriator and ISP immunity
also prevents the victim from suing the VR provider. Until
these issues are addressed (for example, following some of
the suggestions given by Lake), victims of identity theft in VR
environments cannot even bring their claims to US courts.

Kumarapeli [15] highlights that the major players in VR
are now focused on producing realistic avatars, tracking facial
expressions and user body movement. On the one hand, this
can help to enrich communications in VR. On the other
hand, the capability of tracking such information - without
allowing users to opt out from undesired tracking - can
expose several privacy issues. For example,
if the system
tracks hints of anger during a VR-mediated collaboration and
shows that explicitly on the avatar face, the collaboration could
be negatively affected. Therefore, it is important to adopt
strategies that allow for enriching avatars’ behaviour, while
ﬁltering undesired emotions and informing the users about the
emotions currently detected.

In 2020, Miller et al. [16] wrote that a considerable number
of works on user authentication in VR assume a positive
connotation. In other words, many papers explore the iden-
tiﬁcation of users as a way for providing seamless and non-

Privacy IssuesInformationalPhysicalAssociational (Due toCombination withSocial Networks)Mass SurveillanceUnclear PoliciesDiscriminationNeuromarketingLeak of  Biometric DataLeak of PersonalReactionsEmotional ResponseProxemicsGazeBiomechanicsLegal Holes Unclear Policies onTrackingAbsence of Opting-out optionsWhat is tracked?What is private andwhat public?Health IssuesShort TermLong TermThird Parties DataTheftWhich theft isprosecuted?Shortcomings inSecurity MeasuresDegraded AutonomyJOURNAL OF

4

invasive authentication. However, the potential shown by VR
data to provide authentication implies the potential to identify
and de-anonymise users against their will. In their work, they
showed that VR motion data can be used to identify users
without requiring them to perform any speciﬁc action, contrary
to what VR authentication studies have done before. The
authors recruited 511 participants and showed them ﬁve 360-
degrees videos (randomly picked from a pool of 80 videos),
each 20s long. The participants did not have to perform any
particular task and were free to look around as they preferred.
The results of the study show that users can be identiﬁed on
the basis of their motion data with an accuracy of 87,5%,
using a simple Random Forest algorithm. The authors also
noted that the most important features included height, posture,
distance from VR content, focal length, and placement of the
hand controllers at rest. In conclusion, just collecting data
of VR interactions shows high probabilities for identiﬁcation,
even if such interactions were not designed with identiﬁcation
intentions. Therefore, one of the future challenges for VR
will be to design non-identifying interactions. For example,
manipulating positional data (e.g., altering the height) could
obfuscate some physical characteristics and help to protect
users’ privacy.

Finally, Maloney et al. [17] show that most social VR
platforms (such as AltspaceVR, RecRoom, and VRchat) do
not clearly inform users about which collected information is
private and which public. After conducting a survey among
VR users regarding their privacy-related behaviour on social
VR platforms, the authors drew some interesting conclusions.
First, users showed a similar tendency to share their expe-
riences and emotions in VR, compared to traditional social
networks. Second, social VR platforms aim to provide to
their users an immersive experience by using resembling
avatars. However, this leads to the leakage of some personal
information, such as height, race, and appearance in general.

C. Threats to Physical Privacy

Buck and Bodenheimer [18] point out that the way that
users interact with the surrounding environment can be a
critical information itself. The authors highlight that research
has neglected the relationship between users and personal
space in VR environments. In particular, personal space is
plastic and varies depending on the interaction at hand:
for example, personal space restricts when users approach
objects they enjoy and expands when the interaction is not
appreciated. This knowledge could potentially be used by
companies to gather information about personal preferences,
done by positioning an item in the environment and verifying
whether users approach it or walk away from it. In turn,
this could allow to identify and proﬁle people without their
knowledge nor consent. Moreover, the psychology literature
shows that stress increases when interactions happen within
personal space, hence personal space should be calculated and
taken into account for designing pleasant virtual interactions.
In conclusion, personal space is easy to detect and use to
infer information about VR users, and this poses the nontrivial
problem of how to collect and treat this type of data.

In general, any interaction in VR can lead to private data
leakage. Falk et al. [19] prove feasible a de-anonymization
attack on VR which correlates VR avatars to their human
users, leveraging human unique movement patterns. Named
ReAvatar, this attack uses only the movement information
provided by the VR setup, available without any peculiar
privilege or malicious code injection. In their experiments,
both the attacker and the victim join a VR game (i.e., VR-
Chat), where people are embodied as avatars and can interact
with other people’s avatars. The goal of the attacker is to
discover who is hiding behind a certain avatar by analysing
the movement patterns of the observed victim. To do so, the
attacker asks the victim to perform common and apparently
innocuous movements, such as dancing or picking up objects.
The attacker observes the victim’s avatar and extracts the
features of their movement. Then, the authors implement pose
estimation using part afﬁnity ﬁelds (PAF), detect keywise pairs
of poses, and extract the local coordinates of (x,y,z) from the
victim avatar. Finally, each joint pair is evaluated against a
threshold that determines if the avatar corresponds to any
known person. In a limited study of 6 avatars and 5 users,
ReAvatar achieved 89,60% accuracy, proving that the attack
is at least feasible.

Although beyond the scope of this review, it is worth noting
that eye-tracking technologies are increasingly integrated into
modern VR HMDs. Eye-tracking data have the potentiality
of revealing more information than intended about the users.
For example, Partala et al. [20] showed that pupil size varies
according to emotionally provocative sound stimuli. Their
experiments suggested that the size of the pupil discriminates
during and after different variations of emotional stimuli. This
means that eye-tracking technologies embedded in VR systems
might allow to extrapolate emotional
information, without
explicit knowledge or consent from the users.

D. Solutions for Strengthening Privacy in VR

Bozkir et al. [21] proposed a method to assess the cognitive
load of users during a driving simulation experience, while
preserving their privacy. To do so, they used critical and non-
critical time frames, trained multiple classiﬁers (SVM, DTs,
RFs, and kNN with k=1,5,10) and validated their proposal with
a leave-one-person-out cross-validation (LOOCV) approach.
The authors used a small number of short time frames, which
allows them to predict cognitive load in real time using min-
imal data, thus preserving users’ privacy. Their experimental
hardware setup included a HTC-Vive, a Logitech G27 Steering
Wheel and Pedals, Phillips headphones, and a Pupil-Labs
HTC-Vive binocular add-on for eye tracking.

Regarding the use of eye tracking technology, John et
al. [22], [23] note that the trend of equipping VR headsets
with eye tracking sensors puts users’ privacy in danger. Eye-
trackers collect images of the users’ iris patterns and iris scans,
often used as biometrics for a variety of services, can identify
people with high accuracy. To counteract this issue, John et
al. [22] showed that Gaussian ﬁlters can be applied to iris
images to blur iris patterns, making them unrecognisable while
preserving gaze detection capabilities. Later in 2020, John

JOURNAL OF

5

et al. [23] investigated a different approach, hardware-based.
Their idea is to attach the eye tracker to a small telescopic arm,
allowing users to manually defocus images of the iris at will.
In addition to being effective, their approach has the valuable
feature of allowing users to directly control when they want
to show their iris (e.g., if needed for authentication purposes)
or when they want to hide it.

III. THREATS TO VR SECURITY

Adams et al. [9] interviewed 20 participants, 10 users and
10 developers, investigating their perception of security in VR.
Only 2 users raised concerns about malicious applications, 4
participants in total worried about data snifﬁng, and 3 users
said that security ”is not there yet”, which suggests that not
many end-users might have cybersecurity concerns. Given
this attitude, the authors are of the opinion that many early
VR applications will exhibit different security vulnerabilities,
as cyber-security does not hold a high perceived value for
to assess which attacks
is critical
end-users. Therefore,
could be expected and mounted on VR. In this section, we
provide an overview of the different attacks that can affect
VR, categorized according to the tree shown in Figure 3. First,
we discuss VR-speciﬁc attacks that are made possible by the
very nature of VR and the involved sensors. Then, we cover
the generic security issues that can affect VR, as they affect
various information systems.

it

A. VR-Speciﬁc Security Threats

Casey et al. [24] noted that VR, due to its immersive nature,
can have a considerable impact on people; therefore, security is
of paramount importance. In their paper, the authors formulate
four VR-speciﬁc attacks, classiﬁed as Immersive attacks, as
they leverage the unique immersive characteristics delivered
by VR systems. These attacks are:

• Chaperone attacks manipulate the Virtual Environment
(VE) boundaries (i.e., tampers with the walls drawn in
the VR scene) to make the collision avoidance fail and
put users’ safety at risk;

• Disorientation attacks aim to cause dizziness and con-
fusion in VR users, causing a condition referred to as
cybersickness. Dennison et al. [25] deﬁne cybersickness
as a form of motion and simulation sickness due to
physiological factors of the users, in correlation with their
immersion and presence in VR environments;

• Human Joystick attacks aim to control the physical move-
ment of a user, such that they move to a predeﬁned spot
without realizing it;

• Overlay attack, where an attacker inserts in the VE

unwanted objects, such as images and videos.

In addition to the four Immersive attacks, Casey et al. [24]
list two additional possible attacks. The ﬁrst is the Camera
Stream and Tracking Exﬁltration attack, where the attacker
gains access to the HMD live stream and the HMD front-
facing camera stream. The second is the Man-In-The-Room
attack, which consists of an attacker joining the target’s VR
environment while remaining invisible, allowing to extract
information regarding the user or maliciously manipulate the

environment. These six attacks have different
impacts in
terms of the Conﬁdentiality, Integrity, Availability, and Safety
(CIAS) quartet, as shown in Table I.

The authors analyzed OpenVR, an SDK developed by
Valve, to identify how an attacker could perform the attacks
that
they identiﬁed. Using an HTC Vive headset and an
Oculus Rift, the authors proved that these attacks could be
carried out. They found that Chaperone, Disorientation, and
Human Joystick attacks could be struck by modifying a JSON
conﬁguration ﬁle. For the Chaperone attacks,
the authors
modiﬁed the virtual room setup stored in the JSON ﬁle. To
strike a Disorientation attack, they modiﬁed two parameters
that control players’ orientation, stored in the same JSON
ﬁle. The same parameters were manipulated to carry out a
Human Joystick attack, even though the sequence and the rate
of modiﬁcations are different. They also proved possible the
Overlay attack, due to the fact that any OpenVR application
is allowed to call an overlay and that no mechanism for force
closing overlays existed. The authors suggested that this could
be exploited to show undesired advertisements or even perform
ransomware attacks that prevent users from using their VR
system. Last, the authors were able to extract information
from the video buffer of the HTC Vive; the Oculus Rift was
not used as it was not equipped with a front camera. In
conclusion, every attack was successful and the reason was
OpenVR lack of robustness: critical information was stored
in plain-text, permissions were not deﬁned or not restrictive
enough, and applications were insufﬁciently isolated without
sufﬁcient integrity checks. Casey et al. suggest that Arya [26],
[27], a policy enforcer created for AR applications, could be
adapted to the VR domain.

Regarding Overlay attacks, Ahn et al. [28] noted that
most of the research conducted for AR and VR security has
focused more on input privacy (i.e., minimising the sensor
data available to third parties) than visual output security.
A notable exception is the aforementioned Arya [26], [27],
proposed by Lebeck et al. The authors showcase that deﬁning
rule-based policies for every conceivable AR/VR scenario is
an intractable task, using a notable example that assume an
application required to create various virtual objects, which
should not obstruct the users’ view nor overlap with other
important objects (e.g., a virtual avatar). In other words, in this
application a new dynamic object should be positioned in the
environment in such a way that it is visible but not obstructive.
To overcome the complexity of managing this task, the authors
proposed Arya, which uses Fog computing and Reinforcement
Learning to automatically synthesizes security policies. As
suggested by Casey et al. [24], their approach can be used to
prevent attackers from manipulating a VR application, either
to distract and disrupt users or to prevent expected interactions
by obstructing important environmental objects. An example
of an attack would be a ransomware that obstructs the user’s
view with an object until the victim pays a ransom.

Last, VR platform might be vulnerable to various speciﬁc
side-channel attacks. For example, Al Arafat et al. [29] investi-
gated keystrokes on virtual keyboards in terms of security. The
authors proposed VR-Spy, a side-channel attack that allows to
extract gesture patterns from channel state information (CSI)

JOURNAL OF

6

Fig. 3. Security issues in VR. In purple the three main categories, further speciﬁed in subcategories and speciﬁc concerns.

wave-forms of Wi-Fi signals and then, by applying machine
learning, recognize keystrokes from such patterns. The exper-
imental setup consists of a person equipped with a commer-
cially available headset, positioned between 2 commercially
off-the-shelf (COTS) wireless devices. Their experiments show
that VR-Spy achieves an accuracy of 69,75% when performing
virtual keystroke recognition. Referring to the CIAS quartet,
this speciﬁc side-channel attack (listed in Table I) breaches
communication conﬁdentiality.

B. Generic Security Threats that Affect VR

Beyond security threats that affect speciﬁcally VR due to its
characteristics, VR systems can also be vulnerable to generic
security threats Valluripally et al. [30], [31], [32] focused
on modeling and controlling generic attacks that could cause
they
cybersickness in VR users. In their ﬁrst paper [30],
introduce a rule-based framework that controls cybersickness
by means of 3Qs adaptation. In other words, they propose a
system that regulates three aspects:

• Quality of Application (QoA), a measure of application

performance;

• Quality of Service (QoS), a measure of network resources

such as bandwidth and jitter;

• Quality of Experience (QoE), a measure of user perceived

satisfaction.

The framework is useful for reducing sickness, both if
induced by incidental performance issues (e.g.,
temporary
network bottlenecks), as well as if caused by malicious attacks,
such as DoS. Through continuous monitoring of anomaly
events, the framework classiﬁes events into predeﬁned cate-
gories and selects the appropriate adaptation strategy. For ex-
ample, assuming that the system is deployed on Amazon Web
Services (AWS), if the framework detects an abnormal high
CPU utilisation that affects QoA, an adaptation strategy would
be to upgrade the server instance to a better instance (e.g., from
AWS t2.micro to AWS c4.large). Their experiments show that
adaptations for QoA anomalies can reduce cybersickness by up
to 26.43%, while, in the case of QoS anomalies, the proposed
adaptation reduces cybersickness by 30.28%. The framework
also has the ability to take into account the associated hourly
costs for each adaptation strategy, so that the best cost-effective
adaptation can be adopted.

Security ThreatsBy-standerSpecific on VRGenericAuthenticationMan-in-the-MiddleSide-Channel AttacksImmersive AttacksMan-in-the-RoomChaperoneOverlayUnauthorised AccessBruteforcePersonal DataLeakageImpersonation(Shoulder-Surfing)Hand-over toUnauthorised ActorCamera Stream andTracking ExfiltrationVideo RecordingsDenial-of-ServiceDisorientation(Cybersickness)Human JoystickSide-Channel AttacksJOURNAL OF

7

TABLE I
VR-SPECIFIC ATTACKS AND THEIR IMPACT IN TERMS OF THE CIAS QUARTET

Conﬁdentiality

Integrity

Availability

Safety

Chaperone Attack

Disorientation Attack

Human Joystic Attack

Overlay Attack

Camera Stream and Tracking
Exﬁltration Attack

Man-In-The-Room Attack

Side-channel Attack on Virtual
Key Logging

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

(cid:55)

In their subsequent work, Valluripally et al. [31], [32]
expand on their analysis of sickness-inducing attacks. First,
the authors conducted an experiment where they simulate the
effects of on-going security attacks and/or privacy attacks
while users perform some tasks in VR. The experiment was
performed by artiﬁcially manipulating the trafﬁc rate and it
shows that these attacks cause considerable disruption to dif-
ferent factors that contribute to cybersickness, such as nausea
and discomfort. The authors then proved that cybersickness
can be correlated with security and privacy issues, regardless
if due to attacks, faults, or a combination of both. In particular,
they proposed a framework based on an attack-fault
tree
(AFT) formalism for producing threat models that describe
the possible security and privacy attacks. The resulting AFTs
are used to perform a quantitative assessment of the probability
of disruption caused by each threat. Evidence shows that
the threats that induce higher levels of cybersickness in VR-
based Learning Environments (VRLEs) are DoS attacks, data
leakage, man-in-the-room attacks, and generic unauthorised
accesses. Based on the quantitative results, the authors also
experimented the effect on cybersickness when different de-
sign principles are applied, such as hardening and redundancy.
For example, applying hardening and the principle of least
privilege reduces the probability of cybersickness by 28,96%,
whereas applying redundancy and the principle of least priv-
ilege achieves only a small reduction of 3,05%. When all
prescribed principles are applied together, the probability of
experiencing cybersickness is reduced by 35,18% in total.

Gulhane et al. [33] focused on a sub-area of VR, namely,
VRLEs. VRLEs are VR spaces designed for delivering virtual
learning experiences to their users. For doing so, VRLEs
often combine data from emotion tracking sensors with other
sensitive information, such as users’ learning progresses and
personal data. Therefore, VRLEs pose a number of challenges
with respect to the security, privacy, and safety of their users.
Gulhane et al. proposed a risk assessment framework that uses
attack trees to formalise internal and external vulnerabilities
for VRLEs, such as DoS, SQL injections, and unauthorised
logins. For example, they use attack trees to formalize the
observation that delayed packets (e.g., due to DoS attacks)

would lead to compromise the availability of the server, hence
its security. The output
is a risk score for each analysed
property: security, privacy, and safety. Using vSocial [34] (a
cloud-based VRLE designed for young people with learning
disabilities) as a testbed, the authors evaluated the attack trees
produced by their methodology. Each leaf of every attack tree
represents a threat and, for each leaf, the authors simulated
the corresponding attack. Then, they assigned an impact score
for every threat and used the scores for computing complete
attack trees.

Finally, it should be noted that VR equipment could facil-
itate security threats, such as shoulder-surﬁng attacks where
a malicious party spies on the user’s actions to steal their
password. Chen et al. [35] described a computer vision-based
attack, struck using VR augmented with additional sensors. In
their experiments, the authors showed that it is possible to use
a HMD, equipped with an additional ZED stereo camera, for
recording the surroundings and stealing the passwords input
by users on their devices. The paper shows that it is possible to
reconstruct a 3D video from the two two side-by-side videos
recorded by the ZED camera. Then, the 3D video can be
analysed and used for extracting the 3D trajectories of the
ﬁngertip movements to recover the passwords tapped by the
victim. The paper shows that there is the potential risk of
malicious users that pretend playing some videogames on VR
while recording unconscious people moving in the surrounding
environment. In particular, the experiments show that there is
a strong correlation between the success rate of the attack
and the distance from the victim, as well as with the number
of input attempts. In addition, some authentication systems
require to conﬁrm the input password and such requirement
increases the success rate of the proposed attack.

IV. AUTHENTICATION IN VR
Among the areas of research within VR security, the topic
of authentication deserves a section of its own. In fact, most
of the work related to VR security focuses on identifying or
authenticating its users. In this section, we provide an in-depth
exploration of the literature and we summarise the works in
Table II.

JOURNAL OF

8

TABLE II
WORKS ON AUTHENTICATION FOR VR

Authentication Approach

Works in the Literature

Traditional Authentication

George et al. [36], Yu et al. [37], Olade et al. [38], Funk et al. [39],
Khamis et al. [40]

Authentication via VR interactions Mathis et al. [41], [42], George et al. [43], Funk et al. [39],

Head gaze and movements

Eye-Tracking

Bio-mechanics

Mathis et al. [41], [42], Funk et al. [39], Rogers et al. [44], Sivasamy et
al. [45], Mustafa et al. [46]

Olade et al. [38], Mathis et al. [41], [42], Liebers et al. [47], Luo et
al. [48], Khamis et al. [40], Lohr et al. [49], [50], Zhu et al. [51]

Mustafa et al. [46], Pfeuffer et al. [52], Kupin et al. [53], Ajit et al. [54],
Liebers et al. [55], Miller et al. [56], Miller et al. [57], Olade et al. [58],
Shen et al. [59]

In their seminal work, George et al. [36] proposed a ﬁrst step
toward integrating traditional authentication approaches into
VR, in particular PINs and swipe patterns. They conducted
a study with a total of 30 people and showed that both
techniques are suitable for transposition into VR. In particular,
they showed that the usability in VR matches the usability in
the physical world. Furthermore, they showed that the private
visual channel granted by VR makes such authentication
processes harder to observe and steal.

Similarly, Yu et al. [37] investigated the implementation
of two traditional authentication methods, pattern swiping
and PINs, while also making a ﬁrst attempt to create a 3D
password for VR. Although the authors did not introduce
sufﬁcient details about the 3D password, they provided some
intuition about the relative resilience of the three methods
against shoulder-surﬁng attacks. In their experiments,
the
participants were recorded while using the three authentication
methods and then asked to guess the passwords of other
participants, watching the recordings. The results showed
that 3D passwords were considerably harder to guess than
2D swipes and PINs, most probably due to the additional
complexity added by introducing a third dimension.

Olade et al. [38] further investigated the portability of swipe
patterns from mobile devices to VR, noting that George et
al. [36] did not provide a direct performance comparison
between mobile devices and VR. In their experimental setup,
the authors implemented the swiping authentication system in
terms of 4 different interaction methods: using the hand-held
controller (HHC), the HMD, the LeapMotion (a hand-tracking
device), and the aGlass (for eye tracking). While the mobile
swiping authentication was the easiest and fastest to use, the
HHC and the LeapMotion versions were comparable both
in terms of speed and usability. Regarding shoulder-surﬁng
attacks, given the same amount of information, attackers have
a considerable lower success rate when swiping is done in VR
than when it is done on a mobile phone screen.

Mathis et al. [41], [42] proposed RubikAuth, a three-
dimensional authentication method, consisting in a ﬁve-faced
cube (one face is omitted for improved reachability) that
exhibits 1 colour and 9 digits per face. For authenticating

themselves, the user rotates the cube with the left HHC and
selects n digits as their chosen password. The entropy of a
RubikAuth password is equal to 45n, considerably higher than
the 10n entropy granted by traditional numerical pins. The
authors evaluated the impact on performance of different input
techniques, concluding that controller tapping is faster than
head pose and eye gaze, while the study participants did not
express any clear preference regarding the usability of each
input approach.

The authors also evaluated the security of their proposal,
using three realistic attackers with different tools: pen and
paper to annotate observations, a 3D replica of the cube,
and recordings of users performing authentication. The ex-
periments show that having access to such resources slightly
increases the chances of guessing a RubikAuth password
(and, reasonably, the same applies to other VR authentica-
tion modes): 8 attacks out of 540 attempts succeeded, even
though the passwords were simple patterns involving only
a single cube face. RubikAuth exhibits strong guarantees
against shoulder-surﬁng attacks, as it is possible to apply fake
face switches to deceive bystanders. It is also possible to
strategically angle the cube and pick numbers from different
faces without applying any rotation.

Funk et al. [39] proposed LookUnlock, a head-gaze-based
solution to enter passwords on HMDs. LookUnlock can use
different kind of spatially-aware passwords, namely, spatial
passwords, virtual passwords, and hybrid passwords. To set
a spatial password, users move the HMD cursor to different
positions in the environment and perform enter actions. For the
unlocking phase, users insert their password by placing the
head-gaze cursor over the spatial targets previously deﬁned
at setting phase. After the ﬁrst object,
the users have up
to 3000 ms for detecting the next object, before getting a
time-out. LookUnlock adds an additional layer of security to
the authentication phase by binding spatial passwords to the
environment. In practical terms, the same actions performed
in a different environment would not authenticate the user, as
the framework would identify that the physical environment
differs from the one used at enrolment time.

JOURNAL OF

9

A. Biomechanics-based Authentication

As pointed out by Miller et al. [57], traditional authentica-
tion methods, such as PINs and passwords, not only can be
stolen by malicious attackers, but they also allow a legitimate
user to hand-over control to a third party. This can be particu-
larly problematic for VR applications that must ensure that the
user performing the tasks is the same user who authenticated
themselves in the ﬁrst place. For example, a VR scene used
to undertake university exams should prevent a student from
cheating by logging in and handing over the control to a
fellow student. One solution for countering handover threats
is to implement implicit and continuous authentication via
biometrics, which allow for detecting automatically when the
user’s characteristics differ from the expected ones. Another
downside of explicit authentication, as observed by Liebers
et al. [47], is that it negatively affects user immersion in
VR. Biometrics-based authentication techniques also have an
advantage over explicit authentication methods in this regard,
as they are implicit and provide a smoother experience for the
users. In this section, we describe the state of the art for what
concerns the authentication of VR users using biomechanical
biometrics. Jain et al. [60] noted that body movement can be
used for authentication purposes when it is universal, distinc-
tive, repeatable, and collectible. Based on such observations,
several works in the literature explored how VR sensors can be
used to capture movement patterns. In this section, we explore
the state of the art; in Table III we summarise the features used
by each analysed work and the accuracy results obtained by
the authors.

Li et al. [61] noted that adults exposed to fast beat audio
tracks exhibit unique patterns of head movement. Their ob-
servation resulted in Headbanger, a framework that captures
unique head movements that arise as a natural response to fast-
tempo audio stimuli, and authenticates the users accordingly.
Implemented using a Google Glass device, Headbanger shows
an EER of 4,43% when users are exposed to a 10-second
music cue. When tested against imitation attacks, less than
3% of attempted attacks achieved a false positive.

With VRCAuth, Sivasamy et al. [45] also investigated the
use of head movements to provide continuous authentication
in VR settings. VRCAuth performs a binary classiﬁcation
to determine whether the current user is authorised or not.
The authors evaluated ﬁve different binary classiﬁers on two
different data sets, the Kaggle VR driving simulator [62] and
the user behaviours in spherical video streaming [63]. Both
datasets provide three-dimensional information; additionally,
the latter provides quaternion information. The results of the
experiments show that the PART and LMT classiﬁers achieved
an accuracy of more than 99% for the ﬁrst dataset. On the
second dataset, every classiﬁer achieved an accuracy of more
than 99%, suggesting that quaternion data can signiﬁcantly
simplify binary classiﬁcation tasks.

Similarly to Miller et al. [16], Mustafa et al. [46] found
that body movement patterns (freely interacting within a VR
environment) exhibit enough information to identify users. In
their work, the authors argued that data of head movements
can be used for authentication purposes. To prove their claim,

they designed an experiment with 23 subjects that interacted
with a VR application developed by the authors. The VR
application was designed speciﬁcally for evaluating head and
body biometrics. In the experiment, the users start from a point
A and must move towards a random point B where a ball
appears, then to a third random point C, and so on, until the
user has reached 25 balls. To move towards a ball, users must
move a VR pointer towards the target ball by nudging the VR
headset in the desired direction. Each subject was evaluated
in two sessions that took place, at least one day apart from
each other, and the experiments showed an EER of around
7%, in the best case. Although these results would not sufﬁce
to deploy a real-life application, head and body movements
hold promise for authentication purposes.

Beyond the raw data of its sensors, VR equipment can
provide more interesting information for authentication pur-
poses. In 2019, Pfeuffer et al. [52] investigated the use of body
motion and behavioural biometrics for identifying users in a
VR setting. They conducted their experiments using an HTC
Vive (composed of a HMD, two controllers, and an optical
tracking), enriched with an additional eye tracker from Pupil
Labs. First, they identiﬁed four basic tasks that can be found in
most VR applications: pointing, grasping, walking, and typing.
Then, they designed speciﬁc tasks that revolve around these
four activities and invited 22 participants to perform them.
Based on the collected data, the authors evaluated different
motions and distance relations (e.g., the distance between the
headset and the joysticks). However, their best result, obtained
using a combination of head motion and the distance between
every device, achieved only an average of 40% accuracy.
Therefore, further investigations were warranted.

Other works investigated the combination of data from
controllers and HMDs for achieving authentication on VR.
Several of these works used a virtual ball-throwing task as
a case study. In the ﬁrst instance, Kupin et al. [53] used as
a feature the position of the dominant hand holding a VR
controller, following the intuition that users exhibit identiﬁable
trajectories due to their unique biomechanics. In their experi-
ment, the authors instructed users to pick up a virtual ball and
throw it at a target and they compared the trajectory of the
dominating hand of each user against a dataset containing the
movements of the other users. Using bounding box centering
and a nearest-neighbour (NN) matching algorithm on 95
different 3D trajectories, the authentication accuracy reached
92,86%, proving that trajectories exhibit enough peculiarities
to identify a user.

Ajit et al. [54] improved the approach proposed by Kupin
et al. [53], extending the data analysis to the recessive hand
and the head and using the device orientation in addition
to the position. In an experiment
the
authors improved the results of Kupin et al., obtaining an
authentication accuracy of 93,03%. Their approach is based on
a perceptron classiﬁer which learns weights on the matches be-
tween position and orientation features on the hand controllers’
trajectories, as well as the headset trajectory. In practical terms,
trajectories belonging to the same user result in a low classiﬁer
score and allow the user to authenticate.

involving 33 users,

Liebers et al. [55] further investigated the effect of body

JOURNAL OF

10

TABLE III
BIOMECHANICS-BASED AUTHENTICATION IN VR

P articipants

A ccuracy ( % )

E q ual Error R ate ( % )

P ositio n
H ead

H ead

C o ntrollers O rientatio n
C o ntrollers P ositio n
D istance B et w een
O rientatio n

B o d y

D evices
V elocity/ A cceleratio n
N or m alisatio n
G ait E sti m atio n

Li et al. [61]

30

4,43

Sivasamy et al. [45]

40 / 48

99

Mustafa et al. [46]

Pfeuffer et al. [52]

Kupin et al. [53]

Ajit et al. [54]

Liebers et al. [55]

Miller et al. [56]

Miller et al. [57]

Shen et al. [59]

7

23

22

95

33

16

46

46

20

40

92,86

93,03

100

85

98,53

95

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

normalisation on user identiﬁcation in VR. In particular, they
analysed the impact of body height normalisation, arm length
normalisation, and the combination of both against scenarios
where no normalisation is applied. They evaluated a small
pool of 16 participants during the execution of two tasks that
can be correlated to actions executed in a typical VR game: a
bowling throw task and an arrow shooting task. The research
highlights that, while physiological factors play a clear role in
behavioural biometrics, they also increase the noise injected
into deep learning algorithms. Removing or reducing the fea-
tures showed a positive impact on the identiﬁcation accuracy
of the deep learning models implemented by the authors,
i.e. RNN and MLP. Not only this work suggests that it is
possible to achieve user identiﬁcation without processing some
sensitive information, but also that it is feasible to perform
continuous authentication during regular gaming sessions.

Miller et al. [56] noted that authentication approaches based
on behavioural biometrics assume that users enrol in the same
VR system they will later use. However, in the future users
might interact with many different VR headsets in their daily
tasks. This exposes a problem, because different VRs exhibit
system-speciﬁc biases, meaning that every time that users want
to use a new headset, they have to engage in new enrolment
phases. Therefore, Miller et al. investigated the differences
between 3 different VR systems (Oculus Quest, HTC Vive, and
HTC Vive Cosmos), collecting the biometric data of 46 users
performing a simple task on each system. They instructed the
participants to perform a simple (virtual) ball-throwing task
on each headset, repeated 10 times, for several consecutive
days. Expanding on what has previously been done by Ajit et
al. [54], they introduced trigger control information from the

dominant controller, as well as linear and angular velocity to
account for the differences in speed between users. The results
in terms of within-system and cross-system accuracy showed
that some features play a prominent role for authentication pur-
poses. In particular, head orientation, left controller position,
right controller orientation, and right controller position proved
to be the most important features for authentication purposes.
Their results conﬁrm the intuition of Ajit et al. [54], about
the relative importance of different features when performing
authentication.

Improving their previous work, Miller et al. [57] proposed
using siamese neural networks to learn the baseline distance
function across HMDs. Knowing this information, when a
user wants to use a new VR headset, it sufﬁces to apply
the distance function to offset the inherent differences with
the original headset used for enrolment. This prevents users
from having to go through an additional enrolment phase
every time they use new VR equipment. In this paper, they
used the same experimental setting they used in their previous
study [56]. Regarding user authentication, their results show
that the siamese network achieves at its best a 1,39% EER,
when the Oculus Quest trajectories are used at enrolment time
and the HTC Vive at use time. For user identiﬁcation, their
highest accuracy is 98,53%, with the same setup observed for
the EER authentication result.

Shen et al. [59] note that VR systems often store users’
private data, such as social network accounts and credit card
information. Although convenient, this method of accessing in-
formation exposes signiﬁcant security and privacy issues. For
amending this issue, the authors proposed an authentication
system based on the users’ gait signatures, named GaitLock,

JOURNAL OF

11

that implements a new gait recognition model, Dynamic-SRC.
Dynamic-SRC fuses data information from both the HMD
accelerometer and the HMD gyroscope to address the problem
of noisy signals coming from head motions. The validation
experiments consisted of different walking tasks; among these
tasks, the most interesting is the uncontrolled outdoor walking
task. The results show that Dynamic-SRC outperforms by 20%
the gait recognition accuracy of the best alternative algorithm
(SRC with Sparse Fusion). Furthermore, in the uncontrolled
walking task, GaitLock achieves an accuracy of 95% using
only a small dataset of 5 steps. Although the authors used
only an AR device that could provide enough computational
power (i.e., Google Glasses), they noted that with enough
computational power, their system can be transposed to VR.

B. Authentication with eye-tracking sensors

Although early VR headsets were not equipped by default
with eye trackers, these sensors are becoming more and more
common in commercial headsets. One of the main beneﬁts
provided by VR HMDs to eye tracking is that HMDs fully
cover users’ eyes, allowing for controlling lighting conditions
and reducing problematic reﬂexions.

Authentication using eye tracking sensors has been studied
long before VR technology took hold. For example, in 1978
Hill [64] patented an apparatus for recognising individuals by
the retinal vasculature in their eyes and, in 2004, Maeder et
al. [65] investigated the use of eye gaze to authenticate users.
More recently, in 2016 Sluganovic et al. [66] observed that
gaze-based authentication systems suffer from high error rates
or require long authentication times. Based on this premise,
they proposed using reﬂexive saccades, rapid eye movements
that reorient the eye to the next focus object. Other works, such
as Rigas et al. [67] and Holland and Komogortsev [68], show
the potential of using saccades for identiﬁcation purposes. In
this section, we focus on works that discuss the use of eye-
tracking sensors in VR, either alone or alongside other sensors.
the research
conducted in the vast ﬁeld of eye-based authentication and
recognition, not speciﬁcally targeted to VR applications and
implementation. In Table IV, we summarise the papers dis-
cussed in this section and we highlight which features have
been used by the authors for performing authentication.

this paper, we neglect

the scope of

For

Rogers et al. [44] showed the possibility of identifying
users using their unconscious head movement and blinking,
while performing a simple passive task. The authors set up an
experiment in which they showed 20 participants a rapid series
of numbers and letters. Using the collected data, they achieved
an identiﬁcation accuracy of 94%, showing the suitability of
unconscious movements for unobtrusive user authentication.
Liebers et al. [47] proposed an implicit identiﬁcation method
based on users’ saccadic movements and head orientation.
Similarly to when eyes switch from slow pursuit to saccadic
movement, as previously mentioned, when the stimulus speed
exceeds the saccadic speed threshold, human beings must
recruit head movement to keep track of the stimulus. The
authors show that the characteristics of ﬁxations and saccades,
together with head orientation, are complex and unique enough

to be used as biometric features. In particular, with a small
pool of 12 participants, using a kNN algorithm on every
feature they envisioned, their approach achieves an accuracy
of 82%, whereas using deep learning the accuracy reaches the
100% mark.

Luo et al. [48] noted that authentication methods based on
head and body movements, such as those mentioned above,
expose the authentication actions to bystanders. They also
noted that eye-gazing alone can exhibit a high EER, too high
for trusting it as an authentication method. Therefore, with
OcuLock the authors propose to involve the entire human
visual system (HVS), as it is composed of different entities,
such as eyelids and extraocular muscles, which exhibit features
that could be used for authenticating purposes. Tested with
70 participants, OcuLock achieves an EER of 3,55% against
impersonation attacks and 4,97% against statistical attacks.
However,
it should be noted that standard HMS headsets
equipped with eye-tracking cameras cannot measure such
HVS signals; for example, they cannot be used to implement
a framework based on electrooculography (EOG) such as
OcuLock. In fact, to capture EOG signals, the authors had to
enrich with tiny electrodes the foam face cover of a Lenovo
Mirage Solo VR headset.

With VRPursuits, Khamis et al. [40] showed that VR
equipped with eye tracking is suitable for implementing
smooth pursuits that address the Midas touch problem (i.e.,
the problem of distinguishing deliberate gaze from basic eye
perception functions). Although their work does not address
user authentication nor security properties, their implementa-
tion of a virtual ATM shows the potential feasibility of an
authentication method based on smooth pursuits detection. In
their proof of concept, participants were asked to enter a 4-
digit PIN by intentionally looking at the desired numbers. The
numbers, from 0 to 9, were visualised as two groups of cubes
rotating clockwise and counterclockwise, respectively.

Lohr et al. [49], [50] explicitly address the goal of using
eye movement biometrics to authenticate VR users. During the
enrolment phase, the prototype extracts four ﬁxation features
and eight saccades features, for a total of twelve eye movement
features. To perform authentication, the authors propose to
compare the features of two different
templates (the user
currently examined and a stored template), create a vector of
match scores, and ﬁnally combine the scores into a single
fused score using a weighted mean fusion with equal weights.
Olade et al. [58] proposed BioMove, a method for recognis-
ing biomechanics behaviour patterns and using them to authen-
ticate users. In particular, the authors studied the movements
of the head, hands, and eyes of 15 users while performing
controlled tasks, such as grab, rotate, and drop. The authors
investigated the use of BioMove for the purpose of both user
identiﬁcation and authorization. In the best case scenario, for
identiﬁcation tasks BioMove achieved a classiﬁcation accuracy
the authors’ experiments
98,6%. Regarding authentication,
show a 0,0032% FPR and a 1,3% FNR, highlighting that
BioMove (and behavioural biometrics, in general) could be
used as an efﬁcient second-factor authentication.

Zhu et al. [51] noted that, by design, VR systems prevent
their users from seeing what happens around them in the real

JOURNAL OF

12

TABLE IV
AUTHENTICATION WITH EYE-TRACKING SENSORS

P articipants

A ccuracy ( % )

E q ual Error R ate ( % )

P ositio n
H ead

H ead

C o ntrollers O rientatio n
C o ntrollers P ositio n
O rientatio n

G aze

S accades

P u pil Size

G

O

E

Sig nals

Blin kin g

Rogers et al. [44]

Liebers et al. [47]

Luo et al. [48]

Khamis et al. [40]

20

11

70

26

Lohr et al. [49], [50]

458

Olade et al. [58]

Zhu et al. [51]

15

52

94

100

82

98,6

4,97

9,98

4

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

(cid:51)

world. This means that users have a hard time concealing their
actions from bystanders, which could lead them to potentially
leak sensitive information. BlinKey, an authentication scheme
designed for VR headsets equipped with eye-tracking technol-
ogy, aims to mitigate the problem by using only users’ eyes,
naturally covered when using a VR HMD. The core idea of
BlinKey is to encode a password as a set of blinks, performed
with a rhythm only known to the user (e.g., following a tune
that they like). As an additional authentication layer, BlinKey
analyses the pupil size variation between blinks, a biological
marker that uniquely characterises every person. BlinKey
was implemented and tested using a commercially available
HTC Vive Pro equipped with a Pupil Labs eye tracker. To
evaluate the security resilience of their proposals, the authors
tested four different types of attack: zero-effort, statistical,
shoulder surﬁng, and credential-aware. For the ﬁrst attack,
attacking participants tried to guess the target blinking pattern
without any information and were incapable of compromising
passwords composed of 7 or more blinks. With statistical
attacks, attackers had access to a dataset of blinks of their
victim, which they could statistically analyse. This leads to
a slight advantage for the attacker, with respect to the zero-
effort attack, but passwords composed of at least 8 blinks seem
to prevent any compromise attempt. Shoulder-surﬁng attacks
were more successful, with an attack success rate of 4.9%.
Last, credential-aware attacks assume that the attacker knows
the password and tries to replicate it with their own blinks (i.e.,
exhibiting their own pupillary biometrics). Although the attack
proved to be more successful than the previous ones, when the
password consisted of at least 10 blinks the attack success rate
was 4,4%, showing that pupil variation alone cannot be used
as an authentication factor.

C. Other works in VR Authentication

Most papers in the ﬁeld of VR authentication, at the time
of writing, either leverage something users know, such as

a password, or some personal characteristics, such as their
behavioural biometrics. Combining these different approaches
for achieving multi-layered authentication has the potential to
produce stronger authentication schemes across the board.

For example, with RubikBiom, Mathis et al. [69] investi-
gated the use of knowledge-driven behavioural authentication
for authentication in the VR domain. The authors developed a
proof of concept that uses two different authentication features.
A password only known to the user and the movement patterns
that arise from the act of inputting such a password in VR.
As for previous proposals for behavioural biometrics,
the
intuition is that every user exhibits peculiar movement patterns
due to their speciﬁc biomechanics. In particular, an attacker
that attempts to inﬁltrate a victim’s account by shoulder-
surﬁng, not only should steal the password, but should also be
able to replicate the same movement patterns when inserting
the password. In RubikBiom, the password is a 4-digit PIN
selected on a 5-faced cube. Each face has a different colour
and exhibits 9 digits (1-9), similarly to the setup used by
the same authors in their works previously discussed [41],
[42]. The best accuracy score was 98,91%, which demonstrates
that multilayered approaches in VR hold promise. The result
was obtained with a fully convolutional network (FCN) over
a multivariate dataset (composed of dominant hand position
and rotation), together with non-dominant hand position and
rotation.

In a preliminary study, Wang and Gao [70] show that multi-
attribute authentication methods could also be effective in
countering Man-in-the-Room (MITR) attacks. The basic intu-
ition behind their authentication scheme is that objects in the
real world are deﬁned by a rich set of features (e.g., colour and
shape). In their proof-of-concept, the user chooses a number of
secret features at enrolment time and, at authentication time,
the framework creates random objects which might contain
none, some, or every feature. To log into the system, the user
must stare at the object that exhibits all the desired features.

JOURNAL OF

13

This approach is particularly interesting because it allows to
effectively decouple the input process from the password,
increasing the resilience to MITR attacks.

Von Willich et al. [71] discussed the danger that passersby
create to VR users, unaware of their surroundings. HMDs
impede visual perception of the surrounding environment,
allowing bystanders to physically collide with VR users or
observe their actions to infer their authentication credentials.
As a mitigation, the authors propose to detect passersby using
environmental sensors and depict them in the VR environment,
so that the VR user is aware of them, effectively implementing
augmented virtuality (AV), a paradigm that involves enriching
the virtual world with information from the real world. This
depiction can take different forms, such as avatars, 2D pictures,
or 3D renderings. While AV was originally meant for avoiding
unwanted collisions with dynamic agents in the real world,
the authors argue that it can be used for preventing some by-
standing attacks. Although AV cannot impede attackers from
observing from a distance, it could be used to detect attackers
that get close enough to be picked by the sensors and prevent
them from having a proper close-up view of VR users’ motion,
thus reducing their chances of inferring useful information.

V. VR FOR TEACHING, TRAINING, AND EVALUATING
SECURITY

VR environments have been proposed as a mean for im-
proving the cyber and physical security of sensitive locations,
as well as for training employees on routines and policies.
In addition, VR has been proposed to assess the usability of
authentication processes. In this section, we provide a brief
overview of these different applications.

A. Teaching Cyber-Security

In 2017, Puttawong et al. [72] noted that the abstract nature
of network security can make it hard to grasp for students,
when taught in traditional lecture-based classes. Therefore,
the authors proposed VRFiWall, a VR edutainment game
developed with Unity for teaching ﬁrewall security. In this
game, users interact with the environment using two basic
actions, that is, pointing and head gestures. This simple game,
which instructs its users about stateless ﬁrewalls, revolves
around a hero on a secret mission from his kingdom (IP
source) to another kingdom (IP destination). To complete his
mission, the hero has to match the requirements of Statelessa,
a non-playing character that embodies the ﬁrewall.

Following the same philosophy, Visoottiviseth et al. [73]
proposed Lord of Secure, a serious game for VR that chal-
lenges users with different cybersecurity concepts. The game
is divided into three chapters, which present various topics: IP
spooﬁng, ﬂooding, TCP covert channels, ﬁrewalls, intrusion
detection and prevention systems (IDSes and IPSes), and
honeypots. The goal of Lord of Secure is to make abstract
security topics easier to digest for cybersecurity students and
to evaluate the users’ understanding of core concepts by
means of pre-test and post-test quizzes. Among a group of
28 participants, 90% claimed that they well understood the
concepts covered in the game, and 82% thought that this

approach allowed them to understand better than traditional
frontal lessons. Indeed, quizzes that included pre-test and post-
test clearly showed that the users improved their knowledge by
playing the game. On average, considering Chapters 1 and 3,
70% of the users improved their scores after playing the game.
Taking into account users’ enjoyment and their improvements,
the authors concluded that edutainment games might be an
alternative and more effective way to teach cybersecurity.

Recently, Ulsamer et al. [74] discussed the use of sto-
rytelling in VR to improve user awareness of information
security (ISA), in particular, with respect to social engineering.
In their experiments, they split the participants into two groups,
providing one of the groups with a VR environment and the
other (named no-VR) with a traditional e-learning platform.
The learning objectives set for the two groups were the same.
The no-VR group received theoretical material and interesting
examples (but no videos) related to social engineering. The
VR group, instead, watched a storytelling 3D video with a
coherent and immersive plot that revolves around a hacker
which performs social engineering; the hacker is played by an
actor and the user follows his steps throughout the story. The
ISA analysis show that the VR group achieved better scores in
the ISA test, supporting the hypothesis that VR-based learning
can improve cybersecurity awareness and material retention.
Since that the no-VR group was provided with static material
but no traditional videos, it is still unknown whether regular
videos could achieve comparable results to VR-based videos.

B. Training Physical Security

Henrique da Silva et al. [75] proposed a VR-based tool to
train staff in a nuclear facility structure and plan its defence
strategies. The authors produced (and used) a high-ﬁdelity 3D
reproduction of a Brazilian nuclear research centre, showing
that their approach can be useful for evaluating the physical
security of different facilities. In particular, they proved that
inside the VR simulation it is possible to identify strategic
points of view and change the environment to evaluate the
impact on visibility. For example, their VR implementation
allowed them to change weather conditions, such as rain,
wind, and snow, as well as natural light conditions (day and
night alternation, sun position, presence of stars) and artiﬁcial
illumination. In conclusion, VR environments can be useful
tools, both for evaluating the physical security of critical
facilities and for training employees in risk management.

C. Evaluating Cyber-Security Usability

Mathis et al. [76], [77] noted that evaluating the usability
of new authentication schemes can be expensive, in particular
for the cases when special hardware and infrastructures are
required. VR can be helpful
in addressing this problem.
First, it saves researchers time and money by sparing them
from building their physical prototypes (e.g., a replica of an
ATM machine). Moreover, it enables them to recruit more
participants and increase their pools’ diversity, by allowing to
enrol people from different parts of the world.

With RepliCueAuth, Mathis et al. [76] paved the way to
usability studies in VR, discerning which security assessments

JOURNAL OF

14

could be transferred from VR to the real world and which ones
not. In their work, the authors replicated in VR the experiments
of a paper that explored 3 cue-based authentication methods
on situated displays. The results showed that some usability
studies can be transferred from VR to the real world, such
as the accuracy of authentication entry, perceived workload,
and perception of security. However, there are some notable
differences between the VR experience and the physical study,
in terms of results. Users took longer time to authenticate on
VR with the touch-based method, while they in the real world
the gazing-based approach was the slowest one. Similarly,
the security studies conducted on VR and on real world
experiments lead to comparable results for some evaluation
variables, but results differed in other instances. For example,
the attack rates for shoulder-surﬁng attacks were similar when
observing a real human being and a VR avatar, but
the
accuracy of the attackers’ guesses was different.

VI. CONCLUSION
Once a technology only used in exhibitions and research
laboratories, VR is becoming more and more common among
local businesses and families. Therefore, it is of paramount
importance to take into consideration the issues that
this
groundbreaking technology can create. In this work, we have
provided a thorough analysis of the privacy and security threats
that affect VR. First, we split the privacy issues in three
main categories, explaining what could cause these issues and
what might be the consequences. Then, we focused on the
security aspect of VR. We categorised the threats to security
in VR, including both the generic threats that affect VR and
the threats that are speciﬁc to VR. We have also dedicated
a speciﬁc section to the topic of authentication in VR, as it
appears to be the most common area of research in the ﬁeld
of VR cybersecurity, at the time of writing. Finally, we have
covered other interesting areas of research that use VR for
cybersecurity goals, such as teaching cybersecurity, training
physical security, and evaluating the usability of cybersecurity
solutions.

REFERENCES

“US

Virtual

[1] “10 Virtual Reality Statistics You Should Know in 2022 [In-
fographic],” https://www.oberlo.com/blog/virtual-reality-statistics, [Ac-
cessed 23-Mar-2022].
Petrock,
Users

Real-
[2] V.
ity
https://www.emarketer.com/content/
us-virtual-and-augmented-reality-users-2020, [Accessed 23-Mar-2022].
2021-
https://www.grandviewresearch.com/industry-analysis/

2028,”
virtual-reality-vr-market/methodology, [Accessed 23-Mar-2022].
[4] “Global Virtual Reality (VR) Market Size, Status and Forecast 2021-
2027,” https://reports.valuates.com/market-reports/QYRE-Othe-2A191/
virtual-reality, [Accessed 23-Mar-2022].

[3] “Virtual Reality Market

Share & Trends Report,

Augmented

2020,”

and

[5] J. Bailenson, “Protecting Nonverbal Data Tracked in Virtual Reality,”
JAMA Pediatrics, vol. 172, no. 10, pp. 905–906, 10 2018. [Online].
Available: https://doi.org/10.1001/jamapediatrics.2018.1909

[6] F. Roesner, T. Kohno, and D. Molnar, “Security and privacy for
augmented reality systems,” Commun. ACM, vol. 57, no. 4, p. 88–96,
apr 2014. [Online]. Available: https://doi.org/10.1145/2580723.2580730
[7] A. King, F. Kaleem, and K. Rabieh, “A survey on privacy issues of aug-
mented reality applications,” in 2020 IEEE Conference on Application,
Information and Network Security (AINS), 2020, pp. 32–40.

[8] J. A. De Guzman, K. Thilakarathna, and A. Seneviratne, “Security
in mixed reality: A literature survey,”
and privacy approaches
ACM Comput. Surv., vol. 52, no. 6, oct 2019. [Online]. Available:
https://doi.org/10.1145/3359626

[9] D. Adams, A. Bah, C. Barwulor, N. Musaby, K. Pitkin, and
the story of privacy and
E. M. Redmiles, “Ethics emerging:
reality,” in Fourteenth Symposium
security perceptions
on Usable Privacy and Security (SOUPS 2018).
Baltimore, MD:
USENIX Association, Aug. 2018, pp. 427–442. [Online]. Available:
https://www.usenix.org/conference/soups2018/presentation/adams

in virtual

[10] J.

Durbin,

“Oculus

able
hackable-webcam-oculus-sensor-be-aware/

webcams.”

[Online].

sensors

are
Available:

technically
hack-
https://uploadvr.com/

[11] F. O’Brolch´ain, T. Jacquemard, D. Monaghan, N. O’Connor, P. Novitzky,
and B. Gordijn, “The convergence of virtual reality and social networks:
threats to privacy and autonomy,” Science and engineering ethics,
vol. 22, no. 1, pp. 1–29, 2016.

[12] C. Nwaneri, “Ready lawyer one: Legal issues in the innovation of virtual

reality,” Harv. JL & Tech., vol. 30, p. 601, 2016.

[13] J. Tromp, C. Le, B. Le, and D.-N. Le, Massively Multi-user Online
Social Virtual Reality Systems: Ethical Issues and Risks for Long-Term
Use. Cham: Springer International Publishing, 2018, pp. 131–149.
[Online]. Available: https://doi.org/10.1007/978-3-319-90059-9 7
[14] J. Lake, “Hey, you stole my avatar!: Virtual reality and its risks to

identity protection,” Emory LJ, vol. 69, p. 833, 2020.

[15] D. Kumarapeli, “[dc] privacy in vr: Empowering users with emotional
privacy from verbal and non-verbal behavior of their avatars,” in 2021
IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts
and Workshops (VRW), 2021, pp. 715–716.

[16] M. R. Miller, F. Herrera, H. Jun, J. A. Landay, and J. N. Bailenson,
“Personal identiﬁability of user tracking data during observation of 360-
degree vr video,” Scientiﬁc Reports, vol. 10, no. 1, pp. 1–10, 2020.
[17] D. Maloney, S. Zamanifard, and G. Freeman, “Anonymity vs.
familiarity: Self-disclosure and privacy in social virtual reality,” in 26th
ACM Symposium on Virtual Reality Software and Technology, ser. VRST
’20. New York, NY, USA: Association for Computing Machinery,
2020. [Online]. Available: https://doi.org/10.1145/3385956.3418967
[18] L. E. Buck and B. Bodenheimer, “Privacy and personal space: Address-
ing interactions and interaction data as a privacy concern,” in 2021 IEEE
Conference on Virtual Reality and 3D User Interfaces Abstracts and
Workshops (VRW), 2021, pp. 399–400.

[19] B. Falk, Y. Meng, Y. Zhan, and H. Zhu, “Poster: Reavatar:
Virtual reality de-anonymization attack through correlating movement
signatures,” in Proceedings of the 2021 ACM SIGSAC Conference on
Computer and Communications Security, ser. CCS ’21. New York,
NY, USA: Association for Computing Machinery, 2021, p. 2405–2407.
[Online]. Available: https://doi.org/10.1145/3460120.3485345

[20] T. Partala, M. Jokiniemi, and V. Surakka, “Pupillary responses to
emotionally provocative stimuli,” in Proceedings of the 2000 Symposium
on Eye Tracking Research & Applications, ser. ETRA ’00. New York,
NY, USA: Association for Computing Machinery, 2000, p. 123–129.
[Online]. Available: https://doi.org/10.1145/355017.355042

[21] E. Bozkir, D. Geisler, and E. Kasneci, “Person independent, privacy
preserving, and real time assessment of cognitive load using eye tracking
in a virtual reality setup,” in 2019 IEEE Conference on Virtual Reality
and 3D User Interfaces (VR), 2019, pp. 1834–1837.

[22] B. John, S. Koppal, and E. Jain, “Eyeveil: Degrading iris authentication
in eye tracking headsets,” in Proceedings of the 11th ACM Symposium
on Eye Tracking Research & Applications, ser. ETRA ’19. New York,
NY, USA: Association for Computing Machinery, 2019. [Online].
Available: https://doi.org/10.1145/3314111.3319816

[23] B. John, S. J¨org, S. Koppal, and E. Jain, “The security-utility trade-off
for iris authentication and eye animation for social virtual avatars,” IEEE
Transactions on Visualization and Computer Graphics, vol. 26, no. 5,
pp. 1880–1890, 2020.

[24] P. Casey, I. Baggili, and A. Yarramreddy, “Immersive virtual reality
attacks and the human joystick,” IEEE Transactions on Dependable and
Secure Computing, vol. 18, no. 2, pp. 550–562, 2021.

[25] M. S. Dennison, A. Z. Wisti, and M. D’Zmura, “Use of physiological
signals to predict cybersickness,” Displays, vol. 44, pp. 42–52, 2016,
contains Special Issue Articles – Proceedings of the 4th Symposium
on Liquid Crystal Photonics
[Online]. Available:
https://www.sciencedirect.com/science/article/pii/S0141938216301081

(SLCP 2015).

[26] K. Lebeck, K. Ruth, T. Kohno, and F. Roesner, “Securing augmented
reality output,” in 2017 IEEE Symposium on Security and Privacy (SP),
2017, pp. 320–337.

[27] ——, “Arya: Operating system support for securely augmenting reality,”

IEEE Security Privacy, vol. 16, no. 1, pp. 44–53, 2018.

JOURNAL OF

15

[28] S. Ahn, M. Gorlatova, P. Naghizadeh, M. Chiang, and P. Mittal,
“Adaptive fog-based output
security for augmented reality,” in
Proceedings of the 2018 Morning Workshop on Virtual Reality and
Augmented Reality Network, ser. VR/AR Network ’18. New York, NY,
USA: Association for Computing Machinery, 2018, p. 1–6. [Online].
Available: https://doi.org/10.1145/3229625.3229626

[29] A. A. Arafat, Z. Guo, and A. Awad, “Vr-spy: A side-channel attack on
virtual key-logging in vr headsets,” in 2021 IEEE Virtual Reality and
3D User Interfaces (VR), 2021, pp. 564–572.

[30] S. Valluripally, V. Akashe, M. Fisher, D. Falana, K. A. Hoque, and
P. Calyam, “Rule-based adaptations to control cybersickness in social
virtual reality learning environments,” in 2021 8th International Con-
ference on Future Internet of Things and Cloud (FiCloud), 2021, pp.
350–358.

[31] S. Valluripally, A. Gulhane, R. Mitra, K. A. Hoque, and P. Calyam,
“Attack trees for security and privacy in social virtual reality learning
environments,” in 2020 IEEE 17th Annual Consumer Communications
Networking Conference (CCNC), 2020, pp. 1–9.

[32] S. Valluripally, A. Gulhane, K. A. Hoque, and P. Calyam, “Modeling and
defense of social virtual reality attacks inducing cybersickness,” IEEE
Transactions on Dependable and Secure Computing, pp. 1–1, 2021.
[33] A. Gulhane, A. Vyas, R. Mitra, R. Oruche, G. Hoefer, S. Valluripally,
P. Calyam, and K. A. Hoque, “Security, privacy and safety risk as-
sessment for virtual reality learning environment applications,” in 2019
16th IEEE Annual Consumer Communications Networking Conference
(CCNC), 2019, pp. 1–9.

Stichter,
and
social virtual

[34] S. S. Nuguri, P. Calyam, R. Oruche, A. Gulhane, S. Valluripally,
system
in
80,
[Online]. Available:

J.
for
special
no.
https://doi.org/10.1007/s11042-020-09051-w

Z. He,
“vsocial:
reality learning environment

education,” Multimedia Tools and Applications,

16 827–16 856, May

applications

cloud-based

2021.

vol.

11,

pp.

a

[35] S. Chen, Z. Li, F. Dangelo, C. Gao, and X. Fu, “A case study of security
and privacy threats from augmented reality (ar),” in 2018 International
Conference on Computing, Networking and Communications (ICNC),
2018, pp. 442–446.

[36] C. George, M. Khamis, E. von Zezschwitz, M. Burger, H. Schmidt,
F. Alt, and H. Hussmann, “Seamless and secure vr: Adapting and
evaluating established authentication systems for virtual reality.” NDSS,
2017.

[37] Z. Yu, H.-N. Liang, C. Fleming, and K. L. Man, “An exploration of
usable authentication mechanisms for virtual reality systems,” in 2016
IEEE Asia Paciﬁc Conference on Circuits and Systems (APCCAS), 2016,
pp. 458–460.

[38] I. Olade, H.-N. Liang, C. Fleming, and C. Champion, “Exploring
the vulnerabilities and advantages of swipe or pattern authentication
in virtual reality (vr),” in Proceedings of the 2020 4th International
Conference on Virtual and Augmented Reality Simulations, ser. ICVARS
2020. New York, NY, USA: Association for Computing Machinery,
2020, p. 45–52. [Online]. Available: https://doi.org/10.1145/3385378.
3385385

[39] M. Funk, K. Marky,

I. Mizutani, M. Kritzler, S. Mayer,
and F. Michahelles, “Lookunlock: Using spatial-targets for user-
authentication on hmds,” in Extended Abstracts of the 2019 CHI
Conference on Human Factors in Computing Systems, ser. CHI EA ’19.
New York, NY, USA: Association for Computing Machinery, 2019, p.
1–6. [Online]. Available: https://doi.org/10.1145/3290607.3312959
[40] M. Khamis, C. Oechsner, F. Alt, and A. Bulling, “Vrpursuits: Interaction
in virtual reality using smooth pursuit eye movements,” in Proceedings
of the 2018 International Conference on Advanced Visual Interfaces, ser.
AVI ’18. New York, NY, USA: Association for Computing Machinery,
2018. [Online]. Available: https://doi.org/10.1145/3206505.3206522
[41] F. Mathis, J. Williamson, K. Vaniea, and M. Khamis, “Rubikauth:
reality,” in Extended
Fast and secure authentication in virtual
Abstracts of the 2020 CHI Conference on Human Factors in Computing
Systems, ser. CHI EA ’20. New York, NY, USA: Association
for Computing Machinery, 2020, p. 1–9.
[Online]. Available:
https://doi.org/10.1145/3334480.3382827

[42] F. Mathis, J. H. Williamson, K. Vaniea, and M. Khamis, “Fast and secure
authentication in virtual reality using coordinated 3d manipulation
and pointing,” ACM Trans. Comput.-Hum. Interact., vol. 28, no. 1, jan
2021. [Online]. Available: https://doi.org/10.1145/3428121

[43] C. George, M. Khamis, D. Buschek, and H. Hussmann, “Investigating
the third dimension for authentication in immersive virtual reality and
in the real world,” in 2019 IEEE Conference on Virtual Reality and 3D
User Interfaces (VR), 2019, pp. 277–285.

[44] C. E. Rogers, A. W. Witt, A. D. Solomon,

and K. K.
Venkatasubramanian, “An approach for user identiﬁcation for head-
mounted displays,” in Proceedings of the 2015 ACM International
Symposium on Wearable Computers, ser. ISWC ’15. New York, NY,
USA: Association for Computing Machinery, 2015, p. 143–146.
[Online]. Available: https://doi.org/10.1145/2802083.2808391

[45] M. Sivasamy, V. Sastry, and N. Gopalan, “Vrcauth: Continuous authen-
tication of users in virtual reality environment using head-movement,” in
2020 5th International Conference on Communication and Electronics
Systems (ICCES), 2020, pp. 518–523.

[46] T. Mustafa, R. Matovu, A. Serwadda, and N. Muirhead, “Unsure
how to authenticate on your vr headset? come on, use your head!”
in Proceedings of the Fourth ACM International Workshop on Security
and Privacy Analytics, ser.
IWSPA ’18. New York, NY, USA:
[Online].
Association for Computing Machinery, 2018, p. 23–30.
Available: https://doi.org/10.1145/3180445.3180450

[47] J. Liebers, P. Horn, C. Burschik, U. Gruenefeld, and S. Schneegass,
“Using gaze behavior and head orientation for implicit identiﬁcation in
virtual reality,” in Proceedings of the 27th ACM Symposium on Virtual
Reality Software and Technology, ser. VRST ’21. New York, NY,
USA: Association for Computing Machinery, 2021. [Online]. Available:
https://doi.org/10.1145/3489849.3489880

[48] S. Luo, A. Nguyen, C. Song, F. Lin, W. Xu, and Z. Yan, “Oculock:
Exploring human visual system for authentication in virtual reality head-
mounted display,” in 2020 Network and Distributed System Security
Symposium (NDSS), 2020.

[49] D. Lohr, S.-H. Berndt, and O. Komogortsev, “An implementation of
eye movement-driven biometrics in virtual reality,” in Proceedings of
the 2018 ACM Symposium on Eye Tracking Research & Applications,
ser. ETRA ’18. New York, NY, USA: Association for Computing
Machinery, 2018. [Online]. Available: https://doi.org/10.1145/3204493.
3208333

[50] D. J. Lohr, S. Aziz, and O. Komogortsev, “Eye movement biometrics
using a new dataset collected in virtual reality,” in ACM Symposium
on Eye Tracking Research and Applications, ser. ETRA ’20 Adjunct.
New York, NY, USA: Association for Computing Machinery, 2020.
[Online]. Available: https://doi.org/10.1145/3379157.3391420

[51] H. Zhu, W. Jin, M. Xiao, S. Murali, and M. Li, “Blinkey: A two-factor
user authentication method for virtual reality devices,” Proc. ACM
Interact. Mob. Wearable Ubiquitous Technol., vol. 4, no. 4, dec 2020.
[Online]. Available: https://doi.org/10.1145/3432217

[52] K. Pfeuffer, M. J. Geiger, S. Prange, L. Mecke, D. Buschek,
and F. Alt, Behavioural Biometrics in VR: Identifying People from
Body Motion and Relations in Virtual Reality. New York, NY, USA:
Association for Computing Machinery, 2019, p. 1–12.
[Online].
Available: https://doi.org/10.1145/3290605.3300340

[53] A. Kupin, B. Moeller, Y. Jiang, N. K. Banerjee, and S. Banerjee,
“Task-driven biometric authentication of users in virtual reality (vr)
environments,” in MultiMedia Modeling, I. Kompatsiaris, B. Huet,
V. Mezaris, C. Gurrin, W.-H. Cheng, and S. Vrochidis, Eds. Cham:
Springer International Publishing, 2019, pp. 55–67.

from device trajectories

[54] A. Ajit, N. Banerjee, and S. Banerjee, “Combining pairwise feature
matches
for biometric authentication in
virtual reality environments,” in 2019 IEEE International Conference
on Artiﬁcial Intelligence and Virtual Reality (AIVR). Los Alamitos, CA,
USA: IEEE Computer Society, dec 2019, pp. 9–97. [Online]. Available:
https://doi.ieeecomputersociety.org/10.1109/AIVR46125.2019.00012
[55] J. Liebers, M. Abdelaziz, L. Mecke, A. Saad, J. Auda, U. Gruenefeld,
identiﬁcation in
F. Alt, and S. Schneegass, “Understanding user
virtual reality through behavioral biometrics and the effect of body
normalization,” in Proceedings of the 2021 CHI Conference on Human
Factors in Computing Systems, ser. CHI ’21. New York, NY, USA:
Association for Computing Machinery, 2021.
[Online]. Available:
https://doi.org/10.1145/3411764.3445528

[56] R. Miller, N. K. Banerjee, and S. Banerjee, “Within-system and cross-
system behavior-based biometric authentication in virtual reality,” in
2020 IEEE Conference on Virtual Reality and 3D User Interfaces
Abstracts and Workshops (VRW), 2020, pp. 311–316.

[57] ——, “Using siamese neural networks to perform cross-system behav-
ioral authentication in virtual reality,” in 2021 IEEE Virtual Reality and
3D User Interfaces (VR), 2021, pp. 140–149.

[58] I. Olade, C. Fleming, and H.-N. Liang, “Biomove: Biometric
user identiﬁcation from human kinesiological movements for virtual
reality systems,” Sensors, vol. 20, no. 10, 2020. [Online]. Available:
https://www.mdpi.com/1424-8220/20/10/2944

[59] Y. Shen, H. Wen, C. Luo, W. Xu, T. Zhang, W. Hu, and D. Rus,
“Gaitlock: Protect virtual and augmented reality headsets using gait,”

JOURNAL OF

16

IEEE Transactions on Dependable and Secure Computing, vol. 16, no. 3,
pp. 484–497, 2019.

[60] A. Jain, A. Ross, and S. Prabhakar, “An introduction to biometric
recognition,” IEEE Transactions on Circuits and Systems for Video
Technology, vol. 14, no. 1, pp. 4–20, 2004.

[61] S. Li, A. Ashok, Y. Zhang, C. Xu, J. Lindqvist, and M. Gruteser, “Whose
move is it anyway? authenticating smart wearable devices using unique
head movement patterns,” in 2016 IEEE International Conference on
Pervasive Computing and Communications (PerCom), 2016, pp. 1–9.

[62] S. Jafarnejad, “Virtual reality driving simulator dataset,” https://www.

kaggle.com/sasanj/virtual-reality-driving-simulator-dataset/metadata,
August 2017.

[63] C. Wu, Z. Tan, Z. Wang, and S. Yang, “A dataset for exploring user
behaviors in vr spherical video streaming,” in Proceedings of the 8th
International Conference on Multimedia Systems, ser. MMSys ’17.
Taipei, Taiwan: ACM, 2017.

[64] R. B. Hill, “Apparatus and method for identifying individuals through
their retinal vasculature patterns,” Aug. 22 1978, uS Patent 4,109,237.
[65] A. Maeder, C. Fookes, and S. Sridharan, “Gaze based user authen-
tication for personal computer applications,” in Proceedings of 2004
International Symposium on Intelligent Multimedia, Video and Speech
Processing, 2004., 2004, pp. 727–730.

[66] I. Sluganovic, M. Roeschlin, K. B. Rasmussen, and I. Martinovic, “Using
reﬂexive eye movements for fast challenge-response authentication,”
in Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security, ser. CCS ’16. New York, NY, USA:
Association for Computing Machinery, 2016, p. 1056–1067. [Online].
Available: https://doi.org/10.1145/2976749.2978311

[67] I. Rigas, O. Komogortsev, and R. Shadmehr, “Biometric recognition
via eye movements: Saccadic vigor and acceleration cues,” ACM
Trans. Appl. Percept., vol. 13, no. 2, jan 2016. [Online]. Available:
https://doi.org/10.1145/2842614

[68] C. D. Holland and O. V. Komogortsev, “Complex eye movement pattern
biometrics: Analyzing ﬁxations and saccades,” in 2013 International
Conference on Biometrics (ICB), 2013, pp. 1–8.

[69] F. Mathis, H. I. Fawaz, and M. Khamis, “Knowledge-driven biometric
authentication in virtual reality,” in Extended Abstracts of the 2020 CHI
Conference on Human Factors in Computing Systems, ser. CHI EA ’20.

New York, NY, USA: Association for Computing Machinery, 2020, p.
1–10. [Online]. Available: https://doi.org/10.1145/3334480.3382799
[70] J. Wang and B. Gao, “Analysis of multi-attribute user authentication to
against man-in-the-room attack in virtual reality,” in HCI International
2021 - Posters, C. Stephanidis, M. Antona, and S. Ntoa, Eds. Cham:
Springer International Publishing, 2021, pp. 455–461.

[71] J. von Willich, M. Funk, F. M¨uller, K. Marky,

J. Riemann,
and M. M¨uhlh¨auser,
“You invaded my tracking space! using
augmented virtuality for spotting passersby in room-scale virtual
reality,” in Proceedings of the 2019 on Designing Interactive Systems
Conference,
ser. DIS ’19. New York, NY, USA: Association
for Computing Machinery, 2019, p. 487–496. [Online]. Available:
https://doi.org/10.1145/3322276.3322334

[72] N. Puttawong, V. Visoottiviseth, and J. Haga, “Vrﬁwall virtual reality
edutainment for ﬁrewall security concepts,” in 2017 2nd International
Conference on Information Technology (INCIT), 2017, pp. 1–6.
[73] V. Visoottiviseth, A. Phungphat, N. Puttawong, P. Chantaraumporn, and
J. Haga, “Lord of secure: the virtual reality game for educating network
security,” in 2018 Seventh ICT International Student Project Conference
(ICT-ISPC), 2018, pp. 1–6.

[74] P. Ulsamer, A. Sch¨utz, T. Fertig, and L. Keller, “Immersive story-
telling for information security awareness training in virtual reality,”
in Proceedings of the 54th Hawaii International Conference on System
Sciences, 2021, p. 7153.

[75] M. Henrique da Silva, A. Cotelli do Esp´ırito Santo, E. R. Marins,
A. P. Legey de Siqueira, D. M. Mol, and A. Carlos de Abreu Mol,
“Using virtual reality to support
the physical security of nuclear
facilities,” Progress in Nuclear Energy, vol. 78, pp. 19–24, 2015.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
S0149197014001851

[76] F. Mathis, K. Vaniea, and M. Khamis, RepliCueAuth: Validating the
Use of a Lab-Based Virtual Reality Setup for Evaluating Authentication
Systems. New York, NY, USA: Association for Computing Machinery,
2021. [Online]. Available: https://doi.org/10.1145/3411764.3445478
[77] F. Mathis, “[dc] virsec: Virtual reality as cost-effective test bed for
usability and security evaluations,” in 2021 IEEE Conference on Virtual
Reality and 3D User Interfaces Abstracts and Workshops (VRW), 2021,
pp. 705–706.

